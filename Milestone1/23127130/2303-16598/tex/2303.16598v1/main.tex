\documentclass{elsarticle}
%These are the used packages.
%------------------------------------------------------------------------
\usepackage{imakeidx}
\makeindex[intoc]
\newcommand{\BH}[1]{\large\text{\hyperpage{#1}}\normalsize}
\newcommand{\IN}[1]{\index{#1|BH}#1}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry} 
\usepackage[titletoc]{appendix}
\usepackage{amsmath,amsthm,amssymb}
\usepackage{bbm}
\usepackage{dsfont}
\usepackage{setspace}
\usepackage{multicol}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows}
\usetikzlibrary{arrows.meta}
\usepackage{capt-of}
\bibliographystyle{plainnat}
\usepackage[colorlinks]{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    citecolor=red
}
\usepackage{cleveref}
\usepackage{titleref}
\allowdisplaybreaks
\newcommand{\teddy}[1]{{\color{red} #1}}
\newcommand{\teddydone}[1]{{\color{black} #1}}
\newcommand{\mahya}[1]{{\color{blue} #1}}
\usepackage[normalem]{ulem}
\newcommand{\stkout}[1]{\ifmmode\text{\sout{\ensuremath{#1}}}\else\sout{#1}\fi}
\newcommand{\mynode}[2]{\tikz[remember picture]{\node[inner sep=0pt](#1){$#2$};}}

%These are shortcuts for names of commonly used sets.
%------------------------------------------------------------------------
\def\R{{\mathbb R}} %reals
\def\Z{{\mathbb Z}} %integers
\def\N{{\mathbb N}} %naturals
\def\Q{{\mathbb Q}} %rationals
\def\C{{\mathbb C}} %complexes
\def\F{{\mathbb F}} %a general field
\def\E{{\mathbb E}} %typically used for expectations
\def\P{{\mathcal P}} %partitions
\def\G{{\mathcal G}} %w-random graph
\def\W{{\mathcal W}} %graphon space
\def\S{{\mathcal S}} %fancy set
\def\B{{\mathcal B}}
\def\UL{{\text{UL}}}
\def\LR{{\text{LR}}}
\def\I{{\mathcal I}}
\def\blue{{\textcolor{blue}}}
\newtheorem*{lemma*}{Lemma}

%------------------------------------------------------------------------

%These are shortcuts for names of functions that pop up often in this paper (e.g. the parameter Psi).
%------------------------------------------------------------------------
\def\wPsi{\widetilde{\Psi}} %the continuous parameter Psi
%------------------------------------------------------------------------

%These are commands for common notations (e.g. norms).
%------------------------------------------------------------------------
\newcommand{\norm}[1]{\left\lVert#1\right\rVert} %\norm{a} will output \|a\|

%------------------------------------------------------------------------

%The regular AMS theorem environments.
%------------------------------------------------------------------------
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{hypothesis}[theorem]{Hypothesis}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{case}{Case}
\newtheorem{subcase}{Case}
\numberwithin{subcase}{case}
\newtheorem{notation}[theorem]{Notation}
%------------------------------------------------------------------------

\begin{document}
\begin{frontmatter}

\title{Robust recovery of Robinson $L^p$-graphons}

\author{Mahya Ghandehari}
\ead{mahya@udel.edu}
\author{Teddy Mishura}
\ead{tmishura@udel.edu}
\address{Department of Mathematical Sciences, Ewing Hall, University of Delaware in Newark, DE}

\begin{abstract}
In this paper, we study the Robinson graphon completion/recovery problem for the class of $L^p$-graphons. 
 We introduce a function $\Lambda$  on the space of $L^p$-graphons, which measures the extent to which a graphon $w$ exhibits the Robinson property: for all $x<y<z$, $w(x,z)\leq \min\{w(x,y),w(y,z)\}$. We prove that the function $\Lambda$ satisfies the following: (1) $\Lambda$ is compatible with the cut-norm, in the sense that if two graphons are close in the cut-norm, then their $\Lambda$ values are close; and (2) when $p > 5$, every $L^p$-graphon $w$ can be approximated by a Robinson graphon, with error of the approximation bounded in terms of \IN{$\Lambda(w)$}. When $w$ is a noisy version of a Robinson graphon, our method provides a concrete formula for recovering the Robinson graphon approximating $w$ in cut-norm. 
 \end{abstract}

\begin{keyword}
%% keywords here, in the form: keyword \sep keyword
graphons \sep $L^p$-graphons \sep Robinson \sep Recovery \sep
%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)
\MSC[2020]  05C62  \sep 15A83 \sep 15B52
\end{keyword}
\end{frontmatter}
\tableofcontents
%-------------------------------------------------------------------------
%-------------------------------------------------------------------------
%-------------------------------------------------------------------------
%-------------------------------------------------------------------------
\section{Introduction}
%-------------------------------------------------------------------------
%MATRIX COMPLETION
%-------------------------------------------------------------------------
Given an incomplete matrix $M_I$ with many missing entries,  is it possible to recover the underlying complete matrix $M$?
An instance of such a scenario is when data is aggregated from customer ratings, where any given customer only rates few items. In general, this problem is ill-posed; indeed, with low dimensional information, it is not possible to uniquely recover high dimensional data. However, in practical applications, it is often the case that additional structure about the original matrix $M$ is known. In the above example regarding costumer ratings, it is usually assumed that most people's preferences are based on very few factors, implying that the complete matrix $M$ should be low rank. Leveraging this assumption makes the completion of $M_I$ quite tractable, even if the majority of its entries are missing. 
%
In general, the problem of filling in the incomplete entries in a matrix $M_I$ under the condition that the completed matrix satisfies a specified structural property is known as \emph{matrix completion problem}. 
Due to its many applications in data science, the completion problem for low rank matrices has gained the attention of many researchers (see e.g.~\cite{Candes2009, Tao2010, keshavan2010, recht2011, Gross, SunLuo, Vandereycken, Jain}).
Matrix completion problem has also been investigated when other structural properties (e.g.~Hankel, Toeplitz, and moment structures) are considered; see \cite{Fazel,WANG2016133,eftekhari2018,GOYENS2023498} for some examples.



Unfortunately, even known information can be corrupt by noise. If $\hat{M}$ is an estimate for the matrix $M$, structural knowledge about $M$ often fails to be enough for exact identification of $M$ from $\hat{M}$. Thus, in the case of noise, the problem of completion becomes that of \emph{recovery}: Given an observed matrix $\hat{M}$, find a matrix close to $M$ that satisfies a specified structural property.  
For examples of recovery of noisy matrices, see \cite{candes2010noise,Koltchinskii2011,klopp-noisy,Keshavan-noisy,Rohde,agarwal2012,Klopp2017,tao2011} for low rank matrices, \cite{flammarion2019} for  monotone matrices, and \cite{cai2011} for  covariance matrices.

%-------------------------------------------------------------------------
%ROBINSON MATRIX
%-------------------------------------------------------------------------
%
In this paper, we study the recovery problem for the \textit{Robinson} matrices.  A \emph{Robinson matrix}, also called an \emph{R-matrix}, is a symmetric matrix $A=[a_{ij}]$ such that for $i < j < k$ we have 
%
\begin{equation*}
    a_{ik} \leq \min\{a_{ij},a_{jk}\}.
\end{equation*}  
%
Robinson matrices are well-studied objects in data science, largely because of their connection with the  classical seriation problem \cite{fogel2014,Liiv_2010,Mirkin1984GraphsAG,prea-fortin,seston}. The objective of the seriation problem is to use pairwise comparisons of a set of items to recover their `linear' ordering. Determining when a \IN{matrix} can be permuted into a Robinson matrix, and finding a proper Robinson ordering, are well-studied problems; in fact, they can be solved in polynomial time; see \cite{Mirkin1984GraphsAG} for the original algorithm, and \cite{atkins1998,Fortin2017RobinsonianMR,LAURENT2017151,laurent2017} for more recent efficient algorithms. 
%
Recovery of Robinson ordering, when the underlying matrix is perturbed by noise,  has been studied before: For a polynomial time approximate algorithm when seeking infinity norm approximations, see \cite{chepoi2009}, and for a discussion on the NP-hardness of this problem when other $p$-norm approximations are required, see \cite{barthelemy2001np}.

%-------------------------------------------------------------------------
%GRAPHONS
%-------------------------------------------------------------------------
To put matrices of various size in one framework, and also to allow sampling from such matrices, we use \emph{graphons}. 
These are symmetric and measurable functions $w: [0,1]^2 \to \R$. A graphon is called an $L^p$-graphon if its $p$-norm is finite. 
$L^{\infty}$-graphons are typically referred to as graphons, and were introduced in \cite{LOVASZ2006933} as the limit objects of converging sequences of dense graphs (i.e.~ graph sequences $\{G_n\}$ in which the number of edges is quadratic in the number of vertices).
%
Borgs {et al.}~extended this point of view in \cite{Borgs_2018,Borgs_2019}, and proved that $L^p$-graphons (for $1 < p < \infty$)  are limit objects of sparse graph sequences.
%
The mode of convergence that defines these limits is the \textit{cut norm}, which was introduced in \cite{friezekannan} for matrices, and can be extended to graphons in a natural manner: 
%
\begin{equation*}
\|w\|_{\square}=\sup_{A,B \subseteq [0,1]}\Bigg|\iint_{A\times B} w(x,y)dxdy\Bigg|,
\end{equation*}
%
where $A,B$ are Lebesgue measurable.
%
Similar to the case of matrices, we say an $L^p$-graphon $w:[0,1]^2 \to \R$ is a \emph{Robinson} graphon if for all $x < y < z$, 
%
\begin{equation*}
 w(x,z)\leq \min\{w(x,y),w(y,z)\}.
\end{equation*}
%
An $L^p$-graphon is called \emph{Robinson a.e.}~if it is almost everywhere equal to a Robinson graphon. 
%

In this paper, we study the graphon completion/recovery problem for the class of Robinson graphons. 
Having recovered the limiting Robinson graphon of a class of converging graph sequences,  one can use efficient randomized algorithms in \cite{janssen2022} to seriate the graphs.
%
Naturally, we measure proximity in terms of cut norm, when performing the Robinson graphon recovery.
Our goal here is to obtain a statement of the following general form:
\begin{quote}
\emph{Given a graphon $w$ that is almost Robinson, find a Robinson graphon $u$ such that $\|w-u\|_{\Box}$ is sufficiently small.}
\end{quote}
%
As a first step towards such results, we need to formalize the notion of almost Robinson graphons. 
This is done by devising a graphon function, say $\Lambda$, that acts as a gauge of Robinson property by counting (aggregated) local violations of the Robinson property. 
Such a function is considered a suitable measurement of the Robinson property if it is subadditive and satisfies the following three properties:
%
\begin{itemize}
    \item\textbf{(Recognition)} $\Lambda(w) = 0$ if and only if $w$ is Robinson a.e.

    \item\textbf{(Continuity)} $\Lambda$ is continuous with respect to the cut norm.

    \item\textbf{(Recovery)} Given a graphon $w$, there exists a Robinson graphon $u$ such that $\|w-u\|_{\Box} \leq f(\Lambda(w))$. Here, $f:[0,\infty) \to [0,\infty)$ is a fixed decreasing function with $\lim_{x \to 0^+} f(x) = 0$, which is independent of $w$.
\end{itemize}
%

In this paper, we design an $L^p$-graphon function $\Lambda$, which roughly speaking, measures local violations of the Robinson property for a graphon (Definition~\ref{def:lambda}). 
We prove that $\Lambda$ is a suitable measurement for the Robinson property when $p > 5$; that is, we show that $\Lambda$
satisfies the properties of recognition and continuity (Proposition~\ref{prop:Lambda-prop}), as well as Robinson recovery  (Theorem~\ref{thm:main-result}). 
%
This extends the results of \cite{Chuangpishit_2015,ghandehari2020graph}, where a suitable graphon function $\Gamma$ on the space of $L^\infty$-graphons was introduced.
Our results (in particular, Definition~\ref{def:R(w)} and Theorem~\ref{thm:main-result}) provide us with a recipe for graphon recovery in the class of Robinson graphons.
%Through application of these ideas and careful estimates, the function $\Lambda$ not only extends the results of $\Gamma$ to $L^p$-graphons, but improves the results on $L^{\infty}$-graphons as well. 

%-------------------------------------------------------------------------
%ORGANIZATION OF THE PAPER
%-------------------------------------------------------------------------
This paper is organized as follows: In Section \ref{sec:notationbg}, we introduce various necessary background involving graphons and the study of the Robinson property. Section \ref{sec:previousparam} discusses previous work that has been done to recover Robinson graphons in the cut norm; here, we also comparatively summarize our own graphon recovery results. In Section \ref{sec:lambda}, alongside the building of necessary machinery and statement of technical lemmas, we present proofs of our main recovery results. The aforementioned technical lemmas are proven in Appendix \ref{section:proofs of lemmas}. 

%-------------------------------------------------------------------------
%-------------------------------------------------------------------------
%-------------------------------------------------------------------------
%-------------------------------------------------------------------------
\section{Notation and background}\label{sec:notationbg}
In this section of the paper, we present necessary background and notation for the reader, organized into two parts. We begin with basic notation used throughout the paper; afterwards, we present graph limit theory, stating required definitions alongside notable results, then transition into explanation of the Robinson property for both matrices and graphons. 

All functions and sets discussed during this paper are assumed to be measurable. The symmetric difference between two sets $A$ and $B$ is denoted $A \Delta B$. The notation $\|\cdot\|_p$ is used to represent the standard $p$-norm; that is, for a function $f:X \to \R$ and $1 \leq p < \infty$,
%
\begin{equation*}
    \|f\|_p := \left(\int_X |f|^p\right)^{\frac{1}{p}} \mbox{ and } \|f\|_{\infty} := \inf_{a \in \R}\{f(x) \leq a \mbox{ a.e.}\}.
\end{equation*}
%
Additionally, the notation $\E(X)$ is used to denote the expectation of the random variable $X$.
\subsection{Graphons and the cut norm}
We begin by defining the graphon, the fundamental building block of graph limit theory, in several of its myriad forms.
%
\begin{definition}[\IN{Graphon space}] We shall introduce several types of functions here, noting that unless otherwise stated, the word \emph{graphon} will be used interchangeably throughout the text.
\begin{itemize}
    \item Let $\W_0$ be the set of all symmetric, measurable functions $w:[0,1]^2 \to [0,1]$. The elements of this set are called \textit{graphons}.

    \item Let $\W^{\infty}$ be the set of all bounded, symmetric, measurable functions $w:[0,1]^2 \to \R$. The elements of this set are called \textit{kernels}.

    \item Let $\W^p$ be the set of all symmetric, measurable functions $w:[0,1]^2 \to \R$ such that $\|w\|_p < \infty$ for $p \geq 1$. The elements of this set are called $L^p$ \textit{graphons}.
\end{itemize}
\end{definition}
%
It is clear that $\W_0 \subset \W^{\infty} \subseteq \W^p$ for $p \geq 1$. We mention as well the space of \emph{step graphons} $\mathcal{S} \subseteq \W^{\infty}$, which comprises the set of symmetric step functions on $[0,1]^2$; that is, for $w_n \in \mathcal{S}$, there exists some partition $\mathcal{P}= \{P_1,\ldots,P_m\}$ of $[0,1]$ such that $w_n$ is constant on $P_i \times P_j$ for all $1 \leq i,j \leq m$. We define $\mathcal{S}_0 \subseteq \W_0$ similarly.

Now that we have introduced several function spaces, we naturally introduce a norm. Specifically, we shall work with the \textit{\IN{cut norm}}, which was introduced in \cite{friezekannan} for matrices and is defined for graphons below.
%
\begin{definition}[Cut norm]
Let $w \in \W^1$. We define the \textit{\IN{cut norm}} by
\begin{equation*}
    \|w\|_{\square} = \sup_{S,T \subseteq [0,1]}\Bigg|\iint_{S \times T}w(x,y)dxdy\Bigg|
\end{equation*}
where the supremum is taken over all measurable subsets $S$ and $T$.
\end{definition}
%
\noindent It is obvious that for any function $w \in \W^1$, 
%
\begin{equation*}
    \|w\|_{\square} \leq \|w\|_{1} \leq \|w\|_{p} \leq \|w\|_{\infty}
\end{equation*}
%
for all $p \geq 1$. Another notion of distance used to compare graphons is the \emph{cut distance}, a more general form of relabeling graphs to minimize norm difference. Applied to graphons, it is the set $[0,1]$ that must be relabeled. Let $\Phi$ be the set of all measure preserving bijections from $[0,1]$ to $[0,1]$; that is, if $A \subset [0,1]$, then $|\Phi(A)| = |A|$. The \textit{\IN{cut distance}} between two graphons $u$ and $w$ is
%
\begin{equation*}
    \delta_{\square}(u,w) = \inf_{\phi \in \Phi}\|u-w^{\phi}\|_{\square},
\end{equation*}
%
where $w^{\phi}(x,y) = w(\phi(x),\phi(y)).$ However, the distance $\delta_{\square}$ is only a pseudometric; we can identify graphons of cut distance 0 to get the set $\widetilde{\W}_0$ of \textit{unlabeled graphons}. $\widetilde{\W}$ and $\widetilde{\W}^p$ are defined similarly. While these metrics may seem complicated, they provide a huge benefit: For $p > 1$, the metric space $(\widetilde{W}^p,\delta_{\Box})$ has a compact unit ball. For $p=1$, additional conditions are required to ensure compactness, though we do not consider this case in the paper. Additionally, the \IN{cut norm} and \IN{cut distance} do not just exist as extrema---for the \IN{cut norm}, the supremum is achieved, and likewise for the \IN{cut distance}, the infimum is achieved \cite[Lemma 8.10]{lovaszbook}.

In the business of \IN{graphon}s, one will commonly have to deal with the average of functions over sets of the form $S\times T$, as is evidenced by the definition of the cut norm. Thus, some notation is introduced to allow us to easily refer to common objects related to such averages. Let $w \in \W$ and let $A,B \subseteq [0,1]$. The \textit{\IN{cell average}} of $w$ over $A \times B$ is given by 
%
\begin{equation*}
\overline{w}(A\times B) = \frac{1}{|A \times B|}\iint_{A\times B}w~dxdy.
\end{equation*}
%
Given a fixed $L^p$-graphon $w \in \W^p$, there exists a specific construction of a step function $w_{\mathcal{P}}$ such that $\|w-w_{\mathcal{P}}\|_p$ is small for sufficiently many steps; it is possible to describe this construction in terms of cell averages, and we do so below. Let $w \in \W^1$ and let $\mathcal{P} = (S_1,...,S_k)$---where we assume $|S_i|>0$---be a partition of $[0,1]$ into a finite number of nonempty measurable sets. We define the function $w_{\mathcal{P}}$ by
%
\begin{equation*}
    w_{\mathcal{P}}(x,y) = \frac{1}{|S_i\times S_j|}\iint_{S_i \times S_j}w(x,y)dxdy = \overline{w}(S_i\times S_j)\quad (x \in S_i,y \in S_j),
\end{equation*}
%
where the operator $w \mapsto w_{\mathcal{P}}$ is called the \textit{\IN{stepping operator}}. The \IN{stepping operator} does not increase either the $p$-norm or cut norm \cite{Borgs_2019} of any graphon $w$ it is applied to; indeed, if $w \in \W^1$, $\mathcal{P}$ is any partition of $[0,1]$ into a finite number of nonempty measurable sets, and $p \geq 1$, then
%
\begin{equation*}
    \|w_{\mathcal{P}}\|_p \leq \|w\|_p ~\text{ and } ~\|w_{\mathcal{P}}\|_{\square} \leq \|w\|_{\square}.
\end{equation*}
% 
We note that this property is sometimes referred to as being \textit{contractive}.

\subsection{The Robinson property}
The Robinson property for matrices was first introduced in the study of the classical seriation problem \cite{robinson_1951}, whose objective is to order a set of items so that similar items are placed close to one another. The seriation question translates naturally into a question regarding symmetric matrices which can be turned into Robinson matrices. A symmetric \IN{matrix} $A=[a_{ij}]$ is said to be a \emph{Robinson \IN{matrix}} if
%
\begin{equation*}
   i \leq j \leq k \implies a_{ik} \leq \min\{a_{ij},a_{jk}\}.
\end{equation*}  
%
A symmetric \IN{matrix} $A$ is called \textit{Robinsonian} if it becomes a Robinson \IN{matrix} after simultaneous application of a permutation $\pi$ to its rows and columns. In that case, the permutation $\pi$ is called a \textit{Robinson ordering} of $A$. If the entries $a_{ij}$ of the symmetric \IN{matrix} $A$ represent similarity of items $i$ and $j$, then the Robinson ordering represents a linear arrangement of the items so that similar items are placed closer together. 

The Robinson property for $L^p$-graphons is defined similarly and was first considered in \cite{Chuangpishit_2015}. When measuring large quantities of matrices or graphs for the Robinson property, such as in quality analysis of data, it is an interesting and useful question to determine if these objects can be viewed as samples of some process $w$. Were this the case, oftentimes only the Robinson property of the process $w$ would need to be analyzed for quantitative results concerning the data as a whole. To this end, an $L^p$-graphon $w \in \W^p$ is said to be \emph{Robinson} if 
%
\begin{equation*}
   x \leq y \leq z \implies w(x,z) \leq \min\{w(x,y),w(y,z)\}.
\end{equation*}  
%
We call an $L^p$ \IN{graphon} \textit{Robinson almost everywhere}, or Robinson a.e.~for short, if it is equal a.e.~to a Robinson $L^p$ \IN{graphon}. An $L^p$ \IN{graphon} $w \in \W^p$ is called \textit{Robinsonian} if there exists a Robinson $L^p$ \IN{graphon} $u \in \W^p$ such that $\delta_{\Box}(w,u) = 0$. Robinson and Robinsonian graphons and kernels are identically defined.

This natural extension of the Robinson property to the world of graphons results in the addition of much difficulty; for example, the problem of finding the Robinson ordering of a matrix becomes finding a measure preserving bijection that properly re-orders a graphon, a clearly less tractable problem for most graphons of any interest. As a result of this phenomenon, much effort has been focused in the area of measuring and approximating the Robinson property of graphons---if a graphon is ``close enough'' to being Robinson, it might not need to be re-ordered at all for results about its samples to hold. We discuss this in more detail in the next section.
%-------------------------------------------------------------------------
%-------------------------------------------------------------------------
%-------------------------------------------------------------------------
%-------------------------------------------------------------------------
\section{Robinson property: measurement and recovery}\label{sec:previousparam}
The recovery problem for Robinson matrices can be extended to the realm of graphons, where we aim for results of the form:
%
%\begin{quote}
{If a graphon $w$ is almost Robinson, then it is $\|\cdot\|_\Box$-close to a Robinson graphon.}
%\end{quote}
%
We formalize the meaning of an almost Robinson graphon by devising a graphon function that acts as a gauge of Robinson property.
Such a function is considered suitable if it \emph{recognizes} Robinson graphons (i.e.~attains zero precisely when applied to  Robinson graphon), is \emph{continuous} on the space of graphons (i.e.~attains similar values when applied to matrices of similar global structure), 
and provides a \emph{stable} measurement of the Robinson property (i.e.~if the number of local violations is small, then the matrix is indeed close to a Robinson matrix in the global sense). 
In this section, we give a brief overview of past results utilizing such graphon functions for recovering bounded Robinson graphons in cut norm \cite{Chuangpishit_2015}, before discussing efforts to tackle this problem in the world of $L^p$-graphons.

\subsection{Bounded graphons} 
The function $\Gamma:\W_0 \to [0,1]$ was introduced in \cite{Chuangpishit_2015} and was used to estimate how close a given graphon was to the set of Robinson graphons in \IN{cut norm}. We recall the definition of \IN{$\Gamma$}, noting that it can naturally extend  to $\W^1$. For $w \in \W^1$ and a measurable subset $A$ of $[0,1]$, we define $\Gamma(w,A)$ to be the following integral
%
\begin{equation*}
    \Gamma(w,a) =\iint_{y<z}\left[\int_{x \in A \cap [0,y]} (w(x,z)-w(x,y))dx\right]_+dydz+ \iint_{y<z}\left[\int_{x \in A \cap [z,1]} (w(x,y)-w(x,z))dx\right]_+dydz,
\end{equation*}
%
where $[x]_+ = \max(x,0)$. Moreover, $\Gamma(w)$ is defined as $\Gamma(w) := \sup_{A}\Gamma(w,A)$, where the supremum is taken over all  measurable subsets of $[0,1]$.
%
The function $\Gamma$ satisfies the following desirable properties:
%
\begin{itemize}
 \item[(i)] \label{item:gamma_one}({\bf Recognition} \cite[Proposition 4.2]{Chuangpishit_2015}) $w \in \W_0$ is Robinson a.e. if and only if $\Gamma(w)=0$.
 \item[(ii)] \label{item:gamma_two} ({\bf Continuity} \cite[Lemma 6.2]{Chuangpishit_2015}) $\Gamma$ is continuous on $\W_0$ with respect to cut norm.
 \item[(iii)] \label{item:gamma_three}{(\bf recovery} \cite[Theorem 3.2]{ghandehari2020graph})
For every $w \in \W_0$, there exists a Robinson graphon $u \in \W_0$ satisfying
\begin{equation*}
    \|u-w\|_{\Box} \leq 14\Gamma(w)^{1/7}.
\end{equation*} 
\end{itemize}
%
Combining all three statements above, it was proved in \cite{ghandehari2020graph} that $\Gamma$ recognizes samples of Robinson graphons: these are precisely graph sequences whose $\Gamma$-values converge to 0. 
%
\begin{remark}
The proof of continuity of $\Gamma$ in \hyperref[item:gamma_two]{(ii)} relies on continuity of the triangular cut operator on 
${\mathcal W}_0$, which cannot be generalized to graphons $w \in \W^p$ (see \cite{MISHURA202226}). Thus, the cut norm continuity of $\Gamma$ cannot be easily extended to the setting of $L^p$-graphons. In fact, whether $\Gamma$ is cut norm continuous on $\W^p$ remains an open question.
\end{remark}
%
\begin{remark}
In \cite{janssen2019optimization}, the first author and collaborators introduce a matrix function that measures how badly a given matrix fails to be Robinson. They also show that this function satisfies (i), (ii), and (iii) with 1-norm instead of cut norm. It is not hard to see that the function from \cite{janssen2019optimization} does not extend to a cut norm continuous function on $\W_0$; thus it is of no interest in this paper.
\end{remark}
%
\subsection{$L^p$-graphons}
Let $1\leq p\leq \infty$. We now introduce the new function \IN{$\Lambda : \W^p \to \R$} on $L^p$-\IN{graphon}s for measuring the Robinson property. We define the following notation to facilitate ease of reading. Let $A,B \subset \R$. We say that $A \leq B$ if for all $a \in A$ and $b \in B$, we have that $a \leq b$. 
\begin{definition}[Robinson measurement function]\label{def:lambda}
    Let $w \in \mathcal{W}^1$. Define
%
\begin{equation}\label{eq:lambda}
    \Lambda(w) = \frac{1}{2}\sup_{\substack{A \leq B \leq C, \\ |A|=|B|=|C|}}\bigg[\iint_{A\times C}w~dxdy-\iint_{B\times C} w~dxdy\bigg]\nonumber\\
    + \frac{1}{2}\sup_{\substack{X \leq Y \leq Z, \\ |X|=|Y|=|Z|}}\bigg[\iint_{X\times Z}w~dxdy-\iint_{X\times Y} w~dxdy\bigg]
\end{equation}
%  
where $A,B,C$ and $X,Y,Z$ are measurable subsets of $[0,1]$. 
\end{definition}
%
Informally, \IN{$\Lambda$} can be thought of as extending the Robinson property from pointwise comparison to comparison of blocks. 
%
It turns out that $\Lambda$ extends the properties of $\Gamma$ to $L^p$-graphons for $p \geq 1$, that is, 
%
\begin{itemize}
    \item[(i)] \textbf{(Recognition)} A graphon $w \in \W^p$ is Robinson a.e.~if and only if $\Lambda(w)=0$.  

    \item[(ii)] \textbf{(Continuity)} \IN{$\Lambda$} is continuous with respect to cut-norm, i.e., $|\Lambda(w)-\Lambda(u)|\leq 2\|w-u\|_{\Box}$ for $u,w \in \W^1$.

    \item[(iii)] {(\bf Recovery)} For every $w \in W^p$ where $p > 5$, there exists a Robinson graphon $u \in \W^p$ satisfying
    \begin{equation*}
        \|u-w\|_{\Box} \leq 78\Lambda(w)^{\frac{p-5}{5p-5}}.
    \end{equation*} 
\end{itemize}
%
In fact, we provide a recipe for obtaining the Robinson approximation $u$ for a given graphon $w$ (Definition~\ref{def:R(w)}).
We devote the next section to the proofs of the three statements above. As a corollary, we observe that our results for $\Lambda$, 
when applied to $L^{\infty}$-graphons, provide an improvement on the bound of Robinson approximation in \cite{ghandehari2020graph}.
%-------------------------------------------------------------------
%-------------------------------------------------------------------
%-------------------------------------------------------------------
%-------------------------------------------------------------------
\section{Robinson recovery of $L^p$-graphons}\label{sec:lambda}
In this section, we introduce and study the new function \IN{$\Lambda$} on $L^p$-\IN{graphon}s for measuring the Robinson property.  We borrow the following terminology from \cite{ghandehari2020graph}.
The upper triangle of the unit square is denoted
%
\begin{equation*}
\Delta=\left\{(x,y)\in[0,1]^2:\ x\leq y\right\}.
\end{equation*}
%
 The \textit{upper left (UL)} and \textit{lower right (LR)} regions of a given point $(a,b) \in \Delta$ are given by
%
\begin{align*}
\UL(a,b)&=[0,a]\times[b,1],\\
\LR(a,b)&=[a,b]\times[a,b]\cap \Delta.
\end{align*}
%
From Definition~\ref{def:lambda}, we have $\Lambda(w) \geq 0$ for all  $w\in \W^1$, as we may take $A=B=C=X=Y=Z=\emptyset$.  Moreover, 
%
\begin{equation*}
\Lambda(w)\leq \frac{1}{2}\Bigg(\iint_{A\times C}|w|dxdy+\iint_{B\times C}|w|dxdy+\iint_{X\times Z}|w|dxdy+\iint_{X\times Y}|w|dxdy\Bigg) \leq \|w\|_1,
\end{equation*}
%
implying that $\Lambda(w) \leq \|w\|_p$ for every $p\geq 1$. 
%
Note that since the supremum is sublinear, we also have that $\Lambda$ is subadditive, i.e., for all $u,w \in \W^p$
\begin{equation}\label{eq:Lambda-prop}
    \Lambda(u+w) \leq \Lambda(u) + \Lambda(w).
\end{equation}
%
Next, we show that $\Lambda$ shares important properties with $\Gamma$.
%
\begin{proposition}\label{prop:Lambda-prop}
Let $1\leq p\leq \infty$. Suppose $w, u\in \W^p$. Then we have
\begin{itemize}
%
\item[(i)] (Continuity) \IN{$\Lambda$} is continuous with respect to cut-norm, i.e., $|\Lambda(w)-\Lambda(u)|\leq 2\|w-u\|_{\Box}$. \label{item:Lambda-cts}
%    
\item[(ii)] (Recognition) \IN{$\Lambda$} characterizes Robinson $L^p$-\IN{graphon}s, i.e.,  $w$ is Robinson a.e.~if and only if $\Lambda(w)=0$. \label{item:lambda:recognizes}
\end{itemize}
\end{proposition}
%
\begin{proof}
To prove (i), let $w,u \in \mathcal{W}^1$, and fix $\epsilon > 0$. There exist measurable sets $A\leq B\leq C$ with equal size and measurable sets $X\leq Y\leq Z$ with equal size such that
%
\begin{equation}\label{eq:lambdaepbound}
\frac{1}{2}\bigg(\iint_{A\times C}w~dxdy-\iint_{B\times C}w~dxdy + \iint_{X\times Z}w~dxdy-\iint_{X\times Y} w~dxdy\bigg) \geq \Lambda(w)-\epsilon.
\end{equation}
%
Thus, combining \eqref{eq:lambdaepbound} with the definition of $\Lambda(u)$, we get that
%
\begin{eqnarray*}
    2(\Lambda(w)-\Lambda(u)-\epsilon) \leq
    \iint_{A \times C}(w-u) + \iint_{B \times C}(u-w) 
  + \iint_{X\times Z} (w-u)+\iint_{X \times Y}(u-w)
    \leq 4\|w-u\|_{\square}.
\end{eqnarray*}
%
The proof for $\Lambda(u)-\Lambda(w)$ follows the same logic. Taking $\epsilon \to 0$, we get $|\Lambda(w)-\Lambda(u)| \leq 2\|w-u\|_{\square}.$ 

To prove (ii), observe that if $w$ is Robinson a.e., then $\Lambda(w) = 0$. To prove the reverse direction, suppose $\Lambda(w) = 0$. For $n \in \mathbb{N}$, let $w_n = w_{\mathcal{P}_n}$, where $\mathcal{P}_n$ is the partition $\big\{I_i= (\frac{i-1}{n},\frac{i}{n}]\big\}_{i=1}^n$. Note that as $\Lambda(w) = 0,$ for any choice of measurable subsets $A \leq B \leq C$ of $[0,1]$ of equal size, we have
%
\begin{equation*}
    \iint_{A \times C} w(x,y)dxdy \leq \iint_{B \times C}w(x,y)dxdy \ \mbox{ and }\  \iint_{A \times C} w(x,y)dxdy \leq \iint_{A \times B}w(x,y)dxdy.
\end{equation*}
%
Applying the above inequalities to the sets $I_i$, we observe that $w_n$ is Robinson. Since $w_n\to w$ in the $L^1$ norm, using the Borel--Cantelli Lemma and going down to a  subsequence if necessary, we can assume that $\{w_n\}$ converges to $w$ pointwise a.e.~in $[0,1]^2$. So, there exists a null set $N \subset [0,1]^2$ such that  $w(x,y) = \lim_{n}w_n(x,y)$ for $(x,y) \in [0,1]^2\setminus N$. As $w$ is symmetric, we can assume that $N$ is symmetric with respect to the main diagonal. Next, we define the symmetric function $\widetilde{w}$ as follows:
%
\begin{equation*}
    \widetilde{w}(x,y) = \begin{cases}
    w(x,y) & (x,y) \in \Delta \setminus N\\
    \sup\left\{w(u,v):\ (u,v) \in \UL(x,y)\setminus N\right\} & (x,y) \in \Delta\cap N
    \end{cases}.
\end{equation*}
%
Clearly $w = \widetilde{w}$ a.e.; so, to finish the proof, we will show that $\widetilde{w}$ is Robinson. Take $(x_1,y_1)\in \Delta$ and $(x_2,y_2)\in\UL(x_1,y_1)$, and consider the following cases:\\
{\bf Case 1:} If $(x_1,y_1),(x_2,y_2)\in \Delta\setminus N$, then the graphon $\widetilde{w}$ satisfies the Robinson property for these points, since $\widetilde{w}$ on $\Delta\setminus N$ is just the pointwise limit of Robinson graphons.\\
{\bf Case 2:} If $(x_1,y_1),(x_2,y_2)\in \Delta\cap N$, then the Robinson property for $\widetilde{w}$ at these points can be easily verified, using the definition of $\widetilde{w}$ for points in $\Delta\cap N$.\\
{\bf Case 3:} Suppose $(x_1,y_1)\in \Delta\setminus N$ and  $(x_2,y_2)\in \Delta\cap N$. Using Case 1, for every $(u,v)\in \UL(x_2,y_2)\setminus N$, we have 
$w(u,v)\leq w(x_1,y_1)=\widetilde{w}(x_1,y_1);$
taking the supremum on the left-hand-side of this inequality, we get $\widetilde{w}(x_2,y_2)\leq \widetilde{w}(x_1,y_1)$.\\
{\bf Case 4:} Suppose $(x_1,y_1)\in \Delta\cap N$ and  $(x_2,y_2)\in \Delta\setminus N$. The Robinson property of $\widetilde{w}$ at these points follows directly from the definition of $\widetilde{w}(x_1,y_1)$. 
\end{proof} 
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Robinson approximation of $L^p$-graphons}\label{subse:region}
In this section, we introduce the $\alpha$-Robinson approximation of an \IN{$L^p$-graphon}, and present some of its important properties. 
%
\begin{definition}[$\alpha$-Robinson approximation for \IN{graphon}s]\label{def:R(w)} 
Let $p \geq 1$, and fix a parameter $0<\alpha<1$.
Given a \IN{graphon} $w\in {\mathcal W}^p$, the $\alpha$-\emph{\IN{Robinson approximation}} $R_w^{\alpha}$ of $w$ is the symmetric function defined as follows: for all $(x,y)\in \Delta$,
\begin{equation}
R_w^{\alpha}(x,y)=\sup\left\{ \overline{w}(S\times T)\,:\, S\times T\subseteq \UL(x,y),\, |S|=|T|=\alpha\right\},
\end{equation}
%
where $S,T$ are measurable, and taking the convention that $\sup\emptyset =0$. 
Moreover, we set $R_w^{\alpha}=w$ if $\alpha=0$ and $w$ is Robinson.
\end{definition}
%
Clearly, for every $w\in \W^p$, the  approximation  $R_w^{\alpha}$ is a Robinson \IN{graphon}. Also,  $R_w^{\alpha}$ attains 0 on every point with distance at most $\alpha$ to the boundary of the square $[0,1]^2$. We summarize some other useful properties of $R_w^{\alpha}$ below.
%
\begin{lemma}[Properties of the Robinson approximation]\label{lem:rw-properties}
Let $p \geq 1$, and fix a parameter $0<\alpha<1$.
Given \IN{graphon}s $w,u\in {\mathcal W}^p$  , we have:
\begin{enumerate}
    \item[(i)] If  $u \leq w$ pointwise, then $0 \leq R_w^{\alpha}-R_u^{\alpha} \leq R_{w-u}^{\alpha}.$
    
    \item[(ii)] $\|R_w^{\alpha}\|_{\infty} \leq \alpha^{-\frac{2}{p}}\|w\|_p$. \label{item:Rw-inftybound}

    \item[(iii)] If $\{w_n\} \subseteq \W^p$ such that $\|w_n -w\|_1\to 0$, then $\|R_w^{\alpha}-R_{w_n}^{\alpha}\|_{\Box} \to 0$ as $n \to \infty.$ 
\end{enumerate}
We note that for item $(iii)$, only convergence in the $L^1$ norm---the weakest $L^p$ norm---is required. Therefore, convergence in any $L^p$ norm is enough to guarantee the convergence of the $\alpha$-\IN{Robinson approximation}s in the \IN{cut norm}.
\end{lemma}

\begin{proof}
To prove (i), let $(x,y) \in \Delta$. By definition of the $\alpha$-\IN{Robinson approximation}, for every $\epsilon > 0$, there exist sets $A,B \subseteq \UL(x,y)$ such that $R_w^{\alpha}(x,y) \geq \overline{w}(A\times B) \geq R_w^{\alpha}(x,y)-\epsilon$ and $C,D \subseteq \UL(x,y)$ such that $R_u^{\alpha}(x,y)\geq\overline{u}(C\times D) \geq R_u^{\alpha}(x,y)-\epsilon$. We also note that $|A|=|B|=|C|=|D|=\alpha$. Since $u\leq w$, we have
%
\begin{equation*}
    0 \leq \frac{1}{\alpha^2}\iint_{C\times D} (w - u)dxdy
   =\frac{1}{\alpha^2}\iint_{C\times D} w~dxdy-\frac{1}{\alpha^2}\iint_{C\times D} u~dxdy
   \leq R_w^{\alpha}(x,y)-R_{u}^{\alpha}(x,y)+\epsilon
\end{equation*}
Letting $\epsilon \to 0$, we conclude that $0 \leq R_w^{\alpha}-R_u^{\alpha}$. Moreover, we note that
%
\begin{equation*}
   R_w^{\alpha}(x,y)-\epsilon-R_{u}^{\alpha}(x,y)  \leq \frac{1}{\alpha^2}\iint_{A\times B} w~dxdy - \frac{1}{\alpha^2}\iint_{A \times B} u~dxdy 
= \frac{1}{\alpha^2}\iint_{A\times B} (w - u)dxdy 
\leq R_{w-u}^{\alpha}(x,y),
\end{equation*}
%
showing that (i) holds true, again by letting $\epsilon \to 0$. 

To prove (ii), we note that for every $\epsilon > 0$, there exist sets $A,B \subseteq \UL(x,y)$ where $|A|=|B|=\alpha$ such that $R_w^{\alpha}(x,y) \geq \overline{w}(A\times B) \geq R_w^{\alpha}(x,y)-\epsilon$. Then, by H\"older's inequality,
%
\begin{equation*}
R_w^{\alpha}(x,y)-\epsilon \leq \frac{1}{\alpha^2}\iint_{A\times B} w~dxdy \leq \frac{1}{\alpha^2}\|w\|_p\|\mathbbm{1}_{A\times B}\|_q = \alpha^{-\frac{2}{p}}\|w\|_p,
\end{equation*}
%
where we used $\|\mathbbm{1}_{A\times B}\|_q=\alpha^{2/q}=\alpha^{2-2/p}.$ Again, letting $\epsilon \to 0$ finishes the proof of (ii).

To prove (iii), we define an auxiliary function $l_n(x,y) = \min\left(w_n(x,y),w(x,y)\right)$. Clearly $|l_n-w|\leq |w_n-w|$, so $\{l_n\}_{n\in \N}$ also converges to $w$ in $L^1$ norm. 
%
Now, we use part (i) to get that
%
\begin{equation*}
    \|R_{w_n}^{\alpha}-R_w^{\alpha}\|_{\Box} \leq \|R_{w_n}^{\alpha}-R_{l_n}^{\alpha}\|_{\Box}+\|R_{w}^{\alpha}-R_{l_n}^{\alpha}\|_{\Box} 
    \leq \|R_{w_n-l_n}^{\alpha}\|_{\Box}+\|R_{w-l_n}^{\alpha}\|_{\Box}
    \leq \|R_{w_n-l_n}^{\alpha}\|_{\infty}+\|R_{w-l_n}^{\alpha}\|_{\infty},
\end{equation*}
%
and then apply (ii) with $p=1$ to get
$$\|R_{w_n-l_n}^{\alpha}\|_{\infty}+\|R_{w-l_n}^{\alpha}\|_{\infty}\leq \alpha^{-2}\Big(\|w_n-l_n\|_1+\|w-l_n\|_1\Big)
    \leq \alpha^{-2}\Big(\|w_n-w\|_1+2\|w-l_n\|_1\Big) \to 0,$$
which completes the proof.
\end{proof}
%
It turns out that the Robinson approximation given in Definition~\ref{def:R(w)} is continuous almost everywhere;
namely, $R_w^{\alpha}$ is continuous on $[\alpha,1-\alpha]^2$ and is set to 0 otherwise. 

\begin{lemma}\label{lem:Rw-cts}
Let $w \in \W^p$, $1 \leq p \leq \infty$, and $\alpha \in (0,1)$. Then $R_w^{\alpha}$ is continuous on the set $[\alpha,1-\alpha]^2$. 
\end{lemma}

\begin{proof}
Let $(x,y) \in \Delta$ and let $\{(x_n,y_n)\}_{n \in \N} \subset [\alpha,1-\alpha]^2$ be a sequence such that $(x_n,y_n) \to (x,y) \in [\alpha,1-\alpha]^2$.
Then, by definition of $\UL$, it must be the case that
%
$\UL(\min(x_n,x),\max(y_n,y)) \subseteq \UL(x,y) \subseteq \UL(\max(x_n,x),\min(y_n,y)),$
%
which implies that
%
\begin{equation}\label{eq:rwbounds}
    R_w^{\alpha}(\min(x_n,x),\max(y_n,y)) \leq R_w^{\alpha}(x_n,y_n) \leq R_w^{\alpha}(\max(x_n,x),\min(y_n,y)).
\end{equation}
%
We shall show that both the upper and lower bound in \eqref{eq:rwbounds} converge to $R_w^{\alpha}(x,y)$; by the Squeeze Theorem, this will imply our original claim. 
To do so, note that as $w$ is a measurable function with $\|w\|_1<\infty$, for every $\epsilon > 0$, there exists a $\delta > 0$ such that $\iint_S |w|dxdy < \epsilon$
whenever $S \subset [\alpha,1-\alpha]^2$ and $|S| < \delta$

Let $N \in \N$ be such that for all $n \geq N$, we have that $d((x_n,y_n),(x,y)) < \frac{\delta}{2}$. Define the set $S :=  \UL(x,y) \setminus \UL(\min(x_n,x),\max(y_n,y))$ (the blue regions in Figure~\ref{fig:rwcts}). Since $|S|<\delta$, we have 
%
\begin{equation*}
    R_w^{\alpha}(x,y) \leq R_w^{\alpha}(\min(x_n,x),\max(y_n,y))+\iint_{S}|w|dxdy \leq R_w^{\alpha}(\min(x_n,x),\max(y_n,y))+\epsilon.
\end{equation*}
%
\begin{figure}\label{fig:rwcts}
    \centering
    \includegraphics[scale=0.4]{RwCtsAllCases.png}
    \caption{The blue area represents the symmetric difference between $\UL(x,y)$ and $\UL(\min(x_n,x),\max(y_n,y))$.}
\end{figure}
%
Since $R_w^{\alpha}(\min(x_n,x),\max(y_n,y)) \leq R_w^{\alpha}(x,y)$ holds as well, we get 
%
\begin{equation*}
    |R_w^{\alpha}(\min(x_n,x),\max(y_n,y))-R_w^{\alpha}(x,y)| < \epsilon.
\end{equation*}
%
This proves that $\lim_n R_w^{\alpha}(\min(x_n,x),\max(y_n,y)) = R_w^{\alpha}(x,y).$ An identical argument shows that the similar result $\lim_n R_w^{\alpha}(\max(x_n,x),\min(y_n,y)) = R_w^{\alpha}(x,y)$ holds. This finishes the proof. 
\end{proof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Stability of $L^p$ approximations}
In this section we present our main results on \IN{$\Lambda$}. Because \IN{$\Lambda$} functions as a measure of the Robinson property, it is desirable for a \IN{graphon} with a small \IN{$\Lambda$} value to be in some way \textit{close} to a Robinson \IN{graphon}. We think  of such a property as \textit{\IN{Robinson stability}}. 
%
Our proof that \IN{$\Lambda$} is Robinson stable uses techniques similar to those in \cite{ghandehari2020graph}. As a result, we need to introduce similar notation. Let $w \in \W^{\infty}$ be a \IN{graphon} with $w\geq 0 $ and $\lceil\|w\|_{\infty}\rceil=M$.
Fix a parameter $\alpha\in (0,1)$ (as in Definition~\ref{def:R(w)}), and let $m$ be a fixed integer. For $k\in \{1,\ldots,mM-1\}$, define the $k$-th black region $\B_k$, the $k$-th white region $\W_k$ and the $k$-th grey region $\G_k$ as follows. 
%
\begin{align*}
    \B_k&=\Big\{(x,y)\in \Delta:\ x=y\ \ \text{or} \ \  \exists \ S\times T\subseteq \UL(x,y) \  \text{with}\ |S|=|T|=\alpha \text{ and }   \overline{w}(S \times T)>\frac{k}{m}\Big\},\\
    \W_k&=\Big\{(x,y)\in \Delta \setminus {\B}_k:\ \exists \ S\times T\subseteq \LR(x,y)\  \text{with} \ |S|=|T|=\alpha \text{ and }  \overline{w}(S \times T)\leq \frac{k}{m}\Big\},\\
    \G_k&=\Delta\setminus (\B_k\cup\W_k).
\end{align*}
%
We set $\B_0=\W_{mM}=\Delta$ and $\W_0=\B_{mM}=\emptyset$ and let $\G=\bigcup_{k=1}^{mM-1} \G_k$.
In addition, we also define the following regions:
\begin{align*}
    &\mathcal{R}_k:=\B_k\cap \W_{k+1}.
\end{align*}  
Black regions provide lower bounds while white regions provide upper bounds on $\overline{w}$. Grey regions provide no information about what values $\overline{w}$ could take on while the regions $\mathcal{R}_k$ are used to form tight bounds on the behaviour of $\overline{w}$. Next, we observe that the $\mathcal{R}_k$ regions partition $\Delta\setminus \mathcal{G}$, skipping the proof of the following lemma as it is identical to the one in \cite[Lemma 4.8]{ghandehari2020graph}. 
%
\begin{figure}\label{fig:bnwregions}
    \centering
    \begin{minipage}{0.2\textwidth}
    \includegraphics[width=\textwidth]{BlackRegionsThesisPicture.png}
    \end{minipage}
    \begin{minipage}{0.2\textwidth}
    \includegraphics[width=\textwidth]{WhiteRegionsThesisPicture.png}
    \end{minipage}
     \caption{An example of black and white regions for $m=4$ and $\alpha =0.1$.}
\end{figure}
%
\begin{lemma}\label{lem:rk-parts-delt/g}
Let $w \in {\mathcal W}^\infty$ be such that $w \geq 0$ and $\lceil \|w\|_{\infty} \rceil = M$, and let $\mathcal{B}_k$, $\mathcal{W}_k$, and $\mathcal{G}_k$ be as defined above. Then, 
%
$$\Delta \setminus \left(\bigcup_{k=1}^{mM-1}\mathcal{G}_k\right) = \bigcup_{k=0}^{mM-1}\mathcal{R}_k.$$
%
\end{lemma}

%\begin{remark}\label{rem:upper-lower-boundary}
By definition, for every $k\in \{1,\ldots, mM-1\}$, the regions $\B_k$ and $\W_k$ have \emph{upper} and \emph{lower boundary} functions $f_k,g_k:[0,1]\rightarrow [0,1]$, where $f_k$ is the upper boundary of $\B_k$ and $g_k$ is the lower boundary of $\W_{k}$. These are defined in \cite{ghandehari2020graph} as follows: 
%
\begin{eqnarray*}
f_k(x) &=& \sup\{z \in [x,1]: (x,z) \in \mathcal{B}_k\}, \\
g_k(x) &=& \inf\{z \in [x,1]: (x,z) \in \mathcal{W}_k\};
\end{eqnarray*}
%
with the convention $\inf \emptyset = 1$. Additionally, we define $f_0(x) = 1$ and $g_{mM}(x) = x$ for all $x \in [0, 1]$ to represent the corresponding boundaries for $\mathcal{B}_0 = \mathcal{W}_{mM} = \Delta$. Finally, since $f_k$ and $g_{k+1}$ are the upper and lower boundaries of $\mathcal{B}_k$ and $\mathcal{W}_{k+1}$ respectively, if the region $\mathcal{R}_k$ is nonempty, then it is bounded from below by $g_{k+1}$ and from above by $f_k$. We refer to Figure \ref{fig:bnwregions} for a visual representation of the regions and \IN{boundary function}s previously mentioned.
%\end{remark}

From the definition of the black and white regions, it is easy to see that the functions $f_k$ and $g_k$ are both increasing functions. So, they can only admit jump discontinuities. We naturally extend the \IN{graph} of these functions to \textit{\IN{boundary curve}s} by adding vertical line segments connecting any such discontinuities, denoting the resulting curves once again by $f_k$ and $g_k$ respectively.

Let $S,T \subseteq [0,1]$ be measurable. We say that  $S \times T$ \textit{crosses} a \IN{boundary curve} $f_k$ or $g_k$ if the top-left corner of the cell is strictly above the \IN{boundary curve} and its bottom-right corner is strictly below the curve. This definition is used as the set $S \times T$ is not necessarily a connected subset of $\R^2$ and so a \IN{boundary curve} can go through the cell without having to intersect with it. See Figure \ref{fig:crossing} for an example of this phenomenon.
%
\begin{figure}[h]
    \centering
    \includegraphics[scale=0.2]{CrossingExplanationPicture.png}
    \caption{An example of a cell $S \times T$ that crosses a \IN{boundary curve} $f_2$ without intersecting it.}
    \label{fig:crossing}
\end{figure}

The proof of our main theorem is based on the idea that the total area of all the grey regions is small. This allows us to concentrate on the behaviour of $w$ and $R_w^{\alpha}$ inside the regions $\mathcal{R}_k$, where their values are strictly controlled. We show that their local average difference in these regions can be controlled by $\Lambda(w)$, leading to the conclusion that $\|w-R_w^{\alpha}\|_\Box$ must be small. 
We introduce three  lemmas here, each necessary for controlling the size of regions or integrals over certain sets in the proof of our main result. We will present the proofs of Lemma~\ref{lem:splitint} and Lemma~\ref{lem:gnrlpigeon} in Appendix \ref{section:proofs of lemmas}; the proof of Lemma~\ref{lem:grey-regions-small} is identical to \cite[Lemma 4.10]{ghandehari2020graph} and so we omit it.
%

\begin{lemma}\label{lem:grey-regions-small}
Let $k\in{\mathbb Z}^{\geq 0}$, $w \in \W^p$ with $w\geq 0$, and $\alpha \in (0,1)$. Then, $\overline{\G_k}$ does not contain any $\beta\times \beta$ square, where $\beta>\alpha$. Here, $\overline{\G_k}$ denotes the closure of $\G_k$ in the Euclidean topology of ${\mathbb R}^2$. 
\end{lemma}
%
\begin{lemma}\label{lem:splitint}
Let $u\in L^\infty[0,1]$ (not necessarily non-negative), and $P\subseteq [0,1]$ be a measurable subset such that $\int_P u\neq 0$. Let $0 < \beta < |P|$ be fixed. Then $P$ can be partitioned into $N:=\lceil |P|/\beta\rceil$ subsets $P_1,\ldots,P_{N}$ so that the following conditions are satisfied:

\begin{onehalfspacing}
\begin{itemize}
    \item[(i)] $P_1 \leq \ldots \leq P_{N-1}.$
    
    \item[(ii)] $|P_i|= \beta$ for $1\leq i\leq N-1$ and $|P_{N}|\leq \beta$.
    
    \item[(iii)] $\big|\int_{P_{N}} u\big|\leq \frac{1}{N}\big|\int_{P}u\big|$. 
\end{itemize}
\end{onehalfspacing}
%
\end{lemma}

%
\begin{lemma}\label{lem:gnrlpigeon}
Let $f \in L^1[0,1]^2$, and let $S,S' \subseteq [0,1]$ be measurable subsets such that $|S|=|S'|$. Suppose for a constant $C > 0$ we have
%
\begin{equation*}
    \iint_{S \times S'} f~dxdy\geq C.
\end{equation*}
%
Then, for every $\alpha \in (0,1)$, there exist measurable sets $T\subset S$ and $T'\subset S'$ such that $|T| = |T'|=\alpha|S|$ and
%
\begin{equation*}
    \frac{1}{|T\times T'|}\iint_{T \times T'}f~dxdy \geq \frac{C}{|S \times S'|}.
\end{equation*}
%
\end{lemma}
Prefacing our main result, we begin first with a necessary proposition---as our main proof heavily features ``cutting'' \IN{graphon}s off at certain values, we require a way to control their behaviour once cut. The following proposition, providing us with such a way, is the central part of our proof.

\begin{proposition}\label{prop:robinson-upprbnd}
Let $p>2$ and $w \in \W^{\infty}$ with $w\geq 0$. Suppose $\|w\|_p \leq 1$. If $R_w^{\alpha}$ is the \IN{Robinson approximation} of $w$ with parameter $\alpha=\|w\|_{\infty}^{-\frac{p}{3p-2}}\Lambda(w)^{\frac{2p}{5p-2}}$, then 
%
\begin{equation}\label{eq:approx-result}
\|w-R_w^{\alpha}\|_{\Box} \leq  \teddydone{4}\bigg(1+(8\|w-R_w^{\alpha}\|_p+2)\|w\|_{\infty}^{\frac{2p}{3p-2}}\bigg)\Lambda(w)^{\frac{p-2}{5p-2}}.
\end{equation}
%
\end{proposition}
%
The proof of this proposition bears similarities to the proof of \cite[Theorem 3.2]{ghandehari2020graph}. However, the graphons in that paper were restricted to values in $[0,1]$, making it easy to establish many claims and arguments. Unfortunately, even though the approximation result of \cite{ghandehari2020graph} could be used, it would not provide the upper bound needed for Proposition~\ref{prop:robinson-upprbnd} and would not suffice for the unbounded case. Therefore, we present a complete proof of the above proposition. As a corollary of this proposition, we improve upon the bound obtained in \cite{ghandehari2020graph}.
%
\begin{proof}
%Let $M:=\lceil\|w\|_\infty\rceil$. 
By \cite[Lemma 8.10]{lovaszbook}, there exist measurable $S,T\subseteq [0,1]$ so that
%
$$\Big|\iint_{S\times T} (w-R_w^{\alpha})dxdy\Big|= \| w-R_w^{\alpha}\|_{\Box}.$$
%
Replacing $S\times T$ with $T\times S$ if necessary, we can assume without loss of generality that 
%
\begin{equation}\label{eq;choice-D}
\bigg|\iint_{(S\times T)\cap \Delta} (w-R_w^{\alpha})dxdy\bigg| \, \geq\frac{1}{2}\| w-R_w^{\alpha}\|_{\Box}. 
\end{equation} 
%
Fix $\beta \in (\alpha, \teddydone{\frac{8}{7}}\alpha)$. Next, we split $S$ into $N_1:=\lceil |S|/\beta\rceil$ subsets $S_1, S_2,\ldots, S_{N_1}$, and $T$ into $N_2 := \lceil |T|/\beta\rceil$ subsets $T_1,\ldots,T_{N_2}$, so that the following conditions are satisfied:
\begin{multicols}{2}
\begin{itemize}
\item[(i)] $S_1 \leq \ldots \leq S_{N_1-1}$.

\item[(ii)] $|S_i|= \beta$ for $1\leq i\leq N_1-1$ and $|S_{N_1}|\leq \beta$.

\item[(iii)] $\Big|\iint_{S_{N_1}\times T} (w-R_w^{\alpha})dxdy\Big|\leq \frac{\| w-R_w^{\alpha}\|_{\Box}}{N_1}$. 

\item[(i)]$T_1 \leq \ldots \leq T_{N_2-1}.$

\item[(ii)] $|T_j|= \beta$ for $1\leq j\leq N_2-1$ and $|T_{N_2}|\leq \beta$.

\item[(iii)] $\Big|\iint_{S\times T_{N_2}} (w-R_w^{\alpha})dxdy\Big|\leq \frac{\| w-R_w^{\alpha}\|_{\Box}}{N_2}.$
\end{itemize}
\end{multicols}
To prove that a partition of $S$ satisfying the above three properties exists, we apply Lemma~\ref{lem:splitint} to the function $u(\cdot)=\int_{T} (w-R_w^{\alpha})(\cdot,y)dy$ and $P=S$; a similar proof shows that such a partition exists for $T$.

We will assume, without loss of generality, that $N_1,N_2\geq \teddydone{8}$, as the proposition holds true if $N_1\leq \teddydone{7}$ or $N_2\leq \teddydone{7}$ for the following reason. Assume that $N_1\leq \teddydone{7}$. Then, it must be the case that $|S|\leq \teddydone{7}\beta$, and so we get
\begin{equation*}
    \|w-R_w^{\alpha}\|_{\Box}=\left|\iint(w-R_w^{\alpha})\mathbbm{1}_{S\times T}\right|\leq \|w-R_w^{\alpha}\|_\infty (\teddydone{7}\beta)\leq \|w\|_\infty \left(\teddydone{8}\alpha\right)
    = \teddydone{8}\|w\|_{\infty}^{\frac{2p-2}{3p-2}}\Lambda(w)^{\frac{2p}{5p-2}}.
\end{equation*}
In the above inequalities, we used the fact that since $0\leq w,R_w^\alpha$ and $\|R_w^\alpha\|_\infty\leq \|w\|_\infty$, we have  $\|w-R_w^{\alpha}\|_\infty\leq\|w\|_\infty$.
To verify that the statement of the proposition holds true in this case, we need to show that 
%
\begin{align*}
\teddydone{8}\|w\|_{\infty}^{\frac{2p-2}{3p-2}}\Lambda(w)^{\frac{2p}{5p-2}}&\leq \teddydone{8}\|w\|_{\infty}^{\frac{2p}{3p-2}}\Lambda(w)^{\frac{p-2}{5p-2}},\\ 
\Lambda(w)^{\frac{p+2}{5p-2}}&\leq \|w\|_{\infty}^{\frac{2}{3p-2}}.
\end{align*}
%
However, since $\Lambda(w)\leq 1$ and $p>2$, we have $\Lambda(w)^{\frac{p+2}{5p-2}}\leq\Lambda(w)^{\frac{2}{3p-2}}$. This, together with the fact that $\Lambda(w)\leq \|w\|_\infty$, proves that Proposition \ref{prop:robinson-upprbnd} holds if $N_1 \leq \teddydone{7}$. An identical argument shows that the proposition also holds if $N_2 \leq \teddydone{7}$.

From this point forward, we make the following assumption:
\begin{assumption}\label{assump1}
 $N_1,N_2 \geq \teddydone{8}.$
\end{assumption}
%
Note that with repeated applications of the triangle inequality, we have
%
$$\sum_{\scriptsize{
\begin{array}{c}
1\leq i< N_1, \ 1\leq j< N_2\\
(S_i\times T_j)\cap \Delta\neq \emptyset\\
\end{array}}}\hspace{-2.12pt}
\Bigg|\iint_{S_i\times T_j} (w-R_w^{\alpha})\Bigg|\geq \Bigg|\iint_{(S\times T)\cap \Delta} (w-R_w^{\alpha})\Bigg|
-\Bigg|\iint_{(S_{N_1}\times T)\cup (S\times T_{N_2})} (w-R_w^{\alpha})\Bigg|,$$
%
which, together with Equation~\eqref{eq;choice-D}  and property (iii) of the partitions $\{S_i\}$ and $\{T_i\}$, implies that
%
\begin{equation*}
\sum_{\scriptsize{
\begin{array}{c}
1\leq i< N_1, \ 1\leq j< N_2\\
(S_i\times T_j)\cap \Delta\neq \emptyset\\
\end{array}}}\hspace{-2.12pt}
\Bigg|\iint_{S_i\times T_j} (w-R_w^{\alpha})\Bigg|\geq \Big(\frac{1}{2}-\frac{1}{N_1}-\frac{1}{N_2}\Big)\| w-R_w^{\alpha}\|_{\Box}.
\end{equation*}
%
The above inequality, combined with Assumption~\ref{assump1}, implies that
\begin{equation}\label{eq:int-over-sq-grid}
\sum_{\scriptsize{
\begin{array}{c}
1\leq i< N_1, \ 1\leq j< N_2\\
(S_i\times T_j)\cap \Delta\neq \emptyset\\
\end{array}}}\hspace{-2.12pt}
\Bigg|\iint_{S_i\times T_j} (w-R_w^{\alpha})\Bigg|\geq \teddydone{\frac{1}{4}}\| w-R_w^{\alpha}\|_{\Box}.
\end{equation}
%
\begin{claim}\label{claim:si0ti0ineq}
  There exists a cell $S_{i_0}\times T_{j_0}\subseteq \Delta$ contained in a region $\mathcal{R}_k=\B_k\cap \W_{k+1}$ so that $|S_{i_0}|=|T_{j_0}|=\alpha$, and
%
\begin{equation*}
\Big| \iint_{S_{i_0}\times T_{j_0}} (w-R_w^{\alpha})dxdy\Big| \geq  \alpha^2\left[\teddydone{\frac{1}{4}}\| w-R_w^{\alpha}\|_{\Box}
-2(2mM-1)\|w-R_w^{\alpha}\|_p\alpha^{1-\frac{2}{p}}\right].
\end{equation*}
%
\end{claim}
%
We use the pigeonhole principle to prove the claim. Indeed, by Lemma~\ref{lem:rk-parts-delt/g}, $\Delta=\bigcup_{k=0}^{mM-1}\mathcal{R}_k\, \cup  \, \bigcup_{k=1}^{mM-1} \G_k$, and that each of the regions $\G_k$ or $\mathcal{R}_k$ is bounded by \IN{boundary curve}s  in
$\{f_k, g_l: \ 1\leq k\leq mM-1, 1\leq l\leq mM\}$. Thus, if a  cell $S_i\times T_j$  does not cross the \IN{graph} of any of these \IN{boundary curve}s, then it must be entirely contained inside one closed region $\overline{\mathcal{R}_k}$ or $\overline{\G_k}$. 
%
Next, by Lemma~\ref{lem:grey-regions-small}, none of the grey regions $\overline{{\G_k}}$ can contain any of the cells ${S_i}\times {T_j}$ with $1\leq i<N_1$ and $1\leq j<N_2$, because $|S_i|=|T_j|=\beta$ for such $i$ and $j$. 
%Thus, these cells must either lie in a single region $\overline{\mathcal{R}_k}$ or cross a \IN{boundary curve}. 
Let $\I$ denote the collection of indices $(i,j)$ with $i<N_1$ and $j<N_2$, for  which the associated cells do not lie in a single region $\overline{\mathcal{R}_k}$. From the above discussion, we have
%
$$\I=\Big\{(i,j): 1\leq i<N_1, 1\leq j< N_2,~\mbox{and}~\exists\  1\leq k \leq mM-1~\mbox{s.t.}~(S_i\times  T_j)~\mbox{crosses}~f_k~\mbox{or}~g_{k}~\mbox{or } g_{mM}\Big\}.$$
%
Recall that the lower and upper boundaries $f_k,g_k$  are increasing curves.  As a result, each $f_k$ (similarly $g_k$) crosses at most $2/\beta$ cells from the grid. Thus, as there are $2mM-1$ total $f_k$ and $g_k$, we have 
%
$$|\I|\leq \frac{2(2mM-1)}{\beta}.$$
%
Since every cell indexed in $\I$ is of size $\beta^2$, using H\"{o}lder's inequality, we show 
%
\begin{equation}\label{eq:over-I}
\sum_{\scriptsize{
\begin{array}{c}
(i,j)\in \I \\
(S_i\times T_j)\cap \Delta\neq \emptyset\\
\end{array}}}
\left|\iint_{S_i\times T_j} (w-R_w^{\alpha})dxdy\right|\leq \frac{2(2mM-1)}{\beta} \|w-R_w^{\alpha}\|_p\beta^{2-\frac{2}{p}}. 
\end{equation}
%

Putting inequalities \eqref{eq:int-over-sq-grid} and \eqref{eq:over-I} together, we get
%
\begin{equation*}
\sum_{\scriptsize{
\begin{array}{c}
1\leq i< N_1, \ 1\leq j< N_2\\
(S_i\times T_j)\cap \Delta\neq \emptyset\\
(i,j)\not\in {\cal I}
\end{array}}}
\left|\iint_{S_i\times T_j} (w-R_w^{\alpha})dxdy\right|
\geq \teddydone{\frac{1}{4}}\| w-R_w^{\alpha}\|_{\Box}
- 2(2mM-1) \|w-R_w^{\alpha}\|_p\beta^{1-\frac{2}{p}}. 
\end{equation*}
%
 Since there are at most $(\lfloor \beta^{-1}\rfloor)^2$  cells  $S_i\times T_j$ of size $\beta\times \beta$ and $\beta^2 \leq (\lfloor \beta^{-1}\rfloor)^{-2}$, there must exist a cell $S_{i_0}\times T_{j_0}\subseteq \Delta$ so that $|S_{i_0}|=|T_{j_0}|=\beta$, $(i_0,j_0)\not\in \I$ and
%
\begin{equation*}
\Big| \iint_{S_{i_0}\times T_{j_0}} (w-R_w^{\alpha})dxdy\Big| \geq  \beta^2\left[\teddydone{\frac{1}{4}}\| w-R_w^{\alpha}\|_{\Box}
- 2(2mM-1) \|w-R_w^{\alpha}\|_p\beta^{1-\frac{2}{p}}\right].
\end{equation*}
%
So $S_{i_0}\times T_{j_0}$ lies entirely in $\overline{\mathcal{R}_k}=\overline{\B_k\cap \W_{k+1}}$ for some $0\leq k\leq mM-1$. By Lemma \ref{lem:gnrlpigeon}, we can reduce $\beta$ to $\alpha$; this lets us assume that $S_{i_0}\times T_{j_0}$ is an $\alpha \times \alpha$ cell contained in $\mathcal{R}_k=\B_k\cap \W_{k+1}$ satisfying
%
\begin{equation*}
\Big| \iint_{S_{i_0}\times T_{j_0}} (w-R_w^{\alpha})dxdy\Big| \geq  \alpha^2\left[\teddydone{\frac{1}{4}}\| w-R_w^{\alpha}\|_{\Box}-
{2(2mM-1)}\|w-R_w^{\alpha}\|_p\beta^{1-\frac{2}{p}}\right].
\end{equation*}
%
As this inequality holds for all $\beta > \alpha$, we take the limit as $\beta \to \alpha$. So, we have proved the claim.

From the definition of $R_w^{\alpha}$ and the black and white regions, we observe that if $1\leq k\leq Mm-1$, then we have $\frac{k}{m}< R_w^{\alpha}\leq\frac{k+1}{m}$ on $S_{i_0}\times T_{j_0}$; if $k=0$, then $0\leq R_w^{\alpha}\leq\frac{1}{m}$ on $S_{i_0}\times T_{j_0}$.

\begin{claim}\label{claim-3case}
Under the assumptions made so far, 
\begin{equation*}%\label{eq-3case}
\| w-R_w^{\alpha}\|_{\Box}\leq \teddydone{4}\left(\frac{2\Lambda(w)}{\alpha^2}+ \frac{1}{m}+{2(2mM-1)} \|w-R_w^{\alpha}\|_p\alpha^{1-\frac{2}{p}}\right).
\end{equation*}
\end{claim}
%
\noindent To prove the claim, we consider three cases:

{\bf Case 1:} 
Assume that $\iint_{S_{i_0}\times T_{j_0}} (w-R_w^{\alpha})dxdy>0$ and $0\leq k\leq mM-2$. In this case, using Claim~\ref{claim:si0ti0ineq}, and the fact that $|S_{i_0}\times T_{j_0}|=\alpha^2$, we have
\begin{equation}\label{eqn:avg}
\overline{w}(S_{i_0}\times T_{j_0})-\frac{k}{m}\geq \overline{w-R_w^{\alpha}}(S_{i_0}\times T_{j_0})
\geq
\teddydone{\frac{1}{4}}\| w-R_w^{\alpha}\|_{\Box}- 2(2mM-1) \|w-R_w^{\alpha}\|_p\alpha^{1-\frac{2}{p}}.
\end{equation}


Now let $(x,y)$ be the lower right corner of $S_{i_0}\times T_{j_0}$.  Then $(x,y)\in \W_{k+1}$, implying $\LR (x,y)$ contains a region $S_l\times T_l$ so that $|S_l|=|T_l|=\alpha$, and $\overline{w}(S_l \times T_l)\leq  \frac{k+1}{m}$. So  inequality \eqref{eqn:avg} combined with the definition of $\Lambda$ implies that 
%
\begin{eqnarray*}
    \Lambda(w)&\geq& \frac{\alpha^2}{2}\left[\overline{w}(S_{i_0}\times T_{i_0})-\overline{w}(S_{i_0}\times T_l)+\overline{w}(S_{i_0}\times T_l)-\overline{w}(S_l\times T_l)\right]\\
&\geq& \frac{\alpha^2}{2}\bigg(\teddydone{\frac{1}{4}}\| w-R_w^{\alpha}\|_{\Box}- 2(2mM-1) \|w-R_w^{\alpha}\|_p\alpha^{1-\frac{2}{p}}+ \frac{k}{m}-\frac{k+1}{m}\bigg),
\end{eqnarray*}
%
which can be simplified as 
%
\begin{eqnarray*}
\teddydone{\frac{1}{4}}\| w-R_w^{\alpha}\|_{\Box} 
\leq \frac{2\Lambda(w)}{\alpha^2}+\frac{1}{m}+2(2mM-1)\|w-R_w^{\alpha}\|_p\alpha^{1-\frac{2}{p}}.
 \end{eqnarray*}
%

{\bf Case 2:} For the second case, assume $\iint_{S_{i_0}\times T_{j_0}}(w-R_w^{\alpha})dxdy\geq 0$ and $1\leq k\leq mM-1$. By a similar argument used to show \eqref{eqn:avg},
\begin{equation*}
\frac{k+1}{m}-\overline{w}(S_{i_0}\times T_{j_0})\geq \teddydone{\frac{1}{4}}\| w-R_w^{\alpha}\|_{\Box}- 2(2mM-1) \|w-R_w^{\alpha}\|_p\alpha^{1-\frac{2}{p}}.
\end{equation*}
%
Now let $(x,y)$ be the upper left corner of $S_{i_0}\times T_{j_0}$. Then $(x,y)\in \B_{k}$, which means $\UL (x,y)$ contains a region $S_u\times T_u$ such that $|S_u|=|T_u|=\alpha$ and $\overline{w}(S_u \times T_u)> \frac{k}{m}$. Using the definition of \IN{$\Lambda$}, similar to the argument in Case 1, we get
%
\begin{eqnarray*}
\Lambda(w)&\geq& \frac{\alpha^2}{2}\left(\frac{k}{m}+ \teddydone{\frac{1}{4}}\| w-R_w^{\alpha}\|_{\Box}- 2(2mM-1) \|w-R_w^{\alpha}\|_p\alpha^{1-\frac{2}{p}} - \frac{k+1}{m}\right),
\end{eqnarray*}
%
which simplifies to 
%
\begin{eqnarray*}
 \teddydone{\frac{1}{4}}\| w-R_w^{\alpha}\|_{\Box}\leq \frac{2\Lambda(w)}{\alpha^2}+ \frac{1}{m}+{2(2mM-1)} \|w-R_w^{\alpha}\|_p\alpha^{1-\frac{2}{p}}.
\end{eqnarray*}
%

\textbf{Case 3:}
Assume that either $\iint_{S_{i_0}\times T_{j_0}} (w-R_w^{\alpha})dxdy>0$ and $k= mM-1$ \textit{or} that $\iint_{S_{i_0}\times T_{j_0}} (w-R_w^{\alpha})dxdy\geq 0$ and $k=0$. We note that $\mathcal{R}_{mM-1} = \mathcal{B}_{mM-1}\cap \W_{mM} = \mathcal{B}_{mM-1}$ and that $\mathcal{R}_0 = \mathcal{B}_0\cap\W_1 = \W_1$. In the first assumption, we have that $R_w^{\alpha} > M-\frac{1}{m}$ on $S_{i_0}\times T_{j_0}$ whereas $w \leq M$ by definition. Thus, $\frac{\alpha^2}{m}\geq\iint_{S_{i_0}\times T_{j_0}} (w-R_w^{\alpha})dxdy>0$. In the second assumption, we have that $R_w^{\alpha} \leq \frac{1}{m}$ on $S_{i_0}\times T_{j_0}$ and by positivity of the integral in the second assumption it must be that $\frac{\alpha^2}{m} \geq \iint_{S_{i_0}\times T_{j_0}} w-R_w^{\alpha}\geq0$. Combining either of these results with Claim~\ref{claim:si0ti0ineq} gives us that
%
$$
\frac{\alpha^2}{m} \geq \alpha^2\left[\teddydone{\frac{1}{4}}\| w-R_w^{\alpha}\|_{\Box}- 2(2mM-1)\|w-R_w^{\alpha}\|_p\alpha^{1-\frac{2}{p}}\right],
$$
%
which can be rearranged to show
%
$$
\teddydone{\frac{1}{4}}\| w-R_w^{\alpha}\|_{\Box}\leq \frac{1}{m}+{2(2mM-1)} \|w-R_w^{\alpha}\|_p\alpha^{1-\frac{2}{p}}.
$$
%
So the claimed inequality holds in all cases. 

We can now finish the proof.  Taking $\alpha=\|w\|_{\infty}^{-\frac{p}{3p-2}}\Lambda(w)^{\frac{2p}{5p-2}}$ and $m=\lceil\Lambda(w)^{-\frac{p-2}{5p-2}}\rceil$ in Claim~\ref{claim-3case}, we get 
%
\begin{equation*}
\teddydone{\frac{1}{4}}\| w-R_w^{\alpha}\|_{\Box} \leq  \bigg(1+(4\|w-R_w^{\alpha}\|_p+2)\|w\|_{\infty}^{\frac{2p}{3p-2}}\bigg)\Lambda(w)^{\frac{p-2}{5p-2}}+\bigg(4\|w-R_w^{\alpha}\|_p\|w\|_{\infty}^{\frac{2p}{3p-2}}\bigg)\Lambda(w)^{\frac{2p-4}{5p-2}}.
 \end{equation*}
%
Since $\Lambda(w)\leq 1$, we  get $\Lambda(w)^{\frac{2p-4}{5p-2}}\leq \Lambda(w)^{\frac{p-2}{5p-2}}$; this simplifies the above equation to the desired result.
\end{proof}
%
As a corollary to Proposition \ref{prop:robinson-upprbnd}, we obtain an improvement for the earlier results on Robinson approximation of traditional \IN{graphon}s and \IN{kernel}s. 
%
\begin{corollary}\label{cor:bnddstability}
Let $w:[0,1]^2\to [0,1]$ be a \IN{graphon}. Then $$\| w-R_w^{\alpha}\|_{\Box} \leq \teddydone{44}\Lambda(w)^{\frac{1}{5}},$$
where $\alpha= \|w\|_{\infty}^{-\frac{1}{3}}\Lambda(w)^{\frac{2}{5}}.$ For a bounded kernel $u:[0,1]^2\to\R$ we have 
$$\| u-R_u^{\alpha^*}\|_{\Box} \leq  \teddydone{44}\|u\|_\infty^{\frac{4}{5}}\Lambda(u)^{\frac{1}{5}},$$
where $\alpha^* = \|u\|_{\infty}^{-\frac{2}{5}}\Lambda(u)^{\frac{2}{5}}.$ 
\end{corollary}
%
\begin{proof}
Let $\alpha_p = \|w\|_{\infty}^{-\frac{p}{3p-2}}\Lambda(w)^{\frac{2p}{5p-2}}$. Then, from \eqref{eq:approx-result}, we have  $\| R_w^{\alpha_p}-w\|_{\Box} \leq  \teddydone{44}\Lambda(w)^{\frac{p-2}{5p-2}},$ since $\|w\|_\infty\leq 1$ and $\|w-R_w^{\alpha_p}\|_p\leq 1$. 
Recall that the approximation in Proposition~\ref{prop:robinson-upprbnd} is dependent upon the parameter $\alpha$ (dependent on $p$) chosen for the Robinson approximation. However, as $L^\infty[0,1]^2\subseteq L^p[0,1]^2$ for every $p>1$, we can allow $p\rightarrow \infty$, showing
$\| w-R_w^{\alpha}\|_{\Box} \leq  \teddydone{44}\Lambda(w)^{\frac{1}{5}},$ where $\alpha = \|w\|_{\infty}^{-\frac{1}{3}}\Lambda(w)^{\frac{2}{5}}$ as desired.

For a \IN{kernel} $u:[0,1]^2\to[0,\|u\|_{\infty}]$, we scale by the infinity norm to make a new function $u^* := u/\|u\|_{\infty}$ to get that %
%
\begin{equation}\label{eq:scaledstable}
    \|u^*-R_{u^*}^{\alpha^*}\|_{\Box} \leq \teddydone{44}\Lambda(u^*)^{\frac{1}{5}},
\end{equation}
%
where $\alpha^* = \|u\|_{\infty}^{-\frac{2}{5}}\Lambda(u)^{\frac{2}{5}}$. We note that by definition of \IN{$\Lambda$} and positivity of $\|u\|_{\infty}$, it must be the case that $\Lambda(u^*)^{\frac{1}{5}}= \|u\|_{\infty}^{-\frac{1}{5}}\Lambda(u)^{\frac{1}{5}}.$ Furthermore, by definition of $R_u^{\alpha},$ we have
%
$$
R_{u^*}^{\alpha^*} = \|u\|_{\infty}^{-1}R_u^{\alpha^*}. 
$$
%
Thus, combining these two observations with \eqref{eq:scaledstable} yields
%
$\frac{1}{\|u\|_{\infty}}\|u-R_u^{\alpha^*}\|_{\Box}\leq \teddydone{44}\|u\|_{\infty}^{-\frac{1}{5}}\Lambda(u)^{\frac{1}{5}},$
which proves the claim.
\end{proof}
%
We are now ready to state and prove our main result about stability of \IN{$\Lambda$}. We begin with a necessary definition---a key technique in this proof is taking an unbounded \IN{graphon} and ``cutting it off'' at a certain threshold.
%
\begin{notation}[\IN{$M$-cut-off}]\label{def:mcutoff}
Let $w \in \mathcal{W}^1$ and define
%
\begin{equation*}
E_M=\{(x,y)\in [0,1]^2: w(x,y)>M\}.
\end{equation*}
%
The $M$-\emph{cut-off} of $w$, denoted by $w_M$, is defined to be $w_M:=(\mathbbm{1}-\mathbbm{1}_M)w$, where $\mathbbm{1}_M$ is the characteristic function of $E_M$ and $\mathbbm{1}$ is the characteristic function of $[0,1]^2$. 
%An $L^p$-\IN{kernel} $w:[0,1]^2\to [0,\infty)$ is called \emph{Robinson stable} if for every $M>0$, we have 
%$$\|R_w^{\alpha}-R_{w_M}\|_\Box\leq \|w-w_M\|_1.$$
\end{notation}
%
\begin{theorem}\label{thm:main-result}
Suppose $w:[0,1]^2\to [0,\infty)$ is an $L^p$-\IN{kernel} with $p > 5$ and $\|w\|_p\teddydone{\leq}1$. Then there exists some $\alpha \in [0,\frac{1}{2})$ such that $R_w^{\alpha}$, the \IN{Robinson approximation} of $w$ with parameter $\alpha$, satisfies 
$$\| w-R_w^{\alpha}\|_{\Box} \leq \teddydone{78}\Lambda(w)^{\frac{p-5}{5p-5}}.$$
\end{theorem}
%
The idea of the proof is as follows: We use an $\epsilon/3$ argument on the difference in \IN{cut norm} between $w$ and its \IN{Robinson approximation} $R_w^{\alpha}$, introducing the terms $w_M$ and $R_{w_M}^{\alpha}$, bounding each term above in terms of \IN{$\Lambda$}. If $w_M$ is Robinson, then the upper bound is proved only using properties of Robinson functions without use of Corollary \ref{cor:bnddstability}. If $w_M$ is not Robinson, then its difference in \IN{cut norm} with $R_{w_M}^{\alpha}$ must be handled using Corollary \ref{cor:bnddstability}. Handling these two cases finishes the proof.

\begin{proof}
By definition of \IN{Robinson approximation}, if $\Lambda(w) = 0$, then we set $\alpha=0$, resulting in $R_w^{\alpha}=w$. Thus, we assume that $\Lambda(w) > 0$ and define our cut-off value $M = 2\Lambda(w)^{-\frac{1}{p-1}}$. The proof then breaks into two cases.

\textbf{Case 1:} Suppose that $\Lambda(w_M) >0$. We begin by defining the Robinson parameter $\alpha=\|w_M\|_{\infty}^{-\frac{2}{5}}\Lambda(w_M)^{\frac{2}{5}}$, where $w_M$ is as defined in Definition \ref{def:mcutoff}. The triangle inequality can then be used to show that 
%
\begin{equation*}
\|w-R_w^{\alpha}\|_{\Box} \leq \|w-w_M\|_{\Box}+\|w_M-R_{w_M}^{\alpha}\|_{\Box}+\|R_w^{\alpha}-R_{w_M}^{\alpha}\|_{\Box}.
\end{equation*}
%
We will proceed by dealing with each of these terms one by one, starting with $\|w-w_M\|_{\Box}$. 
By definition, $\mathbbm{1}_M$ is the characteristic function of $E_M$, the region of $[0,1]^2$ where $w > M$. Since $M|E_M|^{\frac{1}{p}}\leq \|w\mathbbm{1}_M\|_p\leq \|w\|_p\leq 1$, we get that $|E_M|\leq (\frac{1}{M})^p$. Therefore, choosing $q$ satisfying  $1/p+1/q=1$, we get that
%
\begin{equation}\label{eq:qnormM}
\|\mathbbm{1}_M\|_q=|E_M|^{1/q}\leq\left(\frac{1}{M}\right)^{\frac{p}{q}}=M^{1-p}= 2^{1-p}\Lambda(w).
\end{equation}
%
It is also true that 
%
\begin{equation}\label{eq:w-wm-ineq}
    \|w-w_M\|_{\Box}\leq\|w-w_M\|_1 =\|w\mathbbm{1}_M\|_1\leq \|w\|_p\|\mathbbm{1}_M\|_q \leq 2^{1-p}\Lambda(w)
    \leq 2^{1-p}\Lambda(w)^{\frac{p-5}{5p-5}},
\end{equation}
%
handling the first term. We can further say that $\|w-w_M\|_{\Box}\leq\frac{1}{16}\Lambda(w)^{\frac{p-5}{5p-5}}$ for all $p > 5$. Now we shift focus to $\|w_M-R_{w_M}^{\alpha}\|_{\Box}$. By Corollary \ref{cor:bnddstability}, as $w_M$ is bounded, we have the following.
%
$$\|w_M-R_{w_M}^{\alpha}\|_{\Box} \leq  \teddydone{44}\|w_M\|_{\infty}^{\frac{4}{5}}\Lambda(w_M)^{\frac{1}{5}}
    \leq \teddydone{44}M^{\frac{4}{5}}(\Lambda(w)+2^{1-p}\Lambda(w))^{\frac{1}{5}},$$
%
where the second inequality is due to the combination of \eqref{eq:Lambda-prop}
for  $w_M=w-w\mathbbm{1}_M$ alongside the fact that  $\Lambda(-w\mathbbm{1}_M)\leq \|w\mathbbm{1}_M\|_1\leq 2^{1-p}\Lambda(w)$ by \eqref{eq:qnormM}. 
%
This simplifies to 
%
\begin{align}\label{eq:rwm-wm-ineq}
    \|w_M-R_{w_M}^{\alpha}\|_{\Box}\leq \teddydone{44} (1+2^{1-p})^{\frac{1}{5}}M^{\frac{4}{5}}\Lambda(w)^{\frac{1}{5}} 
    \leq \teddydone{44} (1+2^{1-p})^{\frac{1}{5}}\ 2^{\frac{4}{5}}\Lambda(w)^{\frac{p-5}{5p-5}}\leq \teddydone{77.6}\Lambda(w)^{\frac{p-5}{5p-5}},
\end{align}
%
where we used the fact that $p > 5$.

To bound the third term, we use Lemma~\ref{lem:rw-properties} (i) and Proposition~\ref{prop:Lambda-prop} (i) to get the following:
%
\begin{equation*}
\|R_w^{\alpha}-R_{w_M}^{\alpha}\|_{\Box}\leq \|R_w^{\alpha}-R_{w_M}^{\alpha}\|_{\infty}\leq \|R_{w-w_M}^{\alpha}\|_\infty\leq \alpha^{-2}\|w-w_M\|_1=\alpha^{-2}\|w\mathbbm{1}_M\|_1\leq \alpha^{-2}\|w\|_p\|\mathbbm{1}_M\|_q,
\end{equation*}
% 
where, in the last inequality, we used H\"{o}lder's inequality with conjugate indices $p,q$.
Now, using the upper bound for $\|\mathbbm{1}_M\|_q$ provided by \eqref{eq:qnormM}, and substituting the value of $\alpha$, we get
%
\begin{equation}\label{eq:mid-way}
    \|R_w^{\alpha}-R_{w_M}^{\alpha}\|_{\Box}\leq 2^{1-p}\alpha^{-2}\Lambda(w)=2^{1-p}\Lambda(w)\left(\|w_M\|_{\infty}^{-\frac{2}{5}}\Lambda(w_M)^{\frac{2}{5}}\right)^{-2}.
\end{equation}
%
Next, applying \eqref{eq:Lambda-prop} to $w=w_M+w\mathbbm{1}_M$, we get
\begin{equation*}
\Lambda(w_M) \geq \Lambda(w)-\Lambda(w\mathbbm{1}_M) \geq \Lambda(w)-\|w\mathbbm{1}_M\|_1 \geq \Lambda(w)-\|w\|_p\|\mathbbm{1}_M\|_q \geq (1-2^{1-p})\Lambda(w).
\end{equation*}
%
Since $p>5$, the above inequality implies that $\Lambda(w_M) \geq \frac{15}{16}\Lambda(w)$.
This lower bound, together with $\|w_M\|_{\infty}\leq M=2\Lambda(w)^{\frac{-1}{p-1}}$ and inequality \eqref{eq:mid-way}, implies that 
%
\begin{align*}
 2^{p-1}\|R_w^{\alpha}-R_{w_M}^{\alpha}\|_{\Box}&\leq \Lambda(w)\|w_M\|_{\infty}^{\frac{4}{5}}\Lambda(w_M)^{-\frac{4}{5}}
\leq \Lambda(w)M^{\frac{4}{5}}(1-2^{1-p})^{-\frac{4}{5}}\Lambda(w)^{-\frac{4}{5}}
\leq \frac{2^{\frac{4}{5}}}{(1-2^{1-p})^{\frac{4}{5}}}\Lambda(w)^{\frac{p-5}{5p-5}}.
\end{align*}
%
When $p > 5$, we have $2^{\frac{4}{5}}2^{1-p}(1-2^{1-p})^{-\frac{4}{5}} \leq 0.2$, so 
%
\begin{equation}\label{eq:rw-rw-ineq}
    \|R_w^{\alpha}-R_{w_M}^{\alpha}\|_{\Box} \leq 0.2\Lambda(w)^{\frac{p-5}{5p-5}}.
\end{equation}
%
Thus \eqref{eq:w-wm-ineq}, \eqref{eq:rwm-wm-ineq}, and \eqref{eq:rw-rw-ineq} together will give us that $\|w-R_w^{\alpha}\|_{\Box} \leq \teddydone{78}\Lambda(w)^{\frac{p-5}{5p-5}},$ proving the statement of the theorem in this case.

\textbf{Case 2:} Suppose that $\Lambda(w_M) = 0$. In this case, we define the Robinson parameter to be $\alpha = M^{-\frac{2}{5}}\Lambda(w)^{\frac{2}{5}}.$ We proceed similarly to Case 1, bounding each of the three summands in the right hand side of the following inequality:
%
\begin{equation*}
\|w-R_w^{\alpha}\|_{\Box} \leq \|w-w_M\|_{\Box}+\|w_M-R_{w_M}^{\alpha}\|_{\Box}+\|R_w^{\alpha}-R_{w_M}^{\alpha}\|_{\Box}.
\end{equation*}
%
The first term on the right side of the inequality can be handled identically to Case 1, yielding $\|w-w_M\|_{\Box}\leq\frac{1}{16}\Lambda(w)^{\frac{p-5}{5p-5}}$. For the third term, we can proceed identically to Case 1 up to \eqref{eq:mid-way} to get
%
$$\|R_w^{\alpha}-R_{w_M}^{\alpha}\|_{\Box}\leq 2^{1-p}\alpha^{-2}\Lambda(w).$$
% 
Substituting $\alpha=M^{-\frac{2}{5}}\Lambda(w)^{\frac{2}{5}}$ and noting that $p>5$, we get $\|R_w^{\alpha}-R_{w_M}^{\alpha}\|_{\Box}\leq 0.2 \Lambda(w)^{\frac{p-5}{5p-5}}$.

However, the second term $\|w_M-R_{w_M}^{\alpha}\|_{\Box}$ must be handled differently. We observe that as $\Lambda(w_M) = 0$, it must be that $w_M$ is Robinson a.e.; we therefore can directly approximate $R_{w_M}^{\alpha}$ as in the following claim. 

\begin{claim}\label{claim-case2-approx}
When $w_M:[0,1]^2\to [0,M]$ is Robinson a.e., we have $$\|w_M-R_{w_M}^{\alpha}\|_\Box \leq \iint_{\{|x-y|\leq2\alpha\}}w_M(x,y)dxdy.$$
\end{claim}
\noindent To prove the claim, first note that for any point $(x,y) \in \Delta$, we have that $w_M(x,y)$ is an upper bound for every value of $w_M$ over the set $\UL(x,y)$; thus, any average over that set (such as in the definition of $R_w^{\alpha}$) would not exceed $w_M(x,y)$. 
So $R_{w_M}^{\alpha} \leq w_M$.
%
On the other hand, note that as $w_M$ is Robinson a.e., we have
%
\begin{equation}\label{eq:rwm}
R_{w_M}^{\alpha}(x,y) =\begin{cases} \dfrac{1}{\alpha^2}\displaystyle\iint_{[x-\alpha,x]\times[y,y+\alpha]}w_Mdxdy & \text{ for } (x,y) \in [\alpha,1-\alpha]^2\cap \Delta\\  0 & \text{ otherwise }\end{cases},
\end{equation}
%
where we also define $R_{w_M}^{\alpha}(x,y) = R_{w_M}^{\alpha}(y,x)$. We now introduce an auxiliary function $\widetilde{w}_M$ defined as follows:
\begin{equation*}
    \widetilde{w}_M(x,y) = \widetilde{w}_M(y,x) = \begin{cases} w_M(x-\alpha,y+\alpha) & (x,y) \in [\alpha,1-\alpha]^2 \cap \Delta \\ 0 & \text{ otherwise }\end{cases}.
\end{equation*}
%
It is clear from the definition of both $\widetilde{w}_M$ and \eqref{eq:rwm} that $R_{w_M}^{\alpha} \geq \widetilde{w}_M$. Thus we have $0\leq w_M - R_{w_M}^{\alpha} \leq w_M - \widetilde{w}_M$ pointwise, allowing us to show the following:
%
\begin{align*}
    \|w_M - R_{w_M}^{\alpha}\|_{\Box} &\leq  \|w_M - \widetilde{w}_M\|_{\Box} = 2\iint_{[0,1]^2\cap \Delta}(w_M-\widetilde{w}_M)dxdy \\
    &= 2\left(\iint_{[0,1]^2\cap \Delta}w_Mdxdy - \iint_{[\alpha,1-\alpha]^2\cap\Delta}\widetilde{w}_Mdxdy\right) \\
    &= 2\left(\iint_{[0,1]^2\cap \Delta}w_Mdxdy - \iint_{0\leq x\leq y-2\alpha\leq 1-2\alpha}w_M (x,y)dxdy\right)\\
    &\leq \iint_{\{|x-y|\leq2\alpha\}}w_M(x,y)dxdy.
\end{align*}
This proves Claim~\ref{claim-case2-approx}. 
%
Finally, note that
\begin{equation*}
\iint_{\{|x-y|\leq 2\alpha\}}w_M(x,y)dxdy \leq \|w_M\|_p\|\mathbbm{1}_{[0,1]^2\cap \{|x-y|\leq2\alpha\}}\|_q \leq 
(1-(1-2\alpha)^2)^{\frac{1}{q}} \leq (4\alpha)^{1-\frac{1}{p}},
\end{equation*}
%
where in the last inequality we used that $0\leq \alpha\leq 1$. Substituting for $\alpha$ and noting that $p>5$, we have 
%
$$\|w_M - R_{w_M}^{\alpha}\|_{\Box} \leq 4^{1-\frac{1}{p}}\Big(\frac{\Lambda(w)}{M}\Big)^{(\frac{2}{5})(1-\frac{1}{p})}
=2^{1-\frac{1}{p}}\Big(\frac{\Lambda(w)}{M}\Big)^{(\frac{2}{5})(1-\frac{1}{p})}\leq 2{\Lambda(w)}^{\frac{2}{5}}.$$
%
Since $\Lambda(w)\leq 1$ and  $\frac{2}{5} \geq (p-5)(5p-5)^{-1}$ for all $p>5$, we get 
%
$\|w_M - R_{w_M}^{\alpha}\|_{\Box} \leq  2{\Lambda(w)}^{\frac{2}{5}}\leq 2\Lambda(w)^{\frac{p-5}{5p-5}}.$
Therefore, if $\Lambda(w_M)=0$, we have that $\|w-R_w^{\alpha}\|_{\Box} \leq 3\Lambda(w)^{\frac{p-5}{5p-5}}$, proving the theorem in Case 2. Thus the theorem holds true.
\end{proof}
%
\begin{remark}\label{rem:lambdalwrbnd}
We draw attention to a particular property of \IN{$\Lambda$}:  Let $S_u \leq S_l \leq T_l \leq T_u$ be subsets of $[0,1]$ such that $|S_u| = |S_l| = |T_l| = |T_u| = \alpha.$ Then
    %
    \begin{equation*}
    \Lambda(w) \geq \frac{\alpha^2}{2}(\overline{w}(S_u \times T_u)-\overline{w}(S_l\times T_l)).
    \end{equation*}
    %
To prove this, let $A = S_u$, $B=S_l$, $C=T_u$, $X=S_l$, $Y=T_l$, and $Z=T_u$. Then by definition, 
%
\begin{align*}
    \Lambda(w) &\geq \frac{1}{2}\bigg(\iint_{S_u\times T_u}w~dxdy-\iint_{S_l\times T_u}w~dxdy+\iint_{S_l\times T_u}w~dxdy -\iint_{S_l\times T_l}w~dxdy\bigg) \\
    &=\frac{\alpha^2}{2}(\overline{w}(S_u\times T_u)-\overline{w}(S_l \times T_l)),
\end{align*}
%
proving the claim. This, alongside the fact that \IN{$\Lambda$} is continuous with respect to the \IN{cut norm} and recognizes Robinson \IN{graphon}s, classifies it as a ``\IN{$\Gamma$}-type function'' as defined in \cite{ghandehari2020graph}. These were shown to have stable \IN{Robinson approximation}s for \IN{graphon}s taking values in $[0,1]$, and to recognize when limits of convergent \IN{graph} sequences are Robinson. While stability results for \IN{$\Lambda$} already exist for bounded \IN{graphon}s, we prove here much better estimates than those given in \cite{ghandehari2020graph} due to the improved definition of \IN{$\Lambda$} and our careful estimates.
\end{remark}

%
\section*{Acknowledgements}
We thank Jeannette Janssen for helpful comments and fruitful discussions which improved this work. We thank the Department of Mathematical Sciences at the University of Delaware for their continued support throughout the process of this research. 
M.~Ghandehari was supported by NSF grant DMS-1902301 while this work was being completed.


\section*{Appendix: Proofs of Lemmas~\ref{lem:splitint} and \ref{lem:gnrlpigeon}}\label{section:proofs of lemmas}
In this Appendix we present full proofs of the lemmas used previously in the paper, recalling their statements for clarity.
%
\begin{lemma*} (Lemma~\ref{lem:splitint})
Let $u\in L^\infty([0,1])$, let $P\subseteq [0,1]$ be a measurable subset such that $\int_P u~dx\neq 0$, and let $0 < \beta <|P|$ be fixed. 
Then $P$ can be partitioned into $N:=\lceil |P|/\beta\rceil$ subsets $P_1,\ldots,P_{N}$ so that the following conditions are satisfied:
%
\begin{onehalfspacing}
\begin{itemize}
    \item[(i)] $P_1 \leq \ldots \leq P_{N-1}.$
    
    \item[(ii)] $|P_i|= \beta$ for $1\leq i\leq N-1$ and $|P_{N}|\leq \beta$.
    
    \item[(iii)] $\big|\int_{P_{N}} u~dx\big|\leq \frac{1}{N}\big|\int_{P}u~dx\big|$. 
\end{itemize}
\end{onehalfspacing}
%
\end{lemma*}
%
\begin{proof}[Proof of Lemma \ref{lem:splitint}]
For any sets $P_1,\ldots,P_N$ satisfying the above properties, we must have 
$$|P_N| =\delta := |P|-\beta\left(\left\lceil\frac{|P|}{\beta}\right\rceil-1\right).$$
To prove the lemma, it is enough to find a subset   $P_N\subseteq P$ satisfying $|P_N|=\delta$ and condition (iii). Indeed, given such a subset $P_N$, one can form the other sets $P_1,\ldots,P_{N-1}$ by splitting $P\setminus P_N$ into consecutive sets of measure $\beta$. 

If $\delta = \beta$, then the lemma follows trivially from the pigeonhole principle. So, we assume that $\delta < \beta$.
Moreover,  replacing $u$ by $-u$ if necessary, we can assume that $\int_P u~dx > 0$. 
We now prove the lemma in two steps:

{\bf Step 1:} There must exist a set $Q \subset P$ such that $|Q| = |P|-\delta(\lceil \frac{|P|}{\delta}\rceil-1)$ and $\int_Q u > 0$. To show this statement, note that
%
\begin{equation}\label{eq:Qpositivity}
    \int_P u~dx = \int_{P^+}u~dx + \int_{P^-}u~dx >0,
\end{equation}
%
where $P^+ := \{x \in P : u(x) > 0\}$ and $P^- :=\{y \in P : u(y) < 0\}$. If $|P^+|\geq \delta$, then any subset $Q$ of measure $\delta$ from $P^+$ suffices. If $|P^+| < \delta$, then we let $Q=P^+\cup Q'$ for a subset  $Q'\subseteq P^-$ with $|Q'|=\delta-|P^+|$, and note that 
 $\int_{Q} u\geq \int_{P} u>0$ by \eqref{eq:Qpositivity}.

{\bf Step 2:} We now prove the existence of a subset $P_N\subseteq P$ satisfying $|P_N|=\delta$ and condition (iii). Towards a contradiction, assume that for any set $S \subseteq P$ such that $|S| = \delta$, we have 
%
\begin{equation}\label{eq:splitintcontra}
    \bigg|\int_S u~dx\bigg|> \frac{1}{N}\int_{P}u~dx.
\end{equation}
%
Consider now $R:=P \setminus Q$. For any $p \in P$, let $r_p = \inf \{q: |R \cap [p,q]|=\delta\}$, and let the auxiliary function $\phi$ be defined as
%
\begin{equation*}
    \phi: P \to \R, \  \phi(p) := \int_{R \cap [p,r_p]}u~dx.
\end{equation*}
%
For ease of writing, let $R_p := R \cap [p,r_p]$, and note that as $|R_p| = \delta$, by \eqref{eq:splitintcontra}, we get $\phi(p) \neq 0$ for all $p \in P$. It is easy to see that $\phi$ is continuous, as for $p,q\in P$, we have
%
\begin{equation*}
    |\phi(p)-\phi(q)| = \bigg|\int_{R_p}u~dx - \int_{R_q}u~dx\bigg| \mahya{=} \bigg|\int_{R_p \Delta R_q}u~dx\bigg|\\
    \leq \|u\|_{\infty}|R_p \Delta R_q| \leq \|u\|_{\infty}|p-q|.
\end{equation*}
%
Therefore, as $\phi \neq 0$, it is either strictly positive or strictly negative. Without loss of generality, we assume that $\phi(p) > 0$ for all $p$, and to avoid violating our assumption, it must also be that 
%
\begin{equation}\label{eq:piecesbnd}
    \phi(x) > \frac{1}{N}\int_{P}u~dx
\end{equation}
%
for all $p \in P$. Consider $\{p_i\}_{i=1}^M \subset R$, where $p_1=0$, $p_{i+1}=r_{p_i}$ for $1 < i < M$, and $M= \lceil \frac{|P|}{\delta}\rceil-1$. Then it must be the case, due to the positivity of $w$ and \eqref{eq:piecesbnd}, that 
%
\begin{equation}\label{eq:measurelemmacontra}
    \int_P u~dx= \sum_{i=1}^M \phi(p_i) + \int_Q u~dx
    > \frac{M}{N}\int_P u~dx.
\end{equation}
%
This will lead to a contradiction, as we will show that $M \geq N$, i.e. $\lceil \frac{|P|}{\delta}\rceil-1 \geq \lceil \frac{|P|}{\beta}\rceil$. We note that as $\delta < \beta$, it must be the case that $M \geq N-1$. Therefore, the only way our claim can be violated is if $M$ is indeed equal to $N-1$. For this to be possible, $\delta$ must be within a tight range of values: specifically,
%
${|P|}/{\lceil \frac{|P|}{\beta}\rceil} \leq \delta < \beta.$
%
However, the exact value of $\delta$ is known to be $|P|-\beta(\lceil \frac{|P|}{\beta}\rceil-1)$. Thus, if $M = N-1$, we have 
%
\begin{eqnarray*}
\left\{
\begin{array}{l}
|P|-\beta\left(\left\lceil \frac{|P|}{\beta}\right\rceil-1\right) \geq \frac{|P|}{\lceil \frac{|P|}{\beta}\rceil}, \mbox{ or equivalently, }    |P| \geq \beta\left\lceil \frac{|P|}{\beta}\right\rceil\\
|P|-\beta\left(\left\lceil \frac{|P|}{\beta}\right\rceil-1\right)<\beta, \mbox{ or equivalently, } |P| < \beta\left\lceil \frac{|P|}{\beta}\right\rceil
\end{array}\right.
\end{eqnarray*}
%
This is a contradiction, so it must be the case that $M \geq N$, making \eqref{eq:measurelemmacontra} a contradiction. Thus the lemma holds true and such a partition of $P$ must exist. 
\end{proof}
%
\begin{lemma*} (Lemma~\ref{lem:gnrlpigeon})
Let $f \in L^1([0,1]^2)$, and let $S,S' \subseteq [0,1]$ be measurable subsets such that $|S|=|S'|$. Suppose for a constant $C > 0$ we have
%
\begin{equation*}
    \iint_{S \times S'} f~dxdy \geq C.
\end{equation*}
%
Then, for every $\alpha \in (0,1)$, there exist measurable sets $T\subset S$ and $T'\subset S'$ such that $|T| = |T'|=\alpha|S|$ and
%
\begin{equation*}
    \frac{1}{|T\times T'|}\iint_{T \times T'}f~dxdy \geq \frac{C}{|S \times S'|}.
\end{equation*}
%
\end{lemma*}
%
\begin{proof}[Proof of Lemma \ref{lem:gnrlpigeon}]
Suppose there exist integers $n,k,l$, with $l<k$, so that $|S| = \frac{k}{n}$ and $\alpha |S| = \frac{l}{n}$; the case where one or both of $|S|$ or $\alpha$ is not rational can be done using standard density/approximation arguments. 
Next, split $S$ into $k$ consecutive sets $S_1 \leq S_2 \leq \ldots \leq S_k$ of measure $\frac{1}{n}$; likewise, split $S'$ into $k$ consecutive sets $S'_1 \leq S'_2 \leq \ldots \leq S'_k$ also of measure $\frac{1}{n}$ and note that
%
\begin{equation*}
    \iint_{S \times S'} f~dxdy = \sum_{i = 1}^k \sum_{j=1}^k\iint_{S_i \times S'_j}f~dxdy.
\end{equation*}
%
Let $B_{i,j}:=\iint_{S_i \times S'_j} f~dxdy$ and let $\mathcal{N}_{k,l}$ denote the collection of all $l$-subsets of the set $\{1,...,k\}$. 
%
Note that there are $\binom{k-1}{l-1}$ many $l$-subsets of $k$ elements containing a specific element $i_0$. Using this, counting the number of times a specific $B_{i,j}$ appears in the following sum results in
%
\begin{equation*}
    \sum_{I \in \mathcal{N}_{k,l}}  \sum_{J \in \mathcal{N}_{k,l}} \sum_{\substack{i\in I\\j\in J}} B_{i,j} = 
    \sum_{i,j=1}^k \binom{k-1}{l-1}^2B_{i,j} \geq \binom{k-1}{l-1}^2C.
\end{equation*}
%
Thus, by the pigeonhole principle, there exist sets $I,J\in \mathcal{N}_{k,l}$ such that 
$$\sum_{\substack{i \in I\\j\in J}}B_{i,j} \geq \frac{\binom{k-1}{l-1}^2}{\binom{k}{l}^2}C = \frac{l^2}{k^2}C.$$
%
This implies that the sets $T = \cup_{i \in I}S_i$ and $T' = \cup_{i \in J}S'_i$ satisfy both that
%
\begin{equation*}
    \iint_{T \times T'} f~dxdy \geq \frac{l^2}{k^2}C
\end{equation*}
%
and $|T|=|T'|=\alpha|S|$, proving the initial statement.
\end{proof}



%\bibliography{bibliography}


\begin{thebibliography}{46}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agarwal et~al.(2012)Agarwal, Negahban, and Wainwright]{agarwal2012}
Alekh Agarwal, Sahand Negahban, and Martin~J. Wainwright.
\newblock {Noisy matrix decomposition via convex relaxation: Optimal rates in
  high dimensions}.
\newblock \emph{The Annals of Statistics}, 40\penalty0 (2):\penalty0 1171 --
  1197, 2012.
\newblock \doi{10.1214/12-AOS1000}.
\newblock URL \url{https://doi.org/10.1214/12-AOS1000}.

\bibitem[Atkins et~al.(1998)Atkins, Boman, and Hendrickson]{atkins1998}
J.E. Atkins, E.G. Boman, and B.~Hendrickson.
\newblock A spectral algorithm for seriation and the consecutive ones problem.
\newblock \emph{SIAM Journal on Computing}, 28\penalty0 (1):\penalty0 297--310,
  1998.

\bibitem[Barth{\'e}lemy and Brucker(2001)]{barthelemy2001np}
J.P. Barth{\'e}lemy and F.~Brucker.
\newblock Np-hard approximation problems in overlapping clustering.
\newblock \emph{Journal of classification}, 18\penalty0 (2):\penalty0 159--183,
  2001.

\bibitem[Borgs et~al.(2018)Borgs, Chayes, Cohn, and Zhao]{Borgs_2018}
C.~Borgs, J.~Chayes, H.~Cohn, and Y.~Zhao.
\newblock An $l^{p}$ theory of sparse graph convergence ii: Ld convergence,
  quotients and right convergence.
\newblock \emph{The Annals of Probability}, 46\penalty0 (1), Jan 2018.
\newblock ISSN 0091-1798.

\bibitem[Borgs et~al.(2019)Borgs, Chayes, Cohn, and Zhao]{Borgs_2019}
C.~Borgs, J.~Chayes, H.~Cohn, and Y.~Zhao.
\newblock An $l^p$ theory of sparse graph convergence i: Limits, sparse random
  graph models, and power law distributions.
\newblock \emph{Transactions of the American Mathematical Society},
  372\penalty0 (5):\penalty0 30193062, May 2019.
\newblock ISSN 1088-6850.

\bibitem[Cai and Liu(2011)]{cai2011}
Tony Cai and Weidong Liu.
\newblock Adaptive thresholding for sparse covariance matrix estimation.
\newblock \emph{Journal of the American Statistical Association}, 106\penalty0
  (494):\penalty0 672--684, 2011.
\newblock \doi{10.1198/jasa.2011.tm10560}.

\bibitem[Candes and Plan(2010)]{candes2010noise}
Emmanuel~J. Candes and Yaniv Plan.
\newblock Matrix completion with noise.
\newblock \emph{Proceedings of the IEEE}, 98\penalty0 (6):\penalty0 925--936,
  2010.
\newblock \doi{10.1109/JPROC.2009.2035722}.

\bibitem[Cand{\`e}s and Recht(2009)]{Candes2009}
Emmanuel~J. Cand{\`e}s and Benjamin Recht.
\newblock Exact matrix completion via convex optimization.
\newblock \emph{Foundations of Computational Mathematics}, 9\penalty0
  (6):\penalty0 717--772, Dec 2009.
\newblock ISSN 1615-3383.
\newblock \doi{10.1007/s10208-009-9045-5}.
\newblock URL \url{https://doi.org/10.1007/s10208-009-9045-5}.

\bibitem[Cand\`es and Tao(2010)]{Tao2010}
Emmanuel~J. Cand\`es and Terence Tao.
\newblock The power of convex relaxation: near-optimal matrix completion.
\newblock \emph{IEEE Trans. Inform. Theory}, 56\penalty0 (5):\penalty0
  2053--2080, 2010.
\newblock ISSN 0018-9448.
\newblock \doi{10.1109/TIT.2010.2044061}.
\newblock URL \url{https://doi.org/10.1109/TIT.2010.2044061}.

\bibitem[Chandrasekaran et~al.(2011)Chandrasekaran, Sanghavi, Parrilo, and
  Willsky]{chandrasekaran2011}
Venkat Chandrasekaran, Sujay Sanghavi, Pablo~A. Parrilo, and Alan~S. Willsky.
\newblock Rank-sparsity incoherence for matrix decomposition.
\newblock \emph{SIAM Journal on Optimization}, 21\penalty0 (2):\penalty0
  572--596, 2011.
\newblock \doi{10.1137/090761793}.

\bibitem[Chepoi and Seston(2009)]{chepoi2009}
V.~Chepoi and M.~Seston.
\newblock Seriation in the presence of errors: A factor 16 approximation
  algorithm for $l_{\infty}$-fitting robinson structures to distances.
\newblock \emph{Algorithmica}, 59:\penalty0 521--568, 02 2009.

\bibitem[Chuangpishit et~al.(2015)Chuangpishit, Ghandehari, Hurshman, Janssen,
  and Kalyaniwalla]{Chuangpishit_2015}
H.~Chuangpishit, M.~Ghandehari, M.~Hurshman, J.~Janssen, and N.~Kalyaniwalla.
\newblock Linear embeddings of graphs and graph limits.
\newblock \emph{Journal of Combinatorial Theory, Series B}, 113:\penalty0
  162184, Jul 2015.
\newblock ISSN 0095-8956.

\bibitem[de~Castro et~al.(2017)de~Castro, Lacour, and
  Ngoc]{Castro2017AdaptiveEO}
Yohann de~Castro, Claire Lacour, and Thanh Mai~Pham Ngoc.
\newblock Adaptive estimation of nonparametric geometric graphs.
\newblock \emph{Mathematical Statistics and Learning}, 2017.

\bibitem[Eftekhari et~al.(2018)Eftekhari, Yang, and Wakin]{eftekhari2018}
Armin Eftekhari, Dehui Yang, and Michael~B. Wakin.
\newblock Weighted matrix completion and recovery with prior subspace
  information.
\newblock \emph{IEEE Transactions on Information Theory}, 64\penalty0
  (6):\penalty0 4044--4071, 2018.
\newblock \doi{10.1109/TIT.2018.2816685}.

\bibitem[Fazel et~al.(2013)Fazel, Pong, Sun, and Tseng]{Fazel}
Maryam Fazel, Ting~Kei Pong, Defeng Sun, and Paul Tseng.
\newblock Hankel matrix rank minimization with applications to system
  identification and realization.
\newblock \emph{SIAM J. Matrix Anal. Appl.}, 34\penalty0 (3):\penalty0
  946--977, 2013.
\newblock ISSN 0895-4798.
\newblock \doi{10.1137/110853996}.
\newblock URL \url{https://doi.org/10.1137/110853996}.

\bibitem[Flammarion et~al.(2019)Flammarion, Mao, and Rigollet]{flammarion2019}
Nicolas Flammarion, Cheng Mao, and Philippe Rigollet.
\newblock {Optimal rates of statistical seriation}.
\newblock \emph{Bernoulli}, 25\penalty0 (1):\penalty0 623 -- 653, 2019.
\newblock \doi{10.3150/17-BEJ1000}.
\newblock URL \url{https://doi.org/10.3150/17-BEJ1000}.

\bibitem[Fogel et~al.(2016)Fogel, d'Aspremont, and Vojnovic]{fogel2014}
F.~Fogel, A.~d'Aspremont, and M.~Vojnovic.
\newblock Spectral ranking using seriation.
\newblock \emph{J. Mach. Learn. Res.}, 17\penalty0 (1):\penalty0 30133057,
  January 2016.
\newblock ISSN 1532-4435.

\bibitem[Fortin(2017)]{Fortin2017RobinsonianMR}
D.~Fortin.
\newblock Robinsonian matrices: Recognition challenges.
\newblock \emph{Journal of Classification}, 34:\penalty0 191--222, 2017.

\bibitem[Frieze and Kannan(1999)]{friezekannan}
A.~Frieze and R.~Kannan.
\newblock Quick approximation to matrices and applications.
\newblock \emph{Combinatorica}, 19:\penalty0 175--220, 02 1999.

\bibitem[Ghandehari and Janssen(2019)]{janssen2019optimization}
M.~Ghandehari and J.~Janssen.
\newblock An optimization parameter for seriation of noisy data.
\newblock \emph{SIAM Journal on Discrete Mathematics}, 33\penalty0
  (2):\penalty0 712--730, 2019.

\bibitem[Ghandehari and Janssen(2020)]{ghandehari2020graph}
M.~Ghandehari and J.~Janssen.
\newblock Graph sequences sampled from robinson graphons.
\newblock 2020.

\bibitem[Goyens et~al.(2023)Goyens, Cartis, and Eftekhari]{GOYENS2023498}
Florentin Goyens, Coralia Cartis, and Armin Eftekhari.
\newblock Nonlinear matrix recovery using optimization on the grassmann
  manifold.
\newblock \emph{Applied and Computational Harmonic Analysis}, 62:\penalty0
  498--542, 2023.
\newblock ISSN 1063-5203.
\newblock \doi{https://doi.org/10.1016/j.acha.2022.11.001}.
\newblock URL
  \url{https://www.sciencedirect.com/science/article/pii/S1063520322000859}.

\bibitem[Gross(2011)]{Gross}
David Gross.
\newblock Recovering low-rank matrices from few coefficients in any basis.
\newblock \emph{IEEE Trans. Inform. Theory}, 57\penalty0 (3):\penalty0
  1548--1566, 2011.
\newblock ISSN 0018-9448.
\newblock \doi{10.1109/TIT.2011.2104999}.
\newblock URL \url{https://doi.org/10.1109/TIT.2011.2104999}.

\bibitem[Jain et~al.(2013)Jain, Netrapalli, and Sanghavi]{Jain}
Prateek Jain, Praneeth Netrapalli, and Sujay Sanghavi.
\newblock Low-rank matrix completion using alternating minimization (extended
  abstract).
\newblock In \emph{S{TOC}'13---{P}roceedings of the 2013 {ACM} {S}ymposium on
  {T}heory of {C}omputing}, pages 665--674. ACM, New York, 2013.
\newblock \doi{10.1145/2488608.2488693}.
\newblock URL \url{https://doi.org/10.1145/2488608.2488693}.

\bibitem[Janssen and Smith(2022)]{janssen2022}
Jeannette Janssen and Aaron Smith.
\newblock {Reconstruction of line-embeddings of graphons}.
\newblock \emph{Electronic Journal of Statistics}, 16\penalty0 (1):\penalty0
  331 -- 407, 2022.
\newblock \doi{10.1214/21-EJS1940}.
\newblock URL \url{https://doi.org/10.1214/21-EJS1940}.

\bibitem[Keshavan et~al.(2010{\natexlab{a}})Keshavan, Montanari, and
  Oh]{Keshavan-noisy}
Raghunandan~H. Keshavan, Andrea Montanari, and Sewoong Oh.
\newblock Matrix completion from noisy entries.
\newblock \emph{J. Mach. Learn. Res.}, 11:\penalty0 2057--2078,
  2010{\natexlab{a}}.
\newblock ISSN 1532-4435.

\bibitem[Keshavan et~al.(2010{\natexlab{b}})Keshavan, Montanari, and
  Oh]{keshavan2010}
Raghunandan~H. Keshavan, Andrea Montanari, and Sewoong Oh.
\newblock Matrix completion from a few entries.
\newblock \emph{IEEE Transactions on Information Theory}, 56\penalty0
  (6):\penalty0 2980--2998, 2010{\natexlab{b}}.
\newblock \doi{10.1109/TIT.2010.2046205}.

\bibitem[Klopp(2014)]{klopp-noisy}
Olga Klopp.
\newblock Noisy low-rank matrix completion with general sampling distribution.
\newblock \emph{Bernoulli}, 20\penalty0 (1):\penalty0 282--303, 2014.
\newblock ISSN 1350-7265.
\newblock \doi{10.3150/12-BEJ486}.
\newblock URL \url{https://doi.org/10.3150/12-BEJ486}.

\bibitem[Klopp et~al.(2017)Klopp, Lounici, and Tsybakov]{Klopp2017}
Olga Klopp, Karim Lounici, and Alexandre~B. Tsybakov.
\newblock Robust matrix completion.
\newblock \emph{Probability Theory and Related Fields}, 169\penalty0
  (1):\penalty0 523--564, Oct 2017.
\newblock ISSN 1432-2064.
\newblock \doi{10.1007/s00440-016-0736-y}.
\newblock URL \url{https://doi.org/10.1007/s00440-016-0736-y}.

\bibitem[Koltchinskii et~al.(2011)Koltchinskii, Lounici, and
  Tsybakov]{Koltchinskii2011}
Vladimir Koltchinskii, Karim Lounici, and Alexandre~B. Tsybakov.
\newblock {Nuclear-norm penalization and optimal rates for noisy low-rank
  matrix completion}.
\newblock \emph{The Annals of Statistics}, 39\penalty0 (5):\penalty0 2302 --
  2329, 2011.
\newblock \doi{10.1214/11-AOS894}.
\newblock URL \url{https://doi.org/10.1214/11-AOS894}.

\bibitem[Laurent and Seminaroti(2017)]{LAURENT2017151}
M.~Laurent and M.~Seminaroti.
\newblock A lex-bfs-based recognition algorithm for robinsonian matrices.
\newblock \emph{Discrete Applied Mathematics}, 222:\penalty0 151--165, 2017.
\newblock ISSN 0166-218X.

\bibitem[Laurent et~al.(2017)Laurent, Seminaroti, and Tanigawa]{laurent2017}
M.~Laurent, M.~Seminaroti, and S.~Tanigawa.
\newblock A structural characterization for certifying robinsonian matrices.
\newblock \emph{Electronic Journal of Combinatorics}, 24, 01 2017.

\bibitem[Liiv(2010)]{Liiv_2010}
I.~Liiv.
\newblock Seriation and matrix reordering methods: An historical overview.
\newblock \emph{Statistical Analysis and Data Mining: The ASA Data Science
  Journal}, 3\penalty0 (2):\penalty0 70--91, 2010.

\bibitem[Lovsz(2012)]{lovaszbook}
L.~Lovsz.
\newblock \emph{Large Networks and Graph Limits.}, volume~60 of
  \emph{Colloquium Publications}.
\newblock American Mathematical Society, 2012.
\newblock ISBN 978-0-8218-9085-1.

\bibitem[Lovsz and Szegedy(2006)]{LOVASZ2006933}
L.~Lovsz and B.~Szegedy.
\newblock Limits of dense graph sequences.
\newblock \emph{Journal of Combinatorial Theory, Series B}, 96\penalty0
  (6):\penalty0 933--957, 2006.
\newblock ISSN 0095-8956.

\bibitem[Mirkin et~al.(1984)Mirkin, Beus, and Rodin]{Mirkin1984GraphsAG}
B.G. Mirkin, H.L. Beus, and S.N. Rodin.
\newblock \emph{Graphs and Genes}.
\newblock Biomathematics. Springer Berlin Heidelberg, 1984.
\newblock ISBN 9783540126577.

\bibitem[Mishura(2022)]{MISHURA202226}
T.~Mishura.
\newblock Cut norm discontinuity of triangular truncation of graphons.
\newblock \emph{Linear Algebra and its Applications}, 650:\penalty0 26--41,
  2022.
\newblock ISSN 0024-3795.

\bibitem[Pr{\'e}a and Fortin(2014)]{prea-fortin}
Pascal Pr{\'e}a and Dominique Fortin.
\newblock An optimal algorithm to recognize {R}obinsonian dissimilarities.
\newblock \emph{J. Classification}, 31\penalty0 (3):\penalty0 351--385, 2014.
\newblock ISSN 0176-4268.
\newblock \doi{10.1007/s00357-014-9150-2}.
\newblock URL \url{http://dx.doi.org/10.1007/s00357-014-9150-2}.

\bibitem[Recht(2011)]{recht2011}
Benjamin Recht.
\newblock A simpler approach to matrix completion.
\newblock \emph{J. Mach. Learn. Res.}, 12\penalty0 (null):\penalty0
  34133430, dec 2011.
\newblock ISSN 1532-4435.

\bibitem[Robinson(1951)]{robinson_1951}
W.~S. Robinson.
\newblock A method for chronologically ordering archaeological deposits.
\newblock \emph{American Antiquity}, 16\penalty0 (4):\penalty0 293301, 1951.

\bibitem[Rohde and Tsybakov(2011)]{Rohde}
Angelika Rohde and Alexandre~B. Tsybakov.
\newblock Estimation of high-dimensional low-rank matrices.
\newblock \emph{Ann. Statist.}, 39\penalty0 (2):\penalty0 887--930, 2011.
\newblock ISSN 0090-5364.
\newblock \doi{10.1214/10-AOS860}.
\newblock URL \url{https://doi.org/10.1214/10-AOS860}.

\bibitem[Seston(2008)]{seston}
Morgan Seston.
\newblock A simple algorithm for recognize {R}obinsonian dissimilarities.
\newblock In \emph{C{OMPSTAT} 2008---{P}roceedings in {C}omputational
  {S}tatistics}, pages 241--248, CD--ROM. Physica-Verlag/Springer, Heidelberg,
  2008.

\bibitem[Sun and Luo(2016)]{SunLuo}
Ruoyu Sun and Zhi-Quan Luo.
\newblock Guaranteed matrix completion via non-convex factorization.
\newblock \emph{IEEE Trans. Inform. Theory}, 62\penalty0 (11):\penalty0
  6535--6579, 2016.
\newblock ISSN 0018-9448.
\newblock \doi{10.1109/TIT.2016.2598574}.
\newblock URL \url{https://doi.org/10.1109/TIT.2016.2598574}.

\bibitem[Tao and Yuan(2011)]{tao2011}
Min Tao and Xiaoming Yuan.
\newblock Recovering low-rank and sparse components of matrices from incomplete
  and noisy observations.
\newblock \emph{SIAM Journal on Optimization}, 21\penalty0 (1):\penalty0
  57--81, 2011.
\newblock \doi{10.1137/100781894}.

\bibitem[Vandereycken(2013)]{Vandereycken}
Bart Vandereycken.
\newblock Low-rank matrix completion by {R}iemannian optimization.
\newblock \emph{SIAM J. Optim.}, 23\penalty0 (2):\penalty0 1214--1236, 2013.
\newblock ISSN 1052-6234.
\newblock \doi{10.1137/110845768}.
\newblock URL \url{https://doi.org/10.1137/110845768}.

\bibitem[Wang et~al.(2016)Wang, Li, and Wang]{WANG2016133}
Chuan-Long Wang, Chao Li, and Jin Wang.
\newblock Comparisons of several algorithms for toeplitz matrix recovery.
\newblock \emph{Computers \& Mathematics with Applications}, 71\penalty0
  (1):\penalty0 133--146, 2016.
\newblock ISSN 0898-1221.
\newblock \doi{https://doi.org/10.1016/j.camwa.2015.11.010}.
\newblock URL
  \url{https://www.sciencedirect.com/science/article/pii/S0898122115005416}.

\end{thebibliography}

\end{document}

****************************************************************************************************************
History/background references:

MR\teddydone{44}00949 Reviewed Barthelemy, Marc Spatial networksa complete introduction: from graph theory and statistical physics to real-world applications. Springer, Cham, [2022], 2022. xix+437 pp. ISBN: 978-3-030-94105-5; 978-3-030-94106-2 (Reviewer: David J. Aldous) 05-02 (05C82 \teddydone{44}C20 60D05 62P35 82B20 90B10)
Review PDF Clipboard Series Book

MR1986198 Reviewed Penrose, Mathew Random geometric graphs. Oxford Studies in Probability, 5. Oxford University Press, Oxford, 2003. xiv+330 pp. ISBN: 0-19-850626-0 (Reviewer: Ilya S. Molchanov) 60-02 (05C80 60D05) and citations in it.

****************************************************************************************************************
Ideas for the introductions:

Recovering: We have a Robinson graphon. Make a noisy sample (that is, we get a graphon, that is supposed to be close to our original random process. But because of noise, it is not Robinon anymore). Then compute R_w to be the Robinson graphon that we were originally looking for. We consider this "recovering" our Robinson graphon from samples. 

Completion: Suppose we have an incomplete graphon given to me. Put 0 in the empty places. Assuming the graphon was supposed to be Robinson, we find a Robinson approximation, which we think of as the "completion problem". 

****************************************************************************************************************
We should reference to:

Janssen, Jeannette (3-DLHS-MS); Smith, Aaron (3-OTTW-MS)
Reconstruction of line-embeddings of graphons. (English summary)
Electron. J. Stat. 16 (2022), no. 1, 331407.


****************************************************************************************************************
Useful for our story to put our paper with the right community. We need to understand how our work relates/compares with these ones.

MR2967065 Reviewed Bollobs, Bla; Janson, Svante; Riordan, Oliver Monotone graph limits and quasimonotone graphs. Internet Math. 8 (2012), no. 3, 187231. (Reviewer: Jan Hladk) 05C35 (05C80)

MR2573956 Reviewed Diaconis, Persi; Holmes, Susan; Janson, Svante Threshold graph limits and random threshold graphs. Internet Math. 5 (2008), no. 3, 267320 (2009). (Reviewer: Hamed Hatami) 05C80 (60K35)
Review PDF Clipboard Journal Article 36 Citations

****************************************************************************************************************
Finitely forcible graphons:

MR4132060 Reviewed Krl', Daniel; Lovsz, Lszl M.; Noel, Jonathan A.; Sosnovec, Jakub Finitely forcible graphons with an almost arbitrary structure. Discrete Anal. 2020, Paper No. 9, 36 pp. (Reviewer: Nikolaos Fountoulakis) 05C35 (05C80)

MR3938713 Reviewed Glebov, Roman; Klimoov, Tereza; Krl, Daniel Infinite-dimensional finitely forcible graphon. Proc. Lond. Math. Soc. (3) 118 (2019), no. 4, 826856. (Reviewer: Jan Hladk) 05C35 (05C80)
Review PDF Clipboard Journal Article 7 Citations

MR3886181 Reviewed Cooper, Jacob W.; Kr, Daniel; Martins, Tasa L. Finitely forcible graph limits are universal. Adv. Math. 340 (2018), 819854. 05C35

****************************************************************************************************************
Network recovery/estimation:

Athreya, Avanti (1-JHOP-AMS); Tang, Minh (1-NCS-S); Park, Youngser (1-JHOP-CIS); Priebe, Carey E. (1-JHOP-AM)
On estimation and inference in latent structure random graphs. (English summary)
Statist. Sci. 36 (2021), no. 1, 6888.
62H12 (05C80 62R30)

Cai, T., T. Liang and A. Rakhlin (2017). On detection and structural reconstruction of small-world random networks. IEEE Transactions on Network Science and Engineering 4 (3), 165176. MR3696219 MR3696219\textbf{}

Zhang, Yuan (1-OHS-S); Levina, Elizaveta (1-MI-S); Zhu, Ji (1-MI-S)
Estimating network edge probabilities by neighbourhood smoothing. (English summary)
Biometrika 104 (2017), no. 4, 771783.
62G05 (05C90 62G07)

Airoldi, E. M., Costa, T. B. & Chan, S. H. (2013). Stochastic blockmodel approximation of a graphon: Theory and consistent estimation. In Advances in Neural Information Processing Systems 26, C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani & K. Q. Weinberger, eds. Red Hook, New York: Curran Associates, pp. 692700.

Cai, D., Ackerman, N. & Freer, C. (2015). An iterative step-function estimator for graphons. arXiv: 1412.2129v2

Zhao, Y., Wu, Y.-J., Levina, E. & Zhu, J. (2017). Link prediction for partially observed networks. J. Comp. Graph. Statist., doi:10.1080/10618600.2017.1286243. MR3698680

Wolfe, P. J. & Olhede, S. C. (2013). Nonparametric graphon estimation. arXiv: 1309.5936. cf. MR2908387

Lichtenwalter, R. N., Lussier, J. T. & Chawla, N. V. (2010). New perspectives and methods in link prediction. In Proc. 16th ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining, KDD '10. New York: ACM, pp. 243\teddydone{44}.

Gao, Chao (1-YALE-NDM); Lu, Yu (1-YALE-NDM); Ma, Zongming (1-PA-NDM); Zhou, Harrison H. (1-YALE-NDM)
Optimal estimation and completion of matrices with biclustering structures. (English summary)
J. Mach. Learn. Res. 17 (2016), Paper No. 161, 29 pp.
62H12 (62G05 62H30)

****************************************************************************************************************
Matrix completion problem:

MR2723472 Reviewed Cands, Emmanuel J.; Tao, Terence The power of convex relaxation: near-optimal matrix completion. IEEE Trans. Inform. Theory 56 (2010), no. 5, 20532080. (Reviewer: Tian Zhou Xu) 15A83 (60B20 90C22 90C46 94A12)

MR256\teddydone{44}40 Reviewed Cands, Emmanuel J.; Recht, Benjamin Exact matrix completion via convex optimization. Found. Comput. Math. 9 (2009), no. 6, 717772. (Reviewer: Gunter Semmler) 90C25 (15A83 90C22)

MR2806637 Reviewed Halko, N.; Martinsson, P. G.; Tropp, J. A. Finding structure with randomness: probabilistic algorithms for constructing approximate matrix decompositions. SIAM Rev. 53 (2011), no. 2, 217288. (Reviewer: Thomas K. Huckle) 65F30 (60B20 68W20)

MR2683452 Reviewed Keshavan, Raghunandan H.; Montanari, Andrea; Oh, Sewoong Matrix completion from a few entries. IEEE Trans. Inform. Theory 56 (2010), no. 6, 29802998. 62H12 (05C80 90C90)


* https://arxiv.org/pdf/2101.03033.pdf and references in there are very relevant. 


* https://proceedings.neurips.cc/paper/2015/file/f197002b9a0853eca5e046d9ca4663d5-Paper.pdf
