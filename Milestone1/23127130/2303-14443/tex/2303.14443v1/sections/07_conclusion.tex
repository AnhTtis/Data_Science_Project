\section{Conclusion}
\label{sec:conclusion}

In this paper, we demonstrate that current systems for automatic paper-reviewer assignments are vulnerable and can be misled by \emph{adversarial papers}. On a broader level, we develop a novel framework for constructing adversarial examples in discrete domains through joint optimization in the problem space and feature space. Based on this framework, we can craft objects that satisfy real-world constraints and evade machine-learning models at the same time.

In summary, our work demonstrates a significant attack surface of current matching systems and motivates further security analysis prior to their deployment. As a result, we have informed the developers of TPMS and Autobid about our findings, as part of a responsible disclosure process.
