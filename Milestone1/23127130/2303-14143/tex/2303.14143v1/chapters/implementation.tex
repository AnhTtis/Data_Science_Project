To demonstrate LLM-driven smart home control in practice, we built a proof-of-concept implementation in Python. Our implementation accepts user commands as strings, packages them into prompts along with contextual information about real devices, then processes responses from OpenAI's \texttt{text-davinci-003} model into smart home API calls that change the device state as specified by the LLM. We scope the application to one room (a researcher's living room) with three Philips Hue color smart lights~\cite{hue2022} and one TP-Link Kasa smart plug~\cite{kasa2023} that controls a stereo. We store the device context in JSON as in our experimental setup, with the difference that the device state for the Hue lights is pulled directly from the Hue API without modification. Our code is open source and available online.\footnote{https://github.com/UT-MPC/homegpt}

The teaser figure depicts the result when issuing the command ``set up for a party''. We include the JSON context of the light group\footnote{https://developers.meethue.com/develop/hue-api/groupds-api/}, along with a field for the plug powering the stereo. The model mutates the parameters in the JSON to change the stereo state to ``on'' and, impressively, also changes the ``effect'' parameter of the Hue light group from ``none'' to ``colorloop'' to create a looping color effect. The latter change suggests that GPT-3 may have been trained on material about the specific features of the Hue API and can leverage that along with the inferred meaning of the user command to trigger more intuitive changes than existing systems.

We briefly list multiple other commands we tested in our implementation, along with responses from the model:

\begin{itemize}
    \item ``make it bright in here'' -- sets lights to full brightness
    \item ``make it groovy'' -- sets lights to color loop; adds invalid ``genre'' field to stereo and sets it to ''groovy''
    \item ``gotta relax'' -- dims lights, turns stereo on
    \item ``I'm cold'' -- sets lights to warm white, turns stereo on
    \item ``I'm leaving'' -- turns off lights and stereo
    \item ``I'm home'' -- turns on lights and stereo
\end{itemize}

We note, of course, that these tests are far from exhaustive. We observed high variability in responses, meaning the same command can elicit many responses: some good, some bad. A more robust system design will be necessary to tackle the inconsistencies present in current LLM model outputs. We address this in our discussion in the following section.