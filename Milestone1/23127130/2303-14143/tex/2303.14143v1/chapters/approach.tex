In this section, we introduce the system design that we use to explore the feasibility of LLM-driven smart home control. We first assume the use of an LLM like GPT-3 that provides responses to user prompts written in natural language. These LLM models are not task-specific, rather, they are trained on an immense amount of cross-domain textual information and, depending on the structure of the prompt, can provide responses suited to a variety of different use cases (e.g., writing a poem, writing code in response to a high-level program description, etc.). We opt to adapt the model's outputs to our task using zero-shot learning through prompt engineering.

Our challenge is therefore to package relevant context % (i.e., currently available devices and relevant information about the environment) 
and user commands into a concise prompt issued to the model, such that its responses include concrete, machine-parseable changes to device state that can be passed off to the appropriate smart device APIs. Qualitatively, we want these courses of action to be shaped by the model successfully inferring (1)~the intent behind the user command and (2)~the manner in which the state of available devices can be changed to meet the user's intent. To that end, we first define an abstract schema for capturing smart home context before describing a method for engineering prompts to conversational LLMs that elicit useful, actionable responses.

\subsection{Context Schema}
In order for the model to ``know'' what actions are available to it, we need to package the available devices, their states, and other relevant information---i.e., the context---into a machine-parseable format. This package effectively describes the action space available to the model: the knobs it can turn, and information (e.g., which room the user is in) that might influence {\it how} it turns them. It also provides a hint about how the model should format its response. Representations of context can be complex and have been explored in the literature \cite{hua2022copi, warble21}. Since our goal is to conduct an exploratory study rather than design an end-to-end solution, we use a schema that is simple but adequate for our experimental setup. We choose JSON for structuring this data since it is the de-facto data interchange format for RESTful APIs used by many smart home devices~\cite{hue2022, nest2022, insteon2022}. Leveraging a common format is also advantageous since there is a high likelihood that the LLM has been trained on source material that contains it, which benefits the model's ability to converse in it.

\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{figs/schema.png}
    \caption{Data structures for expressing smart home device and user context in prompts to an LLM.}
    \label{fig:schema}
\end{figure}

At the top level, context is a collection of ``key, value'' pairs. There are two relevant contexts: ``user'' context that contains immutable information about the user's state, e.g., which room they are in, and ``device'' context, which contains mutable and immutable information about the devices in the home. Each top-level key in the collection of device context defines a room in the home, and within each room we define collections of devices organized by type, e.g., ``lights'', ``tvs'', etc. Within a collection of devices, we define each individual device as a collection of properties about that device, e.g., for a light we can define its ``state'' property and its ``r'', ``g'', and ``b'' color values. This overall structure is depicted in Fig.~\ref{fig:schema} and illustrated by the example in the following:

\begin{lstlisting}[language=json]
{
  "user": {
    "location": "living_room"
  }
}
\end{lstlisting}
\vspace{-.2cm}
\begin{lstlisting}[language=json]
{
  "devices": {
    "bedroom": {
      "lights": {
        "bedside_lamp": {
          "state": "off"
        }
      }
    },
    "living_room": {
      "lights": {
        "overhead": {
          "state": "on"
        },
        "lamp": {
          "state": "off"
        }
      },
      "tvs": {
        "living_room_tv": {
          "state": "off",
          "volume": 20
        }
      }
    }
  }
}
\end{lstlisting}

In this example, the user's home has two rooms---a bedroom and living room---and the user is currently located in the living room. The bedroom has one light turned off, and the living room has two lights (one turned on) and a television.

\subsection{Prompt Engineering}
Having developed a structure for storing context, we now move to the practical challenge of engineering  prompts that elicit useful responses from the model.

Our prompts consist of four segments, as follows:
\begin{itemize}
    \item \textbf{Framing.} This portion of the prompt provides direction to the conversational agent about its role in the interaction---it is being asked to make decisions as an AI that controls a smart home. We open with the phrase ``You are an AI that controls a smart home.''
    \item \textbf{Context.} This informs the agent of the user context and devices available in the environment, which scopes the space of its actions and provides a hint as to the structure of our desired response. We continue the prompt: ``Here is the state of the devices in the home, in JSON format: \{devices\} Here is information about the user: \{user\}'', where both contexts are formatted as shown earlier.
    \item \textbf{Command.} This portion inserts the user command and directs the agent to manipulate the state of devices in response, as follows: ``The user issues the command: \{command\}. Change the device state as appropriate.'' The command is written in natural language, as a user might utter to their smart assistant.
    \item \textbf{Formatting.} We close the prompt by requesting the response in JSON format so that it can be easily parsed and input to a relevant smart device API: ``Provide your response in JSON format.''
\end{itemize}

\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{figs/prompt_example.png}
    \caption{An example prompt and response from ChatGPT, demonstrating its ability to change device state in response to ambiguous user commands like ``get ready for a party''. JSON is omitted from this figure in favor of a visual depiction. }
    \label{fig:prompt_example}
\end{figure}

An example prompt with this structure and the corresponding response from ChatGPT 3.5 are depicted in Figure~\ref{fig:prompt_example}. We can see that by using the proposed context structure inside the the prompt, we are able to elicit responses from the model that contain changes to the underlying JSON that accurately reflect what a user's intent might be. In essence, GPT-3.5 is able to relate the meaning of ``party'' to the devices available, as well as alter their specific settings in desirable ways. In the next section, we use this system design to perform qualitative analysis of the model's responses.