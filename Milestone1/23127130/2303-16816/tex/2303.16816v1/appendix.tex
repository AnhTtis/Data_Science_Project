\onecolumn
\appendix
\renewcommand{\theequation}{A.\arabic{equation}} 
\renewcommand{\theProof}{A.\arabic{Proof}} 
\renewcommand{\thelemma}{A.\arabic{lemma}} 
\renewcommand{\theRemark}{A.\arabic{Remark}}
\renewcommand{\theTheorem}{A.\arabic{Theorem}}
\renewcommand{\theCorollary}{A.\arabic{Corollary}}

\subsection{Proofs}
In this section we provide the proofs of theorem \ref{thm:unbounded} and \ref{thm:bounded} under the assumptions stated in the main text. To do so we first prove a series of lemmas. 
%In this section we state, necessary lemmas with proofs, following assumptions made in main text, in order to state proofs of theorem \ref{thm:pac:altKL} and \ref{thm:pac:alt1}.
\newcommand{\Efrho}{E_{f\sim\rho}}
\newcommand{\Efpi}{E_{f\sim\pi}}

%	\begin{equation}
%	P\left (\omega\in\Omega \mid E_{\theta\sim\rho}\mathcal{L}(\theta) \leq E_{\theta\sim\rho}V(\theta)+\left (E_{\theta\sim\pi} \left ( \frac{\rho(\theta)}{\pi(\theta)} \right )^\alpha \right)^\frac{1}{\alpha}\left (E_{\theta\sim\pi}\bE \left [ (\mathcal{L}(\theta)-V(\theta))^\frac{\alpha}{\alpha-1} \right ] \right )^{\frac{\alpha-1}{\alpha}} \right )
%\end{equation} 
% with $\phi(f)=\lambda(\mathcal{L}(f)-V_N(f))$, $\lambda\in\reals,\lambda>0$ it follows

\begin{lemma} \label{lemma:etoz} For random variable $\e_g(t)\sim\mathcal{N}(0,Q_e)$, the following holds
	\begin{align*} 
		\bE[\|\e_g(t)\|_2^r]\leq \mu_{\max}(Q_e)^{\frac{r}{2}}\bE[\|\z(t)\|_2^r]\\
		\z(t)\sim \mathcal{N}(0,I),
	\end{align*}
	where $Q_e=\bE[\e_g(t)\e_g^T(t)]$, and $\mu_{\max}(Q_e)$ denotes the maximal eigen value of $Q_e$.
\end{lemma}
\begin{Proof}[Proof of Lemma \ref{lemma:etoz}]
	First, note $\z(t)=Q_e^{-\frac{1}{2}}\e_g(t)$, and 
	\begin{align*}
		\|\e_g(t)\|_2^2=\e_g^T(t)\e_g(t)=\z^T(t)Q_e^{\frac{1}{2}}Q_e^{\frac{1}{2}}\z(t)=\z^T(t)Q_e\z(t)
	\end{align*}
	therefore
	\begin{align*}
		\|\e_g(t)\|_2^2 \leq \mu_{\max}(Q_e)\|\z(t)\|_2^2\\
		\|\e_g(t)\|_2^r\leq\mu_{\max}(Q_e)^{\frac{r}{2}}\|\z(t)\|_2^r\\
		\bE[\|\e_g(t)\|_2^r]\leq\mu_{\max}(Q_e)^{\frac{r}{2}}\bE[\|\z(t)\|_2^r]\\
	\end{align*}
	Finally, note that $\z(t) \sim  \mathcal{N}(0,I)$.
\end{Proof}
\begin{lemma} \label{lemma:zMomentsSq}
	If $\z(t)\sim \mathcal{N}(0,I_m)$, then
	\begin{align*}
		\bE[\|\z(t)\|_2^r]^2\leq 4((m+r-1)!)
	\end{align*}
\end{lemma}

\begin{Proof}[Proof of Lemma \ref{lemma:zMomentsSq}]
	First, notice that the distribution of $\|\z(t)\|_2=\sqrt{\sum_{i=1}^m \z_i^2(t)}$ is chi- distribution, as such
	\begin{align}
		\bE[\|\z(t)\|_2^r]=2^{\frac{r}{2}}\dfrac{\Gamma(\frac{m+r}{2})}{\Gamma(\frac{m}{2})}
	\end{align}
	We will use mathematical induction to prove the lemma.\\
	\textbf{For $r=0$}, lemma holds, since
	\begin{align}
		\bE[\|\z(t)\|_2^0]^2=\left (2^{\frac{0}{2}}\dfrac{\Gamma(\frac{m+0}{2})}{\Gamma(\frac{m}{2})}\right )^2=1\leq 4(m-1)! 		,\quad \forall m\in\mathbb{N}.
	\end{align}
	\textbf{for $r=1$}, lemma holds, as
	\begin{align*}
		\bE[\|\z(t)\|_2^1]=2^{\frac{1}{2}}\dfrac{\Gamma(\frac{m+1}{2})}{\Gamma(\frac{m}{2})}.
	\end{align*}
	Notice that, for scalar $\x\sim\mathcal{N}(0,1)$
	\begin{align*}
		\bE[|\x|^k]=2^{\frac{k}{2}}\dfrac{\Gamma(\frac{k+1}{2})}{\sqrt{\pi}}
	\end{align*}
	It is also known that 
	\begin{align*}
		\bE[|\x|^k]=\begin{cases} (k-1)!!\sqrt{\frac{2}{\pi}},& k\text{ odd}\\ (k-1)!!,& k\text{ even} \end{cases}
	\end{align*}
	therefore,
	\begin{align*}
		2^{\frac{k}{2}}\dfrac{\Gamma(\frac{k+1}{2})}{\sqrt{\pi}}=\begin{cases} (k-1)!!\sqrt{\frac{2}{\pi}},& k\text{ odd}\\ (k-1)!!,& k\text{ even} \end{cases}
	\end{align*}
	Applying this to $k=m$ and $k=m-1$, we obtain
	\begin{align*}
		2^{\frac{m}{2}}\dfrac{\Gamma(\frac{m+1}{2})}{\sqrt{\pi}}=\begin{cases} (m-1)!!\sqrt{\frac{2}{\pi}},& m\text{ odd}\\ (m-1)!!,& m\text{ even} \end{cases}\\
		2^{\frac{m-1}{2}}\dfrac{\Gamma(\frac{m}{2})}{\sqrt{\pi}}=\begin{cases} (m-2)!!\sqrt{\frac{2}{\pi}},& (m-1)\text{ odd}, (m \text{ even})\\ (m-2)!!,& (m-1)\text{ even}, (m \text{ odd}) \end{cases}
	\end{align*}
	Now notice,
	\begin{align*}
		\bE[\|z(t)\|_2^1]=2^{\frac{1}{2}}\dfrac{\Gamma(\frac{m+1}{2})}{\Gamma(\frac{m}{2})} = \frac{ 2^{\frac{m}{2}}\dfrac{\Gamma(\frac{m+1}{2})}{\sqrt{\pi}}}{2^{\frac{m-1}{2}}\dfrac{\Gamma(\frac{m}{2})}{\sqrt{\pi}}}=\frac{(m-1)!!}{(m-2)!!}c_m\\
		c_m=\begin{cases}\sqrt{\frac{2}{\pi}} ,& m\text{ even}\\\sqrt{\frac{\pi}{2}} ,& m\text{ odd} \end{cases}
	\end{align*}
	notice that $c_m\leq 2$ for all $m$, and therefore
	\begin{align}
		\bE[\|\z(t)\|_2^1]\leq 2\frac{(m-1)!!}{(m-2)!!}\leq 2(m-1)!!
	\end{align}
	Then
	\begin{align*}
		\bE[\|\z(t)\|_2^1]^2\leq 4((m-1)!!)^2
	\end{align*}
	Note that $((m-1)!!)^2\leq m!$. We can see that by contradiction: assume that
	%\begin{align*}
		$((m-1)!!)^2\geq m !$. Notice that $m!=m!!(m-1)!!$ and hence $((m-1)!!)^2\geq m !$
		implies 
		%$((m-1)!!)^2\geq m!!(m-1)!!$
		$(m-1)!!\geq m!!$.
	%\end{align*}
	As $(m-1)!!$ must be less than $m!!$ we have a contradiction. Therefore $((m-1)!!)^2\leq m!$ holds and we have
	\begin{align*}
		\bE[\|\z(t)\|_2^1]^2\leq 4 m!.
	\end{align*}
	That is, we have shown that for $r=0$ and $r=1$ Lemma \ref{lemma:zMomentsSq} holds. \\
	 Now suppose that for all $k \geq 2$ and for all  $0\leq r \leq k$
	\begin{align}
		2^{\frac{r}{2}}\dfrac{\Gamma(\frac{m+r}{2})}{\Gamma(\frac{m}{2})}\leq 4(m+r-1)!,
		\label{pf:b2:eq-1}
	\end{align}
	We will show that \eqref{pf:b2:eq-1} holds for $r=k+1$ too.
	To this end, notice that 
	\begin{align*}
		\Gamma \left (\frac{m+k}{2} \right )=\Gamma \left(\frac{m+k-2}{2}+1 \right)=\frac{m+k-2}{2}\Gamma \left(\frac{m+k-2}{2} \right)
	\end{align*}
	Using this relation we obtain
	\begin{equation}
	\label{pf:b2:eq1}
		\begin{split}
			\left (2^{\frac{k}{2}}\dfrac{\Gamma(\frac{m+k}{2})}{\Gamma(\frac{m}{2})}\right )^2=\left ( \left ( 2^{\frac{k-2}{2}}\dfrac{\Gamma(\frac{m+k-2}{2})}{\Gamma(\frac{m}{2})} \right )\left (2\frac{m+k-2}{2} \right) \right )^2 \\
			=\left ( 2^{\frac{k-2}{2}}\dfrac{\Gamma(\frac{m+k-2}{2})}{\Gamma(\frac{m}{2})} \right )^2\left (2\frac{m+k-2}{2}  \right )^2.
		\end{split}
	\end{equation}	
	Now $k-2\in[0,k]$, so we can apply to it the induction hypothesis. That is,
	for $r=k-2$, \eqref{pf:b2:eq-1} holds, i.e., 
	\begin{align*}
		\left ( 2^{\frac{r}{2}}\dfrac{\Gamma(\frac{m+r}{2})}{\Gamma(\frac{m}{2})} \right )\leq 4(m+r-1)!=4(m+k-3)!.
	\end{align*}
	%then we have $4(m+r-1)!\leq 4(m+k-3)!$, as such currently we have 
	and therefore
	\begin{align*}
		\left (2^{\frac{k}{2}}\dfrac{\Gamma(\frac{m+k}{2})}{\Gamma(\frac{m}{2})}\right )^2\leq 4(m+k-3)! \left ( 4\frac{(m+k-2)^2}{4} \right )\\
		=4(m+k-3)!(m+k-2)(m+k-2).
	\end{align*}
	%Substituting this into \eqref{pf:b2:eq1} a
    Using $(m+k-2)\leq (m+k-1)$, it follows that 
	\begin{align*}
	 \left ( 2^{\frac{k-2}{2}}\dfrac{\Gamma(\frac{m+k-2}{2})}{\Gamma(\frac{m}{2})} \right )^2\left (2\frac{m+k-2}{2}  \right )^2 \le 
		4(m+k-3)!(m+k-2)(m+k-2)	\leq 4(m+k-1)!
	\end{align*}
	 Substituting the last inequality into \eqref{pf:b2:eq1}, it follows that
	 \eqref{pf:b2:eq-1} holds for $r=k+1$. 
\end{Proof}
\begin{lemma}\label{lemma:evenzmoments} For random variable $\z\sim\mathcal{N}(0,I_m)$, the even moments of $\|\z\|_2$ are bounded by
	\begin{align*}
		\bE[\|\z\|_2^{2r}]\leq 2^r(m+r-1)!
	\end{align*}
	\begin{Proof}[Proof of Lemma \ref{lemma:evenzmoments}]
		Clearly $\|\z\|_2$ has the chi distribution,
		\begin{align*}
			\bE[\|\z\|_2^{2r}]=2^{\frac{2r}{2}}\dfrac{\Gamma(\frac{m+2r}{2})}{\Gamma(\frac{m}{2})}=2^{r}\dfrac{\Gamma(\frac{m}{2}+r)}{\Gamma(\frac{m}{2})}
		\end{align*}
		\begin{align*}
			\Gamma\left (\frac{m}{2}+r \right )=\Gamma \left (\frac{m}{2}+(r-1) +1 \right )= \left (\frac{m}{2}+(r-1) \right )\Gamma \left (\frac{m}{2}+(r-1) \right )\\
			=\left (\frac{m}{2}+(r-1) \right )\left (\frac{m}{2}+(r-2) \right ) \dots \frac{m}{2}\Gamma\left ( \frac{m}{2} \right )
		\end{align*}
		\begin{align*}
			\bE[\|\z\|_2^{2r}]=2^r \frac{\left (\frac{m}{2}+(r-1) \right )\left (\frac{m}{2}+(r-2) \right ) \dots \frac{m}{2}\Gamma\left ( \frac{m}{2} \right )}{\Gamma\left ( \frac{m}{2} \right )}
		\end{align*}
		notice $\frac{m}{2}\leq m$, then
		\begin{align*}
			\bE[\|\z\|_2^{2r}]\leq 2^r\frac{(m+r-1)!}{m!} \leq 2^r (m+r-1)!
		\end{align*}
	\end{Proof}
\end{lemma}
Combining Lemmas (\ref{lemma:etoz} and \ref{lemma:zMomentsSq}), we obtain the following lemma.
\begin{lemma} \label{lemma:evenEmoments} Let $r\in\mathbb{N}$
	\begin{align*}
		\bE[\|\e_g(t)\|_2^{2r}]\leq \mu_{\max}(Q_e)^{r}2^r(m+r-1)!
	\end{align*}
\end{lemma}
Combining Lemmas (\ref{lemma:etoz} and \ref{lemma:evenzmoments}), we obtain the following lemma.
\begin{lemma} \label{lemma:Emoments} Let $r\in \{1,3,5,\dots\}$
	\begin{align*}
		\bE[\|\e_g(t)\|_2^r]\leq 2\mu_{\max}(Q_e)^{\frac{r}{2}}\sqrt{(m+r-1)!}
	\end{align*}
\end{lemma}

\begin{lemma}\label{lemma:stationary4thMoment} Let $\z(t)$ be any stationary process, and $r\in\mathbb{N}$, then for a stochastic process $\mathbf{s}(t)=\sum_{k=0}^\infty \alpha_k \z(t-k),$
with $\sum_{k=0}^\infty \|\alpha_k\|\leq +\infty$, the following holds
\begin{equation}
    \bE[\|\mathbf{s}(t)\|^r]\leq \left ( \sum_{k=0}^\infty \| \alpha_k\| \right )^r \bE[\|\z(t)\|^r]
\end{equation}
\end{lemma}
\begin{Proof}[of Lemma \ref{lemma:stationary4thMoment}]
    \newcommand{\m}{r} %in case proof holds for any moment
    \begin{multline}
        \bE[\|\mathbf{s}(t)\|^\m]=\bE \left [\|\sum_{k=0}^\infty \alpha_k \z(t-k)\|^\m \right ] \leq \bE\left [\left (\sum_{k=0}^\infty \|\alpha_k\| \|\z(t-k)\| \right )^\m \right ]\\
        =\bE\left [ \sum_{k_1=0}^\infty \dots \sum_{k_\m=0}^\infty \left ( \prod_{i=1}^\m \|\alpha_{k_i}\| \prod_{i=0}^\m \|\z(t-k_i)\| \right ) \right ] =  \sum_{k_1=0}^\infty \dots \sum_{k_\m=0}^\infty \left ( \prod_{i=1}^\m \|\alpha_{k_i}\| \bE\left [ \prod_{i=0}^\m  \|\z(t-k_i)\|  \right ] \right )
    \end{multline}
    By the inequality of arithmetic and geometric means
    \begin{equation}
        \prod_{i=0}^\m  \|\z(t-k_i)\| \leq \frac{1}{\m}\sum_{i=1}^\m \|\z(t-k_i)\|^\m
    \end{equation}
    then
    \begin{equation}
        \bE\left [ \prod_{i=0}^\m  \|\z(t-k_i)\|  \right ] \leq \bE\left [ \frac{1}{\m}\sum_{i=1}^\m \|\z(t-k_i)\|^\m  \right ] =  \frac{1}{\m}\sum_{i=1}^\m \bE\left [\|\z(t-k_i)\|^\m  \right ]
    \end{equation}
    By assumption $\z(t)$ is stationary, therefore
    $\bE[\|\z(t-k_i)\|^\m]=\bE[\|\z(t)\|^\m]$, i.e. $\bE[\|\z(t)\|^\m]$ does not depend on $k_i$, and so we obtain the statement of the lemma
    \begin{equation}
         \bE[\|\mathbf{s}(t)\|^\m] \leq \bE[\|\z(t)\|^\m] \sum_{k_1=0}^\infty \dots \sum_{k_\m=0}^\infty \left ( \prod_{i=1}^\m \|\alpha_{k_i}\|  \right ) = \left ( \sum_{k=0}^\infty \|\alpha_k\| \right )^\m\bE[\|\z(t)\|^\m]
    \end{equation}
\end{Proof}

\begin{lemma}\label{lemma:E|zinf-zf|^r}
Let $r\in\mathbb{N}$, then with notation as above the following holds
    \begin{align}
        \bE[\|\z_\infty(t)-\z_f(t)\|^r] \leq \hat{\gamma}^{rt}\left (  \frac{\hat{M} \| \hat{C} \| \|\hat{B}\|}{1-\hat{\gamma}} \right )^r \bE \left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix} \right \|^r \right ] 
    \end{align}
\end{lemma}
\begin{Proof}[of Lemma \ref{lemma:E|zinf-zf|^r}]
    Notice that the process $\mathbf{s}(t)=\z_\infty(t)-\z_f(t)=\hat{\y}_f(t|0)-\hat{\y}_f(t)$ can be expressed as:
    \begin{align}
        \mathbf{s}(t)&=\left (\sum_{k=1}^t \hat{C}\hat{A}^{k-1}\hat{B}\w(t-k)+\hat{D}\w(t) \right ) - \left ( \sum_{k=1}^\infty \hat{C}\hat{A}^{k-1}\hat{B}\w(t-k)+\hat{D}\w(t) \right)\\
        &=-\sum_{k=t+1}^\infty \hat{C}\hat{A}^{k-1}\hat{B}\w(t-k) 
    \end{align}
    in the case of $\w(t)=\mathbf{u}(t)$
    \begin{align}
        \mathbf{s}(t)=-\sum_{k=t+1}^\infty \hat{C}\hat{A}^{k-1}\hat{B}\mathbf{u}(t-k) = \sum_{k=0}^\infty \alpha_{k,t}(s,1) \begin{bmatrix} \y(t-k) \\ \mathbf{u}(t-k) \end{bmatrix}
    \end{align}
    with
    \begin{align}
        \alpha_{k,t}(s,1)=\begin{cases}\begin{bmatrix} 0 & -\hat{C}\hat{A}^{k-1}\hat{B} \end{bmatrix}, & k\geq t+1 \\ 0,& k<t+1 \end{cases}
    \end{align}
    In the case of $\w(t)=\begin{bmatrix} \y^T(t) & \mathbf{u}^T(t) \end{bmatrix}^T$
    \begin{align}
        \mathbf{s}(t)=-\sum_{k=t+1}^\infty \hat{C}\hat{A}^{k-1}\hat{B}\begin{bmatrix} \y(t-k) \\ \mathbf{u}(t-k) \end{bmatrix} = \sum_{k=0}^\infty \alpha_{k,t}(s,2) \begin{bmatrix} \y(t-k) \\ \mathbf{u}(t-k) \end{bmatrix}
    \end{align}
    with
    \begin{align}
        \alpha_{k,t}(s,2)=\begin{cases} -\hat{C}\hat{A}^{k-1}\hat{B}, & k\geq t+1 \\ 0,& k<t+1 \end{cases}
    \end{align}
    Notice that in both cases we can upper-bound with the same quantity $\|\alpha_{k,t}(s,1)\|\leq \|\alpha_{k,t}(s)\|$, and $\|\alpha_{k,t}(s,2)\|\leq \|\alpha_{k,t}(s)\|$ with
    \begin{align}
        \|\alpha_{k,t}(s)\|=\begin{cases} \|\hat{C}\hat{A}^{k-1}\hat{B}\|,& k\geq t+1 \\ 0, & k<t+1 \end{cases}
    \end{align}
    Since $\w(t)$ is a stationary process, and by assumption predictors are stable, i.e. all eigenvalues of $\hat{A}$ are inside unit circle, thus $\sum_{k=0}^\infty \|\alpha_{k,t}(s)\| \leq +\infty, \forall t\geq0$, we apply Lemma \ref{lemma:stationary4thMoment}, and obtain
    \begin{align}
        \bE[\|\mathbf{s}(t)\|^r]=\bE[\|\z_\infty(t)-\z_f(t)\|^r]&\leq \left ( \sum_{k=0}^\infty \|\alpha_{k,t}(s)\| \right )^r \bE\left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix} \right \|^r \right ]\\
        &\leq \left ( \sum_{k=t+1}^\infty \|\hat{C}\| \|\hat{A}^{k-1}\| \| \hat{B}\| \right )^r \bE\left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix} \right \|^r \right ]
    \end{align}
    with $\|\hat{A}^k\|\leq \hat{M}\hat{\gamma}^k$, for some $M>1$ and $\hat{\gamma}\in [\hat{\gamma}^*,1)$, where $\hat{\gamma}^*$ is the spectral radius of $\hat{A}$, then with a sum of geometric series, we get the statement of the lemma
    \begin{align}
        \bE[\|\z_\infty(t)-\z_f(t)\|^r] \leq \left ( \hat{M} \| \hat{C} \| \|\hat{B}\| \frac{\hat{\gamma}^t}{1-\hat{\gamma}} \right )^r \bE\left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix} \right \|^r \right ].
    \end{align}

\end{Proof}

\begin{lemma}\label{lemma:E|z_inf|^r} Let $r\in\mathbb{N}$, then with notation as above the following holds
    \begin{align}
        \bE \left [ \|\z_\infty(t)\|^r \right ] &\leq \left (1+\|\hat{D}\|+ \frac{\hat{M}\|\hat{B}\|\|\hat{C}\|}{1-\hat{\gamma}} \right )^r \bE\left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix}\right \|^r \right ]
    \end{align}
\end{lemma}
\begin{Proof}[of Lemma \ref{lemma:E|z_inf|^r}]
    Notice that $\z_\infty(t)=\y(t)-\hat{\y}_f(t)$ can be expressed as

    In the case of $\w(t)=\mathbf{u}(t)$, 
    \begin{align}
        \z_\infty(t)=\y(t)-\sum_{k=1}^\infty \hat{C}\hat{A}^{k-1}\hat{B}\mathbf{u}(t-k)-\hat{D}\mathbf{u}(t) = \sum_{k=0}^\infty \alpha_k(\z_\infty,1) \begin{bmatrix} \y(t-k) \\ \mathbf{u}(t-k) \end{bmatrix}
    \end{align}
    with 
    \begin{align}
        \alpha_k(\z_\infty,1) = \begin{cases} \begin{bmatrix} I & -\hat{D}\end{bmatrix},& k=0 \\ \begin{bmatrix} 0 & -\hat{C}\hat{A}^{k-1}\hat{B}\end{bmatrix}, & k>0  \end{cases}
    \end{align}
    in the case of $\w(t)=[\y^T(t), \mathbf{u}^T(t)]^T$
    \begin{align}
        \z_\infty(t)=\y(t)-\sum_{k=1}^\infty \hat{C}\hat{A}^{k-1}\hat{B}\begin{bmatrix} \y(t-k)\\ \mathbf{u}(t-k)\end{bmatrix} -\hat{D}\begin{bmatrix} \y(t)\\ \mathbf{u}(t)\end{bmatrix}=\sum_{k=0}^\infty \alpha_k(\z_\infty,2) \begin{bmatrix} \y(t-k) \\ \mathbf{u}(t-k) \end{bmatrix}
    \end{align}
    Recall that in this case, we assume $\hat{D}=[0,\hat{D}_\mathbf{u}]$, note that $\|\hat{D}\|=\|\hat{D}_\mathbf{u}\|$ and thus
    \begin{align}
        \alpha_k(\z_\infty,2) = \begin{cases} \begin{bmatrix} I & -\hat{D}_\mathbf{u}\end{bmatrix},& k=0 \\ -\hat{C}\hat{A}^{k-1}\hat{B}, & k>0  \end{cases}
    \end{align}
    Note that in both cases we can upper-bound with the same quantity, i.e. $\|\alpha_k(\z_\infty)\|\leq \|\alpha_k(\z_\infty)\|$, and $\|\alpha_k(\z_\infty,2)\|\leq \|\alpha_k(\z_\infty)\|$, with
    \begin{align}
        \|\alpha_k(\z_\infty)\|\leq \begin{cases} 1 + \|\hat{D}\|,& k=0\\
        \|\hat{C}\hat{A}^{k-1}\hat{B}\|,& k>0 \end{cases} \label{eq:alpha_k(z_inf)}
    \end{align}
    Since, in both cases, $\sum_{k=0}^\infty \|\alpha_k(\z_\infty)\|\leq +\infty$, due to stability of the predictor, and $\begin{bmatrix} \y^T(t)& \mathbf{u}^T(t) \end{bmatrix}^T$ is stationary, we apply Lemma \ref{lemma:stationary4thMoment}, to both cases, and upper bound by \eqref{eq:alpha_k(z_inf)}, to obtain an upper-bound for both cases:
    \begin{align}
        \bE \left [ \|\z_\infty(t)\|^r \right ] &\leq \left (\sum_{k=0}^\infty \|\alpha_k(\z_\infty,1)\| \right )^4 \bE\left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix}\right \|^r \right ]\\
        &\leq\left (\|I\|+\|\hat{D}\|+\sum_{k=1}^\infty \|\hat{C}\hat{A}^{k-1}\hat{B}\| \right )^r \bE\left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix}\right \|^r \right ]\\
        &\leq \left (1+\|\hat{D}\|+ \frac{\hat{M}\|\hat{B}\|\|\hat{C}\|}{1-\hat{\gamma}} \right )^r \bE\left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix}\right \|^r \right ]
    \end{align}

\end{Proof}

\begin{lemma}\label{lemma:E|z_f|^r} Let $r\in\mathbb{N}$, then with notation as above, the following holds
    \begin{align}
        \bE \left [ \|\z_f(t)\|^r \right ] &\leq \left ( \|I\| + \|\hat{D}\| +  \frac{\hat{M}\|\hat{B}\|\|\hat{C}\|}{1-\hat{\gamma}} \right )^r \bE\left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix}\right \|^r \right ]
    \end{align}
\end{lemma}

\begin{Proof}[of Lemma \ref{lemma:E|z_f|^r}]
    Notice that the process $\z_f(t)=\y(t)-\hat{\y}(t|0)$ can be expressed as:\\
    In the case of $\w(t)=\mathbf{u}(t)$
    \begin{align}
        \z_f(t)= \y(t)-\sum_{k=1}^t \hat{C}\hat{A}^{k-1}\hat{B}\mathbf{u}(t-k) - \hat{D}\mathbf{u}(t) = \sum_{k=0}^\infty \alpha_k(\z_f,1) \begin{bmatrix} \y(t-k) \\ \mathbf{u}(t-k) \end{bmatrix}
    \end{align}
    with
    \begin{equation}
        \alpha_k(\z_f,1)=\begin{cases} \begin{bmatrix}I&-\hat{D} \end{bmatrix},& k=0 \\ \begin{bmatrix} 0 & -\hat{C}\hat{A}^{k-1}\hat{B} \end{bmatrix}, & 0<k\leq t \\ 0,& k>t  \end{cases}
    \end{equation}
    In the case of $\w(t)=[\y^T(t), \mathbf{u}^T(t)]^T$, 
    \begin{align}
        \z_f(t)= \y(t)-\sum_{k=1}^t \hat{C}\hat{A}^{k-1}\hat{B}\begin{bmatrix} \y(t-k) \\ \mathbf{u}(t-k) \end{bmatrix} - \hat{D}\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix} = \sum_{k=0}^\infty \alpha_k(\z_f,2) \begin{bmatrix} \y(t-k) \\ \mathbf{u}(t-k) \end{bmatrix}
    \end{align}
    with
    \begin{equation}
        \alpha_k(\z_f,2)=\begin{cases} \begin{bmatrix}I&0\end{bmatrix} -\hat{D},& k=0 \\ -\hat{C}\hat{A}^{k-1}\hat{B}, & 0<k\leq t \\ 0,& k>t  \end{cases}
    \end{equation}
    Note that for both cases we can upper-bound by the same quantity $\|\alpha_k(\z_f,1)\|\leq \|\alpha_k(\z_f)\|$, and $\|\alpha_k(\z_f,2)\|\leq \|\alpha_k(\z_f)\|$, with
    \begin{align}
        \|\alpha_k(\z_f)\|=\begin{cases} 1+\|\hat{D}\|,& k=0\\ \|\hat{C}\hat{A}^{k-1}\hat{B}\|,& 0<k\leq t \\
        0,& k>t \end{cases}
    \end{align}
    Since by assumption predictors are stable, we apply Lemma \ref{lemma:stationary4thMoment} and obtain
    \begin{align}
        \bE \left [ \|\z_f(t)\|^r \right ] &\leq \left ( \sum_{k=0}^\infty \|\alpha_k(\z_f)\| \right )^r \bE\left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix}\right \|^r \right ]\\
        &\leq \left ( \|I\| + \|\hat{D}\| + \sum_{k=1}^t \|\hat{C}\hat{A}^{k-1}\hat{B}\| \right )^r \bE\left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix}\right \|^r \right ]\\
        &\leq \left ( \|I\| + \|\hat{D}\| + \hat{M}\|\hat{B}\|\|\hat{C}\| \sum_{k=1}^t \hat{\gamma}^{k-1} \right )^r \bE\left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix}\right \|^r \right ]\\
        &= \left ( \|I\| + \|\hat{D}\| + \hat{M}\|\hat{B}\|\|\hat{C}\| \frac{1-\hat{\gamma}^t}{1-\hat{\gamma}} \right )^r \bE\left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix}\right \|^r \right ]
    \end{align}
    Notice that $\hat{\gamma}^t>0, \forall t$, thus we obtain the statement of the lemma
    \begin{align}
        \bE \left [ \|\z_f(t)\|^r \right ] &\leq \left ( \|I\| + \|\hat{D}\| +  \frac{\hat{M}\|\hat{B}\|\|\hat{C}\|}{1-\hat{\gamma}} \right )^r \bE\left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix}\right \|^r \right ].
    \end{align}
\end{Proof}

\begin{lemma}\label{lemma:E|yw|^r} Let $r\in\mathbb{N}$, then with notation as above, the following holds.
    \begin{align}
        \bE\left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix}\right \|^r \right ] \leq \|\Sigma_{gen}\|_{\ell_1}^r G_r(\e_g)
    \end{align}
    with
    \begin{align}
        \|\Sigma_{gen}\|_{\ell_1}&=\|I\|+\sum_{k=1}^\infty \|C_gA_g^{k-1}K_g\|\\
        G_r(\e_g)&=\begin{cases} 2^{\frac{r}{2}}\mu_{\max}(Q_e)^{\frac{r}{2}}(n_u+n_y+\frac{r}{2}-1)!,& r \text{ is even}\\ 2\mu_{\max}(Q_e)^{\frac{r}{2}}\sqrt{(n_u+n_y+r-1)!},& r \text{ is odd} \end{cases} 
    \end{align}
\end{lemma}

\begin{Proof}[of Lemma \ref{lemma:E|yw|^r}]
    Note that $\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix}$ can be expressed as
    \begin{align}
        \begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix} = \sum_{k=1}^\infty C_gA_g^{k-1}K_g\e_g(t-k) + \e_g(t) = \sum_{k=0}^\infty \alpha_k(\y,\w)\e_g(t-k)
    \end{align}
    with $\e(t)$ stationary, we apply Lemma \ref{lemma:stationary4thMoment} to get
    \begin{align}
        \bE\left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix}\right \|^r \right ] \leq \left ( \sum_{k=0}^\infty \|\alpha_k(\y,\w)\| \right )^r \bE\left [ \|\e_g(t)\|^r \right]
    \end{align}
Let us denote $\|\Sigma_{gen}\|_{\ell_1}=\sum_{k=0}^\infty \|\alpha_k(\y,\w)\|$, the $\ell_1$ norm of the generative system. Furthermore we can apply Lemma \ref{lemma:evenEmoments} and Lemma \ref{lemma:Emoments} to obtain, 
	\begin{align*}
		\bE[\|\e_g(t)\|_2^{r}]\leq G_r(\e_g)=\begin{cases} 2^{\frac{r}{2}}\mu_{\max}(Q_e)^{\frac{r}{2}}(n_u+n_y+\frac{r}{2}-1)!,& r \text{ is even}\\ 2\mu_{\max}(Q_e)^{\frac{r}{2}}\sqrt{(n_u+n_y+r-1)!},& r \text{ is odd} \end{cases} 
	\end{align*}
 with this we have the statement of the lemma. 
\end{Proof}


\begin{lemma} \label{lemma:(a+b)^2r} Let $r\in\mathbb{N}$, and $r\geq0$, then for $a,b\in\reals$ the following holds
    \begin{align}
        (a+b)^{2r} \leq 2^{2r-1}a^{2r}+2^{2r-1}b^{2r}
    \end{align}
\end{lemma}
\begin{Proof}[of Lemma \ref{lemma:(a+b)^2r}]
    \begin{align}
        (a+b)^{2r} = 2^{2r}\frac{1}{2^{2r}}(a+b)^{2r}= 2^{2r} \left (\frac{1}{2}(a+b) \right )^{2r}
    \end{align}
    since $\phi(x)=x^{2r}$ is convex for $r\geq 0$, we have by definition of convexity
    \begin{align}
        \left (\frac{1}{2}(a+b) \right )^{2r}=\phi\left (\frac{a+b}{2} \right )\leq \frac{1}{2} \phi(a) + \frac{1}{2}\phi(b)
    \end{align}
    thus we obtain the statement of the lemma
    \begin{align}
        (a+b)^{2r}\leq \frac{2^{2r}}{2} (a^{2r}+b^{2r}) =  2^{2r-1}(a^{2r}+b^{2r})
    \end{align}
\end{Proof}

\begin{lemma} \label{lemma:moments_|V-Lhat|} Let $r\in\mathbb{N} $, then with notation as above, the following holds
    \begin{align}
        \bE[\|V_N(f)-\hat{\mathcal{L}}_N(f)\|^r] \leq \frac{(n_u+n_y+r-1)!}{\sqrt{N}} \left ( 4\bar{G}_{gen}  \bar{G}_f(f)  \right )^r
    \end{align}
    with 
    \begin{align}
        \bar{G}_f(f)&=\left (1+\|\hat{D}\|+ \frac{\hat{M}\|\hat{B}\|\|\hat{C}\|}{1-\hat{\gamma}} \right ) \frac{\hat{M}\|\hat{C}\| \|\hat{B}\|}{(1-\hat{\gamma})^\frac{3}{2}} \\
        \bar{G}_{gen}&=\|\Sigma_{gen}\|_{\ell_1}^{2} \mu_{\max}(Q_e)
    \end{align}
\end{lemma}

\begin{Proof}
        with $\z_\infty(t)=\y(t)-\hat{\y}_f(t)$, and $\z_f(t)=\y(t)-\hat{\y}_f(t|0)$, we start by applying triangle inequalities
    \begin{multline}
        \bE[\|V_N(f)-\hat{\mathcal{L}}_N(f)\|^r] = \bE \left [\left | \frac{1}{N}\sum_{t=0}^{N-1} \|\z_\infty(t)\|^2-\|\z_f(t)\|^2   \right |^r \right ] \leq \bE \left [ \left (  \frac{1}{N}\sum_{t=0}^{N-1} \left | \|\z_\infty(t)\|^2-\|\z_f(t)\|^2   \right | \right )^r \right ]
    \end{multline}
    \begin{align}
        \bE[\|V_N(f)-\hat{\mathcal{L}}_N(f)\|^r] \leq \frac{1}{N^r} \sum_{t_1=0}^{N-1} \dots \sum_{t_r=0}^{N-1} \bE \left [  \prod_{j=1}^r \left | \|\z_\infty(t_j)\|^2-\|\z_f(t_j)\|^2 \right |\right ]
    \end{align}
    Now using the fact that $|a^2-b^2|=|(a-b)(a+b)| = |a-b|(a+b)$, since $a,b\geq 0$, we get
    \begin{align}
        \bE[\|V_N(f)-\hat{\mathcal{L}}_N(f)\|^r] \leq \frac{1}{N^r} \sum_{t_1=0}^{N-1} \dots \sum_{t_r=0}^{N-1} \bE \left [  \prod_{j=1}^r \left | \|\z_\infty(t_j)\|-\|\z_f(t_j)\| \right |\left ( \|\z_\infty(t_j)\|+\|\z_f(t_j)\| \right ) \right ]
    \end{align}
    We apply Cauchy-Schwarz, i.e. $\bE[XY]\leq |\bE[XY]| \leq \sqrt{\bE[X^2]} \sqrt{\bE[Y^2]}$, with $X=\prod_{j=1}^r \left | \|\z_\infty(t_j)\|-\|\z_f(t_j)\| \right |$, and $Y=\prod_{j=1}^r \left ( \|\z_\infty(t_j)\|+\|\z_f(t_j)\| \right )$, 
    \begin{align}
        \bE[\|V_N(f)-\hat{\mathcal{L}}_N(f)\|^r] \leq \frac{1}{N^r} \sum_{t_1=0}^{N-1} \dots \sum_{t_r=0}^{N-1} \sqrt{\bE \left [  \prod_{j=1}^r \left | \|\z_\infty(t_j)\|-\|\z_f(t_j)\| \right |^2 \right ] } \sqrt{\bE \left [ \prod_{j=1}^r \left ( \|\z_\infty(t_j)\|+\|\z_f(t_j)\| \right )^2 \right ]} \label{eq:ASDFH}
    \end{align}
    For now let's focus on $\bE \left [  \prod_{j=1}^r \left | \|\z_\infty(t_j)\|-\|\z_f(t_j)\| \right |^2 \right ]$, by applying reverse triangle inequality we obtain
    \begin{align}
        \bE \left [  \prod_{j=1}^r \left | \|\z_\infty(t)\|-\|\z_f(t)\| \right |^2 \right ] \leq \bE \left [  \prod_{j=1}^r  \|\z_\infty(t)-\z_f(t)\|^2 \right ]
    \end{align}
    now we apply the inequality of arithmetic-geometric means
    \begin{align}
        \bE \left [  \prod_{j=1}^r  \|\z_\infty(t)-\z_f(t)\|^2 \right ] \leq \frac{1}{r}\sum_{j=1}^r \bE[\|\z_\infty(t)-\z_f(t) \|^{2r}]
    \end{align}
    by applying Lemma \ref{lemma:E|zinf-zf|^r}, we obtain the first term
    \begin{align}
        \bE \left [  \prod_{j=1}^r \left | \|\z_\infty(t_j)\|-\|\z_f(t_j)\| \right |^2 \right ]  \leq  \left (\frac{\hat{M}\|\hat{C}\| \|\hat{B}\|}{1-\hat{\gamma}} \right )^{2r} \bE \left [ \left \| \begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix} \right \|^{2r} \right ] \frac{1}{r} \sum_{j=1}^r \hat{\gamma}^{2rt_j} \label{eq:aslkjgdsaf}
    \end{align}
    Now for the second term $\bE \left [ \prod_{j=1}^r \left ( \|\z_\infty(t_j)\|+\|\z_f(t_j)\| \right )^2 \right ]$, we apply the inequality of arithmetic-geometric means
    \begin{align}
        \bE \left [ \prod_{j=1}^r \left ( \|\z_\infty(t_j)\|+\|\z_f(t_j)\| \right )^2 \right ] \leq \frac{1}{r} \sum_{j=1}^r \bE\left [ \left ( \|\z_\infty(t_j)\|+\|\z_f(t_j)\| \right )^{2r}\right ]
    \end{align}
    By Lemma \ref{lemma:(a+b)^2r}, we obtain
    \begin{align}
        \frac{1}{r} \sum_{j=1}^r \bE\left [ \left ( \|\z_\infty(t_j)\|+\|\z_f(t_j)\| \right )^{2r}\right ] \leq \frac{2^{2r-1}}{r} \sum_{j=1}^r  \left ( \bE\left [ \|\z_\infty(t_j)\|^{2r} \right] + \bE\left [ \|\z_f(t_j)\|^{2r} \right ] \right )
    \end{align}
    By Lemma \ref{lemma:E|z_inf|^r} and Lemma \ref{lemma:E|z_f|^r}, we obtain
    \begin{align}
         \frac{2^{2r-1}}{r} \sum_{j=1}^r  \left ( \bE\left [ \|\z_\infty(t_j)\|^{2r} \right] + \bE\left [ \|\z_f(t_j)\|^{2r} \right ] \right ) &\leq \frac{2^{2r}}{r} \sum_{j=1}^r \left (1+\|\hat{D}\|+ \frac{\hat{M}\|\hat{B}\|\|\hat{C}\|}{1-\hat{\gamma}} \right )^{2r} \bE\left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix}\right \|^{2r} \right ]\\
         &=2^{2r} \left (1+\|\hat{D}\|+ \frac{\hat{M}\|\hat{B}\|\|\hat{C}\|}{1-\hat{\gamma}} \right )^{2r} \bE\left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix}\right \|^{2r} \right ] \label{eq:ASDGDSFHG}
    \end{align}
    Now taking \eqref{eq:ASDGDSFHG} and \eqref{eq:aslkjgdsaf} back to \eqref{eq:ASDFH}, we have

    \begin{multline}
        \bE[\|V_N(f)-\hat{\mathcal{L}}_N(f)\|^r] \leq \frac{1}{N^r} \sum_{t_1=0}^{N-1} \dots \sum_{t_r=0}^{N-1} \sqrt{\bE \left [  \prod_{j=1}^r \left | \|\z_\infty(t_j)\|-\|\z_f(t_j)\| \right |^2 \right ] } \sqrt{\bE \left [ \prod_{j=1}^r \left ( \|\z_\infty(t_j)\|+\|\z_f(t_j)\| \right )^2 \right ]} \\
        \leq \frac{1}{N^r} \sum_{t_1=0}^{N-1} \dots \sum_{t_r=0}^{N-1} \sqrt{\left (\frac{\hat{M}\|\hat{C}\| \|\hat{B}\|}{1-\hat{\gamma}} \right )^{2r} \bE \left [ \left \| \begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix} \right \|^{2r} \right ] \frac{1}{r} \sum_{j=1}^r \hat{\gamma}^{2rt_j}} \\
        \cdot \sqrt{2^{2r} \left (1+\|\hat{D}\|+ \frac{\hat{M}\|\hat{B}\|\|\hat{C}\|}{1-\hat{\gamma}} \right )^{2r} \bE\left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix}\right \|^{2r} \right ] }
    \end{multline}
    \begin{multline}
        \bE[\|V_N(f)-\hat{\mathcal{L}}_N(f)\|^r] \leq 2^{r} \left (1+\|\hat{D}\|+ \frac{\hat{M}\|\hat{B}\|\|\hat{C}\|}{1-\hat{\gamma}} \right )^{r} \left (\frac{\hat{M}\|\hat{C}\| \|\hat{B}\|}{1-\hat{\gamma}} \right )^{r} \bE\left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix}\right \|^{2r} \right ] \\
        \cdot \frac{1}{N^r} \sum_{t_1=0}^{N-1} \dots \sum_{t_r=0}^{N-1}\sqrt{\frac{1}{r} \sum_{j=1}^r \hat{\gamma}^{2rt_j}}
    \end{multline}
    Note that we can write
    \begin{align}
        \frac{1}{N^r} \sum_{t_1=0}^{N-1} \dots \sum_{t_r=0}^{N-1}\sqrt{\frac{1}{r} \sum_{j=1}^r \hat{\gamma}^{2rt_j}} = \frac{1}{N^r} \sum_{t_1=0}^{N-1} \dots \sum_{t_r=0}^{N-1} \phi(\frac{1}{r} \sum_{j=1}^r \hat{\gamma}^{2rt_j})
    \end{align}
    thus we can apply Jensen's inequality for concave function $\phi(x)=\sqrt{x}$, i.e. $\phi \left (\frac{1}{\|S\|}\sum_{i\in S} x_i\right ) \geq \frac{1}{\|S\|} \sum_{i\in S} \phi (x_i)$, thus we obtain
    \begin{align}
        \frac{1}{N^r} \sum_{t_1=0}^{N-1} \dots \sum_{t_r=0}^{N-1}\sqrt{\frac{1}{r} \sum_{j=1}^r \hat{\gamma}^{2rt_j}} \leq \sqrt{\frac{1}{N^r} \sum_{t_1=0}^{N-1} \dots \sum_{t_r=0}^{N-1}\frac{1}{r} \sum_{j=1}^r \hat{\gamma}^{2rt_j}}
    \end{align}
    Now by commuting the sums we get
    \begin{align}
        \sqrt{\frac{1}{N^r} \sum_{t_1=0}^{N-1} \dots \sum_{t_r=0}^{N-1}\frac{1}{r} \sum_{j=1}^r \hat{\gamma}^{2rt_j}} = \sqrt{\frac{1}{r} \sum_{j=1}^r \frac{1}{N^r} \sum_{t_1=0}^{N-1} \dots \sum_{t_r=0}^{N-1} \hat{\gamma}^{2rt_j}}
    \end{align}
    now notice that $\hat{\gamma}^{2rt_j}$ only depend on one sum, for which we can use the sum of geometric series, after which the same term will be repeated $N^{r-1}$ times, therefore
    \begin{align}
        \sqrt{\frac{1}{r} \sum_{j=1}^r \frac{1}{N^r} \sum_{t_1=0}^{N-1} \dots \sum_{t_r=0}^{N-1} \hat{\gamma}^{2rt_j}} = \sqrt{\frac{1}{r}\sum_{j=1}^r \frac{N^{r-1}}{N^r} \frac{1-\hat{\gamma}^{2rN}}{1-\hat{\gamma}^{2r}} } =  \frac{1}{\sqrt{N}} \sqrt{\frac{1-\hat{\gamma}^{2rN}}{1-\hat{\gamma}^{2r}}}
    \end{align}
    since $\hat{\gamma}^{2rN}\geq0$, and $(1-\hat{\gamma})^{\frac{r}{2}}\leq (1-\hat{\gamma}^{2r})^\frac{1}{2}$, since
    \begin{align}
        (1-\hat{\gamma})^{\frac{r}{2}}&\leq \left ( (1-\hat{\gamma}^{r})(1+\hat{\gamma}^{r}) \right )^\frac{1}{2}\\
        1&\leq (1+\hat{\gamma}^{r})
    \end{align}
    we obtain
    \begin{align}
        \bE[\|V_N(f)-\hat{\mathcal{L}}_N(f)\|^r] \leq \frac{2^{r}}{\sqrt{N}} \left (1+\|\hat{D}\|+ \frac{\hat{M}\|\hat{B}\|\|\hat{C}\|}{1-\hat{\gamma}} \right )^{r} \left (\frac{\hat{M}\|\hat{C}\| \|\hat{B}\|}{(1-\hat{\gamma})^\frac{3}{2}} \right )^{r} \bE\left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix}\right \|^{2r} \right ] \label{eq:moments_|V-Lhat|_pre_yw}
    \end{align}
    We can apply Lemma \ref{lemma:E|yw|^r}, to get
    \begin{align}
        \bE\left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix}\right \|^{2r} \right ] \leq \|\Sigma_{gen}\|_{\ell_1}^{2r} G_{2r}(\e_g)
    \end{align}
    since $2r$ is always even, then 
    \begin{align}
        G_{2r}(\e_g) = 2^r\mu_{\max}(Q_e)^{r}(n_u+n_y+r-1)!
    \end{align}
    and with this we obtain the statement of the lemma
    \begin{multline}
        \bE[\|V_N(f)-\hat{\mathcal{L}}_N(f)\|^r] \leq \frac{2^{2r}}{\sqrt{N}} \left (1+\|\hat{D}\|+ \frac{\hat{M}\|\hat{B}\|\|\hat{C}\|}{1-\hat{\gamma}} \right )^{r} \left (\frac{\hat{M}\|\hat{C}\| \|\hat{B}\|}{(1-\hat{\gamma})^\frac{3}{2}} \right )^{r} \\
        \cdot \|\Sigma_{gen}\|_{\ell_1}^{2r} \mu_{\max}(Q_e)^{r}(n_u+n_y+r-1)!  
    \end{multline}
    with some algebraic manipulation we get
    \begin{multline}
        \bE[\|V_N(f)-\hat{\mathcal{L}}_N(f)\|^r] \leq \frac{(n_u+n_y+r-1)!}{\sqrt{N}} \left ( 4\left (1+\|\hat{D}\|+ \frac{\hat{M}\|\hat{B}\|\|\hat{C}\|}{1-\hat{\gamma}} \right ) \frac{\hat{M}\|\hat{C}\| \|\hat{B}\|}{(1-\hat{\gamma})^\frac{3}{2}}   \|\Sigma_{gen}\|_{\ell_1}^{2} \mu_{\max}(Q_e) \right )^r
    \end{multline}
\end{Proof}


\begin{lemma} \label{lemma:mgf(Vn-hatL)} With notation as above for $0<\lambda< \frac{1}{4 n_w \bar{G}_{gen}  \bar{G}_f(f)}$ following holds
    \begin{align}
        \bE[e^{\lambda|V_N(f)-\hat{\mathcal{L}}_N(f)|}]\leq 1+ \frac{(n_y+n_u)!}{\sqrt{N}} \frac{4 \lambda \bar{G}_{gen}  \bar{G}_f(f)}{1-4 \lambda (n_y+n_u)\bar{G}_{gen}  \bar{G}_f(f)}
    \end{align}
\end{lemma}
\begin{Proof}[of Lemma \ref{lemma:mgf(Vn-hatL)}]
    with $X=\lambda | V_N(f) - \hat{\mathcal{L}}_N(f)|$
    \begin{align}
        \bE[e^{\lambda(V_N(f)-\hat{\mathcal{L}}_N(f))}] = 1+\sum_{r=1}^\infty \frac{\lambda^r}{r!} \bE[|V_N(f)-\hat{\mathcal{L}}_N(f)|^r] \leq 1+ \sum_{r=1}^\infty \frac{\lambda^r}{r!} \frac{(n_u+n_y+r-1)!}{\sqrt{N}} \left ( 4\bar{G}_{gen}  \bar{G}_f(f)  \right )^r
    \end{align}
    Furthermore, with $n_w=n_u+n_y$
    \begin{align*}
        \frac{(n_w+r-1)!}{r!}=n_w!\frac{n_w+1}{2}\frac{n_w+2}{3}\dots \frac{n_w+r-1}{r}
    \end{align*}
    and as $\frac{n_w+r-1}{r}\leq n_w$, for all $r\geq 1$, then
    \begin{align*}
        \frac{(n_w+r-1)!}{r!}\leq n_w!\left (n_w \right )^{r-1} = n_w!\frac{\left (n_w \right )^{r}}{n_w}		= \frac{n_w!}{n_w}\left (n_w \right )^r=(n_w-1)!(n_w)^r.
    \end{align*}
    this allows us to write
    \begin{align}
         \bE[e^{\lambda(V_N(f)-\hat{\mathcal{L}}_N(f))}] \leq 1+ \frac{(n_w-1)!}{\sqrt{N}} \sum_{r=1}^\infty \left (4 \lambda n_w \bar{G}_{gen}  \bar{G}_f(f)  \right )^r
    \end{align}
    the infinite sum is absolutely convergent if $$4 \lambda n_w \bar{G}_{gen}  \bar{G}_f(f)<1$$
    that means that
    \begin{align}
        0<\lambda< \frac{1}{4 n_w \bar{G}_{gen}  \bar{G}_f(f)}
    \end{align}
    under this condition we can write
    \begin{align}
         \bE[e^{\lambda(V_N(f)-\hat{\mathcal{L}}_N(f))}] \leq 1+ \frac{(n_w-1)!}{\sqrt{N}} \frac{4 \lambda n_w \bar{G}_{gen}  \bar{G}_f(f)}{1-4 \lambda n_w\bar{G}_{gen}  \bar{G}_f(f)}=1+ \frac{n_w!}{\sqrt{N}} \frac{4 \lambda \bar{G}_{gen}  \bar{G}_f(f)}{1-4 \lambda n_w\bar{G}_{gen}  \bar{G}_f(f)}
    \end{align}
\end{Proof}

% \begin{lemma}\label{lemma:totalMGF} Let 
%     \begin{align}
%         0<\lambda\leq \max\{\left (8 m \bar{G}_{gen}  \bar{G}_f(f)\right )^{-1}, \left ( 6(m+1) n_y \mu_{\max}(Q_e)G_e(f)^{2} \right )^{-1} \},
%     \end{align}
%     then with notation as above the following holds
%     \begin{align}
%         \bE\left [e^{\lambda(\mathcal{L}(f)-\hat{\mathcal{L}}_N(f))} \right ] \leq  1+ \frac{1}{2} \left (\frac{m!}{\sqrt{N}} \frac{8 \lambda \bar{G}_{gen}  \bar{G}_f(f)}{1-8 \lambda m\bar{G}_{gen}  \bar{G}_f(f)} +\frac{2}{N}\frac{(m+1)! \left (6\lambda n_y\mu_{\max}(Q_e)G_e(f)^{2}\right )^2}{(1-6(m+1)\lambda n_y\mu_{\max}(Q_e)G_e(f)^{2})} \right )
%     \end{align}

%     \begin{Proof}[of Lemma \ref{lemma:totalMGF}]
%         \begin{align}
%             \bE\left [e^{\lambda(\mathcal{L}(f)-\hat{\mathcal{L}}_N(f))} \right ] = 1 + \sum_{r=1}^\infty \frac{\lambda^r}{r!} \bE[(\mathcal{L}(f)-\hat{\mathcal{L}}_N(f))^r]
%         \end{align}
%         Now note that, $(\mathcal{L}(f)-\hat{\mathcal{L}}_N(f))^r\leq |\mathcal{L}(f)-\hat{\mathcal{L}}_N(f)|^r$
%         \begin{align}
%             |\mathcal{L}(f)-\hat{\mathcal{L}}_N(f)|^r = |\mathcal{L}(f)-V_N(f)+ V_N(f)-\hat{\mathcal{L}}_N(f)|^r\\
%             \leq \Big ( |\mathcal{L}(f)-V_N(f)|+ |V_N(f)-\hat{\mathcal{L}}_N(f)| \Big )^r \\
%             =2^r \frac{1}{2^r} \Big ( |\mathcal{L}(f)-V_N(f)|+ |V_N(f)-\hat{\mathcal{L}}_N(f)| \Big )^r\\
%             = 2^r \left (\frac{1}{2}\left | \mathcal{L}(f)-V_N(f) \right |+ \frac{1}{2}\left |V_N(f)-\hat{\mathcal{L}}_N(f) \right | \right )^r
%         \end{align}
%         now since the function $\phi(x)=x^r$ is convex for any $r\geq 1$, for $x\geq 0$, by convexity it follows that
%         \begin{align}
%             (\mathcal{L}(f)-\hat{\mathcal{L}}_N(f))^r \leq 2^r \left (\frac{1}{2}\left | \mathcal{L}(f)-V_N(f) \right |^r + \frac{1}{2}\left |V_N(f)-\hat{\mathcal{L}}_N(f) \right |^r  \right )\\
%             =2^{r-1} \left (\left | \mathcal{L}(f)-V_N(f) \right |^r + \left |V_N(f)-\hat{\mathcal{L}}_N(f) \right |^r  \right )
%         \end{align}
%         Thus 
%         \begin{align}
%             \bE[(\mathcal{L}(f)-\hat{\mathcal{L}}_N(f))^r] \leq 2^{r-1} \left (\bE \left [ \left | \mathcal{L}(f)-V_N(f) \right |^r \right ] + \bE \left [\left |V_N(f)-\hat{\mathcal{L}}_N(f) \right |^r\right ]  \right )
%         \end{align}
%         and therefore 
%         \begin{align}
%              1 + \sum_{r=1}^\infty \frac{\lambda^r}{r!} \bE[(\mathcal{L}(f)-\hat{\mathcal{L}}_N(f))^r] \leq 1 + \sum_{r=1}^\infty \frac{\lambda^r}{r!} 2^{r-1} \left (\bE \left [ \left | \mathcal{L}(f)-V_N(f) \right |^r \right ] + \bE \left [\left |V_N(f)-\hat{\mathcal{L}}_N(f) \right |^r\right ]  \right )\\
%              = \frac{1}{2}\left (1 + \sum_{r=1}^\infty \frac{(2\lambda)^r}{r!}\bE \left [ \left | \mathcal{L}(f)-V_N(f) \right |^r \right ]  \right ) + \frac{1}{2} \left (1 + \sum_{r=1}^\infty \frac{(2\lambda)^r}{r!}\bE \left [\left |V_N(f)-\hat{\mathcal{L}}_N(f) \right |^r\right ]  \right )
%          \end{align}
%          thus 
%          \begin{align}
%             \bE\left [e^{\lambda(\mathcal{L}(f)-\hat{\mathcal{L}}_N(f))} \right ] \leq \frac{1}{2} \left (\bE\left [e^{2\lambda \mathcal{L}(f)-V_N(f))} \right ] + \bE\left [e^{2\lambda( V_N(f)-\hat{\mathcal{L}}_N(f))} \right ] \right )
%         \end{align}
%         By Lemma \ref{lemma:mgf(Vn-hatL)}, for $0<\lambda< \left (4 m \bar{G}_{gen}  \bar{G}_f(f)\right )^{-1}$ we have, for $m=n_u+n_y$
%         \begin{align}
%         \bE[e^{\lambda(V_N(f)-\hat{\mathcal{L}}_N(f))}] \leq 1+ \frac{m!}{\sqrt{N}} \frac{4 \lambda \bar{G}_{gen}  \bar{G}_f(f)}{1-4 \lambda m\bar{G}_{gen}  \bar{G}_f(f)}
%         \end{align}
%         and by Lemma \ref{lem:mgf}, for $0<\lambda\leq \left ( 3(m+1) n_y \mu_{\max}(Q_e)G_e(f)^{2} \right )^{-1}$, we have
%         \begin{align}
%             \bE\left [e^{\lambda(\mathcal{L}(f)-V_N(f))} \right ]\leq 1+\frac{2}{N}\frac{(m+1)! \left (3\lambda n_y\mu_{\max}(Q_e)G_e(f)^{2}\right )^2}{(1-3(m+1)\lambda n_y\mu_{\max}(Q_e)G_e(f)^{2})}
%         \end{align}

%     Thus, for 
%     \begin{align}
%         0<2\lambda< \left (4 m \bar{G}_{gen}  \bar{G}_f(f)\right )^{-1},\\
%         \text{and}\quad 0<2\lambda\leq \left ( 3(m+1) n_y \mu_{\max}(Q_e)G_e(f)^{2} \right )^{-1}
%     \end{align}
%     i.e.
%     \begin{align}
%         0<\lambda\leq \max\{\left (8 m \bar{G}_{gen}  \bar{G}_f(f)\right )^{-1}, \left ( 6(m+1) n_y \mu_{\max}(Q_e)G_e(f)^{2} \right )^{-1} \}
%     \end{align}
% \begin{align}
%     \bE\left [e^{\lambda(\mathcal{L}(f)-\hat{\mathcal{L}}_N(f))} \right ] \leq \frac{1}{2} \left (1+ \frac{m!}{\sqrt{N}} \frac{8 \lambda \bar{G}_{gen}  \bar{G}_f(f)}{1-8 \lambda m\bar{G}_{gen}  \bar{G}_f(f)} + 1+\frac{2}{N}\frac{(m+1)! \left (6\lambda n_y\mu_{\max}(Q_e)G_e(f)^{2}\right )^2}{(1-6(m+1)\lambda n_y\mu_{\max}(Q_e)G_e(f)^{2})} \right )\\
%     = 1+ \frac{1}{2} \left (\frac{m!}{\sqrt{N}} \frac{8 \lambda \bar{G}_{gen}  \bar{G}_f(f)}{1-8 \lambda m\bar{G}_{gen}  \bar{G}_f(f)} +\frac{2}{N}\frac{(m+1)! \left (6\lambda n_y\mu_{\max}(Q_e)G_e(f)^{2}\right )^2}{(1-6(m+1)\lambda n_y\mu_{\max}(Q_e)G_e(f)^{2})} \right )
% \end{align}


        
%     \end{Proof}
    
% \end{lemma}









\begin{lemma}\label{lemma:L-Vr} Let $\y_\nu(t),\hat{\y}_{f,\nu}(t),\hat{\y}_{f,\nu}(t|s)\in \mathbb{R}^1$ denote the $\nu$'th component of $\y(t),\hat{\y}_{f}(t),\hat{\y}_{f}(t|s)$ respectively,
\begin{align}
   \mathcal{L}_\nu(f) &\triangleq \bE[(\hat{\y}_{f,\nu}(t)-\y_\nu(t))^2]=\lim_{s \rightarrow -\infty} \bE[(\hat{\y}_{f,\nu}(t|s)-\y_\nu(t))^2]\\
   V_{N,\nu}(f) &\triangleq \frac{1}{N}\sum_{t=0}^{N-1} (\hat{\y}_{f,\nu}(t)-\y_\nu(t))^2
\end{align}
and let $\sigma(r)$, be such that the following holds.
	\begin{align}
		\sigma(r)&\geq \sup_{t,k,l}\bE[\|\e(t,k,l)\|_2^r]\\
		\e(t,k,j)&=\begin{cases} Q_e-\e_g(t-k)\e_g^T(t-j),& k=j\\ -\e_g(t-k)\e_g^T(t-j),& k\neq j \end{cases}
	\end{align}
	Then the raw moments are bounded 
	\begin{align} 
		\bE[(\mathcal{L}_\nu(f)-&V_{N,\nu}(f))^r]\leq\frac{1}{N}\sigma(r)4(r-1)G_{e}(f)^{2r}
	\end{align}
\end{lemma}
\begin{Proof}[Proof of Lemma \ref{lemma:L-Vr}]
	
	The prediction error can be expressed as
	\begin{align*}
		(\y_\nu(t)-\hat{\y}_{f,\nu}(t))=\sum_{k=0}^\infty\alpha_k\e_g(t-k)
	\end{align*}
        
	with
	\begin{align*}
		\alpha_k=\alpha_k(\nu)=\begin{cases} D_{e_\nu},& k=0\\ C_{e_\nu}A_e^{k-1}K_e,& k>0 \end{cases}
	\end{align*}
        where $D_{e_\nu}=\mathbf{1}_\nu D_e$, and $C_{e_\nu}=\mathbf{1}_\nu C_e$ denote the $\nu$'th row of matrices $D_e,C_e$ respectively.
	Then generalised loss $\mathcal{L}_\nu(f)$ for component $\nu$ is expressed as
	\begin{align*}
		\mathcal{L}_\nu(f)&=\bE[(\y_\nu(t)-\hat{\y}_{f,\nu}(t))^2]\\
		&=\bE\left[\text{trace}\left ( \left(\sum_{k=0}^\infty\alpha_k\e_g(t-k)\right)\left(\sum_{k=0}^\infty\alpha_k\e_g(t-k)\right)^T \right )\right]\\
		&=\sum_{k=0}^\infty\alpha_kQ_e\alpha_k^T
	\end{align*}
	and infinite horizon prediction loss is 
	\begin{align*}
		V_{N,\nu}(f)&=\frac{1}{N}\sum_{t=0}^{N-1}(\y_\nu(t)-\hat{\y}_{f,\nu}(t))^2\\
		\mathcal{L}_\nu(f)-V_{N,\nu}(f)&=\frac{1}{N}\sum_{t=0}^{N-1}\left (\sum_{k=0}^\infty\alpha_kQ_e\alpha_k^T  - \sum_{k=0}^\infty\sum_{j=0}^{\infty}\alpha_k\e_g(t-k)\e_g(t-j)\alpha_k^T \right )\\
		&=\frac{1}{N}\sum_{t=0}^{N-1}\sum_{k=0}^\infty\sum_{j=0}^{\infty}\alpha_k\e(t,k,j)\alpha_j^T \\
		\e(t,k,j)&=\begin{cases} \text{trace}(Q_e)-\e_g(t-k)\e_g^T(t-j),& k=j\\ -\e_g(t-k)\e_g^T(t-j),& k\neq j \end{cases}
	\end{align*}
	For ease of notation let us define
	\begin{align*}
		\z(t,k,j)=\alpha_k\e(t,k,j)\alpha_j^T
	\end{align*}
	then
	\begin{align*}
		&\bE[(\mathcal{L}_\nu(f)-V_{N,\nu}(f))^r]\\
		%&=\frac{1}{N^r} \bE\left[\lef\sum_{t_1=0}^{N-1}\dots \sum_{t_r=0}^{N-1} %\sum_{k_1,j_1=0}^\infty \dots \sum_{k_r,j_r=0}^\infty %\prod_{l=1}^{r}z(t_l,k_l,j_l)\right| \le \\
		& = \frac{1}{N^r} \sum_{t_1=0}^{N-1}\dots \sum_{t_r=0}^{N-1} \sum_{k_1,j_1=0}^\infty \dots \sum_{k_r,j_r=0}^\infty \bE\left [\prod_{l=1}^{r}z(t_l,k_l,j_l)\right]
	\end{align*}
	Note that, with i.i.d. innovation noise $\e_g(t)$, if
	\begin{align*}
		&t_r-k_r\notin \{ t_i-k_i,t_i-j_i\}_{i=1}^{r-1}\\
		&\quad \land t_r-j_r\notin \{ t_i-k_i,t_i-j_i\}_{i=1}^{r-1}
	\end{align*}
	or similarly
	\begin{equation}
	\label{pf:b8:eq1}
		\{t_r-k_r,t_r-j_r\} \cap \{ t_i-k_i,t_i-j_i\}_{i=1}^{r-1} = \emptyset
	\end{equation}
	then $\z(t_r,k_r,j_r)$ is independent of $\z(t_i,k_i,j_i)$. Moreover,
	notice that $E(\z(t_r,k_r,j_r)]=0$. 
	Hence, if \eqref{pf:b8:eq1}, it holds that
	\begin{equation}
	\label{pf:b8:eq2}
		%&\bE[(\mathcal{L}(f)-V_N(f))^r]=\frac{1}{N^r}\sum_{t_1=0}^{N-1}\dots %\sum_{t_r=0}^{N-1}\\
		%&\sum_{k_1,j_1=0}^\infty \dots \sum_{k_r,j_r=0}^\infty 
		\bE\left [\prod_{l=1}^{r}z(t_l,k_l,j_l)\right] = \bE\left [\prod_{l=1}^{r-1}\z(t_l,k_l,j_l)\right ]\underset{=0}{\underbrace{\bE[\z(t_r,k_r,j_r)]}}=0.
	\end{equation}
	Let us denote
	\begin{align*}
		\mathcal{Z}=\{ t_i-k_i+k_r,t_i-j_i+k_r,t_i-k_i+j_r,t_i-j_i+j_r\}_{i=1}^{r-1}.
	\end{align*}
	Then using \eqref{pf:b8:eq2} for those $\{t_l,k_l,j_l\}_{l=1}^{r}$ which satisfy
	\eqref{pf:b8:eq1}, it follows that
	\begin{equation}
	\label{pf:b8:eq22}
		\bE[(\mathcal{L}_\nu(f)-V_{N,\nu}(f))^r]=\frac{1}{N^r}\sum_{t_1=0}^{N-1}\dots \sum_{t_{r-1}=0}^{N-1}\sum_{k_1,j_1=0}^\infty \dots \sum_{k_r,j_r=0}^\infty \sum_{t_{r}\in\mathcal{Z}}\bE\left [\prod_{l=1}^{r}z(t_l,k_l,j_l)\right ].
	\end{equation}
	Note that 
	\begin{align*}
		\bE\left [\prod_{l=1}^{r}z(t_l,k_l,j_l)\right ]&\leq \left |\bE\left [\prod_{l=1}^{r}z(t_l,k_l,j_l)\right ] \right |\leq \bE\left [\prod_{l=1}^{r}|z(t_l,k_l,j_l)|\right ].
	\end{align*}
	Let us focus on $|\z(t_i,k_i,j_i)|$:
	\begin{align*}
		|\z(t_l,k_l,j_l)| &\leq \|\alpha_{k_l}\|_2\|\alpha_{j_l}\|_2\|\e(t_l,k_l,j_l)\|_2\\
		\bE\left [\prod_{l=1}^{r}|\z(t_l,k_l,j_l)|\right ]&\leq \prod_{l=1}^r\|\alpha_{k_l}\|_2\|\alpha_{j_l}\|_2\bE\left [\prod_{l=1}^r\|\e(t_l,k_l,j_l)\|_2 \right ]
	\end{align*}
	Then using Arithmetic Mean-Geometric Mean Inequality, \cite{steele2004cauchy} we have
	\begin{align}
		\bE\left [\prod_{l=1}^r\|\e(t_l,k_l,j_l)\| \right ] \leq \frac{1}{r}\sum_{l=1}^r \bE[\|\e(t_l,k_l,j_l)\|_2^r] \label{pf:b8:eq3}
	\end{align}
	% 	\textcolor{blue}{For now, let us, assume $\bE[\|e(t_l,k_l,j_l)\|_2^r]<\sigma(r)$, i.e. }
	Now, let $\sigma(r)$, be such that the following holds.
	\begin{align}
		\sigma(r)\geq \sup_{t,k,l}\bE[\|\e(t,k,l)\|_2^r]
	\end{align}
	Then, 
	%\begin{align*}
	\(	\frac{1}{r}\sum_{l=1}^r \bE[\|\e(t_l,k_l,j_l)\|_2^r] \leq \sigma(r) \)
	%\end{align*}
	 and then from \eqref{pf:b8:eq3} it follows that 
	\begin{align}
		\bE\left [\prod_{l=1}^r|\e(t_l,k_l,j_l)| \right ] \leq \sigma(r)
	\end{align}
	Combining this with \eqref{pf:b8:eq22}, it follows that
	\begin{align}
		&\bE[(\mathcal{L}_\nu(f)-V_{N,\nu}(f))^r]\leq\frac{1}{N^r}\sum_{t_1=0}^{N-1}\dots \sum_{t_{r-1}=0}^{N-1}\sum_{k_1,j_1=0}^\infty \dots \sum_{k_r,j_r=0}^\infty \sum_{t_{r}\in\mathcal{Z}}\sigma(r)\prod_{l=1}^r\|\alpha_{k_l}\|_2\|\alpha_{j_l}\|_2
		\label{pf:b8:eq4}
	\end{align}
	% \begin{align*}
	%     \sum_{t_{r}\in\mathcal{Z}}\sigma(r)\prod_{l=1}^r\|\alpha_{k_l}\|_2\|\alpha_{j_l}\|_2
	% \end{align*}
	and the quantity $\sigma(r)\prod_{l=1}^r\|\alpha_{k_l}\|_2\|\alpha_{j_l}\|_2$ does not depend on $t_r$. Moreover 
	\begin{align*}
		\sum_{t_{r}\in\mathcal{Z}}\sigma(r)\prod_{l=1}^r\|\alpha_{k_l}\|_2\|\alpha_{j_l}\|_2\leq
		\sigma(r)\prod_{l=1}^r\|\alpha_{k_l}\|_2\|\alpha_{j_l}\|_2 |\mathcal{Z}|,
	\end{align*}
	where $|\mathcal{Z}|$ is the cardinality of the set $\mathcal{Z}$. Note $|\mathcal{Z}|\leq 4(r-1)$, therefore
	\begin{align*}
		\sum_{t_{r}\in\mathcal{Z}}&\sigma(r)\prod_{l=1}^r\|\alpha_{k_l}\|_2\|\alpha_{j_l}\|_2\leq \sigma(r)\prod_{l=1}^r\|\alpha_{k_l}\|_2\|\alpha_{j_l}\|_2 4(r-1),
	\end{align*}
	Combining the latter inequality with \eqref{pf:b8:eq4}, it follows that
	\begin{align}
		\bE[(\mathcal{L}_\nu(f)-V_{N,\nu}(f))^r]&\leq \frac{1}{N^r}\sum_{t_1=0}^{N-1}\dots \sum_{t_{r-1}=0}^{N-1}\sigma(r)4(r-1)\sum_{k_1,j_1=0}^\infty \dots \sum_{k_r,j_r=0}^\infty  \prod_{l=1}^r\|\alpha_{k_l}\|_2\|\alpha_{j_l}\|_2 
	\end{align}
	Now notice
	\begin{align*}
		G_{e,\nu}(f)^{2r}=\left ( \sum_{k=0}^\infty \|\alpha_k\|_2 \right )^{2r}=\left ( \sum_{k,j=0}^\infty \|\alpha_k\|_2\|\alpha_j\|_2 \right )^r \\
		=\sum_{k_1,j_1=0}^\infty \dots \sum_{k_r,j_r=0}^\infty  \prod_{l=1}^r\|\alpha_{k_l}\|_2\|\alpha_{j_l}\|_2 
	\end{align*}
    therefore we obtain
	\begin{align*}
		\bE[(\mathcal{L}_\nu(f)-V_{N,\nu}(f))^r] &\leq \frac{1}{N^r}\sum_{t_1=0}^{N-1}\dots \sum_{t_{r-1}=0}^{N-1}\sigma(r)4(r-1)G_{e,\nu}(f)^{2r} \\
		&\leq\frac{1}{N^r}N^{r-1}\sigma(r)4(r-1)G_{e,\nu}(f)^{2r}\\
		&\leq\frac{1}{N}\sigma(r)4(r-1)G_{e,\nu}(f)^{2r}\\
	\end{align*}
    and since
    \begin{align*}
		\|\alpha_k(\nu)\|=\begin{cases} \|\mathbf{1}_\nu D_e\|\leq \|D_e\|,& k=0\\ \|\mathbf{1}_\nu C_eA_e^{k-1}K_e\|\leq \|C_eA_e^{k-1}K_e\|,& k>0 \end{cases}
	\end{align*}
    then
    \begin{align}
        G_{e,\nu}\leq G_e = \|D_e\| + \sum_{k=1}^\infty \|C_eA_e^{k-1}K_e\|
    \end{align}
    and since $2r>1$ we obtain the statement of the lemma
    \begin{align}
        \bE[(\mathcal{L}_\nu(f)-V_{N,\nu}(f))^r] &\leq \frac{1}{N}\sigma(r)4(r-1)G_e(f)^{2r}
    \end{align}
    
\end{Proof}





\begin{lemma}\label{lemma:L-Vrfull} with notation as above the following holds
    \begin{align}
        \bE[(\mathcal{L}(f)-V_{N}(f))^r] &\leq \frac{n_y^r}{N}\sigma(r)4(r-1)G_e(f)^{2r}
    \end{align}
\end{lemma}



\begin{Proof}[of Lemma \ref{lemma:L-Vrfull}]
    By definition
    \begin{align}
        \mathcal{L}(f)&=\bE[ (\y(t)-\hat{\y}_f(t))^T(\y(t)-\hat{\y}_f(t)) ] = \sum_{\nu=1}^{n_y} \bE[(\y_\nu(t)-\hat{\y}_{f,\nu}(t))^2]=\sum_{\nu=1}^{n_y}\mathcal{L}_\nu(f)\\
        V_N(f)&=\frac{1}{N} \sum_{t=0}^{N-1} (\y(t)-\hat{\y}_f(t))^T(\y(t)-\hat{\y}_f(t))  = \sum_{\nu=1}^{n_y} \frac{1}{N} \sum_{t=0}^{N-1} (\y_\nu(t)-\hat{\y}_{f,\nu}(t))^2=\sum_{\nu=1}^{n_y}V_{N,\nu}(f)\\
    \end{align}
    then
    \begin{align}
        \bE[(\mathcal{L}(f)-V_N(f))^r]=\bE\left [ \left (\sum_{\nu=1}^{n_y}\mathcal{L}_\nu(f)-V_{N,\nu}(f) \right )^r \right ]=\sum_{\nu_1}^{n_y}\dots \sum_{\nu_r}^{n_y} \bE\left [ \prod_{i=1}^r (\mathcal{L}_{\nu_i}(f)-V_{N,\nu_i}(f)) \right ]
    \end{align}
    Then using Arithmetic Mean-Geometric Mean Inequality, \cite{steele2004cauchy}, we get $\prod_{i=1}^r (\mathcal{L}_{\nu_i}(f)-V_{N,\nu_i}(f))\leq \frac{1}{r}\sum_{i=1}^r (\mathcal{L}_{\nu_i}(f)-V_{N,\nu_i}(f))^r$, and thus
    \begin{align}
        \bE[(\mathcal{L}(f)-V_N(f))^r]\leq \sum_{\nu_1=1}^{n_y}\dots \sum_{\nu_r=1}^{n_y} \frac{1}{r}\sum_{i=1}^r \bE\left [(\mathcal{L}_{\nu_i}(f)-V_{N,\nu_i}(f))^r \right ]
    \end{align}
    From Lemma \ref{lemma:L-Vr}, we have $\bE[(\mathcal{L}_\nu(f)-V_{N,\nu}(f))^r] \leq \frac{1}{N}\sigma(r)4(r-1)G_e(f)^{2r}$, thus
    \begin{align}
        \bE[(\mathcal{L}(f)-V_N(f))^r] &\leq \sum_{\nu_1=1}^{n_y}\dots \sum_{\nu_r=1}^{n_y} \frac{1}{r}\sum_{i=1}^r \frac{1}{N}\sigma(r)4(r-1)G_e(f)^{2r}\\
        &= \frac{n_y^{r}}{N}\sigma(r)4(r-1)G_e(f)^{2r}
    \end{align}
\end{Proof}




\begin{lemma}\label{lemma:sigmar} let $m=n_u+n_y$, then for $r \ge 2$, the quantity 
	\begin{align*}
		\sigma(r)=\max \left \{(\mu_{\max}(Q_e)^r4(m+r-1)!), (\mu_{\max}(Q_e)^{r}3^r(m+r-1)!)  \right \} = \mu_{\max}(Q_e)^{r}3^r(m+r-1)!
	\end{align*}
	%or simply 
	%\begin{align*}
%		\sigma(r)=\mu_{\max}(Q_e)^{r}3^r(m+r-1)!,\quad r\geq 2,
%	\end{align*} 
satisfies
	\begin{align*}
		\sigma(r)\geq \sup_{t,k,l}\bE[\|\e(t,k,l)\|_2^r]
	\end{align*}
\end{lemma}

\begin{Proof}[Proof of Lemma \ref{lemma:sigmar}]
	Recall that
	\begin{align*}
		\e(t,k,j)=\begin{cases} Q_e-\e_g(t-k)\e_g^T(t-j),& k=j\\ -\e_g(t-k)\e_g^T(t-j),& k\neq j \end{cases}
	\end{align*}
	First let us take the case when $k\neq j$. Then
	\begin{align*}
		\bE[\|\e(t,k,l)\|_2^r]=\bE[\|-\e_g(t-k)\e_g^T(t-j)\|_2^r]
	\end{align*}
	Again as $\e_g(t)$ is i.i.d. we have 
	\begin{align*}
		\bE[\|\e(t,k,l)\|_2^r]\leq \bE[\|\e_g(t-k)\|_2^r]\bE[\|\e_g(t-j)\|_2^r]
	\end{align*}
	and due to stationarity of $\e_g(t)$, we have $\bE[\|\e_g(t-k)\|_2^r]=\bE[\|\e_g(t-j)\|_2^r]$, therefore
	\begin{align*}
		\bE[\|\e(t,k,l)\|_2^r]\leq \bE[\|\e_g(t)\|_2^r]^2
	\end{align*}
	and again due to stationarity of $\e_g(t)$, the moments do not depend on $t$, and using Lemma \ref{lemma:Emoments} we obtain
	\begin{align*}
		\sigma(r)\geq \mu_{\max}(Q_e)^r4((m+r-1)!) \geq \bE[\|\e(t,k,l)\|_2^r]^2
	\end{align*}
	% 	From Lemma \ref{lemma:etoz} 
	% 	\begin{align*}
	% 		\bE[\|e(t)\|_2^r]^2\leq (\mu_{\max}(Q_e)^{\frac{r}{2}}\bE[\|z\|_2^r])^2 
	% 	\end{align*}
	% 	and from Lemma \ref{lemma:zMomentsSq} we obtain
	% 	\begin{align*}
	% 		\bE[\|\e_g(t)\|_2^r]^2\leq \mu_{\max}(Q_e)^r4((m+r-1)!)
	% 	\end{align*}
	Now let us take the case when $k=j$. Then
	\begin{align*}
		\bE[\|\e(t,k,l)\|_2^r]&=\bE[\|Q_e-\e_g(t-k)\e_g^T(t-k)\|_2^r]\\
		&\leq \bE[(\|Q_e\|_2+\|\e_g(t)\|_2^2)^r]\\
		&= \bE \left [ \sum_{j=0}^r \begin{pmatrix} r\\ j \end{pmatrix} \|Q_e\|_2^{r-j}\|\e_g(t)\|_2^{2j} \right ]\\
		&=\sum_{j=0}^r \begin{pmatrix} r\\ j \end{pmatrix} \|Q_e\|_2^{r-j}\bE\|\e_g(t)\|_2^{2j}]
	\end{align*}
	As $Q_e$ is a positive definite matrix,$\|Q_e\|_2 = \mu_{max}(Q_e)$, and hence
	\begin{align*}
		\bE[\|\e(t,k,l)\|_2^r]\leq \sum_{j=0}^r \begin{pmatrix} r\\ j \end{pmatrix} \mu_{\max}(Q_e)^{r-j}\bE\|\e_g(t)\|_2^{2j}]
	\end{align*}
	using Lemma \ref{lemma:evenEmoments} we obtain
	\begin{align*}
		\bE[\|\e(t,k,l)\|_2^r]&\leq \sum_{j=0}^r \begin{pmatrix} r\\ j \end{pmatrix} \mu_{\max}(Q_e)^{r-j}\mu_{\max}(Q_e)^{j}2^j(m+j-1)!\\
		&\leq \mu_{\max}(Q_e)^{r} \sum_{j=0}^r \begin{pmatrix} r\\ j \end{pmatrix}2^j(m+j-1)!.
	\end{align*}
	Since for $j\leq r$,  $(m+j-1)!\leq (m+r-1)!$, hence
	\begin{align*}
		&\bE\|\e(t,k,l)\|_2^{2r}]\leq \mu_{\max}(Q_e)^{r}(m+r-1)! \sum_{j=0}^r \begin{pmatrix} r\\ j \end{pmatrix}2^j
	\end{align*}
	Notice $3^r=(1+2)^r=\sum_{j=0}^r \begin{pmatrix} r\\ j \end{pmatrix}2^j$, hence
	\begin{align*}
		\bE\|\e_g(t,k,l)\|_2^{2r}]\leq \mu_{\max}(Q_e)^{r}3^r(m+r-1)!
	\end{align*}
	Hence,
	\begin{align*}
		\sigma(r)=\max \left \{\mu_{\max}(Q_e)^r4(m+r-1)!, \right . \\
		\left .\mu_{\max}(Q_e)^{r}3^r(m+r-1)!  \right \}.
	\end{align*}
	As we are interested in moments higher or equal to two, i.e. $r\geq 2$, then
	\begin{align*}
		\sigma(r)=\mu_{\max}(Q_e)^{r}3^r(m+r-1)!.
	\end{align*}
\end{Proof}
\begin{lemma}\label{lem:mgf} For $\lambda\leq \left ( 3(m+1) n_y \mu_{\max}(Q_e)G_e(f)^{2} \right )^{-1}$, the moment generating function is bounded
        \begin{align}
            		\bE\left [e^{\lambda(\mathcal{L}(f)-V_N(f))} \right ]\leq 1+\frac{2}{N}\frac{(m+1)! \left (3\lambda n_y\mu_{\max}(Q_e)G_e(f)^{2}\right )^2}{(1-3(m+1)\lambda n_y\mu_{\max}(Q_e)G_e(f)^{2})}
        \end{align}
\end{lemma}
\begin{Proof}[Proof of Lemma \ref{lem:mgf}] \label{proof:mgf} %\ref{thm:mgf}
	We can bound the moment generating function via series expansion. First note that $\bE[\mathcal{L}(f)-V_N(f)]=0$, and hence 
	\begin{align*}
		\bE\left [e^{\lambda(\mathcal{L}(f)-V_N(f))} \right ]=1+\lambda\bE[\mathcal{L}(f)-V_N(f)]+\sum_{r=2}^\infty \frac{\lambda^r}{r!}E[(\mathcal{L}(f)-V_N(f))^r].
	\end{align*}
	 Then using Lemma \ref{lemma:L-Vrfull} we get
	\begin{align}
		\bE\left [e^{\lambda(\mathcal{L}(f)-V_N(f))} \right ]\leq 1+\sum_{r=2}^\infty \frac{\lambda^r}{r!}\frac{n_y^r}{N}\sigma(r)4(r-1)G_e(f)^{2r} %\label{eqA:proofofMGF}
	\end{align}
	% 	With \eqref{eqA:proofofMGF} we reach the statement of the theorem, however we still need to show 
	% 	\begin{align*}
	% 		\sigma(r)\geq \sup_{t,k,l}\bE[\|\e(t,k,l)\|_2^r]
	% 	\end{align*}
	Now using Lemma \ref{lemma:sigmar} we obtain
	\begin{align*}
		&\bE\left [e^{\lambda(\mathcal{L}(f)-V_N(f))} \right ]\leq 1+\frac{1}{N}\sum_{r=2}^\infty \frac{(m+r-1)!}{r!}4(r-1)\left (3n_y\lambda\mu_{\max}(Q_e)G_e(f)^{2}\right )^r\\
	\end{align*}
	Notice that $4(r-1)\leq 2^r$, for $r\in\mathbb{N}$. Furthermore
	\begin{align*}
		\frac{(m+r-1)!}{r!}=m!\frac{m+1}{2}\frac{m+2}{3}\dots \frac{m+r-1}{r}
	\end{align*}
	and as $\frac{m+r-1}{r}\leq \frac{m+1}{2}$, for all $r\geq 2$, then
	\begin{align*}
		\frac{(m+r-1)!}{r!}\leq m!\left (\frac{m+1}{2} \right )^{r-1} = m!\frac{\left (\frac{m+1}{2} \right )^{r}}{\frac{m+1}{2}}		= 2\frac{m!}{m+1}\left (\frac{m+1}{2} \right )^r.
	\end{align*}
	%now we can obtain a bound for which we can define the absolute convergence criteria
	 Hence, we can derive the following inequality:
	\begin{align*}
		&\bE\left [e^{\lambda(\mathcal{L}(f)-V_N(f))} \right ]\leq 1+\frac{2}{N}\frac{m!}{m+1} \sum_{r=2}^\infty \left (3(m+1)\lambda n_y\mu_{\max}(Q_e)G_e(f)^{2}\right )^r.
	\end{align*}
	Notice that if $$| 3(m+1)\lambda n_y\mu_{\max}(Q_e)G_e(f)^{2} | < 1,$$ then the 
	infinite sum 
	$\sum_{r=2}^\infty \left (3(m+1)\lambda n_y\mu_{\max}(Q_e)G_e(f)^{2}\right )^r$
	is absolutely convergent, and 
	\[
	  \begin{split}
	   & \sum_{r=2}^\infty \left (3(m+1)\lambda n_y\mu_{\max}(Q_e)G_e(f)^{2}\right )^r 
	   = \frac{ \left (3(m+1)\lambda n_y\mu_{\max}(Q_e)G_e(f)^{2}\right )^2}{1-3(m+1)\lambda n_y\mu_{\max}(Q_e)G_e(f)^{2}}
	  \end{split}  
	\]
	 To sum up, if
	 %which in turn gives conditions on $\lambda$.
	\begin{align*}
		\lambda\leq \left ( 3(m+1)n_y \mu_{\max}(Q_e)G_e(f)^{2} \right )^{-1}.
	\end{align*}
	then 
	\begin{align*}
		\bE\left [e^{\lambda(\mathcal{L}(f)-V_N(f))} \right ]&\leq 1+\frac{2}{N}\frac{m!}{m+1} \frac{ \left (3(m+1)\lambda n_y\mu_{\max}(Q_e)G_e(f)^{2}\right )^2}{1-3(m+1)\lambda n_y\mu_{\max}(Q_e)G_e(f)^{2}}\\
		&\leq 1+\frac{2}{N}\frac{(m+1)! \left (3\lambda n_y\mu_{\max}(Q_e)G_e(f)^{2}\right )^2}{(1-3(m+1)\lambda n_y\mu_{\max}(Q_e)G_e(f)^{2})}.
	\end{align*}
	
\end{Proof}









\begin{lemma}\label{lemma:PAC-BayesianKL_General} For measurable functions $X(f),Y(f)$ on $\mathcal{F}$, 
    With probability at least $1-\delta$, the following holds
    \begin{align}
         \forall\rho:\quad &E_{f\sim \hat{\rho}} X (f) \le \  E_{f\sim \hat{\rho}} Y(f) +\dfrac{1}{\lambda}\!\left[KL(\hat{\rho} \|\pi) + \ln\dfrac{1}{\delta}	+ \Psi_{\pi}(\lambda,N) \right ],
    \end{align}
      with
    \begin{equation}
        \Psi_{\pi}(\lambda,N)=	\ln E_{f\sim\pi} \bE[e^{\lambda(X(f)-Y(f))}]
    \end{equation}
\end{lemma}

\begin{Proof}[ of Lemma \ref{lemma:PAC-BayesianKL_General}] 
	Let us apply the Donsker \& Varadhan variational 
	formula to the function $\lambda(X(f)-Y(f))$
   it then follows that
   \begin{align}
		 \sup_{\hat{\rho}} (\lambda E_{f\sim \hat{\rho}} X(f) - \lambda E_{f\sim \hat{\rho}} Y(f) - KL(\hat{\rho} \|\pi)) = \ln E_{f\sim\pi} e^{\lambda(X(f)-Y(f))}, \label{T:pacAlt:eq0.1}
	\end{align}
In particular, 
  \begin{align}
		 e^{\sup_{\hat{\rho}} (\lambda E_{f\sim \hat{\rho}} X(f) - \lambda E_{f\sim \hat{\rho}} Y(f) - KL(\hat{\rho} \|\pi))} = e^{\ln E_{f\sim\pi} e^{\lambda(X(f)- Y(f))}}= E_{f\sim\pi} e^{\lambda(X(f)-Y(f))} \label{T:pacAlt:eq0.2}
	\end{align}
  and hence
  \begin{align}
		 \bE[e^{\sup_{\hat{\rho}} (\lambda E_{f\sim \hat{\rho}} X(f) - \lambda E_{f\sim \hat{\rho}} Y(f) - KL(\hat{\rho} \|\pi))}]=\bE [E_{f\sim\pi} e^{\lambda(X(f)- Y(f))}] = \\ \nonumber
     E_{f\sim\pi} \bE[e^{\lambda(X(f)-Y(f))}]=e^{\Psi_{\pi}(\lambda,N)}
   \label{T:pacAlt:eq0.3}
	\end{align}
  with
    \begin{equation}
        \Psi_{\pi}(\lambda,N)=	\ln E_{f\sim\pi} \bE[e^{\lambda(X(f)-Y(f))}]
    \end{equation}
 Hence,
 \begin{align}
		 \bE[e^{\sup_{\hat{\rho}} (\lambda E_{f\sim \hat{\rho}} X(f) - \lambda E_{f\sim \hat{\rho}} Y(f) - KL(\hat{\rho} \|\pi)}]e^{-\Psi_{\pi}(\lambda,N)} = 1
   \label{T:pacAlt:eq0.4}
	\end{align}
Since 
 \begin{align}
		 \bE[e^{\sup_{\hat{\rho}} (\lambda E_{f\sim \hat{\rho}} X(f) - \lambda E_{f\sim \hat{\rho}} Y(f) - KL(\hat{\rho} \|\pi)}]e^{-\Psi_{\pi}(\lambda,N)} =  \nonumber \\
   \bE[e^{\sup_{\hat{\rho}} (\lambda E_{f\sim \hat{\rho}} X(f) - \lambda E_{f\sim \hat{\rho}} Y(f) - KL(\hat{\rho} \|\pi)-\Psi_{\pi}(\lambda,N)}]
   \label{T:pacAlt:eq0.5}
	\end{align}
 it follows that 
 \begin{align}
   \bE[e^{\sup_{\hat{\rho}} (\lambda E_{f\sim \hat{\rho}} X(f) - \lambda E_{f\sim \hat{\rho}} Y(f) - KL(\hat{\rho} \|\pi))-\Psi_{\pi}(\lambda,N)}] = 1
   \label{T:pacAlt:eq0.6}
	\end{align}
 By Chernoff's bound applied to
 the random variable
 $\mathcal{X}=\sup_{\hat{\rho}} (\lambda E_{f\sim \hat{\rho}} (f) - \lambda E_{f\sim \hat{\rho}} Y(f) - KL(\hat{\rho} \|\pi))-\Psi_{\pi}(\lambda,N)$ it then follows that for any $a > 0$
 \begin{align*}
  \bP(\mathcal{X} \ge a) \le  \frac{E[e^{\mathcal{X}}]}{e^{a}} \le e^{-a}
\end{align*}
By choosing $a=\ln \frac{1}{\delta}$, it follows that
\begin{align*}
  \bP(\mathcal{X} \ge \ln \frac{1}{\delta}) \le \delta
\end{align*}
and hence, 
\begin{align*}
  \bP(\mathcal{X} \le  \ln \frac{1}{\delta}) \ge 1-\delta
\end{align*}
By substituting the definition  of $\mathcal{X}$ and regrouping 
the terms, it then  follows that
\begin{align*}
  \bP( \sup_{\hat{\rho}} (\lambda E_{f\sim \hat{\rho}} X (f) - \lambda E_{f\sim \hat{\rho}} Y(f) - KL(\hat{\rho} \|\pi)) \le  \ln \frac{1}{\delta}+\Psi_{\pi}(\lambda,N)) \ge 1-\delta
\end{align*}
Note that 
\begin{align*}
\{ \omega  \mid \sup_{\hat{\rho}} (\lambda E_{f\sim \hat{\rho}} X (f) - \lambda E_{f\sim \hat{\rho}} Y(f)(\omega) - KL(\hat{\rho} \|\pi)) \le  \ln \frac{1}{\delta}+\Psi_{\pi}(\lambda,N) \}= \\
\{
   \omega \mid \forall \hat{\rho}: 
   E_{f\sim \hat{\rho}} X(f) \le
     E_{f\sim \hat{\rho}} Y(f)(\omega) +
     \dfrac{1}{\lambda}\!\left[KL(\hat{\rho} \|\pi) + \ln\dfrac{1}{\delta}	+ \Psi_{\pi}(\lambda,N) \right
\}
\end{align*}
and hence
it then follows that
	with probability at least $1-\delta$, the following 
	holds
	\begin{align}
		 \forall\rho:\quad &E_{f\sim \hat{\rho}} X (f) \le \  E_{f\sim \hat{\rho}} Y(f) +\dfrac{1}{\lambda}\!\left[KL(\hat{\rho} \|\pi) + \ln\dfrac{1}{\delta}	+ \Psi_{\pi}(\lambda,N) \right ],
	\end{align}
 \end{Proof}


\begin{Corollary}\label{cor:PACKL_L-V} By Lemma \ref{lemma:PAC-BayesianKL_General}, and Lemma \ref{lem:mgf}, for $0<\lambda\leq \inf_{f\in\mathcal{F}} \left ( 3(m+1) n_y \mu_{\max}(Q_e)G_e(f)^{2} \right )^{-1}$, with $\mathcal{M}_\pi$, denoting the set of all absolutely continuous probability densities w.r.t. $\pi$, then with probability at least $1-\delta$, the following holds
	\begin{align}
		 \forall\rho\in\mathcal{M}_\pi:\quad &E_{f\sim \hat{\rho}} \mathcal{L} (f) \le  E_{f\sim \hat{\rho}} V_N(f) +\dfrac{1}{\lambda}\!\left[KL(\hat{\rho} \|\pi) + \ln\dfrac{1}{\delta}	+ \widehat{\Psi}_{\pi,1}(\lambda,N) \right ],
	\end{align}
 with 
 \begin{align}
     \widehat{\Psi}_{\pi,1}(\lambda,N) \triangleq \ln E_{f\sim\pi} \left ( 1+\frac{2}{N}\frac{(m+1)! \left (3\lambda n_y\mu_{\max}(Q_e)G_e(f)^{2}\right )^2}{(1-3(m+1)\lambda n_y\mu_{\max}(Q_e)G_e(f)^{2})} \right )
 \end{align}
\end{Corollary}

\begin{Corollary}\label{cor:PACKL_V-hatL}
    By Lemma \ref{lemma:PAC-BayesianKL_General}, and Lemma \ref{lemma:mgf(Vn-hatL)}, for $0<\lambda \leq \inf_{f\in\mathcal{F}} \left ( 4 n_w \bar{G}_{gen}  \bar{G}_f(f)\right )^{-1}$, with $\mathcal{M}_\pi$, denoting the set of all absolutely continuous probability densities w.r.t. $\pi$, then with probability at least $1-\delta$, the following holds
    	\begin{align}
    		 \forall\rho\in\mathcal{M}_\pi:\quad &E_{f\sim \hat{\rho}} V_N (f) \le  E_{f\sim \hat{\rho}} \hat{\mathcal{L}}_N(f) +\dfrac{1}{\lambda}\!\left[KL(\hat{\rho} \|\pi) + \ln\dfrac{1}{\delta}	+ \widehat{\Psi}_{\pi,2}(\lambda,N) \right ],
    	\end{align}
     with 
    \begin{align}
     \widehat{\Psi}_{\pi,2}(\lambda,N) \triangleq \ln E_{f\sim\pi } \left ( 1+ \frac{(n_y+n_u)!}{\sqrt{N}} \frac{4 \lambda \bar{G}_{gen}  \bar{G}_f(f)}{1-4 \lambda (n_y+n_u)\bar{G}_{gen}  \bar{G}_f(f)} \right )
    \end{align}

\end{Corollary}

\begin{lemma} \label{lemma:unbounded_full_KL}
     For
         \begin{align}
             0<\tilde{\lambda} \leq \frac{1}{2}\Big ( \sup_{f\in\mathcal{F}} \max\{ 3(m+1) n_y \mu_{\max}(Q_e)G_e(f)^{2} , 4 n_w \bar{G}_{gen}  \bar{G}_f(f) \} \Big )^{-1}
         \end{align}with probability at least $1-2\delta$, the following holds
         \begin{align}
             \forall\rho\in\mathcal{M}_\pi:\quad &E_{f\sim \hat{\rho}} \mathcal{L} (f) \le  E_{f\sim \hat{\rho}} \hat{\mathcal{L}}_N(f) +\dfrac{1}{\tilde{\lambda}}\!\left[KL(\hat{\rho} \|\pi) + \ln\dfrac{1}{\delta}	+ \frac{\widehat{\Psi}_{\pi,2}(2\tilde{\lambda},N)+ \widehat{\Psi}_{\pi,1}(2\tilde{\lambda},N)}{2} \right ]  
         \end{align}
         with 
         \begin{align}
             \widehat{\Psi}_{\pi,1}(2\tilde{\lambda},N) = \Psi_{\pi,1}(\tilde{\lambda},N) = \ln E_{f\sim\pi} \left ( 1+\frac{2}{N}\frac{(m+1)! \left (6\tilde{\lambda} n_y\mu_{\max}(Q_e)G_e(f)^{2}\right )^2}{(1-6(m+1)\tilde{\lambda} n_y\mu_{\max}(Q_e)G_e(f)^{2})} \right )\\
             \widehat{\Psi}_{\pi,2}(2\tilde{\lambda},N) = \Psi_{\pi,2}(\tilde{\lambda},N) = \ln E_{f\sim\pi } \left ( 1+ \frac{(n_y+n_u)!}{\sqrt{N}} \frac{8 \tilde{\lambda} \bar{G}_{gen}  \bar{G}_f(f)}{1-8 \tilde{\lambda} (n_y+n_u)\bar{G}_{gen}  \bar{G}_f(f)} \right )
         \end{align} 
     
     \begin{Proof} \label{proof:thm:unbounded}
         we have 
         \begin{align}
             P(\omega\in S_1)\geq 1-\delta \\
             P(\omega\in S_2)\geq 1-\delta
         \end{align}
         with 
         \begin{align}
             S_1\triangleq\{\omega\in\Omega|\forall\rho\in\mathcal{M}_\pi:\quad &E_{f\sim \hat{\rho}} \mathcal{L} (f) \le  E_{f\sim \hat{\rho}} V_N(f) +\dfrac{1}{\lambda}\!\left[KL(\hat{\rho} \|\pi) + \ln\dfrac{1}{\delta}	+ \widehat{\Psi}_{\pi,1}(\lambda,N) \right ] \}\\
             S_2\triangleq \{\omega\in\Omega|\forall\rho\in\mathcal{M}_\pi:\quad &E_{f\sim \hat{\rho}} V_N (f) \le  E_{f\sim \hat{\rho}} \hat{\mathcal{L}}_N(f) +\dfrac{1}{\lambda}\!\left[KL(\hat{\rho} \|\pi) + \ln\dfrac{1}{\delta}	+ \widehat{\Psi}_{\pi,2}(\lambda,N) \right ] \}
         \end{align}
         with $\bar{A}$ denoting the complementary set of $A$, i.e. $\bar{A}=\Omega\setminus A$
         \begin{align}
             P(\omega\in \bar{S}_1)<\delta\\
             P(\omega\in \bar{S}_2)<\delta\\
         \end{align}
         Thus by union bound we get
         \begin{align}
             P\left (\omega\in (\bar{S}_1 \cup \bar{S}_2)\right )<2\delta
         \end{align}
         and thus
          \begin{align}
             P\left (\omega\in (S_1 \cap S_2)\right )\geq 1-2\delta
         \end{align}
         with this we can write: with probability at least $1-2\delta$, the following holds
         \begin{align}
             \forall\rho\in\mathcal{M}_\pi:\quad &E_{f\sim \hat{\rho}} \mathcal{L} (f) \le  E_{f\sim \hat{\rho}} \hat{\mathcal{L}}_N(f) +\dfrac{2}{\lambda}\!\left[KL(\hat{\rho} \|\pi) + \ln\dfrac{1}{\delta}	+ \frac{\widehat{\Psi}_{\pi,2}(\lambda,N)+ \widehat{\Psi}_{\pi,1}(\lambda,N)}{2} \right ]  
         \end{align}
         In order to bring this to a more common way of writing PAC-Bayesian bounds, let us define $\tilde{\lambda}=0.5\lambda \leftrightarrow \lambda = 2\tilde{\lambda}$, thus we can write, for
         \begin{align}
             0<\tilde{\lambda} \leq \frac{1}{2}\Big ( \sup_{f\in\mathcal{F}} \max\{ 3(m+1) n_y \mu_{\max}(Q_e)G_e(f)^{2} , 4 n_w \bar{G}_{gen}  \bar{G}_f(f) \} \Big )^{-1}
         \end{align}with probability at least $1-2\delta$, the following holds
         \begin{align}
             \forall\rho\in\mathcal{M}_\pi:\quad &E_{f\sim \hat{\rho}} \mathcal{L} (f) \le  E_{f\sim \hat{\rho}} \hat{\mathcal{L}}_N(f) +\dfrac{1}{\tilde{\lambda}}\!\left[KL(\hat{\rho} \|\pi) + \ln\dfrac{1}{\delta}	+ \frac{\widehat{\Psi}_{\pi,2}(2\tilde{\lambda},N)+ \widehat{\Psi}_{\pi,1}(2\tilde{\lambda},N)}{2} \right ]  
         \end{align}
         with 
         \begin{align}
             \widehat{\Psi}_{\pi,1}(2\tilde{\lambda},N) = \Psi_{\pi,1}(\tilde{\lambda},N) = \ln E_{f\sim\pi} \left ( 1+\frac{2}{N}\frac{(m+1)! \left (6\tilde{\lambda} n_y\mu_{\max}(Q_e)G_e(f)^{2}\right )^2}{(1-6(m+1)\tilde{\lambda} n_y\mu_{\max}(Q_e)G_e(f)^{2})} \right )\\
             \widehat{\Psi}_{\pi,2}(2\tilde{\lambda},N) = \Psi_{\pi,2}(\tilde{\lambda},N) = \ln E_{f\sim\pi } \left ( 1+ \frac{(n_y+n_u)!}{\sqrt{N}} \frac{8 \tilde{\lambda} \bar{G}_{gen}  \bar{G}_f(f)}{1-8 \tilde{\lambda} (n_y+n_u)\bar{G}_{gen}  \bar{G}_f(f)} \right )
         \end{align}
     \end{Proof}
\end{lemma}




\subsection{Bounded noise}
In this section we state the lemmas and proofs associated with bounded innovation noise case.
\begin{lemma}\label{lemma:bounded_e_moments} Let $\e_g(t)\in \mathcal{E}\subset \mathbb{R}^{n_y+n_y}$, be a zero mean, independant, and bounded stochastic process, s.t. $|\e_{g,i}(t)|\leq c_e$, $\forall i\in \{1,\dots,nu+ny\}$, i.e $\e_{g,i}(t)$ is the $i$'th component of $\e_g(t)$
\begin{align}
    \bE[\|\e_g(t)\|^r]\leq  \left ( c_e \sqrt{n_y+n_u} \right )^r
\end{align}

\begin{Proof}
    \begin{align}
            \bE[\|\e_g(t)\|^r]=\bE\left [\left ( \sqrt{\sum_{i=1}^{nu+ny} \e_{g,i}^2(t)} \right)^r \right ] \leq \left ( \sqrt{\sum_{i=1}^{nu+ny} c_e^2} \right)^r = \left ( \sqrt{ (n_u+n_y) c_e^2} \right)^r = \left ( c_e \sqrt{n_y+n_u} \right )^r
    \end{align}
\end{Proof}
\end{lemma}


\begin{lemma}\label{lemma:bounded_sigmar} Let $\e_g(t)\in \mathcal{E}\subset \mathbb{R}^{n_y+n_y}$, be a zero mean, independant, and bounded stochastic process, s.t. $|\e_{g,i}(t)|\leq c_e$, $\forall i\in \{1,\dots,nu+ny\}$, i.e $\e_{g,i}(t)$ is the $i$'th component of $\e_g(t)$
    \begin{align}
        \sigma(r)= \left ( 2c_e^2 (n_y+n_u) \right )^r \geq \sup_{t,k,l} \bE[\|e(t,k,l)\|^r_2]\\
        e(t,k,l) = \bE[\e_g(t-k)\e_g^T(t-l)]-\e_g(t-k)\e_g^T(t-l)
    \end{align}
\begin{Proof}
 %    For the case of $k=l$, we have
 %    \begin{align}
 %        \bE\left [ \| \bE[\e_g(t-k)\e_g^T(t-l)]-\e_g(t-k)\e_g^T(t-l) \|^r \right ]
 %    \end{align}
 %        	Recall that
	% \begin{align*}
	% 	\e(t,k,j)=\begin{cases} Q_e-\e_g(t-k)\e_g^T(t-j),& k=j\\ -\e_g(t-k)\e_g^T(t-j),& k\neq j \end{cases}
	% \end{align*}
	First let us take the case when $k\neq j$. Then, due to independance of $\e_g(t)$, we have $\bE[\e_g(t-k)\e_g(t-j)]=0$, and thus
	\begin{align*}
		\bE[\|\e(t,k,l)\|_2^r]=\bE[\|-\e_g(t-k)\e_g^T(t-j)\|_2^r]
	\end{align*}
	Again as $\e_g(t)$ is i.i.d. we have 
	\begin{align*}
		\bE[\|\e(t,k,l)\|_2^r]\leq \bE[\left ( \|\e_g(t-k)\|_2\|\e_g^T(t-j)\|_2\right )^r] \leq  \bE[\|\e_g(t-k)\|_2^r]\bE[\|\e_g(t-j)\|_2^r]
	\end{align*}
	and due to stationarity of $\e_g(t)$, we have $\bE[\|\e_g(t-k)\|_2^r]=\bE[\|\e_g(t-j)\|_2^r]$, therefore
	\begin{align*}
		\bE[\|\e(t,k,l)\|_2^r]\leq \bE[\|\e_g(t)\|_2^r]^2
	\end{align*}
	and again due to stationarity of $\e_g(t)$, the moments do not depend on $t$, and using Lemma \ref{lemma:bounded_e_moments} we obtain
	\begin{align*}
	\forall k\neq j, \;	\bE[\|\e(t,k,l)\|_2^r] \leq  \left ( c_e^2 (n_y+n_u) \right )^r
	\end{align*}
	Now let us take the case when $k=j$. Then 
 \begin{align}
     \bE\left [ \| \bE[\e_g(t-k)\e_g^T(t-l)]-\e_g(t-k)\e_g^T(t-l) \|^r \right ] \leq \bE\left [ \left (  \| \bE[\e_g(t-k)\e_g^T(t-l)]\|+ \| \e_g(t-k)\e_g^T(t-l) \| \right )^r \right ]
 \end{align}
 By convexity $(a+b)^r = 2^r\frac{1}{2^r}(a+b)^r = 2^r\left (\frac{1}{2}(a+b) \right )^r \leq 2^{r-1}(a^r+b^r)$, we obtain
 \begin{align}
     \bE[\|\e(t,k,l)\|_2^r] \leq 2^{r-1} \left ( \bE\left [\| \bE[\e_g(t-k)\e_g^T(t-l)]\|^r \right ]+ \bE \left [ \| \e_g(t-k)\e_g^T(t-l) \|^r \right ] \right )\\
     =2^{r-1} \left ( \| \bE[\e_g(t-k)\e_g^T(t-l)]\|^r + \bE \left [ \| \e_g(t-k)\e_g^T(t-l) \|^r \right ] \right )\\
     \leq 2^{r-1} \left (  \bE[\|\e_g(t-k)\e_g^T(t-l)\|^r] + \bE \left [ \| \e_g(t-k)\e_g^T(t-l) \|^r \right ] \right )
     \leq 2^r \bE \left [ \| \e_g(t)\|^{2r} \right ]
 \end{align}
  Again by using Lemma \ref{lemma:bounded_e_moments}, we obtain
  \begin{align}
      \forall k=j \; \bE[\|\e(t,k,l)\|_2^r] \leq  \left ( 2c_e^2 (n_y+n_u) \right )^r
  \end{align}
  Thus we obtain the statement of the lemma 
    \begin{align}
        \forall t,k,j\; \bE[\|\e(t,k,l)\|_2^r] \leq \max \{ \left ( c_e^2 (n_y+n_u) \right )^r, \left ( 2c_e^2 (n_y+n_u) \right )^r \} = \left ( 2c_e^2 (n_y+n_u) \right )^r
    \end{align}
\end{Proof}

\end{lemma}




\begin{lemma}\label{lemma:bounded_mgf(L-V)} With notation as above, with $|\e_{g,i}|\leq c_e$, the following holds
    \begin{align}
        \bE[e^{\lambda(\mathcal{L}(f)-V_N(f))}]\leq 1+\frac{1}{N}e^{\lambda 4c_e^2n_y(n_y+n_u)G_e(f)^2}
    \end{align}



    \begin{Proof} By power series, and $\bE[\mathcal{L}(f)-V_N(f)]=0$, we have 
        \begin{align}
            \bE[e^{\lambda(\mathcal{L}(f)-V_N(f))}] = 1 + \sum_{r=2}^\infty \frac{\lambda^r}{r!} \bE[(\mathcal{L}(f)-V_N(f))^r]
        \end{align}
        Now by Lemma \ref{lemma:L-Vrfull}, and Lemma \ref{lemma:bounded_sigmar}, and $4(r-1)\leq 2^r$ we have
        \begin{align}
            \bE[(\mathcal{L}(f)-V_N(f))^r] \leq \frac{1}{N} (4c_e^2n_y(n_y+n_u)G_e(f)^2)^r 
        \end{align}
        Thus, 
        \begin{align}
            \bE[e^{\lambda(\mathcal{L}(f)-V_N(f))}] \leq 1 + \frac{1}{N} \sum_{r=2}^\infty \frac{1}{r!}  (\lambda 4c_e^2n_y(n_y+n_u)G_e(f)^2)^r 
        \end{align}
        now since $\lambda 4c_e^2n_y(n_y+n_u)G_e(f)^2\geq 0$, then
        \begin{align}
             1 + \frac{1}{N} \sum_{r=2}^\infty \frac{1}{r!}  (\lambda 4c_e^2n_y(n_y+n_u)G_e(f)^2)^r \\
             \leq 1 + \frac{1}{N} \sum_{r=0}^\infty \frac{1}{r!}  (\lambda 4c_e^2n_y(n_y+n_u)G_e(f)^2)^r\\
             = 1+\frac{1}{N}e^{\lambda 4c_e^2n_y(n_y+n_u)G_e(f)^2}
        \end{align}
    \end{Proof}
\end{lemma}

\begin{lemma}\label{lemma:bounded_mgf(V-hatL)}
With notation as above, with $|\e_{g,i}|\leq c_e$, the following holds
    \begin{align}
        \bE[e^{\lambda(V_N(f)-\hat{\mathcal{L}}(f))}]\leq 1+\frac{1}{\sqrt{N}}e^{2\lambda G_f(f) \|\Sigma_{gen}\|_{\ell_1}^2 c_e^2 (n_y+n_u)}
    \end{align}
    with 
    \begin{align}
        G_f(f)\triangleq \left (1+\|\hat{D}\|+ \frac{\hat{M}\|\hat{B}\|\|\hat{C}\|}{1-\hat{\gamma}} \right ) \left (\frac{\hat{M}\|\hat{C}\| \|\hat{B}\|}{(1-\hat{\gamma})^\frac{3}{2}} \right )
    \end{align}

    \begin{Proof}
        By power series, we have 
        \begin{align}
            \bE[e^{\lambda(V_N(f)-\hat{\mathcal{L}}(f))}]\leq \bE[e^{\lambda|V_N(f)-\hat{\mathcal{L}}(f)|}] = 1 + \sum_{r=1}^\infty \frac{\lambda^r}{r!} \bE[|V_N(f)-\hat{\mathcal{L}}(f)|^r]
        \end{align}
        For the terms $\bE[|V_N(f)-\hat{\mathcal{L}}_N(f)|^r]$, we reuse the proof of Lemma \ref{lemma:moments_|V-Lhat|}, and continue from \eqref{eq:moments_|V-Lhat|_pre_yw}, i.e.
        \begin{align}
        \bE[\|V_N(f)-\hat{\mathcal{L}}_N(f)\|^r] \leq \frac{2^{r}}{\sqrt{N}} \left (1+\|\hat{D}\|+ \frac{\hat{M}\|\hat{B}\|\|\hat{C}\|}{1-\hat{\gamma}} \right )^{r} \left (\frac{\hat{M}\|\hat{C}\| \|\hat{B}\|}{1-\hat{\gamma}} \right )^{r} \bE\left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix}\right \|^{2r} \right ]  \sqrt{\frac{1}{1-\hat{\gamma}^{2r}}}
    \end{align}
    Note that 
    \begin{align}
       \left ( 1-\hat{\gamma}\right )^\frac{r}{2} \leq  \left ( 1-\hat{\gamma}^{2r}\right )^{\frac{1}{2}}
    \end{align}
    it is easy to see since for $\hat{\gamma}\in [0,1)$, the following holds 
    \begin{align}
        \left ( 1-\hat{\gamma}\right )^r &\leq  1-\hat{\gamma}^{2r} = (1-\hat{\gamma}^r)(1+\hat{\gamma}^r)\\
        1 &\leq 1+\hat{\gamma}^r
    \end{align}
    This allows us to simplify the expression to
    \begin{align}
        \bE[\|V_N(f)-\hat{\mathcal{L}}_N(f)\|^r] \leq \frac{2^{r}}{\sqrt{N}} \left (1+\|\hat{D}\|+ \frac{\hat{M}\|\hat{B}\|\|\hat{C}\|}{1-\hat{\gamma}} \right )^{r} \left (\frac{\hat{M}\|\hat{C}\| \|\hat{B}\|}{1-\hat{\gamma}} \right )^{r} \bE\left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix}\right \|^{2r} \right ] \left ( \frac{1}{\sqrt{1-\hat{\gamma}}} \right )^r 
    \end{align}
    Now, from Lemma \ref{lemma:stationary4thMoment}, we get
    \begin{align}
        \bE\left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix}\right \|^{2r} \right ] \leq \|\Sigma_{gen}\|_{\ell_1}^{2r} \bE[\|\e_g(t)\|^{2r}]
    \end{align}
    by lemma \ref{lemma:bounded_e_moments}, we get
        \begin{align}
        \bE\left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix}\right \|^{2r} \right ] \leq \left ( \|\Sigma_{gen}\|_{\ell_1}^2 c_e^2 (n_y+n_u) \right )^r
    \end{align}
    Thus, with $G_f(f)\triangleq  \dfrac{1}{\sqrt{1-\hat{\gamma}}}\left (1+\|\hat{D}\|+ \frac{\hat{M}\|\hat{B}\|\|\hat{C}\|}{1-\hat{\gamma}} \right ) \left (\frac{\hat{M}\|\hat{C}\| \|\hat{B}\|}{1-\hat{\gamma}} \right )$
    \begin{align}
        \bE[\|V_N(f)-\hat{\mathcal{L}}_N(f)\|^r] \leq  \frac{1}{\sqrt{N}}   \left (2G_f(f) \|\Sigma_{gen}\|_{\ell_1}^2 c_e^2 (n_y+n_u) \right )^r 
    \end{align}
    Thus
    \begin{align}
        \bE[e^{\lambda|V_N(f)-\hat{\mathcal{L}}(f)|}] &\leq 1 + \frac{1}{\sqrt{N}} \sum_{r=1}^\infty \frac{1}{r!} \left (2\lambda G_f(f) \|\Sigma_{gen}\|_{\ell_1}^2 c_e^2 (n_y+n_u) \right )^r \\
        &\leq 1+\frac{1}{\sqrt{N}}e^{2\lambda G_f(f) \|\Sigma_{gen}\|_{\ell_1}^2 c_e^2 (n_y+n_u)}
        \end{align}
    and therefore the statement of the lemma holds.
    \end{Proof}
    
\end{lemma}

\begin{Corollary} \label{cor:thm:bounded}
    By lemma \ref{lemma:PAC-BayesianKL_General}, lemmas \ref{lemma:bounded_mgf(L-V)},\ref{lemma:bounded_mgf(V-hatL)}, and by applying a union bound, we obtain, for $\lambda>0$, $\delta\in[0,1)$, the set of absolutely continuous probability density functions $\mathcal{M}_\pi$ w.r.t. $\pi$, the following holds with probability at least $1-2\delta$
    \begin{align}
        \forall \rho\in\mathcal{M}_\pi:\quad E_{f\sim\rho} \mathcal{L}(f) \leq E_{f\sim\rho }\hat{\mathcal{L}}_N(f) + \frac{1}{\lambda}\left [\KL(\rho||\pi)+\ln\left (\frac{1}{\delta}\right ) + \widehat{\Psi}_{c_e,\pi}(\lambda,N)\right ]
    \end{align}
    with 
    \begin{align}
        \widehat{\Psi}_{c_e,\pi}(\lambda,N) \triangleq \frac{1}{2} \left ( \widehat{\Psi}_{c_e,\pi,1}(\lambda,N)+\widehat{\Psi}_{c_e,\pi,2}(\lambda,N)\right )\\
        \widehat{\Psi}_{c_e,\pi,1}(\lambda,N) \triangleq \ln E_{f\sim\pi } \left ( 1+\frac{1}{N}e^{\lambda 4c_e^2n_y(n_y+n_u)G_e(f)^2} \right )\\
        \widehat{\Psi}_{c_e,\pi,2}(\lambda,N) \triangleq \ln E_{f\sim\pi } \left (1+\frac{1}{\sqrt{N}}e^{2\lambda G_f(f) \|\Sigma_{gen}\|_{\ell_1}^2 c_e^2 (n_y+n_u)} \right )
    \end{align}
\end{Corollary}



% \begin{lemma}\label{lemma:bounded_L-Vrfull} Let $\e_g(t)\in \mathcal{E}\subset \mathbb{R}^{n_y+n_y}$, be a zero mean, i.i.d., and bounded stochastic process, s.t. $|\e_{g,i}(t)|\leq c_e$, $\forall i\in \{1,\dots,nu+ny\}$, i.e $\e_{g,i}(t)$ the $i$'th component of $\e_g(t)$ is bounded by $c_e$
%     \begin{align}
%         \bE[e^{\lambda(\mathcal{L}(f)-\hat{\mathcal{L}}_N(f))}] 
%         \leq 1+ \frac{1}{2N} e^{\lambda G_{gen,1} G_e(f)^{2}} + \frac{1}{2\sqrt{N}} e^{\lambda G_f(f) G_{gen,2}}
%     \end{align}
%     with 
%     \begin{align}
%         G_{gen,1}&\triangleq 8c_e^2 n_y (n_y+n_u) \\
%         G_{gen,2}&\triangleq 4  c_e^2 (n_y+n_u) \|\Sigma_{gen}\|_{\ell_1}^2\\
%         \|\Sigma_{gen}\|_{\ell_1}&=1+\sum_{k=0}^\infty \|C_gA_g^{k-1}K_g\|_2\\
%         G_f(f)&\triangleq  \dfrac{1}{\sqrt{1-\hat{\gamma}}}\left (1+\|\hat{D}\|+ \frac{\hat{M}\|\hat{B}\|\|\hat{C}\|}{1-\hat{\gamma}} \right ) \left (\frac{\hat{M}\|\hat{C}\| \|\hat{B}\|}{1-\hat{\gamma}} \right )
%     \end{align}


%     \begin{Proof}
%         Notice that 
%         \begin{align}
%             (\mathcal{L}(f)-\hat{\mathcal{L}}_N(f))^r=( (\mathcal{L}(f)-V_N(f))+(V_N(f)-\hat{\mathcal{L}}_N(f) ) )^r
%         \end{align}
%         By convexity argument we obtain 
%        \begin{align}
%             (\mathcal{L}(f)-\hat{\mathcal{L}}_N(f))^r\leq 2^{r-1}\left ( (\mathcal{L}(f)-V_N(f))^r+(V_N(f)-\hat{\mathcal{L}}_N(f) )^r \right )\\
%             \leq 2^{r-1}\left ( (\mathcal{L}(f)-V_N(f))^r+|V_N(f)-\hat{\mathcal{L}}_N(f) |^r \right )
%         \end{align}
%         Thus 
%         \begin{align}
%             \bE\left [(\mathcal{L}(f)-\hat{\mathcal{L}}_N(f))^r \right ] \leq 2^{r-1} \left ( \bE\left [(\mathcal{L}(f)-V_N(f))^r \right ] + \bE\left [|V_N(f)-\hat{\mathcal{L}}_N(f) |^r \right ] \right )
%         \end{align}
%         Now if we express the moment generating function as
%         \begin{align}
%             \bE[e^{\lambda(\mathcal{L}(f)-\hat{\mathcal{L}}_N(f))}] &\leq 1+ \sum_{r=1}^\infty \frac{\lambda^r}{r!} \bE[(\mathcal{L}(f)-\hat{\mathcal{L}}_N(f))^r]\\
%             &\leq 1+ \frac{1}{2}\sum_{r=1}^\infty \frac{(2\lambda)^r}{r!} \left ( \bE\left [(\mathcal{L}(f)-V_N(f))^r \right ] + \bE\left [|V_N(f)-\hat{\mathcal{L}}_N(f) |^r \right ] \right )\\
%             &=1+ \frac{1}{2}\sum_{r=1}^\infty \frac{(2\lambda)^r}{r!} \bE\left [(\mathcal{L}(f)-V_N(f))^r \right ] + \frac{1}{2}\sum_{r=1}^\infty \frac{(2\lambda)^r}{r!}\bE\left [|V_N(f)-\hat{\mathcal{L}}_N(f) |^r \right ]
%         \end{align}
%         Note that $\bE\left [(\mathcal{L}(f)-V_N(f)) \right ]=0$, and thus
%         \begin{align}
%             \bE[e^{\lambda(\mathcal{L}(f)-\hat{\mathcal{L}}_N(f))}] 
%             \leq 1+ \frac{1}{2}\sum_{r=2}^\infty \frac{(2\lambda)^r}{r!} \bE\left [(\mathcal{L}(f)-V_N(f))^r \right ] + \frac{1}{2}\sum_{r=1}^\infty \frac{(2\lambda)^r}{r!}\bE\left [|V_N(f)-\hat{\mathcal{L}}_N(f) |^r \right ]
%         \end{align}
%         Now let us focus on $\bE\left [(\mathcal{L}(f)-V_N(f))^r \right ]$.
%         Using Lemma \ref{lemma:L-Vr}, and Lemma \ref{lemma:bounded_sigmar}, we have 
%         \begin{align}
%             \bE[(\mathcal{L}(f)-V_{N}(f))^r] &\leq \frac{1}{N}\left ( 2c_e^2 n_y (n_y+n_u) G_e(f)^{2} \right )^r 4(r-1)
%         \end{align}
%         note $4(r-1)\leq 2^r$, thus
%         \begin{align}
%             \bE[(\mathcal{L}(f)-V_{N}(f))^r] &\leq \frac{1}{N}\left ( 4c_e^2 n_y (n_y+n_u) G_e(f)^{2} \right )^r 
%         \end{align}
%         Now we can focus on the infinite sum
%         \begin{align}
%             \sum_{r=2}^\infty \frac{(2\lambda)^r}{r!} \bE\left [(\mathcal{L}(f)-V_N(f))^r \right ] \leq \frac{1}{N} \sum_{r=2}^\infty \frac{1}{r!} \left ( 8\lambda c_e^2 n_y (n_y+n_u) G_e(f)^{2} \right )^r 
%         \end{align}
%         since $8\lambda c_e^2 n_y (n_y+n_u) G_e(f)^{2}\geq 0$, and with $G_{gen,1}\triangleq 8c_e^2 n_y (n_y+n_u) $, we obtain
%         \begin{align}
%              \frac{1}{N} \sum_{r=2}^\infty \frac{1}{r!} \left ( \lambda G_{gen,1} G_e(f)^{2} \right )^r \leq \frac{1}{N} \sum_{r=0}^\infty \frac{1}{r!} \left ( \lambda G_{gen,1} G_e(f)^{2} \right )^r = \frac{1}{N} e^{\lambda G_{gen,1} G_e(f)^{2}}
%         \end{align}


%         For the terms $\bE[|V_N(f)-\hat{\mathcal{L}}_N(f)|^r]$, we reuse the proof of Lemma \ref{lemma:moments_|V-Lhat|}, and continue from \eqref{eq:moments_|V-Lhat|_pre_yw}, i.e.
%         \begin{align}
%         \bE[\|V_N(f)-\hat{\mathcal{L}}_N(f)\|^r] \leq \frac{2^{r}}{\sqrt{N}} \left (1+\|\hat{D}\|+ \frac{\hat{M}\|\hat{B}\|\|\hat{C}\|}{1-\hat{\gamma}} \right )^{r} \left (\frac{\hat{M}\|\hat{C}\| \|\hat{B}\|}{1-\hat{\gamma}} \right )^{r} \bE\left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix}\right \|^{2r} \right ]  \sqrt{\frac{1}{1-\hat{\gamma}^{2r}}}
%     \end{align}
%     Note that 
%     \begin{align}
%        \left ( 1-\hat{\gamma}\right )^\frac{r}{2} \leq  \left ( 1-\hat{\gamma}^{2r}\right )^{\frac{1}{2}}
%     \end{align}
%     it is easy to see since for $\hat{\gamma}\in [0,1)$, the following holds 
%     \begin{align}
%         \left ( 1-\hat{\gamma}\right )^r &\leq  1-\hat{\gamma}^{2r} = (1-\hat{\gamma}^r)(1+\hat{\gamma}^r)\\
%         1 &\leq 1+\hat{\gamma}^r
%     \end{align}
%     This allows us to simplify the expression to
%     \begin{align}
%         \bE[\|V_N(f)-\hat{\mathcal{L}}_N(f)\|^r] \leq \frac{2^{r}}{\sqrt{N}} \left (1+\|\hat{D}\|+ \frac{\hat{M}\|\hat{B}\|\|\hat{C}\|}{1-\hat{\gamma}} \right )^{r} \left (\frac{\hat{M}\|\hat{C}\| \|\hat{B}\|}{1-\hat{\gamma}} \right )^{r} \bE\left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix}\right \|^{2r} \right ] \left ( \frac{1}{\sqrt{1-\hat{\gamma}}} \right )^r 
%     \end{align}
%     Now, from Lemma \ref{lemma:stationary4thMoment}, we get
%     \begin{align}
%         \bE\left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix}\right \|^{2r} \right ] \leq \|\Sigma_{gen}\|_{\ell_1}^{2r} \bE[\|\e_g(t)\|^{2r}]
%     \end{align}
%     by lemma \ref{lemma:bounded_e_moments}, we get
%         \begin{align}
%         \bE\left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix}\right \|^{2r} \right ] \leq \left ( \|\Sigma_{gen}\|_{\ell_1}^2 c_e^2 (n_y+n_u) \right )^r
%     \end{align}
%     Thus, with $G_f(f)\triangleq  \dfrac{1}{\sqrt{1-\hat{\gamma}}}\left (1+\|\hat{D}\|+ \frac{\hat{M}\|\hat{B}\|\|\hat{C}\|}{1-\hat{\gamma}} \right ) \left (\frac{\hat{M}\|\hat{C}\| \|\hat{B}\|}{1-\hat{\gamma}} \right )$
%     \begin{align}
%         \bE[\|V_N(f)-\hat{\mathcal{L}}_N(f)\|^r] \leq \frac{2^{r}}{\sqrt{N}} G_f^r(f) \left ( \|\Sigma_{gen}\|_{\ell_1}^2 c_e^2 (n_y+n_u) \right )^r  \\
%         = \frac{1}{\sqrt{N}}   \left (2G_f(f) \|\Sigma_{gen}\|_{\ell_1}^2 c_e^2 (n_y+n_u) \right )^r 
%     \end{align}
%     Notice that 
%     Now 
%     \begin{align}
%         \sum_{r=1}^\infty \frac{(2\lambda)^r}{r!}\bE\left [|V_N(f)-\hat{\mathcal{L}}_N(f) |^r \right ] \leq \frac{1}{\sqrt{N} } \sum_{r=1}^\infty \frac{1}{r!}  \left (4 \lambda G_f(f) \|\Sigma_{gen}\|_{\ell_1}^2 c_e^2 (n_y+n_u) \right )^r 
%     \end{align}
%     since $4 \lambda G_f(f) \|\Sigma_{gen}\|_{\ell_1}^2 c_e^2 (n_y+n_u) \geq 0$, and with $G_{gen,2}\triangleq 4 \|\Sigma_{gen}\|_{\ell_1}^2 c_e^2 (n_y+n_u) $ we get
%     \begin{align}
%          \frac{1}{\sqrt{N} } \sum_{r=1}^\infty \frac{1}{r!}  \left ( \lambda G_f(f) G_{gen,2}   \right )^r \leq \frac{1}{\sqrt{N} } \sum_{r=0}^\infty \frac{1}{r!}  \left (\lambda G_f(f) G_{gen,2} \right )^r = \frac{1}{\sqrt{N}} e^{\lambda G_f(f) G_{gen,2}}
%     \end{align}
%     Now bringing everything back together we obtain
%     \begin{align}
%         \bE[e^{\lambda(\mathcal{L}(f)-\hat{\mathcal{L}}_N(f))}] 
%         \leq 1+ \frac{1}{2N} e^{\lambda G_{gen,1} G_e(f)^{2}} + \frac{1}{2\sqrt{N}} e^{\lambda G_f(f) G_{gen,2}}
%     \end{align}
    

%     \end{Proof}
% \end{lemma}



\subsection{Bounded innovation noise case: Alternative formulation}

\begin{lemma}\label{lem:repeatedCauchy}
    for a sequence of random variables $x_j\in\mathbb{R}$, and $j\in\{1,\dots,r\}$
    \begin{align}
        \bE\left [\prod_{j=1}^r x_j \right ] \leq \left ( \prod_{j=1}^{r-1} \bE \left [ x_j^{(2^j)} \right ]^{(2^{-j})} \right ) \bE \left [ x_r^{(2^{r-1})} \right ]^{2^{-(r-1)}}
    \end{align}

\end{lemma}
\begin{Proof}[of Lemma \ref{lem:repeatedCauchy}]
\renewcommand{\bE}[1]{\mathbf{E}\left [ #1 \right ]}
We first apply Cauchy-Schwarz inequality $\bE{\prod_{j=1}^r x_j}\leq |\bE{\prod_{j=1}^r x_j}| =|\bE{\left ( x_1 \right ) \left ( \prod_{j=2}^r x_j \right )}| \leq \sqrt{\bE{x_1^2}}\sqrt{\bE{\prod_{j=2}^r x_j^2}}$, and obtain
\begin{align}
    \bE{\prod_{j=1}^r x_j} \leq \bE{x_j^2 }^{2^{-1}}\bE{\prod_{j=2}^r x_j^2 }^{2^{-1}}
\end{align}
Then we apply Cauchy-Schwarz again
\begin{align}
    \bE{\prod_{j=1}^r x_j} \leq \bE{x_1^2 }^{2^{-1}}\bE{x_2^{(2^2)} }^{2^{-2}}\bE{\prod_{j=3}^r x_j^{(2^2)} }^{2^{-2}} = \prod_{j=1}^2 \bE{x_j^{(2^j)}}^{(2^{-j})} \bE{\prod_{j=2+1}^r x_j^{(2^2)} }^{2^{-2}}
\end{align}
We repeat this process until we have
\begin{align}
    \bE{\prod_{j=1}^r x_j} \leq \prod_{j=1}^{r-2} \bE{x_j^{(2^j)}}^{(2^{-j})} \bE{x_{r-1}^{(2^{r-2})} x_r^{(2^{r-2})} }^{2^{-(r-2)}}
\end{align}
Then we apply the final Cauchy-Schwarz inequality and obtain the statement of the lemma
\begin{align}
    \bE{\prod_{j=1}^r x_j} &\leq \prod_{j=1}^{r-2} \bE{x_j^{(2^j)}}^{(2^{-j})} \bE{x_{r-1}^{(2^{r-1})} }^{2^{-(r-1)}}\bE{x_r^{(2^{r-1})} }^{2^{-(r-1)}}\\
    &=\prod_{j=1}^{r-1} \bE{x_j^{(2^j)}}^{(2^{-j})} \bE{x_r^{(2^{r-1})} }^{2^{-(r-1)}}
\end{align}

    
\end{Proof}

\begin{lemma} \label{lemma:newE|V-Lhat|^r}
Let $m=n_y+n_u$. If $|e_g(t)| < c_e$, then 
        \begin{align}
         \bE[\|V_N(f)-\hat{\mathcal{L}}_N(f)\|^r] \leq  \bar{G}_{f,1}(f) \|\Sigma_{gen}\|_{\ell_1} (c_e\sqrt{m}) \left (\frac{2\|\Sigma_{gen}\|_{\ell_1}(c_e\sqrt{m})}{N} \bar{G}_{f,2}(f) \right )^r
    \end{align}
    where 
    $\bar{G}_{f,1}(f)\triangleq \left (  \frac{\hat{M} \| \hat{C} \| \|\hat{B}\|}{1-\hat{\gamma}} \right ) $, and $\bar{G}_{f,2}(f)\triangleq \left (1+\|\hat{D}\|+ \frac{\hat{M}\|\hat{B}\|\|\hat{C}\|}{1-\hat{\gamma}} \right ) \frac{1}{1-\hat{\gamma}}$
    %\begin{align}   
    %     \left (  \frac{4\bar{G}_f(f)\|\Sigma_{gen}\|_{\ell_1}^{3} (c_e \sqrt{m}) }{N} \right )^{r} ,
    %\end{align}
    %    with 
    %\begin{align}
        %\bar{G}_f(f)&\triangleq \frac{1}{1-\hat{\gamma}}\left (  \frac{\hat{M} \| \hat{C} \| \|\hat{B}\|}{1-\hat{\gamma}} \right )\left (1+\|\hat{D}\|+ \frac{\hat{M}\|\hat{B}\|\|\hat{C}\|}{1-%\hat{\gamma}} \right ),\\
        \( \|\Sigma_{gen}\|_{\ell_1}\triangleq\|I\|+\sum_{k=1}^\infty \|C_gA_g^{k-1}K_g\| \).
    %\end{align}
\end{lemma}


\begin{Proof}[of Lemma \ref{lemma:newE|V-Lhat|^r}]
        with $\z_\infty(t)=\y(t)-\hat{\y}_f(t)$, and $\z_f(t)=\y(t)-\hat{\y}_f(t|0)$, we start by applying triangle inequalities
    \begin{multline}
        \bE[\|V_N(f)-\hat{\mathcal{L}}_N(f)\|^r] = \bE \left [\left | \frac{1}{N}\sum_{t=0}^{N-1} \|\z_\infty(t)\|^2-\|\z_f(t)\|^2   \right |^r \right ] \leq \bE \left [ \left (  \frac{1}{N}\sum_{t=0}^{N-1} \left | \|\z_\infty(t)\|^2-\|\z_f(t)\|^2   \right | \right )^r \right ]
    \end{multline}
    \begin{align}
        \bE[\|V_N(f)-\hat{\mathcal{L}}_N(f)\|^r] \leq \frac{1}{N^r} \sum_{t_1=0}^{N-1} \dots \sum_{t_r=0}^{N-1} \bE \left [  \prod_{j=1}^r \left | \|\z_\infty(t_j)\|^2-\|\z_f(t_j)\|^2 \right |\right ]
    \end{align}
    Now using the fact that $|a^2-b^2|=|(a-b)(a+b)| = |a-b|(a+b)$, since $a,b\geq 0$, we get
    \begin{align}
        \bE[\|V_N(f)-\hat{\mathcal{L}}_N(f)\|^r] \leq \frac{1}{N^r} \sum_{t_1=0}^{N-1} \dots \sum_{t_r=0}^{N-1} \bE \left [  \prod_{j=1}^r \left | \|\z_\infty(t_j)\|-\|\z_f(t_j)\| \right |\left ( \|\z_\infty(t_j)\|+\|\z_f(t_j)\| \right ) \right ]
    \end{align}
    We apply Cauchy-Schwarz, i.e. $\bE[XY]\leq |\bE[XY]| \leq \sqrt{\bE[X^2]} \sqrt{\bE[Y^2]}$, with $X=\prod_{j=1}^r \left | \|\z_\infty(t_j)\|-\|\z_f(t_j)\| \right |$, and $Y=\prod_{j=1}^r \left ( \|\z_\infty(t_j)\|+\|\z_f(t_j)\| \right )$, 
    \begin{align}
        \bE[\|V_N(f)-\hat{\mathcal{L}}_N(f)\|^r] \leq \frac{1}{N^r} \sum_{t_1=0}^{N-1} \dots \sum_{t_r=0}^{N-1} \sqrt{\bE \left [  \prod_{j=1}^r \left | \|\z_\infty(t_j)\|-\|\z_f(t_j)\| \right |^2 \right ] } \sqrt{\bE \left [ \prod_{j=1}^r \left ( \|\z_\infty(t_j)\|+\|\z_f(t_j)\| \right )^2 \right ]} \label{eq:ASDFH}
    \end{align}
    For now let's focus on $\bE \left [  \prod_{j=1}^r \left | \|\z_\infty(t_j)\|-\|\z_f(t_j)\| \right |^2 \right ]$, by applying reverse triangle inequality we obtain
    \begin{align}
        \bE \left [  \prod_{j=1}^r \left | \|\z_\infty(t_j)\|-\|\z_f(t_j)\| \right |^2 \right ] \leq \bE \left [  \prod_{j=1}^r  \|\z_\infty(t_j)-\z_f(t_j)\|^2 \right ]
    \end{align}
    For the ease of notation for the next step, let us define $x_j\triangleq \|\z_\infty(t_j)-\z_f(t_j)\|^2$, then the quantity of interest is
    \begin{align}
        \bE \left [  \prod_{j=1}^r  x_j \right ]
    \end{align}
    For the above quantity we can apply Lemma \ref{lem:repeatedCauchy}, which states
    \begin{align}
        \bE\left [\prod_{j=1}^r x_j \right ] \leq \prod_{j=1}^{r-1} \bE \left [ x_j^{(2^j)} \right ]^{(2^{-j})} \bE \left [ x_r^{(2^{r-1})} \right ]^{2^{-(r-1)}}
    \end{align}
    From Lemma \ref{lemma:E|zinf-zf|^r}, we also know that
    \begin{align}
        \bE[\|\z_\infty(t)-\z_f(t)\|^r] \leq \hat{\gamma}^{rt}\left (  \frac{\hat{M} \| \hat{C} \| \|\hat{B}\|}{1-\hat{\gamma}} \right )^r \bE \left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix} \right \|^r \right ] 
    \end{align}
    Thus combining Lemma \ref{lem:repeatedCauchy} and Lemma \ref{lemma:E|zinf-zf|^r}, we get 
    \begin{multline}
        \bE \left [  \prod_{j=1}^r  \|\z_\infty(t_j)-\z_f(t_j)\|^2 \right ] \leq \prod_{j=1}^{r-1} \hat{\gamma}^{2t_j} \left (  \frac{\hat{M} \| \hat{C} \| \|\hat{B}\|}{1-\hat{\gamma}} \right )^2 \bE \left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix} \right \|^{(2^{j+1})} \right ]^\frac{1}{2^j} \\
        \times \hat{\gamma}^{2t_r} \left (  \frac{\hat{M} \| \hat{C} \| \|\hat{B}\|}{1-\hat{\gamma}} \right )^2 \bE \left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix} \right \|^{(2^{r})} \right ]^\frac{1}{2^{r-1}}
    \end{multline}
    with Lemma \ref{lemma:E|yw|^r}, and Lemma \ref{lemma:bounded_e_moments}, we have 
    \begin{align}
        \bE\left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix}\right \|^{r} \right ] \leq \|\Sigma_{gen}\|_{\ell_1}^{r} (c_e\sqrt{m})^r,
    \end{align}
    thus we get 
    \begin{multline}
        \bE \left [  \prod_{j=1}^r  \|\z_\infty(t_j)-\z_f(t_j)\|^2 \right ] \leq \prod_{j=1}^{r-1} \hat{\gamma}^{2t_j} \left (  \frac{\hat{M} \| \hat{C} \| \|\hat{B}\|}{1-\hat{\gamma}} \right )^2  \left ( \|\Sigma_{gen}\|_{\ell_1}^{2^{j+1}} (c_e\sqrt{m})^{2^{j+1}} \right )^{2^{-j}} \\
        \cdot \hat{\gamma}^{2t_r} \left (  \frac{\hat{M} \| \hat{C} \| \|\hat{B}\|}{1-\hat{\gamma}} \right )^2  \left ( \|\Sigma_{gen}\|_{\ell_1}^{2r} (c_e\sqrt{m})^{2r} \right )^{2^{-(r-1)}},
    \end{multline}
    With some algebraic simplification we obtain the first term
    \begin{align}
        \bE \left [  \prod_{j=1}^r  \|\z_\infty(t_j)-\z_f(t_j)\|^2 \right ] \leq \left (  \frac{\hat{M} \| \hat{C} \| \|\hat{B}\|}{1-\hat{\gamma}} \right )^2 \|\Sigma_{gen}\|_{\ell_1}^{2} (c_e\sqrt{m})^{2}   \prod_{j=1}^{r} \hat{\gamma}^{2t_j},
    \end{align}

    Now for the second term $\bE \left [ \prod_{j=1}^r \left ( \|\z_\infty(t_j)\|+\|\z_f(t_j)\| \right )^2 \right ]$, we apply the inequality of arithmetic-geometric means
    \begin{align}
        \bE \left [ \prod_{j=1}^r \left ( \|\z_\infty(t_j)\|+\|\z_f(t_j)\| \right )^2 \right ] \leq \frac{1}{r} \sum_{j=1}^r \bE\left [ \left ( \|\z_\infty(t_j)\|+\|\z_f(t_j)\| \right )^{2r}\right ]
    \end{align}
    By Lemma \ref{lemma:(a+b)^2r}, we obtain
    \begin{align}
        \frac{1}{r} \sum_{j=1}^r \bE\left [ \left ( \|\z_\infty(t_j)\|+\|\z_f(t_j)\| \right )^{2r}\right ] \leq \frac{2^{2r-1}}{r} \sum_{j=1}^r  \left ( \bE\left [ \|\z_\infty(t_j)\|^{2r} \right] + \bE\left [ \|\z_f(t_j)\|^{2r} \right ] \right )
    \end{align}

    By Lemma \ref{lemma:E|z_inf|^r} and Lemma \ref{lemma:E|z_f|^r}, we obtain
    \begin{align}
         \frac{2^{2r-1}}{r} \sum_{j=1}^r  \left ( \bE\left [ \|\z_\infty(t_j)\|^{2r} \right] + \bE\left [ \|\z_f(t_j)\|^{2r} \right ] \right ) &\leq \frac{2^{2r}}{r} \sum_{j=1}^r \left (1+\|\hat{D}\|+ \frac{\hat{M}\|\hat{B}\|\|\hat{C}\|}{1-\hat{\gamma}} \right )^{2r} \bE\left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix}\right \|^{2r} \right ]\\
         &=2^{2r} \left (1+\|\hat{D}\|+ \frac{\hat{M}\|\hat{B}\|\|\hat{C}\|}{1-\hat{\gamma}} \right )^{2r} \bE\left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix}\right \|^{2r} \right ] 
    \end{align}
        with Lemma \ref{lemma:E|yw|^r}, and Lemma \ref{lemma:bounded_e_moments}, we have 
    \begin{align}
        \bE\left [ \left \|\begin{bmatrix} \y(t) \\ \mathbf{u}(t) \end{bmatrix}\right \|^{r} \right ] \leq \|\Sigma_{gen}\|_{\ell_1}^{r} (c_e\sqrt{m})^r,
    \end{align}
    we get
    \begin{align}
        \bE \left [ \prod_{j=1}^r \left ( \|\z_\infty(t_j)\|+\|\z_f(t_j)\| \right )^2 \right ] \leq \left ( 2\|\Sigma_{gen}\|_{\ell_1}(c_e\sqrt{m})\left (1+\|\hat{D}\|+ \frac{\hat{M}\|\hat{B}\|\|\hat{C}\|}{1-\hat{\gamma}} \right )  \right )^{2r}   \label{eq:ASDGDSFHG}
    \end{align}

    
    Now taking \eqref{eq:ASDGDSFHG} and \eqref{eq:aslkjgdsaf} back to \eqref{eq:ASDFH}, we have

    \begin{multline}
        \bE[\|V_N(f)-\hat{\mathcal{L}}_N(f)\|^r] \leq \frac{1}{N^r} \sum_{t_1=0}^{N-1} \dots \sum_{t_r=0}^{N-1} \sqrt{\bE \left [  \prod_{j=1}^r \left | \|\z_\infty(t_j)\|-\|\z_f(t_j)\| \right |^2 \right ] } \sqrt{\bE \left [ \prod_{j=1}^r \left ( \|\z_\infty(t_j)\|+\|\z_f(t_j)\| \right )^2 \right ]} \\
        \leq \frac{1}{N^r} \sum_{t_1=0}^{N-1} \dots \sum_{t_r=0}^{N-1} \sqrt{\left (  \frac{\hat{M} \| \hat{C} \| \|\hat{B}\|}{1-\hat{\gamma}} \right )^2 \|\Sigma_{gen}\|_{\ell_1}^{2} (c_e\sqrt{m})^{2}   \prod_{j=1}^{r} \hat{\gamma}^{2t_j}} \\
        \cdot \sqrt{\left ( 2\|\Sigma_{gen}\|_{\ell_1}(c_e\sqrt{m})\left (1+\|\hat{D}\|+ \frac{\hat{M}\|\hat{B}\|\|\hat{C}\|}{1-\hat{\gamma}} \right )  \right )^{2r} }
    \end{multline}
    with $G_f(f)\triangleq\left (  \frac{\hat{M} \| \hat{C} \| \|\hat{B}\|}{1-\hat{\gamma}} \right )\left (1+\|\hat{D}\|+ \frac{\hat{M}\|\hat{B}\|\|\hat{C}\|}{1-\hat{\gamma}} \right )$
    \begin{multline}
        \bE[\|V_N(f)-\hat{\mathcal{L}}_N(f)\|^r] \leq \left (  \frac{\hat{M} \| \hat{C} \| \|\hat{B}\|}{1-\hat{\gamma}} \right ) \|\Sigma_{gen}\|_{\ell_1} (c_e\sqrt{m}) \left ( 2\|\Sigma_{gen}\|_{\ell_1}(c_e\sqrt{m})\left (1+\|\hat{D}\|+ \frac{\hat{M}\|\hat{B}\|\|\hat{C}\|}{1-\hat{\gamma}} \right )  \right )^{r} \\
        \cdot \frac{1}{N^r} \sum_{t_1=0}^{N-1} \dots \sum_{t_r=0}^{N-1}\prod_{j=1}^{r} \hat{\gamma}^{t_j}
    \end{multline}
    Note that $\left (\sum_{t=0}^{N-1} \hat{\gamma}^t\right )^r = \sum_{t_1=0}^{N-1}\dots\sum_{t_r=0}^{N-1}\prod_{j=1}^r \hat{\gamma}^{t_j}$, and by applying the sum of the geometric series we obtain 
    \begin{multline}
         \bE[\|V_N(f)-\hat{\mathcal{L}}_N(f)\|^r] \leq   \left (  \frac{\hat{M} \| \hat{C} \| \|\hat{B}\|}{1-\hat{\gamma}} \right ) \|\Sigma_{gen}\|_{\ell_1} (c_e\sqrt{m}) \left ( 2\|\Sigma_{gen}\|_{\ell_1}(c_e\sqrt{m})\left (1+\|\hat{D}\|+ \frac{\hat{M}\|\hat{B}\|\|\hat{C}\|}{1-\hat{\gamma}} \right )  \right )^{r}\\
         \cdot \left ( \frac{1-\hat{\gamma}^N}{N(1-\hat{\gamma})} \right )^r
    \end{multline}
    Note that $1-\hat{\gamma}^N\leq 1$, so with $\bar{G}_{f,1}(f)\triangleq \left (  \frac{\hat{M} \| \hat{C} \| \|\hat{B}\|}{1-\hat{\gamma}} \right ) $, and $\bar{G}_{f,2}(f)\triangleq \left (1+\|\hat{D}\|+ \frac{\hat{M}\|\hat{B}\|\|\hat{C}\|}{1-\hat{\gamma}} \right ) \frac{1}{1-\hat{\gamma}}$ the statement of the lemma follows.    
\end{Proof}
\begin{lemma} \label{lemma:mgf(Vn-hatL:alt)} With notation as above the  following holds
    \begin{align}
        \bE[e^{\lambda|V_N(f)-\hat{\mathcal{L}}_N(f)|}]\leq 1
         + \bar{G}_{f,1}(f) \|\Sigma_{gen}\|_{\ell_1} (c_e\sqrt{m})
        \sum_{r=1}^{\infty} \frac{\left (\lambda \frac{2\|\Sigma_{gen}\|_{\ell_1}(c_e\sqrt{m})}{N} \bar{G}_{f,2}(f) \right )^r}{r!} \\
       =(1-\bar{G}_{f,1}(f) \|\Sigma_{gen}\|_{\ell_1} (c_e\sqrt{m}))+ \bar{G}_{f,1}(f) \|\Sigma_{gen}\|_{\ell_1} (c_e\sqrt{m}) e^{\lambda \frac{2\|\Sigma_{gen}\|_{\ell_1}(c_e\sqrt{m})}{N} \bar{G}_{f,2}(f)}
    \nonumber 
    \end{align}
\end{lemma}
\begin{Proof}[of Lemma \ref{lemma:mgf(Vn-hatL)}]
    with $X=\lambda |V_N(f) - \hat{\mathcal{L}}_N(f)|$
    \begin{align}
        \bE[e^{\lambda(V_N(f)-\hat{\mathcal{L}}_N(f))}] = 1+\sum_{r=1}^\infty \frac{\lambda^r}{r!} \bE[|V_N(f)-\hat{\mathcal{L}}_N(f)|^r] \leq 1+ \sum_{r=1}^\infty \frac{\lambda^r}{r!} \left (\frac{2\|\Sigma_{gen}\|_{\ell_1}(c_e\sqrt{m})}{N} \bar{G}_{f,2}(f) \right )^r    
    \end{align}

\end{Proof}

\begin{lemma}[Alternative bound using \cite{alquier2012pred}]
\label{cor:KL(L-V):alt2}
With probability at least $1-\delta$, the following holds
    \begin{align}
         \forall\rho:\quad &E_{f\sim \hat{\rho}} \mathcal{L} (f) \le \  E_{f\sim \hat{\rho}} V_N(f) +\dfrac{1}{\lambda}\!\left[\KL(\hat{\rho} \|\pi) + \ln\dfrac{1}{\delta}	+ \Psi_{\pi,2}(\lambda,N) \right ],
    \end{align}
      with
    \begin{equation}
        \Psi_{\pi,2}(\lambda,N)=	\ln E_{f\sim\pi} \bE[e^{\lambda(\mathcal{L}(f)-V_N(f))}] \leq  \ln E_{f\sim\pi} \left(
        e^{\frac{\lambda^2}{2N} (G_e(f)+G_{e,1}(f))^2C^2 (4G_e(f)C+1)^2}\right)  
    \end{equation}
   where  $C=c_e\sqrt{n_u+n_y}$
   \[ G_{e,1}(f)=\|D_e\|_2+\sum_{k=1}^{\infty} (k+1) \|C_eA_e^{k-1}K_e\|_2 \]
   In particular, 
   $\lim_{N \rightarrow \infty} \Psi_{\pi,2}(\lambda,N)=0$ for any $\lambda > 0$
   and for $\lambda_N=\sqrt{N}$,
   $\lim_{N \rightarrow} \frac{1}{\lambda_N} \Psi_{\pi,2}(\lambda_N,N)=0$.
   \end{lemma}
% Note that as the spectral radius $0 \le \rho(A_e) < \gamma < 1$,
% then $\|A_e^k\| < \gamma^k M$ for some $M>1$, and hence, 
% \begin{align*}
%     G_{e,1}(f) \le \|D_e\|_2 + M \|C_e\|_2\|K_e\|_2 
%    \sum_{k=1}^{\infty} (k+1)\gamma^{k-1} = 
%    \le \|D_e\|_2 + M \|C_e\|_2\||K_e\|_2 
%    (\sum_{k=1}^{\infty} \gamma^{k-1} +\sum_{k=1}^{\infty} k \gamma^{k-1}) \\
%    \le \sum_{k=1}^{\infty} (k+1)\gamma^{k-1} = 
%     G_{e,1}(f) \le \|D_e\|_2 + M \|C_e\|_2\| \|K_e\|_2
%     (\frac{1}{1-\gamma}+\frac{1}{(1-\gamma)^2}) < +\infty
% \end{align*}
\begin{Proof}[Proof of Lemma \ref{cor:KL(L-V):alt2}]
 For each $f \in \mathcal{F}$, consider
 $\mathbf{X}_t=\y(t)-\hat{\y}_f(t)$.
 Then $\mathbf{X}_t$ %is stationary and as
 \[ \mathbf{X}_t=\sum_{k=0}^{\infty} \alpha_k \e_g(t-k), \]
 where 
  \begin{align*}
		\alpha_k=\begin{cases} D_{e},& k=0\\ C_{e} A_e^{k-1}K_e,& k>0 \end{cases}
\end{align*}
 By \cite[Proposition 4.2]{alquier2013prediction} 
 $X_t$ is a weakly dependent process in the terminology of
 \cite{alquier2013prediction}, and $\|X_t\| \le G_e(f) C$ and
 the coefficient $\theta_{\infty,N}(1)$ satisfies
 $\theta_{\infty,N}(1) < 2G_{e,1}(f)C$ for all $N \mathbb{N}$. 
 Consider the function $h(x_1,\ldots,x_N)=\frac{1}{(2L+1)} \sum_{i=1}^{N} \|x_i\|_2^2$ defined on
 $\mathcal{X}=[-L,L]^N$, where $L=2G_e(f) C$. 
 Then $h$ is $1-Lipschitz$. 
 Notice that $\lambda V_N(f)=\frac{\lambda}{N} (2L+1)h(\mathbf{X}(0),\ldots,\mathbf{X}(N-1))$. 
 Then 
 \[ \bE[e^{\lambda(\mathcal{L}(f)-V_N(f))}]=\bE[e^{\frac{\lambda}{N} (2L+1) (\bE[h(\mathbf{X}(0),\ldots, \mathbf{X}(N-1))]-h(\mathbf{X}(0),\ldots,\mathbf{X}(N-1))}]
 \]
 and hence by \cite[Theorem 6.6]{alquier2013prediction}
 \[ \bE[e^{\lambda(\mathcal{L}(f)-V_N(f))}] \le e^{\frac{\lambda^2}{N} (2L+1)^2 ( \|\mathbf{X}_0\|_{\infty} + \theta_{\infty,N}(1))^2/2} 
 \]
 where $ \|\mathbf{X}_0\|_{\infty}$  is the smallest real number such
 that $\|\mathbf{X}_0\| \le \|\mathbf{X}_0\|_{\infty}$  with probability $1$.
 By using the definition $L$, and the facts that 
 $\|X_t\| \le G_e(f) C$ and $\theta_{\infty,N}(1) < 2G_{e,1}(f)C$
 the statement of the lemma follows. 



 \begin{align}
     \bE[e^{\lambda(\mathcal{L}(f)-V_N(f))}] \le e^{\frac{\lambda^2}{N} (2L+1)^2 ( \|\mathbf{X}_0\|_{\infty} + \theta_{\infty,N}(1))^2/2} \leq e^{\frac{\lambda^2}{N} (4G_e(f)C+1)^2 ( G_e(f) + 2G_{e,1})^2 C^2/2}
 \end{align}
\end{Proof}

\begin{Proof}[of Theorem \ref{thm:bounded_alt}] \label{proof:thm:bounded_alt}

    By applying Lemma \ref{cor:KL(L-V):alt2}, Lemma \ref{lemma:mgf(Vn-hatL:alt)}, and by applying the union bound as in Lemma \ref{lemma:unbounded_full_KL}, we obtain, for $\lambda>0$, $\delta \in (0,1]$, with probability at least $1-2\delta$
    \begin{align}
        \forall \rho\in\mathcal{M}_\pi: \; E_{f\sim\rho} \mathcal{L}(f) \leq \E_{f\sim\rho} \hat{\mathcal{L}}_N(f) + \frac{2}{\lambda}\left [ \KL(\rho|\pi) + \ln \frac{1}{\delta} +\frac{\Psi_1(\lambda,N)+\Psi_2(\lambda,N)}{2} \right ]
    \end{align}
    with
    \begin{align}
        \Psi_1(\lambda,N) &\triangleq \ln E_{f\sim\pi} e^{\frac{\lambda^2}{2N} (4G_e(f)C+1)^2 ( G_e(f) + 2G_{e,1})^2 C^2}\\ 
        \Psi_2(\lambda,N) &\triangleq \ln E_{f\sim\pi} \left ( (1-\bar{G}_{f,1}(f) \|\Sigma_{gen}\|_{\ell_1} (c_e\sqrt{m}))+ \bar{G}_{f,1}(f) \|\Sigma_{gen}\|_{\ell_1} (c_e\sqrt{m}) e^{\lambda \frac{2\|\Sigma_{gen}\|_{\ell_1}(c_e\sqrt{m})}{N} \bar{G}_{f,2}(f)} \right )
    \end{align}
    Now with $\tilde{\lambda}\triangleq 0.5\lambda \leftrightarrow \lambda=2\tilde{\lambda}$, we obtain the statement of the lemma: for $\tilde{\lambda}>0$, $\delta\in(0,1]$, then
    with probability at least $1-2\delta$
    \begin{align}
        \forall \rho\in\mathcal{M}_\pi: \; E_{f\sim\rho} \mathcal{L}(f) \leq \E_{f\sim\rho} \hat{\mathcal{L}}_N(f) + \frac{1}{\tilde{\lambda}}\left [ \KL(\rho|\pi) + \ln \frac{1}{\delta} +\frac{\Psi_1(\tilde{\lambda},N)+\Psi_2(\tilde{\lambda},N)}{2} \right ]
    \end{align}
    with
    \begin{align}
        \Psi_1(\tilde{\lambda},N) &\triangleq \ln E_{f\sim\pi} e^{\frac{\tilde{\lambda}^2}{N} 2(4G_e(f)C+1)^2 ( G_e(f) + 2G_{e,1})^2 C^2}\\ 
        \Psi_2(\tilde{\lambda},N) &\triangleq \ln E_{f\sim\pi} \left ( (1-\bar{G}_{f,1}(f) \|\Sigma_{gen}\|_{\ell_1} (c_e\sqrt{m}))+ \bar{G}_{f,1}(f) \|\Sigma_{gen}\|_{\ell_1} (c_e\sqrt{m}) e^{\frac{\tilde{\lambda}}{N} 8\|\Sigma_{gen}\|_{\ell_1}(c_e\sqrt{m}) \bar{G}_{f,2}(f)} \right )
    \end{align}
    
\end{Proof}