@inproceedings{wong2021leveraging,
  title={Leveraging sparse linear layers for debuggable deep networks},
  author={Wong, Eric and Santurkar, Shibani and Madry, Aleksander},
  booktitle={International Conference on Machine Learning},
  pages={11205--11216},
  year={2021},
  organization={PMLR}
}
@book{molnar2020interpretable,
  title={Interpretable machine learning},
  author={Molnar, Christoph},
  year={2020},
  publisher={Lulu. com}
}
@article{StateOfSparsity,
  title={The state of sparsity in deep neural networks},
  author={Gale, Trevor and Elsen, Erich and Hooker, Sara},
  journal={arXiv preprint arXiv:1902.09574},
  year={2019}
}

@inproceedings{lin2015bilinear,
  title={Bilinear cnn models for fine-grained visual recognition},
  author={Lin, Tsung-Yu and RoyChowdhury, Aruni and Maji, Subhransu},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1449--1457},
  year={2015}
}
@inproceedings{nauta2021neural,
  title={Neural prototype trees for interpretable fine-grained image recognition},
  author={Nauta, Meike and van Bree, Ron and Seifert, Christin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14933--14943},
  year={2021}
}
@article{rudin2022interpretable,
  title={Interpretable machine learning: Fundamental principles and 10 grand challenges},
  author={Rudin, Cynthia and Chen, Chaofan and Chen, Zhi and Huang, Haiyang and Semenova, Lesia and Zhong, Chudi},
  journal={Statistics Surveys},
  volume={16},
  pages={1--85},
  year={2022},
  publisher={Amer. Statist. Assoc., the Bernoulli Soc., the Inst. Math. Statist., and the~…}
}
@inproceedings{nori2019interpretml,
  title={Accurate intelligible models with pairwise interactions},
  author={Lou, Yin and Caruana, Rich and Gehrke, Johannes and Hooker, Giles},
  booktitle={Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={623--631},
  year={2013}
}

@article{olah2017feature,
  title={Feature visualization},
  author={Olah, Chris and Mordvintsev, Alexander and Schubert, Ludwig},
  journal={Distill},
  volume={2},
  number={11},
  pages={e7},
  year={2017}
}
@article{kim2021hive,
  title={Hive: evaluating the human interpretability of visual explanations},
  author={Kim, Sunnie SY and Meister, Nicole and Ramaswamy, Vikram V and Fong, Ruth and Russakovsky, Olga},
  journal={arXiv preprint arXiv:2112.03184},
  year={2021}
}
@article{elude, 
year = {2022}, 
title = {{ELUDE: Generating interpretable explanations via a decomposition into labelled and unlabelled features}}, 
author = {Ramaswamy, Vikram V and Kim, Sunnie S Y and Meister, Nicole and Fong, Ruth and Russakovsky, Olga}, 
journal = {arXiv}, 
eprint = {2206.07690}, 
abstract = {{Deep learning models have achieved remarkable success in different areas of machine learning over the past decade; however, the size and complexity of these models make them difficult to understand. In an effort to make them more interpretable, several recent works focus on explaining parts of a deep neural network through human-interpretable, semantic attributes. However, it may be impossible to completely explain complex models using only semantic attributes. In this work, we propose to augment these attributes with a small set of uninterpretable features. Specifically, we develop a novel explanation framework ELUDE (Explanation via Labelled and Unlabelled DEcomposition) that decomposes a model's prediction into two parts: one that is explainable through a linear combination of the semantic attributes, and another that is dependent on the set of uninterpretable features. By identifying the latter, we are able to analyze the "unexplained" portion of the model, obtaining insights into the information used by the model. We show that the set of unlabelled features can generalize to multiple models trained with the same feature space and compare our work to two popular attribute-oriented methods, Interpretable Basis Decomposition and Concept Bottleneck, and discuss the additional insights ELUDE provides.}}, 
note = {Decomposition in unlabelled / labelled features. Sparse explanation, not prediction as it uses ground truth attribute labels for explanation. Does not have to be faithful with actually done prediction.}, 
keywords = {}
}

@article{margeloiu2021concept,
  title={Do concept bottleneck models learn as intended?},
  author={Margeloiu, Andrei and Ashman, Matthew and Bhatt, Umang and Chen, Yanzhi and Jamnik, Mateja and Weller, Adrian},
  journal={arXiv preprint arXiv:2105.04289},
  year={2021}
}

@inproceedings{koh2020concept,
  title={Concept bottleneck models},
  author={Koh, Pang Wei and Nguyen, Thao and Tang, Yew Siang and Mussmann, Stephen and Pierson, Emma and Kim, Been and Liang, Percy},
  booktitle={International Conference on Machine Learning},
  pages={5338--5348},
  year={2020},
  organization={PMLR}
}
@inproceedings{ICPRFinegrained,
  title={Multi-Grained Interpretable Network for Image
Recognition},
  author={Peiyu Yang and Zeyi Wen and Ajmal Mian},
  booktitle={26TH International Conference on Pattern Recognition},
  year={2022},
}
@article{hoffmann2021looks,
  title={This looks like that... does it? Shortcomings of latent space prototype interpretability in deep networks},
  author={Hoffmann, Adrian and Fanconi, Claudio and Rade, Rahul and Kohler, Jonas},
  journal={arXiv preprint arXiv:2105.02968},
  year={2021}
}
@inproceedings{fong2017interpretable,
  title={Interpretable explanations of black boxes by meaningful perturbation},
  author={Fong, Ruth C and Vedaldi, Andrea},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={3429--3437},
  year={2017}
}
 @inproceedings{Missingness,
      title={Missingness Bias in Model Debugging},
      author={Saachi Jain and Hadi Salman and Eric Wong and Pengchuan Zhang and Vibhav Vineet and Sai Vemprala and Aleksander Madry},
      booktitle={International Conference on Learning Representations},
      year={2022},
      url={https://openreview.net/forum?id=Te5ytkqsnl}
    } 
article{Missingness, 
year = {2022}, 
title = {{Missingness Bias in Model Debugging}}, 
author = {Jain, Saachi and Salman, Hadi and Wong, Eric and Zhang, Pengchuan and Vineet, Vibhav and Vemprala, Sai and Madry, Aleksander}, 
journal = {arXiv}, 
eprint = {2204.08945}, 
abstract = {{Missingness, or the absence of features from an input, is a concept fundamental to many model debugging tools. However, in computer vision, pixels cannot simply be removed from an image. One thus tends to resort to heuristics such as blacking out pixels, which may in turn introduce bias into the debugging process. We study such biases and, in particular, show how transformer-based architectures can enable a more natural implementation of missingness, which side-steps these issues and improves the reliability of model debugging in practice. Our code is available at https://github.com/madrylab/missingness}}, 
keywords = {}
}
@inproceedings{OcclusionPaper,
  title={Visualizing and understanding convolutional networks},
  author={Zeiler, Matthew D and Fergus, Rob},
  booktitle={European conference on computer vision},
  pages={818--833},
  year={2014},
  organization={Springer}
}

@article{ClassUniqueCorr, 
year = {2020}, 
title = {{Learning Class Unique Features in Fine-Grained Visual Classification}}, 
author = {Zheng, Runkai and Yu, Zhijia and Zhang, Yinqi and Ding, Chris and Cheng, Hei Victor and Liu, Li}, 
journal = {arXiv}, 
eprint = {2011.10951}, 
abstract = {{A major challenge in Fine-Grained Visual Classification (FGVC) is distinguishing various categories with high inter-class similarity by learning the feature that differentiate the details. Conventional cross entropy trained Convolutional Neural Network (CNN) fails this challenge as it may suffer from producing inter-class invariant features in FGVC. In this work, we innovatively propose to regularize the training of CNN by enforcing the uniqueness of the features to each category from an information theoretic perspective. To achieve this goal, we formulate a minimax loss based on a game theoretic framework, where a Nash equilibria is proved to be consistent with this regularization objective. Besides, to prevent from a feasible solution of minimax loss that may produce redundant features, we present a Feature Redundancy Loss (FRL) based on normalized inner product between each selected feature map pair to complement the proposed minimax loss. Superior experimental results on several influential benchmarks along with visualization show that our method gives full play to the performance of the baseline model without additional computation and achieves comparable results with state-of-the-art models.}}, 
keywords = {}
}

@article{article,
author = {Bibal, Adrien and Lognoul, Michael and Streel, Alexandre and Frénay, Benoît},
year = {2021},
month = {06},
pages = {},
title = {Legal requirements on explainability in machine learning},
volume = {29},
journal = {Artificial Intelligence and Law},
doi = {10.1007/s10506-020-09270-4}
}

@inproceedings{kim2018interpretability,
  title={Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (tcav)},
  author={Kim, Been and Wattenberg, Martin and Gilmer, Justin and Cai, Carrie and Wexler, James and Viegas, Fernanda and others},
  booktitle={International conference on machine learning},
  pages={2668--2677},
  year={2018},
  organization={PMLR}
}
@article{chen2019looks,
  title={This looks like that: deep learning for interpretable image recognition},
  author={Chen, Chaofan and Li, Oscar and Tao, Daniel and Barnett, Alina and Rudin, Cynthia and Su, Jonathan K},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}
@inproceedings{rymarczyk2021protopshare,
  title={Protopshare: Prototypical parts sharing for similarity discovery in interpretable image classification},
  author={Rymarczyk, Dawid and Struski, {\L}ukasz and Tabor, Jacek and Zieli{\'n}ski, Bartosz},
  booktitle={Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \& Data Mining},
  pages={1420--1430},
  year={2021}
}
@inproceedings{rymarczyk2022interpretable,
  title={Interpretable image classification with differentiable prototypes assignment},
  author={Rymarczyk, Dawid and Struski, {\L}ukasz and G{\'o}rszczak, Micha{\l} and Lewandowska, Koryna and Tabor, Jacek and Zieli{\'n}ski, Bartosz},
  booktitle={European Conference on Computer Vision},
  pages={351--368},
  year={2022},
  organization={Springer}
}


@inproceedings{bau2017network,
  title={Network dissection: Quantifying interpretability of deep visual representations},
  author={Bau, David and Zhou, Bolei and Khosla, Aditya and Oliva, Aude and Torralba, Antonio},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6541--6549},
  year={2017}
}
@inproceedings{selvaraju2017grad,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={618--626},
  year={2017}
}
@article{adebayo2018sanity,
  title={Sanity checks for saliency maps},
  author={Adebayo, Julius and Gilmer, Justin and Muelly, Michael and Goodfellow, Ian and Hardt, Moritz and Kim, Been},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}
@incollection{kindermans2019reliability,
  title={The (un) reliability of saliency methods},
  author={Kindermans, Pieter-Jan and Hooker, Sara and Adebayo, Julius and Alber, Maximilian and Sch{\"u}tt, Kristof T and D{\"a}hne, Sven and Erhan, Dumitru and Kim, Been},
  booktitle={Explainable AI: Interpreting, Explaining and Visualizing Deep Learning},
  pages={267--280},
  year={2019},
  publisher={Springer}
}



@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}
@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4700--4708},
  year={2017}
}
@inproceedings{gazagnadou2019optimal,
  title={Optimal mini-batch and step sizes for SAGA},
  author={Gazagnadou, Nidham and Gower, Robert and Salmon, Joseph},
  booktitle={International conference on machine learning},
  pages={2142--2150},
  year={2019},
  organization={PMLR}
}
@article{friedman2010regularization,
  title={Regularization paths for generalized linear models via coordinate descent},
  author={Friedman, Jerome and Hastie, Trevor and Tibshirani, Rob},
  journal={Journal of statistical software},
  volume={33},
  number={1},
  pages={1},
  year={2010},
  publisher={NIH Public Access}
}
@article{imagenet15russakovsky,
    Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
    Title = { {ImageNet Large Scale Visual Recognition Challenge} },
    Year = {2015},
    journal   = {International Journal of Computer Vision (IJCV)},
    doi = {10.1007/s11263-015-0816-y},
    volume={115},
    number={3},
    pages={211-252}
}
@INPROCEEDINGS{7298658,
  author={Van Horn, Grant and Branson, Steve and Farrell, Ryan and Haber, Scott and Barry, Jessie and Ipeirotis, Panos and Perona, Pietro and Belongie, Serge},
  booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Building a bird recognition app and large scale dataset with citizen scientists: The fine print in fine-grained dataset collection}, 
  year={2015},
  volume={},
  number={},
  pages={595-604},
  doi={10.1109/CVPR.2015.7298658}}
@inproceedings{
yuksekgonul2022posthoc,
title={Post-hoc Concept Bottleneck Models},
author={Mert Yuksekgonul and Maggie Wang and James Zou},
booktitle={ICLR 2022 Workshop on PAIR{\textasciicircum}2Struct: Privacy, Accountability, Interpretability, Robustness, Reasoning on Structured Data},
year={2022},
url={https://openreview.net/forum?id=HAMeOIRD_g9}
}
@article{10.1109/access.2022.3167702, 
year = {2022}, 
title = {{Concept Bottleneck Model With Additional Unsupervised Concepts}}, 
author = {Sawada, Yoshihide and Nakamura, Keigo}, 
journal = {IEEE Access}, 
issn = {2169-3536}, 
doi = {10.1109/access.2022.3167702}, 
abstract = {{With the increasing demands for accountability, interpretability is becoming an essential capability for real-world AI applications. However, most methods utilize post-hoc approaches rather than training the interpretable model. In this article, we propose a novel interpretable model based on the concept bottleneck model (CBM). CBM uses concept labels to train an intermediate layer as the additional visible layer. However, because the number of concept labels restricts the dimension of this layer, it is difficult to obtain high accuracy with a small number of labels. To address this issue, we integrate supervised concepts with unsupervised ones trained with self-explaining neural networks (SENNs). By seamlessly training these two types of concepts while reducing the amount of computation, we can obtain both supervised and unsupervised concepts simultaneously, even for large-sized images. We refer to the proposed model as the concept bottleneck model with additional unsupervised concepts (CBM-AUC). We experimentally confirmed that the proposed model outperformed CBM and SENN. We also visualized the saliency map of each concept and confirmed that it was consistent with the semantic meanings.}}, 
pages = {41758--41765}, 
volume = {10}, 
keywords = {}
}
@inproceedings{szegedy2016rethinking,
  title={Rethinking the inception architecture for computer vision},
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2818--2826},
  year={2016}
}
@Inbook{Izenman2008,
author="Izenman, Alan Julian",
title="Linear Discriminant Analysis",
bookTitle="Modern Multivariate Statistical Techniques: Regression, Classification, and Manifold Learning",
year="2008",
publisher="Springer New York",
address="New York, NY",
pages="237--280",
abstract="Suppose we are given a learning set {\$}{\$}{\backslash}mathcal{\{}L{\}}{\$}{\$}of multivariate observations (i.e., input values {\$}{\$}{\backslash}mathfrak{\{}R{\}}^r{\$}{\$}), and suppose each observation is known to have come from one of K predefined classes having similar characteristics. These classes may be identified, for example, as species of plants, levels of credit worthiness of customers, presence or absence of a specific medical condition, different types of tumors, views on Internet censorship, or whether an e-mail message is spam or non-spam.",
isbn="978-0-387-78189-1",
doi="10.1007/978-0-387-78189-1_8",
url="https://doi.org/10.1007/978-0-387-78189-1_8"
}
@inproceedings{goodfellow2013maxout,
  title={Maxout networks},
  author={Goodfellow, Ian and Warde-Farley, David and Mirza, Mehdi and Courville, Aaron and Bengio, Yoshua},
  booktitle={International conference on machine learning},
  pages={1319--1327},
  year={2013},
  organization={PMLR}
}


@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}
@article{pearson1901liii,
  title={LIII. On lines and planes of closest fit to systems of points in space},
  author={Pearson, Karl},
  journal={The London, Edinburgh, and Dublin philosophical magazine and journal of science},
  volume={2},
  number={11},
  pages={559--572},
  year={1901},
  publisher={Taylor \& Francis}
}
@misc{robustness,
   title={Robustness (Python Library)},
   author={Logan Engstrom and Andrew Ilyas and Hadi Salman and Shibani Santurkar and Dimitris Tsipras},
   year={2019},
   url={https://github.com/MadryLab/robustness}
}
@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}
@article{miller1956magical,
  title={The magical number seven, plus or minus two: Some limits on our capacity for processing information.},
  author={Miller, George A},
  journal={Psychological review},
  volume={63},
  number={2},
  pages={81},
  year={1956},
  publisher={American Psychological Association}
}
@article{DevilChannels, 
year = {2020}, 
title = {{The Devil is in the Channels: Mutual-Channel Loss for Fine-Grained Image Classification}}, 
author = {Chang, Dongliang and Ding, Yifeng and Xie, Jiyang and Bhunia, Ayan Kumar and Li, Xiaoxu and Ma, Zhanyu and Wu, Ming and Guo, Jun and Song, Yi-Zhe}, 
journal = {IEEE Transactions on Image Processing}, 
issn = {1057-7149}, 
doi = {10.1109/tip.2020.2973812}, 
pmid = {32092002}, 
eprint = {2002.04264}, 
abstract = {{The key to solving fine-grained image categorization is finding discriminate and local regions that correspond to subtle visual traits. Great strides have been made, with complex networks designed specifically to learn part-level discriminate feature representations. In this paper, we show that it is possible to cultivate subtle details without the need for overly complicated network designs or training mechanisms – a single loss is all it takes. The main trick lies with how we delve into individual feature channels early on, as opposed to the convention of starting from a consolidated feature map. The proposed loss function, termed as mutual-channel loss (MC-Loss), consists of two channel-specific components: a discriminality component and a diversity component. The discriminality component forces all feature channels belonging to the same class to be discriminative, through a novel channel-wise attention mechanism. The diversity component additionally constraints channels so that they become mutually exclusive across the spatial dimension. The end result is therefore a set of feature channels, each of which reflects different locally discriminative regions for a specific class. The MC-Loss can be trained end-to-end, without the need for any bounding-box/part annotations, and yields highly discriminative regions during inference. Experimental results show our MC-Loss when implemented on top of common base networks can achieve state-of-the-art performance on all four fine-grained categorization datasets (CUB-Birds, FGVC-Aircraft, Flowers-102, and Stanford Cars). Ablative studies further demonstrate the superiority of the MC-Loss when compared with other recently proposed general-purpose losses for visual classification, on two different base networks. Codes are available at: https://github.com/dongliangchang/Mutual-Channel-Loss.}}, 
pages = {4683--4695}, 
volume = {29}, 
keywords = {}
}
@article{AlphaZero, 
year = {2021}, 
title = {{Acquisition of Chess Knowledge in AlphaZero}}, 
author = {McGrath, Thomas and Kapishnikov, Andrei and Tomašev, Nenad and Pearce, Adam and Hassabis, Demis and Kim, Been and Paquet, Ulrich and Kramnik, Vladimir}, 
journal = {arXiv}, 
eprint = {2111.09259}, 
abstract = {{What is learned by sophisticated neural network agents such as AlphaZero? This question is of both scientific and practical interest. If the representations of strong neural networks bear no resemblance to human concepts, our ability to understand faithful explanations of their decisions will be restricted, ultimately limiting what we can achieve with neural network interpretability. In this work we provide evidence that human knowledge is acquired by the AlphaZero neural network as it trains on the game of chess. By probing for a broad range of human chess concepts we show when and where these concepts are represented in the AlphaZero network. We also provide a behavioural analysis focusing on opening play, including qualitative analysis from chess Grandmaster Vladimir Kramnik. Finally, we carry out a preliminary investigation looking at the low-level details of AlphaZero's representations, and make the resulting behavioural and representational analyses available online.}}, 
keywords = {}
}
@inproceedings{HierarchicalFineGrained,
  title={Fine-grained representation learning and recognition by exploiting hierarchical semantic embedding},
  author={Chen, Tianshui and Wu, Wenxi and Gao, Yuefang and Dong, Le and Luo, Xiaonan and Lin, Liang},
  booktitle={Proceedings of the 26th ACM international conference on Multimedia},
  pages={2023--2031},
  year={2018}
}
@article{Flamingo, 
year = {2021}, 
title = {{Your “Flamingo” is My “Bird”: Fine-Grained, or Not}}, 
author = {Chang, Dongliang and Pang, Kaiyue and Zheng, Yixiao and Ma, Zhanyu and Song, Yi-Zhe and Guo, Jun}, 
journal = {2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
doi = {10.1109/cvpr46437.2021.01131}, 
abstract = {{Whether what you see in Figure 1 is a "flamingo" or a "bird", is the question we ask in this paper. While fine-grained visual classification (FGVC) strives to arrive at the former, for the majority of us non-experts just "bird" would probably suffice. The real question is therefore – how can we tailor for different fine-grained definitions under divergent levels of expertise. For that, we re-envisage the traditional setting of FGVC, from single-label classification, to that of top-down traversal of a pre-defined coarse-to-fine label hierarchy – so that our answer becomes "bird" ⇒ "Phoenicopteriformes" ⇒ "Phoenicopteridae" ⇒ "flamingo". To approach this new problem, we first conduct a comprehensive human study where we confirm that most participants prefer multi-granularity labels, regardless whether they consider themselves experts. We then discover the key intuition that: coarse-level label prediction exacerbates fine-grained feature learning, yet fine-level feature betters the learning of coarse-level classifier. This discovery enables us to design a very simple albeit surprisingly effective solution to our new problem, where we (i) leverage level-specific classification heads to disentangle coarse-level features with fine-grained ones, and (ii) allow finer-grained features to participate in coarser-grained label predictions, which in turn helps with better disentanglement. Experiments show that our method achieves superior performance in the new FGVC setting, and performs better than state-of-the-art on the traditional single-label FGVC problem as well. Thanks to its simplicity, our method can be easily implemented on top of any existing FGVC frameworks and is parameter-free.}}, 
pages = {11471--11480}, 
volume = {00}, 
keywords = {}
}
@article{PlugInHierarchy, 
year = {2022}, 
title = {{A Novel Plug-in Module for Fine-Grained Visual Classification}}, 
author = {Chou, Po-Yung and Lin, Cheng-Hung and Kao, Wen-Chung}, 
journal = {arXiv}, 
eprint = {2202.03822}, 
abstract = {{Visual classification can be divided into coarse-grained and fine-grained classification. Coarse-grained classification represents categories with a large degree of dissimilarity, such as the classification of cats and dogs, while fine-grained classification represents classifications with a large degree of similarity, such as cat species, bird species, and the makes or models of vehicles. Unlike coarse-grained visual classification, fine-grained visual classification often requires professional experts to label data, which makes data more expensive. To meet this challenge, many approaches propose to automatically find the most discriminative regions and use local features to provide more precise features. These approaches only require image-level annotations, thereby reducing the cost of annotation. However, most of these methods require two- or multi-stage architectures and cannot be trained end-to-end. Therefore, we propose a novel plug-in module that can be integrated to many common backbones, including CNN-based or Transformer-based networks to provide strongly discriminative regions. The plugin module can output pixel-level feature maps and fuse filtered features to enhance fine-grained visual classification. Experimental results show that the proposed plugin module outperforms state-of-the-art approaches and significantly improves the accuracy to 92.77\textbackslash\% and 92.83\textbackslash\% on CUB200-2011 and NABirds, respectively. We have released our source code in Github https://github.com/chou141253/FGVC-PIM.git.}}, 
keywords = {}
}
@article{ghorbani2019towards,
  title={Towards automatic concept-based explanations},
  author={Ghorbani, Amirata and Wexler, James and Zou, James Y and Kim, Been},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}
@article{ElasticNet, 
year = {2005}, 
title = {{Regularization and variable selection via the elastic net}}, 
author = {Zou, Hui and Hastie, Trevor}, 
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)}, 
issn = {1467-9868}, 
doi = {10.1111/j.1467-9868.2005.00503.x}, 
abstract = {{Summary.  We propose the elastic net, a new regularization and variable selection method. Real world data and a simulation study show that the elastic net often outperforms the lasso, while enjoying a similar sparsity of representation. In addition, the elastic net encourages a grouping effect, where strongly correlated predictors tend to be in or out of the model together. The elastic net is particularly useful when the number of predictors (p) is much bigger than the number of observations (n). By contrast, the lasso is not a very satisfactory variable selection method in the p≫n case. An algorithm called LARS-EN is proposed for computing elastic net regularization paths efficiently, much like algorithm LARS does for the lasso.}}, 
pages = {301--320}, 
number = {2}, 
volume = {67}, 
keywords = {}
}
@inproceedings{ClassSpecificFilters,
  title={Training interpretable convolutional neural networks by differentiating class-specific filters},
  author={Liang, Haoyu and Ouyang, Zhihao and Zeng, Yuyuan and Su, Hang and He, Zihao and Xia, Shu-Tao and Zhu, Jun and Zhang, Bo},
  booktitle={European Conference on Computer Vision},
  pages={622--638},
  year={2020},
  organization={Springer}
}
@article{russakovsky2015imagenet,
  title={Imagenet large scale visual recognition challenge},
  author={Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
  journal={International journal of computer vision},
  volume={115},
  number={3},
  pages={211--252},
  year={2015},
  publisher={Springer}
}
@article{szegedy2013intriguing,
  title={Intriguing properties of neural networks},
  author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  journal={arXiv preprint arXiv:1312.6199},
  year={2013}
}
inproceedings{lin2015bilinear,
  title={Bilinear CNN models for fine-grained visual recognition},
  author={Lin, Tsung-Yu and RoyChowdhury, Aruni and Maji, Subhransu},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1449--1457},
  year={2015}
}
article{DBLP:journals/corr/LinRM15a,
  author    = {Tsung{-}Yu Lin and
               Aruni RoyChowdhury and
               Subhransu Maji},
  title     = {Bilinear {CNN} Models for Fine-grained Visual Recognition},
  journal   = {CoRR},
  volume    = {abs/1504.07889},
  year      = {2015},
  url       = {http://arxiv.org/abs/1504.07889},
  eprinttype = {arXiv},
  eprint    = {1504.07889},
  timestamp = {Mon, 13 Aug 2018 16:48:05 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/LinRM15a.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{kong2017low,
  title={Low-rank bilinear pooling for fine-grained classification},
  author={Kong, Shu and Fowlkes, Charless},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={365--374},
  year={2017}
}
article{DBLP:journals/corr/KongF16,
  author    = {Shu Kong and
               Charless C. Fowlkes},
  title     = {Low-rank Bilinear Pooling for Fine-Grained Classification},
  journal   = {CoRR},
  volume    = {abs/1611.05109},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.05109},
  eprinttype = {arXiv},
  eprint    = {1611.05109},
  timestamp = {Mon, 13 Aug 2018 16:49:16 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/KongF16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{miao2016survey,
  title={A survey on feature selection},
  author={Miao, Jianyu and Niu, Lingfeng},
  journal={Procedia Computer Science},
  volume={91},
  pages={919--926},
  year={2016},
  publisher={Elsevier}
}
@article{UnsupervisedSelection, 
year = {2020}, 
title = {{A review of unsupervised feature selection methods}}, 
author = {Solorio-Fernández, Saúl and Carrasco-Ochoa, J. Ariel and Martínez-Trinidad, José Fco.}, 
journal = {Artificial Intelligence Review}, 
issn = {0269-2821}, 
doi = {10.1007/s10462-019-09682-y}, 
pages = {907--948}, 
number = {2}, 
volume = {53}, 
keywords = {}
}
@article{ruping2006learning,
  title={Learning interpretable models},
  author={R{\"u}ping, Stefan and others},
  year={2006}
}
@inproceedings{rokade2021towards,
  title={Towards Quantification of Explainability Algorithms},
  author={Rokade, Pratyush and Alluri, BKSP Kumar Raju},
  booktitle={2021 The 5th International Conference on Advances in Artificial Intelligence (ICAAI)},
  pages={31--37},
  year={2021}
}

@article{friedler2019assessing,
  title={Assessing the local interpretability of machine learning models},
  author={Friedler, Sorelle A and Roy, Chitradeep Dutta and Scheidegger, Carlos and Slack, Dylan},
  year={2019}
}
@inproceedings{islam2020towards,
  title={Towards quantification of explainability in explainable artificial intelligence methods},
  author={Islam, Sheikh Rabiul and Eberle, William and Ghafoor, Sheikh K},
  booktitle={The thirty-third international flairs conference},
  year={2020}
}
@inproceedings{yang2017scalable,
  title={Scalable Bayesian rule lists},
  author={Yang, Hongyu and Rudin, Cynthia and Seltzer, Margo},
  booktitle={International conference on machine learning},
  pages={3921--3930},
  year={2017},
  organization={PMLR}
}

@article{FeatureSelect, 
year = {2019}, 
title = {{A Review of Feature Selection and Its Methods}}, 
author = {Venkatesh, B. and Anuradha, J.}, 
journal = {Cybernetics and Information Technologies}, 
doi = {10.2478/cait-2019-0001}, 
abstract = {{Nowadays, being in digital era the data generated by various applications are increasing drastically both row-wise and column wise; this creates a bottleneck for analytics and also increases the burden of machine learning algorithms that work for pattern recognition. This cause of dimensionality can be handled through reduction techniques. The Dimensionality Reduction (DR) can be handled in two ways namely Feature Selection (FS) and Feature Extraction (FE). This paper focuses on a survey of feature selection methods, from this extensive survey we can conclude that most of the FS methods use static data. However, after the emergence of IoT and web-based applications, the data are generated dynamically and grow in a fast rate, so it is likely to have noisy data, it also hinders the performance of the algorithm. With the increase in the size of the data set, the scalability of the FS methods becomes jeopardized. So the existing DR algorithms do not address the issues with the dynamic data. Using FS methods not only reduces the burden of the data but also avoids overfitting of the model.}}, 
pages = {3--26}, 
number = {1}, 
volume = {19}, 
keywords = {}
}
@inproceedings{bohle2022b,
  title={B-cos Networks: Alignment is All We Need for Interpretability},
  author={B{\"o}hle, Moritz and Fritz, Mario and Schiele, Bernt},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10329--10338},
  year={2022}
}
@article{dhal2021comprehensive,
  title={A comprehensive survey on feature selection in the various fields of machine learning},
  author={Dhal, Pradip and Azad, Chandrashekhar},
  journal={Applied Intelligence},
  pages={1--39},
  year={2021},
  publisher={Springer}
}
@article { DocKru2021,
  author = {Alexander Dockhorn and Rudolf Kruse},
  title = {Fuzzy Modeling in Game AI},
  journal = {Journal of Pure and Applied Mathematics},
  year = {2021},
  url = {http://www.twmsj.az/Files/Contents%20V.12%20N.1.2021/pp54-68.pdf},
  volume = {12},
  number = {1},
  pages = {54-68}
}
@article{LDAForSelec,
  title={Effective discriminative feature selection with nontrivial solution},
  author={Tao, Hong and Hou, Chenping and Nie, Feiping and Jiao, Yuanyuan and Yi, Dongyun},
  journal={IEEE transactions on neural networks and learning systems},
  volume={27},
  number={4},
  pages={796--808},
  year={2015},
  publisher={IEEE}
}
@article{rudin2019stop,
  title={Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead},
  author={Rudin, Cynthia},
  journal={Nature Machine Intelligence},
  volume={1},
  number={5},
  pages={206--215},
  year={2019},
  publisher={Nature Publishing Group}
}
@inproceedings{chimeramix,
  title     = {ChimeraMix: Image Classification on Small Datasets via Masked Feature Mixing},
  author    = {Reinders, Christoph and Schubert, Frederik and Rosenhahn, Bodo},
  booktitle = {Proceedings of the Thirty-First International Joint Conference on
               Artificial Intelligence, {IJCAI-22}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Lud De Raedt},
  pages     = {1298--1305},
  year      = {2022},
  month     = {7},
  note      = {Main Track},
  doi       = {10.24963/ijcai.2022/181},
  url       = {https://doi.org/10.24963/ijcai.2022/181},
}
@article{tessera2021keep,
  title={Keep the gradients flowing: Using gradient flow to study sparse network optimization},
  author={Tessera, Kale-ab and Hooker, Sara and Rosman, Benjamin},
  journal={arXiv preprint arXiv:2102.01670},
  year={2021}
}
@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{wah2011caltech,
  title={The caltech-ucsd birds-200-2011 dataset},
  author={Wah, Catherine and Branson, Steve and Welinder, Peter and Perona, Pietro and Belongie, Serge},
  year={2011},
  publisher={California Institute of Technology}
}
@inproceedings{StanfordCars,
  title = {3D Object Representations for Fine-Grained Categorization},
  booktitle = {4th International IEEE Workshop on  3D Representation and Recognition (3dRR-13)},
  year = {2013},
  address = {Sydney, Australia},
  author = {Jonathan Krause and Michael Stark and Jia Deng and Li Fei-Fei}
}
@techreport{FGVCAircraft,
   title         = {Fine-Grained Visual Classification of Aircraft},
   author        = {S. Maji and J. Kannala and E. Rahtu
                    and M. Blaschko and A. Vedaldi},
   year          = {2013},
   archivePrefix = {arXiv},
   eprint        = {1306.5151},
   primaryClass  = "cs-cv",
}
@incollection{Pytorch,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}
@InProceedings{Rudolph_2022_WACV,
    author    = {Rudolph, Marco and Wehrbein, Tom and Rosenhahn, Bodo and Wandt, Bastian},
    title     = {Fully Convolutional Cross-Scale-Flows for Image-Based Defect Detection},
    booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
    month     = {January},
    year      = {2022},
    pages     = {1088-1097}
}