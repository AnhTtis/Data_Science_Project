\documentclass[preprint, 12pt,5p,times]{elsarticle}
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
%\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{float}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{nccmath}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{sidecap}
\usepackage{wrapfig}
\usepackage{subfig}
\usepackage{tabularx}


\usepackage[none]{hyphenat}
\hyphenpenalty=1000
\emergencystretch=5em

\journal{Neural Networks}

\begin{document}
	
\begin{frontmatter}
	
	%% Title, authors and addresses
	
	%% use the tnoteref command within \title for footnotes;
	%% use the tnotetext command for theassociated footnote;
	%% use the fnref command within \author or \address for footnotes;
	%% use the fntext command for theassociated footnote;
	%% use the corref command within \author for corresponding author footnotes;
	%% use the cortext command for theassociated footnote;
	%% use the ead command for the email address,
	%% and the form \ead[url] for the home page:
	%% \title{Title\tnoteref{label1}}
	%% \tnotetext[label1]{}
	%% \author{Name\corref{cor1}\fnref{label2}}
	%% \ead{email address}
	%% \ead[url]{home page}
	%% \fntext[label2]{}
	%% \cortext[cor1]{}
	%% \affiliation{organization={},
	%%             addressline={},
	%%             city={},
	%%             postcode={},
	%%             state={},
	%%             country={}}
	%% \fntext[label3]{}
	
	\title{Associated Random Neural Networks for Collective Classification of Nodes in Botnet Attacks
	\tnotetext[t1]{This research was supported by the IoTAC Research and Innovation Action,
		funded by the European Commission (EC) under H2020 Call SU-ICT-02-2020 ``Building blocks for resilience in evolving ICT systems'', under Grant Agreement No. 952684.}}
	
	%% use optional labels to link authors explicitly to addresses:
	%% \author[label1,label2]{}
	%% \affiliation[label1]{organization={},
	%%             addressline={},
	%%             city={},
	%%             postcode={},
	%%             state={},
	%%             country={}}
	%%
	%% \affiliation[label2]{organization={},
	%%             addressline={},
	%%             city={},
	%%             postcode={},
	%%             state={},
	%%             country={}}
	
	
	\author[inst1,inst2,inst3]{Erol Gelenbe\corref{cor1}}
	\ead{seg@iitis.pl}
	\cortext[cor1]{Corresponding author}
		\author[inst1]{Mert Nak\i p}
	\ead{mnakip@iitis.pl}
	
	\address[inst1]{Institute of Theoretical and Applied Informatics,
		Polish Academy of Sciences (PAN), 
		Bałtycka 5,
		Gliwice,
		44--100, 
		Poland
	} 
	\address[inst2]{Lab. I3S, Universit\'{e} C\^{o}te d'Azur, 
		Cedex 2,
		Nice,
		06103, 
		France
	}
	\address[inst3]{Ya\c{s}ar University, 
	Bornova,
	Izmir,
	35100, 
	Turkey
	}
	
	\begin{abstract}
	Botnet attacks are a major threat to networked systems because of their ability to 
	turn the network nodes that they compromise into additional attackers, leading to the spread of high volume attacks over long periods. The detection of such Botnets is 
	complicated by the fact that multiple network IP addresses will be simultaneously compromised,
	so that Collective Classification of compromised nodes, in addition to the already available traditional methods that focus on individual nodes, can be useful. Thus this work introduces a collective Botnet attack classification technique that operates on traffic from
	a $n$-node IP network, with a novel 
	Associated Random Neural Network (ARNN) that identifies the nodes
	which are compromised. The ARNN is a recurrent architecture that  incorporates two mutually associated, interconnected and architecturally identical $n$-neuron random neural networks,
	that act simultneously as mutual critics to reach the decision regarding which of $n$ nodes have been compromised. A novel gradient learning descent algorithm is presented  
	for the ARNN, and is shown to operate effectively both with conventional off-line training from prior data, and with on-line incremental training
	without prior off-line learning.  Real data from a $107$ node packet network is used
	with over $700,000$ packets to evaluate the  ARNN, showing that it provides accurate predictions. Comparisons with other well-known state of the art methods using the same learning and testing datasets, show that the ARNN offers significantly better performance.
	\end{abstract}
	
	%%Graphical abstract
	%\begin{graphicalabstract}
		%\includegraphics{grabs}
	%\end{graphicalabstract}
	
	%%Research highlights
	%\begin{highlights}
	%	\item Research highlight 1
	%	\item Research highlight 2
	%\end{highlights}
	
	\begin{keyword}
Collective Classification \sep Botnet Attack Detection \sep Associated Random Neural Networks \sep	The Internet \sep Nodes Compromised by Botnets \sep Random Neural Networks \sep ARNN Learning  
	\end{keyword}
	
\end{frontmatter}
	
	
	
	
	
\section{Introduction} \label{section:introduction}

Many classification problems, such as identifying a given individual's face in a large
dataset of face images of people \cite{Davis}, associate a binary label to data items \cite{Binary}. This is also the usual case for network attack detection from traffic data \cite{Botnet1} that attemps to determine
whether a given network node has been compromised by an attack \cite{Filus21}. Such problems are often solved with Machine Learning (ML) algorithms that learn off-line from one or more datasets that contain the ground-truth data. The trained ML algorithm can then be tested on datasets that have not been used for learning, and then used online with previously unseen or new data. Typically, the online usage of such attack detection algorithms is carried out ``one node at a time'', i.e. as an individual classification problem for a specific node that may be concerned by possible attacks \cite{Alshamkhany,Access22}.

When we need to classify each individual node in a set $V=\{v_1,~...~,v_n\}$ of interconnected nodes in a network as being ``compromised'' or uncompromised (i.e.,  ``safe'') we obviously face with a Binary {\em Individual} Classification Problem for each of the $n$ nodes. However, when the attacking entity is a Botnet which induces a compromised node to attack several other nodes with which it is able to directly communicate, then we are faced with a {\em Collective Binary Classification Problem}
where the classification of the distinct nodes is correlated, even though we cannot be sure that
a compromised node has sufficient bandwidth or processing capacity to actually compromise other nodes. 

Indeed  let $A=[A_{ij}]_{n\times n}$ be the (deterministic)  adjacency matrix
where $A_{ij}=1$ indicates that node $v_i$ has opened a connection to node $v_j$ and therefore can send packet traffic to it, while $A_{ij}=0$
indicates that node $v_i$ is unable to send packets to node $v_j$. Then  during a Botnet attack, nodes that can receive traffic from compromised nodes are themselves likely to become compromised, and to become in turn attackers against other nodes, so that one needs to classify nodes by taking account both the local atack traffic at each node, and their patterns of communication between nodes. 

Collective (also known as ``relational'') classification problems have been widely studied \cite{Collective1,Collective3} using a variety of  techniques
linked to ML.  As indicated in the literature \cite{Collective2},
collective classification may use a collection of local conditional classifiers which 
classify an individual's label conditionally on the label value of others, and then fuses
the overall sets of outputs, or may try to
solves the problem either as a global optimization or
a global relaxation problem \cite{Collective4,Collective5}, with the global approach being
often computationally more costly.

Botnet attack detection has been discussed in numerous papers, mainly using 
single node attack detection techniques \cite{CollectiveSurvey1,CollectiveSurvey2,CollectiveSurvey3} which can identify
individually comprimised nodes, except for some studies that analyze relations between nodes to detect the existence or spread of a Botnet \cite{CollectiveDetect1,CollectiveDetect2,CollectiveDetect3}. 

Thus in this paper we address the Collective Classification problem of detecting all the nodes in a given network which have been
compromised by a Botnet.  In particular, we introduce a ML method that combines
supervised learning by a novel Random Neural Network \cite{RNN1} architecture -- which we call the Associated Random Neural Network (ARNN) -- that learns from a sample taken from the traffic flowing among a set of network nodes, to classify them as being either compromised by a Botnet, or as non-compromised.  

The Random Neural Network is a bio-inspired spiking
Neural Network that has a convenient mathematical solution, and  has been applied by numerous authors, including \cite{Video,Aiello,Khaled0,Kaptan1,Khaled1,Khaled2,BuildingEnergy2,VideoScheduling,Intrusion,AdaptiveModulation,HVAC1,HVAC2,BuildingEnergy1,VoiceQuality,VideoQuality,Virus,Rubino1,Rubino2,Rubino3,Yin1,Yin4}, in diverse problems that can be addressed with ML such as video compression, tumor recognition from MRI images, video quality evaluation, smart building climate management, enhanced reality, voice quality evaluation over the internet, wireless channel modulation, climate control in buildings, the detection of network viruses and other cyberattacks.



In the case of Botnet detection, the   ARNN is trained off-line with data that is certified as containing Botnet attacks, and with data that is attack free, and the trained   ARNN is then used online to monitor a network's traffic to collectively classfy  which nodes -- if any -- are compromised by a Botnet.

In the sequel, Section \ref{Survey} surveys previous  research on Botnet attacks. In Section \ref{Method} the proposed ARNN is described; to improve readability its gradient learning algorithm is detailed separately in \ref{Appendix}. 

Section \ref{Experimental} presents the experimental work based on a large MIRAI Botnet dataset involving $107$ network nodes and over $760,000$ packets \cite{KitsuneKaggle} that is used for training and evaluating the proposed method. The evaluation of the  ARNN using this dataset is detailed in Section \ref{Eval}, where we have also compared our results with other well known ML methods. Finally, conclusions and suggestions for further work are presented in Section \ref{Conclusions}.  







     
%Given a network and an object o in the network, there are three distinct types of correlations that can be utilized to determine the classification or label of o: 1. The correlations between the label of o and the observed attributes of o.2. The correlations between the label of o and the observed attributes (including observed labels) of objects in the neighborhood of o. 3. The correlations between the label of o and the unob- served labels of objects in the neighborhood of o.
%Collective classification refers to the combined classification of a set of interlinked objects using all three types of infor- mation described above. Note that, sometimes the phrase re- lational classification is used to denote an approach that con- centrates on classifying network data by using only the first two types of correlations listed above. However, in many applications that produce data with correlations between la- bels of interconnected objects (a phenomenon sometimes re- ferred to as relational autocorrelation [37]) labels of the ob- jects in the neighborhood are often unknown as well. In such cases, it becomes necessary to simultaneously infer the labels for all the objects in the network.
%Within the machine learning community, classification is typically done on each object independently, without tak- ing into account any underlying network that connects the objects. Collective classification does not fit well into this setting. For instance, in the webpage classification problem where webpages are interconnected with hyperlinks and the task is to assign each webpage with a label that best indi- cates its topic, it is common to assume that the labels on interconnected webpages are correlated. Such interconnec- tions occur naturally in data from a variety of applications such as bibliographic data [10, 16], email networks [7] and social networks [37]. Traditional classification techniques would ignore the correlations represented by these intercon- nections and would be hard pressed to produce the classi- fication accuracies possible using a collective classification approach.
%Even though traditional exact inference algorithms such as variable elimination [64, 11] and the junction tree algo- rithm [20] harbor the potential to perform collective clas- sification, they are practical only when the graph structure of the network satisfies certain conditions. In general, ex- act inference is known to be an NP-hard problem and, to the best of our knowledge, there is no guarantee that real- world network data satisfy the conditions that make exact inference tractable for collective classification. As a conse- quence, most of the research in collective classification has been devoted to the development of approximate inference algorithms.
%In this article we provide an introduction to four popular approximate inference algorithms used for collective clas- sification, iterative classification, Gibbs sampling, loopy be- lief propagation and mean-field relaxation labeling. We pro- vide an outline of the basic algorithms by providing pseudo- code, explain how one could apply them to real-world data, provide theoretical justifications (if there exist any), and dis- cuss issues such as feature construction and various heuris- tics that may lead to improved classification accuracy. We provide case studies, on both real-world and synthetic data, to demonstrate the strengths and weaknesses of these ap- proaches. All of these algorithms have a rich history of de- velopment and application to various problems relating to collective classification and we provide a brief discussion of this when we examine related work. Collective classification has been an active field of research for the past decade and as a result, there are numerous other approximate inference algorithms besides the four we describe here.
%Collective classification is a combinatorial optimization problem, in which we are given a set of nodes, V = {V1, . . . , Vn} and a neighborhood function N , where Ni ⊆ V \ {Vi}, which describes the underlying network structure. Each node in V is a random variable that can take a value from an appropriate domain. V is further divided into two sets of nodes: X , the nodes for which we know the correct values (observed variables) and, Y, the nodes whose values need to be determined. Our task is to label the nodes Yi ∈ Y with one of a small number of labels, L = {L1,...,Lq}; we’ll use the shorthand yi to denote the label of node Yi. We explain the notation further using a webpage classification example that will serve as a running example through- out the article. Figure 1 shows a network of webpages with hyperlinks. In this example, we will use the words (and phrases) contained in the webpages as local attributes. For brevity, we abbreviate the local attributes, thus, ‘ST’ stands for “student”, ‘CO’ stands for “course”, ‘CU’ stands for “curriculum” and ‘AI’ stands for “Artificial Intelligence”. Each webpage is indicated by a box, the corresponding topic of the webpage is indicated by an ellipse inside the box, and each word in the webpage is represented using a circle in- side the box. The observed random variables X are shaded whereas the unobserved ones Y are not. We will assume that the domain of the unobserved label variables L, in this case, is a set of two values: “student homepage” (abbreviated to ‘SH’) and “course homepage” (abbreviated to ‘CH’). Fig- ure 1 shows a network with two unobserved variables (Y1 and Y2), which require prediction, and seven observed vari- ables (X3, X4, X5, X6, X7, X8 and X9). Note that some of the observed variables happen to be labels of webpages (X6 and X8) for which we know the correct values. Thus, from the figure, it is easy to see that the webpage W1, whose unobserved label variable is represented by Y1, contains two words ‘ST’ and ‘CO’ and hyperlinks to webpages W2, W3 andW4.

%Even though collective classification has gained attention only in the past five to seven years, the general problem of inference for structured output spaces has received attention for a considerably longer period of time from various research communities including computer vision, spatial statistics and natural language processing. In this section, we attempt to describe some of the work that is most closely related to the work described in this article, however, due to the widespread interest in collective classification our list is sure to be incomplete.
%One of the earliest principled approximate inference al- gorithms, relaxation labeling [21], was developed by researchers in computer vision in the context of object labeling in images. Due to its simplicity and appeal, relaxation label- ing was a topic of active research for some time and many re- searchers developed different versions of the basic algorithm [31]. Mean-field relaxation labeling [56, 61], discussed in this article, is a simple instance of this general class of al-gorithms. Besag [5] also considered statistical analysis of images and proposed a particularly simple approximate in- ference algorithm called iterated conditional modes which is one of the earliest descriptions and a specific version of the iterative classification algorithm presented in this article. Besides computer vision, researchers working with an iter- ative decoding scheme known as “Turbo Codes” [4] came up with the idea of applying Pearl’s belief propagation al- gorithm [43] on networks with loops. This led to the development of the approximate inference algorithm that we, in this article, refer to as loopy belief propagation (LBP) (also known as sum product algorithm) [28, 36, 29].
%Another area that often uses collective classification techniques is document classification. Chakrabarti, Dom, & In- dyk [8] was one of the first to apply collective classification to a corpora of patents linked via hyperlinks and reported that considering attributes of neighboring documents actu- ally hurts classification performance. Slattery & Craven [50] also considered the problem of document classification by constructing features from neighboring documents using an Inductive Logic Programming rule learner. Yang, Slattery, & Ghani [59] conducted an in-depth investigation over multi- ple datasets commonly used for document classification ex- periments and identified different patterns. Since then, col- lective classification has also been applied to various other applications such as part-of-speech tagging [30], classifica- tion of hypertext documents using hyperlinks [51], link pre- diction in friend-of-a-friend networks [52], optical character recognition [54], entity resolution in sensor networks [9], predicting disulphide bonds in protein molecules [53], seg- mentation of 3D scan data [2] and classification of email “speech acts” [7].
%Besides the four approximate inference algorithms discussed in this article, there are other algorithms that we did not discuss such as graph-cuts based formulations [6], for- mulations based on linear programming relaxations [24, 55] and expectation propagation [38]. Other examples of ap- proximate inference algorithms include algorithms develiterations).
%Accuracyoped to extend and improve loopy belief propagation (LBP) to remove some of its shortcomings such as alternatives with convergence guarantees [63] and alternatives that go beyond just using edge and node marginals to compute more accu- rate marginal probability estimates such as the cluster vari- ational method [62], junction graph method [1] and region graph method [61]. More recently, there have been some attempts to extend collective classification techniques to the semi-supervised learning scenario [58, 34].







\section{Recent Work on Botnet Attack Detection}\label{Survey}

In networked systems the cost of not meeting security requirements can be very high \cite{bib:ciscopriv,bib:cisco,HTTP}, hence much effort has been devoted to developing techniques that {\bf detect attacks} against network components such as hosts, servers, routers, switches, IoT devices, mobile devices and various network applications. 



Botnet attacks are particularly harmful, since they induce their victims to become
sources of further attacks  against third parties
\cite{Survey,Botnet25,Botnet2}. Recent Botnet reports include the 2016 MIRAI attack \cite{Mirai}, and the MERIS type attacks from 2021 and 2022 that can generate some $46$ million requests per second, lasting more than $60$ minutes, exploiting over $5,000$ source IP addresses as Bots from over $130$ countries
\cite{Meris1,Meris2}, which is a similar rate of requests as all the Wikimedia daily requests 
made in ten seconds. Another MERIS attack generated $17.2$  million requests per second against a commercial  web site, and such attacks have been observed to
target some $50$ web sites per day, with over $100$ Distributed Denial of Service (DDoS) attacks,
of which one third appear to occur in China, and $13\%$ in the USA,
involving a number of Bots sometimes ranging between $30,000$ up to  $250,000$.


Botnet attack detection techniques typically  
examine incoming traffic streams and identify sub-streams  that are benign or ``normal'', and those that may contain attacks \cite{bib:Jeatrakul2009,Botnet12,Botnet8}, and
often classify  attacks into ``types''  \cite{bib:yin2017deep} based on signatures \cite{bib:cortes2019hybrid, bib:li2019designing} that exploit prior knowledge about attack patterns. In addition, false alarms should also be minimized
so that useful network traffic is not eliminated by mistake. However, such methods can also be overwhelmed by attack generators \cite{bib:medbiotguerra2020medbiot} that have been designed to adaptively modify their behaviour.



 
 %With the advancement of computers and technology, security threats are also evolving at a fast pace. Botnets are one such security threat which requires a high level of research and focus in order to be eliminated. In this paper, we use machine learning to detect Botnet attacks. Using the Bot-IoT and University of New South Wales (UNSW) datasets, four machine learning models based on four classifiers are built: Naïve Bayes, K-Nearest Neighbor, Support Vector Machine, and Decision Trees. Using 82,000 records from UNSW-NB15 dataset, the decision trees model has yielded the best overall results with 99.89% testing accuracy, 100% precision, 100% recall, and 100% F-score in detecting botnet attacks. XXSeveral datasets are available for this work such as theBot-IoT and the UNSW-NB15 datasets. The Bot-IoT datasetcontains over 72 million records with 42 features (27Integer, 13 Float, and 2 String types) and was created by setting up a botnet network in a controlled environment andmonitoring the network traffic to capture any packets thatwere being sent. The dataset contains labeled normal andmalicious traffic which includes attacks such as DDoS, DoS,OS Scan, etc. The other dataset, UNSW-NB15 contains 43features (14 Float, 6 Strings and 23 Integer types) and 2.5million records which are labeled as either attack traffic or normal traffic and further expanded to the category of attackand the subcategory. In addition to DDoS and DoS attacks,the dataset contains records for Fuzzers, Backdoor,Reconnaissance and Worm attacks [17]. These records were collected in pcap files and then converted to CSV to createthe dataset. Both datasets have been compiled and made publicly available by UNSW Canberra for research purposes[18]. Furthermore, it is found that the UNSW-NB15 dataset is a more polished dataset, where has similar attributes to the Bot-IoT dataset but is more diverse in the type of malicious  (PDF) Botnet Attack Detection Using Machine Learning. Available from: https://www.researchgate.net/publication/347445002_Botnet_Attack_Detection_Using_Machine_Learning [accessed Dec 27 2022]. November 2020  DOI: 10.1109/IIT50501.2020.9299061, 14th IEEE International Conference on Innovations in Information Technology (IIT), UAE author = {Mustafa Alshamkhany and Wisam Alshamkhany and Mohamed Mansour and Salam Dhou and Fadi A. Aloul}


   
 Defense techniques for Botnets based on the smart location of counter-attacks by ``white hat'' worm launchers have also been suggested \cite{Botnet3,Botnet7},
while refined deep learning (DL) techniques have been investigated to recognize constantly evolving 
Botnet traffic \cite{Botnet4}, and transfer learning can improve detection accuracy, without concatenating large datasets having different characteristics \cite{Botnet5}. 

Recent work has also created a taxonomy of Botnet communication patterns including encryption and hiding \cite{Botnet6} with some authors examining how Internet Service Providers (ISP) can participate collectively to mitigate their effect \cite{Botnet19}. Other work suggests that traditional Botnet detection techniques in the Internet are not well adapted to emerging applications such as the IoT \cite{Botnet10}, some studies have addressed Botnet apps in specific operating system contexts such as Android \cite{Botnet17} or Botnet detection for specific applications such as Peer to Peer Systems (P2P) \cite{Botnet22}, or Vehicular Networks for which specific detection and protection mechanisms are suggested \cite{Botnet21}. 

Some recent research has  focused on the manner in which Botnet variability can be reflected in intrusion detection software that is designed for a given host \cite{Botnet24}. Universal sets of features that may be applicable to attack detection \cite{Botnet26} have also been
suggested, and detection techniques for specific types of Botnets such as the ones based on the Domain Generation Algorithm \cite{Botnet23} have been proposed.

 

Most of the previous literature on Botnets, as well as our recent work, has focused on {\em single node detection} with off-line learning. We developed detection techniques for Distributed Denial of Service (DDoS) attacks
using {\em gradient descent learning} with the RNN \cite{Filus21,Spilios}, because Botnets often use DDoS as the means of bringing down their victims. 
The system-level remedial actions that should be taken after an attack is detected \cite{Gelenbe2020} were also analyzed.  To avoid learning all possible types of attack patterns, an {\em auto-associative approach  based on Deep Learning of ''normal‘‘ patterns with a dense multi-layer RNN} \cite{gelenbe2017deepdense} was developed to detect malicious attacks by identifying deviations from normal traffic \cite{Brun, Nakip, Nakip_incremental}.  It was also shown that a single trained auto-associative dense RNN
can provide detection of multiple types of attacks (i.e. not just Botnets) \cite{G-Nets-Attack},
and that learning can be partially conducted on-line, with less need for long and computationally costly off-line training \cite{Access22}.


\subsection{Approach Developed in this Paper}

While it is possible to accurately detect malicious attacks by processing traffic at a given node, it is difficult to certify that the detected attack is indeed a Botnet by observing a single node since Botnets are based on the propagation of attack patterns through multiple nodes. Furthermore, many attack detectors detect anomalies in the incoming traffic rather that pointing to a specific attack \cite{G-Nets-Attack}. Thus the present paper develops a Collective Classification approach to secifically address the Botnet detection problem in the following manner:
\begin{enumerate}
	\item A finite set of $n$ interconnected network IP (Internet Protocol) addresses is considered,
	\item Some of these addresses are equipped with a Local Attack Detector (LAD), so that a local evaluation is available at some of the nodes about whether they are being attacked. Note that the fact that a node is attacked  does not necessarily imply that it has been compromised,
	\item A specific neural network architecture, the Associated RNN (ARNN) with $2n$ neurons, is designed {\bf to deduce  which (if any) of the IP addresses have been {\em compromised}}  by Botnet(s), using the available decisions from the LADs regarding individual nodes. The ARNN is trained,
	using the algorithm detailed in \ref{Appendix}, on a small  subset of data taken from a large open access Botnet dataset \cite{KitsuneKaggle} containing over $760,000$ packets exchanged among  $107$ IP (Internet Protocol) addresses.
	\item Then using the remaining large dataset (not used for training) we determine which of the $107$ IP addresses have been compromised and become Botnet attackers, resulting in a high level of accuracy regarding which IP addresses are compromised.
	\item Two other well established ML methods are also used to identify which of the $107$ nodes have been compromised. The results show  that the  ARNN provides significantly better accuracy concerning both True Positives and True Negatives.
	\end{enumerate}






\section{The  ARNN Decision System}
\label{Method}

\begin{figure}[h!]
	\centering 

	\includegraphics[height=10cm,width=8.5cm]{Figures/SystemDesign.jpg}
	\caption{A schematic diagram of  the $2n$-neuron  ARNN that carries out a Collective Classification of the compromised nodes (if any) for a 	$n$-node IoT network denoted $V=\{v_1,~...~,v_n\}$.  The ARNN has two neurons $X_i$ and $Y_i$ that represent opposite views for each network node $v_i$: $X_i$ indicates that $v_i$ is compromised, while $Y_i$ indicates that $v_i$ is not compromised.  The corresponding numerical decision variables are $Q_i,~q_i\in [0,1]$, where $Q_i$ is the probability that $X_i$ is excited and $q_i$ is the probability that $Y_i$ is excited. $X_i$ has an excitatory connection $W^+_{ij}$ to each other neuron $X_j$ and an inhibitory connection $W^-_{ij}$ to all other $Y_j$ neurons, and $Y_i$ has an excitatory connection $w^+_{ij}$ to each other neuron $Y_j$ and an inhibitory connection $w^-_{ij}$ to all other $X_j$ neurons. A neuron does not excite or inhibit its own self. Thus inside the  ARNN, the neurons of type $X$ excite other neurons of type $X$ and inhibit all neurons of type $Y$, and vice-versa for the neurons of type $Y$. The ARNN is ``self-critical'' in the sense that neurons of type $X$ try to supress the neurons of type $Y$, and vice-versa. $\Lambda_i$ represents the output from the LAD (local attack detector) at node $v_i$ stating that $v_i$ has been compromised while $\lambda_i$ represents the LAD output at node $v_i$ stating that it has not been compromised. $\Lambda_i,~\lambda_i$ act as an excitatory and inhibitory external input, respectively,  for $X_i$, while they act as an inhibitory, excitatory input for $Y_i$.}
	\label{fig:SystemDesign}
\end{figure}

The decision system presented in this paper, the ``self-critical'' ARNN with $2n$ neurons, is shown schematically in Figure~\ref{fig:SystemDesign}. The   ARNN carries out a Collective Classification of the compromised nodes (if any) for a 	$n$-node IP network denoted $V=\{v_1,~...~,v_n\}$.  For each network node $v_i$, the ARNN has two neurons $X_i$ and $Y_i$ that represent opposite views. $X_i$ indicates that $v_i$ is compromised, while $Y_i$ indicates that $v_i$ is not compromised.  Their corresponding numerical decision variables are $Q_i,~q_i\in [0,1]$, where $Q_i$ is the probability that $X_i$ is excited and $q_i$ is the probability that $Y_i$ is excited. $X_i$ has an excitatory connection $W^+_{ij}$ to every other neuron $X_j$ and an inhibitory connection $W^-_{ij}$ to all $Y_j$ neurons, and $Y_i$ has an excitatory connection $w^+_{ij}$ to every other neuron $Y_j$ and an inhibitory connection $w^-_{ij}$ to all $X_j$ neurons. None of the neuron can directly excite or inhibit themselves. Thus inside the  ARNN, the neurons of type $X$ excite other neurons of type $X$ and inhibit all neurons of type $Y$, and vice-versa for the neurons of type $Y$. The ARNN is ``self-critical'' in the sense that neurons of type $X$ try to supress the neurons of type $Y$, and vice-versa. $\Lambda_i$, is a non-negative real number that represents the output from the LAD  (local attack detector) at $v_i$ stating that $v_i$ has been compromised while $\lambda_i$ represents the LAD output at node $v_i$ stating that it has not been compromised. $\Lambda_i,~\lambda_i$ can be chosen from the corresponding probabilities outputted from the LADs acting as excitatory and inhibitory external input, respectively,  for each $X_i$, while they have the opposite effect as inhibitory and excitatory input for $Y_i$, respectively.

The two neurons  $X_i$  and $Y_i$ have  {\em internal states} $K_i(t)\geq 0$ and $k_i(t) \geq 0$, respectively.
If its internal state $K_i(t)$ is strictly positive, then the RNN neuron $X_i$ will fire spikes at exponentially distributed successive intervals, sending excitatory and/or inhibitory spikes at rates $W^+_{ij},~W^-_{ij}\geq 0$ to the other neurons in the ARNN. Similarly when $k_i(t)>0$ neuron $Y_i$ will fire spikes at rates and $w^+_{ij},~w^-_{ij}\geq 0$ for $Y_i$, respectively, to the other neurons $X_j$ and $Y_j$ in the ARNN. These firing rates are the ``weights'' that are learned with the training dataset using the algorithm described in \ref{Appendix}.

When any of the neurons $ \{X_i,~Y_i,~i=1,~...~ n\}$ receives an excitatory spike either from its external input or from another neuron, say at time $t$, its internal state will increase by $1$,
i.e. $K_i(t^+)=K_i(t)+1$ or $k_i(t^+)=k_i(t)+1$. Similarly if a neuron receives an inhibitory spike then its internal state decreases by $1$ provided it was previously at a positive state value, and its state does not change if it was previously at the zero value, i.e.  $K_i(t^+)=max[0,K_i(t)-1]$ or $k_i(t^+)=max[0,k_i(t)-1]$. 
Also  when a neuron fires, its internal state drops by $1$,
i.e. $K_i(t^+)=K_i(t)-1$ or $k_i(t^+)=k_i(t)-1$; note that a neuron can only fire if its state was previously positive.

We thus define the probability that these $2n$  neurons are ``excited'' or firing by:
\begin{eqnarray}
&&For~ X_i:~Q_i=\lim_{t\rightarrow\infty} Prob[K_i(t)>0],\\
&&For~Y_i:~q_i=\lim_{t\rightarrow\infty} Prob[k_i(t)>0],
\end{eqnarray}
and $Q_i$ is the variable that ``advocates'' that node $i$ is compromised, while the role of $q_i$ is to advocate the opposite.




Consider the following system of $2n$ equations for $Q_i,~q_i$, obtained from the RNN equations \cite{bib:Gelenbe1993}:
\begin{eqnarray} \label{RNN}
Q_i&=&\frac{\Lambda_i + \sum_{j=1}^n W^+_{ji}Q_j}{\lambda_i+\sum_{j=1}^n [W^+_{ij}+W^-_{ij}]+\sum_{j=1}^n w^-_{ji}q_j},\\
q_i&=&\frac{\lambda_i + \sum_{j=1}^n w^+_{ji}q_j}{\Lambda_i+\sum_{j=1}^n[w^+_{ij}+w^-_{ij}]+\sum_{j=1}^n W^-_{ji}Q_j},\nonumber
\end{eqnarray} 
where
\begin{equation}
W^+_{ii}=W^-_{ii}=w^+_{ii}=w^-_{ii}=0.
\end{equation}
Let $K(t)=(K_1(t),~...~,K_n(t))$ and $k(t)=(k_1(t),~...~,k_n(t))$, and define the vectors of non-negative integers $H=(H_1,~...~,H_n)$ and $h=(h_1,~...~,h_n)$.
From \cite{bib:Gelenbe1993}, we know that if the solution to the equations (\ref{RNN}) satisfy $0\leq Q_i,~q_i< 1$ for $1\leq i\leq n$, then the joint stationary distribution of the  ARNN's state is:
\begin{eqnarray} \label{prod}
&&\lim_{t\rightarrow\infty}Prob[K(t)=H,~k(t)=h~]\\ 
&&~~~~~~~~~~~=\prod_{i=1}^n Q_i^{H_i}(1-Q_i).q_i^{h_i}(1-q_i)~.\nonumber
\end{eqnarray}


\bigskip
 %More simply one can also use:
%\begin{equation}
%\Lambda_i=A^l_i,~\lambda_i=1-A^l_i,
%\end{equation}
%to estimate whether a Botnet attack is targeting
%node $i$ in Bucket $l$.
\noindent{\bf Note:} From  (\ref{prod}) we can see that if $Q_i>q_i$ then:
\begin{equation} \label{A}
\lim_{t\rightarrow \infty} Prob[K_i(t)>k_i(t)] = \frac{Q_i(1-q_i)}{q_i(1-Q_i)}>1.
\end{equation}




%Note that the outgoing firing rates of each of pair of neurons at a RNN node are such that:
%\begin{equation}
%If~ A(i,j)=0,~then~ W^+_{ij}=W^-_{ij}=w^+_{ij}=w^-_{ij}=0.
%\end{equation}
To simplify the learning algorithm, we restrict the weights in the following manner:
\begin{equation}
	W=W^+_{ij}+W^-_{ij} = w^+_{ij}+w^-_{ij},~i,j\in \{1,~..~n\},~i\neq j, \label{con}
\end{equation}
where $W>0$ is a constant representing the total firing or spiking rate any neuron $X_i$ or $Y_i$ 
towatds other neurons. 
This restriction also avoids having weights which take very large values. 
%$W^+_{ij}$ and $w^+_{ij}$ are initially set to specific values and then they will be updated using the learning algorithm described below.
%The weights in the equations for $Q_i$ and $q_i$ are also constrained in the following manner: 
%\begin{equation}
%	W^+_{ii}=w^+_{ii}=W^-_{ii}=w^-_{ii}=0,~ for ~any~ i,
%\end{equation}
%\begin{equation}
%W=W^+_{ij}+W^-_{ij} = w^+_{ij}+w^-_{ij},~\forall~i,j\in \{1,~..~n\},~i\neq j,
%\end{equation}
%where $W$ is a constant representing the total firing or spiking rate any neuron $X_i$ or $Y_i$ to all the other neurons with states$X_j,~Y_j$. 
We can write the $2n$ RNN equations (\ref{RNN}) as:
\begin{eqnarray} \label{Qq}
Q_i&=&\frac{\Lambda_i + \sum_{j=1}^n W^+_{ji}Q_j}{\lambda_i+(n-1)W+\sum_{j=1}^nw^-_{ji}q_j},\\
q_i&=&\frac{\Lambda_i + \sum_{j=1}^n w^+_{ji}q_j}{\Lambda_i+ (n-1)W+\sum_{j=1}^nW^-_{ji}Q_j}.\nonumber
\end{eqnarray}
On the other hand, the learning algorithm detailed in \ref{Appendix}
computes the values of $W^+_{ij},~w^+_{ij}$ for all the neuron pairs $i,j,~i\neq j$
so as to minimize an error based  cost function ${\bf E}$ using an appropriate training dataset
such as Kitsune \cite{mirsky2018kitsune,KitsuneKaggle}.








\section{Network Learning and Accuracy of Botnet Attack Prediction}\label{Experimental}


The data we use concerns the MIRAI Botnet Attack \cite{Soldatos2}. documented in the Kitsune dataset \cite{mirsky2018kitsune,KitsuneKaggle}
which contains  a total of $764,137$ individual
packets. The dataset contains $107$ network nodes identified by IP addresses,  and a given node may be both a source node for some packets, and a destination for other packets.

This publicly available dataset, which is already partially processed (by the providers of the dataset) contains the ground-truth that the providers held, regarding the packets which are
Botnet attack packets, and those which are not attack packets. Thus each packet is labeled as either an ``attack'' ($a=1$) or a ``normal'' packet ($a=0$), so that the Kitsune dataset
already contains the ``ground truth''. 
Since the dataset is quite large, some parts of the data may be used for training the attack detection algorithms, while other parts may be used for evaluating the effectiveness of them.

The data items in this dataset are the individual packets, where each packet can be denoted as 
$pk(t,s,d,a)$, where:
\begin{itemize}
	%\item  $I$ is its unique numerical identifier $1\leq I\leq I_M$, 
	\item $t$ is a time-stamp indicating when the packet is sent, 
	\item $s,d$ are the source and destination nodes of the packet,
	\item $a$ is the binary variable with $a=1$ for a packet that has been identified as an attack packet, and $a=0$ for a packet that has been identfied as a benign non-attack packet.
\end{itemize} 
It is interesting to note that this dataset is time varying. The obvious reason is that in the course of a Botnet attack the number of nodes that are compromised increases with the number of attacks which occur, and the number of attack packets obviously also increases as the number of compromised nodes increases. The Kitsune dataset does not incorporate the consequences of attack detection. Indeed if an attack is detected and the compromised nodes are progressively blacklisted, then the number of attack packets and the number of nodes that are compromised, may eventually decrease, but this is not incorporated in the Kitsune dataset.

Thus, since this data is based on an attack that is going unchecked, the initial part of the data contains hardly any attack packets, while the latter part contains many more attack packets, as would be expected. Whether a given node is compromised or not also depends on the amount of traffic it receives from compromised nodes, as this traffic may contain attack packets capable of compromising the destination node.
Thus detecting whether a network node is compromised or not, does not only depend on its own behaviour, i.e.
on whether it sends attack packets, but also on whether it has received traffic from other compromised nodes. 


\subsection{Processing the MIRAI Botnet Data}

These $764,137$ packets in \cite{KitsuneKaggle} cover a consecutive time period of roughly $7137$ seconds (approximately $2$ hours). Thus we aggregate
the data in a more compact form by grouping packets into successive time $10$ second 
time slots whose length is denoted by $\tau$.
The choice of $\tau=10~secs$  is based on the need to have a significant number of $\approx 713$ time slots, and to have a statistically significant number of packets in each slot. Since we have $107$ nodes, the average number of packets per node in each slot is also approximately $10$.

The packets within each successive slot are thus
grouped into ``buckets'', where $B^l$ denotes the $l-th$ bucket, i.e.
the set of packets whose time stamp lies between $(l-1)\tau$ and $l\tau$ seconds:
\begin{equation}
B^l = \{pk(t,s,d,a),~(l-1)\tau\leq t <l \tau\},~\tau=10~secs.\nonumber
\end{equation}
%Within bucket $B^l$, we denote the set of packets which are {\em sent} from node $s$ to any of the destinations $d$ as: \begin{equation} S^l(s)= \{pk(I,t,s,d,a),~\forall d,~\forall a,~(l-1)\leq t <l \},\nonumber \end{equation} and the set of packets which are {\em received} at node $d$ from all sources $s$ in $B^l$ are denoted: \begin{equation} R^l(d)= \{pk(I,t,s,d,a),~\forall s,~\forall a,~(l-1)\leq t <l \}.\nonumber \end{equation} 


Let $S^l(s)$ denote the set of packets that have been transmitted by node $s$ {\em until the end of the $l-th$ time slot}:
\begin{equation}
S^l(s)= \{pk(t,s,d,a),~\forall d,~\forall a,~0\leq t <l \tau \},
\end{equation} 
and, let $R^l(d)$ denote the set of packets that have been received by node $d$ in the same time frame: 
\begin{equation}
R^l(d)= \{pk(t,s,d,a),~\forall s,~\forall a,~0\leq t <l \tau\}~.
\end{equation} 
Then $A^l_d$ is the {\em attack ratio} which represents the ratio of attack packets, among all packets received by node $d$ at the end of $l-th$ slot and is computed as
\begin{eqnarray}
&&If~~| R^l(d)| >0:\nonumber\\
&&A^l_d=\frac{|\{pk(t,s,d,1),~\forall s,~0\leq t <l\tau\}| }{| R^l(d)| },\\
&&Else~~A^l_d=0\nonumber,
\end{eqnarray} 
while $K^l_s$ is the {\em proportion of compromised packets} which is the ratio of attack packets sent by node $s$ at the end of the same slot, given by:
\begin{eqnarray}
&&If~~| S^l(s)| >0:\nonumber\\
&&K^l_s=\frac{|\{pk(t,s,d,1),~\forall d,~0\leq t <l\tau\}| }{| S^l(s)| },\\
&&Else~~K^l_s=0. \nonumber
\end{eqnarray} 
Since any node $i$ may be a source or destination, or both a source and destination, of packets, $A^l_i$ and $K^l_i$ are, respectively, the input and output ground truth data regarding which nodes are attacked, and which nodes are compromised at the end of $l-th$ time slot.

In addition, for each node $i$, we define the binary variable regarding the \emph{ground truth}, denoted by $G^l_i$ as:
\begin{equation}\label{groundtruth_binary_decision}
G^l_i = \mathbf{1}\left[K^l_i > \Theta\right],
\end{equation}
where $\mathbf{1}\left[L\right]=1$ if $L$ is true and $0$ otherwise, where $\Theta\in[0,1]$ is a threshold. Thus, at the end of the $l-th$ slot, if $G^l_i=1$ the ground truth indicates that node $i$ 
has been compromised. If $G^l_i=0$ then node $i$ is considered not to be
compromised.

\subsection{The  ARNN Error Functio $E$} \label{Learn}

Let us call ''{\bf TrainData}'' the subset of time slots
used for Training the  ARNN. The manner in which this subset is selected from the MIRAI dataset is detailed below. 
Since we wish to predict whether each of the $n$ nodes has been compromised given the data about attacks, the error function to be minimized by the learning algorithm takes the form:
\begin{eqnarray}
{\bf E}&=&\frac{1}{2}\sum_{l\in {\bf TrainData}}\sum_{i=1}^n \big[\big(Q^l_i(A^l_i)-K^l_i\big)^2 \nonumber\\ 
&&~~~~~~~~~+\big(q^l_i(1-A^l_i)-(1-K^l_i)\big)^2 \big], \label{cost}
\end{eqnarray}
where the functions $Q^l_i(A^l_i)$ and $q^l_i(1-A^l_i)$ are computed by the ARNN using equation (\ref{Qq}) as follows:
\begin{eqnarray} 
&&Q^l_i(A^l_i)=\nonumber\\
&&\frac{A^l_i + \sum_{j=1}^n W^+_{ji}Q^l_j(A^l_i)}{(1-A^l_i)+ (n-1)W+\sum_{j=1}^nw^-_{ji}q^l_j(1-A^l_i)},\nonumber
\end{eqnarray}

\begin{eqnarray}
q^l_i(1-A^l_i)&&=\nonumber\\
&&\frac{(1-A^l_i) + \sum_{j=1}^n w^+_{ji}q^l_j(1-A^l_i)}{A^l_i + (n-1)W+\sum_{j=1}^nW^-_{ji}Q^l_j(A^l_i)}.\nonumber
\end{eqnarray}

For each node $i$, we define the {\bf binary decision} of the output of the  ARNN, denoted by the binary variable $Z_i$ as 
\begin{equation}\label{binary_decision}
Z^l_i = \mathbf{1}\left[L^l_i = \frac{Q^l_i(1-q^l_i)}{q^l_i(1-Q^l_i)}>\gamma\right],
\end{equation}
where $\gamma\in[0,\infty]$ is a ``decision threshold''. Thus, at $l-th$ slot, if $Z^l_i=1$ the  ARNN indicates that node $i$ has been compromised, while if $Z^l_i=0$ then ARNN considers that node $i$ is not compromised.

Then, we perform two distinct experiments:

\subsubsection{Experiment I: Offline Training of  ARNN}


To construct a balanced training dataset  {\bf TrainData}  for the  ARNN, the sequence of slots was scanned chronologically from the beginning of the whole MIRAI dataset until the first slot was found that contained some  nodes that had been compromised. Specifically, this was in $l^*-th$ slot with $l^*=445$ in the MIRAI dataset.  

Then, the training set ${\bf TrainData}$ with a total of $25$ time slots was constructed as follows:
	\begin{eqnarray}
	&&	{\bf TrainData}=\nonumber\\
	&&	\{(A^l_i,K^l_i),~l=l^*-12,...,{l^*+12};~i=1,...,n\},\nonumber \label{CTS}
	\end{eqnarray}
	of which the first $12$ have very few attack packets, while the following $13$ all contain a significant number of attack packets. 
	
The test set, denoted by ${\bf TestData}$, is composed of {\em all the remaining} time slots which have not used for training the  ARNN:
	\begin{eqnarray}
	&&{\bf TestData}=\nonumber\\
	&&\{(A^l_i,K^l_i),~l=\{1,..., l^*-13\} \cup \{l^*+13,...,713\};\nonumber\\
	&&~~~~~~~~~~~~~~i=1,...,n\},\nonumber 
	\end{eqnarray}


\subsubsection{Experiment II: Online (Incremental) Training  of  ARNN}

In this part, ARNN's training took place online, along with testing, which represents the case where there is no available training set offline. To this end, it was used for prediction on every slot $l$ and also if $mod(l, 6)=0$ it was trained at the end of slot $l$. That is, we perform testing for $10$ second slots and training for $1$ minute slots. 

Accordingly, on each ``training slot'' $l$ for which $mod(l, 6)=0$, the training set ${\bf TrainData}$ for incremental learning was constructed as follows:
	\begin{equation*}
	{\bf TrainData}= \{(A^{l'}_i,K^{l'}_i),~{l'}=l-5,...,{l};~i=1,...,n\}.
	\end{equation*}
Recall that {\bf TrainData} is updated for each $l$ such that $mod(l, 6)=0$, so that the  ARNN's weights ($W^+_{ij}$ and $w^+_{ij}$) are updated based on {\bf TrainData} at the end of slot $l$, without reinitializing the weights. 

\subsection{Other Machine Learning Models  Used for Comparison}\label{sec:ML}

For both Experiments I and II, the performance of  the ARNN is also compared with those obtained with two well-known ML models: the Multi-Layer Perceptron (MLP) and the Long-Short Term Memory (LSTM) neural network. We now briefly present the specific architectures of these models which we use during our experimental work, and Figure~\ref{fig:ML_arch} displays the inputs and outputs which are common to the ML models.  

\begin{figure}[h!]
	\centering 

	\includegraphics[scale=0.55]{Figures/ML_arch.jpg}
	\caption{High-level architecture that shows the inputs and outputs at each slot $l$ for the ML techniques that are used in the comparison with  the ARNN, where $\hat{K}_i^l$ denotes the predicted compromised ratio of IP Address $i$ at slot $l$ by any considered ML model.
	}
	\label{fig:ML_arch}
\end{figure}

Then, based on these input-output sets, each ML model is used as follows:
\begin{itemize}
	
	%\item \textbf{Linear Regression} is considered as the linear baseline model. 
		
	%\item \textbf{KNN} is implemented using the \emph{scikit-learn} library \cite{scikit-learn} in Python. The number of neighbours in the KNN is set to the number of slots in the {\bf TrainData}, which equals $25$ for Experiment I and $6$ for Experiment II.
	
	\item \textbf{MLP}, which is a feedforward (fully-connected) neural network, is comprised of three hidden layers and an output layer, where there are $n$ neurons at each layer. A sigmoidal activation function is used for each neuron in the network. 
	
	\item \textbf{LSTM}, which is a recurrent neural network, is comprised of an lstm layer, two hidden layers and an output layer, where there are $n$ lstm units or neurons at each layer. A sigmoidal activation function is used for each neuron in the network. 
	
\end{itemize}


\section{Experimental Results}\label{Eval}

We now evaluate the performance of  the ARNN model and compare it with the performance of some existing techniques for Experiment I and Experiment II, respectively. Note that we set the learning rate $\eta=0.1$ in the algorithm of \ref{Appendix}. 


\subsection{Experiment I - Offline Training of  the ARNN} 

We set $\Theta=0.3$ and $0.96 \leq \gamma \leq 1$, and summarize the statistics of Accuracy, True Negative Rate (TNR) and True Positive Rate (TNR) performances of  ARNN, which are presented in detail in Figures~\ref{fig:Accuracy_offline},~\ref{fig:TNR_offline},~and~\ref{fig:TPR_offline}, respectively. Figure~\ref{fig:BoxPlot_offline} displays a box-plot that shows the statistics over all the IP Addresses. These results show that  ARNN achieves a high performance with very few outliers in regards of Accuracy, TNR, and TPR. The median accuracy is about $92\%$ while the first quartile is at $87\%$; that is, accuracy is above $87\%$ for $75\%$ of IP addresses. The median of TNR is almost $100\%$; that is, there are almost no false alarms (TNR$=100\%$) for more than $50\%$ of IP addresses. Also, the median of TPR equals $100\%$ and the first quartile is about $62\%$. Thus the TPR equals $100\%$ for more than $50\%$ of IP addresses while it is lower than $62\%$ for only less than $25\%$ of addresses.


\begin{figure}[h!]
	\centering 
	%\includegraphics[scale=0.34]{ThetaSearch_Test.jpg}\vspace{0.5cm}
	\includegraphics[scale=0.25]{Figures/BoxPlot_25samplesTraining.jpg}
	\caption{Box-plots of the Accuracy, TNR and TPR performance of  ARNN over IP Addresses, where each of box-plot shows the calculated statistics (e.g. median) based on the results presented in Figures~\ref{fig:Accuracy_offline},~\ref{fig:TNR_offline},~and~\ref{fig:TPR_offline}, respectively
	}
	\label{fig:BoxPlot_offline}
\end{figure}


\begin{figure}[h!]
	\centering 
	%\includegraphics[scale=0.34]{ThetaSearch_Test.jpg}\vspace{0.5cm}
	\includegraphics[scale=0.25]{Figures/ACC_25samplesTraining.jpg}
	\caption{Evaluation of the average accuracy over all packets of each IP Address $i \in \{1, \dots, 107\}$ in ${\bf TestData}$. The accuracy is computed by comparing the binary decision in the ground truth $G_i^l$ and the binary decision of ARNN $Z_i^l$.% with $\Theta=0.2$ and $\gamma=0.1$. %We observe that the accuracy equals $100\%$ for $78\%$ of all IP Addresses while it is below $80\%$ for only $7$ IP Addresses.
		%time slots $l \in \{1, \dots, 713\}\backslash \{433, \dots, 458\}$, where $\gamma = 0.16$. Note that if $G_i^l \neq 1$ $\forall l \in \{1, \dots, 713\}\backslash \{433, \dots, 458\}$, then TPR does not exist for IP address $i$.
	}
	\label{fig:Accuracy_offline}
\end{figure}


\begin{figure}[h!]
	\centering 
	\includegraphics[scale=0.25]{Figures/TNR_25samplesTraining.jpg}
	\caption{Evaluation of the average percentage TNR over all packets of each IP Address $i \in \{1, \dots, 107\}$ in ${\bf TestData}$. For each $i$, TNR is computed by comparing $G_i^l$ and $Z_i^l$ for the values of $l$ where $G_i^l=0$. 
	}
	\label{fig:TNR_offline}
\end{figure}
 
\begin{figure}[h!]
	\centering 
	\includegraphics[scale=0.25]{Figures/TPR_25samplesTraining.jpg}
	\caption{Evaluation of the average percentage TPR over all packets of each IP Address $i \in \{1, \dots, 107\}$ in ${\bf TestData}$. For each $i$, TPR is computed by comparing $G_i^l$ and $Z_i^l$ for the values of $l$ where $G_i^l=1$. Note that if $G_i^l=0$ for an IP Address $i$ for any $l$ in ${\bf TestData}$ (that is, the ground truth indicates that IP Address $i$ has not been compromised within the observation period of the dataset), TPR does not exist for $i$. Accordingly, in the considered dataset TPR exists for $39$ IP Address. 
	}
	\label{fig:TPR_offline}
\end{figure}

Figure~\ref{fig:Accuracy_offline} displays the average decision accuracy for each IP Address $i \in \{1, \dots, 107\}$. The results in this figure show that the accuracy of  ARNN is above $95\%$ for $50\%$ of the IP Addresses while it is between $62\%$ and $80\%$ for only $20\%$ of addresses and does not decrease below $62\%$. Next, Figure~\ref{fig:TNR_offline} presents average percentage TNR of  ARNN for each IP Address. The results in this figure show that TNR is above $95\%$ for $59\%$ of all IP Addresses, and it is between $62\%$ and $80\%$ for $15\%$ of addresses. Lastly, Figure~\ref{fig:TPR_offline} displays the percentage average TPR for $39$ IP Addresses for which are considered compromised at least once in the ground truth. The results in this figure show that TPR is greater than $95\%$ for $64\%$ of IP addresses while it is above $90\%$ for more than $74\%$ of the addresses.


%Lastly, in order to observe the prediction ability of the  ARNN, we analyze the distribution of Likelihood Ratio (LR) predicted by  ARNN and compare that with LR in Ground Truth. This comparison is presented in Fig.~\ref{fig:Hist_offline}, where the results show that the distribution of the LR that is predicted by  ARNN is highly similar to that is computed with the Ground Truth. In addition, based on the results in this figure, we measured that the difference between Ground Truth and  ARNN is $136$ for the total number of occurrences of LRs that are greater than $1$ (or, symmetrically, that are less than $1$).

%\begin{figure}[h!]
%	\centering 
%	\includegraphics[scale=0.32]{Hist_25samplesTraining.jpg}
%	\caption{Comparison of the histograms of Likelihood Ratio that is predicted by  ARNN and that is computed with the Ground Truth in  ${\bf TestData}$. For the better visualization, the Likelihood Ratios are saturated at $3$. }
%	\label{fig:Hist_offline}
%\end{figure}

\subsection{Online (Incremental) Training  of  the ARNN} 

Having set $\Theta=0.3$ and $0.96 \leq \gamma \leq 1$, we obtain the Accuracy, TNR, and TPR of  ARNN with online training shown in Figure~\ref{fig:TPR_online} in the form of box-plots. In this figure, we see that median accuracy equals $92\%$ while the first quartile equals $87\%$. That is, the accuracy is above $87\%$ for $75\%$ of all IP Addresses. The TNR is above $99\%$ for at least $50\%$ of IP Addresses. The median TPR equals $100\%$; that is, at least $50\%$ (exactly $62\%$) of IP Addresses are $100\%$ accurately identified as compromised. When the results in Experiment II in Figure~\ref{fig:BoxPlot_online} are compared with those of Experiment I of Figure~\ref{fig:BoxPlot_offline}, we see that TPR increases slightly with online training and TNR remains almost the same. In addition, recall that online training is simpler since it does not require data collection, as offline training does. 


\begin{figure}[h!]
	\centering 
	%\includegraphics[scale=0.34]{ThetaSearch_Test.jpg}\vspace{0.5cm}
	\includegraphics[scale=0.25]{Figures/BoxPlot_sequentialTraining.jpg}
	\caption{Box-plots of the Accuracy, TNR and TPR performance of  ARNN over all IP Addresses, where each box-plot shows the calculated statistics (e.g. median) based on the results presented in Figures~\ref{fig:Accuracy_online},~\ref{fig:TNR_online},~and~\ref{fig:TPR_online}, respectively
	}
	\label{fig:BoxPlot_online}
\end{figure}

Figure~\ref{fig:Accuracy_online} presents the average accuracy of  ARNN for each IP Address $i$ is displayed. The results in this figure show that the accuracy of  ARNN is above $95\%$ for $50\%$ of IP Addresses while it is between $62\%$ and $80\%$ for only $20\%$ of addresses and does not decrease below $62\%$. Next, we present the average percentage TNR in Figure~\ref{fig:TNR_online}, and show that the TNR is above $95\%$ for $59\%$ of IP Addresses. Moreover, Figure~\ref{fig:TPR_online} displays the average percentage TPR for individual IP Addresses, where for IP Address $i$, TPR is presented only if $G_i^l=1$ for at least a single value of $l$. The results in this figure show that percentage TPR is greater than $95\%$ for $72\%$ of IP Addresses, while TPR under offline training is shown (in Fig.~\ref{fig:TPR_offline}) to be above $95\%$ for $64\%$ of IP Addresses. Hence, one may observe that  ARNN achieves significantly higher TPR when it is trained online.

\begin{figure}[h!]
	\centering 
	%\includegraphics[scale=0.34]{ThetaSearch_Test.jpg}\vspace{0.5cm}
	\includegraphics[scale=0.25]{Figures/ACC_sequentialTraining.jpg}
	\caption{Evaluation of the average accuracy over all packets of each IP Address $i \in \{1, \dots, 107\}$. The accuracy is computed by comparing the binary decision in the ground truth $G_i^l$ and the binary decision of ARNN $Z_i^l$.
	}
	\label{fig:Accuracy_online}
\end{figure}

\begin{figure}[h!]
	\centering 
	%\includegraphics[scale=0.34]{ThetaSearch_Test.jpg}\vspace{0.5cm}
	\includegraphics[scale=0.25]{Figures/TNR_sequentialTraining.jpg}
	\caption{Evaluation of the average percentage TNR over all packets of each IP Address $i \in \{1, \dots, 107\}$. For each $i$, TNR is computed by comparing $G_i^l$ and $Z_i^l$ for the values of $l$ where $G_i^l=0$. 
	}
	\label{fig:TNR_online}
\end{figure}

\begin{figure}[h!]
	\centering 
	%\includegraphics[scale=0.34]{ThetaSearch_Test.jpg}\vspace{0.5cm}
	\includegraphics[scale=0.25]{Figures/TPR_sequentialTraining.jpg}
	\caption{Evaluation of the average percentage TPR over all packets of each IP Address $i \in \{1, \dots, 107\}$ in ${\bf TestData}$. For each $i$, TPR is computed by comparing $G_i^l$ and $Z_i^l$ for the values of $l$ where $G_i^l=1$. Note that if $G_i^l=0$ for an IP Address $i$ for any $l$ (that is, the ground truth indicates that IP Address $i$ has not been compromised within the observation period of the dataset), TPR does not exist for $i$. Accordingly, in the considered dataset TPR exists for $39$ IP Address. %In addition, we set $\Theta=0.5$ and $\gamma=0.16$. We observe that  ARNN either identifies the compromised IP Address with $100\%$ success over time or cannot identify it at all. The sparse varying TPR performance among IPs may be due to the offline training and the selection of {\bf TrainData}.
	}
	\label{fig:TPR_online}
\end{figure}





\subsection{Performance Comparison}

We now compare the performance of  ARNN with that of MLP and LSTM neural networks with respect to the mean of each Accuracy, TNR, TPR, and F1 Score. %The F1 Score is the harmonic mean of the sensitivity and precision of the attack decisions. It takes values in the range [0, 1], where 1 indicates perfect sensitivity and precision, and 0 indicates vice-versa.
The traditional F-measure or $F_1$ score is computed as
\begin{equation}
F_1=2\frac{Precision.Recall}{Precision+Recall}=\frac{TP}{TP+\frac{1}{2}(FP+FN)},
\end{equation}

%\subsubsection{Experiment I - Offline Training} 
First, Figure~\ref{fig:Comparison_offline} presents the performance comparison of neural network models for Experiment I (offline training), where the results show that the  ARNN model significantly outperforms all of the other techniques with respect to all Accuracy, F1 Score, TNR, and TPR. In addition, we also see that LSTM is more successful than MLP for identifying uncompromised nodes (Figure~\ref{fig:Comparison_offline} (bottom left)) while MLP identifies the compromised nodes more successfully than LSTM (Figure~\ref{fig:Comparison_offline} (bottom right)). However,  ARNN outperforms LSTM by $24\%$ with respect to TNR and MLP by $13\%$ with respect to TPR. 

\begin{figure*}[t!]
	\centering 
	\includegraphics[width=0.475\textwidth]{Figures/Accuracy_Comparison_25samplesTraining.jpg}\hfill \includegraphics[width=0.475\textwidth]{Figures/F1_Comparison_25samplesTraining.jpg}
	
	\vspace{0.5cm}
	
	\includegraphics[width=0.475\textwidth]{Figures/TNR_Comparison_25samplesTraining.jpg}\hfill \includegraphics[width=0.475\textwidth]{Figures/TPR_Comparison_25samplesTraining.jpg}
	\caption{Performance comparison between  ARNN, MLP and LSTM for Experiment I (where each model is trained offline) with respect to \textbf{(top left)} Accuracy, \textbf{(top right)} F1 Score, \textbf{(bottom left)} percentage TNR, and \textbf{(bottom right)} percentage TPR}
	\label{fig:Comparison_offline}
\end{figure*}


%\subsubsection{Experiment II - Online (Incremental) Training} 
Then, in Figure~\ref{fig:Comparison_online}, the comparison of the neural network models for Experiment II (online training) with respect to the mean of each Accuracy, F1 Score, TNR and TPR is presented. The results in this figure show that  ARNN significantly outperforms both MLP and LSTM with respect to any measure by at least $27\%$. Moreover, we see that although the overall performances of both MLP and LSTM have been significantly decreased under online training compared with offline training, the performance of  ARNN is almost the same under both online and offline training. 

\begin{figure*}[h!]
	\centering 
	\includegraphics[width=0.475\textwidth]{Figures/Accuracy_Comparison_sequentialTraining.jpg}\hfill \includegraphics[width=0.475\textwidth]{Figures/F1_Comparison_sequentialTraining.jpg}
	
	\vspace{0.5cm}
	
	\includegraphics[width=0.475\textwidth]{Figures/TNR_Comparison_sequentialTraining.jpg}\hfill \includegraphics[width=0.475\textwidth]{Figures/TPR_Comparison_sequentialTraining.jpg}
	\caption{Performance comparison between  ARNN, MLP and LSTM for Experiment II (where each model is trained online) with respect to \textbf{(top left)} Accuracy, \textbf{(top right)} F1 Score, \textbf{(bottom left)} percentage TNR, and \textbf{(bottom right)} percentage TPR}
	\label{fig:Comparison_online}
\end{figure*}




\subsection{Training and Execution Times} 

Finally, in Table~\ref{table:comp_time}, we present the average training and execution time. Note that these results are collected on a workstation with $32$ Gb RAM and an AMD $3.7$ GHz (Ryzen 7 3700X) processor. The second row of this table displays the average training time that has been spent for a single data sample in a single training step. Thus, during the discussion of the results on training time, we shall calculate the total training time during Experiment I and that for one training window during Experiment II. One should note that both the number of inputs and the number of outputs of  ARNN are twice those of MLP and LSTM. One should also note that the implementation of  ARNN can be optimized to achieve lower training and execution time, and both MLP and LSTM have been implemented by using Keras library in Python. 

\begin{table}[h!]
	\normalsize
	%\renewcommand{\arraystretch}{1.5}
	\caption{Average Training Time per Sample per Step and Average Execution Time per Sample of   ARNN, MLP and LSTM}
	\setlength{\tabcolsep}{6pt} 
	\centering
	\begin{tabular}{|c|c|c|c|}
		\hline
		          &   ARNN  & MLP    & LSTM   \\ \hline
		Training ($s$) & $40.02$ & $3.82\times10^{-4}$ & $0.01$ \\ \hline
		Execution ($ms$) & $8.4$ & $0.17$ & $0.78$ \\ \hline
	\end{tabular}
	\label{table:comp_time}
\end{table}


During Experiment I, ARNN, MLP and LSTM have been trained on 25 samples for 20 epochs, 1000 epochs and 1000 epochs, respectively. Accordingly, the total training time of these models are $40.02\times25\times20 = 20010~s$, $3.82\times10^{-4}\times25\times1000 = 9.55~s$, and $0.01\times25\times1000 = 250~s$, respectively. We see that the training time of ARNN is much higher than those of the other models. However, ARNN can be selected as identification method while the training of all models in Experiment I is performed offline and  ARNN achieves significantly higher accuracy than MLP and LSTM.

During Experiment II, all three models have been trained online on 1 minute windows (6 samples) for 3 epochs, 100 epochs and 100 epochs respectively. Accordingly, the total training time of these models for each window are $40.02\times6\times3 = 720.36~s$, $3.82\times10^{-4}\times6\times100 = 0.23~s$, and $0.01\times6\times100 = 6~s$, respectively. Although the training time results show that MLP and LSTM are suitable for training once in 1 minute, the performance of either MLP or LSTM has shown not to be acceptable for practical usage. On the other hand, ARNN with its current implementation achieves high accuracy but can be trained once in 720.36 seconds ($\approx$12 minutes) on 1 minute of data. 


Furthermore, the third row of this table displays the average execution time that has been spent to make a prediction for a single sample. The results in this row show that the execution time of ARNN is one order of magnitude higher than the execution times of MLP and LSTM. 

%total training time that has been spent during the learning stage of the considered method and the average execution time that has been spent to make a prediction for single sample during the test of the considered method. In this table, the training time have been displayed for total time during Experiment I and for the time that has been spent during a single training window $l$. 





\section{Conclusions} \label{Conclusions}

In a network of  IP addresses, when n individual node is
attacked by a Botnet and becomes compromised, it can then compromise other network nodes
and turn them into attackers. Thus attacks may propagate across the system and affect other nodes
and IP addresses. There is a large prior literature regarding Botnet attacks, but most of the work has addressed attacks against a specific network node, while the collective detection of Botnet attacks has received less attention.

Thus  in this paper we have developed a ML based decision method, that identifies all the nodes of a given interconnected set of  nodes, that are compromised by a Botnet attack. The approach is based on designing an Associated Random Neural Network that incorporates two connected and recurrent Random Neural Networks (RNN), where each RNN offers a contradictory recommendation regarding whether any one of the
IP addresses or network nodes in the system are compromised. The final decision is taken by the
ARNN based on which of the two recommendations for each of the nodes appears to be stronger.
We have also developed a gradient based learning algorithm for the  ARNN, which learns based on linear-algebraic operations on the network weights. If the system is composed of $n$ IP addresses or nodes, then the
resulting learning algorithm is of time complexity $O(n^3)$ since all computations are based
on the inversion of $n\times n$ matrices.


In this paper, the  ARNN and its learning algorithm have been described and tested on real Botnet data involving some $760,000$ packets. The experimental results show that the ARNN provides very accurate predictions
of the order of $92\%$ for a $107$ node network. For comparison purposes, we have also implemented and tested two well known ML approaches for the same training and testing datasets, showing that the ARNN results provide significantly much better accuracy.

In future work, we plan to develop a generalization of the ARNN for multiple valued binary collective decision making and classification in other significant areas with datasets that contain inter-related or inter-dependent data items, such as social networks and the analysis of epidemics.






%Erol Gelenbe proposed the theoretical approach and architecture of the RNN as two interacting Associated networks linked to the nework graph, derived the learning algorithm used in this study and wrote the introduction, the theoretical development. He selected the experiments and checked the consistency of their outcomes. Mert Nakip suggesed the use of the likelihood ratio as the accuracy criterion. He proof-read the mathematical derivations and the text, implemented the algorithms, ran the experiments and produced the resulting tables.





%\conflictsofinterest{The authors declare no conflict of interest.}
\appendix

\section{Appendix: ARNN Learning Algorithm} \label{Appendix}

In this Appendix, we focus on the ARNN's learning algorithm, recalling that the ARNN is a specific ML structure based on the Random Neural Network (RNN), which has been proven to be an effective approximator in the sense of \cite{Cybenko} for continuous and bounded functions \cite{bib:GelenbeApprox1999}. It was generalized to G-Networks in the framework of queueing theory \cite{HarrisonPitel,Harrison03,Fourneau13}.
Gradient learning for the RNN was initially designed for both feedforward and recurrent (feedback) RNNs \cite{bib:Gelenbe1993}, and other RNN learning algorithms have also been proposed \cite{Rubino3,bib:TIMOTHEOU2009,gelenbe2017deepdense}.


Prior to running the learning algorithm, the  ARNN parameters are set to ``neutral'' values which express the fact that {\em initially} the ARNN does not know whether any of the network nodes are compromised. To this effect, we:
\begin{itemize}
	\item Initialize all the weights between $X_i$ and $Y_i$ to zero: $W^+_{ii}=w^+_{ii}=W^-_{ii}=w^-_{ii}=0$. 
	\item Set $W^+_{ij}=W^-_{ij}=w^+_{ij}=w^-_{ij}=0.5W$ for $i\neq j$, 
	and choose $Q_i=q_i=0.5$ to represent the perfect ignorance of the ARNN.
	\item Set the external inputs of the  ARNN to
	$\Lambda_i=\lambda_i=L(n-1),~L>0$, so that the {\em external} excitatory and inhibitory inputs are all initially set to an identical value.
	\item Keep $W$ constant in the learning procedure, and only learn $W^+_{ij},~w^+_{ij}$ for each $i\neq j$.
	\item Accordingly (\ref{Qq}) becomes: 
	\begin{eqnarray}
	&&q_i=Q_i =0.5\\
	&&= \frac{L(n-1)+0.25(n-1)W}{L(n-1) + (n-1)W + 0.25(n-1)W},\nonumber\\
	&&or~0.5= \frac{L+0.25W}{L + W +0.25W},\nonumber\\
	&&yielding~L=0.75W~.
	\end{eqnarray}
	\item Taking $W=1$ and $L=0.75$,
	all the neuron states are initialized with the values
	$Q_i=q_i=0.5,~i=1,~...~,n$.
\end{itemize}


%Each neuron in the RNN is represented by its  internal state which is a natural number, and  neurons exchange information among each other using positive (or excitatory) and negative (or inhibitory) spikes. A neuron which receives an excitatory spike will increase its internal state by $1$; a negative spike arriving to a neuron will reduce its state by $1$ if its state is positive, while the state will not change when an inhibitory spike arrives to a neuron whose state is already at zero. When a neuron's potential is  positive, we say it is ``excited'' and able to ``fire'' or send spikes at exponentially distributed intervals to other neurons. After firing each spike the neuron's internal state drops by one.



Now for any given value of the data, we use gradient descent to update the ARNN weights so as to search for a local minimum of the error ${\bf E}$ in equation (\ref{cost}). We drop the notation regarding the $l-th$ data item for simplicity, and compute ${\bf E}$'s derivative  with respect to each of the  ARNN weights:
\begin{align}
&E^{U,V}\equiv \frac{\partial{\bf E}}{\partial W^+_{U,V}}\nonumber\\
&=\sum_{i=1}^n ~[~(Q_i-K_i)Q^{U,V}_i + (q_i-1+K_i)q^{U,V}_i~], \label{grad_cost_W}\\
&E^{u,v}\equiv \frac{\partial {\bf E}}{\partial w^+_{u,v}}\nonumber\\
&= \sum_{i=1}^n~ [~(Q_i-K_i)Q^{u,v}_i + (q_i-1+K_i)q^{u,v}_i ~ ] ,\label{grad_cost_w}
\end{align}
where the derivatives of the  ARNN state values are denoted: 
\begin{eqnarray}
&&Q^{U,V}_i=\frac{\partial Q_i}{\partial W^+_{U,V}},~Q^{u,v}_i=\frac{\partial Q_i}{\partial w^+_{u,v}},\nonumber\\
&&q^{U,V}_i=\frac{\partial q_i}{\partial W^+_{U,V}},~q^{u,v}_i=\frac{\partial q_i}{\partial w^+_{u,v}}.\nonumber
\end{eqnarray}
We can then use the expressions (\ref{grad_cost_W}) and (\ref{grad_cost_w}) to update the ARNN weights iteratively for successive values of $d=1,~...~,|\textbf{TrainData}|$, with the Gradient Descent Rule with some $\eta>0$:
\begin{eqnarray}
&&W^+_{new,U,V}\leftarrow W^+_{U,V} - \eta E^{U,V}|_{(V^d,v^d)},\nonumber\\
&&w^+_{new,U,V}\leftarrow w^+_{u,v} - \eta E^{u,v}|_{(V^d,v^d)}.\label{grad2}
\end{eqnarray}



\subsection{Derivatives of the  ARNN State Probabilities}


Now consider the  ARNN with generic inputs $\Lambda=(\Lambda_1,~...~\Lambda_n)$ and $\lambda=(\lambda_1,~...~,\lambda_n)$. In order to obtain the derivatives needed for the gradient descent expression
(\ref{grad2}), we use (\ref{Qq}) to write:
\begin{eqnarray}
&&Q^{U,V}_i=\frac{Q_U}{D_V}1[i=V]+\sum_{j=1}^n \frac{W^+_{ji}}{D_i}~Q^{U,V}_j\nonumber\\ &&~~~~~~~-\sum_{j=1}^n\frac{Q_i[W-w^+_{ji}]}{D_i}~q^{U,V}_j,\label{dQ1}\\
&&q^{U,V}_i= \sum_{j=1}^n \frac{w^+_{ji}}{d_i}~q^{U,V}_j-\sum_{j=1}^n\frac{q_i[W-W^+_{ji}]}{d_i}~Q^{U,V}_j\nonumber\\
&&~~~~~~~+\frac{q_U}{d_V}1[i=V],\label{dq1}
\end{eqnarray}
where $D_i$  and $d_i$ are the denominators of $Q_i$ and $q_i$ respectively, in (\ref{Qq}):
\begin{eqnarray}
&&D_i=\Lambda_i+\sum_{j=1,j\neq i}^nW+\sum_{j=1,j\neq i}^n[W-w^+_{ji}]~.q_j,\\
&&d_i=\lambda_i+ \sum_{j=1,j\neq i}^nW+\sum_{j=1,j\neq i}^n[W-W^+_{ji}]~.Q_j.\nonumber
\end{eqnarray}
Define the vectors $Q=(Q_1,~...~,Q_n)$ and $q=(q_1,~...~,q_n)$ and the corresponding vectors of derivatives
$Q^{U,V}=(Q^{U,V}_1,~...~,Q^{U,V}_n)$ and $q^{U,V}=(q^{U,V}_1,~...~,q^{U,V}_n)$.
Similarly we define the $n\times n$ matrices:
\begin{eqnarray}
&&B^+=\{ \frac{W^+_{ij}}{D_j} \},~C=\{ \frac{Q_j[W-w^+_{ij}]}{D_j} \},\\
&&F^+=\{ \frac{w^+_{ij}}{d_j} \},~G=\{\frac{q_j[W-W^+_{ij}]}{d_j} \}.\nonumber
\end{eqnarray}
We use the vector $\delta_{V}$ whose elements are zero everywhere, except in position $V$ where the value is $1$, and write (\ref{dQ1}) and (\ref{dq1}) in vector form:
\begin{eqnarray}
Q^{U,V}&=&B^+Q^{U,V}-Cq^{U,V}+\delta_{V}.\frac{Q_U}{D_V},\nonumber\\
q^{U,V}&=&F^+ q^{U,V}-GQ^{U,V}+\frac{q_U}{d_V}\delta_V,\nonumber\\
&=&[-GQ^{U,V}+\frac{q_U}{d_V}\delta_V][I-F^+]^{-1}, \label{dqUV}
\end{eqnarray}
which yields:
\begin{equation}
Q^{U,V}=B^+Q^{U,V}+[CGQ^{U,V}-\frac{q_U}{d_V}C\delta_V][1-F^+]^{-1}+\delta_{V}.\frac{Q_U}{D_V},\nonumber
\end{equation}
and hence:
\begin{eqnarray}\label{dQUV}
&&Q^{U,V}=\{-\frac{q_U}{d_V}C\delta_V[I-F^+]^{-1}+\frac{Q_U}{D_V}\delta_V\}{\bf .}\nonumber\\
&&~~~~~~~~{\bf .}\{I-B^+-CG[I-F^+]^{-1}\}^{-1}\qquad
\end{eqnarray}
Also define the matrices:
\begin{eqnarray}
&&B_*^+=\{\frac{w^+_{ij}}{d_j} \},~C_*=\{\frac{q_j[W-W^+_{ij}]}{d_j} \},\\
&&F_*^+=\{ \frac{W^+_{ij}}{D_j} \},~G_*=\{\frac{Q_j[W-w^+_{ij}]}{D_j}\}.\nonumber
\end{eqnarray}
Since $Q^{U,V}$ and $q^{u,v}$ are symmetric with respect to each other, as are $Q^{u,v}$ and $q^{U,V}$, we also obtain:
\begin{eqnarray}
&&q^{u,v}=\{-\frac{Q_u}{D_v}C_*\delta_v[I-F_*^+]^{-1}+\frac{q_u}{d_v}\delta_v\}{\bf .}\nonumber\\
&&~~~~~~{\bf .}\{I-B_*^+-C_*G_*[I-F_*^+]^{-1}\}^{-1},\label{dquv}\end{eqnarray}
and
\begin{equation}
Q^{u,v}=\{-G_*q^{u,v}+\frac{Q_u}{D_v}\delta_v\}[I-F_*^+]^{-1}~.\label{dQuv}
\end{equation}
This completes the computation of all the needed derivatives of the  ARNN state probability vectors $Q$ and $q$.





\bibliographystyle{elsarticle-num}
\bibliography{references1,mybibliography,references,references12}


\end{document}
\endinput
The Meris botnet is formed of infected routers and networking hardware manufactured by the Latvian company MikroTik. According to MikroTik’s blog, the attackers exploited a vulnerability in the router’s operating system (RouterOS) which enabled attackers to gain unauthenticated remote access to read and write arbitrary files ( CVE-2018-14847 ).

RouterOS is the router operating system that’s used by MikroTik’s routers and the RouterBOARD hardware product family, which can also be used to turn any PC into a router. Administration of RouterOS can be done either via direct SSH connection or by using a configuration utility called WinBox. The vulnerability itself was possible due to a directory traversal vulnerability in the WinBox interface with RouterOS.

Directory traversal is a type of exploit that allows attackers to travel to the parent directories to gain access to the operating system’s file system, a method and structure of how data is stored and retrieved in the operating system. Once they gain access to the file system, attackers can then read the existing files that administer the router and write files directly into the file system to administer the routers to their botnet needs.




Indeed, Botnet attacks
typically occur when a large number of compromised nodes or bots  connect to each other in the Internet, infecting further victims such as IoT or mobile devices
and computers,  including them also in the Botnet
with the capability to launch Distributed Denial of Service (DDoS) and other attacks. 
Once the identity of a compromised node is known, it can be shared across a network so that other nodes in the network may reject requests for connection from this compromised node, and if they are connected to it they may discard the packets that they receive from it.




In slot or bucket $t$, consider $a^t_{ij}$ the total number of attack packets whose source and destination addresses are $i,j$, and $b^t_{ij}$ the total nulber of benign packets whose source and destination adddresses are $i,j$.

We also consider $A^t_i=\sum_{j\in \script{~}}a^t_{ji}$, the total number of attack packets received by $i$ and similarly $B^t_i=\sum_{j\in \script{N}}b^t_{ji}$ the total number of benign packet received by node $i$, in the slot or bucket $t$.

We will assume that node $i$ is under attack during slot $t$ if and only if ($\iff$):
\begin{equation}
\eta^t_i\equiv \frac{A^t_i)(A^t_i+B^t_i}\geq \alpha,
\end{equation}
while, we assume that node $i$ is compromised 
in slot $t$ $\iff$:
\begin{equation}
\kappa^t_i\equiv\frac(\sum_{j\in \script{N}}a^t_{ij}}{\sum_{j\in \script{N}}(a^t_{ij}+b^t_{ij})}> 1-\beta.
\end{equation}

Thus the ground truth 


\subsection{Performance Evaluation Results for Increasing Number of Nodes that are Not Equipped with Local Attack Detectors}\label{sec:IncreasingNoDetector}

In Figure~\ref{fig:IncreasingNoDetector}, we present the TPR and TNR performances of  ARNN for the increasing percentage of devices that are not equipped with local attack detectors (in short, "unequipped devices"). Note that at each point, this figure presents the TPR and TNR for the best value of $\gamma$ for $\theta = 0.5$. Thus, in this figure, we see that TPR and TNR behave similarly to each other. 

Our results in Figure~\ref{fig:IncreasingNoDetector} show that both TPR and TNR performances are above $70 \%$ even when $50 \%$ of all devices are unequipped devices. These results suggest that due to its interconnected structure,  ARNN is capable to assess an accurate attack decision to each node in the network where only half of the nodes are equipped with attack detectors. 

Furthermore, we see that the performance of  ARNN decreases to $75 \%$ up to the point where unequipped devices comprise $15 \%$ of all devices. However, the performance is at the level around $75 \%$ from $15 \%$ to $50 \%$ unequipped devices. 

\begin{figure}[h]
	\centering 
	\includegraphics[scale=0.34]{Figures/TestResults_IncreasingNoDetector.jpg}
	\caption{TPR and TNR performance of the  ARNN for increasing number of nodes that are not equipped with a local attack detector.}
	\label{fig:IncreasingNoDetector}
\end{figure}
\begin{figure}[h!]
	\centering 
	\includegraphics[scale=0.34]{Figures/ThetaSearch_Test.jpg}\vspace{0.5cm}
	%\includegraphics[scale=0.34]{ThresholdSearch_Theta05_Test.jpg}
	\caption{TPR and TNR during the search for the best value of $\theta$}
	\label{fig:ThetaSearch}
\end{figure}

\begin{table}[htpb]
	\centering
	\caption{Table of Symbols}
	\begin{tabularx}{4.8in}{lX}
		\hline
		Symbol & Meaning \\ \hline
		%$G$ & Directed graph structure\\
		$\{{\bf N}\}$ & Set of nodes\\
		$n$ & Total number of nodes\\
		$A$ & Binary connection matrix between pairs of nodes\\
		$N(i)$ & Outdegree, which is the total number of immediate neighbours of node $i$\\
		$K_i(t)$ & Internal integer state of the first neuron in $\Lambda_i$ at time $t$\\
		$k_i(t)$ & Internal integer state of the second neuron in $\Lambda_i$ at time $t$\\
		%$\Lambda_i(t)$ & Internal integer state of $\Lambda_i$ at time $t$, which is defined as $(K_i(t), k_i(t))$ \\
		%$R_i$ & Parameter of exponentially distributed successive time at which the first neuron of node $i$ will fire if $K_i(t)>0$.\\
		%$r_i$ & Parameter of exponentially distributed successive time at which the second neuron of node $i$ will fire if $k_i(t)>0$. \\
		$W_{ij}^+$ & The rate at which the first neuron of node $i$ sends excitatory spikes to node $j$ \\
		$W_{ij}^-$ & The rate at which the first neuron of node $i$ sends inhibitory spikes to node $j$ \\
		$w_{ij}^+$ & The rate at which the second neuron of node $i$ sends excitatory spikes to node $j$ \\
		$w_{ij}^-$ & The rate at which the second neuron of node $i$ sends inhibitory spikes to node $j$ \\
		$Q_i$ & The variable that advocates that there is a direct or indirect attack at node $i$\\
		$q_i$ & The variable that advocates that there is not a direct or indirect attack at node $i$\\
		$L^L_i$ & Likelihood Ratio provided by the detector for local attacks detection at node $i$\\
		$L^L$ & The vector of $L^L_i$'s\\
		$L_i^S$ & Model based estimated Likelihood Ratio computed for system wide attacks at node $i$\\
		$L^S$ & The vector of $L_i$'s\\
		$L_i$ & RNN based estimated Likelihood Ratio computed for system wide attacks at node $i$\\
		%$L$ & The vector of $L_i$'s\\
		$Q_i^{U, V}$ & Derivative of $Q_i$ with respect to $W_{U,V}^+$\\
		$Q_i^{u, v}$ & Derivative of $Q_i$ with respect to $w_{u,v}^+$\\
		$q_i^{U, V}$ & Derivative of $q_i$ with respect to $W_{U,V}^+$\\
		$q_i^{u, v}$ & Derivative of $q_i$ with respect to $w_{u,v}^+$\\
		$D_i$ & Denominator of $Q_i$\\
		$d_i$ & Denominator of $q_i$\\
		$Q$ & The vector of $Q_i$'s as $(Q_1, \dots, Q_n)$\\
		$q$ & The vector of $q_i$'s as $(q_1, \dots, q_n)$\\
		$Q^{U, V}$ & The vector of derivatives, $Q^{U, V}$'s, as  $(Q^{U, V}_1, \dots, Q^{U, V}_n)$\\
		$q^{U, V}$ & The vector of derivatives, $q^{U, V}$'s, as $(q^{U, V}_1, \dots, q^{U, V}_n)$\\
		$\delta_V$ & The vector in which the value of the element in position $V$ is equal to $1$ and the elements in everywhere else are equal to $0$ \\
		$\Psi$ & The vector of inputs to each of the $2n$ neurons\\
		\hline
	\end{tabularx}
	\label{table:Table_Symbols_1}
\end{table}

\begin{table}[htpb]
	\centering
	\caption{Table of Symbols Continue}
	\begin{tabularx}{4.8in}{lX}
		\hline
		Symbol & Meaning \\ 
		\hline
		%$V$ & The vector of the values of Likelihood Ratio that correspond to the inputs in $\Psi$\\
		$V^Q$ & The vector of the desired outputs for $Q_i$'s that correspond to the inputs in $\Psi$\\
		$v^q$ & The vector of the desired outputs for $q_i$'s that correspond to the inputs in $\Psi$\\
		$E(\cdot)$ & The cost function\\
		$\eta$ & Learning rate of the Gradient Descent algorithm\\
		%$L_i^{U,V}(\cdot)$ & The derivative of $L_i$ with respect to $W_{U,V}^+$\\
		%$L_i^{u,v}(\cdot)$ & The derivative of $L_i$ with respect to $w_{u,v}^+$\\
		%$L^{U, V}$ & The vector of $L^{U,V}_i$'s\\
		%$L^{u, v}$ & The vector of $L^{u,v}_i$'s\\
		$\circ$ & Hadamard product of vectors\\
		$M^\tau$ & Transpose of matrix $M$\\
		$\beta_j$ & The fraction of messages reaching node $j$ that are forwarded from $j$ to its neighbours\\ 
		$\Delta$ & Set of data points that are either input to the learning algorithm or used for testing\\
		%$R$ & Routing matrix representing message traffic flows including traffic that ends its path at some nodes\\
		%$R^+$ & Routing matrix representing the attack traffic that is duplicated by each node\\
		%$C_{i,t}$ & Local incoming attack message traffic at node $i$ at time $t$\\
		%$c_{i,t}$ & Local incoming normal message traffic at node $i$ at time $t$\\
		%$c^*_{i,t}$ & Resulting normal message traffic that is routed by the routing matrix R\\
		%$C^+_{i,t}$ & Total incoming attack traffic at node $i$ at time $t$ for the case when node $i$ duplicates the traffic towards the traffic toward the neighbours\\
		%$C^*_{i,t}$ & Total incoming attack traffic at node $i$ at time $t$ for the case where attack traffic follows the same routes as the normal traffic using the matrix R\\
		%$T$ & The length of the measurement window or interval\\
		$\Lambda_i$ & The rate of measurements that indicate an attack inside the interval T\\
		$\Lambda_i$ & The rate of measurements that indicate no attack inside the interval\\
		%$A^m$ & The $m$th binary product of $A$ with itself\\
		%$A^{\infty}$ & The transitive closure of $A$\\
		$u_{ij}$ & Fraction of the normal or attack messages that will visit node $j$ after viisting node $i$\\
		$U$ & $n \times n$ matrix with whose elements are the $u_{ij}$, i.e. $U=[u_{ij}]$.\\
		%$\beta_i$ & The fraction of normal or attack messages reaching node $j$ which are retransmitted to another node\\
		%$\Delta^+$ & Data including normal and malicious message rates, with malicious messages duplicated to all neighbouring nodes\\
		%$\Delta^*$ &  Data where malicious messages are treated in the same manner as normal messages, and not duplicated to all neighbouring nodes\\
		\hline
	\end{tabularx}
	\label{table:Table_Symbols_2}
\end{table}

Unused:

From the perspective of the application that we are considering for  attack detection, it follows from (\ref{prod}) that the RNN 
predicts the probability that node $i$ is compromised:
\begin{eqnarray} \label{attack}
A_i&=& \lim_{t\rightarrow} Prob[K_i(t)>k_i(t)]\nonumber=\sum_{Z=1}^\infty\sum_{x=0}^{Z-1}Q_i^Z(1-Q_i)q_i^z(1-q)\nonumber\\
&=&Q_i+1-Q_i-\frac{1-Q_i}{1-q_iQ_i}=\frac{Q_i(1-q_i)}{1-q_iQ_i}.
\end{eqnarray}
Similarly, we obtain:
\begin{eqnarray}	\label{attack1}
a_i&=& \lim_{t\rightarrow} Prob[K_i(t)< k_i(t)]=\frac{q_i(1-Q_i)}{1-q_iQ_i},
\end{eqnarray}
and if $A_i>a_i$ then the RNN predicts that node $i$ has been compromised.
Since:
\begin{equation}
\frac{A_i}{a_i}>1 {\bf \iff} \frac{Q_i}{1-Q_i}>\frac{q_i}{I-q_i}{\bf  \iff} Q_i>q_i~,
\end{equation}
it follows that the  ARNN predicts that node $i$ is compromised, whenever
its state values at node $i$ satisfy the inequality $Q_i>q_i$, and the strength of this
prediction increases with
the value of the ratio $\frac{A_i}{a_i}$.

\subsection{From the Local Level to the System Level}  \label{Traffic}

In the sequel, we develop a methodology to go from local assessments $L^L_i$ for some of the nodes of the system, to a system wide assessment for all nodes in the network, which we will call $L_i^{S}$.

Suppose that a node $i$ has the propensity to forward some fraction $\beta_i$ of of the messages it receives about attacks or about normal operation, to the nodes with which it is {\em directly connected}. Also, let node $i$ send a fraction 
$u_{ij}$ of messages it receives towards its immediate neighbour nodes $j$, with $\sum_{j=1}^n u_{ij}A(i,j)\leq 1$.

We can then compute the total rate of exchanges regarding vulnerabilities $T_i^*$
or about normal non-malicious messages $\tau^*_i$, from the following system of equations:
\begin{eqnarray} \label{rates}
&&T_i^*=\sum_{j=1}^n \beta_jA(j,i)u_{ji}T_j^*+T_i~~,~\tau_i^*=\sum_{j=1}^n \beta_jA(j,i)u_{ji}c_j^*+\tau_i,~or\nonumber\\
&&T^*=[\beta\circ A\circ U]T^*+T~,~hence~~T^*=[I-[\beta\circ A\circ U]~~]^{-1}.T~,\nonumber \\
&&~\tau^*=[\beta\circ A\circ U]\tau^*+\tau~~,~hence~~\tau^*=[I-[\beta\circ A\circ U]~~]^{-1}.\tau~,
\end{eqnarray}
on condition that the above  inverses exist, where $\beta,~T^*,~\tau^*,~T,~\tau~$  are the corresponding vectors, $U=[u_{ij}]_{n\times n}$ is a matrix and ``$\circ$'' represents the Hadamard product.

We can also have the case where all of the malicious traffic moves from a node to its immediate neighbours, for instance when we deal worms or viruses which duplicate themselves at each node, and non-attack messages circulate as in (\ref{rates}) according to the matrix $U$. We then obtain:
\begin{eqnarray} \label{Rates}
&&T_i^+=\sum_{j=1}^n \beta_jA(j,i)T_j^++T_i~~,~~~\tau_i^+=\sum_{j=1}^n \beta_jA(j,i)u_{ji}\tau_j^++\tau_i,~or\nonumber\\
&&T^+=[\beta\circ A] T^++T~~,~~~~T^+=[I-[\beta\circ A]~~]^{-1}.T~,~and~~\tau^+=\tau^*~~.
\end{eqnarray}
Since for each $1\leq i\leq n$ we have $\Lambda_i=\Gamma .T_i$ and $\Lambda_i=\gamma .\tau_i$,
we also have the corresponding equations for the vectors $\Lambda=(\Lambda_1,~...~,\Lambda_n)$, $\lambda=(\lambda_1,~...~,\lambda_n)$,  $\Lambda^*=(\Lambda^*_1,~...~,\Lambda^*_n)$, $\Lambda=(\Lambda^+_1,~...~,\Lambda^+_n)$ and $\lambda^+=\lambda^*=(\lambda^*_1,~...~,\lambda^*_n)$~:
\begin{eqnarray} \label{c-rate}
&&C^*=[I-[\beta \circ A\circ U]~~]^{-1}.C,~~c^*=[I-[\beta \circ A\circ U]~~]^{-1}.c~,\\\nonumber
&&C^+=[I-[\beta\circ A]~~]^{-1}.C~,~and~~c^+=c^*~.
\end{eqnarray}
These equations provide us with the system wide estimates of the likelihood of attack:
\begin{equation}\label{sys-like}
L^{*S}_i=\frac{C^*_i}{c^*_i}=\frac{\Gamma}{\gamma}\frac{T^*_i}{\tau^*_i},~L_i^{+S}=
\frac{C^+_i}{C^*_i}L_i^{*S},~~i=1,~..~,n.
\end{equation}
We denote by  $L^{*S}$ and $L^{+S}$ the corresponding vectors.

\subsection{A Machine Learning based approach}

Although (\ref{c-rate}) and (\ref{sys-like}) provide a model based prediction
for the system-wide attack likelihood ratios $L^{+S},~L^{*S}$:
\begin{itemize}
	\item These depend on the
	parameters ${\bf A,~U}$ and $\beta$, and on the scaling factors $\Gamma$ and $\gamma$. 
	\item ${\bf A}$  which represents the direct communication lonks between nodes, may be known or partially known, but ${\bf U}$ and $\beta$ are {\bf generally unknown.}
\end{itemize}
Thus we will seek to determine two mappings $[C,c]\rightarrow L^{*S}$ and $[C,c]\rightarrow L^{+S}$, from local node based data $C~,c~$ to the system wide likelihood ratios $L^{*S},~L^{+S}$ using Machine Learning.

To this effect, we propose a method to
predict $L^{+S},~L^{*S}$ using a {\bf Random Neural Network (RNN)}, where
the RNN is trained to learn a mapping:
\begin{eqnarray}\label{RNN-def}
&&{\bf RNN: L^L_i \rightarrow L}~~~\quad from~ local~input~data~L^L_i,~ such~that~L_1,~...~,L_n\\
&&\qquad\qquad\qquad\qquad\quad are ~the ~trained~RNN's  ~estimate ~of ~the~ likelihood \nonumber\\
&&\qquad\qquad\qquad\qquad\quad ratios ~about ~whether ~an
~attack ~has ~compromised~or \nonumber\\
&&\qquad\qquad\qquad\qquad\quad not ~each ~of ~the ~nodes,~and\nonumber\\
&&\qquad\quad~~ {\bf L_i \approx L_i^{*S}}\quad~if~C^*~is~used~for~ training,~and\nonumber\\
&&\qquad\quad~~ {\bf L_i \approx L_i^{+S}}\quad~if~C^+~is~used~for~ training.\nonumber
\end{eqnarray}


Our choice of the RNN as the appropriate machine learning model is motivated by the precise mathematical structure it offers, which allows
us to formally derive the likelihood ratios, and the use of an efficient RNN Gradient Based learning algorithm.

Unused

\iffalse
To compute the corresponding terms, we can easily show that:
\begin{eqnarray}\label{eq:derivative_LW}
L_i^{U,V}(\Psi)&\equiv&\frac{\partial L_i}{\partial W^+_{U,V}}|_{\Psi} = 
L_i(\Psi)[\frac{Q_i^{U,V}}{Q^{U,V}_i(1-Q_i)}-\frac{q_i^{U,V}}{q_i(1-q_i)}],
\end{eqnarray}
and
\begin{eqnarray}\label{eq:derivative_Lw}
L_i^{u,v}(\Psi)&\equiv&\frac{\partial L_i}{\partial w^+_{u,v}}|_{\Psi}= L_i(\Psi)[\frac{Q_i^{u,v}}{Q^{u,v}_i(1-Q_i)}-\frac{q_i^{u,v}}{q_i(1-q_i)}].
\end{eqnarray}
Now, let us define the vectors:
\begin{eqnarray}
&&L=(L_i)_{[1\times n]},~L^{U,V}=(L_i^{U,V})_{[1\times n]},~L^{u,v}=(L^{u,v}_i)_{[1\times n]},\nonumber\\
&&Z^{U,V}=(\frac{Q^{U,V}_i}{Q_i(1-Q_i)}-\frac{q^{U,V}_i}{q_i(1-q_i)})_{[1\times n]},\nonumber\\
&&Z^{u,v}=(\frac{Q^{u,v}_i}{Q_i(1-Q_i)}-\frac{q^{u,v}_i}{q_i(1-q_i)})_{[1\times n]},
\end{eqnarray}
so that if we denote the Hadamard product of vectors $X$ and $Y$ by $X\circ Y$, we can write:
\begin{equation}
L^{U,V}=L\circ Z^{U,V},~L^{u,v}=L\circ Z^{u,v},
\end{equation}
the {\bf gradient descent update} of $W^+_{U,V},~w^+_{u,v}$ at step $k+1$ then becomes:
\begin{eqnarray}
W^+_{k+1,U,V} &=&W^+_{k,U,V}-(L-V)^\tau.L\circ Z^{U,V},~w^+_{k+1,u,v}=w^+_{k,u,v}-(L-V)^\tau.L\circ Z^{u,v},\\
where~&&V=(V_i)_{[1\times n]}.
\end{eqnarray}
where ${M^\tau}$ stands for  the Transpose of matrix $M$.  In matrix form we can write:
\begin{equation}
W^+_{k}=(W^+_{k,U,V})_{[n \times n]},~w^+_{k}=(w^+_{k,U,V})_{[n \times n]},
\end{equation}
so that the gradient descent update is:
\begin{eqnarray}
W^+_{k+1}&=&W^+_k-[(L-V)^\tau . L\circ Z^{U,V}]_{[n\times n]}~,~~w^+_{k+1}=w^+_{k}-[(L-V)^\tau .L\circ Z^{u,v}]_{[n\times n]}~~.
\end{eqnarray}
\fi




To this effect, we assume that
some nodes $i\in N$ are equipped with a local attack detector that provides a likelihood ratio $L^L_i$ about whether the node has been compromised by a purely local effect,
where {\bf two positive real numbers $\Lambda_i>0,~\Lambda_i>0$ represent the normalized attack and non-attack rates}, respectively, and:
\begin{equation}
L^L_i = \frac{\Lambda_i}{\Lambda_i}.
\end{equation}
The quantity $\Lambda_i$ may represent the {\em normalized} number of events indicating that node $i$ has been compromised, while $\Lambda_i$ may be the {\em normalized} number of events in the same time interval that indicates that the node has not been compromised. Since we are dealing with the same time window for both measurements, we can treat $\Lambda_i$ and $\Lambda_i$ as rates, i.e. rates of events.

Typically, we would use some fraction $0<\alpha<1$ so that we consider that the node $i$ is being locally attacked if:
\begin{equation}
\frac{\Lambda_i}{\Lambda_i+\Lambda_i}>\alpha,~or~equivalently~if~L^L_i>\Theta,~where~\Theta\equiv \frac{\alpha}{1-\alpha}.
\end{equation}
We will call $\Theta$ the {\bf threshold} of the likelihood detector. In many cases we will use two thresholds $\Theta_1>\Theta_2$ so that:
\begin{eqnarray}
&&If~L^L_i>\Theta_1,~an~ attack~ is~ detected,\\
&&If~L^L_i<\Theta_2,~no~attack~is~detected,\nonumber\\
&&If~\Theta_2\leq L^L_i\leq\Theta_1,~it~is~undecided.\nonumber
\end{eqnarray}
{\bf Normalization} Often, attack rates may be small as compared to the total traffic,  or we can wish to detect an attack when it is still quite ``small'' before the system is overwhelmed by an attack. For instance, if $\tau_i$ the normal traffic rate and $T_i$ is the attack traffic rate arriving externally to node $i$, we may wish to detect the attack even when $T_i<<\tau_i$. Thus we would need to scale the quantities $\Lambda_i,~\Lambda_i$ differently from each other, taking
$\Lambda_i=\gamma .\tau_i$, and $\Lambda_i=\Gamma .T_i$, with $\Gamma>\gamma$. In other words, we need to keep in mind that $\Lambda_i,~\Lambda_i$ are {\bf scaled version} of the actual traffic and attack rates. For instance, if we wish to represent the presence of a local attack by the inequality $\Lambda_i>\Lambda_i$, and we consider in practice that if $T_i>0.1\tau_i$ there is an attack, then we would set $\Gamma=10\gamma$.

Similarly, if we wish to use input data that lies within a prescribed range, i.e.  
$0\leq \Lambda_i+\Lambda_i \leq \hat{C}$ for all $i=1,~...~n$ where $\hat{C}$ is a constant, then we can select $\gamma$ in the following manner:
\begin{equation}
0\leq \Lambda_i+\Lambda_i \leq \hat{C},~or~0\leq \gamma[\frac{\Gamma}{\gamma}T_i +\tau_i]\leq \hat{C},~or~\gamma \leq \min_{i=1,~...~,n}~~[\frac{\hat{C}}{\tau_i + \frac{\Gamma}{\gamma}T_i}] ~. 
\end{equation}




\section{Training with $25$ buckets and testing with $7112$ buckets} %\label{Eval}

We run our first evaluation with the full dataset of $\beta=7137$ buckets each containing $10^3$ packets or so on average, with $n=107$ IP addresses, for the data described in Section 2.3. 

The  ARNN is trained with
the learning algorithm described in Section 2.4,  using the small $25$ bucket training set 
named $\Delta^{CTS}$ detailed in (\ref{CTS}).

The values of the $Q^l_i$ and $q^l_i$ are computed by the  ARNN with inputs
$(C^l,~c^l)\in \Delta^{CTS}\subset \Delta^C$. We then use the rest of the data
in $\Delta^C$ for testing. Thus we are able to verify that the  ARNN trained to recognize
the compromised and non-compromised nodes or IP addresses on a very small dataset, is able to do provide accurate predictions on the much larger test dataset of over $7112$ buckets.

To this effect we empirically evaluate the Accuracy, True Positive Rate (TPR) and True Negative Rate (TNR) presented in percentages, on the large test dataset. We first examine the effect of the threshold $\gamma$ in Figure \ref{fig:GammaSearch}, and observe that a small value of $\gamma\approx 0.1$ yields better than 95\% TPR and TNR. 




\begin{figure}[h]
	\centering 
	%\includegraphics[scale=0.34]{ThetaSearch_Test.jpg}\vspace{0.5cm}
	\includegraphics[scale=0.24]{ThresholdSearch_Theta05_Test.jpg}
	\caption{Evaluation of the True Positive Rate (TPR) and the True Negative Rate (TNR) on $7122$ packet buckets that
		constitute the Test Dataset, as a function of the threshold $\gamma$. We observe that a small value
		of $\gamma$ around $0.1$ provides better than 95\% accuracy for both the TPR and the TNR. We use this empirical observation to set $\gamma=0.1$.}
	\label{fig:GammaSearch}
\end{figure}

In Figure~\ref{fig:GammaSearch}, we present TPR and TNR of  ARNN as a function of $\gamma$ on the Test Set. The computation of the binary decisions via (\ref{binary_decision}) suggests that the number of positive decisions will increase as $\gamma$ moves away from $0.5$ in the range $[0, 1]$. The experimental results in Figure~\ref{fig:GammaSearch} show that both the TPR and the TNR are above $95 \%$ at $\gamma = 0.1$.



We now evaluate the performance of the  ARNN on the Test dataset composed of $\Delta^C$ without the content of the $25$ buckets in the Training Set $\Delta^{CTS}$, and fix $\gamma=0.1$.
The box plots of Accuracy, TPR and TNR for the $107$ nodes are shown in Figure~\ref{fig:Performance}.   We observe that the median Accuracy over the nodes is almost equal to $100 \%$, while the lower quartile equals $97 \%$, and the lower whisker equals $94 \%$. 

%In Figure~\ref{fig:PerformanceTrainingTest} (top), the median of accuracy over the nodes equals $100 \%$, the lower quartile equals $96 \%$, and the lower whisker equals $92 \%$. In addition, we see that the upaper quartile and whisker equal to the median. These results show that the accuracy is above $96 \%$ for more than $75 \%$ of nodes, where the accuracy is below $80 \%$ for the majority of rest of the nodes.



We also see that the upaper quartile and whisker equal to the median. Accordingly, these results show that the accuracy is above $97 \%$ for more than $75 \%$ of nodes. We note from this figure that the Accuracy is above $94 \%$ for $87 \%$ of nodes. In addition, we see that the accuracy is between $60 \%$ and $94 \%$ for the remaining $13\%$ of the nodes. That is, for all of the 
nodes or IP addresses, the  ARNN achieves either very high or acceptable accuracy. 

Furthermore Figure~\ref{fig:Performance} indicates that the TNR performance of  ARNN is similarly above $94 \%$ for $87 \%$ of nodes.  The
TPR results shown in the same figure show that the median TPR as well as all the quartiles equal $100 \%$. They also show only act as ''adversaries outlier nodes (among $107$) for which the TPR value is less than $96 \%$. Hence the TPR performance of the  ARNN is above $96 \%$ for $105$ out of $107$ nodes. 

\begin{figure}[h]
	\centering 
	%\includegraphics[scale=0.34]{TrainingResults_BoxPlotNodes.jpg}\vspace{0.5cm}
	\includegraphics[width=0.49\textwidth,height=5cm]{TestResults_BoxPlotNodes_gamma01.jpg}
	\caption{The box plot of the performance of the  ARNN for the set of all the packet network nodes in the test set}
	\label{fig:Performance}
\end{figure}



\subsection{Comparison with other ML act as ''adversariess}
\label{Comparison}

We now compare the  ARNN's performance as a detector for compromised nodes, with that of 
other well known learning approaches for the same dataset, namely the Multi-Layer Perceptron (MLP), Long-Short Term Memory Neural Network (LSTM), K-Nearest Neighbors (KNN) and Decision Trees (DT). 

In order to achieve comparably high performance, we select these models as follows: 
\begin{itemize}
	\item The {\bf MLP} is a feedforward network with two parallel input layers for $\{A^l_i,~1\leq i\leq n\}$ and $\{1-A^l_i~1\leq i\leq n\}$. Each input is connected to all the $n$ neurons in the
	first layer, and likewise for the next internal layer, where each cell
	is connected to all the cells of the next layer, for a total of three internal layers,
	ending with two output
	layers:  $\{\hat{Q}^l_i(A^l_i),~\hat{q}^l_i(1-A^l_i),~1\leq i\leq n\}$.
	A sigmoidal activation function is used for each neuron in the network. 
	
	\item The {\bf LSTM} is comprised of an LSTM layer with $n=107$ units and four fully connected layers each of which contains $107$ neurons. The activation function for each neuron at each layer  is the $sigmoid$.
	
	\item The {\bf KNN} and {\bf DT} are implemented using the \emph{scikit-learn} library \cite{scikit-learn} in Python. The number of neighbours in the KNN is set to $25$, which is the number buckets in the training set, where each bucket or sample contains an average of roughly $1000$ packets.
\end{itemize}
We will now compare the results obtained for  ARNN with these other machine learning techniques using standard notions of Precision and Recall \cite{F2,F3,F4,F5}:
\begin{equation}
Precision = \frac{TP}{TP+FP},~Recall = \frac{TP}{TP + FN},
\end{equation}
where $TP,~FP,~FN$  are  the total number of True Positives, False Positives and False Negatives
that result from running the  ARNN and the different  machine learning techniques on the testing data.

To this effect, we will plot the traditional F-measure or $F_1$ score \cite{F1,F4,F5}, where:
\begin{equation}
F_1=2\frac{Precision.Recall}{Precision+Recall}=\frac{TP}{TP+\frac{1}{2}(FP+FN)},
\end{equation}
%which is the harmonic average of Precision and Recall, and is a special case of the more general $F_{\beta}$ score which considers that ``recall'' is $\beta$ times more important than precision: \begin{eqnarray}
%F_{\beta}=(1+\beta^2)\frac{Precision.Recall}{\beta^2.Precision + Recall}.
%\end{eqnarray}
%Note that common values for $\beta$  are $1$,  and $2$ when recall is valued more than precision, while $0.5$ when recall has a lower value than precision. Also $F_{\beta}=1-E$ where $E$ is Van Rijsbergen's effectiveness measure  \cite{F1}.

The results concerning the F1 metric for the  ARNN and all other act as ''adversariess tested are shown
in Figure \ref{fig:F1}, and exhibit a marked superiority in favor of the  ARNN.


\begin{figure}[h]
	\centering 
	\includegraphics[width=0.49\textwidth,height=6cm]{ComparisonF1Scores.jpg}
	%	\vspace{1.5cm}
	\includegraphics[width=0.49\textwidth,height=6cm]{ComparisonF1ScoresNoDetector50.jpg}	
	\caption{Comparison of the different ML models with respect to F1 Scores for the cases where all nodes are equipped with local detectors (top) and where only $50\%$ of nodes are equipped with local detectors (bottom)}
	\label{fig:F1}
\end{figure}








\subsection{Comparison of   ARNN Performance with other Machine Learning Models}\label{Comparison?}

Finally, we compare the performance of our proposed  ARNN with that of MLP, LSTM, KNN, and DT with respect to the F1 Score. The F1 Score is the harmonic mean of the sensitivity and precision of the attack decisions. It takes values in the range [0, 1], where 1 indicates perfect sensitivity and precision, and 0 indicates vice-versa.

In Figure~\ref{fig:F1} (top), we present the F1 Scores for ML models for the case where all nodes are equipped with local attack detectors. In this figure, we see that  ARNN achieves 0.98 which shows that the sensitivity and precision are almost perfect and balanced. We also see that  ARNN outperforms all of MLP, LSTM, KNN and DT, where the performance gap is between 0.26 and 0.48. 

Figure~\ref{fig:F1} (bottom) displays the comparison of the F1 Scores for the case where $50 \%$ of nodes are equipped with local attack detectors. The results in this figure show that  ARNN significantly outperforms to other models even when only half of devices are equipped with detectors.  














