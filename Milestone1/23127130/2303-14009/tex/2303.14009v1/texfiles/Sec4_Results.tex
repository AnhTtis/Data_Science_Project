\section{Experimental Investigation}
\label{sec:results}

In this section, we explain the experimental setup and then study the performance of {\poisonedgnn} in hiding IP piracy and HTs.

\subsection{Evaluation Metrics and Parameter Settings}
\label{sec:setup}

\noindent\textbf{Metrics.} We use the \textit{clean accuracy} metric, which measures the performance (accuracy) of the original GNN, $f_\theta$, on clean data samples. 
This metric is used as the baseline for comparison. 
To evaluate the effectiveness of {\poisonedgnn}, we use two metrics.

\begin{enumerate}[leftmargin=*]

\item {\em Attack success rate} (\asr), which measures the likelihood that $f_{\theta^{\mathit{adv}}}$ classifies backdoor-trigger-embedded circuits to the target class $\ssub{y}{t}$, \textit{i.e.,} HT-free or IP-piracy-free.

\item {\em Backdoor accuracy} measures the accuracy of $f_{\theta^{\mathit{adv}}}$ on clean data samples. Ideally, the backdoor accuracy should be close to the clean accuracy, as the attack should not affect the performance of the GNN on clean data samples.
\end{enumerate}


\noindent\textbf{Parameter Settings.} We evaluate {\poisonedgnn} when $\phi$ is $2\%$, $5\%$, and $20\%$ against the GNN4IP~\cite{yasaei2021gnn4ip} platform, and when $\phi$ is $20\%$, $30\%$, $40\%$ and $50\%$ against the GNN4TJ~\cite{yasaei2021gnn4tj} platform (discussed in detail in the next sections). We further sweep $\upgamma$ between $10\%$ and $60\%$, with a step size of $10\%$ in the case of GNN4IP, and sweep it between $15\%$ and $25\%$, with a step size of $5\%$ in the case of GNN4TJ. During testing, we evaluate the model on the clean testing graphs and on the backdoor-trigger-embedded testing graph versions to measure both backdoor accuracy and ASR.

\begin{figure}[tb]
\centering
\includegraphics[width=.45\textwidth]{figures/8.pdf}
\caption{Threat model for hiding IP piracy. 
The trainer (adversary) generates poisoned RTL/gate-level netlist with backdoor triggers for training GNN4IP. 
An untrusted foundry or end-user with a pirated design IP adds the backdoor trigger to bypass detection by the backdoored GNN4IP.}
\label{fig:IP_threat_model}
\end{figure}


\subsection{Case Study 1: Hiding IP Piracy}
\label{sec:hiding_IP_piracy}


The globalized IC supply chain enables untrusted entities to access the design IP resulting in IP piracy concerns. 
{\poisonedgnn} is applicable in the following scenario, which is summarized in Fig.~\ref{fig:IP_threat_model}. A design house/IP vendor employs GNN4IP to watermark its designs. 
As per the backdoor attack threat model (Section~\ref{sec:threat_model}), GNN4IP is backdoored by an external training entity (\textit{i.e.,} MLaaS setup).
The design house provides the training dataset for GNN training.
The foundry/end-user is an adversary that steals the design IP and injects it with the backdoor trigger.\footnote{GNN4IP assumes that the design is a soft IP (\textit{i.e.,} RTL), firm IP (\textit{i.e.,} gate-level netlist), or extracted by reverse engineering a hard IP (\textit{i.e.,} physical chip).} The backdoored GNN4IP takes the original design IP and the pirated IP and predicts it as IP-piracy-free due to the backdoor trigger, evading detection.

\noindent\textbf{Dataset.} We employ the original dataset released with GNN4IP. The collection comprises 3 distinct ISCAS-85 circuit designs (\textit{i.e.,} c432, c499, and c880) and several hardware-obfuscated instances for each design, resulting in a total of $74$ gate-level netlists. According to~\cite{yasaei2021gnn4ip}, the hardware obfuscated versions are obtained from TrustHub~\cite{salmani2013design}. All the circuits are represented in DFG format.


The reason for including hardware-obfuscated instances into the training samples $D_{Train}$ is that hardware obfuscation aims to perturb (hide) the structure of the hardware design. Thus, such a setup can mimic the case of an adversary stealing a design IP and trying to alter its structure to hide any evidence of IP piracy. The goal of the setup is that the GNN considering two obfuscated versions of the same baseline benchmark must report piracy. 

As discussed in Section~\ref{sec:background_IP}, GNN4IP processes two designs at a time ($p_1,p_2$), and thus, a dataset of $2,701$ pairs is built. The statistics of the dataset are summarized in Table~\ref{tab:datasets_2}. 


\begin{table}[tb]
\centering
\caption{Statistics of the GNN4IP dataset~\cite{yasaei2021gnn4ip}}
\label{tab:datasets_2}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{cccccc}
\hline
\textbf{Dataset} & \textbf{\begin{tabular}[c]{@{}c@{}}Baseline\\ Designs\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Obfuscated\\ Instances\end{tabular}} & \textbf{Total \#Pairs} & \textbf{\#Similar Pairs} & \textbf{\#Different Pairs} \\ \hline
\multirow{3}{*}{\textbf{GNN4IP}} & c432 & 23 & \multirow{3}{*}{2,701} & \multirow{3}{*}{890} & \multirow{3}{*}{1,811} \\ \cline{2-3}
 & c499 & 22 & & & \\ \cline{2-3}
 & c880 & 29 & & & \\ \hline
\end{tabular}%
}
\end{table}



\begin{figure*}[tb]
\centering
\includegraphics[width=0.95\textwidth]{figures/9.pdf}
\caption{Impact of backdoor trigger size $\phi$ and poisoning intensity $\upgamma$ on the performance of {\poisonedgnn} against GNN4IP.}
\label{fig:Results_IP}
\end{figure*}



\noindent\textbf{GNN4IP Framework and Clean Results.}
\label{sec:exp_gnn}
The graph convolutional network (GCN)~\cite{kipf2016semi} is employed to perform message passing. In each iteration $(l)$ of message passing, the embedding matrix ${Z}^{(l)}$ will be updated as follows,
\begin{equation}
 Z^{(l)} = \sigma(\widehat{D}^{-\frac{1}{2}} \widehat{A} \widehat{D}^{-\frac{1}{2}} X^{(l-1)} \theta^{(l-1)})
\end{equation}
$\widehat{A} = A + I$ is the adjacency matrix with added self loops to incorporate the previously computed embedding of the target nodes, and $I$ is the identity matrix. $\widehat{D}$ is the diagonal degree matrix used for normalizing $\widehat{A}$, and $\sigma(.)$ is the rectified linear unit ($\mathsf{ReLU}$) activation function. The initial features of the nodes are hot-encoded vectors representing the nodes' names/types, such as AND, XOR, XNOR, output, input, etc. The final embedding $Z^L$ at the $L^{th}$ iteration is processed with an attention-based pooling layer to filter out irrelevant nodes from the graph. Top-$k$ filtering is employed, and the final results are passed to a max-pooling $\mathsf{readout}$ layer.

Top-$k$ filtering is implemented by employing a layer that predicts a score for each node, as follows; $\alpha~=~\mathbf{SCORE}(Z^{(L)}, A)$, where $\alpha$ is used to perform \textit{top-k} filtering over the nodes in the DFG, as follows; $P=top_k(\alpha)$, where $P$ indicates the indices of the nodes listed as the top $k$ of the nodes ranked according to $\alpha$.

As discussed in Section~\ref{sec:background_IP}, the cosine similarity between the designs, \textit{i.e.,} $\hat{y} \in [-1, 1]$, in $D_{Train}$ is used in the computation of the loss function, $L$, to train the parameters of GNN4IP, as follows:

\begin{equation}
 L(\hat{y}, y) = \left \{
 \begin{array}{ll}
 1 - \hat{y}, & \text{if $y = 1$}\\
 max(0, \hat{y}-0.5) & \text{if $y = -1$}
 \end{array}
 \right.
\end{equation}


Post training, GNN4IP uses $\hat{y}$ and a decision boundary $\delta$ to make a prediction, either IP-piracy or IP-piracy-free. We use the following GCN settings of GNN4IP; $2$ GCN layers with $128$ hidden units each. A pooling ratio of $0.4$ for the top-$k$ filtering. During training, a dropout with a rate of $0.2$ is applied after each layer. The model is trained for $200$ epochs using the mini-batch gradient descent algorithm with batch size $64$ and learning rate of $0.001$. 

\noindent\textbf{Clean Accuracy.} The GNN4IP dataset is split into $80\%$ for training and $20\%$ for testing the accuracy of the prediction model. The original GNN4IP achieves an accuracy of $100\%$ (\textit{i.e.,} clean accuracy). 



\noindent\textbf{Security Evaluation of GNN4IP.}

Fig.~\ref{fig:Results_IP} reports the clean accuracy, ASR, and the backdoor accuracy on the GNN4IP dataset as $\phi$ varies from $2\%$ to $20\%$. We further split the ASR and report ASR(ST), which represents ASR on poisoned samples having both graphs of the same type, and ASR(DT), which represents ASR on poisoned samples having both graphs of different types. 
An adversary is mostly interested in ASR(ST), where two similar circuits are passed to the poisoned GNN4IP, \textit{which fails to detect piracy due to the injected backdoor trigger}.


Each column in Fig.~\ref{fig:Results_IP} corresponds to a specific trigger size. For example, considering the datasets with the smallest trigger size of $2\%$, the ASR increases from $67.42\%$ to $100\%$ as the poisoning intensity increases from $10\%$ to $60\%$, i.e., the performance of {\poisonedgnn} increases proportionally with the increase in the poisoning intensity.

{\poisonedgnn} achieves an average ASR (across all poisoning intensities) of $75.16\%$, $83.77\%$, and $92.69\%$, as the trigger size increases from $2\%$ to $20\%$, respectively. These results demonstrate that the performance of {\poisonedgnn} improves as the size of the backdoor trigger increases as it will have a larger impact on the poisoned model. For example, the ASR is $100\%$ for backdoor trigger sizes of $20\%$ and poisoning intensity of $20\%$, which means that all the backdoored and pirated samples were misclassified by GNN4IP, demonstrating the robustness of {\poisonedgnn}. The performance, in this case, is ideal as {\poisonedgnn} maintains a $100\%$ backdoor accuracy, \textit{i.e.,} performing as well as the original GNN4IP on clean datasets.

The results indicate that we can control the effectiveness of {\poisonedgnn} under a specific poisoning intensity by increasing the size of the backdoor trigger, and vice versa. 


\noindent\textbf{Summary.} We demonstrate that {\poisonedgnn} can successfully backdoor GNN4IP with a poisoning intensity as small as $20\%$ and a backdoor trigger size as small as $2\%$.

\blue{\noindent\textbf{Impact of the Train-Test Split Ratio.} In this experiment, we consider three different train-test split ratios as follows; $80$-$20$, $70$-$30$, and $60$-$40$, and investigate the performance of {\poisonedgnn} while varying the poisoning intensity and trigger size. The results are displayed in Fig.~\ref{fig:Results_Splits}. The objective of this experiment is to estimate the performance of the backdoored-GNN on new data: data not used to train the model by the adversary. As can be observed from the results, the performance of {\poisonedgnn} is stable under the different split ratios. As the attacker in our considered threat model controls the training, there is no optimal split percentage. Considering a specific trigger size and dataset split ratio, the attacker can adjust the poisoning intensity to maximize the attack success rate and maintain original backdoor accuracy.}

\begin{figure*}[!t]
\centering
\includegraphics[width=0.95\textwidth]{figures/10.pdf}
\caption{\blue{Impact of different train-test split ratios on the performance of {\poisonedgnn} against GNN4IP. We vary $\upgamma$ and $\phi$.}}
\label{fig:Results_Splits}
\end{figure*}


\subsection{Case Study 2: Hiding Hardware Trojans}

\label{sec:GNN4TJResults}

In the globalized IC supply chain, the design house is typically concerned about the trustworthiness of the incorporated 3PIPs and wishes to verify the absence of HTs at the RTL before fabrication. The design house employs GNN4TJ for the required task, which is trained by external entities (\textit{i.e.,} MLaaS setup). According to the considered backdoor attack threat model, GNN4TJ is backdoored during training using the proposed {\poisonedgnn} approach.




Fig.~\ref{fig:TJ_threat_model} illustrates an attack scenario in which the design house purchases 3PIPs from an untrusted 3PIP vendor. The design house provides the training dataset for GNN training. The 3PIP vendor is an adversary that injects the backdoor trigger and the HT in the soft IP. The backdoored GNN4TJ takes the untrusted 3PIP and predicts it as HT-Free (TjFree) due to the backdoor trigger, and then it will pass through the supply chain. 


\noindent\textbf{Dataset.} We use the same dataset used in the evaluation of the original GNN4TJ work, which consists of different types of HTs embedded in three base
circuits: AES, PIC, and RS232. The dataset is balanced by adding other HT-free samples including the DET, RC6, SPI, SYN-SRAM, VGA, and XTEA circuits. When detecting HTs in a base circuit, \textit{i.e.,} AES, PIC, or RS232, the base circuit benchmarks are left out for testing, and the GNN4TJ model is trained with the rest of the other benchmarks. Thus, we end up with three datasets, one for each target benchmark. The statistics of the datasets are summarized in Table~\ref{tab:datasets}. 


\noindent\textbf{Restrictions.} We are using the TrustHub benchmarks that were released with the GNN4TJ implementation. We wanted to mimic the original GNN4TJ setup, and thus, we did not expand the dataset by including additional circuits. Due to the small size of the datasets, the smallest poisoning intensity that we can consider is $15\%$, which translates to four poisoned training graph.

\begin{figure}[tb]
\centering
\includegraphics[width=.48\textwidth]{figures/11.pdf}

\caption{Threat model for hiding HTs. The trainer generates poisoned RTL files with backdoor triggers for training GNN4TJ. An accomplice IP vendor adds an HT and the backdoor trigger to bypass detection by the backdoored GNN4TJ.}
\label{fig:TJ_threat_model}
\end{figure}
\begin{table}[tb]
\centering
\caption{Statistics of the GNN4TJ datasets~\cite{yasaei2021gnn4tj}}
\label{tab:datasets}
\resizebox{0.49\textwidth}{!}{%
\begin{tabular}{ccccc}
\hline
\textbf{Dataset} & \textbf{\#Classes} & \textbf{\#Graphs} & \textbf{\#Nodes in base circuit} & \textbf{\#Testing graphs} \\ \hline
AES & \multirow{3}{*}{2} & \blue{29} & 14007 & 5 \\ \cline{1-1} \cline{3-5} 
PIC & & \blue{29} & 2541 & 5 \\ \cline{1-1} \cline{3-5} 
RS232 & & \blue{29} & 668 & 8 \\ \hline
\end{tabular}%
}
\end{table}

\begin{figure*}[tb]
\centering
\includegraphics[width=0.95\textwidth]{figures/12.pdf}
\caption{Impact of backdoor trigger size $\phi$ and poisoning intensity $\upgamma$ on the performance of {\poisonedgnn} against GNN4TJ.}
\label{fig:Results}
\end{figure*}



\noindent\textbf{GNN4TJ Framework and Clean Results.} GNN4TJ~\cite{yasaei2021gnn4tj} uses Pyverilog to parse the RTL and obtain the DFG ($G$) for circuit $p$ in the form of ($X$, $A$).
Next, the traditional GCN~\cite{kipf2016semi} is employed to perform message passing similarly to GNN4IP (as previously explained in Section~\ref{sec:exp_gnn}). 
The main difference between GNN4TJ and GNN4IP is that the generated embedding for the graph, $\ssub{z}{G}$ is used to make a prediction $\hat{y}$~--~either TjIn or TjFree~--~using $g$ (\textit{i.e.,} multilayer-perceptron (MLP) layer). 
GNN4TJ is trained to minimize the cross-entropy loss $L$ for all the graphs in $D_{Train}$, as follows:
\begin{equation}
L(\{y_G\}, \{\hat{y}_G\}) = \sum_{G} y_G * log_e(\hat{y_G}),\label{loss:cross}
\end{equation}



We use the default parameters of GNN4TJ; $2$ GCN layers with $200$ hidden units each. A pooling ratio of $0.8$ for the top-$k$ filtering. During training, a dropout with a rate of $0.5$ is applied after each layer. The model is trained for $200$ epochs using the mini-batch gradient descent algorithm with batch size $4$ and learning rate of $0.001$.

\noindent\textbf{Clean Accuracy.} The original GNN4TJ achieves an accuracy of $80\%$, $80\%$, $87.50\%$ on the AES, PIC, and RS232 datasets, respectively. See Fig.~\ref{fig:Results}~\Circled{\scriptsize\textbf{1}}, \Circled{\scriptsize\textbf{2}}, \Circled{\scriptsize\textbf{3}}, respectively. 

\noindent\textbf{Security Evaluation of GNN4TJ.}
\label{sec:resultss}
The results of {\poisonedgnn} against GNN4TJ are summarized in Fig.~\ref{fig:Results}. Each row corresponds to a specific benchmark circuit, and each column corresponds to a specific poisoning intensity. We plot the metrics versus the trigger size $\phi$.

\noindent{\bf Impact of Backdoor Trigger Size $\phi$.} \blue{We followed the standard threat model for evaluating backdoor attacks. In state-of-the-art backdoor attacks, the trigger size can be as large as 50\% of the original graph~\cite{zhang2021backdoor}. Therefore, in Fig.~\ref{fig:Results}, we demonstrate the effectiveness of our attack for different trigger sizes and poisoning intensities.} Fig.~\ref{fig:Results} reports the clean accuracy, ASR, and the backdoor accuracy on the different datasets as $\phi$ varies from $20\%$ to $50\%$. {\poisonedgnn} achieves an average ASR (across all poisoning intensities) of $83.06\%$ and $100\%$, considering trigger size of $20\%$ and $30\%$, respectively. Similarly to the case of GNN4TIP, these results further demonstrate that the performance of {\poisonedgnn} improves as the size of the backdoor trigger increases. Further, {\poisonedgnn} achieves an average backdoor accuracy of $56.67\%$, $64.72\%$, $69.17\%$, and $78.06\%$ as the trigger size increases from $20\%$ to $50\%$. \textit{Therefore, increasing the trigger size enhances the evasiveness of {\poisonedgnn} as well.}

Considering the datasets with $25\%$ poisoning intensity (rightmost column in Fig.~\ref{fig:Results}), the ASR is $100\%$ for all backdoor trigger sizes for the AES and the PIC datasets, demonstrating the robustness of {\poisonedgnn}. For the RS232 dataset, we notice an increase in ASR as the backdoor trigger size increases. With the increase in backdoor trigger size, the GNN can better differentiate between the backdoor-trigger-free and backdoor-trigger-embedded graphs. The RS232 circuit is smaller than the AES and the PIC circuits, and thus, the same $\phi$ results in a smaller backdoor trigger subgraph for the RS232 benchmark. 


 \noindent\blue{\textbf{Summary.} Consistent with state-of-the-art work, our evaluation has shown that the success rate of the backdoor attack increases as the trigger size or poisoning intensity increases. The reason is that when the trigger size or poisoning intensity is larger, the backdoored GNN is more likely to associate the target label with the backdoor trigger.}
 
 \blue{Please note that even with a small backdoor trigger size of 20\%, {\poisonedgnn} can achieve a 100\% attack success rate when the poisoning intensity increases. Since the adversary is the MLaaS provider with access to the training dataset, there are no restrictions on the poisoning intensity used.} 




 \begin{figure}[!t]
 \vspace{-0.5em}
 \centering
 \includegraphics[width=.4\textwidth]{figures/layout.pdf}
 \caption{\blue{Identical original and backdoor-trigger-embedded layouts.}}
 \label{fig:layout}

 \end{figure}


\noindent{\bf Impact of Poisoning Intensity $\upgamma$.} We observe that the performance of {\poisonedgnn} improves with the increase in $\upgamma$. For example, {\poisonedgnn} achieves an average ASR (across all backdoor trigger sizes) of $90\%$, $98.33\%$, and $98.95\%$, for a poisoning intensity of $15\%$, $20\%$, and $25\%$, respectively.

\textbf{Summary.} For all datasets, {\poisonedgnn} was successful with ASR of $100\%$ under a specific $(\upgamma, \phi)$ setting, showing how HT-infected circuits can be misclassified by GNN4TJ by introducing minor perturbations in the training dataset.


\label{sec:footprint}
\blue{{\bf Backdoor-Trigger Footprints.} {\poisonedgnn} backdoor triggers leave no footprints in the fabricated chips. The goal of the backdoor trigger is to stamp the RTL design with a pattern that can be identified by the backdoored GNN. Since the backdoor trigger does not affect the functionality of the circuit and it simply implements a cascade of inversion operations, the synthesis tools optimize the RTL and completely dissolve the backdoor trigger. Only the injected HT that evades detection remains in the circuit. To that end, we synthesize the backdoor-trigger-free and backdoor-trigger-injected RTL designs using the standard ASIC design flow for the $22nm$ technology using \textit{Synopsys Design Compiler}. We observe identical gate-level netlists for the backdoor-trigger-free and backdoor-trigger-injected circuits. Furthermore, we pass the netlists to a physical-layout flow based on \textit{Synopsys IC Compiler II}.} \blue{Fig.~\ref{fig:layout} displays the layouts of the SYN-SRAM backdoor-trigger-free and the backdoor-trigger-embedded circuits. As it can be observed, the layouts are identical except for minor routing differences. We do not study the footprints of the HTs as the goal of {\poisonedgnn} is not to design new HT designs but to deceive the GNN-based HT detection system to prevent the detection of existing HT designs.}
