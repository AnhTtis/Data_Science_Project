% \vspace{-5pt}
\section{Conclusion}
% \vspace{-5pt}


In this paper, we proposed an MBRL framework named \model{}, which mainly tackles the difficulty of vision-based prediction and control in the presence of complex visual dynamics.
%
Our approach has four novel contributions to world model representation learning and corresponding MBRL algorithms.
%
First, it learns to decouple controllable and noncontrollable latent state transitions via modular network structures and inverse dynamics. 
%
Second, it introduces the min-max variance constraints to prevent ``training collapse'', where a single state transition branch captures all information.
%
Third, it makes long-horizon decisions by rolling out the noncontrollable dynamics into the future and learning their influences on current behavior. 
%
Fourth, it models the sparse dependency of future noncontrollable dynamics on current controllable dynamics to deal with some practical dynamic environments.
%
\model{} achieves competitive results on the CARLA autonomous driving task, where other vehicles can be naturally viewed as noncontrollable components, indicating that with the help of decoupled latent states, the agent can make more forward-looking decisions by previewing possible future states in the action-free network branch.
%
Besides, Our approach was shown to effectively improve the visual control task in a modified DeepMind Control Suite, achieving significant advantages over existing methods in standard, noisy, and transfer learning setups.
%
