\begin{figure}
    \includegraphics[width=1\columnwidth]{figures/tau_parameter_estimation.pdf}
    \caption{Duration parameters $\tau_{\textrm{CNN}}^{\textrm{r/e}}$ estimated by the two-output CNNs
    trained on rectangular (top panel) and exponential signals (bottom panel),
    plotted against the duration $\tau$ of the injected signal. 
    These use the same synthetic test sets as
    in Sec.~\ref{sec:trainsynth_testsynth},
    with windows matching the training in each panel.
    Only signals passing the
    $\rho_{\textrm{CNN}}^{\textrm{r/e}}$ thresholds
    of the two-stage filtering are plotted.
    The color scale (shared between both panels) corresponds to the
    $\rho_{\textrm{inj}}$ of the injected signals.}
    \label{fig:PE}
\end{figure}

So far, we have considered a CNN with only one output: the estimated SNR,
which only allows yes/no detection statements.
In practice, one will also be interested in the parameters of a signal candidate.
Estimates of the frequency-evolution parameters $\lambda$
are naturally obtained from where the detection statistic
peaks in the template bank.
In our preferred setup, the two-stage filtering, final candidates
will additionally have $(t^0,\tau)$ estimates from the algorithm in Ref.~\cite{Prix:2011qv}.

However, CNNs can also estimate multiple parameters directly.
In this section, we present a first exploration of this possibility via training CNNs with multiple outputs.
We keep the same architecture as before
with only the addition of one extra node to the output
layer: we now want to output both $\rho_{\textrm{CNN}}$ and a duration estimate $\tau_{\textrm{CNN}}$ for a potential signal.
One could also
estimate the starting time $t^0$ by adding another output, but since in our setup the
starting time is limited to a small range around  $T_{\textrm{gl}}$, we
ignore it for this first proof of concept.

We here show the results of two newly trained models with the additional $\tau_{\textrm{CNN}}$
output and trained and tested with synthetic data. The duration input labels for
training are normalized to a range between $[0,1]$. 
The output can then be transformed back to the
duration in days. In general, we find that the accuracy of the $\rho_{\textrm{CNN}}$ estimation
remains unaltered, while the quality of $\tau_{\textrm{CNN}}$ estimates depends on which type of windows
we use in training. These are shown for one CNN trained on only rectangular
signals and by one trained on only exponential signals, as functions of
the injected durations from the test set, in
Fig.~\ref{fig:PE}.
To focus on signals that are at least marginally detectable,
we only include those passing the  $\rho_{\textrm{CNN}}^{\textrm{r/e}}$ thresholds
of the two-stage filtering,
in both cases corresponding to \mbox{$p_{\textrm{FA}}^{\textrm{CNN}} = 10^{-3}$}.

For the rectangular-trained CNN, the estimated durations $\tau^{\textrm{r}}_{\textrm{CNN}}$ follow quite well the true durations, 
but with some scatter especially for low-SNR signals.
About 3\% of signals form a set of outliers with durations underestimated
by over 95\%, mostly for shorter injections.
Excluding these outliers, the remaining distribution of relative errors
is well-centered around zero
with a root-mean-square (RMS) of $27\%$. For the exponential-trained CNN,
there is a mild trend towards more under-estimated $\tau^{\textrm{e}}_{\textrm{CNN}}$
values for longer injected signals.
In this case, about 7\% of signals are underestimated by over 95\%,
but after excluding this subset the error distribution is only slightly wider
with a RMS of $29\%$.

We also tested these synthetic-trained CNNs on real data. For rectangular
signals, the duration estimation is overall quite robust, and the plot
equivalent to Fig.~\ref{fig:PE} follows the same shape except for some more cases of
overestimation at high durations. The outlier percentages for real data
estimations slightly increase to 6\% and the RMS error stays close to 27\%. For
exponential signals, there is noticeably more overestimation and the outlier
percentage increases to 11\% and the RMS error to 47\%. 

As an additional investigation, we trained a two-output CNN on signals with \textit{both}
rectangular and exponential windows. Overall it behaves like a mixture of the
results of the two separately trained networks, with the exception
of stronger overestimation at long durations and high SNRs in real data.
Performance could potentially be improved by adding another output acting as a
window label, since the duration parameter $\tau$ actually has different
meanings for the two different windows, as also discussed in
Ref.~\cite{10.1093/mnras/stac3665}. This would be similar to how Ref.~\cite{Prix:2011qv}
has already discussed treating window function choice as an additional parameter
in Bayesian parameter estimation.

This and other possible improvements to the architecture and training of the
two-output network to obtain better accuracy, and any further extensions of this
approach to parameter estimation with CNNs, are left for future work.
