\documentclass[10pt,journal,compsoc]{IEEEtran}
%\linespread{2}
\usepackage{cuted}
\usepackage{stackrel}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{xfrac}
\usepackage{algorithm}
\usepackage{array}
\usepackage{stfloats}
\usepackage{multirow}
\usepackage{color}
\usepackage{tabulary}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{colortbl}
\usepackage{pbox}
\usepackage{booktabs}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{setspace}
\usepackage{bigints}
\usepackage{float}
\usepackage{algorithm}
\usepackage{url}
\usepackage[noend]{algpseudocode}
\usepackage[T1]{fontenc}
%\usepackage[colorinlistoftodos,prependcaption,textsize=normal]{todonotes}
\usepackage{regexpatch}
\usepackage{algorithm}
\usepackage{algcompatible}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{cuted}
\usepackage{comment}
\usepackage{hyperref}
\usepackage{makecell}

\ifCLASSOPTIONcompsoc
  % IEEE Computer Society needs nocompress option
  % requires cite.sty v4.0 or later (November 2003)
  \usepackage[nocompress]{cite}
\else
  % normal IEEE
  \usepackage{cite}
\fi


\DeclareMathOperator{\sign}{sign}

\providecommand{\abs}[1]{\left\lvert#1\right\rvert}
\newcommand\norm[1]{\left\lVert#1\right\rVert}
%\tracingxpatches%for debugging
\makeatletter
%\xpatchcmd{\@todo}{\setkeys{todonotes}{#1}}{\setkeys{todonotes}{inline,#1}}{}{}
\makeatother

\newtheorem{thm}{Theorem}
\newtheorem{asmt}{Assumption}
\newtheorem{prop}{Proposition}
\newtheorem{lem}{Lemma}
\newtheorem{rem}{Remark}
\newtheorem{defn}{Definition}
\newtheorem{col}{Corollary}

\usepackage[normalem]{ulem} 
 
%\usepackage[letterpaper, lefk=1in, righk=1in, bottom=1in, top=0.75in]{geometry}
%\usepackage{kbordermatrix}
%\usepackage[papersize={8.5in,11in}]
%\usepackage[a4paper, total={8.5in,11in}]{geometry}
%\usepackage[paperwidth=8.5in, paperheighk=11in]{geometry}
\providecommand{\abs}[1]{\lvert#1\rvert}
\providecommand{\norm}[1]{\lVert#1\rVert}

\newcommand{\subparagraph}{}
\newcommand{\indep}{\rotatebox[origin=c]{90}{$\models$}}
\setlength{\parskip}{5pt}

\usepackage{xcolor,cancel}
\usepackage{longtable}

\newcommand\hcancel[2][black]{\setbox0=\hbox{$#2$}%
\rlap{\raisebox{.45\ht0}{\textcolor{#1}{\rule{\wd0}{1pt}}}}#2} 
\begin{comment}
\newcommand{\apt}[1]{{#1}}
\newcommand{\og}[1]{{#1}}
\newcommand{\att}[1]{{#1}}
\end{comment}
\newcommand{\apt}[1]{\textcolor{Violet}{#1}}
\newcommand{\og}[1]{\textcolor{RoyalBlue}{#1}}
\newcommand{\att}[1]{\textcolor{red}{#1}}

% correct bad hyphenation here
\hyphenation{}


\begin{document}
\newcounter{MYtempeqncnt}
  \title{Multi-Task Model Personalization for Federated Supervised SVM in Heterogeneous Networks} 
 \author{Aleksei Ponomarenko-Timofeev, Olga Galinina, Ravikumar Balakrishnan, \\
 Nageen Himayat, Sergey Andreev, and Yevgeni Koucheryavy}
	
	

\IEEEtitleabstractindextext{%
\begin{abstract}
	%With the ever-growing volume of produced data, an unprecedented opportunity of enhancing the performance of machine learning methods appears. Yet, privacy concern in handling data and its efficient transfer are two factors that should be addressed properly. 
In this paper, we design an efficient distributed iterative learning method based on support vector machines (SVMs), which tackles federated classification and regression. The proposed method supports efficient computations and model exchange in a network of heterogeneous nodes and allows personalization of the learning model in the presence of non-i.i.d. data. To further enhance privacy, we introduce a random mask procedure that helps avoid data inversion. Finally, we analyze the impact of the proposed privacy mechanisms and the heterogeneity of participant hardware and data on the system performance.
\end{abstract}
% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
	multi-task learning, support vector machine, classification, regression, federated learning.
\end{IEEEkeywords}}
\maketitle 

\IEEEdisplaynontitleabstractindextext
%\att{Nageen: Avoid inversion, no coding, random mask procedure, for unenrypted or only curious server, does not need to be device, free-rider is future direction}

\begin{comment}{
\att{Plan before submission:
\begin{itemize}
    \item I tried to find locations in the intro for the train of thoughts we discussed. Please, check if I found the right spots. Also, I couldn't place the last one (N10 in skype, N8 below under comments), please, paste where the corresponding text begins. 
\end{itemize}
}
\att{    ----------------
\begin{itemize}
    \item Remove third parties, explain TEE
    \item [x] Olga edits ``Security An'' and ``NumRes'' here
    \item Section ``Related work''
    \begin{itemize}
    \item Add TMC paper(s)
    \item Expand ref list to around 50 (average among good TMC papers!), maybe at the revision?
    \end{itemize}
\end{itemize}
}
    \att{    ----------------
\begin{itemize}
    \item
    \item Add multi--task to Fig.1; extend the legend?
    \item [x] Send to Nageen and Ravi (and to Sergey to speed up)
    \item Implement the edits
\end{itemize}
}
\end{comment}

\begin{comment}

1) Из-за распространения устройств у нас появляется доступ к большему объёму данных.

2) Эти данные занимают много места и владельцы данных (пользователи) хотят конфиденциальность

3) Для этого мы используем ФЛ, так-как он уменьшает объём данных для передачи и даёт возможность задействовать механизмы прайваси.

4) Тут как раз мы говорим что без персонализации весь ФЛ может расползтись во все стороны не оправдать ожидания по производительности с точки зрения МЛ метрик.

5) Далее идёт описание краткое ФЛ и как он может работать например в нейронках. И тут говорится почему СВМ может быть лучше.

6) Далее мы говорим про разношёрстное железо, которое может влиять на быстродействие системы обучения.

7) После этого добавляем что СВМ можно неплохо формализовать в терминах теории оптимизации. Что тоже хороший плюс.

8) Исходя из всего вышесказанного мы рассматриваем СВМ и смотрим как он реагирует на гетерогенныме данные и на гетерогенное железо.

\end{comment}

\IEEEraisesectionheading{\section{Introduction}\label{sec:introduction}}
%1) Из-за распространения устройств у нас появляется доступ к большему объёму данных.

\IEEEPARstart{T}{he} proliferation of connected smart devices has led to a surge in the volume of data available for machine learning (ML) in real-world applications. The cost of transmitting large volumes of data and privacy concerns~\cite{liu2021machine}  drive the development of federated learning (FL)~\cite{bonawitz2019towards,kairouz2021advances}, which offers a promising solution for distributed ML training across multiple devices without sharing their underlying data. %In FL, a pool of data-holding participants are learning a model cooperatively while being coordinated by a parameter server and exchange model deltas. %Multiple privacy mechanisms may be applied to the FL to protect participants' information~\cite{hardy2017private, senekane2019differentially, dwork2014algorithmic}.
%\par
%Combined with the introduction of mobile edge computing (MEC) capabilities into modern wireless networks, 
FL opens numerous practical opportunities~\cite{ye2020edgefed}, such as learning models for scheduling tasks in a cellular network~\cite{ma2020scheduling,nishio2019client} or offloading computational tasks~\cite{yang2020computation}. 
%4) Тут как раз мы говорим что без персонализации весь ФЛ может расползтись во все стороны не оправдать ожидания по производительности с точки зрения МЛ метрик.

In distributed scenarios, the devices may be located in different environments and collect statistically diverse data, which results in data heterogeneity. Conventional FL approaches may face challenges in producing a model, equally suitable for all participants. To enable personalization in scenarios with high data heterogeneity, the concept of multi-task learning (MTL)~\cite{caruana1997multitask} leverages the fact that models can be efficiently trained using a shared representation. % and thus optimizes the performance of the model for all participants equally. \att{[smth on federated MTL?]}%This makes MTL attractive for applications where a performance boost for multiple tasks is required simultaneously.
%5) Далее идёт описание краткое ФЛ и как он может работать например в нейронках. 
The MTL paradigm has been widely applied, for example, to deep neural networks (DNN). Two methods for enabling MTL in the DNNs are soft and hard parameter sharing. Hard parameter sharing implies that certain task representation layers are synchronized while output layers are trained by each participant individually. This approach reduces the risk of overfitting, as shown in~\cite{baxter1997bayesian}. Contrary to hard parameter sharing, soft parameter sharing does not enforce the synchronization of layers but makes shared layers correlated. 

Although neural networks (NNs) provide powerful models, they are, in general, computationally expensive. One of their lightweight alternatives that can still achieve high accuracy in many problems while requiring fewer data~\cite{shao2012comparison}  is support vector machines (SVMs). In SVM, 
%Compared to conventional neural networks, SVM has the advantage of being a lightweight method since it essentially utilizes a single layer. 
%TODO\att{To implement MTL for SVMs, soft parameter sharing can be employed [may be brought back if you see a good place to have it]}. 
%The tractability of SVMs allows improving performance of soft parameter sharing in scenarios with non-i.i.d. data. 
the supervised (i.e., classification or regression) problem is formulated as an optimization problem, which produces a hyperplane in a multi-dimensional space of features that characterize the object~\cite{kecman2005support}. The SVM-based methods essentially solve convex minimization problems, which are well-studied and may employ multiple numerical approaches. To efficiently utilize feature extraction, SVM-based solutions may rely on a set of tools available for data preprocessing ~\cite{jebara2004multi, christ2018time}.
%With this in mind, the SVM-based solutions are generally more lightweight, compared to those based on NNs. 
%The required volume of training data for SVM solutions is also smaller, compared to the NNs~\cite{shao2012comparison}.

Traditionally, distributed SVM problems~\cite{smith2017federated} are solved using conventional optimization techniques, such as the stochastic gradient descent (SGD) method, which might not be the most efficient choice in terms of performance in the case where multiple nodes iterate on disjoint sets of data. 
%[remove as this is unclear]The major gap for improvement might appear not due to the architectural deficiency of the method, but rather due to the characteristics of the scenario. 
%[removed because we don't have a system of interest yet] One of the factors that should be considered is that the system of interest is distributed. 
% [removed because it's not clear why we need this information here; obviously, everyone needs to reduce the number of communication rounds] In a distributed system, multiple nodes with disjoint sets of data should reach a consensus regarding the solution to the problem. Transmission of model updates consumes network resources and thus should be optimized to reduce the number of communication rounds. This not only decreases the cumulative communication costs but improves convergence to a stable solution. 
%[removed as repetition] Currently, the state-of-the-art SVM-based methods utilize SGD to solve classification and regression problems~\cite{smith2017federated}. %[removed as there is no clarification on which other methods] while other methods for solving these problems exist as well. 
To accelerate the training procedure and further enhance the performance of distributed SVM-based solutions, we propose an MTL framework, which employs the alternating direction method of multipliers (ADMM) and allows for model personalization.
%\att{In this paper, the approach to learning SVM models utilizing the alternating direction method of multipliers (ADMM) is studied. ADMM is utilized to reduce the number of epochs required for reaching comparable performance.[this does not belong here, move it after the PROBLEM]}
%\att{[И тут говорится почему СВМ может быть лучше.]}
%[SVM not introduced yet]In SVMs, however, there is no notion of layers by default. This might be considered a factor that limits the flexibility of the method, despite the fact that it makes the design of the system less complicated. This also reduces the network stress, since in SVM, technically, a single layer is present, allowing for more lightweight federated operation.
%7) После этого добавляем что СВМ можно неплохо формализовать в терминах теории оптимизации. Что тоже хороший плюс. 
%To properly evaluate the correctness of the method selection for solving the SVM problem, certain factors should be taken into account. 
%In real distributed systems, devices might have diverse computing capabilities as well as non-i.i.d. data [we already discussed that in par 2]. As a result, if the selected method is not robust against any of these factors, the versatility of the method will be limited. 
%It is therefore important to evaluate the sensitivity of the method toward the diversity of both hardware capabilities and data as a composition of factors. 
\begin{comment}
[I don't really know where to put all of this now, but let's come back to it later so that this literature is not lost]
Most of the studies of SVM-based multi--task classification and regression methods focus on the mathematical formulations of the problems~\cite{liang2008connection}~\cite{cai2009svm+} and usually address the distributed operation and heterogeneity of the data separately. Consequently, there is a need to explore the combined effects of hardware and data diversity among the participants on the performance of the system in a distributed setting. 
%[removed because mentioned]One of the important benefits of employing SVM in scenarios where devices have poor computing capabilities is low computational complexity, relative to the NN-based methods.
This reduces the computing delays in the cases of inference and learning, which may have considerable variance~\cite{chunduri2017run}~\cite{schad2010runtime} and affect the performance of the distributed system~\cite{sigrist2015mixed}. With the reduction of the delay variance, the behavior of the system is more predictable in general.
\end{comment}
%Another important motivating factor for studying the SVM-based framework specifically is the tractability of the method. 
% The SVM-based solutions, on one hand, have the downside of not having built-in feature extraction procedures, compared to the NNs. 
%8) Исходя из всего вышесказанного мы рассматриваем СВМ и смотрим как он реагирует на гетерогенныме данные и на гетерогенное железо.
%In addition, we conduct a study of the proposed distributed MTL-SVM framework for classification and regression with soft parameter sharing. We explore its performance in the presence of participants that delay their responses (termed stragglers) and different levels of data heterogeneity. 
%[move the refs on TEE to our security analysis?]...technical countermeasures such as encrypted communication channels and trusted execution environments (TEE)~\cite{ekberg2013trusted,pinto2017iioteed}. 
%[I don't see why it is here; if it should be put back, let's discuss] Free-riders might be countered with disconnect on timeout in the cases, in which they stop contributing to the learning procedure or their contributions to the learning procedure become irrelevant~\cite{zhang2012convex}.
% Decided to explain what is going on in the figure, if reader becomes confused with it, there is an explanation
% Also put it before the contribs, since it should not break the logic: [Why we are doing it] -> [What kind of setting we see for the problem] -> [What is the contribution of the paper in this case] -> [The structure of the paper]
%As a result of the diversity of computing capabilities, some of the participants may not be capable of completing epochs on par with all others. 
%The coordinator node may undertake different strategies to compensate the effects caused by the presence of such participants, which we also explore. 
Particularly, we present a lightweight and robust multi-task algorithm for solving classification and regression problems in distributed systems  %It utilizes a method that is suitable for utilization in distributed systems consisting 
of multiple nodes with personal datasets. We assess the impact of the heterogeneous computing capabilities of the participants.
%In the proposed framework, participants holding the data compute model updates and transmit them to the coordinator for aggregation. Should some participants fail to deliver the update, they will be sent a new global model regardless to enforce the synchronization in the system. 
Our contributions are presented as follows:

\begin{itemize}
    \item We present the mathematical formulation of the proposed MTL method for classification and regression problems. Based on this formulation, we propose an iterative algorithm that allows for model personalization in a system of multiple participants.
    \item We study the effects of the presence of stragglers, which are participants that are unable to complete a single epoch within a coordinator-set time limit due to poor computing capabilities. We assess the impact in the cases, where participants have equal computing capabilities as well as diverse capabilities.
    \item We design a masking mechanism, which provides privacy at the cost of distorting the content of the model update and explore its impact on the convergence of the algorithms.
    \item We compare the proposed algorithm with the state-of-the-art solution, which utilizes a similar approach but solves the primal problem, while our method solves the corresponding dual problem. We evaluate the performance in terms of conventional metrics and run-time of methods in a single-threaded mode.
\end{itemize}

The remainder of this paper is organized as follows. In Section~\ref{sec:rwork}, we overview state-of-the-art SVM-based solutions for distributed MTL. In Section~\ref{sec:pfor}, we present the mathematical formulation of the optimization problems. Sections~\ref{sec:mtc} and~\ref{sec:mtr} contain the derivation of iterative solutions for classification and regression problems, as well as the estimates of the run-time complexity. In Section~\ref{sec:sau}, we address data privacy and describe the proposed masking mechanism. Section~\ref{sec:numres} is dedicated to the simulated scenario description and discusses the observed behavior of the system. Finally, concluding remarks are provided in Section~\ref{sec:concl}.

\section{Related Work}
\label{sec:rwork}
% ПОЧЕМУ ЭТОТ "ВАГОН" МЫСЛЕЙ ТАКОЙ БОЛЬШОЙ: Тут мы описываем что сделано помимо работ на которые мы раньше ссылались. В основном смотрим в сторону СВМ и говорм какие подходы на чём основаны.
To exploit the large volume of information available across multiple devices, numerous distributed learning solutions were developed~\cite{verbraeken2019survey}. If the models of different participants are correlated, the performance of the employed distributed method can be improved by applying MTL. 
For example, the authors of~\cite{al2020prediction} proposed an MTL framework for short-time traffic prediction using data collected from connected vehicles. Another MTL problem tackled by the authors of ~\cite{zhang2020app} is to predict the removal of applications from an online store based on the factors such as downloads and ratings. In this problem, MTL is required due to the fact that all of the applications are different (e.g., games and office suites), and thus gain and lose relevance according to dissimilar patterns. 

The field of distributed MTL has also received considerable attention, as highlighted in~\cite{zhang2021survey}. In particular, SVM, one of the conventional algorithms in the area of classification problems, was extended to accommodate distributed MTL formulations. An SVM-based framework for federated MTL in the presence of heterogeneous data was proposed in~\cite{smith2017federated}. Another approach based on SVM~\cite{10.1145/1014052.1014067} extended the single-task regularization-based method to MTL. For highly dynamic scenarios, where new features are introduced into the problem, the authors of~\cite{7899861} proposed an approach for transferring the knowledge from the model with an old set of features to a model with a new set of features. Further, the second-order cone programming (SOCP) to train multi-task learning support vector machines (MTL-SVMs) in terms of a primal problem was studied in~\cite{NIPS2007_67f7fb87}. 
A solution to decrease the number of solved tasks using SVMs while preserving the multi-task capability of the system was also explored by the authors of~\cite{multikernel}. Another approach to exploiting the interrelations between tasks was demonstrated by the authors of~\cite{marfoq2021federated}, where the distribution of data for each task is assumed to be a mixture of unknown distributions. 

Furthermore, with the growing concern for the privacy of user data in modern society~\cite{kairouz2019advances}, it becomes important to explore if the operational principle can provide privacy guarantees. While the existing works proposed SVM-based approaches to the problem of MTL, only a few focused on the asymptotic difficulty of the devised methods and data privacy analysis. Apart from privacy, the resilience of the framework towards adversaries, such as free-riders, who seek to obtain the model without participating in the training procedure, or curious servers, is a crucial aspect that should be addressed~\cite{lyu2020threats}. To tackle these threats, the authors of works~\cite{lv2021data} proposed strategies for estimating task relevance by calculating the correlation of the model update shared by a particular participant with the current global model. Authors of the study~\cite{huang2020exploratory} proposed a mechanism for scoring participants based on the produced shared model updates and analyzed various attack models. To discourage the devices from acting as free-riders, incentivization mechanisms can be applied~\cite{khan2020federated}. 
\par
%While the aforementioned papers focus on the security of the system, privacy aspects are also actively investigated. 
In the case that no countermeasures are implemented in the system, a curious server may launch a membership inference attack~\cite{shokri2017membership}. Authors of work~\cite{ma2021privacy} devised a countermeasure for attacks such as a membership inference attack~\cite{liu2021machine}. To address the privacy problem, the authors of~\cite{shu2022clustered} proposed a dual-server architecture for the MTL framework. The framework also utilizes secure multi-party computation to enable secure mathematical operations and enforce the security of the data with CrypTen~\cite{knott2021crypten}. Other works explored the application of cryptography mechanisms such as multi-key fully homomorphic encryption (MK-FHE) to the MTL frameworks~\cite{stripelis2021secure}. While encryption allows participants to securely exchange even encrypted raw data, utilization of MK-FHE might be overly complex for devices with poor hardware capabilities. In such cases, differential privacy (DP) mechanisms can be applied~\cite{holohan2018bounded}, not only to SVM but also to DNN-based solutions~\cite{abadi2016deep}. 
%\par
% 
%In this work, we \att{[begin with smth closer to our main contribution?]} aim to analyze the behavior of the proposed framework in presence of stragglers and non-i.i.d. data. We also explore a masking approach for providing data privacy to the participants. 

\begin{figure}[ht!]
	\centering
	\includegraphics[width=0.85\linewidth]{Scenario_cut.pdf}
	\caption{Envisioned distributed multi-task learning system.}
	\label{fig:physense}
\end{figure}
Prior works focused on distributed MTL, data and hardware heterogeneity, and privacy separately. Formulation of an efficient ML method and assessment of its performance under the heterogeneity conditions is a gap that we aim to bridge in this paper.

\section{Problem Formulation}
\label{sec:pfor}
In this section, we address the envisioned distributed multi-task learning scenario and define the corresponding soft-margin classification and regression problems. An example of the considered system is illustrated in Fig.~\ref{fig:physense}. Here, participants $A$ and $B$ with non-i.i.d. data iteratively train a common ML model. The third node, the coordinator, facilitates the training procedure by aggregating the model updates shared by $A$ and $B$ and responding with the result. The nodes may have different hardware, which leads to their diverse computing capabilities. 

Throughout further calculations and analysis, we represent vectors in bold, while scalars are given in regular font.


\subsection{General Scenario}
\label{subsec:gsce}
Our system consists of $T$ participants and one central coordinator (see Fig.~\ref{fig:physense}). Each participant $k$, $k=1,...,T$, holds a set of $n_k$ data samples $\pmb{x}_{ik} \in \mathbb{R}^{d}$, where $d$ is the dimensionality of the feature vector, and corresponding observations $y_{ik}$, $i=1,...,n_k$. The goal of each participant is to learn a decision function that recovers the observation from the provided data sample. In conventional SVM classification, the learned model is a set of parameters that define a \textit{separating hyperplane} for these classes. The \textit{decision function} can be defined as $a\left(\pmb{x}\right) = \pmb{w}^\intercal \pmb{x}$, where $\pmb{x}$ is a data point and $\pmb{w}$ is the separating hyperplane. 

We assume that the data are heterogeneous, i.e., their distribution varies from one participant to another. We define a \textit{task} as a problem of finding a participant-specific hyperplane defined by the properties of the data distribution at this participant. To tailor the learning model, we introduce a task-specific model component $\pmb{v}_k$ so that the decision function transforms to $a_k\left(\pmb{x}\right) = \pmb{w}^\intercal \pmb{x} + \pmb{v}^\intercal_k \pmb{x}$. 

The training process is iterative. When the participant with index $k$ takes part in collaborative learning at epoch $j$, it computes \textit{local} $\pmb{v}_k^{(j)}$ and \textit{global} $\tilde{\pmb{w}}_k^{(j)}$, which is shared with the coordinator. Then, the difference $\Delta \pmb{w}_k^{(j)}$ between the previous model, ${\pmb{w}}_k^{(j-1)}$, and updated $\tilde{\pmb{w}}_k^{(j)}$ is sent to the coordinator, which accumulates the differences from all participants for a fixed period of time $T_{\text{wait}}$. After the waiting period expires, the coordinator calculates global $\pmb{w}^{(j)}$ and returns the update to the participants. The participants run the next epoch of the local learning procedure using updated global $\pmb{w}^{(j)}$ and their individual local $\pmb{v}_{k}^{(j)}$. This process continues until the coordinator reaches the stopping criteria.

%\textcolor{red}{[Find an appropriate place for stopping criteria]} For both classification and regression problems, we introduce a stopping threshold $\chi_{\text{stop}}$. Each device and coordinator are required to reach state when the following conditions~\eqref{eq:condstop} are satisfied. Hereinafter, we utilize the Euclidean norm $\norm{\cdot}_2$.
%%
%\begin{equation}
%	\left\{
%	\begin{array}{l}
%		\frac{\norm{\pmb{w}_k^{(j-1)} - \pmb{w}_k^{(j)}}}{\norm{\pmb{w}_k^{(j-1)}}} \le \chi_{\text{stop}} \\
%		\norm{\pmb{w}_k^{(j)}} \ge \chi_{\text{stop}} \\
%		\frac{C_2 \norm{\pmb{v}_{k}^{(j-1)} - \pmb{v}_{k}^{(j)}} }{\pmb{v}_{k}^{(j)}} \le \chi_{\text{stop}}
%	\end{array}
%	\right.
%	\label{eq:condstop}
%\end{equation}

% These requirements are common for classification and regression as $\chi_{\text{stop}}$. The first requirement controls sensitivity to relative change of $\pmb{w}_k^{(j)}$. If a relative change of the $\pmb{w}_k^{(j)}$ is less than $\chi_{\text{stop}}$, this requirement is satisfied. The second requirement sets a lower limit in the norm of the $\pmb{w}_k^{(j-1)}$, introducing some of the data into the ``global'' model. Third requirement controls sensitivity to the relative change of $\pmb{v}_k^{(j)}$ with regards to the regularization constant $C_1$. If $C_1$ is set to zero, the system is operating in single-task mode and this requirement is always satisfied.
 

Furthermore, we introduce the random computing delay $T_{\text{pcomp},k}^{(j)}$ for participant $k$ at epoch $j$. Parameters of the delay distribution depend on both the number of data points, $n_k$, and the dimensionality, $d$, and their higher values result in a greater mean of the $T_{\text{pcomp},k}^{(j)}$. The coordinator is assumed to have a constant computing delay, $T_{\text{ccomp}}^{(j)}$, since it only computes the sum of the models sent by the participants.
%We assume that compute delays $T_{\text{comp},k}^{(j)}$ follow the Gaussian distribution with the mean and variance depending on the volume of the dataset, which is defined by the number of features $d$ and the number of samples $n_k$.The assumption of Gaussian distribution of the compute delay is based on the fact that in real systems, multiple extraneous processes may preempt participants calculations.
If a participant fails to deliver its update to the coordinator within the waiting period, $T_\text{wait}^{(j)}$, it receives an update of the global hyperplane regardless. If the participant is in the process of calculating the local model while receiving an update from the coordinator, it then interrupts the ongoing calculations, applies the updated global model, and restarts the computation with current $\pmb{v}_k^{(j)}$. This enforces synchronization and prevents the accumulation of outdated updates if the participant struggles to complete the computations. 
%
We assume that the communication channel is sufficiently reliable and communications-related imperfections are out of the scope of this study. We also assume that communication delays are negligible compared to computation delays, thus, the updates are assumed to arrive instantly.
For an example of two participants, the message sequence chart is depicted in Fig.~\ref{fig:MSC}.
\begin{figure*}[t!]
	\centering
	\includegraphics[width=\linewidth]{Flow_diagr.pdf}
	\caption{Message sequence chart of proposed training procedure.}
	\label{fig:MSC}
\end{figure*}
%
In the beginning, the coordinator sends the initial value of the global component, $\pmb{w}^{(0)}$, and other parameters. At epoch $i$, the participants compute their local and global model updates during a random time interval, $T_{comp}^{\left(i\right)}$.
%. Each of the participants needs a random amount of time $T_{comp}^{\left(i\right)}$ on epoch $i$ to complete the calculations. 
Computing delays of different participants are not correlated since the hardware resources are not shared. After completing computations, the participants submit their global model updates $\Delta \pmb{w}^{(i)}_k$ to the coordinator for aggregating. The aggregation phase on the coordinator is more lightweight compared to the model calculation phase on participating participants. The corresponding summation time $T_{sum}$ is constant at each epoch. %\att{However, the summation time $T_{sum}$ has a slight variation on different iterations [do we assume a distribution of these?].} 
After the aggregation, the coordinator distributes the updated $\pmb{w}^{(0)}$ and continues accumulating updates during the time $T_{wait}$. If the participant receives an update from the coordinator, it interrupts the current calculations, applies the received global model, and restarts. If the coordinator receives an update from a participant during the summation operation, it continues the calculations and discards the belated update.

We further proceed to the problem formulation for MTL-SVM classification and regression with the notations provided in Table~\ref{tab:nottab}.

\begin{table}[h!]
	\centering
	\caption{Notation}
	\label{tab:nottab}
	\begin{tabular}{lr}
		\hline
		Notation & \makecell[c]{Description} \\
		\hline
		%\hline
		$\pmb{w}^{(j)}$ & Global model at epoch $j$\\
		%\hline
		$\Delta \pmb{w}^{(j)}$ & Global model update at epoch $j$\\
		%\hline
		$\Delta \pmb{w}^{(j)}_{k}$ & Participant $k$ shared model update at epoch $j$\\
		%\hline
		$\pmb{v}^{(j)}_{k}$ & Local model at participant $k$ at epoch $j$ \\
		%\hline 
		$\pmb{x}_{ik}$ & $i$-th feature vector at participant $k$ \\
		%\hline
		$y_{ik}$ & $i$-th scalar label at participant $k$ \\
		%\hline
		$\xi_{ik}$ & $i$-th scalar slack variable at participant $k$ \\
		%\hline
		$\alpha_{ik}$ & $i$-th scalar Lagrange coefficient at participant $k$ \\
		%\hline
		$C_1$ & Slackness regularization constant \\
		%\hline
		$C_2$ & Task separation regularization constant \\
		%\hline
		$T_{wait}$ & Waiting period (set by coordinator) \\
		%\hline
		$T_{comp,k}^{(j)}$ & Computing delay at participant $k$ at epoch $j$\\
		\hline
	\end{tabular}
\end{table}

\subsection{Problem Formulation: Classification}
\label{subsec:pfc}
\par \textbf{Classification problem:} Given feature vectors $\pmb{x}_{ik} \in \mathbb{R}^{d}$ and labels $y_{ik} \in \{-1,1\}$ for $k = 1,...,T$, $i = 1,...,n_k$, find separating hyperplane components $\pmb{w}$ and $\pmb{v}_k$ for the participant-specific decision rule $a_k(\pmb x_{}) = \sign(\pmb{w}^\intercal \pmb{x}_{} + \pmb{v}_k^\intercal \pmb{x}_{})$. The optimal hyperplane can be found by solving the following \textit{primal} optimization problem:%%, such that $\sign(\pmb{w}^\intercal \pmb{x}_{} + \pmb{v}_k^\intercal \pmb{x}_{}) = y_{ik}$.

%\begin{mini*}|s|
%{\pmb{w}, \pmb{v}_k, \xi_{ik}}{\frac{1}{2}\norm{\pmb{w}}^2 +\frac{C_2}{2} \sum \limits^{T}_{k=1}\norm{\pmb{v}_k}^2}{}{}
%\addConstraint{y_{ik} \cdot \left( \pmb{w}^\intercal \pmb{x}_{ik} + \pmb{v}_k^\intercal \pmb{x}_{ik} \right) \geq 1}{i = 1,\ldots,n_k, k = 1,\ldots,T}
%\end{mini*}

\begin{equation}
	\begin{aligned}
		\min_{\pmb{w},\pmb{v}_k,} \quad & \frac{1}{2}\norm{\pmb{w}}^2 +\frac{C_2}{2} \sum \limits^{T}_{k=1}\norm{\pmb{v}_k}^2 \\
		\textrm{s.t.} \quad & y_{ik} \cdot \left( \pmb{w}^\intercal \pmb{x}_{ik} + \pmb{v}_k^\intercal \pmb{x}_{ik} \right) \geq 1, \\ 
		& i = 1,...,n_k, \quad k = 1,...,T,
	\end{aligned}
	\label{eq:prstrict}
\end{equation}
where $C_2$ is a regularization constant that controls the degree of similarity between the tasks. If $C_2$ is set to an infinitely large value, the solution would result in $\pmb{v}_k=0$, which corresponds to the single-task mode with one separating hyperplane for all participants. 

The two classes may be linearly inseparable, making primal problem~\eqref{eq:prstrict} infeasible. To address that, we utilize a soft margin SVM with the slack variables $\xi_{ik}$ and reformulate the primal task as follows:
\begin{equation}
	\begin{aligned}
		\min_{\pmb{w},\pmb{v}_k,\xi_{ik}} \quad & \frac{1}{2}\norm{\pmb{w}}^2 +\frac{C_2}{2} \sum \limits^{T}_{k=1}\norm{\pmb{v}_k}^2 + C_1  \sum \limits^{T}_{k=1} \sum \limits_{i=1}^{n_k} \xi_{ik}\\
		\textrm{s.t.} \quad & y_{ik} \cdot \left( \pmb{w}^\intercal \pmb{x}_{ik} + \pmb{v}_k^\intercal \pmb{x}_{ik} \right) \geq 1 - \xi_{ik},\\
		 & \xi_{ik} \geq  0, \quad i = 1,...,n_k, \quad k = 1,...,T,
	\end{aligned}
	\label{eq:prmsvm}
\end{equation}
where regularization constant $C_1$ controls the tolerance of the system towards outliers.

\subsection{Problem Formulation: Regression}
\label{subsec:pfr}
\par \textbf{Regression problem:} Given data $\pmb{x}_{ik} \in \mathbb{R}^{d}$ and labels $y_{ik} \in \mathbb{R}$ for $k = 1,...,T$, $i = 1,...,n_k$,
%$\left\{y_i, x_{i1},...,x_{id}\right\}_{i=1}^{n_k}$ of $n_k$ data points, 
recover the (linear) relation between the dependent variable $y_{ik}$ and feature vector $\pmb{x}_{ik}$. For the participant $k$, the relation is defined by hyperplanes $\pmb{w}$ and $\pmb{v}_k$, which leads to \textit{decision function} $a_k(\pmb{x}_{}) = \pmb{w}^\intercal \pmb{x}_{} + \pmb{v}_k^\intercal \pmb{x}_{}$.

\begin{figure}[ht!]
	\centering
	\includegraphics[width=\linewidth]{LF.pdf}
	\caption{Modified loss function $|x|_{\epsilon}$ with $\epsilon=0.1$ tolerance compared to quadratic loss function.}
	\label{fig:lfunc}
\end{figure}

For the regression problem, we also employ the soft-margin formulation. To maintain the tractability of our method, we define the loss function as $Q(x) = \sum\limits_{k=1}^{T} \sum\limits_{i=1}^{n_k}  \abs{ \left(\pmb{w} + \pmb{v}_k\right)^\intercal \pmb{x}_{ik} - y_{ik} }_{\epsilon}$, where $\abs{z}_{\epsilon} = \max\left\{ 0, \abs{z}-\epsilon \right\}$. The selected loss function is illustrated in Fig.~\ref{fig:lfunc}. In this case, the slack variables correspond to the following two cases where the error caused by the noise is either above or below the hyperplane i.e.,
\begin{equation}
	\centering
	\begin{array}{cc}
		\xi_{ik}^+ = \left(a(\pmb{x}_{ik}) - y_{ik} - \epsilon\right), & \xi_{ik}^- = \left(-a(\pmb{x}_{ik}) + y_{ik} - \epsilon\right).
	\end{array}
	\label{eq:hilobound}
\end{equation}
%
%
%
We formulate the primal problem with the slack variables as
%%
\begin{equation}
	\begin{aligned}
		\min_{\pmb{w},\pmb{v}_k ,\xi_{ik}^{+},\xi_{ik}^{-}} \quad & \frac{1}{2} \norm{\pmb{w}}^2 +  \frac{C_2}{2}  \sum \limits_{k=1}^{T}  \norm{\pmb{v}_k}^2 + C_1  \sum \limits_{k=1}^{T} \sum \limits_{i=1}^{n_k} \left(\xi_{ik}^{+}  + \xi_{ik}^{-}  \right)\\
	    \textrm{s.t.} \quad & \!\!\! \pmb{w}^\intercal \pmb{x}_{ik}  \geq  y_{ik}- \epsilon - \xi_{ik}^{-} , i = 1,...,n_k, t = 1, ..., T,\\
		& \!\!\! \pmb{w}^\intercal \pmb{x}_{ik}  \leq  y_{ik} + \epsilon + \xi_{ik}^{+}, i = 1,...,n_k, t = 1, ..., T,\\
		& \!\!\! \xi_{ik}^{-} \geq 0, \xi_{ik}^{+} \geq 0, i = 1,...,n_k, t = 1, ..., T.
	\end{aligned}
	\label{eq:regpr}
\end{equation}
In the following sections, we translate the primal problems for classification and regression into the corresponding dual formulations and solve them.
%\subsection{System-level assumptions}

%\textcolor{red}{Complete network reliability, no networking delays or effects since we are primarily focused on the computational delays. Furthermore, network delays are negligible, compared to the compute delays.}

\section{Multi-task Classification}
\label{sec:mtc}
In this section, we formulate the dual problem for~\eqref{eq:prmsvm} and derive an iterative solution for participants in the multi-task setting.
\subsection{Dual Problem for Classification}
\label{subsec:dpc}
\par Let us convert the primal problem~\eqref{eq:prmsvm} into the dual problem using the Lagrangian $L(\pmb{w}, \pmb{v}_k, \pmb \xi)$ function
%%
\begin{equation}
	\begin{array}{l}
		L(\pmb{w}, \pmb{v}_k, \pmb \xi) = \\ \frac{1}{2}\norm{\pmb{w}}^2
		+  \frac{C_2}{2} \sum \limits^{T}_{k=1}\norm{\pmb{v}_k}^2 + C_1  \sum \limits^{T}_{k=1} \sum \limits_{i=1}^{n_k} \xi_{ik}
		\!-\! \!\sum \limits_{k=1}^{T} \! \sum \limits_{i=1}^{n_k}  \eta_{ik} \xi_{ik} \\
		\!-\! \sum \limits_{k=1}^{T} \! \sum \limits_{i=1}^{n_k}   \alpha_{ik} \! \left[y_{ik}  \!\left( \pmb{w}^\intercal \pmb{x}_{ik} \!+\! \pmb{v}_k^\intercal \pmb{x}_{ik} \right) \!-\!1\! + \!\xi_{ik} \right]\!.
	\end{array}
	\label{eq:lagrmsvm}
\end{equation}
Here, $\alpha_{ik}$ and $\eta_{ik}$ are Lagrangian coefficients, %, and   is a \att{classification margin coefficient for sample point $i$ and task $k$[where does this definition come from? technically, it is also Lagr.c.]}, %Dual variables $\alpha_{ik}$ and $\eta_{ik}$ 
which correspond to constraints $y_{ik} \cdot \left(\pmb{w}^\intercal \pmb{x}_{ik} + \pmb{v}_k^\intercal \pmb{x}_{ik}\right) \geq 1- \xi_{ik}$ and $\xi_{ik} \geq 0$, accordingly.
%%
We reduce the number of variables in the Lagrangian by using the requirements for a saddle point existence. For a saddle point to exist, the following should hold: $\frac{\partial L}{\partial \pmb{w}} = 0$, $\frac{\partial L}{\partial \pmb{v}_k}  = 0$, and $\frac{\partial L}{\partial \xi_{ik}}  = 0$. Using these conditions, we may then express $\pmb{w}$, $\pmb{v}_k$, and $C_1$ as follows:
%%
\begin{equation}
	\left\{ \!\!
	\begin{array}{l}
		 \frac{\partial L}{\partial \pmb{w}} = \pmb{w}  -\sum \limits_{k=1}^{T} \sum \limits_{i=1}^{n_k}  \alpha_{ik} y_{ik} \pmb{x}_{ik}, \\
		 \frac{\partial L}{\partial \pmb{v}_k} = C_2 \pmb{v}_k
		\!-\! \sum \limits_{i=1}^{n_k} \alpha_{ik} y_{ik}  \pmb x_{ik}, \\
		 \frac{\partial L}{\partial \xi_{ik}} = C_1  -  \eta_{ik} -\alpha_{ik},
	\end{array}
	\right. \!\!
	\Rightarrow
	\left\{  \!\!
	\begin{array}{l}
		\pmb{w} = \sum \limits_{k=1}^{T}\sum \limits_{i=1}^{n_k}  \alpha_{ik} y_{ik} \pmb{x}_{ik}, \\
		\pmb{v}_k=\frac{1}{C_2}\sum \limits_{i=1}^{n_k} \alpha_{ik} y_{ik}  \pmb{x}_{ik},  \\
		C_1  =  \eta_{ik} +\alpha_{ik}.
	\end{array}
	\right.
	\label{eq:derres}
\end{equation}

We substitute variables~\eqref{eq:derres} into the Lagrangian~\eqref{eq:lagrmsvm}. The arguments of $L(\pmb{w}, \pmb{v}_k, \xi)$ are reduced to variables $\alpha_{ik}$; $\pmb{x}_{ik}$ and $y_{ik}$ are fixed terms. For convenience, we solve the minimization problem $\min_{\alpha_{ik}}{\left(-L\left(\pmb\alpha\right)\right)}$, where $-L(\pmb\alpha)$ is defined as
\begin{equation}
	\begin{array}{l}
    \!\!-L(\pmb \alpha)\! = \\ \!\frac{1}{2}\norm{\sum \limits_{k=1}^{T}\!\sum \limits_{i=1}^{n_k} \! \alpha_{ik} y_{ik} \pmb{x}_{ik}}^2 
	\!\!\!+\!  \frac{1}{2C_2}\! \sum \limits^{T}_{k=1} \! \norm{\sum\limits_{i=1}^{n_k} \!  \alpha_{ik} y_{ik} \pmb{x}_{ik}}^2 
	\!\!\!-\!\! \sum \limits_{k=1}^{T} \!\sum \limits_{i=1}^{n_k} \!  \alpha_{ik}.
%
%	\!	-L(\pmb \alpha) = \frac{1}{2}\norm{\sum \limits_{k=1}^{T}\sum \limits_{i=1}^{n_k}  \alpha_{ik} y_{ik} \pmb{x}_{ik}}^2 
%	+  \frac{1}{2C_2} \sum \limits^{T}_{k=1}\norm{\sum\limits_{i=1}^{n_k}  \alpha_{ik} y_{ik} \pmb{x}_{ik}}^2 - \sum \limits_{k=1}^{T} \sum \limits_{i=1}^{n_k}   \alpha_{ik}.
	\end{array}
	\label{eq:dualproblag}
\end{equation}
Hence, we arrive at the following dual optimization problem:
\begin{equation}
	\begin{array}{rl}
    \underset{\alpha_{ik}}{\min} \quad & \!\frac{1}{2}\norm{\sum \limits_{k=1}^{T}\!\sum \limits_{i=1}^{n_k} \! \alpha_{ik} y_{ik} \pmb{x}_{ik}}^2 \\
    & + \frac{1}{2C_2}\! \sum \limits^{T}_{k=1} \! \norm{\sum\limits_{i=1}^{n_k} \!  \alpha_{ik} y_{ik} \pmb{x}_{ik}}^2 
	\!\!\!-\!\! \sum \limits_{k=1}^{T} \!\sum \limits_{i=1}^{n_k} \!  \alpha_{ik} \\
	  \textrm{s.t.} \quad & 0\leq  \alpha_{ik} \leq  C_1, i = 1,...,n	. 
%
%	\!	-L(\pmb \alpha) = \frac{1}{2}\norm{\sum \limits_{k=1}^{T}\sum \limits_{i=1}^{n_k}  \alpha_{ik} y_{ik} \pmb{x}_{ik}}^2 
%	+  \frac{1}{2C_2} \sum \limits^{T}_{k=1}\norm{\sum\limits_{i=1}^{n_k}  \alpha_{ik} y_{ik} \pmb{x}_{ik}}^2 - \sum \limits_{k=1}^{T} \sum \limits_{i=1}^{n_k}   \alpha_{ik}.
	\end{array}
%	\begin{aligned}
%	\min_{\alpha_{ik}} \quad & \frac{1}{2}\norm{\sum \limits_{k=1}^{T}\sum \limits_{i=1}^{n_k}  \alpha_{ik} y_{ik} \pmb{x}_{ik}}^2 
%	+  \frac{1}{2C_2} \sum \limits^{T}_{k=1}\norm{\sum\limits_{i=1}^{n_k}  \alpha_{ik} y_{ik} \pmb{x}_{ik}}^2 \\ 
%	\quad & - \sum \limits_{k=1}^{T} \sum \limits_{i=1}^{n_k}   \alpha_{ik}\\
%	\textrm{s.t.} \quad & 0\leq  \alpha_{ik} \leq  C_1, i = 1,...,n	.
%	\end{aligned}
	\label{eq:dualprob}
\end{equation}

We aim to solve problem~\eqref{eq:dualprob} by using ADMM~\cite{boyd2011distributed} and minimize $-L(\pmb \alpha)$ over each $\alpha_{ik}$ individually. We define an impact $z_{ik}(\alpha_{ik})$ of each $\alpha_{ik}$ on the value of the objective function as given below:
%%
\begin{equation}
	\begin{array}{l}
	   z_{ik}(\alpha_{ik}) = \\
    \alpha_{ik} y_{ik} \pmb{x}_{ik}^\intercal \left( \sum \limits_{k_2=1}^{T}\sum \limits_{i_2=1}^{n_k} \alpha_{i_2k_2} y_{i_2k_2} {\pmb{x}_{i_2k_2}} - \alpha_{ik} y_{ik} \pmb{x}_{ik} \right) \\
+ \frac{1}{2} \alpha_{ik}^2 y_{ik}^2  \norm{\pmb{x}_{ik}}^2 
+  \frac{1}{C_2}  \alpha_{ik} y_{ik} \pmb{x}_{ik}^\intercal \sum\limits_{i_2=1, i_2 \neq i}^{n_k} \alpha_{i_2k} y_{i_2k} {\pmb{x}_{i_2k}} \\
+ \frac{1}{2C_2} \alpha_{ik}^2 y_{ik}^2 \norm{\pmb{x}_{ik}}^2 -  \alpha_{ik} .
	\end{array}
	\label{eq:zin}
\end{equation}
%%
Our goal is to minimize each $z_{ik}(\alpha_{ik})$ sequentially. At each participant $k$, the index $i$ is selected randomly. % and can be defined as a random permutation of vector $\left(1,...,n_k\right)$. 
Importantly, $z_{ik}(\alpha_{ik})$ is a quadratic function, and, therefore, by using condition $\frac{\partial z_{ik}(\alpha_{ik})}{\partial \alpha_{ik}} = 0$, we can obtain $\hat{\alpha}_{ik}$, at which the impact is at maximum. The condition on the derivative leads to the equation
%%
\begin{equation}
	\begin{array}{l}
-1 + y_{ik} \pmb{x}_{ik}^\intercal \left( \sum \limits_{k_2=1}^{T}\sum \limits_{i_2=1}^{n_k} \alpha_{i_2k_2} y_{i_2k_2} {\pmb{x}_{i_2k_2}} - \alpha_{ik} y_{ik} \pmb{x}_{ik} \right) \\
+ \alpha_{ik} y_{ik}^2  \norm{\pmb{x}_{ik}}^2
+  \frac{1}{C_2}   y_{ik} {\pmb{x}_{ik}^\intercal} \sum\limits_{i_2=1, i_2 \neq i}^{n_k} \alpha_{i_2k} y_{i_2k} {\pmb{x}_{i_2k}} \\
+ \frac{1}{C_2} \alpha_{ik} y_{ik}^2 \norm{\pmb{x}_{ik}}^2 = 0.
	\end{array}
	\label{eq:alpha_eq}
\end{equation}
%%
%However, we may also notice certain substitutions that can be made in this equation, such as in~\eqref{eq:subs_dzia}. These will aid us to then express calculation step for computing $\alpha_{ik}$.
To compute the new value of $\alpha_{ik}$, we apply expressions for $\pmb{w}$ and $\pmb{v}_{k}$ in~\eqref{eq:derres}. At the start of each epoch, participants utilize current values of $\pmb{w}$ and $\pmb{v}_{k}$, which contain previously computed $\alpha_{ik}$ denoted as $\alpha_{ik}^{\text{(prev)}}$. Thus, we may use $\pmb{w}$ and $\pmb{v}_{k}$ as a link between two consecutive iterations and express parts of~\eqref{eq:alpha_eq} as provided below:
%%
\begin{equation}
	\!\left\{ \!\!\!
	\begin{array}{l}
		\sum \limits_{k_2=1}^{T}\sum \limits_{i_2=1}^{n_k} \alpha_{i_2k_2} y_{i_2k_2} {\pmb{x}_{i_2k_2}} - \alpha_{ik} y_{ik} \pmb{x}_{ik}  = \pmb w -  \alpha_{ik}^{(\text{prev})}  y_{ik}  \pmb{x}_{ik},\!\! \\
    \frac{1}{C_2}  \sum\limits_{\substack{i_2=1 \\ i_2 \neq i}}^{n_k} \alpha_{i_2k} y_{i_2k} {\pmb{x}_{i_2k}} = \pmb{v}_k -  \frac{1}{C_2}\alpha_{ik}^{(\text{prev})} y_{ik} {\pmb{x}_{ik}}.
	\end{array}
	\right.
	\label{eq:subs_dzia}
\end{equation}
Using~\eqref{eq:subs_dzia}, we can continue to the derivation of the \textit{distributed} iterative solution of the dual problem.

\subsection{Distributed Solution for Classification Problem}
\label{subsec:dscp}
After substituting~\eqref{eq:subs_dzia} in~\eqref{eq:alpha_eq}, we obtain the expression for $\alpha_{ik}^{\text{(prev)}}$ and $\alpha_{ik}$:
\begin{equation}
	\begin{array}{l}
		1 = y_{ik} \pmb{x}_{ik}^\intercal \left( \pmb{w} -  \alpha_{ik}^{(\text{prev})}  y_{ik}  \pmb{x}_{ik} \right) + \alpha_{ik} y_{ik}^2  \norm{\pmb{x}_{ik}}^2 \\
		+    y_{ik} {\pmb{x}_{ik}^\intercal} \left( \pmb{v}_k - \frac{1}{C_2}\alpha_{ik}^{(\text{prev})} y_{ik} {\pmb{x}_{ik}} \right) 
		+ \frac{1}{C_2} \alpha_{ik} y_{ik}^2 \norm{\pmb{x}_{ik}}^2.
	\end{array}
	\label{eq:subs_der}
\end{equation}
In~\eqref{eq:subs_der}, $\alpha_{ik}$ is an unknown variable which we express as
\begin{equation}
	\alpha_{ik} = \frac{1- y_{ik} \pmb{x}_{ik}^\intercal \pmb{w} - y_{ik} \pmb{x}_{ik}^\intercal \pmb{v}_k}{\norm{\pmb{x}_{ik}}^2 \left(1+\frac{1}{C_2}\right)} + \alpha_{ik}^{\text{(prev)}}.
	\label{eq:ait_iters}
\end{equation}
To calculate updated $\pmb{w}$ and $\pmb{v}_k$ at epoch $j$, we can apply expressions in~\eqref{eq:derres}, which yields
\begin{equation}
	\left\{
	\begin{array}{l}
		\pmb{w}_{ik}^{(j+1)}  = \pmb{w}_{ik}^{(j)} + \left(\alpha_{ik}^{(j+1)} - \alpha_{ik}^{(j)} \right) y_{ik} \pmb{x}_{ik}  ,\\
		\pmb{v}_k^{(j+1)} = \pmb{v}_k^{(j)} + \frac{1}{C_2}\left(\alpha_{ik}^{(j+1)} - \alpha_{ik}^{(j)} \right) y_{ik} \pmb{x}_{ik},
	\end{array}
	\right.
  \label{eq:cls_w_v}
\end{equation}
where $\alpha_{ik}^{(j+1)} - \alpha_{ik}^{(j)} =  \frac{1- y_{ik} \pmb{x}_{ik}^\intercal \pmb{w} - y_{ik} \pmb{x}_{ik}^\intercal \pmb{v}_k}{\norm{\pmb{x}_{ik}}^2 \left(1+\frac{1}{C_2}\right)}$ as follows from \eqref{eq:ait_iters}. As seen from the above expressions, the tasks are decoupled from each other and participants can participate in collaborative training by only sharing $\Delta \pmb w_{ik} = \pmb{w}_{ik}^{(j+1)} - \pmb{w}_{ik}^{(j)}$ at each epoch.

\subsection{Computational Complexity of Classification}
\label{subsec:ccc}
\par Furthermore, we analyze the complexity of the straightforward implementation of our MTL-SVM classification algorithm. In this analysis, we assume that no low-level optimization steps are taken. We denote the volume of the training set as $L$, i.e., $L = n_k$ for the federated multi-task methods and $L = \sum \limits_{k=1}^{T} n_k$ in the case if all data are available at the central server. Employing the notation from~Table~\ref{tab:conota}, we arrive at the following costs $C_{\text{z}}$ of computing variable $z$:
%\og{We} define the \og{employed notation in Table~\ref{tab:conota}.}
%We further denote the volume of the training set as $L$, dimensionality of a single sample as $d$, and cost of certain value as $C_{\text{value}}$. We arrive at the following computational costs for the model:
\begin{equation}
	\left\{
		\begin{array}{l}
			C_{\pmb \alpha} = L\left(3C_\text{mul}^{d} + 2C_\text{add}^{d} + C_\text{div}^{3} + C_\text{add}^{1}\right),\\
			C_{\pmb{w}} = L\left(C_\text{mul}^{d} + C_\text{add}^{d} + C_\text{sub}^{1} + C_\text{mul}^{1}\right),\\
			C_{\pmb{v}} = L\left(C_\text{mul}^{d} + C_\text{add}^{d} + C_\text{mul}^{2} + C_\text{sub}^{1} + C_\text{div}^{1}\right),\\
			C_{\text{end}} = C_\text{sub}^{4} + C_\text{mul}^{3} + C_\text{div}^{1} + C_{\text{sqrt}}^{1}.
		\end{array}
	\right. 
\end{equation}
Here, $d$ is the dimensionality of the data. We may observe that if the computational costs of different operations are assumed to be the same, the total cost can be approximated as $C_{\text{total}}(L,d) = Ld + d + L + c$, where $c$ corresponds to the delays introduced by the code execution.

%\par However, we may also formulate the complexity of our algorithm as:
%
%\begin{equation}
%	\left\{
%		\begin{array}{l}
%			C_{\text{total}}(L,D) \in O(LD) \\
%			C_{\text{total}}(L,D) \in \Omega(LD) \\
%			C_{\text{total}}(L,D) \in \Theta(LD)
%		\end{array}
%	\right.,
%\end{equation}
%
%since for all $L\geq1$ and $D\geq1$, $C_{\text{total}}(L,D) = LD + D + L + c \leq LD + LD + LD + c = 3LD + c$

\begin{table}[ht]
	\centering
	\caption{Notation for Complexity Analysis}
	\begin{tabular}{lr}
		\hline
		Notation & \makecell[c]{Description} \\
		\hline
		%\hline
		$C_\text{add}^{d}$ & Computational cost of $d$ additions \\
		%\hline
		$C_\text{sub}^{d}$ & Computational cost of $d$ subtractions \\
		%\hline
		$C_\text{mul}^{d}$ & Computational cost of $d$ multiplications \\
		%\hline
		$C_\text{div}^{d}$ & Computational cost of $d$ divisions \\
		%\hline
		$C_{\text{sqrt}}^{d}$ & Computational cost of $d$ square roots \\
		\hline
	\end{tabular}
	\label{tab:conota}
\end{table}

\section{Multi-task Regression}
\label{sec:mtr}
\par In this section, we formulate the dual problem for~\eqref{eq:regpr} and derive an iterative solution for individual participants in the multi-task setting.

\subsection{Dual Problem for Regression}
\label{subsec:dpr}
Using the objective function and constraints in~\eqref{eq:regpr}, we formulate the Lagrangian as
\begin{equation}
	\begin{array}{l}
		{L} (\pmb{w}, \pmb \xi^{+},  \pmb \xi^{-})
		= \frac{1}{2}\norm{\pmb{w}}^2  + \frac{C_2}{2}  \sum \limits_{i=1}^{T}\norm{\pmb{v}_k}^2
		 
		\\
		- \sum \limits_{i=1}^{T}\sum \limits^{n_k}_{i=1}\alpha_{ik}^{-} \left[ \pmb{w}^\intercal \pmb{x}_{ik} + \pmb{v}_k^\intercal \pmb{x}_{ik} -y_{ik}+\epsilon+\xi^{-}_{ik} \right]
		\\
		- \sum \limits_{i=1}^{T}\sum \limits^{n_k}_{i=1}\alpha_{ik}^{+} \left[ -\pmb{w}^\intercal \pmb{x}_{ik} - \pmb{v}_k^\intercal \pmb{x}_{ik}+y_{ik}+\epsilon+\xi^{+}_{ik} \right] 
		\\
		-\sum \limits_{i=1}^{T}\sum \limits^{n_k}_{i=1} \left(\eta^{-}_{ik}\xi^{-}_{ik} + \eta^{+}_{ik} \xi^{+}_{ik} \right) + 
		C_1\sum \limits_{i=1}^{T}  \sum \limits_{i=1}^{n_k} \left(\xi_{ik}^{+}  + \xi_{ik}^{-}  \right) 
	\end{array}
	\label{eq:reglag}
\end{equation}
%We reduce the number of arguments of the Lagrange function~\eqref{eq:reglag} by employing the saddle point existence conditions. To achieve this, we take 
and calculate its partial derivatives as follows:
\begin{equation}
	\left\{
	\begin{array}{l}
		\frac{\partial L}{\partial \pmb{w}} = \pmb{w} +\sum \limits_{k=1}^{T} \sum \limits_{i=1}^{n_k} \alpha_{ik}^{+}  \pmb{x}_{ik} -\sum \limits_{k=1}^{T} \sum \limits_{i=1}^{n_k} \alpha_{ik}^{-}  \pmb{x}_{ik}, \\
		\frac{\partial L}{\partial \pmb{v}_k} = C_2 \pmb{v}_k \! +\! \sum \limits_{i=1}^{n_k}  \alpha_{ik}^{+}  \pmb{x}_{ik} \!-\! \sum \limits_{i=1}^{n_k}  \alpha_{ik}^{-}  \pmb{x}_{ik}, \\
		\frac{\partial L}{\partial \xi_i} = C_1  -  \eta_{ik}^{+} -\alpha_{ik}^{+}.
	\end{array}
	\right.	
	\label{eq:regpd}
\end{equation}
As in the case of the classification problem, we can express $\pmb{w}$, $\pmb{v}_{k}$ and $C_2$ as
\begin{equation}
	\left\{
	\begin{array}{l}
		\pmb{w} =\sum\limits_{k=1}^{T} \sum \limits_{i=1}^{n_k} \left( \alpha_{ik}^{-} - \alpha_{ik}^{+}   \right) \pmb{x}_{ik}, \\
		\pmb{v}_k=\frac{1}{C_2}\sum \limits_{i=1}^{n_k}\left(   \alpha_{ik}^{-} -\alpha_{ik}^{+}  \right)  \pmb{x}_{ik}, \\
		C_2  =  \eta_{ik}^{+} +\alpha_{ik}^{+}, \\
		 C_1 = \eta_{ik}^{-} + \alpha_{ik}^{-}.
	\end{array}
	\right.	
	\label{eq:regexpr}
\end{equation}
We reformulate~\eqref{eq:reglag} by substituting expressions~\eqref{eq:regexpr} for $\pmb{w}$, $\pmb{v}_k$, and $C_2$. For convenience we minimize $-L(\alpha)$ given as
\begin{equation}
		\begin{array}{l}
		-L(\alpha) = \frac{1}{2} \left|\left|\sum\limits_{k=1}^{T}\sum \limits_{i=1}^{n_k}\! \left( \alpha_{ik}^{-} -  \alpha_{ik} ^{+}\right) \pmb{x}_{ik} \right|\right|^2 
		\\
		+ \frac{1}{2C_2} \sum \limits^{T}_{k=1}\left|\left|\sum\limits_{i=1}^{n_k} \left( \alpha_{ik}^{-} -\alpha_{ik}^{+} \right)  \pmb{x}_{ik} \right|\right|^2
		\\
		\!-\!  \sum \limits_{k=1}^{T} \sum \limits_{i=1}^{n_k}\left(  \alpha_{ik}^{-} \!-\!  \alpha_{ik}^{+} \right) y_{ik} 
		+ 
		\epsilon \sum \limits_{k=1}^{T} \sum \limits_{i=1}^{n_k} \left(  \alpha_{ik}^{-} + \alpha_{ik}^{+} \right).
		\end{array}
	\label{eq:lagsubs}
\end{equation}
Furthermore, we rewrite~\eqref{eq:lagsubs} as follows:
\begin{equation}
	\begin{array}{l}
		\!\!\! -L(\alpha) = \frac{1}{2} \sum \limits_{\substack{k_1=1 \\ k_2=1}}^{T} \sum \limits_{\substack{i=1 \\ j=1}}^{n_k} \left(  \alpha_{ik_1}^{-} - \alpha_{ik_1}^{+} \right) \left(  \alpha_{jk_2}^{-} - \alpha_{jk_2}^{+} \right) \pmb{x}_{ik_1}^T   \pmb{x}_{jk_2}
		\\
		+ \frac{1}{2C_2} \sum \limits^{T}_{k=1} \sum\limits_{i,j=1}^{n_k} \left( \alpha_{ik}^{-} -\alpha_{ik}^{+} \right)  \left( \alpha_{jk}^{-} -\alpha_{jk}^{+} \right)  \pmb{x}_{ik}^\intercal \pmb{x}_{jk} 
		\\
		\!-\!  \sum \limits_{k=1}^{T} \sum \limits_{i=1}^{n_k}\left(  \alpha_{ik}^{-} \!-\!  \alpha_{ik}^{+} \right) y_{ik} 
		+ 
		\epsilon \sum \limits_{k=1}^{T} \sum \limits_{i=1}^{n_k} \left(  \alpha_{ik}^{-} + \alpha_{ik}^{+} \right).
	\end{array}
	\label{eq:neglag}
\end{equation}
%%
%To minimize~\eqref{eq:neglag}, we then 
Therefore, we may define the dual optimization problem with respect to variables $\left(\alpha_{ik}^{+},\alpha_{ik}^{-}\right)$ as shown below:
%%
\begin{equation}
	\begin{aligned}
		\min_{\alpha_{ik}^{+}, \alpha_{ik}^{-}} \quad & \frac{1}{2} \sum \limits_{\substack{k_1=1 \\ k_2=1}}^{T} \sum \limits_{\substack{i=1 \\ j=1}}^{n_k} \left(  \alpha_{ik_1}^{-} - \alpha_{ik_1}^{+} \right) \left(  \alpha_{jk_2}^{-} - \alpha_{jk_2}^{+} \right) \pmb{x}_{ik_1}^T   \pmb{x}_{jk_2}	\\
		\quad & + \frac{1}{2C_2} \sum \limits^{T}_{k=1} \sum\limits_{i,j=1}^{n_k} \left( \alpha_{ik}^{-} -\alpha_{ik}^{+} \right)  \left( \alpha_{jk}^{-} -\alpha_{jk}^{+} \right) \pmb{x}_{ik}^\intercal \pmb{x}_{jk} 
		\\
		\quad & \!-\!  \sum \limits_{k=1}^{T} \sum \limits_{i=1}^{n_k}\left(  \alpha_{ik}^{-} \!-\! \alpha_{ik} ^{+} \right) y_{ik} 
		+ 
		\epsilon \sum \limits_{k=1}^{T} \sum \limits_{i=1}^{n_k} \left(  \alpha_{ik}^{-} + \alpha_{ik}^{+} \right) \\
		\textrm{s.t.} \quad & 0 \leq  \alpha_{ik}^{+} \leq  C_1, k=1,...,T, i = 1,...,n_k,\\
		\quad &0 \leq  \alpha_{ik}^{-} \leq  C_1, k=1,...,T, i = 1,...,n_k.
	\end{aligned}
	\label{eq:regdp}
\end{equation}
%%
We then employ the ADMM and minimize the objective function in~\eqref{eq:regdp} sequentially for selected $i,k$. For convenience, we express $\pmb{w}$ and $\pmb{v}_k$ via the difference $\Delta \alpha_{ik} = \alpha_{ik}^{-}-\alpha_{ik}^{+}$ as%, $\pmb{w}$ and $\pmb{v}_k$ are defined below:
%%
\begin{equation}
	\left\{
	\begin{array}{l}
		\Delta  \alpha_{ik}  = \alpha_{ik}^{-}-\alpha_{ik}^{+},\\
		\pmb{w} =\sum\limits_{k=1}^{T} \sum \limits_{i=1}^{n_k} \Delta \alpha_{ik} \pmb{x}_{ik}, \\
		\pmb{v}_k =\frac{1}{C_2} \sum \limits_{i=1}^{n_k} \Delta  \alpha_{ik} \pmb{x}_{ik}.\\
	\end{array}
	\right.
	\label{eq:dalpha_reg}
\end{equation}
The impact of pair $\left(\alpha_{ik}^{+},\alpha_{ik}^{-}\right)$ can be calculated as
%\vspace{-0.3cm}
\begin{equation}
  \begin{array}{l}
	 \!\!\!z_i(\alpha_{ik}^{-},\alpha_{ik}^{+}) = \\ \!
	\frac{1}{2}  \Delta  \alpha_{ik}^2 ||\pmb{x}_{ik}||^2 
	%\\+\frac{1}{2} \cdot2\cdot
	\! + \! \Delta  \alpha_{ik} \pmb{x}_{ik}^\intercal \! \! \sum \limits_{\substack{k_1=1 \\
	k_1 \neq k}}^{T}\!  \left(\! \sum \limits_{\substack{j=1 \\ j \neq i}}^{n_k} \! \Delta \alpha_{jk_1} \pmb{x}_{jk_1} \!\! \right) 
	\!\!\!\\ 
	%+ \frac{1}{2C_2}\cdot 2
	+\frac{1}{C_2}\cdot \Delta \alpha_{ik} \pmb{x}_{ik}^\intercal \left( \sum\limits_{\substack{j=1 \\ i\neq j}}^{n_k}  \Delta \alpha_{jk} \pmb{x}_{jk}  \right) + \frac{1}{2C_2} \Delta \alpha_{ik} ^2 ||\pmb{x}_{ik}||^2 
	\\
    - \Delta \alpha_{ik} y_{ik}  + \epsilon \left(\Delta  \alpha_{ik} + 2\alpha_{ik} ^{+} \right),
  \end{array}
  \label{eq:regdivco}
\end{equation}
where $ \Delta \alpha_{ik} = \alpha_{ik}^{-}-\alpha_{ik}^{+}$. 
%%
We define the minimization problem for the quadratic function $z_i$ 
%( \Delta \alpha_{ik} )$} 
as follows:
%%
\vspace{-0.1cm}
\begin{equation}
	  \begin{aligned}
		%\min_{\alpha_{ik}^{+},\alpha_{ik}^{-}}  & z_i(\alpha_{ik}^{-},\alpha_{ik}^{+}) \!=\!
		\min_{\Delta \alpha_{\! ik}^{ },\alpha_{\! ik}^{+}} \quad & \frac{1}{2}  \Delta  \alpha_{ik}^2 \! \norm{\pmb{x}_{ik}}^2 
		 %\\+\frac{1}{2} \cdot2\cdot 
		 \!+\! \Delta  \alpha_{ik}^{ } \pmb{x}_{ik}^\intercal \!\!\!\! \sum \limits_{\substack{k_1=1 \\ k_1 \neq k}}^{T} \!\!\left( 
		\! \sum \limits_{\substack{j=1 \\ j \neq i}}^{n_k} \!\! \Delta \alpha_{jk_1} \pmb{x}_{jk_1} 
		\right)	\\
		& +\frac{1}{C_2} \Delta \alpha_{ik}^{ } \pmb{x}_{ik}^\intercal \left( \sum\limits_{\substack{j=1 \\ i\neq j}}^{n_k}  \Delta \alpha_{jk} \pmb{x}_{jk}  \right) 
		\!\! + \frac{1}{2C_2} \Delta \alpha_{ik}^2 \norm{\pmb{x}_{ik}}^2 \\
        &- \Delta \alpha_{ik} y_{ik}  + \epsilon \left(\Delta  \alpha_{ik}^{ } + 2\alpha_{ik}^{+} \right) \\
        \textrm{s.t.} \quad & 0 \leq  \alpha_{ik}^{+} \leq  C_1, k=1,...,T, i = 1,...,n_k,\\
		\quad &0 \leq  \alpha_{ik}^{-} \leq  C_1, k=1,...,T, i = 1,...,n_k.
	\end{aligned}
	\label{eq:indmin}
\end{equation}
%%
We rely on the convexity of the quadratic function $z_i(\alpha_{ik}^{-}, \alpha_{ik}^{+})$ and %find the minimum by finding such $(\alpha_{ik}^-, \alpha_{ik}^+)$ that 
the condition $\frac{\partial z_{ik} \left( \Delta \alpha_{ik} \right)} {\partial \left( \Delta \alpha_{ik} \right)} = 0$.
%%
\vspace{-0.3cm}
\begin{equation}
	\begin{array}{l}
	 \!\!\!	\!\!\!	\frac{\partial z_{ik}(\Delta \alpha_{ik})} {\partial \left( \Delta \alpha_{ik} \right)}\! =\! 0 \Rightarrow
		\Delta \alpha_{ik} \! \norm{\pmb{x}_{ik}}^2 
		\!+\! x_i^T \!\!\! \sum \limits_{\substack{k_1=1 \\ k_1 \neq k}}^{T} \! \left( \sum \limits_{\substack{j=1 \\ j\neq i}}^{n_k}  \! \! \! \! \Delta\alpha_{jk} \pmb{x}_{jk} \right)
		 \\
	 \!\!\!	+  \frac{1}{C_2}\cdot \pmb{x}_{ik}^\intercal \left( \sum\limits_{\substack{j=1 \\ i\neq j}}^{n_k}  \Delta \alpha_{jk} \pmb{x}_{jk}  \right) \!+ \! \frac{1}{C_2} \Delta \alpha_{ik} \! \norm{\pmb{x}_{ik}}^2
		\!- \! y_{ik} \! +\!  \epsilon\! =\! 0. \!\!\!
	\end{array}
	\label{eq:indminder}
\end{equation}
%%
%From \og{equation~\eqref{eq:indminder}}, we may also express the update of $\Delta \alpha_{ik}$. 
To simplify equation~\eqref{eq:indminder} with respect to $\Delta \alpha_{ik}$, we reorganize it using the following expressions:
%%
\begin{equation}
	\left\{
	\begin{array}{l}
		\sum \limits_{\substack{j=1 \\ j\neq i}}^{n_k} \Delta  \alpha_{jk}\pmb{x}_{jk} = C_2 \pmb{v}_k -   \Delta \alpha_{ik}^{\text{(prev)}}\pmb{x}_{ik},\\
		\sum\limits_{k_1=1}^{T} \sum \limits_{j=1}^{n_k} \Delta  \alpha_{jk_1}\pmb{x}_{jk_1} = \pmb{w} - \sum \limits_{j=1}^{n_k} \Delta  \alpha_{jk}\pmb{x}_{jk}  = \pmb{w}-C_2 \pmb{v}_k.
	\end{array}
	\right.
	\label{eq:regsubs}
\end{equation}
%%
In the next subsection, we formulate the expressions for the updated Lagrange coefficients and the hyperplane in the case of \textit{distributed} learning.


\subsection{Distributed Solution for Regression Problem}
\label{subsec:dsrp}
Similarly to the classification problem, we substitute expressions~\eqref{eq:regsubs} into~\eqref{eq:indminder}. As a result, we may derive the update for $\Delta \alpha_{ik}$ that each participant computes separately as
%%
\begin{equation}
	\begin{array} {l}
		\Delta \alpha_{ik} = -\frac{\pmb{x}_{ik}^\intercal \left (\pmb{v}_k    - \pmb{w}\right) - y_{ik}  +  \epsilon}{ \left (\frac{1}{C_2}-1\right) \norm{\pmb{x}_{ik}}^2 } +   \Delta \alpha_{ik}^{\text{(prev)}}.\\
	\end{array}
	\label{eq:regdevup}
\end{equation}
%%
Based on~\eqref{eq:regdevup} and~\eqref{eq:regexpr}, we define the updates for the global and local hyperplane components as
%%
\begin{equation}
	\left\{
	\begin{array}{l}
		% \Delta  \alpha_{ik}  = \alpha_{ik}^{-}-\alpha_{ik}^{+}\\
		\Delta \pmb{w} =\sum\limits_{k=1}^{T} \sum \limits_{i=1}^{n_k}  \left(\Delta  \alpha_{ik} - \Delta \alpha_{ik}^{\text{(prev)}} \right) \pmb{x}_{ik}, \\
		\Delta \pmb{v}_k =\frac{1}{C_2} \sum \limits_{i=1}^{n_k} \left(\Delta  \alpha_{ik} - \Delta \alpha_{ik}^{\text{(prev)}} \right) \pmb{x}_{ik}.
	\end{array}
	\right.
	\label{eq:reghypup}
\end{equation}
As a result, the common component $\pmb{w}$ is computed using the information from all participants, however, without sharing the training data. The local model $\pmb{v}_k$ only requires access to the data of the corresponding participant. This supports privacy of data since instead of the complete dataset, the participants share only common components $\pmb{w}_k$, which are then combined by the coordinator into $\pmb{w}$ and propagated back to the participants.

\subsection{Computational Complexity of Regression}
\label{subsec:ccr}
\par Here, we analyze the complexity of the MTL-SVM regression using the notation from Table~\ref{tab:conota}. We arrive at the following complexity formulations:
\begin{equation}
	\left\{
	\begin{array}{l}
		C_{ \pmb\alpha^+} = C_{ \pmb\alpha^-} = L\left(2D_m + D_a + D_d + 3_a + 1_d\right),\\
		C_{\pmb{w}} = L\left(2D_m + 2D_a + 2_s\right),\\
		C_{\pmb{v}} = L\left(2D_m + 2D_a + 2_s + 2_d\right),\\
		C_{\text{end}} = 4D_s + 4D_m + 4D_a + 4_{\text{sqrt}} + 2_d + 1_m.
	\end{array}
	\right. 
	\label{eq:compan_reg}
\end{equation}
In~\eqref{eq:compan_reg}, we recompute the updated values of $\pmb{w}$ and $\pmb{v}_k$ twice due to the presence of $\alpha_{ik}^+$ and $\alpha_{ik}^-$. This effectively doubles the computational cost of the regression solution. Asymptotically, the computational cost of the regression is the same as in the case of classification.
%\textcolor{red}{[Maybe we can assemble two complexity sections into one, or highlight in this one where regression becomes ``heavier'' due to two slack variables.]}

\section{Security Analysis of Updates}
\label{sec:sau}
\subsection{Analysis of Update Structure}
\label{subsec:aus}
In the envisioned distributed system, the updates are known to the coordinator. In this subsection, we assess whether a \textit{curious server} can reconstruct the data from the observed information. According to the proposed scheme, the server has access to the public model component, $\pmb{w}$, model update of a tagged participant $k$, $\Delta\pmb{w_k}^{\left(j\right)}$ at epoch $j$, and learning parameter $C_2$. The number of points $n_k$ of the participant $k$ for the training procedure may also be known under the assumption that users share it with the coordinator. The curious server may attempt to recover the local model component $\pmb{v}_k^{(j)}$, $d \times n_k$, data matrix $\pmb{X}_k$, and vector $\pmb{y}_k$ of data labels of participant $k$. Without loss of generality, we perform further analysis for a system with a single participant $k$ and a coordinator.

Here, we use the example of the classification problem and outline the composition of updates $\Delta \pmb{w}_{k}^{\left(j+1\right)}$ and $\Delta \pmb{v}_{k}^{\left(j+1\right)}$ in~\eqref{eq:cls_w_v} for a tagged participant $k$ at epoch $j+1$ as
\begin{equation}
\left\{
 \begin{array}{l}
 \Delta \pmb{w}_{k}^{
		\left(j + 1\right)} = \sum\limits_{i=1}^{n_k}\frac{1 - y_i \left(\pmb{w}^{\left(j\right)} + \pmb{v}_{k}^{\left(j\right)}\right)^\intercal  \pmb{x}_{ik}}{\norm{\pmb{x}_{ik}}^2} \pmb{x}_{ik} y_{ik},\\
 \Delta \pmb{v}_{k}^{
		\left(j + 1\right)} = \frac{1}{C_2}\left(\sum\limits_{i=1}^{n_k}\frac{1 - y_i \left(\pmb{w}^{\left(j\right)} + \pmb{v}_{k}^{\left(j\right)}\right)^\intercal  \pmb{x}_{ik}}{\norm{\pmb{x}_{ik}}^2} \pmb{x}_{ik} y_{ik}\right).
 \end{array}
 \right.
 \label{eq:captionres}
\end{equation}
%Based on~\eqref{eq:captionres}, 
One may conclude that since $C_2$ is known to the coordinator, it can easily derive $\Delta \pmb{v}_{k}^{\left(j+1\right)}$ using $\Delta \pmb{w}_{k}^{\left(j+1\right)}$. In this case, it would be possible to reconstruct both the entire dataset $\pmb{X}_{k}$ and labels $\pmb{y}_{k}$ by solving a system of $\left(d+1\right)n_k$ non-linear equations that follow from the first expression in~\eqref{eq:captionres}. 

To restore the data precisely, the curious server should capture $\Delta\pmb{w}_k$ for each of the $(d+1)n_k$ epochs, which may significantly exceed the number of iterations. The coordinator also needs to know the number of samples used for training, $n_k$, which generally may vary among tasks. However, if both the nature of the data and at least the estimates of $n_k$ are known, the curious server can produce multiple solutions for the system of non-linear equations for the available estimates of $n_k$ and then select the most realistic answer.% Moreover, the curious server may collude with malicious nodes to inflate the number of iterations before reaching the stopping criteria. %\att{[wasn't that the server who decides on stopping? then it would not need other users, it may request continuation itself?]}

\begin{figure}[ht]
	\centering
	\includegraphics[width=\linewidth]{Distorter.pdf}
	\caption{Example of discrete and continuous masking.}
	\label{fig:vecdist}
\end{figure}
To protect the data from reconstruction, we introduce random distortion in the transmitted updates as elaborated further in subsection~\ref{subsection:masking}. To do so, we first rewrite the expression for $\Delta \pmb{w}_{k}^{\left(j+1\right)}$ as given in~\eqref{eq:largesecurityequation} on the top of the next page.
%{We can review the formulation of the shared model update calculation as given \og{below}:}
\begin{figure*}[h!]
%\begin{strip}
%	\begin{center}
		\begin{equation}
		\Delta \pmb{w}_{k}^{
			\left(j + 1\right)} = \underbrace{y_1 \frac{1 - y_1 \left(\pmb{w}^{\left(j\right)} + \pmb{v}_{k}^{\left(j\right)}\right)^\intercal \begin{bmatrix}
					x_{11}\\...\\x_{1d}
			\end{bmatrix}}{\sum\limits_{i = 1}^{d}x_{1i}^2}}_{h_1} \begin{bmatrix}
			x_{11}\\...\\x_{1d}
		\end{bmatrix} + ... + \underbrace{y_{n_k} \frac{1 - y_{n_k} \left(\pmb{w}^{\left(j\right)} + \pmb{v}_{k}^{\left(j\right)}\right)^\intercal  \begin{bmatrix}
					x_{n_k 1}\\..\\x_{n_k d}
			\end{bmatrix}}{\sum\limits_{i = 1}^{d}x_{n_k i}^2}}_{h_{n_k}} \begin{bmatrix}
			x_{n_k 1}\\...\\x_{n_k d}
		\end{bmatrix}
		\label{eq:largesecurityequation}
		\end{equation}		\hrule
%	\end{center}
%\end{equation}
\end{figure*}
Let $h_{ik}^{(j)}$ denote the weight of vector $\pmb{x}_{ik}$ at epoch~$j$ for participant~$k$ in~\eqref{eq:largesecurityequation}, i.e.,
\begin{equation}
\begin{array}{c}
	 h_{ik}^{(j)} = y_{ik} \frac{1 - y_{ik} \left(\pmb{w}^{\left(j\right)} + \pmb{v}_{k}^{\left(j\right)}\right)^\intercal \pmb{x}_{ik}}{\sum\limits_{\ell = 1}^{d}x_{1\ell}^2}.
	 \end{array}
	 \label{eq:diagweight}
\end{equation}
%
Based on~\eqref{eq:diagweight}, the update for $\Delta \pmb{w}_{k}^{\left(j+1\right)}$ can be represented in a matrix form. If $\pmb{X}_{k}$ is a matrix of training points, and $\pmb{H}_{k}$ is a diagonal matrix of corresponding weights of the training points, then
%
\begin{equation}
\Delta \pmb{w}_{k}^{\left(j + 1\right)}\! =\! \pmb{X}_{k} \cdot \pmb{H}_{k}^{\left(j\right)}, \pmb{H}_{k}^{\left(j\right)}\! =\! \begin{bmatrix}
 h_{1k}^{\left(j\right)} & 0 & ... & 0 \\
 0 & h_{2k}^{\left(j\right)} & ... & 0 \\
 ... & ... & ... & ... \\
 0 & 0 & ... & h_{n_kk}^{\left(j\right)}
\end{bmatrix}\!.
\label{eq:matrixform}
\end{equation}
%\att{[connection between (33) and the following text?]}
%

%{Looking at the practical side of the problem, in the case of the UCIHAR dataset, the algorithm converged to a stable solution in less than 300 iterations. 
%If we calculate the number of required intercepts for UCIHAR $\left(d=561, L \approx 300\right)$, we arrive at 168600 intercepts for data recovery. 



\subsection{Proposed Masking Mechanism}
\label{subsection:masking}

To prevent the curious server from recovering the data from the intercepted model updates, we apply \textit{masking} to $\Delta \hat{\pmb{w}^{\left(j + 1\right)}}$ as follows:
%
\begin{equation}
 \Delta \hat{\pmb{w}}_{k}^{\left(j + 1\right)} = \pmb{X}_{k} \cdot \pmb{H}_{k} \cdot \pmb{p}_{k},
\end{equation}
%
where $\pmb{p}_{k} \in \mathcal{R}^d$ is a \textit{masking vector} of random variables. For \textit{discrete masking}, we utilize Bernoulli-distributed $\pmb{p}_{k}, p_{ik} \in \{0,1\}$, which, however, can be brute-forced if the number of iterations is sufficiently large. 

To make the recovery of the data even more difficult for the curious server, we propose the application of a continuous distribution for generating $\pmb{p}_{k}$. As an example of such distribution, we may consider the Beta distribution $\beta\left(a,b\right)$, where values are, for example, in the range $\left[0,1\right]$. 
%#NEXTREVISION
%This prevents the amplification of contribution for random points, as we can only decrease the ``importance'' of certain data points. If we would try to boost the impact of some point, there appears a matter of setting the upper limit of the amplification. This limit must be set depending on the sensitivity of the problem towards highly amplified points. Adding the capability to amplify the impact of a single point will also open opportunities for attackers to submit harmful over-amplified updates and disguise them as benign. 
Moreover, $\beta\left(a,b\right)$ allows the participants to adjust the shape of the distribution as desired by choosing parameters $a$ and $b$. There are two reasons behind this proposal. Firstly, if the distribution is continuous, the curious server can no longer rely on the assumption of a limited set of values and brute-force the system. Secondly, the application of a continuous distribution yields a lower performance drop compared to that of the discrete distribution since it less affects the value of the update. 

The geometrical representation of the above procedure is illustrated in~Fig.~\ref{fig:vecdist}, where the two-dimensional vector $\Delta \pmb{w}$ is represented as a sum of components $\Delta w_{i} = h_i \pmb{x}_{i}$, $i \in 1,...,n_k$. The continuous distribution of masking vector elements varies $\Delta w_{i}$, while the discrete removes selected terms from summation. %, on the participant $k$. 
We note that, in this case, the noise is correlated with the original data. Hence, the proposed approach differs from the one commonly used in differential privacy solutions, where the noise is not correlated with the data and is usually generated as a random variable with a Laplacian or Gaussian distribution. Our method is related to data masking that was also studied for FL~\cite{dhakal2019coded}.

\section{Numerical Results}
\label{sec:numres}
In this section, we provide selected numerical results and qualitative conclusions on the behavior of the proposed algorithm for solving classification/regression problems in the presence of stragglers. We also study the impact of different masking mechanisms on the resulting performance. Finally, we briefly explore the security of the system in the presence of a curious server.
% ~\cite{kairouz2019advances} [unclear, maybe better to reformulate but in a sense "we consider this" not in "we do not consider that"? btw free riders are explained in VI.A, maybe it's better to mention them first time only there]. \og{We consider attacks only on the model since \att{...} }} %Evasion attacks during the inference phases are out of the scope since they will be identical to the attacks on conventional SVM. 

We measure the performance of the following three methods utilized in both regression and classification problems:
\begin{itemize}
	\item \textit{Global SVM} -- The data of all participants are collected by the coordinator, which trains one global model $\pmb{w}$ and shares it. Importantly, in this case, all of the data are disclosed to the coordinator, which also significantly increases the load on the network and violates privacy requirements.
	\item \textit{Local SVM} -- Each participant trains a local model, $\pmb{w}_k$, without using any external communications. This method provides perfect privacy as no data leaves the participant. However, it results in lower accuracy of the trained model since the volume of training data available locally is smaller than in the case of the global method.
	\item \textit{MTL-SVM} -- The participant trains a model consisting of two components. Global model $\pmb{w}_k$ of the participant $k$ is computed locally, and then the update $\Delta \pmb{w}_k$ is shared with the coordinator. Local model $\pmb{v}_k$ is computed and kept locally. The coordinator processes global model updates received from the participants and sends back the new global model. The training is performed iteratively and requires communication between the coordinator and the participants. In this method, the participants do not explicitly share their data with the coordinator, yet a global model is trained. This allows the coordinator to disseminate the global model to newly joined participants, instead of recomputing it from scratch. The load on the network depends only on the number of participating nodes and the dimensionality of the model.
\end{itemize}
%%
To summarize, the global SVM method trains a single model by aggregating and processing all training data from the participants. Local SVM does not disclose any of the data, and the node is limited to its own training set. 
In MTL-SVM, participants send global model updates, which are aggregated at the coordinator to produce the common global model, which is 
personalized by the local model. % that tailors the common model to the specific features of their data distribution. 
%{In addition, in the case of the regression problem, we also apply the least square gradient descent method (LSGD) is applied for finding the solution.} 
\vspace*{-0.5cm}

\subsection{Simulation Parameters and Datasets}
%shortened to fit the line
\label{subsec:simparms}
In this subsection, we describe our scenario, outline the structure of the experiments, and define the employed system parameters. % used to obtain the numerical results.
%%

% OLD STUFF ABOUT SYNTHETIC SETS, JUST IN CASE
%Regression method is evaluated with synthetic datasets with Gaussian features, i.e., $\pmb x_{ik} \sim \mathcal{N}(\pmb{m}_j, \pmb \Sigma_j)$, where $\pmb m_j, \pmb \Sigma_j$ correspond to the particular class and task and control the similarity of the tasks. For synthetic datasets, volume $n_k$ is constant, while in UCIHAR the number of data points per participant varies.

Our setup comprises one coordinator and $T=20$ participants, each with its own task. We study the performance of the proposed classification algorithm utilizing the commonly used UCIHAR dataset for human activity recognition~\cite{10.1007/978-3-642-35395-6_30,anguita2013public}. The dataset contains data collected from multiple sensors during different activities such as sitting, walking, etc. The ``sitting'' class is separated from all other classes. Each of the data points contains $d = 561$ frequency and time domain features extracted from raw sensor measurements. The set contains data for multiple individuals, which are considered to be different participants in our experiment. For regression, we construct synthetic datasets, where we control the mean and variance of $\pmb x_{ik}$ for each participant separately, which allows us to introduce tasks with dissimilar data. In this case, learning a singular global model might be infeasible due to statistical differences between the feature characteristics of different participants. 
%\att{[Concrete parameters of synthetic dataset? if we decide to provide them at this iteration (can be done after Nageen or at the revision)]}
%\att{[Make sure that synthetic datasets are described somewhere so the results are reproducible]}%\att{homogeneity [what is it?]} among the tasks in the set. % and feature vector length $d$ are the same for all tasks. 
%For synthetic datasets, we can control the similarity of the tasks, as well as the parameters of the classes. We can control the variance of the sample point ``cloud'' and the separation between the centers of the \og{Gaussian} clouds.
The main system parameters are summarized in Table~\ref{tab:ml_parm}. 

We structure our numerical experiments as follows. We begin with a scenario where all participants have equal computing capabilities. % and then introduce the hardware heterogeneity \og{by varying the average compute delay of different participants}.
%by adding a \og{corresponding} multiplier for the compute delay. %The multipliers are applied accordingly to the participants by dividing corresponding delays by the multipliers. 
%In the case of fully homogeneous hardware, the multiplier for all of the participants is equal to one. 
%If heterogeneity is introduced, ``faster'' participants have a multiplier greater than one, and ``slower'' participants have a multiplier less than one.
Computing delays for a single participant are generated as random variables drawn from a Gaussian distribution since concurrent processes might affect the overall time of a single epoch. The mean and variance of the distribution are proportional to the complexity and, therefore, depend on $d$ and $n_k$. The parameters of the dependency of the mean and standard deviation on $d$ and $n_k$ are fitted based on the delay measurements performed on the computer. For the global method, we assume that the coordinator has the same computing capacity as all of the participants combined. %; \og{thus,} the compute delay is calculated as the sum of delays for individual participants. 

\begin{table}[ht]
	\centering
	\caption{Key System Parameters}
	\label{tab:ml_parm}
	\begin{tabular}{lr}
		\hline
		Parameter & \makecell[c]{Value} \\
		\hline
		%\hline
		Datasets & \makecell[r]{UCIHAR,\\ Synthetic}\\
		%\hline (Gaussian features [Or can remove "(Gaussian features)" ]
		Number of participants & 20 \\
		%\hline
		Tasks per participant & 1 \\
		%\hline
		Computing delay model & Gaussian \\% \att{[ref?]} \\
		%\hline
		Cross validations & 5 \\
		%\hline
		Training sub-set size & 70\% of all samples \\
		%\hline
		Participant hardware & \makecell[r]{Heterogeneous,\\ Homogeneous} \\
		\hline
		%Total max. iterations & 300 \\
		%\hline
	\end{tabular}
\end{table}

%Apart from the low-level simulation parameters, we provide a table with high level settings. 
%Among them is the heterogeneity of the participants, which regulates how much time each participant needs to process a single point during training. 
Furthermore, we model the \textit{diverse} computing capabilities of the participants. %Delays of the computationally strongest device are drawn from a mixture of Gaussian distributions as described above. % with mean depending on the dataset parameters. 
In this case, delays of a selected participant are obtained by dividing the corresponding random variables drawn from a Gaussian distribution by a constant factor that corresponds to its hardware capabilities. %We then introduce hardware heterogeneity by increasing the computing delays of some participants. 
The employed modeling approach reflects \textit{hardware heterogeneity} in real systems, where different equipment (e.g., smartphones, smart glasses, notebooks, etc.) is utilized, which may lead to participants being unable to deliver their updates. % Either may not be needed here? artifact :)
%[I remove THe below because it does not seem to be clear and justified at this point of the text]
%We observe that for the cases when the coordinator awaits updates from all of the participants, the convergence towards the final solution is smoother than in the case we limit the waiting period of the coordinator to a certain quantile of the maximum computation delay. 
%[this was better fit above so I already said it there]
%In particular, for a weaker node, the variability of computing capabilities is modeled by adding a corresponding multiplier that increases the average delay. 
In our particular example, we monotonically increase the hardware capabilities factor value from $1.0$ to $10.0$. %As one of the of the scenarios, we consider a case, where all of the participants have same compute capabilities (homogeneous hardware). 
%
In addition to hardware heterogeneity, we control the \textit{data heterogeneity} of the synthetic dataset by varying the statistical properties of the training data. %\att{[how?]} 
%As an example of such heterogeneity, \og{one may} consider a set of thermometer measurements in different rooms of the \og{building}. In this case, the mean temperature in living space might differ from the one in the basement. In all of the scenarios the participants have unique training points, however. 
%[commented the below ou because it is not exactly true and not connected to other sentences here]
%In all the cases, we explore the effects of the presence of stragglers, i.e., participants with lower computational capabilities that delay their updates. 
%Finally, we consider scenarios where some participants (``free riders'') may attempt to obtain the model without participating in the learning procedure.
%We simulate participant hardware heterogeneity by introducing a vector multipliers for generated delays. That allows us to assign a certain distribution to the delay multiplier values. 
%
%\begin{table}[h!]
%	\caption{Simulation parameters}
%	\begin{tabular}{l|r}
%		\hline
%		Parameter & Value \\
%		\hline
%		\hline
%		Monte Carlo trials & 64 \\
%		\hline
%		Participant HW types & Heterogeneous/Homogeneous \\
%		\hline
%		Training data heterogeneity & Task specific \\
%		\hline
%	\end{tabular}
%	\label{tab:simparm}	
%\end{table}
For clarity, the core structure of our numerical results is provided in Table~\ref{tab:my_label}.
\begin{table}[h!]
    \centering
    \caption{Scenario Characteristics in Numerical Results}
    \label{tab:my_label}
    \begin{tabular}{lcccccc}
        \hline
        \multirow{3}{*}{} & \multicolumn{3}{c}{Classification} & \multicolumn{3}{c}{Regression} \\
        \hline
        %\hline
         & 7.2.1 & 7.2.2 & 7.2.3 & 7.3.1 & 7.3.2 & 7.3.3 \\
        \hline
        Hom. data & \checkmark & \checkmark & \checkmark & \checkmark & & \\
        %\hline
        Het. data & & & & & \checkmark & \checkmark \\
        %\hline
        Hom. HW & \checkmark & \checkmark & & \checkmark & \checkmark & \\
        %\hline
        Het. HW & & & \checkmark & & & \checkmark \\
        \hline
    \end{tabular}
\end{table}

%\subsection{Metrics of Interest}
To assess the performance of our regression algorithm, we employ the R-squared coefficient, which is commonly used to evaluate the goodness of regression fit and is defined for samples from task $k$ as
%
%\begin{equation}
	$R^2 \!=\! 1 -\! \frac{\sum_{i=1}^{n_k} \left(y_{ik} - a(\pmb{x}_{ik})\right)^2}{\sum_{i=1}^{n_k}\left(y_{ik} \!- \frac{1}{n}\!\sum_{j=1}^{n_k}y_{jk}\right)^{\!2}} .$
%	\label{eq:regrs}
%\end{equation} 
In the case of classification, we measure true positive (TP) and true negative (TN) values and compare the results in terms of balanced accuracy $\frac{\text{TP} + \text{TN}}{2}$. 
%of precision $\frac{\text{TP}}{\text{TP} +\text{FP}}$, recall $\frac{\text{TP}}{\text{TP} +\text{FN}}$, and
%%
%\begin{equation}
%	\text{Error} = \frac{FP + FN}{2}.
%	\label{eq:fnfp2}
%\end{equation}
%
%
%\vspace*{-1cm}
\subsection{Evaluation of Classification Algorithm}
\subsubsection{Equal Computing Capacities, No Stragglers}
\label{subsec:cls_eco}
We consider a scenario where all nodes are responsive and have equal computational capacities. We measure the time required to complete a single epoch and compare it with that of the state-of-the-art MOCHA algorithm~\cite{smith2017federated}, which is built on a similar principle and aims at tackling the problem of stragglers. %the issues that are characteristic of the distributed environment with heterogeneous participants. %We \og{apply} a 5-fold cross-validation on a training set first, splitting the dataset into 5 parts on each task, and then using 1 part for testing, and others from training. 
%The regularization constants are selected based on the 5-fold cross-validation.
%%
%%

\begin{comment}
We begin with studying the dynamics of FN and FP in time. In Fig.~\ref{fig:fnpc}, we observe that MTL-SVM nearly reaches the local method accuracy. The global method produces a single model for all tasks that demonstrates worse performance, compared to that of local method. We observe that the proposed algorithm reaches the steady state faster than the state-of-the-art method~\cite{smith2017federated} and results in slightly lower FP/FN values.%, as well as higher error for MOCHA.
%
%%
\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{figs/FNFP.pdf}
\caption{Classification, UCIHAR: FN/FP comparison.}
\label{fig:fnpc}
\end{figure}
%%
We continue by comparing the algorithms in terms of FP. In Fig.~\ref{fig:fnpc}, we observe that the state-of-the art multi--task method outperforms the global method; however, the local and MTL-SVM methods demonstrate better performance. Naturally, the global method converges more rapidly since more data is available for training.
\end{comment}
%%
In Fig.~\ref{fig:evsvssvm_st}, we provide the comparison in terms of balanced accuracy. The coordinator, in this particular case, waits for all of the participants to deliver an update. These settings are denoted by the label \textit{[All]} in the legend here and in subsequent figures. We observe that MTL-SVM outperforms other considered methods. In particular, the global method results in the lowest performance, while the local method demonstrates comparable values. We note that the local method can be outperformed by multi-task solutions if the dataset volume is limited. In this case, the multi-task algorithms allow us to leverage the information on the data of other participants. %In regards to the average error, MTL-SVM achieves the best performance among the considered methods.
%%
\begin{figure}[h!]
	\centering
	\includegraphics[width=\linewidth]{BA_SVMvsMOCHA.pdf}
	\caption{Classification, UCIHAR: no stragglers.}
	\label{fig:evsvssvm_st}
\end{figure}
%%
In addition, MTL-SVM rapidly converges due to the optimization of one Lagrange multiplier at each iteration in the solution of the dual problem. This could prove beneficial for devices with limited computing capacities and energy constraints as they can perform the calculations and reenter the power-saving mode.
\par
To analyze the computing delays, we select the optimal regularization constants for both methods and conduct the training procedure 64 times using the Windows release of MATLAB R2021a on a stock Lenovo P330 workstation with an i7-8700 CPU. We observe that MTL-SVM trains the models for 20 tasks in $4.47$\,s, with a standard deviation of $0.031$\,s, while the state-of-the-art multi-task algorithm requires $5.28$\,s with a standard deviation of $0.068$\,s, which represents a $20\%$ improvement in speed.
%Delay will increase with larger training sets, both number of training points and their dimensionality. Just for reference, these times were achieved in Windows release of MATLAB R2021a on a stock Lenovo P330 workstation with an i7-8700 CPU.
%%
\subsubsection{Equal Computing Capacities, Stragglers}
%%
Further, we study the impact of the presence of stragglers on the performance of our classifier. We assume equal computing capabilities for all participants, which means the delays are drawn from the same distribution. In contrast to the previous experiment, 
 %The presence of stragglers is explained by the diversity of concurrent computing workload of the participants in the case coordinator waits for the slowest participants. In Fig.~\ref{fig:cstrset}, such 
the coordinator has a waiting period $T_{wait}$, during which the participants are expected to complete calculating their updates. If during $T_{wait}$, some of the participants fail to deliver $\Delta \pmb{w}_i^{\left(j\right)}$, they are considered to be stragglers at epoch $j$. The aggregated global update $\Delta \pmb{w}^{\left(j\right)}$ is then calculated based on the individual updates that are received successfully. The global update, $\Delta \pmb{w}^{\left(j\right)}$, is sent to all participants, including stragglers. 

The coordinator can adjust the parameter $T_{wait}$. For example, participants may evaluate their performance with a common benchmark and store maximum epoch completion time. The coordinator acquires these data when participants join and select, e.g., the maximum from the list of received values. %This corresponds to waiting for updates from all of the participants within a certain margin. %It was noted that limiting the $T_{wait}$ time led to accelerated convergence. [looks like you see the future here :)] 
We explore four cases with different waiting periods $T_{wait}$. 
%for the responses from the participants. 
The corresponding percentages of successfully responded participants are given in the legend in the brackets as, e.g., \textit{[45\%]}.
%

In Fig.~\ref{fig:cstrset}, we explore the impact of different percentages of responded participants on the achieved performance in terms of convergence and the final balanced accuracy. 
%The average percentages of responded devices are given in brackets in the legend.
\begin{figure}[h!]
	\centering
	\includegraphics[width=\linewidth]{BA_UCI_HOM.pdf}
	\caption{Classification, UCIHAR: homogeneous hardware.}
	\label{fig:cstrset}
\end{figure}
%
The presence of stragglers accelerates the convergence at the beginning due to the fact that the waiting period, $T_{wait}$, is lower than the epoch duration of the \textit{[All]} configuration. This enables a faster exchange of updates, thus accelerating the learning process. However, this effect is limited by the amount of information utilized by the non-straggling participants. For example, as illustrated in~\ref{fig:cstrset}, the $10\%$ response ratio yields poor stability due to an insufficient amount of information delivered for the construction of the model. In this particular case, the balanced accuracy degrades to the values, comparable to the ones achieved in the case of learning a single global model.
%%
\hspace{-0.1cm}
\subsubsection{Diverse Computing Capacities, Stragglers}
%%

In addition, we explore the impact of introducing heterogeneous hardware, where delays are modeled using the hardware capabilities factor. 
%on the performance of the system. 
In Fig.~\ref{fig:cstrset_het}, we may observe that the final balanced accuracy is slightly higher than that in the case of homogeneous stragglers. The results also reveal that if the waiting period leads to $20\%$ of the participants responding on time, convergence toward the solution is accelerated, albeit at the cost of reduced numerical stability, compared to other cases. The degradation in numerical stability can be observed in the form of sporadic drops in balanced accuracy. 
%in Fig.~\ref{fig:cstrset_het}. 
Although some of the participants %$i \in \left\{1,\ldots,k\right\}$ 
fail to submit the common component $\Delta\pmb{w}_k^{\left(j\right)}$ to the coordinator on time at epoch $j$, they still receive the global common component, $\Delta\pmb{w}^{\left(j\right)}$. This component, however, does not include the information from these straggling participants, thus making the model less suitable for them if the data are heterogeneous. For higher percentages of responsive participants, the balanced accuracy increases, as well as the numerical stability of the method improves. The final value of the balanced accuracy reaches similar values in all cases.
%%
\begin{figure}[h!]
	\centering
	\includegraphics[width=\linewidth]{BA_UCI_HET.pdf}
	\caption{Classification, UCIHAR: heterogeneous hardware.}%[shortened to fit the line]
	\label{fig:cstrset_het}
\end{figure}
%%
\subsection{Evaluation of Regression Algorithm}
\subsubsection{Equal Computing Capacities, Homogeneous Data}% \att{[to which subsection in classification it corresponds? the names are different, are the cases different too?]}}
\label{sss:reg_homdhomh}
We begin our assessment of the regression algorithm with the case of equal computing capabilities and identical distribution of data across participants. In Fig.~\ref{fig:rstrset}, we evaluate the performance in terms of $R^2$
using a synthetic dataset with $T = 20$ tasks, each with $n_k = 200$ samples and $d = 200$ features. The noise added to the synthetic data represents measurement noise and is adjusted to maintain the SNR of $20$\,dB. We may notice that the MTL-SVM method with waiting period $T_{wait}$ corresponding to the $45\%$ of participants responding results in slightly faster convergence in absolute time due to shorter epochs. As we decrease $T_{wait}$ further and the coordinator receives fewer responses, the convergence rate degrades due to insufficient information from the participants. In summary, a reduction of $T_{wait}$ may yield marginal improvements in the case of a fully homogeneous scenario.
%%
\begin{figure}[h!]
	\centering
	\includegraphics[width=\linewidth]{Reg_homo_lvar.pdf}
	\caption{Regression, synthetic: homogeneous node hardware, identical data distribution.}
	\label{fig:rstrset}
\end{figure}
%
If we explore the results for smaller values of $T_{wait}$, we observe that for $25\%$ of participants responding, the convergence rate decreases. The case where $T_{wait}$ is reduced further and only $10\%$ of participants deliver updates on time, results in numerical instability. However, in all of the cases, the method converges to a stable solution with a high $R^2$ level.
%%
\subsubsection{Equal Computing Capacities, Diverse Data}% \att{check titles, they might not correspond to the content}}
%%
\label{sss:homhhetd}
While our previous results in~\ref{sss:reg_homdhomh} assume that the data of the participants are homogeneous, in reality, this may not hold, and each participant requires model personalization. We, therefore, also investigate the behavior of the proposed methods in a scenario of heterogeneous data on nodes with homogeneous hardware.
%%
\begin{figure}[h!]
	\centering
	\includegraphics[width=\linewidth]{Reg_homo_hvar.pdf}
	\caption{Regression, synthetic: heterogeneous data and homogeneous node hardware.}
	\label{fig:hetreg}
\end{figure}
%%
In Fig.~\ref{fig:hetreg}, we observe several effects caused by the heterogeneity of the data across participants. Compared to Fig.~\ref{fig:rstrset}, the convergence rate increases noticeably for the cases where $T_{wait}$ is configured to allow $45\%$ and $25\%$ of participants to respond on time. Despite a drop in the $R^2$ metric, for both $45\%$ and $25\%$ response percentages, the method still converges at a higher rate than in the case when the coordinator waits for all of the participants. For the $10\%$ case, the convergence degrades compared to other cases. Moreover, we observe that at the later epochs, the $R^2$ metric declines slowly. This effect is caused by the insufficient amount of information delivered with $\Delta \pmb{w}$. In this particular scenario, we observe the system balancing between having enough data delivered by the participants and reducing the waiting period to shorten the epoch time. The overall performance is, however, degraded due to the heterogeneity of the data. %TODO\att{[why multi--task doesn't help?]}
%%
\subsubsection{Diverse Computing Capacities, Diverse Data}
%%
In Fig.~\ref{fig:rstrset100}, we present the results where the data and computing power of the participating nodes are heterogeneous. %The data of the participants maintain its heterogeneity. 
We may notice that setting $T_{wait}$ for allowing $45\%$ percent of participants to respond is no longer feasible and provides no benefit in terms of learning speed. If $75\%$ of participants respond on time, it still provides a visible improvement in terms of convergence rate, while $20\%$ percent of participants responding on time yield noticeable performance degradation. In this scenario, we observe effects from both the reduction of $T_{wait}$ and increased heterogeneity of the stragglers. This results in less information being delivered from the participants and, thus, a sharper decrease in the quality of the model for lower percentages of data delivered on time.
%%
\begin{figure}[h!]
	\centering
	\includegraphics[width=\linewidth]{Reg_hete_hvar.pdf}
	\caption{Regression, synthetic: heterogeneous node hardware and data.}
	\label{fig:rstrset100}
\end{figure}
%
The performance of the method with both the hardware and data being heterogeneous does not change significantly compared to the scenario in~\ref{sss:homhhetd}.
%%
\subsection{Security Aspects: Impact of Masking}
%%
%{\apt{We explore the impact of \of{subsampling} by constructing \og{a} \att{coding vector [was it introduced?]} using} Beta distribution.} 
We evaluate the impact of masking by considering two types of distributions of elements of the masking vector, $p$, namely, Bernoulli and $\beta\left(a, b\right)$ distributions. We also employ truncated UCIHAR with $n_k=100$ samples per task, which is marked as ``light UCIHAR''. With this dataset, it is possible to illustrate the benefit of the proposed MT-SVM algorithm for data-deficient scenarios. For the Bernoulli distribution, the parameter is adjusted in the range of $\left\{1, 0.75, 0.5, 0.25\right\}$, for $\beta\left(a,b\right)$ distribution, we set $a=2, b=0.5$ (the mean of the $\pmb{p}$ then equals $\frac{a}{a+b} = 0.8$) to avoid complete drop-out of the data points. Since $\beta\left(a,b\right)$ distribution can affect all data points, we control the ratio of the points where we do not apply masking within the range $\left\{1, 0.75, 0.5, 0.25\right\}$.
%
\begin{figure}[h!]
 \centering
 \begin{subfigure}{0.48\linewidth}
  \includegraphics[width=\linewidth]{MTL_Bern_full.pdf}
  \subcaption{Original UCIHAR dataset.}
 \end{subfigure}
 \begin{subfigure}{0.48\linewidth}
  \includegraphics[width=\linewidth]{MTL_Bern_trunc.pdf}
  \subcaption{Light UCIHAR dataset.}
 \end{subfigure}
 \caption{Classification, UCIHAR: effects of Bernoulli masking. The percentage in the brackets corresponds to the fraction of training points that are affected by the masking procedure.}
 \label{fig:berncode}
\end{figure}
%%
For the Bernoulli masking, in Fig.~\ref{fig:berncode}, we may observe a significant performance degradation for low values of distribution parameters, i.e., for $E[p] = 0.25$, since most of the points are excluded from the training procedure. For parameter values of $\left\{1, 0.75, 0.5\right\}$, the degradation is not as severe, albeit the difference with MTL-SVM without masking is noticeable. For a truncated dataset with $n_k = 100$, the performance impact is more evident. This dataset also highlights one of the strong sides of the MTL, when participants hold a limited volume of data. Even for the highest exclusion ratio of $0.25$, the resulting balanced accuracy is greater than that in the case of the local mode of operation.
%%
\begin{figure}[h!]
 \centering
 \begin{subfigure}{0.48\linewidth}
  \includegraphics[width=\linewidth]{Beta_fullset.pdf}
  \subcaption{Original UCIHAR dataset.}
 \end{subfigure}
 \begin{subfigure}{0.48\linewidth}
  \includegraphics[width=\linewidth]{Beta_cutset.pdf}
  \subcaption{Light UCIHAR dataset.}
 \end{subfigure}
 \caption{Classification, UCIHAR: effects of $\beta\left(2,0.5\right)$ masking on balanced accuracy for original and truncated versions of the dataset. In $\beta\left(r\right)$, $r$ corresponds to the ratio of the points not affected by the masking.}
\end{figure}
%%
The application of the $\beta\left(a,b\right)$ distribution yields a more stable performance, compared to the Bernoulli distribution. The difference between applying these two distributions is such that the Bernoulli distribution only excludes random data points from participation in a single epoch. Contrary to this, the $\beta\left(a,b\right)$ distribution decreases the contribution of every data point by a random value. Thus, the effect of randomization based on the $\beta\left(a,b\right)$ distribution is less noticeable than that of the case of the Bernoulli distribution, which results in a more stable performance. We may observe that with the $\beta\left(a,b\right)$ distribution, the overall performance is nearly unaffected by the introduced masking. In the case of the light UCIHAR dataset, we can observe that the MTL method consistently outperforms the local method.

%UCOMMENT%\att{[it is not fair to consider distributions with different means as they introduce different level of distortion without mentioning that. It would be fair to compare those distribution with the mean 1, for example; advertising 0.8 over 0.5 is not reasonable]}

%UCOMMENT%\att{[there was a subsection on free riders, if we don't use it, remove mentioning them in other sections]}
%%
%\subsection{Effects of Free-Riders}
%{To fairly measure the impact of the free-rider presence we will be separately measuring the performance of compliant participants, and free-riders. \\
%The first example is the presence of smart free-riders. They hold the data but want to just receive the model without spending their computer resources. However, if they just send in an update filled with zeros, they will be easily detected and removed from the system. Therefore they run the first epoch only and keep sending the same update.}
%%
%\begin{figure}[h!]
%\includegraphics[width=\linewidth]{figs/Errors_saboteur_stop_10.pdf}
%\caption{Effect of presence of 10 free-riders.}
%\label{fig:stop_fride}
%\end{figure}
%%
%{From Fig.~\ref{fig:stop_fride} we can deduct that the performance of compliant nodes is not impacted. Free-riders, however, fail to reach the performance of the compliant nodes and demonstrate a trend towards an unusable model. This leads us to believe, that this may be one of the incentives for the nodes to fully participate in the training procedure.}
%%

%%% WHAT WE NEED HERE:
%1. Когда наш метод лучше глобального и локального просто так 
%2. Насколько он быстрее других аналогов 
%3. Насколько он устойчив к страглерам: сколько можно пропустить апдейтов на одном устройстве в среднем, а сколько устройств можно %пропустить, чтобы еще что-то работало
%4. А что будет с устойчивостью и отношение к локальном у и глобальному, если у нас разные распределения данных по устройствам?

\section{Conclusions}
\label{sec:concl}
In this work, we study a distributed learning system deployed over a network of heterogeneous participants and provide an algorithmic solution for the federated multi-task classification and regression problems. The proposed algorithm allows personalizing the learning model for each participant without sharing the training data and improves the performance, compared to that of the locally trained models provide. The method is especially beneficial in the case of the low volumes of data available to individual participants.
%
Based on the results of the numerical performance evaluation, we come to the following conclusions regarding the designed algorithm.
\par
The proposed iterative distributed solution provides performance comparable to or superior to learning on locally available data. In the case of learning a single global model on heterogeneous data aggregated at the coordinator, the advantage of our distributed iterative method is even more pronounced. 
%~\ref{fig:evsvssvm_st}
In all the considered cases, the proposed MTL-SVM method outperforms the global method by a noticeable margin. The performance of our distributed method also exceeds the performance of local learning methods. Such an advantage is especially noticeable in scenarios where participants hold an insufficient volume of data. %When compared with the other multi--task algorithms, our method also converges faster and to a higher balanced accuracy.
%\par
When compared with other similar methods, our method requires 20\% less time for one epoch.
%and reaches a lower error. [I removed this because the difference is marginal, and we didn't check many datasets; if you want to emphasize that, let's discuss how to do that carefully]
This is especially important for participants with limited computing power or energy source. 
\par The method is robust to the presence of stragglers, and its performance may also be boosted by adjusting the waiting period $T_{wait}$ to a smaller value. This could decrease the epoch duration at the cost of missing updates from slower participants.
%\par
%Since reducing the waiting period introduces more stragglers into the scenario, we assess the stability and performance of the method with different percentages of stragglers among the participants. 
In the presence of stragglers, our proposed method demonstrates stable convergence and performance even in those cases, where only a quarter of the participants are responding on time. This holds for both homogeneous and diverse computing capacities. 
%In the regression problem with the heterogeneous data, noticeable performance degradation occurred when less than a quarter of the participants were delivering updates on time. [not a positive tone]
\par
Furthermore, in the case of the low training data volume, participants can reach a higher accuracy than in the case of learning only local data. This may aid participants that are limited in terms of available data either due to its scarcity or low volume of available storage. This is also beneficial for participants with poor hardware since they may not be able to store all of the data at the same time.
%\par
Finally, the proposed masking mechanisms allow participants to prevent data disclosure in case of message interception or a curious server threat model. The theoretical analysis of privacy guarantees is one of the future directions we intend to explore.
\begin{comment}
   \section*{Acknowledgements}
\att{What to write specifically?} 
\end{comment}

%
%Based on \og{the results of our numerical performance evaluation}, we make the following conclusions: \att{[I think it is a bit unfair when you separate and compare classification and regression given that you have different datasets for them and no measure to compare them; you might want to reconsider and generalize those conclusions]}
%\begin{itemize}
%	\item \og{The proposed} multi--task \og{solution is} tolerant towards the \og{presence of} stragglers and \og{undelivered} responses. \og{Despite a} slower conver\og{gence in} the presence of stragglers, the algorithm produces a model, identical to the one \og{computed} without stragglers. {This can be seen in Fig.~\ref{fig:cstrset}, Fig.~\ref{fig:cstrset_het}, and Fig.~\ref{fig:hetreg}.}
%	\item \og{The r}egression \og{method} is less sensitive to \og{the} presence of stragglers. \att{While it is not very sensitive towards stragglers, it is sensitive to hardware heterogeneity [unclear, stragglers are the results of heterogeneity]. This may be caused by some of the participants dropping out of training and thus producing sub-optimal model.}
%  \item The stragglers affect the conver\og{gence} rate of the classification \og{[only classification?]}, but do not affect the final quality of the model.
%  \item Application of summation operation for the updates, means the method may be portable to over-the-air solutions. Application of over-the-air compute is infeasible with current hardware, but advances in electronics may change the situation.
%  \item \og{The proposed} MTL-SVM system can be made more secure with the introduction of the coding, \og{which does not} allow \og{an} eavesdropper to recover the \og{exact training} data. \og{Varying the distribution of random variable involved in subsampling, one may reach} \og{a} negligible performance drop. Moreover, each participant may utilize \og{its own \att{?}} arbitrary distribution to further complicate the recovery of the data. \att{[speaking about which distribution is better, please, pay attention to whether it is fair to compare them]}
%  \item \og{The d}ecrease of the local data volume lead\og{s} to \og{a} noticeable degradation of the model quality \att{[separately, this is obvious, are you going somewhere with this?]. It also highlights and exploits the benefits of multi--task mode of operation.[unclear what you mean]}
%\end{itemize}
%
%%{In this paper we presented a multi--task machine learning algorithm based on SVM and analysis of its properties. We compared the performance of the algorithm with MOCHA framework in terms of error and performance. From the results, we see that not only MTL-SVM reaches steady-state earlier, but the steady-state error is noticeably lower. If we consider the measured compute delay, we see that MTL-SVM reaches steady-state low error in 0.8 seconds, while MOCHA reaches this error in 2.2 seconds. 
%
% \att{We also analyzed [check consistency of the tense: it's either present or past] how [we don't use ``how''] the update of the model might be secured from eavesdroppers without application of encryption. %We study this aspect, because application of the algorithm without subsampling might lead to the data being recovered by eavesdropper.
% Application of subsampling with continuous distribution demonstrated negligible loss of performance. [was it already discussed above?]}
%%%
%
%%%
%\att{[please, merge the rest with the above if you want to have items, if not, rewrite without items the entire text then] From the tests on the sensitivity towards stragglers, it can be seen, that the system has a low sensitivity towards stragglers. The heterogeneity of the participating hardware does increase the sensitivity. This is due to the fact that low-end participants most likely will [we dont use futere tense] lag behind the overall system.}
%%%
%
%{As a part of this study, we also implemented a demo program to test algorithms in a real network. The demo with the documentation can be found at~\cite{MLD}.}
%%
%With a growing amount of such target tasks, the question arises how knowledge of non-target speaker state and trait information may help the task at hand throughout classification or regression. If such information is not available, the follow-up question will be how combined assessment may help individual tasks, as in multi--task learning. Since learning multiple classification and regression tasks simultaneously allows to model mutual information between the tasks—which in turn can result in enhanced recognition performance for the individual tasks, multi--task learning has recently attracted a lot of attention in the machine learning community. Applying Support Vector Machines (SVM) with kernel functions that use a task-coupling parameter, or multi--task learning based on minimisation of regularisation functionals, outperformed single-task SVMs (Evgeniou and Pontil, 2004). In Micchelli and Pontil (2005), the authors use matrix-valued functions as kernels for multi--task learning. 
%C.A. Micchelli, M. Pontil Kernels for multi--task learning Proceedings of the 18th Conference on Neural Information Processing Systems, Vancouver, BC (2005), pp. 1-8

%Multiple object tracking: A literature review
%

%  trained on dierent yet inter-related datasets. The method is advantageous when multiple classification tasks and dierently labeled datasets exist over a common input space. Different datasets can mutually reinforce a common choice of representation or relevant features for their various classffiers. We derive a multi--task representation learning approach using the maximum entropy discrimination formalism. The resulting convex al-gorithms maintain the global solution prop-erties of support vector machines. How-ever, in addition to multiple SVM classica-tion/regression parameters they also jointlyestimate an optimal subset of features or op-timal combination of kernels. Experimentsare shown on standardized datasets.
%multi--task learning or meta-learning leverages these many datasets synergistically, aggregating them and augmenting the eective size of the total training data (Baxter, 1995; Thrun & Pratt, 1997; Caru- ana, 1997). This can lead to improvement in overall classication and regression performance compared to learning the tasks in isolation. We elaborate meta- learning in a support vector machine setting and fo- cus on the case where many small datasets over dif- ferent tasks select one common underlying represen- tation. More specically, we discuss optimizing the representation either as a feature selection congura- tion (Jebara & Jaakkola, 2000; Weston et al., 2000) or as a convex kernel combination (Lanckriet et al., 2002; Cristianini et al., 2001). This is done jointly while estimating a support vector classication or re- gression machine by using the maximum entropy dis- crimination (MED) framework. While previous eorts suggest nding these representations for a single task, recent theoretical results (Baxter, 2000; Ben-David & Schuller, 2003) suggest that improvements are possi- ble with multi--task learning. This article combines the above motivations into a joint multi--task feature and kernel selection SVM framework.




%multi--task learning or meta-learning leverages these many datasets synergistically, aggregating them and augmenting the effective size of the total training data (Baxter, 1995; Thrun & Pratt, 1997; Caru- ana, 1997). This can lead to improvement in overall classication and regression performance compared to learning the tasks in isolation. 

\bibliographystyle{IEEEtran}
\bibliography{refs_mtl}


%\bibliography{bibliography}
\end{document}


