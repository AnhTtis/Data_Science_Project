\noindent 
We proposed cooperative federated learning (CFL), a paradigm that extends the notion of cooperation in federated learning (FL) and unlocks the potential of edge/fog networks in the execution of distributed machine learning tasks. 
Through device-to-device (D2D) and device-to-server (D2S) cooperation, CFL counteracts the heterogeneity of edge/fog networks to improve ML model performance, energy efficiency, temporal sensitivity, and data/model privacy. We proposed novel technologies that enable efficient D2D and D2S cooperation in CFL. 
% edge devices can share data, ML models, and computational 
% When they involve device-to-device collaboration, devices can share data, model, and computational resources. We also show that the inclusion of device-to-server cooperation provides further opportunities for both energy efficient and faster ML model training. 
Finally, we illustrated how CFL can extend the frontiers of research in FL. % and, more generally, distributed ML. 




