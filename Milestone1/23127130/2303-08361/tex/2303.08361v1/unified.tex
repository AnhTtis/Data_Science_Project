% unified framework tackles these limitations

% Our ultimate goal is to develop a network-aware cooperative FL methodology that can address the missed opportunities in FL. 
% As outlined in Sec.~\ref{sec:intro}, different types of network cooperation can address separate opportunities in FL, and, in order to simultaneously realize all of this untapped potential, we need a unified framework combining various kinds of network cooperation. 
% This vision for a unified framework involves: 
% \begin{enumerate}
%     \item Maximizing use of links between device pairs via D2D data and model sharing, which increases total network data processed per global aggregation, reduces overall network energy consumption per datum, and minimizes network delay and straggler effects from both data processing and model transmission at aggregations.
%     \item Engaging edge servers as mixed-use resources. These edge servers will be able to cooperate with devices by receiving data from devices and performing ML model training on server, when needed. They also reduce the communication delay and energy consumed during ML model transmission. Furthermore, they act as local data caches, which can carry globally representative distributions of high quality data, to lessen the impact of non-iid data across the network. 
%     \item Multi-hop cooperation between devices and servers via data and model sharing, which can further reduce the energy and time expenditure for ML model training tasks and extends federated learning so that even devices without direct communication links to the central server will participate and benefit from the FL process. 
%     \item Considering varying network devices' privacy needs by developing an opt-in framework with varying levels of data and model sensitivity. 
%     \item Integrating devices with partially labeled or unlabeled datasets into FL. Due to their lack of labeled data, devices with partially labeled and unlabeled data may have different data distributions and domains than their labeled counterparts.
%     Consequently their ML model and training needs will differ from those devices with labeled data as well. 
%     Instead of making these devices use the same global model, cooperation allows the network to integrate these unlabeled or partially labeled devices into the FL ecosystem through domain adaptation. %to provide these unlabeled or partially labeled devices with a customized combination of ML models from labeled devices in a way that approximates their local data distribution. %integrating them into the FL ecosystem requires domain adaptation. 
% \end{enumerate}
% % Specifically, a unified framework includes: (1) maximizing use of links between device pairs via D2D data and model sharing, which increases total network data processed per global aggregation, reduces overall network energy consumption per datum, and minimizes network delay and straggler effects from both data processing and model transmission at aggregations, (2) engaging edge servers as computational 

\subsection{Towards Network-Aware CFL}
% Originating from the pillars of D2D and D2S cooperation, we can develop complementary technologies, which all follow the paradigm of network-aware CFL. %This proposed paradigm relies on cooperative edge/fog networks to enhance standard FL 
As depicted in Fig.~\ref{fig:main_diagram}, our vision for CFL relies on cooperative edge/fog networks to enhance standard FL on (i) ML performance - the effectiveness of the ML model trained by the network, (ii) energy efficiency - the network-wide accumulated energy expenditure on data processing, and data/model communication, (iii) temporal efficiency - the total time including idle time consumed by the FL process, and (iv) data and model privacy - the heterogeneous privacy needs in large-scale edge/fog networks. 
% The design considerations outlined above motivate network-aware CFL, a novel paradigm that relies on cooperative edge/fog networks to enhance standard FL on four fundamental fronts: (i) ML performance - the effectiveness of the ML model trained by the network, (ii) energy efficiency - the network-wide accumulated energy expenditure on data processing, and model and data communication, (iii) temporal efficiency - the total time including idle time consumed by the FL process, and (iv) data and model privacy - the heterogeneous privacy needs in large-scale edge/fog networks. 
Methodologies that develop network-aware CFL must carefully balance their contributions to these four coupled elements, which contain design trade-offs. % which are coupled together and thus contain design trade-offs. 

% So, we first establish an analytical foundation depicted in Fig.~\ref{fig:main_diagram} that characterizes network-aware cooperative FL by four fundamental components: (i) ML performance - the classification effectiveness of the ML model trained by the network, (ii) energy efficiency - the network-wide accumulated energy expenditure on data processing, model and data communication, and idling, (iii) temporal sensitivity - measuring time consumption of the ML training and associated processes as a network resource, and (iv) data and model privacy - user controlled preservation of data and model integrity. 
% While these four aspects have some overlapping effects, for instance the most energy efficient method may not generate the best ML model performance, methods that move towards developing network-aware cooperative FL must consider these four elements explicitly. 

% After standard FL and the core trade-offs of cooperation, 
The first layer of network-aware CFL consists of the pillars of D2D and D2S cooperation and their core mechanisms. %The first layer of development consists of the fundamental mechanisms of device-to-device (D2D) and device-to-server (D2S) cooperation relative to the four guiding trade-offs/principles in a standard FL network. %must consider 
D2D and D2S cooperation can leverage data and model transfers to cope with device heterogeneity. % (e.g., varying computational power). 
{\color{black}For example, data offloading through D2D links can yield energy savings, and ML model routing through D2S links can mitigate straggler effects.}

With our established frameworks of D2D and D2S cooperation, we can then develop complementary technologies to enhance CFL along the four design considerations of (i) ML performance, (ii) energy efficiency, (iii) temporal sensitivity, and (iv) data/model privacy.
% Subsequently, we can extend the benefit brought by D2D and D2S cooperation along the four core CFL properties of (i) ML performance, (ii) energy efficiency, (iii) temporal sensitivity, and (iv) data/model privacy through proposed complementary technologies, 
In Fig.~\ref{fig:main_diagram}, we depict three sample complementary techniques, with each technique primarily improving one aspect of CFL. For instance, multi-hop collaborations such as those seen in industrial IoT~\cite{li2022data} enhance resource (energy and delay) efficiency, integration of unlabeled data such as those in autonomous driving~\cite{luo2021self} can improve ML performance, and heterogeneous privacy as seen in social trust~\cite{lin2021friend} offers an alternative approach to data/model privacy. 
% such as multi-hop collaborations in large-scale IoT~\cite{li2022data}, unlabeled datasets in autonomous driving~\cite{luo2021self}, or heterogeneous data privacy by connecting FL with social trust aspects~\cite{lin2021friend} as depicted in the complementary technologies layer in Fig.~\ref{fig:main_diagram}. 
We next develop D2D and D2S cooperation as the two pillars of network-aware CFL, and, as future work, explain how complementary technologies can enhance them. 
% demonstrate how each pillar can be extended and enhanced with novel technologies, presented as possibilities for future work. 


% % The first step towards network-aware cooperative FL is to develop FL strategies and frameworks that leverage network cooperation to improve or enhance ML performance, temporal sensitivity, energy efficiency, and data and model privacy. 
% In this layer, foundational cooperation strategies such as D2D data offloading, data sharing agreements, device sampling for aggregation, idle time management, etc., are integrated together into new frameworks, e.g., parallel successive learning, multi-edge server cooperative learning, and mixed-supervision federated learning. 
% % We depict these resulting cooperative strategies in the first layer towards network-aware cooperative FL of Fig.~\ref{fig:main_diagram}. 
% The next layer combines these above considerations together leading to further developments such as: (i) PSL with mixed composition datasets, (ii) massive federated domain adaptation with multi-server support, and (iii) online federated domain adaptation enabled by PSL with multi-server support. 
% At the highest level, all such considerations are further augmented by ad-hoc networking considerations, economic and game theoretic modelling to enable autonomous and automatic cooperative FL, data dispersion via generative modeling or latent diffusion models in order to further preserve/encrypt local data, and rigorous mathematical characterization of differential privacy. 
% % We will now explain each of these aspects in-depth.


%\input{image_staging.tex}