\documentclass[10pt,twocolumn,letterpaper]{article}
\usepackage[rebuttal]{cvpr}

% Include other packages here, before hyperref.
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{multirow}
\usepackage{colortbl}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\definecolor{LightCyan}{rgb}{0.88,1,1}
% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref,breaklinks,colorlinks,bookmarks=false]{hyperref}


\definecolor{mygray}{gray}{0.95}
\definecolor{mypink}{rgb}{.99,.91,.95}
\colorlet{mylightblue}{white!50!blue}
\definecolor{mylightgreen}{rgb}{0, 0.7, 0}



% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}

% If you wish to avoid re-using figure, table, and equation numbers from
% the main paper, please uncomment the following and change the numbers
% appropriately.
%\setcounter{figure}{2}
%\setcounter{table}{1}
%\setcounter{equation}{2}

% If you wish to avoid re-using reference numbers from the main paper,
% please uncomment the following and change the counter for `enumiv' to
% the number of references you have in the main paper (here, 6).
%\let\oldthebibliography=\thebibliography
%\let\oldendthebibliography=\endthebibliography
%\renewenvironment{thebibliography}[1]{%
%     \oldthebibliography{#1}%
%     \setcounter{enumiv}{6}%
%}{\oldendthebibliography}

\input{definitions}


%%%%%%%%% BODY TEXT - ENTER YOUR RESPONSE BELOW
\newcommand{\reviewercomment}[1]{\vspace*{-0.2cm}\noindent\paragraph{#1}}
\newcommand{\question}[1]{\textcolor{red}{#1}}
\newcommand{\comment}[1]{}

\newcommand{\fsnine}[0]{\fontsize{9}{9}\selectfont}
\newcommand{\CO}{\color{black!40!blue}}
\newcommand{\CR}{\color{black!40!red}}


%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\cvprPaperID{5780} % *** Enter the CVPR Paper ID here
\def\confName{CVPR}
\def\confYear{2023}

\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{\vspace{-0.2cm}3Mformer: Multi-order Multi-mode Transformer for Skeletal Action Recognition (Rebuttal)\vspace{-0.4cm}}  % **** Enter the paper title here

\maketitle
\thispagestyle{empty}
\appendix

\noindent We are humbled by very positive, kind and helpful reviews.
%\vspace{-0.1cm}

\vspace{-0.4cm}
\section*{\color{white!30!blue}Assigned Reviewer \#1 (iE2B)}
% \vspace{-0.10cm}

 \vspace{-0.6cm}
\reviewercomment{\color{white!30!blue}1. How are short-term temporal patterns recognized?}$\!\!\!$
A block of $T$ neighbor frames are passed to the MLP unit (lines 369-375). The whole sequence consists of $\tau$ such blocks, each passed separately through the MLP unit (and each joint $1,\cdots,J$). Thus, the MLP only mixes the information from $1,\cdots,T$ frames of a given block/body joint $j$ and captures short-term relations (within-block) of a given 3D body joint (in contrast to between-block relations). The MLP unit input size is  $3T$; 3 due to 3D coordinate). The $\text{MLP}\!:\!\mbr{3T}\!\rightarrow\!\mbr{d}$ contains: FC ($3T\!\rightarrow\!6T$), ReLU, FC ($6T\!\rightarrow\!9T$), ReLU, Dropout, 
FC ($9T\!\rightarrow\!d$). $J$ body joints and $\tau$ blocks are treated as the batch dimension. Feature output size $d$: 100, 150, 420 on NTU60, NTU120, Kinetics.

 \vspace{-0.3cm}
\reviewercomment{\color{white!30!blue}2. Improve Sec. 4. `Joint' in joint-mode similar to body `joints'.}$\!\!\!\!$Duly noted. %By joint-mode we mean jointly modeling two or more modes in the attention mechanism. 
We have revised the text to `coupled-token', `coupled-mode', \etc., added more details, a simple figure for coupling modes and reused Fig. 4 from supp. mat.

\vspace{-0.3cm}
\reviewercomment{\color{white!30!blue}3. Clarify `mode' and `order'.}$\!\!\!$Thank you. In the tensor terminology, a tensor with $m$ modes is a multi-array with $m$ dimensions a.k.a. modes, which can be addressed to access $(i_1,\cdots,i_m)$-th coefficient. The term `order $m$' (or `$m$-th order') indicates that higher order dependencies of some sort are captured, \eg, the $m$-th order hyper-edge in a graph captures association between $m$ nodes instead of node pairs.

\vspace{-0.3cm}
\reviewercomment{\color{white!30!blue}4. Clarify $\sigma(\mathbf{Q}, \mathbf{K})$ and approximation.}$\!\!\!$Indeed, the notation of [1] is rather involved.  As $\mathbf{Q}\!\in\!\mbr{J^n}\!\!\times\! d$,  $\mathbf{K}\!\in\!\mbr{J^m}\!\!\!\times\! d$, $\sigma(\mathbf{Q},\mathbf{K})\!=\!\text{SoftMax}(\mathbf{Q}\mathbf{K}^\top)/Z_j$. We have now provided more details on the approximation for SoftMax attention based on main paper on Eq. (21) in [1] (Kim \etal 2022).

\vspace{-0.3cm}
\reviewercomment{\color{white!30!blue}5. Ablations of MP.} We choose average pooling (avg-pool) and max-pooling (max-pool) for hyper-edge features in comparison to our learned weighted pooling (wei-pool):
\vspace{-0.3cm}
\begin{table}[h!]
\begin{center}
\resizebox{0.9\linewidth}{!}{\begin{tabular}{l c c c c c}
\toprule
\multirow{2}{*}{Pooling}& \multicolumn{2}{c}{NTU-60} & \multicolumn{2}{c}{NTU-120} & Kinetics-Skel.\\
\cline{2-6}
& {X-Sub} & {X-View} & {X-Sub} & {X-Set} & Top-1 acc.\\
\midrule
avg-pool & 91.3 & 96.8 & 86.5 & 89.0 & 41.9\\
max-pool & 92.7 & 98.0 & 88.5 & 91.0 & 43.8\\
\rowcolor{LightCyan} wei-pool ({\it ours}) & 94.8 & 98.7 & 92.0 & 93.8 & 48.3\\
\bottomrule
\end{tabular}}
\label{tab:wp-mp}
\end{center}
\end{table}
\vspace{-1.5cm}

\reviewercomment{\color{white!30!blue}6. Are joint tokens reshaped?}$\!\!\!\!$We reshape/matricize tensor(s) to form  joint-mode tokens with different attention/fo- cus properties. % for the fusion of multi-order features. 
How our tensors are formed is also important.$\!\!\!\!$

%\reviewercomment{7. One typo.} Duly noted, thank you.

 \vspace{-0.4cm}
\section*{\color{orange}Assigned Reviewer \#2 (tnmh)}
% \vspace{-0.10cm}

 \vspace{-0.6cm}
\reviewercomment{\color{orange}1. Why the method works/when does it fail?}$\!\!\!\!$
%
Our method works well as it (i)  uses skeletal hypergraphs of various orders to learn the interaction of varying size groups of skeletal joints (as opposed  to typical skeleton graph physical connectivity), (ii)  fuses groups multiple orders by 3Mformer by several joint-token types via two basic building blocks (MP \& TP) that learn various aspects of higher-order motion dynamics. Multiple-order hyperedges are more resistant to noise (\eg,  Kinetics is noisy due to pose estimation errors), if one body joint is noisy (but the rest is stable). We inject Gaussian noise into 3D {\em ankle} joints, vary noise amplitude:

%\begin{center}
\hspace{-0.5cm}
\vspace{-0.3cm}
\resizebox{\linewidth}{!}{
\setlength{\tabcolsep}{1.5pt}
%\renewcommand{\arraystretch}{0.5}
\begin{tabular}{l | c c c c | l  c c c c}
\toprule
 & original & $\times$ 1 & $\times$ 1.5 & $\times$ 2 & & original & $\times$ 1 & $\times$ 1.5 & $\times$ 2\\
\midrule
ST-GCN & 81.5 &  74.9 (\textcolor{blue}{$\downarrow$6.6}) &  69.2 (\textcolor{blue}{$\downarrow$12.3}) & 50.1 (\textcolor{blue}{$\downarrow$31.4}) & 3Mformer & 94.8 & 91.9 (\textcolor{blue}{$\downarrow$2.9}) & 89.5 (\textcolor{blue}{$\downarrow$5.3}) & 86.8 (\textcolor{blue}{$\downarrow$8.0})\\
\bottomrule
\end{tabular}}
%\end{center}
%\end{table}
%\vspace{-0.5cm}
\vspace{0.05cm}
%As our 3Mformer relies on hyper-edge feature representations, the failure case would be 

\noindent Table  shows 3Mformer copes with noise  better than ST-GCN.$\!\!\!\!$

Our method may underperform if (i)the backbone encoder cannot efficiently produce higher-order features (ii) the number of skeletal joints are very large (the number of hyper-edge features would be very large) (iii) when dataset is too small to learn high-order interactions (extra learnable parameters). For example see results on MSRAction3D:

%\begin{center}
\hspace{0.5cm}
\vspace{-0.3cm}
\resizebox{0.7\linewidth}{!}{\begin{tabular}{l c c c}
\toprule
 acc.  & 73.82 (order 2)  & 63.64 (order  3) & 55.27 (order  4) \\
% \midrule
\bottomrule
\end{tabular}}
%\end{center}
%\end{table}
%\vspace{-0.5cm}

% \vspace{-0.3cm}
\reviewercomment{\color{orange}2. Model complexity (parameter no. \& FLOPs).}$\!\!\!\!$
See  the number of model parameters/FLOPs and NTU-60 accuracy:

%\begin{center}
%\vspace{-0.3cm}
\hspace{-0.5cm}
\resizebox{\linewidth}{!}{\begin{tabular}{l c c c c c c}
\toprule
 & \multirow{2}{*}{ST-GCN} & \multirow{2}{*}{2S-AGCN} & \multirow{2}{*}{NAS-GCN} & 2rd-order & 3rd-order & 3Mformer\\
  &  & & & only ({\it ours}) & only ({\it ours}) & ({\it ours})\\
\midrule
Params (M) & 3.14 & 3.45 & 6.57 & 1.15 & 2.07 & 4.37\\
FLOPs (G) & 16.36 & 37.22 & 108.82 & 6.54 & 35.53 & 58.45\\
Acc. (\%) & 81.5 & 88.5 & 89.4 & 83.0 & 91.3 & {\bf 94.8}\\
\bottomrule
\end{tabular}}
%\end{center}
%\end{table}
%\vspace{-0.3cm}

\vspace{-0.2cm}
\reviewercomment{\color{orange}3. High compute cost.}$\!\!\!\!$ 
Our cost is  moderate. 2S-AGCN (37.22 GFLOPs \& 3.45M param.) yields 89.4\% acc. Our `3rd-order' uses 35.5 GFLOPs \& 2.07M param. which is 2 GFLOPs \& 1.37M param. less, yet we outperform 2S-AGC by \textbf{1.9\%}. NAS-GCN uses 40.4 GFLOPs/2.2M param. more compared to our 3Mformer:  we beat NAS-GCN by \textbf{4.4\%}.

%We politely disagree. Our 2nd-order HoT alone with less learning parameters outperforms most existing GCN-based methods by 1--2\% on average, and our 3rd-order HoT alone achieves very competitive results compared to existing graph-, transformer- and hypergraph-based models for the same or even smaller parameter scale  on 3 benchmarks. Our 3Mformer further boosts the performance by $\sim$ 6\% on average.

%{\color{red}Compare training  speeds per epoch of few methods instead of `disagreeing'.}


\vspace{-0.3cm}
\reviewercomment{\color{orange}4. How many GPUs are used.}$\!\!\!\!$ 
 Similar to CTR-GCN (ICCV'21), Else-Net (ICCV'21) \& InfoGCN (CVPR'22),  our experiments are conducted on 1$\times$ Titan RTX 2090.
 Training 3Mformer on NTU-60 took around 30 hours and the total inference time was around 50s.
% {\color{red} hours per epoch+dataset please.}

\vspace{-0.3cm}
\reviewercomment{\color{orange}5. Compare to recent works (CTR-GCN).}$\!\!\!\!$  Duly noted:
% Our 3Mformer outperforms CTR-GCN by 2.4\% and 1.9\% on NTU-60 X-Sub and X-View respectively, and beats CTR-GCN by 3.1\% and 3.2\% on NTU-120 X-Sub and X-Set respectively.
%Below we show a comparison.
% We will add more recent works into comparison. 

\begin{center}
\vspace{-0.3cm}
\resizebox{\linewidth}{!}{\begin{tabular}{l c c c c c c}
\toprule
 &  Else-Net &  3s-AdaSGN & CTR-GCN &  InfoGCN & PoseConv3D  & 3Mformer\\
  & (ICCV'21) & (ICCV'21) & (ICCV'21) & (CVPR'22) & (CVPR'22) & ({\it ours})\\
\midrule
NTU60 (X-Sub)&  91.6 & 90.5 & 92.4 & 93.0 & 94.1 & {\bf 94.8} \\
NTU120 (X-Sub) & - & 85.9 & 88.9 & 89.8 & 86.9 & {\bf 92.0} \\
Kinetics & - & - & - & - & 47.7 & {\bf 48.3}\\
\bottomrule
\end{tabular}}
\end{center}
%\end{table}

\vspace{-0.6cm}
\reviewercomment{\color{orange}6. 3-rd order hypergraph makes  model  dataset specific.}$\!\!\!\!$ Resp. 1 (AR2) shows that small datasets may be not enough to train high-order models. On key classic large datasets, NTU-60, NTU-120, Kinetics, we did not observe any issue as human motions exhibit similar multi-joint dynamics for typical action classes. Perhaps some fine-grained unusual action classes could pose problems.  On the Northwestern-UCLA dataset (top-1 acc.) our 3Mformer is also effective:

%\begin{center}
\hspace{-0.5cm}
\vspace{-0.3cm}
\resizebox{\linewidth}{!}{\begin{tabular}{l c c c c c}
\toprule
 & CTR-GCN & InfoGCN & 2rd-order & 3rd-order & 3Mformer\\
  &  (ICCV'21) & (CVPR'22) & only ({\it ours}) & only ({\it ours}) & ({\it ours})\\
\midrule
acc.(\%) & 96.5  & 97.0 & 96.5 & {\bf 97.2} & {\bf 97.8}\\
\bottomrule
\end{tabular}}
%\end{center}
%\end{table}
%\vspace{-0.5cm}



\section*{\color{purple}Assigned Reviewer \#3 (TuMu)}
\vspace{-0.6cm}

\reviewercomment{\color{purple}1. Why such complicated  high-order correlations?}$\!\!\!\!$ Thank you, we will of course cite [A] (Peng \etal). Kindly notice our 3Mformer yields 92.0 \% 93.8 on NTU-12 while [A] yields \textbf{80.5\%} \& \textbf{81.7\%} as we explore the fusion of multiple orders of hyperedges and several joint-token types capturing easy-to-complex dynamics of varying joint groups. Kindly also see Resp. 1, 2 \& 3 to AR2.

\vspace{-0.3cm}
\reviewercomment{\color{purple}2. Info on epochs \& hyperparameters.}$\!\!\!\!$ Kindly see line 581--586 (main submission) for learning rates/epochs. We %used 5-fold cross-validation on 
split the train set into 80\% train/20\% val. for hyperparameter tuning. We have now added these details into the draft.%{\color{red} Again, think what more you can provide here. Be proactive and maybe the paper will be oral. If not, it can still get rejected.}

%%%%%%%%% REFERENCES
% {\small
% \bibliographystyle{ieee_fullname}
% \bibliography{egbib}
% }

\end{document}
