% Version 5 being finalized on 01.06.23.
% Major changes in the lemmas and the proofs of the theorems.

% Version 4, based on Version 3, after rejection by ICML.
% The date is 27.04.23.

% Version 2, updated after the CDC submission deadline.
% The date is 07.04.23.

\documentclass[11pt]{article}

% \documentclass[journal,final]{IEEEtran}
% \documentclass[conference]{ieeeconf}
% \IEEEoverridecommandlockouts
% \overrideIEEEmargins

\setlength{\textheight}{225mm}
\setlength{\textwidth}{165mm}
\setlength{\oddsidemargin}{-5mm}
\setlength{\topmargin}{-5mm}

% \setlength{\textheight}{237mm}

% \usepackage{multirow}
% \usepackage{amssymb,amsmath,amsthm}
\usepackage{amssymb,amsmath,amsthm}
\usepackage{latexsym,amsfonts}
\usepackage{color}
\usepackage{graphicx}
%  \graphicspath{{./Figures/}}
  \DeclareGraphicsExtensions{.jpeg,.png,.jpg,.eps,.pdf}
\usepackage{tikz}
\usepackage{epstopdf}
\usepackage{hyperref}

\input{notation.tex}

% Special notation for this paper.

\definecolor{verm}{rgb}{0.6,0.2,0.2}
\definecolor{purp}{rgb}{0.3,0.1,0.6}
\definecolor{purple}{rgb}{0.4,0.0,0.6}
\definecolor{bggreen}{rgb}{0.1,0.3,0.1}
\definecolor{dgreen}{rgb}{0.1,0.6,0.1}
\definecolor{black}{rgb}{0.0,0.0,0.0}
\definecolor{crim}{rgb}{0.3,0.1,0.1}
\definecolor{dred}{rgb}{0.5,0.1,0.1}

\newtheorem{corollary}{Corollary}{\bf}{\it}
\newtheorem{definition}{Definition}{\bf}{\it}
\newtheorem{example}{Example}{\bf}{\rm}
\newtheorem{lemma}{Lemma}{\bf}{\it}
\newtheorem{theorem}{Theorem}{\bf}{\it}
\newtheorem{proposition}{Proposition}{\bf}{\it}
\newtheorem{conjecture}{Conjecture}{\bf}{\it}
\newtheorem{problem}{Problem}{\bf}{\rm}

\begin{document}

\title{
Convergence of Momentum-Based Heavy Ball Method with \\
Batch Updating and/or Approximate Gradients 
% (Dedicated to the Memory of Boris Teodorovich Polyak)
}

\author{Tadipatri Uday Kiran Reddy and M.\ Vidyasagar
\thanks{
TUKR is a Ph.D.\ student at the University of Pennsylvania.
This work was done when he was a final year undergraduate in the
Electrical Engineering Department
at the Indian Institute of Technology Hyderabad, Kandi, Telangana 502284, INDIA.
Email: ukreddy@seas.upenn.edu.
MV is SERB National Science Chair and Distinguished Professor,
Indian Institute of Technology Hyderabad, Kandi, Telangana 502284, INDIA.
Email: m.vidyasagar@iith.ac.in.
This research is supported by the Science and Engineering Research Board (SERB),
India.
The authors thank the Speech Information Processing (SIP) Lab, Indian Institute
of Technology Hyderabad for providing their computational resources.}
}

\date{\today}

\maketitle

\begin{abstract}

In this paper, we study the well-known ``Heavy Ball''
method for convex and nonconvex optimization introduced by
Polyak in 1964, and establish its convergence under
a variety of situations.
Traditionally, most algorithms use ``full-coordinate update,''
that is, at each step, \textit{every component} of the argument is updated.
However, when the dimension of the argument is very high,
it is more efficient to update \textit{some but not all} components of 
the argument at each iteration.
We refer to this as ``batch updating'' in this paper.

When gradient-based algorithms are used together with batch updating,
in principle it is sufficient to compute only those components of the
gradient for which the argument is to be updated.
However, if a method such as backpropagation is used to compute these
components, computing only \textit{some components}
of gradient does not offer much savings over computing
the entire gradient.
Therefore, to achieve a noticeable reduction in CPU usage at each step,
one can use \textit{first-order differences} to approximate the
gradient.
The resulting estimates are \textit{biased}, and also have 
\textit{unbounded variance}.
Thus some delicate analysis is required to ensure that the HB
algorithm converge when batch updating is used instead of full-coordinate
updating, and/or approximate gradients are used instead of true gradients.
% Stating and proving such theorems is the objective of the present paper.
In this paper, we establish the almost sure convergence of the iterations to
the stationary point(s) of the objective function under suitable
conditions; in addition, we also derive upper
bounds on the \textit{rate of convergence.}
To the best of our knowledge, there is no other paper that combines
all of these features.

\textbf{This paper is dedicated to the memory of Boris Teodorovich Polyak}

\end{abstract}

\section{Introduction}\label{sec:Intro}

\subsection{Contributions of the Paper}\label{ssec:11}

In this paper, we study the well-known and widely-used ``Heavy Ball'' (HB)
method for convex and nonconvex optimization introduced by 
Polyak in \cite{Polyak-CMMP64}, and establish its convergence under
a variety of situations.
% ``momentum-based''
% optimization algorithms, namely the Heavy Ball (HB) method due to Polyak
% and the Accelerated Gradient method due to Nesterov \cite{Nesterov-Dokl83}.
% The latter is often referred to as the Nesterov Accelerated Gradient (NAG)
% method.

Let $J : \R^d \ap \R$ denote the $\C^1$ objective function to be
minimized, and let $\bth_t$ denote the estimate for the minimizer
of $J(\cdot)$ at step $t$.
Traditionally, most algorithms use ``full-coordinate update,''
that is, at each step $t$, \textit{every component} of $\bth_t$ is updated.
However, when the dimension $d$ of $\bth_t$ is very high, as it usually is
in problems of deep neural network training and deep reinforcement learning,
it is more efficient to update \textit{some but not all} components of $\bth_t$
at each $t$.
We refer to this as ``batch updating'' in this paper.\footnote{Other 
commonly used phrases are coordinate update, block update, etc.}

When gradient-based algorithms are used together with batch updating,
in principle it is sufficient
to compute the components $[\gJ(\bth_t)]_i$ for 
\textit{only those indices} $i$
for which the $i$-th component of $\bth_t$ is to be updated.
However, if a method such as backpropagation is used to compute these
components, it turns out that computing only \textit{some components}
of gradient does not offer much savings over computing
the entire gradient $\gJ(\bth_t)$.
% is not any more CPU-intensive than computing just some components of
% $\gJ(\bth_t)$.
Therefore, to achieve a noticeable reduction in CPU usage at each step,
one should find a way to estimate the values of $[\gJ(\bth_t)]_i$
for only a few specified indices $i$.
This can be done by using first-order differences to approximate the
gradient.
However, from a mathematical standpoint, the resulting estimates are
\textit{biased}.
Moreover, if the function values used in estimating $[\gJ(\bth_t)]_i$
are corrupted by additive noise, then the estimates of $[\gJ(\bth_t)]_i$
also have \textit{unbounded variance}, in the sense that
the variance grows without bound as $\tai$.
Thus some delicate analysis is required to ensure that the HB 
algorithm converges when batch updating is used instead of full-coordinate
updating, and/or approximate gradients are used instead of true gradients.
% Stating and proving such theorems is the objective of the present paper.

We are now in a position to state the contributions of the present paper.
We study both convex as well as a class of nonconvex objective functions.
We apply stochastic versions of the HB algorithm with batch updating,
and the measurements of $\gJ(\cdot)$ are either noisy or approximate or both.
% We adapt some ideas from \cite{Liu-Yuan-arxiv22}, and not only
We establish the almost sure convergence of the iterations to the
stationary point(s) of the objective function.
In addition, by adapting some ideas from \cite{Liu-Yuan-arxiv22}, we also
derive upper bounds on the \textit{rate of convergence.}
To the best of our knowledge, there is no other paper that combines
all of these features.

\subsection{Comparison with Known Results}\label{ssec:12}

The literature on optimization is vast, and it is not possible
to review it in its entirety.
Given that fact, our review is focused on the papers that are directly
relevant to the specific class of problems studied here.
A more thorough literature survey is found in \cite{MV-TUKR-ICML23}.

First, we describe some important papers that study ``full coordinate update.''
Momentum-based algorithms, which make use of not just the
current gradient and but also past gradients and/or function values,
have been proposed to improve the convergence rates, compared to
simple steepest descent.
These are particularly popular in training deep neural networks.
Some of the pioneering papers include Polyak's Heavy Ball 
\cite{Polyak-CMMP64}, and Nesterov's Accelerated Gradient (NAG) 
\cite{Nesterov-Dokl83, Sutskever-et-al-PMLR13, Bengio-CoRR12}.
Noisy measurements of the gradient can also be used in these methods.
The convergence of these and related algorithms is often established
using the powerful Robbins-Siegmund theorem \cite{Robb-Sieg71}.
Standard assumptions on the objective function include the global
Lipschitz-continuity of the gradient $\gJ(\cdot)$, and in many if
not most cases, the convexity or strict convexity of $J(\cdot)$.
In \cite{Liu-Yuan-arxiv22}, the authors used the Robbins-Siegmund theorem
not only to prove the convergence of various theorems, but also
to bound the rate of convergence to a stationary point; it is one of the
first papers to do so.
However, the present paper makes several advances beyond
\cite{Liu-Yuan-arxiv22}.
First, we allow batch updating, as opposed to full-coordinate updating.
Second, the proof of convergence in \cite{Liu-Yuan-arxiv22} is based on using
a specific class of step size sequences.
In contrast, here we require only the well-known Robbins-Monro conditions
\cite{Robbins-Monro51}.
Third, we permit the use of \textit{approximate gradients} instead of
the true gradients.
This causes the measurement errors to have both nonzero conditional mean
as well as unbounded conditional variance.
We analyze this situation as well, and show (among other things) that
the Robbins-Monro conditions are replaced by a more general set
of conditions introduced in \cite{MV-BASA-arxiv22}.
The class of objective functions are the same as in 
\cite{Khaled-Rich-arxiv20, Bottou-et-al-SIAM18, Mertikopoulos-et-al-arxiv20,
Sebbouh-Gower-Defazio-arxiv20}.
However, these papers
also assume that the errors in gradient measurements have bounded variance.

Next, we come to batch updating (also referred to as Block Coordinate Descent
(BCD)) with noisy measurements.
Batch updating with error-free measurements
has been studied widely with convergence results \cite{Nesterov-SICOPT12,
Richtarik-Takac-MP12, Richtarik-Takac-MP15}.
In \cite{Lu-Xiao-arxiv13}, the authors have
provided a probabilistic convergence result, based
on the Nesterov's framework \cite{Nesterov-SICOPT12}.
The study was limited to smooth convex functions and bounded noise variance.
Stochastic Approximation (SA) \cite{Robbins-Monro51,
Wolf-AOMS52, Borkar-book09, Bottou-et-al-SIAM18} is the key framework
in proving convergence.
% (our work is also based on this framework).
Convergence of batch updating in SGD for nonconvex functions is not studied
much.
In \cite{Xu-Yin-SICOPT15}, the convergence of BCD is proved for
(non-)convex functions
under bounded noise in the measurements.
Batch updating has gained a lot
of attention in  distributed ML \cite{Niu-et-al-arxiv11}, broadly categorized
into two main algorithms: Synchronous SGD (updates are performed
one after another node) \cite{Chen-et-al-iclr16} and Asynchronous SGD (ASGD)
(random updates by any node at any time) \cite{Niu-et-al-arxiv11,
Xie-et-al-ICML20}.
In short, the present paper addresses a combination of
issues that are not found in the existing literature, to the best
of the authors' knowledge.

\section{Problem Formulation and Analysis}\label{sec:Prob}

In this section, we begin by presenting a general class of optimization
algorithms, where the search direction is chosen in a random fashion.
Then we discuss various options for batch updating, and 
relate their conditional expectation and conditional variance to the same
quantities with full-coordinate updating.
The options are applicable to \textit{any} optimization algorithm,
and not restricted to a specific algorithm (Heavy Ball in our case).
Our main convergence proof for the stochastic Heavy Ball algorithm 
with full coordinate update
is given in Section \ref{sec:Main}, and builds on similar results
% These bounds derived here are then combined with the convergence proof 
given in \cite{Liu-Yuan-arxiv22}.
Combined with the results in Section \ref{ssec:33}, this is enough to establish
that the SHB (Stochastic Heavy Ball) algorthm will also converge with each
of three batch updating methods in Section \ref{ssec:33}.

In batch updating, \textit{only some} components of
the search direction $\bphH$ need to be computed at each $t$.
In particular, when $\bphH$ has the form \eqref{eq:321}, then
the exact gradient $\gJ(\bth_t)$ need to be computed at each $t$.
However, in deep neural network training, if a method such as back-propagation
to compute the gradient $\gJ(\bth_t)$, there is virtually no saving in
CPU effort even if \textit{only some but not all} components are
computed at each $t$.
In contrast, if first-order methods are used to \textit{approximate}
the components to be used, then substantial CPU savings will result.
With this in mind, in Section \ref{ssec:34},
we introduce two different approaches to approximating
the exact gradient $\gJ(\bth_t)$ by first-order differences.
The first of these, which we describe as Approach A, is historic and
goes back to \cite{Kief-Wolf-AOMS52,Blum54}.
While the analysis of Approach A is very easy, it is not very efficient.
Specifically, at each instant, Approach A requires $2n_t$ function
evaluations, where $n_t$ is the number of components of $\bth_t$ to be
updated at time $t$.
The second, which we call Approach B, is based on the 
Simultaneous Perturbation Stochastic Approximation (SPSA) introduced in
\cite{Spall-JHU98}.
In SPSA, \textit{only two} function evaluations are required at time step,
irrespective of the value of $n_t$.
However, the analysis is considerably more complicated, and the
\textit{provable} bounds on conditional variance are much larger than in
Approach B.
Having said that, the computational results presented in Section \ref{sec:Num}
show that Approach B requires roughly the same number of iterations 
as Approach A, and also requires far fewer function evaluations.

In this paper, the convergence of the Heavy Ball algorithm with full
coordinate updating is established using the Robbins-Siegmund theorem
\cite{Robb-Sieg71} and a few generalizations thereof.
The contents of the present section can be used with other methods
besides the Heavy Ball method.
The authors believe that \textit{any}
proof that is based on the Robbins-Siegmund theorem
and full coordinate updating can also be made to work with 
batch updating and/or approximate gradients.
Research along these lines is currently under way.

% In principle, the bounds derived here can be applied to other 
% methods as well besides Heavy Ball,
% once convergence with full coordinate update is proved.
% As mentioned above, the computational savings of batch updating are
% best-realized when approximate gradients are used in place of the
% true gradients.

\subsection{General Form of the Algorithm}\label{ssec:32}

% In this subsection, we state the general form of the Stochastic Heavy Ball
% (SHB) algorithm.
% and Stochastic NAG (SNAG) algorithms that are analyzed here.
% For this purpose, it is assumed that 
Suppose the objective function $J(\cdot)$ is $C^1$.
Additional assumptions are given in Section \ref{ssec:41}.
The general form of the algorithm studied in this paper is as follows:
Choose an initial guess $\bth_0 \in \R^d$ (either in a deterministic or
a random fashion).
For $t \geq 0$, choose a denote a random vector $\bphH \in \R^d$,
which is the search direction at time $t+1$, and update $\bth_t$
using the formula
% Both algorithms have the same general form, namely
\be\label{eq:321}
\bth_{t+1} = \bth_t + \al_t \bphi_{t+1} + \mu (\bth_t - \bth_{t-1}) ,
\ee
% where $\bphi_{t+1}$ is an
% $\R^d$-valued random variable, denoting the search direction at time $t$, and
where $\mu \in [0,1)$ is called the ``momentum coefficient,''
and $\al_t$ is the step size at time $t$.
In this paper, it is assumed that $\{ \al_t \}$ is a predetermined
sequence of real numbers; however, because our proof is based on an
extension of the Robbins-Sigmund theorem, the theory remains valid
even with random step sizes.
Define $\bth_0^t := ( \th_0 , \cdots , \th_t )$, and similarly
$\bphi_1^t := ( \phi_1 , \cdots , \phi_t )$.
(Note that there is no $\bphi_0$.)
% Also, for the moment we omit the superscripts ``HB'' and ``NAG'' for clarity.)
Suppose that all of these are random variables on some underlying
probability space $(\OM , \SI , P)$.\footnote{The reader is referred to
\cite{Durrett19} for all concepts related to stochastic processes,
conditional expectations, etc.}
Let $\{ \F_t \}$ denote any \textbf{filtration}, that is,
an increasing sequence of $\s$-algebras satisfying $\F_t \seq
\F_{t+1} \seq \SI$, such that $\bth_0^t, \bphi_1^t$ are measurable
with respect to $\F_t$, denoted by $\bth_1^t , \bphi_1^t \in \M(\F_t)$.
Further, if $X \in \R^d$ is a random vector, let $E_t(X)$ be a shorthand for
$E( X | \F_t )$, the conditional expectation of $X$ with respect to $\F_t$,
and $CV_t(X)$ denote the conditional variance of $X$, that is
\bd
CV_t(X) := E_t( \nmeusq{ X - E_t(X) } ) .
\ed

% Setting $\mu = 0$ leads to the standard
% stochastic gradient descent algorithm with full coordinate updating, where
% it is customary to assume that
In the conventional Heavy Ball method, one chooses
\be\label{eq:322}
\bphH = - \gJ(\bth_t) +\bzeta_{t+1} ,
\ee
% \be\label{eq:322a}
% \bphN = - \gJ(\bth_t + \mu( \bth_t - \bth_{t-1} ) ) +\bxi_{t+1} ,
% \ee
where $\bzeta_{t+1}$ is a measurement error with $E_t(\bzeta_{t+1}) = \bz$.
Thus $\bphH$ is a noise-corrupted  but unbiased measurement of $- \gJ(\bth_t)$.
Further, if we set $\mu = 0$, then we get the stochastic gradient descent (SGD)
algorithm.
However, throughout this paper, we \textit{do not assume} that $\bphH$
has the form \eqref{eq:322}, in the interests of achieving greater generality.
% while $\bphN$ is a noise-corrupted  measurement of
% $- \gJ(\bth_t + \mu( \bth_t - \bth_{t-1} )$.

% However, when one applies batch updating and/or uses approximate
% gradients instead of the (noise-corrupted) true gradient,
% \eqref{eq:322} does not hold in general.
% and \eqref{eq:322a} do 
% To cater to this more general situation, we proceed as follows:
% Let $\bth_0^t := ( \th_0 , \cdots , \th_t )$, and similarly
% $\bphi_1^t := ( \phi_1 , \cdots , \phi_t )$.
% (Note that there is no $\bphi_0$.)
% Also, for the moment we omit the superscripts ``HB'' and ``NAG'' for clarity.)
% Suppose that all of these are random variables on some underlying
% probability space $(\OM , \SI , P)$.\footnote{The reader is referred to
% \cite{Durrett19} for all concepts related to stochastic processes,
% conditional expectations, etc.}
% Let $\{ \F_t \}$ denote any \textbf{filtration}, that is,
% an increasing sequence of $\s$-algebras satisfying $\F_t \seq
% \F_{t+1} \seq \SI$, such that $\bth_0^t, \bphi_1^t$ are measurable
% with respect to $\F_t$, denoted by $\bth_1^t , \bphi_1^t \in \M(\F_t)$.
% Further, let $E_t(X)$ be a shorthand for
% $E( X | \F_t )$, the conditional expectation of $X$ with respect to $\F_t$.

% With this notational convention, our stochastic
% algorithm is once again given by
% \eqref{eq:321}, where $\bphi_{t+1}$ is as yet unspecified
% to permit greater generality.
% Define
% To differentiate between SHB and SNAG, we define

\subsection{Types of Batch Updating Considered}\label{ssec:33}

Let $\bphH$ denote a generic search direction.
The updating method described in \eqref{eq:321} is then the
full coordinate update option.
We refer to it as ``Option 1.''
In batch updating, the rule \eqref{eq:321} is applied to \textit{some
but not necessarily all} components of $\bth_{t+1}$.
Unless this is done with some care, technical difficulties can arise.
With this in mind,
we describe three different options for batch updating,
which we call single coordinate, multiple coordinate, and Bernoulli updates.
These are called Options 2, 3 and 4, and are denoted by
$\bphH^{(k)}$ for $k = 2 , 3 , 4$.
These updating schemes
include most if not all of the widely used batch updating methods.
In each of these options, while the search direction is random, the
\textit{conditional expectation}
of the update direction is the same as in Option 1.
In symbols, $E_t(\bphH^{(k)}) = E_t(\bphH^{(1)})$ for $k = 2 , 3 , 4$.
In Lemma \ref{lemma:31}, we relate the conditional variance of
$\bphH^{(k)}$ to $\bphH^{(1)}$.
Because $\bphH$ can be \textit{any} random vector, Lemma \ref{lemma:31}
can be applied not only to the various options for search directions discussed 
in the paper, but to other situations as well.

% that are studied in the paper.

% In addition, we also describe variants of each of these options, when
% the noise-corrupted
% true gradient is replaced by a first-order approximation, commonly
% referred to as Simultaneous Perturbation Stochastic Approximation (SPSA)
% \cite{Spall-JHU98}. We refer to these variations of the basic HB algorithm
% as Stochastic Heavy Ball (SHB).
% By choosing the search direction appropriately, we can recover batch
% updating versions of SHB and SNAG.
% Four different options are prescribed, as denoted by superscripts.
% Some of the content here, except for SPSA, is taken from
% \cite{MV-TUKR-ICML23}, and the reader is referred to that source
% for further details.
Throughout, the symbol $\bphi_{t+1}$ denotes the search direction
in \eqref{eq:321}.
We now describe Options 1 through 4 for batch  updating.

\textbf{Option 1: Full Coordinate Update:}
Let
\be\label{eq:331}
\bphi^{(1)}_{t+1} = \bphi_{t+1} .
\ee

\textbf{Option 2: Single Coordinate Update:}
This option is also known as ``coordinate gradient descent'' as defined in
\cite{Wright15} and studied further in \cite{Bach-et-al-aisats19}.
(However, those papers study only the steepest descent method and not 
its variants, such as SHB).
At time $t$, choose an index $\kappa_t \in [d]$ at random with a
uniform probability, and independently of previous choices.
Let $\eb_{\kappa_t}$ denote the elementary unit vector with a $1$
as the $\kappa_t$-th component and zeros elsewhere,
and let $\bzeta_{t+1}$ denote the measurement noise as in \eqref{eq:324}.
Then define
\be\label{eq:332}
\bphi^{(2)}_{t+1} = d \eb_{\kappa_t } \circ \bphi_{t+1} ,
\ee
where $\circ$ denotes the Hadamard, or component-wise, product of two
vectors of equal dimension.
The factor of $d$ arises because the likelihood that $\kappa_t$
equaling any one index $i \in [d]$ is $1/d$.

\textbf{Option 3: Multiple Coordinate Update:}
This option is just coordinate update along multiple
coordinates chosen independently at random.
At time $t$, choose $N$ different indices $\kappa_t^n$ from $[d]$
\textit{with replacement}, with each choice being independent of the rest,
and also of past choices.
Moreover, each $\kappa_t^n$ is chosen from $[d]$ with uniform probability.
Then define
\be\label{eq:333}
\bphi^{(3)}_{t+1} := \frac{d}{N} \sum_{n=1}^N \eb_{\kappa_t^n}
\circ \bphi_{t+1} .
\ee
Because sampling is with replacement, the likelihood
of an index $i \in [d]$ getting selected for updating at least once
is $N/d$; so the muiltiplicative factor in \eqref{eq:333} is the
reciprocal of this likelihood.
In this option, $\bphi^{(3)}_{t+1}$ can have \textit{up to} $N$ nonzero
components.
Because the sampling is \textit{with replacement}, there might
be some duplicated samples.
In such a case, the corresponding component of $\bphi_{t+1}$ simply
gets counted multiple times in \eqref{eq:333}.

\textbf{Option 4: Bernoulli Update:}
At time $t+1$, let $\{ B_{t+1,i}, i \in [d] \}$  be independent Bernoulli
processes with success rate $\r_{t+1}$.
Thus
\be\label{eq:334}
\Pr \{ B_{t+1,i} = 1 \} = \r_{t+1} , \fa i \in [d] .
\ee
It is permissible for the success probability $\r_{t+1}$ to vary with time.
However, at any one time, all components must have the same success
probability.
Then define
\be\label{eq:335}
\v_{t+1} := \sum_{i=1}^d \eb_i I_{ \{ B_{t+1,i} = 1 \} }  \in \bi^d .
\ee
Thus $\v_{t+1}$ is a random vector, and
$v_{t+1,i}$ equals $1$ if $ B_{t+1,i} = 1$, and equals $0$ otherwise.
Now define
\be\label{eq:336}
\bphi^{(4)}_{t+1} = \frac{1}{\r_{t+1}}  \v_{t+1} \circ \bphi_{t+1} .
\ee
Note that, as with the other options,
the factor $1/\r_t$ is the reciprocal of the likelihood of
a particular $i \in [d]$ being selected for updating.
However, there is no \textit{a priori} upper bound
on the number of nonzero components of $\bphi^{(4)}_{t+1}$;
the search direction $\bphi^{(4)}_{t+1}$ can have up to $d$ nonzero components.
But the \textit{expected} number of nonzero components is $\r_{t+1} d$.

When the choice of the batch update direction involves some
random choices (such as $\kappa_t^n$ or $B_{t+1,i}$), the filtration
$\{ \F_t \}$ is chosen in such a way that all of these random variables
are also measurable with respect to $\F_t$, in addition to $\bth_0^t$
and $\bphi_1^t$.
% Then the key point is this: In all four options,
% \be\label{eq:340a}
% E_t(\bphi^{(n)}_{t+1}) = E_t(\bphi_{t+1}) , n = 1 , \cdots , 4 .
% \ee

The objectives of Lemma \ref{lemma:31} below are: (i) to show that
all the four search directions have the same conditional expectation,
and (ii) to relate the conditional
variance of Options 2, 3, and 4 to that of Option 1.
Subsequent lemmas do the same for Approaches A and B.

\begin{lemma}\label{lemma:31}
% As in \eqref{eq:322}, define
We have that
\be\label{eq:340}
E_t(\bphi^{(k)}_{t+1} ) = E_t(\bphH^{(1)}) , k = 2 , 3 , 4 .
\ee
Moreover,
\be\label{eq:341}
\begin{split}
CV_t( \bphi^{(2)}_{t+1} ) &= (d-1) \nmeusq{E_t(\bphH^{(1)})} + d CV_t(\bphH^{(1)}) , \\
% (d-1) E_t( \nmeusq{\bphH^{(1)}} ) , \\
CV_t( \bphi^{(3)}_{t+1} ) &= (d-1) \nmeusq{E_t(\bphH^{(1)})} + d CV_t(\bphH^{(1)}) , \\
% (d-1) E_t( \nmeusq{\bphH^{(1)}} ) , \\
CV_t( \bphi^{(4)}_{t+1} ) &=
% E_t ( \nmeusq{ \bphi^{(4)}_{t+1} - \w_t } ) =
% \frac{1 - \r_t} {\r_t} E_t( \nmeusq{\bphH^{(1)}} ) .
\frac{1-\r_{t+1} }{\r_{t+1} } E_t( \nmeusq{\bphH^{(1)}} )
+ \frac{1}{\r_{t+1} } CV_t(\bphH^{(1)}) .
\end{split}
\ee
\end{lemma}

\textbf{Remark:}
Any random variable $X \in \R^d$ can be decomposed as $E_t(X) + Y$,
where $E_t(Y) = \bz$.
Hence
\bd
E_t(\nmeusq{X}) = \nmeusq{ E_t(X) } + E_t(\nmeusq{Y})
= \nmeusq{ E_t(X) } + CV_t(X) .
\ed
Thus the conclusions of the lemma can be stated equivalently as
\be\label{eq:341a}
\begin{split}
E_t(\nmeusq{ \bphH^{(2)} } ) = d [ \nmeusq{ E_t( \bphH^{(1)} ) }
+ CV_t( \nmeusq{\bphH^{(1)}} ) ] = d E_t( \nmeusq{\bphH^{(1)}} ) , \\
E_t(\nmeusq{ \bphH^{(3)} } ) = d [ \nmeusq{ E_t( \bphH^{(1)} ) }
+ CV_t( \nmeusq{\bphH^{(1)}} ) ] = d E_t( \nmeusq{\bphH^{(1)}} ) \\
E_t(\nmeusq{ \bphH^{(4)} } ) = \frac{1}{\r_{t+1} }
[ \nmeusq{ E_t( \bphH^{(1)} ) } + CV_t( \nmeusq{\bphH^{(1)}} ) ]
= \frac{1}{\r_{t+1} } E_t( \nmeusq{\bphH^{(1)}} ) .
% + \frac{1 - \r_t} {\r_t} CV_t( \nmeusq{\bphH^{(1)}} ) .
\end{split}
\ee

This way of stating the identities makes it clear that they hold for
\textit{arbitrary} search directions $\bphH^{(1)}$.

\begin{proof}
Recall that $\bphH^{(1)} = \bphH$.
For notational convenience, define
\be\label{eq:324}
\w_t = E_t ( \bphi_{t+1} ) ,
\bzeta_{t+1} := \bphi_{t+1} - E_t ( \bphi_{t+1} )
= \bphi_{t+1} - \w_t .
\ee
From the ``tower'' property of conditional expectations
(see \cite{Williams91}), it follows that\footnote{Hereafter
we omit the phrase ``almost surely'' almost everywhere.}
\be\label{eq:325}
E_t(\bzeta_{t+1}) = \bz \as, \fa t .
\ee
From this, it is obvious that \eqref{eq:340} is satisfied.
Therefore, to compute the conditional varance of $\bphi^{(k)}_{t+1}$,
it is necessary to compute the residual $\nmeusq{\bphi^{(k)}_{t+1} ) - \w_t}$,
and then take its conditional expectation.

\textbf{Option 2:}
Suppose that $\kappa_t = i$.
Then
\bd
\phi^{(2)}_{t+1,j} = \left\{ \ba{ll}
d ( w_{t,i} + \zeta_{t+1,i} ) , & \mbox{if } j = i , \\
0, & \mbox{if } j \neq i , \ea \right.
\ed
\bd
\phi^{(2)}_{t+1,j} - w_{t,j} = \left\{ \ba{ll}
(d-1) w_{t,i} + d \zeta_{t+1,i} , & \mbox{if } j = i , \\
- w_{t,j} , & \mbox{if } j \neq i , \ea \right.
\ed
Therefore, conditioned on the event $\kappa_t = i$, we have that
\bd
\sum_{j=1}^d ( \phi^{(2)}_{t+1,j} - w_{t,j} )^2 = \sum_{i=1}^d
\left[ (d-1)^2 w_{t,i}^2 + d^2 \zeta_{t+1,i}^2
+ \sum_{j\neq i} w_{t,j}^2 \right] + CPT ,
\ed
where ``CPT'' stands for ``Cross Product Term'' involving a product
of some component of $\w_t$ and some component of $\bzeta_{t+1}$.
Since each of the events $\kappa_t = i$ occurs with probability $1/d$,
it follows that the average value is given by
\begin{eqnarray*}
\nmeusq{ \bphi^{(2)}_{t+1} - \w_t} & = & 
\frac{1}{d} \sum_{i=1}^d \left[ (d-1)^2 w_{t,i}^2 + d^2 \zeta_{t+1,i}^2
+ \sum_{j\neq i} w_{t,j}^2 \right] + CPT \\
& = & \left[ \frac{(d-1)^2 + (d-1)}{d} \right] \sum_{i=1}^d
w_{t,i}^2 + d \sum_{i=1}^d \zeta_{t+1,i}^2 + CPT \\
& = & (d-1) \nmeusq{ \w_t } + d \nmeusq{ \bzeta_{t+1} } + CPT .
\end{eqnarray*}
Now, when we take $E_t(\cdot)$ of this quantity,
the conditional expectations of all cross-product terms vanish, leaving
\bd
E_t( \nmeusq{ \bphi^{(2)}_{t+1} - \w_t} )
= (d-1) \nmeusq{\w_t} + d E_t( \nmeusq{\bzeta_{t+1} } ) .
% = E_t( \nmeusq{ \bphH^{(1)} } ) .
\ed
This gives the first equation in \eqref{eq:341}.

\textbf{Option 3:}
Observe that $\bphi_{t+1}$ is the average of $N$ different quantities
wherein the error terms $\bzeta_{t+1}^n , n \in [N]$ are independent.
Therefore their variances just add up, giving the middle equation in
\eqref{eq:341}.

\textbf{Option 4:}
For notational simplicity, we just use $\r$ in the place of $\r_{t+1}$.
In this case, each component $\phi_{t+1,i}$ equals
% $- (1/\r) ( \gJ(\bth_t)_i + \zeta_{t+1,i} )$
$ (1/\r) ( w_{t,i} + \zeta_{t+1,i} )$
with probability $\r$, and $0$ with probability $1-\r$.
Thus $\phi_{t+1,i} - w_{t,i}$ equals $((1/\r)-1) w_{t,i} + 
(1/\r) \zeta_{t+1,i}$ with probability $\r$,
and $- w_{t,i}$ with probability $1-\r$.
As can be easily verified, the conditional variance is
$((1-\r)/\r)w_{t,i}^2 + (1/\r)E_t(\zeta_{t+1,i}^2))$ for each component.
As the Bernoulli processes for each component are mutually independent,
the variances simply add up.
It follows that
\bd
CV_t( \bphi^{(4)}_{t+1} ) = \frac{1-\r}{\r} \nmeusq{\w_t} 
+ \frac{1}{\r} E_t( \nmeusq{\bzeta_{t+1} } ) ,
\ed
which is the bottom equation in \eqref{eq:341}.
\end{proof}

\subsection{Types of Approximate Gradients Considered.}\label{ssec:34}

% \textbf{Options 1A through 4A:}
In the traditional stochastic gradient descent or stochastic Heavy Ball methods,
the random search direction $\bphH$ has the form \eqref{eq:322},
where, as before, $\gJ(\bth_t)$ denotes the gradient.
In this subsection,
we introduce Options 1A through 4A, wherein the true gradient
$\gJ(\bth_t)$ is replaced by a first-order approximation.
As mentioned above, Option 1A originated in \cite{Kief-Wolf-AOMS52,Blum54},
while Options 2A, 3A and 4A consist of applying single-coordinate updating,
multiple coordinate updating, and Bernoulli updating, to the
search direction $\bphH^{(1A)}$.
The ``A'' options are included purely in the interests
of historical completeness, as they are not as efficient as Options 1B
through 4B, which require only two function evaluations per iteration.

% To introduce these various options, recall from \eqref{eq:324} that
% $\w_t = \bphH$ and $\bzeta_{t+1} = \bphH - \w_t$.
% Now we define
% \be\label{eq:326}
% \phH := \w_t + \gJ(\bth_t) .
% \ee
% Note that $\phH \in \M(\F_t)$.
% The idea is that when $\bphH = \gJ(\bth_t) + \bzeta_{t+1}$,
% (that is, the stochastic gradient descent or stochastic Heavy Ball
% algorithms), we have that $\phH = \bz$.
% However, when approximate gradients are used, this is not necessarily true.
% With the definition \eqref{eq:326}, it follows from \eqref{eq:324} that
% \bd
% \bphi_{t+1} = \w_t + \bzeta_{t+1} = \phH - \gJ(\bth_t) + \bzeta_{t+1} .
% \ed
% Thus, in the stochastic gradient descent algorithm,
% we would have $\phH = \bz$ almost surely.
% However, no such assumption is made here, to accommodate the use of
% approximate gradients in the general formulation \eqref{eq:321}.

To introduce Options 1A through 4A, we proceed as follows:
Let $\{ c_t \}$ be a predetermined sequence of ``increments,''
not to be confused with the step size sequence $\{ \al_t \}$,
and let $\eb_i \in \R^d$ denote the $i$-th unit vector, with a $1$
in the $i$-th location and zeros elsewhere.
Suppose $\bxi_{t+1}^- , \bxi_{t+1}^+$ are measurement errors that are
independent of each other, and satisfy
\be\label{eq:328}
E( \bxi_{t+1}^- | \F_t ) = \bz \fa t ,
E( \bxi_{t+1}^+ | \F_t ) = \bz \fa t ,
\ee
% Moreover, each of these is assumed to be independent of $\bzeta_{t+1}$
% in \eqref{eq:324}.
At each time $t+1$, define the approximate gradient
$\gbold_{t+1}^{(A)} \in \R^d$ componentwise, by
\be\label{eq:327}
g_{t+1, i}^{(A)} =
\frac{ [ J(\bth_t + c_t \eb_i) + \xi_{t+1,i}^+ ]
- [ J(\bth_t - c_t \eb_i) + \xi_{t+1,i}^- ] } {2 c_t } , i \in [d] .
\ee
% Rewrite  $\y_{t+1}^{(A)}$ as
% \be\label{eq:329}
% \y_{t+1}^{(A)} = - \y_t^{(A)} + \frac{\bxi_t^- - \bxi_t^+ }{2c_t} 
% = - \left( \y_t^{(A)} + \frac{\bxi_{t+1}^{(A)}} {c_t} \right) ,
% \ee
% where
If we define $\y_t , \bxi_{t+1}$ componentwise via
\be\label{eq:3210}
y_{t,i}^{(A)} = \frac{J(\bth_t + c_t \eb_i) - J(\bth_t - c_t \eb_i)}{2 c_t } ,
\fa i \in [d] ,
\ee
\be\label{eq:3211}
\xi_{t+1,i}^{(A)} = \half (\xi_{t+1}^+ - \xi_{t+1}^- ) , i \in [d] ,
\ee
then
\be\label{eq:3211a}
\gbold_{t+1}^{(A)} = \y_t + \frac{\bxi_{t+1}^{(A)} }{c_t}  .
\ee
Note that $\y_t^{(A)}$ is deterministic and belongs to $\M(\F_t)$.
Also, $E_t( \bxi_{t+1}^{(A)} ) = \bz$.
Hence $E_t(\gbold_{t+1}^{(A)}) = \y_t$.

With these definitions, Option 1A consists of defining
% replacing $\gJ(\bth_t)$
% in \eqref{eq:326} by $-\gbold_{t+1} = - ( \y_t^{(A)}  + \bxi_{t+1}/c_t$ ).
% Thus
\be\label{eq:3211b}
\bphH^{(1A)} := - \gbold_{t+1} =
% \bphit + \y_{t+1} + \bzeta_{t_1} 
% \bphit - \y_t^{(A)} - \frac{\bxi_{t+1}} {c_t} + \bzeta_{t+1} .
- \y_t^{(A)} - \frac{\bxi_{t+1}} {c_t} .
\ee
Comparing \eqref{eq:3211b} with \eqref{eq:322} shows that
we have replaced $-\gJ(\bth_t)$ by $-\y_t^{(A)}$ and
$\bzeta_{t+1}$ by $-\bxi_{t+1}/c_t$.
Options 2A, 3A and 4A then consist of applying single coordinate update,
multiple coordinate update, and Bernoulli update, to $\bphH^{(1A)}$.
% 
% With these definitions, it follows that all of these options have the
% same conditional expectation, that is,
% \bd
% E_t( \bphH{(kA)}) = \bphit - \y_t^{(A)} , k = 1 , 2, 3, 4 .
% \ed
% Note that it is \textit{not true in general} that $\y_t^{(A)}
% = - \gJ(\bth_t)$.
% However, it is easy to see that $\nmeu{\y_t^{(A)} + \gJ(\bth_t)} = O(c_t)$.

Now we prove a result analogous to Lemma \ref{lemma:31} for Options
1A through 4A.

\begin{lemma}\label{lemma:34}
Define $\w_t^A := E_t( \bphH^{(1A)} ) = \y_t^{(A)}$.
Then
% As with Options 1 through 4, all the entities $\bphH^{(kA)}$ for 
% $k = 1 , 2, 3, 4$ all have the same conditional mean.
% So we can define
\be\label{eq:3211a}
E_t( \bphH^{(kA)} )  = \w_t^A  , k = 2 , 3 , 4 .
\ee
% With the above definition, we have that
Also
\be\label{eq:3212}
% \nmeu{ \w_t^A - \phH} 
\nmeu{ \w_t^{(A)} + \gJ(\bth_t)} \leq \frac{\sqrt{d} L c_t}{2} .
\ee
% Next, define
% \be\label{eq:3213}
% \ee
Moreover
\be\label{eq:3214a}
CV_t( \bphH^{(1A)} ) = \frac{ CV_t( \nmeusq{ \bxi_{t+1}} ) }{c_t^2} , 
\ee
% \frac{ E_t ( \nmeusq{\bxi_{t+1}} ) }{c_t^2} , \\
\be\label{eq:3214}
\begin{split}
CV_t( \bphH^{(2A)} ) &= (d-1) \left[ \nmeusq{\w_t^A} 
+ \frac{ CV_t( \nmeusq{ \bxi_{t+1}} ) }{c_t^2} 
\right] = (d-1) E_t( \nmeusq{ \bphH^{(1A)} } ) , \\
% (d-1) \frac{ E_t ( \nmeusq{\bxi_{t+1}} ) }{c_t^2}  , \\
CV_t( \bphH^{(3A)} ) &= (d-1) \left[ \nmeusq{\w_t^A} 
+ \frac{ CV_t( \nmeusq{ \bxi_{t+1}} ) }{c_t^2} 
\right] = (d-1) E_t( \nmeusq{ \bphH^{(1A)} } ) , \\
% (d-1) \frac{ E_t ( \nmeusq{\bxi_{t+1}} ) }{c_t^2}  , \\
CV_t( \bphH^{(4A)} ) &= \frac{1-\r_t}{\r_t}
\left[ \nmeusq{\w_t^A} 
+ \frac{ CV_t( \nmeusq{ \bxi_{t+1}} ) }{c_t^2} 
\right] = \frac{1-\r_t}{\r_t} E_t( \nmeusq{ \bphH^{(1A)} } ) .
% \frac{(1-\r_t)}{\r_t} \frac{ E_t ( \nmeusq{\bxi_{t+1}} ) }{c_t^2}  .
\end{split}
\ee
\end{lemma}

\begin{proof}
% It folllows from \eqref{eq:326} and \eqref{eq:3211b} that
% \bd
% \w_t^A = \phH - \y_t^{(A)} , \w_t = \phH + \gJ(\bth_t).
% \ed
% Therefore
% \bd
% \w_t^A - \w_t = \y_t^{(A)} - \gJ(\bth_t) .
% \ed
We adapt the proof of \cite[Eq.\ (2.40)]{Ber-Tsi-SIAM00} to the present
situation.
In particular,
\begin{eqnarray*}
y_{t,i}^{(A)} & = & \frac{1}{2c_t} [ J(\bth_t + c_t \eb_i) - J(\bth_t - c_t \eb_i) ]\\
& = & \frac{1}{2c_t} \int_{-1}^1 \frac{d}{d\l} J( \bth_t + \l c_t \eb_i)
\; d \l \\
& = & \frac{1}{2c_t} \int_{-1}^1 c_t [ \gJ( \bth_t + \l c_t \eb_i)  ]_i
\; d \l \\
& = & \half \int_{-1}^1 \left\{ [ \gJ(\bth_t) ]_i
+ [ \gJ( \bth_t + \l c_t \eb_i)  - \gJ(\bth_t) ]_i \right\} \; d \l \\
& = & \half \int_{-1}^1 \gJ(\bth_t) ]_i \; d \l
+ \half \int_{-1}^1 [ \gJ( \bth_t + \l c_t \eb_i)  - \gJ(\bth_t) ]_i \; d \l .
\end{eqnarray*}
The first term is just $[ \gJ(\bth_t) ]_i$.
As for the second term, we have the bound
\bd
\half \left| \int_{-1}^1 [ \gJ( \bth_t + \l c_t \eb_i)  - \gJ(\bth_t) ]_i
\; d \l \right| \leq \frac{Lc_t} {2} \int_{-1}^1 |\l| \; d \l
= \frac{L c_t}{2} .
\ed
Therefore
\bd
| y_{t,i}^{(A)} - [ \gJ(\bth_t) ]_i | \leq \frac{L c_t}{2} , \fa i \in [d] ,
\ed
\bd
\nmeu{\y_t^{(A)} - \gJ(\bth_t)} \leq \frac{\sqrt{d} L c_t}{2} .
\ed
This proves \eqref{eq:3212}.

% Next, recall that
% \bd
% \bphH^{(1A)} = \bphit - \y_t^{(A)} - \frac{\bxi_{t+1}} {c_t} + \bzeta_{t+1} 
% = \w_t^A - \frac{\bxi_{t+1}} {c_t} + \bzeta_{t+1} .
% \ed
% Since $\w_t^A \in \M(\F_t)$, and $\bxi_{t+1}, \bzeta_{t+1}$
% are conditionally independent given $\F_t$, it readily follows that
% \bd
% CV_t( \bphH^{(1A)} ) =
% \frac{ CV_t( \nmeusq{ \bxi_{t+1}} ) }{c_t^2} + CV_t( \nmeusq{\bzeta_{t+1}} ) .
% \ed
The remaining relationships in \eqref{eq:3214} now follow as in the
proof of Lemma \ref{lemma:31}.
\end{proof}

Next, we introduce Options 1B through 4B, which are based on the
Simultaneous Perturbation Stochastic Approximation (SPSA) approach
proposed in \cite{Spall-JHU98}.
To define the various options, for all indices $i \in [d]$,
we next define the quantity
\be\label{eq:337}
g_{t+1,i}^{(B)} = \frac{[ J(\bth_t + c_t \bD_{t+1}) + \xi_{t+1,i}^+ ]
- [ J(\bth_t - c_t \bD_{t+1}) - \xi_{t+1,i}^- ] } {2 c_t \D_{t+1, i}} ,
\ee
where $\D_{t+1,i}, i \in [d]$ are $d$ different and pairwise
independent \textbf{Rademacher variables}.\footnote{Recall that Rademacher
random variables assume values in $\bp$ and are independent of each other.}
Moreover, it is assumed that $\D_{t+1,i} , i \in [d]$ are all independent
of the filtration $\F_t$.
The measurement errors  $\xi_{t+1,1}^+ , \cdots , \xi_{t+1,d}^+$,
$\xi_{t+1,1}^- , \cdots , \xi_{t+1,d}^-$ represent the measurement errors.
It is assumed that these $2d$ random variables are pairwise independent
with zero conditional expectation with respect to $\F_t$,
and are also independent of $\D_{t+1,j}$ for each $j \in [d]$.
If we define
\be\label{eq:337a}
% Let $\y_{t}$ be defined as
y_{t+1, i}^{(B)} := \frac{J(\bth_t + c_t\bD_{t+1}) - J(\bth_t - c_t\bD_{t+1})}
{2c_t\D_{t+1,i}} ,
\ee
\be\label{eq:337b}
\xi_{t+1,i}^{(B)} := \frac{\xi_{t+1,i}^+  - \xi_{t+1,i}^- } {2 \D_{t+1, i}} ,
\ee
then one can express
\be\label{eq:337c}
\gbold_{t+1}^{(B)} = \y_{t+1}^{(B)} + \frac{\bxi_{t+1}^{(B)}}{c_t } .
\ee
% Moreover, to first-order in $c_t$, $\y_{t+1}$ is an approximation to 
% $\gJ(\bth_t)$.
The assumptions about the measurement errors lead to 
\bd
E_t(\bxi_{t+1}^{(B)}) = \bz .
\ed
% In the interests of simplicity, it is assumed that $\bxi_{t+1}$ is
% the only source of measurement error in computing $\gbold_{t+1}$.

With these definitions, Option 1B consists of defining
\be\label{eq:337d}
\bphi^{(1B)}_{t+1} := - \gbold_{t+1}^{(B)}
% \phH - \gbold_{t+1}^{(B)} + \bzeta_{t+1} 
= - \left( \y_{t+1}^{(B)} + \frac{\bxi_{t+1}^{(B)}}{c_t } \right) .
\ee
% In other words, Option 1B consists of replacing the true gradient
% $-\gJ(\bth_t)$ in \eqref{eq:326} by $\gbold_{t+1}^{(B)}$.
Once we define $\bphi^{(1B)}_{t+1}$, we can apply each of the three
batch updatings to it, namely single coordinate, multiple coorinate,
and Bernoulli.
These are referred to as Options 2B, 3B and 4B.
% Note that there are two measurement error terms in \eqref{eq:337d},
% namely $\bzeta_{t+1}$ and $\bxi_{t+1}^{(B)}/(2c_t)$.
% In actual applications, it is reasonable to assume that $\bzeta_{t+1} = \bz$,
% so that $\bxi_{t+1}/(2c_t)$ is the only error term.
% However, in the interests of generality, we retain the term $\bzeta_{t+1}$.

A major difference between the Class A options and the Class B options is this:
In the Class A options, we have that $\y_t^{(A)} \in \M(\F_t)$.
Hence the conditional variance $CV_t(\bphH^{(1A)})$ arises solely
from the term $\bxi_{t+1}/c_t$.
In contrast, in the Class B options,
it is \textit{not true in general} that $\y_{t+1}^{(B)} \in \M(\F_t)$.
This is because the Rademacher variables $\D_{t+1,i}$ are defined at time $t+1$.
Hence $\y_{t+1}^{(B)}$ also contributes to  $CV_t(\bphH^{(1B)})$.
This makes the analysis more complicated compared to the Class A options.
% This is in contrast to Option 1A, where $\y_t^{(A)} \in \M(\F_t)$.

% where $\bxi_{t+1}^- , \bxi_{t+1}^+$ are measurement errors.
% Once we define the above ``approximate'' search directions, we can

It is possible to use other probability distributions for $\bD$.
For instance, in \cite{Nesterov-Spokoiny-FCM15}, the perturbations
$\D_{t+1,i}$ are assumed to have Gaussian distributions.
Note that, if $\D_{t+1,i}$ are binary, then $\nmeu{\bD_{t+1}} = \sqrt{d}$,
and as a result,
\be\label{eq:339}
\frac{ \nmeu{\bD_{t+1} } }{ | \D_{t+1,i} | } = \sqrt{d} , \fa i \in [d] .
\ee
Therefore, while $\bD_{t+1}$ is random, the above ratio is not random.
With Gaussian variables, this ratio can be arbitrarily large, but with
ever lower probability.
This is an unnecessary complication that we wish to avoid.
A further generalization of SPSA is given in \cite{Bhat-Pras-arxiv22}
which requires $2k$ function evaluations instead of $2$, 
where $k$ is the order of G-SPSA. We do not study this extension in this paper.

Now we analyze Options 1B through 4B.
Because of the complexity of analyzing the B options, we divide the
bounds into two parts.
% The next lemma relates $\w_t^B$ to $ \w_t$.

\begin{lemma}\label{lemma:32}
Define
\be\label{eq:341b}
\w_t^B := E_t( \bphH^{(1B)} ) .
\ee
Then
\be\label{eq:352}
E_t( \bphH^{(kB)} ) = \w_t^B  , \mbox{ for } k = 2, 3, 4 .
\ee
Moreover
\be\label{eq:353}
\nmeu{\w_t^B +\gJ(\bth_t)} \leq \frac{c_t d^{3/2} L}{2} ,
\ee
where $L$ is the Lipschitz constant of $\gJ(\cdot)$.
\end{lemma}

\begin{proof}
Equation \eqref{eq:352} is obvious.
The proof of \eqref{eq:353} is facilitated by a few observations.
First, $1/\D_{t,i} = \D_{t,i}$ because $\D_{t,i}$ is bipolar.
Second, if $i,j \in [d]$, the pairwise independence of $\D_{t,i}$
means that $E[\D_{t,i} \D_{t,j} ] = \d_{ij}$, the Kronecker delta.
Finally, since, each $\D_{t,i}$ is independent of the $\s$-algebra $\F_t$,
it follows that for any function $f \in \M(\F_t)$, we have
\bd
E_t ( \D_{t,i} \D_{t,j} f ) = \d_{ij} f .
\ed
Next, if $B_{t+1}$ is a random variable assuming values in $[-1,1]$, then
$E_t(B_{t+1}) \in (-1,1)$.
Therefore the conditional variance $E_t ( ( B_{t+1} - E_t(B_{t+1}) )^2 )$
lies in $(0, 4)$.
(Better bounds are possible, but this one is good enough.)

It follows from \eqref{eq:337d} that
\bd
\w_t^{(B)} + \gJ(\bth_t) = E_t( \y_{t+1}^{(B)}) + \gJ(\bth_t)  .
\ed
Define
\bd
V_{t+1} := \frac{ J( \bth_t + c_t \bD_{t+1} ) - J( \bth_t - c_t \bD_{t+1} ) }
{ 2 c_t } .
\ed
Then
\bd
y_{t+1,i}^{(B)} = \frac{V_{t+1}}{\D_{t+1,i}} .
\ed
It is worth noting that the numerator is independent of the index $i$;
only the denominator depends on $i$.
So we analyze the numerator.
We can write
\begin{eqnarray*}
V_{t+1} & = & \frac{1}{2 c_t} \int_{-1}^1 \frac{d}{d \l} [ J( \bth_t + \l c_t \bD_{t+1} ) ] d \l\\
& = & \frac{1}{2 c_t} \int_{-1}^1 c_t \IP { \bD_{t+1} } { \gJ( \bth_t + \l c_t \bD_{t+1} ) } d \l = A_{t+1} + B_{t+1} ,
\end{eqnarray*}
where
\bd
A_{t+1} := \frac{1}{2 c_t} \int_{-1}^1 c_t \IP{ \bD_{t+1} } { \gJ(\bth_t) } \; d \l
=  \IP{ \bD_{t+1} }  { \gJ(\bth_t) } ,
\ed
\bd
B_{t+1} := \frac{1}{2 c_t} \int_{-1}^1 c_t \IP{ \bD_{t+1} } { \gJ(\bth_t + \l c_t \bD_{t+1} ) 
- \gJ(\bth_t) } d \l .
\ed
Fix an index $i \in [d]$, and define
\bd
u_{t+1,i} := \frac{ A_{t+1} }{\D_{t+1,i} }  = A_{t+1} \D_{t+1,i} ,
v_{t+1,i} := \frac{B_{t+1}} {\D_{t+1,i} } = B_{t+1} \D_{t+1,i} .
\ed
Then
\bd
y_{t+1,i}^{(B)} = \frac{V_{t+1}}{\D_{t+1,i}}  = u_{t+1,i} + v_{t+1,i} .
\ed
We will analyze each term separately.

We begin with $u_{t+1,i}$.
By the above,
\bd
A_{t+1}  = \IP{ \bD_{t+1} }  { \gJ(\bth_t) } = \D_{t+1,i} [ \gJ(\bth_t) ]_i
+ \sum_{j \neq i} \D_{t+1,j} [ \gJ(\bth_t) ]_j .
\ed
Therefore, noting that $\D_{t+1,i}^2 = 1$ gives
\bd
u_{t+1,i}  = \D_{t+1,i} A_{t+1} = [ \gJ(\bth_t) ]_i + \bar{A}_{t+1,i} ,
\ed
where
\bd
\bar{A}_{t+1,i} := \sum_{j \neq i} \D_{t+1,i} \D_{t+1,j} [ \gJ(\bth_t) ]_j .
\ed
% Here we use the fact that $1/\D_{t+1,i} = \D_{t+1,i}$.
Next, observe that the product $\D_{t+1,i} \D_{t+1,j}$ is independent 
of the $\s$-algebra $\F_t$.
Therefore
\begin{eqnarray*}
E_t( \bar{A}_{t+1,i} ) & = &
\sum_{j \neq i} E_t ( \D_{t+1,i} \D_{t+1,j} [ \gJ(\bth_t) ]_j ) \\
& = & E[ \D_{t+1,i} \D_{t+1,j} ] \sum_{j \neq i} [ \gJ(\bth_t) ]_j = 0
\end{eqnarray*}
whenever $j \neq i$.
Hence
\bd
E_t ( u_{t+1,i} ) = [ \gJ(\bth_t) ]_i ,
\ed

As for $v_{t+1,i}$, we use the Lipschitz-continuity of $\gJ(\cdot)$
and write
\begin{eqnarray*}
| B_{t+1} | & \leq & \frac{1}{2 c_t} \int_{-1}^1 c_t \IP{ \nmeu { \bD_{t+1} } }
{ \nmeu{\gJ(\bth_t + \l c_t \bD_{t+1} ) - \gJ(\bth_t) } } d \l \\
& \leq & \half c_t L \nmeusq{\bD_{t+1}} \int_{-1}^1 |\l| d \l =
\frac{c_t d L}{2} .
\end{eqnarray*}
% So if we define
% \bd
% v_{t+1,i} := \frac{B_{t+1}} {\D_{t+1,i} } ,
% \ed
Thus
\bd
| v_{t+1,i} | \leq \frac{c_t d L}{2} , \fa i \in [d] .
\ed
As a result
\bd
| E_t( v_{t+1,i} ) | \leq \frac{c_t d L}{2} , \fa i \in [d] ,
\ed
\bd
\nmeu{ E_t(\v_{t+1} ) } = \left[ \sum_{i=1}^d | E_t( v_{t+1,i} ) |^2
\right]^{1/2} \leq \frac{ c_t d^{3/2} L }{2 } .
\ed
Now the above computations show that
\bd
E_t( \y_{t+1}^{(B)} ) = E_t( \u_{t+1} ) + E_t( \v_{t+1} )
= \gJ(\bth_t) + E_t( \v_{t+1} ) .
\ed
Therefore
\be\label{eq:354}
E_t( \y_{t+1}^{(B)} - \gJ(\bth_t) ) = \v_{t+1} .
\ee
from which \eqref{eq:353} follows.
\end{proof}

The next result gives bounds on the conditional variances of
$\bphH^{kB}$ for $k = 1 , 2 , 3 , 4$.

\begin{lemma}\label{lemma:33}
For convenience, define
\be\label{eq:355}
K_t := \sqrt{d} \nmeusq{\gJ(\bth_t)} + 4 c_t d^2 L \nmeu{\gJ(\bth_t)}
+ 4 c_t^2 d^{5/2} L^2 .
\ee
Then
\be\label{eq:355a}
CV_t(\y_{t+1}^{(B)} ) \leq K_t .
\ee
Further
\be\label{eq:356}
\begin{split}
CV_t( \bphH^{(1B)} ) &\leq K_t 
+ \frac{ E_t(\nmeusq{\bxi_{t+1}^{(B)}})}{c_t^2} , \\
CV_t( \bphH^{(2B)} ) &\leq (d-1) \left[ \nmeusq{\w_t^B} + K_t 
+ \frac{ E_t(\nmeusq{\bxi_{t+1}^{(B)}})}{c_t^2}  \right], \\
CV_t( \bphH^{{(3B)}} ) &\leq (d-1) \left[ \nmeusq{\w_t^B} + K_t 
+ \frac{ E_t(\nmeusq{\bxi_{t+1}^{(B)}})}{c_t^2}  \right], \\
CV_t( \bphH^{(4B)} ) &\leq  \frac{(1-\r_t)}{\r_t} \left[ \nmeusq{\w_t^B} + K_t 
+ \frac{ E_t(\nmeusq{\bxi_{t+1}^{(B)}})}{c_t^2}  \right].
\end{split}
\ee
\end{lemma}

\begin{proof}
We prove \eqref{eq:355a} and \eqref{eq:356} for Option 1B.
Once this bound is established, the remaining bounds in \eqref{eq:356}
follow exactly as in Lemma \ref{lemma:31}.

% By definition, we have
% \bd
% CV_t( \bphH^{(1B)} ) = E_t ( \nmeusq{ \bphH^{(1B)} - E_t( \bphH^{(1B)} ) } ) .
% \ed
% 
% Recall from \eqref{eq:337d} that
% \bd
% \bphi^{(1B)}_{t+1} 
% = \phH - \left( \y_{t+1}^{(B)} + \frac{\bxi_{t+1}}{c_t } \right) + \bzeta_{t+1} .
% \ed
% Since the last two noise terms have zero conditional mean and are independent
% of the rest, it is apparent that
% \bd
% CV_t( \bphH^{(1B)} ) = CV_t(\phH - \y_{t+1}^{(B)} ) 
% + \frac{E_t \nmeusq{\bxi_t} }{c_t^2} + E_t ( \nmeusq{\bzeta_t} ) .
% \ed
% Hence \eqref{eq:356} is proved if it can be shown that
% \bd
% CV_t(\phH - \y_{t+1}^{(B)} ) \leq K_t .
% \ed
% In the A options, the quantity $\y_t^{(A)} \in \M(\F_t)$.
% Hence $CV_t(\phH - \y_{t+1}^{(A)} ) = 0$.
% However, this is not true in the case of the B options.
% However, it is not true in general that $CV_t(\phH - \y_{t+1}^{(B)} ) = 0$.
% The last two terms on the right side are the last two terms in the
% definition of $K_t$ in \eqref{eq:355}.
% So \eqref{eq:356} is proved if it can be established that
% \bd
% CV_t(\phH - \y_{t+1}^{(B)} ) \leq
% d \nmeusq{\gJ(\bth_t)} + 2 c_t d^{5/2} L \nmeu{\gJ(\bth_t)}
% + c_t^2 d^3 L^2 .
% \ed
% Since $\phH \in \M(\F_t)$, it does not contribute to the conditional
% variance.
% Thus $CV_t(\phH - \y_{t+1}^{(B)} ) = CV_t(\y_{t+1})$, and the bound
% is proved if it can be shown that
% \be\label{eq:3510}
% CV_t(\y_{t+1}^{(B)} ) \leq K_t .
% \sqrt{d} \nmeusq{\gJ(\bth_t)} + 4 c_t d^2 L \nmeu{\gJ(\bth_t)}
% + 4 c_t^2 d^{5/2} L^2 .
% \ee
% We shall work towards this objective.

From the proof of Lemma \ref{lemma:32}, we know that
\bd
% E_t( \y_{t+1,i} ) = [ \gJ(\bth_t) ]_i + \bar{A}_{t+1,i} + v_{t+1,i} ,
y_{t+1,i}^{(B)} = [ \gJ(\bth_t) ]_i + \bar{A}_{t+1,i} + v_{t+1,i} ,
\ed
where
\bd
\bar{A}_{t+1,i} := \sum_{j \neq i} \D_{t+1,i} \D_{t+1,j} [ \gJ(\bth_t) ]_j ,
\ed
\bd
v_{t+1,i} := \frac{B_{t+1}} {\D_{t+1,i} } = B_{t+1} \D_{t+1,i} .
\ed
Now define
\bd
\vb_{t+1,i} := v_{t+1,i} - E_t( v_{t+1,i} ) ,
\ed
and recall from the proof of Lemma \ref{lemma:32} that
$E_t(\bar{A}_{t+1,i}) = 0$ for all $i$.
Again, since $\gJ(\bth_t) \in \M(\F_t)$, it does not contribute to
$CV_t(\y_{t+1}^{(B)} )$.
This leads to the conclusion that
\beq
CV_t(\y_{t+1}^{(B)} ) & = & \sum_{i=1}^d E_t( ( \bar{A}_{t+1,i} + \vb_{t+1,i} )^2 ) 
\nonumber \\
& = & \sum_{i=1}^d [ E_t( \bar{A}_{t+1,i}^2 ) + E_t( \vb_{t+1,i}^2)
+ 2E_t( \bar{A}_{t+1,i} \vb_{t+1,i} )] . \label{eq:3511}
\eeq
We shall bound each term separately.

First we bound $E_t ( \bar{A}_{t+1,i}^2 )$.
Note that, because $\D_{t+1,i}^2 = 1$ always, we have
\bd
\bar{A}_{t+1,i}^2 = \sum_{k \neq i} \sum_{j \neq i}
\D_{t+1,j}\D_{t+1,k} [ \gJ(\bth_t) ]_j  [ \gJ(\bth_t) ]_k .
\ed
When we can take $E_t$ of this quantity, we observe that the
product $\D_{t+1,k} \D_{t+1,j}$ is independent of $\F_t$.
Hence
\bd
E_t ( \D_{t+1,j}\D_{t+1,k} [ \gJ(\bth_t) ]_j  [ \gJ(\bth_t) ]_k )
= \d_{jk} [ \gJ(\bth_t) ]_j  [ \gJ(\bth_t) ]_k ,
\ed
\bd
E_t ( \bar{A}_{t+1,i}^2 ) =
\sum_{k \neq i} \sum_{j \neq i}
\d_{jk} [ \gJ(\bth_t) ]_j  [ \gJ(\bth_t) ]_k 
= \sum_{j \neq i} [ \gJ(\bth_t) ]_j^2 
\leq \nmeusq{\gJ(\bth_t)} .
\ed
Next we bound $| \bar{A}_{t+1,i} |$.
Note that $| \D_{t+1,i} \D_{t+1,j} | = 1$ for all $i,j$.
Therefore we can apply Schwarz' inequality to deduce that
\bd
\left| \sum_{j \neq i} \D_{t+1,i} \D_{t+1,j} [ \gJ(\bth_t) ]_j \right|
\leq \sqrt{d} \nmeu{\gJ(\bth_t)} .
\ed
% The exact form of $v_{t+1,i}$ is not important --only the fact that
% $| v_{t+1,i} | \leq c_t d L$,
% as established in the proof of Lemma \ref{lemma:32}.
Finally, since $| v_{t+1,i} | \leq c_t d L$, it follows that
$| \vb_{t+1,i} | \leq 2 c_t d L$.
% We also need bounds on $| \bar{A}_{t+1,i} |$ and
% on $E_t ( \bar{A}_{t+1,i}^2 )$.
% Recall that if $X$ is a random variable assuming values in $[-a,a]$,
% the $|E_t(X)| \leq a$.
Therefore, for each index $i$,
\bd
| E_t ( \bar{A}_{t+1,i}^2 + 2 \bar{A}_{t+1,i} \vb_{t+1,i} + \vb_{t+1,i}^2 ) |
\leq \nmeusq{\gJ(\bth_t)} + 4 c_t d L \sqrt{d} \nmeu{\gJ(\bth_t)}
+ 4 c_t^2 d^2 L^2 .
\ed
The above is a componentwise bound.
The bound on $CV_t(\y_{t+1}^{(B)})$ is $\sqrt{d}$ times the above bound.
Now substituting the above bound into \eqref{eq:3511} gives
\eqref{eq:355a}.

Once we find a bound for $CV_t(\bphi_{t+1}^{(1B)})$, the other
bounds follow as in the proof of Lemma \ref{lemma:31}.
\end{proof}

\section{Statements of Main Theorems}\label{sec:Main}

In this section we state the main theorems of this paper.

\subsection{Assumptions on the Objective Function and Search Direction}
\label{ssec:41}

In this paper, we study functions $J : \R^d \ap \R$ that satisfy the
following \textbf{Standing Assumptions:}
\ben
\item[(A1)] $J(\cdot)$ is $\C^1$.
Moreover, $\gJ(\cdot)$ is globally Lipschitz-continuous with constant $L$.
\item[(A2)] $J(\cdot)$ has a global infimum $J^*$, which is attained.
\item[(A3)] $J(\cdot)$ has compact level sets.
Thus, for every fixed constant $r$, the set
\bd
L_J(r) := \{ \bth : J(\bth) \leq r \}
\ed
is compact.
\een
Note that an equivalent way of stating Assumption (A3) is that
\bd
\lim_{\nmeu{\bth} \ap \infty} J(\bth) = \infty .
\ed
Such a function is also called \textbf{radially unbounded}, or
\textbf{coercive}.
We do not use either term in this paper.

As stated above, (A1)--(A3) are the standing assumptions.
Now we state other assumptions.
Note that different assumptions are used in different theorems.
For this purpose, we define
\bd
\Jb(\bth) := J(\bth) - J^* .
\ed
We also make use of the following concept 
from \cite[Definition 1]{MV-MCSS-arxiv23}:
A function $\eta : \R_+ \ap \R_+$ is
said to \textbf{belong to Class $\B$} if $\eta(0) = 0$, and in addition
\bd
\inf_{\e \leq r \leq M} \eta(r) > 0 , \fa 0 < \e < M < \infty .
\ed
Note $\eta(\cdot)$ is \textit{not} assumed to be monotonic.
However, if $\eta : \R_+ \ap \R_+$ is continuous, then
$\eta(\cdot)$ belongs to Class $\B$ if and only if (i) $\eta(0) = 0$,
and (ii) $\eta(r) > 0$ for all $r > 0$.
\ben
\item[(J1)] There exists a constant $H$ such that
\be\label{eq:411}
\nmeusq{ \gJ(\bth) } \leq H \Jb(\bth) , \fa \bth \in \R^d .
\ee
\item[(J2)]
There is a function $\eta(\cdot)$ belonging to Class $\B$ such that
\be\label{eq:412}
\eta(\Jb(\bth)) \leq \nmeu{\gJ(\bth)} , \fa \bth \in \R^d .
\ee
\item[(J3)] Define
\be\label{eq:413}
S(J) := \{ \bth : \gJ(\bth) = \bz \} .
\ee
The assumption is:
There is a function $\nu(\cdot)$ belonging to Class $\B$
such that
\be\label{eq:414}
\r(\bth,S(J)) \leq \nu(\Jb(\bth) )  , \fa \bth \in \R^d .
\ee
where
\bd
\r(\bth,S(J)) := \inf_{\bpsi \in S(J)} \nmeu{\bth - \bpsi } 
\ed
is the distance between $\bth$ and the set $S(J)$.
\een

Now we discuss the significance of these assumptions.
First it is shown that these assumptions hold readily in the case
where $J(\cdot)$ is convex with some additional conditions.
Then an example is presented where these assumptions hold even though
$J(\cdot)$ is not convex.

If $J(\cdot)$ is convex, then it is known
that \eqref{eq:411} is satisfied with $H = 2L$, where $L$ is the Lipschitz
constant of $\gJ(\cdot)$; see \cite[Theorem 2.1.5]{Nesterov04}.
If in addition $J(\cdot)$ is also $R$-strictly convex, in the sense that
\bd
J(\bpsi) \geq J(\bth) + \IP{\gJ(\bth)}{\bpsi - \bth} + \frac{R}{2}
\nmeusq{ \bpsi - \bth } ,
\ed
for some constant $R$,
then it follows from \cite[Theorem 2.1.10]{Nesterov04} that
\bd
\Jb(\bth) \leq \frac{1}{2R} \nmeusq{\gJ(\bth} , \fa \bth \in \R^d .
\ed
This is the same as (J2) with $\eta(r) = \sqrt{2Rr}$.
In this case, $S(J)$ is a singleton set, say $\{ \bths \}$, so that
$\r(\bth,S(J)) = \nmeu{\bth - \bths}$, and
$J(\bth) \leq (L/2) \nmeusq{\bth - \bths}$.
Therefore, (J3) is also satisfied.

Note that Assumptions (J1), (J2) and (J3) permit $J(\cdot)$
to have multiple local minima.
However, each local minimum must also be a global minimum.
Otherwise (J2) and (J3) would fail to be satisfied.

\begin{example}\label{exam:31}
The objective of this example is to present a nonconvex function
that satisfies Assumptions (J1), (J2), (J3).
Consider the following function $J : \R \ap \R$:
\bd
J(\th) := \left\{ \ba{ll} \sin[(\pi/2)(\th-1)] + 1 , & -5 \leq \th \leq 5 , \\
0.5 + \sqrt{(\pi/2)(\th-5) + 0.25}, & 5 \leq \th , \\
J(-\th), & \th \leq -5 , \ea \right.
\ed
which is depicted in Figure \ref{fig:exam-1}
It has multiple local minima, but each of them is also a global minimum.
This function satisfies Assumptions (J1)--(J3).
Moreover, by changing the number $5$ to something larger, the function
can be made to have an arbitrarily large number of minima.
% However, if a function $J(\cdot)$ had some local minima that are not also
% global minima, then (J2) and (J3) would fail to be satisfied.
\bfig[htb]
\bc
\includegraphics[width=0.6\columnwidth]{Example-1_v2}
\ec
\caption{Depiction of a function with multiple minima satisfying
Assumptions (J1), (J2) and (J3)}
\label{fig:exam-1}
\efig
\end{example}

% Note that these assumptions are the same as in \cite{MV-TUKR-ICML23}.
Next we state the assumptions on the vector $\bphH$.
When full coordinate update is employed, this becomes the search direction.
If batch updating is employed, then the search direction is $\bphH^{(k)}$,
$k = 2, 3, 4$.
However, our assumptions are stated only in terms of $\bphH$.
\ben
\item[(D1).]
Define
\be\label{eq:326}
\phH := E_t ( \bphH) + \gJ(\bth_t) .
\ee
Then there exists a sequence of deterministic constants
$\{ b_t \}$ such that
\be\label{eq:415}
\nmeusq{ \phH} \leq b_t^2 , \fa t .
\ee
\item[(D2).] There is a sequence of deterministic constants $\{ M_t \}$ such
that
\be\label{eq:416}
% E_t( \nmeusq{\bzeta_{t+1} } ) 
CV_t( \phH ) \leq M_t^2 (1 + \nmeusq{\gJ(\bth_t) } ) , \fa t .
\ee
\item[(D3).] (\textit{When approximate gradients are used})
There is a fixed constant $a_0$ such that
\be\label{eq:416a}
E_t( \nmeusq{\bxi_{t+1} } ) \leq a_0^2 , \fa t .
\ee
\een

Now we discuss the significance of these assumptions.
Assumption (D1) is less restrictive than requiring that 
$E_t(\bphH) = - \gJ(\bth_t)$ (or equivalently $\phH = \bz$),
which is the prevailing assumption in almost all existing papers.
% In this case $\phH = \bz$ for all $t$.
When approximate gradients are used, it becomes necessary to permit
$\phH$ to be nonzero.
Next, we come to Assumption (D2).
In \cite{Khaled-Rich-arxiv20}, the following condition is stated as
the weakest condition for analyzing stochastic gradient descent for
nonconvex objective functions:
There exist constants $A, B, C$ such that
\be\label{eq:417}
E_t( \nmeusq{\bzeta_{t+1} } ) \leq A \Jb(\bth_t) + B \nmeusq{\gJ(\bth_t)} + C .
\ee
However, if Assumption (J1) holds, then \eqref{eq:417} can be recast
in the form \eqref{eq:416}, with $M_t$ being uniformly bounded with
respect to $t$.
As we shall see below, when approximate gradients are used, \eqref{eq:416}
holds, but the sequence $\{ M_t \}$ is \textit{not} bounded.
% \textit{does not hold} with bounded $M_t$.
% It becomes necessary to permit $M_t$ to grow without bound.
Finally, (D3) is just a bound on the measurement errors
when approximate gradients are used.

\subsection{Main Theorems}

In this subsection, we state the main theorems.
Two distinct families of algorithms are considered.
In the first family, the search direction $\bphH$ is completely arbitrary,
and we study the convergence properties of Options 1, 2, 3, 4 applied to
$\bphH$.
In the second family, it is assumed that 
% $\phH$ as defined in either \eqref{eq:3211b} or \eqref{eq:337d} equals $\bz$,
$\bphH$ equals either $\bphH^{(1A)}$ as defined in \eqref{eq:3211b} or 
$\bphH^{(1B)}$ as defined in \eqref{eq:337d}.
% Because it is assumed that $\phH = \bz$ in the second families of algorithms,
% the only source of the bias (that, a possibly nonzero value of 
% $E_t(\bphH) + \gJ(\bth_t)$) comes from the use of approximate gradients.

Note that, in all the theorem statements,
all the conclusions hold almost surely, but the phrase ``almost surely''
is not expicitly stated.

The first theorem pertains to the boundedness and convergence of
the iterations $\{ \bth_t \}$, when anyone of Options 1 through 4 is applied.

\begin{theorem}\label{thm:SHB}
Suppose the Standing Assumptions (A1)--(A3)
about $J(\cdot)$ hold, as well as Assumptions (D1)--(D2).
% about $\phH$.
Suppose any one of Options (1)--(4) is applied in the SHB algorithm.
\ben
\item Suppose Assumption (J1) holds, and in addition
\be\label{eq:421}
\sum_{t=0}^\infty \al_t^2 < \infty ,
\sum_{t=0}^\infty \al_t b_t  < \infty ,
\sum_{t=0}^\infty \al_t^2 M_t^2 < \infty ,
\ee
\be\label{eq:422}
\sum_{t=0}^\infty \al_t = \infty .
\ee
Then $\{ J(\bth_t) \}$ and $\{ \bth_t \}$ are bounded, and
% \footnote{In this
% theorem, all statements hold almost surely.}
% \item Suppose that, in addition to \eqref{eq:421}, we also have that
% Then
\be\label{eq:423}
\liminf_{\tai} \nmeu{ \gJ(\bth_t)} = 0 .
\ee
\item If in addition to the assumptions in Item 1, we add Assumption (J2),
then $\gJ(\bth_t) \ap \bz$ as $\tai$, and $\Jb(\bth_t) \ap 0$ as $\tai$.
\item If in addition to the assumptions in Item 2, we also add Assumption (J3),
then $\r(S(J),\bth_t) \ap 0$ as $\tai$.
\een
\end{theorem}

\textbf{Remarks:}
As will be seen in the next section, the proof of Theorem \ref{thm:SHB}
builds on the approach suggested in \cite{Liu-Yuan-arxiv22}.
However, in that paper the step sizes are assumed to
have a very specific form, namely $\al_t = \Theta(1/(t+1)^{1-\e})$
for some $\e \in (0,0.5)$.
No such assumptions are made here.
Instead we have \eqref{eq:421} and \eqref{eq:422}, which are
generalizations of the standard Robbins-Monro conditions
as proposed in \cite{MV-BASA-arxiv22} for a different purpose.
In this sense, Theorem \ref{thm:SHB}, when applied to Option 1,
contains \cite[Theorem 2]{Liu-Yuan-arxiv22} as a special case.
Further, when Theorem \ref{thm:SHB} is applied to Options 2, 3, or 4,
it shows that the stochastic Heavy Ball algorithm also converges with
any one of single component, multiple component, or Bernoulli batch updating.
If the momentum parameter $\mu$ is set to zero, then the stochastic
Heavy Ball becomes stochastic gradient descent.
Our theorem also guarantees the convergence of SGD with
batch-updating.
So far as the authors are aware, these results are new.
Moreover, the step size sequence remains more general than in
\cite{Liu-Yuan-arxiv22}.

The above theorem is applicable to Options 1 through 4.
If we now replace these by their A or B counterparts (that is, replacing
the true gradient by the approximate gradient), we get the following theorem:
% We separate the Class A options from Class B options, because the proofs
% are quite different.
% As one might expect, the proofs for Class A options are much simpler.

\begin{theorem}\label{thm:SHB-A}
Suppose the Standing Assumptions (A1)--(A3) about $J(\cdot)$ hold, as well as
Assumptions (D1) and (D3).\footnote{Note that (D2) is not assumed.}
% about $\phH$.
% Suppose $\phH = \bz$, and 
Suppose that that any one of Options (1A)--(4A), or (1B)--(4B)
is applied in the SHB algorithm.
Then we have the following conclusions:
\ben
\item Suppose Assumption (J1) holds, and in addition, 
\be\label{eq:424}
\sum_{t=0}^\infty \al_t^2 < \infty ,
\sum_{t=0}^\infty \al_t c_t  < \infty ,
\sum_{t=0}^\infty ( \al_t / c_t )^2 < \infty ,
\ee
as well as \eqref{eq:422}.
Then $\{ J(\bth_t) \}$ and $\{ \bth_t \}$ are bounded, and
\be\label{eq:425}
\liminf_{\tai} \nmeu{ \gJ(\bth_t)} = 0 .
\ee
\item If in addition to the assumptions in Item 1, we also add Assumption (J2),
then $\gJ(\bth_t) \ap \bz$ as $\tai$, and $\Jb(\bth_t) \ap 0$ as $\tai$.
\item If in addition to the assumptions in Item 2, we also add Assumption (J3),
then $\r(S(J),\bth_t) \ap 0$ as $\tai$.
\een
\end{theorem}

% \begin{theorem}\label{thm:SHB-B}
% Suppose the Standing Assumptions (A1)--(A3) about $J(\cdot)$ hold, as well as
% Assumptions (D1) plus (D3).
% % about $\phH$.
% Suppose $\phH = \bz$, and that any one of Options (1B)--(4B)
% is applied in the SHB algorithm.
% \ben
% \item Suppose Assumption (J1) holds, and in addition
% \eqref{eq:424} holds.
% Then $\{ J(\bth_t) \}$ and $\{ \bth_t \}$ are bounded, and
% \be\label{eq:425a}
% \liminf_{\tai} \nmeu{ \gJ(\bth_t)} = 0 .
% \ee
% \item If in addition to the assumptions in Item 1, we also add Assumption (J2),
% then $\gJ(\bth_t) \ap \bz$ as $\tai$, and $\Jb(\bth_t) \ap 0$ as $\tai$.
% \item If in addition to the assumptions in Item 2, we also add Assumption (J3),
% then $\r(S(J),\bth_t) \ap 0$ as $\tai$.
% \een
% \end{theorem}

The next theorem is about the \textit{rate} of convergence in Theorem
\ref{thm:SHB}.
Before stating it, we specify what ``rate of convergence'' means for a
stochastic process.

\begin{definition}\label{def:Rate}
Suppose $\{ X_t \}$ is a stochastic process on a probability space
$(\OM , \SI , P)$, and that $Y: \R_+ \ap \R_+$ is a measurable function.
Then we say that $X_t = O(Y_t)$ if $\{ X_t/Y_t \}$ is bounded almost surely,
and that $X_t = o(Y_t)$ if $X_t/Y_t \ap 0$ almost surely as $\tai$.
\end{definition}
Note that if $X_t = O(Y_t)$, then for almost all
$\om \in \OM$, there exists a constant $C(\om)$ such that
\be\label{eq:426}
|X_t(\om)| \leq C(\om) Y(t) , \fa t .
\ee
However, the bounding constant $C(\om)$ could vary from one sample path to
another, and there is no presumption that there is a uniform bound across
sample paths.

\begin{theorem}\label{thm:SHB-Rate}
Suppose, in addition to all of the assumptions in Theorem \ref{thm:SHB},
we add a fourth assumption of strict convexity:
\ben
\item[(J4)] There exists a constant $R > 0$ such that, for all
$\bth,\bpsi \in \R^d$, we have
\be\label{eq:427}
J(\bpsi) \geq J(\bth) + \IP{\gJ(\bth)}{\bpsi-\bth} 
+ \frac{R}{2} \nmeusq{\bpsi-\bth} .
\ee
\een
Suppose the Stochastic Heavy Ball algorithm is applied with any one of
Options 1, 2, 3, or 4.
Then we have the following conclusions:
\ben
\item
Suppose the step size sequence $\al_t$ is chosen as
\be\label{eq:428}
\al_t = \Theta \left( \frac{1}{t^{1-\e} } \right) ,
\ee
for some $\e \in (0,0.5)$.
Then almost surely
\be\label{eq:429}
\Jb(\bth_t) = o \left( \frac{1}{t^{1-\d} } \right) ,
\ee
for all $\d \in (2\e,1)$.
\item Suppose that the sequence of step sizes $\{ \al_t \}$ is decreasing,
and satisfies
\be\label{eq:4210}
\frac{ \al_t }{ \sum_{\t = 1}^t \al_\t } = \infty.
\ee
Then almost surely
\be\label{eq:4211}
\min_{1 \leq \t \leq t} \nmeusq{ \gJ(\bth_\t) } = 
o \left( \frac{ \al_t }{ \sum_{\t = 1}^t \al_\t } \right) .
\ee
In particular, if we choose $\al_t = \al_0 / (t^{\e + 0.5})$
with $\al_0 > 0$ for some $\e \in [0,0.5]$, then
\be\label{eq:4212}
\min_{1 \leq \t \leq t} \nmeusq{ \gJ(\bth_\t) }
= o \left( \frac{1}{t^{\e + 0.5} } \right) .
\ee
\een
\end{theorem}

\textbf{Remark:} The above theorem is an extension of
\cite[Theorem 2]{Liu-Yuan-arxiv22} to batch-updating.

\section{Proofs of Main Theorems}\label{sec:Proofs}

Recall the SHB algorithm defined in \eqref{eq:321}.
We now define
\be\label{eq:501}
\v_t := \bth_t - \bth_{t-1} , \z_t = \bth_t + \frac{\mu}{1 - \mu} \v_t .
\ee
Then, as shown in \cite{Liu-Yuan-arxiv22}, it is possible to rearrange 
the three equations \eqref{eq:321} and \eqref{eq:501} as
\be\label{eq:502}
\v_{t+1} = \mu \v_t + \al_t \bphH ,
\ee
\be\label{eq:502a}
\z_{t+1} = \z_t + \frac{\al_t}{1 - \mu} \bphH .
\ee
The advantage of the above reformulation is that the original
updating formula for $\bth_{t+1}$ is divided into two separate
updates, for $\v_{t+1}$ and $\z_{t+1}$ respectively,
in such a way that neither update contains a ``delayed'' term.
Moreover, the variable of optimization $\bth_t$ can be expressed
from \eqref{eq:501} as
\be\label{eq:503}
\bth_t = \z_t - \frac{\mu}{1 - \mu} \v_t .
\ee

The proof of Theorem \ref {thm:SHB}
is based on the ``almost supermartingale lemma'' of Robbins \&
Siegmund Theorem \cite{Robb-Sieg71}.
That paper is rather difficult to locate.
However, the same theorem is stated as \cite[Lemma 2, Section 5.2]{BMP92}.
A recent survey of many results along similar lines is found in
\cite{Fran-Gram22}, where Lemma \ref{lemma:51} below is stated as Lemma 4.1.
The result states the following:

\begin{lemma}\label{lemma:51}
Suppose $\{ z_t \} , \{ \d_t \} , \{ \g_t \} , \{ \psi_t \}$ are
stochastic processes defined on some probability space $(\OM,\SI,P)$,
taking values in $[0,\infty)$, adapted to some
filtration $\{ \F_t \}$, satisfying
\be\label{eq:504}
E_t(z_{t+1} ) \leq (1 + \d_t) z_t + \g_t - \psi_t \as, \fa t .
\ee
Define
\be\label{eq:505}
\OM_0 := \{ \om \in \OM : \sum_{t=0}^\infty \d_t(\om) < \infty \}
\cap \{ \om : \sum_{t=0}^\infty \g_t(\om) < \infty \} .
\ee
Then for all $\om \in \OM_0$, $\lim_{\tai} z_t(\om)$ exists, and in addition,
\be\label{eq:506}
\sum_{t=0}^\infty \psi_t(\om) < \infty , \fa \om \in \OM_0 .
\ee
In particular, if $P(\OM_0) = 1$, then $\{ z_t \}$ is bounded almost surely.
\end{lemma}


The proof below makes use of a couple of straight-forward extensions
of Lemma \ref{lemma:51}.

\begin{lemma}\label{lemma:A1}
Suppose $\{ z_t \} , \{ \d_t \} , \{ \g_t \} , \{ \psi_t \} , \{ \al_t \}$ are
stochastic processes defined on some probability space $(\OM,\SI,P)$,
taking values in $[0,\infty)$, adapted to some
filtration $\{ \F_t \}$.
Suppose further that
\be\label{eq:A1}
E_t(z_{t+1} ) \leq (1 + \d_t) z_t + \g_t - \al_t \psi_t \as, \fa t .
\ee
Define
\be\label{eq:A2}
\OM_0 := \{ \om \in \OM : \sum_{t=0}^\infty \d_t(\om) < \infty \mbox{ and }
\sum_{t=0}^\infty \g_t(\om) < \infty \mbox{ and }
\sum_{t=0}^\infty \al_t(\om) = \infty \} .
\ee
Then
\ben
\item There exists a random variable $W$ defined on $(\OM,\SI,P)$ such that
$z_t(\om) \ap W(\om)$ for all $\om \in \OM_0$.
Moreover
\be\label{eq:A3}
\liminf_{\tai} \psi(\om) = 0  \fa \om \in \OM_0 .
\ee
\item Suppose there exists a function $\eta(\cdot)$ of Class $\B$ 
such that $\psi_t(\om) \geq \eta(z_t(\om))$ for all $\om \in \OM_0$.
Then $z_t(\om) \ap 0$ as $\tai$ for all $\om \in \OM_0$.
\een
\end{lemma}

\begin{proof}
By Lemma \ref{lemma:51}, there exist a random variable $W$ such that
$z_t(\om) \ap W(\om)$ as $\tai$.
Moreover,
\bd
\sum_{t=0}^\infty \al_t(\om) \psi_t(\om) < \infty , \fa \om \in \OM_0 .
\ed
Now, by definition
\bd
\sum_{t=0}^\infty \al_t(\om) = \infty , \fa \om \in \OM_0 .
\ed
Therefore \eqref{eq:A3} follows.
This is Item 1.

To prove item 2, suppose that, for some $\om \in \OM_0$, we have that
$W(\om) > 0$, say $W(\om) =: \e > 0$.
Choose a time $T$ such that $z_t(\om) \geq \e/2$ for all $t \geq T$.
If we discard all terms for $t < T$, we get
\bd
\sum_{t=T}^\infty \al_t(\om) \psi_t(\om) < \infty , \fa \om \in \OM_0 ,
\sum_{t=T}^\infty \al_t(\om) = \infty .
\ed
Next, for each $t \geq T$, we have that $\psi_t(\om) \geq \eta(\e/2) > 0$.
This is a contradiction.
Therefore the set of $\om \in \OM_0$ for which $W(\om) > 0$ has zero measure
within $\OM_0$.
In other words, $z_t(\om) \ap 0$ for all $\om \in \OM_0$.
\end{proof}

\begin{lemma}\label{lemma:A2}
Suppose $\{ X_t \} , \{ Y_t \} , \{ c_t \}, \{ d_t \}$ are $R_+$-valued are
stochastic processes defined on some probability space $(\OM,\SI,P)$,
taking values in $[0,\infty)$, adapted to some
filtration $\{ \F_t \}$, such that
\be\label{eq:A4}
E_t(X_{t+1}) \leq (1 - d_t + c_t) X_t + Y_t .
\ee
Suppose further that, almost surely,
\bd
\sum_{t=0}^\infty Y_t < \infty , \sum_{t=0}^\infty c_t < \infty ,
\sum_{t=0}^\infty d_t = \infty .
\ed
Then $X_t \ap 0$ as $\tai$ almost surely.
\end{lemma}

The lemma follows from Item 2 of Lemma \ref{lemma:A1} with
\bd
z_t = X_t , \d_t = c_t , \g_t = Y_t , \psi_t = X_t , \al_t = d_t ,
\eta(r) = r .
\ed

Now we come to the proof of Theorem \ref{thm:SHB}, which is given in stages.
As in \cite{Liu-Yuan-arxiv22}, the proof consists of showing that the combined
quantity $\Jb(\z_{t+1}) + \nmeusq{\v_{t+1} }$ satisfies the conditions of 
Lemma \ref{lemma:51}.
For this purpose, we find bounds for $E_t(\Jb(\z_{t+1}))$ and for
$E_t( \nmeusq{\v_{t+1} } )$ and add them.
Since there is a lot of computation involved, it is a good idea to
keep the overall objective in mind.
In \cite{Liu-Yuan-arxiv22}, in order to establish that $\Jb(\bth_t) \ap 0$,
it is assumed that $\al_t = \Theta(1/(t+1)^{1-\e})$
for some $\e \in (0,0.5)$.
By using Lemma \ref{lemma:A2}, we are able to do away with this assumption.
Instead, the assumption on the step sizes in Theorem \ref{thm:SHB}
reduces to the famiiar Robbins-Monro conditions if $b_t = 0$ and
$M_t$ is bounded.

Throughout various proofs, we make repeated use of the following
simple identity:
For $x,y \in \R, C > 0$, we have
\be\label{eq:51}
2Cxy \leq \e x^2 + \frac{C^2}{\e} y^2 , \fa \e > 0 .
\ee
To see this, note that
\bd
0 \leq \left( \sqrt{\e} x - \frac{C}{\sqrt{\e}} y \right)^2 
= \e x^2 + \frac{C^2}{\e} y^2 - 2Cxy .
\ed

We begin by providing an upper bound on $E_t( \nmeusq{ \bphH } )$.

\begin{lemma}\label{lemma:52}
Suppose Assumptions (D1), (D2) and (J1) hold.
Then
\be\label{eq:52}
E_t( \nmeusq{ \bphH } ) \leq (b_t^2 + b_t + M_t^2) 
+ H ( b_t +1 + M_t^2 ) \Jb(\bth_t) =: S .
\ee
\end{lemma}

\begin{proof}
Recall from \eqref{eq:326} and \eqref{eq:324} that
\bd
\bphH = \phH - \gJ(\bth_t) + \bzeta_{t+1} .
\ed
Since $E_t(\bzeta_{t+1}) = \bz$, it follows that
\be\label{eq:53a}
E_t ( \nmeusq{ \bphH } ) = \nmeusq{ \phH - \gJ(\bth_t) }
+ E_t( \nmeusq{ \bzeta_{t+1} } ) 
\ee
Define
\be\label{eq:53}
S_1 := \nmeusq{ \phH - \gJ(\bth_t) } , S_2 = E_t( \nmeusq{ \bzeta_{t+1} } ) .
\ee
% & =: & S_1 + S_2 . \label{eq:53}
% \eeq
Now Assumptions (D1) and (J1) imply that
\beq
% \nmeusq{ \phH - \gJ(\bth_t) } & \leq & \nmeusq{ \phH }
S_1 & \leq & \nmeusq{ \phH }
+ 2 \nmeu{ \phH } \cdot \nmeu{ \gJ( \bth_t ) } 
+ \nmeusq{\gJ(\bth_t)} \nonumber \\
& \leq & b_t^2 + b_t ( 1 + \nmeusq{ \gJ(\bth_t) })
+ \nmeusq{\gJ(\bth_t)} \nonumber \\
& \leq & b_t^2 + b_t ( 1 + H \Jb(\bth_t) ) + H \Jb(\bth_t ) ,
\label{eq:54}
\eeq
while Assumption (D2) implies that
\be\label{eq:55}
E_t( \nmeusq{ \bzeta_{t+1} } ) \leq M_t^2 ( 1 + H \Jb(\bth) )
\ee
Substituting from \eqref{eq:54} and \eqref{eq:55} into \eqref{eq:53a}
gives \eqref{eq:52}.
\end{proof}

\begin{lemma}\label{lemma:53}
Define $S$ to be the right side of the bound in \eqref{eq:52}.
Then, for every $\e_1 > 0$, we have that
\be\label{eq:56}
E_t( \nmeusq{\v_{t+1} } ) \leq \mu^2 \nmeusq{\v_t} 
+ \al_t^2 S \nonumber \\
+ \mu \al_t b_t (1 + \nmeusq{\v_t} ) \nonumber \\
+ \mu \left( \e_1 \nmeusq{\v_t} + \frac{\al_t^2}{\e_1} 
H \Jb(\bth_t) \right) .  
\ee
\end{lemma}

\begin{proof}
It follows from \eqref{eq:502} that
\be\label{eq:57}
\nmeusq{\v_{t+1} } = \mu^2 \nmeusq{\v_t} +\al_t^2
\nmeusq{\bphH } + 2 \mu \al_t \IP{\bphH }{\v_t}.
\ee
Lemma \ref{lemma:52} already shows that
\bd
E_t( \nmeusq{\bphH } ) \leq S ,
\ed
while $\nmeusq{\v_t} \in \M(\F_t)$.
These are the first two terms on the right side of \eqref{eq:56}.
So it remains only to bound the last term.
Define
\be\label{eq:58}
S_3 = E_t ( 2 \mu \al_t \IP{\bphH }{\v_t} ) .
\ee
Then
\beq
S_3 & = & 2 \mu \al_t \IP{E_t(\bphH)}{\v_t} \nonumber \\
& = & 2 \mu \al_t \IP{ \phH - \gJ(\bth_t) }{\v_t} \nonumber \\
& \leq & 2 \mu \al_t b_t \nmeu{\v_t} + 2 \mu \al_t 
\nmeu{\gJ(\bth_t)} \cdot \nmeu{\v_t} \nonumber \\
& \leq & \mu \al_t b_t (1 + \nmeusq{\v_t}) 
+ \mu \left( \e_1 \nmeusq{\v_t} + \frac{\al_t^2}{\e_1}H \Jb(\bth_t)
\right) , \label{eq:59}
\eeq
where in the last step we use Assumption (J1).
Substituting from \eqref{eq:59} into \eqref{eq:57} gives the desired conclusion.
\end{proof}

\begin{lemma}\label{lemma:54}
We have that, for every $\e_2 > 0$,
\beq
E_t(\Jb(\z_{t+1})) & \leq & \left(1 + \frac{H\al_tb_t}{2(1-\mu)}\right)\Jb(\z_t) 
+ \frac{\al_t^2 L}{2(1 - \mu)^2}S
+ \e_2 \nmeusq{\v_t} \nonumber \\
& - & \left[ \frac{\al_t}{ 1 - \mu}
- \frac{\al_t^2 \mu^2 L^2}{4\e_2(1-\mu)^4} \right]
\nmeusq{\gJ(\bth_t)} + \frac{\al_tb_t}{2(1-\mu)} . \label{eq:510}
\eeq
\end{lemma}

\begin{proof}
Recall from \eqref{eq:502a} that
\bd
\z_{t+1} = \z_t + \frac{\al_t}{1 - \mu} \bphH .
\ed
From \cite[Eq.\ (2.40)]{Ber-Tsi-SIAM00}, we know that
\bd
\Jb(\z_{t+1}) \leq \Jb(\z_t) + \frac{\al_t}{1 - \mu}
\IP{ \gJ(\z_t)}{\bphH } 
+ \frac{L}{2}\left( \frac{\al_t}{1 - \mu} \right)^2
\nmeusq{ \bphH } .
\ed
Therefore
\bd
E_t(\Jb(\z_{t+1}) ) \leq \Jb(\z_t) 
+ \frac{L}{2}\left( \frac{\al_t}{1 - \mu} \right)^2 S 
+ \frac{\al_t}{1 - \mu} S_4 ,
\ed
where
\beq
S_4 & = & E_t(\IP{ \gJ(\z_t)}{\bphH }) \nonumber \\
& = & \IP{ \gJ(\z_t)}{\phH - \gJ(\bth_t)} \nonumber \\
& \leq & b_t \nmeu{\gJ(\z_t)} - \IP{ \gJ(\z_t)}{\gJ(\bth_t)} \nonumber \\
& \leq & \frac{b_t}{2} (1 + \nmeusq{\gJ(\z_t)})
- \IP{ \gJ(\z_t)}{\gJ(\bth_t)} \nonumber \\
& \leq & \frac{b_t}{2} (1 + H \Jb(\z_t))
- \IP{ \gJ(\z_t)}{\gJ(\bth_t)} \label{eq:511}
\eeq
So now we bound the inner product.
Note that
\bd
- \IP{ \gJ(\z_t)}{\gJ(\bth_t)} = - \nmeusq{\gJ(\bth_t)} 
+ \IP{\gJ(\bth_t) - \gJ(\z_{t})}{\gJ(\bth_t)} .
\ed
Next, from the $L$-Lipschitz-continuity of $\gJ(\cdot)$, we have
\bd
\nmeu{\gJ(\bth_t) - \gJ(\z_{t})} \leq L \nmeu{ \bth_t - \z_{t} } 
= \frac{\mu L}{1 - \mu} \nmeu{\v_t} .
\ed
We conclude that
\bd
- \IP{ \gJ(\z_t)}{\gJ(\bth_t)} \leq - \nmeusq{\gJ(\bth_t)} 
+ \frac{\mu L}{1 - \mu} \nmeu{\gJ(\bth_t))} \cdot \nmeu{\v_t} .
\ed
Hence, for all $\e_2 > 0$, we have
\begin{eqnarray*}
\frac{\al_t}{1 - \mu} S_4 & \leq & - \frac{\al_t}{1 - \mu}
\nmeusq{\gJ(\bth_t)} 
+  \frac{\al_t \mu L}{(1 - \mu)^2} \nmeu{\gJ(\bth_t))} \cdot \nmeu{\v_t}
+ \frac{\al_tb_t}{2(1-\mu)} (1 + H \Jb(\z_t))\\
& \leq & - \frac{\al_t}{1 - \mu}
\nmeusq{\gJ(\bth_t)} 
+ \e_2 \nmeusq{\v_t}
+ \frac{\al_t^2 \mu^2 L^2}{4\e_2 (1- \mu)^4} \nmeusq{\gJ(\bth_t)} 
+ \frac{\al_tb_t}{2(1-\mu)} (1 + H \Jb(\z_t)).
\end{eqnarray*}
Substituting all of these bounds into
\be\label{eq:512}
E_t(\Jb(\z_{t+1})) \leq \Jb(\z_t) + \frac{ \al_t^2 L}{2(1-\mu)^2} S
+ \frac{\al_t}{1 - \mu} S_4 
\ee
and collecting the coefficients of
$\nmeusq{\gJ(\bth_t)}$ in one place gives the desired upper bound 
\eqref{eq:510}.
\end{proof}

We can now add the bounds for $\Jb(\z_{t+1})$ and $\nmeusq{\v_{t+1}}$.
However, these bounds involve $\Jb(\bth_t)$ or $\nmeusq{\gJ(\bth_t)}$.
We now show how to replace these by bounds involving
$\Jb(\z_t)$ and $\nmeusq{\gJ(\z_t)}$.

\begin{lemma}\label{lemma:55}
If Assumption (J1) holds, then
\be\label{eq:513}
\Jb(\bth_t) \leq \left( 1 + \frac{H}{2} \right) \Jb(\z_t)
+ \frac{\mu^2 (1+L)} {2(1-\mu)^2} \nmeusq{\v_t} ,
\ee
\end{lemma}

\begin{proof}
Observe that
\begin{eqnarray*}
\Jb(\bth_t) & \leq & \Jb(\z_t) - \frac{\mu}{1 - \mu}
\IP{\gJ(\z_t)}{\v_t} 
+ \frac{\mu^2 L}{2(1 - \mu)^2} \nmeusq{\v_t} \\
& \leq & \Jb(\z_t) + \half \nmeusq{\gJ(\z_t)} 
+ \frac{\mu^2}{2 (1 - \mu)^2 } \nmeusq{\v_t}  
+ \frac{\mu^2 L}{2(1 - \mu)^2} \nmeusq{\v_t} .
\end{eqnarray*}
After substituting $\nmeusq{\gJ(\z_t)} \leq H \Jb(\z_t)$, this gives
\eqref{eq:513}.
\end{proof}

\begin{proof}
(Of Theorem \ref{thm:SHB}:)
Lemmas \ref{lemma:52} through \ref{lemma:55} are essentially the
same as corresponding results in \cite{Liu-Yuan-arxiv22}.
However, in the present Theorem \ref{thm:SHB}, the assumptions on
the step size sequence $\{ \al_t \}$ are less restrictive.
So the method of proof here also differs from that in \cite{Liu-Yuan-arxiv22}.

Equation \eqref{eq:421} states that
\bd
\sum_{t=0}^\infty \al_t^2 < \infty ,
\sum_{t=0}^\infty \al_t b_t < \infty ,
\sum_{t=0}^\infty \al_t^2 M_t^2 < \infty .
\ed
The first equation implies that $\al_t \ap 0$ as $\tai$, which in turn
implies that $\al_t$ is bounded.
Combining this with the middle equation shows that
\bd
\sum_{t=0}^\infty \al_t^2 b_t < \infty .
\ed
Next, because every absolutely summable sequence is also square-summable,
we also have that
\bd
\sum_{t=0}^\infty \al_t^2 b_t^2 < \infty.
\ed

We can put Lemma \ref{lemma:53}, \ref{lemma:54}, \ref{lemma:55} together
and obtain an upper bound of the form
\be\label{eq:514}
E_t( \Jb(\z_{t+1}) + \nmeusq{\v_{t+1} } ) \leq \Jb(\z_t)
+ C_{1, t} + HC_{2, t} \Jb(\z_t) 
+ C_3 \nmeusq{\v_t} + HC_{4, t} \nmeusq{\v_t} - C_{5,t} \nmeusq{\gJ(\bth_t)},
\ee
where,
\bd
C_{1, t} = \left[\mu + \frac{1}{2(1-\mu)}\right]\al_tb_t
+ \left[1 + \frac{L}{2(1-\mu)^2}\right]\al_t^2(b_t^2 + b_t + M_t^2),
\ed
\bd
C_{2, t} =  \frac{\al_tb_t}{2(1-\mu)} + \al_t^2\left(1+\frac{H}{2}\right)
\left(\left[1 + \frac{L}{2(1-\mu)^2}\right]\left(b_t + 1 + M_t^2\right) + \frac{\mu}{\e_1}\right),
\ed
\bd
C_3  = \mu^2 + \mu\e_1 + \e_2,
\ed
\bd
C_{4, t} = \al_t^2\frac{\mu^2(1+L)}{2(1-\mu)^2}
\left(\left[1 + \frac{L}{2(1-\mu)^2}\right]\left(b_t + 1 + M_t^2\right) + \frac{\mu}{\e_1}\right)
\ed
\bd
C_{5,t} = \frac{\al_t}{ 1 - \mu}
- \frac{\al_t^2 \mu^2 L^2}{4\e_2(1-\mu)^4} .
\ed

Suppose the hypotheses \eqref{eq:421} holds.
Then, and by suitably choosing $\e_1$
and $\e_2$, we can ensure that
\bd
C_3  = \mu^2 + \mu\e_1 + \e_2 \leq 1 .
\ed
% make the ``constant'' coefficient of $\nmeusq{\v_t}$
Moreover, based on the observations above,
the sequences $\{ C_{1,t} \}, \{ C_{2,t} \} , \{ C_{4,t} \}$
are all square-summable.
Finally, since \eqref{eq:421} and \eqref{eq:422} hold, we have that
$C_{5,t} \geq 0$ for all $t \geq T$ for a suitably chosen $T$, and
\bd
\sum_{t=T}^\infty C_{5,t} 
= \sum_{t=T}^\infty \frac{\al_t}{ 1 - \mu}
- \sum_{t=T}^\infty \frac{\al_t^2 \mu^2 L^2}{4\e_2(1-\mu)^4} 
= \infty ,
\ed
because the first sum is infinite and the second sum is finite.
% and $C_{5, t}$ to be non-negative.
Now we can apply Lemma \ref{lemma:51} to \eqref{eq:514}
starting at time $t = T$.
% Then the Robbins-Siegmund theorem 
This leads to the conclusion that 
$\Jb(\z_t) + \nmeusq{\v_t}$ is bounded almost surely, and converges
almost surely to some random variable $W$.
Thus $\Jb(\z_t)$ and $\nmeusq{\v_t}$ are individually bounded.
Now Lemma \ref{lemma:55} shows that $\Jb(\bth_t)$ is bounded.
Lemma \ref{lemma:51} also implies that
\bd
\sum_{t=T}^\infty \al_t \nmeusq{ \gJ(\bth_t) } < \infty .
\ed
This, coupled with \eqref{eq:422}, shows that
\be\label{eq:515c}
\liminf_{\tai} \nmeusq{\gJ(\bth_t)} = 0 .
\ee
Together, these establish Item 1 of the theorem.

Now we go back to Lemma \ref{lemma:53}.
If $\Jb(\bth_t)$ is bounded, then so is $S$.
We can now rearrange \eqref{eq:56} in the form
\be\label{eq:515a}
E_t(\nmeusq{\v_{t+1}}) \leq \mu( \mu + \e_1) \nmeusq{\v_t}
+ \mu \al_t b_t (1 + \nmeusq{\v_t} ) + \al_t^2 \left(
S + \frac{ \mu \bar{H} }{\e_1} \Jb(\bth_t) \right) ,
\ee
The term inside parentheses is bounded, say by $M$.
% The last term on the right is summable because $\sum_{t=0}^\infty \al_t^2
% < \infty$.
Also, since $\mu < 1$, we can choose $\e_1$ such that $\mu( \mu + \e_1)
= 1 - \mu_0$ where $\mu_0 > 0$.
So now we can rewrite \eqref{eq:515a} as
\be\label{eq:515b}
E_t(\nmeusq{\v_{t+1}}) \leq (1 - \mu_0 + \mu \al_t b_t) \nmeusq{\v_t} 
+ \mu \al_t b_t + \al_t^2 M .
\ee
Now apply Lemma \ref{lemma:A2} with 
\bd
X_t = \nmeusq{\v_t} , d_t = \mu_0  \fa t ,
c_t = \mu \al_t b_t , Y_t = \mu \al_t b_t + \al_t^2 M .
\ed
Then it follows that $\nmeusq{\v_t} \ap 0$ as $\tai$, or $\v_t \ap \bz$
as $\tai$.

Next, as above let 
\bd
W(\om) = \lim_{\tai} \Jb(\z_t) + \nmeusq{\v_t} .
\ed
Because $\nmeusq{\v_t} \ap 0$, it follows that $\Jb(\z_t(\om)) \ap W(\om)$,
and also that $\Jb(\bth_t(\om)) \ap W(\om)$.
Now Assumption (J2) states that there exists a function $\eta$ of Class $\B$
such that $\gJ(\bth_t) \geq \eta(\Jb(\bth_t))$.
This assumption, coupled with \eqref{eq:515c} leads to the conclusion
(as in the proof of Item 2 of Lemma \ref{lemma:A1}) that
$W(\om) = 0$ almost surely.
Hence both $\Jb(\bth_t)$ and $\nmeusq{\gJ(\bth_t)}$ converge to zero
almost surely.

This completes the proof of Theorem \ref{thm:SHB} for the case of Option 1
(full coordinate update).
Now we analyze Options 2, 3 and 4.
From Lemma \ref{lemma:31}, specifically \eqref{eq:340}, we know that
\bd
E_t(\bphH^{(k)}) = E_t(\bphH^{(1)}) = \w_t , k = 2 , 3 , 4 .
\ed
Hence
\bd
\phH^{(k)} = E_t(\bphH^{(k)}) + \gJ(\bth_t) 
E_t(\bphH^{(1)}) + \gJ(\bth_t) = \phH , k = 2 , 3 , 4 .
\ed
We focus on the case $k = 2$.
It will be seen that the other two cases are entirely similar.
To mimic the proof for Option 1, we need a bound for
$E_t(\nmeusq{\bphH^{(2)}})$ analogous to \eqref{eq:52}.
Now observe that $\w_t = \phH - \gJ(\bth_t)$.
Also, from \eqref{eq:341a}, we have
\bd
E_t(\nmeusq{\bphH^{(2)}}) = d E_t(\nmeusq{\bphH^{(1)}}) \leq d S .
\ed
% \bd
% CV_t(\bphH^{(2)}) = (d-1) [ \nmeusq{\w_t} + E_t(\nmeusq{ \bzeta_{t+1} } ) ] .
% \ed
% Therefore a bound for $\nmeusq{\w_t}$ is provided  by \eqref{eq:54}, namely
% \bd
% \nmeusq{\phH - \gJ(\bth_t) } \leq S_1 ,
% \ed
% while \eqref{eq:53a} implies that
% \bd
% \nmeusq{\w_t} + E_t(\nmeusq{ \bzeta_{t+1} } ) \leq S_1 + S_2 = S .
% \ed
% Consequently
% \begin{eqnarray*}
% E_t(\nmeusq{\bphH^{(2)}}) & = & \nmeusq{ E_t(\bphH^{(2)}) }
% + CV_t(\bphH^{(2)}) \\
% & = & S_1 + (d-1) (S_1 + S_2) \leq d (S_1 + S_2) = d S.
% \end{eqnarray*}
Therefore we can simply replicate the proof for Option 1, with
$S$ replaced by $dS$.
The same holds for Option 3 as well.
For Option 4, again from \eqref{eq:341a} we have
% \bd
% CV_t(\bphH^{(4)}) \leq \frac{1-\r_t}{\r_t} ( S_1 + S_2 ) .
% \ed
% Hence
% \bd
% E_t(\nmeusq{\bphH^{(4)}}) \leq S_1 + \frac{1-\r_t}{\r_t} ( S_1 + S_2 )
% \leq \left[ 1 + \frac{1-\r_t}{\r_t} \right] S = \frac{1}{\r_t} S .
\bd
E_t(\nmeusq{ \bphH^{(4)} } ) 
= \frac{1}{\r_{t+1} } E_t( \nmeusq{\bphH^{(1)}} ) .
\ed
So we replace $S$ by $S/\r_{t+1}$ in the proof.
This establishes the convergence for all four options.
\end{proof}

\begin{proof}
\textbf{(Of Theorem \ref{thm:SHB-A}):}
We begin with Option A.
Recall \eqref{eq:341a}, which is quite similar to \eqref{eq:341}.
Hence, as in the proof of Theorem \ref{thm:SHB}, once convergence is
established with the search direction $\bphH^{(1A)}$ (Option 1A),
convergence follows for Options 2A, 3A and 4A.

When the search direction is $\bphH^{(1A)}$, we have from Lemma
\ref{lemma:34}, specifically \eqref{eq:3212}, that
\bd
\nmeu{ E_t(\bphH^{(1A)}) + \gJ(\bth_t) } \leq \frac{\sqrt{d} L c_t}{2} .
\ed
Next, it follows from \eqref{eq:3214a} and Assumption (D3) that
\bd
CV_t(\bphH^{(1A)}) \leq \frac{a_0^2}{c_t^2} .
\ed
Now we apply Theorem \ref{thm:SHB} with
\bd
b_t = \frac{\sqrt{d} L c_t}{2} , M_t^2 = \frac{a_0^2}{c_t^2} .
\ed
Then, since $\sqrt{d}L$ and $a_0^2$ are just constants,
\eqref{eq:424} imply \eqref{eq:421}.
So the desired convergence follows for all Class A Options.

The convergence of Option 1B requires just a bit more book-keeping.
First, Lemma \ref{lemma:32}, specifically \eqref{eq:353}, shows that
\bd
\nmeu{ E_t(\bphH^{(1B)}) + \gJ(\bth_t) } \leq d^{3/2} L c_t =: b_t .
\ed
Next, an upper bound for $CV_t(\bphH^{(1B)})$ is given in \eqref{eq:356}.
Using the by now familiar approach of bounding $2 \nmeu{\gJ(\bth_t)}$ by
$1 + \nmeusq{\gJ(\bth_t)}$, we can rewrite \eqref{eq:355} in the form
\bd
K_t \leq a_1 + a_2 \nmeusq{\gJ(\bth_t)}
\ed
for suitable constants $a_1, a_2$ which are $O(c_t)$.
Thus
\bd
CV_t(\bphH^{(1B)}) \leq a_1 + a_2 \nmeusq{\gJ(\bth_t)} + \frac{a_0^2}{c_t^2} .
\ed
This can be rewritten in the form \eqref{eq:416} for some $M_t^2 
= O(1/c_t^2)$.
Now we apply Theorem \ref{thm:SHB} as above.
This establishes the convergence with Option 1B, and the convergence of
the other Class B options follows as before.
\end{proof}

%This observation, coupled with \eqref{eq:422}, show that
% This is the first part of the conclusions.
% Second, suppose \eqref{eq:422} also holds.
% Then
% By arguments in the proof of
% \cite[Theorem 1]{MV-TUKR-ICML23}, the other conclusions follow.

Note that the proof of Theorem \ref{thm:SHB} is based on an extension
of the Robbins-Siegmund theorem, given here as Lemma \ref{lemma:A2}.
This lemma can be adopted in a straight-forward manner to obtain
the \textit{rate} of convergence, stated as \cite[Lemma 2]{Liu-Yuan-arxiv22},
and restated here as Lemma \ref{lemma:56} for the convenience of the reader.
Moreover, our proof applies not only to the case of full coordinate update 
(Option 1), but also to the three forms of batch-updating (Options 2, 3, 4).
Therefore, once Theorem \ref{thm:SHB} is proved, Theorem \ref{thm:SHB-Rate}
follows readily from Lemma \ref{lemma:56}.
% from the following result, stated as 
% \cite[Lemma 2]{Liu-Yuan-arxiv22}.
% See also the Remark after the lemma.
Since the proof is completely analogous to the cited result, it is omitted.

\begin{lemma}\label{lemma:56}
Suppose $\{ X_t \}$ is a sequence of nonnegative real numbers,
and $\{ \al_t \}$ is a sequence of decreasing positive real numbers.
Suppose further that
\be\label{eq:514}
\sum_{t=0}^\infty \al_t X_t < \infty , 
\sum_{t=1}^\infty \frac{\al_t}{ \sum_{\t=0}^{t-1} \al_\t } = \infty .
\ee
Define
\be
w_t = \frac{2 \al_t}{ \sum_{\t=0}^{t-1} \al_\t } ,
\ee
\bd
Y_{t+1} = (1 - w_t) Y_t + w_t X_t, \fa t \geq 0 , Y_0 = X_0 .
\ed
Then
\be\label{eq:515}
Y_t = o \left( \frac{1}{ \sum_{\t=0}^{t-1} \al_\t } \right) ,
\ee
\be\label{eq:516}
\min_{0 \leq \t \leq t} X_\t = 
o \left( \frac{1}{ \sum_{\t=0}^{t-1} \al_\t } \right) .
\ee
\end{lemma}

\section{Numerical Examples}\label{sec:Num}

In this section, we present the outcomes of several numerical experiments.
Specifically, we applied batch updating in
% This section outlines the implementation and evaluation of batch updating for
various standard optimization algorithms, such as SGD, SHB, SNAG, ADAM, NADAM,
and RMSPROP optimizers \footnote{The author is referred to \cite{Ruder-arxiv16}
for the brief description of these optimization algorithms.}.
In the case of SNAG, we studied two variants: NAG\_F where the step size
$\al_t$ is varied and the momentum term $\mu$ is fixed, and NAG\_S
where the momentum term $\mu_t$ is scheduled according to the Nesterov's
sequence \cite{Nesterov-Dokl83}, and $\al_t = \al_0$, a fixed constant.
While applying these algorithms,
we used both noise-corrupted actual gradients, as well as approximate gradients
based on noisy measurements.

We implemented four different options, namely Options 1, 1B, 4, and 4A, 4B.
That is, we implemented full updating with both noisy and approximate
gradients, and also batch updating where
the components to be updated at each time were chosen via
independent Bernoulli processes with a success rate of $\r$, which was
varied over a range of values.
To simulate noisy conditions, additive white Gaussian noise (AWGN) was added
with various signal-to-noise ratios (SNRs).
We used step and increment sequences of the form
\bd
\al_t = \frac{\al_0}{(1 + (t/\tau))^p},
c_t = \frac{c_0}{(1 + (t/\tau))^q}, \mu = 0.9 , \fa t .
\ed
where $\tau$ = 200, $\al_0 = 10^{-6}$, $c_0 = 10^{-4}$, $p = 1$,
and $q = 0.01$. For comparison, we set $\alpha_0$ to be the same
in ADAM, NADAM, and RMSPROP.
For SGD \&  NAG\_F, we used the same $\al_t$ and $\mu$(=0 in case of SGD),
while for NAG\_S, we chose $\al_t = 10^{-6}$ and 
$\mu_t$ to be the Nesterov sequence.

To evaluate the performance of batch updating, we chose the convex
objective function
\bd
J(\bth_t) = \bth_t^\top A \bth_t + \log \left( \sum_{i=0}^{d-1}e^{\th_{t, i}}
\right) ,
\ed
where $\bth_t$ is a vector of 1 million parameters,
and $A$ is a block-diagonal matrix of size ($10^6 \times 10^6$) consisting
of 100 Hilbert matrices, each of dimension $10^4 \times 10^4$.
The Hilbert matrix is known to be notoriously ill-conditioned,
and as its eigenvectors are not aligned with elementary basis vectors
\cite{Fettis-MC67}.
Therefore this represents a good choice for testing the
robustness of batch updating.

Here are the implementation details.
We implemented the
algorithms in \textit{Python} using the \textit{PyTorch} framework.
The experiments were conducted on a workstation equipped with an
Intel Xeon Silver 4114 CPU @ 2.20GHz, 256 GB RAM,
and 4 NVIDIA GeForce RTX 2080 Ti GPUs, each with 12GB of memory.

\begin{figure*}[ht]
\centering
\includegraphics[width=80mm]{exact_final.eps}
\includegraphics[width=80mm]{exact_bcd_final.eps}
\caption{[LEFT] Option 1; [RIGHT] Option 4}
\label{fig:exact}
\end{figure*}

The results, as shown in Figure \ref{fig:exact}, demonstrate that
when noisy gradients are used, ADAM, NADAM and RMSPROP comfortably
outperform the other four methods.
Within those four, NAG\_S outperforms SHB, which in turn outperforms NAG\_F.
As expected, SGD performs the worst of all.
Moreover, the convergence of ADAM, NADAM, and RMSPROP with Option 4 and
$\r = 0.2$ (only 20\% of components updated at each iteration) is comparable
to that of full update, after accounting for the reduced updating.
However, when approximate gradients are used in place of noisy gradients,
as shown in Figure \ref{fig:approx}, NAG\_S diverges almost immediately, 
while ADAM, NADAM, and RMSPROP neither converge nor diverge.
In fact, these three methods perform worse than even SGD.
Among the rest, SGD converges the most slowly, NAG\_F is intermediate,
and SHB performs the best.

Thus, the use of approximate gradients apparently makes it infeasible to use
NAG\_S, ADAM, NADAM, and RMSPROP, whether with full or batch updates.
As pointed out earlier, implementing batch updates with noisy gradient
does not lead to much savings in CPU time because computing only some
components of the gradient vector is almost as CPU-intensive as computing
the entire gradient.
In contrast, with approximate gradients, the amount of computation is
proportional to $\r$ when Option 4B is used.
The fact that all three methods (SGD, NAG\_F, and SHB) all converge
despite using approximate gradients is very encouraging.

\begin{figure*}[ht]
\centering
\includegraphics[width=80mm]{approx_final.eps}
\includegraphics[width=82mm, height=72mm]{approx_bcd_final.eps}
\caption{[LEFT] Option 1B; [RIGHT] Option 4B}
\label{fig:approx}
\end{figure*}

\begin{figure*}[ht]
\centering
\includegraphics[width=\textwidth]{approx_bcd_all_diff_delta_final.eps}
\caption{Option 4B at different $\rho$}
\label{fig:varyrho}
\end{figure*}

Figure \ref{fig:varyrho} shows that , as expected,
reducing $\rho$ results in slower
convergence because parameters are updated less frequently.
However, the iterations still converge for values of $\r$ as small as $0.1$,
that is, only 10\% of the components of $\bth_t$ are
updated on average at each iteration.

We also tested the robustness
of the batch updating schemes at various noise levels.
The results are shown in Figure \ref{fig:varysnr}. The convergence
rates of these algorithms are comparable at all SNR levels.%
%this is because
%of implicit noise arising due to approximate gradients, which are computed
%using SPSA.

\begin{figure*}[ht]
\centering
\includegraphics[width=\textwidth]{approx_bcd_all_diff_snrs_final.eps}
\caption{Option 4B at different SNR levels}
\label{fig:varysnr}
\end{figure*}

\begin{figure}[ht]
\centering
\includegraphics[width=0.6\columnwidth]{4a_4b.eps}
\caption{Option 4A (124.5 ms/it) and Option 4B (7.8 ms/it) at SNR of 20dB and
$\r$ = 0.01}
\label{fig:avsb}
\end{figure}

Finally, we compare Option 4A (2$d$ evaluations) and Option 4B (2 evaluations)
with 10000. 
Figure \ref{fig:avsb} shows that there is no significant difference in the results.
However, Approach A has a better upper bound than Approach B in terms of 
condtional variance. Option 4A takes 124.5 ms/iteration with just $\r$=1\%, 
whle Option 4B takes 7.8 ms/iteration. Therefore, Approach A is more computationally
intensive, and the benefits from lower bounds on the
conditional variance are not seen in practice.
 
\section{Conclusions and Future Work}\label{sec:Conc}

In this paper, we have proposed a general framework for analyzing the
convergence of batch updating methods in convex and nonconvex optimization.
In addition to full-coordinate updating which we call Option 1,
we have proposed three different batch updating methods
(called Options 2, 3, 4).
These include almost all the widely used batch updating, or
coordinate-updating methods that are currently used.
By relating the conditional expectation and the conditional variance
of Options 2, 3, and 4 to those of Option 1, we provide a general
methodology for proving the convergence of batch updating methods.
As a specific application, we have analyzed the well-known Heavy Ball method.
In addition to the use of batch updating, we also permit the use of
approximate gradients, based on just two function evaluations.
We are able to prove the convergence of the Stochastic Heavy Ball method
under each of these bat updating methods, with the use of either noisy
or approximate gradients.
Because our proof is based on some mild generalizations of the
well-known Robbins-Siegmund theorem \cite{Robb-Sieg71},
in principle our work will work with other optimization methods as well.
Our current plan is to extend the present results to methods such as
ADAM and RMSPROP, by adapting the methods of \cite{Bara-Bian-SIAM21}.
% We have established some useful relationships on the conditional variance
% of the resulting measurement errors in each case.
% Using these bounds, we are able to prove the convergence of the Stochastic
% Heavy Ball method in a variety of situations.

We have also carried out a series of numerical computations to demonstrate the
following tentative conclusions:
\bit
\item When batch updating is applied to noisy gradients, methods such as
ADAM, NADAM, and RMSPROP outperform Stochastic versions of pure gradient
descent, Heavy Ball, and two variants of Nesterov's method.
\item However, when batch updating is applied to approximate gradients,
Nesterov's original method diverges, while ADAM, NADAM, and RMSPROP
barely show any reduction in the objective function.
In fact, they perform worse than the plain steepest descent.
On the other hand, Stochastic Heavy Ball performs the best.
\eit
Therefore further theoretical analysis is required to explore
why this is so.

\input{V5-Heavy-Ball-arxiv.bbl}

% \bibliographystyle{IEEEtran}
% \bibliography{ML,Opt}

\end{document}
