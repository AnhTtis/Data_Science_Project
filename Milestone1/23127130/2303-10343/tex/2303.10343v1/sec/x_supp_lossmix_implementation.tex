\vspace{0.5em}
\section{LossMix Implementation}
\vspace{0.5em}
\paragraph{Data Selection} In our implementation of LossMix, we follow the recommendation of Mixup~\cite{mixup} and mix two data points/images together. We did not experiment with mixing three or more data points/images. To minimize the I/O requirements, we use a single data loader. Each minibatch is then mixed with a randomly shuffled version of itself. 
Another implementation that uses a single loader is to reverse the minibatch, as used by 
{FixMatch}~\cite{fixmatch}, or to shift all elements by one index.
% \href{https://github.com/google-research/fixmatch/blob/master/mixup.py\#L37}

\paragraph{Input Mixing}
For each pair of data points, we use a $\text{Beta}(\alpha, \alpha)$ distribution to sample a mixing coefficient $\lambda$. 
We set $\alpha$ to $1.0$ by default,
following \cite{bof}.
This results in a uniform sampling distribution for $\lambda$.
When mixing two images, we first center-align them, then create a mixed output image with dimensions equal to the maximum height and width of the original images.
We pad the resulting image with zeros to maintain the original aspect ratios, which is important for preserving the aspect ratios and geometry of instances in object detection.
We do not experiment with other alignment options, such as aligning by the image origin $(0, 0)$ or using random translations. The effects of different $\alpha$ values on LossMix are presented in \Table{det_abl}.

\paragraph{Target Mixing}
According to \Equation{our_y}, the augmented ground truth for the mixed image is an implicitly weighted union of the original ground truth: $\tilde{y} = \{(y_i; \lambda), (y_j; (1 - \lambda)\}$, where $\lambda$ is the mixing coefficient sampled from a Beta distribution as described in the previous paragraph.
In the case of object detection, the label $y$ is a set of instance ground truth, which is a collection of objects in the image, each with its corresponding class labels and bounding box coordinates.
For example, $y_i$ could be a set of objects $\{(c_{i1},b_{i1}), (c_{i2},b_{i2}),\ldots\}$ present in the image $x_i$.
$c_{ik}$ denotes the class label of object $k$ and $b_{ik}$ represents its corresponding bounding box coordinates.
After mixing, all objects of $y_i$ will share the same mixing weight $\lambda$ of the image, while those of $y_j$ will have weight $(1 - \lambda)$.
These instance-level weights will then be used for loss mixing as described in \Equation{our_loss} and \Equation{det_loss_mix}.
Finally, all bounding box coordinates are adjusted appropriately based on the alignment operation in the \textbf{Input Mixing} step described above.

