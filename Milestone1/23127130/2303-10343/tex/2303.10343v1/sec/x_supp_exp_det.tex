\input{fig/phases}

\section{Object Detection Experiments}
We leverage the open-source PyTorch-based Detectron2~\cite{detectron2} as our codebase for object detection experimentation.
Faster RCNN~\cite{faster_rcnn} with ResNet~\cite{resnet}--FPN~\cite{fpn} backbone is employed as our baseline architecture.
All backbones use Synchronized Batch Normalization, which we found to be either on par or better then frozen BatchNorm in most cases.
Unless otherwise specified, we follow most of the default configurations of Detectron2 for both PASCAL VOC~\cite{pascal} and MS COCO~\cite{coco} datasets. 
Specifically, we use ImageNet1K~\cite{imagenet} pretrained weights to initialize the ResNet-50 and ResNet-101~\cite{resnet} backbones.
We use Stochastic Gradient Descent (SGD) optimizer
and random horizontal flipping.
We use a batch size of 64 for faster convergence, an initial learning rate of 0.08, and the default step scheduler from Detectron2.
We use linear warm-up for $100$ iterations with a warm-up factor of $0.001$.
All models use multi-scale training with smallest image side randomly sample from $(480,\ldots, 800)$ for VOC and $(640,\ldots, 800)$ for COCO, both with an increment of $32$. 
The minimum image side at test time is set to $800$ and the maximum for both training and testing is $1333$ by default.
We train PASCAL VOC for 18,000 iterations, which is about 70 epochs, and MS COCO for 270,000 iterations ($3\times$ schedule), equating about 146 epochs.
All experiments were trained with 8 NVIDIA GPUs, either V100 or A100.


Regarding the implementation of other methods, we sample $\lambda \sim \text{Beta}(1.0, 1.0)$ for the popular unweighted \textit{Union} mixing strategy~\cite{union_da_fewshot_acrofod,union_instseg_seesaw,union_mot_bytetrack,bof,union_ssl_dual,union_ssl_instant_teaching}, similar to the setting for our LossMix.
For \textit{Noise} mixing strategy~\cite{afan}, we randomly sampled $\lambda \sim \text{U}(0.0, 0.2)$, i.e., a small mixing ratio from an uniform distribution with an arbitrary upper bound of $0.2$ and only keep the instance labels of the image with the larger coefficient $(1-\lambda)$.
For LossMix-Reg model in \Table{det_abl} deploying LossMix in a RegMixup~\cite{regmixup}-style, we set half of the total batch size to be mixed data and the other half to be regular, non-mixed data, which have effective loss weights of $\lambda=1.0$.

