\section{Domain Adaptation Experiments}
\vspace{0.4em}
For our domain adaptation experiments, we use the official open-source repository published by Adaptive Teacher~\cite{amt}, which is also built with Detectron2~\cite{detectron2}.
For a fair comparison, we follow previous works~\cite{umt,amt} and use Faster RCNN~\cite{faster_rcnn} with a ResNet-101~\cite{resnet} backbone. 
All images are resized to have a shorter side of $600$ while maintaining their aspect ratios. The confidence threshold for filtering pseudo labels is set to $0.8$. 
Weak augmentations include random horizontal flipping and cropping, while strong augmentations include random color jittering, grayscaling, Gaussian blurring, and cutout. The weight smoothing coefficient of the exponential moving average (EMA) for updating the Teacher model is set to $0.9996$. For simplicity, we keep all loss weights for labeled and pseudo-labeled examples (\Equation{loss_warm} and \Equation{loss_adapt}) at $1.0$ and do not tune them. We use Adaptive Teacher's default weight of $0.1$ for the discriminator branch.

\vspace{1em}

We found that the set of training hyperparameters reported in Adaptive Teacher \cite{amt} yield suboptimal results for the open-sourced codebase.
The authors confirmed that there are instability issues\footnote{\href{https://github.com/facebookresearch/adaptive_teacher/issues/26\#issuecomment-1192059882}{adaptive\_teacher/issues/26\#issuecomment-1192059882}} 
and were only able to achieve an mAP of $45.6$\footnote{\href{https://github.com/facebookresearch/adaptive_teacher/issues/9\#issuecomment-1193174238}{adaptive\_teacher/issues/9\#issuecomment-1193174238}} 
instead of the reported mAP of $49.3$ in their paper \cite{amt}. 
This is because the open-sourced code is built with Detectron2 \cite{detectron2}, while their original internal code was built with D2GO\footnote{\href{https://github.com/facebookresearch/adaptive_teacher/issues/9\#issuecomment-1134933287}{adaptive\_teacher/issues/9\#issuecomment-1134933287}}.
To ensure a fair comparison, we tuned the hyperparameters and report our best mAP number of $46.7$ for Adaptive Teacher in Table \Table{voc_clip}. 
Specifically, we performed a grid search over batch sizes of $\{8,2\}$ and learning rates of $\{0.002, 0.005, 0.01\}$ for both the baseline Adaptive Teacher and our model trained with LossMix. The total training consisted of 60,000 iterations, with 20,000 iterations for warm-up and 40,000 iterations for adaptation. We observed that most models reach their peak performance within the first 20K steps of the adaptation phase (after the warm-up phase). 
If the instability issues are resolved, the results for both the reproduced AT (mAP=$46.7$) and our LossMix (mAP=$51.1$) in  \Table{voc_clip} could potentially improve.

