{
    "arxiv_id": "2303.10343",
    "paper_title": "LossMix: Simplify and Generalize Mixup for Object Detection and Beyond",
    "authors": [
        "Thanh Vu",
        "Baochen Sun",
        "Bodi Yuan",
        "Alex Ngai",
        "Yueqi Li",
        "Jan-Michael Frahm"
    ],
    "submission_date": "2023-03-18",
    "revised_dates": [
        "2023-03-21"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
    ],
    "abstract": "The success of data mixing augmentations in image classification tasks has been well-received. However, these techniques cannot be readily applied to object detection due to challenges such as spatial misalignment, foreground/background distinction, and plurality of instances. To tackle these issues, we first introduce a novel conceptual framework called Supervision Interpolation, which offers a fresh perspective on interpolation-based augmentations by relaxing and generalizing Mixup. Building on this framework, we propose LossMix, a simple yet versatile and effective regularization that enhances the performance and robustness of object detectors and more. Our key insight is that we can effectively regularize the training on mixed data by interpolating their loss errors instead of ground truth labels. Empirical results on the PASCAL VOC and MS COCO datasets demonstrate that LossMix consistently outperforms currently popular mixing strategies. Furthermore, we design a two-stage domain mixing method that leverages LossMix to surpass Adaptive Teacher (CVPR 2022) and set a new state of the art for unsupervised domain adaptation.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.10343v1"
    ],
    "publication_venue": null
}