In this paper, we propose to synthesize hand-object interactions from a given object image. We explicitly reason about \textit{where} to interact and \textit{how} to interact by LayoutNet and ContentNet. Both of them are implemented as diffusion models to achieve controllable and high-quality visual results. The synthesized HOI images enable a shortcut to more plausible 3D affordance via reconstructing hand poses from them. Although the generation quality and the consistency between the extracted 3D poses and images can be further improved, we believe that  HOI synthesis along with our proposed solution opens doors for many promising applications and contributes towards the general goal of understanding human interactions in the wild. 