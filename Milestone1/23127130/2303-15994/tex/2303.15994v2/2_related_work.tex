\begin{figure*}[h!]
\begin{center}
\includegraphics[width=\linewidth]{hilo_overview.pdf}
\end{center}
\vspace{-2mm}
\caption{An overview of our HiLo framework with HiLo baseline.
a) HiLo relation swapping module swaps the multiple relations in the subject-object pair to obtain H-L Data and L-H Data respectively.
b) Input data into our HiLo framework with HiLo baseline model, there are two branches, namely H-L decoder and L-H decoder, which learn H-L Data and L-H Data respectively.
c) In addition to task losses for PSG, we propose HiLo prediction alignment, which includes subject-object consistency loss and relation consistency loss, so that the parallel branch can be better optimized.
}
\vspace{-4mm}
\label{figure:hilofex_baseline}
\end{figure*}

\subsection{Scene Graph Generation}
The Scene Graph Generation (SGG) \cite{lu2016visual} task plays a crucial role in connecting vision and language, and has received widespread attention in the computer vision community.
Many methods have been proposed to improve the performance of SGG, which can be classified into three categories \cite{zhu2022scene}.
The first is to introduce multi-modal information, such as appearance \cite{sadeghi2011recognition}, space \cite{zhu2017visual}, depth \cite{sharifzadeh2021improving}, and segmentation \cite{khandelwal2021segmentation}.
The second is to introduce prior information and commonsense knowledge, such as statistical \cite{baier2017improving, dai2017detecting, zellers2018neural, chen2019knowledge} and language prior knowledge \cite{lu2016visual, liao2019natural, zhang2019large, hwang2018tensorize, dupty2020visual}.
The third category involves designing different model structures, such as message passing \cite{li2017vip, dai2017detecting, li2017scene, zellers2018neural, gu2019scene, hu2022neural}, attention mechanisms \cite{zheng2019visual, qi2019attentive}, tree structures and visual translation \cite{zhang2017visual, hung2020contextual}. However, most of these methods are two-stage methods that cannot learn scene graphs end-to-end.
%
In contrast, to improve the learning ability of SGG models, several methods based on transformers have been proposed, including SGTR \cite{li2022sgtr}, RelationFormer \cite{shit2022relationformer} and RelTR \cite{cong2023reltr}. These are end-to-end trainable in a single stage.

\subsection{Unbiased Scene Graph Generation}
Solving the long-tail problem in the SGG task has attracted considerable attention from researchers, and several unbiased methods \cite{tang2020unbiased, yu2020cogtree, chiou2021recovering, desai2021learning, guo2021general, li2021bipartite, dong2022stacked, goel2022not, li2022devil, li2022ppdl, deng2022hierarchical, zhang2022fine} have been proposed.
These methods typically improve the model from the perspective of data re-sampling~\cite{li2021bipartite} or a class-balanced loss~\cite{kang2023skew}.
BGNN \cite{li2021bipartite} uses a two-layer re-sampling strategy to provide a more balanced data distribution during training, while CogTree \cite{yu2020cogtree} proposal exploits the semantic relation between different predicate classes to design a novel CogTree loss.
HML \cite{deng2022hierarchical} improves the model's ability to solve long-tail problems by designing a staged training process, and IETrans~\cite{zhang2022fine} proposes an internal and external transfer method to transfer high frequency relations to low frequency relations and recover missing relations to train the unbiased model.
%
Dong \etal~\cite{dong2022stacked} propose to group relations by their frequency and train specialized relation encoders for each group. 
While these methods are able to mitigate the long-tail problem, they do not address relational semantic overlap.

\subsection{Panoptic Scene Graph Generation}
Contrary to SGG, the PSG task~\cite{yang2022panoptic} uses panoptic segmentation masks instead of bounding boxes to represent objects, resulting in a more comprehensive scene graph.
PSGTR \cite{yang2022panoptic}, an end-to-end method based on the DETR structure, was proposed to construct a transformer-based PSG model.
PSGFormer~\cite{yang2022panoptic} further improved on PSGTR by introducing Object \& Relation Query Learning Blocks and Query Matching Blocks. Their strong performance on most relation classes indicates that their method is implicitly unbiased. In contrast, our approach is the first to explicitly bias a PSG model, creating separate branches for low and high frequency relations, which are then fused together.

Since the scene graph in PSG is built upon the subjects, objects and their relations, strong panoptic segmentation~\cite{kirillov2019panoptic} is crucial for PSG.
Several DETR-based \cite{carion2020end} methods such as Deformable-DETR \cite{zhu2020deformable}, Segmenter \cite{strudel2021segmenter}, MaskFormer \cite{cheng2021per} and Mask2Former \cite{cheng2022masked} have recently pushed the envelope in panoptic segmentation.
These methods have introduced deformable transformer encoders and decoders, as well as pixel decoders and multi-scale information to improve model performance and speed up convergence.
Our proposed baseline builds upon these techniques to further enhance the PSG performance and speed up model convergence.