\section{Conclusion}
\label{sec:conclusion}

This work aimed to explore different design approaches to communicate three-dimensional directional cues with vibrotactile feedback. We developed two conditions based on the \emph{Cutaneous Rabbit} illusion and one based on \emph{Apparent Tactile Motion} to communicate 2D direction. The gradient of the overall 3D direction was then encoded by the number of discrete vibration pulses, the vibration intensity, or a combination of both.
Our study showed that three-dimensional directional cues can be communicated by \conA and \conB with a high success rate for both the 2D direction and gradient (median for \conA: 91.7\%, \conB: 93.3\%) -- significantly better compared to \conC. With respect to our research questions, we found partial evidence for RQ1, as multiple participants specifically mentioned the dual mapping for gradient as a benefit. Still, for the quantitative data, both \emph{Rabbit} conditions performed more or less identical. RQ2 has to be dismissed at this point. However, as revealed by our qualitative analysis, we believe that the \emph{Apparent Tactile Motion} illusion can also be a viable option for future designs, as the smooth transition between actuators was appreciated by participants. The challenge will lie in overcoming the inferences we found between 2D directional and gradient intensity mapping.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/intendedMovement_both.png}
    \caption{\change{An assistive robotic arm with AI-created directional movement recommendations. The cyan arrow indicate the current movement direction of the arm, while the blue arrow shows the recommendation, which would be mapped as 3D directional cues on the glove. Note: The cyan and blue arrows are only for presentation purposes.}}
    \Description{An overview of a human-robot interaction scenario for future work. A robotic arm (Kinova Jaco) is mounted on a table. The robot is trying to grasp a blue object, and a visual cue (blue arrow) illustrates the intended movement direction toward the object. A cyan arrow points more down toward the table surface, missing the object.}
    \label{fig:future}
\end{figure}

\textbf{Future Research:}  In our work, we aim to apply this approach to communicate the intended movements~\cite{Pascher.2023robotMotionIntent} of a semi-autonomous robot in collaborative scenarios, where vision alone may not be sufficient to successfully predict robot motion. \change{In \autoref{fig:future} an assistive robot arm is illustrated, which is manually controlled by the user but is supported through an \ac{AI} which provides real time directional movement recommendations. Here, our approach could be used to map these directional movement recommendations as vibration input on the hand. Changes in the intensity of the actuators indicate the amount of directional change, thus enabling the user to better imagine the generated trajectory.}
We also encourage researchers to both replicate our design and study and apply it to different use cases. 
Future research should also investigate variables such as the effect of higher-resolution tactile displays\change{, different setting of actuators,} or other approaches to encode gradient (e.g. through different vibration frequencies, \change{varying linear and non-linear intensity levels}), which were not possible with the \emph{SensorialXR} technology.
\change{Furthermore, results of our study should also be evaluated with participants with a dominant left hand or their non-dominant hand.}