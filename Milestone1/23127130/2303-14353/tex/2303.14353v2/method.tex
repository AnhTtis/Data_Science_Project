\section{Method}
In this work, we propose a novel perspective on solving ill-posed inverse problems. In particular, we assume that our noisy observation $\vct{\tilde{y}}$ results from a process that gradually applies more and more severe degradations to an underlying clean signal. 
% In particular, we assume that our observation is the result of gradually degrading and noising a clean signal  $\vct{x}_0$ through a \textit{stochastic degradation process} (to be defined more rigorously shortly)
%\begin{equation}
%	\vct{y}_t = \fwd{t}{\vct{x}_0} + \vct{z}_t, ~ \vct{z}_t \sim \gaussian{\sigma_t^2}, ~~t\in[0,1]
%\end{equation}
%where $ \fwd{t}{\cdot}$ is a deterministic function and $t$ parameterizes the \textit{severity} of the degradation. Lower values of $t$ correspond to less severely corrupted versions of the original clean signal. 
\subsection{Degradation severity}
To define severity more rigorously, we appeal to the intuition that given two noiseless, degraded signals $\vct{y}$  and $\vct{y}^+$  of a clean signal $\vct{x}_0$, then  $\vct{y}^+$ is corrupted by a more severe degradation than $\vct{y}$, if $\vct{y}$ contains all the information necessary to find $\vct{y}^+$ without knowing $\vct{x}_0$.
\begin{definition}[Severity of degradations]
	A mapping $ \mathcal{A}_+:\mathbb{R}^n  \rightarrow \mathbb{R}^n $ is a \textit{more severe degradation than}    $ \mathcal{A}:\mathbb{R}^n  \rightarrow \mathbb{R}^n $ if there exists a surjective mapping $ \mathcal{G}_{\mathcal{A} \rightarrow \mathcal{A}_+}:Image( \mathcal{A})  \rightarrow Image( \mathcal{A}_+) $. That is,
	\begin{equation*}
		\mathcal{A}_+(\vct{x}_0) =  \mathcal{G}_{\mathcal{A} \rightarrow \mathcal{A}_+}(\mathcal{A}(\vct{x}_0)) ~~\forall \vct{x}_0\in dom(\mathcal{A}).
	\end{equation*}
	We call $\mathcal{G}_{\mathcal{A} \rightarrow \mathcal{A}_+}$ the \textit{forward degradation transition function} from $\mathcal{A}$ to $\mathcal{A}_+$.
\end{definition}	
%This definition formalizes the intuition that if we are given a degraded signal $y= \mathcal{A}(\vct{x}_0)$ and only given $y$ we can find $\mathcal{A}_+(\vct{x}_0) =  \mathcal{G}_{\mathcal{A} \rightarrow \mathcal{A}_+}(\mathcal{A}(\vct{x}_0)) =  \mathcal{G}_{\mathcal{A} \rightarrow \mathcal{A}_+}(y)$, then $\mathcal{A}_+$ must be a more severe degradation than $\mathcal{A}$, since  $y$ contains all the necessary information to find $\mathcal{A}_+(\vct{x}_0)$. 
Take image inpainting as an example (Fig.  \ref{fig:severity_plot}) and let $\mathcal{A}_t$ denote a masking operator that sets pixels to $0$ within a centered box, where the box side length is $l(t) = t\cdot W$, where $W$ is the image width and $t\in[0, 1]$. Assume that we have an observation $\vct{y}_{t'} = \mathcal{A}_{t'}(\vct{x}_0)$ which is a degradation of a clean image $\vct{x}_0$ where a small center square with side length $l(t')$ is masked out. Given $\vct{y}_{t'}$, without having access to the complete clean image, we can find any other masked version of $\vct{x}_0$ where a box with at least side length $l(t')$ is masked out. Therefore every other masking operator $ \mathcal{A}_{t''} ,~ t' < t''$ is a more severe degradation than $ \mathcal{A}_{t'}$. The forward degradation transition function $\mathcal{G}_{\mathcal{A}_{t'} \rightarrow \mathcal{A}_{t''}}$ in this case is simply $ \mathcal{A}_{t''}$. We also note here, that the \textit{reverse degradation transition function} $\mathcal{H}_{\mathcal{A}_{t''} \rightarrow \mathcal{A}_{t'}}$ that recovers $ \mathcal{A}_{t'}(\vct{x}_0)$ from a more severe degradation $ \mathcal{A}_{t''}(\vct{x}_0)$ for any $\vct{x}_0$ does not exist in general.

\begin{figure}[t]
	\centering
	\includegraphics[width=0.8\linewidth]{plots/severity_explain.pdf}
	\caption{ Severity of degradations: We can always find a more degraded image $\vct{y}_{t''}$ from a less degraded version of the same clean image $\vct{y}_{t'}$ via the forward degradation transition function $\mathcal{G}_{t'\rightarrow t''}$, but not vice versa. }
	\label{fig:severity_plot}
\end{figure}

\subsection{Deterministic and stochastic degradation processes}
Using this novel notion of degradation severity, we can define a deterministic degradation process that gradually removes information from the clean signal via more and more severe degradations.
\begin{definition}[Deterministic degradation process]
	A \textit{deterministic degradation process} is a differentiable mapping $ \mathcal{A}:[0, 1] \times \mathbb{R}^n  \rightarrow \mathbb{R}^n$ that has the following properties:
	\begin{enumerate}
		\item  \textit{Diminishing severity:} $ \mathcal{A}(0, \vct{x}) = \vct{x}$
		\item \textit{Monotonically degrading:} $\forall t'\in[0,1)$ and $t'' \in (t', 1]$ $\mathcal{A}(t'', \cdot)$ is a more severe degradation than $\mathcal{A}(t', \cdot)$.
	\end{enumerate}
\end{definition}
	We use the shorthand  $\mathcal{A}(t, \cdot) = \fwd{t}{\cdot}$ and $\mathcal{G}_{  \mathcal{A}_{t'} \rightarrow \mathcal{A}_{t''} } =\mathcal{G}_{t' \rightarrow t''}$ for the underlying forward degradation transition functions for all $t' < t''$.  Our deterministic degradation process starts from a clean signal $\vct{x}_0$ at time $t=0$ and applies degradations with increasing severity over time. If we choose  $\mathcal{A}(1, \cdot) = \mathbf{0}$, then all information in the original signal is destroyed over the degradation process. One can sample easily from the \textit{forward process}, that is the process that evolves forward in time, starting from a clean image $\vct{x}_0$ at $t=0$. A sample from time $t$ can be computed directly as $\vct{y}_t = \fwd{t}{\vct{x}_0}$.

% Alternatively, one may consider splitting the $[0,1]$ interval into small time increments $\Delta t$, and starting from $\vct{y}_0 = \vct{x}_0$ recursively compute $\vct{y}_{t+\Delta t} =  \mathcal{G}_{t \rightarrow t+\Delta t}(\vct{y}_t)$.

In order to account for measurement noise, one can combine the deterministic degradation process with a stochastic noising process that gradually adds Gaussian noise to the degraded measurements.
\begin{definition}[Stochastic degradation process (SDP)]\label{def:sdp}
	$\vct{y}_t = \fwd{t}{\vct{x}_0} + \vct{z}_t, ~ \vct{z}_t \sim \gaussian{\sigma_t^2}$ is a \textit{stochastic degradation process} if $\mathcal{A}_t$ is a deterministic degradation process, $t \in [0, 1]$, and $\vct{x}_0\sim q_0(\vct{x}_0)$ is a sample from the clean data distribution. We denote the distribution of $\vct{y}_t$ as $q_t(\vct{y}_t) \sim \mathcal{N}(\fwd{t}{\vct{x}_0}, \sigma_t^2 \textbf{I})$.
\end{definition}
%A discretization of the above general definition of an SDP is closely related to several popular diffusion frameworks, such as DDPM ($\mathcal{A}_{t} = \sqrt{\bar{\alpha}_t} \mathbf{I}$ and $\vct{z}_t \sim  \gaussian{(1-\bar{\alpha}_t)}$), Score-Based Models ( $\mathcal{A}_{t}  = \mathbf{I}$ and $\vct{z}_t \sim  \gaussian{(\sigma_t^2 - \sigma_{t-1}^2)}$), Soft Diffusion \cite{daras2022soft} ($\fwd{t}{\vct{x}} = \mathbf{C}_t \vct{x}$ time-dependent linear mapping, $\vct{z}_t$ Gaussian), and Cold Diffusion \cite{bansal2022cold} ($\mathcal{A}_{t} $ is arbitrary degradation and $\vct{z}_t = \mathbf{0}$). 
A key contribution of our work is looking at a noisy, degraded signal as a sample from the forward process of an underlying SDP, and considering the reconstruction problem as running the reverse process of the SDP backwards in time in order to recover the clean sample. Recent works on generative frameworks that redefine the standard Gaussian diffusion process fit into our formulation naturally. In particular, Soft Diffusion \citep{daras2022soft} uses a stochastic degradation process with linear forward model, that is $\mathcal{A}_t(\cdot) = \mtx{A}_t$,  without an assumption on the monotonicity of the degradation. The requirement for monotonicity does not necessarily arise in image generation, as there is no notion of data consistency. Cold Diffusion \citep{bansal2022cold} on the other hand uses a deterministic degradation process (without the requirement on monotonicity) between arbitrary distributions to achieve image generation.

Our formulation interpolates between degraded and clean image distributions through a severity parametrization that requires an analytical form of $\mathcal{A}(\cdot)$. An alternative approach \citep{delbracio2023inversion, heitz2023iterative} is to parametrize intermediate distributions as convex combinations of corresponding pairs of noisy and clean samples as $\vct{y}_t = t \tilde{\vct{y}} + (1-t) \vct{x}_0, ~~ t\in[0,1]$, also referred to as \textit{blending} \citep{heitz2023iterative}. In our framework, this formulation can be thought of as a deterministic degradation process $\mathcal{A}_t(\vct{x}_0;  \tilde{\vct{y}} ) = t \tilde{\vct{y}} + (1-t) \vct{x}_0$ conditioned on $\tilde{\vct{y}}$. However, as the underlying degradation operator is not leveraged in this formulation, we cannot develop theoretical guarantees on data consistency of the reconstruction. Moreover, we observe improved noise robustness using the proposed SDP formulation. For a more detailed comparison we refer the reader to Appendix \ref{apx:blending}.

%\begin{itemize}
%	\item \textbf{Denoising Diffusion Probabilistic Models (DDPM): } $\fwd{t}{x} = \sqrt{\bar{\alpha}_t} \mathbf{I}$ and $\vct{z}_t \sim  \gaussian{(1-\bar{\alpha}_t)}$ where $\bar{\alpha}_t$ is determined by the variance schedule.
%	\item \textbf{Score-matching with Langevin Dynamics (SMLD):} $\fwd{t}{x} = \mathbf{I}$ and $\vct{z}_t \sim  \gaussian{(\sigma_t^2 - \sigma_{t-1}^2)}$ where $\sigma_t$ follows a specific geometric series.
%	\item \textbf{Soft Diffusion}: $\fwd{t}{x} = \mathbf{C}_t x$ time-dependent linear mapping, $\vct{z}_t$ Gaussian with similar geometric variance schedule to SMLD.
%	\item \textbf{Cold Diffusion:} $\fwd{t}{x}$ is arbitrary deterministic degradation and $\vct{z}_t = \mathbf{0}$.
%\end{itemize}

%\begin{figure}[t]
%	\centering
%	\includegraphics[width=0.99\linewidth]{plots/diffusion_overview.png}
%	\caption{ Overview of our method. }
%	\label{fig:overview_plot}
%\end{figure}
\subsection{SDP as a stochastic differential equation}
We can formulate the evolution of our degraded and noisy measurements $\vct{y}_t$ as an SDE:
\begin{equation*}
	\text{d}\vct{y}_t = \dfwd{t}{\vct{x}_0} \text{d}t + \sqrt{\frac{\text{d}}{\text{d}t}\sigma_t^2}\text{d}w,
\end{equation*}
where we use the notation $\dfwd{t}{\cdot}$ to indicate derivative with respect to time $t$.
This is an example of an Itô-SDE, and for a fixed $\vct{x}_0$ the above process is reversible, where the reverse diffusion process is given by
\begin{equation*}
	\text{d}\vct{y}_t = \left(\dfwd{t}{\vct{x}_0} \text{d}t -\left(\frac{\text{d}}{\text{d}t}\sigma_t^2\right) \nabla_{\vct{y}_t} \log q_t(\vct{y}_t) \right) \text{d}t
	 +  \sqrt{\frac{\text{d}}{\text{d}t}\sigma_t^2} \text{d}\bar{\vct{w}}.
\end{equation*}
One would solve the above SDE by discretizing it (for example Euler-Maruyama), approximating differentials with finite differences: 
\begin{equation} \label{eq:update}
	\vct{y}_{t-\Delta t} =  \vct{y}_t + \underbrace{\fwd{t-\Delta t}{\vct{x}_0} -  \fwd{t}{\vct{x}_0}}_\text{incremental reconstruction} 
	- \underbrace{(\sigma_{t-\Delta_t}^2 - \sigma_{t}^2) \nabla_{\vct{y}_t}\log q_t(\vct{y}_t)}_\text{denoising} + \sqrt{\sigma_{t}^2 - \sigma_{t-\Delta_t}^2} \vct{z},
\end{equation} 
where $\vct{z} \sim \gaussian{}$. The update in \eqref{eq:update} lends itself to an interesting interpretation. One can look at it as the combination of a small, incremental reconstruction and denoising steps. In particular, assume that $\small{\vct{y}_t = \fwd{t}{\vct{x}_0} + \vct{z}_t}$ and let 
\begin{equation}\label{eq:R}
	\mathcal{R}(t, \Delta t; \vct{x}_0) := \fwd{t-\Delta t}{\vct{x}_0} -  \fwd{t}{\vct{x}_0}.
\end{equation}

Then,  the first term $\vct{y}_t + \mathcal{R}(t, \Delta t; \vct{x}_0) =  \fwd{t-\Delta t}{\vct{x}_0} + \vct{z}_t$ will reverse a $\Delta t$ step of the deterministic degradation process, equivalent in effect to the reverse degradation transition function $\mathcal{H}_{t\rightarrow t-\Delta t}$. The second term is analogous to a denoising step in standard diffusion, where a slightly less noisy version of the image is predicted. However, before we can simulate the reverse SDE in \eqref{eq:update} to recover $\vct{x}_0$, we face two obstacles.
First, we do not know the score of $q_t(\vct{y}_t)$. This is commonly tackled by learning a noise-conditioned score network that matches $\log  q_t(\vct{y}_t|\vct{x}_0)$ which we can easily compute. We are also going to follow this path. Second, we do not know $ \fwd{t-\Delta t}{\vct{x}_0}$ and $\fwd{t}{\vct{x}_0}$ for the incremental reconstruction step, since $\vct{x}_0$ is unknown to us when reversing the degradation process.

\subsection{Denoising - learning a score network}
To run the reverse SDE, we need the score of the noisy, degraded distribution $\nabla_{\vct{y}_t} \log  q_t(\vct{y}_t)$, which is intractable. However, we can use the denoising score matching framework to approximate the score. In particular, instead of the true score, we can easily compute the score for the conditional distribution, when the clean image $\vct{x}_0$ is given as
$
	\nabla_{\vct{y}_t}\log q_t(\vct{y}_t | \vct{x}_0) = \frac{ \fwd{t}{\vct{x}_0} - \vct{y}_t}{\sigma_t^2}.
$
During training, we have access to clean images $\vct{x}_0$ and can generate any degraded, noisy image $\vct{y}_t$ using our SDP formulation $\vct{y}_t = \fwd{t}{\vct{x}_0} + \vct{z}_t$. Thus, we learn an estimator of the conditional score function $s_{\vct{\theta}}(\vct{y}_t, t)$ by minimizing
\begin{equation} \label{eq:loss}
		\mathcal{L}_t({\vct{\theta}}) = \mathbb{E}_{(\vct{x}_0, \vct{y}_t)} \left[ \left\| s_{\vct{\theta}}(\vct{y}_t, t) -  \frac{ \fwd{t}{\vct{x}_0} - \vct{y}_t}{\sigma_t^2}\right\|^2\right],
\end{equation}
where $(\vct{x}_0, \vct{y}_t)\sim q_0(\vct{x}_0) q_t(\vct{y}_t | \vct{x}_0)$. One can show that the well-known result of \citet{vincent2011connection} applies to our SDP formulation, and thus by minimizing the objective in \eqref{eq:loss}, we can learn the score  $\nabla_{\vct{y}_t} \log  q_t(\vct{y}_t)$ (see details in Appendix \ref{apx:dsm}).

We parameterize the score network as
\begin{equation}\label{eq:parametrization}
	s_{\vct{\theta}}(\vct{y}_t, t) =  \frac{ \fwd{t}{\Phi_{\vct{\theta}}(\vct{y}_t, t)} - \vct{y}_t}{\sigma_t^2},
\end{equation}
that is given a noisy and degraded image as input,the model predicts the underlying clean image $\vct{x}_0$.  Other parametrizations are also possible, such as predicting $\vct{z}_t$ or (equivalently) predicting $ \fwd{t}{\vct{x}_0}$. However, as pointed out in \citet{daras2022soft}, this might lead to learning the image distribution only locally, around degraded images. Furthermore, in order to estimate the incremental reconstruction $\mathcal{R}(t, \Delta t; \vct{x}_0)$, we not only need to estimate $ \fwd{t}{\vct{x}_0}$, but other functions of $\vct{x}_0$, and thus estimating $\vct{x}_0$ directly gives us more flexibility.
Rewriting \eqref{eq:loss} with the new parametrization leads to
\begin{equation} \label{eq:loss_final}
		\mathcal{L}({\vct{\theta}}) = \mathbb{E}_ {t, (\vct{x}_0, \vct{y}_t)}\left[w(t) \left\|  \fwd{t}{\Phi_{\vct{\theta}}(\vct{y}_t, t)}  -  \fwd{t}{\vct{x}_0} \right\|^2\right],
\end{equation}
where ${t\sim U[0,1], (\vct{x}_0, \vct{y}_t)\sim q_0(\vct{x}_0) q_t(\vct{y}_t | \vct{x}_0)}$ and typical choices in the diffusion literature for the weights $w(t)$ are $1$ or $1/\sigma_t^2$. Intuitively, the neural network receives a noisy, degraded image, along with the degradation severity, and outputs a prediction $\hat{\vct{x}}_0(\vct{y}_t) = \Phi_{\vct{\theta}}(\vct{y}_t, t)$ such that the \textit{degraded} ground truth $\fwd{t}{\vct{x}_0}$ and the \textit{degraded} prediction $\fwd{t}{\hat{\vct{x}}_0(\vct{y}_t)}$ are consistent.

\subsection{Incremental reconstructions \label{sec:inc_rec}}
Given an estimator of the score, we still need to approximate $\mathcal{R}(t, \Delta t; \vct{x}_0)$ from \eqref{eq:R} in order to run the reverse SDE in \eqref{eq:update}. That is we have to estimate \textit{how the degraded image changes if we slightly decrease the degradation severity}. As we parameterize our score network in \eqref{eq:parametrization} to learn a representation of the clean image manifold directly, we can estimate the incremental reconstruction term as
\begin{equation}\label{eq:R_hat}
	\hat{\mathcal{R}}(t, \Delta t; \vct{y}_t) = \fwd{t-\Delta t}{\Phi_{\vct{\theta}}(\vct{y}_t, t)} -  \fwd{t}{\Phi_{\vct{\theta}}(\vct{y}_t, t)}.
\end{equation} 
One may consider this a \textit{look-ahead method} (see alternative formulations in Appendix \ref{apx:inc_rec_approx}), since we use  $\vct{y}_t$ with degradation severity $t$ to predict a less severe degradation of the clean image "ahead" in the reverse process. This becomes more obvious when we note, that our score network already learns to predict $\fwd{t}{\vct{x}_0}$ given $\vct{y}_t$ due to the training loss in \eqref{eq:loss_final}. However, even if we learn the true score perfectly via  \eqref{eq:loss_final}, there is no guarantee that $\fwd{t-\Delta t}{\vct{x}_0} \approx \fwd{t-\Delta t}{\Phi_{\vct{\theta}}(\vct{y}_t, t)}$. The following result provides an upper bound on the approximation error.
\begin{theorem}\label{thm:basic_error}
	Let  $\hat{\mathcal{R}}(t, \Delta t; \vct{y}_t)$ from \eqref{eq:R_hat} denote our estimate of the incremental reconstruction, where $\Phi_{\vct{\theta}}(\vct{y}_t, t)$ is trained on the loss in \eqref{eq:loss_final}. Let  $\mathcal{R}^*(t, \Delta t; \vct{y}_t) = \mathbb{E}[	\mathcal{R}(t, \Delta t; \vct{x}_0) | \vct{y}_t]$ denote the MMSE estimator of $\mathcal{R}(t, \Delta t; \vct{x}_0)$. Assume, that the degradation process is smooth such that $\| \fwd{t}{\vct{x}} - \fwd{t}{\vct{x}'} \| \leq L_x^{(t)} \|\vct{x}-\vct{x}'\|, ~\forall \vct{x}, \vct{x}' \in \mathbb{R}^n$ and  $\| \fwd{t}{\vct{x}} - \fwd{t'}{\vct{x}} \| \leq L_t |t -t'|, ~\forall t, t' \in [0, 1],~ \forall \vct{x}\in \mathbb{R}^n$. Further assume that the clean images have bounded entries $\vct{x}_0[i] \leq B, ~\forall i \in (1, 2, ..., n)$ and that the error in our score network is bounded by $\| s_{{\vct{\theta}}}(\vct{y}_t, t) -  \nabla_{\vct{y}_t}\log q_t(\vct{y}_t) \| \leq \frac{\epsilon_t}{\sigma_t^2}, ~\forall t \in [0,1]$. Then, 
	\begin{equation*}
		\|\hat{\mathcal{R}}(t, \Delta t; \vct{y}_t) - \mathcal{R}^*(t, \Delta t; \vct{y}_t)\| \leq 
		\underbrace{(L_x^{(t)} + L_x^{(t - \Delta t)})}_\text{degr. smoothness} \underbrace{\sqrt{n} B }_\text{data} + \underbrace{2 L_t}_\text{scheduling} \underbrace{\Delta t}_\text{algorithm} +  \underbrace{2\epsilon_t}_\text{optimization}.
	\end{equation*}
\end{theorem} 
The first term in the upper bound suggests that smoother degradations are easier to reconstruct accurately. The second term indicates two crucial points: (1) sharp variations in the degradation with respect to time leads to potentially large estimation error and (2) the error can be controlled by choosing a small enough step size in the reverse process. Scheduling of the degradation over time is a design parameter, and Theorem \ref{thm:basic_error} suggests that sharp changes with respect to $t$ should be avoided. Finally, the error grows with less accurate score estimation, however with large enough network capacity, this term can be driven close to $0$.

The main contributor to the error in Theorem \ref{thm:basic_error} stems from the fact that consistency under less severe degradations, that is $ \fwd{t-\Delta t}{\Phi_{\vct{\theta}}(\vct{y}_t, t)} \approx  \fwd{t-\Delta t}{\vct{x}_0}$, is not enforced by the loss in \eqref{eq:loss_final}. To this end, we propose a novel loss function, the \textit{incremental reconstruction loss}, that combines learning to denoise and reconstruct simultaneously:
 \begin{equation} \label{eq:loss_irn}
 	\mathcal{L}_{IR}(\Delta t, {\vct{\theta}}) = 
 	 \mathbb{E}_ {t, (\vct{x}_0, \vct{y}_t)}\left[w(t) \left\|  \fwd{\tau}{\Phi_{\vct{\theta}}(\vct{y}_t, t)}  -  \fwd{\tau}{\vct{x}_0} \right\|^2\right],
 \end{equation}
where $\tau = \text{max}(t-\Delta t, 0), ~ t\sim U[0,1],$ $(\vct{x}_0, \vct{y}_t)\sim q_0(\vct{x}_0) q_t(\vct{y}_t | \vct{x}_0)$.
It is clear, that minimizing this loss directly improves our estimate of the incremental reconstruction in \eqref{eq:R_hat}. We find that if $\Phi_{\vct{\theta}}$ has large enough capacity, minimizing the incremental reconstruction loss in \eqref{eq:loss_irn} also implies minimizing \eqref{eq:loss_final}, and thus the true score is learned (denoising is achieved). Furthermore, we show that \eqref{eq:loss_irn} is an upper bound to \eqref{eq:loss_final} (Appendix \ref{apx:irn_loss}). By minimizing \eqref{eq:loss_irn}, the model learns not only to denoise, but also to perform small, incremental reconstructions of the degraded image such that $\fwd{t-\Delta t}{\Phi_{\vct{\theta}}(\vct{y}_t, t)} \approx  \fwd{t-\Delta t}{\vct{x}_0}$. There is however a trade-off between incremental reconstruction performance and learning the score: we are optimizing an upper bound to \eqref{eq:loss_final} and thus it is possible that the score estimation is less accurate. We expect incremental reconstruction loss to work best in scenarios where the degradation may change rapidly with respect to $t$ and hence a network trained to estimate $\fwd{t}{\vct{x}_0}$ from $\vct{y}_t$ may become inaccurate when predicting $\fwd{t-\Delta t}{\vct{x}_0}$ from $\vct{y}_t$.

%The following proposition gives us some guarantees that the score (and thus denoising) is also learned when optimizing \eqref{eq:loss_irn}.
%\begin{proposition}\label{thm:irn_loss}
%If the model $\Phi_{\vct{\theta}}(\vct{y}_t, t)$ has large enough capacity, such that $	\mathcal{L}_{IRN}(\Delta t, {\vct{\theta}}) = 0$ is achieved, then $s_{\vct{\theta}}(\vct{y}_t, t) =  \nabla_{\vct{y}_t} \log q_t(\vct{y}_t), ~\forall t \in [0, 1]$. Otherwise, if we assume that $\| \mathcal{G}_{t' \rightarrow t''}(\vct{x}) - \mathcal{G}_{t' \rightarrow t''}(\vct{y})\| \leq L_G(t', t'') \|\vct{x} - \vct{y}\|, ~\forall t', t'' \in [0,1],~ t' < t'',~  \forall \vct{x},\vct{y} \in \mathbb{R}^n$, then we have 
%\begin{equation}
%	\mathcal{L}({\vct{\theta}}) \leq  \max_{t\in[0, 1]}( L_G(\tau, t)) \mathcal{L}_{IRN}(\Delta t, {\vct{\theta}}) .
%\end{equation}
%\end{proposition}
%This means that if the model has large enough capacity, minimizing the incremental reconstruction loss in \eqref{eq:loss_irn} also implies minimizing \eqref{eq:loss_final}, and thus the true score is learned (denoising is achieved). Otherwise, the incremental reconstruction loss is an upper bound on the loss in \eqref{eq:loss_final}. Training a model on \eqref{eq:loss_irn}, the model learns not only to denoise, but also to perform small, incremental reconstructions of the degraded image such that $\fwd{t-\Delta t}{\Phi_{\vct{\theta}}(\vct{y}_t, t)} \approx  \fwd{t-\Delta t}{\vct{x}_0}$. There is however a trade-off between incremental reconstruction performance and learning the score: as Proposition \ref{thm:irn_loss} indicates, we are optimizing an upper bound to \eqref{eq:loss_final} and thus it is possible that the score estimation is less accurate. We expect our proposed incremental reconstruction loss to work best in scenarios where the degradation may change rapidly with respect to $t$ and hence a network trained to accurately estimate $\fwd{t}{\vct{x}_0}$ from $\vct{y}_t$ may become inaccurate when predicting $\fwd{t-\Delta t}{\vct{x}_0}$ from $\vct{y}_t$. This hypothesis is further supported by our experiments in Section \ref{sec:exp}. Finally, we mention that in the extreme case where we choose $\Delta t = 1$, we obtain a loss function purely in clean image domain.

%The improvement in the approximation error of the incremental reconstruction term in \eqref{eq:R} when optimizing the incremental reconstruction loss is reflected by the following theorem.
%\begin{theorem}
%	Under the conditions of Theorem \ref{thm:basic_error}, if the model $\Phi_{\vct{\theta}}(\vct{y}_t, t)$ is trained on the incremental reconstruction loss in \eqref{eq:loss_irn}, and assuming that the loss is bounded by $\|\fwd{t - \Delta t}{\Phi_{\vct{\theta}}(\vct{y}_t, t)}  -  \fwd{t - \Delta t}{\vct{x}_0}\| \leq \epsilon^{IR}_t$, then 
%	\begin{multline}
%			\|\hat{\mathcal{R}}(t, \Delta t; \vct{y}_t) - \mathcal{R}^*(t, \Delta t; \vct{y}_t)\| \leq \\ (L_x^{(t)} + L_x^{(t - \Delta t)})B \sqrt{n} +\epsilon_t + \epsilon^{IR}_t.
%	\end{multline}
%\end{theorem}
\subsection{Data consistency}
Data consistency is a crucial requirement on generated images when solving inverse problems. That is, we want to obtain reconstructions that are consistent with our original measurement under the degradation model. More formally, we define data consistency as follows in our framework.
\begin{definition}[Data consistency]
Given a deterministic degradation process $ \fwd{t}{\cdot}$,  two degradation severities $\tau \in [0, 1]$ and $\tau^+ \in [\tau, 1]$ and corresponding degraded images $\vct{y}_\tau \in \mathbb{R}^n$ and $\vct{y}_{\tau^+}\in\mathbb{R}^n$, $\vct{y}_{\tau^+}$ is \textit{data consistent} with $\vct{y}_\tau$ under $ \fwd{t}{\cdot}$ if $\exists \vct{x}_0\in\mathcal{X}_0$ such that $\fwd{\tau}{\vct{x}_0} = \vct{y}_\tau$ and $\fwd{\tau^+}{\vct{x}_0} = \vct{y}_{\tau^+}$, where $\mathcal{X}_0$ denotes the clean image manifold. We use the notation $\vct{y}_{\tau^+} \dc \vct{y}_\tau$.
\end{definition}
Simply put, two degraded images are data consistent, if there is a clean image which may explain both under the deterministic degradation process. As our proposed technique is directly trained to reverse a degradation process, enforcement of data consistency is built-in without applying additional steps, such as projection. The following theorem guarantees that in the ideal case, data consistency is maintained in \textit{each iteration} of the reconstruction algorithm. Proof is provided in Appendix \ref{apx:dc_thm}.
\begin{theorem}[Data consistency over iterations] \label{thm:dc}
	Assume that we run the updates in \eqref{eq:update} with $s_{\vct{\theta}}(\vct{y}_t, t) =  \nabla_{\vct{y}_t} \log q_t(\vct{y}_t), ~\forall t \in [0, 1]$ and $	\hat{\mathcal{R}}(t, \Delta t; \vct{y}_t) = \mathcal{R}(t, \Delta t; \vct{x}_0), ~ \vct{x}_0\in \mathcal{X}_0$. If we start from a noisy degraded observation $\vct{\tilde{y}} = \fwd{1}{\vct{x}_0} + \vct{z}_{1}, ~ \vct{x}_0\in \mathcal{X}_0, ~\vct{z}_1 \sim \gaussian{\sigma_{1}^2} $ and run the updates in \eqref{eq:update} for $\tau = 1,1-\Delta t, ..., \Delta t, 0$, then
\begin{equation*}
 	\mathbb{E}[ \vct{\tilde{y}} ] \dc  \mathbb{E}[ \vct{y}_\tau] , ~	\forall \tau \in [1,1-\Delta t, ..., \Delta t, 0].
\end{equation*}
\end{theorem}
%Proof is provided in Appendix \ref{apx:dc_thm}. Even though the assumption that we achieve perfect incremental reconstruction is strong, in practice data consistency is indeed maintained without additional guidance from $\vct{\tilde{y}}$ during the reverse process, as shown in Section \ref{sec:exp}, hinting at the robustness of the proposed framework. 

\begin{figure*}[t]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=0.99\linewidth]{plots/increcon_PSNR_LPIPS_curves.pdf}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=0.99\linewidth]{plots/increcon_recon_sample_std.pdf}
	\end{subfigure}
	\caption{ Perception-distortion trade-off on CelebA-HQ deblurring: distortion metrics initially improve, peak fairly early in the reverse process, then gradually deteriorate, while perceptual metrics improve. We plot the mean of $30$ trajectories ($\pm std$ shaded) starting from the same measurement.}
	\label{fig:perception_distortion}
\end{figure*}

%\subsection{Guidance} \label{sec:guidance}
%So far, we have only used our noisy observation $\vct{\tilde{y}} = \fwd{1}{\vct{x}_0} + \vct{z}_1$ as a starting point for the reverse diffusion process, however the measurement is not used directly in the update in \eqref{eq:update}. We learned the score of the prior distribution $\nabla_{\vct{y}_t} \log q_t(\vct{y}_t)$, which we can leverage to sample from the posterior distribution $ q_t(\vct{y}_t | \vct{\tilde{y}})$. In fact, using Bayes rule the score of the posterior distribution can be written as 
%\begin{equation}
%	\nabla_{\vct{y}_t} \log q_t(\vct{y}_t | \vct{\tilde{y}}) = \nabla_{\vct{y}_t} \log q_t(\vct{y}_t) + \nabla_{\vct{y}_t} \log q_t(\vct{\tilde{y}} | \vct{y}_t),
%\end{equation}
%where we already approximate  $\nabla_{\vct{y}_t} \log q_t(\vct{y}_t)$ via $s_{\vct{\theta}}(\vct{y}_t, t)$. Finding the posterior distribution analytically is not possible, and therefore we use the approximation
%$
%	q_t(\vct{\tilde{y}} | \vct{y}_t) \approx q_t(\vct{\tilde{y}} | \Phi_{\vct{\theta}}(\vct{y}_t, t)),
%$
%from which distribution we can easily sample from. Since $q_t(\vct{\tilde{y}} | \Phi_{\vct{\theta}}(\vct{y}_t, t)) \sim \mathcal{N}(\fwd{1}{ \Phi_{\vct{\theta}}(\vct{y}_t, t)}, \sigma_1^2 \textbf{I})$, our estimate of the posterior score takes the form
%\begin{equation}
%	s'_{\vct{\theta}}(\vct{y}_t, t) = s_{\vct{\theta}}(\vct{y}_t, t)  - \eta_t \nabla_{\vct{y}_t}\frac{\|\vct{\tilde{y}} - \fwd{1}{ \Phi_{\vct{\theta}}(\vct{y}_t, t)} \|^2}{2 \sigma_1^2},
%\end{equation}
%where $\eta_t$ is a hyperparameter that tunes how much we rely on the original noisy measurement. Even though we do not need to rely on $\vct{\tilde{y}}$ after the initial update for our method to work, we observe small improvements by adding the above guidance scheme to our algorithm.
\begin{figure}[t]
 \begin{algorithm}[H]
	\caption{\methodname}\label{alg:irnd_main}
	\begin{algorithmic}
		\Require $\vct{\tilde{y}}$: noisy observation,  $\Phi_{\vct{\theta}}$: score network, $\fwd{t}{\cdot}$: degradation function, $\Delta t$: step size, $\sigma_t$: noise std at time $t$, $\eta_t$: guidance step size, $\forall t\in[0, 1]$, $t_{stop}$: early-stopping parameter
		\State $N \gets \lfloor1/\Delta t\rfloor$
		\State $\vct{y} \gets \vct{\tilde{y}}$
		\For{$i = 1 \text{ to }N$}
		\State $t \gets 1 - \Delta t \cdot i$
		\If{$ t \leq t_{stop}$}
		\State $\textbf{break}$  \hfill\Comment{Early-stopping}
		\EndIf
		\State $\vct{z} \sim \mathcal{N}(0, \sigma_t^2 \mathbf{I})$
		\State $\hat{\vct{x}}_0 \gets  \Phi_{\vct{\theta}}(\vct{y}, t)$ \hfill\Comment{Predict posterior mean}
		\State $\vct{y}_r \gets \fwd{t-\Delta t}{\hat{\vct{x}}_0} - \fwd{t}{\hat{\vct{x}}_0}$ \hfill\Comment{Incremental reconstruction}
		\State $\vct{y}_{d} \gets -\frac{\sigma_{t-\Delta t}^2 - \sigma_t^2}{\sigma_t^2}(\fwd{t}{\hat{\vct{x}}_0} - \vct{y})$ \hfill\Comment{Denoising}
		\State $\vct{y}_g \gets  (\sigma_{t-\Delta t}^2 - \sigma_t^2) \nabla_{y} \|\vct{\tilde{y}} - \fwd{1}{\hat{\vct{x}}_0}\|^2$ \hfill\Comment{Guidance}
		\State $\vct{y} \gets \vct{y} +\vct{y}_r + \vct{y}_d + \eta_t \vct{y}_g + \sqrt{\sigma_{t}^2 - \sigma_{t-\Delta t}^2} \vct{z}$
		\EndFor
		\Ensure $\vct{y}$ \hfill\Comment{Alternatively, output $\hat{\vct{x}}_0$ (see Appendix \ref{apx:output_note})}
	\end{algorithmic} 
\end{algorithm}
\end{figure}

\subsection{Perception-distortion trade-off}
Diffusion models generate synthetic images of exceptional quality, almost indistinguishable from real images to the human eye. This perceptual image quality is typically evaluated on features extracted by a pre-trained neural network, resulting in metrics such as Learned Perceptual Image Patch Similarity (LPIPS)\citep{zhang2018unreasonable} or Fréchet Inception Distance (FID)\citep{heusel2017gans}. In image restoration however, we are often interested in image distortion metrics that reflect faithfulness to the original image, such as Peak Signal to Noise Ratio (PSNR) or Structural Similarity Index Measure (SSIM) when evaluating the quality of reconstructions. Interestingly, distortion and perceptual  quality are fundamentally at  odds with each  other,  as shown in the seminal work of \citet{blau2018perception}.  As diffusion models tend to favor high perceptual quality, it is often at the detriment of distortion metrics \citep{chung2022diffusion}.

As shown in Figure \ref{fig:perception_distortion}, we empirically observe that in the reverse process of \methodname{}, the quality of reconstructions with respect to distortion metrics initially improves, peaks fairly early in the reverse process, then gradually deteriorates. Simultaneously, perceptual metrics such as LPIPS demonstrate stable improvement for most of the reverse process. More intuitively, the algorithm first finds a rough reconstruction that is consistent with the measurement, but lacks fine details. This reconstruction is optimal with respect to distortion metrics, but visually overly smooth and blurry. Consecutively, image details progressively emerge during the rest of the reverse process, resulting in improving perceptual quality at the cost of deteriorating distortion metrics. Therefore, our method provides an additional layer of flexibility: by \textit{early-stopping} the reverse process, we can trade-off perceptual quality for better distortion metrics. Adjusting the early-stopping parameter $t_{stop}$ allows us to obtain distortion- and perception-optimized reconstructions depending on our requirements.

\subsection{Degradation scheduling}
 In order to deploy our method, we need to define how the degradation changes with respect to severity $t$ following the properties specified in Definition \ref{def:sdp}. That is, we have to determine how to interpolate between the identity mapping $\fwd{0}{\vct{x}} = \vct{x}$ for $t=0$ and the most severe degradation $\fwd{1}{\cdot}$ for $t=1$.  Theorem \ref{thm:basic_error} suggests that sharp changes in the degradation function with respect to $t$ should be avoided. Here, we leverage a principled method of scheduling using a greedy algorithm to select a set of degraded distributions, such that the maximum distance between consecutive distributions is minimized. Details can be found in Appendix \ref{apx:scheduling}. 
 
 Finally, we find that adding a guidance term similar to that used in DPS \citep{chung2022diffusion} slightly improves reconstructions, however it is not necessary for maintaining data consistency. For more details, we refer the reader to Appendix \ref{apx:guidance}. A summary of \methodname{} is shown in Algorithm \ref{alg:irnd_main}.
%\begin{algorithm}
%	\caption{\methodname}\label{alg:irnd}
%	\begin{algorithmic}
%		\Require $\vct{\tilde{y}}$: noisy observation,  $\Phi_{\vct{\theta}}$: score network, $\fwd{t}{\cdot}$: degredation function, $\Delta t$: step size, $\sigma_t$: noise std at time $t$, $\eta_t$: guidance step size, $\forall t\in[0, 1]$, $t_{stop}$: early-stopping parameter
%		\State $N \gets \lfloor1/\Delta t\rfloor$
%		\State $\vct{y} \gets \vct{\tilde{y}}$
%		\For{$i = 1 \text{ to }N$}
%		\State $t \gets 1 - \Delta t \cdot i$
%		\If{$ t \leq t_{stop}$} \Comment{Early-stopping}
%		\State \textbf{break}
%		\EndIf
%		\State $\vct{z} \sim \mathcal{N}(0, \sigma_t^2 \mathbf{I})$
%		\State $\hat{\vct{x}}_0 \gets  \Phi_{\vct{\theta}}(\vct{y}, t)$ \Comment{Predict posterior mean}
%		\State $\vct{y}_r \gets \fwd{t-\Delta t}{\hat{\vct{x}}_0} - \fwd{t}{\hat{\vct{x}}_0}$ \Comment{Incremental reconstruction}
%		\State $\vct{y}_{d} \gets -\frac{\sigma_{t-\Delta t}^2 - \sigma_t^2}{\sigma_t^2}(\fwd{t}{\hat{\vct{x}}_0} - \vct{y})$ \Comment{Denoising}
%		\State $\vct{y}_g \gets  -(\sigma_{t-\Delta t}^2 - \sigma_t^2) \nabla_{y} \|\vct{\tilde{y}} - \fwd{1}{\hat{\vct{x}}_0}\|^2$ \Comment{Guidance}
%		\State $\vct{y} \gets \vct{y} +\vct{y}_r + \vct{y}_d + \eta_t \vct{y}_g + \sqrt{\sigma_{t}^2 - \sigma_{t-\Delta t}^2} \vct{z}$
%		\EndFor
%		\Ensure $\vct{y}$ \Comment{Alternatively, output $\hat{\vct{x}}_0$}
%	\end{algorithmic} 
%\end{algorithm}

\begin{figure}[t]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=0.7\linewidth, left]{plots/increcon_data_consistency_ffhq_inpainting_curves.pdf}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
	\includegraphics[width=0.6\linewidth, center]{plots/increcon_imagenet_test_comparison.pdf}
\end{subfigure}%
%	\begin{subfigure}{.33\linewidth}
%		\includegraphics[width=1.05\linewidth, right]{plots/increcon_nfe_lpips_curves.pdf}
%	\end{subfigure}
	\caption{ \underline{Left}: Data consistency in FFHQ inpainting. $\epsilon_{dc} := \norm{\vct{\tilde{y}} - \fwd{1}{\hat{\vct{x}}_0(\vct{y}_t)}}^2$ measures how consistent is the clean image estimate with the measurement. We expect $\epsilon_{dc}$ to approach the noise floor $\sigma_1^2 = 0.0025$ in case of perfect data consistency. We plot $\bar{\epsilon}_{dc}$ the mean over the validation set. \methodname{} maintains data consistency throughout the reverse process. \underline{Right}: Data consistency is not always achieved with DPS.}
	\label{fig:curves}
\end{figure}

\begin{figure}[t]
	\centering
	\includegraphics[width=0.4\linewidth]{plots/increcon_nfe_lpips_curves.pdf}
	\caption{ Number of reverse diffusion steps vs. perceptual  quality. \methodname{} produces reconstructions of high quality even with a low number of neural function evaluations (NFEs).}
	\label{fig:nfe_compare}
\end{figure}
