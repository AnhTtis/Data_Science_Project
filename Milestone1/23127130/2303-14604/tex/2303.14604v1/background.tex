\section{Background}

Climate change is a pressing global issue believed to be caused by human activities such as burning fossil fuels, deforestation, and agriculture, which all emit greenhouse gasses (e.g., CO$_2$ and methane). Climate change has significant impacts on human communities, as well as on ecosystems and biodiversity. Mitigating harmful emissions is essential in addressing climate change~\cite{un_climate_change, masson2021climate}.

Green AI is the use of AI techniques and technologies in a way to reduce their environmental impact and promote sustainability in AI \cite{greenai, tackling}. Some examples are developing more energy-efficient algorithms and hardware, and reducing the carbon footprint of data centers. With the rapid growth of AI (e.g., the amount of compute for training state-of-the-art models doubled every 10 months between 2015 and 2022~\cite{three_eras}), it is imperative to understand the environmental implications, challenges, and opportunities of AI. By making AI more sustainable, we can reduce its environmental impact while also reaping the benefits that AI has to offer.

A related line of work addresses communication efficiency or model compression for FL ~\cite{konen2016federated,vogels2019powersgd,jiang2019model,Fetchsgd}. Historically, the primary objectives of these techniques have been cost reduction and not carbon emission savings per se. Quantifying and reducing the carbon emissions of FL is our primary objective. Although one might argue that renewable energy can power centralized AI systems \cite{google_cloud_sust, meta-pue, amazon_sust}, providing FL with renewable energy is inherently more challenging, as end-user devices are tied to their local energy mixes whose carbon footprint must be taken into account. In this paper we set out to study the problem of Green FL, present challenges, guidelines, and the lessons learned from realizing the trade-off between energy efficiency, performance, and time to train in a production FL system.




