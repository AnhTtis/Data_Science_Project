\section{Conclusion}
In this study, we leverage the susceptibility of the pre-trained CLIP text encoder (to input perturbations) to design a query-free adversarial attack against the Stable Diffusion model for text-to-image generation. %We study both   untargeted   and targeted   attacks against the T2I Stable Diffusion Model. 
In addition to untargeted attacks, we also develop a targeted attack  method by exploring and exploiting the influential dimensions (that we call steerable key dimensions) in the text embedding space so as to enable targeted  content manipulation in the synthesized images. 
Our experiments have shown that a five-character prompt perturbation could have been effective in attack Stable Diffusion models. 



% the T2I Stable Diffusion Model can be made to ignore the objects in original sentences with simple prompts of only five-character perturbation words consisting of letters, digits, or common symbols. We also discuss the limitations of black-box attacks, as the availability of parameters in cross-attention module can affect the success rate of the generated prompts. In future work, incorporating parameters in the cross-attention module may help humans better understand the generated prompts and how T2I DMs processes human language. Overall, our findings underscore the need for increased attention to the vulnerability of pre-trained models and the importance of developing more robust defense mechanisms against perturbation attacks.
% % In this paper, we reveal the potential hazard in pre-trained CLIP text encoder leakaging it to introduce a query-light black-box perturbation attacks for its downstream task diffusion model. Through experiments, we show that it is easy to let diffusion model ignore original sentence with 5 letters consisting of letters, digits or common symbols. We illustrate the limitation of black-box attack that the availability barriers the success rate of generated prompts. In the future, combining with parameters in cross attention module may help humans to understant those generated prompts and how diffusion model process human language.