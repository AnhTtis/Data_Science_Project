\section{Introduction}


This paper studies the efficient optimization of a family of random functions $H_N$ which are high-dimensional and extremely non-convex. 
The computational complexity of such random optimization problems remains poorly understood in the majority of cases as most impossibility results concern worst-case rather than average-case behavior.

We focus on a general class of such problems: the Hamiltonians of multi-species spherical spin glasses. 
Mean-field spin glasses have been studied since \cite{sherrington1975solvable} as models for disordered magnetic systems and are also closely linked to random combinatorial optimization problems \cite{krzakala2007gibbs, dembo2017extremal, panchenko2018k}. Simply put, their Hamiltonians are certain polynomials in many variables with independent centered Gaussian coefficients.
%

Multi-species spin glasses such as the bipartite SK model \cite{kincaid1975phase,korenblit1985spin,fyodorov1987antiferromagnetic,fyodorov1987phase} open the door to yet richer behavior and as discussed below remain poorly understood from a rigorous viewpoint.
%
Our main result gives, for all multi-species spherical spin glasses, an exact \emph{algorithmic threshold} $\ALG$ for the maximum Hamiltonian value obtained by a natural class of \emph{stable} optimization algorithms.


For the more well-known single-species spin glasses, the celebrated Parisi formula \cite{parisi1979infinite,talagrand2006parisi,talagrand2006spherical,auffinger2017parisi} gives the limiting maximum value of $H_N$ as a certain variational formula.
In previous work \cite{huang2021tight} we obtained the algorithmic threshold for these models restricted to have only even degree interactions, given by the same variational formula over an extended state space.
The central idea was to show $H_N$ obeys a branching version of the \emph{overlap gap property} (OGP): the absence of a certain geometric configuration of high-energy inputs \cite{gamarnik2014limits,gamarnik2021survey}. 
The proofs of the Parisi formula \cite{talagrand2006parisi,talagrand2006spherical,auffinger2017parisi}, the branching OGP in \cite{huang2021tight}, and other results (e.g. \cite{guerra2002thermodynamic,bayati2010combinatorial}) require the so-called interpolation method, which is known to fail when the model's covariance is not convex.
Due to this limitation of the interpolation method, the proof of our previous result does not generalize to single-species spin glasses with odd interactions, nor to multi-species spin glasses. 
For the same reason, the Parisi formula for the ground state of a multi-species spin glass 
is known only in restricted cases \cite{barra2015multi,panchenko2015free, subag2021tap, bates2022free}. 



We develop a new method to establish the branching OGP which does not use the interpolation method.
Instead, we recursively apply a uniform concentration idea introduced in \cite{subag2018free}.
Consequently we are able to determine $\ALG$ for all multi-species spherical spin glasses, including those whose ground state energy is not known. 
As a special case, this removes the even interactions condition from \cite{huang2021tight} for spherical models and is the first OGP that applies to mean-field spin glasses with odd interactions.

Our results strengthen a geometric picture put forth in \cite[Section 1.4]{huang2021tight} that in mean-field random optimization problems, the tractability of optimization to value $E$ coincides with the presence of densely branching ultrametric trees within the super-level set at value $E$.
On the hardness side, such trees are precisely what the branching OGP forbids. 
On the algorithmic side, it will be clear from our methods (see the end of Subsection~\ref{subsec:bogp-summary}) that efficient algorithms can be designed to descend such trees whenever they exist, thereby achieving value $E$.






Our algorithmic threshold for multi-species models is expressed as the maximum of a somewhat different variational principle.
We analyze our algorithmic variational principle in detail, showing that maximizers are formed by joining the solutions to a pair of differential equations, and are explicit and unique for single-species and pure models.
To our surprise the maximizers are not unique in general, a behavior we term \emph{algorithmic symmetry breaking}. 


\subsection{Problem Description and the Value of $\ALG$}


Fix a finite set $\sS = \{1,\ldots,r\}$. 
For each positive integer $N$, fix a deterministic partition $\{1,\ldots,N\} = \sqcup_{s\in\sS}\, \cI_s$ with $\lim_{N\to\infty} |\cI_s| / N =\lambda_s$ where $\vlam = (\lambda_1,\ldots,\lambda_r) \in \bbR_{>0}^\sS$ sum to $1$.
For $s\in \sS$ and $\bx \in \bbR^N$, let $\bx_s \in \bbR^{\cI_s}$ denote the restriction of $\bx$ to coordinates $\cI_s$.
We consider the state space 
\[
    \cB_N = \lt\{
        \bx \in \bbR^N : 
        \norm{\bx_s}_2^2 \le \lambda_s N
        ~\forall s\in \sS
    \rt\}.
\]
Fix $\vh = (h_1,\ldots,h_r) \in \bbR_{\ge 0}^\sS$ and let $\bone = (1,\ldots,1) \in \bbR^N$.
For each $k\ge 2$ fix a symmetric tensor $\Gamma^{(k)} = (\gamma_{s_1,\ldots,s_k})_{s_1,\ldots,s_k\in \sS} \in (\bbR_{\ge 0}^{\sS})^{\otimes k}$ with $\sum_{k\ge 2} 2^k \norm{\Gamma^{(k)}}_\infty < \infty$, and let $\Gp{k} \in (\bbR^N)^{\otimes k}$ be a tensor with i.i.d. standard Gaussian entries.
For $A\in (\bbR^\sS)^{\otimes k}$, $B\in (\bbR^N)^{\otimes k}$, define $A\diamond B \in (\bbR^N)^{\otimes k}$ to be the tensor with entries
\begin{equation}
    \label{eq:def-diamond}
    (A\diamond B)_{i_1,\ldots,i_k} = A_{s(i_1),\ldots,s(i_k)} B_{i_1,\ldots,i_k},
\end{equation}
where $s(i)$ denotes the $s\in \sS$ such that $i\in \cI_s$.
Let $\bh = \vh \diamond \bone$.
We consider the mean-field multi-species spin glass Hamiltonian
\begin{align}
    \label{eq:def-hamiltonian}
    H_N(\bsig) &= \la \bh, \bsig \ra + \wtH_N(\bsig), \quad \text{where}\\
    \label{eq:def-hamiltonian-no-field}
    \wtH_N(\bsig) &=
	\sum_{k\ge 2}
	\fr{1}{N^{(k-1)/2}}
	\la \Gamma^{(k)} \diamond \bG^{(k)}, \bsig^{\otimes k} \ra \\
	\notag
	&=
	\sum_{k\ge 2}
	\fr{1}{N^{(k-1)/2}}
	\sum_{i_1,\ldots,i_k=1}^N 
	\gamma_{s(i_1),\ldots,s(i_k)} \bG^{(k)}_{i_1,\ldots,i_k} \sigma_{i_1}\cdots \sigma_{i_k}
\end{align}
with inputs $\bsig = (\sigma_1,\ldots,\sigma_N) \in \cB_N$.
For $\bsig,\brho\in \cB_N$, define the species $s$ overlap and overlap vector
\begin{equation}
    \label{eq:R}
    R_s(\bsig, \brho)
    =
    \fr{ \la \bsig_s, \brho_s \ra}{\lambda_s N},
    \qquad
    \vR(\bsig, \brho) 
    = 
    \lt(R_1(\bsig, \brho), \ldots, R_r(\bsig, \brho)\rt).
\end{equation}
Let $\odot$ denote coordinate-wise product. 
For $\vx = (x_1,\ldots,x_r) \in \bbR^\sS$, let 
\begin{align*}
    \xi(\vx) 
    &= \sum_{k\ge 2} \la \Gamma^{(k)}\odot \Gamma^{(k)}, (\vlam \odot \vx)^{\otimes k}\ra \\
    &= \sum_{k\ge 2}
	\sum_{s_1\ldots,s_k\in \sS}
	\gamma_{s_1,\ldots,s_k}^2
	(\lambda_{s_1} x_{s_1})
	\cdots
	(\lambda_{s_k} x_{s_k}).
\end{align*}
The random function $\wtH_N$ can also be described as the Gaussian process on $\cB_N$ with covariance
\[
	\bbE \wtH(\bsig)\wtH(\brho)
	=
	N\xi(\vR(\bsig, \brho)).
\]
It will be useful to define, for $s\in \sS$,
\[
    \xi^s(\vx) 
    = 
    \lambda_s^{-1} 
    \partial_{x_s} 
    \xi(\vx).
\]

Our main result is a characterization of the largest energy attainable by algorithms with $O(1)$-Lipschitz dependence on the disorder coefficients.
To define this class of algorithms, we consider the following distance on the space $\sH_N$ of Hamiltonians $H_N$.
We identify $H_N$ with its disorder coefficients $(\Gp{k})_{k\ge 2}$, which we concatenate in an arbitrary but fixed order into an infinite vector $\bg(H_N)$. 
We equip $\sH_N$ with the (possibly infinite) distance
\[
    \norm{H_N - H'_N}_2
    =
    \norm{\bg(H_N) - \bg(H'_N)}_2
\]
and $\cB_N$ with the $\ell_2$ distance.
For each $\tau > 0$, these distances define a class of $\tau$-Lipschitz functions $\cA_N : \sH_N \to \cB_N$, satisfying 
\[
    \norm{\cA_N(H_N) - \cA_N(H'_N)}_2 \le \tau \norm{H_N - H'_N}_2,\quad\forall~H_N,H_N'\in \sH_N.
\]
Note that this inequality holds vacuously for pairs $(H_N,H_N')$ where the latter distance is infinite.
As explained in \cite[Section 8]{huang2021tight}, the class of $O(1)$-Lipschitz algorithms includes gradient descent and Langevin dynamics for the Gibbs measure $e^{\beta H_N(\bsig)} \de \bsig$ (with suitable reflecting boundary conditions) run on constant time scales.\footnote{Up to modification on a set of probability at most $e^{-cN}$, which suffices just as well for our purposes.} 
The behavior of such dynamics has been a major focus of study in its own right, see e.g. \cite{sompolinsky1981dynamic,cugliandolo1994out,arous1995large,arous1997symmetric,arous2001aging,arous2006cugliandolo,arous2020bounding,dembo2020dynamics,dembo2021diffusions,dembo2021universality,celentano2021high}. 




We will characterize the largest energy attainable by a $\tau$-Lipschitz algorithm, where $\tau$ is an arbitrarily large constant independent of $N$, in terms of the following variational principle.
For $0 \le q_0 \le q_1 \le 1$, let $\bbI(q_0,q_1)$ be the set of increasing, continuously differentiable functions $f : [q_0,q_1] \to [0,1]$.
Let $\Adm(q_0,q_1) \subset \bbI(q_0,q_1)^\sS$ be the set of coordinate-wise increasing, continuously differentiable functions $\Phi:[q_0,q_1]\to [0,1]^{\sS}$ which satisfy, for all $q\in [q_0,q_1]$,
\begin{equation}
    \label{eq:admissible}
    \la \vlam, \Phi(q)\ra = q.
\end{equation}
We say $\Phi$ is \emph{admissible} if it satisfies \eqref{eq:admissible}.
For $p \in \bbI(q_0,1)$, $\Phi \in \Adm(q_0,1)$, define the algorithmic functional
\begin{equation}
    \label{eq:alg-functional}
    \bbA(p,\Phi; q_0)
    \equiv
    \sum_{s\in \sS}
    \lambda_s \lt[
        h_s \sqrt{\Phi_s(q_0)}
        +
        \int_{q_0}^1
        \sqrt{\Phi'_s(q) (p\times \xi^s \circ \Phi)'(q)}
        ~\de q
    \rt]
\end{equation}
where $(p\times \xi^s\circ \Phi)(q) = p(q) \xi^s(\Phi(q))$. (See the end of this subsection for an interpretation of this formula.)
We can now state the algorithmic threshold for multi-species spherical spin glasses:
\begin{equation}
    \label{eq:alg}
    \ALG
    \equiv
    \sup_{q_0\in [0,1]}
    \sup_{\substack{p\in \bbI(q_0,1) \\ \Phi \in \Adm(q_0,1)}} \bbA(p,\Phi; q_0).
\end{equation}

The following theorem is our main result. Together with Theorem~\ref{thm:main-alg} in our forthcoming companion work \cite{amp-in-progress}, we find that $\ALG$ is the largest energy attained by an $O(1)$-Lipschitz algorithm.
Here and throughout, all implicit constants may depend also on $(\xi,\vh,\vlam)$.

\begin{theorem}
\label{thm:main-ogp}
    Let $\tau, \eps > 0$ be constants.
    For $N\geq N_0$ sufficiently large, any $\tau$-Lipschitz $\cA_N : \sH_N \to \cB_N$ satisfies
    \[
        \bbP[H_N(\cA_N(H_N))/N \ge \ALG + \eps]
        \le 
        \exp(-cN),
        \qquad
        c = c(\eps, \tau) > 0.
    \]
\end{theorem}

\begin{theorem}[Proved in \cite{amp-in-progress}]
\label{thm:main-alg}
For any $\eps>0$, there exists an efficient and $O_{\eps}(1)$-Lipschitz algorithm $\cA_N:\sH_N\to \cB_N$ such that
    \[
        \bbP[H_N(\cA_N(H_N))/N \geq \ALG-\eps]
        \ge 1-\exp(-cN),
        \quad 
        c = c(\eps) > 0.
    \] 
\end{theorem}

Our proof of Theorem~\ref{thm:main-alg} in \cite{amp-in-progress} uses approximate message passing (AMP), a general family of gradient-based algorithms, following a recent line of work \cite{subag2018following,mon18,ams20,alaoui2022algorithmic,sellke2021optimizing}.


In fact, in Theorem~\ref{thm:main-ogp} we will not require the full Lipschitz assumption on $\cA_N$.
Theorem~\ref{thm:main-ogp} holds for all algorithms satisfying an \emph{overlap concentration} property (see Definition~\ref{defn:oc}, Theorem~\ref{thm:main-ogp-oc}), that for any fixed correlation $p\in [0,1]$ between the disorder coefficients of $H_N^1$ and $H_N^2$, the overlap vector $\vR(\cA_N(H_N^1), \cA_N(H_N^2))$ concentrates tightly around its mean.
This property holds automatically for $O(1)$-Lipschitz $\cA_N$ due to Gaussian concentration of measure.

\paragraph{Interpretation of the Algorithmic Functional $\bbA$}


Suppose first that $\vh = \vzero$. 
We will see (Theorem~\ref{thm:alg-optimizer}) that $\ALG$ is maximized at $q_0=0$, $p\equiv 1$, in which case 
\begin{equation}
    \label{eq:alg-no-field}
    \bbA(p,\Phi; q_0) = \sum_{s\in \sS} \lambda_s \int_0^1 \sqrt{\Phi'_s(q) (\xi^s \circ \Phi)'(q)} ~\de q.
\end{equation}
In a single-species spherical spin glass, we have $\lambda_1=1$ and $\Phi(q)=q$, so \eqref{eq:alg-no-field} reduces to the formula $\ALG = \int_0^1 \xi''(q)^{1/2}~\de q$ derived in \cite{huang2021tight}.
This energy is attained by the algorithm of Subag \cite{subag2018following}, which starts from the origin and explores to the surface of the sphere by small orthogonal steps in the direction of the largest eigenvector of the local tangential Hessian.

In multi-species models, \eqref{eq:alg-no-field} is the energy attained by a generalization of Subag's algorithm, which is essentially shown in Proposition~\ref{prop:uc-bogp}.
Instead of computing a maximal eigenvector at each step, given the current iterate $\bx^t$ this algorithm chooses $\bx^{t+1}$ to maximize $\langle \nabla^2 H_N(\bx^t), (\bx^{t+1}-\bx^t)^{\otimes 2}\rangle$
on a product of $r$ small spheres centered at $\bx^t$. 
This algorithm may advance through different species at different speeds by tuning the radii of the spheres at each step, and the function $\Phi$ is a ``radius schedule" whose image specifies the path of depths $(\norm{\bx_s^t}_2^2/\lambda_s N)_{s\in \sS}$ traced by the iterates $\bx^t$.
Thus each $\Phi \in \Adm(0,1)$ corresponds to an algorithm, and Theorem~\ref{thm:main-ogp} essentially states that the algorithmic threshold is the energy attained by the multi-species Subag algorithm with the best $\Phi$.


The function $p$ arises from a further generalization of this algorithm, which becomes necessary in the presence of external field $\vh\neq \vzero$.
The idea is to reveal the disorder coefficients of $H_N$ gradually (in the sense of progressively less noisy Gaussian observations, see \eqref{eq:def-correlated-disorder}) and in tandem with the iterates $\bx^t$.
Though counterintuitive, this allows the algorithm to take advantage of the gradients of the newly revealed part of $H_N$ at each step.
The iterate $\bx^{t+1}$ is now chosen to maximize the sum
\begin{equation}
    \label{eq:compound-objective}
    \langle \nabla (H_N^{t+1} - H_N^t)(\bx^t), \bx^{t+1}-\bx^t \rangle
    + \frac{1}{2}\langle \nabla^2 H_N^t(\bx^t), (\bx^{t+1}-\bx^t)^{\otimes 2}\rangle
\end{equation}
of a gradient contribution from the new component and a Hessian contribution from the previously revealed components.
The function $p$ is an ``information schedule" that determines the rate at which entries of $H_N$ are revealed.
Moreover, to take advantage of the external field, the algorithm starts from a point $\bx^0$ correlated with $\bh$ whose norm is $q_0 \sqrt{N}$; the first term in \eqref{eq:alg-functional} is exactly the value $\langle \bh,\bx^0\rangle/N$ (see \eqref{eq:root-energy}).

Technically it is not obvious whether these generalized Subag algorithms can be directly made suitably Lipschitz. This is one reason we prove Theorem~\ref{thm:main-alg} using AMP in \cite{amp-in-progress}. 

\subsection{Description of Maximizers to the Algorithmic Variational Problem}

In this subsection we describe the detailed properties of the maximizers $(p,\Phi,q_0)$ of \eqref{eq:alg}, culminating in an explicit description in Theorem~\ref{thm:alg-optimizer} as a piecewise combination of solutions to two ordinary differential equations.


For intuition, it may help to recall the famous ansatz that spin glass Gibbs measures are asymptotically ultrametric, corresponding to orthogonally branching trees in $\bbR^N$ (see e.g. \cite{mezard1985microstructure,panchenko2013parisi,jagannath2017approximate,chatterjee2019average}). When $\vh=\vzero$, the associated tree is rooted at the origin; otherwise the root's location is correlated with $\bh$ but random.
Theorem~\ref{thm:alg-optimizer} below shows that maximizers of $\bbA$ consist of a ``root-finding" component and a ``tree-descending" component; the corresponding algorithms first locate an analogous root, and then descend an algorithmic analog of a low-temperature ultrametric tree. 


This description holds under the following generic assumption.
\begin{assumption}
    \label{as:nondegenerate}
    All quadratic and cubic interactions participate in $H$, i.e. $\Gamma^{(2)}, \Gamma^{(3)} > 0$ coordinate-wise.
    We will call such models \textbf{non-degenerate}.
\end{assumption}
Note that $\ALG$ is continuous in the parameters $\xi,\vh$ (for a simple proof, first observe that $\bbA$ and hence $\ALG$ are monotone and subadditive in $(\xi,\vh)$).
Since Assumption~\ref{as:nondegenerate} is a dense condition, to determine the value of $\ALG$ it suffices to do so under this assumption.
In fact we will describe in detail the maximizing triples $(p,\Phi;q_0)$ under this assumption, which always exist but need not be unique.
Non-degeneracy removes extraneous symmetries among the maximizers of $\bbA$ which arise when e.g. $\xi$ is a sum of polynomials in disjoint sets of variables.


\begin{definition}
    \label{defn:diag-signed}
    A matrix $M\in \bbR^{\sS \times \sS}$ is \textbf{diagonally signed} if $M_{i,i}\ge 0$ and $M_{i,j}<0$ for all $i\neq j$.
\end{definition}
\begin{definition}
    \label{defn:solvable}
    A symmetric diagonally signed matrix $M$ is \textbf{super-solvable} if it is positive semidefinite, and \textbf{solvable} if it is furthermore singular; otherwise $M$ is \textbf{strictly sub-solvable}.
    A point $\vx \in (0,1]^\sS$ is super-solvable, solvable, or strictly sub-solvable if $M^*_\sym(\vx)$ is, where
    \begin{equation}
        \label{eq:M*sym}
        M^*_\sym(\vx) = 
        \diag\lt(\lt(\fr{\partial_{x_s}\xi(\vx) + \lambda_s h_s^2}{x_s}\rt)_{s\in \sS}\rt) 
        - \lt(\partial_{x_s,x_{s'}}\xi(\vx)\rt)_{s,s'\in \sS}
        .
    \end{equation}
    We also adopt the convention that $\vzero$ is always super-solvable, and solvable if $\vh=\vzero$. 
\end{definition}

\begin{remark}
    It is possible to extend the notions of (super, strict sub)-solvability to all of $[0,1]^\sS$ by using the alternative characterization from Corollary~\ref{cor:solvability-equivalent}. 
    However this will not be necessary, as our results only use these notions for $\vx \in (0,1]^\sS \cup \{\vzero\}$.
\end{remark}


\begin{definition}
\label{defn:root-finding-trajectory}
    Suppose $\vx \in (0,1]^\sS$ is super-solvable with $\la \vlam, \vx\ra = q_1$.
    A \textbf{root-finding trajectory} with endpoint $\vx$ is a pair $(p,\Phi) \in \bbI(q_0,q_1) \times \Adm(q_0,q_1)$, for some $q_0 \in [0, q_1]$, satisfying $p(q_1)=1$, $\Phi(q_1) = \vx$, $p(q_0)=0$, and for all $q\in [q_0,q_1]$:
    \begin{equation}
        \label{eq:root-finding-ode}
        \fr{(p\times \xi^s \circ \Phi)'(q)}{\Phi'_s(q)}
        =
        L_s\equiv \fr{\xi^s(\vx) + h_s^2}{x_s},\quad\forall s\in\sS.
    \end{equation}
\end{definition}


Assuming for now that $p,\Phi_s\in C^1([q_0,1])$,
\eqref{eq:root-finding-ode} together with admissibility can be written for each $q\in [q_0,q_1]$ as the ordinary differential equation

\begin{align}
\label{eq:root-finding-system-1}
    p'(q) 
    \xi^s(\Phi(q))
    +
    p(q)
    \sum_{s'\in\sS}
    \partial_{x_{s'}}\xi^s(\Phi(q))
    \,
    \Phi_{s'}'(q)
    &=
    L_s \Phi_s'(q),\quad\forall s\in\sS;
    \\
\label{eq:root-finding-system-2}
    \sum_{s\in\sS}
    \lambda_s \Phi_s'(q)
    &=
    1;
    \\
\label{eq:root-finding-system-3}
    p'(q),\Phi_s'(q)&\geq 0.
\end{align}
Here $\vL$ is treated as fixed, as it is determined by the boundary condition at $q_1$. Note that equation~\eqref{eq:root-finding-system-1} does not depend on $q$, except that $\Phi(q)$ determines $q$ via admissibility. In fact \eqref{eq:root-finding-system-1} is equivalent to a well-posed ordinary differential equation (away from $\vzero$, which it never reaches by Proposition~\ref{prop:root-finding-trajectory}). Moreover as shown in Proposition~\ref{prop:root-finding-trajectory}(\ref{it:unique-root-finding}), solving this ODE from a super-solvable initial condition always yields a valid root-finding trajectory (e.g. the resulting $p$ is actually increasing on $[q_0,q_1]$).


\begin{proposition}
\label{prop:root-finding-well-posed}
    For $(p(q),\Phi(q))$ in compact subsets of $[0,1]\times (0,1]^\sS$ the equation \eqref{eq:root-finding-system-1} has a unique solution $(p'(q),\Phi'(q))$ which is locally Lipschitz in $(p(q),\Phi(q))$.
\end{proposition}


\begin{proposition}
    \label{prop:root-finding-trajectory}
    $\vh \neq \vzero$ if and only if there exists a super-solvable $\vx \in (0,1]^\sS$. 
    If this holds, for each such $\vx$: 
    \begin{enumerate}[label=(\alph*), ref=\alph*]
        % \item \label{it:vh}
        \item
        \label{it:unique-root-finding}
        Let $q_1 = \la \vlam, \vx\ra > 0$.
        There is a unique root-finding trajectory $(p,\Phi)$ with endpoint $\vx$. It is obtained by solving \eqref{eq:root-finding-system-1} backward in time from initial condition $p(q_1)=1$, $\Phi(q_1)=\vx$ until reaching $p(q_0)=0$. Moreover the resulting $p$ is increasing and concave on $[q_0,q_1]$.
        \item 
        \label{it:unique-root-finding-q0}
        $q_0>0$, and in fact $\Phi_s(q_0)>0$ if and only if $h_s>0$.
    \end{enumerate}
\end{proposition}


\begin{definition}
    \label{defn:tree-descending-trajectory}
    Suppose $\vx \in (0,1]^\sS \cup \{\vzero\}$ is solvable with $\la \vlam, \vx\ra = q_1$.
    A \textbf{tree-descending trajectory} with endpoint $\vx$ is a pair $(p,\Phi) \in \bbI(q_1,q_2) \times \Adm(q_1,q_2)$ satisfying $p\equiv 1$, $\Phi(q_1)=\vx$, $M^*_\sym(\vx) \Phi'(q_1) = \vzero$, $\norm{\Phi_s(q_2)}_\infty = 1$ and
    \begin{equation}
        \label{eq:tree-descending-ode}
        \fr{1}{\Phi'_s(q)}
    	\deriv{q}
    	\sqrt{\fr{\Phi'_s(q)}{(\xi^s \circ \Phi)'(q)}}
    	=
		\fr{1}{\Phi'_{s'}(q)}
    	\deriv{q}
    	\sqrt{\fr{\Phi'_{s'}(q)}{(\xi^{s'} \circ \Phi)'(q)}}
    \end{equation}
    for all $s,s'\in \sS$ and $q\in [q_1,q_2]$.
    Moreover, $(p,\Phi)$ is \emph{targeted} if $\Phi(1)=\vone$ (i.e. $q_2=1$).
\end{definition}


Similarly to \eqref{eq:root-finding-system-1}, assuming $\Phi''$ is defined, \eqref{eq:tree-descending-ode} together with the admissibility constraint 
\begin{equation}
\label{eq:admissible-second-order}
\sum_{s\in\sS} \lambda_s\Phi_s''(q)=0
\end{equation}
is equivalent to a second order differential equation. We show in Subsection~\ref{subsec:type-II} and Appendix~\ref{subsec:type-II-Lipschitz} that this equation is suitably well-posed and obtain the following results.




\begin{proposition}
    \label{prop:tree-descending-trajectory}
    Suppose Assumption~\ref{as:nondegenerate} holds and $\vx \in (0,1]^\sS \cup \{\vzero\}$ is solvable with $\la \vlam, \vx\ra = q_1$.
    \begin{enumerate}[label=(\alph*), ref=\alph*]
        \item \label{itm:tree-descending-with-field} If $\vh \neq \vzero$, then $\vx \in (0,1]^\sS$ and $q_1 > 0$. 
        There is a unique $\vv \in \bbR_{\ge 0}^\sS$ satisfying
        \begin{align}
            \label{eq:start-velocity-direction}
            M^*_\sym(\vx)\vv &= \vzero, \\
            \label{eq:start-velocity-magnitude}
            \la \vlam, \vv\ra &= 1.
        \end{align}
        There is a unique tree-descending trajectory with endpoint $\vx$, which is obtained by solving \eqref{eq:tree-descending-ode} forward in time from $\Phi(q_1)=\vx$, $\Phi'(q_1)=\vv$ until reaching $\norm{\Phi_s(q_2)}_\infty = 1$.
        \item \label{itm:tree-descending-no-field} If $\vh = \vzero$, then $\vx = \vzero$ and $q_1 = 0$. 
        For any $\vv \in \bbR_{\ge 0}^{\sS}$ satisfying \eqref{eq:start-velocity-magnitude}, there is a unique tree-descending trajectory with $\Phi(0)=\vzero$ and $\Phi'(0)=\vv$, which is obtained by solving \eqref{eq:tree-descending-ode} forward in time from these conditions until reaching $\norm{\Phi_s(q_2)}_\infty = 1$.
    \end{enumerate}
\end{proposition}

The following theorem is our main result describing maximizers of \eqref{eq:alg}. 
\begin{theorem}
    \label{thm:alg-optimizer}
    Suppose Assumption~\ref{as:nondegenerate} holds.
    Then a maximizer $(p,\Phi,q_0)$ of \eqref{eq:alg} exists, and all maximizers are continuously differentiable on $[q_0,1]$. 
    There exists $q_1\in [q_0,1]$ such that $\Phi(q_1) \in (0,1]^\sS \cup \{\vzero\}$ and furthermore 
    $(p,\Phi)$ is the root-finding trajectory with endpoint $\Phi(q_1)$ on $[q_0,q_1]$ and a (targeted) tree-descending trajectory with endpoint $\Phi(q_1)$ on $[q_1,1]$. $\ALG$ is given by
    \begin{equation}
        \label{eq:alg-for-optimizer}
        \ALG = 
        \bbA(p,\Phi; q_0) =
        \sum_{s\in \sS}
        \lambda_s \lt[
            \sqrt{\Phi_s(q_1) (\xi^s(\Phi(q_1)) + h_s^2)}  + 
            \int_{q_1}^1 \sqrt{\Phi'_s(q)(\xi^s\circ \Phi)'(q)}~\de q
        \rt].
    \end{equation}
    Finally the value of $q_1$ is described as follows:
    \begin{enumerate}[label=(\alph*), ref=\alph*]
        \item \label{itm:supsolvable} If $\vone$ is super-solvable then $q_1=1$, i.e. $(p,\Phi)$ is the root-finding trajectory with endpoint $\vone$.
        \item \label{itm:subsolvable-with-field} If $\vone$ is sub-solvable and $\vh \neq \vzero$, then $q_1 \in (q_0,1)$, i.e. $(p,\Phi)$ contains both root-finding and tree-descending trajectories. 
        \item \label{itm:subsolvable-no-field} If $\vh = \vzero$, then $\vone$ is sub-solvable and $q_1=0$, i.e. $(p,\Phi)$ is a (targeted) tree-descending trajectory with endpoint~$\vzero$. 
    \end{enumerate}
\end{theorem}

Note that in case (\ref{itm:subsolvable-with-field}), $\Phi(q_1) \in (0,1]^\sS$ if $h_s>0$ for \textbf{any} $s$.
Examples of each of these cases are given in Figure~\ref{fig:ode}.

\begin{remark} 
    \label{rem:normalization}
    The choice of state space $\cB_N$ is a natural though arbitrary normalization.
    For any $\va \in \bbR_{>0}^\sS$, we could just as well consider the state space 
    \begin{equation}
    \label{eq:BN-va}
        \cB_N(\va) = \lt\{
            \bx \in \bbR^N : \tnorm{\bx_s}_2^2 \le a_s \lambda_s N ~\forall s\in \sS
        \rt\}.
    \end{equation}
    Clearly optimizing the model described by $\xi,\vh$ over this space is equivalent to optimizing the model described by\footnote{Here and throughout this paper, powers of vectors such as $\sqrt{\va}$ are taken coordinate-wise.}
    \begin{equation}
        \label{eq:rescale-problem-transformation}
        \tilde \xi(\vx) = \xi(\vx \odot \sqrt{\va}), \qquad
        \tilde \vh = \vh \odot \sqrt{\va}
    \end{equation} 
    over $\cB_N$, so changing the problem in this way does not add any complexity.
    However, from this point of view we can see that the requirement in the equation \eqref{eq:alg} and Theorem~\ref{thm:alg-optimizer} that $\Phi(1) = \vone$ is merely a product of the normalization.
    If we wished to optimize over $\cB_N(\va)$, equation \eqref{eq:alg} and Theorem~\ref{thm:alg-optimizer} still hold with the right endpoint of $\Phi$ changed to $\va$, which is easily proved by the transformation \eqref{eq:rescale-problem-transformation}.
    Thus the non-targeted trajectories in Figure~\ref{fig:ode} describe optimal algorithms for other state spaces $\cB_N(\va)$.
\end{remark}

\begin{remark}
    Because the root-finding and tree-descending ODEs are well-posed, the results above give a natural approach to solve the $N$-independent problem of approximately maximizing $\bbA$ to $\eps$ error. If $\vone$ is super-solvable then $\ALG$ is given directly by \eqref{eq:alg-for-optimizer}. If $\vh\neq \vzero$, then it suffices to brute-force search for the value $\Phi(q_1)$ over a $\delta$-net of solvable $\vx\in [0,1]^{\sS}$ and solve each of the two ODEs above; note that the vector $\Phi'(q_1)$ is determined by \eqref{eq:root-finding-system-1}. Finally if $\vh=\vzero$, since $q_1=0$ it suffices to brute-force search over all $\Phi'(0)$ satisfying \eqref{eq:root-finding-system-2}.
\end{remark}

% \iffalse
\begin{figure}[t]
    \begin{subfigure}[b]{.32\textwidth}
        \centering
        \includegraphics[width=.9\linewidth]{imgs-final/phi-supersolvable.png} \\
        \includegraphics[width=.9\linewidth]{imgs-final/p-supersolvable.png}
        \caption{$\vh = (0.4,1.4)$, $\vone$ super-solvable.}
        \label{subfig:supersolvable}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{.32\textwidth}
        \centering
        \includegraphics[width=.9\linewidth]{imgs-final/phi-subsolvable-with-field.png} \\
        \includegraphics[width=.9\linewidth]{imgs-final/p-subsolvable-with-field.png}
        \caption{$\vh = (0.4,0.4)$, $\vone$ sub-solvable.}
        \label{subfig:with-field}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{.32\textwidth}
        \centering
        \includegraphics[width=.9\linewidth]{imgs-final/phi-no-field.png} \\
        \includegraphics[width=.9\linewidth]{imgs-final/p-no-field.png}
        \caption{$\vh = (0,0)$.}
        \label{subfig:no-field}
    \end{subfigure}
    \caption{
    \small
        Examples of Theorem~\ref{thm:alg-optimizer}.
        Consider the model $\vlam = (\fr13, \fr23)$, $\xi(x_1,x_2) = \nu(\lambda_1x_1,\lambda_2x_2)$, and various $\vh$ specified in the captions above, where $\nu(x_1,x_2) = x_1^2 + x_1x_2 + x_2^2 + x_1^4 + x_1x_2^3$.
        These are described by parts (\ref{itm:supsolvable}), (\ref{itm:subsolvable-with-field}), and (\ref{itm:subsolvable-no-field}) of Theorem~\ref{thm:alg-optimizer}, respectively.
        The top diagrams plot $\Phi(q)$ with root-finding components green and tree-descending components blue.
        The optimal $\Phi$, which passes through $(1,1)$, is bold.
        Figures~\ref{subfig:with-field} and \ref{subfig:no-field} show non-targeted trajectories otherwise described by Theorem~\ref{thm:alg-optimizer}.
        In Figure~\ref{subfig:supersolvable} the black curve comprises the solvable points and $(1,1)$ is inside of this curve.
        In Figure~\ref{subfig:with-field} the outer black curve comprises the solvable points, which are the possible values of $\Phi(q_1)$, and $(1,1)$ is outside of this curve. The inner black curve of Figure~\ref{subfig:with-field} comprises the corresponding values of $\Phi(q_0)$.
        The bottom diagrams plot $(q, p(q))$ for the optimal $p$.
    }
    \label{fig:ode}
\end{figure}
% \fi


\subsection{Explicit Solutions in Special Cases}


While the formulas \eqref{eq:alg}, \eqref{eq:alg-for-optimizer} for $\ALG$ involve the solution to a variational problem, $\ALG$ can be written explicitly in the important special cases of single-species models where $r=1$ and $\vlam = (1)$, and pure models where $\xi$ is a monomial.


\subsubsection{Single-Species Models}

In single-species models, $\xi(q)$ is a univariate function and \eqref{eq:admissible} implies $\Phi(q)=q$.
Let $\vh = (h)$. 
\begin{corollary}[Algorithmic threshold of single-species models]
    \label{cor:alg-one-species}
    If $\xi'(1) + h^2 \ge \xi''(1)$, then 
    \[
        \ALG = (\xi'(1) + h^2)^{1/2}.
    \]
    The variational formula \eqref{eq:alg} is maximized at $q_0=\fr{h^2}{\xi'(1)+h^2}$, $p(q) = \fr{q(\xi'(1)+h^2)-h^2}{\xi'(q)}$ for $q\in [q_0,1]$.
    Otherwise there is a unique $q_1\in [0,1)$ satisfying $\xi'(q_1) + h^2 = q_1 \xi''(q_1)$, and 
    \[  
        \ALG = q_1 \xi''(q_1)^{1/2} + \int_{q_1}^1 \xi''(q)^{1/2}~\de q.
    \]
    The variational formula \eqref{eq:alg} is maximized at
    \[
        q_0 = \fr{h^2}{\xi''(q_1)},
        \qquad
        p(q) =
        \begin{cases}
            \fr{q\xi''(q_1)-h^2}{\xi'(q)} & q\in [q_0,q_1], \\
            1 & q\in [q_1,1].
        \end{cases}    
    \]
\end{corollary}
Except for the formulas for $q_0$ and $p(q)$, this corollary follows readily from Theorem~\ref{thm:alg-optimizer}; note that super-solvability of $\vone$ generalizes the inequality $\xi'(1) + h^2 \ge \xi''(1)$ and solvability of $\Phi(q_1)$ generalizes $\xi'(q_1) + h^2 = q_1 \xi''(q_1)$.
The formulas for $q_0$ and $p(q)$ follow from \eqref{eq:type1-q0-formula} and \eqref{eq:type1-p-formula}.

The formula for $\ALG$ in Corollary~\ref{cor:alg-one-species} matches \cite[Proposition 2.2]{huang2021tight}.
Whereas \cite{huang2021tight} proves this formula for even $\xi$, we obtain it in full generality.
This formula also matches the ground state energy in full replica symmetric breaking models as obtained in \cite[Proposition 2]{chen2017parisi}.


\subsubsection{Direct Proof for Single Species Models without External Field}

In the case $h=0$, the formula for $\ALG$ can be directly recovered from the variational formula \eqref{eq:alg}.
First, we should clearly take $q_0=0$, so $\ALG = \sup_{p\in \bbI(0,1)} \int_0^1 (p\xi')'(q)^{1/2}~\de q$.
Then, because
\[
    \int_t^1 (p\xi')'(q)~\de q
    =
    \xi'(1) - p(t)\xi'(t)
    \ge 
    \xi'(1) - \xi'(t)
    =
    \int_t^1 \xi''(q)~\de q
\]
for all $t\in [0,1]$ with equality at $t=0$, the function $(p\xi')'$ majorizes $\xi''$ (see e.g. \cite{joe1992generalized} for precise definitions of majorization in non-discrete settings). Here we use that $\xi''$ is increasing, but do not assume that $(p\xi')'$ is.
By Karamata's inequality,
\[
    \int_0^1 (p\xi')'(q)^{1/2}~\de q \le \int_0^1 \xi''(q)^{1/2}~\de q
\]
with equality at $p\equiv 1$.

\subsubsection{Pure Models}




Finally we give in Theorem~\ref{thm:pure} below an explicit formula for $\ALG$ for \emph{pure} $\xi$ consisting of a single monomial, and moreover identify the unique maximizer to $\bbA$. 
Our proof in Subsection~\ref{subsec:pure} takes advantage of scale invariance to relate values of $\ALG$ at different radii (see Remark~\ref{rem:normalization}). 
Recently \cite{subag2021tap} used a similar scale invariance (and other ideas) to compute the free energy in such models under the mild assumption of convergence as $N\to\infty$.
Intriguingly for all pure models, the value $\ALG$ agrees with the threshold $E_{\infty}$ arising from critical point asymptotics in \cite{auffinger2013random} and determined in the multi-species setting by \cite{mckenna2021complexity}. 



It should be noted that Assumption~\ref{as:nondegenerate} on non-degeneracy is false for pure models, so we cannot rely on the structural results of Theorem~\ref{thm:alg-optimizer}. 
Additionally, note that although the optimal trajectories $\Phi$ stated in Theorem~\ref{thm:pure} are not admissible, this does not present a problem; Lemma~\ref{lem:admissible-optional} shows that admissibility is just a convenient choice of time parametrization and deviating from it does not affect the value of $\bbA$.


\begin{theorem}
\label{thm:pure}
    Suppose $\vh=\vzero$ and
    \[
    \xi(x_1,\dots,x_r)=\prod_{s\in\sS} x_s^{a_s}
    \]
    for positive integers $a_1,\dots,a_r$ with $r\geq 2$ and $\sum_{s\in\sS}a_s\geq 3$. Define the exponents $b_s$ by
    \begin{equation}
    \label{eq:pure-exponents-formula}
    b_s=
    \frac{1- \sqrt{\frac{a_s}{a_s+L\lambda_s}}}{2},
    \quad s\in \sS
    \end{equation}
    where $L=L(\va)>0$ is the unique value such that $\sum_{s\in\sS}a_s b_s=1$. Then $\ALG$ and the $(p,\Phi,q_0)$ maximizing $\bbA$ are 
    \begin{align*}
    \ALG&=\sum_{s\in\sS} \frac{\lambda_s \sqrt{L a_s}}{\sqrt{a_s+L\lambda_s}},
    \\
    \big(p(q)\,, \Phi(q),\,q_0\big)
    &=
    \big(1,\,(q^{b_1},\dots,q^{b_r}),\,0\big)
    .
    \end{align*}
    In the case $\xi(x_1,x_2)=x_1 x_2$ we have
    \begin{align*}
    \ALG&=\sqrt{\lambda_1}+\sqrt{\lambda_2},
    \\
    \big(p(q)\,, \Phi(q),\,q_0\big)
    &=
    \big(1,\,(q,q),\,0\big)
    .
    \end{align*}
    Moreover the optimal $(p,\Phi,q_0)$ is always unique up to reparametrization.
\end{theorem}




Theorem~\ref{thm:pure} simplifies in the special case that $\frac{a_s}{\lambda_s}$ is independent of $s$, i.e. $\lambda_s=\frac{a_s}{\sum_{s\in\sS}a_s}$. In particular $\ALG$ depends only on the total degree $\sum_{s\in\sS}a_s$. Note that the formula \eqref{eq:pure-exponents-formula} gives $b_s=\frac{1}{\sum_{s\in\sS} a_s}$, which is equivalent by reparametrization to $b_s=1$ as stated below.


\begin{corollary}
\label{cor:pure}
    For pure models with $\lambda_s=\frac{a_s}{\sum_{s'\in\sS}a_{s'}}$, $\Phi(q)=(q,\dots,q)$ uniquely maximizes $\bbA$ and
    \[
    \ALG=2\sqrt{\frac{\big(\sum_{s\in\sS} a_s\big)-1}{\sum_{s\in\sS} a_s}}.
    \]
\end{corollary}



For all pure models, the value $\ALG$ in Theorem~\ref{thm:pure} agrees with the threshold $E_{\infty}$ defined as follows. We denote by $\nabla_{\sph}$ the gradient on the product of spheres $\cS_N\equiv\{\bx\in\cB_N~:~\vR(\bx,\bx)=\vone\}$, and $\nabla^2_{\sph}$ the Riemannian Hessian.
Below the \emph{index} of a square matrix denotes the number of non-negative eigenvalues.

\begin{definition}
\label{defn:E-infty}
    For $\vh=\vzero$ and any $\xi$, the value $E_{\infty}$ is given by $E_{\infty}=\lim_{k\to\infty} E_k\geq 0$. Here $E_k\geq 0$ is the minimal value such that for any $E>E_k$,
    \[
    \lim_{N\to\infty}
    \frac{1}{N}
    \log
    \bbE\lt[
    \lt|
    \lt\{
    \bsig\in\cS_N~:~
    H_N(\bsig)\geq EN,~
    \nabla_{\sph}H_N(\bsig)=0,~
    \text{index}(\nabla^2_{\sph} H_N(\bsig))\ge k
    \rt\}
    \rt|
    \rt]
    <0.
    \]
\end{definition}



Informally, $E_{\infty}$ is the threshold above which critical points of unbounded index cease to exist in an annealed sense. 
For multi-species spin glasses, $E_{\infty}$ is given by the somewhat complicated formula \cite[Equation (2.7)]{mckenna2021complexity} which involves the solution to a matrix Dyson equation, recalled in Subsection~\ref{subsec:pure}. This generalizes the single-species formulas in \cite{auffinger2013random,arous2020geometry}.
We note that for pure \emph{single-species models}, \cite[Theorem 1.4]{auffinger2020number} claims (without a full proof yet) that for any $E<E_{\infty}$, critical points of bounded index (depending only on $E$) exist above energy $E$ with high probability. 

\begin{corollary}
\label{cor:E-infty}
    For all pure $\xi$, we have
    \[
    \ALG=E_{\infty}.
    \]
\end{corollary}

In the single species case, Corollary~\ref{cor:E-infty} holds for the pure $p$-spin model $\xi(x)=x^p$ with
$\ALG=E_{\infty}=2\sqrt{\frac{p-1}{p}}$ identified in \cite{auffinger2013random}, as discussed in \cite[Section 2.3]{huang2021tight}.
While the single-species formula is simple, Corollary~\ref{cor:E-infty} is much less obvious in general. 
In \cite{amp-in-progress} we will give a more general approach to this connection by showing that the top of the bulk spectrum of $\nabla^2_{\sph} H_N(\bsig)$ is approximately $0$ for $\bsig$ the output of an explicit optimization algorithm attaining value $\ALG$. This statement holds for all $\xi$ and implies that $\ALG$ in general lies in an interval denoted [$E_{\infty}^-,E_{\infty}]$ in \cite{auffinger2013complexity}.




\subsection{Non-Uniqueness of Maximizers and Algorithmic Symmetry Breaking}
\label{subsec:ASB}

 
In cases (\ref{itm:subsolvable-with-field}) and (\ref{itm:subsolvable-no-field}) of Theorem~\ref{thm:alg-optimizer}, the ODE description of maximizers does \emph{not} uniquely determine $(p,\Phi)$.
In case (\ref{itm:subsolvable-with-field}), each $(p,\Phi)$ described by Theorem~\ref{thm:alg-optimizer} is specified by the point $\vx = \Phi(q_1)$, which must be solvable and have the property that the tree-descending trajectory with endpoint $\vx$ (unique by Proposition~\ref{prop:tree-descending-trajectory}) is targeted. 
In case (\ref{itm:subsolvable-no-field}), each $(p,\Phi)$ is specified by the velocity $\vv = \Phi'(0)$, which must satisfy \eqref{eq:start-velocity-magnitude} and have the property that the tree-descending trajectory with endpoint $\vzero$ and starting velocity $\vv$ (unique by Proposition~\ref{prop:tree-descending-trajectory}) is targeted.
There may be multiple possible $\vx$ or $\vv$; see Figure~\ref{fig:asb} for examples.



In fact, even in \emph{symmetric} two-species models -- where $\vlam = (\fr12,\fr12)$, $\vh = (h,h)$, and $\xi(q_1,q_2)$ is symmetric in $q_1,q_2$ -- there may be many $(p,\Phi)$ described by Theorem~\ref{thm:alg-optimizer}.
Moreover, surprisingly, the maximizer of \eqref{eq:alg} need not be symmetric!
The only possible symmetric maximizer is $\Phi(q)=(q,q)$, which (for suitable $p$) satisfies the properties in Theorem~\ref{thm:alg-optimizer}.
In Figures~\ref{subfig:with-field-asb} and \ref{subfig:no-field-asb} we give examples of models, corresponding to cases (\ref{itm:subsolvable-with-field}) and (\ref{itm:subsolvable-no-field}) of Theorem~\ref{thm:alg-optimizer}, where a pair of asymmetric $\Phi$ numerically outperform the symmetric $\Phi$.
We name this phenomenon \emph{algorithmic symmetry breaking}.\footnote{While we don't prove rigorously that these examples exhibit algorithmic symmetry breaking, it can be verified explicitly that for the model $\xi(x,y)=x^4+y^4+24xy$, $\vh = (0,0)$ with endpoint $\va = (5,5)$ (cf. Remark~\ref{rem:normalization}), the symmetric path $\Phi(q)=(q,q)$ is not even a local optimum as witnessed by $\Phi^{\eps}(q)=(q+\eps\sin(\pi q/10),q)$.}
The presence of algorithmic symmetry breaking implies that there exist symmetric models where the best instantiation of the multi-species Subag algorithm advances through the species asymmetrically.
Note that it is impossible for solutions to a first order ODE to cross, but the tree-descending ODE is second order which enables this behavior.


It is also possible to have 
several trajectories satisfying the ODE description in Theorem~\ref{thm:alg-optimizer} and we expect an unbounded number can coexist, see Figure~\ref{subfig:many-asb}.
While it is a priori unclear that the extremal trajectories attaining value $E_1$ (defined in the caption) outperform the diagonal trajectory, there is a simple reason the diagonal-crossing trajectories attaining $E_2$ cannot be optimal: if these two trajectories were optimal, then 
joining their above-diagonal parts would yield another global maximizer which is not $C^1$ and in particular does not satisfy the ODE description of Theorem~\ref{thm:alg-optimizer}. (Note also that different trajectories must have different derivatives where they meet, given their description by a second order ODE.)
We leave the question of characterizing global maximizers in the presence of algorithmic symmetry breaking for future work.


We emphasize that algorithmic symmetry breaking is not a barrier to any algorithm, as the optimal $(p,\Phi,q_0)$ for the variational principle needs to be computed only once.
Moreover $\xi$ is convex in the examples shown in Figure~\ref{fig:asb}, so algorithmic symmetry breaking is not related to the failure of the interpolation method to determine the free energy (obtained for convex $\xi$ in \cite{bates2022free}).


\begin{figure}
    \begin{subfigure}[b]{.32\textwidth}
        \centering
        \includegraphics[width=.9\linewidth]{imgs-final/asb-with-field.png}
        \caption{
            $h=1.5$, $a=3$.
            Here $E_0 \approx 7.1755$, $E_1 \approx 7.1767$. 
        }
        \label{subfig:with-field-asb}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{.32\textwidth}
        \centering
        \includegraphics[width=.9\linewidth]{imgs-final/asb-no-field.png}
        \caption{
            $h=0$, $a=3$.
            Here $E_0 \approx 6.9230$, $E_1 \approx 6.9254$.
        }
        \label{subfig:no-field-asb}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{.32\textwidth}
        \centering
        \includegraphics[width=.9\linewidth]{imgs-final/asb-many.png}
        \caption{
            $h=0$, $a=5$.
            Here $E_0 \approx 17.0286$, $E_1 \approx 17.0642$, $E_2 \approx 17.0292$.
        }
        \label{subfig:many-asb}
    \end{subfigure}
    \caption{
    \small
        Plots of $\Phi(q)$ with algorithmic symmetry breaking.
        Consider $\vlam = (\fr12,\fr12)$, $\vh = (h,h)$, and $\xi(x_1,x_2) = \nu(a\lambda_1x_1,a\lambda_2x_2)$ for $h,a$ given in the captions above, where $\nu(x_1,x_2) = x_1^2 + x_1x_2 + x_2^2 + x_1^4 + x_2^4$.
        Figure~\ref{subfig:with-field-asb} shows an example with external field (Theorem~\ref{thm:alg-optimizer}(\ref{itm:subsolvable-with-field})), Figure~\ref{subfig:no-field-asb} shows an example without external field (Theorem~\ref{thm:alg-optimizer}(\ref{itm:subsolvable-no-field})), and Figure~\ref{subfig:many-asb} shows an example with several symmetry-breaking trajectories.
        Targeted trajectories are bold and colors have the same meaning as in Figure~\ref{fig:ode}.
        Numerical estimates of the energy $\bbA(p,\Phi; q_0)$ attained by each bold path are given in the captions: $E_0$ is the energy of the diagonal trajectory and $E_k$ is the energy of the asymmetric trajectories that intersect the diagonal $k$ times not including $(0,0)$.
        In all cases the asymmetric trajectories outperform the symmetric trajectory, and in Figure~\ref{subfig:many-asb} the asymmetric trajectories farthest from diagonal perform the best.
    }
    \label{fig:asb}
\end{figure}


Assuming non-degeneracy, we show that algorithmic symmetry breaking does not occur sufficiently close to $\vzero$. 
To make this precise, let $\Delta^r = \{\vv \in \bbR_{\ge0}^\sS : \la \vlam, \vv\ra = 1\}$ denote the simplex of admissible $\Phi'$ vectors.
Then if $\vh=\vzero$, we define a map $F_{t}:\Delta^r\to \Delta^r$ given by
\begin{equation}
\label{eq:F-t}
    F_{t}(\vv)=\Phi(t)/t
\end{equation}
where $\Phi$ is the tree-descending trajectory with endpoint $\Phi(0)=\vzero$, $\Phi'(q)=\vv$. The next proposition shows that $F_{t}$ is injective for small $t$, i.e. algorithmic symmetry breaking is absent sufficiently close to the origin, and is surjective for all $t$.


\begin{proposition}
\label{prop:type-II-locally-unique}
Assume $\xi$ is non-degenerate and $\vh=\vzero$. There exists $\eps>0$ such that the map $F_{t}$ defined in \eqref{eq:F-t} is injective for $t\in (0,\eps]$. Moreover $F_{t}$ is surjective for all $t>0$.
\end{proposition}



\subsection{Branching Overlap Gap Property as a Tight Barrier to Algorithms}
\label{subsec:bogp-summary}

Mean-field spin glasses, including the multi-species models we focus on here, are natural examples of random optimization problems.
Other examples are random constraint satisfaction problems such as random (max)-$k$-SAT and random perceptron models. 
For any such problem, a basic property to understand is the maximum objective that an efficient algorithm can find.

Since the early 2000s, there has been extensive heuristic work in the physics and computer science communities aiming to understand this question in terms of geometric properties of these problems' solution spaces \cite{krzakala2007gibbs, zdeborova2007phase, achlioptas2008phasetransitions}.
The first rigorous link from solution geometry to hardness was obtained by Gamarnik and Sudan \cite{gamarnik2014limits}, in the form of the Overlap Gap Property (OGP).
An OGP argument shows that the absence of a certain geometric constellation in the super-level set $S_E(H_N) = \{\bsig : H_N(\bsig) / N \ge E\}$ implies that suitably stable algorithms cannot find objectives larger than $E$.
The proof is by contradiction, showing that a stable algorithm attaining value $E$ can construct the forbidden constellation.

The value $E$ at which the constellation disappears (and at which hardness is shown) depends on the constellation and does not generally equal the value $\ALG$ found by the best efficient algorithm.
The first OGP works used as the constellation a pair of solutions with medium overlap \cite{gamarnik2014limits, gamarnik2019overlap, chen2019suboptimality, gamarnik2020optimization}.
Subsequent work considered constellations with more points, arranged in a ``star" \cite{rahman2017independent, gamarnik2017performance, gamarnik2021partitioning, gamarnik2022algorithms} or ``ladder" \cite{wein2020independent, bresler2021ksat} configuration; these constellations vanish at smaller $E$, thereby showing hardness closer to $\ALG$.
In particular, \cite{rahman2017independent, wein2020independent} identify the computational threshold of maximum independent set on $G(N,d/N)$ within a $1+o_d(1)$ factor, and \cite{bresler2021ksat} identifies that of random $k$-SAT within a constant factor clause density.
We refer the reader to \cite[Sections 1.2 and 1.3]{huang2021tight} for a more detailed discussion and \cite{gamarnik2021survey} for a survey of OGP.

Our previous work \cite{huang2021tight} introduced the \emph{branching OGP}, where the forbidden constellation is a densely branching ultrametric tree.
For mixed even $p$-spin models, this work showed that this constellation is absent for any $E>\ALG$, and therefore Lipschitz algorithms cannot surpass $\ALG$.
It was further shown that for these models, any ultrametric constellation that is not densely branching is \emph{not} forbidden at all $E>\ALG$, and thus the branching OGP is necessary to show hardness at $\ALG$.
As discussed previously, the hardness proof of \cite{huang2021tight} uses interpolation to upper bound the maximum energy of the ultrametric constellation, and hence does not apply with odd interactions or more generally in multi-species models.

In Section~\ref{sec:uc}, we develop a new method to establish the branching OGP which does not rely on interpolation. 
Instead we recursively apply a uniform concentration idea of Subag \cite{subag2018free} (see Lemma~\ref{lem:unif-main}) to show that among all densely branching ultrametric constellations, the highest energy ones can be constructed \emph{greedily}.
Roughly speaking, in such constellations the children $\bx^1,\ldots,\bx^k$ of a point $\bx$ lie on a small sphere centered at $\bx$ such that the increments $\bx^i-\bx$ are orthogonal to $\bx$ and to each other, and approximately maximize $H_N$ on this set.
Because the aforementioned generalized Subag algorithm traces a root-to-leaf path of this tree, this method automatically finds a matching algorithm and lower bound (again modulo that the greedy algorithm is not clearly Lipschitz; our AMP algorithm in \cite{amp-in-progress} also descends this tree).
In other words, the optimal algorithm can be read off from the proof of the lower bound.



We remark that in the branching OGP (and many previous OGPs) one must actually consider a family of correlated Hamiltonians. 
In the branching OGP the correlation structure of these Hamiltonians is also ultrametric.
The function $p$ in \eqref{eq:alg-functional} enters to parametrize the correlation structure of this Hamiltonian family, see Subsection~\ref{subsec:ultra-corr-H}.


Finally, let us point out that the branching OGP is somewhat of a counterpart to the ultrametricity of low-temperature Gibbs measures mentioned previously. 
One essentially expects that $\ALG=\OPT$ holds whenever the Gibbs measure branches at all depths in a suitable zero-temperature limit, which is a strong form of \emph{full replica symmetry breaking}.
However, in general the true Gibbs measures may not exhibit full RSB and may even have finite combinatorial depth, whereas the algorithmic trees we consider must always branch continuously. 


\subsection{Other Related Work}

Following the introduction of mean-field spin glasses in \cite{sherrington1975solvable}, a great deal of effort has been devoted to computing their free energy.
In \cite{parisi1979infinite}, Parisi conjectured the value of the free energy based on his celebrated ultrametric ansatz. 
Following progress by \cite{mezard1985microstructure,ruelle1987mathematical,guerra2002thermodynamic,aizenman2003extended}, the Parisi formula was confirmed by \cite{talagrand2006parisi,talagrand2006spherical,panchenko2013parisi}, and the zero-temperature Parisi formula for the ground state energy by \cite{auffinger2017parisi,chen2017parisi}.
An understanding of the high temperature regime was obtained earlier in \cite{aizenman1987some,comets1995sherrington} and through Talagrand's cavity method \cite{TalagrandVolI}.

Another important line of work is the landscape complexity, i.e. the determination of the exponential growth rate of critical points of $H_N$ at each energy level. Such asymptotics were put forward in \cite{crisanti2003complexity,crisanti2005complexity,parisi2006computing} followed by much rigorous progress in \cite{auffinger2013random,auffinger2013complexity,subag2017complexity,arous2020geometry,mckenna2021complexity,kivimae2021ground,subag2021concentration}. 
The dynamical behavior of spin glasses is also of great interest; as previously mentioned, the behavior of e.g. Langevin dynamics has been described on dimension-free time-scales.
At high temperature, fast mixing has been recently established in
\cite{eldan2021spectral,anari2021entropic,adhikari2022spectral}.



The first multi-species spin glass to be introduced was the bipartite Sherrington-Kirkpatrick model in \cite{kincaid1975phase}. It was later studied further in \cite{korenblit1985spin,fyodorov1987antiferromagnetic,fyodorov1987phase}. Recent rigorous results on the free energy include \cite{barra2015multi,panchenko2015free, subag2021tap, bates2022free}. While the analogous lower bound to the Parisi formula applies in general with a similar proof, the upper bound is only known in two non-trivial special cases: models where $\xi$ is convex in the positive orthant, and pure models (assuming the $N\to\infty$ limit exists in the latter case). A different free energy upper bound (for the case of Ising spins) was recently proved by Mourrat \cite{mourrat2020free}, taking the form of an infinite-dimensional Hamilton-Jacobi equation.


In the large degree limit, the maxima of random constraint satisfaction problems such as random max-$k$-SAT and MaxCut are known to be described by mean-field spin glasses \cite{dembo2017extremal, panchenko2018k}. See also \cite{alaoui2021local,jones2022random} for algorithmic analogs. 



\subsection{Notations and Preliminaries}
\label{subsec:notation}

Throughout this paper we adopt the following notational conventions. 
For $\bx \in \bbR^N$, $\bx_s \in \bbR^{\cI_s}$ denotes the restriction of $\bx$ to the coordinates $\cI_s$.
The symbol $\odot$ denotes coordinate-wise product, and the symbol $\diamond$ denotes the operation defined in \eqref{eq:def-diamond}.
The all-$0$ and all-$1$ vectors in $\bbR^\sS$ are denoted $\vzero, \vone$, and those in $\bbR^N$ are denoted $\bzero, \bone$.
For vectors $\vx,\vy \in \bbR^{\sS}$, $\vx \preceq \vy$ denotes the coordinate-wise inequality, and for matrices $\preceq$ denotes the Loewner order. 
Vector operations such as $\sqrt{\vx}$ are always coordinate-wise. 


Let $S_N = \{\bx \in \bbR^N : \norm{\bx}_2^2 = N\}$.
For any tensor $\bA \in (\bbR^N)^{\otimes k}$, we define the operator norm
\[
    \tnorm{\bA}_{\op} = 
    \fr1N \max_{\bsig^1,\ldots,\bsig^k \in S_N} 
    \lt|\la \bA, \bsig^1 \otimes \cdots \otimes \bsig^k \ra\rt|.
\]
The following proposition shows that with all but exponentially small probability, the operator norms of all constant-order gradients of $H_N$ are bounded and $O(1)$-Lipschitz.
\begin{proposition}
\label{prop:gradients-bounded}
    For any fixed model $(\xi, \vh)$ there exists a constant $c>0$, sequence $(K_N)_{N\geq 1}$ of convex sets $K_N\subseteq \sH_N$, and sequence of constants $(C_{k})_{k\geq 1}$ independent of $N$, such that the following properties hold.
    \begin{enumerate}[label=(\alph*)]
        \item 
        \label{it:KN-high-prob}
        $\P[H_N\in K_N]\geq 1-e^{-cN}$;
        \item For all $H_N\in K_N$ and 
        $\bx, \by\in \cB_N$,
        \begin{align}
            \label{eq:gradient-bounded}
            \norm{\nabla^k H_N(\bx)}_{\op}
            &\le 
            C_{k}, \\
            \label{eq:gradient-lipschitz}
            \norm{\nabla^k H_N(\bx) - \nabla^k H_N(\by)}_{\op}
            &\le 
            C_{k+1} \norm{\bx - \by}_N.
        \end{align}
    \end{enumerate}
\end{proposition}

\begin{proof}
    Note that the conditions \eqref{eq:gradient-bounded} and \eqref{eq:gradient-lipschitz} are convex in $H_N$. Defining $K_N$ to be the set of $H_N$ such that the estimates \eqref{eq:gradient-bounded}, \eqref{eq:gradient-lipschitz} hold with suitably large implicit constants, it remains to show point~\ref{it:KN-high-prob}.
    For this, by Slepian's lemma it suffices to consider the case where $\gamma_{s_1,\dots,s_k}$ is replaced by the maximal entry in $\Gamma^{(k)}$. The result then follows by \cite[Proposition 2.3]{huang2021tight} since we assumed at the outset that $\sum_{k\ge 2} 2^k \norm{\Gamma^{(k)}}_\infty < \infty$.
\end{proof}

