\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

\IEEEoverridecommandlockouts
\overrideIEEEmargins

\title{\LARGE \bf
Provably correct sensor-driven path-following for unicycles using monotonic score functions
}


\author{Benton Clark$^{1}$, Varun Hariprasad$^{2}$, and Hasan A. Poonawala$^{1}$%
\thanks{*This work was not supported by any organization}%
\thanks{$^{1}$Benton Clark and Hasan A. Poonawala are with Faculty of Mechanical and Aerospace Engineering,
        University of Kentucky, Lexington, KY 40506, United States
        {\tt\small \{benton.clark,hasan.poonawala\}@uky.edu}}%
\thanks{$^{2}$ Varun Hariprasad is a student at Paul Laurence Dunbar High School,
1600 Man o' War Boulevard, Lexington, KY 40513, United States
{\tt\small varunhpr5@gmail.com}}%
}

\usepackage[utf8]{inputenc}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{todonotes}
\usepackage{leftidx}
\usepackage{tikz}
\usepackage{pgfplots}
\usetikzlibrary{arrows,decorations.pathmorphing,positioning,fit,trees,shapes,shadows,automata,calc,intersections,decorations.markings,pgfplots.fillbetween,patterns} 

\setlength{\marginparwidth}{2cm}
\usepackage[normalem]{ulem}
\newcommand{\hlc}[1]{\bgroup\markoverwith
  {\textcolor{#1}{\rule[-1ex]{2pt}{2.5ex}}}\ULon}
\newcommand{\hlctodo}[2]{\todo[color=#1]{#2}\bgroup\markoverwith
  {\textcolor{#1}{\rule[-.5ex]{2pt}{2.5ex}}}\ULon }
\usepackage{hyperref}
\hypersetup{colorlinks=true,     
linkcolor=blue,          % color of internal links
        citecolor=blue,        % color of links to bibliography
          filecolor=magenta,      % color of file links
           urlcolor=magenta           % color of external links
}


% Custom commands for mobile robot kinematics
\newcommand{\phit}{\phi(t)}
\newcommand{\ppath}{\mathcal{P}}
\newcommand{\dset}{\mathcal{D}}


% Commands for StBSF and SeBSF
\newcommand{\stbsf}{F}
\newcommand{\sebsf}{\Tilde{F}}


% Custom commands for LS analysis
\newcommand{\Qone}{\overline{Q}_1}
\newcommand{\Qtwo}{\overline{Q}_2}
\newcommand{\Qthr}{\overline{Q}_3}
\newcommand{\Qfor}{\overline{Q}_4}
\newcommand{\Qoneic}{\Qone^L}
\newcommand{\Qthric}{\Qthr^L}
\newcommand{\Xo}{X_0}
\newcommand{\tlb}{\underline{\theta}}
\newcommand{\tub}{\overline{\theta}}
\newcommand{\dlb}{\underline{d}}
\newcommand{\dub}{\overline{d}}

% Commands for d-\theta figure
\newcommand{\pathfunc}{\gamma}
\newcommand{\switchsurf}{\alpha}
\newcommand{\deviation}{d}
\newcommand{\localangle}{\theta}
\newcommand{\locstate}{\state}
\newcommand{\exaenvir}{\rho}

% Custom commands
\newcommand{\Ftx}{F(\theta,x)}
\newcommand{\Ftd}{F(\theta,d)}
\newcommand{\gtx}{g(\theta,x)}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\oF}{\overline{F}}
\newcommand{\uF}{\underline{F}}
\newcommand{\oFd}{\overline{F}_\delta}
\newcommand{\pd}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\bmat}[1]{\begin{bmatrix}#1\end{bmatrix}}
\newcommand{\bigpar}[1]{\left( #1 \right)}
\newcommand{\sign}[1]{\mathrm{sign} #1 }
% Commands: Frames and Kinematics
\newcommand{\Frame}{\mathcal{F}}
\newcommand{\origin}{\mathcal{O}}
\newcommand{\ihat}{\hat{i}}
\newcommand{\jhat}{\hat{j}}
\newcommand{\khat}{\hat{k}}
\newcommand{\vd}{\vec{d}}
\newcommand{\vt}{\vec{\theta}}
\newcommand{\vx}{\vec{x}}
\newcommand{\vc}{\vec{c}}
\newcommand{\vxe}{\vec{x}_e}
\newcommand{\vxz}{\vec{x}_0}
\newcommand{\vv}{\vec{v}}
\newcommand{\vy}{\vec{y}}
\newcommand{\vw}{\vec{\omega}}
\newcommand{\vr}{\vec{r}}
\newcommand{\vrp}{\vec{r}\;'}
\newcommand{\ve}{\vec{e}}
\newcommand{\vq}{\vec{q}}
\newcommand{\dvr}{\dot \vr}
\newcommand{\qdes}{\vec q_{\text{des}}}
\newcommand{\Qss}{\mathcal{Q}}
\newcommand{\fproj}{f_\text{proj}}

% Commands: LS / LAS Analysis
\newcommand{\Qonenot}{Q_{\star 0}^1}
\newcommand{\Qthrnot}{Q_{\star 0}^3}
\newcommand{\XLp}{X_{L}^+}
\newcommand{\XLm}{X_{L}^-}
\newcommand{\XLo}{X_{L^0}}
\newcommand{\dbound}{d_\star}
\newcommand{\tbound}{\theta_\star}
\newcommand{\vctrl}{\beta e^{-\alpha \stbsf^2}}
\newcommand{\vctrlsebsf}{\beta e^{-\alpha \sebsf^2}}
\newcommand{\invf}[1]{{#1}^{-1}}
% Differentiate w.r.t. frame input
\newcommand{\difff}[2]{\leftidx{^{#1}}{\frac{d #2}{dt}}}
% Differentiate w.r.t. the 0 frame
\newcommand{\difffz}[1]{\difff{0}{#1}}
\DeclareMathOperator{\sgn}{sgn}

\newtheorem{lemma}{Lemma}
\newtheorem{fact}{Fact}
\newtheorem{theorem}{Theorem}
\newtheorem{remark}{Remark}
\newtheorem{definition}{Definition}

\begin{document}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}
\begin{abstract}
This paper develops a provably stable sensor-driven controller for path-following applications of robots with unicycle kinematics, one specific class of which is the wheeled mobile robot (WMR). %
The sensor measurement is converted to a scalar value (the score) through some mapping (the score function); the latter may be designed or learned. 
The score is then mapped to forward and angular velocities using a simple rule with three parameters. 
The key contribution is that the correctness of this controller only relies on the score function satisfying monotonicity conditions with respect to the underlying state -- local path coordinates --  instead of achieving specific values at all states. %
The monotonicity conditions may be checked online by moving the WMR, without state estimation, or offline using a generative model of measurements such as in a simulator.
Our approach provides both the practicality of a purely measurement-based control and the correctness of state-based guarantees. 
We demonstrate the effectiveness of this path-following approach on both a simulated and a physical WMR that use a learned score function derived from a binary classifier trained on real depth images. 
\end{abstract}





\section{Introduction}
\label{sec:intro}
Mobile robot navigation is a long-standing topic of research and development in robotics. %
A primary navigation problem is to follow a path~\cite{micaelli1993trajectory,wit1993nonlinear,rio_pathfollowing_1999}, such as defined by lanes on a highway or the walls of a hallway. %
The path is typically assumed free of obstacles, but straying too far from the path may cause collisions. %
Therefore, we would like the robot to stay within some distance from the path due to the possible collisions with objects. 

Traditional approaches to the path-following problem look at designing controllers with provable guarantees of the system stability, assuming direct state measurements are available for feedback~\cite{wit1993nonlinear}. %
The state is typically the distance to a point on the path and the relative heading to the path. %
Measuring these quantities in unstructured environments is difficult or impossible, which limits deployment of mobile robots in such settings. 

In order to avoid direct state measurement, several groups have focused on learning direct sensor-to-actuator feedback controllers~\cite{levine2016end,giusti2015machine}. 
Most of these methods use deep neural networks~\cite{Goodfellow2016DLbook} to map high-dimensional measurements from on-board sensors (e.g.\ optical camera, LiDAR) to control input values, without intermediate state estimation. %
The drawback of these approaches is that they do not provide guarantees on the system stability or convergence to the path for the resulting closed-loop system. %
These methods also require significant data and computational resources~\cite{levine2016end}. 

This lack of guarantees for learned controllers has prompted new controller synthesis and verification methods~\cite{chang2019neural,reedverified,rpm,poonawala2021training}. %
In principle, the methods could enable provably correct sensor-driven control. %
However, they suffer from two drawbacks related to path-following, especially in unstructured environments.
First, the guarantees rely on prior knowledge of a measurement model that predicts measurements that would be obtained around the path. 
This model may be difficult to obtain, and the guarantees are brittle to variation in the real mapping from local path coordinates to sensor measurements that will occur when deployed in changing environments. %
Second, the synthesis and verification of these methods is often computationally expensive, preventing a possible solution where new verified controllers are computed in response to changing environments.

The method in~\cite{poonawala2021training} attempts to overcome the issue of changing environments by using discrete control inputs predicted by a classifier. They argue that the changing measurement model  is equivalent to a variable switching surface in the state space. Using differential inclusion models, they guarantee that deviation from the path are bounded despite uncertainty in the measurement model. This robustness is obtained at the expense of producing a discontinuous switching controller, which is undesirable for real hardware systems. Additionally, the human designer must still choose the number and value of the discrete inputs. 

Ideally, we wish to obtain a sensor-driven path-following controller with guaranteed behavior that does not rely on online state estimation or offline measurement prediction. %

\paragraph*{Contributions} 
This paper proposes a sensor-driven path-following control approach where a high-dimensional sensor measurement is mapped to a scalar value which is in turn mapped to forward and angular velocities of a robot with unicycle kinematics. 
The main contribution is to show that this mapping -- called the Sensor-based Score Function -- from sensor to scalar value must satisfy conditions that do not rely on knowing the measurement obtained in a state \emph{a priori}.  
Additionally, the mapping from scalar value to control inputs is simple with only three parameters that we describe how to choose.
A consequence of this approach is that a measurement model is not necessary when designing the controller, and the guarantees are robust to changes in the measurement model during deployment.
The score function thus enables a connection between pure measurement-based control and rigorous state-based analysis.
We provide results of simulated and physical path-following experiments to demonstrate the benefits of this approach.


\newcommand{\curv}{\rho}
\section{Path-Following Problem}
\label{sec:kinematics}
We consider mobile robots with unicycle kinematics~\cite{malu_kinematics_2014}. Given a one-dimensional curve $\ppath$ in the plane, we can express the kinematics in a local state-space representation known as the ``orthogonal projection''~\cite[p.132]{wit1993nonlinear} of the robot's centroid $P$ about a path $\ppath$. 
The system dynamics consist of the following equations:
\begin{align*}
     \dot s &= v\cos\theta/(1-\curv(s)d), \\ % \label{eq:sdot}
     \dot d &= v\sin\theta, \text{ and}\\ %\label{eq:ddot}
     \dot \theta &= \omega - v\cos(\theta)\curv(s)/(1-\curv(s)d), %\label{eq:tdot-full} \
\end{align*}
where $s$ is the arc length along the curve $\ppath$, 
$\curv(s)$ is the path's curvature at the distance $s$, 
$d$ is the signed distance of the point $P$ from the path, 
$\theta$ is the difference between the heading direction of the WMR and the tangent to the path, 
$v$ is the forward velocity control input, and 
$\omega$ is the angular velocity control input.
The state space values are derived from a Frenet-Serret frame attached along the path $\ppath$ whose normal coincides with the point $P$.
Figure~\ref{fig:ddwmr} provides an illustration of this parameterization.

The \textbf{path-following problem} is to ensure that $d(t) \to 0$ as $t \to \infty$ and that $\dot s(t) > 0$ for all time. 
Note that for paths with time-varying curvature, convergence to the path is impossible without feed-forward control of the path. 
Therefore, our analysis will focus on the case of straight paths.
The convergence guarantees we obtain for the straight-line paths imply bounded deviations for the curved-path case, as argued in~\cite{reedverified}. %

\input{figures/fig_localcoordinates}



\section{Sensor-driven Path-Following Control}
A sensor-driven controller maps a measurement $\vy \in Y\subset\R^l$ to control inputs $v$ and $\omega$ of the system, where $Y$ is the space of measurements whose dimension is $l \in \N$. %
Instead of designing this controller in an end-to-end manner, we propose mapping the measurement $\vy$ to a scalar value, and then using a simple rule to convert the scalar value into control inputs. 
\subsection{Sensor-Based Score Functions}
\label{sec:sebsf}
We refer to a map $\sebsf: Y\rightarrow\R$ as a \textbf{Sensor-based Score Function} (SeBSF). A SeBSF is an extreme example of dimensionality reduction for high-dimensional sensor measurements, such as optical cameras of LiDAR. 

Sensor-based Score Functions are common, even if not called as such. %
In reinforcement learning where the policy is obtained from a value function over observations~\cite{levine2016end}, the value function is a SeBSF. 
A binary-class support vector machine~\cite{Cortes1995} with input as the sensor image first calculates a score function, whose sign dictates the class. 

As these examples suggest, a distinguishing feature of our work is how we convert the SeBSF into a control law that achieves path-following with guarantees. 

\subsection{Kinematic Control Law}
We propose the following kinematic control law for the mobile robot:
\begin{align}
    \label{eq:omega-ctrl-law} \omega &= \gamma \sebsf, \\
    \label{eq:v-ctrl-law} v &= \vctrlsebsf,
\end{align}
where $\sebsf=\sebsf(\vy)$ is a SeBSF, and $\alpha \ge 0,\beta,\gamma > 0$ are controller parameters.
Parameters $\alpha , \beta,\text{ and }\gamma$ of~\eqref{eq:omega-ctrl-law}-\eqref{eq:v-ctrl-law} correspond to the forward velocity decay rate, the maximum forward velocity, and the angular velocity gain, respectively.

\newcommand{\sensormap}{H}
\subsection{State-Based Score Functions}


To provide guarantees on closed-loop behavior we must convert the sensor-driven control law into a state-based control law. 
To do so, we introduce the notion of a \textbf{State-based Score Function} (StBSF) derived from an SeBSF together with the (unknown) map from state to measurement, which we call the \textbf{sensor map}. %
We define the sensor map formally as follows. 
\begin{definition}
\label{def:sensor-map}
    Let $X\subset\R^2$ be the state space of a WMR as defined in section~\ref{sec:kinematics}.
    Let $Y\subset\R^l$ be the measurement space of an $l$-dimensional sensor.
    Then a sensor map $\sensormap \colon X \to Y$ is a function
    \[ \vy = \sensormap(\vx) , \]
    where $\vx\in X$ and $\vy\in Y$.
\end{definition}
If the sensor map is known \emph{a priori} -- that is, a measurement model is available -- then the conditions we derive can be checked offline. %
For example, we can predict closed-loop behavior in simulation. %
If the map is unknown, the conditions can be checked online without reconstructing the map. %


We now define a State-Based Sensor Function (StBSF).
\begin{definition}
\label{def:stbsf}
    Let $X$, $Y$, $\sensormap$, and $\sebsf$ be a state space, measurement space, sensor map, and SeBSF respectively.
    A State-based Score Function $\stbsf \colon X \rightarrow \R $ is the composition of the SeBSF and sensor map:
    \begin{align}
        \stbsf = \sebsf \circ \sensormap
    \end{align}
\end{definition}
This definition is important as it allows us to analyze the closed-loop behavior due to a sensor-driven control. 


\subsection{Conditions On State-Based Score Functions}
In order to guarantee that the path-following is stable and the robot converges to the path, we need that $\stbsf$ be continuously differentiable, and for all states in some region of interest the following conditions hold:
\begin{align}
    F(\vec 0) &= 0 \label{eq:stbsfcondzero}\\
    \pd{F}{\theta} &< 0,\text{ and} \label{eq:stbsfcondpdtheta}\\
    \pd{F}{d} &< 0. \label{eq:stbsfcondpdd}
\end{align}

The important idea is that \textbf{these conditions can be checked online, without estimation of the state}.
We may check~\eqref{eq:stbsfcondzero} by obtaining a measurement when the robot is on the path with its heading aligned with the path tangent. 
We may check~\eqref{eq:stbsfcondpdtheta} by spinning the robot in place while taking measurements. %
We may check~\eqref{eq:stbsfcondpdd} by moving laterally and taking measurements. However, if $| \theta |= \pi/2$ then this last test would be inconclusive. 


\section{Closed-Loop Analysis}
\input{texs/analysis}
%\input{texs/analysis_bkup}

\section{Experiments}
Experiments for this work consist of both simulations and physical experiments.
Both sets of experiments consist of a WMR attached with an on-board depth sensor, wherein a SeBSF was used to control the robot.

\subsection{Obtaining a SeBSF}
\label{sec:experimentsebsf}
A support vector machine~\cite{Cortes1995} (SVM) maps vector-valued inputs $y$ to binary class labels. When these labels are $\{+1,-1\}$ then the SVM is given by 
\[ f(\vy) = \sign{(w^T y + c)}, \]
where $w$ and $c$ are the weights and bias terms of the SVM. %
We obtain an SeBSF by training an SVM using labeled data, and then using the argument of the $\sign{}$ function as the sensor-based score: 
\begin{align}
    \sebsf(\vy) = w^T \vy + c, \label{eq:svmscore} 
\end{align}
where $\vy$ represents the vectorized images provided from the depth sensor.

The inputs we use are depth images captured using a Intel RealSense D435i camera affixed to a mobile robot, when the robot is in a corridor. %
The path is defined by the center of the corridor. 
To label these images, we measure the distance $d$ from the center and heading angle $\theta$ relative to the corridor using a ruler and protractor. 
We then label the images according to $\sign{( -\theta - d)}$. %
Note that the label itself does not contain state information, we use the measured state as a guide to labeling. %

\subsection{SeBSF Verification}
In this section, we check whether the SeBSF $\sebsf$ in~\eqref{eq:svmscore} produces a state-based score function that satisfies conditions~\eqref{eq:stbsfcondzero}-\eqref{eq:stbsfcondpdd}. %
The data collected to train the SVM allows us to sample sensor map $\sensormap$ relating an image  $\vy_i$ acquired from the WMR depth sensor with the state $\vx_i$ it was collected in. 

\begin{figure}[t]
\centering
\includegraphics[scale=0.48]{graphs/dt-map2.png}
\caption{\small Plot of the output of the SVM SeBSF verification process.
The vectors at each point represent the local gradient term estimated using finite difference methods.
A red arrow represents $\pd{F}{x_i}<0$, and green opposite.
The maroon curve bounds a region within which both partial derivatives of $\sebsf \circ \sensormap$ are negative.}
\label{fig:sebsf-verification}
\end{figure}

Figure~\ref{fig:sebsf-verification} shows the result of sampling $\sensormap$.
Note that since the SVM was trained as a classifier instead of a regressor, the SVM StBSF $\sebsf \circ H$ is not guaranteed to satisfy conditions~\eqref{eq:stbsfcondzero}-\eqref{eq:stbsfcondpdd}.
However, Figure~\ref{fig:sebsf-verification} shows that within a bounded region of the origin, the StBSF $\sebsf \circ H$ does satisfy~\eqref{eq:stbsfcondpdtheta} and~\eqref{eq:stbsfcondpdd}.
This is the region contained in the maroon boundary shown in Figure~\ref{fig:sebsf-verification}, which contains the origin.
This again highlights the power of the SeBSF --- while the exact score of the SVM is unknown at each point, the partial derivatives are of primary importance for guaranteeing path following.


\subsection{Simulated Experiments}
The simulation experiments were carried out using the AI Habitat simulator~\cite{szot2021habitat,habitat19iccv} in combination with the Habitat-Matterport 3D Dataset~\cite{ramakrishnan2021hm3d} (HM3D) for the navigation mesh map.
The map HM3D-795 was selected for its straight hallway with relatively few obstructions along the length.
The simulator runs with a 100Hz control loop for a fixed interval of time, where the control loop frequency was selected sufficiently fast to estimate a continuous controller on the discrete input WMR used in the simulator.

Within the simulator, a depth sensor was provided to the WMR with characteristics (pixel count, pixel format, etc.) that mimic the Intel RealSense D435i. %
We use the sensor-based score function in~\eqref{eq:svmscore} which is derived from a SVM classifier for \emph{real} images (see Section~\ref{sec:experimentsebsf}) to control the \emph{simulated} robot. %

We simulate 27 trajectories, corresponding to three sets of 9 trajectories corresponding to three different values of ratio $\beta/\gamma$, since this ratio influences closed-loop behavior. %
We choose $\alpha=5\mathrm{e}{-5}$ for all trajectories. % 

Figure~\ref{fig:topdown-map} shows the trajectory obtained in each of the simulations superimposed over a top-down view of the map. %
Each of the successful trajectories approach the path (yellow line) as expected. %
Figure~\ref{fig:ss-trajectories} shows these trajectories in the  state-space. %
Both figures show that as the ratio $\frac{\beta}{\gamma}$ decreases, the robot converges more quickly to the desired path.
Also, the only set of parameters that did not experience a crash was the lowest value of ratio $\beta/\gamma$, highlighting the importance of this ratio for stability.

We note that there is a minor discrepancy in the path-following exhibited about halfway down the hallway.
This trend was expected as the SVM uses geometric data to predict the score, and the opening in the hallway slightly perturbed the output.
It is useful to see though that the SeBSF is robust to minor variations in the environment.

\begin{figure}[t]
\centering
\includegraphics[width = 0.48\textwidth]{graphs/map-795-2.png}
\caption{\small A top-down view of the trajectories run in the AI Habitat simulator.
The yellow line running the middle of the hallway represents the desired path to follow.
The colors indicate the $\beta/\gamma$ ratio of the trajectories.
Trajectories either end in a crash (marker `X') or don't (marker `O'). 
The inset expands the initial part of the hallway to show the crashes.}
\label{fig:topdown-map}
\end{figure}
\begin{figure}[h]
\centering
\includegraphics[width = 0.5\textwidth]{graphs/ss-795-2.png}
\caption{\small The state space plots for the trajectories presented in Figure~\ref{fig:topdown-map}.
The trajectories for $\beta/\gamma \in \{0.2,2\}$ appear to trace out a line $F_0$ in $\Qtwo$ and $\Qfor$. The opening in the hallway (see Figure~\ref{fig:topdown-map}) temporarily causes these trajectories to leave $F_0$ in $\Qfor$. For $\beta/\gamma = 20$, there is no invariant cone in $\Qtwo$ or $\Qfor$.
}
\label{fig:ss-trajectories}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[scale=0.03]{images/IMG_2807.JPG}
\caption{\small The platform on which the SeBSF data collection and physical experiments were conducted.}
\label{fig:openbot}
\end{figure}
\subsection{Physical Experiments}
\label{ssec:physical-experiments}
The physical experiments consisted of running the SVM-based SeBSF on a physical mobile robot platform down a hallway.
Figure~\ref{fig:openbot} shows an image of the platform. %
We use a custom-rigged OpenBot~\cite{mueller2021openbot} WMR platform.
The OpenBot platform typically expects a smartphone for the autonomous control.
Instead, we attached an Intel Realsense  D435i camera for imaging, with a RaspberryPi 4 to compute the SVM SeBSF score and send wheel velocity commands to the Arduino driving the motor controllers on the OpenBot.
We extract a depth image with 640x480 pixels in Z16 output format from the RealSense camera at a rate of $15$Hz. 

The experimental setup and data collection was similar to an idea used in~\cite{bakker2010path}.
Each trajectory took place over a 100ft stretch of a straight hallway measuring $8$ft wide.
Three runs were obtained, with a different set of parameters $\beta$ and $\gamma$ chosen for each run.
$\alpha=5\mathrm{e-}5$ was held constant between trials.
A dry-erase marker, visible in Figure~\ref{fig:openbot}, was attached to the back of the OpenBot.
The marker at the back of the car marks the path followed by the robot.
A ruler and protractor were used to measure the distance $d$ and the angle $\theta$ respectively along the trajectory of each run.
The points collected were uniformly spaced by a distance of $2$ft.



Figure~\ref{fig:state-space-map} shows the results of these physical experiments.
We expect that behavior of trajectories to differ from that in simulation due to the low control frequency ($15$Hz).
We varied the ratio $\beta/\gamma$ by keeping $\beta$ fixed and increasing the $\gamma$ (thus decreasing the ratio $\beta/\gamma$).
This approach meant that the WMR rotated more aggressively given the same SeBSF output, which caused issues when running at a relatively low control frequency.
However, the physical experiments do confirm that as the ratio $\beta/\gamma$ decreases, the trajectories converge faster to the desired path.
We also see the trajectories oscillate less as the ratio decreases.

One significant deviation from predicted behavior, labeled as `Perturbation' in Figure~\ref{fig:state-space-map}, occurred when the depth sensor was near a door with a glass pane, thus significantly perturbing the SeBSF output. %
This perturbation only impacted the controller with the largest $\gamma$ value. %
It's impact persists for about $6$ft of the path, then the WMR converges back to the path.

\begin{figure}[t]
\centering
\includegraphics[scale=0.55]{graphs/phys-exp-output.png}
\caption{A state-space plot of the output from the physical experiments.
Note that the `Perturbation' portion of the trajectory corresponds to the trajectory $\beta/\gamma=8.1$.}
\label{fig:state-space-map}
\end{figure}


\section{Discussion \& Future Work}
We have both theoretically and empirically demonstrated the path-following guarantees of the continuous controller in combination with a SeBSF score function.
The theory stated that given a SeBSF $\sebsf$ whose StBSF representation $\sebsf\circ H$ satisfies conditions~\eqref{eq:stbsfcondzero}-\eqref{eq:stbsfcondpdd}, and selecting controller gains with a suitably small forward velocity per turning rate, the WMR would converge to the path defined by the sensor reading $\sebsf(\vec 0)=0$.
Our empirical results, both in simulation and on a physical system support this claim.

One point to note however is that the graphs in Figures~\ref{fig:ss-trajectories} and~\ref{fig:state-space-map} did not converge to the origin $\theta=d=0$, but rather converged to a point $(0,d)$ where $d\ne 0$.
We expect that this discrepancy is due to the fact that the SVM did not perfectly achieve the condition $F(\vec 0)=0$. 
However, from Figure~\ref{fig:sebsf-verification}, each of the partial derivatives in that region are negative, and by continuity there must exist a sensor output such that $F(\vx) = 0$. 
We conjecture that the sensor-driven controller is converging to the path defined by the score function being zero, which now differs from our imposed straight-line path. 

Future work will look at a few different ideas.
First, we will extend the following analysis for general curved paths in the plane while maintaining the stabililty guarantees. %
We conjecture that handling curved paths allow us to define paths by the set of robot poses where the \emph{sensor}-based score function is zero, so that condition~\eqref{eq:stbsfcondzero} would automatically be satisfied on such paths. %
Second, we will develop a path following controller for path in 3D, extending the utility of this algorithm to robots such as quadrotors. %
Lastly, we will explore using alternative methods to derive a sensor-based score function, such as using reinforcement learning driven by rewards related to near-collisions.


\bibliographystyle{IEEEtran}
\bibliography{main}
\end{document}
