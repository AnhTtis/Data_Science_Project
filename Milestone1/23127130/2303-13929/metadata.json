{
    "arxiv_id": "2303.13929",
    "paper_title": "Autonomous Blimp Control via H-infinity Robust Deep Residual Reinforcement Learning",
    "authors": [
        "Yang Zuo",
        "Yu Tang Liu",
        "Aamir Ahmad"
    ],
    "submission_date": "2023-03-24",
    "revised_dates": [
        "2023-03-27"
    ],
    "latest_version": 1,
    "categories": [
        "cs.RO"
    ],
    "abstract": "Due to their superior energy efficiency, blimps may replace quadcopters for long-duration aerial tasks. However, designing a controller for blimps to handle complex dynamics, modeling errors, and disturbances remains an unsolved challenge. One recent work combines reinforcement learning (RL) and a PID controller to address this challenge and demonstrates its effectiveness in real-world experiments. In the current work, we build on that using an H-infinity robust controller to expand the stability margin and improve the RL agent's performance. Empirical analysis of different mixing methods reveals that the resulting H-infinity-RL controller outperforms the prior PID-RL combination and can handle more complex tasks involving intensive thrust vectoring. We provide our code as open-source at https://github.com/robot-perception-group/robust_deep_residual_blimp.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.13929v1"
    ],
    "publication_venue": null
}