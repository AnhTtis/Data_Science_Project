% This file was created with Citavi 6.10.0.0

@article{liu2020adaptive,
  title={Adaptive sliding-mode-backstepping trajectory tracking control of underactuated airships},
  author={Liu, Shi Qian and Sang, Yuan Jun and Whidborne, James F},
  journal={Aerospace Science and Technology},
  volume={97},
  pages={105610},
  year={2020},
  publisher={Elsevier}
}


@inproceedings{fukushima2006model,
  title={Model predictive control of an autonomous blimp with input and output constraints},
  author={Fukushima, Hiroaki and Saito, Ryosuke and Matsuno, Fumitoshi and Hada, Yasushi and Kawabata, Kuniaki and Asama, Hajime},
  booktitle={2006 IEEE Conference on Computer Aided Control System Design, 2006 IEEE International Conference on Control Applications, 2006 IEEE International Symposium on Intelligent Control},
  pages={2184--2189},
  year={2006},
  organization={IEEE}
}
@INPROCEEDINGS{1626776,

  author={Jinjun Rao and Zhenbang Gong and Jun Luo and Shaorong Xie},

  booktitle={IEEE International Conference Mechatronics and Automation, 2005}, 

  title={A flight control and navigation system of a small size unmanned airship}, 

  year={2005},

  volume={3},

  number={},

  pages={1491-1496 Vol. 3},

  doi={10.1109/ICMA.2005.1626776}}
  
 @article{paszke2019pytorch,
	title={Pytorch: An imperative style, high-performance deep learning library},
	author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
	journal={Advances in neural information processing systems},
	volume={32},
	year={2019}
}

 @inproceedings{zhang1999visual,
  title={Visual servoing with dynamics: Control of an unmanned blimp},
  author={Zhang, Hong and Ostrowski, James P},
  booktitle={Proceedings 1999 IEEE International Conference on Robotics and Automation (Cat. No. 99CH36288C)},
  volume={1},
  pages={618--623},
  year={1999},
  organization={IEEE}
}

 @INPROCEEDINGS{1013654,

  author={Azinheira, J.R. and Rives, P. and Carvalho, J.R.H. and Silveira, G.F. and de Paiva, E.C. and Bueno, S.S.},

  booktitle={Proceedings 2002 IEEE International Conference on Robotics and Automation (Cat. No.02CH37292)}, 

  title={Visual servo control for the hovering of all outdoor robotic airship}, 

  year={2002},

  volume={3},

  number={},

  pages={2787-2792 vol.3},

  doi={10.1109/ROBOT.2002.1013654}}




 @article{Takaya2006PIDLO,
  title={PID landing orbit motion controller for an indoor blimp robot},
  author={Toshihiko Takaya and Hidenori Kawamura and Yoshihiro Minagawa and Masahito Yamamoto and Azuma Ohuchi},
  journal={Artificial Life and Robotics},
  year={2006},
  volume={10},
  pages={177-184}
}

 @article{price2022perception,
  title={Perception-driven Formation Control of Airships},
  author={Price, Eric and Black, Michael J and Ahmad, Aamir},
  journal={arXiv preprint arXiv:2209.13040},
  year={2022}
}



 @INPROCEEDINGS{8794127,

  author={Johannink, Tobias and Bahl, Shikhar and Nair, Ashvin and Luo, Jianlan and Kumar, Avinash and Loskyll, Matthias and Ojea, Juan Aparicio and Solowjow, Eugen and Levine, Sergey},

  booktitle={2019 International Conference on Robotics and Automation (ICRA)}, 

  title={Residual Reinforcement Learning for Robot Control}, 

  year={2019},

  volume={},

  number={},

  pages={6023-6029},

  doi={10.1109/ICRA.2019.8794127}}

@book{MATLAB:2022,
year = {2022},
author = {MATLAB},
title = {version 7.10.0 (R2022a)},
publisher = {The MathWorks Inc.},
address = {Natick, Massachusetts}
} 

@article{cheng2019robust,
  title={Robust three-dimensional path-following control for an under-actuated stratospheric airship},
  author={Cheng, Lin and Zuo, Zongyu and Song, Jiawei and Liang, Xiao},
  journal={Advances in Space Research},
  volume={63},
  number={1},
  pages={526--538},
  year={2019},
  publisher={Elsevier}
}
@inproceedings{ko2007gaussian,
  title={Gaussian processes and reinforcement learning for identification and control of an autonomous blimp},
  author={Ko, Jonathan and Klein, Daniel J and Fox, Dieter and Haehnel, Dirk},
  booktitle={Proceedings 2007 ieee international conference on robotics and automation},
  pages={742--747},
  year={2007},
  organization={IEEE}
}
@inproceedings{rottmann2009adaptive,
  title={Adaptive autonomous control using online value iteration with gaussian processes},
  author={Rottmann, Axel and Burgard, Wolfram},
  booktitle={2009 IEEE International Conference on Robotics and Automation},
  pages={2106--2111},
  year={2009},
  organization={IEEE}
}
 @INPROCEEDINGS{4399531,

  author={Rottmann, Axel and Plagemann, Christian and Hilgers, Peter and Burgard, Wolfram},

  booktitle={2007 IEEE/RSJ International Conference on Intelligent Robots and Systems}, 

  title={Autonomous blimp control using model-free reinforcement learning in a continuous state and action space}, 

  year={2007},

  volume={},

  number={},

  pages={1895-1900},

  doi={10.1109/IROS.2007.4399531}}
  
@article{nie2019three,
  title={Three-dimensional path-following control of a robotic airship with reinforcement learning},
  author={Nie, Chunyu and Zheng, Zewei and Zhu, Ming},
  journal={International Journal of Aerospace Engineering},
  volume={2019},
  pages={1--12},
  year={2019},
  publisher={Hindawi Limited}
}
@article{silver2018residual,
  title={Residual policy learning},
  author={Silver, Tom and Allen, Kelsey and Tenenbaum, Josh and Kaelbling, Leslie},
  journal={arXiv preprint arXiv:1812.06298},
  year={2018}
}


@inproceedings{duggal2016plantation,
  title={Plantation monitoring and yield estimation using autonomous quadcopter for precision agriculture},
  author={Duggal, Vishakh and Sukhwani, Mohak and Bipin, Kumar and Reddy, G Syamasundar and Krishna, K Madhava},
  booktitle={2016 IEEE international conference on robotics and automation (ICRA)},
  pages={5121--5127},
  year={2016},
  organization={IEEE}
}
@inproceedings{price2022simulation,
  title={Simulation and control of deformable autonomous airships in turbulent wind},
  author={Price, Eric and Liu, Yu Tang and Black, Michael J and Ahmad, Aamir},
  booktitle={Intelligent Autonomous Systems 16: Proceedings of the 16th International Conference IAS-16},
  pages={608--626},
  year={2022},
  organization={Springer}
}
@misc{Andrychowicz.20200610,
 abstract = {In recent years, on-policy reinforcement learning (RL) has been successfully applied to many different continuous control tasks. While RL algorithms are often conceptually simple, their state-of-the-art implementations take numerous low- and high-level design decisions that strongly affect the performance of the resulting agents. Those choices are usually not extensively discussed in the literature, leading to discrepancy between published descriptions of algorithms and their implementations. This makes it hard to attribute progress in RL and slows down overall progress [Engstrom'20]. As a step towards filling that gap, we implement {\textgreater}50 such ``choices'' in a unified on-policy RL framework, allowing us to investigate their impact in a large-scale empirical study. We train over 250'000 agents in five continuous control environments of different complexity and provide insights and practical recommendations for on-policy training of RL agents.},
 author = {Andrychowicz, Marcin and Raichuk, Anton and Sta{\'n}czyk, Piotr and Orsini, Manu and Girgin, Sertan and Marinier, Raphael and Hussenot, L{\'e}onard and Geist, Matthieu and Pietquin, Olivier and Michalski, Marcin and Gelly, Sylvain and Bachem, Olivier},
 date = {2020-06-10},
 title = {What Matters In On-Policy Reinforcement Learning? A Large-Scale  Empirical Study},
 url = {},
 file = {Andrychowicz, Raichuk et al. 2020-06-10 - What Matters In On-Policy Reinforcement:Attachments/Andrychowicz, Raichuk et al. 2020-06-10 - What Matters In On-Policy Reinforcement.pdf:application/pdf}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{Gonzalez2016,
author = {Gonzalez, Luis and Montes, Glen and Puig, Eduard and Johnson, Sandra and Mengersen, Kerrie and Gaston, Kevin},
year = {2016},
month = {01},
pages = {97},
title = {Unmanned Aerial Vehicles (UAVs) and Artificial Intelligence Revolutionizing Wildlife Monitoring and Conservation},
volume = {16},
journal = {Sensors},
doi = {10.3390/s16010097}
}


@misc{Liu.20220310,
 abstract = {Blimps are well suited to perform long-duration aerial tasks as they are energy efficient, relatively silent and safe. To address the blimp navigation and control task, in previous work we developed a hardware and software-in-the-loop framework and a PID-based controller for large blimps in the presence of wind disturbance. However, blimps have a deformable structure and their dynamics are inherently non-linear and time-delayed, making PID controllers difficult to tune. Thus, often resulting in large tracking errors. Moreover, the buoyancy of a blimp is constantly changing due to variations in ambient temperature and pressure. To address these issues, in this paper we present a learning-based framework based on deep residual reinforcement learning (DRRL), for the blimp control task. Within this framework, we first employ a PID controller to provide baseline performance. Subsequently, the DRRL agent learns to modify the PID decisions by interaction with the environment. We demonstrate in simulation that DRRL agent consistently improves the PID performance. Through rigorous simulation experiments, we show that the agent is robust to changes in wind speed and buoyancy. In real-world experiments, we demonstrate that the agent, trained only in simulation, is sufficiently robust to control an actual blimp in windy conditions. We openly provide the source code of our approach at https://github.com/ robot-perception-group/AutonomousBlimpDRL.},
 author = {Liu, Yu Tang and Price, Eric and Black, Michael J. and Ahmad, Aamir},
 date = {2022-03-10},
 title = {Deep Residual Reinforcement Learning based Autonomous Blimp Control},
 url = {https://arxiv.org/pdf/2203.05360},
 file = {Liu, Price et al. 2022-03-10 - Deep Residual Reinforcement Learning based:Attachments/Liu, Price et al. 2022-03-10 - Deep Residual Reinforcement Learning based.pdf:application/pdf}
}


