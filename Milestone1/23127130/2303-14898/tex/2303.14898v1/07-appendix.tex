\appendix
\balance
\section{Appendix}
% \input{algorithm/al-alignment}

% \input{algorithm/al-event}

\subsection{Model Description}
\label{ap:attn}
In this section, we introduce the temporal attention layer and cross-lingual attention layer for entity alignments utilized in Section~\ref{sec:align}. We first introduce the general attention mechanism we utilized, then specify the two layers respectively.

Given two representation sequence from temporal domain: key sequence $\boldsymbol{H}_K = \{\boldsymbol{h}_K^{1}, \boldsymbol{h}_K^{2}, \cdots, \boldsymbol{h}_K^{T}\}$ and query sequence $\boldsymbol{H}_Q = \{\boldsymbol{h}_Q^{1}, \boldsymbol{h}_Q^{2}, \cdots, \boldsymbol{h}_Q^{T}\}$  from all time steps, we propose the following attention to calculate the pairwise importance:
\begin{equation}
    \small
    \mathbf{\beta} = \text{Attn}(key = \boldsymbol{H}_K, query = \boldsymbol{H}_Q) = \operatorname{softmax}\left(\frac{\boldsymbol{H}_Q \boldsymbol{W}^Q(\boldsymbol{H}_K \boldsymbol{W}^K)^T}{\sqrt{d}} + \boldsymbol{M}\right),
\end{equation}
\noindent
where $\boldsymbol{W}^Q$, $\boldsymbol{W}^L$ are trainable temporal parameters, $\mathbf{\beta}$ is learned temporal weight indicating pairwise importance, $d$ denotes dimension of input representations, and $\boldsymbol{M}$ is added to ensure auto-regressive setting, i.e., preventing future information affecting current state. We define $\boldsymbol{M}_{ij}=0$ if $i\leq j$, otherwise $-\infty$.

For {\em temporal attention} layer, we use $\boldsymbol{h}_e = \{\boldsymbol{h}_e(1), \boldsymbol{h}_e(2), \cdots, \boldsymbol{h}_e(T)\}$ for both query and key sequence to obtain the temporal attention weights $\beta$:
\begin{equation}
    \small
    \mathbf{\beta} = \text{Attn}(key = \boldsymbol{h}_e, query = \boldsymbol{h}_e),
\end{equation}
\noindent
then the desired $\boldsymbol{H}_e(t)$ is leaned as the combination of input sequence, where $\boldsymbol{W}^V$ is a trainable matrix.:
\begin{equation}
    \begin{aligned}
    \small
    \boldsymbol{H}_e(t) &= \text{Temporal-Attn}(\boldsymbol{h}_e(1), \cdots, \boldsymbol{h}_e(t)) \\
    &= \sum_{i = 1}^{t} \beta_{it} \boldsymbol{h}_e(i)\boldsymbol{W}^V
    \end{aligned}
\end{equation}

For {\em cross-lingual attention} layer, we use $\boldsymbol{H}^s_e = \{\boldsymbol{H}^s_e(1), \cdots, \boldsymbol{H}^s_e(T)\}$ in source language as query sequence and $\boldsymbol{H}^t_e = \{\boldsymbol{H}^t_e(1), \cdots, \boldsymbol{H}^t_e(T)\}$ in target language as key sequence to obtain the attention weights $\beta$:
\begin{equation}
    \small
    \mathbf{\beta}_{e,t} = \text{Attn}(key = \boldsymbol{H}^t_e, query = \boldsymbol{H}^s_e)_{tt},
\end{equation}
\noindent
where $\mathbf{\beta}_{e,t}$ is trainable weight to adjust the alignment strength of different entities at different time.

\subsection{Theorem Proof}
\label{ap:proof}
\begin{theorem}
Let $N$ denote the number of negative samples for optimization, $\epsilon$ denotes the ratio of correct pseudo data, $\beta$ denotes the ratio of pseudo data amount to the initial groundtruth data amount. As the number of negative samples $N \rightarrow \infty$, the $\mathcal{L}_{s\rightarrow t}^{ST}$ converges to its limit with an absolute deviation decaying in $O(\frac{1+\epsilon}{1+\beta}\cdot N ^{-2/3})$.
\end{theorem}
\begin{proof}
In representation learning, the margin loss has been widely adopted as the similarity metric. Without loss of generality, they can be expressed in the form of Noise Contrastive Estimation (NCE)~\cite{NCE}. Therefore, we express $\mathcal{L}_{\mathcal{G}}$ and $\mathcal{L}_{\Gamma_{s\leftrightarrow t}}$ in the form of Noise Contrastive Estimation (NCE) by introducing the negative sampling:
\begin{equation}
\scriptsize
    \mathcal{L}_{\mathcal{G}} \triangleq \mathbb{E}\left[-\log \frac{e^{f(\cdot;\Theta) / \tau}}{e^{f(\cdot;\Theta)/ \tau}+\sum_- e^{\left(f^-(\cdot;\Theta)\right) / \tau}}\right],
\end{equation}

\begin{equation}
\scriptsize
    \mathcal{L}_{\Gamma_{s\leftrightarrow t}} \triangleq \mathbb{E} \left[-\log \frac{e^{g(\cdot;\Phi)) / \tau}}{e^{g(\cdot;\Phi) / \tau}+\sum_- e^{g^-(\cdot;\Phi) / \tau}}\right],
\end{equation}
\noindent
for simplicity, $f^-(\cdot;\Theta)$ denotes the score for negative quadruple, and  $g^-(\cdot;\Phi)$ denotes score for negative alignment pair.

For our training objective $\mathcal{L}_{s \rightarrow t}^{ST}$, we show the convergence analysis of four terms one by one, then prove the overall convergence results. First of all, following~\cite{proof,selfKG}, let $N$ denote the number of negative samples per each quadruple, and we have:
\begin{equation}
\scriptsize
\begin{aligned}
&\lim _{N \rightarrow \infty}\left[\mathcal{L}_{\Tilde{\mathcal{G}}_t}-\log M\right]\\
&=-\frac{1}{\tau} \underset{(e_t, r, e_t^\prime, t) \in \Tilde{\mathcal{G}}_t}{\mathbb{E}}\left[f(\cdot;\Theta)\right] \\
&+\lim _{N \rightarrow \infty} \underset{e^-_t\in \mathcal{E}_t}{\underset{(e_t, r, e_t^\prime, t) \in \Tilde{\mathcal{G}}_t}{\mathbb{E}}}\left[\log \left(\frac{\lambda}{N} e^{f(\cdot;\Theta)/ \tau}+\frac{1}{N} \sum_- e^{f^-(\cdot;\Theta) / \tau}\right)\right]\\ 
&= -\frac{1}{\tau} \underset{(e_t, r, e_t^\prime, t) \in \Tilde{\mathcal{G}}_t}{\mathbb{E}}\left[f(\cdot;\Theta)\right] + \underset{(e_t, r, e_t^\prime, t) \in \Tilde{\mathcal{G}}_t}{\mathbb{E}} \left[\log \underset{e^-_t\in \mathcal{E}_t}{\mathbb{E}}\left[e^{f^-(\cdot;\Theta)}\right]\right],
\end{aligned}
\end{equation}
\noindent
where $\lambda$ denotes the duplicate quadruples co-existing in both incomplete $\Tilde{\mathcal{G}}_t$ and negative samples. The convergence speed is derived as follows:

For one side:
\begin{equation}
\scriptsize
    \mathcal{L}_{\Tilde{\mathcal{G}}_t}-\log N - \lim _{N \rightarrow \infty}\left[\mathcal{L}_{\Tilde{\mathcal{G}}_t}-\log N\right] \leq \frac{\lambda}{N}e^{\frac{2}{\tau}}.
\end{equation}

For another side:
\begin{equation}
    \scriptsize
    \lim _{N \rightarrow \infty}\left[\mathcal{L}_{\Tilde{\mathcal{G}}_t}-\log N\right] - \left[\mathcal{L}_{\Tilde{\mathcal{G}}_t}-\log N\right] \leq \frac{\lambda}{N}e^{2/\tau} + \frac{5}{4} N^{-\frac{2}{3}} e^{\frac{1}{\tau}}(e^{\frac{1}{\tau}}-e^{-\frac{1}{\tau}}).
\end{equation}

We then generalize the above results to the loss term on pseudo data. Suppose $\epsilon$ of the pseudo data are correct. Then we can have the following two inequality. For one side:
\begin{equation}
\scriptsize
\begin{aligned}
    &\mathcal{L}_{\Tilde{\mathcal{G}}_t^{ST}}-\log N - \lim _{N \rightarrow \infty}\left[\mathcal{L}_{\Tilde{\mathcal{G}}_t^{ST}}-\log N\right] \\
    &\leq \epsilon \underset{e\in\mathcal{E}_t}{\mathbb{E}}\left[\log \frac{\underset{e^{-}\in\mathcal{E}_t}{\mathbb{E}}\left[\frac{\lambda}{N}e^{1/\tau} + e^{f^-(\cdot;\Theta_t)/\tau}\right]}{\underset{e^{-}\in\mathcal{E}_t}{\mathbb{E}}e^{f^-(\cdot;\Theta_t)/\tau}} \right] \leq \epsilon \frac{\lambda}{N}e^{\frac{2}{\tau}}
\end{aligned}
\end{equation}

Therefore, for $\mathcal{L}_{s \rightarrow t}^{ST}$ in this side, we have:

\begin{equation}
    \scriptsize
    \mathcal{L}_{s \rightarrow t}^{ST}-\log N - \lim _{N \rightarrow \infty}\left[\mathcal{L}_{s \rightarrow t}^{ST}-\log N\right] \leq \frac{1+\epsilon}{1+\beta} \frac{\lambda}{N}e^{\frac{2}{\tau}},
\end{equation}
where $\beta$ is the ratio of pseudo data amount to groundtruth data amount during training.

Similarly, for another side, we have:
\begin{equation}
\scriptsize
\begin{aligned}
    \lim _{N \rightarrow \infty}\left[\mathcal{L}_{s \rightarrow t}^{ST}-\log N\right] &- \left[\mathcal{L}_{s \rightarrow t}^{ST}-\log N\right] \leq \frac{1+\epsilon}{1+\beta} \frac{\lambda}{N}e^{2/\tau} \\
    &+ \frac{1+\epsilon}{1+\beta} \frac{5}{4} N^{-\frac{2}{3}} e^{\frac{1}{\tau}}(e^{\frac{1}{\tau}}-e^{-\frac{1}{\tau}}).
\end{aligned}
\end{equation}

Therefore, we conclude that the $\mathcal{L}_{s \rightarrow t}^{ST}$ converges to its limit with an absolute deviation decaying in $O(\frac{1+\epsilon}{1+\beta}\cdot N ^{-2/3})$


\end{proof}

\subsection{Datasets}
\label{ap:data}
\noindent \textbf{Dataset Information}.
The commonly utilized benchmark TKGs are divided into two categories: temporal event graphs~\cite{ICEWS18} and knowledge graphs where temporally associated facts have valid periods~\cite{WIKI,YAGO,DBPedia}. In this paper, we mainly evaluate \model on the EventKG~\cite{EventKG}, which is a multilingual resource incorporating event-centric information extracted from several large-scale knowledge graphs such as Wikidata~\cite{WIKI}, DBpedia~\cite{DBPedia} and YAGO~\cite{YAGO}. Each temporal event is organized as $(e, r, e^\prime, t_s, t_e)$, where each piece of data is attached with a valid time period from start time $t_s$ to end time $t_e$. Following~\cite{Renet}, we preprocess the format such that each fact is converted to a sequence $\{(e, r, e^\prime, t_s), (e, r, e^\prime, t_s+1), \cdots, (e, r, e^\prime, t_e)\}$ from $t_s$ to $t_e$, with the minimum time unit as one step.

\noindent \textbf{Splitting Scheme}.
We collect events during 1980 to 2022, and noisy events of early years are removed. To construct multilingual TKGs, we first preserve important entities and relations by excluding infrequent ones that have less than $20$ events in each language. Then we collect the events and cross-lingual alignments.To guarantee the relation match, we only preserve relations appearing in English TKG. We split the time span into 40 equal time steps for training, validation and testing (28/4/8), where each time step roughly lasts for one year. To focus on the prediction on existing entities during training period, and eliminate the negative effects possibly caused by the randomly appearning new entities in val/test period, we only preserve entities having events during training period, following~\cite{RE-GCN}. Table~\ref{tb:data} shows the dataset statistics, including 2 source languages and 6 target languages. We purposefully choose 6 different target languages with diverse characteristics in term of the TKG size, which can evaluate \model from different data granularity. It is worth noting that to simulate the scarcity issue in target TKGs, the training quadruples presented in Table~\ref{tb:data} are randomly selected from original TKGs, with random ratio $20\%$.

\subsection{Baselines}
\label{ap:baseline}
We describe the baselines utilized in the experiments in detail:
\begin{itemize}[leftmargin = 15pt]
    \item \textbf{TransE}~\cite{TransE} is a translation-based embedding model, where both entities and relations are represented as vectors in the latent space. The relation is utilized as a translation operation between the subject and the object entity;
    \item \textbf{TransR}~\cite{TransR}  advances TransE by optimizing modeling of n-n relations, where each entity embedding can be projected to hyperplanes defined by relations;
    \item \textbf{DistMult}~\cite{DistMult} is a general framework with bilinear objective for multi-relational learning that unifies most multi-relational embedding models;
    \item \textbf{RotatE}~\cite{RotatE} represents entities as complex vectors and relations as rotation operations in a complex vector space;
    \item \textbf{TA-DistMult}~\cite{TA-DistMult} is a temporal knowledge graph reansoing method aiming at predicting missing events in history. We utilize it for predicting future events; 
    \item \textbf{RE-NET}~\cite{Renet} is a generative model to predict future facts on temporal knowledge graphs, which employs a recurrent neural network to model the entity evolution, and utilizes a neighborhood aggregator to consider the connection of facts at the same time intervals;
    \item \textbf{RE-GCN}~\cite{RE-GCN} learns the temporal representations of both entities and relations by modeling the KG sequence recurrently;
    \item \textbf{KEnS}~\cite{KEnS} starts to directly improve KGR performance on static KGs given a set of seed alignment, and proposes an ensemble-based approach for the task;
    \item \textbf{AlignKGC}~\cite{AlignKGC} jointly optimizes entity alignment loss and knowledge graph reasoning loss to improve the performance;
    \item \textbf{SS-AGA}~\cite{SS-AGA} views alignments as new edge type and employ a relation-aware GNN with learnable attention weight to model the influence of the aligned entities.
\end{itemize}


\subsection{Reproducibility}
\label{ap:implementation}
\subsubsection{Baseline Setup}
 For static knowledge graph reasoning methods, i.e., TransE, TransR, DistMult, and RotatE, we ignore all time information in quadruples, and view temporal knowledge graphs as static, cumulative ones. For static/temporal KG embedding methods, we merge source graph and target graph by adding one new type of relation (alignment), as they do not explicitly model cross-lingual entity alignment. For multilingual baselines, we train them on 1-to-1 knowledge transferring (instead of the original setting) for fair comparison. For static baselines, we utilize the static embeddings for predictions in all time steps. For fair comparisons, we keep the dimension of all embeddings as $128$, we feed pre-trained TransE embeddings on the merge graph including both source and target TKGs to those that require initial entity/relation embeddings. We tune learning rate of baselines based on {\em MRR} on validation set, and we train all baseline models and \model on same GPUs (Nvidia A100) and CPUs (Intel(R) Xeon(R) Platinum 8275CL).
 
\subsubsection{\model Setup}
We first utilize the source TKG to train the teacher representation module. Then we initialize the student module with the parameters of the teacher. During the training procedure, we first optimize the objective without generating pseudo data in the first 10 epoch. After that, we start to generate high-quality pseudo data. For the generation in each epoch, we gradually increase the amount of pseudo alignments from $10\%$ to $40\%$, and transfer all temporal events that meet the requirement. During evaluation, we tune hyperparameters based on {\em MRR} on validation set, and report the performance on the test set. Next, we report the choices of hyperparameters. For model training, we utilize Adam optimizer, and set maximum number of epochs as $50$. We set batch size as $256$, the dimension of all embeddings as $128$, and dropout rate as $0.5$. For the sake of efficiency,  we set number of temporal neighbors $b$ as $8$, and employ $1$ neighborhood aggregation layer in temporal encoder. For TKG reasoning, we set negative sampling factor as 10. For entity alignment, we set negative sampling factor as 50. For temporal generation process, We divide time span into $4$ time intervals. For model training, we mainly tune margin value $\lambda_1$, $\lambda_2$ in score functions in range $\{0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9\}$, learning rate  in range $\{0.02,0.01,0.005,0.001,0.0005\}$. 

\subsubsection{Efficiency Comparison}
\label{ap:time}
To demonstrate the efficiency of \model framework, we train \model and baseline models from scratch on both target language and source language, and compare the training time. We train all baseline models and \model on same GPUs (Nvidia A100) and CPUs (Intel(R) Xeon(R) Platinum 8275CL). Figure~\ref{fig:time} shows that \model significantly outperforms baseline models with reasonable training time. Notably, we include the pseudo data generation time. Compared with slow temporal models {\em RE-NET, RE-GCN} for knowledge graph reasoning, \model is more efficient because our temporal encoder can learn temporal entity embeddings via sampled temporal neighbors at each time without using RNNs.
