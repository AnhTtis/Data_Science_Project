\section{Methodology}
In this section, we present the proposed \model framework for the cross-lingual temporal knowledge graph reasoning task.

\subsection{Overview}
Figure~\ref{fig:framework} shows an overview of \model. Given the TKGs in source language and target language, the teacher network and the student network first represent the source and target TKGs in a temporally evolving uni-space respectively. To facilitate training of the student, the knowledge distillation is enabled by a cross-lingual alignment module and an explicit temporal event transfer process. To deal with the scarcity issue of cross-lingual alignments, we propose a pseudo alignment generation technique to facilitate the knowledge distillation process, which is mutually-paced along with model training.  To address the temporal knowledge discrepancy issue, the alignment module pulls the aligned entities close to each other based on the alignment strength which is dynamically adjusted.

Section~\ref{sec:encoder} and Section~\ref{sec:align} introduce our teacher/student network and the knowledge distillation respectively, followed by Section~\ref{sec:st} which details how we generate pseudo alignments. Finally, Section~\ref{sec:obj} specifies our learning objective on both groundtruth data and pseudo data, and summarizes the training of \model.

\subsection{The Teacher/Student Network}
\label{sec:encoder}
We train two identical temporal representation modules on source and target TKGs with different parameters. The representation module $f(\cdot;\Theta)$ parameterized by $\Theta$ is designed to measure the plausibility of each quadruple, which represents each entity $e$ into a low-dimensional latent space at each time: $\mathbf{h}_{e}(t) \in \mathbb{R}^d$. On a TKG $\mathcal{G}$, entities $e \in \mathcal{E}$ are evolving, as they interact with different entities over time. Such temporally interacted entities are defined as temporal neighbors. Therefore, we aim to model the temporal pattern of each entity $e$ by encoding the changes of temporal neighbors. 

Towards this goal, $f(\cdot;\Theta)$ first samples temporal neighbors $\mathcal{N}_{e}(t)$ from the TKG for each entity $e\in \mathcal{E}$. $\mathcal{N}_{e}(t)$ consists of a set of the most recently interacted entities at time $t$. Then $f(\cdot;\Theta)$ attentively aggregates information from the temporal neighbors. Specifically, given the temporal neighbor $\mathcal{N}_{e}(t)$, we represent the entity $e$ as $\mathbf{h}_{e}(t)$ at time $t$:
\begin{equation}
    \small
    \mathbf{h}^l_{e}(t) = \sigma\left(\sum_{(e_i, r_i, t_i) \in \mathcal{N}_{e}(t)} \alpha^l_{e,e_i} \left(\mathbf{h}_{e_i}^{l-1}(t_i) \mathbf{W}\right)\right),
\end{equation}
\noindent where $l$ denotes the layer number, $\sigma(\cdot)$ denotes the activation function {\em ReLU}, $\alpha^l_{e,e_i}$ denotes the attention weight of entity $e_i$ to the represented entity $e$, and $\mathbf{W}$ is the trainable transformation matrix. To aggregate from history, $\alpha^l_{e,e_i}$ is supposed to be aware of entity feature, time delay and topology feature induced by relations. Thus, we design the attention weight $\alpha^l_{e,e_i}$ as follows:
\begin{equation}
    \small
      \alpha^l_{e,e_i} = \frac{\exp(q^l_{e,e_i})}{\underset{(e_k, r_k, t_k)\in \mathcal{N}_{e}(t)}{\sum}\exp(q^l_{e,e_k})}, ~~ q^l_{e,e_k} = \mathbf{a}\left(\mathbf{h}^{l-1}_{e} \| \mathbf{h}^{l-1}_{e_k} \| \mathbf{h}_{r_k} \| \kappa(t - t_k)\right),  
\end{equation}
\noindent
where $q^l_{e,e_k}$ measures the pairwise importance by considering the entity embedding, relation embedding and time embedding, $\mathbf{a}\in\mathbb{R}^{4d}$ is the shared parameter in the attention mechanism. Following~\cite{TGAT} we adopt random Fourier features as time encoding $\kappa(\Delta t)$ to reflect the time difference.

To measure plausibility of each possible quadruple, we utilize TransE~\cite{TransE} as the score function $f(e, r, e^\prime, t; \Theta) = -\|\mathbf{h}^l_{e}(t) + \mathbf{h}_r - \mathbf{h}^l_{e^\prime}(t) \|^2$, where true quadruples should have higher scores. To optimize the parameter $\Theta$ on a TKG $\mathcal{G}$, we set the objective to rank the scores of true quadruples higher than all other false quadruples produced by negative sampling:
\begin{equation}
    \small
    \mathcal{L}_{\mathcal{G}} = \underset{(e, r, e^\prime, t) \in \mathcal{G}}{\mathbb{E}} \left[\max(0, \lambda_1 - f(e, r, e^\prime, t; \Theta) + f(e, r, e^{-}, t;\Theta))\right],
    \label{eq:kgloss}
\end{equation}
\noindent
where $(e, r, e^{-}, t)$ is negative samples with object $e^{\prime}$ replaced by $e^{-}$, $\lambda_1$ is the margin to distinguish positive and negative quadruples. 

\subsection{Knowledge Distillation}
\label{sec:align}
The incomplete target TKG, $\Tilde{\mathcal{G}}t$, can be used to train the corresponding parameter $\Theta_t$ through minimization of $\mathcal{L}{\Tilde{\mathcal{G}}_t}$. However, the low-resource nature of the target language often results in an incomplete target TKG, leading to suboptimal $\Theta_t$. In light of this, we propose a knowledge distillation approach to transfer temporal knowledge from the source TKG to the target TKG. The proposed approach consists of two components: an alignment module that enhances $\Theta_t$ using the more informative $\Theta_s$ learned from the source TKG, and an explicit temporal event transfer based on the improved parameters. This integrated approach aims to improve the completeness and quality of the target TKG by leveraging the knowledge contained in the source TKG.

\noindent \textbf{The Alignment Module}.
In general, the source parameters $\Theta_s$ provide a more informative representation of each entity $e \in \mathcal{E}$ compared to the target parameters $\Theta_t$. To take advantage of this, we utilize $\Theta_s$ to guide the optimization of $\Theta_t$ through the alignment module $g(\cdot;\Phi)$, which measures the correspondence between each pair of entities and is parameterized by $\Phi$.

Directly pulling embeddings of aligned entities at all time steps can transfer misleading knowledge due to the temporal knowledge discrepancy. Therefore, the alignment module first utilizes a temporal attention layer to integrate information of each entity from history in both source and target TKGs, i.e., $\mathbf{H}^s_{e}(t), \mathbf{H}^t_{e}(t) \in\mathbb{R}^d$, then it pulls such integration $\mathbf{H}^s_{e}(t)$ close to $\mathbf{H}^t_{e}(t)$ instead of the initial $\mathbf{h}^s_{e}(t)$ and $\mathbf{h}^t_{e}(t)$. Moreover, the temporal integration $\mathbf{H}^s_{e}(t)$ and $\mathbf{H}^t_{e}(t)$ also encode the temporal evolution information for each entity, which can be utilized to estimate the adaptive alignment strength at different time to improve the alignment module. Concretely, the temporal integration is learned by:
\begin{equation}
\begin{aligned}
    \small
    \mathbf{H}^s_{e}(t) &= \text{Temporal-Attn}(\mathbf{h}^s_{e}(1), \mathbf{h}^s_{e}(2), \cdots, \mathbf{h}^s_{e}(t)), \\
    \mathbf{H}^t_{e}(t) &= \text{Temporal-Attn}(\mathbf{h}^t_{e}(1), \mathbf{h}^t_{e}(2), \cdots, \mathbf{h}^t_{e}(t)),
\end{aligned}
\end{equation}
\begin{equation}
    \small
    g(e_s, e_t, t; \Phi) = \frac{\mathbf{H}^s_{e}(t) \cdot \mathbf{H}^t_{e}(t)}{\|\mathbf{H}^s_{e}(t)\|_2 \cdot \|\mathbf{H}^t_{e}(t)\|_2},
\end{equation}
\noindent
where $\text{Temporal-Attn}$ is the temporal attention network designed to integrate information on the temporal domain. The correspondence between each pair of entities $(e_s, e_t)$ across source and target languages at time $t$ is measured by $g(e_s, e_t, t; \Phi)$. As the temporal knowledge for aligned entities is not identical, the alignment strength between them should vary across time $t$. The alignment strength is strong when the two entities share similar information, and weak when the information is dissimilar or the alignment is unreliable. This variability is achieved through the design of a trainable weight $\beta_{e,t}$ to adjust the alignment strength for different entities at different times, which is generated by a cross-lingual attention layer:
\begin{equation}
    \small
    \beta_{e,t} = \text{Cross-Attn}(key = \mathbf{H}^t_{e}(1:T), query = \mathbf{H}^s_{e}(1:T))_{tt}.
\end{equation}

Due the page limitation, we refer readers to Appendix~\ref{ap:attn} for the detailed implementation of $\text{Temporal-Attn}(\cdot)$ and $\text{Cross-Attn}(\cdot)$.

To optimize the parameter $\Phi$ on the incomplete alignments $\Tilde{\Gamma}_{s \leftrightarrow t}$, we set the objective in order to rank the correspondence of true alignments higher than false alignments:
\begin{equation}
\small
    \mathcal{L}_{\Tilde{\Gamma}_{s \leftrightarrow t}} = \underset{\Tilde{\Gamma}_{s \leftrightarrow t}}{\mathbb{E}} \left[\underset{t \in \mathcal{T}}{\mathbb{E}} \left[ \beta_{e,t} \cdot \max(0, \lambda_2 - g(e_s, e_t, t; \Phi) + g(e_s, e_t^{-}, t; \Phi)) \right]\right],
    \label{eq:alignloss}
\end{equation}
\noindent
where the entity pair $(e_s, e_t) \in \Tilde{\Gamma}_{s \leftrightarrow t}$ is the aligned entities across languages, $(e_s, e_t^{-})$ is the negative samples, $\lambda_2$ is the margin value.

\noindent \textbf{Temporal Event Transfer}.
Cross-lingual alignments offer the potential to directly transfer temporal events towards the progressive completion of the target TKG. This is based on the premise that entities that are reliably aligned are likely to experience similar temporal events across languages, with the same relations. 

Given an aligned pair $(e_s, e_t)$, the temporal event $(e_t, r, e_t^?, t)$ or $(e_t^?, r, e_t, t)$ is added to the target TKG if the corresponding event $(e_s, r, e_s^?, t)$ or $(e_s^?, r, e_s, t)$ exists in the source TKG $\mathcal{G}_s$. To determine the missing entity $e_t^?$, we first verify if $(e_s^?, e_t^?)$ is present in the alignment set. If so, the temporal event is directly added to the target TKG. Otherwise, the updated student network $f(\cdot;\Theta_t)$ is utilized to predict the missing entity and the top-1 entity is utilized to complete the temporal event. We define the set of transferred temporal events in the target TKG as $\Tilde{\mathcal{G}}_t^{ST}$ for ease of discussion.

\subsection{Generating Pseudo Alignments}
\label{sec:st}
The limited amount of cross-lingual alignments negatively constrain the effect of the knowledge distillation process. In this section, we introduce how to generate pseudo alignments $\Tilde{\Gamma}_{s\leftrightarrow t}^{ST}$ with high confidence to boost cross-lingual transfer effectiveness.

To expand the range of alignments used in the knowledge transfer process, we generate pseudo-alignments with high confidence scores and incorporate them into the training data. The confidence score for each pair of entities $(e_s, e_t)$ is calculated as the average cosine similarity: $sim(e_s, e_t) = \underset{t}{\mathbb{E}}\left[g(e_s, e_t, t;\Phi)\right]$. While pair-wise similarity comparison is computationally intensive, we improve efficiency by first adding alignments for entities that are neighbors of already aligned entities $\Tilde{\mathcal{E}}t = \{e_t|(e_s, e_t) \in \Tilde{\Gamma}_{s\leftrightarrow t}\}$ in the target TKG, as they are likely to be represented well to produce reliable alignment. Following~\cite{bootEA}, we formulate the generation process as solving the following optimization problem:
\begin{equation}
    \begin{aligned}
    \max &\sum_{e_t \in \mathcal{N}(\Tilde{\mathcal{E}}_t)} \sum_{e_s\in\mathcal{E}_s} sim(e_s, e_t) \cdot \phi(e_s, e_t), \\
    s.t. & \sum_{e_s\in\mathcal{E}_s} \phi(e_s, e_t) = 1, ~~~ \sum_{e_t \in \mathcal{N}(\Tilde{\mathcal{E}}_t)} \phi(e_s, e_t) = 1,
    \end{aligned}
    \label{eq:pseudoalign}
\end{equation}
\noindent
where $\phi(e_s, e_t)$ is a binary indicator of whether to add $(e_s, e_t)$ as pseudo alignment, $\phi(e_s, e_t) = 1$ if we choose to add this pair, otherwise  $\phi(e_s, e_t) = 0$. The two constrains can guarantee each entity $e_t \in \mathcal{N}(\Tilde{\mathcal{E}}_t)$ is aligned to at most one entity in source language $e_s\in\mathcal{E}_s$. Finally, all pairs that satisfying $\phi(e_s, e_t) = 1$ can be viewed as candidates to be added into alignment data. We further select the top ones in terms of $sim(e_s, e_t)$ to control the total size of pseudo alignments. Notably, in each generation, the target entities to be aligned can already have the alignment, i.e., $\mathcal{N}(\Tilde{\mathcal{E}}_t) \bigcup \Tilde{\mathcal{E}}_t \neq \emptyset$. In this case, we can update the existing alignments with the pseudo ones to eliminate the possible alignment noise.

\input{algorithm/al-training}

\subsection{Mutually-paced Optimization}
\label{sec:obj}
\noindent \textbf{Learning Objective}.
Given a source TKG $\mathcal{G}_s$, the incomplete target TKG $\Tilde{\mathcal{G}}_t$, and the incomplete cross-lingual alignment $\Tilde{\Gamma}_{s\leftrightarrow t}$, the objective of cross-lingual temporal knowledge graph reasoning $\mathcal{L}_{s\rightarrow t}$ can be summarized as follows:
\begin{equation}
\mathcal{L}_{s\rightarrow t} = \mathcal{L}_{\Tilde{G}_t} + \mathcal{L}_{\Tilde{\Gamma}_{s\leftrightarrow t}},
\label{eq:gtloss}
\end{equation}
\noindent
where $\mathcal{L}_{\Tilde{G}_t}$ denotes knowledge graph reasoning loss which measures the correctness of each quadruple, $\mathcal{L}_{\Tilde{\Gamma}_{s\leftrightarrow t}}$ denotes the alignment loss which measures the distance of aligned entities in the uni-space. To enlarge the knowledge distillation effect, we progressively transfer temporal events $\Tilde{\mathcal{G}}_t$ and generate high-quality pseudo alignment $\Tilde{\Gamma}_{s\leftrightarrow t}^{ST}$. Therefore, the training objective on both ground-truth data and pseudo data $\mathcal{L}_{s\rightarrow t}^{ST}$ becomes:
\begin{equation}
    \small
    \begin{aligned}
        \mathcal{L}_{s\rightarrow t}^{ST} &= \frac{|\Tilde{\mathcal{G}}_t|}{|\Tilde{\mathcal{G}}_t| + |\Tilde{\mathcal{G}}_t^{ST}|} \cdot \mathcal{L}_{\Tilde{\mathcal{G}}_t} + \frac{|\Tilde{\mathcal{G}}_t^{ST}|}{|\Tilde{\mathcal{G}}_t| + |\Tilde{\mathcal{G}}_t^{ST}|} \cdot  \mathcal{L}_{\Tilde{\mathcal{G}}_t^{ST}} \\
        &+ \frac{|\Tilde{\Gamma}_{s\leftrightarrow t}|}{|\Tilde{\Gamma}_{s\leftrightarrow t}| + |\Tilde{\Gamma}_{s\leftrightarrow t}^{ST}|} \cdot \mathcal{L}_{\Tilde{\Gamma}_{s\leftrightarrow t}} + \frac{|\Tilde{\Gamma}_{s\leftrightarrow t}^{ST}|}{|\Tilde{\Gamma}_{s\leftrightarrow t}| + |\Tilde{\Gamma}_{s\leftrightarrow t}^{ST}|} \cdot \mathcal{L}_{\Tilde{\Gamma}_{s\leftrightarrow t}^{ST}},
    \end{aligned}
    \label{eq:stloss}
\end{equation}
\noindent
where $|\cdot|$ denotes the set size. Eq.~\eqref{eq:stloss} formulates the learning objective on both scarce data and pseudo data for cross-lingual temporal knowledge graph reasoning in target languages. We give the convergence analysis in the following theorem:

\begin{theorem}
Let $N$ denote the number of negative samples for optimization, $\epsilon$ denotes the portion of correct pseudo data, $\beta$ denotes the proportion of pseudo data to the initial ground-truth data. As the number of negative samples $N \rightarrow \infty$, the $\mathcal{L}_{s\rightarrow t}^{ST}$ converges to its limit with an absolute deviation decaying in $O(\frac{1+\epsilon}{1+\beta}\cdot N ^{-2/3})$.
\end{theorem}
\begin{proof}
Refer to Appendix~\ref{ap:proof}.
\end{proof}

\noindent \textbf{Mutually-paced Optimization and Generation}. 
The \model framework can be optimized by minimizing Eq.~\eqref{eq:stloss} w.r.t. $\Theta$ and $\Phi$ alternatively. The generated pseudo alignments can help the training of the representation modules by the knowledge distillation, and in turn transferring temporal events in the target TKG can improves alignment module by providing high-quality representations. In light of this, we propose a mutually-paced optimization and generation procedure. Generally speaking, we iteratively generate pseudo alignments and update the representation module and alignment module respectively. To be concrete, as shown in Algorithm~\ref{al:training}, we first update the alignment module $g(\cdot;\Phi)$ and transfer temporal events to transfer knowledge from source to target. Then we divide the time span into several time steps to update the student representation module from recent time step to far away ones. Finally, we generate the pseudo alignments, as the optimization $\Theta_t$ on all temporal events can improve the entity feature quality, which is beneficial for alignment prediction.  Algorithm~\ref{al:training} summarizes the training procedure. 

% \subsection{Complexity Analysis}
% The time complexity consists of model training and pseudo data generation. For model training, let $b$ denote the number of temporal neighbors for each entity, $l$ denote the number of layers in the representation module, $N$ denote negative sampling factor, the overall complexity is $\mathcal{O}\left(lb^2N(|\Tilde{\mathcal{G}}_t| + |\Tilde{\mathcal{G}}_t^{ST}|) + N|\mathcal{T}|^2(|\Tilde{\Gamma}_{s\leftrightarrow t}| + |\Tilde{\Gamma}_{s\leftrightarrow t}^{ST}|)\right)$, corresponding to the representation module and the alignment module. For pseudo data generation, solving Eq.~\eqref{eq:pseudoalign} can be reduced to linear time by using the similar algorithm in~\cite{graphpartition,bootEA}, and the time complexity of Algorithm~\ref{al:pseudoG} also grows linearly with $|\Tilde{\Gamma}_{s\leftrightarrow t}| + |\Tilde{\Gamma}_{s\leftrightarrow t}^{ST}|$.
