\section{Experiment}

\input{table/tabel-dataset}
\input{table/table-main-clean}

We evaluate \model on EventKG data~\cite{EventKG} including 2 source languages and 6 target languages, and we aim to answer the following research questions:
\begin{itemize}[leftmargin = 15pt]
    \item \textbf{RQ1}: How does \model perform compared with state-of-the-art models on the low-resource target languages?
    \item \textbf{RQ2}: How do reliability of alignment information (with various noise ratio) affect model performances?
    \item \textbf{RQ3}: How do each component and important parameters affect \model performance?
\end{itemize}

\subsection{Datasets} % ~\footnote{https://eventkg.l3s.uni-hannover.de/index.html}
We evaluate \model by 12 cross-lingual TKG transfer tasks on EventKG data~\cite{EventKG}, which is a multilingual TKG including 2 source languages and 6 target languages. For each language, we collect events during 1980 to 2022 and split the time span into 40 time steps for training, validation and testing (28/4/8). Table~\ref{tb:data} shows the dataset statistics. We describe the dataset details in Appendix~\ref{ap:data}.

\subsection{Experimental Setup}

\noindent \textbf{Baselines}.
We compare ten state-of-the-art baselines from three related areas. We describe the baseline details in Appendix~\ref{ap:baseline}.
\begin{itemize}[leftmargin = 15pt]
    \item Static KG embedding methods: \textbf{TransE}~\cite{TransE}, \textbf{TransR}~\cite{TransR}, \textbf{DistMult}~\cite{DistMult}, \textbf{RotatE}~\cite{RotatE};
    \item Temporal KG embedding methods: \textbf{TA-DistMult}~\cite{TA-DistMult}, \textbf{RE-NET}~\cite{Renet}, \textbf{RE-GCN}~\cite{RE-GCN}; 
    \item Multilingual KG embedding methods: \textbf{KEnS}~\cite{KEnS}; \textbf{AlignKGC}~\cite{AlignKGC}; \textbf{SS-AGA}~\cite{SS-AGA}. 
\end{itemize}


\noindent \textbf{Evaluation Protocol and Metrics}.
For each prediction $(e, r, ?, t)$ or $(?, r, e, t)$, we rank missing entities to evaluate the performance. Following~\cite{RE-GCN}, we adopt raw mean reciprocal rank ({\em MRR}) and raw Hits at 10 ({\em H@10}) as evaluation metrics. To quantitatively compare how well the transferred knowledge from the source languages can improve predictions on the low-resource languages, we adopt Transfer Ratio ({\em T.R.}) to evaluate the average improvement of each 
method over the best baseline without knowledge transferring, i.e.:
\begin{equation}
    \small
    T.R. (t_i) = \frac{1}{|S|} \sum_{s_i \in \mathcal{S}} \frac{\text{Model}(s_i \rightarrow t_i)}{\text{BestBaseline}(t_i)}
\end{equation}
\noindent
where $t_i$ denotes each target language, $s_i \in \mathcal{S}$ denotes each source language, and $\text{BestBaseline}(t_i)$ denotes the best baseline performance on the target language $t_i$ without any knowledge transferring, i.e., {\em RE-GCN w/o source}.

\noindent \textbf{Implementation}.
To simulate scarce setting, by default, we utilize $10\%$ alignments and $20\%$ events of target TKG by random selection. For static/temporal KG embedding methods, we merge source graph and target graph by adding one new type of relation (alignment). For multilingual baselines, we train them on 1-to-1 knowledge transferring (instead of the original setting) for fair comparison. We introduce implementation details of baseline models and \model in Appendix~\ref{ap:implementation}. Code and data are open-source and available at \url{https://github.com/amzn/mpkd-thewebconf-2023}.

\begin{figure}[t]
    \centering
    \includegraphics[width = 1.0 \linewidth]{fig/noisy.pdf}
    \caption{Experimental results under various alignment noise ratios. Average H@10 on 6 target languages are reported. \model achieves relatively robust results, with only $3.7\%$ relative drop, others have over $10\%$ drop.}
    \label{fig:noise}
    \vspace{-5mm}
\end{figure}

\subsection{Experiments on Cross-lingual Reasoning (RQ1)}
We first evaluate the model performance with incomplete cross-lingual alignments, where we randomly preserve $10\%$ alignments of the target entities for distilling knowledge. Table~\ref{tb:clean} reports the overall results for the cross-lingual experiments. By utilizing only $10\%$ cross-lingual alignments, \model achieves $33\%$ ({\em MRR}) and $30\%$ ({\em H@10}) relative improvement over best baseline without the knowledge transferring ({\em RE-GCN w/o source}) on average, demonstrating the effectiveness of \model in modeling alignments for knowledge transferring. Compared with ten baselines using alignments, \model still achieves  relative $14\%$ relative improvements over the second best results. Specifically, we have the following observations:
\begin{itemize}[leftmargin = 5pt]
\item Static baseline ({\em TransE, TransR, DistMult, RotatE}) fail to beat {\em RE-GCN w/o source}, although using alignments, due the insufficient modeling of temporal information. Similarly, multilingual methods ({\em KEnS, AlignKGC, SS-AGA}) also produce unsatisfying results; 

\item All temporal baselines ({\em TA-DistMult, RE-Net, RE-GCN}) manage to beat {\em RE-GCN w/o source}, as the modeling of both temporal evolution and cross-lingual alignment can facilitate the representation learning of target entities. But the improvements are marginal compared with our model, as the effect of knowledge distillation is constrained by the limited amount of cross-lingual alignments; 

\item Our model consistently achieves the best performance. Through $10\%$ alignments, \model can progressively transfer temporal knowledge and generate pseudo alignments with high confidence to boost the effect and range of the knowledge distillation;

\item We also notice the uneven improvements across languages, (e.g., ~$40\%$ improvements for German, ~$20\%$ for Italian). We hypothesize it is because of various language dependencies with source languages.
\end{itemize}

% \subsubsection{Performance among entity groups}.
% \ruijie{waiting for results.} To dig into the knowledge distillation effects for different groups of entities, we cluster entities in term of event frequency into four groups, and present the detailed performance distribution among groups in Figure~\ref{fig:group}.

\subsection{Experiments under Alignment Noises (RQ2)}
In reality, cross-lingual alignments can be obtained by human labeling or rule-based inference modules, which may introduce indispensable noises. We evaluate how the reliability of alignment information affects baseline models and \model. In this experiment, we still utilize $10\%$ alignments. To simulate unreliable alignments, we select a subset of alignments (measured by {\em Noise Ratio}) and randomly change the aligned target entity to another entity without alignment information.

\input{table/tabel-ablation}
We vary the noise ratio from $0.0$ to $0.2$ to evaluate the models performance, as shown in Figure~\ref{fig:noise}. We report the average H@10 on 6 target languages by utilizing English TKG and French TKG respectively. As expected, with the increase of noise ratio, the performances of all compared models degrade, as the wrong alignment links mislead the knowledge transfer process. Most baselines fail to beat {\em RE-GCN w/o Source} even with $10\%$ noise, and all lose with $20\% noise$, which indicates that the quality of alignments significantly influences the model effectiveness in the cross-lingual TKG reasoning task. Notably, \model achieves relatively robust results, with only $3.7\%$ performance drop, while other strong baselines have over $10\%$ drop. This is because during the generation of pseudo alignments, \model can automatically replace those unreliable ones based on the confidence score. Also, in the alignment module, \model can assign small alignment strength to unreliable alignments.

\subsection{Model Analysis (RQ3)}
\noindent \textbf{Ablation Study}.
We evaluate performance improvements brought by the \model framework by following ablations: 
\begin{itemize}[leftmargin = 15pt]
\item {\bf \model w/o Align. Strength Control} uniformly set the alignment strength for all entities across all time steps; 
\item {\bf \model w Pure Training} optimizes the teacher-student framework without pseudo alignment generation and temporal event transfer; 
\item {\bf \model w/o Pseudo Align} eliminates the pseudo alignments generation process; 
\item {\bf \model w/o Event Transfer} eliminates the explicit transfer of temporal events.
% \item {\bf Static Training} optimizes the framework in a static manner, i.e., it replaces line 7-10 in Algorithm~\ref{al:training} with static training on all quadruples instead of step by step.
\end{itemize}
Table~\ref{tb:ablation} reports the results measured by $H@10$. Each component leads to performance boost. \model with uniform alignment strength largely degrades performance, due to temporal knowledge discrepancy. \model without pseudo data generation achieves similar performance with temporal baselines {\em RE-Net, RE-GCN}, because of the limited amount of cross-lingual alignments. Bother generating pseudo alignments and explicitly transferring temporal events increase the performance, and combining them together in a mutually-paced procedure (in \model) can achieve the best results. 

\noindent \textbf{The Effect of Pseudo Alignments Ratio}.
To investigate the effects of the pseudo alignments on the reasoning performance, we vary the amount of pseudo alignments during training period and compare the corresponding performance measured by {\em H@10}, as shown in Figure~\ref{fig:pseudoratio}. The blue line and red line show the performances of single model on complete target TKG and single model on $20\%$ target TKG (our setting) respectively. From $0.1$, \model starts to generate and expand the initially available alignments. We observe a significant performance improvement, demonstrating the positive effects of the pseudo alignments. As expected, we find a performance decrease at $50\%$, as the added pseudo data with relatively low confidence start to introduce noise that hurt the performance.


\begin{figure}[t]
    \centering
    \begin{subfigure}[b]{0.495\linewidth}
    \centering
    \includegraphics[width = \linewidth]{fig/alignratio.pdf}
    \caption{Pseudo align. analysis.}
    \label{fig:pseudoratio}
    \end{subfigure}
    \begin{subfigure}[b]{0.495\linewidth}
    \centering
    \includegraphics[width = \linewidth]{fig/time_analysis.pdf}
    \caption{Efficiency analysis.}
    \label{fig:time}
    \end{subfigure}
    \caption{Efficiency analysis and pseudo alignment analysis.}
    \label{fig:analysis}
\end{figure}


\subsection{Efficiency Comparison}
To demonstrate the efficiency of \model framework, we train \model and baseline models from scratch on both target language and source language, and compare the training time. Figure~\ref{fig:time} shows that \model significantly outperforms baseline models with reasonable training time. More details are provided in Appendix~\ref{ap:time}.

