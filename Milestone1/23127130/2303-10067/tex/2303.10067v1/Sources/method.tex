\section{Approach: }
\label{method}

In this paper, AND is designed using a bibliographic dataset $\mathcal{D}=\{d_i\}_{i=1}^{N}$, consisting of $N$ bibliographic records, where each record $d_i$ refers to a unique publication such that $d_i=\{t_i, s_i, \langle a_{i,u},\delta_{i,u}\rangle _{u=1}^{\omega_i}\}$. Here, $t_i$ and $s_i$ denote the \emph{title} and \emph{source} of the record, respectively. $a_{i,u}$ and $\delta_{i,u}$ refer to the $u$\emph{th} author and its corresponding name, respectively, among $\omega_i$ co-authors of $d_i$. Let $\Delta=\{\delta(m)\}_{m=1}^{M}$ be a set of $M$ unique author names in $D$ shared by a set of $L$ unique authors $\mathcal{A}=\{a(l)\}_{l=1}^{L}$ co-authoring all records in $D$, where $L>>M$. Note that each author name $\delta(m)$ might refer to one or more authors in $\mathcal{A}$ and each author $a(l)$ might be referred to by one or two author names in $\Delta$. This is because we consider two variates for each author as it might occur differently in different papers. For example, the author ``\emph{Rachid Deriche}''\orcidlink{0000-0002-4643-8417} is assigned to two elements in $\Delta$, namely ``\emph{Rachid Deriche}'' and ``\emph{R. Deriche}''.



Given a reference record $d^* \notin \mathcal{D}$, the goal of our approach is to link each author name $\delta^*_{u} \in \Delta$ that occurs in $d^*$ to the appropriate author in $\mathcal{A}$ by leveraging $t^*$, $s^*$ and $\{\delta^*_{u}\}_{u=1}^{\omega^*}$. Figure~\ref{fig:illust} illustrates an overview of our proposed approach. First, the approach computes the correspondence frequency $\delta^*_{u}\mathbf{R}\mathcal{A}$ that returns the number of authors in $\mathcal{A}$ corresponding to $\delta^*_{u}$. $\delta^*_{u}\mathbf{R}\mathcal{A} = 0$ indicates that $\delta^*_{u}$ corresponds to a new author $a(\textrm{new}) \notin \mathcal{A}$. $\delta^*_{u}\mathbf{R}\mathcal{A} = 1$ indicates that $\delta^*_{u}$ corresponds to only one author $a(l) \in \mathcal{A}$. In this case, we directly assign $\delta^*_{u}$ to $a(l)$ and no further processing is necessary. Note that in this case, $\delta^*_{u}$ might also refer to a new author $a(\textrm{new}) \notin \mathcal{A}$ who has the same name as an existing author $a(l) \in \mathcal{A}$. However, our approach does not handle this situation. Please refer to Section~\ref{subsec:limit} that lists the limitation of the proposed approach. 


The goal of this paper is to handle the case of  $\delta^*_{u}\mathbf{R}\mathcal{A} > 1$ which indicates that $\delta^*_{u}$ can refer to more than one author. To this end, the approach extracts the atomic name variate from the author name $\delta^*_{u}$. For example, for the author name $\delta^*_{u} = $ ``\emph{Lei Wang}'', the atomic name variate is $\overline{\delta^*_{u}} = $  ``\emph{L Wang}''. Let $\overline{\delta^*_{u}}$ correspond to $\overline{\delta_\mu}$ which denotes the $\mu$\emph{th} atomic name variate among $K$ possible name variates. Afterwards, the corresponding Neural Network model $\theta_\mu \in \Theta=\{\theta_k\}_{k=1}^{K}$ is picked to distinguish between all authors $\mathcal{A}_\mu=\{a(l_\mu)\}_{l_\mu=1}^{L_\mu}$ who share the same name variate $\overline{\delta_\mu}$.\\

\begin{figure*}[h]
  \centering
  %\includegraphics[width=5in,height=2.5in]{Figures/Overview.pdf}
  \includegraphics[width=0.85 \linewidth]{Figures/overview.pdf}
  \caption{An illustration of the task for linking a name mentioned in the reference string with the corresponding DBLP author entity.}
  \label{fig:illust}
\end{figure*}
  \vspace{-0.4cm}



\subsection{Model Architecture}

The Neural Network (NN) model $\theta_\mu$ takes as input the attributes of $d^*$, namely the first name of the target author $\delta^{* \textrm{first-name}}_{u}$, full names of two co-authors $\delta^{*}_{p}$ and $\delta^{*}_{j}$, title $t^*$ and source $s^*$. Figure~\ref{fig:arch} illustrates the architecture of $\theta_\mu$, with an output layer of length $L_k$ corresponding to the number of unique authors in $\mathcal{A_\mu}$ who have the same atomic name variate $\delta_k$. As shown in Figure~\ref{fig:arch}, $\theta_\mu$ takes two inputs $\mathbf{x_{\mu,1}}$ and $\mathbf{x_{\mu,2}}$, such that: 


\begin{equation}
\centering
 \begin{split}
    \mathbf{x_{\mu,1}}= \textrm{char2vec}(\delta^{* \textrm{first-name}}_{u})\bigoplus \frac{1}{2}\left( \textrm{char2vec}(\delta^{*}_{p}) + \textrm{char2vec}(\delta^{*}_{j})\right), \\
    \mathbf{x_{\mu,2}}=\frac{1}{2}\left( \textrm{bert}(t^*) + \textrm{bert}(s^*)\right),
    \end{split}
\end{equation}


\noindent where $\textrm{char2vec}(\mathbf{w})$ returns a vector representation of length $200$ generated using \emph{Char2Vec}~\cite{cao2016joint}, which provides a symbolic representation of $w$.  $\textrm{bert}(\mathbf{w})$ returns a vector representation of each token in $\mathbf{w}$ w.r.t its context in the sentence. This representation of length $786$ is generated using BERT~\cite{devlin2018bert}. The goal of separating the two inputs is to overcome the sparseness of content embedding and force the model to emphasise more on target author representation.

All the hidden layers possess a ReLU activation function, whereas the output is a Softmax classifier. Since the model has to classify thousands of classes, each of which is represented with very few samples, $50\%$ of the units in the last hidden layers are dropped out during training to avoid over-fitting. Furthermore, the number of publications significantly differs from one author to another. Therefore, each class (i.e. the author) is weighted according to its number of samples (i.e. publications). The model is trained with \emph{adam} optimizer and sparse categorical cross-entropy loss function. Our empirical analysis showed that the best performance was achieved with this architecture and these parameters, which were obtained through grid search.



\begin{figure*}[t!]
  \centering
  \includegraphics[width=0.85 \linewidth]{Figures/model.pdf}
  \caption{The architecture of our model.}
  \label{fig:arch}
  \vspace{-0.5cm}
\end{figure*}




\subsection{Author name representation}


The names of authors do not hold any specific semantic nature as they are simply a specific sequence of characters referring to one or more persons. Therefore, we need a model that can encode words based on the order and distribution of characters such that author names with a similar name 
spellings are encoded closely, assuming possible manual editing errors of cited papers. 

Chars2vec is a powerful NN-based language model that is preferred when the text consists of abbreviations, typos, etc. It captures the non - vocabulary words and places words with similar spelling closer in the vector space. This model uses a fixed list of characters for word vectorization, where a one-hot encoding represents each character.



\subsection{Source and Title embedding}


The source (e.g. journal names and book titles) of reference can provide a hint about the area of research of the given reference. In addition, the title is a meaningful sentence that embeds the specific topic of the reference. Therefore, we used these two features to capture the research area of the author. Contrary to the author's name, the goal here is to capture the context of the sequences of words forming the title and source. Therefore, we employed the pre-trained BERT model~\cite{devlin2018bert} to obtain sentence embeddings of both the title and source. 


\subsection{Model Training}

Given the training set $\mathcal{D}_\mu \subset \mathcal{D}$ that corresponds to the subset of bibliographic records authored by authors having the atomic name variate $\overline{\delta_\mu}$, $d_{i_\mu} \in \mathcal{D}_\mu$ generates $\omega_{i_\mu}$ training samples $\langle \delta_\mu, \delta_{i_\mu,p}, \delta_{i_\mu,j}, t_{i_\mu}, s_{i_\mu} \rangle_{p=1}^{\omega_{i_\mu}}$, where $\delta_{i_\mu,j}$ is a random co-author of $d_{i_\mu}$ and might be also the same author name as $\delta_{i_\mu,p}$ and/or $\delta_\mu$. Note also that we consider one combination where $\delta_{i_\mu,p} = \delta_\mu$. In order to train the model with the other common name variate where the first name is substituted with its initial, for each sample, we generate another version with name variates $\langle \overline{\delta_\mu}, \overline{\delta_{i_\mu,p}}, \overline{\delta_{i_\mu,j}}, t_{i_\mu}, s_{i_\mu} \rangle$. Consequently, each bibliographic record is fed into the model $2 \times \omega_{i_\mu}$ times. 

Since the third co-author $\delta_{i_\mu,p}$ is randomly assigned to the training sample among $\omega_{i_\mu}$ co-authors  $d_{i_\mu}$, we randomly reassign it after $Y$ epochs. In addition to lower training complexity, this has shown in the conducted experiments a slightly better result than training the model at each epoch with samples of all possible co-author pairs $p$ and $j$. 

\subsection{Model Tuning}

For each training epoch, \emph{WhoIs} model fine-tunes the parameters to predict the appropriate target author. The performance of the model is considerably influenced by the number of epochs set to train. Specifically, a low epoch count may lead to underfitting. Whereas, a high epoch count may lead to over-fitting. To avoid this, we enabled early stopping, which allows the model to specify an arbitrarily large number of epochs.

Keras supports early stopping of the training via a callback called \emph{EarlyStopping}. This callback is configured with the help of the \emph{monitor} argument which allows setting the validation loss. With this setup, the model receives a trigger to halt the training when it observes no more improvement in the validation loss.

Often, the very first indication of no more improvement in the validation loss would not be the right epoch to stop training; because the model may start improving again after passing through a few more epochs. We overcome this by adding a delay to the trigger in terms of consecutive epochs count on which, we can wait to observe no more improvement. A delay is added by setting the \emph{patience} argument to an appropriate value. \emph{patience} in \emph{WhoIs} is set to $50$, so that the model only halts when the validation loss stops getting better for the past 50 consecutive epochs.

\subsection{Model checkpoint}
Although \emph{WhoIs} stops the training process when it achieves a minimum validation loss, the model obtained at the end of the training may not give the best accuracy on validation data. To account for this, Keras provides an additional callback called \emph{ModelCheckpoint}. This callback is configured with the help of another \emph{monitor} argument. We have set the \emph{monitor} to monitor the validation accuracy. With this setup, the model updates the weights only when it observes better validation accuracy compared to earlier epochs. Eventually, we end up persisting in the best state of the model with respect to the best validation accuracy.


\subsection{Prediction:}
Given the new bibliographic record $d^*=\{t^*, s^*, \langle \delta^*_{u}\rangle _{u=1}^{\omega^*}\}$, the goal is to disambiguate the author name $\delta^*_{\textrm{target}}$ which is shared by more than one author ($\delta^*_{\textrm{target}}\mathbf{R}\mathcal{A} > 1$). To this end, $Y$ samples $S_{y=1}^Y$ are generated for all possible pairs of co-author names $p$ and $j$: $\langle \delta^*_{\textrm{target}}, \delta^*_{p}, \delta^*_{j}, t^*, s^* \rangle_{p=1,j=1}^{\omega^*,\omega^*}$, where  $Y = \textrm{C}(\omega^*+1, 2)$, i.e. the combination of $\omega^*+1$ authors taken 2 at a time, and $\delta^*_u$ can be a full or abbreviated author name. All the $Y$ samples are fed to the corresponding model $\theta_\mu$, where the target author $a_{\textrm{target}}$ of the target name $\delta^*_{\textrm{target}}$ is predicted as follows:
 


\begin{equation}
    a_{{target}}=\underset{1\cdots L_\mu}{{argmax}} \left(\theta_\mu(S_1)\oplus \theta_\mu(S_2)\oplus\cdots\oplus \theta_\mu(S_Y)\right),
\end{equation}


\noindent where $\theta_\mu(S_y)$ returns a probability vector of length $L_\mu$ with each element $l_\mu$ denotes the probability of the author name $\delta^*_{\textrm{target}}$ to be the author $a_{l_\mu}$. 

