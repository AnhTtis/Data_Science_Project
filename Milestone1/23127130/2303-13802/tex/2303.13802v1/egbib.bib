@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@inproceedings{RAVEN,
  title={Words can shift: Dynamically adjusting word representations using nonverbal behaviors},
  author={Wang, Yansen and Shen, Ying and Liu, Zhun and Liang, Paul Pu and Zadeh, Amir and Morency, Louis-Philippe},
  booktitle=AAAI,
  pages={7216--7223},
  year={2019}
}

@inproceedings{MCTN,
  title={Found in translation: Learning robust joint representations by cyclic translations between modalities},
  author={Pham, Hai and Liang, Paul Pu and Manzini, Thomas and Morency, Louis-Philippe and P{\'o}czos, Barnab{\'a}s},
  booktitle=AAAI,
  pages={6892--6899},
  year={2019}
}

@inproceedings{MulT,
  title={Multimodal transformer for unaligned multimodal language sequences},
  author={Tsai, Yao-Hung Hubert and Bai, Shaojie and Liang, Paul Pu and Kolter, J Zico and Morency, Louis-Philippe and Salakhutdinov, Ruslan},
  booktitle={Proceedings of the conference. Association for Computational Linguistics. Meeting},
  year={2019},
}

@InProceedings{PMR,
    author    = {Lv, Fengmao and Chen, Xiang and Huang, Yanyong and Duan, Lixin and Lin, Guosheng},
    title     = {Progressive Modality Reinforcement for Human Multimodal Emotion Recognition From Unaligned Multimodal Sequences},
    booktitle = CVPR,
    year      = {2021},
    pages     = {2554-2562}
}

@inproceedings{TFN,
  title={Tensor fusion network for multimodal sentiment analysis},
  author={Zadeh, Amir and Chen, Minghai and Poria, Soujanya and Cambria, Erik and Morency, Louis-Philippe},
  booktitle={Empirical Methods in Natural Language Processing, EMNLP},
  year={2017}
}

@inproceedings{LMF,
  title={Efficient low-rank multimodal fusion with modality-specific factors},
  author={Liu, Zhun and Shen, Ying and Lakshminarasimhan, Varun Bharadhwaj and Liang, Paul Pu and Zadeh, Amir and Morency, Louis-Philippe},
  booktitle={Proceedings of the conference. Association for Computational Linguistics. Meeting},
  year={2018}
}

@inproceedings{MFN,
  title={Memory fusion network for multi-view sequential learning},
  author={Zadeh, Amir and Liang, Paul Pu and Mazumder, Navonil and Poria, Soujanya and Cambria, Erik and Morency, Louis-Philippe},
  booktitle=AAAI,
  year={2018}
}

@inproceedings{MICA,
  title={Attention is not Enough: Mitigating the Distribution Discrepancy in Asynchronous Multimodal Sequence Fusion},
  author={Liang, Tao and Lin, Guosheng and Feng, Lei and Zhang, Yan and Lv, Fengmao},
  booktitle={ICCV},
  pages={8148--8156},
  year={2021}
}

@inproceedings{MFM,
  title={Learning factorized multimodal representations},
  author={Tsai, Yao-Hung Hubert and Liang, Paul Pu and Zadeh, Amir and Morency, Louis-Philippe and Salakhutdinov, Ruslan},
  booktitle={ICLR},
  year={2019}
}

@inproceedings{EFLSTM,
  title={Recognizing emotions in video using multimodal dnn feature fusion},
  author={Williams, Jennifer and Kleinegesse, Steven and Comanescu, Ramona and Radu, Oana},
  booktitle={Proceedings of Grand Challenge and Workshop on Human Multimodal Language (Challenge-HML)},
  pages={11--19},
  year={2018}
}

@inproceedings{MARN,
  title={Multi-attention recurrent network for human communication comprehension},
  author={Zadeh, Amir and Liang, Paul Pu and Poria, Soujanya and Vij, Prateek and Cambria, Erik and Morency, Louis-Philippe},
  booktitle=AAAI,
  year={2018}
}

@inproceedings{RMFN,
    title = "Multimodal Language Analysis with Recurrent Multistage Fusion",
    author = "Liang, Paul Pu  and
      Liu, Ziyin  and
      Bagher Zadeh, AmirAli  and
      Morency, Louis-Philippe",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    year = "2018",
    pages = "150--161",
}

@article{mosi,
  title={Multimodal sentiment intensity analysis in videos: Facial gestures and verbal messages},
  author={Zadeh, Amir and Zellers, Rowan and Pincus, Eli and Morency, Louis-Philippe},
  journal={IEEE Intelligent Systems},
  volume={31},
  number={6},
  pages={82--88},
  year={2016},
  publisher={IEEE}
}

@inproceedings{mosei,
  title={Multimodal language analysis in the wild: Cmu-mosei dataset and interpretable dynamic fusion graph},
  author={Zadeh, AmirAli Bagher and Liang, Paul Pu and Poria, Soujanya and Cambria, Erik and Morency, Louis-Philippe},
  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics},
  pages={2236--2246},
  year={2018}
}

@inproceedings{Glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={1532--1543},
  year={2014}
}

@inproceedings{Facet,
  title={Openface: an open source facial behavior analysis toolkit},
  author={Baltrusaitis, Tadas and Robinson, Peter and Morency, Louis-Philippe},
  booktitle={2016 IEEE Winter Conference on Applications of Computer Vision (WACV)},
  pages={1--10},
  year={2016},
  organization={IEEE}
}

@inproceedings{COVAREP,
  title={COVAREPâ€”A collaborative voice analysis repository for speech technologies},
  author={Degottex, Gilles and Kane, John and Drugman, Thomas and Raitio, Tuomo and Scherer, Stefan},
  booktitle=ICASSP,
  pages={960--964},
  year={2014},
  organization={IEEE}
}

@inproceedings{hingeloss,
  title={A deep visual-semantic embedding model},
  author={Frome, A and Corrado, GS and Shlens, J and others},
  booktitle={Proceedings of the Advances in Neural Information Processing Systems},
  pages={2121--2129},
  year={2013}
}

@inproceedings{FDMER,
  title={Disentangled Representation Learning for Multimodal Emotion Recognition},
  author={Yang, Dingkang and Huang, Shuai and Kuang, Haopeng and Du, Yangtao and Zhang, Lihua},
  booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
  pages={1642--1651},
  year={2022}
}

@inproceedings{TCSP,
 title={A text-centered shared-private framework via cross-modal prediction for multimodal sentiment analysis},
  author={Wu, Yang and Lin, Zijie and Zhao, Yanyan and Qin, Bing and Zhu, Li-Nan},
  booktitle={Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021},
  pages={4730--4738},
  year={2021}
}

@inproceedings{KD,
  title={Distilling the Knowledge in a Neural Network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  booktitle={NIPS workshop},
  year={2015}
}

@inproceedings{MISA,
  title={Misa: Modality-invariant and-specific representations for multimodal sentiment analysis},
  author={Hazarika, Devamanyu and Zimmermann, Roger and Poria, Soujanya},
  booktitle={Proceedings of the 28th ACM international conference on multimedia},
  pages={1122--1131},
  year={2020}
}

@inproceedings{logitsKD1,
  title={Born again neural networks},
  author={Furlanello, Tommaso and Lipton, Zachary and Tschannen, Michael and Itti, Laurent and Anandkumar, Anima},
  booktitle={International Conference on Machine Learning},
  pages={1607--1616},
  year={2018},
}

@inproceedings{logitsKD2,
  title={Improved knowledge distillation via teacher assistant},
  author={Mirzadeh, Seyed Iman and Farajtabar, Mehrdad and Li, Ang and Levine, Nir and Matsukawa, Akihiro and Ghasemzadeh, Hassan},
      booktitle=AAAI,
  pages={5191--5198},
  year={2020}
}

@inproceedings{logitsKD3,
  title={Online knowledge distillation via collaborative learning},
  author={Guo, Qiushan and Wang, Xinjiang and Wu, Yichao and Yu, Zhipeng and Liang, Ding and Hu, Xiaolin and Luo, Ping},
  booktitle=CVPR,
  pages={11020--11029},
  year={2020}
}

@inproceedings{logitsKD4,
  title={Decoupled Knowledge Distillation},
  author={Zhao, Borui and Cui, Quan and Song, Renjie and Qiu, Yiyu and Liang, Jiajun},
  booktitle=CVPR,
  year={2022}
}

@inproceedings{featKD1,
  title={Fitnets: Hints for thin deep nets},
  author={Romero, Adriana and Ballas, Nicolas and Kahou, Samira Ebrahimi and Chassang, Antoine and Gatta, Carlo and Bengio, Yoshua},
  booktitle=NIPS,
  year={2015}
}

@inproceedings{featKD2,
  title={A comprehensive overhaul of feature distillation},
  author={Heo, Byeongho and Kim, Jeesoo and Yun, Sangdoo and Park, Hyojin and Kwak, Nojun and Choi, Jin Young},
  booktitle=CVPR,
  pages={1921--1930},
  year={2019}
}

@inproceedings{featKD3,
  title={Relational knowledge distillation},
  author={Park, Wonpyo and Kim, Dongju and Lu, Yan and Cho, Minsu},
  booktitle=CVPR,
  year={2019}
}

@inproceedings{featKD4,
  title={Data2vec: A general framework for self-supervised learning in speech, vision and language},
  author={Baevski, Alexei and Hsu, Wei-Ning and Xu, Qiantong and Babu, Arun and Gu, Jiatao and Auli, Michael},
  booktitle={International Conference on Machine Learning},
  year={2022}
}

@inproceedings{GDIJCAI,
  title={Better and faster: knowledge transfer from multiple self-supervised learning tasks via graph distillation for video classification},
  author={Zhang, Chenrui and Peng, Yuxin},
  booktitle=IJCAI,
  year={2018}
}

@inproceedings{GDECCV,
  title={Graph distillation for action detection with privileged modalities},
  author={Luo, Zelun and Hsieh, Jun-Ting and Jiang, Lu and Niebles, Juan Carlos and Fei-Fei, Li},
  booktitle=ECCV,
  pages={166--183},
  year={2018}
}

@inproceedings{GDACCV,
  title={Knowledge transfer graph for deep collaborative learning},
  author={Minami, Soma and Hirakawa, Tsubasa and Yamashita, Takayoshi and Fujiyoshi, Hironobu},
  booktitle=ACCV,
  year={2020}
}


@inproceedings{melville2009sentiment,
  title={Sentiment analysis of blogs by combining lexical knowledge with text classification},
  author={Melville, Prem and Gryc, Wojciech and Lawrence, Richard D},
  booktitle={Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={1275--1284},
  year={2009}
}

@article{petrovica2017emotion,
  title={Emotion recognition in affective tutoring systems: Collection of ground-truth data},
  author={Petrovica, Sintija and Anohina-Naumeca, Alla and Ekenel, Hazim Kemal},
  journal={Procedia Computer Science},
  volume={104},
  pages={437--444},
  year={2017},
  publisher={Elsevier}
}

@article{liu2017facial,
  title={A facial expression emotion recognition based human-robot interaction system},
  author={Liu, Zhentao and Wu, Min and Cao, Weihua and Chen, Luefeng and Xu, Jianping and Zhang, Ri and Zhou, Mengtian and Mao, Junwei},
  journal={IEEE/CAA Journal of Automatica Sinica},
  volume={4},
  number={4},
  pages={668--676},
  year={2017},
  publisher={IEEE}
}



@inproceedings{pham2019found,
  title={Found in translation: Learning robust joint representations by cyclic translations between modalities},
  author={Pham, Hai and Liang, Paul Pu and Manzini, Thomas and Morency, Louis-Philippe and P{\'o}czos, Barnab{\'a}s},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={6892--6899},
  year={2019}
}

@inproceedings{zhang2021matching,
  title={Matching distributions between model and data: Cross-domain knowledge distillation for unsupervised domain adaptation},
  author={Zhang, Bo and Zhang, Xiaoming and Liu, Yun and Cheng, Lei and Li, Zhoujun},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={5423--5433},
  year={2021}
}

@inproceedings{nguyen2021knowledge,
  title={Knowledge distillation with distribution mismatch},
  author={Nguyen, Dang and Gupta, Sunil and Nguyen, Trong and Rana, Santu and Nguyen, Phuoc and Tran, Truyen and Le, Ky and Ryan, Shannon and Venkatesh, Svetha},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={250--265},
  year={2021},
  organization={Springer}
}

@inproceedings{Crossmodaldistillation,
  title={Cross modal distillation for supervision transfer},
  author={Gupta, Saurabh and Hoffman, Judy and Malik, Jitendra},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2827--2836},
  year={2016}
}

@inproceedings{bert,
	title={Bert: Pre-training of deep bidirectional transformers for language understanding},
	author={Kenton, Jacob Devlin Ming-Wei Chang and Toutanova, Lee Kristina},
	booktitle={Proceedings of naacL-HLT},
	pages={4171--4186},
	year={2019}
}

@article{li2020learning,
  title={Learning representations for facial actions from unlabeled videos},
  author={Li, Yong and Zeng, Jiabei and Shan, Shiguang},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={44},
  number={1},
  pages={302--317},
  year={2020},
  publisher={IEEE}
}

@inproceedings{li2019self,
  title={Self-supervised representation learning from videos for facial action unit detection},
  author={Li, Yong and Zeng, Jiabei and Shan, Shiguang and Chen, Xilin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer vision and pattern recognition},
  pages={10924--10933},
  year={2019}
}

