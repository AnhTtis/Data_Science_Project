\section{Related Work}
\label{sec:relw}


\paragraph{Image distortion.} %
Over the past decades, the research community has explored a plethora of simple hand-designed image distortions such as zoom, reflection, rotation, shear, color jittering, solarization, and blurring --- see \cite{shorten_survey_2019} and \cite{perez_effectiveness_2017} for an extensive survey. %
Although all these distortions induce the model to be robust to small perturbations of the input, they might lead to unrealistic images and provide only limited image augmentations. To design more powerful image distortions, the research community has started to combine multiple simple image distortions into a more powerful data augmentation schemes such as Neural Augmentation~\citep{perez_effectiveness_2017}, SmartAugment~\citep{lemley_smart_2017}, AutoAugment~\citep{cubuk_autoaugment_2019}, and RandAugment~\citep{cubuk_randaugment_2020-2}. Although these augmentation schemes oftentimes significantly improve model performance, the resulting distortions are limited by the initial set of simple distortions. Moreover, finding a good combination of simple image distortions is computationally intense since it requires numerous network trainings. 
\paragraph{Image mixing.} An alternative way to increase the diversity of augmented images is to consider multiple images and their labels. For example, CutMix~\citep{yun_cutmix_2019} creates collages of pairs of images while MixUp~\citep{zhang_mixup_2017} interpolates them pixel-wise. In both cases, the mixing factor is regulated by a hyper-parameter, which is also used for label interpolation. However, these augmentation techniques directly target the improvement of class boundaries, at the cost of producing
unrealistic  %
images. 
We argue %
that unrealistic augmentations are a sub-optimal heuristic currently adopted as a strong regularizer, which is no longer needed when larger datasets are available, as shown in~\cite{steiner_how_2021}.%


\paragraph{Data augmentation with autoencoders.} To improve the realism of augmented images, some researchers have explored applying the image augmentations in the latent space of an autoencoder (AE). \cite{devries_dataset_2017} and 
\cite{liu_data_2018} proposed to interpolate/extrapolate neighborhoods in latent space to generate new images. %
Alternatively, \cite{schwartz_delta-encoder_2018} introduced a novel way of training AE to synthesize images from a handful of samples and use them as augmentations to enhance few-shot learning.
Finally, \cite{pesteie_adaptive_2019} used a variational AE trained to synthesize clinical images for data augmentation purposes. However, most of above-mentioned approaches are limited by the quality of the reconstructed images which are oftentimes blurry. 




 



\paragraph{Data augmentation with generative models.} To improve the visual quality of augmented images, the community has studied the use of generative models in the context of both data augmentation and dataset augmentation. \cite{tritrong_repurposing_2021, mao_generative_2021} explored the use of instance-specific augmentations obtained via GAN inversion~\citep{xia_gan_2022, huh_transforming_2020, zhu_generative_2016}, which map original images into latent vectors that can be subsequently transformed to generate augmented images~\citep{jahanian_steerability_2020, harkonen_ganspace_2020}. %
However, GAN inversion is a computationally intense operation and latent space transformations are difficult to control~\citep{wang_implicit_2019, wang_regularizing_2021}. \cite{antoniou_data_2018} proposed a specific GAN model to generate a realistic image starting from an original image combined with a noise vector. However, this work was only validated on low-shot benchmarks. Researchers have also explored learning representations using samples from a trained generative model exclusively~\citep{shrivastava_learning_2017, zhang_datasetgan_2021-2, li_bigdatasetgan_2022, besnier_this_2020, li_semantic_2021, zhao_synthesizing_2022, jahanian_generative_2022} as well as combining real dataset images with samples from a pre-trained generative model~\citep{frid-adar_gan-based_2018, bowles_gan_2018, ravuri_classification_2019}, with the drawback of drastically shifting the training distribution.
Finally, the use of unpaired image-to-image translation methods to augment small datasets was explored in \cite{sandfort_data_2019, huang_auggan_2018, gao_low-shot_2018, choi_self-ensembling_2019}.
However, such approaches are designed to translate source images into target images and thus are limited by the source and target image distributions.
 
 










\paragraph{Data augmentation with latent neighbor images.} Another promising data augmentation technique uses neighbor images to create semantically-similar image pairs that can be exploited for multi-view representation learning typical of SSL. This technique was promoted in NNCLR~\citep{dwibedi_little_2021-1}, an extension of the SSL model SimCLR~\citep{chen_simple_2020} to use neighbors, with some limitations due to the restricted and dynamic subset used for neighbor retrieval. Alternatively, \cite{jahanian_generative_2022} explored the generation of neighbor pairs by using latent space transformations in conjunction with a pre-trained generative model. However, this model only uses generated samples to learn the representations and reports poor performance on a simplified ImageNet setup (training on $128\times128$ resolution images for only 20 epochs).















