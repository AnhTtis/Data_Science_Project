{
    "arxiv_id": "2303.11611",
    "paper_title": "Model Robustness Meets Data Privacy: Adversarial Robustness Distillation without Original Data",
    "authors": [
        "Yuzheng Wang",
        "Zhaoyu Chen",
        "Dingkang Yang",
        "Pinxue Guo",
        "Kaixun Jiang",
        "Wenqiang Zhang",
        "Lizhe Qi"
    ],
    "submission_date": "2023-03-21",
    "revised_dates": [
        "2023-03-22"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV"
    ],
    "abstract": "Large-scale deep learning models have achieved great performance based on large-scale datasets. Moreover, the existing Adversarial Training (AT) can further improve the robustness of these large models. However, these large models are difficult to deploy to mobile devices, and the effect of AT on small models is very limited. In addition, the data privacy issue (e.g., face data and diagnosis report) may lead to the original data being unavailable, which relies on data-free knowledge distillation technology for training. To tackle these issues, we propose a challenging novel task called Data-Free Adversarial Robustness Distillation (DFARD), which tries to train small, easily deployable, robust models without relying on the original data. We find the combination of existing techniques resulted in degraded model performance due to fixed training objectives and scarce information content. First, an interactive strategy is designed for more efficient knowledge transfer to find more suitable training objectives at each epoch. Then, we explore an adaptive balance method to suppress information loss and obtain more data information than previous methods. Experiments show that our method improves baseline performance on the novel task.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.11611v1"
    ],
    "publication_venue": null
}