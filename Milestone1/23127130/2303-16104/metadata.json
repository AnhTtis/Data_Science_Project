{
    "arxiv_id": "2303.16104",
    "paper_title": "Hallucinations in Large Multilingual Translation Models",
    "authors": [
        "Nuno M. Guerreiro",
        "Duarte Alves",
        "Jonas Waldendorf",
        "Barry Haddow",
        "Alexandra Birch",
        "Pierre Colombo",
        "Andr√© F. T. Martins"
    ],
    "submission_date": "2023-03-28",
    "revised_dates": [
        "2023-03-29"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CL"
    ],
    "abstract": "Large-scale multilingual machine translation systems have demonstrated remarkable ability to translate directly between numerous languages, making them increasingly appealing for real-world applications. However, when deployed in the wild, these models may generate hallucinated translations which have the potential to severely undermine user trust and raise safety concerns. Existing research on hallucinations has primarily focused on small bilingual models trained on high-resource languages, leaving a gap in our understanding of hallucinations in massively multilingual models across diverse translation scenarios. In this work, we fill this gap by conducting a comprehensive analysis on both the M2M family of conventional neural machine translation models and ChatGPT, a general-purpose large language model~(LLM) that can be prompted for translation. Our investigation covers a broad spectrum of conditions, spanning over 100 translation directions across various resource levels and going beyond English-centric language pairs. We provide key insights regarding the prevalence, properties, and mitigation of hallucinations, paving the way towards more responsible and reliable machine translation systems.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.16104v1"
    ],
    "publication_venue": null
}