% File tacl2021v1.tex
% Dec. 15, 2021

% The English content of this file was modified from various *ACL instructions
% by Lillian Lee and Kristina Toutanova
%
% LaTeXery is mostly all adapted from acl2018.sty.

\documentclass[11pt,a4paper]{article}
\usepackage{times,latexsym}
\usepackage{url}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

\usepackage{tikz}
\usepackage{subcaption}
\usepackage{colortbl}
\usepackage{makecell}
\usepackage{multicol}
\usepackage{float}
\usepackage{lscape}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{colortbl}
\usepackage{enumitem}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{longtable}
\usepackage{tabu}
\usepackage{longtable}
\usepackage{arydshln}
\usepackage{inconsolata}
\usepackage{rotating}

\renewcommand\sfdefault{cmss}
\usepackage{pdflscape}

\usepackage{soul}
\definecolor{HallRedShade}{HTML}{fdf1ec}
\definecolor{HallRedText}{HTML}{b76039}
\sethlcolor{HallRedShade}


% \renewcommand\thesubfigure{(\alph{subfigure})}
% \captionsetup[sub]{
%   labelformat=simple
% }

% dashed midrule
\makeatletter
\def\adl@drawiv#1#2#3{%
        \hskip.5\tabcolsep
        \xleaders#3{#2.5\@tempdimb #1{1}#2.5\@tempdimb}%
                #2\z@ plus1fil minus1fil\relax
        \hskip.5\tabcolsep}
\newcommand{\cdashlinelr}[1]{%
  \noalign{\vskip 1.3pt
           \global\let\@dashdrawstore\adl@draw
           \global\let\adl@draw\adl@drawiv}
  \cdashline{#1}[.4pt/2pt]
  \noalign{\global\let\adl@draw\@dashdrawstore
           \vskip 1.3pt}}
\makeatother
%% Package options:
%% Short version: "hyperref" and "submission" are the defaults.
%% More verbose version:
%% Most compact command to produce a submission version with hyperref enabled
%%    \usepackage[]{tacl2021v1}
%% Most compact command to produce a "camera-ready" version
%%    \usepackage[acceptedWithA]{tacl2021v1}
%% Most compact command to produce a double-spaced copy-editor's version
%%    \usepackage[acceptedWithA,copyedit]{tacl2021v1}
%
%% If you need to disable hyperref in any of the above settings (see Section
%% "LaTeX files") in the TACL instructions), add ",nohyperref" in the square
%% brackets. (The comma is a delimiter in case there are multiple options specified.)

\usepackage[acceptedWithA]{tacl2021v1}
%\setlength\titlebox{10cm} % <- for Option 2 below

%%%% Material in this block is specific to generating TACL instructions
\usepackage{xspace,mfirstuc,tabulary}
\newcommand{\dateOfLastUpdate}{Dec. 15, 2021}
\newcommand{\styleFileVersion}{tacl2021v1}

\newcommand{\ex}[1]{{\sf #1}}

\newif\iftaclinstructions
\taclinstructionsfalse % AUTHORS: do NOT set this to true
\iftaclinstructions
\renewcommand{\confidential}{}
\renewcommand{\anonsubtext}{(No author info supplied here, for consistency with
TACL-submission anonymization requirements)}
\newcommand{\instr}
\fi

%
\iftaclpubformat % this "if" is set by the choice of options
\newcommand{\taclpaper}{final version\xspace}
\newcommand{\taclpapers}{final versions\xspace}
\newcommand{\Taclpaper}{Final version\xspace}
\newcommand{\Taclpapers}{Final versions\xspace}
\newcommand{\TaclPapers}{Final Versions\xspace}
\else
\newcommand{\taclpaper}{submission\xspace}
\newcommand{\taclpapers}{{\taclpaper}s\xspace}
\newcommand{\Taclpaper}{Submission\xspace}
\newcommand{\Taclpapers}{{\Taclpaper}s\xspace}
\newcommand{\TaclPapers}{Submissions\xspace}
\fi

\usepackage{soul}
\usepackage{pdflscape}
\definecolor{hl_color_da}{HTML}{FFC6C6}
\definecolor{hl_color_ng}{HTML}{D7C9FF}
\definecolor{hl_color_pc}{HTML}{FFD4AA}
\definecolor{hl_color_jw}{HTML}{BCE6E6}
\definecolor{hl_color_am}{HTML}{F7DCB4}
\definecolor{hl_color_bh}{HTML}{F7DCB4}
\definecolor{hl_color_ab}{HTML}{F7DCB4}
\definecolor{graytext}{HTML}{404040}

\newcommand{\duarte}[1]{\textbf{\textcolor{graytext}{\sethlcolor{hl_color_da}\hl{[DA: #1]}}}}
\newcommand{\nuno}[1]{\textbf{\textcolor{graytext}{\sethlcolor{hl_color_ng}\hl{[NG: #1]}}}}
\newcommand{\pierre}[1]{\textbf{\textcolor{graytext}{\sethlcolor{hl_color_pc}\hl{[PC: #1]}}}}
\newcommand{\jonas}[1]{\textbf{\textcolor{graytext}{\sethlcolor{hl_color_jw}\hl{[JW: #1]}}}}
\newcommand{\andre}[1]{\textbf{\textcolor{graytext}{\sethlcolor{hl_color_am}\hl{[AM: #1]}}}}
\newcommand{\barry}[1]{\textbf{\textcolor{graytext}{\sethlcolor{hl_color_bh}\hl{[AM: #1]}}}}
\newcommand{\lexi}[1]{\textbf{\textcolor{graytext}{\sethlcolor{hl_color_ab}\hl{[AM: #1]}}}}

\definecolor{tikz_blue}{HTML}{009ADE}
\definecolor{tikz_red}{HTML}{F67280}
\definecolor{tikz_orange}{HTML}{F28522}
\definecolor{tikz_gray}{HTML}{E2E2E2}
\definecolor{tikz_green}{HTML}{91B54D}

%%%% End TACL-instructions-specific macro block
%%%%

\title{Hallucinations in Large Multilingual Translation Models}

% Author information does not appear in the pdf unless the "acceptedWithA" option is given

% The author block may be formatted in one of two ways:

% Option 1. Author’s address is underneath each name, centered.

% \author{
%   Template Author1\Thanks{The {\em actual} contributors to this instruction
%     document and corresponding template file are given in Section
%     \ref{sec:contributors}.} 
%   \\
%   Template Affiliation1/Address Line 1
%   \\
%   Template Affiliation1/Address Line 2
%   \\
%   Template Affiliation1/Address Line 2
%   \\
%   \texttt{template.email1example.com}
%   \And
%   Template Author2 
%   \\
%   Template Affiliation2/Address Line 1
%   \\
%   Template Affiliation2/Address Line 2
%   \\
%   Template Affiliation2/Address Line 2
%   \\
%   \texttt{template.email2@example.com}
% }

% % Option 2.  Author’s address is linked with superscript
% % characters to its name, author names are grouped, centered.
\definecolor{citeblue}{HTML}{120d77}

\author{Nuno M. Guerreiro$^{1,3}$ \quad Duarte M. Alves$^{1,3}$ \quad Jonas Waldendorf\,$^{4}$ \\
\textbf{Barry Haddow}$^{4}$ \quad \textbf{Alexandra Birch}$^{4}$ \quad \textbf{Pierre Colombo}$^{5}$ \quad \textbf{André F. T. Martins}$^{1,2,3}$ \\
$^1$Instituto de Telecomunicações, Lisbon, Portugal \hfill $^2$Unbabel, Lisbon, Portugal\\
$^3$Instituto Superior T\'ecnico, University of Lisbon, Portugal\\
$^4$School of Informatics, University of Edinburgh\\
$^5$MICS, CentraleSupélec, Université Paris-Saclay\\
\small \url{miguelguerreironuno@gmail.com}}

% \textcolor{citeblue}{\url{miguelguerreironuno@gmail.com \quad andre.t.martins@tecnico.ulisboa.pt}} \\ \small \textcolor{citeblue}{\texttt{\{pierre.colombo, pablo.piantanida\}@centralesupelec.fr}}} \\ 

\date{}

\begin{document}
\maketitle
\begin{abstract}
    Large-scale multilingual machine translation systems have demonstrated remarkable ability to translate directly between numerous languages, making them increasingly appealing for real-world applications. However, when deployed \textit{in the wild}, these models may generate hallucinated translations which have the potential to severely undermine user trust and raise safety concerns. Existing research on hallucinations has primarily focused on small bilingual models trained on high-resource languages, leaving a gap in our understanding of hallucinations in massively multilingual models across diverse translation scenarios. In this work, we fill this gap by conducting a comprehensive analysis on both the M2M family of conventional neural machine translation models and ChatGPT, a general-purpose large language model~(LLM) that can be prompted for translation. Our investigation covers a broad spectrum of conditions, spanning over 100 translation directions across various resource levels and going beyond English-centric language pairs. We provide key insights regarding the prevalence, properties, and mitigation of hallucinations, paving the way towards more responsible and reliable machine translation systems. 
\end{abstract}

\section{Introduction}
\label{sec:introduction}
Recent advancements in large-scale multilingual machine translation have brought us closer to realizing a universal translation system: a single model capable of handling numerous languages and translation directions~\citep{aharoni-etal-2019-massively, arivazhagan-etal-2019, fanetal2020_m2m, zhang-etal-2020-improving, wenzek-etal-2021-findings, goyal-etal-2022-flores, nllb2022}. Concurrently, general-purpose large language models~(LLMs) have exhibited a remarkable ability to generalize to new tasks, including translation, where they are becoming increasingly stronger~\citep{browngpt3_openai, palm_google, hendyetal2023_microsoftchatgpt}. Compared to traditional bilingual models, these systems can offer significant performance improvements and greatly simplify engineering efforts, as a single model can be used for all language pairs~\citep{arivazhagan-etal-2019}. As a result, they are an increasingly attractive choice for real-world applications. However, when deployed \textit{in the wild}, these models may still generate \textit{hallucinations}:~highly pathological translations that can severely damage user trust and pose serious safety concerns~\citep{perez2022red, kumaretal2022_harmeacl}.

The problem of hallucinations has long been recognized by researchers~\citep{jietal2022}, and recent studies have contributed towards better understanding, detection and mitigation of these pathological translations. However, these studies have been conducted on \textit{small bilingual} models~(<100M parameters) trained on a \textit{single English-centric high-resource} language pair~\citep{raunak-etal-2021-curious, ferrando-etal-2022-towards, guerreiro-etal-2022-lookingforaneedle, guerreiro-etal-2022-optimaltransport, dale-etal-2022-hallsalti, xu-etal-2022-taclhalls}. This leaves a knowledge gap regarding the prevalence and properties of hallucinations in large-scale translation models across different translation directions, domains and data conditions.

% While the problem of hallucinations has long been recognized by researchers and practitioners~\citep{jietal2022}, research on hallucinations in large-scale multilingual translation models has been largely overlooked. In fact, the vast majority of dedicated studies on hallucinations in machine translation have been conducted on \textit{small bilingual} models~(<100M parameters) trained on a \textit{single English-centric high-resource} language pair~\citep{raunak-etal-2021-curious, ferrando-etal-2022-towards, guerreiro-etal-2022-lookingforaneedle, dale-etal-2022-hallsalti, guerreiro-etal-2022-optimaltransport, xu-etal-2022-taclhalls}. This leaves a significant gap in our knowledge of how prevalent hallucinations are in large multilingual translation systems across different translation directions, domains and data conditions.

In this work, we aim to fill this gap by investigating hallucinations on two different classes of models. The first and main class in our analysis is the \textit{de facto} standard approach of massively multilingual supervised models: we use the M2M-100 family of multilingual NMT models~\citep{fanetal2020_m2m}, which includes the largest open-source multilingual NMT model with 12B parameters. The second class is the novel and promising approach of leveraging generative LLMs for translation. Contrary to conventional NMT models, these models are trained on massive amounts of monolingual data in many languages, with a strong bias towards English, and do not require parallel data. In our analysis, we use ChatGPT\footnote{\url{https://openai.com/blog/chatgpt}; this system has not been documented, so details of training data and training regime are unknown.}, a LLM that has been shown to achieve surprisingly high translation quality over a wide range of language pairs~\citep{hendyetal2023_microsoftchatgpt, Peng2023ChatGPT4MT}.

We organize our study by analyzing the two prevalent types of hallucinations in NMT considered in the literature: hallucinations under perturbation and natural hallucinations~\citep{Lee2018HallucinationsIN, raunak-etal-2021-curious, guerreiro-etal-2022-lookingforaneedle}. Firstly, we study hallucinations under perturbation and evaluate whether these translation systems are robust to source-side artificial perturbations. While previous studies have found that these perturbations (e.g., spelling errors and capitalization mistakes) can reliably induce hallucinations~\citep{Lee2018HallucinationsIN, raunak-etal-2021-curious}, it is not clear whether those conclusions hold for large multilingual models. Secondly, we comprehensively investigate natural hallucinations, and evaluate their prevalence and properties in the outputs of the massively multilingual M2M models on a vast range of conditions, spanning from English-centric to non-English-centric language pairs, translation directions with little supervision, and specialized sensitive domains where hallucinations have devastating impact on user trust (e.g., medical data). Finally, we study a hybrid setup where other translation systems can be requested as fallback systems when an original system hallucinates, with the aim of mitigating hallucinations and improving overall translation quality. 

Our analysis reveals several key insights on the prevalence and properties of hallucinations, including:
\begin{itemize}
    \item multilingual models predominantly struggle with hallucinations in low-resource language pairs and translating out of English, with hallucination rates well above 10\% for some translation directions;
    \item hallucinations in low-resource language pairs can manifest toxic patterns that can be traced back to the training data, posing serious safety issues;
    \item smaller distilled models can mitigate hallucinations by incorporating modeling choices that discourage them, such as leveraging less potent shallow decoders that rely more on the encoder representations, and reducing bias towards higher-resource language pairs through uniform sampling of translation directions during distillation;
    \item ChatGPT produces hallucinations that are qualitatively different from those of conventional translation models, mostly consisting of off-target translations, overgeneration, and even failed attempts to translate;
    \item hallucinations are \textit{sticky} and hard to reverse with models that share the same training data and architecture, whereas employing more diverse models as fallback systems can substantially improve overall translation quality and eliminate pathologies like oscillatory hallucinations.
\end{itemize}

We release all our code and make available over a million translations in more than 100 translation directions to spur future research.\footnote{All resources will be made available in \url{https://github.com/deep-spin/lmt_hallucinations}.}


\section{Background}
\label{sec:background}
\subsection{Large Multilingual Language Models}
Massively multilingual neural machine translation has recently emerged as a powerful paradigm for building machine translation systems that can handle numerous languages~\citep{akhbardeh-etal-2021-findings,wenzek-etal-2021-findings,nllb2022, siddhantetal2022_multilingual_google, googletranslate2022, palm_google}. These systems aim to translate directly with a single model for multiple language pairs without relying on any pivot language.

The dominant strategy for achieving these systems is to train large multilingual models on vast amounts of parallel data often obtained through a combination of data mining and data augmentation strategies, such as backtranslation~\citep{sennrich-etal-2016-improving, edunov-etal-2018-understanding}. Compared to classic bilingual models, the multilinguality of these systems results in significant improvements, particularly for low-resource and non-English-centric language pairs, as these benefit the most from multilingual transfer~\citep{arivazhagan-etal-2019, fanetal2020_m2m}. 

As an alternative, a novel and promising strategy is to leverage the emergent capabilities of large language models (LLMs). These systems are pretrained on massive nonparallel corpora and can be prompted to solve arbitrary tasks~\citep{radford2019language, browngpt3_openai}. In fact, this approach has led to impressive results across a wide variety of NLP tasks~\citep{palm_google, opt_2022}. Translation is no exception: LLMs can produce fluent and adequate translations, especially for high-resource English-centric language pairs, that are competitive with those of dedicated supervised translation models~\citep{vilaretal2023_palm, Peng2023ChatGPT4MT, garciaetal2023_google, hendyetal2023_microsoftchatgpt, bawdenandyvon2023_bloom}.

\subsection{Hallucinations in Machine Translation}
Hallucinations lie at the extreme end of translation pathologies and present a critical challenge in machine translation, as they can severely compromise the safety and reliability of real-world applications.

Importantly, hallucinations in machine translation are unlike hallucinations in other natural language generation tasks (e.g., abstractive summarization and generative question answering)~\citep{jietal2022}. While, for these other tasks, models often produce hallucinated outputs~\citep{falke-etal-2019-ranking, cao-etal-2022-hallucinated, selfcheckgpt_2023}, hallucinations in machine translation, possibly attributed to the more closed-ended nature of the task, are substantially rarer and hard to observe in clean, unperturbed data. This has led several previous studies to examine their properties by creating artificial scenarios where hallucinations are more likely to occur (e.g., introducing perturbations in the source text~\citep{Lee2018HallucinationsIN} or noise in the training data~\citep{raunak-etal-2021-curious}). To distinguish these two scenarios, hallucinations in machine translation are categorized into two types~\citep{raunak-etal-2021-curious}: \textit{hallucinations under perturbation} and \textit{natural hallucinations}.

\paragraph{Hallucinations under perturbation.} A model generates a hallucination under perturbation when it produces a significantly lower quality translation for a slightly perturbed input compared to the original input~\citep{Lee2018HallucinationsIN}. Hallucinations under perturbation explicitly reveal the lack of robustness of translation systems to perturbations in the source text~(e.g., misspellings or capitalization errors) by finding translations that undergo significant negative shifts in quality due to these changes.

\paragraph{Natural hallucinations.} Contrary to hallucinations under perturbations, these translations occur naturally without any perturbation. As a result, natural hallucinations are rare and challenging to study. In this work, we follow the taxonomy introduced in~\citet{raunak-etal-2021-curious} and later extended in~\citet{guerreiro-etal-2022-lookingforaneedle}. Under this taxonomy, hallucinations are translations that contain content that is detached from the source text. To distinguish between different types of hallucinations, they can be categorized as \textit{largely fluent detached hallucinations} or \textit{oscillatory hallucinations}. The former refers to translations that bear minimal or no relation at all to the source, while the latter refers to inadequate translations that contain erroneous repetitions of words and phrases.
%Nevertheless, recent research has made significant strides towards better understanding, detection and mitigation of these translations~\citep{guerreiro-etal-2022-lookingforaneedle, guerreiro-etal-2022-optimaltransport, dale-etal-2022-hallsalti, xu-etal-2022-taclhalls}. 

\section{Experimental Suite}
\label{sec:experimental_suite}
In this section, we provide an overview of the models, datasets and evaluation metrics used throughout our study. 
\subsection{Models}
We focus on two classes of models: (i) conventional supervised multilingual NMT models, and (ii) LLMs that can be prompted for translation.

For the supervised multilingual NMT models, we use the transformer-based~\citep{transformer_vaswani} M2M-100 family of models~\citep{fanetal2020_m2m}, which consists of three variants with different sizes: \texttt{M2M~(S)} with 418M parameters, \texttt{M2M~(M)} with 1.2B parameters, and \texttt{M2M~(L)}~--- the largest available open-source multilingual NMT model~---  with 12B parameters. These models were trained on a many-to-many parallel dataset comprising 7.5B sentences crawled from the web, and support 100 languages and thousands of translation directions. We also experiment with \texttt{SMaLL100} \citep{mohammadshahi-etal-2022-small}, a shallow multilingual NMT model with 330M parameters obtained via distillation of \texttt{M2M (L)}. Unlike the M2M models, \texttt{SMaLL100} was trained on a much smaller training set with uniform sampling across all language pairs to reduce the bias towards high-resource languages: only 100k parallel sentences from the original M2M training data were used for each translation direction, for a total of 456M parallel sentences. For decoding, we run beam search with a beam size of 4. All experiments were run on \texttt{fairseq}~\citep{ott-etal-2019-fairseq}. 

As for the alternative strategy using LLMs, we use \texttt{ChatGPT} (\texttt{gpt-3.5-turbo})\footnote{\url{https://platform.openai.com/docs/models/gpt-3-5}; we used the API in March, 2023.} , a variant of GPT3.5 --- a GPT-family~\citep{Radford2018ImprovingLU, radford2019language, browngpt3_openai} large-scale model with 175B parameters --- that has been fine-tuned with human feedback in the style of InstructGPT~\citep{instructgpt_2022}. \texttt{ChatGPT} has been shown to achieve impressive results for multiple multilingual NLP tasks, including translation~\citep{kocmiandfedermann2023, lu2023error, gptscore_2023, hendyetal2023_microsoftchatgpt, Peng2023ChatGPT4MT}. To generate translations, we use the zero-shot prompt template used in ~\citet{hendyetal2023_microsoftchatgpt} and keep the generation parameters as the default API parameters.\footnote{We encountered several API/server errors when prompting \texttt{ChatGPT} for translation with temperature 0, particularly for low-resource language pairs and languages with lower coverage scripts. Those errors are alleviated, although not entirely eliminated, when the default parameters are used.}

\subsection{Datasets}
\label{subsec:datasets}
We carefully selected datasets based on two main criteria: their familiarity to researchers and practitioners, and the avoidance of train/test overlap for the M2M models.\footnote{\texttt{ChatGPT}’s training data is not publicly available. As such, we cannot guarantee that it has not been exposed to the data we use in our analysis.} To this end, we chose to use premier translation benchmarks: \textsc{Flores}-101~\citep{goyal-etal-2022-flores}, WMT and TICO~\citep{anastasopoulos-etal-2020-tico}. \textsc{Flores}-101 is a high-quality multi-parallel dataset that consists of Wikipedia text in 101 languages and allows for the assessment of hallucinations across a vast range of translation directions; we join the \texttt{dev} and \texttt{devtest} subsets for evaluation. For WMT, we used the same benchmarks as those used in the original M2M paper evaluation suite, as these were explicitly removed from the training data. Additionally, we selected recent WMT test sets from the WMT21 and WMT22 campaigns as they were released after the models were trained. In contrast to these general-purpose datasets, TICO is a specialized medical-domain multilingual benchmark that includes COVID-19 related data, such as medical papers and news articles; we join the \texttt{dev} and \texttt{test} sets. Full details about the datasets can be found in Appendix~\ref{app:datasets}.

\subsection{Evaluation Metrics}
Throughout our work, we focus mainly on sentence-level evaluation. Our main lexical metric is spBLEU~\citep{goyal-etal-2022-flores},\footnote{We use spBLEU as implemented in \textsc{Sacrebleu}~\citep{post-2018-call}: \texttt{nrefs:1|case:mixed|eff:yes|tok:flores101|\\smooth:exp|version:2.3.1}.} as it has been widely employed in works on massively multilingual translation~\citep{fanetal2020_m2m, wenzek-etal-2021-findings, mohammadshahi-etal-2022-small, nllb2022} and offers fairer evaluation for low-resource languages compared to BLEU~\citep{papineni-etal-2002-bleu}. Moreover, we follow the most recent MT metrics shared-task recommendations~\citep{freitag-etal-2022-results} and also adopt neural metrics. We use the latest reference-based and reference-free COMET variants: COMET-22~\citep{rei-etal-2022-comet} and CometKiwi~\citep{rei-etal-2022-cometkiwi}. Lastly, we use the cross-lingual encoder LaBSE~\citep{feng-etal-2022-language} to obtain sentence similarity scores, as these have been successfully employed in prior research on detection of natural hallucinations~\citep{guerreiro-etal-2022-optimaltransport, dale-etal-2022-hallsalti}.

\section{Hallucinations under Perturbation}
\label{sec:halls_under_perturbation}
We start our analysis by focusing on artificially created hallucinations. We first provide an overview of our experimental setting, focusing on the construction of the perturbed data and detection approach. Then, we present our results and analyze the properties of these hallucinations across different resource levels and models.

\begin{table*}[t]
\centering
\renewcommand\arraystretch{0.9}
\footnotesize
\begin{tabular}{>{\arraybackslash}m{1.45cm} >{\arraybackslash}m{1.5cm} >{\arraybackslash}m{1.15cm} c >{\raggedleft\arraybackslash}m{1.75cm} >{\arraybackslash}m{1.15cm} c >{\arraybackslash}m{1.5cm} >{\arraybackslash}m{1.15cm}}
\toprule
\multirow{2}{*}{\textsc{Model}} & \multicolumn{2}{c}{\textbf{\textsc{Low Resource}}} & & \multicolumn{2}{c}{\textbf{\textsc{Mid Resource}}} & & \multicolumn{2}{c}{\textbf{\textsc{High Resource}}}\\\cmidrule{2-3}\cmidrule{5-6}\cmidrule{8-9}
& LP Fraction & Rate (\%) & & \multicolumn{1}{l}{{LP Fraction}} & Rate (\%) & & LP Fraction & Rate (\%)\\\midrule
\texttt{SMaLL100} & \begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (2*6/7*0.15, 0.15); 
 \draw [fill=tikz_gray] (2*6/7*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{2}}\textcolor{black!50}{/7}}; 
 \end{tikzpicture} & $0.213_{\textcolor{black!50}{\tiny{0.00}}}$ & &\begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (2*6/19*0.15, 0.15); 
 \draw [fill=tikz_gray] (2*6/19*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{2}}\textcolor{black!50}{/19}}; 
 \end{tikzpicture} & $0.009_{\textcolor{black!50}{\tiny{0.00}}}$ & &\begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (1*6/5*0.15, 0.15); 
 \draw [fill=tikz_gray] (1*6/5*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{1}}\textcolor{black!50}{/5}}; 
 \end{tikzpicture} & $0.017_{\textcolor{black!50}{\tiny{0.00}}}$ \\ \texttt{M2M (S)} & \begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (5*6/7*0.15, 0.15); 
 \draw [fill=tikz_gray] (5*6/7*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{5}}\textcolor{black!50}{/7}}; 
 \end{tikzpicture} & $0.261_{\textcolor{black!50}{\tiny{0.08}}}$ & &\begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (11*6/19*0.15, 0.15); 
 \draw [fill=tikz_gray] (11*6/19*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{11}}\textcolor{black!50}{/19}}; 
 \end{tikzpicture} & $0.140_{\textcolor{black!50}{\tiny{0.08}}}$ & &\begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (0*6/5*0.15, 0.15); 
 \draw [fill=tikz_gray] (0*6/5*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{0}}\textcolor{black!50}{/5}}; 
 \end{tikzpicture} & $0.000_{\textcolor{black!50}{\tiny{0.00}}}$ \\ \texttt{M2M (M)} & \begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (3*6/7*0.15, 0.15); 
 \draw [fill=tikz_gray] (3*6/7*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{3}}\textcolor{black!50}{/7}}; 
 \end{tikzpicture} & $0.083_{\textcolor{black!50}{\tiny{0.00}}}$ & &\begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (6*6/19*0.15, 0.15); 
 \draw [fill=tikz_gray] (6*6/19*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{6}}\textcolor{black!50}{/19}}; 
 \end{tikzpicture} & $0.035_{\textcolor{black!50}{\tiny{0.00}}}$ & &\begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (0*6/5*0.15, 0.15); 
 \draw [fill=tikz_gray] (0*6/5*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{0}}\textcolor{black!50}{/5}}; 
 \end{tikzpicture} & $0.000_{\textcolor{black!50}{\tiny{0.00}}}$ \\ \texttt{M2M (L)} & \begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (4*6/7*0.15, 0.15); 
 \draw [fill=tikz_gray] (4*6/7*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{4}}\textcolor{black!50}{/7}}; 
 \end{tikzpicture} & $0.296_{\textcolor{black!50}{\tiny{0.08}}}$ & &\begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (3*6/19*0.15, 0.15); 
 \draw [fill=tikz_gray] (3*6/19*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{3}}\textcolor{black!50}{/19}}; 
 \end{tikzpicture} & $0.017_{\textcolor{black!50}{\tiny{0.00}}}$ & &\begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (0*6/5*0.15, 0.15); 
 \draw [fill=tikz_gray] (0*6/5*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{0}}\textcolor{black!50}{/5}}; 
 \end{tikzpicture} & $0.000_{\textcolor{black!50}{\tiny{0.00}}}$ \\\cdashlinelr{1-9} \texttt{ChatGPT} & \begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (4*6/7*0.15, 0.15); 
 \draw [fill=tikz_gray] (4*6/7*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{4}}\textcolor{black!50}{/7}}; 
 \end{tikzpicture} & $0.059_{\textcolor{black!50}{\tiny{0.08}}}$ & &\begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (10*6/19*0.15, 0.15); 
 \draw [fill=tikz_gray] (10*6/19*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{10}}\textcolor{black!50}{/19}}; 
 \end{tikzpicture} & $0.183_{\textcolor{black!50}{\tiny{0.08}}}$ & &\begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (0*6/5*0.15, 0.15); 
 \draw [fill=tikz_gray] (0*6/5*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{0}}\textcolor{black!50}{/5}}; 
 \end{tikzpicture} & $0.000_{\textcolor{black!50}{\tiny{0.00}}}$ \\ \bottomrule
\end{tabular}
\caption{Fraction of languages for which models produces at least one hallucination under perturbation, and average hallucination rate (and median, in subscript) across all languages at each resource level.}
\label{tab:flores_halls_under_perturb_20}
\end{table*}

\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{figures/new_flores_hallucination_rate_heatmap_20_wo_tng.png}\vspace{-8pt} \caption{Heatmap of hallucination rates for each model in the languages considered. Pattern-filled cells indicate at least one hallucination under perturbation for a given model-language pair.}
    \label{fig:flores_halls_under_perturb_20}
\end{figure*}

\subsection{Evaluation Setting}
\label{subsec:halls_under_perturb_eval_setting}

\paragraph{Perturbations.} To construct the perturbed source sequences, we apply the same minimal perturbations used in \citet{xu-etal-2022-taclhalls}: misspeling of words, insertion of frequent tokens in the beginning of the source sequence, and capitalization errors. For full details on the construction of the perturbed data, refer to Appendix~\ref{app:data_for_halls_under_perturbation}.

\paragraph{Translation directions.} We use the \textsc{Flores} dataset for these experiments, and focus specifically on translation out of English. We selected all bridge languages\footnote{In the M2M paper~\citep{fanetal2020_m2m}, a bridge language is defined as a language that connects languages across language groupings (e.g., Romance, Slavic languages) and is mined against all other bridge languages. It is usually one of the most resourced languages within a language grouping and its purpose is to reduce the number of bitext pairs while preserving translation directions of practical interest.}, as well as additional low-resource languages that were underrepresented among bridge languages. Overall, we generate translations for 31 different language pairs~(LPs). We present the language pairs and more details on our choice of languages in Appendix~\ref{app:data_for_halls_under_perturbation}.



\paragraph{Detection.} Our detection approach is inspired by that of previous works on hallucinations under perturbation~\citep{Lee2018HallucinationsIN, raunak-etal-2021-curious, ferrando-etal-2022-towards, xu-etal-2022-taclhalls}. The algorithm is a simple 2-rule process: we fix (i)~a minimum threshold quality score for the original translations, and (ii)~an extremely low maximum quality score for the perturbed translations. A model generates a hallucination under perturbation when both translations meet the thresholds. Crucially, rule (i) ensures that low-quality translations for unperturbed sources are not considered as candidates for hallucinations under perturbation.\footnote{Note that low-quality translations for unperturbed sources fall under the scope of the study on natural hallucinations, that follows in subsequent sections of the paper.}

We extend this algorithm to handle multiple models and language pairs by adapting rule (i). We first obtain source sentences for which all models produce translations that meet a minimum quality threshold (spBLEU > 9). Then, we sort them according to average quality across the different models, and select the top 20\% as candidates. Finally, we apply rule (ii) and set the threshold to spBLEU < 3. We selected both thresholds based on the choices made in previous works~\citep{raunak-etal-2021-curious, ferrando-etal-2022-towards, xu-etal-2022-taclhalls}.

This approach ensures a fixed sample size across different language pairs, and that the sentences analyzed for each language pair are consistent across all models. Moreover, it allows us to effectively detect hallucinations under perturbation across multiple models in a multilingual scenario in a scalable manner, while accounting for the unique quality trends observed across different models and languages.\footnote{Note that detection of hallucinations under perturbation does not explicitly target detachment from the source text. We provide a broader discussion on the difference between this detection approach and that of natural hallucinations~(introduced later in Section~\ref{subsec:natural_halls_evalsetting}) in Appendix~\ref{app:supp_results_for_hall_under_perturbation}.}

\subsection{Results}

We show aggregated results in Table~\ref{tab:flores_halls_under_perturb_20} and language-specific results in Figure~\ref{fig:flores_halls_under_perturb_20}. Overall, they reveal that perturbations have the potential to trigger hallucinations under perturbation, even in larger models. In what follows, we highlight several noteworthy trends found in our results.

\paragraph{Average hallucination rates generally decrease with increasing resource levels.} Table~\ref{tab:flores_halls_under_perturb_20} shows that all models, with the exception of \texttt{ChatGPT} that we analyze separately below, exhibit lower hallucination rates as resource levels increase. This is expected and suggests that models are better equipped to handle source-side perturbations for language pairs with more parallel data during training. In fact, hallucinations under perturbation for high-resource languages are almost non-existent. However, Figure~\ref{fig:flores_halls_under_perturb_20} reveals variability across languages, and even within the models in the same family that have been trained on the same data. For instance, when translating to Asturian~(\texttt{ast}), \texttt{M2M~(L)} and its distilled version \texttt{SMaLL100} have significantly higher hallucination rates than the smaller \texttt{M2M~(S)}. Thus, hallucinations under perturbation may emerge in other non-trivial ways unrelated to the training data.

\paragraph{\texttt{SMaLL100} exhibits lower hallucination rates than its teacher model \texttt{M2M (L)}.}  Recall that \texttt{SMaLL100} was trained using uniform sampling across all language pairs to prevent bias towards higher resourced language pairs. The results in Table~\ref{tab:flores_halls_under_perturb_20} may reflect one positive outcome from such approach: despite being much smaller than~\texttt{M2M~(L)}, \texttt{SMaLL100} hallucinates less and for fewer languages than its teacher model for low- and mid-resource language pairs.

\paragraph{Hallucinations under perturbation are not correlated with the quality of original translations.} The common approach for detection of hallucinations under perturbation~(see Section~\ref{subsec:halls_under_perturb_eval_setting}) raises an interesting question: \emph{are the original source sentences for which models produce higher quality translations less likely to lead to hallucinations when perturbed?} Our analysis found a very weak correlation~(according to Pearson correlation; see Appendix~\ref{app:supp_results_for_hall_under_perturbation}) between hallucinations under perturbation and spBLEU scores for the original unperturbed sources across all models. This indicates that even minimal perturbations in the source text can cause models to undergo significant shifts in translation quality.

\paragraph{\texttt{ChatGPT} exhibits different hallucination patterns from conventional translation models.} Table~\ref{tab:flores_halls_under_perturb_20} shows that, contrary to traditional models, \texttt{ChatGPT} generates more hallucinations for mid-resource languages than for low-resource languages. In fact, it surprisingly produces fewer hallucinations for low-resource languages than any other model. Moreover, \texttt{ChatGPT}'s hallucinations are qualitatively different from those of other models: they often consist of off-target translations,\footnote{We perform automatic language identification using the \texttt{fasttext}~\citep{joulin2016fasttext} LID model \texttt{lid.176.bin}.} overgeneration, or even failed attempts to translate (e.g., \textit{“This is an English sentence, so there is no way to translate it to Vietnamese”}; we provide further examples in Appendix~\ref{app:supp_results_for_hall_under_perturbation}). Furthermore, unlike traditional NMT models that frequently produce oscillatory character hallucinations, \texttt{ChatGPT} does not generate any such hallucinations under perturbation. This is further evidence that translation errors, even severely critical ones, obtained via prompting a LLM are different from those produced by traditional machine translation models~\citep{vilaretal2023_palm, garciaetal2023_google, hendyetal2023_microsoftchatgpt, bawdenandyvon2023_bloom}.

Interestingly, we also found that the vast majority of the hallucinations can be reversed with further sampling from the model.\footnote{We also found this to be the case with a one-shot prompt.} This connects to findings in~\citet{guerreiro-etal-2022-lookingforaneedle, selfcheckgpt_2023}: as with traditional NMT models, hallucinations with a LLM may not necessarily indicate model defect or incapacity to generate adequate translations, and may just result from “bad luck” during generation.

\section{Natural Hallucinations}
\label{sec:natural_halls}

Let us now turn to investigating natural hallucinations.\footnote{From now on, we will use the terms natural hallucinations~--- both detached and oscillatory hallucinations --- and hallucinations interchangeably.} We first provide an in-depth overview of our evaluation setting, focusing on the scenarios and detection methodology. Subsequently, we present a thorough analysis, exploring diverse properties of natural hallucinations such as their different types, the influence of translation direction, and prevalence of toxicity.

\subsection{Evaluation Setting}
\label{subsec:natural_halls_evalsetting}
\paragraph{Evaluation scenarios.} Analyzing massively multilingual translation models opens up several research scenarios that have not been studied in previous works that focused solely on bilingual models. We will take advantage of this opportunity and investigate natural hallucinations in three different evaluation scenarios, studying more than 100 translation directions in the main text alone. 

We start with an English-centric scenario where we pair 32 different languages with English for a total of 64 translation directions. Then, we study a non-English-centric scenario inspired by~\citet{fanetal2020_m2m}, where we explore 25 language pairs corresponding to real-world use cases of translation not involving English (e.g., translating Greek directly to Turkish). Finally, we assess the prevalence of hallucinations on sensitive medical data where they can have a devastating impact on user trust. We pair 9 different languages with English for a total of 18 directions. We present all the translation directions investigated in these setups in Appendix~\ref{app:subsec_translation_directions}. We report results for the first two setups using the \textsc{Flores} dataset in the main text and WMT in Appendix~\ref{app:subsec:engcentric}. For the final setup, we use the medical-domain TICO dataset.

\paragraph{Detection.} We integrate key findings from recent research on detection of hallucinations and focus on two main detectors: ALTI+~\citep{ferrando-etal-2022-towards} for detached hallucinations, and top $n$-gram (TNG)~\citep{raunak-etal-2021-curious, salted_raunak2022, guerreiro-etal-2022-lookingforaneedle} for oscillatory hallucinations. 

ALTI+ evaluates the relative contributions of both source and target prefixes to model predictions. As hallucinations are translations detached from the source sequence, ALTI+ can effectively detect them by identifying sentences with minimal source contribution. Notably, it faithfully reflects model behavior and explicitly signals model detachment from the source text in any translation direction~\citep{ferrando-etal-2022-towards}. In previous works, this method has been successfully employed to detect hallucinated toxicity in a multilingual context in~\citet{nllb2022}, and it has been validated on human-annotated hallucinations in~\citet{dale-etal-2022-hallsalti}, where it was demonstrated that ALTI+ scores easily separate detached hallucinations from other translations.\footnote{We followed the recommendations in~\citet{guerreiro-etal-2022-lookingforaneedle} and set model-based ALTI+ thresholds based on validation data where the models are expected to perform well. Specifically, we obtained the lowest 0.02\% --- in line with natural hallucination rates reported in the literature~\citep{salted_raunak2022} --- of the ALTI+ score distributions for high-resource WMT benchmarks. Additionally, to ensure further trustworthy, high-precision measurements, we excluded detected candidates with LaBSE or CometKiwi scores --- as these have been also been validated for detection of human-annotated detached hallucinations~\citep{dale-etal-2022-hallsalti, guerreiro-etal-2022-optimaltransport} --- exceeding the top 10\% of scores on translations from the same WMT benchmarks.}

TNG, on the other hand, is a straightforward, lightweight black-box heuristic targeting oscillatory hallucinations. It works by comparing the count of the top repeated translation $n$-gram to the count of the top repeated source $n$-gram, ensuring the difference is at least $t$. This approach has been validated on human-annotated hallucinations and found to identify oscillatory hallucinations with perfect precision~\citep{guerreiro-etal-2022-lookingforaneedle}. We follow previous work by using $n=4$ and $t=2$~\citep{raunak-etal-2021-curious, guerreiro-etal-2022-lookingforaneedle} and excluding translations that meet the reasonable quality threshold outlined in Section~\ref{subsec:halls_under_perturb_eval_setting}.\footnote{Note that oscillatory hallucinations can be simultaneously detected with ALTI+ and TNG.}

\paragraph{Remark on Model Selection.} We rely on ALTI+, a model-based detector, for reliable detection of detached hallucinations. Since we lack access to glass-box internal features from \texttt{ChatGPT}, we exclude it from our model selection to ensure consistency in our analysis. It is important to note that using alternative detectors could lead to misleading results and create discrepancies between the evaluation scenarios for \texttt{ChatGPT} and other models. Nonetheless, we will further examine \texttt{ChatGPT} in Section~\ref{sec:mitigation}, exploring various aspects such as the generation of oscillatory hallucinations and translation quality in scenarios where other models produce hallucinations.

\begin{table*}[t]
\centering
\renewcommand\arraystretch{0.9}
\footnotesize
\begin{tabular}{>{\arraybackslash}m{1.45cm} >{\arraybackslash}m{1.75cm} >{\arraybackslash}m{1.15cm} c >{\raggedright\arraybackslash}m{1.75cm} >{\arraybackslash}m{1.15cm} c >{\arraybackslash}m{1.85cm} >{\arraybackslash}m{1.15cm}}
\toprule
\multirow{2}{*}{\textsc{Model}} & \multicolumn{2}{c}{\textbf{\textsc{Low Resource}}} & & \multicolumn{2}{c}{\textbf{\textsc{Mid Resource}}} & & \multicolumn{2}{c}{\textbf{\textsc{High Resource}}}\\\cmidrule{2-3}\cmidrule{5-6}\cmidrule{8-9}
& LP Fraction & Rate (\%) & & \multicolumn{1}{l}{{LP Fraction}} & Rate (\%) & & LP Fraction & Rate (\%)\\\midrule
\texttt{SMaLL100} & \begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (14*6/16*0.15, 0.15); 
 \draw [fill=tikz_gray] (14*6/16*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{14}}\textcolor{black!50}{/16}}; 
 \end{tikzpicture} & $2.352_{\,\textcolor{black!50}{\tiny{0.57}}}$ & &\begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (19*6/38*0.15, 0.15); 
 \draw [fill=tikz_gray] (19*6/38*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{19}}\textcolor{black!50}{/38}}; 
 \end{tikzpicture} & $0.055_{\,\textcolor{black!50}{\tiny{0.02}}}$ & &\begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (1*6/10*0.15, 0.15); 
 \draw [fill=tikz_gray] (1*6/10*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{1}}\textcolor{black!50}{/10}}; 
 \end{tikzpicture} & $0.005_{\,\textcolor{black!50}{\tiny{0.00}}}$ \\ \texttt{M2M (S)} & \begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (15*6/16*0.15, 0.15); 
 \draw [fill=tikz_gray] (15*6/16*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{15}}\textcolor{black!50}{/16}}; 
 \end{tikzpicture} & $15.20_{\,\textcolor{black!50}{\tiny{2.86}}}$ & &\begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (22*6/38*0.15, 0.15); 
 \draw [fill=tikz_gray] (22*6/38*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{22}}\textcolor{black!50}{/38}}; 
 \end{tikzpicture} & $0.254_{\,\textcolor{black!50}{\tiny{0.05}}}$ & &\begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (3*6/10*0.15, 0.15); 
 \draw [fill=tikz_gray] (3*6/10*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{3}}\textcolor{black!50}{/10}}; 
 \end{tikzpicture} & $0.025_{\,\textcolor{black!50}{\tiny{0.00}}}$ \\ \texttt{M2M (M)} & \begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (14*6/16*0.15, 0.15); 
 \draw [fill=tikz_gray] (14*6/16*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{14}}\textcolor{black!50}{/16}}; 
 \end{tikzpicture} & $12.53_{\,\textcolor{black!50}{\tiny{1.42}}}$ & &\begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (17*6/38*0.15, 0.15); 
 \draw [fill=tikz_gray] (17*6/38*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{17}}\textcolor{black!50}{/38}}; 
 \end{tikzpicture} & $0.110_{\,\textcolor{black!50}{\tiny{0.00}}}$ & &\begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (2*6/10*0.15, 0.15); 
 \draw [fill=tikz_gray] (2*6/10*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{2}}\textcolor{black!50}{/10}}; 
 \end{tikzpicture} & $0.010_{\,\textcolor{black!50}{\tiny{0.00}}}$ \\ \texttt{M2M (L)} & \begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (14*6/16*0.15, 0.15); 
 \draw [fill=tikz_gray] (14*6/16*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{14}}\textcolor{black!50}{/16}}; 
 \end{tikzpicture} & $11.22_{\,\textcolor{black!50}{\tiny{2.19}}}$ & &\begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (11*6/38*0.15, 0.15); 
 \draw [fill=tikz_gray] (11*6/38*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{11}}\textcolor{black!50}{/38}}; 
 \end{tikzpicture} & $0.034_{\,\textcolor{black!50}{\tiny{0.00}}}$ & &\begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (0*6/10*0.15, 0.15); 
 \draw [fill=tikz_gray] (0*6/10*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{0}}\textcolor{black!50}{/10}}; 
 \end{tikzpicture} & $0.000_{\,\textcolor{black!50}{\tiny{0.00}}}$ \\ \bottomrule
\end{tabular}
\caption{Fraction of LPs on the English-centric setup for which models produce at least one hallucination, and average hallucination rate (and median, in subscript) across all LPs at each resource level.}
\label{tab:flores_eng_centric}
\end{table*}

\begin{figure*}
\centering
\includegraphics[width=\textwidth]{figures/english_centric/tng_hall_rates.png}
\caption{Heatmap of the percentage of hallucinations detected with TNG (oscillatory hallucinations) among all hallucinations. Pattern-filled cells indicate at least one natural hallucination for a given model-LP combination.}
\label{fig:tng_rates_engcentric}  
\end{figure*}

\begin{table}[t]
\centering
\renewcommand\arraystretch{1}
\footnotesize
\begin{tabular}{>{\arraybackslash}m{1.35cm} >{\raggedleft\arraybackslash}m{1.5cm} >{\raggedleft\arraybackslash}m{1.5cm}}
\toprule
{\textsc{Model}} & {{\texttt{xx--en}}} & {{\texttt{en--xx}}}\\\midrule
\texttt{SMaLL100} & $0.221$ & $1.022$ \\ 
\texttt{M2M (S)} & $1.756$ & $6.152$ \\ 
\texttt{M2M (M)} & $2.290$ & $4.110$ \\ 
\texttt{M2M (L)} & $2.483$ & $3.169$ \\ \bottomrule
\end{tabular}
\caption{Average hallucination rates (\%) across all LPs at each direction (into or out of English).}
\label{tab:flores_halls_enxx_xxen}
\end{table}

\subsection{English-Centric Translation}
We start by investigating natural hallucinations on English-centric language pairs. We reveal key insights on how properties of hallucinations change across resource levels, models and translation directions. We present language-pair specific results in Appendix~\ref{app:subsec:engcentric}.

\label{subsec:analysis_eng_centric_flores}
\paragraph{Hallucinations in low-resource language pairs are not only more frequent, but also distinct.} Table~\ref{tab:flores_eng_centric} shows that hallucinations occur frequently for low-resource directions, with all M2M models exhibiting average hallucination rates exceeding 10\%. Furthermore, all models generate hallucinations for the vast majority of low-resource language pairs. On what comes to the type of hallucinations, Figure~\ref{fig:tng_rates_engcentric} demonstrates that, in contrast to mid- and high-resource language pairs, oscillatory hallucinations are less prevalent, while detached hallucinations occur more frequently in low-resource languages. This reveals that models tend to rely less on the source context when translating to or from low-resource languages. Importantly, although massive multilingual models have significantly improved translation quality for low-resource languages, these findings not only suggest that there is considerable room for improvement, but also highlight potential safety concerns arising from translations in these directions.

\begin{table*}[t]
\centering
\renewcommand\arraystretch{0.9}
\footnotesize
\begin{tabular}{>{\arraybackslash}m{1.45cm} >{\raggedleft\arraybackslash}m{1.75cm} >{\arraybackslash}m{1.15cm} c >{\raggedleft\arraybackslash}m{1.75cm} >{\arraybackslash}m{1.15cm} c >{\arraybackslash}m{1.6cm} >{\arraybackslash}m{1.15cm}}
\toprule
\multirow{2}{*}{\textsc{Model}} & \multicolumn{2}{c}{\textbf{\textsc{Low Resource}}} & & \multicolumn{2}{c}{\textbf{\textsc{Mid Resource}}} & & \multicolumn{2}{c}{\textbf{\textsc{High Resource}}}\\\cmidrule{2-3}\cmidrule{5-6}\cmidrule{8-9}
& \multicolumn{1}{l}{LP Fraction} & Rate (\%) & & \multicolumn{1}{l}{{LP Fraction}} & Rate (\%) & & LP Fraction & Rate (\%)\\\midrule
\texttt{SMaLL100} & \begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (5*6/10*0.15, 0.15); 
 \draw [fill=tikz_gray] (5*6/10*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{5}}\textcolor{black!50}{/10}}; 
 \end{tikzpicture} & $2.160_{\,\textcolor{black!50}{\tiny{0.02}}}$ & &\begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (6*6/13*0.15, 0.15); 
 \draw [fill=tikz_gray] (6*6/13*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{6}}\textcolor{black!50}{/13}}; 
 \end{tikzpicture} & $0.054_{\,\textcolor{black!50}{\tiny{0.00}}}$ & &\begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (1*6/2*0.15, 0.15); 
 \draw [fill=tikz_gray] (1*6/2*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{1}}\textcolor{black!50}{/2}}; 
 \end{tikzpicture} & $0.025_{\,\textcolor{black!50}{\tiny{0.02}}}$ \\ \texttt{M2M (S)} & \begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (10*6/10*0.15, 0.15); 
 \draw [fill=tikz_gray] (10*6/10*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{10}}\textcolor{black!50}{/10}}; 
 \end{tikzpicture} & $12.61_{\,\textcolor{black!50}{\tiny{1.79}}}$ & &\begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (12*6/13*0.15, 0.15); 
 \draw [fill=tikz_gray] (12*6/13*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{12}}\textcolor{black!50}{/13}}; 
 \end{tikzpicture} & $0.467_{\,\textcolor{black!50}{\tiny{0.05}}}$ & &\begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (1*6/2*0.15, 0.15); 
 \draw [fill=tikz_gray] (1*6/2*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{1}}\textcolor{black!50}{/2}}; 
 \end{tikzpicture} & $0.075_{\,\textcolor{black!50}{\tiny{0.07}}}$ \\ \texttt{M2M (M)} & \begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (7*6/10*0.15, 0.15); 
 \draw [fill=tikz_gray] (7*6/10*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{7}}\textcolor{black!50}{/10}}; 
 \end{tikzpicture} & $12.22_{\,\textcolor{black!50}{\tiny{2.41}}}$ & &\begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (7*6/13*0.15, 0.15); 
 \draw [fill=tikz_gray] (7*6/13*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{7}}\textcolor{black!50}{/13}}; 
 \end{tikzpicture} & $0.172_{\,\textcolor{black!50}{\tiny{0.05}}}$ & &\begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (0*6/2*0.15, 0.15); 
 \draw [fill=tikz_gray] (0*6/2*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{0}}\textcolor{black!50}{/2}}; 
 \end{tikzpicture} & $0.000_{\,\textcolor{black!50}{\tiny{0.00}}}$ \\ \texttt{M2M (L)} & \begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (6*6/10*0.15, 0.15); 
 \draw [fill=tikz_gray] (6*6/10*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{6}}\textcolor{black!50}{/10}}; 
 \end{tikzpicture} & $6.580_{\,\textcolor{black!50}{\tiny{2.02}}}$ & &\begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (4*6/13*0.15, 0.15); 
 \draw [fill=tikz_gray] (4*6/13*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{4}}\textcolor{black!50}{/13}}; 
 \end{tikzpicture} & $0.077_{\,\textcolor{black!50}{\tiny{0.00}}}$ & &\begin{tikzpicture}[font=\scriptsize] 
 % Draw the horizontal bar 
 \draw [fill=tikz_red] (0,0) rectangle (0*6/2*0.15, 0.15); 
 \draw [fill=tikz_gray] (0*6/2*0.15, 0) rectangle (6*0.15, 0.15); 
 % Add labels 
 \node [left, color=tikz_red] at (0, 0.1) {\textbf{\scriptsize{0}}\textcolor{black!50}{/2}}; 
 \end{tikzpicture} & $0.000_{\,\textcolor{black!50}{\tiny{0.00}}}$ \\ \bottomrule
\end{tabular}
\caption{Fraction of LPs on the non-English-centric setup for which models produce at least one hallucination, and average hallucination rate (and median, in subscript) across all LPs at each resource level.}
\label{tab:flores_noneng_centric}
\end{table*}

\paragraph{\texttt{SMaLL100} consistently relies more on the source text than other models.} Despite having the smallest number of parameters, \texttt{SMaLL100} shows remarkable hallucination rates across low- and mid-resource language pairs, hallucinating significantly less than its larger counterparts in low-resource settings. These improved rates may be attributed not only to the uniform sampling of language pairs during training, but also to architectural decisions. While \texttt{SMaLL100} shares a 12-layer encoder with the other models to process source representations, it diverges by employing a shallow 3-layer decoder---instead of a 12-layer decoder---and placing the target language code on the encoder side. We hypothesize that this design encourages greater reliance on the more complex encoder representations, reducing the likelihood of detachment from the source. In fact, distinct patterns in ALTI+ scores~(shown in Appendix~\ref{app:subsec:engcentric}) support this hypothesis:~\texttt{SMaLL100} consistently demonstrates higher source contributions and similar patterns across all resource levels. In contrast, M2M models show a greater tendency to rely less on the source, especially in low-resource language pairs. Importantly, however, \texttt{SMaLL100}'s reduced hallucination rates do not necessarily imply superior translation quality compared to the other M2M models: we observed a strong correlation between M2M models' corpus-level COMET-22 scores and their respective hallucination rates for low-resource languages, whereas, contrastingly, for \texttt{SMaLL100} the correlation is weak. This indicates that despite detaching less from the source content, \texttt{SMaLL100}'s translations are not necessarily of higher quality to those of other M2M models. This and other statistics can be found in the Appendix~\ref{app:subsec:engcentric}.

\paragraph{Scaling up models within the same model family leads to reduced hallucination rates.} As shown in Table~\ref{tab:flores_eng_centric}, increasing the size of the M2M family models results in consistent reductions in hallucination rates. Relative improvements are more pronounced for mid- and high-resource language pairs, with \texttt{M2M (L)} exhibiting fewer hallucinations and hallucinating for fewer languages than all other models.

\paragraph{Hallucinations are more frequent when translating out of English.} Table~\ref{tab:flores_halls_enxx_xxen} demonstrates that models are significantly more prone to hallucinate when translating out of English. In fact, in line with the observations of~\citet{ferrando-etal-2022-towards}, we found that models tend to detach more from the source text when translating out of English. This is evidenced by ALTI+ source contributions being lower across all language pairs in this direction compared to translating into English. Interestingly, we discovered that the translation direction can also influence the properties of hallucinations: (i) over 90\% of off-target hallucinations occur when translating out of English, and (ii) nearly all hallucinations into English for mid- and high-resource language pairs are oscillatory.

\begin{table*}[t]
\centering
\renewcommand\arraystretch{0.9}
\footnotesize
\begin{tabular}{>{\arraybackslash}m{1.45cm} >{\arraybackslash}m{1.25cm} >{\arraybackslash}m{1.25cm} c >{\arraybackslash}m{1.25cm} >{\arraybackslash}m{1.25cm} c >{\arraybackslash}m{1.25cm} >{\arraybackslash}m{1.25cm}}
\toprule
\multirow{2}{*}{\textsc{Model}} & \multicolumn{2}{c}{\textbf{\textsc{Low Resource}}} & & \multicolumn{2}{c}{\textbf{\textsc{Mid Resource}}} & & \multicolumn{2}{c}{\textbf{\textsc{High Resource}}}\\\cmidrule{2-3}\cmidrule{5-6}\cmidrule{8-9}
& \textsc{Flores} & TICO & & \textsc{Flores} & TICO & & \textsc{Flores} & TICO\\\midrule
\texttt{SMaLL100} & $0.448_{\,\textcolor{black!50}{\tiny{0.17}}}$ & $0.429_{\,\textcolor{black!50}{\tiny{0.29}}}$ & & $0.062_{\,\textcolor{black!50}{\tiny{0.02}}}$  & $0.083_{\,\textcolor{black!50}{\tiny{0.07}}}$ & & $0.008_{\,\textcolor{black!50}{\tiny{0.00}}}$ & $0.000_{\,\textcolor{black!50}{\tiny{0.00}}}$ \\ 
\texttt{M2M (S)} & $7.778_{\,\textcolor{black!50}{\tiny{3.48}}}$ & $6.262_{\,\textcolor{black!50}{\tiny{3.67}}}$ & & $0.087_{\,\textcolor{black!50}{\tiny{0.05}}}$ & $0.167_{\,\textcolor{black!50}{\tiny{0.17}}}$ & & $0.017_{\,\textcolor{black!50}{\tiny{0.00}}}$ & $0.024_{\,\textcolor{black!50}{\tiny{0.00}}}$ \\
\texttt{M2M (M)} & $3.484_{\,\textcolor{black!50}{\tiny{0.67}}}$ & $2.167_{\,\textcolor{black!50}{\tiny{0.33}}}$ & & $0.268_{\,\textcolor{black!50}{\tiny{0.05}}}$  & $0.363_{\,\textcolor{black!50}{\tiny{0.02}}}$ & & $0.008_{\,\textcolor{black!50}{\tiny{0.00}}}$ & $0.000_{\,\textcolor{black!50}{\tiny{0.00}}}$  \\
\texttt{M2M (L)} & $1.008_{\,\textcolor{black!50}{\tiny{0.37}}}$ & $0.596_{\,\textcolor{black!50}{\tiny{0.21}}}$ & & $0.031_{\,\textcolor{black!50}{\tiny{0.02}}}$ & $0.018_{\,\textcolor{black!50}{\tiny{0.00}}}$ & & $0.000_{\,\textcolor{black!50}{\tiny{0.00}}}$ & $0.000_{\,\textcolor{black!50}{\tiny{0.00}}}$  \\\bottomrule
\end{tabular}
\caption{Comparison between average hallucination rate (and median, in subscript) for the same LPs at each resource level for \textsc{Flores} and TICO medical data.}
\label{tab:specialized_domain_compare}
\end{table*}

\paragraph{Toxic hallucinations pose substantial safety risks.} Toxic text in translations can emerge in the form of hallucinations~\citep{nllb2022}. To assess the prevalence of toxic text in detected hallucinations, we utilized the toxicity wordlists provided by~\citet{nllb2022}. We found that toxic text primarily appears in translations out of English and almost exclusively affects low-resource language pairs. For instance, over 1 in 8 hallucinations in Tamil contain toxic text. Interestingly, these toxic hallucinations not only exhibit high lexical overlap among them, but are repeated across models for multiple unique source sentences. Moreover, they are not necessarily reduced by scaling up the model size. These observations suggest that these hallucinations are likely to be traced back to toxic patterns in the training data,\footnote{Upon inspecting the Common Crawl corpora that were used to create the training data, we found reference translations that exactly match the toxic hallucinations.} aligning with observations in~\citet{raunak-etal-2021-curious, guerreiro-etal-2022-lookingforaneedle}. Moreover, we also found that these hallucinations can be propagated through model distillation, as evidenced by \texttt{SMaLL100} generating toxic hallucinations that are copies of those of its teacher model. This underlines the necessity of rigorously filtering training data to ensure safe and responsible use of these models in real-world applications. 

\subsection{Beyond English-Centric Translation}
We shift our focus to translation directions that do not involve English, typically corresponding to directions with less supervision during training. We present language-pair specific results in Appendix~\ref{app:subsec:nonengcentric}.

\paragraph{Trends are largely similar to English-centric directions.} Table~\ref{tab:flores_noneng_centric} reveals trends that largely mirror those observed in the English-centric setup:\footnote{Comparing absolute hallucination rates between the two setups is not advised, as they involve different translation directions, which may render such comparisons unreliable.}~(i)~hallucinations are more frequent in low-resource settings; (ii)~\texttt{SMaLL100} significantly outperforms the M2M models in low-resource language pairs; and (iii)~scaling up to \texttt{M2M~(L)} consistently yields substantial improvements over the smaller M2M models in low- and mid-resource directions. Additionally, the trends related to hallucination types also hold across the two setups: detached hallucinations are more prevalent in low-resource settings, while oscillatory hallucinations overwhelmingly dominate in mid- and high-resource directions~(see Appendix~\ref{app:subsec:nonengcentric}).

\paragraph{Less supervised language pairs exhibit extremely high hallucination rates.} As expected, models struggle more with hallucinations for directions with less or even no supervision during training, such as \texttt{ro-hy} and \texttt{af-zu}. For instance, \texttt{M2M (M)} hallucinates for nearly half of the translations in these directions. 


\subsection{Translation on Specialized Domains}
We now turn to investigating hallucinations in data from the medical domain, where they can have devastating consequences. Using the TICO dataset, we compare hallucination rates with the \textsc{Flores} dataset for 18 translation directions. We present language-pair specific results in Appendix~\ref{app:subsec:specialized_domain}.

\paragraph{Hallucinations are not exacerbated under medical domain data.} Table~\ref{tab:specialized_domain_compare} reveals that hallucination rates for the TICO medical data do not consistently exceed those observed for the \textsc{Flores} Wikipedia data. This finding diverges from previous works that investigated hallucinations for specialized domain data~\citep{wang-sennrich-2020-exposure, muller-etal-2020-domain}. We hypothesize that, in contrast with the smaller models typically trained on limited datasets from a single domain used in those works, the concept of "domain shift" may not be as pronounced for M2M models. These models are not only much larger but, crucially, they are trained on a dataset containing over 7 billion parallel sentences gathered from the web, which encompasses a broad array of domains. This massive training set potentially mitigates the impact of domain shift and, consequently, reduces its influence on hallucinations.

\section{Mitigation of Hallucinations through Fallback Systems}
\label{sec:mitigation}

Building upon our analysis on natural hallucinations in the previous section, we now explore the potential of reducing hallucinations and enhancing overall translation quality by employing a simple hybrid setup that can take advantage of multiple systems with possible complementary strengths. Put simply, we leverage an alternative system as a fallback when the primary original model produces hallucinations. Our analysis in the main text is focused on the more extensive English-centric setup. We provide results on the non-English-centric setup in Appendix~\ref{app:fallbacksystemanalysis}.


\subsection{Employing models of the same family as fallback systems}

We begin by analyzing the performance of same-family models when employed as fallback systems for one another (e.g., using \texttt{SMaLL100}, \texttt{M2M (M)}, and \texttt{M2M~(L)} as fallbacks for \texttt{M2M~(S)}).\footnote{For simplicity, we consider the distilled \texttt{SMaLL100} as a model from the M2M family.}

\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{figures/fallback/engcentric_reversal.png}
    \caption{Reversal rates for oscillatory (\texttt{Osc.}) and detached (\texttt{Det.}) hallucinations when using models of the same family as fallback systems.}
    \label{fig:engcentric_reversal}
\end{figure}

\begin{figure*}[t]
\begin{subfigure}[b]{0.495\textwidth}
\centering
\includegraphics[scale=0.645]{figures/fallback/engcentric_resource_level_comet22_w_nllb.png}
\caption{Translation quality.}
\label{fig:flores_engcentric_fallback_quality}
\end{subfigure} \quad 
\begin{subfigure}[b]{0.495\textwidth}
\centering
\includegraphics[scale=0.555]{figures/fallback/engcentric_tng_w_nllb.png}
\caption{Prevalence of oscillatory hallucinations.}
\label{fig:flores_engcentric_fallback_oscillatory}
\end{subfigure}
\caption{Fallback system analysis recurring to models of different families, such as \texttt{ChatGPT} and \texttt{NLLB}. We analyse overall translation quality improvements on the original model hallucinated translations~(represented with dashed lines) across different resource levels via COMET-22 scores in~(a), and overall prevalence of oscillatory hallucinations among the fallback translations in~(b).}
\label{fig:flores_engcentric_reversal_quality_osc}
\end{figure*}

\paragraph{Detached hallucinations are particularly \textit{sticky} across M2M models.}
Figure~\ref{fig:engcentric_reversal} reveals that when employing M2M models as fallback systems, reversal rates---percentage of hallucinations from the original system that are corrected by the fallback system---are consistently higher for oscillatory hallucinations than for detached hallucinations. These findings not only corroborate those in~\citet{guerreiro-etal-2022-lookingforaneedle}, where oscillatory hallucinations were found to be less related to model defects, but also further emphasize the close connection between detached hallucinations and training data. This connection can help explain their \textit{stickiness}: since the M2M models share the same training data, reversing these hallucinations using other same-family models as fallbacks is more challenging. Interestingly, we also observe that \texttt{M2M (L)} particularly struggles to reverse the detached hallucinations generated by its distilled counterpart \texttt{SMaLL100}, suggesting that model defects can persist and be shared during distillation.

\paragraph{Scaling up within the model family is not an effective strategy for mitigating hallucinations.} In line with our analysis in Section~\ref{subsec:analysis_eng_centric_flores}, Figure~\ref{fig:engcentric_reversal} shows that reversal rates using \texttt{SMaLL100} as a fallback system are higher for detached hallucinations than for oscillatory hallucinations. In fact, although \texttt{SMaLL100} is a distilled M2M model, its training data, training procedure, and architecture differ from those of the M2M models. This distinction may make it more complementary as a fallback system to other M2M models than simply scaling up within the same model family. This suggests that merely increasing the scale of models within the same family is not an effective strategy for mitigating hallucinations, and exploring alternative models with different architectures and trained on different data could yield more substantial improvements. In the next section, we will analyze this alternative strategy.

\subsection{Employing external models as fallback systems}

Motivated by the findings from the previous section, we will now study how models that are not from the M2M family can be employed to further mitigate hallucinations and improve translation quality. We will test this approach with two different models: (i)~we will prompt \texttt{ChatGPT} as detailed in Section~\ref{sec:experimental_suite}, and (ii)~we will use a high-quality 3.3B parameter model from the NLLB family of multilingual NMT models~(\texttt{NLLB}) proposed in~\citet{nllb2022}.

\paragraph{Translation quality can be significantly improved with external fallback systems.} Figure~\ref{fig:flores_engcentric_fallback_quality} demonstrates that external fallback systems, particularly \texttt{NLLB}, can significantly enhance translation quality of originally hallucinated translations compared to same-family models.\footnote{For reference, in the English-centric setup, the averaged COMET-22 corpus-level scores for low-, mid-, and high-resource LPs obtained with \texttt{M2M(L)} are $73.63$, $86.54$, and $87.19$, respectively. We provide fallback system quality scores for all language pairs in Appendix~\ref{app:fallbacksystemanalysis}.} This improvement is especially notable for low-resource languages, where both \texttt{ChatGPT} and \texttt{NLLB} consistently boost translation quality. Remarkably, \texttt{NLLB} generally outperforms \texttt{ChatGPT} as a fallback system for low- and mid-resource languages, aligning with the findings in~\citet{hendyetal2023_microsoftchatgpt}, which revealed that GPT models have limited capabilities for lower-resourced languages and lag behind dedicated translation models in those settings. Nonetheless, \texttt{ChatGPT} still surpasses dedicated M2M translation systems in these resource levels when used as a fallback system, underscoring the limitations of relying on same-family models as fallback systems. 

\paragraph{Oscillatory hallucinations are practically non-existent when \texttt{ChatGPT} is the fallback system.} From Figure~\ref{fig:flores_engcentric_fallback_oscillatory}, we see another benefit of employing external fallback systems: oscillatory hallucinations are almost entirely eliminated. Interestingly, consistent with our findings in Section~\ref{sec:halls_under_perturbation}, we observe that \texttt{ChatGPT} produces very few, if any, oscillations, slightly improving the rates obtained with \texttt{NLLB}. This provides further evidence that, although hallucinations obtained via prompting LLMs may still occur, they exhibit different properties and surface forms. Investigating and understanding these differences in hallucination properties presents an interesting research path for future work.


\section{Conclusion}
\label{sec:conclusions}
We have comprehensively investigated the phenomenon of hallucinations in massively multilingual translation models. By departing from the settings studied in previous work that focused on bilingual models trained on high-resource language pairs, we were able to explore a wide range of research scenarios that remained overlooked. 

Our analysis revealed several key insights on the prevalence and properties of hallucinations across various models of different scale, translation directions, and data conditions, including: the prevalence of hallucinations across multiple translation directions across different resource levels and beyond English-centric translation; the emergence of toxicity in hallucinations; and the effect of scaling up within the same model family on the prevalence of hallucinations. Additionally, we explored how fallback systems can mitigate hallucinations and improve overall translation quality. We found that hallucinations can be \textit{sticky} and difficult to reverse when using models that share the same training data and architecture. However, by leveraging other external models, we can significantly improve translation performance and virtually eliminate pathologies such as oscillatory hallucinations.

To support future research on this topic, we are open-sourcing our code and releasing over a million translations and detection results across several models and language pairs.

% Here, we highlight three relevant trends that emerged from our investigation. First, we found that massively multilingual translation models predominantly struggle with hallucinations in low-resource language pairs, where models are more prone to detach from the source text. Critically, we found that, for these translation directions, hallucinations can emerge as severely compromising toxic text. Second, we discovered that smaller distilled models can mitigate hallucinations by incorporating modeling choices that discourage them. For instance, using less potent shallow decoders that rely more on the source content and mitigating bias towards higher-resource language pairs through uniform sampling of translation directions during distillation. Third, we found that ChatGPT produces hallucinations that are qualitatively different from those of conventional translation models, mostly consisting of off-target translations or even failed attempts to translate.

\section*{Limitations}
Our study mainly focuses on the M2M family of multilingual models. We chose this family of models as it includes several models at different sizes and the largest open-source multilingual NMT model. It is unclear how our findings generalize to other families of multilingual models~(e.g., the NLLB family of models).

Our detection approaches inherit the limitations that carry over with the metrics that are leveraged in them. For instance, following all of previous work, we adopt a BLEU metric to detect hallucinations under perturbation. However, this and other lexical metrics ranked worst than reference-based neural metrics in last year's WMT22 Metrics Shared Task~\citep{freitag-etal-2022-results}. 

We analyzed \texttt{ChatGPT} as it has demonstrated impressive capabilities for translation and other multilingual tasks, such as MT evaluation. Unfortunately, the model remains behind API walls and documentation is scarce. As such, we could not ensure that \texttt{ChatGPT} was not trained on our evaluation sets, nor could we evaluate the contribution of the source text to \texttt{ChatGPT}'s translations, which would have enabled detection of detached hallucinations. Despite these limitations, we believe our findings provide relevant insights into the properties of translations generated by the model.

\section*{Acknowledgments}
We would like to thank Meta AI for open-sourcing the M2M models and maintaining libraries such as \texttt{stopes}~\citep{andrews-etal-2022-stopes} and \texttt{nllb}~\citep{nllb2022}. The work is partially supported by the European Research Council (ERC StG DeepSPIN 758969), by EU’s Horizon Europe Research and Innovation Actions (UTTER, contract 101070631), by the FCT through contract UIDB/50008/2020, and by the projects MAIA and NextGenAI (LISBOA-01-0247-FEDER-045909 and 2022-C05i0102-02). Part of this work was performed using HPC resources from GENCI-IDRIS (Grant 2022- AD01101838).

\newpage

\bibliography{tacl2021, new_anthology, custom}
\bibliographystyle{acl_natbib}

\onecolumn
\appendix 
\input{appendix}
\end{document}
