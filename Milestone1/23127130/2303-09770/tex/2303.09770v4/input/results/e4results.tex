\subsection{Experiment 4: Iterative GDL Classification}
\label{exp4r}

Even if with perfect classification, the approach outlined so far would only result in determining the top 50\% performing graphs in $\mathcal{G}_{all}$.
While this outcome can undoubtedly be useful in practice, it is generally desirable to narrow down the graphs further to the best-performing.
However, there is no reason we only need to construct a single classification model.

In this experiment, we seek a smaller, better median performance set of graphs from $\mathcal{G}_{all}$ by iteratively constructing GDL models with these steps:
\begin{enumerate}[nolistsep]

% \setcounter{enumi}{-1}

\item Set $k=1$ and create an initial $\mathcal{G}^{k}_{known}$. % (here 20\% of $\mathcal{G}_{all}$) and 

\item Create a GDL model $m^k(G_i)$ using $\mathcal{G}^{k}_{known}$, which is naturally broken into sets ``Known 1'' and ``Known 0'' based on the median $J$ value of $\mathcal{G}^{k}_{known}$.

\item Predict the classes of the $\mathcal{G}^{k}_{unknown}$ using $m^k(G_i)$, creating ``Predicted 1'' and ``Predicted 0'', which are sets of graphs predicted to be good (1) or bad (0), respectively. % , at this iteration

\item The goal is to identify good graphs, so we set $\mathcal{G}^{k+1}_{known}$ equal to ``Known 1'' and $\mathcal{G}^{k+1}_{unknown}$ equal to ``Predicted 1'' (and the remaining graphs are removed under the assumption that they are bad).

\item Set $k \rightarrow k + 1$ and repeat Step 2 until $k = n$.
    
\end{enumerate}

\noindent At each iteration, the size of $\mathcal{G}^{k}_{known}$ will be halved in a way that decreases its median performance value, so the good/bad classification threshold of $m^k(G_i)$ should shift as well.

The results of this experiment initialized with 20\% of the data known are summarized in \fref{fig:iterations}.
First, the leftmost box plot shows the distribution of $J(\mathcal{G}_{all})$.
The next two box plots show the splitting of $\mathcal{G}_{known}$ based on the classification threshold at iteration 1.
The final two box plots in iteration 1 are the predicted 1s and 0s based on the GDL model; note that, while there are certainly incorrectly identified graphs, the medians are quite separated and consistent with their ``Known'' counterparts.
The subsequent box plots show the results for each iteration, up to $n=5$.
We observe at iteration 5, with $N_{known} = $ 540 graphs now, the classification is quite poor as the ``Predicted'' box plots are similarly distributed. 
The trend lines for the two medians also convey this point, with substantial decreases until the fifth iteration.
This behavior is perhaps expected because we are not adding any new data from the initial $\mathcal{G}^1_{known}$, and the number of graphs for training decreases.
Adding more data at each iteration based on ``Predicted 1'' is future work.

Assessing the outcome at the end of iteration 4 (since the fifth did not classify well), there are a total of 2,920 graphs in the final ``good'' set with a median of $3 \times 10^{-4}$, substantially lower than the initial classification median of $2 \times 10^{-1}$.
Here we assume a designer would evaluate $J(G_i)$ for all the graphs in ``Predicted 1''; thus, there would be a total of 11,029 graphs that were optimized. 
For this final set, \textit{all} of the top 10, 87 of the top 100, and 727 of the top 1000 graphs still remain at 25\% the computational cost of complete enumeration.
Furthermore, compared to randomly sampling 11,029 graphs from $\mathcal{G}_{all}$, the iterative GDL model results greatly exceed the expected means of 2.25, 22.51, and 225.13 for the top 10, 100, and 1000 graphs being included in the random set, respectively.

To better understand the statistical significance of this iterative approach, five more randomized runs were completed with different samplings of $\mathcal{G}^1_{known}$. % (total of six runs).
Over these runs, the average graphs that would be known or ``optimized'' was 11282.2 graphs (with a 492.8 standard deviation).
For the top 100 graphs, 88.2 (2.5) remained compared to an expected value of 22.96.
Finally, for the top 1000 graphs, 751.2 (39.5) remained compared to an expected value of 229.6.
Furthermore, the median values of the ``Known 1'' and ``Predicted 1'' graph sets for each iteration are shown in Fig.~\ref{fig:iterations-stats} averaged over the six runs.
Here we still see a decrease in the median values indicating the iterative GDL approach is narrowing down the set of potentially ``good'' graphs to the higher percentiles of performance. In fact, at iteration 4, all medians for ``Predicted 1'' are better than the 90th percentile, with the mean closer to the 95th.
However, as previously discussed in Fig.~\ref{fig:iterations}, the benefits from the 5th iteration are minimal.

As indicated in Fig.~\ref{fig:accvar}, there are expected trade-offs when attempting to reduce computational costs by decreasing the required evaluations of $J(G_i)$ and GDL tasks.
Therefore, an additional study was conducted only reducing the starting $\mathcal{G}^{1}_{known}$. % the number of known graphs ($\mathcal{G}_{known}$). % using the same approach outlined above
Initialized with only $10\%$ of $\mathcal{G}_{all}$, the iterative approach now concluded with 8118.2 (969.1) graphs on average needing to be optimized per Eq.~(\ref{eq:cir-opt}). %  being 8118.2. % (with a standard deviation of 969.12).
Summarizing the results of five random runs, 9.2 (0.4) of the top 10 graphs remained, 85.2 (6.3) of the top 100 graphs remained, and 715.2 (76.9) of the 1000 graphs remained.
Another difference between the different starting $\mathcal{G}_{known}$ sizes (i.e., $20\%$ vs.~$10\%$) is total iterative GDL classification cost, including training the various GDL models at each iteration. % the time it took to train the models.
The difference here is 45 vs. 36 minutes between 20\% vs.~10\% $\mathcal{G}^{1}_{known}$, respectively.
% The $20\%$ model took approximately 45 minutes, while the $10\%$ model took approximately 36 minutes.
Since both summarized top graph outcomes are comparatively similar, additional investigations into using fewer graphs for $\mathcal{G}^{1}_{known}$ are critical to understanding trade-offs related to the total computational costs of the design study to meet different designer goals.
