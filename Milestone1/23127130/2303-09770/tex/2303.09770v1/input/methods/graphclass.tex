\subsection{Graph Classification}
\label{gclass}

\begin{figure}[t]
\centering
\includegraphics[scale=0.95]{input/figures/graphclass.pdf}
\caption{Illustration of graph classification based on performance values.}
\label{fig:graphclass}
\end{figure}

\textit{Graph classification} refers to classifying graphs based on selected labels.
Here, we consider \textit{supervised} graph classification, where we have a collection of graphs $\mathcal{G}$, each with its label $J(G_i)$, used to train a model using additional graph properties, such as the structure, embeddings, and node data.
These features help the model discriminate between the graphs, improving the prediction of the labels.
An illustration of graph classification is shown in \fref{fig:graphclass}.
Here, the median performance value might be used as the determination point to divide our graphs into binary classes representing ``good'' graphs in the lower half of the observed performance values and ``bad'' graphs in the upper half. 


There are various methods of graph classification, including Deep Graph Convolutional Neural Networks (DGCNN) \cite{b2}, hidden layer representation that encodes the graph structure and node features \cite{b8}, EigenPooling \cite{b12}, and differentiable pooling \cite{b81}.
It has been used in many different studies, such as learning molecular fingerprints \cite{b80}, text categorization \cite{b98}, encrypted traffic analysis \cite{b99}, and cancer research \cite{b100}.

\subsection{Datasets}
\label{sec:datasets}

Based on the Type 1 problem classification considered here from \sref{enumeration}, we will consider the case when only some of the performance values $J(G_i)$ for $G_i \subset \mathcal{G}$ are known.
This will divide the graphs into two sets as follows:
\begin{align}
\mathcal{G} \equiv \mathcal{G}_{all} = \mathcal{G}_{known} \cup \mathcal{G}_{unknown}
\end{align}

\noindent where $\mathcal{G}_{known}$  is the set of graphs with known values for $J(G_i)$ and $\mathcal{G}_{unknown}$ represents graphs with unknown $J(G_i)$ values (and this is what the GDL model is for).
We will denote the sizes of the sets as $|\mathcal{G}_{all}| = N_{all}$, $|\mathcal{G}_{known}| = N_{known}$, and $|\mathcal{G}_{unknown}| = N_{unknown}$. They also satisfy:
\begin{align}\label{eq:N}
N_{all} = N_{known} + N_{unknown}
\end{align}

\noindent We also note that this is a bit different than other types of datasets used in machine learning as there is a known, finite amount of potential inputs.
The goal here is to develop accurate models where $N_{known} \ll N_{unknown}$.

As is typical in machine learning, we will create two subsets from $\mathcal{G}_{known}$ :
\begin{align}
\mathcal{G}_{known} = \mathcal{G}_{training} \cup \mathcal{G}_{validation}
\end{align}

\noindent where $\mathcal{G}_{training}$ is the training dataset and $\mathcal{G}_{validation}$ is the validation dataset.
The model fits using $\mathcal{G}_{training}$, and the fitted model is used to predict the responses for the observations in $\mathcal{G}_{validation}$ \cite{b46}. 
For example, after each iteration, the model will adjust its weights accordingly and test them on the validation set, which can help understand model performance and adjust options as necessary. 
The unknown set is used when the model is finalized, and you want to now test it on data that the model has not seen.


\begin{figure}[t]
\centering
\includegraphics[scale=0.95]{input/figures/set_distinction.pdf}
\caption{Illustration of $\mathcal{G}_{all}$ and $\mathcal{G}_{known}$ for 100 graphs, the performance-based classification of $\mathcal{G}_{known}$, and the potential difference between the medians.}
\label{perc}
\end{figure}

As shown in \fref{fig:graphclass}, the binary classification of graphs in $\mathcal{G}_{known}$  is based on the median performance value (or potentially some other dividing line using the known data).
Since we only know $J(G_i)$ in $\mathcal{G}_{known}$  rather than $\mathcal{G}_{all}$, the median performance value used for the initial labeling might be different than the true value if we had all the performance values for $\mathcal{G}_{all}$.
However, as the relative size of $\mathcal{G}_{known}$  increases, this error will become small.
The concepts in this section are illustrated in \fref{perc}.
Here we have 100 graphs in $\mathcal{G}_{all}$ and 20 randomly selected graphs for $\mathcal{G}_{known}$.
The true median and $\mathcal{G}_{known}$-based median do differ, and two graphs are between these lines. 

