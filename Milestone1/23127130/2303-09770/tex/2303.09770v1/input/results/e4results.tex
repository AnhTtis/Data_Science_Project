

\subsection{Experiment 4: Iterative GDL Classification}
\label{exp4r}



Even if with perfect classification, the approach outlined so far would only result in determining the top 50\% performing graphs in $\mathcal{G}_{all}$.
While this outcome can undoubtedly be useful in practice, it is generally desirable to narrow down the graphs further to the best-performing.
However, there is no reason we only need to construct a single classification model.

In this experiment, we seek a smaller, better median performance set of graphs from $\mathcal{G}_{all}$ by iteratively constructing GDL models with these steps:
\begin{enumerate}[nolistsep]



\item Set $k=1$ and create an initial $\mathcal{G}^{k}_{known}$. 

\item Create a GDL model $m^k(G_i)$ using $\mathcal{G}^{k}_{known}$, which is naturally broken into sets ``Known 1'' and ``Known 0'' based on the median $J$ value of $\mathcal{G}^{k}_{known}$.

\item Predict the classes of the $\mathcal{G}^{k}_{unknown}$ using $m^k(G_i)$, creating ``Predicted 1'' and ``Predicted 0'', which are sets of graphs predicted to be good (1) or bad (0), respectively. % , at this iteration

\item The goal is to identify good graphs, so we set $\mathcal{G}^{k+1}_{known}$ equal to ``Known 1'' and $\mathcal{G}^{k+1}_{unknown}$ equal to ``Predicted 1'' (and the remaining graphs are removed under the assumption that they are bad).

\item Set $k \rightarrow k + 1$ and repeat Step 2 until $k = n$.
    
\end{enumerate}

\noindent At each iteration, the size of $\mathcal{G}^{k}_{known}$ will be halved in a way that decreases its median performance value, so the good/bad classification threshold of $m^k(G_i)$ should shift as well.

The results of this experiment initialized with 20\% of the data known are summarized in \fref{fig:iterations}.
First, the leftmost box plot shows the distribution of $J(\mathcal{G}_{all})$.
The next two box plots show the splitting of $\mathcal{G}_{known}$ based on the classification threshold at iteration 1.
The final two box plots in iteration 1 are the predicted 1s and 0s based on the GDL model; note that, while there are certainly incorrectly identified graphs, the medians are quite separated and consistent with their ``Known'' counterparts.
The subsequent box plots show the results for each iteration, up to $n=5$.
We observe at iteration 5, with $N_{known} = $ 540 graphs now, the classification is quite poor as the ``Predicted'' box plots are similarly distributed. 
The trend lines for the two medians also convey this point, with substantial decreases until the fifth iteration.
This behavior is perhaps expected because we are not adding any new data from the initial $\mathcal{G}^1_{known}$, and the number of graphs for training decreases.
Adding more data at each iteration based on ``Predicted 1'' is future work.

Assessing the outcome at the end of iteration 4 (since the fifth did not classify well), there are a total of 2,920 graphs in the final ``good'' set with a median of $3 \times 10^{-4}$, substantially lower than the initial classification median of $2 \times 10^{-1}$.
Here we assume a designer would evaluate $J(G_i)$ for all the graphs in ``Predicted 1''; thus, there would be a total of 11,030 graphs that were optimized. 
For this final set, \textit{all} of the top 10 and 87 of the top 100 graphs still remain at 25\% the computational cost of complete enumeration.
Furthermore, compared to randomly sampling 11,030 graphs from $\mathcal{G}_{all}$, the iterative GDL model results greatly exceed the expected means of 2.25 and 22.52 for the top 10 and 100 graphs being included in the random set, respectively.
