\subsection{Graph Neural Networks} %working title
\label{gnn}
Similar to traditional deep learning models that use Convolutional Neural Networks (CNNs), GDL utilizes GNNs, which are used to learn representations of graph-structured data, such as social networks, molecules, and computer programs. 
GNNs are very similar to CNNs in that they can extract localized features and compose them to construct representations \cite{b43}. 
As previously mentioned, the critical difference between the two is that GNNs can learn on non-euclidean data and handle data that is not evenly structured, like images or text. 
Lastly, GNNs can learn from data that is not labeled, known as unsupervised learning. 
This is important because many real-world datasets are not labeled.

Training a GNN for graph classification (i.e., determining if a graph has a characteristic or not) is relatively simple, and there is typically a three-step process that needs to occur: 1) embed each node by performing multiple rounds of message passing, 2) aggregate node embeddings into a unified graph embedding, and then 3) train a final classifier on the graph embedding.
We take a closer look at how this occurs in \sref{model}, where we discuss each layer of the GNN used here.