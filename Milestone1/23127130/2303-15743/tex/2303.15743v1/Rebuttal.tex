\documentclass[10pt,twocolumn,letterpaper]{article}
\usepackage[rebuttal]{cvpr}

% Include other packages here, before hyperref.
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{color}


% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref,breaklinks,colorlinks,bookmarks=false]{hyperref}

% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}



% If you wish to avoid re-using figure, table, and equation numbers from
% the main paper, please uncomment the following and change the numbers
% appropriately.
%\setcounter{figure}{2}
%\setcounter{table}{1}
%\setcounter{equation}{2}

% If you wish to avoid re-using reference numbers from the main paper,
% please uncomment the following and change the counter for `enumiv' to
% the number of references you have in the main paper (here, 6).
%\let\oldthebibliography=\thebibliography
%\let\oldendthebibliography=\endthebibliography
%\renewenvironment{thebibliography}[1]{%
%     \oldthebibliography{#1}%
%     \setcounter{enumiv}{6}%
%}{\oldendthebibliography}


%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\cvprPaperID{7985} % *** Enter the CVPR Paper ID here
\def\confName{CVPR}
\def\confYear{2023}


\input{mycommands.tex}
\renewcommand{\paragraph}[1]{{\vspace{0.2em}\noindent \textbf{#1} -- }}
\definecolor{razzmatazz}{rgb}{0.89, 0.15, 0.42}
\definecolor{officegreen}{rgb}{0.0, 0.5, 0.0}
\definecolor{frenchblue}{rgb}{0.0, 0.45, 0.73}
\newcommand\RvwA[0]{{\color{razzmatazz}R1}}
\newcommand\RvwB[0]{{\color{frenchblue}R2}}
\newcommand\RvwC[0]{{\color{officegreen}R3}}
\newcommand\hj[1]{{\bf\color{orange}[HJ: #1]}}
\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{Rebuttal for Paper `HS-Pose'(\#7985)}  % **** Enter the paper title here

\maketitle
\thispagestyle{empty}
\appendix

%%%%%%%%% BODY TEXT - ENTER YOUR RESPONSE BELOW
%%%%%%%%% appreciation %%%%%%%%%%%%%%
We appreciate the constructive feedback from the reviewers, \textbf{6mn6} (\textbf{\RvwA}), \textbf{c6UE} (\textbf{\RvwB}), and \textbf{We9e} (\textbf{\RvwC}). We value their opinion that our proposed method is novel (\textbf{\RvwC}), interesting (\textbf{\RvwC}), brings significant performance boosts, outperforms other SOTAs (\textbf{\RvwA},\textbf{\RvwB},\textbf{\RvwC}) and runs in real-time (\textbf{\RvwC}). We are glad that they found that our work carefully checked the challenges and conquer them one by one (\textbf{\RvwB}), and the effectiveness of our designs were verified by a thorough ablation study (\textbf{\RvwA},\textbf{\RvwB},\textbf{\RvwC}). Moreover, we appreciate that they found our work beneficial to the community: the HS-layer is general and can be used in other methods (\textbf{\RvwC}); our work can potentially draw more attention to the network architecture design (\textbf{\RvwB}). Below, we address all questions raised.

\vspace{1.1mm}
\noindent\textbf{[\RvwA] The method builds on GPV-Pose. The novelty of the three designs in the proposed HS-layer is limited.}
% 
GPV-Pose is a well-designed SOTA method, but there is still much room for improvement. In our work, we carefully analyzed the structure of GPV-Pose and found critical problems which limit its performance such as the loss of the translation and scale information during the feature extraction, only using local geometric structure, and the sensitivity to noise. Our three designs (contributions) carefully address the problems one by one while avoiding making the network complex. Moreover, HS-layer is a general network and is not GPV-Pose dependent. Therefore, we keep the minimum modification of the GPV-Pose to demonstrate the effectiveness of the proposed designs. According to the ablation studies, the HS-layer works as intended; each design addresses the target problem and brings big influences.



\noindent\textbf{[\RvwA] Does the gain from STE actually come from the encoding of scale and translation? How STE helps relative translation estimation?} 
%
Yes. The geometric extraction path cannot utilize translation and scale information since it removes the 3D points' coordinates and uses normalization to achieve geometric structures. The linear layer is the ONLY path to get translation and scale information. We set the input point cloud's mean position as the origin of the coordinate frame. Therefore, the coordinates received by STE provide information on the relative translation and the scale. Scale encoding is also essential since an object's size influences the relative translation.
%Consequently, the encoding of translation and scale helps the relative translation estimation. 
% In the ablation study, STE boosts the performance of the translation and scale while retaining the performance in rotation, which demonstrates its contribution. 
Will make this clearer. 
% in the final paper.


\noindent\textbf{[\RvwB] STE: Why add a linear layer to the geometric extraction, and why elementwise summation, not concatenation or attention?}
%
The geometric structural information has been shown to be essential in rotation estimation~\cite{FSNET_2021_CVPR_reb} while invariant to translation and scale. Therefore, we retain the geometric path and supplement the translation and scale information by parallelly connecting a linear layer.
% The combination of two paths can be either elementwise summation, concatenation, or attention. 
We choose elementwise summation, which requires fewer computational resources than concatenation and attention, to keep the network light and fast.
%and as fast as possible. 
% Elementwise summation requires fewer computational resources than concatenation and attention. Therefore, we choose it to keep the network lightweight and as fast as possible.
Will add more details.
% In the ablation study [AS-1], the significant performance boost on translation and scale demonstrates the effectiveness of our design choice. We will add more details.
% in the camera-ready.

\noindent\textbf{[\RvwB] Improvement on CAMERA25 (\textbf{CA}) is less significant than REAL275 (\textbf{RE}).} 
%
\textbf{CA} is a synthetic dataset that contains no noise, while \textbf{RE} is a real-world collected dataset that contains complex noise.
One advantage of our method versus the other SOTAs is the robustness to noise, which is not reflected on \textbf{CA}. 
% One key contribution of our method is the robustness to noise, which is not reflected when testing on \textbf{CA}. 
The performance difference between our method and the other SOTAs is expected to be larger when noise is present, which matches the observed results in the \textbf{CA} and \textbf{RE}. 
%The differences in the evaluation results show that ours can better handle noisy real-world scenarios.
We will include a clear discussion.
%It is worth noting that the performance on \textbf{RE} better reflects the ability to handle challenging realistic scenarios compared with \textbf{CA}. The significant performance boost of our method on \textbf{RE} demonstrates that our method is more capable of real-world applications. Even though the performance improvement on the \textbf{CA} is not as significant as on the \textbf{CA}, the proposed method gained specific improvements over its baseline and ranked first and second compared to SOTAs on all the metrics without the need for prior information. We will include a clear discussion.
% on this in the final version.



\noindent\textbf{[\RvwB] In 3.4 RF-F, the author shouldn't claim that the feature-based neighbors searching (FNS) is unique since DGCNN (Siggraph,2019) already explored it}.
%
We respectively disagree. We emphasized that forming receptive fields with feature distances to capture global geometric relationships is novel, and we have not claimed that FNS is unique. The proposed RF-F is different from DGCNN. DGCNN uses FNS to form the graph in the \textit{feature space} to capture global feature relationships. RF-F finds the 3D points with the shortest feature distances to form a graph in the \textit{3D space} and captures global geometric relationships. 


\noindent\textbf{[\RvwB] Should also test on instance-level datasets}.
%
% Thanks for the suggestion. 
Since our target setting is category-level, we chose to test on the widely adopted category-level datasets and did not test on instance-level datasets. Due to the time limit, we cannot provide the results on the recommended datasets now. However, we would try to include them in the supplementary. 

\noindent\textbf{[\RvwC] The neighbor number for RF-F and ORL: how is it chosen? How does it affect the performance?}
%
% To ensure a fair comparison between the proposed RF-F and the RF-P used in GPV-Pose, we keep the neighbor number the same. We set the neighbor number of the ORL to a similar number as the RF-F. For the neighbor number of RF-F, insufficient or excessive neighbor numbers would affect the performance as it will impact the representativeness of the learned geometric structure. For ORL, insufficient impacts the perceptiveness of the reliable points, and excessive neighbors also impact the noise robustness since it increases the possibility of including outliers. We will add more details in the final supplementary.
To ensure a fair comparison between the proposed RF-F and the RF-P used in GPV-Pose, we keep the neighbor number the same. We set the neighbor number of the ORL to a similar number as the RF-F. Insufficient or excessive neighbors would affect the performance of RF-F and ORL. Thanks for pointing out and we will add more details in the final supplementary.


\noindent\textbf{[\RvwC] Can the translation and size be directly regressed from the extracted features?}
%
Yes, they can.
% We believe they can be regressed directly.
%, and we are also interested in trying this in the future. 
However, in this work, we minimally change the GPV-Pose's structure to rigorously demonstrate the proposed designs' influences.

\noindent\textbf{[\RvwA] L466-469: If $\neighbor^M_p(\point_n)$ is the $M$ nearest neighbors, why do outliers have fewer neighbors than reliable points?}
%
We apologise for the misleading statement. The neighbor number is the same for all the points. When formulating the receptive field with point distance, the reliable points are more likely to be presented in other points' receptive fields compared with outliers since reliable points have a shorter distance between each other. We will revise this.

\noindent\textbf{[\RvwA, \RvwC] Ambiguities: } Thanks for pointing out. \textbf{Noise in [AS-6] and Fig.~6.} $\rightarrow$ The noise level refers to the outlier ratio. \textbf{Eq.~(4) in L361} $\rightarrow$ the first $\feature_n$ should be the output of the geometric extraction path. We will revise all clearly.


% \vspace{-0.8em}
{\scriptsize
\renewcommand{\section}[2]{}% remove title
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}
% %%%%%%%%% REFERENCES
% {\small
% \bibliographystyle{ieee_fullname}
% \bibliography{egbib}
% }

\end{document}
