% This part is too long. Need to be shortened.

\section{Related Works} \label{sec: related_works}
\textbf{Instance-level object pose estimation}
Instance-level object pose estimation estimates the pose of known objects with the 3D CAD model provided. Existing methods usually achieve the pose using end-to-end regression \cite{SSD_6D_ICCV_2017, CosyPose_ECCV_2020, DeepIM_IJCV_Version_Li_2020}, template matching \cite{Temp6D_CVPR_22, OSOP_2022_CVPR, OVE6D_2022_CVPR}, or 2D-3D correspondence-matching~\cite{Tremblay_2018_Bbox_Corners, OneShot_2d3d_2022_CVPR, Epro-PnP_2022_CVPR, SurfEmb_2022_CVPR, SLAM6D_2022_CVPR, PVN3D_CVPR_2019}. End-to-end regression-based methods estimate object pose directly from the visual observations and have a high inference speed. Template matching methods recover the object pose by comparing the visual observation and usually exhibit robustness to textureless objects. \cite{Hinterstoisser_2016_PPF, Vidal_matching_PPF_2018} use the 3D models as templates, which achieve high accuracy but suffer from low matching speed. In recent years, latent feature-based template matching methods \cite{AAE_perspective, MP-Encoder_CVPR_2020, zheng2022TPAE, PoseRBPF} have achieved real-time performance and have gained popularity. 2D-3D correspondence matching-based methods \cite{ZebraPose_2022_CVPR, DPOD_2019_ICCV} first estimate the 2D-3D correspondences and then retrieve the objects' pose by PnP methods. They show outstanding results for textured objects. The correspondences can be sparse bounding box corners \cite{BB8_Rad_2017_ICCV, SSS_6D_2018_CVPR}, or distinguishable points on the object's surface \cite{Pix2Pose_2019_ICCV, CDPN, PVNet}. While the aforementioned methods have shown impressive capabilities in estimating object pose, their applicability is limited to a few objects and usually needs the corresponding CAD models.
% Even though the methods mentioned above exhibit impressive performance on object pose estimation, they can only deal with a single object or a handful of objects and require the objects' CAD models. 
% The limited amount of target objects in the CAD library restricts their usage in applications for daily life.

\textbf{Category-level object pose estimation}
Category-level methods estimate the pose of unseen objects within specific categories~\cite{DualPoseNet_2021_ICCV, ShaPO_ECCV_2022, CPSpp_2020, category_level_2}.
% Sahin et al.~\cite{category_level_2} propose an intrinsic structure adaptor for handling distribution shifts and shape variation. 
NOCS~\cite{NOCS_2019_CVPR} suggests mapping the input shape to a normalized canonical space (NOCS) and retrieving the pose by point matching. \cite{ShaPO_ECCV_2022, CASS_2020_CVPR, UDA-COPE_2022_CVPR} enhance NOCS using a shape prior \cite{Tian_ShapePrior_2020_ECCV}, mapping the shape to a metric scale space \cite{CASS_2020_CVPR}, or domain adaptation \cite{UDA-COPE_2022_CVPR}. \cite{SGPA_2021_ICCV, Self-DPDN_ECCV_2022} leverage structural similarity between the shape prior and the observed object. 
%CPS++ proposes metric shape retrieval with the synthetic-to-real domain transfer. 
TransNet~\cite{TransNet_ECCV_2022} extends the targets to transparent objects. However, they show limited speed and are unsuitable for real-time applications. CATRE~\cite{liu_2022_catre} explored real-time pose refinement for pose estimation. FS-Net~\cite{FSNET_2021_CVPR} explored local geometric relationships using 3D-GC~\cite{3dgcn_lin_CVPR_2020}, which shows robustness to rotation estimation and runs in real-time. \cite{GPV-Pose_2022_CVPR, SAR-Net_Lin_2022_CVPR, SSP-Pose_IROS_22, RBP-Pose_ECCV_2022} inherit the utilization of 3D-GC and enhance the pose estimation performance in different ways. SAR-Net~\cite{SAR-Net_Lin_2022_CVPR} proposes shape alignment and symmetry-aware shape reconstruction. GPV-Pose~\cite{GPV-Pose_2022_CVPR} presents geometric-pose consistency terms and point-wise bounding box (Bbox) voting. \cite{SSP-Pose_IROS_22, RBP-Pose_ECCV_2022} further enhance \cite{GPV-Pose_2022_CVPR} by shape deformation~\cite{SSP-Pose_IROS_22} and residual Bbox voting~\cite{RBP-Pose_ECCV_2022}. Nonetheless, they only look at local geometric relationships and are limited in handling more complex shapes. 
