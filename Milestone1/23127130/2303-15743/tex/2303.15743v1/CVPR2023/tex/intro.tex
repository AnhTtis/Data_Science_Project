\section{Introduction}
% {\color{red} TODOs: 1) Decide whether to use 20 neighbors' results.; 2) Add the neighbor number ablation descriptions; 3)check the language and shorten the intro and related work; 4)check the length. 5) Clean the code.}
\input{CVPR2023/fig/teaser/item.tex}
Accurate and efficient estimation of an object's pose and size is crucial for many real-world applications~\cite{BundleTrack_IROS_2021}, including robotic manipulation~\cite{autonomous_driving_application_2017}, augmented reality~\cite{augmented_reality_application_2021}, and autonomous driving, among others. In these applications, it is essential that pose estimation algorithms can handle the diverse range of objects encountered in daily life.
While many existing works~\cite{Uni6d_2022_CVPR, Epro-PnP_2022_CVPR, ES6D_2022_CVPR, RNNPose_2022_CVPR} have demonstrated impressive performance in estimating an object's pose, they typically focus on only a limited set of objects with known shapes and textures, aided by CAD models. In contrast, category-level object pose estimation algorithms~\cite{category_level_2, CAPTRA_2021, 6D_pack_2020_ICRA, DualPoseNet_2021_ICCV, GPV-Pose_2022_CVPR} address all objects within a given category and enable pose estimation of unseen objects during inference without the target objects' CAD models, which is more suitable for daily-life applications. However, developing such algorithms is more challenging due to the shape and texture diversity within each category. 


In recent years, category-level object pose estimation research~\cite{FSNET_2021_CVPR, RBP-Pose_ECCV_2022, SSP-Pose_IROS_22} has advanced rapidly by adopting state-of-the-art deep learning methods. \cite{NOCS_2019_CVPR, CASS_2020_CVPR} gain the ability to generalize by mapping the input shape to normalized or metric-scale canonical spaces and then recovering the objects' poses via correspondence matching. Better handling of intra-category shape variation is also achieved by leveraging shape priors~\cite{Tian_ShapePrior_2020_ECCV, SGPA_2021_ICCV, SSP-Pose_IROS_22}, symmetry priors~\cite{SAR-Net_Lin_2022_CVPR}, or domain adaptation~\cite{UDA-COPE_2022_CVPR, Self-DPDN_ECCV_2022}. Additionally, \cite{FSNET_2021_CVPR} enhances the perceptiveness of local geometry, and~\cite{GPV-Pose_2022_CVPR, RBP-Pose_ECCV_2022} exploit geometric consistency terms to improve the performance further. 

Despite the remarkable progress of existing methods, there is still room for improvement in the performance of the category-level object pose estimation. Reconstruction and matching-based methods~\cite{NOCS_2019_CVPR, Tian_ShapePrior_2020_ECCV, UDA-COPE_2022_CVPR} are usually limited in speed due to the time-consuming correspondence-matching procedure. Recently, various methods~\cite{FSNET_2021_CVPR, SAR-Net_Lin_2022_CVPR, GPV-Pose_2022_CVPR, SSP-Pose_IROS_22, RBP-Pose_ECCV_2022} built on 3D graph convolution (3D-GC)~\cite{3dgcn_lin_CVPR_2020} have achieved impressive performance and run in real-time. They show outstanding local geometric sensitivity and the ability to generalize to unseen objects. However, only looking at small local regions impedes their ability to leverage the global geometric relationships that are essential for handling complex geometric shapes and makes them vulnerable to outliers. In addition, the scale and translation invariant nature of 3D-GC restrict the perception of object size and translation information.

To overcome the limitations of 3D-GC in category-level object pose estimation, we propose the hybrid scope latent feature extraction layer (HS-layer), which can perceive both local and global geometric relationships and has a better awareness of translation and scale. Moreover, the proposed HS-layer is highly robust to outliers. To demonstrate the effectiveness of the HS-layer, we replace the 3D-GC layers in GPV-Pose~\cite{GPV-Pose_2022_CVPR} to construct a new category-level object pose estimation framework, HS-pose. This framework significantly outperforms the state-of-the-art method and runs in real time. Our approach extends the perception of 3D-GC to incorporate other essential information by using two parallel paths for information extraction. The first path encodes size and translation information (STE), which is missing in 3D-GC due to its invariance property. The second path extracts outlier-robust geometric features using the receptive field with the feature distance metric (RF-F) and the outlier-robust feature extraction layer (ORL).


The main contribution of this paper is as follows:
\vspace{-2mm}
\begin{itemize}
    \item We propose a network architecture, the hybrid scope latent feature extraction layer (HS-layer), that can simultaneously perceive local and global geometric structure, encode translation and scale information, and extract outlier-robust feature information. Our proposed HS-layer balances all these critical aspects necessary for category-level pose estimation. 
    \vspace{-2mm} 
    \item We use the HS-layer to develop a category-level pose estimation framework, HS-Pose, based on GPV-Pose. The HS-Pose, when compared to its parent framework, has an advantage in handling complex geometric shapes, capturing object size and translation while being robust to noise.
    \vspace{-2mm}
    \item We conduct extensive experiments and show that the proposed method can handle complex shapes and outperforms the state-of-the-art methods by a large margin while running in real-time (50FPS).                                
\end{itemize}
\vspace{-1mm}