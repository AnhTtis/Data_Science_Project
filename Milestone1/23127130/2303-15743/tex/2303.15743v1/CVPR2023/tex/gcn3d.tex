\section{Background: 3D Graph Convolution}\label{sec:3dgc}
Since the proposed method is strongly related to 3D graph convolution (3D-GC), we briefly review its implementation here.
%
3D graph convolution (3D-GC), as proposed in \cite{3dgcn_lin_CVPR_2020}, is a neural network structure designed to extract local geometric features from unordered point cloud data. Since distinguishing deterministic geometric features is usually needed to recover an object's pose from various shapes, 3D-GC has recently gained popularity in the category-level object pose estimation domain \cite{FSNET_2021_CVPR, GPV-Pose_2022_CVPR, SSP-Pose_IROS_22, SAR-Net_Lin_2022_CVPR, RBP-Pose_ECCV_2022}. 

The input to 3D-GC is the point cloud and the features associated with the points $\{(\point_n\in\realR^3, \feature_n \in \realR^{D_\text{in}})\}_{n=1}^N$. The output of 3D-GC is the point cloud with their extracted features $\{(\point_n\in\realR^3,\feature_n \in \realR^{D_\text{out}})\}_{n=1}^N$, possibly with a different feature dimension.

The core unit of 3D-GC is a deformable kernel that generalizes the convolution kernel used in 2D image processing to deal with unstructured point cloud data. In particular, a 3D-GC kernel $K^S$ is defined as:
\begin{equation}
    K^S = \{(\kernelPoint_C, \weight_C), (\kernelPoint_1, \weight_1), \dots, (\kernelPoint_S, \weight_S)\},
\end{equation}
where $S$ is the total number of support vectors, $\kernelPoint_C=[0, 0, 0]^T$ is the central kernel point, $\{\kernelPoint_s\in \realR^3\}_{s=1}^N$ are the support kernel vectors and ${\weight}$ is the weight associated with each kernel vector. The 3D-GC kernel performs a convolution on the receptive field $R^M(\point_i)$, which is the point along with its neighbors and their associated features $\feature$:
\begin{equation}
    \label{eq:receptive_field}
    R^M(\point_i) = \{(\point_i, \feature_i), (\point_m, \feature_m) | \point_m \in \neighbor^M(\point_i)\}.
\end{equation}
Here $\neighbor^M(\point_i)$ is the set of the $M$ nearest neighbor points of $\point_i$. In particular, in \cite{3dgcn_lin_CVPR_2020} the receptive field with point distance metric (RF-P) is used for finding which of the nearest neighbors is within the point distance metric:
\begin{equation}
  \distance_p(\point_i, \point_j) = \norm{\point_i - \point_j}.
\end{equation}

% In particular, $\neighbor^M(\point_i)$ is defined as a set of points that satisfies:
% \begin{align*}
%     &\neighbor^M(\point_i) \subseteq \pointCloud,
%     |\neighbor^M(\point_i)| = M \text{ and } \\
%     &\text{for all } \point_n \in \pointCloud \setminus \neighbor^M(\point_i), \text{ we have} \\
%     &\distance(\point_i, \point_n) \geq \max_{\point_m \in \neighbor^M(\point_i)} \distance(\point_i, \point_m)  
% \end{align*}
% where $|\cdot|$ measures the cardinal number of a set, and $\distance(\cdot, \cdot)$ is a valid distance metric. 

% %It should be noticed that the number of support kernel points $S$ and the number of neighbors in the receptive field $M$ could be different, and both of them are hyperparameters that can be tuned.

The convolution between the receptive field $R^M(\point_i)$ and the 3D-GC kernel $K^S$ is defined as:
\begin{equation}
    \convolution(R^M(\point_i), K^S) = \feature_i^T\weight_C + 
    \sum_{s=1}^{S} \max_{\point_m \in \neighbor^M(\point_i)} \similarity(\point_m, \kernelPoint_s),
    \label{eq:gc}
\end{equation}
% \begin{equation}
% \begin{aligned}
%     \convolution(R^M(\point_i), K^S) = &\feature_i^T\weight_C \\ &+ 
%     \sum_{s=1}^{S} \max_{\point_m \in \neighbor^M(\point_i)} \similarity(\point_m, \kernelPoint_s)
%     \label{eq:gc}
% \end{aligned}
% \end{equation}
where $\similarity(\point_m, \kernelPoint_s)$ measures the similarity between the neighbor point $\point_m$ and the kernel support vector $\kernelPoint_s$:
\begin{equation}
    \similarity(\point_m, \kernelPoint_s) =
    \feature_m^T\weight_s \frac{(\point_m - \point_i)^T\kernelPoint_s}{\norm{\point_m - \point_i}\norm{\kernelPoint_s}}
    \label{eq:sim}.
\end{equation}
% For the first layer of graph convolution where the points the do not have corresponding features, $\feature_n$ and the $\weight$ for kernel are set to $1$.

It should be noted that 3D-GC has a size and translation invariance due to the normalization in Eq.~\ref{eq:sim}. A brief inner structure of the 3D-GC layer is shown in Fig.~\ref{fig:gcn3d}. For more details, the readers can refer to the original work \cite{3dgcn_lin_CVPR_2020}. 
\input{CVPR2023/fig/3dgcn_structure/item.tex}
% With the 3D-GC kernel and receptive field, the 3D-GC Convolution layer and 3D Graph max pooling can be constructed to form the 3D-GC network (3D-GCN) \cite{3dgcn_lin_CVPR_2020}, which has shown superior local geometric perception and brought impressive performance improvement in category-level object pose estimation tasks \cite{FSNET_2021_CVPR, GPV-Pose_2022_CVPR, RBP-Pose_ECCV_2022}. However, 
% It should be noticed that the scale and translation invariance of 3D-GC conflicts with category-level pose estimation tasks, which are required to estimate the object's translation and size. Also, looking only at the local regions makes 3D-GC unable to perceive the global geometric structural relationships and, consequently, is sensitive to noise as well as showing a limited ability to handle complex shapes. In this work, we will show how simple modifications of the 3D-GC net can significantly improve the three problems mentioned above.

