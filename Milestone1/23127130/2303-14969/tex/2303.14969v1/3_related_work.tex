\cutparagraphup
\section{Related Work}
\cutparagraphup

To the best of our knowledge, the problem of universal few-shot learning of dense prediction tasks remains unexplored.
Existing few-shot learning approaches for dense prediction are targeted to specific tasks that require learning unseen \emph{classes} of objects, such as semantic segmentation~\citep{shaban2017one, wang2019panet, iqbal2022msanet}, instance segmentation~\citep{michaelis2018one, fan2020fgn}, and object detection~\citep{fan2020few, wang2020frustratingly}, rather than general tasks.
As categorical labels are discrete in nature, most of the methods involve per-class average pooling of support image features, which cannot be generalized to regression tasks as there would be infinitely many "classes" of continuous labels.
Others utilize masked correlation between support and query features~\citep{min2021hypercorrelation, hong2022cost}, learn a Gaussian Process on features~\citep{johnander2021dense}, or train a classifier weight prediction model~\citep{kang2019few}.
In principle, these architectures can be extended to more general dense prediction tasks with slight modification~(Section~\ref{sec:experiment}), yet their generalizability to unseen dense prediction tasks, rather than classes, has not been explored.

\vspace{-0.05cm}
As our method involves task-specific tuning of a small portion of parameters, it is related to transfer learning that aims to efficiently fine-tune a pre-trained model to downstream tasks.
In natural language processing (NLP), language models pre-trained on large-scale corpus~\citep{kenton2019bert, brown2020language} show outstanding performance on downstream tasks with fine-tuning a minimal amount of parameters~\citep{houlsby2019parameter, zaken2022bitfit, lester2021power}.
Following the emergence of pre-trained Vision Transformers~\citep{dosovitskiy2020image}, similar adaptation approaches have been proven successful in the vision domain~\citep{li2021benchmarking, jia2022visual, chen2022vision}.
While these approaches reduce the amount of \emph{parameters} required for state-of-the-art performance on downstream tasks, they still require a large amount of \emph{labeled images} for fine-tuning (\emph{e.g.}, thousands).
In this context, our method can be seen as a few-shot extension of the adaptation methods, by incorporating a general few-shot learning framework and a powerful architecture.