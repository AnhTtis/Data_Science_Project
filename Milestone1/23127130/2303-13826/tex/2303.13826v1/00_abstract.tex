\begin{abstract}
% Abstract goes here.
Zero-shot quantization (ZSQ) is promising for compressing and accelerating deep neural networks when the data for training full-precision models are inaccessible. In ZSQ, network quantization is performed using synthetic samples, thus, the performance of quantized models depends heavily on the quality of synthetic samples. Nonetheless, we find that the synthetic samples constructed in existing ZSQ methods can be easily fitted by models. Accordingly, quantized models obtained by these methods suffer from significant performance degradation on hard samples.
To address this issue, we propose \textbf{HA}rd sample \textbf{S}ynthesizing and \textbf{T}raining (HAST). Specifically, HAST pays more attention to hard samples when synthesizing samples and makes synthetic samples hard to fit when training quantized models.
HAST aligns features extracted by full-precision and quantized models to ensure the similarity between features extracted by these two models. Extensive experiments show that HAST significantly outperforms existing ZSQ methods, achieving performance comparable to models that are quantized with real data.

%Quantization  when the training data is achievable. Nonetheless, training data can be inaccessible due to privacy issues, facilitating the development of zero-shot quantization (ZSQ). In ZSQ, models are quantitated using synthesized data.

%To reduce the performance drop, most existing methods require training data to fine-tune the quantized model. However, in many real-world scenarios, training data may not be available due to privacy and security issues, rendering these methods not applicable. Zero-shot quantization (ZSQ) handles such problems, usually by leveraging a full-precision model to synthesize data and guide fine-tuning of the quantized model. In this paper, we find that quantized model suffers from significant generalization issues due to 1) the use of synthetic samples well classified, and 2) learning generalization knowledge insufficiently, resulting in performance degradation. We propose \textbf{H}ard \textbf{S}ample \textbf{S}ynthesizing and \textbf{L}earning (HSSL) scheme to address these issues in the following way: HSSL i) dynamically suppresses the optimization of well-classified samples and adds adversarial perturbation to increase the learning difficulty of synthetic samples, and ii) transfers attention knowledge with generalization ability as a supplement to soft labels. Our HSSL is demonstrated to well mimic real data in terms of difficulty and transfer generalization ability better. Experiments show that HSSL outperforms the performance of many existing methods by a great margin, especially at ultra-low precision settings.
\end{abstract}