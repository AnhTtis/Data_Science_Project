\section{Conclusion}
\label{sec:conclusion}
\par In this paper, we investigate the state-of-the-art solutions based on noise optimization for zero-shot quantization and demonstrate that the synthetic samples are easy for the quantized model to fit, which harms the performance of the quantized model on real test data. Thus, hard samples matter a lot for zero-shot quantization. We achieve the goal by not only paying more attention to generating hard samples but also making samples harder to fit during fine-tuning. Feature alignment is applied in the fine-tuning process to help the quantized model learn hard samples better. Our method can achieve comparable performance with those fine-tuned using real data.