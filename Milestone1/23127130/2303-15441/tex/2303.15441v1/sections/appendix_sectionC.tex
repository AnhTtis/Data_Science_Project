% Details of using other optimization appraoches (e.g., linear approximation
\section{Ablation of the Adversarial Optimization Method}
When there are multiple attributes (i.e., $N>1$) to optimize, linearizing the cost function as grid in high dimensional space will help to efficiently approximate convergence in limited epochs. Specifically, we have the option to adopt PGD \cite{madry2018towards} (i.e., update using $\eta \cdot\operatorname{sign} (\nabla_{\mathbf{w}} \mathcal{L})$) for efficient optimization. We compared generating counterfactuals with and without  projected gradients. Table~\ref{tab:appendix_pgd} shows the visual quality and flip rate of the generated counterfactuals. We can observe that \ourmodel-PGD image quality is finer under Structured Similarity Indexing Method (SSIM) \cite{SSIM}, while \ourmodel-SGD has a higher flip rate. The images from \ourmodel-PGD is finer since the signed method stabilizes the optimization by eliminating problems of gradient vanishing and exploding. 

 \begin{table}[h]
   \small
   \centering
   \begin{tabular}{@{}llcc@{}}
     \toprule
    \multicolumn{1}{c}{Optimization} & Classifier &  SSIM ($\uparrow$) & Flip Rate (\%, $\uparrow$)\\
     \midrule
     \multicolumn{1}{c}{\multirow{3}{*}{SGD}} & Perceived Age & 0.5732 & 67.24  \\
                                              & Perceived Gender & 0.5815 & 49.40 \\
                                              & Mustache & 0.5971 & 36.33 \\
                        \midrule
     \multicolumn{1}{c}{\multirow{3}{*}{PGD}} & Perceived Age & 0.8065 & 50.19\\
                                              & Perceived Gender & 0.7035 & 42.84 \\
                                              & Mustache & 0.7613 & 25.10 \\
     \bottomrule
   \end{tabular}
   %\end{adjustbox}
   \caption{The comparison of counterfactuals generated with stochastic gradient descent (SGD) and projected gradient descent (PGD) method. We can observe that \ourmodel-PGD image quality is finer under SSIM (Structured Similarity Indexing Method) \cite{SSIM} metrics, while \ourmodel-SGD has a higher flip rate. }
   \label{tab:appendix_pgd}
\end{table}

Our empirical observation during the experiment is that \ourmodel-PGD frequently oscillates around a local minima of edit weights and fails to reach an optimal counterfactual. We hypothesize that the reason of lower flip rates from the signed method is that the edit weight search is constrained on nodes of a grid space (the grid unit length is step-size $\eta$), which loses precision and underperforms during counterfactual search. 


