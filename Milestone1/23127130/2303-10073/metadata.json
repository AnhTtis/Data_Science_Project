{
    "arxiv_id": "2303.10073",
    "paper_title": "DialogPaint: A Dialog-based Image Editing Model",
    "authors": [
        "Jingxuan Wei",
        "Shiyu Wu",
        "Xin Jiang",
        "Yequan Wang"
    ],
    "submission_date": "2023-03-17",
    "revised_dates": [
        "2023-03-20"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV"
    ],
    "abstract": "We present DialogPaint, an innovative framework that employs an interactive conversational approach for image editing. The framework comprises a pretrained dialogue model (Blenderbot) and a diffusion model (Stable Diffusion). The dialogue model engages in conversation with users to understand their requirements and generates concise instructions based on the dialogue. Subsequently, the Stable Diffusion model employs these instructions, along with the input image, to produce the desired output. Due to the difficulty of acquiring fine-tuning data for such models, we leverage multiple large-scale models to generate simulated dialogues and corresponding image pairs. After fine-tuning our framework with the synthesized data, we evaluate its performance in real application scenes. The results demonstrate that DialogPaint excels in both objective and subjective evaluation metrics effectively handling ambiguous instructions and performing tasks such as object replacement, style transfer, color modification. Moreover, our framework supports multi-round editing, allowing for the completion of complicated editing tasks.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.10073v1"
    ],
    "publication_venue": "11 pages, 9 figures"
}