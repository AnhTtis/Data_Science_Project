\section{Problem Setup}
\label{sec:problem-setup}

\input{figures/system.tex}

We aim to solve long-horizon sequential manipulation problems that require semantic and geometric reasoning from an instruction $i$ expressed in natural language. 
We are given a library of skills $\mathcal{L} = \{\pi^1, \ldots, \pi^N\}$. 
Each skill has a natural language description and comes with a policy $\pi(a|s)$, a Q-function $Q^\pi (s, a)$, and a dynamics model $T^\pi(s' | s, a)$, all of which can be acquired via off-the-shelf reinforcement learning (RL) or imitation learning (IL) methods.
Actions output by the policy $a\sim\pi(\cdot|s)$ are the parameters of a corresponding manipulation primitive~\cite{felip2013manipulation} $\rho(a)$ which consumes the action and executes a series of motor commands on the robot (see Appx.~\ref{sec:implementation-details} for more details).
We also assume that a method exists for conveying the environment state $s$ to the LLM as natural language. The task planning problem is to find a sequence of skills $[\pi_1, \dots, \pi_H]$ that is likely to satisfy the instruction $i$ (for notational convenience, we will hereafter represent sequences with range subscripts, e.g. $\pi_{1:H}$). The task planning objective is to maximize the language model likelihood of the skill sequence $\pi_{1:H}$ given instruction $i$ and initial state $s_1$:
\begin{equation}
    p(\pi_{1:H} \mid i, s_1). \label{eq:task-score}
\end{equation}

This objective only considers the probability that the sequence of skills will satisfy the goal from a symbolic perspective. 
For example, if the goal is to move a box from the table to the rack, a symbolically correct sequence of actions might be \graytext{Pick(box)}, \graytext{Place(box, rack)}. 
However, we must also consider whether the skill sequence can succeed from a geometric perspective. 
Specifically, for each skill $\pi_h$, we need to consider the geometric feasibility of the underlying continuous parameters $a_h$.
For example, a symbolically correct sequence of skills may fail geometrically due to kinematic constraints of the robot. A geometrically feasible plan is one where each skill $\pi_h$ and its continuous action parameter $a_h$ receives a binary reward $r_h$; if just one action fails, then the entire plan fails. The geometric feasibility is defined to be the probability that all skills $\pi_{1:H}$ achieve rewards $r_{1:H}$:
\begin{equation}
    p(r_{1:H} \mid i, s_1, \pi_{1:H}). \label{eq:motion-score}
\end{equation}
Taking the product of Eqs.~\ref{eq:task-score}~and~\ref{eq:motion-score} results in an objective which represents the probability that a skill sequence $\pi_{1:H}$ is both likely to satisfy instruction $i$ and is geometrically feasible:
\begin{equation}
    \begin{split}
        &p(\pi_{1:H}, r_{1:H} \mid i, s_1) \\
        &\quad\quad= p(\pi_{1:H} \mid i, s_1)\, p(r_{1:H} \mid i, s_1, \pi_{1:H}).
    \end{split} \label{eq:tamp-score}
\end{equation}

% Provided are libraries of primitives $\mathcal{L}^\pi = \{\pi^1, \ldots, \pi^N\}$ and predicate classifiers $\mathcal{L}^P = \{p^1, \ldots, p^M\}$.

% \chris{Since we are the first to perform TAMP from natural language, we need a general and flexible problem formalism that admits solutions in the form of reactive agents (SayCan, InnerMonologue), hierarchical planners, and integrated task and motion planners.}

% \chris{As seen below, I was originally trying to separate the \textit{symbolic} from the \textit{geometric} component of the problem, though I'm not sure that this is the best way of going about it. Because symbolic transition dynamics are unknown, notions of planning in the symbolic space don't make much sense anymore. Symbolic states are more like emissions from a physical state that we are altering through actions, and we are trying to drive these symbolic emissions to one of several symbolic goal states that are consistent with the natural language instruction $T_{ins}$.}

% \subsection{Task planning under partial completeness}
% \label{subsec:task-planning-setup}

% \chris{The idea here is to define the \textit{symbolic} component of the problem; but an augmented one, where states are only represented by simple spatial relations (hence the hats atop the caligraphic sets), actions are known and correspond to our primitives $\mathcal{L}^\pi$, but the \klin{symbolic?} transition dynamics are unknown. Hence graph search cannot be used for planning.}

% A \textit{partially complete} task planning problem $\hat{\Pi}$ is a tuple $\langle \mathcal{O}, \hat{\mathcal{P}}, \hat{\mathcal{S}}, \mathcal{A}, \hat{\mathcal{I}}, \hat{\mathcal{G}} \rangle$ with full observability of objects $\mathcal{O}$ but with unspecified transition dynamics.
% $\hat{\mathcal{P}}$ is a set of predicates that describe basic spatial relations of objects like $\mathrm{On}(a, b)$, but does not include more complex relations commonly used to define transition pre- and post-conditions such as $\mathrm{InHand}(a)$ $\mathrm{CollisionFree}(a, b, \tau)$.
% A state $\hat{s} \in \hat{\mathcal{S}}$ is an assignment of values to predicates $\hat{\mathcal{P}}$ over objects, $\hat{\mathcal{I}}$ is the initial state, and $\hat{\mathcal{G}}$ is a set of goal states.
% A solution is a plan skeleton $\tau=[\pi_1, \pi_2, \ldots, \pi_H]$ the drives the initial state $\hat{\mathcal{I}}$ into a state $s\in\hat{\mathcal{G}}$ that satisfies the instruction $T_{ins}$.


% \subsection{Motion planning with primitives}
% \label{subsec:motion-planning-setup}


% \subsection{Task and motion planning from language}
% \label{subsec:tamp-setup}





% \subsection{Motion planning}
% \label{subsec:motion-planning-setup}

% Summarize the motion planning problem defined in TAPS.


% \subsection{Task and motion planning}
% \label{subsec:tamp-setup}
% Merge above.

% In this section, we formalize the task and motion planning problem.