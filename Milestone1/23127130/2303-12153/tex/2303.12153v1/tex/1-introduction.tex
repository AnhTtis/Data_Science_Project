\section{Introduction}
\label{sec:introduction}
{\em Task and Motion Planning\/} (TAMP) refers to a problem setting in which a robot has to solve long-horizon tasks that require both symbolic and geometric reasoning~\cite{integrated-tamp-2021}.
In the most common family of solution methods, a task planner consumes a symbolic domain specification and a goal to produce a candidate plan skeleton, while a motion planner verifies the plan skeleton for its geometric feasibility and returns a motion plan if successful.
The process repeats until a solution is found or the planner times out.\blfootnote{Toyota Research Institute provided funds to support this work. This work was also supported by the National Aeronautics and Space Administration (NASA) under the Innovative Advanced Concepts (NIAC) program.}

While details differ across TAMP methods, three core components are common~\cite{integrated-tamp-2021}.
First, they require a forward dynamics model and full state observability.
Second, they rely on meticulously defined symbolic planning domains, tuned to the robot's capabilities, the environment, and the task, to perform task planning.
Third, they require a process to test task plans for their geometric feasibility.
While different TAMP methods have relaxed the dependence on these components, many prominent works require all three~\cite{kaelbling2011-HPN, lagriffoul2014efficiently, toussaint2015-lgp, dantam2016incremental, bidot2017geometric, garrett2020-pddlstream}.

The emergence of {\em Large Language Models\/} (LLMs)~\cite{foundation-models-2021} as a task-agnostic reasoning module presents a promising pathway to general robot planning capabilities.
% Several recent works have capitalized on their utility~\cite{saycan-2022, innermono-2022, code-as-policies-2022}. 
% In treating LLMs as a \textit{black box}, their operation does not require a detailed symbolic specification as do symbolic planners. 
% Several recent works~\cite{saycan-2022, innermono-2022, code-as-policies-2022} have capitalized on their ability to perform planning for robot systems without tedious manual specification of symbolic planning domains.
Several recent works~\cite{saycan-2022, innermono-2022, code-as-policies-2022} have capitalized on their ability to perform planning for robot systems without needing to manually specify symbolic planning domains.
% However, in light of results that question the planning ability of LLMs~\cite{llms-cant-plan-2022}, a remaining challenge is how to verify the correctness and feasibility of their plans on the symbolic and geometric level. 
However, challenges remain. In this work, we address the following: how can we verify the correctness and feasibility of long-horizon LLM-generated plans on the symbolic and geometric level? 

% \input{figures/teaser.tex}
\input{figures/teaser-real.tex}
% We consider the problem of solving geometrically complex sequential manipulation tasks from a natural language instruction.
We propose Text2Motion, a language-based planning framework that interfaces an LLM with a library of learned skill policies and a policy sequence optimizer~\cite{taps-2022} to solve geometrically complex sequential manipulation tasks (Fig.~\ref{fig:teaser}).
Our contributions are two-fold: (i) an integrated search algorithm which interleaves LLM task planning with policy sequence optimization to construct geometrically feasible plans for tasks not seen by the skill policies during training; and (ii) a plan termination method that infers goal states from a natural language instruction to verify the completion of plans.  We find that our integrated method achieves a success rate of 64\% on a suite of challenging table top manipulation tasks, while prior language-based planning methods achieve a 13\% success rate.

% we demonstrate that integrated planning method is amenable several classes of problems, including challenging partially observable tasks.
Text2Motion is inspired by traditional TAMP methods, but solves sequential manipulation tasks with a drastically different approach.
%Text2Motion solves TAMP problems in settings that drastically depart from what traditional TAMP works have assumed. 
An LLM is used instead of a symbolic planner.
% Value functions and uncertainty quantification are applied to detect the feasibility of skills, and hence, specification for symbolic transition dynamics of actions is not a requirement. 
Value functions and uncertainty quantification determine the feasibility of skills and implicitly serve as preconditions, while learned dynamics models implicitly provide post-conditions.
% Text2Motion predicts symbolic goal constraints from natural language instructions instead of receiving them, and uses learned dynamics models and skill policies in place of simulation and subroutines. 
% Value functions and uncertainty quantification determine the feasibility of skills, while dynamics models are used in place of simulation and determine 
% Value functions, uncertainty quantification, and dynamics determine the feasibility of skills, while their effects 
Text2Motion \textit{predicts} symbolic goals from language instructions instead of \textit{receiving} them, and uses dynamics models and skill policies in place of simulation and subroutines.

% \klin{P1. TAMP: The good, the bad.}

% Task and motion planning (TAMP) algorithms have long been studied for their efficacy in finding and optimizing plans to complete complex robotics tasks. Furthermore, TAMP systems implicitly reduce the risk of error by only executing actions of feasible plans. However, TAMP systems require significant domain expertise. For each new environment, one need to hand-specifying a symbolic planning domain; for each new task, one needs to hand-specify a symbolic goal.

% % , along with full state observability of the environment and known dynamics for motion planning. However, defining planning domains for each new task is tedious, challenging when dealing with partial observability and stochasticity, and requires domain expertise.
% % Algorithmic efficiency is another point of concern due to the expense of simulating dynamics and calling robotics subroutines (e.g. inverse kinematics, motion planning, collision checking).
% % Lastly, because the systems are monotholic and domain-specific, integrating learned components is complicated, if not impossible.

% \klin{P2. Language-planners: The good, the bad.}

% A recent line of work removes the need for meticulously defined symbolic domains by using large language models (LLMs) in the planning loop. For instance, SayCan \cite{saycan-2022} selects the robot's next action by scoring a set of skill using an LLM and value function. CodeAsPolicies \cite{code-as-policies-2022} uses an LLM trained on do to directly produce a python program in response to a language instruction. However, there are challenges with language planning and we tackle an important one here: For a given natural language instruction, \textit{how can we quantify plans generated by an LLM and determine their instruction satisfiability and geometric feasibility before even executing an action}?

% \klin{P3. Text2Motion}

% In this paper, we seek to address the above limitations of language-based planners with a new language-based planner, \textsc{Text2Motion}. 

% % \klin{At least 2 ways to frame: i) (current) ``language can make TAMP better" ii) (other) ``we can verify language plans in robotics". Unclear which framing is best, or how to integrate these two perspectives.}


% % \klin{Re: How can we verify a plan output by an LLM and determine its geometric feasibility before even executing a plan. <- this is something that hasn't been tackled.

% % Verify == check if it's possible to succeed on a sequence of actions from an action skeleton output by an LLM.

% % Do so via product of Q functions + `high fidelity' dynamics model by training on success examples only + threshold on Q values to deal w/ hallucinated dynamics.}


% % We specifically focus on:
% % \begin{itemize}
% %     \item \textbf{Reducing domain expertise:} TAMP without completely specified planning domains and propositional goals;
% %     \item \textbf{Scalability:} Ease of integration and with learned components for task planning or motion planning;
% %     \item \textbf{Generality:} Ability to solve unseen and difficult to represent (PDDL) tasks in zero-shot fashion.
% % \end{itemize}

% \textbf{Importance:}
% TAMP is a powerful paradigm for solving \textit{arbitrary} long-horizon robotics problems with sufficiently complex geometric dependencies.
% For reasons outlined above, making these systems work on new tasks requires expertise and heavy engineering. 
% Addressing these problems results in a TAMP method that is applicable to new tasks by design, and requires little-to-no domain expertise to interact with.
% That is, the ability to solve TAMP problems from natural language.

% \textbf{Challenge:}
% While inconvenient to specify, symbolic planning domains provide useful information on how the environment state transitions \textit{w.r.t.} actions taken.
% TAMP systems rely on this information to deduce symbolically correct task plans before attempting to ground them in executable actions.
% By removing symbolic planning domains from the equation, we require general purpose reasoning from the TAMP solver, for which pretrained large language models (LLMs)~\cite{foundation-models-2021} seem a natural solution.
% However, recent work has demonstrated that LLMs are unable to predict long-horizon plans at high accuracy~\cite{llms-cant-plan-2022}. 
% Following this observation are two key challenges: (1, task-level) how to elicit more accurate task plans from LLMs; (2, motion-level) how to ground task plans in real-world feasibility, rank them, and verify their properties. 

% While related works have focused their effort towards (1), they have ignored essential characteristics in (2) required for robust and verifiable robot planning.
% Open-loop methods~\cite{saycan-2022} circumvent dealing with plans altogether by iteratively grounding and executing actions, but in doing so are limited to tasks without geometric action dependencies. 
% And while methods that predict programs~\cite{code-as-policies-2022, progprompt-2022} could indeed define closed-loop behaviors, it is unclear how to verify plans represented in code.

% % Our guiding insight is that plans produced by LLMs in response to natural language instructions should not be blindly trusted, because they be infeasible or lack robustness.

% % Our guiding insight is that plans produced by LLMs in response to natural language instructions should not be blindly trusted because they be infeasible or lack robustness. Instead, we opt to produce multiple distinct plans in response to instructions, optimize the continuous parameters of those plans for overall plan success, filter out plans based on whether or not they satisfy the natural language instruction and finally select the plan with the highest likelihood of success.
% % Our core idea is that we can reliably test whether a given plan satisfies a natural language instruction. We do so by leveraging an LLM and a grounded library of predicate classifiers.

% \klin{Move this to experiments section?}

% Task and motion plans (regardless of their origin) can be measured along several axes:

% \begin{enumerate}
%     \item \textbf{Instruction-satisfaction}. Does the eventual state satisfy the goal specified by the natural language instruction? 
%     \item \textbf{Optimality}. Given a plan that leads to an instruction-satisfying state, how many steps did the robot need to execute? 
% \end{enumerate}


% \textbf{Core idea:}

% Have varying quality and can be tested on goal satisfaction and geometric feasibility before execution.

% Our guiding insight is that plans produced by LLMs should not be blindly trusted, because they could be symbolically incorrect, infeasible, or potentially unsafe.
% Rather, they should be optimized to resolve action dependencies, scored and ranked based on geometric feasibility, and verified for symbolic correctness. 
% We propose a hierarchical TAMP method that uses an LLM to generate propositional goals and plan skeletons from a language instruction, and before resolving geometric constraints with task-agnostic policy sequencing (TAPS)~\cite{taps-2022}.
% The algorithm below roughly describes the process; please refer to Sec.~\ref{sec:text2motion} for details.

% % \input{algorithms/method.tex}

% We herein state our \textbf{contributions:} 

% \begin{itemize}
%     \item Text2Motion: a framework for using LLMs (with policies, Q functions and dynamics models) to generate and optimize grounded long horizon plans. \klin{this bullet assumes the integrated approach of saycan + dynamics models, the hierarchical approach isn't grounded step by step; also, not sure how to split up T2M and CaG ...}
%     \item Code as goals: a method for verifying LLM task plans via LLM-generated generate code expressions whose evaluation to truth corresponds to a fulfilled natural language instruction. \klin{naive goal parsing is still CaG since a python list is still code .. ?}
%     \item Generator-Scorer: a simple two step procedure that drastically reduces the cost of using an LLM as a scorer \klin{could be a stand-alone contribution; we'd probably need to compare it with SayCan itself, or at least have an ablation on number of skills to generate? If the integrated approach turns out to not work so well, not sure how to integrate this last bullet contribution in a clean way.}. 
%     % taking natural language instructions, generating an action sequence and their continuous parameters, and verifying the feasibility and executability of the plan.
% \end{itemize}


