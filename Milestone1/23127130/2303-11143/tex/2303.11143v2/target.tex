% !TEX root = paper.tex

\section{Target systems}\label{chap:targetSystems}

In this section, we illustrate the three models we attacked: Gemini \cite{xu2017neural}, GMN \cite{DBLP:conf/icml/LiGDVK19}, and SAFE \cite{massarelli2021function}. We give a high-level description of their internals and then discuss specific provisions for the Greedy (Section \ref{sec:greedy}) and GCAM (Section \ref{sec:whitebox}) attacks---whereas Spatial Greedy needs no adaptations.

For their choice, we first surveyed recent comparative evaluations (most prominently~\cite{marcelli2022machine}) to identify plausible, performant candidates. We then reviewed the characteristics of the neural networks and the code analysis choices behind them, identifying three distinctly different approaches to problem solving. As we will see, for example, GMN and Gemini rely on CFG properties whereas SAFE does not; GMN accounts for graph similarity using an explicit matching mechanism that is different from the message passing network behind Gemini; SAFE employs a different kind of neural network than the other two systems. 

\subsection{Gemini}\label{sec:gemini}

Gemini \cite{xu2017neural} represents functions in the problem space through their Attributed Control Flow Graph (ACFG). An ACFG is a control flow graph where each basic block consists of a vector of manual features (i.e., node embeddings).

The focal point of this approach consists of a graph neural network (GNN) based on the Structure2vec~\cite{DBLP:conf/icml/DaiDS16} model that converts the ACFG into an embedding vector, obtained by aggregating the embedding vectors of individual ACFG nodes. The similarity score for two functions is given by the cosine similarity of their ACFG embedding vectors. 


\subsubsection{Greedy Attack}\label{sec:black:gemini}
Each ACFG node contributes a vector of 8 manually selected features. Five of these features depend on the characteristics of the instructions in the node, while the others on the graph topology. The model distinguishes instructions from an ISA only for how they contribute to these 5 features.
This enables a gray-box variant of our Greedy attack: we measure the robustness of Gemini using a set of candidates $\texttt{CAND}$ of only five instructions, carefully selected for covering the five features. Later in the paper, we use this variant as the baseline approach for a comparison with Spatial Greedy.



\subsubsection{GCAM Attack}\label{sec:white:gemini}

As described in the previous section, some of the components of a node feature vector $v$ depend on the instructions inside the corresponding basic block. As Gemini maps all possible ISA instructions into 5 features, we can associate each instruction with a deterministic modification of $v$ represented as a vector $u$. We select five categories of instructions and for each category $c_j$ we compute the modification $u_j$ that will be applied to the feature vector $v$. We selected the categories so as to cover the aforementioned features.

When we introduce in the block an instruction belonging to category $c_j$, we add its corresponding $u_j$ modification to the feature vector $v$. Therefore, adding instructions inside the block modifies the feature vector $v$ by adding to it a linear combination vector $\sum_{j}n_j u_j$, where $n_j$ is the number of instructions of category $c_j$ added. Our perturbation $\delta$ acts on the feature vector of the function only in the components corresponding to the added dead branches, by modifying the coefficients of the linear combination above.

Since negative coefficients are meaningless, we avoid them by adding to the optimization problem appropriate constraints. Moreover, we solve the optimization problem without forcing the components of $\delta$ to be integers, as this would create an integer programming problem. Therefore, at the end of the iterative optimization process, we get our problem-space perturbation $\delta_p$ by \textit{rounding} each component of $\delta$. It is immediate to obtain from $\delta_p$ the problem-space modification to our binary function $f_1$. Indeed, in each dead block, we must add as many instructions belonging to a category as the corresponding coefficient in $\delta_p$.

\subsection{GMN}\label{sec:gmn}
Graph Matching Network (GMN)~\cite{DBLP:conf/icml/LiGDVK19} computes the similarity between two graph structures. When functions are represented through their CFGs, GMN offers state-of-the-art performance for the binary similarity problem~\cite{DBLP:conf/icml/LiGDVK19,marcelli2022machine}.

Differently from solutions based on standard GNNs (e.g., Gemini), which compare embeddings built separately for each graph, GMN computes the distance between two graphs as it attempts to match them. In particular, while in a standard GNN the embedding vector for a node captures properties of its neighborhood only, GMN also accounts for the similarity with nodes from the other graph.

\subsubsection{Greedy Attack}\label{sec:black:gmn}
Similarly to the case of Gemini, each node of the graph consists of a vector of manually-engineered features. In particular, each node is a bag of 200 elements, each of which represents a class of assembly instructions, grouped according to their mnemonics. The authors do not specify why they only consider these mnemonics among all the available ones in the \texttt{x86-64} ISA.
Analogously to Gemini, when testing the robustness of this model against the Greedy approach we devise a gray-box variant by considering a set of candidates $\texttt{CAND}$ of 200 instructions, each of which belonging to one and only one of the considered classes.

\subsubsection{GCAM Attack}\label{sec:white:gmn}
Our white-box attack operates analogously to what we presented in Section \ref{sec:white:gemini}.
Similarly to the Gemini case, each dead branch adds a node to the CFG while the feature mapping function transforms each CFG node into a feature vector. The feature vector is a bag of the instructions contained in the node, where assembly instructions are divided into one of 200 categories using the mnemonics.



\subsection{SAFE}\label{sec:safe}
SAFE~\cite{massarelli2021function} is an embedding-based similarity model. It represents functions in the problem space as sequences of assembly instructions.
It first converts assembly instructions into continuous vectors using an instruction embedding model based on the word2vec~\cite{DBLP:conf/nips/MikolovSCCD13} word embedding technique.
Then, it supplies such vectors to a bidirectional self-attentive recurrent neural network (RNN), obtaining an embedding vector for the function. The similarity between two functions is the cosine similarity of their embedding vectors.

\subsubsection{Greedy Attack}\label{sec:black:safe}
The Greedy attack against SAFE follows the black-box approach described in Section \ref{sec:greedy}. Since SAFE does not use manually engineered features, we cannot select a restricted set of instructions that generates all vectors of the feature space for a gray-box variant. We test its resilience against the Greedy approach considering a carefully designed list of candidates $\texttt{CAND}$ composed of random and hand-picked instructions, meaning that the baseline is a black-box attack.


\subsubsection{GCAM Attack}\label{sec:white:safe}
In the feature space, we represent a binary function as a sequence of instruction embeddings belonging to a predefined metric space. The perturbation $\delta$ is a sequence of real-valued vectors initialized with embeddings of real random instructions; each dead block contains four of such vectors. In the optimization process, we modify each embedding $i_j \in \delta$ by a small quantity given by the negative gradient of the loss function $\mathcal{L}$. In other words, every time we optimize the objective function, we alter each $i_j \in \delta$ by moving it in the negative direction identified through the gradient.

Since during optimization we modify instruction embeddings in terms of their single components, we have no guarantee that the obtained vectors are embeddings of real instructions. For this reason, after the optimization process, we compute the problem-space perturbation $\delta_p$ by {\em rounding}, at each iteration, the embeddings in $\delta$ to the closest embeddings in the space of real instruction embeddings.
