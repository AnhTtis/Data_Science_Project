% !TEX root = paper.tex

\section{Target systems}\label{chap:targetSystems}
In this section, we illustrate the three state-of-the-art code models for binary function similarity we attacked: Gemini \cite{xu2017neural}, GMN \cite{DBLP:conf/icml/LiGDVK19}, and SAFE \cite{massarelli2021function}. We select these models as they are the best models for binary function similarity (as from a recent extensive comparison~\cite{marcelli2022machine}) and follow radically different approaches to the problem. For each model, we give a high-level description of its internals and then discuss specific provisions for the Greedy (Section \ref{sec:greedy}) and GCAM (Section \ref{sec:whitebox}) attacks; Spatial Greedy needs no adaptations.

\subsection{Gemini}\label{sec:gemini}

Gemini \cite{xu2017neural} represents functions in the problem space through their Attributed Control Flow Graph (ACFG). An ACFG is a control flow graph where each basic block consists of a vector of manual features (i.e., node embeddings).

The focal point of this approach consists of a graph neural network (GNN) based on the Structure2vec~\cite{DBLP:conf/icml/DaiDS16} model that converts the ACFG into an embedding vector. That is, Gemini solves the binary similarity problem by transforming two functions into embedding vectors using a GNN and then computing the similarity as the cosine distance between the two vectors.

The authors used a Siamese architecture~\cite{DBLP:conf/nips/BromleyGLSS93} to train the model. The embedding for the ACFG consists of aggregating the embedding vectors relative to the single nodes of the considered graph. The embedding of each node has to reflect both the features of the node itself and the information related to the graph topology.
 
\subsubsection{Greedy Attack}\label{sec:black:gemini}
Each ACFG node contributes a vector of 8 manually selected features. Five of these features depend on the characteristics of the instructions in the node, while the others on the graph topology. The model distinguishes instructions from an ISA only for how they contribute to these 5 features.
This enables a gray-box variant of our Greedy attack: we measure the robustness of Gemini using a set of candidates $\texttt{CAND}$ of only five instructions, carefully selected for covering the five features. Later in the paper, we use this variant as the baseline approach for a comparison with Spatial Greedy.

\subsubsection{GCAM Attack}\label{sec:white:gemini}
As described in the previous section, some of the components of a node feature vector $v$ depend on the instructions inside the corresponding basic block. As Gemini maps all possible ISA instructions into 5 features, we can associate each instruction with a deterministic modification of $v$ represented as a vector $u$. We select five categories of instructions and for each category $c_j$ we compute the modification $u_j$ that will be applied to the feature vector $v$. We selected the categories so as to cover the aforementioned features.

When we introduce in the block an instruction belonging to category $c_j$, we add its corresponding $u_j$ modification to the feature vector $v$. Therefore, adding instructions inside the block modifies the feature vector $v$ by adding to it a linear combination vector $\sum_{j}n_j u_j$, where $n_j$ is the number of instructions of category $c_j$ added. Our perturbation $\delta$ acts on the feature vector of the function only in the components corresponding to the added dead branches, by modifying the coefficients of the linear combination above.

Since negative coefficients are meaningless, we avoid them by adding to the optimization problem appropriate constraints. Moreover, we solve the optimization problem without forcing the components of $\delta$ to be integers, as this would create an integer programming problem. Therefore, at the end of the iterative optimization process, we get our problem-space perturbation $\delta_p$ by \textit{rounding} each component of $\delta$. It is immediate to obtain from $\delta_p$ the problem-space modification to our binary function $f_1$. Indeed, in each dead block, we must add as many instructions belonging to a category as the corresponding coefficient in $\delta_p$.

\subsection{GMN}\label{sec:gmn}
Graph Matching Network (GMN)~\cite{DBLP:conf/icml/LiGDVK19} computes the similarity between two graph structures. When functions are represented through their CFGs, GMN offers state-of-the-art performance for the binary similarity problem~\cite{DBLP:conf/icml/LiGDVK19,marcelli2022machine}.

Differently from standard GNNs (e.g., Gemini), which produce embeddings for one input graph at a time (and such vectors are eventually used for similarity calculation), GMN computes the distance between the two graphs as it attempts to match them.
The solution consists of a typical GNN architecture based on a message-passing mechanism.

What sets GMN apart from a standard GNN is a component taking into account also inter-graph relationships. While in a standard GNN each node consists of a vector representing only its neighborhood (both in terms of nodes and edges), in GMN each node has also a component describing the similarity with the nodes from the other graph.% of the pair. 

\subsubsection{Greedy Attack}\label{sec:black:gmn}
Similarly to the case of Gemini, each node of the graph consists of a vector of manually-engineered features. In particular, each node is a bag of 200 elements, each of which represents a class of assembly instructions, grouped according to their mnemonics. The authors do not specify why they only consider these mnemonics among all the available ones in the \texttt{x86-64} ISA.
Analogously to Gemini, when testing the robustness of this model against the Greedy approach we devise a gray-box variant by considering a set of candidates $\texttt{CAND}$ of 200 instructions, each of which belonging to one and only one of the considered classes.

\subsubsection{GCAM Attack}\label{sec:white:gmn}
Similarly to the case of Gemini, each dead branch adds a node to the CFG while the feature mapping function transforms each CFG node of the CFG into a vector of features.
The feature vector of the node is a bag of the instructions contained in the node, where assembly instructions are divided into one of 200 categories using the mnemonics.

The white-box attacks is carried out in a way analogous to Gemini, as discussed in Section \ref{sec:white:gemini}.

\subsection{SAFE}\label{sec:safe}
SAFE \cite{massarelli2021function} is an embedding-based similarity model. It represents functions in the problem space as sequences of filtered assembly instructions. Its feature mapping function $\lambda$ is a self-attentive recurrent neural network (RNN) that operates directly on problem-space objects.

SAFE first converts the filtered assembly instructions into continuous vectors using an instruction embedding model based on the word2vec~\cite{DBLP:conf/nips/MikolovSCCD13} word embedding technique. The model identifies an instruction embedding space, representable as an embedding matrix where each row corresponds to the embedding of a specific filtered instruction.

SAFE then supplies such instruction embeddings to a bidirectional RNN to obtain a matrix of summary vectors, which it then multiplies by an attention matrix, getting a final embedding matrix representing the entire function. Finally, it flattens such matrix and gives the result as input to a final two-layer fully connected network, obtaining the function embedding vector. The authors adopt the Siamese architecture to train the model.

\subsubsection{Greedy Attack}\label{sec:black:safe}
The Greedy attack against SAFE follows the black-box approach described in Section \ref{sec:greedy}. Since SAFE does not use manually engineered features, we cannot select a restricted set of instructions that generates all vectors of the feature space for a gray-box variant. We test its resilience against the Greedy approach considering a carefully designed list of candidates $\texttt{CAND}$ composed of random and hand-picked instructions, meaning that the baseline is a black-box attack.

\subsubsection{GCAM Attack}\label{sec:white:safe}
In the feature space, we represent a binary function as a sequence of instruction embeddings belonging to a predefined metric space. The perturbation $\delta$ is a sequence of real-valued vectors initialized with embeddings from the metric space corresponding to real random instructions. During the optimization process, we modify each embedding $i_j \in \delta$ by a small quantity given by the negative gradient of the loss function $\mathcal{L}$. In other words, every time we optimize the objective function, we alter each $i_j \in \delta$ by moving it in the negative direction identified through the gradient.

Since during the optimization process we modify instruction embeddings in terms of their single components, at the end of this procedure, we have no guarantee that the obtained components identify embeddings corresponding to the ones of real instructions. For this reason, after the optimization process, we compute the problem-space perturbation $\delta_p$ by {\em rounding} the embeddings in $\delta$ to the closest embeddings in the space of real instruction embeddings.