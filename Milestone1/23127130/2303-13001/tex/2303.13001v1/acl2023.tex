% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Remove the "review" option to generate the final version.
\usepackage{ACL2023}
% Standard package includes
\usepackage{times}
\usepackage{latexsym}
% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}
\usepackage{times}
\usepackage{latexsym}
\usepackage{bm}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{multirow}
\usepackage{amsfonts}
\usepackage{color}
\usepackage{amsmath, mathtools}
% This is not strictly necessary, and may be commented out.
% However, it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}


% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{Is ChatGPT A Good Keyphrase Generator? A Preliminary Study}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a seperate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{Mingyang Song$^{\spadesuit}$, Haiyun Jiang$^{\clubsuit}$$^\ast$, Shuming Shi$^{\clubsuit}$\\
	{\bf Songfang Yao$^{\spadesuit}$, Shilong Lu$^{\spadesuit}$, Yi Feng$^{\spadesuit}$, Huafeng Liu$^{\spadesuit}$, Liping Jing$^{\spadesuit}$}\thanks{\ \ Corresponding Author} \\
	$^{\clubsuit}$Tencent AI Lab, Shenzhen, China \\
	$^{\spadesuit}$Beijing Key Lab of Traffic Data Analysis and Mining \\
	$^{\spadesuit}$Beijing Jiaotong University, Beijing, China \\
	{\tt mingyang.song@bjtu.edu.cn} \\
}

\begin{document}
\maketitle
\begin{abstract}
%Recently, the emergence of ChatGPT has attracted wide attention from the computational linguistics community. Therefore, in this report, we provide a preliminary evaluation of ChatGPT for the keyphrase generation task to show its capability as a keyphrase generator, such as keyphrase generation prompts, keyphrase generation diversity, multi-domain keyphrase generation, and long document understanding. We adopt the prompt advised by OpenAI and extend it to six candidate prompts to trigger the keyphrase generation ability of ChatGPT and find that the candidate prompts generally work well and show minor performance differences on six benchmark datasets. Overall, we find that ChatGPT has excellent potential for keyphrase generation, and we also list several limitations and future expansions of this report in the final section. In addition, we find that absent keyphrase generation is still a challenge for ChatGPT. 
The emergence of ChatGPT has recently garnered significant attention from the computational linguistics community. To demonstrate its capabilities as a keyphrase generator, we conduct a preliminary evaluation of ChatGPT for the keyphrase generation task. We evaluate its performance in various aspects, including keyphrase generation prompts, keyphrase generation diversity, multi-domain keyphrase generation, and long document understanding. Our evaluation is based on six benchmark datasets, and we adopt the prompt suggested by OpenAI while extending it to six candidate prompts. 
We find that ChatGPT performs exceptionally well on all six candidate prompts, with minor performance differences observed across the datasets. Based on our findings, we conclude that ChatGPT has great potential for keyphrase generation. Moreover, we discover that ChatGPT still faces challenges when it comes to generating absent keyphrases. Meanwhile, in the final section, we also present some limitations and future expansions of this report. We have released the used data\footnote{\url{https://github.com/MySong7NLPer/ChatGPT_as_Keyphrase_Generator}}.




\end{abstract}

\section{Introduction}
ChatGPT\footnote{\url{https://openai.com/blog/chatgpt}} is an intelligent chatbot developed by OpenAI based on the InstructGPT \cite{instructgpt}. ChatGPT aims to provide excellent conversation responses based on the prompts provided. OpenAI highlights that ChatGPT can provide detailed responses, answer follow-up questions, and challenge incorrect or inappropriate prompts while maintaining a natural dialogue format. Furthermore, ChatGPT encompasses a wide range of natural language processing abilities, such as code debugging, question answering, article paraphrasing, keyphrase generation, and logic reasoning, to name a few. We are particularly intrigued by the capability of keyphrase generation of ChatGPT, as we would like to understand how well it performs compared to the state-of-the-art keyphrase generation models. We focus on narrowing the gap between ChatGPT and such keyphrase generation models and exploring new and innovative ways to improve the performance of keyphrase generation and enhance its features to provide even better results. Note that we consider that keyphrases and keywords are different in this report. Keyphrases are often phrases of two or more words rather than single words (keywords). %Furthermore, we present corresponding analysis on this issue in the report.

\begin{figure}
	\centering
	\includegraphics[scale=0.5]{prompt.png}
	\caption{Prompts or instructions advised by ChatGPT for keyphrase generation (Date: 2023.03.01).}
	\label{prompts}
\end{figure}


\begin{table*}[t!]
	\begin{center}
		\scriptsize
		\renewcommand\arraystretch{1.7}
		\renewcommand\tabcolsep{7pt}
		\begin{tabular}{l|c|c|c|c|c}
			\hline \hline 
			\textbf{Test Set} & \textbf{Domain}  & \textbf{Type} & \textbf{\# Doc.} & \textbf{Avg. \# Words} & \textbf{Present KPs (\%)} \\ \hline
			\textsc{KP20k} \cite{catseq17}  &  Scientific Abstract  & Short & {\color{red}\textbf{20,000}} & 179.8 & 57.40 \\
			\textsc{Inspec} \cite{Inspec} &  Scientific Abstract & Short & {\color{red}\textbf{500}} & 128.7 & 55.69 \\
			\textsc{Nus} \cite{Nus} &  Scientific Abstract & Short & {\color{red}\textbf{211}} & 219.1 & 67.75 \\
			\textsc{Krapivin} \cite{Krapivin} &  Scientific Abstract & Short & {\color{red}\textbf{400}} & 182.6 & 44.74  \\
			\textsc{SemEval2010} \cite{SemEval} &  Scientific Abstract & Short & {\color{red}\textbf{100}} & 234.8 & 42.01 \\
			\hline
			%\textsc{DUC2001} \cite{duc2001_singlerank} &  News Article & Medium & {\color{red}\textbf{308}} & 847.2 & 97.82  \\
			\textsc{OpenKP} \cite{xiong19} &  Open Web Domain & Long & {\color{red}\textbf{6,616}} & 900.4 & 100.00   \\
			%\textsc{SemEval2010} \cite{SemEval} &  Full Scientific Paper & Long & {\color{red}\textbf{100}} & 1587.5 & 88.70   \\
			\hline\hline
		\end{tabular}
	\end{center}
	\caption{\label{dataset} Information of adopted test sets. \textbf{\# Doc.} is the number of documents in the dataset.  \textbf{Avg. \# Words} is the average number of words for documents. \textbf{Present KPs (\%)} indicates the percentage of keyphrases, which are presented in the documents. \textbf{Note that this report uses all of the test data rather than sampling part from it}.}
\end{table*}

\begin{table}[t!]
	\renewcommand\arraystretch{2}
	\begin{center}
		\scriptsize
		\begin{tabular}{p{0.5cm}p{6cm}}
			\hline\hline
			
			\multicolumn{2}{c}{\textsc{Prompts}} \\ \hline
			
			
			\textsc{\textbf{Tp}$1^\dagger$}    & \textbf{\texttt{Extract keywords from this text:}} \texttt{[\textsc{Document}]} \\ \hline
			\textsc{\textbf{Tp}$2$}   & \texttt{Generate keywords from this text:} \texttt{[\textsc{Document}]} \\ 
			\textsc{\textbf{Tp}$3$}    & \texttt{Extract keyphrases from this text:} \texttt{[\textsc{Document}]} \\ 
			\textsc{\textbf{Tp}$4$}    & \texttt{Generate keyphrases from this text:} \texttt{[\textsc{Document}]} \\ 
			\textsc{\textbf{Tp}$5$}    & \texttt{Generate present and absent keywords from this text:} \texttt{[\textsc{Document}]} \\ 
			\textsc{\textbf{Tp}$6$}    & \texttt{Generate present and absent keyphrases from this text:} \texttt{[\textsc{Document}]} \\ 
			\hline\hline
			
		\end{tabular}
		\caption{\label{case} Six prompts are designed for chatting with ChatGPT to collect keywords or keyphrases from the given text document. $^\dagger$ indicates the prompt provided by OpenAI\footnotemark[2].}
	\end{center}
\end{table}
In this report, we summarize a preliminary study of ChatGPT on keyphrase generation to gain a better understanding of it. Specifically, we focus on five perspectives:

\noindent{\textbf{$\bullet$ Keyphrase Generation Prompts}:} 

ChatGPT is essentially a large language model which needs prompts as guidance to trigger its ability to generate keyphrases. The different style of prompts or instructions may affect the quality of generated keyphrases.
Generally, the performance of ChatGPT to obtain keyphrases depends largely on the prompts. A good prompt often obtains better performance than a bad one. Therefore, we verify the quality of six prompts to verify the performance of ChatGPT in the task of keyphrase generation. 
%\noindent{\textbf{$\bullet$ Keyphrase Generation Robustness}:} 



\noindent{\textbf{$\bullet$ Keyphrase Generation Diversity}:} 

Keyphrase generation aims to generate a set of phrases that can \textit{cover the main topics discussed in a given document} \cite{2014survey}. Recent advances in keyphrase generation have made remarkable progress, demonstrated through improved quality metrics such as F1-score. However, the importance of diversity in keyphrase generation has been largely ignored \cite{diversity}. Following previous studies \cite{one2set, wrone2set}, we report the average numbers of unique present and absent keyphrases and the average duplication ratios of all predicted keyphrases to investigate the ability of ChatGPT to generate diverse keyphrases.

\noindent{\textbf{$\bullet$ Multi-domain Keyphrase Generation}:} 

ChatGPT is a versatile language model that performs various natural language processing tasks across multiple domains. We are interested in evaluating how well ChatGPT performs on different domains, considering differences in text styles (e.g., news documents vs. scientific articles). This will give us a better understanding of its strengths and limitations in different contexts.

\footnotetext[2]{\url{https://platform.openai.com/examples/default-keywords}}



\noindent{\textbf{$\bullet$  Different Length Document Understanding}:} 

Different lengths of documents usually correspond to different optimal processing strategies, especially for long documents. For example, in the task of keyphrase generation, while it may be possible to design better algorithms to handle a large number of candidates in long documents, we believe that employing sophisticated features, especially those that encode background knowledge, will enable keyphrases and non-keyphrases to be distinguished more efficiently, even in the presence of a large number of candidates. At the same time, how to encode long documents is also a problem worth studying. Therefore, we tested the ability of ChatGPT as a general large language model to handle documents of different lengths.
\begin{table*}[!htb]
	\scriptsize
	\centering
	\renewcommand\tabcolsep{6pt}
	\renewcommand\arraystretch{1.3}
	\begin{tabular}{c|cc|cc|cc|cc|cc}
		\hline\hline
		\multirow{2}{*}{\normalsize \textbf{\textsc{Model}}} & \multicolumn{2}{c|}{\textsc{\textbf{KP20k}}} & \multicolumn{2}{c|}{\textsc{\textbf{Inspec}}}& \multicolumn{2}{c|}{\textsc{\textbf{Nus}}}& \multicolumn{2}{c|}{\textsc{\textbf{Krapivin}}}& \multicolumn{2}{c}{\textsc{\textbf{SemEval}}}\\ %\cline{2-2} 
		& F1@5 & F1@M & F1@5 & F1@M & F1@5 & F1@M& F1@5 & F1@M& F1@5 & F1@M \\ \hline
		\multicolumn{11}{l}{\textsc{RNN-based Models}} \\\hline
		\multicolumn{1}{l|}{\textsc{catSeq \cite{catseq17}}}
		& 0.291 & 0.367 & 0.225 & 0.262 & 0.323 & 0.397 & 0.269 & 0.354 & 0.242 & 0.283 \\ 
		\multicolumn{1}{l|}{\textsc{catSeqTG-2RF1 \cite{adaptive_reward}}}
		& 0.321 & 0.386 & 0.253 & 0.301 & 0.375 & 0.433 & 0.300 & 0.369 & 0.287 & 0.329 \\ 
		\multicolumn{1}{l|}{\textsc{ExHiRD-h \cite{ExHiRD}}}
		& 0.311 & 0.374 & 0.253 & 0.291 & N/A & N/A & 0.286 & 0.347 & 0.284 & 0.335 \\ \hline\hline
		
		
		
		\multicolumn{11}{l}{\textsc{Transformer-based Models}} \\\hline
		\multicolumn{1}{l|}{{\textsc{SetTrans} \cite{one2set}}}
		& 0.358 & 0.392 & 0.285 & 0.324 & 0.406 & 0.450 & 0.326 & \textbf{0.364} & 0.331 & 0.357 \\ 
		\multicolumn{1}{l|}{{\textsc{WR-SetTrans} \cite{wrone2set}}}
		& \textbf{0.370} & \textbf{0.378} & {0.330} & {0.351} & \textbf{0.428} & \textbf{0.452} & \textbf{0.360} & {0.362} & \textbf{0.360} & \textbf{0.370} \\\hline\hline
		
		\multicolumn{11}{l}{\textsc{PLM-based Models}} \\\hline
		
		\multicolumn{1}{l|}{\textsc{SciBART-base$^\ddagger$ (124M)}}
		& 0.341 & 0.396 & 0.275 & 0.328 & 0.373 & 0.421 & 0.282 & 0.329 & 0.270 & 0.304 \\ 
		\multicolumn{1}{l|}{\textsc{BART-base$^\ddagger$ (140M)}}
		& 0.322 & 0.388 & 0.270 & 0.323 & 0.366 & 0.424 & 0.270 & 0.336 & 0.271 & 0.321 \\ 
		\multicolumn{1}{l|}{\textsc{T5-base$^\ddagger$ (223M)}}
		& 0.336 & 0.388 & 0.288 & 0.339 & 0.388 & 0.440 & 0.302 & 0.350 & 0.295 & 0.326 \\ 
		\hline\hline
		
		\multicolumn{11}{l}{\textsc{ChatGPT\ (gpt-3.5-turbo)}} \\\hline
		\multicolumn{1}{l|}{\textsc{ChatGPT w/ \textbf{Tp}$1^\dagger$}}
		& 0.186 & 0.160 & 0.298 & 0.417 & 0.319 & 0.225 & 0.239 & 0.187 & 0.267 & 0.216 \\
		\multicolumn{1}{l|}{\textsc{ChatGPT w/ \textbf{Tp}$2$}}
		& 0.180 & 0.149 & 0.310 & 0.433 & 0.314 & 0.239 & 0.243 & 0.197 & 0.275 & 0.240 \\
		\multicolumn{1}{l|}{\textsc{ChatGPT w/ \textbf{Tp}$3$}}
		& 0.161 & 0.141 & 0.383 & 0.463 & 0.281 & 0.211 & 0.218 & 0.184 & 0.268 & 0.214 \\
		\multicolumn{1}{l|}{\textsc{ChatGPT w/ \textbf{Tp}$4$}}
		& 0.160 & 0.136 & 0.322 & 0.393 & 0.208 & 0.187 & 0.170 & 0.163 & 0.233 & 0.212 \\
		\multicolumn{1}{l|}{\textsc{ChatGPT w/ \textbf{Tp}$5$}}
		& 0.174 & 0.161 & 0.330 & 0.427 & 0.336 & 0.261 & 0.244 & 0.204 & 0.281 & 0.243 \\
		\multicolumn{1}{l|}{\textsc{ChatGPT w/ \textbf{Tp}$6$}}
		& 0.179 & 0.165 & \textbf{0.401} & \textbf{0.476} & 0.287 & 0.253 & 0.230 & 0.213 & 0.262 & 0.233 \\
		
		\hline\hline
	\end{tabular}
	
	\caption{Results of present keyphrase generation on five datasets. F1 scores on the top 5 and M keyphrases are reported, where M is a variable cut-off equal to the number of predictions. The results of the baselines are reported in their corresponding papers. Specifically, $^\ddagger$ indicates the results are reported in \citet{wudi}. The best results are highlighted in bold.}
	\label{present}
\end{table*}
\section{ChatGPT for Keyphrase Generation}
\subsection{Evaluation Setting}
We briefly introduce the evaluation setting, which mainly includes the compared baselines, datasets, and evaluation metrics.
Note that each time a new query is made to ChatGPT, we clear conversations to avoid the influence of previous samples, which is similar to \citet{gangda}.

\subsubsection{Baselines}
We compare ChatGPT with several state-of-the-art keyphrase generation systems: \textsc{catSeq} \cite{catseq17}, \textsc{catSeqTG-2RF1} \cite{adaptive_reward}, \textsc{ExHiRD-h} \cite{ExHiRD}, \textsc{SetTrans} \cite{one2set}, and \textsc{WR-SetTrans} \cite{wrone2set}. Furthermore, we also compare ChatGPT with several state-of-the-art keyphrase extraction systems: JointKPE (BERT-base) \cite{baseline}, JointKPE (RoBERTa-base) \cite{baseline}, HyperMatch \cite{hypermatch}, and KIEMP \cite{song2021importance}. By default, the results in this report come from the ChatGPT version on 2023.03.01. For new results, we will mark the updated version information correspondingly.

\subsubsection{Datasets}
We evaluate ChatGPT and all the baselines on five test datasets: \textsc{Inspec} \cite{Inspec}, \textsc{NUS} \cite{Nus}, \textsc{Krapivin} \cite{Krapivin}, \textsc{SemEval} \cite{SemEval}, and \textsc{KP20k} \cite{catseq17}. As implemented in \cite{one2set, wrone2set}, we perform data preprocessing, including tokenization, lowercasing, replacing all digits with the symbol ⟨digit⟩, and removing duplicated instances. Note that all the baselines were trained by using the KP20k training set. Furthermore, we verify the keyphrase generation ability of ChatGPT in real-world scenarios on the \textsc{OpenKP} dataset \cite{xiong19} where \textit{documents are from diverse domains} and have variant content quality. Table~\ref{dataset} summarizes the information of the used dataset.
\begin{table*}[!htb]
	\scriptsize
	\centering
	\renewcommand\tabcolsep{6pt}
	\renewcommand\arraystretch{1.3}
	\begin{tabular}{c|cc|cc|cc|cc|cc}
		\hline\hline
		\multirow{2}{*}{\normalsize \textsc{\textbf{{Model}}}} & \multicolumn{2}{c|}{\textsc{\textbf{KP20k}}} & \multicolumn{2}{c|}{\textsc{\textbf{Inspec}}}& \multicolumn{2}{c|}{\textsc{\textbf{Nus}}}& \multicolumn{2}{c|}{\textsc{\textbf{Krapivin}}}& \multicolumn{2}{c}{\textsc{\textbf{SemEval}}}\\ %\cline{2-2} 
		& F1@5 & F1@M & F1@5 & F1@M & F1@5 & F1@M& F1@5 & F1@M& F1@5 & F1@M \\ \hline
		
		\multicolumn{11}{l}{\textsc{RNN-based Models}} \\\hline
		\multicolumn{1}{l|}{\textsc{catSeq \cite{catseq17}}}
		& 0.015 & 0.032 & 0.004 & 0.008 & 0.016 & 0.028 & 0.018 & 0.036 & 0.016 & 0.028 \\ 
		\multicolumn{1}{l|}{\textsc{catSeqTG-2RF1 \cite{adaptive_reward}}}
		& 0.027 & 0.050 & 0.012 & 0.021 & 0.019 & 0.031 & 0.030 & 0.053 & 0.021 & 0.030 \\ 
		\multicolumn{1}{l|}{\textsc{ExHiRD-h \cite{ExHiRD}}}
		& 0.016 & 0.032 & 0.011 & 0.022 & N/A & N/A & 0.022 & 0.043 & 0.017 & 0.025 \\ 
		\hline\hline
		\multicolumn{11}{l}{\textsc{Transformer-based Models}} \\\hline
		\multicolumn{1}{l|}{{\textsc{SetTrans} \cite{one2set}}}
		& 0.036 & {0.058} & 0.021 & 0.034 & 0.042 & 0.060 & 0.047 & 0.073 & 0.026 & 0.034 \\ 
		\multicolumn{1}{l|}{{\textsc{WR-SetTrans} \cite{wrone2set}}}
		& \textbf{0.050} & \textbf{0.064} & 0.025 & 0.034 & \textbf{0.057} & \textbf{0.071} & \textbf{0.057} & \textbf{0.074} & \textbf{0.040} & \textbf{0.043} \\
		\hline\hline
		
		\multicolumn{11}{l}{\textsc{PLM-based Models}} \\\hline
		\multicolumn{1}{l|}{\textsc{SciBART-base$^\ddagger$ (124M)}}
		& 0.029 & 0.052 & 0.016 & 0.028 & 0.033 & 0.053 & 0.033 & 0.054 & 0.018 & 0.022 \\ 
		\multicolumn{1}{l|}{\textsc{BART-base$^\ddagger$ (140M)}}
		& 0.022 & 0.042 & 0.010 & 0.017 & 0.026 & 0.042 & 0.028 & 0.049  & 0.016 & 0.021 \\ 
		\multicolumn{1}{l|}{\textsc{T5-base$^\ddagger$ (223M)}}
		& 0.017 & 0.034 & 0.011 & 0.020 & 0.027 & 0.051 & 0.023 & 0.043 & 0.014 & 0.020 \\ 
		
		
		
		\hline\hline
		\multicolumn{11}{l}{\textsc{ChatGPT\ (gpt-3.5-turbo)}} \\\hline
		\multicolumn{1}{l|}{\textsc{ChatGPT w/ \textbf{T\scriptsize{P}}$1^\dagger$}}
		& 0.045 & 0.053 & 0.016 & 0.030 & 0.001 & 0.001 & 0.003 & 0.004 & 0.006 & 0.007 \\
		\multicolumn{1}{l|}{\textsc{ChatGPT w/ \textbf{Tp}$2$}}
		& 0.045 & 0.052 & 0.025 & 0.042 & 0.008 & 0.009& 0.007 & 0.011 & 0.005 & 0.007 \\
		\multicolumn{1}{l|}{\textsc{ChatGPT w/ \textbf{Tp}$3$}}
		& 0.041 & 0.045 & 0.027 & 0.047 & 0.003 & 0.004 & 0.004 & 0.008 & 0.002 & 0.002 \\
		\multicolumn{1}{l|}{\textsc{ChatGPT w/ \textbf{Tp}$4$}}
		& 0.038 & 0.039 & \textbf{0.030} & \textbf{0.041} & 0.009 & 0.012 & 0.011 & 0.015 & 0.004 & 0.005 \\
		\multicolumn{1}{l|}{\textsc{ChatGPT w/ \textbf{Tp}$5$}}
		& 0.036 & 0.026 & 0.017 & 0.015 & 0.004 & 0.005 & 0.006 & 0.005 & 0.004 & 0.004 \\
		\multicolumn{1}{l|}{\textsc{ChatGPT w/ \textbf{Tp}$6$}}
		& 0.041 & 0.025 & 0.029 & 0.024 & 0.009 & 0.009 & 0.005 & 0.009 & 0.005 & 0.006 \\
		
		\hline\hline
	\end{tabular}
	
	\caption{Results of absent keyphrase generation on five datasets. F1 scores on the top 5 and M keyphrases are reported, where M is a variable cut-off equal to the number of predictions. The results of the baselines are reported in their corresponding papers. Specifically, $^\ddagger$ indicates the results are reported in \citet{wudi}. The best results are highlighted in bold.}
	\label{absent}
\end{table*}

\subsubsection{Evaluation Metrics}
Following previous studies \cite{catseq17, adaptive_reward, one2set, wrone2set}, we adopt macro averaged F1@5 and F1@M to evaluate the quality of both present and absent keyphrases. When using F1@5, blank keyphrases are added to make the keyphrase number reach five if the prediction number is less than five. Mainly, we employ the Porter Stemmer to remove the identical stemmed keyphrases.

\subsection{Keyphrase Generation Prompts}
To design the prompts or instructions for triggering the keyphrase generation ability of ChatGPT, we seek inspiration from ChatGPT by asking it for advice. Concretely, we ask ChatGPT with the following instruction:

{{$\bullet$ \ \ \texttt{Provide ten prompts or instructions that can make you collect keyphrases from a given text.}}} 

\noindent and obtain the results in Figure~\ref{prompts}. The generated prompts seem reasonable, as they all involve extracting some core features of the keyphrases. However, we found that using these prompts to ask ChatGPT, what we got was not a list of keyphrases but something like a summary. Fortunately, OpenAI provides an official prompt on how to extract keywords. Based on this instruction, we extend it to six different candidate prompts, as shown in Table~\ref{case}. Specifically, we expect to analyze ChatGPT's understanding of several of the following through these six prompts:
\begin{itemize}
	\item[1.] \textit{What is the difference between “keyword” and “keyphrase” ?}
	
	From the results in Table~\ref{present}, it seems that ChatGPT does not have a gap in the understanding between "keyword" and "keyphrase".
	
	\item[2.] \textit{What is the difference between “extract” and “generate” ?}
	
	As you can see from Table~\ref{dup}, the prompts using “generate” (e.g., $\textsc{\textbf{Tp}2}$ and $\textsc{\textbf{Tp}4}$) predict more absent keyphrases than the prompts using “extract” (e.g., $\textsc{\textbf{Tp}1$^\dagger$}$ and $\textsc{\textbf{Tp}3}$) when chatting with ChatGPT. This shows that ChatGPT makes a distinction between present and absent keyphrases.
	
	\item[3.] \textit{What is the difference between “present keyphrase” and “absent keyphrase” ?}
	
	Figure~\ref{present_absent} illustrates the answer of ChatGPT to this question.
	From the results, we find that ChatGPT distinguishes between present and absent keyphrases. When explicitly asked in the instruction to generate present and absent will significantly increase the number of generated absent keyphrases by ChatGPT. More importantly, we find that ChatGPT is really not good at generating absent keyphrases in this report.
	
	\begin{figure}
		\centering
		\includegraphics[scale=0.35]{present_absent.png}
		\caption{The answer of ChatGPT about the difference between “present keyphrase” and “absent keyphrase”.}
		\label{present_absent}
	\end{figure}
\end{itemize}

\subsection{Multi-domain Keyphrase Generation}
To verify the adaptability of ChatGPT under different domain documents, we tested it on the OpenKP dataset. The results show that ChatGPT is highly adaptable to multi-domain data and performs better than the state-of-the-art keyphrase extraction baselines. 


%\subsection{Keyphrase Generation Robustness}
%This report synthesizes the capability of ChatGPT in keyphrase generation with \textit{different prompts} as trigger to handle \textit{different domains} and \textit{documents of different lengths} to verify its robustness.

\begin{table}[t!]
	\begin{center}
		\scriptsize
		\renewcommand\arraystretch{1.5}
		\renewcommand\tabcolsep{4pt}
		\begin{tabular}{l|ccc|ccc}
			\hline \hline 
			
			\multirow{2}{*}{\normalsize \textbf{{Model}}} & \multicolumn{3}{c|}{\textsc{\textbf{KP20k}}} & \multicolumn{3}{c}{\textsc{\textbf{SemEval}}} \\ \cline{2-7}
			& \#PK & \#AK & Dup  & \#PK & \#AK & Dup  \\ \hline
			\textbf{\color{red}\textsc{Oracle}}  &  \textbf{\color{red}\textsc{3.31}}  & \textbf{\color{red}\textsc{1.95}} & \textbf{\color{red}\textsc{0.000}}  &  \textbf{\color{red}\textsc{6.12}}  & \textbf{\color{red}\textsc{8.31}} & \textbf{\color{red}\textsc{0.000}} \\\hline
			
			
			\multicolumn{1}{l|}{\textsc{SetTrans}}  &  \textbf{5.10}  & \textbf{2.01} & 0.080  &  4.62  & 2.18 & 0.080 \\
			\multicolumn{1}{l|}{\textsc{WR-SetTrans}}  &  6.35  & 3.26 & 0.100  &  \textbf{5.94}  & \textbf{3.60} & 0.100 \\\hline
			\multicolumn{1}{l|}{\textsc{ChatGPT w/ \textbf{Tp}$1^\dagger$}}
			& 14.14 & 5.58 & \textbf{0.005} & 24.53 & 1.06 & \textbf{0.009} \\
			\multicolumn{1}{l|}{\textsc{ChatGPT w/ \textbf{Tp}$2$}}
			& 16.29 & 6.33 & 0.006 & 21.78 & 1.66 & 0.013
			\\
			\multicolumn{1}{l|}{\textsc{ChatGPT w/ \textbf{Tp}$3$}}
			& 13.02 & 6.99 & 0.024 & 22.48 & 2.07 & 0.009 \\
			\multicolumn{1}{l|}{\textsc{ChatGPT w/ \textbf{Tp}$4$}}
			& 13.29 & 7.92 & \textbf{0.005} & 11.97 & 3.65 & 0.006 \\
			\multicolumn{1}{l|}{\textsc{ChatGPT w/ \textbf{Tp}$5$}}
			& 12.00 & 14.36 & 0.027 & 20.48 & 7.74 & 0.020 \\
			\multicolumn{1}{l|}{\textsc{ChatGPT w/ \textbf{Tp}$6$}}
			& 9.68 & 13.09 & 0.279 & 17.24 & 8.40 & 0.040 \\
			
			\hline\hline
		\end{tabular}
	\end{center}
	\caption{\label{dup} Number and duplication ratio of predicted keyphrases on three datasets. “\#PK” and “\#AK” are the average number of unique present and absent keyphrases respectively. “Dup” refers to the average duplication ratio of predicted keyphrases. “Oracle” refers to the gold average keyphrase number.}
\end{table}
\subsection{Keyphrase Generation Diversity}
To investigate the ability of ChatGPT to generate diverse keyphrases, we measure the average numbers of unique present and absent keyphrases and the average duplication ratio of all the predicted keyphrases following recent studies \cite{one2set, wrone2set}. The results are reported in Table 4. Based on the results, ChatGPT generates more unique keyphrases than all baselines by a large margin and achieves a significantly lower duplication ratio without additional hyper-parameter settings.
\subsection{Long Document Understanding}
Handling long documents is challenging in many natural language processing tasks, often with complex contexts in long documents. Similarly, effectively understanding long documents is an urgent challenge in keyphrase generation. Most of the existing keyphrase extraction baselines \cite{baseline, song2021importance, hypermatch} need to truncate the input documents to require the input limitations of the used backbone (e.g., BERT \cite{bert}), which leads to a large amount of information loss. Meanwhile, extracting keyphrases that are salient to the document meanings is an essential step to semantic document understanding. Therefore, we tested the effect of ChatGPT on understanding long documents, as shown in Table~\ref{extraction}. From the results, we find that ChatGTP can understand long documents well. Later we will choose some longer documents (e.g., a document contains approximately 4096 words) as test documents.




\begin{table}[!htb]
	\scriptsize
	\centering
	\renewcommand\tabcolsep{4pt}
	\renewcommand\arraystretch{1.5}
	\begin{tabular}{c|cc}
		\hline\hline
		\multirow{2}{*}{\normalsize \textbf{\textsc{Model}}} & \multicolumn{2}{c}{\textsc{\textbf{OpenKP}}} \\ %\cline{2-2} 
		 & \textbf{F1@3} & F1@5 \\ \hline
		
		\multicolumn{3}{l}{\textsc{PLM-based Models}} \\\hline
		
		\multicolumn{1}{l|}{\textsc{JointKPE (BERT-Base) \cite{baseline}}}
		 & 0.376 & 0.325   \\ 
		%\multicolumn{1}{l|}{\textsc{JointKPE (SpanBERT-Base) \cite{baseline}}}
		 %& 0.385 & 0.336  \\ 
		\multicolumn{1}{l|}{\textsc{JointKPE (RoBERTa-Base) \cite{baseline}}}
		 & 0.391 & 0.338  \\
		\multicolumn{1}{l|}{\textsc{HyperMatch \cite{hypermatch}}}
		 & \textbf{0.394} & 0.338  \\ 
		\multicolumn{1}{l|}{\textsc{KIEMP \cite{song2021importance}}}
		 & 0.392 & 0.340   \\
		\hline\hline
		
		\multicolumn{3}{l}{\textsc{ChatGPT\ (gpt-3.5-turbo)}} \\\hline
		%\multicolumn{1}{l|}{\textsc{ChatGPT w/ \textbf{T\scriptsize{P}}$1^\dagger$}}
		%& 0.045 & 0.053 & 0.016  \\
		\multicolumn{1}{l|}{\textsc{ChatGPT w/ \textbf{Tp}$3$}}
		& 0.287 & \textbf{0.436}   \\
		
		
		\hline\hline
	\end{tabular}
	
	\caption{Results of present keyphrase generation on the OpenKP dataset. F1@3 is the main evaluation metric for this dataset \cite{xiong19}. The results of the baselines are reported in their corresponding papers. The best results are highlighted in bold.}
	\label{extraction}
\end{table}


\section{Conclusion}
This report presents a preliminary study of ChatGPT for the keyphrase generation task, including keyphrase generation prompts, keyphrase generation diversity, multi-domain keyphrase generation, and long document understanding.
The results from the Inspec dataset in Table~\ref{present} and Table~\ref{absent} show that ChatGPT has a strong keyphrase generation capability. It just needs to design better prompts to guide it. Therefore, in the following section, we list several aspects not considered in this report and argue that these may affect the keyphrase generation performance of ChatGPT.

\section{Limitations}
We admit that this report is far from complete with various aspects to make it more reliable.
\subsection{Powerful Prompt Designing}
Generally, when chatting with ChatGPT, the design of prompts can largely influence the results it gives. In this report, we make some improvements based on the prompts given by OpenAI, but they are not necessarily optimal. Therefore, designing more appropriate prompts is the key to effectively exploiting the performance of ChatGPT on the task of keyphrase generation.

\subsection{Hyper-Parameter Settings}
In realistic scenes, users may not care about setting hyper-parameters of ChatGPT when chatting with ChatGPT. Meanwhile, the settings of the hyper-parameters typically require prior knowledge about ChatGPT. Therefore, we do not consider setting different hyper-parameters in this report, which affected the keyphrase generation performance of ChatGPT. Next, we will further consider the corresponding hyper-parameters of ChatGPT to verify its performance on the keyphrase generation task and give a more detailed analysis.

\subsection{Few-Shot Prompting}
With the increasing power of large language models, in-context learning has become a new paradigm for natural language processing \cite{icl}, where large language models make predictions only based on contexts augmented with a few examples. It has been a new trend to explore in-context learning to evaluate and extrapolate the ability of large language models (e.g., the emergent ability \cite{emergent}). In this report, we do not consider using some strategies to explore the ability of ChatGPT. In the future direction, we believe it is possible to enhance the performance of large language models in the keyphrase generation task through similar methods. 

\subsection{Evaluation Metric} 
Previous studies \cite{catseq17, one2set} have mainly used extensions of standard F1-based metrics to measure the performance of keyphrase generation models. Such evaluation metrics usually operate based on exact matches between predicted and gold keyphrases. Such a strategy cannot account for partial matches or semantic similarity. For example, if the prediction is "keyphrase generation model" and the gold is "keyphrase generation system", despite both semantic similarity and partial matching, the score will be 0. These minor deviations are ubiquitous in keyphrase generation yet harshly penalized by the "exact match" evaluation metrics. Therefore, a semantic-based evaluation metric may be more suitable to measure the performance of ChatGPT on the keyphrase generation task. Furthermore, human evaluation can provide more insights for comparing ChatGPT with keyphrase generation baselines.

\bibliography{anthology}
\bibliographystyle{acl_natbib}
\end{document}
