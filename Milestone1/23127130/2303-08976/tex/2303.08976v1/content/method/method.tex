
%\section{Interoperability layer}
%\subsection{Input specification}
%\subsection{Output specification}

%\section{Architecture}
\iffalse
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{content/results/figures/method/BAT-flow-objective-function-oriented.png}
    \caption{Objective function-oriented tuners}
    \label{fig:my_label}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{content/results/figures/method/BAT-flow-program-oriented.png}
    \caption{Program-oriented tuners}
    \label{fig:my_label}
\end{figure}
\fi
%\subsection{Capabilities}

%One way to handle constraints for autotuners that do not have built-in constraint support is for BAT's kernel runner to check that the configuration satisfies the constraints before running it. However, this approach has the drawback that autotuners such as OpenTuner and SMAC3 (only the older SMAC2 supports this) may have poor performance when searching in spaces where large parts of the space are invalid. 


%To solve this problem it's possible to use alternate representations of the search space, such as the Chain of Trees (CoT) proposed by Rasch et al.~\cite{rasch_efficient_2021}. This representation encodes the relation between feasible values for the parameters as trees and traverses these trees to find configurations to be tested. This format allows for both efficient generation, traversal and storage of constrained search spaces. Hellsten et al.~\cite{hellsten_baco_2022} developed this idea further by proposing to sample uniformly over the leaves of the trees instead of traversing from the root. This change in sampling technique avoids the inherit bias of the original sampling technique.

% Another approach is to embed the constraints into the search space by transforming the representation of the search space. Then this new search space can be passed to the autotuner and then the result can mapped back into the original search space.
%Handling constraints for autotuners that do not have built-in constraints supports.
%The most basic way is for BAT's kernel runner to check that the configuration satisfies the constraints before running it. If it does not then this does not count towards the function evaluation-based budget. However, this has the drawback that autotuners that do not support constraints nativly, e.g. OpenTuner and SMAC3(only the older SMAC2 appears to support this), could have severe performance degradation for search spaces where large parts of the search space is invalid.

\section{Benchmarks}

\subsection{GEMM}

Generalized dense matrix-matrix multiplication (GEMM) is part of the BLAS linear algebra 
specification, and is one of the most widely-used GPU kernels. 
The GEMM kernel included in BAT is from CLBlast~\cite{clblast}, a tunable OpenCL BLAS library.
GEMM implements the multiplication of two matrices, $A$ and $B$:
\begin{equation}\nonumber
C = \alpha A \cdot B + \beta C
\end{equation}
%
where $\alpha$ and $\beta$ are scalars and $C$ is the output matrix. 
The CLBlast GEMM kernel is tunable with the parameters shown in Table~\ref{tab:gemm-parameters}.  \verb|MWG| and \verb|NWG| control the amount of work assigned to each thread block. \verb|MDIMC| and  \verb|NDIMC| describe the size of thread block, while \verb|MDIMA| and \verb|MDIMB| control shared memory usage, \verb|VWM| and \verb|VWN| are the vector widths used for loading from and storing to global memory, and \verb|SA| and \verb|SB| enables or disables the use of shared memory for elements in $A$ and $B$.

\begin{table}[ht]
    \caption{Tunable parameters -- GEMM kernel in BAT.}
    \centering
    \begin{tabular}{l|l|l}
    \toprule
    Parameter & Values & \# \\
    \midrule
 \verb|MWG|  & $\{$16, 32, 64, 128$\}$ & 4 \\
 \verb|NWG|  & $\{$16, 32, 64, 128$\}$ & 4 \\
 \verb|MDIMC|  & $\{$8, 16, 32$\}$ & 3 \\
 \verb|NDIMC|  & $\{$8, 16, 32$\}$ & 3 \\
 \verb|MDIMA|  & $\{$8, 16, 32$\}$ & 3 \\
 \verb|NDIMB|  & $\{$8, 16, 32$\}$ & 3 \\
 \verb|VWM|  & $\{$1, 2, 4, 8$\}$ & 4 \\
 \verb|VWN|  & $\{$1, 2, 4, 8$\}$ & 4 \\
 \verb|SA|  & $\{$0, 1$\}$ & 2 \\
 \verb|SB|  & $\{$0, 1$\}$ & 2 \\
 \bottomrule
    \end{tabular}
    \label{tab:gemm-parameters}
\end{table}


\subsection{N-body}

The N-body kernel computes gravitational forces between N bodies, typically applied in astrophysical simulations. The N-body kernel in BAT was created by Petrovi\v{c} et al. for use in KTT~\cite{petrovic_benchmark_2019}, as a tunable implementation of the code sample from the CUDA SDK. 
The N-body kernel follows a simple quadratic scheme where the forces between all pairs of bodies are computed every iteration. As such, the kernel is very compute intensive. 

The tunable parameters for the N-body kernel in BAT are shown in Table~\ref{tab:nbody-parameters}. 
The inner loop unroll factor parameters determine the degree to which partial loop unrolling is applied for various loops in the kernel. The \verb|outer_unroll_factor| controls the amount of work allocated to each thread. The \verb|use_soa| parameter specifies whether the input bodies are stored in an array of structures or a structure of arrays. \verb|local_mem| enables or disables the use of shared memory as a software managed cache. \verb|vector_type| is to control the number of elements loaded from memory in one instruction.
\begin{table}[ht]
    \caption{Tunable parameters -- Nbody kernel in BAT.}
    \centering
    \begin{tabular}{l|p{3cm}|l}
    \toprule
    Parameter & Values & \# \\
    \midrule
\verb|block_size| & $\{$64, 128, 256, 512$\}$ & 4 \\
\verb|outer_unroll_factor| & $\{$1, 2, 4, 8$\}$ & 4 \\
\verb|inner_unroll_factor1| & $\{$0, 1, 2, 4, 8, 16, 32$\}$ & 7 \\
\verb|inner_unroll_factor2| & $\{$0, 1, 2, 4, 8, 16, 32$\}$ & 7 \\
\verb|use_soa| & $\{$0, 1$\}$ & 2 \\
\verb|local_mem| & $\{$0, 1$\}$ & 2 \\
\verb|vector_type| & $\{$1, 2, 4$\}$ & 3 \\
 \bottomrule
    \end{tabular}
    \label{tab:nbody-parameters}
\end{table}



%\subsection{TRIAD}

\subsection{Hotspot}

The Hotspot kernel included in BAT is based on the Hotspot kernel in the Rodinia Benchmark suite~\cite{che_rodinia_2009}. 
The %Hotspot 
kernel is part of a thermal simulation application used to estimate processor temperature based on processor architecture
and simulated power currents. The kernel iteratively solves a series of differential equations. The kernel inputs are the power and initial temperatures, the output is a grid of average temperature values spanning the chip.

% *** reorder  We have re-implemented the Hotspot kernel in Rodinia from scratch to simplify the indexing scheme and increase the tunability of the kernel. 
To simplify the indexing scheme and increase the tunability of the kernel, we have re-implemented the Hotspot kernel in Rodinia from scratch. 
The main difference of our implementation with that of Rodinia is that our kernel can be used with any thread block dimension, can arbitrarily vary the amount of work per thread, and vary the extent to which temporal tiling is applied.

The tunable parameters for the Hotspot kernel in BAT are shown in Table~\ref{tab:hotspot-parameters}. 
\verb|block_size_x| and \verb|block_size_y| describe the thread block dimensions in x and y, the kernel uses at least 32 and at most 1024 threads.
\verb|tile_size_x| and \verb|tile_size_y| control the number of output elements computed by each thread in the x and y dimensions. \verb|temporal_tiling_factor| is the number of iterations of the stencil operation performed by a single kernel launch, for more details on the temporal tiling optimization see Hijma et al.~\cite{hijma2022}. \verb|sh_power| enables or disables the use of shared memory as a cache for storing the input power currents. \verb|blocks_per_sm| is used in the \verb|__launch__bounds()| directive in CUDA to hint the compiler to aim for a certain occupancy when running the kernel, effectively this optimization encourages the compiler to decrease register usage in the kernel.

\begin{table}[ht]
    \caption{Tunable parameters -- Hotspot kernel in BAT.}
    \centering
    \begin{tabular}{l|p{3cm}|l}
    \toprule
    Parameter & Values & \# \\
    \midrule
\verb|block_size_x| & $\{1,2,4,8,32n \mid 32n \in [32, 1024] \}$ & 37 \\
%\verb|block_size_x| & $\{$1, 2, 4, 8, 16, 32, 64, 96, 128, 160, 192, 224, 256, 288, 320, 352, 384, 416, 448, 480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800, 832, 864, 896, 928, 960, 992, 1024$\}$ & 37 \\
\verb|block_size_y| & $\{$1, 2, 4, 8, 16, 32$\}$ & 6 \\
\verb|tile_size_x| & $\{$n $\mid$ n $\in$ [1, 10] $\}$& 10 \\
\verb|tile_size_y| & $\{$n $\mid$ n $\in$ [1, 10] $\}$& 10 \\
%\verb|tile_size_x| & $\{$1, 2, 3, 4, 5, 6, 7, 8, 9, 10$\}$ & 10 \\
%\verb|tile_size_y| & $\{$1, 2, 3, 4, 5, 6, 7, 8, 9, 10$\}$ & 10 \\
\verb|temporal_tiling_factor| & $\{$n $\mid$ n $\in$ [1, 10] $\}$& 10 \\
\verb|loop_unroll_factor_t| & $\{$n $\mid$ n $\in$ [1, 10] $\}$& 10 \\
\verb|sh_power| & $\{$0, 1$\}$ & 2 \\
\verb|blocks_per_sm| & $\{$0, 1, 2, 3, 4$\}$ & 5 \\
 \bottomrule
    \end{tabular}
    \label{tab:hotspot-parameters}
\end{table}

\subsection{Pnpoly}
% The PnPoly implementation that I found in Richard's repository also contained host-side code. So I analyzed PnPoly, but have not formally implemented PnPoly as part of BAT for this reason. 

% Great, I can try to implement it like that then. (without that parameter)
% Thank you for the help with the paper! - my pleasure! :-)
% Right! I suppose you could use it without the 'use-precomputed-slopes' parameter. That's the only one that is shared between host and device. If you remove that one it could be used as an all-device-code kernel if you like. 

% Ok great!

Pnpoly (Point-in-polygon) kernel is used by Goncalves et al.~\cite{goncalves2016spatial} as part of a geospatial database system for massive point clouds obtained through airborne LiDAR. The kernel is used to query all points within a certain outline, for example points on highways or all points within a city.
Pnpoly has been used as a benchmark kernel for autotuning in several studies~\cite{willemsen_bayesian_2021, schoonhoven2022benchmarking}. However, the Pnpoly kernel in BAT includes only the GPU kernel of the full GPU-enabled database operator. 

The tunable parameters of the Pnpoly kernel in BAT are listed in Table~\ref{tab:pnpoly-parameters}.
\verb|block_size_x| is simply the number of threads per block. \verb|tile_size| the amount of points processed by each thread. \verb|between_method| selects the algorithm to use to see if a point lies between two other points. Similarly, \verb|use_method| selects the algorithm that is used to keep track of whether the evaluated point is inside or outside of the polygon.
\begin{table}[ht]
    \caption{Tunable parameters -- Pnpoly kernel in BAT.}
    \centering
    \begin{tabular}{l|p{3cm}|l}
    \toprule
    Parameter & Values & \# \\
    \midrule
\verb|block_size_x|  & $\{ 32n | 32n \in [32, 1024] \}$ & 31 \\
%, 64, 96, 128, 160, 192, 224, 256, 288, 320, 352, 384, 416, 448, 480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800, 832, 864, 896, 928, 960, 992, 1024$\}$ & 31 \\

%\verb|block_size_x|  & $\{$32, 64, 96, 128, 160, 192, 224, 256, 288, 320, 352, 384, 416, 448, 480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800, 832, 864, 896, 928, 960, 992, 1024$\}$ & 31 \\
 %\verb|tile_size|  &  $\{$1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20$\}$ & 11 \\
 \verb|tile_size|  & $\{ 1, 2n | 2n \in [2, 20] \}$ & 11 \\
 \verb|between_method| & $\{0, 1, 2, 3\}$ & 4 \\
 %\verb|use_precomputed_slopes| & $\{0, 1\}$ & 2 \\
 \verb|use_method| & $\{0, 1, 2\}$ & 3 \\
 \bottomrule
    \end{tabular}
%    \caption{BAT: Tunable parameters for the Pnpoly kernel.}
    \label{tab:pnpoly-parameters}
\end{table}

\subsection{Convolution}

Van Werkhoven et al.~\cite{vanWerkhoven2014optimizing}
have implemented an optimized and highly-tunable GPU-accelerated 
library for 2D Convolution operations, which has become a commonly used benchmark in autotuning~\cite{nugteren_cltune:_2015,petrovic_benchmark_2019,kerneltuner,schoonhoven2022benchmarking}.

A convolution operation computes a linear combination of weights and a range of the input 
image for each output pixel. A 2D convolution of an input image $I$ of size 
$(w\times h)$ and a convolution filter $F$ of size $(F_w\times F_h)$ computes 
an output image $O$ of size $((w-F_w)\times (h-F_h))$:
\begin{equation}\nonumber
O(x,y) = \sum\limits_{j=0}^{F_h} \sum\limits_{i=0}^{F_w} I(x+i,y+j)\times F(i,j)
\end{equation}

The tunable parameters of the Convolution kernel in BAT are listed in Table~\ref{tab:convolution-parameters}.  \verb|block_size_x| and \verb|block_size_y| describe the thread block dimensions, \verb|tile_size_x| and \verb|tile_size_y| the number of output pixels processed by each thread in the x and y dimensions.  \verb|use_padding| controls whether or not to use the padding scheme in shared memory that is used to avoid shared memory bank conflicts as described in Van Werkhoven et al.~\cite{vanWerkhoven2014optimizing}. Padding is only significant when the \verb|block_size_x| is not a multiple of number of memory banks in shared memory. Finally, \verb|read_only| controls whether or not to load input elements from global memory through read-only cache. 
\begin{table}[ht]
    \caption{Tunable parameters -- Convolution kernel in BAT.}
    \centering
    \begin{tabular}{l|p{3cm}|l}
    \toprule
    Parameter & Values & \# \\
    \midrule
 \verb|block_size_x|  & $\{$1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 112, 128$\}$ & 12 \\
\verb|block_size_y|  & $\{1, 2, 4, 8, 16, 32\}$ & 6 \\
 \verb|tile_size_x|  & $\{1, 2, 3, 4, 5, 6, 7, 8\}$ & 8 \\
 \verb|tile_size_y|  & $\{1, 2, 3, 4, 5, 6, 7, 8\}$ & 8 \\
 \verb|use_padding|  & $\{0, 1\}$ & 2 \\
 \verb|read_only|  & $\{0, 1\}$ & 2 \\
 \bottomrule
    \end{tabular}
    \label{tab:convolution-parameters}
\end{table}

\subsection{Expdist}

The Expdist kernel is part of a localization microscopy applications that implements a template-free particle fusion algorithm by combining many different observations into a single super-resolution reconstruction~\cite{heydarian2018template}. The expdist kernel is used as part of the registration process where the kernel is called repeatedly to quantify the registration of two particles. The distance between two particles $t$ and $m$, given registration $M$, is computed as follows:
\begin{equation*}
D = \sum\limits_{i=1}^{K_t} \sum\limits_{j=1}^{K_m} \textrm{exp}\left( - \frac{\|\vec{x}_{t,i} - M(\vec{x}_{m,j})\|^2 }{ 2\sigma^2} \right)
\end{equation*}
The kernel operates directly on the individual localizations ($\vec{x_t}$ and $\vec{x_m}$) in each particle rather than pixelated images and takes the uncertainties in the localizations ($\sigma$) into account. The algorithm is quadratic in the number of localizations per particle and is as such very compute intensive.

The tunable parameters used in the ExpDist kernel are shown in Table~\ref{tab:expdist-parameters}.
The kernel supports two main implementations that are controlled by the \verb|use_column| parameter. When \verb|use_column| is set to 1, the kernel reduces the number of thread blocks used to perform the computation by using a fixed number of thread blocks in the y dimension, set by \verb|n_y_blocks|. \verb|use_shared_mem| use shared memory selects the way in which shared memory is used.
\begin{table}[ht]
    \caption{Tunable parameters -- ExpDist kernel in BAT.}
    \centering
    \begin{tabular}{l|p{3cm}|l}
    \toprule
    Parameter & Values & \# \\
    \midrule
\verb|block_size_x| & \{32, 64, 128, 256, 512, 1024\} & 6 \\
\verb|block_size_y| & \{1, 2, 4, 8, 16, 32\} & 6 \\
\verb|tile_size_x| & \{1, 2, 3, 4, 5, 6, 7, 8\} & 8 \\
\verb|tile_size_y| & \{1, 2, 3, 4, 5, 6, 7, 8\} & 8 \\
\verb|use_shared_mem| & \{0, 1, 2\} & 3 \\
\verb|loop_unroll_factor_x| & \{1, 2, 3, 4, 5, 6, 7, 8\} & 8 \\
\verb|loop_unroll_factor_y| & \{1, 2, 3, 4, 5, 6, 7, 8\} & 8 \\
\verb|use_column| & \{0, 1\} & 2\\
\verb|n_y_blocks| & \{1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024\} & 11 \\
 \bottomrule
    \end{tabular}
    \label{tab:expdist-parameters}
\end{table}


\subsection{Dedispersion}

The Dedispersion kernel in BAT originates from the AMBER pipeline for the detection of single pulse astronomical transients~\cite{sclocco2020amber}.
Dedispersion is the process of reverting the dispersion of a radio signal transmitted over many frequencies through space. 
The signal component with the highest frequency $f_h$ is received at time $t_x$, while simultaneously emitted components with lower frequency arrive at $t_x + k$, where $k$ is the delay in seconds as by the dispersion equation:
\begin{equation*}
    k \approx 4150 \times DM \times \left( \frac{1}{f_i^2} \times \frac{1}{f_h^2} \right)
\end{equation*}

The kernel takes samples in time across many frequency bands (channels) as input and outputs the dedispersed samples for many different dispersion measure $DM$ values. The kernel is parallelized such that each thread can work on multiple samples and dispersion measures, while iterating over the frequency bands. As input for the BAT Dedispersion kernel, we are using the parameters from the ARTS survey on the Apertif telescope~\cite{van2022apertif}, which uses a sampling rate of 24.4 KHz, 2048 DMs, and 1536 channels.

The tunable parameters of the dedispersion kernel are shown in Table~\ref{tab:dedisp-parameters}. 
The \verb|loop_unroll_factor_channel| parameter depends on the input, as any divisor of the number of channels can be used as a partial loop unrolling factor for the inner loop in the kernel. When the loop unroll factor is 0, it is left to the CUDA compiler to decide whether or not to apply loop unrolling. \verb|tile_stride_x| controls the stride used to vary the amount of work per threads. When \verb|tile_stride_x| is 0 and \verb|tile_size_x| is larger than 1, threads will process \verb|tile_size_x| consecutive samples, when \verb|tile_stride_x| is 1 threads will process \verb|tile_size_x| samples that are each \verb|block_size_x| apart in the input. \verb|tile_stride_y| works similarly but for dispersion measures in the y-dimension.
\begin{table}[ht]
    \caption{Tunable parameters -- Dedispersion kernel in BAT.}
    \centering
    \begin{tabular}{l|p{3cm}|l}
    \toprule
    Parameter & Values & \# \\
    \midrule
\verb|block_size_y| & $\{1,2,4,8,16n \mid 16n \in [16, 512] \}$ & 36 \\
%\verb|block_size_x|  & \{1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512\} & 36 \\
\verb|block_size_y|  & $\{4n \mid 4n \in [4,128]\}$ & 32 \\
%\{4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128\} & 32 \\
%\verb|tile_size_x|  & \{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16\} & 16 \\
%\verb|tile_size_y|  & \{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16\} & 16 \\
\verb|tile_size_x|  & $\{ n | n \in [1, 16] \}$ & 16 \\
\verb|tile_size_y|  & $\{ n | n \in [1, 16] \}$ & 16 \\
\verb|tile_stride_x|  & \{0, 1\} & 2 \\
\verb|tile_stride_y|  & \{0, 1\} & 2 \\
\verb|loop_unroll_factor_channel|  & \{0, 1, 2, 3, 4, 6, 8, 12, 16, 24, 32, 48, 64, 96, 128, 192, 256, 384, 512, 768, 1536\} & 21 \\
\verb|blocks_per_sm|  & \{0, 1, 2, 3, 4\} & 5 \\
    \bottomrule
    \end{tabular}
%    \caption{Tunable parameters -- Dedispersion kernel in BAT.}
    \label{tab:dedisp-parameters}
\end{table}



%\input{content/method/setup}
%\input{content/method/framework}