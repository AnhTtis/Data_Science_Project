\section{Methodology}
\subsection{Dataset and Pre-Processing}
Anisotropic 3D T1-weighted data was retrospectively collected from 26 patients. Images were collected in the coronal plane using a volume-interpolated breath-hold (VIBE) sequence, after injection of gadolinium contrast. Whole abdominal coverage was achieved in a breath-hold of $\approx 21$s, with the following parameters: pixel size $\approx 1.3 \times 1.3 \times 6$mm, matrix size $\approx 256 \times 256$ and partitions $\approx 45$.

Each volume was interpolated to create isotropic pixels. Training and validation data were created by extracting 2D slices of size $92 \times 92 \times 92$ pixels, in both the coronal (originally high-resolution in both directions) and sagittal planes (low resolution in the AP-direction). This resulted in a total of 2391 unpaired data sets, which were used for training ($90\%$) and validation ($10\%$). 

\subsection{CycleGAN}
The CycleGAN architecture \cite{ZhuPIE17} (see Fig.\ref{fig:cyclegan_loss}a) is a variant of a Generative Adversarial Network (GAN) that imposes a Cycle-Consistency Loss in order to perform image-to-image translation with unpaired data. Here, the goal of the CycleGAN is to take low-resolution (LR) sagittal images ($X$) and translate them to high-resolution (HR) coronal images ($Y$), through a generator mapping, $G: X \rightarrow Y$.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\textwidth]{fig/cycle_consistency.png}
    \caption{(Adapted from \cite{ZhuPIE17}) (a) Abstracted CycleGAN model architecture, (b) forward Cycle-Consistency Loss, and (c) backward Cycle-Consistency Loss.}
    \label{fig:cyclegan_loss}
\end{figure}

\subsection{Gradient Mapping Cycle-Consistency Loss}
The Cycle-Consistency Loss (Fig.\ref{fig:cyclegan_loss}b and \ref{fig:cyclegan_loss}c) is necessary as the generator mappings $G$ and $F$ are severely under constrained. To mitigate this, an inverse mapping is introduced which enforces $F(G(X)) \approx X$.

In this study we developed a novel Cycle-Consistency Loss (See Equation \ref{eq:cycle_consistent_grad_map}) that works by imposing a ``\emph{Gradient Mapping}" between the gradient maps of input images $(x, y)$ and ``cycled" images $(F(G(x)), G(F(y)))$, respectively \cite{grad_variance_loss}.

\begin{equation}
\begin{aligned}
L_{gmap}(G,F) = \mathbb{E}_{x \sim \text { pdata }} (x)[ \|S_{x}(F(G(x)))-S_{x}(x) \\
+S_{y}(F(G(x)))-S_{y}(x)\|_1 ]\\
+\mathbb{E}_{y \sim \text { pdata }}(y)[ \|S_{x}(G(F(y)))-S_{x} (y)\\+S_{y}(G(F(y)))-S_{y}(y)\|_1 ]\\
\end{aligned}
\label{eq:cycle_consistent_grad_map}
\end{equation}

In Equation \ref{eq:cycle_consistent_grad_map}, $S_x$ and $S_y$ denote the $x$ and $y$ gradients acquired using a Sobel Operator and $||\cdot||_{1}$ denotes an $L_{1}$ loss. The final loss function is then defined as follows:

\begin{equation}
\begin{aligned}
\mathcal{L}_{\text {total}}(G, F) &=\lambda_{cyc} L_{cyc} + \lambda_{gmap}L_{gmap},
\label{eq:final_loss}
\end{aligned}
\end{equation}

where $L_{cyc}$ denotes the original Cycle-Consistency Loss from \cite{ZhuPIE17} and $\lambda_{cyc}, \lambda_{gmap}$ denote loss weights for the Cycle-Consistency and Gradient Mapping losses respectively.

\subsection{Patch Reconstruction Algorithm}

The trained network can be applied to unseen prospective data which is not of fixed size (examples of these full-size images are shown on the left of each image pair in Fig. \ref{fig:output_ims_saggital}). To reconstruct a full 2D slice of shape $m \times n$, we use an overlapping patch reconstruction algorithm. Each overlapping patch is passed through our network to produce a corresponding HR patch of the same size. These patches are then stitched together to produce an unnormalised reconstructed HR image from the overlapping patches. 

%After the network has been trained on small $92 \times 92$ patches, it can be applied to unseen prospective data which is not of fixed size (examples of these full-size images are shown on the left of each image pair in Fig. \ref{fig:output_ims_saggital}). To reconstruct a full 2D slice of shape $m \times n$, we use an overlapping patch reconstruction algorithm. A full-size slice $I_{LR}$ is split into patches of size $92 \times 92$ to match the input size to our model. We then stride each patch $S$ pixels across the entire image based on a \emph{stride factor} $S_{f}$: 
%\begin{equation}
%\begin{aligned}
%S = \frac{D_{p}}{S_{f}},
%\label{eq:patch_algo}
%\end{aligned}
%\end{equation}

%where $S$ is the stride, $D_{p}$ is the square patch dimension (in this case it is $92$) and $S_{f}$ is the stride factor, which is a scalar chosen to be $16$ for our images. Each overlapping patch is passed through our network to produce a corresponding HR patch of the same size. These patches are then stitched together to produce an unnormalised reconstructed image $I_{HR}$ from the overlapping patches.

%Finally, we acquire the matrix $M$ which has shape $m \times n$ to match $I_{HR}$, consisting of values $\frac{1}{x_{i,j}}$, where $x_{i,j}$ corresponds to the number of times each pixel $(i,j)$ was overlapped by patches. Finally, we take the Hadamard product $I_{HR} \odot M$ to generate our normalised image $I_{Norm}$ (see Figure \ref{fig:output_ims_saggital} for images).

\subsection{Quantitative Metric}

Quantitative image quality was measured by calculating edge sharpness (ES) and the Perception Based Image Quality Evaluator (PIQUE) \cite{pique} (as a no-reference image quality score). ES was calculated by measuring the maximum gradient of the pixel intensities across the border of the bladder \cite{MES}. 

\subsection{Qualitative Metric}
Qualitative image scoring was performed by two MR specialists (VM and JS) in one sitting. Three sagittal slices were extracted for the original data (high resolution in HF dimension, and low resolution in the AP dimension), and for the super-resolved data. \\

Images were viewed in a random order and scored in two categories: 

\begin{enumerate}
    \item Global image quality (sharpness and delineation of anatomic features) 
    \item Image artefacts (observersâ€™ confidence that any artefacts aren't hallucinated)
\end{enumerate}

For all categories, a 5-point Likert scale was used, with 1 = poor (non-diagnostic) and 5 = excellent (diagnostic).
