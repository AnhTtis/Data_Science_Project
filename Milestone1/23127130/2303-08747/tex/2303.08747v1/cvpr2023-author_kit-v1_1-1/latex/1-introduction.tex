% !TEX root=main.tex

\section{Introduction}
\label{sec:introduction}
\begin{figure}[t]
  \centering
  \includegraphics[height=6.7cm, width=0.49\textwidth]{images/base_diagram.png} 
  \caption{Overview of our proposed Cascaded Zoom-in detector. During training (top), density crops are extracted, and labeled as a new class (red boxes) on the original image. The training set is augmented with the rescaled density crops and the corresponding ground truth boxes within these crops. During the first stage of inference (bottom), the base class objects and density crops (red boxes) are detected on the whole image. In the second stage, the density crops are rescaled to a common larger size, and a second inference is performed. Finally, the detections on density crops are combined with the detections on the whole image.}
  \label{fig:base_daigram}
\end{figure}

With the advent of deep learning, object detection methods achieved significant progress \cite{fpn-Lin-2017, detr-Carion-2020, cascadercnn-Cai-2018, fcos-Tian-2019, faster_rcnn-Ren-2015, yolo_9000-Redmon-2017}. This has resulted in the fast growth of their adoption to many downstream applications, including aerial images captured with Drones or Satellites, for earth monitoring, surveillance, inspection, etc \cite{geobench-Alex-2021, xia-DOTA-2018, aerial1-Cheng-2016, aerial2-Han-2021, remote_sense-Long-2017}. However, unlike natural images in the Pascal VOC \cite{voc-Everingham-2010} and MS-COCO \cite{mscoco-Lin-2014} datasets, aerial images are captured in high resolution, and are typically comprised of many small objects, that are sparsely distributed in crowded object regions. As a comparison, the average number of objects in Pascal VOC and MS-COCO images are 3 and 7, respectively, whereas images in the VisDrone \cite{zhu-VisDrone-2018} and DOTA \cite{xia-DOTA-2018} datasets -- two popular benchmarks in the aerial detection community -- have an average number of 53 and 67 objects, respectively. The average width of Pascal VOC and MS-COCO images are 500 and 640 pixels, respectively, while  the same in VisDrone and DOTA images are 1500 and 4000 pixels, respectively. Therefore, improvements observed in object detection methods applied to natural images do not easily translate to object detection in high-resolution aerial images.

\begin{figure*}[h!]
  %\centering
  \hspace{1cm}
  \includegraphics[height=7.4cm, width=0.9\textwidth]{images/main_diagram.png} \\
  %\hspace{1cm}
  \begin{tabular}{@{\hspace{+1.3cm}} l @{\hspace{+1.1cm}} l  @{\hspace{1.3cm}} l @{\hspace{+2.3cm}} l}%{cccc}
     (a) Baseline & (b) Uniform crops & (c) Density crops & (d) Our approach \\
  \end{tabular}
  \caption{An illustration of different approaches for the detection of small objects in high-resolution aerial images. (a) The image is down-scaled and processed at the detector's resolution. (b) The image is split into uniform, possibly overlapping crops, and each crop is processed by the detector. (c) An external learnable module crops the image into dense object regions. Each crop is re-scaled and processed at the detector's resolution. (d) Our proposed CZ detector is re-purposed to detect the density crops along with the base class objects, eliminating the need for an external module. Each crop is re-scaled and processed at the detector's resolution in a second stage of inference. Blue arrows show the path of the original image and red shows the path of density crops.}
  \label{fig:main_diagram}
\end{figure*}

The high-resolution imagery and tiny objects raise several challenges for object detection in aerial images, including the loss of information due to rescaling and feature down-sampling, low tolerance to bounding box shifts, and noisy feature representations \cite{sod_survey-Cheng-2022, glsan-Deng-2020} among others. Since it is difficult to input high-resolution aerial images directly to a detector due to the computational cost and large memory footprint, they are often resized to the standard resolution range (see Fig. \ref{fig:main_diagram}~(a)). This rescaling, coupled with the feature down-sampling in ConvNets, often results in feature representations linked to small objects diminished or corrupted by the noisy background activations \cite{querydet-Yang-2022}. Regarding the tolerance to bounding box shifts, a small shift in the bounding box may cause a large decline in the Intersection over Union (IoU), raising the false positive detections \cite{sod_survey-Cheng-2022}. 

To utilize the higher resolution, and also mitigate the information loss, a popular approach consists in cropping the input image into uniform patches, and then performing object detection on these patches in high resolution by upsampling (see Fig. \ref{fig:main_diagram}~(b)). Although these uniform patches help to improve the accuracy, this approach does not respect the distribution of the objects in the image, and hence the scale normalization achieved is not optimal \cite{clusnet-Yang-2019, dmap-Li-2020}. As the objects in aerial images usually appear crowded in sparsely distributed regions of the image, it is desirable to perform density-based cropping, and then process high-resolution versions of those crowded object regions for better scale balance. 

To extract these density crops, existing methods utilizes additional learnable modules (see Fig. \ref{fig:main_diagram}~(c)) such as density maps \cite{dmap-Li-2020}, cluster proposal networks \cite{clusnet-Yang-2019}, global-local detection pipeline \cite{glsan-Deng-2020} etc. This usually results in additional learnable components in the pipeline, often with multiple stages of training. Even with single-stage end-to-end methods, the crops obtained are noisy in the beginning and are only useful for aiding small object detection in the later stages of the training \cite{clusnet-Yang-2019}. Moreover, as the learning is evolving the crops also evolve, so the model is not receiving a consistent indication of what exactly is a "density crop". Thus, practitioners still widely use uniform cropping over the advanced density crop-based approaches due to the practical simplicity it offers \cite{small_obj_detection, tiling_obj_detection}.


In this paper, we tried to bridge this gap between research and practice by proposing an efficient cascaded zoom-in (CZ) detection method that can leverage density crops within the training of a standard detector, offering the simplicity of uniform cropping, yet providing the benefits of density crops(see Fig. \ref{fig:main_diagram}~(d)). We simply make use of the existing detector itself to discover the density crops, by adding the "crop" as a new class to the detector. The crops are labeled as a pre-processing step using a crop labeling algorithm, and hence the detector receives a consistent signal of what constitutes a crop. During inference, while other methods require complex post-processing to filter the noisy crops, we can simply perform it based on the confidence of the "crop" class from the detector.

Fig.~\ref{fig:base_daigram} illustrates the training and testing of our method. First, the density crops are extracted from each training image as a pre-processing step, using our crop labeling algorithm. These density crops are added as a new class to be detected in the corresponding image. Then we augment the training set with the higher resolution version of the density crops, and the corresponding ground truth (GT) boxes of objects inside the crop. Then, the detector is trained as usual. This training process has an almost negligible overhead over standard detector training, and it is similar to that of uniform crop based training. Inference is performed in two stages. In the first stage, the base class objects and density crops are detected from each input image. In the second stage, high-quality density crops are selected based on their confidence score, and another inference based is performed on an up-sampled version of these crops. Finally, the detections from stages one and two are fused to get the output detection. Compared to standard object detector learning, the extra work required at training time is the crop labeling which can be performed as a pre-processing step. While making predictions, the extra work required is one more inference. As both of these processes don't require any significant modification on a normal object detection pipeline, similar to uniform crops, our method can be easily incorporated for accelerating small object detection.

Our main contribution can be summarized as follows:

\noindent \textbf{(1)} An efficient cascaded zoom-in (CZ) object detector based on density cropping is proposed for high-resolution aerial images, where a given detector is re-purposed to extract density crops(thus not using additional modules) along with base class objects. At train time, this approach relies on a simple pre-processing step for density crop labeling, and at test time, an additional inference step is needed to process the predicted density crops.

\noindent \textbf{(2)} We empirically validate the benefits of our cascaded zoom-in detection on aerial images from drones (VisDrone) and satellites (DOTA), and obtain state-of-the-art performance. A consistent improvement in the detection accuracy is observed on both datasets over the baseline detection. Particularly, the mAP of small object detection is improved by more than 3 points.
 
 

%In contrast, our method proposes to use the detector not only to find the classes of interest, but also to accurately localize those regions in the image containing groups of objects. This reduces the complexity of the approach as only an "augmented" detector needs to be trained.  and allows us to use any detector for this approach.
%We initially use the detector at coarse resolution and zoom-in only on the regions that are classified as density crops and need to be further analyzed at higher resolution. This allows a dynamic analysis of the image, in which only the regions with a high probability to contain objects are analyzed at high resolution, reducing the computational time of the method and also possible false positives that would be generated by densely analyzing the image at high resolution.
%In addition to that, they often used overly complex learning algorithms to train those learnable components often as a separate stage from the detector training. In this paper, we propose that scale normalization can be simply achieved by re-purposing the detector with a multi-stage inference. So without any additional learnable components and learning algorithms, we detect the focus regions to adaptively crop and zoom into 

%  \includegraphics[scale=0.57]{images/base_diagram.png} 
%  \includegraphics[height=4cm, width=0.23\textwidth]{images/base_diagram.png} 