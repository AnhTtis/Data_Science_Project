\section{Conclusion}
This paper explored the feasibility of using only box annotations for VIS. We first extended the pixel-supervised VIS methods to a box-supervised VIS (BoxVIS) baseline, and proposed a spatial-temporal pairwise affinity (STPA) loss to introduce temporal pixel-wise mask supervision. Finally, we collected a large scale box-supervised VIS dataset (BVISD). The experimental results showed that with the ResNet50 backbone, the proposed BoxVIS trained on BVISD can yield high-quality object masks with decent spatial and temporal consistency, achieving comparable or even better performance than pixel-supervised VIS methods on YTVIS21 and OVIS. It is a promising direction to further investigate more effective BoxVIS models. 
% Overall, this paper verifies the feasibility of video instance segmentation with only box annotations.