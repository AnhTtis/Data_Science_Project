\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr} 
%\usepackage{iccv}


\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{multirow}
\usepackage{array}
\usepackage{booktabs}
\usepackage{makecell}
\usepackage{float}
\usepackage{diagbox}
\usepackage{changepage}
\usepackage{cuted} % strip
\usepackage{xcolor}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{dsfont}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

\newcommand*{\Scale}[2][4]{\scalebox{#1}{$#2$}}%
\newcommand*{\Resize}[2]{\resizebox{#1}{!}{$#2$}}%

% \iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{2764} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
% \ificcvfinal\pagestyle{empty}\fi

% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Table}{Tables}

\begin{document}

%%%%%%%%% TITLE
\title{BoxVIS: Video Instance Segmentation with Box Annotations}

 \author{{Minghan Li \quad and \quad Lei Zhang\thanks{Corresponding author.} } \\
    	Department of Computing, Hong Kong Polytechnic University  \\
    	{\tt\small liminghan0330@gmail.com, cslzhang@comp.polyu.edu.hk}
    }

\maketitle
% Remove page # from the first page of camera-ready.
%\ificcvfinal\thispagestyle{empty}\fi


%%%%%%%%% ABSTRACT
\input{sec/0_abstract.tex}
\input{sec/1_introduction.tex}
\input{sec/2_related_works_b.tex}
\input{sec/3_methodology.tex}
\input{sec/4_experiments.tex}
\input{sec/5_conclusion}

\newpage
{\small
\bibliographystyle{ieee_fullname}
\bibliography{paper_for_review}
}

\onecolumn
\def\thesection{\Alph{section}}

\vspace{+1cm}
\begin{center}
 {\huge Supplementary Materials}
\end{center}
\vspace{+1cm}

\appendix

In this supplementary file, we provide the following materials:
\begin{itemize}
    \item More visual comparison of pixel-supervised and box-supervised VIS methods ($cf.$ Section 4.2 in the main paper);
    \item More visualization of instance masks predicted by BoxVIS ($cf.$ Section 4.2 in the main paper).
\end{itemize}

\noindent\textbf{A. More visual comparison of pixel-supervised and box-supervised VIS methods}

In Figs. { \color{red} 1} - { \color{red} 3}, we provide more visual comparison results of instance masks predicted by M2F-VIS \cite{cheng2021mask2former-video}, M2F-VIS-box and our BoxVIS on videos with crowded scenes, blurred or occluded objects. It can bee seen that compared to the box-supervised baseline M2F-VIS-box, our BoxVIS can predicate instance masks with better spatial and temporal consistency. On the other hand, BoxVIS can yield instance masks of the same high quality as the pixel-supervised M2F-VIS \cite{cheng2021mask2former-video}.

\

% --------------------------------------------------------------------------------
\noindent\textbf{B. Visualization of instance masks predicted by BoxVIS} 

In \cref{fig:visualizer_yt21} and \cref{fig:visualizer_ovis}, we visualize instance masks predicted by BoxVIS on various videos of YTVIS21 and OVIS, demonstrating the model generalization ability.

\begin{figure*}[h]
    \centering
    \includegraphics[width=0.98\textwidth]{figs/fig/multi_objs_comparison.jpg}
\caption{Visual comparison of instance segmentation results by M2F-VIS (top), M2F-VIS-box (middle row) and BoxVIS (bottom row) on videos with crowded scenes.}
\label{fig:visualizer_crowded}
\end{figure*}

\begin{figure*}[h]
    \centering
    \includegraphics[width=0.98\textwidth]{figs/fig/occ_comparison.jpg}
\caption{Visual comparison of instance segmentation results by M2F-VIS (top), M2F-VIS-box (middle row) and BoxVIS (bottom row) on videos with occluded objects.}
\label{fig:visualizer_occ}
\end{figure*}

\begin{figure*}[h]
    \centering
    \includegraphics[width=0.98\textwidth]{figs/fig/motion_comparison.jpg}
\caption{Visual comparison of instance segmentation results by M2F-VIS (top), M2F-VIS-box (middle row) and BoxVIS (bottom row) on videos with blurred objects.}
\label{fig:visualizer_motion}
\end{figure*}


\begin{figure*}[h]
    \centering
    \includegraphics[width=0.98\textwidth]{figs/fig/visual_yt21_sm1.jpg}
    \includegraphics[width=0.98\textwidth]{figs/fig/visual_yt21_sm2.jpg}
\caption{Visualization of instance masks predicted by BoxVIS on YTVIS21 valid set.  }
\label{fig:visualizer_yt21}
\end{figure*}

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.98\textwidth]{figs/fig/visual_ovis_sm.jpg}
    \includegraphics[width=0.98\textwidth]{figs/fig/visual_ovis_sm2.jpg}
\caption{Visualization of instance masks predicted by BoxVIS on OVIS valid set.  }
\label{fig:visualizer_ovis}
\end{figure*}


\end{document}