%\documentclass{article}

%\begin{document}
\subsection{Evaluation metrics}
\label{eval_metrics}

To evaluate the quality of the generated images
we consider two factors: a) How well generated images reproduce the visual appearance of images from the target domain,
b) How well a generated image preserves the structure of a source image. To the best of our knowledge, there is no single established metric that covers both factors.
Therefore, we selected three metrics that are focused on  different aspects: \textit{Structural Similarity Index} (SSIM)~\cite{ssim_ref}, \textit{first Wasserstein Distance} ($\mbox{WD}$)~\cite{ramdas2017wasserstein}, and \textit{Fréchet Inception Distance}(FID)~\cite{fid_ref}.
 \begin{figure}[htbp]
%\centering
\floatconts
  {Fig:fig_1_ab}
  {\vspace{-2em} \caption{(a) Examples of artificially generated $\mbox{H\&E} \rightarrow \mbox{MT}$ images using four I2I methods. Real MT and H\&E images were obtained from close slices of tissue. More examples can be found in \appendixref{appendix:a} in \figureref{Fig:fig_2} and \figureref{Fig:fig_3}. (b) Evaluation of I2I: SSIM is applied to pairs of source and artificially generated images converted to gray-scale, while WD and FID are applied to sets of target and artificial images.} \vspace{-2em}}
  {
	\subfigure{
		\label{Fig:fig_1a}
		\includegraphics[scale=0.6]{Figure_1.pdf}
	}
	\subfigure{
		\label{Fig:fig_1b}
		\includegraphics[scale=0.6]{Figure_2.pdf}
	}
  }
%\caption{The process of evaluation of image to image translation task: SSIM is applied to pairs of \textit{source} and artificially \textit{generated} images, while WD and FID are applied to collections of target and generated images.}
\end{figure}
%SSIM is an index consisting of luminance, contrast, and structural similarity components that reflects perceived by humans characteristics of images.
SSIM is a perceptual image quality metric developed to assess the degradation of structural information in processed images.
For aligned $x$ and $y$ local neighborhoods (we used $7 \times 7$ size), the index is calculated as follows 
\begin{equation}
\label{Eg:ssim}
\mbox{SSIM}(x,y) =\dfrac{(2\mu_{x}\mu_{y}+c_{1})(2\sigma_{xy}+c_{2})}{(\mu_{x}^{2}+\mu_{y}^{2}+c_{1})(\sigma_{x}^{2}+\sigma_{y}^{2}+c_{2})}, 
\end{equation}
where
$\mu$, $\sigma^2$,
$\sigma_{xy}$ are mean, variance, and covariance of pixel intensities, respectively. $c_{1}$ and $c_{2}$ are small constants to avoid instability when the denominator is close to zero. The index  was defined as the multiplication of luminance, contrast, and structure factors, which after simplification results in \equationref{Eg:ssim}. For entire images, SSIM is calculated by averaging along all the local neighborhoods and sometimes termed mean SSIM.
Similarly to \cite{ref_stainnet}, we calculate the mean SSIM between the source and the artificially generated images, both converted to gray-scale, in order to assess structure preservation (see \figureref{Fig:fig_1b}). We have used the SSIM implementation by \citet{van2014scikit}.

The WD, also known as Earth-Mover distance, between two one-dimensional discrete distributions $X$ and $Y$ can be computed as follows 
\begin{equation}
\mbox{WD}(X, Y) = \sum_{v \in \mathbb{R}} |C_X(v) - C_Y(v)|,
\end{equation}
where the $C_X$ and $C_Y$ are cumulative distribution functions.
We use WD to measure the discrepancy between color appearances of generated and target images, see \figureref{Fig:fig_1b}. For this purpose, we average two WDs computed for the two color channels in LAB color space. 
We have used the WD implementation by \citet{virtanen2020scipy}.

%distributions of pixels' colors in generated and target images. 
%
%Wasserstein Distance (WD) is another major metric that measures how accurately one method can transfer the color-based stain characteristics from source (HE) to target domain (MT) as depicted in Figure 9. 
%The idea behind WD is to compare the distributions that in case of images might be represented by color histograms. 
%WD is also known as earth mover's distance and in simple terms estimates the cost of piling up one heap of earth into another, where heaps are represented as two distributions. 
%WD is applied to LAB color space. \textcolor{marked}{This is not clear, we need more context here. The next sentence is also not well connected.}
%However, WD metric operates only on a and b channels that reflects human color perception, while 'L' channel is discarded due to the nature of the task of domain-specific transfer. 
%The metric is measured between Target and Generated image pairs to measure how the method is able to transfer domain-specific attribute. 
%WD is calculated as:
%\begin{equation}
%W_p(X, Y) = \left( \inf_{\gamma \in \Gamma(X,Y)} \int_{\mathbb{R}^d \times \mathbb{R}^d} \|x - y\|^p d\gamma(x, y) \right)^{\frac{1}{p}}
%\end{equation}
%and represents the distance between two probability distributions $X$ and $Y$ in $d$-dimensional space, where $p$ is a positive integer and $\Gamma(X,Y)$ is the set of all joint distributions with marginals $X$ and $Y$. 
%WD is the $L_p$ distance between the two distributions, where $L_p$ is the $p$th power of the $L_1$ norm of the difference between the two distributions.

The Fréchet Inception Distance (FID) is a widely adopted metric used to assess the quality of generated images~\cite{Parmar0Z22}.  
FID compares the distributions of two image sets (e.g. generated and target, see \figureref{Fig:fig_1b}). Namely, it measures the Fréchet distance \cite{dowson1982frechet} between the distributions of image deep features generated with the Inception v3 network~\cite{SzegedyVISW16} pre-trained on the ImageNet~\cite{5206848}. Since normal distributions are assumed, FID between distributions $X$ and $Y$ is calculated as follows \cite{dowson1982frechet} 
%However, in FID a pre-trained network is used (Inception v3 model)\textcolor{marked}{Did we provide a reference before?}
%where the last feature map prior to the fully connected layers is used to capture computer-vision-specific features. 
%These activations are calculated for target and generated images (see Figure 1) and then summarized as multivariate Gaussians calculating mean and co-variance. 
%The derived values are used to calculate FID. 
%A lower FID indicates better-quality images (the target and result distribution are more alike), while a higher FID score indicates lower quality. 
%Normally, FID is calculated across thousands of target domain images and thousands of generated images to get a better approximation to the source and target distributions.
%FID is calculated as:
\begin{equation}
\mbox{FID}(X, Y) = \left\| \mu_x - \mu_y \right\|^2 + tr(\Sigma_x + \Sigma_y - 2(\Sigma_x \Sigma_y)^{\frac{1}{2}}),
\end{equation}
where $\mu, \Sigma$ are distribution mean and co-variance, and $tr$ is the trace operator. 
%The Fréchet distance ranges from 0 to infinity, with a lower value indicating that the two distributions are more similar.
In contrast to the WD described above, FID allows the assessment of not only color but also texture or structure similarity between image sets. We use the Clean-FID implementation~\cite{Parmar0Z22} in our experiments.


%\end{document}

