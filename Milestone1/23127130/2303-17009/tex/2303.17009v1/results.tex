\subsection{Results}
\label{Sec:main_results}
\tableref{Tab:comp_results} summarizes the average translation performance between both directions ($\mbox{H}\&\mbox{E} \rightarrow \mbox{MT}$ and $\mbox{MT} \rightarrow \mbox{H\&E}$) for the I2I methods. The performance for each direction of translation is separately shown in \appendixref{appendix:c}.
By calculating the FID measure on the validation dataset with samples distributed similarly to the training data,
we conclude that CycleGAN excels over other methods in mimicking the structure and color of target images.
CUT and MUNIT performed closely.
Our WD measure, which measures the ability to mimic colors (see \sectionref{eval_metrics}), shows a similar ranking of the best performing methods.
The StainGAN method shows close but slightly worse results than CycleGAN, the design of which was borrowed by StainGAN.
UTOM, which also adopted the CycleGAN architecture but introduced an additional constraint to reduce the distortion of image content, did not show (based on SSIM) the expected improvement.
The SSIM measure shows that Pix2Pix, StainNet, and ColorStat introduce the lowest level of distortion.
However, these methods are essentially worse in generating the desired color and texture.
StainNet, with $1 \times 1$ filters, as well as all three traditional methods frequently fail to properly generate color patterns, because they are based on pixel-to-pixel mappings which do not take into account a local neighborhood.
Specifically, they cannot reproduce blue patterns of connective tissue for $\mbox{H\&E} \rightarrow \mbox{MT}$ translation, see \figureref{Fig:fig_1a},  and \figureref{Fig:fig_2}, \figureref{Fig:fig_3} in \appendixref{appendix:a}. As measured by SSIM, the lowest distortion among traditional methods, introduced by ColorStat, is similar to the one introduced by CycleGAN and its derivatives UTOM and StainGAN. This reinforces the suitability of CycleGAN for stain transfer.

The results on the test set again demonstrate that CycleGAN achieves the best performance. However, FID and WD show worse values since
the generated colors resemble images of the training/validation sets rather than the images of the test set. For the same reason, WD, which exclusively measures color similarity, showed a different ranking of the methods. MUNIT and DRIT performed worse than the principally different CycleGAN. However, they may allow the adaptation to the color distribution of a target domain without the need to retrain an I2I network.
%\textcolor{marked}{MUNIT and DRIT methods have a potential advantage of being capable of generating images with color distribution according to the target data. 
%In these methods, the style/attribute feature vectors from the target data can be employed during the test time, avoiding time consuming retraining on the target data. - Put in Conclusion if no related experiments} 
%More diverse test and training datasets in terms of staining procedures, would expected
\begin{table}[t!]
    \centering
    \floatconts
    {Tab:comp_results}%
    {\caption{Evaluation of I2I methods with FID (texture \& color similarity to target domain), WD (color similarity to target domain), and SSIM with standard errors (structure preservation) for the Validation, and Test sets. The methods are ordered according to FID for the validation set. Best results are in bold. WD has a factor $10^{-4}$.} \vspace{-1em}  }

    \bgroup
    \def\arraystretch{1}
    \def\aboverulesep{0.ex}
    \def\belowrulesep{0.ex}
    \footnotesize
    \center
    {\begin{tabular}{l|ccc|ccc} %{clrrrrrrrrr}
         \toprule
         \multicolumn{1}{l|}{\multirow{2}{*}{Model}} & \multicolumn{3}{c|}{Validation} & & Test                 &                \\
         & FID$\downarrow$ & WD$\downarrow$ & SSIM$\uparrow$         & FID$\downarrow$ & WD$\downarrow$ & SSIM$\uparrow$         \\
         \cmidrule[0.1ex](lr){1-7}
         CycleGAN  & \textbf{16.33}  & \textbf{1.46}  & 0.951 ± 0.001          & \textbf{25.18}  & \textbf{5.04}  & 0.934 ± 0.001                      \\
         CUT       & 17.10           & 1.60           & 0.914 ± 0.001          & 29.75           & 6.30           & 0.901 ± 0.001          \\
         MUNIT     & 19.20           & 1.61           & 0.871 ± 0.001          & 29.36           & 6.15           & 0.842 ± 0.001          \\
         StainGAN  & 19.59           & 3.27           & 0.952 ± 0.000          & 26.64           & 6.97           & 0.926 ± 0.001          \\
         UNIT      & 20.23           & 2.54           & 0.940 ± 0.001          & 36.78           & 7.40           & 0.918 ± 0.001          \\
         UTOM      & 20.64           & 2.32           & 0.952 ± 0.000          & 32.79           & 7.06           & 0.951 ± 0.000          \\
         DRIT      & 22.83           & 2.06           & 0.915 ± 0.001          & 33.62           & 5.44           & 0.892 ± 0.001          \\
         Pix2Pix   & 48.47           & 8.42           & \textbf{0.998} ± 0.000 & 49.71           & 5.34           & \textbf{0.997} ± 0.000 \\
         StainNet  & 50.49           & 11.41          & 0.972 ± 0.000           & 47.81           & 12.33          & 0.967 ± 0.000          \\

         ColorStat & 62.13           & 9.60           & 0.974 ± 0.001          & 58.42           & 6.96           & 0.939 ± 0.001          \\
         Macenko   & 70.39           & 12.90          & 0.926 ± 0.001          & 53.27           & 11.83          & 0.910 ± 0.001          \\
         Vahadane  & 76.55           & 15.14          & 0.911 ± 0.001          & 59.94           & 14.71          & 0.885 ± 0.001          \\
         \bottomrule
    \end{tabular} \vspace{-1.5em} }
    \egroup

\end{table}






