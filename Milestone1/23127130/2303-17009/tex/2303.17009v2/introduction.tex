%\documentclass{article}


%\begin{document}

\section{Introduction}
Image-to-image translation (I2I) methods~\cite{PangLQC22} map images from a source to a target domain, usually preserving semantic information, while changing an image style. With the success of conditional GAN-based image generation technology \cite{MirzaO14},
I2I techniques gained popularity, suggesting a generic approach for tackling diverse computer vision problems such as translation between day and night scenes, colorizing gray-scale images, or reconstruction of an image from its edges \cite{ref_pix2pix}. Especially influential were the methods that were able to learn translation between image domains (e.g. between day and night), given only unpaired examples without scene correspondences between the images from the different domains~\cite{ref_unit,zhu2017unpaired}.

In digital histopathology such methods were employed in a few different scenarios, which we will differentiate into three categories. 
First, I2I was used for \textit{image normalization}~\cite{zanjani2018histopathology,ref_stainnet,mahapatra2020structure,ref_staingan,BenTaiebH18} and \textit{image augmentation}~\cite{wagner2021structure} in order to improve the robustness of image processing systems to variability in staining and image acquisition settings. Image normalization is performed at the inference stage and adapts an image to a reference appearance. On the other hand, image augmentation is performed during the training stage to challenge the system with training examples that vary from the standard appearance (and may appear in real data in the future). 

Second, I2I enabled not only the subtle correction of image appearances due to variability in staining and image acquisition, but also the translation between colorization styles due to different types of reagents used for staining (so-called \textit{stain transfer})~\cite{abs-1901-04059,de2021deep,VasiljevicFWL21,BoydVMDPVC22,LahianiGKANK19}. Since particular types of stains are used for the visualization of specific structures in the tissue (e.g. nuclei, fibrotic tissue etc.), such technology allows to avoid repeated staining with different reagents, when there is a need for the analysis of tissue features that are not emphasized with a single type of staining. Additionally, nowadays  histopathological laboratories use systems for the automated evaluation of tissue samples. Since, it is often required to analyze samples stained with the reagents that are different from those used for training, stain transfer algorithms become advantageous~\cite{GadermayrAKBM18,abs-1907-04681}. 
Stain transfer can be considered as an example of domain adaptation~\cite{SrinidhiCM21} in digital histopathology, where a system needs to be adapted to process images of tissue samples stained with a different reagent compared to samples used for training the system. 

%Traditional approaches for image normalization and augmentation in histology \cite{ref_macenko,ref_vahadane,ReinhardAGS01} can also be applied for stain transfer....
The third and most difficult use of I2I in histopathology is \textit{virtual staining}, when artificial images mimicking stained tissues are generated from unstained tissue samples.
The literature targeting this challenging problem is more scarce.
Only a few works aimed to generate artificial images mimicking stained tissues from  fluorescence~\cite{ref_utom,rivenson2019virtual} and hyperspectral~\cite{BayramogluKEH17} images were published. In~\cite{li2020deep} the authors used paired examples of bright-field images of stained and unstained tissue samples to train a virtual staining system. We expect that the research activity in this emerging domain will yet accelerate in the upcoming years, since the ability to perform virtual staining would have tremendous impact in histopathology~\cite{rivenson2020emerging}. 
%Tight collaboration between computer vision scientists, physicists, and pathologists would greatly benefit the progress in this field. 

Substantial effort was already made to quantitatively evaluate the effectiveness of different image normalization and augmentation techniques, using both traditional and GAN-based methods~\cite{TellezLBBBCL19,stacke2020measuring,zanjani2018histopathology,ref_staingan}. Unfortunately, stain transfer and virtual staining methods (as categorized above) are lacking a comparative study that quantitatively evaluates a broad range of suitable I2I approaches. Here, we provide such a quantitative comparison of I2I methods for stain transfer. To this end, we compare several GAN-based state-of-the-art~ \cite{ref_unit,zhu2017unpaired,ref_munit,ref_drit,ref_stainnet,ref_utom,ref_pix2pix,ref_staingan,park2020contrastive} and  traditional~\cite{ref_macenko,ref_vahadane,ReinhardAGS01} methods. Particularly, we experiment with the conversion between Masson's Trichrome (MT) and Hematoxylin-Eosin (H\&E) staining, see visual examples in \figureref{Fig:fig_1a}. We evaluate the performance of I2I approaches using complementary quantitative measures (\sectionref{Sec:comparative evaluation}), the tissue grading errors when integrated into a computer-aided image analysis pipeline (\sectionref{Sec:NASH_classification}), and visual pathologists' analysis (\sectionref{Sec:pathologist_assessment}). Our comparative evaluation outlines the limitations and advantages of different I2I methods, thereby allowing practitioners to properly choose the most suitable one. 
%Trained I2I models along with the stain transfer code will be released upon publication of this paper. 
  




%\end{document}