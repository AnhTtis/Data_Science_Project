\section{Conclusion}
%In conclusion, the survey conducted in this paper provides valuable insights into the current state of image-to-image translation methods for stain transfer in histopathology . The paper is also presenting the evaluation framework that enabled a systematic and objective evaluation of the results, ensuring the accuracy and reliability of the findings. The evaluation framework consists of the data set, code for inference and metrics as well as a set of pretrained models for each of the method.
%
%In the paper we applied holistic approach of evaluating methods. It includes, a) quantitative criteria that used relevant assesment metrics to measure the method performance, b) qualitative criteria that was assessed manually by hystopathological experts and b) business impact that employed existing classifiers to measure reusability of the existent classifier on generated images.
%
%Overall, the results of the survey indicate that CycleGan method outperforms other approaches. These findings have important implications for stain transfer in histopathology, and suggest the need for further research in this area to [recommendations for future research].
%
%In summary, this survey serves as a valuable resource for understanding the current state of art in the I2I translation for stain transfer in histopathology, and provides a solid foundation for future research in this field.

In our study, we evaluated three traditional and nine GAN-based I2I methods for stain transfer in histopathology. The analysis was based on three quantitative measures that assess the quality of color and texture translation, as well as the distortion of the image content. We additionally evaluated the performance of a deep learning grading system that was fed with artificially stained tissue images. Furthermore, we conducted experiments where expert pathologists were asked to distinguish real from artificial images. 

The results have shown that CycleGAN provides the highest quality of stain transfer and introduces similar or lower distortions than traditional pixel-to-pixel methods. On the contrary, pixel-to-pixel methods, i.e., StainNet and the traditional methods, are hardly suitable for stain transfer. Moreover, all compared approaches derived from CycleGAN did not show advantages over the original version. 
%Principally different MUNIT and DRIT, though performed worse than CycleGAN, can allow adaptation to the color distribution of target domain without the need to retrain an I2I network. 
%The adaptation is achieved during inference using style feature vectors from the target domain. 
%As the follow up steps, we plan to further investigate benefits of such methods for stain transfer.


%----
Our study inspires the use of stain transfer methods for both pathologist visual evaluation and computer-aided assessment when a type of staining is missing. Trained models, inference code, and data will accompany this paper. We encourage stain transfer researchers to use our framework for the evaluation of stain transfer methods not included in our study. For example, a potential of emerging diffusion-based methods for stain transfer has not yet been shown. 
%----
We plan to further experiment with stain transfer going from tiles to WSIs and transferring different types of staining. This would allow pathologists to draw their conclusions faster by multiplexing between several types of staining.
%----

