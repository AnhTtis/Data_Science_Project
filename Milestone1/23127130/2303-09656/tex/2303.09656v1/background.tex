\section{Credibility Evaluation of Social Media Posts}\label{sec:background}


Short social media posts usually comprise a source, i.e. the author of a post; content; and peripheral cues, such as likes and re-tweets. In the present study, we were interested in how source characteristics and the quality of message content were reflected in readers’ credibility judgments. Our study was informed by a bidirectional model of first- and second-hand evaluation strategies proposed by \cite{barzilai2020dealing}, which describes how readers can evaluate conflicting views on an issue (see also \citealt{stadtler2014content}). More precisely, the model provided us with a framework for the elements readers may consider when evaluating the credibility of social media posts. 

\cite{barzilai2020dealing} specify three first-hand evaluation strategies that can be used to judge content quality. These strategies are discourse-based validation, knowledge-based validation, and corroboration. When using discourse-based strategies, readers use various discourse features, such as argument quality, to make judgments about the credibility of content. In knowledge-based validation, readers rely on their prior knowledge and beliefs about the topic, whereas in corroboration, readers compare text content to what other resources state about a given issue.

The term ‘second-hand evaluation strategies’, \citep{barzilai2020dealing, stadtler2014content} refer to sourcing strategies that readers employ to judge a source's trustworthiness. Readers can make inferences and evaluate sources’ expertise, benevolence, and integrity \citep{hendriks2015measuring} by relying on  available information about the source. According to the model, readers use evaluation strategies to judge information and a source reciprocally. That is, source trustworthiness judgments inform content quality judgments, and \textit{vice versa}.

Next, we will first discuss two first-hand evaluation strategies: the discourse-based validation and knowledge-based validation of content. In discourse-based validation, the focus is on argument evaluation.  Knowledge-based validation focuses on prior beliefs when evaluating arguments. Then, we will move to second-hand evaluation strategies, focusing on those aspects of the source that are relevant to the present study.

\subsection{Evaluation of an Argument} 

Social media posts with restricted lengths, such as messages on Twitter, are usually simple arguments with a rhetoric argument structure. A rhetorical argument is a claim with an accompanying justification, and it differs from a dialogic argument or debate, which includes an opposition between two or more assertions \citep{kuhn1991skills}. A simple rhetoric argument contains one assertion with only one instance of justifying support, which is called evidence \citep{zarefsky2019practice} or data \citep {toulmin2003uses}. The argument can also include other components, such as a warrant, an often unstated but implicit inference that connects the evidence to the claim \citep{toulmin2003uses}. For example, empirical research, or evidence entitles us to conclude that vaccines are safe (claim) because we trust that the research has followed the scientific standards, which is the warrant.

When evaluating arguments, readers can pay attention to the coherence of the argument and the quality of evidence provided \citep{NussbaumE.Michael2021CiaT}. There are several different types of evidence \citep {HornikxJ.M.A2005Aroe, kuhn1991skills, zarefsky2019practice}, which differ in terms of their quality, reflecting how the evidence was produced \citep{ClarkA.Chinn2014ECaE}. For example, research processes, such as experiments, statistical analyses, and meta-analyses can offer causal and statistical evidence. The other type of evidence is testimonial evidence \citep{zarefsky2019practice} or expert evidence \citep{HornikxJ.M.A2005Aroe}. Testimony, which can consist of either a fact or an opinion, is a statement on the part of some source. It is reasonable to rely on testimonial evidence from a qualified source when an author does not have direct knowledge of the topic but can trust the expertise of others. 

Anecdotal evidence and social consensus are evidence types that are common in health communication, especially in social media. Anecdotal evidence, such as personal experiences, relies on a narrative way of knowing \citep{hinyard2007using}. Furthermore, social consensus refers to widely agreed upon facts, shared value judgments, shared historical understandings, previously established claims, and stipulations \citep{zarefsky2019practice}. 

Because social media contain an enormous number of short messages competing for readers’ attention, the persuasiveness of the evidence is crucial. When examining the relative persuasiveness of different evidence types (i.e., anecdotal versus statistical evidence), results have been contradictory. However, \cite{HornikxJ.M.A2005Aroe} found in his narrative literature review that in six of twelve studies, in which the persuasiveness of anecdotal evidence and the persuasiveness statistical evidence were compared, statistical evidence was shown to be more persuasive than anecdotal evidence. In one study anecdotal evidence was shown to be more persuasive, and in five studies no differences were found. In addition, a meta-analysis consisting of 15 studies concerning health communication campaigns  \citep{zebregs2015differential} showed that statistical evidence has a stronger influence on beliefs and attitudes than anecdotal evidence but that anecdotal evidence had a stronger influence on intention, which relate more closely to affective responses. 

In terms of the evaluation of evidence, readers may struggle to differentiate evidence in terms of quality. For example, \cite{list2021examining} found that even though undergraduate students (\textit{N} = 82) considered anecdotal evidence considerably less convincing than other types of evidence, they struggled to differentiate observational, correlational, and causal evidence effectively. This is worrying because, on social media, discussions of health issues often include causal claims or generalisations that may or may not be supported by appropriate causal evidence. 

\subsection{Prior Beliefs in Argument Evaluation} 

When browsing, reading, and evaluating short social media messages, readers may use heuristic processing which is superficial and quick and relies on salient cues \citep{metzger2013credibility}. Prior beliefs are one internal resource that readers can use to quickly evaluate the plausibility and credibility of information \citep{richter2017comprehension}. When readers evaluate information, they seem to favor belief-consistent information over belief-inconsistent information \citep{abendroth2020mere, mccrudden2016differences, van2016attitude}.

For example, \cite{mccrudden2016differences} asked 72 high school students to evaluate eight arguments about climate change. Four arguments claimed that humans affect climate change, and four other arguments claimed the opposite. Half of the arguments were strong, and half were weak. It was found that students evaluated belief-consistent arguments more favorably than belief-inconsistent arguments. However, arguments were not evaluated solely on the basis of their belief-consistency. Namely, students evaluated strong arguments more favorably than weak arguments. Importantly, further analysis showed that students’ evaluations of strong belief-inconsistent arguments and weak belief-consistent arguments did not differ. 

Similarly, prior beliefs have been found to play a role when readers evaluate the credibility of websites \citep{tarchi2019identifying, van2016attitude}.  For example, \cite{van2016attitude} examined the role of prior beliefs, or attitudes, as Van Strien et al. refer to them, when 79 university students evaluated four websites in favor of and four websites against organic food. The students with stronger prior attitudes judged the credibility of the attitude-inconsistent websites to be lower. 

\subsection{Evaluation of a Source}

The trustworthiness of a source refers to readers' perceptions of positive characteristics on the part of that source, which allow them to accept the source’s message \citep{fogg2002persuasive, ohanian1990construction}. Readers' judgments about the source's trustworthiness may be based on evidence of the source's competence, honesty, goodwill, and epistemic responsibility \citep{rolin2020trust}. Evaluation of source trustworthiness is essential, particularly when readers evaluate scientific information, including health information, that they do not have specialized knowledge \citep{hendriks2015measuring}. \cite{hendriks2015measuring} found three dimensions that laypersons rely on when deciding whether they trust an expert. These dimensions are expertise, integrity, and benevolence. 

A source’s expertise can be evaluated by exploring that source’s credentials, such as degrees, professional achievements, affiliations, and other indicators of competence, such as awards and publications \citep{rolin2020trust, braaten2018task}. Furthermore, ‘integrity’ refers to honesty, objectivity, and acting according to scientific and professional standards, whereas ‘benevolence’ refers to goodwill and intentions toward others and society \citep{hendriks2015measuring}.		

The source information provided on social media messages is often limited. For example, on Twitter, the information that users can provide amounts to a short profile description and a profile picture. Thus, when evaluating a source's trustworthiness, readers must be content with these limited cues regarding the source. Furthermore, people are not reliably sensitive to cues indicating trustworthiness \citep{shieber2015testimony}. 

Accordingly, in this study, we created short descriptions of the sources of social media messages, including cues about their expertise and profile pictures. We manipulated the source expertise and profile picture, in which the gender and ethnicity of the source varied. Next, we will present some previous research on the role of these source characteristics in credibility evaluation. 

It is widely acknowledged that information about a source's expertise plays a pivotal role in credibility evaluation of social media messages and beyond \citep{meinert2022expertise, LIN2016264, stadtler2014content}.
\cite{hirvonen2018cognitive} have studied cognitive authority in health-related information-sharing processes online. They found that authority-related cues, such as user information, the authority's own experience, and education and background, were important when girls and young women evaluated the information credibility of their peers in an online forum related to health topics.

\cite{LIN2016264} studied the credibility evaluation of mock Twitter pages considering health issues.  Altogether, 696 undergraduates participated in a quasi-experiment.  The two aspects of the Twitter pages were manipulated: the author (author cues) and originality of the tweets (original or retweeted, as well as bandwagon cues). The Twitter pages were owned by the Center for Disease Control and Preventions (CDC), a college student, or a stranger without any identifying information. After viewing the pages, students were asked to evaluate the source's credibility from three perspectives: competence, goodwill, and trustworthiness.
The author cues were found to influence perceived credibility the most. The  CDC was evaluated as more credible than the student and the stranger. The bandwagon cues, which are cues that imply that others see the post as credible, also had an effect: the student and the stranger were  evaluated as more credible when they retweeted each other. Interestingly, the CDC twitter page without any retweets was perceived as the most credible in all evaluated aspects.

%Since the beginning of research on credibility evaluation in online settings, the expertise of the author has been a factor studied (lähteitä tähän??). \cite{Eastin2001} studied source expertise and prior topic knowledge of the content in relation to credibility in online health information. While both source expertise and knowledge of content affected the perceptions of credibility, no interaction was found between these variables.




%Study by \cite{meinert2022expertise} have found that expertise cues are used as a heuristic, reducing latency and thus effort in evaluating credibility.




%The effect of updates and cognitive elaboration on the perceived credibility of social media has been previously studied by \cite{westerman2014social} in the specific context of twitter. Results indicate that update speed does not have a direct relationship with credibility, but rather that cognitive elaboration mediates this relationship.¨

In addition to source expertise, some studies have examined other features of the source, such as gender and ethnicity. \cite{spence2013intercultural} investigated  intercultural differences in responding to health messages specifically in the context of Facebook. In their study, participants from the Caucasian and African American communities (\textit{N}=200\textit{)} were evaluated to determine their response efficacy and behavioral intentions after being exposed to a social media page with an avatar. The African American page owner communicated either high or low ethnic identity, encouraging participants to read a story about heart disease. African American participants perceived both ethnic authors as more competent, caring, and trustworthy than Caucasian participants did. While the perceived credibility of the author was not measured, African American participants indicated stronger intention to change their dietary behavior after seeing a health message delivered by an African American avatar with high ethnic identification as compared to one with low ethnic identification.

\cite{armstrong2009blogs} examined the role of gender in credibility evaluation of blogs. They found that gender influenced how undergraduates perceived credibility. The blog posts with male authors were seen as more credible than posts with female authors. Similar results regarding credibility and gender have also been attained with newscasters \citep{weibel2008gender}. 

Finally, \cite{groggel2019race} investigated how people perceived both gender and ethnicity as well as physical attractiveness as a cue indicating trustworthiness when evaluating Twitter accounts. In the study, Amazon Mechanical Turk workers evaluated the trustworthiness of 816 Twitter profiles. The results indicated that attractiveness was positively associated with trust. Furthermore, White Twitter accounts were evaluated as more trustworthy than Black accounts. Also, Black male and both Black and White female accounts were viewed as less trustworthy than White male accounts. White workers also evaluated White accounts as trustworthy.

