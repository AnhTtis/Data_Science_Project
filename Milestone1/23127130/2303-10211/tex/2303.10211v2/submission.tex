\documentclass{article}


% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2023


% ready for submission
\usepackage{amsmath}
\usepackage[preprint]{neurips_2023}


% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2023}s


% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2023}


% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2023}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{natbib}
\usepackage[pdftex]{graphicx}
\usepackage{cases}
\usepackage{arydshln}
\usepackage{multirow}
\usepackage{amsthm}
\usepackage{booktabs}
\usepackage{bm}
\usepackage{zref-xr}
\zxrsetup{toltxlabel}

\zexternaldocument*{build/supplement}

\makeatletter


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\newcommand{\expnumber}[2]{{#1}\mathrm{e}{#2}}
\newcommand{\significant}{\makebox[0pt]{\ $^*$}}

\bibliographystyle{abbrvnat}
\setcitestyle{authoryear,open={(},close={)}} %Citation-related commands


\title{SITReg: Multi-resolution architecture for symmetric, inverse consistent, and topology preserving image registration using deformation inversion layers}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.


\author{%
  Joel Honkamaa \\
  Department of Computer Science\\
  Aalto University\\
  Aalto, Finland\\
  \texttt{joel.honkamaa@aalto.fi}\\
  % examples of more authors
  \And
  Pekka Marttinen \\
  Department of Computer Science\\
  Aalto University\\
  Aalto, Finland\\
  \texttt{pekka.marttinen@aalto.fi}\\
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \AND
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
}


\begin{document}


\maketitle


\begin{abstract}
Deep learning based deformable medical image registration methods have emerged as a strong alternative for classical iterative registration methods. Since image registration is in general an ill-defined problem, the usefulness of inductive biases of symmetricity, inverse consistency and topology preservation has been widely accepted by the research community. However, while many deep learning registration methods enforce these properties via loss functions, no prior deep learning registration method fulfills all of these properties by construct. Here, we propose a novel multi-resolution registration architecture which is by construct symmetric, inverse consistent, and topology preserving. We also develop an implicit layer for memory efficient inversion of the deformation fields. The proposed method achieves state-of-the-art registration accuracy on two datasets.
\end{abstract}


\section{Introduction}\label{sec:intro}

We study deformable medical image registration using deep learning, where the goal is to find a mapping between coordinate systems of two images to match the corresponding anatomical parts. The predicted coordinate mappings are called deformations. Typically, deep learning is applied by training a registration network which outputs a candidate deformation for two input images. We focus on unsupervised intra-modality registration, where there is no ground truth deformation and the images are of the same modality, which is useful, e.g, when deforming brain MRI images from different patients to an atlas or analyzing a patient's breathing cycle using multiple images. Since medical image registration is challenging, various properties are often assumed to improve the registration quality: \textit{inverse consistency}, \textit{symmetry}, and \textit{topology preservation}, are widely seen as useful by the research community \citep{sotiras2013deformable}. Another property is diffeomorphism, which however overlaps with topology preservation, and hence we consider them as one, as explained later. Although these properties do not guarantee successful registration, they serve as inductive biases to narrow down the search space. As terminology in the literature can be ambiguous, we begin by precisely defining each property, and we provide further clarifications of them in Appendix \ref*{appendix:property_examples}.

We define a \textit{registration method} as a function $f$ that takes two images, $x_1$ and $x_2$, and produces a deformation. Some methods can output the deformation in both directions, and we use subscripts to indicate the direction. For example, $f_{1\to2}$ produces a deformation that aligns the image of the first argument to the image of the second argument. As a result, a registration method may predict up to four different deformations for any given input pair: $f_{1\to2}(x_1, x_2)$, $f_{2\to1}(x_1, x_2)$, $f_{1\to2}(x_2, x_1)$, and $f_{2\to1}(x_2, x_1)$. Some methods predict deformations in one direction only, resulting in two possible outputs: $f_{1\to2}(x_1, x_2)$ and $f_{1\to2}(x_2, x_1)$, in which case we might omit the subscript.

\textit{Inverse consistent} registration methods ensure that $f_{1\to2}(x_1, x_2)$ is an accurate inverse of $f_{2\to1}(x_1, x_2)$, which we quantify using the \textit{inverse consistency error}: $||f_{1\to2}(x_1, x_2) \circ f_{2\to1}(x_1, x_2) - \mathcal{I}||^2$, where $\circ$ is the composition operator and $\mathcal{I}$ is the identity deformation. Originally inverse consistency was achieved via variational losses \citep{christensen11995topological} but later algorithms were \textit{inverse consistent by construct}, e.g., classical methods DARTEL \citep{ashburner2007fast} and SyN \citep{avants2008symmetric}. However, due to a limited spatial resolution of the predicted deformations, even for these methods the inverse consistency error is not exactly zero. Some deep learning methods enforce inverse consistency via a penalty \citep{zhang2018inverse, kim2019unsupervised, estienne2021mics}. A popular stationary velocity field (SVF) formulation \cite{arsigny2006log} achieves inverse consistency by construct and has been used by many works, e.g. \citet{dalca2018unsupervised, krebs2018unsupervised, krebs2019learning, niethammer2019metric, shen2019networks, shen2019region, mok2020fast}.

In \textit{symmetric registration}, the registration outcome does not depend on the order of the inputs, i.e., $f_{1\to2}(x_1, x_2)$ equals $f_{2\to1}(x_2, x_1)$. Since anatomical correspondence trivially does not depend on the input order, enforcing the property is very natural. Unlike with inverse consistency, $f_{1\to2}(x_1, x_2)$ can equal $f_{2\to1}(x_2, x_1)$ exactly for some methods \citep{avants2008symmetric, estienne2021mics}, which we call \textit{symmetric by construct}. A related property, cycle consistency, can be assessed using \textit{cycle consistency error} $||f(x_1, x_2) \circ f(x_2, x_1) - \mathcal{I}||^2$. It can be computed for any method since it does not require the method to predict deformations in both directions. If the method is symmetric by construct, inverse consistency error equals cycle consistency error. Some existing deep learning registration methods enforce cycle consistency \citep{mahapatra2019training, gu2020pair, zheng2021symreg} via a penalty. The method by \citet{estienne2021mics} is symmetric by construct but only for a single component of their multi-step formulation, and also it is not inverse consistent by construct making the symmetry less powerful. Very recently in parallel to us, \citet{iglesias2023ready} proposed a by construct symmetric and inverse consistent registration method within the SVF framework. The work had no effect on our work and achieved the goal in a way different from ours.

The third property, \textit{topology preservation} of predicted deformations, we define similarly to \citet{christensen11995topological}. From the real-world point of view it refers to the preservation of anatomical structures. Mathematically we want the deformations to be homeomorphisms, i.e., invertible and continuous. In registration literature it is common to talk about diffeomorphims which are additionally differentiable. In practice we want a deformation not to fold on top of itself which we measure by estimating the local Jacobian determinants of the predicted deformations and checking whether they are positive. Most commonly in deep learning applications topology preservation is achieved using the diffeomorphic SVF formulation \citep{arsigny2006log}. It does not completely prevent the deformation from folding but such voxels are usually limited to just a handful in the whole volume of millons of voxels, which is usually sufficient in practice. Topology preservation can also be encouraged using a specific loss, e.g. by penalizing negative determinants \citep{mok2020fast}.

Our main contributions can be summed up as follows:
\begin{itemize}
    \item We propose a multi-resolution deep learning registration architecture which is by construct inverse consistent and symmetric, and preserves topology. The properties are fulfilled for the whole multi-resolution pipeline, not just separately for each resolution. Apart from the parallel work \citep{iglesias2023ready}, we are not aware of other deep learning registration methods which are by construct both symmetric and inverse consistent, and ours is the first such method with a multi-resolution deep learning architecture. For motivation of the multi-resolution approach, see Section \ref{sec:multi-resolution_background}.
    \item As a component in our architecture, we propose an \textit{implicit} neural network layer, which we call \textit{deformation inversion layer}, based on a well-known fixed point iteration formula \citep{chen2008simple} and recent advances in Deep Equilibrium models \citep{bai2019deep, duvenaud2020deep}. The layer allows memory efficient inversion of deformation fields.
    \item We show that the method achieves state-of-the-art results on two popular benchmark data sets in terms of registration accuracy and deformation regularity. The accuracy of the inverses generated by our method is also very good and similar to the s-o-t-a SVF framework.
\end{itemize}

We name the method \textit{SITReg} after its symmetricity, inverse consistency and topology preservation properties.

\begin{figure}[t]
\centering
\includegraphics[width=1.0\textwidth]{figures/deformation_example.pdf}
\caption{\textbf{Example deformation produced by the method.} Composition of the forward and the inverse deformations is shown on the right to demonstrate the accuracy of the inverse. Only one 2D slice is shown of the 3D deformation. The visualized deformation is from the LPBA40 experiment.}
\label{fig:example_deformation}
\end{figure}

\section{Preliminaries}

\subsection{Topology preserving registration}

The LDDMM method by \citep{cao2005large} is a classical registration method that can generate diffeomorphic deformations which preserve topology, but it has not been used much in deep learning due to computational cost. Instead, a simpler stationary velocity field (SVF) method \citep{arsigny2006log} has been popular \citep{krebs2018unsupervised, krebs2019learning, niethammer2019metric, shen2019networks, shen2019region, mok2020fast}. In SVF the final deformation is obtained by integrating a stationary velocity field over itself over a unit time, which under mild continuity constraints for the velocity field results in a diffeomorphism. Another classical method by \citet{choi2000injectivity, rueckert2006diffeomorphic} uses a different approach to generate invertible deformations. The idea is to constrain a deformation to be diffeomorphic but small, and to form the final deformation as a composition of multiple such small deformations. Since diffeomorphisms form a group under composition, also the final deformation is diffeomorphic.
%
Note that this is actually close to a practical implementation of the SVF, where the velocity field is usually integrated by first scaling the velocity field down by a power of two and interpreting the result as a small deformation, which is then repeatedly composed with itself for the final deformation. The idea is hence similar: a composition of small deformations.

In this work we build topology preserving deformations using the same strategy: as composition of small topology preserving deformations.

\subsection{Multi-resolution registration}\label{sec:multi-resolution_background}

Multi-resolution registration methods learn the deformation by first estimating it in a low resolution and then incrementally improving it while moving towards higher a resolution. For each resolution one feeds the inputs deformed with the deformation learned thus far, and incrementally composes the full deformation. The approach has been around for already a few decades \citep{rueckert1999nonrigid, oliveira2014medical} and has been used by many methods, including the top-performing classical and deep learning registration methods \citep{avants2008symmetric, klein2009evaluation, mok2020large, mok2021conditional, hering2022learn2reg}.

In this work we propose the first multi-resolution deep learning registration architecture that is by construct symmetric, inverse consistent, and topology preserving.

\subsection{Symmetric registration formulations}\label{sec:symmetric_registration_formulation}

Symmetric registration does not assign moving or fixed identity to either image but instead considers them equally. A classical registration method called symmetric normalization (SyN) \cite{avants2008symmetric} proposed a symmetric registration algorithm which learns two separate transformations: one for deforming the first image half-way toward the second image and the other for deforming the second image half-way toward the first image. The images are then matched in the intermediate coordinates and the full deformation can be obtained as composition of the half-way deformations (of which either one is inverted). The idea of matching the images in intermediate coordinates has later been used by other methods such as the deep learning method SYMNet \cite{mok2020fast}. However, SYMNet does not guarantee symmetry by construct for individual predictions.

In our architecture we use the intuition of deforming the images half-way towards each other to achieve inverse consistency and symmetry throughout or multi-resolution architecture.

\subsection{Deep equilibrium networks}\label{sec:deqn}

Deep equilibrium networks use \textit{implicit} fixed point iteration layers, which have emerged as an alternative to the common \textit{explicit} layers in deep learning \citep{bai2019deep, bai2020multiscale, duvenaud2020deep}. Unlike explicit layers, which produce output via an exact sequence of operations, the output of an implicit layer is defined indirectly as a solution to a fixed point equation, which in turn is defined using a fixed point mapping. In the simplest case the fixed point mapping takes two arguments, one of which is the input. For example, let  $g: A \times B \to B$ be a fixed point mapping defining an implicit layer. Then, for some input $a$, the output of the layer is a solution $z$ for equation
\begin{equation}
    z = g(z, a).
\end{equation}
Such an equation is called a fixed point equation and the solution is called a fixed point solution. If $g$ has suitable properties, the equation can be solved iteratively by starting with an initial guess and repeatedly feeding the output as the next input to $g$. More advanced iteration methods have also been developed for solving fixed point equations, such as Anderson acceleration \citep{walker2011anderson}.

The main mathematical innovation related to deep equilibrium networks is that the derivative of such a layer with respect to its inputs can be calculated based solely on a fixed point solution, i.e., no intermediate iteration values need to be stored for back-propagation. Now given some, solution $(a_0, z_0)$, such that $z_0 = g(z_0, a_0)$, and assuming certain local invertibility properties for $g$, the implicit function theorem ensures the existence of a solution mapping in the neighborhood of the solution $(a_0, z_0)$, which for another input outputs another solution to the fixed point equation. Let us denote the solution mapping as $z^*$. The solution mapping can be seen as the theoretical explicit layer corresponding to the implicit layer. To find the derivatives of the implicit layer we need to find the Jacobian of $z^*$ at point $a_0$ which can be obtained using implicit differentiation as
\begin{equation*}
\partial z^*(a_0) = \left[ I - \partial_1 g(z_0, a_0) \right]^{-1}\partial_0 g(z_0, a_0).
\end{equation*}
The vector-Jacobian product of $z^*$ needed for neural network back-propagation can be calculated from this using another fixed point equation, without fully computing the Jacobians, see, e.g., \citet{duvenaud2020deep}. As a result, both forward and backward passes of the fixed point iteration layer can be computed as a fixed point iteration.

We use these ideas to develop a neural network layer for inverting deformations based on the fixed point equation proposed for that by \citet{chen2008simple}. The resulting layer is very memory efficient as only the fixed point solution needs to be stored for the backward pass.

\section{Methods}

In deformable image registration the goal is to find a mapping from $\mathbb{R}^n$ to $\mathbb{R}^n$, connecting the coordinate systems of two non-aligned images  $x_1, x_2: \mathbb{R}^n\to \mathbb{R}^k$, often called a deformation. Here $n$ is the dimensionality of the image, e.g. $n = 3$ for three dimensional medical images, and $k$ is the number of channels, e.g. $k = 3$ for an RGB-image. Mathematically a deformation applied to an image can be represented as a composition of the image with the deformation, denoted by $\circ$, and in practice we use linear interpolation to represent images in continuous coordinates.
%
Similarly to many works in image registration, we want to learn a \textit{neural network} $f$ that can take two images as input and output the deformation connecting the image coordinates. That is, we would like in some sense that $x_1 \circ f(x_1, x_2) \approx x_2$, which in the medical context refers to anatomical  correspondence.

\subsection{Symmetric formulation}

As discussed in the introduction Section \ref{sec:intro}, we want our method to be symmetric. To achieve this, we propose to define the network $f$ using an auxiliary network $u$, which also predicts deformations, as
\begin{equation}\label{eq:anti-symmetric_formulation}
    f(x_1, x_2) := u(x_1, x_2) \circ u(x_2, x_1)^{-1}
\end{equation}
As a result, it holds that $f(x_1, x_2) = f(x_2, x_1)^{-1}$ apart from errors introduced by the composition and inversion, meaning that the cycle-consistency error should be very small. An additional benefit is that $f(x_1, x_1)$ should equal the identity transformation, again apart from numerical inaccuracies, which is a very natural property for a registration method.
%
Applying the formulation in Equation \ref{eq:anti-symmetric_formulation} naively would double the computational cost. Hence we propose to encode features from both the inputs separately before feeding them to the deformation extraction network following Equation \ref{eq:anti-symmetric_formulation}. Extracting features separately has been used in recent registration methods \citep{estienne2021mics, young2022superwarp}. Denoting the feature extraction network by $h$, the modified formulation is
\begin{equation}\label{eq:anti-symmetric_formulation_with_features}
    f(x_1, x_2) := u(h(x_1), h(x_2)) \circ u(h(x_2), h(x_1))^{-1}.
\end{equation}

\subsection{Multi-resolution architecture}\label{sec:multi-resolution}

\begin{figure*}[t]
\centering
\includegraphics[width=1.0\textwidth]{figures/architecture_overview.pdf}
\vskip -0.05in
\label{fig:architecture_overview}
\caption{\textbf{Overview of the proposed architecture.} Multi-resolution features are first extracted from the inputs $x_1$ and $x_2$ using convolutional encoder $h$. Output deformations $f_{1\to2}(x_1, x_2)$ and $f_{2\to1}(x_1, x_2)$ are built recursively from the multi-resolution features using the symmetric deformation updates described in Section \ref{sec:multi-resolution} and visualized in Figure \ref{fig:anti-symmetric_update}. The architecture is symmetric and inverse consistent with respect to the inputs and the final deformation is obtained in both directions. The brain images are from the OASIS dataset \citep{marcus2007open}}
\vskip -0.1in
\end{figure*}

As the overarching architecture, we propose a novel symmetric and inverse consistent multi-resolution coarse-to-fine approach. For motivation, see Section \ref{sec:multi-resolution_background}. Overview of the whole architecture is visualized in Figure \ref{fig:architecture_overview}.
%
First, we extract image feature representations $h^{(k)}(x_1), h^{(k)}(x_2)$, at different resolutions $k \in \{0,\dots,K - 1\}$. Index $k=0$ is the original resolution and increasing $k$ by one halves the spatial resolution. In practice $h$ is a ResNet \citep{he2016deep} style convolutional network. Starting from the lowest resolution $k=K-1$, we recursively build the final deformation between the inputs using the extracted feature representations. To ensure symmetry, we build two deformations: one for deforming the first image half-way towards the second image, and the other for deforming the second image half-way towards the first image (see Section \ref{sec:symmetric_registration_formulation}). The full deformation is then composed of these at the final stage. Let us denote the half-way deformations extracted at resolution $k$ as $f_{1\to1.5}^{(k)}(x_1, x_2)$ and $f_{2\to1.5}^{(k)}(x_1, x_2)$. Initially, at level $k = K$, these are identity deformations. Then, at each $k = K-1,\ldots, 0$, the half-way deformations are updated by composing them with a predicted update deformation. In detail, the update at level $k$ consists of three steps (visualized in Figure \ref{fig:anti-symmetric_update}):
    \begin{enumerate}
        \item Deform the feature representations $h^{(k)}(x_1), h^{(k)}(x_2)$ of level $k$ towards each other by the half-way deformations from the previous level $k + 1$:
        \begin{equation}\label{eq:deformed_features}
            \begin{cases}
                z_1^{(k)}:=h^{(k)}(x_1) \circ f_{1\to1.5}^{(k + 1)}(x_1, x_2)\\
                z_2^{(k)}:=h^{(k)}(x_2) \circ f_{2\to1.5}^{(k + 1)}(x_1, x_2)
            \end{cases}
        \end{equation}
        %JooThese deformed feature representations are then used to predict the deformation update.
        \item Define an update deformation $U^{(k)}$, using the idea from Equation \ref{eq:anti-symmetric_formulation_with_features} and the half-way deformed feature representations $z_1^{(k)}$ and $z_2^{(k)}$:
        \begin{equation}
            U^{(k)} := u^{(k)}(z_1^{(k)}, z_2^{(k)}) \circ u^{(k)}(z_2^{(k)}, z_1^{(k)})^{-1}.\label{eq:update_deformation_formula}
        \end{equation}
        Here, $u^{(k)}$ is a trainable convolutional neural network (details in Appendix \ref*{appendix:implementation_details}) predicting an auxiliary deformation. The intuition here is that the symmetrically predicted update deformation $U^{(k)}$ should learn to adjust for whatever differences in the image features remain after deforming them half-way towards each other in Step 1 with deformations $f^{(k+1)}$ from the previous resolution.%The actual deformation update is then obtained by providing the deformed feature representations from Equation \ref{eq:deformed_features} as arguments for $U^{(k)}$:
%        \begin{equation}
 %           U^{(k)}(h^{(k)}(x_1) \circ f_{1\to1.5}^{(k + 1)}(x_1, x_2), h^{(k)}(x_2) \circ f_{2\to1.5}^{(k + 1)}(x_1, x_2))
 %       \end{equation}
        \item Obtain the updated half-way deformation $f_{1\to1.5}^{(k)}(x_1, x_2)$ by composing the earlier half-way deformation of level $k + 1$ with the update deformation $U^{(k)}$
        \begin{equation}\label{eq:forward_update}
            %\begin{aligned}
            %    &f_{1\to1.5}^{(k)}(x_1, x_2)\\
            %    = &f_{1\to1.5}^{(k + 1)}(x_1, x_2)\ \circ\ U^{(k)}(h^{(k)}(x_1) \circ f_{1\to1.5}^{(k + 1)}(x_1, x_2), h^{(k)}(x_2) \circ f_{2\to1.5}^{(k + 1)}(x_1, x_2)).
            %\end{aligned}
            f_{1\to1.5}^{(k)}(x_1, x_2) = f_{1\to1.5}^{(k + 1)}(x_1, x_2)\ \circ\ U^{(k)}.
        \end{equation}
        For the other direction $f_{2\to1.5}^{(k)}(x_1, x_2)$, we use the inverse of the deformation update $\left(U^{(k)}\right)^{-1}$ which can be obtained simply by reversing $z_1^{(k)}$ and $z_2^{(k)}$ in Equation \ref{eq:update_deformation_formula}:
        \begin{equation}\label{eq:inverse_update}
            %\begin{aligned}
            %    &f_{2\to1.5}^{(k)}(x_1, x_2)\\
            %    = &f_{2\to1.5}^{(k + 1)}(x_1, x_2)\ \circ\ U^{(k)}(h^{(k)}(x_2) \circ f_{2\to1.5}^{(k + 1)}(x_1, x_2), h^{(k)}(x_1) \circ f_{1\to1.5}^{(k + 1)}(x_1, x_2)).
            %\end{aligned}
            f_{2\to1.5}^{(k)}(x_1, x_2)\\
                = f_{2\to1.5}^{(k + 1)}(x_1, x_2)\ \circ\ \left(U^{(k)}\right)^{-1}.
        \end{equation}
        The inverses $f_{1\to1.5}^{(k)}(x_1, x_2)^{-1}$ and $f_{2\to1.5}^{(k)}(x_1, x_2)^{-1}$ are updated similarly.
    \end{enumerate}

The full deformations are obtained at stage $k=0$ as:
    \begin{equation}\label{eq:final_deformation}
        \begin{cases}
            f_{1\to2}(x_1, x_2) &= f_{1\to1.5}^{(0)}(x_1, x_2) \circ f_{2\to1.5}^{(0)}(x_1, x_2)^{-1}\\
            f_{2\to1}(x_1, x_2) &= f_{2\to1.5}^{(0)}(x_1, x_2) \circ f_{1\to1.5}^{(0)}(x_1, x_2)^{-1}
        \end{cases}
    \end{equation}

\begin{figure}
\label{fig:anti-symmetric_update}
\centering
\includegraphics[width=0.7\columnwidth]{figures/anti-symmetric_update.pdf}
\caption{\textbf{Recursive multi-resolution deformation update.} Figure visualizes the deformation update at resolution $k$, described in Section \ref{sec:multi-resolution}. The update takes as input the half-way deformations $f_{1\to1.5}^{(k+1)}(x_1, x_2)$ and $f_{2\to1.5}^{(k+1)}(x_1, x_2)$ from the previous resolution, and updates them through a composition with an update deformation $U^{(k)}$. $U^{(k)}$ is calculated symmetrically from image features $z_1^{(k)}$ and $z_2^{(k)}$ at resolution $k$ (deformed mid-way towards each other with the previous half-way deformations), using a neural network $u^{(k)}$ according to Equation \ref{eq:update_deformation_formula}. The deformation inversion layer is used to invert the auxiliary deformations predicted by $u^{(k)}$ and it is described in Section \ref{sec:def_inv_layer}.}
\end{figure}

The motivation to use half-way deformations is that if we instead used learned full deformations at each stage, we would have to decide either of the image coordinates to which to deform the feature representations of the next stage, which would brake the symmetry of the overall architecture. Now we can instead deform the feature representations of both of the inputs by the symmetrically predicted half-way deformations, which ensures that the updated deformations from each stage are separately invariant to input order.

\begin{proposition}\label{proposition:anti-symmetricity}
The proposed multi-resolution architecture is by construct symmetric and inverse consistent.
\end{proposition}

\begin{proof}\renewcommand{\qedsymbol}{}
Appendix \ref*{appendix:anti-symmetricity_proof}, including also discussion on numerical errors from compositions and inversions.
\end{proof}

\subsection{Implicit deformation inversion layer}\label{sec:def_inv_layer}

Implementing the architecture requires inverting deformations from $u^{(k)}$ in Equation \ref{eq:update_deformation_formula}. This could be done, e.g., with the SVF framework, but we propose an approach which requires storing $5$ times less data for backward pass compared to the standard SVF, resulting in significant memory saving due to the large number of inversions required. For details on memory usage see Appendix \ref*{appendix:memory}.

As shown by \citet{chen2008simple}, deformations can be inverted in certain cases by a  fixed point iteration. Consequently, we propose to use the deep equilibrium network framework from Section \ref{sec:deqn} for inverting deformations, and label the resulting layer \textit{deformation inversion layer}. The fixed point equation proposed by \citet{chen2008simple} is
\begin{equation*}
    g(z, a) := -(a - \mathcal{I}) \circ z + \mathcal{I},
\end{equation*}
where $a$ is the deformation to be inverted, $z$ is the candidate for the inverted $a$, and $\mathcal{I}$ is the identity deformation. It is easy to see that feeding $a^{-1}$ for $z$, yields $a^{-1}$ as an output. We use Anderson acceleration \citep{walker2011anderson} for solving the fixed point equation and use the memory-effecient back-propagation \citep{bai2019deep, duvenaud2020deep} strategy discussed in Section \ref{sec:deqn}.

Lipschitz condition is sufficient but not necessary for the fixed point algorithm to converge \citep{chen2008simple}. As Lipschitz condition is not enforced by our method, we do not derive a theoretical proof for convergence, but empirically demonstrate that it always converges, and usually in $3$ to $6$ iterations. At most $7$ iterations were needed for maximum inversion error less than $10^{-2}$ voxels for the whole volume (Appendix \ref*{appendix:deformation_inversion_iteration_counts}). The good convergence follows from limiting individual deformations predicted by $u^{(k)}$ to be small by hard constraint which also ensures topology preservation, see details in Appendix \ref*{appendix:implementation_details}. Also, as demonstrated by the main experiments, our method produces topology preserving deformations almost everywhere.

\subsection{Training and implementation}

We train the model in an unsupervised end-to-end manner similarly to most other unsupervised registration methods, by using similarity and deformation regularization losses. The similarity loss encourages deformed images to be similar to the target images, and the regularity loss encourages desirable properties, such as smoothness, on the predicted deformations. For similarity we use local normalized cross-correlation with window width 7 and for regularization we use $L^2$ gradient penalty on the displacement fields, identically to VoxelMorph \citep{balakrishnan2019voxelmorph}. We apply the losses in both directions to maintain symmetry. One could apply the losses in the intermediate coordinates and avoid building the full deformations during training. However, we do not do this since we expect that applying the losses in the original image coordinates yields the best results. The final loss is:
\begin{equation}
%\begin{aligned}
    %\mathcal{L} &=
    %\operatorname{NCC}(x_1 \circ \phi,\ x_2) +
    %\operatorname{NCC}(x_2 \circ \phi^{-1},\ x_1)\\
    %&+ \lambda * \left[
    %    \operatorname{Grad}(d(\phi)) + \operatorname{Grad}(d(\phi^{-1}))
    %\right],
    \mathcal{L} = \operatorname{NCC}(x_1 \circ \phi,\ x_2) +
    \operatorname{NCC}(x_2 \circ \phi^{-1},\ x_1) + \lambda * \left[
        \operatorname{Grad}(d(\phi)) + \operatorname{Grad}(d(\phi^{-1}))
    \right],
%\end{aligned}
\end{equation}
where $\phi$ is a deformation, $d(\cdot)$ the displacement field,  $\operatorname{NCC}$ the local normalized cross-correlation loss, and $\operatorname{Grad}$ the gradient loss. For details on hyperparameter selection, see Appendix \ref*{appendix:hyperparameter_selection}.
%
Our implementation is in PyTorch \citep{pytorch}, and can be found at \href{https://github.com/honkamj/SITReg}{https://github.com/honkamj/SITReg}. Evaluation methods and preprocessing done by us, see Section \ref{sec:experiments}, are included.

\section{Experimental setup}\label{sec:experiments}

\textbf{Datasets:} We use two subject-to-subject registration datasets: \textit{OASIS} brains dataset with 414 T1-weighted brain MRI images \citep{marcus2007open} as pre-processed for Learn2Reg challenge \citep{hoopes2021hypermorph, hering2022learn2reg} (data use agreement website \footnote{\href{https://www.oasis-brains.org/\#access}{https://www.oasis-brains.org/\#access}}), and \textit{LPBA40} dataset from University of California Laboratory of Neuro Imaging (USC LONI) with 40 brain MRI images \citep{shattuck2008construction} (LONI Research License, Version 3.0\footnote{\href{https://resource.loni.usc.edu/resources/atlases/license-agreement/}{https://resource.loni.usc.edu/resources/atlases/license-agreement/}}). Pre-processing for both datasets includes bias field correction, normalization, and cropping. For OASIS dataset we use affinely pre-aligned images and for LPBA40 dataset we use rigidly pre-aligned images. Additionally we train our model without any pre-alignment on OASIS data (\textit{OASIS raw}) to test our method with larger initial displacements. Voxel sizes of the affinely aligned and raw datasets are the same but volume sizes differ. Details of the split into training, validation, and test sets, and cropping and resolution can be found in Appendix \ref*{appendix:dataset_details}.
%
%with resolution $256 \times 256 \times 256$
%

%\subsection{Evaluation metrics}

\textbf{Evaluation metrics:} We evaluate the \textit{registration accuracy} using segmentations included in the datasets: automatic segmentations of $35$  brain structures for OASIS and manual segmentations of $56$ brain structures for LPBA40. We use two metrics: Dice score (Dice) and 95\% quantile of the Hausdorff distances (HD95) between the segmentations of each structure, similarly to  Learn2Reg challenge \citep{hering2022learn2reg}. Dice score measures overlap of the segmentations and Hausdorff distance measures the distance between the surfaces of the segmentations. We compare the segmentations of the source images deformed by the method and the segmentations of the target images.
%
However, evaluating registration methods solely based on overlap of anatomic regions has its limitations \citep{pluim2016truth, rohlfing2011image}, and hence also \textit{deformation regularity} should be measured. As is common, we evaluate the regularity of the generated deformations by metrics based on the local Jacobian determinant. We measure topology preservation by counting the number voxels with negative determinant ($|J_{\phi}|_{\leq 0}$), and smoothness by computing the standard deviation of the determinant ($\operatorname{std}(|J_{\phi}|)$). A negative determinant means the deformation is not topology preserving at that location. % We estimate the spatial gradients required for estimating the determinants using central finite differences.
Additionally, we measure inverse and cycle \textit{consistency} errors, introduced in Section \ref{sec:intro}.

%\subsection{Baseline methods}

\textbf{Baselines:} We compare against \textit{VoxelMorph} \citep{balakrishnan2019voxelmorph}, \textit{SYMNet} \citep{mok2020fast}, and conditional LapIRN (\textit{cLapIRN}) \citep{mok2020large, mok2021conditional}. VoxelMorph is a standard baseline in deep learning based unsupervised registration. With SYMNet we are interested in how well our method preserves topology and how accurate the generated inverse deformations are compared to SVF based methods. Additionally, since SYMNet is symmetric from the loss point of view, it is interesting to see how symmetric predictions it produces in practice. cLapIRN was the best method on OASIS dataset in Learn2Reg 2021 challenge \citep{hering2022learn2reg}. We used the official implementations\footnote{\href{https://github.com/voxelmorph/voxelmorph}{https://github.com/voxelmorph/voxelmorph}}\footnote{\href{https://github.com/cwmok/Fast-Symmetric-Diffeomorphic-Image-Registration-with-Convolutional-Neural-Networks}{https://github.com/cwmok/Fast-Symmetric-Diffeomorphic-Image-Registration-with-Convolutional-Neural-Networks}}\footnote{\href{https://github.com/cwmok/Conditional_LapIRN/}{https://github.com/cwmok/Conditional\_LapIRN/}} adjusted to our datasets. SYMNet uses anti-folding loss to penalize negative determinant. Since this loss is a separate component that could be easily used with any method, we also train SYMNet without it (\textit{SYMNet, no anti-fold}). This provides a comparison on how well the vanilla SVF framework can generate invertible deformations in comparison to our method. For details on hyperparameter selection for baseline models, see Appendix \ref*{appendix:baseline_hyperparameter}.

\section{Results}\label{sec:results}

\begin{table*}
\centering
\setlength\tabcolsep{3pt}
\scriptsize
\caption{\textbf{Results for the OASIS dataset.} Mean and standard deviation of each metric are computed on the test set. VoxelMorph and cLapIRN do not predict inverse deformations and hence the inverse-consistency error is not shown. Determinant standard deviation and the consistency metrics are omitted for the SITReg trained with the non-affinely-aligned raw data since they are not comparable with other results (the omitted values were $0.18(0.028)$,  $\expnumber{1.2}{-3} (\expnumber{2.7}{-4})$, and $\expnumber{1.2}{-3} (\expnumber{2.7}{-4})$).}
\vskip 0.15in
\begin{tabular}{lcccccc}

\toprule
& \multicolumn{2}{c}{Accuracy} & \multicolumn{2}{c}{Deformation regularity} & \multicolumn{2}{c}{Consistency}\\
\cmidrule(r){2-3} \cmidrule(r){4-5} \cmidrule(r){6-7}
Model & Dice $\uparrow$ & HD95 $\downarrow$ & $|J_{\phi}|_{\leq 0} \downarrow$ & $\operatorname{std}(|J_{\phi}|) \downarrow$ & Cycle $\downarrow$ & Inverse $\downarrow$ \\
\midrule SYMNet (original) & $0.788 (0.029)$ &   $2.15 (0.57)$   &          $\bm{0.32} (0.98)$           &               $\bm{0.42} (0.038)$                & $\expnumber{3.0}{-1} (\expnumber{2.9}{-2})$  & $\bm{\expnumber{3.5}{-3}} (\expnumber{4.2}{-4})$ \\
 SYMNet (no anti-fold)            & $0.787 (0.029)$ &   $2.17 (0.58)$   &            $86 (37)$             &               $0.44 (0.043)$                & $\expnumber{2.8}{-1} (\expnumber{2.8}{-2})$ & $\expnumber{5.2}{-3} (\expnumber{8.4}{-4})$ \\
 VoxelMorph                 & $0.803 (0.031)$ &   $2.08 (0.57)$   &       $\expnumber{3.4}{3} (\expnumber{2.3}{3})$        &               $0.46 (0.030)$                & $\expnumber{4.5}{-1} (\expnumber{5.3}{-2})$ &                       -                       \\
 cLapIRN                    & $0.812 (0.027)$ &   $1.93 (0.50)$   &       $\expnumber{3.8}{4} (\expnumber{7.7}{3})$        &               $0.52 (0.030)$                & $\expnumber{1.2}{0} (\expnumber{1.6}{-1})$ &                       -                       \\
 \midrule SITReg            & $\bm{0.817} (0.025)$\significant &   $1.85 (0.46)$\significant   &            $11 (5.6)$            &               $\bm{0.42} (0.035)$                & $\bm{\expnumber{5.6}{-3}} (\expnumber{6.9}{-4})$\significant & $\expnumber{5.6}{-3} (\expnumber{6.9}{-4})$ \\
 SITReg (raw data)          & $0.810 (0.024)$ &   $\bm{1.81} (0.54)$\significant   &           $1.5 (1.9)$            &               -                & - & - \\
\midrule
\multicolumn{7}{l}{$^*$ Statistically significant ($p < 0.05$) improvement compared to the baselines, for details see Appendix \ref*{appendix:statistical_significance}.}
\end{tabular}
\vskip -0.15in
\label{table:results_oasis}
\end{table*}

\begin{table*}
\centering
\setlength\tabcolsep{3pt}
\scriptsize
\caption{\textbf{Results for the LPBA40 experiment.} Mean and standard deviation of each metric are computed on the test set. VoxelMorph and cLapIRN do not predict inverse deformations and hence the inverse-consistency error is not shown.}
\vskip 0.15in
\begin{tabular}{lcccccc}

\toprule
& \multicolumn{2}{c}{Accuracy} & \multicolumn{2}{c}{Deformation regularity} & \multicolumn{2}{c}{Consistency}\\
\cmidrule(r){2-3} \cmidrule(r){4-5} \cmidrule(r){6-7}
Model & Dice $\uparrow$ & HD95 $\downarrow$ & $|J_{\phi}|_{\leq 0} \downarrow$ & $\operatorname{std}(|J_{\phi}|) \downarrow$ & Cycle $\downarrow$ & Inverse $\downarrow$ \\
 \midrule SYMNet (original) & $0.669 (0.033)$ &   $6.79 (0.70)$   &           $\bm{0.69} (2.2)$           &               $0.34 (0.049)$                & $\expnumber{2.7}{-1} (\expnumber{6.1}{-2})$ & $\bm{\expnumber{2.1}{-3}} (\expnumber{4.3}{-4})$ \\
 SYMNet (no anti-fold)            & $0.664 (0.034)$ &   $6.88 (0.73)$   &           $14. (10.)$            &               $0.36 (0.052)$                & $\expnumber{2.8}{-1} (\expnumber{5.8}{-2})$ & $\expnumber{2.9}{-3} (\expnumber{6.7}{-4})$ \\
 VoxelMorph                 & $0.676 (0.032)$ &   $6.72 (0.68)$   &       $\expnumber{7.2}{3} (\expnumber{8.4}{3})$        &               $0.34 (0.035)$                & $\expnumber{3.1}{-1} (\expnumber{1.1}{-1})$ & -                                             \\
 cLapIRN                    & $0.714 (0.019)$ &   $5.93 (0.43)$   &       $\expnumber{3.0}{3} (\expnumber{1.1}{3})$        &               $\bm{0.26} (0.019)$                & $\expnumber{5.6}{-1} (\expnumber{1.8}{-1})$ & -                                             \\
 \midrule SITReg            & $\bm{0.716} (0.017)$ &   $\bm{5.91} (0.41)$   &           $1.8 (2.1)$            &               $0.29 (0.029)$                & $\bm{\expnumber{2.7}{-3}} (\expnumber{4.1}{-4})$\significant & $\expnumber{2.7}{-3} (\expnumber{4.1}{-4})$ \\
\midrule
\multicolumn{7}{l}{$^*$ Statistically significant ($p < 0.05$) improvement compared to the baselines, for details see Appendix \ref*{appendix:statistical_significance}.}
\end{tabular}
\vskip -0.05in
\label{table:results_lpba40}
\end{table*}

The results for the OASIS dataset are in Table \ref{table:results_oasis} and for LPBA40 in Table \ref{table:results_lpba40}. Tissue overlap results on individual anatomical regions can be found in Appendix \ref*{appendix:additonal_results}. The proposed method performs very well on both datasets in terms of registration accuracy: dice score and HD95 are equal to or better than for any baseline. In addition, the generated deformations have very little folding, similar to the diffeomorphic SVF-based SYMNet, which justifies calling our algorithm topology preserving. The number of folding voxels for both our method and SYMNet is extremely small, only a few in the whole volume of millions of voxels, whereas cLapIRN and VoxelMorph have significantly more folding voxels. In terms of cycle consistency, our method outperforms all the baseline models by a significant margin, and in terms of inverse consistency our method is similar to the SVF based SYMNet, which performs very well, showcasing that our method is indeed inverse consistent by construct. Interestingly, the model trained with non-affinely-aligned OASIS data performs equally well to the model trained with affinely aligned data, which demonstrates that the method is capable of accurately registering images even with large initial misalignments.

The assessment of registration performance should not be based on a single metric, e.g., segmentation based metrics, but instead on the overall performance with respect to different metrics, similarly to, e.g., the Learn2reg challenge \citep{hering2022learn2reg}. In the overall comparison, our method has better registration performance than the baselines since no baseline clearly outperforms our method on any metric, but our method outperforms each baseline clearly on at least two metrics: While cLapIRN performs similarly to our method in terms of tissue overlap metrics, our method achieves that with far fewer folding voxels and better cycle consistency, and while SYMNet performs similarly or slightly better in terms of deformation regularity and inverse consistency, our method performs significantly better on tissue overlap and cycle consistency metrics.

\begin{table*}
\centering
\setlength\tabcolsep{3pt}
\scriptsize
\caption{\textbf{Computational efficiency on the OASIS dataset.} Mean and standard deviation values are shown. Inference time and inference memory usage were measured on NVIDIA GeForce RTX 3090. The images raw dataset without pre-alignment have $3.8$ times more voxels resulting in significantly larger inference time and memory usage for the SITReg model trained with it.}
\vskip 0.15in
\begin{tabular}{lccc}
\toprule
 Model                               & Inference Time (s) $\downarrow$ & Inference Memory (GB) $\downarrow$ & \# parameters (M) $\downarrow$ \\
 \midrule SYMNet (original)                    &          \textbf{0.10} (0.0010)          &                \textbf{1.6}                 &              \textbf{0.9}               \\
 SYMNet (simple)         &          \textbf{0.10} (0.0011)          &                \textbf{1.6}                 &              \textbf{0.9}               \\
 VoxelMorph                          &         0.17 (0.00078)          &                5.4                 &              1.3               \\
 cLapIRN                             &         0.11 (0.00085)          &                4.1                 &              1.2               \\
 \midrule SITReg                      &          0.47 (0.032)           &                2.9                 &              1.2               \\
 SITReg (raw data) &           2.0 (0.022)           &                11.1                &              2.5               \\
\bottomrule
\end{tabular}
\vskip -0.1in
\label{table:performance_results}
\end{table*}

A comparison of the methods' efficiencies is in Table \ref{table:performance_results}. Inference time of our method is slightly larger than that of the compared methods, but unlike VoxelMorph and cLapIRN, it produces deformations in both directions immediately. Also, half a second runtime is still very fast and restrictive only in the most time-critical use cases. In terms of memory usage our method is very competitive.

\section{Conclusions}

We proposed a novel image registration architecture inbuilt with the desirable inductive biases of symmetry, inverse consistency, and topology preservation. The multi-resolution formulation was capable of accurately registering images even with large intial misalignments. As part of our method, we developed a new neural network component \textit{deformation inversion layer}. The model is easily end-to-end trainable and does not require tedious multi-stage training strategies. In the experiments the method demonstrated state-of-the-art registration performance. The main limitations are the somewhat heavier computational cost than other methods, and the lack of theoretical convergence guarantees, especially for larger deformations, although in practice good performance was observed.

\begin{ack}
This work was supported by the Academy of Finland (Flagship programme: Finnish Center for Artificial Intelligence FCAI, and grants 336033, 352986) and EU (H2020 grant 101016775 and NextGenerationEU).

Data were provided in part by OASIS-1: Cross-Sectional: Principal Investigators: D. Marcus, R, Buckner, J, Csernansky J. Morris; P50 AG05681, P01 AG03991, P01 AG026276, R01 AG021910, P20 MH071616, U24 RR021382.

We also acknowledge the computational resources provided by the Aalto Science-IT Project.
\end{ack}


\def\UrlBreaks{\do\/\do-}
\clearpage
\bibliography{references}


\end{document}
