\section{Adopting a Standard Towards Proper Risk Management}
\label{sec:requirements}

%\changeda{R2: If possible, make references to standardization items clickable so that readers can quickly navigate to the information in discussion.}\bdsnote{I've done that for the primary asset, see the first entry in the table of constructs, and the mentioning in Section 6. I think it is cool. In the tables, we can also replace the 6.x with the same text, but with a clickable reference that goes specifically to the label in the text rather than to the section heading.}.

This section provides an answer to RQ2 by discussing what the four phases of the \nist IT systems risk management standard would entail as applied to {\softprot}, i.e., what tasks need to be done in its four phases. Figure~\ref{fig:flow} presents an overview. Note how the tasks flow quite naturally, each task building on the previous ones. 
The discussion of these tasks will cover various recurring aspects, which are highlighted by means of numbered text markings. We introduce the necessary \introconstruct{constructs}\footnote{In most cases, we identify only the abstract top-level constructs, under which more concrete constructs have to be included as well. For example, we will mention the "software protection" construct, without enumerating concrete protections such as opaque predicates, control flow flattening, virtualization, etc.}, \intromodel{models}, and \intromethod{methods/practices}, introducing some useful new terminology along the way.

\begin{figure}[t]
\begin{center}
\includegraphics[width=11cm]{images/mapping_of_sections.pdf}
   \caption{Four phases of the proposed risk management approach with reference to the corresponding sections in the presentation of the approach in Section~\ref{sec:requirements}) and in the presentation of the \poc implementation in Section~\ref{sec:workflow}.}
   \label{fig:flow}
\end{center}

\end{figure}

%\changedb{R2: Itâ€™s good to see that the authors made some links between EPS and the standardization
%part in Table 3, 4, and 5. But I found the logic connections are still weak. The authors should
%at least add a column in each table to briefly explain why or why not a checkmark is there.
%}

Tables~\ref{tab:constructs},~\ref{tab:models}, and~\ref{tab:methods} present an overview of the covered abstract artifacts. For those artifacts that have already been implemented in an actual instantiation, the ESP column lists the subsections of Section~\ref{sec:workflow} in which that instantiation will be discussed in more detail. Those instantiations will demonstrate that these artifacts can in fact be implemented in a working system. They will hence demonstrate the feasibility of the covered artifacts, thus also enabling a concrete assessment of their suitability for their intended purpose, as will be discussed in Section~\ref{sec:esp:results}.

\begin{table}[t]
\begin{center}
{\footnotesize
\begin{tabular}{r l c | r l c}
No. & Construct Name & ESP & No. & Construct Name & ESP \\
\hline
\constructlab{1}  & \hyperlink{construct.1}{primary asset}                                      &   \ref{sec:esp:risk_framing}   & 
\constructlab{26} & \hyperlink{construct.26}{protection applicability}                            &   \ref{sec:esp:risk_framing}  \\
\constructlab{2}  & \hyperlink{construct.2}{secondary asset}                                     &  \ref{sec:esp:risk_framing}    & 
\constructlab{27} & \hyperlink{construct.27}{protection composability}  &   \ref{sec:esp:risk_framing},\ref{sec:esp:risk_mitigation} \\
\constructlab{3}  & \hyperlink{construct.3}{attack path}                                         &   \ref{sec:esp:risk_assessment}   & 
\constructlab{28} & \hyperlink{construct.28}{layered protection deployment}  &    \ref{sec:esp:risk_framing},\ref{sec:esp:risk_mitigation} \\
\constructlab{4}  & \hyperlink{construct.4}{attack step}  &   \ref{sec:esp:risk_framing},\ref{sec:esp:risk_mitigation}   & 
\constructlab{29} & \hyperlink{construct.29}{protection synergies}  &   \ref{sec:esp:risk_framing},\ref{sec:esp:risk_assessment}  \\
\constructlab{5}  & \hyperlink{construct.5}{attack pivot}                                        &                & 
\constructlab{30} & \hyperlink{construct.30}{potency}           &   \ref{sec:esp:risk_framing},\ref{sec:esp:risk_mitigation} \\
\constructlab{6}  & \hyperlink{construct.6}{attack time frame}                                   &                & 
\constructlab{31} & \hyperlink{construct.31}{resilience}                                          &   \ref{sec:esp:risk_framing} \\
\constructlab{7}  & \hyperlink{construct.7}{asset renewability}                                  &                & 
\constructlab{32} & \hyperlink{construct.32}{stealth}                                             &  \ref{sec:esp:risk_framing}  \\
\constructlab{8}  & \hyperlink{construct.8}{primary security req.}                                &    \ref{sec:esp:risk_framing}  & 
\constructlab{33} & \hyperlink{construct.33}{overhead/cost constraints}  &   \ref{sec:esp:risk_framing},\ref{sec:esp:risk_mitigation}  \\
\constructlab{9}  & \hyperlink{construct.9}{non-functional security req.}                         &    \ref{sec:esp:risk_framing}  & 
\constructlab{34} & \hyperlink{construct.34}{software development life cycle req.}        &    \ref{sec:esp:risk_framing} \\
\constructlab{10} & \hyperlink{construct.10}{attack identification phase}                         &                & 
\constructlab{35} & \hyperlink{construct.35}{profile information}                                 &     \\
\constructlab{11} & \hyperlink{construct.11}{attack exploitation phase}                           &                & 
\constructlab{36} & \hyperlink{construct.36}{software connectivity}                                   &   \ref{sec:esp:risk_framing}  \\  
\constructlab{12} & \hyperlink{construct.12}{secondary security req.}                             &   \ref{sec:esp:risk_framing}   & 
\constructlab{37} & \hyperlink{construct.37}{software update ability}                                        &     \\   
\constructlab{13} & \hyperlink{construct.13}{functional security req.}                            &     & 
\constructlab{38} & \hyperlink{construct.38}{environment limitations}                             &   \ref{sec:esp:risk_framing}  \\
\constructlab{14} & \hyperlink{construct.14}{assurance security req.}                             &   \ref{sec:esp:risk_framing}  & 
\constructlab{39} & \hyperlink{construct.39}{actual threats}                                      &   \ref{sec:esp:risk_assessment}  \\
\constructlab{15} & \hyperlink{construct.15}{protection policy req.}                              &                & 
\constructlab{40} & \hyperlink{construct.40}{actual risks}                                        &    \ref{sec:esp:risk_assessment} \\
\constructlab{16} & \hyperlink{construct.16}{weaknesses}                                          &                & 
\constructlab{41} & \hyperlink{construct.41}{attack surface}                                      &    \ref{sec:esp:risk_assessment} \\
\constructlab{17} & \hyperlink{construct.17}{attack resources}                                    &   \ref{sec:esp:risk_framing}   & 
\constructlab{42} & \hyperlink{construct.42}{attack vectors}                                      &   \ref{sec:esp:risk_assessment}  \\
\constructlab{18} & \hyperlink{construct.18}{attack capabilities}                                 &   \ref{sec:esp:risk_framing}   & 
\constructlab{43} & \hyperlink{construct.43}{attack paths of least resistance}                    &     \\
\constructlab{19} & \hyperlink{construct.19}{worst-case scenario assumptions}                     &                &
 \constructlab{44} & \hyperlink{construct.44}{analysis tools / toolbox}  & \ref{sec:esp:risk_framing},\ref{sec:esp:risk_assessment}  \\
\constructlab{20} & \hyperlink{construct.20}{attack enabling features}                            &    \ref{sec:esp:risk_framing}  & 
\constructlab{45} & \hyperlink{construct.45}{software features}                   &    \ref{sec:esp:risk_assessment} \\
\constructlab{21} & \hyperlink{construct.21}{attack preventing features}                         &    \ref{sec:esp:risk_framing}  & 
\constructlab{46} & \hyperlink{construct.46}{third-party-provided incomplete analysis}            &     \\
\constructlab{22} & \hyperlink{construct.22}{attack effort determination features}  &    \ref{sec:esp:risk_framing},\ref{sec:esp:risk_assessment}  & 
\constructlab{47} & \hyperlink{construct.47}{residual risks}                                      &   \ref{sec:esp:risk_mitigation}  \\
\constructlab{23} & \hyperlink{construct.23}{attack likelihood of success features}       &   \ref{sec:esp:risk_framing}  & 
\constructlab{48} & \hyperlink{construct.48}{most protective protection solution}      &    \ref{sec:esp:risk_mitigation:optimization} \\
\constructlab{24} & \hyperlink{construct.24}{software protections}                                &    \ref{sec:esp:risk_framing}  & 
\constructlab{49} & \hyperlink{construct.49}{alternative protection targets}  & \ref{sec:esp:risk_mitigation:optimization} \\
\constructlab{25} & \hyperlink{construct.25}{protection strength metrics}  & \ref{sec:esp:risk_framing},\ref{sec:esp:risk_mitigation} & 
\constructlab{50} & \hyperlink{construct.50}{mitigation round}         &     \\  
\end{tabular}
}
\caption{Constructs of the proposed approach, with references to the discussions of their instantiation, if any.}
\label{tab:constructs}
\end{center}
\end{table}

\begin{table}[t]
\begin{center}

{\footnotesize
\begin{tabular}{r l c | r l c}
No. & Model Name & ESP & No. & Model Name & ESP \\
\hline
\modellab{1}  & \hyperlink{model.1}{application and asset model}   &  \ref{sec:esp:risk_framing}  &  
\modellab{4} & \hyperlink{model.4}{attack model} & \ref{sec:esp:risk_framing}     \\
\modellab{2}  & \hyperlink{model.2}{secondary asset attributes model}  &  \ref{sec:esp:risk_framing}     & 
\modellab{5} & \hyperlink{model.5}{software protection model} & \ref{sec:esp:risk_framing} \\
\modellab{3}  & \hyperlink{model.3}{asset value evolution model}    &      & 
\modellab{6} & \hyperlink{model.6}{actual threat model} & \ref{sec:esp:risk_framing}     \\

\end{tabular}
}

\caption{Models required in the proposed approach, with references to the discussions of their instantiation, if any.}
\label{tab:models}
\end{center}
\end{table}

\begin{table}[t]
\begin{center}

{\footnotesize \setlength\tabcolsep{3 pt}
\begin{tabular}{r l c |r l c}
Phase &  & & Phase & &  \\
\& No. & Method Name & ESP & \& No. & Method Name & ESP \\
\hline
1\ \ \ \methodlab{1} & \hyperlink{method.1}{primary asset description}           &   \ref{sec:esp:risk_framing}   &   
3  \methodlab{17} & \hyperlink{method.17}{mitigation deployment}                &   \ref{sec:esp:risk_mitigation:deployment}   \\
1\ \ \ \methodlab{2} &  \hyperlink{method.2}{software analysis tools}      &    \ref{sec:esp:risk_framing}  &   
3  \methodlab{18} & \hyperlink{method.18}{mitigation validation}                   &      \\         
1\ \ \ \methodlab{3} & \hyperlink{method.3}{secondary asset description}      &    \ref{sec:esp:risk_framing}  &   
3  \methodlab{19} & \hyperlink{method.19}{\softprot impact estimation}           &   \ref{sec:esp:risk_mitigation}   \\         
1\ \ \ \methodlab{4} & \hyperlink{method.4}{secondary asset identification algorithms}     & \ref{sec:esp:risk_framing}     &   
3  \methodlab{20} & \hyperlink{method.20}{single-pass mitigation decision making}                      &   \ref{sec:esp:risk_mitigation:hiding}   \\         
1\ \ \ \methodlab{5} &  \hyperlink{method.5}{requirement description}       &   \ref{sec:esp:risk_framing}   &   
3  \methodlab{21} & \hyperlink{method.21}{iterative mitigation decision making}     &      \\         
1\ \ \ \methodlab{6} &  \hyperlink{method.6}{export models of supported protections}   &   \ref{sec:esp:risk_framing}   &   
3  \methodlab{22} & \hyperlink{method.22}{asset hiding}     &   \ref{sec:esp:risk_mitigation:hiding}   \\         
2\ \ \ \methodlab{7} & \hyperlink{method.7}{threat analysis}      &    \ref{sec:esp:risk_assessment}  &   
3  \methodlab{23} & \hyperlink{method.23}{\softprot selection optimization}      &   \ref{sec:esp:risk_mitigation:optimization}   \\         
2\ \ \ \methodlab{8} &  \hyperlink{method.8}{threat impact estimation}    &   \ref{sec:esp:risk_assessment}   &   
3  \methodlab{24} & \hyperlink{method.24}{\softprot select search space pruning}       &   \ref{sec:esp:risk_mitigation:optimization}   \\         
2\ \ \ \methodlab{9} &  \hyperlink{method.9}{risk prioritization}    &    \ref{sec:esp:risk_assessment}  &   
3\  \methodlab{25} & \hyperlink{method.25}{cookbooks with \softprot recipes} &      \\         
2\  \methodlab{10} &  \hyperlink{method.10}{defender's analysis toolbox execution}   &  \ref{sec:esp:risk_assessment}    &   
3\  \methodlab{26} & \hyperlink{method.26}{driving the \softprot tool}   &   \ref{sec:esp:risk_mitigation:deployment}   \\         
2\  \methodlab{11} & \hyperlink{method.11}{incremental attack path enumeration}     &     &   
4\  \methodlab{27} & \hyperlink{method.27}{ risk analysis updating}     &      \\         
2\  \methodlab{12} & \hyperlink{method.12}{incremental threat analysis}    &      &   
4\  \methodlab{28} & \hyperlink{method.28}{application exposure monitoring}    &      \\         
2\  \methodlab{13} & \hyperlink{method.13}{transparent threat analysis reporting}    &   \ref{sec:esp:risk_assessment}   &   
4\  \methodlab{29} & \hyperlink{method.29}{monitoring risk framing input evolution}    &      \\         
2\  \methodlab{14} & \hyperlink{method.14}{risk monetisation}    &      &   
4\  \methodlab{30} & \hyperlink{method.30}{monitoring running applications}      &   \ref{sec:esp:risk_monitoring}   \\         
2\  \methodlab{15} & \hyperlink{method.15}{OWASP risk rating methodology}    &      &   
4\  \methodlab{31} & \hyperlink{method.31}{monitoring communication of running apps}                  &  \ref{sec:esp:risk_monitoring}    \\         
3\  \methodlab{16} & \hyperlink{method.16}{mitigation decision making}                  &   \ref{sec:esp:risk_mitigation}   &
4\  \methodlab{32} & \hyperlink{method.32}{user experience evaluation}             &      \\         
\end{tabular}
}

\end{center}
\caption{Methods in the proposed approach's phases, with references to the discussions of their instantiation, if any.}
\label{tab:methods}
\end{table}



We also highlight \introopenissue{open issues that are research challenges} and discuss where we think \introsota{existing state of the art can serve as a foundation}, in some cases by pointing out \introresearchdir{potentially useful research directions to find solutions}. We present \introrecommendation{recommendations and requirements}, in particular \introautomationreq{automation requirements}, and we highlight aspects on which different stakeholders need to perform \introfuturework{future standardization and engineering work} (as opposed to research). 

% \conceptlab{12}
% \openissuelab{12}
% \sotalab{12}
% \recommendationlab{12}
% \automationreqlab{12}
% \futureworklab{12}




\subsection{Risk Framing}
\label{sec:framing}
In this phase of the approach, one defines the context in which a risk analysis will be performed. For the case at hand, one defines the relevant software targets, their assets and security requirements, potential attacks, available {\softprot}s, and \sdlc requirements. To enable standardization, a common vocabulary needs to be established that covers all possible constructs and models to describe all relevant scenarios. This needs to be unambiguous and formalized such that automated support tools can be engineered. %In this section, we list the constructs and models we consider critical to frame the risks that {\softprot}s aim to mitigate. %It is for all of the discussed concepts and their various aspects that the unambiguous, standardized, and complete vocabulary and description methodology are to be provided such that risk can be framed for concrete cases at hand. 
\futurework{Provisioning the complete vocabulary to describe the risk frame} is, of course, out of reach here. That will instead need to be done in a larger document that results from a community effort. %Later in the paper, we will provide some seeds, however.
\sota{The meta-model of Basile et al.\ can serve as a starting point for modelling all the relevant constructs and their relations~\cite{reganoMeta}}.

\subsubsection{Assets} 
\label{sec:framing:assets}
A first task for a case at hand is to determine which assets are \emph{potentially} relevant. This is needed for all the potential assets known a priori, i.e., in the original application, in already deployed {\softprot}s, if any, or in any of the {\softprot}s that might later be deployed in the mitigation phase. 

The \construct{primary assets} are static and dynamic software elements of which a \mate attacker might violate security requirements because they have value for the attacker or the vendor: monetary value, public image, customer satisfaction, bragging rights, etc. Examples are secret keys or confidential data embedded in applications, algorithms that constitute valuable intellectual property or trade secrets, multiplayer game logic that needs to remain intact to prevent cheating (e.g., see-through walls, use aim-bots, or show full world maps), and authentication checks that need to remain in place. These assets are the primary targets of \mate attackers. They cover a range of abstraction levels and granularities corresponding to a range of code and data elements (functions, variables, global data, constants, etc.). For example, an algorithm can be large and expressed in abstract terms, while a secret encryption key to steal is merely a string of bits. Primary assets are already present in the vanilla, unprotected software.

The \construct{secondary assets} are software elements that attackers might target on their \construct{attack path} (i.e., the sequence of executed \construct{attack steps}) towards the primary assets. Attackers consider these elements as mileposts on their way to their primary targets. Secondary assets can be \construct{attack pivots} (a.k.a.\ hooks) in the vanilla software, but they can also be artifacts or fingerprints of injected {\softprot}s that attackers need to overcome. An example pivot is a ciphertext buffer containing high-entropy data, which an attacker might first try to identify with statistical dynamic analysis. Once the buffers have been identified, the attacker might pivot to the program slices that produce the buffers' data, and in those slices they can obtain the secret keys. An example of an injected {\softprot} is an integrity check. A gamer that wants to alter the speed with which he can move around in the virtual game world might first have to undo or bypass the integrity check. 

\recommendation{The distinction between primary and secondary assets should not be strict.}  For example, a cryptographic key that protects one movie might be a secondary asset if the attacker tries to steal one movie. A similar key that serves as a master key for all movie encryptions is clearly a primary asset. Moreover, \softprot vendors consider the {\softprot}s supported with their tools as primary assets that they do not want to be reverse-engineered easily. While those {\softprot}s protect the primary assets of their customers' software, they are the primary assets of the \softprot vendors. Should attackers learn how to attack or circumvent them automatically, their value goes down the drain.

The deployment of some {\softprot}s requires one to describe the relationship between assets and non-asset program elements. This is the case when {\softprot} transformations applied to the code of assets require other non-asset code to be transformed with it to conserve the program semantics. When deploying a \softprot on only the assets, this should not make those assets stand out to the attacker, e.g., because the entropy of encrypted data or obfuscated code is much higher than that of plain data or because the protection introduces recognizable fingerprints. To increase the attacker's effort needed to localize them, one can deploy the same {\softprot}s on non-asset code, as proposed by Regano et al.~\cite{reganoL2P}. Furthermore, to decide which {\softprot}s can be deployed conservatively, it might be necessary to analyse the whole application and model it. In short, an \model{application and asset model} is needed to describe the wide range of software elements that form the target application, including the elements of assets and non-assets, and the relevant relations between them. The \sota{application meta-model of Basile et al.} can provide a useful starting point~\cite{reganoMeta}, but it definitely needs to be refined, as it currently only captures coarse-grained relations such as call graphs. 

Multiple methods need to be considered for instantiating a concrete application model. Obviously, a \method{primary asset description method} is required to let a user identify and describe their primary assets, preferably at a high level of abstraction, such as with \sota{source code annotations}~\cite{D5.11}. Next, \automationreq{}\method{software analysis tools} need to map those descriptions onto the corresponding lower-level software elements (e.g., onto corresponding assembly operations) and extract the structure and relevant properties of the software. Such tools are already used in all \softprot tools we know of, both commercially and in research. If the \softprot decision support tools cannot identify secondary assets themselves, a \method{secondary asset description method} is required to let a user describe the secondary assets and how they relate to primary assets. Alternatively, we foresee that \automationreq{}\method{secondary asset identification algorithms} can be developed to automate their identification. Such algorithms would be executed in the later risk assessment phase, but in the framing phase, the necessary knowledge needs to be modelled in the form of \model{secondary asset models} that describe what technical attributes of software elements allow attackers to exploit them as mileposts. An example is the already mentioned buffers that contain high-entropy data. Precisely the fact that some buffer holds such data makes it a potential milepost. \openissue{The design of such secondary asset models is an open issue.} Note that those models would not need to be recreated from scratch for every application. Instead, they would be reusable and grow over time as new types of secondary assets are considered.

As {\softprot} aims to delay attacks rather than prevent them, we need \model{asset value evolution models} to describe the evolution of their value over time, including the \construct{attack time frame} in which assets have value as well as the impact a successful attack can have on a business model. This includes the \construct{renewability of assets}, i.e., how easy it is to replace software and assets to reduce the impact of successful attacks. For modelling this evolving relationship between business value and assets, we expect that companies can use \sota{their existing asset valu\-ation models.}

%\abnote{a paragraph without annotations looks strange here, should we merge with the next part? Or "determine which assets" becomes a recommendation?} %\bdsnote{I don't agree, but maybe this type of paragraph should be placed at the start of the subsections.} 

%
\futurework{To enable asset risk framing in a standardized manner, stakeholders first need to join forces to draft a taxonomy of possible assets and their features.} 
A starting point can be \sota{Wyseur's list of assets} in the form of private data, public data, unique data, global data, traceable code/data, code, and application execution~\cite{D1.02}. Another starting point can be Ceccato et al.'s \sota{taxonomy of code and data elements} that MATE attackers considered in their experiments~\cite{emse2019}.

\subsubsection{Security Requirements} 
The \construct{primary security requirements} of assets are often the \construct{non-functional requirements} of confidentiality and integrity. These come in different forms, levels of abstraction, and granularity. Their scope differs from that in other domains, so their classifications can not be trivially reused. For example, \mate integrity requirements can include constraints on where or how code is executed, that at any point in time at most one copy of a program is running, and that certain program fragments are not lifted and executed ex-situ. In addition, there might be non-repudiation requirements. For example, unauthorized copies must be detected upon execution.  

\recommendation{For different phases in the software \sdlc, different requirements may hold, and different types of attack activities may need to be mitigated}, such as in the \construct{attack identification phase} versus the \construct{attack exploitation phase}. Some requirements may be absolute, such as a master key that should never leak; others may be time-limited, such as a key to a live  event that should remain secret for 5 minutes; still, others may be relative and economical, such as that running many copies in parallel undetected should cost more than licensing them.

Assessing whether non-functional requirements can be guaranteed is hard in practice because of the \mate attackers' white-box access. \construct{Secondary security requirements} can help frame possible risks. These can be (i) non-functional requirements for secondary assets; (ii) \construct{functional requirements} that are easier to check but of which the mere presence in itself provides few guarantees, such as the presence of a copy-protection mechanism; (iii) \construct{assurance security requirements} that minimize the risk that relevant aspects are overlooked; and (iv) what we will call \researchdir{}\construct{protection policy requirements}. The latter relates to worst-case assumptions about attacker capabilities, such as assuming that the mere presence of some features suffices to enable certain attacks. Such assumptions can compensate for the lack of proper evaluation of primary requirements. For example, a lack of stealth resulting from easily identifiable invariants in injected {\softprot}s hints for potential \construct{weaknesses} vis-\`a-vis certain attacks~\cite{yadegari}. Protection policy requirements then require that elements with certain features are not present at all or meet certain requirements, such as statistical properties. This is similar to security policies in the domain of remote exploitation, where, e.g., code pointer integrity is a policy about handling code pointers that can ensure that indirect control flow cannot be hijacked by exploits~\cite{CPI}.

In the risk framing phase, the task for a case at hand is to determine and describe the security requirements for all assets and \emph{potential} weaknesses identified as relevant. A \method{requirement description method} is needed for the user to describe their primary and part of their secondary requirements, using a requirement taxonomy. One option is \sota{to annotate the source code}~\cite{D5.11,D5.13}. \futurework{Standardizing a taxonomy requires a community effort.} \openissue{How to model protection policy requirements} is an open issue. It is closely related to the secondary asset model discussed in the previous section; the necessary models will hence best be co-designed.

\subsubsection{Attack Models} 
\mate risk management needs to consider a range of potential attacks described in an \model{attack model}. 
This needs to cover attackers with different levels of \construct{attack resources} and \construct{attack capabilities}: money, expertise, available tools, etc. The latter involves a range of methods and evolves over time, so a \futurework{living catalog} is needed. \openissue{We currently do not know what level of detail will produce the best results}, so both more generic attack methods and tool usage scenarios (e.g., disassembling code) and very concrete ones (e.g., using the IDA Pro 8.0 disassembler) need to be supported. As the goal of \softprot is to delay attacks, \recommendation{not only the feasibility of successful attacks is to be covered, but also the potential effort involved}, possibly including what attackers would probabilistically waste in unsuccessful attack strategies. 

While research has shown that attackers commonly waste time on unsuccessful attack steps in real attacks~\cite{emse2019}, \openissue{it is unclear whether useful attack models can build on} \construct{worst-case scenario assumptions}. Examples are attackers being served by an oracle always to choose the right attack path, and analysis tools producing results with ground-truth precision. For example, locating the code of interest is an important, time-consuming attack step that cannot simply be assumed to be performed effortlessly using an oracle~\cite{ReMind}. Doing so would imply that increasing the stealth of {\softprot}s is not useful, which experts certainly reject. 

For each potential attack step, the attack model needs to encode which features of software elements are \construct{attack-enabling features}, \construct{attack-preventing features}, and \construct{attack effort determination features}, i.e., that enable or prevent an attack step, or that significantly affect the required time and effort of an attack step, as well as the \construct{attack likelihood of success features}. An example is the presence of certain secondary assets. These features might include features of the software under attack, the environment in which attacks can be performed, but also knowledge obtained by the attacker. \openissue{The best abstraction levels to consider are an open question.} 

The same holds for the \construct{software protections} and a set of (quantitative) \construct{protection strength metrics} that can be used in later phases to estimate the effort/time/resources that attackers will need to invest in the attack steps in scope. Depending on the maturity of a decision support tool, that set may have to be selected manually during the risk framing. As discussed in Section~\ref{sec:challenges}, there currently is no widely accepted set of metrics. Many proposals~\cite{Anckaert2007,D4.06} have been made on features that should be measured (e.g., control flow complexity) and on concrete metrics for doing those measurements (e.g., cyclomatic complexity~\cite{mccabe} or code comprehension~\cite{Tamada2012}). \sota{Those proposals on metrics can serve as starting points}, but \openissue{more empirical research is needed on top of existing work~\cite{ReMind} to determine which metrics are valid under which circumstances and for which purposes.} \sota{RevEngE} by Taylor and Collberg seems to be a good approach for enabling more productive research of human attack activities~\cite{RevEngE}. In the context of the Grand Reverse Engineering challenge\footnote{\url{https://grand-re-challenge.org/}}, their data collection software is not only used to analyze attacks on randomly generated programs but also on purposely designed MATE challenges, which allows studying the relations between human attack effort and metrics. \sota{For automated attack tools, such as symbolic execution or black-box deobfuscation, the framework proposed by Banescu et al.\ can be a  starting point~\cite{Ban17}.} Because that framework relies on \ml, thus requiring evaluations on many samples, it is not suited for manual attack activities.  

In the risk framing phase, the task for a case at hand is to determine the attack model, i.e., the combinations of the mentioned attributes that potential attackers in scope might \emph{potentially} have. 
Existing models from network security risk analysis cannot be reused. \recommendation{\mate attack modelling needs to include manual tasks and human comprehension of code}, which are not considered in network security. 
For example, in network security, the development of zero-day exploits (using tools also found in the \mate toolbox) is handled as an unpredictable event, which side-steps the complexity of analysing and predicting human activities. \sota{This entirely prevents the use of existing assessment models developed for the network security scenario}. 

Some \sota{studies document how \mate attackers operate in practice}~\cite{ceccatoTaxonomy,emse2019,ReMind,D1.02attack}. Together with \sota{numerous blogs and case studies by reverse engineers}, such as those by Rolles~\cite{virtualizationAttack}, they can help to determine an appropriate attack model. \sota{Existing MATE attack taxonomies} can also be built upon to enable users to formulate attack models for their cases~\cite{MATEtaxonomy,ahmadvand2018,banescu2017tutorial}.

\subsubsection{Software Protections}
A \model{software protection model} is needed to describe in a unified manner the wide range of {\softprot}s that a user's tools might support. This model needs to include at least possible limitations on \construct{applicability} and \construct{composability}, be it for \construct{layered SP deployment} to protect each other or to exploit \construct{synergies} between multiple {\softprot}s; the security requirements that they help to enforce; (measurable) features or limitations they have that can enable, slow-down, ease, block, or otherwise impact potential attacks, on the {\softprot}s themselves but also on the assets they are supposed to protect; how big those impacts are on the potential attacks; and potential implementation weaknesses including how they can fail to meet protection policy requirements and become (easily) attackable assets themselves; etc. The link to validated (but as of yet still missing) metrics mentioned above is clear, and the impact that deployed SPs have on metrics used to asses attack effort, i.e., the \construct{potency}, \construct{resilience}, and when relevant the \construct{stealth} of potentially deployed SPs obviously also needs to be modelled. 

The \softprot model needs to capture the costs of using a \softprot. This can include the direct monetary costs of {\softprot} tool licenses, but also indirect costs such as having to budget for more security servers or having a longer time to market, or any other  cost that might follow from changes to the \sdlc.    

The potential overhead of all available {\softprot}s needs to be known w.r.t.\ run time, latency, throughput, size, ... This is critical because many applications have a little overhead budget when it comes to responsiveness, computation times, etc. In part, the performance impact depends solely on a {\softprot} itself, such as the (constant) time or memory required to initialize it. The impact can also depend on how a {\softprot} is deployed. For example, whenever a \softprot requires the injection of a few instructions into code fragments, the resulting overhead will depend heavily on how frequently executed those fragments are. \recommendation{Multiple ways for expressing the potential cost of {\softprot}s are hence needed.}

In the risk framing phase, the user needs to determine which combinations of {\softprot}s can \emph{potentially} be deployed to mitigate risks, given the available {\softprot} tools. For automating the later phase of risk mitigation, \automationreq{the used \softprot tool should be able} \method{to export a model of all discussed features of all SPs it supports}, such that a decision support tool can import that model and such that the tool user does not have to provide the information manually. Therefore, the SP tool vendor is responsible for instantiating the SP model of their tool. \futurework{This obviously requires tool vendors and other SP stakeholders to agree on a standardized taxonomy of SPs and their relevant features.}  To model the available composability, the \sota{finite state automata} proposed by Heffner and Collberg to model pre/post-requirements, pre/post prohibitions, and pre/post suggestions for combinations of {\softprot}s are an interesting idea~\cite{heffner2004obfuscation}. 

\subsubsection{Software Development Life Cycle Requirements}
\label{sec:framing_sdlc}
{\softprot}s come with side-effects, such as slowing down software, making it bigger, making debugging harder, requiring changes to distribution models, requiring certain scalability on the side of secure servers, etc. Taking the time to decide on {\softprot}s, possibly iteratively with the involvement of experts and time-consuming human analysis, also affects the time to market.

Hard and soft \construct{constraints} need to be collected in terms of quantifiable overheads/costs in all possible relevant forms, and with respect to compatibility with \construct{\sdlc requirements}. Different constraints might apply to different parts of a program. For example, in an online game or a movie player, the launching of the game or player might have a large overhead budget, while during the game or movie real-time behavior is critical. 

For all available {\softprot}s, later phases of the risk analysis will need to estimate the impact on the relevant costs and \sdlc. It is, therefore, necessary to obtain all relevant \construct{profile information} on the software, including execution frequencies of all relevant code fragments. 

An important complication occurs when the vendors of \softprot tools (hereafter named \softprot vendors) and users of such tools (hereafter called application vendors) do not trust each other. Both parties often put severe constraints on how the \softprot tools are deployed and on the amount of information they exchange. A \softprot vendor will typically not be very forthcoming about the weaknesses or internal artifacts of the supported {\softprot}s and disallow reverse engineering of them, while the application vendors do not want to share too many details or code with the \softprot vendor. Consequentially, only illegitimate attackers will get white-box access to the protected applications in which {\softprot}s and original assets are interwoven as discussed in Section~\ref{sec:challenges}. If the experts performing the risk management lack white-box access to all available {\softprot}s and to the protected application, this will have a tremendous impact on the methods and data that can be used during the risk assessment and risk mitigation phases that target attackers with white-box access. \recommendation{This lack of white-box access by the defenders obviously needs to be documented, and the potential impact thereof needs to be assessed} during the risk framing.

%As for the available experts, their involvement is so important that we think it is necessary to explicitly consider their availability during the risk framing phase. \softprot is so complex, and available expertise so scarce and expensive, that applying the best practices for all of the different risk management phases might be beyond the reach of an application vendor. During the risk framing phase, it is therefore important to consider which expertise is and will be available and which will not be available, such that the later phases can be adapted, e.g., by excluding the use of certain \softprot schemes/tools or by opting to use simpler, more worst-case scenario assumptions than results of complex analyses, and such that the impact of the lack of expertise can be considered.

In addition, aspects of the \sdlc relevant to the monitoring phase (that will be discussed later) need to be framed, such as \construct{connectivity} and \construct{updatability}. Whether an application will always be online, occasionally connected, or mostly offline impacts which online {\softprot}s and which monitoring techniques can be deployed. So does the ability to let application servers such as video streaming servers or online game servers interact with online security services such as a remote attestation server. Likewise, it is important \recommendation{to document whether updates can be forced upon users and to what extent the vendors can synchronize users' updates}.

Finally, \construct{limitations to the environment} in which software will be distributed and executed need to be documented. For example, Android supports fewer OS interfaces for debugging, and some device vendors limit what applications can do after installation, such as iOS's limitation on downloading binary code blobs post-installment. Such limitations clearly affect the types of {\softprot}s that can be deployed, so they need to be included in the risk framing.

\automationreq{To avoid the need for costly human expertise and manual intervention in the next process phase, as much as possible information discussed above needs to be formali\-zed, such that tools can reason about them in the subsequent phases.} As already noted at the beginning of Section~\ref{sec:framing}, this obviously requires a standardization effort by the community to create a standard vocabulary and taxonomies that cover all constructs and models to be documented in the risk framing phase.

%\lrnote{Risk framing RQ9/13/14: usability by {\softprot} experts/non-SWprot-experts-application-developers} \bdsnote{I think those are useful questions to ask in general, but in this paper, we already assume positive answers, don't we?}

%\todo[inline]{collect what can be reused}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Risk Assessment}
% \abnote{discuss impact of servers used by \softprots in the overall risk}
\label{sec:assessment}

In the discussion of risk framing, the term ``potential" occurs frequently, because in that phase all forms of knowledge are still considered in isolation, including potential \softprot weaknesses, application features, \softprot tool capabilities, and attacker capabilities. In the risk assessment phase, one assesses how they interact for the case at hand by determining which of all potential risks actually manifest themselves in the software at hand. First, a \method{threat analysis} needs to identify the \construct{actual threats} starting from an analysis of the assets and their intrinsic weaknesses, as well as from attack strategies and their technical attributes that impact their feasibility.
Then a qualitative, semi-qualitative, or preferably quantitative \method{threat impact estimation} needs to be performed to identify the \construct{actual risks}, and a \method{risk prioritization} needs to be done.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Identification of the Actual Threats} %Assets \& Security Requirements}
\label{sec:identification_threats}

This phase aims to determine a list of attacks that could succeed on one or more of the application's assets by violating their security requirements.
%
This phase therefore consists of a detailed threat analysis that outputs a \model{actual threats model} that describes those analyzed attacks deemed feasible within the assets' relevant attack time frames, i.e., the actual \construct{attack surface} and the \construct{attack vectors} on it (e.g., exploited pivots and weaknesses), the \construct{attack paths of least resistance} among them, the levels and amounts of expertise, effort, and resources attackers need to mount those attacks, the damage caused by exploitation, etc. 
For each attack path contributing to the major threats, \recommendation{the weaknesses and secondary assets used by attackers as pivots need to be included, as well as the used assumptions, such as worst-case-scenario considerations or parameters that are unknown in practice}. Reporting this information in an actual threat report is necessary to enable confidence in the outcome of the assessment. 

Critically, \recommendation{the enumeration and assessment of feasible attack steps must be performed on both the attack identification phase and the attack exploitation phase}. The former takes place in the attacker's lab on their infrastructure, the latter more often takes place on other users' devices. 

Several open issues need to be addressed to perform this task correctly. First, \futurework{standardization should produce a more precise approach and methodology for defining the \mate threat model, the attack surface, and attack vectors.} The latter includes the information attackers can extract from the target software. Assets can be attacked with different strategies, in which attackers rely on automated tools and analyses to collect and exploit information about the software and to represent the software in structured representations. A range of \construct{analysis tools} and techniques are applicable, all with their own strengths and limitations, including static, dynamic, symbolic, and concolic analyses. 
Knowing the attacker's goals and tools is the starting point for identifying and enumerating the possible attack paths. This knowledge includes the kinds of analysis results that the different tools can produce, i.e., \construct{software features} such as taint information, profiles, data, and control flow dependencies. It also includes the software features those analyses depend on to produce their results, their weaknesses, limitations, and precision. 

In this phase \method{the defender hence needs to deploy their own analysis toolbox} to determine the features of the  primary assets and related application elements that can have an impact on the feasibility of attacks because they enable, prevent, slow down, or otherwise impact attacks. This includes \recommendation{checking whether the protection policy requirements formulated in the risk framing phase are violated}. It also \recommendation{needs to be done for all potential weaknesses} that were identified in the framing phase, such as invariants or fingerprints in the code that might facilitate certain attack vectors. Moreover, \recommendation{the set of actually present secondary assets needs to be determined} to identify the presence of features that make them pivots for attackers towards the primary assets. \automationreq{Obviously, most if not all of the analyses in the toolbox should be applied automatically.}

While we are convinced that such defender toolboxes can produce most of the necessary information for enumerating feasible attacks, a number of research questions are open. 
For example, \openissue{how can the formal pieces of information extracted by the tools be used to precisely identify the viable attack paths?} In particular, when attackers need to resort to manual efforts, that is not easy to formalize. 
\openissue{How do we then assess the required effort and likelihood of success?} 
\openissue{To what extent can automated analysis with a defender toolbox suffice to avoid the need for actual penetration testing involving human experts?} %It would be interesting to determine how this knowledge can be used to automate attack identification. 

%%%%%%%%%%%%%%%%%%%%%%%

It is also an open question \openissue{how fine-grained or concrete the enumeration of con\-sidered attacks paths and their attack steps needs to be} and how their attributes are to be aggregated.
Since the assessment must drive the mitigation, the generated information must be rich enough for the mitigation decision makers. 
Therefore, to some extent, the answer to the above question will depend on the goal of the assessment. This can be a semi-automated or fully automated mitigation phase. In the latter case, assessment information must be extensive and accurate, as an automated decision support system cannot rely on human intuition and experts' past experience.


%%%%%%%%%%%%%%%%%%%%%%%%%%%

The identification of attacks with an analysis toolbox requires \recommendation{white-box access to the application code}. In case this is not possible, e.g, because of \sdlc requirements discussed in Section~\ref{sec:framing_sdlc}, \recommendation{alternative sources of information about the different integrated components need to be considered}, such as \construct{third-party-provided incomplete analysis} reports, i.e., partial analysis reports provided by the involved parties. Alternatively, and as long as the discussed enumeration approach cannot completely replace human expertise, the inclusion of results of penetration tests performed by  red teams could be considered.  %Possible weaknesses in the design and implementation of the application to protect seriously affect the attacks that can be mounted and need to be identified.
%
In short, \openissue{the threat analysis needs to be able to take into consideration a wide range of information sources and forms.}


For the scalability and practical use of a software threat analysis process, another open issue is \openissue{} \method{incremental attack path enumeration}, i.e., how to update and maintain the attack path enumeration without repeating a full analysis from scratch when any of the involved aspects evolve while the application is still being developed, be it the application itself, the \softprot tool flow, the attackers' tool boxes, etc. Especially if the attack enumeration involves human expertise, a solution in the form of \automationreq{}\method{incremental analysis} is critical. 

The current state of the art still requires such human expert involvement. Past research aimed to \sota{auto\-mate the attack discovery with} abductive logic and Prolog~\cite{basileOTP,reganoProlog}. That suffers from computational issues, since generating attack paths as sequences of attack steps causes a combinatorial explosion and requires massive pruning.
With the pruning by Regano et al.~\cite{reganoProlog} only high-level attack strategies can be generated, which often do not contain enough information to make fine-tuned selections among similar {\softprot}s. For example, they allow determining the need for using obfuscation but do not provide hints for selecting among different types of obfuscation.

\researchdir{\ml} might be useful to synthesize attack paths from attack steps more effectively~\cite{10.1145/2229156.2229157}.
Moreover, \researchdir{}\sota{methods for exploit generation}~\cite{brumley_apeg,angr} that automatically construct remote exploits for vulnerable applications could be investigated to determine \mate attack paths automatically. 
They will certainly need modifications, as finding exploitable vulnerabilities is rather different from finding \mate attack paths.
For example, in the \mate threat analysis, for each identified attack path \recommendation{defenders need to estimate the likelihood of succeeding as a function of the invested effort, attacker expertise, time, money, and luck in trying the right strategy first or not}, etc. All of that is absent in the mentioned automated exploit generation.  

Regarding automation, we think the identification and description of primary assets cannot be automated, as those depend on the business model around the software. They can hence not be determined by only analysing the software. By contrast, \automationreq{the identification of secondary assets, as mentioned in Section~\ref{sec:framing:assets}, as well as the discovery of attack paths and the assessment of their likelihood, complexity, and other risk factors, should be prime targets for automation}.

Even if full automation is out of reach because parts cannot be automated or do not produce satisfactory results, automating large parts of the threat identification phase will already have benefits. It will reduce human effort, thus making proper risk assessment cheaper and hence more accessible, and it can raise awareness about identified attack strategies, thus making the assessment more effective. \researchdir{A gradual evolution from a mostly manual process, over a semi-automated one, to potentially a fully automated one, is hence a valuable R\&D goal}. We stress that in order to succeed, automated tools should then not only provide the necessary inputs for later (automated) phases of the risk management, \automationreq{they should also enable experts to validate the produced results to grow confident in the tools}, by \method{providing a transparent report on the performed threat analysis.}  Section~\ref{sec:workflow} will present a tool that, although rather basic, achieves just that.
%
\sota{For presenting the threats to human experts, different formats have been proposed in the literature, including attack graphs~\cite{attack_graphs} and Petri Nets~\cite{petri_nets_attacks}}.






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Evaluating and Prioritizing Risks}
% \abnote{explain the consequences and side effects of assets violated }
\label{sec:req:prioritization}


The \recommendation{risk assessment report must indicate the consequences that exploitation of an identified actual threat may have. It must produce an easily intelligible value or score associated with all the risks to all assets}. 
%
Since the objective of the report is prioritizing the risks to drive the mitigation phase, \recommendation{it must not only consider the direct value of the violated primary assets, but also the side effects}, like impact on the business reputation or market share losses.

Furthermore, \recommendation{it may consider the likelihood that attack\-ers are interested in executing the identified threats} because of different expected {\roi}s. For example, an attack path that offers a lot of potential gains for the attacker might be less attractive when it comes with a high probability of being detected and having to face legal consequences.


When outcomes from the impact analysis are available in proper form, our feeling is that this phase has no peculiarities compared to risk analysis in other fields. 
Models and methods can therefore be adopted from existing literature to build a system that allows the consistent evaluation of the impact. 
As a promising option, we consider \researchdir{}\sota{}\method{risk monetisation}~\cite{doerry2015monetizing}, the process of estimating the economic loss related to risk and the \roi of mitigation activity. This eases reporting to higher management and is general enough to work for every asset type, including software assets.
\researchdir{}\sota{Investigating the aspects of the }\method{OWASP risk rating methodology} could also yield interesting results  that might work in the \mate context~\cite{OWASPrisk}. 
Automation support for the available options can then obviously also be reused, possibly after some adaptations.


\subsection{Risk Mitigation}
This phase comprises two parts: first \method{mitigation decision making}, and next there is \method{implementing} and \method{validating} the decisions.  

\subsubsection{Mitigation Decision Making}
\label{sec:decision_making}
\recommendation{Risk mitigation requires the defenders to evaluate how the deployment of combinations and configurations of {\softprot}s will affect the high(est) risk attack paths}. %, either by preventing the execution of those attack paths as is, instead requiring additional or alternative attack steps; or by requiring attackers to invest significantly more effort, time, and resources to execute them. 

Ideally, this evaluation can be done through \method{\softprot impact estimation} without having to actually deploy the considered {\softprot}s and having to measure their effect. This is a major difference from the risk assessment phase, which relied heavily on measurements. \openissue{How precise the estimations need to be to enable a sufficiently precise comparison of} \construct{residual risks} is an open question. We consider two possible approaches. 

First, we consider \method{single-pass mitigation}. \researchdir{This builds on an assumption that estima\-tions are accurate enough to determine the best possible combination of {\softprot}s without additional measure\-ment.} A human or tool then first determines the \construct{most protective selection}, i.e., the combination and configuration of SPs that achieves the minimal residual risk while not violating hard constraints. Next, one selects \construct{alternative protection targets} that trade off some of the residual risks for other aspects, such as lower performance penalty. For each alternative target, one then again selects the best target-specific {\softprot}s and estimates the delta in residual risk and in other relevant aspects over the selection that yielded the minimal residual risk. Finally, one then chooses between the most protective selection and the alternatives. This human decision will typically involve {\softprot} experts, application architects, and managers familiar with the business strategy. Given the complexity of {\softprot} as discussed before, we consider such a decision making process not automatable at this point in time, nor in the near future. 
%It is simply out of reach for humans and for current decision support tools.  \abnote{anectodal?}

The alternative is \method{iterative mitigation}. \researchdir{This approach, which is familiar to practitioners in the industry, adds additional {\softprot}s iteratively in a layered fashion.} The assessment and mitigation phases are not executed once, but alternated over multiple rounds. In each \construct{mitigation round}, an assessment is followed by mitigation. In the first round, the risk assessment is done on the vanilla application. In later rounds, the assessment is performed on the application protected with all {\softprot}s selected in previous rounds. During such later assessments, measurements are performed on already selected and deployed {\softprot}s. This works around the lack of precise enough estimation methods as needed for the first approach. 
%Additional risks introduced by the deployment of {\softprot}s need to be considered as well in estimating the residual risk. For instance, remote attestation techniques rely on the presence of a trusted remote server that checks software integrity. While research papers assume these server as trusted and invulnerable, considering risks in the real world is different and attackers controlling these servers may hide their activities. 
It also eases the handling of novel risks introduced by deployed {\softprot}s, such as when the location of non-stealthy {\softprot}s might leak the location of assets.

In each round, the mitigation adds an SP layer consisting of a few additional {\softprot}s to the ones already selected in previous rounds. In each round, different combinations of {\softprot}s can be proposed that offer different risk reduction and cost trade-offs. Humans will then again select one combination and continue to the next round, or stop once the whole cost budget is consumed or no more significant risk reduction is achieved. In each round, different constraints can be imposed that limit the {\softprot}s considered in that round, and the set of {\softprot} is chosen that offers the best potential to reduce the residual risk. Estimating the reduction potential rather than the immediate reduction in each round allows for taking into account a priori knowledge about the fact that some {\softprot}s have the potential to become much stronger after additional rounds corresponding to additional layers are deployed, while other {\softprot}s cannot become stronger because of a lack of synergies.

An example of constraints evolving between rounds is that in the first rounds {\softprot}s might only be deployed on assets, while in later \method{asset hiding} rounds, non-stealthy {\softprot}s can be added for non-assets to avoid that protected assets stand out because of \softprot fingerprints. Our \poc contains such an asset hiding step, albeit in the same round as the asset protection step, i.e., without performing measurements in between, as will be detailed in Section~\ref{sec:esp:workflow:hiding}.

The iterative approach is more realistic for several reasons. The humans making decisions in each round can make up for deficiencies in the existing tool support and formalized knowledge, and they can build more confidence in the outcomes of the mitigation process. Secondly, measurements are performed in each round, which again allows for more confidence in the outcomes. 

Automation poses the most severe constraints on the mitigation task.  
\method{Optimizing the selection of of {\softprot}s} must comply with computational constraints. \automationreq{In most usage scenarios, optimization models must return results within minutes or hours.} 
%\abnote{this is true also when no automation is required. Or not?}
Given the large search space to explore, this requires ad hoc \method{search space pruning} methods that prune less relevant combinations efficiently. In some usage scenarios, optimization models returning far-from-optimal results quickly are acceptable, such that the time-to-market requirements of a software launch can be met while spending more time to find better {\softprot} combinations for later updates.\footnote{Anonymously, \softprot suppliers confirm to us that for many of their customers the norm is weak implementation at first because security/protection is not on the feature list from product management, and then complaining when things get broken, after which the supplier needs to help out. Obviously, they prohibit us to document concrete cases.}

\recommendation{Within one round of decision making, the optimization process should be driven by at least the potency of the selec\-ted \softprot combination and by estimating the protected software's performance. Ideally, resilience is also considered.} Current methods for estimating the potency, resilience, and (to some extent) overheads are not usable for automatic decision support, as they require the deployment of the {\softprot}s to perform a measurement. Given the time and resources needed to apply {\softprot}s on non-toy programs to measure objective metrics and run-time overheads, an optimization process that requires measurements instead of estimations would only consider a very limited solution space, which would make the optimization process useless.

\openissue{Estimating the strength (and overhead) of layered {\softprot}s} is really hard, as their code is highly interwoven.% Methods from, e.g., network security to aggregate the strength and overhead of combined but clearly isolated network security controls are hence not reusable.
Our work on \sota{estimating the potency of obfuscations~\cite{reganoMetric}} and on \sota{a game-theoretic approach to optimize the selection of {\softprot}s~\cite{ReganoPhd}} will be discussed in Section~\ref{sec:esp_optimization_approach}.
\researchdir{\ml can likely help to solve this difficult problem}, as already demonstrated for specific aspects of strength such as resilience against symbolic execution~\cite{Ban17}, but clearly need further research.

\openissue{Another open issue is that {\softprot}s have varying effects on attack success probability}, in particular when the security requirements are time-limited or relative. In some cases, the effects can be quantified in absolute terms, such as increased brute-force effort required to leak an encryption key from well-studied white-box crypto protection. In other cases, such as the delay in human comprehension of code that has undergone design obfuscations~\cite{collbergbook}, the effect is harder to quantify. When software contains different assets with different forms of security requirements, the relative value of different {\softprot}s hence becomes  difficult to determine, and hence the overall risk mitigation optimization becomes increasingly difficult.


\sota{There is a limited body of existing work available on the described decision support}, and it does not cover all necessary constructs, models, and methods. In industrial practice, companies provide so-called \method{cookbooks with {\softprot} recipes}. For each asset, users of their tools are advised to manually select and deploy the prescribed SPs in an iterative, layered fashion as long as the overhead budget allows for additional {\softprot}s. Automated approaches are either overly simplistic or limited to specific types of {\softprot}s, and hence only support specific security requirements. 
Collberg et al.~\cite{collberg1997taxonomy}, and Heffner and Collberg~\cite{heffner2004obfuscation} studied how to decide which obfuscations to deploy in which order and on which fragments given an overhead budget. So did Liu et al.~\cite{obf_optvialangmods,7985664}. They differ in their decision logic and in the metrics they use to measure {\softprot} effectiveness. Importantly, however, their used metrics are fixed and limited to specific program complexity and program obscurity metrics, without adapting them to the identified attack paths.
Coppens et al.\ proposed an iterative software diversification approach to counter a concrete form of attack, namely diffing attacks on security patches~\cite{coppens2013feedback}. Their work measured the performance of concrete attack tools to steer diversification and reduce residual risks. All of the mentioned works are limited to obfuscations. In all works, measurements are performed after each round of transformations, much like in the second approach we discussed above. 

To improve the user-friendliness of manually deployed \softprot tools, Brunet et al.\ proposed composable compiler passes and reporting of deployed transformations~\cite{10.1145/3338503.3357722}. Holder et al.\ evaluated which combinations and orderings of obfuscating transformations  yield the most effective overall obfuscation~\cite{obf_evaloptphaseord}. However, they did not discuss the automation of the selection and ordering according to a concrete program and security requirements.




\subsubsection{Actual Deployment}
\recommendation{In each mitigation round, the chosen {\softprot} combination needs to be deployed}, so {\softprot} tools need to be configured and run to inject the {\softprot}s selected so far. Ideally, this is completely automated. \automationreq{This requires tool interfaces that allow} \method{the decision support tools to drive the {\softprot} tools}. Providing such interfaces and enabling this automation would have significant benefits. Besides saving effort on manual user interventions, it would also skip the learning curve of configuring the used tool flows properly. Moreover, having such an integrated framework could pave the road for an open standard for an API for {\softprot}.

Following the deployment, \recommendation{it is critical to validate that the {\softprot} tools actually delivered as expected.} Were the selected {\softprot}s injected in the intended way? Do the injected {\softprot}s have weaknesses that were not expected? \openissue{How to obtain the necessary validation is an open question in some usage scenarios,} in particular when the deployment of the mitigation is executed by multiple parties that do not want to share sensitive information and do not provide white-box access to their software components. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Risk Monitoring}

According to the NIST~\cite{nistSP800-37} risk monitoring includes ``assessing control effectiveness, documenting changes to the system or its environment of operation, conducting risk assessments and impact analysis, and reporting the security and privacy posture of the system.''
%
For \softprot, \recommendation{monitoring involves the continuous tasks to be performed once the software has been released} to track how the risk exposition evolves over time. 
This consists of two related activities: \method{updating the risk analysis}, and \method{monitoring the risk exposure of the released application}. 


\subsubsection{Keeping the Risk Analysis Up-to-date}

Keeping the analysis up-to-date requires \method{monitoring how the inputs used in the three earlier risk analysis phases evolve over time and how that evolution affects the decisions made in those phases.} We can abstract these into monitoring the evolution of three different pillars of information: the information related to the assessments (\eg, new attacks, attack techniques, tool updates), the information related to {\softprot}s (\eg, updates, vulnerabilities, breaches), and the information related to the protected application. 
Of course, monitoring can then lead to the decision that a differently-protected version of the application should be released whenever any tracked changes lead to a re-evaluation of earlier decisions.

The \recommendation{monitoring of information related to {\softprot}s con\-cerns both attacks against existing {\softprot}s and newly developed {\softprot}s}. For example, when a complex attack technique (e.g., generic deobfuscation~\cite{yadegari}) is first presented in the academic literature, it might not be considered relevant during an original risk assessment because the attack is hard to replicate and its effectiveness has not been demonstrated on more complex pieces of software. However, when attackers later release a toolbox that automates the replication and publish a blog discussing how they used it to attack a complex application successfully, this should lead to a re-evaluation. Similarly, \recommendation{when new {\softprot}s become available with higher effectiveness against old or new attacks, or with lower overhead, this may lead to a re-evaluation}.

%Other changes in the {\softprot} landscape that can affect the risk assessment are new {\softprot}s that become available on the market, with different properties than those that were considered before. For example, they might protect against certain attacks in a much stronger fashion or with significantly less overhead than previous techniques. All these changes in knowledge of the {\softprot} landscape can then lead to the knowledge that changes need to be made to earlier decisions.

Similarly, \recommendation{monitoring must consider that information related to the application can itself evolve}. One example is where a company might decide that there are, in fact, additional assets in the program that need to be protected. This can happen both as a late realisation after deployment, but also in the case where the application itself evolves over time, by virtue of new versions being released with changes in functionality or structure. Another example is that the priorities in the company's value estimation can change over time. This would mean that the associated formulas for the risk analysis produce different values.

\subsubsection{Risk Monitoring of the Released Application}
\label{sec:monitoring_relaesed}
%In addition to keeping the risk analysis up to date, it is also possible to try to monitor the usage of the specific instances of the protected application. To be able to perform this type of monitoring, an application needs to send information about its operation back to the vendor. This is of course only possible in the case where the application already had an online component to begin with, or if the deployment of a {\softprot} with an online component was deemed necessary by the risk analysis.

Next, one needs to \method{monitor how copies of the released soft\-ware are running on their users' premises}.
This can be achie\-ved by \method{monitoring the information that the protected application communicates to the vendors}. 
%This information can originate from the original application in case it already had an online component, as is the case in a streamed media client, or when a \softprot with an online component was injected as part of the mitigation process. 
Such information may originate from a \sota{monitoring\-by-design \softprot such as reactive remote attestation~\cite{viticchie2016reactive}}, but also from communication with other online components that were not originally designed for online monitoring.
This is particularly the case when anomaly detection can link irregular communication patterns to unauthorized activities, such as running multiple copies in parallel or executing program fragments in a debugger in execution orders or frequencies not consistent with authorized uses. 
Such patterns can occur from communications present in the original applications, or from online {\softprot}s such as code \sota{renewability~\cite{renewability}} and \sota{client-server code splitting~\cite{barrierslicing}}. 
Importantly, the use of non-monitoring communication does not require the implementation of reaction mechanisms in the protected application to be effective. 

In many cases, \recommendation{it is advisable to analyse the data obtained with the monitoring}. The insights extracted can be helpful to respond to detected anomalies, for example, by letting the application server take action in case of discovered attacks, as well as to keep the risk analysis process up-to-date, for example, to re-valuate the threats and their likelihood. 

Finally, the vendor of the released application needs \method{user experience evaluation methods} to monitor whether the impacts of the deployed {\softprot}s  on the user experience and cost are in line with expectations or promises by the \softprot vendor. For example, if users start reporting usability issues or if online {\softprot}s lead to scalability issues, \eg because more copies are sold than originally anticipated, those evolutions might also warrant a revision of the risk mitigation strategy.

\if 0
{\footnotesize
\begin{longtable}[c]{p{.75cm}lp{9cm}p{1cm}}
\caption{Recommendations}
\normalsize\\
\toprule
Rec. & Phase & Description & ESP \\
\midrule
\recommendationlab{1} & framing& the distinction between primary assets and secondary assets should not be strict &\\
% \recommendationlab{2} & framing& describe the relationship between assets and non-asset artifacts &\\
% \recommendationlab{3} & framing& develop and use mechanisms to describe software artifacts (assets or non-assets), and
% of the relations between them&\\
% \recommendationlab{4} & framing&  model the evolution of assetsâ€™ values over time& \\
\recommendationlab{2} & framing&  tailor risk analysis according to the different phases in the Software Development Life Cycle (SDLC)&\\
% \recommendationlab{6} & framing&  model attackers according to different levels of resources and capabilities&\\
\recommendationlab{3} & framing& cover both the feasibility of successful attacks and the needed effort &\\
% \recommendationlab{8} & framing& for each potential attack step, clarify in clear terms what enables or prevents the attack step, and what significantly increases or decreases the required time and effort, and the likelihood of success&\\
\recommendationlab{4} & framing& consider manual tasks and human comprehension of code when modelling MATE attacks&\\
% \recommendationlab{10} & framing& describe a wide range of available \softprot{}s in a unified manner &\\
\recommendationlab{5} & framing& consider all the costs associated with using \softprot{}s&\\
% \recommendationlab{12} & framing& estimate the amount of potential overhead of \softprot{}s on your code &\\
% \recommendationlab{13} & framing& list hard and soft constraints and associate them with quantifiable overheads/costs &\\
% \recommendationlab{14} & framing& obtain all relevant profile information of the software to protect & \\
\recommendationlab{6} & framing& document if defenders cannot have white-box access to the application to protect, assess the impact thereof &\\
% \recommendationlab{16} & framing& consider the aspects of the SDLC that are relevant to the monitoring phase &\\
\recommendationlab{7} & framing&  document whether updates can be forced upon users, and to what extent the vendors can synchronize user updates &\\
% \recommendationlab{} & framing& document limitations to the environment where protected applications will be distributed and executed &\\
% \recommendationlab{19} & assessment& identify threats and risks \textcolor{red}{isn't trivial??? Especially the concrete word used in the text} &\\
% \recommendationlab{} &  assessment& perform a qualitative, semi-qualitative, or preferably quantitative estimation of these treatsâ€™ impacts and a prioritization of the risks &\\
\recommendationlab{} &  framing & consider during the assessment weaknesses, secondary assets,  assumptions, worst-case-scenario considerations and parameters that are unknown in practice & \\

\recommendationlab{} & assessment& perform an analysis to identify viable attacks and characterize them with compromised assets, needed attacker expertise, effort and resources, damages &\\
\recommendationlab{9} &  assessment& all of the enumeration and assessment of feasible attack steps must be performed both on the attack identification phase and on the attack exploitation phase &\\
\recommendationlab{10} & assessment& check if the formulated requirements are violated &\\
\recommendationlab{11} & assessment& check if weaknesses in software lead to violations of the requirements &\\
\recommendationlab{12} & assessment& determine the set of actually present secondary assets &\\
\recommendationlab{13} & assessment& assessment needs white-box access to the application code &\\
\recommendationlab{14} & assessment& consider alternative sources of information about the features and weaknesses present in the different integrated components &\\ 
\recommendationlab{15} &  assessment& estimate the likelihood of succeeding as a function of the invested effort, attacker expertise, time, money, luck in trying the right strategy first or not &\\
\recommendationlab{16} &  assessment& reports must highlight the consequences of risk exploitation with an easily global intelligible score &\\
\recommendationlab{17} & assessment& consider both the value of the violated primary assets and side effects &\\
\recommendationlab{18} &  assessment& consider the likelihood that attackers are interested in executing the identified threats &\\
\recommendationlab{19} & mitigation& defenders must evaluate how certain combinations and configurations of \softprot{}s will the high(est) risk attack paths &\\
% \recommendationlab{32} & mitigation& the evaluation of the impact of the deployment of \softprot{}s can be done through estimation &\\
\recommendationlab{20} & mitigation& optimize the \softprot{}s to use based least on the potency and on the estimation of the overhead, possibly also resilience &\\
\recommendationlab{21} & mitigation& the chosen combination and configuration needs to be deployed &\\
\recommendationlab{22} &  mitigation& validate that the \softprot tools actually delivered as expected &\\
\recommendationlab{23} & monitoring& perform continuous monitoring tasks once the protected software has been released &\\
% \recommendationlab{37} & monitoring& Keep the risk analysis up-to-date by tracking how the inputs used in the past
% \recommendationlab{37} & monitoring& risk analysis activities evolve over time, and how that evolution affects the decisions made &\\
\recommendationlab{24} & monitoring& define and trigger specific tasks when new attacks against \softprot{}s are discovered and when new \softprot{}s are developed &\\
\recommendationlab{25} & monitoring& re-evaluate the selected mitigations if new {\softprot}s are developed &\\
\recommendationlab{26} & monitoring& assume that framing can evolve &\\
% \recommendationlab{41} & monitoring& monitor software execution after release at users' premises &\\
\recommendationlab{27} & monitoring& analyse online data obtained with monitoring &\\
% \recommendationlab{43} & monitoring& verify that impact \softprot{}s on user experience and promises by SP vendors &\\
\midrule
\label{tab:recommendations}\end{longtable}
}
\fi

\if 0
\begin{itemize}
\begin{itemize}
    \item update asset list and values
    \item update in the software application, even bigger if app architecture is adapted to be better protected
    \item attacker model, new tools of attack, updates on what tools allow to extract/visualize/represent, 
    \item known vulnerabilities
    \item models for assessing risks
    \item new priorities/values in company estimation (\ie change the evaluation and prioritization tasks and formulas during/for risk analysis)
    \item new protections available, improvement in the protections, new support in protection
\end{itemize}
\textbf{NIST definition: }Monitor the system and the associated controls on an ongoing basis to include assessing control effectiveness, documenting changes to the system and environment of operation, conducting risk assessments and impact analyses, and reporting the security and privacy posture of the system.

\textbf{NIST definition: }Information security continuous monitoring (ISCM) is defined as maintaining ongoing awareness of information security, vulnerabilities, and threats to support organizational risk management decisions


\item monitoring must dynamically update all the scores that have been generated during the last complete risk analysis tasks



\item monitoring should allow reporting in real time the state of exposition to the risks, including the possibility to detect compromised applications

\item parallel/analogies between IDS/IPS and protections
    \begin{itemize}
    \item protections support three functions: avoiding/delaying attacks + detecting attacks + make tampering more difficult + reporting monitoring data
    
    \item \textbf{network risk analysis:} IDS/IPS are the monitoring counterparts
    
    \item  \textbf{network risk analysis:} continuous monitoring acquires info from external sources to identify asap vulnerabilities, and data about attacks are used to sense the overall security status
    
    \item in software protection monitoring is harder, as it requires the injection also of the monitoring elements as protections
    
    \item code guards are like IPS, detect and react with no human intervention
    \end{itemize}

    \item the remote attestation covers an aspect of the monitoring, that report in real-time evidence about the app integrity
    
    \item code mobility maintains stats about the blocks deployment: this is an example of app monitoring data to be used
    
    \item reaction is based on acquired information according to a policy that may include business and security decisions: protection vendors may not be interested in blocking apps as soon as anti-tampering notice tampering to avoid business consequences of false positives
    
    \item off-line anti-tampering defines in-app monitoring of the status of a single application since they do not interact with a server 

    \item protections may give hints on the current status of exposition of attacks (single applications: analyse data from protections) and overall (e.g., from failed attestation you guess attacks)
    
    \item how to notify when compromised apps have consequences on users (private data stolen, content managed by app stolen, etc.)
    
    \item how to notify customers (of software protection companies) that they have to update the app

\end{itemize}



network risk analysis: 
\begin{itemize}
\item TASK M-1, SYSTEM AND ENVIRONMENT CHANGES, The information system and environment of operation are monitored in accordance with the continuous monitoring strategy.
\item TASK M-2, ONGOING ASSESSMENTS: Ongoing assessments of control effectiveness are conducted in accordance with the continuous monitoring strategy.
\item TASK M-3, ONGOING RISK RESPONSE, The output of continuous monitoring activities is analyzed and responded to appropriately.
\item TASK M-4, AUTHORIZATION UPDATES, Risk management documents are updated based on continuous monitoring activities.
\item TASK M-5, SECURITY AND PRIVACY REPORTING, A process is in place to report the security and privacy posture to the authorizing official and other senior leaders and executives.
\item TASK M-6, ONGOING AUTHORIZATION, Authorizing officials conduct ongoing authorizations using the results of continuous monitoring activities and communicate changes in risk determination and acceptance decisions.
\item TASK M-7, SYSTEM DISPOSAL, A system disposal strategy is developed and implemented, as needed.
\end{itemize}
\fi

\if false
\section{Automation Requirements}

% \abnote{TODO: extend}


% {\color{brown}Automating the process of risk analysis of a software applications requires the resolution of several research and engineering problems. Nonetheless, we point out that also partial solution would be of interest and that the solution of these tasks would also have important side effects. 
% Some of them have been already discussed in the previous sections.}
% \abnote{rephrase, maybe cut after bjoen pink part moved}

% {\abnote{maybe duplicated with pink bjorn}
% While it is not possible to imagine a process that automatically provides the assets in the software to protect, identifying the secondary assets is certainly an objective, especially if this is based on models of attackers. The identification of the secondary assets would also have additional benefits. Indeed, it would show defenders that they have to protect more than just the assets, thus focusing the attention on a larger parts of the code and increasing the awareness.

% Another task mentioned is the automatic identification of the attacks and the automatic assessment of the complexity, feasibility and consequences of the identified attacks.
% We also note that simply modelling what tools can do, the artifacts they produce and how these would be usable to mount attack would be a fundamental achievement, as it would allow determining the attack steps that require manual effort and help precise assessment of the risks.

% Nonetheless, there are additional constraints on the information gathered by an automatic attack discovery tool that depend on the next phases of the . Indeed, the toll's findings must be rich enough to be usable for fine tuned decisions, like the selection of similar protection (\eg, CFF vs.\ OP obfuscation) and the selection of individual configuration parameters of a single protection. 

% Having an attack discovery tool would help defenders to understand how hackers work, what they can do and why \softprot is important, that is, for awareness purposes. On the other hand, being able to figure out the findings of the tools would reassure experts about the correct behaviour of the tools, thus increase the acceptance of such an automatic tool, \textcolor{red}{which is currently very limited, as we experienced during the design of our tool.}
% }

% An attack discovery tool should be paired with automatic methods to assess based on 
\changed{
It is on the mitigation task that automation poses the most severe constraints. 
First, optimizing the selection of the combination of {\softprot}s to apply in order to mitigate the risks must comply with strict computational constraints. In turn, this implies the solution of ad hoc optimization models that, given the very large size they may reach, must guarantee that results are obtained in useful time (minutes, hours, rarely days) and that pruning actually discards the less important combinations.

Moreover, an optimization process should decide based at least on the potency of the selected combination of {\softprot}s and on the estimation of the performance of the protected app (\eg user experience). Current methods for estimating the potency and overheads are not usable for automatic decision support, as they require the actual application of the {\softprot}s.
Given the time and resources needed to apply {\softprot}s on non-toy programs, measure objective metrics, and compute or estimate the overheads by running the protected applications, the optimization would only consider a very limited solution space, making an optimization process useless.

Therefore, methods to predict the potency and the overheads are needed when a combination of {\softprot}s is applied.
%
As a solution, we have applied ML techniques to estimate the changes in the objective metrics after the application of {\softprot}s. From the predicted metrics we compute the new potency. Also, our simplified overhead estimation model is based on predicted metrics and data about the {\softprot}s, nonetheless, a new model that uses ML is under development.

As the last part that would complement automatic decision support, we mention the automatic application of the selected {\softprot}s. This step would avoid the complexity of learning how to properly configure the application of {\softprot}s. Moreover, having such a framework would pave the road for an open standard for an API for {\softprot}.
}

{\color{brown}



% For automating the risk management process, the ability is needed to automate the identification of:
\begin{itemize}

\item automatically identify the assets in the software is definitely outside the reach

\item 
identify the secondary assets to protect from an explicit specification of the primary assets in the software, \eg, by  using a sort of attacker model catalogue or as the output of automatic attack discovery. 
Secondary target: show defenders that they protect much more than just assets, focus attention on a larger important part of the code, not just the assets

\item automatically determine which attack/attack steps can be automated and when the manual effort is needed

\item ??? correctly model all the artifacts that tools produce (or may produce) to help attackers in mounting attacks. Associate some usability scores. 

\item automatically identify the attacks/attack paths, the resulting findings must be rich enough to be used for fine-tuned decisions (\eg, CFF vs.\ OP). Includes: determining the attack strategies, and adapt the automated discovery algorithms to the strategies.
Secondary target: teach people how hackers work, what they can do and why \softprot is important.
Secondary target: reassure experts that the engine works well
https://www.overleaf.com/project/5e1594c3b69e0300019fd9d9
\item 
automate the assessment of the attacks.\\
This requires the ability to estimate likelihood, and complexity (OWASP keywords). Other models of assessment (at least the fields) can be followed even if all the methods will be different.
Requires the ability to model what tools provide to attackers and when manual effort is needed.
May be hardcoded at the beginning, maybe more dynamic estimation can be achieved with more advanced automatic discovery algorithms

\item automatically identify the suitable {\softprot}s based the attack assessment

\item prioritize assets and {\softprot}s based on the attack assessment (may be superseded by full optimization)

\item automatically identify the {\softprot}s in synergy and compose them properly to maximize {\softprot} benefits

\item 
overhead estimation: evaluate the impact of the application of {\softprot}s in terms of performance and user experience 

\item estimate the impact of the {\softprot}s on assets/applications ({\softprot} level) without actually applying the {\softprot}s.
Needed to evaluate several combinations/{\softprot}s to choose the optimum.
Needed since assets and {\softprot}s are interleaved, it is not feasible to find a general model of prediction that is independent on the application to protect (universal metric, in netsec you just evaluate the fw and a few functionalities based on the service you want to protect)

\item
optimize the selection of the {\softprot}s to apply in order to mitigate the risks. Constraints: satisfy usability of the applications and the investments required 
Depends on previous items (impact without application and overhead estimation)
Do it before the end of the world (computational issues as for many optimization problems)

\item automatically mitigate the risks introduced by the mitigate phase itself (\ie asset hiding)
\item automatically apply {\softprot}s

\item the monitoring (as aspect of maintaining an up to date list of threats and risks and estimations and risk assessment procedures) depends on the economic model of the assets
\item 
\textcolor{red}{more?}
\end{itemize}
}
\fi

\if 0
\subsection{Comparison with existing}
{\color{brown}
I have thought about this section, which we have planned to have weeks ago. All the differences have been already told in the past sections. 

Why we cannot reuse some parts of the existing network security risk analysis (NSRA) process.
\abnote{add bullets points to be integrated elsewhere in the above paragraphs}

\begin{itemize}
\item different assets, different security properties (super set): this prevents from using categorizations. \bdsnote{Is this really the case? Then we should be able to explain or give concrete examples.
}
\abnote{for network security it is used the CIA triple, confidentiality, integrity, availability, for instance, we also have execution correctness as an aspect of integrity let's evaluate where to add it or it is more or less enough.}


%Models to evaluate asset value and consequences maybe can be mutuated.


%\item more complex attack paths, involve modelling of human comprehension. Different attack model. Aspects that are modelled in NSRA as unpredictable events are the aim of the attackers and their characteristics 
%This prevents entirely the use of 


%\item {\softprot}s interleaved: not isolated; cannot determine the effect in isolation of {\softprot}s and assets/systems. All the mitigation estimations would risk to be useless (pretty sure they are).


%\item {\softprot}s not available, not categorized, abuse of security-through-obscurity. The way mitigations are identified and have been standardized (in the sense that best practice exist) does not extend.

%\item no metrics to evaluate the effectiveness of attacks and {\softprot}s

%\item formulas may work: just transform in numbers  previous findings. 

%\item methodology may be the same: too general to say it does not work.

\end{itemize}
}
\fi
%\todo[inline]{collect what can be reused}


%\textcolor{blue}{TABLE THAT SUMMARIZES and organizes the recommendations}