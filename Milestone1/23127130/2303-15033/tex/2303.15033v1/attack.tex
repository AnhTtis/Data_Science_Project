\begin{itemize}
    %\item useless intro
    %\item security requirements description (maybe move into intro/requirements chapter)
    \item brief description of attack paths/trees (refs to attack trees theory + other security applications)
    \item difficulties (i.e. why coarse attack steps = backward programming combinatorial explosion + no way to automatically model actual attack steps)
    \item general work-flow of attack finder + description
\end{itemize}

%This chapter presents the risk assessment method used by \esp to infer possible attacks against the application assets in the vanilla application, \ie the unprotected program. As detailed in Section~\ref{sec:esp:workflow:model}, \esp, prior to this phase, executes a preliminary analysis of the source code, enriching the \ekb with the description of the application structure, instancing the related meta-model classes described in Section~\ref{sec:model:app}. The risk assessment phase employs this information, in order to infer attacks tailored to the specific application examined. Each attack aims to breach a security requirement of an application asset; these are provided by the user, annotating the application source code as detailed in Section~\ref{sec:esp:impl:solDep}.

%The definition of security requirements stem from the \nist guide to risk management \cite{nistSP800-39}, which defines the \textit{confidentiality} and the \textit{integrity} of assets. In this thesis, two new additional requirements are introduced, in order to adapt to the application security scenario.

%\esp supports three security requirements for assets: \textit{confidentiality}, \textit{integrity}, \textit{execution correctness}. A confidential asset must not be understandable by an attacker: this is the case for example of an algorithm that must remain secret, in order to safeguard the software company IP, or of a data structure that holds personal information of the user, such as the credit card number in an e-commerce application. The integrity requirement specifies that an asset must not be modifiable by an attacker: for example, in the case of a soccer video-game, the variables holding the characteristics of the soccer players, or the match score, can be marked with the integrity requirement, in order to avoid an attacker to cheat. The execution correctness requirement is a stronger form of integrity for code: the latter must not be modified, but must also be called as expected by other functions. For example, an attacker that wants to remove a license check function, marked with this requirement, may modify the function in order to not perform the check, but can also avoid the function to be executed, removing any calls by other functions to the license check one.

%
%Weak confidentiality is a particular case of the previous requirements, breached when the attacker is able to get a datum value in every moment of the application execution. For example, e-banking websites typically employ a two-factor authentication: to access its account, and every time it executes a security-sensitive operation (\eg a money transfer to another bank account), the user must not only provide its credentials, but also a \otp, valid only to authorize a single operation. \glspl{otp} are typically generated either using a hardware dongle, or with a mobile application. In the second case, the \otp is generation is based on a pre-shared secret among the mobile application and the e-banking server, and on a factor that changes every time a new \otp is requested by the user: for example, a counter that is incremented every time a new \otp is generated. An attacker, which has already stolen the access credentials of a user, may be interested in being able to generate such passwords at will, hacking the \otp generator. Even in the most simple case, when the attacker wants to access the e-banking account, and then transfer all the money to its account, the attacker needs to obtain two \glspl{otp}: one to access
%
%Some data may be also tagged
%with the weak confidentiality property. This property is breached when the attacker
%is able to retrieve the datum at every moment of the application execution
%(thus for hard-coded data the weak confidentiality is the same as the normal
%confidentiality). This is mostly interesting for attacks that target the assets of a
%victim’s application (i.e., not the attacker’s copy) by means of a distributed approach
%aiming at continuously obtaining the data values. For instance, in case of
%an OTP (One-Time Password) generator1 that generates the next password by
%hashing the value of a fixed seed and a counter modified at each generation, the
%variable storing the counter can be marked with weak confidentiality. To predict
%the next passwords (not only the next one), it does not suffice that the attacker
%obtains once the value of victim’s counter, he has to obtain it just before every
%generation. Therefore, either he is able to access every time the victim’s application to read the counter value, or he has to obtain one counter, understand
%the counter update function, and reproduce it on his copy.
%

%\esp models attacks against such security requirements with \textit{attack paths}, which are sequences of simple tasks that an attacker may execute (\eg locating a variable in the binary, debugging a function at run-time), called \textit{attack steps}: this modelling approach has already been used by other works in literature for risk assessment of computer networks \cite{ekelhart,fenz}. Each attack step is associated with a set of postconditions, which model the result of a successful execution by the attacker of the simple task related to the step, and a set of preconditions, which must be fulfilled by the results of other steps preceding it in the path. Attack steps may contain also preconditions about the application structure: for example, an attack step modelling the debugging of a function, can be executed only if the analyzed asset is a code and not a variable.
%Attack steps are modeled as Horn clauses \cite{hornClauses} (see Section~\ref{sec:background:expSys:inf}), and are stored in the \ekb as rules written in the Prolog language.

%\esp, to infer the possible attack paths against the asset security requirements of the target application, relies on an external inference engine, where attack steps are modelled as logical rules. At the start of the risk assessment phase, \esp instructs the engine about the structure of the application, modelling each concept of the application meta-model (see Section~\ref{sec:model:app}) as an axiom, \ie a fact that engine knows to be true. Then, \esp queries the engine, for each asset security requirement, to prove that the attacker can breach it: to do this, the engine tries to find every possible chain of rules (\ie a sequence of attack steps forming an attack path), which can be ultimately proven with a subset of the aforementioned axioms about the application structure. The engine carries out this task using a backward programming algorithm (see Section~\ref{sec:background:expSys:inf}). Other works in literature \cite{ou,kagal} have already used a similar approach to assess risk for computer networks. To ease readability, in the remainder of this chapter attack steps and axioms are expressed with the mathematical proofs notation. 

%The attack steps are modelled with the following inference rules:
% \begin{equation*}
% \infer[id,]{C}{P}
% \end{equation*}
% Where:
% \begin{itemize}
% 	\item $id$ is the name that identifies the attack step;
% 	\item $P$ is a set of facts, called \emph{premises}: if these facts are verified, the attack step can be executed by the attacker;
% 	\item $C$ is a set of facts, called \emph{conclusions}: these facts will be verified if the attack step can be carried out by the attacker.
% \end{itemize}

% The user can influence the time needed to infer the possible attack steps with two parameters. First, he or she can set a hard time limit (expressed in seconds). Also, he or she can decide a limit for the backward programming algorithm, in term of number of traversed relationships among application parts (\eg the maximum distance among application parts in the call graph), when the algorithm is searching for an attack step that, with its conclusions, can satisfy a premise of another attack step.

% Finally, the attack paths are saved in the \esp \ekb, structured using the related classes described in the meta-model (Section~\ref{sec:model:att}). The attacks are then used in the risk mitigation phase of \esp: during the latter, the protections best suitable to protect the application assets, against the attack paths previously found by the inference engine.

% This chapter is a reworked version of the publication ``Towards Automatic Risk Analysis and Mitigation of Software Applications'' \cite{reganoProlog}. It is organized in the following sections:

% \begin{itemize}
% 	\item Section~\ref{sec:prolog:app} describes the preliminary of the application structure modeling in the inference engine, previously obtained by \esp parsing the source code;
% 	\item Section~\ref{sec:prolog:goals} defines the rules needed to model the attacker goals;
% 	\item Section~\ref{sec:prolog:att} details the methodology for modelling attack steps, and how the inference engine combines them in attack paths;
% 	\item Section~\ref{sec:prolog:risk} reports on the method used to assess the risk of the inferred attack paths;
% 	\item Section~\ref{sec:prolog:validation} contains a comparison of the obtained results \wrt the \esp requisites defined in \ref{sec:esp:problem}.
% \end{itemize}

%At the start of the risk assessment phase, the \esp models all the information regarding the application structure in form of Prolog axioms, \ie facts that the engine consider true by definition. Then, the \esp queries the engine to find, for each asset security requirement, a sequence of rules (\ie attack steps) that, given the aforementioned axioms, can prove the breach of an asset security requirement. Attack paths will thus start with an attack step having only preconditions on the applic

%given the aforementioned axioms, to infer all the possible logical sequences of rules that can lead to the


\subsubsection{Application structure modeling}
\label{sec:prolog:app}

\begin{itemize}
    \item application, code, datum facts
    \item relationships facts (containment, call graph)
    \item asset + security requirements facts
\end{itemize}

% This section presents the modelling of all the preliminary information needed by the inference engine to find possible attacks against the application, comprising assets with their security requirements and the application structure. All this information is automatically retrieved by \esp in the preliminary source code analysis phase of its workflow.

% First, the existence of an application $a$ is defined with the following fact:
% \begin{equation*}
% \infer{application(a)}{}
% \end{equation*}
% Then, the application structure must be formally modelled. Each basic component of the code can be either a code or a datum (a constant or a variable); for example, if the application $a$ contains a function $f$ and a global variable $d$, this can be modelled with the following facts, using by abuse of notation the symbol $\rhd$ to indicate the containment relationship:
% \begin{equation*}
% \infer{code(f)}{} \quad \infer{datum(d)}{} \quad \infer{f \rhd a}{} \quad \infer{d \rhd a} {}
% \end{equation*}
% The containment relationship permits to organize the application structure in a hierarchical way. For example, if the function $c$ contains a local variable $v$, and a code snippet $s$, we can define the function structure with the following facts:
% \begin{equation*}
% \infer{datum(v)}{} \quad \infer{\rhd f}{} \quad \infer{code(s)}{} \quad \infer{\rhd f}{}
% \end{equation*}
% Then, a code $c$ accessing a variable $v$ can be expressed with the following fact:
% \begin{equation*}
% \infer{accesses(c,v)}{}
% \end{equation*}
% Also the call graph of the application can be modelled; if a function $f_1$ containing a call to a function $f_2$, the following fact holds:
% \begin{equation*}
% \infer{calls(f_1,f_2)}{}
% \end{equation*}
% Finally, the assets and their security requirements must be defined. If the \esp user requests the confidentiality security requirement \infer{\confidentiality}{} for a function $f_1$, integrity \infer{\integrity}{} for a function $f_2$ , and execution correctness \infer{\excorr}{} for a function $f_3$, the following facts are asserted:
% \begin{equation*}
% \infer{code(f_1)}{} \quad \infer{code(f_2)}{} \quad \infer{code(f_3)}{} \quad
% \infer{\confidentiality(f_1)}{} \quad \infer{\integrity(f_2)}{} \quad \infer{\excorr(f_3)}{}
% \end{equation*}

\subsubsection{Attacker goals modeling}
\label{sec:prolog:goals}

\begin{itemize}
    \item goal = breach asset security requirement
    \item basic rules to reach breaching of each of 3 sec. req.
\end{itemize}

% After modelling the application structure, and the assets with their security requirement, the basic rules that define the goals of the attacker can be defined. \esp, for each asset security requirement, will query the inference engine to find a set of rules that lead to breaching the requirement, denoted formally as the logical negation of the requirement. For example, if the application contains a variable $v$ whose confidentiality must be safeguarded, the inference engine will try to find all the possible sequences of attack steps that lead to the following outcome, which is a goal $G$ of the attacker:
% \begin{equation}
% \neg \confidentiality(v) \iff G.
% \end{equation}

% Security requirements are characterized by the different ways in which the attacker can breach them. The confidentiality of an asset $a_1$ is breached if the attacker finds a way to retrieve its content (instructions if $a_1$ is a code, or data if $a_1$ is a variable): 
% \begin{equation*}
% \infer{\neg \confidentiality(a_1)}{contentRetrieved(a_1)}
% \end{equation*}
% The integrity of an asset $a_2$ is breached if the attacker manages to change it, modelled with the following rules:
% \begin{equation*}
% \infer{\neg \integrity(a_2)}{changed(y)}
% \end{equation*}
% To model the breaching of execution correctness, two rules are needed. Formally, the attacker breaches the execution correctness of a code, either by modifying its instructions, or by avoiding the execution of the code, removing at least one call to the function. Thus, if a function $f$ is marked with the execution correctness requirement, the latter can be modelled with the following rules:
% \begin{equation}
% \infer{\neg \excorr(f)}{changed(f)} \quad \infer{\neg \excorr(f)}{calls(g,f) & changed(g)}
% \end{equation}
% With the definition of the following facts in the inference engine, \esp informs the latter of the application structure and of the security requirements of the assets. Thus, the attacks able reach the attacker goals, \ie to breach the security requirements of the assets, will adapt to the application structure.

\subsubsection{Attack steps and paths modeling}
\label{sec:prolog:att}

\begin{itemize}
    \item just 1 example of attack tree building
    \item ref to more complex examples in SPRO+WISTP papers
    \item brief description of actual implementation
    \item complexity analysis
\end{itemize}

% This section elaborates on the formal modelling of attack steps, basic and indivisible tasks that an attacker may carry out, and that can be combined into complete attack paths against the application assets. 

% %For the purpose of this section, it is sufficient to mark each attack step with a general id $AS$, to distinguish them from regular inference rules. Indeed, this distinction is important for the \esp: attack steps identify actions executed by the attacker, which can be deferred in the risk mitigation phase, while regular rules are simple inferences used to connect logically attack steps together, but with no use in the aforementioned phase. Also, when presenting inferred attack paths to the user, including normal inferences would result in unnecessary clutter that would complicate user comprehension of the paths.

% First, a set of basic attack steps must be defined. First, the attacker may retrieve the content of a hard-coded asset $h$, \eg a constant or a set of instructions, by locating it in the binary, and inspecting the latter manually:
% \begin{equation*}
% \infer[statLocate(h)]{contentRetrieved(h)}{hardcoded(h)}
% \end{equation*}

% Conversely, the attacker may retrieve the instructions constituting a code asset $c$ at run-time, for example by means of step-by-step execution with a debugger, provided that the execution flow of the application can lead to the target code. Similarly, an attacker can read the value of a local variable $v$ locating it in memory at run-time. This leads to the following attack steps:
% \begin{equation*}
% \infer[dynLocate(c)]{contentRetrieved(c)}{code(c)}
% \end{equation*}
% \begin{equation*}
% \infer[dynLocate(v)]{contentRetrieved(v)}{datum(v) & v \rhd f }
% \end{equation*}

% If an attacker wants to locate a datum $d$ to retrieve its value, he may try to first identify and execute at run-time a function $f$ that uses the aforementioned datum, thus finding it in memory when the instruction of the function $f$ that accesses the datum $d$ is executed:
% \begin{equation*}
% \infer[dynLocate(d)]{contentRetrieved(d)}{code(c) & contentRetrieved(c) & accesses(c,v)    }
% \end{equation*}
% Also, if an attacker wants to locate a function $f$, and he or she has already retrieved a function $g$ that calls $f$, then by simply following the call, looking at the target address of the call instruction, he or she can retrieve the function $f$ in the binary:
% \begin{equation*}
% \infer[followCall(g,f)]{contentRetrieved(f)}{calls(g,f) & contentRetrieved(g)}
% \end{equation*}
% Thus, if such datum $d$ is a confidential asset, one of the possible attack paths, leading to the attacker goal $G$ of breaching $d$ confidentiality can be obtained by chaining the previous attack steps:
% \begin{equation*}
% \infer{G}{
% 	\infer{\neg \confidentiality(d)}{
% 		\infer[dynLocate(d)]{contentRetrieved(d)}{
% 			\infer[statLocate(c)]{contentRetrieved(c)}{\infer{hardcoded(c)}{\infer{code(c)}{}}} & \infer{accesses(c,v)}{}
% 		}
% 	}
% }
% \end{equation*}
% % In this example, the attacker first identifies the address of the function $c$ in the code section of the application binary, analyzing statically the latter. Indeed the $statLocate(c)$ attack step can be executed, because $c$, being a code, is hard-coded. Then he or she attaches a debugger to the application and sets a breakpoint at the address of the function $c$ previously located. Then, since the code $c$ accesses the variable $v$, by executing $c$ step-by-step the attacker is able to find the variable $v$ when $c$ accesses it, and thus, knowing $v$'s location in memory, can retrieve its content. Therefore, the confidentiality of the asset $d$ is breached, and the attacker goal $G$ is proved. Clearly, instead of this hybrid approach (\ie by resorting to both static and dynamic analysis), the attacker can breach $d$ confidentiality in a completely dynamic manner, finding the code $c$ observing the execution flow of the application. Similarly, the call graph of the application can be used to define other attack steps. For example, an attacker may locate a function $f_1$ at run-time, if he has previously located a function $f_2$ that calls $f_1$, and the function is executed.

% % For tampering attacks two types of attack steps may be modelled. As for the retrieval of content, tampering may be carried out statically only on hard-coded assets, while it can be executed dynamically on every kind of asset. Given a code or datum $x$, the attacker may change it statically or dynamically with the following attack steps, which require the attacker to know the location of $x$:
% % \begin{equation*}
% % \infer[statChange(x)]{changed(x)}{contentRetrieved(x) & hardcoded(x)} 
% % \end{equation*}
% % \begin{equation*}
% % \infer[dynChange(x)]{changed(x)}{contentRetrieved(x)}
% % \end{equation*}

% % Thus, attack paths that endanger the integrity and execution correctness security requirements of an asset can be obtained by chaining the steps required to locate the asset that must be tampered, and the steps in which the attacker actually tamper with the asset. Given a function $f$ whose execution correctness must be preserved, \ie $f$ must not be tampered with, and all the calls to $f$ must be executed, this attacker goal $G$ can be obtained with the following two example attack paths:
% % \begin{equation*}
% % \infer{G}{
% % 	\infer{\neg \excorr(f)}{
% % 		\infer{calls(g,f)}{} & \infer[statChange(g)]{changed(g)}{  \infer[statLocate(g)]{contentRetrieved(g)}{\infer{hardcoded(g)}{}}      }
% % 	}                            
% % }
% % \end{equation*}
% % \begin{equation*}
% % \infer{G}{
% % 	\infer{\neg \excorr(f)}{
% % 		\infer[dynChange(f)]{changed(f)}{\infer[followCall(g,f)]{contentRetrieved(f)}{\infer{calls(g,f)}{} &
% % 				\infer[statLocate(g)]{contentRetrieved(g)}{\infer{hardCoded(g)}{}}
% % 		}}
% % 	}
% % }
% % \end{equation*}
% % In the first attack path, the attacker first locates the function $g$. He can do it statically since $g$ is hard-coded. Then he or her changes it, removing from $g$ the call to the asset $f$. In this way, the execution correctness of $f$ is broken. In the second attack path, the attacker locates statically the function $g$ as before, but in this case uses its address to set a breakpoint in a debugger attached to the application. For example, this can be useful in the case of an indirect call, when the target address of the call (\ie the address of $f$) is not known a priori, since it is evaluated by the program at run-time. Thus, he will execute the application, which will stop at the breakpoint set at the start of function $g$. With an execution step-by-step of the function $g$, the attacker finds the call to function $f$, follows it an then retrieves the address of the address function, thus being able to change the contained instructions and breach the execution correctness of the asset $f$.

% % Thus, starting from apparently naive attack steps, the inference engine can combine them in rather complex attack paths. All the concept and relationships among them, modelling the application structure, are obtained automatically by \esp, thus these attack paths can be obtained in a completely automated fashion, with the users asked only for the security requirements of the assets.

% Other attack steps have been devised to model attacks on applications that include network connections in their execution flow, modelling sniffing, spoofing and remote code injection attacks. However, these attack steps cannot be employed in a completely automated workflow by \esp, since it would require the identification of the specific functions that perform such network activity. This is complicated to do automatically, especially if the application uses custom network libraries. Since the requirements for \esp (see Section~\ref{sec:esp:problem}) state that all workflow phases must be executed automatically, such network-based attack steps are not deemed relevant for the scope of this thesis. Still, use of the spoofing attack step to model attacks against an \otp generator has been reported in a conference publication \cite{basileOTP}.

% The chaining of the rules is executed by the inference engine via a custom backward programming algorithm, called by \esp for each asset security requirement. Given this goal, the algorithm starts by negating the asset security requirement and then finds all the possible attack steps that can lead to the asset security requirement negation: each parallel attack step leads to a separate attack path. Then, it goes on building all the possible paths: for each of the latter, the algorithm consider completely inferred a path when the last attack step requirements can be proved only with the axioms detailing the application. Therefore, \esp builds for each asset security requirement an attack graph, which contains four different attack paths to breach the execution correctness of a code $c_2$, which is called by another function $c_1$.

% %as the one depicted in Figure~\ref{fig:attackGraph}\footnote{The avoidedCalls fact has been added to the graph to ease comprehension, but would not be present in a real attack path.},
% %\tikzstyle{Function} = [rectangle,rounded corners,draw=black, top color=white,
% %bottom color=white!50,very thick, inner sep=0.4em, minimum size=1.5em, text
% %centered]
% %\tikzstyle{Variable} = [rectangle,draw=black, top color=white, bottom
% %color=white!50,very thick, inner sep=0.4em, minimum size=1.5em, text centered]
% %\tikzstyle{myarrow} = [->, >=latex', shorten >=1pt, thick]
% %\tikzstyle{mydashedarrow} = [->, >=latex', shorten >=1pt, dashed]
% %\tikzstyle{mythickarrow} = [->, >=latex', shorten >=1pt,line width=0.6mm]
% %\tikzstyle{mylabel} = [text width=7em, text centered]
% %
% %\begin{figure}[t]
% %\centering
% %\begin{tikzpicture}[node distance=0.3cm, auto]
% %\node [Function] (breached) {breached(executionCorrectness,$c_2$)};
% %\node [Function, above right = of {$(breached)+(+0.6,+0.5)$}]
% %(changedC2)
% %{changed($c_2$)};
% %\node [Variable, above right = of {$(changedC2)+(+1.5,-0.1)$}]
% %(statChC2)
% %{statChange($c_2$)};
% %\node [Variable, right = of {$(statChC2)+(+1.511,0)$}]
% %(statLocC2)
% %{statLocate($c_2$)};
% %\node [Variable, below right = of {$(changedC2)+(+1.5,+0.1)$}]
% %(dynChC2)
% %{dynChange($c_2$)};
% %\node [Variable, right = of {$(dynChC2)+(+1.511,0)$}]
% %(dynLocC2)
% %{dynLocate($c_2$)};
% %\node [Function, below right = of {$(breached)+(-0.4,-0.4)$}]
% %(avoided)
% %{avoidedCalls($c_2$)};
% %\node [Function, below right = of {$(avoided)+(-0.6,-0.4)$}]
% %(changedC1)
% %{changed($c_1$)};        
% %\node [Variable, above right = of {$(changedC1)+(+1.5,-0.1)$}]
% %(stChC1)
% %{statChange($c_1$)};
% %\node [Variable, right = of {$(stChC1)+(+1.511,0)$}]
% %(statLocC1)
% %{statLocate($c_1$)};
% %\node [Variable, below right = of {$(changedC1)+(+1.5,+0.1)$}]     
% %(dynChC1)
% %{dynChange($c_1$)};
% %\node [Variable, right = of {$(dynChC1)+(+1.511,0)$}]
% %(dynLocC1)
% %{dynLocate($c_1$)};
% %
% %\draw[mydashedarrow] ($(avoided.north)+(-0.1,0)$) --
% %(breached.south);    
% %\draw[mydashedarrow] (changedC1.north) -- (avoided.south);    
% %\draw[mydashedarrow] (changedC2.south) -- (breached.north);    
% %\draw[myarrow] (dynChC1.west) --
% %($(changedC1.east)+(-0.08,-0.2)$);
% %\draw[myarrow] (stChC1.west) --
% %($(changedC1.east)+(-0.08,+0.2)$);\draw[myarrow]
% %(dynChC2.west) --
% %($(changedC2.east)+(-0.08,-0.2)$);
% %\draw[myarrow] (statChC2.west) --
% %($(changedC2.east)+(-0.08,+0.2)$);
% %\draw[mythickarrow] (statLocC2.west) -- (statChC2.east);
% %\draw[mythickarrow] (dynLocC2.west) -- (dynChC2.east);
% %\draw[mythickarrow] (statLocC1.west) -- (stChC1.east);
% %\draw[mythickarrow] (dynLocC1.west) -- (dynChC1.east);
% %
% %\end{tikzpicture}
% %\caption{Attack graph built against the execution correctness of a code $c2$, which is called by the code $c1$.}
% %\label{fig:attackGraph}
% %\end{figure}

% %\subsection{Network attack steps}
% %\label{sec:prolog:network}
% %This section models two additional attack steps, modelling sniffing and spoofing attacks, thus being suitable to assess threats on applications that, during their execution, communicate with a remote server. For example, e-banking websites typically employ a two-factor authentication: to access its account, and every time it executes a security-sensitive operation (\eg a money transfer to another bank account), the user must not only provide its credentials, but also a \otp, valid only to authorize a single operation. \glspl{otp} are typically generated either using a hardware dongle, or with a mobile application. In the second case, the \otp is generation is based on a pre-shared secret among the mobile application and the e-banking server, and on a factor that changes every time a new \otp is requested by the user: for example, a counter that is incremented every time a new \otp is generated. An attacker, which has already stolen the access credentials of a user, may be interested in being able to generate such passwords at will, hacking the \otp generator. 
% %%
% %To help with the modelling of this network attack steps, the \otp example is used throughout the section, thus is needed to describe its execution flow. At the first installation on the e-banking service user device, the \otp generator downloads two random values from the server, using an encrypted connection: a \textit{seed} and a \textit{counter}. Then, every time the user requests a new \otp, the generator asks a \pin to the user, so that unauthorized users having gained access (\eg stealing) to the device running the generator can obtain access to the e-banking account of the user. If the \pin inserted is correct, the generator produces the \otp, with a method based on the values of the aforementioned seed and counter, which is known to both the application and the e-banking server; thus, the \otp inserted by the user when accessing the e-banking site can be validated against the \otp produced on the server with the same method and the same values of seed and counter. After the generation of the \otp, the counter is incremented both on the generator and on the server, and a new \otp can be produced. 



\subsubsection{Risk probability}
\label{sec:prolog:risk}

\begin{itemize}
    \item evaluation of risk of each attack path on unprotected application
    \item useful for expert manual assessment of proposed L1P solution
    \item not used by automatic risk mitigation phase (since risks are on unprotected app)
    \item formulas (already present on WISTP paper, maybe just a ref is sufficient)
\end{itemize}

% In this section, a method to assess the probability of the threats against the application assets is presented. \esp, when presenting the attack paths to the user, includes also such a  probability: this is useful for experts that want to manually analyze the protections inferred by \esp in the risk mitigation phase, since they can identify the assets that are most at risk, and consequently focus on the protections targeting the most threatened assets.

% Instead, it will not be used to drive the risk mitigation phase (see Section~\ref{sec:l1p:metrics:score}): the motivation behind this is that the probabilities inferred in this phase refer to the unprotected application, while the risk mitigation phase uses a set of formulas tailored to assess the effect of attacks on protected assets, to assess the effectiveness of the inferred mitigations.

% The risk probability is based on the types of attacks inferred, and on the presumed skills of the attacker, given the profile chosen by the user at the start of the \esp workflow. Given all the inferred attack paths \(AP_{i}\), all their attack steps \(AS_{i,j}\), and all the assets \(a_{k}\), the \emph{risk} $\Omega_{\mathrm{AP}_{i}}^\epsilon$ of an attack path \(AP_{i}\) executed by an attacker with expertise $\epsilon$ is defined as:
% \begin{equation*}
% \Omega_{\mathrm{AP}_{i}}^\epsilon = \pi(\mathrm{AP}_{i},\epsilon)\;\Gamma_{\mathrm{AP}_{i}}\;\label{eq:risk}
% \end{equation*}
% where $\Gamma_{\mathrm{AP}_{i}}$ represents the damage resulting from a successful attack path, and  $\pi({\mathrm{AP}_{i}},\epsilon)$ is the probability of an attacker being able to successfully carry out the attack path, given its expertise $\epsilon$. To do so, it must be able to execute all the attack steps needed to complete it. Thus, the probability of executing an attack path is evaluated taking into account the probabilities of all the attack steps constituting the path:
% \begin{equation*}
% \pi({\mathrm{AP}_{i}},\epsilon) = f\left(\pi({\mathrm{AS}_{i,1}},\epsilon),\pi({\mathrm{AS}_{i,2}},\epsilon),\dots\right).
% \end{equation*}
% The \esp user can decide the function $f$ that must be used to combine the probabilities of the attack steps belonging to the same path, choosing among a worst case analysis, with $f=min$, a best case analysis, with $f=max$, and an approximation of the probabilities composition, with $f=\cdot$.

% $\Gamma_{\mathrm{AP}_{i}}$ is a quantitative measure of the damage resulting from a successful attack path. It is evaluated as the sum of the damage $\Gamma_{\mathrm{AS}_{i,j}}$ from each attack step:
% \[
% \Gamma_{\mathrm{AP}_{i}} = \sum_j \Gamma_{\mathrm{AS}_{i,j}}= \sum_j \sum_{k} ( W_{a_{k}} b( a_{k},\mathrm{AS}_{i,j}) )
% \]
% %where $\Gamma_{\mathrm{AS}_{i,j}}$  is the cost of a single attack step
% where \(W_{a_{k}}\) is a user-defined asset weight, and \(b( a_{k},\mathrm{AS}_{j})\) is a function, evaluated by \esp, that returns the fraction of the security properties of the asset \(a_{k}\) that are breached by the attack step \(\mathrm{AS}_{j}\), that is, it returns \(1\) if all the security properties are compromised and \(0\) if none\footnote{Thus, the whole asset weight assigned by the user is gained by the attacker when all the security properties are compromised.}.
% %\(b( a_{k},\mathrm{AS}_{j})\) is .

% The attack step probabilities $\pi({\mathrm{AS}_{i,j}})$, for each combination of attack step type, and level of attacker skill, have been obtained during the \asp project, interviewing the software security experts involved in the project during \esp design phase.


% %
% %The \esp employs a worst case analysis, setting $f=min$, thus the probability of an attack path is approximated as the one of the most easy attack step. 
% %
% %$\Gamma_{\mathrm{AP}_{i}}$ is a quantitative measure of the damage resulting from a successful attack path, calculated as the sum of the damage $\Gamma_{\mathrm{AS}_{i,j}}$ from each attack step:
% %
% %\[
% %\Gamma_{\mathrm{AP}_{i}} = \sum_j \Gamma_{\mathrm{AS}_{i,j}}= \sum_j \sum_{k} ( W_{a_{k}} b( a_{k},\mathrm{AS}_{i,j}) )
% %\]
% %%where $\Gamma_{\mathrm{AS}_{i,j}}$  is the cost of a single attack step
% %where \(W_{a_{k}}\) is the user-defined asset weight, and \(b( a_{k},\mathrm{AS}_{j})\) is a function, deduced by our inference system, which returns the fraction of the security properties of the asset \(a_{k}\) that are breached by the attack step \(\mathrm{AS}_{j}\), which is, it returns \(1\) if all the security properties are compromised and \(0\) if none\footnote{In practice, we assume that the whole asset weight assigned by the user is gained by the attacker when all the security properties are compromised.}. Finally, the values obtained with the risk formulas are mapped on a three values score (low, medium, high) with an ad hoc mapping.

\subsubsection{Validation}
\label{sec:prolog:validation}

\begin{itemize}
    \item cite requirements, why they are solved and why we are so cool
\end{itemize}

% In this section, the methodologies presented in this chapter, used by \esp to infer possible attack paths against the application assets, are compared \wrt the \esp requisites listed in Section~\ref{sec:esp:problem}.

% Regarding the requisites on the usage scenario of \esp, detailed in Sec.~\ref{sec:esp:problem:framing}, they are satisfied by the risk assessment phase. First, the profile of the attacker is taken into account, when the risk of each attack path is evaluated. Second, the execution of the backward programming algorithm used by the inference engine can be constrained, using a hard time limit, and also setting a maximum length for the attack paths: a deeper and more time-consuming search is suitable prior to the distribution of the application, while, when patches are released and time is an issue, a shallow search for possible new attack paths derived from the introduction of the patch code can be performed, limiting the time needed using the aforementioned constraints. Third, the results of the mitigation phase, \ie attack paths, are easily readable, being modelled as ordered sequences of simple attack steps: furthermore, logical inferences that do not correspond to real tasks executed by the attacker are not included in the paths, to avoid confusion for the user. Furthermore, a risk level for each inferred attack path is presented to the \esp user, which can easily identify the most problematic threats to the application.

% Analyzing the requisites for the risk assessment phase, described in Sec.~\ref{sec:esp:problem:assessment}, they are mostly satisfied. First, \esp supports not only the security requirements defined by the \nist for risk monitoring \cite{nistSP800-39}, \ie confidentiality and integrity, but also a stronger form of the latter, called execution correctness, and applicable only to functions: this security requirement prescribes that the function marked with it must not only be preserved from modification, but it must be also called as originally devised by the application developer (\eg a license check that must not be circumvented). Furthermore, \esp is able to build attack graphs for every asset in the application, due to the definition of logical inference rules that define attack steps, \ie simple attacker tasks. The chaining of these steps in attack paths is subject to the application structure, which is automatically modelled with logical facts in the inference engine: thus, the relative requirement is satisfied. Finally, a probability of execution for each attack path is evaluated, based on the attacker skills, and the probability of execution of each attack step: the latter are based on information gathered among the software security experts involved in the \asp project. The complexity metrics of the software are not taken into account in the attack path probability evaluation: however, they are taken into account later in the \esp workflow, during the risk mitigation phase, when the effectiveness of the inferred protections in protecting the assets, against the attack path inferred in the risk assessment phase, is tested with a game-theoretic approach based on this metrics.

% Finally, in the validation phase of \esp at the end of the \asp project \cite{D1.06.9}, software security experts analyzed also the attack paths inferred in the risk mitigation phase. In particular, the ones inferred by \esp on the \asp use cases (see Section~\ref{sec:esp:results}) were compared with actual attacks executed by highly skilled white-hat hackers on the same test applications. In general, \esp attack paths covered the real methodologies of the aforementioned hackers. However, they were deemed as too general to model with a sufficient amount of detail such attacks. Indeed, new rules can be added to the inference engine, in order to better model real attacks on software: however, as in the case of network-related attacks, the main problem is inferring automatically the semantics of the code that enables the execution of such complex attack step. Thus, this is still an open problem, which the author is actively investigating, in particular focusing on automated binary exploitation frameworks \cite{angr, huang}, which could be used to actually assess the vulnerabilities of the applications in an automated manner. Their results could be still modelled as attack paths, thus being compatible with the remainder of the workflow.