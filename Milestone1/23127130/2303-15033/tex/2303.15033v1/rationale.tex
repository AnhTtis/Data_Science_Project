\section{Background on Standardization and the State of Software Protection}
\label{sec:background}

%\changeda{R1: I find it challenging to get a grasp on the structure of this section. Parts of it (3.1 and 3.2)
%reads like what I would expect from a background or state-of-the-art section, giving insight
%into to status in the field. Other parts (3.3), however, read more like an argument for your
%work - what you would like to achieve - and is less tied to the work of others. Consequently,
%I am wondering if it would be easier for a reader (that is more used to the traditional way of
%structuring research papers) if this section was reorganised and split so that one part dealt
%with more of the state-of-the-art, and another more with expectations, requirements, etc.
%And it would also be good if the type of section was clearer from the section heading}

We first discuss some risk management standards and how they have been adopted in other security domains, such as network security, and the healthy market for products and services that exists there as a result. We then contrast this with the lack of such a market and standards for {\softprot}.%, for which we discuss the challenges to making progress towards proper risk management standards. Finally, we highlight what benefits such progress can bring.

\subsection{Standardized Risk Management Approaches}
\label{sec:standardizedRisk}
Protecting software can be seen as a risk management process, a customary activity in various industries such as finance, pharmaceutics, infrastructure, and \itech. 
The \nist has proposed an \itech systems risk management standard that identifies four main phases \cite{nistSP800-39}:
\begin{enumerate}\itemsep 0pt
\item \emph{risk framing}: to establish the scenario in which the risk must be managed;
\item \emph{risk assessment}: to identify threats against the system assets, vulnerabilities of the system, the harm that may occur if those are exploited, and the likelihood thereof;
\item  \emph{risk mitigation}: to determine and implement appropriate actions to mitigate the risks;
\item \emph{risk monitoring}: to verify that the implemented actions effectively mitigate the risks.
\end{enumerate}

The ISO27k framework also focuses on information risk management in three phases~\cite{ISO27k}:
\begin{enumerate}\itemsep 0pt
\item \emph{identify risk} to identify the main threats and vulnerabilities that loom over assets;
\item \emph{evaluate risk} to estimate the impact of the consequences of the risks; 
\item \emph{treat risk} to mitigate the risks that can be neither accepted nor avoided.
\end{enumerate}
ISO27k adds an explicit operational phase for handling changes that happen in the framed scenario.

Those approaches have been consistently applied in practice for securing corporate networks.
Regulations stimulate companies to analyse the risks against their \itech systems. For instance, the \gdpr explicitly requires a risk analysis of all private data handling. 
Companies invest in compliance with the ISO27k family to obtain market access.
Consequently, risk analysis of networks has developed a common vocabulary, and a company's tasks have been properly identified and often standardized, so offerings from consultancy firms can be compared easily. 
There is a business market related to this task, best practices, and big consultant firms have risk analysis of corporate networks in their catalogs~\cite{Gartner-report-riskanalysis}.

In the domain of software security, several frameworks for risk analysis and decision support exist that mainly focus on Software Vulnerability Management~\cite{nistir8011} and Enterprise Patch Management~\cite{nistSP800-40}. 
Other frameworks focus on quality assurance best practices and benchmarking, including the OWASP Software Assurance Maturity Model (SAMM)~\cite{owaspsamm}, the OWASP Application Security Verification Standard (ASVS)~\cite{owaspasvs}, and the Building Security in Maturity Model (BSIMM)~\cite{bsimm}. 
These address problems of software security and are not applicable to {\softprot}.

NIST SP800-53~\cite{nistSP800-53} extends beyond software security and provides a comprehensive and flexible catalog of privacy and security controls for systems and organizations as part of their organizational risk mitigation strategy, for which they build on NIST SP800-39~\cite{nistSP800-39}. It targets whole IT infrastructures, including hardware and software. Regarding software, it advises to "Employ anti-tamper technologies, tools, and techniques throughout the system
development life cycle" in its SR-9 Supply Chain Risk Management family of controls. Obfuscation is mentioned only as an option to strengthen the tamper protection, not to protect the original software. The document does not discuss how to deploy these protections, or how to select the ones to deploy. NIST SP800-53 is hence not applicable to {\softprot}. For much of the remainder of this paper, we will actually discuss what a {\softprot} counterpart of NIST SP800-53 needs to entail. 

%\rthreenote{The paper should recognize and factor in frameworks such as NIST 800-53, BSIMM, OpenSaMM, OWASP ASVS.}\bdsnote{The latter 3 all relate to software security, more concretely to the development of software without flaws or bugs. The former also mentions reverse engineering, in relation to  TAMPER RESISTANCE AND DETECTION, but only refers to it as a functional requirement. No evaluation of how good such a technique is is discussed. SA-4,SI-7,SR-5,SR-9,SR11 in the document do discuss software integrity and software tampering, confidentiality of software assets is not mentioned at all, it concerns the protection of company assets and privacy against third parties or insider threats, not the MATE model. Obfuscation is also only mentioned with respect to tamper resistance of software.}
%\abnote{I only know OWASP ASVS, gues it is not addressing a MATE scenario. Attackers do not have full control of the execution environment but may have past knowledge of the source/binary code of the remote application they are tampering with. But if you can tamper with your copy locally you may also in some cases tamper with the remote version.
%NIST-800-53x is about the mitigations in the context of the 39. It can be useful to mention it should have a counterpart in the selection of the software protections to apply.}

%\abnote{add something about 800-53x}


\subsection{The State of \mate Software Protection}

%\changedb{R2: I like the author’s response regarding my question about ”security-through-obscurity”
%(abbr. S-t-O). Now I realize that here are two different things about S-t-O when we discuss
%it: 1) the fact that some security applications (e.g., DRM) require SP is the manifest of S-t-O,
%3
%otherwise those applications won’t need to hide their implementation details; and 2) SP itself
%can still aim to be free of S-t-O by fully disclosing its design and implementation. When it
%comes to ESP, I agree that it can be free of obscurity if we consider its end-to-end application,
%although whether it can achieve ”security” is debatable (not possible to be secure in terms of
%theories like indistinguishable obfuscation, but maybe ”secure” enough in practice). Overall,
%I think this would be an interesting discussion to appear in the paper (with some edits to
%improve readability).
%}
%\bdsnote{I've added a footnote (currently nr 5) for this.}

Compared to network security and software security, \softprot has years of delay. 
For setting the scope, %we reiterate from the introduction that the scope of {\softprot} includes protections that aim to safeguard the confidentiality and integrity of software by making reverse engineering and tampering harder. 
Table~\ref{tab:protection_examples} lists a number of well-known {\softprot}s. Out-of-scope are mitigations to prevent the exploitation of vulnerabilities, such as \aslr, compartmentalization techniques, or safe programming language features in, e.g., Rust. %Furthermore, it is important to understand that 
In the \mate attack model, attackers have full control over the devices on which they attack the software. They can disable security features of the operating system and the run-time environment, such as \aslr, which therefore cannot be trusted. 
For that reason, {\softprot} centers around protections embedded in the software itself, rather than relying on the security provided by the run-time environment.


\begin{table}[t]
    \centering
    {
    \setlength{\tabcolsep}{0.3em}
    \small
    \begin{tabular}{lp{10.2cm}}
        \toprule
        protection type & explanation\\ 
        \midrule
            anti-debugging             & Techniques to detect or prevent the attachment of an attacker's debugger~\cite{circulardebugging}. \\
            branch functions           & Indirect, computed jumps replace direct control transfers to prevent reconstruction of control flow graphs~\cite{linn2003branchFunctions}.\\
            call stack checks          & Checks if functions are called from allowed callers to block out-of-context calls. \\
            code mobility              & Code is lifted from the binary to prevent static analysis. At run time, the code is downloaded into the running app from a server~\cite{codeMobility}. \\
            code virtualization        & Code in the native instruction set is replaced by bytecode and an injected interpreter interprets that bytecode, of which the format is diversified~\cite{Anckaert2006}.\\
            control flow flattening    & A structured control flow graph graph is replaced by a dispatcher that transfers control to any of the original nodes based on data. This makes it harder to comprehend the original flow of control and the code~\cite{wangFlatteningTechReport}.\\
            data obfuscation           & Transformations that alter data values and structures to hide the original ones.\\
            opaque predicates          & Logic that evaluates to true/false based on invariants known at protection time but that are hard to discover by an attacker~\cite{collbergOpake}. This enables inserting bogus control flow to hinder code comprehension and precise analysis~\cite{JENS,Jens2}.\\
            remote attestation         & Techniques in which a remote server sends attestation requests to a running program. If the program fails to deliver valid proof of integrity, it is considered to be tampered with, and an appropriate reaction can be triggered~\cite{viticchie2016reactive}. \\
            white-box crypto     & Implementations of cryptographic primitives such that even white-box access to the run-time program state does not reveal the used keys~\cite{wyseur2011white}.\\
        \bottomrule
    \end{tabular}
    }
    \caption{A number of software protections.}
    \label{tab:protection_examples}
\end{table}


%Another reason to leave security features such as ASLR out of scope, is that their deployment is already standardized, and hence no longer the topic of a custom, application-specific risk analysis process.




    
The market of \changed{such} {\softprot} is neither open nor accessible to companies with a small budget.
%
In 2017 Gartner projected that 30\% of enterprises would have used \changed{\softprot} to protect at least one of their mobile, IoT, and JavaScript critical applications in 2020~\cite{Gartner}.
However, two years later Arxan reported that 97\% (and 100\% of financial institutions) of the top 100 mobile apps are easy to decompile as they lack binary code protection or implement weak protection~\cite{arxan-report}. %, and the 100\% of the Financial Institution apps were easy to decompile, regardless of the presence of protections. 
A study confirms the absence of both anti-debugging and anti-tampering protections for 59\% of about 38k Play Store apps. The study highlights that weak Java-based methods are employed in 99\% of the {\softprot} uses~\cite{ceccato-new-one}. Repackaging benign apps to obtain malicious apps~\cite{Khanmohammadi2019repacked,Zhou2012repacked} is easy because of the intrinsically weak app packaging process but also because used anti-repackaging protections are currently weak~\cite{merlo2021repackage}.
Furthermore, it is estimated that 37\% of installed software is not licensed, for a total amount of losses estimated at \$46.3B in 2015--2017~\cite{BSA}.
%
Consequently, the \softprot market, which accounted for \$365.4M dollars in 2018, is expected to grow fast~\cite{frost}.
%, also easing the spread of malware that uses unlicensed software a major vector.


Cybersecurity competences are lacking~\cite{Gartner-report-online}. \softprot is no exception.
Few companies have internal {\softprot} teams: only 7\% of respondents stated their organization has all it needs to tackle cybersecurity challenges; 46\% stated they need additional expertise/skills to address all aspects of cybersecurity~\cite{Irdeto-report1}. Meanwhile, many organizations lack competent staff, budget, or resources~\cite{Mandiant}.

When the value of assets justifies it, developers resort to paying third parties to protect their software. 
The price is typically high, involving licenses to tools and often access to expert consultants. Moreover, the services and the strength of the obtained \softprot are covered by a cloak of opaqueness, with \sto omnipresent\footnote{
Abandoning \sto implies that transparency is given about the \softprot process, the design and implementation of all \softprot tools being used, including the supported {\softprot}s and decision support tools. It does not at all imply that \softprot users need to be transparent about the applications they protect. Indeed, the very objective of using \softprot to hamper MATE attacks on assets with confidentiality requirements is to keep those assets obscured. This is to be achieved by keeping the unprotected code secret, and by keeping the used tool configuration secret, not by hiding the used tools or evaluations of their effectiveness.  
}.
For example, whereas early white-box cryptography schemes were peer reviewed~\cite{AESwhite,chow2002white} and then broken~\cite{AESbroken,DESbroken}, we could not find peer-reviewed analyses of schemes currently marketed by big vendors. 
%Despite collaborating with industry, we as academic researchers get no access to their technical documentation, internal security analyses, and pentest report. 
%As another anecdotal piece of evidence, consider the fact that we, academic researchers that collaborate with commercial {\softprot} vendors in numerous bilateral and government-funded projects, hardly obtain any manuals of their commercial offerings or deeply technical documentation, security analyses, and penetration test reports thereof. In addition, 
Moreover, most vendors' licenses forbid the publication of reverse engineering and pen testing reports on their products. They do not share their internal procedures, tools, or reports with academics. 
%As some of the big {\softprot} vendors are also active in other fields of (ICT) security, risk analysis and mitigation is almost certainly the principle that drives their {\softprot} experts. Yet a methodology for applying a risk analysis process for {\softprot} is not publicly available.
%
%Looking at the public records of attacks against some categories of applications that manage high-value assets and have devoted budget to {\softprot}, like media streaming services, online gaming, connected transports, and IoT, which resort to {\softprot} companies, we can observe that {\softprot} vendors seem to be effective in delaying attacks and potentially even in preventing attacks altogether, if only because attackers prefer attacking other software that is not well protected.


We deduce that many companies do not understand the risk and therefore do not feel the need for deploying {\softprot}, or they do not have the internal competences and knowledge to do so properly, or they lack the money to pay third-party providers. In short, there exists no widely accessible, functional, transparent, open {\softprot} market. 
% driven by agreed upon standards and transparency.
%\abnote{the agreed upon standards is a bit forced}
At some of the big {\softprot} vendors that are also active in other security fields, risk analysis and mitigation is most certainly the principle that drives their experts and that is encoded in policies. Yet no methodology is publicly available for applying a risk analysis process when deciding how to protect software.
Needless to say, no standard process guarantees the proper selection and application of available {\softprot}s given a case at hand.

\section{Motivation and Challenges for Standardization, Formalization, and Automation}
\label{sec:motivation}

This section first motivates why we strive for standardization. Next, it argues why formalization and automation are (equally) important. The section concludes with a discussion of some challenges towards these objectives, thus complementing the background provided above. 


\subsection{Motivation for Standardization}

Standardization efforts aim at ``striking a balance between users' requirements, the technological possibilities and associated costs of producers, and constraints imposed by the government for the benefit of society in general''~\cite{standardization}. The benefits come from the positive impact of standards on quality/reliability, information standards, compatibility/interoperability, and variety reduction~\cite{standardization}. In line with those benefits, a standardized, methodological approach to \mate risk analysis could have a plethora of benefits. This section speculates on this potential.

%\rtwonote{On this whole section: None of these predictions are currently backed by fact or even logical arguments, but reads more like a marketing/VC brochure promising significant gains if this approach was supported. We would need more factual arguments motivating the particular approach}\bdsnote{Aldo, are there statements in here that you think we can back up with facts, e.g., similarities to what has happened in other fields. Alternatively, I propose to start the section by "could" instead of "would" and by an explicit statement that in this section, we speculate on potential benefits. That doesn't make the section stronger, but at least it makes it clear that we admit that this is speculative, hence taking away a stick from the reviewers.} 

First, it could force stakeholders to follow a more rigorous approach to \softprot. Risk framing forces analysts to define workflows, processes, methods, and formulas to evaluate risks and the impact of mitigations. In network security, a structured risk analysis has limited the impact of subjective judgments by suggesting the use of collegial decisions involving more roles \cite{nistSP800-39}.
%\bdsnote{I feel we need a citation here to back up this claim.}
% \abnote{something from ISO but anecdotal}
A more rigorous approach for \softprot could similarly increase the transparency of all phases, guaranteeing a more reliable estimation of the reached \softprot level and of the quality delivered by third parties.
In turn, we expect less reliance on \sto. 
Simply adopting the OWASP Security Design Principles forces security specialists to avoid \sto, which is also considered a weakness in MITRE CWE 656~\cite{CWE-656}.

A standard could induce the community to use well-defined terminology and to agree on the meaning of each {term}, as happened after  NIST SP 800~\cite{nistSP800-39}.
Building common ground and well-defined playing rules would also benefit the {\softprot} market by creating a more open and transparent ecosystem where services can be compared as normal products, thus bridging the gap with the network security market in which products are evaluated by third parties using standardized methods such as the Gartner Magic Quadrant for Network Firewalls~\cite{magicquadrant}.
Hence, we expect the rise of consultancy firms that can independently evaluate \softprot effectiveness.
%
We also expect a price reduction, as highlighted in a study~\cite{frost}. %\abnote{no idea, trend of consultancy prices?} 
With a lower entry price and the definition of entry-level protection services, more companies can then afford professional \softprot services, with benefits for all the stakeholders.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
When \softprot becomes standardized and more clearly defined, it could also create a market for decision support products that automate risk management. This could in turn lead to cost savings and to more accessible and more effective \softprot. 

%\item 
The availability of standards increases awareness, as reported by an EU agency one year after adopting the GDPR \cite{gdpr1yafter}.
The mere existence of a standard would initially inform people about the need for \softprot.
Compliance would then force all parties to obtain in-depth knowledge, and the standards and related best practices would eventually be incorporated into educational programs. 
%Moreover, a standard would mitigate the risk for weak \softprot that is now evident in developers and companies that cannot afford services from vendors. \abnote{not sure about the message given but the last sentence}

The work towards standards could also impact research. 
It could initially stimulate the community to focus on identifying and plugging existing gaps and, later on, create new or more effective, validated {\softprot}s to be integrated into a standard framework. 
The interest in the field and the impact of research results would then likely attract more researchers to the {\softprot} field, which is now marginal in the software engineering community. 
We have found analogies with the impact of the ISO/SAE~21434 standard for cybersecurity engineering of road vehicles \cite{10.1007/978-3-030-55583-2_9}.  
Years before its adoption, car manufacturers anticipated effort and funded research 
to cope with the demanding standard. The investments in automotive cybersecurity will grow from \$4.9B in 2020 to \$9.7B in 2030, with a market size expected to grow from \$238B in 2020
to \$469B in 2030~\cite{mckinsey-automotive}. Parts of this increase and of the focal shift towards cybersecurity might not be caused directly by the ISO/SAE~21434 standardization. However, we are convinced that the planned standardization was a major contributing factor in the past years, given that compliance with the standard as part of UN R155 has already become mandatory in Europe, Japan, and Korea since July 2022. The anticipation of the standard can also be observed in guidelines published long before its finalization, such as in the "ENISA good practices for security of Smart Cars" published in November 2019 with contributions of major carmakers~\cite{ENISA}.
%:2021 \abnote{something from the automotive of ICS field}
%https://www.mckinsey.com/~/media/mckinsey/industries/automotive%20and%20assembly/our%20insights/cybersecurity%20in%20automotive%20mastering%20the%20challenge/cybersecurity-in-automotive-mastering-the-challenge.pdf

%Moreover, after the task of \softprot is properly framed, the impact  on current SDLC practices needs to be evaluated, thus opening new research directions in software engineering. 
%\abnote{check swprot papers/conferences vs. software papers/conferences to state that there are just a few experts in sw protection}

% \pagebreak


Increased attention by research institutions and academia usually translates into better education opportunities, possibly with dedicated curricula, which usually pair well with the career opportunities created by a more open market.
Ultimately this could help companies employ skilled people and support a freer job market to compensate at least partially for the lack of \softprot experts.


%\abnote{check trend in careers in AI and cybersecurity/network vs. number of experts needed.}


In the end, the benefit would extend to the whole society, as having better-protected software reduces the global exposure of citizens to risks and, we hope, would make \mate attacks a less lucrative field, or at least reduce its growth.

\subsection{Motivation for Formalization and Automation}
\label{sec:motivation_formalization_automation}
A standardized, methodological risk management approach is not necessarily formalized or automated. We argue, however, that formalization and automation are by and large required. The main reason is the need for precision, i.e., the repeatability or reproducibility of obtained results. 

In the security field, including {\softprot}, we want to avoid a scenario in which different experts that deploy the same risk management approach on the same software under the same conditions would come up with different sets of identified threats and different sets of supposedly good combinations of protections. One of the more important reasons to stay clear of such a scenario is that it would complicate the validation and enforcement of compliance. 

Cognitive psychology research has shown, however, that humans are incorrigibly inconsistent in making summary judgments based on complex information~\cite{thinking,rational}. Hence they provide different answers when asked to evaluate the same information multiple times. Experts also suffer from this. Their judgments hence lack precision in environments that are not sufficiently regular to be predictable~\cite{conditions,thinking}. Those environments are also known as low-validity environments. Determining the major \mate attack threats on a given piece of software given the source code, the formulated security requirements, the domain knowledge, etc., as well as selecting appropriate combinations of {\softprot}s come down to making predictions in such an environment. One of the reasons is that there are many parameters one cannot think of in advance, such as the configurations with which the final software will be deployed on-site. Psychology research has also shown that the precision of expert judgment improves when there exists backup in the form of formulas and algorithms to complement, guide, or replace otherwise imprecise human cognitive processes~\cite{robust}. We hence put forward formalization and automation as important objectives for \mate risk management. 

We are not the first ones to do so. For example, in their survey on architectural threat analysis, Tuma et al.\ analyse whether the surveyed methods are supported by formal frameworks and by (semi-)automated tools because of their impact on precision~\cite{architectural}. They also differentiate between template-based approaches and example-based ones, as the former yield higher precision. 
Similarly, we put forward that using an unambiguous vocabulary with clear definitions will benefit the precision of \mate risk management.  


Economic arguments further support our claim that automation cannot be separated from the aim of adopting a risk analysis process for \softprot. Manual \softprot decision making requires expertise, effort, and hence time. As we discussed, there are not enough experts to protect all software that can benefit from rigorous \softprot. Even if enough experts were available to put in the necessary manual effort, they would remain costly, keeping good \softprot out of reach for SMEs. 

Scaling up the number of experts to meet all demands without automating parts of the processes is not realistic. Every time a new version of an application is issued (e.g., because of regular updates or a bug), it needs to be protected. Part of the work on previous versions can probably be reused, but typically the {\softprot}s at least need to be diversified.

Additionally, \softprot firms may have to protect many versions, such as ports of the same software to different platforms, including laptops or mobiles with limited computational power. If maintaining the application's usability is at risk on some platforms because of the \softprot overhead, developers may decide to limit the features on those platforms. As an example, media players with DRM will only access low-quality versions of media if the platform does not allow full protection.

Moreover, even if human experts were available, their latency would still be problematic. Software vendors face time-to-market pressure. For that reason alone, automated tool support that can cut the time and effort required to protect applications is beneficial.


\subsection{Challenges towards Standardization, Formalization, and Automation}
\label{sec:challenges}

% \input{challenges-original}
\input{challenges-aldo}
