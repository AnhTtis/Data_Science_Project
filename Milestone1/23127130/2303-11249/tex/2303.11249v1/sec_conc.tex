\section{Conclusion}  \label{sec:conc}

The question of what makes a data distribution suitable for deep learning is a fundamental open problem.
Focusing on locally connected neural networks~---~a prevalent family of deep learning architectures that includes as special cases convolutional neural networks, recurrent neural networks (in particular the recent S4 models) and local self-attention models~---~we address this problem by adopting theoretical tools from quantum physics.
Our main theoretical result states that a certain locally connected neural network is capable of accurate prediction (\ie~can express a solution with low population loss) over a data distribution \emph{if and only if} the data distribution admits low quantum entanglement under certain canonical partitions of features.
Experiments with widespread locally connected neural networks corroborate this finding.

Our theory suggests that the suitability of a data distribution to locally connected neural networks may be enhanced by arranging features such that low entanglement under canonical partitions is attained.
Employing a certain surrogate for entanglement, we show that this arrangement can be implemented efficiently, and that it leads to substantial improvements in the prediction accuracies of common locally connected neural networks on various datasets.

The data modalities to which deep learning is most commonly applied~---~namely ones involving images, text and audio~---~are often regarded as natural (as opposed to, for example, tabular data fusing heterogeneous information).
We believe the difficulty in explaining the suitability of such modalities to deep learning may be due to a shortage in tools for formally reasoning about natural data.
Concepts and tools from physics~---~a branch of science concerned with formally reasoning about natural phenomena~---~may be key to overcoming said difficulty.
We hope that our use of quantum entanglement will encourage further research along this line.
