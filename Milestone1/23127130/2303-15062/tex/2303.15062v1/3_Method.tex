\section{Proposed Method}

\subsection{Motivation}
Existing instance segmentation methods typically adopt a two-step inference process: (1) generate proposals where each instance is represented as bounding box~\cite{(MRCNN)he2017mask, (HTC)chen2019hybrid, (centermask)lee2020centermask,(msrcnn)huang2019mask} or point~\cite{(solov2)wang2020solov2, (condinst)tian2020conditional,(solo)wang2020solo,(centermask)wang2020centermask} in proposal branch, and (2) produce a mask for each instance in mask branch.
Figure \ref{fig:motivation} provides an intuition that the performance of the instance segmentation network critically depends on the correctness of proposals at the proposal branch.
Thus, improving the proposal branch may lead to a significant performance improvement in semi-supervised instance segmentation (SSIS).

To delve deeper into the problem,  we adjust a confidence threshold in the proposal branch to verify the influence of the proposal on the output instance mask as shown in Figure \ref{fig:quality_of_pseudo_label}.
At a low threshold of 0.1 with a larger number of proposals, we obtain more true-positive masks but much more false-positive masks as well (see Figure \ref{fig:quality_of_pseudo_label_semi_th01}).
The reason is that false-positive proposals ($e.g.,$ misclassified or erroneously localized proposals) often lead to noisy mask predictions.
Conversely, when we increase the threshold to 0.5, we lose several true-positive masks that were detected at lower thresholds (see Figure \ref{fig:quality_of_pseudo_label_semi_th05}).
In other words, although the mask branch could represent the instance mask, the absence of the thresholded proposal results in missing instance masks. However, finding an optimal threshold per instance is impractical, and balancing between true-positive and false-positive proposals still remains a challenging problem in SSIS.

\input{sources/fig_overview}

\subsection{Weakly Semi-Supervised Instance Segmentation using Point Labels}

From the above observations, we can expect that obtaining correct instance proposals will yield accurate mask representations to improve an SSIS network.
To this end, we revisit the point label, which is a one-pixel categorical instance representation cue.
The annotation budget for point labels is known as costly-efficient by the literature~\cite{(budget_aware)bellver2019budget,(what_point)bearman2016s}.

\noindent\textbf{Task definition}. We propose a new training protocol named Weakly Semi-Supervised Instance Segmentation (WSSIS) using point labels and verify that the budget-friendly point labels can provide effective guidance. The training protocol employs point-labeled data with a small amount of fully labeled data, which yields reduced annotation costs.

\noindent\textbf{Training basline}. Figure \ref{fig:overview} shows our proposed baseline of a two-step learning procedure for WSSIS: (1) train a teacher network using only the full labels; (2) train a student network using both the full and pseudo labels generated by the teacher network along with the point labels.
Generating high-quality pseudo labels is crucial for WSSIS, so we employ point labels as guidance for filtering the proposals to remain only true-positive proposals.
Then, given the filtered proposals, we generate instance masks by exploiting the mask representation of the teacher network. Note that the proposed architecture is a baseline for the proposed task so that one can explore a more advanced training scheme.

\input{sources/fig_adaptive_pyramid_selection}

\noindent\textbf{FPN head}.
Most existing instance segmentation approaches~\cite{(MRCNN)he2017mask,(solov2)wang2020solov2,(HTC)chen2019hybrid,(condinst)tian2020conditional} adopt Feature Pyramid Network (FPN)~\cite{(fpn)lin2017feature} architecture for multi-scale instance prediction.
Namely, SOLOv2~\cite{(solov2)wang2020solov2} employs a 5-level feature pyramid (P2$\sim$P6), and each pyramid level recognizes instances of particular sizes.
When combined with using point labels for sampling proposals, a careful approach to which level to extract proposals based on the size of the instance is demanding.
Otherwise, 
generated instance masks are often noisy as shown in Figure \ref{fig:pyramid} below.

\noindent \textbf{Strategy of using pyramid-level adaptively}. Since points do not contain instance size information, we estimate which pyramid level is proper for each point. To this end, we propose a strategy named Adaptive Pyramid-Level Selection, which adaptively selects a pyramid level that is expected to produce the most appropriate instance mask based on the reliability of the network.
Namely, we rescale the coordinate of point labels according to the resolution of each level and extract confidence scores for all levels.
Then, we generate an instance mask only from the pyramid level with the maximum confidence score, as illustrated in Figure \ref{fig:pyramid}.
Formally, there is $N$ proposal branches $\{\mathbf{F}^{p}_{i}\}_{i=1}^{N}$, and we follows the configuration of FPN~\cite{(fpn)lin2017feature} with $N{=}5$.
For each point label $(x, y, c)$, where $c$ denotes category id, we extract an instance proposal and confidence score $(\mathbf{P}_{i}, \mathbf{s}_{i})=\mathbf{F}^{p}_{i}(x, y, c)$.
Regarding the confidence score as the reliability of the prediction, we adaptively select a pyramid level $k$ with the maximum score, $k=\text{argmax}_{k{\in}\{1,2,\dots,N\}}\mathbf{s}_{k}$.
Finally, at the mask branch $\mathbf{F}^{m}$, we generate a pseudo instance mask $M={\sigma}(\mathbf{F}^{m}(\mathbf{P}_{k}))$, where $\sigma$ is sigmoid function.

\input{sources/fig_result_maskrefinenet}


\subsection{Mask Refinement Network}

With a sufficient amount of fully labeled data ($e.g.,$ using 50\% images), the teacher network can afford to generate reasonable pseudo-instance masks given true-positive proposals.
However, when the amount of fully labeled data is extremely small ($e.g.,$ using only 1\% images), the mask representation by the network would produce rough instance masks; it means the true-positive proposal could not ensure that the instance mask is a true-positive.

To handle such a challenging case, we propose a simple yet effective post-hoc mask refinement method named MaskRefineNet.
Figure \ref{fig:overview} shows that MaskRefineNet can refine the rough mask output from the teacher network based on three input sources, including input image, rough mask, and point information. 
Specifically, we loosely crop each instance region in the input image, rough mask, and point information, and resize them to 256$\times$256, then concatenate them together into an input tensor.
For the point information, we transform the point label to the form of a heatmap where each point is encoded into a 2D gaussian kernel with a sigma of 6.
The effectiveness of the MaskRefineNet can be attributed to two reasons;
(1) it leverages the prior knowledge of the teacher network; since MaskRefineNet takes the rough mask predictions from the teacher network as the input, it learns how to calibrate common errors of predictions from the teacher network;
(2) it takes guidance from the input point that is likely to provide an accurate target instance cue for recognizing overlapping instances and falsely predicted pixels.
Consequently, MaskRefineNet refines the missing \& noisy parts and disentangles the crowded target instances in the rough mask as shown in Figure \ref{fig:quality_of_maskrefinenet} with the help of the point guidance.