\section{Related Works}

\begin{figure*}[t]
    \centering
    % \resizebox{\linewidth}{!}{
        % \tikzexternaldisable
        \tikzsetnextfilename{cyclegan}%
        \begin{tikzpicture}
            \node[inner sep=1pt, fill=white] at (0, 0) {\input{fig/cyclegan_2}};
        \end{tikzpicture}
    % }
    \caption{
        \textbf{\cyclegan framework.} 
        The \cyclegan~\cite{zhu2017unpaired} consists of two pairs of GANs, $\paren{\gab, \db}$ and $\paren{\gba, \da}$. 
        The discriminators try to distinguish translations from real images, 
        while the generators (or translators) seek to produce realistic translations that are also consistent with the input. 
        The consistency is enforced by the cycle-consistency loss and (optional) identity loss. 
        Here, we use $a$ to denote an image from domain $A$, $b$ as an image from domain $B$,
        $\fake{(*)}$ is a fake image (a translation), 
        $\reco{(*)}$ notes a cyclic reconstruction, 
        and $\iden{(*)}$ represents an identity reconstruction
        (when identity losses are used, $\left.\gab\right|_B$ and $\left.\gba\right|_A$ are encouraged to be identity maps).
    }
    \label{fig:cyclegan}
\end{figure*}

\begin{figure}[t]
    \centering
    \includegraphics[width=1.0\linewidth]{fig/images/droplets.pdf}
    \caption{Droplet-like artifacts produced by the original \uvcgan.}
    \label{fig:droplet_artifacts}
\end{figure}


Problems related to unpaired I2I translation have been approached from multiple
directions. There are two major classes of solutions: GAN-based
and diffusion-based.

\paragraph{GAN-based Methods.}
Multiple GAN-based methods have been developed to tackle the problem of unpaired I2I
translation. One distinct group of GAN-based methods involves methods that rely on  cycle consistency,
including \cyclegan~\cite{zhu2017unpaired}, DualGAN~\cite{yi2017dualgan}, \ugatit~\cite{kim2019u},
and the recent \uvcgan~\cite{torbunov2023uvcgan}. This class of algorithms requires two generator networks that translate
images in opposite directions. Its basis is a cycle-consistency constraint, requiring that a cyclically translated
image should match the original. Cycle-consistent models can show remarkable performance~\cite{torbunov2023uvcgan}, but
there are concerns that the cycle-consistency condition might be too restrictive.


\aclgan~\cite{zhao2020unpaired} attempts to relax the cycle-consistency constraint and replace it with a weaker
adversarial one. Such relaxation allows the network to make larger changes to the source image, potentially achieving better translation quality. \council~\cite{nizan2020breaking} moves a step further and
completely discards cycle consistency. Instead, it trains an ensemble of generators performing translation
in a single direction, allowing for a larger diversity of generated images.

\cut~\cite{park2020contrastive} takes an alternative route and uses a contrastive loss to maximize the information
between the source and the translated images. This approach removes the need to have multiple generators and allows
\cut to train faster. Using \cut as a basis, \ittr~\cite{zheng2022ittr} improves its performance by modifying the
generator architecture. In a similar fashion, \somesim~\cite{zheng2021spatially} designs a contrastive-based loss
function that guides the image translation without the need for multiple generators.

\paragraph{Diffusion-based Methods.} 
With the recent explosion of interest in diffusion models (DMs)
multiple works have attempted to employ them
for unpaired I2I translation. For instance, \ilvr~\cite{choi2021ilvr} achieves an unpaired image translation
by modifying the standard Gaussian denoising process. It relies on a DM trained only on the
target domain but guides it toward the source image during denoising.

\sdedit~\cite{meng2021sdedit} introduces another viable approach for performing image translation. Instead
of modifying the diffusion process itself, it simply changes the starting point of diffusion. \sdedit uses a source
image perturbed by Gaussian noise as a seed image and runs the standard diffusion process on top of it.

Finally, recent \egsde~\cite{zhao2022egsde} work makes an observation that both \ilvr and \sdedit are
trained on the target domain data. As such, they may perform a suboptimal translation. \egsde combines
\ilvr and \sdedit approaches and modifies both the starting point of the denoising process and the
denoising process itself. To overcome the limitation of the DM being trained only on the target
domain, it introduces a special energy function, pretrained on both domains. This energy function
guides the denoising process, allowing it to achieve \sota results on several benchmarks.
