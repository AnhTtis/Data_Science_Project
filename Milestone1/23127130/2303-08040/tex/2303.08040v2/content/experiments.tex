\section{Experimental Evaluation}
%\carlos{Can we remove this paragraph?}We divide the experiments into two sections: a first section, using synthetic data, where we compare the \enquote{Equal Treatment Inspector} to previous state-of-the-art methods that measure demographic parity violations, and a second one, presenting use-cases on real data, that shows the auditing and inspection results of our approach. Thus, we show the reliability of the \enquote{Equal Treatment Inspector} in real datasets. Additionally, we offer software tutorials to facilitate the reproducibility of our results as mentioned in the reproducibility statement~\ref{sec:reproducibility}
\subsection{Experiments with Synthetic Data}

\textbf{Comparison methods and baselines:} We evaluate the "Equal Treatment Inspector" that does Classifier Two-Sample Test on the explanation, $g_\psi$(eq. \ref{eq:fairDetector}),against the same test on other distributions: input data distributions $g_\Upsilon$ (also known as bias on the data), prediction distributions $g_\upsilon$(also known as demographic parity) and a combination of both $g_\phi$ (see Equation~\ref{eq:c2st.all.dist}). These experiments are grounded on previously discussed theory (Section ~\ref{sec:theory}):

\begin{gather}
    \Upsilon = \argmin_{\tilde{\Upsilon}} \sum_{(x, z) \in \Dd{val}} \ell( g_{\tilde{\Upsilon}}(\textcolor{blue}{x}) , z) \quad \upsilon = \argmin_{\tilde{\upsilon}} \sum_{(x, z) \in \Dd{val}} \ell( g_{\tilde{\upsilon}}(\textcolor{blue}{f_\theta(x)}) , z )\\
    \phi = \argmin_{\tilde{\phi}} \sum_{(x, z) \in \Dd{val}} \ell( g_{\tilde{\phi}}(\textcolor{blue}{{f_\theta(x),x}}) , z )
\end{gather}\label{eq:c2st.all.dist}

\textbf{Dataset:} To generate a synthetic dataset for both cases, we first draw $10,000$ samples from a  normal distribution $X_1 \sim N(0,1), X_2 \sim N(0,1), (X_3,X_4) \sim  N\left(\begin{bmatrix}0  \\ 0 \end{bmatrix},\begin{bmatrix}1 & \gamma \\ \gamma & 1 \end{bmatrix}\right)$. We then define a binary feature $Z$ with values $1\quad\texttt{if} \quad X_4>0,\quad \texttt{else}\quad 0$. We compare the fairness auditing methods while increasing the correlation $\gamma = r(X_3, Z)$ from 0 to 1. In both experimental scenarios below, our model $f_\beta$, is a function over the domain of the features $X_1, X_2, X_3$.


\textbf{Experimental scenarios:}\\
\textbf{Indirect Case: }\textit{Bias in the data and un-equal treatment model.} There is a demographic parity violation in the input data that is learned by the model. 
The predictor's domain is $(X_1, X_2,X_3)$, and the features are independent of each other. The protected attribute is $Z$ (binary-valued) and its correlation with the predictor's domain $(X_3, Z)$ is parameterized by $\gamma(X_3, Z)$, allowing to adjust for discrimination. To generate the synthetic demographic parity violation in the model we create the target $Y = \sigma(X_1 + X_2 + X_3)$, where $\sigma$ is the logistic function.

\textbf{Uninformative Case: }\textit{Bias on the data but equal treatment model.} The demographic parity violation on the input data remains the same but the relationship of the target variable changes, it is now independent of the protected attribute.
The target function is defined as $Y = \sigma(X_1 + X_2)$, and, the $\gamma$ parameter allows adjusting for discrimination in the training data even if the model does not capture it. The target is then  independent of the protected attribute, $Y \perp X_3 \Rightarrow Y \perp Z \Rightarrow f_\beta \perp Z$.


\begin{figure*}[ht]
\centering
\includegraphics[width=.42\textwidth]{images/fairAuditSyntheticCaseA.pdf}
\includegraphics[width=.42\textwidth]{images/fairAuditSyntheticCaseB.pdf}
\caption{In the left figure, \enquote{Indirect case}: All distributions capture this fairness violation; only the prediction distributions are less sensitive due to their low dimensionality. In the right figure, \enquote{Uninformative case}, only the explanation distributions and prediction distributions detect that the model is non-discriminant, input data flags a false positive detection.}\label{fig:fairSyn}

\end{figure*}

In Figure \ref{fig:fairSyn} we present and compare the different experiments on synthetic data. Overall, we find that learning on the explanations distributions captures un-equal treatment of the model in both situations. We say that a method is \textit{Accountable} if the feature attributions identified are the ones that indeed contribute towards the synthetically generated discrimination for both methods, see Appendix~\ref{app:xai.eval} for the experiment.

\begin{comment}
\begin{table}[ht]
\centering
\steffen{The following caption is long, but not very clear. In particular, it is not at all self-contained. The notion of `learning space' is nowhere defined and therefore incomprehensible}\\
\steffen{``experiment case'' is not clear. I think it can simply be discarded. What is there a vertical line between uninformative and accountable, but none between indirect and uninformative. In general, the table seems a bit ad-hoc. It does not summarize systematically all the effects that we investigated but only picks a few. If made complete this table might be a nice summarization, maybe even to be used in the conclusion rather than somewhere else. The table itself could be made smaller. I would not use bold fonts and I would use begin\{small\} end\{small\} as commands around the table}\\
\steffen{why does the $g$ have different parameter names?}\carlos{equations 5 and 6. Classifier two sample test on diff distributions}\carlos{I am considering either removing it or making it better.}

\caption{Summary table whether each learning space is able to detect un-equal treatment and provide accountability. Based on the results of two synthetic examples from Figure~\ref{fig:fairSyn}. \enquote{Accountability} column indicates whether two-sample classifier testing can provide insights into the sources of discrimination regarding demographic parity violations and the protected attribute(see experiment~\ref{app:xai.eval}).} \label{tab:AuditDetector}
\begin{tabular}{c|cc|cc}
\multicolumn{1}{c|}{\textbf{}}               & \multicolumn{2}{c|}{\textbf{Experiment Case}}                       & \textbf{}             \\
\multicolumn{1}{c|}{\textbf{Learning Space}} & \textbf{Indirect}     & \multicolumn{1}{c|}{\textbf{Uninformative}} & \textbf{Accountable}  \\ \hline
Input        $g_\Upsilon$  & \cmark & \xmark   & \xmark \\
Prediction   $g_\upsilon$  & \cmark & \cmark   & \xmark \\
Input \& Pred. $g_\phi$  & \cmark & \xmark   & \xmark \\
Explanation $g_\psi$  & \cmark & \cmark   & \cmark
\end{tabular}
\end{table}
\end{comment}
\subsection{Use Case: US Income Data}\label{sec:experiments}
\begin{figure*}[ht]
\centering
\includegraphics[width=.49\textwidth]{images/detector_auc_ACSIncome.pdf}
\includegraphics[width=.49\textwidth]{images/feature_importance_ACSIncome.pdf}
\caption{The left figure shows the performance of the \enquote{Equal Treatment Inspector} over different pairs of protected attributes on the US Income dataset. Different pairwise comparisons achieve different degrees of unequal treatment. The right figure displays the features driving unequal treatment. Higher values indicate a higher probability that the features are the causes of unequal treatment.}\label{fig:xaifolks}

%\steffen{I do not understand what is depicted in the left figure. It says `density' on the left, but density of what? I expect a term that we defined in the paper, like `density of explanations' -- however this does not seem to make sense here}\carlos{Now? Density of Distributions, its like a histogram, its aka kernel density estimates}

\end{figure*}

\textbf{Dataset:} Main body: US Income\footnote{Please see the ACS PUMS data dictionary for the full list of variables available \url{https://www.census.gov/programs-surveys/acs/microdata/documentation.html}} \cite{DBLP:conf/nips/DingHMS21}. Appendix: ACS Employment, Travel Time.

\textbf{Baseline Study:} Random Shuffle of the protected attribute and pair-wise comparisons.  In the Appendix~\ref{app:stat.independence.exp}, we provide the results of the statistical hypothesis ($H0$) testing of section~\ref{sec:expSpaceIndependence}.
 
\textbf{Experiment:} Bootstraps of the \enquote{Equal Treatment Inspector} and evaluate pairwise differences. For the inspection experiment, left figure~\ref{fig:xaifolks}, we calculate the Wasserstein distance between the coefficients of the linear regression on the baseline and coefficients of the different pair-wise comparisons. 



\emph{Equal Treatment} is a very strict notion that is difficult to satisfy in practice. But by making relative pairwise differences and explaining the coefficients of $g_\psi$, we can gain insights into the impact of different factors and better understand the sources of inequality or disparities. We observe \enquote{Education} as a highly discriminatory proxy while the use of the feature \enquote{Worked Hours Per Week} is less discriminatory. This allows us to identify areas where adjustments or interventions may be needed to move closer to the ideal of equal treatment.

