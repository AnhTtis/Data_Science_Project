\section{Experimental Extension}

In this section, we extend the experimental setup presented in the main body of the paper, where we focused on the US Income dataset. We varied the types of algorithms for a given experimental set-up by conducting three sets of experiments: (i) AUC statistical independence hypothesis testing (ii) hyperparameter evaluation and (iii) varying the types of algorithms for the estimators $f_\theta$ and ET Inspector $g_\psi$.

\subsection{Statistical Independence Test via Classifier AUC Test}\label{app:stat.independence.exp}

As discussed in Section \ref{sec:stat.independence}, we perform the statistical test $H_0: AUC=\nicefrac{1}{2}$ of the Equal Treatment Inspector. We perform a Brunner-Munzel one tailed test against $H_1: AUC>\nicefrac{1}{2}$ as implemented in~\cite{2020SciPy-NMeth}. 
Table \ref{tab:auc.stats} reports the results for statistical independence of the pair-wise test comparison. Columns include the empirical AUC, the confidence intervals at 95\% confidence level (columns \enquote{Low} and \enquote{High}), and the p-value of the test.
The \enquote{Random} row is the randomly assigned groups and represents a baseline for comparison. The statistical tests clearly show that the AUC is significantly different from $\nicefrac{1}{2}$.

\begin{table}[ht]
\centering
\caption{Results of the statistical independence test conducted using the Classifier Two-Sample AUC Test, as described in Section \ref{app:stat.independence.exp}. The table includes the empirical Area Under the Curve (AUC) values, confidence intervals at a 95\% confidence level (columns "Low" and "High"), p-values of the test, and the corresponding test statistics. The "Random" row represents the baseline comparison group with randomly assigned groups. The statistical tests demonstrate that the AUC values significantly differ from $\nicefrac{1}{2}$, indicating a departure from statistical independence.}\label{tab:auc.stats}
\begin{tabular}{c|ccccc}
\textit{\textbf{Pair}} & \textbf{AUC} & \textbf{Low} & \textbf{High} & \textbf{pvalue} & \textbf{Test Statistic} \\ \hline
\textit{Random}        & 0.501        & 0.494        & 0.507         & 0.813           & 0.236              \\
\textit{White-Other}   & 0.735        & 0.731        & 0.739         & $< 2.2e\text{-}16$             & 97.342             \\
\textit{White-Black}   & 0.62         & 0.612        & 0.627         & $< 2.2e\text{-}16$            & 27.581             \\
\textit{White-Mixed}   & 0.615        & 0.607        & 0.624         & $< 2.2e\text{-}16$             & 23.978             \\
\textit{Asian-Other}   & 0.795        & 0.79         & 0.8           & $< 2.2e\text{-}16$             & 107.784            \\
\textit{Asian-Black}   & 0.667        & 0.659        & 0.676         & $< 2.2e\text{-}16$             & 38.848             \\
\textit{Asian-Mixed}   & 0.644        & 0.634        & 0.653         & $< 2.2e\text{-}16$             & 28.235             \\
\textit{Other-Black}   & 0.717        & 0.708        & 0.725         & $< 2.2e\text{-}16$             & 48.967             \\
\textit{Other-Mixed}   & 0.697        & 0.688        & 0.707         & $< 2.2e\text{-}16$             & 39.925             \\
\textit{Black-Mixed}   & 0.598        & 0.586        & 0.61          & $< 2.2e\text{-}16$             & 15.451            
\end{tabular}
\end{table}
\begin{figure}[ht]
\centering
\includegraphics[width=.49\textwidth]{images/power.pdf}
\caption{Comparing the power of two-sample test based on Accuracy vs AUC.}
\label{fig:power}
\end{figure}

We also  compare the power of the statistical test experimentally based on AUC against the two-sample test of \cite{DBLP:conf/iclr/Lopez-PazO17}, which is based on accuracy. We consider datasets where $Y \sim Ber(0.5)$ and $X = (X_1, X_2)$ with positives distributed as $N( (\mu, \mu), \Sigma)$ and negatives distributed as $N( (-\mu, -\mu), \Sigma)$, where $\Sigma = \begin{bmatrix}1 & 0.5 \\ 0.5 & 1 \end{bmatrix}$. Figure \ref{fig:power} reports the power of the AUC-based test using a logistic regression classifier, estimated by 1000 runs for each of the $\mu$'s ranging from $0.005$ to $0.1$. The figure highlights that, under such a setting, testing the AUC rather than the accuracy leads to a better power.

\subsection{Hyperparameters Evaluation}\label{app:hyperparameter}
This section presents an extension to our experimental setup, where we increase the model complexity by varying the model hyperparameters. Specifically, we use the US Income dataset for the population of California 2014. As the explanation distribution depends on the model, we vary the hyperparameters to observe how it affects Equal Treatment (ET). We selected three models: Decision Tree, Gradient Boosting, and Random Forest. For the Decision Tree model, we varied the depth of the tree, while for the Gradient Boosting and Random Forest models, we changed the number of estimators. We calculated the Shapley values using TreeExplainer \cite{DBLP:journals/natmi/LundbergECDPNKH20}.

The results presented in Figure \ref{fig:xai.hyper} show the AUC of the Equal Treatment Inspector for the US Income dataset for the state of CA14. We observed that less complex models, such as decision trees with depth 1 or 2, are also less discriminative. However, as we increase the model complexity, the unequal treatment of the model becomes more pronounced, achieving a plateau when the model has enough complexity. Furthermore, when we compare the performance of the Equal Treatment Inspector across different models, such as Logistic Regression and XGBoost, we observe distinct minimal differences (note that the y-axis takes different values).

\begin{figure}[ht]
\centering
\includegraphics[width=.49\textwidth]{images/HyperLogReg.pdf}\hfill
\includegraphics[width=.49\textwidth]{images/HyperXGB.pdf}
\caption{The AUC of the Equal Treatment Inspector for the US Income dataset for the state of CA14. The left image shows the results using a logistic regression detector, while the right image shows the results using an XGBoost detector. By changing the model, we can see that simpler models (decision tree with depth 1 or 2) are less discriminative, while when increasing the model complexity, the unequal treatment of the model starts taking higher values.}
\label{fig:xai.hyper}
\end{figure}

\subsection{Varying Estimator and Inspector}

Our proposed notion of \emph{equal treatment} relies on the explanation distribution. While other notions, such as dataset bias or equal opportunity, rely on the input data or on the model error, \emph{equal treatment} relies on the notion that individuals across protected groups should be treated similarly. This treatment is dependent on the model. In this section, we evaluate the performance of our Equal Treatment Inspector by varying the different types of model architectures for the original estimator and the detector. We used the US Income dataset for the population of California in 2014.

We varied the estimator and detector models by selecting seven algorithms: XGBoost, Logistic Regression, Lasso, Ridge, Random Forest, Decision Tree, and MLP. We trained each algorithm using the same hyperparameters, and the Shapley values were calculated using TreeExplainer. The results are presented in Table \ref{tab:benchmark}.


\begin{table}[ht]
\begin{tabular}{c|ccccc}
\multicolumn{1}{l|}{}       & \multicolumn{5}{c}{\textbf{Estimator $f_\theta$}}                                                     \\ \cline{2-6} 
\textit{gmodel $g_\psi$}    & \textbf{DecisionTree} & \textbf{SVC} & \textbf{Logistic Reg.} & \textbf{Random Forest} & \textbf{XGB} \\ \hline
\textit{DecisionTreeClass.} & 0.631                 & 0.644        & 0.644                  & 0.664                  & 0.634        \\
\textit{KNeighborsClass.}   & 0.737                 & 0.754        & 0.75                   & 0.744                  & 0.751        \\
\textit{LogisticRegression} & 0.767                 & 0.812        & 0.812                  & 0.812                  & 0.821        \\
\textit{MLPClassifier}      & 0.786                 & 0.795        & 0.795                  & 0.813                  & 0.804        \\
\textit{RandomForest}       & 0.776                 & 0.782        & 0.781                  & 0.758                  & 0.795        \\
\textit{SVC}                & 0.743                 & 0.807        & 0.807                  & 0.79                   & 0.81         \\
\textit{XGBClassifier}      & 0.775                 & 0.78         & 0.78                   & 0.789                  & 0.79        
\end{tabular}
\caption{Comparison of Equal Treatment performance of our proposed method, measured by AUC, for different combinations of ET Inspectors and estimators on the US Income dataset using CA14 data. The table shows that the choice of detector and estimator impacts the measure of Equal Treatment.  We can see how for the same detector different estimators flag different measures are obtained. On the other side for the same estimators how different detectors achieve different results.}\label{tab:benchmark}
\end{table}



In conclusion, the explanation distribution serves as a projection of the data and model that is sensitive to what the model has learned. The results over the main body and the appendix provide evidence of the importance of considering model complexity when measuring fairness metrics.


\subsection{Explainable AI Synthetic Evaluation}\label{app:xai.eval}
In this section, we present a synthetic experiment to complement the results of the main body. The aim is to evaluate fairness auditing methods while increasing the correlation hyperparameter $\gamma$, using a dataset similar to that of Section \ref{sec:experiments} but with an additional variable.

We begin by drawing $10,000$ samples from a normal distribution, where $X_1$ and $X_2$ follow $N(0,1)$, and $(X_3,X_5)$ and $(X_4,X_5)$ follow bivariate normal distributions $N\left(\begin{bmatrix}0 \ 0 \end{bmatrix},\begin{bmatrix}1 & \gamma \ \gamma & 1 \end{bmatrix}\right)$ and $N\left(\begin{bmatrix}0 \ 0 \end{bmatrix},\begin{bmatrix}1 & \gamma0.5 \ \gamma0.5 & 1 \end{bmatrix}\right)$, respectively. Here, $Z$ is a binary feature defined as $1$ if $X_5 > 0$ and $0$ otherwise. We compare the fairness auditing methods with the increase of the correlation hyperparameter $\gamma$ from $0$ to $1$. Our model $f_\beta(X_1, X_2, X_3,X_4)$ is a function defined over the domain of the features.

We introduce two experimental scenarios. In the first scenario, we have unequal data distributions and unequal treatment of the model (indirect): $Y = \sigma(X_1 + X_2 + X_3 + X_4)$, where $\sigma$ is the logistic function. In the second scenario, we have unequal data distributions but equal treatment of the model (uninformative): $Y = \sigma(X_1 + X_2)$, with $Y \perp X_3\Rightarrow Y \perp X_4 \Rightarrow Y \perp Z \Rightarrow f_\beta \perp Z$.

\begin{figure}[ht]
\centering
\includegraphics[width=.49\textwidth]{images/coef_evolutionA.pdf}\hfill
\includegraphics[width=.49\textwidth]{images/coef_evolutionB.pdf}
\caption{Coefficients driving the un-equal treatment of the model have a stronger increase. If there is no un-equal treatment, the coefficients remain constant. Y-axis is shared to evaluate the difference.}
\label{fig:xai.coef}
\end{figure}

The goal of this experiment is to evaluate how the coefficients change with respect to the correlation hyperparameter $\gamma$. When the model has unequal treatment, the coefficients of the features that drive this disparate treatment increase, and the slope is steepest for the feature that has a higher correlation. On the other hand, when the model achieves equal treatment (uninformative) case, the coefficients remain constant. The results of the experiment are illustrated in Figure \ref{fig:xai.coef}, which shows the coefficients driving the unequal treatment of the model with a stronger increase, while the coefficients remain constant in the case of equal treatment.
