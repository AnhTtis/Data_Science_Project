\section{Additional Experiments}

In this section, we run additional experiments regarding C2ST, hyperparameters, and models for estimators $f_\theta$ and inspectors $g_\psi$.

\subsection{Statistical Independence Test via Classifier AUC Test}\label{app:stat.independence.exp}

We complement the experiments of Section \ref{sec:experiments} by reporting in Table \ref{tab:auc.stats} the results of the C2ST for group pair-wise comparisons. As discussed in Section \ref{sec:stat.independence}, we perform the statistical test $H_0: AUC=\nicefrac{1}{2}$ of the \enquote{Equal Treatment Inspector} using a Brunner-Munzel one tailed test against $H_1: AUC>\nicefrac{1}{2}$ as implemented in~\cite{2020SciPy-NMeth}. 
Table \ref{tab:auc.stats} reports the empirical AUC on test set, the confidence intervals at 95\% confidence level (columns \enquote{Low} and \enquote{High}), and the p-value of the test.  
The \enquote{Random} row regards a randomly assigned group and represents a baseline for comparison. The statistical tests clearly show that the AUC is significantly different from $\nicefrac{1}{2}$, also when correcting for multiple comparison tests.

\begin{table}[ht]
\centering
\caption{Results of the C2ST on the \enquote{Equal Treatment Inspector}. %as described in Section \ref{app:stat.independence.exp}. %The table includes the empirical Area Under the Curve (AUC) values, confidence intervals at a 95\% confidence level (columns "Low" and "High"), p-values of the test, and the corresponding test statistics. The "Random" row represents the baseline comparison group with randomly assigned groups. The statistical tests demonstrate that the AUC values significantly differ from $\nicefrac{1}{2}$, indicating a departure from statistical independence.
}\label{tab:auc.stats}
\begin{tabular}{c|ccccc}
\textit{\textbf{Pair}} & \textbf{AUC} & \textbf{Low} & \textbf{High} & \textbf{pvalue} & \textbf{Test Statistic} \\ \hline
\textit{Random}        & 0.501        & 0.494        & 0.507         & 0.813           & 0.236              \\
\textit{White-Other}   & 0.735        & 0.731        & 0.739         & $< 2.2e\text{-}16$             & 97.342             \\
\textit{White-Black}   & 0.62         & 0.612        & 0.627         & $< 2.2e\text{-}16$            & 27.581             \\
\textit{White-Mixed}   & 0.615        & 0.607        & 0.624         & $< 2.2e\text{-}16$             & 23.978             \\
\textit{Asian-Other}   & 0.795        & 0.79         & 0.8           & $< 2.2e\text{-}16$             & 107.784            \\
\textit{Asian-Black}   & 0.667        & 0.659        & 0.676         & $< 2.2e\text{-}16$             & 38.848             \\
\textit{Asian-Mixed}   & 0.644        & 0.634        & 0.653         & $< 2.2e\text{-}16$             & 28.235             \\
\textit{Other-Black}   & 0.717        & 0.708        & 0.725         & $< 2.2e\text{-}16$             & 48.967             \\
\textit{Other-Mixed}   & 0.697        & 0.688        & 0.707         & $< 2.2e\text{-}16$             & 39.925             \\
\textit{Black-Mixed}   & 0.598        & 0.586        & 0.61          & $< 2.2e\text{-}16$             & 15.451            
\end{tabular}
\end{table}
\begin{figure}[ht]
\centering
\includegraphics[width=.55\textwidth]{images/power.pdf}
\caption{Comparing the power of C2ST based on Accuracy vs AUC.}
\label{fig:power}
\end{figure}

We also compare the power of the C2ST based on the AUC against the two-sample test of \cite{DBLP:conf/iclr/Lopez-PazO17}, which is based on accuracy. We generate synthetic datasets where $Y \sim Ber(0.5)$ and $X = (X_1, X_2)$ with positives distributed as $N( (\mu, \mu), \Sigma)$ and negatives distributed as $N( (-\mu, -\mu), \Sigma)$, where $\Sigma = \begin{bmatrix}1 & 0.5 \\ 0.5 & 1 \end{bmatrix}$. Thus, the large the $\mu$, the easier is to distinguish the two distributions. Figure \ref{fig:power} reports the power of the AUC-based test vs the accuracy-based test using a logistic regression classifier, estimated by 1000 runs for each of the $\mu$'s ranging from $0.005$ to $0.1$. The figure highlights that, under such a setting, testing the AUC rather than the accuracy leads to a better power (probability of rejecting $H_0$ when it does not hold).

\subsection{Hyperparameters Evaluation}\label{app:hyperparameter}

This section presents an extension to our experimental setup, where we increase the model complexity by varying the model hyperparameters. We use the US Income dataset for the population of the CA14 district. %As the explanation distribution depends on the model, we vary the hyperparameters to observe how it affects Equal Treatment (ET). 
We consider three models for $f_{\theta}$: Decision Trees, Gradient Boosting, and Random Forest. For the Decision Tree models, we vary the depth of the tree, while for the Gradient Boosting and Random Forest models, we vary the number of estimators. Shapley values are calculated by means of the TreeExplainer algorithm \citep{DBLP:journals/natmi/LundbergECDPNKH20}. For the ET inspector $g_{\psi}$, we consider logistic regession, and XGB.

Figure \ref{fig:xai.hyper} shows that less complex models, such as Decision Trees with maximum depth 1 or 2, are also less unfair. However, as we increase the model complexity, the unequal treatment of the model becomes more pronounced, achieving a plateau when the model has enough complexity. Furthermore, when we compare the results for different ET inspectors, we observe minimal differences (note that the y-axis takes different ranges).

\begin{figure}[ht]
\centering
\includegraphics[width=.49\textwidth]{images/HyperLogReg.pdf}\hfill
\includegraphics[width=.49\textwidth]{images/HyperXGB.pdf}
\caption{AUC of the inspector for ET, over the district of CA14 for the US Income dataset.} %The left image shows the results using a logistic regression detector, while the right image shows the results using an XGBoost detector. By changing the model, we can see that simpler models (decision tree with depth 1 or 2) are less discriminative, while when increasing the model complexity, the unequal treatment of the model starts taking higher values.}
\label{fig:xai.hyper}
\end{figure}

\subsection{Varying Estimator and Inspector}\label{subsec:EstimatorInspectorVariations}

%Our proposed notion of \emph{equal treatment} relies on the explanation distribution. While other notions, such as dataset bias or equal opportunity, rely on the input data or on the model error, \emph{equal treatment} relies on the notion that individuals across protected groups should be treated similarly. This treatment is dependent on the model. In this section, we evaluate the performance of our \enquote{Equal Treatment Inspector} by varying the different types of model architectures for the original estimator and the detector. We used the US Income dataset for the population of California in 2014.

We vary here the model $f_{\theta}$ and the inspector $g_{\psi}$ over a wide range of well-known classification algorithms. % by selecting seven algorithms: \texttt{xgboost}~\citep{DBLP:conf/kdd/ChenG16}, Logistic Regression, Lasso, Ridge, Random Forest~\citep{DBLP:journals/ml/Breiman01}, Decision Tree~\citep{DBLP:books/wa/BreimanFOS84}, and MLP. We trained each algorithm using the same hyperparameters, and the Shapley values were calculated using TreeExplainer. The results are presented in Table~\ref{tab:benchmark}.
Table~\ref{tab:benchmark} shows that the choice of model and inspector impacts on the measure of Equal Treatment, namely the AUC of the inspector.  %We can see how for the same detector different estimators flag different measures are obtained. On the other side for the same estimators how different detectors achieve different results.
%
%In conclusion, the explanation distribution serves as a projection of the data and model that is sensitive to what the model has learned. The results over the main body and the appendix provide evidence of the importance of considering model complexity when measuring fairness metrics.
By Theorem \ref{thm:main}, the larger the AUC of any inspector the smaller is the $p$-value of the null hypothesis $\Ss(f_\theta, X) \perp Z$. Therefore, inspectors able to achive the best AUC should be considered. Weak inspectors have lower probability of rejecting the null hypothesis when it does not hold.

\begin{table}[ht]\centering
\begin{tabular}{r|ccccc}
\multicolumn{1}{l|}{}       & \multicolumn{5}{c}{\textbf{Model $f_\theta$}}                                                     \\ \cline{2-6} 
\textbf{Inspector $g_\psi$}    & \textbf{DecisionTree} & \textbf{SVC} & \textbf{Logistic Reg.} & \textbf{RF} & \textbf{XGB} \\ \hline
\textbf{DecisionTree} & 0.631                 & 0.644        & 0.644                  & 0.664                  & 0.634        \\
\textbf{KNN}   & 0.737                 & 0.754        & 0.75                   & 0.744                  & 0.751        \\
\textbf{Logistic Reg.} & 0.767                 & 0.812        & 0.812                  & 0.812                  & 0.821        \\
\textbf{MLP}      & 0.786                 & 0.795        & 0.795                  & 0.813                  & 0.804        \\
\textbf{RF}       & 0.776                 & 0.782        & 0.781                  & 0.758                  & 0.795        \\
\textbf{SVC}                & 0.743                 & 0.807        & 0.807                  & 0.790                   & 0.810        \\
\textbf{XGB}      & 0.775                 & 0.780         & 0.780                   & 0.789                  & 0.790       
\end{tabular}
\caption{AUC of the ET inspector for different combinations of models and inspectors.}\label{tab:benchmark}
\end{table}




\subsection{Explaining ET Unfairness}\label{app:xai.eval}

We complement the results of the experimental Section \ref{subsec:exp.synthetic} with a further experiment relating the correlation hyperparameter $\gamma$ to the coefficients of an explainable ET inspector. We consider a synthetic dataset with one more feature, by drawing $10,000$ samples from a  $X_1 \sim N(0, 1)$, $X_2 \sim N(0, 1)$, and $(X_3,X_5)$ and $(X_4,X_5)$ following bivariate normal distributions $N\left(\begin{bmatrix}0 \ 0 \end{bmatrix},\begin{bmatrix}1 & \gamma \ \gamma & 1 \end{bmatrix}\right)$ and $N\left(\begin{bmatrix}0 \ 0 \end{bmatrix},\begin{bmatrix}1 & \gamma0.5 \ \gamma0.5 & 1 \end{bmatrix}\right)$, respectively. We define the binary protected feature $Z$ with values $Z=1$ if $X_5 > 0$ and $Z=0$ otherwise. %We compare the fairness auditing methods with the increase of the correlation hyperparameter $\gamma$ from $0$ to $1$. Our model $f_\beta(X_1, X_2, X_3,X_4)$ is a function defined over the domain of the features.
%
As in Section \ref{subsec:exp.synthetic}, we consider two experimental scenarios. In the first scenario, the indirect case, we have unfairness in the data and in the model. The targe feature is $Y = \sigma(X_1 + X_2 + X_3 + X_4)$, where $\sigma$ is the logistic function. In the second scenario, the uninformative case, we have unfairness in the data and fairness in the model. The target feature is $Y = \sigma(X_1 + X_2)$.

Figure \ref{fig:xai.coef} shows howt the coefficients of the inspector $g_{\psi}$ vary with correlation $\gamma$ in both scenario. In the indirect case, coefficients for $\Ss(f_{\theta}, X_1)_1$ and $\Ss(f_{\theta}, X_1)_2$  correctly attributes zero importance to such variables, while coefficients for $\Ss(f_{\theta}, X_1)_3$ and $\Ss(f_{\theta}, X_1)_4$ grow linearly with $\gamma$, and with the one for $\Ss(f_{\theta}, X_1)_3$ with higher slope as expected. In the uninformative case, coefficients are correctly zero for all variables.

\begin{figure}[ht]
\centering
\includegraphics[width=.49\textwidth]{images/coef_evolutionA.pdf}\hfill
\includegraphics[width=.49\textwidth]{images/coef_evolutionB.pdf}
\caption{Coefficient of $g_{\psi}$ over $\gamma$ for synthetic datasets in two experimental scenarios.}
\label{fig:xai.coef}
\end{figure}

%The goal of this experiment is to evaluate how the coefficients change with respect to the correlation hyperparameter $\gamma$. When the model has unequal treatment, the coefficients of the features that drive this disparate treatment increase, and the slope is steepest for the feature that has a higher correlation. On the other hand, when the model achieves equal treatment (uninformative) case, the coefficients remain constant. The results of the experiment are illustrated in Figure \ref{fig:xai.coef}, which shows the coefficients driving the unequal treatment of the model with a stronger increase, while the coefficients remain constant in the case of equal treatment.

\subsection{Statistical Comparison of Demographic Parity versus Equal Treatment}\label{app:stat.DP.ET}

So far, we measured ET and DP fairness usingthe AUC of an inspector, $g_{\psi}$ and $g_v$ respectively (see Section \ref{sec:exp}). For DP, however, other probability density distance metrics can be considered, including the p-value of the Kolmogorovâ€“Smirnov (KS) test and the Wasserstein distance. Table \ref{table:dist} reports all such distances in the format ``mean $\pm$ stdev" calculated over 100 random sampled datasets. 
The pairs of group comparisons are sorted by descending AUC values. 
We highlight in red values below the threshold of $0.05$ for the KS test, of $0.55$ for the AUC of the C2ST, and of $0.05$ for the Wasserstein distance.  
They represent cases where ET violation occurs, but no DP violation is measured (with different metrics).


\begin{table}[ht]
\caption{Comparison of ET and DP measured in differnt ways. Case of ET violaion but no DP violation are highlighted in red.}\label{table:dist}
\begin{tabular}{c|c|c|ccc}
Pair        & Data       & Equal treatment  & \multicolumn{3}{c}{Demographic Parity}                 \\ \hline
            &            & C2ST(AUC)        & C2ST(AUC)             & KS(pvalue)         & Wasserstein      \\ \hline
Asian-Other &  Income & $0.794 \pm 0.004$ & $0.709 \pm 0.004$ & $0.338 \pm 0.007$ & $0.256 \pm 0.004$ \\
White-Other &  Income & $0.734 \pm 0.002$ & $0.675 \pm 0.003$ & $0.282 \pm 0.003$ & $0.209 \pm 0.002$ \\
Other-Black &  Income & $0.724 \pm 0.004$ & $0.628 \pm 0.006$ & $0.216 \pm 0.007$ & $0.143 \pm 0.004$ \\
Other-Mixed &  Income & $0.707 \pm 0.005$ & $0.593 \pm 0.005$ & $0.169 \pm 0.006$ & $0.117 \pm 0.004$ \\
Asian-Black &  Income & $0.664 \pm 0.008$ & $0.587 \pm 0.004$ & $0.142 \pm 0.005$ & $0.111 \pm 0.004$ \\
Asian-Mixed &  Income & $0.644 \pm 0.005$ & $0.607 \pm 0.006$ & $0.159 \pm 0.008$ & $0.128 \pm 0.006$ \\
White-Mixed &  Income & $0.613 \pm 0.005$ & $0.546 \pm 0.005$ & $0.082 \pm 0.004$ & \textcolor{red}{$0.058 \pm 0.002$} \\
White-Black &  Income & $0.613 \pm 0.005$ & $0.57 \pm 0.007$ & $0.113 \pm 0.008$ & $0.08 \pm 0.006$ \\
Black-Mixed &  Income & $0.603 \pm 0.006$ & \textcolor{red}{$0.523 \pm 0.007$} & \textcolor{red}{$0.055 \pm 0.007$} & \textcolor{red}{$0.023 \pm 0.004$} \\ \hline
Asian-Black &  TravelTime & $0.677 \pm 0.052$ & \textcolor{red}{$0.502 \pm 0.011$} & \textcolor{red}{$0.021 \pm 0.009$} & \textcolor{red}{$0.01 \pm 0.003$} \\
Asian-Other &  TravelTime & $0.653 \pm 0.024$ & \textcolor{red}{$0.528 \pm 0.006$} & \textcolor{red}{$0.053 \pm 0.011$} & \textcolor{red}{$0.027 \pm 0.004$} \\
Asian-Mixed &  TravelTime & $0.647 \pm 0.013$ & $0.557 \pm 0.003$ & $0.096 \pm 0.004$ & \textcolor{red}{$0.045 \pm 0.002$} \\
White-Other &  TravelTime & $0.636 \pm 0.02$ & $0.568 \pm 0.007$ & $0.107 \pm 0.01$ & $0.06 \pm 0.005$ \\
Other-Mixed &  TravelTime & $0.618 \pm 0.017$ & \textcolor{red}{$0.546 \pm 0.011$} & $0.079 \pm 0.012$ & \textcolor{red}{$0.043 \pm 0.006$} \\
Other-Black &  TravelTime & $0.615 \pm 0.021$ & \textcolor{red}{$0.526 \pm 0.011$} & \textcolor{red}{$0.049 \pm 0.014$} & \textcolor{red}{$0.026 \pm 0.006$} \\
White-Black &  TravelTime & $0.599 \pm 0.006$ & $0.569 \pm 0.004$ & $0.12 \pm 0.006$ & \textcolor{red}{$0.057 \pm 0.003$} \\
Black-Mixed &  TravelTime & $0.588 \pm 0.012$ & $0.557 \pm 0.012$ & $0.098 \pm 0.015$ & \textcolor{red}{$0.0557 \pm 0.001$} \\
White-Mixed &  TravelTime & $0.557 \pm 0.008$ & \textcolor{red}{$0.497 \pm 0.006$} & \textcolor{red}{$0.016 \pm 0.004$} & \textcolor{red}{$0.006 \pm 0.002$} \\ \hline
Other-Black &  Employment & $0.744 \pm 0.008$ & \textcolor{red}{$0.524 \pm 0.005$} & \textcolor{red}{$0.036 \pm 0.005$} & \textcolor{red}{$0.036 \pm 0.004$} \\
Asian-Other &  Employment & $0.711 \pm 0.011$ & $0.557 \pm 0.003$ & $0.066 \pm 0.004$ & $0.066 \pm 0.003$ \\
White-Other &  Employment & $0.695 \pm 0.007$ & \textcolor{red}{$0.524 \pm 0.003$} & $0.019 \pm 0.005$ & $0.019\pm 0.002$ \\
Other-Mixed &  Employment & $0.683 \pm 0.022$ & $0.557 \pm 0.008$ & $0.083 \pm 0.005$ & $0.083 \pm 0.003$ \\
Black-Mixed &  Employment & $0.678 \pm 0.028$ & \textcolor{red}{$0.534 \pm 0.007$} & \textcolor{red}{$0.049 \pm 0.007$} & \textcolor{red}{$0.048 \pm 0.004$} \\
Asian-Mixed &  Employment & $0.671 \pm 0.019$ & $0.61 \pm 0.006$ & $0.0144 \pm 0.006$ & $0.145 \pm 0.004$ \\
Asian-Black &  Employment & $0.655 \pm 0.021$ & $0.587 \pm 0.004$ & $0.106 \pm 0.006$ & $0.106 \pm 0.004$ \\
White-Mixed &  Employment & $0.651 \pm 0.009$ & $0.581 \pm 0.006$ & $0.095 \pm 0.004$ & $0.095 \pm 0.003$ \\ 
White-Black &  Employment & $0.619 \pm 0.011$ & \textcolor{red}{$0.544 \pm 0.004$} & \textcolor{red}{$0.049 \pm 0.003$} & \textcolor{red}{$0.049 \pm 0.002$} \\\hline
Asian-Mixed &  Mobility & $0.753 \pm 0.02$ & \textcolor{red}{$0.511 \pm 0.014$} & \textcolor{red}{$0.04 \pm 0.012$} & \textcolor{red}{$0.014\pm 0.006$} \\
Other-Mixed &  Mobility & $0.748 \pm 0.02$ & $0.573 \pm 0.015$ & $0.113 \pm 0.017$ & \textcolor{red}{$0.062 \pm 0.009$} \\
Asian-Other &  Mobility & $0.714 \pm 0.011$ & $0.565 \pm 0.01$ & $0.114 \pm 0.011$ & \textcolor{red}{$0.054 \pm 0.005$} \\
Asian-Black &  Mobility & $0.672 \pm 0.012$ & \textcolor{red}{$0.503 \pm 0.014$} & \textcolor{red}{$0.032 \pm 0.011$} & \textcolor{red}{$0.012 \pm 0.004$} \\
Other-Black &  Mobility & $0.66 \pm 0.012$ & \textcolor{red}{$0.526 \pm 0.009$} & \textcolor{red}{$0.044 \pm 0.009$} & \textcolor{red}{$0.02 \pm 0.004$} \\
White-Mixed &  Mobility & $0.655 \pm 0.007$ & $0.568 \pm 0.005$ & $0.105 \pm 0.007$ & \textcolor{red}{$0.044 \pm 0.003$} \\ 
White-Other &  Mobility & $0.626 \pm 0.017$ & $0.555 \pm 0.009$ & $0.091 \pm 0.01$ & \textcolor{red}{$0.046\pm 0.005$} \\
White-Black &  Mobility & $0.611 \pm 0.009$ & \textcolor{red}{$0.518 \pm 0.008$} & \textcolor{red}{$0.043 \pm 0.008$} & \textcolor{red}{$0.017 \pm 0.004$} \\
Black-Mixed &  Mobility & $0.602 \pm 0.035$ & \textcolor{red}{$0.503 \pm 0.016$} & \textcolor{red}{$0.031 \pm 0.013$} & \textcolor{red}{$0.012 \pm 0.006$} \\\hline
\end{tabular}
\end{table}