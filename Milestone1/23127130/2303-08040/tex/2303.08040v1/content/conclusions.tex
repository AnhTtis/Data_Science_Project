\section{Conclusions}
This work introduces novel measures and inspections of demographic parity fairness in machine learning models. Previous demographic parity measures relied on the model predictions, which lacked sensibility and the possibility to inspect, or, on input data, which is independent of the model. 

We have provided theoretical guarantees, synthetic data experiments, and real data cases that show the benefits of our approach, which relies on the explanation space.  A promising and unexplored information space that can serve to account for model behaviour.


\textbf{Limitations:}
Our work is focused on tabular data. 
%The  potential utility of the explanation space and our method for fairness auditing in computer vision or natural language processing tasks remains an open question.
We have used Shapley values to derive the theoretical guarantees, whose values can be distinct from the SHAP (computational approximation). Also, we have used logistic regression as \enquote{Demographic Parity Inspector} and exploited its coefficients for accountability, but we believe that other AI explanation techniques such as other feature attribution methods, logical reasoning, argumentation,  or counterfactual explanations, may be applicable and come with their own advantages. Furthermore, the usage of fair AI methods does not necessarily guarantee the fairness of AI-based socio-technical systems~\cite{DBLP:conf/fat/KulynychOTG20}.

\subsection*{Reproducibility Statement}\label{sec:reproducibility}
To ensure the reproducibility of our results, we make the data, data preparation routines, code repositories, and methods publicly available \url{https://anonymous.4open.science/r/xAIAuditing-1841/README.md}. Note that we do not perform any hyperparameter tuning throughout our work unless stated otherwise. Instead, we use default \texttt{scikit-learn} parameters \cite{pedregosa2011scikit}. We describe the system requirements and software dependencies of our experiments. Our experiments were run on a 4 vCPU server with 32 GB RAM.
\subsection*{Acknowledgments}
This work has received funding by the European Union’s Horizon 2020 research and innovation program under the Marie
Skłodowska-Curie Actions (grant agreement number 860630) for
the project: \enquote{NoBIAS - Artificial Intelligence without Bias}. Furthermore, this work reflects only the authors’ view and the European Research Executive Agency (REA) is not responsible for any
use that may be made of the information it contains. 