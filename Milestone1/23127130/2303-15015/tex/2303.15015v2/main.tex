
\documentclass{article} % For LaTeX2e
\usepackage{iclr2023_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}



\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors

\usepackage{amsmath}

%mine
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{wrapfig}
\usepackage{multirow, makecell}

\usepackage{algorithm}
\usepackage{algpseudocode}  
\usepackage{amssymb}
\usepackage{amsmath}  
\usepackage{amsthm}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}  % Use Input in the format of Algorithm  
\renewcommand{\algorithmicensure}{\textbf{Output:}} % Use Output in the format of Algorithm 
\allowdisplaybreaks[4]




\title{Towards Open Temporal Graph Neural Networks}


% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

% \author{Antiquus S.~Hippocampus, Natalia Cerebro \& Amelie P. Amygdale \thanks{ Use footnote for providing further information
% about author (webpage, alternative address)---\emph{not} for acknowledging
% funding agencies.  Funding acknowledgements go at the end of the paper.} \\
% Department of Computer Science\\
% Cranberry-Lemon University\\
% Pittsburgh, PA 15213, USA \\
% \texttt{\{hippo,brain,jen\}@cs.cranberry-lemon.edu} \\
% \And
% Ji Q. Ren \& Yevgeny LeNet \\
% Department of Computational Neuroscience \\
% University of the Witwatersrand \\
% Joburg, South Africa \\
% \texttt{\{robot,net\}@wits.ac.za} \\
% \AND
% Coauthor \\
% Affiliation \\
% Address \\
% \texttt{email}
% }

\author{Kaituo Feng\\
Beijing Institute of Technology\\
\texttt{kaituofeng@gmail.com} \\
\And
Changsheng Li \thanks{Corresponding author}\\
Beijing Institute of Technology\\
\texttt{lcs@bit.edu.cn} \\
\And
Xiaolu Zhang\\
Ant Group\\
\texttt{yueyin.zxl@antfin.com} \\
\And
Jun Zhou\\
Ant Group\\
\texttt{jun.zhoujun@antfin.com} \\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle
\begin{abstract}
    
    Graph neural networks (GNNs) for temporal graphs have recently attracted increasing attentions,  
    where a common assumption is that the class set for nodes is closed.
    However, in real-world scenarios, it often faces the open set problem with the dynamically increased class set  as the time passes by.
    This will bring two big challenges to the existing temporal GNN methods: 
    (i) How to dynamically propagate appropriate information in an open temporal graph, where new class nodes are often linked to  old class nodes. 
    This case  will lead to a sharp contradiction. This is because typical GNNs are prone to make the embeddings of connected nodes become similar, while we expect the embeddings of these two interactive nodes to be distinguishable since they belong to different classes.
    %This will cause a sharp contradiction, when attempting to propagate knowledge between two nodes with different classes. 
    (ii) How to avoid catastrophic knowledge forgetting over old classes  when learning new classes occurred in temporal graphs.
    %Learning nodes with new classes could lead to forgetting the knowledge of old classes; 
    In this paper, we propose a general and principled learning approach for open temporal graphs, called OTGNet, with the goal of addressing the above two challenges. 
    %Temporal Class-Incremental Graph Neural Networks, named OTGNet.  
   We assume the knowledge of a node can be disentangled into class-relevant and class-agnostic one, and thus explore a new message passing mechanism by extending the information bottleneck principle to only propagate class-agnostic knowledge between nodes of different classes, avoiding aggregating conflictive information.
    Moreover, we devise a strategy to select both important and diverse triad sub-graph structures for effective class-incremental learning. 
    Extensive experiments on three real-world datasets of different domains demonstrate the superiority of our method, compared to the baselines.

\end{abstract}


\section{Introduction}


{Temporal graph  \citep{nguyen2018continuous} represents} a sequence of time-stamped events (e.g. addition or deletion for edges or nodes) \citep{rossi2020temporal}, which is a popular kind of graph structure in variety of domains such as social networks \citep{kleinberg2007challenges}, citations networks %\citep{gollapalli2014extracting}
\citep{feng2022freekd}, topic communities \citep{hamilton2017inductive}, etc. 
% For example, in a topic community,  all posts can be represented by a graph, where each node represents one post. When adding a post at a certain timestamp, it can be regarded as adding a post node to the dynamic graph. 
For instance, in topic communities, all posts can be modelled as a graph, where each node represents one post. 
New posts can be continually added into the community, thus the graph is dynamically evolving. 
%adding a post at a certain timestamp can be regarded as adding a post node to the dynamic graph. 
In order to handle this kind of graph structure, many methods have been proposed in the past decade \citep{wang2020traffic, xu2020inductive,rossi2020temporal,nguyen2018continuous,li2022robust}. 
The key to success for these methods is to learn an effective node embedding by capturing temporal patterns based on time-stamped events. 
% they could learn from the evolution patterns and capture the fine-grained temporal dynamics on continuous-time dynamic graph.
%they are good at learning from the fine-grained temporal dynamics when graph is evolving.
%(how to utilize the temporal information when graph is evolving ?)
% For example, CTDNE \citep{nguyen2018continuous} designed a temporal random walk model to incorporate temporal dependencies into network embedding methods. 
% TGAT \citep{xu2020inductive} propose a temporal graph attention layer to learn the temporal interactions by a functional time encoding technique.


A basic assumption among the above methods is that  the class set of nodes is always closed, i.e., the class set is fixed as time passes by. 
However, in many real-world applications, the class set is open.
% , rather than a closed one. 
%we face an open set problem with dynamically increased class set
% For instance, in topic communities (e.g.reddit), new topics (e.g. subreddit) being created could be regarded as adding new classes to the graph. 
We still take topic communities as an example, all the topics can be
regarded as the class set of nodes 
for a post-to-post graph. 
When a new topic is created in the community, it means a new class is involved into the graph.
%each post belong to a topic new topics (e.g. subreddit) could occur in topic communities (e.g.reddit) as time lapses. %Adding posts of a new topic could be regarded as adding nodes of a new class to the graph in topic communities.
This will bring two challenges to previous approaches:  
The first problem is the
heterophily 
% \begin{wrapfigure}{r}{0.46\textwidth}
%   \begin{center}
%   \vspace{-2mm}
%     \includegraphics[width=0.46\textwidth]{figure/teaser.pdf}
%   \end{center}
%   \vspace{-4mm}
%   \caption{ An illustration for an open temporal graph. In the beginning, there is an old class (class 1). As the time passes by, a new class (class 2) occurs.
%   $t_4$ denotes the timestamp the edge is built.
%   The edge occurred at $t_4$  connects $v_4$ and $v_5$ (e.g., the same user comments on both post $v_4$ and post $v_5$ in topic communities). 
%   }
%   \vspace{-4mm}
%     \label{teaser}
% \end{wrapfigure}
propagation issue.
In an open temporal graph, a node belonging to a new class is often
\begin{wrapfigure}{r}{0.46\textwidth}
  \begin{center}
  \vspace{-2mm}
    \includegraphics[width=0.46\textwidth]{figure/teaser.pdf}
  \end{center}
  \vspace{-2mm}
  \caption{ An illustration for an open temporal graph. In the beginning, there is an old class (class 1). As the time passes by, a new class (class 2) occurs.
  $t_4$ denotes the timestamp the edge is built.
  The edge occurred at $t_4$  connects $v_4$ and $v_5$ (e.g., the same user comments on both post $v_4$ and post $v_5$ in topic communities). 
  }
  \vspace{-2mm}
    \label{teaser}
\end{wrapfigure}
linked to a node of old class, as shown in Figure \ref{teaser}.  
In Figure \ref{teaser}, `class 2' is a new class, and `class 1' is an old class. 
There is a link occured at timestamp $t_4$ connecting two nodes $v_4$ and $v_5$, where $v_4$ and $v_5$ belong to different classes. 
Such a connection will lead to a sharp contradiction. This is because typical GNNs are prone to learn similar embeddings for $v_4$ and $v_5$ due to their connection   \citep{xie2020gnns,zhu2020beyond}, while we expect the embeddings of $v_4$ and $v_5$ to be distinguishable since they belong to different classes. 
%Specifically, when a link is build between old class nodes and new class nodes, on the one hand, graph neural networks intend to propagate information between these two nodes to make their embeddings similar since they are connected \citep{xie2020gnns,zhu2020beyond}. 
%On the other hand, we hope their embeddings being distinguishable since they belong to different classes.
We call this dilemma as heterophily propagation.
%In class-incremental scenario, as the new classes continually been introduced to the temporal graph, there could be more and more heterophily propagation issues.
Someone might argue that we can simply drop those links connecting different class nodes. However, this might break the graph structure and lose information.
Thus, how and what to transfer between connected nodes of different classes 
remains a challenge for open temporal graph.




The second problem is the catastrophic forgetting issue. When learning a new class in an open temporal graph, the knowledge of the old class might be catastrophically forgot, thus degrading the overall performance of the model.
In the field of computer vision, many incremental learning methods have been proposed  \citep{wu2019large,tao2020few}, which focus on convolutional neural networks (CNNs) for non-graph data like images. If simply applying these methods to graph-structured data by individually treating each node, the topological structure and the interaction between nodes will be ignored. 
Recently, \citet{wang2020streaming,zhou2021overcoming}  propose to overcome  catastrophic forgetting for graph data. However, They focus on static graph snapshots, and utilize static GNN for each snapshot, thus largely ignoring  fine-grained temporal topological information.

In this paper, we put forward the first class-incremental learning approach towards open temporal dynamic graphs, called OTGNet.
%design a new model \textbf{T}emporal Class-\textbf{I}ncremental Graph Neural \textbf{Net}works, named \textbf{OTGNet}.
To mitigate the issue of heterophily propagation, we assume the information of a node can be disentangled into class-relevant and class-agnostic one. Based on this assumption, we design a new message passing mechanism by resorting to  information bottleneck \citep{alemi2016deep} to only propagate class-agnostic knowledge between nodes of different classes. In this way, we can well avoid transferring conflictive information.
To prevent  catastrophic knowledge forgetting over old classes, we propose to select representative sub-graph structures generated from old classes, and incorporate them into the learning process of new classes.  
Previous works \citep{zhou2018dynamic,zignani2014link,huang2014mining} point out triad structure (triangle-shape structure) is a fundamental element of temporal graph and  can  capture evolution patterns. 
Motivated by this, we devise a value function to select not only important but also diverse triad structures, and replay them for continual learning. 
Due to the combinational property, optimizing the value function is  NP-hard. Thus, we develop a simple yet effective algorithm to find its approximate solution, and  give a theoretical guarantee to the lower bound of the approximation ratio.
It is worth noting that our message passing mechanism and triad structure selection can benefit from each other.
On the one hand, learning good node embeddings by our message passing mechanism is helpful to select more representative triad structure. On the other hand, selecting representative triads can well preserve the knowledge of old classes and thus is good for propagating information more precisely.
% The experimental results also verify this point.


Our contributions can be summarized as : 1) Our approach constitutes the first attempt to investigate open temporal graph neural network; 2) We propose a general framework, OTGNet, which can address the issues of both heterophily propagation and catastrophic forgetting;  3) We perform extensive experiments and analyze the results,  proving the effectiveness of our method.

\section{Related Work}
% \textbf{Dynamic graph neural networks}
% Dynamic graph neural networks is good at capturing temporal dynamics to learn node embeddings on dynamic graphs \citep{rossi2020temporal, ma2020streaming}.
% Existing methods could be divided into two kinds \citep{trivedi2019dyrep}: discrete-time methods  and continuous-time-methods.
% The earlier discrete-time methods segmented dynamic graph into a series of static graph snapshots. For example, DynamicTriad \citep{zhou2018dynamic} utilized the triad closure process in a sequential snapshots to learn node embeddings. 
% % DynGEM \citep{goyal2018dyngem} applied the auto-encoder architecture to learn node representations that ensure stable over time. 
% ContinualGNN \citep{wang2020streaming} expected to train a static graph neural network that could preserve learnt knowledge in previous snapshots and learning new patterns in current snapshot.
% However, the fine-grained temporal dynamics couldn't be modeled by discrete-time methods. Thus, many researches have recently focus on continuous-time methods, which are more general for temporal graphs \citep{rossi2020temporal}. 
% % These methods regarded temporal graphs as a sequence of events in chronological order, 
% % which might include node addition, node deletion, edge addition, edge deletion, etc. 
% Generally, these methods regarded temporal graphs as a sequence of time-stamped event in chronological order, 
% For instance, 
% % DyRep \citep{trivedi2019dyrep} took the advantage of temporal point process \citep{mei2017neural} to capture the dynamics in continuous-time graph. 
% TGAT \citep{xu2020inductive} developed a time-aware self-attention mechanism that extends GAT \citep{velivckovic2017graph} to temporal graphs. 
% The work in TGN \citep{rossi2020temporal} proposed an efficient inductive learning model that could memorize long term dependencies for nodes in the temporal graph. However, these approaches all neglected the occurrence of new class nodes in temporal graphs.
Dynamic GNNs 
can be generally divided into two groups \citep{rossi2020temporal} according to the characteristic of dynamic graph: discrete-time dynamic GNNs \citep{zhou2018dynamic,goyal2018dyngem,wang2020streaming} and  continuous-time dynamic GNNs (a.k.a. temporal GNNs \citep{nguyen2018continuous}) \citep{rossi2020temporal,trivedi2019dyrep}.
Discrete-time approaches focus on  discrete-time dynamic graph that is a collection of static graph snapshots taken at intervals in time, and  contains dynamic information at a very coarse level.  
Continuous-time approaches study continuous-time dynamic graph that represents a sequence of time-stamped events, and  possesses temporal dynamics  at finer time granularity. 
In this paper, we focus on temporal GNNs. We first briefly review related works on temporal GNNs, followed by class-incremental learning. 

\textbf{Temporal GNNs.}
In recent years, many temporal GNNs \citep{kumar2019predicting, wang2021apan,trivedi2019dyrep} have been proposed.
% A representative work on temporal graph  is DyRep \citep{trivedi2019dyrep}, which  took the advantage of temporal point process \citep{mei2017neural} to capture fine-grained temporal dynamics. 
For instance, DyRep \citep{trivedi2019dyrep} took the advantage of temporal point process to capture fine-grained temporal dynamics.
CAW \citep{wang2021inductive} retrieved temporal
network motifs to represent the temporal dynamics.
TGAT \citep{xu2020inductive} proposed a temporal graph attention layer to learn  temporal interactions.
%by a time encoding technique.
Moreover, TGN \citep{rossi2020temporal} proposed an efficient model that can memorize long term dependencies in the temporal graph. 
However, all of them concentrate on closed temporal graphs, i.e., the class set is always kept unchanged, neglecting that new classes can be dynamically increased in many real-world applications.

% \textbf{Class-incremental learning}
% Class-Incremental learning has been proposed to overcome catastrophic forgetting when learning new class data incrementally \citep{li2017learning, belouadah2019il2m,wu2019large}. Current class-incremental learning methods could be roughly divided into three lines \citep{liu2021rmm}: parameter isolation methods, regularization-based methods and memory-based methods. Parameter isolation methods \citep{rusu2016progressive,xu2018reinforced,mallya2018piggyback} assign different parameters for different tasks. They maintain the parameters for old tasks unchanged when learning new task to  prevent forgetting. Regularization-based methods \citep{kirkpatrick2017overcoming,li2017learning,tao2020topology} add a penalty term to loss function that restricts the update of parameter when learning new tasks. 
% % For instance,  \citep{kirkpatrick2017overcoming} penalized the update of parameters that are significant to previous tasks. \citep{li2017learning} utilized knowledge distillation to penalize the drift of model's output from previous tasks. 
% Memory-based \citep{wu2019large,bang2021rainbow,rebuffi2017icarl} methods maintain a memory buffer that stores representative samples (examplars). These samples are replayed when learning new tasks to relieve the forgetting of previous tasks. Recently, there are also some works trying to overcome catastrophic forgetting for learning graph data. TWP \citep{liu2021overcoming} introduced a structure-aware penalty term to loss function to preserve learnt knowledge about old classes. ER-GAT \citep{zhou2021overcoming} selected representative nodes for old classes and replay them when learning new tasks to prevent forgetting. However, these methods are all based on static graph neural networks and could be sub-optimal when learning temporal graphs.

\textbf{Class-incremental learning.}
Class-incremental learning have been widely studied in the computer vision community \citep{li2017learning,wu2019large}. For example,
%Incremental learning have been studied to overcome catastrophic forgetting of old data when learning new data incrementally \citep{li2017learning, belouadah2019il2m,wu2019large}. A number incremental learning methods have been proposed in the filed of computer vision. The representative works includes:
EWC \citep{kirkpatrick2017overcoming} proposed to penalize the update of parameters that are significant to previous tasks. 
iCaRL \citep{li2017learning} maintained a memory buffer to store representative samples for memorizing the knowledge of old classes and replaying them when learning new classes.
% and utilized knowledge distillation to penalize the drift of model's output from previous tasks. 
% BiC \citep{wu2019large} proposed a bias correction layer to correct the classification bias caused by the class imbalance problem in class-incremental learning.
These methods focus on CNNs for non-graph data like images. It is obviously not suitable to directly apply them to graph data.
Recently, a few incremental learning works have been proposed for graph data \citep{wang2020streaming,zhou2021overcoming}. 
ContinualGNN \citep{wang2020streaming} proposed a method for closed discrete-time dynamic graph, and trained the model based on static snapshots. 
%Note that ContinualGNN couldn't deal with the class-incremental scenario since it assumed the class set is closed.
% TWP \citep{liu2021overcoming} introduced a structure-aware penalty term to loss function to preserve learnt knowledge about old classes. 
ER-GAT \citep{zhou2021overcoming} selected representative nodes for old classes and replay them when learning new tasks. 
Different from them studying discrete-time dynamic graph, we aim to investigate open temporal graph. 
%However, these methods either focus on static graph or focus on static snapshots of graph, they are insufficient to deal with open temporal graphs.



\section{Proposed Method}
% In this section, we will elaborate the details of the proposed OTGNet. 
% For better clarification, we first give some preliminaries, followed by the introduction of our method.

\subsection{Preliminaries}

% We construct the temporal graph could  by a sequence of temporal interactions (edges) between nodes as in \citep{ma2020streaming,rossi2020temporal}. 
% As the graph evolves, new edges are continually added to the graph. A new edge may connect two existing nodes (edge addition), or link a new node to a existing node (node addition). We denote the temporal graph as $\mathcal{G}=\{\mathcal{V}, \mathcal{E}\}$, where $\mathcal{V}=\{v_1,v_2,...v_n\}$ is the set that contains the entire nodes until the last timestamp $t_{m}$, and 
% % $\mathcal{E}=\{\mathcal{E}_{s_1d_1}(t_1),\mathcal{E}_{s_2d_2}(t_2),...,\mathcal{E}_{s_md_m}(t_m)| t_1 \leq t_2 \leq ... \leq t_m\}$ 
% % $\mathcal{E}=\{(v_{s_1},v_{d_1},t_{1}), (v_{s_2},v_{d_2},t_{2}),...,(v_{s_m},v_{d_m},t_{m}) | t_1 \leq t_2 \leq ... \leq t_m\}$ 
% $\mathcal{E}=\{(v_{s},v_{d},t)\ |\ t \leq t_m \}$ 
% is the temporal edge set until the last time-stamp $t_{m}$.
% $(v_{s},v_{d},t)$ represents node $v_s$ and node $v_d$ build a edge at time-stamp $t$.
% %  $\mathcal{E}_{s_id_i}(t_i)=(v_{s_i},v_{s_i},t_i)$ denotes the edge between node $v_{s_i}$ and $v_{d_i}$ at time-stamp $t_i$.

% with a corresponding node feature matrix $X\in \mathbb{R}^{|V|\times d}$ where $d$ is the dimension of node feature.
% We denote $\mathcal{Y}$ as the class set of all nodes and $\mathcal{Y}_i$ as the class set of $i^{th}$ task.


% . The neighbor set of  node $i$ at time $t$ is denoted as $\mathcal{N}_i(t)$. $e_i(t)$ is the embedding of node $i$ derived by temporal graph neural networks at time $t$. We denote $t-$ as the time right before $t$. Note that the deletion of nodes and edges will not introduce new classes, and our method could also cope with this case. Thus, we focus on the addition of links or nodes. 

% \textbf{Notations.}
% We denote the temporal graph as a sequence of time-stamped events $\mathcal{G}=\{p(t_1),p(t_2),...|t_1\leq t_2\leq ...\}$. 
% An event $p(t)$ falls into two types:
% (i) A node-wise event $v_i(t, y)$ introduces a new node $i$ of class $y$ to the graph at timestamp $t$. In open temporal graph, the addition of nodes might bring new classes to the graph.
% (ii) An interaction event $e_{ij}(t)$ represents adding an edge between node $i$ and node $j$ at timestamp $t$.
% $\mathcal{V}(T)=\{i\ |\ \exists v_i(t, y) \in \mathcal{G}, t \leq T \}$ is the set of temporal nodes before $T$. 
% $\mathcal{E}(T)=\{(i,j)\ |\ \exists e_{ij}(t) \in \mathcal{G}, t \leq T \}$ is the set of temporal edges before $T$. 
% $\mathcal{Y}(T)=\{y\ |\ \exists v_i(t, y) \in \mathcal{G}, t \leq T \}$ is the set of node classes before $T$.
% The neighbor set of node $i$ at time $T$ is denoted as $\mathcal{N}_i(T)$. 
% The embeddings of node $i$ at time $t$ is denoted as $h_i(t)$ and the initial feature of node $i$ is denoted as $x_i$.
% We denote $t-$ as the time right before $t$. Note that the deletion of nodes and edges will not introduce new classes, and our method could also cope with this case. Thus, we focus on the addition of links or nodes. 

\textbf{Notations.}
Let $\mathcal{G}(t)=\{\mathcal{V}(t), \mathcal{E}(t)\}$ denote a temporal graph at time-stamp $t$, where $\mathcal{V}(t)$ is  the set of existing nodes at $t$, and $\mathcal{E}(t)$ is the set of existing temporal edges at $t$.
Each element $e_{ij}(t_k) \in \mathcal{E}(t)$ represents node $i$ and node $j$ are linked at time-stamp $t_k (t_k \leq t)$.
Let $\mathcal{N}_i(t)$ be the neighbor set of node $i$ at $t$.
We assume  $x_i(t)$ denotes the embedding of node $i$ at $t$, where $x_i(0)$ is the  initial feature of node $i$.
Let $\mathcal{Y}(t)=\{1,2,\cdots,m(t)\}$ be the class set of all nodes at $t$, where $m(t)$ denotes  the number of existing classes until time $t$.

% In open temporal graph, the addition of nodes might bring new classes to the graph. Thus, we denote $\mathcal{Y}(t)$ as the class set of existing nodes at time-stamp $t$. Let $\mathcal{E}(t)$ be the the set of temporal edges and $\mathcal{N}_i(t)$ be the neighbor set of node $i$ at timestamp $t$. The embeddings of node $i$ at time $t$ is denoted as $e_i(t)$ and the initial feature of node $i$ is denoted as $x_i$. We denote $t-$ as the time right before $t$ as in \citep{ma2020streaming}. Note that the deletion of nodes and edges will not introduce new classes, and our method could also cope with this case. Thus, we focus on the addition of links or nodes. 



\textbf{Problem formulation.}
In our open temporal graph setting, as new nodes are continually added into the graph, new classes can occur, i.e., the  number  $m(t)$ of classes is increased and thus the class set $\mathcal{Y}(t)$ is open, rather than a closed one like traditional temporal graph. 
Thus, we formulate our problem as a sequence of class-incremental tasks $\mathcal{T}=\{\mathcal{T}_1, \mathcal{T}_2,\cdots, \mathcal{T}_L,\cdots \}$ in chronological order.
%Each task $\mathcal{T}_i$ can contain one or multiple classes. 
%Following previous class-incremental learning setting in computer vision, such as \citep{shim2021online,belouadah2019il2m}, 
Each task $\mathcal{T}_i$ contains one or multiple new classes which are never seen in previous tasks $\{\mathcal{T}_1,\mathcal{T}_2,\cdots,\mathcal{T}_{i-1}\}$.
%we also assume there is no overlapped category label between different tasks, i.e., $\mathcal{T}_i \cap  \mathcal{T}_j= \emptyset$.
In our new problem setting, the goal is to learn an open temporal graph neural network based on current task $\mathcal{T}_i$, expecting our model  to not only perform well on current task but also prevent catastrophic forgetting over previous tasks.
%$\{\mathcal{T}_1,\mathcal{T}_2,\cdots,\mathcal{T}_{i-1}\}$.  

% Compared to $\mathcal{T}_i$, $\mathcal{T}_{i+1}$ contain at least one new occurred class.  node set $\mathcal{V}_i$ of new classes and a edge set $\mathcal{E}_i$. $\mathcal{V}_i$ is the new nodes in task $\mathcal{T}_i$ and each node $v \in \mathcal{V}_i$  corresponds to a label $y_v \in \mathcal{Y}_i$. The label sets of different tasks are disjoint (i.e. $\mathcal{Y}_i \cap \mathcal{Y}_j=	\emptyset$). $\mathcal{E}_i$ contains the interactions between nodes in task $\mathcal{T}_i$, as well as interactions between nodes in task $\mathcal{T}_i$ and nodes in previous tasks. 
% % Once the learning for a task is finished, the interactions for this task are no longer permitted for training (or only a small subset of data is available in memory-based method).
% When learning these task incrementally, we expect our model to not only perform well on current task but also prevent catastrophic forgetting about previous tasks.  


\subsection{Framework}

\begin{wrapfigure}{r}{0.47\textwidth}
  \begin{center}
  \vspace{-17mm}
    \includegraphics[width=0.47\textwidth]{figure/triad.pdf}
  \end{center}
  \vspace{-4mm}
  \caption{ An illustration of overall architecture.
  }
  \vspace{-3.5mm}
    \label{architecture}
\end{wrapfigure}
% Our overall framework is illustrated in Figure \ref{triadd}.
% When learning task $\mathcal{T}_i$, we input the interactions in current task and the first two interactions of old class triads into our proposed message passing framework. All nodes  are used to calculate node classification loss for training. The closed triads and open triads are respectively served as positive and negative samples to preserve evolution patterns. After learning task $\mathcal{T}_i$, we select representative triads for the classes in $\mathcal{T}_i$ and then enter into task $\mathcal{T}_{i+1}$.

As aforementioned, there are two key challenges in open temporal graph learning:  heterophily propagation and catastrophic forgetting. 
To address the two challenges, we propose a general framework, OTGNet, as illustrated in Figure \ref{architecture}. 
Our framework mainly includes two modules : 
A knowledge preservation module is devised to overcome catastrophic forgetting, which consists of two components:
a triad structure selection component is devised to select 
representative triad structures;
% to memorize the knowledge of old classes; 
a triad structure replay component is designed for replaying the selected triads to avoid catastrophic forgetting.
An information bottleneck based message passing module is proposed to propagate class-agnostic knowledge between different class nodes, 
% (e.g., an edge connects one node from a new class and the other node from the selected triad set of old classes)
which can address the heterophily propagation issue.
% After that, the classification module is trained on the updated embedding of nodes of new classes, and the triad structure replay module is trained on the selected representative structures to avoid  catastrophic knowledge forgetting over old classes.
Next, we will elaborate each module of our framework.

\subsection{Knowledge Preservation over Old Class}
% As previous works \citep{zhou2018dynamic,zignani2014link,huang2014mining} point out, the triad structure is the fundamental element of temporal graph and its triad closure process could demonstrate the evolution patterns. 
% The triad structure falls into two type: closed triad and open triad. A closed triad consists of three nodes that links to each other, while an open triad also consists of three nodes but two of the three nodes are not connected. 
% The triad closure process describes how a closed triad is formed from an open triad. Some open triads are tend to become closed triads, while others are conservative and are not prone to become closed triads \citep{zhou2018dynamic, zignani2014link}. 
% % For example, in social networks, user A and user B are the friends of user C but user A and user B don't know each other. In this case, user A, user B and user C form an open triad. If user C tends to introduce his friends to each other and let user A and user B build connections, then this open triad develops into a closed triad. However, some open triads won't develops into closed triads for some reasons (such as user C is not enthusiasm enough).
% Motivated by previous works, we intend to select representative closed triads and open triads for old classes to preserve knowledge.
% We denote the closed triad for class $c$ as $g^c=(v_o, v_p, v_q)$, where node $v_o,v_p,v_q$ are all belong to class $c$ and $v_o, v_p, v_q$ are connected to each other ($v_p$ and $v_q$ link to each other in the last). 
% In the same way we denote open triad for class $c$ as $\tilde{g}^c=(v_o, \tilde{v}_p, \tilde{v}_q)$ but $\tilde{v}_p$ and $\tilde{v}_q$ don't link to each other in the last observation of the graph.

When learning new classes based on current task $\mathcal{T}_i$, it is likely for the model to catastrophically forget knowledge over old classes from previous tasks. If we combine all data of old classes with the data of new classes for retraining, the computational complexities will be sharply increased, and be not affordable. 
Thus, we  propose to select representative  structures from old classes to preserve knowledge, and incorporate them into the learning process of new classes for replay.

\textbf{Triad Structure Selection.} 
As previous works \citep{zhou2018dynamic,zignani2014link,huang2014mining} point out, the triad structure is a fundamental element of temporal graph and its triad closure process could demonstrate the evolution patterns.
According to \citet{zhou2018dynamic}, the triads have two types of structures: closed triad and open triad, as shown in Figure \ref{showtriad}. 
A closed triad consists of three vertices connected with each other, while an open triad has two of three vertices not connected with each other. The closed triad can be developed from an open triad, and the triad closure process is able to model the evolution patterns \citep{zhou2018dynamic}. 
%More information could be found in Appendix. 
Motivated by this point, we propose a new strategy to preserve the knowledge of old classes by selecting representative triad structures from old classes. 
However, how to measure the `representativeness' of each triad, and how to select some triads to represent the knowledge of old classes have been not explored so far.
\vspace{-.15in}
\begin{wrapfigure}{r}{0.28\textwidth}
\centering
\subfigure[closed triad.]{
\begin{minipage}[t]{0.14\textwidth}
\centering
\includegraphics[width=0.6in]{figure/closed.pdf}
\end{minipage}%
}%
\subfigure[open triad.]{
\begin{minipage}[t]{0.14\textwidth}
\centering
\includegraphics[width=0.6in]{figure/open.pdf}
\end{minipage}
}%
\centering
\vspace{-0.15in}
\caption{An illustration for closed triad and open triad.}
\label{showtriad}
\vspace{-0.2in}
\end{wrapfigure}
% According to \citep{zhou2018dynamic}, the triads have two types of structures: closed triad and open triad. 
% A closed triad consists of three vertices connected with each other, while an open triad has two of three vertices not connected with each other. The closed triad can can be developed from an open triad, and this triadic closure process is able to capture the temporal dynamics. 

% \textcolor{red}{the reason for talking about these types. If they are necessary, you should tell what is the purpose for each type.}

%The open triad and closed triad  serve as negative samples and positive samples to model the triad closure process \citep{zhou2018dynamic}.   
%In particular, we model how a closed triad, which consists of three vertices connected with each other, develops from an open triad that has two of three vertices not connected with each other. This triadic closure process is a fundamental mechanism in the formation and evolution of networks, thereby makes our model being able to capture the network dynamics and to learn representation vectors for each vertex at different time steps

%Roughly speaking, there are two types of triads: closed triads and open triads. In a closed triad, for any two vertices, there is a relationship between them. In an open triad, there are only two relationships, which means that two of the three vertices are not connected with each other. We model how a closed triad develops from an open triad, which is called as triad closure process and is a fundamental mechanism in the formation and evolution of dynamic networks . In particular, we design a uniform framework to quantify the probability of an open triad develops to a closed triad,

To write conveniently, we omit $t$ for all symbols in this section. Without loss of generality, we denote a closed triad for class $k$ as $g_k^c=(v_s, v_p, v_q)$, where all of three nodes $v_s,v_p,v_q$  belong to class $k$ and $v_s, v_p, v_q$ are pairwise connected, i.e., $e_{sp}(t_i), e_{sq}(t_j), e_{pq}(t_l)\in \mathcal{E}(t_m)$ and  $t_i,t_j<t_l$, $t_m$ is the last time-stamp of the graph. 
We denote an open triad for class $k$ as ${g}_k^o=(v_{\tilde{s}},v_{\tilde{p}},v_{\tilde{q}})$ with $v_{\tilde{p}}$ and $v_{\tilde{q}}$ not linked to each other in the last observation of 
the graph, i.e., $e_{\tilde{s}\tilde{p}}(t_i),e_{\tilde{s}\tilde{q}}(t_j) \in \mathcal{E}(t_m)$ and $e_{\tilde{p}\tilde{q}} \notin \mathcal{E}(t_m)$. Assuming $S^c_k=\{g^c_{k,1},g^c_{k,2},...,g^c_{k,M}\}$ and $S^o_k=\{g^o_{k,1},g^o_{k,2},...,g^o_{k,M}\}$ is the selected closed triad set and open triad set for class $k$, respectively. $M$ is the memory budget for each class. 
Next, we introduce how to measure and select closed triads $S^c_k$. It is analogous to open triads $S^o_k$. 

In order to measure the `representativeness' of each triad, one intuitive and reasonable thought is to see how the performance of the model is affected if removing this triad from the graph. However, if we retrain the model once one triad is removed, the time cost is prohibitive.   
Inspired by the influence function aiming to estimate the parameter changes of the machine learning model when removing a training sample \citep{koh2017understanding}, we extend the influence function to directly estimate the `representativeness' of each triad structure without retraining, and propose an objective function as:
%Here we introduce our policy to select representative closed triads, the selection for  representative open triads is in the same way. 
%We denote $M$ as the memory budget for each class and denote the set consists of selected triads for class $c$ as $S^c=\{g^c_1,g^c_2,...,g^c_M\}$.
%Previous work has found that different training samples have different contributions to the model's final parameters \citep{lapedriza2013all}. When different training samples are removed in training, the influence to the model's final performance is different.
%Therefore, for $S^c$, we intend to select the triads that contribute most to the performance of models in class $c$. However, removing each triad and then retraining the model is prohibitively time-consuming. 
%Fortunately, previous studies about influence function \citep{koh2017understanding,cook1980characterizations} have provided theory foundations to estimate the parameter changes without retraining when remove different training samples. Thus, we utilize influence function to estimate the model's performance change if we mask the three nodes in a triad when training:
% \begin{equation}
% \label{inf}
%     \mathcal{I}_{loss}(g_k^c,\theta)
%     =-{\mathrm{\nabla}_\theta \mathcal{L}(G_k,\theta) }^\top H_\theta^{-1}\mathrm{\nabla}_\theta \mathcal{L}(g_k^c,\theta),
% \end{equation}
\begin{equation}
   \label{inf}
   \begin{aligned}
  \mathcal{I}_{loss}(g^c_k,\theta) &= {\left.\frac{\displaystyle\operatorname d\mathcal{L}_(G_k,\theta_{\varepsilon,g^c_k})}{\displaystyle\operatorname d\varepsilon}\right|}_{\varepsilon=0} 
      = \nabla_\theta \mathcal{L}(G_k,\theta)^\top       {\left.\frac{\displaystyle\operatorname d\hat\theta_{\varepsilon,g^c_k}}{\displaystyle\operatorname d\varepsilon}\right|}_{\varepsilon=0}\\
      &= -{\mathrm{\nabla}_\theta \mathcal{L}(G_k,\theta) }^\top H_\theta^{-1}\mathrm{\nabla}_\theta \mathcal{L}(g^c_k,\theta)
   \end{aligned}
\end{equation}
where $\mathcal{L}$ represents the loss function, e.g., cross-entropy used in this paper. 
$\theta$ is the parameter of the model, and $G_k$ is the node set of class $k$.
$\theta_{\varepsilon,g^c_k}$ is the retrained parameter if we upweight three nodes in $g^c_k$ by $\varepsilon(\varepsilon \rightarrow 0)$ during training.
 $\varepsilon$ is a small weight added on the three nodes of the triad $g^c_k$ in the loss function $\mathcal{L}$.
$H_\theta$ is the Hessian matrix. $\mathrm{\nabla}_\theta \mathcal{L}(g^c_k,\theta)$, $\mathrm{\nabla}_\theta \mathcal{L}(G_k,\theta)$ are the gradients of the loss to $g^c_k$ and $G_k$, respectively. 
% $\mathcal{I}_{loss}(g^c,\theta)$ estimates the influence to model performance for class $c$ if  we upweight three nodes in a triad $g^c$ when training. 
The full derivation of Eq. (\ref{inf}) is in Appendix \ref{appendix2}.

In Eq. (\ref{inf}), $\mathcal{I}_{loss}(g^c_k,\theta)$ estimates the influence of the triad $g^c_k$ on the model performance for class $k$.
The more negative $\mathcal{I}_{loss}(g_k^c,\theta)$ is, the more positive influence on model performance $g_k^c$ provides, in other words, 
% the more negative $\mathcal{I}_{loss}(g_k^c,\theta)$ is, 
the more important $g_k^c$ is.
Thus, we define the `representativeness' of a triad structure as:
\begin{equation}{\label{import}}
    \mathcal{R}(g_k^c)=-\mathcal{I}_{loss}(g_k^c,\theta)
\end{equation}
In order to well preserve the knowledge of old classes, we expect all $g_k^c$ in $S_k^c$ are important, and propose the following objective function to find $S_k^c$:
\begin{equation}{\label{import2}}
    S^c_k=\arg\max\limits_{\{g_{k,1}^c,\cdots,g_{k,M}^c\}}\sum_{i=1}^M\mathcal{R}(g_{k,i}^c)
\end{equation}
During optimizing (\ref{import2}), we only take the triad $g_{k,i}^c$ with positive  $\mathcal{R}(g_{k,i}^c)$ as the candidate,  since  $g_{k,i}^c$  with negative $\mathcal{R}(g_{k,i}^c)$ can be thought to be harmful to the model performance.
We note that only optimizing (\ref{import2}) might lead to that the selected $g_{k,i}^c$ have similar functions. Considering this, we hope $S^c_k$ should be not only important but also diverse. To do this, we first define:
\begin{equation}
    \mathcal{C}({g_{k,i}^c)}=\{g_{k,j}^c|\ ||\bar{x}(g_{k,j}^c)-\bar{x}(g_{k,i}^c){||}_2\le\delta,g_{k,j}^c\in N_k^c\},
\end{equation}
where $\bar{x}(g_{k,j}^c)$ denotes the average embedding of three  vertices in $g_{k,j}^c$. $N^c_k$ denotes the set containing all positive closed triads for class $k$, and $\delta$ is a similar radius.
$\mathcal{C}({g_{k,i}^c)}$ measures the number of $g_{k,j}^c$, where the distance of $\bar{x}(g_{k,j}^c)$ and $\bar{x}(g_{k,i}^c)$ is less or equal to $\delta$.
To make the selected triads $S^c_k$ diverse, we also anticipate that  $\{\mathcal{C}({g_{k,1}^c)},\cdots,\mathcal{C}({g_{k,M}^c)}\}$  can cover different triads as many as possible by:
%, and introduce the following objective function:
\begin{equation}\label{diverse}
    S_k^c=\arg\max\limits_{\{g_{k,1}^c,\cdots,g_{k,M}^c\}} \frac{|\bigcup_{i=1}^M\mathcal{C}({g_{k,i}^c)}|}{|N_k^c|}
\end{equation}
Finally, we combine  (\ref{diverse}) with (\ref{import2}), and present the final objective function for triad selection as:
\begin{equation}\label{final_selection}
    S_k^c=\arg\max\limits_{\{g_{k,1}^c,\cdots,g_{k,M}^c\}}  F(S_k^c)=\arg\max\limits_{\{g_{k,1}^c,\cdots,g_{k,M}^c\}} \left(\sum_{i=1}^M\mathcal{R}(g_{k,i}^c) +\gamma \frac{|\bigcup_{i=1}^M\mathcal{C}({g_{k,i}^c)}|}{|N_k^c|} \right)
\end{equation}
where $\gamma$ is a hyper-parameter. By (\ref{final_selection}), we can select not only important but also diverse triads to preserve the knowledge of old classes.

%the coverage  In order to measure the diversity of $S_k^c$, we give the following definition: 
% use its negative value $imp(g^c)=-\mathcal{I}_{loss}(g^c,\theta)$ to measure the importance of $g^c$. The sum of importance of all $g_c$ in the set $S^c$ could be written as: $imp(S^c)=\sum_{g_i^c\in S^c}imp(g^c)$. We denote the set contains all triads with positive $imp(g^c)$ as $N^c$. One simple policy could be selecting $M$ triads from $N^c$ in the descending order of $imp(g^c)$.
%However, directly choosing triads based on the magnitude of $imp(g_c)$ is sub-optimal. 
%Since triads with the large $imp(g_c)$ could be similar, similar triads is redundant for preserving knowledge.
%So we introduce a regularization term $div(S^c)$ to encourage the diversity of selected triads in $S^c$, defined as:
% \begin{equation}
%     div(S_k^c)=\frac{|\bigcup_{g_{k,i}^c\in S_k^c} C_{g_{k,i}^c}|}{|N_k^c|},\ C_{g_{k,i}^c}=\{g_{k,j}^c|\ ||emb(g_{k,j}^c)-emb(g_{k,i}^c){||}_2\le\delta,g_{k,j}^c\in N_k^c\},
% \end{equation}
% where $emb(g_{k,i}^c)=\sum_{v \in g_{k,i}^c} x_v(t)$ defined as the embedding of triad $g_i^c$.
% $C_{g_{k,i}^c}$ contains the triads that the ball with radius $\delta$ centered at $g_{k,i}^c$ could cover in the embedding space. 
% $div(S_k^c)$ is defined as the ratio of the number of covered triads to the number of all triads, which could encourage the diversity of a set of triads. Combining the importance measurement and the diversity regularization term, we defined the value function of a set of selected triads as:
% \begin{equation}
%     F(S_k^c)=imp(S_k^c)+\gamma div(S_k^c)
% \end{equation}
%where $\gamma$ is the hyper-parameter. We intend to select a triad set of fixed size $M$ that maximizes $f(S_k^c)$:
% \begin{equation}
%     {max}_{S_k^c}\ F(S_k^c),\ s.t.|S_k^c|=M\ and\ S_k^c\subseteq N_k^c
% \end{equation}
Due to the combinatorial property, solving (\ref{final_selection}) is NP-hard.
Fortunately, we show that $F(S_k^c)$ satisfies the condition of monotone and submodular. The proof can be found in Appendix \ref{appendix3}.  Based on this property, (\ref{final_selection})  could be solved by a greedy algorithm \citep{pokutta2020unreasonable} with an approximation ratio guarantee, by the following Theorem 1 \citep{krause2014submodular}. 
%The time complexity for selecting $S_k^c$ is roughly $O(M|N_k^c|^2)$, which is affordable, because $M$ is usually small, and $|N_k^c|$ is usually in the hundreds in practice. 
% not more than $O(d_k|\mathcal{E}_k|)$ where $|\mathcal{E}_k|$ is the number of edges between two nodes of class $k$ and $d_k$ is the max degree of nodes of class $k$. 
%The detailed time complexity analysis could be found in Appendix A.8.


\begin{wrapfigure}{R}{0pt}

\begin{minipage}{0.43\textwidth}
\vspace{-10mm}
\begin{algorithm}[H]
  \caption{Representative triad selection}  
  \begin{algorithmic}[1]  
    \Require 
    all triads $N_k^c$ for class $k$, budget $M$;
    \Ensure
    representative triad set $S_k^c$;
    \State Initialize  $S_k^c=\emptyset$;
    \While{$|S_k^c|<M$}  \\
    \ \ \ \ $u={{argmax}_{u\in N_k^c\backslash S_k^c}F(S_k^c\cup\{u\}})$;\\
    \ \ \ \ $S_k^c = S_k^c\cup u$;
    \EndWhile    
    \State return $S_k^c$
  \end{algorithmic}  
  \label{greedy}
\end{algorithm}  
\vspace{-16mm}
\end{minipage} 
\end{wrapfigure}  

\textbf{Theorem 1.}  
Assuming our value function $F:2^N\rightarrow\mathbb{R}_+$ is monotone and submodular. 
If ${S_k^c}^\ast$ is an optimal triad set and $S_k^c$ is a triad set selected by the greedy algorithm \citep{pokutta2020unreasonable}, then $F(S_k^c)\geq(1-\frac{1}{e})F({S_k^c}^\ast)$ holds.

By Theorem 1, we can greedily select closed triads as in Algorithm \ref{greedy}. 
As aforementioned, the open triad set $S^o_k$ can be chosen by the same method.
The proof of Theorem 1 can be found in \citet{krause2014submodular}. 
% \textcolor{blue}{The triad selection time analysis is in Appendix A.10.} 

\paragraph{An Acceleration Solution.}
We first provide the time complexity analysis of triad selection.
When counting triads for class $k$, we first enumerate the edge that connects two nodes $v_s$ and $v_d$ of class $c$. Then, for each neighbor node of $v_s$ that belongs to class $k$, we check whether this neighbor node links to $v_d$. If this is the case and the condition of temporal order is satisfied, these three nodes form a closed triad, otherwise these three nodes form an open triad.
Thus, a rough upper bound of the number of closed triads in class $k$ is $O(d_k|\mathcal{E}_k|)$, where $|\mathcal{E}_k|$ is the number of edges between two nodes of class $k$, and $d_k$ is the max degree of nodes of class $k$. 
When selecting closed triads, finding a closed triad that maximizes the value function takes $O(|N_k^c|^2)$, where $|N_k^c|$ is the number of positive closed triads in class $k$. 
Thus, it is of order $O(M|N_k^c|^2)$ for selecting the closed triad set $S_k^c$, where $M$ is the memory budget for each class. The time complexity for selecting the open triads is the same.

To accelerate the selection process, a natural idea is to reduce $N_k^c$ by only selecting closed triads from $g_k^c$ with large values of $\mathcal{R}(g_k^c)$. Specifically, we sort the closed triad $g_k^c$ based on  $\mathcal{R}(g_k^c)$, and use the top-$K$  ones as the candidate set $N_k^c$ for selection. The way for selecting  open triads is the same. 
% We also provide the performance-speed trade-off analysis of triad selection in the experiment.


\textbf{Triad Structure Replay.}
After obtaining  representative closed and open triad sets, $S_k^c$ and $S_k^o$, 
we will replay these triads from old classes when learning new classes, so as to overcome catastrophic forgetting. 
First, we hope the model is able to correctly predict the labels of nodes from the selected triad set, and thus use the cross entropy loss $\mathcal{L}_{ce}$ for each node in the selected triad set.
% \begin{equation}
%     \mathcal{L}_{ce}=-\sum_{g \in D^c}\sum_{v \in g}\sum_{j\in m(t)}{\mathbb{I}(y_i=j)log(p^j_{v})}-\sum_{g \in D^o}\sum_{v \in g}\sum_{j\in m(t)}{\mathbb{I}(y_i=j)log(p^j_{v})}
% \end{equation}
% where $D^c$, $D^o$ are the set containing selected closed triads, open triads of all old classes,$p^j_{v}$ is the predicted probability of node $v$ for class $j$.

Moreover, as mentioned above, the triad closure process can capture the evolution pattern of a dynamic graph. 
Thus, we use the link prediction loss $\mathcal{L}_{link}$  to correctly predict the probability  whether two nodes are connected based on the closed and open triads, to further preserve knowledge:
%preserve the evolution patterns \citep{zhou2018dynamic}. 
% The closed triads are served as positive samples, where we expect the probability of forming an edge between $v_p$ and $v_q$ to be large. While the open triads are served as negative samples, where the probability of forming the last edge is expected to be low.
% The link prediction loss $\mathcal{L}_{link}$ is as follows:
\begin{equation}
    \mathcal{L}_{link}=-\frac{1}{N_c}\sum_{i=1}^{N_c}\log(\sigma({x_p^i(t)}^\top x_q^i(t)))-\frac{1}{N_o}\sum_{i=1}^{N_o}\log(1-\sigma({\tilde{x}_p^i(t)}^\top \tilde{x}^i_q(t))),
\end{equation}
where $N_{c}$,$N_{o}$ are the number of closed, open triads respectively, where $N_c = N_o = N_t *M$.
$N_t$ is the number of old classes.
$\sigma$ is the sigmoid function. $x_p^i(t),x_q^i(t)$ are the embeddings of $v_p$, $v_q$ of the $i^{th}$ closed triad. $\tilde{x}_p^i(t)$, $\tilde{x}_q^i(t)$ are the embeddings of $v_{\tilde{p}}$, $v_{\tilde{q}}$ of the $i^{th}$ open triad.
Here the closed triads and open triads serve as postive samples and negative samples, respectively. 


\subsection{Message Passing via Information Bottleneck}

% When combining the selected triad structure from old classes with a new class for joint learning, it is possible that one edge connects one node of the new class and one node of an old class, as shown in Figure \ref{teaser}.
When new class occurs, it is possible that one edge connects one node of the new class and one node of an old class, as shown in Figure \ref{teaser}.
 To avoid aggregating conflictive knowledge between nodes of different classes, one intuitive thought is to extract class-agnostic knowledge from each node, and transfer the class-agnostic knowledge between nodes of different classes To do this, we extend the information bottleneck principle to obtain a class-agnostic representation for each node.

\textbf{Class-agnostic Representation.}
% In order to prevent node embeddings being disturbed , we intend to transfer class-agnostic knowledge between nodes of different classes. 
% Conventional information bottleneck \citep{tishby2000information} is proposed to learn a representation that preserves the maximum information about the class.  
Traditional information bottleneck  aims to learn a representation that preserves the maximum information about the class while has minimal mutual information with the input \citep{tishby2000information}.
Differently, we attempt to extract class-agnostic representations from an opposite view, i.e., we expect the learned representation has minimum information about the class, but preserve the maximum information about the input. 
%. of node embeddings that have minimum information about the classes. Especially, we expect the mutual information between the node embedding and the latent representation being maximized and the mutual information between the latent representation and its corresponding node label being minimized. 
% Formally, we propose the following objective function to obtain class-agnostic representation as:
Thus, we propose an objective function as:
\begin{equation}\label{ibobj}
    J_{IB}=\min_{Z(t)}\ I(Z(t),Y)-\beta I(Z(t),X(t)),
\end{equation}
where $\beta$ is the Lagrange multiplier.
%\citep{alemi2016deep}. 
$I(\cdot,\cdot)$ denotes the mutual information. $X(t)$, $Z(t)$ are the random variables of the node embeddings and class-agnostic representations at time-stamp $t$. $Y$ is the random variable of node label. 
% Although there are some non-parametric approximation methods, such as maximum likelihood-ratio estimators, to obtain  $Z(t)$. 
%  However, these methods often have bad performance when the dimension of the variable is high [3, 6]. Recently,  neural network based  methods have been proposed and achieved  promising performance [1, 3]. Inspired by this, 
In this paper, we  adopt a two-layer MLP for mapping $X(t)$ to $Z(t)$.

% $x_i(t)$ and $y_i$ are the embedding and label of node $i$ at time-stamp $t$, respectively. 
% $z_i(t)$ is an intermediate variable which is a class-agnostic representation of node $i$. Note that we only use $z_i(t)$ to propagate information to other nodes having different classes with node $i$.
% If one node has the same class with node $i$, we still use $x_i(t)$ for information aggregation, so as to avoid losing information.
%the random variables of the node embedding, the extracted class-agnostic representation, at timestamp $t$, respectively.
%$Y$ is the random variable of the one-hot node label. Note that the label for a single node is unchanged over time.
% In this paper, we  adopt a two-layer MLP for mapping $x_i(t)$ to $z_i(t)$, in order to learn $z_i(t)$.

However, directly optimizing (\ref{ibobj}) is intractable. Thus, we utilize CLUB \citep{cheng2020club} to estimate the upper bound of $I(Z(t),Y)$ and utilize MINE \citep{belghazi2018mutual} to estimate the lower bound of $I(Z(t),X(t))$. Thus, the upper bound of our objective could be written as:
% \begin{equation}
%     J_{IB}\!\!\leq\!\mathbb{E}_{p(Z,Y)}\![logq_{\mu}(y|z)]\!-\!\mathbb{E}_{p(Z)}\!\mathbb{E}_{p(Y)}\![logq_{\mu}(y|z)]\!-\!\beta( {sup}_{\psi}\mathbb{E}_{p(E\!,Z)}[T_\psi]\!-\!log(\!\mathbb{E}_{p(E)\!p(Z)}[e^{T_\psi}])).\!
%     \label{es}
% \end{equation}
\begin{align} \nonumber
    J_{IB}\leq \mathcal{L}_{IB} &= \mathbb{E}_{p(Z(t),Y)}[\log q_{\mu}(y|z(t))]-\mathbb{E}_{p(Z(t))}\mathbb{E}_{p(Y)}[\log q_{\mu}(y|z(t))] \\ 
    &\ \ \ \ -\beta( {\sup}_{\psi}\mathbb{E}_{p(X(t),Z(t))}[T_\psi(x(t),z(t))]-\log(\mathbb{E}_{p(X(t))p(Z(t))}[e^{T_\psi(x(t),z(t))}])).
    \label{es}
\end{align}
where $z(t)$, $x(t)$, $y$ are the instances of $Z(t)$, $X(t)$, $Y$ respectively. 
$T_{\psi}:\mathcal{X} \times \mathcal{Z} \rightarrow \mathbb{R}$ 
is a neural network parametrized by $\psi$. Since $p(y|z(t))$ is unknown, we introduce a variational approximation $q_{\mu}(y|z(t))$ to approximate $p(y|z(t))$ with parameter $\mu$.  By minimizing this upper bound $\mathcal{L}_{IB}$, we can obtain an approximation solution to Eq. (\ref{ibobj}).
%achieve minimizing our objective of information bottleneck. 
The derivation of formula (\ref{es}) is in Appendix \ref{appendix1}.

It is worth noting that $z_i(t)$ is an intermediate variable as the class-agnostic representation of node $i$. We only use $z_i(t)$ to propagate information to other nodes having different classes from node $i$.
If one node $j$ has the same class with node $i$, we still use $x_i(t)$ for information aggregation of node $j$, so as to avoid losing information. In this way, the heterophily propagation issue can be well addressed.

% where $\beta$ is the Lagrange multiplier \citep{alemi2016deep}. $I(\cdot,\cdot)$ denotes the mutual information. $x_i(t)$ and $y_i$ are the embedding and label of node $i$ at time-stamp $t$, respectively. 
% $z_i(t)$ is an intermediate variable which is a class-agnostic representation of node $i$. Note that we only use $z_i(t)$ to propagate information to other nodes having different classes with node $i$.
% If one node has the same class with node $i$, we still use $x_i(t)$ for information aggregation, so as to avoid losing information.

% By minimizing this upper bound, we could achieve minimizing our objective of information bottleneck. In practice, the expectations could be approximated by Monte Carlo sampling \citep{wan2021multi,alemi2016deep}. Therefore, the loss for information bottleneck $L_{IB}$ is as follows:
% \begin{equation}
% \mathcal{L}_{IB}\!\!=\!\frac{1}{\!|S_{d}|\!}\!\sum_{i\in\! S_d\!}\![logq_\mu(y_i\!|z_i)\!-\frac{1}{|S_{d}|}\!\sum_{j\in\! S_d}\!{logq_\mu(y_j\!|z_i)}]\!-\frac{\beta}{\!|S_{d}|\!}\!\sum_{i\in\! S_d}\![T_\psi\!(e_i,\!z_i)\!-log{(\frac{1}{\!|S_{d}|\!}\!\sum_{j\in\! S_d}\!e^{T_\psi(e_i,\!z_j)})}],\! 
% \end{equation}
% where $S_d$ is the set of nodes that interacts with other different class nodes in a batch and $|S_d|$ is the size of $S_d$. $e_i$, $z_i$, $y_i$ are the embedding, class-agnostic representation, label of node $i$ respectively. 

\textbf{Message Propagation.}
% When an interaction occurs between two nodes, we use the following ways to update their embeddings respectively.
% After obtaining the class-agnostic representation $z(t)$ for each node, we can then transfer knowledge between two nodes of different classes using their class-agnostic representations. 
In order to aggregate temporal information and topological information in temporal graph, many information propagation mechanism have been proposed \citep{rossi2020temporal,xu2020inductive}. Here, we extend a typical mechanism proposed in TGAT \citep{xu2020inductive}, and present the following way to learn the temporal attention coefficient as:
% Our message passing framework is two-step as shown in Figure \ref{passing}. When an interaction occur between two nodes ($v_1$, $v_2$), we first aggregate message from history neighborhoods ($\{v_3,v_4,v_5\}$ and $\{v_6,v_7,v_8\}$) to update the embeddings of two interactive nodes before connection.
\begin{equation}
    a_{ij}(t)=\frac{\exp(([x_i(t)||\Phi(t-t_i)]W_q)^\top([h_{j}(t)||\Phi(t-t_j)]W_p))}{\sum_{l \in \mathcal{N}_i(t)}\exp(([x_i(t)||\Phi(t-t_i)]W_q)^\top([h_{l}(t)||\Phi(t-t_l)]W_p))}
\end{equation}
where $\Phi$ is a time encoding function proposed in TGAT.  $||$ represents the concatenation operator. 
$W_p$ and $W_q$ are two learnt parameter matrices.
$t_i$ is the time of the last interaction of node $i$. 
$t_j$ is the time of the last interaction between node $i$ and node $j$. 
$t_l$ is the time of the last interaction between node $i$ and node $l$.
Note that we adopt different $h_{l}(t)$ from that in the original TGAT, defined as:
\begin{equation}
    h_{l}(t)=
    \begin{cases}
    x_l(t),& \text{$y_i=y_l$}\\
    z_l(t),& \text{$y_i\neq y_l$}
    %=MLP_{IB}(x_l(t)), & \text{$y_i\neq y_l$}
    \end{cases},
\end{equation}
where $h_{l}(t)$ is the message produced by neighbor node $l \in \mathcal{N}_i(t)$.
If  node $l$ and $i$ have different classes, we leverage its class-agnostic representation $z_l(t)$ for information aggregation of node $i$, otherwise we directly use its embedding $x_l(t)$ for aggregating. 
Note that our method supports multiple layers of network. We do not use the symbol of the layer only for writing conveniently.

Finally, we update the embedding of node $i$ by aggregating the information from its neighbors:
\begin{equation}
     x_i(t)=\sum_{j \in \mathcal{N}_i(t)}a_{ij}(t) W_h h_{j}(t),
\end{equation}
where  $W_h$ is a learnt parameter matrix for message aggregation. 





\subsection{Optimization}
During training, we first optimize the information bottleneck loss $\mathcal{L}_{IB}$. Then, we  minimize $\mathcal{L}=\mathcal{L}_{ce}+\rho \mathcal{L}_{link}$, where $\rho$ is the hyper-parameter and $\mathcal{L}_{ce}$ is the node classification loss over both nodes of new classes and that of the selected triads. We alternatively optimize them until convergence. The detailed training procedure and pseudo-code could be found in Appendix \ref{appendix5}.

In testing, we extract an corresponding embedding of a test node by assuming its label to be the one that appears the most times among its neighbor nodes in the training set, due to referring to extracting class-agnostic representations. After that, we predict the label of test nodes based on the extracted embeddings.



% Our overall framework is illustrated in Figure \ref{triadd}.
% When learning task $\mathcal{T}_i$, we input the interactions in current task and the first two interactions of old class triads into our proposed message passing framework. All nodes  are used to calculate node classification loss $L_{CE}$ for training. The closed triads and open triads are respectively served as positive and negative samples to preserve evolution patterns. After learning task $\mathcal{T}_i$, we select representative triads for the classes in $\mathcal{T}_i$ and then enter into task $\mathcal{T}_{i+1}$.
% By summing up all loss, the overall loss $\mathcal{L}$ for our model training is as follows:
% \begin{equation}
%     \mathcal{L} = \mathcal{L}_{CE} +\rho \mathcal{L}_{link} +  \mathcal{L}_{IB}
% \end{equation}
% where $\rho$ is the hyper-parameter. The pseudo-code of training procedure could be found in Appendix.
\section{Experiments}
% In this section, we conduct extensive experiments to evaluate our method on three real-world datasets from different domains. 
% We first introduce the datasets and our experiment settings. Then, we compare our method with other baselines on two metrics. Last, we conduct ablation study to show the effectiveness of different parts in our method.
\subsection{Experiment Setup}

\begin{wraptable}{r}{0.45\textwidth}
\centering
\begin{small}
\vspace{-0.9in}
\caption{Dataset Statistics}
 \label{datasets}
 \setlength{\tabcolsep}{1mm}
 {
\begin{tabular}{@{}cccc@{}}
\toprule
                     & Reddit   & Yelp    & Taobao \\ \midrule
\# Nodes             & 10845    & 15617   & 114232 \\
\# Edges             & 216397   & 56985   & 455662 \\
\# Total classes     & 18       & 15      & 90     \\
% \# Heterophily edges & 9.03\%  &42.06\% & 46.11\%  \\
\# Timespan          & 6 months & 5 years & 6 days \\ \midrule
\# Tasks             & 6        & 5       & 3      \\
\# Classes per task  & 3        & 3       & 30     \\
\# Timespan per task & 1 month  & 1 year & 2 days 
\\ \bottomrule
\end{tabular}%
}
\end{small}
\vspace{-0.2in}
\end{wraptable}

\textbf{Datasets.} 
We construct three real-world datasets to evaluate our method: Reddit \citep{hamilton2017inductive}, Yelp \citep{sankar2020dysat}, Taobao \citep{du2019sequential}.
% Reddit\footnote{https://files.pushshift.io/reddit/comments/}, Yelp\footnote{https://www.yelp.com/dataset}, Taobao\footnote{https://tianchi.aliyun.com/dataset/dataDetail?dataId=9716}. 
In Reddit, we construct a post-to-post graph.
% , following \citet{hamilton2017inductive}. 
Specifically, we treat posts as nodes and treat the subreddit (topic community) a post belongs to as the node label. When a user comments two posts with the time interval less or equal to a week, a temporal edge between the two nodes will be built.
We regard the data in each month as a task, where July to December in 2009 are used. In each month, we sample $3$ large communities that do not appear in previous months as the new classes. For Yelp dataset, we construct a business-to-business temporal graph from 2015 to 2019 in the same way as Reddit. 
For Taobao dataset, we construct an item-to-item graph in the same way as Reddit in a 6-days promotion season of Taobao. 
Table \ref{datasets} summarizes the statistics of these datasets. More information about datasets could be found in Appendix \ref{appendix4}.



\textbf{Experiment Settings.}
 For each task, we use $80\%$ nodes for training, $10\%$ nodes for validation, $10\%$ nodes for testing. We use two widely-used metrics  in class-incremental learning to evaluate our method \citep{chaudhry2018riemannian,bang2021rainbow}: AP and AF. Average Performance (AP)  measures the average  performance of a model on all previous tasks. Here we use accuracy to measure model performance. Average Forgetting (AF)  measures the decreasing extent of model performance on previous tasks compared to the best ones. 
  More implementation details is in Appendix \ref{appendix6}.
 
\textbf{Baselines.} 
First, we compare with three incremental learning methods based on static GNNs: ER-GAT \citep{zhou2021overcoming}, TWC-GAT \citep{liu2021overcoming} and ContinualGNN \citep{wang2020streaming}. For ER-GAT and TWC-GAT, we use the final state of temporal graph as input in each task. Since ContinualGNN is based on snapshots, we split each task into $10$ snapshots. In addition, we combine three representative temporal GNN (TGAT \citep{xu2020inductive}, TGN \citep{rossi2020temporal}, TREND \citep{wen2022trend}) and three widely-used class-incremental learning methods in computer vision (EWC \citep{kirkpatrick2017overcoming}, iCaRL \citep{rebuffi2017icarl}, BiC \citep{wu2019large}) as baselines. 
For our method, we set $M$ as $10$ on all the datasets.



\begin{table}
\centering
\vspace{-0.2in}
\begin{small}
\caption{Comparisons (\%) of our method with baselines. The bold represents the best in each column.}
 \vspace{-0.02in}
%is better for this metric (\%).}
 \label{baselines}
 \setlength{\tabcolsep}{1.5mm}
 {
\begin{tabular}{@{}ccccccc@{}}
\toprule
\multirow{2}{*}{Method} & \multicolumn{2}{c}{Reddit} & \multicolumn{2}{c}{Yelp} & \multicolumn{2}{c}{TaoBao} \\ \cmidrule(l){2-7} 
                        & AP($\uparrow$)           & AF($\downarrow$)          & AP($\uparrow$)           & AF($\downarrow$)          & AP($\uparrow$)            & AF($\downarrow$)           \\ \midrule
ContinualGNN            & 52.17 $\pm$ 2.46       & 25.59  $\pm$ 5.39      & 49.73 $\pm$ 0.27      & 28.76 $\pm$ 1.52     & 58.39  $\pm$ 0.24      & 47.03 $\pm$ 0.50       \\
ER-GAT                  & 52.03 $\pm$ 2.59       & 22.67  $\pm$ 3.30      & 62.05 $\pm$ 0.70       & 18.91 $\pm$ 1.09     & 70.09 $\pm$ 0.88      & 23.24 $\pm$ 0.36    \\
TWC-GAT                 & 52.88 $\pm$ 0.53       & 19.60  $\pm$ 3.64       & 60.90 $\pm$ 3.74       & 16.92 $\pm$ 0.63     & 59.91 $\pm$ 1.71      & 42.78 $\pm$ 1.39       \\ \midrule
TGAT                    & 48.47 $\pm$ 1.81       & 31.03  $\pm$ 4.48     & 64.89  $\pm$ 1.27      & 27.31 $\pm$ 3.99     & 60.62 $\pm$ 0.23        & 43.35 $\pm$ 0.77       \\
TGAT+EWC                & 50.16 $\pm$ 2.45       & 28.27 $\pm$ 4.00      & 66.58 $\pm$ 3.11       & 25.48 $\pm$ 1.75       & 64.03 $\pm$ 0.62        & 38.26 $\pm$ 1.20        \\
TGAT+iCaRL              & 54.50 $\pm$ 2.04       & 27.66 $\pm$ 1.11      & 71.71 $\pm$ 2.48       & 17.56 $\pm$ 2.46      & 73.74 $\pm$ 1.40         & 23.90 $\pm$ 2.04       \\
TGAT+BiC                & 54.61  $\pm$ 0.89       & 25.42 $\pm$ 2.72      & 74.73 $\pm$ 3.54      & 16.42 $\pm$ 4.41       & 74.05 $\pm$ 0.48        & 23.27 $\pm$ 0.65       \\ \midrule
TGN                     & 47.49 $\pm$ 0.48       & 32.06  $\pm$ 1.91     & 56.24 $\pm$ 1.65      & 41.27 $\pm$ 2.30      & 65.89 $\pm$ 1.20        & 36.15 $\pm$ 1.55       \\
TGN+EWC                 & 49.45 $\pm$ 1.45        & 31.74 $\pm$ 1.11       & 60.83 $\pm$ 3.55       & 35.73 $\pm$ 3.48      & 68.89 $\pm$ 2.09       & 32.08 $\pm$ 3.88    \\
TGN+iCaRL               & 50.86  $\pm$ 4.83      & 31.01  $\pm$ 2.78     & 73.34 $\pm$ 1.99       & 15.43 $\pm$ 0.93       & 77.42 $\pm$ 0.80      & 19.57  $\pm$ 1.29     \\
TGN+BiC                 & 53.16  $\pm$ 1.53      & 26.83  $\pm$ 0.95     & 73.98  $\pm$ 2.07      & 16.79 $\pm$ 2.90     & 77.40 $\pm$ 0.80       & 18.63  $\pm$ 1.69    \\ \midrule
TREND                     & 49.61 $\pm$ 2.92       & 28.68  $\pm$ 4.20     & 57.28 $\pm$ 2.83      & 37.48 $\pm$ 3.26      & 61.02 $\pm$ 0.16        & 42.44 $\pm$ 0.14       \\
TREND+EWC                 & 53.12 $\pm$ 3.30        & 25.70 $\pm$ 3.08       & 65.45 $\pm$ 4.79       & 26.80 $\pm$ 4.98      & 62.72 $\pm$ 1.18       & 40.00 $\pm$ 2.09    \\
TREND+iCaRL               & 52.53  $\pm$ 3.67     & 30.63  $\pm$ 0.18     & 69.93 $\pm$ 5.55       & 15.81 $\pm$ 7.48       & 74.49 $\pm$ 0.05      & 23.27  $\pm$ 0.25     \\
TREND+BiC                 & 54.22  $\pm$ 0.56      & 22.42  $\pm$ 3.15     & 71.15  $\pm$ 2.42      & 12.78 $\pm$ 5.12     & 75.13 $\pm$ 1.06       & 21.70  $\pm$ 0.63    \\ \midrule
OTGNet (Ours)            & \textbf{73.88} $\pm$ 4.55        & \textbf{19.25} $\pm$ 5.10       & \textbf{83.78} $\pm$ 1.06       & \textbf{4.98} $\pm$ 0.46       & \textbf{79.92} $\pm$ 0.12        & \textbf{12.82} $\pm$ 0.61         \\ \bottomrule
\end{tabular}%
}
\end{small}
\end{table}



\subsection{Results and Analysis} 
\label{exp}
\textbf{Overall Comparison.}
As shown in Table \ref{baselines}, our method outperform other methods by a large margin. The reasons are as follows. For the first three methods, they are all based on static GNN that can not capture the fine-grained dynamics in temporal graph. TGN, TGAT and TREND are three dynamic GNNs with fixed class set.  When applying three typical class-incremental learning methods to TGN, TGAT  and TREND, the phenomenon of catastrophic forgetting is alleviative. However, they still suffer from the issue of heterophily propagation.

\textbf{Performance Analysis of Different Task Numbers.} 
To provide further analysis of our method, we plot the performance changes of different methods along with the increased tasks.
As shown in Figure \ref{vary_ap}, our method generally achieves better performance than baselines as the task number increases. 
Since BiC based methods achieve better performance based on Table \ref{baselines}, we do not report the results of the other two incremental learning based methods.
In addition, the curves of OTGNet are smoother that those of other methods, which indicates our method can well address the issue of catastrophic forgetting. Because of space limitation, we provide the curves of AF in Appendix \ref{appendix7}.

\begin{figure}
  \begin{center}
    \includegraphics[width=0.9\textwidth]{figure/vary_ap.pdf}
  \end{center}
  \vspace{-6mm}
  \caption{ The changes of average performance (AP) (\%) on three datasets with the increased tasks. 
%   The value at x-coordinate $i$ represents the mean accuracy of all learned tasks after learning task $i$.
    %The coordinate (x,y)  represents the mean accuracy of all learned tasks after learning task x reaches y.
  }
   \vspace{-6mm}
    \label{vary_ap}
\end{figure}

\begin{table}
\vspace{-0.2in}
\centering
\begin{small}
\caption{Ablation study of our proposed information bottleneck based propagation mechanism.}
 \label{IB}
 \setlength{\tabcolsep}{1.5mm}
 {
\begin{tabular}{@{}ccccccc@{}}
\toprule
\multirow{2}{*}{Setting} & \multicolumn{2}{c}{Reddit} & \multicolumn{2}{c}{Yelp} & \multicolumn{2}{c}{TaoBao} \\ \cmidrule(l){2-7} 
                        & AP($\uparrow$)           & AF($\downarrow$)          & AP($\uparrow$)           & AF($\downarrow$)          & AP($\uparrow$)            & AF($\downarrow$)           \\ \midrule
OTGNet-w.o.-IB           & 54.10  $\pm$ 2.01      & 34.00 $\pm$ 1.63      & 76.93  $\pm$ 5.14       & 14.96 $\pm$ 5.61     & 79.00 $\pm$ 0.37      & 13.41 $\pm$ 0.57      \\
OTGNet-w.o.-prop  & 54.67 $\pm$ 2.05 & 28.73 $\pm$ 2.63  & 75.67 $\pm$ 1.69 & 12.87 $\pm$ 1.19  & 79.07 $\pm$ 0.02  & 14.48 $\pm$ 0.34 \\
OTGNet-GBK  & 58.79 $\pm$ 1.08 & 25.22 $\pm$ 2.22  & 77.03 $\pm$ 2.99 & 9.79 $\pm$ 1.15  & 77.73 $\pm$ 0.27  & 15.49 $\pm$ 0.34 \\
OTGNet              & \textbf{73.88} $\pm$ 4.55        & \textbf{19.25} $\pm$ 5.10       & \textbf{83.78} $\pm$ 1.06       & \textbf{4.98} $\pm$ 0.46       & \textbf{79.92} $\pm$ 0.12        & \textbf{12.82} $\pm$ 0.61        \\ \bottomrule
\end{tabular}%
}
\end{small}
 \vspace{-0.1in}
\end{table}

\begin{table}
\centering
\vspace{-0.2in}
\begin{small}
\caption{Results of triad selection strategy  on the three datasets.}
\vspace{-0.02in}
 \label{triad}
 \setlength{\tabcolsep}{0.7mm}
 {
\begin{tabular}{@{}ccccccc@{}}
\toprule
\multirow{2}{*}{Setting} & \multicolumn{2}{c}{Reddit} & \multicolumn{2}{c}{Yelp} & \multicolumn{2}{c}{TaoBao} \\ \cmidrule(l){2-7} 
                        & AP($\uparrow$)           & AF($\downarrow$)          & AP($\uparrow$)           & AF($\downarrow$)          & AP($\uparrow$)            & AF($\downarrow$)           \\ \midrule
OTGNet-w.o.-triad           & 60.81 $\pm$ 4.46       & 34.94  $\pm$ 4.73      & 69.28 $\pm$ 1.73      & 23.79 $\pm$ 1.75     & 67.05  $\pm$ 0.44      & 31.44 $\pm$ 0.41\\
OTGNet-random            & 69.66 $\pm$ 3.81       & 23.24  $\pm$ 3.83      & 78.76 $\pm$ 2.62      & 9.19 $\pm$ 1.65     & 79.09  $\pm$ 0.36      & 13.89 $\pm$ 0.45       \\
OTGNet-w.o.-diversity               & 71.06 $\pm$ 5.73       & 22.96  $\pm$ 6.91      & 80.76 $\pm$ 2.60       & 9.91 $\pm$ 3.83     & 78.84 $\pm$ 0.46      & 13.87 $\pm$ 1.18    \\
OTGNet              & \textbf{73.88} $\pm$ 4.55        & \textbf{19.25} $\pm$ 5.10       & \textbf{83.78} $\pm$ 1.06       & \textbf{4.98} $\pm$ 0.46       & \textbf{79.92} $\pm$ 0.12        & \textbf{12.82} $\pm$ 0.61          \\ \bottomrule
\end{tabular}%
}
\end{small}
\end{table}

\begin{table}
\centering
\vspace{-0.2in}
\begin{small}
\caption{Results of evolution pattern preservation on the three datasets.}
\vspace{-0.02in}
 \label{pattern}
 \setlength{\tabcolsep}{1mm}
 {
\begin{tabular}{@{}ccccccc@{}}
\toprule
\multirow{2}{*}{Setting} & \multicolumn{2}{c}{Reddit} & \multicolumn{2}{c}{Yelp} & \multicolumn{2}{c}{TaoBao} \\ \cmidrule(l){2-7} 
                        & AP($\uparrow$)           & AF($\downarrow$)          & AP($\uparrow$)           & AF($\downarrow$)          & AP($\uparrow$)            & AF($\downarrow$)           \\ \midrule
OTGNet-w.o.-pattern           & 70.23  $\pm$ 5.56      & 23.10 $\pm$ 7.44      & 81.44  $\pm$ 1.38       & 6.97 $\pm$ 3.10     & 79.01 $\pm$ 0.19      & 14.05 $\pm$ 0.46      \\
OTGNet              & \textbf{73.88} $\pm$ 4.55        & \textbf{19.25} $\pm$ 5.10       & \textbf{83.78} $\pm$ 1.06       & \textbf{4.98} $\pm$ 0.46       & \textbf{79.92} $\pm$ 0.12        & \textbf{12.82} $\pm$ 0.61        \\ \bottomrule
\end{tabular}%
}
\vspace{-0.1in}
\end{small}
\end{table}

\begin{table}[!]
\centering
\begin{small}
\vspace{-0.1in}
\caption{Results of of our acceleration solution with different  $K$.}
\label{selection_time1}
 \setlength{\tabcolsep}{1.5mm}{%
\begin{tabular}{@{}cccccccccc@{}}
\toprule
\multirow{2}{*}{} & \multicolumn{3}{c}{Reddit}                                                         & \multicolumn{3}{c}{Yelp}                                                          & \multicolumn{3}{c}{Taobao}                                                         \\ \cmidrule(l){2-10} 
                  & AP($\uparrow$)    & AF($\downarrow$)     & \begin{tabular}[c]{@{}c@{}}Time (h)\end{tabular} & AP($\uparrow$)    & AF($\downarrow$)   & \begin{tabular}[c]{@{}c@{}}Time (h)\end{tabular} & AP($\uparrow$)    & AF($\downarrow$)    & \begin{tabular}[c]{@{}c@{}}Time (h)\end{tabular} \\ \midrule
$K$=1000            & 73.88   & 19.25  & 1.23                                                               & 83.78  & 4.98   & 0.25                                                               & 79.92  & 12.82   & 1.61                                                               \\
$K$=500             & 71.26 & 22.45 & 0.45                                                               & 83.48  & 6.32 & 0.07                                                               & 79.19 & 13.94 & 0.53                                                               \\
$K$=200             & 66.83  & 26.88 & 0.07                                                               & 81.86  & 6.87 & 0.02                                                               & 79.14 & 13.73 & 0.10                                                               \\
$K$=100             & 66.22 & 28.86 & 0.04                                                               & 78.83 & 10.54 & 0.01                                                               & 78.81 & 14.58 & 0.04           \\ \bottomrule                                                   
\end{tabular}%
}
\vspace{-0.2in}
\end{small}
\end{table}


\textbf{Ablation Study of our proposed propagation mechanism.}
We further study the effectiveness of our information bottleneck based message propagation mechanism. OTGNet-w.o.-IB represents our method directly transferring the embeddings of neighbor nodes instead of  class-agnostic representations. 
OTGNet-w.o.-prop denotes our method directly dropping the links between nodes of different classes.
We take GBK-GNN \citep{du2022gbk}  as another baseline, where GBK-GNN originally handles the heterophily for static graph.
For a fair comparison, we modify GBK-GNN to an open temporal graph: Specifically, we create two temporal message propagation modules with separated parameters  as the two kernel feature transformation matrices in GBK-GNN. 
We denote this baseline as OTGNet-GBK.
As shown in Table \ref{IB}, OTGNet outperforms OTGNet-w.o.-IB and OTGNet-GBK on the three datasets. 
This illustrates that it is 
effective to extract class-agnostic information for  addressing the heterophily propagation issue. 
  OTGNet-w.o.-prop generally performs better than OTGNet-w.o.-IB. This tells us that it is inappropriate to directly transfer information between two nodes of different classes.
 OTGNet-w.o.-prop is inferior to OTGNet, which means that the information is lost if directly dropping the links between nodes of different nodes. 
 {An interesting phenomenon is  AF score decreases much without using  information bottleneck. This indicates that learning better node embeddings  by our message passing module is helpful to triad selection.
 }


\textbf{Triad Selection Strategy Analysis.}
First, we design three variants to study the impact of our triad selection strategy.
OTGNet-w.o.-triad means our method does not use any triad (i.e. $M=0$).
OTGNet-random represents our method selecting triads randomly. OTGNet-w.o.-diversity means our method selecting triads  without considering the diversity. 
As shown in Table \ref{triad}, The performance of our method decreases much when without using triads, which shows the effectiveness of using triads to prevent catastrophic forgetting.
OTGNet achieves better performance than OTGNet-random and OTGNet-w.o.-diversity, indicating the proposed triads selection strategy is effective. 


\textbf{Evolution Pattern Preservation Analysis.} We study the effectiveness of evolution pattern preservation. OTGNet-w.o.-pattern represents our method without evolution pattern preservation (i.e. $\rho=0$).
As shown in Table \ref{pattern}, OTGNet has superior performance over OTGNet-w.o.-pattern, which illustrates the evolution pattern preservation is beneficial to memorize the knowledge of old classes.



\vspace{-0.1in}

\paragraph {Acceleration Performance of Triad Selection.}
As stated aforementioned, to speed up the triad selection, we can sort  triads $g_k^c$ based on the values of $\mathcal{R}(g_k^c)$, and use top $K$ triads as the candidate set $N_k^c$ for selection. We perform experiments with different $K$, fixing $M=10$.  Table \ref{selection_time1} shows the results.
We notice that when using smaller $K$, the selection time drops quickly but the performance of our model degrades little. This illustrates our acceleration solution is efficient and effective.
Besides, the reason for performance dropping is that the total diversities of the triad candidates decreases.


\section{Conclusion}
\label{conclusion}
In this paper, we put forward a general framework, OTGNet, to investigate open temporal graph. We devise a novel message passing mechanism based on information bottleneck to extract class-agnostic knowledge for aggregation, which can address heterophily propagation issue.
To  overcome catastrophic forgetting, we propose to select representative triads to memorize knowledge of old classes, and design a new value function
to realize the selection.  
Experimental results on three real-world datasets demonstrate the effectiveness of our method.
 

\section{Acknowledgements}
This work was supported by the National Natural Science Foundation
of China (NSFC) under Grants 62122013, U2001211.


\bibliography{iclr2023_conference}
\bibliographystyle{iclr2023_conference}
\clearpage

\appendix
\section{Appendix}
\subsection{Derivation of Our Information Bottleneck Objective}
\label{appendix1}
Our message passing mechanism is motivated by traditional information bottleneck \citep{alemi2016deep,tishby2000information}. The objective of traditional information bottleneck is $\max_{Z} I(Z,Y)-\beta I(Z,X)$, which attempts to maximize the mutual information between label $Y$ and latent representation $Z$, and minimize the mutual information between input feature $X$ and latent representation $Z$. Different from that, we intend to extract class-agnostic information from node embeddings. Thus, we aim to minimize the mutual information between node label $Y$ and class-agnostic representation $Z(t)$, and maximize the mutual information between input embedding $X(t)$ and class-agnostic representation $Z(t)$. Our objective could be written as: $J_{IB}=\min_{Z(t)} I(Z(t),Y)-\beta I(Z,X(t))$. 
First, we give a proof of the upper bound of $I(Z(t),Y)$, motivated by \citet{cheng2020club}. 
Let $ I_{club}(Z(t),Y)=\mathbb{E}_{p(Z(t),Y)}[\log p(y|z(t))]-\mathbb{E}_{p(Z(t))}\mathbb{E}_{p(Y)}[\log p(y|z(t))]$. Let $o=I_{club}(Z(t),Y)-I(Z(t),Y)$, then we have:
\begin{align} \nonumber
    o&=
    \int{dz(t)dyp(z(t),y)\log p(y|z(t))}-\int{dz(t)p(z(t))\int{dyp(y)\log p(y|z(t))}}\\  \nonumber
    &\ \ \ \ -\int{dz(t)dyp(z(t),y)\log \frac{p(y|z(t))}{p(y)}}\\ \nonumber
    &=\int{dz(t)dyp(z(t),y)\log p(y)}-\int{dz(t)p(z(t))\int{dyp(y)\log p(y|z(t))}}\\ \nonumber
&=\int{dyp(y)\log p(y)}-{dyp(y)\int{dz(t)p(z(t))\log p(y|z(t))}}\\ 
&=\int{dyp(y)(\log p(y)-\int{dz(t)p(z(t))\log p(y|z(t))})}.
\end{align}
Since $log(\cdot)$ is a concave function, according to Jensens Inequality \citep{kian2014operator}, we have:
\begin{equation}
    \log p(y)-\!\int{\!\!dzp(z(t))\log p(y|z(t))}\!=
    \!\log \!(\!\!\int{\!\!dz(t)p(z(t))p(y| z(t))})
    -\!\!\int{\!\!dz(t)p(z(t))\log p(y|z(t))}\!\geq\!0.
\end{equation}
Then, we have:
\begin{equation}
    o=\int{dyp(y)(\log p(y)-\int{dz(t)p(z(t))\log p(y|z(t))})}\geq0.
\end{equation}
Thus, we derive the upper bound of $I(Z(t),Y)$:
\begin{equation}
    I(Z(t),Y)\le I_{club}(Z(t),Y)=\mathbb{E}_{p(Z(t),Y)}[\log p(y|z(t))]-\mathbb{E}_{p(Z(t))}\mathbb{E}_{p(Y)}[\log p(y|z(t))].
\end{equation}
Since $p(y|z(t))$ is unknown, we  introduce a variational approximation distribution $q_{\mu}(y|z(t))$ to approximate $p(y|z(t))$, following \citet{cheng2020club}.
%with parameter $\mu$.

Next, we give a proof to the lower bound of $I(X(t),Z(t))$, based on \citet{belghazi2018mutual}. According to Donsker-Varadhan representation \citep{donsker1975asymptotics}, we know:
\begin{align}\nonumber
    I(X(t),Z(t))&=KL(p(X(t),Z(t)),p(X(t))p(Z(t)))\\
    &={\sup}_{T:\mathrm{\Omega}\rightarrow R}\mathbb{E}_{p(X(t),Z(t))}[T]-\log(\mathbb{E}_{p(X(t))p(Z(t))}[e^T]),
\end{align}
where $\Omega=\mathcal{X} \times \mathcal{Z}$ is the input space. 
Let $\mathcal{F}$ be any class of functions $T:\mathrm{\Omega}\rightarrow R$, we have:
\begin{equation}
    KL(p(X(t),Z(t)),p(X(t))p(Z(t)))\geq{\sup}_{T\in\mathcal{F}}\mathbb{E}_{p(X(t),Z(t))}[T]-\log(\mathbb{E}_{p(X(t))p(Z(t))}[e^T]).
\end{equation}
We could choose $\mathcal{F}$ to be the family of functions $T_\psi:\mathcal{X}\times 
\mathcal{Z}\rightarrow\mathbb{R}$ parameterized by a neural network $\psi$:
\begin{equation}
    KL(p(X(t),Z(t)),p(X(t))p(Z(t)))\geq{\sup}_{\psi}\mathbb{E}_{p(X(t),Z(t))}[T_\psi]-\log(\mathbb{E}_{p(X(t))p(Z(t))}[e^{T_\psi}]).
\end{equation}
Thus, we have:
\begin{equation}
    I(X(t),Z(t))\geq I_{mine}(X(t),Z(t))={\sup}_{\psi}\mathbb{E}_{p(X(t),Z(t))}[T_\psi]-\log(\mathbb{E}_{p(X(t))p(Z(t))}[e^{T_\psi}]).
\end{equation}
Therefore, we could derive an upper bound of $J_{IB}$:
\begin{align}\nonumber
    J_{IB} \leq \mathcal{L}_{IB}&=I_{club}(Z(t),Y)-\beta I_{mine}(X(t),Z(t))\\ \nonumber
    \!\!&=\!\mathbb{E}_{p(Z(t),Y)}\![\log q_{\mu}(y|z(t))]\!-\!\mathbb{E}_{p(Z(t))}\!\mathbb{E}_{p(Y)}\![\log q_{\mu}(y|z(t))]\! \\
    &\ \ \ \ -\beta( {\sup}_{\psi}\mathbb{E}_{p(X(t),Z(t))}[T_\psi]\!-\!\log(\mathbb{E}_{p(X(t))p(Z(t))}[e^{T_\psi}])).\!
\end{align}

In order to minimize $J_{IB}$, we attempt to minimize its upper bound, i.e., $\mathcal{L}_{IB}$, and utilize the Monte Carlo sampling to approximate the expectations in $\mathcal{L}_{IB}$, motivated by \citep{wan2021multi,alemi2016deep}.
Therefore, the final loss function of $\mathcal{L}_{IB}$ can be expressed as:
\begin{align}\nonumber
\mathcal{L}_{IB} = &\frac{1}{|S_{d}|}\sum_{i\in S_d}\ [\ \log q_\mu(y_i|z_i(t))-\frac{1}{|S_{d}|}\sum_{j\in S_d}{\log q_\mu(y_j|z_i(t))}\ ]\ \\ 
&-\frac{\beta}{|S_{d}|}\sum_{i\in S_d}\ [\ T_\psi(x_i(t),\!z_i(t))-\log{(\frac{1}{|S_{d}|}\sum_{j\in S_d}e^{T_\psi(x_i(t),z_j(t))})}\ ]\ , 
\end{align}
where $S_d$ is a batch of nodes and $|S_d|$ is the size of $S_d$. $x_i(t)$, $z_i(t)$ are the embedding, the class-agnostic representation of node $i$ respectively at time-stamp $t$. $y_i$ is the label of node $i$. 


\subsection{Derivation of Triad Influence Function}
\label{appendix2}
%Based on previous works about influence function \citep{cook1980characterizations,koh2017understanding}, 
In this section, we prove that our triad influence function $\mathcal{I}_{loss}(g_k^c,\theta)$ could estimate the influence of the triad $g_k^c$ on the model performance for class $k$. The triad influence function $\mathcal{I}_{loss}(g_k^c,\theta)$ is defined as:
\begin{equation}
    \mathcal{I}_{loss}(g_k^c,\theta)
    =-{\mathrm{\nabla}_\theta \mathcal{L}(G_k,\theta) }^\top H_\theta^{-1}\mathrm{\nabla}_\theta \mathcal{L}(g_k^c,\theta),
\end{equation}
where $\theta$ is the parameter of the model and $G_k$ is the training node set of class $k$. $H_\theta$ is the Hessian matrix. $\mathrm{\nabla}_\theta \mathcal{L}(g_k^c,\theta)$, $\mathrm{\nabla}_\theta \mathcal{L}(G_k,\theta)$ are the gradient of loss to $g_k^c$ and $G_k$, respectively. 

The basic idea of the influence function \citep{cook1980characterizations,koh2017understanding} is to estimate the parameter change if
a training sample is upweighted by some small $\varepsilon$ ($\varepsilon \rightarrow 0$).
Thus, we add a small weight $\varepsilon$ on three nodes of the triad $g_k^c$ in the loss function $\mathcal{L}(\theta)$. The new loss function could be written as: 
\begin{equation}
   \label{eq:deviation1}
   \begin{aligned}
      \mathcal{L}_{\varepsilon,g_k^c}(\theta) &= \arg\min\;_{\theta}\;\sum_{v\in G_k}l(v,\theta) + \varepsilon \sum_{v\in g_k^c}l(v,\theta)\\
                                   &= \mathcal{L}(G_k,\theta) + \varepsilon \mathcal{L}(g_k^c,\theta),
   \end{aligned}
\end{equation}
where $l(v,\theta)$ is the loss of node $v$. With the new loss function, the parameter of model is changed to 
 $\hat\theta_{\varepsilon,g_k^c}=\arg\min\;_{\theta}\;\mathcal{L}_{\varepsilon,g_k^c}(\theta)$.
 
 According to \citet{cook1980characterizations}, we know  that the influence of upweighting $\varepsilon$ could be evaluated by ${\left.\frac{\displaystyle\operatorname d\hat\theta_{\varepsilon,g_k^c}}{\displaystyle\operatorname d\varepsilon}\right|}_{\varepsilon=0}$.

Since the new loss function (\ref{eq:deviation1}) is minimized by $\hat\theta_{\epsilon,g_k^c}$, we examine the first-order optimality condition:
\begin{equation}
    \label{newopt}
    0 = \mathrm{\nabla}_\theta \mathcal{L}(G_k,\theta) + \varepsilon \mathrm{\nabla}_\theta \mathcal{L}(g_k^c,\theta).
\end{equation}
Then, since we have $\hat\theta_{\varepsilon,g_k^c} \rightarrow \theta$ as $\varepsilon \rightarrow 0$,
we perform a Taylor expansion on the right-hand side of Eq. (\ref{newopt}) and the higher order infinitesimal $o(\hat\theta_{\varepsilon,g_k^c} - \theta)$ terms are dropped :
\begin{equation}
\label{approx}
  0 \approx  [\mathrm{\nabla}_\theta \mathcal{L}(G_k,\theta) + \epsilon \mathrm{\nabla}_\theta \mathcal{L}(g_k^c,\theta)] +  [\mathrm{\nabla}^2_\theta \mathcal{L}(G_k,\theta) + \epsilon \mathrm{\nabla}^2_\theta \mathcal{L}(g_k^c,\theta)]  (\hat\theta_{\varepsilon,g_k^c} - \theta).
\end{equation}
From Eq. (\ref{approx}), we could derive that 
\begin{equation}
 \hat\theta_{\varepsilon,g_k^c} - \theta \approx -
 [\mathrm{\nabla}_\theta \mathcal{L}(G_k,\theta) + \epsilon \mathrm{\nabla}_\theta \mathcal{L}(g_k^c,\theta)] [\mathrm{\nabla}^2_\theta \mathcal{L}(G_k,\theta) + \epsilon \mathrm{\nabla}^2_\theta \mathcal{L}(g_k^c,\theta)]^{-1} .
\end{equation}

Because $\theta$ minimizes $\mathcal{L}(G_k,\theta)$, $\mathrm{\nabla}_\theta \mathcal{L}(G_k,\theta)$ equals 0. By dropping the higher order infinitesimal  $o(\varepsilon)$ terms, we have:
\begin{equation}
   \label{eq:newlossfunction2}
      \hat\theta_{\varepsilon,g_k^c} - \theta \approx -[\nabla_\theta^{2}\mathcal{L}(G_k,\theta)]^{-1} \nabla_\theta \mathcal{L}(g_k^c,\theta) \varepsilon.
\end{equation}
We denote the $H_{\theta}=\nabla_\theta^{2}\mathcal{L}(G_k,\theta)$, and thus have:
\begin{equation}
   \label{eq:newlossfunction4}
      \hat\theta_{\varepsilon,g_k^c} - \theta \approx -H_{\theta}^{-1} \varepsilon \nabla_\theta \mathcal{L}(g_k^c,\theta).
\end{equation}
Then, we could estimate the change of parameters influenced by  a triad as follows:
\begin{equation}
   \label{eq:newlossfunction3}
   \begin{aligned}
      {\left.\frac{\displaystyle\operatorname d\hat\theta_{\varepsilon,g_k^c}}{\displaystyle\operatorname d\varepsilon}\right|}_{\varepsilon=0} &= {\left.\frac{\hat\theta_{\varepsilon,g_k^c} - \theta}{\displaystyle\operatorname \varepsilon}\right|}_{\varepsilon=0} = {\left.\frac{-\varepsilon H_{\theta}^{-1} \nabla_\theta \mathcal{L}(g_k^c,\theta)}{\displaystyle\operatorname \varepsilon}\right|}_{\varepsilon=0} \\
      &= -H_{\theta}^{-1} \nabla_\theta \mathcal{L}(g_k^c,\theta).
   \end{aligned}
\end{equation}
Finally, we could derive the triad influence function $\mathcal{I}_{loss}(g_k^c,\theta)$ by the chain rule:
\begin{equation}
   \label{eq:newlossfunction3}
   \begin{aligned}
  \mathcal{I}_{loss}(g_k^c,\theta) &= {\left.\frac{\displaystyle\operatorname d\mathcal{L}_(G_k,\theta_{\varepsilon,g_k^c})}{\displaystyle\operatorname d\varepsilon}\right|}_{\varepsilon=0} = \nabla_\theta \mathcal{L}(G_k,\theta)^\top       {\left.\frac{\displaystyle\operatorname d\hat\theta_{\varepsilon,g_k^c}}{\displaystyle\operatorname d\varepsilon}\right|}_{\varepsilon=0}\\
      &= -{\mathrm{\nabla}_\theta \mathcal{L}(G_k,\theta) }^\top H_\theta^{-1}\mathrm{\nabla}_\theta \mathcal{L}(g_k^c,\theta).
   \end{aligned}
\end{equation}



\subsection{Proof of Monotonicity and Submodularity}
\label{appendix3}
Our proposed value function is defined as:
\begin{align} \label{ff}
    F(S_k^c)=\sum_{g_{k,i}^c \in S_k^c}{\mathrm{\nabla}_\theta \mathcal{L}(G_k,\theta) }^\top H_\theta^{-1}\mathrm{\nabla}_\theta \mathcal{L}(g_{k,i}^c,\theta)+\gamma \frac{|\bigcup_{g_{k,i}^c\in S_k^c} \mathcal{C}_{g_{k,i}^c}|}{|N_k^c|},
\end{align}
where $\mathcal{C}_{g_{k,i}^c}=\{g_{k,j}^c|\ ||\bar{x}(g_{k,j}^c)-\bar{x}(g_{k,i}^c){||}_2\le\delta,g_{k,j}^c\in N_k^c\}$ and $N^c_k$ is the set containing all triads with positive $\mathcal{R}(g_k^c)$. As stated before, finding a fixed size set $S_k^c$ ($S_k^c\subseteq N_k^c$) that maximizes $F(S_k^c)$ is NP-hard due to the combinatorial complexity. Thus, we first prove that our value function $F$ is monotone and submodular.
Then our optimization problem could be solved by a greedy algorithm with an approximation ratio guarantee according to \citet{krause2014submodular}.


\textbf{Definition 1.} (Monotonicity) A function $f:2^N\rightarrow\mathbb{R}$ is monotone if for $\forall A\subseteq B\subseteq N$, it holds that $F(A)\leq F(B) $.

\textbf{Lemma 1.} Our value function $F$ in Eq. (\ref{ff}) is monotone.
\begin{proof}
  We define two triad sets $A,B$ that satisfy $A\subseteq B\subseteq N_k^c$. Let $\Delta=F(B)-F(A)$. We have:
\begin{align}\nonumber
\Delta &=\sum_{g_{k,i}^c\in B}{\mathrm{\nabla}_\theta \mathcal{L}(G_k,\theta)}^TH_\theta^{-1}{\mathrm{\nabla}_\theta \mathcal{L}(g_{k,i}^c,\theta)}-\sum_{g_{k,i}^c\in A}{\mathrm{\nabla}_\theta \mathcal{L}(G_k,\theta)}^TH_\theta^{-1}{\mathrm{\nabla}_\theta \mathcal{L}(g_{k,i}^c,\theta)}\\ \nonumber
&\ \ \ \ +\frac{|\bigcup_{g_{k,i}^c\in B} \mathcal{C}_{g_{k,i}^c}|}{|N_c|}-\frac{|\bigcup_{g_{k,i}^c\in A} \mathcal{C}_{g_{k,i}^c}|}{|N_c|}\\ \nonumber
 &= {\mathrm{\nabla}_\theta \mathcal{L}(G_k,\theta)}^TH_\theta^{-1}(\sum_{g_{k,i}^c\in B}{\mathrm{\nabla}_\theta \mathcal{L}(g_{k,i}^c,\theta)}\!-\!\!\sum_{g_{k,i}^c\in A}{\mathrm{\nabla}_\theta \mathcal{L}(g_{k,i}^c,\theta)})\\ \nonumber
 &\ \ \ \ +\frac{|\bigcup_{g_{k,i}^c\in B} \mathcal{C}_{g_{k,i}^c}|}{|N_c|}\!-\!\frac{|\bigcup_{g_{k,i}^c\in A} \mathcal{C}_{g_{k,i}^c}|}{|N_c|}\\ \nonumber
&={\mathrm{\nabla}_\theta \mathcal{L}(G_k,\theta)\mathrm{\ } }^TH_\theta^{-1} \sum_{g_{k,i}^c\in T}{\mathrm{\nabla}_\theta \mathcal{L}(g_{k,i}^c,\theta)} +\frac{|\bigcup_{g_{k,i}^c\in B} \mathcal{C}_{g_{k,i}^c}|}{|N_c|}-\frac{|\bigcup_{g_{k,i}^c\in A} \mathcal{C}_{g_{k,i}^c}|}{|N_c|}\\ \nonumber
&\geq\frac{|\bigcup_{g_{k,i}^c\in B} \mathcal{C}_{g_{k,i}^c}|}{|N_c|}-\frac{|\bigcup_{g_{k,i}^c\in A} \mathcal{C}_{g_{k,i}^c}|}{|N_c|}\geq\frac{|\bigcup_{g_{k,i}^c\in A} \mathcal{C}_{g_{k,i}^c}|}{|N_c|}-\frac{|\bigcup_{g_{k,i}^c\in A} \mathcal{C}_{g_{k,i}^c}|}{|N_c|}=0.
\end{align}

Thus, we have:
\begin{align}
    \Delta&=F(B)-F(A) \geq 0.\\
    &\Rightarrow F(A) \leq F(B).
\end{align}
\end{proof}
\textbf{Definition 2.} (Submodularity) A function $f:2^N\rightarrow\mathbb{R}$ is submodular if for $\forall A\subseteq B\subseteq N$ and $\forall x\in N\backslash B$, it holds that $ F(A\cup\{x\})-F(A)\geq F(B\cup\{x\})-F(B)$.

\textbf{Lemma 2.} Our value function $F$  in Eq. (\ref{ff}) is submodular.
\begin{proof}
We define two triad sets $A,B$ that satisfy $A\subseteq B\subseteq N_k^c$. Let $T=B\backslash A$. Define $\Delta=(F(A\cup\{x\})-F(A))-(F(B\cup\{x\})-F(B))$. Then we have:
\begin{align}\nonumber
    \Delta &=\!\!{\mathrm{\nabla}_\theta \mathcal{L}(G_k,\theta)}^T\!\! H_\theta^{-1}\!(\!\!\!\!\!\!\!\!\!\sum_{g_{k,i}^c\in A\cup\{x\}}{\!\!\!\!\!\!\!\!\!\mathrm{\nabla}_\theta \mathcal{L}(g_{k,i}^c,\theta)}\!-\!\!\!\!\sum_{g_{k,i}^c\in A}{\!\!\!\!\mathrm{\nabla}_\theta \mathcal{L}(g_{k,i}^c,\theta)}\!+\!\!\!\!\!\!\!\!\!\!\sum_{g_{k,i}^c\in B\cup\{x\}}\!\!\!\!{\!\!\!\!\mathrm{\nabla}_\theta \mathcal{L}(g_{k,i}^c,\theta)}-\!\!\!\!\sum_{g_{k,i}^c\in B}{\!\!\!\!\mathrm{\nabla}_\theta \mathcal{L}(g_{k,i}^c,\theta)})\\ 
    &\ \ \ \ +\frac{|\bigcup_{g_{k,i}^c\in A\cup\{x\}} \mathcal{C}_{g_{k,i}^c}|}{|N_k^c|}-\frac{|\bigcup_{g_{k,i}^c\in A} \mathcal{C}_{g_{k,i}^c}|}{|N_k^c|}-(\frac{|\bigcup_{g_{k,i}^c\in B\cup\{x\}} \mathcal{C}_{g_{k,i}^c}|}{|N_k^c|}-\frac{|\bigcup_{g_{k,i}^c\in B} \mathcal{C}_{g_{k,i}^c}|}{|N_k^c|}).\\ \nonumber
\Delta&={\mathrm{\nabla}_\theta \mathcal{L}(G_k,\theta)\mathrm{\ } }^TH_\theta^{-1}(\sum_{g_{k,i}^c\in\{x\}}{\mathrm{\nabla}_\theta \mathcal{L}(g_{k,i}^c,\theta)}-\sum_{g_{k,i}^c\in{x}}{\mathrm{\nabla}_\theta \mathcal{L}(g_{k,i}^c,\theta)})\\ 
&\ \ \ \ +\frac{|\bigcup_{g_{k,i}^c\in A\cup\{x\}} \mathcal{C}_{g_{k,i}^c}|}{|N_k^c|}-\frac{|\bigcup_{g_{k,i}^c\in A} \mathcal{C}_{g_{k,i}^c}|}{|N_k^c|}-(\frac{|\bigcup_{g_{k,i}^c\in B\cup\{x\}} \mathcal{C}_{g_{k,i}^c}|}{|N_k^c|}-\frac{|\bigcup_{g_{k,i}^c\in B} \mathcal{C}_{g_{k,i}^c}|}{|N_k^c|}).\\
\Delta&=\frac{|\bigcup_{g_{k,i}^c\in A\cup\{x\}} \mathcal{C}_{g_{k,i}^c}|}{|N_k^c|}-\frac{|\bigcup_{g_{k,i}^c\in A} \mathcal{C}_{g_{k,i}^c}|}{|N_k^c|}-(\frac{|\bigcup_{g_{k,i}^c\in B\cup\{x\}} \mathcal{C}_{g_{k,i}^c}|}{|N_k^c|}-\frac{|\bigcup_{g_{k,i}^c\in B} \mathcal{C}_{g_{k,i}^c}|}{|N_k^c|}).\\ \nonumber
\Delta& =\frac{|\bigcup_{g_{k,i}^c\in A\cup\{x\}} \mathcal{C}_{g_{k,i}^c}|}{|N_k^c|}-\frac{|\bigcup_{g_{k,i}^c\in A} \mathcal{C}_{g_{k,i}^c}|}{|N_k^c|}-(\frac{|\bigcup_{g_{k,i}^c\in A\cup T\cup\{x\}} \mathcal{C}_{g_{k,i}^c}|}{|N_k^c|}-\frac{|\bigcup_{g_{k,i}^c\in A\cup T} \mathcal{C}_{g_{k,i}^c}|}{|N_k^c|}).\\ 
\nonumber
\Delta& = \frac{1}{N_k^c}(|(\bigcup_{g_{k,i}^c\in A} \mathcal{C}_{g_{k,i}^c})\cup(\bigcup_{g_{k,i}^c\in\{x\}} \mathcal{C}_{g_{k,i}^c})|-|(\bigcup_{g_{k,i}^c\in A} \mathcal{C}_{g_{k,i}^c})| \\
&\ \ \ \ -|(\bigcup_{g_{k,i}^c\in A} \mathcal{C}_{g_{k,i}^c})\cup(\bigcup_{g_{k,i}^c\in T} \mathcal{C}_{g_{k,i}^c})\cup(\bigcup_{g_{k,i}^c\in\{x\}} \mathcal{C}_{g_{k,i}^c})|+|(\bigcup_{g_{k,i}^c\in A} \mathcal{C}_{g_{k,i}^c})\cup(\bigcup_{g_{k,i}^c\in T} \mathcal{C}_{g_{k,i}^c})|).
\end{align}

For convenience, we denote $\bigcup_{g_{k,i}^c\in Q} \mathcal{C}_{g_{k,i}^c}=\mathcal{C}_Q^\ast$. We have:
\begin{align} \nonumber
\Delta&=\frac{1}{|N_k^c|}(|\mathcal{C}_A^\ast\cup \mathcal{C}_{\{x\}}^\ast|-|\mathcal{C}_A^\ast|-|\mathcal{C}_A^\ast\cup \mathcal{C}_{\{T\}}^\ast\cup \mathcal{C}_{\{x\}}^\ast|+|\mathcal{C}_A^\ast\cup \mathcal{C}_T^\ast|)\\ \nonumber
&=\frac{1}{|N_k^c|}(|\mathcal{C}_A^\ast|+|\mathcal{C}_{\{x\}}^\ast|-|\mathcal{C}_A^\ast\cap \mathcal{C}_{\{x\}}^\ast|-|\mathcal{C}_A^\ast|+|\mathcal{C}_A^\ast\cup \mathcal{C}_{\{T\}}^\ast\cup \mathcal{C}_{\{x\}}^\ast|+|\mathcal{C}_A^\ast\cup \mathcal{C}_T^\ast|)\\ \nonumber
%&=\frac{1}{|N_k^c|}(|\mathcal{C}_{\{x\}}^\ast|-|\mathcal{C}_A^\ast\cap \mathcal{C}_{\{x\}}^\ast|-|\mathcal{C}_A^\ast\cup \mathcal{C}_{\{T\}}^\ast\cup \mathcal{C}_{\{x\}}^\ast|+|\mathcal{C}_A^\ast\cup \mathcal{C}_T^\ast|)\\ \nonumber
%&=\frac{1}{|N_k^c|}(|\mathcal{C}_{\{x\}}^\ast|-|\mathcal{C}_A^\ast\cap \mathcal{C}_{\{x\}}^\ast|-|\mathcal{C}_A^\ast\cup \mathcal{C}_{\{T\}}^\ast\cup \mathcal{C}_{\{x\}}^\ast|+|\mathcal{C}_A^\ast\cup \mathcal{C}_T^\ast|)\\ \nonumber
&=\frac{1}{|N_k^c|}(|\mathcal{C}_{\{x\}}^\ast|-|\mathcal{C}_A^\ast\cap \mathcal{C}_{\{x\}}^\ast|-|\mathcal{C}_A^\ast|-|\mathcal{C}_T^\ast|-|\mathcal{C}_{\{x\}}^\ast|+|\mathcal{C}_A^\ast\cap \mathcal{C}_T^\ast|\\ \nonumber
&\ \ \ \ +|\mathcal{C}_A^\ast\cap \mathcal{C}_{\{x\}}^\ast|+|\mathcal{C}_T^\ast\cap \mathcal{C}_{\{x\}}^\ast|-|\mathcal{C}_A^\ast\cap \mathcal{C}_{\{T\}}^\ast\cap \mathcal{C}_{\{x\}}^\ast|+|\mathcal{C}_A^\ast\cup \mathcal{C}_T^\ast|)\\ \nonumber
&=\frac{1}{|N_k^c|}(-|\mathcal{C}_A^\ast|-|\mathcal{C}_T^\ast|\!+\!|\mathcal{C}_A^\ast\cap \mathcal{C}_T^\ast|\!+\!|\mathcal{C}_T^\ast\cap \mathcal{C}_{\{x\}}^\ast|\!-\!|\mathcal{C}_A^\ast\cap \mathcal{C}_{\{T\}}^\ast\cap \mathcal{C}_{\{x\}}^\ast|\!+\!|\mathcal{C}_A^\ast\cup \mathcal{C}_T^\ast|)\\ \nonumber
&=\frac{1}{|N_k^c|}(-|\mathcal{C}_A^\ast|-|\mathcal{C}_T^\ast|+|\mathcal{C}_A^\ast\cap \mathcal{C}_T^\ast|+|\mathcal{C}_T^\ast\cap \mathcal{C}_{\{x\}}^\ast|-|\mathcal{C}_A^\ast\cap \mathcal{C}_{\{T\}}^\ast\cap \mathcal{C}_{\{x\}}^\ast|\\ \nonumber
&\ \ \ \ +|\mathcal{C}_A^\ast|+|\mathcal{C}_T^\ast|-|\mathcal{C}_A^\ast\cap \mathcal{C}_T^\ast|)\\ \nonumber
&=\frac{1}{|N_k^c|}(|\mathcal{C}_T^\ast\cap \mathcal{C}_{\{x\}}^\ast|-|\mathcal{C}_A^\ast\cap \mathcal{C}_{\{T\}}^\ast\cap \mathcal{C}_{\{x\}}^\ast|)\\
&\geq 0.
\end{align}
Then, we can derive:
\begin{align}
    \Delta&=(F(A\cup\{x\})-F(A))-(F(B\cup\{x\})-F(B)) \geq 0. \\ 
    &\Rightarrow F(A\cup\{x\})-F(A) \geq F(B\cup\{x\})-F(B).
\end{align}
% Therefore, Lemma 2 is proofed.
\end{proof} 





\subsection{Dataset Details}
\label{appendix4}
\paragraph{Reddit Dataset}
Reddit is a large platform of topic communities where people could write and upload their posts to share their opinions.
For the Reddit dataset \footnote{https://files.pushshift.io/reddit/comments/},  we construct a post-to-post graph, similar to \citet{hamilton2017inductive}.
We omit the top 20 largest communities, because they are large and generic default communities, which could skew the class distribution \citep{hamilton2017inductive}. From the rest of communities, in each month we sample $3$ largest communities that doesn't appear in previous months as new classes for each task.  We take the data from July to November in 2009 and construct  $6$ tasks based on the selected data. 
In the graph, the posts are regarded as nodes and their corresponding communities are regarded as node labels. When a user comments a post at time $t$, the temporal edges at timestamp $t$ will be built, connecting this post to other posts this user has commented within a week. 
We initialize the feature representation of a node by averaging 300-dimensional GloVe word embeddings of all comments in this post, following \citet{hamilton2017inductive}.

\paragraph{Yelp Dataset}
Yelp is a large business review website where people could upload their reviews for commenting business, and find their interested business by others' reviews.
For the Yelp dataset\footnote{https://www.yelp.com/dataset}, we construct a business-to-business temporal graph, in the same way as Reddit.
Specifically, we take the data from 2015 to 2019, and treat the data in each year as a task, thus forming $5$ tasks in total.
In each year, we sample $3$ largest business categories as three classes in each task. Note that the business categories in each task have never occurred in previous tasks.
We regard each business as a node and set  the business's category as its node label. The temporal edge will be formed, once a user reviews the corresponding two businesses within a month.
We initialize the feature representation for each node by averaging 300-dimensional GloVe word embeddings of all reviews for this business.
 

\paragraph{Taobao Dataset}
Taobao is a large online shopping platform where items (products) could be viewed and purchased by people online. 
For the Taobao dataset\footnote{https://tianchi.aliyun.com/dataset/dataDetail?dataId=9716}\citep{du2019sequential}, we construct an item-to-item graph, in the same way as Reddit. The data in the Taobao dataset is a 6-days promotion season of Taobao in 2018. 
We set the time duration for each task as $2$ days. 
In each two days, we take the top $30$ largest item categories according to the number of items as the new classes for this task. The categories in each task have never occurred in previous tasks.
We regard the items as nodes and take the categories of items as the node labels. The temporal edge will be built if a user purchases two corresponding items in the promotion season.
We use the 128-dimensional embedding provided by the original dataset as the initial feature of the node.



\subsection{ Pseudo-code of Proposed Method}
\label{appendix5}
We provide the pseudo-code of our training procedure, as shown in Algorithm  \ref{overall}. When learning task $\mathcal{T}_i$, we input the interactions in current task and triads of previous tasks together into our proposed message passing framework. All nodes in current interactions and previous triads are used to calculate node classification loss for training. The closed triads and open triads serve as positive and negative samples to preserve evolution patterns, respectively. After learning task $\mathcal{T}_i$, we select representative triads for the classes in $\mathcal{T}_i$ and then begin to learn task $\mathcal{T}_{i+1}$.
Note that our algorithm does not guarantee that the selected triads must be  connected with the nodes in the new task. This is because the selected triads play two roles in our method: on one hand, when the nodes in the triads are connected with the nodes in a new task, it will propagate knowledge among these nodes by extracting class-agnostic representations; on the other hand,  triads are used to preserve the knowledge of old classes, so as to avoid  catastrophic knowledge forgetting when learning new classes. Even though the selected triad does not connect with the nodes in the new task, we think it still is important for learning old classes by simultaneously considering both importance and diversity. 
% Code is available at: \href{https://github.com/tulerfeng/OTGNet}{https://github.com/tulerfeng/OTGNet}.



\subsection{Implementation details}
\label{appendix6}
We perform our experiments using GeForce RTX 3090 Ti GPU. 
 We use the Adam optimizer for training with learning rate $\eta=0.0001$ on the Reddit dataset, learning rate $\eta=0.005$ on the Yelp datasets and learning rate $\eta=0.001$ on the Taobao datasets.
For all baselines and our method, we train each new task until convergence, and then evaluate the performance of the model  on current task and all previous tasks.
  For the Reddit dataset and the Yelp dataset, we train each task 500 epochs. For the Taobao dataset, we train each task 100 epochs. We set the dropout rate to 0.5 on all the datasets. 
 The node classification head is a two-layer MLP with hidden size 128. The selected triad pairs per class $M$ is set to $10$ on all datasets. 
 The sub-network extracting class-agnostic information is a two-layer MLP with hidden size 100. 
Note that we do not use a whole graph in the forward pass computation. 
For replaying the triads, we sample 5 neighbors of each node in the triad for forward propagation, motivated by the sampling strategy in TGAT and TGN. For the nodes on the current new task, we also sample 5 neighbor nodes (maybe from old class nodes) for each node to aggregate the neighborhood information. 
 
% When reusing the triads, we adopt their original timestamps. Since the node embedding is corresponding to time in the temporal setting, we restore the original embeddings of three nodes in a triad and their sampled neighbors in the buffer. When replay triads, we use their original timestamps and embeddings. So the triad is replayed on its original subgraph at its original timestamp, which is independent with the current task learning. 


\begin{algorithm}[t]
  \setcounter{algorithm}{1}
  \caption{OTGNet: Open Temporal Graph Neural Networks}  
  \begin{algorithmic}[1]  
    \Require 
    task number $L$, last time-stamp $t$, interaction set $\mathcal{E}(t)$, node label set $\mathcal{Y}(t)=\{1,2,...,m(t)\}$, node initial feature $x_i(0)$, epochs $N_e$, memory budget per class $M$, trade-off parameter $\rho$;
    \Ensure
    prediction of node classes;
    \State Initialize node embeddings;
    \State Initialize triad memory buffer $S=\emptyset$;
    \For{each task $\mathcal{T}_i$ from $\mathcal{T}_1$ to $\mathcal{T}_L$}
        \For{each epoch $e$ from $1$ to $N_e$}
            \For{each batch $b$ in epoch $e$}
                \State let $H$ be the set containing all interactions in batch $b$;
                \If{$\mathcal{T}_i \neq \mathcal{T}_1$}
                    \State let $H_{pre}$ be the set containing the interactions for all triads in $S$;
                    \State $H=H \cup H_{pre}$;
                \EndIf
                \State extract class-agnostic embeddings for all interactive nodes and their neighbors in $H$;
                \State propagate message for all interactive nodes in $H$;
                \State calculate node classification loss $\mathcal{L}_{ce}$ for all interactive nodes in $H$;
                \State let $\mathcal{L}=\mathcal{L}_{ce}$;
                \If{$\mathcal{T}_i \neq \mathcal{T}_1$}
                    \State calculate link prediction loss $\mathcal{L}_{link}$ for all triads in $S$;
                    \State $\mathcal{L}=\mathcal{L}_{ce}+\rho \mathcal{L}_{link}$;
                \EndIf
                %\State calculate the information bottleneck loss $\mathcal{L}_{IB}$;
                \State minimize the information bottleneck loss $\mathcal{L}_{IB}$;
                \State minimize the training loss $\mathcal{L}$;
            \EndFor
        \EndFor
        \For{each class $k$ in task $\mathcal{T}_i$}
            \State select representative closed triad set $S_k^o$ for class $k$  by Algorithm 1;
            \State select representative open triad set $S_k^o$ for class $k$ by Algorithm 1;
            \State $S=S\cup S_k^c\cup S_k^o$
        \EndFor
        \For{each task $\mathcal{T}_j$ from $\mathcal{T}_1$ to $\mathcal{T}_i$}
            \State evaluate the performance of our model on the unseen test data of $\mathcal{T}_j$;
        \EndFor
    \EndFor
  \end{algorithmic}  
  \label{overall}
\end{algorithm}  




\subsection{Additional Experiments}
\label{appendix7}

\paragraph{Forgetting Analysis of Different Task Numbers.}

\begin{figure}
  \begin{center}
  \vspace{-0.2 in}
    \includegraphics[width=0.99\textwidth]{figure/vary_af.pdf}
  \end{center}
    \vspace{-0.2 in}
  \caption{ The changes of average forgetting (AF) (\%) on three datasets with the increased tasks. 
  }
    \vspace{-0.2 in}
    \label{vary_af}
\end{figure}



We study the average forgetting (AF) changes of different methods along with the increased tasks. As stated in the main body of this paper, AF measures the decreasing extent of model performance on previous tasks compared to the best ones. 
 Note that AF does not count the last task since the forgetting for the last task has not yet happened. 
As shown in Figure \ref{vary_af}, AF of our method is generally smaller than that of other methods. This indicates that our method generally suffers from less catastrophic forgetting than other methods.



\paragraph{Convergence Analysis.}
We analyze the convergence of our method. We plot the loss curves (including the total training loss $\mathcal{L}$ and the information bottleneck loss  $\mathcal{L}_{IB}$ on the largest dataset, Taobao. 
As shown in Figure \ref{loss_plot}, our method can be eventually convergent when learning for each task. 


\begin{figure}
\centering
\subfigure[Training loss $\mathcal{L}$]{
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=1.93in]{figure/train_loss_taobao.pdf}
\end{minipage}
}%
\subfigure[Information bottleneck loss $\mathcal{L}_{IB}$]{
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[width=2in]{figure/IB_loss_taobao.pdf}
\end{minipage}%
}%
\centering
\vspace{-0.15in}
\caption{Convergence analysis. A new task is added for every 100 epochs.}
\label{loss_plot}
\vspace{-0.15in}
\end{figure}

\begin{figure}
\centering
\subfigure[AP with varying $M$]{
\begin{minipage}[t]{0.49\linewidth}
\centering
\includegraphics[width=2.1in]{figure/ap_m.pdf}
\end{minipage}%
}%
\subfigure[AF with varying $M$]{
\begin{minipage}[t]{0.49\linewidth}
\centering
\includegraphics[width=2in]{figure/af_m.pdf}
\end{minipage}
}%
\centering
\caption{The sensitivity of $M$ in our method on three datasets}
\label{hyper_m}
\end{figure}

\paragraph{Sensitivity Analysis of $M$.}
We analyze the influence of the number $M$ of selected triads when fixing $K=1000$. As shown in Figure \ref{hyper_m}(a)(b),
 it could be observed that when we fix $K=1000$, our method obtains good performance when $M\geq10$. This is because with a relatively large $K$, we could select not only important but also diverse triads to preserve knowledge for achieving good performance. 
Thus, we set $M=10$ throughout the experiment.


\begin{figure}
\centering
\subfigure[AP with varying $\rho$]{
\begin{minipage}[t]{0.49\linewidth}
\centering
\includegraphics[width=2.1in]{figure/ap_rho.pdf}
\end{minipage}%
}%
\subfigure[AF with varying $\rho$]{
\begin{minipage}[t]{0.49\linewidth}
\centering
\includegraphics[width=2in]{figure/af_rho.pdf}
\end{minipage}
}%
\centering
\caption{The sensitivity of $\rho$ in our method on three datasets}
\label{hyper_rho}
\end{figure}

\paragraph{Sensitivity Analysis of $\rho$.}
We analyze the sensitiveness of $\rho$. $\rho$ is the hyper-parameter on the link prediction loss for evolution pattern preservation.
As shown in Figure \ref{hyper_rho}(a)(b), we observe that our method is not sensitive to $\rho$ in a relatively large range.

\begin{figure}
\centering
\vspace{-0.2in}
\subfigure[AP with varying $\gamma$]{
\begin{minipage}[t]{0.49\linewidth}
\centering
\includegraphics[width=2in]{figure/ap_gamma.pdf}
\end{minipage}%
}%
\subfigure[AF with varying $\gamma$]{
\begin{minipage}[t]{0.49\linewidth}
\centering
\includegraphics[width=2in]{figure/af_gamma.pdf}
\end{minipage}
}%
\centering
\caption{The sensitivity of $\gamma$ in our method on three datasets.}
\vspace{-0.3in}
\label{hyper_gamma}
\end{figure}

\paragraph{Sensitivity Analysis of $\gamma$.}

We analyze the sensitivity of $\gamma$ in our method. Recall that $\gamma$ is a trade-off parameter for balancing the contributions between diversity and importance when selecting representative triads. As shown in Figure \ref{hyper_gamma}, our method is not sensitive to $\gamma$ in a relatively large range.

\begin{figure}
\centering
\subfigure[AP with varying $\beta$]{
\begin{minipage}[t]{0.49\linewidth}
\centering
\includegraphics[width=2.1in]{figure/ap_beta.pdf}
\end{minipage}%
}%
\subfigure[AF with varying $\beta$]{
\begin{minipage}[t]{0.49\linewidth}
\centering
\includegraphics[width=2in]{figure/af_beta.pdf}
\end{minipage}
}%
\centering
\caption{The sensitivity of $\beta$ in our method on three datasets}
\label{hyper_beta}
\end{figure}

\paragraph{Sensitivity Analysis of $\beta$.}
We analyze the sensitivity of $\beta$ in our method.  $\beta$ is the Lagrange multiplier in the objective of information bottleneck. As shown in Figure \ref{hyper_beta}, we observe that our method has stable performance when changing $\beta$ in a certain range.


\begin{figure}[t]
\centering
\vspace{-0.2in}
\subfigure[AP with varying $\delta$]{
\begin{minipage}[t]{0.49\linewidth}
\centering
\includegraphics[width=2in]{figure/ap_delta.pdf}
\end{minipage}%
}%
\subfigure[AF with varying $\delta$]{
\begin{minipage}[t]{0.49\linewidth}
\centering
\includegraphics[width=2in]{figure/af_delta.pdf}
\end{minipage}
}%
\centering
\caption{The sensitivity of $\delta$ in our method on three datasets}
\label{hyper_delta}
\end{figure}




\paragraph{Sensitivity Analysis of $\delta$.}
We further analyze the sensitivity of $\delta$ in our method.  $\delta$ is a hyper-parameter for measuring the diversity of a triad set. As shown in Figure \ref{hyper_delta}, our method is not sensitive to $\delta$ in a relatively large range.





\subsection{AP and AF for Each Task.}
\label{appendix8}
Here we provide the AP and AF metric for each task of our method and two baselines (TGAT+BiC, TGN+BiC) which generally perform well among all baselines. As shown in Table \ref{each_reddit} \ref{each_yelp} \ref{each_taobao}, our method generally outperforms two baselines for most tasks. 

\begin{table}[H]
\centering
\vspace{-0.2in}
\caption{AP and AF for each task on the Reddit dataset.}
\label{each_reddit}
\begin{small}
 \setlength{\tabcolsep}{1.5mm}
 {
\begin{tabular}{@{}ccccccccccccc@{}}
\toprule
\multirow{2}{*}{Method} & \multicolumn{2}{c}{Task 1} & \multicolumn{2}{c}{Task 2} & \multicolumn{2}{c}{Task 3} & \multicolumn{2}{c}{Task 4} & \multicolumn{2}{c}{Task 5} & \multicolumn{2}{c}{Task 6} \\ \cmidrule(l){2-13} 
                        & AP           & AF          & AP           & AF          & AP           & AF          & AP           & AF          & AP           & AF          & AP            & AF        \\ \midrule
TGAT+BiC                & 50.52 & 23.96   & 47.18 & 23.59   & 42.31 & 21.15   & 63.03 & 26.86   & 46.18 & 31.53   & 78.46 & -            \\
TGN+BiC                 & 52.26 & 22.22   & 56.34 & 9.15   & 35.34 & 29.09   & 63.03 & 30.05   & 31.85 & 43.63   & 80.15 & -         \\
OTGNet                  & 61.02 & 15.80   & 71.83 & 20.25   & 39.30 & 45.43   & 83.38 & 13.16   & 91.72 & 1.59   & 95.97 & -        \\ \bottomrule
\end{tabular}%
}
\end{small}
\end{table}

\begin{table}[H]
\centering
\begin{small}
\vspace{-0.2in}
\caption{AP and AF for each task on the Yelp dataset.}
\label{each_yelp}
 \setlength{\tabcolsep}{2mm}{%
\begin{tabular}{@{}ccccccccccc@{}}
\toprule
\multirow{2}{*}{Method} & \multicolumn{2}{c}{Task 1} & \multicolumn{2}{c}{Task 2} & \multicolumn{2}{c}{Task 3} & \multicolumn{2}{c}{Task 4} & \multicolumn{2}{c}{Task 5} \\ \cmidrule(l){2-11} 
                        & AP           & AF          & AP           & AF          & AP           & AF          & AP           & AF          & AP            & AF         \\ \midrule
TGAT+BiC                & 71.61 & 9.76   & 78.89 & 9.63   & 73.68 & 21.84   & 62.23 & 24.46   & 87.25 & -             \\
TGN+BiC                 & 55.50 & 23.07   & 79.63 & 7.04   & 74.47 & 22.63   & 72.83 & 14.40   & 87.45 & -         \\
OTGNet                  & 76.38 & 0.26   & 88.89 & 0.74   & 83.95 & 10.79   & 79.62 & 8.15   & 90.08 & -         \\ \bottomrule
\end{tabular}%
}
\end{small}
\end{table}

\begin{table}[H]
\centering
\begin{small}
\vspace{-0.2in}
\caption{AP and AF for each task on the Taobao dataset.}
\label{each_taobao}
 \setlength{\tabcolsep}{3mm}{%
\begin{tabular}{@{}ccccccc@{}}
\toprule
\multirow{2}{*}{Method} & \multicolumn{2}{c}{Task 1} & \multicolumn{2}{c}{Task 2} & \multicolumn{2}{c}{Task 3} \\ \cmidrule(l){2-7} 
                        & AP           & AF          & AP           & AF          & AP            & AF         \\ \midrule
TGAT+BiC               & 68.82 & 22.69   & 63.16 & 23.86   & 90.15 & -            \\
TGN+BiC                 & 74.23 & 17.62   & 67.96 & 19.65   & 90.00 & -          \\
OTGNet                  & 77.62 & 12.86   & 72.81 & 12.80   & 89.35 & -        \\ \bottomrule
\end{tabular}%
}
\end{small}
\end{table}


\begin{table}[H]
\centering
\begin{small}
\caption{Running time (hours) comparison with baselines.}
\label{run_time}
 \setlength{\tabcolsep}{1.5mm}{%
\begin{tabular}{@{}cccccccccc@{}}
 \toprule
\multirow{2}{*}{Method} & \multicolumn{3}{c}{Reddit} & \multicolumn{3}{c}{Yelp} & \multicolumn{3}{c}{Taobao} \\ \cmidrule(l){2-10} 
                        & AP     & AF     & Time (h) & AP    & AF    & Time (h) & AP     & AF     & Time (h) \\ \midrule
TGAT+BiC                & 54.61  & 25.42  & 5.05     & 74.73 & 16.42 & 3.03     & 74.05  & 23.27  & 5.82     \\
TGN+BiC                 & 53.16  & 26.83  & 5.81     & 73.98 & 16.79 & 3.17     & 77.40  & 18.63  & 6.23     \\
TGAT-retrain            & 75.86  & 3.71   & 26.31    & 87.64 & 0.61  & 10.07    & 83.35  & 0.78   & 32.75    \\
TGN-retrain             & 77.41  & 3.34   & 31.58    & 80.83 & 3.47 & 10.80    & 81.63  & 3.64   & 35.65    \\
OTGNet                  & 73.88  & 19.25  & 6.78     & 83.78 & 4.98  & 3.73     & 79.92  & 12.82   & 7.81    \\ \bottomrule
\end{tabular}%
}
\end{small}
\end{table}

\subsection{Running Time Analysis}
\label{appendix9}
When new classes occur, if we combine all data of old classes with the data of new classes for retraining, the computational complexities will be sharply increased, and be not affordable.  Here, we compare the running time of our method with the retraining methods (TGAT-retrain, TGN-retrain) and two baselines (TGAT+BiC, TGN+BiC) which generally perform well among baseline methods. For the retraining methods, we use all data of old tasks for training when learning new tasks.

As shown in in Table \ref{run_time}, the running time of our method is comparable to the two incremental learning baselines (TGAT+BiC, TGN+BiC), while our model outperforms them on AP and AF metric with a large margin. 
For the retraining methods (TGAT-retrain, TGN-retrain), we can see the running time is increased by several times. In real-world applications, new classes might frequently occur. If we use all history data for training once a new class occurs, the time consuming could be unaffordable. 
Note that their Average Forgetting (AF) are better than our model. This is because they use all training data for learning each time, and thus can avoid forgetting.









\subsection{Limitations and Future Works}
\label{appendix10}
The quadratic time complexity of triad selection is a limitation of our method. Although only considering partial triads could be efficient, the performance of our model would be degraded to some extent. How to develop a more efficient and effective algorithm for representative triad selection is our future work. For example, we could design a hierarchical selection policy to reduce the time complexity, or develop a divide-and-conquer method for efficient triad selection. Whats more, we can design better practical approximations to the theoretical optimal solution of our value function to select representative triads. 


\subsection{Visualizations}
\label{appendix11}

\begin{figure}[H]
\centering
\subfigure[OTGNet-w.o.-IB]{
\begin{minipage}[t]{0.49\linewidth}
\centering
\includegraphics[width=2in]{figure/task1_no_IB.pdf}
\end{minipage}%
}%
\subfigure[OTGNet]{
\begin{minipage}[t]{0.49\linewidth}
\centering
\includegraphics[width=2in]{figure/task1_IB.pdf}
\end{minipage}
}%
\centering
\caption{t-SNE visualization of learned node embeddings on Reddit when task 1 is finished. Different colors denote different classes.}
\label{vis_IB}
\end{figure}

\begin{figure}[H]
\centering
\vspace{-0.2in}
\subfigure[OTGNet-w.o.-IB]{
\begin{minipage}[t]{0.49\linewidth}
\centering
\includegraphics[width=2in]{figure/task2_no_IB.pdf}
\end{minipage}%
}%
\subfigure[OTGNet]{
\begin{minipage}[t]{0.49\linewidth}
\centering
\includegraphics[width=2in]{figure/task2_IB.pdf}
\end{minipage}
}%
\centering
\caption{t-SNE visualization of learned node embeddings on Reddit after a new task is added. Different colors denote different classes. The new task contains 3 new classes.}
\label{vis_no_IB}
\end{figure}

To qualitatively demonstrate the effectiveness of our class-agnostic representations, we adopt t-SNE \citep{van2008visualizing} to visualize the learned node embeddings of our OTGNet. For comparison, we also visualize the node embeddings of OTGNet-w.o.-IB (i.e., OTGNet directly transferring the embeddings of neighbor nodes instead of class-agnostic representations).
Figure \ref{vis_IB} shows the results of their learned node embeddings on Reddit when task 1 is finished, and Figure \ref{vis_no_IB} demonstrates the results after a new task is added.  
We can clearly observe that OTGNet possesses better representation ability by considering class-agnostic representations.


\end{document}
