
We analyzed how the number of categories, number of points, and color palettes used to distinguish various categories impact people's abilities to reason with multiclass scatterplots.
We performed a crowdsourced study measuring how well people were able to compare category means over varying category numbers and color palette designs. This study allowed us to characterize the effect of category number in multiclass scatterplots as well as how robust different color palette designs are across varying numbers of categories. 
%through the relative mean judgments task with the fine-tuned parameters from pilot studies.
%The overall goal of the formal study is to assess the potential cues of each visual encoding to mean judgments and at which level each visual factor would lead to bias in human perception.
We hypothesized that:

\begin{itemize}
\item[\textbf{H1:}] \textbf{Performance will decrease as the number of categories increases.}
%The number of categories would significantly impact the precision of mean judgment.}

As visual information becomes more complex, perception and cognition degrades~\cite{liberman1957discrimination, regier2009language}. Haroz \& Whitney~\cite{haroz2012capacity} found that these findings generalized to categorical visualizations: increasing the number of categories degrades visual search performance. However, Gleicher et al.'s findings contradicted this observation, instead finding no performance difference between two or three category visualizations~\cite{gleicher2013perception}.  
%Since the rising number of categories can make a scatterplot more complex, we expected that these findings would be consistent in multiclass scatterplots.
We expect that for larger numbers of categories, this robustness will likely falter, even with designer-crafted palettes. \add{Existing heuristics recommend that visualizations should not use more than seven colors for reliable data interpretation \cite{munzner2014visualization}. This guidance suggests that we should see drastic performance reductions for seven or more categories.}

\item[\textbf{H2:}] \textbf{The choices of the color palette will affect people's abilities to effectively compare means.}

Perceptual studies demonstrate that color is a strong cue in both visualization~\cite{szafir2018modeling} and categorical perception~\cite{goldstone1995effects}. Past work has shown that, even in unitless data, the choice of color palettes can affect visualization interpretation~\cite{gramazio2016colorgorical,healey1996choosing}. We likewise anticipate that color palette design may differently support varying numbers of categories: some palettes may more robustly distinguish a range of classes than others, especially as the complexity of the palette increases with larger numbers of colors. 
%\add{While we anticipate that palettes maximizing the perceptual distances between colors will perform best, current design recommendations \cite{munzner2014visualization,stone2006choosing} suggest palettes should maximize categorical features of the colors (e.g., hue or name uniqueness \cite{heer2012color}) while minimizing lightness variation, which can bias attention. We anticipate that palettes following these practices will support higher performance. }
%Hence we agreed that the choice of color palettes would impact the judgment accuracy of multiclass scatterplots and expected users would achieve better accuracy rates with more discriminable palettes.
%The discriminability can be measured by some of our above color metrics (see \autoref{sec:metrics}).

%\item[\textbf{H3:}] \textbf{There would be an interaction effect\footnote{A variable that has an interaction effect will have a different effect on dependent variables, depending on the level of a third variable.} among the number of categories, hardness level, and the discriminability of the color palette.}

%Previous study~\cite{smart2019measuring} found that there are interaction effects across various visual encoding factors in scatterplots.
%Hence we expected there would exist interaction effects of our independent variables in multiclass scatterplots.

\end{itemize}
%Gleicher et al.~\cite{gleicher2013perception} shows that there are solid cues for both $\Delta$ value and color palette to impact the accuracy of human perception.
%Haroz and Whitney~\cite{haroz2012capacity} found that there exist capacity limits when drawing different numbers of categories in visualization design.

The anonymized data, results, and infrastructure 
for our study can be found on \href{https://osf.io/wz8eb/?view_only=03db060f94ee42f29f453ed3013e3405}{OSF.}\footnote{https://osf.io/wz8eb/?view\_only=03db060f94ee42f29f453ed3013e3405}

\subsection{Task}


%Among them, the relative mean judgment task, which is required to estimate the mean position of classes and compare its value in scatterplots, is commonly employed in perceptual experiments to evaluate the differences across multiple classes of points~\cite{sarikaya2018scatterplots}.
%For example, Gleicher et al.~\cite{gleicher2013perception} performed this task to evaluate perception accuracy for basic multiclass scatterplots.
%Karmer et al.~\cite{kramer2017visual} found by comparing the mean and variances of variables over time, people can capture trend information within data.
%Hong et al.~\cite{hong2021weighted} introduced perceptual biases in judging mean positions in scatterplots with varying colors and sizes of points.
%For multiclass scatterplots, the mean judgment task requires  making accurate judgments of mean localization and mean comparison, thus it combines the ability of both value retrieval and sort tasks, and enables to assess of the visual aggregation from human perception~\cite{gleicher2013perception, sarikaya2018scatterplots}.
%As a consequence, we perform the mean judgment task to assess human perception in multiclass scatterplots.

Scatterplots have been studied across a range of tasks (see Sarikaya \& Gleicher~\cite{sarikaya2018scatterplots} for a survey). We employed a relative mean judgment task as applied in previous studies~\cite{gleicher2013perception,hong2021weighted,kramer2017visual}. As in Gleicher et al.~\cite{gleicher2013perception}, we asked participants to estimate the category with the highest average y-value. We used this task as it required participants to first find data points of different categories and then estimate statistical values 
%estimated 
over all points in that category. This task is sensitive to both overinclusion (i.e., including points that are not in a given class) and underinclusion (i.e., failing to include points in a given category), meaning that confusion between points of different categories should be reflected in participants' responses. It also represents a basic statistical quantity that most lay participants 
%would be able to complete. 
are able to compute.
%predict accurate judgments of mean localization and comparison among classes, thus it combines the ability of both value retrieval and sort tasks~\cite{amar2005low}, and enables us to assess the efficiency of visual aggregation in perception~\cite{gleicher2013perception}.
%For specific, in each of our questions, participants are required to select a class of points with the highest average y-value of all the others among the whole multiclass scatterplot.
%\autoref{fig:amt-engagement} illustrates 3 examples of our questions based on the mean judgment task.

\begin{figure*}[htbp] 
\vspace{-1em}
\centering
\includegraphics[width=0.7\textwidth]{Figure/color_palettes.pdf} 
\vspace{-1em}
\caption{The 10 color palettes used in our experiment.} 
\label{fig:palettes}
\end{figure*}


\begin{figure*}[htbp] 
\centering
\includegraphics[width=0.8\textwidth]{Figure/engagement.pdf} 
\caption{Three engagement checks with D3 color palettes. Participants were required to pass two out of these three tasks to be considered as an approved response. All engagement checks were placed in random order with other formal trials.} 
\label{fig:amt-engagement}
\end{figure*}

%\subsection{Metrics}
%\label{sec:metrics}


%\subsection{Hypotheses}

\subsection{Stimuli Generation}
\label{sec-stimuli-generation}

\begin{table*}[htbp] 
\centering
\caption{The experiment parameters. We refined the factors and domain range in three pilot studies. Category number and color palettes are our independent variables, and hardness level and point number are the control variables. The experiments were built from the combination of these four factors.
} 
\includegraphics[width=0.9\textwidth]{Figure/factor-table-clean.pdf} 
\label{tab:parameters}
\end{table*}

Participants estimated means for a series of scatterplots. We generated each scatterplot as a 400x400 pixel graph using D3~\cite{6064996}. Each scatterplot was rendered to white background and two orthogonal black axes with 13 unlabeled ticks. For every point, we 
%chose a fixed size that is 3 pixels in radius among all the tasks.
rendered a filled circle mark with a three pixel radius.
\add{We selected three pixel points based on internal piloting to ensure that points were distinguishable between classes while also minimizing the need to address overdraw and reflecting design parameters commonly seen in real-world visualizations. }
%We used Gaussian distribution to generate our set of points for the experiments. 

%We then introduce several metrics employed in our studies to measure multiclass scatterplots.

%\subsubsection{Hardness Level ($\Delta$).}

As shown in \autoref{fig:palettes}, we selected 10 qualitative color palettes: ColorBrewer/Paired~\cite{harrower2003colorbrewer}, ColorBrewer/Set3~\cite{harrower2003colorbrewer}, D3/Category10~\cite{6064996}, Tableau/Tab10~\cite{tableau}, Paul Tol/Muted~\cite{tol2012colour}, SFSO/Parties~\cite{sfso}, \newline  Stata/S1~\cite{statagraphics19}, Stata/S2~\cite{statagraphics19}, Carto/Bold~\cite{carto} and Carto/Patel~\cite{carto}. These color palettes were chosen from popular visualization tools that provide 
%over 
at least 10 categorical colors in a single palette. If there were more than 10 colors in a certain palette, we used the first 
%ten as our colors. 
10 as the palette's colors.
In each scatterplot, colors were randomly selected from the target palette and 
%rendered
mapped to corresponding categories. While some tools prescribe a fixed order to the selection of colors from a palette, this is not a universal design practice. 
%Therefore, we minimized potential effects from variations in this practice by randomization. 
%\add{We used a random subset to avoid the original palettes' sequential impact (i.e., a palette might be optimized for its unique subjective sequence). 
\add{Randomization helps avoids potential bias from differences beyond color selection as not all palettes may have been intentionally ordered, but future work should investigate differences in the ordered application of palettes.}
%However, some tools encoded colors in a fixed order for multiclass scatterplots, but we managed colors as random factors in our analysis.


We tuned our dataset parameters in a series of three extensive pilot studies, measuring performance for varying numbers of categories, points, and hardness levels (see Appendix for details). As in Gleicher et al.~\cite{gleicher2013perception}, we controlled task hardness using the distance between classes. The hardness level is denoted by $\Delta$ and is calculated by the 
%numerical 
distance between y-means of classes in multiclass scatterplots. 
To generate 
%the x-y 
positional data with the given mean and covariance, we used a function from Numpy~\cite{oliphant2006guide} that randomly samples from a multivariate normal distribution. We denoted our data points as \begin{math} \{ x,y \in \mathbb{R} \, | \, 0<x,y<10 \} \end{math}. First, we randomly sample the mean \begin{math} \mu{_1} \end{math} in the range [5, 9] for the category that possesses the highest mean, then set the mean \begin{math} \mu{_2} = \mu{_1} - \Delta\end{math} as the second highest mean based on y-values. To prevent subsequent means from drifting too far apart and artificially simplifying the task, we constrained the mean \begin{math} \mu_i \end{math} of the rest of the categories to \begin{math} \Delta < \mu{_1} - \mu_i < 1.5\Delta \end{math}. Finally, we determined the covariance for each category that has y-mean \begin{math} \mu_i \end{math} with \begin{math} cov(\lambda_i,  \lambda_i) \end{math} where \begin{math}\lambda_i=random(1, min(\mu_i, 10-\mu_i))\end{math}. We used this variance to tune the datasets such that selecting the category with the highest point did not reliably produce the correct answer, with variance tuned in piloting.  

Each scatterplot contained between 10 and 20 points per category. 
To prevent overlapping points, we applied jittering methods which add random noise to any data points that would otherwise overlap each other.
We generated 450 datasets in total.
%\add{Please see \autoref{tab:parameters} in Appendix for detailed numbers of scatterplots per color palettes and categories.}

\begin{figure*}[htbp] 
\centering
\includegraphics[width=0.8\textwidth]{Figure/hardness-stimuli.pdf} 
\caption{Instances with varying hardness level ($\Delta$) values employed in our study. The difficulty level of instances varies from easy to hard from left to right, with four categories.} 
\label{fig:delta-stimuli}
\end{figure*}


%and dividing them into 10 sets. Each set contains 45 tasks, including 3 engagement checks and 42 formal trials. 

\begin{figure*}[htbp] 
\centering
\includegraphics[width=0.8\textwidth]{Figure/catnum-stimuli.pdf}
\caption{Instances with varying numbers of categories employed in our study. Their numbers of categories are 3, 6, and 9 respectively from left to right, with the same hardness level (intermediate).} 
\label{fig:num-stimuli}
\end{figure*}

\subsection{Procedure}
Our experiment consisted of three phases: (1) informed consent and color-blindness screening, (2) task description and tutorial, and (3) formal study.
At the beginning of the study, participants were provided with informed consent in accordance with our IRB protocol. They were then asked to complete an Ishihara test for color-blindness screening~\cite{hardy1945tests}. 
%, in which we selected 6 tests that participants were required to pass all to continue the study. 
After completing the screening successfully, participants were led to a description page for the mean judgment task. They were required to successfully complete an easy tutorial question to minimize possible ambiguities in their understanding of the task.

During our formal study, each participant completed our target task (\textit{Identify the class with the highest average y-value}) for 45 stimuli presented sequentially using a single color palette (42 formal trials and three engagement checks). We used stratified random sampling to balance number of categories and difficulty levels that each participant saw. 
To ensure participants saw a range of category numbers, we grouped category numbers into three classes: small, medium, and large, which corresponded to 2-4, 5-7, and 8-10 categories, as shown in \autoref{fig:num-stimuli}. 
%We used these grouping to perform a stratified sampling of category numbers for each participant, with each participant seeing 14 tasks within each category group. 
We also grouped stimuli into three difficulty levels: easy, intermediate, and hard, as shown in \autoref{fig:delta-stimuli}. Each person saw 14 stimuli from each category and difficulty group, with combinations of category and difficulty assigned at random. 
%Our datasets included all combinations of category numbers and difficulty levels. The point number 
%The number of points was uniformly distributed over a range from 10 to 20 per category. Each participant saw 45 tasks from one set, which was randomly assigned from pre-generated 10 sets when they started the study. There was only one color palette being used for each participant over the entire experiment, which was also randomly assigned at the beginning of the study. All the tasks were presented in random order.

We randomly placed three engagement checks within 42 formal trials to assess if participants were inattentive during the test.
These engagement checks presented three classes with large differences in their means (c.f., Figure~\ref{fig:amt-engagement}). 
%Figure~\ref{fig:amt-engagement} illustrated examples of these questions. 
%i.e., the engagement tasks employed in our study.
We randomly ordered the sequence of the formal questions and the engagement checks to avoid learning or fatigue effects.
%After completing all the formal tests, each participant was required to report their demographics and received \$3.00 compensation.



\subsection{Participants}
We recruited 95 participants from the US and Canada with at least a 95\% approval rating on Amazon Mechanical Turk (MTurk). We excluded four participants who failed more than one engagement check. We analyzed data from the remaining 91 participants (46 male, 45 female; 24--65 years of age).
%The ages of our participants were between 24 and 65, on average at 45.3 with a standard deviation of 10.7. 
All participants reported normal or corrected to normal vision. 
%or wearing corrected glasses.
Our experiment took about 15 minutes on average, and each of the participants was compensated \$3.00 for their time.

\subsection{Analysis}

%The overall goal of our analysis is to validate our hypotheses and some findings from previous studies and capture the differences among different visual encodings that impact human judgment.

%During our main study, we calculated the accuracy rate for each participant and the corresponding time spent on each question, and combined these results with different combinations of our employed independent visual factors.
We measured performance as both accuracy and time spent on task.
%For each of our independent variables, we conduct the analysis of variance (ANOVA) independently to test for variations in the impact of judgment accuracy of different visual encodings.
We analyzed the resulting data using a 10 (color palette) x 9 (number of categories) mixed-factors ANCOVA, with the number of points, interparticipant variation, trial order, and hardness levels as random covariates. 
%Besides, we analyzed the interaction effects across different combinations of independent variables through the analysis of covariance (ANCOVA). First, We treated delta values as random effects, which that showed the number of points has a small effect on performance. As a result, we conducted ANCOVA with trial order, delta values, and number of points as random effects, and number of category and color palettes as covariates.
During our post-hoc analysis, we employed the Tukey's honestly significant difference test (Tukey's HSD) with $\alpha$ = 0.05 and Bonferroni correction. 

% \fix{Detailed factors for ANOVA and ANCOVA analysis, such as how to combine factors, use which random effect, finally computed a ?-level (2, 3, 4, ...) ANCOVA}