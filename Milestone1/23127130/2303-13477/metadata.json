{
    "arxiv_id": "2303.13477",
    "paper_title": "TransPoser: Transformer as an Optimizer for Joint Object Shape and Pose Estimation",
    "authors": [
        "Yuta Yoshitake",
        "Mai Nishimura",
        "Shohei Nobuhara",
        "Ko Nishino"
    ],
    "submission_date": "2023-03-23",
    "revised_dates": [
        "2023-03-24"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV"
    ],
    "abstract": "We propose a novel method for joint estimation of shape and pose of rigid objects from their sequentially observed RGB-D images. In sharp contrast to past approaches that rely on complex non-linear optimization, we propose to formulate it as a neural optimization that learns to efficiently estimate the shape and pose. We introduce Deep Directional Distance Function (DeepDDF), a neural network that directly outputs the depth image of an object given the camera viewpoint and viewing direction, for efficient error computation in 2D image space. We formulate the joint estimation itself as a Transformer which we refer to as TransPoser. We fully leverage the tokenization and multi-head attention to sequentially process the growing set of observations and to efficiently update the shape and pose with a learned momentum, respectively. Experimental results on synthetic and real data show that DeepDDF achieves high accuracy as a category-level object shape representation and TransPoser achieves state-of-the-art accuracy efficiently for joint shape and pose estimation.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.13477v1"
    ],
    "publication_venue": null
}