\section{Methodology}
\label{sec:method}
In keeping with the daily routine of daily life, blockchain networks are frequently examined on a daily basis~\cite{casale2021networks,chen2020understanding}. We divide a blockchain network into daily intervals, using a reference time zone to create a set of snapshot graphs. In a snapshot graph of a blockchain network, a node represents a trader/investor, whereas an edge denotes a financial transaction. Next, we define {\sf InnerCore}, {\sf InnerCore} expand, and {\sf InnerCore} decay on the snapshot graphs. 

We use in-degree, out-degree, in-strength, and out-strength as node properties (defined in Table \ref{tab:node_property_functions}) to compute the {\sf AlphaCore}  decomposition of a snapshot graph, as these node features can be defined easily for a weighted, directed, multi-graph. 
Core decomposition helps us eliminate unimportant edges and nodes (e.g.,  addresses trading small amounts). Using the results of the core decomposition, we then identify an {\sf InnerCore} of nodes, which helps us pinpoint the most influential nodes. 

\begin{table}
\fontsize{9}{12}\selectfont
\centering
\footnotesize
\caption{Example node property functions.}
\label{tab:node_property_functions}
\begin{tabular}{ll}
%\toprule
Function & Definition\\
\midrule
$N(v)$ & neighbors of $v$ \\
$N_{out}(v)$ & neighbors reachable with outgoing edges from $v$ \\
$N_{in}(v)$ & neighbors reachable with incoming edges to $v$ \\
$deg(v)$ & edges to/from $v$ (Degree) \\
$deg_{out}(v)$ & outgoing edges from $v$ (Out-Degree) \\
$deg_{in}(v)$ & incoming edges to $v$ (In-Degree) \\
$S(v)$ & sum of edge weights incident to a node (Strength)\\
$S_{out}(v)$ & sum of outgoing edge weights (Out-Strength)\\
$S_{in}(v)$ & sum of incoming edge weights (In-Strength)\\
%\bottomrule
\end{tabular}
\end{table}
%
\subsection{InnerCore of a Graph}
\label{sec:methinnercore}
 %
 The data depth of a node $v \in V$ is defined as the degree of "outlyingness" of the node property function in relation to the origin $\mathbf{0}$. We define the {\sf InnerCore} of $G$ as the set of nodes $\V^{inner}$ whose data depth, relative to themselves, is less than an $\epsilon$ value. We set $\epsilon$ to a small value, and iteratively recompute the depth of each node as we remove nodes whose data depth is greater than $\epsilon$ in each iteration. This process continues until no more nodes can be removed. The resulting set of nodes is the {\sf InnerCore} of the graph. The {\sf InnerCore} computation is illustrated in Algorithm~\ref{alg:innercore}.%
\SetKwInput{KwInput}{Input}
\SetKwInput{KwOutput}{Output}
\SetKwRepeat{Do}{do}{while}
%
\begin{algorithm}[tb!]
\footnotesize
\KwInput{Directed, weighted, multigraph $G(V,E,w)$,\\
Set of node property functions $p_1, ..., p_n \in P$,\\%,
Data depth threshold $\epsilon$}
\KwOutput{innerCore $V^{inner}$}
\tcp{Compute feature matrix}
$F = [f_1, ..., f_n] = \forall p_i \in P: f_i = p_i(v, G), \forall v \in V$\label{alg:line1}\;% \tcp*{initial feature matrix}
$\Sigma_F^{-1}$ = cov$(F)^{-1}$\tcp*{compute only once}\label{alg:line2}
\tcp{Compute initial depth values}
$z = [z_1, ..., z_n] = \forall v_i \in V: z_i = [1+(F_{i,*})'\Sigma^{-1}_F(F_{i,*})]^{-1}$\label{alg:line3}\;
  \Do{$\exists z_i: (z_i \geq \epsilon) \wedge (v_i \in V)$ \tcp{one iteration}}{
    \ForEach{$z_i \geq \epsilon$}{
    $\V = \V \setminus \{v_i\}$\label{alg:line14}\;
    }
    \tcp{recompute node properties}
    $F = \forall p_i \in P: p_i(v, G), \forall v \in V$\label{alg:line16}\;
    \tcp{recompute depth}
    $z_i = [1+(F_{i,*})'\Sigma^{-1}_F(F_{i,*})]^{-1}, \forall v_i \in V$\label{alg:line17}\;
  }
\KwRet{$\V$ \tcp{as innerCore $V^{inner}$}}\label{alg:line21}
\caption{{\sf InnerCore} Discovery}
\label{alg:innercore}
\end{algorithm}

Algorithm~\ref{alg:innercore} computes a feature matrix based on each node property function in line~\ref{alg:line1}. For instance, this could include a node's neighborhood size as listed in Table~\ref{tab:node_property_functions}. The feature matrix $F$ is used to compute the inverse covariance matrix $\Sigma_F$ in line~\ref{alg:line2}, which will be utilized for future data depth calculations. The initial depth of each node is determined using the Mahalanobis depth with respect to the origin at line~\ref{alg:line3}. Nodes with depth greater than or equal to input $\epsilon$ are removed from the node set $\V$ at line~\ref{alg:line14}. Once one batch of node removals has been performed, the feature matrix and depth values are re-evaluated in lines~\ref{alg:line16}--\ref{alg:line17}. If any remaining nodes still have a depth greater than or equal to $\epsilon$, the next batch is initiated at the same $\epsilon$ level. When there are no nodes left with depth larger than $\epsilon$, the algorithm is considered complete, and the remaining nodes in $\V$ are returned as the {\sf InnerCore}.

\medskip
\noindent\textbf{Scalability}. Computing the {\sf InnerCore} requires performing Cholesky decomposition on the covariance matrix at line~\ref{alg:line2} once, which has time complexity $O(d^3)$ for $d$ features. Node features need to be recomputed at each iteration of the while loop with a cost of $O(|\V|\times deg)$, where $deg$ is the average degree in the graph. There are at most $|\V|$ iterations (number of nodes). In the worst case, the total time complexity is $O(d^3 + |\V|\times deg \times |\V|)$. However, since the neighborhood of a node can be sparse, the value of $deg$ is small. Moreover, since multiple nodes are removed in batches, the number of iterations is much smaller than $|\V|$. For example, in a network with approximately 480,000 nodes and 1 million edges (\S 4), only 4 iterations on average are needed for an $\epsilon$ of 0.1.

\medskip\noindent\textbf{InnerCore vs. Alphacore.} {\sf InnerCore} discovery of a graph $G$ does not require a complete decomposition of all graph cores by varying $\epsilon$, as it is done in {\sf AlphaCore}~\cite{victor2021alphacore}. Instead, we set an $\epsilon$ value (e.g., $\epsilon=0.1$) just once, and then use the value to iteratively prune nodes until all remaining nodes, relative to themselves, satisfy a data depth less than $\epsilon$. The  {\sf InnerCore} approach is also different from graph-$k$-core decomposition~\cite{BatageljZ11}, where the outer cores are computed first before the higher $k$-core can be determined. As a result, {\sf InnerCore} discovery is quite scalable and can be applied to very large graphs. Our experiments in \S\ref{sec:exp} reveal that {\sf InnerCore} discovery has a running time that is only one-tenth of that required for {\sf AlphaCore} decomposition.

\subsection{InnerCore Expansion and Decay}
\label{sec:methdecayexpansion}
By analyzing how a temporal graph expands and shrinks in relation to the entry and exit of nodes on a daily basis, we can gain valuable insights into market sentiment. Specifically, we investigate how the {\sf InnerCore} of a network expands and decays on a given day compared to previous days. We define two measures to quantify the activity of influential nodes in the network: expansion and decay. {\em Expansion} measures the ratio of influential nodes on day $t$ that were also influential in the preceding $i$ days, while {\em decay} quantifies the ratio of influential nodes from the previous $i$ days that are not present in the influential nodes of day $t$. We define the influential nodes of a graph as its {\sf InnerCore} nodes (i.e., $\V_t^{inner}$).

To this end, we first discover $\V_t^{inner}$ as the set of nodes in the {\sf InnerCore} of the snapshot graph at timestamp $t$, and define $\V_{\cup(t-i)}^{inner}=\bigcup_i\V_{t-i}^{inner}$ as the union set of nodes in the {\sf InnerCore} of snapshot graphs from timestamps $\{t-1,t-2,\ldots, t-i\}$ for $i\geq 1$. Next, we define the expansion and decay measures at timestamp $t$ as follows:
%
 \begin{definition}[Expansion]
$\mathbb{E}_t=\left|\V^{inner}_t \setminus \V^{inner}_{\cup(t-i)}\right| / \left | \V^{inner}_{\cup(t-i)}\right|.$
 \end{definition}

The expansion values have a range $[0,\infty)$, where a value greater than 1 indicates a  growth in the size of {\sf InnerCore}. 
\begin{definition}[Decay]
$\mathbb{D}_t=\left|\V^{inner}_{\cup(t-i)} \setminus \V^{inner}_{t}\right| / \left | \V^{inner}_{\cup(t-i)}\right|.$
\end{definition}
The decay values have a range $[0,1]$, where a value of 0 indicates that all {\sf InnerCore} members from $t$ are present at $t+1$ as well. 

\begin{exam} [Expansion and Decay]
Suppose we have a temporal graph that produces two daily snapshot graphs at days $t$ and $t+1$. On day $t$, the InnerCore is composed of five nodes: $\V^{inner}_t=\{v_1, v_2, v_3, v_4, v_5\}$. On day $t+1$, the InnerCore has expanded to include eight nodes: $\V^{inner}_{t+1}=\{v_3, v_4, v_5, v_6, v_7, v_8, v_9, v_{10}\}$.

If we set $i=1$, we can calculate the expansion and decay measures for day $t+1$ based on the previous day. In this case, the union of the InnerCores is $\V^{inner}_{\cup(t-i)}=\{v_1, v_2, v_3, v_4, v_5\}$. Therefore, we have:

The expansion measure $\mathbb{E}_{t+1}$ is equal to $\frac{\left|\{v_6, v_7, v_8, v_9, v_{10}\}\right|}{\left|\{v_1, v_2, v_3, v_4, v_5\}\right|}$, which yields a value of 1. The decay measure $\mathbb{D}_{t+1}$ is equal to $\frac{\left|\{v_1,v_2\}\right|}{\left|\{v_1, v_2, v_3, v_4, v_5\}\right|}$, which yields a value of 0.4.
\end{exam}
%
\subsection{Behavioral Patterns in Temporal Networks}
\label{sec:methpatterns}
%
Temporal networks, such as blockchain networks, are constantly evolving and may undergo significant changes in user sentiment and node activity due to technological updates and cataclysmic events in as little as a few days.

By utilizing expansion and decay, we have identified four behavioral patterns that capture user sentiment and node activity. These patterns serve as the foundation for network analysis in our experiments detailed in \S\ref{sec:exp}. Figure~\ref{fig:behavior} illustrates the expansion and decay values for each pattern. To gain a better understanding of these patterns, particularly when examining the temporal graph of a financial network such as the Ethereum transaction network, it is helpful to consider the network's underlying transaction semantics.
%
\begin{itemize}[leftmargin=.1in]
    \item The {\em Despair} pattern is characterized by a reduction in expansion and an increase in decay, implying that previously influential nodes are leaving the network, while the {\sf InnerCore} is shrinking due to a decrease in the number of new influential nodes.
    \item The {\em Uncertainty} pattern is distinguished by an increase in both expansion and decay. This is primarily due to the influx of many new investors into the network who do not remain active for a significant period of time.
    \item The {\em Hope} pattern is characterized by a reduction in decay and an increase in expansion, indicating the presence of many newcomers to the network who remain active within the network.
    \item The {\em Faith} pattern is identified by a decrease in both decay and expansion, which initially suggests a state of confusion. On the positive side, nodes, such as investors, may have faith in the network's ability to withstand a catastrophic event, as demonstrated in the LunaTerra case in our experimental results. On the negative side, it may indicate a sense of hopelessness as investors may hold onto their assets without engaging in transactions or exiting the system altogether.
\end{itemize}
%
\begin{figure}
    \centering \includegraphics[width=\linewidth]{figs/behavior.png}
    \caption{In a temporal graph (e.g., transaction network), changes in decay and expansion
    reflect varying levels of hope, despair, uncertainty, and faith in the asset being represented.
    }
    \label{fig:behavior}
\end{figure}
%
\subsection{Motif Analysis in Innercore}
\label{sec:methmotif}
% 
Our rationale behind using motif analysis in conjunction with {\sf InnerCore} is to accurately discover larger and potentially influential players in the daily network.  The structure of a motif defines a behavior of interest and its existence in a network indicates the presence of such behavior.  

\begin{figure}[!ht]
\centering
\begin{subfigure}{.15\textwidth}
  \centering 
  % include first image
\includegraphics[width=.95\linewidth]{figs/motif1.png}
  \label{fig:m4}
\end{subfigure}~
\begin{subfigure}{.15\textwidth}
  \centering 
\includegraphics[width=.95\linewidth]{figs/motif4.png}
  \label{fig:m5}
\end{subfigure}
\begin{subfigure}{.15\textwidth}
  \centering 
\includegraphics[width=.95\linewidth]{figs/motif5.png}
  \label{fig:m10}
\end{subfigure}
\begin{subfigure}{.15\textwidth}
  \centering 
\includegraphics[width=.95\linewidth]{figs/motif6.png}
  \label{fig:m12}
\end{subfigure}
\begin{subfigure}{.15\textwidth}
  \centering 
\includegraphics[width=.95\linewidth]{figs/motif11.png}
  \label{fig:m14}
\end{subfigure}
\caption{Five three-node motifs exhibiting buy and sell behaviors.  Nodes labeled C denote the center where a center with an in-degree = 2 indicates buy behavior and an out-degree = 2 indicates sell behavior. Out of the 16 connected three-node motifs (see Figure 1B in \cite{milo2002network}), only the five given above (motifs 1, 4, 5, 6, and 11) contain a center node. 
\label{fig:motifs}}
\end{figure}

Motif analysis has been a popular tool to identify subgraph patterns and the addresses involved in them \cite{LeeKGOL20,bailey2009meme,zhang2012extracting,paranjape2017motifs,milo2002network}. We have decided to use three-node motifs since they can be identified more quickly than higher-order motifs, while still capturing the direct buying or selling behavior between addresses.  Our decision is consistent with previous research on temporal motifs~\cite{paranjape2017motifs}.  

\medskip
\noindent\textbf{Scalability}. The fastest triangular motif discovery algorithm has time complexity $O(|\V^{inner}|^\omega)$, where $\omega < 2.376$ is the fast matrix product exponent~\cite{latapy2008main,coppersmith1987matrix}. The number of nodes in the {\sf InnerCore} is denoted by $|\V^{inner}|$. We demonstrate in \S\ref{sec:exp} that triangular motif discovery on {\sf InnerCore}s has low time costs because of the relatively small size of daily networks' {\sf InnerCore}s.

We define the center of each 3-node motif as a node that either receives incoming edges from the two other nodes (buy behavior) or delivers outgoing edges to two other nodes (sell behavior). This definition ensures that motif centers 
exhibit buy or sell behavior, 
and they do not act as intermediary nodes between the other two nodes in a motif.

Out of the 16 connected three-node motifs (see Figure 1B in \cite{milo2002network}), only five of them contain a center node (Figure~\ref{fig:motifs}).
We identify all instances of these five motifs and their centers from our daily networks' {\sf InnerCore}s. 
Finally, we utilize the well-known {\sf TF-IDF} measure from information retrieval~\cite{salton1988term} to rank the discovered center nodes. 


{\sf TF-IDF} is a statistical measure to reflect the relevance of a word in a collection of documents. In our setting, we treat each discovered center address as a word and daily instances of each motif as a collection of documents to propose a novel node relevance score for temporal graphs: {\sf NF-IAF}.   

Formally, let $M={m_1,m_4,m_{5},m_{6},m_{11}}$ be the set of five motifs of interest, and let $T={t_1,t_2,\dots,t_n}$ be the set of $n$ days under consideration. 
For each $m_i \in M$ and $t_j \in T$, let ${c(v,m_i,t_j)}$ denote the number of occurrences of node $v\in \V^{inner}$ in all instances of motif $m_i$ on day $t_j$.
For all $v\in \V^{inner}$, $m_i\in M$, and $t_j\in T$, we define the node frequency ({\sf NF}) and inverse-appearance frequency ({\sf IAF}) as follows:
%
\begin{definition}[Node Frequency]
We define the node frequency of node $v$ for motif $m_i$ on day $t_j$  as 
$$NF(v,m_i,t_j)=  \frac{c(v,m_i,t_j)}{\sum\limits_{v \in \V_j^{inner}}{c(v,m_i,t_j)}}.$$ % 
\end{definition}
%
The {\sf NF} measures how frequently a particular node occurs in a specific motif on a specific day relative to the total number occurrences of all nodes in that motif on that day. 
%
\begin{definition}[Inverse Appearance Frequency]
We define the inverse appearance frequency of node $v$ for motif $m_i$  as 
$$IAF(v,m_i) = \log\frac{|T|}{df(v,m_i)}$$
where $|T|$ is the total number of days in the dataset, and $df(v,m_i)$ is defined as the number of days $t_j\in T$ where $c(v,m_i,t_j)>0$.
\end{definition}
%
The {\sf IAF} measures the importance of a node by how frequently it appears across all days for a motif.  If a node appears in many days for a motif, its {\sf IAF} will be low, indicating that it is not very informative. On the other hand, if a node appears in only a few days for a motif, its {\sf IAF} will be high, indicating that it is a rare and potentially important node.
%
\begin{definition}[NF-IAF Score]
The {\sf NF-IAF} score of node $v$ for motif $m_i$ on day $t_j$ is given as 
$$NF{\text-}IAF(v,m_i,t_t) = NF(v,m_i,t_j) \times IAF(v,m_i).$$
\end{definition}
%
A greater {\sf NF-IAF} score of a center node on a particular day  
indicates greater relevance between that node and the behavior associated with the motif type.  Therefore, a node corresponding to a motif center on a particular day with a high {\sf NF-IAF} score has an increased likelihood that it has more influence on the network on that day, while a lower {\sf NF-IAF} score indicates the opposite.  
\input{sections/042_tfidfexample.tex}
 
  

 