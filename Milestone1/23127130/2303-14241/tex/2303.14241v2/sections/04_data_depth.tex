\section{Data Depth}
\label{sec:depth}
Depth functions have been initially introduced in the setting of non-parametric multivariate analysis to define affine invariant versions of median, quantiles, and ranks in higher dimensional spaces where there is no natural order  (see historical overviews by~\citet{mosler2012multivariate,Nieto-Reyes:Battey:2015}).  The key idea of the depth approach is to offer a center-outward ordering of all observations by assigning a numeric score in $(0,1]$ range to each data point with respect to its position within a cloud of multivariate or functional observations or a probability distribution. Nowadays, data depth is a rapidly developing field that gains increasing momentum due to the wide applicability of depth concepts to classification, visualization, high dimensional and functional data analysis~\citep{Hyndman:Shang:2010, Narisetty:Nair:2016, mozharovskyi2020nonparametric, sguera2020notion, zhang2021depth}.
Most recently, depth approaches have found novel applications in density-based clustering and space-time data mining~\citep{Jeong:etal:2016, HuangGel2017, vinue2020robust}, shape recognition and uncertainty quantification in computer graphics~\citep{Whitaker:etal:2013, sheharyar2019visual}, ordinal data analysis~\citep{Kleindessner:vonLuxburg:2017} and computational geometry for privacy-preserving data analysis~\citep{mahdikhani2020achieve}.
Nevertheless, data depth is yet a largely unexplored concept in network sciences~\citep{Fraiman:et:2015, raj2017path,Tian:Gel:2017, tian2019fusing}.


\begin{definition}[Data Depth] Formally, let $E$ be a Banach space (e.g., $E=\mathbb{R}^d$), $\mathcal B$ its Borel sets in $E$, and $\mathcal P$ be a set of probability distributions on $\mathcal B$. We view $\mathcal P$ as the class of empirical distributions giving equal probabilities $1/n$ to $n$ data points in $E$. Then, a data depth function is a function $\mathbb{D}: E\times \mathcal P \longrightarrow [0,1]$, $(x,P) \longrightarrow \mathbb{D}(x|P)$, $x\in E, P\in \mathcal P$ that satisfies the following desirable properties: \textit{affine invariant}, \textit{upper semi-continuous} in $x$,
\textit{quasiconcave} in $x$ (i.e., having convex upper level sets) and \textit{vanishing as} $||x||\to \infty$. Specifically, a data depth function $\mathbb{D}(x)$ measures how closely an observed point $x \in \mathbb{R}^d$, $d\geq 1$, is located to the center of a finite set $\mathcal{X}\in \mathbb{R}^d$, or relative to $F$, which is a probability distribution in $\mathbb{R}^d$. In complex network analysis, these points may correspond to nodes or edges having features.
\end{definition}


Among many depth functions formulated to date, the Mahalanobis depth is one of the most prominent in the current practice.

\begin{definition}[Mahalanobis (MhD) depth]
Let $x\in \mathbb{R}^d$ be an observed data point, then Mahalanobis (MhD) depth of $x$ with respect to a $d$-variate probability distribution $F$ having mean vector $\mu_F \in \mathbb{R}^d$ and covariance matrix $\Sigma_F \in \mathbb{R}^{d\times d}$ is given by
 \begin{equation}
MhD_{\mu_F}(x)=\bigl(1+(x-\mu_F)^\top\Sigma^{-1}_F(x-\mu_F)\bigr)^{-1}.
 \end{equation}
Here $^\top$ denotes matrix transpose. The MhD depth measures the \textit{outlyingness} of the point with respect to the deepest point of the distribution (here $\mu_F$), and allows to easily handle the elliptical family of distributions, including a Gaussian case.
\end{definition}
MhD offers flexibility in changing the reference point with respect to which we compute data rankings. For instance, instead of $\mu_F$ we can select an arbitrary point $x_0\in \mathbb{R}^d$ and compute MhD in respect to this new reference point $x_0$
\begin{equation}
\label{MhD_arb}
MhD_{x_0}(x)=\bigl(1+(x-x_0)^\top\Sigma^{-1}_F(x-x_0)\bigr)^{-1}.
 \end{equation}
Furthermore, $\Sigma_F$ can be substituted by any empirical estimator of covariance matrix $\hat{\Sigma}$ obtained from the observed data sample $x_1, x_2, \ldots, x_n$.
