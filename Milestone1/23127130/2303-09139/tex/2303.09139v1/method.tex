\section{$\text{GRVO}$ with Shifted Yield Areas}
Our method differs from prior works by applying an additional modulation to the desired velocity function $v_i^*$ and we denote this function as $\mathcal{M}(v^*)$. The modulated velocity can be plugged into $\text{GRVO}$ to derive our final local navigation algorithm:
\begin{align*}
u_i(t)\triangleq\text{GRVO}(\mathcal{M}(v_i^*),x_i(t)).
\end{align*}
Note that our method can also be combined with local navigation methods other than $\text{GRVO}$. Our modulation function aims at shifting the POI between the two agents to large open areas in $\mathcal{F}$. Being a decentralized algorithm, such modulation is highly challenging because an agent does not have the ability to acquire other agents' trajectories, nor to alter their motions. However, we find it suffices to only modulate the velocity of the agent being considered based on a rough estimation of other agents' trajectories, as long as the same modulation function $\mathcal{M}$ is deployed on all the agents. In the following sections, we present details about POI detection, shifting, and modulation.

\subsection{POI Detection}
\begin{figure}[h]
\centering
\includegraphics[width=1\linewidth]{figs/POI.pdf}
%position
\put(-225,65){$p(x_j)$}
\put(-25 ,5 ){$p(x_i)$}
%projected position
\put(-247,50){$s_j$}
\put(-3  ,30){$s_i$}
%agent velocity
\put(-215,45){$\dot{p}(x_j)$}
\put(-70 ,30){$\dot{p}(x_i)$}
%velocity
\put(-205,5 ){$-\dot{P}_{ij}(1)$}
\put(-75 ,60){$\dot{P}_{ij}(0)$}
%POI
\put(-150,20){POI}
\caption{\label{fig:POI} \small{We illustrate the procedure of estimating the POI between $x_i$ (blue) and $x_j$ (green). Two points are first projected to the closest skeletal nodes $s_i$ and $s_j$, respectively. The shortened path $P_{ij}$ is illustrated with red nodes and dashed lines. If the difference between $\dot{p}(x_i)$, $\dot{p}(x_j)$ and tangents of $P_{ij}$ are smaller than a user-defined $\epsilon$ (gray cones) path, then we assume a POI exists. The POI is the point where two agents meet along $P_{ij}$. In this figure, since $x_j$ is slower (shorter green arrow), the POI is closer to $x_j$.}}
\vspace*{-10px}
\end{figure}
We define for each agent $x_i$ a sensing radius $R_i$. When any other agent $x_j$ satisfies $\|p(x_i)-p(x_j)\|\leq R_i$, we assume a potential yielding behavior might happen between them. Since $x_i$ does not know $x_j$'s future trajectory, we need to estimate POI based on the following assumption. We first project $p(x_i), p(x_j)$ onto their closest points on $G$, which  are denoted as $s_i$ and $s_j$, respectively. We then compute a shorted path between $s_i$ and $s_j$ on $G$ via Dijkstra's algorithm. In practice, we precompute the all-pair shortest distances so any shortened path can be looked up instantaneously. This path is denoted as $P_{ij}(\alpha)$, where $\alpha\in[0,1]$, $P_{ij}(0)=s_i$, and $P_{ij}(1)=s_j$. If both $x_i$ and $x_j$ are moving along the opposite tangential directions of $P_{ij}$, then we assume $P_{ij}$ is the estimated path containing a POI of the two agents. We determine that the two agents are traveling along opposite tangential directions if the following conditions hold:
\small
\begin{align}
\label{eq:meeting}
&\frac{\dot{P}_{ij}(0)}{\|\dot{P}_{ij}(0)\|}^T\frac{\dot{p}(x_i)}{\|\dot{p}(x_i)\|}>1-\epsilon \quad
-\frac{\dot{P}_{ij}(1)}{\|\dot{P}_{ij}(1)\|}^T\frac{\dot{p}(x_j)}{\|\dot{p}(x_j)\|}>1-\epsilon,
\end{align}
\normalsize
and no POI would be considered otherwise. Here $\epsilon$ is a user-defined upper bound of velocity bias. For a decentralized algorithm, our agent $x_i$ does not know the velocity of $x_j$ either, so we estimate $\dot{p}(x_j)$ using a finite difference of two consecutive frames of $x_j$. The POI between $x_i$ and $x_j$ is then estimated as $P_{ij}(\alpha_\text{POI})$ where $\alpha_\text{POI}$ is computed such that the following condition holds:
\begin{align*}
\frac{|P_{ij}([0,\alpha_\text{POI}])|}{\|\dot{p}(x_i)\|}=
\frac{|P_{ij}([\alpha_\text{POI},1])|}{\|\dot{p}(x_j)\|},
\end{align*}
where $|P_{ij}|$ denotes the arc-length of a sub-trajectory. The POI detection procedure is illustrated in \prettyref{fig:POI} and outlined in \prettyref{alg:POIDetection}, which incurs marginal overhead to conventional local navigation techniques.
\begin{algorithm}[t]
\caption{POISet($x_i$)\label{alg:POIDetection}}
\begin{algorithmic}[1]
\State Set$\gets\emptyset$
\For{Each agent $x_j\neq x_i\land\|p(x_j)-p(x_i)\|<R$}
\State Project to skeletal point $s_i,s_j$
\State Loop up shortest path $P_{ij}$
\If{\prettyref{eq:meeting} holds}
\State Set$\gets\text{Set}\bigcup\{P_{ij}(\alpha_\text{POI})\}$
\EndIf
\EndFor
\State Return Set
\end{algorithmic}
\end{algorithm}

\subsection{POI Shifting\label{sec:shifting}}
Given a POI located at $s_i\in V$, we then estimate its surrounding area. Given the medial axis, this area can be immediately estimated as the circular domain at $s_i$. If a POI is located on an edge of $E$ neighboring $s_i$ and $s_j$, we interpolate the circular domain radius. The radius of circular domain $r(s_i)$ must be sufficiently large for the yielding behavior to have a high success rate. Unfortunately, we are still lacking a theoretical analysis connecting the success rate of $\text{GRVO}$ and the size of the yielding area. Instead, we use the following heuristic rule to compute the minimal domain radius $r(s_i)$ for $n$ agents to successfully yield to each other:
\begin{align}
\label{eq:heuristic}
r(s_i)\geq \eta r(n+1),
\end{align}
where $\eta\in(0,1]$ is a user-provided parameter. In typical scenarios, we have $n=2$ since POI is estimated for two agents. If \prettyref{eq:heuristic} is violated, we need to shift POI to a nearby large space on the medial axis graph $G$. We propose first searching for nodes belonging to $P_{ij}$. This is because $P_{ij}$ lies on our estimated path and shifting POI within $P_{ij}$ would not cause a detour. If $P_{ij}$ does not contain any node satisfying \prettyref{eq:heuristic}, we search the entire $G$ for the nearest node, which is the center of a large domain. If both attempts fail, we decide the entire map consists of narrow spaces and do not shift POI. This procedure is summarized in \prettyref{alg:POIShifting}.
\begin{algorithm}[t]
\caption{POIShift(POI,$n$)\label{alg:POIShifting}}
\begin{algorithmic}[1]
\State Dist$\gets\infty$, $\text{POI}_0\gets\text{POI}$, POI$\gets$None
\For{Each $s_i\in P_{ij}$}
\If{\prettyref{eq:heuristic}$\land\|\text{POI}_0-p(s_i)\|<\text{Dist}$}
\State $\text{POI}\gets p(s_i)$, Dist$\gets\|\text{POI}_0-p(s_i)\|$
\EndIf
\EndFor
\If{Dist$<\infty$}
\State Return $\text{POI}$
\EndIf
\For{Each $s_i\in V$}
\If{\prettyref{eq:heuristic}$\land\|\text{POI}_0-p(s_i)\|<\text{Dist}$}
\State $\text{POI}\gets p(s_i)$, Dist$\gets\|\text{POI}_0-p(s_i)\|$
\EndIf
\EndFor
\State Return $\text{POI}$
\end{algorithmic}
\end{algorithm}

\subsection{POI Merging}
We found that handling only POI cases with two agents improves the success rate of $\text{GRVO}$. For extremely challenging environments, however, more agents can meet at nearby POIs and we must consider POIs involving $n>2$ agents. We handle this case by iteratively merging nearby POIs as outlined in \prettyref{alg:POIMerging}. In practice, if two POIs denoted as $\text{POI}_i$ and $\text{POI}_j$ involve $n_i$ and $n_j$ agents, respectively, we merge them into a single $\text{POI}_{ij}$ if the following condition holds:
\begin{align}
\label{eq:mergeCondition}
\|\text{POI}_i-\text{POI}_j\|\leq\eta\min\left(r(n_1+1),r(n_2+1)\right).
\end{align}
The merged $\text{POI}_{ij}$ involves $n=n_i+n_j$ agents and its required yielding radius is specified by \prettyref{eq:heuristic}. We perform the POI shifting procedure as described in \prettyref{sec:shifting}. If the shifting procedure fails, then we reject merging. We iteratively merge POIs until no more merging can be performed.
\begin{algorithm}[t]
\caption{POIMerge($x_i$)\label{alg:POIMerging}}
\begin{algorithmic}[1]
\State Set$\gets$POISet($x_i$), More$\gets$True
\For{$\text{POI}\in$Set}
\If{POIShift(POI,2)$\neq$None}
\State{Set$\gets$Set$/\{\text{POI}\}$}
\State{Set$\gets$Set$\bigcup$POIShift(POI,2)}
\EndIf
\EndFor
\While{More}
\State More$\gets$False
\For{A pair of $\text{POI}_i, \text{POI}_j\in$Set with $n_i, n_j$}
\If{\prettyref{eq:mergeCondition} holds}
\If{POIShift($\text{POI}_i$,$n_i+n_j$)$\neq$None}
\State{Set$\gets$Set$/\{\text{POI}_i,\text{POI}_j\}$}
\State{Set$\gets$Set$\bigcup$POIShift($\text{POI}_i$,$n_i+n_j$)}
\State More$\gets$True
\ElsIf{POIShift($\text{POI}_j$,$n_i+n_j$)$\neq$None}
\State{Set$\gets$Set$/\{\text{POI}_i,\text{POI}_j\}$}
\State{Set$\gets$Set$\bigcup$POIShift($\text{POI}_j$,$n_i+n_j$)}
\State More$\gets$True
\EndIf
\EndIf
\EndFor
\EndWhile
\State Return Set
\end{algorithmic}
\end{algorithm}

\input{figure}
\subsection{Velocity Modulation}
After the above procedure, an agent has a set of POI positions against a multitude of other agents. We choose the nearest $\text{POI}$ to $p(x_i(t))$ as the temporary goal point to modulate our velocity. Note that due to various sources of uncertainty and inaccuracy in estimating $\text{POI}$, modulating our velocity can cause detours. To minimize this effect, we only adopt modulation if the nearest $\text{POI}$ was successfully shifted, i.e. we define $\mathcal{M}$ as:
\begin{align*}
\mathcal{M}(v_i^*)\triangleq
\begin{cases}
\left[\argmin{\text{POI}}\|\text{POI}-p(x_i)\|\right]-x_i & \text{POI shifted}   \\
v_i^* & \text{otherwise}.
\end{cases}
\end{align*}

\subsection{Acceleration by Precomputation}
The main computational bottleneck of our algorithm lies in the POI merging procedure. This involves at most $2N$ calls to \prettyref{alg:POIShifting}, and each call to \prettyref{alg:POIShifting} incurs a computational cost of $|V|+|E|$. However, we can further reduce the cost of \prettyref{alg:POIShifting} to $\mathcal{O}(1)$ by precomputing a lookup table. Note that POI generally lies on an edge of $G$. However, if we use sufficiently dense samples to construct $V$, we can shift POI to a nearby vertex $s_i\in V$ incurring a small error. In this way, \prettyref{alg:POIShifting} will only be called with discrete inputs POIShift($s_i$,$n$), and we can construct a table of size $|V|\times N$ to precompute all possible results. After such acceleration, the complexity of each evaluation of modulation function $\mathcal{M}$ is only $\mathcal{O}(2N)$.