\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{color}
\usepackage{latexsym}
\usepackage{tablefootnote}
\usepackage{algorithm}
\usepackage{algorithmic}
\newcommand{\red}[1]{\textcolor{red}{#1}}
\newcommand*{\E}{\mathbb{E}}
\newcommand*{\QEDA}{\hfill\hbox{\vrule width1.0ex height1.0ex}}

\include{def}


\begin{document}

\title{Stochastic Proximal Bundle Method with Max Model}
%\date{July 2022}
\maketitle


\section{Problem Setup}

Stochastic	
	convex composite optimization (SCCO) problem
	\begin{equation}\label{eq:ProbIntro}
	\phi_{*}:=\min \left\{\phi(x):=f(x)+h(x): x \in \R^n\right\}
	\end{equation}
	where 
	\begin{equation}\label{pbint2}
	f(x)=\mathbb{E}_{\xi}[F(x,\xi)].
    \end{equation}
    \begin{equation}\label{pbint2s}
	f'(x)=\mathbb{E}_{\xi}[F'(x,\xi)].
    \end{equation}
% Assume that
% \[
% \E_\xi \left [ (F(u;\xi) - f(u))^2 \right] \le \E[(F(u;\xi)-f(u))^2].
% \]
% \[
% \E_\xi \left [ \E (F(u;\xi) - F(u;\xi'))^2 \right] \le \E[(F(u;\xi)-f(u))^2]
% \]



\begin{equation}
\label{def:tell}
    \tilde \ell(u,x;\xi) := F(x;\xi)+ \inner{F'(x;\xi)}{u-x} + h(u)
\end{equation}

\begin{equation}
\label{def:ell}
     \ell(u,x;\xi) := f(x)+ \inner{F'(x;\xi)}{u-x} + h(u)
\end{equation}

The linearization satisfies
\[
\tilde \ell(u,z_i;\xi) \le \Phi(u;\xi).
\]

\subsection{Assumptions}
	
Let $\Xi$ denote the
	support of random 
	vector $\xi$ and assume that the following conditions on \eqref{eq:ProbIntro} are assumed to hold:
	\begin{itemize}
% \item[(A1)] \red{remove}
% $h \in \bConv{n}$ is
% $M_h$-Lipschitz continuous on its domain, i.e., $|h(x)-h(x')| \le M_h \|x-x'\|$ for every $x,x' \in \dom h$;
\item[(A1)]
$f$ and $ h$ are proper closed convex functions satisfying
		$\dom f \supset \dom h$;
		
\item[(A2)] for almost every $\xi \in \Xi$,
a functional oracle $F(\cdot,\xi) :\dom h \to \R$ and
a stochastic subgradient
oracle $s(\cdot,\xi):\dom h \to \R^n$ satisfying
\[
f(x) = \E[F(x,\xi)], \quad f'(x) := \E[s(x,\xi)] \in \partial f(x)
\]
for every $x \in \dom h$ are available;
		\item[(A3)]
		$M := \sup \{ \E[\|s(x,\xi)\|^2]^{1/2} : x \in \dom h \} < \infty$;
%  \item[(A5)] $\dom h$ has a finite diameter $D>0$;
 	\item[(A4)]
		the set of optimal solutions $X^*$ of
	 \eqref{eq:ProbIntro}-\eqref{pbint2}	is nonempty.
	 % \item[(A5)] $\E \left [ (F(x;\xi) - f(x))^2 \right] \le \E[(F(u;\xi)-f(u))^2]$ for every $x\in \dom h$;
    \item[(A6)] $\dom h$ has a diameter $d_0<\infty$.
	\end{itemize}
	

	
	We now make some observations about the above conditions.
	First, as in \cite{nemjudlannem09},
	condition (A2) does not require $F(\cdot,\xi)$ to be
	convex.
	Second,
condition (A3) implies that
\begin{equation}\label{ineq:fp}
 \|f'(x)\| = \|\E[s(x,\xi)]\| \le \E[\|s(x,\xi)\|] \le \left(\E[\|s(x,\xi)\|^2]\right)^{1/2} \le M \quad \forall x \in \dom h.
\end{equation}
Third, defining for every $\xi \in \Xi$ and $x \in \dom h$,
	\begin{equation}\label{def:Phi}
	\Phi(\cdot,\xi)=F(\cdot,\xi)+h(\cdot), \quad 
	\ell(\cdot,x;\xi)= f(x)+\inner{s(x,\xi)}{\cdot-x} + h(\cdot), 
	\end{equation}
it follows from (A2), the second identity in \eqref{def:Phi},
and the convexity of $f$ by (A1), that
\begin{equation}\label{eq:exp0}
    \E[\Phi(\cdot,\xi)] = \phi(\cdot)\ge f(x) + \inner{f'(x)}{\cdot-x} + h(\cdot) =
\E[\ell(\cdot;x,\xi)]
\end{equation}
where $\phi(\cdot)$ is as in \eqref{eq:ProbIntro}.
Hence, $\ell(\cdot;x,\xi)$ is
a stochastic composite linear approximation of
$\phi(\cdot)$
in the sense that its expectation is a true composite linear approximation of $\phi(\cdot)$. (The terminology ``composite" refers to the function $h$ which is included in the approximation $\ell(\cdot;x,\xi)$ as is.)




\section{Stochastic Multi-cut Bundle method}

\red{stochastic regularized cutting-plane (SRCP) method}
\red{change the algorithm}

\noindent\rule[0.5ex]{1\columnwidth}{1pt}

Stochastic Multi-cut Bundle Method (SMCB)

\noindent\rule[0.5ex]{1\columnwidth}{1pt}
{\bf Input:} Scalars $\{\lam_j\}>0$, integer $I \ge 1$, set $B$ such that 
$\{1\} \subseteq B \subseteq \{1,\ldots, \lfloor I/2 \rfloor\}$, and point $ x_0 \in \dom h $.
\begin{itemize}
\item [0.] 
 Set 
 %$j=1$, $z_0=x$
	$j=1$ and $z_0=x_0$,
 take a sample $\xi_0$
 of $\xi$, and set
 $\underline{\phi}_0(\cdot) = \tilde \ell (\cdot,z_0;\xi_0)$; 
    \item [1.] 
 %    take 
	% a sample $\xi_{j-1}$ of r.v.\ $\xi$ independent from the previous samples $\xi_0,\ldots,\xi_{j-2}$
	% and 
 compute
 %    \begin{align} \label{eq:Gammaj}
	% \bar \phi_j(\cdot) =  \left\{\begin{array}{ll}
	%     % \tilde \ell(\cdot,x;\xi_{0}), & \text { if } j=1 , \\ 
	% 	   \max \{ \fr
	%     \tilde \ell(\cdot,z_{j-1};\xi_{j-1}) +  \frac{j-1}{j} \bar \phi_{j-1}(\cdot), \tilde \ell(\cdot,z_{j-1};\xi_{j-1})\},  & \text { if } j \in B,
 %     \\ 
	% 	    \frac{1}{j}
	%     \tilde \ell(\cdot,z_{j-1};\xi_{j-1}) +  \frac{j-1}{j} \bar \phi_{j-1}(\cdot) ,  & \text { otherwise},
	% 	    \end{array}\right.
 %    \end{align}	
    \begin{align} 
	\underline{\phi}_j(\cdot) &=  \left\{\begin{array}{ll}
	    % \tilde \ell(\cdot,x;\xi_{0}), & \text { if } j=1 , \\ 
		   \max\{\frac{1}{j}
	    \tilde \ell(\cdot,z_{j-1};\xi_{j-1}) + \frac{j-1}{j}  
     % \frac{1}{j}
	    % \tilde \ell(\cdot,z_{j-1};\xi_{j-1}) +  \frac{j-1}{j}
     \underline{\phi}_{j-1}(\cdot), \tilde \ell(\cdot,z_{j-1};\xi_{j-1})\},  & \text { if } j \in B,
     \\ 
		    \frac{1}{j}
	    \tilde \ell(\cdot,z_{j-1};\xi_{j-1}) +  \frac{j-1}{j} \underline{\phi}_{j-1}(\cdot) ,  & \text { otherwise},
		    \end{array}\right. \label{eq:Gammaj}\\
  %   \end{align}	
  %   \lessgap
  %   \lessgap
		% \begin{align}
	    z_{j} &=\underset{u\in \R^n}\argmin
	    \left\lbrace  \underline{\phi}_j^{\lam_j}(u):=
	    \underline{\phi}_j(u) +\frac{1}{2\lam_j}\|u- z_0 \|^2 \right\rbrace, \label{def:xj}  \\  
% 	    \end{align}
% and
% 	    \lessgap
%     \lessgap
% 	    \begin{align} \label{def:yj}
	w_j &=  \frac{1}{j} \sum_{i=1}^j z_i \label{def:wj}
    \end{align}		 
    \lessgap
    \item [2.] 
    if $j<I$, then take 
	a sample $\xi_{j}$ of r.v.\ $\xi$ independent from the previous samples $\xi_0,\ldots,\xi_{j-1}$,
 set $j \leftarrow j+1$ and go to step 1; otherwise \textbf{stop}.
\end{itemize}
{\bf Output:} $(z_I,w_I)$.

\noindent
\rule[0.5ex]{1\columnwidth}{1pt}

--------Renato's notes---

First dual-average paper by Nesterov
\[
\lam_j = \frac{j}{\beta_j}
\]
\[
\beta_j \approx \sqrt{j}
\]

Second dual-average paper by Nesterov

 \[
\lam_j = \frac{j}{\beta_j}
\]
\[
\beta_j \approx \gamma \sqrt{I+1}
\]

-----------

\section{Only $M$ included}

\subsection{Deterministic case (convex case)}

Let $\lam>0$ and $\Gamma \le \phi$ be given
and set
\[
x = \argmin \left \{ \Gamma(u) + \frac{1}{2\lam} \|u-x_0\|^2 \right\}
\]
\[
m = \min \left \{ \Gamma(u) + \frac{1}{2\lam} \|u-x_0\|^2 \right\}
\]
Update
\[
\Gamma^+ = \tau \Gamma + (1-\tau) \ell_\phi(\cdot;x)
\]
and assume that 
\[
\lam^+ \le \frac{\lam}{\tau}
\]
Have
\begin{align*}
    m^+ &= \Gamma^+(x^+) + \frac{1}{2\lam^+} \|x^+-x_0\|^2 \\
    &=\tau \Gamma(x^+) + (1-\tau) \ell_\phi(x^+;x) + \frac{1}{2\lam^+} \|x^+-x_0\|^2 \\
    &\ge \tau \left [  \Gamma(x^+) + \frac{1}{2\lam} \|x^+-x_0\|^2 \right] + (1-\tau) \ell_\phi(x^+;x)  \\
    &\ge \tau \left [  \Gamma(x) + \frac{1}{2\lam} \|x-x_0\|^2 + \frac{1}{2\lam} \|x^+-x\|^2  \right] + (1-\tau) \ell_\phi(x^+;x)  \\
    &= \tau \left [  m + \frac{1}{2\lam} \|x^+-x\|^2  \right] + (1-\tau) \ell_\phi(x^+;x)
\end{align*}
Hence,
\begin{align*}
    m^+ - \tau m &\ge \frac{1}{2\lam} \|x^+-x\|^2  + (1-\tau) \ell_\phi(x^+;x) \\
    &= \frac{1}{2\lam} \|x^+-x\|^2  + (1-\tau) \phi(x^+) - (1-\tau) [\phi(x^+)-\ell_\phi(x^+;x) ] \\
    &\ge \frac{1}{2\lam} \|x^+-x\|^2  + (1-\tau) \phi(x^+) - (1-\tau) 2M \|x^+-x\| \\
    &\ge (1-\tau) \phi(x^+) -
    2 (1-\tau)^2 M^2 \lam
\end{align*}
Thus
\begin{align*}
    t^+- \tau t &= [ \phi(y^+)-m^+] -
\tau [ \phi(y) - m] =
[ \phi(y^+)-\tau  \phi(y)] - [m^+-\tau m] \\
&\le [ \phi(y^+)-\tau  \phi(y) - (1-\tau) \phi(x^+) ] + 2 (1-\tau)^2 M^2 \lam \\
&\le  2 (1-\tau)^2 M^2 \lam
\end{align*}
Indexing the above equation, we conclude that
\begin{align*}
    t_{j+1} - \tau_j t_j \le 2 (1-\tau_j)^2 M^2 \lam_j
\end{align*}
Assume that
\[
\tau_j = \frac{j}{j+1} \quad \forall j \ge 1
\]
Multiplying ?? by $j+1$, we then conclude that
\[
(j+1) t_{j+1} - j t_j \le
\frac{2}{j+1} M^2 \lam_j
\]
and hence that
\[
J t_J - t_1 \le 2 M^2 \sum_{j=1}^{J-1} \frac{\lam_j}{j+1}
\]
{\bf 1st choice:}
\[
\lam_j = \gamma \sqrt{j} \quad \forall j \ge 1
\]
and note that
\[
\lam_{j+1} = \gamma \sqrt{j+1} =
\gamma \sqrt{j} \sqrt{\frac{j+1}{j}}
= \lam_j \sqrt{\frac{j+1}{j}}
\le \lam_j \frac{j+1}{j} = \frac{\lam_j}{\tau_j}
\]
So, we conclude that
\[
J t_J - t_1 \le 2 M^2 \sum_{j=1}^{J-1} \frac{\lam_j}{j+1} \le 2 \gamma M^2 \sum_{j=1}^{J-1} \frac{1}{\sqrt{j}} \approx \gamma M^2 \sqrt{J}
\]
Hence
\[
t_J \le \frac{t_1}{J} +
\frac{\gamma M^2}{\sqrt{J}}
\]
Thus
\begin{align*}
    \frac{t_1}{J} +
\frac{\gamma M^2}{\sqrt{J}} &\ge
\phi(y_J) - \left[ \Gamma_J(x_J) + \frac{1}{2 \lam_J} \|x_J-x_0\|^2 \right] \\
&\ge \phi(y_J) - \left[ \Gamma_J(x_*) + \frac{1}{2 \lam_J} \|x_*-x_0\|^2 - \frac{1}{2 \lam_J} \|x_*-x_J\|^2 \right] \\
&\ge \phi(y_J) - \left[ \phi(x_*) + \frac{1}{2 \lam_J} \|x_*-x_0\|^2 - \frac{1}{2 \lam_J} \|x_*-x_J\|^2 \right]
\end{align*}
so that
\begin{align*}
    \phi(y_J) - \phi(x_*)
&\le 
\frac{t_1}{J} +
\frac{\gamma M^2}{\sqrt{J}} + \frac{1}{2 \lambda_J} \left( \|x_*-x_0\|^2 -
 \|x_*-x_J\|^2 \right)  \\
&\le \frac{t_1}{J} +
\frac{\gamma M^2}{\sqrt{J}} + \frac{1}{2 \gamma \sqrt{J}} \left( \|x_*-x_0\|^2 -
 \|x_*-x_J\|^2 \right)
\end{align*}
{\bf 2nd choice:}
\[
\lam_j = \gamma \frac{j}{\sqrt{J}} \quad \forall j \ge 1
\]
and note that
\[
\lam_{j+1} = \gamma \sqrt{j+1} =
\gamma \sqrt{j} \sqrt{\frac{j+1}{j}}
= \lam_j \sqrt{\frac{j+1}{j}}
\le \lam_j \frac{j+1}{j} = \frac{\lam_j}{\tau_j}
\]
So, we conclude that
\[
J t_J - t_1 \le 2 M^2 \sum_{j=1}^{J-1} \frac{\lam_j}{j+1} \le \frac{2 \gamma M^2}{\sqrt{J}} \sum_{j=1}^{J-1} \frac{j}{j+1} \approx \gamma M^2 \sqrt{J}
\]
Hence
\[
t_J \le \frac{t_1}{J} +
\frac{\gamma M^2}{\sqrt{J}}
\]
Thus
\begin{align*}
    \frac{t_1}{J} +
\frac{\gamma M^2}{\sqrt{J}} &\ge
\phi(y_J) - \left[ \Gamma_J(x_J) + \frac{1}{2 \lam_J} \|x_J-x_0\|^2 \right] \\
&\ge \phi(y_J) - \left[ \Gamma_J(x_*) + \frac{1}{2 \lam_J} \|x_*-x_0\|^2 - \frac{1}{2 \lam_J} \|x_*-x_J\|^2 \right] \\
&\ge \phi(y_J) - \left[ \phi(x_*) + \frac{1}{2 \lam_J} \|x_*-x_0\|^2 - \frac{1}{2 \lam_J} \|x_*-x_J\|^2 \right]
\end{align*}
so that
\begin{align*}
    \phi(y_J) - \phi(x_*)
&\le 
\frac{t_1}{J} +
\frac{\gamma M^2}{\sqrt{J}} + \frac{1}{2 \lambda_J} \left( \|x_*-x_0\|^2 -
 \|x_*-x_J\|^2 \right)  \\
&\le \frac{t_1}{J} +
\frac{\gamma M^2}{\sqrt{J}} + \frac{1}{2 \gamma \sqrt{J}} \left( \|x_*-x_0\|^2 -
 \|x_*-x_J\|^2 \right)
\end{align*}
since $\lam_J = \gamma \sqrt{J}$

\subsection{Deterministic case (strongly convex case)}

Let $\lam>0$ and $\Gamma \le \phi$ be given
and set
\[
x = \argmin \left \{ \Gamma(u) + \frac{1}{2\lam} \|u-x_0\|^2 \right\}
\]
\[
m = \min \left \{ \Gamma(u) + \frac{1}{2\lam} \|u-x_0\|^2 \right\}
\]
Update
\[
\Gamma^+ = \tau \Gamma + (1-\tau) \ell_\phi(\cdot;x)
\]
and assume that 
\[
\lam^+ \le \frac{\lam}{\tau}
\]
Have
\begin{align*}
    m^+ &= \Gamma^+(x^+) + \frac{1}{2\lam^+} \|x^+-x_0\|^2 \\
    &=\tau \Gamma(x^+) + (1-\tau) \ell_\phi(x^+;x) + \frac{1}{2\lam^+} \|x^+-x_0\|^2 \\
    &\ge \tau \left [  \Gamma(x^+) + \frac{1}{2\lam} \|x^+-x_0\|^2 \right] + (1-\tau) \ell_\phi(x^+;x)  \\
    &\ge \tau \left [  \Gamma(x) + \frac{1}{2\lam} \|x-x_0\|^2 + \frac{1}{2\lam_\mu} \|x^+-x\|^2  \right] + (1-\tau) \ell_\phi(x^+;x)  \\
    &= \tau \left [  m + \frac{1}{2\lam_\mu} \|x^+-x\|^2  \right] + (1-\tau) \ell_\phi(x^+;x)
\end{align*}
where
\[
\frac{1}{\lam_\mu} := \frac1\lam + \mu \ge \mu
\]
Hence,
\begin{align*}
    m^+ - \tau m &\ge \frac{1}{2\lam_mu} \|x^+-x\|^2  + (1-\tau) \ell_\phi(x^+;x) \\
    &= \frac{1}{2\lam_\mu} \|x^+-x\|^2  + (1-\tau) \phi(x^+) - (1-\tau) [\phi(x^+)-\ell_\phi(x^+;x) ] \\
    &\ge \frac{1}{2\lam_\mu} \|x^+-x\|^2  + (1-\tau) \phi(x^+) - (1-\tau) 2M \|x^+-x\| \\
    &\ge (1-\tau) \phi(x^+) -
    2 (1-\tau)^2 M^2 \lam^\mu
\end{align*}
Thus
\begin{align*}
    t^+- \tau t &= [ \phi(y^+)-m^+] -
\tau [ \phi(y) - m] =
[ \phi(y^+)-\tau  \phi(y)] - [m^+-\tau m] \\
&\le [ \phi(y^+)-\tau  \phi(y) - (1-\tau) \phi(x^+) ] + 2 (1-\tau)^2 M^2 \lam^\mu \\
&\le  2 (1-\tau)^2 M^2 \lam^\mu 
% \le \frac{2 (1-\tau)^2 M^2} \mu
\end{align*}
Indexing the above equation, we conclude that
\begin{align}
    t_{j+1} - \tau_j t_j \le 2 (1-\tau_j)^2 M^2 \lam^\mu_j
    % \frac{2 (1-\tau_j)^2 M^2} \mu
     \label{eq:recurv-st-conv}
\end{align}
Assume that
\[
\tau_j = \frac{j}{j+1} \quad \forall j \ge 1
\]
Multiplying \eqref{eq:recurv-st-conv} by $j+1$, we then conclude that
\[
(j+1) t_{j+1} - j t_j \le
\frac{2M^2 \lam_j^\mu}{(j+1)}
\]
and hence that
\[
J t_J - t_1 \le 2 M^2  \sum_{j=1}^{J-1} \frac{\lam^\mu_j}{j+1}
\]
Now, choose
\[
\lam_j = \gamma \sqrt{j} \left( 1 + \mu \sqrt{j} \right)  \quad \forall j \ge 1
\]
and note that
\[
\lam_{j+1} = \gamma \sqrt{j+1}\left( 1 + \mu \sqrt{j+1} \right) =
\gamma \sqrt{{\frac{j}{\tau_j}}} 
\left( 1 + \mu \sqrt{{\frac{j}{\tau_j}}} \right)
\le
\frac{1}{\tau_j} \gamma \sqrt{j} 
\left( 1 + \mu \sqrt{j} \right)
= \frac{\lam_j}{\tau_j}
\]
So, we conclude that
\[
J t_J - t_1 \le 2 M^2 \sum_{j=1}^{J-1} \frac{\lam_j^\mu}{j+1} \le \frac{2  M^2}{\mu} \sum_{j=1}^{J-1} \frac{1}{j+1} \approx \frac{ M^2}{\mu} \log J
\]
Hence
\[
t_J \le \frac{t_1}{J} +
\frac{ M^2 \log J}{\mu J}
\]
Thus
\begin{align*}
    \frac{t_1}{J} +
\frac{\gamma M^2}{\sqrt{J}} &\ge
\phi(y_J) - \left[ \Gamma_J(x_J) + \frac{1}{2 \lam_J} \|x_J-x_0\|^2 \right] \\
&\ge \phi(y_J) - \left[ \Gamma_J(x_*) + \frac{1}{2 \lam_J} \|x_*-x_0\|^2 - \frac{1}{2 \lam_J^\mu} \|x_*-x_J\|^2 \right] \\
&\ge \phi(y_J) - \left[ \phi(x_*) + \frac{1}{2 \lam_J} \|x_*-x_0\|^2 - \frac{1}{2 \lam_J^\mu} \|x_*-x_J\|^2 \right]
\end{align*}
so that
\begin{align*}
   \phi(y_J) - \phi(x_*)
&\le \frac{t_1}{J} +\frac{ M^2 \log J}{\mu J}
 + \frac{1}{2 \lam_J} \|x_*-x_0\|^2 -
\frac{1}{2 \lam_J^\mu} \|x_*-x_J\|^2 \\
&\le \frac{t_1}{J} +\frac{ M^2 \log J}{\mu J}
 + \frac{1}{2 \gamma \mu J} \|x_*-x_0\|^2
\end{align*}
since $\lam_J \ge \gamma \mu J$

\section{Including $(L,M)$}

\subsection{Deterministic case (convex case)}

Let $\lam>0$ and $\Gamma \le \phi$ be given
and set
\[
x = \argmin \left \{ \Gamma(u) + \frac{1}{2\lam} \|u-x_0\|^2 \right\}
\]
\[
m = \min \left \{ \Gamma(u) + \frac{1}{2\lam} \|u-x_0\|^2 \right\}
\]
Update
\[
\Gamma^+ = \tau \Gamma + (1-\tau) \ell_\phi(\cdot;x)
\]
and assume that 
\[
\lam^+ \le \frac{\lam}{\tau}
\]
Have
\begin{align*}
    m^+ &= \Gamma^+(x^+) + \frac{1}{2\lam^+} \|x^+-x_0\|^2 \\
    &=\tau \Gamma(x^+) + (1-\tau) \ell_\phi(x^+;x) + \frac{1}{2\lam^+} \|x^+-x_0\|^2 \\
    &\ge \tau \left [  \Gamma(x^+) + \frac{1}{2\lam} \|x^+-x_0\|^2 \right] + (1-\tau) \ell_\phi(x^+;x)  \\
    &\ge \tau \left [  \Gamma(x) + \frac{1}{2\lam} \|x-x_0\|^2 + \frac{1}{2\lam} \|x^+-x\|^2  \right] + (1-\tau) \ell_\phi(x^+;x)  \\
    &= \tau \left [  m + \frac{1}{2\lam} \|x^+-x\|^2  \right] + (1-\tau) \ell_\phi(x^+;x)
\end{align*}
Hence,
\begin{align*}
    m^+ - \tau m &\ge \frac{1}{2\lam} \|x^+-x\|^2  + (1-\tau) \ell_\phi(x^+;x) \\
    &= \frac{1}{2\lam} \|x^+-x\|^2  + (1-\tau) \phi(x^+) - (1-\tau) [\phi(x^+)-\ell_\phi(x^+;x) ] \\
    &\ge \frac{1}{2\lam} \|x^+-x\|^2  + (1-\tau) \phi(x^+) - (1-\tau) \left [  2M \|x^+-x\| + \frac{L}2 \|x^+-x\|^2 \right ] \\
    &= (1-\tau) \left[
    \phi(x^+) -  2M \|x^+-x\| + \frac12 \left(\frac{1}{(1-\tau)\lam} - L \right) \|x^+-x\|^2
    \right ] \\
    &\ge (1-\tau) \left [ \phi(x^+) -
    \frac{ 2(1-\tau) M^2 \lam}{1-L(1-\tau) \lam} \right]
\end{align*}
Thus
\begin{align*}
    t^+- \tau t &= [ \phi(y^+)-m^+] -
\tau [ \phi(y) - m] =
[ \phi(y^+)-\tau  \phi(y)] - [m^+-\tau m] \\
&\le [ \phi(y^+)-\tau  \phi(y) - (1-\tau) \phi(x^+) ] +
    \frac{ 2(1-\tau)^2 M^2 \lam}{1-L(1-\tau) \lam} \\
&\le  \frac{ 2(1-\tau)^2 M^2 \lam}{1-L(1-\tau) \lam}
\end{align*}
Assume
\beq \label{eq:con-comp}
\frac{1}{1-\tau} \ge \lam ( L + \alpha )
\eeq
or equivalently
\[
1 - (1-\tau) \lam L \ge (1-\tau) \lam \alpha
\]
Then
\[
 t^+- \tau t \le \frac{ 2(1-\tau)^2 M^2 \lam}{1-L(1-\tau) \lam} \le \frac{ 2(1-\tau) M^2 }{\alpha}
\]
Indexing the above equation, we conclude that
\begin{align*}
    t_{j+1} - \tau_j t_j \le \frac{2 (1-\tau_j) M^2}{\alpha_j}
\end{align*}
Assume that
\[
\tau_j = \frac{j}{j+1} \quad \forall j \ge 1
\]
Multiplying ?? by $j+1$, we then conclude that
\[
(j+1) t_{j+1} - j t_j \le
\frac{2 M^2}{\alpha_j}
\]
and hence that
\[
J t_J - t_1 \le 2 M^2 \sum_{j=1}^{J-1} \frac{1}{\alpha_j}
\]
{\bf 1st choice:}
\[
\lam_j = \gamma \sqrt{j+1} \quad \forall j \ge 0
\]
and note that
\[
\lam_{j+1} = \gamma \sqrt{j+2} =
\gamma \sqrt{j+1} \sqrt{\frac{j+2}{j+1}}
= \lam_j \sqrt{\frac{j+2}{j+1}}
\le \lam_j \frac{j+2}{j+1} = \frac{\lam_j}{\tau_{j+1}} \le
\frac{\lam_j}{\tau_{j}}
\]
since $\tau_j \le \tau_{j+1}$.
Also, \eqref{eq:con-comp} becomes
\[
j+1 = \frac{1}{1-\tau_j} \ge \lam_j ( L + \alpha_j ) = \gamma \sqrt{j+1} ( L + \alpha_j)
\]
or
\[
\sqrt{j+1} \ge \gamma(L + \alpha_j)
\]
or
\[
\alpha_j \le \frac{\sqrt{j+1} -\gamma L} {\gamma}
\]
Take
\[
\alpha_j = \frac{\sqrt{j+1}} {2\gamma}, \quad \gamma \le \frac{1}L
\]
So, we conclude that
\[
J t_J - t_1 \le 2 M^2 \sum_{j=1}^{J-1} \frac{1}{\alpha_j} \le 2 M^2 \sum_{j=1}^{J-1} \frac{2 \gamma}{\sqrt{j+1}} \approx \gamma M^2 \sqrt{J}
\]
Hence
\[
t_J \le \frac{t_1}{J} +
\frac{\gamma M^2}{\sqrt{J}}
\]
Thus
\begin{align*}
    \frac{t_1}{J} +
\frac{\gamma M^2}{\sqrt{J}} &\ge
\phi(y_J) - \left[ \Gamma_J(x_J) + \frac{1}{2 \lam_J} \|x_J-x_0\|^2 \right] \\
&\ge \phi(y_J) - \left[ \Gamma_J(x_*) + \frac{1}{2 \lam_J} \|x_*-x_0\|^2 - \frac{1}{2 \lam_J} \|x_*-x_J\|^2 \right] \\
&\ge \phi(y_J) - \left[ \phi(x_*) + \frac{1}{2 \lam_J} \|x_*-x_0\|^2 - \frac{1}{2 \lam_J} \|x_*-x_J\|^2 \right]
\end{align*}
so that
\begin{align*}
    \phi(y_J) - \phi(x_*)
&\le 
\frac{t_1}{J} +
\frac{\gamma M^2}{\sqrt{J}} + \frac{1}{2 \lambda_J} \left( \|x_*-x_0\|^2 -
 \|x_*-x_J\|^2 \right)  \\
&\le \frac{t_1}{J} +
\frac{\gamma M^2}{\sqrt{J}} + \frac{1}{2 \gamma \sqrt{J}} \|x_*-x_0\|^2 
\end{align*}
{\bf 2nd choice:}
\[
\lam_j = \gamma \frac{j+1}{\sqrt{J+1}} \quad \forall j \ge 1
\]
and note that
\[
\sqrt{J+1} \, \lam_{j+1} = \gamma (j+2) =
\gamma (j+1)  \frac{j+2}{j+1}
= \frac{\gamma (j+1)}{\tau_{j+1}} \le
\frac{\gamma (j+1)}{\tau_{j}} =
\frac{\sqrt{J+1} \, \lam_j}{\tau_{j}}
\]
Also, \eqref{eq:con-comp} becomes
\[
j+1 = \frac{1}{1-\tau_j} \ge \lam_j ( L + \alpha_j ) = \frac{\gamma (j+1)} {\sqrt{J+1}} ( L + \alpha_j)
\]
or
\[
\sqrt{J+1} \ge \gamma(L + \alpha_j)
\]
or
\[
\alpha_j \le \frac{\sqrt{J+1} -\gamma L} {\gamma}
\]
Take
\[
\alpha_j = \frac{\sqrt{J+1}} {2\gamma}, \quad 
\]
and $\gamma$ such that
\[
\frac{\sqrt{J+1}} {2\gamma} \ge L
\]
i.e.,
\[
\gamma = \min\left\{ \frac{\sqrt{J+1}} {2L} , \frac{d_0}M \right\}
\]
So
\[
\gamma^{-1} = \max \left\{ \frac{2L}{\sqrt{J+1}}  , \frac M{d_0} \right\}
\]
So, we conclude that
\[
J t_J - t_1 \le 2 M^2 \sum_{j=1}^{J-1} \frac{1}{\alpha_j} = \frac{4 \gamma M^2(J-1)}{\sqrt{J+1}} \approx  \gamma M^2 \sqrt{J} \le d_0 M \aqrt{J}
\]
since $\gamma \le 1$.
Hence
\[
t_J \le \frac{t_1}{J} +
\frac{d_0 M}{\sqrt{J}}
\]
Thus
\begin{align*}
    \frac{t_1}{J} +
\frac{Md_0}{\sqrt{J}} \ge t_J  &=
\phi(y_J) - \left[ \Gamma_J(x_J) + \frac{1}{2 \lam_J} \|x_J-x_0\|^2 \right] \\
&\ge \phi(y_J) - \left[ \Gamma_J(x_*) + \frac{1}{2 \lam_J} \|x_*-x_0\|^2 - \frac{1}{2 \lam_J} \|x_*-x_J\|^2 \right] \\
&\ge \phi(y_J) -  \phi(x_*) - \frac{1}{2 \lam_J} \|x_*-x_0\|^2 +\frac{1}{2 \lam_J} \|x_*-x_J\|^2
\end{align*}
so that
\begin{align*}
    \phi(y_J) - \phi(x_*)
&\le 
\frac{t_1}{J} +
\frac{Md_0}{\sqrt{J}} + \frac{1}{2 \lambda_J} \left( \|x_*-x_0\|^2 -
 \|x_*-x_J\|^2 \right)  \\
&\le \frac{t_1}{J} +
\frac{Md_0}{\sqrt{J}} + \frac{1}{2 \gamma \sqrt{J}} d_0^2 \\
&\le
\frac{t_1}{J} +
\frac{Md_0}{\sqrt{J}} +
\frac{1}{2 \sqrt{J}} d_0^2 \left( \frac{2L}{\sqrt{J+1}}  +  \frac M{d_0}\right) \\
&= {\cal O}\left( \frac{t_1}{J} +
\frac{Md_0}{\sqrt{J}}
+ \frac{Ld_0^2}{J}
\right)
\end{align*}
since $\lam_J = \gamma \sqrt{J}$

\subsection{Deterministic case (strongly convex case)}

Let $\lam>0$ and $\Gamma \le \phi$ be given
and set
\[
x = \argmin \left \{ \Gamma(u) + \frac{1}{2\lam} \|u-x_0\|^2 \right\}
\]
\[
m = \min \left \{ \Gamma(u) + \frac{1}{2\lam} \|u-x_0\|^2 \right\}
\]
Update
\[
\Gamma^+ = \tau \Gamma + (1-\tau) \ell_\phi(\cdot;x)
\]
and assume that 
\beq \label{eq:cond-cru'}
\lam^+ \le \frac{\lam}{\tau}
\eeq
Have
\begin{align*}
    m^+ &= \Gamma^+(x^+) + \frac{1}{2\lam^+} \|x^+-x_0\|^2 \\
    &=\tau \Gamma(x^+) + (1-\tau) \ell_\phi(x^+;x) + \frac{1}{2\lam^+} \|x^+-x_0\|^2 \\
   \mbox{(due to \eqref{eq:cond-cru'})} \ \ &\ge \tau \left [  \Gamma(x^+) + \frac{1}{2\lam} \|x^+-x_0\|^2 \right] + (1-\tau) \ell_\phi(x^+;x)  \\
    &\ge \tau \left [  \Gamma(x) + \frac{1}{2\lam} \|x-x_0\|^2 + \frac{1}{2\lam_\mu} \|x^+-x\|^2  \right] + (1-\tau) \ell_\phi(x^+;x)  \\
    &= \tau \left [  m + \frac{1}{2\lam_\mu} \|x^+-x\|^2  \right] + (1-\tau) \ell_\phi(x^+;x)
\end{align*}
where
\[
\frac{1}{\lam_\mu} := \frac1\lam + \mu \ge \mu
\]
Assume
\beq \label{eq:con-comp'}
\alpha:= \frac{1}{\lam_\mu(1-\tau)} -L > 0
\eeq
Hence,
\begin{align*}
    m^+ - \tau m &\ge \frac{1}{2\lam_\mu} \|x^+-x\|^2  + (1-\tau) \ell_\phi(x^+;x) \\
    &= \frac{1}{2\lam_\mu} \|x^+-x\|^2  + (1-\tau) \phi(x^+) - (1-\tau) [\phi(x^+)-\ell_\phi(x^+;x) ] \\
    &\ge \frac{1}{2\lam_\mu} \|x^+-x\|^2  + (1-\tau) \phi(x^+) - (1-\tau)  \left [  2M \|x^+-x\| + \frac{L}2 \|x^+-x\|^2 \right ]
     \\
     &= (1-\tau) \left[
    \phi(x^+) -  2M \|x^+-x\| + \frac12 \left(\frac{1}{(1-\tau)\lam_\mu} - L \right) \|x^+-x\|^2
    \right ] \\
 \mbox{(due to \eqref{eq:con-comp'})} \ \    &\ge  (1-\tau) \left[
    \phi(x^+) -  2M \|x^+-x\| + \frac{\alpha}2  \|x^+-x\|^2
    \right ] \\
     &\ge (1-\tau) \left[ \phi(x^+) -
     \frac{2M^2}{\alpha} \right]
\end{align*}
Thus
\begin{align*}
    t^+- \tau t &= [ \phi(y^+)-m^+] -
\tau [ \phi(y) - m] =
[ \phi(y^+)-\tau  \phi(y)] - [m^+-\tau m] \\
&\le [ \phi(y^+)-\tau  \phi(y) - (1-\tau) \phi(x^+) ] + \frac{2 (1-\tau) M^2}{\alpha} \\
&\le  \frac{2 (1-\tau) M^2}{\alpha} 
% \le \frac{2 (1-\tau)^2 M^2} \mu
\end{align*}
Indexing the above equation, we conclude that
\begin{align}
    t_{j+1} - \tau_j t_j \le \frac{2 (1-\tau_j) M^2 }{\alpha_j}
    % \frac{2 (1-\tau_j)^2 M^2} \mu
     \label{eq:recurv-st-conv}
\end{align}
Assume that
\[
\tau_j = \frac{j}{j+1} \quad \forall j \ge 1
\]
Multiplying \eqref{eq:recurv-st-conv} by $j+1$, we then conclude that
\[
(j+1) t_{j+1} - j t_j \le
\frac{2M^2}{\alpha_j}
\]
and hence that
\[
J t_J - t_1 \le 2 M^2 \Gamma_k
\]
where
\[
\Gamma_J := \sum_{j=1}^{J-1} \frac{1}{\alpha_j}
\]
Thus
\begin{align*}
    \frac{t_1 + 2 M^2 \Gamma_J}{J}  &\ge t_J = 
\phi(y_J) - \left[ \Gamma_J(x_J) + \frac{1}{2 \lam_J} \|x_J-x_0\|^2 \right] \\
&\ge \phi(y_J) - \left[ \Gamma_J(x_*) + \frac{1}{2 \lam_J} \|x_*-x_0\|^2 - \frac{1}{2 \lam_J^\mu} \|x_*-x_J\|^2 \right] \\
&\ge \phi(y_J) - \left[ \phi(x_*) + \frac{1}{2 \lam_J} \|x_*-x_0\|^2 - \frac{1}{2 \lam_J^\mu} \|x_*-x_J\|^2 \right]
\end{align*}

---------

\[
\frac{\lam_J^\mu}{\lam J} = \left( \frac{\lam_J}{1+\lam_J \mu} \frac{1}{\lam_J} \right) = \left( \frac{1}{1+\lam_J \mu}  \right)
\]

\[
  2 M d_0 \ge \frac{1}{\lam_J} d_0^2 - \frac{1}{\lam_J^\mu}(d_0^+)^2
\]

---------


so that
\begin{align*}
   \phi(y_J) - \phi(x_*)
&\le \frac{t_1+2 M^2 \Gamma_k}{J} 
 + \frac{1}{2 \lam_J} \|x_*-x_0\|^2 -
\frac{1}{2 \lam_J^\mu} \|x_*-x_J\|^2 \\
&\le \frac{t_1+2 M^2 \Gamma_J}{J} 
 + \frac{d_0^2}{2 \lam_J}
\end{align*}

% -------------------

% \begin{align*}
%    \phi(y_J) - \phi(x_*)
% &\le \frac{t_1}{J} +\frac{ M^2 \log J}{\mu J}
%  + \frac{1}{2 \lam_J} \|x_*-x_0\|^2 -
% \frac{1}{2 \lam_J^\mu} \|x_*-x_J\|^2 \\
% &\le \frac{t_1}{J} +\frac{ M^2 \log J}{\mu J}
%  + \frac{1}{2 \gamma \mu J} \|x_*-x_0\|^2
% \end{align*}
% since $\lam_J \ge \gamma \mu J$

% ----------------

{\bf 1st choice}
\[
\lam_j = \gamma \frac{j}{\sqrt{J}} \left( 1 + \mu \sqrt{j} \right)  \quad \forall j \ge 1
\]
Using the above definition and the fact that $\tau_j \le 1$, we have
\[
\sqrt{J} \lam_{j+1} = \gamma \sqrt{j+1}\left( 1 + \mu \sqrt{j+1} \right) =
\gamma \sqrt{{\frac{j}{\tau_j}}} 
\left( 1 + \mu \sqrt{{\frac{j}{\tau_j}}} \right)
\le
\frac{1}{\tau_j} \gamma \sqrt{j} 
\left( 1 + \mu \sqrt{j} \right)
= \sqrt{J} \frac{\lam_j}{\tau_j}
\]
and hence that \eqref{eq:cond-cru'} holds.
Also, \eqref{eq:con-comp'} becomes
\begin{align*}
\alpha_j + L &=\frac{1}{\lam_j^\mu(1-\tau_j)} =
\frac{j+1}{\lam_j^\mu} 
= (j+1) \left( \mu + \frac{1}{\lam_j} \right)
\ge  (j+1) \mu +  \frac{j}{\lam_j}
\\
&=  (j+1) \mu +  \frac{\sqrt{J}}{\gamma (1+ \mu \sqrt{j})}
\ge (j+1) \mu +  \frac{\sqrt{J}}{\gamma  (1+ \mu \sqrt{J})}
\end{align*}
Take
\[
\gamma :=\frac{\sqrt{J}}{L(1+\mu \sqrt{J})}
\]
Then
\[
\alpha_j + L \ge 
(j+1) \mu +  \frac{\sqrt{J}}{\gamma  (1+ \mu \sqrt{J})} =
(j+1) \mu + L
\]
and hence that
\[
\alpha_j \ge (j+1) \mu %+ L ( \sqrt{j}-1 )
\]
Also,
\[
\lam_J = \gamma \sqrt{J} \left( 1 + \mu \sqrt{J} \right) = \frac{J}{L}
\]


% \[
% j+1 = \frac{1}{1-\tau_j} \ge \lam_j^\mu(L+\alpha_j) = \frac{\lam_j}{1+\lam_j\mu} (L+\alpha_j)
% \]
% Since $\lam_j/(1+\lam_j\mu) \le 1/\mu$,  a sufficient condition for
% \eqref{eq:con-comp'} is
% \[
% j+1 \ge (L+\alpha_j)/\mu
% \]
% or
% \[
% \alpha_j \le \mu (j+1) -L
% \]


{\bf 2nd choice}
\[
\lam_j = \gamma \sqrt{j} \left( 1 + \mu \sqrt{j} \right)  \quad \forall j \ge 1
\]
Using the above definition and the fact that $\tau_j \le 1$, we have
\[
\lam_{j+1} = \gamma \sqrt{j+1}\left( 1 + \mu \sqrt{j+1} \right) =
\gamma \sqrt{{\frac{j}{\tau_j}}} 
\left( 1 + \mu \sqrt{{\frac{j}{\tau_j}}} \right)
\le
\frac{1}{\tau_j} \gamma \sqrt{j} 
\left( 1 + \mu \sqrt{j} \right)
= \frac{\lam_j}{\tau_j}
\]
and hence that \eqref{eq:cond-cru'} holds. Also, \eqref{eq:con-comp'} becomes
\begin{align*}
\alpha_j + L &=\frac{1}{\lam_j^\mu(1-\tau_j)} =
\frac{j+1}{\lam_j^\mu} 
= (j+1) \left( \mu + \frac{1}{\lam_j} \right)
\ge  (j+1) \mu +  \frac{j}{\lam_j}
\\&=  (j+1) \mu +  \frac{j}{\gamma \sqrt{j} (1+ \mu \sqrt{j})}
\ge
(j+1) \mu +  \frac{\sqrt{j}}{\gamma  (1+ \mu \sqrt{j})} \\
&\ge (j+1) \mu +  \frac{\sqrt{j}}{\gamma  (1+ \mu \sqrt{J})}
\end{align*}
Take
\[
\gamma :=\frac{1}{L(1+\mu \sqrt{J})}
\]
Then
\[
\alpha_j + L \ge 
(j+1) \mu +  \frac{\sqrt{j}}{\gamma  (1+ \mu \sqrt{J})} =
(j+1) \mu + L \sqrt{j}
\]
and hence
\[
\alpha_j \ge (j+1) \mu + L ( \sqrt{j}-1 )
\]
Also,
\[
\lam_J = \gamma \sqrt{J} \left( 1 + \mu \sqrt{J} \right) = \frac{\sqrt{J}}{L}
\]
% or
% \[
% \left( \mu + \frac{1}{\lam_j} \right) (j+1) \ge L + \alpha_j
% \]
% Now take
% \[
% \gamma = \frac{L }
% \]
% Since $\lam_j/(1+\lam_j\mu) \le 1/\mu$,  a sufficient condition for
% \eqref{eq:con-comp'} is
% \[
% j+1 \ge (L+\alpha_j)/\mu
% \]
% or
% \[
% \alpha_j \le \mu (j+1) -L
% \]

\subsection{Deterministic case (strongly convex case - Again)}

Let $\lam>0$ and $\Gamma \le \phi$ be given
and set
\[
x = \argmin \left \{ \Gamma(u) + \frac{1}{2\lam} \|u-x_0\|^2 \right\}
\]
\[
m = \min \left \{ \Gamma(u) + \frac{1}{2\lam} \|u-x_0\|^2 \right\}
\]
Update
\[
\Gamma^+ = \tau \Gamma + (1-\tau) \ell_\phi(\cdot;x)
\]
and assume that 
\beq \label{eq:cond-cru'}
\lam^+ \le \frac{\lam}{\tau}
\eeq
Have
\begin{align*}
    m^+ &= \Gamma^+(x^+) + \frac{1}{2\lam^+} \|x^+-x_0\|^2 \\
    &=\tau \Gamma(x^+) + (1-\tau) \ell_\phi(x^+;x) + \frac{1}{2\lam^+} \|x^+-x_0\|^2 \\
   \mbox{(due to \eqref{eq:cond-cru'})} \ \ &\ge \tau \left [  \Gamma(x^+) + \frac{1}{2\lam} \|x^+-x_0\|^2 \right] + (1-\tau) \ell_\phi(x^+;x)  \\
    &\ge \tau \left [  \Gamma(x) + \frac{1}{2\lam} \|x-x_0\|^2 + \frac{1}{2\lam_\mu} \|x^+-x\|^2  \right] + (1-\tau) \ell_\phi(x^+;x)  \\
    &= \tau \left [  m + \frac{1}{2\lam_\mu} \|x^+-x\|^2  \right] + (1-\tau) \ell_\phi(x^+;x)
\end{align*}
where
\[
\frac{1}{\lam_\mu} := \frac1\lam + \mu \ge \mu
\]
Assume
\beq \label{eq:con-comp''}
\alpha:= \frac{1}{\lam_\mu(1-\tau)} -L > 0
\eeq
Hence,
\begin{align*}
    m^+ - \tau m &\ge \frac{1}{2\lam_\mu} \|x^+-x\|^2  + (1-\tau) \ell_\phi(x^+;x) \\
    &= \frac{1}{2\lam_\mu} \|x^+-x\|^2  + (1-\tau) \phi(x^+) - (1-\tau) [\phi(x^+)-\ell_\phi(x^+;x) ] \\
    &\ge \frac{1}{2\lam_\mu} \|x^+-x\|^2  + (1-\tau) \phi(x^+) - (1-\tau)  \left [  2M \|x^+-x\| + \frac{L}2 \|x^+-x\|^2 \right ]
     \\
     &= (1-\tau) \left[
    \phi(x^+) -  2M \|x^+-x\| + \frac12 \left(\frac{1}{(1-\tau)\lam_\mu} - L \right) \|x^+-x\|^2
    \right ] \\
 \mbox{(due to \eqref{eq:con-comp'})} \ \    &\ge  (1-\tau) \left[
    \phi(x^+) -  2M \|x^+-x\| + \frac{\alpha}2  \|x^+-x\|^2
    \right ] \\
     &\ge (1-\tau) \left[ \phi(x^+) -
     \frac{2M^2}{\alpha} \right]
\end{align*}
Thus
\begin{align*}
    t^+- \tau t &= [ \phi(y^+)-m^+] -
\tau [ \phi(y) - m] =
[ \phi(y^+)-\tau  \phi(y)] - [m^+-\tau m] \\
&\le [ \phi(y^+)-\tau  \phi(y) - (1-\tau) \phi(x^+) ] + \frac{2 (1-\tau) M^2}{\alpha} \\
&\le  \frac{2 (1-\tau) M^2}{\alpha} 
% \le \frac{2 (1-\tau)^2 M^2} \mu
\end{align*}
Indexing the above equation, we conclude that
\begin{align}
    t_{j+1} - \tau_j t_j \le \frac{2 (1-\tau_j) M^2 }{\alpha_j}
    % \frac{2 (1-\tau_j)^2 M^2} \mu
     \label{eq:recurv-st-conv}
\end{align}
Assume that
\[
\tau_j = \frac{\tau j}{\tau j+1} \quad \forall j \ge 1
\]
Multiplying \eqref{eq:recurv-st-conv} by $\tau j+1$, we then conclude that
\[
(\tau j+1) t_{j+1} - \tau j t_j \le
\frac{2M^2}{\alpha_j}
\]
and hence that
\[
J t_J - t_1 \le 2 M^2 \Gamma_k
\]
where
\[
\Gamma_k := \sum_{j=1}^{J-1} \frac{1}{\alpha_j}
\]
Thus
\begin{align*}
    \frac{t_1 + 2 M^2 \Gamma_k}{J}  &\ge t_J = 
\phi(y_J) - \left[ \Gamma_J(x_J) + \frac{1}{2 \lam_J} \|x_J-x_0\|^2 \right] \\
&\ge \phi(y_J) - \left[ \Gamma_J(x_*) + \frac{1}{2 \lam_J} \|x_*-x_0\|^2 - \frac{1}{2 \lam_J^\mu} \|x_*-x_J\|^2 \right] \\
&\ge \phi(y_J) - \left[ \phi(x_*) + \frac{1}{2 \lam_J} \|x_*-x_0\|^2 - \frac{1}{2 \lam_J^\mu} \|x_*-x_J\|^2 \right]
\end{align*}
so that
\begin{align*}
   \phi(y_J) - \phi(x_*)
&\le \frac{t_1+2 M^2 \Gamma_k}{J} 
 + \frac{1}{2 \lam_J} \|x_*-x_0\|^2 -
\frac{1}{2 \lam_J^\mu} \|x_*-x_J\|^2 \\
&\le \frac{t_1+2 M^2 \Gamma_k}{J} 
 + \frac{d_0^2}{2 \lam_J}
\end{align*}

% -------------------

% \begin{align*}
%    \phi(y_J) - \phi(x_*)
% &\le \frac{t_1}{J} +\frac{ M^2 \log J}{\mu J}
%  + \frac{1}{2 \lam_J} \|x_*-x_0\|^2 -
% \frac{1}{2 \lam_J^\mu} \|x_*-x_J\|^2 \\
% &\le \frac{t_1}{J} +\frac{ M^2 \log J}{\mu J}
%  + \frac{1}{2 \gamma \mu J} \|x_*-x_0\|^2
% \end{align*}
% since $\lam_J \ge \gamma \mu J$

% ----------------

{\bf 1st choice}
\[
\lam_j = \gamma \frac{j}{\sqrt{J}} \left( 1 + \mu \sqrt{j} \right)  \quad \forall j \ge 1
\]
Using the above definition and the fact that $\tau_j \le 1$, we have
\[
\sqrt{J} \lam_{j+1} = \gamma \sqrt{j+1}\left( 1 + \mu \sqrt{j+1} \right) =
\gamma \sqrt{{\frac{j}{\tau_j}}} 
\left( 1 + \mu \sqrt{{\frac{j}{\tau_j}}} \right)
\le
\frac{1}{\tau_j} \gamma \sqrt{j} 
\left( 1 + \mu \sqrt{j} \right)
= \sqrt{J} \frac{\lam_j}{\tau_j}
\]
and hence that \eqref{eq:cond-cru'} holds.
Also, \eqref{eq:con-comp'} becomes
\begin{align*}
\alpha_j + L &=\frac{1}{\lam_j^\mu(1-\tau_j)} =
\frac{j+1}{\lam_j^\mu} 
= (j+1) \left( \mu + \frac{1}{\lam_j} \right)
\ge  (j+1) \mu +  \frac{j}{\lam_j}
\\
&=  (j+1) \mu +  \frac{\sqrt{J}}{\gamma (1+ \mu \sqrt{j})}
\ge (j+1) \mu +  \frac{\sqrt{J}}{\gamma  (1+ \mu \sqrt{J})}
\end{align*}
Take
\[
\gamma :=\frac{\sqrt{J}}{L(1+\mu \sqrt{J})}
\]
Then
\[
\alpha_j + L \ge 
(j+1) \mu +  \frac{\sqrt{J}}{\gamma  (1+ \mu \sqrt{J})} =
(j+1) \mu + L
\]
and hence that
\[
\alpha_j \ge (j+1) \mu %+ L ( \sqrt{j}-1 )
\]
Also,
\[
\lam_J = \gamma \sqrt{J} \left( 1 + \mu \sqrt{J} \right) = \frac{J}{L}
\]


% \[
% j+1 = \frac{1}{1-\tau_j} \ge \lam_j^\mu(L+\alpha_j) = \frac{\lam_j}{1+\lam_j\mu} (L+\alpha_j)
% \]
% Since $\lam_j/(1+\lam_j\mu) \le 1/\mu$,  a sufficient condition for
% \eqref{eq:con-comp'} is
% \[
% j+1 \ge (L+\alpha_j)/\mu
% \]
% or
% \[
% \alpha_j \le \mu (j+1) -L
% \]


{\bf 2nd choice}
\[
\lam_j = \gamma \sqrt{j} \left( 1 + \mu \sqrt{j} \right)  \quad \forall j \ge 1
\]
Using the above definition and the fact that $\tau_j \le 1$, we have
\[
\lam_{j+1} = \gamma \sqrt{j+1}\left( 1 + \mu \sqrt{j+1} \right) =
\gamma \sqrt{{\frac{j}{\tau_j}}} 
\left( 1 + \mu \sqrt{{\frac{j}{\tau_j}}} \right)
\le
\frac{1}{\tau_j} \gamma \sqrt{j} 
\left( 1 + \mu \sqrt{j} \right)
= \frac{\lam_j}{\tau_j}
\]
and hence that \eqref{eq:cond-cru'} holds. Also, \eqref{eq:con-comp'} becomes
\begin{align*}
\alpha_j + L &=\frac{1}{\lam_j^\mu(1-\tau_j)} =
\frac{j+1}{\lam_j^\mu} 
= (j+1) \left( \mu + \frac{1}{\lam_j} \right)
\ge  (j+1) \mu +  \frac{j}{\lam_j}
\\&=  (j+1) \mu +  \frac{j}{\gamma \sqrt{j} (1+ \mu \sqrt{j})}
\ge
(j+1) \mu +  \frac{\sqrt{j}}{\gamma  (1+ \mu \sqrt{j})} \\
&\ge (j+1) \mu +  \frac{\sqrt{j}}{\gamma  (1+ \mu \sqrt{J})}
\end{align*}
Take
\[
\gamma :=\frac{1}{L(1+\mu \sqrt{J})}
\]
Then
\[
\alpha_j + L \ge 
(j+1) \mu +  \frac{\sqrt{j}}{\gamma  (1+ \mu \sqrt{J})} =
(j+1) \mu + L \sqrt{j}
\]
and hence
\[
\alpha_j \ge (j+1) \mu + L ( \sqrt{j}-1 )
\]
Also,
\[
\lam_J = \gamma \sqrt{J} \left( 1 + \mu \sqrt{J} \right) = \frac{\sqrt{J}}{L}
\]



% -----------

% So, we conclude that
% \[
% J t_J - t_1 \le 2 M^2 \sum_{j=1}^{J-1} \frac{\lam_j^\mu}{j+1} \le \frac{2  M^2}{\mu} \sum_{j=1}^{J-1} \frac{1}{j+1} \approx \frac{ M^2}{\mu} \log J
% \]
% Hence
% \[
% t_J \le \frac{t_1}{J} +
% \frac{ M^2 \log J}{\mu J}
% \]

% Now, choose
% \[
% \lam_j = \gamma \frac{j}{\sqrt{J}} \left( 1 + \mu  \frac{j}{\sqrt{J}}\right)  \quad \forall j \ge 1
% \]


% Assume that $I$ and $C_1$ are such that
% \[
% \alpha= \frac{C_1}{2I} < 1
% \]
% Assume also that $\frac{j-1}{j}$ satisfies
% \[
% \frac{1-\frac{j-1}{j}}{1+\frac{j-1}{j}} = \alpha 
% \]
% or equivalently,
% \[
% \frac{j-1}{j} = \frac{1-\alpha}{1+\alpha}
% \]
% and hence
% \[
% 1-\frac{j-1}{j} = \frac{2\alpha}{1+\alpha}
% \]
% Then
% \[
% \frac{j-1}{j}^I + \frac{1-\frac{j-1}{j}}{1+\frac{j-1}{j}}
% = \frac{j-1}{j}^I + \alpha = \frac{j-1}{j}^I + \frac{C_1}{2I}
% \]
% Now
% \[
% \log (\frac{j-1}{j}^I ) = I \log \frac{j-1}{j}
% \le I(\frac{j-1}{j}-1)
% \]
% So
% if
% \[
% I (\frac{j-1}{j}-1) \le \log \alpha \quad (*) 
% \]
% then
% \[
% \frac{j-1}{j}^I + \frac{1-\frac{j-1}{j}}{1+\frac{j-1}{j}}
% = \frac{j-1}{j}^I + \alpha \le 2 \alpha = \frac{C_1}{I}
% \]
% Now $(*)$ is equivalent to
% \[
% I  \ge \frac{1}{j}^{-1} \log \alpha^{-1}
% = \frac{1+\alpha}{2\alpha} \log \alpha^{-1}
% \]
% Since $\alpha<1$, a sufficient condition for the above to hold is that
% \[
% I  \ge \frac{1}{\alpha} \log \alpha^{-1} = \alpha^{-1} \log \alpha^{-1} = \frac{2I}{C_1} 
% \log \left(\frac{2I}{C_1} \right)
% \]
% or equivalently,
% \[
% 1 \ge \frac{2}{C_1} 
% \log \left(\frac{2I}{C_1} \right)
% \]
% So we can also assume that
% $C_1$ and $I$ satisfy the above condition. There are many ways to satisfy this condition, e.g., $C_1$ and $I$ such that
% \[
% C_1 = 2 \log I, \quad C_1 \ge 2
% \]
% Also
% \begin{align*}
%     t_{I} &\le 2Md_0\frac{j-1}{j}^{I-1}  + \frac{\frac{1}{j}\lam_j M^2}{\frac{j-1}{j}} \\
%     &= \frac{2Md_0\frac{j-1}{j}^{I}  + \frac{1}{j}\lam_j M^2}{\frac{j-1}{j}} \\
%     &\le \frac{2Md_0\alpha  + \frac{1}{j}\lam_j M^2}{\frac{j-1}{j}} \\
%     &= \alpha \frac{2Md_0  + 2(1+\alpha)^{-1}\lam_j M^2}{\frac{j-1}{j}} \\
%     &\le 2\alpha \frac{Md_0  +\lam_j M^2}{\frac{j-1}{j}} \\
%     &\le 2\alpha(1+\alpha) \frac{Md_0  +\lam_j M^2}{1-\alpha}
% \end{align*}
\section{Dual averaging analysis}
\subsection{convex case}








\end{document}