@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}

% clip
@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

% resnet
@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

% vit
@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

% datasets
@inproceedings{sultani2018real,
  title={Real-world anomaly detection in surveillance videos},
  author={Sultani, Waqas and Chen, Chen and Shah, Mubarak},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6479--6488},
  year={2018}
}

@inproceedings{karpathy2014large,
  title={Large-scale video classification with convolutional neural networks},
  author={Karpathy, Andrej and Toderici, George and Shetty, Sanketh and Leung, Thomas and Sukthankar, Rahul and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={1725--1732},
  year={2014}
}

@article{perera2020multiviewpoint,
  title={A multiviewpoint outdoor dataset for human action recognition},
  author={Perera, Asanka G and Law, Yee Wei and Ogunwa, Titilayo T and Chahl, Javaan},
  journal={IEEE Transactions on Human-Machine Systems},
  volume={50},
  number={5},
  pages={405--413},
  year={2020},
  publisher={IEEE}
}

@inproceedings{shao2020finegym,
  title={Finegym: A hierarchical video dataset for fine-grained action understanding},
  author={Shao, Dian and Zhao, Yue and Dai, Bo and Lin, Dahua},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={2616--2625},
  year={2020}
}

@article{sigurdsson2018charades,
  title={Charades-ego: A large-scale dataset of paired third and first person videos},
  author={Sigurdsson, Gunnar A and Gupta, Abhinav and Schmid, Cordelia and Farhadi, Ali and Alahari, Karteek},
  journal={arXiv preprint arXiv:1804.09626},
  year={2018}
}

@inproceedings{zhao2019hacs,
  title={Hacs: Human action clips and segments dataset for recognition and temporal localization},
  author={Zhao, Hang and Torralba, Antonio and Torresani, Lorenzo and Yan, Zhicheng},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={8668--8678},
  year={2019}
}

@inproceedings{das2019toyota,
  title={Toyota smarthome: Real-world activities of daily living},
  author={Das, Srijan and Dai, Rui and Koperski, Michal and Minciullo, Luca and Garattoni, Lorenzo and Bremond, Francois and Francesca, Gianpiero},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={833--842},
  year={2019}
}

@inproceedings{rohrbach2012database,
  title={A database for fine grained activity detection of cooking activities},
  author={Rohrbach, Marcus and Amin, Sikandar and Andriluka, Mykhaylo and Schiele, Bernt},
  booktitle={2012 IEEE conference on computer vision and pattern recognition},
  pages={1194--1201},
  year={2012},
  organization={IEEE}
}

@inproceedings{wu2020not,
  title={Not only look, but also listen: Learning multimodal violence detection under weak supervision},
  author={Wu, Peng and Liu, Jing and Shi, Yujia and Sun, Yujia and Shao, Fangtao and Wu, Zhaoyang and Yang, Zhiwei},
  booktitle={European conference on computer vision},
  pages={322--339},
  year={2020},
  organization={Springer}
}

@article{denkovski2022multi,
  title={Multi Visual Modality Fall Detection Dataset},
  author={Denkovski, Stefan and Khan, Shehroz S and Malamis, Brandon and Moon, Sae Young and Ye, Bing and Mihailidis, Alex},
  journal={IEEE Access},
  year={2022},
  publisher={IEEE}
}

@inproceedings{li2021grounded,
      title={Grounded Language-Image Pre-training},
      author={Liunian Harold Li* and Pengchuan Zhang* and Haotian Zhang* and Jianwei Yang and Chunyuan Li and Yiwu Zhong and Lijuan Wang and Lu Yuan and Lei Zhang and Jenq-Neng Hwang and Kai-Wei Chang and Jianfeng Gao},
      year={2022},
      booktitle={CVPR},
}

@inproceedings{tang2019coin,
  title={Coin: A large-scale dataset for comprehensive instructional video analysis},
  author={Tang, Yansong and Ding, Dajun and Rao, Yongming and Zheng, Yu and Zhang, Danyang and Zhao, Lili and Lu, Jiwen and Zhou, Jie},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1207--1216},
  year={2019}
}

@inproceedings{dallel2020inhard,
  title={Inhard-industrial human action recognition dataset in the context of industrial collaborative robotics},
  author={Dallel, Mejdi and Havard, Vincent and Baudry, David and Savatier, Xavier},
  booktitle={2020 IEEE International Conference on Human-Machine Systems (ICHMS)},
  pages={1--6},
  year={2020},
  organization={IEEE}
}

@inproceedings{ragusa2021meccano,
  title={The meccano dataset: Understanding human-object interactions from egocentric videos in an industrial-like domain},
  author={Ragusa, Francesco and Furnari, Antonino and Livatino, Salvatore and Farinella, Giovanni Maria},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={1569--1578},
  year={2021}
}

@article{huaulme2021micro,
  title={MIcro-surgical anastomose workflow recognition challenge report},
  author={Huaulm{\'e}, Arnaud and Sarikaya, Duygu and Le Mut, K{\'e}vin and Despinoy, Fabien and Long, Yonghao and Dou, Qi and Chng, Chin-Boon and Lin, Wenjun and Kondo, Satoshi and Bravo-S{\'a}nchez, Laura and others},
  journal={Computer Methods and Programs in Biomedicine},
  volume={212},
  pages={106452},
  year={2021},
  publisher={Elsevier}
}

@article{huaulme2022peg,
  title={PEg TRAnsfer Workflow recognition challenge report: Does multi-modal data improve recognition?},
  author={Huaulm{\'e}, Arnaud and Harada, Kanako and Nguyen, Quang-Minh and Park, Bogyu and Hong, Seungbum and Choi, Min-Kook and Peven, Michael and Li, Yunshuang and Long, Yonghao and Dou, Qi and others},
  journal={arXiv preprint arXiv:2202.05821},
  year={2022}
}

@inproceedings{materzynska2019jester,
  title={The jester dataset: A large-scale video dataset of human gestures},
  author={Materzynska, Joanna and Berger, Guillaume and Bax, Ingo and Memisevic, Roland},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops},
  pages={0--0},
  year={2019}
}

@inproceedings{li2020word,
  title={Word-level deep sign language recognition from video: A new large-scale dataset and methods comparison},
  author={Li, Dongxu and Rodriguez, Cristian and Yu, Xin and Li, Hongdong},
  booktitle={Proceedings of the IEEE/CVF winter conference on applications of computer vision},
  pages={1459--1469},
  year={2020}
}

@inproceedings{li2021uav,
  title={Uav-human: A large benchmark for human behavior understanding with unmanned aerial vehicles},
  author={Li, Tianjiao and Liu, Jun and Zhang, Wei and Ni, Yun and Wang, Wenqian and Li, Zhiheng},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={16266--16275},
  year={2021}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@inproceedings{carreira2017quo,
  title={Quo vadis, action recognition? a new model and the kinetics dataset},
  author={Carreira, Joao and Zisserman, Andrew},
  booktitle={proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6299--6308},
  year={2017}
}

@inproceedings{goyal2017something,
  title={The" something something" video database for learning and evaluating visual common sense},
  author={Goyal, Raghav and Ebrahimi Kahou, Samira and Michalski, Vincent and Materzynska, Joanna and Westphal, Susanne and Kim, Heuna and Haenel, Valentin and Fruend, Ingo and Yianilos, Peter and Mueller-Freitag, Moritz and others},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={5842--5850},
  year={2017}
}

@inproceedings{feichtenhofer2016convolutional,
  title={Convolutional two-stream network fusion for video action recognition},
  author={Feichtenhofer, Christoph and Pinz, Axel and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1933--1941},
  year={2016}
}

@inproceedings{wang2016temporal,
  title={Temporal segment networks: Towards good practices for deep action recognition},
  author={Wang, Limin and Xiong, Yuanjun and Wang, Zhe and Qiao, Yu and Lin, Dahua and Tang, Xiaoou and Van Gool, Luc},
  booktitle={European conference on computer vision},
  pages={20--36},
  year={2016},
  organization={Springer}
}

@inproceedings{lin2019tsm,
  title={Tsm: Temporal shift module for efficient video understanding},
  author={Lin, Ji and Gan, Chuang and Han, Song},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={7083--7093},
  year={2019}
}

@article{kay2017kinetics,
  title={The kinetics human action video dataset},
  author={Kay, Will and Carreira, Joao and Simonyan, Karen and Zhang, Brian and Hillier, Chloe and Vijayanarasimhan, Sudheendra and Viola, Fabio and Green, Tim and Back, Trevor and Natsev, Paul and others},
  journal={arXiv preprint arXiv:1705.06950},
  year={2017}
}

@inproceedings{feichtenhofer2019slowfast,
  title={Slowfast networks for video recognition},
  author={Feichtenhofer, Christoph and Fan, Haoqi and Malik, Jitendra and He, Kaiming},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={6202--6211},
  year={2019}
}

@inproceedings{bertasius2021space,
  title={Is space-time attention all you need for video understanding?},
  author={Bertasius, Gedas and Wang, Heng and Torresani, Lorenzo},
  booktitle={ICML},
  volume={2},
  number={3},
  pages={4},
  year={2021}
}

@inproceedings{liu2022video,
  title={Video swin transformer},
  author={Liu, Ze and Ning, Jia and Cao, Yue and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Hu, Han},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3202--3211},
  year={2022}
}

@inproceedings{qian2021spatiotemporal,
  title={Spatiotemporal contrastive video representation learning},
  author={Qian, Rui and Meng, Tianjian and Gong, Boqing and Yang, Ming-Hsuan and Wang, Huisheng and Belongie, Serge and Cui, Yin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6964--6974},
  year={2021}
}

@article{han2020self,
  title={Self-supervised co-training for video representation learning},
  author={Han, Tengda and Xie, Weidi and Zisserman, Andrew},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={5679--5690},
  year={2020}
}

@article{zhai2019visual,
  title={The visual task adaptation benchmark},
  author={Zhai, Xiaohua and Puigcerver, Joan and Kolesnikov, Alexander and Ruyssen, Pierre and Riquelme, Carlos and Lucic, Mario and Djolonga, Josip and Pinto, Andre Susano and Neumann, Maxim and Dosovitskiy, Alexey and others},
  year={2019}
}

@inproceedings{gupta2019lvis,
  title={Lvis: A dataset for large vocabulary instance segmentation},
  author={Gupta, Agrim and Dollar, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={5356--5364},
  year={2019}
}

@article{li2022elevater,
  title={ELEVATER: A Benchmark and Toolkit for Evaluating Language-Augmented Visual Models},
  author={Li, Chunyuan and Liu, Haotian and Li, Liunian Harold and Zhang, Pengchuan and Aneja, Jyoti and Yang, Jianwei and Jin, Ping and Lee, Yong Jae and Hu, Houdong and Liu, Zicheng and others},
  journal={arXiv preprint arXiv:2204.08790},
  year={2022}
}

@inproceedings{thoker2022severe,
  author    = {Thoker, Fida Mohammad and Doughty, Hazel and Bagad, Piyush and Snoek, Cees},
  title     = {How Severe is Benchmark-Sensitivity in Video Self-Supervised Learning?},
  journal   = {ECCV},
  year      = {2022},
}

@inproceedings{wang2019towards,
  title={Towards universal object detection by domain attention},
  author={Wang, Xudong and Cai, Zhaowei and Gao, Dashan and Vasconcelos, Nuno},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={7289--7298},
  year={2019}
}

@article{gupta2022grit,
  title={GRIT: General Robust Image Task Benchmark},
  author={Gupta, Tanmay and Marten, Ryan and Kembhavi, Aniruddha and Hoiem, Derek},
  journal={arXiv preprint arXiv:2204.13653},
  year={2022}
}

@inproceedings{duan2016benchmarking,
  title={Benchmarking deep reinforcement learning for continuous control},
  author={Duan, Yan and Chen, Xi and Houthooft, Rein and Schulman, John and Abbeel, Pieter},
  booktitle={International conference on machine learning},
  pages={1329--1338},
  year={2016},
  organization={PMLR}
}

@article{zhu2020comprehensive,
  title={A comprehensive study of deep video action recognition},
  author={Zhu, Yi and Li, Xinyu and Liu, Chunhui and Zolfaghari, Mohammadreza and Xiong, Yuanjun and Wu, Chongruo and Zhang, Zhi and Tighe, Joseph and Manmatha, R and Li, Mu},
  journal={arXiv preprint arXiv:2012.06567},
  year={2020}
}

@article{kong2022human,
  title={Human action recognition and prediction: A survey},
  author={Kong, Yu and Fu, Yun},
  journal={International Journal of Computer Vision},
  volume={130},
  number={5},
  pages={1366--1401},
  year={2022},
  publisher={Springer}
}

@article{ren2015faster,
  title={Faster r-cnn: Towards real-time object detection with region proposal networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@inproceedings{long2015fully,
  title={Fully convolutional networks for semantic segmentation},
  author={Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3431--3440},
  year={2015}
}

@inproceedings{tran2015learning,
  title={Learning spatiotemporal features with 3d convolutional networks},
  author={Tran, Du and Bourdev, Lubomir and Fergus, Rob and Torresani, Lorenzo and Paluri, Manohar},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={4489--4497},
  year={2015}
}

@article{simonyan2014two,
  title={Two-stream convolutional networks for action recognition in videos},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@inproceedings{tran2018closer,
  title={A closer look at spatiotemporal convolutions for action recognition},
  author={Tran, Du and Wang, Heng and Torresani, Lorenzo and Ray, Jamie and LeCun, Yann and Paluri, Manohar},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={6450--6459},
  year={2018}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{caron2021emerging,
  title={Emerging properties in self-supervised vision transformers},
  author={Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\'e}gou, Herv{\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9650--9660},
  year={2021}
}

@article{soomro2012ucf101,
  title={UCF101: A dataset of 101 human actions classes from videos in the wild},
  author={Soomro, Khurram and Zamir, Amir Roshan and Shah, Mubarak},
  journal={arXiv preprint arXiv:1212.0402},
  year={2012}
}

@INPROCEEDINGS{hmdb51,  author={Kuehne, H. and Jhuang, H. and Garrote, E. and Poggio, T. and Serre, T.},  booktitle={2011 International Conference on Computer Vision},   title={HMDB: A large video database for human motion recognition},   year={2011},  volume={},  number={},  pages={2556-2563},  doi={10.1109/ICCV.2011.6126543}}

@INPROCEEDINGS{sports1m,
  author={Karpathy, Andrej and Toderici, George and Shetty, Sanketh and Leung, Thomas and Sukthankar, Rahul and Fei-Fei, Li},
  booktitle={2014 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={Large-Scale Video Classification with Convolutional Neural Networks}, 
  year={2014},
  volume={},
  number={},
  pages={1725-1732},
  doi={10.1109/CVPR.2014.223}}
  
@inproceedings{miech2019howto100m,
  title={Howto100m: Learning a text-video embedding by watching hundred million narrated video clips},
  author={Miech, Antoine and Zhukov, Dimitri and Alayrac, Jean-Baptiste and Tapaswi, Makarand and Laptev, Ivan and Sivic, Josef},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2630--2640},
  year={2019}
}

@article{hpo,
  title={Hyper-parameter optimization: A review of algorithms and applications},
  author={Yu, Tong and Zhu, Hong},
  journal={arXiv preprint arXiv:2003.05689},
  year={2020}
}

@article{nas,
  author  = {Thomas Elsken and Jan Hendrik Metzen and Frank Hutter},
  title   = {Neural Architecture Search: A Survey},
  journal = {Journal of Machine Learning Research},
  year    = {2019},
  volume  = {20},
  number  = {55},
  pages   = {1--21},
  url     = {http://jmlr.org/papers/v20/18-598.html}
}

@article{tong2022videomae,
  title={Videomae: Masked autoencoders are data-efficient learners for self-supervised video pre-training},
  author={Tong, Zhan and Song, Yibing and Wang, Jue and Wang, Limin},
  journal={arXiv preprint arXiv:2203.12602},
  year={2022}
}

@inproceedings{lee2017unsupervised,
  title={Unsupervised representation learning by sorting sequences},
  author={Lee, Hsin-Ying and Huang, Jia-Bin and Singh, Maneesh and Yang, Ming-Hsuan},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={667--676},
  year={2017}
}

@inproceedings{han2019video,
  title={Video representation learning by dense predictive coding},
  author={Han, Tengda and Xie, Weidi and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops},
  pages={0--0},
  year={2019}
}

@inproceedings{epstein2020oops,
  title={Oops! predicting unintentional action in video},
  author={Epstein, Dave and Chen, Boyuan and Vondrick, Carl},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={919--929},
  year={2020}
}

@inproceedings{wang2018non,
  title={Non-local neural networks},
  author={Wang, Xiaolong and Girshick, Ross and Gupta, Abhinav and He, Kaiming},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7794--7803},
  year={2018}
}

@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10012--10022},
  year={2021}
}

@inproceedings{liu2022convnet,
  title={A convnet for the 2020s},
  author={Liu, Zhuang and Mao, Hanzi and Wu, Chao-Yuan and Feichtenhofer, Christoph and Darrell, Trevor and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11976--11986},
  year={2022}
}

@inproceedings{feichtenhofer2020x3d,
  title={X3d: Expanding architectures for efficient video recognition},
  author={Feichtenhofer, Christoph},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={203--213},
  year={2020}
}


@inproceedings{grauman2022ego4d,
  title={Ego4d: Around the world in 3,000 hours of egocentric video},
  author={Grauman, Kristen and Westbury, Andrew and Byrne, Eugene and Chavis, Zachary and Furnari, Antonino and Girdhar, Rohit and Hamburger, Jackson and Jiang, Hao and Liu, Miao and Liu, Xingyu and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18995--19012},
  year={2022}
}

@article{k600,
  title={A short note about kinetics-600},
  author={Carreira, Joao and Noland, Eric and Banki-Horvath, Andras and Hillier, Chloe and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1808.01340},
  year={2018}
}

@article{k700,
  title={A short note on the kinetics-700 human action dataset},
  author={Carreira, Joao and Noland, Eric and Hillier, Chloe and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1907.06987},
  year={2019}
}

@article{vgg,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@inproceedings{resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{zhu2018hidden,
  title={Hidden two-stream convolutional networks for action recognition},
  author={Zhu, Yi and Lan, Zhenzhong and Newsam, Shawn and Hauptmann, Alexander},
  booktitle={Asian conference on computer vision},
  pages={363--378},
  year={2018},
  organization={Springer}
}

@inproceedings{p3d,
  title={Learning spatio-temporal representation with pseudo-3d residual networks},
  author={Qiu, Zhaofan and Yao, Ting and Mei, Tao},
  booktitle={proceedings of the IEEE International Conference on Computer Vision},
  pages={5533--5541},
  year={2017}
}

@inproceedings{s3d,
  title={Rethinking spatiotemporal feature learning: Speed-accuracy trade-offs in video classification},
  author={Xie, Saining and Sun, Chen and Huang, Jonathan and Tu, Zhuowen and Murphy, Kevin},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={305--321},
  year={2018}
}

@inproceedings{eco,
  title={Eco: Efficient convolutional network for online video understanding},
  author={Zolfaghari, Mohammadreza and Singh, Kamaljeet and Brox, Thomas},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={695--712},
  year={2018}
}

@inproceedings{arnab2021vivit,
  title={Vivit: A video vision transformer},
  author={Arnab, Anurag and Dehghani, Mostafa and Heigold, Georg and Sun, Chen and Lu{\v{c}}i{\'c}, Mario and Schmid, Cordelia},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={6836--6846},
  year={2021}
}

@inproceedings{zhang2021vidtr,
  title={Vidtr: Video transformer without convolutions},
  author={Zhang, Yanyi and Li, Xinyu and Liu, Chunhui and Shuai, Bing and Zhu, Yi and Brattoli, Biagio and Chen, Hao and Marsic, Ivan and Tighe, Joseph},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={13577--13587},
  year={2021}
}

@inproceedings{rhomoco,
  title={A large-scale study on unsupervised spatiotemporal representation learning},
  author={Feichtenhofer, Christoph and Fan, Haoqi and Xiong, Bo and Girshick, Ross and He, Kaiming},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3299--3309},
  year={2021}
}

@inproceedings{videomoco,
  title={Videomoco: Contrastive video representation learning with temporally adversarial examples},
  author={Pan, Tian and Song, Yibing and Yang, Tianyu and Jiang, Wenhao and Liu, Wei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11205--11214},
  year={2021}
}

@inproceedings{vclr,
  title={Video contrastive learning with global context},
  author={Kuang, Haofei and Zhu, Yi and Zhang, Zhi and Li, Xinyu and Tighe, Joseph and Schwertfeger, S{\"o}ren and Stachniss, Cyrill and Li, Mu},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3195--3204},
  year={2021}
}

@article{fbvideomae,
  title={Masked Autoencoders As Spatiotemporal Learners},
  author={Feichtenhofer, Christoph and Fan, Haoqi and Li, Yanghao and He, Kaiming},
  journal={arXiv preprint arXiv:2205.09113},
  year={2022}
}
  
@article{ding2021motion,
  title={Motion-aware Self-supervised Video Representation Learning via Foreground-background Merging},
  author={Ding, Shuangrui and Li, Maomao and Yang, Tianyu and Qian, Rui and Xu, Haohang and Chen, Qingyi and Wang, Jue},
  journal={arXiv preprint arXiv:2109.15130},
  year={2021}
}

@inproceedings{epickitchen,
  title={Scaling egocentric vision: The epic-kitchens dataset},
  author={Damen, Dima and Doughty, Hazel and Farinella, Giovanni Maria and Fidler, Sanja and Furnari, Antonino and Kazakos, Evangelos and Moltisanti, Davide and Munro, Jonathan and Perrett, Toby and Price, Will and others},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={720--736},
  year={2018}
}

@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@article{ruder2016overview,
  title={An overview of gradient descent optimization algorithms},
  author={Ruder, Sebastian},
  journal={arXiv preprint arXiv:1609.04747},
  year={2016}
}

@article{wang2021actionclip,
  title={Actionclip: A new paradigm for video action recognition},
  author={Wang, Mengmeng and Xing, Jiazheng and Liu, Yong},
  journal={arXiv preprint arXiv:2109.08472},
  year={2021}
}

@inproceedings{chen2019temporal,
  title={Temporal attentive alignment for large-scale video domain adaptation},
  author={Chen, Min-Hung and Kira, Zsolt and AlRegib, Ghassan and Yoo, Jaekwon and Chen, Ruxin and Zheng, Jian},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={6321--6330},
  year={2019}
}

@article{sahoo2021contrast,
  title={Contrast and mix: Temporal contrastive video domain adaptation with background mixing},
  author={Sahoo, Aadarsh and Shah, Rutav and Panda, Rameswar and Saenko, Kate and Das, Abir},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={23386--23400},
  year={2021}
}

@inproceedings{he2020momentum,
  title={Momentum contrast for unsupervised visual representation learning},
  author={He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={9729--9738},
  year={2020}
}

@inproceedings{ganin2015unsupervised,
  title={Unsupervised domain adaptation by backpropagation},
  author={Ganin, Yaroslav and Lempitsky, Victor},
  booktitle={International conference on machine learning},
  pages={1180--1189},
  year={2015},
  organization={PMLR}
}

@inproceedings{roberto2017procedural,
  title={Procedural generation of videos to train deep action recognition networks},
  author={Roberto de Souza, Cesar and Gaidon, Adrien and Cabon, Yohann and Manuel Lopez, Antonio},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4757--4767},
  year={2017}
}

@inproceedings{pan2020adversarial,
  title={Adversarial cross-domain action recognition with co-attention},
  author={Pan, Boxiao and Cao, Zhangjie and Adeli, Ehsan and Niebles, Juan Carlos},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={07},
  pages={11815--11822},
  year={2020}
}

@inproceedings{newell2020useful,
  title={How useful is self-supervised pretraining for visual tasks?},
  author={Newell, Alejandro and Deng, Jia},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7345--7354},
  year={2020}
}

@inproceedings{inception,
  title={Going deeper with convolutions},
  author={Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1--9},
  year={2015}
}

@misc{2020mmaction2,
    title={OpenMMLab's Next Generation Video Understanding Toolbox and Benchmark},
    author={MMAction2 Contributors},
    howpublished = {\url{https://github.com/open-mmlab/mmaction2}},
    year={2020}
}

@inproceedings{text4vis,
  title={Revisiting Classifier: Transferring Vision-Language Models for Video Recognition},
  author={Wu, Wenhao and Sun, Zhun and Ouyang, Wanli},
  booktitle=AAAI,
  year={2023}
}

@inproceedings{wu2021mvfnet,
  title={Mvfnet: Multi-view fusion network for efficient video recognition},
  author={Wu, Wenhao and He, Dongliang and Lin, Tianwei and Li, Fu and Gan, Chuang and Ding, Errui},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={4},
  pages={2943--2951},
  year={2021}
}

@inproceedings{wu2019multi,
  title     = {Multi-Agent Reinforcement Learning Based Frame Sampling for Effective Untrimmed Video Recognition},
  author    = {Wu, Wenhao and He, Dongliang and Tan, Xiao and Chen, Shifeng and Wen, Shilei},
  booktitle = ICCV,
  year      = {2019}
}

@inproceedings{nsnet,
  title={NSNet: Non-saliency Suppression Sampler for Efficient Video Recognition},
  author={Xia, Boyang and Wu, Wenhao and Wang, Haoran and Su, Rui and He, Dongliang and Yang, Haosen and Fan, Xiaoran and Ouyang, Wanli},
  booktitle=ECCV,
  pages={705--723},
  year={2022}
}

@inproceedings{tsqnet,
  title={Temporal Saliency Query Network for Efficient Video Recognition},
  author={Xia, Boyang and Wang, Zhihao and Wu, Wenhao and Wang, Haoran and Han, Jungong},
  booktitle=ECCV,
  pages={741--759},
  year={2022}
}

@inproceedings{
yang2023aim,
title={{AIM}: Adapting Image Models for Efficient Video Action Recognition},
author={Taojiannan Yang and Yi Zhu and Yusheng Xie and Aston Zhang and Chen Chen and Mu Li},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=CIoSZ_HKHS7}
}

@article{yang2021mutualnet,
  title={MutualNet: Adaptive convnet via mutual learning from different model configurations},
  author={Yang, Taojiannan and Zhu, Sijie and Mendieta, Matias and Wang, Pu and Balakrishnan, Ravikumar and Lee, Minwoo and Han, Tao and Shah, Mubarak and Chen, Chen},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={45},
  number={1},
  pages={811--827},
  year={2021},
  publisher={IEEE}
}

@inproceedings{hu2021signbert,
  title={Signbert: pre-training of hand-model-aware representation for sign language recognition},
  author={Hu, Hezhen and Zhao, Weichao and Zhou, Wengang and Wang, Yuechen and Li, Houqiang},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={11087--11096},
  year={2021}
}

@inproceedings{truong2022direcformer,
  title={Direcformer: A directed attention in transformer approach to robust action recognition},
  author={Truong, Thanh-Dat and Bui, Quoc-Huy and Duong, Chi Nhan and Seo, Han-Seok and Phung, Son Lam and Li, Xin and Luu, Khoa},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={20030--20040},
  year={2022}
}

@inproceedings{cheng2020skeleton,
  title={Skeleton-based action recognition with shift graph convolutional network},
  author={Cheng, Ke and Zhang, Yifan and He, Xiangyu and Chen, Weihan and Cheng, Jian and Lu, Hanqing},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={183--192},
  year={2020}
}

@article{das2021vpn++,
  title={Vpn++: Rethinking video-pose embeddings for understanding activities of daily living},
  author={Das, Srijan and Dai, Rui and Yang, Di and Bremond, Francois},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={44},
  number={12},
  pages={9703--9717},
  year={2021},
  publisher={IEEE}
}

@article{li2022uniformerv2,
  title={UniFormerV2: Spatiotemporal Learning by Arming Image ViTs with Video UniFormer},
  author={Li, Kunchang and Wang, Yali and He, Yinan and Li, Yizhuo and Wang, Yi and Wang, Limin and Qiao, Yu},
  journal={arXiv preprint arXiv:2211.09552},
  year={2022}
}

@inproceedings{tran2019video,
  title={Video classification with channel-separated convolutional networks},
  author={Tran, Du and Wang, Heng and Torresani, Lorenzo and Feiszli, Matt},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5552--5561},
  year={2019}
}