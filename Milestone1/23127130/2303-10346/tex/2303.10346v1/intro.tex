
\section{Introduction}
\label{sec:intro}

6D object pose estimation, i.e. determining the 3D rotation and translation of a object in the camera coordinate system, is an important computer vision task with a large body of literature~\cite{brachmann2014learning,wang2019densefusion,labbe2020cosypose,li2018deepim}.
Category-level object pose estimation attempts to solve the problem without relying on the exact CAD model of the target object~\cite{wang2019normalized}, which is hence more challenging than instance-level one.
Since the seminal work of Wang et al.~\cite{wang2019normalized}, most existing category-level works are based on a canonical representation of Normalized Object Coordinate Space (NOCS). Given an unseen object instance, they learn a neural network to map the perspective projection of the object to the NOCS of the corresponding category from which object pose can be estimated.

%Existing works have demonstrated that NOCS-based methods are able to achieve satisfactory results on some categories of household objects.
Given an object category, NOCS is defined by globally aligning a set of 3D object instances with normalized size and poses. It works well for objects with moderate intra-category shape variations.
When handling object categories containing significant shape variations,
% or complex symmetry structures,
however, NOCS-based methods become inaccurate and less robust.
This is because the object coordinates induced by global and rigid alignment are not semantically coherent. For instance, a point on the lens of a long-lens camera would be mapped to a semantically incorrect point in NOCS if the NOCS was constructed with camera models of significantly varying part proportions. Such misalignment makes the mapping network hard to learn and generalize, thus causing inferior pose accuracy under large shape variations (\Fig{teaser}).
%Since NOCS only provides rough correspondences, the shape correspondences are learned with suboptimal supervision, making pose estimation based on them inferior in accuracy and weak in generality.
%Most of the recent works explore the idea of learning the categorical prior (e.g. the averaging shape of a category). Based on the learned categorical prior, they are able to determine the dense shape correspondence between objects, leading to satisfactory results in some categories of household objects.

\input{figures/teaser}

To tackle this issue, we propose Semantically-aware Object Coordinate Space (SOCS) to achieve accurate and robust category-level 6D object pose and size estimation under large shape variations.
Unlike NOCS which is constructed by directly aligning pose and size normalized objects of a specific category, SOCS is built by \emph{warping-and-aligning the objects guided by a sparse set of keypoints with semantically meaningful correspondence}, leveraging the state-of-the-art category-specific keypoint selection and matching for a shape set~\cite{shi2021skeleton}. In particular, we align all objects of a specific category in the training set to the \emph{mean shape}~\cite{tian2020shape} of the set. We utilize 3D thin-plate spline warping~\cite{duchon1977splines} to ensure a smooth non-rigid deformation and hence coordinate interpolation. SOCS is therefore semantically coherent: Any point on the surface of a object can be mapped to a semantically meaningful location in SOCS, allowing for accurate pose and size estimation.

%To tackle the above problem, we propose shape correspondence field, a new representation of the canonical coordinate system for category-level 6D pose estimation. Unlike NOCS which normalizes the objects into the canonical coordinate with rigid transformations, the proposed shape correspondence field aligns the objects with non-rigid transformations by leveraging the category-specific keypoints, resulting in a semantic meaningful category-aligned canonical space. The shape correspondence field is natural and effective for the learning of intra-class semantic consistency within a category. See Fig.~\ref{fig:teaser} for an illustration.

%Moreover, we propose a category-level 6D pose estimation method based on the shape correspondence field implemented with an implicit network.
To learn the mapping from image space to SOCS effectively, we propose a novel multi-scale coordinate-based attention network. %\kx{let me know if you have a better name}.
To capture the shape variation of the target object in image space, we devise a multi-scale feature extraction network with cross-attention feature aggregation.
In the cross-attention module, we encode global point positions to help better extract coordinate-sensitive features. Thanks to such global positional encoding, our network is able to model 3D points in the full space, which further enables a dense point sampling in SOCS training. The letter facilitates dense coordinate estimation even for unobserved locations, which is critical to handling inter-object occlusions.
To attain pose invariance, the network is trained in a contrastive fashion with a pose consistency loss.
%To this end, we first develop a novel aggregation-querying network for point cloud processing. Given an input point cloud, it first fed into the aggregation layers for feature extraction. The querying network enables outputs at any location besides those of the input points. Specifically, it takes a point coordinate along with the feature encoding the input points, and outputs the canonical location of the point in the shape correspondence field. By densely sampling points in the 3D space, the aggregation-querying network is able to make point-wise estimations on the unseen locations, providing more information to reduce the uncertainty of the estimated object pose. The network is trained in a Siamese fashion with a feature consistency loss to better extract the pose-invariant feature of input point clouds.

We conducted extensive evaluations demonstrating that our method is
1) easy to train,
2) well-generalizing for large intra-category shape variations, and 3) robust to inter-object occlusions.
Even with the vanilla mapping network of~\cite{wang2019normalized}, our method is still comparable to state of the arts, clearly showing the effectiveness of SOCS.
%Our full method achieves state-of-the-art on a new dataset of objects with novel geometry and complex symmetry and the competitive performance on the CAMERA25/ REAL275 dataset.
Our full method achieves state-of-the-art on the NOCS-REAL275 and ModelNet40-partial datasets, improving the $5^{\circ}5$cm score by $5.6\%$ on NOCS-REAL275 and $5^{\circ}0.05$ score by $16\%$ on ModelNet40-partial.
In particular, ModelNet40-partial contains categories containing objects with large shape variations.


% for symmetry, we propose polar ...
% for the learning of intra-class consistency, we propose ANOCS estimation at invisible locations
% refine, distribution
% stochastic optimization


In summary, our work makes two contributions. \emph{First}, we propose semantically-aligned object coordinate space (SOCS) to accommodate large intra-category shape variations for semantically coherent coordinate regression. \emph{Second}, we propose a multi-scale attention network for learning the mapping from image space to SOCS effectively allowing for dense coordinate regression.

\if 0
\begin{itemize}
  \vspace{-6pt}
  \item We propose semantically-aligned object coordinate space (SOCS) to accommodate large intra-category shape variations for semantically coherent coordinate regression.
  \vspace{-6pt}
  \item We propose a multi-scale attention network for learning the mapping from image space to SOCS effectively allowing for dense coordinate regression.
  %\vspace{-8pt}
  %\item We show that our method generalizes well to intra-category unseen objects and achieves performance almost on par with the state-of-the-art fully supervised methods on the category-level NOCS benchmark.
  %\vspace{-8pt}
\end{itemize}
\fi 