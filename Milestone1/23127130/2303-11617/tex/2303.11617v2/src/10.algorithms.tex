\subsection{Mesh extraction}
\label{app:algo_mesh}

In this section, we provide more detail on the way to construct an adapted mesh to a neural network based on a \ac{cpwl} approximation of its activation function, as described in \alg{adaptiveMesh}. We recall the notations introduced in \sect{adaptivity}.

Suppose that $\pi[u_k]_{|R}$ is a linear linear map from $R \subset \RR^d$ to $\RR^m$ and has the expression $\pi[u_k]_{|R}: \pmb{x} \mapsto \pmb{W}_R \pmb{x} + \pmb{b}_R$. For $1 \leq i \leq m$, we write $\pmb{W}_{R, i}$ and $\pmb{b}_{R, i}$ the $i$-th row of $\pmb{W}$ and $\pmb{b}$. Let $\pi[\rho]$ be a \ac{cpwl} function from $\RR$ to $\RR$ that we apply element-wise on the coordinates of $\pi[u_k]_{|R}$, and let $(\xi_j)_{1 \leq j \leq K}$ denote the breakpoints of $\pi[\rho]$. We also introduce the local coefficients $(\alpha_j, \beta_j)$ of $\pi[\rho]$ such that the restriction of $\pi[\rho]$ to $\cc{\xi_j}{\xi_{j+1}}$ has the expression $x \mapsto \alpha_j x + \beta_j$.

To identify the regions where $\pi[\rho] \circ \pi[u_k]_{|R}$ is linear, we need to consider the equations $\pmb{W}_{R, i} \pmb{x} + \pmb{b}_{R, i} = \xi_j$ for all $1 \leq i \leq m$ and $1 \leq j \leq K$. These hyperplanes intersect in $R$ and define subregions adapted to $\pi[\rho] \circ \pi[u_k]_{|R}$. This is the step that corresponds to $\mathtt{cutRegion}$ in \alg{adaptiveMesh}. We now present specific algorithms to define these subregions in dimensions zero, one and two.

\subsubsection{Dimensions zero and one}
\label{app:algo_mesh_cut_01}

In dimension zero, a region is reduced to one single point so nothing needs to be done. In the one-dimensional case, $R$ is a segment that we write $\cc{p_-}{p_+}$. We first compute the range of each linear map $h_i: x \mapsto w_i x + b_i$ on $R$ by computing their values at $p_-$ and $p_+$. We then find which breakpoints $\xi_j$ belong to that range via a binary search, and we compute the corresponding antecedents $p_{i, j}$ of $\xi_j$ by $h_i$ with normalised coordinates as follows
\[p_{i, j} = \frac{1}{2} (p_- + p_+) + \frac{t_{i, j}}{2} (p_+ - p_-), \qquad t_{i, j} = \frac{2 \xi_j - (h_i(p_+) + h_i(p_-))}{h_i(p_+) - h_i(p_-)} \in \cc{-1}{+1}.\]
We found this formulation more numerically stable compared to expressing $p_{i, j}$ in terms of $w_i$, $b_i$ and $\xi_j$. We sort the normalised coordinates $t_{i, j}$ and obtain the corresponding sorted abscissae $(p_l)$. For each segment $\cc{p_l}{p_{l+1}}$, we evaluate the linear maps $h_i$ at $\frac{1}{2} (p_l + p_{l+1})$ and retrieve the coefficients $(\alpha_{l, i}, \beta_{l, i})$ of $\pi[\rho]$ at this location to update the local expression $(\pmb{W}_R, \pmb{b}_R)$ into $(\mathrm{diag}(\pmb{\alpha}_l) \pmb{W}_R, \mathrm{diag}(\pmb{\alpha}_l) \pmb{b}_R + \pmb{\beta}_l)$.

\subsubsection{Dimension two}
\label{app:algo_mesh_cut_2}

The two-dimensional case is much more involved as the hyperplanes are lines that can intersect with the boundary of $R$ and among one another. We consider four steps.

    {\itshape (i) Intersection of the hyperplanes with $\partial R$} Since $R$ is a convex polygon, each hyperplane $h_i: \pmb{x} \mapsto \pmb{w}_i \pmb{x} + b_i$ can intersect with $\partial R$ at two points at most. If the number of intersections is zero or one, then $R$ lies entirely on one side of the hyperplane thus we only need to handle the case when there are two intersection points. One notable corner case occurs when the hyperplane coincides with an edge of the polygon. In this degenerate case, the region is not cut.

The clipping of a line by a convex polygon can be done in logarithmic time, using a method akin to binary search. We refer the reader to \cite{skala1994} for the full algorithm. We write $(P_{i, j}^-, P_{i, j}^+)$ the clipping of $h_i$ by $R$, and $(P_l)$ the collection of these vertices.

    {\itshape (ii) Intersection of the hyperplanes among themselves.} Next, we check the intersection of pairwise combinations of the lines obtained above. It is important to note that for a fixed row $i$, the lines $(P_{i, j}^-, P_{i, j}^+)$ are parallel. Indeed, they are solutions to $\pmb{w}_i \pmb{x} + b_i = \xi$ for two different values of $\xi$. This means that we can skip the tests corresponding to lines arising from the same row. Let $i_1 \neq i_2$ be two different row indices, $j_1$ and $j_2$ be two breakpoint indices, and suppose that $(P_{i_1, j_1}^-, P_{i_1, j_1}^+)$ and $(P_{i_2, j_2}^-, P_{i_2, j_2}^+)$ are two non-parallel lines. We compute their intersection $Q$ via the following parametrisation and solve for $s$ and $t$:
\[Q = \overline{P}_{i_1, j_1} + s \Delta P_{i_1, j_1} = \overline{P}_{i_2, j_2} + t \Delta P_{i_2, j_2}, \qquad \begin{bmatrix} \Delta P_{i_1, j_1} & -\Delta P_{i_2, j_2} \end{bmatrix} \begin{bmatrix} s \\ t \end{bmatrix} = \begin{bmatrix} \overline{P}_1 - \overline{P}_2 \end{bmatrix},\]
where $\overline{P}_{i, j} = \frac{1}{2}(P_{i, j}^- + P_{i, j}^+)$ is the middle of the segment and $\Delta P_{i, j} = \frac{1}{2}(P_{i, j}^+ - P_{i, j}^-)$ is half the direction vector. We need to check that $s$ and $t$ are between $-1$ and $+1$.

    {\itshape (iii) Representation of these intersections as an adjacency graph.} We initialise a connectivity graph with the edges of the region $R$. During step {\itshape (i)}, for each line $(P_{i, j}^-, P_{i, j}^+)$ that cuts the polygon, we add the points $P_{i, j}^-$ and $P_{i, j}^+$ to the edges they belong to, and add an arc in the graph, that connects these two points. During step {\itshape (ii)}, we only need to add new vertices to the graph.

    {\itshape (iv) Extraction of the smallest cycles in this graph.} Finding the partition of $R$ where the composition by $\pi[\rho]$ is \ac{cpwl} amounts to finding the fundamental cycle basis of the undirected graph defined above. We refer to \cite{kavitha2009} for a definition of the fundamental cycle basis of a planar graph and for an algorithm to build it.

\begin{algorithm}
    \caption{$\mathtt{adaptiveMesh}(u)$}
    \label{alg:adaptiveMesh}
    \begin{algorithmic}
        \State $\tau \gets [(\Omega, \pmb{I}_d, \pmb{0}_d)]$
        \For{$\ell \in \mathtt{layers}(u)$}
        \State $\pmb{W} \gets \mathtt{weight}(\ell), \quad \pmb{b} \gets \mathtt{bias}(\ell), \quad \tau^{\text{new}} \gets \varnothing$
        \For{$(R, \pmb{W}_R, \pmb{b}_R) \in \tau$}
        \State $\pmb{W}_R^{\text{new}} \gets \pmb{W} \times \pmb{W}_R, \quad \pmb{b}_R^{\text{new}} \gets \pmb{W} \times\pmb{b}_R + \pmb{b}$ \Comment{Compose by linear map}
        \For{$(S, \pmb{W}_S, \pmb{b}_S) \in \mathtt{cutRegion}(\pi[\rho], R, \pmb{W}_R^{\text{new}}, \pmb{b}_R^{\text{new}})$} \Comment{See \app{algo_mesh_cut_01} and \app{algo_mesh_cut_2}.}
        \State $(\pmb{\alpha}, \pmb{\beta}) \gets \mathtt{coefficients}(\pi[\rho], S)$ \Comment{Retrieve local coefficients of $\pi[\rho]$ in $s$}
        \State $\pmb{W}_S^{\text{new}} \gets \mathtt{diag}(\pmb{\alpha}) \times \pmb{W}_S, \quad \pmb{b}_S^{\text{new}} \gets \mathtt{diag}(\pmb{\alpha}) \times \pmb{b}_S + \pmb{\beta}$ \Comment{Compose by $\pi[\rho]$}
        \State $\tau^{\text{new}} \gets \tau^{\text{new}} \cup \{(S, \pmb{W}_S^{\text{new}}, \pmb{b}_S^{\text{new}})\}$
        \EndFor
        \EndFor
        \State $\tau \gets \tau^{\text{new}}$
        \EndFor
        \State \Return $\tau$
    \end{algorithmic}
\end{algorithm}

\subsubsection{Notes on the algorithm}

In \alg{adaptiveMesh}, $\mathtt{weight}(\ell)$ and $\mathtt{bias}(\ell)$ denote the parameters of the network at layer $\ell$. The instruction $\mathtt{coefficients}$ is just a lookup operation to retrieve the local coefficients of $\pi[\rho]$. Here its output are vectors because the local map on a region is vector-valued. Finally if $\pmb{\alpha}$ is a vector, $\mathtt{diag}(\pmb{\alpha})$ is the diagonal matrix whose diagonal coefficients are $\pmb{\alpha}$.

\subsection{Decomposition of convex polygons}
\label{app:algo_polygon}

In the general two-dimensional case, the cells of the mesh adapted to $u$ are arbitrary convex polygons. Numerical quadrature rules are known for triangles and convex quadrangles, so we decide to split the cells into a collection of these two reference shapes. We encode hard rules to decompose convex polygons with up to ten vertices into triangles and convex quadrangles. For example, an octagon is split into one triangle and two quadrangles by considering the three cycles $(1, 2, 3, 4)$, $(4, 5, 6, 7)$, $(7, 8, 1, 4)$. Larger polygons are recursively split in half until they have fewer than ten vertices.