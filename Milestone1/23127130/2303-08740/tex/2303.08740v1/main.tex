\documentclass{article}



\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}		% Can be removed after putting your text content
\usepackage{graphicx}
%\usepackage{natbib}
\usepackage{doi}



\title{2D and 3D CNN-Based Fusion approach for COVID-19 Severity Prediction From 3D CT-Scans}

%\date{September 9, 1985}	% Here you can change the date presented in the paper title
%\date{} 					% Or removing it


\author{ \href{https://sciprofiles.com/profile/FaresBougourzi}{\includegraphics[scale=0.06]{orcid.pdf}\hspace{1mm}Fares BOUGOURZI}
\thanks{.} \\
University Paris-Est Creteil, Laboratoire LISSI, 94400 \\Vitry sur Seine, Paris, France \\
	\texttt{faresbougourzi@gmail.com} \\
	%% examples of more authors
	\And
	\href{https://orcid.org/0000-0000-0000-0000}{\includegraphics[scale=0.06]{orcid.pdf}\hspace{1mm}Fadi DORNAIKA} \\
	University of the Basque Country UPV/EHU,\\
	San Sebastian, SPAIN; IKERBASQUE, Basque \\ Foundation for Science, Bilbao, SPAIN \\
	\texttt{fadi.dornaika@ehu.eus} \\  
 	%% examples of more authors
	\And
	\href{https://orcid.org/0000-0000-0000-0000}{\includegraphics[scale=0.06]{orcid.pdf}\hspace{1mm}Amir Nakib} \\
	University Paris-Est Creteil, Laboratoire LISSI,\\ 94400 Vitry sur Seine, Paris, France \\
	\texttt{nakib@u-pec.fr} \\ 
	%% examples of more authors 
	\And
	\href{https://orcid.org/0000-0000-0000-0000}{\includegraphics[scale=0.06]{orcid.pdf}\hspace{1mm}Cosimo Distante} \\
	Institute of Applied Sciences and Intelligent\\ Systems, National Research Council of Italy,\\ 73100 Lecce, Italy \\ Department of Innovation Engineering, University \\of Salento, 73100 Lecce, Italy \\
	\texttt{cosimo.distante@cnr.it} \\	
	%% examples of more authors
	\And
	\href{https://orcid.org/0000-0000-0000-0000}{\includegraphics[scale=0.06]{orcid.pdf}\hspace{1mm}Abdelmalik Taleb-Ahmed} \\
	IEMN UMR CNRS 8520, Université \\Polytechnique Hauts de France, UPHF\\
	\texttt{Abdelmalik.Taleb-Ahmed@uphf.fr} \\
	%% \AND
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
	%% \And
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
	%% \And
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
}

% Uncomment to remove the date
%\date{}

% Uncomment to override  the `A preprint' in the header
%\renewcommand{\headeright}{Technical Report}
%\renewcommand{\undertitle}{Technical Report}
\renewcommand{\shorttitle}{\textit{arXiv} Template}

%%% Add PDF metadata to help others organize their library
%%% Once the PDF is generated, you can check the metadata with
%%% $ pdfinfo template.pdf
\hypersetup{
pdftitle={A template for the arxiv style},
pdfsubject={q-bio.NC, q-bio.QM},
pdfauthor={David S.~Hippocampus, Elias D.~Striatum},
pdfkeywords={First keyword, Second keyword, More},
}

\begin{document}
\maketitle

\begin{abstract}
Since the appearance of Covid-19 in late 2019, Covid-19 has become an active research topic for the artificial intelligence (AI) community. One of the most interesting AI topics is Covid-19 analysis of medical imaging. CT-scan imaging is the most informative tool about this disease. 

This work is part of the 3nd COV19D competition for Covid-19 Severity Prediction. In order to deal with the big gap between the validation and test results that were shown in the previous version of this competition, we proposed to combine the prediction of 2D and 3D CNN predictions. For the 2D CNN approach, we propose 2B-InceptResnet architecture which consists of two paths for segmented lungs and infection of all slices of the input CT-scan, respectively. Each path consists of ConvLayer and Inception-ResNet pretrained model on ImageNet.
For the 3D CNN approach, we propose  hybrid-DeCoVNet architecture which consists of four blocks: Stem, four 3D-ResNet layers, Classification Head and Decision layer.

Our proposed approaches outperformed the baseline approach in the validation data of the 3nd COV19D competition for Covid-19 Severity Prediction by 36\%.



\end{abstract}


% keywords can be removed
\keywords{Covid-19 \and Deep Leaning \and CNNs \and Recognition \and Severity }


\section{Introduction}
Since the appearance of the Covid-19 pandemic in the late of 2019, reverse transcription-polymerase chain reaction (RT-PCR) has been considered as the golden standards for Covid-19 Detection. However, the RT-PCR test has many drawbacks including inadequate supply of RT-PCR kits, time-consuming consumption, and considerable false negative results \cite{jin_rapid_2020, wu_jcs_2021, kucirka_variation_2020}. To deal with this limitations, Medical Imaging modalities have been widly used as supporting tools. These imaging modalities include X-rays and CT-scans \cite{vantaggiato2021covid,bougourzi_recognition_2021}. Indeed, CT-scans are not only used to detect Covid-19 infected cases, but they could be used to follow up the state of the patient and predicting the disease severity \cite{bougourzi_per-covid-19_2021, bougourzi_challenge_2021}.

In the last decade, Deep Learning methods have become dominant in most of the computer vision tasks and they have achieved high performance  compared to traditional methods \cite{bougourzi_fusing_2020, bougourzi_deep_2022}. However, the main drawback of deep learning, especially the CNN architecture is the need of huge labelled data, which is hard to be obtained in medical domains \cite{bougourzi_per-covid-19_2021}. On the other hand, most of the proposed CNN architectures adopted for Static images (single image input) \cite{bougourzi_challenge_2021}.

In this work, we proposed to combine the predictions of trained 3D and 2D CNN architectures for Covid-19 Severity Prediction from 3D CT-scans as part  of 3nd COV19D Competition. In order to deal with the big gap between the validation and test results that were shown in the previous version of this competition, we proposed to combine the prediction of 2D and 3D CNN predictions. For the 2D CNN approach, we propose 2B-InceptResnet architecture which consists of two paths for segmented lungs and infection of all slices of the input CT-scan, respectively. Each path consists of ConvLayer and Inception-ResNet pretrained model on ImageNet. For the 3D CNN approach, we propose  Hybrid-DeCoVNet architecture which consists of four blocks: Stem, four 3D-ResNet layers, Classification Head and Decision layer. 
The main contributions of this paper can be summarized as follows: 

\begin{itemize} 
\item We propose a combination trained 3D and 2D CNN architectures for Covid-19 severity prediction.

\item We propose 2B-InceptResnet architecture which consists of two paths for segmented lungs and infection, where this architecture aims to exploit pretrained weights on Imagenet.

\item We propose a Hybrid-DeCoVNet architecture for Covid-19 Severity Prediction.

\item The codes used and the pre-trained models are publicly available in \url{https://github.com/faresbougourzi/3rd-COV19D-Competition}. ( Last accessed on March, 15{$^{th}$} 2023).

\end{itemize}

This paper is organized in following way:  Section \ref{S:1} describes our proposed approaches for Covid-19 Detection and Severity Detection. The experiments and results are described in Section \ref{S:2}. Finally, we concluded our paper in Section \ref{S:3}.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Our Approaches}
\label{S:1}

In this paper, we summarize the obtained results COVID-19 Severity Detection Challenge, which is part of the 3rd COV19D Competition and held in conjunction with IEEE ICASSP 2023.

Table \ref{tab:oldcha} summarizes the results of the 2nd COV19D competition for Covid-19 Severity Prediction. As shown in this table, all of the proposed approaches performance considerably drop in the testing phase compared with the validation performance. The aim of this work is to reduce the overfitting and having more generalization ability. To this end, we trained models provided training and validation splits then we gathered all the data then we performed 5 Fold cross-validation. In the testing phase the ensemble of all models (trained on different data splitting) will be evaluated on the unseen testing data.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[h]
 \caption{2nd COV19D competition for Covid-19 Severity Prediction Results. }
\label{tab:oldcha}
\centering
\begin{tabular}{|p{3cm}|p{2cm}|p{2cm}|}
\hline

\textbf{Team}  & \textbf{Validation} &\textbf{Test}  \\\hline
 FDVTS \cite{hou2023boosting}&77.03&  51.76 \\ \hline 
 Code 1055 \cite{bougourzi2023cnr}&68.18 &  51.48\\ \hline
CNR-IEMN \cite{kienzle2023covid}& 80.08& 47.11  \\ \hline 
MDAP \cite{turnbull2023using}& 75.46 & 46.00 \\ \hline 
%MDAP \cite{tan2023two}&68.55  & 41.49 \\ \hline 
\end{tabular}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%\cite{hou2023boosting,bougourzi2023cnr, kienzle2023covid,turnbull2023using}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Data Preprocessing}
\label{sec:headings}

The aim of this phase is to remove the slices that do not show lungs at all and to detect the features inside the lung for the remaining slices. Since each 3D CT scans can have  multiple slices with no lung regions, we trained a ResneXt-50 model \cite{Resnext} to filter the non-lung slices and keep just the slices where the lung appears. To this end,  we manually labelled 20 CT-scans from the training data as lung and non-lung classes. Furthermore, three Covid-19 segmentation datasets are used: COVID-19 CT segmentation \cite{COVID-19-Dataset},  Segmentation dataset nr.2 \cite{COVID-19-Dataset}, and COVID-19- CT Seg dataset \cite{2021MedPh..48.1197M}. In the second preprocessing phase, we trained Attention-Unet \cite{oktay_attention_2018, bougourzi2022ilc}  architecture to segment the lungs and Covid-19 infection. The same datasets used for filtering the slices are used to train and validate the Attention-Unet architecture, where the three datasets are combined and randomly splited into train-val splits corresponding to 70-30\%, respectively. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{2D-based CNN architecture}
\label{sec:headings}
Inspired by our proposed  CNR-IEMN approach \cite{kienzle2023covid}, that were proposed for the 2nd COV19D challenge, we propose two branches Inception-Resnet architecture (2B-InceptResnet) as shown in Figure \ref{fig:approach}. After segmenting both the lung and Covid-19 infection from the filtred slices, each segmentation types slices are concatenated then resized into two volumes which have the shapes $299\times299\times32$ and $299\times299\times16$, respectively. The aim of resizing each volume into two size is to reduce the information loss due to resizing operation and having two views to the same input. Both the lungs and infection volumes are feed into a ConvLayer, which is depicted in Figure \ref{fig:approach2}, then the resulting tensor is feed to Inception-Resnet architecture. The last deep features from each path are concatenated then passed to two FC layer to predict the input CT-scans severity. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
\centering
    \includegraphics[width = 7in, height = 4in]{Severity.jpg} 
    \caption{Our proposed 2B-InceptResneth.}
    \label{fig:approach}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%[h]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
    \includegraphics[width = 5in, height = 1in]{Severity.pdf} 
    \caption{Our proposed ConvLayer block.}
    \label{fig:approach2}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%[h]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{3D-based CNN architecture}
\label{sec:headings}
Following the proposed DeCoVNet architecture in \cite{wang2020weakly}, we proposed the hybrid-DeCoVNet for Covid-19 Severity Prediction as shown in Figure \ref{fig:approach3}. The proposed Hybrid-DeCOVNet consists of four componets as show in Figure  \ref{fig:approach3}. First, the segmented lung and infection are concatenated to form two channels, then the concatenate segmented slices of each CT-scan are concatenated and resized into $224\times224\times2\times64$. The produced volume is feed into the first block of  hybrid-DeCoVNet, which is called Stem. The stem block is 3D convolutional layer with kernet (7, 7, 5) for the hight, width and depth, respectively. This convolutional kernel transforms the two input channels into 16 channels, and it is followed by Normalization Layer (BN) and ReLU activation function. The second block of Hybrid-DeCOVNet consists of four 3D-Resnet layers, that expands the channels into 64, 128, 256 and 512, respectively. The Classification Head consists of 3D Adaptive MaxPooling, three 3D concolutional layers, and 3D Global MaxPooling. The output of the Classification Head is flattened into one channel deep features map which is feed into Decision head that consists of one FC layer.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
\centering
    \includegraphics[width = 7in, height = 4in]{Severity3.jpg} 
    \caption{Our proposed hybrid-DeCoVNet Approach.}
    \label{fig:approach3}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%[h]


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experiments and Results}
\label{S:2}
\subsection{The COV19-CT-DB Database}
The COVID19-CT-Database (COV19-CT-DB) \cite{kollias2022ai, arsenos2022large, kollias2021mia, kollias2020deep, kollias2020transparent, kollias2018deep}  consists of chest CT scans that are annotated for the existence of COVID-19.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[h]
 \caption{Data samples in each Severity Class }
\label{tab:datasev}
\centering
\begin{tabular}{|p{2.5cm}|p{2cm}|p{2cm}|}
\hline

\textbf{Severity Class}  & \textbf{Training} &\textbf{Validation}  \\\hline
1. mild& 133 &  31 \\ \hline 
2. moderate& 124& 20\\ \hline
3. severe& 166& 45  \\ \hline 
4. critical& 39& 5 \\ \hline 

\end{tabular}
\end{table}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  

Further partitioning of the COVID-19 cases was based on the severity of COVID-19, which was given by four medical experts in a range of 1 to 4, with 4 denoting critical status. 
The training set contains a total of 462 3-D CT scans. The validation set consists of 101 3-D CT scans. The number of scans in each severity class  in these sets is shown in Table \ref{tab:datasev}.



\subsection{Experimental Setup}
For Deep Learning training and testing, we used the Pytorch \cite{paszke_pytorch_2019} Library with NVIDIA GPU Device GeForce TITAN RTX 24 GB. For the 2B-InceptResnet architecture training, the  used batch size consists of 16 CT-scan volumes and the architecture is trained for 40 epochs. The initial learning rate is 0.0001, which decreases by 0.1 after 15 epochs, followed by another 0.1 decrease after 30 epochs. The Hybrid-DeCOVNet is trained for 100 epochs since No pretrained weights are used. Both 2D and 3D CNN architectures are trained and tested on two scenarios: Train-Val and five folds cross validation. In the train and val scenario, we used the provided training and validation data by the 3rd COV19D organizers, in order to compare with the baseline results. To test the generalization ability of the proposed approach, we randomly splitted the combination of train and validation data in five folds.




\subsection{Results}
\label{sec:headings}

Table \ref{tab:Sevresult} and \ref{tab:Svfdcresult} summarize the results (F1 score) of detecting the severity of Covid-19 for train-val, and five folds cross validation scenarios, respectively. As described in section\ref{tab:Sevresult}, both the 2D and 3D approaches outperforms the baseline results by big margin, with small superiority for the 2D approach compared with the 3D approach. In addition, the combination of the two models predictions improves the results of the single architectures.
Similarly, Table \ref{tab:Svfdcresult} shows that the ensemble approach improves the results.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[ht]
 \caption{Covid-19 Severity Results on the Train-Val scenario. }
\label{tab:Sevresult}
\centering
\begin{tabular}{|p{1cm}|p{5cm}|c|}
\hline

\textbf{Model}  &\textbf{Architecture}  & \textbf{Macro F1-Score}   \\\hline
- &Baseline& 38.00  \\ \hline 
1&3D-DeconvNet &68.40 \\ \hline
2&TwoB-InceptRes (Base) & 72.96\\ \hline 
3&Ensemble (2D + 3D) & 74.16\\ \hline

\end{tabular}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[ht]
 \caption{Covid-19 Severity Results on the five folds cross validation scenario. }
\label{tab:Svfdcresult}
\centering
\begin{tabular}{|p{1cm}|p{5cm}|c|c|c|c|c|}
\hline

\textbf{Model}  &\textbf{Architecture}  & \textbf{Fold1}& \textbf{Fold2}& \textbf{Fold3}& \textbf{Fold4}& \textbf{Fold5}   \\\hline
 
1&3D-DeconvNet & 71.26& 65.07&69.50 &67.23&65.03\\ \hline
2&TwoB-InceptRes (Base) & 73.28& 66.50& 73.20&67.01&64.91\\ \hline
3&Ensemble (2D + 3D) & 73.44& 67.45& 73.24&68.56&65.55\\ \hline

\end{tabular}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}
\label{S:3}
In this work, we proposed an ensemble of 2D and 3D CNN-based approach for the 3nd COV19D competition for Covid-19 Severity Prediction. 
In order to deal with the big gap between the validation and test results that were shown in the previous version of this competition, we proposed to combine the prediction of 2D and 3D CNN predictions. For the 2D CNN approach, we propose 2B-InceptResnet architecture which consists of two paths for segmented lungs and infection of all slices of the input CT-scan, respectively. Each path consists of ConvLayer and Inception-ResNet pretrained model on ImageNet.
For the 3D CNN approach, we propose  hybrid-DeCoVNet architecture which consists of four blocks: Stem, four 3D-ResNet layers, Classification Head and Decision layer.

Our proposed approaches outperformed the baseline approach in the validation data of the 3nd COV19D competition for Covid-19 Severity Prediction by 36\%. In the testing phase, we will evaluate the ensemble performance of the trained 2D and 3D models using all splits.

%\bibliographystyle{unsrt}
%\bibliography{references}


\begin{thebibliography}{10}

\bibitem{jin_rapid_2020}
Ying-Hui Jin, Lin Cai, and Zhen-Shun et~al. Cheng.
\newblock A rapid advice guideline for the diagnosis and treatment of 2019
  novel coronavirus (2019-{nCoV}) infected pneumonia (standard version).
\newblock {\em Military Medical Research}, 7(1):4, February 2020.

\bibitem{wu_jcs_2021}
Yu-Huan Wu, Shang-Hua Gao, Jie Mei, Jun Xu, Deng-Ping Fan, Rong-Guo Zhang, and
  Ming-Ming Cheng.
\newblock {JCS}: {An} {Explainable} {COVID}-19 {Diagnosis} {System} by {Joint}
  {Classification} and {Segmentation}.
\newblock {\em IEEE Transactions on Image Processing}, 30:3113--3126, 2021.
\newblock Conference Name: IEEE Transactions on Image Processing.

\bibitem{kucirka_variation_2020}
Lauren~M. Kucirka, Stephen~A. Lauer, Oliver Laeyendecker, Denali Boon, and
  Justin Lessler.
\newblock Variation in {False}-{Negative} rate of reverse transcriptase
  polymerase chain {Reaction}–{Based} {SARS}-{CoV}-2 {Tests} by time since
  exposure.
\newblock {\em Annals of Internal Medicine}, 173(4):262--267, May 2020.
\newblock Publisher: American College of Physicians.

\bibitem{vantaggiato2021covid}
Edoardo Vantaggiato, Emanuela Paladini, Fares Bougourzi, Cosimo Distante,
  Abdenour Hadid, and Abdelmalik Taleb-Ahmed.
\newblock Covid-19 recognition using ensemble-cnns in two new chest x-ray
  databases.
\newblock {\em Sensors}, 21(5):1742, 2021.

\bibitem{bougourzi_recognition_2021}
Fares Bougourzi, Riccardo Contino, Cosimo Distante, and Abdelmalik Taleb-Ahmed.
\newblock Recognition of {COVID}-19 from {CT} {Scans} {Using} {Two}-{Stage}
  {Deep}-{Learning}-{Based} {Approach}: {CNR}-{IEMN}.
\newblock {\em Sensors}, 21(17):5878, January 2021.
\newblock Number: 17 Publisher: Multidisciplinary Digital Publishing Institute.

\bibitem{bougourzi_per-covid-19_2021}
Fares Bougourzi, Cosimo Distante, Abdelkrim Ouafi, Fadi Dornaika, Abdenour
  Hadid, and Abdelmalik Taleb-Ahmed.
\newblock Per-{COVID}-19: {A} {Benchmark} {Dataset} for {COVID}-19 {Percentage}
  {Estimation} from {CT}-{Scans}.
\newblock {\em Journal of Imaging}, 7(9):189, September 2021.
\newblock Number: 9 Publisher: Multidisciplinary Digital Publishing Institute.

\bibitem{bougourzi_challenge_2021}
Fares Bougourzi, Riccardo Contino, Cosimo Distante, and Abdelmalik Taleb-Ahmed.
\newblock Cnr-iemn: A deep learning based approach to recognise covid-19 from
  ct-scan.
\newblock In {\em ICASSP 2021-2021 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pages 8568--8572. IEEE, 2021.

\bibitem{bougourzi_fusing_2020}
F.~Bougourzi, F.~Dornaika, K.~Mokrani, A.~Taleb-Ahmed, and Y.~Ruichek.
\newblock Fusing {Transformed} {Deep} and {Shallow} features ({FTDS}) for
  image-based facial expression recognition.
\newblock {\em Expert Systems with Applications}, 156:113459, October 2020.

\bibitem{bougourzi_deep_2022}
F.~Bougourzi, F.~Dornaika, and A.~Taleb-Ahmed.
\newblock Deep learning based face beauty prediction via dynamic robust losses
  and ensemble regression.
\newblock {\em Knowledge-Based Systems}, 242:108246, April 2022.

\bibitem{hou2023boosting}
Junlin Hou, Jilan Xu, Nan Zhang, Yuejie Zhang, Xiaobo Zhang, and Rui Feng.
\newblock Boosting covid-19 severity detection with infection-aware contrastive
  mixup classification.
\newblock In {\em Computer Vision--ECCV 2022 Workshops: Tel Aviv, Israel,
  October 23--27, 2022, Proceedings, Part VII}, pages 537--551. Springer, 2023.

\bibitem{bougourzi2023cnr}
Fares Bougourzi, Cosimo Distante, Fadi Dornaika, and Abdelmalik Taleb-Ahmed.
\newblock Cnr-iemn-cd and cnr-iemn-csd approaches for covid-19 detection and
  covid-19 severity detection from 3d ct-scans.
\newblock In {\em Computer Vision--ECCV 2022 Workshops: Tel Aviv, Israel,
  October 23--27, 2022, Proceedings, Part VII}, pages 593--604. Springer, 2023.

\bibitem{kienzle2023covid}
Daniel Kienzle, Julian Lorenz, Robin Sch{\"o}n, Katja Ludwig, and Rainer
  Lienhart.
\newblock Covid detection and severity prediction with 3d-convnext and custom
  pretrainings.
\newblock In {\em Computer Vision--ECCV 2022 Workshops: Tel Aviv, Israel,
  October 23--27, 2022, Proceedings, Part VII}, pages 500--516. Springer, 2023.

\bibitem{turnbull2023using}
Robert Turnbull.
\newblock Using a 3d resnet for detecting the presence and severity of covid-19
  from ct scans.
\newblock In {\em Computer Vision--ECCV 2022 Workshops: Tel Aviv, Israel,
  October 23--27, 2022, Proceedings, Part VII}, pages 663--676. Springer, 2023.

\bibitem{Resnext}
Saining Xie, Ross Girshick, Piotr Dollár, Zhuowen Tu, and Kaiming He.
\newblock Aggregated residual transformations for deep neural networks, 2017.

\bibitem{COVID-19-Dataset}
RADIOLOGISTS.
\newblock {COVID-19 CT-scans segmentation datasets}, available at: {\url{
  http://medicalsegmentation.com/covid19/}}, 2019.
\newblock Last visited: 18-08-2021.

\bibitem{2021MedPh..48.1197M}
Jun Ma, Yixin Wang, Xingle An, Cheng Ge, Ziqi Yu, Jianan Chen, Qiongjie Zhu,
  Guoqiang Dong, Jian He, Zhiqiang He, Tianjia Cao, Yuntao Zhu, Ziwei Nie, and
  Xiaoping Yang.
\newblock Toward data efficient learning: {A} benchmark for {COVID} 19 {CT}
  lung and infection segmentation.
\newblock {\em Medical Physics}, 48:1197--1210, March 2021.
\newblock ADS Bibcode: 2021MedPh..48.1197M.

\bibitem{oktay_attention_2018}
Ozan Oktay, Jo~Schlemper, and Loic Le et~al. Folgoc.
\newblock Attention {U}-{Net}: {Learning} {Where} to {Look} for the {Pancreas}.
\newblock {\em arXiv:1804.03999 [cs]}, May 2018.
\newblock arXiv: 1804.03999.

\bibitem{bougourzi2022ilc}
Fares Bougourzi, Cosimo Distante, Fadi Dornaika, Abdelmalik Taleb-Ahmed, and
  Abdenour Hadid.
\newblock Ilc-unet++ for covid-19 infection segmentation.
\newblock In {\em Image Analysis and Processing. ICIAP 2022 Workshops: ICIAP
  International Workshops, Lecce, Italy, May 23--27, 2022, Revised Selected
  Papers, Part II}, pages 461--472. Springer, 2022.

\bibitem{wang2020weakly}
Xinggang Wang, Xianbo Deng, Qing Fu, Qiang Zhou, Jiapei Feng, Hui Ma, Wenyu
  Liu, and Chuansheng Zheng.
\newblock A weakly-supervised framework for covid-19 classification and lesion
  localization from chest ct.
\newblock {\em IEEE transactions on medical imaging}, 39(8):2615--2625, 2020.

\bibitem{kollias2022ai}
Dimitrios Kollias, Anastasios Arsenos, and Stefanos Kollias.
\newblock Ai-mia: Covid-19 detection \& severity analysis through medical
  imaging.
\newblock {\em arXiv preprint arXiv:2206.04732}, 2022.

\bibitem{arsenos2022large}
Anastasios Arsenos, Dimitrios Kollias, and Stefanos Kollias.
\newblock A large imaging database and novel deep neural architecture for
  covid-19 diagnosis.
\newblock In {\em 2022 IEEE 14th Image, Video, and Multidimensional Signal
  Processing Workshop (IVMSP)}, page 1–5. IEEE, 2022.

\bibitem{kollias2021mia}
Dimitrios Kollias, Anastasios Arsenos, Levon Soukissian, and Stefanos Kollias.
\newblock Mia-cov19d: Covid-19 detection through 3-d chest ct image analysis.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, page 537–544, 2021.

\bibitem{kollias2020deep}
Dimitrios Kollias, N~Bouas, Y~Vlaxos, V~Brillakis, M~Seferis, Ilianna Kollia,
  Levon Sukissian, James Wingate, and S~Kollias.
\newblock Deep transparent prediction through latent representation analysis.
\newblock {\em arXiv preprint arXiv:2009.07044}, 2020.

\bibitem{kollias2020transparent}
Dimitris Kollias, Y~Vlaxos, M~Seferis, Ilianna Kollia, Levon Sukissian, James
  Wingate, and Stefanos~D Kollias.
\newblock Transparent adaptation in deep medical image diagnosis.
\newblock In {\em TAILOR}, page 251–267, 2020.

\bibitem{kollias2018deep}
Dimitrios Kollias, Athanasios Tagaris, Andreas Stafylopatis, Stefanos Kollias,
  and Georgios Tagaris.
\newblock Deep neural architectures for prediction in healthcare.
\newblock {\em Complex \& Intelligent Systems}, 4(2):119–131, 2018.

\bibitem{paszke_pytorch_2019}
Adam Paszke, Sam Gross, and Francisco et~al. Massa.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In {\em Advances in neural information processing systems}, pages
  8026--8037, 2019.

\end{thebibliography}


\end{document}
