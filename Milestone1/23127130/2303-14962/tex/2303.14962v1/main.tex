%\documentclass[10pt,journal,compsoc]{IEEEtran}
\documentclass[journal, compsoc]{IEEEtran}

%\ifCLASSOPTIONcompsoc
%  \usepackage[nocompress]{cite}
%\else
%  \usepackage{cite}
%\fi

% *** GRAPHICS RELATED PACKAGES ***
%\ifCLASSINFOpdf
%\else
%\fi

% Recommended, but optional, packages for figures and better typesetting:
%\usepackage{times}
%\usepackage[utf8]{inputenc} % allow utf-8 input
%\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{url}            % simple URL typesetting
%\usepackage{hyperref}
\usepackage{amsmath,amsfonts,amssymb}       % blackboard math 
%\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{multirow}
\usepackage{algorithm,algorithmic}
\usepackage{xcolor}
\usepackage[normalem]{ulem}
\usepackage{arydshln}
\usepackage{caption}
\usepackage{enumitem}
\usepackage{wrapfig}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{cutwin}
\usepackage{bbm}
\usepackage[pangram]{blindtext}
\usepackage[calc]{adjustbox}

\usepackage{tabularx}
\usepackage{color, colortbl}
\usepackage{kotex}
\usepackage{lipsum}

\usepackage{enumitem} % leftmargin for items

% USER DEFINED
\makeatletter
\def\hlinewd#1{%
	\noalign{\ifnum0=`}\fi\hrule \@height #1 %
	\futurelet\reserved@a\@xhline}
\makeatother

\def\AlgoSize{\small}
\renewcommand{\algorithmiccomment}[1]{\bgroup\hfill$\triangleright$~#1\egroup}

\definecolor{crimson}{rgb}{0.86, 0.08, 0.24}
\definecolor{orange-red}{rgb}{1.0, 0.27, 0.0}
\newcommand{\highlight}[1]{{\color{crimson}{#1}}}
\newcommand{\modified}[1]{{\color{orange-red}{#1}}}
\newcommand{\bsy}{\boldsymbol}

\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}

\newcommand{\newor}{%
  \mathbin{%
    {\vee}\mspace{-2.9mu}
  }%
}
\usepackage{bm}
\newcommand{\bs}[1] {\bm{#1}}

\usepackage{svg}
\DeclareMathOperator*{\minimize}{minimize}
\DeclareMathOperator*{\logicalor}{\vee}
\DeclareMathOperator*{\threshold}{thresh}

\usepackage{gensymb}
\usepackage{marvosym}

% define lines
\usepackage{mathtools,tikz}
\DeclareRobustCommand\sampleline[1]{%
  \tikz\draw[#1] (0,0) (0,\the\dimexpr\fontdimen22\textfont2\relax)
  -- (2em,\the\dimexpr\fontdimen22\textfont2\relax);%
}

\definecolor{Red}{rgb}{1,0,0}
\definecolor{Blue}{rgb}{0,0,0.8}
\definecolor{Green}{rgb}{0,0.7,0.2}
\definecolor{airforceblue}{rgb}{0.36, 0.54, 0.66}
\definecolor{ao(english)}{rgb}{0.0, 0.5, 0.0}
\definecolor{azure(colorwheel)}{rgb}{0.0, 0.5, 1.0}
\definecolor{crimson}{rgb}{0.86, 0.08, 0.24}
\definecolor{darkcerulean}{rgb}{0.03, 0.27, 0.49}
\definecolor{cobalt}{rgb}{0.0, 0.28, 0.67}
\definecolor{rosegold}{rgb}{0.72, 0.43, 0.47}
\definecolor{orange-red}{rgb}{1.0, 0.27, 0.0}
\definecolor{mountainmeadow}{rgb}{0.19, 0.73, 0.56}
\definecolor{malachite}{rgb}{0.04, 0.85, 0.32}
\definecolor{darkblue}{rgb}{0.0, 0.0, 0.55}

\definecolor{customblue}{rgb}{0.2, 0.35, 0.8}
\definecolor{gg}{gray}{0.9}

%\usepackage{hyperref}
%\hypersetup{colorlinks=true}
%\hypersetup{linktoc=all}
%\hypersetup{citecolor=customblue}
%\hypersetup{linkcolor=crimson}
%\hypersetup{urlcolor=MidnightBlue}
%\usepackage[all]{hypcap}

%\usepackage[nameinlink]{cleveref}
%\creflabelformat{equation}{#2\textup{#1}#3}  
%\crefname{assumption}{assumption}{assumptions}
%\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}

% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}


\usepackage{makecell}
\newcommand{\tobemorified}[1]{{\color{crimson}{#1}}}
\newcommand{\hibf}[1]{{\color{crimson}{\textbf{#1}}}}
\newcommand{\jss}[1]{{\color{azure(colorwheel)}{\sout{#1}}}}
\newcommand{\js}[1]{{\color{azure(colorwheel)}{#1}}} %ao(english)
\newcommand{\eat}[1]{{}}
\creflabelformat{equation}{#2\textup{#1}#3}  

% correct bad hyphenation here
%\hyphenation{op-tical net-works semi-conduc-tor}

%\usepackage{hyperref}
%\usepackage{url}

\begin{document}
%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
%\title{Bare Demo of IEEEtran.cls for\\ IEEE Computer Society Journals}
\title{Forget-free Continual Learning with Soft-Winning SubNetworks}

\author{Haeyong~Kang\thanks{Email: haeyong.kang@kaist.ac.kr},
        Jaehong~Yoon, %~\IEEEmembership{Member,~IEEE,}
        Sultan Rizky Madjid, 
        Sung Ju Hwang,
        and~Chang~D.~Yoo$^{\ast}$\thanks{$^\ast$ Corresponding Author.} %~\IEEEmembership{Life~Fellow,~IEEE}% <-this % stops a space
%\IEEEcompsocitemizethanks{\IEEEcompsocthanksitem Haeyong Kang was with the School of Electrical Engineering, KAIST, Daejeon, Korea. \protect\\
% note need leading \protect in front of \\ to get a newline within \thanks as
% \\ is fragile and will error, could use \hfil\break instead.
%E-mail: haeyong.kang@kaist.ac.kr
%\IEEEcompsocthanksitem J. Doe and J. Doe are with Anonymous University.}% <-this % stops an unwanted space
%\thanks{Manuscript received April 19, 2023; revised August 26, 2023.}
}

% The paper headers
%\markboth{Journal of \LaTeX\ Class Files,~Vol.~**, No.~*, March~2023}%
\markboth{Preprint, March~2023}
{Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for Computer Society Journals}

% in the abstract or keywords.
\IEEEtitleabstractindextext{%
%\input{1_abstract}
\begin{abstract}%v 
Inspired by \emph{Regularized Lottery Ticket Hypothesis (RLTH)}, which states that competitive smooth (non-binary) subnetworks exist within a dense network in continual learning tasks, we investigate two proposed architecture-based continual learning methods which sequentially learn and select adaptive binary- (WSN) and non-binary Soft-Subnetworks (SoftNet) for each task. WSN and SoftNet jointly learn the regularized model weights and task-adaptive non-binary masks of subnetworks associated with each task whilst attempting to select a small set of weights to be activated (winning ticket) by reusing weights of the prior subnetworks. Our proposed WSN and SoftNet are inherently immune to catastrophic forgetting as each selected subnetwork model does not infringe upon other subnetworks in Task Incremental Learning (TIL). In TIL, binary masks spawned per winning ticket are encoded into one N-bit binary digit mask, then compressed using Huffman coding for a sub-linear increase in network capacity to the number of tasks. Surprisingly, in the inference step, SoftNet generated by injecting small noises to the backgrounds of acquired WSN (holding the foregrounds of WSN) provides excellent forward transfer power for future tasks in TIL. SoftNet shows its effectiveness over WSN in regularizing parameters to tackle the overfitting, to a few examples in Few-shot Class Incremental Learning (FSCIL). 
\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
Continual Learning (CL), Task Incremental Learning (TIL), Few-shot Class Incremental Learning (FSCIL), Regularized Lottery Ticket Hypothesis (RLTH), Wining SubNetworks (WSN), Soft-Subnetwork (SoftNet)
\end{IEEEkeywords}}

% make the title area
\maketitle

\IEEEdisplaynontitleabstractindextext
% \IEEEdisplaynontitleabstractindextext has no effect when using
% compsoc or transmag under a non-conference mode.

% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle

\input{2_intro}

\input{3_related_work}

\input{4_approach}

\input{5_experiment}

\input{6_conclusion}

%\noindent 
%\textbf{Acknowledgement}.This work was supported by Institute for Information \& communications Technology Promotion (IITP) grant funded by the Korea government (MSIT) (No. 2021-0-01381, Development of Causal AI through Video Understanding and Reinforcement Learning, and Its Applications to Real Environments) and partly supported by Institute of Information \& communications Technology Planning \& Evaluation (IITP) grant funded by the Korea government (MSIT) (No. 2022-0-00184, Development and Study of AI Technologies to Inexpensively Conform to Evolving Policy on Ethics).

\bibliographystyle{plain}
\bibliography{reference}

\vspace{-0.16in}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{./biography/haeyong.pdf}}]{Haeyong Kang}
(S'05) received the M.S. degree in Systems and Information Engineering from University of Tsukuba in 2007. From April 2007 to October 2010, he worked as an associate research engineer at LG Electronics. With working experiences at Korea Institute of Science and Technology (KIST) and the University of Tokyo, He is currently pursuing the Ph.D at School of Electrical Engineering, KAIST. His current research interests include unbiased machine learning and continual learning.
\end{IEEEbiography}

%\vspace{-20mm}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{./biography/jaehong.pdf}}]{Jaehong Yoon}
He received the B.S. and M.S. degrees in Computer Science from Ulsan National Institute of Science and Technology (UNIST), and received the Ph.D. degree in the School of Computing from Korea Advanced Institute of Science and Technology (KAIST). He is currently working as a postdoctoral research fellow at KAIST. His current research interests include efficient deep learning, on-device learning, and learning with real-world data.
\end{IEEEbiography}

%\vspace{-20mm}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{./biography/sultan.pdf}}]{Sultan Rizky Madjid}
received a B.S. degree in Electrical Engineering with a double major in Mechanical Engineering from KAIST in 2021 and an M.S. degree in Electrical Engineering from KAIST in 2023. His research interests include model compression, sparse representations in deep learning, and continual learning.
\end{IEEEbiography}

%\vspace{-20mm}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{./biography/sungjuhwang.pdf}}]{Sung Ju Hwang}
He received the B.S. degree in Computer Science and Engineering from Seoul National University. He received the M.S. and Ph.D. degrees in Computer Science from The University of Texas at Austin. From September 2013 to August 2014, he was a postdoctoral research associate at Disney Research. From September 2013 to December 2017, he was an assistant professor in the School of Electric and Computer Engineering at UNIST. Since 2017, he has been on the faculty at the Korea Advanced Institute of Science and Technology (KAIST), where he is currently a KAIST Endowed Chair Professor in the Kim Jaechul School of Artificial Intelligence and School of Computing at KAIST. 
\end{IEEEbiography}

%\vspace{-20mm}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{./biography/cdyoo.pdf}}]{Chang D. Yoo}
(Senior Member, IEEE) He received the B.S. degree in Engineering and Applied Science from the California Institute of Technology, the M.S. degree in Electrical Engineering from Cornell University, and the Ph.D. degree in Electrical Engineering from the Massachusetts Institute of Technology. From January 1997 to March 1999, he was Senior Researcher at Korea Telecom (KT). Since 1999, he has been on the faculty at the Korea Advanced Institute of Science and Technology (KAIST), where he is currently a Full Professor with tenure in the School of Electrical Engineering and an Adjunct Professor in the Department of Computer Science. He also served as Dean of the Office of Special Projects and Dean of the Office of International Relations.
\end{IEEEbiography}

\appendices
\input{7_appendix}

% that's all folks
\end{document}


