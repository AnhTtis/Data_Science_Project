\begin{figure*}[ht]
    \centering
    \setlength{\tabcolsep}{0pt}{%
    \begin{tabular}{ccccc}
    \includegraphics[width=0.33333\textwidth]{images/avg_acc_csnb_tiny_data.pdf}  & 
    % \hspace{0.6in}
    \includegraphics[width=0.33333\textwidth]{images/avg_comp_rate_csnb_tiny_data_huffman.pdf} &
    % \hspace{0.6in}
    \includegraphics[width=0.33333\textwidth]{images/avg_bit_capa_csnb_tiny_data_huffman.pdf} \\
    
    
    \small (a) Per Task Accuracy over $c$ & \small (b) N-Bit-wise-Compression Rate & \small (c) Progressive Capacities of Models
    
    %\multicolumn{2}{c}{\small (a) Per Task Accuracy over Varying $c$} &
    %\multicolumn{3}{c}{\small (b) \% Weights used per Layer over Increasing No. of Tasks}
    \end{tabular}}
    \caption{\footnotesize \textbf{Performances and Compressed Capacities} - Sequence of TinyImageNet Dataset Experiments. (a) The $c=0.1$ shows generalized performances over others, (b) With fixed $c=0.1$, we investigate the bit-wise Huffman compression rate and observe that as the number of bits to compress increases the average compression rate gets higher, and (c) We compared the model capacity with the model capacity + the compressed binary masks over varying bits. Within the 40-tasks, the 7-bits compressed capacities are the least increasing along with the $c=0.1$ model capacity.}
    \label{fig:app_main_tinyimg_plots}
\end{figure*}