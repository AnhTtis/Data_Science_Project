@inproceedings{Li2017,
   author = {J Li and C Zhao and K Hamedani and Y Yi},
   doi = {10.1109/IJCNN.2017.7966288},
   isbn = {2161-4407},
   journal = {2017 International Joint Conference on Neural Networks (IJCNN)},
   pages = {3439-3446},
   title = {Analog hardware implementation of spike-based delayed feedback reservoir computing system},
   year = {2017},
}
@article{Farronato2022,
   abstract = {Abstract Novel memory devices are essential for developing low power, fast, and accurate in-memory computing and neuromorphic engineering concepts that can compete with the conventional complementary metal?oxide?semiconductor (CMOS) digital processors. 2D semiconductors provide a novel platform for advanced semiconductors with atomic thickness, low-current operation, and capability of 3D integration. This work presents a charge-trap memory (CTM) device with a MoS2 channel where memory operation arises, thanks to electron trapping/detrapping at interface states. Transistor operation, memory characteristics, and synaptic potentiation/depression for neuromorphic applications are demonstrated. The CTM device shows outstanding linearity of the potentiation by applied drain pulses of equal amplitude. Finally, pattern recognition is demonstrated by reservoir computing where the input pattern is applied as a stimulation of the MoS2-based CTMs, while the output current after stimulation is processed by a feedforward readout network. The good accuracy, the low current operation, and the robustness to input random bit flip makes the CTM device a promising technology for future high-density neuromorphic computing concepts.},
   author = {Matteo Farronato and Piergiulio Mannocci and Margherita Melegari and Saverio Ricci and Christian Monzio Compagnoni and Daniele Ielmini},
   doi = {https://doi.org/10.1002/adma.202205381},
   issn = {0935-9648},
   issue = {n/a},
   journal = {Advanced Materials},
   keywords = {2D semiconductors,charge-trap memory,neural networks,neuromorphic engineering,reservoir computing},
   month = {10},
   note = {https://doi.org/10.1002/adma.202205381},
   pages = {2205381},
   publisher = {John Wiley & Sons, Ltd},
   title = {Reservoir Computing with Charge-Trap Memory Based on a MoS2 Channel for Neuromorphic Engineering},
   volume = {n/a},
   url = {https://doi.org/10.1002/adma.202205381},
   year = {2022},
}
@inproceedings{Fang2021,
   author = {H Fang and B Taylor and Z Li and Z Mei and H H Li and Q Qiu},
   doi = {10.1109/DAC18074.2021.9586133},
   isbn = {0738-100X},
   journal = {2021 58th ACM/IEEE Design Automation Conference (DAC)},
   pages = {361-366},
   title = {Neuromorphic Algorithm-hardware Codesign for Temporal Pattern Learning},
   year = {2021},
}
@article{Serrano-Gotarredona2015,
   abstract = {This article reports on two databases for event-driven object recognition using a Dynamic Vision Sensor (DVS). The first, which we call Poker-DVS and is being released together with this article, was obtained by browsing specially made poker card decks in front of a DVS camera for 2–4 s. Each card appeared on the screen for about 20–30 ms. The poker pips were tracked and isolated off-line to constitute the 131-recording Poker-DVS database. The second database, which we call MNIST-DVS and which was released in December 2013, consists of a set of 30,000 DVS camera recordings obtained by displaying 10,000 moving symbols from the standard MNIST 70,000-picture database on an LCD monitor for about 2–3 s each. Each of the 10,000 symbols was displayed at three different scales, so that event-driven object recognition algorithms could easily be tested for different object sizes. This article tells the story behind both databases, covering, among other aspects, details of how they work and the reasons for their creation. We provide not only the databases with corresponding scripts, but also the scripts and data used to generate the figures shown in this article (as Supplementary Material).},
   author = {Teresa Serrano-Gotarredona and Bernabé Linares-Barranco},
   issn = {1662-453X},
   journal = {Frontiers in Neuroscience},
   title = {Poker-DVS and MNIST-DVS. Their History, How They Were Made, and Other Details},
   volume = {9},
   url = {https://www.frontiersin.org/articles/10.3389/fnins.2015.00481},
   year = {2015},
}
@article{Gehrig2021,
   abstract = {Once an academic venture, autonomous driving has received unparalleled corporate funding in the last decade. Still, the operating conditions of current autonomous cars are mostly restricted to ideal scenarios. This means that driving in challenging illumination conditions such as night, sunrise, and sunset remains an open problem. In these cases, standard cameras are being pushed to their limits in terms of low light and high dynamic range performance. To address these challenges, we propose, DSEC, a new dataset that contains such demanding illumination conditions and provides a rich set of sensory data. DSEC offers data from a wide-baseline stereo setup of two color frame cameras and two high-resolution monochrome event cameras. In addition, we collect lidar data and RTK GPS measurements, both hardware synchronized with all camera data. One of the distinctive features of this dataset is the inclusion of high-resolution event cameras. Event cameras have received increasing attention for their high temporal resolution and high dynamic range performance. However, due to their novelty, event camera datasets in driving scenarios are rare. This work presents the first high-resolution, large-scale stereo dataset with event cameras. The dataset contains 53 sequences collected by driving in a variety of illumination conditions and provides ground truth disparity for the development and evaluation of event-based stereo algorithms.},
   author = {Mathias Gehrig and Willem Aarents and Daniel Gehrig and Davide Scaramuzza},
   month = {3},
   title = {{DSEC}: A Stereo Event Camera Dataset for Driving Scenarios},
   url = {http://arxiv.org/abs/2103.06011},
   year = {2021},
}
@article{Mueggler2016,
   abstract = {New vision sensors, such as the Dynamic and Active-pixel Vision sensor (DAVIS), incorporate a conventional global-shutter camera and an event-based sensor in the same pixel array. These sensors have great potential for high-speed robotics and computer vision because they allow us to combine the benefits of conventional cameras with those of event-based sensors: low latency, high temporal resolution, and very high dynamic range. However, new algorithms are required to exploit the sensor characteristics and cope with its unconventional output, which consists of a stream of asynchronous brightness changes (called "events") and synchronous grayscale frames. For this purpose, we present and release a collection of datasets captured with a DAVIS in a variety of synthetic and real environments, which we hope will motivate research on new algorithms for high-speed and high-dynamic-range robotics and computer-vision applications. In addition to global-shutter intensity images and asynchronous events, we provide inertial measurements and ground-truth camera poses from a motion-capture system. The latter allows comparing the pose accuracy of ego-motion estimation algorithms quantitatively. All the data are released both as standard text files and binary files (i.e., rosbag). This paper provides an overview of the available data and describes a simulator that we release open-source to create synthetic event-camera data.},
   author = {Elias Mueggler and Henri Rebecq and Guillermo Gallego and Tobi Delbruck and Davide Scaramuzza},
   doi = {10.1177/0278364917691115},
   month = {10},
   title = {The Event-Camera Dataset and Simulator: Event-based Data for Pose Estimation, Visual Odometry, and {SLAM}},
   url = {http://arxiv.org/abs/1610.08336 http://dx.doi.org/10.1177/0278364917691115},
   year = {2016},
}
@article{Bi2019-graph,
   abstract = {Neuromorphic vision sensing (NVS)\ devices represent visual information as sequences of asynchronous discrete events (a.k.a., ``spikes'') in response to changes in scene reflectance. Unlike conventional active pixel sensing (APS), NVS allows for significantly higher event sampling rates at substantially increased energy efficiency and robustness to illumination changes. However, object classification with NVS streams cannot leverage on state-of-the-art convolutional neural networks (CNNs), since NVS does not produce frame representations. To circumvent this mismatch between sensing and processing with CNNs, we propose a compact graph representation for NVS. We couple this with novel residual graph CNN architectures and show that, when trained on spatio-temporal NVS data for object classification, such residual graph CNNs preserve the spatial and temporal coherence of spike events, while requiring less computation and memory. Finally, to address the absence of large real-world NVS datasets for complex recognition tasks, we present and make available a 100k dataset of NVS recordings of the American sign language letters, acquired with an iniLabs DAVIS240c device under real-world conditions.},
   author = {Yin Bi and Aaron Chadha and Alhabib Abbas and Eirina Bourtsoulatze and Yiannis Andreopoulos},
   month = {8},
   title = {Graph-Based Object Classification for Neuromorphic Vision Sensing},
   url = {http://arxiv.org/abs/1908.06648},
   year = {2019},
}
@article{,
   abstract = {Incommensurate charge order in hole-doped oxides is intertwined with exotic phenomena such as colossal magnetoresistance, high-temperature superconductivity, and electronic nematicity. Here, we map, at atomic resolution, the nature of incommensurate charge?lattice order in a manganite using scanning transmission electron microscopy at room temperature and cryogenic temperature (?93 K). In diffraction, the ordering wave vector changes upon cooling, a behavior typically associated with incommensurate order. However, using real space measurements, we discover that the ordered state forms lattice-locked regions over a few wavelengths interspersed with phase defects and changing periodicity. The cations undergo picometer-scale (?6 pm to 11 pm) transverse displacements, suggesting that charge?lattice coupling is strong. We further unearth phase inhomogeneity in the periodic lattice displacements at room temperature, and emergent phase coherence at 93 K. Such local phase variations govern the long-range correlations of the charge-ordered state and locally change the periodicity of the modulations, resulting in wave vector shifts in reciprocal space. These atomically resolved observations underscore the importance of lattice coupling and phase inhomogeneity, and provide a microscopic explanation for putative ?incommensurate? order in hole-doped oxides.},
   author = {Ismail El Baggari and Benjamin H Savitzky and Alemayehu S Admasu and Jaewook Kim and Sang-Wook Cheong and Robert Hovden and Lena F Kourkoutis},
   doi = {10.1073/pnas.1714901115},
   issue = {7},
   journal = {Proceedings of the National Academy of Sciences},
   month = {2},
   note = {doi: 10.1073/pnas.1714901115},
   pages = {1445-1450},
   publisher = {Proceedings of the National Academy of Sciences},
   title = {Nature and evolution of incommensurate charge order in manganites visualized with cryogenic scanning transmission electron microscopy},
   volume = {115},
   url = {https://doi.org/10.1073/pnas.1714901115},
   year = {2018},
}
@article{Hovden2016,
   abstract = {Charge-density waves (CDWs) and their concomitant periodic lattice distortions (PLDs) govern the electronic properties in several layered transition-metal dichalcogenides. In particular, 1T-TaS2 undergoes a metal-to-insulator phase transition as the PLD becomes commensurate with the crystal lattice. Here we directly image PLDs of the nearly commensurate (NC) and commensurate (C) phases in thin, exfoliated 1T-TaS2 using atomic resolution scanning transmission electron microscopy at room and cryogenic temperature. At low temperatures, we observe commensurate PLD superstructures, suggesting ordering of the CDWs both in- and out-of-plane. In addition, we discover stacking transitions in the atomic lattice that occur via one-bond-length shifts. Interestingly, the NC PLDs exist inside both the stacking domains and their boundaries. Transitions in stacking order are expected to create fractional shifts in the CDW between layers and may be another route to manipulate electronic phases in layered dichalcogenides.},
   author = {Robert Hovden and Adam W Tsen and Pengzi Liu and Benjamin H Savitzky and Ismail El Baggari and Yu Liu and Wenjian Lu and Yuping Sun and Philip Kim and Abhay N Pasupathy and Lena F Kourkoutis},
   doi = {10.1073/pnas.1606044113},
   issue = {41},
   journal = {Proceedings of the National Academy of Sciences},
   month = {10},
   note = {doi: 10.1073/pnas.1606044113},
   pages = {11420-11424},
   publisher = {Proceedings of the National Academy of Sciences},
   title = {Atomic lattice disorder in charge-density-wave phases of exfoliated dichalcogenides (1T-TaS2)},
   volume = {113},
   url = {https://doi.org/10.1073/pnas.1606044113},
   year = {2016},
}
@article{Pan2023,
   abstract = {Abstract Antiferroelectrics, which undergo a field-induced phase transition to ferroelectric order that manifests as double-hysteresis polarization switching, exhibit great potential for dielectric, electromechanical, and electrothermal applications. Compared to their ferroelectric cousins, however, considerably fewer efforts have been made to understand and control antiferroelectrics. Here, it is demonstrated that the polarization switching behavior of an antiferroelectric can be strongly influenced and effectively regulated by point defects. In films of the canonical antiferroelectric PbZrO3, decreasing oxygen pressure during deposition (and thus increasing adatom kinetic energy) causes unexpected ?ferroelectric-like? polarization switching although the films remain in the expected antiferroelectric orthorhombic phase. This ?ferroelectric-like? switching is correlated with the creation of bombardment-induced point-defect complexes which pin the antiferroelectric-ferroelectric phase boundaries, and thus effectively delay the phase transition under changing field. The effective pinning energy is extracted via temperature-dependent switching-kinetics studies. In turn, by controlling the concentration of defect complexes, the dielectric tunability of the PbZrO3 can be adjusted, including being able to convert between ?positive? and ?negative? tunability near zero field. This work reveals the important role and strong capability of defects to engineer antiferroelectrics for new performance and functionalities. This article is protected by copyright. All rights reserved},
   author = {Hao Pan and Zishen Tian and Megha Acharya and Xiaoxi Huang and Pravin Kavle and Hongrui Zhang and Liyan Wu and Dongfang Chen and John Carroll and Robert Scales and Cedric J G Meyers and Kathleen Coleman and Brendan Hanrahan and Jonathan E Spanier and Lane W Martin},
   doi = {https://doi.org/10.1002/adma.202300257},
   issn = {0935-9648},
   issue = {n/a},
   journal = {Advanced Materials},
   keywords = {antiferroelectric,defect,dielectric tunability,polarization switching,thin film},
   month = {3},
   note = {https://doi.org/10.1002/adma.202300257},
   pages = {2300257},
   publisher = {John Wiley & Sons, Ltd},
   title = {Defect-induced, Ferroelectric-like Switching and Adjustable Dielectric Tunability in Antiferroelectrics},
   volume = {n/a},
   url = {https://doi.org/10.1002/adma.202300257},
   year = {2023},
}
@article{Kim2022,
   abstract = {Understanding the evolution and role of nanoscale polar structures during polarization rotation in relaxor ferroelectrics is a long-standing challenge in materials science and condensed-matter physics. These nanoscale polar structures are characterized by polar nanodomains, which are believed to play a key role in enabling the large susceptibilities of relaxors. Using epitaxial strain, we stabilize the intermediate step during polarization rotation in epitaxial films of a prototypical relaxor and study the co-evolution of polarization and polar nanodomains. Our multimodal approach allows for a detailed examination of correlations between polarization and polar nanodomains; illuminates the effect of local chemistry, strain and electric field on their co-evolution; and reveals the underappreciated role of strain in enabling the large electromechanical coupling in relaxors. As the strain increases, the competition between chemistry-driven disorder and strain-driven order of the polar units intensifies, which is manifested in the coexistence of inclined and elongated polar nanodomains in the intermediate step of polarization rotation. Our findings establish that structural transitions between polar nanodomain configurations underpins the polarization rotation and large electromechanical coupling of relaxors.},
   author = {Jieun Kim and Abinash Kumar and Yubo Qi and Hiroyuki Takenaka and Philip J Ryan and Derek Meyers and Jong-Woo Kim and Abel Fernandez and Zishen Tian and Andrew M Rappe and James M LeBeau and Lane W Martin},
   doi = {10.1038/s41567-022-01773-y},
   issn = {1745-2481},
   issue = {12},
   journal = {Nature Physics},
   pages = {1502-1509},
   title = {Coupled polarization and nanodomain evolution underpins large electromechanical responses in relaxors},
   volume = {18},
   url = {https://doi.org/10.1038/s41567-022-01773-y},
   year = {2022},
}
@article{Fernandez2022,
   abstract = {Abstract Over the last 30 years, the study of ferroelectric oxides has been revolutionized by the implementation of epitaxial-thin-film-based studies, which have driven many advances in the understanding of ferroelectric physics and the realization of novel polar structures and functionalities. New questions have motivated the development of advanced synthesis, characterization, and simulations of epitaxial thin films and, in turn, have provided new insights and applications across the micro-, meso-, and macroscopic length scales. This review traces the evolution of ferroelectric thin-film research through the early days developing understanding of the roles of size and strain on ferroelectrics to the present day, where such understanding is used to create complex hierarchical domain structures, novel polar topologies, and controlled chemical and defect profiles. The extension of epitaxial techniques, coupled with advances in high-throughput simulations, now stands to accelerate the discovery and study of new ferroelectric materials. Coming hand-in-hand with these new materials is new understanding and control of ferroelectric functionalities. Today, researchers are actively working to apply these lessons in a number of applications, including novel memory and logic architectures, as well as a host of energy conversion devices.},
   author = {Abel Fernandez and Megha Acharya and Han-Gyeol Lee and Jesse Schimpf and Yizhe Jiang and Djamila Lou and Zishen Tian and Lane W Martin},
   doi = {https://doi.org/10.1002/adma.202108841},
   issn = {0935-9648},
   issue = {30},
   journal = {Advanced Materials},
   keywords = {epitaxy,ferroelectrics,piezoelectrics,pyroelectrics,thin films},
   month = {7},
   note = {https://doi.org/10.1002/adma.202108841},
   pages = {2108841},
   publisher = {John Wiley & Sons, Ltd},
   title = {Thin-Film Ferroelectrics},
   volume = {34},
   url = {https://doi.org/10.1002/adma.202108841},
   year = {2022},
}
@article{Nie2014,
   abstract = {The cuprate high-temperature superconductors have been the focus of unprecedentedly intense and sustained study not only because of their high superconducting transition temperatures, but also because they represent the most exquisitely investigated examples of highly correlated electronic materials. In particular, the pseudogap regime of the phase diagram exhibits a variety of mysterious emergent behaviors. In the last few years, evidence from NMR and scanning tunneling microscopy (STM) studies, as well as from a new generation of X-ray scattering experiments, has accumulated, indicating that a general tendency to short-range?correlated incommensurate charge density wave (CDW) order is ?intertwined? with the superconductivity in this regime. Additionally, transport, STM, neutron-scattering, and optical experiments have produced evidence?not yet entirely understood?of the existence of an associated pattern of long-range?ordered point-group symmetry breaking with an electron-nematic character. We have carried out a theoretical analysis of the Landau?Ginzburg?Wilson effective field theory of a classical incommensurate CDW in the presence of weak quenched disorder. Although the possibilities of a sharp phase transition and long-range CDW order are precluded in such systems, we show that any discrete symmetry-breaking aspect of the charge order?nematicity in the case of the unidirectional (stripe) CDW we consider explicitly?generically survives up to a nonzero critical disorder strength. Such ?vestigial order,? which is subject to unambiguous macroscopic detection, can serve as an avatar of what would be CDW order in the ideal, zero disorder limit. Various recent experiments in the pseudogap regime of the hole-doped cuprates are readily interpreted in light of these results.},
   author = {Laimei Nie and Gilles Tarjus and Steven Allan Kivelson},
   doi = {10.1073/pnas.1406019111},
   issue = {22},
   journal = {Proceedings of the National Academy of Sciences},
   month = {6},
   note = {doi: 10.1073/pnas.1406019111},
   pages = {7980-7985},
   publisher = {Proceedings of the National Academy of Sciences},
   title = {Quenched disorder and vestigial nematicity in the pseudogap regime of the cuprates},
   volume = {111},
   url = {https://doi.org/10.1073/pnas.1406019111},
   year = {2014},
}
@inproceedings{Gaba2014,
   author = {S Gaba and P Knag and Z Zhang and W Lu},
   doi = {10.1109/ISCAS.2014.6865703},
   isbn = {2158-1525},
   journal = {2014 IEEE International Symposium on Circuits and Systems (ISCAS)},
   pages = {2592-2595},
   title = {Memristive devices for stochastic computing},
   year = {2014},
}
@article{Knag2014,
   author = {P Knag and W Lu and Z Zhang},
   doi = {10.1109/TNANO.2014.2300342},
   issn = {1941-0085},
   issue = {2},
   journal = {IEEE Transactions on Nanotechnology},
   pages = {283-293},
   title = {A Native Stochastic Computing Architecture Enabled by Memristors},
   volume = {13},
   year = {2014},
}
@article{Zidan2018,
   author = {M A Zidan and Y Jeong and J H Shin and C Du and Z Zhang and W D Lu},
   doi = {10.1109/TMSCS.2017.2721160},
   issn = {2332-7766},
   issue = {4},
   journal = {IEEE Transactions on Multi-Scale Computing Systems},
   pages = {698-710},
   title = {Field-Programmable Crossbar Array (FPCA) for Reconfigurable Computing},
   volume = {4},
   year = {2018},
}
@article{Wang2023,
   abstract = {III-nitride semiconductors are promising optoelectronic and electronic materials and have been extensively investigated in the past decades. New functionalities, such as ferroelectricity, ferromagnetism, and superconductivity, have been implanted into III-nitrides to expand their capability in next-generation semiconductor and quantum technologies. The recent experimental demonstration of ferroelectricity in nitride materials, including ScAl(Ga)N, boron-substituted AlN, and hexagonal BN, has inspired tremendous research interest. Due to the large remnant polarization, high breakdown field, high Curie temperature, and significantly enhanced piezoelectric, linear and nonlinear optical properties, nitride ferroelectric semiconductors have enabled a wealth of applications in electronic, ferroelectronic, acoustoelectronic, optoelectronic, and quantum devices and systems. In this review, the development of nitride ferroelectric semiconductors from materials to devices is discussed. While expounding on the unique advantages and outstanding achievements of nitride ferroelectrics, the existing challenges and promising prospects have been also discussed.},
   author = {Ping Wang and Ding Wang and Shubham Mondal and Mingtao Hu and Jiangnan Liu and Zetian Mi},
   doi = {10.1088/1361-6641/acb80e},
   issn = {0268-1242},
   issue = {4},
   journal = {Semiconductor Science and Technology},
   pages = {043002},
   publisher = {IOP Publishing},
   title = {Dawn of nitride ferroelectric semiconductors: from materials to devices},
   volume = {38},
   url = {https://dx.doi.org/10.1088/1361-6641/acb80e},
   year = {2023},
}
@article{Hoffman2010,
   abstract = {Abstract The non-volatile polarization of a ferroelectric is a promising candidate for digital memory applications. Ferroelectric capacitors have been successfully integrated with silicon electronics, where the polarization state is read out by a device based on a field effect transistor configuration. Coupling the ferroelectric polarization directly to the channel of a field effect transistor is a long-standing research topic that has been difficult to realize due to the properties of the ferroelectric and the nature of the interface between the ferroelectric and the conducting channel. Here, we report on the fabrication and characterization of two promising capacitor-less memory architectures.},
   author = {Jason Hoffman and Xiao Pan and James W Reiner and Fred J Walker and J P Han and Charles H Ahn and T P Ma},
   doi = {https://doi.org/10.1002/adma.200904327},
   issn = {0935-9648},
   issue = {26-27},
   journal = {Advanced Materials},
   keywords = {Data Storage,Ferroics,Thin Films},
   month = {7},
   note = {https://doi.org/10.1002/adma.200904327},
   pages = {2957-2961},
   publisher = {John Wiley & Sons, Ltd},
   title = {Ferroelectric Field Effect Transistors for Memory Applications},
   volume = {22},
   url = {https://doi.org/10.1002/adma.200904327},
   year = {2010},
}
@article{Chai2020,
   abstract = {Future data-intensive applications will have integrated circuit architectures combining energy-efficient transistors, high-density data storage and electro-optic sensing arrays in a single chip to perform in situ processing of captured data. The costly dense wire connections in 3D integrated circuits and in conventional packaging and chip-stacking solutions could affect data communication bandwidths, data storage densities, and optical transmission efficiency. Here we investigated all-ferroelectric nonvolatile LiNbO3 transistors to function through redirection of conducting domain walls between the drain, gate and source electrodes. The transistor operates as a single-pole, double-throw digital switch with complementary on/off source and gate currents controlled using either the gate or source voltages. The conceived device exhibits high wall current density and abrupt off-and-on state switching without subthreshold swing, enabling nonvolatile memory-and-sensor-in-logic and logic-in-memory-and-sensor capabilities with superior energy efficiency, ultrafast operation/communication speeds, and high logic/storage densities.},
   author = {Xiaojie Chai and Jun Jiang and Qinghua Zhang and Xu Hou and Fanqi Meng and Jie Wang and Lin Gu and David Wei Zhang and An Quan Jiang},
   doi = {10.1038/s41467-020-16623-9},
   issn = {2041-1723},
   issue = {1},
   journal = {Nature Communications},
   pages = {2811},
   title = {Nonvolatile ferroelectric field-effect transistors},
   volume = {11},
   url = {https://doi.org/10.1038/s41467-020-16623-9},
   year = {2020},
}
@article{Khan2020,
   abstract = {The discovery of ferroelectricity in oxides that are compatible with modern semiconductor manufacturing processes, such as hafnium oxide, has led to a re-emergence of the ferroelectric field-effect transistor in advanced microelectronics. A ferroelectric field-effect transistor combines a ferroelectric material with a semiconductor in a transistor structure. In doing so, it merges logic and memory functionalities at the single-device level, delivering some of the most pressing hardware-level demands for emerging computing paradigms. Here, we examine the potential of the ferroelectric field-effect transistor technologies in current embedded non-volatile memory applications and future in-memory, biomimetic and alternative computing models. We highlight the material- and device-level challenges involved in high-volume manufacturing in advanced technology nodes (≤10 nm), which are reminiscent of those encountered in the early days of high-K-metal-gate transistor development. We argue that the ferroelectric field-effect transistors can be a key hardware component in the future of computing, providing a new approach to electronics that we term ferroelectronics.},
   author = {Asif Islam Khan and Ali Keshavarzi and Suman Datta},
   doi = {10.1038/s41928-020-00492-7},
   issn = {2520-1131},
   issue = {10},
   journal = {Nature Electronics},
   pages = {588-597},
   title = {The future of ferroelectric field-effect transistor technology},
   volume = {3},
   url = {https://doi.org/10.1038/s41928-020-00492-7},
   year = {2020},
}
@article{Banerjee2022,
   abstract = {Abstract Hafnium oxide (HfO2) is one of the mature high-k dielectrics that has been standing strong in the memory arena over the last two decades. Its dielectric properties have been researched rigorously for the development of flash memory devices. In this review, the application of HfO2 in two main emerging nonvolatile memory technologies is surveyed, namely resistive random access memory and ferroelectric memory. How the properties of HfO2 equip the former to achieve superlative performance with high-speed reliable switching, excellent endurance, and retention is discussed. The parameters to control HfO2 domains are further discussed, which can unleash the ferroelectric properties in memory applications. Finally, the prospect of HfO2 materials in emerging applications, such as high-density memory and neuromorphic devices are examined, and the various challenges of HfO2-based resistive random access memory and ferroelectric memory devices are addressed with a future outlook.},
   author = {Writam Banerjee and Alireza Kashir and Stanislav Kamba},
   doi = {https://doi.org/10.1002/smll.202107575},
   issn = {1613-6810},
   issue = {23},
   journal = {Small},
   keywords = {ferroelectric random access memory,hafnium oxide,hybrid memory,morphotropic phase boundaries,resistive random access memory},
   month = {6},
   note = {https://doi.org/10.1002/smll.202107575},
   pages = {2107575},
   publisher = {John Wiley & Sons, Ltd},
   title = {Hafnium Oxide (HfO2) – A Multifunctional Oxide: A Review on the Prospect and Challenges of Hafnium Oxide in Resistive Switching and Ferroelectric Memories},
   volume = {18},
   url = {https://doi.org/10.1002/smll.202107575},
   year = {2022},
}
@article{Mulaosmanovic2021,
   abstract = {In this article, we review the recent progress of ferroelectric field-effect transistors (FeFETs) based on ferroelectric hafnium oxide (HfO2), ten years after the first report on such a device. With a focus on the use of FeFET for nonvolatile memory application, we discuss its basic operation principles, switching mechanisms, device types, material properties and array structures. Key device performance metrics such as cycling endurance, retention, memory window, multi-level operation and scaling capability are analyzed. We also briefly survey recent developments in alternative applications for FeFETs including neuromorphic and in-memory computing as well as radiofrequency devices.},
   author = {Halid Mulaosmanovic and Evelyn T Breyer and Stefan Dünkel and Sven Beyer and Thomas Mikolajick and Stefan Slesazeck},
   doi = {10.1088/1361-6528/ac189f},
   issn = {0957-4484},
   issue = {50},
   journal = {Nanotechnology},
   pages = {502002},
   publisher = {IOP Publishing},
   title = {Ferroelectric field-effect transistors based on HfO2: a review},
   volume = {32},
   url = {https://dx.doi.org/10.1088/1361-6528/ac189f},
   year = {2021},
}
@article{Liao2023,
   abstract = {The rapid development of 5 G, big data, and Internet of Things (IoT) technologies is urgently required for novel non-volatile memory devices with low power consumption, fast read/write speed, and high reliability, which are crucial for high-performance computing. Ferroelectric memory has undergone extensive investigation as a viable alternative for commercial applications since the post-Moore era. However, conventional perovskite-structure ferroelectrics (e.g., PbZrxTi1-xO3) encounter severe limitations for high-density integration owing to the size effect of ferroelectricity and incompatibility with complementary metal-oxide-semiconductor technology. Since 2011, the ferroelectric field has been primarily focused on HfO2-based ferroelectric thin films owing to their exceptional scalability. Several reviews discussing the control of ferroelectricity and device applications exist. It is believed that a comprehensive understanding of mechanisms based on industrial requirements and concerns is necessary, such as the wake-up effect and fatigue mechanism. These mechanisms reflect the atomic structures of the materials as well as the device physics. Herein, a review focusing on phase stability and domain structure is presented. In addition, the recent progress in related ferroelectric memory devices and their challenges is briefly discussed.},
   author = {Jiajia Liao and Siwei Dai and Ren-Ci Peng and Jiangheng Yang and Binjian Zeng and Min Liao and Yichun Zhou},
   doi = {https://doi.org/10.1016/j.fmre.2023.02.010},
   issn = {2667-3258},
   journal = {Fundamental Research},
   keywords = {Domain structure,Fatigue,Ferroelectric field-effect transistor,Hfo ferroelectrics,Phase stability,Wake-up},
   title = {HfO2-based ferroelectric thin film and memory device applications in the post-Moore era: A review},
   url = {https://www.sciencedirect.com/science/article/pii/S2667325823000419},
   year = {2023},
}
@article{Fichtner2019,
   author = {Simon Fichtner and Niklas Wolff and Fabian Lofink and Lorenz Kienle and Bernhard Wagner},
   doi = {10.1063/1.5084945},
   issn = {0021-8979},
   issue = {11},
   journal = {Journal of Applied Physics},
   month = {3},
   note = {doi: 10.1063/1.5084945},
   pages = {114103},
   publisher = {American Institute of Physics},
   title = {AlScN: A III-V semiconductor based ferroelectric},
   volume = {125},
   url = {https://doi.org/10.1063/1.5084945},
   year = {2019},
}
@article{Dreyer2016,
   author = {Cyrus E Dreyer and Anderson Janotti and Chris G Van de Walle and David Vanderbilt},
   doi = {10.1103/PhysRevX.6.021038},
   issue = {2},
   journal = {Physical Review X},
   month = {6},
   pages = {21038},
   publisher = {American Physical Society},
   title = {Correct Implementation of Polarization Constants in Wurtzite Materials and Impact on III-Nitrides},
   volume = {6},
   url = {https://link.aps.org/doi/10.1103/PhysRevX.6.021038},
   year = {2016},
}
@article{Wang2022,
   author = {Ding Wang and Ping Wang and Shubham Mondal and Yixin Xiao and Mingtao Hu and Zetian Mi},
   doi = {10.1063/5.0099913},
   issn = {0003-6951},
   issue = {4},
   journal = {Applied Physics Letters},
   month = {7},
   note = {doi: 10.1063/5.0099913},
   pages = {042108},
   publisher = {American Institute of Physics},
   title = {Impact of dislocation density on the ferroelectric properties of ScAlN grown by molecular beam epitaxy},
   volume = {121},
   url = {https://doi.org/10.1063/5.0099913},
   year = {2022},
}
@article{Wang2022,
   author = {Ping Wang and Ding Wang and Shubham Mondal and Zetian Mi},
   doi = {10.1063/5.0097117},
   issn = {0003-6951},
   issue = {2},
   journal = {Applied Physics Letters},
   month = {7},
   note = {doi: 10.1063/5.0097117},
   pages = {023501},
   publisher = {American Institute of Physics},
   title = {Ferroelectric N-polar ScAlN/GaN heterostructures grown by molecular beam epitaxy},
   volume = {121},
   url = {https://doi.org/10.1063/5.0097117},
   year = {2022},
}
@article{Wang2021,
   author = {Ping Wang and Ding Wang and Nguyen M Vu and Tony Chiang and John T Heron and Zetian Mi},
   doi = {10.1063/5.0054539},
   issn = {0003-6951},
   issue = {22},
   journal = {Applied Physics Letters},
   month = {5},
   note = {doi: 10.1063/5.0054539},
   pages = {223504},
   publisher = {American Institute of Physics},
   title = {Fully epitaxial ferroelectric ScAlN grown by molecular beam epitaxy},
   volume = {118},
   url = {https://doi.org/10.1063/5.0054539},
   year = {2021},
}
@article{Wolff2021,
   author = {Niklas Wolff and Simon Fichtner and Benedikt Haas and Md Redwanul Islam and Florian Niekiel and Maximilian Kessel and Oliver Ambacher and Christoph Koch and Bernhard Wagner and Fabian Lofink and Lorenz Kienle},
   doi = {10.1063/5.0033205},
   issn = {0021-8979},
   issue = {3},
   journal = {Journal of Applied Physics},
   month = {1},
   note = {doi: 10.1063/5.0033205},
   pages = {034103},
   publisher = {American Institute of Physics},
   title = {Atomic scale confirmation of ferroelectric polarization inversion in wurtzite-type AlScN},
   volume = {129},
   url = {https://doi.org/10.1063/5.0033205},
   year = {2021},
}
@article{Wang2023,
   author = {Ping Wang and Ding Wang and Shubham Mondal and Mingtao Hu and Yuanpeng Wu and Tao Ma and Zetian Mi},
   doi = {10.1021/acsami.2c22798},
   issn = {1944-8244},
   issue = {14},
   journal = {ACS Applied Materials & Interfaces},
   month = {4},
   note = {doi: 10.1021/acsami.2c22798},
   pages = {18022-18031},
   publisher = {American Chemical Society},
   title = {Ferroelectric Nitride Heterostructures on CMOS Compatible Molybdenum for Synaptic Memristors},
   volume = {15},
   url = {https://doi.org/10.1021/acsami.2c22798},
   year = {2023},
}
@article{Wang2022,
   abstract = {Abstract Electrically switchable bistable conductance that occurs in ferroelectric materials has attracted growing interest due to its promising applications in data storage and in-memory computing. Sc-alloyed III-nitrides have emerged as a new class of ferroelectrics, which not only enable seamless integration with III-nitride technology but also provide an alternative solution for CMOS back end of line integration. In this paper, the resistive switching behavior and memory effect in an ultrawide-bandgap, high Curie temperature, fully epitaxial ferroelectric ScAlN/GaN heterostructure is reported for the first time. The structure exhibits robust ON and OFF states that last for months at room temperature with rectifying ratios of 60?210, and further shows stable operation at high temperatures (≈670 K) that are close to or even above the Curie temperature of most conventional ferroelectrics. Detailed studies suggest that the underlying mechanism is directly related to a ferroelectric field effect induced charge reconstruction at the hetero-interface. The robust resistive switching landscape and the electrical polarization engineering capability in the polar heterostructure, together with the promise to integrate with both silicon and GaN technologies, can pave the way for next-generation memristors and further enable a broad range of multifunctional and cross-field applications.},
   author = {Ding Wang and Ping Wang and Shubham Mondal and Subhajit Mohanty and Tao Ma and Elaheh Ahmadi and Zetian Mi},
   doi = {https://doi.org/10.1002/aelm.202200005},
   issn = {2199-160X},
   issue = {9},
   journal = {Advanced Electronic Materials},
   keywords = {AlScN,III-nitride memory,ferroelectric,high-temperature memory},
   month = {9},
   note = {https://doi.org/10.1002/aelm.202200005},
   pages = {2200005},
   publisher = {John Wiley & Sons, Ltd},
   title = {An Epitaxial Ferroelectric ScAlN/GaN Heterostructure Memory},
   volume = {8},
   url = {https://doi.org/10.1002/aelm.202200005},
   year = {2022},
}
@article{Zhang2013,
   abstract = {Sc-based III-nitride alloys were studied using Density Functional Theory with special quasi-random structures and were found to retain wide band gaps which stay direct up to x = 0.125 (ScxAl1-xN) and x = 0.375 (ScxGa1-xN). Epitaxial strain stabilization prevents spinodal decomposition up to x = 0.3 (ScxAl1-xN on GaN) and x = 0.24 (ScxGa1-xN on GaN), with critical thicknesses for strain relaxation ranging from 3 nm to near-infinity. The increase in Sc content introduces compressive in-plane stress with respect to AlN and GaN, and leads to composition- and stress-tunable band gaps and polarization, and ultimately introduces ferroelectric functionality in ScxGa1-xN at x = 0.625.},
   author = {Siyuan Zhang and David Holec and Wai Y. Fu and Colin J. Humphreys and Michelle A. Moram},
   doi = {10.1063/1.4824179},
   month = {3},
   title = {Tunable optoelectronic and ferroelectric properties in Sc-based III-nitrides},
   url = {http://arxiv.org/abs/1303.3745 http://dx.doi.org/10.1063/1.4824179},
   year = {2013},
}
@article{Farrer2002,
   author = {N Farrer and L Bellaiche},
   doi = {10.1103/PhysRevB.66.201203},
   issue = {20},
   journal = {Physical Review B},
   month = {11},
   pages = {201203},
   publisher = {American Physical Society},
   title = {Properties of hexagonal ScN versus wurtzite GaN and InN},
   volume = {66},
   url = {https://link.aps.org/doi/10.1103/PhysRevB.66.201203},
   year = {2002},
}
@article{Ranjan2003,
   author = {V Ranjan and L Bellaiche and Eric J Walter},
   doi = {10.1103/PhysRevLett.90.257602},
   issue = {25},
   journal = {Physical Review Letters},
   month = {6},
   pages = {257602},
   publisher = {American Physical Society},
   title = {Strained Hexagonal ScN: A Material with Unusual Structural and Optical Properties},
   volume = {90},
   url = {https://link.aps.org/doi/10.1103/PhysRevLett.90.257602},
   year = {2003},
}
@article{Wang2021,
   author = {Ding Wang and Ping Wang and Boyu Wang and Zetian Mi},
   doi = {10.1063/5.0060021},
   issn = {0003-6951},
   issue = {11},
   journal = {Applied Physics Letters},
   month = {9},
   note = {doi: 10.1063/5.0060021},
   pages = {111902},
   publisher = {American Institute of Physics},
   title = {Fully epitaxial ferroelectric ScGaN grown on GaN by molecular beam epitaxy},
   volume = {119},
   url = {https://doi.org/10.1063/5.0060021},
   year = {2021},
}
@article{Wang2023,
   author = {Ding Wang and Ping Wang and Shubham Mondal and Mingtao Hu and Danhao Wang and Yuanpeng Wu and Tao Ma and Zetian Mi},
   doi = {10.1063/5.0136265},
   issn = {0003-6951},
   issue = {5},
   journal = {Applied Physics Letters},
   month = {1},
   note = {doi: 10.1063/5.0136265},
   pages = {052101},
   publisher = {American Institute of Physics},
   title = {Thickness scaling down to 5 nm of ferroelectric ScAlN on CMOS compatible molybdenum grown by molecular beam epitaxy},
   volume = {122},
   url = {https://doi.org/10.1063/5.0136265},
   year = {2023},
}
@article{Wu2020,
   author = {Y Wu and X Liu and P Wang and D A Laleyan and K Sun and Y Sun and C Ahn and M Kira and E Kioupakis and Z Mi},
   doi = {10.1063/1.5124828},
   issn = {0003-6951},
   issue = {1},
   journal = {Applied Physics Letters},
   month = {1},
   note = {doi: 10.1063/1.5124828},
   pages = {013101},
   publisher = {American Institute of Physics},
   title = {Monolayer GaN excitonic deep ultraviolet light emitting diodes},
   volume = {116},
   url = {https://doi.org/10.1063/1.5124828},
   year = {2020},
}
@article{Wang2020,
   author = {Ping Wang and David Arto Laleyan and Ayush Pandey and Yi Sun and Zetian Mi},
   doi = {10.1063/5.0002445},
   issn = {0003-6951},
   issue = {15},
   journal = {Applied Physics Letters},
   month = {4},
   note = {doi: 10.1063/5.0002445},
   pages = {151903},
   publisher = {American Institute of Physics},
   title = {Molecular beam epitaxy and characterization of wurtzite ScxAl1−xN},
   volume = {116},
   url = {https://doi.org/10.1063/5.0002445},
   year = {2020},
}
@article{Wang2021,
   author = {Ping Wang and Boyu Wang and David Arto Laleyan and Ayush Pandey and Yuanpeng Wu and Yi Sun and Xianhe Liu and Zihao Deng and Emmanouil Kioupakis and Zetian Mi},
   doi = {10.1063/5.0035026},
   issn = {0003-6951},
   issue = {3},
   journal = {Applied Physics Letters},
   month = {1},
   note = {doi: 10.1063/5.0035026},
   pages = {032102},
   publisher = {American Institute of Physics},
   title = {Oxygen defect dominated photoluminescence emission of ScxAl1−xN grown by molecular beam epitaxy},
   volume = {118},
   url = {https://doi.org/10.1063/5.0035026},
   year = {2021},
}
@article{Wang2023,
   author = {Ding Wang and Ping Wang and Minming He and Jiangnan Liu and Shubham Mondal and Mingtao Hu and Danhao Wang and Yuanpeng Wu and Tao Ma and Zetian Mi},
   doi = {10.1063/5.0143645},
   issn = {0003-6951},
   issue = {9},
   journal = {Applied Physics Letters},
   month = {2},
   note = {doi: 10.1063/5.0143645},
   pages = {090601},
   publisher = {American Institute of Physics},
   title = {Fully epitaxial, monolithic ScAlN/AlGaN/GaN ferroelectric HEMT},
   volume = {122},
   url = {https://doi.org/10.1063/5.0143645},
   year = {2023},
}
@article{Tan2015,
   abstract = {Grain size effects on the physical properties of polycrystalline ferroelectrics have been extensively studied for decades; however there are still major controversies regarding the dependence of the piezoelectric and ferroelectric properties on the grain size. Dense BaTiO3 ceramics with different grain sizes were fabricated by either conventional sintering or spark plasma sintering using micro- and nano-sized powders. The results show that the grain size effect on the dielectric permittivity is nearly independent of the sintering method and starting powder used. A peak in the permittivity is observed in all the ceramics with a grain size near 1 μm and can be attributed to a maximum domain wall density and mobility. The piezoelectric coefficient d33 and remnant polarization Pr show diverse grain size effects depending on the particle size of the starting powder and sintering temperature. This suggests that besides domain wall density, other factors such as back fields and point defects, which influence the domain wall mobility, could be responsible for the different grain size dependence observed in the dielectric and piezoelectric/ferroelectric properties. In cases where point defects are not the dominant contributor, the piezoelectric constant d33 and the remnant polarization Pr increase with increasing grain size.},
   author = {Yongqiang Tan and Jialiang Zhang and Yanqing Wu and Chunlei Wang and Vladimir Koval and Baogui Shi and Haitao Ye and Ruth McKinnon and Giuseppe Viola and Haixue Yan},
   doi = {10.1038/srep09953},
   issn = {2045-2322},
   issue = {1},
   journal = {Scientific Reports},
   pages = {9953},
   title = {Unfolding grain size effects in barium titanate ferroelectric ceramics},
   volume = {5},
   url = {https://doi.org/10.1038/srep09953},
   year = {2015},
}
@article{Liu2021,
   author = {Xiwen Liu and Dixiong Wang and Kwan-Ho Kim and Keshava Katti and Jeffrey Zheng and Pariasadat Musavigharavi and Jinshui Miao and Eric A Stach and Roy H I I I Olsson and Deep Jariwala},
   doi = {10.1021/acs.nanolett.0c05051},
   issn = {1530-6984},
   issue = {9},
   journal = {Nano Letters},
   month = {5},
   note = {doi: 10.1021/acs.nanolett.0c05051},
   pages = {3753-3761},
   publisher = {American Chemical Society},
   title = {Post-CMOS Compatible Aluminum Scandium Nitride/2D Channel Ferroelectric Field-Effect-Transistor Memory},
   volume = {21},
   url = {https://doi.org/10.1021/acs.nanolett.0c05051},
   year = {2021},
}
@article{Wang2021,
   author = {Ping Wang and Ding Wang and Boyu Wang and Subhajit Mohanty and Sandra Diez and Yuanpeng Wu and Yi Sun and Elaheh Ahmadi and Zetian Mi},
   doi = {10.1063/5.0055851},
   issn = {0003-6951},
   issue = {8},
   journal = {Applied Physics Letters},
   month = {8},
   note = {doi: 10.1063/5.0055851},
   pages = {082101},
   publisher = {American Institute of Physics},
   title = {N-polar ScAlN and HEMTs grown by molecular beam epitaxy},
   volume = {119},
   url = {https://doi.org/10.1063/5.0055851},
   year = {2021},
}
@article{Wang2023,
   abstract = {Abstract Computing in the analog regime using nonlinear ferroelectric resistive memory arrays can potentially alleviate the energy constraints and complexity/footprint challenges imposed by digital von Neumann systems. Yet the current ferroelectric resistive memories suffer from either low ON/OFF ratios/imprint or limited compatibility with mainstream semiconductors. Here, for the first time, ferroelectric and analog resistive switching in an epitaxial nitride heterojunction comprising ultrathin (≈5 nm) nitride ferroelectrics, i.e., ScAlN, with potentiality to bridge the gap between performance and compatibility is demonstrated. High ON/OFF ratios (up to 105), high uniformity, good retention, (<20% variation after > 105 s) and cycling endurance (>104) are simultaneously demonstrated in a metal/oxide/nitride ferroelectric junction. It is further demonstrated that the memristor can provide programmability to enable multistate operation and linear analogue computing as well as image processing with high accuracy. Neural network simulations based on the weight update characteristics of the nitride memory yielded an image recognition accuracy of 92.9% (baseline 96.2%) on the images from Modified National Institute of Standards and Technology. The non-volatile multi-level programmability and analog computing capability provide first-hand and landmark evidence for constructing advanced memory/computing architectures based on emerging nitride ferroelectrics, and promote homo and hybrid integrated functional edge devices beyond silicon.},
   author = {Ding Wang and Ping Wang and Shubham Mondal and Mingtao Hu and Yuanpeng Wu and Tao Ma and Zetian Mi},
   doi = {https://doi.org/10.1002/adma.202210628},
   issn = {0935-9648},
   issue = {n/a},
   journal = {Advanced Materials},
   keywords = {ScAlN,in-memory computing,large ON/OFF ratio,memory,nitride ferroelectrics,ultrathin},
   month = {3},
   note = {https://doi.org/10.1002/adma.202210628},
   pages = {2210628},
   publisher = {John Wiley & Sons, Ltd},
   title = {Ultrathin Nitride Ferroic Memory with Large ON/OFF Ratios for Analog In-memory Computing},
   volume = {n/a},
   url = {https://doi.org/10.1002/adma.202210628},
   year = {2023},
}
@article{Wang2022,
   author = {Ping Wang and Ding Wang and Yutong Bi and Boyu Wang and Jonathan Schwartz and Robert Hovden and Zetian Mi},
   doi = {10.1063/5.0060608},
   issn = {0003-6951},
   issue = {1},
   journal = {Applied Physics Letters},
   month = {1},
   note = {doi: 10.1063/5.0060608},
   pages = {012104},
   publisher = {American Institute of Physics},
   title = {Quaternary alloy ScAlGaN: A promising strategy to improve the quality of
          ScAlN},
   volume = {120},
   url = {https://doi.org/10.1063/5.0060608},
   year = {2022},
}
@report{Johnson1939,
   abstract = {IT is now recognized that several important types of reactions in metallic systems proceed by the formation of nuclei and the growth of these nuclei. The process of freezing is a simple example of this, as Tammann pointed out years ago.' Tammann held that the rate of freezing is determined by a rate of nucleation, expressed as the number of nuclei formed per unit volume of unfrozen liquid per second, and a rate of growth of these nuclei, expressed as the linear rate of radial growth in units of length per second. For isothermal freezing the conception is simple; for ordinary freezing, extending over a range of temperature, it is not as simple, for the values of the two constants must change with change in temperature. There is ample evidence that the postulated mechanism is correct even though a quantitative derivation of the rate of isothermal or of ordinary freezing in terms of the two constants has been lacking. I n recent years other reactions have been found to proceed in asimilar fashion. I t has been well established, particularly by Bain,2-8 that the formation of pearlite from the eutectoid decomposition of the solid solution austenite proceeds in such a way, and Polanyi and Schmid, Tammann and Crone, Karnop and Sachs, and othersg-l1 have shown that the process of recrystallization proceeds in a similar way. Isothermal reaction rates have been determined for eutectoid decomposition by a number of investigators. Bain'sz+ work on the formation of pearlite from austenite is especially valuable in this respect-the type of isothermal reaction curve obtained, as illustrated in Fig. 13, showed an initial slow rate, accelerating to an intermediate maximum rate which then decelerated to the completion of the reaction; similar curves have been obtained by Wever and his c~llaborators.~~ Other eutectoid decompositions show similar behavior: for example, the decomposition of the beta eutectoid in the copper-aluminum system, studied by Smith Manuscript received at the o5ce of the Institute Dec. 1, 1938.},
   author = {William A. Johnson and Robert F. Mehl},
   institution = {American Institute of Mining and Metallugical Engineers},
   title = {Reaction Kinetics in Processes of Nucleation and Growth},
   year = {1939},
}
@article{Avrami1939,
   author = {Melvin Avrami},
   doi = {10.1063/1.1750380},
   issn = {0021-9606},
   issue = {12},
   journal = {The Journal of Chemical Physics},
   month = {12},
   note = {doi: 10.1063/1.1750380},
   pages = {1103-1112},
   publisher = {American Institute of Physics},
   title = {Kinetics of Phase Change. I General Theory},
   volume = {7},
   url = {https://doi.org/10.1063/1.1750380},
   year = {1939},
}
@article{Avrami1940,
   author = {Melvin Avrami},
   doi = {10.1063/1.1750631},
   issn = {0021-9606},
   issue = {2},
   journal = {The Journal of Chemical Physics},
   month = {2},
   note = {doi: 10.1063/1.1750631},
   pages = {212-224},
   publisher = {American Institute of Physics},
   title = {Kinetics of Phase Change. II Transformation‐Time Relations for Random Distribution of Nuclei},
   volume = {8},
   url = {https://doi.org/10.1063/1.1750631},
   year = {1940},
}
@article{Avrami1941,
   author = {Melvin Avrami},
   doi = {10.1063/1.1750872},
   issn = {0021-9606},
   issue = {2},
   journal = {The Journal of Chemical Physics},
   month = {2},
   note = {doi: 10.1063/1.1750872},
   pages = {177-184},
   publisher = {American Institute of Physics},
   title = {Granulation, Phase Change, and Microstructure Kinetics of Phase Change. III},
   volume = {9},
   url = {https://doi.org/10.1063/1.1750872},
   year = {1941},
}
@article{Kolmogorov1937,
   author = {An Kolmogorov},
   journal = {Izv, Akad, Nauk SSSR, Ser. Mat},
   pages = {355-360},
   title = {On the Statistical Theory of Metal Crystallization},
   volume = {1},
   year = {1937},
}
@article{Jiang2022,
   abstract = {Single crystals of BaTiO3 exhibit small switching fields and energies, but thin-film performance is considerably worse, thus precluding their use in next-generation devices. Here, we demonstrate high-quality BaTiO3 thin films with nearly bulk-like properties. Thickness scaling provides access to the coercive voltages (<100 mV) and fields (<10 kV cm−1) required for future applications and results in a switching energy of <2 J cm−3 (corresponding to <2 aJ per bit in a 10 × 10 × 10 nm3 device). While reduction in film thickness reduces coercive voltage, it does so at the expense of remanent polarization. Depolarization fields impact polar state stability in thicker films but fortunately suppress the coercive field, thus driving a deviation from Janovec–Kay–Dunn scaling and enabling a constant coercive field for films <150 nm in thickness. Switching studies reveal fast speeds (switching times of ~2 ns for 25-nm-thick films with 5-µm-diameter capacitors) and a pathway to subnanosecond switching. Finally, integration of BaTiO3 thin films onto silicon substrates is shown. We also discuss what remains to be demonstrated to enable the use of these materials for next-generation devices.},
   author = {Y Jiang and E Parsonnet and A Qualls and W Zhao and S Susarla and D Pesquera and A Dasgupta and M Acharya and H Zhang and T Gosavi and C.-C. Lin and D E Nikonov and H Li and I A Young and R Ramesh and L W Martin},
   doi = {10.1038/s41563-022-01266-6},
   issn = {1476-4660},
   issue = {7},
   journal = {Nature Materials},
   pages = {779-785},
   title = {Enabling ultra-low-voltage switching in BaTiO3},
   volume = {21},
   url = {https://doi.org/10.1038/s41563-022-01266-6},
   year = {2022},
}
@book{Balluffi2005,
   author = {Robert W. Balluffi and Samuel M. Allen and W. Craig Carter},
   month = {12},
   publisher = {Wiley},
   title = {Kinetics of Materials},
   year = {2005},
}
@article{Ishibashi1971,
   author = {Yoshihiro Ishibashi and Yutaka Takagi},
   doi = {10.1143/JPSJ.31.506},
   issn = {0031-9015},
   issue = {2},
   journal = {Journal of the Physical Society of Japan},
   month = {8},
   note = {doi: 10.1143/JPSJ.31.506},
   pages = {506-510},
   publisher = {The Physical Society of Japan},
   title = {Note on Ferroelectric Domain Switching},
   volume = {31},
   url = {https://doi.org/10.1143/JPSJ.31.506},
   year = {1971},
}
@article{Merz1954,
   author = {Walter J Merz},
   doi = {10.1103/PhysRev.95.690},
   issue = {3},
   journal = {Physical Review},
   month = {8},
   pages = {690-698},
   publisher = {American Physical Society},
   title = {Domain Formation and Domain Wall Motions in Ferroelectric BaTiO3 Single Crystals},
   volume = {95},
   url = {https://link.aps.org/doi/10.1103/PhysRev.95.690},
   year = {1954},
}
@article{Jo2009,
   author = {J Y Jo and S M Yang and T H Kim and H N Lee and J.-G. Yoon and S Park and Y Jo and M H Jung and T W Noh},
   doi = {10.1103/PhysRevLett.102.045701},
   issue = {4},
   journal = {Physical Review Letters},
   month = {1},
   pages = {45701},
   publisher = {American Physical Society},
   title = {Nonlinear Dynamics of Domain-Wall Propagation in Epitaxial Ferroelectric Thin Films},
   volume = {102},
   url = {https://link.aps.org/doi/10.1103/PhysRevLett.102.045701},
   year = {2009},
}
@article{Tybell2002,
   author = {T Tybell and P Paruch and T Giamarchi and J.-M. Triscone},
   doi = {10.1103/PhysRevLett.89.097601},
   issue = {9},
   journal = {Physical Review Letters},
   month = {8},
   pages = {97601},
   publisher = {American Physical Society},
   title = {Domain wall creep in epitaxial ferroelectric Pb(Zr0.2Ti0.8)O3 thin films},
   volume = {89},
   url = {https://link.aps.org/doi/10.1103/PhysRevLett.89.097601},
   year = {2002},
}
@article{Yazawa2023,
   abstract = {Ferroelectric polarization switching is one common example of a process that
occurs via nucleation and growth, and understanding switching kinetics is
crucial for applications such as ferroelectric memory. Here we describe and
interpret anomalous switching dynamics in the wurtzite nitride thin film
ferroelectrics Al0.7Sc0.3N and Al0.94B0.06N using a general model that can be
directly applied to other abrupt transitions that proceed via nucleation and
growth. When substantial growth and impingement occur while nucleation rate is
increasing, such as in these wurtzite ferroelectrics under high electric
fields, abrupt polarization reversal leads to very large Avrami coefficients
(e.g., n = 11), inspiring an extension of the KAI (Kolmogorov-Avrami-Ishibashi)
model. We apply this extended model to two related but distinct scenarios that
crossover between (typical) behavior described by sequential nucleation and
growth and a more abrupt transition arising from significant growth prior to
peak nucleation rate. This work therefore provides more complete description of
general nucleation and growth kinetics applicable to any system while
specifically addressing both the anomalously abrupt polarization reversal
behavior in new wurtzite ferroelectrics.},
   author = {Keisuke Yazawa and John Hayden and Jon-Paul Maria and Wanlin Zhu and Susan Trolier-McKinstry and Andriy Zakutayev and Geoff L. Brennecka},
   month = {3},
   title = {Anomalously Abrupt Switching of Ferroelectric Wurtzites},
   url = {https://arxiv.org/abs/2303.06103},
   year = {2023},
}
@article{Janovec1958,
   abstract = {The coercive field Ec is defined as an electric field on the attainment of which the probability of producing anti-parallel nuclei begins to rise extremely rapidly. A theory of the coercive field is given which explains the dependence of Ec on the thickness of the crystal and leads to values which agree with experiment in order of magnitude.},
   author = {Václav Janovec},
   doi = {10.1007/BF01688741},
   issn = {1572-9486},
   issue = {1},
   journal = {Cechoslovackij fiziceskij zurnal},
   pages = {3-15},
   title = {On the theory of the coercive field of single-domain crystals of BaTiO3},
   volume = {8},
   url = {https://doi.org/10.1007/BF01688741},
   year = {1958},
}
@article{Kay1962,
   author = {H F Kay and J W Dunn},
   doi = {10.1080/14786436208214471},
   issn = {0031-8086},
   issue = {84},
   journal = {The Philosophical Magazine: A Journal of Theoretical Experimental and Applied Physics},
   month = {12},
   note = {doi: 10.1080/14786436208214471},
   pages = {2027-2034},
   publisher = {Taylor & Francis},
   title = {Thickness dependence of the nucleation field of triglycine sulphate},
   volume = {7},
   url = {https://doi.org/10.1080/14786436208214471},
   year = {1962},
}
@article{Chae2021,
   author = {Sieun Chae and Kelsey Mengle and Kyle Bushick and Jihang Lee and Nocona Sanders and Zihao Deng and Zetian Mi and Pierre F P Poudeu and Hanjong Paik and John T Heron and Emmanouil Kioupakis},
   doi = {10.1063/5.0056674},
   issn = {0003-6951},
   issue = {26},
   journal = {Applied Physics Letters},
   month = {6},
   note = {doi: 10.1063/5.0056674},
   pages = {260501},
   publisher = {American Institute of Physics},
   title = {Toward the predictive discovery of ambipolarly dopable ultra-wide-band-gap semiconductors: The case of rutile GeO2},
   volume = {118},
   url = {https://doi.org/10.1063/5.0056674},
   year = {2021},
}
@article{Chae2022,
   abstract = {Entropic stabilization has evolved into a strategy to create new oxide materials and realize novel functional properties engineered through the alloy composition. Achieving an atomistic understanding of these properties to enable their design, however, has been challenging due to the local compositional and structural disorder that underlies their fundamental structure-property relationships. Here, we combine high-throughput atomistic calculations and linear regression algorithms to investigate the role of local configurational and structural disorder on the thermodynamics of vacancy formation in (MgCoNiCuZn)O-based entropy-stabilized oxides (ESOs) and their influence on the electrical properties. We find that the cation-vacancy formation energies decrease with increasing local tensile strain caused by the deviation of the bond lengths in ESOs from the equilibrium bond length in the binary oxides. The oxygen-vacancy formation strongly depends on structural distortions associated with the local configuration of chemical species. Vacancies in ESOs exhibit deep thermodynamic transition levels that inhibit electrical conduction. By applying the charge-neutrality condition, we determine that the equilibrium concentrations of both oxygen and cation vacancies increase with increasing Cu mole fraction. Our results demonstrate that tuning the local chemistry and associated structural distortions by varying alloy composition acts an engineering principle that enables controlled defect formation in multi-component alloys.},
   author = {Sieun Chae and Logan Williams and Jihang Lee and John T Heron and Emmanouil Kioupakis},
   doi = {10.1038/s41524-022-00780-0},
   issn = {2057-3960},
   issue = {1},
   journal = {npj Computational Materials},
   pages = {95},
   title = {Effects of local compositional and structural disorder on vacancy formation in entropy-stabilized oxides from first-principles},
   volume = {8},
   url = {https://doi.org/10.1038/s41524-022-00780-0},
   year = {2022},
}
@article{Kotsonis2020,
   author = {George N Kotsonis and Peter B Meisenheimer and Leixin Miao and Joseph Roth and Baomin Wang and Padraic Shafer and Roman Engel-Herbert and Nasim Alem and John T Heron and Christina M Rost and Jon-Paul Maria},
   doi = {10.1103/PhysRevMaterials.4.100401},
   issue = {10},
   journal = {Physical Review Materials},
   month = {10},
   pages = {100401},
   publisher = {American Physical Society},
   title = {Property and cation valence engineering in entropy-stabilized oxide thin films},
   volume = {4},
   url = {https://link.aps.org/doi/10.1103/PhysRevMaterials.4.100401},
   year = {2020},
}
@article{Meisenheimer2019,
   author = {Peter B Meisenheimer and Logan D Williams and Suk Hyun Sung and Jiseok Gim and Padraic Shafer and George N Kotsonis and Jon-Paul Maria and Morgan Trassin and Robert Hovden and Emmanouil Kioupakis and John T Heron},
   doi = {10.1103/PhysRevMaterials.3.104420},
   issue = {10},
   journal = {Physical Review Materials},
   month = {10},
   pages = {104420},
   publisher = {American Physical Society},
   title = {Magnetic frustration control through tunable stereochemically driven disorder in entropy-stabilized oxides},
   volume = {3},
   url = {https://link.aps.org/doi/10.1103/PhysRevMaterials.3.104420},
   year = {2019},
}
@article{Vu2020,
   abstract = {The manipulation of antiferromagnetic order in magnetoelectric Cr2O3 using electric field has been of great interest due to its potential in low-power electronics. The substantial leakage and low dielectric breakdown observed in twinned Cr2O3 thin films, however, hinders its development in energy efficient spintronics. To compensate, large film thicknesses (250 nm or greater) have been employed at the expense of device scalability. Recently, epitaxial V2O3 thin film electrodes have been used to eliminate twin boundaries and significantly reduce the leakage of 300 nm thick single crystal films. Here we report the electrical endurance and magnetic properties of thin (less than 100 nm) single crystal Cr2O3 films on epitaxial V2O3 buffered Al2O3 (0001) single crystal substrates. The growth of Cr2O3 on isostructural V2O3 thin film electrodes helps eliminate the existence of twin domains in Cr2O3 films, therefore significantly reducing leakage current and increasing dielectric breakdown. 60 nm thick Cr2O3 films show bulk-like resistivity (~ 1012 Ω cm) with a breakdown voltage in the range of 150–300 MV/m. Exchange bias measurements of 30 nm thick Cr2O3 display a blocking temperature of ~ 285 K while room temperature optical second harmonic generation measurements possess the symmetry consistent with bulk magnetic order.},
   author = {N M Vu and X Luo and S Novakov and W Jin and J Nordlander and P B Meisenheimer and M Trassin and L Zhao and J T Heron},
   doi = {10.1038/s41598-020-71619-1},
   issn = {2045-2322},
   issue = {1},
   journal = {Scientific Reports},
   pages = {14721},
   title = {Bulk-like dielectric and magnetic properties of sub 100 nm thick single crystal Cr2O3 films on an epitaxial oxide electrode},
   volume = {10},
   url = {https://doi.org/10.1038/s41598-020-71619-1},
   year = {2020},
}
@article{Meisenheimer2020,
   abstract = {Historically, the enthalpy is the criterion for oxide materials discovery and design. In this regime, highly controlled thin film epitaxy can be leveraged to manifest bulk and interfacial phases that are non-existent in bulk equilibrium phase diagrams. With the recent discovery of entropy-stabilized oxides, entropy and disorder engineering has been realized as an orthogonal approach. This has led to the nucleation and rapid growth of research on high-entropy oxides–multicomponent oxides where the configurational entropy is large but its contribution to its stabilization need not be significant or is currently unknown. From current research, it is clear that entropy enhances the chemical solubility of species and can realize new stereochemical configurations which has led to the rapid discovery of new phases and compositions. The research has expanded beyond studies to understand the role of entropy in stabilization and realization of new crystal structures to now include physical properties and the roles of local and global disorder. Here, key observations made regarding the dielectric and magnetic properties are reviewed. These materials have recently been observed to display concerted symmetry breaking, metal-insulator transitions, and magnetism, paving the way for engineering of these and potentially other functional phenomena. Excitingly, the disorder in these oxides allows for new interplay between spin, orbital, charge, and lattice degrees of freedom to design the physical behavior. We also provide a perspective on the state of the field and prospects for entropic oxide materials in applications considering their unique characteristics.},
   author = {P B Meisenheimer and J T Heron},
   doi = {10.1557/adv.2020.295},
   issn = {2059-8521},
   issue = {64},
   journal = {MRS Advances},
   pages = {3419-3436},
   title = {Oxides and the high entropy regime: A new mix for engineering physical properties},
   volume = {5},
   url = {https://doi.org/10.1557/adv.2020.295},
   year = {2020},
}
@article{Vu2020,
   author = {Nguyen M Vu and Peter B Meisenheimer and John T Heron},
   doi = {10.1063/1.5142856},
   issn = {0021-8979},
   issue = {15},
   journal = {Journal of Applied Physics},
   month = {4},
   note = {doi: 10.1063/1.5142856},
   pages = {153905},
   publisher = {American Institute of Physics},
   title = {Tunable magnetoelastic anisotropy in epitaxial (111) Tm3Fe5O12 thin films},
   volume = {127},
   url = {https://doi.org/10.1063/1.5142856},
   year = {2020},
}
@inproceedings{Kang2022,
   author = {T Kang and S Lee and S Song and M R Haghighat and M P Flynn},
   doi = {10.1109/ISSCC42614.2022.9731571},
   isbn = {2376-8606},
   journal = {2022 IEEE International Solid- State Circuits Conference (ISSCC)},
   pages = {500-502},
   title = {A Multimode 157μW 4-Channel 80dBA-SNDR Speech-Recognition Frontend With Self-DOA Correction Adaptive Beamformer},
   volume = {65},
   year = {2022},
}
@article{Hoshuyama1999,
   author = {O Hoshuyama and A Sugiyama and A Hirano},
   doi = {10.1109/78.790650},
   issn = {1941-0476},
   issue = {10},
   journal = {IEEE Transactions on Signal Processing},
   pages = {2677-2684},
   title = {A robust adaptive beamformer for microphone arrays with a blocking matrix using constrained adaptive filters},
   volume = {47},
   year = {1999},
}
@article{Frost1972,
   author = {O L Frost},
   doi = {10.1109/PROC.1972.8817},
   issn = {1558-2256},
   issue = {8},
   journal = {Proceedings of the IEEE},
   pages = {926-935},
   title = {An algorithm for linearly constrained adaptive array processing},
   volume = {60},
   year = {1972},
}
@article{Zoltowski1988,
   author = {M D Zoltowski},
   doi = {10.1109/29.1614},
   issn = {0096-3518},
   issue = {6},
   journal = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
   pages = {945-947},
   title = {On the performance analysis of the MVDR beamformer in the presence of correlated interference},
   volume = {36},
   year = {1988},
}
@article{Lee2022,
   author = {S Lee and T Kang and J Bell and M Haghighat and A Martinez and M P Flynn},
   doi = {10.1109/JSSC.2021.3103727},
   issn = {1558-173X},
   issue = {6},
   journal = {IEEE Journal of Solid-State Circuits},
   pages = {1812-1823},
   title = {An Eight-Element Frequency-Selective Acoustic Beamformer and Bitstream Feature Extractor},
   volume = {57},
   year = {2022},
}
@article{Jhang2021,
   author = {Chuan-Jia Jhang and Cheng-Xin Xue and Je-Min Hung and Fu-Chun Chang and Meng-Fan Chang},
   doi = {10.1109/TCSI.2021.3064189},
   issue = {5},
   journal = {IEEE Transactions on Circuits and Systems I: Regular Papers},
   pages = {1773-1786},
   title = {Challenges and Trends of SRAM-Based Computing-In-Memory for AI Edge Devices},
   volume = {68},
   year = {2021},
}
@article{Yin2020,
   abstract = {We present XNOR-SRAM, a mixed-signal in-memory computing (IMC) SRAM macro that computes ternary-XNOR-and-accumulate (XAC) operations in binary/ternary deep neural networks (DNNs) without row-by-row data access. The XNOR-SRAM bitcell embeds circuits for ternary XNOR operations, which are accumulated on the read bitline (RBL) by simultaneously turning on all 256 rows, essentially forming a resistive voltage divider. The analog RBL voltage is digitized with a column-multiplexed 11-level flash analog-to-digital converter (ADC) at the XNOR-SRAM periphery. XNOR-SRAM is prototyped in a 65-nm CMOS and achieves the energy efficiency of 403 TOPS/W for ternary-XAC operations with 88.8% test accuracy for the CIFAR-10 data set at 0.6-V supply. This marks 33\times better energy efficiency and 300\times better energy-delay product than conventional digital hardware and also represents among the best tradeoff in energy efficiency and DNN accuracy.},
   author = {Shihui Yin and Zhewei Jiang and Jae Sun Seo and Mingoo Seok},
   doi = {10.1109/JSSC.2019.2963616},
   issn = {1558173X},
   issue = {6},
   journal = {IEEE Journal of Solid-State Circuits},
   keywords = {Binary weights,SRAM,deep neural networks (DNNs),ensemble learning,in-memory computing (IMC),ternary activations},
   month = {6},
   pages = {1733-1743},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {XNOR-SRAM: In-Memory Computing SRAM Macro for Binary/Ternary Deep Neural Networks},
   volume = {55},
   year = {2020},
}
@article{Jung2022,
   abstract = {Implementations of artificial neural networks that borrow analogue techniques could potentially offer low-power alternatives to fully digital approaches1–3. One notable example is in-memory computing based on crossbar arrays of non-volatile memories4–7 that execute, in an analogue manner, multiply–accumulate operations prevalent in artificial neural networks. Various non-volatile memories—including resistive memory8–13, phase-change memory14,15 and flash memory16–19—have been used for such approaches. However, it remains challenging to develop a crossbar array of spin-transfer-torque magnetoresistive random-access memory (MRAM)20–22,  despite the technology’s practical advantages such as endurance and large-scale commercialization5. The difficulty stems from the low resistance of MRAM, which would result in large power consumption in a conventional crossbar array that uses current summation for analogue multiply–accumulate operations. Here we report a 64 × 64 crossbar array based on MRAM cells that overcomes the low-resistance issue with an architecture that uses resistance summation for analogue multiply–accumulate operations. The array is integrated with readout electronics in 28-nanometre complementary metal–oxide–semiconductor technology. Using this array, a two-layer perceptron is implemented to classify 10,000 Modified National Institute of Standards and Technology digits with an accuracy of 93.23 per cent (software baseline: 95.24 per cent). In an emulation of a deeper, eight-layer Visual Geometry Group-8 neural network with measured errors, the classification accuracy improves to 98.86 per cent (software baseline: 99.28 per cent). We also use the array to implement a single layer in a ten-layer neural network to realize face detection with an accuracy of 93.4 per cent.},
   author = {Seungchul Jung and Hyungwoo Lee and Sungmeen Myung and Hyunsoo Kim and Seung Keun Yoon and Soon-Wan Kwon and Yongmin Ju and Minje Kim and Wooseok Yi and Shinhee Han and Baeseong Kwon and Boyoung Seo and Kilho Lee and Gwan-Hyeob Koh and Kangho Lee and Yoonjong Song and Changkyu Choi and Donhee Ham and Sang Joon Kim},
   doi = {10.1038/s41586-021-04196-6},
   issn = {1476-4687},
   issue = {7892},
   journal = {Nature},
   pages = {211-216},
   title = {A crossbar array of magnetoresistive memory devices for in-memory computing},
   volume = {601},
   url = {https://doi.org/10.1038/s41586-021-04196-6},
   year = {2022},
}
@article{Cai2020,
   abstract = {To tackle important combinatorial optimization problems, a variety of annealing-inspired computing accelerators, based on several different technology platforms, have been proposed, including quantum-, optical- and electronics-based approaches. However, to be of use in industrial applications, further improvements in speed and energy efficiency are necessary. Here, we report a memristor-based annealing system that uses an energy-efficient neuromorphic architecture based on a Hopfield neural network. Our analogue–digital computing approach creates an optimization solver in which massively parallel operations are performed in a dense crossbar array that can inject the needed computational noise through the analogue array and device errors, amplified or dampened by using a novel feedback algorithm. We experimentally show that the approach can solve non-deterministic polynomial-time (NP)-hard max-cut problems by harnessing the intrinsic hardware noise. We also use experimentally grounded simulations to explore scalability with problem size, which suggest that our memristor-based approach can offer a solution throughput over four orders of magnitude higher per power consumption relative to current quantum, optical and fully digital approaches.},
   author = {Fuxi Cai and Suhas Kumar and Thomas Van Vaerenbergh and Xia Sheng and Rui Liu and Can Li and Zhan Liu and Martin Foltin and Shimeng Yu and Qiangfei Xia and J Joshua Yang and Raymond Beausoleil and Wei D Lu and John Paul Strachan},
   doi = {10.1038/s41928-020-0436-6},
   issn = {2520-1131},
   issue = {7},
   journal = {Nature Electronics},
   pages = {409-418},
   title = {Power-efficient combinatorial optimization using intrinsic noise in memristor Hopfield neural networks},
   volume = {3},
   url = {https://doi.org/10.1038/s41928-020-0436-6},
   year = {2020},
}
@article{Yin2020,
   author = {S Yin and X Sun and S Yu and J -S. Seo},
   doi = {10.1109/TED.2020.3015178},
   issn = {1557-9646},
   issue = {10},
   journal = {IEEE Transactions on Electron Devices},
   pages = {4185-4192},
   title = {High-Throughput In-Memory Computing for Binary Deep Neural Networks With Monolithically Integrated RRAM and 90-nm CMOS},
   volume = {67},
   year = {2020},
}
@inproceedings{Khwa2018,
   author = {W -S. Khwa and J -J. Chen and J -F. Li and X Si and E -Y. Yang and X Sun and R Liu and P -Y. Chen and Q Li and S Yu and M -F. Chang},
   doi = {10.1109/ISSCC.2018.8310401},
   isbn = {2376-8606},
   journal = {2018 IEEE International Solid - State Circuits Conference - (ISSCC)},
   pages = {496-498},
   title = {A 65nm 4Kb algorithm-dependent computing-in-memory SRAM unit-macro with 2.3ns and 55.8TOPS/W fully parallel product-sum operation for binary DNN edge processors},
   year = {2018},
}
@inproceedings{Chih2021,
   abstract = {From the cloud to edge devices, artificial intelligence (AI) and machine learning (ML) are widely used in many cognitive tasks, such as image classification and speech recognition. In recent years, research on hardware accelerators for AI edge devices has received more attention, mainly due to the advantages of AI at the edge: including privacy, low latency, and more reliable and effective use of network bandwidth. However, traditional computing architectures (such as CPUs, GPUs, FPGAs, and even existing AI accelerator ASICs) cannot meet the future needs of energy-constrained AI edge applications. This is because ML computing is data-centric, most of the energy in these architectures is consumed by memory accesses. In order to improve energy efficiency, both academia and industry are exploring a new computing architecture, namely compute in memory (CIM). CIM research is focused on a more analog approach with high-energy efficiency; however, lack of accuracy, due to a low SNR, is the main disadvantage; therefore, an analog approach may not be suitable for some applications that require high accuracy.},
   author = {Yu Der Chih and Po Hao Lee and Hidehiro Fujiwara and Yi Chun Shih and Chia Fu Lee and Rawan Naous and Yu Lin Chen and Chieh Pu Lo and Cheng Han Lu and Haruki Mori and Wei Chang Zhao and Dar Sun and Mahmut E. Sinangil and Yen Huei Chen and Tan Li Chou and Kerem Akarvardar and Hung Jen Liao and Yih Wang and Meng Fan Chang and Tsung Yung Jonathan Chang},
   doi = {10.1109/ISSCC42613.2021.9365766},
   isbn = {9781728195490},
   issn = {01936530},
   journal = {Digest of Technical Papers - IEEE International Solid-State Circuits Conference},
   month = {2},
   pages = {252-254},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {An 89TOPS/W and 16.3TOPS/mm2All-Digital SRAM-Based Full-Precision Compute-In Memory Macro in 22nm for Machine-Learning Edge Applications},
   volume = {64},
   year = {2021},
}
@article{Meng2022,
   author = {F -H. Meng and X Wang and Z Wang and E Y -J. Lee and W D Lu},
   doi = {10.1109/JETCAS.2022.3227471},
   issn = {2156-3365},
   issue = {4},
   journal = {IEEE Journal on Emerging and Selected Topics in Circuits and Systems},
   pages = {858-866},
   title = {Exploring Compute-in-Memory Architecture Granularity for Structured Pruning of Neural Networks},
   volume = {12},
   year = {2022},
}
@inproceedings{Wu2022,
   author = {Y Wu and S Yoo and F -H. Meng and W D Lu},
   doi = {10.1109/ISCAS48785.2022.9937414},
   isbn = {2158-1525},
   journal = {2022 IEEE International Symposium on Circuits and Systems (ISCAS)},
   pages = {625-628},
   title = {Spatiotemporal Spike Pattern Detection with Second-order Memristive Synapses},
   year = {2022},
}
@article{Park2022,
   author = {Y Park and Z Wang and S Yoo and W D Lu},
   doi = {10.1109/JXCDC.2022.3202517},
   issn = {2329-9231},
   issue = {2},
   journal = {IEEE Journal on Exploratory Solid-State Computational Devices and Circuits},
   pages = {93-101},
   title = {RM-NTT: An RRAM-Based Compute-in-Memory Number Theoretic Transform Accelerator},
   volume = {8},
   year = {2022},
}
@article{Eshraghian2022,
   abstract = {Memristive arrays are a natural fit to implement spiking neural network (SNN) acceleration. Representing information as digital spiking events can improve noise margins and tolerance to device variability compared to analog bitline current summation approaches to multiply-accumulate (MAC) operations. Restricting neuron activations to single-bit spikes also alleviates the significant analog-to-digital converter (ADC) overhead that mixed-signal approaches have struggled to overcome. Binarized, and more generally, limited-precision, NNs are considered to trade off computational overhead with model accuracy, but unlike conventional deep learning models, SNNs do not encode information in the precision-constrained amplitude of the spike. Rather, information may be encoded in the spike time as a temporal code, in the spike frequency as a rate code, and in any number of stand-alone and combined codes. Even if activations and weights are bounded in precision, time can be thought of as continuous and provides an alternative dimension to encode information in. This article explores the challenges that face the memristor-based acceleration of NNs and how binarized SNNs (BSNNs) may offer a good fit for these emerging hardware systems.},
   author = {Jason K. Eshraghian and Xinxin Wang and Wei D. Lu},
   doi = {10.1109/MNANO.2022.3141443},
   issn = {19427808},
   issue = {2},
   journal = {IEEE Nanotechnology Magazine},
   month = {4},
   pages = {14-23},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Memristor-Based Binarized Spiking Neural Networks: Challenges and applications},
   volume = {16},
   year = {2022},
}
@inproceedings{Wang2021,
   author = {X Wang and Y Wu and W D Lu},
   doi = {10.1109/IEDM19574.2021.9720543},
   isbn = {2156-017X},
   journal = {2021 IEEE International Electron Devices Meeting (IEDM)},
   pages = {12.2.1-12.2.4},
   title = {RRAM-enabled AI Accelerator Architecture},
   year = {2021},
}
@generic{Lee2020,
   abstract = {With the slowing down of the Moore’s law and fundamental limitations due to the von-Neumann bottleneck, continued improvements in computing hardware performance become increasingly more challenging. Resistive switching (RS) devices are being extensively studied as promising candidates for next generation memory and computing applications due to their fast switching speed, excellent endurance and retention, and scaling and three-dimensional (3D) stacking capability. In particular, RS devices offer the potential to natively emulate the functions and structures of synapses and neurons, allowing them to efficiently implement neural networks (NNs) and other in-memory computing systems for data intensive applications such as machine learning tasks. In this review, we will examine the mechanisms of RS effects and discuss recent progresses in the application of RS devices for memory, deep learning accelerator, and more faithful brain-inspired computing tasks. Challenges and possible solutions at the device, algorithm, and system levels will also be discussed. [Figure not available: see fulltext.].},
   author = {Seung Hwan Lee and Xiaojian Zhu and Wei D. Lu},
   doi = {10.1007/s12274-020-2616-0},
   issn = {19980000},
   issue = {5},
   journal = {Nano Research},
   keywords = {bio-inspired application,in-memory computing,memory application,metal cation,oxygen vacancy,resistive switching},
   month = {5},
   pages = {1228-1243},
   publisher = {Tsinghua University Press},
   title = {Nanoscale resistive switching devices for memory and computing applications},
   volume = {13},
   year = {2020},
}
@article{Tao2022,
   abstract = {Memory-augmented neural networks (MANNs) provide better inference performance
in many tasks with the help of an external memory. The recently developed
differentiable neural computer (DNC) is a MANN that has been shown to
outperform in representing complicated data structures and learning long-term
dependencies. DNC's higher performance is derived from new history-based
attention mechanisms in addition to the previously used content-based attention
mechanisms. History-based mechanisms require a variety of new compute
primitives and state memories, which are not supported by existing neural
network (NN) or MANN accelerators. We present HiMA, a tiled, history-based
memory access engine with distributed memories in tiles. HiMA incorporates a
multi-mode network-on-chip (NoC) to reduce the communication latency and
improve scalability. An optimal submatrix-wise memory partition strategy is
applied to reduce the amount of NoC traffic; and a two-stage usage sort method
leverages distributed tiles to improve computation speed. To make HiMA
fundamentally scalable, we create a distributed version of DNC called DNC-D to
allow almost all memory operations to be applied to local memories with
trainable weighted summation to produce the global memory output. Two
approximation techniques, usage skimming and softmax approximation, are
proposed to further enhance hardware efficiency. HiMA prototypes are created in
RTL and synthesized in a 40nm technology. By simulations, HiMA running DNC and
DNC-D demonstrates 6.47x and 39.1x higher speed, 22.8x and 164.3x better area
efficiency, and 6.1x and 61.2x better energy efficiency over the
state-of-the-art MANN accelerator. Compared to an Nvidia 3080Ti GPU, HiMA
demonstrates speedup by up to 437x and 2,646x when running DNC and DNC-D,
respectively.},
   author = {Yaoyu Tao and Zhengya Zhang},
   month = {2},
   title = {HiMA: A Fast and Scalable History-based Memory Access Engine for Differentiable Neural Computer},
   url = {https://arxiv.org/abs/2202.07275},
   year = {2022},
}
@inproceedings{Chou2019,
   abstract = {Processing in memory (PIM) is a concept to enable massively parallel dot products while keeping one set of operands in memory. PIM is ideal for computationally demanding deep neural networks (DNNs) and recurrent neural networks (RNNs). Processing in resistive RAM (RRAM) is particularly appealing due to RRAM's high density and low energy. A key limitation of PIM is the cost of multibit analog-to-digital (A/D) conversions that can defeat the efficiency and performance benefits of PIM. In this work, we demonstrate the CASCADE architecture that connects multiply-accumulate (MAC) RRAM arrays with buffer RRAM arrays to extend the processing in analog and in memory: dot products are followed by partial-sum buffering and accumulation to implement a complete DNN or RNN layer. Design choices are made and the interface is designed to enable a variation-tolerant, robust analog dataflow. A new memory mapping scheme named R-Mapping is devised to enable the in-RRAM accumulation of partial sums; and an analog summation scheme is used to reduce the number of A/D conversions required to obtain the final sum. CASCADE is compared with recent in-RRAM computation architectures using state-of-the-art DNN and RNN benchmarks. The results demonstrate that CASCADE improves the energy efficiency by 3.5 while maintaining a competitive throughput.},
   author = {Teyuh Chou and Wei Tang and Jacob Botimer and Zhengya Zhang},
   city = {New York, NY, USA},
   doi = {10.1145/3352460.3358328},
   isbn = {9781450369381},
   journal = {Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture},
   keywords = {Neural network accelerator,Process in memory,Resistive RAM},
   pages = {114-125},
   publisher = {Association for Computing Machinery},
   title = {CASCADE: Connecting RRAMs to Extend Analog Dataflow In An End-To-End In-Memory Processing Paradigm},
   url = {https://doi.org/10.1145/3352460.3358328},
   year = {2019},
}
@article{Hermiz2013,
   author = {John Hermiz and Ting Chang and Chao Du and Wei Lu},
   doi = {10.1063/1.4794024},
   issn = {0003-6951},
   issue = {8},
   journal = {Applied Physics Letters},
   month = {2},
   note = {doi: 10.1063/1.4794024},
   pages = {083106},
   publisher = {American Institute of Physics},
   title = {Interference and memory capacity effects in memristive systems},
   volume = {102},
   url = {https://doi.org/10.1063/1.4794024},
   year = {2013},
}
@inproceedings{Chen2017,
   author = {L Chen and J Li and Y Chen and Q Deng and J Shen and X Liang and L Jiang},
   doi = {10.23919/DATE.2017.7926952},
   isbn = {1558-1101},
   journal = {Design, Automation & Test in Europe Conference & Exhibition (DATE), 2017},
   pages = {19-24},
   title = {Accelerator-friendly neural-network training: Learning variations and defects in RRAM crossbar},
   year = {2017},
}
@article{Kingma2014,
   abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
   author = {Diederik P. Kingma and Jimmy Ba},
   month = {12},
   title = {Adam: A Method for Stochastic Optimization},
   url = {http://arxiv.org/abs/1412.6980},
   year = {2014},
}
@article{Sebastian2020,
   abstract = {Traditional von Neumann computing systems involve separate processing and memory units. However, data movement is costly in terms of time and energy and this problem is aggravated by the recent explosive growth in highly data-centric applications related to artificial intelligence. This calls for a radical departure from the traditional systems and one such non-von Neumann computational approach is in-memory computing. Hereby certain computational tasks are performed in place in the memory itself by exploiting the physical attributes of the memory devices. Both charge-based and resistance-based memory devices are being explored for in-memory computing. In this Review, we provide a broad overview of the key computational primitives enabled by these memory devices as well as their applications spanning scientific computing, signal processing, optimization, machine learning, deep learning and stochastic computing.},
   author = {Abu Sebastian and Manuel Le Gallo and Riduan Khaddam-Aljameh and Evangelos Eleftheriou},
   doi = {10.1038/s41565-020-0655-z},
   issn = {1748-3395},
   issue = {7},
   journal = {Nature Nanotechnology},
   pages = {529-544},
   title = {Memory devices and applications for in-memory computing},
   volume = {15},
   url = {https://doi.org/10.1038/s41565-020-0655-z},
   year = {2020},
}
@article{Wang2022,
   abstract = {In analog in-memory computing systems based on nonvolatile memories such as resistive random-access memory (RRAM), neural network models are often trained offline and then the weights are programmed onto memory devices as conductance values. The programmed weight values inevitably deviate from the target values during the programming process. This effect can be pronounced for emerging memories such as RRAM, PcRAM, and MRAM due to the stochastic nature during programming. Unlike noise, these weight deviations do not change during inference. The performance of neural network models is investigated against this programming variation under realistic system limitations, including limited device on/off ratios, memory array size, analog-to-digital converter (ADC) characteristics, and signed weight representations. Approaches to mitigate such device and circuit nonidealities through architecture-aware training are also evaluated. The effectiveness of variation injection during training to improve the inference robustness, as well as the effects of different neural network training parameters such as learning rate schedule, will be discussed.},
   author = {Qiwen Wang and Yongmo Park and Wei D Lu},
   doi = {https://doi.org/10.1002/aisy.202100199},
   issn = {2640-4567},
   issue = {8},
   journal = {Advanced Intelligent Systems},
   keywords = {RRAM,analog computing,deep neural networks,emerging memory,in-memory computing,process-in-memory},
   month = {8},
   note = {https://doi.org/10.1002/aisy.202100199},
   pages = {2100199},
   publisher = {John Wiley & Sons, Ltd},
   title = {Device Variation Effects on Neural Network Inference Accuracy in Analog In-Memory Computing Systems},
   volume = {4},
   url = {https://doi.org/10.1002/aisy.202100199},
   year = {2022},
}
@inproceedings{Wu2022,
   author = {Y Wu and F Cai and L Thomas and T Liu and A Nourbakhsh and J Hebding and E Smith and R Quon and R Smith and A Kumar and A Pang and J Holt and R Someshwar and F Nardi and J Anthis and S -H. Yen and C Chevallier and A Uppala and X Chen and N Breil and T Sherwood and K Wong and W Cho and D Thompson and J Hsu and B Ayyagari and S Krishnan and W D Lu and M Chudzik},
   doi = {10.1109/IEDM45625.2022.10019450},
   isbn = {2156-017X},
   journal = {2022 International Electron Devices Meeting (IEDM)},
   pages = {18.4.1-18.4.4},
   title = {Demonstration of a Multi-Level μA-Range Bulk Switching ReRAM and its Application for Keyword Spotting},
   year = {2022},
}
@article{Miao2014,
   abstract = {The Kaldi 1 toolkit is becoming popular for constructing automated speech recognition (ASR) systems. Meanwhile, in recent years, deep neural networks (DNNs) have shown state-of-the-art performance on various ASR tasks. This document describes our recipes to implement fully-fledged DNN acoustic modeling using Kaldi and PDNN. PDNN is a lightweight deep learning toolkit developed under the Theano environment. Using these recipes, we can build up multiple systems including DNN hybrid systems, convolu-tional neural network (CNN) systems and bottleneck feature systems. These recipes are directly based on the Kaldi Switchboard 110-hour setup. However, adapting them to new datasets is easy to achieve.},
   author = {Yajie Miao},
   doi = {https://doi.org/10.48550/arXiv.1401.6984 Focus to learn more Submission history},
   journal = {arXiv},
   month = {1},
   title = {{Kaldi+PDNN}: Building DNN-based ASR Systems with Kaldi and PDNN},
   url = {http://www.cs.cmu.edu/~ymiao/pdnntk.html},
   year = {2014},
}
@article{Dutta2021,
   abstract = {Automatic Speech Recognition (ASR) is the process of mapping an acoustic speech signal into a human readable text format. Traditional systems exploit the Acoustic Component of ASR using the Gaussian Mixture Model — Hidden Markov Model (GMM-HMM) approach. Deep Neural Network (DNN) opens up new possibilities to overcome the shortcomings of conventional statistical algorithms. Recent studies modeled the acoustic component of ASR system using DNN in the so called hybrid DNN-HMM approach. In the context of activation functions used to model the non-linearity in DNN, Rectified Linear Units (ReLU) and maxout units are mostly used in ASR systems. This paper concentrates on the acoustic component of a hybrid DNN-HMM system by proposing an efficient activation function for the DNN network. Inspired by previous works, euclidean norm activation function is proposed to model the non-linearity of the DNN network. Such non-linearity is shown to belong to the family of Piecewise Linear (PWL) functions having distinct features. These functions can capture deep hierarchical features of the pattern. The relevance of the proposal is examined in depth both theoretically and experimentally. The performance of the developed ASR system is evaluated in terms of Phone Error Rate (PER) using TIMIT database. Experimental results achieve a relative increase in performance by using the proposed function over conventional activation functions.},
   author = {Anirban Dutta and Gudmalwar Ashishkumar and Ch V Rama Rao},
   doi = {10.1007/s11704-020-9419-z},
   issn = {2095-2236},
   issue = {4},
   journal = {Frontiers of Computer Science},
   pages = {154705},
   title = {Performance analysis of ASR system in hybrid DNN-HMM framework using a PWL euclidean activation function},
   volume = {15},
   url = {https://doi.org/10.1007/s11704-020-9419-z},
   year = {2021},
}
@inproceedings{Pan2012,
   author = {J Pan and C Liu and Z Wang and Y Hu and H Jiang},
   doi = {10.1109/ISCSLP.2012.6423452},
   journal = {2012 8th International Symposium on Chinese Spoken Language Processing},
   pages = {301-305},
   title = {Investigation of deep neural networks (DNN) for large vocabulary continuous speech recognition: Why DNN surpasses GMMS in acoustic modeling},
   year = {2012},
}
@inproceedings{Correll2022,
   author = {J M Correll and L Jie and S Song and S Lee and J Zhu and W Tang and L Wormald and J Erhardt and N Breil and R Quon and D Kamalanathan and S Krishnan and M Chudzik and Z Zhang and W D Lu and M P Flynn},
   doi = {10.1109/VLSITechnologyandCir46769.2022.9830490},
   isbn = {2158-9682},
   journal = {2022 IEEE Symposium on VLSI Technology and Circuits (VLSI Technology and Circuits)},
   pages = {264-265},
   title = {An 8-bit 20.7 TOPS/W Multi-Level Cell ReRAM-based Compute Engine},
   year = {2022},
}
@inproceedings{Tang2014,
   author = {X Tang and P -E. Gaillardon and G De Micheli},
   doi = {10.1109/FPT.2014.7082777},
   journal = {2014 International Conference on Field-Programmable Technology (FPT)},
   pages = {207-214},
   title = {A high-performance low-power near-Vt {RRAM}-based {FPGA}},
   year = {2014},
}
@inproceedings{Gaillardon2012,
   author = {P -E. Gaillardon and D Sacchetto and S Bobba and Y Leblebici and G De Micheli},
   doi = {10.1109/VLSI-SoC.2012.7332083},
   journal = {2012 IEEE/IFIP 20th International Conference on VLSI and System-on-Chip (VLSI-SoC)},
   pages = {94-98},
   title = {{GMS}: Generic memristive structure for non-volatile {FPGA}s},
   year = {2012},
}
@article{Cong2014,
   author = {J Cong and B Xiao},
   doi = {10.1109/TVLSI.2013.2259512},
   issn = {1557-9999},
   issue = {4},
   journal = {IEEE Transactions on Very Large Scale Integration (VLSI) Systems},
   pages = {864-877},
   title = {FPGA-RPI: A Novel FPGA Architecture With RRAM-Based Programmable Interconnects},
   volume = {22},
   year = {2014},
}
@article{Tanachutiwat2011,
   author = {S Tanachutiwat and M Liu and W Wang},
   doi = {10.1109/TVLSI.2010.2063444},
   issn = {1557-9999},
   issue = {11},
   journal = {IEEE Transactions on Very Large Scale Integration (VLSI) Systems},
   pages = {2023-2032},
   title = {FPGA Based on Integration of CMOS and RRAM},
   volume = {19},
   year = {2011},
}
@inproceedings{Li2015,
   author = {B Li and Lixue Xia and Peng Gu and Y Wang and Huazhong Yang},
   doi = {10.1145/2744769.2744870},
   isbn = {0738-100X},
   journal = {2015 52nd ACM/EDAC/IEEE Design Automation Conference (DAC)},
   pages = {1-6},
   title = {MErging the Interface: Power, area and accuracy co-optimization for RRAM crossbar-based mixed-signal computing system},
   year = {2015},
}
@inproceedings{Xia2016,
   author = {L Xia and T Tang and W Huangfu and M Cheng and X Yin and B Li and Y Wang and H Yang},
   doi = {10.1145/2897937.2898101},
   journal = {2016 53nd ACM/EDAC/IEEE Design Automation Conference (DAC)},
   pages = {1-6},
   title = {Switched by input: Power efficient structure for RRAM-based convolutional neural network},
   year = {2016},
}
@article{Li2018,
   abstract = {Memristors with tunable resistance states are emerging building blocks of artificial neural networks. However, in situ learning on a large-scale multiple-layer memristor network has yet to be demonstrated because of challenges in device property engineering and circuit integration. Here we monolithically integrate hafnium oxide-based memristors with a foundry-made transistor array into a multiple-layer neural network. We experimentally demonstrate in situ learning capability and achieve competitive classification accuracy on a standard machine learning dataset, which further confirms that the training algorithm allows the network to adapt to hardware imperfections. Our simulation using the experimental parameters suggests that a larger network would further increase the classification accuracy. The memristor neural network is a promising hardware platform for artificial intelligence with high speed-energy efficiency.},
   author = {Can Li and Daniel Belkin and Yunning Li and Peng Yan and Miao Hu and Ning Ge and Hao Jiang and Eric Montgomery and Peng Lin and Zhongrui Wang and Wenhao Song and John Paul Strachan and Mark Barnell and Qing Wu and R Stanley Williams and J Joshua Yang and Qiangfei Xia},
   doi = {10.1038/s41467-018-04484-2},
   issn = {2041-1723},
   issue = {1},
   journal = {Nature Communications},
   pages = {2385},
   title = {Efficient and self-adaptive in-situ learning in multilayer memristor neural networks},
   volume = {9},
   url = {https://doi.org/10.1038/s41467-018-04484-2},
   year = {2018},
}
@article{Yao2017,
   abstract = {Conventional hardware platforms consume huge amount of energy for cognitive learning due to the data movement between the processor and the off-chip memory. Brain-inspired device technologies using analogue weight storage allow to complete cognitive tasks more efficiently. Here we present an analogue non-volatile resistive memory (an electronic synapse) with foundry friendly materials. The device shows bidirectional continuous weight modulation behaviour. Grey-scale face classification is experimentally demonstrated using an integrated 1024-cell array with parallel online training. The energy consumption within the analogue synapses for each iteration is 1,000 × (20 ×) lower compared to an implementation using Intel Xeon Phi processor with off-chip memory (with hypothetical on-chip digital resistive random access memory). The accuracy on test sets is close to the result using a central processing unit. These experimental results consolidate the feasibility of analogue synaptic array and pave the way toward building an energy efficient and large-scale neuromorphic system.},
   author = {Peng Yao and Huaqiang Wu and Bin Gao and Sukru Burc Eryilmaz and Xueyao Huang and Wenqiang Zhang and Qingtian Zhang and Ning Deng and Luping Shi and H.-S. Philip Wong and He Qian},
   doi = {10.1038/ncomms15199},
   issn = {2041-1723},
   issue = {1},
   journal = {Nature Communications},
   pages = {15199},
   title = {Face classification using electronic synapses},
   volume = {8},
   url = {https://doi.org/10.1038/ncomms15199},
   year = {2017},
}
@article{Sivan2019,
   abstract = {3D monolithic integration of logic and memory has been the most sought after solution to surpass the Von Neumann bottleneck, for which a low-temperature processed material system becomes inevitable. Two-dimensional materials, with their excellent electrical properties and low thermal budget are potential candidates. Here, we demonstrate a low-temperature hybrid co-integration of one-transistor-one-resistor memory cell, comprising a surface functionalized 2D WSe2 p-FET, with a solution-processed WSe2 Resistive Random Access Memory. The employed plasma oxidation technique results in a low Schottky barrier height of 25 meV with a mobility of 230 cm2 V−1 s−1, leading to a 100x performance enhanced WSe2 p-FET, while the defective WSe2 Resistive Random Access Memory exhibits a switching energy of 2.6 pJ per bit. Furthermore, guided by our device-circuit modelling, we propose vertically stacked channel FETs for high-density sub-0.01 μm2 memory cells, offering a new beyond-Si solution to enable 3-D embedded memories for future computing systems.},
   author = {Maheswari Sivan and Yida Li and Hasita Veluri and Yunshan Zhao and Baoshan Tang and Xinghua Wang and Evgeny Zamburg and Jin Feng Leong and Jessie Xuhua Niu and Umesh Chand and Aaron Voon-Yew Thean},
   doi = {10.1038/s41467-019-13176-4},
   issn = {2041-1723},
   issue = {1},
   journal = {Nature Communications},
   pages = {5201},
   title = {All WSe2 1T1R resistive RAM cell for future monolithic 3D embedded memory integration},
   volume = {10},
   url = {https://doi.org/10.1038/s41467-019-13176-4},
   year = {2019},
}
@article{Zidan2017,
   abstract = {Advances in electronics have revolutionized the way people work, play and communicate with each other. Historically, these advances were mainly driven by CMOS transistor scaling following Moore’s law, where new generations of devices are smaller, faster, and cheaper, leading to more powerful circuits and systems. However, conventional scaling is now facing major technical challenges and fundamental limits. New materials, devices, and architectures are being aggressively pursued to meet present and future computing needs, where tight integration of memory and logic, and parallel processing are highly desired. To this end, one class of emerging devices, termed memristors or memristive devices, have attracted broad interest as a promising candidate for future memory and computing applications. Besides tremendous appeal in data storage applications, memristors offer the potential to enable efficient hardware realization of neuromorphic and analog computing architectures that differ radically from conventional von Neumann computing architectures. In this review, we analyze representative memristor devices and their applications including mixed signal analog-digital neuromorphic computing architectures, and highlight the potential and challenges of applying such devices and architectures in different computing applications.},
   author = {Mohammed A Zidan and An Chen and Giacomo Indiveri and Wei D Lu},
   doi = {10.1007/s10832-017-0103-0},
   issn = {1573-8663},
   issue = {1},
   journal = {Journal of Electroceramics},
   pages = {4-20},
   title = {Memristive computing devices and applications},
   volume = {39},
   url = {https://doi.org/10.1007/s10832-017-0103-0},
   year = {2017},
}
@article{Wang2018,
   abstract = {Perpendicular magnetic tunnel junctions based on MgO/CoFeB structures are of particular interest for magnetic random-access memories because of their excellent thermal stability, scaling potential, and power dissipation. However, the major challenge of current-induced switching in the nanopillars with both a large tunnel magnetoresistance ratio and a low junction resistance is still to be met. Here, we report spin transfer torque switching in nano-scale perpendicular magnetic tunnel junctions with a magnetoresistance ratio up to 249% and a resistance area product as low as 7.0 Ω µm2, which consists of atom-thick W layers and double MgO/CoFeB interfaces. The efficient resonant tunnelling transmission induced by the atom-thick W layers could contribute to the larger magnetoresistance ratio than conventional structures with Ta layers, in addition to the robustness of W layers against high-temperature diffusion during annealing. The critical switching current density could be lower than 3.0 MA cm−2 for devices with a 45-nm radius.},
   author = {Mengxing Wang and Wenlong Cai and Kaihua Cao and Jiaqi Zhou and Jerzy Wrona and Shouzhong Peng and Huaiwen Yang and Jiaqi Wei and Wang Kang and Youguang Zhang and Jürgen Langer and Berthold Ocker and Albert Fert and Weisheng Zhao},
   doi = {10.1038/s41467-018-03140-z},
   issn = {2041-1723},
   issue = {1},
   journal = {Nature Communications},
   pages = {671},
   title = {Current-induced magnetization switching in atom-thick tungsten engineered perpendicular magnetic tunnel junctions with large tunnel magnetoresistance},
   volume = {9},
   url = {https://doi.org/10.1038/s41467-018-03140-z},
   year = {2018},
}
@article{Perez2019,
   author = {Eduardo Perez and Mamathamba K Mahadevaiah and Cristian Zambelli and Piero Olivo and Christian Wenger},
   doi = {10.1116/1.5054983},
   issn = {2166-2746},
   issue = {1},
   journal = {Journal of Vacuum Science & Technology B},
   month = {1},
   note = {doi: 10.1116/1.5054983},
   pages = {012202},
   publisher = {American Vacuum Society},
   title = {Data retention investigation in Al:HfO2-based resistive random access memory arrays by using high-temperature accelerated tests},
   volume = {37},
   url = {https://doi.org/10.1116/1.5054983},
   year = {2019},
}
@inproceedings{Tang2020,
   author = {X Tang and E Giacomin and P Cadareanu and G Gore and P -E. Gaillardon},
   doi = {10.23919/DATE48585.2020.9116478},
   isbn = {1558-1101},
   journal = {2020 Design, Automation & Test in Europe Conference & Exhibition (DATE)},
   pages = {144-a-144-f},
   title = {A RRAM-based FPGA for Energy-efficient Edge Computing},
   year = {2020},
}
@article{Calhoun2010,
   author = {B H Calhoun and J F Ryan and S Khanna and M Putic and J Lach},
   doi = {10.1109/JPROC.2009.2037211},
   issn = {1558-2256},
   issue = {2},
   journal = {Proceedings of the IEEE},
   pages = {267-282},
   title = {Flexible Circuits and Architectures for Ultralow Power},
   volume = {98},
   year = {2010},
}
@article{Tuan2007,
   author = {T Tuan and A Rahman and S Das and S Trimberger and S Kao},
   doi = {10.1109/TCAD.2006.885731},
   issn = {1937-4151},
   issue = {2},
   journal = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
   pages = {296-300},
   title = {A 90-nm Low-Power FPGA for Battery-Powered Applications},
   volume = {26},
   year = {2007},
}
@book{Kuon2009,
   author = {Ian Kuon and Jonathan Rose},
   city = {New York},
   doi = {10.1007/978-1-4419-0739-4},
   isbn = {978-1-4419-0738-7},
   month = {10},
   publisher = {Springer},
   title = {Quantifying and Exploring the Gap Between FPGAs and ASICs},
   year = {2009},
}
@article{Lin2007,
   author = {M Lin and A El Gamal and Y -C. Lu and S Wong},
   doi = {10.1109/TCAD.2006.887920},
   issn = {1937-4151},
   issue = {2},
   journal = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
   pages = {216-229},
   title = {Performance Benefits of Monolithically Stacked 3-D FPGA},
   volume = {26},
   year = {2007},
}
@inproceedings{Hutton2004,
   abstract = {This paper proposes a new adaptable FPGA logic element based on fracturable 6-LUTs, which fundamentally alters the longstanding belief that a 4-LUT is the most efficient area/delay tradeoff. We will describe theory and benchmarking results showing a 15% performance increase with 12% area decrease vs. a standard BLE4. The ALM structure is one of a number of architectural improvements giving Altera’s 90nm Stratix II architecture a 50% performance advantage over its 130nm Stratix predecessor.},
   author = {Mike Hutton and Jay Schleicher and David Lewis and Bruce Pedersen and Richard Yuan and Sinan Kaptanoglu and Gregg Baeckler and Boris Ratchev and Ketan Padalia and Mark Bourgeault and Andy Lee and Henry Kim and Rahul Saini},
   city = {Berlin, Heidelberg},
   editor = {Jürgen Becker and Marco Platzner and Serge Vernalde},
   isbn = {978-3-540-30117-2},
   journal = {Field Programmable Logic and Application},
   pages = {135-144},
   publisher = {Springer Berlin Heidelberg},
   title = {Improving FPGA Performance and Area Using an Adaptive Logic Module},
   year = {2004},
}
@book{Betz1999,
   author = {Vaughn Betz and Jonathan Rose and Alexander Marquardt},
   city = {New York},
   doi = {https://doi.org/10.1007/978-1-4615-5145-4},
   isbn = {978-1-4613-7342-1},
   issn = {0893-3405},
   institution = {Springer},
   month = {3},
   title = {Architecture and CAD for Deep-Submicron FPGAs},
   year = {1999},
}
@inproceedings{Tang2019,
   author = {X Tang and E Giacomin and A Alacchi and B Chauviere and P -E. Gaillardon},
   doi = {10.1109/FPL.2019.00065},
   isbn = {1946-1488},
   journal = {2019 29th International Conference on Field Programmable Logic and Applications (FPL)},
   pages = {367-374},
   title = {OpenFPGA: An Opensource Framework Enabling Rapid Prototyping of Customizable FPGAs},
   year = {2019},
}
@article{Lin2021,
   author = {J Lin and C -D. Wen and X Hu and T Tang and I -C. Lin and Y Wang and Y Xie},
   doi = {10.1109/TCAD.2020.3037316},
   issn = {1937-4151},
   issue = {10},
   journal = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
   pages = {2049-2062},
   title = {Rescuing RRAM-Based Computing From Static and Dynamic Faults},
   volume = {40},
   year = {2021},
}
@article{Suh1995,
   author = {Kang-Deog Suh and Byung-Hoon Suh and Young-Ho Lim and Jin-Ki Kim and Young-Joon Choi and Yong-Nam Koh and Sung-Soo Lee and Suk-Chon Kwon and Byung-Soon Choi and Jin-Sun Yum and Jung-Hyuk Choi and Jang-Rae Kim and Hyung-Kyu Lim},
   doi = {10.1109/4.475701},
   issn = {1558-173X},
   issue = {11},
   journal = {IEEE Journal of Solid-State Circuits},
   pages = {1149-1156},
   title = {A 3.3 V 32 Mb NAND flash memory with incremental step pulse programming scheme},
   volume = {30},
   year = {1995},
}
@article{Xiang2019,
   author = {Y Xiang and P Huang and Y Zhao and M Zhao and B Gao and H Wu and H Qian and X Liu and J Kang},
   doi = {10.1109/TED.2019.2931135},
   issn = {1557-9646},
   issue = {11},
   journal = {IEEE Transactions on Electron Devices},
   pages = {4517-4522},
   title = {Impacts of State Instability and Retention Failure of Filamentary Analog RRAM on the Performance of Deep Neural Network},
   volume = {66},
   year = {2019},
}
@article{Zhao2019,
   author = {M Zhao and B Gao and Y Xi and F Xu and H Wu and H Qian},
   doi = {10.1109/JEDS.2019.2943017},
   issn = {2168-6734},
   journal = {IEEE Journal of the Electron Devices Society},
   pages = {1239-1247},
   title = {Endurance and Retention Degradation of Intermediate Levels in Filamentary Analog RRAM},
   volume = {7},
   year = {2019},
}
@inproceedings{Zhao2017,
   author = {M Zhao and H Wu and B Gao and Q Zhang and W Wu and S Wang and Y Xi and D Wu and N Deng and S Yu and H -Y. Chen and H Qian},
   doi = {10.1109/IEDM.2017.8268522},
   isbn = {2156-017X},
   journal = {2017 IEEE International Electron Devices Meeting (IEDM)},
   pages = {39.4.1-39.4.4},
   title = {Investigation of statistical retention of filamentary analog RRAM for neuromophic computing},
   year = {2017},
}
@article{Graves2013,
   abstract = {This paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time. The approach is demonstrated for text (where the data are discrete) and online handwriting (where the data are real-valued). It is then extended to handwriting synthesis by allowing the network to condition its predictions on a text sequence. The resulting system is able to generate highly realistic cursive handwriting in a wide variety of styles.},
   author = {Alex Graves},
   pages = {1-43},
   title = {Generating Sequences With Recurrent Neural Networks},
   url = {http://arxiv.org/abs/1308.0850},
   year = {2013},
}
@article{Masland2012,
   abstract = {The mammalian retina consists of neurons of >60 distinct types, each playing a  specific role in processing visual images. They are arranged in three main stages. The first decomposes the outputs of the rod and cone photoreceptors into ∼12 parallel information streams. The second connects these streams to specific types of retinal ganglion cells. The third combines bipolar and amacrine cell activity to create the diverse encodings of the visual world--roughly 20 of them--that the retina transmits to the brain. New transformations of the visual input continue to be found: at least half of the encodings sent to the brain (ganglion cell response selectivities) remain to be discovered. This diversity of the retina's outputs has yet to be incorporated into our understanding of higher visual function.},
   author = {Richard H Masland},
   doi = {10.1016/j.neuron.2012.10.002},
   issn = {1097-4199 (Electronic)},
   issue = {2},
   journal = {Neuron},
   keywords = {Animals,Humans,Nerve Net,Neurons,Retina,Visual Pathways,classification,cytology,physiology},
   month = {10},
   pages = {266-280},
   pmid = {23083731},
   title = {The neuronal organization of the retina.},
   volume = {76},
   year = {2012},
}
@generic{Tapiador-Morales2020,
   abstract = {Neuromorphic vision sensors detect changes in luminosity taking inspiration from mammalian retina and providing a stream of events with high temporal resolution, also known as Dynamic Vision Sensors (DVS). This continuous stream of events can be used to extract spatio-temporal patterns from a scene. A time-surface represents a spatio-temporal context for a given spatial radius around an incoming event from a sensor at a specific time history. Time-surfaces can be organized in a hierarchical way to extract features from input events using the Hierarchy Of Time-Surfaces algorithm, hereinafter HOTS. HOTS can be organized in consecutive layers to extract combination of features in a similar way as some deep-learning algorithms do. This work introduces a novel FPGA architecture for accelerating HOTS network. This architecture is mainly based on block-RAM memory and the non-restoring square root algorithm, requiring basic components and enabling it for low-power low-latency embedded applications. The presented architecture has been tested on a Zynq 7100 platform at 100 MHz. The results show that the latencies are in the range of 1 &mu; s to 6.7 &mu; s, requiring a maximum dynamic power consumption of 77 mW. This system was tested with a gesture recognition dataset, obtaining an accuracy loss for 16-bit precision of only 1.2\% with respect to the original software HOTS.},
   author = {Ricardo Tapiador-Morales and Jean-Matthieu Maro and Angel Jimenez-Fernandez and Gabriel Jimenez-Moreno and Ryad Benosman and Alejandro Linares-Barranco},
   doi = {10.3390/s20123404},
   isbn = {1424-8220},
   issue = {12},
   journal = {Sensors},
   keywords = {AER,FPGA,HDL,dynamic vision sensors,event-based,pattern recognition,synchronous digital VLSI},
   title = {Event-Based Gesture Recognition through a Hierarchy of {Time-Surfaces} for {FPGA}},
   volume = {20},
   year = {2020},
}
@article{Neftci2019,
   abstract = {Spiking neural networks are nature's versatile solution to fault-tolerant and energy efficient signal processing. To translate these benefits into hardware, a growing number of neuromorphic spiking neural network processors attempt to emulate biological neural networks. These developments have created an imminent need for methods and tools to enable such systems to solve real-world signal processing problems. Like conventional neural networks, spiking neural networks can be trained on real, domain specific data. However, their training requires overcoming a number of challenges linked to their binary and dynamical nature. This article elucidates step-by-step the problems typically encountered when training spiking neural networks, and guides the reader through the key concepts of synaptic plasticity and data-driven learning in the spiking setting. To that end, it gives an overview of existing approaches and provides an introduction to surrogate gradient methods, specifically, as a particularly flexible and efficient method to overcome the aforementioned challenges.},
   author = {Emre O. Neftci and Hesham Mostafa and Friedemann Zenke},
   pages = {1-25},
   title = {Surrogate Gradient Learning in Spiking Neural Networks},
   url = {http://arxiv.org/abs/1901.09948},
   year = {2019},
}
@article{Rebecq2017,
   abstract = {Event cameras are bio-inspired vision sensors that output pixel-level brightness changes instead of standard intensity frames. They offer significant advantages over standard cameras, namely a very high dynamic range, no motion blur, and a latency in the order of microseconds. We propose a novel, accurate tightly-coupled visual-inertial odometry pipeline for such cameras that leverages their outstanding properties to estimate the camera ego-motion in challenging conditions, such as high-speed motion or high dynamic range scenes. The method tracks a set of features (extracted on the image plane) through time. To achieve that, we consider events in overlapping spatio-temporal windows and align them using the current camera motion and scene structure, yielding motion-compensated event frames. We then combine these feature tracks in a keyframe-based, visual-inertial odometry algorithm based on nonlinear optimization to estimate the camera’s 6-DOF pose, velocity, and IMU biases. The proposed method is evaluated quantitatively on the public Event Camera Dataset [19] and significantly outperforms the state-of-the-art [28], while being computationally much more efficient: our pipeline can run much faster than real-time on a laptop and even on a smartphone processor. Furthermore, we demonstrate qualitatively the accuracy and robustness of our pipeline on a large-scale dataset, and an extremely high-speed dataset recorded by spinning an event camera on a leash at 850 deg/s.},
   author = {Henri Rebecq and Timo Horstschaefer and Davide Scaramuzza},
   doi = {10.5244/c.31.16},
   isbn = {190172560X},
   journal = {British Machine Vision Conference 2017, BMVC 2017},
   title = {Real-time visual-inertial odometry for event cameras using keyframe-based nonlinear optimization},
   year = {2017},
}
@article{Cannici2019,
   abstract = {Event-based cameras, also known as neuromorphic cameras, are bioinspired sensors able to perceive changes in the scene at high frequency with low power consumption. Becoming available only very recently, a limited amount of work addresses object detection on these devices. In this paper we propose two neural networks architectures for object detection: YOLE, which integrates the events into surfaces and uses a frame-based model to process them, and fcYOLE, an asynchronous event-based fully convolutional network which uses a novel and general formalization of the convolutional and max pooling layers to exploit the sparsity of camera events. We evaluate the algorithm with different extensions of publicly available datasets, and on a novel synthetic dataset.},
   author = {Marco Cannici and Marco Ciccone and Andrea Romanoni and Matteo Matteucci},
   doi = {10.1109/CVPRW.2019.00209},
   isbn = {9781728125060},
   issn = {21607516},
   journal = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
   pages = {1656-1665},
   title = {Asynchronous convolutional networks for object detection in neuromorphic cameras},
   volume = {2019-June},
   year = {2019},
}
@article{Bi2019,
   abstract = {Neuromorphic vision sensing (NVS) devices represent visual information as sequences of asynchronous discrete events (a.k.a., 'spikes'') in response to changes in scene reflectance. Unlike conventional active pixel sensing (APS), NVS allows for significantly higher event sampling rates at substantially increased energy efficiency and robustness to illumination changes. However, object classification with NVS streams cannot leverage on state-of-the-art convolutional neural networks (CNNs), since NVS does not produce frame representations. To circumvent this mismatch between sensing and processing with CNNs, we propose a compact graph representation for NVS. We couple this with novel residual graph CNN architectures and show that, when trained on spatio-temporal NVS data for object classification, such residual graph CNNs preserve the spatial and temporal coherence of spike events, while requiring less computation and memory. Finally, to address the absence of large real-world NVS datasets for complex recognition tasks, we present and make available a 100k dataset of NVS recordings of the American sign language letters, acquired with an iniLabs DAVIS240c device under real-world conditions.},
   author = {Yin Bi and Aaron Chadha and Alhabib Abbas and Eirina Bourtsoulatze and Yiannis Andreopoulos},
   doi = {10.1109/ICCV.2019.00058},
   isbn = {9781728148038},
   issn = {15505499},
   journal = {Proceedings of the IEEE International Conference on Computer Vision},
   pages = {491-501},
   title = {Graph-based object classification for neuromorphic vision sensing},
   volume = {2019-Octob},
   year = {2019},
}
@article{Leong2020,
   abstract = {This paper introduces a fusion convolutional architecture for efficient learning of spatio-temporal features in video action recognition. Unlike 2D convolutional neural networks (CNNs), 3D CNNs can be applied directly on consecutive frames to extract spatio-temporal features. The aim of this work is to fuse the convolution layers from 2D and 3D CNNs to allow temporal encoding with fewer parameters than 3D CNNs. We adopt transfer learning from pre-trained 2D CNNs for spatial extraction, followed by temporal encoding, before connecting to 3D convolution layers at the top of the architecture. We construct our fusion architecture, semi-CNN, based on three popular models: VGG-16, ResNets and DenseNets, and compare the performance with their corresponding 3D models. Our empirical results evaluated on the action recognition dataset UCF-101 demonstrate that our fusion of 1D, 2D and 3D convolutions outperforms its 3D model of the same depth, with fewer parameters and reduces overfitting. Our semi-CNN architecture achieved an average of 16-30% boost in the top-1 accuracy when evaluated on an input video of 16 frames.},
   author = {Mei Chee Leong and Dilip K. Prasad and Yong Tsui Lee and Feng Lin},
   doi = {10.3390/app10020557},
   issn = {20763417},
   issue = {2},
   journal = {Applied Sciences (Switzerland)},
   keywords = {Action recognition,Convolution network,Spatio-temporal features,Transfer learning},
   title = {{Semi-CNN} architecture for effective spatio-temporal learning in action recognition},
   volume = {10},
   year = {2020},
}
@article{Hochreiter1997,
   abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient-based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O(1). Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
   author = {Sepp Hochreiter and Jürgen Schmidhuber},
   doi = {10.1162/neco.1997.9.8.1735},
   issn = {08997667},
   issue = {8},
   journal = {Neural Computation},
   pages = {1735-1780},
   pmid = {9377276},
   title = {Long Short-Term Memory},
   volume = {9},
   year = {1997},
}
@article{Zheng2021,
   abstract = {Spiking neural networks (SNNs) are promising in a bio-plausible coding for spatio-temporal information and event-driven signal processing, which is very suited for energy-efficient implementation in neuromorphic hardware. However, the unique working mode of SNNs makes them more difficult to train than traditional networks. Currently, there are two main routes to explore the training of deep SNNs with high performance. The first is to convert a pre-trained ANN model to its SNN version, which usually requires a long coding window for convergence and cannot exploit the spatio-temporal features during training for solving temporal tasks. The other is to directly train SNNs in the spatio-temporal domain. But due to the binary spike activity of the firing function and the problem of gradient vanishing or explosion, current methods are restricted to shallow architectures and thereby difficult in harnessing large-scale datasets (e.g. ImageNet). To this end, we propose a threshold-dependent batch normalization (tdBN) method based on the emerging spatio-temporal backpropagation, termed “STBP-tdBN”, enabling direct training of a very deep SNN and the efficient implementation of its inference on neuromorphic hardware. With the proposed method and elaborated shortcut connection, we significantly extend directly-trained SNNs from a shallow structure (<10 layer) to a very deep structure (50 layers). Furthermore, we theoretically analyze the effectiveness of our method based on “Block Dynamical Isometry” theory. Finally, we report superior accuracy results including 93.15% on CIFAR-10, 67.8% on DVS-CIFAR10, and 67.05% on ImageNet with very few timesteps. To our best knowledge, it’s the first time to explore the directly-trained deep SNNs with high performance on ImageNet. We believe this work shall pave the way of fully exploiting the advantages of SNNs and attract more researchers to contribute in this field.},
   author = {Hanle Zheng and Yujie Wu and Lei Deng and Yifan Hu and Guoqi Li},
   doi = {10.1609/aaai.v35i12.17320},
   isbn = {9781713835974},
   issn = {2159-5399},
   journal = {35th AAAI Conference on Artificial Intelligence, AAAI 2021},
   keywords = {Machine Learning: (Deep) Neural Network Algorithms,Machine Learning: (Deep) Neural Network Learning T,Machine Learning: Bio-inspired Learning},
   pages = {11062-11070},
   title = {Going Deeper With Directly-Trained Larger Spiking Neural Networks},
   volume = {12B},
   year = {2021},
}
@article{Wu2022-LIAF,
   abstract = {Spiking neural networks (SNNs) based on the leaky integrate and fire (LIF) model have been applied to energy-efficient temporal and spatiotemporal processing tasks. Due to the bioplausible neuronal dynamics and simplicity, LIF-SNN benefits from event-driven processing, however, usually face the embarrassment of reduced performance. This may because, in LIF-SNN, the neurons transmit information via spikes. To address this issue, in this work, we propose a leaky integrate and analog fire (LIAF) neuron model so that analog values can be transmitted among neurons, and a deep network termed LIAF-Net is built on it for efficient spatiotemporal processing. In the temporal domain, LIAF follows the traditional LIF dynamics to maintain its temporal processing capability. In the spatial domain, LIAF is able to integrate spatial information through convolutional integration or fully connected integration. As a spatiotemporal layer, LIAF can also be used with traditional artificial neural network (ANN) layers jointly. In addition, the built network can be trained with backpropagation through time (BPTT) directly, which avoids the performance loss caused by ANN to SNN conversion. Experiment results indicate that LIAF-Net achieves comparable performance to the gated recurrent unit (GRU) and long short-term memory (LSTM) on bAbI question answering (QA) tasks and achieves state-of-the-art performance on spatiotemporal dynamic vision sensor (DVS) data sets, including MNIST-DVS, CIFAR10-DVS, and DVS128 Gesture, with much less number of synaptic weights and computational overhead compared with traditional networks built by LSTM, GRU, convolutional LSTM (ConvLSTM), or 3-D convolution (Conv3D). Compared with traditional LIF-SNN, LIAF-Net also shows dramatic accuracy gain on all these experiments. In conclusion, LIAF-Net provides a framework combining the advantages of both ANNs and SNNs for lightweight and efficient spatiotemporal information processing.},
   author = {Zhenzhi Wu and Hehui Zhang and Yihan Lin and Guoqi Li and Meng Wang and Ye Tang},
   doi = {10.1109/TNNLS.2021.3073016},
   issn = {21622388},
   issue = {11},
   journal = {IEEE Transactions on Neural Networks and Learning Systems},
   keywords = {Bioplausible neuronal dynamics,leaky integrate and fire (LIF) model,spatiotemporal information,spiking neural networks (SNNs)},
   pages = {6249-6262},
   pmid = {33979292},
   publisher = {IEEE},
   title = {{LIAF-Net}: Leaky Integrate and Analog Fire Network for Lightweight and Efficient Spatiotemporal Information Processing},
   volume = {33},
   year = {2022},
}
@article{Fang2021-deep,
   abstract = {Deep Spiking Neural Networks (SNNs) present optimization difficulties for gradient-based approaches due to discrete binary activation and complex spatialtemporal dynamics. Considering the huge success of ResNet in deep learning, it would be natural to train deep SNNs with residual learning. Previous Spiking ResNet mimics the standard residual block in ANNs and simply replaces ReLU activation layers with spiking neurons, which suffers the degradation problem and can hardly implement residual learning. In this paper, we propose the spikeelement- wise (SEW) ResNet to realize residual learning in deep SNNs. We prove that the SEW ResNet can easily implement identity mapping and overcome the vanishing/exploding gradient problems of Spiking ResNet. We evaluate our SEW ResNet on ImageNet, DVS Gesture, and CIFAR10-DVS datasets, and show that SEW ResNet outperforms the state-of-the-art directly trained SNNs in both accuracy and time-steps. Moreover, SEW ResNet can achieve higher performance by simply adding more layers, providing a simple method to train deep SNNs. To our best knowledge, this is the first time that directly training deep SNNs with more than 100 layers becomes possible. Our codes are available at https: //github.com/fangwei123456/Spike-Element-Wise-ResNet.},
   author = {Wei Fang and Zhaofei Yu and Yanqi Chen and Tiejun Huang and Timothee Masquelier and Yonghong Tian},
   isbn = {9781713845393},
   issn = {10495258},
   issue = {NeurIPS},
   journal = {Advances in Neural Information Processing Systems},
   pages = {21056-21069},
   title = {Deep Residual Learning in Spiking Neural Networks},
   volume = {25},
   year = {2021},
}
@article{Fang2021-incorporating,
   abstract = {Spiking Neural Networks (SNNs) have attracted enormous research interest due to temporal information processing capability, low power consumption, and high biological plausibility. However, the formulation of efficient and high-performance learning algorithms for SNNs is still challenging. Most existing learning methods learn weights only, and require manual tuning of the membrane-related parameters that determine the dynamics of a single spiking neuron. These parameters are typically chosen to be the same for all neurons, which limits the diversity of neurons and thus the expressiveness of the resulting SNNs. In this paper, we take inspiration from the observation that membrane-related parameters are different across brain regions, and propose a training algorithm that is capable of learning not only the synaptic weights but also the membrane time constants of SNNs. We show that incorporating learnable membrane time constants can make the network less sensitive to initial values and can speed up learning. In addition, we reevaluate the pooling methods in SNNs and find that max-pooling will not lead to significant information loss and have the advantage of low computation cost and binary compatibility. We evaluate the proposed method for image classification tasks on both traditional static MNIST, Fashion-MNIST, CIFAR-10 datasets, and neuromorphic N-MNIST, CIFAR10-DVS, DVS128 Gesture datasets. The experiment results show that the proposed method outperforms the state-of-the-art accuracy on nearly all datasets, using fewer time-steps. Our codes are available at https://github.com/fangwei123456/Parametric-Leaky-Integrate-and-Fire -Spiking-Neuron.},
   author = {Wei Fang and Zhaofei Yu and Yanqi Chen and Timothée Masquelier and Tiejun Huang and Yonghong Tian},
   doi = {10.1109/ICCV48922.2021.00266},
   isbn = {9781665428125},
   issn = {15505499},
   journal = {Proceedings of the IEEE International Conference on Computer Vision},
   pages = {2641-2651},
   title = {Incorporating Learnable Membrane Time Constant to Enhance Learning of Spiking Neural Networks},
   volume = {1},
   year = {2021},
}
@article{Deng2022,
   abstract = {Recently, brain-inspired spiking neuron networks (SNNs) have attracted widespread research interest because of their event-driven and energy-efficient characteristics. Still, it is difficult to efficiently train deep SNNs due to the non-differentiability of its activation function, which disables the typically used gradient descent approaches for traditional artificial neural networks (ANNs). Although the adoption of surrogate gradient (SG) formally allows for the back-propagation of losses, the discrete spiking mechanism actually differentiates the loss landscape of SNNs from that of ANNs, failing the surrogate gradient methods to achieve comparable accuracy as for ANNs. In this paper, we first analyze why the current direct training approach with surrogate gradient results in SNNs with poor generalizability. Then we introduce the temporal efficient training (TET) approach to compensate for the loss of momentum in the gradient descent with SG so that the training process can converge into flatter minima with better generalizability. Meanwhile, we demonstrate that TET improves the temporal scalability of SNN and induces a temporal inheritable training for acceleration. Our method consistently outperforms the SOTA on all reported mainstream datasets, including CIFAR-10/100 and ImageNet. Remarkably on DVS-CIFAR10, we obtained 83$\%$ top-1 accuracy, over 10$\%$ improvement compared to existing state of the art. Codes are available at \url\{https://github.com/Gus-Lab/temporal_efficient_training\}.},
   author = {Shikuang Deng and Yuhang Li and Shanghang Zhang and Shi Gu},
   journal = {International Conference on Learning Representations (ICLR)},
   pages = {1-17},
   title = {Temporal Efficient Training of Spiking Neural Network via Gradient Re-weighting},
   url = {http://arxiv.org/abs/2202.11946},
   year = {2022},
}
@article{Eshraghian2021,
   abstract = {The brain is the perfect place to look for inspiration to develop more efficient neural networks. The inner workings of our synapses and neurons provide a glimpse at what the future of deep learning might look like. This paper serves as a tutorial and perspective showing how to apply the lessons learnt from several decades of research in deep learning, gradient descent, backpropagation and neuroscience to biologically plausible spiking neural neural networks. We also explore the delicate interplay between encoding data as spikes and the learning process; the challenges and solutions of applying gradient-based learning to spiking neural networks; the subtle link between temporal backpropagation and spike timing dependent plasticity, and how deep learning might move towards biologically plausible online learning. Some ideas are well accepted and commonly used amongst the neuromorphic engineering community, while others are presented or justified for the first time here. A series of companion interactive tutorials complementary to this paper using our Python package, snnTorch, are also made available: https://snntorch.readthedocs.io/en/latest/tutorials/index.html},
   author = {Jason K. Eshraghian and Max Ward and Emre Neftci and Xinxin Wang and Gregor Lenz and Girish Dwivedi and Mohammed Bennamoun and Doo Seok Jeong and Wei D. Lu},
   title = {Training Spiking Neural Networks Using Lessons From Deep Learning},
   url = {http://arxiv.org/abs/2109.12894},
   year = {2021},
}
@article{Ioffe2015,
   abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82% top-5 test error, exceeding the accuracy of human raters.},
   author = {Sergey Ioffe and Christian Szegedy},
   isbn = {9781510810587},
   journal = {32nd International Conference on Machine Learning, ICML 2015},
   pages = {448-456},
   title = {Batch normalization: Accelerating deep network training by reducing internal covariate shift},
   volume = {1},
   year = {2015},
}
@article{Zhu2019,
   author = {Alex Zihao Zhu and Liangzhe Yuan and Kenneth Chaney and Kostas Daniilidis},
   doi = {10.1109/CVPRW.2019.00216},
   isbn = {9781728125060},
   issn = {21607516},
   journal = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
   pages = {1694},
   title = {Unsupervised event-based learning of optical flow, depth and egomotion},
   volume = {2019-June},
   year = {2019},
}
@article{Wang2019,
   abstract = {The recently developed event cameras can directly sense the motion by generating an asynchronous sequence of events, i.e., an event stream, where each individual event (x, y, t) corresponds to the space-time location when a pixel sensor captures an intensity change. Compared with RGB cameras, event cameras are frameless but can capture much faster motion, therefore have great potential for recognizing gestures of fast motions. To deal with the unique output of event cameras, previous methods often treat event streams as time sequences, thus do not fully explore the space-time sparsity and structure of the event stream data. In this work, we treat the event stream as a set of 3D points in space-time, i.e., space-time event clouds. To analyze event clouds and recognize gestures, we propose to leverage PointNet, a neural network architecture originally designed for matching and recognizing 3D point clouds. We adapt PointNet to cater to event clouds for real-time gesture recognition. On the benchmark dataset of event camera based gesture recognition, i.e., IBM DVS128 Gesture dataset, our proposed method achieves a high accuracy of 97.08% and performs the best among existing methods.},
   author = {Qinyi Wang and Yexin Zhang and Junsong Yuan and Yilong Lu},
   doi = {10.1109/WACV.2019.00199},
   isbn = {9781728119755},
   journal = {Proceedings - 2019 IEEE Winter Conference on Applications of Computer Vision, WACV 2019},
   pages = {1826-1835},
   publisher = {IEEE},
   title = {Space-time event clouds for gesture recognition: From RGB cameras to event cameras},
   year = {2019},
}
@article{Chung2014,
   abstract = {In this paper we compare different types of recurrent units in recurrent neural networks (RNNs). Especially, we focus on more sophisticated units that implement a gating mechanism, such as a long short-term memory (LSTM) unit and a recently proposed gated recurrent unit (GRU). We evaluate these recurrent units on the tasks of polyphonic music modeling and speech signal modeling. Our experiments revealed that these advanced recurrent units are indeed better than more traditional recurrent units such as tanh units. Also, we found GRU to be comparable to LSTM.},
   author = {Junyoung Chung and Caglar Gulcehre and KyungHyun Cho and Yoshua Bengio},
   pages = {1-9},
   title = {Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling},
   url = {http://arxiv.org/abs/1412.3555},
   year = {2014},
}
@article{Shrestha2018,
   abstract = {Configuring deep Spiking Neural Networks (SNNs) is an exciting research avenue for low power spike event based computation. However, the spike generation function is non-differentiable and therefore not directly compatible with the standard error backpropagation algorithm. In this paper, we introduce a new general backpropagation mechanism for learning synaptic weights and axonal delays which overcomes the problem of non-differentiability of the spike function and uses a temporal credit assignment policy for backpropagating error to preceding layers. We describe and release a GPU accelerated software implementation of our method which allows training both fully connected and convolutional neural network (CNN) architectures. Using our software, we compare our method against existing SNN based learning approaches and standard ANN to SNN conversion techniques and show that our method achieves state of the art performance for an SNN on the MNIST, NMNIST, DVS Gesture, and TIDIGITS datasets.},
   author = {Sumit Bam Shrestha and Garrick Orchard},
   issn = {10495258},
   issue = {NeurIPS},
   journal = {Advances in Neural Information Processing Systems},
   keywords = {ek laboratories,national university of singapore,nus},
   pages = {1412-1421},
   title = {{Slayer}: Spike layer error reassignment in time},
   volume = {2018-Decem},
   year = {2018},
}
@article{Tan2022,
   abstract = {Automatic lip-reading (ALR) aims to recognize words using visual information from the speaker's lip movements. In this work, we introduce a novel type of sensing device, event cameras, for the task of ALR. Event cameras have both technical and application advantages over conventional cameras for the ALR task because they have higher temporal resolution, less redundant visual information, and lower power consumption. To recognize words from the event data, we propose a novel Multi-grained Spatio-Temporal Features Perceived Network (MSTP) to perceive fine-grained spatio-temporal features from microsecond time-resolved event data. Specifically, a multi-branch network architecture is designed, in which different grained spatio-temporal features are learned by operating at different frame rates. The branch operating on the low frame rate can perceive spatial complete but temporal coarse features. While the branch operating on the high frame rate can perceive spatial coarse but temporal refinement features. And a message flow module is devised to integrate the features from different branches, leading to perceiving more discriminative spatio-temporal features. In addition, we present the first event-based lip-reading dataset (DVS-Lip) captured by the event camera. Experimental results demonstrated the superiority of the proposed model compared to the state-of-the-art event-based action recognition models and video-based lip-reading models.},
   author = {Ganchao Tan and Yang Wang and Han Han and Yang Cao and Feng Wu and Zheng Jun Zha},
   doi = {10.1109/CVPR52688.2022.01946},
   isbn = {9781665469463},
   issn = {10636919},
   journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
   keywords = {Action and event recognition,Datasets and evaluation,Vision applications and systems},
   pages = {20062-20071},
   title = {Multi-grained Spatio-Temporal Features Perceived Network for Event-based Lip-Reading},
   volume = {2022-June},
   year = {2022},
}
@article{Carreira2017,
   abstract = {The paucity of videos in current action classification datasets (UCF-101 and HMDB-51) has made it difficult to identify good video architectures, as most methods ob- tain similar performance on existing small-scale bench- marks. This paper re-evaluates state-of-the-art architec- tures in light of the new Kinetics Human Action Video dataset. Kinetics has two orders of magnitude more data, with 400 human action classes and over 400 clips per class, and is collected from realistic, challenging YouTube videos. We provide an analysis on how current architectures fare on the task of action classification on this dataset and how much performance improves on the smaller benchmark datasets after pre-training on Kinetics. We also introduce a new Two-Stream Inflated 3D Con- vNet (I3D) that is based on 2D ConvNet inflation: fil- ters and pooling kernels of very deep image classifica- tion ConvNets are expanded into 3D, making it possible to learn seamless spatio-temporal feature extractors from video while leveraging successful ImageNet architecture designs and even their parameters. We show that, after pre-training on Kinetics, I3D models considerably improve upon the state-of-the-art in action classification, reaching 80.2% on HMDB-51 and 97.9% on UCF-101.},
   author = {Joao Carreira and Andrew Zisserman},
   journal = {Computer Vision and Pattern Recognition (CVPR)},
   pages = {6299-6308},
   title = {Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset},
   year = {2017},
}
@article{Liu2021-TAM,
   abstract = {Video data is with complex temporal dynamics due to various factors such as camera motion, speed variation, and different activities. To effectively capture this diverse motion pattern, this paper presents a new temporal adaptive module (TAM) to generate video-specific temporal kernels based on its own feature map. TAM proposes a unique two-level adaptive modeling scheme by decoupling the dynamic kernel into a location sensitive importance map and a location invariant aggregation weight. The importance map is learned in a local temporal window to capture short-term information, while the aggregation weight is generated from a global view with a focus on long-term structure. TAM is a modular block and could be integrated into 2D CNNs to yield a powerful video architecture (TANet) with a very small extra computational cost. The extensive experiments on Kinetics-400 and Something-Something datasets demonstrate that our TAM outperforms other temporal modeling methods consistently, and achieves the state-of-the-art performance under the similar complexity. The code is available at https://github.com/liu-zhy/temporal-adaptive-module.},
   author = {Zhaoyang Liu and Limin Wang and Wayne Wu and Chen Qian and Tong Lu},
   doi = {10.1109/ICCV48922.2021.01345},
   isbn = {9781665428125},
   issn = {15505499},
   journal = {Proceedings of the IEEE International Conference on Computer Vision},
   pages = {13688-13698},
   title = {{TAM}: Temporal Adaptive Module for Video Recognition},
   year = {2021},
}
@article{Wang2022-event-stream,
   author = {Y Wang and X Zhang and Y Shen and B Du and G Zhao and L Cui and H Wen},
   doi = {10.1109/TPAMI.2021.3054886},
   issn = {1939-3539 VO  - 44},
   issue = {7},
   journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
   pages = {3436-3449},
   title = {Event-Stream Representation for Human Gaits Identification Using Deep Neural Networks},
   volume = {44},
   year = {2022},
}
@article{Wang2019-EV-gait,
   abstract = {In this paper, we introduce a new type of sensing modality, the Dynamic Vision Sensors (Event Cameras), for the task of gait recognition. Compared with the traditional RGB sensors, the event cameras have many unique advantages such as ultra low resources consumption, high temporal resolution and much larger dynamic range. However, those cameras only produce noisy and asynchronous events of intensity changes rather than frames, where conventional vision-based gait recognition algorithms can't be directly applied. To address this, we propose a new Event-based Gait Recognition (EV-Gait) approach, which exploits motion consistency to effectively remove noise, and uses a deep neural network to recognise gait from the event streams. To evaluate the performance of EV-Gait, we collect two event-based gait datasets, one from real-world experiments and the other by converting the publicly available RGB gait recognition benchmark CASIA-B. Extensive experiments show that EV-Gait can get nearly 96% recognition accuracy in the real-world settings, while on the CASIA-B benchmark it achieves comparable performance with state-of-the-art RGB-based gait recognition approaches.},
   author = {Yanxiang Wang and Bowen Du and Yiran Shen and Kai Wu and Guangrong Zhao and Jianguo Sun and Hongkai Wen},
   doi = {10.1109/CVPR.2019.00652},
   isbn = {9781728132938},
   issn = {10636919},
   journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
   keywords = {And Body Pose,Categorization,Face,Gesture,Others,Recognition: Detection,Retrieval,Vision Applications and Systems},
   pages = {6351-6360},
   title = {{EV-gait}: Event-based robust gait recognition using dynamic vision sensors},
   volume = {2019-June},
   year = {2019},
}
@article{Gehrig2019,
   abstract = {Event cameras are vision sensors that record asynchronous streams of per-pixel brightness changes, referred to as 'events'. They have appealing advantages over frame based cameras for computer vision, including high temporal resolution, high dynamic range, and no motion blur. Due to the sparse, non-uniform spatio-temporal layout of the event signal, pattern recognition algorithms typically aggregate events into a grid-based representation and subsequently process it by a standard vision pipeline, e.g., Convolutional Neural Network (CNN). In this work, we introduce a general framework to convert event streams into grid-based representations by means of strictly differentiable operations. Our framework comes with two main advantages: (i) allows learning the input event representation together with the task dedicated network in an end to end manner, and (ii) lays out a taxonomy that unifies the majority of extant event representations in the literature and identifies novel ones. Empirically, we show that our approach to learning the event representation end-to-end yields an improvement of approximately 12\% on optical flow estimation and object recognition over state-of-the-art methods.},
   author = {Daniel Gehrig and Antonio Loquercio and Konstantinos Derpanis and Davide Scaramuzza},
   doi = {10.1109/ICCV.2019.00573},
   isbn = {9781728148038},
   issn = {15505499},
   issue = {ICCV},
   journal = {Proceedings of the IEEE International Conference on Computer Vision},
   pages = {5632-5642},
   title = {End-to-end learning of representations for asynchronous event-based data},
   volume = {2019-Octob},
   year = {2019},
}
@article{Kingma2015,
   abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
   author = {Diederik P. Kingma and Jimmy Lei Ba},
   journal = {3rd International Conference on Learning Representations, ICLR 2015 - Conference Track Proceedings},
   pages = {1-15},
   title = {Adam: A method for stochastic optimization},
   year = {2015},
}
@generic{Werbos1990,
   abstract = {Basic backpropagation, which is a simple method now being widely used in areas like pattern recognition and fault diagnosis, is reviewed. The basic equations for backpropagation through time, and applications to areas like pattern recognition involving dynamic systems, systems identification, and control are discussed. Further extensions of this method, to deal with systems other than neural networks, systems involving simultaneous equations, or true recurrent networks, and other practical issues arising with the method are described. Pseudocode is provided to clarify the algorithms. The chain rule for ordered derivatives-the theorem which underlies backpropagation-is briefly discussed. The focus is on designing a simpler version of backpropagation which can be translated into computer code and applied directly by neutral network users.},
   author = {P.J. Werbos},
   issue = {10},
   journal = {Proceedings of the IEEE},
   keywords = {P.J. Werbos},
   pages = {1550 - 1560},
   title = {Backpropagation Through Time: What It Does and How to Do It},
   volume = {78},
   url = {http://ieeexplore.ieee.org/document/58337/?reload=true},
   year = {1990},
}
@article{Xiao2020,
   abstract = {Lip reading is the task of recognizing speech content by analyzing movements in the lip region when people are speaking. Based on the continuity in adjacent frames in the speaking process, and the consistency in motion patterns among different people when they pronounce the same phoneme, we model lip movements as a sequence of apparent deformations in the lip region during the speaking process. Specifically, we introduce a Deformation Flow Network (DFN) to learn the deformation flow between adjacent frames, which directly captures the motion information within the lip region. The learned deformation flow is then combined with the original grayscale frames with a two-stream network to perform lip reading. To make the two streams learn from each other in the learning process, we introduce a bidirectional knowledge distillation loss to train the two branches jointly. Owing to the complementary cues provided by different branches, the two-stream network shows substantial improvement over using either single branch. A thorough experimental evaluation on two large-scale lip reading benchmarks is presented with detailed analysis. The results accord with our motivation, and show that our method achieves state-of-the-art or comparable performance on these two challenging datasets.},
   author = {Jingyun Xiao and Shuang Yang and Yuanhang Zhang and Shiguang Shan and Xilin Chen},
   doi = {10.1109/FG47880.2020.00132},
   isbn = {9781728130798},
   journal = {Proceedings - 2020 15th IEEE International Conference on Automatic Face and Gesture Recognition, FG 2020},
   keywords = {lip reading,visual speech recognition},
   pages = {364-370},
   title = {Deformation Flow Based Two-Stream Network for Lip Reading},
   year = {2020},
}
@article{Feng2020,
   abstract = {Lip reading, also known as visual speech recognition, aims to recognize the speech content from videos by analyzing the lip dynamics. There have been several appealing progress in recent years, benefiting much from the rapidly developed deep learning techniques and the recent large-scale lip-reading datasets. Most existing methods obtained high performance by constructing a complex neural network, together with several customized training strategies which were always given in a very brief description or even shown only in the source code. We find that making proper use of these strategies could always bring exciting improvements without changing much of the model. Considering the non-negligible effects of these strategies and the existing tough status to train an effective lip reading model, we perform a comprehensive quantitative study and comparative analysis, for the first time, to show the effects of several different choices for lip reading. By only introducing some easy-to-get refinements to the baseline pipeline, we obtain an obvious improvement of the performance from 83.7% to 88.4% and from 38.2% to 55.7% on two largest public available lip reading datasets, LRW and LRW-1000, respectively. They are comparable and even surpass the existing state-of-the-art results.},
   author = {Dalu Feng and Shuang Yang and Shiguang Shan and Xilin Chen},
   pages = {1-6},
   title = {Learn an Effective Lip Reading Model without Pains},
   url = {http://arxiv.org/abs/2011.07557},
   year = {2020},
}
@article{Zhang2018,
   abstract = {Deep neural networks (DNNs) have achieved tremendous success in a variety of applications across many disciplines. Yet, their superior performance comes with the expensive cost of requiring correctly annotated large-scale datasets. Moreover, due to DNNs' rich capacity, errors in training labels can hamper performance. To combat this problem, mean absolute error (MAE) has recently been proposed as a noise-robust alternative to the commonly-used categorical cross entropy (CCE) loss. However, as we show in this paper, MAE can perform poorly with DNNs and challenging datasets. Here, we present a theoretically grounded set of noise-robust loss functions that can be seen as a generalization of MAE and CCE. Proposed loss functions can be readily applied with any existing DNN architecture and algorithm, while yielding good performance in a wide range of noisy label scenarios. We report results from experiments conducted with CIFAR-10, CIFAR-100 and FASHION-MNIST datasets and synthetically generated noisy labels.},
   author = {Zhilu Zhang and Mert R. Sabuncu},
   issn = {10495258},
   issue = {NeurIPS},
   journal = {Advances in Neural Information Processing Systems},
   pages = {8778-8788},
   title = {Generalized cross entropy loss for training deep neural networks with noisy labels},
   volume = {2018-Decem},
   year = {2018},
}
@article{Martinez2020,
   abstract = {Lip-reading has attracted a lot of research attention lately thanks to advances in deep learning. The current state-of-the-art model for recognition of isolated words in-the-wild consists of a residual network and Bidirectional Gated Recurrent Unit (BGRU) layers. In this work, we address the limitations of this model and we propose changes which further improve its performance. Firstly, the BGRU layers are replaced with Temporal Convolutional Networks (TCN). Secondly, we greatly simplify the training procedure, which allows us to train the model in one single stage. Thirdly, we show that the current state-of-the-art methodology produces models that do not generalize well to variations on the sequence length, and we address this issue by proposing a variable-length augmentation. We present results on the largest publicly-available datasets for isolated word recognition in English and Mandarin, LRW and LRW1000, respectively. Our proposed model1 results in an absolute improvement of 1.2% and 3.2%, respectively, in these datasets which is the new state-of-the-art performance.},
   author = {Brais Martinez and Pingchuan Ma and Stavros Petridis and Maja Pantic},
   doi = {10.1109/ICASSP40776.2020.9053841},
   isbn = {9781509066315},
   issn = {15206149},
   journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
   keywords = {Lip-reading,Temporal Convolutional Networks,Visual Speech Recognition},
   pages = {6319-6323},
   title = {Lipreading Using Temporal Convolutional Networks},
   volume = {2020-May},
   year = {2020},
}
@article{Wang2021-action-net,
   abstract = {Spatial-temporal, channel-wise, and motion patterns are three complementary and crucial types of information for video action recognition. Conventional 2D CNNs are computationally cheap but cannot catch temporal relationships; 3D CNNs can achieve good performance but are computationally intensive. In this work, we tackle this dilemma by designing a generic and effective module that can be embedded into 2D CNNs. To this end, we propose a spAtio-temporal, Channel and moTion excitatION (ACTION) module consisting of three paths: Spatio-Temporal Excitation (STE) path, Channel Excitation (CE) path, and Motion Excitation (ME) path. The STE path employs one channel 3D convolution to characterize spatio-temporal representation. The CE path adaptively recalibrates channel-wise feature responses by explicitly modeling interdependencies between channels in terms of the temporal aspect. The ME path calculates feature-level temporal differences, which is then utilized to excite motion-sensitive channels. We equip 2D CNNs with the proposed ACTION module to form a simple yet effective ACTION-Net with very limited extra computational cost. ACTION-Net is demonstrated by consistently outperforming 2D CNN counterparts on three backbones (i.e., ResNet-50, MobileNet V2 and BNInception) employing three datasets (i.e., Something-Something V2, Jester, and EgoGesture). Code is provided at https://github.com/V-Sense/ACTION-Net.},
   author = {Zhengwei Wang and Qi She and Aljosa Smolic},
   doi = {10.1109/CVPR46437.2021.01301},
   isbn = {9781665445092},
   issn = {10636919},
   issue = {15},
   journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
   pages = {13209-13218},
   title = {{Action-Net}: Multipath excitation for action recognition},
   year = {2021},
}
@article{Gallego2022,
   abstract = {Event cameras are bio-inspired sensors that differ fromconventional frame cameras: Instead of capturing images at a fixed rate, they asynchronouslymeasure per-pixel brightness changes, and output a streamof events that encode the time, location and sign of the brightness changes. Event cameras offer attractive properties compared to traditional cameras: high temporal resolution (in the order ofms), very high dynamic range (140 dB versus 60 dB), low power consumption, and high pixel bandwidth (on the order of kHz) resulting in reduced motion blur. Hence, event cameras have a large potential for robotics and computer vision in challenging scenarios for traditional cameras, such as low-latency, high speed, and high dynamic range. However, novelmethods are required to process the unconventional output of these sensors in order to unlock their potential. This paper provides a comprehensive overviewof the emerging field of event-based vision, with a focus on the applications and the algorithms developed to unlock the outstanding properties of event cameras. We present event cameras fromtheir working principle, the actual sensors that are available and the tasks that they have been used for, from low-level vision (feature detection and tracking, optic flow, etc.) to high-level vision (reconstruction, segmentation, recognition). We also discuss the techniques developed to process events, including learning-based techniques, aswell as specialized processors for these novel sensors, such as spiking neural networks. Additionally, we highlight the challenges that remain to be tackled and the opportunities that lie ahead in the search for amore efficient, bio-inspired way for machines to perceive and interact with the world.},
   author = {Guillermo Gallego and Tobi Delbruck and Garrick Orchard and Chiara Bartolozzi and Brian Taba and Andrea Censi and Stefan Leutenegger and Andrew J. Davison and Jorg Conradt and Kostas Daniilidis and Davide Scaramuzza},
   doi = {10.1109/TPAMI.2020.3008413},
   issn = {19393539},
   issue = {1},
   journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
   keywords = {Event cameras,asynchronous sensor,bio-inspired vision,high dynamic range,low latency,low power},
   pages = {154-180},
   pmid = {32750812},
   title = {Event-Based Vision: A Survey},
   volume = {44},
   year = {2022},
}
@generic{Kaiser2020,
   abstract = {A growing body of work underlines striking similarities between biological neural networks and recurrent, binary neural networks. A relatively smaller body of work, however, addresses the similarities between learning dynamics employed in deep artificial neural networks and synaptic plasticity in spiking neural networks. The challenge preventing this is largely caused by the discrepancy between the dynamical properties of synaptic plasticity and the requirements for gradient backpropagation. Learning algorithms that approximate gradient backpropagation using local error functions can overcome this challenge. Here, we introduce Deep Continuous Local Learning (DECOLLE), a spiking neural network equipped with local error functions for online learning with no memory overhead for computing gradients. DECOLLE is capable of learning deep spatio temporal representations from spikes relying solely on local information, making it compatible with neurobiology and neuromorphic hardware. Synaptic plasticity rules are derived systematically from user-defined cost functions and neural dynamics by leveraging existing autodifferentiation methods of machine learning frameworks. We benchmark our approach on the event-based neuromorphic dataset N-MNIST and DvsGesture, on which DECOLLE performs comparably to the state-of-the-art. DECOLLE networks provide continuously learning machines that are relevant to biology and supportive of event-based, low-power computer vision architectures matching the accuracies of conventional computers on tasks where temporal precision and speed are essential.},
   author = {Jacques Kaiser and Hesham Mostafa and Emre Neftci},
   isbn = {1662-453X},
   journal = {Frontiers in Neuroscience  },
   title = {Synaptic Plasticity Dynamics for Deep Continuous Local Learning ({DECOLLE})   },
   volume = {14      },
   url = {https://www.frontiersin.org/articles/10.3389/fnins.2020.00424},
   year = {2020},
}
@generic{Kugele2020,
   abstract = {Spiking neural networks (SNNs) are potentially highly efficient models for inference on fully parallel neuromorphic hardware, but existing training methods that convert conventional artificial neural networks (ANNs) into SNNs are unable to exploit these advantages. Although ANN-to-SNN conversion has achieved state-of-the-art accuracy for static image classification tasks, the following subtle but important difference in the way SNNs and ANNs integrate information over time makes the direct application of conversion techniques for sequence processing tasks challenging. Whereas all connections in SNNs have a certain propagation delay larger than zero, ANNs assign different roles to feed-forward connections, which immediately update all neurons within the same time step, and recurrent connections, which have to be rolled out in time and are typically assigned a delay of one time step. Here, we present a novel method to obtain highly accurate SNNs for sequence processing by modifying the ANN training before conversion, such that delays induced by ANN rollouts match the propagation delays in the targeted SNN implementation. Our method builds on the recently introduced framework of streaming rollouts, which aims for fully parallel model execution of ANNs and inherently allows for temporal integration by merging paths of different delays between input and output of the network. The resulting networks achieve state-of-the-art accuracy for multiple event-based benchmark datasets, including <monospace>N-MNIST</monospace>, <monospace>CIFAR10-DVS</monospace>, <monospace>N-CARS</monospace>, and <monospace>DvsGesture</monospace>, and through the use of spatio-temporal shortcut connections yield low-latency approximate network responses that improve over time as more of the input sequence is processed. In addition, our converted SNNs are consistently more energy-efficient than their corresponding ANNs.},
   author = {Alexander Kugele and Thomas Pfeil and Michael Pfeiffer and Elisabetta Chicca},
   isbn = {1662-453X},
   journal = {Frontiers in Neuroscience  },
   title = {Efficient Processing of Spatio-Temporal Data Streams With Spiking Neural Networks   },
   volume = {14      },
   url = {https://www.frontiersin.org/articles/10.3389/fnins.2020.00439},
   year = {2020},
}
@article{Pickett2013,
   abstract = {Emulating the spiking phenomena associated with neural activity in technological devices offers the promise of drastically improving their efficiency and scale. The fabrication of a neuristor that consists of nanoscale Mott memristors provides a step towards making such devices practical for integrated circuit applications.},
   author = {Matthew D Pickett and Gilberto Medeiros-Ribeiro and R Stanley Williams},
   doi = {10.1038/nmat3510},
   issn = {1476-4660},
   issue = {2},
   journal = {Nature Materials},
   pages = {114-117},
   title = {A scalable neuristor built with Mott memristors},
   volume = {12},
   url = {https://doi.org/10.1038/nmat3510},
   year = {2013},
}
@article{Islam2022,
   abstract = {Gradual switching between multiple resistance levels is desirable for analog in-memory computing using resistive random-access memory (RRAM). However, the filamentary switching of HfOx-based conventional RRAM often yields only two stable memory states instead of gradual switching between multiple resistance states. Here, we demonstrate that a thermal barrier of Ge2Sb2Te5 (GST) between HfOx and the bottom electrode (TiN) enables wider and weaker filaments, by promoting heat spreading laterally inside the HfOx. Scanning thermal microscopy suggests that HfOx + GST devices have a wider heating region than control devices with only HfOx, indicating the formation of a wider filament. Such wider filaments can have multiple stable conduction paths, resulting in a memory device with more gradual and linear switching. The thermally enhanced HfOx + GST devices also have higher on/off ratio (>103) than control devices (<102) and a median set voltage lower by approximately 1 V (∼35%), with a corresponding reduction of the switching power. Our HfOx + GST RRAM shows 2× gradual switching range using fast (∼ns) identical pulse trains with amplitude less than 2 V.},
   author = {R. Islam and S. Qin and S. Deshmukh and Z. Yu and C. Köroǧlu and A. I. Khan and K. Schauble and K. C. Saraswat and E. Pop and H. S.P. Wong},
   doi = {10.1063/5.0101417},
   issn = {00036951},
   issue = {8},
   journal = {Applied Physics Letters},
   pages = {1-9},
   title = {Improved gradual resistive switching range and 1000× On/Off ratio in HfOx RRAM achieved with a Ge2Sb2Te5 thermal barrier},
   volume = {121},
   year = {2022},
}
@article{Corti2020,
   abstract = {New computation schemes inspired by biological processes are arising as an alternative to standard von-Neumann architectures, to provide hardware accelerators for information processing based on a neural networks approach. Systems of frequency-locked, coupled oscillators are investigated using the phase difference of the signal as the state variable rather than the voltage or current amplitude. As previously shown, these oscillating neural networks can efficiently solve complex and unstructured tasks such as image recognition. We have built nanometer scale relaxation oscillators based on the insulator–metal transition of VO2. Coupling these oscillators with an array of tunable resistors offers the perspective of realizing compact oscillator networks. In this work we show experimental coupling of two oscillators. The phase of the two oscillators could be reversibly altered between in-phase and out-of-phase oscillation upon changing the value of the coupling resistor, i.e. by tuning the coupling strength. The impact of the variability of the devices on the coupling performances are investigated across two generations of devices.},
   author = {Elisabetta Corti and Bernd Gotsmann and Kirsten Moselund and Adrian M Ionescu and John Robertson and Siegfried Karg},
   doi = {https://doi.org/10.1016/j.sse.2019.107729},
   issn = {0038-1101},
   journal = {Solid-State Electronics},
   keywords = {Coupled oscillators,Image recognition,Neuromorphic computing,Phase,Resistive-coupling,Timing,VO},
   pages = {107729},
   title = {Scaled resistively-coupled VO2 oscillators for neuromorphic computing},
   volume = {168},
   url = {https://www.sciencedirect.com/science/article/pii/S0038110119307324},
   year = {2020},
}
@article{Shukla2014,
   abstract = {Strongly correlated phases exhibit collective carrier dynamics that if properly harnessed can enable novel functionalities and applications. In this article, we investigate the phenomenon of electrical oscillations in a prototypical MIT system, vanadium dioxide (VO2). We show that the key to such oscillatory behaviour is the ability to induce and stabilize a non-hysteretic and spontaneously reversible phase transition using a negative feedback mechanism. Further, we investigate the synchronization and coupling dynamics of such VO2 based relaxation oscillators and show, via experiment and simulation, that this coupled oscillator system exhibits rich non-linear dynamics including charge oscillations that are synchronized in both frequency and phase. Our approach of harnessing a non-hysteretic reversible phase transition region is applicable to other correlated systems exhibiting metal-insulator transitions and can be a potential candidate for oscillator based non-Boolean computing.},
   author = {Nikhil Shukla and Abhinav Parihar and Eugene Freeman and Hanjong Paik and Greg Stone and Vijaykrishnan Narayanan and Haidan Wen and Zhonghou Cai and Venkatraman Gopalan and Roman Engel-Herbert and Darrell G Schlom and Arijit Raychowdhury and Suman Datta},
   doi = {10.1038/srep04964},
   issn = {2045-2322},
   issue = {1},
   journal = {Scientific Reports},
   pages = {4964},
   title = {Synchronized charge oscillations in correlated electron systems},
   volume = {4},
   url = {https://doi.org/10.1038/srep04964},
   year = {2014},
}
@article{Pickett2011,
   abstract = {We experimentally demonstrate and present an analytical model for a nanoscale metal/oxide/metal device that simultaneously exhibits memristance, based on oxygen vacancy drift, and current-controlled negative differential resistance, based on a metal-insulator transition instability. We show that this oxide nanodevice can be used to fabricate a continuously tunable voltage-controlled oscillator.},
   author = {Matthew D Pickett and Julien Borghetti and J Joshua Yang and Gilberto Medeiros-Ribeiro and R Stanley Williams},
   doi = {https://doi.org/10.1002/adma.201004497},
   issn = {0935-9648},
   issue = {15},
   journal = {Advanced Materials},
   keywords = {electronic properties,memristance,metal-insulator transition,phase transformation},
   month = {4},
   note = {https://doi.org/10.1002/adma.201004497},
   pages = {1730-1733},
   publisher = {John Wiley & Sons, Ltd},
   title = {Coexistence of Memristance and Negative Differential Resistance in a Nanoscale Metal-Oxide-Metal System},
   volume = {23},
   url = {https://doi.org/10.1002/adma.201004497},
   year = {2011},
}
@article{Wei2022,
   abstract = {A trade-off between the memory window and the endurance exists for transition-metal-oxide RRAM. In this work, we demonstrated that HfOx/Ge-based metal-insulator-semiconductor RRAM devices possess both a larger memory window and longer endurance compared with metal-insulator-metal (MIM) RRAM devices. Under DC cycling, HfOx/Ge devices exhibit a 100× larger memory window compared to HfOx MIM devices, and a DC sweep of up to 20,000 cycles was achieved with the devices. The devices also realize low static power down to 1 nW as FPGA’s pull-up/pull-down resistors. Thus, HfOx/Ge devices act as a promising candidates for various applications such as FPGA or compute-in-memory, in which both a high ON/OFF ratio and decent endurance are required.},
   author = {Na Wei and Xiang Ding and Shifan Gao and Wenhao Wu and Yi Zhao},
   doi = {10.3390/electronics11223820},
   issn = {20799292},
   issue = {22},
   journal = {Electronics (Switzerland)},
   keywords = {Germanium,HfOx RRAM,MIGe,endurance,memory window},
   title = {HfOx/Ge RRAM with High ON/OFF Ratio and Good Endurance},
   volume = {11},
   year = {2022},
}
@article{Pedretti2018,
   abstract = {Hardware processors for neuromorphic computing are gaining significant interest as they offer the possibility of real in-memory computing, thus by-passing the limitations of speed and energy consumption of the von Neumann architecture. One of the major limitations of current neuromorphic technology is the lack of bio-realistic and scalable devices to improve the current design of artificial synapses and neurons. To overcome these limitations, the emerging technology of resistive switching memory has attracted wide interest as a nano-scaled synaptic element. This paper describes the implementation of a perceptron-like neuromorphic hardware capable of spike-timing dependent plasticity (STDP), and its operation under stochastic learning conditions. The learning algorithm of a single or multiple patterns, consisting of either static or dynamic visual input data, is described. The impact of noise is studied with respect to learning efficiency (false fire, true fire) and learning time. Finally, the impact of stochastic learning rule, such as the inversion of the time dependence of potentiation and depression in STDP, is considered. Overall, the work provides a proof of concept for unsupervised learning by STDP in memristive networks, providing insight into the dynamics of stochastic learning and supporting the understanding and design of neuromorphic networks with emerging memory devices.},
   author = {Giacomo Pedretti and Valerio Milo and Stefano Ambrogio and Roberto Carboni and Stefano Bianchi and Alessandro Calderoni and Nirmal Ramaswamy and Alessandro S. Spinelli and Daniele Ielmini},
   doi = {10.1109/JETCAS.2017.2773124},
   issn = {21563357},
   issue = {1},
   journal = {IEEE Journal on Emerging and Selected Topics in Circuits and Systems},
   keywords = {Resistive switching memory (RRAM),artificial synapse,memristive device,neuromorphic network,pattern learning},
   month = {3},
   pages = {77-85},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Stochastic Learning in Neuromorphic Hardware via Spike Timing Dependent Plasticity with RRAM Synapses},
   volume = {8},
   year = {2018},
}
@article{Kim2021,
   abstract = {We demonstrate a novel process for building a Resistive RAM (ReRAM) stack which reduces the forming voltage ( $\text\{V\}-\{\textit \{form\}\}$ ) and increases the switching resistance, both characteristics that are important ingredients for the use of ReRAM in scalable analog compute for AI. Utilizing this process, we explore analog switching characteristics above 100k $\Omega $ and demonstrate 4-bit programming at Rmax $=1\text\{M\}\Omega $. Utilizing the same writing characteristics, CIFAR-10 inference simulation shows 90% accuracy, comparable to the full precision model accuracy.},
   author = {Y. Kim and S. C. Seo and S. Consiglio and P. Jamison and H. Higuchi and M. Rasch and E. Y. Wu and D. Kong and I. Saraf and C. Catano and R. Muralidhar and S. Nguyen and S. Devries and O. Van Der Straten and M. Sankarapandian and R. N. Pujari and A. Gasasira and S. M. McDermott and H. Miyazoe and D. Koty and Q. Yang and H. Yan and R. Clark and K. Tapily and S. Engelmann and R. R. Robison and C. Wajda and A. Mosden and T. Tsunomura and R. Soave and N. Saulnier and W. Haensch and G. Leusink and P. Biolsi and V. Narayanan and T. Ando},
   doi = {10.1109/LED.2021.3066181},
   issn = {15580563},
   issue = {5},
   journal = {IEEE Electron Device Letters},
   keywords = {Analog compute,ReRAM,cross-bar array,plasma process},
   month = {5},
   pages = {759-762},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Resistive Memory Process Optimization for High Resistance Switching Toward Scalable Analog Compute Technology for Deep Learning},
   volume = {42},
   year = {2021},
}
@article{Burr2017,
   author = {Geoffrey W Burr and Robert M Shelby and Abu Sebastian and Sangbum Kim and Seyoung Kim and Severin Sidler and Kumar Virwani and Masatoshi Ishii and Pritish Narayanan and Alessandro Fumarola and Lucas L Sanches and Irem Boybat and Manuel Le Gallo and Kibong Moon and Jiyoo Woo and Hyunsang Hwang and Yusuf Leblebici},
   doi = {10.1080/23746149.2016.1259585},
   issn = {null},
   issue = {1},
   journal = {Advances in Physics: X},
   month = {1},
   note = {doi: 10.1080/23746149.2016.1259585},
   pages = {89-124},
   publisher = {Taylor & Francis},
   title = {Neuromorphic computing using non-volatile memory},
   volume = {2},
   url = {https://doi.org/10.1080/23746149.2016.1259585},
   year = {2017},
}
@article{Krishnan2022,
   author = {G Krishnan and Z Wang and I Yeo and L Yang and J Meng and M Liehr and R V Joshi and N C Cady and D Fan and J -S. Seo and Y Cao},
   doi = {10.1109/TCAD.2022.3197516},
   issn = {1937-4151},
   issue = {11},
   journal = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
   pages = {4241-4252},
   title = {Hybrid RRAM/SRAM in-Memory Computing for Robust DNN Acceleration},
   volume = {41},
   year = {2022},
}
@inproceedings{Krishnan2021,
   author = {G Krishnan and J Sun and J Hazra and X Du and M Liehr and Z Li and K Beckmann and R V Joshi and N C Cady and Y Cao},
   doi = {10.1109/IRPS46558.2021.9405092},
   isbn = {1938-1891},
   journal = {2021 IEEE International Reliability Physics Symposium (IRPS)},
   pages = {1-5},
   title = {Robust RRAM-based In-Memory Computing in Light of Model Stability},
   year = {2021},
}
@inproceedings{Mackin2019,
   author = {C Mackin and P Narayanan and H Tsai and S Ambrogio and A Chen and G W Burr},
   doi = {10.1109/CLEOE-EQEC.2019.8872657},
   journal = {2019 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC)},
   pages = {1},
   title = {Neuro-Inspired Computing: From Resistive Memory to Optics},
   year = {2019},
}
@article{Yu2013,
   abstract = {Neuromorphic computing is an emerging computing paradigm beyond the conventional digital von Neumann computation. An oxide-based resistive switching memory is engineered to emulate synaptic devices. At the device level, the gradual resistance modulation is characterized by hundreds of identical pulses, achieving a low energy consumption of less than 1 pJ per spike. Furthermore, a stochastic compact model is developed to quantify the device switching dynamics and variation. At system level, the performance of an artificial visual system on the image orientation or edge detection with 16 348 oxide-based synaptic devices is simulated, successfully demonstrating a key feature of neuromorphic computing: tolerance to device variation. Copyright © 2013 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim.},
   author = {Shimeng Yu and Bin Gao and Zheng Fang and Hongyu Yu and Jinfeng Kang and H. S.Philip Wong},
   doi = {10.1002/adma.201203680},
   issn = {09359648},
   issue = {12},
   journal = {Advanced Materials},
   keywords = {artificial visual systems,neuromorphic computing,oxide RRAM,resistive switching,synaptic devices},
   month = {3},
   pages = {1774-1779},
   pmid = {23355110},
   title = {A low energy oxide-based electronic synaptic device for neuromorphic visual systems with tolerance to device variation},
   volume = {25},
   year = {2013},
}
@inproceedings{Meng2022,
   author = {Jian Meng and Injune Yeo and Wonbo Shim and Li Yang and Deliang Fan and Shimeng Yu and Jae-Sun Seo},
   doi = {10.1109/IRPS48227.2022.9764480},
   isbn = {1938-1891},
   journal = {2022 IEEE International Reliability Physics Symposium (IRPS)},
   pages = {3C.1-1-3C.1-6},
   title = {Sparse and Robust RRAM-based Efficient In-memory Computing for DNN Inference},
   year = {2022},
}
@article{Yu2011,
   author = {S Yu and Y Wu and R Jeyasingh and D Kuzum and H . -S. P Wong},
   doi = {10.1109/TED.2011.2147791},
   issn = {1557-9646},
   issue = {8},
   journal = {IEEE Transactions on Electron Devices},
   pages = {2729-2737},
   title = {An Electronic Synapse Device Based on Metal Oxide Resistive Switching Memory for Neuromorphic Computation},
   volume = {58},
   year = {2011},
}
@article{Wan2020,
   author = {W Wan and R Kubendran and B Gao and S Joshi and P Raina and H Wu and G Cauwenberghs and H S P Wong},
   doi = {10.1109/VLSITechnology18217.2020.9265066},
   isbn = {2158-9682},
   journal = {2020 IEEE Symposium on VLSI Technology},
   pages = {1-2},
   title = {A Voltage-Mode Sensing Scheme with Differential-Row Weight Mapping for Energy-Efficient RRAM-Based In-Memory Computing},
   year = {2020},
}
@inproceedings{Li2016,
   author = {H Li and T F Wu and A Rahimi and K -S. Li and M Rusch and C -H. Lin and J -L. Hsu and M M Sabry and S B Eryilmaz and J Sohn and W -C. Chiu and M -C. Chen and T -T. Wu and J -M. Shieh and W -K. Yeh and J M Rabaey and S Mitra and H . -S. P Wong},
   doi = {10.1109/IEDM.2016.7838428},
   isbn = {2156-017X},
   journal = {2016 IEEE International Electron Devices Meeting (IEDM)},
   pages = {16.1.1-16.1.4},
   title = {Hyperdimensional computing with 3D VRRAM in-memory kernels: Device-architecture co-design for energy-efficient, error-resilient language recognition},
   year = {2016},
}
@inproceedings{Li2021,
   author = {H Li and W -C. Chen and A Levy and C -H. Wang and H Wang and P -H. Chen and W Wan and H . -S. P Wong and P Raina},
   isbn = {2158-9682},
   journal = {2021 Symposium on VLSI Technology},
   pages = {1-2},
   title = {One-Shot Learning with Memory-Augmented Neural Networks Using a 64-kbit, 118 GOPS/W RRAM-Based Non-Volatile Associative Memory},
   year = {2021},
}
@article{Wan2022,
   abstract = {Realizing increasingly complex artificial intelligence (AI) functionalities directly on edge devices calls for unprecedented energy efficiency of edge hardware. Compute-in-memory (CIM) based on resistive random-access memory (RRAM)1 promises to meet such demand by storing AI model weights in dense, analogue and non-volatile RRAM devices, and by performing AI computation directly within RRAM, thus eliminating power-hungry data movement between separate compute and memory2–5. Although recent studies have demonstrated in-memory matrix-vector multiplication on fully integrated RRAM-CIM hardware6–17, it remains a goal for a RRAM-CIM chip to simultaneously deliver high energy efficiency, versatility to support diverse models and software-comparable accuracy. Although efficiency, versatility and accuracy are all indispensable for broad adoption of the technology, the inter-related trade-offs among them cannot be addressed by isolated improvements on any single abstraction level of the design. Here, by co-optimizing across all hierarchies of the design from algorithms and architecture to circuits and devices, we present NeuRRAM—a RRAM-based CIM chip that simultaneously delivers versatility in reconfiguring CIM cores for diverse model architectures, energy efficiency that is two-times better than previous state-of-the-art RRAM-CIM chips across various computational bit-precisions, and inference accuracy comparable to software models quantized to four-bit weights across various AI tasks, including accuracy of 99.0 percent on MNIST18 and 85.7 percent on CIFAR-1019 image classification, 84.7-percent accuracy on Google speech command recognition20, and a 70-percent reduction in image-reconstruction error on a Bayesian image-recovery task.},
   author = {Weier Wan and Rajkumar Kubendran and Clemens Schaefer and Sukru Burc Eryilmaz and Wenqiang Zhang and Dabin Wu and Stephen Deiss and Priyanka Raina and He Qian and Bin Gao and Siddharth Joshi and Huaqiang Wu and H.-S. Philip Wong and Gert Cauwenberghs},
   doi = {10.1038/s41586-022-04992-8},
   issn = {1476-4687},
   issue = {7923},
   journal = {Nature},
   pages = {504-512},
   title = {A compute-in-memory chip based on resistive random-access memory},
   volume = {608},
   url = {https://doi.org/10.1038/s41586-022-04992-8},
   year = {2022},
}
@article{Kang2022,
   author = {Peng Kang and Srutarshi Banerjee and Henry Chopp and Aggelos Katsaggelos and Oliver Cossairt},
   doi = {10.48550/ARXIV.2209.01080},
   journal = {arXiv},
   title = {Event-Driven Tactile Learning with Location Spiking Neurons},
   url = {https://arxiv.org/abs/2209.01080},
   year = {2022},
}
@article{Li2017-CIFARDVS,
   abstract = {Neuromorphic vision research requires high-quality and appropriately challenging event-stream datasets to support continuous improvement of algorithms and methods. However, creating event-stream datasets is a time-consuming task, which needs to be recorded using the neuromorphic cameras. Currently, there are limited event-stream datasets available. In this work, by utilizing the popular computer vision dataset CIFAR-10, we converted 10,000 frame-based images into 10,000 event streams using a dynamic vision sensor (DVS), providing an event-stream dataset of intermediate difficulty in 10 different classes, named as “CIFAR10-DVS.” The conversion of event-stream dataset was implemented by a repeated closed-loop smooth (RCLS) movement of frame-based images. Unlike the conversion of frame-based images by moving the camera, the image movement is more realistic in respect of its practical applications. The repeated closed-loop image movement generates rich local intensity changes in continuous time which are quantized by each pixel of the DVS camera to generate events. Furthermore, a performance benchmark in event-driven object classification is provided based on state-of-the-art classification algorithms. This work provides a large event-stream dataset and an initial benchmark for comparison, which may boost algorithm developments in even-driven pattern recognition and object classification.},
   author = {Hongmin Li and Hanchao Liu and Xiangyang Ji and Guoqi Li and Luping Shi},
   doi = {10.3389/fnins.2017.00309},
   issn = {1662-453X},
   journal = {Frontiers in Neuroscience},
   title = {{CIFAR10-DVS}: An Event-Stream Dataset for Object Classification},
   volume = {11},
   url = {https://www.frontiersin.org/articles/10.3389/fnins.2017.00309},
   year = {2017},
}
@inproceedings{Amir2017,
   author = {Arnon Amir and Brian Taba and David Berg and Timothy Melano and Jeffrey Mckinstry and Carmelo Di Nolfo and Tapan Nayak and Alexander Andreopoulos and Guillaume Garreau and Marcela Mendoza and Jeff Kusnitz and Michael Debole and Steve Esser and Tobi Delbruck and Myron Flickner and Dharmendra Modha and U C San Diego and Uzh-eth Zurich},
   journal = {Computer vision and pattern recognition},
   pages = {7243-7252},
   title = {A Low Power , Fully Event-Based Gesture Recognition System},
   year = {2017},
}
@inproceedings{Kim2020,
   author = {J Kim and S -P. Kim and J Kim and H Hwang and J Kim and D Park and U Jeong},
   doi = {10.1109/SMC42975.2020.9283337},
   isbn = {2577-1655 VO  -},
   journal = {2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
   pages = {178-183},
   title = {Object shape recognition using tactile sensor arrays by a spiking neural network with unsupervised learning},
   year = {2020},
}
@article{Grimaldi2022,
   author = {Antoine Grimaldi and Victor Boutin and Sio-hoi Ieng and Ryad Benosman},
   doi = {10.36227/techrxiv.18003077.v1},
   journal = {TechRxiv},
   title = {A robust event-driven approach to always-on object recognition},
   year = {2022},
}
@article{Perera2022,
   author = {Duwage C Perera and Jayendran C Rasaiah},
   doi = {10.1021/acsomega.1c05666},
   issue = {15},
   journal = {ACS Omega},
   month = {4},
   note = {doi: 10.1021/acsomega.1c05666},
   pages = {12556-12569},
   publisher = {American Chemical Society},
   title = {Exchange Functionals and Basis Sets for Density Functional Theory Studies of Water Splitting on Selected ZnO Nanocluster Catalysts},
   volume = {7},
   url = {https://doi.org/10.1021/acsomega.1c05666},
   year = {2022},
}
@article{Nakhal2016,
   author = {Suliman Nakhal and Martin Lerch},
   doi = {doi:10.1515/znb-2015-0215},
   issue = {5},
   journal = {Zeitschrift für Naturforschung B},
   pages = {457-461},
   title = {New transition metal oxide fluorides with ReO3-type structure},
   volume = {71},
   url = {https://doi.org/10.1515/znb-2015-0215},
   year = {2016},
}
@article{Li2012,
   author = {Neng Li and Kai-Lun Yao},
   journal = {American Istitute of Physics advances},
   pages = {032135},
   title = {The electronic and optical properties of carbon-doped SrTiO 3 : Density functional characterization},
   volume = {2},
   year = {2012},
}
@article{Szekeres1996,
   author = {A Szekeres and P Danesh},
   journal = {Semiconductor science and technology},
   pages = {1225-1230},
   title = {Mechanical stress in SiO 2 / Si structures formed by thermal oxidation of amorphous and crystalline silicon},
   volume = {11},
   year = {1996},
}
@article{Peng2020,
   abstract = {Two-dimensional (2D) transition metal dichalcogenides (TMDCs) and graphene compose a new family of crystalline materials with atomic thicknesses and exotic mechanical, electronic, and optical properties. Due to their inherent exceptional mechanical flexibility and strength, these 2D materials provide an ideal platform for strain engineering, enabling versatile modulation and significant enhancement of their optical properties. For instance, recent theoretical and experimental investigations have demonstrated flexible control over their electronic states via application of external strains, such as uniaxial strain and biaxial strain. Meanwhile, many nondestructive optical measurement methods, typically including absorption, reflectance, photoluminescence, and Raman spectroscopies, can be readily exploited to quantitatively determine strain-engineered optical properties. This review begins with an introduction to the macroscopic theory of crystal elasticity and microscopic effective low-energy Hamiltonians coupled with strain fields, and then summarizes recent advances in strain-induced optical responses of 2D TMDCs and graphene, followed by the strain engineering techniques. It concludes with exciting applications associated with strained 2D materials, discussions on existing open questions, and an outlook on this intriguing emerging field.},
   author = {Zhiwei Peng and Xiaolin Chen and Yulong Fan and David J Srolovitz and Dangyuan Lei},
   doi = {10.1038/s41377-020-00421-5},
   issn = {2047-7538},
   issue = {1},
   journal = {Light: Science & Applications},
   pages = {190},
   title = {Strain engineering of 2D semiconductors and graphene: from strain fields to band-structure tuning and photonic applications},
   volume = {9},
   url = {https://doi.org/10.1038/s41377-020-00421-5},
   year = {2020},
}
@article{Tao2020,
   abstract = {In the past decades, low-dimensional semiconductors received intensive research interest. By introducing intentionally size-confined nanostructures or crystal imperfections, low-dimensional semiconductors have been broadly exploited as zero-dimensional quantum dots (QDs) for high-performance quantum emitters. The QD-based nonclassical light sources allow not only the deterministic generation of single photons but also entangled-photon pairs. However, the randomness in strain, shape and composition in semiconductors results in unpredictable transition energies for different QDs. This complication impedes the generation of single and entangled photons with well-defined energies, which fundamentally limits the success probability of scalable quantum information technologies. Strain engineering, a unique and powerful method to reshape the electronic states of semiconductors, has advanced the development of all-solid-state low-dimensional semiconductor based single and entangled-photon sources. In this review, the recent progress of employing mechanical strain field to control the electronic states and optical properties of low-dimensional semiconductors is reviewed. A comprehensive summary of diverse strain engineered devices for engineering the exciton binding energy, the coherent coupling of electronic states, the optical properties of low-dimensional semiconductors including single and entangled photons are provided. In addition, prospects and challenges of deploying the strain-engineering technique for future scalable quantum networks and photonic quantum circuits are discussed.},
   author = {Lue Tao and Weiwen Ou and Yang Li and Han Liao and Jiaxiang Zhang and Fuwan Gan and Xin Ou},
   doi = {10.1088/1361-6641/ab8e0b},
   issn = {0268-1242},
   issue = {10},
   journal = {Semiconductor Science and Technology},
   pages = {103002},
   publisher = {IOP Publishing},
   title = {Recent advances in mechanical strain engineering of low-dimensional semiconductors and their applications in high-performance quantum emitters},
   volume = {35},
   url = {https://dx.doi.org/10.1088/1361-6641/ab8e0b},
   year = {2020},
}
@article{Wu2015,
   author = {Xinyu Wu and Vishal Saxena and Kehan Zhu and Sakkarapani Balagopal},
   issue = {11},
   journal = {IEEE Transactions on Circuits and Systems II: Express Briefs},
   pages = {1088-1092},
   title = {A CMOS Spiking Neuron for Brain-Inspired Neural Networks with Resistive Synapses and In-Situ Learning},
   volume = {62},
   year = {2015},
}
@article{Lunt2018,
   abstract = {Strain is a crucial measure of materials deformation for evaluating and predicting the mechanical response, strength, and fracture. The spatial resolution attainable by the modern real and reciprocal space techniques continues to improve, alongside the ability to carry out atomistic simulations. This is offering new insights into the very concept of strain. In crystalline materials, the presence of well-defined, stable atomic planes allows defining strain as the relative change in the interplanar spacing. However, the presence of disorder, e.g. locally around defects such as dislocation cores, and particularly the pervasive atomic disorder in amorphous materials challenge existing paradigms: disorder prevents a reference configuration being defined, and allows strain to be accommodated in a different manner to crystalline materials. As an illustration, using experimental pair distribution function analysis in combination with Molecular Dynamic (MD) simulations, we highlight the importance of bond angle change vs bond stretching for strain accommodation in amorphous systems.},
   author = {Alexander J G Lunt and Philip Chater and Alexander M Korsunsky},
   doi = {10.1038/s41598-018-19900-2},
   issn = {2045-2322},
   issue = {1},
   journal = {Scientific Reports},
   pages = {1574},
   title = {On the origins of strain inhomogeneity in amorphous materials},
   volume = {8},
   url = {https://doi.org/10.1038/s41598-018-19900-2},
   year = {2018},
}
@article{Yang1999,
   abstract = {Long-term potentiation (LTP) and long-term depression (LTD), two prominent forms  of synaptic plasticity at glutamatergic afferents to CA1 hippocampal pyramidal cells, are both triggered by the elevation of postsynaptic intracellular calcium concentration ([Ca2+]i). To understand how one signaling molecule can be responsible for triggering two opposing forms of synaptic modulation, different postsynaptic [Ca2+]i elevation patterns were generated by a new caged calcium compound nitrophenyl-ethylene glycol-bis(beta-aminoethyl ether)-N,N,N',N'-tetraacetic acid in CA1 pyramidal cells. We found that specific patterns of [Ca2+]i elevation selectively activate LTP or LTD. In particular, only LTP was triggered by a brief increase of [Ca2+]i with relatively high magnitude, which mimics the [Ca2+]i rise during electrical stimulation typically used to induce LTP. In contrast, a prolonged modest rise of [Ca2+]i reliably induced LTD. An important implication of the results is that both the amplitude and the duration of an intracellular chemical signal can carry significant biological information.},
   author = {S N Yang and Y G Tang and R S Zucker},
   doi = {10.1152/jn.1999.81.2.781},
   issn = {0022-3077 (Print)},
   issue = {2},
   journal = {Journal of neurophysiology},
   keywords = {Animals,Calcium,Chelating Agents,Egtazic Acid,Excitatory Postsynaptic Potentials,Hippocampus,In Vitro Techniques,Intracellular Fluid,Long-Term Potentiation,Neuronal Plasticity,Patch-Clamp Techniques,Photolysis,Rats,Rats, Sprague-Dawley,Synapses,analogs & derivatives,drug effects,metabolism,pharmacology,physiology},
   month = {2},
   pages = {781-787},
   pmid = {10036277},
   title = {Selective induction of LTP and LTD by postsynaptic [Ca2+]i elevation.},
   volume = {81},
   year = {1999},
}
@book{Sze2006,
   author = {S. M. Sze and Kwok K. Ng},
   pages = {549},
   title = {Physics of Semiconductor Devices, 3rd ed. (John Wiley & Sons, Hoboken, NJ, 2007)},
   year = {2006},
}
@article{Park2022,
   abstract = {Neuromorphic computing, a computing paradigm inspired by the human brain, enables energy-efficient and fast artificial neural networks. To process information, neuromorphic computing directly mimics the operation of biological neurons in a human brain. To effectively imitate biological neurons with electrical devices, memristor-based artificial neurons attract attention because of their simple structure, energy efficiency, and excellent scalability. However, memristor’s non-reliability issues have been one of the main obstacles for the development of memristor-based artificial neurons and neuromorphic computings. Here, we show a memristor 1R cross-bar array without transistor devices for individual memristor access with low variation, 100% yield, large dynamic range, and fast speed for artificial neuron and neuromorphic computing. Based on the developed memristor, we experimentally demonstrate a memristor-based neuron with leaky-integrate and fire property with excellent reliability. Furthermore, we develop a neuro-memristive computing system based on the short-term memory effect of the developed memristor for efficient processing of sequential data. Our neuro-memristive computing system successfully trains and generates bio-medical sequential data (antimicrobial peptides) while using a small number of training parameters. Our results open up the possibility of memristor-based artificial neurons and neuromorphic computing systems, which are essential for energy-efficient edge computing devices.},
   author = {See-On Park and Hakcheon Jeong and Jongyong Park and Jongmin Bae and Shinhyun Choi},
   doi = {10.1038/s41467-022-30539-6},
   issn = {2041-1723},
   issue = {1},
   journal = {Nature Communications},
   pages = {2888},
   title = {Experimental demonstration of highly reliable dynamic memristor for artificial neuron and neuromorphic computing},
   volume = {13},
   url = {https://doi.org/10.1038/s41467-022-30539-6},
   year = {2022},
}
@article{Chae2022,
   abstract = {Entropic stabilization has evolved into a strategy to create new oxide materials and realize novel functional properties engineered through the alloy composition. Achieving an atomistic understanding of these properties to enable their design, however, has been challenging due to the local compositional and structural disorder that underlies their fundamental structure-property relationships. Here, we combine high-throughput atomistic calculations and linear regression algorithms to investigate the role of local configurational and structural disorder on the thermodynamics of vacancy formation in (MgCoNiCuZn)O-based entropy-stabilized oxides (ESOs) and their influence on the electrical properties. We find that the cation-vacancy formation energies decrease with increasing local tensile strain caused by the deviation of the bond lengths in ESOs from the equilibrium bond length in the binary oxides. The oxygen-vacancy formation strongly depends on structural distortions associated with the local configuration of chemical species. Vacancies in ESOs exhibit deep thermodynamic transition levels that inhibit electrical conduction. By applying the charge-neutrality condition, we determine that the equilibrium concentrations of both oxygen and cation vacancies increase with increasing Cu mole fraction. Our results demonstrate that tuning the local chemistry and associated structural distortions by varying alloy composition acts an engineering principle that enables controlled defect formation in multi-component alloys.},
   author = {Sieun Chae and Logan Williams and Jihang Lee and John T. Heron and Emmanouil Kioupakis},
   doi = {10.1038/s41524-022-00780-0},
   issn = {20573960},
   issue = {1},
   journal = {npj Computational Materials},
   pages = {95},
   publisher = {Springer US},
   title = {Effects of local compositional and structural disorder on vacancy formation in entropy-stabilized oxides from first-principles},
   volume = {8},
   year = {2022},
}
@article{Kumar2020,
   abstract = {Current hardware approaches to biomimetic or neuromorphic artificial intelligence rely on elaborate transistor circuits to simulate biological functions. However, these can instead be more faithfully emulated by higher-order circuit elements that naturally express neuromorphic nonlinear dynamics1–4. Generating neuromorphic action potentials in a circuit element theoretically requires a minimum of third-order complexity (for example, three dynamical electrophysical processes)5, but there have been few examples of second-order neuromorphic elements, and no previous demonstration of any isolated third-order element6–8. Using both experiments and modelling, here we show how multiple electrophysical processes—including Mott transition dynamics—form a nanoscale third-order circuit element. We demonstrate simple transistorless networks of third-order elements that perform Boolean operations and find analogue solutions to a computationally hard graph-partitioning problem. This work paves a way towards very compact and densely functional neuromorphic computing primitives, and energy-efficient validation of neuroscientific models.},
   author = {Suhas Kumar and R. Stanley Williams and Ziwen Wang},
   doi = {10.1038/s41586-020-2735-5},
   isbn = {4158602027355},
   issn = {14764687},
   issue = {7826},
   journal = {Nature},
   pages = {518-523},
   pmid = {32968256},
   publisher = {Springer US},
   title = {Third-order nanocircuit elements for neuromorphic engineering},
   volume = {585},
   year = {2020},
}
@article{Rost2015,
   author = {Christina M Rost and Edward Sachet and Trent Borman and Ali Moballegh and Elizabeth C Dickey and Dong Hou and Jacob L Jones and Stefano Curtarolo and Jon-paul Maria},
   doi = {10.1038/ncomms9485},
   journal = {Nature Communications},
   pages = {8485},
   publisher = {Nature Publishing Group},
   title = {Entropy-stabilized oxides},
   volume = {6},
   year = {2015},
}
@article{Zidan2018,
   abstract = {A memristor is a resistive device with an inherent memory. The theoretical concept of a memristor was connected to physically measured devices in 2008 and since then there has been rapid progress in the development of such devices, leading to a series of recent demonstrations of memristor-based neuromorphic hardware systems. Here, we evaluate the state of the art in memristor-based electronics and explore where the future of the field lies. We highlight three areas of potential technological impact: on-chip memory and storage, biologically inspired computing and general-purpose in-memory computing. We analyse the challenges, and possible solutions, associated with scaling the systems up for practical applications, and consider the benefits of scaling the devices down in terms of geometry and also in terms of obtaining fundamental control of the atomic-level dynamics. Finally, we discuss the ways we believe biology will continue to provide guiding principles for device innovation and system optimization in the field.},
   author = {Mohammed A. Zidan and John Paul Strachan and Wei D. Lu},
   doi = {10.1038/s41928-017-0006-8},
   issn = {25201131},
   issue = {1},
   journal = {Nature Electronics},
   pages = {22-29},
   publisher = {Springer US},
   title = {The future of electronics based on memristive systems},
   volume = {1},
   year = {2018},
}
@article{Ielmini2007,
   abstract = {Chalcogenide materials are receiving increasing interest for their many applications as active materials in emerging memories, such as phase-change memories, programmable metallization cells, and cross-point devices. The great advantage of these materials is the capability to appear in two different phases, the amorphous and the crystalline phases, with rather different electrical properties. The aim of this work is to provide a physically based model for conduction in the amorphous chalcogenide material, able to predict the current-voltage (I-V) characteristics as a function of phase state, temperature, and cell geometry. First, the trap-limited transport at relatively low currents (subthreshold regime) is studied, leading to a comprehensive model for subthreshold conduction accounting for (a) the shape of the I-V characteristics, (b) the measured temperature dependence, (c) the dependence of subthreshold slope on the thickness of the amorphous phase, and (d) the voltage dependence of the activation energy. The threshold switching mechanism is then explained by the nonequilibrium population in high-mobility shallow traps at high electric field and by the nonuniform field distribution along the amorphous layer thickness. A single analytical model is then shown which is able to account for subthreshold conduction, threshold switching, negative differential resistance region, and ON regime. The model can be applied for fast yet physically based computation of the current in chalcogenide-based devices (e.g., phase change memory cells and arrays) as a function of applied voltage, temperature, and programmed state. © 2007 American Institute of Physics.},
   author = {Daniele Ielmini and Yuegang Zhang},
   doi = {10.1063/1.2773688},
   isbn = {3902236760},
   issn = {00218979},
   issue = {5},
   journal = {Journal of Applied Physics},
   pages = {054517},
   title = {Analytical model for subthreshold conduction and threshold switching in chalcogenide-based memory devices},
   volume = {102},
   year = {2007},
}
@article{Kumar2022,
   abstract = {Research on electronic devices and materials is currently driven by both the slowing down of transistor scaling and the exponential growth of computing needs, which make present digital computing increasingly capacity-limited and power-limited. A promising alternative approach consists in performing computing based on intrinsic device dynamics, such that each device functionally replaces elaborate digital circuits, leading to adaptive ‘complex computing’. Memristors are a class of devices that naturally embody higher-order dynamics through their internal electrophysical processes. In this Review, we discuss how novel material properties enable complex dynamics and define different orders of complexity in memristor devices and systems. These native complex dynamics at the device level enable new computing architectures, such as brain-inspired neuromorphic systems, which offer both high energy efficiency and high computing capacity.},
   author = {Suhas Kumar and Xinxin Wang and John Paul Strachan and Yuchao Yang and Wei D. Lu},
   doi = {10.1038/s41578-022-00434-z},
   isbn = {0123456789},
   issn = {20588437},
   journal = {Nature Reviews Materials},
   pages = {575-591},
   publisher = {Springer US},
   title = {Dynamical memristors for higher-complexity neuromorphic computing},
   volume = {7},
   year = {2022},
}
@article{Meisenheimer2019,
   abstract = {Entropy-stabilized oxides possess a large configurational entropy that allows for the unique ability to include typically immiscible concentrations of species in different configurations. Particularly in oxides, where the physical behavior is strongly correlated to stereochemistry and electronic structure, entropic stabilization creates a unique platform to tailor the interplay of extreme structural and chemical disorder to realize unprecedented functionalities. Here, we control stereochemically driven structural disorder in single crystalline, rocksalt, (MgCoNiCuZn)O-type entropy-stabilized oxides through the incorporation of Cu2+ cations. We harness the disorder to tune the degree of glassiness in the antiferromagnetic structure. Structural distortions driven by the Jahn-Teller effect lead to a difference in valence on the Co cation sites, which extends to dilution and disorder of the magnetic lattice. A spin glass model reveals that the fractional spin ordering of the magnetic lattice can be tuned by ∼65%. These findings demonstrate entropy-stabilization as a tool for control of functional phenomena.},
   author = {Peter B. Meisenheimer and Logan D. Williams and Suk Hyun Sung and Jiseok Gim and Padraic Shafer and George N. Kotsonis and Jon Paul Maria and Morgan Trassin and Robert Hovden and Emmanouil Kioupakis and John T. Heron},
   doi = {10.1103/PhysRevMaterials.3.104420},
   issn = {24759953},
   issue = {10},
   journal = {Physical Review Materials},
   pages = {104420},
   publisher = {American Physical Society},
   title = {Magnetic frustration control through tunable stereochemically driven disorder in entropy-stabilized oxides},
   volume = {3},
   year = {2019},
}
@article{Meisenheimer2017,
   abstract = {Entropy-stabilized materials are stabilized by the configurational entropy of the constituents, rather than the enthalpy of formation of the compound. A unique benefit to entropy-stabilized materials is the increased solubility of elements, which opens a broad compositional space, with subsequent local chemical and structural disorder resulting from different atomic sizes and preferred coordinations of the constituents. Known entropy-stabilized oxides contain magnetically interesting constituents, however, the magnetic properties of the multi-component oxide have yet to be investigated. Here we examine the role of disorder and composition on the exchange anisotropy of permalloy/(Mg0.25(1-x)CoxNi0.25(1-x)Cu0.25(1-x)Zn0.25(1-x))O heterostructures. Anisotropic magnetic exchange and the presence of a critical blocking temperature indicates that the magnetic order of the entropy-stabilized oxides considered here is antiferromagnetic. Changing the composition of the oxide tunes the disorder, exchange field and magnetic anisotropy. Here, we exploit this tunability to enhance the strength of the exchange field by a factor of 10x at low temperatures, when compared to a permalloy/CoO heterostructure. Significant deviations from the rule of mixtures are observed in the structural and magnetic parameters, indicating that the crystal is dominated by configurational entropy. Our results reveal that the unique characteristics of entropy-stabilized materials can be utilized and tailored to engineer magnetic functional phenomena in oxide thin films.},
   author = {P. B. Meisenheimer and T. J. Kratofil and J. T. Heron},
   doi = {10.1038/s41598-017-13810-5},
   isbn = {4159801713810},
   issn = {20452322},
   issue = {1},
   journal = {Scientific Reports},
   pages = {3-8},
   title = {Giant enhancement of exchange coupling in entropy-stabilized oxide heterostructures},
   volume = {7},
   year = {2017},
}
@article{Lee2018,
   abstract = {Rapid advances in the semiconductor industry, driven largely by device scaling, are now approaching fundamental physical limits and face severe power, performance, and cost constraints. Multifunctional materials and devices may lead to a paradigm shift toward new, intelligent, and efficient computing systems, and are being extensively studied. Herein examines how, by controlling the internal ion distribution in a solid-state film, a material's chemical composition and physical properties can be reversibly reconfigured using an applied electric field, at room temperature and after device fabrication. Reconfigurability is observed in a wide range of materials, including commonly used dielectric films, and has led to the development of new device concepts such as resistive random-access memory. Physical reconfigurability further allows memory and logic operations to be merged in the same device for efficient in-memory computing and neuromorphic computing systems. By directly changing the chemical composition of the material, coupled electrical, optical, and magnetic effects can also be obtained. A survey of recent fundamental material and device studies that reveal the dynamic ionic processes is included, along with discussions on systematic modeling efforts, device and material challenges, and future research directions. By controlling the internal ion distribution in a solid-state film, the material's chemical composition and physical (i.e., electrical, optical, and magnetic) properties can be reversibly reconfigured, in situ, using an applied electric field. The reconfigurability is achieved in a wide range of materials, and can lead to the development of new memory, logic, and multifunctional devices and systems.},
   author = {Jihang Lee and Wei D. Lu},
   doi = {10.1002/adma.201702770},
   issn = {15214095},
   issue = {1},
   journal = {Advanced Materials},
   pages = {1702770},
   title = {On-Demand Reconfiguration of Nanomaterials: When Electronics Meets Ionics},
   volume = {30},
   year = {2018},
}
@article{,
   abstract = {Recent scaling results for the ac conductivity of ionic glasses by Roling et al. [Phys. Rev. Lett. 78, 2160 (1997)] and Sidebottom [Phys. Rev. Lett. 82, 3653 (1999)] are discussed. We prove that Sidebottom's version of scaling is completely general. A new approximation to the universal ac conductivity arising in the extreme disorder limit of the symmetric hopping model, the “diffusion cluster approximation,” is presented and compared to computer simulations and experiments. © 2000 The American Physical Society.},
   author = {Thomas B. Schrøder and Jeppe C. Dyre},
   doi = {10.1103/PhysRevLett.84.310},
   issn = {10797114},
   issue = {2},
   journal = {Reviews of Modern Physics},
   pages = {873},
   title = {Universality of ac conduction in disordered solids},
   volume = {72},
   year = {2000},
}
@article{Strukov2008,
   abstract = {Anyone who ever took an electronics laboratory class will be familiar with the fundamental passive circuit elements: the resistor, the capacitor and the inductor. However, in 1971 Leon Chua reasoned from symmetry arguments that there should be a fourth fundamental element, which he called a memristor (short for memory resistor). Although he showed that such an element has many interesting and valuable circuit properties, until now no one has presented either a useful physical model or an example of a memristor. Here we show, using a simple analytical example, that memristance arises naturally in nanoscale systems in which solid-state electronic and ionic transport are coupled under an external bias voltage. These results serve as the foundation for understanding a wide range of hysteretic current-voltage behaviour observed in many nanoscale electronic devices that involve the motion of charged atomic or molecular species, in particular certain titanium dioxide cross-point switches. ©2008 Nature Publishing Group.},
   author = {Dmitri B. Strukov and Gregory S. Snider and Duncan R. Stewart and R. Stanley Williams},
   doi = {10.1038/nature06932},
   issn = {00280836},
   issue = {7191},
   journal = {Nature},
   pages = {80-83},
   pmid = {18451858},
   title = {The missing memristor found},
   volume = {453},
   year = {2008},
}
@article{Scher1991,
   author = {Harvey Scher and Michael F Shlesinger and John T Bendler},
   doi = {10.1063/1.881289},
   journal = {Physics today},
   pages = {26-34},
   title = {Time-scale invariance in transport and relaxation},
   volume = {44},
   year = {1991},
}
@article{Elliott1987,
   abstract = {The various origins of a frequency-dependent conductivity in amorphous semiconductors are reviewed, stressing particularly recent advances and the influences that factors such as correlation and non-random spatial distributions of electrically active centres can have on the a.c. conductivity. A comprehensive survey is given of the experimental a.c. data for two types of amorphous semiconductor, namely chalcogenide and pnictide materials. It is concluded that the a.c. behaviour at intermediate to high temperatures is well accounted for by the correlated-barrier-hopping model, whereas the low-temperature behaviour is probably due to atomic tunnelling. © Taylor & Francis Group, LLC.},
   author = {S. R. Elliott},
   doi = {10.1080/00018738700101971},
   issn = {14606976},
   issue = {2},
   journal = {Advances in Physics},
   pages = {135-218},
   title = {A.c. conduction in amorphous chalcogenide and pnictide semiconductors},
   volume = {36},
   year = {1987},
}
@article{Alomar2015,
   author = {Miquel L Alomar and Miguel C Soriano and Miguel Escalona-morán and Vincent Canals and Ingo Fischer and Claudio R Mirasso and Jose L Rosselló},
   issue = {10},
   journal = {IEEE Transactions on Circuits and Systems II: Express Briefs},
   pages = {977-981},
   title = {Digital implementation of a single dynamical node reservoir computer},
   volume = {62},
   year = {2015},
}
@article{Flanders2011,
   abstract = {This Prospects presents the problems that must be solved by the vertebrate nervous system in the process of sensorimotor integration and motor control. The concepts of efference copy and inverse model are defined, and multiple biological mechanisms are described, including those that form the basis of integration, extrapolation, and comparison/cancellation operations. Open questions for future research include the biological basis of continuous and distributed versus modular control, and somatosensory–motor coordination.},
   author = {Martha Flanders},
   doi = {10.1007/s00422-011-0419-9},
   issn = {1432-0770},
   issue = {1},
   journal = {Biological Cybernetics},
   pages = {1-8},
   title = {What is the biological basis of sensorimotor integration?},
   volume = {104},
   url = {https://doi.org/10.1007/s00422-011-0419-9},
   year = {2011},
}
@book_section{Refaeilzadeh2009,
   author = {Payam Refaeilzadeh and Lei Tang and Huan Liu},
   city = {Boston, MA},
   doi = {10.1007/978-0-387-39940-9_565},
   editor = {LING LIU and M TAMER ÖZSU},
   isbn = {978-0-387-39940-9},
   journal = {Encyclopedia of Database Systems},
   pages = {532-538},
   publisher = {Springer US},
   title = {Cross-Validation},
   url = {https://doi.org/10.1007/978-0-387-39940-9_565},
   year = {2009},
}
@article{Anisimov1991,
   author = {Vladimir I Anisimov and Jan Zaanen and Ole K Andersen},
   issue = {3},
   journal = {Physical Review B},
   pages = {943-954},
   title = {Band theory and Mott insulators: Hubbard U instead of Stoner I},
   volume = {44},
   year = {1991},
}
@article{,
   abstract = {We present a new algorithm to generate Special Quasirandom Structures (SQS), i.e., best periodic supercell approximations to the true disordered state for a given number of atoms per supercell. The method is based on a Monte Carlo simulated annealing loop with an objective function that seeks to perfectly match the maximum number of correlation functions (as opposed to merely minimizing the distance between the SQS correlation and the disordered state correlations for a pre-specified set of correlations). The proposed method optimizes the shape of the supercell jointly with the occupation of the atomic sites, thus ensuring that the configurational space searched is exhaustive and not biased by a pre-specified supercell shape. The method has been implemented in the "mcsqs" code of the Alloy Theoretic Automated Toolkit (ATAT) in the most general framework of multicomponent multisublattice systems and in a way that minimizes the amount of input information the user needs to specify and that allows for efficient parallelization. © 2013 Elsevier Ltd.},
   author = {A. Van De Walle and P. Tiwary and M. De Jong and D. L. Olmsted and M. Asta and A. Dick and D. Shin and Y. Wang and L. Q. Chen and Z. K. Liu},
   doi = {10.1016/j.calphad.2013.06.006},
   issn = {03645916},
   journal = {Calphad: Computer Coupling of Phase Diagrams and Thermochemistry},
   pages = {13-18},
   publisher = {Elsevier},
   title = {Efficient stochastic generation of special quasirandom structures},
   volume = {42},
   year = {2013},
}
@article{,
   abstract = {We report the magnetic properties of Mg0.2Co0.2Ni0.2Cu0.2Zn0.2O, a high-entropy oxide with a rocksalt structure, and the influence of substitutions on these properties. From the magnetic susceptibility and neutron diffraction measurements, we found that this compound exhibits long-range magnetic order below 120 K despite the substantial structural disorder. Other rocksalt-type high-entropy oxides with various chemical substitutions were found to host either an antiferromagnetic order or spin-glass state depending on the amount of magnetic ions. The presence of magnetic order for such a disordered material potentially provides a route to explore exotic magnetic properties and functions.},
   author = {Marco Polo Jimenez-Segura and Tomohiro Takayama and David Bérardan and Andreas Hoser and Manfred Reehuis and Hidenori Takagi and Nita Dragoe},
   doi = {10.1063/1.5091787},
   issn = {0003-6951},
   issue = {12},
   journal = {Applied Physics Letters},
   month = {3},
   pages = {122401},
   publisher = { AIP Publishing LLC  },
   title = {Long-range magnetic ordering in rocksalt-type high-entropy oxides},
   volume = {114},
   year = {2019},
}
@article{Zhang2019,
   abstract = {We report for the first time the magnetic structure of the high entropy oxide (Mg0.2Co0.2Ni0.2Cu0.2Zn0.2)O using neutron powder diffraction. This material exhibits a sluggish magnetic transition but possesses a long-range ordered antiferromagnetic ground state, as revealed by direct current and alternating current magnetic susceptibility, neutron diffraction, and spectroscopy. The magnetic propagation wavevector is k = (1/2, 1/2, 1/2) based on the cubic structure Fm3̅m, and the magnetic structure consists of ferromagnetic sheets in the (111) planes with spins antiparallel between two neighboring planes. Neutron spectroscopy reveals strong magnetic excitations at 100 K that survive up to room temperature. This work demonstrates that entropy-stabilized oxides represent a unique platform to study long-range magnetic order with an extreme chemical disorder.},
   author = {Junjie Zhang and Jiaqiang Yan and Stuart Calder and Qiang Zheng and Michael A. McGuire and Douglas L. Abernathy and Yang Ren and Saul H. Lapidus and Katharine Page and Hong Zheng and John W. Freeland and John D. Budai and Raphael P. Hermann},
   doi = {10.1021/acs.chemmater.9b00624},
   issn = {0897-4756},
   journal = {Chemistry of Materials},
   month = {5},
   pages = {3705-3711},
   publisher = {American Chemical Society},
   title = {Long-Range Antiferromagnetic Order in a Rocksalt High Entropy Oxide},
   volume = {31},
   year = {2019},
}
@article{Zunger1990,
   abstract = {Structural models used in calculations of properties of substitutionally random A(1-x)B(x) alloys are usually constructed by randomly occupying each of the N sites of a periodic cell by A or B. We show that it is possible to design "special quasirandom structures" (SQS's) that mimic for small N (even N = 8) the first few, physically most relevant radial correlation functions of a perfectly random structure far better than the standard technique does. We demonstrate the usefulness of these SQS's by calculating optical and thermodynamic properties of a number of semiconductor alloys in the local-density formalism.},
   author = {Alex Zunger and S.-H. Wei and L. G. Ferreira and James E. Bernard},
   doi = {10.1007/978-94-007-1960-6_10},
   isbn = {9789400719606},
   issue = {3},
   journal = {Physical Review Letters},
   pages = {353-356},
   title = {Special Quasirandom Structures},
   volume = {65},
   year = {1990},
}
@article{Kresse1993,
   abstract = {We present ab initio quantum-mechanical molecular-dynamics calculations based on the calculation of the electronic ground state and of the Hellmann-Feynman forces in the local-density approximation at each molecular-dynamics step. This is possible using conjugate-gradient techniques for energy minimization, and predicting the wave functions for new ionic positions using sub-space lignment. This approach avoids the instabilities inherent in quantum-mechanical molecular-dynamics calculations for metals based on the use of a fictitious Newtonian dynamics for the electronic degree of freedom. This method gives perfect control of the adiabaticity and allows us to perform simulations over several picoseconds.},
   author = {G. Kresse and J. Hafner},
   doi = {10.1103/PhysRevB.47.558},
   isbn = {0163-1829 (Print)\n0163-1829 (Linking)},
   issn = {01631829},
   issue = {1},
   journal = {Physical Review B},
   pages = {558-561},
   pmid = {9984901},
   title = {Ab initio molecular dynamics for liquid metals},
   volume = {47},
   year = {1993},
}
@article{Kresse1996,
   abstract = {We present an efficient scheme for calculating the Kohn-Sham ground state of metallic systems using pseudopotentials and a plane-wave basis set. In the first part the application of Pulay’s DIIS method (direct inversion in the iterative subspace) to the iterative diagonalization of large matrices will be discussed. Our approach is stable, reliable, and minimizes the number of order Natoms3 operations. In the second part, we will discuss an efficient mixing scheme also based on Pulay’s scheme. A special ‘‘metric’’ and a special ‘‘preconditioning’’ optimized for a plane-wave basis set will be introduced. Scaling of the method will be discussed in detail for non-self-consistent and self-consistent calculations. It will be shown that the number of iterations required to obtain a specific precision is almost independent of the system size. Altogether an order Natoms2 scaling is found for systems containing up to 1000 electrons. If we take into account that the number of k points can be decreased linearly with the system size, the overall scaling can approach Natoms. We have implemented these algorithms within a powerful package called VASP (Vienna ab initio simulation package). The program and the techniques have been used successfully for a large number of different systems (liquid and amorphous semiconductors, liquid simple and transition metals, metallic and semiconducting surfaces, phonons in simple metals, transition metals, and semiconductors) and turned out to be very reliable. © 1996 The American Physical Society.},
   author = {G. Kresse and J. Furthmüller},
   doi = {10.1103/PhysRevB.54.11169},
   isbn = {1098-0121},
   issn = {1550235X},
   issue = {16},
   journal = {Physical Review B - Condensed Matter and Materials Physics},
   pages = {11169-11186},
   pmid = {9984901},
   title = {Efficient iterative schemes for ab initio total-energy calculations using a plane-wave basis set},
   volume = {54},
   year = {1996},
}
@article{Eshraghian2022-training,
   author = {Jason K Eshraghian and Xinxin Wang and Mohammed Bennamoun and Max Ward and Wei D Lu and Gregor Lenz},
   journal = {arXiv},
   title = {Training spiking neural networks using lessons from deep learning},
   url = {arxiv:2109.12894v4},
   year = {2022},
}
@article{Li2018,
   author = {Yibo Li and Zhongrui Wang and Rivu Midya and Qiangfei Xia and J Joshua Yang},
   journal = {Journal of physics D: Applied Physics},
   keywords = {in colour only in,memristive devices,memristor,neuromorphic computing,some figures may appear,the online journal},
   pages = {503002},
   publisher = {IOP Publishing},
   title = {Review of memristor devices in neuromorphic computing : materials sciences and device challenges},
   volume = {51},
   year = {2018},
}
@article{Kresse1996,
   abstract = {We present a detailed description and comparison of algorithms for performing ab-initio quantum-mechanical calculations using pseudopotentials and a plane-wave basis set. We will discuss: (a) partial occupancies within the framework of the linear tetrahedron method and the finite temperature density-functional theory, (b) iterative methods for the diagonalization of the Konn-Sham Hamiltonian and a discussion of an efficient iterative method based on the ideas of Pulay's residual minimization, which is close to an order N2atomsscaling even for relatively large systems, (c) efficient Broyden-like and Pulay-like mixing methods for the charge density including a new special 'preconditioning' optimized for a plane-wave basis set, (d) conjugate gradient methods for minimizing the electronic free energy with respect to all degrees of freedom simultaneously. We have implemented these algorithms within a powerful package called VAMP (Vienna ab-initio molecular-dynamics package). The program and the techniques have been used successfully for a large number of different systems (liquid and amorphous semiconductors, liquid simple and transition metals, metallic and semi-conducting surfaces, phonons in simple metals, transition metals and semiconductors) and turned out to be very reliable.},
   author = {G. Kresse and J. Furthmüller},
   doi = {10.1016/0927-0256(96)00008-0},
   isbn = {0927-0256},
   issn = {09270256},
   issue = {1},
   journal = {Computational Materials Science},
   pages = {15-50},
   pmid = {9984901},
   title = {Efficiency of ab-initio total energy calculations for metals and semiconductors using a plane-wave basis set},
   volume = {6},
   year = {1996},
}
@article{Gauthier2021,
   abstract = {Reservoir computing is a best-in-class machine learning algorithm for processing information generated by dynamical systems using observed time-series data. Importantly, it requires very small training data sets, uses linear optimization, and thus requires minimal computing resources. However, the algorithm uses randomly sampled matrices to define the underlying recurrent neural network and has a multitude of metaparameters that must be optimized. Recent results demonstrate the equivalence of reservoir computing to nonlinear vector autoregression, which requires no random matrices, fewer metaparameters, and provides interpretable results. Here, we demonstrate that nonlinear vector autoregression excels at reservoir computing benchmark tasks and requires even shorter training data sets and training time, heralding the next generation of reservoir computing.},
   author = {Daniel J Gauthier and Erik Bollt and Aaron Griffith and Wendson A S Barbosa},
   doi = {10.1038/s41467-021-25801-2},
   issn = {2041-1723},
   issue = {1},
   journal = {Nature Communications},
   pages = {5564},
   title = {Next generation reservoir computing},
   volume = {12},
   url = {https://doi.org/10.1038/s41467-021-25801-2},
   year = {2021},
}
@article{Zahoor2020,
   author = {Furqan Zahoor and Tun Zainal and Azni Zulkifli and Farooq Ahmad Khanday},
   keywords = {Emerging memory,Multilevel cell (MLC),Non-volatile,emerging memory,memory,mlc,multilevel cell,non-volatile storage,oxygen vacancies,resistance switching,resistive random access,rram},
   publisher = {Nanoscale Research Letters},
   title = {Resistive Random Access Memory ( RRAM ): an Overview of Materials , Switching Mechanism , Performance , Multilevel Cell ( mlc ) Storage , Modeling , and Applications},
   year = {2020},
}
@article{Naous2021,
   author = {Rawan Naous and Anne Siemon and Michael Schulten and Hamzah Alahmadi and Andreas Kindsmüller and Michael Lübben and Arne Heittmann and Rainer Waser and Khaled Nabil Salama and Stephan Menzel},
   doi = {10.1038/s41598-021-83382-y},
   isbn = {0123456789},
   issn = {2045-2322},
   journal = {Scientific Reports},
   pages = {1-11},
   publisher = {Nature Publishing Group UK},
   title = {Theory and experimental verification of configurable computing with stochastic memristors},
   url = {https://doi.org/10.1038/s41598-021-83382-y},
   year = {2021},
}
@article{Kang2010,
   author = {Uksong Kang and Hoe-ju Chung and Seongmoo Heo and Duk-ha Park and Hoon Lee and Jin Ho Kim and Soon-hong Ahn and Soo-ho Cha and Jaesung Ahn and Dukmin Kwon and Jae-wook Lee and Han-sung Joo and Woo-seop Kim and Dong Hyeon Jang and Nam Seog Kim and Jung-hwan Choi and Tae-gyeong Chung and Jei-hwan Yoo and Joo Sun Choi and Changhyun Kim and Senior Member and Young-hyun Jun and Abstract An and Gb Ddr},
   issue = {1},
   pages = {111-119},
   title = {8 Gb 3-D DDR3 DRAM Using Through-Silicon-Via Technology},
   volume = {45},
   year = {2010},
}
@inproceedings{Morillas2020,
   author = {R M Morillas and P Ituero},
   doi = {10.1109/DCIS51330.2020.9268614},
   isbn = {2640-5563 VO  -},
   journal = {2020 XXXV Conference on Design of Circuits and Integrated Systems (DCIS)},
   pages = {1-6},
   title = {{STDP} Design Trade-offs for {FPGA}-Based Spiking Neural Networks},
   year = {2020},
}
@article{Chang2011,
   author = {Ting Chang and Sung-hyun Jo and Wei Lu},
   issue = {9},
   journal = {ACS Nano},
   keywords = {memory,memristor,neuromorphic,retention,training,transition},
   pages = {7669-7676},
   title = {Short-Term Memory to Long-Term Memory Transition in a Nanoscale Memristor},
   volume = {5},
   year = {2011},
}
@article{,
   author = {Song Han and Jeff Pool and John Tran and William J Dally},
   pages = {1-9},
   title = {Learning both Weights and Connections for Efficient Neural Networks},
}
@article{,
   author = {Jiecao Yu and Andrew Lukefahr and David Palframan and Ganesh Dasika and Reetuparna Das and Scott Mahlke},
   isbn = {9781450348928},
   keywords = {hardware parallelism,neural network pruning,single instruction},
   title = {Scalpel : Customizing DNN Pruning to the Underlying Hardware Parallelism},
}
@article{Han2016,
   author = {Song Han and Huizi Mao and William J Dally},
   journal = {ICLR 2016},
   pages = {1-14},
   title = {Deep compression: Compression deep neural networks with pruning, trained quantization and Huffman coding},
   year = {2016},
}
@article{Wen2016,
   author = {Wei Wen and Chunpeng Wu and Yandan Wang and Yiran Chen and Hai Li},
   journal = {arXiv},
   title = {Learning structured sparsity in deep neural networks},
   year = {2016},
}
@article{Li2017-pruning,
   author = {Hao Li and Asim Kadav and Igor Durdanovic and Hanan Samet and Hans Peter Graf},
   issue = {2016},
   pages = {1-13},
   title = {Pruning filters for efficient convnets},
   year = {2017},
}
@article{Molchanov2017,
   author = {Pavlo Molchanov and Stephen Tyree and Tero Karras and Timo Aila and Jan Kautz},
   issue = {2015},
   pages = {1-17},
   title = {P RUNING C ONVOLUTIONAL N EURAL N ETWORKS},
   year = {2017},
}
@article{Liang2018,
   author = {Ling Liang and L E I Deng and Yueling Zeng and Xing Hu and Y U Ji},
   doi = {10.1109/ACCESS.2018.2874823},
   title = {Crossbar-Aware Neural Network Pruning},
   volume = {6},
   year = {2018},
}
@inproceedings{He2017,
   author = {Y He and X Zhang and J Sun},
   doi = {10.1109/ICCV.2017.155},
   isbn = {2380-7504 VO  -},
   journal = {2017 IEEE International Conference on Computer Vision (ICCV)},
   pages = {1398-1406},
   title = {Channel Pruning for Accelerating Very Deep Neural Networks},
   year = {2017},
}
@article{,
   author = {Ahmed Shaban},
   doi = {10.1038/s41467-021-24427-8},
   issn = {2041-1723},
   issue = {2021},
   journal = {Nature Communications},
   publisher = {Springer US},
   title = {implementation},
   url = {http://dx.doi.org/10.1038/s41467-021-24427-8},
}
@article{Vaswani2017,
   author = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N.Gomez and Lukasz Kaiser},
   issue = {Nips},
   title = {Attention Is All You Need},
   year = {2017},
}
@article{,
   author = {Sung Hyun Jo and Tanmay Kumar and Sundar Narayanan and Wei D Lu and Hagop Nazarian and Patrick Henry and Santa Clara},
   issue = {408},
   pages = {10-13},
   title = {3D-stackable Crossbar Resistive Memory based on Field Assisted Superlinear Threshold ( FAST ) Selector},
}
@article{,
   abstract = {We present a novel strategy for unsupervised feature learning in image applications inspired by the Spike-Timing-Dependent-Plasticity (STDP) biological learning rule. We show equivalence between rank order coding Leaky-Integrate-and-Fire neurons and ReLU artificial neurons when applied to non-temporal data. We apply this to images using rank-order coding, which allows us to perform a full network simulation with a single feed-forward pass using GPU hardware. Next we introduce a binary STDP learning rule compatible with training on batches of images. Two mechanisms to stabilize the training are also presented : a Winner-Takes-All (WTA) framework which selects the most relevant patches to learn from along the spatial dimensions, and a simple feature-wise normalization as homeostatic process. This learning process allows us to train multi-layer architectures of convolutional sparse features. We apply our method to extract features from the MNIST, ETH80, CIFAR-10, and STL-10 datasets and show that these features are relevant for classification. We finally compare these results with several other state of the art unsupervised learning methods.},
   author = {Paul Ferré and Franck Mamalet and Simon J Thorpe},
   doi = {10.3389/fncom.2018.00024},
   issn = {1662-5188},
   journal = {Frontiers in computational neuroscience},
   keywords = {Spike-Timing-Dependent-Pasticity,neural network,unsupervised learning,vision,winner-takes-all},
   month = {4},
   pages = {24},
   publisher = {Frontiers Media S.A.},
   title = {Unsupervised Feature Learning With Winner-Takes-All Based STDP},
   volume = {12},
   url = {https://pubmed.ncbi.nlm.nih.gov/29674961 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5895733/},
   year = {2018},
}
@article{Graupner2012,
   author = {Michael Graupner and Nicolas Brunel},
   doi = {10.1073/pnas.1109359109},
   issue = {10},
   journal = {Proceedings of the International Joint Conference on Neural Networks},
   pages = {3991-3996},
   title = {Calcium-based plasticity model explains sensitivity of synaptic changes to spike pattern , rate , and dendritic location},
   volume = {109},
   year = {2012},
}
@article{Deng2013,
   author = {Y Deng and P Huang and B Chen and X Yang and B Gao and J Wang and L Zeng and G Du and J Kang and X Liu},
   doi = {10.1109/TED.2012.2231683},
   issn = {1557-9646 VO  - 60},
   issue = {2},
   journal = {IEEE Transactions on Electron Devices},
   pages = {719-726},
   title = {RRAM Crossbar Array With Cell Selection Device: A Device and Circuit Interaction Study},
   volume = {60},
   year = {2013},
}
@article{Shouval2002,
   author = {Harel Z Shouval and Mark F Bear and Leon N Cooper},
   doi = {10.1073/pnas.152343099},
   issue = {16},
   journal = {Proceedings of the National Academy of Sciences of the United States of America},
   pages = {10831-10836},
   title = {A unified model of NMDA receptor-dependent bidirectional synaptic plasticity},
   volume = {99},
   year = {2002},
}
@article{,
   author = {Maheswari Sivan and Yida Li and Hasita Veluri and Yunshan Zhao and Baoshan Tang and Xinghua Wang and Evgeny Zamburg and Jin Feng Leong and Jessie Xuhua Niu and Umesh Chand and Aaron Voon-yew Thean},
   doi = {10.1038/s41467-019-13176-4},
   issn = {2041-1723},
   issue = {2019},
   journal = {Nature Communications},
   pages = {1-12},
   publisher = {Springer US},
   title = {All WSe2 1T1R resistive RAM cell for future monolithic 3D embedded memory integration},
   url = {http://dx.doi.org/10.1038/s41467-019-13176-4},
}
@inproceedings{Burr2014,
   author = {G W Burr and R M Shelby and C di Nolfo and J W Jang and R S Shenoy and P Narayanan and K Virwani and E U Giacometti and B Kurdi and H Hwang},
   doi = {10.1109/IEDM.2014.7047135},
   isbn = {2156-017X VO  -},
   journal = {2014 IEEE International Electron Devices Meeting},
   pages = {29.5.1-29.5.4},
   title = {Experimental demonstration and tolerancing of a large-scale neural network (165,000 synapses), using phase-change memory as the synaptic weight element},
   year = {2014},
}
@article{,
   abstract = {As complementary metal–oxide–semiconductor (CMOS) scaling reaches its technological limits, a radical departure from traditional von Neumann systems, which involve separate processing and memory units, is needed in order to extend the performance of today’s computers substantially. In-memory computing is a promising approach in which nanoscale resistive memory devices, organized in a computational memory unit, are used for both processing and memory. However, to reach the numerical accuracy typically required for data analytics and scientific computing, limitations arising from device variability and non-ideal device characteristics need to be addressed. Here we introduce the concept of mixed-precision in-memory computing, which combines a von Neumann machine with a computational memory unit. In this hybrid system, the computational memory unit performs the bulk of a computational task, while the von Neumann machine implements a backward method to iteratively improve the accuracy of the solution. The system therefore benefits from both the high precision of digital computing and the energy/areal efficiency of in-memory computing. We experimentally demonstrate the efficacy of the approach by accurately solving systems of linear equations, in particular, a system of 5,000 equations using 998,752 phase-change memory devices.},
   author = {Manuel Le Gallo and Abu Sebastian and Roland Mathis and Matteo Manica and Heiner Giefers and Tomas Tuma and Costas Bekas and Alessandro Curioni and Evangelos Eleftheriou},
   doi = {10.1038/s41928-018-0054-8},
   issn = {2520-1131},
   issue = {4},
   journal = {Nature Electronics},
   pages = {246-253},
   title = {Mixed-precision in-memory computing},
   volume = {1},
   url = {https://doi.org/10.1038/s41928-018-0054-8},
   year = {2018},
}
@article{Li2018,
   abstract = {Memristor crossbars offer reconfigurable non-volatile resistance states and could remove the speed and energy efficiency bottleneck in vector-matrix multiplication, a core computing task in signal and image processing. Using such systems to multiply an analogue-voltage-amplitude-vector by an analogue-conductance-matrix at a reasonably large scale has, however, proved challenging due to difficulties in device engineering and array integration. Here we show that reconfigurable memristor crossbars composed of hafnium oxide memristors on top of metal-oxide-semiconductor transistors are capable of analogue vector-matrix multiplication with array sizes of up to 128 × 64 cells. Our output precision (5–8 bits, depending on the array size) is the result of high device yield (99.8%) and the multilevel, stable states of the memristors, while the linear device current–voltage characteristics and low wire resistance between cells leads to high accuracy. With the large memristor crossbars, we demonstrate signal processing, image compression and convolutional filtering, which are expected to be important applications in the development of the Internet of Things (IoT) and edge computing.},
   author = {Can Li and Miao Hu and Yunning Li and Hao Jiang and Ning Ge and Eric Montgomery and Jiaming Zhang and Wenhao Song and Noraica Dávila and Catherine E Graves and Zhiyong Li and John Paul Strachan and Peng Lin and Zhongrui Wang and Mark Barnell and Qing Wu and R Stanley Williams and J Joshua Yang and Qiangfei Xia},
   doi = {10.1038/s41928-017-0002-z},
   issn = {2520-1131},
   issue = {1},
   journal = {Nature Electronics},
   pages = {52-59},
   title = {Analogue signal and image processing with large memristor crossbars},
   volume = {1},
   url = {https://doi.org/10.1038/s41928-017-0002-z},
   year = {2018},
}
@article{Sheridan2017,
   author = {Patrick M Sheridan and Fuxi Cai and Chao Du and Wen Ma and Zhengya Zhang and Wei D Lu},
   doi = {10.1038/nnano.2017.83},
   journal = {Nature Nanotechnology},
   pages = {784-790},
   publisher = {Nature Publishing Group},
   title = {Sparse coding with memristor networks},
   volume = {12},
   year = {2017},
}
@article{Choi2017,
   author = {Shinhyun Choi and Jong Hoon Shin and Jihang Lee and Patrick Sheridan and Wei D Lu},
   doi = {10.1021/acs.nanolett.7b00552},
   journal = {Nano Letters},
   keywords = {arti fi cial neural,clustering,network,neuromorphic computing,principal component analysis,unsupervised learning},
   pages = {3113-3118},
   title = {Experimental Demonstration of Feature Extraction and Dimensionality Reduction Using Memristor Networks},
   volume = {17},
   year = {2017},
}
@inproceedings{Lyon1982,
   author = {R Lyon},
   doi = {10.1109/ICASSP.1982.1171644},
   isbn = {VO  - 7},
   journal = {ICASSP '82. IEEE International Conference on Acoustics, Speech, and Signal Processing},
   pages = {1282-1285},
   title = {A computational model of filtering, detection, and compression in the cochlea},
   volume = {7},
   year = {1982},
}
@article{Suzuki2022,
   abstract = {Reservoir computing is a temporal information processing system that exploits artificial or physical dissipative dynamics to learn a dynamical system and generate the target time-series. This paper proposes the use of real superconducting quantum computing devices as the reservoir, where the dissipative property is served by the natural noise added to the quantum bits. The performance of this natural quantum reservoir is demonstrated in a benchmark time-series regression problem and a practical problem classifying different objects based on temporal sensor data. In both cases the proposed reservoir computer shows a higher performance than a linear regression or classification model. The results indicate that a noisy quantum device potentially functions as a reservoir computer, and notably, the quantum noise, which is undesirable in the conventional quantum computation, can be used as a rich computation resource.},
   author = {Yudai Suzuki and Qi Gao and Ken C Pradel and Kenji Yasuoka and Naoki Yamamoto},
   doi = {10.1038/s41598-022-05061-w},
   issn = {2045-2322},
   issue = {1},
   journal = {Scientific Reports},
   pages = {1353},
   title = {Natural quantum reservoir computing for temporal information processing},
   volume = {12},
   url = {https://doi.org/10.1038/s41598-022-05061-w},
   year = {2022},
}
@article{Phillips1996,
   author = {James Christopher Phillips},
   journal = {Reports on Progress in Physics},
   pages = {1133-1207},
   title = {Stretched exponential relaxation in molecular and electronic glasses},
   volume = {59},
   year = {1996},
}
@article{Wu2018,
   author = {Zhen Wei Wu and Walter Kob and Wei-hua Wang and Limei Xu},
   doi = {10.1038/s41467-018-07759-w},
   issn = {2041-1723},
   journal = {Nature Communications},
   pages = {5334},
   publisher = {Springer US},
   title = {Stretched and compressed exponentials in the relaxation dynamics of a metallic glass-forming melt},
   volume = {9},
   url = {http://dx.doi.org/10.1038/s41467-018-07759-w},
   year = {2018},
}
@article{Wang2017,
   abstract = {The accumulation and extrusion of Ca2+ in the pre- and postsynaptic compartments play a critical role in initiating plastic changes in biological synapses. To emulate this fundamental process in electronic devices, we developed diffusive Ag-in-oxide memristors with a temporal response during and after stimulation similar to that of the synaptic Ca2+ dynamics. In situ high-resolution transmission electron microscopy and nanoparticle dynamics simulations both demonstrate that Ag atoms disperse under electrical bias and regroup spontaneously under zero bias because of interfacial energy minimization, closely resembling synaptic influx and extrusion of Ca2+, respectively. The diffusive memristor and its dynamics enable a direct emulation of both short- and long-term plasticity of biological synapses, representing an advance in hardware implementation of neuromorphic functionalities.},
   author = {Zhongrui Wang and Saumil Joshi and Sergey E Savel’ev and Hao Jiang and Rivu Midya and Peng Lin and Miao Hu and Ning Ge and John Paul Strachan and Zhiyong Li and Qing Wu and Mark Barnell and Geng-Lin Li and Huolin L Xin and R Stanley Williams and Qiangfei Xia and J Joshua Yang},
   doi = {10.1038/nmat4756},
   issn = {1476-4660},
   issue = {1},
   journal = {Nature Materials},
   pages = {101-108},
   title = {Memristors with diffusive dynamics as synaptic emulators for neuromorphic computing},
   volume = {16},
   url = {https://doi.org/10.1038/nmat4756},
   year = {2017},
}
@article{Appeltant2011,
   abstract = {Novel methods for information processing are highly desired in our information-driven society. Inspired by the brain's ability to process information, the recently introduced paradigm known as 'reservoir computing' shows that complex networks can efficiently perform computation. Here we introduce a novel architecture that reduces the usually required large number of elements to a single nonlinear node with delayed feedback. Through an electronic implementation, we experimentally and numerically demonstrate excellent performance in a speech recognition benchmark. Complementary numerical studies also show excellent performance for a time series prediction benchmark. These results prove that delay-dynamical systems, even in their simplest manifestation, can perform efficient information processing. This finding paves the way to feasible and resource-efficient technological implementations of reservoir computing.},
   author = {L Appeltant and M C Soriano and G Van der Sande and J Danckaert and S Massar and J Dambre and B Schrauwen and C R Mirasso and I Fischer},
   doi = {10.1038/ncomms1476},
   issn = {2041-1723},
   issue = {1},
   journal = {Nature Communications},
   pages = {468},
   title = {Information processing using a single dynamical node as complex system},
   volume = {2},
   url = {https://doi.org/10.1038/ncomms1476},
   year = {2011},
}
@article{,
   author = {Wojciech Becker, Sören and Ackermann, Marcel and Lapuschkin, Sebastian and Müller, Klaus-Robert and Samek},
   doi = {10.48550/ARXIV.1807.03418},
   journal = {arXiv},
   title = {Interpreting and Explaining Deep Neural Networks for Classification of Audio Signals},
   url = {https://arxiv.org/abs/1807.03418},
   year = {2018},
}
@article{Yoo2022,
   author = {Sangmin Yoo and Yongmo Park and Ziyu Wang and Yuting Wu and Saaketh Medepalli and Wesley Thio and Wei D Lu},
   doi = {10.1002/aisy.202200179},
   issue = {11},
   journal = {Advanced Intelligent Systems},
   keywords = {RRAM,SNN,cortical column,neuromorphic computing,pyramidal neuron,second-order memristor,sensorimotor interaction},
   pages = {2200179},
   title = {Columnar Learning Networks for Multisensory Spatiotemporal Learning},
   volume = {4},
   year = {2022},
}
@article{Kumar2022,
   abstract = {Research on electronic devices and materials is currently driven by both the slowing down of transistor scaling and the exponential growth of computing needs, which make present digital computing increasingly capacity-limited and power-limited. A promising alternative approach consists in performing computing based on intrinsic device dynamics, such that each device functionally replaces elaborate digital circuits, leading to adaptive ‘complex computing’. Memristors are a class of devices that naturally embody higher-order dynamics through their internal electrophysical processes. In this Review, we discuss how novel material properties enable complex dynamics and define different orders of complexity in memristor devices and systems. These native complex dynamics at the device level enable new computing architectures, such as brain-inspired neuromorphic systems, which offer both high energy efficiency and high computing capacity.},
   author = {Suhas Kumar and Xinxin Wang and John Paul Strachan and Yuchao Yang and Wei D Lu},
   doi = {10.1038/s41578-022-00434-z},
   issn = {2058-8437},
   issue = {7},
   journal = {Nature Reviews Materials},
   pages = {575-591},
   title = {Dynamical memristors for higher-complexity neuromorphic computing},
   volume = {7},
   url = {https://doi.org/10.1038/s41578-022-00434-z},
   year = {2022},
}
@article{Caporale2008,
   abstract = {Spike timing?dependent plasticity (STDP) as a Hebbian synaptic learning rule has been demonstrated in various neural circuits over a wide spectrum of species, from insects to humans. The dependence of synaptic modification on the order of pre- and postsynaptic spiking within a critical window of tens of milliseconds has profound functional implications. Over the past decade, significant progress has been made in understanding the cellular mechanisms of STDP at both excitatory and inhibitory synapses and of the associated changes in neuronal excitability and synaptic integration. Beyond the basic asymmetric window, recent studies have also revealed several layers of complexity in STDP, including its dependence on dendritic location, the nonlinear integration of synaptic modification induced by complex spike trains, and the modulation of STDP by inhibitory and neuromodulatory inputs. Finally, the functional consequences of STDP have been examined directly in an increasing number of neural circuits in vivo.},
   author = {Natalia Caporale and Yang Dan},
   doi = {10.1146/annurev.neuro.31.060407.125639},
   issn = {0147-006X},
   issue = {1},
   journal = {Annual Review of Neuroscience},
   month = {6},
   note = {doi: 10.1146/annurev.neuro.31.060407.125639},
   pages = {25-46},
   publisher = {Annual Reviews},
   title = {Spike Timing–Dependent Plasticity: A Hebbian Learning Rule},
   volume = {31},
   url = {https://doi.org/10.1146/annurev.neuro.31.060407.125639},
   year = {2008},
}
@article{Single1998,
   abstract = {The mechanisms underlying visual motion detection can be studied simultaneously in different cell compartments in vivo by using calcium as a reporter of the spatiotemporal activity distribution in single motion-sensitive cells of the fly. As predicted by the Reichardt model, local dendritic calcium signals are found to indicate the direction and velocity of pattern motion but are corrupted by spatial pattern properties. The latter are canceled out by spatial integration, thus leading to a purely directional selective output signal in the axon. These findings attribute a specific computational task to the dendrites of visual interneurons and imply a functional interpretation of dendritic morphology.},
   author = {Sandra Single and Alexander Borst},
   doi = {10.1126/science.281.5384.1848},
   issue = {5384},
   journal = {Science},
   month = {9},
   note = {doi: 10.1126/science.281.5384.1848},
   pages = {1848-1850},
   publisher = {American Association for the Advancement of Science},
   title = {Dendritic Integration and Its Role in Computing Image Velocity},
   volume = {281},
   url = {https://doi.org/10.1126/science.281.5384.1848},
   year = {1998},
}
@article{,
   abstract = {Coincidence-detector neurons in the auditory brainstem of mammals and birds use interaural time differences to localize sounds1,2. Each neuron receives many narrow-band inputs from both ears and compares the time of arrival of the inputs with an accuracy of 10–100 µs (3–6). Neurons that receive low-frequency auditory inputs (up to about 2 kHz) have bipolar dendrites, and each dendrite receives inputs from only one ear7,8. Using a simple model that mimics the essence of the known electrophysiology and geometry of these cells, we show here that dendrites improve the coincidence-detection properties of the cells. The biophysical mechanism for this improvement is based on the nonlinear summation of excitatory inputs in each of the dendrites and the use of each dendrite as a current sink for inputs to the other dendrite. This is a rare case in which the contribution of dendrites to the known computation of a neuron may be understood. Our results show that, in these neurons, the cell morphology and the spatial distribution of the inputs enrich the computational power of these neurons beyond that expected from ‘point neurons’ (model neurons lacking dendrites).},
   author = {Hagai Agmon-Snir and Catherine E Carr and John Rinzel},
   doi = {10.1038/30505},
   issn = {1476-4687},
   issue = {6682},
   journal = {Nature},
   pages = {268-272},
   title = {The role of dendrites in auditory coincidence detection},
   volume = {393},
   url = {https://doi.org/10.1038/30505},
   year = {1998},
}
@article{Rall1967,
   author = {W Rall and R E Burke and T G Smith and P G Nelson and K Frank},
   doi = {10.1152/jn.1967.30.5.1169},
   issn = {0022-3077},
   issue = {5},
   journal = {Journal of Neurophysiology},
   month = {9},
   note = {doi: 10.1152/jn.1967.30.5.1169},
   pages = {1169-1193},
   publisher = {American Physiological Society},
   title = {Dendritic location of synapses and possible mechanisms for the monosynaptic EPSP in motoneurons.},
   volume = {30},
   url = {https://doi.org/10.1152/jn.1967.30.5.1169},
   year = {1967},
}
@book_section{Rall1964,
   author = {Wilfrid Rall},
   journal = {Neural theory and modeling},
   pages = {73-97},
   title = {Theoretical significance of dendritic trees for neuronal input-output relations},
   year = {1964},
}
@article{Najem2018,
   author = {Joseph S.S. Najem and Graham J. Taylor and Ryan J. Weiss and Md Sakib Hasan and Garrett Rose and Catherine D. Schuman and Alex Belianinov and C. Patrick Collier and Stephen A. Sarles},
   doi = {10.1021/acsnano.8b01282},
   issn = {1936-0851},
   issue = {5},
   journal = {ACS Nano},
   month = {5},
   note = {doi: 10.1021/acsnano.8b01282},
   pages = {4702-4711},
   publisher = {American Chemical Society},
   title = {Memristive Ion Channel-Doped Biomembranes as Synaptic Mimics},
   volume = {12},
   url = {https://doi.org/10.1021/acsnano.8b01282},
   year = {2018},
}
@article{Yang2013,
   abstract = {This Review looks at recent progress in the development and understanding of memristive devices, and examines the performance requirements for computing with such devices.},
   author = {J Joshua Yang and Dmitri B Strukov and Duncan R Stewart},
   doi = {10.1038/nnano.2012.240},
   issn = {1748-3395},
   issue = {1},
   journal = {Nature Nanotechnology},
   pages = {13-24},
   title = {Memristive devices for computing},
   volume = {8},
   url = {https://doi.org/10.1038/nnano.2012.240},
   year = {2013},
}
@article{Strukov2008,
   abstract = {Basic electronics textbooks list three fundamental passive circuit elements: resistors, capacitors and inductors. But nearly forty years ago, Leon Chua predicted the existence of a fourth, the memristor — in effect a nonlinear resistor with memory. A paper from the Hewlett-Packard research lab now reports that memristance arises naturally in nanoscale systems where solid-state electronic and ionic transport are coupled under an external bias voltage. This finding can help explain many examples of apparently anomalous hysteretic current–voltage behaviour observed in electronic devices during the past 50 years. Memristors may have a significant impact on future electronic circuits by dramatically increasing the functional density over that achieved by transistors.},
   author = {Dmitri B Strukov and Gregory S Snider and Duncan R Stewart and R Stanley Williams},
   doi = {10.1038/nature06932},
   issn = {1476-4687},
   issue = {7191},
   journal = {Nature},
   pages = {80-83},
   title = {The missing memristor found},
   volume = {453},
   url = {https://doi.org/10.1038/nature06932},
   year = {2008},
}
@article{Wang2017,
   abstract = {The accumulation and extrusion of Ca2+ in the pre- and postsynaptic compartments play a critical role in initiating plastic changes in biological synapses. To emulate this fundamental process in electronic devices, we developed diffusive Ag-in-oxide memristors with a temporal response during and after stimulation similar to that of the synaptic Ca2+ dynamics. In situ high-resolution transmission electron microscopy and nanoparticle dynamics simulations both demonstrate that Ag atoms disperse under electrical bias and regroup spontaneously under zero bias because of interfacial energy minimization, closely resembling synaptic influx and extrusion of Ca2+, respectively. The diffusive memristor and its dynamics enable a direct emulation of both short- and long-term plasticity of biological synapses, representing an advance in hardware implementation of neuromorphic functionalities.},
   author = {Zhongrui Wang and Saumil Joshi and Sergey E Savel’ev and Hao Jiang and Rivu Midya and Peng Lin and Miao Hu and Ning Ge and John Paul Strachan and Zhiyong Li and Qing Wu and Mark Barnell and Geng-Lin Li and Huolin L Xin and R Stanley Williams and Qiangfei Xia and J Joshua Yang},
   doi = {10.1038/nmat4756},
   issn = {1476-4660},
   issue = {1},
   journal = {Nature Materials},
   pages = {101-108},
   title = {Memristors with diffusive dynamics as synaptic emulators for neuromorphic computing},
   volume = {16},
   url = {https://doi.org/10.1038/nmat4756},
   year = {2017},
}
@article{Ahn2021,
   abstract = {Abstract Memristors have emerged as transformative devices to enable neuromorphic and in-memory computing, where success requires the identification and development of materials that can overcome challenges in retention and device variability. Here, high-entropy oxide composed of Zr, Hf, Nb, Ta, Mo, and W oxides is first demonstrated as a switching material for valence change memory. This multielement oxide material provides uniform distribution and higher concentration of oxygen vacancies, limiting the stochastic behavior in resistive switching. (Zr, Hf, Nb, Ta, Mo, W) high-entropy-oxide-based memristors manifest the ?cocktail effect,? exhibiting comparable retention with HfO2- or Ta2O5-based memristors while also demonstrating the gradual conductance modulation observed in WO3-based memristors. The electrical characterization of these high-entropy-oxide-based memristors demonstrates forming-free operation, low device and cycle variability, gradual conductance modulation, 6-bit operation, and long retention which are promising for neuromorphic applications.},
   author = {Minhyung Ahn and Yongmo Park and Seung Hwan Lee and Sieun Chae and Jihang Lee and John T Heron and Emmanouil Kioupakis and Wei D Lu and Jamie D Phillips},
   doi = {https://doi.org/10.1002/aelm.202001258},
   issn = {2199-160X},
   issue = {5},
   journal = {Advanced Electronic Materials},
   keywords = {first-principles calculations,high-entropy oxides,memristors,neuromorphic computing,pulsed laser deposition},
   month = {5},
   note = {https://doi.org/10.1002/aelm.202001258},
   pages = {2001258},
   publisher = {John Wiley & Sons, Ltd},
   title = {Memristors Based on (Zr, Hf, Nb, Ta, Mo, W) High-Entropy Oxides},
   volume = {7},
   url = {https://doi.org/10.1002/aelm.202001258},
   year = {2021},
}
@article{Hu2018,
   abstract = {Abstract Using memristor crossbar arrays to accelerate computations is a promising approach to efficiently implement algorithms in deep neural networks. Early demonstrations, however, are limited to simulations or small-scale problems primarily due to materials and device challenges that limit the size of the memristor crossbar arrays that can be reliably programmed to stable and analog values, which is the focus of the current work. High-precision analog tuning and control of memristor cells across a 128 ? 64 array is demonstrated, and the resulting vector matrix multiplication (VMM) computing precision is evaluated. Single-layer neural network inference is performed in these arrays, and the performance compared to a digital approach is assessed. Memristor computing system used here reaches a VMM accuracy equivalent of 6 bits, and an 89.9% recognition accuracy is achieved for the 10k MNIST handwritten digit test set. Forecasts show that with integrated (on chip) and scaled memristors, a computational efficiency greater than 100 trillion operations per second per Watt is possible.},
   author = {Miao Hu and Catherine E Graves and Can Li and Yunning Li and Ning Ge and Eric Montgomery and Noraica Davila and Hao Jiang and R Stanley Williams and J Joshua Yang and Qiangfei Xia and John Paul Strachan},
   doi = {https://doi.org/10.1002/adma.201705914},
   issn = {0935-9648},
   issue = {9},
   journal = {Advanced Materials},
   keywords = {crossbar arrays,memristor,metal oxide,neuromorphic computing},
   month = {3},
   note = {https://doi.org/10.1002/adma.201705914},
   pages = {1705914},
   publisher = {John Wiley & Sons, Ltd},
   title = {Memristor-Based Analog Computation and Neural Network Classification with a Dot Product Engine},
   volume = {30},
   url = {https://doi.org/10.1002/adma.201705914},
   year = {2018},
}
@article{Kim2014,
   author = {Sungho Kim and ShinHyun Choi and Wei Lu},
   doi = {10.1021/nn405827t},
   issn = {1936-0851},
   issue = {3},
   journal = {ACS Nano},
   month = {3},
   note = {doi: 10.1021/nn405827t},
   pages = {2369-2376},
   publisher = {American Chemical Society},
   title = {Comprehensive Physical Model of Dynamic Resistive Switching in an Oxide Memristor},
   volume = {8},
   url = {https://doi.org/10.1021/nn405827t},
   year = {2014},
}
@article{Zidan2018,
   abstract = {A memristor is a resistive device with an inherent memory. The theoretical concept of a memristor was connected to physically measured devices in 2008 and since then there has been rapid progress in the development of such devices, leading to a series of recent demonstrations of memristor-based neuromorphic hardware systems. Here, we evaluate the state of the art in memristor-based electronics and explore where the future of the field lies. We highlight three areas of potential technological impact: on-chip memory and storage, biologically inspired computing and general-purpose in-memory computing. We analyse the challenges, and possible solutions, associated with scaling the systems up for practical applications, and consider the benefits of scaling the devices down in terms of geometry and also in terms of obtaining fundamental control of the atomic-level dynamics. Finally, we discuss the ways we believe biology will continue to provide guiding principles for device innovation and system optimization in the field.},
   author = {Mohammed A Zidan and John Paul Strachan and Wei D Lu},
   doi = {10.1038/s41928-017-0006-8},
   issn = {2520-1131},
   issue = {1},
   journal = {Nature Electronics},
   pages = {22-29},
   title = {The future of electronics based on memristive systems},
   volume = {1},
   url = {https://doi.org/10.1038/s41928-017-0006-8},
   year = {2018},
}
@article{Choi2017,
   author = {Shinhyun Choi and Jong Hoon Shin and Jihang Lee and Patrick Sheridan and Wei D Lu},
   doi = {10.1021/acs.nanolett.7b00552},
   issn = {1530-6984},
   issue = {5},
   journal = {Nano Letters},
   month = {5},
   note = {doi: 10.1021/acs.nanolett.7b00552},
   pages = {3113-3118},
   publisher = {American Chemical Society},
   title = {Experimental Demonstration of Feature Extraction and Dimensionality Reduction Using Memristor Networks},
   volume = {17},
   url = {https://doi.org/10.1021/acs.nanolett.7b00552},
   year = {2017},
}
@article{Jeong2018,
   author = {YeonJoo Jeong and Jihang Lee and John Moon and Jong Hoon Shin and Wei D Lu},
   doi = {10.1021/acs.nanolett.8b01526},
   issn = {1530-6984},
   issue = {7},
   journal = {Nano Letters},
   month = {7},
   note = {doi: 10.1021/acs.nanolett.8b01526},
   pages = {4447-4453},
   publisher = {American Chemical Society},
   title = {K-means Data Clustering with Memristor Networks},
   volume = {18},
   url = {https://doi.org/10.1021/acs.nanolett.8b01526},
   year = {2018},
}
@article{Jo2009,
   author = {Sung Hyun Jo and Kuk-Hwan Kim and Wei Lu},
   doi = {10.1021/nl8037689},
   issn = {1530-6984},
   issue = {2},
   journal = {Nano Letters},
   month = {2},
   note = {doi: 10.1021/nl8037689},
   pages = {870-874},
   publisher = {American Chemical Society},
   title = {High-Density Crossbar Arrays Based on a Si Memristive System},
   volume = {9},
   url = {https://doi.org/10.1021/nl8037689},
   year = {2009},
}
@article{Jo2008,
   author = {Sung Hyun Jo and Wei Lu},
   doi = {10.1021/nl073225h},
   issn = {1530-6984},
   issue = {2},
   journal = {Nano Letters},
   month = {2},
   note = {doi: 10.1021/nl073225h},
   pages = {392-397},
   publisher = {American Chemical Society},
   title = {CMOS Compatible Nanoscale Nonvolatile Resistance Switching Memory},
   volume = {8},
   url = {https://doi.org/10.1021/nl073225h},
   year = {2008},
}
@article{Kim2014,
   author = {Sungho Kim and ShinHyun Choi and Jihang Lee and Wei D Lu},
   doi = {10.1021/nn503464q},
   issn = {1936-0851},
   issue = {10},
   journal = {ACS Nano},
   month = {10},
   note = {doi: 10.1021/nn503464q},
   pages = {10262-10269},
   publisher = {American Chemical Society},
   title = {Tuning Resistive Switching Characteristics of Tantalum Oxide Memristors through Si Doping},
   volume = {8},
   url = {https://doi.org/10.1021/nn503464q},
   year = {2014},
}
@article{Gaba2014,
   author = {S Gaba and F Cai and J Zhou and W D Lu},
   doi = {10.1109/LED.2014.2363618},
   issn = {1558-0563},
   issue = {12},
   journal = {IEEE Electron Device Letters},
   pages = {1239-1241},
   title = {Ultralow Sub-1-nA Operating Current Resistive Memory With Intrinsic Non-Linear Characteristics},
   volume = {35},
   year = {2014},
}
@article{Lee2016,
   author = {Jihang Lee and Chao Du and Kai Sun and Emmanouil Kioupakis and Wei D Lu},
   doi = {10.1021/acsnano.5b07943},
   issn = {1936-0851},
   issue = {3},
   journal = {ACS Nano},
   month = {3},
   note = {doi: 10.1021/acsnano.5b07943},
   pages = {3571-3579},
   publisher = {American Chemical Society},
   title = {Tuning Ionic Transport in Memristive Devices by Graphene with Engineered Nanopores},
   volume = {10},
   url = {https://doi.org/10.1021/acsnano.5b07943},
   year = {2016},
}
@article{Chang2011-transition,
   author = {Ting Chang and Sung-Hyun Jo and Wei Lu},
   doi = {10.1021/nn202983n},
   issn = {1936-0851},
   issue = {9},
   journal = {ACS Nano},
   month = {9},
   note = {doi: 10.1021/nn202983n},
   pages = {7669-7676},
   publisher = {American Chemical Society},
   title = {Short-Term Memory to Long-Term Memory Transition in a Nanoscale Memristor},
   volume = {5},
   url = {https://doi.org/10.1021/nn202983n},
   year = {2011},
}
@article{Jeong2015,
   author = {YeonJoo Jeong and Sungho Kim and Wei D Lu},
   doi = {10.1063/1.4934818},
   issn = {0003-6951},
   issue = {17},
   journal = {Applied Physics Letters},
   month = {10},
   note = {doi: 10.1063/1.4934818},
   pages = {173105},
   publisher = {American Institute of Physics},
   title = {Utilizing multiple state variables to improve the dynamic range of analog switching in a memristor},
   volume = {107},
   url = {https://doi.org/10.1063/1.4934818},
   year = {2015},
}
@article{Yang2012,
   abstract = {Nanoscale resistive switching devices, sometimes termed memristors, have recently generated significant interest for memory, logic and neuromorphic applications. Resistive switching effects in dielectric-based devices are normally assumed to be caused by conducting filament formation across the electrodes, but the nature of the filaments and their growth dynamics remain controversial. Here we report direct transmission electron microscopy imaging, and structural and compositional analysis of the nanoscale conducting filaments. Through systematic ex-situ and in-situ transmission electron microscopy studies on devices under different programming conditions, we found that the filament growth can be dominated by cation transport in the dielectric film. Unexpectedly, two different growth modes were observed for the first time in materials with different microstructures. Regardless of the growth direction, the narrowest region of the filament was found to be near the dielectric/inert-electrode interface in these devices, suggesting that this region deserves particular attention for continued device optimization.},
   author = {Yuchao Yang and Peng Gao and Siddharth Gaba and Ting Chang and Xiaoqing Pan and Wei Lu},
   doi = {10.1038/ncomms1737},
   issn = {2041-1723},
   issue = {1},
   journal = {Nature Communications},
   pages = {732},
   title = {Observation of conducting filament growth in nanoscale resistive memories},
   volume = {3},
   url = {https://doi.org/10.1038/ncomms1737},
   year = {2012},
}
@article{Yang2014,
   abstract = {Nanoscale metal inclusions in or on solid-state dielectrics are an integral part of modern electrocatalysis, optoelectronics, capacitors, metamaterials and memory devices. The properties of these composite systems strongly depend on the size, dispersion of the inclusions and their chemical stability, and are usually considered constant. Here we demonstrate that nanoscale inclusions (for example, clusters) in dielectrics dynamically change their shape, size and position upon applied electric field. Through systematic in situ transmission electron microscopy studies, we show that fundamental electrochemical processes can lead to universally observed nucleation and growth of metal clusters, even for inert metals like platinum. The clusters exhibit diverse dynamic behaviours governed by kinetic factors including ion mobility and redox rates, leading to different filament growth modes and structures in memristive devices. These findings reveal the microscopic origin behind resistive switching, and also provide general guidance for the design of novel devices involving electronics and ionics.},
   author = {Yuchao Yang and Peng Gao and Linze Li and Xiaoqing Pan and Stefan Tappertzhofen and ShinHyun Choi and Rainer Waser and Ilia Valov and Wei D Lu},
   doi = {10.1038/ncomms5232},
   issn = {2041-1723},
   issue = {1},
   journal = {Nature Communications},
   pages = {4232},
   title = {Electrochemical dynamics of nanoscale metallic inclusions in dielectrics},
   volume = {5},
   url = {https://doi.org/10.1038/ncomms5232},
   year = {2014},
}
@inproceedings{Chen2015,
   author = {B Chen and F Cai and J Zhou and W Ma and P Sheridan and W D Lu},
   doi = {10.1109/IEDM.2015.7409720},
   isbn = {2156-017X},
   journal = {2015 IEEE International Electron Devices Meeting (IEDM)},
   pages = {17.5.1-17.5.4},
   title = {Efficient in-memory computing architecture based on crossbar arrays},
   year = {2015},
}
@article{Sheridan2016,
   author = {P M Sheridan and C Du and W D Lu},
   doi = {10.1109/TNNLS.2015.2482220},
   issn = {2162-2388},
   issue = {11},
   journal = {IEEE Transactions on Neural Networks and Learning Systems},
   pages = {2327-2336},
   title = {Feature Extraction Using Memristor Networks},
   volume = {27},
   year = {2016},
}
@article{Zhu2020,
   abstract = {The ability to efficiently analyze the activities of biological neural networks can significantly promote our understanding of neural communications and functionalities. However, conventional neural signal analysis approaches need to transmit and store large amounts of raw recording data, followed by extensive processing offline, posing significant challenges to the hardware and preventing real-time analysis and feedback. Here, we demonstrate a memristor-based reservoir computing (RC) system that can potentially analyze neural signals in real-time. We show that the perovskite halide-based memristor can be directly driven by emulated neural spikes, where the memristor state reflects temporal features in the neural spike train. The RC system is successfully used to recognize neural firing patterns, monitor the transition of the firing patterns, and identify neural synchronization states among different neurons. Advanced neuroelectronic systems with such memristor networks can enable efficient neural signal analysis with high spatiotemporal precision, and possibly closed-loop feedback control.},
   author = {Xiaojian Zhu and Qiwen Wang and Wei D Lu},
   doi = {10.1038/s41467-020-16261-1},
   issn = {2041-1723},
   issue = {1},
   journal = {Nature Communications},
   pages = {2439},
   title = {Memristor networks for real-time neural activity analysis},
   volume = {11},
   url = {https://doi.org/10.1038/s41467-020-16261-1},
   year = {2020},
}
@article{Zhu2019-MoS2,
   abstract = {Coupled ionic–electronic effects present intriguing opportunities for device and circuit development. In particular, layered two-dimensional materials such as MoS2 offer highly anisotropic ionic transport properties, facilitating controlled ion migration and efficient ionic coupling among devices. Here, we report reversible modulation of MoS2 films that is consistent with local 2H–1T′ phase transitions by controlling the migration of Li+ ions with an electric field, where an increase/decrease in the local Li+ ion concentration leads to the transition between the 2H (semiconductor) and 1T′ (metal) phases. The resulting devices show excellent memristive behaviour and can be directly coupled with each other through local ionic exchange, naturally leading to synaptic competition and synaptic cooperation effects observed in biology. These results demonstrate the potential of direct modulation of two-dimensional materials through field-driven ionic processes, and can lead to future electronic and energy devices based on coupled ionic–electronic effects and biorealistic implementation of artificial neural networks.},
   author = {Xiaojian Zhu and Da Li and Xiaogan Liang and Wei D Lu},
   doi = {10.1038/s41563-018-0248-5},
   issn = {1476-4660},
   issue = {2},
   journal = {Nature Materials},
   pages = {141-148},
   title = {Ionic modulation and ionic coupling effects in MoS2 devices for neuromorphic computing},
   volume = {18},
   url = {https://doi.org/10.1038/s41563-018-0248-5},
   year = {2019},
}
@article{Zhu2019-AEM,
   abstract = {Abstract Advances in the understanding of nanoscale ionic processes in solid-state thin films have led to the rapid development of devices based on coupled ionic?electronic effects. For example, ion-driven resistive-switching (RS) devices have been extensively studied for future memory applications due to their excellent performance in terms of switching speed, endurance, retention, and scalability. Recent studies further suggest that RS devices are more than just resistors with tunable resistance; instead, they exhibit rich and complex internal ionic dynamics that equip them with native information-processing capabilities, particularly in the temporal domain. RS effects induced by the migration of different types of ions, often driven by an electric field, are discussed. It is shown that, by taking advantage of the different state variables controlled by the ionic processes, important synaptic functions can be faithfully implemented in solid-state devices and networks. Recent efforts on improving the controllability of ionic processes to optimize device performance are also discussed, along with new opportunities for material design and engineering enabled by the ability to control ionic processes at the atomic scale.},
   author = {Xiaojian Zhu and Seung Hwan Lee and Wei D Lu},
   doi = {https://doi.org/10.1002/aelm.201900184},
   issn = {2199-160X},
   issue = {9},
   journal = {Advanced Electronic Materials},
   keywords = {ionic processes,nanoionics,neuromorphic computing,reconfigurable nanostructures,resistive-switching effect},
   month = {9},
   note = {https://doi.org/10.1002/aelm.201900184},
   pages = {1900184},
   publisher = {John Wiley & Sons, Ltd},
   title = {Nanoionic Resistive-Switching Devices},
   volume = {5},
   url = {https://doi.org/10.1002/aelm.201900184},
   year = {2019},
}
@article{Shin2018,
   author = {J H Shin and Q Wang and W D Lu},
   doi = {10.1109/LED.2018.2868459},
   issn = {1558-0563},
   issue = {10},
   journal = {IEEE Electron Device Letters},
   pages = {1512-1515},
   title = {Self-Limited and Forming-Free CBRAM Device With Double Al2O3 ALD Layers},
   volume = {39},
   year = {2018},
}
@article{Zhu2018,
   author = {Xiaojian Zhu and Wei D Lu},
   doi = {10.1021/acsnano.7b07317},
   issn = {1936-0851},
   issue = {2},
   journal = {ACS Nano},
   month = {2},
   note = {doi: 10.1021/acsnano.7b07317},
   pages = {1242-1249},
   publisher = {American Chemical Society},
   title = {Optogenetics-Inspired Tunable Synaptic Functions in Memristors},
   volume = {12},
   url = {https://doi.org/10.1021/acsnano.7b07317},
   year = {2018},
}
@article{Sheridan2017,
   abstract = {Sparse representation of information provides a powerful means to perform feature extraction on high-dimensional data and is of broad interest for applications in signal processing, computer vision, object recognition and neurobiology. Sparse coding is also believed to be a key mechanism by which biological neural systems can efficiently process a large amount of complex sensory data while consuming very little power. Here, we report the experimental implementation of sparse coding algorithms in a bio-inspired approach using a 32 × 32 crossbar array of analog memristors. This network enables efficient implementation of pattern matching and lateral neuron inhibition and allows input data to be sparsely encoded using neuron activities and stored dictionary elements. Different dictionary sets can be trained and stored in the same system, depending on the nature of the input signals. Using the sparse coding algorithm, we also perform natural image processing based on a learned dictionary.},
   author = {Patrick M Sheridan and Fuxi Cai and Chao Du and Wen Ma and Zhengya Zhang and Wei D Lu},
   doi = {10.1038/nnano.2017.83},
   issn = {1748-3395},
   issue = {8},
   journal = {Nature Nanotechnology},
   pages = {784-789},
   title = {Sparse coding with memristor networks},
   volume = {12},
   url = {https://doi.org/10.1038/nnano.2017.83},
   year = {2017},
}
@article{Sheridan2017,
   abstract = {Sparse representation of information provides a powerful means to perform feature extraction on high-dimensional data and is of broad interest for applications in signal processing, computer vision, object recognition and neurobiology. Sparse coding is also believed to be a key mechanism by which biological neural systems can efficiently process a large amount of complex sensory data while consuming very little power. Here, we report the experimental implementation of sparse coding algorithms in a bio-inspired approach using a 32 × 32 crossbar array of analog memristors. This network enables efficient implementation of pattern matching and lateral neuron inhibition and allows input data to be sparsely encoded using neuron activities and stored dictionary elements. Different dictionary sets can be trained and stored in the same system, depending on the nature of the input signals. Using the sparse coding algorithm, we also perform natural image processing based on a learned dictionary.},
   author = {Patrick M Sheridan and Fuxi Cai and Chao Du and Wen Ma and Zhengya Zhang and Wei D Lu},
   doi = {10.1038/nnano.2017.83},
   issn = {1748-3395},
   issue = {8},
   journal = {Nature Nanotechnology},
   pages = {784-789},
   title = {Sparse coding with memristor networks},
   volume = {12},
   url = {https://doi.org/10.1038/nnano.2017.83},
   year = {2017},
}
@inproceedings{Sironi2018,
   abstract = {Event-based cameras have recently drawn the attention of the Computer Vision community thanks to their advantages in terms of high temporal resolution, low power consumption and high dynamic range, compared to traditional frame-based cameras. These properties make event-based cameras an ideal choice for autonomous vehicles, robot navigation or UAV vision, among others. However, the accuracy of event-based object classification algorithms, which is of crucial importance for any reliable system working in real-world conditions, is still far behind their frame-based counterparts. Two main reasons for this performance gap are: 1. The lack of effective low-level representations and architectures for event-based object classification and 2. The absence of large real-world event-based datasets. In this paper we address both problems. First, we introduce a novel event-based feature representation together with a new machine learning architecture. Compared to previous approaches, we use local memory units to efficiently leverage past temporal information and build a robust event-based representation. Second, we release the first large real-world event-based dataset for object classification. We compare our method to the state-of-the-art with extensive experiments, showing better classification performance and real-time computation.},
   author = {Amos Sironi and Manuele Brambilla and Nicolas Bourdis and Xavier Lagorce and Ryad Benosman},
   journal = {Computer Vision and Pattern Recognition (CVPR)},
   title = {{HATS}: Histograms of Averaged Time Surfaces for Robust Event-based Object Classification},
   year = {2018},
}
@article{Lagorce2017,
   abstract = {This paper describes novel event-based spatio-temporal features called time-surfaces and how they can be used to create a hierarchical event-based pattern recognition architecture. Unlike existing hierarchical architectures for pattern recognition, the presented model relies on a time oriented approach to extract spatio-temporal features from the asynchronously acquired dynamics of a visual scene. These dynamics are acquired using biologically inspired frameless asynchronous event-driven vision sensors. Similarly to cortical structures, subsequent layers in our hierarchy extract increasingly abstract features using increasingly large spatio-temporal windows. The central concept is to use the rich temporal information provided by events to create contexts in the form of time-surfaces which represent the recent temporal activity within a local spatial neighborhood. We demonstrate that this concept can robustly be used at all stages of an event-based hierarchical model. First layer feature units operate on groups of pixels, while subsequent layer feature units operate on the output of lower level feature units. We report results on a previously published 36 class character recognition task and a four class canonical dynamic card pip task, achieving near 100 percent accuracy on each. We introduce a new seven class moving face recognition task, achieving 79 percent accuracy.},
   author = {Xavier Lagorce and Garrick Orchard and Francesco Galluppi and Bertram E. Shi and Ryad B. Benosman},
   doi = {10.1109/TPAMI.2016.2574707},
   issn = {01628828},
   issue = {7},
   journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
   keywords = {Neuromorphic sensing,event-based vision,feature extraction},
   month = {7},
   pages = {1346-1359},
   pmid = {27411216},
   publisher = {IEEE Computer Society},
   title = {{HOTS}: A Hierarchy of Event-Based Time-Surfaces for Pattern Recognition},
   volume = {39},
   year = {2017},
}
@inproceedings{Li2021,
   author = {Yuhang Li and Yufei Guo and Shanghang Zhang and Shikuang Deng and Yongqing Hai and Shi Gu},
   editor = {M Ranzato and A Beygelzimer and Y Dauphin and P S Liang and J Wortman Vaughan},
   journal = {Advances in Neural Information Processing Systems},
   pages = {23426-23439},
   publisher = {Curran Associates, Inc.},
   title = {Differentiable Spike: Rethinking Gradient-Descent for Training Spiking Neural Networks},
   volume = {34},
   url = {https://proceedings.neurips.cc/paper/2021/file/c4ca4238a0b923820dcc509a6f75849b-Paper.pdf},
   year = {2021},
}
@inproceedings{Li2021,
   abstract = {Spiking neural networks (SNNs) have emerged as a biology-inspired method mimicking the spiking nature of brain neurons. This biomimicry derives SNNs' energy efficiency of inference on neuromorphic hardware. However, it also causes an intrinsic disadvantage in training high-performing SNNs from scratch since the discrete spike prohibits the gradient calculation. To overcome this issue, the surrogate gradient (SG) approach has been proposed as a continuous relaxation. Yet the heuristic choice of SG leaves it vacant how the SG benefits the SNN training. In this work, we first theoretically study the gradient descent problem in SNN training and introduce finite difference gradient to quantitatively analyze the training behavior of SNN. Based on the introduced finite difference gradient, we propose a new family of Differentiable Spike (Dspike) functions that can adaptively evolve during training to find the optimal shape and smoothness for gradient estimation. Extensive experiments over several popular network structures show that training SNN with Dspike consistently outperforms the state-of-the-art training methods. For example, on the CIFAR10-DVS classification task, we can train a spiking ResNet-18 and achieve 75.4% top-1 accuracy with 10 time steps.},
   author = {Yuhang Li and Yufei Guo and Shanghang Zhang and Shikuang Deng and Yongqing Hai and Shi Gu},
   journal = {Neural Information Processing Systems (NeurIPS)},
   title = {Differentiable Spike: Rethinking Gradient-Descent for Training Spiking Neural Networks},
   year = {2021},
}
@inproceedings{Meng2022,
   abstract = {Spiking Neural Network (SNN) is a promising energy-efficient AI model when implemented on neuromorphic hardware. However, it is a challenge to efficiently train SNNs due to their non-differentiability. Most existing methods either suffer from high latency (i.e., long simulation time steps), or cannot achieve as high performance as Artificial Neural Networks (ANNs). In this paper, we propose the Differentiation on Spike Representation (DSR) method, which could achieve high performance that is competitive to ANNs yet with low latency. First, we encode the spike trains into spike representation using (weighted) firing rate coding. Based on the spike representation, we systematically derive that the spiking dynamics with common neural models can be represented as some sub-differentiable mapping. With this viewpoint, our proposed DSR method trains SNNs through gradients of the mapping and avoids the common non-differentiability problem in SNN training. Then we analyze the error when representing the specific mapping with the forward computation of the SNN. To reduce such error, we propose to train the spike threshold in each layer, and to introduce a new hyperparameter for the neural models. With these components, the DSR method can achieve state-of-the-art SNN performance with low latency on both static and neuromorphic datasets, including CIFAR-10, CIFAR-100, ImageNet, and DVS-CIFAR10.},
   author = {Qingyan Meng and Mingqing Xiao and Shen Yan and Yisen Wang and Zhouchen Lin and Zhi-Quan Luo},
   journal = {Computer Vision and Pattern Recognition (CVPR)},
   title = {Training High-Performance Low-Latency Spiking Neural Networks by Differentiation on Spike Representation},
   year = {2022},
}
@inproceedings{Meng2022,
   abstract = {A.1. Derivation for Eq. (14) In this subsection, we consider the LIF model defined by Eqs. (3a) to (3c) and (5), and derive Eq. (14) from Eq. (13) in the main content under mild assumptions. From the main content, we have derived thatâ thatˆthatâ[N ] ≈ ˆ I[N ] τ − V [N ] ∆t N n=1 λ N −n , (S1) as shown in Eq. (13). Since the LIF neuron is supposed to fire no or very few spikes whenˆI whenˆ whenˆI[N ] τ < 0 and fire almost always whenˆI whenˆ whenˆI[N ] τ > V th ∆t , we can separate the accumulated membrane potential V [ N ] into two parts: one part V − [N ] represents the "exceeded" membrane potential that does not contribute to spike firing, and the other part V + [N ] represents the "remaining" membrane potential. In detail, the "exceeded" membrane potential V − [N ] can be calculated as V − [N ] =      (∆t N n=1 λ N −n) ˆ I[N ] τ , ˆ I[N ] τ < 0, (∆t N n=1 λ N −n)(ˆ I[N ] τ − V th ∆t), ˆ I[N ] τ > V th ∆t , 0, otherwise. (S2) And the "remaining" membrane potential can be calculated as V + [N ] = V [N ] − V − [N ]. With the decomposition of membrane potential V [N ] and the fact that ∆t N n=1 λ N −n = τ when N → ∞ and ∆t → 0, we can further approximatê a[N ] from Eq. (S1) as lim N →∞â →∞ˆ→∞â[N ] ≈ lim N →∞ clampˆI clampˆ clampˆI[N ] τ − V + [N ] τ , 0, V th ∆t , (S3) if the limit of right hand side exists. * Corresponding author. Now we want to find the condition to ignore the term V + [N ] τ in Eq. (S3). In the case V − [N ] = 0, the magnitude of membrane potential |V (n)| would gradually increase with time. After introducing V − , the "remaining" membrane potential V + [N ] typically does not diverge over time. In fact, V + [N ] is typically bounded in [0, V th ] when N → ∞, except in the extreme case when the input current at different time steps distributes extremely unevenly. So we can just assume that V + [N ] ∈ [0, V th ]. Furthermore, if we set a significantly smaller threshold V th compared to the magnitude ofˆIofˆ ofˆI[N ], the term V + [N ] τ can be ignored. Then from Eq. (S3), we have lim N →∞â →∞ˆ→∞â[N ] ≈ clamp lim N →∞ˆI →∞ˆ →∞ˆI[N ] τ , 0, V th ∆t. (S4) That is ,we can approximatê a[N ] by clampˆI clampˆ clampˆI[N ] τ , 0, V th ∆t , with an approximation error bounded by V th τ when N → ∞. In summary, we derive Eq. (14) from Eq. (13) in the main content under following mild conditions: 1. The LIF neuron fires no or finite spikes as N → ∞ whenˆI whenˆ whenˆI[N ] τ < 0. And the LIF neuron does not fire only at a finite number of time steps as N → ∞ whenˆI whenˆ whenˆI[N ] τ > V th ∆t. 2. V + [N ] ∈ [0, V th ]. A.2. Derivation for Eq. (15) In this subsection, we consider the IF model defined by Eqs. (3a) to (3c) and (4) and derive Eq. (15) in the main content under mild assumptions.},
   author = {Qingyan Meng and Mingqing Xiao and Shen Yan and Yisen Wang and Zhouchen Lin and Zhi-Quan Luo},
   journal = {Computer Vision and Pattern Recognition},
   title = {Supplementary Materials for: Training High-Performance Low-Latency Spiking Neural Networks by Differentiation on Spike Representation A. Details about Spike Representation},
   year = {2022},
}
@article{Belkin2018,
   abstract = {Breakthroughs in machine learning are rapidly changing science and society, yet our fundamental understanding of this technology has lagged far behind. Indeed, one of the central tenets of the field, the bias-variance trade-off, appears to be at odds with the observed behavior of methods used in the modern machine learning practice. The bias-variance trade-off implies that a model should balance under-fitting and over-fitting: rich enough to express underlying structure in data, simple enough to avoid fitting spurious patterns. However, in the modern practice, very rich models such as neural networks are trained to exactly fit (i.e., interpolate) the data. Classically, such models would be considered over-fit, and yet they often obtain high accuracy on test data. This apparent contradiction has raised questions about the mathematical foundations of machine learning and their relevance to practitioners. In this paper, we reconcile the classical understanding and the modern practice within a unified performance curve. This "double descent" curve subsumes the textbook U-shaped bias-variance trade-off curve by showing how increasing model capacity beyond the point of interpolation results in improved performance. We provide evidence for the existence and ubiquity of double descent for a wide spectrum of models and datasets, and we posit a mechanism for its emergence. This connection between the performance and the structure of machine learning models delineates the limits of classical analyses, and has implications for both the theory and practice of machine learning.},
   author = {Mikhail Belkin and Daniel Hsu and Siyuan Ma and Soumik Mandal},
   doi = {10.1073/pnas.1903070116},
   month = {12},
   title = {Reconciling modern machine learning practice and the bias-variance trade-off},
   url = {http://arxiv.org/abs/1812.11118 http://dx.doi.org/10.1073/pnas.1903070116},
   year = {2018},
}
@article{Orchard2015,
   abstract = {Creating datasets for Neuromorphic Vision is a challenging task. A lack of available recordings from Neuromorphic Vision sensors means that data must typically be recorded specifically for dataset creation rather than collecting and labeling existing data. The task is further complicated by a desire to simultaneously provide traditional frame-based recordings to allow for direct comparison with traditional Computer Vision algorithms. Here we propose a method for converting existing Computer Vision static image datasets into Neuromorphic Vision datasets using an actuated pan-tilt camera platform. Moving the sensor rather than the scene or image is a more biologically realistic approach to sensing and eliminates timing artifacts introduced by monitor updates when simulating motion on a computer monitor. We present conversion of two popular image datasets (MNIST and Caltech101) which have played important roles in the development of Computer Vision, and we provide performance metrics on these datasets using spike-based recognition algorithms. This work contributes datasets for future use in the field, as well as results from spike-based algorithms against which future works can compare. Furthermore, by converting datasets already popular in Computer Vision, we enable more direct comparison with frame-based approaches.},
   author = {Garrick Orchard and Ajinkya Jayawant and Gregory K. Cohen and Nitish Thakor},
   doi = {10.3389/fnins.2015.00437},
   issn = {1662453X},
   issue = {NOV},
   journal = {Frontiers in Neuroscience},
   keywords = {Benchmarking,Computer vision,Datasets,Neuromorphic Vision,Sensory processing},
   publisher = {Frontiers Research Foundation},
   title = {Converting static image datasets to spiking neuromorphic datasets using saccades},
   volume = {9},
   year = {2015},
}
@article{Esser2016,
   abstract = {Deep networks are now able to achieve human-level performance on a broad spectrum of recognition tasks. Independently, neuromorphic computing has now demonstrated unprecedented energy-efficiency through a new chip architecture based on spiking neurons, low precision synapses, and a scalable communication network. Here, we demonstrate that neuromorphic computing, despite its novel architectural primitives, can implement deep convolution networks that (/) approach state-of-the-art classification accuracy across eight standard datasets encompassing vision and speech, (ii) perform inference while preserving the hardware's underlying energy-efficiency and high throughput, running on the aforementioned datasets at between 1,200 and 2,600 frames/s and using between 25 and 275 mW (effectively >6,000 frames/s per Watt), and (iii') can be specified and trained using backpropagation with the same ease-of-use as contemporary deep learning. This approach allows the algorithmic power of deep learning to be merged with the efficiency of neuromorphic processors, bringing the promise of embedded, intelligent, brain-inspired computing one step closer.},
   author = {Steven K. Esser and Paul A. Merolla and John V. Arthur and Andrew S. Cassidy and Rathinakumar Appuswamy and Alexander Andreopoulos and David J. Berg and Jeffrey L. McKinstry and Timothy Melano and Davis R. Barch and Carmelo Di Nolfo and Pallab Datta and Arnon Amir and Brian Taba and Myron D. Flickner and Dharmendra S. Modha},
   doi = {10.1073/pnas.1604850113},
   issn = {10916490},
   issue = {41},
   journal = {Proceedings of the National Academy of Sciences of the United States of America},
   keywords = {Convolutional network,Neural network,Neuromorphic,Truenorth},
   month = {10},
   pages = {11441-11446},
   publisher = {National Academy of Sciences},
   title = {Convolutional networks for fast, energy-efficient neuromorphic computing},
   volume = {113},
   year = {2016},
}
@article{Xing2020,
   abstract = {The combination of neuromorphic visual sensors and spiking neural network offers a high efficient bio-inspired solution to real-world applications. However, processing event- based sequences remains challenging because of the nature of their asynchronism and sparsity behavior. In this paper, a novel spiking convolutional recurrent neural network (SCRNN) architecture that takes advantage of both convolution operation and recurrent connectivity to maintain the spatial and temporal relations from event-based sequence data are presented. The use of recurrent architecture enables the network to have a sampling window with an arbitrary length, allowing the network to exploit temporal correlations between event collections. Rather than standard ANN to SNN conversion techniques, the network utilizes a supervised Spike Layer Error Reassignment (SLAYER) training mechanism that allows the network to adapt to neuromorphic (event-based) data directly. The network structure is validated on the DVS gesture dataset and achieves a 10 class gesture recognition accuracy of 96.59% and an 11 class gesture recognition accuracy of 90.28%.},
   author = {Yannan Xing and Gaetano Di Caterina and John Soraghan},
   doi = {10.3389/fnins.2020.590164},
   issn = {1662453X},
   journal = {Frontiers in Neuroscience},
   keywords = {DVS,event-based processing,gesture recognition,spiking neural network,video processing},
   month = {11},
   publisher = {Frontiers Media S.A.},
   title = {A New Spiking Convolutional Recurrent Neural Network ({SCRNN}) With Applications to Event-Based Hand Gesture Recognition},
   volume = {14},
   year = {2020},
}
@article{Zhu2022,
   abstract = {Spiking Neural Networks (SNNs) is a practical approach toward more data-efficient deep learning by simulating neurons leverage on temporal information. In this paper, we propose the Temporal-Channel Joint Attention (TCJA) architectural unit, an efficient SNN technique that depends on attention mechanisms, by effectively enforcing the relevance of spike sequence along both spatial and temporal dimensions. Our essential technical contribution lies on: 1) compressing the spike stream into an average matrix by employing the squeeze operation, then using two local attention mechanisms with an efficient 1-D convolution to establish temporal-wise and channel-wise relations for feature extraction in a flexible fashion. 2) utilizing the Cross Convolutional Fusion (CCF) layer for modeling inter-dependencies between temporal and channel scope, which breaks the independence of the two dimensions and realizes the interaction between features. By virtue of jointly exploring and recalibrating data stream, our method outperforms the state-of-the-art (SOTA) by up to 15.7% in terms of top-1 classification accuracy on all tested mainstream static and neuromorphic datasets, including Fashion-MNIST, CIFAR10-DVS, N-Caltech 101, and DVS128 Gesture.},
   author = {Rui-Jie Zhu and Qihang Zhao and Tianjing Zhang and Haoyu Deng and Yule Duan and Malu Zhang and Liang-Jian Deng},
   month = {6},
   title = {{TCJA-SNN}: Temporal-Channel Joint Attention for Spiking Neural Networks},
   url = {http://arxiv.org/abs/2206.10177},
   year = {2022},
}
@inproceedings{Yao2021,
   abstract = {How to effectively and efficiently deal with spatio-temporal event streams, where the events are generally sparse and non-uniform and have the microsecond temporal resolution, is of great value and has various real-life applications. Spiking neural network (SNN), as one of the brain-inspired event-triggered computing models, has the potential to extract effective spatio-temporal features from the event streams. However, when aggregating individual events into frames with a new higher temporal resolution, existing SNN models do not attach importance to that the serial frames have different signal-to-noise ratios since event streams are sparse and non-uniform. This situation interferes with the performance of existing SNNs. In this work, we propose a temporal-wise attention SNN (TA-SNN) model to learn frame-based representation for processing event streams. Concretely, we extend the attention concept to temporal-wise input to judge the significance of frames for the final decision at the training stage, and discard the irrelevant frames at the inference stage. We demonstrate that TA-SNN models improve the accuracy of event streams classification tasks. We also study the impact of multiple-scale temporal resolutions for frame-based representation. Our approach is tested on three different classification tasks: gesture recognition, image classification, and spoken digit recognition. We report the state-of-the-art results on these tasks, and get the essential improvement of accuracy (almost 19\%) for gesture recognition with only 60 ms.},
   author = {Man Yao and Huanhuan Gao and Guangshe Zhao and Dingheng Wang and Yihan Lin and Zhaoxu Yang and Guoqi Li},
   journal = {International Conference on Computer Vision (ICCV)},
   month = {7},
   title = {Temporal-wise Attention Spiking Neural Networks for Event Streams Classification},
   url = {http://arxiv.org/abs/2107.11711},
   year = {2021},
}
@article{Yoo2022,
   author = {Sangmin Yoo and Sieun Chae and Matthew Webb and Tony Chiang and Hanjong Paik and Yongmo Park and Logan Williams and Susan Trolier-McKinstry and Emmanouil Kioupakis and John T. Heron and Wei D. Lu},
   journal = {In Preparation},
   title = {Tuning of Entropy-Stabilized Oxide Memristors for Efficient Data Processing},
   year = {2022},
}
@article{Maass2002,
   abstract = {A key challenge for neural modeling is to explain how a continuous stream of multimodal input from a rapidly changing environment can be processed by stereotypical recurrent circuits of integrate-and-fire neurons in real time. We propose a new computational model for real-time computing on time-varying input that provides an alternative to paradigms based on Turing machines or attractor neural networks. It does not require a task-dependent construction of neural circuits. Instead, it is based on principles of high-dimensional dynamical systems in combination with statistical learning theory and can be implemented on generic evolved or found recurrent circuitry. It is shown that the inherent transient dynamics of the high-dimensional dynamical system formed by a sufficiently large and heterogeneous neural circuit may serve as universal analog fading memory. Readout neurons can learn to extract in real time from the current state of such recurrent neural circuit information about current and past inputs that may be needed for diverse tasks. Stable internal states are not required for giving a stable output, since transient internal states can be transformed by readout neurons into stable target outputs due to the high dimensionality of the dynamical system. Our approach is based on a rigorous computational model, the liquid state machine, that, unlike Turing machines, does not require sequential transitions between well-defined discrete internal states. It is supported, as the Turing machine is, by rigorous mathematical results that predict universal computational power under idealized conditions, but for the biologically more realistic scenario of real-time processing of time-varying inputs. Our approach provides new perspectives for the interpretation of neural coding, the design of experiments and data analysis in neurophysiology, and the solution of problems in robotics and neurotechnology.},
   author = {Wolfgang Maass and Thomas Natschläger and Henry Markram},
   doi = {10.1162/089976602760407955},
   issn = {0899-7667},
   issue = {11},
   journal = {Neural Computation},
   month = {11},
   pages = {2531-2560},
   title = {Real-Time Computing Without Stable States: A New Framework for Neural Computation Based on Perturbations},
   volume = {14},
   url = {https://doi.org/10.1162/089976602760407955},
   year = {2002},
}
@article{Jaeger2001,
   author = {Herbert Jaeger},
   journal = {Bonn, Germany: German National Research Center for Information Technology GMD Technical Report},
   month = {1},
   title = {The" echo state" approach to analysing and training recurrent neural networks-with an erratum note'},
   volume = {148},
   year = {2001},
}
@article{Moon2021,
   abstract = {Reservoir computing (RC) offers efficient temporal data processing with a low training cost by separating recurrent neural networks into a fixed network with recurrent connections and a trainable linear network. The quality of the fixed network, called reservoir, is the most important factor that determines the performance of the RC system. In this paper, we investigate the influence of the hierarchical reservoir structure on the properties of the reservoir and the performance of the RC system. Analogous to deep neural networks, stacking sub-reservoirs in series is an efficient way to enhance the nonlinearity of data transformation to high-dimensional space and expand the diversity of temporal information captured by the reservoir. These deep reservoir systems offer better performance when compared to simply increasing the size of the reservoir or the number of sub-reservoirs. Low frequency components are mainly captured by the sub-reservoirs in later stage of the deep reservoir structure, similar to observations that more abstract information can be extracted by layers in the late stage of deep neural networks. When the total size of the reservoir is fixed, tradeoff between the number of sub-reservoirs and the size of each sub-reservoir needs to be carefully considered, due to the degraded ability of individual sub-reservoirs at small sizes. Improved performance of the deep reservoir structure alleviates the difficulty of implementing the RC system on hardware systems.},
   author = {John Moon and Yuting Wu and Wei D Lu},
   doi = {10.1088/2634-4386/ac1b75},
   issn = {2634-4386},
   issue = {1},
   journal = {Neuromorphic Computing and Engineering},
   pages = {014006},
   publisher = {IOP Publishing},
   title = {Hierarchical architectures in reservoir computing systems},
   volume = {1},
   url = {https://dx.doi.org/10.1088/2634-4386/ac1b75},
   year = {2021},
}
@article{Stathopoulos2017,
   abstract = {Emerging nanoionic memristive devices are considered as the memory technology of the future and have been winning a great deal of attention due to their ability to perform fast and at the expense of low-power and -space requirements. Their full potential is envisioned that can be fulfilled through their capacity to store multiple memory states per cell, which however has been constrained so far by issues affecting the long-term stability of independent states. Here, we introduce and evaluate a multitude of metal-oxide bi-layers and demonstrate the benefits from increased memory stability via multibit memory operation. We propose a programming methodology that allows for operating metal-oxide memristive devices as multibit memory elements with highly packed yet clearly discernible memory states. These states were found to correlate with the transport properties of the introduced barrier layers. We are demonstrating memory cells with up to 6.5 bits of information storage as well as excellent retention and power consumption performance. This paves the way for neuromorphic and non-volatile memory applications.},
   author = {Spyros Stathopoulos and Ali Khiat and Maria Trapatseli and Simone Cortese and Alexantrou Serb and Ilia Valov and Themis Prodromakis},
   doi = {10.1038/s41598-017-17785-1},
   issn = {20452322},
   issue = {1},
   journal = {Scientific Reports},
   pages = {1-7},
   pmid = {29235524},
   publisher = {Springer US},
   title = {Multibit memory operation of metal-oxide Bi-layer memristors},
   volume = {7},
   url = {http://dx.doi.org/10.1038/s41598-017-17785-1},
   year = {2017},
}
@article{,
   author = {Samanwoy Ghosh-dastidar and Abba G Lichtenstein},
   issue = {4},
   journal = {International Journal},
   keywords = {information encoding,learning algorithm,spiking neural network,spiking neuron,supervised learning,unsuper-,vised learning},
   pages = {295-308},
   title = {Review Article SPIKING NEURAL NETWORKS},
   volume = {19},
   year = {2009},
}
@article{Shipp2007,
   author = {Stewart Shipp},
   doi = {https://doi.org/10.1016/j.cub.2007.03.044},
   issn = {0960-9822},
   issue = {12},
   journal = {Current Biology},
   pages = {R443-R449},
   title = {Structure and function of the cerebral cortex},
   volume = {17},
   url = {https://www.sciencedirect.com/science/article/pii/S0960982207011487},
   year = {2007},
}
@generic{Brette2015,
   abstract = {Does the brain use a firing rate code or a spike timing code? Considering this controversial question from an epistemological perspective, I argue that progress has been hampered by its problematic phrasing. It takes the perspective of an external observer looking at whether those two observables vary with stimuli, and thereby misses the relevant question: which one has a causal role in neural activity? When rephrased in a more meaningful way, the rate-based view appears as an ad hoc methodological postulate, one that is practical but with virtually no empirical or theoretical support.},
   author = {Romain Brette},
   isbn = {1662-5137},
   journal = {Frontiers in Systems Neuroscience  },
   title = {Philosophy of the Spike: Rate-Based vs. Spike-Based Theories of the Brain   },
   volume = {9      },
   url = {https://www.frontiersin.org/article/10.3389/fnsys.2015.00151},
   year = {2015},
}
@article{Andersen1980,
   abstract = {1. In vitro slices of guinea-pig hippocampus have been employed to compare excitatory synapses located distally and proximally on the dendritic tree of CA1 pyramidal cells.2. The main orientation of unmyelinated afferent fibres was found to be parallel to each other and perpendicular to the dendritic axis.3. The density of boutons ending on dendritic spines was roughly similar throughout the greater part of the dendritic tree with an average of 42 +/- 7.2 synapses per 100 mum(2). Their number did, however, decrease in the distal fifth of the apical and in the distal third of the basal dendritic region in parallel with an increase of boutons on the dendritic shafts.4. Negative synaptic field potentials (extracellular field e.p.s.p.s) had their maximum in the region where activated afferent fibres terminated and showed reversal when recorded from sufficiently displaced positions along the dendritic axis. The field e.p.s.p. was preceded by a diphasic presynaptic fibre volley. By cutting all but a narrow bundle of afferent fibres selective activation of a small group of dendritic synapses was possible. Stimulation of fibres crossing tissue bridges (35-100 mum wide) evoked field e.p.s.p.s comparable in amplitude to those seen in slices without lesions. The size of the field e.p.s.p.s evoked via distal and proximal bridges was remarkably similar and linearly related to the size of the appropriate stimulus current and presynaptic volley.5. Selective activation of a small group of afferent fibres gave rise to large amplitude population spikes. Proximal and distal bridges were largely equipotent when they were equally wide. Above the threshold amplitude, the evoked population spikes were linearly related to both the presynaptic volley and the stimulus current. Constant current stimulation of fibres at all apical dendritic levels was equally effective in evoking population spikes, with the exception of the outer fifth of the tree where stimulation was unsuccessful. Input across distal or proximal bridges (400 or 50 mum from the soma) also gave the same high probability of discharge of single units (1.0 for thirty-five of thirty-six cells).6. An input across a narrow and distal bridge (35 mum), representing less than 5% of the fibres synapsing on the apical dendrite, was sufficient to give a firing probability of 1.0 for all cells tested (fifteen).7. For seventeen cells pairs of equally wide distal and proximal apical dendritic bridges were compared. Both inputs gave a mean probability of firing above 0.95 with stimulation strengths less than 2.5 times the spike threshold.8. Intracellular e.p.s.p.s had similar shapes following activation across distal and proximal dendritic bridges. The amplitude of neither type was significantly affected by hyperpolarization of the soma up to 25 mV. The half-width was prolonged to the same moderate degree for both inputs.9. The firing level for the action potential was similar for proximal and distal dendritic inputs and for spikes excited by depolarizing current pulses across the soma membrane.10. The apparent equipotentiality of synchronously activated distal and proximal dendritic synapses is discussed in the light of the known histology of the CA1 pyramidal cells.},
   author = {P Andersen and H Silfvenius and S H Sundberg and O Sveen},
   doi = {10.1113/jphysiol.1980.sp013435},
   issn = {0022-3751},
   journal = {The Journal of physiology},
   keywords = {Action Potentials,Animals,Dendrites/*physiology,Guinea Pigs,Hippocampus/*physiology/ultrastructure,In Vitro Techniques,Neurons, Afferent/physiology,Synapses/*physiology},
   month = {10},
   pages = {273-299},
   title = {A comparison of distal and proximal dendritic synapses on CAi pyramids in guinea-pig hippocampal slices in vitro},
   volume = {307},
   url = {https://pubmed.ncbi.nlm.nih.gov/7205666 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1283045/},
   year = {1980},
}
@article{Anderson1980,
   abstract = {The screening of chemicals for the protection of human health and the environment requires the assessment of genetic toxicity. However, existing, internationally-accepted in vitro mammalian genotoxicity tests have been criticized for their low specificity (i.e. high frequency of “false” or “misleading” positive results for compounds that are negative in vivo). An in vitro transgene mutation assay has been established that uses a metabolically competent cell line derived from MutaMouse lung (i.e. FE1 cells). Mutation scoring employs the well-characterized lacZ positive selection system, and the assay is proposed as an alternative in vitro assessment tool. In this study, the performance of the FE1 cell assay was evaluated by examining responses to nine non-DNA-reactive chemicals that previously elicited misleading positive results in other mammalian cell genotoxicity assays. FE1 cells were exposed to concentrations up to approximately 10 mM and/or concentrations that yielded approximately 80-90% cytotoxicity (as measured by relative increase in cell count). The assay demonstrated excellent specificity; exposures to the chemicals examined did not yield any positive responses even when tested in the presence of an exogenous metabolic activation system (i.e. S9) or with an extended sampling time. These results indicate that the FE1 cell mutagenicity assay is an effective and practical alternative to traditional mammalian cell gene mutation assays. The development and validation of effective in vitro tools such as the MutaMouse FE1 cell assay will contribute to international efforts to reduce, refine, and replace experimental animals for toxicity assessment. Environ. Mol. Mutagen. 58:582–591, 2017. © 2017 Wiley Periodicals, Inc.},
   author = {P. Anderson and H. Silfvenius and S. H. Sundberg and O. Sveen},
   doi = {10.4324/9780203129425-12},
   journal = {Journal of Physiology},
   pages = {273-299},
   title = {A comparison of distal and proximal dendritic synapses on CA1 pyramids in guinea-pig hippocampal slices in vitro},
   volume = {307},
   year = {1980},
}
@inproceedings{Comsa2020,
   author = {I M Comsa and K Potempa and L Versari and T Fischbacher and A Gesmundo and J Alakuijala},
   doi = {10.1109/ICASSP40776.2020.9053856},
   isbn = {2379-190X VO  -},
   journal = {ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
   pages = {8529-8533},
   title = {Temporal Coding in Spiking Neural Networks with Alpha Synaptic Function},
   year = {2020},
}
@article{Tavanaei2019,
   abstract = {In recent years, deep learning has revolutionized the field of machine learning, for computer vision in particular. In this approach, a deep (multilayer) artificial neural network (ANN) is trained, most often in a supervised manner using backpropagation. Vast amounts of labeled training examples are required, but the resulting classification accuracy is truly impressive, sometimes outperforming humans. Neurons in an ANN are characterized by a single, static, continuous-valued activation. Yet biological neurons use discrete spikes to compute and transmit information, and the spike times, in addition to the spike rates, matter. Spiking neural networks (SNNs) are thus more biologically realistic than ANNs, and are arguably the only viable option if one wants to understand how the brain computes at the neuronal description level. The spikes of biological neurons are sparse in time and space, and event-driven. Combined with bio-plausible local learning rules, this makes it easier to build low-power, neuromorphic hardware for SNNs. However, training deep SNNs remains a challenge. Spiking neurons’ transfer function is usually non-differentiable, which prevents using backpropagation. Here we review recent supervised and unsupervised methods to train deep SNNs, and compare them in terms of accuracy and computational cost. The emerging picture is that SNNs still lag behind ANNs in terms of accuracy, but the gap is decreasing, and can even vanish on some tasks, while SNNs typically require many fewer operations and are the better candidates to process spatio-temporal data.},
   author = {Amirhossein Tavanaei and Masoud Ghodrati and Saeed Reza Kheradpisheh and Timothée Masquelier and Anthony Maida},
   doi = {10.1016/j.neunet.2018.12.002},
   issn = {18792782},
   journal = {Neural Networks},
   keywords = {Biological plausibility,Deep learning,Machine learning,Power-efficient architecture,Spiking neural network},
   pages = {47-63},
   pmid = {30682710},
   title = {Deep learning in spiking neural networks},
   volume = {111},
   year = {2019},
}
@article{Yin2020,
   author = {S Yin and X Sun and S Yu and J -S. Seo},
   doi = {10.1109/TED.2020.3015178},
   issn = {1557-9646 VO  - 67},
   issue = {10},
   journal = {IEEE Transactions on Electron Devices},
   pages = {4185-4192},
   title = {High-Throughput In-Memory Computing for Binary Deep Neural Networks With Monolithically Integrated RRAM and 90-nm CMOS},
   volume = {67},
   year = {2020},
}
@inproceedings{Liu2020,
   author = {Q Liu and B Gao and P Yao and D Wu and J Chen and Y Pang and W Zhang and Y Liao and C -X. Xue and W -H. Chen and J Tang and Y Wang and M -F. Chang and H Qian and H Wu},
   doi = {10.1109/ISSCC19947.2020.9062953},
   isbn = {2376-8606 VO  -},
   journal = {2020 IEEE International Solid- State Circuits Conference - (ISSCC)},
   pages = {500-502},
   title = {33.2 A Fully Integrated Analog ReRAM Based 78.4TOPS/W Compute-In-Memory Chip with Fully Parallel MAC Computing},
   year = {2020},
}
@article{Liu2020,
   author = {Qi Liu and Bin Gao and Peng Yao and Dong Wu and Junren Chen and Yachuan Pang and Wenqiang Zhang and Yan Liao and Cheng-xin Xue and Wei-hao Chen and Jianshi Tang and Yu Wang and Meng-fan Chang and He Qian and Huaqiang Wu},
   isbn = {9781728132051},
   journal = {2020 IEEE International Solid- State Circuits Conference - (ISSCC)},
   pages = {500-502},
   publisher = {IEEE},
   title = {Compute-In-Memory Chip with Fully Parallel MAC Computing},
   year = {2020},
}
@article{Yin2019,
   abstract = {Resistive RAM (RRAM) has been presented as a promising memory technology toward deep neural network (DNN) hardware design, with nonvolatility, high density, high ON/OFF ratio, and compatibility with logic process. However, prior RRAM works for DNNs have shown limitations on parallelism for in-memory computing, array efficiency with large peripheral circuits, multilevel analog operation, and demonstration of monolithic integration. In this article, we propose circuit-/device-level optimizations to improve the energy and density of RRAM-based in-memory computing architectures. We report experimental results based on prototype chip design of 128 × 64 RRAM arrays and CMOS peripheral circuits, where RRAM devices are monolithically integrated in a commercial 90-nm CMOS technology. We demonstrate the CMOS peripheral circuit optimization using input-splitting scheme and investigate the implication of higher low resistance state on energy efficiency and robustness. Employing the proposed techniques, we demonstrate RRAM-based in-memory computing with up to 116.0 TOPS/W energy efficiency and 84.2% CIFAR-10 accuracy. Furthermore, we investigate four-level programming with single RRAM device, and report the system-level performance and DNN accuracy results using circuit-level benchmark simulator NeuroSim.},
   author = {Shihui Yin and Jae Sun Seo and Yulhwa Kim and Xu Han and Hugh Barnaby and Shimeng Yu and Yandong Luo and Wangxin He and Xiaoyu Sun and Jae Joon Kim},
   doi = {10.1109/MM.2019.2943047},
   issn = {19374143},
   issue = {6},
   journal = {IEEE Micro},
   pages = {54-63},
   publisher = {IEEE},
   title = {Monolithically Integrated RRAM- And CMOS-Based In-Memory Computing Optimizations for Efficient Deep Learning},
   volume = {39},
   year = {2019},
}
@article{Adam2017,
   abstract = {We report a monolithically integrated 3-D metal-oxide memristor crossbar circuit suitable for analog, and in particular, neuromorphic computing applications. The demonstrated crossbar is based on Pt/Al2O3/TiO2-x/TiN/Pt memristors and consists of a stack of two passive 10×0 crossbars with shared middle electrodes. The fabrication process has a low, less than 175 °C, temperature budget and includes a planarization step performed before the deposition of the second crossbar layer. These features greatly improve yield and uniformity of the crosspoint devices and allows for utilizing such a fabrication process for integration with CMOS circuits as well as for stacking of multiple crossbar layers. Furthermore, the integrated crosspoint memristors are optimized for analog computing applications allowing successful forming and switching of all 200 devices in the demonstrated crossbar circuit, and, most importantly, precise tuning of the devices' conductance values within the dynamic range of operation. We believe that the demonstrated work is an important milestone toward the implementation of analog artificial neural networks, specifically, those based on 3-D CMOL circuits.},
   author = {Gina C. Adam and Brian D. Hoskins and Mirko Prezioso and Farnood Merrikh-Bayat and Bhaswar Chakrabarti and Dmitri B. Strukov},
   doi = {10.1109/TED.2016.2630925},
   isbn = {9550121003},
   issn = {00189383},
   issue = {1},
   journal = {IEEE Transactions on Electron Devices},
   keywords = {3-D integrated circuits,analog processing circuits,memristors,nonvolatile memory},
   pages = {312-318},
   publisher = {IEEE},
   title = {3-D Memristor Crossbars for Analog and Neuromorphic Computing Applications},
   volume = {64},
   year = {2017},
}
@article{Member2020,
   author = {Senior Member and Senior Member},
   issue = {10},
   pages = {4185-4192},
   title = {High-Throughput In-Memory Computing for},
   volume = {67},
   year = {2020},
}
@article{Zidan2018,
   abstract = {Memristive devices have been extensively studied for data-intensive tasks such as artificial neural networks. These types of computing tasks are considered to be 'soft' as they can tolerate low computing precision without suffering from performance degradation. However, 'hard' computing tasks, which require high precision and accurate solutions, dominate many applications and are difficult to implement with memristors because the devices normally offer low native precision and suffer from high device variability. Here we report a complete memristor-based hardware and software system that can perform high-precision computing tasks, making memristor-based in-memory computing approaches attractive for general high-performance computing environments. We experimentally implement a numerical partial differential equation solver using a tantalum oxide memristor crossbar system, which we use to solve static and time-evolving problems. We also illustrate the practical capabilities of our memristive hardware by using it to simulate an argon plasma reactor.},
   author = {Mohammed A. Zidan and Yeon Joo Jeong and Jihang Lee and Bing Chen and Shuo Huang and Mark J. Kushner and Wei D. Lu},
   doi = {10.1038/s41928-018-0100-6},
   issn = {25201131},
   issue = {7},
   journal = {Nature Electronics},
   pages = {411-420},
   publisher = {Springer US},
   title = {A general memristor-based partial differential equation solver},
   volume = {1},
   url = {http://dx.doi.org/10.1038/s41928-018-0100-6},
   year = {2018},
}
@article{Prezioso2015,
   abstract = {Despite much progress in semiconductor integrated circuit technology, the extreme complexity of the human cerebral cortex<sup>1</sup>, with its approximately 10<sup>14</sup> synapses, makes the hardware implementation of neuromorphic networks with a comparable number of devices exceptionally challenging. To provide comparable complexity while operating much faster and with manageable power dissipation, networks<sup>2</sup> based on circuits<sup>3,4</sup> combining complementary metal-oxide-semiconductors (CMOSs) and adjustable two-terminal resistive devices (memristors) have been developed. In such circuits, the usual CMOS stack is augmented with one<sup>3</sup> or several<sup>4</sup> crossbar layers, with memristors at each crosspoint. There have recently been notable improvements in the fabrication of such memristive crossbars and their integration with CMOS circuits<sup>5+12</sup>, including first demonstrations<sup>5,6,12</sup> of their vertical integration. Separately, discrete memristors have been used as artificial synapses in neuromorphic networks<sup>13,18</sup>. Very recently, such experiments have been extended<sup>19</sup> to crossbar arrays of phase-change memristive devices. The adjustment of such devices, however, requires an additional transistor at each crosspoint, and hence these devices are much harder to scale than metal-oxide memristors<sup>11,20,21</sup>, whose nonlinear current-voltage curves enable transistor-free operation. Here we report the experimental implementation of transistor-free metal-oxide memristor crossbars, with device variability sufficiently low to allow operation of integrated neural networks, in a simple network: a single-layer perceptron (an algorithm for linear classification). The network can be taught in situ using a coarse-grain variety of the delta rule algorithm<sup>22</sup> to perform the perfect classification of 3 × 3-pixel black/white images into three classes (representing letters). This demonstration is an important step towards much larger and more complex memristive neuromorphic networks. G2015 Macmillan Publishers Limited. All rights reserved.},
   author = {M. Prezioso and F. Merrikh-Bayat and B. D. Hoskins and G. C. Adam and K. K. Likharev and D. B. Strukov},
   doi = {10.1038/nature14441},
   issn = {14764687},
   issue = {7550},
   journal = {Nature},
   pages = {61-64},
   pmid = {25951284},
   title = {Training and operation of an integrated neuromorphic network based on metal-oxide memristors},
   volume = {521},
   year = {2015},
}
@article{Chen2020,
   abstract = {Two-dimensional materials could play an important role in beyond-CMOS (complementary metal–oxide–semiconductor) electronics, and the development of memristors for information storage and neuromorphic computing using such materials is of particular interest. However, the creation of high-density electronic circuits for complex applications is limited due to low device yield and high device-to-device variability. Here, we show that high-density memristive crossbar arrays can be fabricated using hexagonal boron nitride as the resistive switching material, and used to model an artificial neural network for image recognition. The multilayer hexagonal boron nitride is deposited using chemical vapour deposition, and the arrays exhibit a high yield (98%), low cycle-to-cycle variability (1.53%) and low device-to-device variability (5.74%). The devices exhibit different switching mechanisms depending on the electrode material used (gold for bipolar switching and silver for threshold switching), as well as characteristics (such as large dynamic range and zeptojoule-order switching energies) that make them suited for application in neuromorphic circuits.},
   author = {Shaochuan Chen and Mohammad Reza Mahmoodi and Yuanyuan Shi and Chandreswar Mahata and Bin Yuan and Xianhu Liang and Chao Wen and Fei Hui and Deji Akinwande and Dmitri B. Strukov and Mario Lanza},
   doi = {10.1038/s41928-020-00473-w},
   isbn = {4192802000473},
   issn = {25201131},
   issue = {10},
   journal = {Nature Electronics},
   pages = {638-645},
   publisher = {Springer US},
   title = {Wafer-scale integration of two-dimensional materials in high-density memristive crossbar arrays for artificial neural networks},
   volume = {3},
   url = {http://dx.doi.org/10.1038/s41928-020-00473-w},
   year = {2020},
}
@article{Cai2019,
   abstract = {Memristors and memristor crossbar arrays have been widely studied for neuromorphic and other in-memory computing applications. To achieve optimal system performance, however, it is essential to integrate memristor crossbars with peripheral and control circuitry. Here, we report a fully functional, hybrid memristor chip in which a passive crossbar array is directly integrated with custom-designed circuits, including a full set of mixed-signal interface blocks and a digital processor for reprogrammable computing. The memristor crossbar array enables online learning and forward and backward vector-matrix operations, while the integrated interface and control circuitry allow mapping of different algorithms on chip. The system supports charge-domain operation to overcome the nonlinear I–V characteristics of memristor devices through pulse width modulation and custom analogue-to-digital converters. The integrated chip offers all the functions required for operational neuromorphic computing hardware. Accordingly, we demonstrate a perceptron network, sparse coding algorithm and principal component analysis with an integrated classification layer using the system.},
   author = {Fuxi Cai and Justin M. Correll and Seung Hwan Lee and Yong Lim and Vishishtha Bothra and Zhengya Zhang and Michael P. Flynn and Wei D. Lu},
   doi = {10.1038/s41928-019-0270-x},
   issn = {25201131},
   issue = {7},
   journal = {Nature Electronics},
   pages = {290-299},
   publisher = {Springer US},
   title = {A fully integrated reprogrammable memristor–CMOS system for efficient multiply–accumulate operations},
   volume = {2},
   url = {http://dx.doi.org/10.1038/s41928-019-0270-x},
   year = {2019},
}
@article{Lee2016,
   abstract = {Two-photon calcium imaging and electron microscopy were used to explore the relationship between structure and function in mouse primary visual cortex, showing that layer 2/3 neurons are connected in subnetworks, that pyramidal neurons with similar orientation selectivity preferentially form synapses with each other, and that neurons with similar orientation tuning form larger synapses; this study exemplifies functional connectomics as a powerful method for studying the organizational logic of cortical networks.},
   author = {Wei-Chung Allen Lee and Vincent Bonin and Michael Reed and Brett J Graham and Greg Hood and Katie Glattfelder and R Clay Reid},
   doi = {10.1038/nature17192},
   issn = {1476-4687},
   issue = {7599},
   journal = {Nature},
   pages = {370-374},
   title = {Anatomy and function of an excitatory network in the visual cortex},
   volume = {532},
   url = {https://doi.org/10.1038/nature17192},
   year = {2016},
}
@article{Park2019,
   abstract = {Pyramidal neurons integrate synaptic inputs from basal and apical dendrites to generate stimulus-specific responses. It has been proposed that feed-forward inputs to basal dendrites drive a neuron’s stimulus preference, while feedback inputs to apical dendrites sharpen selectivity. However, how a neuron’s dendritic domains relate to its functional selectivity has not been demonstrated experimentally. We performed 2-photon dendritic micro-dissection on layer-2/3 pyramidal neurons in mouse primary visual cortex. We found that removing the apical dendritic tuft did not alter orientation-tuning. Furthermore, orientation-tuning curves were remarkably robust to the removal of basal dendrites: ablation of 2 basal dendrites was needed to cause a small shift in orientation preference, without significantly altering tuning width. Computational modeling corroborated our results and put limits on how orientation preferences among basal dendrites differ in order to reproduce the post-ablation data. In conclusion, neuronal orientation-tuning appears remarkably robust to loss of dendritic input.},
   author = {Jiyoung Park and Athanasia Papoutsi and Ryan T Ash and Miguel A Marin and Panayiota Poirazi and Stelios M Smirnakis},
   doi = {10.1038/s41467-019-13029-0},
   issn = {2041-1723},
   issue = {1},
   journal = {Nature Communications},
   pages = {5372},
   title = {Contribution of apical and basal dendrites to orientation encoding in mouse V1 L2/3 pyramidal neurons},
   volume = {10},
   url = {https://doi.org/10.1038/s41467-019-13029-0},
   year = {2019},
}
@article{Mozafari2019,
   abstract = {Application of deep convolutional spiking neural networks (SNNs) to artificial intelligence (AI) tasks has recently gained a lot of interest since SNNs are hardware-friendly and energy-efficient. Unlike the non-spiking counterparts, most of the existing SNN simulation frameworks are not practically efficient enough for large-scale AI tasks. In this paper, we introduce SpykeTorch, an open-source high-speed simulation framework based on PyTorch. This framework simulates convolutional SNNs with at most one spike per neuron and the rank-order encoding scheme. In terms of learning rules, both spike-timing-dependent plasticity (STDP) and reward-modulated STDP (R-STDP) are implemented, but other rules could be implemented easily. Apart from the aforementioned properties, SpykeTorch is highly generic and capable of reproducing the results of various studies. Computations in the proposed framework are tensor-based and totally done by PyTorch functions, which in turn brings the ability of just-in-time optimization for running on CPUs, GPUs, or Multi-GPU platforms.},
   author = {Milad Mozafari and Mohammad Ganjtabesh and Abbas Nowzari-Dalini and Timothée Masquelier},
   doi = {10.3389/fnins.2019.00625},
   issn = {1662453X},
   issue = {JUL},
   journal = {Frontiers in Neuroscience},
   keywords = {GPU acceleration,STDP,convolutional spiking neural networks,one spike per neuron,reward-modulated STDP,tensor-based computing,time-to-first-spike coding},
   pages = {1-12},
   title = {{SpykeTorch}: Efficient simulation of convolutional spiking neural networks with at most one spike per neuron},
   volume = {13},
   year = {2019},
}
@article{Wang2007,
   abstract = {We have studied the contribution of feedback signals originating from one of the “form-processing” extrastriate cortical areas, area 21a (A21a), to orientation selectivity of single neurons in the ipsilateral area 17 (A17). Consistent with previous findings, reversible inactivation (cooling to 5–10°C) of area 21a resulted in a substantial reduction in the magnitude of the maximum response (Rmax) of A17 cells accompanied by some changes in the half-width at half-height of the Rmax (HWHH). By fitting model functions to the neurons’ response profiles we found that in the vast majority of orientation-tuned A17 cells tested (30/39, 77%), inactivation of A21a resulted in a “flattening” of their orientation-tuning curves. It is characterised by a substantial reduction in the Rmax associated with either a broadening of the orientation-tuning curves (17 cells) or a relatively small reduction (12 cells) or no change (1 cell) in the HWHH. When the “flattening” effect was quantified using a simple ratio index or R/W, defined as Rmax/HWHH, we found that R/W was significantly reduced during inactivation of A21a. The change in R/W is strongly correlated with the change in the maximum slope of the orientation-tuning curves. Furthermore, analysis of response variability indicates that “signal-to-noise” ratio of the responses of A17 neurons decreases during inactivation of A21a. Our results suggest that the predominately excitatory feedback signals originating from A21a play a role in enhancing orientation selectivity of A17 neurons and hence are likely to improve overall orientation discriminability.},
   author = {C Wang and W J Waleszczyk and W Burke and B Dreher},
   doi = {10.1007/s00221-007-1014-0},
   issn = {1432-1106},
   issue = {4},
   journal = {Experimental Brain Research},
   pages = {479-490},
   title = {Feedback signals from cat’s area 21a enhance orientation selectivity of area 17 neurons},
   volume = {182},
   url = {https://doi.org/10.1007/s00221-007-1014-0},
   year = {2007},
}
@article{Nassi2013,
   abstract = {Feedback connections are prevalent throughout the cerebral cortex, yet their function remains poorly understood. Previous studies in anesthetized monkeys found that inactivating feedback from extrastriate visual cortex produced effects in striate cortex that were relatively weak, generally suppressive, largest for visual stimuli confined to the receptive field center, and detectable only at low stimulus contrast. We studied the influence of corticocortical feedback in alert monkeys using cortical cooling to reversibly inactivate visual areas 2 (V2) and 3 (V3) while characterizing receptive field properties in primary visual cortex (V1).Weshow that inactivation of feedback from areas V2 and V3 results in both response suppression and facilitation for stimuli restricted to the receptive field center, in most cases leading to a small reduction in the degree of orientation selectivity but no change in orientation preference. For larger-diameter stimuli that engage regions beyond the center of the receptive field, eliminating feedback from V2 and V3 results in strong and consistent response facilitation, effectively reducing the strength of surround suppression in V1 for stimuli of both low and high contrast. For extended contours, eliminating feedback had the effect of reducing end stopping. Inactivation effects were largest for neurons that exhibited strong surround suppression before inactivation, and their timing matched the dynamics of surround suppression under control conditions. Our results provide direct evidence that feedback contributes to surround suppression, which is an important source of contextual influences essential to vision. © 2013 the authors.},
   author = {Jonathan J. Nassi and Stephen G. Lomber and Richard T. Born},
   doi = {10.1523/JNEUROSCI.5124-12.2013},
   issn = {02706474},
   issue = {19},
   journal = {Journal of Neuroscience},
   pages = {8504-8517},
   pmid = {23658187},
   title = {Corticocortical feedback contributes to surround suppression in V1 of the alert primate},
   volume = {33},
   year = {2013},
}
@article{Ko2011,
   abstract = {In the sensory cortex, neurons are densely interconnected, but the logic by which functionally similar and dissimilar neurons are wired together is an open question. This technical tour de force combines in vivo two-photon calcium imaging and simultaneous whole-cell recording of multiple cells to show that neurons with similar stimulus preferences connect at higher rates than those with dissimilar preferences. This points to the existence of fine-scale sub-networks dedicated to processing related sensory information. Application of this new technique more widely should reveal more about how circuits supporting different sensory or motor functions are constructed in the brain.},
   author = {Ho Ko and Sonja B Hofer and Bruno Pichler and Katherine A Buchanan and P Jesper Sjöström and Thomas D Mrsic-Flogel},
   doi = {10.1038/nature09880},
   issn = {1476-4687},
   issue = {7345},
   journal = {Nature},
   pages = {87-91},
   title = {Functional specificity of local synaptic connections in neocortical networks},
   volume = {473},
   url = {https://doi.org/10.1038/nature09880},
   year = {2011},
}
@article{Yoshimura2000,
   abstract = {The purpose of this study is to elucidate the integrative input mechanisms of pyramidal cells receiving horizontally projecting axon collaterals (horizontal projection) and vertical input from layer IV. We performed whole-cell recordings from pyramidal cells in layer II/III and focally activated other single pyramidal cells monosynaptically connected via long-distance horizontal (LH) projections (the distance between presynaptic and postsynaptic cells was 350-1200 μm) in slice preparations of the kitten primary visual cortex. In addition, presynaptic single fibers in layer IV (vertical input) and/or short-distance horizontal (SH) inputs from neighboring single pyramidal cells (distance within 100 μm) in layer II/III were activated. Unitary EPSPs evoked by the activation of LH and SH connections had smaller amplitude and larger coefficient of variation than those evoked by stimulating the vertical input. Paired-pulse stimulation of the LH and SH inputs caused the depression of the second EPSP, whereas that of vertical inputs caused either facilitation or depression of the second EPSP. The EPSPs evoked by simultaneous activation of LH and vertical inputs summated linearly at the resting membrane potential. However, the EPSPs evoked by stimulation of the two inputs were nonlinearly (supralinearly) summated when the postsynaptic membrane was depolarized to a certain level. Similar EPSP interaction was observed in response to simultaneous activation of the LH and SH inputs.},
   author = {Yumiko Yoshimura and Hiromichi Sato and Kazuyuki Imamura and Yasuyoshi Watanabe},
   doi = {10.1523/jneurosci.20-05-01931.2000},
   issn = {02706474},
   issue = {5},
   journal = {Journal of Neuroscience},
   keywords = {Cat,Horizontal connection,Pyramidal cell,Synaptic interaction,Visual cortex,Whole-cell recording},
   pages = {1931-1940},
   pmid = {10684894},
   title = {Properties of horizontal and vertical inputs to pyramidal cells in the superficial layers of the cat visual cortex},
   volume = {20},
   year = {2000},
}
@article{Falez2020,
   abstract = {In recent years, spiking neural networks (SNNs) emerge as an alternative to deep neural networks (DNNs). SNNs present a higher computational efficiency - using low-power neuromorphic hardware - and require less labeled data for training - using local and unsupervised learning rules such as spike timing-dependent plasticity (STDP). SNNs have proven their effectiveness in image classification on simple datasets such as MNIST. However, to process natural images, a pre-processing step is required. Difference-of-Gaussians (DoG) filtering is typically used together with on-center / off-center coding, but it results in a loss of information that decreases the classification performance. In this paper, we propose to use whitening as a pre-processing step before learning features with STDP. Experiments on CIFAR-10 show that whitening allows STDP to learn visual features that are visually closer to the ones learned with standard neural networks, with a significantly increased classification performance as compared to DoG filtering. We also propose an approximation of whitening as convolution kernels that is computationally cheaper to learn and more suited to be implemented on neuromorphic hardware. Experiments on CIFAR-10 show that it performs similarly to regular whitening. Cross-dataset experiments on CIFAR-10 and STL-10 also show that it is stable across datasets, making it possible to learn a single whitening transformation to process different datasets.},
   author = {Pierre Falez and Pierre Tirilly and Ioan Marius Bilasco},
   doi = {10.1109/IJCNN48605.2020.9207373},
   isbn = {9781728169262},
   journal = {Proceedings of the International Joint Conference on Neural Networks},
   keywords = {Convolutional neural networks,Pattern recognition,Unsupervised learning},
   pages = {0-7},
   title = {Improving STDP-based Visual Feature Learning with Whitening},
   year = {2020},
}
@article{Flanders2011,
   abstract = {This Prospects presents the problems that must be solved by the vertebrate nervous system in the process of sensorimotor integration and motor control. The concepts of efference copy and inverse model are defined, and multiple biological mechanisms are described, including those that form the basis of integration, extrapolation, and comparison/cancellation operations. Open questions for future research include the biological basis of continuous and distributed versus modular control, and somatosensory-motor coordination. © 2011 The Author(s).},
   author = {Martha Flanders},
   doi = {10.1007/s00422-011-0419-9},
   issn = {03401200},
   issue = {1-2},
   journal = {Biological Cybernetics},
   keywords = {Efference copy,Forward model,Haptic,Motor control,Sensory feedback,Somatosensory},
   pages = {1-8},
   pmid = {21287354},
   title = {What is the biological basis of sensorimotor integration?},
   volume = {104},
   year = {2011},
}
@article{Shadmehr2010,
   abstract = {Motor control is the study of how organisms make accurate goal-directed movements. Here we consider two problems that the motor system must solve in order to achieve such control. The first problem is that sensory feedback is noisy and delayed, which can make movements inaccurate and unstable. The second problem is that the relationship between a motor command and the movement it produces is variable, as the body and the environment can both change. A solution is to build adaptive internal models of the body and the world. The predictions of these internal models, called forward models because they transform motor commands into sensory consequences, can be used to both produce a lifetime of calibrated movements, and to improve the ability of the sensory system to estimate the state of the body and the world around it. Forward models are only useful if they produce unbiased predictions. Evidence shows that forward models remain calibrated through motor adaptation: learning driven by sensory prediction errors. © 2010 by Annual Reviews. All rights reserved.},
   author = {Reza Shadmehr and Maurice A. Smith and John W. Krakauer},
   doi = {10.1146/annurev-neuro-060909-153135},
   issn = {0147006X},
   journal = {Annual Review of Neuroscience},
   keywords = {error feedback,forward models,motor adaptation,reaching,saccades,sensorimotor integration},
   pages = {89-108},
   pmid = {20367317},
   title = {Error correction, sensory prediction, and adaptation in motor control},
   volume = {33},
   year = {2010},
}
@article{Huston2011,
   abstract = {Sensorimotor integration is a field rich in theory backed by a large body of psychophysical evidence. Relating the underlying neural circuitry to these theories has, however, been more challenging. With a wide array of complex behaviors coordinated by their small brains, insects provide powerful model systems to study key features of sensorimotor integration at a mechanistic level. Insect neural circuits perform both hard-wired and learned sensorimotor transformations. They modulate their neural processing based on both internal variables, such as the animal's behavioral state, and external ones, such as the time of day. Here we present some studies using insect model systems that have produced insights, at the level of individual neurons, about sensorimotor integration and the various ways in which it can be modified by context. © 2011 Elsevier Ltd.},
   author = {Stephen J. Huston and Vivek Jayaraman},
   doi = {10.1016/j.conb.2011.05.030},
   issn = {09594388},
   issue = {4},
   journal = {Current Opinion in Neurobiology},
   pages = {527-534},
   pmid = {21705212},
   publisher = {Elsevier Ltd},
   title = {Studying sensorimotor integration in insects},
   volume = {21},
   url = {http://dx.doi.org/10.1016/j.conb.2011.05.030},
   year = {2011},
}
@article{Spruston1994,
   abstract = {The dendritic trees of neurons are structurally and functionally complex integrative units receiving thousands of synaptic inputs that have excitatory and inhibitory, fast and slow, and electrical and biochemical effects. The pattern of activation of these synaptic inputs determines if the neuron will fire an action potential at any given point in time and how it will respond to similar inputs in the future. Two critical factors affect the integrative function of dendrites: the distribution of voltage-gated ion channels in the dendritic tree and the passive electrical properties, or ‘electronic structure’, upon which these active channels are superimposed. The authors review recent data from patch-clamp recordings that provide new estimates of the passive membrane properties of hippocampal neurons, and show, with examples, how these properties affect the shaping and attenuation of synaptic potentials as they propagate in the dendrites, as well as how they affect the measurement of current from synapses located in the dendrites. Voltage-gated channels might influence the measurement of ‘passive’ membrane properties and, reciprocally, passive membrane properties might affect the activation of voltage-gated channels in dendrites.},
   author = {Nelson Spruston and David B Jaffe and Daniel Johnston},
   doi = {https://doi.org/10.1016/0166-2236(94)90094-9},
   issn = {0166-2236},
   issue = {4},
   journal = {Trends in Neurosciences},
   pages = {161-166},
   title = {Dendritic attenuation of synaptic potentials and currents: the role of passive membrane properties},
   volume = {17},
   url = {https://www.sciencedirect.com/science/article/pii/0166223694900949},
   year = {1994},
}
@article{Golding2005,
   abstract = {We performed simultaneous patch-electrode recordings from the soma and apical dendrite of CA1 pyramidal neurons in hippocampal slices, in order to determine the degree of voltage attenuation along CA1 dendrites. Fifty per cent attenuation of steady-state somatic voltage changes occurred at a distance of 238 microm from the soma in control and 409 microm after blocking the hyperpolarization-activated (H) conductance. The morphology of three neurons was reconstructed and used to generate computer models, which were adjusted to fit the somatic and dendritic voltage responses. These models identify several factors contributing to the voltage attenuation along CA1 dendrites, including high axial cytoplasmic resistivity, low membrane resistivity, and large H conductance. In most cells the resting membrane conductances, including the H conductances, were larger in the dendrites than the soma. Simulations suggest that synaptic potentials attenuate enormously as they propagate from the dendrite to the soma, with greater than 100-fold attenuation for synapses on many small, distal dendrites. A prediction of this powerful EPSP attenuation is that distal synaptic inputs are likely only to be effective in the presence of conductance scaling, dendritic excitability, or both.},
   author = {Nace L Golding and Timothy J Mickus and Yael Katz and William L Kath and Nelson Spruston},
   doi = {10.1113/jphysiol.2005.086793},
   edition = {2005/07/07},
   issn = {0022-3751},
   issue = {Pt 1},
   journal = {The Journal of physiology},
   keywords = {Animals,Dendrites/*physiology,Excitatory Postsynaptic Potentials/physiology,Hippocampus/*physiology/ultrastructure,In Vitro Techniques,Male,Models, Neurological,Neural Conduction/physiology,Patch-Clamp Techniques,Pyramidal Cells/*physiology/ultrastructure,Rats,Rats, Wistar,Synaptic Transmission},
   month = {10},
   pages = {69-82},
   publisher = {Blackwell Science Inc},
   title = {Factors mediating powerful voltage attenuation along CA1 pyramidal neuron dendrites},
   volume = {568},
   url = {https://pubmed.ncbi.nlm.nih.gov/16002454 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1474764/},
   year = {2005},
}
@article{Buxhoeveden2002,
   abstract = {The minicolumn is a continuing source of research and debate more than half a century after it was identified as a component of brain organization. The minicolumn is a sophisticated local network that contains within it the elements for redundancy and plasticity. Although it is sometimes compared to subcortical nuclei, the design of the minicolumn is a distinctive form of module that has evolved specifically in the neocortex. It unites the horizontal and vertical components of cortex within the same cortical space. Minicolumns are often considered highly repetitive, even clone‐like, units. However, they display considerable heterogeneity between areas and species, perhaps even within a given macrocolumn. Despite a growing recognition of the anatomical basis of the cortical minicolumn, as well as its physiological properties, the potential of the minicolumn has not been exploited in fields such as comparative neuroanatomy, abnormalities of the brain and mind, and evolution.},
   author = {Daniel P Buxhoeveden and Manuel F Casanova},
   doi = {10.1093/brain/awf110},
   issn = {0006-8950},
   issue = {5},
   journal = {Brain},
   month = {5},
   pages = {935-951},
   title = {The minicolumn hypothesis in neuroscience},
   volume = {125},
   url = {https://doi.org/10.1093/brain/awf110},
   year = {2002},
}
@article{Lecun1998,
   author = {Y Lecun and L Bottou and Y Bengio and P Haffner},
   doi = {10.1109/5.726791},
   issn = {1558-2256 VO  - 86},
   issue = {11},
   journal = {Proceedings of the IEEE},
   pages = {2278-2324},
   title = {Gradient-based learning applied to document recognition},
   volume = {86},
   year = {1998},
}
@inproceedings{NEURIPS2019_bdbca288,
   author = {Adam Paszke and Sam Gross and Francisco Massa and Adam Lerer and James Bradbury and Gregory Chanan and Trevor Killeen and Zeming Lin and Natalia Gimelshein and Luca Antiga and Alban Desmaison and Andreas Kopf and Edward Yang and Zachary DeVito and Martin Raison and Alykhan Tejani and Sasank Chilamkurthy and Benoit Steiner and Lu Fang and Junjie Bai and Soumith Chintala},
   city = {New York},
   editor = {H Wallach and H Larochelle and A Beygelzimer and F d\textquotesingle Alché-Buc and E Fox and R Garnett},
   journal = {Advances in Neural Information Processing Systems},
   pages = {8024-8035},
   publisher = {Curran Associates, Inc.},
   title = {{PyTorch}: An Imperative Style, High-Performance Deep Learning Library},
   volume = {32},
   url = {https://proceedings.neurips.cc/paper/2019/file/bdbca288fee7f92f2bfa9f7012727740-Paper.pdf},
   year = {2019},
}
@article{Du2017,
   abstract = {Reservoir computing systems utilize dynamic reservoirs having short-term memory to project features from the temporal inputs into a high-dimensional feature space. A readout function layer can then effectively analyze the projected features for tasks, such as classification and time-series analysis. The system can efficiently compute complex and temporal data with low-training cost, since only the readout function needs to be trained. Here we experimentally implement a reservoir computing system using a dynamic memristor array. We show that the internal ionic dynamic processes of memristors allow the memristor-based reservoir to directly process information in the temporal domain, and demonstrate that even a small hardware system with only 88 memristors can already be used for tasks, such as handwritten digit recognition. The system is also used to experimentally solve a second-order nonlinear task, and can successfully predict the expected output without knowing the form of the original dynamic transfer function.},
   author = {Chao Du and Fuxi Cai and Mohammed A. Zidan and Wen Ma and Seung Hwan Lee and Wei D. Lu},
   doi = {10.1038/s41467-017-02337-y},
   issn = {20411723},
   issue = {1},
   journal = {Nature Communications},
   pages = {1-10},
   pmid = {29259188},
   publisher = {Springer US},
   title = {Reservoir computing using dynamic memristors for temporal information processing},
   volume = {8},
   url = {http://dx.doi.org/10.1038/s41467-017-02337-y},
   year = {2017},
}
@article{Mountcastle1997,
   abstract = {The modular organization of nervous systems is a widely documented principle of design for both vertebrate and invertebrate brains of which the columnar organization of the neocortex is an example. The classical cytoarchitectural areas of the neocortex are composed of smaller units, local neural circuits repeated iteratively within each area. Modules may vary in cell type and number, in internal and external connectivity, and in mode of neuronal processing between different large entities; within any single large entity they have a basic similarity of internal design and operation. Modules are most commonly grouped into entities by sets of dominating external connections. This unifying factor is most obvious for the heterotypical sensory and motor areas of the neocortex. Columnar defining factors in homotypical areas are generated, in part, within the cortex itself. The set of all modules composing such an entity may be fractionated into different modular subsets by different extrinsic connections. Linkages between them and subsets in other large entities form distributed systems. The neighbourhood relations between connected subsets of modules in different entities result in nested distributed systems that serve distributed functions. A cortical area defined in classical cytoarchitectural terms may belong to more than one and sometimes to several distributed systems. Columns in cytoarchitectural areas located at some distance from one another but with some common properties, may be linked by long-range, intracortical connections.},
   author = {Vernon B. Mountcastle},
   doi = {10.1093/brain/120.4.701},
   issn = {00068950},
   issue = {4},
   journal = {Brain},
   keywords = {Columnar organization,Distributed systems,Modules,Neocortex,Primates},
   pages = {701-722},
   pmid = {9153131},
   title = {The columnar organization of the neocortex},
   volume = {120},
   year = {1997},
}
@article{,
   abstract = {The integrative properties of neurons depend strongly on the number, proportions  and distribution of excitatory and inhibitory synaptic inputs they receive. In this study the three-dimensional geometry of dendritic trees and the density of symmetrical and asymmetrical synapses on different cellular compartments of rat hippocampal CA1 area pyramidal cells was measured to calculate the total number and distribution of excitatory and inhibitory inputs on a single cell.A single pyramidal cell has approximately 12,000 microm dendrites and receives around 30,000 excitatory and 1700 inhibitory inputs, of which 40 % are concentrated in the perisomatic region and 20 % on dendrites in the stratum lacunosum-moleculare. The pre- and post-synaptic features suggest that CA1 pyramidal cell dendrites are heterogeneous. Strata radiatum and oriens dendrites are similar and differ from stratum lacunosum-moleculare dendrites. Proximal apical and basal strata radiatum and oriens dendrites are spine-free or sparsely spiny. Distal strata radiatum and oriens dendrites (forming 68.5 % of the pyramidal cells' dendritic tree) are densely spiny; their excitatory inputs terminate exclusively on dendritic spines, while inhibitory inputs target only dendritic shafts. The proportion of inhibitory inputs on distal spiny strata radiatum and oriens dendrites is low ( approximately 3 %). In contrast, proximal dendritic segments receive mostly (70-100 %) inhibitory inputs. Only inhibitory inputs innervate the somata (77-103 per cell) and axon initial segments. Dendrites in the stratum lacunosum-moleculare possess moderate to small amounts of spines. Excitatory synapses on stratum lacunosum-moleculare dendrites are larger than the synapses in other layers, are frequently perforated ( approximately 40 %) and can be located on dendritic shafts. Inhibitory inputs, whose percentage is relatively high ( approximately 14-17 %), also terminate on dendritic spines. Our results indicate that: (i) the highly convergent excitation arriving onto the distal dendrites of pyramidal cells is primarily controlled by proximally located inhibition; (ii) the organization of excitatory and inhibitory inputs in layers receiving Schaffer collateral input (radiatum/oriens) versus perforant path input (lacunosum-moleculare) is significantly different.},
   author = {M Megías and Z Emri and T F Freund and A I Gulyás},
   doi = {10.1016/s0306-4522(00)00496-6},
   issn = {0306-4522 (Print)},
   issue = {3},
   journal = {Neuroscience},
   keywords = {Animals,Dendrites,Hippocampus,Male,Microscopy, Electron,Microscopy, Immunoelectron,Pyramidal Cells,Rats,Rats, Wistar,Synapses,analysis,cytology,gamma-Aminobutyric Acid,physiology,ultrastructure},
   pages = {527-540},
   pmid = {11226691},
   title = {Total number and distribution of inhibitory and excitatory synapses on  hippocampal CA1 pyramidal cells.},
   volume = {102},
   year = {2001},
}
@generic{Rinkus2010,
   abstract = {No generic function for the minicolumn – i.e., one that would apply equally well to all cortical areas and species – has yet been proposed. I propose that the minicolumn does have a generic functionality, which only becomes clear when seen in the context of the function of the higher-level, subsuming unit, the macrocolumn. I propose that: (a) a macrocolumn's function is to store sparse distributed representations of its inputs and to be a recognizer of those inputs; and (b) the generic function of the minicolumn is to enforce macrocolumnar code sparseness. The minicolumn, defined here as a physically localized pool of ∼20 L2/3 pyramidals, does this by acting as a winner-take-all (WTA) competitive module, implying that macrocolumnar codes consist of ∼70 active L2/3 cells, assuming ∼70 minicolumns per macrocolumn. I describe an algorithm for activating these codes during both learning and retrievals, which causes more similar inputs to map to more highly intersecting codes, a property which yields ultra-fast (immediate, first-shot) storage and retrieval. The algorithm achieves this by adding an amount of randomness (noise) into the code selection process, which is inversely proportional to an input's familiarity. I propose a possible mapping of the algorithm onto cortical circuitry, and adduce evidence for a neuromodulatory implementation of this familiarity-contingent noise mechanism. The model is distinguished from other recent columnar cortical circuit models in proposing a generic minicolumnar function in which a group of cells within the minicolumn, the L2/3 pyramidals, compete (WTA) to be part of the sparse distributed macrocolumnar code.},
   author = {Gerard Rinkus},
   isbn = {1662-5129},
   journal = {Frontiers in Neuroanatomy  },
   title = {A cortical sparse distributed coding model linking mini- and macrocolumn-scale functionality   },
   volume = {4      },
   url = {https://www.frontiersin.org/article/10.3389/fnana.2010.00017},
   year = {2010},
}
@article{LeCun2015,
   abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
   author = {Yann LeCun and Yoshua Bengio and Geoffrey Hinton},
   doi = {10.1038/nature14539},
   issn = {1476-4687},
   issue = {7553},
   journal = {Nature},
   pages = {436-444},
   title = {Deep learning},
   volume = {521},
   url = {https://doi.org/10.1038/nature14539},
   year = {2015},
}
@article{Yao2020,
   abstract = {Memristor-enabled neuromorphic computing systems provide a fast and energy-efficient approach to training neural networks1–4. However, convolutional neural networks (CNNs)—one of the most important models for image recognition5—have not yet been fully hardware-implemented using memristor crossbars, which are cross-point arrays with a memristor device at each intersection. Moreover, achieving software-comparable results is highly challenging owing to the poor yield, large variation and other non-ideal characteristics of devices6–9. Here we report the fabrication of high-yield, high-performance and uniform memristor crossbar arrays for the implementation of CNNs, which integrate eight 2,048-cell memristor arrays to improve parallel-computing efficiency. In addition, we propose an effective hybrid-training method to adapt to device imperfections and improve the overall system performance. We built a five-layer memristor-based CNN to perform MNIST10 image recognition, and achieved a high accuracy of more than 96 per cent. In addition to parallel convolutions using different kernels with shared inputs, replication of multiple identical kernels in memristor arrays was demonstrated for processing different inputs in parallel. The memristor-based CNN neuromorphic system has an energy efficiency more than two orders of magnitude greater than that of state-of-the-art graphics-processing units, and is shown to be scalable to larger networks, such as residual neural networks. Our results are expected to enable a viable memristor-based non-von Neumann hardware solution for deep neural networks and edge computing.},
   author = {Peng Yao and Huaqiang Wu and Bin Gao and Jianshi Tang and Qingtian Zhang and Wenqiang Zhang and J. Joshua Yang and He Qian},
   doi = {10.1038/s41586-020-1942-4},
   issn = {14764687},
   issue = {7792},
   journal = {Nature},
   pages = {641-646},
   pmid = {31996818},
   publisher = {Springer US},
   title = {Fully hardware-implemented memristor convolutional neural network},
   volume = {577},
   url = {http://dx.doi.org/10.1038/s41586-020-1942-4},
   year = {2020},
}
@article{Alzubaidi2021,
   abstract = {In the last few years, the deep learning (DL) computing paradigm has been deemed the Gold Standard in the machine learning (ML) community. Moreover, it has gradually become the most widely used computational approach in the field of ML, thus achieving outstanding results on several complex cognitive tasks, matching or even beating those provided by human performance. One of the benefits of DL is the ability to learn massive amounts of data. The DL field has grown fast in the last few years and it has been extensively used to successfully address a wide range of traditional applications. More importantly, DL has outperformed well-known ML techniques in many domains, e.g., cybersecurity, natural language processing, bioinformatics, robotics and control, and medical information processing, among many others. Despite it has been contributed several works reviewing the State-of-the-Art on DL, all of them only tackled one aspect of the DL, which leads to an overall lack of knowledge about it. Therefore, in this contribution, we propose using a more holistic approach in order to provide a more suitable starting point from which to develop a full understanding of DL. Specifically, this review attempts to provide a more comprehensive survey of the most important aspects of DL and including those enhancements recently added to the field. In particular, this paper outlines the importance of DL, presents the types of DL techniques and networks. It then presents convolutional neural networks (CNNs) which the most utilized DL network type and describes the development of CNNs architectures together with their main features, e.g., starting with the AlexNet network and closing with the High-Resolution network (HR.Net). Finally, we further present the challenges and suggested solutions to help researchers understand the existing research gaps. It is followed by a list of the major DL applications. Computational tools including FPGA, GPU, and CPU are summarized along with a description of their influence on DL. The paper ends with the evolution matrix, benchmark datasets, and summary and conclusion.},
   author = {Laith Alzubaidi and Jinglan Zhang and Amjad J Humaidi and Ayad Al-Dujaili and Ye Duan and Omran Al-Shamma and J Santamaría and Mohammed A Fadhel and Muthana Al-Amidie and Laith Farhan},
   doi = {10.1186/s40537-021-00444-8},
   issn = {2196-1115},
   issue = {1},
   journal = {Journal of Big Data},
   pages = {53},
   title = {Review of deep learning: concepts, {CNN} architectures, challenges, applications, future directions},
   volume = {8},
   url = {https://doi.org/10.1186/s40537-021-00444-8},
   year = {2021},
}
@article{Thorpe2001,
   abstract = {Most experimental and theoretical studies of brain function assume that neurons transmit information as a rate code, but recent studies on the speed of visual processing impose temporal constraints that appear incompatible with such a coding scheme. Other coding schemes that use the pattern of spikes across a population a neurons may be much more efficient. For example, since strongly activated neurons tend to fire first, one can use the order of firing as a code. We argue that Rank Order Coding is not only very efficient, but also easy to implement in biological hardware: neurons can be made sensitive to the order of activation of their inputs by including a feed-forward shunting inhibition mechanism that progressively desensitizes the neuronal population during a wave of afferent activity. In such a case, maximum activation will only be produced when the afferent inputs are activated in the order of their synaptic weights. © 2001 Published by Elsevier Science Ltd.},
   author = {Simon Thorpe and Arnaud Delorme and Rufin Van Rullen},
   doi = {10.1016/S0893-6080(01)00083-1},
   issn = {08936080},
   issue = {6-7},
   journal = {Neural Networks},
   keywords = {Information,Latency,Rank Order Coding,Rapid visual processing,Retina,Spikes},
   pages = {715-725},
   pmid = {11665765},
   title = {Spike-based strategies for rapid processing},
   volume = {14},
   year = {2001},
}
@article{Krotov2019,
   abstract = {It is widely believed that end-to-end training with the backpropagation algorithm is essential for learning good feature detectors in early layers of artificial neural networks, so that these detectors are useful for the task performed by the higher layers of that neural network. At the same time, the traditional form of backpropagation is biologically implausible. In the present paper we propose an unusual learning rule, which has a degree of biological plausibility and which is motivated by Hebb’s idea that change of the synapse strength should be local—i.e., should depend only on the activities of the pre- and postsynaptic neurons. We design a learning algorithm that utilizes global inhibition in the hidden layer and is capable of learning early feature detectors in a completely unsupervised way. These learned lower-layer feature detectors can be used to train higher-layer weights in a usual supervised way so that the performance of the full network is comparable to the performance of standard feedforward networks trained end-to-end with a backpropagation algorithm on simple tasks.},
   author = {Dmitry Krotov and John J. Hopfield},
   doi = {10.1073/pnas.1820458116},
   issn = {10916490},
   issue = {16},
   journal = {Proceedings of the National Academy of Sciences of the United States of America},
   keywords = {Backpropagation,Biological deep learning,Hebbian-like plasticity},
   pages = {7723-7731},
   pmid = {30926658},
   title = {Unsupervised learning by competing hidden units},
   volume = {116},
   year = {2019},
}
@article{Poirazi2020,
   abstract = {Dendrites have always fascinated researchers: from the artistic drawings by Ramon y Cajal to the beautiful recordings of today, neuroscientists have been striving to unravel the mysteries of these structures. Theoretical work in the 1960s predicted important dendritic effects on neuronal processing, establishing computational modelling as a powerful technique for their investigation. Since then, modelling of dendrites has been instrumental in driving neuroscience research in a targeted manner, providing experimentally testable predictions that range from the subcellular level to the systems level, and their relevance extends to fields beyond neuroscience, such as machine learning and artificial intelligence. Validation of modelling predictions often requires — and drives — new technological advances, thus closing the loop with theory-driven experimentation that moves the field forward. This Review features the most important, to our understanding, contributions of modelling of dendritic computations, including those pending experimental verification, and highlights studies of successful interactions between the modelling and experimental neuroscience communities.},
   author = {Panayiota Poirazi and Athanasia Papoutsi},
   doi = {10.1038/s41583-020-0301-7},
   isbn = {4158302003017},
   issn = {14710048},
   issue = {6},
   journal = {Nature Reviews Neuroscience},
   pages = {303-321},
   pmid = {32393820},
   publisher = {Springer US},
   title = {Illuminating dendritic function with computational models},
   volume = {21},
   url = {http://dx.doi.org/10.1038/s41583-020-0301-7},
   year = {2020},
}
@article{Hawkins2016,
   abstract = {Pyramidal neurons represent the majority of excitatory neurons in the neocortex. Each pyramidal neuron receives input from thousands of excitatory synapses that are segregated onto dendritic branches. The dendrites themselves are segregated into apical, basal, and proximal integration zones, which have different properties. It is a mystery how pyramidal neurons integrate the input from thousands of synapses, what role the different dendrites play in this integration, and what kind of network behavior this enables in cortical tissue. It has been previously proposed that non-linear properties of dendrites enable cortical neurons to recognize multiple independent patterns. In this paper we extend this idea in multiple ways. First we show that a neuron with several thousand synapses segregated on active dendrites can recognize hundreds of independent patterns of cellular activity even in the presence of large amounts of noise and pattern variation. We then propose a neuron model where patterns detected on proximal dendrites lead to action potentials, defining the classic receptive field of the neuron, and patterns detected on basal and apical dendrites act as predictions by slightly depolarizing the neuron without generating an action potential. By this mechanism, a neuron can predict its activation in hundreds of independent contexts. We then present a network model based on neurons with these properties that learns time-based sequences. The network relies on fast local inhibition to preferentially activate neurons that are slightly depolarized. Through simulation we show that the network scales well and operates robustly over a wide range of parameters as long as the network uses a sparse distributed code of cellular activations. We contrast the properties of the new network model with several other neural network models to illustrate the relative capabilities of each. We conclude that pyramidal neurons with thousands of synapses, active dendrites, and multiple integration zones create a robust and powerful sequence memory. Given the prevalence and similarity of excitatory neurons throughout the neocortex and the importance of sequence memory in inference and behavior, we propose that this form of sequence memory may be a universal property of neocortical tissue.},
   author = {Jeff Hawkins and Subutai Ahmad},
   doi = {10.3389/fncir.2016.00023},
   issn = {16625110},
   issue = {March},
   journal = {Frontiers in Neural Circuits},
   keywords = {active dendrites,neocortex,neocortical theory,prediction,sequence memory},
   pages = {1-13},
   pmid = {27065813},
   title = {Why Neurons Have Thousands of Synapses, a Theory of Sequence Memory in Neocortex},
   volume = {10},
   year = {2016},
}
@article{Li2020,
   abstract = {In the nervous system, dendrites, branches of neurons that transmit signals between synapses and soma, play a critical role in processing functions, such as nonlinear integration of postsynaptic signals. The lack of these critical functions in artificial neural networks compromises their performance, for example in terms of flexibility, energy efficiency and the ability to handle complex tasks. Here, by developing artificial dendrites, we experimentally demonstrate a complete neural network fully integrated with synapses, dendrites and soma, implemented using scalable memristor devices. We perform a digit recognition task and simulate a multilayer network using experimentally derived device characteristics. The power consumption is more than three orders of magnitude lower than that of a central processing unit and 70 times lower than that of a typical application-specific integrated circuit chip. This network, equipped with functional dendrites, shows the potential of substantial overall performance improvement, for example by extracting critical information from a noisy background with significantly reduced power consumption and enhanced accuracy.},
   author = {Xinyi Li and Jianshi Tang and Qingtian Zhang and Bin Gao and J. Joshua Yang and Sen Song and Wei Wu and Wenqiang Zhang and Peng Yao and Ning Deng and Lei Deng and Yuan Xie and He Qian and Huaqiang Wu},
   doi = {10.1038/s41565-020-0722-5},
   isbn = {4156502007},
   issn = {17483395},
   issue = {9},
   journal = {Nature Nanotechnology},
   pages = {776-782},
   pmid = {32601451},
   publisher = {Springer US},
   title = {Power-efficient neural network with artificial dendrites},
   volume = {15},
   url = {http://dx.doi.org/10.1038/s41565-020-0722-5},
   year = {2020},
}
@article{Acharya2021,
   abstract = {In this paper, we discuss the nonlinear computational power provided by dendrites in biological and artificial neurons. We start by briefly presenting biological evidence about the type of dendritic nonlinearities, respective plasticity rules and their effect on biological learning as assessed by computational models. Four major computational implications are identified as improved expressivity, more efficient use of resources, utilizing internal learning signals, and enabling continual learning. We then discuss examples of how dendritic computations have been used to solve real-world classification problems with performance reported on well known data sets used in machine learning. The works are categorized according to the three primary methods of plasticity used—structural plasticity, weight plasticity, or plasticity of synaptic delays. Finally, we show the recent trend of confluence between concepts of deep learning and dendritic computations and highlight some future research directions.},
   author = {Jyotibdha Acharya and Arindam Basu and Robert Legenstein and Thomas Limbacher and Panayiota Poirazi and Xundong Wu},
   doi = {10.1016/j.neuroscience.2021.10.001},
   issn = {18737544},
   journal = {Neuroscience},
   keywords = {deep neural networks,expressivity,machine learning,maxout networks,non-linear dendrites,plasticity,rewiring},
   publisher = {IBRO},
   title = {Dendritic Computing: Branching Deeper into Machine Learning},
   url = {https://doi.org/10.1016/j.neuroscience.2021.10.001},
   year = {2021},
}
@article{Wu2018,
   abstract = {A typical biological neuron, such as a pyramidal neuron of the neocortex, receives thousands of afferent synaptic inputs on its dendrite tree and sends the efferent axonal output downstream. In typical artificial neural networks, dendrite trees are modeled as linear structures that funnel weighted synaptic inputs to the cell bodies. However, numerous experimental and theoretical studies have shown that dendritic arbors are far more than simple linear accumulators. That is, synaptic inputs can actively modulate their neighboring synaptic activities; therefore, the dendritic structures are highly nonlinear. In this study, we model such local nonlinearity of dendritic trees with our dendritic neural network (DENN) structure and apply this structure to typical machine learning tasks. Equipped with localized nonlinearities, DENNs can attain greater model expressivity than regular neural networks while maintaining efficient network inference. Such strength is evidenced by the increased fitting power when we train DENNs with supervised machine learning tasks. We also empirically show that the locality structure of DENNs can improve the generalization performance, as exemplified by DENNs outranking naive deep neural network architectures when tested on classification tasks from the UCI machine learning repository.},
   author = {Xundong Wu and Xiangwen Liu and Wei Li and Qing Wu},
   issn = {10495258},
   issue = {NeurIPS},
   journal = {Advances in Neural Information Processing Systems},
   pages = {8057-8068},
   title = {Improved expressivity through dendritic neural networks},
   volume = {2018-Decem},
   year = {2018},
}
@article{Shi2018,
   abstract = {Resistive RAM crossbar arrays offer an attractive solution to minimize off-chip data transfer and parallelize on-chip computations for neural networks. Here, we report a hardware/software co-design approach based on low energy subquantum conductive bridging RAM (CBRAM®) devices and a network pruning technique to reduce network level energy consumption. First, we demonstrate low energy subquantum CBRAM devices exhibiting gradual switching characteristics important for implementing weight updates in hardware during unsupervised learning. Then we develop a network pruning algorithm that can be employed during training, different from previous network pruning approaches applied for inference only. Using a 512 kbit subquantum CBRAM array, we experimentally demonstrate high recognition accuracy on the MNIST dataset for digital implementation of unsupervised learning. Our hardware/software co-design approach can pave the way towards resistive memory based neuro-inspired systems that can autonomously learn and process information in power-limited settings.},
   author = {Yuhan Shi and Leon Nguyen and Sangheon Oh and Xin Liu and Foroozan Koushan and John R. Jameson and Duygu Kuzum},
   doi = {10.1038/s41467-018-07682-0},
   issn = {20411723},
   issue = {1},
   journal = {Nature Communications},
   pages = {1-11},
   pmid = {30552329},
   publisher = {Springer US},
   title = {Neuroinspired unsupervised learning and pruning with subquantum CBRAM arrays},
   volume = {9},
   url = {http://dx.doi.org/10.1038/s41467-018-07682-0},
   year = {2018},
}
@article{Xue2021,
   abstract = {The development of small, energy-efficient artificial intelligence edge devices is limited in conventional computing architectures by the need to transfer data between the processor and memory. Non-volatile compute-in-memory (nvCIM) architectures have the potential to overcome such issues, but the development of high-bit-precision configurations required for dot-product operations remains challenging. In particular, input–output parallelism and cell-area limitations, as well as signal margin degradation, computing latency in multibit analogue readout operations and manufacturing challenges, still need to be addressed. Here we report a 2 Mb nvCIM macro (which combines memory cells and related peripheral circuitry) that is based on single-level cell resistive random-access memory devices and is fabricated in a 22 nm complementary metal–oxide–semiconductor foundry process. Compared with previous nvCIM schemes, our macro can perform multibit dot-product operations with increased input–output parallelism, reduced cell-array area, improved accuracy, and reduced computing latency and energy consumption. The macro can, in particular, achieve latencies between 9.2 and 18.3 ns, and energy efficiencies between 146.21 and 36.61 tera-operations per second per watt, for binary and multibit input–weight–output configurations, respectively.},
   author = {Cheng Xin Xue and Yen Cheng Chiu and Ta Wei Liu and Tsung Yuan Huang and Je Syu Liu and Ting Wei Chang and Hui Yao Kao and Jing Hong Wang and Shih Ying Wei and Chun Ying Lee and Sheng Po Huang and Je Min Hung and Shih Hsih Teng and Wei Chen Wei and Yi Ren Chen and Tzu Hsiang Hsu and Yen Kai Chen and Yun Chen Lo and Tai Hsing Wen and Chung Chuan Lo and Ren Shuo Liu and Chih Cheng Hsieh and Kea Tiong Tang and Mon Shu Ho and Chin Yi Su and Chung Cheng Chou and Yu Der Chih and Meng Fan Chang},
   doi = {10.1038/s41928-020-00505-5},
   issn = {25201131},
   issue = {1},
   journal = {Nature Electronics},
   pages = {81-90},
   publisher = {Springer US},
   title = {A CMOS-integrated compute-in-memory macro based on resistive random-access memory for AI edge devices},
   volume = {4},
   url = {http://dx.doi.org/10.1038/s41928-020-00505-5},
   year = {2021},
}
@article{Panda2018,
   abstract = {A fundamental feature of learning in animals is the 'ability to forget' that allows an organism to perceive, model, and make decisions from disparate streams of information and adapt to changing environments. Against this backdrop, we present a novel unsupervised learning mechanism adaptive synaptic plasticity (ASP) for improved recognition with spiking neural networks (SNNs) for real time online learning in a dynamic environment. We incorporate an adaptive weight decay mechanism with the traditional spike timing dependent plasticity (STDP) learning to model adaptivity in SNNs. The leak rate of the synaptic weights is modulated based on the temporal correlation between the spiking patterns of the pre- and post-synaptic neurons. This mechanism helps in gradual forgetting of insignificant data while retaining significant, yet old, information. ASP, thus, maintains a balance between forgetting and immediate learning to construct a stable-plastic self-adaptive SNN for continuously changing inputs. We demonstrate that the proposed learning methodology addresses catastrophic forgetting, while yielding significantly improved accuracy over the conventional STDP learning method for digit recognition applications. In addition, we observe that the proposed learning model automatically encodes selective attention toward relevant features in the input data, while eliminating the influence of background noise (or denoising) further improving the robustness of the ASP learning.},
   author = {Priyadarshini Panda and Jason M. Allred and Shriram Ramanathan and Kaushik Roy},
   doi = {10.1109/JETCAS.2017.2769684},
   issn = {21563357},
   issue = {1},
   journal = {IEEE Journal on Emerging and Selected Topics in Circuits and Systems},
   keywords = {Spiking neural networks,adaptive synaptic plasticity,catastrophic forgetting,learning to forget,spike timing dependent plasticity (STDP),unsupervised learning},
   pages = {51-64},
   title = {ASP: Learning to Forget with Adaptive Synaptic Plasticity in Spiking Neural Networks},
   volume = {8},
   year = {2018},
}
@article{Moon2019,
   abstract = {Time-series analysis including forecasting is essential in a range of fields from finance to engineering. However, long-term forecasting is difficult, particularly for cases where the underlying models and parameters are complex and unknown. Neural networks can effectively process features in temporal units and are attractive for such purposes. Reservoir computing, in particular, can offer efficient temporal processing of recurrent neural networks with a low training cost, and is thus well suited to time-series analysis and forecasting tasks. Here, we report a reservoir computing hardware system based on dynamic tungsten oxide (WOx) memristors that can efficiently process temporal data. The internal short-term memory effects of the WOx memristors allow the memristor-based reservoir to nonlinearly map temporal inputs into reservoir states, where the projected features can be readily processed by a linear readout function. We use the system to experimentally demonstrate two standard benchmarking tasks: isolated spoken-digit recognition with partial inputs, and chaotic system forecasting. A high classification accuracy of 99.2% is obtained for spoken-digit recognition, and autonomous chaotic time-series forecasting has been demonstrated over the long term.},
   author = {John Moon and Wen Ma and Jong Hoon Shin and Fuxi Cai and Chao Du and Seung Hwan Lee and Wei D Lu},
   doi = {10.1038/s41928-019-0313-3},
   issn = {2520-1131},
   issue = {10},
   journal = {Nature Electronics},
   pages = {480-487},
   title = {Temporal data classification and forecasting using a memristor-based reservoir computing system},
   volume = {2},
   url = {https://doi.org/10.1038/s41928-019-0313-3},
   year = {2019},
}
@generic{Lee2016,
   abstract = {Deep spiking neural networks (SNNs) hold the potential for improving the latency and energy efficiency of deep neural networks through data-driven event-based computation. However, training such networks is difficult due to the non-differentiable nature of spike events. In this paper, we introduce a novel technique, which treats the membrane potentials of spiking neurons as differentiable signals, where discontinuities at spike times are considered as noise. This enables an error backpropagation mechanism for deep SNNs that follows the same principles as in conventional deep networks, but works directly on spike signals and membrane potentials. Compared with previous methods relying on indirect training and conversion, our technique has the potential to capture the statistics of spikes more precisely. We evaluate the proposed framework on artificially generated events from the original MNIST handwritten digit benchmark, and also on the N-MNIST benchmark recorded with an event-based dynamic vision sensor, in which the proposed method reduces the error rate by a factor of more than three compared to the best previous SNN, and also achieves a higher accuracy than a conventional convolutional neural network (CNN) trained and tested on the same data. We demonstrate in the context of the MNIST task that thanks to their event-driven operation, deep SNNs (both fully connected and convolutional) trained with our method achieve accuracy equivalent with conventional neural networks. In the N-MNIST example, equivalent accuracy is achieved with about five times fewer computational operations.},
   author = {Jun Haeng Lee and Tobi Delbruck and Michael Pfeiffer},
   isbn = {1662-453X},
   journal = {Frontiers in Neuroscience  },
   title = {Training Deep Spiking Neural Networks Using Backpropagation   },
   volume = {10      },
   url = {https://www.frontiersin.org/article/10.3389/fnins.2016.00508},
   year = {2016},
}
@generic{Lee2020,
   abstract = {Spiking Neural Networks (SNNs) have recently emerged as a prominent neural computing paradigm. However, the typical shallow SNN architectures have limited capacity for expressing complex representations while training deep SNNs using input spikes has not been successful so far. Diverse methods have been proposed to get around this issue such as converting off-the-shelf trained deep Artificial Neural Networks (ANNs) to SNNs. However, the ANN-SNN conversion scheme fails to capture the temporal dynamics of a spiking system. On the other hand, it is still a difficult problem to directly train deep SNNs using input spike events due to the discontinuous, non-differentiable nature of the spike generation function. To overcome this problem, we propose an approximate derivative method that accounts for the leaky behavior of LIF neurons. This method enables training deep convolutional SNNs directly (with input spike events) using spike-based backpropagation. Our experiments show the effectiveness of the proposed spike-based learning on deep networks (VGG and Residual architectures) by achieving the best classification accuracies in MNIST, SVHN, and CIFAR-10 datasets compared to other SNNs trained with a spike-based learning. Moreover, we analyze sparse event-based computations to demonstrate the efficacy of the proposed SNN training method for inference operation in the spiking domain.},
   author = {Chankyu Lee and Syed Shakib Sarwar and Priyadarshini Panda and Gopalakrishnan Srinivasan and Kaushik Roy},
   isbn = {1662-453X},
   journal = {Frontiers in Neuroscience  },
   title = {Enabling Spike-Based Backpropagation for Training Deep Neural Network Architectures   },
   volume = {14      },
   url = {https://www.frontiersin.org/article/10.3389/fnins.2020.00119},
   year = {2020},
}
@article{Christensen2022,
   abstract = {Modern computation based on the von Neumann architecture is today a mature cutting-edge science. In the Von Neumann architecture, processing and memory units are implemented as separate blocks interchanging data intensively and continuously. This data transfer is responsible for a large part of the power consumption. The next generation computer technology is expected to solve problems at the exascale with 1018 calculations each second. Even though these future computers will be incredibly powerful, if they are based on von Neumann type architectures, they will consume between 20 and 30 megawatts of power and will not have intrinsic physically built-in capabilities to learn or deal with complex data as our brain does. These needs can be addressed by neuromorphic computing systems which are inspired by the biological concepts of the human brain. This new generation of computers has the potential to be used for the storage and processing of large amounts of digital information with much lower power consumption than conventional processors. Among their potential future applications, an important niche is moving the control from data centers to edge devices. The aim of this Roadmap is to present a snapshot of the present state of neuromorphic technology and provide an opinion on the challenges and opportunities that the future holds in the major areas of neuromorphic technology, namely materials, devices, neuromorphic circuits, neuromorphic algorithms, applications, and ethics. The Roadmap is a collection of perspectives where leading researchers in the neuromorphic community provide their own view about the current state and the future challenges for each research area. We hope that this Roadmap will be a useful resource by providing a concise yet comprehensive introduction to readers outside this field, for those who are just entering the field, as well as providing future perspectives for those who are well established in the neuromorphic computing community.},
   author = {Dennis Valbjørn Christensen and Regina Dittmann and Bernabe Linares-Barranco and Abu Sebastian and Manuel Le Gallo and Andrea Redaelli and Stefan Slesazeck and Thomas Mikolajick and Sabina Spiga and Stephan Menzel and Ilia Valov and Gianluca Milano and Carlo Ricciardi and Shi-Jun Liang and Feng Miao and Mario Lanza and Tyler J. Quill and Scott Tom Keene and Alberto Salleo and Julie Grollier and Danijela Markovic and Alice Mizrahi and Peng Yao and J. Joshua Yang and Giacomo Indiveri and John Paul Strachan and Suman Datta and Elisa Vianello and Alexandre Valentian and Johannes Feldmann and Xuan Li and Wolfram HP Pernice and Harish Bhaskaran and Steve Furber and Emre Neftci and Franz Scherr and Wolfgang Maass and Srikanth Ramaswamy and Jonathan Tapson and Priyadarshini Panda and Youngeun Kim and Gouhei Tanaka and Simon Thorpe and Chiara Bartolozzi and Thomas A Cleland and Christoph Posch and Shih-Chii Liu and Gabriella Panuccio and Mufti Mahmud and Arnab Neelim Mazumder and Morteza Hosseini and Tinoosh Mohsenin and Elisa Donati and Silvia Tolu and Roberto Galeazzi and Martin Ejsing Christensen and Sune Holm and Daniele Ielmini and Nini Pryds},
   doi = {10.1088/2634-4386/ac4a83},
   journal = {Neuromorphic Computing and Engineering},
   title = {2022 Roadmap on Neuromorphic Computing and Engineering},
   year = {2022},
}
@article{Hawkins2019,
   abstract = {How the neocortex works is a mystery. In this paper we propose a novel framework for understanding its function. Grid cells are neurons in the entorhinal cortex that represent the location of an animal in its environment. Recent evidence suggests that grid cell-like neurons may also be present in the neocortex. We propose that grid cells exist throughout the neocortex, in every region and in every cortical column. They define a location-based framework for how the neocortex functions. Whereas grid cells in the entorhinal cortex represent the location of one thing, the body relative to its environment, we propose that cortical grid cells simultaneously represent the location of many things. Cortical columns in somatosensory cortex track the location of tactile features relative to the object being touched and cortical columns in visual cortex track the location of visual features relative to the object being viewed. We propose that mechanisms in the entorhinal cortex and hippocampus that evolved for learning the structure of environments are now used by the neocortex to learn the structure of objects. Having a representation of location in each cortical column suggests mechanisms for how the neocortex represents object compositionality and object behaviors. It leads to the hypothesis that every part of the neocortex learns complete models of objects and that there are many models of each object distributed throughout the neocortex. The similarity of circuitry observed in all cortical regions is strong evidence that even high-level cognitive tasks are learned and represented in a location-based framework.},
   author = {Jeff Hawkins and Marcus Lewis and Mirko Klukas and Scott Purdy and Subutai Ahmad},
   doi = {10.3389/fncir.2018.00121},
   issn = {16625110},
   issue = {January},
   journal = {Frontiers in Neural Circuits},
   keywords = {Cortical column,Grid cell,Hierarchy,Neocortex,Neocortical theory,Object recognition},
   pages = {1-14},
   pmid = {30687022},
   title = {A framework for intelligence and cortical function based on grid cells in the neocortex},
   volume = {12},
   year = {2019},
}
@web_page{Wadehra2019,
   author = {Sunali Wadehra},
   journal = {Practical Pain Management},
   title = {Scientists pinpoints brain circuit that mediates pain},
   url = {https://patient.practicalpainmanagement.com/treatments/alternative/scientists-pinpoint-brain-circuit-mediates-pain},
   year = {2019},
}
@article{Starzyk1996,
   abstract = {Winner-take-all (WTA) is a usually used operation in neural network to locate the most activated neuron. This paper presents a voltage based winner-take-all circuit neural networks implemented in analog VLSI. In the presented WTA circuit, a winner follower mechanism is employed and the winner is chosen by comparing each winner with the output of the winner follower. SPICE simulation results are also presented.},
   author = {Janusz A. Starzyk and Ying Wei Jan},
   doi = {10.1109/mwscas.1996.594211},
   isbn = {0780336364},
   journal = {Midwest Symposium on Circuits and Systems},
   pages = {501-504},
   title = {Voltage based winner takes all circuit for analog neural networks},
   volume = {1},
   year = {1996},
}
@article{Liang2021,
   author = {Fu-Xiang Liang and I-Ting Wang and Tuo-Hung Hou},
   doi = {10.1002/aisy.202100007},
   issn = {2640-4567},
   issue = {8},
   journal = {Advanced Intelligent Systems},
   keywords = {in-memory computing, neuromorphic computing, spiki},
   pages = {2100007},
   title = {Progress and Benchmark of Spiking Neuron Devices and Circuits},
   volume = {3},
   year = {2021},
}
@article{Pedregosa2011,
   author = {Fabian Pedregosa and Gaël Varoquaux and Alexandre Gramfort and Vincent Michel and Bertrand Thirion and Olivier Grisel and Mathieu Blondel and Peter Prettenhofer and Ron Weiss and Vincent Dubourg and Jake Vanderplas and Alexandre Passos and David Cournapeau and Matthieu Brucher and Matthieu Perrot and Édouard Duchesnay},
   issue = {85},
   journal = {Journal of Machine Learning Research},
   pages = {2825-2830},
   title = {Scikit-learn: Machine Learning in Python},
   volume = {12},
   url = {http://jmlr.org/papers/v12/pedregosa11a.html},
   year = {2011},
}
@article{Barupal2019,
   abstract = {BACKGROUND: Blood chemicals are routinely measured in clinical or preclinical research studies to diagnose diseases, assess risks in epidemiological research, or use metabolomic phenotyping in response to treatments. A vast volume of blood-related literature is available via the PubMed database for data mining. OBJECTIVES: We aimed to generate a comprehensive blood exposome database of endogenous and exogenous chemicals associated with the mammalian circulating system through text mining and database fusion. METHODS: Using NCBI resources, we retrieved PubMed abstracts, PubChem chemical synonyms, and PMC supplementary tables. We then employed text mining and PubChem crowdsourcing to associate phrases relating to blood with PubChem chemicals. False positives were removed by a phrase pattern and a compound exclusion list. RESULTS: A query to identify blood-related publications in the PubMed database yielded 1.1 million papers. Matching a total of 15 million synonyms from 6.5 million relevant PubChem chemicals against all blood-related publications yielded 37,514 chemicals and 851,999 publications records. Mapping PubChem compound identifiers to the PubMed database yielded 49,940 unique chemicals linked to 676,643 papers. Analysis of open-access metabolomics papers related to blood phrases in the PMC database yielded 4,039 unique compounds and 204 papers. Consolidating these three approaches summed up to a total of 41,474 achiral structures that were linked to 65,957 PubChem CIDs and to over 878,966 PubMed articles. We mapped these compounds to 50 databases such as those covering metabolites and pathways, governmental and toxicological databases, pharmacology resources, and bioassay repositories. In comparison, HMDB, the Human Metabolome Database, links 1,075 compounds to blood-related primary publications. CONCLUSION: This new Blood Exposome Database can be used for prioritizing chemicals for systematic reviews, developing target assays in exposome research, identifying compounds in untargeted mass spectrometry, and biological interpretation in metabolomics data. The database is available at http://bloodexposome.org. https://doi.org/10.1289/EHP4713.},
   author = {Dinesh Kumar Barupal and Oliver Fiehn},
   doi = {10.1289/EHP4713},
   issn = {15529924},
   issue = {9},
   journal = {Environmental Health Perspectives},
   pages = {2825-2830},
   pmid = {31557052},
   title = {Generating the blood exposome database using a comprehensive text mining and database fusion approach},
   volume = {127},
   year = {2019},
}
@article{Yin2018,
   abstract = {We present a new back propagation based training algorithm for discrete-time spiking neural networks (SNN). Inspired by recent deep learning algorithms on binarized neural networks, binary activation with a straight-through gradient estimator is used to model the leaky integrate-fire spiking neuron, overcoming the difficulty in training SNNs using back propagation. Two SNN training algorithms are proposed: (1) SNN with discontinuous integration, which is suitable for rate-coded input spikes, and (2) SNN with continuous integration, which is more general and can handle input spikes with temporal information. Neuromorphic hardware designed in 28nm CMOS exploits the spike sparsity and demonstrates high classification accuracy (>98% on MNIST) and low energy (51.4-773 nJ/image).},
   author = {Shihui Yin and Shreyas K. Venkataramanaiah and Gregory K. Chen and Ram Krishnamurthy and Yu Cao and Chaitali Chakrabarti and Jae Sun Seo},
   doi = {10.1109/BIOCAS.2017.8325230},
   isbn = {9781509058037},
   journal = {2017 IEEE Biomedical Circuits and Systems Conference, BioCAS 2017 - Proceedings},
   keywords = {Spiking neural networks,back propagation,neuromorphic hardware,straight-through estimator},
   pages = {1-4},
   title = {Algorithm and hardware design of discrete-time spiking neural networks based on back propagation with binary activations},
   volume = {2018-Janua},
   year = {2018},
}
@article{Mozafari2019,
   abstract = {The primate visual system has inspired the development of deep artificial neural networks, which have revolutionized the computer vision domain. Yet these networks are much less energy-efficient than their biological counterparts, and they are typically trained with backpropagation, which is extremely data-hungry. To address these limitations, we used a deep convolutional spiking neural network (DCSNN) and a latency-coding scheme. We trained it using a combination of spike-timing-dependent plasticity (STDP) for the lower layers and reward-modulated STDP (R-STDP) for the higher ones. In short, with R-STDP a correct (resp. incorrect) decision leads to STDP (resp. anti-STDP). This approach led to an accuracy of 97.2% on MNIST, without requiring an external classifier. In addition, we demonstrated that R-STDP extracts features that are diagnostic for the task at hand, and discards the other ones, whereas STDP extracts any feature that repeats. Finally, our approach is biologically plausible, hardware friendly, and energy-efficient.},
   author = {Milad Mozafari and Mohammad Ganjtabesh and Abbas Nowzari-Dalini and Simon J. Thorpe and Timothée Masquelier},
   doi = {10.1016/j.patcog.2019.05.015},
   issn = {00313203},
   journal = {Pattern Recognition},
   keywords = {Deep architecture,Digit recognition,Latency coding,Reward-modulated STDP,STDP,Spiking neural networks},
   pages = {87-95},
   publisher = {Elsevier Ltd},
   title = {Bio-inspired digit recognition using reward-modulated spike-timing-dependent plasticity in deep convolutional networks},
   volume = {94},
   url = {https://doi.org/10.1016/j.patcog.2019.05.015},
   year = {2019},
}
@inproceedings{Wang2020,
   author = {X Wang and Q Wang and F -H. Meng and S H Lee and W D Lu},
   doi = {10.1109/AICAS48895.2020.9073942},
   isbn = {VO  -},
   journal = {2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS)},
   pages = {141-144},
   title = {Deep Neural Network Mapping and Performance Analysis on Tiled RRAM Architecture},
   year = {2020},
}
@article{Wang2022-taichi,
   author = {X Wang and R Pinkham and M A Zidan and F -H. Meng and M P Flynn and Z Zhang and W D Lu},
   doi = {10.1109/TCSII.2021.3097035},
   issn = {1558-3791 VO  - 69},
   issue = {2},
   journal = {IEEE Transactions on Circuits and Systems II: Express Briefs},
   pages = {559-563},
   title = {TAICHI: A Tiled Architecture for In-Memory Computing and Heterogeneous Integration},
   volume = {69},
   year = {2022},
}
@article{Jones2000,
   author = {E. G. Jones},
   doi = {10.1073/pnas.97.10.5019},
   issn = {00278424},
   issue = {10},
   journal = {Proceedings of the National Academy of Sciences of the United States of America},
   pages = {5019-5021},
   pmid = {10805761},
   title = {Microcolumns in the cerebral cortex},
   volume = {97},
   year = {2000},
}
@article{Yoo2022,
   abstract = {Abstract Memristive devices have demonstrated rich switching behaviors that closely resemble synaptic functions and provide a building block to construct efficient neuromorphic systems. It is demonstrated that resistive switching effects are controlled not only by the external field, but also by the dynamics of various internal state variables that facilitate the ionic processes. The internal temperature, for example, works as a second-state variable to regulate the ion motion and provides the internal timing mechanism for the native implementation of timing- and rate-based learning rules such as spike timing dependent plasticity (STDP). In this work, it is shown that the 2nd state-variable in a Ta2O5-based memristor, its internal temperature, can be systematically engineered by adjusting the material properties and device structure, leading to tunable STDP characteristics with different time constants. When combined with an artificial post-synaptic neuron, the 2nd-order memristor synapses can spontaneously capture the temporal correlation in the input streaming events.},
   author = {Sangmin Yoo and Yuting Wu and Yongmo Park and Wei D Lu},
   doi = {https://doi.org/10.1002/aelm.202101025},
   issn = {2199-160X},
   issue = {8},
   journal = {Advanced Electronic Materials},
   keywords = {2nd order memristors,correlation detection,neuromorphic computing,spike-timing dependent plasticity,spiking neural network (SNN)},
   month = {2},
   note = {https://doi.org/10.1002/aelm.202101025},
   pages = {2101025},
   publisher = {John Wiley & Sons, Ltd},
   title = {Tuning Resistive Switching Behavior by Controlling Internal Ionic Dynamics for Biorealistic Implementation of Synaptic Plasticity},
   volume = {8},
   url = {https://doi.org/10.1002/aelm.202101025},
   year = {2022},
}
@web_page{Jackson2018,
   author = {Zohar Jackson and César Souza and Jason Flaks and Yuxin Pan and Hereman Nicolas and Adhish Thite},
   journal = {github},
   title = {Jakobovski/free-spoken-digit-dataset: v1. 0.8.},
   url = {http://github.com/Jakobovski/free-spoken-digit-dataset},
   year = {2018},
}
@article{Deng2012,
   author = {L Deng},
   doi = {10.1109/MSP.2012.2211477},
   issn = {1558-0792 VO  - 29},
   issue = {6},
   journal = {IEEE Signal Processing Magazine},
   pages = {141-142},
   title = {The MNIST Database of Handwritten Digit Images for Machine Learning Research [Best of the Web]},
   volume = {29},
   year = {2012},
}
@article{Rakic2009,
   abstract = {In spite of its stereotypic laminar and columnar organization, the cerebral neocortex displays numerous species-specific adaptations of old and acquired new traits that subserve specific functions introduced during 100 million years of mammalian evolution.The human neocortex, a substrate of our unique cognitive abilities, has many distinct traits in addition to a larger surface, including different places of neuronal origin, distinct migratory pathways and acquisition of new cell types that were traditionally studied by comparative anatomists.The contemporary, evo–devo approach uses developmental principles and mechanisms uncovered by experiments in embryos of living species to obtain a glimpse into how the human neocortex may have developed at the cellular and molecular level in extinct common ancestors.The radial unit model of cortical evolution provides insight into how mutation of genes that control the transition from the symmetric to asymmetric mode of cell division in the proliferative ventricular zone subjected to radial constraint during migration can generate neocortical expansion in surface rather than in thickness.The protomap hypothesis of differential enlargement of the existing and introduction of new cytoarchitectonic areas has been tested in mouse embryos by mutation and/or changes of gene expression and transcriptional factors in the neural stem cells of the proliferative ventricular and subventricular zones.Understanding of the species-specific difference in tempo and sequence of cortical development as well as genesis of new cell subtypes, functional columns and synaptic connectivity is essential for design of therapies for trauma, congenital malformations, neurodegenerative disorders and ageing of the human cerebral neocortex.},
   author = {Pasko Rakic},
   doi = {10.1038/nrn2719},
   issn = {1471-0048},
   issue = {10},
   journal = {Nature Reviews Neuroscience},
   pages = {724-735},
   title = {Evolution of the neocortex: a perspective from developmental biology},
   volume = {10},
   url = {https://doi.org/10.1038/nrn2719},
   year = {2009},
}
@generic{Hawkins2017,
   abstract = {Neocortical regions are organized into columns and layers. Connections between layers run mostly perpendicular to the surface suggesting a columnar functional organization. Some layers have long-range excitatory lateral connections suggesting interactions between columns. Similar patterns of connectivity exist in all regions but their exact role remain a mystery. In this paper, we propose a network model composed of columns and layers that performs robust object learning and recognition. Each column integrates its changing input over time to learn complete predictive models of observed objects. Excitatory lateral connections across columns allow the network to more rapidly infer objects based on the partial knowledge of adjacent columns. Because columns integrate input over time and space, the network learns models of complex objects that extend well beyond the receptive field of individual cells. Our network model introduces a new feature to cortical columns. We propose that a representation of location relative to the object being sensed is calculated within the sub-granular layers of each column. The location signal is provided as an input to the network, where it is combined with sensory data. Our model contains two layers and one or more columns. Simulations show that using Hebbian-like learning rules small single-column networks can learn to recognize hundreds of objects, with each object containing tens of features. Multi-column networks recognize objects with significantly fewer movements of the sensory receptors. Given the ubiquity of columnar and laminar connectivity patterns throughout the neocortex, we propose that columns and regions have more powerful recognition and modeling capabilities than previously assumed.},
   author = {Jeff Hawkins and Subutai Ahmad and Yuwei Cui},
   isbn = {1662-5110},
   journal = {Frontiers in Neural Circuits  },
   title = {A Theory of How Columns in the Neocortex Enable Learning the Structure of the World   },
   volume = {11      },
   url = {https://www.frontiersin.org/article/10.3389/fncir.2017.00081},
   year = {2017},
}
@article{Spruston2008,
   abstract = {Pyramidal neurons have basal and apical dendrites, including an apical tuft. This preserved core structure suggests that they have conserved core functions, whereas structural variation in other areas suggests additional functional specialization.A number of new methods for studying pyramidal-cell activation and circuitry are available. These include in vivo patch-clamp recording, optical activation and transgenic methods for activating, inactivating or labelling neurons and their connections.Synaptic inputs from distinct sources occur onto separate dendritic domains. Defining the degree to which synapses that carry different kinds of information are segregated onto different dendritic domains remains an important challenge.Most excitatory synapses onto pyramidal neurons occur on dendritic spines, but the structure of the synapses they receive differs between dendritic domains.Dendritic integration of synaptic input depends on the dendritic domain that is targeted. Synapses distant from the soma tend to produce less synaptic depolarization, but this might be countered by increasing the conductance of distal synapses or by activating voltage-gated channels in dendrites. Synapses on small-diameter dendrites cause larger local voltage changes, which reduce the effectiveness of synaptic scaling but increase the activation of voltage-gated conductances.Inhibitory synapses specifically target the axon, soma or different dendritic domains. Integration of inhibitory inputs also differs across cellular domains.The intrinsic firing properties of pyramidal neurons vary considerably. Along with variation in dendritic structure and channel distributions, such variability suggests that different pyramidal neurons might carry out specialized functions.Pyramidal-neuron dendrites contain voltage-gated channels that can influence synaptic integration. These channels can also support backpropagating action potentials and dendritically initiated spikes. Dendritic excitability is a general property of all pyramidal neurons studied so far, but the details differ between different types of pyramidal neurons. Although there is some evidence for dendritic excitability in vivo, much more work is needed in this area.Activation of a small fraction of the tens of thousands of excitatory synapses on a pyramidal neuron can probably evoke dendritic spikes, but these events do not always propagate to the soma and the axon. The coupling of dendritic spikes to axonal action-potential firing probably depends on the pattern of synaptic activation. This results in forms of coincidence detection that are determined by dendritic structure and excitability.Backpropagating action potentials and dendritic spikes are important signals for the induction of synaptic plasticity. Even single dendritic spikes can result in significant long-term potentiation or long-term depression.Neurotransmitters can modulate pyramidal-neuron function. At least some forms of modulation affect various dendritic domains and their synaptic inputs in different ways.Domain-specific properties in excitatory and inhibitory synaptic inputs, voltage-gated channels, dendritic excitability and neuromodulation all point to a multi-compartment model of pyramidal-neuron function. Elaborating simple models of pyramidal-neuron function based on these dendritic-domain-specific properties is a central challenge for the study of cortical function.},
   author = {Nelson Spruston},
   doi = {10.1038/nrn2286},
   issn = {1471-0048},
   issue = {3},
   journal = {Nature Reviews Neuroscience},
   pages = {206-221},
   title = {Pyramidal neurons: dendritic structure and synaptic integration},
   volume = {9},
   url = {https://doi.org/10.1038/nrn2286},
   year = {2008},
}
@article{,
   abstract = {The paper proposes a way of bridging the gapbetween physical processes in the brain and the ''felt''aspect of sensory experience. The approach is based onthe idea that experience is not generated by brainprocesses themselves, but rather is constituted by theway these brain processes enable a particular form of''give-and-take'' between the perceiver and theenvironment. From this starting-point we are able tocharacterize the phenomenological differences betweenthe different sensory modalities in a more principledway than has been done in the past. We are also ableto approach the issues of visual awareness andconsciousness in a satisfactory way. Finally weconsider a number of testable empirical consequences,one of which is the striking prediction of thephenomenon of ''change blindness''.},
   author = {J Kevin O'Regan and Alva noë},
   doi = {10.1023/A:1012699224677},
   issn = {1573-0964},
   issue = {1},
   journal = {Synthese},
   pages = {79-103},
   title = {What it is like to see: A sensorimotor theory of perceptual experience},
   volume = {129},
   url = {https://doi.org/10.1023/A:1012699224677},
   year = {2001},
}
@article{Walter2016,
   abstract = {Over the last years, the amount of research performed in the field of spiking neural networks has been growing steadily. Spiking neurons are modeled to approximate the complex dynamic behavior of biological neurons. They communicate via discrete impulses called spikes with the actual information being encoded in the timing of these spikes. As already pointed out by Maass in his paper on the third generation of neural network models, this renders time a central factor for neural computation. In this paper, we investigate at different levels of granularity how absolute time and relative timing enable new ways of biologically inspired neural information processing. At the lowest level of single spiking neurons, we give an overview of coding schemes and learning techniques which rely on precisely timed neural spikes. A high-level perspective is provided in the second part of the paper which focuses on the role of time at the network level. The third aspect of time considered in this work is related to the interfacing of neural networks with real-time systems. In this context, we discuss how the concepts of computation by time can be implemented in computer simulations and on specialized neuromorphic hardware. The contributions of this paper are twofold: first, we show how the exact modeling of time in spiking neural networks serves as an important basis for powerful computation based on neurobiological principles. Second, by presenting a range of diverse learning techniques, we prove the biologically plausible applicability of spiking neural networks to real world problems like pattern recognition and path planning.},
   author = {Florian Walter and Florian Röhrbein and Alois Knoll},
   doi = {10.1007/s11063-015-9478-6},
   issn = {1573-773X},
   issue = {1},
   journal = {Neural Processing Letters},
   pages = {103-124},
   title = {Computation by Time},
   volume = {44},
   url = {https://doi.org/10.1007/s11063-015-9478-6},
   year = {2016},
}
@book{Schmidt2010,
   author = {Klaus Gerhard Schmidt},
   isbn = {9783540778769},
   journal = {VDI Heat Atlas},
   pages = {1271-1278},
   publisher = {Springer-Verlag Berlin Heidelberg},
   title = {Heat ATLAS},
   year = {2010},
}
@web_page{,
   author = {Marlene Spittel and Thilo Spittel},
   doi = {10.1007/978-3-642-14174-4_4},
   editor = {Hans Warlimont},
   note = {Copyright 2016 Springer-Verlag Berlin Heidelberg},
   publisher = {Springer-Verlag Berlin Heidelberg},
   title = {Mechanical and physical properties of alloys and metals: Datasheet from Landolt-Börnstein - Group VIII Advanced Materials and Technologies · Volume 2C3: "Part 3: Non-ferrous Alloys - Heavy Metals" in SpringerMaterials (https://doi.org/10.1007/978-3-642-14},
   url = {https://materials.springer.com/lb/docs/sm_lbs_978-3-642-14174-4_4},
}
@book{,
   author = {G Neuer},
   doi = {10.1007/10031435_58},
   editor = {O Madelung and G K White},
   note = {Copyright 1991 Springer-Verlag Berlin Heidelberg},
   publisher = {Springer-Verlag Berlin Heidelberg},
   title = {3.3.3.7 Ni-based alloys: Datasheet from Landolt-Börnstein - Group III Condensed Matter · Volume 15C: "Thermal Conductivity of Pure Metals and Alloys" in SpringerMaterials (https://doi.org/10.1007/10031435_58)},
   url = {https://materials.springer.com/lb/docs/sm_lbs_978-3-540-46730-7_58},
}
@book{,
   author = {Matthias Neubronner and Thomas Bodmer and Christof Hübner and Paul Bernd Kempa and Evangelos Tsotsas and Axel Eschner and Günther Kasparek and Fabian Ochs and Hans Müller-Steinhagen and Hans Werner and Martin H Spitzner},
   note = {Copyright 2010 Springer-Verlag},
   publisher = {Springer-Verlag},
   title = {D6 Properties of Solids and Solid Materials: Datasheet from VDI-Buch · Volume : "VDI Heat Atlas" in SpringerMaterials (https://doi.org/10.1007/978-3-540-77877-6_26)},
   url = {https://materials.springer.com/lb/docs/sm_nlb_978-3-540-77877-6_26},
}
@article{Kim2013,
   abstract = {Tantalum-oxide-based bi-layered resistance-change memories (RRAMs) have recently improved greatly with regard to their memory performances. The formation and rupture of conductive filaments is generally known to be the mechanism that underlies resistive switching. The nature of the filament has been studied intensively and several phenomenological models have consistently predicted the resistance-change behavior. However, a physics-based model that describes a complete bi-layered RRAM structure has not yet been demonstrated. Here, a complete electro-thermal resistive switching model based on the finite element method is proposed. The migration of oxygen vacancies is simulated by the local temperature and electric field derived from carrier continuity and heat equations fully coupled in a 3-D geometry, which considers a complete bi-layered structure that includes the top and bottom electrodes. The proposed model accurately accounts for the set/reset characteristics, which provides an in-depth understanding of the nature of resistive switching.},
   author = {Sungho Kim and Sae-Jin Kim and Kyung Min Kim and Seung Ryul Lee and Man Chang and Eunju Cho and Young-Bae Kim and Chang Jung Kim and U -In Chung and In-Kyeong Yoo},
   doi = {10.1038/srep01680},
   issn = {2045-2322},
   issue = {1},
   journal = {Scientific Reports},
   pages = {1680},
   title = {Physical electro-thermal model of resistive switching in bi-layered resistance-change memory},
   volume = {3},
   url = {https://doi.org/10.1038/srep01680},
   year = {2013},
}
@article{Kim2014,
   abstract = {Memristors have been proposed for a number of applications from nonvolatile memory to neuromorphic systems. Unlike conventional devices based solely on electron transport, memristors operate on the principle of resistive switching (RS) based on redistribution of ions. To date, a number of experimental and modeling studies have been reported to probe the RS mechanism; however, a complete physical picture that can quantitatively describe the dynamic RS behavior is still missing. Here, we present a quantitative and accurate dynamic switching model that not only fully accounts for the rich RS behaviors in memristors in a unified framework but also provides critical insight for continued device design, optimization, and applications. The proposed model reveals the roles of electric field, temperature, oxygen vacancy concentration gradient, and different material and device parameters on RS and allows accurate predictions of diverse set/reset, analog switching, and complementary RS behaviors using only material-dependent device parameters. © 2014 American Chemical Society.},
   author = {Sungho Kim and Shinhyun Choi and Wei Lu},
   doi = {10.1021/nn405827t},
   issn = {1936086X},
   issue = {3},
   journal = {ACS Nano},
   keywords = {diffusion,drift,memristor,oxygen vacancy,physical model},
   pages = {2369-2376},
   title = {Comprehensive physical model of dynamic resistive switching in an oxide memristor},
   volume = {8},
   year = {2014},
}
@web_page{,
   journal = {Periodictable},
   pages = {https://periodictable.com/Elements/046/data.html},
   title = {Technical data for Palladium},
   url = {https://periodictable.com/Elements/046/data.html},
}
@web_page{,
   journal = {Reade},
   title = {Nickel-Chromium Alloys (NiCr)},
   url = {https://www.reade.com/products/nickel-chromium-alloys-nicr},
}
@web_page{,
   author = {AZO},
   journal = {AZOM},
   title = {Palladium (Pd) - Properties, Applications},
   url = {https://www.azom.com/properties.aspx?ArticleID=1339},
}
@article{Wu2021,
   author = {Yuting Wu and John Moon and Xiaojian Zhu and Wei D Lu},
   doi = {10.1002/aisy.202000276},
   journal = {Advanced Intelligent System},
   keywords = {connectivity reconstructions,memristors,neural signal analysis,spike-timing-dependent plasticity},
   title = {Neural Functional Connectivity Reconstruction with Second-Order Memristor Network},
   volume = {3},
   year = {2021},
}
@article{Prezioso2018,
   author = {M Prezioso and M R Mahmoodi and F Merrikh Bayat and H Nili and H Kim and A Vincent and D B Strukov},
   doi = {10.1038/s41467-018-07757-y},
   issn = {2041-1723},
   issue = {1},
   journal = {Nature Communications},
   pages = {1-8},
   publisher = {Springer US},
   title = {Spike-timing-dependent plasticity learning of coincidence detection with passively integrated memristive circuits},
   volume = {9},
   url = {http://dx.doi.org/10.1038/s41467-018-07757-y},
   year = {2018},
}
@article{Serrano-Gotarredona2013,
   author = {T. Serrano-Gotarredona and T. Masquelier and T. Prodromakis and G. Indiveri and B. Linares-Barranco},
   doi = {10.3389/fnins.2013.00002},
   journal = {frontiers in Neuroscience},
   keywords = {artificial-learning-synapses,cmos,memristor,memristor/cmos,spike-timing-dependent-plasticity,spiking-neural-networks},
   pages = {1-15},
   title = {STDP and STDP variations with memristors for spiking neuromorphic learning systems},
   volume = {7},
   year = {2013},
}
@article{Schimidt2010,
   author = {Aaron J. Schimidt and Ramez Cheaito and Matteo Chiesa},
   doi = {10.1063/1.3289907},
   issue = {2},
   journal = {Journal of Applied Physics},
   title = {Characterization of thin metal films via frequency-domain thermoreflectance},
   volume = {107},
   year = {2010},
}
@article{Yu2011,
   author = {Shimeng Yu and Student Member and Yi Wu and Rakesh Jeyasingh and Duygu Kuzum and H Philip Wong},
   issue = {8},
   journal = {IEEE Transactions on Electron Devices},
   pages = {2729-2737},
   title = {An Electronic Synapse Device Based on Metal Oxide Resistive Switching Memory for Neuromorphic Computation},
   volume = {58},
   year = {2011},
}
@article{Yang1999,
   author = {Shao-nian Yang and Yun-gui Tang and Robert S Zucker},
   journal = {Journal of Neurophysiology},
   pages = {781-787},
   title = {Selective Induction of LTP and LTD by Postsynaptic [Ca2+]i Elevation},
   volume = {81},
   year = {1999},
}
@article{Zhang2005,
   author = {Xing Zhang and Huaqing Xie and Motoo Fuji and Hiroki Ago and Koji Takahashi and Tatsuya Ikuta and Hidekazu Abe and Tetsuo Shimizu},
   doi = {10.1063/1.1921350},
   journal = {Applied Physics Letters},
   title = {Thermal and electrical conductivity of a suspended platinum nanofilm},
   volume = {86},
   year = {2005},
}
@article{Lee2019,
   author = {Jihang Lee and William Schell and Xiaojian Zhu and Emmanouil Kioupakis and Wei D Lu},
   doi = {10.1021/acsami.8b18386},
   issn = {1944-8244},
   issue = {12},
   journal = {ACS Applied Materials & Interfaces},
   month = {3},
   note = {doi: 10.1021/acsami.8b18386},
   pages = {11579-11586},
   publisher = {American Chemical Society},
   title = {Charge Transition of Oxygen Vacancies during Resistive Switching in Oxide-Based RRAM},
   volume = {11},
   url = {https://doi.org/10.1021/acsami.8b18386},
   year = {2019},
}
@article{Sebastian2017,
   author = {Abu Sebastian and Tomas Tuma and Nikolaos Papandreou and Manuel Le Gallo and Lukas Kull and Thomas Parnell and Evangelos Eleftheriou},
   doi = {10.1038/s41467-017-01481-9},
   isbn = {4146701701481},
   issn = {2041-1723},
   issue = {1},
   journal = {Nature Communications},
   pages = {1-10},
   publisher = {Springer US},
   title = {Temporal correlation detection using computational phase-change memory},
   volume = {8},
   url = {http://dx.doi.org/10.1038/s41467-017-01481-9},
   year = {2017},
}
@article{Jo2010,
   abstract = {A memristor is a two-terminal electronic device whose conductance can be precisely modulated by charge or flux through it. Here we experimentally demonstrate a nanoscale silicon-based memristor device and show that a hybrid system composed of complementary metal?oxide semiconductor neurons and memristor synapses can support important synaptic functions such as spike timing dependent plasticity. Using memristors as synapses in neuromorphic circuits can potentially offer both high connectivity and high density required for efficient computing. © 2010 American Chemical Society.},
   author = {Sung Hyun Jo and Ting Chang and Idongesit Ebong and Bhavitavya B. Bhadviya and Pinaki Mazumder and Wei Lu},
   doi = {10.1021/nl904092h},
   issn = {15306984},
   issue = {4},
   journal = {Nano Letters},
   pages = {1297-1301},
   title = {Nanoscale memristor device as synapse in neuromorphic systems},
   volume = {10},
   year = {2010},
}
@article{Guo2019,
   author = {Yilong Guo and Huaqiang Wu and Bin Gao and He Qian},
   doi = {10.3389/fnins.2019.00812},
   journal = {frontiers in Neuroscience},
   keywords = {1T1R RRAM,1t1r rram,RRAM (resistive random access memories),STDP,memories,memristor,resistive random access,rram,snn,spiking neural network,spiking neural network (SNN),stdp,unsupervised learning},
   pages = {1-16},
   title = {Unsupervised Learning on Resistive Memory Array Based Spiking Neural Networks},
   volume = {13},
   year = {2019},
}
@generic{Diehl2015,
   abstract = {In order to understand how the mammalian neocortex is performing computations, two things are necessary; we need to have a good understanding of the available neuronal processing units and mechanisms, and we need to gain a better understanding of how those mechanisms are combined to build functioning systems. Therefore, in recent years there is an increasing interest in how spiking neural networks (SNN) can be used to perform complex computations or solve pattern recognition tasks. However, it remains a challenging task to design SNNs which use biologically plausible mechanisms (especially for learning new patterns), since most such SNN architectures rely on training in a rate-based network and subsequent conversion to a SNN. We present a SNN for digit recognition which is based on mechanisms with increased biological plausibility, i.e., conductance-based instead of current-based synapses, spike-timing-dependent plasticity with time-dependent weight change, lateral inhibition, and an adaptive spiking threshold. Unlike most other systems, we do not use a teaching signal and do not present any class labels to the network. Using this unsupervised learning scheme, our architecture achieves 95% accuracy on the MNIST benchmark, which is better than previous SNN implementations without supervision. The fact that we used no domain-specific knowledge points toward the general applicability of our network design. Also, the performance of our network scales well with the number of neurons used and shows similar performance for four different learning rules, indicating robustness of the full combination of mechanisms, which suggests applicability in heterogeneous biological neural networks.},
   author = {Peter Diehl and Matthew Cook},
   isbn = {1662-5188},
   journal = {Frontiers in Computational Neuroscience  },
   pages = {99},
   title = {Unsupervised learning of digit recognition using spike-timing-dependent plasticity   },
   volume = {9      },
   url = {https://www.frontiersin.org/article/10.3389/fncom.2015.00099},
   year = {2015},
}
@article{Tuma2016,
   author = {Tomas Tuma and Manuel Le Gallo and Abu Sebastian and Senior Member},
   issue = {9},
   journal = {IEEE Electron Device Lett},
   pages = {1238-1241},
   publisher = {IEEE},
   title = {Detecting Correlations Using Phase-Change Neurons and Synapses},
   volume = {37},
   year = {2016},
}
@working_paper{SIA2013,
   abstract = {The International Technology Roadmap for Semiconductors is sponsored by the five leading chip manufacturing regions in the world: Europe, Japan, Korea, Taiwan, and the United States. The sponsoring organizations are the European Semiconductor Industry Association (ESIA), the Japan Electronics and Information Technology Industries Association (JEITA), the Korean Semiconductor Industry Association (KSIA), the Taiwan Semiconductor Industry Association (TSIA), and the United States Semiconductor Industry Association (SIA). The objective of the ITRS is to ensure cost-effective advancements in the performance of the integrated circuit and the products that employ such devices, thereby continuing the health and success of this industry.},
   author = {SIA},
   issn = {0018-9162},
   institution = {SIA},
   journal = {International Technology Roadmap for Semiconductors},
   title = {International Technology Roadmap for Semiconductors, 2013 Edition, Executive Summary},
   url = {https://www.semiconductors.org/wp-content/uploads/2018/08/2013ExecutiveSummary.pdf},
   year = {2013},
}
@article{,
   author = {R Gütig and R Aharonov and S Rotter and Haim Sompolinsky},
   issue = {9},
   journal = {Journal of Neuroscience},
   keywords = {activity-dependent development,hebbian learning,info-,max,spike-timing-dependent plasticity,symmetry breaking,synaptic updating,unsupervised learning},
   pages = {3697-3714},
   title = {Learning Input Correlations through Nonlinear Temporally Asymmetric Hebbian Plasticity},
   volume = {23},
   year = {2003},
}
@article{Cai2019,
   abstract = {Memristors and memristor crossbar arrays have been widely studied for neuromorphic and other in-memory computing applications. To achieve optimal system performance, however, it is essential to integrate memristor crossbars with peripheral and control circuitry. Here, we report a fully functional, hybrid memristor chip in which a passive crossbar array is directly integrated with custom-designed circuits, including a full set of mixed-signal interface blocks and a digital processor for reprogrammable computing. The memristor crossbar array enables online learning and forward and backward vector-matrix operations, while the integrated interface and control circuitry allow mapping of different algorithms on chip. The system supports charge-domain operation to overcome the nonlinear I–V characteristics of memristor devices through pulse width modulation and custom analogue-to-digital converters. The integrated chip offers all the functions required for operational neuromorphic computing hardware. Accordingly, we demonstrate a perceptron network, sparse coding algorithm and principal component analysis with an integrated classification layer using the system.},
   author = {Fuxi Cai and Justin M. Correll and Seung Hwan Lee and Yong Lim and Vishishtha Bothra and Zhengya Zhang and Michael P. Flynn and Wei D. Lu},
   doi = {10.1038/s41928-019-0270-x},
   issn = {25201131},
   journal = {Nature Electronics},
   pages = {290-299},
   title = {A fully integrated reprogrammable memristor–CMOS system for efficient multiply–accumulate operations},
   volume = {2},
   year = {2019},
}
@article{Du2015,
   abstract = {Memristors have attracted broad interest as a promising candidate for future memory and computing applications. Particularly, it is believed that memristors can effectively implement synaptic functions and enable efficient neuromorphic systems. Most previous studies, however, focus on implementing specific synaptic learning rules by carefully engineering external programming parameters instead of focusing on emulating the internal cause that leads to the apparent learning rules. Here, it is shown that by taking advantage of the different time scales of internal oxygen vacancy (V O) dynamics in an oxide-based memristor, diverse synaptic functions at different time scales can be implemented naturally. Mathematically, the device can be effectively modeled as a second-order memristor with a simple set of equations including multiple state variables. Not only is this approach more biorealistic and easier to implement, by focusing on the fundamental driving mechanisms it allows the development of complete theoretical and experimental frameworks for biologically inspired computing systems.},
   author = {Chao Du and Wen Ma and Ting Chang and Patrick Sheridan and Wei D. Lu},
   doi = {10.1002/adfm.201501427},
   issn = {16163028},
   issue = {27},
   journal = {Advanced Functional Materials},
   keywords = {learning,memristive systems,memristor,neuromorphic computing,spike-timing-dependent plasticity},
   pages = {4290-4299},
   title = {Biorealistic Implementation of Synaptic Functions with Oxide Memristors through Internal Ionic Dynamics},
   volume = {25},
   year = {2015},
}
@article{Zidan2017,
   abstract = {Utilizing internal dynamic processes in memristors may allow the devices to process temporal data natively. In this letter, we show the ability of second-order memristors to process information in the time domain, and discuss a memristive STDP network that can learn and classify temporal as well as classical data patterns.},
   author = {Mohammed A. Zidan and Yeon Joo Jeong and Wei D. Lu},
   doi = {10.1109/TNANO.2017.2710158},
   issn = {1536125X},
   issue = {4},
   journal = {IEEE Transactions on Nanotechnology},
   keywords = {Classification,feature,neural network,spike-timing dependent plasticity},
   pages = {721-723},
   title = {Temporal Learning Using Second-Order Memristors},
   volume = {16},
   year = {2017},
}
@article{,
   author = {Takashi Kodama and Woosung Park and Amy Marconnet and Jaehoo Lee and Mehdi Asheghi and Kenneth E Goodson},
   keywords = {electron beam lithography,in-plain thermal conductivity,joule heating measurement,nanofabrication,nanolithography,nanowire},
   title = {<IN-PLANE THERMAL CONDUCTIVITY MEASUREMENT ON NANOSCALE CONDUCTIVE .pdf>},
}
@article{Hopkins2013,
   abstract = {The efficiency in modern technologies and green energy solutions has boiled down to a thermal engineering problem on the nanoscale. Due to the magnitudes of the thermal mean free paths approaching or overpassing typical length scales in nanomaterials (i.e., materials with length scales less than one micrometer), the thermal transport across interfaces can dictate the overall thermal resistance in nanosystems. However, the fundamental mechanisms driving these electron and phonon interactions at nanoscale interfaces are difficult to predict and control since the thermal boundary conductance across interfaces is intimately related to the characteristics of the interface (structure, bonding, geometry, etc.) in addition to the fundamental atomistic properties of the materials comprising the interface itself. In this paper, I review the recent experimental progress in understanding the interplay between interfacial properties on the atomic scale and thermal transport across solid interfaces. I focus this discussion specifically on the role of interfacial nanoscale "imperfections," such as surface roughness, compositional disorder, atomic dislocations, or interfacial bonding. Each type of interfacial imperfection leads to different scattering mechanisms that can be used to control the thermal boundary conductance. This offers a unique avenue for controlling scattering and thermal transport in nanotechnology. © 2013 Patrick E. Hopkins.},
   author = {Patrick E. Hopkins},
   doi = {10.1155/2013/682586},
   issn = {20905122},
   issue = {1},
   journal = {ISRN Mechanical Engineering},
   title = {Thermal transport across solid interfaces with nanoscale imperfections: Effects of roughness, disorder, dislocations, and bonding on thermal boundary conductance},
   volume = {2013},
   year = {2013},
}
@article{,
   abstract = {36 per cent nickel-iron alloy possesses a useful combination of low thermal expansion, moder- ately high strength and good toughness at tem- peratures down to that of liquid helium, -452 ºF (-269 ºC). These properties coupled with good weldability and desirable physical properties make this alloy attractive for many cryogenic applications. A modified form of 36 per cent nickel-iron alloy known as INVAR* M 63 has been used for LNG membrane tanks. It is avail- able as plate, strip, sheet, pipe, tubing, bars, billets, forgings and wire.},
   author = {The International Nickel Company},
   issue = {25 mm},
   pages = {1-8},
   title = {36% Nickel-Iron Alloy for Low Temperature Service},
   year = {1976},
}
@article{Samoshkin2020,
   abstract = {Abstract: The thermal conductivity and thermal diffusivity of europium (Eu) inthe solid and liquid states, including the melting-crystallizationregion, have been measured for the first time by the laser flash methodin the temperature range from 298 to 1625 K. The error of measurement ofthe heat transfer coefficients was 4–6%. The data for the temperatureregions of 298–550 K and 965–1625 K were obtained for the first time.Fitting equations and reference data for the temperature dependence ofthe thermal conductivity and thermal diffusivity of the metal have beenreceived.},
   author = {D. A. Samoshkin and A. Sh Agazhanov and S. V. Stankus},
   doi = {10.1134/S1810232820030042},
   issn = {19905432},
   issue = {3},
   journal = {Journal of Engineering Thermophysics},
   keywords = {and first of them,at the refractory materials,dustry,etc,high temperatures,in chemical in-,in electronics,is high melting tem-,laser flash method,medicine,of unique properties,perature and exceptional corrosion,production,stability,tantalum,tantalum has a number,thermal conductivity,thermal diffusivity,this defines its application},
   pages = {402-406},
   title = {Thermal Conductivity and Thermal Diffusivity of Europium in the Temperature Range of 298–1625 K},
   volume = {29},
   year = {2020},
}
@article{Landon2015,
   abstract = {The thermal conductivity of amorphous TaOx memristive films having variable oxygen content is measured using time domain thermoreflectance. Thermal transport is described by a two-part model where the electrical contribution is quantified via the Wiedemann-Franz relation and the vibrational contribution by the minimum thermal conductivity limit for amorphous solids. The vibrational contribution remains constant near 0.9 W/mK regardless of oxygen concentration, while the electrical contribution varies from 0 to 3.3 W/mK. Thus, the dominant thermal carrier in TaOx switches between vibrations and charge carriers and is controllable either by oxygen content during deposition, or dynamically by field-induced charge state migration.},
   author = {Colin D. Landon and Rudeger H.T. Wilke and Michael T. Brumbach and Geoff L. Brennecka and Mia Blea-Kirby and Jon F. Ihlefeld and Matthew J. Marinella and Thomas E. Beechem},
   doi = {10.1063/1.4926921},
   issn = {00036951},
   issue = {2},
   journal = {Applied Physics Letters},
   title = {Thermal transport in tantalum oxide films for memristive applications},
   volume = {107},
   year = {2015},
}
@article{Bondi2013,
   abstract = {We apply first-principles density-functional theory (DFT) calculations, ab-initio molecular dynamics, and the Kubo-Greenwood formula to predict electrical conductivity in Ta2Ox (0 ≤ x ≤ 5) as a function of composition, phase, and temperature, where additional focus is given to various oxidation states of the O monovacancy (VOn; n = 0,1+,2+). In the crystalline phase, our DFT calculations suggest that V O0 prefers equatorial O sites, while VO1+ and VO2+ are energetically preferred in the O cap sites of TaO7 polyhedra. Our calculations of DC conductivity at 300 K agree well with experimental measurements taken on Ta2O x thin films (0.18 ≤ x ≤ 4.72) and bulk Ta2O 5 powder-sintered pellets, although simulation accuracy can be improved for the most insulating, stoichiometric compositions. Our conductivity calculations and further interrogation of the O-deficient Ta2O 5 electronic structure provide further theoretical basis to substantiate VO0 as a donor dopant in Ta2O 5. Furthermore, this dopant-like behavior is specific to the neutral case and not observed in either the 1+ or 2+ oxidation states, which suggests that reduction and oxidation reactions may effectively act as donor activation and deactivation mechanisms, respectively, for VOn in Ta2O5. © 2013 AIP Publishing LLC.},
   author = {Robert J. Bondi and Michael P. Desjarlais and Aidan P. Thompson and Geoff L. Brennecka and Matthew J. Marinella},
   doi = {10.1063/1.4829900},
   issn = {00218979},
   issue = {20},
   journal = {Journal of Applied Physics},
   title = {Electrical conductivity in oxygen-deficient phases of tantalum pentoxide from first-principles calculations},
   volume = {114},
   year = {2013},
}
@article{Thuau2011,
   abstract = {Thermal properties of thin film materials used in the microelectro mechanical systems (MEMS) industry can differ from bulk materials. It is of great importance for numerous MEMS applications to have a precise knowledge of the thermal properties as they can influence device's final performance. We report on the design, the fabrication and the characterization of a MEMS structure for the measurement of thermal conductivity of conductive thin films. The thermal conductivity of titanium (Ti), indium tin oxide (ITO) and aluminum (Al) 500 nm thin films has been investigated and found to be 16.8 W m -1 K-1, 10.2 W m-1 K-1 and 200 W m-1 K-1, respectively, and are close to the thermal conductivity value of bulk materials. © 2011 Elsevier B.V. All rights reserved.},
   author = {D. Thuau and I. Koymen and R. Cheung},
   doi = {10.1016/j.mee.2010.12.119},
   issn = {01679317},
   issue = {8},
   journal = {Microelectronic Engineering},
   keywords = {Conductive thin film,MEMS,Microstructure,Thermal conductivity},
   pages = {2408-2412},
   publisher = {Elsevier B.V.},
   title = {A microstructure for thermal conductivity measurement of conductive thin films},
   volume = {88},
   url = {http://dx.doi.org/10.1016/j.mee.2010.12.119},
   year = {2011},
}
@article{Hogan1952,
   abstract = {The Forbes bar method has been modified and adapted to the problem of measuring the thermal conductivity of metals and alloys in the temperature range from 25°C to 1000°C. A mathematical analysis is presented which indicates the error involved by assuming plane isothermals in the sample. The electrical and thermal conductivities of commercial "A" nickel, inconel, several stainless steel alloys, and 1010 steel are reported, and the results are compared, qualitatively at least, with the theory presented by Wilson1 and Makinson.2.},
   author = {C. L. Hogan and R. B. Sawyer},
   doi = {10.1063/1.1702169},
   issn = {00218979},
   issue = {2},
   journal = {Journal of Applied Physics},
   pages = {177-180},
   title = {The thermal conductivity of metals at high temperature},
   volume = {23},
   year = {1952},
}
@article{Kumar1994,
   abstract = {This study examines the effect of transverse thickness on the in-plane thermal conductivity of single crystal, defect-free, thin metallic films. The imposed temperature gradient is along the film and the transport of thermal energy is predominantly due to free electron motion. The small size'necessitates an evaluation of the Boltzmann equation of electron transport along with appropriate electron scattering boundary conditions. Simple expressions for the reduction of conductivity due to increased dominance of boundary scattering are presented and the results are compared with other simplified approaches and experimental data from the literature. Grain boundary scattering is also considered via simple arguments. © 1994 by ASME.},
   author = {Sunil Kumar and George C. Vradis},
   doi = {10.1115/1.2910879},
   issn = {15288943},
   issue = {1},
   journal = {Journal of Heat Transfer},
   keywords = {Conduction,Thin Film Flow},
   pages = {28-34},
   title = {Thermal conductivity of thin metallic films},
   volume = {116},
   year = {1994},
}
@article{Reuben2014,
   author = {John Reuben},
   title = {Memory Selector Devices},
   year = {2014},
}
@article{Reifenberg2006,
   abstract = {Among the many emerging non-volatile memory technologies, chalcogenide (i.e. GeSbTe/GST) based phase change random access memory (PRAM) has shown particular promise. While accurate simulations are required for reducing programming current and enabling higher integration density, many challenges remain for improved simulation of PRAM cell operation including nanoscale thermal conduction and phase change. This work simulates the fully coupled electrical and thermal transport and phase change in 2D PRAM geometries, with specific attention to the impact of thermal boundary resistance between the GST and surrounding materials. For GST layer thicknesses between 25 and 75nm, the interface resistance reduces the predicted programming current and power by 31% and 53%, respectively, for a typical reset transition. The calculations also show the large sensitivity of programming voltage to the GST thermal conductivity. These results show the importance of temperature-dependent thermal properties of materials and interfaces in PRAM cells. © 2006 IEEE.},
   author = {J. Reifenberg and E. Pop and A. Gibby and S. Wong and K. Goodson},
   doi = {10.1109/ITHERM.2006.1645329},
   isbn = {0780395247},
   journal = {Thermomechanical Phenomena in Electronic Systems -Proceedings of the Intersociety Conference},
   keywords = {GST,GeSbTe,PRAM,Simulation,Thermal interface resistance},
   pages = {106-113},
   title = {Multiphysics modeling and impact of thermal boundary resistance in phase change memory devices},
   volume = {2006},
   year = {2006},
}
@article{Sebastian2020,
   abstract = {Traditional von Neumann computing systems involve separate processing and memory units. However, data movement is costly in terms of time and energy and this problem is aggravated by the recent explosive growth in highly data-centric applications related to artificial intelligence. This calls for a radical departure from the traditional systems and one such non-von Neumann computational approach is in-memory computing. Hereby certain computational tasks are performed in place in the memory itself by exploiting the physical attributes of the memory devices. Both charge-based and resistance-based memory devices are being explored for in-memory computing. In this Review, we provide a broad overview of the key computational primitives enabled by these memory devices as well as their applications spanning scientific computing, signal processing, optimization, machine learning, deep learning and stochastic computing.},
   author = {Abu Sebastian and Manuel Le Gallo and Riduan Khaddam-Aljameh and Evangelos Eleftheriou},
   doi = {10.1038/s41565-020-0655-z},
   issn = {17483395},
   issue = {7},
   journal = {Nature Nanotechnology},
   pages = {529-544},
   pmid = {32231270},
   publisher = {Springer US},
   title = {Memory devices and applications for in-memory computing},
   volume = {15},
   url = {http://dx.doi.org/10.1038/s41565-020-0655-z},
   year = {2020},
}
@article{DeCoster2018,
   abstract = {We report on the room temperature thermal conductivity of atomic layer deposition-grown amorphous TiO2 and Al2O3 thin films as a function of film thickness and atomic density. For films thinner than 50 nm, we measure an effective thermal conductivity that is reduced with decreasing film thickness. This dependence is attributed to the increased influence of thermal boundary resistances as film thickness is reduced. In addition, we fit for a thickness-independent intrinsic thermal conductivity using a series-resistor model. For films thicker than ∼50 nm, there is no significant dependence on thickness or substrate. We observe a dependence of the thermal conductivity on density, which agrees well with a differential effective-medium approximation modified minimum limit model.},
   author = {Mallory E. DeCoster and Kelsey E. Meyer and Brandon D. Piercy and John T. Gaskins and Brian F. Donovan and Ashutosh Giri and Nicholas A. Strnad and Daniel M. Potrepka and Adam A. Wilson and Mark D. Losego and Patrick E. Hopkins},
   doi = {10.1016/j.tsf.2018.01.058},
   issn = {00406090},
   issue = {February},
   journal = {Thin Solid Films},
   pages = {71-77},
   publisher = {Elsevier},
   title = {Density and size effects on the thermal conductivity of atomic layer deposited TiO2 and Al2O3 thin films},
   volume = {650},
   url = {https://doi.org/10.1016/j.tsf.2018.01.058},
   year = {2018},
}
@article{Scott2018,
   abstract = {The need for increased control of layer thickness and uniformity as device dimensions shrink has spurred increased use of atomic layer deposition (ALD) for thin film growth. The ability to deposit high dielectric constant (high-k) films via ALD has allowed for their widespread use in a swath of optical, optoelectronic, and electronic devices, including integration into CMOS compatible platforms. As the thickness of these dielectric layers is reduced, the interfacial thermal resistance can dictate the overall thermal resistance of the material stack compared to the resistance due to the finite dielectric layer thickness. Time domain thermoreflectance is used to interrogate both the thermal conductivity and the thermal boundary resistance of aluminum oxide, hafnium oxide, and titanium oxide films on silicon. We calculate a representative design map of effective thermal resistances, including those of the dielectric layers and boundary resistances, as a function of dielectric layer thickness, which will be of great importance in predicting the thermal resistances of current and future devices.},
   author = {Ethan A. Scott and John T. Gaskins and Sean W. King and Patrick E. Hopkins},
   doi = {10.1063/1.5021044},
   issn = {2166532X},
   issue = {5},
   journal = {APL Materials},
   title = {Thermal conductivity and thermal boundary resistance of atomic layer deposited high- k dielectric aluminum oxide, hafnium oxide, and titanium oxide thin films on silicon},
   volume = {6},
   url = {http://dx.doi.org/10.1063/1.5021044},
   year = {2018},
}
@article{Shen2018,
   abstract = {Tungsten oxide (WO3-x) crystalline nano/microrods with identical morphology but different contents of oxygen vacancies were prepared by thermally evaporating fixed amount of WO3 powder in reductive atmosphere from different amounts of S power at 1150°C in a vacuum tube furnace, in which both sources were loaded in separate ceramic boat. With increasing amount of S powder, a series of tungsten oxides, WO3, WO2.90, W19O55 (WO2.89), and W18O49 (WO2.72), could be obtained. And devices were fabricated by screen-printing the obtained WO3-x crystals on ceramic substrates with Ag-Pd interdigital electrodes. With increasing content of oxygen vacancies, the devices fabricated with WO3-x crystals present a negative to positive resistance response to relative humidity. Under dry atmosphere, for the devices with increasing x, the strong response to light changed from short to long wavelength; under light irradiation, the conducting ability of the devices was enhanced, due to the more efficient separation and transportation of the photogenerated carriers; and under simulated solar irradiation, the photocurrent intensity of the W18O49 device was roughly 8 times, about 500 times, and even 1000 times larger than that of the W19O55, WO2.90, and WO3 one, respectively. With the versatile optoelectrochemical properties, the obtained WO3-x crystals have the great potential to prepare various humidity sensors and optoelectrical devices.},
   author = {Zhenguang Shen and Zengying Zhao and Jian Wen and Jingwen Qian and Zhijian Peng and Xiuli Fu},
   doi = {10.1155/2018/7802589},
   issn = {16874129},
   journal = {Journal of Nanomaterials},
   title = {Role of Oxygen Vacancies in the Electrical Properties of WO3- x Nano/Microrods with Identical Morphology},
   volume = {2018},
   year = {2018},
}
@article{Sandler1977,
   author = {Mel Sandler},
   doi = {10.1177/004728757701600107},
   issn = {15526763},
   issue = {1},
   journal = {Journal of Travel Research},
   pages = {23-25},
   title = {Road Maps: Handle With Care},
   volume = {16},
   year = {1977},
}
@article{Watson1961,
   abstract = {Results of laboratory determinations of thermal conductivities in the temperature range -150 to 540 deg C are presented for 12 iron-nickel alloys. Six samples are of low nickel content, in the range from 1 to 9 per cent, and six others have nickel contents in the range from 35 to 80 per cent. A sample of AISI 1015 steel is included for comparative purposes. The determinations were made on bar specimens about 2.54 cm in diameter and 37 cm long, by an absolute steady-state method with heat flowing longitudinally in the bar. Computation of results from observed data was effected by means of a digital computer. © 1961 by ASME.},
   author = {T. W. Watson and H. E. Robinson},
   doi = {10.1115/1.3683651},
   issn = {15288943},
   issue = {4},
   journal = {Journal of Heat Transfer},
   pages = {403-407},
   title = {Thermal conductivity of some commercial iron-nickel alloys},
   volume = {83},
   year = {1961},
}
@article{Jacob2009,
   abstract = {Using a solid-state electrochemical cell incorporating yttria-doped thoria (YDT) as the electrolyte and a mixture of (Mn + MnO) as the reference electrode, standard Gibbs free energy of formation of β-Ta2O5 has been determined as a function of temperature in the range (1000 to 1300) K. The solid-state electrochemical cell used can be represented as (-) Pt,Ta + Ta2 O5 / / (Y2 O3) ThO2 / / Mn + MnO,Pt (+) Combining the reversible e.m.f. of the cell with recent data on the free energy of formation of MnO, standard Gibbs free energy of formation of Ta2O5 from Ta metal and diatomic oxygen gas (O2) in the temperature range (1000 to 1300) K is obtained: Δf G\{ring operator\} ± 0.35 / (kJ · mol- 1) = - 2004.376 + 0.40445 (T / K). Because of the significant solid solubility of oxygen in tantalum, a small correction for the activity of Ta in the metal phase in equilibrium with Ta2O5 is applied. An analysis of the results obtained in this study and other free energy data reported in the literature by the "third law" method suggests the need for refining data for Ta2O5 reported in thermodynamic compilations. Used in the analysis is a revised value for standard entropy of Ta2O5 based on more recent low-temperature heat capacity measurements. An improved set of thermodynamic properties of ditantalum pentoxide (Ta2O5) are presented in the temperature range (298.15 to 2200) K. © 2008 Elsevier Ltd. All rights reserved.},
   author = {K. T. Jacob and Chander Shekhar and Y. Waseda},
   doi = {10.1016/j.jct.2008.12.006},
   issn = {10963626},
   issue = {6},
   journal = {Journal of Chemical Thermodynamics},
   keywords = {Assessment,Enthalpy,Entropy,Gibbs free energy,Heat capacity,Thermodynamic properties},
   pages = {748-753},
   publisher = {Elsevier Ltd},
   title = {An update on the thermodynamics of Ta2O5},
   volume = {41},
   url = {http://dx.doi.org/10.1016/j.jct.2008.12.006},
   year = {2009},
}
@article{Goodwill2017,
   abstract = {Pulsed and quasi-static current-voltage (I-V) characteristics of threshold switching in TiN/TaOx/TiN crossbar devices were measured as a function of stage temperature (200-495 K) and oxygen flow during the deposition of TaOx. A comparison of the pulsed and quasi-static characteristics in the high resistance part of the I-V revealed that Joule self-heating significantly affected the current and was a likely source of negative differential resistance (NDR) and thermal runaway. The experimental quasi-static I-V’s were simulated using a finite element electro-thermal model that coupled current and heat flow and incorporated an external circuit with an appropriate load resistor. The simulation reproduced the experimental I-V including the OFF-state at low currents and the volatile NDR region. In the NDR region, the simulation predicted spontaneous current constriction forming a small-diameter hot conducting filament with a radius of 250 nm in a 6 μm diameter device.},
   author = {Jonathan M. Goodwill and Abhishek A. Sharma and Dasheng Li and James A. Bain and Marek Skowronski},
   doi = {10.1021/acsami.6b16559},
   issn = {19448252},
   issue = {13},
   journal = {ACS Applied Materials and Interfaces},
   keywords = {Poole−Frenkel conduction,negative differential resistance,tantalum oxide,thermal runaway,threshold switch},
   pages = {11704-11710},
   pmid = {28293945},
   title = {Electro-Thermal Model of Threshold Switching in TaOx-Based Devices},
   volume = {9},
   year = {2017},
}
@article{Boteler2019,
   abstract = {A study comparing the interaction between wide bandgap (WBG) materials, chip thickness, and heat sink selection on the total temperature rise in a standard power electronics package was performed. The thermal calculations, using the ARL ParaPower tool, showed that chips with thermal conductivities of less than 150 W/mK (including β-Ga2O3) had a dominant effect on total temperature rise, whereas thermal conductivities greater than 400 W/mK (including SiC and diamond) had little impact. In designs with devices having thermal conductivities between 150 and 400 W/mK (including GaN) the temperature rise resulting from the chip is a significant fraction of the total rise for heatsinks with heat transfer coefficients of 50,000 W/m2K or higher. For chips with thermal conductivities less than Si, the thickness of the chip can be a significant factor affecting the overall temperature rise.},
   author = {L. Boteler and A. Lelis and M. Berman and M. Fish},
   doi = {10.1109/WiPDA46397.2019.8998802},
   isbn = {9781728137612},
   journal = {2019 IEEE 7th Workshop on Wide Bandgap Power Devices and Applications, WiPDA 2019},
   keywords = {ARL ParaPower,Diamond,Gallium,Gallium oxide,Power electronics packaging,Silicon carbide,Thermal management,Ultra wide bandgap},
   pages = {265-271},
   title = {Thermal conductivity of power semiconductors-when does it matter?},
   year = {2019},
}
@article{Zhan2020,
   abstract = {Temperature increase in the continuously narrowing interconnects accelerates the performance and reliability degradation of very large scale integration (VLSI). Thermal boundary resistance (TBR) between an interconnect metal and dielectric interlayer has been neglected or treated approximately in conventional thermal analyses, resulting in significant uncertainties in performance and reliability. In this study, we investigated the effects of TBR between an interconnect metal and dielectric interlayer on temperature increase of Cu, Co, and Ru interconnects in deeply scaled VLSI. Results indicate that the measured TBR is significantly higher than the values predicted by the diffuse mismatch model and varies widely from 1 × 10-8 to 1 × 10-7 m2 K W-1 depending on the liner/barrier layer used. Finite element method simulations show that such a high TBR can cause a temperature increase of hundreds of degrees in the future VLSI interconnect. Characterization of interface properties shows the significant importance of interdiffusion and adhesion in TBR. For future advanced interconnects, Ru is better than Co for heat dissipation in terms of TBR. This study provides a guideline for the thermal management in deeply scaled VLSI.},
   author = {Tianzhuo Zhan and Kaito Oda and Shuaizhe Ma and Motohiro Tomita and Zhicheng Jin and Hiroki Takezawa and Kohei Mesaki and Yen Ju Wu and Yibin Xu and Takashi Matsukawa and Takeo Matsuki and Takanobu Watanabe},
   doi = {10.1021/acsami.0c03010},
   issn = {19448252},
   issue = {19},
   journal = {ACS Applied Materials and Interfaces},
   keywords = {FEM simulation,interconnect temperature increase,interdiffusion,interfacial adhesion strength,thermal boundary resistance},
   pages = {22347-22356},
   pmid = {32315529},
   title = {Effect of Thermal Boundary Resistance between the Interconnect Metal and Dielectric Interlayer on Temperature Increase of Interconnects in Deeply Scaled VLSI},
   volume = {12},
   year = {2020},
}
@article{Sebastian2020,
   abstract = {Traditional von Neumann computing systems involve separate processing and memory units. However, data movement is costly in terms of time and energy and this problem is aggravated by the recent explosive growth in highly data-centric applications related to artificial intelligence. This calls for a radical departure from the traditional systems and one such non-von Neumann computational approach is in-memory computing. Hereby certain computational tasks are performed in place in the memory itself by exploiting the physical attributes of the memory devices. Both charge-based and resistance-based memory devices are being explored for in-memory computing. In this Review, we provide a broad overview of the key computational primitives enabled by these memory devices as well as their applications spanning scientific computing, signal processing, optimization, machine learning, deep learning and stochastic computing.},
   author = {Abu Sebastian and Manuel Le Gallo and Riduan Khaddam-Aljameh and Evangelos Eleftheriou},
   doi = {10.1038/s41565-020-0655-z},
   issn = {17483395},
   issue = {7},
   journal = {Nature Nanotechnology},
   pages = {529-544},
   pmid = {32231270},
   publisher = {Springer US},
   title = {Memory devices and applications for in-memory computing},
   volume = {15},
   url = {http://dx.doi.org/10.1038/s41565-020-0655-z},
   year = {2020},
}
@article{Capilla2011,
   abstract = {This work describes the assessment of the acoustic properties of sputtered tantalum oxide films intended as high impedance films for the acoustic isolation of bulk acoustic wave devices operating in the GHz frequency range. The films are grown by sputtering a metallic tantalum target under different oxygen and argon gas mixtures, total pressures, pulsed DC powers and substrate bias. The structural properties of the films are assessed through infrared absorption spectroscopy and X-ray diffraction measurements. Their acoustic impedance is obtained after estimating the mass density by X-ray reflectometry measurements and the longitudinal acoustic velocity by analyzing the longitudinal λ/2 resonance induced in a tantalum oxide film inserted between an acoustic reflector and an AlN-based resonator. A second measurement of the sound velocity is achieved through picosecond acoustic spectroscopy. © 2011 IEEE.},
   author = {J. Capilla and J. Olivares and M. Clement and J. Sangrador and E. Iborra and A. Devos},
   doi = {10.1109/FCS.2011.5977833},
   isbn = {9781612841106},
   journal = {Proceedings of the IEEE International Frequency Control Symposium and Exposition},
   title = {Characterization of amorphous tantalum oxide for insulating acoustic mirrors},
   year = {2011},
}
@article{Yao2020,
   abstract = {Memristor-enabled neuromorphic computing systems provide a fast and energy-efficient approach to training neural networks1–4. However, convolutional neural networks (CNNs)—one of the most important models for image recognition5—have not yet been fully hardware-implemented using memristor crossbars, which are cross-point arrays with a memristor device at each intersection. Moreover, achieving software-comparable results is highly challenging owing to the poor yield, large variation and other non-ideal characteristics of devices6–9. Here we report the fabrication of high-yield, high-performance and uniform memristor crossbar arrays for the implementation of CNNs, which integrate eight 2,048-cell memristor arrays to improve parallel-computing efficiency. In addition, we propose an effective hybrid-training method to adapt to device imperfections and improve the overall system performance. We built a five-layer memristor-based CNN to perform MNIST10 image recognition, and achieved a high accuracy of more than 96 per cent. In addition to parallel convolutions using different kernels with shared inputs, replication of multiple identical kernels in memristor arrays was demonstrated for processing different inputs in parallel. The memristor-based CNN neuromorphic system has an energy efficiency more than two orders of magnitude greater than that of state-of-the-art graphics-processing units, and is shown to be scalable to larger networks, such as residual neural networks. Our results are expected to enable a viable memristor-based non-von Neumann hardware solution for deep neural networks and edge computing.},
   author = {Peng Yao and Huaqiang Wu and Bin Gao and Jianshi Tang and Qingtian Zhang and Wenqiang Zhang and J. Joshua Yang and He Qian},
   doi = {10.1038/s41586-020-1942-4},
   issn = {14764687},
   issue = {7792},
   journal = {Nature},
   pages = {641-646},
   pmid = {31996818},
   publisher = {Springer US},
   title = {Fully hardware-implemented memristor convolutional neural network},
   volume = {577},
   url = {http://dx.doi.org/10.1038/s41586-020-1942-4},
   year = {2020},
}
@article{Wang2019-JJY,
   abstract = {Reinforcement learning algorithms that use deep neural networks are a promising approach for the development of machines that can acquire knowledge and solve problems without human input or supervision. At present, however, these algorithms are implemented in software running on relatively standard complementary metal–oxide–semiconductor digital platforms, where performance will be constrained by the limits of Moore’s law and von Neumann architecture. Here, we report an experimental demonstration of reinforcement learning on a three-layer 1-transistor 1-memristor (1T1R) network using a modified learning algorithm tailored for our hybrid analogue–digital platform. To illustrate the capabilities of our approach in robust in situ training without the need for a model, we performed two classic control problems: the cart–pole and mountain car simulations. We also show that, compared with conventional digital systems in real-world reinforcement learning tasks, our hybrid analogue–digital computing system has the potential to achieve a significant boost in speed and energy efficiency.},
   author = {Zhongrui Wang and Can Li and Wenhao Song and Mingyi Rao and Daniel Belkin and Yunning Li and Peng Yan and Hao Jiang and Peng Lin and Miao Hu and John Paul Strachan and Ning Ge and Mark Barnell and Qing Wu and Andrew G. Barto and Qinru Qiu and R. Stanley Williams and Qiangfei Xia and J. Joshua Yang},
   doi = {10.1038/s41928-019-0221-6},
   issn = {25201131},
   issue = {3},
   journal = {Nature Electronics},
   pages = {115-124},
   publisher = {Springer US},
   title = {Reinforcement learning with analogue memristor arrays},
   volume = {2},
   url = {http://dx.doi.org/10.1038/s41928-019-0221-6},
   year = {2019},
}
@article{Kim2013,
   abstract = {Tantalum-oxide-based bi-layered resistance-change memories (RRAMs) have recently improved greatly with regard to their memory performances. The formation and rupture of conductive filaments is generally known to be the mechanism that underlies resistive switching. The nature of the filament has been studied intensively and several phenomenological models have consistently predicted the resistance-change behavior. However, a physics-based model that describes a complete bi-layered RRAM structure has not yet been demonstrated. Here, a complete electro-thermal resistive switching model based on the finite element method is proposed. The migration of oxygen vacancies is simulated by the local temperature and electric field derived from carrier continuity and heat equations fully coupled in a 3-D geometry, which considers a complete bi-layered structure that includes the top and bottom electrodes. The proposed model accurately accounts for the set/reset characteristics, which provides an in-depth understanding of the nature of resistive switching.},
   author = {Sungho Kim and Sae Jin Kim and Kyung Min Kim and Seung Ryul Lee and Man Chang and Eunju Cho and Young Bae Kim and Chang Jung Kim and U. -In Chung and In Kyeong Yoo},
   doi = {10.1038/srep01680},
   issn = {20452322},
   issue = {1680},
   journal = {Scientific Reports},
   pages = {1-6},
   pmid = {23604263},
   title = {Physical electro-thermal model of resistive switching in bi-layered resistance-change memory},
   volume = {3},
   year = {2013},
}
@article{Kim2014,
   abstract = {An oxide memristor device changes its internal state according to the history of the applied voltage and current. The principle of resistive switching (RS) is based on ion transport (e.g., oxygen vacancy redistribution). To date, devices with bi-, triple-, or even quadruple-layered structures have been studied to achieve the desired switching behavior through device structure optimization. In contrast, the device performance can also be tuned through fundamental atomic-level design of the switching materials, which can directly affect the dynamic transport of ions and lead to optimized switching characteristics. Here, we show that doping tantalum oxide memristors with silicon atoms can facilitate oxygen vacancy formation and transport in the switching layer with adjustable ion hopping distance and drift velocity. The devices show larger dynamic ranges with easier access to the intermediate states while maintaining the extremely high cycling endurance (>10 10 set and reset) and are well-suited for neuromorphic computing applications. As an example, we demonstrate different flavors of spike-timing-dependent plasticity in this memristor system. We further provide a characterization methodology to quantitatively estimate the effective hopping distance of the oxygen vacancies. The experimental results are confirmed through detailed ab initio calculations which reveal the roles of dopants and provide design methodology for further optimization of the RS behavior.},
   author = {Sungho Kim and Shinhyun Choi and Jihang Lee and Wei D. Lu},
   doi = {10.1021/nn503464q},
   issn = {1936086X},
   issue = {10},
   journal = {ACS Nano},
   keywords = {dopant,hopping,memristor,oxygen vacancy,resistive switching,tantalum oxide},
   pages = {10262-10269},
   title = {Tuning resistive switching characteristics of tantalum oxide memristors through Si doping},
   volume = {8},
   year = {2014},
}
@article{Callaway1960,
   abstract = {The consequences of a simple, phenomenological, theory of lattice thermal conductivity with respect to the effect of point imperfections are summarized. The experimental results of Berman et al. on the effect of varying the concentration of Li6 on the conductivity of lithium fluoride are analyzed in detail. © 1960 The American Physical Society.},
   author = {Joseph Callaway and Hans C. Von Baeyer},
   doi = {10.1103/PhysRev.120.1149},
   issn = {0031899X},
   issue = {4},
   journal = {Physical Review},
   pages = {1149-1154},
   title = {Effect of pint iperfections on lttice termal cnductivity},
   volume = {120},
   year = {1960},
}
@article{Luckyanova2014,
   abstract = {We demonstrate the impact on thermal conductivity of varying the concentration of oxygen vacancies and reduced cations in Pr0.1Ce0.9O2-δ thin films prepared by pulsed laser deposition. The oxygen vacancy concentration is controlled by varying the oxygen partial pressure between 1×10-4 and 1atm at 650°C. Corresponding changes in the oxygen non-stoichiometry (δ) are monitored by detecting the lattice parameters of the films with high-resolution X-ray diffraction, while the thermal properties are characterized by time-domain thermoreflectance measurements. The films are shown to exhibit a variation in oxygen vacancy content, and in the Pr3+/Pr4+ ratio, corresponding to changes in δ from 0.0027 to 0.0364, leading to a reduction in the thermal conductivity from k=6.62±0.61 to 3.82±0.51W/m-K, respectively. These values agree well with those predicted by the Callaway and von Baeyer model for thermal conductivity in the presence of point imperfections. These results demonstrate the capability of controlling thermal conductivity via control of anion and cation defect concentrations in a given reducible oxide.},
   author = {Maria N. Luckyanova and Di Chen and Wen Ma and Harry L. Tuller and Gang Chen and Bilge Yildiz},
   doi = {10.1063/1.4865768},
   issn = {00036951},
   issue = {6},
   journal = {Applied Physics Letters},
   pages = {6-9},
   title = {Thermal conductivity control by oxygen defect concentration modification in reducible oxides: The case of Pr0.1Ce0.9O2-δ thin films},
   volume = {104},
   year = {2014},
}
@article{Hur2019,
   abstract = {It is well known that collective migrations of oxygen vacancies in oxide is the key principle of resistance change in oxide-based resistive memory (OxRAM). The practical usefulness of OxRAM mainly arises from the fact that these oxygen vacancy migrations take place at relatively low operating voltages. The activation energy of oxygen vacancy migration, which can be inferred from the operational voltage of an OxRAM, is much smaller compared to the experimentally measured activation energy of oxygen, and the underlying mechanism of the discrepancy has not been highlighted yet. We ask this fundamental question in this paper for tantalum oxide which is one of the most commonly employed oxides in OxRAMs and try the theoretical answer based on the first-principles calculations. From the results, it is proven that the exceptionally large mobility of oxygen vacancy expected by the switching model can be well explained by the exceptionally low activation barrier of positively charged oxygen vacancy within the two-dimensional substructure.},
   author = {Ji Hyun Hur},
   doi = {10.1038/s41598-019-53498-3},
   issn = {20452322},
   issue = {1},
   journal = {Scientific Reports},
   pages = {1-9},
   pmid = {31745150},
   publisher = {Springer US},
   title = {The origin of the exceptionally low activation energy of oxygen vacancy in tantalum pentoxide based resistive memory},
   volume = {9},
   url = {http://dx.doi.org/10.1038/s41598-019-53498-3},
   year = {2019},
}
@article{Lee2020,
   abstract = {Oxide-based memristors are two-terminal devices whose resistance can be modulated by the history of applied stimulation. Memristors have been extensively studied as memory (as resistive random access memory) and synaptic devices for neuromorphic computing applications. Understanding the internal dynamics of memristors is essential for continued device optimization and large-scale implementation. However, a model that can quantitatively describe the dynamic resistive switching (RS, e.g., set/reset cycling) behavior in a self-consistent manner, starting from the initial forming process, is still missing. In this work, we present a Ta2O5/TaOx device model that can reliably predict all key RS properties during forming and repeated set and reset cycles. Our model revealed that the forming process originates from electric field focusing and localized heating effects from the initial nonuniform oxygen vacancy (VO) defect distribution. A broad range of device behaviors, including cycling of the VO distribution during set/reset cycles, multilevel storage, and two different filament growth processes, can be quantitatively captured by the model. In particular, a bulk-type doping effect with low programming current was found to produce linear conductance changes with a large dynamic range that can be highly desirable for neuromorphic computing applications. The simulation results were also compared with experimental dc and pulse measurements in 1R and 1T1R structures and showed excellent agreements.},
   author = {Seung Hwan Lee and John Moon and Yeon Joo Jeong and Jihang Lee and Xinyi Li and Huaqiang Wu and Wei D. Lu},
   doi = {10.1021/acsaelm.9b00792},
   issn = {26376113},
   issue = {3},
   journal = {ACS Applied Electronic Materials},
   keywords = {1T1R,Ta2O5,cycling,forming,memristor,oxygen vacancy},
   pages = {701-709},
   title = {Quantitative, Dynamic TaOxMemristor/Resistive Random Access Memory Model},
   volume = {2},
   year = {2020},
}
@article{Xia2019,
   abstract = {With their working mechanisms based on ion migration, the switching dynamics and electrical behaviour of memristive devices resemble those of synapses and neurons, making these devices promising candidates for brain-inspired computing. Built into large-scale crossbar arrays to form neural networks, they perform efficient in-memory computing with massive parallelism by directly using physical laws. The dynamical interactions between artificial synapses and neurons equip the networks with both supervised and unsupervised learning capabilities. Moreover, their ability to interface with analogue signals from sensors without analogue/digital conversions reduces the processing time and energy overhead. Although numerous simulations have indicated the potential of these networks for brain-inspired computing, experimental implementation of large-scale memristive arrays is still in its infancy. This Review looks at the progress, challenges and possible solutions for efficient brain-inspired computation with memristive implementations, both as accelerators for deep learning and as building blocks for spiking neural networks.},
   author = {Qiangfei Xia and J. Joshua Yang},
   doi = {10.1038/s41563-019-0291-x},
   issn = {14764660},
   issue = {4},
   journal = {Nature Materials},
   pages = {309-323},
   pmid = {30894760},
   publisher = {Springer US},
   title = {Memristive crossbar arrays for brain-inspired computing},
   volume = {18},
   url = {http://dx.doi.org/10.1038/s41563-019-0291-x},
   year = {2019},
}
@article{Kim2015,
   abstract = {Memristors have been extensively studied for data storage and low-power computation applications. In this study, we show that memristors offer more than simple resistance change. Specifically, the dynamic evolutions of internal state variables allow an oxide-based memristor to exhibit Ca2+-like dynamics that natively encode timing information and regulate synaptic weights. Such a device can be modeled as a second-order memristor and allow the implementation of critical synaptic functions realistically using simple spike forms based solely on spike activity.},
   author = {Sungho Kim and Chao Du and Patrick Sheridan and Wen Ma and Shinhyun Choi and Wei D. Lu},
   doi = {10.1021/acs.nanolett.5b00697},
   issn = {15306992},
   issue = {3},
   journal = {Nano Letters},
   keywords = {Ca2+,Memristor,dynamics,resistive switching,second-order,synapse,synaptic plasticity},
   pages = {2203-2211},
   pmid = {25710872},
   title = {Experimental demonstration of a second-order memristor and its ability to biorealistically implement synaptic plasticity},
   volume = {15},
   year = {2015},
}
@article{Peng2020,
   abstract = {Recent state-of-the-art deep convolutional neural networks (CNNs) have shown remarkable success in current intelligent systems for various tasks, such as image/speech recognition and classification. A number of recent efforts have attempted to design custom inference engines based on processing-in-memory (PIM) architecture, where the memory array is used for weighted sum computation, thereby avoiding the frequent data transfer between buffers and computation units. Prior PIM designs typically unroll each 3D kernel of the convolutional layers into a vertical column of a large weight matrix, where the input data needs to be accessed multiple times. In this paper, in order to maximize both weight and input data reuse for PIM architecture, we propose a novel weight mapping method and the corresponding data flow which divides the kernels and assign the input data into different processing-elements (PEs) according to their spatial locations. As a case study, resistive random access memory (RRAM) based 8-bit PIM design at 32 nm is benchmarked. The proposed mapping method and data flow yields ∼ 2.03× speed up and ∼ 1.4× improvement in throughput and energy efficiency for ResNet-34, compared with the prior design based on the conventional mapping method. To further optimize the hardware performance and throughput, we propose an optimal pipeline architecture, with 50% area overhead, it achieves overall 913× and 1.96× improvement in throughput and energy efficiency, which are 132476 FPS and 20.1 TOPS/W, respectively.},
   author = {Xiaochen Peng and Rui Liu and Shimeng Yu},
   doi = {10.1109/TCSI.2019.2958568},
   isbn = {9781728103976},
   issn = {15580806},
   issue = {4},
   journal = {IEEE Transactions on Circuits and Systems I: Regular Papers},
   keywords = {Convolutional neural network,hardware accelerator,processing in memory,resistive random access memory},
   pages = {1333-1343},
   title = {Optimizing Weight Mapping and Data Flow for Convolutional Neural Networks on Processing-in-Memory Architectures},
   volume = {67},
   year = {2020},
}
@article{Jeong2015,
   abstract = {Memristors and memristive systems have been extensively studied for data storage and computing applications such as neuromorphic systems. To act as synapses in neuromorphic systems, the memristor needs to exhibit analog resistive switching (RS) behavior with incremental conductance change. In this study, we show that the dynamic range of the analog RS behavior can be significantly enhanced in a tantalum-oxide-based memristor. By controlling different state variables enabled by different physical effects during the RS process, the gradual filament expansion stage can be selectively enhanced without strongly affecting the abrupt filament length growth stage. Detailed physics-based modeling further verified the observed experimental effects and revealed the roles of oxygen vacancy drift and diffusion processes, and how the diffusion process can be selectively enhanced during the filament expansion stage. These findings lead to more desirable and reliable memristor behaviors for analog computing applications. Additionally, the ability to selectively control different internal physical processes demonstrated in the current study provides guidance for continued device optimization of memristor devices in general.},
   author = {Yeon Joo Jeong and Sungho Kim and Wei D. Lu},
   doi = {10.1063/1.4934818},
   issn = {00036951},
   issue = {17},
   journal = {Applied Physics Letters},
   title = {Utilizing multiple state variables to improve the dynamic range of analog switching in a memristor},
   volume = {107},
   url = {http://dx.doi.org/10.1063/1.4934818},
   year = {2015},
}
@misc{TPU_edge,   
    title = {Edge TPU performance benchmarks},   
    url = {https://coral.ai/docs/edgetpu/benchmarks/},   
    author = {Coral},   
    year = {2020},   
    note = {Accessed on May 20, 2023} 
}
