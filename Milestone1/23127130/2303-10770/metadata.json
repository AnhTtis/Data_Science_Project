{
    "arxiv_id": "2303.10770",
    "paper_title": "RN-Net: Reservoir Nodes-Enabled Neuromorphic Vision Sensing Network",
    "authors": [
        "Sangmin Yoo",
        "Eric Yeu-Jer Lee",
        "Ziyu Wang",
        "Xinxin Wang",
        "Wei D. Lu"
    ],
    "submission_date": "2023-03-19",
    "revised_dates": [
        "2023-05-31"
    ],
    "latest_version": 3,
    "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
    ],
    "abstract": "Event-based cameras are inspired by the sparse and asynchronous spike representation of the biological visual system. However, processing the event data requires either using expensive feature descriptors to transform spikes into frames, or using spiking neural networks that are expensive to train. In this work, we propose a neural network architecture, Reservoir Nodes-enabled neuromorphic vision sensing Network (RN-Net), based on simple convolution layers integrated with dynamic temporal encoding reservoirs for local and global spatiotemporal feature detection with low hardware and training costs. The RN-Net allows efficient processing of asynchronous temporal features, and achieves the highest accuracy of 99.2% for DVS128 Gesture reported to date, and one of the highest accuracy of 67.5% for DVS Lip dataset at a much smaller network size. By leveraging the internal device and circuit dynamics, asynchronous temporal feature encoding can be implemented at very low hardware cost without preprocessing and dedicated memory and arithmetic units. The use of simple DNN blocks and standard backpropagation-based training rules further reduces implementation costs.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.10770v1",
        "http://arxiv.org/pdf/2303.10770v2",
        "http://arxiv.org/pdf/2303.10770v3"
    ],
    "publication_venue": "12 pages, 5 figures, 4 tables"
}