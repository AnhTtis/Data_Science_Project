\begin{figure*}
    \centering    
    \includegraphics[width=.8\textwidth]{figs/multi_cont_attn.pdf}
    \caption{
    Our proposed multi-modal self-supervised learning pipeline.
    Modality-specific data from different distributions are encoded through dedicated encoders and mapped to a shared latent representation space. The aggregated embedding of the segment is then computed by applying attention pooling to the modality-specific representations.
    A self-supervised contrastive objective aligns this aggregate embedding and the mode-specific representations.}
    \label{fig:mmssl}
\end{figure*}
