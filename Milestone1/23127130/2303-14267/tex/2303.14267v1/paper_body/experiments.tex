\section{Experiments}
% a discussion on the experiments
\subsection{Data}
\input{tex_figs/sup_signals}

\input{tex_figs/attn_interp}

The cohort in this study consists of $14$ college students who are ex or active-duty members of the United States military.
The status of these individuals, both as military members as well as students, renders them an interesting cohort for our stress study, given that the individuals from both groups are known to be relatively more prone to experiencing stress.

\input{tables/participant_info}

The smartwatch in this study was Garmin vivoactive 4S. Nevertheless, it is noteworthy that there is no component in the proposed methodology that limits the solution to this smartwatch.
The feature groups and various modalities in our configuration are shown in Table \ref{tab:modfocus}.
\input{tables/modfocus}

\subsection{Labeling}
The focus of this study has been on making predictions on {\it perceived} stress, for which the participants agreed to indicate the episodes in which they felt stressed and provide us with the intensity and timespans of these episodes.

For each record input to our system by an individual, we created a softened (via a Gaussian function) time-series per the following steps:
\begin{itemize}
    \item The peak (corresponding to the {\it mean} of this Gaussian function) is set to the given timestamp, or the midpoint of the timespan ($(t_{\text{start}} + t_{\text{end}})/2$).
    \item The standard deviation of $30$ minutes (scaled proportional to the length of time-span, if a time span of over one hour is provided).
    \item The magnitude of the peak point corresponds to the indicated  for the episode: $\{0,1,2,3\}$ for $\{\texttt {None}, \texttt{Low},\texttt{Medium}, \texttt{High}\}$, respectively.
\end{itemize}
The summation of these Gaussian signals comprises the  signal used as the primary supervision objective.
The way the labels are computed is by looking at the end-point of each episode, and its {\it stress} label is marked \texttt{True} if the value of this signal on that point is larger than a threshold of $0.5$, and \texttt{False} otherwise.
% \shayan{should we remove the subsections in the experiments section?}
\subsection{Modeling}
% separate rnn branches etc. description of the model
Our inference model is composed of a specific encoder for each modality.
In our case, each encoder is defined based on an initial mapping and normalization (via fully connected layers) followed by a bi-directional recurrent neural network (RNN) in long short-term memory (LSTM) configuration.
Specifically, the data from each modality was first projected to a $32$-dimensional vector via a multi-layer perception (MLP) with one hidden layer.
The output was then forwarded to the modality-specific bi-LSTM with the hidden-layer neuron count of $64$. The last stage for representing each modality was another fully-connected projection layer, generating a $32$-dimensional vector per modality, which were used as modality representations in our framework.

Note that the overall pipeline does not have any constraint on the local modality encoders as long as they share the final semantic space to which they project that modality's observations.
Given that we were mainly dealing with time-series data, we used RNNs to model each branch.
Nonetheless, modalities from substantially different domains and their encoders (e.g., Transformer-based Language Model for textual data) can also fit into the same system.

\subsection{Results}
Focusing on our real-world perceived stress corpus, we conducted experiments under the main settings of 1) supervised training baseline, 2) pre-training the contrastive objective and fine-tuning via supervised objective, and 3) training the supervised objective and simultaneously optimizing a scaled version of the contrastive term as a regularizing loss.
 
We observed that leveraging more features and following a late-fusion protocol for combining modality representations did lead to an improved generalization performance over the supervised setup proposed in \cite{fazeli2022passive}, which combined the features at the beginning of the pipeline. In the case of our cohort, training with contrastive regularization led to the best generalization on the unseen test data, and the results are shown in Table \ref{tab:modelresults}.
Note that, in general, it is hard to say which self-supervised setup (pre-training versus regularization) is best, as it could depend on other factors, including model complexity, optimization, data availability, and task difficulty.
That being said, our approach allows learning high-quality representations by optimizing the modality-contrastive objective via both of these setups.

Additionally, we focused on interpretability as well and leveraged the task-specific attention mechanism in our pipeline, which pools the representations from different modalities, to study the utility and contribution of observations from each feature group.
This enables the network to dynamically assign weights to each modality's latent representation (in the shared space) as it processes each instance, allowing us to study their contribution both per instance and in expectation for performing the desired task.
In Figure \ref{fig:attn_interp}, we have shown the results on this matter for the contrastive regularization setup\footnote{The label $\texttt{heart}$ in Figure \ref{fig:attn_interp} corresponds to the $\texttt{daily}$ modality's information, given that its main focus is heart-rate.}.
The results indicate that even though the contributions of the different modalities follow a non-uniform distribution as expected, none of them were ignored by the model and they all play a part in the final predictions.

\input{tables/results.tex}




