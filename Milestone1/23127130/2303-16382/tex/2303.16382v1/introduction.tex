Robotic systems for object handling in warehouses can expedite fulfillment of customer orders by automating tasks such as object picking, sorting, and packing. However, building reliable and scalable robotic systems for object manipulation in warehouses is not trivial. Modern warehouses process millions of unique objects with diverse shapes, materials, and other physical properties. These objects are often stored in unstructured configurations within containers which pose challenges for robotic perception and planning. From 2015 to 2017, the Amazon Robotics Challenge (ARC) helped push the state-of-the-art for robotic systems in a pick-and-place task representative of a warehouse \cite{colling2018progress, correll2016analysis}. Nevertheless, the competition could not incorporate challenges of large-scale operations. Fundamental research still needs to be carried out to enable visual perception algorithms such as object segmentation and identification to generalize to a wide variety of unseen objects and configurations. Additional problems (such as defect detection) and metrics (measuring uncertainty in prediction) need to be defined to capture the scale and high-precision requirements of such systems. 

\begin{figure}[t!]
	\includegraphics[width=\linewidth, keepaspectratio]{images/intro-image.pdf}
	\caption{A large-scale object dataset is collected using a robotic manipulation system operating in an Amazon warehouse. The robotic arm picks one object at a time from the yellow container and places it in a gray tray (top). The dataset contains images for different phases of manipulation i.e., image of objects in the yellow container before picking (bottom-left), during transfer (bottom-mid) and after placement (bottom-right). In addition to sensor data, the dataset also provides high-quality annotations for tasks such as object segmentation, object identification, and defect detection.}
	\label{fig:intro}
	\vspace{-0.2in}
\end{figure}


Benchmarks and datasets such as ImageNet \cite{russakovsky2015imagenet} and MS-COCO \cite{Lin2014MicrosoftCC} have enabled significant performance improvement in computer vision tasks such as image classification and segmentation. No sizeable dataset exists that capture the desired variety of objects, configurations, and interactions in the context of robotic manipulation. Large repositories of 3D shape models \cite{calli2017yale, chang2015shapenet, collins2022abo, downs2022google} enable generating a variety of scenarios with a rich set of annotations in simulation. Nevertheless, they may fail to capture certain physical properties of objects and interactions encountered during manipulation from heterogeneous clutter.
%While 3D models allow generating a variety of scenarios with a rich set of annotations in simulation, they may fail to capture  gap and do not generalize well to the physical world. 
Existing real-world datasets \cite{hodan2018bop} operate under closed set assumption with a small number of object types. Such assumptions prevent evaluating algorithms in terms of its generalization capabilities over novel objects which is critical in large scale operations. Additionally, these datasets only deal with static scenes with objects in near perfect conditions and do not consider interactions with a robotic manipulator.

% Main contributions
In this paper, we present {ARMBench}, a large-scale benchmark dataset for a robotic pick-and-place task that captures a wide variety of warehouse objects and configurations. The dataset comprises images and videos for different stages of robotic manipulation, namely pick, transfer, and place. It includes metadata such as descriptions and reference images for objects in the container. Each pick-and-place activity is also annotated with the identity of the object being manipulated, and the outcome of the manipulation i.e., whether it was successful (a single object was picked and placed) or if it resulted in a defect. The dataset can be used to study different visual perception problems in the context of robotic manipulation. This paper provides novel benchmarks with annotations and baseline performance metrics for: 
\begin{itemize}
	\item \textbf{Object Segmentation} including 450,000+ high-quality manual labels for object segments on 50,000+ images. Variations in objects and degree of clutter present a novel challenge for instance segmentation algorithms.
	\item \textbf{Object Identification} presenting an open set object identification and confidence estimation challenge for robotic manipulation. With 190,000+ unique objects in varying configurations, the dataset will be used to benchmark image retrieval and few-shot classification methods with uncertainty estimation.
	\item \textbf{Defect Detection} with manually assigned labels for rare, but costly, robot-induced defects such as multi-object-pick and packaging defects. The dataset contains 19,000+ images and 4,000+ videos of activities with defects, and 100,000+ activities without defects.
\end{itemize}



%Certain defects are temporal in nature and the dataset provides videos and images of pick, transfer, and place scenes along with thousands of labels for defects.
%We present data for three different types of defects in a robotic manipulation process: 1) packaging damage 2) multi-object pick, and 3) dropped objects. 

% Robotic systems for object handling in warehouses can improve efficiency and operator experience by eliminating repetitive tasks such as object picking, sorting, and packing. However, building reliable and scalable robotic systems for object manipulation in warehouses is not trivial. Modern warehouses process millions of unique objects with diverse shapes, materials, and physical properties. The high-mix low-volume inventory in warehouses poses challenges for perception systems, robotic hardware, motion planning algorithms, and decision making. From 2015 to 2017, the Amazon Robotics Challenge (ARC) pushed the state-of-the-art for robotic systems that can handle a diverse set of unseen objects in a fictional pick-and-place task representative of a warehouse \cite{colling2018progress, correll2016analysis}. Existing solutions lack the robustness and the ability to generalize which has prevented wide adoption by industry.

%However, the robustness of state-of-the-art solutions are far from what is required in warehouses.\textbf{Mani: elaborate}

%Robotic manipulation systems in warehouses improve efficiency by eliminating repetitive tasks such as object picking, sorting, and packing. In addition to improving speed and accuracy of operations, they also improve operator experience and safety. \textbf{A sentence on Robin. What other robotic systems can be refer to that demonstrate improved efficiency of warehouse operations because of robots.}

% Modern warehouses process millions of unique objects with diverse shapes, materials, and physical properties. From 2015 to 2017, three Amazon Robotics Challenge (ARC) competitions highlighted challenges for robotic manipulation in warehouses where systems had to identify and manipulate XX objects in a fictional warehouse process. ARC motivated state-of-the-art research in pick-and-place systems~\cite{mit15,nimbro2018,mit2017}. However, robotic manipulation technologies still lack the performance and robustness required in warehouses to make them financially viable. (refer six sigma?). 

% expedite the transportation of goods and simplify repetitive processes such as object picking, sorting, and packing. Warehouse automation processes require systems to scan and identify objects, perform pick-and-place manipulation, and handle complex decision logic. an automated robot warehouse can bring potential benefits such as increased up-time, higher total throughput, and lower accident rates. With a shrinking workforce, robotic warehouse automation will play an 

%Building reliable and scalable robotic products for object manipulation is not trivial. Modern warehouses process millions of unique objects with diverse shapes, materials, and physical properties, and a warehouse automating robot must have the versatility and robustness to handle the variety at high throughput with a minimal defect. The requirements pose significant challenges to all aspects of robotic systems, from sensors and robotic hardware to vision and manipulation software. Between 2015 and 2017, the three Amazon Robotics Challenge (ARC) competitions drew broad research attention to some of the warehouse automation challenges, such as classification for partially visible items, object detection in heavy clutter, and targeted object retrieval from densely packed bins. The competition also results in several publications of state-of-the-art pick-and-place systems~\cite{mit15,nimbro2018,mit2017}. To further advance robot manipulation techniques for scalable production, fundamental research still needs to be carried out, and continuous learning from systems in production should be used to improve solutions iteratively. By the end of this year, we will have thousands of automatic robotic manipulation stations~\cite{ROBIN} deployed across Amazon warehouse facilities.

% Overview of perception system in object handling and challenges. 
% Hetergenous clutter in warehouses pose unique visual perception challenges in robotic object manipulation systems. Perception systems need to delineate object boundaries and classify objects (\textit{object segmentation}) so that grasp and motion plans can be generated \cite{morrison2018cartman}. The system needs to identify the object (\textit{object identification}) to be able to track inventory, and finally, after the object has been manipulated, any defects introduced have to be detected (\textit{defect detection}). %The large variety of objects stored in a high degree of clutter in containers in warehouses make such perception tasks difficult (Fig.\ \ref{fig:intro}(b)). 
% How datasets enable research and development?

% ImageNet comprises 14 million images of objects across 20,000 categories while MS-COCO comprises 330,000 images of common objects in their natural context. %Similar computer vision tasks are applicable to robotic manipulation in warehouses. How have they helped improve performance?
%The BOP Challenge \cite{hodan2018bop} unifies 13 datasets of real images labeled with 6D pose annotations for a pre-defined set of objects with 3D models\textbf{What is the sig of the BOP challenge?}. 
%While it is possible to model some of the interactions in a simulator, it is not trivial to generate representative synthetic data for real-world scenarios such as defects induced by robotic manipulation. 
%As a result, there are no existing datasets for defect detection in robotic manipulation processes.