\section{Experimental Results}
\label{sec:results}

In this section, we examine the performance of SECAD-Net on the ABC dataset~\cite{koch2019abc} and Fusion 360 Gallery~\cite{willis2021fusion}.  
Through extensive comparisons and ablation studies, we demonstrate the effectiveness of our approach and show its superiority over state-of-the-art reference approaches for CAD reconstruction. 
% After that we provide a complete qualitative and quantitative comparison with state-of-the-art approaches. 
% Finally, we perform a series of ablation experiments to validate the effectiveness of our methods.

\subsection{Setup}

\noindent\textbf{Dataset preparation.} 
For the ABC dataset, the voxel grids and sampling point data are provided by~\cite{yu2022capri}. We use 5,000 groups of data for training and 1,000 for testing. For Fusion 360, which does not contain available voxels, we first randomly select 6,000 meshes, then discretize them into internally filled voxels. The train-test split is the same as ABC. 
We obtain sampling points with the corresponding occupancy value following~\cite{chen2019learning}. 
% We adopt the point sampling strategy from ~\cite{chen2019learning} to obtain sampling points with the corresponding occupancy value.
The resolution of voxel shapes is $64^3$ for both datasets, and the number of sampling points is 8,192.
Considering that fine-tuning each method and generating high-accuracy meshes is time-consuming, we take 50 shapes from each dataset to form 100 shapes for quantitative evaluation.

\begin{table}[]
\caption{Quantitative comparison between reconstruction results on ABC dataset. }
\label{table:ABC} 
\begin{tabularx}{\columnwidth}{c|Y|Y|Y|Y}
\hline
Methods    & CD↓ & ECD↓ & NC↑ & \#P↓  \\ \hline \hline
UCSG-Net~\cite{kania2020ucsg}   & 1.849 & 1.255 & 0.820 & 12.84 \\ \hline
CSG-Stump~\cite{ren2021csg} & 4.031 & 0.754 & 0.828 & 17.18 \\ \hline
ExtrudeNet~\cite{ren2022extrudenet} & 0.471 & 0.914 & 0.852 & 14.46 \\ \hline
Ours       & \textbf{0.330} & \textbf{0.724} & \textbf{0.863} & \textbf{4.30}   \\ \hline
\end{tabularx}
\end{table}

\begin{table}[]
\caption{Quantitative comparison between reconstruction results on Fusion 360 dataset. }
\label{table:Fusion} 
\begin{tabularx}{\columnwidth}{c|Y|Y|Y|Y}
\hline
Methods    & CD↓ & ECD↓ & NC↑ & \#P↓ \\ \hline \hline
UCSG-Net~\cite{kania2020ucsg}   & 2.950          & 5.277          & 0.770          & 10.84         \\ \hline
CSG-Stump~\cite{ren2021csg} & 2.781          & 4.590          & 0.744          & 12.08         \\ \hline
Point2Cyl~\cite{uy2022point2cyl}  & 13.889         & 14.657         & 0.669          & \textbf{2.76} \\ \hline
ExtrudeNet~\cite{ren2022extrudenet}  & 2.263         & 3.558         & \textbf{0.819}          & 15.72 \\ \hline
Ours       & \textbf{2.052} & \textbf{3.282} & 0.803 & 5.44          \\ \hline
\end{tabularx}
\end{table}

\noindent\textbf{Evaluation metrics.}
For quantitative evaluations, %we use three classic evaluation metrics, namely
we follow the metrics that are commonly used in previous methods~\cite{ren2021csg,yu2022capri}, including symmetric Chamfer Distance ($\textit{CD}$), Normal Consistency ($\textit{NC}$), Edge Chamfer Distance ($\textit{ECD}$). 
Details of computing these metrics are given in the supplemental materials. 
Additionally, we also report the number of generated primitives, $\textit{\#p}$, as a measure of how easy the output CAD results are to edit.

\begin{figure}[!t]
    \centerline{
    \includegraphics[width=1.0\linewidth]{figs/compare_on_ABC_ExtrudeNet_compress.pdf}
    }
    \caption{Visual comparison between reconstruction results on ABC dataset.
    }
    % Visual comparison of our approach with UCSG-Net~\cite{kania2020ucsg} and CSG-Stump~\cite{ren2021csg} on ABC. Our reconstruction results are generated using both marching cubes (MC) and our proposed sketch-extrude operations (SE). 
    \label{fig:compare_ABC}
\end{figure}
\begin{figure}[!t]
    \centerline{
    \includegraphics[width=1.0\linewidth]{figs/compare_on_fusion_ExtrudeNet_compress.pdf}
    }
    \caption{Visual comparison between reconstruction results on Fusion 360 dataset.
    }
    \label{fig:compare_fusion}
\end{figure}

\subsection{Comparison on CAD Reconstruction}
%\noindent\textbf{Results Comparison}
% And compared with UCSG-net, CSG-Stumptnet, point2cyl methods. Other methods that target 3D implicit fields or raw meshes are not in a fair comparison with ours, despite their fine reconstructions.
% We compare with UCSG-Net, CSG-Stumpt, point2cyl, and other methods that do not use reconstructing easily editable CAD shapes as prediction targets are not within our scope of comparison.

We thoroughly compare our method with two types of primitive-based CAD reconstruction methods that output editable CAD models, including two CSG-like methods (\ie, UCSG-Net~\cite{kania2020ucsg}, CSG-Stump~\cite{ren2021csg}) and \rev{two cylinder decomposition counterpart (\ie, point2Cyl~\cite{uy2022point2cyl}), ExtrudeNet~\cite{ren2022extrudenet}.} 
For each method, we adopt the implementation provided by the corresponding authors, and use the same training strategy for training and fine-tuning.
For CSG-Stump, we set the number of intersection nodes to 64, making it output a comparable number of primitives to other methods.
Those methods provide a plethora of comparisons to other techniques and establish themselves as state-of-the-art. 
Note that for point2Cyl, we only report its results on  Fusion 360 dataset, as the ABC dataset does not provide the labels needed to train point2Cyl. 

Quantitative results on the ABC and Fusion 360 datasets are reported in Table~\ref{table:ABC} and Table~\ref{table:Fusion}, respectively. 
It can be seen that the proposed SECAD-Net outperforms both kinds of methods on all evaluation metrics while still generating a relatively small number of primitives. %achieves the best reconstruction effect 
Fig.~\ref{fig:compare_ABC} and Fig.~\ref{fig:compare_fusion} display several qualitative comparison results. For fairness, all the reconstructed CAD models are visualized using marching cubes (MC) with 256 resolution.
% while "OURS (SE)" further shows our results generated by sketch and extrusion operators (see Sec.~\ref{sec:reconstruction}). 
Visually as shown in the figures, our method achieves much better geometry and topological fidelity with more accurate structures (\eg, holes, junctions) and sharper features. 
%the reconstruction results of our method are finer and the sides are smoother while the junction of the top and sides is sharper.

%   and improve previous SOTA results by over 9%.

\begin{figure}[!t]
    \centerline{
    \includegraphics[width=1.0\linewidth]{figs/sketch_interp_v3_compress.jpg}
    }
    \caption{For each example, we encode the sketches of top and bottom shapes in latent vector space and then linearly interpolate the corresponding latent codes.
    }
    \label{fig:sketch_interp}
\end{figure}
\subsection{CAD Generation via Sketch Interpolation}
Although without ground truth labels as guidance, SECAD-Net can learn plausible 2D sketches from raw 3D shapes. 
Thanks to the implicit sketch representation, we are able to generate different CAD variations when a pair of shapes is interpolated in the complete and continuous sketch latent space, as shown in Fig.~\ref{fig:sketch_interp}. The results suggest that the generated sketch is gradually transformed even if the pair of shapes have significantly different structures, and we draw two further conclusions: (1) the predicted position of each extrusion box is relatively deterministic, although the input shape is different (see the left and right column sketches in the leftmost group); (2) when an extrusion box does not contain a shape, our SK-head does not generate a sketch, making the network output an adaptive number of cylinders (see the middle column sketches of the leftmost and the rightmost groups).

% To generate more new sketches and explore the learning ability of the network, we feed the network with interpolated feature codes. The results of the visualization are shown in Figure[].  We draw two observations, 1. Each MLP tends to learn 2d sketches with fixed positions, 2. When the target position learned by each MLP should not appear 3D cylinders, the network can adaptively generate implicit fields without occupancy


\begin{table}[]
\caption{Ablation study on network design and sketch loss. We adopted setting (e) in the final model.}
\label{table:ablation} 
\begin{tabularx}{\columnwidth}{Y|c|c|c|c|c}
\hline
Settings              & (a) & (b) & (c) & (d) & (e) \\ \hline\hline
$N_{sh}$   & 1     & 4     & 4     & 4     & 4     \\ \hline
$N_{lay}$ & 2     & 2     & 2     & 4     & 4     \\ \hline
$N_{cyl}$  & 4     & 4     & 8     & 4     & 4     \\ \hline
$\mathcal{L}_{sketch}$         & \cmark       &  \cmark      &  \cmark      &  \xmark      &  \cmark      \\ \hline 
CD↓                  & 2.627 & 0.993 & 1.504 & 0.336 & \textbf{0.330} \\ \hline
ECD↓                 & 1.754 & 0.882 & 1.098 & 0.772 & \textbf{0.724} \\ \hline
NC↑                  & 0.713 & 0.835 & 0.761 & 0.863 & \textbf{0.863} \\ \hline
\end{tabularx}
\end{table}

\subsection{Ablations}
\label{sec:ablations}
We perform ablation studies to carefully analyze the efficiency of major components of our designed model. All quantitative metrics are measured on the ABC dataset.

% We conduct sufficient ablation experiments to examine the effects of the number of components/parameters in the network, the loss function, and the sketch representation on the reconstruction results, respectively. All quantitative metrics are measured on the ABC dataset.

% We perform ablation studies to assess the efficiency of our design.
% We do ablation study on major components of the whole pipeline,
% including network design and global optimization. Starting from a
% baseline approach, we show the necessity and impact of different
% components by incorporating them incrementally.

\noindent\textbf{Effect of network design and sketch loss.}
We first examine the effect of the number of components/parameters in SECAD-Net, including the number of SK-heads ($N_{sh}$), the number of fully connected layers ($N_{lay}$) in each SK-head, and the number of output cylinders ($N_{cyl}$). Then we show the necessity of the sketch loss by deactivating it to train the network. 
The quantified results are presented in Table~\ref{table:ablation}. Settings (a), (b), and (c) show that reducing the number of SK-heads or increasing the number of cylinder outputs will damage the model prediction accuracy. Settings (b), (d), and (e) show that increasing the number of MLP layers in SK-head or enabling $\mathcal{L}_{sketch}$ will improve the prediction accuracy.

% Specifically, we first reduce the number of sketch heads in SECAD-Net and the number of fully connected layers in it. After that we change the setting of the number of cylinders to output and also try to train the network without the sketch loss term. The quantified results are presented in Table xxx.

\begin{table}[]
\caption{Ablation study on sketch representation. }
\label{table:ablation_sk} 
\begin{tabularx}{\columnwidth}{c|Y|Y|Y|Y}
\hline
 Representation & CD↓ & ECD↓ & NC↑ & \#P↓ \\ \hline\hline
Box primitives        & 0.523          & 0.982          & 0.825          & 5.38         \\ \hline
BSP                   & 0.612          & 0.838          & 0.852          & 5.84         \\ \hline
SK-head (Ours) & \textbf{0.330} & \textbf{0.724} & \textbf{0.863} & \textbf{4.30} \\ \hline
\end{tabularx}
\end{table}


\begin{figure}[!t]
    \centerline{
    \includegraphics[width=1.0\linewidth]{figs/ablation_v3_compress.pdf}
    }
    \caption{Visual comparison results for ablation study on sketch representation.
    }
    \label{fig:ablation_vis}
\end{figure}

\noindent\textbf{Effect of implicit sketch representation.}
To assess the efficiency of neural implicit sketch representation, we adopt two other classical shape representations, namely binary
space partitioning (BSP~\cite{chen2020bsp}) and box-like primitives, to compare with our SK-head in SECAD-Net. For BSP, we set the number of output convex shapes to 8, each containing 12 partitions. The assembly method is consistent with ~\cite{chen2020bsp} to represent 2D sketches. For box-like primitives, 24 rectangles are predicted. We divide them into two subsets in half, take the union operation separately, and subtract the other from one of the union results. The numerical and visual comparison results are shown in Table~\ref{table:ablation_sk} and Fig.~\ref{fig:ablation_vis}, respectively. It can be seen that our implicit field can represent the smoothest shape while obtaining the best reconstruction results.

% In addition to fitting implicit fields using a network, there are various data types that can represent 2D sketches. We choose two other classical shape representations, namely BSP and Square primitive, to compare with sk-head in SECAD-Net. For BSP, we set the number of planes to xxx, and the assembly method is the same as in the paper. For the Square primitive, we set the output of xxx squares, and the combination method is the union of all. The experimental results are shown in Table xxx. A comparison of the visualization results is shown in Fig. xxx, it can be seen that our method can represent the smoothest shape while obtaining the best reconstruction results.

\begin{figure}[!t]
    \centerline{
    \includegraphics[width=1.0\linewidth]{figs/other-app_v2_compress.pdf}
    }
    \caption{SECAD-Net can aid in more applications. Left: the results of single-view reconstruction. Right: a subsequent CAD editing by changing the predicted cylinder primitives.
    }
    \label{fig:other_app}
\end{figure}

% \subsection{Applications: CAD Editing and Single-view Reconstruction}
\subsection{Other Applications}

By replacing the voxel encoder, SECAD-Net is flexible to reconstruct CAD models from other input shape representations, \eg, images and point clouds. Fig.~\ref{fig:other_app} shows the results of SECAD-Net in solving single-view reconstruction (SVR) task. Following the training strategy of previous work~\cite{chen2019learning,chen2020bsp}, we first use voxel data to complete the training of the 3D auto-encoding task, and then train an image encoder with the feature encoding of each shape as the target. The voxels and input images used for the SVR task are obtained directly from Fusion 360. Replacing more input representations, while feasible and meaningful, is not the focus of this paper and we leave it to future research.

%Finally, predictions of our method are fully interpretable, 
Finally, the parameters of both 2D sketches and 3D cylinders are available, thus the CAD results output from SECAD-Net can be directly loaded into existing CAD software for further editing. As shown in the right side of Fig.~\ref{fig:other_app}, interpretable CAD variations can be produced via specific editing operations, such as sketch-level curve editing, primitive-level displacement, rotation, scaling, and Boolean operations between primitives. 