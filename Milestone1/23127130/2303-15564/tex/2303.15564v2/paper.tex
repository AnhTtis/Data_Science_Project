
\documentclass{article} % For LaTeX2e
\usepackage{iclr2024_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{hyperref}
\usepackage{url}


\title{Mask and Restore: Blind Backdoor Defense at Test Time with Masked Autoencoder}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

\author{Tao Sun,  Lu Pang, Chao Chen, Haibin Ling  \\ %\thanks{ Use footnote for providing further information about author (webpage, alternative address)---\emph{not} for acknowledging funding agencies.  Funding acknowledgements go at the end of the paper.}
Stony Brook University\\
%Pittsburgh, PA 15213, USA \\
\texttt{\{tao,hling,luppang\}@cs.stonybrook.edu}, \texttt{\{chao.chen.1\}@stonybrook.edu} \\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.

\usepackage{bm}
\usepackage{array}
\usepackage{amsmath,amssymb}
\usepackage{booktabs}
\usepackage{array}
\usepackage{multirow}
\usepackage{stmaryrd}
\usepackage{colortbl}
\usepackage{threeparttable}

\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{subcaption}
\usepackage{enumitem}
\usepackage{graphicx}


\newcommand{\ling}[1]{\textcolor[rgb]{1.00,0,0.5}{#1}}
\newcommand{\lingg}[1]{\textcolor[rgb]{1.00,0.00,1.00}{[HL: #1]}}
\newcommand{\cc}[1]{\textcolor{red}{[CC: #1]}}
\newcommand{\ccinline}[1]{\textcolor{red}{#1}}
\newcommand{\ts}[1]{\textcolor{green}{[TS: #1]}}
\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}
\newcommand{\cparagraph}[1]{\smallskip\noindent\textbf{#1}}

\def\m{\bm{m}}
\def\x{\bm{x}}
\def\z{\bm{z}}

\newcommand{\etal}[0]{\textit{et al.}}
\newcommand{\eg}[0]{\textit{e.g.}}
\newcommand{\etc}[0]{\textit{etc}}
\newcommand{\ie}[0]{\textit{i.e.}}

\begin{document}


\maketitle

\begin{abstract}
 Deep neural networks are vulnerable to backdoor attacks, where an adversary maliciously manipulates the model behavior through overlaying images with special triggers. Existing backdoor defense methods often require accessing a few validation data and model parameters, which are impractical in many real-world applications, \eg, when the model is provided as a cloud service. In this paper, we address the practical task of blind backdoor defense at test time, in particular for black-box models. The true label of every test image needs to be recovered on the fly from a suspicious model regardless of image benignity. We focus on test-time image purification methods that incapacitate possible triggers while keeping semantic contents intact. Due to diverse trigger patterns and sizes, the heuristic trigger search in image space can be unscalable. We circumvent such barrier by leveraging the strong reconstruction power of generative models, and propose a framework of \emph{Blind Defense with Masked AutoEncoder} (BDMAE). It detects possible triggers in the token space using image structural similarity and label consistency between the test image and MAE restorations. The detection results are then refined by considering trigger topology. Finally, we fuse MAE restorations adaptively into a purified image for making prediction. Our approach is blind to the model architectures, trigger patterns and image benignity. Extensive experiments under different backdoor settings validate its effectiveness and generalizability. Code is available at \url{https://github.com/tsun/BDMAE}.
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}

Deep neural networks have been widely used in various computer vision tasks, like image classification~\citep{Krizhevsky2012imagenet}, object detection~\citep{girshick2014rich} and image segmentation~\citep{long2015fully}, \etc. Despite the superior performances, their vulnerability to backdoor attacks has raised increasing concerns~\citep{gu2019badnets,nguyen2020IAB,turner2019lc}. During training, an adversary can maliciously inject a small portion of poisoned data. These images contain special triggers that are associated with specific target labels. At inference, the backdoored model behaves normally on clean images but makes incorrect predictions on images with triggers.

To defend against backdoor behaviors, existing methods often require accessing a few validation data and model parameters. Some works reverse-engineer triggers~\citep{wang2019NC,guan2022shapley}, and mitigate backdoor by pruning bad neurons or retraining models~\citep{liu2018fine-pruning,wang2019NC,zeng2021i-bau}. The clean labeled data they require, however, are often unavailable. A recent work shows that the backdoor behaviors could be cleansed with unlabeled or even out-of-distribution data~\citep{pang2022backdoor}. Instead of modifying the model, Februus~\citep{doan2020februus} detects triggers with GradCAM~\citep{selvaraju2017grad}, and feeds purified images to the model. 

% With increasing concerns on data privacy and intellectual property, many models are provided as black-box where detailed parameters are concealed~\citep{dong2021black,guoaeva,chen2019deepinspect}, \eg, a cloud service API. Existing white-box defense methods are therefore no longer applicable.    

All these defending methods, although effective, assume the model is known. Such white-box assumption, however, may be violated in many real-world scenarios. Due to increasing concerns on data privacy and intellectual property, many models are provided as black-boxes where detailed parameters are concealed~\citep{dong2021black,guoaeva,chen2019deepinspect}, \eg, a cloud service API. It is thus crucial to address the problem for black-box models. 

In this paper, we tackle the extreme setting and address the task of \emph{Blind Backdoor Defense at Test Time}, in particular for black-box models. \emph{Blind} means that there is no information on whether the model and test images are backdoored or not. Shown in Fig.~\ref{fig:task}, the prediction model is black-box and may have been injected a backdoor. Test images come in a data stream. The true label of each test image is unknown; it needs to be recovered on the fly only from the hard label predictions of the suspicious model, without accessing additional data. This is a very challenging task that cannot be solved by existing test-time defense methods. Simply applying test-time image transformations~\citep{gao2019strip,sarkar2020backdoor,qiu2021deepsweep} without model retraining compromises model's accuracies on clean inputs~\citep{sarkar2020facehack}. Heuristic trigger search in image space~\citep{udeshi2022model,xiang2022patchcleanser} does not scale to complex triggers or large image sizes.

\begin{figure}[!t]
\centering	
\includegraphics[width=1.0\linewidth]{fig-png/task.pdf}
\vspace{-3mm}	
%\caption{Illustration of blind backdoor defense at test time. The prediction model is black-box and may be backdoored. Test images come in a data stream. The defender sanitizes every image to obtain the correct label prediction on-the-fly.}
\caption{Test time blind backdoor defense with a black-box prediction model (may be backdoored). Test images come in a stream. The defender purifies them to predict the correct labels on-the-fly.}
\label{fig:task}
\vspace{-3mm}
\end{figure}

To address the challenging task, we resort to the strong reconstruction power of modern image generation models. Intuitively, it can assist us to detect possible triggers and reconstruct the original clean image when the triggers are masked. We propose a novel method called \emph{Blind Defense with Masked AutoEncoder} (BDMAE). Masked Autoencoders~\citep{he2022masked} are scalable self-supervised learners. They randomly mask patches from the input image and reconstruct the missing parts. Each patch corresponds to one of 14$\times$14 tokens. Even using a high masking ratio (\eg, 75\%), the semantic contents can still be recovered. We can therefore search triggers efficiently in the token space. It enables us to generalize to complex trigger patterns or large image sizes.   

Our method belongs to test-time image purification that incapacitates possible triggers while keeping semantic contents intact. We seek trigger scores that measure how likely each image patch contains triggers. High score regions are then removed and restored with MAE. The whole framework includes three main stages. First, we randomly generate MAE masks, and calculate two types of trigger scores based on image structural similarity and label prediction consistency between test images and MAE restorations, respectively. Then, we use the topology of triggers to refine both scores. The trigger scores help to generate topology-aware MAE masks that cover trigger regions more precisely, and the corresponding MAE restorations in turn help to refine trigger scores. Finally, we fuse multiple MAE restorations from adaptive trigger score thresholding into one purified image, and use that image for label prediction. Our approach is blind to the network architecture, trigger patterns or image benignity. It does not require additional training images for a particular test-time defense task. Extensive results demonstrate that BDMAE effectively purifies backdoored images without compromising clean images. BDMAE is generalizable to diverse trigger sizes and patterns.


Our main contributions are summarized as follows:
\begin{enumerate}[leftmargin=*,itemsep=-0.5mm]
\vspace{-3mm}\item We address the practical task of blind backdoor defense at test time and for black-box models. Despite some general techniques for simple attacks, this challenging task has not been formally and systematically studied.

\item We propose to leverage generative models to assist backdoor defense. It may open a door to design general defense methods under limited data using abundant public foundation models. 

\item A novel framework of Blind Defense with Masked Autoencoders (BDMAE) is devised to detect possible triggers and restore images on the fly. Three key stages are delicatedly designed to generalize to different defense tasks without tuning hyper-parameters.

\item We evaluate our method on four benchmarks, Cifar10~\citep{krizhevsky2009cifar10}, GTSRB~\citep{stallkamp2012gtsrb}, ImageNet~\citep{deng2009imagenet} and VGGFace2~\citep{cao2018vggface2}. Regardless of model architectures, image sizes or trigger patterns, our method obtains superior accuracies on both backdoored and clean images.
\end{enumerate}

\vspace{-3mm}
\section{Related Works}
\vspace{-2mm}\textbf{Backdoor attack.}
BadNets~\citep{gu2019badnets} is the earliest work on backdoor attack. It attaches a checkerboard trigger to images and associates them with specific target labels. Many different trigger patterns are used in later works~\citep{nguyen2020IAB,turner2019lc,wenger2021backdoor}. These triggers are visible local patches in the images. Visible global triggers are used in~\citep{chen2017targeted,barni2019sig}. To make the attack stealthy, invisible patterns~\citep{li2021invisible, zhong2022imperceptible,zhao2022defeat} and attacking strategies based on reflection phenomenon~\citep{liu2020reflection}, image quantization and dithering~\citep{wang2022bppattack}, style transfer~\citep{cheng2021deep} and elastic image warping~\citep{nguyen2021wanet} are proposed. Although these stealthy attacks are less perceptible to humans, they are vulnerable to noise perturbations or image transformations. To make it hard for defenders to reconstruct triggers, sample-specific backdoor attacks~\citep{li2021invisible, nguyen2020IAB} are proposed. This paper focuses on the visible triggers of local patches. The triggers can be either shared by samples or sample-specific.


\vspace{-1.4mm}\cparagraph{Backdoor defense.}
Backdoor defense aims to mitigate backdoor behaviors. The training-stage defenses attempt to design robust training mechanism via decoupling training process~\citep{huang2022backdoor}, introducing multiple gradient descent mechanism~\citep{li2021anti} or modifying linearity of trained models~\citep{wang2022training}. However, intruding the training stage is often infeasible. Model reconstruction defenses mitigate backdoor behaviors by pruning bad neurons or retraining models using clean labeled data~\citep{liu2018fine-pruning,wang2019NC,zeng2021i-bau}. A recent work shows that backdoor behaviors could be cleansed by distillation on unlabeled data or even out-of-distribution data~\citep{pang2022backdoor}. Februus~\citep{doan2020februus} is a test-time defense method. It detects triggers with GradCAM~\citep{selvaraju2017grad}, and feeds purified images to the model. 

Recently, black-box backdoor models have drawn increasing attention~\citep{chen2019deepinspect,dong2021black,guoaeva,zhang2021tad}. In this setting, model parameters are concealed for data privacy or intellectual property. %Some black-box backdoor detection methods~\citep{dong2021black,guoaeva} have been proposed. 
These works focus on identifying backdoored models, and usually reject predictions for such situations. Differently, we handle the task of blind backdoor defense at test time, aiming to obtain true label of every test image on the fly, with only access to the hard-label predictions. Test-time image transformation~\citep{gao2019strip,sarkar2020backdoor,qiu2021deepsweep} and heuristic trigger search in image space~\citep{udeshi2022model} do not work well. 

%We handle this by detecting triggers and restoring images with generic Masked Autoencoders~\citep{he2022masked}.

%DeepInspect~\citep{chen2019deepinspect} uses a generative model to learn distribution of possible triggers, though it still requires model gradients. B3D~\citep{dong2021black} proposes a gradient-free optimization algorithm to reverse-engineer potential triggers from predictive confidence scores. AEVA~\citep{guoaeva} utilizes adversarial singularity phenomenon to detect backdoor model from hard labels. 

\vspace{-1.4mm}\cparagraph{Masked AutoEncoder.}
Masked AutoEncoders (MAE)~\citep{he2022masked} are scalable self-supervised learners based on Vision Transformer~\citep{dosovitskiy2021an}. It masks random patches of the input image, and restore the missing pixels. MAE has been used in many vision tasks~\citep{bachmann2022multimae,pang2022masked,tong2022videomae,xie2022simmim,chen2022sdae,li2022uniform}. Motivated by the powerful and robust data generation ability, for the first time we leverage MAE to detect triggers and restore images. %Our work can be extended to many other generative models~\citep{xie2022simmim,chen2022sdae,li2022uniform}.


%\section{Philosophy of BDMAE}
\section{{Motivation and Intuition}}

Blind backdoor defense at test time aims to obtain correct label prediction for test images on-the-fly regardless the benignity of images and models. To solve this, test-time image purification is a viable solution that incapacitates backdoor triggers within images while keeping semantic contents intact. Some early works apply a global image transformation like blurring or shrinking~\citep{sarkar2020backdoor,qiu2021deepsweep,li2021backdoor}. However, there is often a trade-off in selecting the strength. A stronger transformation is more likely to incapacitate the trigger but at a higher risk of ruining the semantic information. Recently, diffusion model based image purification methods~\citep{nie2022diffusion,wang2022guided} leverage pretrained diffusion models to restore the content, but they highly reply on the image generation quality. When the test data distribution is different from the pretrained data distribution (\textit{e.g.}, different image resolutions), the generated images may appear overall similar to the original test images but still different in the details. This makes it hard for the classifier to predict true labels.

Our motivation is to locate possible triggers and restore the missing contents simultaneously. The clean regions are kept intact. With this, the model predictions on clean images or clean models are minimally affected. Searching triggers in images can be challenging considering the diversity of trigger patterns and image sizes. Fortunately, with the help of pretrained Masked AutoEncoders (MAE), we can instead search triggers in the token space and use MAE to restore missing parts. 

Compared with previous works, ours is fundamentally different in that
\begin{itemize}[leftmargin=*,itemsep=-0.5mm]
    \vspace{-2mm}\item We care about accuracies on both clean images and backdoored images, unlike other defense methods that only filter out backdoored images and refuse to make predictions on them.
    \item We leverage pretrained MAE models mainly to assist trigger search, unlike diffusion-based methods that leverage pretrained generative models to hallucinate the entire image contents. 
\end{itemize}


\begin{figure}[!t]
	\centering	
	\includegraphics[width=1.0\linewidth]{fig-png/framework.pdf}

	\caption{Framework of our method. For a test image (may be backdoored), we generate the trigger score and refine it by considering the topology of triggers. The purified image obtained from adaptive restoration is used for making prediction.} 
	\label{fig:frame}

\end{figure}

\section{Methodology}

\subsection{Problem Formulation}

%We first formulate the backdoor attack and defense problems. Then we detail the proposed method of \emph{Blind Defense with Masked AutoEncoder} (BDMAE) with three key stages, as shown in Fig.~\ref{fig:frame}. At a high level, our main idea is to seek a purified version of every test image for making prediction. We efficiently detect possible triggers with the help of MAE and restore missing parts.
\vspace{-2mm}We first formulate the backdoor attack and defense problems, then detail the proposed method of \emph{Blind Defense with Masked AutoEncoder} (BDMAE) (Fig.~\ref{fig:frame}). Our key idea is to detect possible triggers with the help of MAE. % and restoring missing parts.


\vspace{-1.4mm}\cparagraph{Backdoor attack.}
Given a set of clean data $D=\{(\x,y)\}$, an adversary generates backdoored data $\tilde{D}=\{(\Phi{(\x)}, \eta(y))|(\x,y)\in D\}$, where $\Phi(\cdot)$ transforms a clean image into a backdoored image and $\eta(\cdot)$ transforms its true label into a target label. In this paper, we consider the popular formulation of $\Phi(\x)=(1-\bm{b}_{\x})\odot \x + \bm{b}_{\x}\odot \bm{\theta}_{\x}$, where $\bm{b}_{\x}$ is a binary mask, $\bm{\theta}_{\x}$ is the backdoor trigger,  $\odot$ denotes the Hadamard product~\citep{dong2021black,hu2021trigger,zheng2021topological}. $\eta(y)$ maps all true labels to one predefined target label. The mask and trigger  may not be the same for different images. While triggers can span over the entire image, we only focus on local triggers that occupy a small area of the image. A prediction model $f$ is obtained by training on both clean data and backdoored data. In the situation without backdoor attack, $f$ is obtained from clean data only.

\vspace{-1.4mm}\cparagraph{Black-box test-time defense.}
At test time, the suspicious model $f$ is provided as a black box and only its hard label predictions are accessible. The true label of each test image $\x$ needs to be recovered on the fly, without accessing additional data. To realize this, we seek a purified version $\rho(\x)$ such that $f(\rho(\x))$ generates the correct label prediction. The test process is blind to the model or images, meaning that there is no information on whether $f$ is backdoored and whether $\x$ contains triggers. The goal is to achieve high classification accuracies on both clean and backdoored images. 


\subsection{Trigger Score Generation}

For clarity, we assume that $f$ is backdoored and the test image $\x$ contains triggers. Our method can directly apply to clean models or clean images (\textit{c.r.} Sec.\ref{sec:clean}). Let $\hat{y}=f(\x)$ be its original label prediction. To infer the trigger mask, one can repeatedly block some particular parts of the image and observe how model predictions change~\citep{udeshi2022model}. However, the search space is huge for a common image size. Even worse, when the trigger is complex (\eg, of irregular shape), the model may still predict the target label when some parts of the trigger remain in the image. These issues make the na\"ive trigger search method infeasible in practice.  
 
We overcome the above-mentioned issues by leveraging the generic Masked AutoEncoders (MAE)~\citep{he2022masked}. In MAE, each of the 14$\times$14 tokens corresponds to a square patch of the image. MAE can recover the image content even when 75\% tokens are masked out. This brings two benefits: 1) we can safely use a high masking ratio to remove triggers without changing the semantic label; and 2) since triggers are irrelevant to the content, they will unlikely present in the MAE restorations. To locate possible triggers, there are two complementary approaches:
the \textbf{image-based} method that compares the \textit{structural similarity} between the original image and MAE restorations, and the \textbf{label-based} method that compares the \textit{consistency of label predictions} on the original image and MAE restorations. 

% %\begin{itemize}[left=2em]
% \begin{itemize}[leftmargin=2em,itemsep=-0.5mm]
%     \item \textbf {Image-base:} comparing the \textit{structural similarity} between the original image and MAE restorations.
%     \item \textbf {Label-base:} comparing the \textit{consistency of label predictions} on the original image and MAE restorations. 
% \end{itemize}
We use both approaches to obtain an image-based trigger score matrix $S^{(i)}\in[0,1]^{14\times 14}$ and a label-based trigger score matrix $S^{(l)}\in[0,1]^{14\times 14}$. Each element of $S^{(i)}$ or $S^{(l)}$ thus implies how likely the corresponding image patch contains backdoor triggers. Compared with searching in the image space of size $H\times W$, searching in the token space of size $14\times 14$ is much more efficient.

%Let $H$ and $W$ be the height and width of the test image $\x$. We define a function $\mathtt{resize}(\z;h,w)$ that maps a tensor $\z$ to the size of $h\times w$ by interpolation. Our goal is to obtain a \ling{trigger likelihood matrix} $S\in[0,1]^{14\times 14}$ that has high values for trigger regions and low values for clean regions, and each region corresponds to one of the $14\times 14$ tokens, \ie, image patches. This reduces the search space \ling{compared with}\lingg{??} trigger score of image size. 

%To avoid confusion, we use a superscript $^T$ for any tensor of $14\times 14$, and blank superscript for $H\times W$. 

Before going to the method, we first describe how to restore $\x$ given a pre-trained MAE $G$ and a token mask $\m\in \{0,1\}^{14\times 14}$. Define a function $\mathtt{resize}(\z;h,w)$ that resizes a tensor $\z$ to size $h\times w$ by interpolation. As shown in Eq.~\ref{eq:MAE}, $\x$ is first resized to 224$\times$224 requested by MAE. Then we use $G$ to reconstruct the image based on $\m$, and resize it back to $H\times W$. The additional steps aim to remove interpolation errors in the unmasked regions from the restoration $\tilde{\x}$.
\begin{equation}\label{eq:MAE}
	\begin{aligned}
		  \bar{\x}    &=\mathtt{resize}\big(G(\mathtt{resize}(\x;224,224);\m);H,W\big) \\
		\tilde{\m}  &=\mathtt{resize}(\m;H,W) \\
		\tilde{\x}  &= \x\odot (1-\tilde{\m})+ \bar{\x}\odot \tilde{\m} \\
		\tilde{G}(\x,\m) &\triangleq (\tilde{\x},\tilde{\m})
	\end{aligned}
\end{equation}
%
%Algorithm~\ref{alg: triggerGen} describes the procedure to generate trigger-region scores, $S^{(i)}$ and $S^{(l)}$\lingg{what is the difference between the two?}. 
%
Now we describe how to obtain trigger scores $S^{(i)}$ and $S^{(l)}$ from MAE restorations. %Given the test image $\x$, 
Let $\hat{y}=f(\x)$ be its original hard-label prediction. We repeat the following procedure for $N_o$ times indexed by $o$. For each iteration, $N_i$ random token masks $\{\m_{o,i}\in\{0,1\}^{14\times 14}$\} are sampled using a default masking ratio of 75\%. The corresponding MAE reconstructions $\{\tilde{\x}_{o,i}\}$ and masks $\{\tilde{\m}_{o,i}\}$ are extracted from $ \tilde{G}(\x,\m_{o,i})$ based on Eq.~\ref{eq:MAE}. Their hard-label predictions are $\{\hat{y}_{o,i}=f(\tilde{\x}_{o,i})\}$.

\vspace{-1.4mm}\cparagraph{Image-based score $S^{(i)}$.} We fuse $N_i$ restorations into one image $\tilde{\x}_o$ by:
\begin{equation}\label{eq:fuse}
	\tilde{\x}_o=\mathcal{F}\big(\{\tilde{\x}_{o,i}\},\{\tilde{\m}_{o,i}\}\big)=\sum_i (\tilde{\x}_{o,i}\odot \tilde{\m}_{o,i})	\oslash \sum_i (\tilde{\m}_{o,i}) 	
\end{equation}
where $\odot$ and $\oslash$ are element-wise product and division. In Eq.~\ref{eq:fuse}, only image patches from MAE restorations are kept while other patches from the original image are discarded. The motivation is that triggers may not always be fully masked out, but we do not want them to appear in $\tilde{\x}_o$. We manipulate the sampling of $\{\m_{o,i}\}$ to guarantee that every image patch can be restored with Eq.~\ref{eq:fuse}.

The image-based score is defined as $S^{(i)}=\sum_o [1-\mathtt{resize}(\mathrm{SSIM}(\x, \tilde{\x}_{o});14,14)]/N_{o}$, averaged over $N_o$ repeated procedures. Here we use Structural Similarity Index Measure (SSIM)~\citep{wang2004image} to calculate the similarity between $\tilde{\x}_o$ and $\x$, where the SSIM score lies between $-1$ and $1$. As triggers are irrelevant to contents and unlikely present in $\tilde{\x}_o$, SSIM scores in the trigger region will be low. In contrast, the clean regions will be well restored, leading to high SSIM scores. 

\vspace{-1.4mm}\cparagraph{Label-based score $S^{(l)}$}. We average over token masks that lead to different label predictions. Formally, the label-based score is defined as $S^{(l)}=\sum_{o,i}[\m_{o,i}\times(1-\mathbb{I}[\hat{y}=\hat{y}_{o,i}] )]/(N_o N_i)$, where $\mathbb{I}[\cdot]$ is the indicator function. The inconsistency in label predictions usually implies that triggers have been removed by the masks.

The two types of trigger scores are complementary to each other. $S^{(i)}$ favors large and complex triggers, while $S^{(l)}$ favors small triggers. Using both together can adapt to diverse trigger patterns. 


\subsection{Topology-aware Score Refinement}
The trigger scores $S^{(i)}$ and $S^{(l)}$ obtained previously have high values for trigger regions. Nevertheless, they are still very noisy. The difference between scores of trigger regions and clean regions is also small, making it hard to determine a universal threshold for filtering out trigger regions.

We utilize the topology of triggers to refine trigger scores. Note that backdoor triggers are commonly continuous patterns~\citep{hu2021trigger}. The obtained trigger scores indicate possible positions of triggers among the image. With the information, we can generate topology-aware MAE masks $\{\m_r\in\{0,1\}^{14\times 14}\}$ that cover trigger regions more precisely than uniformly sampled ones. This in turn guides us to enhance the difference between score values of clean regions and trigger regions. One issue is that if we apply refinement for all tokens, we may accidentally increase the score values of clean regions in the situation of clean images or clean models. To avoid this, we only focus on the top $L$ tokens that likely contain triggers, with $L=\sum_{r,c}\mathbb{I}[S^{(i)}_{r,c}\geq 0.2]$ or $L=\sum_{r,c} S^{(l)}_{r,c}$. Equivalently, a meta mask $\m_{\rm rf}\in \{0,1\}^{14\times 14}$ can be defined, whose element is 1 only if the corresponding token belongs to the top $L$ tokens. $\m_{\rm rf}$ thus indicates the regions to be refined. 

We use the same procedure to generate topology-aware MAE mask $\m_r$ for both types of trigger scores. The main idea is to sequentially select tokens that have higher trigger scores or are adjacent to already selected tokens. For clarity, let $S^{(*)}$ denote either $S^{(i)}$ or $S^{(l)}$. We initialize $\mathcal{T}=\{t_0\}$ with token $t_0=\arg\max_{t_k} S^{(*)}[t_k]$. Then we repeatedly add token $t_i=\arg\max_{t_k} (S^{(*)}[t_k]+0.5\mathbb{I}[t_k \in \texttt{Adj}(\mathcal{T}) ])\cdot \sigma_{k} $ to $\mathcal{T}$, where $\texttt{Adj}(\mathcal{T})$ includes all 4-nearest neighbors of tokens in $\mathcal{T}$ and $\sigma_{k}\sim U(0,1)$ is a random variable. This step achieves a balance between random exploration and topology-aware exploitation. The process continues until $|\mathcal{T}|=L/2$. The final $\mathcal{T}$ can be converted into an MAE mask $\m_r$, with its complementary part $\bar{\m}_{r}=\m_{\rm rf}-\m_{r}$. 

To refine the trigger score, we obtain the hard-label prediction $\hat{y}_r$ of MAE restoration based on $\m_r$. If $\hat{y}_r\neq \hat{y}$, we increase the score values of 
$S^{(*)}$ by a constant $\beta_0$ for tokens masked by $\m_r$ and $-\beta_0$ for other tokens; otherwise, we modify $S^{(*)}$ in an opposite way. Mathematically, $S^{(*)}\leftarrow S^{(*)}+(1-2\mathbb{I}[ \hat{y}=\hat{y}_{r} ])\times \beta_0\times(\m_{r}-\bar{\m}_{r})$. Since $\|\m_r\|_0=\|\bar{\m}_{r}\|_0=L/2$, the average value of $S^{(*)}$ remains unchanged, while the contrast between trigger region and clean region are enhanced.

% The procedure is summarized in Alg.~\ref{alg:triggerRefine}. 


\subsection{Adaptive Image Restoration}

The combined trigger score used for label prediction is simply calculated as $S=(S^{(i)}+S^{(l)})/2$. One can convert $S$ into a binary mask based on some predefined threshold, and make prediction on the corresponding MAE restoration. However, the optimal threshold varies across different attack settings considering the diversity of image resolutions, backdoor attack methods, and trigger sizes.

We propose an adaptive image restoration mechanism to adapt to different attacks and datasets automatically. The idea is to fuse restorations from $K$ adaptive thresholds, $\{\tau_1\geq \tau_2\geq \cdots\geq \tau_K\}$. If $\sum_{r,c}\mathbb{I}[S_{r,c}\geq \tau_K]/(14\times 14) \leq 25\%$ is not satisfied, we repeatedly increase all thresholds by a small amount. The rationale is that trigger regions should not dominate the image. 
%
These decreasing thresholds lead to a nest structure. We obtain the corresponding MAE restorations $\{\tilde{\x}_{\tau_k},\tilde{\m}_{\tau_k}=\tilde{G}(\x,\m_{\tau_k})\}$, where $\m_{\tau_k}[r,c] = \mathbb{I}[S[r,c]\geq \tau_k]$, and then fuse them into one purified image $\rho(\x)=\mathcal{F}(\{\tilde{\x}_{\tau_k}\},\{\tilde{\m}_{\tau_k}\})$. The model prediction $f(\rho(\x))$ is used for final evaluation. 

%Using $\tau_1$ removes the least number of tokens while using $\tau_K$ removes the most number of tokens. 

\subsection{Generalization to Clean Images and Clean Models}\label{sec:clean}
Until now, we assume that both $f$ and $\x$ are backdoored. In practice, we deal with blind defense, meaning that both models and images can be either backdoored or clean. Our method directly applies to any of these situations, thanks to the dedicated designs. The effectiveness on clean images has been validated by CA metric. For clean models, we include discussions in Appendix Sec.~\ref{sec:supp:clean}.


\begin{table*}[!t]
\caption{Comparison with diffusion model based image purification method (500 test images). }
\renewcommand{\tabcolsep}{0.1cm}
\centering
\scriptsize
\vspace{-2mm}
\scalebox{1.0}{
\begin{tabular}{p{1.0cm}p{1.3cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}}
			\toprule
			\multirow{3}{*}{}  & & \multicolumn{3}{c|}{\texttt{Cifar10}} & \multicolumn{3}{c|}{\texttt{GTSRB}} & \multicolumn{3}{c|}{\texttt{VGGFace2}} & \multicolumn{3}{c|}{\texttt{ImageNet10}} & \multicolumn{3}{c}{\texttt{ImageNet50}}& \multicolumn{3}{|c}{\texttt{ImageNet100}} \\
		\cmidrule{3-20}	
			 & & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR \\
			\midrule
		\multicolumn{2}{c|}{Before Defense}    & 94.0 & 1.0 & 99.0 & 99.7 & 1.1 & 98.9 & 96.7 & 0.0 & 100. & 88.6 & 9.4 & 89.4 & 84.4 & 0.7 & 99.2 & 81.7 & 0.3 & 99.6\\
		\midrule
		 \multirow{2}{*}{DiffPure} & DDPM   & 74.5 & 64.5 & 16.2 & 74.2 & 41.0 & 44.8 & 51.9 & 32.9 & 34.4 & 71.1 & 66.5 & 5.5 & 57.4 & 52.7 & 0.9 & 51.8 & 53.9 & 0.6\\
           & SDE  & 75.5 & 63.9 & 15.6 & 71.7 & 42.8 & 44.4 & 52.8 & 33.6 & 35.5 & 73.2 & 67.6 & 5.1 & 54.1 & 57.2 & 1.1 & 52.8 & 53.8 & 0.7\\
             \midrule
		\multirow{2}{*}{Ours} & Base  & 92.9 & 90.3 & 0.9 & 99.7 & 95.5 & 0.7 & 93.7 & 92.6 & 0.9 & 79.6 & 79.3 & 3.0 & 60.7 & 68.8 & 0.5 & 57.4 & 70.4 & 0.4\\
		&  Large   & 93.3 & 90.3 & 0.7 & 99.7 & 96.0 & 1.1 & 94.3 & 91.9 & 1.9 & 84.1 & 81.1 & 2.8 & 71.3 & 75.2 & 0.6 & 65.4 & 76.2 & 0.4\\
			\bottomrule
		\end{tabular} }
\label{tab:dp_results}
\end{table*}


% \renewcommand{\tabcolsep}{0.1cm}
\begin{table*}[!t]
\caption{Comparison with other image purification methods. ($^\diamond$: white-box; others: black-box.)}% method and others are black-box methods.)}
\renewcommand{\tabcolsep}{0.1cm}
\centering
\scriptsize
\vspace{-2mm}
\scalebox{1.0}{
\begin{tabular}{p{1.0cm}p{1.3cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}}
			\toprule
			\multirow{3}{*}{}  & & \multicolumn{3}{c|}{\texttt{Cifar10}} & \multicolumn{3}{c|}{\texttt{GTSRB}} & \multicolumn{3}{c|}{\texttt{VGGFace2}}  & \multicolumn{3}{c|}{\texttt{ImageNet10}}  & \multicolumn{3}{c|}{\texttt{ImageNet50}} & \multicolumn{3}{c}{\texttt{ImageNet100}}  \\
		\cmidrule{3-20}	
			 & & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR\\
			\midrule
		\multicolumn{2}{c|}{Before Defense} & 93.3 & 0.9 & 99.0 & 98.5 & 1.4 & 98.6 & 95.5 & 0.0 & 100. & 89.5 & 9.7 & 89.2 & 84.0 & 0.5 & 99.4 & 82.3 & 0.2 & 99.8\\
		\midrule
		 \multirow{2}{*}{Februus$^\diamond$} & XGradCAM     & 91.6 & 87.0 & 7.0 & 65.4 & 50.9 & 38.0 & 65.5 & 89.5 & 5.8 & -- & -- &  -- & -- & -- & -- & -- & -- & -- \\
		  & GradCAM++    & 80.0 & 91.0 & 2.3 & 59.1 & 73.9 & 14.6 & 63.1 & 89.4 & 5.9 & -- & -- &  -- & -- & -- & -- & -- & -- & --  \\
		\midrule          
             \multirow{2}{*}{PatchCleanser} & Vanilla  & 89.9 & 43.9 & 55.0 & 95.0 & 10.0 & 89.7 & 93.0 & 43.0 & 56.9 & 84.5 & 58.0 & 37.1 & 79.6 & 45.7 & 49.4 & 78.9 & 43.4 & 52.3\\
             & Variant   & 57.6 & 86.1 & 1.9 & 13.3 & 80.8 & 1.5 & 50.7 & 94.7 & 0.0 & 62.0 & 80.8 & 4.1 & 54.1 & 79.3 & 0.4 & 52.1 & 78.0 & 0.1\\
             \cline{1-2}
             % \cmidrule(l{5pt}r{5pt}){1-2}
            \multirow{2}{*}{Blur} & Weak  & 91.5 & 14.0 & 84.9 & 98.4 & 3.9 & 96.0 & 95.5 & 0.1 & 100. & 88.4 & 14.4 & 83.9 & 83.3 & 4.9 & 94.3 & 81.2 & 3.2 & 96.1\\
             & Strong   & 63.6 & 60.0 & 6.4 & 97.7 & 94.9 & 1.8 & 95.2 & 10.4 & 89.4 & 84.8 & 34.2 & 60.9 & 79.2 & 49.1 & 39.3 & 76.0 & 51.6 & 33.1\\
             % \cmidrule(l{5pt}r{5pt}){1-2}
            % OptDist & & \\
            % \cmidrule(l{5pt}r{5pt}){1-2}
            \cline{1-2}
            \multirow{2}{*}{ShrinkPad} & Weak   & 90.7 & 50.3 & 45.0 & 97.5 & 33.3 & 65.0 & 93.8 & 35.5 & 62.5 & 88.4 & 43.0 & 52.1 & 82.0 & 39.7 & 51.1 & 80.0 & 42.3 & 46.0\\
            & Strong   & 86.7 & 36.7 & 57.9 & 92.8 & 23.5 & 72.3 & 88.3 & 54.4 & 38.3 & 86.7 & 56.7 & 36.0 & 79.4 & 55.1 & 29.8 & 77.2 & 58.6 & 22.5\\
             \midrule
		\multirow{2}{*}{Ours} & Base   & 92.5 & 90.8 & 0.9 & 98.2 & 95.3 & 0.9 & 91.3 & 92.0 & 1.6 & 79.9 & 81.1 & 4.8 & 61.7 & 70.1 & 0.8 & 59.0 & 67.9 & 0.4\\
		&  Large   & 92.7 & 91.1 & 0.8 & 98.4 & 96.0 & 0.9 & 92.9 & 91.8 & 2.2 & 83.9 & 83.7 & 3.9 & 72.6 & 76.1 & 0.6 & 69.5 & 73.9 & 0.3\\
			\bottomrule
		\end{tabular} }
\label{tab:agg_results}
\end{table*}



\section{Experiments}

% \subsection{Experiment Settings}

\subsection{Experimental Setup}
% \ts{Due to page limit, we describe some key setup here. Please refer to the supplementary for additional details.}

\vspace{-2mm}\textbf{Datasets.}
We evaluate our method on the commonly used \texttt{Cifar10}~\citep{krizhevsky2009cifar10}, \texttt{GTSRB}~\citep{stallkamp2012gtsrb}, \texttt{VGGFace2}~\citep{cao2018vggface2}, and three \texttt{ImageNet}~\citep{deng2009imagenet} subsets, including \texttt{ImageNet10}, \texttt{ImageNet50} and \texttt{ImageNet100}.


% We evaluate our method on \texttt{Cifar10}, \texttt{GTSRB}, \texttt{ImageNet10} and \texttt{VGGFace2}. \texttt{Cifar10} is a 10-class scene classification dataset of image  size 32$\times$32~\citep{krizhevsky2009cifar10}. \texttt{GTSRB} consists of 43-class traffic signs images of size 32$\times$32~\citep{stallkamp2012gtsrb}. \texttt{ImageNet10} is a 10-class subset of \texttt{ImageNet}~\citep{deng2009imagenet}, resized to 224$\times$224. For the face recognition dataset \texttt{VGGFace2}~\citep{cao2018vggface2}, we use images from 170 randomly selected classes~\citep{doan2020februus}, and resize them to 224$\times$224.

\vspace{-1.4mm}\cparagraph{Backdoor attacks settings.} We use BadNet~\citep{gu2019badnets} with different triggers, Label-Consistent backdoor attack (LC)~\citep{turner2019lc}, Input-Aware dynamic Backdoor attack (IAB)~\citep{nguyen2020IAB}, and Blended attack~\citep{chen2017targeted} to build backdoored models. For \texttt{Cifar10} and \texttt{GTSRB}, the backbone network is ResNet18~\citep{he2016resnet} from random initialization. We conduct 14 repeated experiments from random target labels or initializations for each attack setting. For \texttt{VGGFace2} and \texttt{ImageNet}, we use pretrained ResNet50~\citep{he2016resnet} and conduct 6 repeated experiments. The backdoor triggers include white/color patches, small image patches, and random curves.


\vspace{-1.4mm}\cparagraph{Method configurations.} We use the publicly available Masked Autoencoders~\citep{he2022masked} pretrained on ImageNet to assist blind defense. The \texttt{Base} variant has 12 encoder layers, and the \texttt{Large} variant has 24 encoder layers with an increased hidden size dimension. The same hyper-parameters are used for all experiments. The initial thresholds used in our work is $\{0.6,0.55,0.5,0.45,0.4\}$. 

%Besides full method, we present results of two ablative variants: \texttt{Ours}-$i$ using $S^{(i)}$ only, and \texttt{Ours}-$l$ using $S^{(l)}$ only.


\vspace{-1.4mm}\cparagraph{Baseline methods.} We compare with several different lines of methods. \textbf{Blur} and \textbf{ShrinkPad}~\citep{li2021backdoor} are two simple purification methods based on test-time image transformation. More transformations are discussed in Appendix Sec.~\ref{sec:supp:ttt}. \textbf{PatchCleanser}~\citep{xiang2022patchcleanser} is a certifiably robust defense method against adversarial patches via double-masking. \textbf{DiffPure}~\citep{nie2022diffusion} uses diffusion models for adversarial purification. In addition to these black-box methods, we also compare with a white-box method \textbf{Februus}~\citep{doan2020februus} that uses GradCAM~\citep{selvaraju2017grad} to locate triggers and restores missing parts with GAN models~\citep{goodfellow2014generative}.

%Methods based on test-time image transformations~\citep{gao2019strip,sarkar2020backdoor,qiu2021deepsweep} compromise accuracies unacceptably in our setting. We therefore compare with a representative white-box method, Februus~\citep{doan2020februus}. It detects possible triggers with GradCAM~\citep{selvaraju2017grad}, and trains GAN models to restore missing regions. We find that GradCAM does not generalize to complex networks, thus we replace it with two improved methods, XGradCAM~\citep{fu2020axiom} and GradCAM++~\citep{chattopadhay2018grad}. The choice of visualization score threshold in Februus is critical. We try with $\{0.6, 0.7, 0.8\}$ and report the best result for each attack setting individually. We use the GAN models released by the authors for image restoration.  

\vspace{-1.4mm}\cparagraph{Evaluation metrics} include the classification accuracy on clean images (CA) and backdoored images (BA), as well as attack success rate (ASR). Due to page limit, we only report results averaged over all backdoor triggers in the main text, and leave detailed results in Appendix Sec.~\ref{sec:detailed_results}.



\begin{table*}[!t]
 \caption{Comparison results on three challenging attacks, IAB, LC and Blended. (\texttt{VF2} short for \texttt{VGGFace2}, and \texttt{IN10} short for \texttt{ImageNet10}.)}
\begin{center}
\renewcommand{\tabcolsep}{0.1cm}
\centering
\scriptsize
\vspace{-3mm}
\scalebox{1.0}{
\begin{tabular}{p{1.0cm}p{1.3cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}}
\toprule
 \multirow{3}{*}{} & & \multicolumn{3}{c|}{\texttt{Cifar10}--IAB} & \multicolumn{3}{c|}{\texttt{GTSRB}--IAB} & \multicolumn{3}{c|}{\texttt{Cifar10}--LC} & \multicolumn{3}{c|}{\texttt{GTSRB}--LC} & \multicolumn{3}{c|}{\texttt{VF2}--Blended}  & \multicolumn{3}{c}{\texttt{IN10}--Blended}  \\
		  \cmidrule{3-20}
			& & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR \\
			\midrule
		\multicolumn{2}{c|}{Before Defense}  
        & 93.4 & 1.6 & 98.4 & 98.0 & 1.2 & 98.7 & 94.5 & 0.5 & 99.5 & 95.8 & 5.3 & 94.7 & 95.1 & 1.9 & 98.1 & 86.5 & 28.4 & 68.4\\
		\midrule		
		  \multirow{2}{*}{Februus$^\diamond$} & XGradCAM  & 91.7 & 29.9 & 68.1 & 68.4 & 72.5 & 24.8 & 92.6 & 63.7 & 33.9 & 80.6 & 91.7 & 5.1 & 68.9 & 74.6 & 21.4 & -- & -- & --\\
		 & GradCAM++   & 77.9 & 55.8 & 35.9 & 49.8 & 84.1 & 12.2 & 83.3 & 85.7 & 10.4 & 72.5 & 91.7 & 5.1 & 66.4 & 72.5 & 23.6 & -- & -- & --\\
        \midrule
        \multirow{2}{*}{PatchCleanser} & Vanilla  & 88.6 & 25.6 & 73.8 & 84.2 & 13.9 & 83.0 & 90.3 & 0.4 & 99.6 & 87.8 & 0.1 & 99.9 & 92.8 & 41.7 & 58.2 & 79.3 & 56.1 & 38.2\\
        & Variant  & 62.2 & 66.7 & 26.3 & 16.6 & 83.0 & 6.7 & 56.5 & 4.7 & 95.3 & 9.8 & 6.0 & 94.0 & 47.0 & 93.4 & 1.4 & 56.5 & 68.7 & 15.5\\
        \midrule
         \multirow{2}{*}{Blur} & Weak   & 91.3 & 33.9 & 63.7 & 97.8 & 18.6 & 81.2 & 92.5 & 92.3 & 0.7 & 95.5 & 95.1 & 1.2 & 95.1 & 38.0 & 60.7 & 86.5 & 47.5 & 46.8\\
        & Strong & 63.0 & 53.1 & 8.4 & 96.8 & 47.7 & 50.7 & 56.8 & 56.1 & 2.5 & 93.7 & 93.6 & 0.7 & 94.9 & 94.7 & 0.3 & 82.6 & 73.6 & 12.8\\
  	\midrule
        \multirow{2}{*}{ShrinkPad} & Weak   & 91.2 & 64.5 & 28.8 & 97.1 & 43.7 & 55.1 & 92.4 & 1.4 & 98.6 & 93.6 & 5.9 & 94.1 & 93.5 & 88.6 & 5.1 & 86.3 & 83.3 & 4.8\\
        & Strong   & 88.5 & 80.6 & 7.1 & 93.1 & 62.2 & 32.5 & 89.7 & 85.1 & 6.1 & 81.8 & 68.0 & 23.1 & 87.0 & 86.1 & 1.0 & 84.5 & 80.3 & 5.4\\
  	\midrule
		 % \multirow{4}{*}{Ours} & Base-$i$  
		 % & Base-$l$  
	   \multirow{2}{*}{Ours} & Base  & 93.0 & 81.8 & 10.5 & 97.8 & 76.2 & 21.4 & 93.7 & 94.1 & 0.4 & 93.9 & 93.6 & 2.3 & 90.7 & 91.8 & 1.0 & 73.4 & 68.0 & 17.3\\
	   & Large   & 93.1 & 80.0 & 13.0 & 98.0 & 70.6 & 27.4 & 93.9 & 94.3 & 0.4 & 94.8 & 93.5 & 2.4 & 92.1 & 92.2 & 0.9 & 81.2 & 73.1 & 14.3\\
	\bottomrule
		\end{tabular} }
	\end{center}	

\label{tab:IAB-LC-Blended}
\end{table*}





\subsection{Main Results}
\vspace{-2mm}\textbf{Comparison with diffusion model based DiffPure.}  Since the diffusion sampling process is extremely slow, we only report results on 500 test images in Tab.~\ref{tab:dp_results}. Overall, DiffPure can partially purify backdoored images but is much less effective than ours. DDPM and SDE sampling strategies obtain comparable performances. The low CA of DiffPure may be due to its reverse generative process that alternates image content, \eg, on \texttt{VGGFace2} where face recognition heavily relies on fine-grained attributes. Another observation is high ASR of DiffPure. This method is originally proposed for imperceptible adversarial perturbation, and the backdoor triggers are hard to be completely removed with diffusion sampling. More details and analysis are provided in Appendix Sec.~\ref{sec:supp:visualization_results}. %in Fig.~\ref{fig:supp:vis_all_1} and Fig.~\ref{fig:supp:vis_all_2}, and more discussion in Appendix. 


\vspace{-1.4mm}\cparagraph{Comparison with other purification methods.} 
Table~\ref{tab:agg_results} lists results of other methods. For Februus, we substitute its original GradCAM with two recent improvements to work on complex backbone networks. The GAN models are released by the authors, yet unavailable for \texttt{ImageNet}. Februus successfully purifies backdoored images but it is not a black-box model. Its performance is sensitive to the CAM visualization. PatchCleanser uses two rounds of masking to locate the trigger patch. The inconsistency check step of vanilla method is frequently affected by noisy label predictions, leading to low BA and high ASR. We make a variant that can make decent predictions on backdoored images, but at a cost of much lower accuracies on clean images. The two simple test-time image transformations, Blur and ShrinkPad, both face a trade-off between CA and BA. Using a strong transformation is more likely to incapacitate backdoor triggers, but decreases clean accuracies. 

Our method achieves high accuracies on both clean and backdoored images. For the two variants, using MAE-Large performs slightly better due to better restorations. Unlike Blur and ShrinkPad that apply global transformations, our method first locates possible triggers and then restore the trigger region only. Compared with Februus and PatchCleanser, our method leverages MAE model to better locate triggers. These two points are key to our excellent performance. We also want to highlight that Tab.~\ref{tab:agg_results} reports the aggregated results. Using different sizes of backdoor triggers may lead to different observations of these methods. Please refer to Appendix Sec.~\ref{sec:supp:analysis} for more discussions.

\vspace{-1.4mm}\cparagraph{Results on more challenging attacks.} 
In additional to the commonly used Backdoor attack with different triggers, we consider three more challenging attacks. IAB attack triggers are sample-specific irregular color curves or shapes, often split into a few fragments. LC attack triggers are checkerboards at the four corners. Blended attack triggers are invisible noise patches in the lower right corner. From Tab.~\ref{tab:IAB-LC-Blended}, IAB and LC are more challenging for the comparison methods. The assumption of triggers covered by a small rectangle mask is invalid in PatchCleanser. The performances of comparison methods are rather inconsistent across different settings. Blur and ShrinkPad happen to be suitable choices for the invisible Blended attack. For all these challenging attack settings, our method obtains consistently high accuracies. 


\begin{figure*}[!t]
	\centering	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_badnet_2by2_color_img1_orig.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_badnet_2by2_color_img1_mae_agg_rn0.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_badnet_2by2_color_img1_ssim0.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_badnet_2by2_color_img1_S1.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_badnet_2by2_color_img1_S2.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_badnet_2by2_color_img1_S1rf.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_badnet_2by2_color_img1_S2rf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_badnet_2by2_color_img1_Srf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_badnet_2by2_color_img1_mae_agg.png}
	\end{subfigure}

	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/VGGFace2_badnet_img2_org.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/VGGFace2_badnet_img2_mae_agg_rn0.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/VGGFace2_badnet_img2_ssim0.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/VGGFace2_badnet_img2_S1.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/VGGFace2_badnet_img2_S2.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/VGGFace2_badnet_img2_S1rf.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/VGGFace2_badnet_img2_S2rf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/VGGFace2_badnet_img2_Srf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/VGGFace2_badnet_img2_mae_agg.png}
	\end{subfigure}

	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize Original image w/ trigger
	\end{minipage} 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize Restored image from rand masks 
	\end{minipage} 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize SSIM score map 
	\end{minipage} 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize $S^{(i)}$ before refinement  
	\end{minipage} 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize $S^{(l)}$ before refinement 
	\end{minipage} 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize $S^{(i)}$ after refinement   
	\end{minipage} 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize $S^{(l)}$ after refinement   
	\end{minipage} 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize $S$ for final restoration  
	\end{minipage} 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize Purified image for prediction  
	\end{minipage} 
\vspace{-2mm}
\caption{Sampled visualizations. Top: \texttt{Cifar10} with 2$\times$2-color trigger. Bottom: \texttt{VGGFace2} with \emph{twitter} trigger. All the scores are clipped to a range of [0,1], with yellow for high value.}\label{fig:visualization}
% \caption{Sampled visualizations of the defense process. (Upper row) \texttt{Cifar10} with 2$\times$2-color trigger. (Lower row) \texttt{VGGFace2} with \emph{twitter} trigger. All the scores are clipped to a range of [0,1], with yellow for high value.}\label{fig:visualization}
\end{figure*}




\begin{figure*}[!t]
	\centering
%	\begin{subfigure}{0.079\textwidth}
%	\includegraphics[width=\textwidth]{fig/cifar10_IAB_img9_orig.png}
%	\end{subfigure}
%	\begin{subfigure}{0.079\textwidth}
%		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img9_S1.png}
%	\end{subfigure}
%	\begin{subfigure}{0.079\textwidth}
%		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img9_maskfull3.png}
%	\end{subfigure}
%	\begin{subfigure}{0.079\textwidth}
%		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img9_mask3.png}
%	\end{subfigure}
%	\begin{subfigure}{0.079\textwidth}
%		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img9_S1rf3.png}
%	\end{subfigure}
%	\begin{subfigure}{0.079\textwidth}
%		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img9_maskfull6.png}
%	\end{subfigure}
%	\begin{subfigure}{0.079\textwidth}
%		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img9_mask6.png}
%	\end{subfigure}
%	\begin{subfigure}{0.079\textwidth}
%		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img9_S1rf6.png}
%	\end{subfigure}
%	\begin{subfigure}{0.079\textwidth}
%		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img9_maskfull9.png}
%	\end{subfigure}
%	\begin{subfigure}{0.079\textwidth}
%		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img9_mask9.png}
%	\end{subfigure}
%	\begin{subfigure}{0.079\textwidth}
%		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img9_S1rf9.png}
%	\end{subfigure}
%	\begin{subfigure}{0.079\textwidth}
%		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img9_mae_agg.png}
%	\end{subfigure}

	\begin{subfigure}{0.077\textwidth}
	\includegraphics[width=\textwidth]{fig/cifar10_IAB_img14_orig.png}
	\end{subfigure}
	\begin{subfigure}{0.077\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img14_S1.png}
	\end{subfigure}
	\begin{subfigure}{0.077\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img14_maskfull2.png}
	\end{subfigure}
	\begin{subfigure}{0.077\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img14_mask2.png}
	\end{subfigure}
	\begin{subfigure}{0.077\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img14_S1rf2.png}
	\end{subfigure}
	\begin{subfigure}{0.077\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img14_maskfull6.png}
	\end{subfigure}
	\begin{subfigure}{0.077\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img14_mask6.png}
	\end{subfigure}
	\begin{subfigure}{0.077\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img14_S1rf6.png}
	\end{subfigure}
	\begin{subfigure}{0.077\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img14_maskfull9.png}
	\end{subfigure}
	\begin{subfigure}{0.077\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img14_mask9.png}
	\end{subfigure}
	\begin{subfigure}{0.077\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img14_S1rf9.png}
	\end{subfigure}
	\begin{subfigure}{0.077\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img14_mae_agg.png}
	\end{subfigure}

	\begin{subfigure}{0.077\textwidth}
		\includegraphics[width=\textwidth]{fig/gtsrb_lc_img69_org.png}
	\end{subfigure}
	\begin{subfigure}{0.077\textwidth}
		\includegraphics[width=\textwidth]{fig/gtsrb_lc_img69_S1.png}
	\end{subfigure}
	\begin{subfigure}{0.077\textwidth}
		\includegraphics[width=\textwidth]{fig/gtsrb_lc_img69_maskfull2.png}
	\end{subfigure}
	\begin{subfigure}{0.077\textwidth}
		\includegraphics[width=\textwidth]{fig/gtsrb_lc_img69_mask2.png}
	\end{subfigure}
	\begin{subfigure}{0.077\textwidth}
		\includegraphics[width=\textwidth]{fig/gtsrb_lc_img69_S1rf2.png}
	\end{subfigure}
	\begin{subfigure}{0.077\textwidth}
		\includegraphics[width=\textwidth]{fig/gtsrb_lc_img69_maskfull6.png}
	\end{subfigure}
	\begin{subfigure}{0.077\textwidth}
		\includegraphics[width=\textwidth]{fig/gtsrb_lc_img69_mask6.png}
	\end{subfigure}
	\begin{subfigure}{0.077\textwidth}
		\includegraphics[width=\textwidth]{fig/gtsrb_lc_img69_S1rf6.png}
	\end{subfigure}
	\begin{subfigure}{0.077\textwidth}
		\includegraphics[width=\textwidth]{fig/gtsrb_lc_img69_maskfull9.png}
	\end{subfigure}
	\begin{subfigure}{0.077\textwidth}
		\includegraphics[width=\textwidth]{fig/gtsrb_lc_img69_mask9.png}
	\end{subfigure}
	\begin{subfigure}{0.077\textwidth}
		\includegraphics[width=\textwidth]{fig/gtsrb_lc_img69_S1rf9.png}
	\end{subfigure}
	\begin{subfigure}{0.077\textwidth}
		\includegraphics[width=\textwidth]{fig/gtsrb_lc_img69_mae_agg.png}
	\end{subfigure}

	\begin{minipage}{0.077\textwidth}
		\centering
		\scriptsize Original image  
	\end{minipage} 
	\begin{minipage}{0.077\textwidth}
		\centering
		\scriptsize $S^{(i)}$ (0) 
	\end{minipage} 	
	\begin{minipage}{0.077\textwidth}
		\centering
		\scriptsize  $\m_{\rm rf}$ (3)
	\end{minipage} 
	\begin{minipage}{0.077\textwidth}
		\centering
		\scriptsize  $\m_{r}$ (3)
	\end{minipage} 
	\begin{minipage}{0.077\textwidth}
		\centering
		\scriptsize $S^{(i)}$ (3) 
	\end{minipage} 	
	\begin{minipage}{0.077\textwidth}
		\centering
		\scriptsize  $\m_{\rm rf}$ (7)
	\end{minipage} 
	\begin{minipage}{0.077\textwidth}
		\centering
		\scriptsize  $\m_{r}$ (7)
	\end{minipage} 
	\begin{minipage}{0.077\textwidth}
		\centering
		\scriptsize $S^{(i)}$ (7) 
	\end{minipage} 	
	\begin{minipage}{0.077\textwidth}
		\centering
		\scriptsize  $\m_{\rm rf}$ (10)
	\end{minipage} 
	\begin{minipage}{0.077\textwidth}
		\centering
		\scriptsize  $\m_{r}$ (10)
	\end{minipage} 
	\begin{minipage}{0.077\textwidth}
		\centering
		\scriptsize $S^{(i)}$ (10) 
	\end{minipage} 	
	\begin{minipage}{0.077\textwidth}
		\centering
		\scriptsize Purified image  
	\end{minipage} 
\vspace{-2mm}
\caption{Visualizations of topology-aware score refinement. Top: \texttt{Cifar10} with IAB. Bottom: \texttt{GTSRB} with LC. The numbers in brackets indicate steps of refinement.}
\label{fig:topology}
\end{figure*}


\begin{figure*}[!t]
	\centering	
	\begin{subfigure}{0.24\linewidth}
	\includegraphics[width=\linewidth,height=25mm]{fig-plot/rp_No_a21.pdf}
	\caption{\texttt{Base}-$i$}
	\label{fig:abl:i}
        \end{subfigure}   
        \hfill
	\begin{subfigure}{0.21\linewidth}
	\includegraphics[width=\linewidth,height=25mm]{fig-plot/rp_No_a22.pdf}
	\caption{\texttt{Base}-$l$}
	\label{fig:abl:l}
	\end{subfigure}
 \hfill
	\begin{subfigure}{0.24\linewidth}
	\includegraphics[width=\linewidth,height=25mm]{fig-plot/rp_Nr_a3.pdf}
	\caption{Full method}
	\label{fig:abl:rf}
    \end{subfigure}	
\hfill
    \begin{subfigure}{0.29\linewidth}
	\includegraphics[width=\linewidth,height=25mm]{fig-plot/refine_th.pdf}
	\caption{ Full method}
	\label{fig:abl:th}
	\end{subfigure}	
\vspace{-3.5mm}
%\caption{(a-c) Effects of repeated times $N_o$ and refinement times $N_r$. (d) Accuracy curves of using fix thresholds on \textcolor{red}{backdoored} and \textcolor{blue}{clean} images, before (dashed) or after (solid) refinement. Refinement enlarges the ranges of optimal thresholds.}\label{fig:abl}
\caption{(a-c) Effects of $N_o$ and $N_r$. (d) Accuracies with fixed thresholds on \textcolor{red}{backdoored}/\textcolor{blue}{clean} images, before (dashed) or after (solid) refinement. Refinement enlarges ranges of optimal thresholds.}\label{fig:abl}
\end{figure*}


\section{Analysis}

\vspace{-2mm}\textbf{Visualizations of defense process.} We plot images and scores in Fig.~\ref{fig:visualization}. Restored images from random masks have the same content as the original images, but are different in the trigger regions and some details. This is reflected in the SSIM score map. The two trigger scores are slightly higher in the trigger region, but very noisy. After refinement, high scores concentrate on the triggers, and scores of content regions are suppressed. $S$ is then used to generate the purified images. Compared with the original backdoored images, triggers are removed while the image contents are preserved. The purified images lead to correct label predictions.


\vspace{-1.4mm}\cparagraph{Effects of topology-aware refinement.} The topology-aware refinement is vital to the generalizability of our method. It exploits initialized scores, and generates topology-aware token masks to refine the scores. This is beneficial especially to complex triggers. In Fig.~\ref{fig:topology}, the triggers are random curves and four distant checkerboards. Before refinement, the trigger regions have relatively high scores in $S^{(i)}$. But the contrast between trigger regions and clean regions are not significant. For each refinement, $\m_r$ is sampled in a topology-aware manner to be continuous patches. $S^{(i)}$ is updated to have increased values for tokens masked by $\m_r$ and reduced values for the rest. After 10 refinements, $S^{(i)}$ well reflects the trigger regions. It is worth mentioning that the refinement focuses on the triggers related to backdoor behaviors. Even though the blue line remains in the purified `dog' image, the red line has been removed, thus it makes correct label prediction.

In Fig.~\ref{fig:abl:rf}, we find that $N_r=10$ is good enough for different triggers. One purpose of refinement is to increase contrast between scores of trigger regions and clean regions, so that the optimal threshold is easier to choose. In Fig.~\ref{fig:abl:th}, we randomly select three defense tasks for each dataset. Instead of fusing restorations from multiple thresholds, we choose a fixed threshold ranging from 0.1 to 0.9, and plot the accuracy curves. In each subplot, red/blue lines denote backdoored/clean images, dashed/solid lines denote before/after refinement. We can see that before refinement, the optimal thresholds have narrow ranges and vary across tasks. After refinement, they become wider. It is thus easy to set unified thresholds for different tasks.


\vspace{-1.4mm}\cparagraph{Sensitivity on hyper-parameters.} Our method mainly involves two critical hyper-parameters, the repeated times $N_o$ and the refinement times $N_r$. Throughout the experiments, we use $N_o=5$ and $N_r=10$. Figures~\ref{fig:abl:i},\ref{fig:abl:l} plot the effects of $N_o$ in \texttt{Base-$i$} and \texttt{Base-$l$}, respectively. For the image-based score $S^{(i)}$, the SSIM score map is similar for different MAE restorations. Thus averaging over 2 repeated results is good enough. For the label-based score $S^{(l)}$, averaging over many repeated results reduces the variance. $N_o=5$ generally performs well for both scores. 

\vspace{-1.4mm}\cparagraph{Discussion and Limitation.}
Test-time backdoor defense has drawn increasing attention. It is a practical yet challenging task. Only model predictions on the single test image can be used, while the backdoor attack methods can be quite diverse. By leveraging pretrained MAE models, our method locates possible triggers inside images and restores the missing contents simultaneously. We demonstrate its effectiveness on backdoor triggers of different patterns and shapes. One limitation of our method is that it focuses on the most popular local triggers. Some particular attack methods use triggers that overlap the entire image. In that case, an additional step of image transformation can be applied before our method~\citep{shi2023black}. We left that for an interesting future work.


\section{Conclusion}
\vspace{-2mm}In this paper, we study the novel yet practical task of blind backdoor defense at test time, in particular for black-box models. We devise a general framework of \textit{Blind Defense with Masked AutoEncoder} (BDMAE) to detect triggers and restore images. Extensive experiments on four benchmarks under various backdoor attack settings verify its effectiveness and generalizability.


% Our method focuses on the most popular local-patch triggers, but also generalizes well to medium-sized triggers like color curves (Fig.~\ref{fig:topology}). Extension to global triggers is left as an interesting future work. 

% A general framework of \textit{Blind Defense with Masked AutoEncoder} (BDMAE) is devised to detect triggers and restore images. Accuracies on clean images or models are uncompromised. 
% Our method generalizes well to various trigger types, network architectures or datasets. 

% \section{Conclusion and Discussion}
% In this paper, we study the novel yet practical task of blind backdoor defense at test time, in particular for black-box models. We propose to leverage generic image generation models. A general framework of \textit{Blind Defense with Masked AutoEncoder} (BDMAE) is devised to detect triggers and restore images. Accuracies on clean images or models are uncompromised. Our method generalizes well to various trigger types, network architectures or datasets. 

% This work focuses on triggers of local patches, as they are commonly used in backdoor attacks. For medium-sized triggers like color curves in Fig.~\ref{fig:topology}, our method can find the trigger segments related to the backdoor behaviors. Extension to global triggers is an interesting future work. Due to the Vision Transformer architecture of MAE, our trigger score has a resolution of 14$\times$14. Using shifted windows to locate triggers at finer granularity is also worth studying. 


\bibliographystyle{iclr2024_conference}
\bibliography{reference}

\clearpage

\appendix
\renewcommand{\thefigure}{A.\arabic{figure}}
\setcounter{figure}{0}
\renewcommand{\thetable}{A.\arabic{table}}
\setcounter{table}{0}
\renewcommand{\theequation}{A.\arabic{equation}}
\setcounter{figure}{0}

% In this supplementary material, we provide additional results and analyses on our method.

% In Sec.~\ref{sec:ssim} and Sec.~\ref{sec:topology}, we remark on SSIM similarity measure used in our method, and analyze the effects of the parameter in the topology-aware token mask generation. In Sec.~\ref{sec:trigger_size}, we compare the performances on \texttt{Cifar10} using various sizes of triggers. We discuss backdoor defense with test-time image transformation in Sec.~\ref{sec:supp:ttt}. Full Februus results under different thresholds are listed in Sec.~\ref{sec:detailed_results}. Lastly, we include additional visualizations of our method in Sec.~\ref{sec:supp:visualization_process}.


\section{Dataset Details}
\vspace{-1.4mm}\cparagraph{\texttt{Cifar10}} is a 10-class classification dataset~\citep{krizhevsky2009cifar10} of size 32$\times$32. There are 50,000 training images and 10,000 test images.

\vspace{-1.4mm}\cparagraph{\texttt{GTSRB}}~\citep{stallkamp2012gtsrb} consists of 43-class traffic signs images of size 32$\times$32, split into 39,209 training images and 12,630 test images. 

\vspace{-1.4mm}\cparagraph{\texttt{VGGFace2}} is a face recognition dataset~\citep{cao2018vggface2}. We use images from 170 randomly selected classes following~\citep{doan2020februus}, and resize them to 224$\times$224. Face recognition is a critical real-world application where backdoor attack may exist.

\vspace{-1.4mm}\cparagraph{\texttt{ImageNet10, ImageNet50 and ImageNet100}} are three subsets of \texttt{ImageNet}~\citep{deng2009imagenet}, resized to 224$\times$224. We created them by selecting the first 10 (50, 100) classes in alphabetical order. Each class has about 1,300 training images and 50 test images.

\section{Implementation Details}
\subsection{Backdoor attack settings}
We use BadNet attack~\citep{gu2019badnets} with different triggers, Label-Consistent backdoor attack (LC)~\citep{turner2019lc}, Input-Aware dynamic Backdoor attack (IAB)~\citep{nguyen2020IAB} and Blended attack~\citep{chen2017targeted} to build backdoored models. 

The triggers of BadNet attack are chosen from 1$\times1 \sim 3\times$3 white or color patches. In addition, we use several 15$\times$15 icons as triggers for \texttt{VGGFace2} and \texttt{ImageNet}. These commonly seen object icons and social media icons are more natural in the real-world application. The triggers of LC attack are 3$\times$3 checkerboards in the four images corners.  The triggers of Blended attack is 15$\times$15 random pixels. The triggers of IAB attack are random color curves or shapes. They are sample-specific, in that each image has its unique trigger pattern.

We randomly select 10\% training data to create backdoored images. Then we train a model until it has a sufficiently high accuracy on clean images and attack success rate on backdoored images. The backbone network for \texttt{Cifar10} and \texttt{GTSRB} is ResNet18~\citep{he2016resnet} from random initialization. The backbone network for \texttt{VGGFace2} and \texttt{ImageNet} is pretrained ResNet50~\citep{he2016resnet}. We also considered other backbone networks in Sec.~\ref{sec:supp:arch}. For each setting of \texttt{Cifar10} and \texttt{GTSRB}, we report average results over 14 repeated experiments from different target labels or initializations. For the large \texttt{VGGFace2} and \texttt{ImageNet}, we reduce it to 6 repeat experiments.  


%is 16-layer VGG-Face model~\citep{parkhi2015deep} following~\citep{doan2020februus}.

\subsection{Method configurations}
We avoid tuning our method to some specific dataset or attack. Instead, we use the same set of hyper-parameters for all experiments. The motivation is that as only one test image is available in the task, it is unlikely to tune those hyper-parameters reliably. Specifically, the default masking ratio is 75\%. $N_o=N_i=5$ and $N_r=10$. Even though, it is worthwhile mentioning that the image resolution and backdoor trigger patches can be highly diverse, better performances of our methods are expected with better tuned hyper-parameters.

We use two pretrained Masked Autoencoders~\citep{he2022masked} that are available from their official repository. The \texttt{Base} variant has 12 encoder layers, and the \texttt{Large} variant has 24 encoder layers with an increased hidden size dimension. For \texttt{Cifar10} and \texttt{GTSRB}, we up-sample each image to 224$\times$224 first in order to fit MAE models. Afterwards, the MAE restorations are down-sampled back to the original image size.  

The detailed procedures of our method can be found in Alg.~\ref{alg: triggerGen} and Alg.~\ref{alg: triggerRefine}. 

\subsection{Experiment environment}
We experiment with Nvidia A5000 or A6000 GPUs using PyTorch 1.8. For the implementation, the MAE related code is adapted from its official repository. 


\begin{figure}[t]
\begin{algorithm}[H]
	\renewcommand{\algorithmicrequire}{\textbf{Input:}}
	\renewcommand{\algorithmicensure}{\textbf{Output:}}
	\caption{Trigger Score Generation} 
	\label{alg: triggerGen} 
	\begin{algorithmic}[1]
		\Require Prediction model $f$, test image $\x$, generic MAE model $G$, repeated times $N_o$, $N_i$.
		\Ensure Trigger scores $S^{(i)}$, $S^{(l)}$
		\State Get original hard-label prediction $\hat{y}=f(\x)$		
		\For {$o=0$ \textbf{to} $N_o$}
		\For {$i=0$ \textbf{to} $N_i$}
		\State Uniformly sample random token mask $\m_{o,i}$
		\State Get MAE reconstruction ${\tilde{\x}_{o,i}}$ and the corresponding mask ${\tilde{\m}_{o,i}}$ from $\tilde{G}(\x,\m_{o,i})$
		\State Get hard-label prediction $\hat{y}_{o,i}=f(\tilde{\x}_{o,i})$
		\EndFor
		\State Fuse restorations into $\tilde{\x}_{o}=\mathcal{F}(\{\tilde{\x}_{o,i}\},\{\tilde{\m}_{o,i}\})$
		\State Calculate structural similarity $I_{o}=\mathrm{SSIM}(\x, \tilde{\x}_{o})$
		\EndFor
		
		\State $S^{(i)}=\sum_o [1-\mathtt{resize}(I_{o};14,14)]/N_{o}$
		\State $S^{(l)}=\sum_{o,i}[\m_{o,i}\times(1-\mathbb{I}[\hat{y}=\hat{y}_{o,i} ])]/(N_o N_i)$
	\end{algorithmic}
\end{algorithm}
\end{figure}


\begin{figure}[t]
\vspace{-6mm}
\begin{algorithm}[H]
	\renewcommand{\algorithmicrequire}{\textbf{Input:}}
	\renewcommand{\algorithmicensure}{\textbf{Output:}}
	\caption{Topology-aware Score Refinement} 
	\label{alg: triggerRefine} 
	\begin{algorithmic}[1]
		\Require Prediction model $f$, test image $\x$, generic MAE model $G$, refinement times $N_r$, initial trigger score $S^{(*)}$, mask $\m_{\rm rf}$ for tokens to be refined, $\beta_0=0.05$.
		\Ensure Refined trigger score $S^{(*)}$.
		\State Get original hard-label prediction $\hat{y}=f(\x)$		
		\For {$r=0$ \textbf{to} $N_r$}
		\State Generate a topology-aware token mask $\m_{r}$
		\State $\bar{\m}_{r}=\m_{\rm rf}-\m_{r}$
		\State Get MAE reconstruction $\tilde{\x}_{r}$ from $\tilde{G}(\x,\m_{r})$
		\State Get hard-label prediction $\hat{y}_{r}=f(\tilde{\x}_{r})$ 
		\State $\beta=(1-2\mathbb{I}[ \hat{y}=\hat{y}_{r} ])\times \beta_0$
		\State $S^{(*)}\leftarrow S^{(*)}+\beta\times(\m_{r}-\bar{\m}_{r})$		
		\EndFor
	\end{algorithmic}
\end{algorithm}
\end{figure}

\section{Comparison Methods}
\vspace{-1.4mm}\cparagraph{\texttt{Februus}}~\citep{doan2020februus} is a \textbf{white-box} defense method. It uses GradCAM~\citep{selvaraju2017grad} visualization to locate image regions that are more relevant to the backdoor target label. It is highly likely that backdoor triggers are inside these regions. Then Februus removes those regions and uses a separately-trained GAN~\citep{goodfellow2014generative} for image restoration. We use the GAN models provided by the authors and skip Februus experiments on \texttt{ImageNet} as the corresponding GAN model is unavailable.  

GradCAM requires knowing detailed model architecture and parameters. In our experiments, we found that GradCAM does work well on models with deeper layers and more complex classifier heads. Therefore, we substitute it with two improved versions, XGradCAM~\citep{fu2020axiom} and GradCAM$++$~\citep{chattopadhay2018grad}. Another critical issue with Februus is the layer for visualization and the threshold for selecting highly relevant regions. The choices significantly affects the performance on clean images and backdoor images. We first find the best layer for each model architecture, and the try all thresholds from $\{0.6,0.7,0.8\}$. The reported results are from thresholds with the best $ACC_c+ACC_b$ for each defense setting individually. 

\vspace{-1.4mm}\cparagraph{\texttt{PatchCleanser}} is a certifiably robust defense against adversarial patches~\citep{xiang2022patchcleanser}. It assumes that the entire adversarial patches can be covered by a small rectangle mask, which may not be applicable to LC and IAB attacks in our task. The method performs two rounds of pixel masking on the image to neutralize the effect of the adversarial patch. If the first mask covers the adversarial patch, then moving the second mask will not change the predicted label. Otherwise, the second round masking may exhibit in-consistent label predictions.

We adapt the official PatchCleanser implementation to our backdoor defense framework. However, we found that the vanilla method may fail to locate backdoor triggers frequently. The reason is that the inconsistency check mentioned above could be affected by noisy label prediction that is neither real semantic label nor target label. It fails to return the disagreer prediction  (Alg.1 Ln. 8-10 of the original paper), instead the majority prediction (\ie, target label) is returned. This results in low BA and high ASR on backdoored images. We proposed a variant that returns the majority voting of all predictions for the in-consistent situations. It works much better to purify backdoored images, but at an expense of lower accuracies on clean images.

\vspace{-1.4mm}\cparagraph{\texttt{Blur}} is a simple test-time image transformation method used in~\citep{li2021backdoor}. We implemented it with a 3$\times$3 Gaussian kernel of standard deviation 0.5 for weak blurring and 1.0 for strong blurring.

\vspace{-1.4mm}\cparagraph{\texttt{ShrinkPad}} is proposed by~\citep{li2021backdoor} that first shrinks images and then randomly pads images to the original size. We adapt the authors' implementation to our framework. For small images from \texttt{Cifar10} and \texttt{GTSRB}, the weak and strong transformation use padding sizes of 4 and 8, respectively. For large images from \texttt{VGGFace2} and \texttt{ImageNet}, the padding sizes are 28 and 56, respectively.


\vspace{-1.4mm}\cparagraph{\texttt{DiffPure}}~\citep{nie2022diffusion} uses pre-trained diffusion models to purify images. It first diffuses an image with a small amount of noise following a forward diffusion process, and then recover the clean image through a reverse generative process. Our implementation is based on their official repository. We use the public 256$\times$256 unconditional diffusion model from OpenAI. Each test image is up-sampled to 256$\times$256 for diffusion model and down-sampled back to the original image size. For the diffusion sampling strategy, we use both DDPM and SDE following DiffPure. We found that the diffusion restorations may not always stick to the original content. The issue is more severe for low-resolution images.


\section{Remarks on SSIM}\label{sec:ssim}
Structural Similarity Index Measure (SSIM)~\citep{wang2004image} is used to measure the similarity between two images. Different from Mean-Squared-Error that measures pixel-wise absolution errors, SSIM considers the inter-dependencies among neighboring pixels. The SSIM index is calculated on two windows, $x$ and $y$, from a pair of images. Its definition is 
\begin{equation}
    \mathrm{SSIM}(x,y)=\frac{(2\mu_x \mu_y +c_1)(2\sigma_{xy}+c_2)}{(\mu_x^2+\mu_y^2+c_1)(\sigma_x^2+\sigma_y^2+c_2)}
\end{equation}
where $\mu_x$ and $\mu_y$ are mean values, $\sigma_x$ and $\sigma_y$ are variances, and $\sigma_{xy}$ is covariance. $c_1$ and $c_2$ are constants. $\mathrm{SSIM}(x,y)$ lies between -1 and 1. 1 indicates perfect similarity, 0 indicates no similarity, and -1 indicates perfect anti-correlation. In our experiments, we observe that the minimum SSIM values are about -0.6$\sim$-0.2 depending on datasets, and the maximum values are close to 1.0.

The window size influences the SSIM values. Generally, a larger window averages over more pixels, thus the SSIM value is less extreme (\ie, close to 0). We use the commonly used 11$\times$11 Gaussian window, whose effective window size is about 5$\times$5. On \texttt{Cifar10} and \texttt{GTSRB} of image size 32$\times$32, due to their low resolution, a 11$\times$11 window usually covers content regions. The original image and MAE restorations are similar, thus it is unlikely that the SSIM values will be extremely negatively. On \texttt{ImageNet} and \texttt{VGGFace2} of image size 224$\times$224, differently, the window may include some background regions or image details. The difference between the original image and MAE restoration can be significantly large, leading to significantly negative SSIM values. Since our image-based trigger score is defined as $S^{(i)}=1-\mathrm{SSIM}$, $S^{(i)}$ tends to be larger for \texttt{ImageNet} and \texttt{VGGFace2}. This is why the adaptive thresholds are necessary to achieve good performance on the two datasets.  




\section{Generalization to Clean Images and Clean Models}\label{sec:supp:clean} 

We highlight that our method is blind to the benignity of images or models. This relies on dedicated designs in different stages. The key to guarantee correct label prediction in the situation of clean images or clean models is not destroying semantic contents in clean regions. Since the final prediction is based on MAE restoration $\rho(\x)$ from the final trigger score $S$, we should keep small score values of $S$ for those clean regions throughout the test-time defense process.

In the trigger score generation stage, if $\x$ is a clean image no matter $f$ is backdoored or not, its MAE restorations should be similar to the original image. This implies that values of $S^{(i)}$ will be small. The values of $S^{(l)}$ will also be small as the label prediction is unlikely to change. If $f$ is a clean model and $x$ is a backdoored image, $S^{(l)}$ will still be small. Although $S^{(i)}$ has high values for trigger region, its impact is reduced when we average $S^{(l)}$ and $S^{(i)}$. In the topology-aware score refinement stage, only the top $L$ tokens are affected. By construction $L=\sum_{r,c}\mathbb{I}[S^{(i)}_{r,c}\geq 0.2]$ or $L=\sum_{r,c} S^{(l)}_{r,c}$, $L$ is generally small in the situation of clean images or clean models. In the adaptive image restoration stage, image regions with trigger scores greater than $\tau_K$ are generated with MAE. These regions are either trigger regions or some content-irrelevant regions. The rest clean content regions are kept intact. Therefore, the model can still make correct label prediction on the purified image $\rho(\x)$.

For backdoored models on clean images, the CA in previous results has validated the effectiveness of our method. Figure~\ref{fig:sup:clean_score} shows different properties of trigger score $S$ between backdoored and clean images. $S$ of clean images has small values, thus the image restoration stage will not change the semantic content. For clean models, Table~\ref{tab:sup:clean-model} lists prediction accuracies for six different datasets. As can be seen, the accuracies on backdoored and clean images are minimally affected. 



\section{Additional Analyses} \label{sec:supp:analysis}

\subsection{Topology-aware Token Mask Generation}\label{sec:topology}
In the score refinement, we generate topology-aware token masks. We repeatedly choose $t_i=\arg\max_{t_k} (S^{*}[t_k]+u\llbracket t_k \in \texttt{Adj}(\mathcal{T}) \rrbracket )\cdot \sigma_{k} $ with $u=0.5$, where $\texttt{Adj}(\mathcal{T})$ includes all 4-nearest neighbors of tokens in $\mathcal{T}$ and $\sigma_{k}\sim U(0,1)$ is a random variable. Here $u$ is the additional probability assigned to the neighboring tokens. When $u=0$, the sampling procedure only select tokens with highest trigger scores. To see the effect of $u$, Fig.~\ref{fig:supp:topology} plots the results on four defense tasks with increasing $u$. For the challenging IAB attacks, the performances drops when not using topology-aware sampling (\ie, $u=0$). $u=0.5$ obtains relatively good performances on the four tasks. Note that due to the existence of random variable $\sigma_k$, using $u=1.0$ still leads to some randomness in the token selection.


\begin{figure}[!t]
	\centering	
	\includegraphics[width=0.36\textwidth]{fig-plot/topology_sampling.pdf}
 \includegraphics[width=0.3\textwidth]{fig-plot/rp_No_a3_vggface2.pdf}
 \includegraphics[width=0.3\textwidth]{fig-plot/rp_Nr_a3_vggface2.pdf}
	\caption{Parameter analysis in the full method. Left: sampling parameter $u$ in topology-aware token mask generation. Center: repeated times $N_o$. Right: refinement times $N_r$.}\label{fig:supp:topology}

\end{figure}


\begin{figure}[!t]
	\centering	
	\includegraphics[width=1.0\linewidth]{fig-plot/cifar10_trigger_size.pdf}
	\caption{Varying trigger (checker-board) sizes on \texttt{Cifar10}.}\label{fig:supp:cifar10_vs}
	
\end{figure}

\subsection{Sensitivity on Hyper-parameters} 
Figure~\ref{fig:supp:topology} shows additional analysis of hyper-parameter sensitivity on \texttt{VGGFace2}. As can be seen, using larger repeated times $N_o$ and refinement times $N_r$ leads to higher accuracies. $N_o=5$ and $N_r=10$ are good enough, which is consistent with our observations on other datasets in Fig.~\ref{fig:abl}.


\subsection{Generalization on network architecture} \label{sec:supp:arch}
Our method is for black-box defense, thus is generalizable on network architectures. In Tab.~\ref{tab:sup:arch}, we show results on \texttt{Cifar10} and \texttt{VGGFace2} with different backbone networks. Februus is a white-box method, thus it relies on the network architecture. On \texttt{Cifar10}, it performs well on the shallow Convolutional Neural Network originally used by the authors, but is less effective on ResNet18 and VGG16. On \texttt{VGGFace2}, its clean accuracies are relatively low. Compared with other black-box methods, our method achieves consistently better performances across different network architectures.






\begin{table*}[!t]
\caption{Varying backbone network architectures.}
\begin{center}
\renewcommand{\tabcolsep}{0.1cm}
\centering
\scriptsize
\scalebox{0.95}{
\begin{tabular}{p{1.0cm}p{2.0cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}}
	\toprule
        & & \multicolumn{9}{c|}{\texttt{Cifar10}} & \multicolumn{9}{c}{\texttt{VGGFace2}} \\
        \cmidrule{3-20}	
	\multirow{3}{*}{} & & \multicolumn{3}{c|}{ResNet18} & \multicolumn{3}{c|}{6 Conv + 2 Dense} & \multicolumn{3}{c|}{VGG16}  & \multicolumn{3}{c|}{ResNet18} & \multicolumn{3}{c|}{ResNet50} & \multicolumn{3}{c}{VGG16} \\
	\cmidrule{3-20}	
			& & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR \\
	\midrule
	\multicolumn{2}{c|}{Before Defense}  & 92.8 & 0.1 & 99.9 & 91.3 & 0.0 & 100. & 89.8 & 0.0 & 100. & 94.0 & 0.0 & 100. & 95.5 & 0.0 & 100. & 91.5 & 0.0 & 100.\\
	\midrule	
	\multirow{2}{*}{Februus} & XGradCAM    & 91.0 & 83.9 & 11.0 & 86.2 & 90.0 & 2.7 & 87.3 & 45.7 & 50.0 & 46.3 & 93.6 & 0.2 & 65.5 & 89.5 & 5.8 & 81.3 & 75.6 & 17.7\\
	& GradCAM++  & 88.0 & 88.4 & 6.1 & 91.3 & 91.2 & 1.5 & 76.2 & 77.5 & 15.1 & 43.5 & 92.8 & 1.1 & 63.1 & 89.4 & 5.9 & 80.5 & 77.1 & 16.1\\
	\midrule
        \multirow{2}{*}{PatchCleanser} & Vanilla   & 89.2 & 33.1 & 66.8 & 87.0 & 36.8 & 62.9 & 86.5 & 29.7 & 70.1 & 92.0 & 36.4 & 63.6 & 93.0 & 43.0 & 56.9 & 88.3 & 35.6 & 64.2\\
        & Variant & 50.4 & 90.0 & 3.3 & 52.6 & 88.2 & 2.8 & 47.8 & 86.6 & 2.8 & 45.0 & 93.1 & 0.0 & 50.7 & 94.7 & 0.0 & 42.8 & 90.3 & 0.1\\
        \midrule
         \multirow{2}{*}{Blur} & Weak   & 90.5 & 90.0 & 2.3 & 87.5 & 73.2 & 20.0 & 86.2 & 27.5 & 69.6 & 93.9 & 0.0 & 100. & 95.5 & 0.1 & 100. & 88.9 & 69.5 & 22.8\\
        & Strong  & 52.5 & 51.1 & 10.7 & 55.0 & 53.7 & 7.3 & 54.7 & 53.6 & 6.8 & 93.7 & 14.2 & 85.4 & 95.2 & 10.4 & 89.4 & 88.3 & 78.8 & 11.3\\
  	\midrule
        \multirow{2}{*}{ShrinkPad} & Weak  & 86.8 & 24.5 & 74.5 & 83.4 & 23.5 & 75.8 & 82.1 & 1.6 & 98.3 & 91.8 & 12.1 & 87.3 & 93.8 & 35.5 & 62.5 & 88.2 & 5.4 & 93.8\\
        & Strong  & 82.7 & 81.2 & 10.8 & 73.8 & 70.5 & 23.4 & 74.1 & 72.1 & 16.3 & 83.5 & 24.9 & 71.1 & 88.3 & 54.4 & 38.3 & 72.6 & 25.2 & 52.3\\
  	\midrule
	\multirow{2}{*}{Ours} & Base  & 91.5 & 90.3 & 3.0 & 89.9 & 90.0 & 1.3 & 88.5 & 87.8 & 2.5 & 87.9 & 88.1 & 4.2 & 91.3 & 92.0 & 1.6 & 83.7 & 84.5 & 5.2\\
	& Large  & 91.7 & 91.1 & 2.1 & 90.3 & 90.2 & 1.2 & 88.8 & 88.3 & 2.2 & 90.5 & 88.0 & 4.6 & 92.9 & 91.8 & 2.2 & 85.5 & 85.3 & 4.5\\
			\bottomrule
		\end{tabular} }
	\end{center}	
\vspace{-2mm}
\label{tab:sup:arch}
\end{table*}



\begin{table}[!t]
\caption{Defense results on clean models.}
\renewcommand{\tabcolsep}{0.06cm}
\begin{center}
\scriptsize
 \scalebox{1.0}{
	\begin{tabular}{p{0.7cm}<{\centering}p{1.0cm}<{\centering}|p{0.76cm}<{\centering}p{0.76cm}<{\centering}|p{0.76cm}<{\centering}p{0.76cm}<{\centering}|p{0.76cm}<{\centering}p{0.76cm}<{\centering}|p{0.76cm}<{\centering}p{0.76cm}<{\centering}|p{0.76cm}<{\centering}p{0.76cm}<{\centering}|p{0.76cm}<{\centering}p{0.76cm}<{\centering}}
		\toprule
		\multirow{2}{*}{} & & \multicolumn{2}{c|}{\texttt{Cifar10}} & \multicolumn{2}{c|}{\texttt{GTSRB}} & \multicolumn{2}{c|}{\texttt{VGGFace2}} & \multicolumn{2}{c|}{\texttt{ImageNet10}} & \multicolumn{2}{c|}{\texttt{ImageNet50}} & \multicolumn{2}{c}{\texttt{ImageNet100}} \\
		\cmidrule{3-14}
		& & CA & BA & CA & BA & CA & BA & CA & BA & CA & BA & CA & BA \\
		\midrule
		\multicolumn{2}{c|}{Before Defense}  & 93.8 & 93.7 & 98.7 & 98.6 & 95.7 & 95.7 & 89.8 & 88.8 & 84.2 & 83.6 & 82.7 & 82.2\\
		\midrule
		\multirow{2}{*}{Ours} & Base   & 93.1 & 93.1 & 98.5 & 98.5 & 91.5 & 91.4 & 81.3 & 80.7 & 61.8 & 61.4 & 59.3 & 59.6\\
		& Large &  93.3 & 93.2 & 98.6 & 98.6 & 92.8 & 92.6 & 85.3 & 84.1 & 72.5 & 72.5 & 69.8 & 70.1\\
		\bottomrule
	\end{tabular} }
    \end{center}	
\vspace{-2mm}
\label{tab:sup:clean-model}
\end{table}



\subsection{Varying Trigger Size}\label{sec:trigger_size}
The trigger size affects the difficulty to detect these triggers. In the BadNet work~\citep{gu2019badnets}, the authors use 3$\times$3-checkerboard as triggers. In Fig.~\ref{fig:supp:cifar10_vs}, we present defense results on \texttt{Cifar10} using various sizes of checkerboard triggers. The performances of comparison methods are discouraging. Our method maintains high accuracies on clean images. Our \texttt{Base-$i$} is not working well on 1$\times$1 trigger because it is hard to detect such a small trigger using image similarity. \texttt{Base-$l$}, on the contrary, works well on this small trigger using label consistency. As trigger size becomes larger, the performance of \texttt{Base-$l$} drops because the trigger can not be removed completely through random masking. The full method \texttt{Base} combines the merits of both image similarity and label consistency, and works for all cases. 




% \begin{table*}[!t]
% \caption{Defense results on \texttt{Cifar10} using various sizes of checkerboard triggers. \ts{TODO: change into figure}}
% \renewcommand{\tabcolsep}{0.1cm}
% 	\begin{center}
% 		\scriptsize
%         \begin{tabular}{@{}p{0.8cm}p{1.6cm}<{\centering}|p{0.45cm}<{\centering}p{0.45cm}<{\centering}p{0.454cm}<{\centering}|p{0.454cm}<{\centering}p{0.45cm}<{\centering}p{0.45cm}<{\centering}|p{0.6cm}<{\centering}p{0.45cm}<{\centering}p{0.45cm}<{\centering}|p{0.6cm}<{\centering}p{0.45cm}<{\centering}p{0.45cm}<{\centering}}
% 			\toprule
% 			\multirow{3}{*}{} & & \multicolumn{3}{c|}{1$\times$1} & \multicolumn{3}{c|}{3$\times$3} & \multicolumn{3}{c|}{5$\times$5} & \multicolumn{3}{c}{7$\times$7} \\
% 			\cmidrule{3-14}	
% 			&  & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR \\
% 			\midrule
% 			\multicolumn{2}{c|}{Before Defense}  & 93.3 & 2.0 & 97.9 & 92.8 & 0.1 & 99.9 & 93.4 & 0.0 & 100. & 93.3 & 0.0 & 100.\\
% 			\cmidrule{1-14}	
% 			 \multirow{2}{*}{Februus} & XGradCAM   & 91.5 & 80.7 & 13.7 & 91.0 & 83.9 & 11.0 & 91.7 & 89.9 & 4.0 & 91.6 & 70.2 & 15.5\\ 
% 			  & GradCAM++  & 74.1 & 85.7 & 7.1 & 81.3 & 91.6 & 2.7 & 75.0 & 92.7 & 0.9 & 75.1 & 72.6 & 11.7\\
% 	\midrule
%         \multirow{2}{*}{PC} & Vanilla  & 89.5 & 48.2 & 50.8 & 89.2 & 33.1 & 66.8 & 89.7 & 46.8 & 52.6 & 89.4 & 30.5 & 68.9\\
%         & Variant  & 57.6 & 87.2 & 2.0 & 50.4 & 90.0 & 3.3 & 58.4 & 88.9 & 1.3 & 57.5 & 81.2 & 2.3\\
%         \midrule
%          \multirow{2}{*}{Blur} & Weak & 91.0 & 13.8 & 85.4 & 90.5 & 90.0 & 2.3 & 91.3 & 78.6 & 13.0 & 91.2 & 67.7 & 17.6\\
%         & Strong  &  58.4 & 57.5 & 3.7 & 52.5 & 51.1 & 10.7 & 60.1 & 57.5 & 3.4 & 60.3 & 55.4 & 4.2\\
%   	\midrule
%         \multirow{2}{*}{ShrinkPad} & Weak & 91.1 & 87.9 & 3.7 & 86.8 & 24.5 & 74.5 & 91.3 & 38.7 & 58.6 & 91.2 & 79.9 & 3.6\\
%         & Strong  & 88.1 & 72.1 & 18.3 & 82.7 & 81.2 & 10.8 & 88.4 & 74.1 & 12.2 & 88.4 & 74.5 & 4.2\\
%   	\midrule
% 			 \multirow{4}{*}{Ours} & Base-$i$  & 91.9 & 78.7 & 15.0 & 91.2 & 88.9 & 4.0 & 92.2 & 91.8 & 0.4 & 92.2 & 88.7 & 0.6\\
% 			  & Base-$l$ & 91.3 & 90.4 & 1.3 & 90.1 & 75.5 & 19.7 & 91.8 & 80.3 & 13.1 & 91.8 & 35.2 & 60.1\\
% 			  & Base   & 92.2 & 90.6 & 1.2 & 91.5 & 90.3 & 3.0 & 92.7 & 92.0 & 0.5 & 92.6 & 89.0 & 0.8\\
% 		 	& Large  & 92.4 & 90.9 & 1.1 & 91.7 & 91.1 & 2.1 & 92.8 & 92.3 & 0.5 & 92.7 & 90.2 & 0.7\\
% 	\bottomrule
% 		\end{tabular}
% 	\end{center}

% 	\label{tab:supp:cifar10_vs}
% \end{table*}






\begin{figure}[!t]
	\centering

\begin{subfigure}{0.16\textwidth}
	\includegraphics[width=\textwidth]{fig/cifar10_badnet_3by3_color_img9_org.png}
\end{subfigure}
\begin{subfigure}{0.16\textwidth}
	\includegraphics[width=\textwidth]{fig/cifar10_badnet_3by3_color_img9_Srf.png}
\end{subfigure}
\begin{subfigure}{0.16\textwidth}
	\includegraphics[width=\textwidth]{fig/cifar10_badnet_3by3_color_img9_mae_agg_adap.png}
\end{subfigure}
\begin{subfigure}{0.16\textwidth}
	\includegraphics[width=\textwidth]{fig/cifar10_badnet_3by3_color_imgc35_org.png}
\end{subfigure}
\begin{subfigure}{0.16\textwidth}
	\includegraphics[width=\textwidth]{fig/cifar10_badnet_3by3_color_imgc35_Srf.png}
\end{subfigure}
\begin{subfigure}{0.16\textwidth}
	\includegraphics[width=\textwidth]{fig/cifar10_badnet_3by3_color_imgc35_mae_agg_adap.png}
\end{subfigure}

\begin{subfigure}{0.16\textwidth}
	\includegraphics[width=\textwidth]{fig/gtsrb_badnet_3by3_white_img28_org.png}
\end{subfigure}
\begin{subfigure}{0.16\textwidth}
	\includegraphics[width=\textwidth]{fig/gtsrb_badnet_3by3_white_img28_Srf.png}
\end{subfigure}
\begin{subfigure}{0.16\textwidth}
	\includegraphics[width=\textwidth]{fig/gtsrb_badnet_3by3_white_img28_mae_agg_adap.png}
\end{subfigure}
\begin{subfigure}{0.16\textwidth}
	\includegraphics[width=\textwidth]{fig/gtsrb_badnet_3by3_white_imgc48_org.png}
\end{subfigure}
\begin{subfigure}{0.16\textwidth}
	\includegraphics[width=\textwidth]{fig/gtsrb_badnet_3by3_white_imgc48_Srf.png}
\end{subfigure}
\begin{subfigure}{0.16\textwidth}
	\includegraphics[width=\textwidth]{fig/gtsrb_badnet_3by3_white_imgc48_mae_agg_adap.png}
\end{subfigure}

\begin{subfigure}{0.16\textwidth}
	\includegraphics[width=\textwidth]{fig/VGGFace2_badnet_img30_pinterest_org.png}
\end{subfigure}
\begin{subfigure}{0.16\textwidth}
	\includegraphics[width=\textwidth]{fig/VGGFace2_badnet_img30_pinterest_Srf.png}
\end{subfigure}
\begin{subfigure}{0.16\textwidth}
	\includegraphics[width=\textwidth]{fig/VGGFace2_badnet_img30_pinterest_mae_agg_adap.png}
\end{subfigure}
\begin{subfigure}{0.16\textwidth}
	\includegraphics[width=\textwidth]{fig/VGGFace2_badnet_imgc48_pinterest_org.png}
\end{subfigure}
\begin{subfigure}{0.16\textwidth}
	\includegraphics[width=\textwidth]{fig/VGGFace2_badnet_imgc48_pinterest_Srf.png}
\end{subfigure}
\begin{subfigure}{0.16\textwidth}
	\includegraphics[width=\textwidth]{fig/VGGFace2_badnet_imgc48_pinterest_mae_adap.png}
\end{subfigure}

\begin{subfigure}{0.16\textwidth}
	\includegraphics[width=\textwidth]{fig/imagenet10_badnet_img76_monitor_org.png}
\end{subfigure}
\begin{subfigure}{0.16\textwidth}
	\includegraphics[width=\textwidth]{fig/imagenet10_badnet_img76_monitor_Srf.png}
\end{subfigure}
\begin{subfigure}{0.16\textwidth}
	\includegraphics[width=\textwidth]{fig/imagenet10_badnet_img76_monitor_mae_agg_adap.png}
\end{subfigure}
\begin{subfigure}{0.16\textwidth}
	\includegraphics[width=\textwidth]{fig/imagenet10_badnet_imgc44_monitor_org.png}
\end{subfigure}
\begin{subfigure}{0.16\textwidth}
	\includegraphics[width=\textwidth]{fig/imagenet10_badnet_imgc44_monitor_Srf.png}
\end{subfigure}
\begin{subfigure}{0.16\textwidth}
	\includegraphics[width=\textwidth]{fig/imagenet10_badnet_imgc44_monitor_mae_agg_adap.png}
\end{subfigure}


\begin{subfigure}{0.16\textwidth}
	\includegraphics[width=\textwidth]{fig/imagenet10_badnet_img64_monitor_org.png}
\end{subfigure}
\begin{subfigure}{0.16\textwidth}
	\includegraphics[width=\textwidth]{fig/imagenet10_badnet_img64_monitor_Srf.png}
\end{subfigure}
\begin{subfigure}{0.16\textwidth}
	\includegraphics[width=\textwidth]{fig/imagenet10_badnet_img64_monitor_mae_agg_adap.png}
\end{subfigure}
\begin{subfigure}{0.16\textwidth}
	\includegraphics[width=\textwidth]{fig/imagenet10_badnet_imgc10_monitor_org.png}
\end{subfigure}
\begin{subfigure}{0.16\textwidth}
	\includegraphics[width=\textwidth]{fig/imagenet10_badnet_imgc10_monitor_Srf.png}
\end{subfigure}
\begin{subfigure}{0.16\textwidth}
	\includegraphics[width=\textwidth]{fig/imagenet10_badnet_imgc10_monitor_mae_agg_adap.png}
\end{subfigure}

\begin{minipage}{0.16\textwidth}
	\centering
	\scriptsize Backdoored image 
\end{minipage} 
\begin{minipage}{0.16\textwidth}
	\centering
	\scriptsize $S$ 
\end{minipage} 
\begin{minipage}{0.16\textwidth}
	\centering
	\scriptsize Purified image 
\end{minipage} 
\begin{minipage}{0.16\textwidth}
	\centering
	\scriptsize Clean image 
\end{minipage} 
\begin{minipage}{0.16\textwidth}
	\centering
	\scriptsize $S$ 
\end{minipage} 
\begin{minipage}{0.16\textwidth}
	\centering
	\scriptsize Purified image 
\end{minipage} 


\caption{Visualizations on backdoored / clean images.}
\label{fig:sup:clean_score}

\end{figure}



\captionsetup[subfigure]{labelformat=empty}
\begin{figure*}[!t]
	\centering
\begin{subfigure}{0.16\linewidth}
	\includegraphics[width=\textwidth]{fig-supp/cifar10_badnet_2by2_color_img1_org_0.png}
\end{subfigure}
\begin{subfigure}{0.16\linewidth}
	\includegraphics[width=\textwidth]{fig-supp/cifar10_badnet_2by2_color_img1_noise_g0.05_0.png}
\end{subfigure}
\begin{subfigure}{0.16\linewidth}
	\includegraphics[width=\textwidth]{fig-supp/cifar10_badnet_2by2_color_img1_noise_g0.1_0.png}
\end{subfigure}
\begin{subfigure}{0.16\linewidth}
	\includegraphics[width=\textwidth]{fig-supp/cifar10_badnet_2by2_color_img1_gs_k3_s0.5_0.png}
\end{subfigure}
\begin{subfigure}{0.16\linewidth}
	\includegraphics[width=\textwidth]{fig-supp/cifar10_badnet_2by2_color_img1_gs_k3_s1.0_1.png}
\end{subfigure}
\begin{subfigure}{0.16\linewidth}
	\includegraphics[width=\textwidth]{fig-supp/cifar10_badnet_2by2_color_img1_OpticalDistortion_1.png}
\end{subfigure}
\begin{minipage}{0.16\linewidth}
        \scriptsize
	\centering Original Image \\ CA = 93.09 \% \\ BA = 0.00 \% \\ ASR = 100. \% 
\end{minipage} 
\begin{minipage}{0.16\linewidth}
        \scriptsize
	\centering Gaussian Noise (w) \\ CA = 53.57 \%  \\ BA = 0.09 \%  \\ ASR = 99.82 \% 
\end{minipage} 
\begin{minipage}{0.16\linewidth}
        \scriptsize
	\centering  Gaussian Noise (s)  \\ CA = 14.53 \%  \\ BA = 3.90 \%  \\ ASR = 73.10 \% 
\end{minipage} 
\begin{minipage}{0.16\linewidth}
        \scriptsize
	\centering  Gaussian Blur (w) \\ CA = 91.3 \%  \\ BA = 0.30 \%  \\ ASR = 99.68 \% 
\end{minipage} 
\begin{minipage}{0.16\linewidth}
        \scriptsize
	\centering  Gaussian Blur (s)  \\ CA = 63.15 \%  \\ BA = 61.98 \%  \\ ASR = 2.01 \% 
\end{minipage} 
\begin{minipage}{0.16\linewidth}
        \scriptsize
	\centering  Optical Distortion \\ CA = 86.78 \%  \\ BA = 69.94 \%  \\ ASR =  20.00 \% 
\end{minipage} 

\begin{subfigure}{0.16\linewidth}
	\includegraphics[width=\textwidth]{fig-supp/cifar10_badnet_2by2_color_img1_RandomGamma_0.png}
\end{subfigure}
\begin{subfigure}{0.16\linewidth}
	\includegraphics[width=\textwidth]{fig-supp/cifar10_badnet_2by2_color_img1_RandomGamma_0.png}
\end{subfigure}
\begin{subfigure}{0.16\linewidth}
	\includegraphics[width=\textwidth]{fig-supp/cifar10_badnet_2by2_color_img1_GridDistortion_0.png}
\end{subfigure}
\begin{subfigure}{0.16\linewidth}
	\includegraphics[width=\textwidth]{fig-supp/cifar10_badnet_2by2_color_img1_flip_0.png}
\end{subfigure}
\begin{subfigure}{0.16\linewidth}
	\includegraphics[width=\textwidth]{fig-supp/cifar10_badnet_2by2_color_img1_shrink_0.png}
\end{subfigure}
\begin{subfigure}{0.16\linewidth}
	\includegraphics[width=\textwidth]{fig-supp/cifar10_badnet_2by2_color_img1_Affine_0.png}
\end{subfigure}
\begin{minipage}{0.16\linewidth}
        \scriptsize
	\centering Random Contrast \\ CA = 93.01 \%  \\ BA = 0.00 \%  \\ ASR = 100.  \% 
\end{minipage} 
\begin{minipage}{0.16\linewidth}
        \scriptsize
	\centering Random Gamma  \\ CA = 93.07 \%  \\ BA = 0.00 \%  \\ ASR =  100. \% 
\end{minipage} 
\begin{minipage}{0.16\linewidth}
        \scriptsize
	\centering  Grid Distortion  \\ CA = 73.76 \%  \\ BA = 26.74 \%  \\ ASR =  64.61 \% 
\end{minipage} 
\begin{minipage}{0.16\linewidth}
        \scriptsize
	\centering  Horizontal Flip \\ CA = 93.33 \%  \\ BA = 0.00 \%  \\ ASR = 100.  \% 
\end{minipage} 
\begin{minipage}{0.16\linewidth}
        \scriptsize
	\centering  Down Scale  \\ CA = 91.16 \%  \\ BA = 0.00 \%  \\ ASR =  100. \% 
\end{minipage} 
\begin{minipage}{0.16\linewidth}
        \scriptsize
	\centering  Affine Trans  \\ CA = 89.37 \%  \\ BA = 1.10 \%  \\ ASR = 98.79  \% 
\end{minipage}

\caption{Defense results of applying test-time image transformations on \texttt{Cifar10} with 2$\times$2-color trigger. The metrics shown are calculated on the entire test set.}
\label{fig:supp:test_transformation}

\end{figure*}

\subsection{Defense with More Test-Time Transformations}\label{sec:supp:ttt}
To defense against backdoor attack, test-time transformations have been used in some previous works~\citep{gao2019strip,sarkar2020backdoor,qiu2021deepsweep}. Since they are training free and can be applied to our task, we briefly summarize these methods and remark on their limitation in our blind backdoor defense setting. \textbf{Supression}~\citep{sarkar2020backdoor} creates multiple fuzzed copies of backdoored images, and uses majority voting among fuzzed copies to recover label prediction. The fuzzed copies are obtained by adding random uniform noise or Gaussian noise to the original image. However, the intensity of noise is critical. Weak noise would not remove the backdoor behaviour, while strong noise may destroy the semantic content.  \textbf{DeepSeep}~\citep{qiu2021deepsweep} mitigates backdoor attacks using data augmentation. It first fine-tunes the infected model via clean samples with an image transformation policy, and then preprocesses inference samples with another image transformation policy. The image transformation functions include affine transformations, median filters, optical distortion, gamma compression, \etc. The fine-tuning stage requires additional clean samples, which are unavailable in our setting. \textbf{STRIP}~\citep{gao2019strip} superposes a test image with multiple other samples, and observes the entropy of predicted labels of these replicas. It aims to detect backdoored inputs, but could not locate the triggers nor recover the true label.


In Fig.~\ref{fig:supp:test_transformation}, we try different test-time image transformations on \texttt{Cifar10} with 2$\times$2-color trigger. For each transformation, we calculate the CA on clean images, BA and ASR on backdoored images. As can be seen, some weak transformations, like Gaussian Noise (w), Gaussian Blur (w), Random Contrast/Gamma, Horizontal Flip and Down Scale, can not reduce ASR. While the rest strong transformations reduces ASR, they also compromise accuracies on clean images unacceptably. To maintain performance on clean images, the model needs to adapt to these image transformations, \eg, through fine-tuning like DeepSeep does. Such requirement is infeasible in the blind backdoor defense, especially for black-box models.


\subsection{Additional Visualization of Defense Process}\label{sec:supp:visualization_process}
We present additional visualization of the defense process in Fig.~\ref{fig:supp:visualization}. The top six rows come from IAB~\citep{nguyen2020IAB} attack. IAB uses sample-specific triggers, \ie, test images contain different triggers for one backdoored model. On \texttt{Cifar10}, the triggers are irregular curves. On \texttt{GTSRB}, the triggers are color patches. Due to the complexity of triggers, the heuristic search in image space using rectangle trigger blockers~\citep{udeshi2022model} may not work well. In our method, the refined trigger score $S$ successfully identifies the trigger in each test image. Triggers are removed in the purified images, leading to correct label predictions. On \texttt{VGGFace2} and \texttt{ImageNet10}, despite their larger image size, our method also manages to locate the tiny triggers and restore the clean images.

\subsection{Additional Visualization of Defense Results}\label{sec:supp:visualization_results}
Figure~\ref{fig:supp:vis_all_1} and Figure~\ref{fig:supp:vis_all_2} visualize the purified images of comparison defense methods. ShrinkPad and Blur apply global transformations on the images. They cannot remove the backdoor triggers, but sometimes can incapacitate the backdoor triggers through adding noises or distorting the trigger patterns. When the trigger patterns are large (\ie, IAB in Figure~\ref{fig:supp:vis_all_2}), a strong transformation would be required to reduce ASR. But this will also sacrifice clean accuracies. 

DiffPure first adds a small amount noise to the backdoored images, and then uses a reserve generative process to recover the clean images. However, it frequently hallucinates image content. Looking at the last three columns of \texttt{VGGFace2}, DiffPure changes the facial expressions and facial features. These fine-grained attributes are critical to face recognition. For other datasets, DiffPure may not recover digits of \texttt{GTSRB} and the trigger patterns remain in the images. Although sometimes the trigger patterns are incapacitated. These visualization clearly shows the difference between our method and DiffPure, even though they both leverage large pretrained generative models. Ours only restores trigger-related regions, and keep other clean regions that contains important semantic details intact.



\section{Detailed Results}\label{sec:detailed_results} We present the full results in Tables.~\ref{tab:supp:cifar10-white-color}-\ref{tab:sup:imagenet100}. Februus~\citep{doan2020februus} uses GradCAM visualization to locate backdoor triggers. It relies on a threshold parameter to determine the backdoor removal regions. In the original paper, the authors use a held-out test set to determine this parameter for each dataset. Since we do not have such held-out test set in our blind backdoor defense task, we try with $\{0.6,0.7,0.8\}$, and report results with the parameter leading to best (CA+BA)/2 in the paper. The best parameter is selected for each attack setting individually. Februus is quite sensitive to this parameter. Generally, using a smaller parameter improves BA but reduces CA in Februus. The best parameter varies across different defense tasks. Our method achieves a good balance between accuracies on clean images and backdoored images. 

In the main text, we report aggregated results over different backdoor triggers. However, the defense performances can be quite different depending on the trigger sizes and patterns. Our method, using two complementary trigger scores, is designed to achieve decent accuracies in all situations.

\begin{figure*}[!t]
	\centering	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img48_org.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img48_mae_agg_rn0.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img48_mae_agg_ssim0.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img48_S1.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img48_S2.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img48_S1rf.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img48_S2rf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img48_Srf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img48_mae_agg_adap.png}
	\end{subfigure}

	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img73_org.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img73_mae_agg_rn0.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img73_mae_agg_ssim0.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img73_S1.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img73_S2.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img73_S1rf.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img73_S2rf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img73_Srf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img73_mae_agg_adap.png}
	\end{subfigure}

        \begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img9_org.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img9_mae_agg_rn0.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img9_mae_agg_ssim0.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img9_S1.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img9_S2.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img9_S1rf.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img9_S2rf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img9_Srf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img9_mae_agg_adap.png}
	\end{subfigure}



        \begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img27_org.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img27_mae_agg_rn0.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img27_mae_agg_ssim0.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img27_S1.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img27_S2.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img27_S1rf.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img27_S2rf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img27_Srf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img27_mae_agg_adap.png}
	\end{subfigure}

         \begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img13_org.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img13_mae_agg_rn0.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img13_mae_agg_ssim0.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img13_S1.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img13_S2.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img13_S1rf.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img13_S2rf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img13_Srf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img13_mae_agg_adap.png}
	\end{subfigure}

       \begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img34_org.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img34_mae_agg_rn0.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img34_mae_agg_ssim0.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img34_S1.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img34_S2.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img34_S1rf.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img34_S2rf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img34_Srf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img34_mae_agg_adap.png}
	\end{subfigure}


       \begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_badnet_2by2_white_img35_org.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_badnet_2by2_white_img35_mae_agg_rn0.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_badnet_2by2_white_img35_ssim0.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_badnet_2by2_white_img35_S1.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_badnet_2by2_white_img35_S2.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_badnet_2by2_white_img35_S1rf.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_badnet_2by2_white_img35_S2rf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_badnet_2by2_white_img35_Srf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_badnet_2by2_white_img35_mae_agg_adap.png}
	\end{subfigure}
 
        \begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img5_org.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img5_mae_agg_rn0.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img5_ssim0.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img5_S1.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img5_S2.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img5_S1rf.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img5_S2rf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img5_Srf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img5_mae_agg_adap.png}
	\end{subfigure}

        \begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img0_org.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img0_mae_agg_rn0.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img0_ssim0.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img0_S1.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img0_S2.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img0_S1rf.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img0_S2rf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img0_Srf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img0_mae_agg_adap.png}
	\end{subfigure}
 
       \begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10pretr_badnet_img0_org.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10pretr_badnet_img0_mae_agg_rn0.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10pretr_badnet_img0_mae_agg_ssim0.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10pretr_badnet_img0_S1.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10pretr_badnet_img0_S2.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10pretr_badnet_img0_S1rf.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10pretr_badnet_img0_S2rf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10pretr_badnet_img0_Srf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10pretr_badnet_img0_mae_agg_adap.png}
	\end{subfigure}

        \begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10_badnet_img8_org.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10_badnet_img8_mae_agg_rn0.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10_badnet_img8_ssim0.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10_badnet_img8_S1.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10_badnet_img8_S2.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10_badnet_img8_S1rf.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10_badnet_img8_S2rf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10_badnet_img8_Srf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10_badnet_img8_mae_agg_adap.png}
	\end{subfigure}
 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize Original image w/ trigger
	\end{minipage} 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize Restored image from rand masks 
	\end{minipage} 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize SSIM score map 
	\end{minipage} 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize $S^{(i)}$ before refinement  
	\end{minipage} 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize $S^{(l)}$ before refinement 
	\end{minipage} 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize $S^{(i)}$ after refinement   
	\end{minipage} 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize $S^{(l)}$ after refinement   
	\end{minipage} 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize $S$ for final restoration  
	\end{minipage} 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize Purified image for prediction  
	\end{minipage} 
   
    \caption{Sampled visualizations of the defense process. All the scores are clipped to a range of [0,1], with yellow for high value. The top six rows are from IAB attack, and the rest are from BadNet attack.}\label{fig:supp:visualization}
\end{figure*}



\begin{figure*}[!t]
	\centering

    \begin{minipage}{0.02\textwidth}
			\centering
			\rotatebox{90}{
				\scriptsize
				Original}
	\end{minipage}
     \begin{minipage}{0.97\textwidth}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_badnet_resnet18_cifar10_5_20_2by2_white_img4_org.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_badnet_resnet18_cifar10_5_20_2by2_white_img2_org.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_badnet_resnet18_gtsrb_2_7_2by2_color_img4_org.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_badnet_resnet18_gtsrb_28_16_1by1_white_img18_org.png}
	\end{subfigure}
		\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/imagenet10_badnet_pretrresnet50_imagenet10_monitor_img7_diff_org.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/imagenet10_badnet_pretrresnet50_imagenet10_umbrella_img9_org.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_badnet_pretrresnet50_VGGFace2_instagram_img3_org.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_badnet_pretrresnet50_VGGFace2_linkedin_img16_org.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_badnet_pretrresnet50_VGGFace2_wechat_img8_org.png}
	\end{subfigure}
    \end{minipage}

    % shrink pad weak ------------------------------------
    \begin{minipage}{0.02\linewidth}
    	\centering
    	\rotatebox{90}{
    		\scriptsize
    		ShrinkPad-w}
    \end{minipage} 
    \begin{minipage}{0.97\textwidth}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_badnet_resnet18_cifar10_5_20_2by2_white_img4_sp_pad4.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_badnet_resnet18_cifar10_5_20_2by2_white_img2_sp_pad4.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_badnet_resnet18_gtsrb_2_7_2by2_color_img4_sp_pad4.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_badnet_resnet18_gtsrb_28_16_1by1_white_img18_sp_pad4.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/imagenet10_badnet_pretrresnet50_imagenet10_monitor_img7_sp_pad28.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/imagenet10_badnet_pretrresnet50_imagenet10_umbrella_img9_sp_pad28.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_badnet_pretrresnet50_VGGFace2_instagram_img3_sp_pad28.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_badnet_pretrresnet50_VGGFace2_linkedin_img16_sp_pad28.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_badnet_pretrresnet50_VGGFace2_wechat_img8_sp_pad28.png}
	\end{subfigure}
     \end{minipage}

    % shrink pad strong ------------------------------------
    \begin{minipage}{0.02\linewidth}
    	\centering
    	\rotatebox{90}{
    		\scriptsize
    		ShrinkPad-s}
    \end{minipage} 
    \begin{minipage}{0.97\textwidth}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_badnet_resnet18_cifar10_5_20_2by2_white_img4_sp_pad8.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_badnet_resnet18_cifar10_5_20_2by2_white_img2_sp_pad8.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_badnet_resnet18_gtsrb_2_7_2by2_color_img4_sp_pad8.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_badnet_resnet18_gtsrb_28_16_1by1_white_img18_sp_pad8.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/imagenet10_badnet_pretrresnet50_imagenet10_monitor_img7_sp_pad56.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/imagenet10_badnet_pretrresnet50_imagenet10_umbrella_img9_sp_pad56.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_badnet_pretrresnet50_VGGFace2_instagram_img3_sp_pad56.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_badnet_pretrresnet50_VGGFace2_linkedin_img16_sp_pad56.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_badnet_pretrresnet50_VGGFace2_wechat_img8_sp_pad56.png}
	\end{subfigure}
     \end{minipage}

      % blur strong ------------------------------------
	 \begin{minipage}{0.02\linewidth}
		\centering
		\rotatebox{90}{
			\scriptsize
			Blur-w}
	\end{minipage} 
        \begin{minipage}{0.97\textwidth}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_badnet_resnet18_cifar10_5_20_2by2_white_img4_supp_blur0.5.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_badnet_resnet18_cifar10_5_20_2by2_white_img2_supp_blur0.5.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_badnet_resnet18_gtsrb_2_7_2by2_color_img4_supp_blur0.5.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_badnet_resnet18_gtsrb_28_16_1by1_white_img18_supp_blur0.5.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/imagenet10_badnet_pretrresnet50_imagenet10_monitor_img7_supp_blur0.5.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/imagenet10_badnet_pretrresnet50_imagenet10_umbrella_img9_supp_blur0.5.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_badnet_pretrresnet50_VGGFace2_instagram_img3_supp_blur0.5.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_badnet_pretrresnet50_VGGFace2_linkedin_img16_supp_blur0.5.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_badnet_pretrresnet50_VGGFace2_wechat_img8_supp_blur0.5.png}
	\end{subfigure}
 \end{minipage}

	 % blur strong ------------------------------------
	 \begin{minipage}{0.02\linewidth}
		\centering
		\rotatebox{90}{
			\scriptsize
			Blur-s}
	\end{minipage} 
        \begin{minipage}{0.97\textwidth}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_badnet_resnet18_cifar10_5_20_2by2_white_img4_supp_blur1.0.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_badnet_resnet18_cifar10_5_20_2by2_white_img2_supp_blur1.0.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_badnet_resnet18_gtsrb_2_7_2by2_color_img4_supp_blur1.0.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_badnet_resnet18_gtsrb_28_16_1by1_white_img18_supp_blur1.0.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/imagenet10_badnet_pretrresnet50_imagenet10_monitor_img7_supp_blur1.0.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/imagenet10_badnet_pretrresnet50_imagenet10_umbrella_img9_supp_blur1.0.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_badnet_pretrresnet50_VGGFace2_instagram_img3_supp_blur1.0.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_badnet_pretrresnet50_VGGFace2_linkedin_img16_supp_blur1.0.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_badnet_pretrresnet50_VGGFace2_wechat_img8_supp_blur1.0.png}
	\end{subfigure}
 \end{minipage}

    % Diffuision------------------------------------
 	\begin{minipage}{0.02\linewidth}
	\centering
	\rotatebox{90}{
		\scriptsize
		DiffPure}
	\end{minipage} 
        \begin{minipage}{0.97\textwidth}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_badnet_resnet18_cifar10_5_20_2by2_white_img4_diff_rec.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_badnet_resnet18_cifar10_5_20_2by2_white_img2_diff_rec.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_badnet_resnet18_gtsrb_2_7_2by2_color_img4_diff_rec.png}
	\end{subfigure}		
	\begin{subfigure}{0.105\textwidth}
	\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_badnet_resnet18_gtsrb_28_16_1by1_white_img18_diff_rec.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/imagenet10_badnet_pretrresnet50_imagenet10_monitor_img7_diff_rec.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/imagenet10_badnet_pretrresnet50_imagenet10_umbrella_img9_diff_rec.png}
	\end{subfigure}	
		\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_badnet_pretrresnet50_VGGFace2_instagram_img3_diff_rec.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_badnet_pretrresnet50_VGGFace2_linkedin_img16_diff_rec.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_badnet_pretrresnet50_VGGFace2_wechat_img8_diff_rec.png}
	\end{subfigure}	
 \end{minipage}

   % BDMAE------------------------------------
    \begin{minipage}{0.02\linewidth}
   	\centering
   	\rotatebox{90}{
   		\scriptsize
   		Ours}
   \end{minipage} 
   \begin{minipage}{0.97\textwidth}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_badnet_resnet18_cifar10_5_20_2by2_white_img4_mae_agg.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_badnet_resnet18_cifar10_5_20_2by2_white_img2_mae_agg.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
	\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_badnet_resnet18_gtsrb_2_7_2by2_color_img4_mae_agg.png}
    \end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_badnet_resnet18_gtsrb_28_16_1by1_white_img18_mae_agg.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/imagenet10_badnet_pretrresnet50_imagenet10_monitor_img7_mae_agg.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/imagenet10_badnet_pretrresnet50_imagenet10_umbrella_img9_mae_agg.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_badnet_pretrresnet50_VGGFace2_instagram_img3_mae_agg.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_badnet_pretrresnet50_VGGFace2_linkedin_img16_mae_agg.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_badnet_pretrresnet50_VGGFace2_wechat_img8_mae_agg.png}
	\end{subfigure}
 \end{minipage}
	
	
	\caption{Sampled visualizations of original images with triggers and images after defense (I).}\label{fig:supp:vis_all_1}
\end{figure*}






\begin{figure*}[!t]
	\centering	
	\begin{minipage}{0.02\linewidth}
		\centering
		\rotatebox{90}{
			\scriptsize
			Original}
	\end{minipage} 
      \begin{minipage}{0.97\textwidth}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_IAB_resnet18_img3_org.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_IAB_resnet18_img9_org.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_lc_resnet18_img13_org.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_IAB_resnet18_gtsrb_img3_org.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_IAB_resnet18_gtsrb_img10_org.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_lc_resnet18_gtsrb_img14_org.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_blended_pretrresnet50_VGGFace2_randompixels_ts15_img16_org.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_blended_pretrresnet50_VGGFace2_randompixels_ts15_img13_org.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_blended_pretrresnet50_VGGFace2_randompixels_ts15_img8_org.png}
	\end{subfigure}
	 \end{minipage}

 % shrink pad weak ------------------------------------
	\begin{minipage}{0.02\linewidth}
		\centering
		\rotatebox{90}{
			\scriptsize
			ShrinkPad-w}
	\end{minipage} 
 \begin{minipage}{0.97\textwidth}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_IAB_resnet18_img3_sp_pad4.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_IAB_resnet18_img9_sp_pad4.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_lc_resnet18_img13_sp_pad4.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_IAB_resnet18_gtsrb_img3_sp_pad4.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_IAB_resnet18_gtsrb_img10_sp_pad4.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_lc_resnet18_gtsrb_img14_sp_pad4.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_blended_pretrresnet50_VGGFace2_randompixels_ts15_img16_sp_pad28.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_blended_pretrresnet50_VGGFace2_randompixels_ts15_img13_sp_pad28.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_blended_pretrresnet50_VGGFace2_randompixels_ts15_img8_sp_pad28.png}
	\end{subfigure}
	 \end{minipage}
  
	% shrink pad strong ------------------------------------
	\begin{minipage}{0.02\linewidth}
		\centering
		\rotatebox{90}{
			\scriptsize
			ShrinkPad-s}
	\end{minipage} 
 \begin{minipage}{0.97\textwidth}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_IAB_resnet18_img3_sp_pad8.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_IAB_resnet18_img9_sp_pad8.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_lc_resnet18_img13_sp_pad8.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_IAB_resnet18_gtsrb_img3_sp_pad8.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_IAB_resnet18_gtsrb_img10_sp_pad8.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_lc_resnet18_gtsrb_img14_sp_pad8.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_blended_pretrresnet50_VGGFace2_randompixels_ts15_img16_sp_pad56.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_blended_pretrresnet50_VGGFace2_randompixels_ts15_img13_sp_pad56.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_blended_pretrresnet50_VGGFace2_randompixels_ts15_img8_sp_pad56.png}
	\end{subfigure}
	 \end{minipage}

  % blur weak ------------------------------------
	\begin{minipage}{0.02\linewidth}
		\centering
		\rotatebox{90}{
			\scriptsize
			Blur-w}
	\end{minipage} 
  \begin{minipage}{0.97\textwidth}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_IAB_resnet18_img3_supp_blur0.5.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_IAB_resnet18_img9_supp_blur0.5.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_lc_resnet18_img13_supp_blur0.5.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_IAB_resnet18_gtsrb_img3_supp_blur0.5.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_IAB_resnet18_gtsrb_img3_supp_blur0.5.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_lc_resnet18_gtsrb_img14_supp_blur0.5.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_blended_pretrresnet50_VGGFace2_randompixels_ts15_img16_supp_blur0.5.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_blended_pretrresnet50_VGGFace2_randompixels_ts15_img13_supp_blur0.5.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_blended_pretrresnet50_VGGFace2_randompixels_ts15_img8_supp_blur0.5.png}
	\end{subfigure}
	 \end{minipage}
  
	
	% blur strong ------------------------------------
	\begin{minipage}{0.02\linewidth}
		\centering
		\rotatebox{90}{
			\scriptsize
			Blur-s}
	\end{minipage} 
  \begin{minipage}{0.97\textwidth}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_IAB_resnet18_img3_supp_blur1.0.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_IAB_resnet18_img9_supp_blur1.0.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_lc_resnet18_img13_supp_blur1.0.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_IAB_resnet18_gtsrb_img3_supp_blur1.0.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_IAB_resnet18_gtsrb_img3_supp_blur1.0.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_lc_resnet18_gtsrb_img14_supp_blur1.0.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_blended_pretrresnet50_VGGFace2_randompixels_ts15_img16_supp_blur1.0.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_blended_pretrresnet50_VGGFace2_randompixels_ts15_img13_supp_blur1.0.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_blended_pretrresnet50_VGGFace2_randompixels_ts15_img8_supp_blur1.0.png}
	\end{subfigure}
	 \end{minipage}
  
	% Diffuision------------------------------------
	\begin{minipage}{0.02\linewidth}
		\centering
		\rotatebox{90}{
			\scriptsize
			DiffPure}
	\end{minipage} 
 \begin{minipage}{0.97\textwidth}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_IAB_resnet18_img3_diff_rec.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_IAB_resnet18_img9_diff_rec.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_lc_resnet18_img13_diff_rec.png}
	\end{subfigure}		
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_IAB_resnet18_gtsrb_img3_diff_rec.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_IAB_resnet18_gtsrb_img10_diff_rec.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_lc_resnet18_gtsrb_img14_diff_rec.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_blended_pretrresnet50_VGGFace2_randompixels_ts15_img16_diff_rec.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_blended_pretrresnet50_VGGFace2_randompixels_ts15_img13_diff_rec.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_blended_pretrresnet50_VGGFace2_randompixels_ts15_img8_diff_rec.png}
	\end{subfigure}	
	 \end{minipage}
  
	% BDMAE------------------------------------
	\begin{minipage}{0.02\linewidth}
		\centering
		\rotatebox{90}{
			\scriptsize
			Ours}
	\end{minipage} 
 \begin{minipage}{0.97\textwidth}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_IAB_resnet18_img3_mae_agg.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_IAB_resnet18_img9_mae_agg.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/cifar10_lc_resnet18_img13_mae_agg.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_IAB_resnet18_gtsrb_img3_mae_agg.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_IAB_resnet18_gtsrb_img10_mae_agg.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/gtsrb_lc_resnet18_gtsrb_img14_mae_agg.png}
	\end{subfigure}
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_blended_pretrresnet50_VGGFace2_randompixels_ts15_img16_mae_agg.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_blended_pretrresnet50_VGGFace2_randompixels_ts15_img13_mae_agg.png}
	\end{subfigure}	
	\begin{subfigure}{0.105\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-diff/VGGFace2_blended_pretrresnet50_VGGFace2_randompixels_ts15_img8_mae_agg.png}
	\end{subfigure}
	 \end{minipage}
	
	\caption{Sampled visualizations of original images with triggers and images after defense (II).}\label{fig:supp:vis_all_2}
\end{figure*}





\clearpage

\begin{table*}[!t]
\caption{Defense results on \texttt{Cifar10} using various sizes of color/white triggers.}
\begin{center}
\renewcommand{\tabcolsep}{0.1cm}
\centering
\scriptsize
\scalebox{0.95}{
\begin{tabular}{p{1.0cm}p{2.0cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}}
			\toprule
			\multirow{3}{*}{}  & & \multicolumn{3}{c|}{1$\times$1-color} & \multicolumn{3}{c|}{1$\times$1-white} & \multicolumn{3}{c|}{2$\times$2-color} & \multicolumn{3}{c|}{2$\times$2-white} & \multicolumn{3}{c|}{3$\times$3-color} & \multicolumn{3}{c}{3$\times$3-white} \\
			\cmidrule{3-20}	
			 & & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR\\
			\midrule
		\multicolumn{2}{c|}{Before Defense}  & 93.7 & 0.1 & 99.9 & 92.9 & 2.3 & 97.5 & 93.2 & 0.0 & 100. & 93.1 & 2.8 & 97.1 & 93.7 & 0.0 & 100. & 93.4 & 0.5 & 99.5\\
		\midrule
		 \multirow{6}{*}{Februus} & XGradCAM (0.6)   & 92.0 & 85.7 & 7.8 & 91.1 & 80.7 & 13.7 & 91.3 & 93.1 & 0.8 & 91.2 & 92.6 & 1.2 & 92.1 & 92.9 & 1.0 & 91.6 & 77.1 & 17.7\\
             & XGradCAM (0.7) & 92.8 & 78.5 & 16.2 & 91.9 & 56.1 & 40.4 & 92.2 & 87.3 & 7.0 & 92.1 & 85.0 & 9.5 & 92.8 & 92.1 & 1.7 & 92.4 & 61.2 & 34.9\\
              & XGradCAM (0.8)  & 93.3 & 62.9 & 33.0 & 92.4 & 18.4 & 80.4 & 92.8 & 50.5 & 46.6 & 92.7 & 50.9 & 46.1 & 93.3 & 81.5 & 13.3 & 92.9 & 32.1 & 65.8\\
		  & GradCAM++ (0.6)  & 74.7 & 91.2 & 0.9 & 74.4 & 89.6 & 3.3 & 76.2 & 92.9 & 0.8 & 74.8 & 91.3 & 1.7 & 75.0 & 92.7 & 0.8 & 75.0 & 87.1 & 6.6\\
               & GradCAM++ (0.7)  & 85.1 & 90.8 & 2.4 & 84.7 & 83.6 & 10.4 & 85.7 & 93.1 & 0.8 & 84.9 & 92.0 & 1.5 & 85.5 & 93.0 & 0.9 & 85.3 & 75.7 & 19.0\\
               & GradCAM++ (0.8)  & 90.8 & 66.0 & 29.5 & 90.0 & 51.4 & 45.1 & 90.7 & 77.5 & 17.5 & 90.3 & 82.3 & 12.2 & 90.8 & 92.4 & 1.5 & 90.5 & 49.9 & 46.7\\
              \midrule	
           	\multirow{2}{*}{PatchCleanser} & Vanilla  & 89.9 & 37.2 & 60.7 & 89.7 & 46.2 & 53.0 & 90.0 & 47.3 & 52.2 & 89.9 & 49.9 & 48.7 & 90.1 & 48.6 & 50.8 & 90.0 & 34.3 & 65.0\\ 
            & Variant  & 58.1 & 77.6 & 1.5 & 56.2 & 87.5 & 2.3 & 57.7 & 90.1 & 1.1 & 57.2 & 87.2 & 1.7 & 59.1 & 90.2 & 0.8 & 57.4 & 84.0 & 3.8\\
          \midrule
            \multirow{2}{*}{Blur} & Weak & 92.0 & 0.5 & 99.4 & 90.9 & 6.8 & 92.7 & 91.5 & 0.3 & 99.7 & 91.2 & 7.3 & 92.3 & 92.1 & 0.1 & 99.9 & 91.6 & 68.8 & 25.2\\
            & Strong   & 65.6 & 65.0 & 3.5 & 61.5 & 59.9 & 5.6 & 63.8 & 62.6 & 3.4 & 63.3 & 54.0 & 14.8 & 64.9 & 60.1 & 6.7 & 62.4 & 58.6 & 4.4\\
          \midrule
            \multirow{2}{*}{ShrinkPad} & Weak  & 91.5 & 44.7 & 51.3 & 89.6 & 53.3 & 42.6 & 89.6 & 6.3 & 93.2 & 90.8 & 82.2 & 9.6 & 91.5 & 28.3 & 70.1 & 91.1 & 86.9 & 3.1\\
           & Strong  & 88.3 & 32.1 & 64.5 & 85.0 & 9.8 & 87.5 & 83.5 & 2.4 & 97.4 & 87.2 & 82.0 & 6.4 & 88.4 & 11.0 & 88.3 & 87.7 & 83.1 & 3.2\\
		\midrule
		 \multirow{4}{*}{Ours} & Base  & 93.0 & 90.7 & 0.6 & 91.8 & 90.3 & 1.5 & 92.5 & 91.5 & 0.5 & 92.3 & 90.0 & 1.5 & 92.9 & 92.1 & 0.5 & 92.6 & 90.5 & 0.8\\
          & Base-$i$ & 92.5 & 73.4 & 20.0 & 91.4 & 86.4 & 6.4 & 92.1 & 91.0 & 1.1 & 91.8 & 84.2 & 8.4 & 92.4 & 90.1 & 2.9 & 92.0 & 84.1 & 8.1\\
         & Base-$l$ & 92.1 & 91.0 & 0.5 & 90.6 & 90.4 & 1.4 & 91.6 & 91.4 & 0.9 & 91.1 & 90.1 & 1.5 & 92.1 & 91.0 & 1.7 & 91.5 & 90.2 & 0.8\\
		& Large  & 93.1 & 90.8 & 0.6 & 92.0 & 90.6 & 1.4 & 92.7 & 91.8 & 0.5 & 92.5 & 90.4 & 1.3 & 93.1 & 92.3 & 0.5 & 92.7 & 90.9 & 0.8\\
 	\bottomrule
		\end{tabular} }
	\end{center}

 \label{tab:supp:cifar10-white-color}
\end{table*}


\begin{table*}[!t]
\caption{Defense results on \texttt{GSTRB} using various sizes of color/white triggers.}
\begin{center}
\renewcommand{\tabcolsep}{0.1cm}
\centering
\scriptsize
\scalebox{0.95}{
\begin{tabular}{p{1.0cm}p{2.0cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}}
			\toprule
			\multirow{3}{*}{} & & \multicolumn{3}{c|}{1$\times$1-color} & \multicolumn{3}{c|}{1$\times$1-white} & \multicolumn{3}{c|}{2$\times$2-color} & \multicolumn{3}{c|}{2$\times$2-white} & \multicolumn{3}{c|}{3$\times$3-color} & \multicolumn{3}{c}{3$\times$3-white} \\
		\cmidrule{3-20}
		 & & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR\\
			\midrule
		\multicolumn{2}{c|}{Before Defense}  & 98.7 & 0.0 & 100. & 98.0 & 2.3 & 97.5 & 98.3 & 0.0 & 100. & 98.5 & 4.4 & 95.5 & 98.8 & 0.0 & 100. & 98.4 & 1.4 & 98.5\\
	\midrule	
		 \multirow{6}{*}{Februus} & XGradCAM (0.6)  & 73.0 & 29.1 & 64.1 & 74.7 & 68.2 & 25.1 & 58.6 & 58.6 & 15.2 & 56.9 & 40.3 & 52.7 & 59.3 & 83.2 & 4.3 & 69.7 & 26.0 & 66.2\\
          & XGradCAM (0.7) & 85.2 & 22.9 & 74.6 & 84.8 & 59.1 & 38.1 & 74.8 & 47.4 & 41.9 & 74.4 & 17.6 & 81.2 & 74.8 & 77.0 & 16.3 & 82.4 & 7.9 & 90.8\\
           & XGradCAM (0.8)  & 93.2 & 14.5 & 84.8 & 92.2 & 45.3 & 53.3 & 88.3 & 30.0 & 67.7 & 88.0 & 2.9 & 97.0 & 88.3 & 51.1 & 46.4 & 91.8 & 2.9 & 96.8\\
		& GradCAM++ (0.6)   & 65.2 & 45.3 & 33.5 & 46.1 & 94.3 & 0.2 & 47.0 & 59.8 & 17.2 & 45.0 & 91.5 & 1.6 & 48.0 & 86.2 & 0.9 & 49.8 & 73.5 & 6.1\\
          & GradCAM++ (0.7)   & 80.3 & 40.8 & 50.8 & 64.3 & 94.8 & 1.6 & 64.8 & 46.7 & 44.5 & 65.5 & 79.2 & 18.4 & 64.7 & 89.1 & 4.3 & 68.1 & 63.2 & 29.2\\
           & GradCAM++ (0.8)   & 91.3 & 28.4 & 69.3 & 81.8 & 91.0 & 6.2 & 83.0 & 17.5 & 81.4 & 83.6 & 22.4 & 77.3 & 82.6 & 70.2 & 26.7 & 84.6 & 30.9 & 67.4\\
	    \midrule
          \multirow{2}{*}{PatchCleanser} & Vanilla  & 95.3 & 4.4 & 94.6 & 95.9 & 10.1 & 89.5 & 94.6 & 12.8 & 87.2 & 95.0 & 16.8 & 83.0 & 94.6 & 10.8 & 89.1 & 94.2 & 5.0 & 94.6\\
           & Variant  & 12.7 & 45.9 & 0.5 & 12.7 & 88.8 & 0.8 & 14.4 & 97.8 & 0.1 & 13.8 & 93.3 & 2.3 & 14.9 & 96.1 & 0.0 & 11.3 & 63.1 & 5.5\\
          \midrule
           \multirow{2}{*}{Blur} & Weak  & 98.6 & 3.0 & 96.9 & 98.0 & 9.4 & 90.3 & 98.2 & 0.1 & 99.9 & 98.5 & 6.6 & 93.3 & 98.6 & 0.2 & 99.8 & 98.3 & 4.1 & 95.6\\ 
           & Strong  & 97.9 & 97.3 & 0.2 & 97.3 & 97.3 & 0.1 & 97.6 & 96.8 & 0.9 & 97.7 & 94.5 & 3.1 & 98.0 & 96.1 & 1.8 & 97.8 & 87.3 & 4.6\\
          \midrule
           \multirow{2}{*}{ShrinkPad} & Weak & 98.0 & 40.4 & 57.9 & 96.9 & 25.0 & 74.6 & 96.7 & 3.2 & 96.7 & 97.8 & 58.9 & 39.8 & 98.0 & 12.9 & 87.0 & 97.8 & 59.4 & 34.4\\
           & Strong & 94.1 & 27.7 & 69.4 & 91.0 & 5.1 & 94.2 & 91.8 & 2.2 & 97.8 & 92.9 & 32.8 & 64.5 & 93.7 & 10.4 & 89.0 & 93.3 & 62.9 & 18.6\\
           \midrule
		\multirow{4}{*}{Ours} & Base  & 98.5 & 92.4 & 0.2 & 97.6 & 95.9 & 1.0 & 98.0 & 97.8 & 0.1 & 98.3 & 96.5 & 1.3 & 98.6 & 98.3 & 0.1 & 98.1 & 91.0 & 2.8\\
          & Base-$i$ & 73.0 & 29.1 & 64.1 & 74.7 & 68.2 & 25.1 & 58.6 & 58.6 & 15.2 & 56.9 & 40.3 & 52.7 & 59.3 & 83.2 & 4.3 & 69.7 & 26.0 & 66.2\\
          & Base-$l$ & 65.2 & 45.3 & 33.5 & 64.3 & 94.8 & 1.6 & 47.0 & 59.8 & 17.2 & 45.0 & 91.5 & 1.6 & 64.7 & 89.1 & 4.3 & 68.1 & 63.2 & 29.2\\
	    & Large  & 98.7 & 94.7 & 0.2 & 97.9 & 96.3 & 0.9 & 98.3 & 98.0 & 0.1 & 98.5 & 96.6 & 1.5 & 98.8 & 98.3 & 0.2 & 98.3 & 91.8 & 2.9\\
			\bottomrule
		\end{tabular} }
	\end{center}

 \label{tab:supp:gtsrb-white-color}
\end{table*}


\begin{table*}[!t]
 \caption{Defense results on \texttt{VGGFace2} using various types of triggers.}
\begin{center}
\renewcommand{\tabcolsep}{0.1cm}
\centering
\scriptsize
\scalebox{0.95}{
\begin{tabular}{p{1.0cm}p{2.0cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}}
			\toprule
			\multirow{3}{*}{} & & \multicolumn{3}{c|}{Trigger ` \begin{minipage}{0.02\linewidth}	\includegraphics[width=\linewidth]{fig-png/instagram.png} \end{minipage} '} & \multicolumn{3}{c|}{Trigger ` \begin{minipage}{0.02\linewidth}	\includegraphics[width=\linewidth]{fig-png/linkedin.png} \end{minipage} '} & \multicolumn{3}{c|}{Trigger ` \begin{minipage}{0.02\linewidth}	\includegraphics[width=\linewidth]{fig-png/pinterest.png} \end{minipage} '} & \multicolumn{3}{c|}{Trigger ` \begin{minipage}{0.02\linewidth}	\includegraphics[width=\linewidth]{fig-png/twitter.png} \end{minipage} '} & \multicolumn{3}{c}{Trigger ` \begin{minipage}{0.02\linewidth}	\includegraphics[width=\linewidth]{fig-png/wechat.png} \end{minipage} '}  \\
		 \cmidrule{3-17}
			 & & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR \\
			\midrule
		\multicolumn{2}{c|}{Before Defense} & 95.6 & 0.0 & 100. & 95.6 & 0.0 & 100. & 95.5 & 0.0 & 100. & 95.4 & 0.0 & 100. & 95.6 & 0.0 & 100.\\
		\midrule
		   \multirow{2}{*}{Februus} & XGradCAM   & 65.2 & 94.1 & 0.0 & 65.3 & 95.0 & 0.0 & 67.5 & 95.4 & 0.0 & 64.6 & 68.2 & 28.6 & 65.0 & 94.8 & 0.0\\
		   & GradCAM++ & 62.8 & 94.1 & 0.0 & 62.5 & 95.0 & 0.0 & 65.3 & 95.4 & 0.0 & 62.3 & 67.7 & 29.2 & 62.5 & 94.8 & 0.1\\
           \midrule
             \multirow{2}{*}{PatchCleanser}    & Vanilla  & 93.2 & 42.4 & 57.6 & 93.2 & 45.8 & 54.1 & 92.9 & 43.8 & 56.1 & 93.0 & 44.8 & 55.2 & 92.8 & 38.3 & 61.6\\
             & Variant & 51.1 & 94.3 & 0.0 & 51.7 & 94.6 & 0.0 & 49.6 & 95.3 & 0.0 & 50.6 & 95.1 & 0.0 & 50.3 & 94.3 & 0.0\\  
		\midrule
            \multirow{2}{*}{Blur} & Weak  & 95.5 & 0.0 & 100. & 95.5 & 0.1 & 99.9 & 95.5 & 0.1 & 99.9 & 95.3 & 0.1 & 99.9 & 95.5 & 0.0 & 100.\\
            & Strong  & 95.3 & 0.1 & 99.9 & 95.3 & 22.0 & 77.5 & 95.2 & 28.4 & 70.9 & 95.0 & 0.6 & 99.4 & 95.2 & 0.8 & 99.2\\
	     \midrule
            \multirow{2}{*}{ShrinkPad} & Weak & 93.9 & 9.1 & 90.6 & 93.8 & 54.4 & 42.0 & 93.9 & 67.3 & 28.9 & 93.7 & 22.9 & 75.9 & 93.9 & 23.9 & 75.2\\
            & Strong  & 88.4 & 35.2 & 61.1 & 88.2 & 71.5 & 17.7 & 88.5 & 78.6 & 11.1 & 88.1 & 42.8 & 50.7 & 88.2 & 43.7 & 51.1\\
         \midrule
			 \multirow{4}{*}{Ours} & Base  & 91.3 & 91.8 & 2.1 & 91.3 & 92.3 & 1.2 & 91.3 & 93.1 & 0.1 & 91.3 & 93.2 & 0.0 & 91.4 & 89.6 & 4.7\\
			 & Large-$i$   & 91.1 & 68.0 & 28.1 & 91.1 & 79.0 & 16.2 & 91.0 & 89.4 & 4.8 & 91.0 & 71.4 & 23.7 & 91.2 & 52.9 & 44.1\\
			 & Large-$l$   & 90.9 & 92.0 & 2.2 & 90.7 & 92.2 & 0.9 & 90.7 & 92.4 & 0.1 & 90.6 & 92.5 & 0.1 & 90.9 & 87.3 & 7.5\\
			 & Large  & 93.0 & 92.4 & 1.9 & 92.8 & 92.6 & 1.2 & 93.0 & 93.5 & 0.1 & 92.7 & 93.5 & 0.0 & 92.9 & 87.0 & 7.9\\
			\bottomrule
		\end{tabular} }
	\end{center}

\label{tab:sup:vggface2}

\end{table*}



\begin{table*}[!t]
 \caption{Defense results on \texttt{ImageNet10} using various types of triggers ($^\dagger$without adaptive thresholds adjustment).}
\begin{center}
\renewcommand{\tabcolsep}{0.1cm}
\centering
\scriptsize
\scalebox{0.95}{
\begin{tabular}{p{1.0cm}p{2.0cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}}
			\toprule
			\multirow{3}{*}{} & & \multicolumn{3}{c|}{1$\times$1-color} & \multicolumn{3}{c|}{2$\times$2-color} & \multicolumn{3}{c|}{3$\times$3-color} & \multicolumn{3}{c|}{Trigger ` \begin{minipage}{0.02\linewidth}	\includegraphics[width=\linewidth]{fig-png/monitor.png}
				\end{minipage} '
			} & \multicolumn{3}{c|}{Trigger ` \begin{minipage}{0.02\linewidth}	\includegraphics[width=\linewidth]{fig-png/umbrella.png} \end{minipage} '
			}
			& \multicolumn{3}{c}{Trigger ` \begin{minipage}{0.02\linewidth}	\includegraphics[width=\linewidth]{fig-png/watermelon_small.png} \end{minipage} '
			} \\
			\cmidrule{3-20}	
			& & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR\\
			\midrule
			\multicolumn{2}{c|}{Before Defense} & 88.4 & 45.5 & 49.6 & 89.2 & 8.6 & 90.4 & 89.8 & 3.6 & 96.1 & 89.7 & 0.0 & 100. & 89.9 & 0.7 & 99.1 & 89.9 & 0.0 & 100.\\	
			\midrule
            \multirow{2}{*}{PatchCleanser} & Vanilla  & 83.0 & 62.3 & 29.8 & 84.7 & 57.8 & 39.2 & 84.5 & 55.2 & 41.9 & 85.0 & 58.0 & 38.9 & 84.9 & 59.4 & 33.9 & 84.8 & 55.0 & 38.8\\
             & Variant  & 55.4 & 67.2 & 14.2 & 63.8 & 84.4 & 3.6 & 62.3 & 84.6 & 2.8 & 62.2 & 87.5 & 1.4 & 64.7 & 79.3 & 1.9 & 63.9 & 82.0 & 0.9\\
                \midrule
                \multirow{2}{*}{Blur} & Weak  & 87.3 & 49.6 & 44.1 & 88.7 & 18.8 & 79.4 & 88.5 & 16.1 & 82.0 & 88.1 & 0.1 & 99.9 & 88.8 & 1.7 & 98.1 & 89.1 & 0.2 & 99.8\\
           & Strong  & 82.7 & 61.3 & 29.4 & 85.9 & 64.7 & 26.8 & 85.6 & 57.0 & 33.6 & 84.9 & 6.0 & 93.8 & 84.7 & 10.2 & 88.6 & 84.9 & 6.2 & 93.3\\
          \midrule
           \multirow{2}{*}{ShrinkPad} & Weak  & 87.7 & 80.7 & 9.0 & 87.8 & 76.9 & 14.3 & 88.7 & 60.2 & 33.1 & 89.0 & 6.9 & 92.7 & 88.5 & 28.9 & 68.0 & 88.8 & 4.3 & 95.6\\
           & Strong & 85.8 & 82.6 & 6.0 & 86.4 & 86.1 & 2.5 & 86.9 & 78.2 & 11.2 & 87.1 & 40.8 & 56.2 & 86.5 & 39.5 & 54.2 & 87.5 & 13.1 & 85.7\\
                \midrule
			\multirow{4}{*}{Ours$^\dagger$} & Base  & 65.1 & 60.4 & 17.5 & 71.6 & 70.8 & 7.0 & 74.4 & 73.1 & 4.6 & 73.3 & 75.9 & 3.2 & 73.3 & 69.0 & 4.5 & 72.8 & 75.4 & 2.2\\
			& Large-$i$  & 65.2 & 56.8 & 25.6 & 70.3 & 54.8 & 33.8 & 71.6 & 58.5 & 28.2 & 72.9 & 68.3 & 13.7 & 72.7 & 68.4 & 12.8 & 73.4 & 66.7 & 15.5\\
			& Large-$l$ & 83.8 & 75.8 & 11.8 & 85.6 & 81.2 & 5.8 & 86.2 & 85.1 & 2.7 & 86.8 & 87.3 & 1.2 & 85.9 & 84.3 & 1.7 & 86.4 & 87.8 & 0.7\\
			& Large  & 77.2 & 69.9 & 13.5 & 81.8 & 77.7 & 5.4 & 82.6 & 80.0 & 3.4 & 82.5 & 80.5 & 1.6 & 82.5 & 73.3 & 3.8 & 83.0 & 80.1 & 1.4\\
			\midrule
			\multirow{4}{*}{Ours} & Base  & 75.1 & 71.4 & 13.8 & 80.1 & 80.8 & 5.4 & 80.9 & 83.8 & 3.1 & 81.5 & 84.1 & 2.5 & 81.0 & 82.7 & 2.4 & 80.9 & 83.7 & 1.7\\
			& Large-$i$  & 79.0 & 62.0 & 27.4 & 82.8 & 49.9 & 43.9 & 82.8 & 53.4 & 39.7 & 83.8 & 61.2 & 28.7 & 83.7 & 67.2 & 20.5 & 83.3 & 59.0 & 31.0\\
			& Large-$l$  & 84.0 & 76.7 & 11.8 & 85.5 & 82.2 & 5.9 & 86.3 & 85.7 & 2.6 & 86.8 & 87.3 & 1.2 & 86.0 & 85.0 & 1.6 & 86.6 & 87.7 & 0.7\\
			& Large  & 81.4 & 76.2 & 10.9 & 84.0 & 83.2 & 5.6 & 84.2 & 84.9 & 2.9 & 84.6 & 86.9 & 1.5 & 84.1 & 84.7 & 1.4 & 85.1 & 86.4 & 1.0\\
			\bottomrule
		\end{tabular} }
	\end{center}

\label{tab:sup:imagenet10}
 
\end{table*}






\begin{table*}[!t]
 \caption{Defense results on \texttt{ImageNet50} using various types of triggers.}
\begin{center}
\renewcommand{\tabcolsep}{0.1cm}
\centering
\scriptsize
\scalebox{0.95}{
\begin{tabular}{p{1.0cm}p{2.0cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}}
			\toprule
			\multirow{3}{*}{} & & \multicolumn{3}{c|}{1$\times$1-color} & \multicolumn{3}{c|}{2$\times$2-color} & \multicolumn{3}{c|}{3$\times$3-color} & \multicolumn{3}{c|}{Trigger ` \begin{minipage}{0.02\linewidth}	\includegraphics[width=\linewidth]{fig-png/monitor.png}
				\end{minipage} '
			} & \multicolumn{3}{c|}{Trigger ` \begin{minipage}{0.02\linewidth}	\includegraphics[width=\linewidth]{fig-png/umbrella.png} \end{minipage} '
			}
			& \multicolumn{3}{c}{Trigger ` \begin{minipage}{0.02\linewidth}	\includegraphics[width=\linewidth]{fig-png/watermelon_small.png} \end{minipage} '
			} \\
			\cmidrule{3-20}	
			& & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR\\
			\midrule
			\multicolumn{2}{c|}{Before Defense}   & 83.7 & 2.4 & 97.0 & 83.8 & 0.2 & 99.7 & 83.9 & 0.2 & 99.8 & 84.4 & 0.0 & 100. & 84.1 & 0.1 & 99.9 & 84.1 & 0.0 & 100.\\
			\midrule
            \multirow{2}{*}{PatchCleanser} & Vanilla  & 79.1 & 47.1 & 48.2 & 79.4 & 44.9 & 51.7 & 79.8 & 44.4 & 52.8 & 79.6 & 49.0 & 47.0 & 80.2 & 44.7 & 47.7 & 79.6 & 44.1 & 49.2\\
            & Variant  & 52.9 & 79.6 & 1.1 & 53.8 & 81.3 & 0.3 & 54.3 & 81.8 & 0.4 & 54.8 & 82.1 & 0.2 & 54.2 & 75.1 & 0.1 & 54.6 & 76.2 & 0.1\\
                \midrule
                \multirow{2}{*}{Blur} & Weak & 82.9 & 11.0 & 86.9 & 83.3 & 7.9 & 90.4 & 83.0 & 9.0 & 89.8 & 83.5 & 0.1 & 99.9 & 83.4 & 0.9 & 99.0 & 83.5 & 0.4 & 99.5\\
           & Strong  & 78.5 & 62.5 & 21.1 & 79.3 & 75.5 & 5.3 & 78.9 & 64.6 & 19.2 & 79.6 & 11.2 & 87.2 & 79.5 & 38.3 & 54.4 & 79.7 & 42.6 & 48.6\\
          \midrule
           \multirow{2}{*}{ShrinkPad} & Weak & 81.7 & 70.2 & 13.9 & 81.9 & 77.1 & 6.1 & 81.9 & 49.8 & 38.5 & 82.3 & 7.5 & 91.4 & 82.2 & 27.8 & 63.5 & 82.2 & 6.1 & 93.2\\
           & Strong  & 79.0 & 76.7 & 3.1 & 79.3 & 76.0 & 4.0 & 79.5 & 72.4 & 7.9 & 79.9 & 41.9 & 48.5 & 79.7 & 46.1 & 36.5 & 79.3 & 17.7 & 78.5\\
              \midrule
			\multirow{4}{*}{Ours$^\dagger$} & Base & 52.8 & 54.9 & 1.6 & 53.6 & 61.1 & 0.8 & 52.8 & 60.4 & 0.9 & 52.7 & 59.9 & 1.3 & 51.7 & 48.4 & 1.5 & 52.5 & 56.7 & 1.0\\
			& Large-$i$ & 57.2 & 48.5 & 22.7 & 57.2 & 37.1 & 44.8 & 57.6 & 47.4 & 29.5 & 57.4 & 57.1 & 10.8 & 56.9 & 53.9 & 10.8 & 57.7 & 50.2 & 17.2\\
			& Large-$l$ & 75.0 & 75.5 & 1.4 & 75.7 & 77.3 & 0.4 & 75.9 & 77.8 & 0.3 & 75.7 & 81.0 & 0.2 & 76.2 & 74.3 & 0.2 & 75.8 & 78.6 & 0.2\\
			& Large  & 66.5 & 62.7 & 1.7 & 67.2 & 69.7 & 0.7 & 67.5 & 69.1 & 0.6 & 66.9 & 67.7 & 0.6 & 67.0 & 56.5 & 0.9 & 67.0 & 64.3 & 0.6\\
           \midrule
		\multirow{4}{*}{Ours} & Base  & 61.8 & 69.9 & 1.4 & 62.3 & 74.6 & 0.5 & 61.8 & 74.0 & 0.6 & 61.7 & 69.8 & 0.8 & 61.3 & 65.5 & 0.6 & 61.4 & 66.7 & 0.8\\
			& Large-$i$  & 71.7 & 48.3 & 34.1 & 71.7 & 35.8 & 52.9 & 72.1 & 47.6 & 38.1 & 71.4 & 55.9 & 24.8 & 72.0 & 56.7 & 19.7 & 71.9 & 48.1 & 32.7\\
 			& Large-$l$  & 75.7 & 77.0 & 1.4 & 76.5 & 79.1 & 0.3 & 76.4 & 79.4 & 0.3 & 76.3 & 81.0 & 0.2 & 76.8 & 75.9 & 0.2 & 76.4 & 78.7 & 0.2\\
			& Large  & 72.2 & 75.3 & 1.3 & 72.7 & 78.3 & 0.5 & 73.0 & 78.7 & 0.4 & 72.7 & 76.9 & 0.4 & 72.4 & 73.2 & 0.4 & 72.6 & 74.2 & 0.5\\
			\bottomrule
		\end{tabular} }
	\end{center}

\label{tab:sup:imagenet50}
 
\end{table*}

\begin{table*}[!t]
 \caption{Defense results on \texttt{ImageNet100} using various types of triggers.}
\begin{center}
\renewcommand{\tabcolsep}{0.1cm}
\centering
\scriptsize
\scalebox{0.95}{
\begin{tabular}{p{1.0cm}p{2.0cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}|@{}p{0.65cm}<{\centering}@{}p{0.6cm}<{\centering}@{}p{0.50cm}<{\centering}}
			\toprule
			\multirow{3}{*}{} & & \multicolumn{3}{c|}{1$\times$1-color} & \multicolumn{3}{c|}{2$\times$2-color} & \multicolumn{3}{c|}{3$\times$3-color} & \multicolumn{3}{c|}{Trigger ` \begin{minipage}{0.02\linewidth}	\includegraphics[width=\linewidth]{fig-png/monitor.png}
				\end{minipage} '
			} & \multicolumn{3}{c|}{Trigger ` \begin{minipage}{0.02\linewidth}	\includegraphics[width=\linewidth]{fig-png/umbrella.png} \end{minipage} '
			}
			& \multicolumn{3}{c}{Trigger ` \begin{minipage}{0.02\linewidth}	\includegraphics[width=\linewidth]{fig-png/watermelon_small.png} \end{minipage} '
			} \\
			\cmidrule{3-20}	
			& & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR & CA & BA & ASR\\
			\midrule
			\multicolumn{2}{c|}{Before Defense}  & 81.9 & 0.9 & 98.9 & 82.4 & 0.1 & 99.9 & 82.6 & 0.1 & 99.9 & 82.4 & 0.0 & 100. & 82.3 & 0.0 & 100. & 82.4 & 0.0 & 100.\\
			\midrule
            \multirow{2}{*}{PatchCleanser} & Vanilla  & 78.5 & 44.1 & 51.9 & 78.9 & 43.2 & 53.6 & 79.2 & 43.3 & 53.7 & 79.0 & 46.5 & 49.9 & 78.8 & 41.1 & 52.5 & 78.9 & 42.3 & 52.1\\
            & Variant & 51.0 & 78.9 & 0.3 & 51.9 & 80.1 & 0.1 & 52.8 & 80.7 & 0.1 & 52.5 & 80.5 & 0.1 & 52.0 & 72.7 & 0.1 & 52.2 & 75.3 & 0.1\\
                \midrule
                \multirow{2}{*}{Blur} & Weak  & 80.7 & 6.4 & 92.2 & 81.1 & 6.1 & 92.7 & 81.3 & 5.9 & 93.0 & 81.2 & 0.1 & 99.9 & 81.2 & 0.8 & 99.2 & 81.4 & 0.2 & 99.7\\
           & Strong   & 75.5 & 67.5 & 10.7 & 75.9 & 74.1 & 2.4 & 76.2 & 62.6 & 18.3 & 75.9 & 24.2 & 71.0 & 76.4 & 37.1 & 53.3 & 76.2 & 44.3 & 43.1\\
          \midrule
           \multirow{2}{*}{ShrinkPad} & Weak & 79.7 & 66.4 & 16.2 & 79.9 & 74.9 & 6.4 & 80.2 & 54.8 & 29.6 & 80.1 & 11.6 & 86.6 & 79.9 & 37.4 & 47.7 & 79.9 & 8.9 & 89.7\\
           & Strong  & 76.7 & 74.6 & 2.3 & 77.0 & 74.2 & 3.5 & 77.3 & 71.5 & 7.1 & 77.4 & 53.5 & 31.2 & 77.7 & 52.4 & 22.8 & 77.0 & 25.6 & 68.0\\
              \midrule
			\multirow{4}{*}{Ours$^\dagger$} & Base  & 48.4 & 52.3 & 0.8 & 49.8 & 58.6 & 0.5 & 49.4 & 58.4 & 0.6 & 49.4 & 57.6 & 0.8 & 48.9 & 46.3 & 0.8 & 48.5 & 53.6 & 0.6\\
			& Large-$i$  & 54.4 & 47.0 & 22.0 & 54.7 & 37.1 & 43.1 & 54.7 & 46.0 & 28.8 & 54.4 & 54.1 & 11.2 & 54.2 & 51.1 & 10.8 & 54.2 & 47.9 & 16.4\\
			& Large-$l$  & 71.8 & 73.8 & 0.6 & 72.1 & 75.4 & 0.1 & 72.1 & 76.0 & 0.1 & 72.1 & 79.3 & 0.1 & 72.0 & 71.4 & 0.1 & 71.9 & 76.3 & 0.1\\
			& Large   & 62.9 & 60.0 & 0.8 & 63.3 & 67.3 & 0.3 & 63.2 & 65.3 & 0.4 & 62.8 & 64.3 & 0.4 & 62.7 & 53.6 & 0.7 & 62.9 & 61.0 & 0.5\\
           \midrule
		\multirow{4}{*}{Ours} & Base  & 58.5 & 67.3 & 0.6 & 59.6 & 73.1 & 0.2 & 59.1 & 71.9 & 0.3 & 59.3 & 68.1 & 0.5 & 58.7 & 62.9 & 0.3 & 58.7 & 64.0 & 0.6\\
			& Large-$i$  & 68.8 & 47.2 & 33.7 & 69.3 & 36.3 & 51.2 & 68.9 & 46.3 & 37.8 & 69.1 & 53.7 & 25.1 & 69.1 & 54.7 & 19.9 & 68.9 & 46.4 & 31.8\\
 			& Large-$l$  & 73.2 & 75.4 & 0.6 & 73.4 & 77.4 & 0.1 & 73.4 & 77.6 & 0.1 & 73.6 & 79.3 & 0.1 & 73.3 & 73.1 & 0.1 & 73.2 & 76.3 & 0.1\\
			& Large & 69.4 & 73.8 & 0.5 & 69.6 & 76.9 & 0.2 & 69.5 & 76.6 & 0.2 & 69.4 & 73.9 & 0.3 & 69.3 & 70.8 & 0.2 & 69.4 & 71.4 & 0.4\\
			\bottomrule
		\end{tabular} }
	\end{center}

\label{tab:sup:imagenet100}
 
\end{table*}






% \vspace{-1.4mm}\cparagraph{Cifar10 and GTSRB.} From Table~\ref{tab:agg_results}, models have high CA, low BA and high ASR before defense. The baseline method Februus works on some attack settings such as \texttt{Cifar10} with $2\times 2$-color trigger, but fails on many others, especially on \texttt{GTSRB}. The reason is that images of \texttt{Cifar10} and \texttt{GTSRB} are of size 32$\times$32. The layer for visualization has a low resolution, making it hard to precisely locate triggers. The performance is also affected by the visualization method. Generally, GradCAM++ uses second-order information, and works better than XGradCAM. The CA of Februus is low because the attended regions on clean images contain contents. Our methods work consistently well on all attack settings. The BA on purified backdoored images are close to the clean accuracy, indicating that triggers have been successfully detected and removed. CA on clean images drops negligibly. Using \texttt{MAE-Large} leads to slightly higher accuracies due to better restorations. Comparing the two variants, \texttt{Base-$i$} does not perform well on small or white triggers as it is hard to detect triggers with structural similarity in such cases. \texttt{Base-$l$} is complementary on these attacks. The full method works for all cases. Table~\ref{tab:GTSRB-IAB-LC} shows results with IAB and LC attacks. IAB uses sample-specific irregular curves as triggers, while LC uses four distant checkerboards. Our method still achieves decent accuracies.


% \vspace{-1.4mm}\cparagraph{ImageNet10.} Results are listed in Tab.~\ref{tab:agg_results}. Since there is no available GAN model for Februus on \texttt{ImageNet10}, we do not compare with it. \texttt{ImageNet10} has a resolution of 224$\times$224, which brings two challenges. The triggers are relatively small compared to the image size. Besides, when reconstructing images with MAE, some details like small edges may be blurred or lost. The corresponding regions thus have low SSIM scores and high $S^{(i)}$ values. This makes it difficult for image-based score to locate triggers. Label-based score, on the contrary, works well in such situations. Nevertheless, the full method can still handle this automatically. As shown in the table, the performances of \texttt{Large} are very close to \texttt{Large-$l$}. One key step is the adaptive thresholds adjustment.  \texttt{ImageNet10} experiments generally have higher $S$ values than those in \texttt{Cifar10} and \texttt{GTSRB}, due to the increased resolution. By increasing the thresholds used for image restoration adaptively, it avoids destruction to the content regions. 

% \vspace{-1.4mm}\cparagraph{VGGFace2.} We use VGG16 and ResNet18 as the network architecture. Table~\ref{tab:agg_results} lists the results. For VGG16, the baseline method Februus obtains high BA on two triggers and poor scores on the rest. For ResNet18, its BA is pretty good, but CA is severely compromised. This verifies that the visualization is quite sensitive to network architecture and trigger patterns.  Our method achieves a good balance between CA and BA. Similar to \texttt{ImageNet10}, \texttt{Large-$i$} fails. The full method achieves decent accuracies on both clean and backdoored images.   



\end{document}
