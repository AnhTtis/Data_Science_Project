\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{stmaryrd}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{array}

\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{subcaption}
\usepackage{enumitem}

\newcommand{\ling}[1]{\textcolor[rgb]{1.00,0.00,1.00}{#1}}
\newcommand{\cc}[1]{\textcolor{red}{[CC: #1]}}
\newcommand{\ccinline}[1]{\textcolor{red}{#1}}
\newcommand{\ts}[1]{\textcolor{green}{[TS: #1]}}
\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}
\newcommand{\cparagraph}[1]{\smallskip\noindent\textbf{#1}}

\def\m{\bm{m}}
\def\x{\bm{x}}
\def\z{\bm{z}}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

\iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{2972} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ificcvfinal\pagestyle{empty}\fi

\begin{document}

%%%%%%%%% TITLE
\title{Mask and Restore: Blind Backdoor Defense at Test Time with Masked Autoencoder}

\author{Tao Sun, Lu Pang, Chao Chen, Haibin Ling\\
Stony Brook University\\
{\tt\small \{tao,hling,luppang\}@cs.stonybrook.edu, chao.chen.1@stonybrook.edu}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
}
\maketitle
% Remove page # from the first page of camera-ready.
\ificcvfinal\thispagestyle{empty}\fi


%%%%%%%%% ABSTRACT
\begin{abstract}
 Deep neural networks are vulnerable to backdoor attacks, where an adversary maliciously manipulates the model behavior through overlaying images with special triggers. Existing backdoor defense methods often require accessing a few validation data and model parameters, which are impractical in many real-world applications, \eg, when the model is provided as a cloud service. In this paper, we address the practical task of blind backdoor defense at test time, in particular for black-box models. The true label of every test image needs to be recovered on the fly from the hard label predictions of a suspicious model. The heuristic trigger search in image space, however, is not scalable to complex triggers or high image resolution. We circumvent such barrier by leveraging generic image generation models, and propose a framework of \emph{Blind Defense with Masked AutoEncoder} (BDMAE). It uses the image structural similarity and label consistency between the test image and MAE restorations to detect possible triggers. The detection result is refined by considering the topology of triggers. We obtain a purified test image from restorations for making prediction. Our approach is blind to the model architectures, trigger patterns or image benignity. Extensive experiments on multiple datasets with different backdoor attacks validate its effectiveness and generalizability. Code is available at \url{https://github.com/tsun/BDMAE}.
 
  
  
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}

Deep neural networks have been widely used in various computer vision tasks, like image classification~\cite{Krizhevsky2012imagenet}, object detection~\cite{girshick2014rich} and image segmentation~\cite{long2015fully}, \etc. Despite the superior performances, their vulnerability to backdoor attacks has raised increasing concerns~\cite{gu2019badnets,nguyen2020IAB,turner2019lc}. During training, an adversary can maliciously inject a small portion of poisoned data. These images contain special triggers that are associated with specific target labels. At inference, the backdoored model behaves normally on clean images but makes incorrect predictions on images with triggers.

To defend against backdoor behaviors, existing methods often require accessing a few validation data and model parameters. Some works reverse-engineer triggers~\cite{wang2019NC,guan2022shapley}, and mitigate backdoor by pruning bad neurons or retraining models~\cite{liu2018fine-pruning,wang2019NC,zeng2021i-bau}. The clean labeled data they require, however, are often unavailable. A recent work shows that the backdoor behaviors could be cleansed with unlabeled or even out-of-distribution data~\cite{pang2022backdoor}. Instead of modifying the model, Februus~\cite{doan2020februus} detects triggers with GradCAM~\cite{selvaraju2017grad}, and feeds purified images to the backdoored model. 
% With increasing concerns on data privacy and intellectual property, many models are provided as black-box where detailed parameters are concealed~\cite{dong2021black,guoaeva,chen2019deepinspect}, \eg, a cloud service API. Existing white-box defense methods are therefore no longer applicable.    


\begin{figure}[!t]
	\centering	
	\includegraphics[width=\linewidth]{fig-png/task.pdf}
  %\vspace{-6mm}
	\caption{Illustration of blind backdoor defense at test time. The prediction model is black-box and may be backdoored. Test images come in a data stream. The defender sanitizes every image to obtain the correct label prediction on-the-fly.}
  \label{fig:task}
  \vspace{-6mm}
\end{figure}

All these defending methods, although effective, assume the model is known. Such white-box assumption, however, may not fit many real-world scenarios.
Due to increasing concerns on data privacy and intellectual property, many models are provided as black-box where detailed parameters are concealed~\cite{dong2021black,guoaeva,chen2019deepinspect}, \eg, a cloud service API. It is thus crucial to address the problem for black-box models. 

In this paper, we tackle the relatively extreme setting and address the task of \emph{Blind Backdoor Defense at Test Time}, in particular for black-box models. \emph{Blind} means that there is no information on whether the model and test images are backdoored or not. Shown in Fig.~\ref{fig:task}, the prediction model is black-box and may have been injected a backdoor. Test images come in a data stream. The true label of every test image is unknown; it needs to be recovered on the fly only from the hard label predictions of the suspicious model, without accessing additional data or the model's confidence. This is a very challenging task that cannot be solved by existing test-time defending methods. Simply applying test-time image transformations~\cite{gao2019strip,sarkar2020backdoor,qiu2021deepsweep} without model retraining compromises the model's accuracy on clean inputs~\cite{sarkar2020facehack}. Heuristic trigger search in image space~\cite{udeshi2022model} does not scale to complex triggers or high image resolution.

To address the challenging task, we resort to the strong reconstruction power of modern image generation models. Intuitively, powerful generation models can reconstruct the original clean image when the trigger is masked. By comparing model predictions on the original and reconstructed images, we can locate the trigger if it exists. We propose a novel method called \emph{Blind Defense with Masked AutoEncoder} (BDMAE). Masked Autoencoders~\cite{he2022masked} are scalable self-supervised learners. It randomly masks patches from the input image and reconstructs the missing parts. Even using a high masking ratio (\eg, 75\%), the semantic content can still be recovered. In our method, we repeatedly mask out specific regions of each test image that possibly contain triggers, and use a generic MAE pretrained on ImageNet~\cite{deng2009imagenet} to restore the missing parts. The reconstruction power of MAE enables us to use high masking ratios without changing the image semantic content. The dissimilarity in image structure between original images and MAE restorations may also indicate the existence of triggers. Since we use the generic MAE, it does not require additional training images for a particular test-time defense task. 

%, and meanwhile, detect whether the model is backdoor-attacked.  built upon Vision Transformer~\cite{dosovitskiy2021an}

To defense against backdoor attack, we seek a trigger-region score that measures the probability of each image patch belonging to triggers, and use MAE to restore those high-score regions. Our method includes three main stages. First, we randomly mask out the test image, and generate scores based on the image similarity and label consistency between the test image and MAE restorations. Then, we sample masks in consideration of trigger topology, and refine the scores accordingly. Finally, image restorations from adaptive score thresholds are fused into one purified image for making prediction. Our approach is blind to the network architecture, trigger patterns or image benignity. Empirical results demonstrate that BDMAE effectively sanitizes backdoored images without compromising clean images. BDMAE is generalizable to diverse trigger sizes and patterns.

Our main contributions are summarized as follows:
\begin{enumerate}[leftmargin=*,itemsep=-1mm]
\item We address the practical task of blind backdoor defense at test time, in particular for black-box models. Despite some general techniques for simple attacks, this critical task has not been formally and systematically studied.

\item We propose to leverage generic image generation models to assist backdoor defense. It may open a door to design general backdoor defense methods under limited data by exploiting abundant public foundation models. 

\item A framework of blind defense with Masked Autoencoders (BDMAE) is devised to detect possible triggers and restore images on the fly. Three key stages are delicatedly designed to generalize to different defense tasks without tuning hyper-parameters.

\item We evaluate our method on four benchmarks, Cifar10~\cite{krizhevsky2009cifar10}, GTSRB~\cite{stallkamp2012gtsrb}, ImageNet~\cite{deng2009imagenet} and VGGFace2~\cite{cao2018vggface2}. Regardless of model architectures, image resolutions or trigger patterns, our method obtains superior accuracies on both backdoored and clean images.
\end{enumerate}

% \vspace{-5mm}
\section{Related Works}
\vspace{-0mm}
\cparagraph{Backdoor attacks.}
BadNets~\cite{gu2019badnets} is the earliest work on backdoor attack. It attaches a checkerboard trigger to images and associates them with specific target labels. Many different trigger patterns are used in later works~\cite{nguyen2020IAB,turner2019lc,wenger2021backdoor}. These triggers are visible local patches in the images. Visible global triggers are used in~\cite{chen2017blended,barni2019sig}. To make the attack stealthy, invisible patterns~\cite{li2021invisible, zhong2022imperceptible,zhao2022defeat} and attacking strategies based on reflection phenomenon~\cite{liu2020reflection}, image quantization and dithering~\cite{wang2022bppattack}, style transfer~\cite{cheng2021deep} and elastic image warping~\cite{nguyen2021wanet} are proposed. Although these stealthy attacks are less perceptible to humans, they are vulnerable to noise perturbations or image transformations. To make it hard for defenders to reconstruct triggers, sample-specific backdoor attacks~\cite{li2021invisible, nguyen2020IAB} are proposed. This paper focuses on the visible triggers of local patches. The triggers can be either shared by samples or sample-specific.


\cparagraph{Backdoor defense.}
Backdoor defense aims to mitigate backdoor behaviors. The training-stage defenses attempt to design robust training mechanism via decoupling training process~\cite{huang2022backdoor}, introducing multiple gradient descent mechanism~\cite{li2021anti} or modifying linearity of trained models~\cite{wang2022training}. However, intruding the training stage is often infeasible. Model reconstruction defenses mitigate backdoor behaviors by pruning bad neurons or retraining models~\cite{liu2018fine-pruning,wang2019NC,zeng2021i-bau} using clean labeled data. A recent work shows that backdoor behaviors could be cleansed by distillation on unlabeled data or even out-of-distribution data~\cite{pang2022backdoor}. Februus~\cite{doan2020februus} is a test-time defense method. It detects triggers with GradCAM~\cite{selvaraju2017grad}, and feeds purified images to the model. 

Recently, black-box backdoor models have drawn increasing attention~\cite{dong2021black,guoaeva,zhang2021tad}. In this setting, the detailed model parameters are concealed due to concerns on data privacy or intellectual property. Some black-box backdoor detection methods~\cite{chen2019deepinspect,dong2021black,guoaeva} have been proposed. These works focus on identifying backdoored models, and usually reject predictions for such situations. Differently, we handle the task of blind backdoor defense at test time. The goal is to obtain true label of every test image on the fly, with only access to the hard-label predictions of that image. Test-time image transformations~\cite{gao2019strip,sarkar2020backdoor,qiu2021deepsweep} and heuristic trigger search in image space~\cite{udeshi2022model} do not work well. 

%We handle this by detecting triggers and restoring images with generic Masked Autoencoders~\cite{he2022masked}.

%DeepInspect~\cite{chen2019deepinspect} uses a generative model to learn distribution of possible triggers, though it still requires model gradients. B3D~\cite{dong2021black} proposes a gradient-free optimization algorithm to reverse-engineer potential triggers from predictive confidence scores. AEVA~\cite{guoaeva} utilizes adversarial singularity phenomenon to detect backdoor model from hard labels. 

\cparagraph{Masked autoencoder.}
Masked Autoencoders (MAE)~\cite{he2022masked} are scalable self-supervised learners based on Vision Transformer~\cite{dosovitskiy2021an}. It masks random patches of the input image, and restore the missing pixels. MAE has been used in many vision tasks~\cite{bachmann2022multimae,pang2022masked,tong2022videomae}. Motivated by the powerful and robust data generation ability, for the first time we leverage MAE to detect triggers and restore images. Our work can be extended to many other generative models~\cite{xie2022simmim,chen2022sdae,li2022uniform}.











\begin{figure}[!t]
	\centering	
	\includegraphics[width=\linewidth]{fig-png/framework.pdf}
 \vspace{-6mm}
	\caption{Framework of our method. For every test image, we generate the trigger-region score and refine it by considering the topology of triggers. The purified image obtained from adaptive restorations is used for making prediction.} 
	\label{fig:frame}
 \vspace{-4mm}
\end{figure}


\section{Methodology}
\vspace{-1mm}
We first formulate the backdoor attack and defense problems. Then we detail the proposed method of \emph{Blind Defense with Masked AutoEncoder} (BDMAE), including three key stages. The framework is illustrated in Fig.~\ref{fig:frame}. At a high level, our main idea is to seek a purified version of every test image for making prediction. We efficiently detect possible triggers with the help of MAE and restore missing parts.

\subsection{Problem Formulation}
\vspace{-1mm}
Denote the set of clean images as $D=\{(\x,y)\}$. An adversary generates a set of backdoored images $\tilde{D}=\{(\Phi{(\x)}, \eta{(y)})|(\x,y)\in D\}$, where $\Phi(\cdot)$ transforms a clean image into a backdoored image and $\eta(\cdot)$ transforms its ground truth label into a target label. We consider the popular formulation of $\Phi(\x)=(1-\m)\odot \x + \m\odot \bm{\theta}$, where $\bm{m}$ is a binary mask, $\bm{\theta}$ is the backdoor trigger and $\odot$ denotes the Hadamard product~\cite{dong2021black,hu2021trigger,zheng2021topological}. The masks and triggers may not be necessarily the same for different images. While the trigger can span over the entire image, this work only focuses on triggers formed from local patches. A prediction model $f$ is trained on clean images and backdoored images until it makes correct predictions on clean images but makes abnormal predictions on images with triggers. It is also possible that $f$ is trained on clean images only.

At test time, the suspicious model $f$ is provided as black-box and only its hard label predictions are accessible. The true label of every test image needs to be recovered on the fly, without accessing additional data. For every test image $\x$, we seek a purified version $\iota(\x)$ such that $\iota(\x)$ does not contain backdoor triggers and $f(\iota(\x))$ gives the correct label prediction. The test process is blind to the model or images, meaning that there is no information on whether $f$ is backdoored and whether $\x$ contains triggers. The goal is to achieve high classification accuracies on all test images, and thus low attack success rate on triggered images. 


\begin{figure}[t]
\vspace{-2mm}
\begin{algorithm}[H]
	\renewcommand{\algorithmicrequire}{\textbf{Input:}}
	\renewcommand{\algorithmicensure}{\textbf{Output:}}
	\caption{Trigger-region Score Generation} 
	\label{alg: triggerGen} 
	\begin{algorithmic}[1]
		\Require Prediction model $f$, test image $\x$, generic MAE model $G$, repeated times $N_o$, $N_i$.
		\Ensure Trigger-region scores $S^{i}$, $S^{l}$
		\State Get original hard-label prediction $\hat{y}=f(\x)$		
		\For {$o=0$ \textbf{to} $N_o$}
		\For {$i=0$ \textbf{to} $N_i$}
		\State Uniformly sample random token mask $\m_{o,i}$
		\State Get MAE reconstruction $\{\tilde{\x}_{o,i}\}$ and the corresponding masks $\{\tilde{\m}_{o,i}\}$ from $\tilde{G}(\x,\m_{o,i})$
		\State Get hard-label prediction $\hat{y}_{o,i}=f(\tilde{\x}_{o,i})$
		\EndFor
		\State Fuse restorations into $\tilde{\x}_{o}=\mathcal{F}(\{\tilde{\x}_{o,i}\},\{\tilde{\m}_{o,i}\})$
		\State Calculate structural similarity $I_{o}=\mathrm{SSIM}(\x, \tilde{\x}_{o})$
		\EndFor
		
		\State $S^{i}=\sum_o [1-\mathcal{I}(I_{o};14,14)]/N_{o}$
		\State $S^{l}=\sum_{o,i}[\m_{o,i}\times(1-\llbracket\hat{y}=\hat{y}_{o,i} \rrbracket )]/(N_o N_i)$
	\end{algorithmic}
\end{algorithm}
\vspace{-8mm}
\end{figure}

\subsection{Trigger-region Score Generation}
\vspace{-1mm}
For clarity, we assume that $f$ is backdoored and the test image $\x$ contains triggers. Our method can directly apply to clean models or clean images (\textit{c.r.} Sec.\ref{sec:clean}). Let $\hat{y}=f(\x)$ be its original label prediction. To infer the trigger mask $\m$, one can repeatedly block a particular part of the image and observe how model predictions change~\cite{udeshi2022model}. However, the search space is huge for a normal image resolution. Even worse, when the trigger is complex (\eg, of irregular shape), the model may still predict the target label when parts of the trigger remain in the image. These issues make the na\"ive trigger search method infeasible in practice.  
 
We overcome the above-mentioned issues by leveraging generic Masked AutoEncoder (MAE)~\cite{he2022masked}. In MAE, each token corresponds to a square patch of the image. MAE can recover the image content even when 75\% tokens are masked out. This brings two benefits: 1) we can safely use a high masking ratio to remove triggers without changing the semantic label; 2) since triggers are irrelevant to the content, they will unlikely present in the MAE restorations. To locate triggers, there are two complementary approaches:

\cparagraph{\textbullet\ Image-base:} comparing the structural similarity between the original image and MAE restorations.

\cparagraph{\textbullet\ Label-base:} comparing the consistency of label predictions on the original image and MAE restorations. 

Now we formulate their procedures. Let $H$ and $W$ be the height and width of the test image $\x$. We define a universal function $\mathcal{I}(\z;h,w)$ that maps a tensor $\z$ to the size of $h\times w$ by interpolation. Our goal is to obtain a trigger-region score $S\in[0,1]^{14\times 14}$ that has higher values for trigger regions and lower values for clean regions. Note that each score corresponds to a token, \ie, an image patch. This reduces the search space compared with trigger score of image size. 

%To avoid confusion, we use a superscript $^T$ for any tensor of $14\times 14$, and blank superscript for $H\times W$. 

Before going to the method, we describe how to restore $\x$ given a token mask $\m$ and a Masked Autoencoder $G$. Shown in Eq.~\ref{eq:MAE}, $\x$ is first resized to 224$\times$224. Then we use $G$ to reconstruct the image, and resize it back to $H\times W$. The restoration $\tilde{\x}$ is generated at the image size, with a purpose  to avoid interpolation errors in the unmasked regions.

\begin{equation}\label{eq:MAE}
	\begin{aligned}
		& \bar{\x}=\mathcal{I}(G(\mathcal{I}(\x;224,224);\m);H,W) \\
		& \tilde{\m}=\mathcal{I}(\m;H,W) \\
		& \tilde{\x} = \x\odot (1-\tilde{\m})+ \bar{\x}\odot \tilde{\m} \\
		& \tilde{G}(\x,\m)\triangleq (\tilde{\x},\tilde{\m})
	\end{aligned}
\end{equation}


Algorithm~\ref{alg: triggerGen} describes the procedure to generate trigger-region scores, $S^{i}$ and $S^{l}$. Given the test image $\x$, we first get its original hard-label prediction $\hat{y}=f(\x)$. Then we uniformly sample $N_i$ random token masks $\{\m_{o,i}\in\{0,1\}^{14\times 14}$\}, and get the MAE reconstructions $\{\tilde{\x}_{o,i}\}$, masks $\{\tilde{\m}_{o,i}\}$ from $ \tilde{G}(\x,\m_{o,i})$. The hard-label predictions $\{\hat{y}_{o,i}=f(\tilde{\x}_{o,i})\}$ are obtained. We use a default masking ratio of 75\% when sampling $\{\m_{o,i}\}$. Since tokens are uniformly masked, it is possible that partial triggers remain in $\{\tilde{\x}_{o,i}\}$. To handle this, we fuse $N_i$ restorations into $\tilde{\x}_o$ by:
\begin{equation}
	\mathcal{F}\big(\{\tilde{\x}_{o,i}\},\{\tilde{\m}_{o,i}\}\big)=\sum_i (\tilde{\x}_{o,i}\odot \tilde{\m}_{o,i})	\oslash \sum_i (\tilde{\m}_{o,i}) 	
\end{equation}
where $\oslash$ is element-wise division. The idea is to only use patches from MAE restorations, and discard those from the original image. We manipulate the sampling of $\{\m_{o,i}\}$ to guarantee that every image location can be recovered.

To calculate the similarity between $\tilde{\x}_o$ and $\x$, we use Structural Similarity Index Measure (SSIM)~\cite{wang2004image}. Its score lies between -1 and 1. As triggers are irrelevant to contents and will unlikely present in $\tilde{\x}_o$, SSIM scores in the trigger region will be low. In contrast, the clean regions will be well restored, leading to high SSIM scores. We resize the SSIM score, convert it to negative form, and average over $N_o$ times to get the image-based trigger score $S^{i}$. For the label-based trigger score $S^{l}$, we simply average over token masks that lead to different label predictions. $\llbracket P \rrbracket$ is 1 if $P$ is true and 0 otherwise. The inconsistency usually implies that triggers  have been removed by the masks. $S^{i}$ favors large and complex triggers, while $S^{l}$ favors small triggers. Combining both adapts to diverse trigger patterns. 

\begin{figure}[t]
\vspace{-2mm}
\begin{algorithm}[H]
	\renewcommand{\algorithmicrequire}{\textbf{Input:}}
	\renewcommand{\algorithmicensure}{\textbf{Output:}}
	\caption{Topology-aware Score Refinement} 
	\label{alg: triggerRefine} 
	\begin{algorithmic}[1]
		\Require Prediction model $f$, test image $\x$, generic MAE model $G$, repeated times $N_r$, initial trigger-region score $S^{*}$, mask $\m_{\rm rf}$ for tokens to be refined, $\beta_0=0.05$.
		\Ensure Refined trigger-region score $S^{*}$.
		\State Get original hard-label prediction $\hat{y}=f(\x)$		
		\For {$r=0$ \textbf{to} $N_r$}
		\State Generate a topology-aware token mask $\m_{r}$
		\State $\bar{\m}_{r}=\m_{\rm rf}-\m_{r}$
		\State Get MAE reconstruction $\tilde{\x}_{r}$ from $\tilde{G}(\x,\m_{r})$
		\State Get hard-label prediction $\hat{y}_{r}=f(\tilde{\x}_{r})$ 
		\State $\beta=(1-2\llbracket \hat{y}=\hat{y}_{r}  \rrbracket)\times \beta_0$
		\State $S^{*}\leftarrow S^{*}+\beta\times(\m_{r}-\bar{\m}_{r})$		
		\EndFor
	\end{algorithmic}
\end{algorithm}
\vspace{-9mm}
\end{figure}

\renewcommand{\tabcolsep}{0.1cm}
\begin{table*}[!t]
\caption{Defense results on \texttt{Cifar10} and \texttt{GSTRB} using various sizes of color/white triggers.}
\vspace{-6mm}
	\begin{center}
		\scriptsize
		\begin{tabular}{p{0.4cm}<{\centering}p{0.8cm}<{\centering}p{2.1cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}}
			\toprule
			\multirow{3}{*}{} & & & \multicolumn{3}{c|}{1$\times$1-color} & \multicolumn{3}{c|}{1$\times$1-white} & \multicolumn{3}{c|}{2$\times$2-color} & \multicolumn{3}{c|}{2$\times$2-white} & \multicolumn{3}{c|}{3$\times$3-color} & \multicolumn{3}{c}{3$\times$3-white} \\
			\cmidrule{4-21}	
			& & & ACC$_c$ & ACC$_b$ & ASR & ACC$_c$ & ACC$_b$ & ASR & ACC$_c$ & ACC$_b$ & ASR & ACC$_c$ & ACC$_b$ & ASR & ACC$_c$ & ACC$_b$ & ASR & ACC$_c$ & ACC$_b$ & ASR\\
			\midrule
		\multirow{7}{*}{\rotatebox{90}{\texttt{Cifar10}}} &	\multicolumn{2}{c|}{Before Defense} & 93.66 & 0.05 & 99.95 & 92.86 & 2.33 & 97.53 & 93.23 & 0.0 & 100.0 & 93.12 & 2.75 & 97.12 & 93.71 & 0.00 & 100.0 & 93.39 & 0.48 & 99.46\\
			\cmidrule{2-21}	
			& \multirow{2}{*}{Februus} & XGradCAM & 92.03 & 85.71 & 7.80 & 91.09 & 80.74 & 13.74 & 91.32 & 93.07 & 0.79 & 91.21 & 92.58 & 1.22 & 92.15 & 92.91 & 0.99 & 91.62 & 77.08 & 17.72\\
			&  & GradCAM++  & 85.14 & 90.82 & 2.41 & 84.66 & 83.62 & 10.36 & 85.70 & 93.06 & 0.78 & 84.91 & 92.03 & 1.45 & 85.46 & 92.98 & 0.87 & 75.01 & 87.09 & 6.59\\
			\cmidrule{2-21}	
			& \multirow{4}{*}{Ours} & Base-$i$ &  92.55 & 73.41 & 20.03 & 91.38 & 86.41 & 6.39 & 92.07 & 90.98 & 1.14 & 91.77 & 84.21 & 8.36 & 92.41 & 90.13 & 2.85 & 92.05 & 84.11 & 8.13\\
			&  & Base-$l$ &  92.12 & 90.97 & 0.51 & 90.61 & 90.36 & 1.41 & 91.57 & 91.38 & 0.86 & 91.15 & 90.07 & 1.49 & 92.13 & 90.99 & 1.70 & 91.55 & 90.21 & 0.84\\
			&  & Base & 92.96 & 90.71 & 0.56 & 91.78 & 90.26 & 1.50 & 92.50 & 91.50 & 0.47 & 92.25 & 89.97 & 1.50 & 92.94 & 92.10 & 0.53 & 92.59 & 90.49 & 0.78\\
		& 	& Large  & 93.13 & 90.78 & 0.60 & 91.97 & 90.59 & 1.36 & 92.73 & 91.75 & 0.45 & 92.45 & 90.36 & 1.30 & 93.13 & 92.30 & 0.48 & 92.68 & 90.87 & 0.76\\	
           \midrule
           \midrule
		\multirow{7}{*}{\rotatebox{90}{\texttt{GTSRB}}} &	\multicolumn{2}{c|}{Before Defense} & 98.72 & 0.00 & 100.0 & 97.96 & 2.33 & 97.52 & 98.31 & 0.00 & 100.0 & 98.55 & 4.39 & 95.51 & 98.77 & 0.00 & 100.0 & 98.37 & 1.38 & 98.47\\
			\cmidrule{2-21}	
			& \multirow{2}{*}{Februus} & XGradCAM  & 85.15 & 22.87 & 74.62 & 84.83 & 59.05 & 38.11 & 74.78 & 47.39 & 41.93 & 56.95 & 40.32 & 52.72 & 74.84 & 77.04 & 16.32 & 69.75 & 25.97 & 66.23\\
		  &	& GradCAM++  & 80.31 & 40.77 & 50.78 & 81.77 & 90.98 & 6.23 & 64.83 & 46.72 & 44.45 & 65.46 & 79.22 & 18.42 & 64.71 & 89.08 & 4.33 & 68.14 & 63.18 & 29.19\\
			\cmidrule{2-21}	
		  &	\multirow{4}{*}{Ours} & Base-$i$ &  96.99 & 70.46 & 23.49 & 96.26 & 93.34 & 4.61 & 96.55 & 96.51 & 1.68 & 96.80 & 87.63 & 10.71 & 97.05 & 92.75 & 5.90 & 96.75 & 78.27 & 16.17\\
		   &	& Base-$l$ & 97.76 & 94.00 & 0.06 & 96.60 & 95.04 & 1.06 & 97.13 & 96.84 & 0.54 & 97.25 & 94.84 & 2.48 & 97.79 & 96.51 & 1.48 & 97.31 & 92.24 & 2.41\\
		  &	& Base & 98.55 & 92.38 & 0.18 & 97.62 & 95.91 & 0.98 & 98.03 & 97.80 & 0.06 & 98.27 & 96.49 & 1.31 & 98.62 & 98.31 & 0.09 & 98.14 & 91.00 & 2.85\\
	    	&	& Large & 98.68 & 94.73 & 0.18 & 97.93 & 96.26 & 0.88 & 98.28 & 98.00 & 0.07 & 98.49 & 96.59 & 1.50 & 98.75 & 98.28 & 0.19 & 98.32 & 91.81 & 2.87\\
			\bottomrule
		\end{tabular}
	\end{center}
 \vspace{-7mm}
	\label{tab:cifar10_gtsrb-white-color}
\end{table*}

\vspace{-2mm}
\subsection{Topology-aware Score Refinement}
\vspace{-1mm}
The trigger scores $S^{i}$ and $S^{l}$ obtained previously have relatively higher values for trigger regions. However, they are very noisy since token masks are uniformly sampled without considering the trigger patterns. Meanwhile, the contrast between trigger regions and clean regions are not significant, making it hard to determinate a threshold. 

We utilize the topology of triggers to refine scores. The procedure is summarized in Alg.~\ref{alg: triggerRefine}. Note that backdoor triggers are commonly continuous~\cite{hu2021trigger}. We can exploit current trigger scores to generate token masks that cover trigger regions more precisely and reduce the score of clean regions. Denote $S^{*}$ as either $S^{i}$ or $S^{l}$. Not all scores need to be refined. We only focus on the top $L$ tokens that likely contain triggers, with $L=\mathrm{sum}(\llbracket S^{i}\geq 0.2 \rrbracket)$ or $L=\mathrm{sum}(S^{l})$. We define a mask $\m_{\rm rf}$ to indicate the $L$ tokens to be refined.

% The purpose is to deal with clean images or clean models. In such cases, the initialized trigger-region scores tend to be small, and increasing the contrast may even hurt the performances.  Then we repeatedly sample token masks to refine $S^{T,*}$.

To generate a topology-aware token mask $\m_r$, we sequentially select tokens that have higher trigger scores or are adjacent to already selected tokens. Specifically, we start with token $t_0$ with the highest score and initialize $\mathcal{T}=\{t_0\}$. Then we repeatedly choose $t_i=\arg\max_{t_k} (S^{*}[t_k]+0.5\llbracket t_k \in \textrm{Adj}(\mathcal{T}) \rrbracket )\cdot \sigma_{k} $ and add it to $\mathcal{T}$, where $\textrm{Adj}(\mathcal{T})$ includes all 4-nearest neighbors of tokens in $\mathcal{T}$ and $\sigma_{k}\sim U(0,1)$ is a random variable. It achieves a balance between random exploration and topology-aware exploitation. This process continues until $|\mathcal{T}|=L/2$. Given $\m_r$ from $\mathcal{T}$, we get its complementary part $\bar{\m}_{r}=\m_{\rm rf}-\m_{r}$. Then we obtain the hard-label prediction $\hat{y}_r$ of MAE restoration based on $\m_r$. If $\hat{y}_r\neq \hat{y}$, we increase $S^{*}$  by a constant $\beta_0$ for tokens masked by $\m_r$, and decrease $S^{*}$ by $\beta_0$ for tokens masked by $\bar{\m}_{r}$; otherwise, we modify $S^{*}$ in an opposite way. Since $\|\m_r\|_0=\|\bar{\m}_{r}\|_0=L/2$, the average value of $S^{*}$ keeps unchanged, but the contrast in values between trigger region and clean region are increased.



\vspace{-0.5mm}
\subsection{Adaptive Image Restoration}
\vspace{-0.5mm}
Given the refined scores $S^{i}$ and $S^{l}$, we simply average them to get the final score $S=(S^{i}+S^{l})/2$. Then we can set a threshold $\tau$ to convert the score into a binary mask $\m=\llbracket S\geq \tau  \rrbracket$, and get the corresponding MAE restoration for making prediction. In practice, the optimal thresholds vary to different triggers and test images. It is difficult to select a threshold based on a single test image. To overcome this, we propose an adaptive mechanism.

The idea is to fuse restorations from $K$ multiple thresholds, $\{\tau_1\geq \tau_2\geq \cdots\geq\tau_K\}$. These decreasing thresholds lead to a nested structure of resulting masks. We obtain the corresponding MAE restorations $\{\tilde{\x}_{\tau_k},\tilde{\m}_{\tau_k}=\tilde{G}(\x,\llbracket S\geq \tau_k  \rrbracket)\}$, and then fuse them into one purified image $\iota(\x)=\mathcal{F}(\{\tilde{\x}_{\tau_k}\},\{\tilde{\m}_{\tau_k}\})$. The default thresholds used in our work is $\{0.6,0.55,0.5,0.45,0.4\}$. We observe that in datasets of high resolution like ImageNet10, the values of $S$ tend to be higher, thus $0.4$ would be too small. To adapt to different datasets automatically, we calculate $\mathrm{avg}(\llbracket S\geq \tau_K  \rrbracket)$ and increase all thresholds by a small factor until this quantity is not greater than 25\%. The rationale is that trigger regions should not dominate the image. The model prediction $f(\iota(\x))$ is used for evaluation. 

%Using $\tau_1$ removes the least number of tokens while using $\tau_K$ removes the most number of tokens. 

\subsection{Generalization to Clean Images and Models}\label{sec:clean}
Until now, we assume that both $f$ and $\x$ are backdoored. In practice, we are dealing with blind defense, meaning that both models and images can be either backdoored or clean. Our method can directly apply to any of these situations, thanks to the dedicated designs. In the trigger score generation stage, if $\x$ is clean, the MAE restorations are similar to the original image. This implies that the values of $S^{i}$ will be small. The values of $S^{l}$ will also be small since the label prediction is unlikely to change. The same results when $f$ is clean. In the score refinement stage, only the top $L$ tokens are affected and $L$ is small in the situation of clean images or models. In the image restoration stage, the predefined thresholds allow the image content to be preserved. The restored parts are either trigger regions or some content-irrelevant regions. Therefore, the model can still make correct label prediction on the purified image $\iota(\x)$.


\renewcommand{\tabcolsep}{0.1cm}
\begin{table*}[!t]
\caption{Defense results on \texttt{ImageNet} using various types of triggers ($^\dagger$without adaptive thresholds adjustment).}
\vspace{-6mm}
	\begin{center}
		\scriptsize
		\begin{tabular}{p{0.4cm}<{\centering}p{1.6cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}}
			\toprule
			\multirow{3}{*}{} & & \multicolumn{3}{c|}{1$\times$1-color} & \multicolumn{3}{c|}{2$\times$2-color} & \multicolumn{3}{c|}{3$\times$3-color} & \multicolumn{3}{c|}{Trigger ` \begin{minipage}{0.02\linewidth}	\includegraphics[width=\linewidth]{fig-png/watermelon_small.png}
				\end{minipage} '
			} & \multicolumn{3}{c|}{Trigger ` \begin{minipage}{0.02\linewidth}	\includegraphics[width=\linewidth]{fig-png/monitor.png} \end{minipage} '
			}
			& \multicolumn{3}{c}{Trigger ` \begin{minipage}{0.02\linewidth}	\includegraphics[width=\linewidth]{fig-png/umbrella.png} \end{minipage} '
			} \\
			\cmidrule{3-20}	
			& & ACC$_c$ & ACC$_b$ & ASR & ACC$_c$ & ACC$_b$ & ASR & ACC$_c$ & ACC$_b$ & ASR & ACC$_c$ & ACC$_b$ & ASR & ACC$_c$ & ACC$_b$ & ASR & ACC$_c$ & ACC$_b$ & ASR\\
			\midrule
			\multicolumn{2}{c|}{Before Defense} & 83.93 & 62.00 & 28.84 & 85.60 & 7.94 & 91.37 & 85.91 & 2.14 & 97.65 & 86.36 & 0.00 & 100.0 & 85.86 & 0.32 & 99.68 & 85.89 & 0.06 & 99.94\\	
			\midrule
			\multirow{4}{*}{Ours$^\dagger$} & Base &  65.07 & 60.11 & 14.33 & 70.80 & 70.08 & 5.00 & 72.79 & 71.97 & 2.13 & 72.77 & 73.89 & 1.56 & 72.67 & 67.06 & 1.76 & 72.97 & 72.89 & 1.56\\
			& Large-$i$ &  66.07 & 57.84 & 19.56 & 69.74 & 53.83 & 33.27 & 70.96 & 57.10 & 27.90 & 70.83 & 66.22 & 12.79 & 71.33 & 66.40 & 11.65 & 70.87 & 63.38 & 16.00\\
			& Large-$l$ & 80.23 & 75.94 & 8.22 & 83.13 & 78.51 & 5.43 & 83.54 & 81.49 & 2.08 & 83.57 & 84.84 & 0.97 & 83.46 & 81.60 & 0.98 & 83.71 & 83.46 & 1.17\\
			& Large & 76.57 & 70.95 & 10.35 & 79.07 & 75.02 & 5.00 & 80.34 & 77.54 & 2.02 & 80.86 & 77.83 & 1.32 & 81.04 & 72.17 & 1.78 & 81.31 & 76.60 & 1.38\\	
			\midrule
			\multirow{4}{*}{Ours} & Base  & 74.94 & 69.70 & 11.90 & 78.19 & 78.86 & 5.08 & 79.61 & 81.48 & 1.95 & 79.76 & 81.49 & 1.71 & 79.70 & 80.43 & 1.40 & 79.44 & 80.68 & 1.44\\
			& Large-$i$  & 77.99 & 67.06 & 19.08 & 80.29 & 48.63 & 43.75 & 81.04 & 51.57 & 39.87 & 80.39 & 59.22 & 28.49 & 81.07 & 64.16 & 20.68 & 80.76 & 55.90 & 31.43\\
			& Large-$l$  & 80.26 & 76.17 & 8.13 & 83.14 & 79.33 & 5.40 & 83.53 & 82.35 & 2.06 & 83.59 & 84.86 & 0.97 & 83.46 & 81.92 & 0.98 & 83.71 & 83.51 & 1.14\\
			& Large & 79.10 & 74.78 & 9.10 & 81.07 & 80.24 & 5.19 & 82.13 & 83.13 & 1.79 & 82.80 & 83.52 & 1.43 & 82.56 & 81.70 & 1.43 & 83.04 & 82.59 & 1.48\\	
			\bottomrule
		\end{tabular}
	\end{center}
	\label{tab:imagenet}
 \vspace{-4mm}
\end{table*}


\renewcommand{\tabcolsep}{0.1cm}
\begin{table*}[!t]
\caption{Defense results on \texttt{VGGFace2} using various types of triggers.}
\vspace{-6mm}
	\begin{center}
		\scriptsize
		\begin{tabular}{p{1.2cm}<{\centering}p{0.6cm}<{\centering}p{2.5cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}}
			\toprule
			\multirow{3}{*}{} & & & \multicolumn{3}{c|}{Trigger ` \begin{minipage}{0.02\linewidth}	\includegraphics[width=\linewidth]{fig-png/instagram.png} \end{minipage} '} & \multicolumn{3}{c|}{Trigger ` \begin{minipage}{0.02\linewidth}	\includegraphics[width=\linewidth]{fig-png/linkedin.png} \end{minipage} '} & \multicolumn{3}{c|}{Trigger ` \begin{minipage}{0.02\linewidth}	\includegraphics[width=\linewidth]{fig-png/pinterest.png} \end{minipage} '} & \multicolumn{3}{c|}{Trigger ` \begin{minipage}{0.02\linewidth}	\includegraphics[width=\linewidth]{fig-png/twitter.png} \end{minipage} '} & \multicolumn{3}{c}{Trigger ` \begin{minipage}{0.02\linewidth}	\includegraphics[width=\linewidth]{fig-png/wechat.png} \end{minipage} '}  \\
			\cmidrule{4-18}
			& & & ACC$_c$ & ACC$_b$ & ASR & ACC$_c$ & ACC$_b$ & ASR & ACC$_c$ & ACC$_b$ & ASR & ACC$_c$ & ACC$_b$ & ASR & ACC$_c$ & ACC$_b$ & ASR \\
			\midrule
			\multirow{7}{*}{VGG16} & \multicolumn{2}{c|}{Before Defense} & 91.74 & 0.00 & 100.0 & 91.58 & 0.02 & 99.98 & 91.38 & 0.00 & 100.0 & 91.54 & 0.05 & 99.95 & 91.60 & 0.00 & 100.0\\
			\cmidrule{2-18}
			& \multirow{2}{*}{Februus} & XGradCAM  & 78.89 & 44.02 & 52.11 & 79.65 & 87.85 & 4.45 & 80.70 & 89.47 & 2.08 & 86.52 & 90.40 & 1.47 & 79.95 & 71.98 & 22.57\\
			& & GradCAM++  & 72.60 & 75.80 & 18.37 & 83.91 & 84.12 & 8.91 & 85.10 & 90.23 & 1.27 & 75.17 & 91.57 & 0.08 & 75.47 & 62.25 & 32.80\\
			\cmidrule{2-18}
			& \multirow{4}{*}{Ours} & Base & 83.61 & 85.30 & 5.41 & 83.79 & 86.86 & 1.54 & 83.42 & 87.84 & 0.27 & 84.07 & 88.22 & 0.14 & 83.75 & 76.43 & 15.84\\
			& & Large-$i$  & 84.86 & 53.14 & 41.63 & 84.50 & 76.21 & 15.12 & 84.91 & 74.20 & 17.22 & 84.94 & 65.96 & 25.94 & 84.60 & 42.60 & 53.38\\
			& & Large-$l$  & 81.86 & 85.82 & 5.04 & 82.04 & 87.15 & 1.14 & 81.64 & 87.74 & 0.11 & 82.21 & 87.68 & 0.11 & 81.72 & 79.57 & 11.97\\
			& & Large  & 85.49 & 85.06 & 5.71 & 85.47 & 87.49 & 1.31 & 85.19 & 88.31 & 0.22 & 85.85 & 88.82 & 0.09 & 85.57 & 80.79 & 10.82\\
			\midrule
			\multirow{7}{*}{ResNet18} & \multicolumn{2}{c|}{Before Defense} & 94.12 & 0.00 & 100.0 & 94.03 & 0.00 & 100.0 & 93.98 & 0.00 & 100.0 & 94.04 & 0.04 & 99.96 & 94.17 & 0.01 & 99.99\\
			\cmidrule{2-18}
			& \multirow{2}{*}{Februus} & XGradCAM   & 57.01 & 93.90 & 0.04 & 57.20 & 93.88 & 0.03 & 58.24 & 93.92 & 0.04 & 29.36 & 93.78 & 0.13 & 28.69 & 93.82 & 0.04\\
			& & GradCAM++  & 53.71 & 93.96 & 0.04 & 54.13 & 93.87 & 0.03 & 55.08 & 93.94 & 0.03 & 27.44 & 92.86 & 1.17 & 26.06 & 93.87 & 0.04\\
			\cmidrule{2-18}
			& \multirow{4}{*}{Ours} & Base  & 87.44 & 86.57 & 6.47 & 87.64 & 90.39 & 1.28 & 87.83 & 91.17 & 0.19 & 87.85 & 91.25 & 0.07 & 87.86 & 80.94 & 13.27\\
			& & Large-$i$  & 88.98 & 56.47 & 39.29 & 88.64 & 73.49 & 20.90 & 88.82 & 85.17 & 8.12 & 88.82 & 70.80 & 23.08 & 88.95 & 40.49 & 56.84\\
			& & Large-$l$  & 87.63 & 88.90 & 4.22 & 87.72 & 90.37 & 1.02 & 87.77 & 91.14 & 0.07 & 87.81 & 91.03 & 0.09 & 87.77 & 80.70 & 13.81\\
			& & Large  & 90.44 & 87.99 & 5.34 & 90.44 & 91.10 & 1.15 & 90.37 & 91.65 & 0.23 & 90.46 & 91.83 & 0.04 & 90.43 & 78.95 & 15.67\\	
			\bottomrule
		\end{tabular}
	\end{center}
	\label{tab:vggface2}
  \vspace{-8mm}
\end{table*}

\vspace{-1mm}
\section{Experiments}
\vspace{-1mm}
% \subsection{Experiment Settings}
\vspace{-2mm}
\cparagraph{Datasets.}
We evaluate our method on \texttt{Cifar10}, \texttt{GTSRB}, \texttt{ImageNet10} and \texttt{VGGFace2}. \texttt{Cifar10} is a 10-class scene classification dataset of image  size 32$\times$32~\cite{krizhevsky2009cifar10}. \texttt{GTSRB} consists of 43-class traffic signs images of size 32$\times$32~\cite{stallkamp2012gtsrb}. \texttt{ImageNet10} is a 10-class subset of \texttt{ImageNet}~\cite{deng2009imagenet}, resized to 224$\times$224. For the face recognition dataset \texttt{VGGFace2}~\cite{cao2018vggface2}, we use images from 170 randomly selected classes~\cite{doan2020februus}, and resize them to 224$\times$224.

\cparagraph{Backdoor attacks settings.} We use BadNet~\cite{gu2019badnets} with different triggers, Label-Consistent backdoor attack (LC)~\cite{turner2019lc} and Input-Aware dynamic Backdoor attack (IAB)~\cite{nguyen2020IAB} to build backdoored models. For each setting, we report results averaged over 14 random target labels or initializations. The default network architecture is ResNet18~\cite{he2016resnet}. We also conduct experiments with VGG16~\cite{simonyan2014very} and a shallow convolutional network from~\cite{doan2020februus}. For \texttt{Cifar10} and \texttt{GTSRB}, models are trained from scratch. For the rest two datasets, models are pretrained on ImageNet~\cite{deng2009imagenet}.

\cparagraph{Method configurations.} Our method is training-free. We use the publicly available Masked Autoencoders~\cite{he2022masked} pretrained on ImageNet to assist blind defense. The \texttt{Base} variant has 12 encoder layers, and the \texttt{Large} variant has 24 encoder layers with an increased hidden size dimension. The same hyper-parameters are used for all experiments. Besides full method, we present results of two ablative variants: \texttt{Ours}-$i$ using $S^{i}$ only, and \texttt{Ours}-$l$ using $S^{l}$ only.

\cparagraph{Baseline methods.} Methods based on test-time image transformations~\cite{gao2019strip,sarkar2020backdoor,qiu2021deepsweep} compromise accuracies unacceptably in our setting. We therefore compare with a representative white-box method, Februus~\cite{doan2020februus}. It detects possible triggers with GradCAM~\cite{selvaraju2017grad}, and trains GAN models to restore missing regions. We find that GradCAM does not generalize to complex networks, thus we replace it with two improved methods, XGradCAM~\cite{fu2020axiom} and GradCAM++~\cite{chattopadhay2018grad}. The choice of visualization score threshold in Februus is critical. We try with $\{0.6, 0.7, 0.8\}$ and report the best result for each attack setting individually. We use the GAN models released by the authors for image restoration.  

\cparagraph{Evaluation metrics} include the classification accuracy on clean images (ACC$_c$) and backdoored images (ACC$_b$), as well as attack success rate (ASR).


\vspace{-1mm}
\subsection{Main Results}
\vspace{-1mm}
\cparagraph{Cifar10 and GTSRB.} From Table~\ref{tab:cifar10_gtsrb-white-color}, models have high ACC$_c$, low ACC$_b$ and high ASR before defense. The baseline method Februus works on some attack settings such as \texttt{Cifar10} with $2\times 2$-color trigger, but fails on many others, especially on \texttt{GTSRB}. The reason is that images of \texttt{Cifar10} and \texttt{GTSRB} are of size 32$\times$32. The layer for visualization has a low resolution, making it hard to precisely locate triggers. The performance is also affected by the visualization method. Generally, GradCAM++ uses second-order information, and works better than XGradCAM. The ACC$_c$ of Februus is low because the attended regions on clean images contain contents. Our methods work consistently well on all attack settings. The ACC$_b$ on purified backdoored images are close to the clean accuracy, indicating that triggers have been successfully detected and removed. ACC$_c$ on clean images drops negligibly. Using \texttt{MAE-Large} leads to slightly higher accuracies due to better restorations. Comparing the two variants, \texttt{Base-$i$} does not perform well on small or white triggers as it is hard to detect triggers with structural similarity in such cases. \texttt{Base-$l$} is complementary on these attacks. The full method works for all cases. Table~\ref{tab:GTSRB-IAB-LC} shows results with IAB and LC attacks. IAB uses sample-specific irregular curves as triggers, while LC uses four distant checkerboards. Our method still achieves decent accuracies.



\begin{figure*}[!t]
	\centering	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_badnet_2by2_color_img1_orig.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_badnet_2by2_color_img1_mae_agg_rn0.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_badnet_2by2_color_img1_ssim0.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_badnet_2by2_color_img1_S1.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_badnet_2by2_color_img1_S2.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_badnet_2by2_color_img1_S1rf.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_badnet_2by2_color_img1_S2rf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_badnet_2by2_color_img1_Srf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_badnet_2by2_color_img1_mae_agg.png}
	\end{subfigure}

	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/VGGFace2_badnet_img2_org.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/VGGFace2_badnet_img2_mae_agg_rn0.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/VGGFace2_badnet_img2_ssim0.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/VGGFace2_badnet_img2_S1.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/VGGFace2_badnet_img2_S2.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/VGGFace2_badnet_img2_S1rf.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/VGGFace2_badnet_img2_S2rf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/VGGFace2_badnet_img2_Srf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig/VGGFace2_badnet_img2_mae_agg.png}
	\end{subfigure}

	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize Original image w/ trigger
	\end{minipage} 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize Restored image from rand masks 
	\end{minipage} 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize SSIM map 
	\end{minipage} 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize $S^{i}$ before refinement  
	\end{minipage} 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize $S^{l}$ before refinement 
	\end{minipage} 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize $S^{i}$ after refinement   
	\end{minipage} 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize $S^{l}$ after refinement   
	\end{minipage} 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize $S$ for final restoration  
	\end{minipage} 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize Purified image for prediction  
	\end{minipage} 

    \caption{Sampled visualizations of the defense process. (Upper row) \texttt{Cifar10} with 2$\times$2-color trigger. (Lower row) \texttt{VGGFace2} with \emph{twitter} trigger. All the scores are clipped to a range of [0,1], with yellow for high value.}\label{fig:visualization}
\end{figure*}





\begin{figure*}[!t]
	\centering
%	\begin{subfigure}{0.079\textwidth}
%	\includegraphics[width=\textwidth]{fig/cifar10_IAB_img9_orig.png}
%	\end{subfigure}
%	\begin{subfigure}{0.079\textwidth}
%		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img9_S1.png}
%	\end{subfigure}
%	\begin{subfigure}{0.079\textwidth}
%		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img9_maskfull3.png}
%	\end{subfigure}
%	\begin{subfigure}{0.079\textwidth}
%		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img9_mask3.png}
%	\end{subfigure}
%	\begin{subfigure}{0.079\textwidth}
%		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img9_S1rf3.png}
%	\end{subfigure}
%	\begin{subfigure}{0.079\textwidth}
%		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img9_maskfull6.png}
%	\end{subfigure}
%	\begin{subfigure}{0.079\textwidth}
%		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img9_mask6.png}
%	\end{subfigure}
%	\begin{subfigure}{0.079\textwidth}
%		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img9_S1rf6.png}
%	\end{subfigure}
%	\begin{subfigure}{0.079\textwidth}
%		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img9_maskfull9.png}
%	\end{subfigure}
%	\begin{subfigure}{0.079\textwidth}
%		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img9_mask9.png}
%	\end{subfigure}
%	\begin{subfigure}{0.079\textwidth}
%		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img9_S1rf9.png}
%	\end{subfigure}
%	\begin{subfigure}{0.079\textwidth}
%		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img9_mae_agg.png}
%	\end{subfigure}

	\begin{subfigure}{0.079\textwidth}
	\includegraphics[width=\textwidth]{fig/cifar10_IAB_img14_orig.png}
	\end{subfigure}
	\begin{subfigure}{0.079\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img14_S1.png}
	\end{subfigure}
	\begin{subfigure}{0.079\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img14_maskfull2.png}
	\end{subfigure}
	\begin{subfigure}{0.079\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img14_mask2.png}
	\end{subfigure}
	\begin{subfigure}{0.079\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img14_S1rf2.png}
	\end{subfigure}
	\begin{subfigure}{0.079\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img14_maskfull6.png}
	\end{subfigure}
	\begin{subfigure}{0.079\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img14_mask6.png}
	\end{subfigure}
	\begin{subfigure}{0.079\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img14_S1rf6.png}
	\end{subfigure}
	\begin{subfigure}{0.079\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img14_maskfull9.png}
	\end{subfigure}
	\begin{subfigure}{0.079\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img14_mask9.png}
	\end{subfigure}
	\begin{subfigure}{0.079\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img14_S1rf9.png}
	\end{subfigure}
	\begin{subfigure}{0.079\textwidth}
		\includegraphics[width=\textwidth]{fig/cifar10_IAB_img14_mae_agg.png}
	\end{subfigure}

	\begin{subfigure}{0.079\textwidth}
		\includegraphics[width=\textwidth]{fig/gtsrb_lc_img69_org.png}
	\end{subfigure}
	\begin{subfigure}{0.079\textwidth}
		\includegraphics[width=\textwidth]{fig/gtsrb_lc_img69_S1.png}
	\end{subfigure}
	\begin{subfigure}{0.079\textwidth}
		\includegraphics[width=\textwidth]{fig/gtsrb_lc_img69_maskfull2.png}
	\end{subfigure}
	\begin{subfigure}{0.079\textwidth}
		\includegraphics[width=\textwidth]{fig/gtsrb_lc_img69_mask2.png}
	\end{subfigure}
	\begin{subfigure}{0.079\textwidth}
		\includegraphics[width=\textwidth]{fig/gtsrb_lc_img69_S1rf2.png}
	\end{subfigure}
	\begin{subfigure}{0.079\textwidth}
		\includegraphics[width=\textwidth]{fig/gtsrb_lc_img69_maskfull6.png}
	\end{subfigure}
	\begin{subfigure}{0.079\textwidth}
		\includegraphics[width=\textwidth]{fig/gtsrb_lc_img69_mask6.png}
	\end{subfigure}
	\begin{subfigure}{0.079\textwidth}
		\includegraphics[width=\textwidth]{fig/gtsrb_lc_img69_S1rf6.png}
	\end{subfigure}
	\begin{subfigure}{0.079\textwidth}
		\includegraphics[width=\textwidth]{fig/gtsrb_lc_img69_maskfull9.png}
	\end{subfigure}
	\begin{subfigure}{0.079\textwidth}
		\includegraphics[width=\textwidth]{fig/gtsrb_lc_img69_mask9.png}
	\end{subfigure}
	\begin{subfigure}{0.079\textwidth}
		\includegraphics[width=\textwidth]{fig/gtsrb_lc_img69_S1rf9.png}
	\end{subfigure}
	\begin{subfigure}{0.079\textwidth}
		\includegraphics[width=\textwidth]{fig/gtsrb_lc_img69_mae_agg.png}
	\end{subfigure}

	\begin{minipage}{0.079\textwidth}
		\centering
		\scriptsize Original image  
	\end{minipage} 
	\begin{minipage}{0.079\textwidth}
		\centering
		\scriptsize $S^{i}$ before refinement 
	\end{minipage} 	
	\begin{minipage}{0.079\textwidth}
		\centering
		\scriptsize  $\m_{\rm rf}$ at 3rd refinement
	\end{minipage} 
	\begin{minipage}{0.079\textwidth}
		\centering
		\scriptsize  $\m_{r}$ at 3rd refinement
	\end{minipage} 
	\begin{minipage}{0.079\textwidth}
		\centering
		\scriptsize $S^{i}$ after 3 refinements 
	\end{minipage} 	
	\begin{minipage}{0.079\textwidth}
		\centering
		\scriptsize  $\m_{\rm rf}$ at 7th refinement
	\end{minipage} 
	\begin{minipage}{0.079\textwidth}
		\centering
		\scriptsize  $\m_{r}$ at 7th refinement
	\end{minipage} 
	\begin{minipage}{0.079\textwidth}
		\centering
		\scriptsize $S^{i}$ after 7 refinements 
	\end{minipage} 	
	\begin{minipage}{0.079\textwidth}
		\centering
		\scriptsize  $\m_{\rm rf}$ at 10th refinement
	\end{minipage} 
	\begin{minipage}{0.079\textwidth}
		\centering
		\scriptsize  $\m_{r}$ at 10th refinement
	\end{minipage} 
	\begin{minipage}{0.079\textwidth}
		\centering
		\scriptsize $S^{i}$ after 10 refinements 
	\end{minipage} 	
	\begin{minipage}{0.079\textwidth}
		\centering
		\scriptsize Purified image  
	\end{minipage} 

\caption{Visualizations of topology-aware score refinement. (Upper) \texttt{Cifar10} with IAB. (Lower) \texttt{GTSRB} with LC. }
\label{fig:topology}
\vspace{-4mm}
\end{figure*}


\cparagraph{ImageNet10.} Results are listed in Tab.~\ref{tab:imagenet}. Since there is no available GAN model for Februus on \texttt{ImageNet10}, we do not compare with it. \texttt{ImageNet10} has a resolution of 224$\times$224, which brings two challenges. The triggers are relatively small compared to the image size. Besides, when reconstructing images with MAE, some details like small edges may be blurred or lost. The corresponding regions thus have low SSIM scores and high $S^{i}$ values. This makes it difficult for image-based score to locate triggers. Label-based score, on the contrary, works well in such situations. Nevertheless, the full method can still handle this automatically. As shown in the table, the performances of \texttt{Large} are very close to \texttt{Large-$l$}. One key step is the adaptive thresholds adjustment.  \texttt{ImageNet10} experiments generally have higher $S$ values than those in \texttt{Cifar10} and \texttt{GTSRB}, due to the increased resolution. By increasing the thresholds used for image restoration adaptively, it avoids destruction to the content regions. 

\cparagraph{VGGFace2.} We use VGG16 and ResNet18 as the network architecture. Table~\ref{tab:vggface2} lists the results. For VGG16, the baseline method Februus obtains high ACC$_b$ on two triggers and poor scores on the rest. For ResNet18, its ACC$_b$ is pretty good, but ACC$_c$ is severely compromised. This verifies that the visualization is quite sensitive to network architecture and trigger patterns.  Our method achieves a good balance between ACC$_c$ and ACC$_b$. Similar to \texttt{ImageNet10}, \texttt{Large-$i$} fails. The full method achieves decent accuracies on both clean and backdoored images.   





\begin{figure*}[!t]
	\centering	
	\begin{subfigure}{0.256\linewidth}
	\includegraphics[width=\linewidth]{fig-plot/rp_No_a21.pdf}
	\caption{\texttt{Base}-$i$.}
	\label{fig:abl:i}
    \end{subfigure}   
	\begin{subfigure}{0.239\linewidth}
	\includegraphics[width=\linewidth]{fig-plot/rp_No_a22.pdf}
	\caption{\texttt{Base}-$l$.}
	\label{fig:abl:l}
	\end{subfigure}
	\begin{subfigure}{0.239\linewidth}
	\includegraphics[width=\linewidth]{fig-plot/rp_Nr_a3.pdf}
	\caption{Full method.}
	\label{fig:abl:rf}
    \end{subfigure}	
	\begin{subfigure}{0.235\linewidth}
	\includegraphics[width=\linewidth]{fig-plot/refine_th.pdf}
	\caption{Full method.}
	\label{fig:abl:th}
	\end{subfigure}	
  \vspace{-2mm}
	\caption{(a-c) Effects of repeated times $N_o$ and refinement times $N_r$. (d) Accuracy curves of using fix thresholds on \textcolor{red}{backdoored} and \textcolor{blue}{clean} images, before (dashed) or after (solid) refinement. Refinement enlarges the ranges of optimal thresholds.}\label{fig:abl}
 \vspace{-4mm}
\end{figure*}

\vspace{-1mm}
\section{Analysis}
\vspace{-2mm}
\cparagraph{Visualizations of defense process.} We plot images and scores in Fig.~\ref{fig:visualization}. Restored images from random masks have the same content as the original images, but are different in the trigger regions and some details. This is reflected in the SSIM map. The two trigger scores are slightly higher in the trigger region, but very noisy. After refinement, high scores concentrate on the triggers, and scores of content regions are suppressed. $S$ is then used to generate the purified images. Compared with the original backdoored images, triggers are removed while the image contents are preserved. The purified images lead to correct label predictions.


\renewcommand{\tabcolsep}{0.1cm}
\begin{table}[!t]
\caption{Results with IAB and LC attack.}
\vspace{-6mm}
	\begin{center}
		\scriptsize
		\begin{tabular}{p{0.4cm}p{0.8cm}<{\centering}p{2cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}}
			\toprule
			\multirow{3}{*}{} & & & \multicolumn{3}{c|}{IAB} & \multicolumn{3}{c}{LC}  \\
			\cmidrule{4-9}	
			& & & ACC$_c$ & ACC$_b$ & ASR & ACC$_c$ & ACC$_b$ & ASR \\
			\midrule
		\multirow{7}{*}{\rotatebox{90}{\texttt{Cifar10}}} 
  &	\multicolumn{2}{c|}{Before Defense} & 93.43 & 1.57 & 98.37 & 94.51 & 0.45 & 99.55\\
			\cmidrule{2-9}	
			& \multirow{2}{*}{Februus} & XGradCAM  & 91.69 & 29.95 & 68.15 & 92.59 & 63.74 & 33.92\\ 
			& & GradCAM++ & 77.85 & 55.78 & 35.87 & 83.29 & 85.75 & 10.42\\
			\cmidrule{2-9}
			& \multirow{4}{*}{Ours} & Base-$i$  & 92.59 & 85.76 & 5.21 & 93.39 & 94.11 & 0.36\\
			& & Base-$l$ & 92.55 & 27.37 & 70.89 & 92.90 & 71.53 & 25.55\\
			& & Base  & 92.98 & 81.79 & 10.47 & 93.74 & 94.09 & 0.42\\
			& & Large  & 93.10 & 80.00 & 12.99 & 93.93 & 94.27 & 0.40\\
               \midrule
               \midrule
		\multirow{7}{*}{\rotatebox{90}{\texttt{GTSRB}}} &	\multicolumn{2}{c|}{Before Defense}  & 98.01 & 1.25 & 98.74 & 95.75 & 5.26 & 94.74\\
			\cmidrule{2-9}	
			& \multirow{2}{*}{Februus} & XGradCAM  & 68.38 & 72.48 & 24.81 & 86.93 & 85.49 & 12.45\\
			& & GradCAM++  & 49.84 & 84.10 & 12.19 & 82.50 & 83.66 & 13.99\\
			\cmidrule{2-9}
			&  \multirow{4}{*}{Ours} & Base-$i$ & 96.41 & 80.29 & 16.82 & 93.04 & 94.86 & 1.38\\
			& & Base-$l$  & 97.09 & 45.93 & 52.73 & 91.90 & 73.83 & 24.78\\
			& & Base  & 97.84 & 76.21 & 21.44 & 93.93 & 93.56 & 2.30\\
			& & Large & 97.97 & 70.65 & 27.44 & 94.82 & 93.54 & 2.40\\
			\bottomrule
		\end{tabular} 
	\end{center}	
	\label{tab:GTSRB-IAB-LC}
 \vspace{-9mm}
\end{table}


\cparagraph{Effects of topology-aware refinement.} The topology-aware refinement is vital to the generalizability of our method. It exploits initialized scores, and generates topology-aware token masks to refine the scores. This is beneficial especially to complex triggers. In Fig.~\ref{fig:topology}, the triggers are random curves and four distant checkerboards. Before refinement, the trigger regions have relatively high scores in $S^{i}$. But the contrast between trigger regions and clean regions are not significant. For each refinement, $\m_r$ is sampled in a topology-aware manner to be continuous patches. $S^{i}$ is updated to have increased values for tokens masked by $\m_r$ and reduced values for the rest. After 10 refinements, $S^{i}$ well reflects the trigger regions. It is worth mentioning that the refinement focuses on the triggers related to backdoor behaviors. Even though the blue line remains in the purified `dog' image, the red line has been removed, thus it makes correct label prediction.

In Fig.~\ref{fig:abl:rf}, we find that $N_r=10$ is good enough for different triggers. One purpose of refinement is to increase contrast between scores of trigger regions and clean regions, so that the optimal threshold is easier to choose. In Fig.~\ref{fig:abl:th}, we randomly select three defense tasks for each dataset. Instead of fusing restorations from multiple thresholds, we choose a fixed threshold ranging from 0.1 to 0.9, and plot the accuracy curves. In each subplot, red/blue lines denote backdoored/clean images, dashed/solid lines denote before/after refinement. We can see that before refinement, the optimal thresholds have narrow ranges and vary across tasks. After refinement, they become wider. It is thus easy to set unified thresholds for different tasks.



\begin{figure}[!t]
	\centering
%\begin{subfigure}{0.075\textwidth}
%	\includegraphics[width=\textwidth]{fig/imagenet10_badnet_img64_monitor_org.png}
%\end{subfigure}
%\begin{subfigure}{0.075\textwidth}
%	\includegraphics[width=\textwidth]{fig/imagenet10_badnet_img64_monitor_Srf.png}
%\end{subfigure}
%\begin{subfigure}{0.075\textwidth}
%	\includegraphics[width=\textwidth]{fig/imagenet10_badnet_img64_monitor_mae_agg_adap.png}
%\end{subfigure}
%\begin{subfigure}{0.075\textwidth}
%	\includegraphics[width=\textwidth]{fig/imagenet10_badnet_imgc10_monitor_org.png}
%\end{subfigure}
%\begin{subfigure}{0.075\textwidth}
%	\includegraphics[width=\textwidth]{fig/imagenet10_badnet_imgc10_monitor_Srf.png}
%\end{subfigure}
%\begin{subfigure}{0.075\textwidth}
%	\includegraphics[width=\textwidth]{fig/imagenet10_badnet_imgc10_monitor_mae_agg_adap.png}
%\end{subfigure}

\begin{subfigure}{0.075\textwidth}
	\includegraphics[width=\textwidth]{fig/cifar10_badnet_3by3_color_img9_org.png}
\end{subfigure}
\begin{subfigure}{0.075\textwidth}
	\includegraphics[width=\textwidth]{fig/cifar10_badnet_3by3_color_img9_Srf.png}
\end{subfigure}
\begin{subfigure}{0.075\textwidth}
	\includegraphics[width=\textwidth]{fig/cifar10_badnet_3by3_color_img9_mae_agg_adap.png}
\end{subfigure}
\begin{subfigure}{0.075\textwidth}
	\includegraphics[width=\textwidth]{fig/cifar10_badnet_3by3_color_imgc35_org.png}
\end{subfigure}
\begin{subfigure}{0.075\textwidth}
	\includegraphics[width=\textwidth]{fig/cifar10_badnet_3by3_color_imgc35_Srf.png}
\end{subfigure}
\begin{subfigure}{0.075\textwidth}
	\includegraphics[width=\textwidth]{fig/cifar10_badnet_3by3_color_imgc35_mae_agg_adap.png}
\end{subfigure}

\begin{subfigure}{0.075\textwidth}
	\includegraphics[width=\textwidth]{fig/gtsrb_badnet_3by3_white_img28_org.png}
\end{subfigure}
\begin{subfigure}{0.075\textwidth}
	\includegraphics[width=\textwidth]{fig/gtsrb_badnet_3by3_white_img28_Srf.png}
\end{subfigure}
\begin{subfigure}{0.075\textwidth}
	\includegraphics[width=\textwidth]{fig/gtsrb_badnet_3by3_white_img28_mae_agg_adap.png}
\end{subfigure}
\begin{subfigure}{0.075\textwidth}
	\includegraphics[width=\textwidth]{fig/gtsrb_badnet_3by3_white_imgc48_org.png}
\end{subfigure}
\begin{subfigure}{0.075\textwidth}
	\includegraphics[width=\textwidth]{fig/gtsrb_badnet_3by3_white_imgc48_Srf.png}
\end{subfigure}
\begin{subfigure}{0.075\textwidth}
	\includegraphics[width=\textwidth]{fig/gtsrb_badnet_3by3_white_imgc48_mae_agg_adap.png}
\end{subfigure}

\begin{subfigure}{0.075\textwidth}
	\includegraphics[width=\textwidth]{fig/VGGFace2_badnet_img30_pinterest_org.png}
\end{subfigure}
\begin{subfigure}{0.075\textwidth}
	\includegraphics[width=\textwidth]{fig/VGGFace2_badnet_img30_pinterest_Srf.png}
\end{subfigure}
\begin{subfigure}{0.075\textwidth}
	\includegraphics[width=\textwidth]{fig/VGGFace2_badnet_img30_pinterest_mae_agg_adap.png}
\end{subfigure}
\begin{subfigure}{0.075\textwidth}
	\includegraphics[width=\textwidth]{fig/VGGFace2_badnet_imgc48_pinterest_org.png}
\end{subfigure}
\begin{subfigure}{0.075\textwidth}
	\includegraphics[width=\textwidth]{fig/VGGFace2_badnet_imgc48_pinterest_Srf.png}
\end{subfigure}
\begin{subfigure}{0.075\textwidth}
	\includegraphics[width=\textwidth]{fig/VGGFace2_badnet_imgc48_pinterest_mae_adap.png}
\end{subfigure}

\begin{subfigure}{0.075\textwidth}
	\includegraphics[width=\textwidth]{fig/imagenet10_badnet_img76_monitor_org.png}
\end{subfigure}
\begin{subfigure}{0.075\textwidth}
	\includegraphics[width=\textwidth]{fig/imagenet10_badnet_img76_monitor_Srf.png}
\end{subfigure}
\begin{subfigure}{0.075\textwidth}
	\includegraphics[width=\textwidth]{fig/imagenet10_badnet_img76_monitor_mae_agg_adap.png}
\end{subfigure}
\begin{subfigure}{0.075\textwidth}
	\includegraphics[width=\textwidth]{fig/imagenet10_badnet_imgc44_monitor_org.png}
\end{subfigure}
\begin{subfigure}{0.075\textwidth}
	\includegraphics[width=\textwidth]{fig/imagenet10_badnet_imgc44_monitor_Srf.png}
\end{subfigure}
\begin{subfigure}{0.075\textwidth}
	\includegraphics[width=\textwidth]{fig/imagenet10_badnet_imgc44_monitor_mae_agg_adap.png}
\end{subfigure}

\begin{minipage}{0.075\textwidth}
	\centering
	\scriptsize Backdoored image 
\end{minipage} 
\begin{minipage}{0.075\textwidth}
	\centering
	\scriptsize $S$ 
\end{minipage} 
\begin{minipage}{0.075\textwidth}
	\centering
	\scriptsize Purified image 
\end{minipage} 
\begin{minipage}{0.075\textwidth}
	\centering
	\scriptsize Clean image 
\end{minipage} 
\begin{minipage}{0.075\textwidth}
	\centering
	\scriptsize $S$ 
\end{minipage} 
\begin{minipage}{0.075\textwidth}
	\centering
	\scriptsize Purified image 
\end{minipage} 
\vspace{-4mm}
\caption{Visualizations on backdoored / clean images.}
\label{fig:clean_score}
\vspace{-4mm}
\end{figure}





\cparagraph{Generalization on network architecture.} Our method is for black-box defense, thus is generalizable on network architectures. In Tab.~\ref{tab:Cifar10-arch}, we show results on \texttt{Cifar10} with three different networks. The trigger is a 3$\times$3 checkerboard. The baseline method Februus performs well on the shallow convolutional neural network originally used by the authors, but is less effective on ResNet18 and VGG16. In contrast, ours achieves high accuracies for all situations. 

\cparagraph{Performance on clean images and models.} We highlight that our method is blind to the benignity of images or models. For backdoored models on clean images, the ACC$_c$ in previous results have validated the effectiveness. Figure~\ref{fig:clean_score} shows different properties of $S$ between backdoored and clean images. $S$ of clean images has small values, thus the image restoration step will not change the content. For clean models, Tab.~\ref{tab:clean-model} shows that the accuracies on clean images and images with triggers are minimally affected. 

\cparagraph{Sensitivity on hyper-parameters.} Our method mainly involves two critical hyper-parameters, the repeated times $N_o$ and the refinement times $N_r$. Throughout the experiments, we use $N_o=5$ and $N_r=10$. Figures~\ref{fig:abl:i},\ref{fig:abl:l} plot the effects of $N_o$ in \texttt{Base-$i$} and \texttt{Base-$l$}, respectively. For the image-based score $S^{i}$, the SSIM map is similar for different MAE restorations. Thus averaging over 2 repeated results is good enough. For the label-based score $S^{l}$, averaging over many repeated results reduces the variance. $N_o=5$ generally performs well for both scores. 


\renewcommand{\tabcolsep}{0.055cm}
\begin{table}[!t]
\caption{\texttt{Cifar10} with different network architectures.}
\vspace{-6mm}
	\begin{center}
		\scriptsize
		\begin{tabular}{@{}p{0.6cm}<{\centering}p{1.6cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}}
			\toprule
			\multirow{3}{*}{} & & \multicolumn{3}{c|}{ResNet18} & \multicolumn{3}{c|}{6 Conv + 2 Dense} & \multicolumn{3}{c}{VGG16}   \\
			\cmidrule{3-11}	
			& & ACC$_c$ & ACC$_b$ & ASR & ACC$_c$ & ACC$_b$ & ASR & ACC$_c$ & ACC$_b$ & ASR \\
			\midrule
			\multicolumn{2}{c|}{Before Defense} & 92.76 & 0.06 & 99.93 & 91.32 & 0.0 & 100.0 & 89.77 & 0.00 & 100.0\\
			\midrule	
			\multirow{2}{*}{Februus} & XGradCAM   & 88.00 & 88.44 & 6.10 & 91.26 & 91.18 & 1.52 & 76.17 & 77.46 & 15.08\\
			& GradCAM++  & 91.05 & 83.91 & 10.98 & 86.17 & 90.00 & 2.72 & 87.28 & 45.68 & 50.01\\
			\midrule
			\multirow{2}{*}{Ours} & Base  & 91.48 & 90.29 & 2.99 & 89.91 & 90.02 & 1.33 & 88.51 & 87.80 & 2.47\\
			& Large & 91.69 & 91.14 & 2.13 & 90.34 & 90.23 & 1.16 & 88.81 & 88.27 & 2.19\\
			\bottomrule
		\end{tabular} 
	\end{center}	
	\label{tab:Cifar10-arch}
  \vspace{-6mm}
\end{table}





\renewcommand{\tabcolsep}{0.06cm}
\begin{table}[!t]
\caption{Defense results on clean models.}
\vspace{-6mm}
	\begin{center}
	\scriptsize
	\begin{tabular}{p{0.8cm}<{\centering}p{0.8cm}<{\centering}|p{0.6cm}<{\centering}p{0.6cm}<{\centering}|p{0.6cm}<{\centering}p{0.6cm}<{\centering}|p{0.6cm}<{\centering}p{0.6cm}<{\centering}|p{0.6cm}<{\centering}p{0.6cm}<{\centering}}
		\toprule
		\multirow{2}{*}{} & & \multicolumn{2}{c|}{Cifar-10} & \multicolumn{2}{c|}{GTSRB} & \multicolumn{2}{c|}{ImageNet} & \multicolumn{2}{c}{VGGFace2} \\
		\cmidrule{3-10}
		& & ACC$_c$ & ACC$_b$ & ACC$_c$ & ACC$_b$ & ACC$_c$ & ACC$_b$ & ACC$_c$ & ACC$_b$ \\
		\midrule
		\multicolumn{2}{c|}{Before Defense} & 93.84 & 93.70 & 98.67 & 98.65 & 86.06 & 85.59  & 94.71 & 94.68 \\
		\midrule
		\multirow{2}{*}{Ours} & Base & 93.12 & 93.09 & 98.50 & 98.49 & 79.44 & 78.94 & 89.28 & 89.12 \\
		& Large & 93.31 & 93.25 & 98.64 & 98.61 & 83.07 & 82.29 & 90.99 & 91.12 \\
		\bottomrule
	\end{tabular}
    \end{center}	
	\label{tab:clean-model}
  \vspace{-8mm}
\end{table}

\vspace{-2mm}
\section{Conclusion}
In this paper, we study the novel yet practical task of blind backdoor defense at test time, in particular for black-box models. We use generic image generation models (\ie, MAE) to detect triggers and restore the clean images.
% A general framework of \textit{Blind Defense with Masked AutoEncoder} (BDMAE) is devised to detect triggers and restore images. Accuracies on clean images or models are uncompromised. 
% Our method generalizes well to various trigger types, network architectures or datasets. 
Our method focuses on the most popular local-patch triggers, but also generalizes well to medium-sized triggers like color curves (Fig.~\ref{fig:topology}). Extension to global triggers is left as an interesting future work. 
% Due to the Vision Transformer architecture of MAE, our trigger score has a resolution of 14$\times$14. Using shifted windows to locate triggers at finer granularity is also worth studying. 


% \section{Conclusion and Discussion}
% In this paper, we study the novel yet practical task of blind backdoor defense at test time, in particular for black-box models. We propose to leverage generic image generation models. A general framework of \textit{Blind Defense with Masked AutoEncoder} (BDMAE) is devised to detect triggers and restore images. Accuracies on clean images or models are uncompromised. Our method generalizes well to various trigger types, network architectures or datasets. 

% This work focuses on triggers of local patches, as they are commonly used in backdoor attacks. For medium-sized triggers like color curves in Fig.~\ref{fig:topology}, our method can find the trigger segments related to the backdoor behaviors. Extension to global triggers is an interesting future work. Due to the Vision Transformer architecture of MAE, our trigger score has a resolution of 14$\times$14. Using shifted windows to locate triggers at finer granularity is also worth studying. 

\appendix
\renewcommand{\thefigure}{A.\arabic{figure}}
\setcounter{figure}{0}
\renewcommand{\thetable}{A.\arabic{table}}
\setcounter{table}{0}
\renewcommand{\theequation}{A.\arabic{equation}}
\setcounter{figure}{0}

% In this supplementary material, we provide additional results and analyses on our method.

% In Sec.~\ref{sec:ssim} and Sec.~\ref{sec:topology}, we remark on SSIM similarity measure used in our method, and analyze the effects of the parameter in the topology-aware token mask generation. In Sec.~\ref{sec:trigger_size}, we compare the performances on \texttt{Cifar10} using various sizes of triggers. We discuss backdoor defense with test-time image transformation in Sec.~\ref{sec:ttt}. Full Februus results under different thresholds are listed in Sec.~\ref{sec:februus}. Lastly, we include additional visualizations of our method in Sec.~\ref{sec:visualization}.




\section{Remarks on SSIM}\label{sec:ssim}
Structural Similarity Index Measure (SSIM)~\cite{wang2004image} is used to measure the similarity between two images. Different from Mean-Squared-Error that measures pixel-wise absolution errors, SSIM considers the inter-dependencies among neighboring pixels. The SSIM index is calculated on two windows, $x$ and $y$, from a pair of images. Its definition is 
\begin{equation}
    \mathrm{SSIM}(x,y)=\frac{(2\mu_x \mu_y +c_1)(2\sigma_{xy}+c_2)}{(\mu_x^2+\mu_y^2+c_1)(\sigma_x^2+\sigma_y^2+c_2)}
\end{equation}
where $\mu_x$ and $\mu_y$ are mean values, $\sigma_x$ and $\sigma_y$ are variances, and $\sigma_{xy}$ is covariance. $c_1$ and $c_2$ are constants. $\mathrm{SSIM}(x,y)$ lies between -1 and 1. 1 indicates perfect similarity, 0 indicates no similarity, and -1 indicates perfect anti-correlation. In our experiments, we observe that the minimum SSIM values are about -0.6$\sim$-0.2 depending on datasets, and the maximum values are close to 1.0.

The window size influences the SSIM values. Generally, a larger window averages over more pixels, thus the SSIM value is less extreme (\ie, close to 0). We use the commonly used 11$\times$11 Gaussian window, whose effective window size is about 5$\times$5. On \texttt{Cifar10} and \texttt{GTSRB} of image size 32$\times$32, due to their low resolution, a 11$\times$11 window usually covers content regions. The original image and MAE restorations are similar, thus it is unlikely that the SSIM values will be extremely negatively. On \texttt{ImageNet10} and \texttt{VGGFace2} of image size 224$\times$224, differently, the window may include some background regions or image details. The difference between the original image and MAE restoration can be significantly large, leading to significantly negative SSIM values. Since our image-based trigger score is defined as $S^i=1-\mathrm{SSIM}$, $S^i$ tends to be larger for \texttt{ImageNet10} and \texttt{VGGFace2}. This is why the adaptive thresholds adjustment is necessary to achieve good performance on the two datasets.  


\section{Topology-aware Token Mask Generation}\label{sec:topology}
In the score refinement, we generate topology-aware token masks. We repeatedly choose $t_i=\arg\max_{t_k} (S^{*}[t_k]+u\llbracket t_k \in \textrm{Adj}(\mathcal{T}) \rrbracket )\cdot \sigma_{k} $ with $u=0.5$, where $\textrm{Adj}(\mathcal{T})$ includes all 4-nearest neighbors of tokens in $\mathcal{T}$ and $\sigma_{k}\sim U(0,1)$ is a random variable. Here $u$ is the additional probability assigned to the neighboring tokens. When $u=0$, the sampling procedure only select tokens with highest trigger-region scores. To see the effect of $u$, Fig.~\ref{fig:supp:topology} plots the results on four defense tasks with increasing $u$. For the challenging IAB attacks, the performances drops when not using topology-aware sampling (\ie, $u=0$). $u=0.5$ obtains relatively good performances on the four tasks. Note that due to the existence of random variable $\sigma_k$, using $u=1.0$ still leads to some randomness in the token selection.


\begin{figure}[h]
	\centering	
	\includegraphics[width=0.7\linewidth]{fig-supp/topology_sampling.pdf}
	\caption{Effects of the sampling parameter in topology-aware token mask generation.}\label{fig:supp:topology}
 \vspace{-2mm}
\end{figure}



\captionsetup[subfigure]{labelformat=empty}
\begin{figure*}[!t]
	\centering
\begin{subfigure}{0.16\linewidth}
	\includegraphics[width=\textwidth]{fig-supp/cifar10_badnet_2by2_color_img1_org_0_0.png}
\end{subfigure}
\begin{subfigure}{0.16\linewidth}
	\includegraphics[width=\textwidth]{fig-supp/cifar10_badnet_2by2_color_img1_noise_g0.05_2_8.png}
\end{subfigure}
\begin{subfigure}{0.16\linewidth}
	\includegraphics[width=\textwidth]{fig-supp/cifar10_badnet_2by2_color_img1_noise_g0.1_0_1.png}
\end{subfigure}
\begin{subfigure}{0.16\linewidth}
	\includegraphics[width=\textwidth]{fig-supp/cifar10_badnet_2by2_color_img1_gs_k3_s0.5_0_0.png}
\end{subfigure}
\begin{subfigure}{0.16\linewidth}
	\includegraphics[width=\textwidth]{fig-supp/cifar10_badnet_2by2_color_img1_gs_k3_s1.0_1_154.png}
\end{subfigure}
\begin{subfigure}{0.16\linewidth}
	\includegraphics[width=\textwidth]{fig-supp/cifar10_badnet_2by2_color_img1_OpticalDistortion_1_176.png}
\end{subfigure}
\begin{minipage}{0.16\linewidth}
        \scriptsize
	\centering Original Image \\ ACC$_c$ = 93.09 \% \\ ACC$_b$ = 0.00 \% \\ ASR = 100.0 \% 
\end{minipage} 
\begin{minipage}{0.16\linewidth}
        \scriptsize
	\centering Gaussian Noise (w) \\ ACC$_c$ = 53.54 \%  \\ ACC$_b$ = 0.07 \%  \\ ASR = 99.82 \% 
\end{minipage} 
\begin{minipage}{0.16\linewidth}
        \scriptsize
	\centering  Gaussian Noise (s)  \\ ACC$_c$ = 15.05 \%  \\ ACC$_b$ = 3.44 \%  \\ ASR = 73.47 \% 
\end{minipage} 
\begin{minipage}{0.16\linewidth}
        \scriptsize
	\centering  Gaussian Blur (w) \\ ACC$_c$ = 91.3 \%  \\ ACC$_b$ = 0.30 \%  \\ ASR = 99.67 \% 
\end{minipage} 
\begin{minipage}{0.16\linewidth}
        \scriptsize
	\centering  Gaussian Blur (s)  \\ ACC$_c$ = 63.15 \%  \\ ACC$_b$ = 61.97 \%  \\ ASR = 2.01 \% 
\end{minipage} 
\begin{minipage}{0.16\linewidth}
        \scriptsize
	\centering  Optical Distortion \\ ACC$_c$ = 86.88 \%  \\ ACC$_b$ = 70.03 \%  \\ ASR =  19.48 \% 
\end{minipage} 

\begin{subfigure}{0.16\linewidth}
	\includegraphics[width=\textwidth]{fig-supp/cifar10_badnet_2by2_color_img1_RandomContrast_0_0.png}
\end{subfigure}
\begin{subfigure}{0.16\linewidth}
	\includegraphics[width=\textwidth]{fig-supp/cifar10_badnet_2by2_color_img1_RandomGamma_0_0.png}
\end{subfigure}
\begin{subfigure}{0.16\linewidth}
	\includegraphics[width=\textwidth]{fig-supp/cifar10_badnet_2by2_color_img1_GridDistortion_0_62.png}
\end{subfigure}
\begin{subfigure}{0.16\linewidth}
	\includegraphics[width=\textwidth]{fig-supp/cifar10_badnet_2by2_color_img1_flip_0_0.png}
\end{subfigure}
\begin{subfigure}{0.16\linewidth}
	\includegraphics[width=\textwidth]{fig-supp/cifar10_badnet_2by2_color_img1_shrink_0_0.png}
\end{subfigure}
\begin{subfigure}{0.16\linewidth}
	\includegraphics[width=\textwidth]{fig-supp/cifar10_badnet_2by2_color_img1_Affine_0_2.png}
\end{subfigure}
\begin{minipage}{0.16\linewidth}
        \scriptsize
	\centering Random Contrast \\ ACC$_c$ = 93.02 \%  \\ ACC$_b$ = 0.00 \%  \\ ASR = 100.0  \% 
\end{minipage} 
\begin{minipage}{0.16\linewidth}
        \scriptsize
	\centering Random Gamma  \\ ACC$_c$ = 93.08 \%  \\ ACC$_b$ = 0.00 \%  \\ ASR =  100.0 \% 
\end{minipage} 
\begin{minipage}{0.16\linewidth}
        \scriptsize
	\centering  Grid Distortion  \\ ACC$_c$ = 72.88 \%  \\ ACC$_b$ = 26.90 \%  \\ ASR =  64.90 \% 
\end{minipage} 
\begin{minipage}{0.16\linewidth}
        \scriptsize
	\centering  Horizontal Flip \\ ACC$_c$ = 93.33 \%  \\ ACC$_b$ = 0.00 \%  \\ ASR = 100.0  \% 
\end{minipage} 
\begin{minipage}{0.16\linewidth}
        \scriptsize
	\centering  Down Scale  \\ ACC$_c$ = 91.16 \%  \\ ACC$_b$ = 0.00 \%  \\ ASR =  100.0 \% 
\end{minipage} 
\begin{minipage}{0.16\linewidth}
        \scriptsize
	\centering  Affine Trans  \\ ACC$_c$ = 89.37 \%  \\ ACC$_b$ = 1.10 \%  \\ ASR = 98.79  \% 
\end{minipage}

\caption{Defense results of applying test-time image transformations on \texttt{Cifar10} with 2$\times$2-color trigger.}
\label{fig:supp:test_transformation}
% \vspace{-4mm}
\end{figure*}


\renewcommand{\tabcolsep}{0.1cm}
\begin{table*}[!t]
\caption{Defense results on \texttt{Cifar10} using various sizes of checkerboard triggers.}
\vspace{-6mm}
	\begin{center}
		\scriptsize
		\begin{tabular}{p{0.8cm}<{\centering}p{2.1cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}}
			\toprule
			\multirow{3}{*}{} & & \multicolumn{3}{c|}{1$\times$1} & \multicolumn{3}{c|}{3$\times$3} & \multicolumn{3}{c|}{5$\times$5} & \multicolumn{3}{c}{7$\times$7} \\
			\cmidrule{3-14}	
			&  & ACC$_c$ & ACC$_b$ & ASR & ACC$_c$ & ACC$_b$ & ASR & ACC$_c$ & ACC$_b$ & ASR & ACC$_c$ & ACC$_b$ & ASR \\
			\midrule
			\multicolumn{2}{c|}{Before Defense} & 93.27 & 1.99 & 97.86 & 92.76 & 0.06 & 99.93 & 93.42 & 0.00 & 100.0 & 93.33 & 0.00 & 100.0\\
			\cmidrule{1-14}	
			 \multirow{2}{*}{Februus} & XGradCAM  & 91.52 & 80.73 & 13.71 & 91.05 & 83.91 & 10.98 & 91.74 & 89.92 & 3.95 & 91.64 & 70.23 & 15.48\\ 
			  & GradCAM++  & 74.09 & 85.71 & 7.13 & 81.29 & 91.61 & 2.67 & 75.04 & 92.65 & 0.92 & 75.14 & 72.59 & 11.74\\
			\cmidrule{1-14}	
			 \multirow{4}{*}{Ours} & Base-$i$  & 91.86 & 78.67 & 15.00 & 91.21 & 88.86 & 3.97 & 92.24 & 91.85 & 0.40 & 92.19 & 88.68 & 0.57\\
			  & Base-$l$ & 91.25 & 90.44 & 1.35 & 90.14 & 75.48 & 19.73 & 91.84 & 80.28 & 13.15 & 91.79 & 35.18 & 60.11\\
			  & Base  & 92.19 & 90.62 & 1.23 & 91.48 & 90.29 & 2.99 & 92.70 & 91.99 & 0.49 & 92.65 & 89.04 & 0.85\\ 
		 	& Large  & 92.41 & 90.88 & 1.15 & 91.69 & 91.14 & 2.13 & 92.81 & 92.26 & 0.49 & 92.75 & 90.22 & 0.70\\
	\bottomrule
		\end{tabular}
	\end{center}
\vspace{-4mm}
	\label{tab:supp:cifar10_vs}
\end{table*}





\section{Varying Trigger Size}\label{sec:trigger_size}
The trigger size affects the difficulty to detect these triggers. In the BadNet work~\cite{gu2019badnets}, the authors use 3$\times$3-checkerboard as triggers. In Tab.~\ref{tab:supp:cifar10_vs}, we present defense results on \texttt{Cifar10} using various sizes of checkerboard triggers. The baseline method Februus~\cite{doan2020februus} achieves relatively high accuracies on backdoored images at the cost of low accuracies on clean images. Our method maintains high accuracies on clean images. Our \texttt{Base-i} is not working well on 1$\times$1 trigger because it is hard to detect such a small trigger using image similarity. \texttt{Base-l}, on the contrary, works well on this small trigger using label consistency. As trigger size becomes larger, the performance of \texttt{Base-l} drops because the trigger can not be removed completely through random masking. The full method \texttt{Base} combines the merits of both image similarity and label consistency, and works for all cases. The \texttt{Large} variant achieves slightly higher accuracies due to better image restoration.






\section{Defense with Test-Time Transformation}\label{sec:ttt}
To defense against backdoor attack, test-time transformations have been used in some previous works~\cite{gao2019strip,sarkar2020backdoor,qiu2021deepsweep}. Since they are training free and can be applied to our task, we briefly summarize these methods and remark on their limitation in our blind backdoor defense setting. \textbf{Supression}~\cite{sarkar2020backdoor} creates multiple fuzzed copies of backdoored images, and uses majority voting among fuzzed copies to recover label prediction. The fuzzed copies are obtained by adding random uniform noise or Gaussian noise to the original image. However, the intensity of noise is critical. Weak noise would not remove the backdoor behaviour, while strong noise may destroy the semantic content.  \textbf{DeepSeep}~\cite{qiu2021deepsweep} mitigate backdoor attacks using data augmentation. It first fine-tunes the infected model via clean samples with an image transformation policy, and then preprocesses inference samples with another image transformation policy. The image transformation functions include affine transformations, median filters, optical distortion, gamma compression, \etc. The fine-tuning stage requires additional cleans samples, which are unavailable in our setting. \textbf{STRIP}~\cite{gao2019strip} superposes a test image with multiple other samples, and observes the entropy of predicted labels of these replicas. It aims to detect backdoored inputs, but could not locate the triggers nor recover the true label.

In Fig.~\ref{fig:supp:test_transformation}, we try different test-time image transformations on \texttt{Cifar10} with 2$\times$2-color trigger. For each transformation, we calculate the ACC$_c$ on clean images, ACC$_b$ and ASR on backdoored images. As can be seen, some weak transformations, like Gaussian Noise (w), Gaussian Blur (w), Random Contrast/Gamma, Horizontal Flip and Down Scale, can not reduce ASR. While the rest strong transformations reduces ASR, they also compromise accuracies on clean images unacceptably. To maintain performance on clean images, the model needs to adapt to these image transformations, \eg, through fine-tuning like DeepSeep does. Such requirement is infeasible in the blind backdoor defense, especially for black-box models.




\renewcommand{\tabcolsep}{0.1cm}
\begin{table*}[!t]
\caption{Defense results on \texttt{Cifar10} and \texttt{GSTRB} using various sizes of color/white triggers.}
\vspace{-6mm}
	\begin{center}
		\scriptsize
		\begin{tabular}{p{0.4cm}<{\centering}p{0.8cm}<{\centering}p{2.1cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}}
			\toprule
			\multirow{3}{*}{} & & & \multicolumn{3}{c|}{1$\times$1-color} & \multicolumn{3}{c|}{1$\times$1-white} & \multicolumn{3}{c|}{2$\times$2-color} & \multicolumn{3}{c|}{2$\times$2-white} & \multicolumn{3}{c|}{3$\times$3-color} & \multicolumn{3}{c}{3$\times$3-white} \\
			\cmidrule{4-21}	
			& & & ACC$_c$ & ACC$_b$ & ASR & ACC$_c$ & ACC$_b$ & ASR & ACC$_c$ & ACC$_b$ & ASR & ACC$_c$ & ACC$_b$ & ASR & ACC$_c$ & ACC$_b$ & ASR & ACC$_c$ & ACC$_b$ & ASR\\
			\midrule
		\multirow{9}{*}{\rotatebox{90}{\texttt{Cifar10}}} &	\multicolumn{2}{c|}{Before Defense} & 93.66 & 0.05 & 99.95 & 92.86 & 2.33 & 97.53 & 93.23 & 0.0 & 100.0 & 93.12 & 2.75 & 97.12 & 93.71 & 0.00 & 100.0 & 93.39 & 0.48 & 99.46\\
			\cmidrule{2-21}	
			& \multirow{6}{*}{Februus} & XGradCAM (0.6)  & 92.03 & 85.71 & 7.80 & 91.09 & 80.74 & 13.74 & 91.32 & 93.07 & 0.79 & 91.21 & 92.58 & 1.22 & 92.15 & 92.91 & 0.99 & 91.62 & 77.08 & 17.72\\
                &  & XGradCAM (0.7)  & 92.79 & 78.45 & 16.15 & 91.89 & 56.07 & 40.41 & 92.23 & 87.34 & 7.00 & 92.12 & 85.02 & 9.53 & 92.85 & 92.14 & 1.73 & 92.45 & 61.18 & 34.91\\
                &  & XGradCAM (0.8)  & 93.25 & 62.94 & 32.98 & 92.36 & 18.44 & 80.39 & 92.78 & 50.51 & 46.58 & 92.66 & 50.93 & 46.07 & 93.25 & 81.54 & 13.33 & 92.94 & 32.10 & 65.76\\
			&  & GradCAM++ (0.6)   & 74.73 & 91.21 & 0.94 & 74.45 & 89.60 & 3.30 & 76.19 & 92.91 & 0.80 & 74.82 & 91.26 & 1.66 & 75.04 & 92.73 & 0.80 & 75.01 & 87.09 & 6.59\\
                &  & GradCAM++ (0.7)   & 85.14 & 90.82 & 2.41 & 84.66 & 83.62 & 10.36 & 85.70 & 93.06 & 0.78 & 84.91 & 92.03 & 1.45 & 85.46 & 92.98 & 0.87 & 85.28 & 75.73 & 19.04\\
                &  & GradCAM++ (0.8)  & 90.81 & 66.05 & 29.46 & 89.97 & 51.40 & 45.08 & 90.71 & 77.53 & 17.48 & 90.31 & 82.33 & 12.21 & 90.78 & 92.37 & 1.48 & 90.54 & 49.93 & 46.65\\
			\cmidrule{2-21}	
			& \multirow{2}{*}{Ours} & Base & 92.96 & 90.71 & 0.56 & 91.78 & 90.26 & 1.50 & 92.50 & 91.50 & 0.47 & 92.25 & 89.97 & 1.50 & 92.94 & 92.10 & 0.53 & 92.59 & 90.49 & 0.78\\
		& 	& Large  & 93.13 & 90.78 & 0.60 & 91.97 & 90.59 & 1.36 & 92.73 & 91.75 & 0.45 & 92.45 & 90.36 & 1.30 & 93.13 & 92.30 & 0.48 & 92.68 & 90.87 & 0.76\\	
           \midrule
           \midrule
		\multirow{9}{*}{\rotatebox{90}{\texttt{GTSRB}}} &	\multicolumn{2}{c|}{Before Defense} & 98.72 & 0.00 & 100.0 & 97.96 & 2.33 & 97.52 & 98.31 & 0.00 & 100.0 & 98.55 & 4.39 & 95.51 & 98.77 & 0.00 & 100.0 & 98.37 & 1.38 & 98.47\\
			\cmidrule{2-21}	
			& \multirow{6}{*}{Februus} & XGradCAM (0.6)  & 73.00 & 29.06 & 64.10 & 74.72 & 68.15 & 25.15 & 58.57 & 58.57 & 15.24 & 56.95 & 40.32 & 52.72 & 59.26 & 83.21 & 4.29 & 69.75 & 25.97 & 66.23\\ 
            & & XGradCAM (0.7)  & 85.15 & 22.87 & 74.62 & 84.83 & 59.05 & 38.11 & 74.78 & 47.39 & 41.93 & 74.41 & 17.57 & 81.24 & 74.84 & 77.04 & 16.32 & 82.39 & 7.91 & 90.81\\
            & & XGradCAM (0.8)  & 93.20 & 14.49 & 84.83 & 92.16 & 45.30 & 53.25 & 88.27 & 30.00 & 67.75 & 88.00 & 2.90 & 97.04 & 88.30 & 51.07 & 46.45 & 91.76 & 2.86 & 96.84\\
		  &	& GradCAM++ (0.6)   & 65.18 & 45.28 & 33.51 & 46.10 & 94.27 & 0.24 & 47.00 & 59.81 & 17.24 & 45.03 & 91.52 & 1.62 & 47.99 & 86.19 & 0.87 & 49.80 & 73.53 & 6.08\\
            &	& GradCAM++ (0.7)   & 80.31 & 40.77 & 50.78 & 64.27 & 94.77 & 1.61 & 64.83 & 46.72 & 44.45 & 65.46 & 79.22 & 18.42 & 64.71 & 89.08 & 4.33 & 68.14 & 63.18 & 29.19\\
            &	& GradCAM++ (0.8)   & 91.27 & 28.39 & 69.28 & 81.77 & 90.98 & 6.23 & 82.98 & 17.50 & 81.38 & 83.56 & 22.38 & 77.29 & 82.56 & 70.22 & 26.68 & 84.59 & 30.90 & 67.43\\
			\cmidrule{2-21}	
		  &	\multirow{2}{*}{Ours} & Base & 98.55 & 92.38 & 0.18 & 97.62 & 95.91 & 0.98 & 98.03 & 97.80 & 0.06 & 98.27 & 96.49 & 1.31 & 98.62 & 98.31 & 0.09 & 98.14 & 91.00 & 2.85\\
	    	&	& Large & 98.68 & 94.73 & 0.18 & 97.93 & 96.26 & 0.88 & 98.28 & 98.00 & 0.07 & 98.49 & 96.59 & 1.50 & 98.75 & 98.28 & 0.19 & 98.32 & 91.81 & 2.87\\
			\bottomrule
		\end{tabular}
	\end{center}
 \vspace{-2mm}
	\label{tab:supp:cifar10_gtsrb-white-color}
\end{table*}



\renewcommand{\tabcolsep}{0.1cm}
\begin{table*}[!t]
\caption{Defense results on \texttt{VGGFace2} using various types of triggers.}
\vspace{-6mm}
	\begin{center}
		\scriptsize
		\begin{tabular}{p{1.2cm}<{\centering}p{0.6cm}<{\centering}p{2.5cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}|p{0.55cm}<{\centering}p{0.55cm}<{\centering}p{0.55cm}<{\centering}}
			\toprule
			\multirow{3}{*}{} & & & \multicolumn{3}{c|}{Trigger ` \begin{minipage}{0.02\linewidth}	\includegraphics[width=\linewidth]{fig-png/instagram.png} \end{minipage} '} & \multicolumn{3}{c|}{Trigger ` \begin{minipage}{0.02\linewidth}	\includegraphics[width=\linewidth]{fig-png/linkedin.png} \end{minipage} '} & \multicolumn{3}{c|}{Trigger ` \begin{minipage}{0.02\linewidth}	\includegraphics[width=\linewidth]{fig-png/pinterest.png} \end{minipage} '} & \multicolumn{3}{c|}{Trigger ` \begin{minipage}{0.02\linewidth}	\includegraphics[width=\linewidth]{fig-png/twitter.png} \end{minipage} '} & \multicolumn{3}{c}{Trigger ` \begin{minipage}{0.02\linewidth}	\includegraphics[width=\linewidth]{fig-png/wechat.png} \end{minipage} '}  \\
			\cmidrule{4-18}
			& & & ACC$_c$ & ACC$_b$ & ASR & ACC$_c$ & ACC$_b$ & ASR & ACC$_c$ & ACC$_b$ & ASR & ACC$_c$ & ACC$_b$ & ASR & ACC$_c$ & ACC$_b$ & ASR \\
			\midrule
			\multirow{9}{*}{VGG16} & \multicolumn{2}{c|}{Before Defense} & 91.74 & 0.00 & 100.0 & 91.58 & 0.02 & 99.98 & 91.38 & 0.00 & 100.0 & 91.54 & 0.05 & 99.95 & 91.60 & 0.00 & 100.0\\
			\cmidrule{2-18}
			& \multirow{6}{*}{Februus} & XGradCAM (0.6)  & 78.89 & 44.02 & 52.11 & 79.65 & 87.85 & 4.45 & 80.70 & 89.47 & 2.08 & 79.98 & 91.58 & 0.09 & 79.95 & 71.98 & 22.57\\
                & & XGradCAM (0.7) & 85.99 & 8.74 & 91.10 & 86.21 & 52.81 & 42.64 & 86.81 & 47.79 & 47.86 & 86.52 & 90.40 & 1.47 & 86.20 & 47.17 & 48.57\\
                & & XGradCAM (0.8)  & 89.69 & 0.04 & 99.96 & 89.79 & 16.90 & 82.31 & 90.04 & 30.57 & 67.47 & 89.89 & 10.83 & 88.71 & 89.79 & 34.75 & 63.33\\
			& & GradCAM++ (0.6)   & 72.60 & 75.80 & 18.37 & 73.84 & 91.57 & 0.07 & 76.19 & 91.40 & 0.07 & 75.17 & 91.57 & 0.08 & 75.47 & 62.25 & 32.80\\
                & & GradCAM++ (0.7)  & 83.27 & 42.74 & 53.89 & 83.91 & 84.12 & 8.91 & 85.10 & 90.23 & 1.27 & 84.77 & 78.41 & 15.41 & 84.52 & 43.98 & 52.71\\
                & & GradCAM++ (0.8)  & 88.94 & 8.60 & 91.26 & 89.32 & 24.31 & 74.58 & 89.38 & 48.14 & 48.10 & 89.38 & 8.26 & 91.42 & 89.30 & 10.62 & 89.10\\
			\cmidrule{2-18}
			& \multirow{2}{*}{Ours} & Base & 83.61 & 85.30 & 5.41 & 83.79 & 86.86 & 1.54 & 83.42 & 87.84 & 0.27 & 84.07 & 88.22 & 0.14 & 83.75 & 76.43 & 15.84\\
			& & Large  & 85.49 & 85.06 & 5.71 & 85.47 & 87.49 & 1.31 & 85.19 & 88.31 & 0.22 & 85.85 & 88.82 & 0.09 & 85.57 & 80.79 & 10.82\\
			\midrule
			\multirow{9}{*}{ResNet18} & \multicolumn{2}{c|}{Before Defense} & 94.12 & 0.00 & 100.0 & 94.03 & 0.00 & 100.0 & 93.98 & 0.00 & 100.0 & 94.04 & 0.04 & 99.96 & 94.17 & 0.01 & 99.99\\
			\cmidrule{2-18}
			& \multirow{6}{*}{Februus} & XGradCAM (0.6)  & 15.00 & 90.39 & 0.09 & 15.40 & 91.52 & 0.05 & 14.05 & 93.15 & 0.04 & 14.76 & 92.78 & 0.07 & 13.63 & 92.22 & 0.05\\
                & & XGradCAM (0.7)  & 29.10 & 93.15 & 0.03 & 29.75 & 93.54 & 0.02 & 29.62 & 93.60 & 0.03 & 29.36 & 93.78 & 0.13 & 28.69 & 93.82 & 0.04\\
                & & XGradCAM (0.8)  & 57.01 & 93.90 & 0.04 & 57.20 & 93.88 & 0.03 & 58.24 & 93.92 & 0.04 & 56.92 & 1.08 & 98.87 & 56.68 & 61.78 & 35.28\\
			& & GradCAM++ (0.6)  & 14.10 & 91.01 & 0.08 & 14.23 & 91.81 & 0.05 & 12.92 & 93.23 & 0.04 & 13.77 & 92.92 & 0.07 & 13.09 & 92.60 & 0.05\\
                & & GradCAM++ (0.7)  & 26.77 & 93.34 & 0.04 & 27.66 & 93.48 & 0.02 & 27.18 & 93.76 & 0.03 & 27.44 & 92.86 & 1.17 & 26.06 & 93.87 & 0.04\\
                & & GradCAM++ (0.8) & 53.71 & 93.96 & 0.04 & 54.13 & 93.87 & 0.03 & 55.08 & 93.94 & 0.03 & 53.76 & 0.78 & 99.18 & 53.62 & 45.54 & 52.60\\
			\cmidrule{2-18}
			& \multirow{2}{*}{Ours} & Base  & 87.44 & 86.57 & 6.47 & 87.64 & 90.39 & 1.28 & 87.83 & 91.17 & 0.19 & 87.85 & 91.25 & 0.07 & 87.86 & 80.94 & 13.27\\
			& & Large  & 90.44 & 87.99 & 5.34 & 90.44 & 91.10 & 1.15 & 90.37 & 91.65 & 0.23 & 90.46 & 91.83 & 0.04 & 90.43 & 78.95 & 15.67\\	
			\bottomrule
		\end{tabular}
	\end{center}
	\label{tab:supp:vggface2}
   \vspace{-4mm}
\end{table*}




\section{Februus Results}\label{sec:februus}
Februus~\cite{doan2020februus} uses GradCAM visualization to locate backdoor triggers. It relies on a threshold parameter to determine the backdoor removal regions. In the original paper, the authors use a held-out test set to determine this parameter for each dataset. Since we do not have such held-out test set in our blind backdoor defense task, we try with $\{0.6,0.7,0.8\}$, and report results with the parameter leading to best (ACC$_c$+ACC$_b$)/2 in the paper. The best parameter is selected for each attack setting individually. We present the full results in Tab.~\ref{tab:supp:cifar10_gtsrb-white-color} and Tab.~\ref{tab:supp:vggface2}. Februus is quite sensitive to this parameter. Generally, using a smaller parameter improves ACC$_b$ but reduces ACC$_c$ in Februus. The best parameter varies across different defense tasks. Our method achieves a good balance between accuracies on clean images and backdoored images. 





\section{Additional Visualization of Defense Process}\label{sec:visualization}
We present additional visualization of the defense process in Fig.~\ref{fig:supp:visualization}. The top six rows come from IAB~\cite{nguyen2020IAB} attack. IAB uses sample-specific triggers, \ie, test images contain different triggers for one backdoored model. On \texttt{Cifar10}, the triggers are irregular curves. On \texttt{GTSRB}, the triggers are color patches. Due to the complexity of triggers, the heuristic search in image space using rectangle trigger blockers~\cite{udeshi2022model} may not work well. In our method, the refined trigger-region score $S$ successfully identifies the trigger in each test image. Triggers are removed in the purified images, leading to correct label predictions. On \texttt{VGGFace2} and \texttt{ImageNet10}, despite their higher image resolution, our method also manages to locate the tiny triggers and restore the clean images.




\begin{figure*}[!t]
	\centering	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img48_org.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img48_mae_agg_rn0.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img48_mae_agg_ssim0.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img48_S1.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img48_S2.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img48_S1rf.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img48_S2rf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img48_Srf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img48_mae_agg_adap.png}
	\end{subfigure}

	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img73_org.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img73_mae_agg_rn0.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img73_mae_agg_ssim0.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img73_S1.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img73_S2.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img73_S1rf.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img73_S2rf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img73_Srf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img73_mae_agg_adap.png}
	\end{subfigure}

        \begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img9_org.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img9_mae_agg_rn0.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img9_mae_agg_ssim0.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img9_S1.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img9_S2.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img9_S1rf.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img9_S2rf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img9_Srf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_IAB_img9_mae_agg_adap.png}
	\end{subfigure}

        \vspace{2mm}

        \begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img27_org.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img27_mae_agg_rn0.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img27_mae_agg_ssim0.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img27_S1.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img27_S2.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img27_S1rf.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img27_S2rf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img27_Srf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img27_mae_agg_adap.png}
	\end{subfigure}

         \begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img13_org.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img13_mae_agg_rn0.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img13_mae_agg_ssim0.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img13_S1.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img13_S2.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img13_S1rf.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img13_S2rf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img13_Srf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img13_mae_agg_adap.png}
	\end{subfigure}

       \begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img34_org.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img34_mae_agg_rn0.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img34_mae_agg_ssim0.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img34_S1.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img34_S2.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img34_S1rf.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img34_S2rf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img34_Srf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/gtsrb_IAB_img34_mae_agg_adap.png}
	\end{subfigure}

       \vspace{2mm}

       \begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_badnet_2by2_white_img35_org.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_badnet_2by2_white_img35_mae_agg_rn0.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_badnet_2by2_white_img35_ssim0.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_badnet_2by2_white_img35_S1.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_badnet_2by2_white_img35_S2.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_badnet_2by2_white_img35_S1rf.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_badnet_2by2_white_img35_S2rf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_badnet_2by2_white_img35_Srf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/cifar10_badnet_2by2_white_img35_mae_agg_adap.png}
	\end{subfigure}
 
        \begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img5_org.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img5_mae_agg_rn0.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img5_ssim0.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img5_S1.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img5_S2.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img5_S1rf.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img5_S2rf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img5_Srf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img5_mae_agg_adap.png}
	\end{subfigure}

        \begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img0_org.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img0_mae_agg_rn0.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img0_ssim0.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img0_S1.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img0_S2.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img0_S1rf.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img0_S2rf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img0_Srf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/VGGFace2_badnet_img0_mae_agg_adap.png}
	\end{subfigure}
 
       \begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10pretr_badnet_img0_org.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10pretr_badnet_img0_mae_agg_rn0.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10pretr_badnet_img0_mae_agg_ssim0.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10pretr_badnet_img0_S1.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10pretr_badnet_img0_S2.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10pretr_badnet_img0_S1rf.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10pretr_badnet_img0_S2rf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10pretr_badnet_img0_Srf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10pretr_badnet_img0_mae_agg_adap.png}
	\end{subfigure}

        \begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10_badnet_img8_org.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10_badnet_img8_mae_agg_rn0.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10_badnet_img8_ssim0.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10_badnet_img8_S1.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10_badnet_img8_S2.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10_badnet_img8_S1rf.png}
	\end{subfigure}	
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10_badnet_img8_S2rf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10_badnet_img8_Srf.png}
	\end{subfigure}
	\begin{subfigure}{0.1\textwidth}
		\includegraphics[width=\textwidth]{fig-supp-vis/imagenet10_badnet_img8_mae_agg_adap.png}
	\end{subfigure}
 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize Original image w/ trigger
	\end{minipage} 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize Restored image from rand masks 
	\end{minipage} 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize SSIM map 
	\end{minipage} 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize $S^{i}$ before refinement  
	\end{minipage} 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize $S^{l}$ before refinement 
	\end{minipage} 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize $S^{i}$ after refinement   
	\end{minipage} 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize $S^{l}$ after refinement   
	\end{minipage} 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize $S$ for final restoration  
	\end{minipage} 
	\begin{minipage}{0.1\textwidth}
		\centering
		\scriptsize Purified image for prediction  
	\end{minipage} 
   
    \caption{Sampled visualizations of the defense process. All the scores are clipped to a range of [0,1], with yellow for high value. The top six rows are from IAB attack, and the rest are from BadNet attack.}\label{fig:supp:visualization}
\end{figure*}






{\small
\bibliographystyle{ieee_fullname}
\bibliography{reference}
}

\end{document}