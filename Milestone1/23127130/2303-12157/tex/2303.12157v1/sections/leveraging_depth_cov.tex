\section{Leveraging a Depth Covariance Function}
\label{sec:leveraging_depth_cov}

Given an image and its corresponding CNN output maps, we may leverage the covariance function by defining a prior over depth functions, conditioning on depth observations to yield a predictive distribution, and actively sampling pixel locations that minimize the variance of depth predictions.

\subsection{Gaussian Process Prior}
\label{subsec:gp_prior}

Given a finite set of input points $X_*$, we may define a Gaussian prior over their log-depths:
\begin{align}
    \mathbf{f}_* \sim \mathcal{N}\left(m,\, K(X_*, X_*) \right) .
\end{align}
The GP defines a prior over functions, and for any number of input points, we obtain a Gaussian prior.  For geometric vision tasks, this prior can be leveraged for anything from sparse to dense methods.  Due to the marginalization property of GPs, adding points to the indexing set will not change the marginal distribution of the existing set.  Alternatively, the prior may be viewed as an image-conditioned regularizer of any desired latent geometry parameterization.

\subsection{Predictive Distribution}
\label{subsec:conditional}

In many cases, log-depth observations $\mathbf{y}$, such as from RGB-D sensors or LiDAR, may be available.  We can explicitly condition the prior on these observations to obtain a posterior distribution.  The predictive mean $\mathbf{f}_*$ and covariance $\Sigma_*$ given $N$ samples is:
\begin{align}
    \mathbf{f}_* &= m + K_{\text{fn}} (K_{\text{nn}} + \sigma_n^2 I)^{-1} (\mathbf{y} - m), \\
    \Sigma_* &= K_{\text{ff}} - K_{\text{fn}} (K_{\text{nn}} + \sigma_n^2 I)^{-1} K_{\text{nf}}.
\end{align}
The predictive mean is a linear function in terms of the observations $\mathbf{y}$, so test-time inference of latent depths is efficient.  If a full covariance is not required, only certain blocks or per-pixel variances need to be calculated. Note that the covariance depends only on the observation coordinates and not the observed values.  We visualize the predictive mean, variance, and correlation maps for an example in Figure \ref{fig:conditioning}.

\begin{figure}[t]
	\centering
	\includegraphics[width=\columnwidth]{figures/pngs/conditioning_example.jpg}
	\caption{Conditioning example for 128 samples.  The posterior variance is high around edges and in areas lacking samples.  The columns of $K_{\text{fn}}$, or correlation maps, are shown for select points.}
	\label{fig:conditioning} 
\end{figure}

\subsection{Active Point Selection}
\label{subsec:active_selection}

For dense reconstruction, it is beneficial to construct a compact representation that can achieve high-fidelity results.  As mentioned previously, the predictive covariance depends only on the RGB image and locations of depth observations, but not on the observations themselves.  By viewing the CNN as a meta-learned initialization of the nonstationary kernel parameters, we may use 2D observations as a proxy for the complexity of 3D geometry.  Active selection of informative pixels up to a desired variance permits representing less complex scenes with fewer samples and allocating capacity towards high-frequency geometry. 

Inspired by sensor placement literature \cite{guestrin_near-optimal_2005}, an entropy-based criterion is used to select informative pixels.  In the greedy-case, this simplifies to selecting the input point with the highest conditional variance at each step.  Since this requires computing the conditional variance for each newly added point, we leverage incremental updates to the variance and Cholesky factorization of the training covariance matrix \cite{ranganathan_online_2011}.  By decoupling the neural network and GP, we do not require any additional network passes.

A qualitative example of active sampling is shown in Figure \ref{fig:qual_sampling}.  Random sampling severely misrepresents depth of table and chairs, which all appear at similar depths.  Active sampling focus samples around the thin chair edge near the image, while also avoiding oversampling on the floor.  Furthermore, active sampling avoids missing the top section of the image, so that the table and chairs are well-represented.

\begin{figure}[t]
	\centering
	\includegraphics[width=0.99\columnwidth]{figures/pngs/random_vs_active_qual.jpg}
	\caption{Qualitative comparison of random and active sampling given 32 sample selections.  Random sampling misrepresents depth at the top of the image, while active sampling focuses on the chair geometry and avoids redundant samples on the floor.}
	\label{fig:qual_sampling} 
\end{figure}