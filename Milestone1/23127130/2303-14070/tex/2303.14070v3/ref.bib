@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={arXiv preprint arXiv:2203.02155},
  year={2022}
}


@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
}

@misc{touvron2023llama,
      title={LLaMA: Open and Efficient Foundation Language Models}, 
      author={Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
      year={2023},
      eprint={2302.13971},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{wang2022selfinstruct,
      title={Self-Instruct: Aligning Language Model with Self Generated Instructions}, 
      author={Yizhong Wang and Yeganeh Kordi and Swaroop Mishra and Alisa Liu and Noah A. Smith and Daniel Khashabi and Hannaneh Hajishirzi},
      year={2022},
      eprint={2212.10560},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@article{abacha2015means,
  title={MEANS: A medical question-answering system combining NLP techniques and semantic Web technologies},
  author={Abacha, Asma Ben and Zweigenbaum, Pierre},
  journal={Information processing \& management},
  volume={51},
  number={5},
  pages={570--594},
  year={2015},
  publisher={Elsevier}
}

@article{gilson2023does,
  title={How does CHATGPT perform on the United States Medical Licensing Examination? the implications of large language models for medical education and knowledge assessment},
  author={Gilson, Aidan and Safranek, Conrad W and Huang, Thomas and Socrates, Vimig and Chi, Ling and Taylor, Richard Andrew and Chartash, David and others},
  journal={JMIR Medical Education},
  volume={9},
  number={1},
  pages={e45312},
  year={2023},
  publisher={JMIR Publications Inc., Toronto, Canada}
}

@article{xu2021raise,
  title={Raise a child in large language model: Towards effective and generalizable fine-tuning},
  author={Xu, Runxin and Luo, Fuli and Zhang, Zhiyuan and Tan, Chuanqi and Chang, Baobao and Huang, Songfang and Huang, Fei},
  journal={arXiv preprint arXiv:2109.05687},
  year={2021}
}


@article{hatherley2020limits,
  title={Limits of trust in medical AI},
  author={Hatherley, Joshua James},
  journal={Journal of medical ethics},
  volume={46},
  number={7},
  pages={478--481},
  year={2020},
  publisher={Institute of Medical Ethics}
}