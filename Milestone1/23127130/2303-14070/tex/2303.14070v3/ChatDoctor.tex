% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.21 of 2022/01/12
%
\documentclass[runningheads]{llncs}
%
\usepackage[T1]{fontenc}
% T1 fonts will be used to generate the final print and online PDFs,
% so please use T1 fonts in your manuscript whenever possible.
% Other font encondings may result in incorrect characters.
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{algorithm}  
\usepackage{algorithmicx}  
\usepackage{algpseudocode}  
\usepackage{amsmath} 
\usepackage{amsfonts}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{regexpatch}
%\usepackage{hyperref}
%\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{mathrsfs}
\usepackage[misc]{ifsym} 
\usepackage[marginal]{footmisc}
\usepackage{graphicx}
% \usepackage{hyperref}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following two lines
% to display URLs in blue roman font according to Springer's eBook style:
%\usepackage{color}
%\renewcommand\UrlFont{\color{blue}\rmfamily}
\usepackage[pagebackref=true,breaklinks=true,colorlinks,bookmarks=false]{hyperref}
%
\begin{document}
%
\title{ChatDoctor: A Medical Chat Model Fine-tuned on LLaMA Model using Medical Domain Knowledge}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
\author{Anonymous}
\institute{Anonymous}
\author{Yunxiang Li\inst{1}, Zihan Li\inst{2}, Kai Zhang\inst{3}, Ruilong Dan\inst{4}, You Zhang\inst{1}$^{(\textrm{\Letter})}$}
\authorrunning{Y. Li et al.}
\institute{University of Texas Southwestern Medical Center, Dallas, USA \and University of Illinois at Urbana-Champaign, Urbana, USA \and Ohio State University, Columbus, USA \and Hangzhou Dianzi University, Hangzhou, China   \\  \email{you.zhang@utsouthwestern.edu}  }
\maketitle             


\begin{abstract}
Recent large language models (LLMs) in the general domain, such as ChatGPT, have shown remarkable success in following instructions and producing human-like responses. However, such language models have not been tailored to the medical domain, resulting in poor answer accuracy and inability to give plausible recommendations for medical diagnosis, medications, etc. To address this issue, we collected more than 700 diseases and their corresponding symptoms, required medical tests, and recommended medications, from which we generated 5K doctor-patient conversations. In addition, we obtained 200K real patient-doctor conversations from online Q\&A medical consultation sites. By fine-tuning LLMs using these 205k doctor-patient conversations, the resulting models emerge with great potential to understand patients' needs, provide informed advice, and offer valuable assistance in a variety of medical-related fields. The integration of these advanced language models into healthcare can revolutionize the way healthcare professionals and patients communicate, ultimately improving the overall efficiency and quality of patient care and outcomes. In addition, we made public all the source codes, datasets, and model weights to facilitate the further development of dialogue models in the medical field.  The training data, codes, and weights of this project are available at:
\href{https://github.com/Kent0n-Li/ChatDoctor}{https://github.com/Kent0n-Li/ChatDoctor}.


\end{abstract}



\section{Introduction}
% general background
% Kai: Let me know if it's too LLM and you want more chat-model oriented. Or you wanna start with medical domain. Both work for me
The development of instruction-following large language models (LLMs) such as ChatGPT~\cite{ouyang2022training} has garnered significant attention due to their remarkable success in instruction understanding and human-like response generation.
These auto-regressive LLMs \cite{wang2022selfinstruct} are pre-trained over web-scale natural languages by predicting the next token, and then fine-tuned to follow large-scale human instructions.
Also, they have shown strong performances over a wide range of natural language processing (NLP) tasks and generalizations to unseen tasks, demonstrating their potential as a unified solution for various problems such as natural language understanding, text generation, and conversational AI. 
However, the exploration of such general-domain LLMs in the medical field remains relatively untapped \cite{gilson2023does}, despite the immense potential they hold for transforming healthcare communication and decision-making \cite{abacha2015means}.
The specific reason is that the existing models do not learn the medical field in specific or in detail, resulting in the models often giving wrong medical responses when serving as a virtual doctor (ChatDoctor). By fine-tuning the large language dialogue model on the data of doctor-patient conversations, the application of the model in the medical field can be significantly spurred. Especially in regions where medical resources are scarce, ChatDoctor can be used to support initial diagnosis and triage of patients, significantly improving the operational efficiency of existing medical systems.

Since large language models such as ChatGPT are in a non-open source state, we used Meta's open-source LLaMA. We first trained a generic conversation model using 52K instruction-following data provided by Stanford Alpaca~\cite{alpaca}, and then fine-tuned the model on our collected physician-patient conversation dataset. 
The main contributions of our method are three-fold: \\
\textbf{1)} We designed a novel framework for fine-tuning large language models in the medical domain.\\
\textbf{2)} We collected a dataset with 5,000 generated doctor-patient conversations and 200,000 real patient-doctor conversations for fine-tuning the large language model.\\
\textbf{3)} We validated that the fine-tuned ChatDoctor with medical domain knowledge has real potential for clinical applications.


%Thank you for your query, if pain is in the upper part of abdomen, then it could be peptic ulcer disease (PUD), or if it is on the right side of abdomen, gall bladder stone/problem, if it is on the left side, urinary tract problem. But all these are just assumptions, as I haven't seen your reports, and kindly provide me with some more details.


\begin{figure}[htbp]
\centering
\includegraphics[width=0.9\textwidth]{imgs/overview.PNG}
\caption{Overview of the physician and patient conversation dataset collection pipeline and the training procedure of ChatDoctor.}
\label{fig:chat3}
\end{figure}

\section{Method}
\subsection{Physician and patient conversation dataset}
The first step in building a physician-patient conversation dataset is to collect the disease database that serves as the golden standard of medical-domain expertise. Therefore, we collected and organized a database, containing about 700 diseases with their relative symptoms, medical tests, and recommended medications. To train high-quality conversation models on an academic budget, we input tuples from the disease database as separate prompts into the ChatGPT API to automatically generate instructions and dialogue data. Notably, our prompts to the ChatGPT API contain names of diseases, corresponding symptoms, recommended tests, and reference medications, and the ChatGPT generate patient-physician dialogues out of these prompts. Correspondingly, our fine-tuned ChatDoctor not only can learn ChatGPT's conversational fluency, but also learn medical-domain expertise from the curated dataset to offer more accurate responses to medical instructions. We generated 5K doctor-patient conversation demonstrations and constructed a new dataset. 

The generated conversations, while ensuring accuracy, have a low diversity of conversations. Therefore, we also collected about 200k real doctor-patient conversations from an online Q\&A based medical advisory service website -- "Health Care Magic." We manually and automatically filtered these data to remove physician and patient names and used language tools to correct grammatical errors in the responses. We named this dataset of real conversations between patients and doctors. We combined the data sets from both sources and named it InstructorDoctor-205k, and our final model was obtained by fine-tuning on it.

\subsection{Training of the model}
We build our ChatDoctor utilizing Meta's LLaMA model~\cite{touvron2023llama}, a publicly accessible LLM.
Notably, in spite of its mere 7 billion parameters, the LLaMA has reported superior efficacy and competitive performance in comparison to the considerably larger GPT-3 (with 175 billion parameters) on several NLP benchmarks.
LLaMA's performance improvement was achieved by amplifying the diversity of training data, as opposed to parameter quantity.
Specifically, LLaMA was trained on 1.0 trillion tokens, procured from publicly accessible data repositories such as CommonCrawl and arXiv documents.

We utilize conversation demonstrations synthesized via ChatGPT~\cite{ouyang2022training} to fine-tune the LLaMA model \cite{xu2021raise}, in accordance with the Stanford Alpaca~\cite{alpaca} training methodology, and our model was firstly be fine-tuned by Stanford Alpaca's data to have some basic conversational capabilities.
The fine-tuning process on InstructorDoctor-205k was conducted using 6 A*100 GPUs for a duration of 18 hours. 
The hyperparameters employed in the training process were as follows: the total batch size of 192, a learning rate of $2 \times 10^{-5}$, a total of 3 epochs, a maximum sequence length of 512 tokens, and a warmup ratio of 0.03, with no weight decay.



\begin{figure}[!htbp]
\centering
\includegraphics[width=0.8\textwidth]{imgs/chat_example3.png}
\caption{An example of a medical advice consultation with ChatDoctor.}
\label{fig:chat3}
\end{figure}







\begin{table}[]
\centering
\caption{Some examples of consulting ChatDoctor about some medical advice.}
\begin{tabular}{l|l|p{8cm}l}\cline{1-3}
No.                &         Class               & Dialogue                                                                                                                                                                                                                                                                                                           &  \\ \cline{1-3}
\multirow{2}{*}{1} & Question of Patient    & Doctor, I have been experiencing vomiting, nausea, and abdominal pain. I recently found out that I have pyloric stenosis. What medications should I take for it?                                                                                                                                                  &  \\ \cline{2-3}
                   & Response of ChatDoctor & The most common treatment for pyloric stenosis is a surgical procedure called a pyloromyotomy. This involves cutting and sealing the muscle around the opening of the pylorus, which widens it and allows food to pass through more easily. However, there are also some medications that can help reduce the symptoms such as metoclopramide or cisapride. Which one would you prefer? &  \\ \cline{1-3}
\multirow{2}{*}{2} & Question of Patient    & Hi doctor, I have been losing hair rapidly for the past few months. I think I might have Alopecia. What should I do?                                                                                                                                              &  \\ \cline{2-3}
                   & Response of ChatDoctor &  There are several medications that can help with Alopecia. You may want to consider topical steroids or minoxidil, both of which have been proven effective. Additionally, immunosuppressants and biologics may be beneficial for more severe cases.                                                                                                                                                                                                                                                                                                             &  \\ \cline{1-3}
\multirow{2}{*}{3} & Question of Patient    & Doctor, I've been experiencing sudden jerks and twitches in my muscles. It's becoming very difficult to manage them on a daily basis.                                                                                                                                               &  \\ \cline{2-3}
                   & Response of ChatDoctor & There are several medications that can help with Myoclonus. Are you taking any other medications?                                                                                                                                                                                                                                                                                         &  \\ \cline{1-3}
\multirow{2}{*}{4} & Question of Patient    & I think I have carbon monoxide poisoning. I feel dizzy and nauseous.                                                                                                                                                &  \\ \cline{2-3}
                   & Response of ChatDoctor & I recommend that you get medical attention immediately and start taking a breathing treatment with 100\% oxygen. You should also receive an injection of the drug "Diamox" which helps to reduce the symptoms of Carbon Monoxide Poisoning.                                                                                                                                                                                                                                                                                    &  \\ \cline{1-3}
\multirow{2}{*}{5} & Question of Patient    & I have been experiencing memory problems and confusion lately. I think I might have Wernicke Korsakoff syndrome. &  \\ \cline{2-3}
    & Response of ChatDoctor & Doctor: Yes, we can try some medications such as thiamine and memantine, but it is best to consult with a neurologist for further evaluation and treatment.  &  \\ \cline{1-3}

\end{tabular}
\label{tabel:1}
\end{table}





\section{Results}
On our ChatDoctor model, we play the role of a patient and manually input some medically relevant questions. The related conversation results are presented in Figures \ref{fig:chat3}.
To assess the performance of ChatDoctor, the input from the self-structured evaluation set was manually assessed by experienced practitioners. We performed a blind evaluation of ChatDoctor and ChatGPT against each other to fairly assess their medical capabilities. In the comparison of recommending medications based on diseases, our ChatDoctor achieved 91.25\% accuracy compared to ChatGPT's 87.5\%.


Some examples of ChatDoctor's response are depicted in Table \ref{tabel:1}. After our analysis, we found many interesting points. For example, in the first question, the patient asks for the recommended medication for pyloric stenosis and does not ask anything about surgery, but the ChatDoctor's response mentions that pyloric stenosis is not adequately treated by medication alone and that the best solution is surgery. In the third question, ChatDoctor may consider that some of the medications available for recommendation are harmful when taken in combination with other medications. Therefore, ChatDoctor did not recommend the medication directly but asked the patient if he or she was taking other medications. In the fourth question, ChatDoctor considers carbon monoxide poisoning to be very urgent and responds by advising the patient to seek immediate medical attention. In the fifth question, ChatDoctor did not have enough knowledge about Wernicke Korsakoff syndrome to answer in more detail and advised the patient to consult with a neurologist for further evaluation and treatment.





\section{Limitations}
We would like to emphasize that ChatDoctor is for academic research only and any commercial use and clinical use are strictly prohibited. First, we have not designed sufficient security measures, and the current model can not guarantee the full correctness of medical diagnoses and recommendations. Second, our model is not licensed for healthcare-related purposes \cite{hatherley2020limits}. Third, ChatDoctor is based on LLaMA and has a non-commercial license, so we necessarily inherited these rules.


\section{Discussion and conclusion}
ChatDoctor, the chatbot obtained by fine-tuning large language models on medical domain knowledge, has a wide range of potential applications. However, due to the unique characteristics of the medical domain, latent language errors in diagnosis and medical advice can have serious consequences. And large language models often generate many incorrect and harmful statements (hallucinations) on the knowledge they do not know, which may result in malpractice. In future work, it will be vital to limit large language models to generate only results that they are confident of and suppress the indefinite responses. Additional safety checks offered by traditional or AI-related methods may also be needed. In addition, the model performance is highly correlated with the high-quality training data that is extremely scarce. Despite these challenges, the potential benefits of ChatDoctor are significant, including improving the accuracy and efficiency of medical diagnoses, and reducing the workload of medical professionals while increasing access to medical advice, especially for most under-served hospitals and patients in third-world countries. By addressing the challenges of language model applications in the medical domain, our ChatDoctor could become a valuable assistant in improving patient outcomes and advancing medical research.

% Kai: Highly recommend to discuss the hallucination problem in ChatDoctor and how to avoid.








%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.

\bibliographystyle{splncs04}
\bibliography{ref}

\end{document}
