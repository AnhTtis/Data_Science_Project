% !TeX spellcheck = en_US


\subsubsection{Optimal Ride-pooling Assignment}\label{sec:alg}
In this section, we will compute the optimal ride-pooling assignment matrices $\beta^\star$ and $\gamma^\star$, under Approximation~\ref{approx}, leveraging an iterative approach, which is described in what follows.
For every pair of requests $r_m,r_n\in \cR$, we can compute the unitary improvement of the objective function of Problem~\ref{prob:rides}, denoted by $\Delta \tilde{J}_{mn}$, w.r.t. the no-pooling scenario. Specifically, it amounts to the difference  between $\tilde{J}_{nm}$, which denotes the cost with $D^\mathrm{rp} = D^{mn,\star}$, and $\tilde{J}_n+\tilde{J}_m$, which again denotes the cost with $D^\mathrm{rp} = D^{mn,0}$. Let $\alpha_m^\prime, m\in \cM$ stand for an auxiliary variable throughout the iterations and represent the demand of request $r_m$ that has not yet been assigned, and which is initialized as $\alpha_m^\prime = \alpha_m$. Further, the pair of requests with the highest improvement is prioritized with the highest possible pooling demand assignment. That is, in each iteration, if $r_m,r_n\in \cR$  is the pair of requests with the highest $\Delta \tilde{J}_{mn}$, we set $\beta_{mn} = \alpha_m^\prime$ and $\beta_{nm}=\alpha_n^\prime$. Moreover, the rides that have been assigned but not pooled, are added back to the original requests, i.e., we set $\alpha_m^\prime =  \beta_{mn}-\gamma_{mn}$ and $\alpha_n^\prime =\beta_{nm}-\gamma_{nm}$. Let $\Delta \tilde{J}_{mn}^\prime, m,n\in \cM$ denote another auxiliary variable  throughout the iterations, initialized as $\Delta \tilde{J}_{mn}^\prime=  \Delta \tilde{J}_{mn}$. At the end of every iteration, $\Delta \tilde{J}^\prime_{mn}$ is set to  0.   
This procedure is repeated until convergence is achieved, i.e., $\max_{m,n} (\Delta \tilde{J}^\prime_{mn}) \leq 0$. The pseudocode of this procedure is presented in Algorithm~\ref{alg:one}. In the following theorem, we establish the convergence and optimality of Algorithm~\ref{alg:one}.
	
\begin{algorithm}[ht]
	\caption{Compute optimal assignment matrices $\beta^\star, \gamma^\star$.}\label{alg:one}
	\begin{algorithmic}
		\STATE $\tilde{J}_{mn} \leftarrow  \mathrm{input} \;\; D^{mn, \star} \; \text{to Problem}~\ref{prob:rides}, \;\; \forall {m,n\in \cM}$
		\STATE $\tilde{J}_{m} + \tilde{J}_n  \leftarrow  \mathrm{input} \;\; D^{mn, 0} \; \text{to Problem}~\ref{prob:rides}, \;\; \forall {{m,n\in \cM}}$
%		\STATE $ \forall m,n \; \mathrm{input} \; D^{mn,0} \; to \; Problem~\ref{prob:rides} \rightarrow \tilde{J}_{m},\tilde{J}_{n}$
		\STATE $\Delta \tilde{J}_{mn} \;\leftarrow\; \tilde{J}_{m} + \tilde{J}_{n} - \tilde{J}_{mn} $
		\STATE $\Delta \tilde{J}_{mn}^\prime \;\leftarrow\; \Delta \tilde{J}_{mn}, \; \forall m,n\in \cM$
		\STATE $\alpha_{m}^\prime \;\leftarrow\; \alpha_{m}, \; \forall m\in \cM $
%		\STATE $\;D^\mathrm{rp} = \mathbb{0}$
		\WHILE {$ \mathrm{max}_{m,n}(\Delta \tilde{J}^\prime_{mn}) > 0 $}
		\STATE $ (m,n) \in \mathrm{argmax}_{m,n} (\Delta \tilde{J}^\prime_{mn})$
		\IF{$o_n = o_m \; \mathrm{and} \; d_n=d_m$}
		\STATE $ \beta_{mn}  \;\leftarrow\; \alpha_{m}^\prime, \;\beta_{nm} \;\leftarrow\; \beta_{mn}$
		\STATE $ \gamma_{mn} \;\leftarrow\; \beta_{mn}  P(\beta_{mn},\beta_{nm})/2, \;\gamma_{nm} \;\leftarrow\; \gamma_{mn}$
%		\STATE $D^\mathrm{rp}_{ii} = b^\mathrm{rp}_{ii} - \beta_{ijkl} , \; b^\mathrm{rp}_{ij} = b^\mathrm{rp}_{ij} + \beta_{ijkl}  $
		\ELSE
		\STATE $\beta_{nm}  \;\leftarrow\;  \alpha_{n}^\prime, \; \beta_{mn}  \;\leftarrow\;  \alpha_{m}^\prime$
		\STATE $\gamma_{mn}  \;\leftarrow\;  \min(\beta_{nm},\beta_{mn}) P(\beta_{mn},\beta_{nm})$
		\STATE $\gamma_{nm} \;\leftarrow\;  \gamma_{mn}$
		\ENDIF
%		\STATE $D^\mathrm{rp} = D^\mathrm{rp} + \gamma_{mn}  D^{mn \star}$
		\STATE$\alpha_{m}^\prime  \;\leftarrow\;  \alpha_{m}^\prime - \gamma_{mn},  \; \alpha_{n}^\prime  \;\leftarrow\; \alpha_{n}^\prime - \gamma_{nm} $
		\STATE$\Delta \tilde{J}^\prime_{mn}  \;\leftarrow\; 0, \;   \Delta \tilde{J}^\prime_{nm} \leftarrow \Delta \tilde{J}^\prime _{mn}  $
		\ENDWHILE
	\end{algorithmic}
\end{algorithm}
%We define the optimal objective function of Problem~\ref{prob:rides} with parametric entry $\gamma$ as $\tilde{J}(X^\star_\gamma)$.


\begin{theorem}\label{theorem:one}
Let $X^\star_\gamma$ denote the optimal solution of Problem~\ref{prob:rides}, under Approximation~\ref{approx}, for the effective ride-pooling demand matrix $\gamma$. Then, in $\abs{\cM}(\abs{\cM}-1)$ iterations at most, Algorithm~\ref{alg:one} converges to $\beta = \beta^\star$ and $\gamma= \gamma^\star$, which is a minimizer of $\tilde{J}(X^\star_\gamma)$ among all valid effective ride-pooling matrices.
\end{theorem} 
\begin{proof}
		The proof can be found in Appendix~\ref{app:2}. 
\end{proof}
%	Algorithm~\ref{alg:one} leads to the parameter $\beta^\star$ so that \mbox{$J(X^\star_{\gamma^\star}) \leq J(X^\star{_\gamma})$}, where $\gamma = \gamma(\beta)$, and $\gamma^\star = \gamma(\beta^\star)$.
%We prove Theorem~\ref{theorem:one} in Appendix~\ref{app:2}. 



\subsection{Discussion}
A few comments are in order.
The mobility system is analyzed at steady-state, which is unsuitable for an online implementation, but it is appropriate for planning and design~\cite{LukeSalazarEtAl2021,SalazarLanzettiEtAl2019}. 
Then, Problems~\ref{prob:main} and \ref{prob:rides} allow for fractional flows, which is acceptable because of the mesoscopic perspective of the work~\cite{PaparellaChauhanEtAl2023,LukeSalazarEtAl2021,SalazarLanzettiEtAl2019}.
We consider the travel time of each arc to be constant, meaning that the routing strategies do not impact travel time and congestion. Finally, $D^\mathrm{rp}$ is not optimal w.r.t. the objective function of Problem~\ref{prob:rides}, but it is w.r.t. its relaxed version, enabling a polynomial-time computation.