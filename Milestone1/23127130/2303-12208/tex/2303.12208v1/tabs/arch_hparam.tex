\bgroup
\def\arraystretch{1.05}%
    \begin{table}[h]
    \centering
    \small
    \begin{tabular}{ccc}
    \hline
    \bf{Parameter} & \multicolumn{2}{c}{\textbf{Model}} \\
    \cmidrule(r){2-3}
    & ARG/MAGVLT & ARG/MAGVLT$_{\text{Large}}$ \\
    % \midrule
    \hline
    %ARGVLT (\textit{I2T only}) & 39.8  &  32.3 & 120.6 & 24.0\\
    Params & 371M & 840M \\  
    Layers & 24 & 36  \\ 
    Embed Dim & 1024 & 1280 \\
    Heads & 8 & 10 \\ 
    \hline
    \end{tabular}
    \caption{Detailed architecture hyperparmeters. The left model column represents the default model described in the main paper, while the right column indicates the large model that will be presented in the next section.
    % The result of the large models will be reported in the Supplementary Materials.
    % We follow the standard convention that the hidden/embedding dimension of transformers is equal to the head dimension multiplied by the number of heads. 
    \label{tab:arch_hparam}}
    \end{table}
\egroup