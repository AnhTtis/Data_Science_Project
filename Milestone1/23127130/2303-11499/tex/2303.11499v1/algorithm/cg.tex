%\vspace{-2mm}
\LinesNotNumbered

\begin{algorithm}
\begin{small}

%\label{algo:inter-op}
\caption{Block Conjugate Gradient. 'prev' and 'cur' stand for previous and current. Only lines with tensor operations inside the loop are numbered.}\label{alg:cg}
$R_0=B-AX_0$\\
$P_0=R_0$\\
$prev=0$\\
\For{iteration=1,2,3...}
{
\nl $S_{prev}=A.P_{prev}$\\
\nl $\Delta=P^{T}_{prev}.S_{prev}$ and $\Lambda=\Delta^{-1}.\Gamma_{prev}$\\
\nl $X_{cur}=X_{prev}+P_{prev}.\Lambda$\\
\nl $R_{cur}=R_{prev}-S_{prev}.\Lambda$\\
\nl $\Gamma_{cur}=R^{T}_{cur}.R_{cur}$\\
\If{$all(diag(\Gamma_{cur})\leq \in)$}
{
    break
}
\nl $\Phi=\Gamma^{-1}_{prev}.\Gamma_{cur}$\\
\nl $P_{cur}=R_{cur}+P_{prev}.\Phi$ \\

$prev=cur$\\
$cur++$\\

}
\textbf{Return} $X_{cur}$
\end{small}

\end{algorithm}

\begin{comment}

  \nl   $S'(m,n)=A(m,k)*P'(k,n)$     \\
 \nl   $\Delta (n,n)=P'^{T}(n,k)*S'(k,n)$ and $\Lambda (n,n)=\Delta ^{-1}(n,k)*\Gamma (k,n)$ \\
 \nl   $X(m,n)=X'(m,n)+P'(m,k)*\Lambda (n,n)$ \\
\nl    $R(m,n)=R'(m,n)-S'(m,k)*\Lambda (n,n)$ \\
 \nl   $\Gamma (n,n)=R^{T}(n,k)*R(k,n)    $  \\
\If{$all(diag(\Gamma)\leq \in)$}
{
    break
}
\nl    $\Phi(n,n)=\Gamma ^{-1}(n,k)*\Gamma (k,n)$ \\
\nl $P(m,n)=R(m,n)+P'(m,k)*\Phi (n,n)$\\

\end{comment}

