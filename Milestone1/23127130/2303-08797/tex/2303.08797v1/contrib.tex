Overall, the approach introduced in this paper is a versatile way to build generative models, with many attractive features that we now summarize.

%The method proposed in this paper has several appealing theoretical and practical properties:
\begin{itemize}[leftmargin=0.2in]
    \item Due to the inclusion of the latent variable, the stochastic interpolant defined in Section~\ref{sec:si:gm} has a probability distribution that is absolutely continuous with respect to the Lesbegue measure, with a density that satisfy a first order transport equation (TE) as well as forward and backward Fokker-Planck equations (FPE) with  tunable diffusion coefficients. These equations are given in Section~\ref{sec:cont:eq}.
    \item The drift coefficients entering the TE and the FPE are smoothed spatially by the presence of the latent variable. These coefficients are also the unique minimizers of quadratic objective functions, given in Section~\ref{sec:cont:eq}, which are readily amenable to empirical estimation using the available data.
    \item Due to the inclusion of the latent variable, our approach gives a new loss for the score of the time-dependent PDF of the interpolant, which we give in Section~\ref{sec:cont:eq}. This score enters as one component of the drifts in the FPE.
    \item We can readily derive ordinary differential equations (ODE) as well as forward and backward stochastic differential equations (SDE) associated with the TE and the forward and backward FPE, respectively. These ODE/SDE are given in Section~\ref{sec:generative} and can be used as deterministic or stochastic generative models, with the possibility to again tune their level of diffusivity. 
    \item We show that the approach controls the likelihood of the SDE-based models, generalizing the ScoreFlow approach from score-based diffusion~\cite{song2021mle}. By contrast, regressing the drift alone is insufficient in general to bound the  likelihood  with ODE-based models, which require more advanced learning schemes to ensure that the Fisher divergence is also minimized. This is discussed in Section~\ref{sec:likelihood_bounds}, where we also show how to optimally tune the level of diffusivity as a function of the error of two components of the drifts.
    \item We develop a general formula for likelihood evaluation of generative models based on stochastic differential equations that serves as a natural counterpart to the continuous change-of-variables formula that is commonly used to compute the likelihood of a deterministic flow. This is discussed in Section~\ref{sec:density}, where we also show how to estimate the cross-entropy.
    \item The flexibility of design of the stochastic interpolant is highlighted in Section~\ref{sec:practical}, where we show how the latent variable can be adapted to various tasks (Section~\ref{sec:reg:noise}) and how the diffusivity can be tuned for better accuracy (Section~\ref{sec:sde:ode}), confirming the picture from the likelihood bounds derived earlier.
    \item Stochastic interpolants admit a simplified, one-sided version in the special case when $\rho_1$ is a Gaussian density. This is discussed in Section~\ref{sec:onesided}, and these one-sided stochastic interpolants allows us to compare our approach with score-based diffusion models (SBDM) in Section~\ref{sec:SBDM}. 
    \item Our approach is amenable to a bias-free variant of the rectification procedure proposed in~\cite{liu2022}, as discussed in Section~\ref{sec:rect}.
    \item Our approach solves the Schr\"odinger bridge problem between two densities when maximizing the loss over the interpolant, as discussed in Section~\ref{sec:sb}.
    \item We highlight the performance of the method on synthetic examples throughout the paper, in particular using Gaussian mixture models for which the drifts are available analytically (as shown in Appendix~\ref{app:Gauss:mixt}).
\end{itemize}

The above list of features and contributions shows that the proposed method conveniently houses many modeling goals under one roof: it forms a connection between arbitrary densities (allowing for the incorporation of prior knowledge and to directly perform data-to-data translation), reaches the target density on a finite time interval, is versatile in the way it can be adapted to various tasks by exploiting the inherent flexibility in the choice of interpolant, and remains bias-free for any choice of the latent variable amplitude and the noise strength, which can both be tuned as model hyper-parameter after training. The method therefore allows us to theoretically and empirically explore the best design choices for learnable  diffusive processes, as well as the resulting trade-off between ODE and SDE methods for generative models. 