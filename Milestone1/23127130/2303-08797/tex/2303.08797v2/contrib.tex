The approach introduced in this paper is a versatile way to build generative models that has many attractive features, which we now summarize.

\begin{itemize}[leftmargin=0.2in]
    \item Due to the inclusion of the latent variable, the stochastic interpolant defined in Section~\ref{sec:si:gm} has a probability distribution that is absolutely continuous with respect to the Lebesgue measure, with a density that satisfies a first order transport equation (TE) as well as forward and backward Fokker-Planck equations (FPEs) with  tunable diffusion coefficients. These equations are given in Section~\ref{sec:cont:eq}.
    \item The drift coefficients entering the TE and the FPE are smoothed spatially by the presence of the latent variable. These coefficients are also the unique minimizers of quadratic objective functions, given in Section~\ref{sec:cont:eq}, which are amenable to empirical estimation using the available data.
    \item Due to the inclusion of the latent variable, our approach gives a new loss for the score of the time-dependent density of the interpolant, which we give in Section~\ref{sec:cont:eq}. This score enters as one component of the drifts in the FPE, and it can also be related to the drift of the TE.
    \item We can readily derive ordinary differential equations as well as forward and backward stochastic differential equations associated with the TE and the forward and backward FPE, respectively. These ODEs and SDEs are given in Section~\ref{sec:generative} and can be used as generative models with the possibility to tune the level of diffusivity. 
    \item We show that our approach controls the likelihood of our SDE-based models, generalizing the ScoreFlow approach from score-based diffusion~\cite{song2021mle}. By contrast, regressing the drift alone is insufficient in general to bound the  likelihood  with ODE-based models, which require more advanced learning schemes to ensure that the Fisher divergence is also minimized. This is discussed in Section~\ref{sec:likelihood_bounds}, where we show how to optimally tune the level of diffusivity.
    \item We develop a general formula for likelihood evaluation of generative models based on stochastic differential equations that serves as a natural counterpart to the continuous change-of-variables formula that is commonly used to compute the likelihood of a deterministic flow. This is discussed in Section~\ref{sec:density}, where we also show how to estimate the cross-entropy.
    \item Design flexibility is highlighted in Section~\ref{sec:practical}, where  we show how the stochastic interpolant can be adjusted to specific generative modeling tasks (Section~\ref{sec:reg:noise}) and how the diffusivity can be tuned for better accuracy (Section~\ref{sec:sde:ode}), confirming the picture from the likelihood bounds derived earlier.
    \item Stochastic interpolants admit a simplified, one-sided version in the special case when $\rho_1$ is a Gaussian density. This setting is discussed in Section~\ref{sec:onesided}, and it allows us to compare our approach with score-based diffusion models (SBDM) in Section~\ref{sec:SBDM}.  
    \item Our approach is amenable to a bias-free variant of the rectification procedure proposed in~\cite{liu2022}, as discussed in Section~\ref{sec:rect}.
    \item Stochastic interpolants allow us to realize generative models built on stochastic bridges in a simpler way that avoids usage of Doob's $h$-transform and is amenable to more direct sampling, as discussed  Section~\ref{sec:stoch:bridges}.
    \item Our approach solves the Schr\"odinger bridge problem between two densities when maximizing the loss over the interpolant, as discussed in Section~\ref{sec:sb}.
    \item We highlight the performance of the method on synthetic examples throughout the paper, in particular using Gaussian mixture models for which the drifts are available analytically (as shown in Appendix~\ref{app:Gauss:mixt}).
\end{itemize}

The above list of features and contributions shows that the proposed method conveniently houses many modeling goals under one roof, allowing us to theoretically and empirically explore the best design choices for learnable  diffusive processes, as well as the resulting trade-offs between ODE and SDE methods for generative models. 