
% We reported the models' accuracy the same way as human accuracy by calculating on the consonant and vowel of the target character and ignored the tone. For the test set, we count the prediction as correct when it matches one of pinyins of polyphones\Lingyuin{We already address it in footnote 6 in section 3. We could move it there if needed.}. The results are presented in Table \ref{tab:model}, shown as \dall in the upper parts of the table (no shuffle, no tone). 



% \subsubsection{Impact of character frequency}
% \Lingyuin{\dhigh and \dmid, the dev/test acc doesn't matter so much, it is mainly designed for comparison with human data.}
% Generally, \dallf has similar scores to \dall on both dev and test set\footnote{\dallf is slightly better than \dall with tone and worse without tone, see subsection \ref{sec: result_tone}.}, and \dmid and \dhigh are worse with less training data. This suggests that the Chinese character pinyin doesn't have a strong correlation with character frequency.

% \subsubsection{Impact of generated pinyin order}
% While traditional practice is to generate left-to-right, sometimes generating right-to-left will achieves better performance on some tasks, e.g., English to Japanese translation \cite{watanabe-sumita-2002-bidirectional}, and further inspired bidirectional models, e.g., BERT \cite{devlin-etal-2019-bert}. \Lingyuin{May I use BERT as examples here? Elmo is more like an encoder/representations.}

% Therefore, we shuffle the position of consonant and vowel in the output for comparison (\dall, shuffle, no tone). However, the result are mixed for dev/test accuracy. The consonant and vowel accuracy on test set are shown in Table~\ref{tab:consonant}, \ref{tab:vowel}. We could see that the vowel accuracy increases after shuffling under ``no tone" setting, which is sometimes observed in other tasks where the element that generated first will have higher accuracy\cite{}\Lingyuin{I will add citation later}. In general, the generated pinyin order isn't observed to have a strong influence.

% \subsubsection{\label{sec: result_tone}Impact of adding tone in generation}
% \Lingyuin{We didn't mention tone in this paper. We need literature to explain why we don't use tone for standard settings. I would prefer that we explain it in intro/data section.}
% Although people usually drop tones for their analyses because of randomness of tones \Lingyuin{Need citation here.}, we add tone before the `End' token in generation, i.e., after consonant and vowel \footnote{This setting could avoid generating consonant and vowel conditioned on tones.}, and present the results in Table \ref{tab:model} (\dall, no shuffle/shuffle, tone). 

% While the results are still mixed, adding tone for \all generally hurts the models' performance on test set, though adding frequency to the input (\dallf) could improve results for experiments with tones. \Lingyuin{I'm curious whether there are some relationship between tone and frequency.}





% Xiaomeng's table, but (All, tone,) dev & test acc modified
% \subsection{Results}
% \begin{table*}[!t]
% \small
% \centering
%  \begin{tabular}{ll|llll|llll}
%  \toprule
%  \multirow{4}{*}{Variant} & \multirow{4}{*}{Model} & \multicolumn{4}{c|}{Development set accuracy} & \multicolumn{4}{c}{Test set accuracy} \\
%  \cmidrule{3-10}
%  &  & \multicolumn{2}{c}{No Shuffle} & \multicolumn{2}{c|}{Shuffle} & \multicolumn{2}{c}{No Shuffle} & \multicolumn{2}{c}{Shuffle} \\
%  \cmidrule{3-10}
%  &  & No Tone & Tone & No Tone & Tone & No Tone & Tone & No Tone & Tone \\
% \midrule
% All & \base & 60.5 (1.0) & 60.6 (0.9) & 60.9 (1.4) & 61.2 (1.2) & 57.5 (0.9) & 52.0 (4.0) & 54.2 (3.4) & 51.0 (2.1) \\
%  & \labm & \textbf{61.4} (1.3) & 61.3 (1.0) & \textbf{61.4} (1.1) & 61.7 (1.4) & \textbf{58.2} (1.0) & 53.2 (2.5) & 52.3 (1.4) & 52.5 (2.6) \\
%  & \labs & 61.0 (1.1) & 60.7 (1.2) & 61.0 (1.0) & 60.6 (1.2) & 57.5 (1.2) & 52.7 (2.3) & 55.8 (2.8) & 55.3 (2.7) \\
%  & \labmr & 60.2 (1.7) & 60.7 (1.9) & 60.7 (2.3) & 60.7 (1.5) & 57.7 (1.9) & 54.3 (2.0) & \textbf{57.8} (2.5) & 54.8 (1.7) \\
%  & \labsr & 60.1 (1.4) & 60.2 (1.4) & 60.7 (1.6) & 60.3 (1.4) & 57.4 (1.4) & 55.7 (1.9) & 53.2 (3.2) & 53.8 (1.9) \\
%  \midrule
% Mid & \base & 60.9 (1.4) & 57.2 (0.8) & 60.6 (1.6) & 57.9 (0.8) & 57.2 (0.8) & 51.6 (2.5) & 54.7 (3.2) & 51.7 (1.4) \\
%  & \labm & \textbf{61.7} (1.4) & \textbf{58.1} (0.7) &\textbf{62.3} (1.1) & \textbf{58.1} (1.3) & \textbf{58.1} (0.7) & 53.6 (3.5) & 53.3 (2.8) & 53.1 (3.9) \\
%  & \labs & 60.9 (1.8) & 57.5 (1.3) & 60.9 (1.5) & 57.3 (0.9) & 57.5 (1.3) & 53.1 (4.0) & 55.2 (3.0) & \textbf{54.7} (2.5) \\
%  & \labmr & 61.2 (2.2) & 57.2 (1.5) & 60.3 (1.9) & 57.7 (1.4) & 57.2 (1.5) & \textbf{55.3} (2.3) & 56.0 (3.5) & 52.9 (1.4) \\
%  \midrule
%  & \labsr & 60.2 (1.8) & 57.1 (1.7) & 60.5 (1.6) & 57.0 (1.2) & 57.1 (1.7) & 53.7 (1.6) & \textbf{56.5} (3.2) & 52.8 (2.0) \\
% High & \base & 58.2 (1.6) & 54.8 (1.4) & 58.3 (1.4) & 54.2 (1.0) & 54.8 (1.4) & 47.0 (3.4) & 50.5 (1.4) & 47.4 (2.9) \\
%  & \labm & 59.3 (1.0) & 55.3 (1.4) & \textbf{59.8} (0.6) & 55.6 (1.5) & 55.3 (1.4) & 49.2 (2.0) & 50.8 (3.1) & 47.6 (4.5) \\
%  & \labs & \textbf{59.4} (1.2) & 55.0 (1.3) & 58.9 (2.3) & 54.9 (1.7) & 55.0 (1.3) & \textbf{50.4} (2.2) & 51.7 (2.9) & 48.0 (2.8) \\
%  & \labmr & 59.1 (2.4) & \textbf{55.8} (1.9) & 59.1 (1.9) & \textbf{56.2} (1.5) & \textbf{55.8} (1.9) & 48.6 (1.7) & 48.8 (3.3) & \textbf{49.8} (2.5) \\
%   & \labsr & 59.3 (1.9) & 55.4 (1.4) & 58.6 (1.0) & 55.1 (0.8) & 55.4 (1.4) & 49.8 (4.1) & \textbf{53.2} (1.8) & 47.4 (1.3) \\
%  \midrule
% $All_{F}$ & \base & 53.5 (3.5) & 50.5 (2.2) & 55.1 (1.6) & 51.2 (2.6) & 50.5 (2.2) & 45.3 (3.0) & 45.0 (2.6) & 44.3 (3.0) \\
%  & \labm & \textbf{55.7} (2.6) & \textbf{52.3} (1.7) & \textbf{56.4} (1.8) & 51.7 (2.0) & \textbf{52.3} (1.7) & 45.3 (2.2) & 44.8 (2.6) & 44.1 (1.9) \\
%   & \labs & 55.1 (4.0) & 51.8 (2.3) & 55.3 (3.9) & 51.7 (3.4) & 51.8 (2.3) & 45.8 (4.1) & 45.8 (4.4) & 43.9 (2.5) \\
%  & \labmr & 55.6 (3.1) & 51.5 (3.3) & 55.7 (2.7) & 51.2 (3.2) & 51.5 (3.3) & \textbf{47.1} (1.4) & 47.0 (3.5) & \textbf{47.8} (1.9) \\
%   & \labsr & 54.9 (4.4) & 51.4 (2.5) & 55.2 (3.7) & \textbf{52.0} (3.5) & 51.4 (2.5) & 47.0 (1.1) & \textbf{47.2} (1.0) & 46.3 (3.0) \\
%  \bottomrule
% %  \multicolumn{10}{l}{$All_F$ is the model adding frequency label with all training data.}
% \end{tabular}
% \caption{\label{tab:model}The mean accuracy of dev and test for different models, where $All_F$ is the model adding frequency label with all training data. The standard deviation is in apprentices. \Lingyuin{The results for tones are not correct! I'll fix it. Maybe I'll add consonant and vowel test acc later.}}
% \end{table*}

%NoToneTable\begin{table*}[!t]
%\centering
%\small
%\begin{tabular}{llcc|cc}
%\toprule
 % &  & \multicolumn{2}{c}{No shuffle} & \multicolumn{2}{c}{Shuffle} \\
% \subsubsection*{Dev Accuracy\Xiaomengin{Might Delete}}
% \labm achieves the highest accuracy on dev set among Tone and Shuffle conditions, which is expected as we use ground truth of phonetic radical here\Lingyuin{Not appropriate, will modify. ``think what threw me off there is that LABELm is best on dev but not on test, so the comment that it did well on dev because of the manual annotations made me think you were saying that the manual annotations are only relevant to dev, not test. Since it did well on dev but not test, then maybe the reason is not due to the manual annotations but rather something else (related to the difference between dev and test)?"}, suggesting that knowing the phonetic radical would improve model performance. However, although adding regularities has lower accuracy on dev set, \labmr and \labsr outperforms the other three models by 2.0 - 3.3\% accuracy, presumably because our dev and test set have different data distributions\footnote{Same trends are observed in our experiments in initial state before we consider different pinyins of polyphones.}. Since regularities are of higher level, it might increase the robustness of the model.\Lingyuin{Are rare words pronunciations more reliable on regularities? If we search on how they are named.}
%\begin{table*}[!t]
%\small
%\centering
 %\begin{tabular}{ll|llll|llll}
 %\toprule
 %\multirow{4}{*}{Variant} & \multirow{4}{*}{Model} & \multicolumn{4}{c|}{Development set accuracy} & \multicolumn{4}{c}{Test set accuracy} \\
 %\cmidrule{3-10}
 %&  & \multicolumn{2}{c}{No Shuffle} & \multicolumn{2}{c|}{Shuffle} & \multicolumn{2}{c}{No Shuffle} & \multicolumn{2}{c}{Shuffle} \\
 %\cmidrule{3-10}
 %&  & No Tone & Tone & No Tone & Tone & No Tone & Tone & No Tone & Tone \\
%\midrule
%\multirow{5}{*}{\dall} 
 %& \base & 60.9(1.4) & 60.6(0.9) &60.6(1.6) &61.2(0.5) & 50.3(3.8) & 48.3(3.3) & 51.0(4.8) & 45.7(4.2) \\
 %& \labm & \textbf{61.7(1.4)} & \textbf{61.3(1.1)} & \textbf{62.3(1.1)} & \textbf{61.7(1.5)} & 49.7(2.2) & 48.0(5.7) & 50.0(3.7) & 46.7(2.4) \\
 %& \labs & 60.9(1.8) & 60.7(1.8) & 60.9(1.5) & 60.6(0.7) & 48.7(3.2) & 47.0(6.8) & 48.0(4.6) & 49.7(4.8) \\
 %& \labmr & 61.2(2.2) &60.7(1.9) &60.3(1.9) &60.7(1.7) & \textbf{52.3(3.8)} & 50.7(3.5) & \textbf{52.0(4.9)} & \textbf{50.7(2.2)} \\
 %& \labsr & 60.2(1.8) & 60.2(1.4) & 60.5(1.6) & 60.3(1.2) & 52.0(1.4) & \textbf{52.7(4.3)} & \textbf{52.0(4.5)} & 48.7(7.2) \\
 %\midrule
%\multirow{5}{*}{\dhigh} 
 %& \base & 53.5(3.5) & 54.7(4.3) & 55.1(1.6) & 54.9(3.2) & 38.7(3.2) & 38.0(4.6) & 40.0(2.6) & 40.7(4.3) \\
 %& \labm & \textbf{55.7(2.6)} & \textbf{56.2(2.2)} & \textbf{56.4(1.8)} & \textbf{56.0(2.4)} & 38.7(2.7) & 41.0(4.2) & 38.3(3.3) & 41.3(4.6) \\
 %& \labs & 55.1(4.0) & 55.8(3.8) & 55.3(3.9) & \textbf{56.0(4.7)} & 39.0(4.3) & 41.0(4.5) & 38.7(4.3) & 41.0(4.0) \\
 %& \labmr & 55.6(3.1) & 55.9(5.0) & 55.7(2.7) & 55.9(4.0) & \textbf{43.3(2.4)} & \textbf{43.3(3.3)} & 42.0(3.6) & 40.7(3.7) \\
 %& \labsr & 54.9(4.4) & 55.4(3.7) & 55.2(3.7) & 55.4(4.1) & 42.7(4.0) & 41.7(3.5) & \textbf{42.3(3.2)} & \textbf{43.3(2.0)} \\
 %\midrule
%\multirow{5}{*}{\dmid} 
 %& \base & 58.2(1.6) & 58.1(1.8) & 58.3(1.4) & 58.4(1.4) & 45.3(2.7) & 44.7(1.4) & 42.7(4.2) & 45.0(2.4) \\
 %& \labm & 59.3(1.0) & \textbf{59.8(1.0)} & \textbf{59.8(0.6)} & 59.5(1.5) & 46.0(2.5) & 42.7(1.9) & 46.7(3.9) & 45.0(5.1) \\
 %& \labs & \textbf{59.4(1.2)} & 59.4(1.8) & 58.9(2.3) & 58.8(2.6) & \textbf{49.0(2.2)} & 47.3(3.5) & 49.0(4.5) & 43.7(4.6) \\
 %& \labmr & 59.1(2.4) & \textbf{59.8(1.4)} & 59.1(1.9) & \textbf{59.8(1.4)} & 44.7(5.1) & \textbf{48.3(4.9)} & 43.7(4.9) & \textbf{47.3(4.5)} \\
 %& \labsr & 59.3(1.9) & 59.1(1.6) & 58.6(1.0) & 59.4(2.1) & 48.3(5.5) & 47.7(1.9) & \textbf{51.3(4.3)} & 46.0(4.5) \\
 %\midrule
%\multirow{5}{*}{\dallf} 
 %& \base & 60.5(1.0) & 60.8(1.4) & 60.9(1.4) & 61.7(1.2) & 47.0(2.5) & 50.7(3.0) & 49.7(3.6) & 47.7(2.5) \\
 %& \labm & \textbf{61.4(1.3)} & \textbf{61.9(1.3)} & \textbf{61.4(1.1)} & \textbf{62.2(2.0)} & 45.7(7.3) & 47.0(2.5) & 46.3(4.3) & 47.7(3.2) \\
 %& \labs & 61.0(1.1) & 60.9(1.2) & 61.0(1.0) & 60.9(1.4) & 47.0(2.5) & \textbf{53.0(3.8)} & 52.3(5.5) & 50.0(7.2) \\
 %& \labmr & 60.2(1.7) & 60.6(2.1) & 60.7(2.3) & 60.9(2.2) & \textbf{52.0(0.7)} & 52.7(1.9) & \textbf{55.0(3.7)} & \textbf{50.7(3.5)} \\
 %& \labsr & 60.1(1.4) & 60.3(1.3) & 60.7(1.6) & 60.2(2.1) & 49.7(2.2) & 50.7(3.0) & 48.7(3.2) & 50.0(6.7)\\
 %\bottomrule
%\end{tabular}
%\caption{\label{tab:model}The average accuracy (\%) of different models on dev and test set, where \dallf is the model adding frequency label with all training data. The standard deviation is in apprentices.}
%\end{table*}

%Data & Model & dev & test & dev & test \\
%\midrule
%All & \base & 60.9 (1.4) & 53.3 (3.5) & 60.6 (1.6) & 54.7 (3.2) \\
% & \labm & \textbf{61.7} (1.4) & 53.2 (1.9) & \textbf{62.3} (1.1) & 53.3 (2.8) \\
% & \labmr & 61.2 (2.2) & 55.2 (2.0) & 60.3 (1.9) & 56.0 (3.5) \\
% & \labs & 60.9 (1.8) & 53.2 (2.2) & 60.9 (1.5) & 55.2 (3.0) \\
% & \labsr & 60.2 (1.8) & \textbf{56.3} (3.0) & 60.5 (1.6) & \textbf{56.5} (3.2) \\
%\midrule
%High Frequency & \base & 55.5 (1.7) & 48.3 (1.6) & 56.9 (2.5) & 47.2 (1.5) \\
% & \labm & 57.1 (1.4) & 49.0 (5.3) & 57.8 (1.2) & 49.0 (1.5) \\
% & \labmr & 57.0 (2.0) & \textbf{50.3} (3.3) & 57.3 (0.5) & \textbf{49.8} (2.8) \\
% & \labs & 56.9 (0.9) & 49.7 (1.8) & 57.3 (1.4) & 49.7 (3.1) \\
% & \labsr & \textbf{57.5} (1.6) & 49.7 (0.7) & \textbf{58.1} (1.2) & 49.5 (1.5)\\
% \bottomrule
%\end{tabular}
%\caption{The mean accuracy of dev and test for different models with all data and high frequency data. The standard deviation is in apprentices. The bold numbers are the highest accuracy among different models.}
%\label{tab:model}
%\end{table*}

%\begin{table*}[!t]
%\small
%\centering
%\begin{tabular}{llll|ll}
%\toprule
% &  & \multicolumn{2}{c}{No shuffle} & \multicolumn{2}{c}{Shuffle} \\
% Training Data & Model & dev acc & test acc & dev acc & test acc \\
%\midrule
%All & \base & 57.2 (0.8) & 51.6 (2.5) & 57.9 (0.8) & 51.7 (1.4) \\
% & \labm & \textbf{58.1} (0.7) & 53.6 (3.5) & \textbf{58.1} (1.3) & 53.1 (3.9) \\
% & \labmr & 57.2 (1.5) & \textbf{55.3} (2.3) & 57.7 (1.4) & 52.9 (1.4) \\
% & \labs & 57.5 (1.3) & 53.1 (4.0) & 57.3 (0.9) & \textbf{54.7} (2.5) \\
% & \labsr & 57.1 (1.7) & 53.7 (1.6) & 57.0 (1.2) & 52.8 (2.0) \\
% \midrule
%High Frequency & \base & 51.9 (1.3) & 49.1 (1.4) & 51.9 (1.3) & 46.9 (1.4) \\
% & \labm & \textbf{53.6} (1.0) & \textbf{49.6} (1.1) & \textbf{53.7} (1.5) & 48.4 (1.7) \\
% & \labmr & 52.9 (1.5) & 48.9 (2.9) & 53.6 (1.0) & \textbf{49.2} (2.3) \\
% & \labs & 53.3 (1.2) & 48.4 (1.3) & 54.0 (1.1) & 49.0 (3.0) \\
% & \labsr & 53.5 (0.7) & 47.0 (1.4) & 53.2 (0.7) & 47.8 (2.2)\\
% \bottomrule
%\end{tabular}
%\caption{The mean accuracy of dev and test for different models with all data and high frequency data. The standard deviation is in apprentices. The bold numbers are the highest accuracy among different models.}
%\label{tab:model}
%\end{table*}
% \subsubsection*{Test Accuracy}\Xiaomengin{New Added Section}