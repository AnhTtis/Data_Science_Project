\section{Introduction}
\label{section:!}

Many aspects of language can be characterized as quasi-regular: the relationship between inputs and outputs is systematic but allow many exceptions. The grapheme-phoneme mapping is an example of such quasi-regularity. For example, the letter string `\textit{-ave}' in English is regularly pronounced as /e\textsci v/ in \textsc{gave}, \textsc{save}, with the exception of /\ae v/ in \textsc{have}. And human speakers can easily grasp both patterns, e.g., in a nonce word naming experiment, most speakers pronounced the word \textsc{tave} as /te\textsci v/, while some pronounced it as /t\ae v/ \cite{glushko1979organization}. 

To explain the grapheme-phoneme mapping process, many models have been proposed, among which the Dual Route Cascaded (DRC) model and the connectionist model are the two most influential yet opposite models. The DRC model \citep{coltheart2001drc, coltheart1978lexical} proposes that the grapheme-phoneme mapping is implemented in two separate routes: a lexical route that directly maps the word's spelling to its pronunciation through a dictionary-like lookup procedure\footnote{The lexical route is usually applied to sight words (e.g., `of', `and') and words that don't follow grapheme-phoneme correspondence rules (e.g., `colonel').}, and a non-lexical route that applies the grapheme-phoneme corresponding `rules' to convert the letters to their corresponding pronunciation. The implementation of the DRC model requires domain-specific knowledge, such as spelling to sound rules. In contrast, the connectionist model \citep{seidenberg1989distributed, plaut1996understanding} proposed that a word's pronunciation is generated through a neural network that takes the orthographic representation as the input and outputs the phonological representation, which does not require specific knowledge of grapheme-phoneme correspondence rules. Both models can explain various behaviors in word identification, such as the faster identification of frequent words compared to infrequent ones. Therefore, there is still an ongoing debate about which model better captures the grapheme-phoneme mapping process. 

However, most of these two models were tested on alphabetic languages (e.g., English and German), and it is still unclear how would these models be generalized to a non-alphabetic language, such as Chinese. The DRC model seems to be unfit for Chinese because there are no regularities in Chinese that can be defined as grapheme-phoneme corresponding rules \citep{yang2009simulating}. In addition, \citet{coltheart2001drc} asserted that ``the Chinese, Japanese and Korean writing systems are structurally so different from the English writing system, that a model like the DRC model would simply not be applicable.'' (p.236). Thus the connectionist model is the only candidate. The majority (81\%) of Chinese characters are phono-semantic compounds \cite{li1993analysis}, which consist of a phonetic radical that contains pronunciation information (denoted by pinyin),\footnote{Chinese characters use pinyin to represent the pronunciation. The pinyin system consists of 24 syllable initials (mostly contain a consonant), 34 syllable finals (mostly contain a vowel or vowels), and 4 tones.} and a semantic radical that contains semantic information.\footnote{The phonetic radical and semantic radical are mutually exclusive, and they are defined in the ancient Chinese dictionary 《說文解字》\textit{`Shuowen Jiezi'}.} For example, for the character 晴 ($<$qing2$>$ `sunny'), the left side 日 ($<$ri4$>$, `sun') is the semantic radical, and the right side 青 ($<$qing1$>$, `blue') is the phonetic radical. While the phonetic radical does not contain componential information about the pronunciation, e.g., the first part of the phonetic radical does not represent the first phoneme (e.g., consonant)/syllable onset as letter strings, the relationship between the phonetic radical's pinyin and the character's pinyin is also quasi-regular. Ignoring the tonal differences, the character's pinyin can be categorized into 4 types \cite{fang1986consistency}: \regular, the same as the phonetic radical's pinyin; \alliterating, deviating in the syllable final; \rhyming, deviating in the syllable onset; and \rad, varying in both syllable onset and final (see Table \ref{tab:0} for examples). The process to pronounce an unknown character involves two steps, where the first step is to identify the phonetic radical, and the second step is to apply the regularity pattern of the pinyin. However, there are no reliable cues to identify the phonetic radical, and the regularity patterns are quite arbitrary \citep{yang2009simulating}. How do Chinese speakers name an unknown character, and how well can the neural models capture the Chinese speakers' behaviors?

\begin{table}[t!]
\centering
\small
\begin{tabular}{p{0.2\linewidth}|p{0.65\linewidth}}
\toprule
 & Example characters \\
\midrule
\regular & 清, 情, 圊, 晴 -- $<$\textbf{qing}$>$ \\
\alliterating & 倩，輤 $<$\textbf{q}ian$>$\\
\rhyming & 精, 靖, 菁 -- $<$j\textbf{ing}$>$ \\
\rad & 猜 $<$cai$>$, 靚 $<$liang$>$, 靛 $<$dian$>$ \\ \bottomrule
\end{tabular}
\caption{\small Examples of characters with the phonetic radical 青 $<$qing$>$, sorted into different regularity types. Syllable onsets and finals are \textbf{bold} when they are the same with the phonetic radical.}
\label{tab:0}
\end{table}

In our study, we first collected human speakers' answers on unknown character naming, since there is no study investigating how Chinese adults read unknown characters.\footnote{Previous studies have focused on children's behavior on unknown character naming and found that children made errors in identifying the incorrect phonetic radical, as well as applying the incorrect regularity pattern \cite{lam2008exploratory, lam2014elaborating}.} We then trained a set of sequence-to-sequence transformer models with different settings on 4,281 phono-semantic characters. Neither human speakers nor models can name the unknown characters accurately, but the transformers have a slightly better average accuracy (47.4\%) than the human speakers (45.3\%). We then evaluated how closely the results of our aggregated transformers matched those of the human participants, in aspects of the variety of answer types and answer overlaps. In general, both the transformers and human speakers are able to identify the phonetic radical correctly and apply all 4 types of regularities to infer the pinyin, and the transformer models show a high correlation with human data in the proportion of each regularity type. In addition, 
there is a considerable amount of agreement between the answers generated by our models and those given by humans.
Our results demonstrate that transformer models can well capture human behavior in unknown Chinese character naming. 
