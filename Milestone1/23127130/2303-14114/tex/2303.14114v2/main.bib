@article{journals/corr/RedmonDGF15,
  author    = {Joseph Redmon and Santosh Kumar Divvala and Ross B. Girshick and Ali Farhadi},
  title     = {You Only Look Once: Unified, Real-Time Object Detection},
  journal   = {CoRR},
  volume    = {abs/1506.02640},
  year      = {2015},
  url       = {http://arxiv.org/abs/1506.02640},
  eprinttype = {arXiv},
}

@article{Berner2014DynamicVS,
  title={Dynamic vision sensor for low power applications},
  author={Raphael Berner and Patrick Lichtsteiner and Tobi Delbruck and J. Kim and K. Lee and J. Lee and K. Park and T. J. Kim and Hyungdon Ryu},
  journal={The 18th IEEE International Symposium on Consumer Electronics (ISCE 2014)},
  year={2014},
  pages={1-2}
}

@article{yurtsever2020survey,
  title={A survey of autonomous driving: Common practices and emerging technologies},
  author={Yurtsever, Ekim and Lambert, Jacob and Carballo, Alexander and Takeda, Kazuya},
  journal={IEEE access},
  volume={8},
  pages={58443--58469},
  year={2020},
  publisher={IEEE}
}

@article{Vidhya2019ImageND,
  title={Image Noise Declining Approaches by Adopting Effective Filters},
  author={R. Vidhya and Pola Ashritha and M.Ajay Kumar and Rajesha. N},
  journal={2019 International Conference on Emerging Trends in Science and Engineering (ICESE)},
  year={2019},
  volume={1},
  pages={1-5}
}

@article{wen2022deep,
  title={Deep learning-based perception systems for autonomous driving: A comprehensive survey},
  author={Wen, Li-Hua and Jo, Kang-Hyun},
  journal={Neurocomputing},
  year={2022},
  publisher={Elsevier}
}

@article{ma20223d,
  title={3D object detection from images for autonomous driving: a survey},
  author={Ma, Xinzhu and Ouyang, Wanli and Simonelli, Andrea and Ricci, Elisa},
  journal={arXiv preprint arXiv:2202.02980},
  year={2022}
}

@article{lu2022computer,
  title={Computer vision for solid waste sorting: A critical review of academic research},
  author={Lu, Weisheng and Chen, Junjie},
  journal={Waste Management},
  volume={142},
  pages={29--43},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{snyder2021thor,
  title={Thor: A deep learning approach for face mask detection to prevent the COVID-19 pandemic},
  author={Snyder, Shay E and Husari, Ghaith},
  booktitle={SoutheastCon 2021},
  pages={1--8},
  year={2021},
  organization={IEEE}
}

@article{feng2019computer,
  title={Computer vision algorithms and hardware implementations: A survey},
  author={Feng, Xin and Jiang, Youni and Yang, Xuejiao and Du, Ming and Li, Xin},
  journal={Integration},
  volume={69},
  pages={309--320},
  year={2019},
  publisher={Elsevier}
}

@article{hafiz2023formula,
  title={Formula-Driven Supervised Learning in Computer Vision: A Literature Survey},
  author={Hafiz, Abdul Mueed and Hassaballah, Mahmoud and Binbusayyis, Adel},
  journal={Applied Sciences},
  volume={13},
  number={2},
  pages={723},
  year={2023},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@article{moeslund2001survey,
  title={A survey of computer vision-based human motion capture},
  author={Moeslund, Thomas B and Granum, Erik},
  journal={Computer vision and image understanding},
  volume={81},
  number={3},
  pages={231--268},
  year={2001},
  publisher={Elsevier}
}

@article{zhou2022computer,
  title={Computer vision techniques in manufacturing},
  author={Zhou, Longfei and Zhang, Lin and Konz, Nicholas},
  journal={IEEE Transactions on Systems, Man, and Cybernetics: Systems},
  year={2022},
  publisher={IEEE}
}

@article{gonzalez2023survey,
  title={A Survey on Underwater Computer Vision},
  author={Gonz{\'a}lez-Sabbagh, Salma P and Robles-Kelly, Antonio},
  journal={ACM Computing Surveys},
  year={2023},
  publisher={ACM New York, NY}
}

@article{doi:10.1080/08839514.2022.2032924,
author = {Irem Ulku and Erdem Akagündüz},
title = {A Survey on Deep Learning-based Architectures for Semantic Segmentation on 2D Images},
journal = {Applied Artificial Intelligence},
volume = {36},
number = {1},
pages = {2032924},
year  = {2022},
publisher = {Taylor & Francis},
doi = {10.1080/08839514.2022.2032924},

URL = { 
    
        https://doi.org/10.1080/08839514.2022.2032924
    
    

},
eprint = { 
    
        https://doi.org/10.1080/08839514.2022.2032924
    
    

}

}

@article{wang2023knowledge,
  title={Knowledge augmented broad learning system for computer vision based mixed-type defect detection in semiconductor manufacturing},
  author={Wang, Junliang and Gao, Pengjie and Zhang, Jie and Lu, Chao and Shen, Bo},
  journal={Robotics and Computer-Integrated Manufacturing},
  volume={81},
  pages={102513},
  year={2023},
  publisher={Elsevier}
}

@article{osti_1639074,
title = {Performance comparison of state-of-the-art high-speed video cameras for scientific applications},
author = {Manin, Julien Luc and Skeen, Scott A. and Pickett, Lyle M.},
abstractNote = {Time-resolved visualization of fast processes using high-speed digital video-cameras has been widely used in most fields of scientific research for over a decade. In many applications, high-speed imaging is used not only to record the time history of a phenomenon but also to quantify it, hence requiring dependable equipment. Important aspects of two-dimensional imaging instrumentation used to qualitatively or quantitatively assess fast-moving scenes include sensitivity, linearity, as well as signal-to-noise ratio (SNR). Under certain circumstances, the weaknesses of commercially available high-speed cameras, i.e., sensitivity, linearity, image lag, etc., render the experiment complicated and uncertain. Our study evaluated two advanced CMOS-based, continuous-recording, high-speed cameras available at the moment of writing. In this work, various parameters, potentially important toward accurate time-resolved measurements and photonic quantification, have been measured under controlled conditions on the bench, using scientific instrumentation. Testing procedures to measure sensitivity, linearity, SNR, shutter accuracy, and image lag are proposed and detailed. The results of the tests, comparing the two high-speed cameras under study, are also presented and discussed. Results show that, with careful implementation and understanding of their performance and limitations, these high-speed cameras are reasonable alternatives to scientific CCD cameras, while also delivering time-resolved imaging data.},
doi = {10.1117/1.oe.57.12.124105},
journal = {Optical Engineering},
number = 12,
volume = 57,
place = {United States},
year = {2018},
month = {12}
}

@article{doi:10.1179/136821909X12490326247524,
author = {P W W Fuller},
title = {An introduction to high speed photography and photonics},
journal = {The Imaging Science Journal},
volume = {57},
number = {6},
pages = {293-302},
year  = {2009},
publisher = {Taylor & Francis},
doi = {10.1179/136821909X12490326247524},
URL = { 
        https://doi.org/10.1179/136821909X12490326247524
},
eprint = { 
        https://doi.org/10.1179/136821909X12490326247524
}
}

@article{lee2020long,
  title={Long-term displacement measurement of full-scale bridges using camera ego-motion compensation},
  author={Lee, Junhwa and others},
  journal={Mechanical Systems and Signal Processing},
  volume={140},
  pages={106651},
  year={2020},
  publisher={Elsevier}
}

@book{schwartz2021retinal,
  title={Retinal Computation},
  author={Schwartz, Greg},
  year={2021},
  publisher={Academic Press}
}

@inproceedings{kinsman2012ego,
  title={Ego-motion compensation improves fixation detection in wearable eye tracking},
  author={Kinsman, Thomas and others},
  booktitle={Proceedings of the Symposium on Eye Tracking Research and Applications},
  pages={221--224},
  year={2012}
}

@article{DBLP:journals/corr/LinMBHPRDZ14,
  author    = {Tsung{-}Yi Lin and
               Michael Maire and
               others},
  title     = {Microsoft {COCO:} Common Objects in Context},
  journal   = {CoRR},
  volume    = {abs/1405.0312},
  year      = {2014},
  url       = {http://arxiv.org/abs/1405.0312},
  eprinttype = {arXiv},
  eprint    = {1405.0312},
  timestamp = {Mon, 13 Aug 2018 16:48:13 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/LinMBHPRDZ14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1803-04523,
  author    = {Anton Mitrokhin and
               Cornelia Ferm{\"{u}}ller and
               Chethan Parameshwara and
               Yiannis Aloimonos},
  title     = {Event-based Moving Object Detection and Tracking},
  journal   = {CoRR},
  volume    = {abs/1803.04523},
  year      = {2018},
  url       = {http://arxiv.org/abs/1803.04523},
  eprinttype = {arXiv},
  eprint    = {1803.04523},
  timestamp = {Mon, 13 Aug 2018 16:46:57 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1803-04523.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1709-09323,
  author    = {Nicholas F. Y. Chen},
  title     = {Pseudo-labels for supervised learning on event-based data},
  journal   = {CoRR},
  volume    = {abs/1709.09323},
  year      = {2017},
  url       = {http://arxiv.org/abs/1709.09323},
  eprinttype = {arXiv},
  eprint    = {1709.09323},
  timestamp = {Mon, 13 Aug 2018 16:49:15 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1709-09323.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{choudhury20103d,
  title={3D integration technologies for emerging microsystems},
  author={Choudhury, Debabani},
  booktitle={2010 IEEE MTT-S international microwave symposium},
  pages={1--4},
  year={2010},
  organization={IEEE}
}

@ARTICLE{Bhowmik2021-up,
  title    = "Bio-inspired smart vision sensor: toward a reconfigurable
              hardware modeling of the hierarchical processing in the brain",
  author   = "Bhowmik, Pankaj and Pantho, Md Jubaer Hossain and Bobda,
              Christophe",
  abstract = "Biological vision systems inspire processing methods in computer
              vision applications. This paper employs the insights of vision
              systems in hardware and presents a pixel-parallel,
              reconfigurable, and layer-based hierarchical architecture for
              smart image sensors. The architecture aims to bring computation
              close to the sensor to achieve high acceleration for different
              machine vision applications while consuming low power. We
              logically divide the image into multiple regions and perform
              pixel-level and region-level processing after removing
              spatiotemporal redundancy. Those processors use bio-inspired
              algorithms to activate the regions with region of interest of a
              scene. The hierarchical processing breaks the traditional
              sequential image processing and introduces parallelism for
              machine vision applications. Also, we make the hardware design
              reconfigurable even after fabrication to make the hardware
              reusable for different applications. Simulation results show that
              the area overhead and power penalty for adding reconfigurable
              features stay in an acceptable range. We emphasize to maximize
              the operating speed and obtain 800 MHz. Besides, the design saves
              84.01\% and 96.91\% dynamic power at the first and second stages
              of the hierarchy by removing redundant information. Furthermore,
              the sequential deployment of high-level reasoning only on the
              selected regions of the image becomes computationally inexpensive
              to execute a complex task in real time.",
  journal  = "Journal of Real-Time Image Processing",
  volume   =  18,
  number   =  1,
  pages    = "157--174",
  month    =  feb,
  year     =  2021
}

@article{DBLP:journals/corr/abs-1805-04687,
  author    = {Fisher Yu and
               others},
  title     = {{BDD100K:} {A} Diverse Driving Video Database with Scalable Annotation
               Tooling},
  journal   = {CoRR},
  volume    = {abs/1805.04687},
  year      = {2018},
  url       = {http://arxiv.org/abs/1805.04687},
  eprinttype = {arXiv},
  eprint    = {1805.04687},
  timestamp = {Mon, 13 Aug 2018 16:47:46 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1805-04687.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{vibes,
  author={Gregory Schwartz},
  title={Visual Environment Behavioral Simulator},
  year={2023},
  url={https://github.com/SchwartzNU/ViBES},
}

@inproceedings{hu2021v2e,
  title={v2e: From video frames to realistic DVS events},
  author={Hu, Yuhuang and Liu, Shih-Chii and Delbruck, Tobi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1312--1321},
  year={2021}
}

@software{MATLAB,
year = {2022},
author = {The MathWorks Inc.},
title = {MATLAB version: 9.13.0 (R2022b)},
publisher = {The MathWorks Inc.},
address = {Natick, Massachusetts, United States},
url = {https://www.mathworks.com}
}

@inproceedings{majeed2021real,
  title={Real-time surveillance system based on facial recognition using YOLOv5},
  author={Majeed, Fahad and Khan, Farrukh Zeeshan and Iqbal, Muhammad Javed and Nazir, Maria},
  booktitle={2021 Mohammad Ali Jinnah University International Conference on Computing (MAJICC)},
  pages={1--6},
  year={2021},
  organization={IEEE}
}

@article{mantau2022human,
  title={A human-detection method based on YOLOv5 and transfer learning using thermal image data from UAV perspective for surveillance system},
  author={Mantau, Aprinaldi Jasa and Widayat, Irawan Widi and Leu, Jenq-Shiou and K{\"o}ppen, Mario},
  journal={Drones},
  volume={6},
  number={10},
  pages={290},
  year={2022},
  publisher={MDPI}
}

@inproceedings{brungel2021detr,
  title={DETR and YOLOv5: exploring performance and self-training for diabetic foot ulcer detection},
  author={Br{\"u}ngel, Raphael and Friedrich, Christoph M},
  booktitle={2021 IEEE 34th International Symposium on Computer-Based Medical Systems (CBMS)},
  pages={148--153},
  year={2021},
  organization={IEEE}
}

@article{xu2021effective,
  title={Effective face detector based on yolov5 and superresolution reconstruction},
  author={Xu, Qingqing and Zhu, Zhiyu and Ge, Huilin and Zhang, Zheqing and Zang, Xu},
  journal={Computational and Mathematical Methods in Medicine},
  volume={2021},
  pages={1--9},
  year={2021},
  publisher={Hindawi Limited}
}

@article{mohiyuddin2022breast,
  title={Breast tumor detection and classification in mammogram images using modified YOLOv5 network},
  author={Mohiyuddin, Aqsa and others},
  journal={Computational and Mathematical Methods in Medicine},
  volume={2022},
  pages={1--16},
  year={2022},
  publisher={Hindawi Limited}
}

@article{wu2021application,
  title={Application of local fully Convolutional Neural Network combined with YOLO v5 algorithm in small target detection of remote sensing image},
  author={Wu, Wentong and others},
  journal={PloS one},
  volume={16},
  number={10},
  pages={e0259283},
  year={2021},
  publisher={Public Library of Science San Francisco, CA USA}
}

@inproceedings{wu2021real,
  title={Real-time vehicle and distance detection based on improved yolo v5 network},
  author={Wu, Tian-Hao and Wang, Tong-Wen and Liu, Ya-Qi},
  booktitle={2021 3rd World Symposium on Artificial Intelligence (WSAI)},
  pages={24--28},
  year={2021},
  organization={IEEE}
}

@inproceedings{zhu2021tph,
  title={TPH-YOLOv5: Improved YOLOv5 based on transformer prediction head for object detection on drone-captured scenarios},
  author={Zhu, Xingkui and Lyu, Shuchang and Wang, Xu and Zhao, Qi},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={2778--2788},
  year={2021}
}

@article{kasper2021detecting,
  title={Detecting heavy goods vehicles in rest areas in winter conditions using YOLOv5},
  author={Kasper-Eulaers},
  journal={Algorithms},
  volume={14},
  number={4},
  pages={114},
  year={2021},
  publisher={MDPI}
}

@article{DBLP:journals/corr/abs-2005-08605,
  author    = {Yuhuang Hu and
               Jonathan Binas and
               Daniel Neil and
               Shih{-}Chii Liu and
               Tobi Delbr{\"{u}}ck},
  title     = {{DDD20} End-to-End Event Camera Driving Dataset: Fusing Frames and
               Events with Deep Learning for Improved Steering Prediction},
  journal   = {CoRR},
  volume    = {abs/2005.08605},
  year      = {2020},
  url       = {https://arxiv.org/abs/2005.08605},
  eprinttype = {arXiv},
  eprint    = {2005.08605},
  timestamp = {Fri, 22 May 2020 16:21:28 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2005-08605.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{9025364,
  author={Calabrese, Enrico and others},
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
  title={DHP19: Dynamic Vision Sensor 3D Human Pose Dataset}, 
  year={2019},
  volume={},
  number={},
  pages={1695-1704},
  doi={10.1109/CVPRW.2019.00217}}

@ARTICLE{10.3389/fnins.2017.00309,
  
AUTHOR={Li, Hongmin and Liu, Hanchao and Ji, Xiangyang and Li, Guoqi and Shi, Luping},   
	 
TITLE={CIFAR10-DVS: An Event-Stream Dataset for Object Classification},      
	
JOURNAL={Frontiers in Neuroscience},      
	
VOLUME={11},           
	
YEAR={2017},      
	  
URL={https://www.frontiersin.org/articles/10.3389/fnins.2017.00309},       
	
DOI={10.3389/fnins.2017.00309},      
	
ISSN={1662-453X},   
   
ABSTRACT={Neuromorphic vision research requires high-quality and appropriately challenging event-stream datasets to support continuous improvement of algorithms and methods. However, creating event-stream datasets is a time-consuming task, which needs to be recorded using the neuromorphic cameras. Currently, there are limited event-stream datasets available. In this work, by utilizing the popular computer vision dataset CIFAR-10, we converted 10,000 frame-based images into 10,000 event streams using a dynamic vision sensor (DVS), providing an event-stream dataset of intermediate difficulty in 10 different classes, named as “CIFAR10-DVS.” The conversion of event-stream dataset was implemented by a repeated closed-loop smooth (RCLS) movement of frame-based images. Unlike the conversion of frame-based images by moving the camera, the image movement is more realistic in respect of its practical applications. The repeated closed-loop image movement generates rich local intensity changes in continuous time which are quantized by each pixel of the DVS camera to generate events. Furthermore, a performance benchmark in event-driven object classification is provided based on state-of-the-art classification algorithms. This work provides a large event-stream dataset and an initial benchmark for comparison, which may boost algorithm developments in even-driven pattern recognition and object classification.}
}

@article{yin2022iris,
  title={IRIS: Integrated Retinal Functionality in Image Sensors},
  author={Yin, Zihan and Kaiser, Md Abdullah-Al and Camara, Lamine Ousmane and Camarena, Mark and Parsa, Maryam and Jacob, Ajey and Schwartz, Gregory and Jaiswal, Akhilesh},
  journal={bioRxiv},
  pages={2022--08},
  year={2022},
  publisher={Cold Spring Harbor Laboratory}
}

@incollection{schwartz2021object,
  title={Object motion sensitivity},
  author={Schwartz, Gregory William and Swygart, David},
  booktitle={Retinal Computation},
  pages={230--244},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{zhou2017unsupervised,
  title={Unsupervised learning of depth and ego-motion from video},
  author={Zhou, Tinghui and Brown, Matthew and Snavely, Noah and Lowe, David G},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1851--1858},
  year={2017}
}

@article{jia2021self,
  title={Self-supervised 3D reconstruction and ego-motion estimation via on-board monocular video},
  author={Jia, Shaocheng and Pei, Xin and Jing, Xiao and Yao, Danya},
  journal={IEEE Transactions on Intelligent Transportation Systems},
  volume={23},
  number={7},
  pages={7557--7569},
  year={2021},
  publisher={IEEE}
}

@article{khan2017ego,
  title={Ego-motion estimation concepts, algorithms and challenges: an overview},
  author={Khan, Naila Habib and Adnan, Awais},
  journal={Multimedia Tools and Applications},
  volume={76},
  pages={16581--16603},
  year={2017},
  publisher={Springer}
}

@article{rodriguez2022free,
  title={Free as a Bird: Event-Based Dynamic Sense-and-Avoid for Ornithopter Robot Flight},
  author={Rodr{\'\i}guez-G{\'o}mez, Juan Pablo and Tapia, Raul and Garcia, Maria del Mar Guzm{\'a}n and Mart{\'\i}nez-de Dios, Jose Ramiro and Ollero, Anibal},
  journal={IEEE Robotics and Automation Letters},
  volume={7},
  number={2},
  pages={5413--5420},
  year={2022},
  publisher={IEEE}
}

@inproceedings{andersen2022event,
  title={Event-based navigation for autonomous drone racing with sparse gated recurrent network},
  author={Andersen, Kristoffer Fogh and Pham, Huy Xuan and Ugurlu, Halil Ibrahim and Kayacan, Erdal},
  booktitle={2022 European Control Conference (ECC)},
  pages={1342--1348},
  year={2022},
  organization={IEEE}
}

@inproceedings{maqueda2018event,
  title={Event-based vision meets deep learning on steering prediction for self-driving cars},
  author={Maqueda, Ana I and Loquercio, Antonio and Gallego, Guillermo and Garc{\'\i}a, Narciso and Scaramuzza, Davide},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5419--5427},
  year={2018}
}

@article{chen2020event,
  title={Event-based neuromorphic vision for autonomous driving: A paradigm shift for bio-inspired visual sensing and perception},
  author={Chen, Guang and Cao, Hu and Conradt, Jorg and Tang, Huajin and Rohrbein, Florian and Knoll, Alois},
  journal={IEEE Signal Processing Magazine},
  volume={37},
  number={4},
  pages={34--49},
  year={2020},
  publisher={IEEE}
}

@article{binas2017ddd17,
  title={DDD17: End-to-end DAVIS driving dataset},
  author={Binas, Jonathan and Neil, Daniel and Liu, Shih-Chii and Delbruck, Tobi},
  journal={arXiv preprint arXiv:1711.01458},
  year={2017}
}

@article{gallego2020event,
  title={Event-based vision: A survey},
  author={Gallego, Guillermo and others},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={44},
  number={1},
  pages={154--180},
  year={2020},
  publisher={IEEE}
}

@article{Hayes:12,
author = {Tim Hayes},
journal = {Opt. Photon. News},
keywords = {Image processing; Imaging systems; Lens system design; Systems design ; Integrated optics devices; Cameras; Image processing; Image quality; Image sensors; LED lenses; Liquid lenses},
number = {2},
pages = {16--21},
publisher = {Optica Publishing Group},
title = {Next-Generation Cell Phone Cameras},
volume = {23},
month = {Jan},
year = {2012},
url = {https://www.optica-opn.org/abstract.cfm?URI=opn-23-2-16},
doi = {10.1364/OPN.23.2.000016},
abstract = {The mobile camera market is being driven by consumers' desire for big imagingcapability in smaller and smaller packages. Despite the limitations imposed by thesecompeting demands---or perhaps because of them---many companies are unleashing creativesolutions that incorporate wafer-level optics, liquid lenses and LEDflashes.},
}

@article{DBLP:journals/corr/abs-2104-11892,
  author    = {Syed Sahil Abbas Zaidi and
               Mohammad Samar Ansari and
               Asra Aslam and
               Nadia Kanwal and
               Mamoona Naveed Asghar and
               Brian Lee},
  title     = {A Survey of Modern Deep Learning based Object Detection Models},
  journal   = {CoRR},
  volume    = {abs/2104.11892},
  year      = {2021},
  url       = {https://arxiv.org/abs/2104.11892},
  eprinttype = {arXiv},
  eprint    = {2104.11892},
  timestamp = {Tue, 01 Feb 2022 08:16:15 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2104-11892.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@software{glenn_jocher_2022_7347926,
  author       = {Glenn Jocher and
                  Ayush Chaurasia and
                  Alex Stoken and
                  others},
  title        = {{ultralytics/yolov5: v7.0 - YOLOv5 SOTA Realtime 
                   Instance Segmentation}},
  month        = nov,
  year         = 2022,
  publisher    = {Zenodo},
  version      = {v7.0},
  doi          = {10.5281/zenodo.7347926},
  url          = {https://doi.org/10.5281/zenodo.7347926}
}

@article{shannon2001mathematical,
  title={A mathematical theory of communication},
  author={Shannon, Claude Elwood},
  journal={ACM SIGMOBILE mobile computing and communications review},
  volume={5},
  number={1},
  pages={3--55},
  year={2001},
  publisher={ACM New York, NY, USA}
}

@article{leff1996thermodynamic,
  title={Thermodynamic entropy: The spreading and sharing of energy},
  author={Leff, Harvey S},
  journal={American Journal of Physics},
  volume={64},
  number={10},
  pages={1261--1271},
  year={1996},
  publisher={American Association of Physics Teachers}
}

@article{baccus2008retinal,
  title={A retinal circuit that computes object motion},
  author={Baccus, Stephen A and {\"O}lveczky, Bence P and Manu, Mihai and Meister, Markus},
  journal={Journal of Neuroscience},
  volume={28},
  number={27},
  pages={6807--6817},
  year={2008},
  publisher={Soc Neuroscience}
}

@article{weng2021neural,
  title={Neural network quantization for efficient inference: A survey},
  author={Weng, Olivia},
  journal={arXiv preprint arXiv:2112.06126},
  year={2021}
}

@inproceedings{patton2021neuromorphic,
  title={Neuromorphic computing for autonomous racing},
  author={Patton, Robert and Schuman, Catherine and Kulkarni, Shruti and Parsa, Maryam and others},
  booktitle={International Conference on Neuromorphic Systems 2021},
  pages={1--5},
  year={2021}
}

 @misc{Rep_Ryan_2022, type={legislation}, title={H.R.4346 - 117th Congress (2021-2022): Chips and Science Act}, rights={Text is government work}, archiveLocation={08/09/2022}, url={http://www.congress.gov/}, abstractNote={Summary of H.R.4346 - 117th Congress (2021-2022): Chips and Science Act}, author={Rep. Ryan, Tim [D-OH-13}, year={2022}, month={Aug}, language={eng} }

@article{li2022dynamic,
  title={Dynamic Registration: Joint Ego Motion Estimation and 3D Moving Object Detection in Dynamic Environment},
  author={Li, Wenyu and others},
  journal={arXiv preprint arXiv:2204.12769},
  year={2022}
}

@inproceedings{hwang2022motion,
  title={Motion Compensation for Body-frame Doppler Estimation of Radar Sensors on Multi-rotor UAV Platforms},
  author={Hwang, Seongbu and Yu, Taewoo and Nam, Sangwook},
  booktitle={2022 19th European Radar Conference (EuRAD)},
  pages={133--136},
  year={2022},
  organization={IEEE}
}

@article{kumar2023pedestrian,
  title={Pedestrian Tracking in UAV Images With Kalman Filter Motion Estimator and Correlation Filter},
  author={Kumar, Ranjeet and Deb, Alok Kanti},
  journal={IEEE Aerospace and Electronic Systems Magazine},
  year={2023},
  publisher={IEEE}
}

@article{yang2022ego,
  title={Ego-motion Estimation Based on Fusion of Images and Events},
  author={Yang, Liren},
  journal={arXiv preprint arXiv:2207.05588},
  year={2022}
}

@inproceedings{meyer2023ego,
  title={Ego-Motion Compensation of Range-Beam-Doppler Radar Data for Object Detection},
  author={Meyer, Michael and Unzueta, Marc and Kuschk, Georg and Tomforde, Sven},
  booktitle={Computer Vision--ECCV 2022 Workshops: Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part I},
  pages={697--708},
  year={2023},
  organization={Springer}
}

@inproceedings{balaprakash2018deephyper,
  title={DeepHyper: Asynchronous hyperparameter search for deep neural networks},
  author={Balaprakash, Prasanna and Salim, Michael and Uram, Thomas D and Vishwanath, Venkat and Wild, Stefan M},
  booktitle={2018 IEEE 25th international conference on high performance computing (HiPC)},
  pages={42--51},
  year={2018},
  organization={IEEE}
}

@inproceedings{schuman2020automated,
  title={Automated Design of Neuromorphic Networks for Scientific Applications at the Edge},
  author={Schuman, Catherine D and Mitchell, J Parker and Parsa, Maryam and others},
  booktitle={2020 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--7},
  year={2020},
  organization={IEEE}
}

@inproceedings{schuman2020evolutionary,
  title={Evolutionary optimization for neuromorphic systems},
  author={Schuman, Catherine D and Mitchell, J Parker and others},
  booktitle={Proceedings of the Neuro-inspired Computational Elements Workshop},
  pages={1--9},
  year={2020}
}

@inproceedings{parsa2021multi,
  title={Multi-Objective Hyperparameter Optimization for Spiking Neural Network Neuroevolution},
  author={Parsa, Maryam and others},
  booktitle={2021 IEEE Congress on Evolutionary Computation (CEC)},
  pages={1225--1232},
  year={2021},
  organization={IEEE}
}

@inproceedings{parsa2021accurate,
  title={Accurate and Accelerated Neuromorphic Network Design Leveraging A Bayesian Hyperparameter Pareto Optimization Approach},
  author={Parsa, Maryam and Schuman, Catherine and others},
  booktitle={International Conference on Neuromorphic Systems 2021},
  pages={1--8},
  year={2021}
}

@article{schuman2022evolutionary,
  title={Evolutionary vs imitation learning for neuromorphic control at the edge},
  author={Schuman, Catherine and Patton, Robert and Kulkarni, Shruti and Parsa, Maryam and Stahl, Christopher and Haas, N Quentin and Mitchell, J Parker and Snyder, Shay and others},
  journal={Neuromorphic Computing and Engineering},
  volume={2},
  number={1},
  pages={014002},
  year={2022},
  publisher={IOP Publishing}
}

@inproceedings{li2022revisiting,
  title={Revisiting random channel pruning for neural network compression},
  author={Li, Yawei and Adamczewski, Kamil and Li, Wen and Gu, Shuhang and Timofte, Radu and Van Gool, Luc},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={191--201},
  year={2022}
}

@article{schuman2022opportunities,
  title={Opportunities for neuromorphic computing algorithms and applications},
  author={Schuman, Catherine D and Kulkarni, Shruti R and Parsa, Maryam and Mitchell, J Parker and Date, Prasanna and Kay, Bill},
  journal={Nature Computational Science},
  volume={2},
  number={1},
  pages={10--19},
  year={2022},
  publisher={Nature Publishing Group US New York}
}

@article{wang2021emerging,
  title={Emerging paradigms of neural network pruning},
  author={Wang, Huan and Qin, Can and Zhang, Yulun and Fu, Yun},
  journal={arXiv preprint arXiv:2103.06460},
  year={2021}
}

@article{blalock2020state,
  title={What is the state of neural network pruning?},
  author={Blalock, Davis and others},
  journal={Proceedings of machine learning and systems},
  volume={2},
  pages={129--146},
  year={2020}
}

@inproceedings{chang2021mix,
  title={Mix and match: A novel fpga-centric deep neural network quantization framework},
  author={Chang, Sung-En and Li, Yanyu and Sun, Mengshu and Shi, Runbin and So, Hayden K-H and Qian, Xuehai and Wang, Yanzhi and Lin, Xue},
  booktitle={2021 IEEE International Symposium on High-Performance Computer Architecture (HPCA)},
  pages={208--220},
  year={2021},
  organization={IEEE}
}

@inproceedings{jin2020adabits,
  title={Adabits: Neural network quantization with adaptive bit-widths},
  author={Jin, Qing and Yang, Linjie and Liao, Zhenyu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2146--2156},
  year={2020}
}

@article{choi2016towards,
  title={Towards the limit of network quantization},
  author={Choi, Yoojin and El-Khamy, Mostafa and Lee, Jungwon},
  journal={arXiv preprint arXiv:1612.01543},
  year={2016}
}

@article{kim2011system,
  title={System-on-chip solution of video stabilization for CMOS image sensors in hand-held devices},
  author={Kim, Young-Geun and Jayanthi, Venkata Ravisankar and Kweon, In-So},
  journal={IEEE transactions on circuits and systems for video technology},
  volume={21},
  number={10},
  pages={1401--1414},
  year={2011},
  publisher={IEEE}
}

@article{jang20213d,
  title={3D heterogeneous device arrays for multiplexed sensing platforms using transfer of perovskites},
  author={Jang, Jiuk and Park, Young-Geun and Cha, Eunkyung and Ji, Sangyoon and Hwang, Hyunbin and Kim, Gon Guk and Jin, Jungho and Park, Jang-Ung},
  journal={Advanced Materials},
  volume={33},
  number={30},
  pages={2101093},
  year={2021},
  publisher={Wiley Online Library}
}

@inproceedings{foldesy20093d,
  title={3D multi-layer vision architecture for surveillance and reconnaissance applications},
  author={Foldesy, Peter and Carmona-Galan, Ricardo and Zar{\'a}ndy, {\'A}kos and Rekeczky, Csaba and Rodr{\'\i}guez-V{\'a}zquez, Angel and Roska, Tam{\'a}s},
  booktitle={2009 European Conference on Circuit Theory and Design},
  pages={185--188},
  year={2009},
  organization={IEEE}
}

@inproceedings{vivet2019advanced,
  title={Advanced 3d technologies and architectures for 3d smart image sensors},
  author={Vivet, Pascal and Sicard, Gilles and others},
  booktitle={2019 Design, Automation \& Test in Europe Conference \& Exhibition (DATE)},
  pages={674--679},
  year={2019},
  organization={IEEE}
}

@article{zhou2020near,
  title={Near-sensor and in-sensor computing},
  author={Zhou, Feichi and Chai, Yang},
  journal={Nature Electronics},
  volume={3},
  number={11},
  pages={664--671},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{vivet2018monolithic,
  title={Monolithic 3D: An alternative to advanced CMOS scaling, technology perspectives and associated design methodology challenges},
  author={Vivet, Pascal and others},
  booktitle={2018 25th IEEE International Conference on Electronics, Circuits and Systems (ICECS)},
  pages={157--160},
  year={2018},
  organization={IEEE}
}

 @article{Ölveczky_Baccus_Meister_2003, title={Segregation of object and background motion in the retina}, volume={423}, rights={2003 Macmillan Magazines Ltd.}, ISSN={1476-4687}, DOI={10.1038/nature01652}, abstractNote={An important task in vision is to detect objects moving within a stationary scene. During normal viewing this is complicated by the presence of eye movements that continually scan the image across the retina, even during fixation. To detect moving objects, the brain must distinguish local motion within the scene from the global retinal image drift due to fixational eye movements. We have found that this process begins in the retina: a subset of retinal ganglion cells responds to motion in the receptive field centre, but only if the wider surround moves with a different trajectory. This selectivity for differential motion is independent of direction, and can be explained by a model of retinal circuitry that invokes pooling over nonlinear interneurons. The suppression by global image motion is probably mediated by polyaxonal, wide-field amacrine cells with transient responses. We show how a population of ganglion cells selective for differential motion can rapidly flag moving objects, and even segregate multiple moving objects.}, number={69386938}, journal={Nature}, publisher={Nature Publishing Group}, author={Ölveczky, Bence P. and Baccus, Stephen A. and Meister, Markus}, year={2003}, month={May}, pages={401–408}, language={en} }

@article{sinha2017survey,
  title={A survey on LPWA technology: LoRa and NB-IoT},
  author={Sinha, Rashmi Sharan and others},
  journal={Ict Express},
  volume={3},
  number={1},
  pages={14--21},
  year={2017},
  publisher={Elsevier}
}

@article{mozaffariahrar2022survey,
  title={A Survey of Wi-Fi 6: Technologies, Advances, and Challenges},
  author={Mozaffariahrar, Erfan and Theoleyre, Fabrice and Menth, Michael},
  journal={Future Internet},
  volume={14},
  number={10},
  pages={293},
  year={2022},
  publisher={MDPI}
}

@inproceedings{lenihan2013developments,
  title={Developments in 2.5 D: The role of silicon interposers},
  author={Lenihan, Timothy G and Matthew, Linda and Vardaman, E Jan},
  booktitle={2013 IEEE 15th Electronics Packaging Technology Conference (EPTC 2013)},
  pages={53--55},
  year={2013},
  organization={IEEE}
}

@article{kempainen2002low,
  title={Low-voltage differential signaling (lvds)},
  author={Kempainen, Stephen},
  journal={Altera Co-operation},
  year={2002}
}

@inproceedings{shah2021review,
  title={Review of Bio-inspired Silicon Retina: From Cell to System Level Implementation},
  author={Shah, Payal and Rathod, Surendra S},
  booktitle={2021 International Conference on Communication information and Computing Technology (ICCICT)},
  pages={1--13},
  year={2021},
  organization={IEEE}
}

 @article{olveczky_Baccus_Meister_2007, title={Retinal Adaptation to Object Motion}, volume={56}, ISSN={0896-6273}, DOI={10.1016/j.neuron.2007.09.030}, abstractNote={Due to fixational eye movements, the image on the retina is always in motion, even when one views a stationary scene. When an object moves within the scene, the corresponding patch of retina experiences a different motion trajectory than the surrounding region. Certain retinal ganglion cells respond selectively to this condition, when the motion in the cell’s receptive field center is different from that in the surround. Here we show that this response is strongest at the very onset of differential motion, followed by gradual adaptation with a time course of several seconds. Different subregions of a ganglion cell’s receptive field can adapt independently. The circuitry responsible for differential motion adaptation lies in the inner retina. Several candidate mechanisms were tested, and the adaptation most likely results from synaptic depression at the synapse from bipolar to ganglion cell. Similar circuit mechanisms may act more generally to emphasize novel features of a visual stimulus.}, number={4}, journal={Neuron}, author={Ölveczky, Bence P. and Baccus, Stephen A. and Meister, Markus}, year={2007}, month={Nov}, pages={689–700}, language={en} }


@article{olveczky2007retinal,
  title={Retinal adaptation to object motion},
  author={{\"O}lveczky, Bence P and Baccus, Stephen A and Meister, Markus},
  journal={Neuron},
  volume={56},
  number={4},
  pages={689--700},
  year={2007},
  publisher={Elsevier}
}

@article{Hussien_2021,
doi = {10.1088/1742-6596/1973/1/012002},
url = {https://dx.doi.org/10.1088/1742-6596/1973/1/012002},
year = {2021},
month = {aug},
publisher = {IOP Publishing},
volume = {1973},
number = {1},
pages = {012002},
author = {Reem M. Hussien and Karrar Q. Al-Jubouri and Mohaimen Al Gburi and Al Gburi Hussein Qahtan and Al Hamami Duaa Jaafar},
title = {Computer Vision and Image Processing the Challenges and Opportunities for new technologies approach: A paper review},
journal = {Journal of Physics: Conference Series},
abstract = {Digital image processing has numerous applications in many sectors of the world. It expands from initial information registration into methods and thoughts combining pattern recognition, computer vision, and machine learning. The wide utilization has pulled in many researchers to integrate with a range of related specializations. This work gives a study of the latest development and theoretical ideas clarifying an improvement of computer vision particularly with pattern recognition and image processing, utilizing various regions of their field implementation. Digital image processing causes researchers to analyze images to get important data and comprehend information. It utilized a technique of multi-range implementation and huge information analysis. This work aims to focus on the latest studies related to image processing, pattern recognition, and computer vision. In this paper, Computer vision standard has been categorized into groups. For example, pattern recognition, image processing, and AI. Additionally, we give a short clarification of the forward-thinking data about the methods and their realization. This survey is restricted to computer vision, and more research can include detecting the conduct and properties of the object including people actions.}
}

@inproceedings{zhu2019unsupervised,
  title={Unsupervised event-based learning of optical flow, depth, and egomotion},
  author={Zhu, Alex Zihao and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={989--997},
  year={2019}
}

@inproceedings{sanket2020evdodgenet,
  title={Evdodgenet: Deep dynamic obstacle dodging with event cameras},
  author={Sanket, Nitin J and others},
  booktitle={2020 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={10651--10657},
  year={2020},
  organization={IEEE}
}

@inproceedings{stoffregen2019event,
  title={Event-based motion segmentation by motion compensation},
  author={Stoffregen, Timo and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={7244--7253},
  year={2019}
}

@inproceedings{liu2020globally,
  title={Globally optimal contrast maximisation for event-based motion estimation},
  author={Liu, Daqi and Parra, Alvaro and Chin, Tat-Jun},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6349--6358},
  year={2020}
}

@inproceedings{gallego2018unifying,
  title={A unifying contrast maximization framework for event cameras, with applications to motion, depth, and optical flow estimation},
  author={Gallego, Guillermo and others},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3867--3876},
  year={2018}
}