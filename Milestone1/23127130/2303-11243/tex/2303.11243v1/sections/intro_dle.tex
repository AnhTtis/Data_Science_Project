\section{Introduction}

\begin{figure}[!t]
    \centering
    \footnotesize
    \includegraphics[width=\linewidth]{images/teaser_v.pdf}
    \caption{\textbf{Motivation and Proposal.} The differences between our method (\textcolor{red}{red}) and previous semi-supervised learning framework (\textcolor[RGB]{61,145,64}{green}) in pseudo label (PL) generation and student model retraining. The introduced framework can improve detection recall by observing different views of an image (\textcolor{red}{red} dots in (a)), and dynamically determine when to discard an unlabeled sample during training (line-chart in (b)) by the learnable critical module.} 
    \label{fig::teaser}
\end{figure}

% 3D understanding is the key to apply computer vision to real-world scenarios. For example, intelligent robots, like the Mars rover and self-driving vehicles, need 3D object information to avoid collision.
% Compared with expensive active sensors, such as LiDAR, cameras are much more affordable and reliable, providing an alternative for 3D perception. However, since the depth information is inevitably lost during the 3D-to-2D image projection process~\cite{eigen2014depth}, identifying 3D objects from 2D images is an ill-posed and challenging problem in the first place.

% Fortunately, recent triumph in deep learning has shed light on tackling this tough problem in a data-driven manner. Relived from directly estimating depth, data-driven approaches made significant advances in monocular 3D object detection (Mono3D) tasks~\cite{liu2020smoke,ma2021monodle,zhang2022monodetr,zhang2021monoflex,wang2021fcos3d,wang2022pgd}.
% However, state-of-the-art Mono3D models still lag far behind human perception capabilities.
% On the contrary, deep learning has surpassed human performance on classification tasks.
% One possible reason behind such performance gap is the notable dataset volume differences: for example, Mono3D models are trained with 3.7k images from the KITTI dataset~\cite{kitti}, while classification models are trained with 1.2 million images from the ImageNet dataset~\cite{imagenet}.


% Taking this into consideration, we believe a data-driven but annotation-efficient approach is necessary to bring the performance of modern Mono3D models to the next level. Semi-supervised learning becomes a natural choice for this problem. Given a task and \textit{limited} amount of human annotated training samples, semi-supervised learning aims to exploit beneficial information from \textit{enormous} unlabeled data for model performance improvement.

% Surprisingly, semi-supervised learning has rarely been explored in the monocular 3D detection context, despite its demonstrated success in numerous 2D vision tasks~\cite{tarvainen2017meanteacher,berthelot2019mixmatch,sohn2020fixmatch,xie2020self,xu2021softteacher,zhou2022denseteacher,zhang2022semi,yang2022st++,liu2022perturbed,yuan2022semi}. We suspect that the noise introduced by the low quality pseudo labels during training eventually overwhelms the benefits brought by abundant extra data. Thus, how to effectively find reliable and informative samples from unlabeled data, is critical to apply semi-supervised learning in mono3d tasks. In particular, 
% two challenges are faced: \emph{How to robustly generate high-quality pseudo labels from unlabeled data} \textbf{and} \emph{How to properly leverage these pseudo labels for effective learning}.

% For the first challenge,
% prior works in 2D tasks~\cite{xu2021softteacher,chen2022labelmatch} alleviate the pseudo label quality issue by handpicking a threshold to filter putative detection boxes from unlabeled data (see \cref{fig::teaser}). Such strategy might not work well in the mono3d setting. Firstly, generating precise pseudo label from images alone is already very difficult (notice the gap between vision-only and multi-modal 3D detection results on public benchmarks); secondly, using handcrafted selection strategy may lead to overfitting to a specific model, reducing the resilience of semi-supervised models. Thus, 
% \textbf{\emph{a robust pseudo label generation strategy is needed to tackle the first challenge.}}
% We introduce a simple yet effective Augmentation-based Prediction aGgregation strategy, dubbed \textbf{APG}, that aims at \textit{robustly} generating pseudo labels for unlabeled data. The core idea is to aggregate predictions from different observations of an image, which we find effectively reduces the detection biases and improves the robustness of pseudo label generation (see \cref{fig::teaser}). 
% % Transformation parameters for observation generations are learned using a Tree-Parzen-Window algorithm~\cite{bergstra2011algorithms}. Compared with content-based transformations such as color-jittering, learned geometry transformations exhibited better support for improving detection recall.

% For the second challenge, classification scores are usually used in 2D tasks~\cite{chen2022labelmatch} to adapt the pseudo detection boxes for training. Note that the quality of the model generated pseudo labels and the performance of the model both evolve as training progresses along. Intuitively, the contribution made by the same pseudo labeled sample, might also change at different model training stages.
% Therefore, \textbf{\emph{a more adaptive mechanism is needed to guide the training on unlabeled data.}}
% Thus, we propose a `Criticize` module for the second challenge.
% %Since not all the pseudo labels from APG is beneficially informative, an \textit{adaptive} strategy is desired to exploit these pseudo labels for effective model training (\ie, the second challenge), which motivates the proposed `Criticize' stage. 
% More specifically, in this stage, a Critical Retraining Strategy (\textbf{CRS}) is imposed to adaptively update the model with noisy pseudo labels. In particular, CRS contains a memory bank to preserve evaluation images and a critic module to determine which pseudo label benefits more when updating the model.
% Given a pseudo label, the optimization loss of the model loosely indicates the benefits this particular pseudo label would bring, should this pseudo label is used for back-propagation.
% The `Criticize` module discards the pseudo label if the model would be updated towards unsatisfactory directions. As training evolves, the Criticize module can better adapt to the model optimization progress through cyclical update of the memory bank.

% To summarize, we propose a novel `Augment and Criticize' framework to approach the two challenges in semi-supervised Mono3D object detection tasks. 
% Experimental results on the state-of-the-art MonoDLE~\cite{ma2021monodle} model show stable improvements of 3\% $\mathtt{CAR (Mod.)~ AP_{3D}}$ on the KITTI benchmark, demonstrating the effectiveness of our framework. Our contributions are as follows:

% \noindent
% (\textbf{1}) \emph{We propose a novel `Augment and Criticize' framework for semi-supervised Mono3D object detection.}

% \noindent
% (\textbf{2}) \emph{We propose an augmented-based prediction aggregation to improve the quality of pseudo labels for unlabeled data.}

% \noindent
% (\textbf{3}) \emph{We propose a critical retraining strategy that adaptively evaluates each pseudo label for effective model training. }

% Despite this, current data volume in Mono3D object detection is nowhere enough for achieving a human-level 3D sensing ability. Since manually annotating 3D boxes in larger-scale data is costly, we argue that semi-supervised learning could be an economical substitute.

% Despite this, these methods heavily rely on a large volume of labeled data for Mono3D object detection training, which is costly. To remedy this, we argue that \emph{semi-supervised learning} has great potential for economical Mono3D object detection. 

% the lack of abundant reliable and informative samples
% from unlabeled data for training. Specifically, 


% Previous methods in 2D tasks (\eg,~\cite{xu2021softteacher,chen2022labelmatch}) try to alleviate this issue by carefully choosing a threshold for detection box selection (see Fig.~\ref{fig::teaser}). This handcraft selection, however, may cause overfit to a specific model, limiting the resilience of the semi-supervised method. Addressing this problem, \textbf{\emph{a robust pseudo label generation strategy is thus necessary}}.

% Revisiting the road map of semi-supervised learning, we observe that, the bottleneck always lies in two aspects: \emph{How to robustly generate high-quality pseudo labels for unlabeled data} \textbf{and} \emph{How to properly leverage these pseudo labels for effective learning}. The former mainly focuses on the quality
% of training samples, while the latter is related to the evolving direction of the detection model. Yet as discussed earlier, it is \emph{non-trivial} to generate precise pseudo labels under the pure monocular 3D premise.  In addition, another essential challenge for semi-supervised Mono3D object detection is the lack of an adaptive training strategy to deal with pseudo labels with different qualities. Intuitively the high-quality pseudo labels should contribute more to model updating, and meanwhile the influence of low-quality samples should be suppressed. The classification score (or its variants) of a detection box is adopted in 2D methods (\eg,~\cite{xu2021softteacher}) to filter out the low-quality samples. But such a handcrafted rule-based manner is hard to guarantee the model evolve along the right direction, because a sample could show diverse effects to the model with different parameters at different training steps. Therefore, \textbf{\emph{a robust and adaptive mechanism is needed to guide the pseudo label generation and training on unlabeled data}}.

% The core idea is replacing the one-pass pseudo label generation to aggregating multi-pass predictions. APG uses multiple observations of a image, it can thus reduce the detection bias and improve the robustness of pseudo label generation.

% \vspace{0.5em}
% \noindent
% \textbf{Contribution.} Motivated by the above, we propose a novel `Augment and Criticize' framework to approach the two challenges in semi-supervised Mono3D object detection.


% We apply the proposed framework to a typical Mono3D detector, MonoDLE~\cite{ma2021monodle}. In experiments, compared with baselines, our semi-supervised detectors, 3DSeMo$_{\text{DLE}}$, achieve consistent improvements for about 3\% $\mathtt{CAR (Mod.)~ AP_{3D}}$ on KITTI, which shows the effectiveness and versatility of our method.



% This is impressively different from the conclusions claimed by the auto-augmentation works in other fields~\cite{???}.

%% Cite paper: Learning Data Augmentation with Online Bilevel Optimization for Image Classification

% the optimal image transformation parameters for augmenting the raw image usually dramatically change the object distribution to help the model locate objects that are not easily detected. 
% This is distinct from the generally adopted data augmentation in deep net training which avoiding change the input distribution too much. 


% \noindent
% (\textbf{4}) \emph{We integrate our semi-supervised framework into different methods, and results evidence its effectiveness. }


% via cyclically memory bank updating. The memory bank is a queue that contains all images from evaluation set.  

% For example, as in Fig.X, the white car away from the camera are successfully located after moving to the image center.
% \section{Introduction: Zhipeng}

Monocular 3D (Mono3D) object detection is an essential and economical way for intelligent agents to perceive 3D information in the real world. However, since the depth information is inevitably lost during the 3D-to-2D projection process~\cite{eigen2014depth}, identifying 3D objects under pure monocular premise is ill-posed in the first place. Fortunately, the recent triumphs in deep learning shed light on circumventing the complex mathematical optimization~\cite{math} and tackling this challenging problem in a data-driven manner~\cite{liu2020smoke,ma2021monodle,zhang2022monodetr,zhang2021monoflex,wang2021fcos3d}. Despite of the improvements, state-of-the-art
Mono3D models still lag far behind human perception capabilities. On the contrary, deep learning has surpassed human-level performance on image classification tasks~\cite{he2015delving}.
One possible reason behind such a performance gap is the notable dataset volume differences: for example, Mono3D models are trained with 3.7K images from KITTI~\cite{geiger2012kitti}, while classification models are trained with 1.2 million images from ImageNet~\cite{deng2009imagenet}.

% It turns out that 3D annotations are much harder and more costly than 2D annotations, which requires LiDARs for 3D groundtruth, carefully calibration, \textit{e.t.}. 

% , while 3D annotation mandates considerably more manual efforts

Why not just simply scale up the dataset volume then? It turns out that 3D annotations are more expensive than 2D ones. High-quality Mono3D datasets need LiDARs for 3D ground truth. Data collection needs carefully calibrated and synchronized different sensors. Taking this into consideration, we believe a data-driven but annotation-efficient approach is necessary to bring the performances of modern Mono3D models to the next level. 

Naturally, semi-supervised learning, which can absorb knowledge from \textit{limited} annotated samples meanwhile exploit beneficial information from the \textit{enormous} unlabeled data, becomes a reasonable choice for this problem. Surprisingly, it has been rarely explored in monocular 3D detection, despite its success in numerous 2D vision tasks~\cite{tarvainen2017meanteacher,berthelot2019mixmatch,sohn2020fixmatch,xie2020self,xu2021softteacher,zhou2022denseteacher,zhang2022semi,yang2022st++,liu2022perturbed,yuan2022semi}. We suspect that the noise in the low-quality pseudo labels during training eventually overwhelms the benefits brought by abundant extra data. Thus, how to effectively find reliable and informative samples from unlabeled data, is crucial to apply semi-supervised learning in Mono3D tasks. In particular, 
two challenges are faced: \emph{How to robustly generate high-quality pseudo labels from unlabeled data} \textbf{and} \emph{How to properly leverage these pseudo labels for effective learning}.

For the first challenge,
prior works in 2D tasks~\cite{xu2021softteacher,chen2022labelmatch} alleviate the pseudo label quality issue by handpicking a threshold to filter putative detection boxes from unlabeled data (see \cref{fig::teaser}). Such strategy might not work well in the Mono3D setting. Firstly, generating precise pseudo labels from images alone is already very difficult (notice the gap between vision-only and multi-modal 3D detection results on public benchmarks); secondly, using a handcrafted selection strategy may overfit to a specific model, reducing the resilience of semi-supervised models. Thus, 
\textbf{\emph{a robust pseudo label generation strategy is needed to tackle the first challenge.}} To this end, we introduce a simple yet effective Augmentation-based Prediction aGgregation strategy, dubbed \textbf{APG}, that aims at \textit{robustly} generating pseudo labels for unlabeled data. The core idea is to aggregate predictions from different observations of an image, which we find effectively reduces the detection biases and improves the robustness of pseudo label generation (see \cref{fig::teaser}). 
% Transformation parameters for observation generations are learned using a Tree-Parzen-Window algorithm~\cite{bergstra2011algorithms}. Compared with content-based transformations such as color-jittering, learned geometry transformations exhibited better support for improving detection recall.

For the second challenge, since not all the pseudo labels are beneficially informative (even for the proposed APG), classification scores are usually used in 2D tasks~\cite{chen2022labelmatch} to adapt the pseudo detection boxes for training. However, it ignores that the contribution of each sample during model training should vary across training iterations and the modelâ€™s parameters. Therefore, \textbf{\emph{a more adaptive mechanism is needed to guide the training on unlabeled data.}} For that, we propose a `Criticize' module for the second challenge. More specifically, in this stage, a Critical Retraining Strategy (\textbf{CRS}) is imposed to \textit{adaptively} update the model with noisy pseudo labels. In particular, CRS contains a memory bank to preserve evaluation images and a criticize module to determine which pseudo label benefits more when updating the model.
Given a pseudo label, the optimization loss of the model roughly indicates the benefits this particular pseudo label would bring, should this pseudo label be used for back-propagation.
The `Criticize' module discards the pseudo label if the model would be updated towards unsatisfactory directions. As training proceeds, the Criticize module can better adapt to the model optimization progress through cyclical updating of the memory bank.


% Note that such a rule-based manner is hard to guarantee the model evolve along the right direction, because a sample could show diverse effects to the model at different training steps. 
% the quality of the model generated pseudo labels and the performance of the model both evolve as training progresses along. Intuitively, the contribution made by the same pseudo labeled sample, might also change at different model training stages.
%Since not all the pseudo labels from APG is beneficially informative, an \textit{adaptive} strategy is desired to exploit these pseudo labels for effective model training (\ie, the second challenge), which motivates the proposed `Criticize' stage. 

% demonstrating the effectiveness and versatility of our framework. 



To summarize, we propose a novel `Augment and Criticize' framework to approach the two challenges in semi-supervised Mono3D object detection. Results on different methods and benchmarks show remarkable improvement. Our contributions are summarized as follow,

\noindent
(\textbf{1}) \emph{We propose a novel `Augment and Criticize' framework for semi-supervised Mono3D object detection.}

\noindent
(\textbf{2}) \emph{We propose an augmented-based prediction aggregation to improve the quality of pseudo labels for unlabeled data.}

\noindent
(\textbf{3}) \emph{We propose a critical retraining strategy that adaptively evaluates each pseudo label for effective model training. }


\noindent
(\textbf{4}) \emph{We integrate our semi-supervised framework into different methods, and results evidence its effectiveness. }

% \noindent
% (\textbf{4}) \emph{Extensive experiments and analyses prove the robustness of the proposed framework.}


% introduced by the low quality pseudo labels in  during training eventually overwhelms the benefits brought by abundant extra data. 

% One possible reason is that its ill-posed task definition makes algorithms suffer from complex environments and eventually incurs noisy pseudo-label on the unlabeled data, degrading performance. A previous method of~\cite{lian2022semimono3d} attempts to construct the multi-view consistency for semi-supervised learning of Mono3D detection. However, it is restricted to stereo or multi-view requirement that may be not perfectly guaranteed in practical scenarios. Instead, in this work, we tend to construct a semi-supervised Mono3D detection framework using only single-camera, -view, and -modality inputs.


% It has been extensively studied in numerous 2D vision tasks~\cite{tarvainen2017meanteacher,berthelot2019mixmatch,sohn2020fixmatch,xie2020self,xu2021softteacher,zhou2022denseteacher,zhang2022semi,yang2022st++,liu2022perturbed,yuan2022semi}, yet surprisingly less explored for Mono3D detection.


% Revisiting the road map of semi-supervised learning, we observe that, the bottleneck always lies in the lack of abundant reliable and informative samples
% from unlabeled data for training. Specifically, two challenges are faced: \emph{How to robustly generate high-quality pseudo labels for unlabeled data} \textbf{and} \emph{How to properly leverage these pseudo labels for effective learning}. The former mainly focuses on the quality
% of training samples, while the latter is related to the evolving direction of the detection model. Yet as discussed earlier, it is \emph{non-trivial} to generate precise pseudo labels under the pure monocular 3D premise. Addressing this problem, \textbf{\emph{a robust pseudo label generation strategy is thus necessary}}. In addition, another essential challenge for semi-supervised Mono3D object detection is the lack of an adaptive training strategy to deal with pseudo labels with different qualities. Intuitively the high-quality pseudo labels should contribute more to model updating, and meanwhile the influence of low-quality samples should be suppressed. The classification score (or its variants) of a detection box is adopted in 2D methods (\eg,~\cite{xu2021softteacher}) to filter out the low-quality samples. But such a rule-based manner is hard to guarantee the model evolve along the right direction, because a sample could show diverse effects to the model at different training steps. Therefore, \textbf{\emph{a more adaptive mechanism is needed to guide the training on unlabeled data}}.



% \vspace{0.5em}
% \noindent
% \textbf{Contribution.} Motivated by the above, we propose a novel `Augment and Criticize' framework to approach the two challenges in semi-supervised Mono3D object detection.

% In specific in `Augment' stage, we introduce a simple yet effective Augmentation-based Prediction aGgregation strategy, dubbed \textbf{APG}, that aims at \textit{robustly} generating pseudo labels for unlabeled data (\ie, the first challenge). The core idea is to aggregate predictions from different observations of an image, which we find effectively reduces the detection bias and improves the robustness of pseudo label generation (see Fig.~\ref{fig::teaser}). In order to avoid handcrafted selection, the transformation parameters for generating an observation are automatically learned by using an efficient reward-based Tree-Parzen-Window algorithm~\cite{bergstra2011algorithms}. Interestingly, we find that, content-based transformations such as color-jitter are not helpful, yet geometry-based transformations like resize and crop exhibit much affirmative effect, for improving detection recall, providing guidance for future research.

% Since not all the pseudo labels from APG is beneficially informative, an \textit{adaptive} strategy is desired to exploit these pseudo labels for effective model training (\ie, the second challenge), which motivates the proposed `Criticize' stage. More specifically, in this stage, a Critical Retraining Strategy (\textbf{CRS}) is imposed to adaptively update the model with noisy pseudo labels. Particularly, CRS contains a memory bank to preserve evaluation images and a critical module to determine which pseudo label benefits to update the model. At each training step, the loss of each pseudo label corresponds to an update choice of the model. The critical module samples images from the memory to determine whether this update improves model capability. If the model resembles to a worse one, the update would be discarded (self-criticise). During the cyclical updating of the memory bank, the critical module gradually encodes the knowledge of the whole evaluation set to its weight parameters, and therefore it becomes more and more powerful along training period. 

% Experimental results on MonoDLE~\cite{ma2021monodle} show improvements of 3\% $\mathtt{CAR (Mod.)~ AP_{3D}}$ on KITTI, demonstrating the effectiveness of our framework. In summary, we make the following contributions: 

% \noindent
% (\textbf{1}) \emph{We propose a novel `Augment and Criticize' framework for semi-supervised Mono3D object detection.}

% \noindent
% (\textbf{2}) \emph{We propose an augmented-based prediction aggregation to improve the quality of pseudo labels for unlabeled data.}

% \noindent
% (\textbf{3}) \emph{We propose a critical retraining strategy that adaptively evaluates each pseudo label for effective model training. }