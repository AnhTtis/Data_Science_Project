\section{Related Work}
% In this section, we review some related approaches in prior literature, from which our method draws inspiration. We also analyze their differences from our mechanism.

% This research branch focus on improving the quality of depth estimation~\cite{wang2020taskawaredp,park2021dd3d} and the projected 3D features from 2D images~\cite{reading2021caddn,zhou2022persdet}. 

\begin{figure*}[!t]
    \centering
    \footnotesize
    \includegraphics[width=0.98\linewidth]{images/overall_framework_v1.pdf}
    \caption{\textbf{`Augment and Criticize' Framework.} We present the three major steps in our semi-supervised scheme, including standard supervised training, pseudo label generation with APG, and retraining with CRS.} 
    \label{fig::overall}
\end{figure*}

% Mono3D object detection methods only require vision clues from a single camera.


\subsection{Monocular 3D Object Detection}
3D object detection is a fundamental task for agents to perceive the surrounding 3D world~\cite{arnold2019survey}. Benefiting from the ubiquitous availabilities of cameras, Mono3D methods have great potential for wide real-world deployment, thus have received extensive attention recently~\cite{brazil2020kinematic,ding2020d4lcn,zhang2021monoflex,shi2021monorcnn,ma2021monodle,lu2021gup,huang2022monodtr}.
Earlier attempts devoted massive efforts to the ill-posed depth estimation problem. By adopting an isolated depth model~\cite{weng2019plpc} to generate pseudo point cloud or lifting 2D features to 3D space~\cite{roddick2018orthographic}, 3D detectors can be applied on such pseudo point cloud or 3D features for object identification. Despite promising results, the hefty computation overhead entailed by dense depth estimation prohibits such methods from practical applications.
By moving depth estimation into an auxiliary head, \cite{liu2020smoke,ma2021monodle,zhang2021monoflex,wang2021fcos3d} enabled end-to-end model training with a neater framework. These methods simultaneously predict object centers in the 2D images and their corresponding depth in the 3D space. Object 3D locations and dimensions can then be easily recovered with camera calibration.
Representative methods like SMOKE~\cite{liu2020smoke} and MonoDLE~\cite{ma2021monodle} adopt CenterNet-like architectures~\cite{zhou2019centernet}, whereas FCOS3D~\cite{wang2021fcos3d} and PGD~\cite{wang2022pgd} extend the 2D FCOS detector~\cite{tian2019fcos} into a 3D detection model.
In this paper, we aim to design a general semi-supervised framework, which is agnostic to specific model designs, to push the envelope of modern Mono3D object detectors.

\subsection{Semi-Supervised Learning}

Semi-Supervised Learning (SSL) is attractive because of its capability to further unveil the power of machine learning with abundant cheap unlabeled data~\cite{van2020survey,van2020survey,radford2015unsupervised,lee2013pseudo,berthelot2019mixmatch,sohn2020fixmatch,rasmus2015semi}. Due to the space limitation, this section only reviews self-training-based methods, which is one of the most engaging directions in SSL~\cite{mclachlan1975iterative, scudder1965probability}. In general, self-training-based semi-supervised learning methods first train a teacher model with a small set of human-annotated data. The teacher model then generates pseudo labels on a much larger set of unlabeled data.
Finally, a student model is trained with both human-labeled and self-annotated data.
Such a paradigm has demonstrated great success in 
image classification~\cite{tarvainen2017meanteacher,berthelot2019mixmatch,sohn2020fixmatch,xie2020self}, semantic segmentation~\cite{yang2022st++,liu2022perturbed,yuan2022semi}, and 2D object detection~\cite{xu2021softteacher,zhou2022denseteacher,zhang2022semi}.
While different applications usually require additional bells and whistles, the core components of semi-supervised learning remain unchanged: how to generate high-quality pseudo-label, and how to retrain student models effectively.
Mean-Teacher~\cite{tarvainen2017meanteacher} proposes temporal ensembling to facilitate retraining. Soft-Teacher~\cite{xu2021softteacher} utilizes the classification score to reweight loss and imposed 2D box jitter to filter unreliable pseudo labels. ST++~\cite{yang2022st++} adopts strong augmentations on the unlabeled samples and leverages evolving stability during training to prioritize high-quality labels.
Compared with well-studied 2D tasks, it is much more challenging for Mono3D detection to collect reliable pseudo labels. Although such issue can be alleviated by introducing multi-view consistency~\cite{lian2022semimono3d}, compared with abundant single-view datasets, high-quality stereo or multi-view datasets are much harder to collect (device-wise multi-view). Besides, learning consistency among video frames is vulnerable to moving objects (temporal-wise multi-view). Thus we believe, it is the single-view scenario that semi-supervised learning can make the most impact. In this paper, we focus on the design of effective semi-supervised learning frameworks for Mono3D object detection.

% It is, however, restricted to stereo or multi-view requirement that may be not easily guaranteed in practical scenarios. In particular, arranging binoculars or multiple cameras increase cost, and estimating depth from video frames shows extreme vulnerability for moving objects. Instead, in this work, we tend to construct a semi-supervised Mono3D detection framework using only single-camera, -view, and -modality inputs, without relying on the multi-view, or any other modality (\eg, LiDAR) information.



% In this work, we explore the robust pseudo label generation method for Mono3D object detection and design a learning-based model to adaptively evaluate the contribution of each pseudo label to model training, which is distinct from previous works using handcrafted and rule-based model updating strategies.

% 

% and leverages evolving stability during training to prioritize reliable labels

%  because of the lagging performance