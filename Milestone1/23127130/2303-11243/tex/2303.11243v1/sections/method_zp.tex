

\section{Method}
Our proposed semi-supervised framework (\cref{fig::overall}) is detailed in this section.
We first recap the definition of semi-supervised Mono3D object detection task and introduce the vanilla self-training scheme in~\cref{Preliminary}.
The augmentation-based prediction aggregation (APG)
for robustly generating high-quality pseudo labels is described in~\cref{sec:method:subsec:APG}, and the critical retraining strategy (CRS) for adaptively learning from unlabeled data is described in \cref{sec:method:subsec:critical_retraining_strategy}.

% Then, we introduce our Augmented-Based Prediction Aggregation (APG) in Sec.~\ref{sec:method:subsec:APG} and present the critical retraining strategy (CRS) in Sec.~\ref{sec:method:subsec:critical_retraining_strategy}.












\subsection{Preliminary}
\label{Preliminary}
% \subsubsection{Task Definition}
% \label{sec:method:subsec:task_definition}
\textbf{Task Definition.}
Given an image sample $x$ in the labeled dataset, its ground truth label $y$ contains information about the category, location, dimension, and orientation of objects visible in $x$.
Semi-supervised Mono3D object detection aims to acquire knowledge from both precisely annotated dataset $\mathcal{D}_l = \{x_i^l, y_i^l\}_{i=1}^{N_l}$ and unlabeled dataset $\mathcal{D}_u = \{x_j^u\}_{j=1}^{N_u}$, where $N_u \gg N_l$.

% We aim to make full use of these two datasets to improve the model performance.

% \subsubsection{Plainest Self-Training Scheme}
% \label{sec:method:subsec:plainest_self-training_scheme}

\textbf{Vanilla Self-Training Scheme.}
As a prominent branch in semi-supervised learning~\cite{self-training-survey, yang2022st++}, self-training works by iteratively optimizing a model with the help of pseudo-labels on the unlabeled samples.
%pseudo-labels to the set of unlabeled training samples is a prominent branch in existing semi-supervised techniques~\cite{self-training-survey, yang2022st++}. 
%Without considering the iterative training strategy, 
A vanilla self-training~\cite{yang2022st++} pipeline contains three major steps: 1) \textit{Standard Supervised Training} which trains a teacher model $M_t$ on the labeled dataset $\mathcal{D}_l$, 2) \textit{Pseudo Label Generation} which predicts pseudo labels $\{\hat y = M_t(x_j) | x_j \in \mathcal{D}_u\} $ on the unlabeled dataset $\mathcal{D}_u$, and 3) \textit{Retraining with Noisy Labels} which learns a student model $M_s$ for final evaluation.
Using $M_s$ as the new teacher, the step 2 and 3 can be repeated until satisfactory performance is obtained.  

% To indicate the enormous potential of self-training, we conduct a simple pilot study adopting a point-cloud-based 3D detector to generate pseudo labels for retraining. As shown in Tab.~\ref{tab:pilot}, without any additional modification, the self-training paradigm brings significant improvement over the baseline model. It even surpasses the SoTA Mono3D method MonoDETR~\cite{zhang2022monodetr} with large margins. Intuitively, the quality of generated pseudo labels decides the upper bound of the self-training paradigm and the retraining strategy improves the training effectiveness with pseudo labels containing much noise.

In this paper, we elaborately investigate the pseudo label generation (step 2) and retraining strategy (step 3), which are the most crucial parts of the self-training scheme. For simplicity, we don't iteratively perform step 2 and 3.

% To fully demonstrate the effectiveness and simplicity of the proposed semi-supervised framework

\subsection{Augmentation-Based Prediction Aggregation}
\label{sec:method:subsec:APG}

To obtain high-quality pseudo labels, previous 2D semi-supervised learning methods~\cite{wang2021fcos3d,xu2021softteacher,li2022stmono3d, zhou2022denseteacher,chen2022labelmatch} resort to a suitable threshold $\tau{}$ to filter predicted boxes.
However, it is non-trivial to determine an optimal threshold for each different method, especially in the ill-posed Mono3D object detection. A higher threshold may bring tons of false negatives (FN), decreasing the quantity of useful pseudo labels. In contrast, a lower threshold may introduce more false positives (FP), resulting in adverse noises. In order to alleviate the dependency on such a handcrafted threshold, we propose the APG strategy to effectively aggregate predictions from different observations of the same image sample to improve the robustness of pseudo-label generation.

\begin{figure}[t]
    \centering
    \footnotesize
    \includegraphics[width=0.97\linewidth]{images/method1.pdf}
    \caption{\textbf{Illustration of APG.} We aggregate the predictions from $K$ different transformations of an unlabeled image. The by-product reliability scores estimated by MLE is adopted in retraining to measure the uncertainty of pseudo labels. } 
    \label{fig::method1}
\end{figure}

%  The transformations are automatically learned by TPE~\cite{bergstra2011algorithms}. 

The proposed algorithm, that is illustrated in Alg.~\ref{alg:st} and Fig.~\ref{fig::method1}, consists of three steps: 

\textbf{1)} Firstly, given an input image from the unlabeled dataset $x_j^u\in \mathcal{D}_u$, the teacher model $M_t$ predicts the detection results for $x_j^u$ and its $K$ augmented images. Let $\mathcal{P}_r$ denote the raw prediction of $x_j^u$, and $\mathcal{P}_f^0$ and $\{\mathcal{P}_f^k\}_{k=1}^{K}$ represent the post-processed (by the pre-defined threshold $\tau$) predictions of $x_j^u$ and the augmented images, respectively. 

\textbf{2)} Secondly, for each prediction $p_i$ in $\mathcal{P}_f^{0}$, we apply the kNN clustering algorithm to find its nearest neighbors in $\{\mathcal{P}_f^k\}_{k=1}^K$, that forms a cluster. $p_i$ is considered as a pseudo label for $x_j^u$. Intuitively, the number of assigned predictions $n$ in the cluster indicates the difficulty degree in detecting an object, and the variance $\sigma$ by Maximum Likelihood Estimation (MLE) measures the uncertainty of $p_i$. With the classification score $s$, these by-products are combined by Eq.~\ref{eq:weight} to demonstrate $p_i$'s reliability, which is then used to weight the loss of each unlabeled data in retraining.
\begin{equation}
    w = \gamma_1 \times s + (1 - \gamma_1) \times \exp{(-\frac{\sigma}{n} * \gamma_2)},
    \label{eq:weight}
\end{equation}
We set $\gamma_1 = 0.6$ and $\gamma_2 = 6$ in our model, respectively.
%where $\gamma_1$ and $\gamma_2$ are two hyper-parameters that are set as 0.6 and 6 in our model, respectively.

\textbf{3)} Finally, for the unused predictions in $\{\mathcal{P}_f^k\}_{k=1}^K$, they would be self-clustered. The cluster centers are treated as reference points, whose closest prediction in $\mathcal{P}_r$ are selected as pseudo labels. Their uncertainties are measured by Eq.~\ref{eq:weight}.



% as a reference point, the kNN clustering algorithm assigns the related ones in augmented predictions $\{\mathcal{P}_f^k\}_{k=1}^K$ with it to form a cluster.




% In particular, given an input image from the unlabeled dataset $x_j^u\in \mathcal{D}_u$, we apply different affine transformations to $x_j^u$ and get their corresponding detection results from the trained teacher model $M_t$. 

% The raw detection results $\mathcal{P}_r$ contain classification scores $s$, 2D centers $c$, and 3D attributes of the objects. A threshold $\tau$ is used to filter out the predictions with low classification scores.
% We denote the filtered results on the original input image as $\mathcal{P}_f^0$, and the filtered results from the $K$ augmented images as $\{\mathcal{P}_f^k\}_{k=1}^{K}$.
% Then, we aggregate all these predictions with the proposed \textbf{Center Aggregation} algorithm, as detailed in~\cref{alg:st}. Specificially, considering each prediction in $\mathcal{P}_f^{0}$ as an anchor, the kNN clustering algorithm assigns the related ones in augmented predictions $\{\mathcal{P}_f^k\}_{k=1}^K$ with it to form a cluster. For the unassigned ones in $\{\mathcal{P}_f^k\}_{k=1}^K$, they would be self-clustered, and the cluster centers are treated as anchors. To this end, the predictions corresponding with all the anchors represent the pseudo label for this unlabeled image. Under the Gaussian distribution assumption, the Maximum Likelihood Estimation (MLE) is adopted to measure the variance of a prediction cluster. Intuitively, the number of samples $n$ in a cluster indicates the detection difficulty of an object, while the variance $\sigma$ measures the accuracy and uncertainty of its predictions. With the classification score, these by-products are combined by Eq.~\ref{eq:weight} to demonstrate the reliability of the generated pseudo labels, which are then used as a clue to weight the loss of each unlabeled data in the retraining phase.
% \begin{equation}
%     w = \gamma_1 \times s + (1 - \gamma_1) \times \exp{(-\frac{\sigma}{n} * \gamma_2)},
%     \label{eq:weight}
% \end{equation}
% where $\gamma_1$ and $\gamma_2$ are two hyper-parameters that are set as 0.6 and 6 in our model. 

% The calculated weight $w$ is adopted on the classification loss $\mathcal{L}_{cls}$ of samples with pseudo labels.
% to augment the unlabeled images for pursuing more robust pseudo label generation.
Moreover, inspired by successful attempts at auto data augmentations~\cite{cubuk2018autoaugment,lim2019fastaugment}, we resort to the
Tree-Structured Parzen Estimators (TPE)~\cite{bergstra2011algorithms} to automatically pick the $K$ transformations and their hyper-parameters (\emph{e.g.}, resize ratio). More details are presented in supplementary materials.

% Please refer to the for more details

%Moreover, it is inefficient to manually choose $K$ augmentations. In this work, we adopt the Tree-Structured Parzen Estimators (TPE)~\cite{bergstra2011algorithms} to automatically decide the transformations and their hyper-parameters (\emph{e.g.}, resize ratio). The inspiration is drawn from automatical data augmentation in other fields~\cite{cubuk2018autoaugment,lim2019fastaugment},
%but much simpler. More details about TPE will be presented in supplementary materials due to space limitation. Code and models would also be released for reproduction. 



% we demonstrate that content-based transformation (\emph{e.g.,} color jitter) is less effective than geometry-based augmentation (\emph{e.g.} shift and resize) for improving recall in monocular 3D object detection. The underlying reason is that missing detections in the task are generally caused by complicated object geometry distribution (see Sec.~\ref{sec:exp:subsec:APG}). For example, when enlarging objects that are far from the camera, it may be easily detected, since this transformation is similar to pulling the object to the camera..


% \input{tables/pilot}

\input{algrithoms/aggregate_center}

\subsection{Critical Retraining Strategy}
\label{sec:method:subsec:critical_retraining_strategy}
% and discard harmful ones during training

Generated pseudo labels inevitably contain noises, thus it is crucial to find informative ones that benefit model evolution. Previous methods (\eg,~\cite{xu2021softteacher}) use the box jitter scores as proxies for the pseudo label quality. However, it might be hard to replicate the success of such strategy in the Mono 3D detection due to the inferior performance of the teacher model $M_t$.
The uncertainty measurements of pseudo labels provided by the APG module can enhance the stability of student model retraining, but it still suffers from the fixed weight of each sample. We argue that the contribution of each sample during model training should adapt to the model's state as training proceeds~\cite{crs_ref1, crs_ref2}.




% not be fully utilized, if each sample is still treated equally during training.
% Although the uncertainty measurement of samples in APG can enhance the stability of student model retraining, it still suffers from fixed weight of each sample, degrading the detection performance.
%The generated pseudo labels inevitably contain noise. Therefore, it is crucial to find informative samples that benefit the model evolve, meanwhile discard the other harmful ones for training. Previous works~\cite{xu2021softteacher} consider the jitter score of a box as its quality, however, hindered by the inferior performance of Mono3D detectors, it is unable to guarantee the reliability of this strategy. As discussed in Sec.~\ref{sec:method:subsec:APG}, we improve the uncertainty measurement by considering the distribution of predictions in both the raw input image and its augmented ones. It can somewhat enhance the stability of retraining a student model, as experimentally demonstrated in Sec.~\ref{sec:exp:subsec:APG}. However,
% Instead of being indicated by an immutable number (\textit{e.g.,} jitter score in previous works~\cite{xu2021softteacher}), we argue that the contribution of each sample during model training should change across training iterations and the modelâ€™s parameters~\cite{crs_ref1,crs_ref2} in an adaptive manner.
To this end, we propose a learning-based critical module to adaptively find the informative unlabeled data, which may provide a new perspective for semi-supervised Mono3D object detection to retrain a better student model. 

% the previous observation on an input image from the unlabeled dataset $x_i^u$ as $\mathcal{O}_{0}$,

\begin{figure}[!t]
    \centering
    \footnotesize
    \includegraphics[width=0.98\linewidth]{images/method2.pdf}
    \caption{\textbf{Illustration of CRS.} We adopt a critical module to discriminate whether a sample from the unlabeled data benefits model convergence. The memory bank is cyclically updated.} 
    \label{fig::method2}
\end{figure}

% to encode sample information to network weights

Specifically, the critical module first evaluates the effect of a training sample from the unlabeled dataset, and then assigns it with a 0-1 binary flag indicating whether to back-propagate its gradients. From a reinforcement learning perspective, we regard the Mono3D detector (student model) as an \textit{agent}, the model's weight parameters as the~\textit{state}, the input image and the output of the model as an \textit{observation}. 
At state $\mathcal{S}$, a detection loss $\mathcal{L}_{unsup}$ for the agent can be calculated based on the given observation $\mathcal{O}$.
If the gradients of $\mathcal{L}_{unsup}$ are back-propagated, the state will be updated to $\mathcal{S}^{'}$ and the model output will be updated to $\mathcal{O}^{'}$. The critical module then evaluates whether $\mathcal{S}^{'}$ is the optimal choice of updated $\mathcal{S}$ based on the observations $\mathcal{O}$ and $\mathcal{O}^{'}$.

% this step benefits the convergence of model on the labeled dataset $\mathcal{D}_l$.

% which updates parameters based on the loss $\mathcal{L}_{unsup}$ calculated with the pseudo label $\hat y_i^u$. The critical module takes the state and outputs of the detector before and after update as input, and evaluates if this step benefits the convergence of model on the labeled dataset $\mathcal{D}_l$.


% where $\mathcal{L}$ generically consists of the classification loss $\mathcal{L}_{cls}$ and the regression loss $\mathcal{L}_{reg}$.

At each training step, an input image $x_i^u$ from the unlabeled data is fed into the detector $M$ (agent), obtaining the detection predictions $\mathbf{D}$ (classification and regression response maps),
% \begin{equation}
%     \mathbf{D} = M(x_i^u | \mathbf{\Theta}),
% \end{equation}
\begin{equation}
    \mathbf{D} = M(x_i^u | \mathcal{S}),
\end{equation}
With the pseudo label $\hat y_i^u$, we can get the training loss,
\begin{equation}
\mathcal{L}_{unsup} = \mathcal{L} (\mathbf{D}, \hat y_i^u),
\end{equation}
We take one `\textit{trial}' gradient descent step to obtain the updated model $M'$ with parameters $\mathcal{S}^{'}$. Then, the critical module evaluates the effectiveness of this update ($\mathcal{S} \rightarrow \mathcal{S}^{'}$),
\begin{equation}
    v = \mathcal{C}(x_i^u, \mathbf{D}, \mathbf{D}^{'} | \Psi),
    \label{eq:cr}
\end{equation}
where $\mathbf{D}^{'}$ is the detection predictions of the updated model $M'$ on $x_i^u$, and $\Psi$ is the parameter of the critical module. During training, we chop off a certain number of samples with the lowest evaluation value $v$ (see Fig.~\ref{fig::method2}).


% When $v$ is larger than 1, $x_i^u$ will be considered as an informative sample, and this update is retained. Otherwise, the update is discarded, and the model parameters will be reverted to $S$. The scheme is illustrated in Fig.~\ref{fig::method2}.

% for guiding model updating
To guarantee the critical module can provide reliable feedback, we propose a reward function to supervise the training of the critical network,
% Moreover, it is crucial to design a feasible training objective to make sure the cirtical module can provide reliable feedback.
% % The most crucial part to guarantee the critical network predict reliable feedback is designing a feasible training objective. 
% In our work, we propose a reward function to supervise the training of the critical network,
\begin{equation}
    r = \mathcal{L}(M(x_i| \mathcal{S}), y_i) - \mathcal{L}(M'(x_i|\mathcal{S}^{'}), y_i),
    \label{eq:reward}
\end{equation}
where $(x_i, y_i)$ denotes samples from the training set of the labeled dataset $\mathcal{D}_l$. The L2 loss~\cite{l2loss} is applied to $v$ and $r$ for supervising the learning of critical module. During training, we alternately update the detector and critical module. 

Notably, it's impractical to evaluate all samples to get a reliable reward $r$ due to the unaffordable computation cost. Motivated by the self-supervised method MoCo~\cite{chen2020mocov2}, we employ a  memory bank (queue) to buffer the training samples in $\mathcal{D}_l$ and cyclically update it. After tons of steps updating, the knowledge of all samples for evaluation are encoded to the weight parameters of the critical network, making it capable of predicting accurate indicator.

% Compared with another  a small mini-batch, the signal is more stable, making global-aware optimization possible. 

% During the training, the critical module learns to evaluate the influence of detector update on the labeled training set. In addition, it serves as a indicator for continue learning~\cite{li2017learning} as well. The module provides the measurement value based on the knowledge from whole labeled training set. Compared with a small mini-batch, the signal is more stable, making global-aware optimization possible.