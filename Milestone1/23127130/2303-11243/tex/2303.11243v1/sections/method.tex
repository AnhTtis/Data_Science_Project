\section{Method}
As shown in Fig.teaser, under the semi-supervised self-training paradigm, our method mainly focuses on the generation of pseudo labels and the re-training strategy with noisy labels. In this section, we first give the definition of semi-supervised monocular 3D object detection task in Sec.~\ref{sec:method:subsec:task_definition} and formulate the plainest self-training scheme in Sec.~\ref{sec:method:subsec:plainest_self-training_scheme}. Then, we introduce our Augmented-Based Prediction Aggregation (ABPA) to generate pseudo labels in Sec.~\ref{sec:method:subsec:ABPA} and present the critical retraining strategy (CRS) in Sec.~\ref{sec:method:subsec:critical_retraining_strategy}.

\input{algrithoms/aggregate_center}

\begin{figure}[t]
    \centering
    \footnotesize
    \includegraphics[width=0.98\linewidth]{images/method1.pdf}
    \caption{1.} 
    \label{fig::method1}
\end{figure}

\begin{figure}[t]
    \centering
    \footnotesize
    \includegraphics[width=0.98\linewidth]{images/method2.pdf}
    \caption{2.} 
    \label{fig::method2}
\end{figure}


\subsection{Task Definition}
\label{sec:method:subsec:task_definition}
Semi-supervised monocular 3D object detection aims to generalize from a combination set of labeled dataset $\mathcal{D}_l = \{x_i^l, y_i^l\}_{i=1}^{N_l}$ and unlabeled dataset $\mathcal{D}_u = \{x_i^u\}_{i=1}^{N_u}$, where $x$ denotes the image, $y$ denotes the label in the form of object class $k$, location $(c_x, c_y, c_z)$, size in each dimension $(d_x, d_y, d_z)$, and orientation $\theta$, respectively. In most cases, $N_u \gg N_l$ indicating much more samples are available on the unlabeled dataset. We aim to make full use of these two datasets to improve the model performance.

\subsection{Plainest Self-Training Scheme}
\label{sec:method:subsec:plainest_self-training_scheme}

We present the plainest form of self-training~\cite{yang2022st++}. Without the iterative training and the end-to-end framework, it includes three major steps:

(1) [Standard Supervised Training] Training a teacher model $M_t$ on the labeled dataset $\mathcal{D}_l$ with the supervised loss $\mathcal{L}_{sup}$.
(2) [Pseudo Label Generation] Predict pseudo labels $\hat y$ on the unlabeled dataset $\mathcal{D}_u$ to obtain $\mathcal{\hat D}_u = \{x_i^u, \hat y_i^u\}_{i=1}^{N_u}$.
(3) [Retrain with Noisy Labels] Re-train a student model $M_s$ on the union set $\mathcal{D}_l \cup \mathcal{\hat D}_u$ with the total loss $\mathcal{L}_{total} = \mathcal{L}_{sup} + \mathcal{L}_{unsup}$ for final evaluation.


To indicate the enormous potential of self-training, we conduct a simple pilot study adopting a point-cloud-based 3D detector to generate pseudo labels for retraining. As shown in Tab.~\ref{tab:pilot}, without any additional modification, the self-training paradigm brings significant improvement over the baseline model. It even surpasses the SoTA Mono3D method MonoDETR~\cite{zhang2022monodetr} with large margins. Intuitively, the quality of generated pseudo labels decides the upper bound of the self-training paradigm and the retraining strategy improves the training effectiveness with pseudo labels containing much noise.

In this paper, we elaborately investigate the pseudo label generation and retraining strategy, which are the most crucial parts of the self-training scheme.

\subsection{Augmented-Based Prediction Aggregation}
\label{sec:method:subsec:ABPA}

As shown in previous detection methods~\cite{wang2021fcos3d,xu2021softteacher,li2022stmono3d, zhou2022denseteacher,chen2022labelmatch}, deciding a suitable classification score $\tau$ as threshold to filter unreliable predictions is crucial. Intuitively, higher threshold leads to tons of false negative (FN) samples, decreasing the number of pseudo labels and hurting the recognition capability of student model. In contrast, lower threshold introduces more false positive (FP) samples, resulting in adverse noise retraining. To ameliorate these issues, based on an offline pipeline, we propose the ABPA to effectively aggregate predictions.

Given an input image $x_i^u\in \mathcal{D}_u$, we apply multiple affine transforms and get corresponding augmented (disturbed) results $\{x_d^i\}_{i=1}^K$. For each image in $\{\{x_i^u\} \cup \{x_d^i\}_{i=1}^K\}$, the trained model predicts classification scores $s$, 2D centers $c$ and 3D attributes of the recognized objects. We leverage a preliminary threshold $\tau$ to initially screen the predictions and then obtain the raw image prediction $\mathcal{P}_r$, raw image filtered prediction $\mathcal{P}_f$, and $K$ augmented images filtered prediction $\{\mathcal{P}_d^i\}_{i=1}^K$. 

Through the \textbf{Center Aggregation} algorithm presented in Alg.~\ref{alg:st}, we post-process the predictions by KNN clustering. Within clusters and the Gaussian distribution assumption, we utilize the Maximum Likelihood Estimation (MLE) to calculate the cluster center and measurement variance. For clusters not containing predictions from $\mathcal{P}_f$, we adopt a nearest search strategy that gathers the prediction from $\mathcal{P}_r$ with the highest score in a fixed circular near domain.

Ideally, the number of samples in a cluster indicates the detecting difficulty, whereas the variance measures the accuracy of localization. Combining with the classification score, these by-products can comprehensively present the reliability of 2D center predictions, naturally contributing to solid weights for the retraining. Moreover, the choices of $K$ augmentations and related parameters in the algorithm by handcraft are inefficient. Motivated by~\cite{cubuk2018autoaugment,lim2019fastaugment}, we adopt the Tree-Structured Parzen Estimators algorithm~\cite{bergstra2011algorithms} to search satisfactory parameters.


\input{tables/pilot}



\subsection{Critical Retraining Strategy}
\label{sec:method:subsec:critical_retraining_strategy}

Given pseudo labels containing tons of noise, exploring informative samples while discarding harmful noisy labels are crucial and \textit{de facto} needs. However, hindered by the inferior performance of Mono3D detector, it is extremely tricky to obtain a reliable measurement for the predictions of 3D attribute, leading to the sub-optimal benefit of pseudo labels. To overcome this issue, we propose the a \textbf{critical module} to facilitate the learning process, permitting to fully exploit the informative and harmful samples.

Specifically, the critical module evaluates the effect of training samples $(x_i^u, \hat y_i^u)$ and guide the optimization with evaluation performance. Analogous to the reinforcement learning algorithm, the state is the input image $x_i^u$, and the agent is the Mono3D detector, which updates parameters based on the loss $\mathcal{L}_{unsup}$ calculated with the pseudo label $\hat y_i^u$. The critical module takes the state and outputs of the detector before and after update as input, and evaluates if this step benefits the convergence of model on the labeled dataset $\mathcal{D}_l$.

At each training step, given the input image $x_i^u$ as the state, we forward detector $M$ to obtain the ouput $\mathcal{F}$, which is formulated as
\begin{equation}
    \mathcal{F} = M(x_i^u | \phi),
\end{equation}
where the $\phi$ is the model parameters. With the pseudo label $\hat y_i^u$, we calculate the unsupervised loss as
\begin{equation}
\mathcal{L}_{unsup} = \mathcal{L} (\mathcal{F}, \hat y_i^u),
\end{equation}
where the $\mathcal{L}$ generically includes the classification loss $\mathcal{L}_{cls}$ and the regression loss $\mathcal{L}_{reg}$. With the loss, we take one fake gradient descent step and obtain the updated model $M'$ with parameters $\phi'$. Then, we leverage the critical module to evaluate the update and get the evaluation value $V$ as 
\begin{equation}
    V = \mathcal{C}(x_i^u, \mathcal{F}, \mathcal{F}' | \theta),
\end{equation}
where $\mathcal{F}'$ is the output of the updated model $M'$ to the input $x_i^u$, and $\theta$ is the parameter of critical module. We select informative samples with $V>0$ to train the detector.

To guide the critic network to predict the actual value of model update, we design a reward signal $R$ which reflects our task objective as
\begin{equation}
    R = \mathcal{L}(M(x_i|\phi), y_i) - \mathcal{L}(M(x_i|\phi'), y_i),
\end{equation}
where $(x_i, y_i)$ denotes samples from the training set in labeled dataset $\mathcal{D}_l$. In practice, we alternately updated the detector and critical module. We also apply a memory bank to buffer the training samples in $\mathcal{D}_l$ and update it cyclically. 

During the training, the critical module learns to evaluate the influence of detector update on the labeled training set. In addition, it serves as a indicator for continue learning~\cite{li2017learning} as well. The module provides the measurement value based on the knowledge from whole labeled training set. Compared with a small mini-batch, the signal is more stable, making global-aware optimization possible.