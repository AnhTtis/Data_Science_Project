\section{Results}
\label{sec:results}

%%%---------------------------%%%
%%%---------------------------%%%

\paragraph{Performance comparison:}
For both datasets, we first compare the performance of our method against the baseline consistency methods in \cref{tab:results_introspect} and \cref{tab:results_dme}. In either case, we see that our method outperforms previous approaches, by not only increasing overall prediction accuracy but also by increasing consistency. In \cref{fig:examples_introspect} and \cref{fig:examples_dme}, we show illustrative examples of our approach on the Introspect and DME datasets, respectively (see additional examples in the Supplementary materials).

%\begin{table}[!b ]
%  \centering
%  \begin{tabular}{@{}lccc@{}}
%    \toprule
%     Model & Cons. Method & Acc. & Cons. \\
%     \midrule
%     BAN & None & 67.14$\pm$0.10 & 69.45$\pm$0.17 \\
%     BAN & SQuINT~\cite{selvaraju2020squinting} & 67.27$\pm$0.19 & 69.87$\pm$0.45 \\
%     BAN & CP-VQA~\cite{tascon2022consistency} & 67.18$\pm$0.24 & 69.52$\pm$0.45\\
%     BAN & {\bf Ours} ($\lambda=0.01$) & {\bf 67.36$\pm$0.19} & {70.38$\pm$0.39} \\
%    \midrule
%    LXMERT & None & 75.10$\pm$0.10 & 76.24$\pm$0.63 \\
%    LXMERT & Random flip & 69.67$\pm$1.24 & 75.99$\pm$3.91\\
%    LXMERT & Flip first & 73.81$\pm$0.47 & 71.94$\pm$2.82\\
%    LXMERT & Flip second & 65.82$\pm$1.03 & {87.56$\pm$2.51}\\
%    LXMERT & {\bf Ours} & {\bf 75.17$\pm$0.08} & {78.75$\pm$0.21} \\
%    \bottomrule
%  \end{tabular}
%  \caption{Results of different consistency methods on the Introspect dataset using two different VQA models: (top) BAN and (bottom) LXMERT. In the case of LXMERT, we show the impact of randomly flipping the answer of either the first or the second question for pairs detected as inconsistent using the relations from LI-MOD. Similarly, {\it flip first} and {\it flip second} refer to flipping the answer of the first and second question in inconsistent pairs, respectively. \STM{STDs added}}
%  \label{tab:results_introspect}
%\end{table}


\begin{table}[!b ]
  \centering
  \begin{tabular}{@{}llcc@{}}
    \toprule
     Model & Cons. Method & Acc. & Cons. \\
     \midrule
     \multirow{4}{*}{BAN} & None & 67.14$\pm$0.10 & 69.45$\pm$0.17 \\
      & SQuINT~\cite{selvaraju2020squinting} & 67.27$\pm$0.19 & 69.87$\pm$0.45 \\
      & CP-VQA~\cite{tascon2022consistency} & 67.18$\pm$0.24 & 69.52$\pm$0.45\\
      & {\bf Ours} ($\lambda=0.01$) & {\bf 67.36$\pm$0.19} & {70.38$\pm$0.39} \\
    \midrule
    \multirow{5}{*}{LXMERT} & None & 75.10$\pm$0.10 & 76.24$\pm$0.63 \\
     & Random flip & 69.67$\pm$1.24 & 75.99$\pm$3.91\\
     & Flip first & 73.81$\pm$0.47 & 71.94$\pm$2.82\\
     & Flip second & 65.82$\pm$1.03 & {87.56$\pm$2.51}\\
     & {\bf Ours} & {\bf 75.17$\pm$0.08} & {78.75$\pm$0.21} \\
    \bottomrule
  \end{tabular}
  \caption{Results of different consistency methods on the Introspect dataset using two different VQA models: (top) BAN and (bottom) LXMERT. In the case of LXMERT, we show the impact of randomly flipping the answer of either the first or the second question for pairs detected as inconsistent using the relations from LI-MOD. Similarly, {\it flip first} and {\it flip second} refer to flipping the answer of the first and second question in inconsistent pairs, respectively.}
  \label{tab:results_introspect}
\end{table}

\begin{table*}[t]
\centering
\begin{tabular}{@{}llcccccr@{}}
\toprule
\multirow{2}{*}{Model} &  \multicolumn{1}{l}{\multirow{2}{*}{Consis. Method}}   & \multicolumn{5}{c}{Accuracy}  & \multicolumn{1}{c}{\multirow{2}{*}{Consistency}} \\ \cline{3-7}
\multicolumn{1}{c}{}         &\multicolumn{1}{c}{}                  & \multicolumn{1}{c}{all} & \multicolumn{1}{l}{grade} & \multicolumn{1}{c}{whole} & \multicolumn{1}{c}{macula} & \multicolumn{1}{c}{region} & \multicolumn{1}{l}{}                             \\ 
\midrule
\multirow{4}{*}{MVQA}     &   \multicolumn{1}{l}{None}          & \multicolumn{1}{c}{81.15$\pm$0.49}   & \multicolumn{1}{c}{78.17$\pm$2.07} & \multicolumn{1}{c}{83.44$\pm$1.87} & \multicolumn{1}{c}{87.25$\pm$1.20}  & \multicolumn{1}{c}{80.38$\pm$2.02}  & \multicolumn{1}{c}{89.95$\pm$3.20}                        \\ 

 &  \multicolumn{1}{l}{SQuINT~\cite{selvaraju2020squinting}}& \multicolumn{1}{c}{80.58$\pm$0.78}   & \multicolumn{1}{c}{77.48$\pm$0.40} & \multicolumn{1}{c}{82.82$\pm$0.74} & \multicolumn{1}{c}{85.34$\pm$0.87}  & \multicolumn{1}{c}{80.02}  & \multicolumn{1}{c}{89.39$\pm$2.12}               
\\ 

 &  \multicolumn{1}{l}{CP-VQA~\cite{tascon2022consistency}}& \multicolumn{1}{c}{83.49$\pm$0.99}   & \multicolumn{1}{c}{\textbf{80.69$\pm$1.30}} & \multicolumn{1}{c}{84.96$\pm$1.14} & \multicolumn{1}{c}{87.18$\pm$2.18} & \multicolumn{1}{c}{\textbf{83.16$\pm$1.09}}  & \multicolumn{1}{c}{94.20$\pm$2.15}  
\\ 

 &  
\multicolumn{1}{l}{{\bf Ours} ($\lambda=0.25$)}& \multicolumn{1}{c}{\textbf{83.59$\pm$0.69}}   & \multicolumn{1}{c}{80.15$\pm$0.95} & \multicolumn{1}{c}{\textbf{86.22$\pm$1.67}} & \multicolumn{1}{c}{\textbf{88.18$\pm$1.07}}  & \multicolumn{1}{c}{82.62$\pm$1.02}  & \multicolumn{1}{c}{{95.78$\pm$1.19}}  

\\ \bottomrule
                                                 
\end{tabular}
\caption{Comparison of methods on the DME dataset with common MVQA backbone. Accuracy and consistency is reported for all questions, as well as different medically relevant sub-question categories: grade, whole, macula and region.
}
\label{tab:results_dme}
\end{table*}
\begin{figure*}[!t]
\centering
\includegraphics[width=0.84\textwidth]{images/examples_ban.pdf}
\caption{Qualitative examples from the Introspect dataset using BAN as backbone. Red siren symbols indicate inconsistent cases.}
\label{fig:examples_introspect}
\end{figure*}
\begin{figure*}[!t]
\centering
\includegraphics[width=0.8\textwidth]{images/examples_dme.pdf}
\caption{Examples from the DME dataset and comparison of methods. Red siren symbols indicate inconsistent cases. DME is a disease that is staged into grades (0, 1 or 2), which depend on the number of visual pathological features of the retina. \textit{Top} and \textit{middle:} Although all methods correctly predict the answer to the first question, some inconsistencies appear when a necessary condition is false. \textit{Bottom}: Only the None baseline produces an inconsistency. Note that SQuINT and CP-VQA's answers do not produce inconsistent pairs because both questions were answered incorrectly, and those answers (``2" and ``yes") respect all known relations. 
}
\label{fig:examples_dme}
\end{figure*} 

In \cref{tab:results_introspect} we also show the performance of the state-of-the-art LXMERT VQA model when combined with our proposed consistency method. In this case too, we see that our method provides increased performances via consistency improvements. Here we investigate the performance induced when flipping the answers of one of the members of each inconsistent pair at test time. Suppose implication labels are present, either by manual annotation or by LI-MOD. In that case, a trivial manner of correcting an inconsistent QA pair of binary answers is to flip or negate one of the answers. This is far simpler than our proposed method as it permits training the VQA model with the standard VQA loss. Having obtained the answers from the model when $\lambda=0$, we identify the inconsistent pairs using the relations predicted by our LI-MOD and then flip the answers (1) either randomly, (2) of the first QA or (3) of the second QA. By including the flipping baselines, we confirm that the added complexity in training our method results in improved accuracy compared to merely correcting inconsistencies post-hoc.To explain why the consistency can increase while the accuracy decreases, consider the following: An inconsistent QA pair guarantees that one of the two answers is incorrect, but correcting the inconsistency does not necessarily fix the incorrect answer. By flipping the correct answer, the inconsistency is corrected, thereby increasing the consistency but decreasing the accuracy. This phenomenon is particularly noticeable in the flipping baselines, as they fix inconsistencies without considering their correctness.

%By doing so, we can better gauge the utility of LI-MOD in improving consistency in our approach. 

In general, we observe that training LXMERT with our consistency loss provides performance gains. Indeed, while random flipping based on LI-MOD clearly deteriorates the performance of LXMERT, so are flipping the first or second answers. This implies that our proposed method indeed leverages the predictions of LI-MOD to make LXMERT more consistent as it improves both model accuracy and consistency. 
\begin{figure*}[!t]
\centering
\includegraphics[width=0.85\textwidth]{images/lambda.pdf}
\caption{Behavior of the accuracy and consistency as a function of $\lambda$ with 95\% confidence intervals. \textit{Left:} LXMERT trained on the Introspect dataset (5 models with random seeds for each value of $\lambda$). \textit{Right:} MVQA trained on the DME dataset (10 models with random seeds for each $\lambda$).
}
\label{fig:lambda}
\end{figure*}
%%%---------------------------%%%
%%%---------------------------%%%


\paragraph{Sensitivity of $\bm{\lambda}$:} We now show the sensitivity of our method and its relation to $\lambda$. We evaluate the performance of our method for different values of $\lambda$ to understand the behaviour of the performance, both in terms of accuracy and consistency. 

\cref{fig:lambda} shows the accuracy and consistency of LXMERT and MVQA for different values of $\lambda$. The difference in the ranges of the values is due to the relative magnitude of the loss function terms and depends on the used loss functions (\eg, binary and non-binary cross-entropy) and the ground-truth answer format (\ie, soft scores for LXMERT, as mentioned in \cref{subsec:imp_details}). 

In general, we observe a very similar behavior for accuracy, which increases and then slowly decreases as $\lambda$ increases. We sustain that the maximum value the accuracy can reach is established by the number of related pairs that are still inconsistent after training with $\lambda=0$. In other words, the limitations in size impose a limit for how much our method can improve the accuracy. For LXMERT on Introspect, for instance, our model corrected 4’553 (78.9\%) of the 5’771 existing inconsistencies and introduced new inconsistencies by mistakenly altering 1’562 (3.5\%) of the 44’111 consistent samples.

Regarding consistency, we observe a constant increase as $\lambda$ increases. The simultaneous decrease in accuracy as the $\lambda$ increases suggests that the relative weight of the consistency loss dominates so that the model no longer focuses on optimizing the cross-entropy. Since it is possible to be consistent without answering correctly, the optimization process results in an increase in consistency at the expense of accuracy for higher values of $\lambda$. However, it is clear from these results that there is a set of $\lambda$  values for which both accuracy and consistency improve.


 

%\begin{table*}[!t]
%  \centering
%  \begin{tabular}{@{}lccr@{}}
%    \toprule
%    Model & Cons. Method & Acc. & Cons. \\
%    \midrule
%    Base & None & 81.15 & 89.95 \\
%    Base & SQuINT~\cite{selvaraju2020squinting} & 80.58 & 89.39 \\
%    Base & Ours & \textbf{82.85} & \textbf{95.09} \\
%    \bottomrule
%  \end{tabular}
%  \caption{Results on the DME dataset.}
%  \label{tab:results_dme}
%\end{table*}





%\begin{figure}[!t]
%\centering
%\includegraphics[width=0.45\textwidth]{images/dme_plot_consacc_vs_lambda.pdf}
%\caption{Behavior of the accuracy and consistency as a function of the loss term gain $\lambda$ for the DME dataset. 95\% confidence intervals are shown.}
%\label{fig:method}
%\end{figure}


\paragraph{LI-MOD performance:} We report that the finetuning of BERT on the subset of annotated relations from Introspect produced $78.67\%$ accuracy in the NLI task. We analyze the performance of this model for entailment and report an AUC value of 0.86, which indicates good generalization capability considering that only $\approx 2 \%$ of the dataset was annotated with relations. In addition, the amount of overlap in the QA pairs between the train and validation sets of the  Introspect dataset is only 1.12\% for binary questions. This shows that our LI-MOD is generalizing to variations in questions as well as to new combinations of QA pairs. \cref{fig:roc_dot} shows the ROC curve for entailment and examples of LI-MOD's predictions. Some of the observed sources of errors in LI-MOD include negations, unusual descriptions (\eg, a cat typing a text message), and image-specific references (\eg, ``is \textit{this} animal real?").


\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\linewidth]{images/roc_examples.pdf}
    \caption{\textit{Left:} Receiver Operating Characteristic (ROC) for the entailment class of our LI-MOD in validation. \textit{Right:} Qualitative examples of LI-MOD's predictions.}
    \label{fig:roc_dot}
\end{figure}

%\begin{figure}[!t]
%\centering
%\includegraphics[width=0.4\textwidth]{images/roc.png}
%    \caption{Receiver Operating Characteristic (ROC) for the entailment class of our LI-MOD in validation}
%\label{fig:roc}
%\end{figure}

%\RS{What is the distribution of relations per group in the train and test sets you annotated?} \STM{For train it is $(\leftarrow : 0.595, \leftrightarrow: 0.1725, -: 0.1175, \rightarrow : 0.109, contradictions: 0.006)$. For val it's fairly similar: $(\leftarrow : 0.572, \leftrightarrow: 0.142, -: 0.156, \rightarrow : 0.109)$}

%\begin{figure}[!t]
%\centering
%\includegraphics[width=0.35\textwidth]{images/confusion_matrix_rels.pdf}
%\caption{Confusion matrix for logical implication prediction using our proposed LI-MOD strategy. Note that distribution of labels in both the training used to is given $(\leftarrow : 60\%, \leftrightarrow: 17\%, -: 12\%, \rightarrow : 11\%)$, while the validation set (performance shown here) follows a similar distribution.}
%\label{fig:confusion_matrix}
%\end{figure}