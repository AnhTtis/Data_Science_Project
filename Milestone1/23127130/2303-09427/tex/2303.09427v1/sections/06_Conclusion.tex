\section{Conclusion and future work}
\label{sec:conclusion}

In this paper, we propose a novel model-agnostic method to measure and improve consistency in VQA. We do so by integrating logical implications between pairs of questions directly in the training process. Additionally, we present a method to infer implications between QA pairs using a transformer-based natural language model. We conduct a series of experiments to verify the validity of our consistency loss in terms of generalizability and robustness against several baselines and across different datasets. Our results reveal the usefulness and applicability of our method to improve performances by reducing incoherence in responses. Future works include the creation of a larger dataset with human-annotated relations, which can then be used as general-purpose relations database for VQA training. 