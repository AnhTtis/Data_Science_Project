\section{Tritium data analysis\label{sec:final-analysis}}

\subsection{Tritium analysis procedures}
\label{sec:tritium_analysis_procedures}
We perform Bayesian and frequentist analyses of the tritium data to measure the spectral endpoint $E_0$ and place a limit on the neutrino mass $m_\beta$. 
The analyses are not blind, but they are validated using MC studies as discussed in \autoref{sec:MCstudies}.

\subsubsection{Bayesian analysis procedure}\label{sec:Bayesian-analysis}
The likelihood function used for Bayesian inference is the Poisson likelihood for the number of counts per bin according to the tritium model (\autoref{eq:fullT2model}), multiplied by prior distributions for all parameters. For bin $k$, the Poisson rate is $(dN/dE_\mathrm{kin})_k^{\mathrm{ctr}}\cdot\Delta E_{\mathrm{kin}, k}$: the tritium model at bin center multiplied by the bin width.\footnote{Test fits with piecewise integration of the probability density in each bin (10 steps per bin) produced consistent results.}  The bins have a fixed width in frequency, so in energy their widths vary slightly across the ROI.

We evaluate the likelihood function using the Stan statistical software platform, which performs Bayesian inference via the Hamiltonian Monte Carlo algorithm~\cite{Carpenter2017,morpho}. This produces numerical posterior distributions for $E_0$ and $m_\beta$, marginalized over nuisance parameters. It is valuable to directly fit $m_\beta$ (instead of the unbounded variable $m_\beta^2$ used in frequentist analyses) because the beta spectrum's Heaviside theta factor (\autoref{eq:betaspectrumfull}) depends on $m_\beta$, without any exponents \cite{AshtariEsfahani:2021moh,Formaggio:2021nfz}. Several Stan convergence diagnostics validate the algorithm's performance for our model~\cite{Betancourt2015, PystanWorkflow}. For $E_0$, we report the posterior mean and the 1$\sigma$ quantile credible interval~\cite{PDG:2020}. The 1$\sigma$  highest posterior density (HPD) interval is consistent within $<0.5\,$eV. For the neutrino mass, we report a 90\% credible limit~\cite{PDG:2020}. 

Uncertainties are propagated by incorporating them into prior distributions. The uncertainty distributions described in 
\autoref{sec:summaryofpriors} become normal priors in the model (or multi-normal for $\sigma$, $p$, and $q$, the resolution and scatter peak parameters). The MCMC algorithm explores the probability space defined by the priors and the tritium model, propagating prior standard deviations (i.e., uncertainties) to the $E_0$ and $m_\beta$ posteriors~\cite{PDG:2020}.

Bayesian inference requires a choice of prior for every parameter, not only those with measured uncertainties. Thus, the Bayesian model includes priors on the background rate $r_f$, as well as $E_0$ and $m_\beta$. For $r_f$, before analysis, prior knowledge constrained likely background rates within several orders of magnitude. This can be modeled with a lognormal prior (which also has the correct bound $r_f>0$). The prior's median is chosen to be $0.0006$\,events/keV/day, the target 90\% C.L.  used to tune event power cuts. To conservatively scale the prior width, we use the soft upper bound $r_f^{\mathrm{max}}\approx0.2006$\,events/keV/day, the 50\% C.L. from observing no events in $\approx\!0.5$\,keV above the endpoint during an early 7-day data set taken to test the apparatus setup. The prior's standard deviation is set equal to $[0.2006-0.0006]$\,events/keV/day, determining the lognormal prior shape. 
 
Separate fits are performed to measure $E_0$ and place a limit on $m_\beta$. When measuring $E_0$, $m_\beta$ should be constrained to its known range, near zero. Otherwise, the $E_0$ posterior is biased upward due to the large $m_\beta$ probability density above the true value---with little density below, since we require $m_\beta>0$. By contrast, when placing a limit on $m_\beta$, a broad $E_0$ prior may be employed, since there is no bound in the $E_0$ prior which introduces an asymmetry.

For the $E_0$ fit, the $m_\beta$ prior is a gamma distribution constructed so that 5\% of its probability mass falls below 0.0085\,eV (from mass splitting uncertainties~\cite{PDG:2020}) and 10\% falls above 0.8\,eV (KATRIN's 90\% C.L.~\cite{KATRIN:2021uub}). A gamma prior is appropriate because of its lower bound at zero, and because it can take on a wide range of shapes depending on the external conditions provided, making it a generic prior choice for positive parameters. Other positive priors tend to effectively rule out either high values of $m_\beta$ or a region near $m_\beta=0$~\cite{Gelman2014, PriorChoiceRecs}.
We use a weakly-informative normal prior on $E_0$ with a standard deviation of 300\,eV. \footnote{We follow established conventions regarding weakly-informative and `non-informative' priors, see~\cite{Gelman2014, PriorChoiceRecs, Betancourt2017, DAgostini2003}.} MC-spectrum tests confirm that the $E_0$ result is robust to the specific choice of prior: when we analyze MC data, the $E_0$ posterior interval width remains constant as the prior standard deviation is scanned from 100 to 400\,eV, within $<1\,$eV computational uncertainty. That uncertainty is calculated by re-analyzing the same MC spectrum 25 times and computing the standard deviation of resulting interval widths.

For the $m_\beta$ fit, we use the same normal $E_0$ prior, and for the $m_\beta$ prior we use a uniform distribution multiplied by an error function with $\mu_{\mathrm{erf}}=1\,$keV and $\sigma_{\mathrm{erf}}=0.2\,$keV. The $m_\beta$ prior for this fit reflects assumptions made before data-taking: if $m_\beta\gtrsim1\,$keV, the apparatus's frequency bandwidth would be too small, as this would shift $\gtrsim2/3$ of the events out of the ROI.   On the lower edge, another error function tapers the prior at 0.0085\,eV ($\sigma_{\mathrm{erf}}=[1/3$ of that value]). MC tests demonstrate that this prior is weakly informative: when we increase/decrease the high-energy error function's parameters by $\approx50$\%, the $m_\beta$ limit is unaffected.

Frequency data are histogrammed in 71 bins, each about 50\,eV in width. An analytic calculation (described in \autoref{sec:sensitivity}) indicates that a bin width near 50\,eV is expected to minimize the neutrino mass uncertainty.   When we instead use  65 bins ($\approx55\,$eV in width), the Bayesian 90\% credible limit on $m_\beta$ increases by 5\,eV.

\subsubsection{Frequentist analysis procedure}


The frequentist analysis uses the tritium model of \autoref{eq:betaspectrumfull}.  There are small differences from the Bayesian analysis model described in \autoref{sec:tritium_model}.
Most notably, the analysis uses $m_\mathrm{\beta} ^2$ instead of $m_\mathrm{\beta}$ as the mass fit parameter and does not limit $m_\mathrm{\beta} ^2$ to be positive. This allows the fit parameter to range on either side of zero to allow for statistical fluctuations near the endpoint. A functional form should be chosen that yields parabolic likelihood profiles.  We tried two forms for $m_\beta ^2 < 0$, the Mainz implementation~\cite{Kraus:2004zw}: 
\begin{equation}\label{eq:mainz_method}
\begin{split}
    \left[ \epsilon + 0.66 k \exp \left(-1-\frac{\epsilon}{0.66k} \right) \right] \sqrt{\epsilon^2 + k^2} \cdot \Theta \left(\epsilon+0.66k\right),
    \end{split}
\end{equation}
 and the Livermore implementation~\cite{Formaggio:2021nfz}:
\begin{equation}\label{eq:livermore_method}
 |\epsilon^2 + \frac{k^2\epsilon}{2|\epsilon|}|\  \Theta(\epsilon + k),  
\end{equation}
with  $k^2=-m_\beta ^2$.  These functions replace the phase-space factor $\epsilon\big[\epsilon^2 -  m_\beta^2\big]^{1/2} \Theta(\epsilon-m_\beta)$ of \autoref{eq:betaspectrumfull} for $m_\beta ^2 < 0$.  They bracket the desired parabolic behavior, the Mainz version likelihood decreasing too slowly below 0, and the Livermore version likelihood decreasing too quickly.  In the Feldman-Cousins construction used to find an upper limit on the mass with our data, these functions give the same result and refinements were not pursued.

The frequentist analysis uses uniform 50-eV-wide energy bins and employs extended binned maximum likelihood fits, assuming that the number of events in each bin are Poisson distributed with an expectation value given by the  numerical integral of the tritium spectrum (\autoref{eq:fullT2model}) over each bin. For minimizing the log likelihood we use the MIGRAD algorithm from the Minuit2 library \cite{iminuit,James:1975dr}. 

All systematic parameter uncertainties listed in \autoref{tab:priors} are modeled as Gaussian. For the $\mathrm{H}_2$ inelastic scatter fraction $\gamma_{\mathrm{H}_2}$ and $\sigma$, the uncertainties  are propagated by adding normal constraints to the log-likelihood function. A multivariate normal constraint is added for $\sigma$, $p$ and $q$. Only the magnetic field and detection efficiency are not included as floating model parameters. Instead, they are propagated by MC sampling. Hard lower limits of 0 are imposed for the number of background and signal events, the resolution, and for the bin efficiencies.

The endpoint $E_0$ and $m_\beta ^2$ are measured in separate analyses. For the endpoint measurement, $m_\beta ^2$ is fixed at zero. For determining a limit on  $m_\beta ^2$, both parameters are free. 
The analysis proceeds in 3 steps. In the first step, the data is fit with a model in which $\gamma_{\mathrm{H}_2}$, $p$, $q$, and $\sigma$ are constrained nuisance parameters and the signal rate $r_s$, the false event rate $r_f$, and $E_0$ (and $m_\beta^2$) are free. The magnetic field and the detection efficiency in each bin are fixed to their calibrated best values. Uncertainty intervals on $E_0$ (and  $m_\beta ^2$) are extracted by the MINOS profile method \cite{minos}. This way, the uncertainties of $\gamma_{\mathrm{H}_2}$, $p$, $q$, and $\sigma$ are propagated to the interval widths of $E_0$ (and $m_{\beta}^2$).  
In the next step, $\gamma_{\mathrm{H}_2}$, $p$, $q$, and $\sigma$ are fixed to the best-fit values while the magnetic field and efficiency uncertainties are propagated by MC sampling. An Asimov data set \cite{Cowan:2010js} from the first-pass best-fit model is generated and then repeatedly analyzed with a model that uses a sampled magnetic field value $B_j$ and efficiency values $\epsilon_{j,i}$, for energy bin $i$. This produces a distribution of fit results for $E_0$ (and $m_\beta ^2$). The difference between the borders of the highest-density intervals and the best-fit values are added in quadrature to the profile interval widths from the first-pass analysis. In the third analysis step, the frequency variation of $p$ and $q$ is propagated (see \autoref{sec:pq_freq_var_prop}).

The Feldman-Cousins construction~\cite{Feldman:1997qc,Workman:2022ynf} is used to translate the best-fit point of actual data to a $90\%$ C.L.~upper limit on $m_\beta^2$, and consequently on $m_\beta$.
%To set a limit on the neutrino mass we use the Feldman-Cousins method~\cite{Feldman:1997qc,Workman:2022ynf}. 
For a range of true masses, pseudo experiments are conducted and the measured $m_\beta ^2$ values are included in an interval following the likelihood-ratio ordering rule. Since systematic parameters are sampled in the generation of pseudo data, their uncertainties are included in these intervals.
We find that the ordering process is impacted by a small number of pseudo experiments with higher than usual likelihood-ratio for a given fitted mass which results in over-coverage of the obtained limits. We determined these outliers to be primarily caused by the proximity of the false event rate $r_f$ to the hard limit of 0, which is implemented in Minuit by a non-linear variable transformation. To address these outliers, we take the median of the likelihood-ratio over small ranges of fitted $m_{\rm{\beta}}^2$ from pseudo experiments for each simulated true mass and find the likelihood-ratio level above which 90\% of experiments are contained.


\subsubsection{Frequency variation of scatter peak amplitudes}\label{sec:pq_freq_var_prop}
The tritium analysis model does not include the frequency variation of $\mathcal{R}_\mathrm{PSF}$, controlled by parameters $\sigma$, $p$ and $q$. In both frequentist and Bayesian analyses, the $\sigma$ variation was found not to affect the reported results, but the $p$ and $q$ variation does have an effect. This variation is captured by the scale factors $s_p(f_c)$ and $s_q(f_c)$, as described in \autoref{subsec:frequency_dependent_detector_response}.

In the frequentist case, pseudo experiments revealed that a neglected frequency dependence of $p$ and $q$ shifts the endpoint result  by $-1.03(90)\,\si{eV}$ on average. No bias was found for $m_\beta ^2$. We therefore include an uncertainty of $E_0$ and $m_\beta ^2$ and a correction of $E_0$ resulting from ignoring this dependence in the frequentist analysis. For any given analysis (of pseudo data or real data), this is done by generating many Asimov data sets from the initial best-fit model modified with a randomized frequency-dependent scaling of $p$ and $q$ by $s_p(f_c)$ and $s_q(f_c)$ and analyzing them with the model that does not have a frequency dependence included. The average shift of the $E_0$ fit result is subtracted from the original fit result and the standard deviations of $E_0$ and $m_\beta ^2$ are added in quadrature to the uncertainties of the experiment's final results. For the $m_\beta$ limit construction with the Feldman-Cousins method, $s_p(f_c)$ and $s_q(f_c)$ are sampled within uncertainties during the pseudo-data generation and hence propagated to the distribution of $m_\beta ^2$ fit results and the confidence limit. 

In the Bayesian analysis, MC studies show that neglecting the frequency dependence of the scatter peak amplitudes shifts the endpoint posteriors by $-3.1 (12)\,\si{eV}$ on average. We correct for this shift by adding  $3.1\,\si{eV}$ to the calculated $E_0$ posterior mean. As in the frequentist case, the $s_p$ and $s_q$ values inputted to the MC data generator for each frequency region are sampled from distributions to account for uncertainty in the frequency variation. That sampling produces a fluctuation in the endpoint results, corresponding to an uncertainty of $[{+4.1},{-4.3}]\,$eV. This contribution is added in quadrature to the $1\sigma$ $E_0$ bounds from the fit to data, increasing the bounds by 0.5\,eV. For $m_\beta$, MC studies show that neglecting the frequency variation of $p$ and $q$ reduces the coverage of 90\% credible limits by 3\%. To correct for this effect, MC 90\% C.L.s must increase by 8\,eV.  This correction is added to the $m_\beta$ limit result.


\subsection{Monte Carlo studies}\label{sec:MCstudies}

The Bayesian and frequentist analyses are both validated with Monte Carlo (MC) studies.  Random samples of tritium decay pseudo-data are generated and fitted by the tritium model (the same model is used to fit experimental data). For ensembles of MC spectra, we confirm that $E_0$ and $m_\beta$ ($m_\beta ^2$ in the frequentist analysis) intervals have no under-coverage, and that $E_0$ best-fit values do not exhibit large biases (\autoref{sec:mc_results}).  We follow the procedure in~\cite{AshtariEsfahani:2021moh} for MC studies.

\subsubsection{Generation of pseudo data}
When generating data, electron energies are sampled and converted to cyclotron frequencies before binning events. The data generation model is highly detailed, to verify that analysis model approximations have a negligible effect on the spectral endpoint $E_0$ and neutrino mass $m_\beta$ results. In the generation model, the beta spectrum is numerically convolved with the energy point-spread function $\mathcal{R}_{\mathrm{PSF}}$. The result is multiplied by an efficiency function and added to a flat background. We use the beta spectrum formula in~\cite{Kleesiek:2018mel}, which includes a relativistic Fermi function with several atomic physics corrections. The generation model includes the theoretical molecular final state spectrum from~\cite{Saenz:2000dul} down to a binding energy of $-2288\,$eV. The $\mathcal{R}_{\mathrm{PSF}}$ model includes simulated, tritium-specific instrumental resolutions for the four magnetic traps in the deep quad trap (see \autoref{subsec:ins_res}). 

Before generating each MC spectrum, the simulated resolutions are combined according to measured statistical contributions from each trap. The resulting resolution histogram is numerically convolved with inelastic scatter spectra to form broadened scatter peaks. The convolutions account for cases when the same electron successively scatters off  different gases (neglected in the analysis model). In addition, CO scattering ($\approx1$\% of scatters) is included during generation but not analysis. Twenty scatter peaks are generated; however, we performed a separate test to confirm that including higher-order peaks does not alter results.

Before generating each spectrum, inputs to the generator are sampled from their uncertainty distributions. This ensures that the ensemble of spectra reflects the relative likelihoods of outcomes, validating inferences~\cite{AshtariEsfahani:2021moh, Cook2006}. The background rate is sampled from the prior distribution in \autoref{sec:Bayesian-analysis}. The mean field $B$ is sampled from the distribution in \autoref{tab:priors}. The efficiency vs. frequency curve is translated to energy using the configured magnetic field strength before being randomized within its uncertainty. Other parameters are sampled from distributions similar to those in \autoref{tab:priors}, with minor differences to avoid making simplifications. Instead of sampling $\sigma$ (which is not present in the detailed generation model), we separately sample each contribution to the uncertainty on the instrumental resolution $\mathcal{I}$ as follows.  First, counts in each bin are sampled to account for Poisson and efficiency matrix uncertainties. Second, trap weights are sampled from normal distributions before combining resolutions for the four traps. Third, the maximum SNR (SNR$_{\rm max}$) uncertainty is included by introducing a factor $s$ which scales the width of the simulated $\mathcal{I}$,  sampling $s$ from a normal distribution. 

Another difference from \autoref{sec:summaryofpriors} is that inelastic scatter fractions for H$_2$, $^3$He and CO are sampled from normal distributions defined by the means and uncertainties in \autoref{tab:scattering_fraction_results}. This sampling is repeated until the sum of fractions is within [0.99, 1.01], then fractions are normalized to make the sum exactly 1. In addition, we account for a covariance between the $^3$He fraction (or equivalently, the H$_2$ fraction) and the gas composition contribution to scatter peak amplitude uncertainties. To do this, we sample the scattering parameters $p$ and $q$ from a bivariate normal distribution excluding gas composition uncertainty, then shift $p$ and $q$ based on the sampled $^3$He fraction, using pre-tritium $^{\mathrm{83m}}$Kr fit results to estimate the expected shift.

MC studies are performed both with and without frequency variation of $\mathcal{R}_{\mathrm{PSF}}$ in the data generation model (see \autoref{sec:pq_freq_var_prop}). Three parameters are varied as a function of frequency: $p$, $q$, and $\sigma$. This is done by convolving a different $\mathcal{R}_{\mathrm{PSF}}$ with the beta spectrum for each frequency step in the field-shifted data, then concatenating the resulting partial-spectra. 
 At each step, the scale factors $s_p(f_c)$ and $s_q(f_c)$ are sampled from normal distributions that account for frequency-variation uncertainties, then multiplied by $p$ and $q$ (see \autoref{subsec:frequency_dependent_detector_response}). Uncertainties on $s_\sigma(f_c(E_\mathrm{kin}))$ are negligible in comparison and are neglected. 


\subsubsection{Coverage and bias tests}
\label{sec:mc_results}
For $E_0$ fit MC studies, ``true" $m_\beta$ values inputted to the generator are sampled from the narrow prior described in \autoref{sec:Bayesian-analysis} (defined by the KATRIN limit). For $m_\beta$ limit MC studies, $m_\beta$ values are sampled from a uniform distribution over [0, 300]\,eV, to observe how the model performs across a large range of ``true" values. For both studies, $E_0$ values are sampled from a normal distribution with $\sigma=0.07\,$eV (see \autoref{sec:Bayesian-analysis}). 


\begin{table}[t]
\caption{Interval coverage (covg.) and best-fit bias from analyzing ensembles of Monte Carlo tritium data sets. The Bayesian $m_\beta$ coverage is computed for trials with MC true $m_\beta > 200$\,eV, as the limit coverage approaches $100\%$ for small masses.}
\label{tab:MCresults}
\centering
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{l  c | c | c}
\hline\hline
 & $E_0 \, 1\sigma$ covg.~& $E_0$\,best-fit bias & $m_\beta$ 90\% C.L.~covg.~\\
\hline
Bayesian & $68\pm2\%$  & $-2.9\pm 0.8\,$eV & $90\pm2\%$ \\
Frequentist &  $69\pm2\%$ &  $-2.5 \pm 0.7 $\,eV& {$90 \pm 1\%$}\\
\hline\hline
\end{tabular}
\end{table}

\begin{figure}[b]
  \centering
  \includegraphics[width=1.0\columnwidth]{Plots/5-final-analysis/01-15-23E_mbeta_fake_data_with-fvar_71-bins_with-mfs_mass-90---post-intervals_33per18eVbin.pdf}
  \caption{
    {Neutrino mass credible limits and posterior means from Bayesian Monte Carlo studies. As expected, $m_\beta$ is overestimated for low MC true $m_\beta$. Credible limits in this region are still robust. For high true $m_\beta$, posterior means approach the expectation (solid black line) and limit coverages approaches the credibility (90\%). In this plot, results are averaged over $\sim\!20\,$eV regions with 33 points per region.}
  }
  \label{fig:mbeta_MC_results}
\end{figure}

MC study results are summarized in \autoref{tab:MCresults}. In the Bayesian case, the values are taken from an MC study with no frequency variation of $\mathcal{R}_{\mathrm{PSF}}$ in the data generator or analysis models. The values for the case with frequency variation were corrected to achieve the same coverage and bias, as explained in \autoref{sec:pq_freq_var_prop}. In the frequentist case, the numbers in the table are taken from an MC study with frequency variation in the data generator; for each spectrum, intervals and best-fits are corrected for this frequency variation using the Asimov sampling method described in \autoref{sec:pq_freq_var_prop}. Accordingly, for both Bayesian and frequentist analyses, \autoref{tab:MCresults} reflects the expected coverage and bias numbers for $E_0$ and $m_\beta$ results that include corrections for the effect of $\mathcal{R}_{\mathrm{PSF}}$ varying with frequency.

We observe no under-coverage of  $E_0$ 1$\sigma$ intervals. $E_0$ best-fit values have a small negative bias. For comparison, when different ``best-fit" statistics (e.g. median and mode) are chosen to summarize the Bayesian $E_0$ posterior distributions, the average best-fit values change by a similar amount to the biases in \autoref{tab:MCresults}. 

For the neutrino mass, the Bayesian coverage of 90\% credible limits is $93.8(7)\%$ for ``true" values of $m_\beta \in [0, 300]\,$eV. As expected, this coverage is inflated by trials with true $m_\beta \sim 0\,$eV, for which credible limits necessarily include $\approx\!\!100\%$ of true values.  This effect may be seen in 
\autoref{fig:mbeta_MC_results}, showing the credible upper limits on $m_\beta$ as a function of the true $m_\beta$. When we consider only trials with true $m_\beta > 200\,$eV, which are negligibly affected by the physical bound at 0, the 90\% limit coverage drops to $89.4(17)\%$.\footnote{In analogy with frequentist coverage, we may also consider the coverage for trials with posterior medians near the best-estimate obtained for real data (57\,eV---see \autoref{sec:tritiumresults}). For MC trials with $m_\beta$ medians within 5\,eV of the result from data, the 90\% limit coverage is $91.3(34)$\%.} For $1\sigma$ intervals on $m_\beta$ (like the one reported for tritium data in \autoref{tab:results}), the coverage is $68.4(14)$\%, including all trials in the MC study.  Moreover, as expected, the bias in the $m_\beta$ posterior mean approaches zero for high values of the MC true $m_\beta$.

The frequentist analysis is not limited to $m_\beta ^2 > 0$ and gives no over-coverage for 90\% confidence limits even for small $m_\beta^2$. Neither \autoref{eq:mainz_method} nor \autoref{eq:livermore_method} yields a parabolic $m_\mathrm{\beta} ^2$ likelihood profile, but since our best-fit value for $m_\beta ^2$ is greater than zero, the 
%90\% confidence-level 
upper limit in the Feldman-Cousins construction is independent of these descriptions.  The coverage of the 90\% confidence limits is found to be $89.6(10)\%$.
These results validate the model of tritium data used here, as well as the Bayesian and frequentist analysis procedures.