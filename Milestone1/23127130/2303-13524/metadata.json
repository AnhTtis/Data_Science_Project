{
    "arxiv_id": "2303.13524",
    "paper_title": "Talking Abortion (Mis)information with ChatGPT on TikTok",
    "authors": [
        "Filipo Sharevski",
        "Jennifer Vander Loop",
        "Peter Jachim",
        "Amy Devine",
        "Emma Pieroni"
    ],
    "submission_date": "2023-02-23",
    "revised_dates": [
        "2023-03-27"
    ],
    "latest_version": 1,
    "categories": [
        "cs.HC",
        "cs.CY",
        "cs.SI"
    ],
    "abstract": "In this study, we tested users' perception of accuracy and engagement with TikTok videos in which ChatGPT responded to prompts about \"at-home\" abortion remedies. The chatbot's responses, though somewhat vague and confusing, nonetheless recommended consulting with health professionals before attempting an \"at-home\" abortion. We used ChatGPT to create two TikTok video variants - one where users can see ChatGPT explicitly typing back a response, and one where the text response is presented without any notion to the chatbot. We randomly exposed 100 participants to each variant and found that the group of participants unaware of ChatGPT's text synthetization was more inclined to believe the responses were misinformation. Under the same impression, TikTok itself attached misinformation warning labels (\"Get the facts about abortion\") to all videos after we collected our initial results. We then decided to test the videos again with another set of 50 participants and found that the labels did not affect the perceptions of abortion misinformation except in the case where ChatGPT explicitly responded to a prompt for a lyrical output. We also found that more than 60% of the participants expressed negative or hesitant opinions about chatbots as sources of credible health information.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.13524v1"
    ],
    "publication_venue": null
}