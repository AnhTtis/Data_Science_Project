

\section{System Details and Robot Setup}
\label{sec:system}

Our robotic system, visualized in Figure \ref{fig:robot_setup}, consists of a robotic arm and hand. The arm is a 6-dof Kinova Jaco and the hand is a 16-dof Allegro hand with four fingers. The arm can be teleoperated through the built-in Kinova joystick, while the the hand can be teleoperated using the the Holo-Dex framework~\cite{holodex}. Here, our teleoperator uses a virtual reality headset to both visualize robot images and control the hand in real time. The headset returns a pose estimate for each finger of the hand which is re-targeted to the Allegro Hand. Inverse Kinematics is then used to translate target Cartesian positions in space to joint angles, which are fed into the low-level hand controller. To achieve robust position control, we use a low-level PD joint position controller with gravity compensation to allow the robot to maintain a hand pose at different orientations in space. Our action space is Cartesian position and orientation of the arm (3D position and 4D quaternion for orientation) and the 16-dimensional joint state of the hand for a total of 23 dimensions.

The Allegro hand is fitted with 15 XELA uSkin tactile sensors, 4 on each finger and 3 on the thumb. Each sensor has a 4x4 resolution output of tri-axial force reading (forces in translational x, y, z) information, which amounts to a 720-dimensional tactile reading. The force readings are uncalibrated, susceptible to hysterisis, and can change when strong magnets or metals are in the vicinity. Due to this, we opt against explicit calibration of the 720 sensor units. To supplement the tactile sensors, we also use two RGB cameras with 640x480 resolution to capture visual information in the scene, though our policies only uses information from one to execute. Our choice of camera for tasks depends on which one captures the most visual information about the objects to ensure fairness when comparing to baselines and enable better joint vision and tactile control.