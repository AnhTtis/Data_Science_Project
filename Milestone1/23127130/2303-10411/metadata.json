{
    "arxiv_id": "2303.10411",
    "paper_title": "Multi-Semantic Interactive Learning for Object Detection",
    "authors": [
        "Shuxin Wang",
        "Zhichao Zheng",
        "Yanhui Gu",
        "Junsheng Zhou",
        "Yi Chen"
    ],
    "submission_date": "2023-03-18",
    "revised_dates": [
        "2023-03-21"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV"
    ],
    "abstract": "Single-branch object detection methods use shared features for localization and classification, yet the shared features are not fit for the two different tasks simultaneously. Multi-branch object detection methods usually use different features for localization and classification separately, ignoring the relevance between different tasks. Therefore, we propose multi-semantic interactive learning (MSIL) to mine the semantic relevance between different branches and extract multi-semantic enhanced features of objects. MSIL first performs semantic alignment of regression and classification branches, then merges the features of different branches by semantic fusion, finally extracts relevant information by semantic separation and passes it back to the regression and classification branches respectively. More importantly, MSIL can be integrated into existing object detection nets as a plug-and-play component. Experiments on the MS COCO, and Pascal VOC datasets show that the integration of MSIL with existing algorithms can utilize the relevant information between semantics of different tasks and achieve better performance.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.10411v1"
    ],
    "publication_venue": null
}