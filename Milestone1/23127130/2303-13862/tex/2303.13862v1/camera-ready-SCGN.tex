\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}


%\usepackage[ruled,boxed,linesnumbered]{algorithm2e}
\usepackage{algorithm}  
%\usepackage[linesnumbered,ruled]{algorithm2e}
\usepackage{algorithmic}
\usepackage[utf8]{inputenc}
\usepackage{soul}
\usepackage{booktabs}
% \usepackage[colorlinks=true,linkcolor=black,citecolor=black]{hyperref}

\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{graphicx}

\usepackage{color}
\usepackage{xcolor}
\usepackage{subfigure}
\usepackage{bm}
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%


\usepackage{colortbl}
\definecolor{mygray}{gray}{.8}
\definecolor{mypink}{rgb}{.99,.91,.95}
\definecolor{mycyan}{cmyk}{.3,0,0,0}

\def\diag{\mbox{diag}}
\def\rank{\mbox{rank}}
\def\grad{\mbox{\text{grad}}}
\def\dist{\mbox{dist}}
\def\sgn{\mbox{sgn}}
\def\tr{\mbox{tr}}
\def\etal{{\em et al.\/}\, }
\def\card{{\mbox{Card}}}
\def\st{\mbox{s.t. }}
\def\ie{\textit{i.e.}}
\usepackage[colorlinks,linkcolor=black,citecolor=black]{hyperref}

\usepackage{algorithm}
\usepackage{algorithmic}

\graphicspath{{figures/}}
\usepackage{multirow}
%\usepackage{multicol}
\def\mr{\mathrm}
\def\mb{\mathbf}
\def\mbb{\mathbb}
\def\mc{\mathcal}
\def\mt{\mathtt}

\def\ch{\textcolor{blue}}
\def\ch{\textcolor{black}}
\def\lyu{\textcolor{red}}
\def\red{\textcolor{black}}

\usepackage{newfloat}
\usepackage{listings}
\lstset{%
	basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
	numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
	aboveskip=0pt,belowskip=0pt,%
	showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}


\begin{document}

\title{Two-level Graph Network for Few-Shot Class-Incremental Learning}


\author{
	\IEEEauthorblockN{
		Hao Chen$^{1*}$, 
		Linyan Li$^{2*}$, 
		Fan Lyu$^{3}$, 
		Fuyuan Hu$^{1,4,5\dagger}$,
		Zhenping Xia$^{1}$
		and Fenglei Xu$^{1}$} 
	\IEEEauthorblockA{$^{1}$ Suzhou University of Science and Technology, $^{2}$ Suzhou Institute of Trade \& Commerce, $^{3}$ Tianjin University, 
		\\ $^{4}$Jiangsu Industrial Intelligent and Low-carbon Technology Engineering Center, 
		\\ $^{5}$Suzhou Key Laboratory of Intelligent Low-carbon Technology Application
	\\  \{haochen@post, fuyuanhu@mail, xzp@mail, xufl@mail\}.usts.edu.cn, lilinyan@szjm.edu.cn, fanlyu@tju.edu.cn}
} 



%\author{\IEEEauthorblockN{1\textsuperscript{st} Hao Chen}
%\IEEEauthorblockA{\textit{School of Electronic and Information Engineering} \\
%\textit{Suzhou University of Science and Technology}\\
%Suzhou, China \\
%haochen@post.usts.edu.cn}
%\and
%\IEEEauthorblockN{2\textsuperscript{nd} Linyan Li}
%\IEEEauthorblockA{\textit{School of Information Technology} \\
%\textit{Suzhou Institute of Trade \& Commerce}\\
%City, Country \\
%lilinyan@szjm.edu.cn}
%\and
%\IEEEauthorblockN{3\textsuperscript{rd} Fan Lyu}
%\IEEEauthorblockA{\textit{College of Intelligence and Computing} \\
%\textit{Tianjin University}\\
%Tianjin, China \\
%fanlyu@tju.edu.cn}
%\and
%\IEEEauthorblockN{4\textsuperscript{th} Fuyuan Hu}
%\IEEEauthorblockA{\textit{School of Electronic and Information Engineering} \\
%\textit{Suzhou University of Science and Technology}\\
%Suzhou, China \\
%fuyuanhu@mail.usts.edu.cn}
%\and
%\IEEEauthorblockN{5\textsuperscript{th} Zhenping Xia}
%\IEEEauthorblockA{\textit{School of Electronic and Information Engineering} \\
%\textit{Suzhou University of Science and Technology}\\
%Suzhou, China \\
%xzp@mail.usts.edu.cn}
%\and
%\IEEEauthorblockN{6\textsuperscript{th} Fenglei Xu}
%\IEEEauthorblockA{\textit{School of Electronic and Information Engineering} \\
%\textit{Suzhou University of Science and Technology}\\
%Suzhou, China \\
%xufl@mail.usts.edu.cn}
%}

\maketitle

\begin{abstract}
Few-shot class-incremental learning (FSCIL) aims to design machine learning algorithms that can continually learn new concepts from a few data points, 
without forgetting knowledge of old classes. 
The difficulty lies in that limited data from new classes not only lead to significant overfitting issues but also exacerbates the notorious catastrophic forgetting problems. 
However, existing FSCIL methods ignore the semantic relationships between sample-level and class-level.
% Using the advantage that graph neural network (GNN) can mine rich information among few samples, 
In this paper, we designed a two-level graph network for FSCIL named Sample-level and Class-level Graph Neural Network (SCGN).
Specifically, a pseudo incremental learning paradigm is designed in SCGN, which synthesizes virtual few-shot tasks as new tasks to optimize SCGN model parameters in advance.
Sample-level graph network uses the relationship of a few samples to aggregate similar samples and obtains refined class-level features.
Class-level graph network aims to mitigate the semantic conflict between prototype features of new classes and old classes.
SCGN builds two-level graph networks to guarantee the latent semantic of each few-shot class can be effectively represented in FSCIL.
Experiments on three popular benchmark datasets show that our method significantly outperforms the baselines and sets new state-of-the-art results with remarkable advantages.
Code is available at https://github.com/sukechenhao/SCGN.
\end{abstract}

\begin{IEEEkeywords}
component, formatting, style, styling, insert
\end{IEEEkeywords}

\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\footnotetext[1]{Co-first author.}
\footnotetext[2]{Corresponding author.}
\renewcommand{\thefootnote}{}


\input{introduction}
\input{related-work}
\input{method}
\input{experiments}


\section{Conclusion}
In this paper, we proposed a novel two-level graph network SCGN for FSCIL.
SCGN builds a pseudo incremental learning paradigm simulating FSCIL in base training.
SGN is used to build the relationship between samples in the FSL task to mine more favorable refined features, but also adapt to the learning paradigm of the FSCIL task, with strong model expansion capability.
CGN aligns cross tasks, solves the semantic gap between old classes and new classes, 
and alleviate the catastrophic forgetting problem in FSCIL tasks.
SCGN enhances the long-term learning ability of the model, making it consistent with the real scene.
Experimental results show that our model is superior in both performance and adaptability than the SOTA methods.


%{\small\bibliographystyle{IEEEtran}
%\bibliography{icme2023template}}

\bibliographystyle{IEEEtran}
	\bibliography{icme2023template}

\end{document}
