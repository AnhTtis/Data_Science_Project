
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \subsection{The Space of Parameterized Trajectories}
% \begin{mydef}
% Let $x_0 \in \X$ be a pre-impact state, $\tau \in \R$
% be a switching time, and $\mu \in \R^k$ be a vector of input
% parameters.  A biped's \emph{state-time-control space} $\Space$ is a finite parameter vector space $\Space \subseteq \X \times \R \times \R^k$.
% \end{mydef}

% A point $c \in \Space$, where $c = \xtu$, defines the evolution of a hybrid
% trajectory $x(t) \in \X$ starting from $x_0$ at time $t = t_0$ with switching
% times in $\tau$, and input parameters $\mu$.

% \begin{mydef}
% \label{def:P}
% A point $c = \xtu \in \Space$ is a \emph{gait} of the biped if it is a root of the \emph{periodicity map} $P: \Space \rightarrow \Rx$ such that $P(c) = \flow[2 \tau] - x_0 = 0$.  The \emph{set of all gaits} $\G$ and the \emph{set of passive dynamic walking gaits} $\Gpass$ are then 
% \begin{align}
%     \G &= \pre{P} = \{c \in \Space: P(c) = 0\}, \\
%     \Gpass &= \{c \in \G: u(t) = 0, t \in \R \}.
% \end{align}
% \end{mydef}

% \begin{mydef} \cite{Spivak1965}
% For $c \in \G$, if $\rank(\pd{P}{c}(c)) = k + 1$, then 
% \begin{enumerate}
%     \item $c$ is a \emph{regular point} of $\G$ (and a \emph{singular point} otherwise),
%     \item the tangent space of $\G$ at $c$, $T_c\G$, is equal to the null space of $\pd{P}{c}$ (i.e., $T_c\G = \Null(\pd{P}{c})$), and
%     \item there exists a neighborhood of regular points containing $c$ that form a differentiable manifold in $\G$.
% \end{enumerate}
% \end{mydef}

% Given that the flow and hence $P$ is differentiable (Assumption~\ref{as:diff}), the gaits in $\G$ form connected components of gaits.  In general, a connected component of $\G$ consist of $(k+1)$-dimensional differentiable manifolds of gaits glued together at singular points of the periodicity map $P$.  These manifolds are the \textit{branches} of the connected component.

% Ultimately, we aim to trace optimal gaits in user-defined slices of a connected component of $\G$.  We identify user-defined slices with the map $M$
% \begin{equation}
% \label{eq:M}
% M(c) = [P^T(c), \Phi^T(c)]^T \in \Rlam,
% \end{equation}
% where $\Phi(c) \in \R^{(\n{\lambda} - 2n)}$ ($\n{\lambda} - 2n > 0$) is a set of user-defined constraints.  For example, to trace gaits that walk on a fixed slope $\sigma_0 \in \R$ and average walking speed $v_0 \in \R$, we have 
% \begin{equation}
%     \label{eq:Phi}
%     \Phi(c) = [\sigma(c) - \sigma_0, v_\text{avg}(c) - v_0]^T,
% \end{equation}
% where ${\fun{\sigma}{\G}{\R}}$ and ${\fun{v_\text{avg}}{\G}{\R}}$ are a gait's slope and average walking speed, respectively (see Appendix).

% %Given $M$, the next step is to identify optimal gaits in $\pre{M} \subset \G$ for a given cost function $J(c) \in \R$.

% \subsection{Optimal Trajectories in the Gait Space}
% When it comes to generating optimal gaits in $\G$, the map $M$ of Equation~\eqref{eq:M} can be treated as the (equality) constraints to an optimization problem $OP$ such that
% \begin{customopti}
%         {optimize}{c \in \Space}{J(c),}{\label{opti:op}}{OP:}
%         \addConstraint{M(c)}{= 0,}
% \end{customopti}
% where $c$ is a vector of decision variables, $J(c) \in \R$ is a given cost function, and $M$ is a vector of equality constraints.

% \begin{myrem}
% \label{rem:stationary}
% Our formulation of $OP$ only identifies stationary points.  We do not distinguish between optimal points that are minima, maxima, or neither.
% \end{myrem}

% \begin{mydef}
% Given the optimization problem $OP$ of Equation~\eqref{opti:op}, a trajectory $c \in \Space$ is an \emph{optimal gait} in $\pre{M} \subset \G$ if $c$ satisfies the first-order optimality conditions (FOC) \cite{Nocedal1999}
% \begin{equation}
% \label{eq:oc}
%     M(c) = 0, \quad \oc = 0,
% \end{equation}
% where $\lambda \in \Rlam$ is a vector of Lagrange multipliers.
% \end{mydef}
% This leads to the set of optimal gaits in a subspace of $\G \times \Rn{\lambda}$ that are the roots of the map $\dJ$, where
% \begin{equation}
% \label{eq:dJ}
% \dJ = \left[ M^T(c), \left( \oc \right)^T \right]^T.
% \end{equation}
% In other words, the map $\dJ$ consists of the FOC for $OP$.  Thus, Equation~\eqref{eq:dJ} transforms an optimization problem into a map $\dJ$ with the same solution set in $\Space$.

% \begin{myprop}
% [Can we state a non-obvious proposition that gaurantees that PDW are optimal w.r.t. J]?  All gaits in the set of PDW gaits $\Gpass$ are optimal with respect to cost function $J(c) = J(u(t; c))$, if $\text{infinum}(J) = 0$ and $J(u = 0) = 0$.
% \end{myprop}

% \begin{myprop}
% \label{prop:iso}
% Let $(c, \lambda) \in \predJ$ be an optimal pair of the cost function $J(c) \in \R$ subject to constraints $M(c) = 0$.  If the pair $(c, \lambda)$ is a regular point of $\dJ$, then it is also an isolated point in $\predJ$.
% \end{myprop}
% \begin{proof}
% The tangent space $T_{(c, \lambda)}\dJ$ represents all of the feasible directions we can move in without violating the FOC (Equation~\ref{eq:oc}).  At a regular point, the tangent space equals the null space.  The null space is empty because the Jacobian of $\dJ$ is square and has maximal rank, hence $(c, \lambda)$ is an isolated point in $\predJ$.
% \end{proof}
% Stated differently, the regular points of $\predJ$ do not form a continuous family of gaits.  Instead of trying to find gaits in an isolated set, we instead embed the $OP$ into a 1D family of optimization problems in such a way that we can connect gaits in $\predJ$ to gaits in $\Gpass$.

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \subsection{Problem Statement}
% \label{ssec:prob}
% Given:
% \begin{itemize}
% 	\item a hybrid model $\Sigma$ of an $n$-degree-of-freedom biped with $m$ switching times, and $k$ control and design parameters,
% 	\item a set of $p$ basis functions $\B_1$, $\ldots$, $\B_p$ for defining the input $u(t) \in \Rq$,  
% 	\item a space $\Space \subset \Rc$ of parameterized trajectories with nonempty sets of gaits $\G$ and $\Gpass$, and
% 	\item twice-differentiable cost function $\fun{J}{\Space}{\R}$ and user-defined map $\fun{\Phi}{\Space}{\R^{\nlam - 2n}}$ ($\nlam - 2n > 0$) for defining $M$ of Equation~\eqref{eq:M}.
% \end{itemize}
% Find: A continuous path $\fun{p}{[0, 1]}{\G}$ such that
% \begin{itemize}
%     \item $p(0) \in \predJ$, 
%     \item $p(1) \in \Gpass$, and
%     \item for all $\epsilon \in [0, 1]$, the gaits $p(\epsilon)$ are stationary points of the parametric optimization problem
% \begin{customopti}
%         {optimize}{(c, \lambda) \in \Space \times \Rlam}{J(c) + \lambda^T \Me(c),}{\label{opti:ope}}{\OPe:}
% \end{customopti}
% where $c$ is a vector of decision variables, $\epsilon \in \R$ is an indexing parameter such that $\Me(c) = [P^T(c), \Ie^T(c)]^T \in \Rlam$ is an indexed set of constraints with $\Ie$ defined in terms of $\epsilon$ and $\Phi$, $J(c) \in \R$ is the cost function, and $\lambda \in \Rlam$ is a vector of Lagrange multipliers.
% \end{itemize}

% In other words, the continuous parameter $\epsilon$ defines a family of optimization problems $OP(\epsilon)$ whose solution set are all gaits in $\G$.  The goal is to start with a PDW gait in $\Gpass$ and attempt to trace a path of optimal gaits that goes through a gait in $\predJ$ (see Figure~\ref{} for an illustration).  We outline such a process using numerical continuation methods in Section~\ref{sec:opt}, including a definition for the function $\Ie$.

% \begin{myrem}
% Given that we only trace stationary points (see Remark~\ref{rem:stationary}), identifying minima of $\OPe$ in $\Gm$, for example, would be a post-processing step in our framework.
% \end{myrem}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \section{Generating A Set of Optimal Gaits}
% \label{sec:opt}
% We now describe how to embed the $OP$ into a 1D parameterized family of optimization problems $\OPe$ suitable for tracing curves of optimal gaits in $\G$.  The primary contribution of this section is the definition of a map $\Me$ that can trace a path of optimal gaits from PDW gaits to a gait in $\predJ$.  The algorithms in this section are from \cite{Rosa2021}, which we reuse to keep this paper self contained.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Specifying a 1D Family of Optimization Problems}
We embed the $OP$ into a 1D family of optimization families through the global homotopy map $\Me$
\begin{equation}
    \label{eq:Me}
    \Me(c, \lambda) = \dJ - \epsilon \dJ[M][(c_0, \lambda_0)],
\end{equation}
where $\epsilon \in \R$ is a real-valued index, $(c_0, \lambda_0) \in \Gpass \times \Rlam$ are the initial seed values, and $\dJ$ is defined in Equation~\eqref{eq:dJ}.

\begin{mydef}
For user-defined constraints $\Phi$, point $c_0 \in \Space$ and index $\epsilon \in \R$, let $\Ie(c)$ be an indexed set of constraints, where, up to a relabeling of the entries,
$$\Ie(c) = \Phi(c) - \epsilon \Phi(c_0) = [\Iz^T(c), \Inz^T(c) - \epsilon \Inz^T(c_0)]^T$$
such that $\Iz(c_0) = 0$ and $\Inz(c_0) \neq 0$.
\end{mydef}

\begin{myprop}
\label{prop:Me}
Given the map $\Me$, which is defined in terms of cost function $J$; periodicity map $P$; and user-defined constraints $\Phi$, if the seed value $(c_0, \lambda_0) \in \Space \times \Rlam$ satisfies
\begin{equation*}
    c_0 \in \Gpass, \oc[c_0][\lambda_0] = 0, \text{ and } M(c_0) \neq 0;
\end{equation*}
then curves traced using $\Me$ have the following homotopy properties:
\begin{enumerate}[label=HP\theenumi]
    \item \label{hp:0} at $\epsilon = 0$, we have an optimal solution to the underlying $OP$ of Equation~\ref{eq:oc},
    \item \label{hp:1} at $\epsilon = 1$, we start with a known optimal gait that is not a root of $\Phi$ (i.e., $\Inz(c_0) \neq 0$), but is optimal with respect to the set of constraints of $M_{\epsilon = 1}(c_0)$,
    \item  \label{hp:fam} the map solves a series of optimizations with an indexed family of constraints $\Inz(c) - \epsilon \Inz(c_0)$, and
    \item \label{hp:inv} every point on a curve defined implictly by $\Me$ satisfies $P(c) = 0$, $\Iz(c) = 0$, and $\oc = 0$.
\end{enumerate}
\end{myprop}

\begin{proof}
Homotopy Property \ref{hp:0} and \ref{hp:1} can be verified directly after plugging in the assumptions regarding the point $c_0$, in which case $\Me$ reduces to
\begin{equation}
\label{eq:simpleMe}
    \Me(c, \lambda) = \begin{bmatrix}
    P(c) \\
    \Iz(c) \\
    \Inz(c) - \epsilon \Inz(c_0) \\
    \oc
    \end{bmatrix}.
\end{equation}
After this simplification, we also see that Homotopy Property \ref{hp:fam} defines the set of constraints that vary throughout the continuation.  An example interpretation of this property is if $\Inz$ is a walking surface constraint $\Inz(c) = \sigma(c)$, then we would trace a set of gaits with a range of slopes $\sigma(c) \in [0, \sigma_0]$ for $\epsilon \in [0, 1]$.  Finally, Homotopy Property \ref{hp:inv} implies that the set of gaits we generate have a shared set of properties as the numerical continuation traces the resulting 1D curve starting from $(c_0, \lambda_0)$.  Most importantly, every gait is optimal with respect to cost $J(c)$ subject to constraints $M(c) - \epsilon M(c_0)$.
\end{proof}

In general, the utility of a global homotopy map is that we can choose any $c_0 \in \Space$ as a seed value for $\Me$ in an attempt to find a curve that goes through $c \in \predJ$, but in choosing our seed value $c \in \Gpass$, we establish several useful properties with respect to the potential curve traced using the map $\Me$.

\begin{myrem}
We have now introduced a set of variables $c$, $\lambda$, $\epsilon$, $c_0$, and $\lambda_0$ that are sometimes fixed and other times free.  In summary, for the purposes of numerical continuation, the variables $c$, $\lambda$, and $\epsilon$ are free variables to be determined by the numerical continuation algorithm.  However, when it comes to defining the stationary points of $OP$ and $\OPe$, $c$ and $\lambda$ are the decision variables and $\epsilon$ is a fixed parameter.  The values for $c_0$, and $\lambda_0$ are fixed in both cases.
\end{myrem}