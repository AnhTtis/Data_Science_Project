In this section we detail the results across CIFAR10 models.  Accuracies for Weight Recycling experiments are averaged across three runs.

Dense model accuracy's:
\begin{table}[!h]
\begin{center}
%\renewcommand{\arraystretch}{1.15}
\begin{tabular}{c c c c c c c} 
 %\hline
 Prune Rate & Width Factor & Conv2 & Conv4 & Conv6 & Conv8 & ResNet18 \\ [0.5ex] 
 \hline\hline
 0 & 1 &79.9 & 87&89 &89.41 & 93.03 \\ 
 \hline 
  0 & 0.1 & 58.5&67.26 & 72.48& 75.06& -\\ 
 \hline
   0 & 0.25 &72.49 & 81.13& 83.65& 84.75& -\\ 
 \hline
   0 & 0.5 &77.55 &84.96 &87.54 &87.18 &-  \\ 
 \hline
 \hline
\end{tabular}
\end{center}
\end{table}
%\FloatBarrier


\begin{table}[!h]
\begin{center}
%\renewcommand{\arraystretch}{1.15}
\begin{tabular}{c c c c c c c } 
 %\hline
 Prune Rate & Width Factor &Algorithm& Conv2 & Conv4 & Conv6 & Conv8  \\ [0.5ex] 
 \hline\hline
\multirow{ 3}{*}{0.2} &\multirow{ 3}{*}{1} & Biprop & 64.1&74.71&78.2&76.59 \\
&& IteRand & 56&57.9&59.6&49.84 \\
&& Weight Recycle& \textbf{80.28}&\textbf{88.05} &\textbf{90.2}&\textbf{90.35} \\
\hline

\multirow{ 3}{*}{0.4} &\multirow{ 3}{*}{1} & Biprop &78.3 &85.9&88.9& 89.13\\
&& IteRand & 65& 73.3&75& 75.14\\
&& Weight Recycle&\textbf{81.2} & \textbf{88.8}&\textbf{90.8}& \textbf{90.93}\\
\hline



\multirow{ 3}{*}{0.5} &\multirow{ 3}{*}{1} & Biprop & 79.56&87.42&89.52&90.35 \\
&& IteRand &65.3 &74&77& 77.61\\
&& Weight Recycle&\textbf{81.36 }&\textbf{88.91}&\textbf{90.9}&\textbf{ 91}\\
\hline

\multirow{ 3}{*}{0.6} &\multirow{ 3}{*}{1} & Biprop & 79.98&87.2&90.25& 90.54\\
&& IteRand & 65.72& 74.13&76.2& 78.9\\
&& Weight Recycle&\textbf{81.36 }&\textbf{88.64}&\textbf{90.6}&\textbf{90.85} \\
\hline

\multirow{ 3}{*}{0.8} &\multirow{ 3}{*}{1} & Biprop &77.9 &85.34&87.5&89.11 \\
&& IteRand &58.9 & 67.1&71.2& 76.72\\
&& Weight Recycle&\textbf{ 80.23}&\textbf{ 87.75}&\textbf{90}&\textbf{ 90.55}\\
\hline

\multirow{ 3}{*}{0.9} &\multirow{ 3}{*}{1} & Biprop & 70.1&79&82.38& 84.84\\
&& IteRand &50 & 54&61&52 \\
&& Weight Recycle&\textbf{76.9} &\textbf{84.3} &\textbf{85.5}&\textbf{ 86.4}\\
\hline

\multirow{ 3}{*}{0.95} &\multirow{ 3}{*}{1} & Biprop & 56.6&64.83&66.12&- \\
&& IteRand & 38.78& 45.91&49.2&- \\
&& Weight Recycle&\textbf{65.11} &\textbf{73.5 }&\textbf{72.11}& -\\
\hline

\multirow{ 3}{*}{0.5} &\multirow{ 3}{*}{0.1} & Biprop &47.2 &50.4 &56.9 & 61.2 \\
&& IteRand & 41 &42.8 &43 & 44.3  \\
&& Weight Recycle& \textbf{52.55}& \textbf{59.64}&\textbf{65}& \textbf{69} \\
\hline

\multirow{ 3}{*}{0.5} &\multirow{ 3}{*}{0.25} & Biprop &64.55 & 73.23& 77.84&  80.4\\
&& IteRand & 53 & 57.5&60.4 & 62.5  \\
&& Weight Recycle& \textbf{68.8}& \textbf{78.51}& \textbf{82}& \textbf{84.5} \\
\hline

\multirow{ 3}{*}{0.5} &\multirow{ 3}{*}{0.5} & Biprop & 74.69&82.6 & 86.23&  87.33\\
&& IteRand & 60.5 &67.3 &70.4 &70.3   \\
&& Weight Recycle&\textbf{76.7} & \textbf{86.5}&\textbf{88.43} &\textbf{89.67}  \\
\hline

\hline
 \hline
\end{tabular}

\end{center}
\caption{\textbf{Binary neural networks}
Biprop, Biprop+IteRand,Biprop+Iterative Weight Recycling results. Weight recycle accuracy averaged across three runs. Best result bolded for each experiment.  Notably, Weight Recycling performs best across all algorithms, and is robust to higher prune rates.  }
\end{table}
%\FloatBarrier

\begin{table}[!h]
\begin{center}
%\renewcommand{\arraystretch}{1.15}
\begin{tabular}{c c c c c c c } 
 %\hline
 Prune Rate & Width Factor &Algorithm& Conv2 & Conv4 & Conv6 & Conv8  \\ [0.5ex] 
 \hline\hline
\multirow{ 3}{*}{0.2} &\multirow{ 3}{*}{1} & Edge-Popup & 70.1&77.6&83&84.39 \\
&& IteRand & 80.7&88.4 &90.58&90.99 \\
&& Weight Recycle & \textbf{81.05}&\textbf{ 88.95}&\textbf{91.1}&\textbf{91.15} \\
\hline

\multirow{ 3}{*}{0.4} &\multirow{ 3}{*}{1} & Edge-Popup & 78.6 &86.74&89.33&90.15\\
&& IteRand & 81.3 &89.2&91.1&\textbf{91.55}\\
&& Weight Recycle& \textbf{81.8}& 89.2&\textbf{91.2}&91.5 \\
\hline

\multirow{ 3}{*}{0.5} &\multirow{ 3}{*}{1} & Edge-Popup & 79.69 &86.67&89.53&90.28\\
&& IteRand & \textbf{81.83} &88.37&90.74&91.11\\
&& Weight Recycle& 81.68&\textbf{88.5} &\textbf{90.9}& \textbf{91.36}\\
\hline
\multirow{ 3}{*}{0.6} &\multirow{ 3}{*}{1} & Edge-Popup & 79.1 &86.43&89.1&90.5\\
&& IteRand & \textbf{81.75} &87.66&90&\textbf{91.16}\\
&& Weight Recycle&81.12 & \textbf{88.15}&\textbf{90.4}&90.95 \\
\hline
\multirow{ 3}{*}{0.8} &\multirow{ 3}{*}{1} & Edge-Popup & 75.15 &83.28&85.4&86.9\\
&& IteRand & 78.04 &85.34&86.94&88.42\\
&& Weight Recycle&\textbf{79.06} &\textbf{ 85.6}&\textbf{87.13}&\textbf{88.87} \\
\hline
\multirow{ 3}{*}{0.9} &\multirow{ 3}{*}{1} & Edge-Popup & 64.05 &74.42&79.57&83.6\\
&& IteRand & 68.87 &78.88&81.22&84.73\\
&& Weight Recycle&\textbf{70.22} &\textbf{79.78} &\textbf{83.2}&\textbf{86.93} \\
\hline
\multirow{ 3}{*}{0.95} &\multirow{ 3}{*}{1} & Edge-Popup & 49.4 &57.61&60.63&76.7\\
&& IteRand & 53.5 &64.72&\textbf{68.8}&\textbf{81.66}\\
&& Weight Recycle& \textbf{55.2}& \textbf{65.22}&68.02&81.51 \\
\hline
\multirow{ 3}{*}{0.5} &\multirow{ 3}{*}{0.1} & Edge-Popup & 48.1 &50.73&57.3&63.35\\
&& IteRand & \textbf{55.2} &59.3&\textbf{64.5}&\textbf{71.56}\\
&& Weight Recycle& 53.4&\textbf{59.82} &64.1&70 \\
\hline

\multirow{ 3}{*}{0.5} &\multirow{ 3}{*}{0.25} & Edge-Popup & 72.49&73.34&78.48&81.5\\
&& IteRand &  \textbf{70.5}&78.91&83&85.5\\
&& Weight Recycle& 70.33& 78.92&83& 85.5\\
\hline

\multirow{ 3}{*}{0.5} &\multirow{ 3}{*}{0.5} & Edge-Popup & 77.55&82.08&86.24&87.92\\
&& IteRand &  \textbf{78}&85.45&88.18&87.99\\
&& Weight Recycle& 77& \textbf{85.63}&\textbf{88.57}&\textbf{89.73} \\
\hline

\hline
 \hline
\end{tabular}

\end{center}
\caption{\textbf{Randomly Initialized Neural Networks}
Edge-Popup, Edge-Popup+IteRand, Edge-Popup+Iterative Weight Recycling results. Weight recycle accuracy averaged across three runs.  Best result bolded for each experiment. Notably, at prune rates above 80\%, weight recycling outperforms all algorithms.  }
\end{table}
%\FloatBarrier


\begin{figure}[!h]
   \includegraphics[width=1.0\textwidth,height=4.5cm]{appendix/figures/conv2to8_cont.pdf}
    \caption{Comparison of Edge-Popup, IteRand, and Weight Recycling using continuous valued weights with signed constant initialization. In this figure, we vary the model depth. }\label{depth_bin}
    \centering
\end{figure}
%\FloatBarrier
\vspace{1em}

\begin{figure}[!h]
   \includegraphics[width=1.0\textwidth,height=4.5cm]{appendix/figures/width_epu2.pdf}
    \caption{Comparison of Edge-Popup, IteRand, and Weight Recycling using continuous valued weights with signed constant initialization. In this figure, we vary the model width. }\label{depth_bin}
    \centering
\end{figure}
%\FloatBarrier