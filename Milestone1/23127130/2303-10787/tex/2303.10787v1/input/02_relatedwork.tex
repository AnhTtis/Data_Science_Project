\section{Related Works}

\subsection{Generative Networks}
% The training of a general GAN needs a trainable discriminator as reward functions, encourage the network to generate realistic contents that is hard to be distinguished by discriminators. 
Generative adversarial networks~\cite{goodfellow2020generative} launched the generative revolution in image generation~\cite{denton2015deep,isola2017image,radford2015unsupervised,karras2019style}, and text generation~\cite{yu2017seqgan,che2017maximum,guo2018long}. This self-supervised training scheme enables the networks to consume large unlabeled realistic dataset, and provides a powerful baseline in various downstream tasks like image colorization~\cite{nazeri2018image}, image compositing~\cite{zhu2021barbershop}, and text synthesis~\cite{li2016precomputed}. Variational autoencoder~\cite{kingma2013auto} is a counterpart framework in generative network domain. The network excludes the burden of discriminator and using only variational loss and regularization loss on latent space in the bottleneck. The concise of both network and training scheme support its generalized representation of the real dataset ~\cite{van2017neural,he2022masked}. 

Modern generative methods have a root in autoencoding pretext tasks from the NLP literature~\cite{devlin2018bert}. Masked language modeling is a category of pretraining tasks in which pieces of a token sequence are hidden with a \verb|[MASK]| token and the model fills in the missing piece. In the autoregressive setting, this approach is simplified to a forward-looking token regression and so models generally have a backward-looking attention emphasis, generating the newest token sequentially. This autoregressive scheme achieves success in computer vision tasks like ViT~\cite{dosovitskiy2020image}, large language models~\cite{radford2018improving} like GPT-3~\cite{brown2020language}.


\subsection{Layout Generation}
Numerous works focusing layout generation have been proposed recently. LayoutGAN~\cite{li2020layoutgan} and LayoutVAE~\cite{jyothi2019layoutvae} provide general 2D layout planning for natural images. More works focus on document layout generation~\cite{kikuchi2021constrained,tabata2019automatic,lin2020variational}. In particular, the work of ~\cite{patil2020read} introduced recursive autoencoding for layout generation, as well as a layout similarity \textit{DocSim}, which looks at the geometric similarity of layouts weighted by size of the elements.~\cite{gupta2021layouttransformer} is an example, in which the transformer architecture is applied in this autoregressive fashion to generate layout tokens (class labels and bounding boxes). In~\cite{arroyo2021variational} ideas from the transformer-based methods mentioned above are combined with variational autoencoders to produce a more controllable and predictable generator. This work also implements the Wasserstein sequence distance as a metric into the layout literature. Our work builds on this idea and gives the Wasserstein distance more geometric significance, giving us the \textit{Doc-EMD} metric that compares well with the Wasserstein and the \textit{DocSim}.


\subsection{Diffusion Generative Methods}
Diffusion models use a sequential denoising model as an objective to generate realistic objects from Gaussian noise~\cite{ho2020denoising,NicholDiffusion2021,SongDenoising2020}. A domain-specific mean-estimator is used to model a markov process that is similar in spirit to deconvolution, but can be trained in an end-to-end manner. This approach is primarily applied in the image domain due to the approximately continuous nature of images and the denoising approach relying on using a Gaussian estimator for the inversion step. The diffusion model has achieved great success in text-image synthesis~\cite{ramesh2022hierarchical,rombach2022high,gu2022vector}, 3D neural rendering~\cite{poole2022dreamfusion}, 3D point cloud generation~\cite{luo2021diffusion}, image compositing~\cite{song2022objectstitch}, audio generation~\cite{kong2020diffwave,agostinelli2023musiclm}, and video generation~\cite{molad2023dreamix}. Recent works have shown that to extend this generative mechanism to discrete spaces, a rounding network can be applied that maps the denoised token embedding to a dictionary~\cite{DiffusionLM2022}. Our work builds on this and applies this approach to document layout, producing realistic document layouts that can be conditioned on partial layouts.


