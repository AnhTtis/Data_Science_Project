The modern drug discovery process consists of multiple sequential steps that progress from an initial large collection of candidates sampled from the intractable drug-like chemical space. These candidates are filtered according to their likelihood of succcess according to some \textit{scoring function}. The results of this \textit{virtual screen} are used to identify chemical ``leads'' for more rigorous yet expensive experimental validation. To consider all hypothetical possible candidate drug molecules for activity with a \textit{single} protein target would require approximately $3.12 \times 10^{34}$ years to search with brute force\cite{top_500}, assuming a throughput of approximately $10^{60} / 10^{18}$ molecules per second (for the sake of simplicity, one molecule per FLOP) with current generation exascale leadership-class computing facilities. Clearly even with this generous estimate, replicating this effort for all known 10s of thousands human proteins with experimentally-determined crystal structures would require computing resources that are not expected to be generally available in our lifetimes. 
% time estimate according to total_num_molecules / (molecules_per_sec * sec_year), assuming (generously) one FLOP per molecule
% (1e60) / (1e18 * 3.154e+7)
% \textcolor{red}{How can we refer to the capabilities of current-generation "leadership class" computing facilities in the context of virtual screening?}. 
% The current highest rated supercomputer on the Top 500 ranking (\url{https://top500.org}), Frontier at Oak Ridge National Laboratory, is rated at 1,685.65 PFlop/s with 8,730,112 cores. 
% The number of seconds in a year is  np.power(10,60) / (np.power(10, 15)*3.154e7)
% 3.6554264572189185e-05. 
% 3.170577e+34 years
In practice, collections of purchasable drug-like molecules are on the order of billions of possibilities. Even with this constraint on chemical space, current scoring functions for inferring protein-drug interactions still require high performance computing (HPC) resources to conduct screens on the scale of billions in an acceptable time frame~\cite{Zhang2014-iq}. 

Scoring functions are roughly divided into the distinct categories of physics-based and machine learning-based. Physics-based methods such as the \textit{molecular docking} methods~\cite{Trott2010-ij, Eberhardt2021-ql} are generally believed to be on the ``fast'' end of the spectrum of accuracy versus latency tradeoff. More accurate methods including Molecular Mechanics/Generalized Boltzmann Surface Area (MM/GBSA)\cite{Massova2000-qu, Greenidge2013-iz} which is used to ``re-score'' docking poses and update their rankings or binding free-energy calculations based upon intensive atomistic molecular dynamics (MD) simulations, are infeasible to run for even a relatively small number of candidate possibilities~\cite{Wright2014-uq, Eberhardt2021-ql}. A general workflow then is to first apply the cheaper docking methods followed by more expensive but accurate calculations based on MD simulations\cite{Lau2021-dr}. Current research is attempting to use machine learning to produce efficient surrogate models of physics-based calculations~\cite{Gentile2020-ku, Clyde2023-vk}. 
  
Much interest in the drug discovery community has shifted towards the development of deep learning models for prediction of protein-ligand interactions, with competitive results on experimental datasets such as PDBBind\cite{Jones2021-al, Jimenez2018-ei, Stepniewska-Dziubinska2018-fo}. Although such methods are highly efficient as compared to traditional physics-based calculations, deploying these methods in practice on billions of molecules requires significant compute resources\cite{Jones2021-al, Lau2021-dr, Stevenson2021-nw, Jacobs2021-ag}. It is also well known that deep learning models are incredibly complex in their architecture definitions as well as their training requirements as compared to more traditional machine learning approaches such as kernel methods. While gradient based optimization does allow for Deep Learning models to handle processing much larger datasets than kernel methods are practically capable of, deep learning models are also notoriously complex architectures, so much so that an entire area of research is dedicated towards their acceleration both at the algorithm level and in hardware. Ultimately scaling these models to address scoring growing collections of molecules will depend on success in development of specialized hardware that can also keep pace with the rapid level of model development. 
% todo (Derek): I'm alluding to the fact that training a deep learning model is a huge pain. you have to choose a good initialization, TRY to monitor details such as the distributions of your activation functions, gradients, etc etc Learning rate scheduler of which there are many, etc etc

Hyper-dimensional computing (HDC) is an emerging paradigm of lightweight machine learning with parallels to kernel methods~\cite{Plate1995-gz, Kanerva2009-sz, Thomas2021-uo, Karunaratne2019-zu, Ge2020-dp}. 
In a simple description, HDC requires the specification of an \textit{encoding} method to transform the raw input data to a high-dimensional vector space as \textit{hypervectors}. Given a notion of similarity metric defined on the high-dimensional space, such as cosine similarity which is only sensitive to the relative orientation, the hypervectors can be aggregated in order to build canonical class representations, forming the \textit{associative memory} of the model. Inference then simply requires computing similarity between the query point with the elements of the associative memory (one for each class).
Thus, HDC has been studied in the computer hardware community for some time in parallel to more traditional deep learning research as it provides the ability to receive massive speedups at the hardware level\cite{Rahimi2019-vb, Burrello2019-qf, Rasanen2016-ac, Mitrokhin2019-op, Kanerva2000-uw, Karunaratne2019-zu, Kang2022-dac}.
 
Despite the potential of HDC in the context of screening protein-ligand interactions, to the best of our knowledge there has only been a single previously reported study of HDC on a molecular machine learning task in general~\cite{Ma2021-xu}. In our work, we seek to expand upon previous work by considering additional structure-based encoding methods derived from extended connectivity fingerprints (ECFP), a widely used representation in a range of molecular modeling tasks and similarity analysis~\cite{Rogers2010-xp}, as well as Self-referencing embedded strings (SELFIES)\cite{Krenn2020-zn}. We evaluate on MoleculeNet in order to facilitate our comparison to previously reported state of the art results. We then seek to establish a rigorous analysis of HDC-based screening models in the context of publicly available collections of labeled molecules frequently studied in ML-based approaches. 
  
The potential for HDC to serve as a lightweight, readily available screening technique that is particularly amenable to advances in hardware architecture, can thus provide a crucially important tool for efficient screening of increasingly large collections of molecular representations.
