
\documentclass[letter, 12pt]{article}


\usepackage{natbib}
\setlength{\bibsep}{0pt plus 0.1ex}
\usepackage{amssymb, blkarray, amsmath,xcolor,graphicx,xspace,colortbl,rotating} % 
\usepackage[raggedrightboxes]{ragged2e} 
\usepackage{textcomp}
\usepackage{appendix}  %% 100
\usepackage{bm}  %% 100
\usepackage{boxedminipage}  %% 100
\usepackage{color}  %% 100
\usepackage{endnotes}  %% 100
\usepackage{ragged2e}  %% 100
\usepackage[onehalfspacing]{setspace}  %% 100
\usepackage{tabulary}  %% 100  
\usepackage{varioref}  %% 100
\usepackage{wrapfig}  %% 100  
%\graphicspath{{Uniqueness_of MFE POST EC1_graphics/}{Uniqueness_of MFE POST EC1_tcache/}{Uniqueness_of MFE POST EC1_gcache/}}
%\DeclareGraphicsExtensions{.pdf,.eps,.ps,.png,.jpg,.jpeg}
%\usepackage[paper=letterpaper, twoside=false,textwidth=6.3in, textheight=8.7in,left=0.98in, top=0.99in,headheight=0.17in, headsep=0.17in,]{geometry}
\usepackage[margin=1in]{geometry}
\DeclareGraphicsExtensions {.pdf,.svg,.eps,.ps,.png,.jpg,.jpeg}
\newtheorem {theorem}{Theorem}
\newtheorem {acknowledgement}{Acknowledgement}
\newtheorem {algorithm}[theorem]{Algorithm}
\newtheorem {assumption}{Assumption}
\newtheorem {axiom}[theorem]{Axiom}
\newtheorem {case}[theorem]{Case}
\newtheorem {claim}{Claim}
\newtheorem {conclusion}[theorem]{Conclusion}
\newtheorem {condition}[theorem]{Condition}
\newtheorem {conjecture}[theorem]{Conjecture}
\newtheorem {corollary}{Corollary}
\newtheorem {criterion}[theorem]{Criterion}
\newtheorem {definition}{Definition}
\newtheorem {example}{Example}
\newtheorem {exercise}[theorem]{Exercise}
\newtheorem {lemma}{Lemma}
\newtheorem {notation}[theorem]{Notation}
\newtheorem {problem}[theorem]{Problem}
\newtheorem {proposition}{Proposition}
\newtheorem {remark}{Remark}
\newtheorem {solution}[theorem]{Solution}
\newtheorem {summary}[theorem]{Summary}
\newcommand{\newgw}[1]{{\color{blue} #1}}
\newcommand{\delgw}[1]{{\color{green} [DELETED: #1]}}
\newcommand{\newbl}[1]{{\color{red} #1}}
\newenvironment {proof}[1][Proof]{\noindent \textbf {#1.} }{\ \rule {0.5em}{0.5em}}


\begin{document}
%\title{On nonlinear Markov Chains with an Aggregator}
%\author{Bar Light}
%\maketitle

\title{Nonlinear Markov Chains with an Aggregator and Their Applications}

\author{Bar Light\protect\thanks{School of Mathematical Sciences, Department of Statistics and Operations Research, Tel Aviv University, Israel. e-mail: \textsf{barlight@tauex.tau.ac.il} }}  
\maketitle

\thispagestyle{empty}

 \noindent \noindent \textsc{Abstract}:
\begin{quote}
	
We study the properties of a subclass of stochastic processes called discrete-time nonlinear Markov chains with an aggregator. In these chains, the next period's distribution of the process depends on both the current state of the process and on a real-valued function of the current distribution of the process. For these chains, we provide conditions for the uniqueness of an invariant distribution and a simple method to find the unique invariant distribution, which do not rely on contraction arguments. Instead, the approach is based on flexible monotonicity properties imposed on the nonlinear Markov kernel. We demonstrate the necessity of these monotonicity conditions to prove the uniqueness of an invariant distribution by simple examples. We apply our findings to analyze stationary distributions in strategic queueing systems, identify conditions under which a class of nonlinear equations in $\mathbb{R}^{n}$ has a unique solution, and investigate the properties of wealth distributions in large dynamic economies.

		 
\end{quote}


%\noindent {\small Keywords: }Dynamic programming;.

%\smallskip \noindent \emph{JELcis plassification}: 

\newpage 


\section{Introduction} 


Nonlinear Markov chains are stochastic processes in which the distribution of the process in the next period  depends on both the current state of the chain and the current distribution. These chains have been extensively studied in  various fields, including the McKeanâ€“Vlasov process \citep{mckean1966class}, mean-field games \citep{huang2006large,lasry2007mean}), population games \citep{sandholm2010population}, and evolutionary biology \citep{kolokoltsov2010nonlinear}. 
Nonlinear Markov chains with an aggregator are a subclass of nonlinear Markov chains,  where the next period's distribution of the process depends on both the current state of the chain and a real-valued function of the current distribution that is called an aggregator.\footnote{The terminology comes from the game theory literature where the distribution of the process represents the distribution of players' states \citep{acemoglu2012,light2022mean}. We keep this terminology for the current paper despite the fact that we study general nonlinear Markov chains that are not necessarily related to game theory. } These chains naturally appear in large dynamic economies e.g., the wealth distribution's evolution in heterogeneous-agent macroeconomics models \citep{aiyagari1994} or the industry dynamics' evolution  \citep{weintraub2008markov}, and in the evolution of opinion dynamics and other stochastic processes described in  \citep{kolokoltsov2010nonlinear}.\footnote{
Numerous dynamic economic models incorporate an aggregator function, as detailed in works such as \cite{acemoglu2012},  \cite{acemoglu2018equilibrium}, and \cite{light2022mean}, which explore a variety of dynamic models featuring an aggregator. Nonlinear Markov chains equipped with an aggregator, studied in this paper, effectively capture the dynamics of these systems, where the invariant distribution often represents the equilibrium of the economic model (see Section \ref{sec:wealth} for a specific example of this type).}



In this paper we study discrete-time nonlinear Markov chain with an aggregator and provide conditions that ensure the uniqueness of an invariant distribution for these chains without relying on contraction arguments.   Our approach to prove uniqueness is based on monotonicity properties imposed on the nonlinear Markov kernel. These monotonicity conditions are flexible and can be tailored to the specific nonlinear Markov chain being studied (see Example \ref{example:flexible} in Section \ref{sec:unique}). We provide simple examples that demonstrate the necessity of these monotonicity conditions in establishing the uniqueness of an invariant distribution (see Examples \ref{example:decreasing} and \ref{example:preserving} in Section \ref{sec:necessity}). We introduce a simple algorithm that utilizes a bisection method to compute the unique invariant distribution of the nonlinear chain, (see Section \ref{sec:compute}) 
which enhances the practical applicability of our uniqueness result. 


In Section \ref{sec:applications}, we explore three distinct applications where our results can be naturally applied. The first application addresses a strategic G/G/1 queueing system, where customer arrivals are influenced by expected waiting times. Under natural conditions on the the arrival process that imply that when the expected waiting time is higher less agents join the queue,  we demonstrate that there can be at most one invariant distribution for the nonlinear dynamics describing the queueing system. Additionally, we compute the equilibrium expected waiting time for a specific M/G/1 case. The second application delves into nonlinear equations in $\mathbb{R}^{n}$, which, despite lacking contraction properties, still possess a unique solution under certain monotonicity conditions that we provide. The third application examines the general evolution of wealth distributions within dynamic economic models, highlighting economic assumptions on agents' decisions that ensure the uniqueness of the invariant equilibrium wealth distribution. Together, these applications showcase the versatility of our findings in establishing the uniqueness of an invariant distribution across a diverse range of nonlinear Markov chains. 



\cite{butkovsky2014ergodic} provides conditions for the ergodicity of nonlinear Markov chains (see also \cite{saburov2016ergodicity} for ergodicity conditions for finite state nonlinear Markov chains and \cite{shchegolev2022new} for improved convergence rates). However, these conditions are significantly stronger than those required for the ergodicity of standard linear Markov chains and are not applicable to many settings of interest including the three applications we provide in this paper. Additionally, in Example \ref{Example:convergence}, we demonstrate that even for one of the most basic nonlinear Markov chains with two states, which satisfies our uniqueness conditions, the chain is not ergodic and 
 does not converge to the unique invariant distribution. This example highlights the limited applicability of any uniqueness result that relies on the ergodicity of the chains in the case of nonlinear Markov chains. In Example \ref{Example: Average Convergence} we further show that a law of large numbers fails for the nonlinear Markov chains even when our uniqueness conditions hold.  Despite these negative results, we   provide some important applications where the uniqueness of the invariant measure is of interest. For example, the invariant measure can correspond to the solution of nonlinear equations in $\mathbb{R}^{n}$ or the equilibrium wealth distribution of large dynamic economies (see Section \ref{sec:applications}). 
Shifting the focus to mean field games, the literature such as \cite{lasry2007mean}, \cite{light2022mean}, and \cite{anahtarci2023learning} explores conditions for the uniqueness of mean field equilibrium in different settings (see also \cite{wikecek2020discrete} and references therein for insights into the connection between discrete-time mean field games and nonlinear Markov chains).
  In a continuous time setting with a finite state space, \cite{neumann2023nonlinear} provides conditions that imply the uniqueness of an invariant measure, predicated on specific assumptions regarding differentiability and non-singularity related to the generator of the Markov chain. Furthermore, \cite{neumann2023nonlinear} illustrates peculiar behaviors exhibited by nonlinear Markov chains in continuous time through several examples.




\section{Model and Definitions}

In this section we present the model and preliminaries. In Section \ref{sec:setting} we introduce the nonlinear Markov chains that we study. In Section \ref{sec:definition} we provide the notations and definitions that are needed to state and prove our results. 

%In Section \ref{sec:unique} we present the monotonicity conditions that imply that  the nonlinear Markov chain has a unique invariant distribution. In Section \ref{sec:necessity} we show that these monotonicity conditions are necessary to prove uniqueness and in Section \ref{sec:convergence} we show that the nonlinear Markov chain does not necessarily converge to the unique invariant distribution even for a very simple two-state case. 

\subsection{Nonlinear Markov Chains with an Aggregator} \label{sec:setting}

Let $S$ be a polish space and $\mathcal{B}(S)$ be the Borel $\sigma$-algebra on $S$. We denote by $\mathcal{P}(S)$ the space of all probability measures on the measurable space $(S,\mathcal{B}(S))$. We study 
 the properties of the nonlinear Markov chain $(X_{t})_{t \in \mathbb{N}}$ on $S$  given by
\begin{equation} \label{Eq:w}
X_{t+1} = w(X_{t},H(\mu _{t}), \epsilon _{t+1})
\end{equation}
where $w: S \times \mathcal{H} \times E \rightarrow S$ is a measurable function, $\mu _{t}$ is the law of $X_{t}$, $H: \mathcal{P}(S) \rightarrow \mathbb{R}$ is a measurable function that is called an aggregator, $\mathcal{H} = \{ H(\mu): \mu \in \mathcal{P}(S) \} $ is the image of $H$, and $(\epsilon_{t})_{t \in \mathbb{N}}$ are independent and identically distributed (I.I.D) random variables that take values in a polish space $E$ with a law $\phi$. 


Let $Q$ be the nonlinear Markov kernel that describes the transitions of the nonlinear Markov chain  $(X_{t})_{t \in \mathbb{N}}$, i.e., 
\begin{equation}
    Q(x,h,B) = \phi (\epsilon \in E : w(x,h,\epsilon) \in B)
\end{equation}
for all $B \in \mathcal{B}(S)$, $x \in S$, $h \in \mathcal{H}$. That is, $Q(x,h,B)$ is the probability that the next period's state would lie in the set $B$ with the current state is $x$ and the current aggregator is $h$. A probability measure $\mu \in \mathcal{P}(S)$ is an invariant distribution of $Q$ if $T\mu = \mu$, i.e., $\mu$ is  a fixed point of $T$ where the operator $T: \mathcal{P}(S) \rightarrow \mathcal{P}(S)$ is given by  
$$T\mu(B) = \int _{S} Q(x,H(\mu),B)\mu(dx)$$
for all $B \in \mathcal{B}(S)$.


We are interested in finding conditions that imply that $T$ has a unique fixed point. The operator $T$ is nonlinear and generally not a contraction so standard methods cannot be applied. Instead, we prove uniqueness by leveraging monotonicity conditions over the nonlinear Markov kernel $Q$ that we now describe. 


\subsection{Preliminaries} \label{sec:definition} 

We assume throughout the paper that $S$ is endowed with a closed partial order $ \geq $.\footnote{The partial order $ \geq $ on $S$ is closed if $x_{n} \geq y_{n}$ for all $n$, $y_{n},x_{n} \in S$, $y_{n} \rightarrow y$ and $x_{n} \rightarrow x$, $y,x \in S$, imply $x \geq y$. For example, the standard product order on $S \subseteq \mathbb{R}^{n}$ is closed. } 
 We say that a function $f :S \rightarrow \mathbb{R}$ is increasing if $f (y) \geq f (x)$ whenever $y \geq x$. When $S \subseteq \mathbb{R}^{n}$ we will assume that $S$ is endowed with the standard product order unless otherwise stated (that is, $x \geq y$ for $x,y \in \mathbb{R}^{n}$ if $x_{i} \geq y_{i}$ for each $i=1,\ldots,n$). 

The space of probability measures $\mathcal{P} (S)$ is endowed with the weak topology. A sequence of measures $\mu_{n} \in \mathcal{P} (S)$ converges weakly to $\mu \in \mathcal{P} (S)$ if for all bounded and continuous functions $f :S \rightarrow \mathbb{R}$ we have
\begin{equation*}\underset{n \rightarrow \infty }{\lim }\int _{S}f (s) \mu_{n} (d s) =\int _{S}f (s) \mu (d s).
\end{equation*}

Let  $D \subseteq \mathbb{R}^{S}$ be a convex set where $\mathbb{R}^{S}$ is the set of all functions from $S$ to $\mathbb{R}$. When $\mu _{1}$ and $\mu _{2}$ are probability measures on $(S ,\mathcal{B}(S))$, we write $\mu _{2} \succeq _{D}\mu _{1}$ if \begin{equation*}\int _{S}f(s)\mu _{2}(ds) \geq \int _{S}f(s)\mu _{1}(ds)
\end{equation*}for all Borel measurable functions $f \in D$ such that the integrals exist. With slight abuse of notation, for two random variables $X,Y$, we write $X \succeq_{D} Y$ if $\mu _{X} \succeq _{D} \mu_{Y} $ where $ \mu_{X}$ is the law of $X$ and $\mu_{Y}$ is the law of $Y$.  



The binary relation $\succeq _{D}$ is called a stochastic order. When $D$ is the set of all increasing functions on $S$, we write $\mu _{2} \succeq _{SD}\mu _{1}$ and say that $\mu _{2}$ first order stochastically dominates $\mu _{1}$. 


To prove that $T$ has a unique fixed point it is  convenient  to assume that the linear Markov kernel  $Q(x,h,\cdot)$ has a unique invariant distribution when the aggregator $h \in \mathcal{H}$ is fixed. That is, the operator $M_{h} :\mathcal{P} (S) \rightarrow \mathcal{P} (S)$ has a unique fixed point where $M_{h}$ is the operator given by 
\begin{equation*}M_{h} \theta  (B) =\int _{S}Q (x ,h ,B) \theta  (d x)
\end{equation*}
that is parameterized by a fixed aggregator $h \in \mathcal{H}$. 
Note that when $T$ does not depend on the aggregator, then the operator $T$ reduces to $M_{h}$. 
Hence, 
if the operator $M_{h}$ possesses more than one invariant distribution, then, by considering $T$ as equivalent to $M_{h}$, the operator $T$ also possesses more than one invariant distribution.
\begin{definition} (Property (U)). 
We say that $Q$ satisfies Property (U) if for any $h \in \mathcal{H}$, the operator $M_{h}$ has a unique fixed point $\mu _{h}$. 
\end{definition}


 
A stronger version of Property (U) says that the Markov kernel $M_{h}^{n} \theta $ converges weakly to $\mu _{h}$ for any probability measure $\theta  \in \mathcal{P} (S)$ where $M_{h}^{n}$ means applying the operator $M_{h}$, $n$ times. 



\begin{definition} \label{def:Xerg} (Property (C)). 
We say that $Q$ satisfies Property (C) 
if $Q$ satisfies Property (U) and  $M_{h}^{n} \theta $ converges weakly to $\mu _{h}$ for any probability measure $\theta  \in \mathcal{P} (S)$ and any $h \in \mathcal{H}$ where $\mu _{h}$ is the unique fixed point of $M_{h}$. 
\end{definition}
Under certain conditions, Property (C) can be established using standard results regarding the stability of Markov chains in general state spaces (e.g., Theorem 13.3.1 or Theorem 16.2.3 in  \cite{meyn2012markov}). When the state space $S$ is finite, Property (C) can be established by assuming that $M_{h}$ is irreducible and aperiodic and Property (U) can be established by assuming that $M_{h}$ is irreducible.  

 
The key assumption that implies that the operator $T$ has at most one fixed point relates to the following monotonicity and preservation properties. 
\begin{definition}
Let $D \subseteq \mathbb{R}^{S}$. 

We say that $Q$ is $D$-decreasing  if for each $x \in S$, we have $Q (x ,h_{1} , \cdot ) \succeq  _{D}Q (x , h_{2}, \cdot )$ whenever $h_{2} \geq h_{1}$, $h_{1},h_{2} \in \mathcal{H}$.

We say that  $Q$ is increasing in $x$  with respect to $\succeq _{D}$ if for each  $h \in \mathcal{H}$, we have $Q (x _{2},h , \cdot ) \succeq  _{D}Q (x_{1} ,h, \cdot )$ whenever $x_{2} \geq x_{1}$.

We say that $Q$ is $D$-preserving if for all  $h \in \mathcal{H}$ the function 
\begin{equation*}
    v(x):=\int f (y) Q(x ,h ,dy) 
\end{equation*}
is in $D$ whenever $f \in D$. 


\end{definition}

Note that when $D$ is the set of all increasing functions then $\succeq _{D}$  reduces to the standard stochastic dominance order and $Q$ is increasing in $x$  with respect to $\succeq _{D}$ if and only if $Q$ is $D$-preserving (see, for example, Corollary 3.9.1 in \cite{topkis2011supermodularity}). In the case that $Q$ is increasing in $x$, Property (C) can be established using results from the theory of monotone Markov chains. These results typically require a splitting condition (see \cite{bhattacharya1988asymptotics},  \cite{kamihigashi2014stochastic}, and \cite{light2024note}) and hold in a wide range of applications.  




We say that $H$ is increasing with respect to $\succeq _{D}$ if $H(\mu_{2}) \geq H(\mu_{1})$ whenever $ \mu_{2} \succeq _{D} \mu_{1}$. 



 
A stochastic order $\succeq_{D}$ is said to be closed with respect to weak convergence if $\mu^{1}_{n} \succeq_{D} \mu^{2}_{n} $ for all $n$, $\mu^{1}_{n}$ converges weakly to $\mu^{1}$, and $\mu^{2}_{n}$ converges weakly to $\mu^{2}$ imply $\mu^{1} \succeq_{D} \mu^{2}$. Many stochastic orders of interest are closed with respect to weak convergence, e.g., the standard stochastic dominance order $\succeq_{SD}$. For a textbook treatment  of the closure properties of stochastic orders see, for example, Theorems 4.B.10  and 3.A.5  in \cite{shaked2007stochastic} .   

We say that $H$ is continuous if  $ \lim _{n \rightarrow \infty} H(\mu_{n}) = H(\mu)$ whenever $\mu_{n}$ converges weakly to $\mu$. We say that $Q$ is continuous if $Q(x_{n},h_{n}, \cdot)$ converges weakly to  $Q(x,h, \cdot )$ whenever $(x_{n},h_{n}) \rightarrow (x,h)$.


Recall that a partially ordered set $(Z , \geq )$ is said to be a lattice if for all $x ,y \in Z$, $\sup \{x ,y\}$ and $\inf \{y ,x\}$ exist in $Z$. $(Z , \geq )$ is a complete lattice if for all non-empty subsets $Z^{ \prime } \subseteq Z$ the elements $\sup Z^{ \prime }$ and $\inf Z^{ \prime }$ exist in $Z$.
 %When $Q$ is increasing in $x$, then the $S$-ergodicity of $Q$ can be established using results from the theory of monotone Markov chains. These results usually require a splitting condition (see \cite{bhattacharya1988asymptotics} and \cite{hopenhayn1992}) that typically holds in applications of interest.



\section{Main Results}

In this section we present our main results.  In Section \ref{sec:unique} we present the monotonicity conditions that imply that  the nonlinear Markov chain has a unique invariant distribution. In Section \ref{sec:necessity} we show that these monotonicity conditions are necessary to establish uniqueness and in Section \ref{sec:convergence} we show that the nonlinear Markov chain does not necessarily converge to the unique invariant distribution even for a very simple two-state case. In Section \ref{sec:compute} we provide a method to compute the unique invariant distribution. In Section \ref{sec:applications} we provide local uniqueness results that are based on local monotonicity conditions. 

\subsection{Uniqueness Theorem} \label{sec:unique}
We now present conditions that imply that $Q$ has a unique invariant distribution. We first provide conditions that imply that $Q$ has at most one invariant distribution. These conditions are based on monotonicity properties of the nonlinear Markov kernel $Q$. In particular, we show that under Property (C) or Property (U) and additional regularity conditions, when $Q$ is $D$-preserving and $D$-decreasing then $Q$ has at most one invariant distribution.  In Section \ref{sec:necessity} we show that these key order-theoretic conditions are necessary in order to establish uniqueness (see Examples \ref{example:decreasing} and \ref{example:preserving}). 

In applications, verifying whether $Q$ is $D$-preserving and $D$-decreasing is typically straightforward. In Section \ref{sec:applications}, we showcase various applications of Theorem \ref{Theorem: unique}, such as queueing systems and dynamic evolution of wealth distributions. In these cases, the monotonicity properties of $Q$ naturally hold, reflecting underlying behavioral or economic assumptions in the studied dynamic systems. The proofs are deferred to the Appendix. 



\begin{theorem} \label{Theorem: unique}
Let $D \subseteq \mathbb{R}^{S}$ be a non-empty set such that $H$ is increasing with respect to $\succeq  _{D}$. Assume that $Q$ is $D$-preserving and $D$-decreasing.

Assume that either of the following conditions hold: 

(i) $Q$ satisfies Property (C) and $\succeq_{D}$ is closed with respect to weak convergence. 

(ii) $Q$ satisfies Property (U) and $(\mathcal{P}(S),\succeq_{D})$ is a complete lattice. 


Then $Q$ has at most one invariant distribution. 
\end{theorem}

\begin{remark} \label{remark:G} The proof of Theorem \ref{Theorem: unique} shows that, to prove Theorem \ref{Theorem: unique}, it is enough to assume that Property (U)  holds only for $h \in \mathcal{H}$ such that $h=H(\mu)$ and $\mu$ is an invariant distribution of $Q$ as opposed to all $h \in \mathcal{H}$. 
\end{remark}

Theorem \ref{Theorem: unique} shows that $Q$ has at most one invariant distribution. The
existence of an invariant distribution follows by standard fixed-point arguments for the case where $S$ is compact and $Q$ is continuous as Proposition \ref{Prop:existence} shows. Extending this existence result for non-compact state spaces remains an interesting research direction. 


\begin{proposition} \label{Prop:existence}
Suppose that $H$ and $Q$ are continuous and that $S$ is compact. Then $Q$ has an invariant distribution. 
\end{proposition}

The monotonicity conditions required to prove Theorem \ref{Theorem: unique} are global, that is, the monotonicity conditions and Properties (U) and (C) are required to hold over all probability measures on $S$. However, in some applications, only a subset of these probability measures contains candidates for stationary distributions or holds particular interest. In Proposition \ref{Prop:local} in Section \ref{sec:localresults} we provide a local version of Theorem \ref{Theorem: unique}.  

Condition (ii) of Theorem \ref{Theorem: unique} is particularly useful for the case that $S$ is a finite set or a compact set in $\mathbb{R}$.
For example, suppose that $S=\{s_{1},\ldots,s_{n}\}$ is an ordered set of numbers with $s_{1} \leq s_{2} \leq ... \leq s_{n}$ and $\mathcal{P}(S)$ is endowed with the standard stochastic dominance order $\succeq  _{SD}$. It is immediate to see that $(\mathcal{P}(S),\succeq_{SD})$ is a complete lattice with
$$ \sup \{ \mu , \lambda \}  (\{s_{t}, \ldots, s_{n} \})=  \max \{ \mu   (\{s_{t}, \ldots, s_{n} \}) ,\lambda   (\{s_{t}, \ldots, s_{n} \}) \} $$
and 
$$ \inf \{ \mu , \lambda \} (\{s_{t}, \ldots, s_{n} \})=  \min \{ \mu (\{s_{t}, \ldots, s_{n} \}) ,\lambda  (\{s_{t}, \ldots, s_{n} \}) \} $$
for all $t =1,\ldots, n$  
(recall that $\mu  \succeq  _{SD} \lambda$ if and only if for every upper set $B$ we have $\mu (B) \geq \lambda (B)$ where $B \in \mathcal{B} (S)$ is an upper set if $x_{1} \in B$ and $x_{2} \geq x_{1}$ imply $x_{2} \in B$). In a similar fashion, $(\mathcal{P}(S),\succeq_{SD})$ is a complete lattice  when $S$ is a compact set in $\mathbb{R}$ when $\mathbb{R}$ is endowed with the standard partial order. For a this result and other examples of stochastic orders that generate lattices of probability measures see  \cite{muller2006stochastic}. 




In applications, it may seem natural to select $D$ as the set of all increasing functions. 
However, the versatility in choosing the set $D$ in Theorem \ref{Theorem: unique} is fruitful for proving uniqueness for various nonlinear Markov chains. 
 Carefully selecting an appropriate set $D$ can be essential for effectively utilizing Theorem \ref{Theorem: unique}. The following examples  demonstrate the importance of this choice. 

\begin{example} \label{example:flexible} (Flexibility of the set $D$).
(i) Consider the following nonlinear Markov chain 
\begin{equation} \label{Eq:ex_1(i)} X_{t+1} = a X_{t} - H(\mu_{t}) + \epsilon_{t+1} \end{equation}
on $\mathbb{R}$ where $0<a<1$, $\epsilon _{t}$ are I.I.D random variables with finite expectations, and $H(\mu_{t}) = \int m(x)  \mu_{t}(dx)$ for some increasing and  function $m:\mathbb{R} \rightarrow \mathbb{R}$ such that $H(\mu_{t})$ is finite. Then, we can use Theorem \ref{Theorem: unique}  to show that the nonlinear Markov chain $(X_{t})_{t \in \mathbb{N}}$ has at most one invariant distribution.  The proof of the claims are provided in the appendix. 
\claim \label{claim1} {The Markov chain given in Equation (\ref{Eq:ex_1(i)}) has at most one invariant distribution.}

\

Now consider the nonlinear Markov chain \begin{equation}\label{eq:ex_1_2dim} (X_{1,t+1},X_{2,t+1}) =  (a X_{1,t} - H(\mu_{t}) + \epsilon_{1,t+1}, k(X_{2,t}) + \epsilon_{2,t+1})\end{equation} 
on $\mathbb{R}^{2}$ where $0<a<1$, $\epsilon _{1,t} , \epsilon_{2,t}$ are I.I.D random variables with finite expectations, $k$ is a function that is not increasing, and $H(\mu_{t}) : = \int m(x_{1})  \mu_{t}(d(x_{1},x_{2}))$ for some increasing function $m$ such that $H(\mu_{t})$ is finite. In this case,   $Q$ is not necessarily $D$-preserving when $D$ is the set of all increasing functions because $k$ is not increasing. However, if we let $D$ to be the set of all the functions that are increasing in the first argument then one can verify that $Q$ is $D$-preserving and $D$-decreasing (see the claim below).  Hence, a suitable choice of the set $D$ can be crucial for applying Theorem \ref{Theorem: unique}. 
\claim \label{claim2} {Consider the Markov chain given in Equation (\ref{eq:ex_1_2dim}). Then it has at most one invariant distribution if Property (C) holds.} 
\end{example}

\begin{example}
(Flexibility of the set $D$). Consider the $n$-dimensional nonlinear Markov chain on $\mathbb{R}^{n}$ 
with 
\begin{equation} \label{Eq_Ex1_ii} X_{i,t+1} =  a_{i} X_{i,t} - \beta_{i} H(\mu_{t}) + \epsilon_{i,t+1} \end{equation}
for $i=1,\ldots,n$ where $0<a_{i}<1$, $\epsilon _{i,t} $ are I.I.D random variables with finite expectations,  and 
$H(\mu_{t}) : = \int \sum 
 \gamma_{i} x_{i}\mu_{t}(d(x_{1},x_{2},\ldots,x_{n}))$ for some vector $\gamma = (\gamma_{1},\ldots,\gamma_{n})$ in $\mathbb{R}^{n}$. 

 Let $O$ be the set of vectors in $\mathbb{R}^{n}$ such that $x_{i}$ is positive for an odd $i$ and negative for an even $i$, that is, $O = \{ x \in \mathbb{R}^{n}: x_{i} \geq 0, i \text{ is odd }, x_{i} \leq 0,  i \text{ is even}\} $. Assume that $\beta = (\beta _{1} ,\ldots,\beta_{n})$ and $\gamma = (\gamma_{1} , \ldots ,\gamma_{n})$ are in $O$. It is easy to see that we cannot use $D$ as the set of all increasing functions in order to apply Theorem \ref{Theorem: unique}. However, 
 consider the set of functions $D$ such that $f: \mathbb{R}^{n} \rightarrow \mathbb{R}$ is in $D$ if $f(x) = \sum _{i}^{n} y_{i}x_{i} + c$ for some $y \in O$ and $c \in \mathbb{R}$. Under this set of functions $D$, we show that we can use Theorem \ref{Theorem: unique} to prove that the nonlinear Markov chain has at most one invariant distribution. This example together with Example \ref{example:flexible} demonstrate the importance of the flexibility of choosing the set of functions $D$ in order to apply Theorem \ref{Theorem: unique}. 
 \claim \label{claim3} {The nonlinear Markov chain given in Equation (\ref{Eq_Ex1_ii}) has at most one invariant distribution.} 
\end{example}

 

Note that the contraction conditions for the ergodicity of nonlinear Markov chains given in \cite{butkovsky2014ergodic} are generally not satisfied for the nonlinear Markov chains in the previous examples (see also the simple two-state nonlinear Markov chain we provide in Example \ref{Example:convergence}). Despite this, we provide a general method to find the unique invariant distribution when it exists of the nonlinear Markov chains in Section \ref{sec:compute}


\subsection{Necessity of the Monotonicity Conditions that Imply Uniqueness} \label{sec:necessity} 
In this section we provide simple examples that show that the properties $Q$ that $Q$ is $D$-preserving and $Q$ is $D$-decreasing are necessary for the uniqueness of the invariant distribution of $Q$.  




\begin{example} \label{example:decreasing}  ($Q$ is not $D$-decreasing). Suppose that $S=\{0,1\}$ endowed with the standard order ($1 \geq 1, 0 \geq 0,  1 > 0$) and $H(\mu) = \mu (\{1\}) $. Assume that $D$ is the set of all increasing functions so $\succeq_{D}$ is the standard stochastic dominance $\succeq_{SD}$. Note that  $H$ is increasing with respect $\succeq_{SD}$.   

 Consider the nonlinear Markov chain 
\[
Q' = 
        \begin{blockarray}{c@{\hspace{2pt}}rr@{\hspace{3pt}}}
         & 0   & 1   \\
        \begin{block}{r@{\hspace{2pt}}|@{\hspace{2pt}}
    |@{\hspace{2pt}}rr@{\hspace{2pt}}||}
        0 & 1- \min(0.5,\mu (\{1\} )) & \min(0.5,\mu (\{1\})) \\
        1 & 0.5 & 0.5  \\
        \end{block}
    \end{blockarray}
\]
It is immediate that $ \pi (\{ 1 \}) = 1/2 = \pi(\{0\})$ and $ \pi ' (\{ 1 \}) = 0,  \pi '  (\{ 0 \}) = 1$ are invariant distributions of $Q'$. 
It is easy to verify that $Q'$ satisfies property (ii) of Theorem 1, and that $Q'$ is $D$-preserving but not $D$-decreasing. Hence all the conditions of Theorem 1 are satisfied except for the condition that $Q'$ is $D$-decreasing and $Q'$ has two invariant distributions. 

\end{example}

\begin{example} \label{example:preserving}
 ($Q$ is not $D$-preserving). Suppose that $S=\{0,1,2\}$ is endowed with the standard order and $H(\mu) = \mu (\{1\}) + \mu (\{2\}) $. Assume that $D$ is the set of all increasing functions so $\succeq_{D}$ is the standard stochastic dominance $\succeq_{SD}$. Note that  $H$ is increasing with respect $\succeq_{SD}$.   


Consider the nonlinear Markov chain  
\[
Q'' = 
        \begin{blockarray}{c@{\hspace{1pt}}rrr@{\hspace{3pt}}}
         & 0   & 1   & 2 \\
        \begin{block}{r@{\hspace{1pt}}|@{\hspace{1pt}}
    |@{\hspace{1pt}}rrr@{\hspace{1pt}}|@{\hspace{1pt}}|}
        0 & 1/3 & 1/3 & 1/3 \\
        1 & 0 & H(\mu) & 1 - H(\mu) \\
        2 & H(\mu)  & 0   & 1-H(\mu)   \\
        \end{block}
    \end{blockarray}
\]

The distributions $ \pi (\{ 0 \}) =  \pi (\{ 1 \}) =  \pi (\{ 2 \}) = 1/3$ and $ \pi' (\{ 0 \}) = 0,  \pi' (\{ 1 \}) = 1,  \pi' (\{ 2 \})=0 $  are invariant distributions of $Q''$. 
It is easy to see that the Markov chain $Q''$ satisfies property (ii) of Theorem 1 and is $D$-decreasing. In addition, $Q''$ is not increasing in $x$, and hence, is not $D$-preserving as $Q''(1,h , \{1,2\} ) > Q''(2,h , \{1,2\} )$ for any $h >0$. Hence all the conditions of Theorem 1 are satisfied except to the condition that $Q''$ is $D$-preserving and $Q''$ has two invariant distributions. 

\end{example}


%\begin{example}
%Consider a Markov chain on  $\{0,1,2,\ldots,\}$ such that $X_{t+1}= X_{t} + 1$ with probability $\min ( \max (q_{1},\mathbb{E}(X_{t})) , q_{2} ) $ and $X_{t+1}= \max \{ X_{t} - 1 , 0 \}$ with probability $1 - \min ( \max (q_{1},\mathbb{E}(X_{t})) , q_{2} ) $  where $ q_{1} < q_{2} < 1/2$. 
%\end{example}



\subsection{Non-Convergence to the Invariant Distribution} \label{sec:convergence} Theorem \ref{Theorem: unique} and Proposition \ref{Prop:existence} provide sufficient conditions for the uniqueness of an invariant distribution for the nonlinear Markov kernel $Q$. However, these results do not provide conditions under which the sequence of measures $\mu_{t}$  converges weakly to the unique invariant distribution of $Q$.  Unfortunately, the following example shows that even in a very simple case, the monotonicity conditions that imply uniqueness do not imply convergence.  This is in sharp contrast with the contraction approach to prove the  uniqueness of an invariant distribution that guarantees convergence (e.g., \cite{butkovsky2014ergodic}).\footnote{See \cite{budhiraja2015local} and \cite{ying2018approximation} for further results. } This example illustrates the restricted applicability of any uniqueness result that depends on the ergodicity of chains in the context of nonlinear Markov chains. 


\begin{example} \label{Example:convergence} ($\mu_{t}$ does not converge to the unique invariant distribution).
Suppose that $S=\{0,1\}$ is endowed with the standard order and $H(\mu) = \mu (\{1\}) $. Assume that $D$ is the set of all increasing functions so $\succeq_{D}$ is the standard stochastic dominance $\succeq_{SD}$. Note that $H$ is increasing with respect $\succeq_{SD}$.    Consider the nonlinear Markov chain 
\[
Q = 
        \begin{blockarray}{c@{\hspace{2pt}}rr@{\hspace{3pt}}}
         & 0   & 1   \\
        \begin{block}{r@{\hspace{2pt}}|@{\hspace{2pt}}
    |@{\hspace{2pt}}rr@{\hspace{2pt}}||}
        0 & \mu (\{1\} ) & \mu (\{0\}) \\
        1 & \mu (\{1\}) & \mu (\{0\})  \\
        \end{block}
    \end{blockarray}
\]
It is easy to see that $ \pi (\{ 1 \}) = 1/2 = \pi(\{0\})$ is the unique invariant distributions of $Q$ and $Q$ 
 satisfies all the conditions of Theorem 1. Note that for any initial distribution $\mu_{1} (\{1\} )  = \gamma $ and $\mu_{1} (\{ 0 \}) = 1-\gamma$ with $\gamma \neq 1/2$, $\mu_{t}$ does not converge to $\pi$ as $\mu_{t} (\{1\} )  = \gamma $ and $\mu_{t} (\{ 0 \}) = 1-\gamma$ for an odd $t$ and $\mu_{t} (\{1\} )  = 1- \gamma $ and $\mu_{t} (\{ 0 \}) = \gamma$ for an even $t$. 
\end{example}



 Example \ref{Example:convergence} illustrates that the sequence of measures $\{ \mu _{t} \}$ does not converge to the unique stationary distribution even when the conditions for uniqueness we described in Section \ref{sec:unique} hold. In addition, the nonlinear Markov chain $Q$ provided in Example \ref{Example:convergence} is very simple with only two states showcasing that we can't expect the sequence of measures $\{ \mu _{t} \}$ to converge in typical applications. In that example, $ \sum _{t=1}^{T} \mu_{t} /T$ converges to the unique stationary distribution. However, Example \ref{Example: Average Convergence} shows that this is not always the case even when the conditions for uniqueness provided in Theorem \ref{Theorem: unique} hold. 

 \begin{example} \label{Example: Average Convergence}
     ($\sum _{t=1}^{T} \mu_{t} /T$ does not converge to the unique invariant distribution).
Suppose that $S=\{0,1\}$ is endowed with the standard order and $H(\mu) = \mu (\{1\}) $. Assume that $D$ is the set of all increasing functions so $\succeq_{D}$ is the standard stochastic dominance $\succeq_{SD}$. Note that $H$ is increasing with respect $\succeq_{SD}$.    Consider the nonlinear Markov chain 
\[
Q = 
        \begin{blockarray}{c@{\hspace{2pt}}rr@{\hspace{3pt}}}
         & 0   & 1   \\
        \begin{block}{r@{\hspace{2pt}}|@{\hspace{2pt}}
    |@{\hspace{2pt}}rr@{\hspace{2pt}}||}
        0 & \mu (\{1\} ) & \mu (\{0\}) \\
        1 & 1-f( \mu (\{0\})) & f( \mu (\{0\})  \\
        \end{block}
    \end{blockarray}
\]
with 
\begin{align*}
    f(x ) & = x1_{ \{ x \leq 0.3 
\} } + (1.2x  -0.06) 1_{ \{ 0.3 < x \leq  0.5  \} } 
+  (0.8x  + 0.14) 1_{ \{ 0.5 < x \leq  0.7 \}  } +  x1_{ \{x > 0.7 
\} }
\end{align*} 
for $x \in [0,1]$. 
Note that $f (x ) \geq x$ and $f$ is increasing, and hence, the conditions of Theorem \ref{Theorem: unique} hold and there exists at most one invariant distribution. In addition, $f$ is continuous so from Proposition \ref{Prop:existence} the nonlinear Markov kernel $Q$ has a unique invariant distribution. 



As in Example \ref{Example:convergence}, if the initial distribution is $\mu _{1} (\{0\} )  = 0.7$, then $\mu _{2}(\{0\})  = 0.3$, and $\mu_{3} (\{0\})  = 0.7$ and so on. 
But $\pi ( \{ 0 \} ) = \pi (\{1\}) = 1/2 $ is not an invariant distribution so $\sum _{t=1}^{T} \mu_{t} /T$ does not converge to the invariant stationary distribution.  

 \end{example}

%Designing algorithms that ensure convergence to the unique invariant distribution of 
%the nonlinear Markov kernel $Q$ remains an interesting open question.



\subsection{Computation of the  Invariant Distribution } \label{sec:compute}


Section \ref{sec:convergence} provides elementary examples where the nonlinear Markov chain does not converge to the unique invariant distribution.   Despite these examples, Section \ref{sec:applications} provides some important applications where computing the unique invariant distribution is of interest. For example, the invariant distribution can correspond to the solution of nonlinear equations in $\mathbb{R}^{n}$ or the equilibrium wealth distribution of large dynamic economies that are well studied in the literature. 

   Thus,  it becomes imperative to devise a method capable of computing the invariant distribution of the nonlinear Markov chain. In this section, under the conditions of Theorem \ref{Theorem: unique} and Proposition \ref{Prop:existence},  we will demonstrate the efficacy of the straightforward bisection method in achieving this computational goal.  
   We provide a simple algorithm to compute the unique invariant distribution of $Q$. The algorithm initiates by identifying an interval \([c, d]\), $c<d$, where the function \(f(h) = h - H(\mu_{h})\) changes sign. The next step is to use a bisection method that guarantees to converge to the root of $f$, say $h^{*}$, that induces the unique invariant distribution of $Q$ given by $\mu_{h^{*}}$.   

\begin{proposition} \label{prop:compute}
    Let $S$ be compact and $D \subseteq \mathbb{R}^{S}$ be a non-empty set such that $H$ is continuous and increasing with respect to $\succeq  _{D}$ and $(\mathcal{P}(S),\succeq_{D})$ is a complete lattice. Assume that $Q$ is continuous, satisfies Property (U), $D$-preserving, and $D$-decreasing. 

 

Let $d= H(\overline{\mu})$ and 
$c=H(\underline{\mu } )$ where $\overline{\mu}$ ($\underline{\mu } $) is the supremum (infimum) of $\mathcal{P}(S)$. 
Consider the function $f(h)= h- H(\mu_{h})$ from $[c,d] \subseteq \mathbb{R}$ into $\mathbb{R}$, $[c,d] \subseteq \mathcal{H}$. Consider the sequence $h_{n} $ induced by the bi-section algorithm on $f$ with the starting interval $[c,d]$,\footnote{That is, let $h_{1} = d$, $h_{2}=c$, and in each iteration, $h_{n}=(h_{n-1}+h_{n-2})/2$. If $f(h_{n})=0$ then stop. If not, then replace either $(h_{n-1},f(h_{n-1}))$ or $(h_{n-2},f(h_{n-2}))$ with $(h_{n},f(h_{n}))$ so that $f$ crosses $0$ on the new interval. See Section 2 in \cite{burden19852} for an analysis of the bi-section method. } then $h_{n}$ converges to $h$ and $\mu_{h}$ is the unique invariant distribution of $Q$. 

\end{proposition}



In practice, it is typically simple to compute the points $c$ and $d$. For example, consider the finite case $S = \{s_{1} ,\ldots , s_{n} \}$ with the standard order $s_{i} \geq s_{j}$ whenever $i \geq j$ and $\mathcal{P}(S)$ endowed with the standard stochastic dominance order $\succeq_{SD}$. Then $\overline{\mu}$ is the Dirac measure centered on $s_{n}$ and $\underline{\mu}$ is the Dirac measure on $s_{1}$, and hence, $c$ and $d$ can be easily computed by applying the function $H$. For example, if $H (\mu)$ is the expected value operator, i.e., $H(\mu) = \sum _{s \in S} s \mu(\{s \}) $, then $c=s_{1}$ and $d=s_{n}$. Hence, the initial interval chosen by the algorithm is $[s_{1},s_{n}]$. As an example, consider Example \ref{Example:convergence} where we provided a simple Markov chain that does not converge to the unique invariant distribution. Applying the bi-section method described above, the algorithm first identifies the interval $[0,1]$ and $h_{1}=1$, $h_{2}=0$. It is immediate that $H(\mu_{h}) = 1-h$, and hence, $f(h) = h - (1-h)) = 2h-1$. Thus, $h_{3} = 1/2$ yields the root of $f$ and the algorithm converges in the first iteration.  


For finite state space described above with $n$ variables, the method described in Proposition \ref{prop:compute} is generally efficient and simple to implement as in each step the algorithm solves a linear program with $n$ variables and $n+1$ constraints (so that $\mu_{h}$ is a probability measure) to find $\mu_{h}$ and then evaluate $f$ to preform the bi-section method. 

%We provide a detailed example in Section ?. 

 \subsection{Local Results} \label{sec:localresults}


In this section, we present a localized version of Theorem \ref{Theorem: unique}. Instead of applying to all probability measures as dictated by Theorem \ref{Theorem: unique}, we introduce local versions of the monotonicity conditions and Properties (U) and (C). These local versions pertain only to a particular subset of probability measures that have specific interest. These conditions ensure that, within this subset, $Q$ has at most one invariant distribution. This subset may encompass probability measures that naturally emerge as candidates for invariant distributions or probability measures that are relevant for an application of interest. For a non-empty subset $\mathcal{W}$ of $\mathcal{P}(S)$ let $\mathcal{H}_{\mathcal{W}} = \{ H(\mu) : \mu \in \mathcal{W} \}$ . 





\begin{definition} Let $\mathcal{W}$ be a non-empty subset of $\mathcal{P} (S)$  

(i) We say that $Q$ satisfies Property (U) on $\mathcal{W}$  if for any $h \in \mathcal{H}_{\mathcal{W}}$, the operator $M_{h}$ has a unique fixed point $\mu _{h}$. 

(ii) We say that $Q$ satisfies Property (C) on $\mathcal{W}$
if $Q$ satisfies Property (U) on $\mathcal{W}$ and  $M_{h}^{n} \theta $ converges weakly to $\mu _{h}$ for any probability measure $\theta  \in \mathcal{W}$ and any $h \in \mathcal{H}_{\mathcal{W}}$. 
\end{definition}


 







Similarly, we provide local versions for the monotonicity and preservation properties introduced in Section \ref{sec:definition}. 


\begin{definition}
Let $D \subseteq \mathbb{R}^{S}$. 

We say that $Q$ is $D$-decreasing on $\mathcal{W}$ if for each $x \in S$, we have $Q (x ,h_{1} , \cdot ) \succeq  _{D}Q (x , h_{2}, \cdot )$ whenever $h_{2} \geq h_{1}$, $h_{1},h_{2} \in \mathcal{H}_{\mathcal{W}}$.

We say that $Q$ is $D$-preserving on $\mathcal{W}$ if for all  $h \in \mathcal{H}_{\mathcal{W}}$ the function 
\begin{equation*}
    v(x):=\int f (y) Q(x ,h ,dy) 
\end{equation*}
is in $D$ whenever $f \in D$. 


\end{definition}



The following Proposition generalizes Theorem \ref{Theorem: unique}. 

\begin{proposition} \label{Prop:local}

    
    Let $\mathcal{W}$ be a non-empty subset of  $\mathcal{P}(S)$. 
    Let $D \subseteq \mathbb{R}^{S}$ be a non-empty set such that $H$ is increasing with respect to $\succeq  _{D}$ on $\mathcal{W}$. 


    
    
    Assume that $Q$ is $D$-preserving on $\mathcal{W}$ and $D$-decreasing on $\mathcal{W}$.


Suppose that $M_{h} \theta \in \mathcal{W}$ whenever $\theta \in \mathcal{W}$ and $h \in \mathcal{H}_{\mathcal{W}}$. 

Assume that either of the following conditions hold: 

(i) $Q$ satisfies Property (C) on $\mathcal{W}$ and $\succeq_{D}$ is closed with respect to weak convergence. 

(ii) $Q$ satisfies Property (U)  on $\mathcal{W}$ and $(\mathcal{W},\succeq_{D})$ is a complete lattice. 


Then $Q$ has at most one invariant distribution on $\mathcal{W}$. 
\end{proposition}

The proof of Proposition \ref{Prop:local} is similar to the proof of Theorem \ref{Theorem: unique} and is given in the Appendix.

\section{Applications} \label{sec:applications}

In this section we present our applications. In Section 3.1 we study the invariant distribution of a G/G/1 queueing system where arrivals depend on the expected waiting times. In Section 3.2 we study non-linear equations that do not necessarily satisfy contraction properties and have a unique solution. In Section 3.3 we study the invariant distribution of wealth distributions in dynamic economies where the rate of returns depend on the aggregate savings in the economy. 

\subsection{Strategic Behavior in Queuing Systems} 
 A considerable body of literature exists on strategic behavior in queueing systems. Within this domain, the inter-arrival times often depend on the queue length or expected waiting time, as agents, being strategic, can opt not to join the queue if they foresee an extended waiting period  \citep{hassin2003queue}.  Typically, queueing systems are examined in the steady state, making it essential to investigate the existence of a unique steady state generated by the system to obtain robust comparative statics results. We will now demonstrate how Theorem \ref{Theorem: unique} can be utilized to establish that there is, at most, one invariant distribution for the waiting time distribution within a general $G/G/1$ strategic queueing system, wherein the inter-arrival times are contingent on the expected waiting time.\footnote{Other nonlinear Markov chains were analyzed in the strategic queueing literature. For example, \cite{xu2013supermarket} show that a supermarket game where customers strategically choose which queue to join has a unique equilibrium under certain monotonicity conditions. See  \cite{mukhopadhyay2016randomized} and \cite{yang2018mean} for further related models. }

Consider a $G/G/1$ queue where the the time between the $t$th and $t+1$th arrivals is given by the random variable $T_{t}$ and the service time of the $t$ customer is given by the random variable $S_{t}$. Because agents are strategic they are less likely to join the queue when the waiting time is longer. We assume that the time between arrivals depends on the expected waiting time and write $T_{t}(\mathbb{E}(X_{t}) )$ where $X_{t}$ is the waiting time of the $t$th customer to describe this dependence. When the expected waiting time is higher then the number of agents that join the queue is lower. We capture this dependence by assuming that  $T_{t}(x ) \succeq_{SD} T_{t}(x' )$ whenever $x \geq x'$, $x,x' \in \mathbb{R}_{+}$. That is, the time between arrivals is stochastically higher when the expected waiting time is higher. We assume that $
(S_{t})_{t \in \mathbb{N}}$ and $(T_{t})_{t \in \mathbb{N}}$ are independent random variables with positive expectations and finite variances. 

The expected waiting times experienced by customers in the queue evolve by the following nonlinear Markov chain on $\mathbb{R}_{+}$: 
\begin{equation} \label{Eq:queue} X_{t+1} = \max (0, X_{t} + S_{t} - T_{t} (\mathbb{E}(X_{t}) ).
\end{equation}




It can be easily verified that $Q$ is $D$-preserving and $D$-decreasing when $D$ is the set of all increasing functions. Under the usual  assumption that the queue does not explode, i.e., $\mathbb{E}S_{t} < \mathbb{E}T_{t}$, a standard argument from the Markov chain literature (e.g., Theorem 
19.3.5 in \cite{meyn2012markov}) can be used to show that Property (C) is satisfied. Hence, we can use Theorem \ref{Theorem: unique} to conclude that there exists at most one waiting time equilibrium steady state distribution. The proofs of all the Corollaries are deferred to Section \ref{Sec:CorrProofs} in the Appendix. 

\begin{corollary} \label{Corr:Queue}
    The nonlinear Markov chain describing the queueing system in Equation (\ref{Eq:queue}) has at most one invariant distribution. 
\end{corollary}


As a particular example for this result, we study  an M/G/1 queuing system where the arrival rate depends on the expected waiting time and provide a closed-form expression for the stationary expected waiting time. 


\begin{example} ($M/G/1$ queue). 
Consider an $M/G/1$ queue so the time between arrivals has an exponential distribution. Let  $Law(S_{t}) = Law (S)$ and $Law(T_{t}(x)) $ has an exponential distribution with the parameter $\lambda(x)$. Suppose that $\lambda : \mathbb{R}_{+} \rightarrow \mathbb{R}_{+}$ is a decreasing function.  

\begin{claim} \label{claim_queue} (i) The nonlinear Markov chain given in Equation (\ref{Eq:queue}) has at most one invariant distribution. 

(ii) Suppose that the mean interarrival time equals the expected waiting time so $\lambda(x) = 1/x$. Then there is a unique invariant distribution for the nonlinear Markov chain given in Equation (\ref{Eq:queue}) and the expected value of the stationary waiting time $X_{\infty}$ is given by the closed-form expression
$$ \mathbb{E}(X_{\infty}) = \frac{\mathbb{E}(S^{2})} {\sqrt{\mathbb{E}(S)^{2}+2\mathbb{E}(S^{2})} - \mathbb{E}(S)} .$$

In particular, if the queue is an $M/M/1$ queue so $S$ is an exponential random variable then 
$$ \mathbb{E}(X_{\infty}) = \frac{ 2\mathbb{E}(S)} {\sqrt{5}-1}. $$
    
\end{claim}


%we must have $1/\lambda = \lambda\mathbb{E}(S^{2})/(2(1-\lambda\mathbb{E}(S))$ which yields 
%$$ \lambda = \frac{\sqrt{(\mathbb{E}(S))^{2}+2\mathbb{E}(S^{2})} - \mathbb{E}(S)}{\mathbb{E}(S^{2})}$$
%and is valid when $\lambda \mathbb{E}(S) < 1$. 

\end{example}


\subsection{Nonlinear Equations}


The study of nonlinear systems of equations in $\mathbb{R}^{n}$ has long been a significant area of interest in mathematics and its applications. Finding conditions that ensure a unique solution to such systems is crucial as it offers insights into the properties and stability of solutions, which in turn, have far-reaching implications across various fields, including operations, engineering, economics, and optimization \citep{ortega2000iterative}. 
It is generally uncommon to identify a comprehensive set of conditions that guarantee a unique global solution for a system of nonlinear equations in $\mathbb{R}^{n}$ that do not satisfy contraction properties. We showcase the application of Theorem \ref{Theorem: unique} to determine conditions that ensure a unique solution for a specific class of nonlinear equations, which we define subsequently. These conditions are based  on monotonicity concerning the majorization order. 




Let $\Delta_{n} = \{ \boldsymbol{x} \in \mathbb{R}^{n}: \sum_{i=1}^{n}  x_{i} = 1, x_{i} \geq 0 \text{ }\forall i \} $ be the $n$-dimensional simplex.  
Consider a stochastic matrix $\boldsymbol{P} (G(\boldsymbol{x})) \in \mathbb{R}^{n\times n}$ that is parameterized by $G(\boldsymbol{x})$ where  $G:\Delta _{n} \rightarrow A$  and $A \subseteq \mathbb{R}$ is the image of $G$, i.e., $P_{ij} (a) \geq 0$, and $\sum _{j=1}^{n} P_{ij} (a) = 1$ for all $a \in A$.



For $\boldsymbol{x},\boldsymbol{y} \in \mathbb{R}^{n}$ write $\boldsymbol{x} \geq _{m} \boldsymbol{y}$ if $ \sum _{j=k}^{n} x_{j} \geq \sum _{j=k}^{n} y_{j}$ for all $1 \leq k \leq n$ and $\sum_{j=1}^{n} x_{j} = \sum _{j=1}^{n} y_{j}$ (the order $\geq _{m}$ is sometimes called majorization between vectors in $\mathbb{R}^{n}$). We denote by $\boldsymbol{P}_{i}(a)$ the $i$th row of the matrix $\boldsymbol{P}$. 


The following Corollary follows  from applying Theorem \ref{Theorem: unique} and Proposition \ref{Prop:existence}. 

\begin{corollary} \label{Coro:non-linear}
Let $G:\Delta _{n} \rightarrow A$ be a continuous function that  is increasing with respect to $ \geq _{m}$. The nonlinear system of equations $\boldsymbol{x} = \boldsymbol{x} \boldsymbol{P} (G(\boldsymbol{x}))$ on $\Delta_{n}$ where $\boldsymbol{P} (G(\boldsymbol{x}))$ is a stochastic matrix that is parameterized by $G(\boldsymbol{x})$ has a unique solution if the following three conditions hold: 


(1) For all $a \in A$, $i \geq i'$, we have  $\boldsymbol{P}_{i}(a) \geq _{m} \boldsymbol{P}_{i'}(a)$.

(2) For all $1 \leq  i \leq n$, $a' \geq a$, $a,a' \in A$, we have  $\boldsymbol{P}_{i}(a) \geq _{m} \boldsymbol{P}_{i}(a')$.

%and all $1 \leq k \leq n$ we have $\sum _{j=k}^{n} P_{ij}(G(\boldsymbol{x})) \geq \sum _{j=k}^{n} P_{ij}(G(\boldsymbol{x}'))$.

(3) For all $a \in A$, the linear system of equations $\boldsymbol{x} = \boldsymbol{x} \boldsymbol{P} (a)$ for $\boldsymbol{x} \in \Delta_{n}$ has a unique solution. 


\end{corollary}




Corollary \ref{Coro:non-linear} leverages Theorem \ref{Theorem: unique} to show that a class  of nonlinear equations have a unique solution. This Corollary can be used as a tool to generate nonlinear systems of equations that are known to have a unique solution. Theorem \ref{Theorem: unique} can also be used to show the uniqueness of solutions for nonlinear equations in many other different ways  than Corollary \ref{Coro:non-linear}, e.g., see Example \ref{example:flexible}.



%Theorem \ref{Theorem: unique} can be further used as a powerful tool to provide answers for questions in probability that involves nonlinear equations. We provide a simple example to illustrate this: is there $(u,\sigma^{2})$ with $u \neq 0$ such that $u= \mathbb{E} N(u,\sigma^{2} ) = - \mathbb{E} (N(u,\sigma^{2} )) ^{k}  $  for an odd number $k$ where $N(u , \sigma^{2})$ is the normal random variable with mean $u$ and variance $\sigma^{2}$? The answer is intuitively negative as the odd moment of the normal distribution is intuitively positive when the mean is positive as the distriubtion is symmetric.   We provide a negative answer to this question with a simple argument using Theorem \ref{Theorem: unique}. While this is a special illustrative example, we believe that the technique to answer this question can be applied to ask similar questions in probability theory. 



%\begin{example} \label{Example:Normal-distributions} (Normal distributions.)
 %   Let $N(u , \sigma^{2})$ be normal random variable with mean $u$ and variance $\sigma^{2}$. From symmetry $\mathbb{E} N(0,\sigma^{2} ) = \mathbb{E} (N(0,\sigma^{2} )) ^{k} = 0 $ for every odd number $k$. We will use Theorem \ref{Theorem: unique} to show that  $u = \mathbb{E} N(u,\sigma^{2} ) \neq - \mathbb{E} (N(u,\sigma^{2} )) ^{k}  $ whenever $k$ is an odd number and $u \neq 0$. 

%Assume in contraction that there exists an odd number $k$ and $u \neq 0$ such that $u= \mathbb{E} N(u,\sigma^{2} ) = - \mathbb{E} (N(u,\sigma^{2} )) ^{k}  $. Consider the nonlinear Markov chain $X_{t} = -H(\mu_{t}) + N(0,\sigma^{2})$ on $\mathbb{R}$ where $H(\mu_{t}) = \int x^{k} \mu_{t}(dx) $. Then it is immediate from Theorem \ref{Theorem: unique} with $D$ as the set of all increasing functions that $X_{t}$ has at most one invariant distribution. Clearly the distribution of $N(0,\sigma^{2})$ is one invariant distribution of $X_{t}$. We claim that the distribution $\mu$ of $N(u,\sigma^{2})$ is also an invariant distribution of $X_{t}$ which contradicts Theorem \ref{Theorem: unique}. To see this, note that $ - H(\mu) + N(0,\sigma^{2}) = N(- \mathbb{E} (N(u,\sigma^{2} )) ^{k},\sigma ^{2} ) = N(u, \sigma^{2} )$ by the contradiction assumption. 
    
%\end{example}





\subsection{Wealth Distributions} \label{sec:wealth}


In heterogeneous-agents macroeconomic models (see \cite{stachurski2009economic} for a recent textbook treatment of economic dynamic models), agents determine their consumption, savings, and allocation of savings across financial assets based on their current wealth level in each period. 


An extensive literature exists on these models, specifically focusing on the analysis of stationary equilibria and the associated stationary wealth distributions. Despite the vast body of research, the conditions ensuring the uniqueness of equilibrium are restricted to a handful of special cases.\footnote{For instance, see \cite{light2020uniqueness, light2021general, achdou2022income}. } In this section, we employ Theorem \ref{Theorem: unique} to demonstrate that there can be, at most, one stationary wealth distribution equilibrium\footnote{The existence of the stationary wealth distribution equilibrium is widely studied in the literature (e.g., \cite{acikgoz2015existence},  \cite{acemoglu2012}, \cite{light2022mean}).  } for a typical progression of wealth dynamics in these models, given that agents' savings increase with the rate of returns and their current wealth levels. We proceed to outline the model.


In each period $t$, there are $n$ positive random variables $R_{1,t},\ldots,R_{n,t}$ that represents returns from different financial assets $i=1,\ldots,n$ and are I.I.D. We denote $Law (R_{i})= Law (R_{i,t})$. Each agent has a policy $\boldsymbol{g} = (g_{1},\ldots,g_{n})$ that determines the amount of wealth the agent allocates to asset $i$ when it has a wealth level $x$, i.e., $g_{i}(R_{1},\ldots,R_{n},x)$ is the non-negative amount that an agent with wealth $x$ allocates to asset $i$ when the law of the returns is given by $(R_{1},\ldots,R_{n})$.\footnote{We assume for simplicity that the agents policy depends on their current  wealth only. All the results in this section can be easily extended to the case when each agent uses a different policy that depends on the agent's specific features such as preferences or behavioral biases.} In applications, the agent's policy is typically derived from a consumption-saving dynamic programming problem.  In our analysis, we assume a general policy function that can be deduced from rational agents, behavioral biases  \citep{acemoglu2018equilibrium}, myopic agents, or learning algorithms. 



The return $R_{i}$ of asset $i$ is parameterized by an aggregator $H(\mu)$ that depends on the wealth distribution in the economy $\mu$ and is increasing with respect to first order stochastic dominance (typically, in applications, $H(\mu) = \int_{x} x \mu(dx) $ is the total savings in the economy). In each period, each agent $j$ receives a non-negative random income $Y_{t}^{j}$ that is independent across time and across agents. We assume for simplicity that $(Y_{t}^{j},R_{1,t},\ldots,R_{n,t})_{t \in \mathbb{N} }$ are I.I.D random variables. 

Each agent's wealth evolution is described by the following nonlinear Markov chain:
\begin{equation} \label{eq:wealth}
X^{j}_{t+1} = \sum _{i=1}^{n} g_{i}(R_{1}(H(\mu _{t} )),\ldots , R_{n} (H(\mu_{t}) ) ,X^{j}_{t} )R_{i,t+1}(H(\mu _{t}) ) + Y ^{j}_{t+1} 
\end{equation}
 where $X_{t}^{j}$ is the current wealth agent $j$ has,  and $\mu_{t}$ is the law of $X_{t}^{j}$ which describes the  wealth distribution across agents in period $t$. Hence, if an agent has a current wealth of  $x_{t}$, the agent invests $g_{i}$ in asset $i$ then the next period's wealth is the sum of investments times the returns plus the next period's income. A stationary equilibrium in this economy is defined by an invariant distribution of the nonlinear Markov chain given in Equation (\ref{eq:wealth}) with the interpretation that this distribution represents the long run equilibrium wealth distribution across agents \citep{aiyagari1994,acemoglu2012}. 

 Under standard assumptions, the policy function is increasing in the current wealth, i.e., savings increase when the agent's wealth is higher, and the returns are decreasing in the savings with respect to first order stochastic dominance, i.e., the returns are (stochastically) lower when the total savings are higher (see \cite{acemoglu2012}, and \cite{acemoglu2018equilibrium}). Under these assumptions, we can apply Theorem \ref{Theorem: unique} to conclude that there is at most one stationary wealth distribution equilibrium if the total amount of savings $\sum g_{i}$ is increasing in the rate of returns. In the economics literature, this property means that the substitution effect dominates the income effect. Hence, the key condition that implies that there is at most one stationary wealth distribution  equilibrium is that  savings increase with the rate of returns (a special case of this result with one financial asset and rational agents is studied in \cite{light2020uniqueness}). We now present this result formally. 

 \begin{corollary} \label{Coro:wealth}
     Suppose that $H(\mu)$ is increasing with respect to $\succeq_{SD}$. Assume that:

     (1) Property (C) holds.\footnote{There is a vast literature on conditions that ensure that property (C) holds in different models of wealth dynamics. For recent results see \cite{ma2020income}}
     
     (2) The function $\sum g_{i}$ is increasing in $x$ and decreasing in the aggregator in the sense that 
     $$ \sum g_{i} (R_{1} (h_{2} ), \ldots , R_{n}  ( h_{2} ) , x_{2} ) \geq  \sum g_{i} (R_{1} (h_{1} ), \ldots , R_{n}  ( h_{1} ) , x_{1} )  $$
     whenever $x_{2} \geq x_{1}$ and $h_{1} \geq h_{2}$. 

     (3) For $i=1,\ldots,n$, $R_{i}(h_{2}) \succeq_{SD} R_{i}(h_{1})$ whenever $h_{1} \geq h_{2}$. 

     Then the nonlinear Markov chain on $\mathbb{R}_{+}$ described in Equation (\ref{eq:wealth}) has at most one invariant distribution.
 \end{corollary}


\section{Conclusions} 

This paper studies discrete-time nonlinear Markov chains with an aggregator and establishes  conditions that imply the uniqueness of an invariant distribution for these chains. Unlike traditional approaches, our conditions do not rely on contraction properties of the chains, but rather on certain monotonicity properties. 
 We demonstrate, using simple examples, that the monotonicity conditions are necessary to prove the uniqueness of an invariant distribution. We provide a method to compute the unique invariant distribution and applied our results to strategic queueing systems, non-linear equations, and the evolution of wealth distributions in dynamic economies. We believe that our results can be applied to other models where the flexible monotonicity conditions we provide hold naturally.




There are  remaining important open questions 
concerning nonlinear Markov chains with an aggregator. For example, to prove the existence of an invariant distribution we assumed that the state space is compact which does not hold for many applications of interest. Moreover, our example shows that even in a basic two-state chain, convergence to the unique invariant distribution is not guaranteed. Therefore, devising algorithms that ensure convergence to the invariant distribution across broader settings than the one explored in Section \ref{sec:compute}, where we introduce a bisection method for identifying the unique invariant distribution, becomes crucial for computing the invariant distribution in practical applications

\newpage


\section{Appendix} 


\subsection{Proofs of Theorem \ref{Theorem: unique} and Propositions \ref{Prop:existence}, \ref{prop:compute}, \ref{Prop:local}}
We will use the following Proposition to prove Theorem \ref{Theorem: unique} (see Corollary 2.5.2 in \cite{topkis2011supermodularity}). 

\begin{proposition}
\label{Topkis Fixed point}Suppose that $Z$ is a non-empty complete lattice, $E$ is a partially ordered set, and $f$ is an increasing function from $Z \times E$ into $Z$. Then, for each $e \in E$, the greatest and least fixed points 
of $f$ exist and are increasing in $e$ on $E$. 
\end{proposition}



\begin{proof}[Proof of Theorem \ref{Theorem: unique}]
Let $\theta _{1} ,\theta _{2} \in \mathcal{P} (S)$ and assume that $\theta _{1}  \succeq  _{D}\theta _{2}$. 
Let $\mu_{1} ,\mu_{2}$ be two invariant distributions of $Q$. Assume without loss of generality that $h_{2} := H( \mu_{2}) \geq H( \mu_{1}) :=h_{1}$ and let $f:S \rightarrow \mathbb{R}$ be a function such that $f \in D$. We have 
\begin{align*}\int _{S}  f(x) M_{h_{2}} \theta _{2} (dx)  &  =\int _{S} \int_{S} f (y) Q(x ,h_{2} ,dy)   \theta _{2} (d x) \\
 &  \leq  \int _{S} \int_{S} f (y) Q(x ,h_{1},dy)   \theta _{2} (d x) \\
 &  \leq \int _{S} \int_{S} f (y) Q(x ,h_{1} ,dy)   \theta _{1} (d x) \\
 & = \int _{S}  f(x) M_{h_{1}} \theta _{1} (dx). 
 \end{align*}

 Thus, $M_{h_{1}} \theta _{1}  \succeq  _{D}M_{h_{2}} \theta _{2}$. The first inequality follows from the fact that $Q$ is $D$-decreasing. The second inequality follows from the facts that $\theta _{1}  \succeq  _{D}\theta _{2}$ and $Q$ is $D$-preserving. 
We conclude that $M_{h_{1}}^{n} \theta _{1}  \succeq  _{D}M_{h_{2}}^{n} \theta _{2}$ for all $n \in \mathbb{N}$. 

Assume that condition (i) of the theorem holds. 
The fact that $Q$ satisfies Property (C) implies that $M_{h_{i}}^{n} \theta _{i}$ converges weakly to the unique fixed point of $M_{h_{i}}$ which is given by $\mu _{h_{i}}$ for $i=1,2$. Because $\mu_{1}$ and $\mu_{2}$ are invariant distributions of $Q$ we have  $\mu _{h_{i}} =\mu_{i}$ for $i=1,2$. Because $ \succeq  _{D}$ is closed with respect to weak convergence,  we have $\mu_{1} \succeq  _{D} \mu_{2}$. Using the fact that $H$ is increasing with respect to $\succeq  _{D} $ implies $h_{1} \geq h_{2}$. 

We conclude that if $\mu_{1}$ and $\mu_{2}$ are invariant distributions of $Q$ then $H(\mu_{1}) = H(\mu_{2})$. Thus, $Q (x ,H(\mu_{1}) ,B) =Q (x,  H(\mu_{2}) ,B)$ for all $x \in S$ and $B \in \mathcal{B} (S)$. Because $Q$ satisfies assumption (U) the operators $M_{H(\mu_{1})}$ and $M_{H(\mu_{2})}$ have unique fixed points. Thus, $\mu _{H(\mu_{1})} = \mu _{H(\mu_{2})}$, i.e., $\mu_{1} = \mu_{2}$. 
We conclude that if an invariant distribution of $Q$ exists, it is unique. 

Now assume that condition (ii) of the theorem holds. Define the order $\geq '$ on $\mathbb{R}$ by $x \geq  'y$ whenever $y \geq  x$.   Under this assumption, the arguments above imply that 
the operator $M$ is increasing from $\mathcal{P}(S) \times \mathcal{H}$ to $\mathcal{P}(S)$ on the complete lattice $( \mathcal{P}(S),\succeq  _{D})$ when $\mathcal{H}$ is endowed with $\geq '$. 
Then by applying Proposition \ref{Topkis Fixed point} to the increasing operator $M$  we have $\mu _{h_{1}} \succeq _{D} \mu _{h_{2}}$, i.e., $\mu_{1} \succeq  _{D} \mu_{2}$. Now we can use the same arguments as the arguments for the case that condition (i) holds to show that if an invariant distribution of $Q$ exists, it is unique. 
\end{proof}


In order to establish the existence of an invariant distribution we will use chauder-Tychonoff's following  fixed-point theorem (see Corollary 17.56 in \cite{aliprantis2006infinite}).

\begin{proposition}
(Schauder-Tychonoff) Let $K$ be a non-empty, compact, convex subset of a locally convex Hausdorff space, and let $f :K \rightarrow K$ be a continuous function. Then the set of fixed points of $f$ is compact and non-empty. 
\end{proposition}

\begin{proof}[Proof of Proposition \ref{Prop:existence}]
  Because $S$ is a compact polish space  $\mathcal{P} (S)$ is a compact polish space under the weak topology  (see Theorem 15.11 in \cite{aliprantis2006infinite}).
Clearly $\mathcal{P} (S)$ is convex. $\mathcal{P} (S)$ endowed with the weak topology is a locally convex Hausdorff space. Thus, if $T $ is continuous, we can apply Schauder-Tychonoff's fixed point theorem to conclude that $T $ has a fixed point. 

To show that $T$ is continuous, take a sequence of measures $\{ \mu_{n} \}$ and assume that it converges weakly to $\mu$.  

Let $f :S \rightarrow \mathbb{R}$ be a continuous and bounded function. Because $Q$ and $H$ are continuous we have $\lim _{n \rightarrow \infty} \int_{S} f(y) Q(x_{n},H(\mu_{n}),dy) = \int_{S} f(y) Q(x,H(\mu),dy) $ whenever $x_{n} \rightarrow x$. Define $m_{n}(x) : = \int_{S} f(y) Q(x,H(\mu_{n}),dy) $. Then $m_{n}(x)$ is a uniformly bounded sequence of functions such that $m_{n}(x_{n}) \rightarrow m(x)$ whenever $x_{n} \rightarrow x$. Thus, by Lebesgue's Convergence Theorem for varying measures (see Theorem 3.5 in \cite{serfozo1982convergence} and Section 5 in \cite{feinberg2020fatou}) we have $\lim _{n \rightarrow \infty} \int m_{n}(x) \mu_{n}(dx) = \int m(x) \mu (dx)$. Hence,
\begin{align*}\underset{n \rightarrow \infty }{\lim }\int _{S}f (x) T  \mu_{n} (d x) &  =\underset{n \rightarrow \infty }{\lim }\int _{S} \int_{S} f(y) Q(x,H(\mu_{n}),dy) \mu_{n} (d x) \\
 &  =\int _{S} \int_{S} f(y) Q(x,H(\mu),dy) \mu (d x) \\
 &  =\int _{S}f (x) T \mu(dx) .\end{align*}
 Thus, $T\mu_{n}$ converges weakly to $T \mu$. We conclude that $T$ is continuous. Thus, by the Schauder-Tychonoff's fixed point theorem, $T $ has a fixed point. 
\end{proof}







\begin{proof} [Proof of Proposition \ref{prop:compute}]
   From Theorem \ref{Theorem: unique} and Proposition \ref{Prop:existence}, $Q$ has a unique invariant distribution, say $\mu^{*}$.
Let $h^{*} =H(\mu^{*})$. From Property (U), $\mu_{h^{*}}$ is the unique probability measure that satisfies
$$\mu_{h^{*}}(B) = \int Q(x, h^{*}, B)  \mu_{h^{*}}(dx)  . $$
Hence, $\mu_{h^{*}} = \mu^{*}$, and $H(\mu_{h^{*}} ) = h^{*}$, i.e., $f(h^{*})=0$. On the other hand, if $h^{*}$ is a root of $f$, then $$\mu_{h^{*}}(B) = \int Q(x, h^{*}, B)  \mu_{h^{*}}(dx) =  \int Q(x, H(\mu_{h^{*}} ), B)  \mu_{h^{*}}(dx)  . $$
That is, $\mu_{h^{*}}$ is the unique invariant distribution of $Q$. 

In other words, $f$ has a (unique) root $h$ such that $f(h)=0$ if and only if $\mu_{h}$ is the (unique) invariant distribution of $Q$.

To find the root of $f$ we will show that $f$ is continuous and that $f(d) \geq 0 \geq f(c)$. This implies that the sequence $h_{n}$ defined in the statement of the proposition converges linearly to the root of $f$ as desired (e.g., Theorem 2.1 in \cite{burden19852}).


Let $H(\mu) \in \mathcal{H}$ and denote $h=H(\mu)$. Then  $d= H(\overline{\mu}) \geq h  \geq H(\underline{\mu } ) = c$ because $H$ is increasing. 
From the proof of Theorem \ref{Theorem: unique}, we have $H(\mu_{d}) \leq H(\mu_{h}) \leq H(\mu_{c})$. 
Hence, 
$$f(d) = d -H(\mu_{d}) \geq f(h)=h - H(\mu_{h}) \geq c -H(\mu_{c})=f(c).$$ 
From the argument above, there exists $h$ such that $f(h)=h-H(\mu_{h})=0$. We conclude that 
 $f(d) \geq 0 \geq f(c)$.

We now show that $f$ is continuous. 
 Consider a sequence $\{h_{n}\} \in D$ such that  $h_{n}$ converges to $h$ and let $\{\mu_{h_{k}}\}$ be a subsequence of $\{ \mu_{h_{n}} \}$ that converges to $\lambda$. From the same argument as the argument in the proof of Proposition \ref{Prop:existence}, for every continuous and bounded function $m:S \rightarrow \mathbb{R}$, we have
 \begin{align*}\underset{k \rightarrow \infty }{\lim }\int _{S}m (x) \mu_{h_{k}} (d x) &  =\underset{k \rightarrow \infty }{\lim }\int _{S} \int_{S} m(y) Q(x,h_{k},dy) \mu_{h_{k}} (d x) \\
 &  =\int _{S} \int_{S} m(y) Q(x,h,dy) \lambda (d x) \\
 &  =\int _{S}m (x) M_{h} \lambda(dx) .\end{align*}
Because $\{ \mu_{h_{k}} \}$ converges to $\lambda$ we also have
$$ \lim _{k \rightarrow \infty} \int_{S} m(x) \mu_{h_{k}}  (dx) = \int_{S} m(x) \lambda  (dx).$$
Thus, $\lambda =M_{h}\lambda$. From assumption (U), $\mu_{h} $ is the unique fixed point of $M_{h}$, and thus,  $\lambda =\mu_{h} $. 

We conclude that each subsequence of $\{ \mu_{h_{n}} \}$ that converges weakly at all converges weakly to $\mu_{h}$. Furthermore, since $S$ is compact, the sequence $\{ \mu_{h_{n}} \}$ is a tight sequence of probability measures. Thus, $\{ \mu_{h_{n}} \}$ converges weakly to $\mu _{h}$ (see the Corollary after Theorem 25.10 in \cite{billingsley2008probability}). 

Because $H$ is continuous, we conclude that $f(h) = h - H(\mu_{h})$ is continuous. Hence, the sequence $\{h_{n} \}$ converges to $h$ such that $f(h)=0$ and $\mu_{h}$ is the unique invariant distribution of $Q$. 
\end{proof}



\begin{proof}[Proof of Proposition \ref{Prop:local}]
The proof is similar to the proof of Theorem \ref{Theorem: unique}. We provide it here for completeness. Let $\theta _{1} ,\theta _{2} \in \mathcal{W}$ such that $\theta _{1}  \succeq  _{D}\theta _{2}$. 
Let $\mu_{1} ,\mu_{2} \in \mathcal{W}$ be two invariant distributions of $Q$. 

Assume without loss of generality that $h_{2} := H( \mu_{2}) \geq H( \mu_{1}) :=h_{1}$ so $h_{1},h_{2} \in \mathcal{H}_{\mathcal{W}}$ and let $f:S \rightarrow \mathbb{R}$ be a function such that $f \in D$. We have 
\begin{align*}\int _{S}  f(x) M_{h_{2}} \theta _{2} (dx)  &  =\int _{S} \int_{S} f (y) Q(x ,h_{2} ,dy)   \theta _{2} (d x) \\
 &  \leq  \int _{S} \int_{S} f (y) Q(x ,h_{1},dy)   \theta _{2} (d x) \\
 &  \leq \int _{S} \int_{S} f (y) Q(x ,h_{1} ,dy)   \theta _{1} (d x) \\
 & = \int _{S}  f(x) M_{h_{1}} \theta _{1} (dx). 
 \end{align*}

 Thus, $M_{h_{1}} \theta _{1}  \succeq  _{D}M_{h_{2}} \theta _{2}$. The first inequality follows from the fact that $Q$ is $D$-decreasing on $\mathcal{W}$. The second inequality follows from the facts that $\theta _{1}  \succeq  _{D}\theta _{2}$ and $Q$ is $D$-preserving on $\mathcal{W}$. Now because $\theta_{1},\theta_{2} \in \mathcal{W}$ and $h_{1},h_{2} \in \mathcal{H}_{\mathcal{W}}$, we have $M_{h_{1}} \theta _{1}, M_{h_{2}} \theta _{2} \in \mathcal{W}$. Applying the same argument as above again, we conclude that $M_{h_{1}}^{n} \theta _{1}  \succeq  _{D}M_{h_{2}}^{n} \theta _{2}$ for all $n \in \mathbb{N}$. 

Now the proof continues exactly as in the proof of Theorem \ref{Theorem: unique}.
\end{proof}



\subsection{Proof of Corollaries \ref{Corr:Queue}, \ref{Coro:non-linear}, \ref{Coro:wealth}} \label{Sec:CorrProofs}



\begin{proof} [Proof of Corollary \ref{Corr:Queue}]
  Let $H(\mu) = \int _{\mathbb{R} _{+}} x \mu(dx)$,  and consider the set of probability measures $ \mathcal{W} = \{\mu \in \mathcal{P}(\mathbb{R}_{+}) : \mathbb{E} T( H( \mu )) > \mathbb{E}(S) \}$ where $Law(S_{t}) = Law (S)$ and $Law(T_{t} (x) ) = Law (T(x) )$. Note that if  $\mu$ is an invariant distribution of the nonlinear Markov chain given in Equation (\ref{Eq:queue}) then it belongs to $\mathcal{W}$ (see Theorem 19.3.5 in \cite{meyn2012markov}).  Let $D$ be the set of increasing functions, so $\succeq_{D}$ is equivalent to $\succeq_{SD}$ and $H$ is increasing with respect to $\succeq_{D}$. Using again Theorem 19.3.5 in \cite{meyn2012markov}), Property (C) is satisfied on $\mathcal{W}$. In addition by using the same arguments as the  arguments in the proof of Claim \ref{claim1},  $Q$ is $D$-preserving and $D$-decreasing. Hence, from Theorem \ref{Theorem: unique} (see also Remark \ref{remark:G}) we conclude that the nonlinear Markov chain given in Equation (\ref{Eq:queue}) has at most one invariant distribution which completes the proof.
\end{proof}


\begin{proof} [Proof of Corollary \ref{Coro:non-linear}]
    We need to show that the conditions of Theorem \ref{Theorem: unique} holds. We let $S=\{1,\ldots,n\}$ with the standard order, $H(\mu)=G \left (\mu(\{1\}),\ldots,\mu ( \{n \}) \right )$, and $D$ to be the set of increasing functions, so $\succeq_{D}$ is equivalent to $\succeq_{SD}$ and $(\mathcal{P}(S),\succeq_{D})$ is a complete lattice. Note that $H$ is increasing with respect to $\succeq_{SD}$ because $\mu \succeq_{SD} \mu' $ holds if and only if $\left (\mu(\{1\}),\ldots,\mu ( \{n \}) \right ) \geq_{m}\left (\mu'(\{1\}),\ldots,\mu ' ( \{n \}) \right ) $ and from the assumption that $G$ is increasing with respect to $\geq_{m}$. 
    
     Condition (1) implies that $Q$ is $D$-preserving, Condition (2) implies that $Q$ is $D$-decreasing, and Condition (3) implies that Property (U) holds.  Thus, we can apply Theorem \ref{Theorem: unique} to prove that $Q$ has at most one invariant distribution.  

    We can identify $Q$ with the stochastic matrix $P$ by $P_{ij} (\cdot) = Q(i,\cdot,\{ j \})$, and hence, using the definition of the invariant distribution, the Corollary follows from Theorem \ref{Theorem: unique}. 
\end{proof}


\begin{proof} [Proof of Corollary \ref{Coro:wealth}]
     We need to show that the conditions of Theorem \ref{Theorem: unique} holds. We let $S= \mathbb{R}_{+}$ with the standard order, and $D$ to be the set of increasing functions, so $\succeq_{D}$ is equivalent to $\succeq_{SD}$. 
    
   It is immediate that Condition (2) implies that $Q$ is $D$-preserving and Conditions (2) and (3) imply that $Q$ is $D$-decreasing. Thus, we can apply Theorem \ref{Theorem: unique} to prove that $Q$ has at most one invariant distribution.  
\end{proof}

\subsection{Proof of Claims 1,2,3,4}


\begin{proof}
    [Proof of Claim \ref{claim1}]
We let $D$ to be the set of all  increasing functions. Clearly $H$ is increasing with respect to $\succeq_{D}$. Property (C) holds for AR(1) process with $a \in (0,1)$, (see for example \cite{light2024note}).   Let $f: \mathbb{R} \rightarrow \mathbb{R}$ be increasing.  Then $ \int f(y)Q(x, h, dy) = \int f(ax -  h + \epsilon ) \phi (d(\epsilon)) $ is increasing in $x$ and decreasing in $h$ so $Q$ is $D$-preserving and $D$-decreasing.
\end{proof}

\begin{proof}
    [Proof of Claim \ref{claim2}]
We let $D$ to be the set of all the functions that are increasing in the first argument. Clearly $H$ is increasing with respect to $\succeq_{D}$. We need to show that  $Q$ is $D$-preserving and $D$-decreasing in order to use Theorem \ref{Theorem: unique}. Let $f \in \mathbb{R}^{\mathbb{R}^{2} }$ be increasing in the first argument.  Then $ \int f(y_{1},y_{2})Q((x_{1},x_{2}),h, dy) = \int f(ax_{1} -  h + \epsilon_{1},k(x_{2}) + \epsilon_{2}) \phi (d(\epsilon_{1},\epsilon_{2})) $ is increasing in the first argument and decreasing in $h$ so $Q$ is $D$-preserving and $D$-decreasing.
\end{proof}

\begin{proof}
    [Proof of Claim \ref{claim3}]
Consider the set of functions $D$ such that $f: \mathbb{R}^{n} \rightarrow \mathbb{R}$ is in $D$ if $f(x) = \sum _{i=1}^{n} y_{i}x_{i} + c$ for some $y \in O$ and $c \in \mathbb{R}$. Property (C) holds (see Example 1 in \cite{light2024note}).  It is immediate that $H$ is increasing with respect to $\succeq _{D}$. 
   
   We now show that $Q$ is $D$-preserving and $D$-decreasing. Let $f \in D$ so $f(x) = \sum _{i=1}^{n} y_{i}x_{i} + b$ for some $y \in O$.
   
   We have 
 \begin{align*}
     v(x):=\int f(x')Q(x,h,dx') & = \int f(a_{1}x_{1} - \beta_{1}h+\epsilon_{1},\ldots,a_{n}x_{n}-\beta_{n}h + \epsilon_{n}) \phi (d \epsilon ) \\
     & = \int \sum _{i=1}^{n} y_{i}(a_{i}x_{i} - \beta_{i}h + \epsilon_{i})\phi (d \epsilon ) + b \\
     & = \sum _{i=1}^{n} y_{i}'x_{i} + b'
      \end{align*}
with $y_{i}' = a_{i}y_{i}$ and $b' = \int \sum _{i=1}^{n} y_{i} ( -\beta_{i}h + \epsilon_{i})\phi (d \epsilon ) + b$. Note that $y' $ is in $O$ as $y \in O$ and $a_{i} \geq 0$ for all $i$. Hence, $v$ is in $D$ which means that $Q$ is $D$-preserving. 


To show that $Q$ is $D$-decreasing  let $h_{2} \geq h_{1}$ and note that 
\begin{align*}
\int f(x')Q(x,h_{2},dx') & =  \int \sum _{i=1}^{n} y_{i}(a_{i}x_{i} - \beta_{i}h_{2} + \epsilon_{i})\phi (d \epsilon ) + b \\
     & \leq  \int \sum _{i=1}^{n} y_{i}(a_{i}x_{i} - \beta_{i}h_{1} + \epsilon_{i})\phi (d \epsilon ) + b  \\
     & = \int f(x')Q(x,h_{1},dx')
\end{align*}
where the inequality follows from the fact that $y$ and $\beta$ are in $O$ so $y_{i}\beta_{i} \geq 0$ for all $i$. Thus, $Q$ is $D$-decreasing.
\end{proof}

\begin{proof}
    [Proof of Claim \ref{claim_queue}]
Part (i) follows immediately from Corollary \ref{Corr:Queue}. 

To prove part (ii), 
let 
\begin{equation} \label{Eq:x} x = \frac{\mathbb{E}(S^{2})} {\sqrt{\mathbb{E}(S)^{2}+2\mathbb{E}(S^{2})} - \mathbb{E}(S)} \end{equation}

and consider the linear Markov chain $W_{t+1} = \max (0, W_{t} + S_{t} - T_{t}(x) )$. Then it has a unique invariant distribution if $\mathbb{E}T_{t}(x) = x > \mathbb{E}(S) $ (see Theorem 19.3.5 in \cite{meyn2012markov}) which holds because
$$ \mathbb{E}(S)\sqrt{\mathbb{E}(S)^{2}+2\mathbb{E}(S^{2})} =\sqrt{\mathbb{E}(S)^{4}+2\mathbb{E}(S^{2})\mathbb{E}(S)^{2}}  < \sqrt{\left ( \mathbb{E}(S)^{2} + \mathbb{E}(S^{2}) \right ) ^{2}} =  \mathbb{E}(S)^{2} + \mathbb{E}(S^{2})  $$
which implies that $x > \mathbb{E}(S)$. 
Let $W_{\infty}$ be the random variable with the law $\mu^{*}$ where $\mu^{*}$ is unique invariant distribution of  the linear Markov chain $(W_{t})_{t \in \mathbb{N}}$. 



From the Pollaczek-Khinchin formula (see Equation (8.1) in Chapter 8 in \cite{cooperintroduction}) the stationary expected waiting time  is given by $\mathbb{E}(W_{\infty }) = \lambda (x) \mathbb{E}(S^{2})/(2(1-\lambda(x)\mathbb{E}(S)))$. Using the fact that $\lambda (x) = 1/x$, and algebraic manipulations, we see that $x = \mathbb{E}(W_{\infty })$. Hence, $\mu^{*}$ is the unique invariant distribution of the nonlinear Markov chain given in Equation (\ref{Eq:queue}). 

For $M/M/1$ queue $S$ is an exponential random variable with a parameter $\mu$, so $\mathbb{E}(S) = 1/\mu$ and $\mathbb{E}(S^{2}) = 2/\mu^{2}$ and we get $$\mathbb{E} (W_{ \infty})  = \frac{ 2}  {(\sqrt{5}-1)\mu} = \frac{ 2\mathbb{E}(S)} {\sqrt{5}-1}.$$ 


\end{proof}



\bibliographystyle{ecta}
\bibliography{unique}







\end{document}