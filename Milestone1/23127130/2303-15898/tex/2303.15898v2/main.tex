
\documentclass[letter, 12pt]{article}


\usepackage{natbib}
\setlength{\bibsep}{0pt plus 0.1ex}
\usepackage{amssymb, blkarray, amsmath,xcolor,graphicx,xspace,colortbl,rotating} % 
\usepackage[raggedrightboxes]{ragged2e} 
\usepackage{textcomp}
\usepackage{appendix}  %% 100
\usepackage{bm}  %% 100
\usepackage{boxedminipage}  %% 100
\usepackage{color}  %% 100
\usepackage{endnotes}  %% 100
\usepackage{ragged2e}  %% 100
\usepackage[onehalfspacing]{setspace}  %% 100
\usepackage{tabulary}  %% 100  
\usepackage{varioref}  %% 100
\usepackage{wrapfig}  %% 100  
%\graphicspath{{Uniqueness_of MFE POST EC1_graphics/}{Uniqueness_of MFE POST EC1_tcache/}{Uniqueness_of MFE POST EC1_gcache/}}
%\DeclareGraphicsExtensions{.pdf,.eps,.ps,.png,.jpg,.jpeg}
%\usepackage[paper=letterpaper, twoside=false,textwidth=6.3in, textheight=8.7in,left=0.98in, top=0.99in,headheight=0.17in, headsep=0.17in,]{geometry}
\usepackage[margin=1in]{geometry}
\DeclareGraphicsExtensions {.pdf,.svg,.eps,.ps,.png,.jpg,.jpeg}
\newtheorem {theorem}{Theorem}
\newtheorem {acknowledgement}{Acknowledgement}
\newtheorem {algorithm}[theorem]{Algorithm}
\newtheorem {assumption}{Assumption}
\newtheorem {axiom}[theorem]{Axiom}
\newtheorem {case}[theorem]{Case}
\newtheorem {claim}[theorem]{Claim}
\newtheorem {conclusion}[theorem]{Conclusion}
\newtheorem {condition}[theorem]{Condition}
\newtheorem {conjecture}[theorem]{Conjecture}
\newtheorem {corollary}{Corollary}
\newtheorem {criterion}[theorem]{Criterion}
\newtheorem {definition}{Definition}
\newtheorem {example}{Example}
\newtheorem {exercise}[theorem]{Exercise}
\newtheorem {lemma}{Lemma}
\newtheorem {notation}[theorem]{Notation}
\newtheorem {problem}[theorem]{Problem}
\newtheorem {proposition}{Proposition}
\newtheorem {remark}{Remark}
\newtheorem {solution}[theorem]{Solution}
\newtheorem {summary}[theorem]{Summary}
\newcommand{\newgw}[1]{{\color{blue} #1}}
\newcommand{\delgw}[1]{{\color{green} [DELETED: #1]}}
\newcommand{\newbl}[1]{{\color{red} #1}}
\newenvironment {proof}[1][Proof]{\noindent \textbf {#1.} }{\ \rule {0.5em}{0.5em}}


\begin{document}
%\title{On nonlinear Markov Chains with an Aggregator}
%\author{Bar Light}
%\maketitle

\title{Nonlinear Markov Chains with an Aggregator and their Applications}

\author{Bar Light\protect\thanks{Microsoft Research, NYC, USA. e-mail: \textsf{barlight@microsoft.com} }}  
\maketitle

\thispagestyle{empty}

 \noindent \noindent \textsc{Abstract}:
\begin{quote}
	
We study the properties of a subclass of stochastic processes called discrete-time nonlinear Markov chains with an aggregator. In these chains, the next period's distribution of the process depends on both the current state of the process and on a real-valued function of the current distribution of the process. We provide conditions for the uniqueness of an invariant distribution for these chains, which do not rely on contraction arguments. Instead, the approach is based on flexible monotonicity properties imposed on the nonlinear Markov kernel. We demonstrate the necessity of these monotonicity conditions to prove the uniqueness of an invariant distribution by simple examples. We apply our findings to analyze stationary distributions in strategic queueing systems, identify conditions under which a class of nonlinear equations in $\mathbb{R}^{n}$ has a unique solution, and investigate the properties of wealth distributions in large dynamic economies.

		 
\end{quote}


%\noindent {\small Keywords: }Dynamic programming;.

%\smallskip \noindent \emph{JELcis plassification}: 

\newpage 


\section{Introduction} 


Nonlinear Markov chains are stochastic processes in which the distribution of the process in the next period  depends on both the current state of the chain and the current distribution. These chains have been extensively studied in  various fields, including the McKeanâ€“Vlasov process \citep{mckean1966class}, mean-field games \citep{huang2006large,lasry2007mean}), population games \citep{sandholm2010population}, and evolutionary biology \citep{kolokoltsov2010nonlinear}. 
Nonlinear Markov chains with an aggregator are a subclass of nonlinear Markov chains,  where the next period's distributions of the process depends on both the current state of the chain and a real-valued function of the current distribution that is called an aggregator.\footnote{The terminology comes from the game theory literature where the distribution of the process represents the distribution of players' states \citep{acemoglu2012,light2022mean}. We keep this terminology for the current paper despite the fact that we study general nonlinear Markov chains that are not necessarily related to game theory. } These chains naturally appear in large dynamic economies e.g., the wealth distribution's evolution in heterogeneous-agent macroeconomics models \citep{aiyagari1994} or the industry dynamics' evolution  \citep{weintraub2008markov}, and in the evolution of opinion dynamics \citep{kolokoltsov2010nonlinear}.  


In this paper we study discrete-time nonlinear Markov chain with an aggregator and provide conditions that ensure the uniqueness of an invariant distribution for these chains without relying on contraction arguments.   Our approach to prove uniqueness is based on monotonicity properties imposed on the nonlinear Markov kernel. These monotonicity conditions are flexible and can be tailored to the specific chain being studied (see Example \ref{example:flexible} in Section \ref{sec:unique}). We provide simple examples that demonstrate the necessity of these monotonicity conditions in proving the uniqueness of an invariant distribution (see Examples \ref{example:decreasing} and \ref{example:preserving} in Section \ref{sec:necessity}). In Section \ref{sec:applications} we discuss three applications where our results can be naturally applied. The first is a strategic G/G/1 queueing system where the arrival of customers  depends on the expected waiting times. The second is nonlinear equations in $\mathbb{R}^{n}$ that lack contraction properties but have a unique solution. The third is general evolution of wealth distributions from the economics literature, where we provide economic conditions on the agents' decisions that imply the uniqueness of the invariant wealth distribution.  These applications showcase the versatility and  of our approach.  





The paper \cite{butkovsky2014ergodic} provides conditions for the ergodicity of nonlinear Markov chains. However, these conditions are significantly stronger than those required for the ergodicity of standard linear Markov chains and are not applicable to many settings of interest including the three applications we provide in this paper. Additionally, in Example \ref{Example:convergence}, we demonstrate that even for one of the most basic nonlinear Markov chains with two states, which satisfies our uniqueness conditions, the chain is not ergodic and 
 does not converge to the unique invariant distribution. This example highlights the limited applicability of any uniqueness result that relies on the ergodicity of the chains in the case of nonlinear Markov chains.





\section{Main Results}

In this section we present our main results. In Section \ref{sec:setting} we introduce the nonlinear Markov chains that we study. In Section \ref{sec:definition} we provide the notations and definitions that are needed to state and prove our results. In Section \ref{sec:unique} we present the monotonicity conditions that imply that  the nonlinear Markov chain has a unique invariant distribution. In Section \ref{sec:necessity} we show that these monotonicity conditions are necessary to prove uniqueness and in Section \ref{sec:convergence} we show that the nonlinear Markov chain does not necessarily converge to the unique invariant distribution even for a very simple two-state case. 

\subsection{Nonlinear Markov Chains with an Aggregator} \label{sec:setting}

Let $S$ be a polish space and $\mathcal{B}(S)$ be the Borel $\sigma$-algebra on $S$. We denote by $\mathcal{P}(S)$ the space of all probability measures on the measurable space $(S,\mathcal{P}(S))$. We study 
 the properties of the nonlinear Markov chain $(X_{t})_{t \in \mathbb{N}}$ on $S$  given by
\begin{equation}
X_{t+1} = w(X_{t},H(\mu _{t}), \epsilon _{t+1})
\end{equation}
where $w: S \times \mathcal{H} \times E \rightarrow S$ is a measurable function, $\mu _{t}$ is the law of $X_{t}$, $H: \mathcal{P}(S) \rightarrow \mathbb{R}$ is a measurable function that is called an aggregator, $\mathcal{H} = \{ H(\mu): \mu \in \mathcal{P}(S) \} $ is the image of $H$, and $(\epsilon_{t})_{t \in \mathbb{N}}$ are independent and identically distributed (I.I.D) random variables that take values in a polish space $E$ with a law $\phi$. 


Let $Q$ be the nonlinear Markov kernel that describes the transitions of the nonlinear Markov chain  $(X_{t})_{t \in \mathbb{N}}$, i.e., 
\begin{equation}
    Q(x,H(\mu),B) = \phi (\epsilon \in E : w(x,H(\mu),\epsilon) \in B)
\end{equation}
for all $B \in \mathcal{B}(S)$. A probability measure $\mu \in \mathcal{P}(S)$ is an invariant distribution of $Q$ if $T\mu = \mu$, i.e., $\mu$ is  a fixed point of $T$ where the operator $T: \mathcal{P}(S) \rightarrow \mathcal{P}(S)$ is given by  
$$T\mu(B) = \int _{S} Q(x,H(\mu),B)\mu(dx)$$
for all $B \in \mathcal{B}(S)$.


We are interested in finding conditions that imply that $T$ has a unique fixed point. The operator $T$ is nonlinear and generally not a contraction so standard methods cannot be applied. Instead, we prove uniqueness by leveraging monotonicity conditions over the nonlinear Markov kernel $Q$ that we now describe. 


\subsection{Notations and Definitions} \label{sec:definition} 

We assume throughout the paper that $S$ is endowed with a closed partial order $ \geq $. 
 We say that a function $f :S \rightarrow \mathbb{R}$ is increasing if $f (y) \geq f (x)$ whenever $y \geq x$ and we say that $f$ is strictly increasing if $f(y)>f(x)$ whenever $y>x$. 

The space of probability measures $\mathcal{P} (S)$ is endowed with the weak topology. A sequence of measures $\mu_{n} \in \mathcal{P} (S)$ converges weakly to $\mu \in \mathcal{P} (S)$ if for all bounded and continuous functions $f :S \rightarrow \mathbb{R}$ we have
\begin{equation*}\underset{n \rightarrow \infty }{\lim }\int _{S}f (s) \mu_{n} (d s) =\int _{S}f (s) \mu (d s).
\end{equation*}

Let  $D \subseteq \mathbb{R}^{S}$ where $\mathbb{R}^{S}$ is the set of all functions from $S$ to $\mathbb{R}$. When $\mu _{1}$ and $\mu _{2}$ are probability measures on $(S ,\mathcal{B}(S))$, we write $\mu _{2} \succeq _{D}\mu _{1}$ if \begin{equation*}\int _{S}f(s)\mu _{2}(ds) \geq \int _{S}f(s)\mu _{1}(ds)
\end{equation*}for all Borel measurable functions $f \in D$ such that the integrals exist. 



The binary relation $\succeq _{D}$ is called a stochastic order. When $D$ is the set of all increasing functions on $S$, we write $\mu _{2} \succeq _{SD}\mu _{1}$ and say that $\mu _{2}$ first order stochastically dominates $\mu _{1}$. If $D$ is the set of all convex functions on $S$, we write $\mu _{2} \succeq _{CX}\mu _{1}$ and say that $\mu _{2}$ dominates $\mu _{1}$ in the convex stochastic order. If $D$ is the set of all increasing and convex functions on $S$, we write $\mu _{2} \succeq _{ICX}\mu _{1}$ (see \cite{shaked2007stochastic} for a detailed textbook treatment of stochastic orders). 


To prove that $T$ has a unique fixed point it is required to assume that the linear Markov kernel  $Q(x,H(\mu),\cdot)$ has a unique invariant distribution for every fixed aggregator $H(\mu)$. That is, the operator $M_{H(\mu)} :\mathcal{P} (S) \rightarrow \mathcal{P} (S)$ has a unique fixed point where $M_{H(\mu)}$ is given by
\begin{equation*}M_{H(\mu)} \theta  (B) =\int _{X}Q (x ,H(\mu) ,B) \theta  (d x).
\end{equation*}
Note that when the Markov kernel $Q$ does not depend on the aggregator $H(\mu)$, then the operator $T$ reduces to $M_{H(\mu)}$. Hence, 
if $M_{H(\mu)}$ has more than one invariant distribution, then $Q$ generally has more than one invariant distribution.  Thus, the following property is necessary to prove that $Q$ has at most one invariant distribution. 

\begin{definition} (Property (U)). 
We say that $Q$ satisfies Property (U) if for any $H(\mu) \in \mathcal{H}$, the operator $M_{H(\mu)}$ has a unique fixed point $\mu _{H(\mu)}$. 
\end{definition}


 
A stronger version of Property (U) says that the Markov kernel $M_{H(\mu)}^{n} \theta $ converges weakly to $\mu _{H(\mu)}$ for any probability measure $\theta  \in \mathcal{P} (S)$. 



\begin{definition} \label{def:Xerg} (Property (C)). 
We say that $Q$ satisfies Property (C) 
if $Q$ satisfies Property (U) and  $M_{H(\mu)}^{n} \theta $ converges weakly to $\mu _{H(\mu)}$ for any probability measure $\theta  \in \mathcal{P} (S)$ and any $H(\mu) \in \mathcal{H}$ where $\mu _{H(\mu)}$ is the unique fixed point of $M_{H(\mu)}$. 
\end{definition}
Property (C) can be established using standard results from the theory of Markov chains in general state spaces (see \cite{meyn2012markov}). When the state space $S$ is finite Property (C) can be established by assuming that $M_{H(\mu)}$ is irreducible and aperiodic for every $H(\mu)$ and Property (U) can be established by assuming that $M_{H(\mu)}$ is irreducible for every $H(\mu)$.  

We say that $Q$ is decreasing in $\mu$  with respect to $\succeq _{D}$ if for each $x \in S$, we have $Q (x ,H(\mu_{1}) , \cdot ) \succeq  _{D}Q (x , H(\mu_{2} ), \cdot )$ whenever $H(\mu_{2}) \geq H(\mu_{1})$. Similarly,  $Q$ is increasing in $x$  with respect to $\succeq _{D}$ if for each  $H(\mu) \in \mathcal{H}$, we have $Q (x _{2},H(\mu) , \cdot ) \succeq  _{D}Q (x_{1} ,H( \mu) , \cdot )$ whenever $x_{2} \geq x_{1}$.
The key assumption that implies that the operator $T$ has at most one fixed point relates to the following monotonicity and preservation properties. 
\begin{definition}
Let $D \subseteq \mathbb{R}^{S}$. 

We say that $Q$ is $D$-decreasing if $Q$  is decreasing in $\mu$  with respect to $\succeq _{D}$. 

We say that $Q$ is $D$-preserving if for all  $H(\mu) \in \mathcal{H}$ the function 
\begin{equation*}
    v(x):=\int f (y) Q(x ,H(\mu) ,dy) 
\end{equation*}
is in $D$ whenever $f \in D$. 


\end{definition}

Note that when $D$ is the set of all increasing functions then $\succeq _{D}$  reduces to the standard stochastic dominance order and $Q$ is increasing in $x$  with respect to $\succeq _{D}$ if and only if $Q$ is $D$-preserving (see \cite{shaked2007stochastic}). In the case that $Q$ is increasing in $x$, Property (C) can be established using results from the theory of monotone Markov chains. These results typically require a splitting condition (see \cite{bhattacharya1988asymptotics} and \cite{kamihigashi2014stochastic}) and hold in a wide range of applications.  




We say that $H$ is increasing with respect to $\succeq _{D}$ if $H(\mu_{2}) \geq H(\mu_{1})$ whenever $ \mu_{2} \succeq _{D} \mu_{1}$. 



 
A stochastic order $\succeq_{D}$ is said to be closed with respect to weak convergence if $\mu^{1}_{n} \succeq_{D} \mu^{2}_{n} $ for all $n$, $\mu^{1}_{n}$ converges weakly to $\mu^{1}$, and $\mu^{2}_{n}$ converges weakly to $\mu^{2}$ imply $\mu^{1} \succeq_{D} \mu^{2}$. Many stochastic orders of interest are closed with respect to weak convergence, e.g., the standard stochastic dominance order $\succeq_{SD}$. For a textbook treatment  of the closure properties of stochastic orders see \cite{shaked2007stochastic}.   

We say that $H$ is continuous if  $ \lim _{n \rightarrow \infty} H(\mu_{n}) = H(\mu)$ whenever $\mu_{n}$ converges weakly to $\mu$. We say that $Q$ is continuous if $Q(x_{n},z_{n}, \cdot)$ converges weakly to  $Q(x,z, \cdot )$ whenever $(x_{n},z_{n}) \rightarrow (x,z)$.


Recall that a partially ordered set $(Z , \geq )$ is said to be a lattice if for all $x ,y \in Z$, $\sup \{x ,y\}$ and $\inf \{y ,x\}$ exist in $Z$. $(Z , \geq )$ is a complete lattice if for all non-empty subsets $Z^{ \prime } \subseteq Z$ the elements $\sup Z^{ \prime }$ and $\inf Z^{ \prime }$ exist in $Z$.
 %When $Q$ is increasing in $x$, then the $S$-ergodicity of $Q$ can be established using results from the theory of monotone Markov chains. These results usually require a splitting condition (see \cite{bhattacharya1988asymptotics} and \cite{hopenhayn1992}) that typically holds in applications of interest.


\subsection{Uniqueness Theorem} \label{sec:unique}
We now present conditions that imply that $Q$ has a unique invariant distribution. We first provide conditions that implies that $Q$ has at most one invariant distribution. These conditions are based on monotonicity properties of the nonlinear Markov kernel $Q$. In particular, we show that under Property (C) or Property (U) and additional regularity conditions, when $Q$ is $D$-preserving and $D$-decreasing then $Q$ has at most one invariant distribution.\footnote{A special case of Theorem \ref{Theorem: unique} in the framework of mean field games was derived in \cite{light2022mean} to prove the uniqueness of mean field equilibrium in a subclass of mean field games. }  In Section \ref{sec:necessity} we show that these key order-theoretic conditions are necessary in order to establish uniqueness (see Examples \ref{example:decreasing} and \ref{example:preserving}). 

In applications, verifying whether $Q$ is $D$-preserving and $D$-decreasing is typically straightforward. In Section \ref{sec:applications}, we showcase various applications of Theorem \ref{Theorem: unique}, such as queueing systems and dynamic evolution of wealth distributions. In these cases, the monotonicity properties of $Q$ naturally hold, reflecting underlying behavioral or economic assumptions in the studied dynamic systems.



\begin{theorem} \label{Theorem: unique}
Let $D \subseteq \mathbb{R}^{S}$ be a non-empty set such that $H$ is increasing with respect to $\succeq  _{D}$. Assume that $Q$ is $D$-preserving and $D$-decreasing.

Assume that either of the following conditions hold: 

(i) $Q$ satisfies Property (C) and $\succeq_{D}$ is closed with respect to weak convergence. 

(ii) $Q$ satisfies Property (U) and $(\mathcal{P}(S),\succeq_{D})$ is a complete lattice. 


Then $Q$ has at most one invariant distribution. 
\end{theorem}

Theorem \ref{Theorem: unique} shows that $Q$ has an invariant distribution when such a distribution exists. The 
existence of an invariant distribution follows by standard fixed-point arguments for the case where $S$ is compact and $Q$ is continuous as Proposition \ref{Prop:existence} shows. Extending this existence result for non-compact state spaces remains an interesting research direction. 


\begin{proposition} \label{Prop:existence}
Suppose that $H$ and $Q$ are continuous and that $S$ is compact. Then $Q$ has an invariant distribution. 
\end{proposition}

Condition (ii) of Theorem \ref{Theorem: unique} is particularly useful for the case that $S$ is a finite set or a compact set in $\mathbb{R}$. For example, suppose that $S$ is finite (say $S=\{0,\ldots,N\}$) endowed with the partial order $\succeq  _{SD}$. In this case, it is immediate that $(\mathcal{P}(S),\succeq_{D})$ is a complete lattice with
$$ \sup \{ \mu , \lambda \}  (\{t, \ldots, N \})=  \max \{ \mu  (\{t, \ldots, N \}) ,\lambda  (\{t, \ldots, N \}) \} $$
and 
$$ \inf \{ \mu , \lambda \}  (\{t, \ldots, N \})=  \min \{ \mu  (\{t, \ldots, N \}) ,\lambda  (\{t, \ldots, N \}) \} $$
for all $t =0,\ldots, N$ (recall that $\mu  \succeq  _{SD} \lambda$ if and only if for every upper set $B$ we have $\mu (B) \geq \lambda (B)$ where $B \in \mathcal{B} (S)$ is an upper set if $x_{1} \in B$ and $x_{2} \geq x_{1}$ imply $x_{2} \in B$). In a similar fashion, $(\mathcal{P}(S),\succeq_{D})$ is a complete lattice  when $S$ is a compact set in $\mathbb{R}$. For a discussion of stochastic orders that generate lattices of probability measures see  \cite{muller2006stochastic}. 


In applications, it may seem natural to select $D$ as the set of all increasing functions. 
However, the versatility in choosing the set $D$ in Theorem \ref{Theorem: unique} is fruitful for proving uniqueness for various nonlinear Markov chains. 
 Carefully selecting an appropriate set $D$ can be essential for effectively utilizing Theorem \ref{Theorem: unique}. To demonstrate the importance of this choice, we now present an example of nonlinear auto-regressive Markov chains.

\begin{example} \label{example:flexible} (Flexibility of the set $D$). 
Consider the following nonlinear Markov chain $$X_{t+1} = a X_{t} - H(\mu_{t}) + \epsilon_{t+1}$$ on $\mathbb{R}$ where $0<a<1$, $\epsilon _{t}$ are I.I.D random variables with finite expectations, and $H(\mu_{t}) = \int m(x)  \mu_{t}(dx)$ for some increasing function $m$. Then, assuming that Property (C) holds, we can use Theorem \ref{Theorem: unique} with $D$ as the set of all increasing functions to show that the nonlinear Markov chain $(X_{t})_{t \in \mathbb{N}}$ has at most one invariant distribution. 

%On the other hand, if $m(x) = -x$ so $H(\mu_{t}) = - \int x \mu_{t} (dx)$ then Theorem \ref{Theorem: unique} does not apply with $D$ as the set of all increasing functions. But if we let $D$ to be the set of all convex functions, then $Q$ is $D$-preserving and $D$-decreasing\footnote{To see this, let $f$ be a convex function and note that $ v(x) = \int f(y)Q(x,H(\mu ), dy) = \int f(ax -  H(\mu) + \epsilon )\phi (d\epsilon)$ is convex as a composition of a convex function and an affine function so $Q$ is $D$-preserving. In addition, $Q$ is $D$-decreasing because $\mu_{t}' \succeq _{CX} \mu_{t}$ implies that the expected values of the two distributions are the same, and hence, $H(\mu _{t}) = H(\mu _{t}')$. } so we can use Theorem \ref{Theorem: unique} to establish uniqueness. 

Now consider the nonlinear Markov chain $$(X_{1,t+1},X_{2,t+1}) =  (a X_{1,t} - H(\mu_{t}) + \epsilon_{1,t+1}, k(X_{2,t}) + \epsilon_{2,t+1})$$ on $\mathbb{R}^{2}$ where $0<a<1$, $\epsilon _{1,t} , \epsilon_{2,t}$ are I.I.D random variables with finite expectations, $k$ is a function that is not increasing, and $H(\mu_{t}) : = \int m(x_{1})  \mu_{t}(d(x_{1},x_{2}))$ for some increasing function $m$. Also in this case, we can't use Theorem \ref{Theorem: unique} with $D$ as the set of all increasing functions because $Q$ is not $D$-preserving. However, if we let $D$ to be the set of all the functions that are increasing in the first argument then one can easily see that $Q$ is $D$-preserving and $D$-decreasing.\footnote{Let $f \in \mathbb{R}^{\mathbb{R}^{2} }$ be increasing in the first argument.  Then $ \int f(y_{1},y_{2})Q((x_{1},x_{2}),H(\mu ), dy) = \int f(ax_{1} -  H(\mu) + \epsilon_{1},k(x_{2}) + \epsilon_{2}) \phi (d(\epsilon_{1},\epsilon_{2})) $ is increasing in the first argument so $Q$ is $D$-preserving. It is immediate that $Q$ is $D$-decreasing.}   Hence, a suitable choice of the set $D$ can be crucial for applying Theorem \ref{Theorem: unique}. 
    
\end{example}


\subsection{Necessity of the Monotonicity Conditions that Imply Uniqueness} \label{sec:necessity} In this section we provide simple examples that show that the key conditions that imply that $Q$ has a unique invariant distribution: $Q$ is $D$-preserving and $Q$ is $D$-decreasing are necessary to prove Theorem \ref{Theorem: unique}.  




\begin{example} \label{example:decreasing}  ($Q$ is not $D$-decreasing). Suppose that $S=\{0,1\}$ and $H(\mu) = \mu (\{1\}) $. Assume that $D$ is the set of all increasing functions so $\succeq_{D}$ is the standard stochastic dominance $\succeq_{SD}$ and  $H$ is increasing with respect $\succeq_{SD}$.   

 Consider the nonlinear Markov chain 
\[
Q' = 
        \begin{blockarray}{c@{\hspace{2pt}}rr@{\hspace{3pt}}}
         & 0   & 1   \\
        \begin{block}{r@{\hspace{2pt}}|@{\hspace{2pt}}
    |@{\hspace{2pt}}rr@{\hspace{2pt}}||}
        0 & 1- \min(0.5,\mu (\{1\} )) & \min(0.5,\mu (\{1\})) \\
        1 & 0.5 & 0.5  \\
        \end{block}
    \end{blockarray}
\]
It is easy to see that $ \pi (\{ 1 \}) = 1/2 = \pi(\{0\})$ and $ \pi ' (\{ 1 \}) = 0,  \pi '  (\{ 0 \}) = 1$ are invariant distributions of $Q'$. 
Note that $Q'$ satisfies property (ii) of Theorem 1 and is $D$-preserving. Hence all the conditions of Theorem 1 are satisfied except for the condition that $Q'$ is $D$-decreasing and $Q'$ has two invariant distributions. 

\end{example}

\begin{example} \label{example:preserving}
 ($Q$ is not $D$-preserving). Suppose that $S=\{0,1,2\}$ and $H(\mu) = \mu (\{1\}) + \mu (\{2\}) $. Assume that $D$ is the set of all increasing functions so $\succeq_{D}$ is the standard stochastic dominance $\succeq_{SD}$ and  $H$ is increasing with respect $\succeq_{SD}$.   


Consider the nonlinear Markov chain  
\[
Q'' = 
        \begin{blockarray}{c@{\hspace{1pt}}rrr@{\hspace{3pt}}}
         & 0   & 1   & 2 \\
        \begin{block}{r@{\hspace{1pt}}|@{\hspace{1pt}}
    |@{\hspace{1pt}}rrr@{\hspace{1pt}}|@{\hspace{1pt}}|}
        0 & 1/3 & 1/3 & 1/3 \\
        1 & 0 & H(\mu) & 1 - H(\mu) \\
        2 & H(\mu)  & 0   & 1-H(\mu)   \\
        \end{block}
    \end{blockarray}
\]

The distributions $ \pi (\{ 0 \}) =  \pi (\{ 1 \}) =  \pi (\{ 2 \}) = 1/3$ and $ \pi' (\{ 0 \}) = 0,  \pi' (\{ 1 \}) = 1,  \pi' (\{ 2 \})=0 $  are invariant distributions of $Q''$. 
The Markov chain $Q''$ satisfies property (ii) of Theorem 1 and is $D$-decreasing. Hence all the conditions of Theorem 1 are satisfied except to the condition that $Q''$ is $D$-preserving\footnote{ Note that $Q$ is $D$-preserving if and only if $Q$ is increasing in $x$ for all $H$. $Q''$ is not increasing in $x$ as $Q''(1,H(\mu) , \{1,2\} ) > Q''(2,H(\mu) , \{1,2\} )$ for any $H(\mu) >0$.} and $Q''$ has two invariant distributions. 

\end{example}


%\begin{example}
%Consider a Markov chain on  $\{0,1,2,\ldots,\}$ such that $X_{t+1}= X_{t} + 1$ with probability $\min ( \max (q_{1},\mathbb{E}(X_{t})) , q_{2} ) $ and $X_{t+1}= \max \{ X_{t} - 1 , 0 \}$ with probability $1 - \min ( \max (q_{1},\mathbb{E}(X_{t})) , q_{2} ) $  where $ q_{1} < q_{2} < 1/2$. 
%\end{example}



\subsection{Non-Convergence to the Invariant Distribution} \label{sec:convergence} Theorem \ref{Theorem: unique} and Proposition \ref{Prop:existence} provide sufficient conditions for the uniqueness of an invariant distribution for the nonlinear Markov kernel $Q$. However, these results do not provide conditions under which the sequence of measures $\mu_{t}$  converges weakly to the unique invariant distribution of $Q$.  Unfortunately, the following example shows that even in a very simple case, the monotonicity conditions that imply uniqueness do not imply convergence.  This is in sharp contrast with the contraction approach to prove the  uniqueness of an invariant distribution that guarantees convergence (e.g., \cite{butkovsky2014ergodic}). This example illustrates the restricted applicability of any uniqueness result that depends on the ergodicity of chains in the context of nonlinear Markov chains. 


\begin{example} \label{Example:convergence} ($\mu_{t}$ does not converge to the unique invariant distribution).
Suppose that $S=\{0,1\}$ and $H(\mu) = \mu (\{1\}) $. Assume that $D$ is the set of all increasing functions so $\succeq_{D}$ is the standard stochastic dominance $\succeq_{SD}$ and  $H$ is increasing with respect $\succeq_{SD}$.    Consider the nonlinear Markov chain 
\[
Q = 
        \begin{blockarray}{c@{\hspace{2pt}}rr@{\hspace{3pt}}}
         & 0   & 1   \\
        \begin{block}{r@{\hspace{2pt}}|@{\hspace{2pt}}
    |@{\hspace{2pt}}rr@{\hspace{2pt}}||}
        0 & \mu (\{1\} ) & \mu (\{0\}) \\
        1 & \mu (\{1\}) & \mu (\{0\})  \\
        \end{block}
    \end{blockarray}
\]
It is easy to see that $ \pi (\{ 1 \}) = 1/2 = \pi(\{0\})$ is the unique invariant distributions of $Q$ and $Q$ 
 satisfies all the conditions of Theorem 1. Note that for any initial distribution $\mu_{1} (\{1\} )  = \gamma $ and $\mu_{1} (\{ 0 \}) = 1-\gamma$ with $\gamma \neq 1/2$, $\mu_{t}$ does not converge to $\pi$ as $\mu_{t} (\{1\} )  = \gamma $ and $\mu_{t} (\{ 0 \}) = 1-\gamma$ for an odd $t$ and $\mu_{t} (\{1\} )  = 1- \gamma $ and $\mu_{t} (\{ 0 \}) = \gamma$ for an even $t$. 
\end{example}




\section{Applications} \label{sec:applications}

In this section we present our applications. In Section 3.1 we study the invariant distribution of a G/G/1 queueing system where arrivals depend on the expected waiting times. In Section 3.2 we study non-linear equations that do not satisfy contraction properties and have a unique solution. In Section 3.3 we study the invariant distribution of wealth distributions in dynamic economies where the rate of returns depend on the aggregate savings in the economy. 

\subsection{Strategic Behavior in Queuing Systems} 
 A considerable body of literature exists on strategic behavior in queueing systems. Within this domain, the inter-arrival times often depend on the queue length or expected waiting time, as agents, being strategic, can opt not to join the queue if they foresee an extended waiting period  \citep{hassin2003queue}.  Typically, queueing systems are examined in the steady state, making it essential to investigate the existence of a unique steady state generated by the system to obtain robust comparative statics results. We will now demonstrate how Theorem \ref{Theorem: unique} can be utilized to establish that there is, at most, one invariant distribution for the waiting time distribution within a general $G/G/1$ strategic queueing system, wherein the inter-arrival times are contingent on the expected waiting time.

Consider a $G/G/1$ queue where the the time between the $t$th and $t+1$th arrivals is given by the random variable $T_{t}$ and the service time of the $t$ customer is given by the random variable $S_{t}$. Because agents are strategic they are less likely to join the queue when the waiting time is longer. We assume that the time between arrivals depends on the expected waiting time and write $T_{t}(\mathbb{E}(X_{t}) )$ where $X_{t}$ is the waiting time of the $t$th customer to describe this dependence. When the expected waiting time is higher then the number of agents that join the queue is lower. We capture this dependence by assuming that  $T_{t}(\mathbb{E}(X_{t}) ) \succeq_{SD} T_{t}(\mathbb{E}(X'_{t}) )$ whenever $\mathbb{E}(X_{t}) \geq \mathbb{E}(X'_{t})$. That is, the time between arrivals is stochastically higher when the expected waiting time is higher. The expected waiting times experienced by customers in the queue evolve by the following nonlinear Markov chain: 
$$X_{t+1} = \max (0, X_{t} + S_{t} - T_{t} (\mathbb{E}(X_{t}) ).$$ 


It is easy to see that $Q$ is $D$-preserving and $D$-decreasing with $H(\mu_{t}) =\mathbb{E}(X_{t})  $ when $D$ is the set of all increasing functions. Under the usual  assumption that the queue does not explode a standard argument from the Markov chain literature (see \cite{meyn2012markov}) can be used to show that Property (C) is satisfied. Hence, Theorem \ref{Theorem: unique}  implies that there exists at most one waiting time equilibrium steady state distribution. As a particular example for this result, we study analytically an M/G/1 queuing system where the arrival rate depends on the expected waiting time. 


\begin{example} ($M/G/1$ queue). 
Consider an $M/G/1$ queue so the time between arrivals has an exponential distribution with parameter $\lambda$ that is correlated with the expected waiting time. The service time is given by a general random variable $S$. Suppose that the mean interarrival time equals the expected waiting time so $\lambda$ equals $1$ over the expected waiting time.\footnote{Note that we can apply Theorem \ref{Theorem: unique} under any $\lambda$ that is decreasing with respect to the expected waiting time.}   From the Pollaczek-Khinchin formula the stationary expected waiting time  is given by $\lambda\mathbb{E}(S^{2})/(2(1-\lambda\mathbb{E}(S))$. Hence, we must have $1/\lambda = \lambda\mathbb{E}(S^{2})/(2(1-\lambda\mathbb{E}(S))$ which yields 
$$ \lambda = \frac{\sqrt{(\mathbb{E}(S))^{2}+2\mathbb{E}(S^{2})} - \mathbb{E}(S)}{\mathbb{E}(S^{2})}$$
and is valid when $\lambda \mathbb{E}(S) < 1$. For $M/M/1$ queue $S$ is an exponential random variable with a parameter $\mu$ so $\mathbb{E}(S) = 1/\mu$ and $\mathbb{E}(S^{2}) = 2/\mu^{2}$ and we get $\lambda = (\sqrt{5}-1)\mu / 2 $ so $\lambda < \mu$.  



\end{example}


\subsection{Nonlinear Equations}


The study of nonlinear systems of equations in $\mathbb{R}^{n}$ has long been a significant area of interest in mathematics and its applications. Finding conditions that ensure a unique solution to such systems is crucial as it offers insights into the properties and stability of solutions, which in turn, have far-reaching implications across various fields, including operations, engineering, economics, and optimization \citep{ortega2000iterative}. 
It is generally uncommon to identify a comprehensive set of conditions that guarantee a unique global solution for a system of nonlinear equations in $\mathbb{R}^{n}$ that do not satisfy contraction properties. We showcase the application of Theorem \ref{Theorem: unique} to determine conditions that ensure a unique solution for a specific class of nonlinear equations, which we define subsequently. These conditions are based  on monotonicity concerning the majorization order. 




Let $\Delta_{n} = \{ \boldsymbol{x} \in \mathbb{R}^{n}: \sum_{i=1}^{n}  x_{i} = 1, x_{i} \geq 0 \text{ }\forall i \} $ be the $n$-dimensional simplex.  
Consider a stochastic matrix $\boldsymbol{P} (G(\boldsymbol{x})) \in \mathbb{R}^{n\times n}$ that is parameterized by $G(\boldsymbol{x})$ where  $G:\Delta _{n} \rightarrow A$  and $A \subseteq \mathbb{R}$ is the image of $G$, i.e., $P_{ij} (G(\boldsymbol{x})) \geq 0$, and $\sum _{j=1}^{n} P_{ij} (G(\boldsymbol{x})) = 1$ for all $G(\boldsymbol{x}) \in A$.



For $\boldsymbol{x},\boldsymbol{y} \in \mathbb{R}^{n}$ write $\boldsymbol{x} \geq _{m} \boldsymbol{y}$ if $ \sum _{j=k}^{n} x_{j} \geq \sum _{j=k}^{n} y_{j}$ for all $1 \leq k \leq n$ and $\sum_{j=1}^{n} x_{j} = \sum _{j=1}^{n} y_{j}$ (the order $\geq _{m}$ is sometimes called majorization between vectors in $\mathbb{R}^{n}$). We denote by $\boldsymbol{P}_{i}(G(\boldsymbol{x}))$ the $i$th row of the matrix $\boldsymbol{P}$. 


The following Corollary follows immediately from Theorem \ref{Theorem: unique} and Proposition \ref{Prop:existence} applied for first order stochastic dominance. 

\begin{corollary} \label{Coro:non-linear}
Let $G:\Delta _{n} \rightarrow A$ be a continuous function that  is increasing with respect to $ \geq _{m}$. The nonlinear system of equations $\boldsymbol{x} = \boldsymbol{x} \boldsymbol{P} (G(\boldsymbol{x}))$ on $\Delta_{n}$ where $\boldsymbol{P} (G(\boldsymbol{x}))$ is a stochastic matrix that is parameterized by $G(\boldsymbol{x})$ has a unique solution if the following three conditions hold: 


(i) For all $G(\boldsymbol{x}) \in A$, $i \geq i'$, we have  $\boldsymbol{P}_{i}(G(\boldsymbol{x})) \geq _{m} \boldsymbol{P}_{i'}(G(\boldsymbol{x}))$.

(ii) For all $1 \leq  i \leq n$, $G(\boldsymbol{x}') \geq G(\boldsymbol{x})$, we have  $\boldsymbol{P}_{i}(G(\boldsymbol{x})) \geq _{m} \boldsymbol{P}_{i}(G(\boldsymbol{x}'))$.

%and all $1 \leq k \leq n$ we have $\sum _{j=k}^{n} P_{ij}(G(\boldsymbol{x})) \geq \sum _{j=k}^{n} P_{ij}(G(\boldsymbol{x}'))$.

(iii) For all $a \in A$, the linear system of equations $\boldsymbol{x} = \boldsymbol{x} \boldsymbol{P} (a)$ for $\boldsymbol{x} \in \Delta_{n}$ has a unique solution. 


\end{corollary}

Corollary \ref{Coro:non-linear} leverages Theorem \ref{Theorem: unique} to show that a class  of nonlinear equations have a unique solution. This Corollary can be used as a tool to generate nonlinear systems of equations that are known to have a unique solution. Theorem \ref{Theorem: unique} can also be used to show the uniqueness of solutions for nonlinear equations in many other different ways  than Corollary \ref{Coro:non-linear}, e.g., see Example \ref{example:flexible}).



%Theorem \ref{Theorem: unique} can be further used as a powerful tool to provide answers for questions in probability that involves nonlinear equations. We provide a simple example to illustrate this: is there $(u,\sigma^{2})$ with $u \neq 0$ such that $u= \mathbb{E} N(u,\sigma^{2} ) = - \mathbb{E} (N(u,\sigma^{2} )) ^{k}  $  for an odd number $k$ where $N(u , \sigma^{2})$ is the normal random variable with mean $u$ and variance $\sigma^{2}$? The answer is intuitively negative as the odd moment of the normal distribution is intuitively positive when the mean is positive as the distriubtion is symmetric.   We provide a negative answer to this question with a simple argument using Theorem \ref{Theorem: unique}. While this is a special illustrative example, we believe that the technique to answer this question can be applied to ask similar questions in probability theory. 



%\begin{example} \label{Example:Normal-distributions} (Normal distributions.)
 %   Let $N(u , \sigma^{2})$ be normal random variable with mean $u$ and variance $\sigma^{2}$. From symmetry $\mathbb{E} N(0,\sigma^{2} ) = \mathbb{E} (N(0,\sigma^{2} )) ^{k} = 0 $ for every odd number $k$. We will use Theorem \ref{Theorem: unique} to show that  $u = \mathbb{E} N(u,\sigma^{2} ) \neq - \mathbb{E} (N(u,\sigma^{2} )) ^{k}  $ whenever $k$ is an odd number and $u \neq 0$. 

%Assume in contraction that there exists an odd number $k$ and $u \neq 0$ such that $u= \mathbb{E} N(u,\sigma^{2} ) = - \mathbb{E} (N(u,\sigma^{2} )) ^{k}  $. Consider the nonlinear Markov chain $X_{t} = -H(\mu_{t}) + N(0,\sigma^{2})$ on $\mathbb{R}$ where $H(\mu_{t}) = \int x^{k} \mu_{t}(dx) $. Then it is immediate from Theorem \ref{Theorem: unique} with $D$ as the set of all increasing functions that $X_{t}$ has at most one invariant distribution. Clearly the distribution of $N(0,\sigma^{2})$ is one invariant distribution of $X_{t}$. We claim that the distribution $\mu$ of $N(u,\sigma^{2})$ is also an invariant distribution of $X_{t}$ which contradicts Theorem \ref{Theorem: unique}. To see this, note that $ - H(\mu) + N(0,\sigma^{2}) = N(- \mathbb{E} (N(u,\sigma^{2} )) ^{k},\sigma ^{2} ) = N(u, \sigma^{2} )$ by the contradiction assumption. 
    
%\end{example}






\subsection{Wealth Distributions}


In heterogeneous-agents macroeconomic models (see \cite{stachurski2009economic} for a recent textbook treatment of economic dynamic models), agents determine their consumption, savings, and allocation of savings across financial assets based on their current wealth level in each period. 


An extensive literature exists on these models, specifically focusing on the analysis of stationary equilibria and the associated stationary wealth distributions. Despite the vast body of research, the conditions ensuring the uniqueness of equilibrium are restricted to a handful of special cases.\footnote{For instance, see \cite{light2020uniqueness, light2021general, achdou2022income}. } In this section, we employ Theorem \ref{Theorem: unique} to demonstrate that there can be, at most, one stationary wealth distribution equilibrium for a typical progression of wealth dynamics in these models, given that agents' savings increase with the rate of returns and their current wealth levels. We proceed to outline the model.


There are $n$ random variables $R_{1},\ldots,R_{n}$ that represents returns from different financial assets $i=1,\ldots,n$. Each agent has a policy $\boldsymbol{g} = (g_{1},\ldots,g_{n})$ that determines the amount of wealth the agent allocates to asset $i$ when it has a wealth level $x$, i.e., $g_{i}(R_{1},\ldots,R_{n},x)$ is the amount that an agent with wealth $x$ allocates to asset $i$ when the returns are $(R_{1},\ldots,R_{n})$.\footnote{We assume for simplicity that the agents policy depends on their current  wealth only. All the results in this section can be easily extended to the case when each agent uses a different policy that depends on the agent's specific features such as preferences or behavioral biases.} In applications, the agent's policy is typically derived from a consumption-saving dynamic programming problem.  In our analysis, we assume a general policy function that can be deduced from rational agents, behavioral biases  \citep{acemoglu2018equilibrium}, or learning algorithms. 



The return $R_{i}$ of asset $i$ is parameterized by an aggregator $H(\mu)$ that depends on the wealth distribution $\mu$ and is increasing with respect to first order stochastic dominance (typically $H(\mu)$ is the expected value or the total savings in applications). The agent's wealth evolution is described by the following nonlinear Markov chain:
$$ X_{t+1} = \sum _{i=1}^{n} g_{i}(R_{1}(H(\mu _{t} )),\ldots , R_{n} (H(\mu_{t}) ) ,X_{t} )R_{i}(H(\mu _{t}) ) + Y _{t+1} $$
 where $X_{t}$ is the current wealth the agent has, $Y_{t}$ is the random income of the agent in period $t$ and $\mu_{t}$ is the wealth distribution in period $t$. Hence, if an agent has a current wealth of  $X$, the agent invests $g_{i}$ in asset $i$ then the next period's wealth is the sum of investments times the returns plus the next period's income. A stationary equilibrium is defined by an invariant distribution of the nonlinear Markov chain $X$ with the interpretation that this distribution represents the long run equilibrium wealth distribution of the economy \citep{aiyagari1994}

 Under standard assumptions on the policy function, Property (C) holds, the policy function is increasing in the current wealth, i.e., savings increase when the agent's wealth is higher, and the returns are decreasing in $H(\mu)$ with respect to first order stochastic dominance, i.e., the returns are (stochastically) lower when the total savings are higher. Hence, from Theorem \ref{Theorem: unique} with the standard first order stochastic dominance, there is at most one stationary wealth distribution equilibrium if the total amount of savings $\sum g_{i}$ is decreasing in $H(\mu)$ which is equivalent to the property that total savings are  increasing in the rate of returns (in the economics literature, this property means that the substitution effect dominates the income effect). Hence, the key condition that implies the uniqueness of a stationary wealth distribution  equilibrium is that  savings increase with the rate of returns (a special case of this result with one financial asset and rational agents is studied in \cite{light2020uniqueness}). 


\section{Conclusions} 

This paper studies discrete-time nonlinear Markov chains with an aggregator and establishes  conditions that imply the uniqueness of an invariant distribution for these chains. Unlike traditional approaches, our conditions do not rely on contraction properties of the chains, but rather on flexible monotonicity properties. 
 We demonstrate, using simple examples, that the monotonicity conditions are necessary to prove the uniqueness of an invariant distribution. We applied our results to strategic queueing systems, non-linear equations, and the evolution of wealth distributions in heterogeneous-agents dynamic economies. We believe that our results can be applied to other models where the flexible monotonicity conditions we provide hold naturally.




There are  remaining important open questions 
concerning nonlinear Markov chains with an aggregator. For example, to prove the existence of an invariant distribution we assumed that the state space is compact which does not hold for many applications of interest. Furthermore, we showed that even in a simple chain with two states, the chain does not converge to the unique invariant distribution. Developing alternative procedures or algorithms that guarantee convergence to the unique invariant distribution is essential for computational approaches that are employed in practical applications. 


\newpage


\section{Appendix} 

We will use the following Proposition to prove Theorem \ref{Theorem: unique} (see Corollary 2.5.2 in \cite{topkis2011supermodularity}). 

\begin{proposition}
\label{Topkis Fixed point}Suppose that $Z$ is a nonempty complete lattice, $E$ is a partially ordered set, and $f$ is an increasing function from $Z \times E$ into $Z$. Then the greatest and least fixed points 
of $f (z ,e)$ exist and are increasing in $e$ on $E$. 
\end{proposition}



\begin{proof}[Proof of Theorem \ref{Theorem: unique}]
Let $\theta _{1} ,\theta _{2} \in \mathcal{P} (S)$ and assume that $\theta _{1}  \succeq  _{D}\theta _{2}$. 
Let $\mu_{1} ,\mu_{2}$ be two invariant distributions of $Q$. Assume without loss of generality that $H( \mu_{2}) \geq H( \mu_{1})$ and let $f:S \rightarrow \mathbb{R}$ be a function such that $f \in D$. We have 
\begin{align*}\int _{S}  f(x) M_{H( \mu_{2})} \theta _{2} (dx)  &  =\int _{S} \int_{S} f (y) Q(x ,H(\mu_{2}) ,dy)   \theta _{2} (d x) \\
 &  \leq  \int _{S} \int_{S} f (y) Q(x ,H(\mu_{1}) ,dy)   \theta _{2} (d x) \\
 &  \leq \int _{S} \int_{S} f (y) Q(x ,H(\mu_{1}) ,dy)   \theta _{1} (d x) \\
 & = \int _{S}  f(x) M_{H( \mu_{1})} \theta _{1} (dx)
 \end{align*}

 Thus, $M_{H(\mu_{1})} \theta _{1}  \succeq  _{D}M_{H(\mu_{2})} \theta _{2}$. The first inequality follows from the fact that $Q$ is $D$-decreasing. The second inequality follows from the facts that $\theta _{1}  \succeq  _{D}\theta _{2}$ and $Q$ is $D$-preserving. 
We conclude that $M_{H(\mu_{1})}^{n} \theta _{1}  \succeq  _{D}M_{H(\mu_{2})}^{n} \theta _{2}$ for all $n \in \mathbb{N}$. 

Assume that condition (i) of the theorem holds. 
The fact that $Q$ satisfies Property (C) implies that $M_{H(\mu_{i})}^{n} \theta _{i}$ converges weakly to the unique fixed point of $M_{H(\mu_{i})}$ which is given by $\mu _{H(\mu_{i})}$ for $i=1,2$. Because $\mu_{1}$ and $\mu_{2}$ are invariant distributions of $Q$ we have  $\mu _{H(\mu_{i})} =\mu_{i}$ for $i=1,2$. Because $ \succeq  _{D}$ is closed with respect to weak convergence,  we have $\mu_{1} \succeq  _{D} \mu_{2}$. Using the fact that $H$ is increasing with respect to $\succeq  _{D} $ implies $H(\mu_{1}) \geq H(\mu_{2})$. 

We conclude that if $\mu_{1}$ and $\mu_{2}$ are invariant distributions of $Q$ then $H(\mu_{1}) = H(\mu_{2})$. Thus, $Q (x ,H(\mu_{1}) ,B) =Q (x,  H(\mu_{2}) ,B)$ for all $x \in S$ and $B \in \mathcal{B} (S)$. Because $Q$ satisfies assumption (U) the operators $M_{H(\mu_{1})}$ and $M_{H(\mu_{2})}$ have unique fixed points. Thus, $\mu _{H(\mu_{1})} = \mu _{H(\mu_{2})}$, i.e., $\mu_{1} = \mu_{2}$. 
We conclude that if an invariant distribution of $Q$ exists, it is unique. 

Now assume that condition (ii) of the theorem holds. Define the order $\geq '$ on $\mathbb{R}$ by $x \geq  'y$ whenever $y \geq  x$.   Under this assumption, the arguments above imply that 
the operator $M_{H(\mu)}$ is increasing from $\mathcal{P}(S) \times \mathcal{H}$ to $\mathcal{P}(S)$ on the complete lattice $( \mathcal{P}(S),\succeq  _{D})$ when $\mathcal{H}$ is endowed with $\geq '$. 
Then by applying Proposition \ref{Topkis Fixed point} to the increasing operator $M$  we have $\mu _{H(\mu_{1})} \succeq _{D} \mu _{H(\mu_{2})}$, i.e., $\mu_{1} \succeq  _{D} \mu_{2}$. Now we can use the same arguments as the arguments for the case that condition (i) holds to show that if an invariant distribution of $Q$ exists, it is unique. 
\end{proof}


In order to establish the existence of an invariant distribution we will use chauder-Tychonoff's following  fixed-point theorem (see Corollary 17.56 in \cite{aliprantis2006infinite}).

\begin{proposition}
(Schauder-Tychonoff) Let $K$ be a nonempty, compact, convex subset of a locally convex Hausdorff space, and let $f :K \rightarrow K$ be a continuous function. Then the set of fixed points of $f$ is compact and nonempty. 
\end{proposition}

\begin{proof}[Proof of Proposition \ref{Prop:existence}]
  Because $S$ is compact $\mathcal{P} (S)$ is (weakly) compact  (see \cite{aliprantis2006infinite}).
Clearly $\mathcal{P} (S)$ is convex. $\mathcal{P} (S)$ endowed with the weak topology is a locally convex Hausdorff space. Thus, if $T $ is continuous, we can apply Schauder-Tychonoff's fixed point theorem to conclude that $T $ has a fixed point. 

To show that $T$ is continuous, take a sequence of measures $\{ \mu_{n} \}$ and assume that it converges weakly to $\mu$.  

Let $f :X \rightarrow \mathbb{R}$ be a continuous and bounded function. Because $Q$ and $H$ are continuous we have $\lim _{n \rightarrow \infty} \int_{S} f(y) Q(x_{n},H(\mu_{n}),dy) = \int_{S} f(y) Q(x,H(\mu),dy) $ whenever $x_{n} \rightarrow x$. Define $m_{n}(x) : = \int_{S} f(y) Q(x,H(\mu_{n}),dy) $. Then $m_{n}(x)$ is a uniformly bounded sequence of functions such that $m_{n}(x_{n}) \rightarrow m(x)$ whenever $x_{n} \rightarrow x$. Thus, by Lebesgue's Convergence Theorem for varying measures (see Theorem 3.5 in \cite{serfozo1982convergence} and Section 5 in \cite{feinberg2020fatou}) we have $\lim _{n \rightarrow \infty} \int m_{n}(x) \mu_{n}(dx) = \int m(x) \mu (dx)$. Hence,
\begin{align*}\underset{n \rightarrow \infty }{\lim }\int _{X}f (x) T  \mu_{n} (d x) &  =\underset{n \rightarrow \infty }{\lim }\int _{S} \int_{S} f(y) Q(x,H(\mu_{n}),dy) \mu_{n} (d x) \\
 &  =\int _{S} \int_{S} f(y) Q(x,H(\mu),dy) \mu (d x) \\
 &  =\int _{X}f (x) T \mu(dx) .\end{align*}
 Thus, $T\mu_{n}$ converges weakly to $T \mu$. We conclude that $T$ is continuous. Thus, by the Schauder-Tychonoff's fixed point theorem, $T $ has a fixed point. 
\end{proof}








\bibliographystyle{ecta}
\bibliography{unique}







\end{document}