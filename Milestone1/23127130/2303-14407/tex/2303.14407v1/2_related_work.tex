   \begin{figure*}[t]
    	\centering
    	\subfloat[]{\includegraphics[width=.20\linewidth]{./ffhq.pdf}}\hspace{1pt}
    	\subfloat[]{\includegraphics[width=.20\linewidth]{./rebalanced-ffhq.pdf}}\hspace{3pt}
    	\subfloat[]{\includegraphics[width=.20\linewidth]{./lpff.pdf}}\hspace{3pt}
    \subfloat[]{\includegraphics[width=.20\linewidth]{./rebalanced-flickr-ffhq-fixed.pdf}}
    
    	\caption{
    	(a) \textit{FFHQ}. (b) \textit{FFHQ-rebal}. (c) \textit{FFHQ+LPFF}. (d) \textit{FFHQ+LPFF-rebal}.
     {The term ``duplicate'' refers to the number of repetitions in data resampling.} }
     \vspace{-5pt}
    	\label{fig:data_distribution}
    \end{figure*}
    
\section{Related Work}
\label{sec:related_work}
    \paragraph{2D Face Generators.}
    Since Goodfellow first proposed the generative adversarial networks (GANs) in 2014  \cite{DBLP:conf/nips/GoodfellowPMXWOCB14}, a growing number of distinct GANs model designs \cite{DBLP:journals/corr/RadfordMC15,DBLP:conf/nips/GulrajaniAADC17,DBLP:conf/iclr/BrockDS19,DBLP:conf/iclr/KarrasALL18} have been developed to
    produce more impressive performance on realistic image synthesis. 
    %
    Among these GANs models, StyleGAN \cite{DBLP:conf/cvpr/KarrasLA19,DBLP:conf/cvpr/KarrasLAHLA20,DBLP:conf/nips/KarrasAHLLA20,DBLP:conf/nips/KarrasALHHLA21} is regarded as the most cutting-edge generator of high-quality images. For face portrait images, StyleGAN provides not only realistic image generation but also implicit semantic features in latent space, which are
    beneficial for many downstream computer vision applications \cite{DBLP:journals/tog/AbdalZMW21,DBLP:journals/tog/ChenLLRLF021,DBLP:conf/iccv/PatashnikWSCL21}.
    %
    However, the face StyleGAN is trained on a pose-imbalanced face dataset, \textit{FFHQ}. StyleGAN inherits the pose bias from \textit{FFHQ}, resulting in artifacts and distortions when projecting and editing large-pose portraits. This issue is especially noticeable in downstream practical applications because in-the-wild photographs are not always forward-looking.
    
    \paragraph{3D-aware Face Generators.}
    2D generators have been expanded to support 3D multi-view rendering.    
    Early methods combined voxel rendering \cite{DBLP:conf/nips/Nguyen-PhuocRMY20,DBLP:conf/iccv/HenzlerM019,DBLP:conf/nips/ZhuZZ00TF18} or NeRF rendering \cite{DBLP:conf/nips/SchwarzLN020,DBLP:conf/iclr/GuL0T22,DBLP:conf/cvpr/ChanMK0W21} with generators to support view-consistent image synthesis. 
    However, those methods have a high cost of calculation, which limits the resolution of the output.
    %
    Later, a number of studies suggested an additional super-resolution network to enhance image quality without adding too much computing load \cite{Chan_2022_CVPR,DBLP:conf/siggraph/TanFMOTPTTZ22,DBLP:journals/corr/abs-2112-11427,DBLP:conf/cvpr/XueLSL22}. 
    %
    Researchers also suggested an effective optimization strategy \cite{DBLP:journals/corr/abs-2206-10535} to directly output high-resolution results without any super-resolution module.
   %
    These techniques not only produce view-consistent results, but also learn, represent, and generate face geometry in a generative manner.
    %
    {Several methods \cite{DBLP:journals/corr/abs-2205-15517,nerffaceediting} achieve semantic attribute editing and geometry-appearance disentanglement in view-consistent image synthesis through the integration of semantic masks into 3D-aware generators.}
    %
    However, for human face training, they rely heavily on 2D image collections (\textit{FFHQ}). Because of the pose imbalance in the training dataset, incorrect facial geometry may arise in the final results, which negatively impacts the performance of downstream applications \cite{DBLP:journals/corr/abs-2205-15517,DBLP:journals/corr/abs-2203-13441,DBLP:conf/wacv/KoCCRK23,xie2022high,nerffaceediting,DBLP:conf/siggrapha/JinRKBC22,DBLP:journals/corr/abs-2301-02700,DBLP:journals/corr/abs-2211-16927}.
    Researchers also try to eliminate the dependency for 3D pose priors \cite{shi2023pof3d} or resample the dataset to increase the density of extremely limited large-pose data \cite{Chan_2022_CVPR}. However, both of them cannot address the root causes.
    
    
    
    
    
    
   

    \paragraph{Face Image Datasets.}
     Numerous studies have noted the pose imbalance in current face image datasets.
    %
     300W-LP \cite{DBLP:conf/cvpr/ZhuLLSL16} is a dataset consisting 
     of 61,225 images across large poses, but all the images {are artificially synthesized by face profiling}.
     %
     AFLW \cite{DBLP:conf/iccvw/KostingerWRB11} contains 21,080 face images with large-pose variations, LS3D-W \cite{DBLP:conf/iccv/BulatT17} contains $\sim$230,000 images from a combination of 300-W test set \cite{DBLP:conf/cvpr/SagonasTZP13}, 300-VW \cite{DBLP:conf/iccvw/ShenZCKTP15}, Menpo \cite{DBLP:conf/cvpr/ZafeiriouTCDS17}, and AFLW2000-3D \cite{DBLP:conf/cvpr/ZhuLLSL16}. But most images in AFLW and LS3D-W are at low resolution.
     %
     {There are several 3D face datasets \cite{DBLP:conf/cvpr/Yang0WHSYC20,wuu2022multiface,DBLP:journals/corr/abs-1904-00168} that contain high-quality multi-view face images mainly {for 3D face reconstruction}}. However,
     %  
    {these datasets have limited variety
    \cite{DBLP:conf/cvpr/Yang0WHSYC20}, or are low-resolution \cite{DBLP:conf/iccvw/KostingerWRB11,DBLP:conf/iccv/BulatT17}, or are synthesized artificially \cite{DBLP:conf/cvpr/ZhuLLSL16}. In contrast, our dataset consists of high-resolution real images collected from in-the-wild photographs.}
