\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

\usepackage{booktabs}
\usepackage{multirow}
\usepackage{float}
\usepackage{subfig}
% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

 \iccvfinalcopy % *** Uncomment this line for the final submission


\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ificcvfinal\pagestyle{empty}\fi


\newcommand{\hb}[1]{{\color{cyan}            {#1}}}
\newcommand{\hbc}[1]{{\color{cyan}            {[HB: #1]}}}

\usepackage{color}
\definecolor{applegreen}{rgb}{0.55, 0.71, 0.0}
\newcommand{\onethousand}[1]{{\color{applegreen}#1}}
\newcommand{\onethousandc}[1]{{\color{magenta}   {[onethousand: #1]}}}

\begin{document}

%%%%%%%%% TITLE
\title{LPFF: A Portrait Dataset for Face Generators Across Large Poses}

\author{Yiqian Wu$^{1,2}$\qquad Jing Zhang$^{1,2}$\qquad Hongbo Fu$^{3}$\qquad Xiaogang Jin$^{1,2}$\thanks{Corresponding author.} \\
$^1$State Key Lab of CAD\&CG, Zhejiang University \\
$^2$ZJU-Tencent Game and Intelligent Graphics Innovation Technology Joint Lab\\
$^3$City University of Hong Kong \\
{\tt\small onethousand@zju.edu.cn,jing\_z99@163.com,hongbofu@cityu.edu.hk,jin@cad.zju.edu.cn}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
}

% \author{Yiqian Wu$^{1,2}$\qquad Jing Zhang$^{1,2}$\qquad Hongbo Fu$^{3}$\qquad Xiaogang Jin$^{1,2}$\thanks{Corresponding author.} \\
% $^1$State Key Lab of CAD\&CG, Zhejiang University \\
% $^2$ZJU-Tencent Game and Intelligent Graphics Innovation Technology Joint Lab\\
% $^3$School of Creative Media, City Univ. of Hong Kong \\

% {\tt\small onethousand@zju.edu.cn,jing\_z99@163.com,hongbofu@cityu.edu.hk,jin@cad.zju.edu.cn}

% }

\maketitle
% Remove page # from the first page of camera-ready.
\ificcvfinal\thispagestyle{empty}\fi


%%%%%%%%% ABSTRACT
\begin{abstract}
The creation of 2D realistic facial images and 3D face shapes using generative networks has been a hot topic in recent years. Existing face generators exhibit exceptional performance on faces in small to medium poses (with respect to frontal faces) but struggle to produce realistic results for large poses. The distorted rendering results on large poses in 3D-aware generators further show that the generated 3D face shapes are far from the distribution of 3D faces in reality. We find that the above issues are caused by the training dataset's pose imbalance.

In this paper, we present \textit{LPFF}, a large-pose Flickr face dataset comprised of 19,590 high-quality real large-pose portrait images. We utilize our dataset to train a 2D face generator that can process large-pose face images, as well as a 3D-aware generator that can generate realistic human face geometry. To better validate our pose-conditional 3D-aware generators, we develop a new FID measure to evaluate the 3D-level performance. Through this novel FID measure and other experiments, we show that \textit{LPFF} can help 2D face generators extend their latent space and better manipulate the large-pose data, and help 3D-aware face generators achieve better view consistency and more realistic 3D reconstruction results.
\end{abstract}


\begin{figure}[h]
    	\centering
    	{\includegraphics[width=0.95\columnwidth]{teaser2.pdf}}
    	\caption{ Image and shape samples generated by EG3D models \cite{Chan_2022_CVPR} trained with the same training strategy but using different datasets (our new dataset \textit{LPFF} and \textit{FFHQ} for (a) and \textit{FFHQ} for (b)). 
      %
      The generators are conditioned by the average camera parameters. 
      %
      Shapes are iso-surfaces extracted from the corresponding density fields using marching cubes. Our dataset helps reduce distorted, ``seam'', ``wall-mounted'', and blurry artifacts exhibited in (b).}
      \vspace{-5pt}
    	\label{fig:teaser}
    \end{figure}




%%%%%%%%% BODY TEXT
\input{1_introductions}
\input{2_related_work}
\input{3_data_preparation}
\input{4_training_details}
\input{5_Evaluation}
\input{6_conclusion}

{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\end{document}