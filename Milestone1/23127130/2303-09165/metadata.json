{
    "arxiv_id": "2303.09165",
    "paper_title": "A New Benchmark: On the Utility of Synthetic Data with Blender for Bare Supervised Learning and Downstream Domain Adaptation",
    "authors": [
        "Hui Tang",
        "Kui Jia"
    ],
    "submission_date": "2023-03-16",
    "revised_dates": [
        "2023-05-16"
    ],
    "latest_version": 3,
    "categories": [
        "cs.CV"
    ],
    "abstract": "Deep learning in computer vision has achieved great success with the price of large-scale labeled training data. However, exhaustive data annotation is impracticable for each task of all domains of interest, due to high labor costs and unguaranteed labeling accuracy. Besides, the uncontrollable data collection process produces non-IID training and test data, where undesired duplication may exist. All these nuisances may hinder the verification of typical theories and exposure to new findings. To circumvent them, an alternative is to generate synthetic data via 3D rendering with domain randomization. We in this work push forward along this line by doing profound and extensive research on bare supervised learning and downstream domain adaptation. Specifically, under the well-controlled, IID data setting enabled by 3D rendering, we systematically verify the typical, important learning insights, e.g., shortcut learning, and discover the new laws of various data regimes and network architectures in generalization. We further investigate the effect of image formation factors on generalization, e.g., object scale, material texture, illumination, camera viewpoint, and background in a 3D scene. Moreover, we use the simulation-to-reality adaptation as a downstream task for comparing the transferability between synthetic and real data when used for pre-training, which demonstrates that synthetic data pre-training is also promising to improve real test results. Lastly, to promote future research, we develop a new large-scale synthetic-to-real benchmark for image classification, termed S2RDA, which provides more significant challenges for transfer from simulation to reality. The code and datasets are available at https://github.com/huitangtang/On_the_Utility_of_Synthetic_Data.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.09165v1",
        "http://arxiv.org/pdf/2303.09165v2",
        "http://arxiv.org/pdf/2303.09165v3"
    ],
    "publication_venue": "24 pages, 14 figures, 5 tables, accepted by the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023. The proposed new synthetic-to-real benchmark S2RDA is available at https://pan.baidu.com/s/1fHHaqrEHbUZLXEg9XKpgSg?pwd=w9wa"
}