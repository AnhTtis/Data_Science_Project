\documentclass[sigconf]{acmart}
%\renewcommand\footnotetextcopyrightpermission[1]{}
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\copyrightyear{2023}
\acmYear{2023}
\setcopyright{acmlicensed}\acmConference[WWW '23]{Proceedings of the ACM Web Conference 2023}{May 1--5, 2023}{Austin, TX, USA}
\acmBooktitle{Proceedings of the ACM Web Conference 2023 (WWW '23), May 1--5, 2023, Austin, TX, USA}
\acmPrice{15.00}
\acmDOI{10.1145/3543507.3583439}
\acmISBN{978-1-4503-9416-1/23/04}


\let\Bbbk\relax
\usepackage{booktabs}
\usepackage{tikz}
\usetikzlibrary{external}
\tikzexternalize % activate!
\usepackage{ textcomp }
\usepackage[utf8]{inputenc}
\usepackage{enumitem}
\newcommand{\xsub}[1]{%
  \mbox{\scriptsize\begin{tabular}{@{}c@{}}#1\end{tabular}}%
}
\usepackage{epstopdf}
\usepackage{makecell}
\usepackage{threeparttable}
\usepackage{longtable}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage{tabulary}
\usepackage{tablefootnote}
\usepackage{array}
%\usepackage{hyperref}
\newcommand{\PreserveBackslash}[1]{\let\temp=\\#1\let\\=\temp}
\renewcommand\arraystretch{1.3}
\newcolumntype{C}[1]{>{\PreserveBackslash\centering}p{#1}}
\newcolumntype{R}[1]{>{\PreserveBackslash\raggedleft}p{#1}}
\newcolumntype{L}[1]{>{\PreserveBackslash\raggedright}p{#1}}
\usepackage{amssymb}
\usepackage{dsfont}
%\usepackage{epstopdf}
\setcounter{tocdepth}{3}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{caption}
\usepackage{color}
\usepackage{mathtools}
\usepackage{url}
\usepackage{hyperref}
\usepackage{bm}
\usepackage{algorithmic}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\newcommand\mycommfont[1]{\footnotesize\ttfamily\textcolor{blue}{#1}}
\SetCommentSty{mycommfont}
\begin{document}

\title{Multi-Behavior Recommendation with Cascading Graph Convolution Networks }
\author{ Zhiyong Cheng$^1$, Sai Han$^1$, Fan Liu$^2$, Lei Zhu$^{3,5}$, Zan Gao$^1$, Yuxin Peng$^{4,5}$}
\affiliation{\institution{$^1$Shandong Artificial Intelligence Institute, Qilu University of Technology (Shandong Academy of Sciences), \country{China}}}
\affiliation{\institution{$^2$ School of Computing, National University of Singapore, \country{Singapore}}}
\affiliation{\institution{$^3$School of
Information Science and Engineering, Shandong Normal University, \country{China}}}
\affiliation{\institution{$^4$Wangxuan Institute of Computer Technology, Peking University, \country{China}}}
\affiliation{\institution{$^5$Peng Cheng Laboratory, \country{China}}}
\email{{jason.zy.cheng,liufancs}@gmail.com,	hansai11@126.com}
%\thanks{Corresponding author: Zhiyong Cheng and Liqiang Nie}

\begin{abstract}
 Multi-behavior recommendation, which exploits auxiliary behaviors (e.g., \textit{click} and \textit{cart}) to help predict users’ potential interactions on the target behavior (e.g., \textit{buy}), is regarded as an effective way to alleviate the data sparsity or cold-start issues in recommendation. Multi-behaviors are often taken in certain orders  in real-world applications (e.g., \textit{click>cart>buy}). In a behavior chain, a latter behavior usually exhibits a stronger signal of user preference than the former one does. Most existing multi-behavior models fail to capture such dependencies in a behavior chain for embedding learning. In this work, we propose a novel multi-behavior recommendation model with cascading graph convolution networks (named MB-CGCN). In MB-CGCN, the embeddings learned from one behavior are used as the input features for the next behavior's embedding learning after a feature transformation operation. In this way, our model explicitly utilizes the behavior dependencies in embedding learning. Experiments on two benchmark datasets demonstrate the effectiveness of our model on exploiting multi-behavior data. It outperforms the best baseline by  33.7\% and 35.9\% on average over the two datasets in terms of Recall@10 and NDCG@10, respectively. 
\end{abstract}

\begin{CCSXML}
<ccs2012>
    <concept>
        <concept_id>10002951.10003317.10003331.10003271</concept_id>
        <concept_desc>Information systems~Personalization</concept_desc>
        <concept_significance>500</concept_significance>
        </concept>
        <concept>
        <concept_id>10002951.10003317.10003347.10003350</concept_id>
        <concept_desc>Information systems~Recommender systems</concept_desc>
        <concept_significance>500</concept_significance>
        </concept>
        <concept>
        <concept_id>10002951.10003227.10003351.10003269</concept_id>
        <concept_desc>Information systems~Collaborative filtering</concept_desc>
        <concept_significance>500</concept_significance>
    </concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Information systems~Personalization}
\ccsdesc[500]{Information systems~Recommender systems}
\ccsdesc[500]{Information systems~Collaborative filtering}

\keywords{Collaborative filtering, GCN, multi-behavior recommendation}

\maketitle

\section{Introduction}
Recommendation, as an effective tool to deal with the information overload issue in the information era, has achieved a tremendous progress in the past decade. The model-based collaborative filtering, which learns user and item representations based on user-item interactions for recommendation, has become the mainstream recommendation technique since its success in the Netflix contest~\cite{MF}. With the rise of deep learning, CF methods have gained rapid development from shallow models~\cite{MF,BPRMF,cheng2018www} to deep models~\cite{NCF,cheng2022tois,NGCF,mao2021ultragcn}. The deep neural network (DNN) based models can learn better user/item representations and capture more complicated user-item interaction relations~\cite{LightGCN,LR-GCCF,DLsuvey,wu2022survey}. And the graph convolutional network (GCN) based ones exploit the high-order proximities over the user-item interaction graph to enhance the representation learning~\cite{NGCF,LightGCN,mao2021ultragcn,IMP-GCN}. In addition, the DNN- and GCN-based models are often equipped with advanced techniques, such as the attention mechanism~\cite{KGAT}, disentangled learning~\cite{DGCF}, contrastive learning~\cite{SimGCL,SGL}, setting up a new standard of recommendation. 

The aforementioned CF models are often built upon a single-type of behavior, which is directly related to the platform profit, such as the purchase behavior in e-commence platforms or the download behavior in an App platform. As such behaviors come with a real financial or time cost to users, single-behavior recommendation models will encounter serious data sparsity issue in real-world applications. Fortunately, users usually take other types of behaviors (i.e., \textit{click}, and \textit{cart}) to get more information about items to help them make the final decisions. For example, in an e-commerce platform, the \textit{click} behavior can bring users more information about the item (e.g., descriptions or reviews), and the \textit{cart} behavior is of the convenience to compare with other candidates for reaching a decision. Comparing to the purchase behaviors, the other types of behaviors have much richer interactions. And these types of behaviors or auxiliary behaviors can be exploited to help capture user preference and alleviate the data sparsity issue  in recommendation. 

Many multi-behavior recommendation models have been reported in literature~\cite{Tang2016multi,zhao2015www,NMTR,MBGCN,MBGMN}. A straightforward approach is to adapt the single-behavior recommendation methods to multi-behaviors, such as extending the standard matrix factorization to multiple matrices~\cite{Tang2016multi,zhao2015www} or designing new sampling strategies on the multiple behaviors based on BPR~\cite{ding2018ijcai,guo2017kbs,BPRH}. With the evidence of performance enhancement by using multi-behavior information, multi-behavior recommendation has drawn more attention in recent years. The recent advanced DNN and GCN techniques have been also applied in this task. For example, DIPN~\cite{DIPN} uses a hierarchical attention network to capture the inter- and intra-behavior relations; MATN~\cite{MATN} and KHGT~\cite{KHGT} apply the transformer network to model multi-behavior relations and learn user/item embeddings. The GCN-based models often construct a unified graph based on all types of interaction behaviors, and then perform GCN over the graph to learn the user and item embeddings with various strategies and techniques~\cite{KHGT,MBGCN,meng2022coarse,GHCF,MBGMN}. 

Despite the progress, those methods fail to exploit the behavior dependencies in a chain to directly facilitate the embedding learning in behaviors. In real-world applications, users often take behaviors in a certain order to discover more about an item to help make the final decision, such as \textit{click->cart->purchase}~\footnote{In real scenarios, users may jump one or two behaviors directly to the final behavior.}. Different behaviors reveal user preference to different extents or from different perspectives~\cite{MBGMN,CRGCN}. In a behavior chain, a latter behavior exhibits a stronger signal of user preference on the item than the former one does~\cite{chainRec}. Therefore, the preference information learned from a previous behavior can be used to facilitate the embedding learning in the next one in the behavior chain. Some methods also consider the dependencies or relations among multi-behaviors~\cite{MBGCN,DIPN,MATN,KHGT}, however, they learn the dependencies for weighing the contributions of other behaviors to the target behaviors in embedding aggregation. In addition, most existing methods treat each type of auxiliary behavior in the same way and have not considered the behavior order in modeling. Only limited methods consider the effects of behavior chain~\cite{NMTR,CRGCN}. NMTR~\cite{NMTR} models the cascading effects of multi-behaviors by injecting the prediction scores of a previous behavior into the next behavior’s score prediction. CRGCN~\cite{CRGCN} designs a cascading residual graph convolutional network to explicitly utilize the cascading behaviors in the embedding learning. Similar to many other multi-behavior recommendation models~\cite{DIPN,MGNN,MBGMN,NMTR,MATN,GHCF,meng2022coarse}, CRGCN also adopts multi-task learning in model training. Multi-task learning can acquire supervision signals from each type of behavior data for the embedding learning, but the learning process is not fully oriented to the target behavior prediction. 

In this paper, we propose a novel multi-behavior recommendation model with cascading graph convolution networks (named MB-CGCN). Specifically, our model consists of a sequence of GCN blocks, each of which corresponds to a behavior in the behavior chain. The LightGCN~\cite{LightGCN} is adopted for its efficiency and efficacy in the blocks to learn user and item embeddings from each behavior. The embeddings of users and items learned from a behavior are used as the input features to the next behavior's embedding learning.  Considering that directly using the output embeddings as the input embeddings of the next GCN may inject noise or misleading information to misguide the learning process, a feature transformation is designed to process the embeddings before the delivery. In this way, our model explicitly utilizes the behavior dependencies  in a chain to directly facilitate the embedding learning in latter behaviors. Finally, the embedding learned from different behaviors are aggregated for the final behavior prediction. Different from previous models, MB-CGCN does not adopt multi-task learning in optimization. It only uses the target behavior as supervision signals, making the embedding learning in all behaviors oriented to the ultimate goal. Extensive experiments have been conducted on two benchmark datasets to evaluate the effectiveness of  MB-CGCN. With the simple structure, MB-CGCN gains a remarkable improvement over the state-of-the-art multi-behavior recommendation methods, achieving 33.7\% and 35.9\% relative gains on average over the two datasets in terms of Recall@10 and NDCG@10, respectively. Further empirical studies are also performed to examine the validity of different designs in our model and analyze the effects of different multi-behavior numbers and orders. The main contributions are summarized as:
\vspace{-3pt}
\begin{itemize}[leftmargin=*]
    \item We highlight the importance of explicitly exploiting the behavior dependencies in a behavior chain  in multi-behavior recommendation and propose to distill the behavioral features of a former behavior to facilitate the embedding learning in the latter one.
    \item We propose a novel multi-behavior recommendation model MB-CGCN with a simple structure. It mainly consists of a sequence of GCN blocks, in which the embeddings learned in a previous GCN are processed by a feature transformation operation and then used as the input to the next one. 
    \item We comprehensively evaluate the effectiveness of MB-CGCN on two real-word datasets. Experiment results show that our model can significantly improve the recommendation performance with a large margin.  We release the our code for reproducibility\footnote{https://github.com/SS-00-SS/MBCGCN}. 
\end{itemize}


\section{Related work}
%The model-based collaborative filtering (CF) method has gained the most attention among various recommendation approaches and have made tremendous progress in past decades. The early CF models are mainly shallow models, such as the matrix factorization~\cite{MF} for rating prediction and BPR~\cite{BPRMF} for item ranking. Due to their success, a variety of CF models have been developed to enhance the performance~\cite{CML,SVD++,WRMF}.  With the rise of deep learning, many deep neural network (DNN) based recommendation models have been developed to either enhance the user/item embedding learning or model the nonlinear interaction between users and items techniques~\cite{NCF,cheng2016wide}. Later on, the graph neural network(GNN) models~\cite{Ying2018GCN,NGCF} have been proposed to exploit the high-order connectivity over the user-item bipartite graph to learn better user and item embeddings. The advancement of GCN-based models bring the performance to a new standard. In more recent years, researches put more efforts on improving the GCN models on various aspects, such as simplified the model by removing redundant operations including transformation matrices and nonlinear activation~\cite{LightGCN,LR-GCCF}, alleviating the over-smoothing issue~\cite{IMP-GCN}, improving efficiency~\cite{mao2021ultragcn}, modeling user diversified interests by applying disentangled learning~\cite{DGCF}, and enhancing the representation robustness by using contrastive learning~\cite{SimGCL,SGL}. 

%Despite the progress, the aforementioned CF models only exploit a single type of behavior (e.g., purchase) in the modeling process, which may encounter serious cold-start or data sparsity issue in real applications. To tackle with this shortcoming, other types of behaviors (such as click) can be exploited to enrich the interaction data. 

Multi-behavior recommendation refers to the exploitation of multiple behaviors in user-item interactions for recommendation~\cite{guo2017kbs,NMTR,MBGCN}. Owing to its effectiveness in alleviating the data sparsity issue and enhancing recommendation performance, it has drawn an increasing attention in recent years~\cite{BPRMF,NMTR,MBGCN,GNMR,meng2022coarse}. 

The early multi-behavior recommendation methods were mainly developed based on traditional recommendation techniques. A direct approach is to extend the traditional matrix factorization~{MF} technique operating on single matrix to multiple matrices~\cite{RLCMF,Tang2016multi}. For example, Ajit et al.~\cite{RLCMF} directly extended the matrix factorization model to factorize multiple matrices simultaneously with sharing item-side embeddings. This model was further extended to perform matrix factorization of multiple behaviors by sharing user or item embeddings~\cite{Tang2016multi,zhao2015www}. Another line of research treated the multiple behaviors as auxiliary behavioral data and designed new sampling strategies to enrich the training samples.  Loni et al.~\cite{Loni} proposed to assign different preference levels to multiple behaviors and extended the standard BPR~\cite{BPRMF} with a new negative sampling strategy for negative item sampling from different behaviors. Ding et al.~\cite{ding2018ijcai} further extended this idea by designing an improved negative sampler to better exploit the multiple behavioral data. Guo et al.~\cite{guo2017kbs} utilized the item-item similarity to generate samples from multiple auxiliary behaviors. Qiu et al.~\cite{BPRH} designed an adaptive sampler in BPR to balance the correlation among behaviors. 

With the great success of deep learning techniques in recommendation, researchers have also attempted to developed deep neural network (DNN) or graph convolutional network (GCN) based multi-behavior recommendation models in recent years. In DNN models, a common approach is to first learn user and item embeddings from each behavior via the designed network, and then aggregate the embeddings learned from different behaviors for the target behavior prediction~\cite{DIPN,MATN,KHGT}. The differences lie in the designed network and used attention mechanism. For example, DIPN~\cite{DIPN} applies a hierarchical attention network to model the relationships between different behaviors in embedding learning aggregation. MATN~\cite{MATN} uses a transformer-based network to encode the multi-behavior relations and a memory attention network to generate the embeddings for each behavior, which are then aggregated for target behavior prediction. Besides the user-item interactions, KHGT~\cite{KHGT} also considers the item-item relations and adopts a transformer network to learn user/item embeddings, which are aggregated with behavior-specific contributions to make the final prediction. Different from those methods that aggregate the embeddings from different behaviors for target behavior prediction, NMTR~\cite{NMTR} adopts a multi-task learning framework to leverage all behaviors of users as prediction targets and reuse the prediction score of the previous behavior to the score prediction of the next behavior. 

For GCN models, a general paradigm is to construct a unified user-item graph based on all behaviors, and then perform GCN operations on the graph to learn user embeddings~\cite{GHCF,MBGCN,MBGMN,meng2022coarse}. GHCF~\cite{GHCF} learns the embedding over the graph via GCN and then simply uses the aggregated representations to predict each behavior individually. MBGCN~\cite{MBGCN} learns the behavior contributions over the unified user-item graph and models behavior semantics over item-item co-interacted graphs. The final prediction is an aggregation of the predicted scores obtained by behavior contributions and behavior semantics. MGNN~\cite{MGNN} leverages the multiplex (multiple-layer) network to learn both shared user and item embeddings and unique embeddings of each behavior. MBGMN~\cite{MBGMN} uses a meta graph neural network to model the diverse multi-behavior patterns and capture the behavior heterogeneity and diversity in the unified graph. Meng et al.~\cite{meng2022coarse} considered the diversified interests of users behind multiple behaviors and proposed a knowledge-enhanced multi-interest learning method (CKML) to learn users’ multiple interests of users by assigning each behavior among interests. HMGGR~\cite{HMGGR} conducts graph contrastive learning among the constructed hyper meta-graphs to adaptively learn the complex dependencies among different behaviors for embedding learning. 

Besides chainRec~\cite{chainRec} and NMTR~\cite{NMTR}, the previous methods have not considered the order information in the modeling. And none of the aforementioned models have explicitly exploited the dependency relations of multi-behaviors into the embedding learning. More recently, Yan et al.~\cite{CRGCN} proposed a CRGCN model to address this limitation with a cascading GCN structure by using multi-task learning. However, due to the use of a residual design, it can only uses a single-layer GCN for auxiliary behaviors. In contrast, our model uses a feature transformation to distill features from previous behaviors and can avoid the problem caused by residual connections. Besides, we did not use the multi-task learning in optimization. %We have more discussions about the difference between CRGCN and MB-CGCN in~\ref{sec:disc}. 

%\subsection{Multi-behavior Recommendation}
%Multi-behavior recommendation\cite{olbrich2011modeling}\cite{lo2016understanding}\cite{guo2017resolving} refers to the interaction between users and items in a multi-interaction behavior scenario, which may include view, cart, and buy. It can alleviate the problem of sparsity of single behavior recommendation\cite{BPRMF}\cite{Fism}.
%At present, the work of multi-behavior recommendation is mainly divided into two aspects.

%The first aspect is to consider the assistance of the auxiliary behavior in predicting the target behavior. The model proposed by Krohn et al.\cite{krohn2012multi} is not only an extension of the collective Matrix Factorization (CMF)\cite{RLCMF} model, but also builds matrix factorization of auxiliary behaviors to help target behaviors learn better. Tang et al.\cite{Tang2016multi} proposed to decompose each auxiliary and target behavior matrix as a task. There are also common works, such as Bayesian Personalized Recommendation(BPR)\cite{BPRMF}\cite{BPRH}. Loni et al.\cite{BPRMF} constructed a sampling pair of one positive behavior and another weak auxiliary behavior.In recent years, with the development of neural networks, multi-behavior recommendation based on Graph Convolution Networks(GCN) has been rapidly developed. Jin et al.\cite{MBGCN} designs user and item graphs about auxiliary and target behavior to capture multi-behavior information based on GCN. Xia et al.\cite{Xia2021MBE}\cite{xia2021graph} uses the attention mechanism\cite{Vaswani2017attention} in the Transfomer model to mine for associations between auxiliary and target behaviors based on GCN. Meng et al. \cite{meng2022coarse} takes into account not only the common characteristics but also the particularities between behaviors.

%The second part is to consider the sequential relation (cascade relation) between the auxiliary behavior and the target behavior.
%Zhou et al.\cite{Micro} codes multi-behaviors, and ranks them in chronological order. Then it is added to Recurrent Neural Network(RNN) network to learn multi-behavior embedding. Gao et al.\cite{NMTR} is based on NCF network, and after setting the intensity sequence between multiple behaviors, the model is trained by cascade multi-task. yan et al.\cite{yan2022cascading} designs a cascading residual graph convolution network structure to better learn user and item embedding.

%In our work, we designed each behavior graph for each behavior in order to better learn user and item embeddings. According to the cascade relationship between behaviors, the behavior graph is passed.


%\subsection{Collaborative Filtering}
%Neural network is a very effective technique, which can fit the complex relationship of data well(e.g., it dig the features of data deeply). So researchers have begun to apply neural networks to recommendations.
%At present, the work of neural network is mainly divided into two categories.

%The first category is traditional neural networks(NN). Salakhutdinov et al.\cite{salakhutdinov2007restricted} is the first to apply neural networks to the recommendation system, and uses a limited Boltzmann machine instead of the traditional matrix factorization for CF. In subsequent years, this approach has been applied to various scenarios, such as video\cite{covington2016deep} and textual\cite{zheng2017joint}\cite{cheng2018aspect}, etc. Later, He et al.\cite{NCF} proposed Neural Cooperative Filtering(NCF), which uses Multi-layer Neural Network to deal with nonlinear interactions and General Matrix Factorization to deal with linear interactions. With the rapid development of neural networks, Recurrent Neural Networks(RNN) are also applied to multi-behavior recommendation, such as Wu et al.\cite{wu2016personal} uses RNN to model the temporal feature of behavior. In addition, \cite{bansal2016ask} uses Deep Neural Network(DNN) to encode text sequence and share embedded expression of text.

%The second category is Graph Neural Network(GNN). Traditional neural networks are difficult to learn higher-order structural information in data, while GNN uses message passing mechanism to integrate neighbor information and enables nodes to access higher-order neighbor information through multi-layer stacking. Therefore, GNN model has been widely used in recommendation system in recent years, and has become the most advanced method. 

%In our work, LightGCN model not only has strong ability to mine information, but also has low complexity. Therefore, we learn user and item embedding based on LightGCN model.

\section{Proposed Model}

\begin{figure*}[htbp]
  \centering
  \includegraphics[width=0.9\textwidth]{model.pdf}
  \caption{Overview of our MB-CGCN model.}
   \label{fig:overview}
\end{figure*}

\subsection{Problem Formulation}
Traditional recommendation methods are generally designed towards the single type of user-item interaction (i.e., a target behavior) that directly relevant to the platform's profit (e.g., \textit {buy}). They often face serious data sparsity or cold-start issue in real-world applications, because this behavior will bring a real financial cost to users. Before taking actions of this behavior, users will interact with items by other manners (e.g., \textit{click} and \textit{cart}) to get more information to help them make decisions. These auxiliary behaviors also contain rich information about user preferences and can be used to alleviate the data sparsity and cold-start issues. In this work, our goal is to design a recommendation model for the target behavior by exploiting the auxiliary behaviors.

Let $\mathcal{U}$ and $\mathcal{I}$ be the user set and item set with $M$ and $N$ users and items, respectively. We use $\{\bm{Y}^1,\bm{Y}^2,\cdots, \bm{Y}^{B}\}$ to denote the multi-behavior interaction matrices sorted in a behavior order. $B$ is the number of behavior types. $\bm{Y}^{b}$ is the interaction matrix of the $b$-th behavior and $\bm{Y}^{B}$ is the target behavior. All the interaction matrices are binary, which means that each entry in the matrices has a value 1 or 0, defined as:
\vspace{-3pt}
\begin{equation}
{y^b_{u,i}}=
 \begin{cases}
	1,& \text{If $u$ has interacted with $i$ under behavior $b$;}\\
	  0,& \text{otherwise.}
\end{cases}
\vspace{-3pt}
\end{equation}

The task of multi-behavior recommendation is formulated as:

\noindent \textbf{Input}: The interaction data of $B$ types of behaviors $\{\bm{Y}^1,\bm{Y}^2,\cdots, \bm{Y}^{B}\}$, for a user set $\mathcal{U}$ and an item set $\mathcal{I}$.

\noindent \textbf{Output}: A recommendation model to predict the probability  that a user $u$ will interact with an item $i$ under the $B$-th behavior, i.e., target behavior.



\subsection{Model Description}
\subsubsection{Overview}
Before delving into the details of our model, we would like to make a first impression on the global view. Motivated by the observations that different behaviors exhibit user preferences from different perspectives~\cite{meng2022coarse} or to different extents~\cite{chainRec,CRGCN}, we would like to explicitly utilize the dependencies among behavior chains for embedding learning in different behaviors. Figure~\ref{fig:overview} shows the overall structure of our MB-CGCN model, which consists of three components: 1) \textbf{Embedding initialization}, which initializes user and item embeddings for the subsequent learning based on the behaviors in a defined order. 2) \textbf{Cascading GCN blocks}, in which LightGCN is adopted to learn the user and item embeddings for each behaviors. More specifically, the embeddings learned from a previous behavior will be delivered to facilitate the next behavior's embedding learning via a feature transformation. 3) \textbf{Embedding aggregation}, which aggregates the embeddings learned from each behavior for the target behavior prediction.

%Now we introduce MB-CGCN in detail, and the model flow is shown in the Figure 1. The model is designed to predict the likelihood that a user will perform the last behavior on an item. It's worth noting that this behavior belongs to any one of $B$ types of behaviors(e.g., view, cart, and buy). The MB-CGCN consists of two core parts:(1)Cascading feature modeling, which better transfer the different behavior information in the cascading graph convolution network module. (2)Multi-Behavior aggregation, which aggregate the embeddings in each behavior state in order to better express the embedding of users and items.

% \begin{itemize}
% 	\item Embedding initialization. Encoding dense low-dimensional feature vectors for users and items.
% 	\item Behavior specific graph convolution module. In order to learn the user and item embeddings with current behavior characteristics under each behavior through the constructed cascade graph convolution module.
% 	\item Multi-Behavior feature transformation layer. In order to better transfer the different behavior information in the convolution module of the cascade graph..
% 	\item Multi-Behavior aggregation layer. In order to better express the embedding of users and items, it is necessary to aggregate the embedding of current behavior features generated by the convolution of multi-behavior cascade graph.
% 	\item Train learning. In order to optimize the model, the final model can better predict the likelihood of user's target behavior on unobserved items.
% \end{itemize} 

% \begin{figure*}[htbp]
%   \centering
%   \includegraphics[width=\textwidth,height=0.35\textwidth]{model.pdf}
%   \caption{overview of model}
% %   \label{fig:teaser}
% \end{figure*}



\subsubsection{Embedding Initialization}
Following existing GCN-based recommendation models~\cite{LightGCN,mao2021ultragcn,MBGCN,CRGCN}, we initialize the embedding vectors of a user $u\in\mathcal{U}$ and an item $i\in\mathcal{I}$ as $\bm{e_u^0}\in \mathbb{R}^d$ and $\bm{e_i^0}\in \mathbb{R}^d$, respectively. $d$ denotes the embedding size. We use $\bm{P} \in \mathbb{R}^{M \times d}$ and $\bm{Q} \in \mathbb{R}^{N \times d}$ to respectively denote the embedding matrix for users and items. Each user or item is described by an unique ID, which is represented by an one-hot vector. Let $\bm{ID}^{U}$ and $\bm{ID}^{I}$ be the one-hot vector matrix for all users and items, the embedding of a user $u_m$ and item $i_n$ are initialized as:
\begin{equation}
  \label{eq:init}
  \begin{aligned}
    \bm{e}_{u_m}^{0} = \bm{P} \cdot \bm{ID}_m^{U}, \quad
    \bm{e}_{i_n}^{0} = \bm{Q} \cdot \bm{ID}_n^{I},
  \end{aligned}
\end{equation}
where $\bm{ID}_m^{U}$ and $\bm{ID}_n^{I}$ are one-hot vector for user $u_m$ and item $i_n$, respectively. Notice that the initialized embeddings are used as the input feature of users and items in the LightGCN of the first behavior, as shown in Figure~\ref{fig:overview}.



\subsubsection{Cascading GCN blocks}
The Cascading GCN blocks are the core component of our model. This component mainly consists of a LightGCN chain, in which each LightGCN~\cite{LightGCN} responses to one type of behaviors to learn the user and item embeddings for this behavior. Along with the chain, the embedding learned from a previous LightGCN is used as the input features of users and items in the next LightGCN after a \textit{feature transformation} operation. The basic idea is to use the cascading LightGCN to extract features from different behaviors and also exploit the dependencies in the behavior chain to help learn the latter behaviors' features. In the next, we briefly recap the core idea of LightGCN and introduce the feature transformation in our model.

\textbf{LightGCN Brief.}
LightGCN is an effective and popular GCN-based model designed for single-behavior recommendation. It removes the transformation matrix and nonlinear activation from the vanilla GCN. This simplification has proven to be efficient and effective in recommendation. In this work, we adopt LightGCN as the backbone model to learn user and item embeddings from each behavior for its efficiency and efficacy. Note other single-behavior GCN-based recommendation models can be also applied, such as UltraGCN~\cite{mao2021ultragcn} and SimGCL~\cite{SimGCL}. 

The core of GCN-based model is to recursively integrate the embedding information from neighboring nodes and update the embedding of ego nodes. Given the input embedding of a user $\bm{e}_u^b$ and an item $\bm{e}_i^b$ for the $b$-th behavior, LightGCN leverages the user-item interaction graph to propagate embeddings as:
\begin{equation}
{\bm{e^{(b,l+1)}_{u}}} ={\sum_{i\epsilon \mathcal{N}_u}  \frac{1}{\sqrt{\left\lvert \mathcal{N}_u\right\rvert} \sqrt{\left\lvert \mathcal{N}_i\right\rvert } } \bm{e^{(b,l)}_{i}}},
\end{equation}

\begin{equation}
{\bm{e^{(b,l+1)}_{i}}} ={\sum_{u\epsilon \mathcal{N}_i}  \frac{1}{\sqrt{\left\lvert \mathcal{N}_i\right\rvert} \sqrt{\left\lvert \mathcal{N}_u\right\rvert } } \bm{e^{(b,l)}_{u}}},
\end{equation}
where $\bm{e^{(b,l)}_{u}}$ and $\bm{e^{(b,l)}_{i}}$ respectively denote the updated embeddings of user $u$ and item $i$ under behavior $b$ after $l$ layers' propagation. $\mathcal{N}_u$ denotes the set of items that are interacted by user $u$, and $\mathcal{N}_i$ denotes the set of users that interact with item $i$. After $L$ layers' propagation, LightGCN obtains $L+1$ embeddings to describe a user $\{e_{u}^{(b,0)},e_{u}^{(b,1)},\cdots, e_{u}^{(b,L)}\}$ and an item $\{e_{i}^{(b,0)},e_{i}^{(b,1)},\cdots, e_{i}^{(b,L)}\}$. To obtain the final user and item embeddings based on the $b$-th behavior, we simply aggregate these embeddings as follows:
\begin{equation}
\bm{e_{u}^{(b)}} = \sum_{l = 0}^{L} \bm{e^{(b,l)}}_{u}, \quad \bm{e_{i}^{(b)}} = \sum_{l = 0}^{L} \bm{e^{(b,l)}_{i}}. 
\end{equation}
The learned embeddings from $b$-th behavior will fed into the LightGCN of the next behavior as the input embeddings after a \textit{feature transformation} operation. 

\textbf{Feature Transformation.}
All the different types of behaviors in interactions reveal users' preferences more or less. In a behavior chain, a latter behavior often exhibits stronger signal or more accurate user preference than a former behavior does~\cite{chainRec}. Therefore, the embeddings learned from a former behavior can be used as good initializations for  the next behavior's embedding learning, which is the underlying intuition of our cascading GCN structure. However, the direct use of a former behavior's features as initialized embeddings can be regarded as a refinement of the embeddings by using latter behaviors, which may lose the diverse information conveyed by different behaviors. On the other hand, the noisy information in a former behavior may negatively impact the learning process of latter behaviors seriously. With this consideration, we introduce a feature transformation design in MB-CGCN to process the learned embeddings  before the delivery. Let $\bm{W^{b}}$ be the transformation matrix for the $b$-th behavior to the $(b+1)$-th behavior, the transformation is performed as:

\begin{equation}
\bm{e_{u}^{(b+1,0)}} = \bm{W_{u}^b} \bm{e_{u}^{(b)}} , \quad \bm{e_{i}^{(b+1,0)}} = \bm{W_{i}^b} \bm{e_{i}^{(b)}},
\end{equation}
where $\bm{W_{u}^b}$ and $\bm{W_{i}^b}$ respectively denote the transformation vector for user $u$ and item $i$. $\bm{e_{u}^{(b+1,0)}}$ and $\bm{e_{i}^{(b+1,0)}}$ denote the initial embeddings of the user $u$ and item $i$ in the $(b+1)$-th behavior. Despite its simplicity, the feature transformation can effectively distill useful feature to facilitate the next behavior's embedding learning as demonstrated in our experiments. 

\subsubsection{Embedding Aggregation} \label{sec:disc}
To well exploit different behaviors, we aggregate the embeddings learned from all behaviors for prediction. The main focus of this work is to study the potential of exploiting the dependency structure of multi-behaviors in a certain order for recommendation. To keep the structure simple, we simply use a linear combination to aggregate the features learned from different behaviors, which is
\begin{equation}
\bm{e_{u}} = \sum_{b = 1}^{B} \bm{e^{(b)}_{u}}, \quad \bm{e_{i}} = \sum_{b = 1}^{B} \bm{e^{(b)}_{i}} . 
\end{equation}

Finally, the model prediction is defined as an inner product of the user and item embeddings:
\begin{equation}
\hat{y} _{ui} = \bm{e}^T_u \bm{e}_i,
\end{equation}
which is used as a ranking score for the target behavior recommendation.

\subsection{Model Training}
Similar to other rank-oriented recommendation work, the pairwise learning strategy is adopted for model optimization~\cite{LightGCN,IMP-GCN,MBGCN}. In implementation, we use the standard BPR loss~\cite{BPRMF}, which assumes a higher score to an observed item than that to an unobserved one. The objective function is formulated as:
\begin{equation}
	\mathcal{L} = \sum_{(u,i,j) \in O} -ln\sigma(y_{ui}-y_{uj})+\lambda \left\lVert \Theta \right\rVert^2,
\end{equation}
where $O=\{(u,i,j)|(u,i) \in \mathcal{R}^{+}, (u,j) \in \mathcal{R}^{-}\}$ is defined as positive and negative sample pairs, and $\mathcal{R}^{+}$ ($\mathcal{R}^{-}$) denotes the sample that has been observed (unobserved) in the target behavior. $\sigma(\cdot)$ denotes the sigmoid function.  $\Theta$ denotes all trainable parameters. $L_2$ regularization is adopted to prevent over-fitting and $\lambda$ is a coefficient to control the $L_2$ regularization.

%Note that we adopted the widely used leave-one-out technique in order to obtain the training and test sets. The data in the training set is that for each user, there is a test item with which it does not interact.

\subsection{Discussion} \label{sec:discuss}
We notice that CRGCN~\cite{CRGCN} also exploits a cascading GCN structure to exploit the behavior dependencies in the embedding learning of  behaviors. As far as we concerned, MB-CGCN is fundamentally different from CRGCN on \emph{how to deliver the embedding from one behavior to the next behavior}. CRGCN delicately designs a residual connection to preserve previous behavioral features as initialized embeddings of the next behavior's network. In this way, it learns user and item embeddings  by gradually refining them through all the behaviors in the chain. The learned embeddings from the last behavior are directly used for prediction. Consequently, the quality of embeddings learned from earlier behaviors (e.g., \textit{click}) exacts a great impact on the final performance. Because the earlier behaviors are not deterministic and often noisy, using higher-order propagation for embedding learning in such behaviors is inevitably bring more noise into embeddings. This also explains why CRGCN uses only one-layer propagation in auxiliary behaviors. In contrast, we adopt a feature transformation to distill useful information for next behavior's embedding learning. This helps our model avoid the above problems, and thus our model can enjoy the benefits brought by high-order propagation. % Comparing to CRGCN, this operation also encourages the model to learn different features from different behaviors. And our model utilizes multi-behaviors more comprehensively by aggregating the embeddings from all behaviors for prediction. %Secondly,  CRGCN adopts  multi-task learning to exploit  supervision signals from all behaviors for optimization. MB-CGCN  uses only the information of target behavior as supervision signal, which makes the embeddings learned from all behaviors oriented to the target prediction. 

 %The most relevant work is CRGCN~\cite{CRGCN}, which also adopt a cascading GCN structure for multi-behavior recommendation. There are at least two main differences between our model and CRGCN. Firstly, CRGCN adopts a residual design to preserve the behavior features of a previous GCN for feeding into the next GCN. As demonstrated in their experiments, this design may pass noisy information to the embedding learning in the next behavior. As a result, the auxiliary behaviors can only use one-layer GCNs for a better performance, which sacrifices the high-order information in the rich auxiliary behaviors. In contrast, our model simply uses a transform matrix, which serves as a filter to keep effective information to the next block, and thus it can enjoy the benefits of multiple layers in GCN as shown in our experiments. Secondly, the model learning process is quite different. In CRGCN, the multi-task learning is adopted to guide the embedding learning in each behavior; and the embeddings learned in each behavior is used for this behavior’s prediction. In our model, the embeddings learned from all behaviors are aggregated for the target behavior prediction; and only the target behavior (or the last behavior) is used as supervision signal, which guides the embedding learning process in all behaviors and crafts all the embeddings for the target behavior prediction. 

\section{Experiment}

%In the next, we will introduce the experimental settings first and then answer the above questions sequentially based on the experimental results.

\subsection{Experiment Settings}
\subsubsection{Dataset}
Two datasets are adopted for evaluation:

\begin{itemize}[leftmargin=*]
\item \textbf{Beibei}: This dataset was collected from Beibei\footnote{https://www.beibei.com/}, which is the largest e-commerce platform for baby products in China. It contains 21,716 users and 7,977 items with three types of user-item behaviors, including \textit{view}, \textit{adding-to-cart} or \textit{cart} for short, and \textit{buy}. Notice that on the Beibei platform, users have to follow a strict order to make purchase, which is \textit{view>cart>buy}.
\item \textbf{Tmall}: This dataset was collected from Tmall\footnote{https://www.tmall.com/}, one of the largest e-commerce platforms in China. It contains 15,449 users and 11,953 items. We also use the three types of behaviors in this dataset as those in Beibei for experiments.
\end{itemize}

For both datasets, we followed the previous studies to remove the duplicates by keeping the earliest one~\cite{NMTR,MBGCN}. 
The statistical information of the two datasets used in our experiments is summarized in Table~\ref{tab:freq}.
%

\begin{table}
  \caption{Statistics of the datasets used in our experiments.}
  \label{tab:freq}
  \begin{tabular}{cccccc}
     \toprule
      Dataset & User\# & Item\# & Buy\# & Cart\# & View\# \\
      \midrule
      Beibei & 21,716 & 7,997  & 304,576 & 642,622 & 2,412,586 \\
      Tmall  & 15,449 & 11,953 & 104,329 & 195,476 & 873,954 \\
      \bottomrule
\end{tabular}
\end{table}


%
\begin{table*}[htb]
  \caption{Overall performance comparison.  Improv. denotes the relative improvements over the best baseline.}
  \label{tab:result}
%   \renewcommand\arraystretch{1.5}
%   \renewcommand\arraystretch{1.5}
  \resizebox{\linewidth}{!}{
    \setlength{\tabcolsep}{3mm}{
      \begin{tabular}{c|l|ccc|ccccc|c|c}
        \hline
        \multirow{2}*{Dataset} & \multirow{2}{*}{Metric} & \multicolumn{3}{c|}{\textbf{Single behavior Methods}} & \multicolumn{6}{c|}{\textbf{Multi behavior Methods}} & \multirow{2}*{Improv.}                                                                                              \\
        \cline{3-11}         &                         & \textbf{MF-BPR}           & \textbf{NeuMF}            & \textbf{LightGCN}  & \textbf{RGCN}    & \textbf{GNMR}    & \textbf{NMTR}    & \textbf{MBGCN}               & \textbf{CRGCN}  & \textbf{MB-CGCN}   &                   
        \\
        \hline
        \multirow{6}*{Beibei}  & Recall@10           & 0.0191               & 0.0232             & 0.0391         & 0.0363 & 0.0413   & 0.0429    & \underline{0.0470}  & 0.0459              & \textbf{0.0579}  & 23.2\%  \\
                               & NDCG@10             & 0.0049               & 0.0135             & 0.0209         & 0.0188 & 0.0221   & 0.0198    & 0.0259              & \underline{0.0324}  & \textbf{0.0381}  & 17.6\%   \\
                               & Recall@20           & 0.0531               & 0.0736             & 0.0717         & 0.0684 & 0.0729   & 0.0776    & 0.0792              & \underline{0.0891}  & \textbf{0.0972}  & 9.1\%  \\
                               & NDCG@20             & 0.0239               & 0.0290             & 0.0270         & 0.0274 & 0.0279   & 0.0296    & 0.0330              & \underline{0.0348}  & \textbf{0.0404}  & 16.1\%  \\
                               & Recall@50           & 0.1014               & 0.1402             & 0.1347         & 0.1309 & 0.1391   & 0.1453    & 0.1493              & \underline{0.1694}  & \textbf{0.1924}  & 13.6\%  \\
                               & NDCG@50             & 0.0330               & 0.0405             & 0.0366         & 0.0371 & 0.0374   & 0.0399    & 0.0447              & \underline{0.0487}  & \textbf{0.0572}  & 17.5\%  \\
                               
        \hline
        \multirow{6}*{Tmall}   & Recall@10           & 0.0076               & 0.0236             & 0.0411         & 0.0215 & 0.0368   & 0.0282    & 0.0509   & \underline{0.0855}  & \textbf{0.1233} & 44.2\%  \\
                               & NDCG@10             & 0.0036               & 0.0128             & 0.0240         & 0.0104 & 0.0216   & 0.0137    & 0.0294   & \underline{0.0439}  & \textbf{0.0677} & 54.2\%   \\
                               & Recall@20           & 0.0244               & 0.0311             & 0.0546         & 0.0326 & 0.0608   & 0.0642    & 0.0691   & \underline{0.1369} &\textbf{0.2007}  & 46.6\%  \\
                               & NDCG@20             & 0.0155               & 0.0152             & 0.0266         & 0.0125 & 0.0263   & 0.0303    & 0.0350   & \underline{0.0676} &\textbf{0.0880}  & 30.2\%  \\
                               & Recall@50           & 0.0393               & 0.0494             & 0.0874         & 0.0411 & 0.0971   & 0.1034    & 0.1117   & \underline{0.2325} &\textbf{0.3322}  & 42.9\%  \\
                               & NDCG@50             & 0.0197               & 0.0193             & 0.0338         & 0.0160 & 0.0336   & 0.0383    & 0.0455   & \underline{0.0866} &\textbf{0.1134}  & 30.9\%  \\
        \hline
      \end{tabular}
    }
  }
  \vspace{-3pt}
\end{table*}

\subsubsection{Evaluation Protocols}
We adopt the widely used leave-one-out strategy for evaluation~\cite{NMTR,MBGCN,MBGMN}. For each user, the last interacted item and all the items which she has not interacted with comprise the test set; the second last interacted item of each user is used to construct the validation set for hyper-parameter tuning; the remainder positive items are used in training.  In the evaluation stage, all the items in the test set are ranked according to the predicted scores by recommendation models.  In our experiments, two standard metrics for top-n recommendation \textit{Recall@K} and \textit{NDCG@K} are used to measure performance.


\subsubsection{Baselines}
To demonstrate the effectiveness of our MB-CGCN, we compare it with several state-of-the-art methods, which can be classified into two categories: single-behavior models and mujlti-behavior models

\noindent \textbf{Single-behavior Models:}
\begin{itemize}[leftmargin=*]
\item \textbf{MF-BPR}\cite{BPRMF}: This method has shown competitive performance on the top-n recommendation task, and is commonly used as a baseline to evaluate the efficacy of new models. BPR is a widely used optimization strategy with the assumption that the positive items should score higher than negative ones.

\item \textbf{NeuMF}\cite{NCF}: It is a representative neural CF models, which uses GMF and MLP simultaneously to capture the non-linear interactions between users and items.

\item \textbf{LightGCN}\cite{LightGCN}: This model is a state-of-the-art GCN-based recommendation model, which exploits the high-order connectives in the user-item bipartite graph for recommendation. In particular, it removes the feature transformation and non-linear activation components in vanilla GCN to simplify the model structure and achieves a significant performance improvement.
\end{itemize}

\noindent  \textbf{Multi-behavior Models:}
\begin{itemize}[leftmargin=*]

\item \textbf{NMTR}\cite{NMTR}: This model develops
a cascading neural network method to model the multi-behavior data for recommendation. It sequentially passes the interaction score of the current behavior to the next and uses multi-task learning for jointly optimization.

\item \textbf{RGCN}\cite{RGCN}: This model differentiates the relations between nodes via edge types in the graph and designs different propagation layers for different relations. This model can adapt to multi-behavior recommendation

\item \textbf{GNMR}\cite{GNMR}: This GNN-based approach attempts to explore the dependencies among multi-behaviors via recursive embedding propagation on the unified multi-behavior interaction graph. It designs a relation aggregation network to  model the interaction heterogeneity.


\item \textbf{MBGCN}\cite{MBGCN}: It is a state-of-the-art GCN-based multi-behavior recommendation model. This method considers the different contributions of multi-behaviors to the target behavior. It learns the behavior contributions by using GCN on the unified multi-behavior graph and exploits the item-item graph to capture the behavior semantics.

\item \textbf{CRGCN}\cite{CRGCN}: This is a most recently proposed model. It  adopts a cascading GCN structure to model multi-behavior data. The behavioral features learned  from a behavior is delivered to the next behavior with a residual design. This method also adopts the multi-task learning in optimization. %Please refer to Section~\ref{sec:discuss} for more discussion about this model.

\end{itemize}


% \begin{table*}[htb]
%   \caption{Performance comparison in terms of Recall@K and NDCG@K(Noticed that the values are repoted by percentage with ‘\%’ omitted).}
%   \label{tab:freq}
% %   \renewcommand\arraystretch{1.5}
% %   \renewcommand\arraystretch{1.5}
%   \resizebox{\linewidth}{!}{
%     \setlength{\tabcolsep}{3mm}{
%       \begin{tabular}{c|c|ccc|ccccc|c|c}
%         \hline
%         \multirow{2}*{Dataset} & \multirow{2}{*}{Metric} & \multicolumn{3}{c|}{\textbf{Single behavior Methods}} & \multicolumn{6}{c|}{\textbf{Multi behavior Methods}} & \multirow{2}*{Improve}                                                                                              \\
%         \cline{3-11}         &                         & \textbf{NCF}           & \textbf{BPRMF}            & \textbf{LightGCN}  & \textbf{GNMR}    & \textbf{RGCN}    & \textbf{NMTR}    & \textbf{MBGCN}               & \textbf{CRGCN}  & \textbf{MB-CGCN}   &                   
%         \\
%         \hline
%         \multirow{6}*{Beibei}  & Recall@5              & 0.524                  & 1.625                     & 2.989              & 2.430 & 3.045 & 2.420 & \underline{3.578}  & 2.285  &\textbf{3.877}  & 8.4   \\
%                               & NDCG@5                & 0.348                  & 1.159                     & 1.930              & 1.691 & 1.983 & 1.591 & \underline{2.404}  & 1.857  & \textbf{2.824} & 17.5   \\
%                               & Recall@10             & 0.190                  & 2.324                     & 3.905              & 3.629 & 4.129 & 4.288 & \underline{4.696}  & 4.581  & \textbf{5.921} & 26.1  \\
%                               & NDCG@10               & 0.491                  & 1.350                     & 2.085              & 1.883 & 2.214 & 1.983 & 2.594   & \underline{3.240} & \textbf{3.809} & 17.6   \\
%                               & Recall@20             & 5.309                  & 7.363                     & 7.170              & 6.840 & 7.286 & 7.760 & 7.920   & \underline{8.911} & \textbf{9.716} & 9.0  \\
%                               & NDCG@20               & 2.390                  & 2.897                     & 2.702              & 2.744 & 2.789 & 2.961 & 3.297   & \underline{3.480} & \textbf{4.040} & 16.1  \\
%         \hline
%         \multirow{6}*{Tmall}   & Recall@5              & 0.278                  & 1.696                     & 2.848              & 1.285 & 2.251 & 1.920 & 3.265   & \underline{5.884} & \textbf{8.451} & 43.6  \\
%                               & NDCG@5                & 0.171                  & 1.132                     & 1.976              & 0.810 & 1.538 & 1.195 & 2.546   & \underline{3.710} & \textbf{5.342} & 44.0   \\
%                               & Recall@10             & 0.764                  & 2.356                     & 4.110              & 2.147 & 3.681 & 2.820 & 5.086   & \underline{8.552} & \textbf{12.334} & 44.2  \\
%                               & NDCG@10               & 0.357                  & 1.284                     & 2.401              & 1.041 & 2.158 & 1.370 & 2.988   & \underline{4.390} & \textbf{6.765} & 54.1   \\
%                               & Recall@20             & 2.444                  & 3.107                     & 5.463              & 3.215 & 6.081 & 6.420 & 6.989   & \underline{13.690} &\textbf{20.069} & 46.6  \\
%                               & NDCG@20               & 1.550                  & 1.524                     & 2.657              & 1.250 & 2.634 & 3.030 & 3.593   & \underline{6.760} & \textbf{8.797} & 30.1  \\
%         \hline
%       \end{tabular}
%     }
%   }
% \end{table*}
\subsubsection{Hyper-parameter Settings.} In implementation, we adopt the \textit{Adam} optimizer for optimization. The embedding size and the batch size of all adopted methods are set to 64 and 1024, respectively. The learning rate is tuned in the range of \{1e{-2}, 1e{-3}, 1e{-4}\}. In addition, we initialize model parameters (behavior features transformation matrices) with the Xavier initializer. The early stopping strategy is also adopted.   The number of GCN layers for each behaviors is tuned in \{1, 2, 3, 4\}. Without specification, for the behavior chain \textit{view>cart>buy}, we use the layers of $\{3,4,3\}$ and $\{3,4,2\}$ for the three behaviors on Beibei and Tmall, respectively. For other baselines, we mainly use their official open-source code and carefully tune the parameters to achieve the best performance for fair comparisons.
%Note that we did not test all possible layer combinations. The selected layers might not be the optimal. 
%

% i.e., If Recall@K in the test set continues to drop for 25 epochs, the training is terminated.



\subsection{Overall Performance}
In this section, we report the performance comparisons between our MB-CGCN and all the baselines. The results on two datasets are shown in Table~\ref{tab:result}. The best results are highlighted in bold and the second best results are underlined. From the results, we can see that the multi-behavior models can achieve better performance than the single-behavior models, demonstrating the benefits of leveraging auxiliary behaviors (i.e., view and cart) for the target behavior (i.e., buy) prediction. Our MB-CGCN model achieves the best performance,  outperforming all baselines significantly in term of both metrics over two datasets. The improvement across different ranges of top $K$ ($K=\{10,20,50\}$) items over the best baseline can achieve 9.0\% and 16.1\% on Beibei, and 46.6\% and 30.1\% on Tmall for Recall@20 and NDCG@20 metrics, respectively. It is a remarkable improvement for recommendation accuracy, especially observing that the best baseline CRGCN has already made a big improvement over the second best baseline, which strongly demonstrates the effectiveness of our MB-CRGN model.

%On the Beibei dataset, It respectively compared with the best baseline. The index values (Recall@K) of our model have improved 26.1\%, 9.0\%, and 13.6\%, and the index values (NDCG@K) have improved 17.6\%, 16.1\% , and 17.3\%. On the Tmall dataset, the improvement rate (Recall@k) is 44.2\%, 46.6\%, and 42.9\% and the improvement rate(NDCG@K) is 54.1\% 30.1\%, and 31.0\% respectively. The results of the experiment prove that our model is effective in multi-behavior recommendation.

For the single-behavior models, NeuMF outperforms MF-BPR in most cases. MF-BPR uses the inner product as interaction function, which is incapable of modeling the complex relations between users and items. In contrast, NeuMF adopts multi-layers of neural networks to model the non-linear interactions, yielding a better performance. LightGCN achieves consistently better performance over MF-BPR and NeuMF. This demonstrates the advantages of the GCN models by exploiting the high-order neighbor's information over the user-item bipartite graph to learn user and item embeddings for recommendation. 


For the multi-behavior recommendation models, RGCN models different behaviors individually and then aggregates the embeddings learned from each behavior for prediction without distinguishing their contributions to the target behavior. It does not perform well among the multi-behavior models. Both GNMR and MBGCN differentiate the behavior contributions before fusion, and they achieve a better performance than RGCN. Comparing to GNMR, MBGCN additionally exploits the item-item relations to capture the behavior semantics and gains further improvement over GNMR. NMTR considers the cascading effects of multi-behaviors in the model structure. It attempts to take the effects into the embedding learning process by passing the prediction scores of a previous behavior to the next one. It surpasses the GNMR model but does not perform as well as MBGCN. The better performance MBGCN attributes to its use of GCN and additional consideration of item-item relations in the modeling. CRGCN moves a step further over NMTR by directly take the cascading effects of multi-behavior into the embedding learning process explicitly. It is achieved by passing the embeddings learned from the previous behavior to the next one for further refinement. In this way, the embedding learning process of CRGCN is actually a refinement of the embeddings through the behavior chain. CRGCN outperforms all other baselines by a large margin, especially on the Tmall datasets. 

MB-CGCN adopts the similar cascading GCN structure as CRGCN, and thus also enjoys the merits of explicitly exploiting the cascading effects in embedding learning. Instead of adopting the residual design in CRGCN to preserve behavior features for delivery, MB-CGCN adopts a feature transformation operation between two GCN blocks to distill effective features from a previous behavior to the next one. In addition, MB-CGCN does not use the multi-task learning in optimization and only employ the signals of target behavior to guide the learning process. The big performance improvement of MB-CGCN over CRGCN demonstrates the effectiveness of our design. 



%Compared with the multi-behavior model, our proposed MB-CGCN consistently achieves the best results on the Beibei and Tmall dataset. NMTR takes into account the cascading relationships between multi-behaviors and then through a multi-task learning framework, but it doesn't consider the use of graph neural networks to further extract multiple behavioral information. RGCN only considers edge information but not the importance of edge information. MBGCN was inspired by the design ideas of RGCN, and calculates the importance of each behavior(edge information) by using a simple algorithm. GNMR further explores the importance of multi-behaviors, and uses a soft attention mechanism to calculate the importance of different behavior based on GCN. However it does not consider how to make better use of the cascade relationship between behaviors in graph convolutional networks. Recently, CRGCN incorporates the cascade relationship into the graph convolution network, and learns a single embedding expression parameter. Buy it does not take into account that embedding in the behavior graph transfer process also requires a mechanism to control and transform.

%Our model MB-CGCN uses light graph convolution network, and proposes a multi-behavior cascading feature transformation. It can deeply explore the representation features of behavior in the different behavior graph. Finally, all the features are fused through a multi-behavior aggregation layer. The experimental results show that our design is effective.

\begin{table}
  \caption{Effects of the feature transformation in MB-CGCN. The reported performance is computed based on the top 20 results.($w/o.\ ft$ and $w.\ ft$ denote MB-CGCN with and without the feature transformation, respectively. }

    \begin{tabular}{r|cc|cc} 
        % \toprule[1.5px]
        \hline
        \textbf{\multirow{2}{*}{Method}} & \multicolumn{2}{c|}{\textbf{Beibei}} & \multicolumn{2}{c}{\textbf{Tmall}} \\
        % \midrule[1.5px]
        \cline{2-5}
                & \textbf{Recall} & \textbf{NDCG} & \textbf{Recall} & \textbf{NDCG}\\
		\hline
		\textbf{w/o. ft} & 0.0892 & 0.0382 & 0.1994 & 0.0825\\
		\textbf{w. ft}   & \textbf{0.0972} & \textbf{0.0404} & \textbf{0.2007} & \textbf{0.0880}\\
    \hline
    \end{tabular}
    % }
%   }
\label{tab:ft}
\end{table}

\subsection{Ablation Study}
\subsubsection{Effect of feature transformation}
In order to evaluate the validity of the feature transformation in our model, we conducted an ablation study to compare our model with and without the feature transformation module (denoted as \textbf{w/o. ft} and \textbf{w. ft} in Table 3). 
 The default order of behaviors used in our experiments are: \textit{view>cart>buy}\footnote{There could be other orders, such as \textit{view>buy}, \textit{cart>buy}, and \textit{cart>view>buy}, which are studied in Section~\ref{sec:behaviororder}.}, which also the required order in Beibei. After removing the feature transformation from MB-CGCN,  the embeddings learned from the first behavior (i.e., \textit{view}) are directly used as the initialized embeddings in the next behavior (i.e., \textit{cart}) for embedding learning; and the same for the embedding learning of the last behavior (i.e., \textit{buy}).

Experimental results are shown in Table~\ref{tab:ft}. With feature transformation, MB-CGCN can gain an relative improvement  of 9.0\% and 5.8\% on Beibei, and 0.7\% and 6.7\% on Tmall for Recall@20 and NDCG@20\%, respectively. A latter behavior in the behavior chain usually shows a strong signal of user preferences on items. The results demonstrate the effectiveness of the feature transformation scheme on distilling useful information from an earlier behavior to help learn user and item embeddings in a latter behavior.

% and it removes the feature transformation matrices.
% And because our model involves multiple behavior graphs, there are differences and correlations between behaviors (e.g., viewing indicates the user's curiosity at the moment, while adding to the cart means the user is weighing the item and hesitating to make a purchase). Therefore, in our model, we design a key behavioral feature transformation matrices. 
%The embeddings under different behavior graphs represent different emotions of users (e.g., the transition from view to buy represents the transition from curiosity to certainty). We designed a behavior feature transformation matrices in the behavior cascading convolution graphs to better learn this transformation process.
%Experimental results show that in Beibei dataset, Recall@20 with transformation mechanism is increased by 8.2\% and NDCG@20 by 5.8\% compared with that without transformation (see Table 3). On Tmall dataset, increase by 0.7\% and 8.0\% respectively (as shown in Table 3). 

%This indicates that the behavior feature transformation matrices is significantly effective in researching the multi-behavior recommendation problem, which shows that the transformation matrices can better learn the importance between multi-behavior.


\subsubsection{Effects of feature aggregation}
 In MB-CGCN, we aggregate the embeddings learned from all behaviors for users and items for the target behavior prediction by a linear aggregation. To evaluate the utility of the feature aggregation,  we compare our model to two variants in experiments:
\begin{itemize}[leftmargin=*]
\item \textbf{w/o. agg.:} This variant removes the feature aggregation module in MB-CGCN. It means the embeddings learned from the last GCN block are directly used for the target prediction.
\item \textbf{w/o. concat.:} This variant replaces the aggregation with a concatenation operation. Specifically, the user and item embeddings learned from each behavior are concatenated together for the target prediction.  
\end{itemize}

From the results shown in Table~\ref{tab:agg}, it is clear that it is necessary to consider the embedding learned from all behaviors. As discussed, with the feature transformation, some features learned from auxiliary behaviors will be filtered when delivering the embeddings learned from the first behavior to the target behavior. And it will also encourage the model to learn different features from each behavior. Therefore, to well exploit the multi-behaviors, it is important for our model to consider all the behavioral features. For simplicity, we only compare the linear combination (\textbf{w. agg}) with the embedding concatenation (\textbf{w. concat.}) in experiments. Empirically, \textbf{w. agg} performs much better than \textbf{w. concat.}. More sophisticated fusion methods (e.g., attention network) can be also applied, which will be explored in future studies.  



%Experimental results show that in Beibei datasets, Recall@20 and NDCG@20 of behavior aggregation method are improved by 74.8\%, 15.0\% and 188.0\%, 43.5\% (see Table 4) respectively compared with those of other methods. In the Tmall datasets, they increased by 187.4\%, 17.9\% and 202.2\%, 28.0\% respectively (see Table 4).
%This indicates that the design of multi-behavior aggregation are helpful to the performance of MB-CGCN
%In order to evaluate the effect of the multi-behavior aggregation in the whole model, We design three variants: $w/o$ aggregation, $w$ concatenation, and $w$ aggregation. They indicate that using the output embedding of the last behavior after cascading gragh convolution, the embedding after concatenation of the three behaviors and the embeddings after aggregating the embeddings under each behavior graph
% (i.e., our model RCGCN) respectively.


%The popular LighGCN model is a reasonable reduction of the traditional graph convolutional network. The high-order graphs at each layer of the model are different, in order to retain more signals, it aggregates the embeddings learned from the multi-layer high-order graph convolutional network. 
%For multi-behavior recommendation, There are differences between behaviors, and there are also differences in the embedding under each behavior graph. In the process of learning and embedding in the cascading gragh convolution module, in order to minimize the signals of behavior, we designed multi-behavioral aggregation.



\begin{table}
  \caption{Effects of feature aggregation in MB-CGCN. The reported performance is computed based on the top 20 results.}
    \begin{tabular}{r|cc|cc}
        % \toprule[1.5px]
        \hline
        % \multirow{2}*{Method(*1e-2)} & \multicolumn{2}{c|}{Beibei} & \multicolumn{2}{c}{Tmall} \\
        \multirow{2}{*}{\textbf{Method}} & \multicolumn{2}{c|}{\textbf{Beibei}} & \multicolumn{2}{c}{\textbf{Tmall}} \\
        % \midrule[1.5px]
        \cline{2-5}
        & \textbf{Recall} & \textbf{NDCG} & \textbf{Recall} & \textbf{NDCG}\\
		\hline
		\textbf{w/o. agg.}  & 0.0556 & 0.0140 & 0.0698 & 0.0291\\
		\textbf{w.  concat.} & 0.0758 & 0.0282 & 0.1648 & 0.0688\\
		\textbf{w. agg.}    & \textbf{0.0972} & \textbf{0.0404} & \textbf{0.2007} & \textbf{0.0880}\\
    \hline
    \end{tabular}
    \label{tab:agg}
\end{table}



\subsection{Impact of multi-behaviors}
%In this section, we study the impact of behavior number and behavior order on performance in our model.

\subsubsection{Behavior number.}
To study the effects of auxiliary behaviors on the performance of our model, we perform experiments on the two datasets with one behavior (i.e., \textit{buy}), two behaviors (e.g., \textit{cart>buy}), and three behaviors (e.g., \textit{view>cart>buy}). Experimental results are reported in Table~\ref{tab:number}. Notice that MB-CGCN with one behavior is simplified to the LightGCN. Apparently, with more types of behaviors, our model performs better. Interestingly, with the use of \textit{cart} data, the performance is improved by a large margin; with the further consideration of \textit{view} data, the improvement becomes smaller. The reasons might be twofold. First, the \textit{cart} data have already enrich the user-item interactions to a large extent, it becomes harder to improve the performance. Besides, the \textit{cart} data can better uncover user preference than the view data. Notice that a \textit{view} behavior does not necessarily means that a user is interested in an item. 

%The more the number of  behaviors is, the more helpful the prediction of the last behavior is and the better the prediction effect of the model is. Therefore, the more cascading behaviors in the model, the more conducive it is for the model to obtain the last behavior prediction.

\begin{table}
  \caption{Effects of behavior number in MB-CGCN. The reported performance is computed based on the top 20 results.}

    \begin{tabular}{r|cc|cc}
        % \toprule[1.5px]
        \hline
        \multirow{2}{*}{\textbf{Method}} & \multicolumn{2}{c|}{\textbf{Beibei}} & \multicolumn{2}{c}{\textbf{Tmall}} \\
        % \midrule[1.5px]
        \cline{2-5}
            & \textbf{Recall} & \textbf{NDCG} & \textbf{Recall} & \textbf{NDCG}\\
		\hline
		\textbf{buy}           & 0.0717   & 0.0270 & 0.0546   & 0.0266\\
		\textbf{cart>buy}      & 0.0930   & 0.0389 & 0.1956   & 0.0851\\
		\textbf{view>cart>buy} & \textbf{0.0972}   & \textbf{0.0404} & \textbf{0.2007}   & \textbf{0.0880}\\
    \hline
    \end{tabular}
\label{tab:number}
\end{table}

% \begin{table}
%   \caption{The effect of behavior cascade number( $lb$, $2bs-mean$, $3bs-mean$ represent that we only convolve with graphs of one behavior (e.g., buy), two behaviosr(e.g., buy and cart) and all behaviors(e.g., buy, cart and view).)}
%   \label{tab:freq}

% %   \resizebox{\textwidth}{!}{
% %   \resizebox{\linewidth}{!}{
% %   \resizebox{\columnwidth}{!}{

%     \begin{tabular}{c|cccccc}
%         % \toprule[1.5px]
%         \hline
%         \multirow{2}*{Method} & \multicolumn{6}{c|}{Beibei} \\
%         % \midrule[1.5px]
%         \cline{2-7}
%                   & Recall@5 & NDCG@5  & Recall@10 & NDCG@10  & Recall@20 & NDCG@20 \\
% 		\hline
% 		1b         & 0.02489  & 0.01785 & 0.03305  & 0.01985   & 0.06175   & 0.02502 \\
% 		2bs-mean   & 0.03534  & 0.02589 & 0.05500  & 0.03623   & 0.09414   & 0.03038 \\
% 		3bs-mean   & 0.03764  & 0.02715 & 0.05801  & 0.03763   & 0.09363   & 0.03236 \\
%     \hline
%     \end{tabular}
    
%         \begin{tabular}{c|cccccc}
%         % \toprule[1.5px]
%         \hline
%         \multirow{2}*{Method} & \multicolumn{6}{c|}{Tmall} \\
%         % \midrule[1.5px]
%         \cline{2-7}
%                   & Recall@5 & NDCG@5  & Recall@10 & NDCG@10  & Recall@20 & NDCG@20 \\
% 		\hline
% 		1b         & 0.02754  & 0.01882 & 0.04064  & 0.02332   & 0.05362   & 0.02515 \\
% 		2bs-mean   & 0.06461  & 0.04135 & 0.09453  & 0.04270   & 0.01733   & 0.07893 \\
% 		3bs-mean   & 0.07391  & 0.04849 & 0.10421  & 0.05110   & 0.18148   & 0.16163 \\
%     \hline
%     \end{tabular}
%     % }
% %   }
% \end{table}


\subsubsection{Behavior order.} \label{sec:behaviororder}
We study the effects of behavior order on our model by four behavior orders on the two datasets: O1(\textit{cart>buy}), O2(\textit{view>cart}), O3(\textit{cart>view>buy}), and O4(\textit{view>cart>buy}). The performance of different behavior orders on two datasets are shown in Figure~\ref{fig:bbei} and Figure~\ref{fig:btmall}. 
Because both O3 and O4 have the same behaviors with different orders, we first compare their performance. The performance of O4 is better than O3 over both datasets, demonstrating the importance of modeling the multi-behaviors in a correct order, which should be consistent with the common behavior orders in real-world applications. Though the interactions of \textit{view} is much richer over that of \textit{cart} on both datasets, the performance of O2 is much better than that of O1. This is because the \textit{cart} behavior reveals more accurate information about user
preferences than the \textit{view} information as discussed above. It is surprising that our model with O3 performs worse than it with O2 on Tmall. Remind that the embedding learned from a previous behavior will directly affect the embedding learning in the next behavior due to the cascading design of our model. A reasonable behavior order, in which a latter behavior should reveal user preference more accurate than its previous behavior, can make the embeddings of the target behavior be gradually learned step by step through the behavior chain. By using the behavior order in O3, the noisy information in the \textit{view} data will negatively affect the embedding learning in the target behavior, whose features play an important role in the final prediction.  This further demonstrates the importance of the behavior order in the cascading modeling of multi-behaviors.

%We investigate the behaviors cascading order that affect the performance of our model and evaluate the results in figure 2 and figure 3, where we can see that the behavior cascading order will affect our model. In the Beibei dataset (see figure 2), for the exploration with two cascades($cart>buy$ and $view>buy$), $cart>buy$ performs better. For the exploration with three cascades($cart>view>buy$ and $view>cart>buy$), $view>cart>buy$ performs better. This is probably because the order in which the user first views, then adds to the cart, and finally buy is more in line with the user's behavior order. 
% (From the user's perspective, users usually view items out of curiosity, and when they see something they want to buy, they may temporarily put it in the shopping cart. Or if they want to compare items of multiple brands, temporarily put them into the shopping cart, which is conducive to subsequent comparison. Finally, after much deliberation, the user chooses the item). 
%The same is true for the Tmall dataset (see figure 3).Therefore the order of the behavior cascade will affect our model and it is necessary to select the order that conforms to the realistic behavior of users. 
% to set the behavior cascade order of the model.

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{label.pdf}
  \includegraphics[width=\linewidth]{beibei.pdf}
  \caption{Effects of behavior order on Beibei.}
  \label{fig:bbei}
\end{figure}
\vspace{-6pt}
\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{label.pdf}
  \includegraphics[width=\linewidth]{tmall.pdf}
  \caption{Effects of behavior order on Tmall.}
  \label{fig:btmall}
\end{figure}


\subsection{Effects of layer number}
 
In the this study, we tune the layer number by setting it the same for all the behaviors.\footnote{Notice that we also performed the studied by separately tuning the number of layers for the LightGCN of each behavior, which does not reported here due to the space limitation. We deem the reported experiments here can already provide a global view on the effects of layer number.} Table~\ref{tab:layer} reports the performance of our model with one, two, three layers on both datasets. MB-CGCN performs better over both datasets with the increase of layer numbers. With more layers, LightGCN can exploit higher-order information in the user-item interaction graph for embedding learning, as demonstrated in previous work~\cite{LightGCN,IMP-GCN}. The better embedding learned from each behavior benefits our model for final prediction. 

It is worth mentioning that CRGCN, which uses the similar structure as our model, cannot benefit from the high-order GCN on the auxiliary behaviors~\cite{CRGCN}. This is because CRGCN uses a residual design to preserve the behavior features in embedding delivery. However, there could be misleading interactions in auxiliary behaviors (such as \textit{view}). For those behaviors, exploiting higher-order neighbors will bring more noise to the model and hurt the performance eventually. In our model, a feature transformation module is used to process the embedding for delivery. This enables our model to enjoy the benefits from high-order GCN operations.  
\begin{table}
  \caption{Effects of layer numbers by setting the same layer numbers to all behaviors.}


%   \resizebox{\textwidth}{!}{
%   \resizebox{\linewidth}{!}{
%   \resizebox{\columnwidth}{!}{

    \begin{tabular}{r|cc|cc}
        % \toprule[1.5px]
        \hline
        \multirow{2}{*}{\textbf{Method}} & \multicolumn{2}{c|}{\textbf{Beibei}} & \multicolumn{2}{c}{\textbf{Tmall}} \\
        % \midrule[1.5px]
        \cline{2-5}
        & \textbf{Recall} & \textbf{NDCG} & \textbf{Recall} & \textbf{NDCG}\\
		\hline
		\textbf{1-Layer}         & 0.0942   & 0.0328 & 0.1923   & 0.0864\\
		\textbf{2-Layer}         & 0.0954   & 0.0359 & 0.1933   & 0.0867\\
		\textbf{3-Layer}   & \textbf{0.0961}   & \textbf{0.0370} & \textbf{0.1967}   & \textbf{0.0869}\\
    \hline
    \end{tabular}
\label{tab:layer}
\vspace{-3pt}
\end{table}

% \begin{table}
%   \caption{The effect of layers of higher-order aggregation on our model($0l$, $1l$ and $2l$ indicate that the number of high levels of graph convolution for each behavior is 0, 1, and 2 levels respectively.)}
%   \label{tab:freq}

% %   \resizebox{\textwidth}{!}{
% %   \resizebox{\linewidth}{!}{
% %   \resizebox{\columnwidth}{!}{

%     \begin{tabular}{c|cccccc}
%         % \toprule[1.5px]
%         \hline
%         \multirow{2}*{Method} & \multicolumn{6}{c|}{Beibei} \\
%         % \midrule[1.5px]
%         \cline{2-7}
%                   & Recall@5 & NDCG@5  & Recall@10 & NDCG@10  & Recall@20 & NDCG@20 \\
% 		\hline
% 		0l         & 0.02984  & 0.01773 & 0.04850  & 0.02805   & 0.08818   & 0.03382 \\
% 		1l         & 0.03345  & 0.01597 & 0.05089  & 0.02680   & 0.09418   & 0.03281 \\
% 		2l         & 0.03644  & 0.02010 & 0.05811  & 0.03037   & 0.09536   & 0.03587 \\
%     \hline
%     \end{tabular}
    
%         \begin{tabular}{c|cccccc}
%         % \toprule[1.5px]
%         \hline
%         \multirow{2}*{Method} & \multicolumn{6}{c|}{Tmall} \\
%         % \midrule[1.5px]
%         \cline{2-7}
%                   & Recall@5 & NDCG@5  & Recall@10 & NDCG@10  & Recall@20 & NDCG@20 \\
% 		\hline
% 		0l         & 0.11178  & 0.03605 & 0.14237  & 0.04007   & 0.15742   & 0.07211 \\
% 		1l         & 0.15343  & 0.05190 & 0.18558  & 0.05635   & 0.19233   & 0.08643 \\
% 		2l         & 0.16764  & 0.52554 & 0.18951  & 0.05733   & 0.19330   & 0.08501 \\
%     \hline
%     \end{tabular}
%     % }
% %   }
% \end{table}

%\subsubsection{Effects of layer numbers for individual behaviors}
%In this study, we tune the layer numbers for each behavior from 1 to 5. The experiments can study how the high-order information of different behaviors affects the final performance. In experiments, when tuning the layer number of a behavior, we set that of other behaviors to 1 to save time. It is interesting that we observe very different trends on the two datasets. On Beibei, the best layer number for all behaviors varied from 2 to 4, which is consistent with the conclusions in previous studies about GCN-models. With more layers, we can exploit higher-order information to learn better embeddings. The performance often arrives at a peak when using at most 3 or 4 layers~\cite{LightGCN,NGCF,LR-GCCF}, and more layers will cause performance degradation due to the over-smoothing issue~\cite{IMP-GCN}. On Tmall, only the performance using  the \textit{buy} behavior show a similar trend. It might be because the \textit{view} behavior data in Tmall has too much noisy, the best performance is obtained when uses only one layer. For \textit{cart} behavior, the perform still grows when the layer number reaches 5, which is unexpected and needs further studies.

%Recall@K and NDCG@K reach the maximum when the layer of $view$ and $buy$ is 3, and $cart$ reaches the maximum when the layer of $cart$ is 4(see figure 4). This may be because in the Beibei dataset, $cart$ is more complex in the learning process, and the $cart$ behavior itself is an intermediate transformation behavior, which involves the information of the pre and post behaviors, and more layers need to be aggregated. The model works best when the number of layers of multiple behaviors($view$, $cart$ and $buy$) is 3, 4, and 3 respectively.
%In the Tmall dataset(see figure 5), when the layer of $buy$ is 1, when the layer of $cart$ is 5, and when the layer of $view$ is 3, Recall@K and NDCG@K reach the maximum, which may be because in the Tmall dataset, $cart$ also belongs to an intermediate transition behavior, which is similar to Beibei dataset. 
% While the number of $buy$ is small, too many layers will lead to learning overfitting in the $buy$ behavior graph when learning. 
%The model works best when the number of layers of multi-behavior($view$, $cart$ and $buy$) is 3, 5, and 1 respectively.
%All in all it is necessary to explore the number of layers of higher-order aggregation, which will improve our model.

%\begin{figure}[h]
%  \centering
%  \subfigure[Beibei]
%  {\includegraphics[width=\linewidth]{Beibei_layer.pdf}}
 % \vspace{-3pt}
%   \subfigure[Tmall]
%  {\includegraphics[width=\linewidth]{Tmall_layer.pdf}} 
%  \vspace{-3pt}
%  \caption{Effects of layer numbers for individual behaviors.}
%\end{figure}

\vspace{-3pt}
\section{conclusion}
In this work, we present a novel multi-behavior recommendation model named MB-CGCN, which adopts the cascading GCN blocks to explicitly leverage the multi-behaviors for embedding learning. In this model, the behavior features learned by LightGCN over a previous behavior is delivered to the next behavior in a chain after a feature transformation operation. The embedding learned from all behaviors are aggregated for the final prediction. Experiments on two real-world datasets show that MB-CGCN outperforms the state-of-the-art multi-behavior models with a substantial performance gain. Further ablation studies verify the effectiveness of the feature transformation and embedding aggregation in our model. We also study the impact of multi-behavior number and order on the final performance. For future work, we plan to conduct experiments on online systems with A/B testing to validate the utility of our model on the real-world applications.

\vspace{-3pt}
\section*{Acknowledgments}
This work was supported in part by the National Key R\&D Program of China under Grant 2021YFF0901502; in part by the National Natural Science Foundation of China under Grants 61902223, 62272254, 62132001, and 61925201; in part by the Shandong Project towards the Integration of Education and Industry under Grants 2022PY009, and 2022PYI001.

%This work develops a Cascading GCN-based multi-behavior recommendation framework, MB-CGCN, to construct user-item higher-order interaction graphs for each behavior state. We design a user-item embedding representation and construct a user-item higher-order connected interaction graph for multi-behavior. According to the behavior cascade relationship, the embedded behavior will be transferred into the next behavior graph after the behavior feature transformation, until the last behavior graph. Finally, the embeddings of users and items in each behavior are aggregated. This method not only considers the cascade relationship between behaviors, but also considers the difference of behavioral information in the transmission process. Our model is extensively tested on two real-world e-commerce datasets, and these experiments demonstrate the effectiveness of MB-CGCN.

%Although our model considers the cascade relationship between behaviors, our model is based on the data with relatively single cascade relationship between behaviors. In the future, we will try to explore our model for other tasks with multiple cascade relationships.

\bibliographystyle{ACM-Reference-Format}
\bibliography{mbcgcn}

\end{document}
