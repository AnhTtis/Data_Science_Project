@article{DBLP:journals/ral/ZhangTYX0BB19,
  author    = {Jingwei Zhang and
               Lei Tai and
               Peng Yun and
               Yufeng Xiong and
               Ming Liu and
               Joschka Boedecker and
               Wolfram Burgard},
  title     = {VR-Goggles for Robots: Real-to-Sim Domain Adaptation for Visual Control},
  journal   = {{IEEE} Robotics Autom. Lett.},
  volume    = {4},
  number    = {2},
  pages     = {1148--1155},
  year      = {2019}
}


@INPROCEEDINGS{8460875,  author={Bousmalis, Konstantinos and Irpan, Alex and Wohlhart, Paul and Bai, Yunfei and Kelcey, Matthew and Kalakrishnan, Mrinal and Downs, Laura and Ibarz, Julian and Pastor, Peter and Konolige, Kurt and Levine, Sergey and Vanhoucke, Vincent},  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},   title={Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping},   year={2018},  volume={},  number={},  pages={4243-4250},  doi={10.1109/ICRA.2018.8460875}}

@inproceedings{ deMeloEtAl20,
  author = "C. de Melo and B. Rothrock and P. Gurram, O. Ulutan and B.S. Manjunath",
  title = "Vision-based gesture recognition in human-robot teams using synthetic data",
  booktitle = "Proc. of the IROS'20",
  year = "2020"
}

@misc{USArmy87,
  author = {},
  title = {Visual Signals: Field Manual 21-60},
  publisher="Department of the United States Army",
  url={https://www.radford.edu/content/dam/colleges/chbs/rotc/Forms/fm/Visual\%20Signals\%20FM\%2021-60.pdf},
  year = "1987"
}
@misc{wu2019detectron2,
  author =       {Yuxin Wu and Alexander Kirillov and Francisco Massa and
                  Wan-Yen Lo and Ross Girshick},
  title =        {Detectron2},
  howpublished = {\url{https://github.com/facebookresearch/detectron2}},
  year =         {2019}
}
@InProceedings{10.1007/978-3-031-04870-8_16,
author="Dimitropoulos, Konstantinos
and Hatzilygeroudis, Ioannis
and Chatzilygeroudis, Konstantinos",
editor="M{\"u}ller, Andreas
and Brandst{\"o}tter, Mathias",
title="A Brief Survey of Sim2Real Methods for Robot Learning",
booktitle="Advances in Service and Industrial Robotics",
year="2022",
publisher="Springer International Publishing",
address="Cham",
pages="133--140",
abstract="Simulation has been crucial for robotics research development almost from the beginning of its existence. While simulation has been widely used for education, testing, and prototyping, only very recently the robotics community has attempted transferring behaviors learned in simulation to the real world (this process is usually referred to as Sim2Real). Those attempts have opened-up a novel research direction that has produced some exciting results that were previously thought impossible to achieve. In this paper, we attempt to give a quick overview of the most promising Simulation-To-Reality (Sim2Real) methods, results and directions.",
isbn="978-3-031-04870-8"
}

@article{DBLP:journals/corr/abs-2012-03806,
  author    = {Sebastian H{\"{o}}fer and
               Kostas E. Bekris and
               Ankur Handa and
               Juan Camilo Gamboa Higuera and
               Florian Golemo and
               Melissa Mozifian and
               Christopher G. Atkeson and
               Dieter Fox and
               Ken Goldberg and
               John Leonard and
               C. Karen Liu and
               Jan Peters and
               Shuran Song and
               Peter Welinder and
               Martha White},
  title     = {Perspectives on Sim2Real Transfer for Robotics: {A} Summary of the
               {R:} {SS} 2020 Workshop},
  journal   = {CoRR},
  volume    = {abs/2012.03806},
  year      = {2020},
  url       = {https://arxiv.org/abs/2012.03806},
  eprinttype = {arXiv},
  eprint    = {2012.03806},
  timestamp = {Tue, 29 Jun 2021 15:47:36 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2012-03806.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{visda2017,
    Author = {Xingchao Peng and Ben Usman and Neela Kaushik and Judy Hoffman and Dequan Wang and Kate Saenko},
    Title = {VisDA: The Visual Domain Adaptation Challenge},
    Year = {2017},
    Eprint = {arXiv:1710.06924},
}

@INPROCEEDINGS{9340728,  author={de Melo, Celso M. and Rothrock, Brandon and Gurram, Prudhvi and Ulutan, Oytun and Manjunath, B.S.},  booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},   title={Vision-Based Gesture Recognition in Human-Robot Teams Using Synthetic Data},   year={2020},  volume={},  number={},  pages={10278-10284},  doi={10.1109/IROS45743.2020.9340728}}

@INPROCEEDINGS{9649285,  author={Zherdeva, Larisa and Minaev, Evgeniy and Zherdev, Denis and Fursov, Vladimir},  booktitle={2021 International Conference on Information Technology and Nanotechnology (ITNT)},   title={Synthetic dataset for navigation tasks of autonomous systems and ground robots},   year={2021},  volume={},  number={},  pages={1-4},  doi={10.1109/ITNT52450.2021.9649285}}

@article{10.1016/j.robot.2019.103336,
author = {Wang, Senbo and Yue, Jiguang and Dong, Yanchao and He, Shibo and Wang, Haotian and Ning, Shaochun},
title = {A Synthetic Dataset for Visual SLAM Evaluation},
year = {2020},
issue_date = {Feb 2020},
publisher = {North-Holland Publishing Co.},
address = {NLD},
volume = {124},
number = {C},
issn = {0921-8890},
url = {https://doi.org/10.1016/j.robot.2019.103336},
doi = {10.1016/j.robot.2019.103336},
journal = {Robot. Auton. Syst.},
month = {feb},
numpages = {13},
keywords = {Algorithm validation, Evaluation criteria, Synthetic dataset, Computer graphic, Visual SLAM}
}

@INPROCEEDINGS{7487210,  author={Zichao Zhang and Rebecq, Henri and Forster, Christian and Scaramuzza, Davide},  booktitle={2016 IEEE International Conference on Robotics and Automation (ICRA)},   title={Benefit of large field-of-view cameras for visual odometry},   year={2016},  volume={},  number={},  pages={801-808},  doi={10.1109/ICRA.2016.7487210}}

@article{DBLP:journals/corr/abs-2007-11118,
  author    = {Ollie Matthews and
               Koki Ryu and
               Tarun Srivastava},
  title     = {Creating a Large-scale Synthetic Dataset for Human Activity Recognition},
  journal   = {CoRR},
  volume    = {abs/2007.11118},
  year      = {2020},
  url       = {https://arxiv.org/abs/2007.11118},
  eprinttype = {arXiv},
  eprint    = {2007.11118},
  timestamp = {Tue, 28 Jul 2020 14:46:12 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2007-11118.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{9206624,  author={Alharbi, Fayez and Ouarbya, Lahcen and Ward, Jamie A},  booktitle={2020 International Joint Conference on Neural Networks (IJCNN)},   title={Synthetic Sensor Data for Human Activity Recognition},   year={2020},  volume={},  number={},  pages={1-9},  doi={10.1109/IJCNN48605.2020.9206624}}

@article{deMeloEtAl22,
  title={Next-generation deep learning based on simulators and synthetic data},
  author={Celso M. de Melo and Antonio Torralba and Leonidas Guibas and James DiCarlo and Rama Chellappa and Jessica Hodgins},
  journal={Trends in Cognitive Sciences},
  year={2021},
  volume={26}, 
  pages = {174-187}
}

@inproceedings{ deSouzaEtAl16,
  author = "C. de Souza and A. Gaidon and E. Vig and A. López",
  title = "Sympathy for the details: Dense trajectories and hybrid classification architectures for action recognition",
  booktitle = "Proc. of ECCV'16",
  year = "2016"
}

@inproceedings{ deSouzaEtAl17,
  author = "C. de Souza and A. Gaidon and Y. Cabon and A. López",
  title = "Procedural generation of videos to train deep action recognition networks",
  booktitle = "Proc. of CVPR'17",
  year = "2017"
}

@inproceedings{Dosovitskiy17,
  title = {{CARLA}: {An} Open Urban Driving Simulator},
  author = {Alexey Dosovitskiy and German Ros and Felipe Codevilla and Antonio Lopez and Vladlen Koltun},
  booktitle = {Proceedings of the 1st Annual Conference on Robot Learning},
  pages = {1--16},
  year = {2017}
}

@inproceedings{ GaidonEtAl16,
  author = "A. Gaidon and Q. Wang and Y. Cabon and E. Vig",
  title = "Virtual worlds as proxy for multi-object tracking analysis",
  booktitle = "Proc. of CVPR'16",
  year = "2016"
}

@misc{Nikolenko19,
    Author = {S. Nikolenko},
    Title = {Synthetic data for deep learning},
    Year = {2019},
    Eprint = {arXiv:1909.11512},
}

@misc{OzaETAl21,
    Author = {Poojan Oza and Vishwanath A. Sindagi and Vibashan VS and Vishal M. Patel},
    Title = {Unsupervised Domain adaptation of object detectors: A survey},
    Year = {2021},
    Eprint = {arXiv:2105.13502v2},
}

@article{Richter2016PlayingFD,
  title={Playing for Data: Ground Truth from Computer Games},
  author={Stephan R. Richter and Vibhav Vineet and Stefan Roth and Vladlen Koltun},
  journal={ArXiv},
  year={2016},
  volume={abs/1608.02192}
}

@inproceedings{ ShafaeiLittle16,
  author = "A. Shafaei and J. Little",
  title = "Real-time human motion capture with multiple depth cameras",
  booktitle = "Proc. of CRV'16",
  year = "2016"
}

@inproceedings{2021_28dd2c79,
 author = {Makoviychuk, Viktor and Wawrzyniak, Lukasz and Guo, Yunrong and Lu, Michelle and Storey, Kier and Macklin, Miles and Hoeller, David and Rudin, Nikita and Allshire, Arthur and Handa, Ankur and State, Gavriel},
 booktitle = {Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks},
 editor = {J. Vanschoren and S. Yeung},
 pages = {},
 title = {Isaac Gym: High Performance GPU Based Physics Simulation For Robot Learning},
 url = {https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/file/28dd2c7955ce926456240b2ff0100bde-Paper-round2.pdf},
 volume = {1},
 year = {2021}
}

@inproceedings{szot2021habitat,
  title     =     {Habitat 2.0: Training Home Assistants to Rearrange their Habitat},
  author    =     {Andrew Szot and Alex Clegg and Eric Undersander and Erik Wijmans and Yili Zhao and John Turner and Noah Maestre and Mustafa Mukadam and Devendra Chaplot and Oleksandr Maksymets and Aaron Gokaslan and Vladimir Vondrus and Sameer Dharur and Franziska Meier and Wojciech Galuba and Angel Chang and Zsolt Kira and Vladlen Koltun and Jitendra Malik and Manolis Savva and Dhruv Batra},
  booktitle =     {Advances in Neural Information Processing Systems (NeurIPS)},
  year      =     {2021}
}

@inproceedings{habitat19iccv,
  title     =     {Habitat: {A} {P}latform for {E}mbodied {AI} {R}esearch},
  author    =     {Manolis Savva and Abhishek Kadian and Oleksandr Maksymets and Yili Zhao and Erik Wijmans and Bhavana Jain and Julian Straub and Jia Liu and Vladlen Koltun and Jitendra Malik and Devi Parikh and Dhruv Batra},
  booktitle =     {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  year      =     {2019}
}

 @InProceedings{RoomR,
  author = {Luca Weihs and Matt Deitke and Aniruddha Kembhavi and Roozbeh Mottaghi},
  title = {Visual Room Rearrangement},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  month = {June},
  year = {2021}
}

@inproceedings{
          li2021igibson,
          title={iGibson 2.0: Object-Centric Simulation for Robot Learning of Everyday Household Tasks},
          author={Chengshu Li and Fei Xia and Roberto Mart{\'\i}n-Mart{\'\i}n and Michael Lingelbach and Sanjana Srivastava and Bokui Shen and Kent Elliott Vainio and Cem Gokmen and Gokul Dharan and Tanish Jain and Andrey Kurenkov and Karen Liu and Hyowon Gweon and Jiajun Wu and Li Fei-Fei and Silvio Savarese},
          booktitle={5th Annual Conference on Robot Learning },
          year={2021},
          url={https://openreview.net/forum?id=2uGN5jNJROR}
}
    
@article{simonyan2014two,
  title={Two-stream convolutional networks for action recognition in videos},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@inproceedings{karpathy2014large,
  title={Large-scale video classification with convolutional neural networks},
  author={Karpathy, Andrej and Toderici, George and Shetty, Sanketh and Leung, Thomas and Sukthankar, Rahul and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={1725--1732},
  year={2014}
}

@article{negin2016human,
  title={Human action recognition in videos: A survey},
  author={Negin, Farhood and Bremond, Fran{\c{c}}ois},
  journal={INRIA Technical Report},
  year={2016}
}

@inproceedings{yue2015beyond,
  title={Beyond short snippets: Deep networks for video classification},
  author={Yue-Hei Ng, Joe and Hausknecht, Matthew and Vijayanarasimhan, Sudheendra and Vinyals, Oriol and Monga, Rajat and Toderici, George},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4694--4702},
  year={2015}
}

@inproceedings{carreira2017quo,
  title={Quo vadis, action recognition? a new model and the kinetics dataset},
  author={Carreira, Joao and Zisserman, Andrew},
  booktitle={proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6299--6308},
  year={2017}
}

@inproceedings{tran2015learning,
  title={Learning spatiotemporal features with 3d convolutional networks},
  author={Tran, Du and Bourdev, Lubomir and Fergus, Rob and Torresani, Lorenzo and Paluri, Manohar},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={4489--4497},
  year={2015}
}

@inproceedings{hou2017tube,
  title={Tube convolutional neural network (T-CNN) for action detection in videos},
  author={Hou, Rui and Chen, Chen and Shah, Mubarak},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={5822--5831},
  year={2017}
}

@inproceedings{saha2017amtnet,
  title={Amtnet: Action-micro-tube regression by end-to-end trainable deep architecture},
  author={Saha, Suman and Singh, Gurkirt and Cuzzolin, Fabio},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={4414--4423},
  year={2017}
}

@inproceedings{choutas2018potion,
  title={Potion: Pose motion representation for action recognition},
  author={Choutas, Vasileios and Weinzaepfel, Philippe and Revaud, J{\'e}r{\^o}me and Schmid, Cordelia},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7024--7033},
  year={2018}
}

@article{weinzaepfel2021mimetics,
  title={Mimetics: Towards understanding human actions out of context},
  author={Weinzaepfel, Philippe and Rogez, Gr{\'e}gory},
  journal={International Journal of Computer Vision},
  volume={129},
  number={5},
  pages={1675--1690},
  year={2021},
  publisher={Springer}
}

@inproceedings{yan2019pa3d,
  title={PA3D: Pose-action 3D machine for video recognition},
  author={Yan, An and Wang, Yali and Li, Zhifeng and Qiao, Yu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7922--7931},
  year={2019}
}

@inproceedings{hoffman2018cycada,
  title={Cycada: Cycle-consistent adversarial domain adaptation},
  author={Hoffman, Judy and Tzeng, Eric and Park, Taesung and Zhu, Jun-Yan and Isola, Phillip and Saenko, Kate and Efros, Alexei and Darrell, Trevor},
  booktitle={International conference on machine learning},
  pages={1989--1998},
  year={2018},
  organization={Pmlr}
}

@article{DBLP:journals/corr/abs-2112-12252,
  author    = {Benjamin Kiefer and
               David Ott and
               Andreas Zell},
  title     = {Leveraging Synthetic Data in Object Detection on Unmanned Aerial Vehicles},
  journal   = {CoRR},
  volume    = {abs/2112.12252},
  year      = {2021},
  url       = {https://arxiv.org/abs/2112.12252},
  eprinttype = {arXiv},
  eprint    = {2112.12252},
  timestamp = {Tue, 04 Jan 2022 15:59:27 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2112-12252.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{8578985,  author={Sankaranarayanan, Swami and Balaji, Yogesh and Castillo, Carlos D. and Chellappa, Rama},  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},   title={Generate to Adapt: Aligning Domains Using Generative Adversarial Networks},   year={2018},  volume={},  number={},  pages={8503-8512},  doi={10.1109/CVPR.2018.00887}}

@inproceedings{10.5555/3045118.3045130,
author = {Long, Mingsheng and Cao, Yue and Wang, Jianmin and Jordan, Michael I.},
title = {Learning Transferable Features with Deep Adaptation Networks},
year = {2015},
publisher = {JMLR.org},
abstract = {Recent studies reveal that a deep neural network can learn transferable features which generalize well to novel tasks for domain adaptation. However, as deep features eventually transition from general to specific along the network, the feature transferability drops significantly in higher layers with increasing domain discrepancy. Hence, it is important to formally reduce the dataset bias and enhance the transferability in task-specific layers. In this paper, we propose a new Deep Adaptation Network (DAN) architecture, which generalizes deep convolutional neural network to the domain adaptation scenario. In DAN, hidden representations of all task-specific layers are embedded in a reproducing kernel Hilbert space where the mean embeddings of different domain distributions can be explicitly matched. The domain discrepancy is further reduced using an optimal multikernel selection method for mean embedding matching. DAN can learn transferable features with statistical guarantees, and can scale linearly by unbiased estimate of kernel embedding. Extensive empirical evidence shows that the proposed architecture yields state-of-the-art image classification error rates on standard domain adaptation benchmarks.},
booktitle = {Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37},
pages = {97–105},
numpages = {9},
location = {Lille, France},
series = {ICML'15}
}

@inproceedings{10.1145/3357384.3357918,
author = {Cao, Manliang and Zhou, Xiangdong and Xu, Yiming and Pang, Yue and Yao, Bo},
title = {Adversarial Domain Adaptation with Semantic Consistency for Cross-Domain Image Classification},
year = {2019},
isbn = {9781450369763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357384.3357918},
doi = {10.1145/3357384.3357918},
abstract = {In the cross-domain image classification scenario, domain adaption aims to address the challenge of transferring the knowledge obtained from the source domain to the target domain that is regarded as similar but different from the source domain. To get more reliable domain invariant representations, recent methods start to consider class-level distribution alignment across the source and target domains by adaptively assigning pseudo target labels. However, these approaches are vulnerable to the error accumulation and hence unable to preserve cross-domain category consistency. Because the accuracy of pseudo labels cannot be guaranteed explicitly. In this paper, we propose Adversarial Domain Adaptation with Semantic Consistency (ADASC) model to align the discriminative features across domains progressively and effectively, via exploiting the class-level relations between domains. Specifically, to simultaneously alleviate the negative influence of the false pseudo-target labels and get the discriminative domain invariant features, we introduce an Adaptive Centroid Alignment (ACA) strategy and a Class Discriminative Constraint (CDC) step to complement each other iteratively and alternatively in an end-to-end framework. Extensive experiments are conducted on several unsupervised domain adaptation datasets, and the results show that ADASC outperforms the state-of-the-art methods.},
booktitle = {Proceedings of the 28th ACM International Conference on Information and Knowledge Management},
pages = {259–268},
numpages = {10},
keywords = {domain adaptation, adversarial learning, semantic consistency, classification},
location = {Beijing, China},
series = {CIKM '19}
}


@InProceedings{pmlr-v80-hoffman18a,
  title = 	 {{C}y{CADA}: Cycle-Consistent Adversarial Domain Adaptation},
  author =       {Hoffman, Judy and Tzeng, Eric and Park, Taesung and Zhu, Jun-Yan and Isola, Phillip and Saenko, Kate and Efros, Alexei and Darrell, Trevor},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {1989--1998},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/hoffman18a/hoffman18a.pdf},
  url = 	 {https://proceedings.mlr.press/v80/hoffman18a.html},
  abstract = 	 {Domain adaptation is critical for success in new, unseen environments. Adversarial adaptation models have shown tremendous progress towards adapting to new environments by focusing either on discovering domain invariant representations or by mapping between unpaired image domains. While feature space methods are difficult to interpret and sometimes fail to capture pixel-level and low-level domain shifts, image space methods sometimes fail to incorporate high level semantic knowledge relevant for the end task. We propose a model which adapts between domains using both generative image space alignment and latent representation space alignment. Our approach, Cycle-Consistent Adversarial Domain Adaptation (CyCADA), guides transfer between domains according to a specific discriminatively trained task and avoids divergence by enforcing consistency of the relevant semantics before and after adaptation. We evaluate our method on a variety of visual recognition and prediction settings, including digit classification and semantic segmentation of road scenes, advancing state-of-the-art performance for unsupervised adaptation from synthetic to real world driving domains.}
}

@inproceedings{inproceedingsgrasp,
author = {James, Stephen and Wohlhart, Paul and Kalakrishnan, Mrinal and Kalashnikov, Dmitry and Irpan, Alex and Ibarz, Julian and Levine, Sergey and Hadsell, Raia and Bousmalis, Konstantinos},
year = {2019},
month = {06},
pages = {12619-12629},
title = {Sim-To-Real via Sim-To-Sim: Data-Efficient Robotic Grasping via Randomized-To-Canonical Adaptation Networks},
doi = {10.1109/CVPR.2019.01291}
}

@article{Bousmalis2018UsingSA,
  title={Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping},
  author={Konstantinos Bousmalis and Alex Irpan and Paul Wohlhart and Yunfei Bai and Matthew Kelcey and Mrinal Kalakrishnan and Laura Downs and Julian Ibarz and Peter Pastor and Kurt Konolige and Sergey Levine and Vincent Vanhoucke},
  journal={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  year={2018},
  pages={4243-4250}
}

@unknown{sim2real_outdoor,
author = {Weerakoon, Kasun and Sathyamoorthy, Adarsh and Manocha, Dinesh},
year = {2022},
month = {05},
pages = {},
title = {Sim-to-Real Strategy for Spatially Aware Robot Navigation in Uneven Outdoor Environments},
doi = {10.48550/arXiv.2205.09194}
}

@INPROCEEDINGS{8793789,  author={Chebotar, Yevgen and Handa, Ankur and Makoviychuk, Viktor and Macklin, Miles and Issac, Jan and Ratliff, Nathan and Fox, Dieter},  booktitle={2019 International Conference on Robotics and Automation (ICRA)},   title={Closing the Sim-to-Real Loop: Adapting Simulation Randomization with Real World Experience},   year={2019},  volume={},  number={},  pages={8973-8979},  doi={10.1109/ICRA.2019.8793789}}

@INPROCEEDINGS{8793561,  author={Baar, Jeroen van and Sullivan, Alan and Cordorel, Radu and Jha, Devesh and Romeres, Diego and Nikovski, Daniel},  booktitle={2019 International Conference on Robotics and Automation (ICRA)},   title={Sim-to-Real Transfer Learning using Robustified Controllers in Robotic Tasks involving Complex Dynamics},   year={2019},  volume={},  number={},  pages={6001-6007},  doi={10.1109/ICRA.2019.8793561}}

@INPROCEEDINGS{9561157,  author={Ho, Daniel and Rao, Kanishka and Xu, Zhuo and Jang, Eric and Khansari, Mohi and Bai, Yunfei},  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)},   title={RetinaGAN: An Object-aware Approach to Sim-to-Real Transfer},   year={2021},  volume={},  number={},  pages={10920-10926},  doi={10.1109/ICRA48506.2021.9561157}}

@inproceedings{CO2A,
  title={Dual-Head Contrastive Domain Adaptation for Video Action Recognition},
  author={da Costa, Victor G Turrisi and Zara, Giacomo and Rota, Paolo and Oliveira-Santos, Thiago and Sebe, Nicu and Murino, Vittorio and Ricci, Elisa},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={1181--1190},
  year={2022}
}

@article{DANN,
  title={Domain-adversarial training of neural networks},
  author={Ganin, Yaroslav and Ustinova, Evgeniya and Ajakan, Hana and Germain, Pascal and Larochelle, Hugo and Laviolette, Fran{\c{c}}ois and Marchand, Mario and Lempitsky, Victor},
  journal={The journal of machine learning research},
  volume={17},
  number={1},
  pages={2096--2030},
  year={2016},
  publisher={JMLR. org}
}

@inproceedings{feichtenhofer2020x3d,
  title={X3D: Expanding architectures for efficient video recognition},
  author={Feichtenhofer, Christoph},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={203--213},
  year={2020}
}

@misc{2020mmaction2,
    title={OpenMMLab's Next Generation Video Understanding Toolbox and Benchmark},
    author={MMAction2 Contributors},
    howpublished = {\url{https://github.com/open-mmlab/mmaction2}},
    year={2020}
}

@inproceedings{saenko2010adapting,
  title={Adapting visual category models to new domains},
  author={Saenko, Kate and Kulis, Brian and Fritz, Mario and Darrell, Trevor},
  booktitle={European conference on computer vision},
  pages={213--226},
  year={2010},
  organization={Springer}
}
@inproceedings{peng2019moment,
  title={Moment matching for multi-source domain adaptation},
  author={Peng, Xingchao and Bai, Qinxun and Xia, Xide and Huang, Zijun and Saenko, Kate and Wang, Bo},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={1406--1415},
  year={2019}
}

@inproceedings{sankaranarayanan2018learning,
  title={Learning from synthetic data: Addressing domain shift for semantic segmentation},
  author={Sankaranarayanan, Swami and Balaji, Yogesh and Jain, Arpit and Lim, Ser Nam and Chellappa, Rama},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3752--3761},
  year={2018}
}

@article{nguyen2022state,
  title={The State of Aerial Surveillance: A Survey},
  author={Nguyen, Kien and Fookes, Clinton and Sridharan, Sridha and Tian, Yingli and Liu, Xiaoming and Liu, Feng and Ross, Arun},
  journal={arXiv preprint arXiv:2201.03080},
  year={2022}
}

@inproceedings{li2021uav,
  title={Uav-human: A large benchmark for human behavior understanding with unmanned aerial vehicles},
  author={Li, Tianjiao and Liu, Jun and Zhang, Wei and Ni, Yun and Wang, Wenqian and Li, Zhiheng},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={16266--16275},
  year={2021}
}

@inproceedings{perera2018uav,
  title={UAV-GESTURE: A dataset for UAV control and gesture recognition},
  author={Perera, Asanka G and Wei Law, Yee and Chahl, Javaan},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV) Workshops},
  pages={0--0},
  year={2018}
}

@inproceedings{barekatain2017okutama,
  title={Okutama-action: An aerial view video dataset for concurrent human action detection},
  author={Barekatain, Mohammadamin and Mart{\'\i}, Miquel and Shih, Hsueh-Fu and Murray, Samuel and Nakayama, Kotaro and Matsuo, Yutaka and Prendinger, Helmut},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition workshops},
  pages={28--35},
  year={2017}
}

@inproceedings{choi2020unsupervised,
  title={Unsupervised and semi-supervised domain adaptation for action recognition from drones},
  author={Choi, Jinwoo and Sharma, Gaurav and Chandraker, Manmohan and Huang, Jia-Bin},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={1717--1726},
  year={2020}
}

@inproceedings{NEURIPS2020_d85b63ef,
 author = {Cubuk, Ekin Dogus and Zoph, Barret and Shlens, Jon and Le, Quoc},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {18613--18624},
 publisher = {Curran Associates, Inc.},
 title = {RandAugment: Practical Automated Data Augmentation with a Reduced Search Space},
 url = {https://proceedings.neurips.cc/paper/2020/file/d85b63ef0ccb114d0a3bb7b7d808028f-Paper.pdf},
 volume = {33},
 year = {2020}
}

