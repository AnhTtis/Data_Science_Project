{
    "arxiv_id": "2303.10525",
    "paper_title": "Robustifying likelihoods by optimistically re-weighting data",
    "authors": [
        "Miheer Dewaskar",
        "Christopher Tosh",
        "Jeremias Knoblauch",
        "David B. Dunson"
    ],
    "submission_date": "2023-03-19",
    "revised_dates": [
        "2023-03-21"
    ],
    "latest_version": 1,
    "categories": [
        "stat.ME",
        "math.ST"
    ],
    "abstract": "Likelihood-based inferences have been remarkably successful in wide-spanning application areas. However, even after due diligence in selecting a good model for the data at hand, there is inevitably some amount of model misspecification: outliers, data contamination or inappropriate parametric assumptions such as Gaussianity mean that most models are at best rough approximations of reality. A significant practical concern is that for certain inferences, even small amounts of model misspecification may have a substantial impact; a problem we refer to as brittleness. This article attempts to address the brittleness problem in likelihood-based inferences by choosing the most model friendly data generating process in a discrepancy-based neighbourhood of the empirical measure. This leads to a new Optimistically Weighted Likelihood (OWL), which robustifies the original likelihood by formally accounting for a small amount of model misspecification. Focusing on total variation (TV) neighborhoods, we study theoretical properties, develop inference algorithms and illustrate the methodology in applications to mixture models and regression.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.10525v1"
    ],
    "publication_venue": "Python code available at https://github.com/cjtosh/owl"
}