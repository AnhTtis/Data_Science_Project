%auto-ignore

In the following lemma, we would like to understand the conditions under which two distributions $P_0$ and $P_1$ can be written as an $\epsilon$-contamination of one another.

\begin{lemma}
	\label{lem:contamination-condition}
	Suppose $ \epsilon \in [0, 1)$ and two probability measures $P_0, P_1$ are given. Then there is a probability measure $Q$ such that $P_0 = (1-\epsilon) P_1 + \epsilon Q$ if and only if the Radon Nikodym derivative $h = \frac{dP_1}{dP_0}$ exists and is bounded above by $\frac{1}{1-\epsilon}$ almost surely $P_0$.
\end{lemma}
\begin{proof} First we note the ``only if'' direction. Suppose indeed that $P_0 = (1-\epsilon) P_1 + \epsilon Q$. Then the absolute continuity condition $P_1 \ll P_0$ follows since $\epsilon < 1$. Thus by the Radon Nikodym theorem $h=\frac{dP_1}{dP_0}$ exists. Since $Q$ is a probability measure, for any non-negative bounded (measurable) function $f$ we have
	$$
	P_0(f) - (1-\epsilon) P_1(f) = \epsilon Q(f) \geq 0,
	$$
	where we use the notation $\mu(f) \doteq \int f d\mu$. Noting $P_1(f) = P_0(hf)$, we thus obtain that
	\begin{equation}
		\label{eq:non-negative}
		\int f dP_0 \geq (1-\epsilon) \int f h dP_0 \qquad \text{ for each bounded } f \geq 0. 
	\end{equation}
	This shows that $h$ is bounded above by $\frac{1}{1-\epsilon}$ almost surely.
	
	Now let us show the ``if'' condition. Suppose $h = \frac{dP_1}{dP_0}$ exists and is bounded above by $\frac{1}{1-\epsilon}$.
	Then equation \eqref{eq:non-negative} is seen to be satisfied. 
	Let us assume $\epsilon > 0$, since $\epsilon = 0$ means that $P_1 = P_0$ and there is nothing to show. This allows us to define the signed measure $Q$ given by 
	$$
	Q(f) \doteq \frac{P_0(f) - (1-\epsilon) P_1(f)}{\epsilon}
	$$
	for every bounded $f$. Since $Q(f) \geq 0$ for each $f \geq 0$, this implies that $Q$ is indeed a non-negative measure. It is indeed a probability measure since $Q(1) = \frac{P_0(1) - (1-\epsilon)P_1(1)}{\epsilon} = 1$. Finally, the result that $P_0 = (1-\epsilon) P_1 + \epsilon Q$ holds by the way $Q$ was defined.
\end{proof}

\iffalse
The following is a rough bound on the integrals with respect to arbitrary $Q \in \cP(\cX)$ in terms of a based measure $P$ and the KL term $\KL(Q|P)$.

\begin{proposition}
	\label{prop:klbound}
	For a non-negative function $f: \cX \to \Rnn$,  $\sigma \geq 1$, and $P, Q \in \cP(\cX)$ we have the bound
	\begin{equation*}
		\int f dQ \leq \int e^{\sigma f} dP + \frac{1}{\sigma} \KL(Q|P).
	\end{equation*}
\end{proposition}
\begin{proof} We may focus on the case $Q \ll P$, since otherwise the term on the right takes the value $+\infty$. Next, following the trick in \cite[Lemma 2.4]{budhiraja2019analysis}, note from the fact $\sup_{a \in \R} [ab - e^{\sigma a}] = (b/\sigma)(\log (b/\sigma) - 1)$ that the inequality $ab \leq e^{\sigma a} + \frac{1}{\sigma}
	(b \log b - b +1)$ holds for every $a, b \geq 0$ and $\sigma \geq 1$. Let $g \doteq  \frac{dQ}{dP}$ and apply the last inequality with $a=f$ and $b=g$ to see that:
	\begin{align*}
		\int f dQ =  \int f g dP  = \int e^{\sigma f} dP + \frac{1}{\sigma}\left(\int g (\log g) dP - \int g dP + 1 \right) = \int e^{\sigma f} dP + \frac{1}{\sigma}\KL(Q|P)
	\end{align*}
\end{proof}


\begin{lemma}
	\begin{enumerate}
		\item the function $F(w,\theta) \doteq  \sum_{i=1}^n [w_i \log w_i - w_i \log  p_\theta(x_i)]$ is continuous jointly as a function of $(w, \theta)$.
		\item the maps $H: \Delta_n \mapsto \Theta$ given by $H(w)= \argmin_{\theta \in \Theta} F(w, \theta)$ and $G: \Theta \mapsto \Delta_n$ given by $G(\theta) = \argmin_{w \in \Delta_n} F(w,\theta)$ are well-defined and continuous.
	\end{enumerate}
	Let $\Theta_\epsilon \doteq \{ \theta |  (H \circ G)(\theta) = \theta \}$; Then the distance to this set $d(\theta^t, \Theta_\epsilon)$ converges zero as $t \to \infty$.
\end{lemma}
\begin{proof}
	Indeed, if this is not the case, since the sequence $\{(w_t, \theta_t)\}_{t=1}^\infty$ lies in the compact set $\Delta_n \times K$ where $K \doteq \operatorname{Img}(H)$, we can choose a limit point $(w^\infty, \theta^\infty)$ for this sequence so that $\theta^\infty \in K \setminus \Theta_I$. Suppose $(w^\infty, \theta^\infty) = \lim_{k \to \infty} (w^{t_k}, \theta^{t_k})$ for some strictly increasing sub-sequence $\{t_k\}_{k \in \nat}$. Using \eqref{eq:montone-iterations} the the continuity of $F$, $F(w^\infty, \theta^\infty) = \liminf_{k \to \infty} F(w^{t_k}, \theta^{t_k}) = \liminf_{t \to \infty} F(w^t, \theta^t)$. Since $w^{t+1} = G(\theta^t)$ and $\theta^{t+1} = H(w^{t+1})$, the continuity assumption show that $F(w^\infty, H(w^\infty)) = \lim_{k \to \infty} F(w^{t_k}, \theta^{t_k}) = F(w^\infty, \theta^\infty)$. Similarly, using the continuity and \eqref{eq:montone-iterations},  $F(G(\theta^\infty), \theta^\infty) = \lim_{k \to \infty} F(w^{t_k+1}, \theta^{t_k}) \geq \lim_{k \to \infty} F(w^{t_k+1}, \theta^{t_k+1}) = F(w^\infty, \theta^\infty)$. By the uniqueness of the minimizers in the definition of $H$ and $G$, we have $w^\infty = G(\theta^\infty)$ and $\theta^\infty = H(w^\infty)$. Hence $\theta^\infty \in \Theta_\epsilon$ -- a contradiction.
\end{proof}
\fi
