


\section{Producing Anticommutators and Exponential Products}
In this section, we formalize our technique to build polynomials of block encodings in both Fock and phase space. This is notable because it shows how Hermiticity is not a requirement for our compilation scheme: whereas phase-space operators $\hat{x}$ and $\hat{p}$ are Hermitian, Fock operators $a, a^\dagger$ are decidedly non-Hermitian.

We first show how our hybrid \qq~architecture allows for the synthesis of anticommutators of Hermitian operators and, by proxy, matrix products of phase-space operators. We then use similar techniques with non-Hermitian operators such as Fock-space operators to manipulate block encodings of matrices. Finally, we contextualize these methods with asymptotic error bounds, providing theoretical analyses of our proposed techniques.








\begin{table}
    \small
    \centering
    \begin{tabularx}{\textwidth}{ccll}
        \hline
        \textbf{Formula} & \textbf{Target} &\textbf{Preconditions} & \textbf{Reference} \\
        \hline
        $\textrm{BCH}(it \sigma^i B , it \sigma^i A )$ & $\exp( t^2 [A, B]) \identity$ &$A, B$ Hermitian &\cref{thm:BCH}  \\
        $\textrm{BCH}(it \sigma^j A , it \sigma^k B ) $ & $\exp(- i t^2 \sigma^i \{ A, B \} )$ &$A, B$ Hermitian &\cref{eq:sigmazterm} \\
                \hline
         $\textrm{BCH}(X \cdot  i t \mathcal{B}_B \cdot X, it \mathcal{B}_A )$ & $\exp\sigma^z (t^2 (AB - (AB)^\dagger) )$ & $[A,B]=0$ &\cref{eq:C2}\\
         $\textrm{BCH}(S \cdot it \mathcal{B}_A \cdot S^\dagger, X \cdot it \mathcal{B}_B \cdot  X) $ & $\exp(i t^2 \sigma^z (AB + (AB)^\dagger) ) $ & $[A,B]=0$ & \cref{eq:AC2}\\
         $\textrm{BCH}(S\cdot  it \mathcal{B}_A \cdot S^\dagger, X \cdot it \mathcal{B}_B \cdot X) $ & $\exp(2 i t^2 \sigma^z AB  )$ & \makecell[l]{$[A,B]=0$, \\$AB = (AB)^\dagger $} &\cref{eq:Product} \\
         $X \cdot \textrm{Trotter}\Big(t \sigma^y (AB - (AB)^\dagger) , $ & $\exp\Big(2 it \begin{bmatrix}
            0 & AB \\
            (AB)^\dagger & 0
        \end{bmatrix} \Big) $ & $[A,B]=0$ &\cref{thm:general-adder-error}\\
            \qquad$ it \sigma^x (AB + (AB)^\dagger) \Big) \cdot X$ & \\
         $\textrm{BCH}(S \cdot i t \mathcal{B}_{A} \cdot S^\dagger, X \cdot i t \mathcal{B}_{B} \cdot X)$ & $\exp\left(it \begin{bmatrix}
            2 AB & 0 \\
            0 & -BA - (BA)^\dagger
        \end{bmatrix}\right)$ & $AB = (AB)^\dagger$ &\cref{lem:multiplication-alg}
    \end{tabularx}
    \caption{
    Overview of techniques for synthesizing particular unitary transformations and the quantum gates needed. Our formulas allow the manipulations of broad classes of Hamiltonian block encodings, denoted $\mathcal{B}_A, \mathcal{B}_B$. Each row contains the formula used, the target to approximate, the preconditions, and a reference to the location of the precise statement of the performance of the method. Most formulas use `conjugated' hamiltonians ($U H U^\dagger$) which can be achieved via conjugation of the exponential. The formula provided denotes hybrid gates with $\sigma^i$ terms, and single-qubit gates are capitalized (e.g., $S, X, H$). The bounds on the number of gates depend on the accuracy required of the approximation and are given in the corresponding theorems. 
    }
    \label{tab:all-formulas}
\end{table}







\subsection{Intuition of polynomial building via anticommutators in phase space}
Our \qq~architecture uses BCH to natively implement anticommutator-like exponentials by exploiting the qubit's Hilbert space. In conjunction with Trotter, these anticommutators are used to build larger block encodings; we generate nontrivial transformations like beamsplitters and the Hong-Ou Mandel effect in~\cref{sec:applications}. 



To begin, we recall the  \qq~commutators
\begin{align}
    [\hat{x}, \hat{p}] = \frac{i}{2} \qquad \sigma^{i} & =\epsilon_{ijk}\frac{i}{2}\left[\sigma^{j},\sigma^{k}\right],\label{eq:PauliCommutator}
\end{align}
where $\epsilon_{ijk}$ is the Levi-Civita symbol, and $i,j,k \in \{x,y,z\}$. We use these relations, as well as the Pauli product identity 
\begin{align}
\sigma^{i} & =\epsilon_{ijk}i\sigma^{j}\sigma^{k}\label{eq:PauliProduct}
\end{align}
to decompose the anticommutator $\sigma_{i} \left\{ A,B\right\} $ in terms of a \qumode-qubit commutator
\begin{align}
    [i \sigma^j A, i \sigma^k B] &= - \sigma^j \sigma^k AB + \sigma^k \sigma^j BA \nonumber \\
    &= i \epsilon_{ijk} \sigma^i AB - i \sigma^i BA \nonumber \\
    &= i \epsilon_{ijk} \sigma^i \{ A, B \} \label{eq:sigmazterm}.
\end{align}
Note this assumes $A, B \in \mathcal{H}_{\Lambda + 1}$ are Hermitian so that $\exp[i \sigma^j A]$ is unitary and commutes with $\sigma^{i}$, as is the case when $A, B$ are mode-only operators. Thus, by using a hybrid qubit-cavity operation of the form $\exp i A \sigma^j, \exp i B \sigma^k$, the BCH formula can convert commutators into anticommutators. 

Finally, because $\frac{1}{2}[A, B] + \frac{1}{2} \{A , B\} = AB$, we use the Trotter formula to produce
\begin{align}
    \trotter \left(\frac{1}{2} \sigma^i [A, B], \frac{1}{2} \sigma^i \{ A, B \} \right) \approx \exp (\sigma^i AB),
\end{align}
assuming we may implement $\exp \left(\frac{1}{2} \sigma^i [A, B]\right)$ via a traditional BCH formula.





\subsection{Polynomial building non-Hermitian block encodings in Fock space}
In this section, we show how to achieve $A^q$ for an arbitrary \qumode~operator $A$. We also show that our techniques work in a multi-\qumode~setting. This extends the prior techniques, which require $A$ to be Hermitian. When $A$ is a Fock space operator, this corresponds to realizing arbitrary powers of $a$ and $a^{\dagger}$, which is known to generate a universal set of operations on the \qumode. This is useful for the simulation of nonlinear materials, which naturally lead to terms that are polynomial in $a, a^\dagger$, as well as quantum signal processing~\cite{martyn2021grand}. 

Our method again uses the qubit coupling to induce a phase in the compound \qq~system, similar to the previous section. We begin with block encodings as described in Eq.~\ref{eq:blockencodedmatrix}. 
To manipulate the block encodings, we begin by recognizing that qubit-only operations can modify the exponential via ``conjugation,",i.e.
\begin{align}
    U e^A U^\dagger = e^{U A U^\dagger}.
\end{align}
Thus, given any block encoding, we can also create the auxiliaries
\begin{align}
    X \cdot \exp \left( it \mathcal{B}_A \right) \cdot X &=  \exp \left( it X \cdot \begin{bmatrix}
        0 & A \\
        A^\dagger & 0
    \end{bmatrix} \cdot X \right) = \exp it \begin{bmatrix}
        0 & A^\dagger \\
        A & 0
    \end{bmatrix} = \exp \left( it \mathcal{B}_{A^\dagger} \right), \\
    S \cdot \exp \left( it \mathcal{B}_A \right) \cdot S^\dagger &= \exp \left( it S \cdot \begin{bmatrix}
        0 & A \\
        A^\dagger & 0
    \end{bmatrix} \cdot S^\dagger \right) = \exp it \begin{bmatrix}
        0 & -i A \\
        i A^\dagger & 0
    \end{bmatrix} = \exp (it \mathcal{B}_{-iA}),
\end{align}
recalling that $S$ is a qubit phase gate. Applying BCH yields the commutators
\begin{align}
    \Big[X \cdot it \mathcal{B}_A \cdot X, it \mathcal{B}_A \Big] 
    &= - t^2 \left( \begin{bmatrix}
        (A^\dagger)^2 & 0 \\
        0 & A^2
    \end{bmatrix} - \begin{bmatrix}
        A^2 & 0 \\
        0 & (A^\dagger)^2
    \end{bmatrix} \right) \nonumber \\
    &= t^2 \sigma^z (A^2 - (A^\dagger)^2), \\
    \left[S \cdot it \mathcal{B}_A \cdot S^\dagger, X \cdot it \mathcal{B}_A \cdot X \right] 
    &= -t^2 \left( \begin{bmatrix}
        - i A^2 & 0 \\
        0 & i (A^\dagger)^2
    \end{bmatrix} - \begin{bmatrix}
        i (A^\dagger)^2 & 0 \\
        0 & - iA^2
    \end{bmatrix} \right) \nonumber \\
    &= i t^2 \sigma^z (A^2 + (A^\dagger)^2).
\end{align}
These commutators themselves can be conjugated. Recall that $H Z H = X$ and $SH Z HS^\dagger = Y$
\begin{align}
    SH \cdot \left[it \mathcal{B}_{A^\dagger}, it \mathcal{B}_A \right] \cdot HS^\dagger &=t^2 \sigma^y (A^2 - (A^\dagger)^2), \\
    H \cdot \left[it \mathcal{B}_{-iA} , it\mathcal{B}_{A^
    \dagger} \right] \cdot H &= i t^2 \sigma^x (A^2 + (A^\dagger)^2),
\end{align}
so that
\begin{align}
    i t^2 \sigma^x (A + (A^\dagger)^2) + t^2 \sigma^y (A^2 - (A^\dagger)^2) = 2 it^2 \begin{bmatrix}
        0 & (A^\dagger)^2 \\
        A^2 & 0
    \end{bmatrix}.
\end{align}
Thus, using only $\mathcal{B}_A(t)$ gates, we can approximate $\mathcal{B}_{A^2}$. 

We now lift this procedure to produce $\exp it \mathcal{B}_{AB}$ given $\exp it \mathcal{B}_A, \exp it \mathcal{B}_B$ for commuting $A, B \in \mathcal{H}_{\Lambda + 1}$. Observe the following commutators (whose exponentials we can implement via BCH)
\begin{align}
    \left[ i \tau \mathcal{B}_{B^\dagger}, i \tau \mathcal{B}_A \right]
    &= \tau^2 \begin{bmatrix}
        AB - (AB)^\dagger & 0 \\
        0 & (BA)^\dagger - BA
    \end{bmatrix}, \\
    \left[ i \tau \mathcal{B}_{-iA}, i \tau \mathcal{B}_{B^\dagger} \right]
    &= i\tau^2 \begin{bmatrix}
        AB + (AB)^\dagger & 0 \\
        0 & -BA - (BA)^\dagger
    \end{bmatrix}. \label{eq:also-alg2}
\end{align}
Provided that $[A, B] = 0$ and via conjugation,
the equality simplifies to
\begin{align}
    SH \cdot  \Big[ it \mathcal{B}_{B^\dagger}, it \mathcal{B}_{A}\Big] \cdot HS^\dagger &= 
    \tau^2 \sigma^y(AB - (AB)^\dagger)  \label{eq:C2},\\
    H \cdot \Big[ it \mathcal{B}_{-iA}  , it \mathcal{B}_{B^\dagger}  \Big] \cdot H &= 
    i\tau^2 \sigma^x (AB + (AB)^\dagger) \label{eq:AC2}.
\end{align}
Via Trotter, we can directly implement the sum:
\begin{align}
    \tau^2 (AB - (AB)^\dagger) \sigma^y  + i\tau^2 \sigma^x  (AB + (AB)^\dagger)   = 2 i \tau^2 \begin{bmatrix}
        0 & (AB)^\dagger \\
        AB & 0
    \end{bmatrix}\label{eq:Product}.
\end{align}
We select $\tau = \sqrt{\frac{t}{2}}$ to obtain the desired time and conjugate by $\sigma^x$ to produce the desired matrix. 

This procedure is described in \cref{alg:adder} and thus allows us to approximate $\exp i t \mathcal{B}_{AB}$. This process can be repeated iteratively, assuming $AB$ commutes with $B$; for example, if $A = B = a$, then this process can be used to produce higher powers $a^k, (a^\dagger)^k$.

Our formulas require $[A, B] = 0$ to build higher order polynomials. This requirement is tolerable, as we still may achieve a broad class of transformations, including homogeneous polynomials of $a$ or $a^\dagger$. 
Our formulas can also be extended to more general cases where the operators commute, e.g. when the synthesized unitary operates on two different \qumodes, as in the conditional beamsplitter (a gate that acts as a beamsplitter controlled on an ancillary qubit).

\cref{alg:adder} is an extension of the prior commutator approaches in phase space because the $\sigma^i = - \frac{i}{2} [\sigma^j, \sigma^k]$ relation is natively expressed in the algorithm; i.e., if we have $\mathcal{B}_{A} = \mathcal{B}_B =  \mathcal{B}_{\hat{x}} = \exp it \hat{x} \sigma^x$, the ``$\textrm{Left}$" term vanishes and the``$\textrm{Right}$" term is the commutator we would apply.


Finally, in \cref{alg:mult}, we demonstrate how to implement $AB$ if $AB = (AB)^\dagger$. This process places $AB$ in the upper left block, which is useful to exactly execute $\exp it AB$ by preparing the qubit state to $\ket{0}$, but it prevents the process from being executed recursively. Simplifying the commutator from \cref{eq:also-alg2} finds
\begin{align}
    \left[ i \tau \mathcal{B}_{-i A}, i \tau \mathcal{B}_{B^\dagger}  \right] = i \tau^2 \begin{bmatrix}
        2 AB & 0 \\
        0 & -BA - (BA)^\dagger
    \end{bmatrix}.
\end{align}



 


\subsection{Error analysis}
The prior description of our algorithm assumes errorless product formulas. However, the BCH and Trotter formulas  introduce errors which must be accounted for, especially when applying our algorithm recursively. In this section, we cite the error scaling of the general addition algorithm described in \cref{alg:adder} and the multiplication algorithm described in \cref{alg:mult}. The proofs and full results are included in \cref{apndx:error-analysis}.

\begin{algorithm}[t]
\caption{ADD($\mathcal{B}_A (t), \mathcal{B}_B(t), p_l, p_r, t$) }\label{alg:adder}
\begin{algorithmic}
\Require $[A, B] = 0$, $\norm{\mathcal{B}_A - \exp it \begin{bmatrix}
    0 & A \\
    A^\dagger & 0
\end{bmatrix} } \in \mathcal{O}((c_A t)^{p_A})$, $\norm{\mathcal{B}_B - \exp it \begin{bmatrix}
    0 & B \\
    B^\dagger & 0
\end{bmatrix} } \in \mathcal{O}((c_B t)^{p_B})$, $p_A, p_B \geq 1$, $t > 0$
\Ensure $\mathcal{B}_{AB}$ where $\norm{\mathcal{B}_{AB}(t) - \exp it \begin{bmatrix}
    0 & AB \\
    (AB)^\dagger & 0
\end{bmatrix}} \in \mathcal{O}((Ct)^{\min (p_A, p_B) / 2})$ for constant $C$
\State $q \coloneqq \max ( \ceil{\frac{1}{2}(\min(p_l, p_r) - 1)}, 1 )$
\State $s \coloneqq \max ( \ceil{\frac{1}{2} ( \min(p_l, p_r) - 1)}, 1 )$
\State $\tau \coloneqq \sqrt{t / 2}$
\State Left $\coloneqq \bch_{q, 1}(X \cdot i \tau \mathcal{B}_B \cdot X, i \tau \mathcal{B}_A)$
\State Right $\coloneqq \bch_{q, 1}(S\cdot i \tau  \mathcal{B}_A \cdot S^\dagger, X \cdot i \tau  \mathcal{B}_B \cdot X)$
\State Left' $\coloneqq SH \cdot \textrm{Left} \cdot HS^\dagger$
\State Right' $\coloneqq H \cdot \textrm{Right} \cdot H$ 
\State \Return $X \cdot \trotter_s(\textrm{Left'}, \textrm{Right'}) \cdot X$
\end{algorithmic}
\end{algorithm}


\begin{algorithm}[t]
\caption{MULT($\mathcal{B}_A (t), \mathcal{B}_B(t), p_l, p_r, t$) }\label{alg:mult}
\begin{algorithmic}
\Require $AB = (AB)^\dagger$, $p_l, p_r \geq 1$, $t > 0$
\Ensure An upper-left block encoding $\mathcal{M}_{AB}$ where $\norm{\mathcal{M}_{AB}(t) - \exp it \begin{bmatrix}
    AB & 0 \\
    0 & \frac{1}{2} ( - BA - (BA)^\dagger)
\end{bmatrix}} \in \mathcal{O}( (C^2 t)^{\min (p_A, p_B) / 2} )$ for constant $C$
\State $q \coloneqq \max ( \ceil{\frac{1}{2}(\min(p_l, p_r) - 1)}, 1 )$
\State $\tau \coloneqq \sqrt{t / 2}$
\State \Return $\textrm{BCH}_q(S \cdot i \tau \mathcal{B}_{A} \cdot S^\dagger, X \cdot i \tau \mathcal{B}_{B} \cdot X) $
\end{algorithmic}
\end{algorithm}




\begin{restatable}{theorem}{algproduct}\label{thm:general-adder-error}
    Suppose we have approximations $\widetilde{\mathcal{B}}_A(t), \widetilde{\mathcal{B}}_B(t)$ with the error scaling
    \begin{align}
        \norm{\exp it \widetilde{\mathcal{B}}_A - \exp it \mathcal{B}_A} &\in \mathcal{O}( (ct)^{p_A} ), \\
        \norm{
        \exp it\widetilde{\mathcal{B}}_B - \exp it\mathcal{B}_B} &\in \mathcal{O} ((ct)^{p_B} ), 
    \end{align}
    for some constant $c$ and order $p_A, p_B \geq 1$ where $[A,B]=0$. Then, the application of \cref{alg:adder} will yield the scaling
    \begin{align}
        \norm{{\rm{ADD}} ( it \widetilde{\mathcal{B}}_A, it \widetilde{\mathcal{B}}_B) - \exp it \mathcal{B}_{AB}} \in \mathcal{O} \left((C_{TOTAL} t)^{\min(p_A, p_B) / 2}\right),
    \end{align}
    with $C_{TOTAL} = \max( \norm{AB}, \norm{BA}, C_{BCH}^2)$ and $C_{BCH} = \max( \norm{A}, \norm{B}, c)$,
    using no more than $ 1.07 \cdot 30^q $ exponentials, where $q = \max (\ceil{\frac{\min(p_1, p_2) - 1}{2}}, 1) $. 
\end{restatable}



\begin{restatable}{theorem}{algmult}\label{lem:multiplication-alg}
    Suppose we have approximate block encodings $\widetilde{\mathcal{B}}_A, \widetilde{\mathcal{B}}_B$  with the error
    \begin{align}
        \norm{\exp it \widetilde{\mathcal{B}}_A - \exp it \begin{bmatrix}
            0 & A \\
            A^\dagger & 0
        \end{bmatrix}} &\in \mathcal{O}( (ct)^{p_A}), \\
        \norm{\exp it \widetilde{\mathcal{B}}_B - \exp it \begin{bmatrix}
            0 & B \\
            B^\dagger & 0
        \end{bmatrix}} &\in \mathcal{O} ((ct)^{p_B}),
    \end{align}
    for constant $c$ and $p_A, p_B \geq 1$ where $AB = (AB)^\dagger$.
    Then, \cref{alg:mult} has the error
    \begin{align}
        \norm{ {\rm{MULT}}( it \widetilde{\mathcal{B}}_A,   it \widetilde{\mathcal{B}}_B) - \exp it \begin{bmatrix}
            AB & 0 \\
            0 & \frac{1}{2}( - BA - (BA)^\dagger)
        \end{bmatrix}} \in \mathcal{O}\left((C^2 t)^{\min (p_A, p_B) / 2}\right),
    \end{align}
    with $C = \max(\norm{A}, \norm{B}, c)$, using no more than $8 \cdot 6^{q - 1}$ exponentials where $q = \max ( \ceil{\frac{\min(p_A, p_B) - 1}{2}}, 1) $.
\end{restatable}

While the asymptotic error analysis suggests that the cost of this method is onerous, we note that the product formulas often have overly pessimistic error scaling and operation counts \cite{zhao2021hamiltonian}. In the applications below, we provide numerical simulations which suggest our technique is more readily implementable than theory suggests.






