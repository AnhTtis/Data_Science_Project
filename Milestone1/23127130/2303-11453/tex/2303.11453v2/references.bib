@article{mendelson2014singular,
  title={On the singular values of random matrices},
  author={Mendelson, Shahar and Paouris, Grigoris},
  journal={Journal of the European Mathematical Society},
  volume={16},
  number={4},
  pages={823--834},
  year={2014}
}

@inproceedings{Daniely2014OptimalLF,
  title={Optimal learners for multiclass problems},
  author={Amit Daniely and S. Shalev-Shwartz},
  booktitle={COLT},
  year={2014}
}

@article{https://doi.org/10.48550/arxiv.1711.02838,
  title={Stochastic cubic regularization for fast nonconvex optimization},
  author={Tripuraneni, Nilesh and Stern, Mitchell and Jin, Chi and Regier, Jeffrey and Jordan, Michael I},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{krahmer2011new,
  title={New and improved Johnson--Lindenstrauss embeddings via the restricted isometry property},
  author={Krahmer, Felix and Ward, Rachel},
  journal={SIAM Journal on Mathematical Analysis},
  volume={43},
  number={3},
  pages={1269--1281},
  year={2011},
  publisher={SIAM}
}

@article{candes2011tight,
  title={Tight oracle inequalities for low-rank matrix recovery from a minimal number of noisy random measurements},
  author={Candes, Emmanuel J and Plan, Yaniv},
  journal={IEEE Transactions on Information Theory},
  volume={57},
  number={4},
  pages={2342--2359},
  year={2011},
  publisher={IEEE}
}

@article{loh2013regularized,
  title={Regularized M-estimators with nonconvexity: Statistical and algorithmic theory for local optima},
  author={Loh, Po-Ling and Wainwright, Martin J},
  journal={Advances in Neural Information Processing Systems},
  volume={26},
  year={2013}
}

@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@article{liu2018rethinking,
  title={Rethinking the value of network pruning},
  author={Liu, Zhuang and Sun, Mingjie and Zhou, Tinghui and Huang, Gao and Darrell, Trevor},
  journal={arXiv preprint arXiv:1810.05270},
  year={2018}
}

@inproceedings{https://doi.org/10.48550/arxiv.1703.00887,
  title={How to escape saddle points efficiently},
  author={Jin, Chi and Ge, Rong and Netrapalli, Praneeth and Kakade, Sham M and Jordan, Michael I},
  booktitle={International conference on machine learning},
  pages={1724--1732},
  year={2017},
  organization={PMLR}
}


@inproceedings{NEURIPS2018_069654d5,
 author = {Mokhtari, Aryan and Ozdaglar, Asuman and Jadbabaie, Ali},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Escaping Saddle Points in Constrained Optimization},
 url = {https://proceedings.neurips.cc/paper/2018/file/069654d5ce089c13f642d19f09a3d1c0-Paper.pdf},
 volume = {31},
 year = {2018}
}

@article{https://doi.org/10.48550/arxiv.1611.03530,
  title={Understanding deep learning (still) requires rethinking generalization},
  author={Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
  journal={Communications of the ACM},
  volume={64},
  number={3},
  pages={107--115},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{https://doi.org/10.48550/arxiv.1710.10345,
  title={The implicit bias of gradient descent on separable data},
  author={Soudry, Daniel and Hoffer, Elad and Nacson, Mor Shpigel and Gunasekar, Suriya and Srebro, Nathan},
  journal={The Journal of Machine Learning Research},
  volume={19},
  number={1},
  pages={2822--2878},
  year={2018},
  publisher={JMLR. org}
}

@inproceedings{park2017non,
  title={Non-square matrix sensing without spurious local minima via the Burer-Monteiro approach},
  author={Park, Dohyung and Kyrillidis, Anastasios and Carmanis, Constantine and Sanghavi, Sujay},
  booktitle={Artificial Intelligence and Statistics},
  pages={65--74},
  year={2017},
  organization={PMLR}
}

@article{gunasekar2017implicit,
  title={Implicit regularization in matrix factorization},
  author={Gunasekar, Suriya and Woodworth, Blake E and Bhojanapalli, Srinadh and Neyshabur, Behnam and Srebro, Nati},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{10.1214/aos/1015957395,
author = {B. Laurent and P. Massart},
title = {{Adaptive estimation of a quadratic functional by model selection}},
volume = {28},
journal = {The Annals of Statistics},
number = {5},
publisher = {Institute of Mathematical Statistics},
pages = {1302 -- 1338},
keywords = {$l_p$-bodies, adaptive estimation, Besov bodies, efficient estimation, Gaussian sequence model, Model selection, quadratic functionals},
year = {2000},
doi = {10.1214/aos/1015957395},
URL = {https://doi.org/10.1214/aos/1015957395}
}


@misc{https://doi.org/10.48550/arxiv.1802.05668,
  doi = {10.48550/ARXIV.1802.05668},
  
  url = {https://arxiv.org/abs/1802.05668},
  
  author = {Polino, Antonio and Pascanu, Razvan and Alistarh, Dan},
  
  keywords = {Neural and Evolutionary Computing (cs.NE), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Model compression via distillation and quantization},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{https://doi.org/10.48550/arxiv.1503.02531,
  doi = {10.48550/ARXIV.1503.02531},
  
  url = {https://arxiv.org/abs/1503.02531},
  
  author = {Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Distilling the Knowledge in a Neural Network},
  
  publisher = {arXiv},
  
  year = {2015},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{hdp,
  added-at = {2019-06-09T20:28:28.000+0200},
  author = {Vershynin, Roman},
  biburl = {https://www.bibsonomy.org/bibtex/29da0fdbecdd86a12bef65108c846edd8/kirk86},
  description = {HDP-book.pdf},
  interhash = {003cd7d6bc4132b9da72a900b7549ddb},
  intrahash = {9da0fdbecdd86a12bef65108c846edd8},
  keywords = {book foundations probability stats theory},
  timestamp = {2019-06-09T20:28:43.000+0200},
  title = {High-Dimensional Probability},
  url = {https://www.math.uci.edu/~rvershyn/papers/HDP-book/HDP-book.pdf},
  year = 2019
}

@article{nn-quadratic-ms,
  title={Theoretical insights into the optimization landscape of over-parameterized shallow neural networks},
  author={Soltanolkotabi, Mahdi and Javanmard, Adel and Lee, Jason D},
  journal={IEEE Transactions on Information Theory},
  volume={65},
  number={2},
  pages={742--769},
  year={2018},
  publisher={IEEE}
}

@article{rong,
  author    = {Rong Ge and
               Chi Jin and
               Yi Zheng},
  title     = {No Spurious Local Minima in Nonconvex Low Rank Problems: {A} Unified
               Geometric Analysis},
  journal   = {CoRR},
  volume    = {abs/1704.00708},
  year      = {2017},
  url       = {http://arxiv.org/abs/1704.00708},
  eprinttype = {arXiv},
  eprint    = {1704.00708},
  timestamp = {Wed, 07 Dec 2022 22:58:56 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/GeJZ17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{https://doi.org/10.48550/arxiv.1510.00149,
  doi = {10.48550/ARXIV.1510.00149},
  
  url = {https://arxiv.org/abs/1510.00149},
  
  author = {Han, Song and Mao, Huizi and Dally, William J.},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Neural and Evolutionary Computing (cs.NE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding},
  
  publisher = {arXiv},
  
  year = {2015},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{klivans,
  title={Good subnetworks provably exist: Pruning via greedy forward selection},
  author={Ye, Mao and Gong, Chengyue and Nie, Lizhen and Zhou, Denny and Klivans, Adam and Liu, Qiang},
  booktitle={International Conference on Machine Learning},
  pages={10820--10830},
  year={2020},
  organization={PMLR}
}


@misc{uglyhead,
  doi = {10.48550/ARXIV.2206.03345},
  
  url = {https://arxiv.org/abs/2206.03345},
  
  author = {Zhang, Gavin and Fattahi, Salar and Zhang, Richard Y.},
  title = {Preconditioned Gradient Descent for Overparameterized Nonconvex Burer--Monteiro Factorization with Global Optimality Certification},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{cong-wang-chi-chen-17,
  title={Implicit regularization in nonconvex statistical estimation: Gradient descent converges linearly for phase retrieval and matrix completion},
  author={Ma, Cong and Wang, Kaizheng and Chi, Yuejie and Chen, Yuxin},
  booktitle={International Conference on Machine Learning},
  pages={3345--3354},
  year={2018},
  organization={PMLR}
}

@inproceedings{laskey2017dart,
  title={Dart: Noise injection for robust imitation learning},
  author={Laskey, Michael and Lee, Jonathan and Fox, Roy and Dragan, Anca and Goldberg, Ken},
  booktitle={Conference on robot learning},
  pages={143--156},
  year={2017},
  organization={PMLR}
}

@article{xu2020error,
  title={Error bounds of imitating policies and environments},
  author={Xu, Tian and Li, Ziniu and Yu, Yang},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={15737--15749},
  year={2020}
}
@inproceedings{domingues2020episodic,
  title={Episodic reinforcement learning in finite mdps: Minimax lower bounds revisited},
  author={Domingues, Omar Darwiche and M{\'e}nard, Pierre and Kaufmann, Emilie and Valko, Michal},
  booktitle={Algorithmic Learning Theory},
  pages={578--598},
  year={2021},
  organization={PMLR}
}

@inproceedings{ng1999policy,
  title={Policy invariance under reward transformations: Theory and application to reward shaping},
  author={Ng, Andrew Y and Harada, Daishi and Russell, Stuart},
  booktitle={Icml},
  volume={99},
  pages={278--287},
  year={1999}
}

@article{salimans2018learning,
  title={Learning Montezuma's Revenge from a Single Demonstration},
  author={Salimans, Tim and Chen, Richard},
  journal={arXiv preprint arXiv:1812.03381},
  year={2018}
}

@article{berner2019dota,
  title={Dota 2 with large scale deep reinforcement learning},
  author={Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and D{\k{e}}biak, Przemys{\l}aw and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and others},
  journal={arXiv preprint arXiv:1912.06680},
  year={2019}
}

@inproceedings{abbeel2004apprenticeship,
  title={Apprenticeship learning via inverse reinforcement learning},
  author={Abbeel, Pieter and Ng, Andrew Y},
  booktitle={Proceedings of the twenty-first international conference on Machine learning},
  pages={1},
  year={2004}
}

@inproceedings{syed2008apprenticeship,
  title={Apprenticeship learning using linear programming},
  author={Syed, Umar and Bowling, Michael and Schapire, Robert E},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={1032--1039},
  year={2008}
}

@inproceedings{ratliff2006maximum,
  title={Maximum margin planning},
  author={Ratliff, Nathan D and Bagnell, J Andrew and Zinkevich, Martin A},
  booktitle={Proceedings of the 23rd international conference on Machine learning},
  pages={729--736},
  year={2006}
}

@inproceedings{ziebart2008maximum,
  title={Maximum entropy inverse reinforcement learning.},
  author={Ziebart, Brian D and Maas, Andrew L and Bagnell, J Andrew and Dey, Anind K},
  booktitle={Aaai},
  volume={8},
  pages={1433--1438},
  year={2008},
  organization={Chicago, IL, USA}
}

@article{torabi2018behavioral,
  title={Behavioral cloning from observation},
  author={Torabi, Faraz and Warnell, Garrett and Stone, Peter},
  journal={arXiv preprint arXiv:1805.01954},
  year={2018}
}
@inproceedings{nair2017combining,
  title={Combining self-supervised learning and imitation for vision-based rope manipulation},
  author={Nair, Ashvin and Chen, Dian and Agrawal, Pulkit and Isola, Phillip and Abbeel, Pieter and Malik, Jitendra and Levine, Sergey},
  booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={2146--2153},
  year={2017},
  organization={IEEE}
}

@article{pan2017agile,
  title={Agile autonomous driving using end-to-end deep imitation learning},
  author={Pan, Yunpeng and Cheng, Ching-An and Saigol, Kamil and Lee, Keuntaek and Yan, Xinyan and Theodorou, Evangelos and Boots, Byron},
  journal={arXiv preprint arXiv:1709.07174},
  year={2017}
}


@inproceedings{sun2017deeply,
  title={Deeply aggrevated: Differentiable imitation learning for sequential prediction},
  author={Sun, Wen and Venkatraman, Arun and Gordon, Geoffrey J and Boots, Byron and Bagnell, J Andrew},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={3309--3318},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{arora2020provable,
  title={Provable representation learning for imitation learning via bi-level optimization},
  author={Arora, Sanjeev and Du, Simon and Kakade, Sham and Luo, Yuping and Saunshi, Nikunj},
  booktitle={International Conference on Machine Learning},
  pages={367--376},
  year={2020},
  organization={PMLR}
}

@article{han2015,
  title={Learning both weights and connections for efficient neural network},
  author={Han, Song and Pool, Jeff and Tran, John and Dally, William},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@inproceedings{finn2016guided,
  title={Guided cost learning: Deep inverse optimal control via policy optimization},
  author={Finn, Chelsea and Levine, Sergey and Abbeel, Pieter},
  booktitle={International conference on machine learning},
  pages={49--58},
  year={2016}
}


@article{reddy2019sqil,
  title={Sqil: Imitation learning via reinforcement learning with sparse rewards},
  author={Reddy, Siddharth and Dragan, Anca D and Levine, Sergey},
  journal={arXiv preprint arXiv:1905.11108},
  year={2019}
}


@inproceedings{zhang2020generative,
  title={Generative adversarial imitation learning with neural network parameterization: Global optimality and convergence rate},
  author={Zhang, Yufeng and Cai, Qi and Yang, Zhuoran and Wang, Zhaoran},
  booktitle={International Conference on Machine Learning},
  pages={11044--11054},
  year={2020},
  organization={PMLR}
}


@inproceedings{lee2018dynamic,
  title={A dynamic regret analysis and adaptive regularization algorithm for on-policy robot imitation learning},
  author={Lee, Jonathan N and Laskey, Michael and Tanwani, Ajay Kumar and Aswani, Anil and Goldberg, Ken},
  booktitle={International Workshop on the Algorithmic Foundations of Robotics},
  pages={212--227},
  year={2018},
  organization={Springer}
}

@article{fu2017learning,
  title={Learning robust rewards with adversarial inverse reinforcement learning},
  author={Fu, Justin and Luo, Katie and Levine, Sergey},
  journal={arXiv preprint arXiv:1710.11248},
  year={2017}
}

@inproceedings{ho2016generative,
  title={Generative adversarial imitation learning},
  author={Ho, Jonathan and Ermon, Stefano},
  booktitle={Advances in neural information processing systems},
  pages={4565--4573},
  year={2016}
}

@article{schaal1999imitation,
  title={Is imitation learning the route to humanoid robots?},
  author={Schaal, Stefan},
  journal={Trends in cognitive sciences},
  volume={3},
  number={6},
  pages={233--242},
  year={1999},
  publisher={Elsevier}
}

@inproceedings{ke2019imitation,
  title={Imitation learning as f-divergence minimization},
  author={Ke, Liyiming and Choudhury, Sanjiban and Barnes, Matt and Sun, Wen and Lee, Gilwoo and Srinivasa, Siddhartha},
  booktitle={Algorithmic Foundations of Robotics XIV: Proceedings of the Fourteenth Workshop on the Algorithmic Foundations of Robotics 14},
  pages={313--329},
  year={2021},
  organization={Springer}
}

@Article{GheshlaghiAzar2013,
author="Gheshlaghi Azar, Mohammad
and Munos, R{\'e}mi
and Kappen, Hilbert J.",
title="Minimax PAC bounds on the sample complexity of reinforcement learning with a generative model",
journal="Machine Learning",
year="2013",
month="Jun",
day="01",
volume="91",
number="3",
pages="325--349",
issn="1573-0565",
doi="10.1007/s10994-013-5368-1",
url="https://doi.org/10.1007/s10994-013-5368-1"
}


@inproceedings{Sidford:2018:VRV:3174304.3175320,
 author = {Sidford, Aaron and Wang, Mengdi and Wu, Xian and Ye, Yinyu},
 title = {Variance Reduced Value Iteration and Faster Algorithms for Solving Markov Decision Processes},
 booktitle = {Proceedings of the Twenty-Ninth Annual ACM-SIAM Symposium on Discrete Algorithms},
 series = {SODA '18},
 year = {2018},
 isbn = {978-1-6119-7503-1},
 location = {New Orleans, Louisiana},
 pages = {770--787},
 numpages = {18},
 url = {http://dl.acm.org/citation.cfm?id=3174304.3175320},
 acmid = {3175320},
 publisher = {Society for Industrial and Applied Mathematics},
 address = {Philadelphia, PA, USA},
} 


@incollection{NIPS1998_1531,
title = {Finite-Sample Convergence Rates for Q-Learning and Indirect Algorithms},
author = {Michael J. Kearns and Satinder P. Singh},
booktitle = {Advances in Neural Information Processing Systems 11},
editor = {M. J. Kearns and S. A. Solla and D. A. Cohn},
pages = {996--1002},
year = {1999},
publisher = {MIT Press},
url = {http://papers.nips.cc/paper/1531-finite-sample-convergence-rates-for-q-learning-and-indirect-algorithms.pdf}
}


@article{10.2307/2627210,
 ISSN = {00251909, 15265501},
 URL = {http://www.jstor.org/stable/2627210},
 author = {F. d'Epenoux},
 journal = {Management Science},
 number = {1},
 pages = {98--108},
 publisher = {INFORMS},
 title = {A Probabilistic Production and Inventory Problem},
 volume = {10},
 year = {1963}
}


@phdthesis{Littman:1996:ASD:924039,
 author = {Littman, Michael Lederman},
 title = {Algorithms for Sequential Decision-making},
 year = {1996},
 isbn = {0-591-16350-0},
 note = {AAI9709069},
 publisher = {Brown University},
 address = {Providence, RI, USA},
} 

@InProceedings{Ross-AIstats10,
  title = 	 {Efficient Reductions for Imitation Learning},
  author = 	 {Stephane Ross and Drew Bagnell},
  booktitle = 	 {Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics},
  pages = 	 {661--668},
  year = 	 {2010},
  editor = 	 {Yee Whye Teh and Mike Titterington},
  volume = 	 {9},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Chia Laguna Resort, Sardinia, Italy},
  month = 	 {13--15 May},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v9/ross10a/ross10a.pdf},
  url = 	 {http://proceedings.mlr.press/v9/ross10a.html},
}

@inproceedings{Beygelzimer05,
  author={Alina Beygelzimer and Varsha Dani and Thomas P. Hayes and John Langford and Bianca Zadrozny},
  title={Error limiting reductions between classification tasks},
  year={2005},
  cdate={1104537600000},
  pages={49-56},
  url={https://doi.org/10.1145/1102351.1102358},
  booktitle={ICML},
}

@inproceedings{kaariainen2006lower,
  title={Lower bounds for reductions},
  author={K{\"a}{\"a}ri{\"a}inen, Matti},
  booktitle={Atomic Learning Workshop},
  year={2006}
}

@inproceedings{Abbeel-Ng-ILviaIRL,
author = {Abbeel, Pieter and Ng, Andrew Y.},
title = {Apprenticeship Learning via Inverse Reinforcement Learning},
year = {2004},
isbn = {1581138385},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1015330.1015430},
doi = {10.1145/1015330.1015430},
booktitle = {Proceedings of the Twenty-First International Conference on Machine Learning},
pages = {1},
numpages = {8},
location = {Banff, Alberta, Canada},
series = {ICML ’04}
}

@incollection{Syed-Schapire-08,
title = {A Game-Theoretic Approach to Apprenticeship Learning},
author = {Syed, Umar and Schapire, Robert E},
booktitle = {Advances in Neural Information Processing Systems 20},
editor = {J. C. Platt and D. Koller and Y. Singer and S. T. Roweis},
pages = {1449--1456},
year = {2008},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/3293-a-game-theoretic-approach-to-apprenticeship-learning.pdf}
}

@incollection{Abbeel-Ng-helicopter,
title = {An Application of Reinforcement Learning to Aerobatic Helicopter Flight},
author = {Abbeel, Pieter and Adam Coates and Morgan Quigley and Andrew Y. Ng},
booktitle = {Advances in Neural Information Processing Systems 19},
editor = {B. Sch\"{o}lkopf and J. C. Platt and T. Hoffman},
pages = {1--8},
year = {2007},
publisher = {MIT Press},
url = {http://papers.nips.cc/paper/3151-an-application-of-reinforcement-learning-to-aerobatic-helicopter-flight.pdf}
}


@incollection{syed-schapire-10,
title = {A Reduction from Apprenticeship Learning to Classification},
author = {Syed, Umar and Schapire, Robert E},
booktitle = {Advances in Neural Information Processing Systems 23},
editor = {J. D. Lafferty and C. K. I. Williams and J. Shawe-Taylor and R. S. Zemel and A. Culotta},
pages = {2253--2261},
year = {2010},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/4180-a-reduction-from-apprenticeship-learning-to-classification.pdf}
}


@article{berend2013,
author = "Berend, Daniel and Kontorovich, Aryeh",
doi = "10.1214/ECP.v18-2359",
fjournal = "Electronic Communications in Probability",
journal = "Electron. Commun. Probab.",
pages = "7 pp.",
pno = "3",
publisher = "The Institute of Mathematical Statistics and the Bernoulli Society",
title = "On the concentration of the missing mass",
url = "https://doi.org/10.1214/ECP.v18-2359",
volume = "18",
year = "2013"
}


@inproceedings{GT-MM-conc,
author = {McAllester, David A. and Schapire, Robert E.},
title = {On the Convergence Rate of Good-Turing Estimators},
year = {2000},
isbn = {155860703X},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
booktitle = {Proceedings of the Thirteenth Annual Conference on Computational Learning Theory},
pages = {1–6},
numpages = {6},
series = {COLT ’00}
}

@article{GT,
 ISSN = {00063444},
 URL = {http://www.jstor.org/stable/2333344},
 author = {I. J. Good},
 journal = {Biometrika},
 number = {3/4},
 pages = {237--264},
 publisher = {[Oxford University Press, Biometrika Trust]},
 title = {The Population Frequencies of Species and the Estimation of Population Parameters},
 volume = {40},
 year = {1953}
}



@article{billingsley1961,
author = "Billingsley, Patrick",
doi = "10.1214/aoms/1177705136",
fjournal = "Annals of Mathematical Statistics",
journal = "Ann. Math. Statist.",
month = "03",
number = "1",
pages = "12--40",
publisher = "The Institute of Mathematical Statistics",
title = "Statistical Methods in Markov Chains",
url = "https://doi.org/10.1214/aoms/1177705136",
volume = "32",
year = "1961"
}


@article{ANGLUIN1979155,
title = "Fast probabilistic algorithms for hamiltonian circuits and matchings",
journal = "Journal of Computer and System Sciences",
volume = "18",
number = "2",
pages = "155 - 193",
year = "1979",
issn = "0022-0000",
doi = "https://doi.org/10.1016/0022-0000(79)90045-X",
url = "http://www.sciencedirect.com/science/article/pii/002200007990045X",
author = "D. Angluin and L.G. Valiant",
abstract = "We describe and analyse three simple efficient algorithms with good probabilistic behaviour; two algorithms with run times of O(n(log n)2) which almost certainly find directed (undirected) Hamiltonian circuits in random graphs of at least cn log n edges, and an algorithm with a run time of O(n log n) which almost certainly finds a perfect matching in a random graph of at least cn log n edges. Auxiliary propositions regarding conversion between input distributions and the “de-randomization” of randomized algorithms are proved. A new model, the random access computer (RAC), is introduced specifically to treat run times in low-level complexity."
}


@InProceedings{wen-sun-ILFO,
  title = 	 {Provably Efficient Imitation Learning from Observation Alone},
  author = 	 {Sun, Wen and Vemula, Anirudh and Boots, Byron and Bagnell, Drew},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {6036--6045},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Long Beach, California, USA},
  month = 	 {09--15 Jun},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/sun19b/sun19b.pdf},
  url = 	 {http://proceedings.mlr.press/v97/sun19b.html},
  abstract = 	 {We study Imitation Learning (IL) from Observations alone (ILFO) in large-scale MDPs. While most IL algorithms rely on an expert to directly provide actions to the learner, in this setting the expert only supplies sequences of observations. We design a new model-free algorithm for ILFO, Forward Adversarial Imitation Learning (FAIL), which learns a sequence of time-dependent policies by minimizing an Integral Probability Metric between the observation distributions of the expert policy and the learner. FAIL provably learns a near-optimal policy with a number of samples that is polynomial in all relevant parameters but independent of the number of unique observations. The resulting theory extends the domain of provably sample efficient learning algorithms beyond existing results that typically only consider tabular RL settings or settings that require access to a near-optimal reset distribution. We also demonstrate the efficacy ofFAIL on multiple OpenAI Gym control tasks.}
}

@article{Bojarski2016EndTE,
  title={End to End Learning for Self-Driving Cars},
  author={Mariusz Bojarski and Davide Del Testa and Daniel Dworakowski and Bernhard Firner and Beat Flepp and Prasoon Goyal and Lawrence D. Jackel and Mathew Monfort and Urs Muller and Jiakai Zhang and Xin Zhang and Jake Zhao and Karol Zieba},
  journal={ArXiv},
  year={2016},
  volume={abs/1604.07316}
}


@article{Merel2017LearningHB,
  title={Learning human behaviors from motion capture by adversarial imitation},
  author={Josh Merel and Yuval Tassa and TB Dhruva and Sriram Srinivasan and Jay Lemmon and Ziyu Wang and Greg Wayne and Nicolas Manfred Otto Heess},
  journal={ArXiv},
  year={2017},
  volume={abs/1707.02201}
}


@article{ARGALL2009469,
title = "A survey of robot learning from demonstration",
journal = "Robotics and Autonomous Systems",
volume = "57",
number = "5",
pages = "469 - 483",
year = "2009",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2008.10.024",
url = "http://www.sciencedirect.com/science/article/pii/S0921889008001772",
author = "Brenna D. Argall and Sonia Chernova and Manuela Veloso and Brett Browning",
keywords = "Learning from demonstration, Robotics, Machine learning, Autonomous systems",
abstract = "We present a comprehensive survey of robot Learning from Demonstration (LfD), a technique that develops policies from example state to action mappings. We introduce the LfD design choices in terms of demonstrator, problem space, policy derivation and performance, and contribute the foundations for a structure in which to categorize LfD research. Specifically, we analyze and categorize the multiple ways in which examples are gathered, ranging from teleoperation to imitation, as well as the various techniques for policy derivation, including matching functions, dynamics models and plans. To conclude we discuss LfD limitations and related promising areas for future research."
}


@inproceedings{DeepQlearning-demonstrations,
  title={Deep Q-learning From Demonstrations},
  author={Todd Hester and Matej Vecer{\'i}k and Olivier Pietquin and Marc Lanctot and Tom Schaul and Bilal Piot and Dan Horgan and John Quan and Andrew Sendonaris and Ian Osband and Gabriel Dulac-Arnold and John Agapiou and Joel Z. Leibo and Audrunas Gruslys},
  booktitle={AAAI},
  year={2018}
}


@article{IL4agile-driving,
author = {Yunpeng Pan and Ching-An Cheng and Kamil Saigol and Keuntaek Lee and Xinyan Yan and Evangelos A Theodorou and Byron Boots},
title ={Imitation learning for agile autonomous driving},
journal = {The International Journal of Robotics Research},
volume = {39},
number = {2-3},
pages = {286-302},
year = {2020},
doi = {10.1177/0278364919880273},

URL={https://doi.org/10.1177/0278364919880273
},
eprint = { 
        https://doi.org/10.1177/0278364919880273
    
}
,
    abstract = { We present an end-to-end imitation learning system for agile, off-road autonomous driving using only low-cost on-board sensors. By imitating a model predictive controller equipped with advanced sensors, we train a deep neural network control policy to map raw, high-dimensional observations to continuous steering and throttle commands. Compared with recent approaches to similar tasks, our method requires neither state estimation nor on-the-fly planning to navigate the vehicle. Our approach relies on, and experimentally validates, recent imitation learning theory. Empirically, we show that policies trained with online imitation learning overcome well-known challenges related to covariate shift and generalize better than policies trained with batch imitation learning. Built on these insights, our autonomous driving system demonstrates successful high-speed off-road driving, matching the state-of-the-art performance. }
}



@article{MoM,
author = {Blair, Charles},
title = {Problem Complexity and Method Efficiency in Optimization (A. S. Nemirovsky and D. B. Yudin)},
journal = {SIAM Review},
volume = {27},
number = {2},
pages = {264-265},
year = {1985},
doi = {10.1137/1027074},
URL = {https://doi.org/10.1137/1027074},
eprint = {https://doi.org/10.1137/1027074}
}

@inproceedings{Boucheron2013ConcentrationI,
  title={Concentration Inequalities - A Nonasymptotic Theory of Independence},
  author={St{\'e}phane Boucheron and G{\'a}bor Lugosi and Pascal Massart},
  booktitle={Concentration Inequalities},
  year={2013}
}



@article{Vinyals2019,
doi = {10.1038/s41586-019-1724-z},
issn = {1476-4687},
journal = {Nature},
number = {7782},
pages = {350--354},
title = {{Grandmaster level in StarCraft II using multi-agent reinforcement learning}},
url = {https://doi.org/10.1038/s41586-019-1724-z},
volume = {575},
year = {2019}
}


@inproceedings{Brantley2020Disagreement-Regularized,
title={Disagreement-Regularized Imitation Learning},
author={Kiante Brantley and Wen Sun and Mikael Henaff},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=rkgbYyHtwB}
}

@article{Ross2014ReinforcementAI,
  title={Reinforcement and Imitation Learning via Interactive No-Regret Learning},
  author={St{\'e}phane Ross and J. Andrew Bagnell},
  journal={ArXiv},
  year={2014},
  volume={abs/1406.5979}
}

@incollection{NIPS2018_8025,
title = {Reward learning from human preferences and demonstrations in Atari},
author = {Ibarz, Borja and Leike, Jan and Pohlen, Tobias and Irving, Geoffrey and Legg, Shane and Amodei, Dario},
booktitle = {Advances in Neural Information Processing Systems 31},
editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
pages = {8011--8023},
year = {2018},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/8025-reward-learning-from-human-preferences-and-demonstrations-in-atari.pdf}
}


@InProceedings{pmlr-v78-dosovitskiy17a,
title = {{CARLA}: {An} Open Urban Driving Simulator}, author = {Alexey Dosovitskiy and German Ros and Felipe Codevilla and Antonio Lopez and Vladlen Koltun}, booktitle = {Proceedings of the 1st Annual Conference on Robot Learning}, pages = {1--16}, year = {2017}, editor = {Sergey Levine and Vincent Vanhoucke and Ken Goldberg}, volume = {78}, series = {Proceedings of Machine Learning Research}, month = {13--15 Nov}, publisher = {PMLR}, pdf = {http://proceedings.mlr.press/v78/dosovitskiy17a/dosovitskiy17a.pdf}, url = {http://proceedings.mlr.press/v78/dosovitskiy17a.html}, abstract = {We introduce CARLA, an open-source simulator for autonomous driving research. CARLA has been developed from the ground up to support development, training, and validation of autonomous urban driving systems. In addition to open-source code and protocols, CARLA provides open digital assets (urban layouts, buildings, vehicles) that were created for this purpose and can be used freely. The simulation platform supports flexible specification of sensor suites and environmental conditions. We use CARLA to study the performance of three approaches to autonomous driving: a classic modular pipeline, an end-to-end model trained via imitation learning, and an end-to-end model trained via reinforcement learning. The approaches are evaluated in controlled scenarios of increasing difficulty, and their performance is examined via metrics provided by CARLA, illustrating the platform’s utility for autonomous driving research.} }


@article{MAL-018,
url = {http://dx.doi.org/10.1561/2200000018},
year = {2012},
volume = {4},
journal = {Foundations and Trends® in Machine Learning},
title = {Online Learning and Online Convex Optimization},
doi = {10.1561/2200000018},
issn = {1935-8237},
number = {2},
pages = {107-194},
author = {Shai Shalev-Shwartz}
}


@inproceedings{codevilla2019exploring,
  title={Exploring the limitations of behavior cloning for autonomous driving},
  author={Codevilla, Felipe and Santana, Eder and L{\'o}pez, Antonio M and Gaidon, Adrien},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9329--9338},
  year={2019}
}

@book{10.5555/2621980,
author = {Shalev-Shwartz, Shai and Ben-David, Shai},
title = {Understanding Machine Learning: From Theory to Algorithms},
year = {2014},
isbn = {1107057132},
publisher = {Cambridge University Press},
address = {USA},
abstract = {Machine learning is one of the fastest growing areas of computer science, with far-reaching applications. The aim of this textbook is to introduce machine learning, and the algorithmic paradigms it offers, in a principled way. The book provides an extensive theoretical account of the fundamental ideas underlying machine learning and the mathematical derivations that transform these principles into practical algorithms. Following a presentation of the basics of the field, the book covers a wide array of central topics that have not been addressed by previous textbooks. These include a discussion of the computational complexity of learning and the concepts of convexity and stability; important algorithmic paradigms including stochastic gradient descent, neural networks, and structured output learning; and emerging theoretical concepts such as the PAC-Bayes approach and compression-based bounds. Designed for an advanced undergraduate or beginning graduate course, the text makes the fundamentals and algorithms of machine learning accessible to students and non-expert readers in statistics, computer science, mathematics, and engineering.}
}

@inproceedings{cheng2018convergence,
  title={Convergence of value aggregation for imitation learning},
  author={Cheng, Ching-An and Boots, Byron},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1801--1809},
  year={2018},
  organization={PMLR}
}

@misc{cheng2018fast,
      title={Fast Policy Learning through Imitation and Reinforcement}, 
      author={Ching-An Cheng and Xinyan Yan and Nolan Wagener and Byron Boots},
      year={2018},
      eprint={1805.10413},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{rajaraman2021provably,
      title={Provably Breaking the Quadratic Error Compounding Barrier in Imitation Learning, Optimally}, 
      author={Nived Rajaraman and Yanjun Han and Lin F. Yang and Kannan Ramchandran and Jiantao Jiao},
      year={2021},
      eprint={2102.12948},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@article{DBLP:journals/corr/YouPWL17,
  author    = {Yurong You and
               Xinlei Pan and
               Ziyan Wang and
               Cewu Lu},
  title     = {Virtual to Real Reinforcement Learning for Autonomous Driving},
  journal   = {CoRR},
  volume    = {abs/1704.03952},
  year      = {2017},
  url       = {http://arxiv.org/abs/1704.03952},
  archivePrefix = {arXiv},
  eprint    = {1704.03952},
  timestamp = {Mon, 13 Aug 2018 16:49:09 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/YouPWL17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{reddy2019what,
title={What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning},
author={Siddharth Reddy and Anca D. Dragan and Sergey Levine},
year={2019},
url={https://openreview.net/forum?id=B1excoAqKQ},
}

@incollection{NIPS1988_95,
title = {ALVINN: An Autonomous Land Vehicle in a Neural Network},
author = {Pomerleau, Dean A.},
booktitle = {Advances in Neural Information Processing Systems 1},
editor = {D. S. Touretzky},
pages = {305--313},
year = {1989},
publisher = {Morgan-Kaufmann},
url = {http://papers.nips.cc/paper/95-alvinn-an-autonomous-land-vehicle-in-a-neural-network.pdf}
}


@article{JMLR:v15:judah14a,
  author  = {Kshitij Judah and Alan P. Fern and Thomas G. Dietterich and Prasad Tadepalli},
  title   = {Active Imitation Learning: Formal and Practical Reductions to I.I.D. Learning},
  journal = {Journal of Machine Learning Research},
  year    = {2014},
  volume  = {15},
  number  = {120},
  pages   = {4105-4143},
  url     = {http://jmlr.org/papers/v15/judah14a.html}
}

@article{donoho1988,
author = "Donoho, David L. and Liu, Richard C.",
doi = "10.1214/aos/1176350820",
fjournal = "Annals of Statistics",
journal = "Ann. Statist.",
month = "06",
number = "2",
pages = "552--586",
publisher = "The Institute of Mathematical Statistics",
title = "The ``Automatic'' Robustness of Minimum Distance Functionals",
url = "https://doi.org/10.1214/aos/1176350820",
volume = "16",
year = "1988"
}

@article{yatracos1985,
author = "Yatracos, Yannis G.",
doi = "10.1214/aos/1176349553",
fjournal = "Annals of Statistics",
journal = "Ann. Statist.",
month = "06",
number = "2",
pages = "768--774",
publisher = "The Institute of Mathematical Statistics",
title = "Rates of Convergence of Minimum Distance Estimators and Kolmogorov's Entropy",
url = "https://doi.org/10.1214/aos/1176349553",
volume = "13",
year = "1985"
}


@inproceedings{RossGB11,
  added-at = {2019-05-29T00:00:00.000+0200},
  author = {Ross, Stéphane and Gordon, Geoffrey J. and Bagnell, Drew},
  biburl = {https://www.bibsonomy.org/bibtex/2ac498c87961d968024282b8d340bac48/dblp},
  booktitle = {AISTATS},
  editor = {Gordon, Geoffrey J. and Dunson, David B. and Dudík, Miroslav},
  ee = {http://proceedings.mlr.press/v15/ross11a/ross11a.pdf},
  interhash = {60995151caa6bc50419bd5e98250ff96},
  intrahash = {ac498c87961d968024282b8d340bac48},
  keywords = {dblp},
  pages = {627-635},
  publisher = {JMLR.org},
  series = {JMLR Proceedings},
  timestamp = {2019-05-30T11:49:35.000+0200},
  title = {A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning.},
  url = {http://dblp.uni-trier.de/db/journals/jmlr/jmlrp15.html#RossGB11},
  volume = 15,
  year = 2011
}

@inproceedings{Luo2020Learning,
title={Learning Self-Correctable Policies and Value Functions from Demonstrations with Negative Sampling},
author={Yuping Luo and Huazhe Xu and Tengyu Ma},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=rke-f6NKvS}
}

@misc{zhu2018reinforcement,
title={Reinforcement and Imitation Learning for Diverse Visuomotor Skills},
author={Yuke Zhu and Ziyu Wang and Josh Merel and Andrei Rusu and Tom Erez and Serkan Cabi and Saran Tunyasuvunakool and János Kramár and Raia Hadsell and Nando de Freitas and Nicolas Heess},
year={2018},
url={https://openreview.net/forum?id=HJWGdbbCW},
}

@INPROCEEDINGS{McAllesterOrtiz,
    author = {David Mcallester and Luis Ortiz and Ralf Herbrich and Thore Graepel},
    title = {Concentration Inequalities for the Missing Mass and for Histogram Rule Error},
    booktitle = {Journal of Machine Learning Research},
    year = {2003},
    pages = {895--911}
}

@article{rajaraman2021linear,
  title={On the value of interaction and function approximation in imitation learning},
  author={Rajaraman, Nived and Han, Yanjun and Yang, Lin and Liu, Jingbo and Jiao, Jiantao and Ramchandran, Kannan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={1325--1336},
  year={2021}
}

@INPROCEEDINGS{rajaraman2020fundamental,
      title={Toward the Fundamental Limits of Imitation Learning}, 
      author={Nived Rajaraman and Lin F. Yang and Jiantao Jiao and Kannan Ramachandran},
      year={2020},
      booktitle = {Advances in Neural Information Processing Systems}
}

@article{DBLP:journals/corr/abs-1903-00640,
  author    = {Jianyu Chen and
               Bodi Yuan and
               Masayoshi Tomizuka},
  title     = {Deep Imitation Learning for Autonomous Driving in Generic Urban Scenarios
               with Enhanced Safety},
  journal   = {CoRR},
  volume    = {abs/1903.00640},
  year      = {2019},
  url       = {http://arxiv.org/abs/1903.00640},
  archivePrefix = {arXiv},
  eprint    = {1903.00640},
  timestamp = {Sat, 30 Mar 2019 19:27:21 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1903-00640.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{deep_compression,
  title={Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding},
  author={Han, Song and Mao, Huizi and Dally, William J},
  journal={arXiv preprint arXiv:1510.00149},
  year={2015}
}

@article{renda_20,
  doi = {10.48550/ARXIV.2003.02389},
  url = {https://arxiv.org/abs/2003.02389},
  author = {Renda, Alex and Frankle, Jonathan and Carbin, Michael},
  title = {Comparing Rewinding and Fine-tuning in Neural Network Pruning},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{AW02,
  title={Strong converse for identification via quantum channels},
  author={Ahlswede, Rudolf and Winter, Andreas},
  journal={IEEE Transactions on Information Theory},
  volume={48},
  number={3},
  pages={569--579},
  year={2002},
  publisher={IEEE}
}


@article{comparison-of-pruning,
  author    = {Davis W. Blalock and
               Jose Javier Gonzalez Ortiz and
               Jonathan Frankle and
               John V. Guttag},
  title     = {What is the State of Neural Network Pruning?},
  journal   = {CoRR},
  volume    = {abs/2003.03033},
  year      = {2020},
  url       = {https://arxiv.org/abs/2003.03033},
  eprinttype = {arXiv},
  eprint    = {2003.03033},
  timestamp = {Tue, 10 Mar 2020 13:33:48 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2003-03033.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ssl,
author = {Wen, Wei and Wu, Chunpeng and Wang, Yandan and Chen, Yiran and Li, Hai},
title = {Learning Structured Sparsity in Deep Neural Networks},
year = {2016},
isbn = {9781510838819},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {High demand for computation resources severely hinders deployment of large-scale Deep Neural Networks (DNN) in resource constrained devices. In this work, we propose a Structured Sparsity Learning (SSL) method to regularize the structures (i.e., filters, channels, filter shapes, and layer depth) of DNNs. SSL can: (1) learn a compact structure from a bigger DNN to reduce computation cost; (2) obtain a hardware-friendly structured sparsity of DNN to efficiently accelerate the DNN's evaluation. Experimental results show that SSL achieves on average 5.1 \texttimes{} and 3.1 \texttimes{} speedups of convolutional layer computation of AlexNet against CPU and GPU, respectively, with off-the-shelf libraries. These speedups are about twice speedups of non-structured sparsity; (3) regularize the DNN structure to improve classification accuracy. The results show that for CIFAR-10, regularization on layer depth reduces a 20-layer Deep Residual Network (ResNet) to 18 layers while improves the accuracy from 91.25\% to 92.60\%, which is still higher than that of original ResNet with 32 layers. For AlexNet, SSL reduces the error by ~ 1\%.},
booktitle = {Proceedings of the 30th International Conference on Neural Information Processing Systems},
pages = {2082–2090},
numpages = {9},
location = {Barcelona, Spain},
series = {NIPS'16}
}

@article{constantine21,
  author    = {Jiacheng Zhuo and
               Jeongyeol Kwon and
               Nhat Ho and
               Constantine Caramanis},
  title     = {On the computational and statistical complexity of over-parameterized
               matrix sensing},
  journal   = {CoRR},
  volume    = {abs/2102.02756},
  year      = {2021},
  url       = {https://arxiv.org/abs/2102.02756},
  eprinttype = {arXiv},
  eprint    = {2102.02756},
  timestamp = {Tue, 09 Feb 2021 13:35:56 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2102-02756.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Petrovitch1901,
author = {Petrovitch, Michel},
journal = {Mathematische Annalen},
pages = {417-436},
title = {Sur une manière d'étendre le théorème de la moyenne aux équations différentielles du premier ordre. (Mit 2 Figuren im Text)},
url = {http://eudml.org/doc/158006},
volume = {54},
year = {1901},
}

@article{Tropp_2011,
	doi = {10.1007/s10208-011-9099-z},
  
	url = {https://doi.org/10.1007%2Fs10208-011-9099-z},
  
	year = 2011,
	month = {aug},
  
	publisher = {Springer Science and Business Media {LLC}
},
  
	volume = {12},
  
	number = {4},
  
	pages = {389--434},
  
	author = {Joel A. Tropp},
  
	title = {User-Friendly Tail Bounds for Sums of Random Matrices},
  
	journal = {Foundations of Computational Mathematics}
}


@misc{l0_reg,
  doi = {10.48550/ARXIV.1712.01312},
  url = {https://arxiv.org/abs/1712.01312},
  author = {Louizos, Christos and Welling, Max and Kingma, Diederik P.},
  title = {Learning Sparse Neural Networks through $L_0$ Regularization},
  publisher = {arXiv},
  year = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{liu_slimming,
  title={Learning efficient convolutional networks through network slimming},
  author={Liu, Zhuang and Li, Jianguo and Shen, Zhiqiang and Huang, Gao and Yan, Shoumeng and Zhang, Changshui},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2736--2744},
  year={2017}
}


@misc{ye_pruning,
  doi = {10.48550/ARXIV.1802.00124},
  url = {https://arxiv.org/abs/1802.00124},
  author = {Ye, Jianbo and Lu, Xin and Lin, Zhe and Wang, James Z.},
  title = {Rethinking the Smaller-Norm-Less-Informative Assumption in Channel Pruning of Convolution Layers},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{https://doi.org/10.48550/arxiv.1912.01599,
  doi = {10.48550/ARXIV.1912.01599},
  
  url = {https://arxiv.org/abs/1912.01599},
  
  author = {Gamarnik, David and Kızıldağ, Eren C. and Zadik, Ilias},
  
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), Optimization and Control (math.OC), Probability (math.PR), Statistics Theory (math.ST), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Mathematics, FOS: Mathematics},
  
  title = {Stationary Points of Shallow Neural Networks with Quadratic Activation Function},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{seewong,
author = {Keshavan, Raghunandan and Oh, Sewoong},
year = {2009},
month = {10},
pages = {},
title = {A Gradient Descent Algorithm on the Grassman Manifold for Matrix
Completion},
volume = {910}
}

@inproceedings{chi_escaping,
  title={How to escape saddle points efficiently},
  author={Jin, Chi and Ge, Rong and Netrapalli, Praneeth and Kakade, Sham M and Jordan, Michael I},
  booktitle={International conference on machine learning},
  pages={1724--1732},
  year={2017},
  organization={PMLR}
}

@inproceedings{li_compression,
  title={Learning filter basis for convolutional neural network compression},
  author={Li, Yawei and Gu, Shuhang and Gool, Luc Van and Timofte, Radu},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5623--5632},
  year={2019}
}


@misc{he_2018,
  doi = {10.48550/ARXIV.1808.06866},
  url = {https://arxiv.org/abs/1808.06866},
  author = {He, Yang and Kang, Guoliang and Dong, Xuanyi and Fu, Yanwei and Yang, Yi},
  title = {Soft Filter Pruning for Accelerating Deep Convolutional Neural Networks},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{kusupati_20,
  title={Soft threshold weight reparameterization for learnable sparsity},
  author={Kusupati, Aditya and Ramanujan, Vivek and Somani, Raghav and Wortsman, Mitchell and Jain, Prateek and Kakade, Sham and Farhadi, Ali},
  booktitle={International Conference on Machine Learning},
  pages={5544--5555},
  year={2020},
  organization={PMLR}
}

@misc{liebenwein_19,
  doi = {10.48550/ARXIV.1911.07412},
  url = {https://arxiv.org/abs/1911.07412},
  author = {Liebenwein, Lucas and Baykal, Cenk and Lang, Harry and Feldman, Dan and Rus, Daniela},
  title = {Provable Filter Pruning for Efficient Neural Networks},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{li_16,
  doi = {10.48550/ARXIV.1608.08710},
  url = {https://arxiv.org/abs/1608.08710},
  author = {Li, Hao and Kadav, Asim and Durdanovic, Igor and Samet, Hanan and Graf, Hans Peter},  
  title = {Pruning Filters for Efficient ConvNets},
  publisher = {arXiv},
  year = {2016},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{lebedev_15,
  title={Fast convnets using group-wise brain damage},
  author={Lebedev, Vadim and Lempitsky, Victor},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2554--2564},
  year={2016}
}

@article{wen_16,
  title={Learning structured sparsity in deep neural networks},
  author={Wen, Wei and Wu, Chunpeng and Wang, Yandan and Chen, Yiran and Li, Hai},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}


@article{impreg,
  author    = {Yuanzhi Li and
               Tengyu Ma and
               Hongyang Zhang},
  title     = {Algorithmic Regularization in Over-parameterized Matrix Recovery},
  journal   = {CoRR},
  volume    = {abs/1712.09203},
  year      = {2017},
  url       = {http://arxiv.org/abs/1712.09203},
  eprinttype = {arXiv},
  eprint    = {1712.09203},
  timestamp = {Sun, 08 Aug 2021 16:40:51 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1712-09203.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{RECHT,
	doi = {10.1137/070697835},
  
	url = {https://doi.org/10.1137\%2F070697835},
  
	year = 2010,
	month = {jan},
  
	publisher = {Society for Industrial {\&} Applied Mathematics ({SIAM})},
  
	volume = {52},
  
	number = {3},
  
	pages = {471--501},
  
	author = {Benjamin Recht and Maryam Fazel and Pablo A. Parrilo},
  
	title = {Guaranteed Minimum-Rank Solutions of Linear Matrix Equations via Nuclear Norm Minimization},
  
	journal = {{SIAM} Review}
}

@article{Koltchinskii2010,
  title={Nuclear-norm penalization and optimal rates for noisy low-rank matrix completion},
  author={Koltchinskii, Vladimir and Lounici, Karim and Tsybakov, Alexandre B},
  year={2011}
}


@article{https://doi.org/10.48550/arxiv.1009.2118,
  title={Restricted strong convexity and weighted matrix completion: Optimal bounds with noise},
  author={Negahban, Sahand and Wainwright, Martin J},
  journal={The Journal of Machine Learning Research},
  volume={13},
  number={1},
  pages={1665--1697},
  year={2012},
  publisher={JMLR. org}
}

@inproceedings{hessianbound,
  title={Stabilized SVRG: Simple variance reduction for nonconvex optimization},
  author={Ge, Rong and Li, Zhize and Wang, Weiyao and Wang, Xiang},
  booktitle={Conference on learning theory},
  pages={1394--1448},
  year={2019},
  organization={PMLR}
}



@article{DBLP:journals/corr/abs-1905-00529,
  author    = {Rong Ge and
               Zhize Li and
               Weiyao Wang and
               Xiang Wang},
  title     = {Stabilized {SVRG:} Simple Variance Reduction for Nonconvex Optimization},
  journal   = {CoRR},
  volume    = {abs/1905.00529},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.00529},
  eprinttype = {arXiv},
  eprint    = {1905.00529},
  timestamp = {Tue, 26 Apr 2022 16:10:18 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1905-00529.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@misc{wainwright2015,
  doi = {10.48550/ARXIV.1509.03025},
  
  url = {https://arxiv.org/abs/1509.03025},
  
  author = {Chen, Yudong and Wainwright, Martin J.},
  
  keywords = {Statistics Theory (math.ST), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Mathematics, FOS: Mathematics, FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Fast low-rank estimation by projected gradient descent: General statistical and algorithmic guarantees},
  
  publisher = {arXiv},
  
  year = {2015},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@book{wainwright_2019, place={Cambridge}, series={Cambridge Series in Statistical and Probabilistic Mathematics}, title={High-Dimensional Statistics: A Non-Asymptotic Viewpoint}, DOI={10.1017/9781108627771}, publisher={Cambridge University Press}, author={Wainwright, Martin J.}, year={2019}, collection={Cambridge Series in Statistical and Probabilistic Mathematics}}


@article{SCARDAPANE201781,
title = {Group sparse regularization for deep neural networks},
journal = {Neurocomputing},
volume = {241},
pages = {81-89},
year = {2017},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2017.02.029},
url = {https://www.sciencedirect.com/science/article/pii/S0925231217302990},
author = {Simone Scardapane and Danilo Comminiello and Amir Hussain and Aurelio Uncini},
keywords = {Deep networks, Group sparsity, Pruning, Feature selection},
abstract = {In this paper, we address the challenging task of simultaneously optimizing (i) the weights of a neural network, (ii) the number of neurons for each hidden layer, and (iii) the subset of active input features (i.e., feature selection). While these problems are traditionally dealt with separately, we propose an efficient regularized formulation enabling their simultaneous parallel execution, using standard optimization routines. Specifically, we extend the group Lasso penalty, originally proposed in the linear regression literature, to impose group-level sparsity on the network’s connections, where each group is defined as the set of outgoing weights from a unit. Depending on the specific case, the weights can be related to an input variable, to a hidden neuron, or to a bias unit, thus performing simultaneously all the aforementioned tasks in order to obtain a compact network. We carry out an extensive experimental evaluation, in comparison with classical weight decay and Lasso penalties, both on a toy dataset for handwritten digit recognition, and multiple realistic mid-scale classification benchmarks. Comparative results demonstrate the potential of our proposed sparse group Lasso penalty in producing extremely compact networks, with a significantly lower number of input features, with a classification accuracy which is equal or only slightly inferior to standard regularization terms.}
}



@article{grouplasso,
author = {Yuan, Ming and Lin, Yi},
year = {2006},
month = {02},
pages = {49-67},
title = {Model Selection and Estimation in Regression With Grouped Variables},
volume = {68},
journal = {Journal of the Royal Statistical Society Series B},
doi = {10.1111/j.1467-9868.2005.00532.x}
}

@inproceedings{Koren2009TheBS,
  title={The BellKor Solution to the Netflix Grand Prize},
  author={Yehuda Koren},
  year={2009}
}

@inproceedings{rennie_05,
author = {Rennie, Jasson D. M. and Srebro, Nathan},
title = {Fast Maximum Margin Matrix Factorization for Collaborative Prediction},
year = {2005},
isbn = {1595931805},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1102351.1102441},
doi = {10.1145/1102351.1102441},
pages = {713–719},
numpages = {7},
location = {Bonn, Germany},
series = {ICML '05}
}

@article{ge_16,
  title={Matrix completion has no spurious local minimum},
  author={Ge, Rong and Lee, Jason D and Ma, Tengyu},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}
@article{bhojanapalli_16,
  title={Global optimality of local search for low rank matrix recovery},
  author={Bhojanapalli, Srinadh and Neyshabur, Behnam and Srebro, Nati},
  journal={Advances in Neural Information Processing Systems},
  volume={29},
  year={2016}
}
@inproceedings{li_17,
  title={Algorithmic regularization in over-parameterized matrix sensing and neural networks with quadratic activations},
  author={Li, Yuanzhi and Ma, Tengyu and Zhang, Hongyang},
  booktitle={Conference On Learning Theory},
  pages={2--47},
  year={2018},
  organization={PMLR}
}

@article{zhuang_18,
  title={Discrimination-aware channel pruning for deep neural networks},
  author={Zhuang, Zhuangwei and Tan, Mingkui and Zhuang, Bohan and Liu, Jing and Guo, Yong and Wu, Qingyao and Huang, Junzhou and Zhu, Jinhui},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}


@article{cai_10,
author = {Cai, Jian-Feng and Cand\`{e}s, Emmanuel J. and Shen, Zuowei},
title = {A Singular Value Thresholding Algorithm for Matrix Completion},
journal = {SIAM Journal on Optimization},
volume = {20},
number = {4},
pages = {1956-1982},
year = {2010},
doi = {10.1137/080738970},
URL = {https://doi.org/10.1137/080738970},
eprint = {https://doi.org/10.1137/080738970},
}

@article{meka_09,
  title={Guaranteed rank minimization via singular value projection},
  author={Jain, Prateek and Meka, Raghu and Dhillon, Inderjit},
  journal={Advances in Neural Information Processing Systems},
  volume={23},
  year={2010}
}

@article{keshavan_09,
  title={Matrix completion from a few entries},
  author={Keshavan, Raghunandan H and Montanari, Andrea and Oh, Sewoong},
  journal={IEEE transactions on information theory},
  volume={56},
  number={6},
  pages={2980--2998},
  year={2010},
  publisher={IEEE}
}

@article{ma_09,
  title={Fixed point and Bregman iterative methods for matrix rank minimization},
  author={Ma, Shiqian and Goldfarb, Donald and Chen, Lifeng},
  journal={Mathematical Programming},
  volume={128},
  number={1-2},
  pages={321--353},
  year={2011},
  publisher={Springer}
}

@article{recht_09,
  title={A simpler approach to matrix completion.},
  author={Recht, Benjamin},
  journal={Journal of Machine Learning Research},
  volume={12},
  number={12},
  year={2011}
}


@article{recht_2010,
	doi = {10.1137/070697835},
	url = {https://doi.org/10.1137%2F070697835},
	year = 2010,
	month = {jan},
	publisher = {Society for Industrial {\&} Applied Mathematics ({SIAM})},
	volume = {52},
	number = {3},
	pages = {471--501},
	author = {Benjamin Recht and Maryam Fazel and Pablo A. Parrilo},
	title = {Guaranteed Minimum-Rank Solutions of Linear Matrix Equations via Nuclear Norm Minimization},
	journal = {{SIAM} Review}
}
@article{toh_2010,
author = {Toh, Kim-Chuan and Yun, Sangwoon},
year = {2010},
month = {09},
pages = {},
title = {An Accelerated Proximal Gradient Algorithm for Nuclear Norm Regularized Least Squares Problems},
volume = {6},
journal = {Pacific Journal of Optimization}
}

@article{ye_2021,
  title={Global convergence of gradient descent for asymmetric low-rank matrix factorization},
  author={Ye, Tian and Du, Simon S},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={1429--1439},
  year={2021}
}

@article{srebo_11,
  title={On the universality of online mirror descent},
  author={Srebro, Nati and Sridharan, Karthik and Tewari, Ambuj},
  journal={Advances in neural information processing systems},
  volume={24},
  year={2011}
}

@misc{neyshabur_14,
  doi = {10.48550/ARXIV.1412.6614},
  url = {https://arxiv.org/abs/1412.6614},
  author = {Neyshabur, Behnam and Tomioka, Ryota and Srebro, Nathan},
  title = {In Search of the Real Inductive Bias: On the Role of Implicit Regularization in Deep Learning},
  publisher = {arXiv},
  year = {2014},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{hardt_15,
  title={Train faster, generalize better: Stability of stochastic gradient descent},
  author={Hardt, Moritz and Recht, Ben and Singer, Yoram},
  booktitle={International conference on machine learning},
  pages={1225--1234},
  year={2016},
  organization={PMLR}
}

@article{neyshabur_17,
  title={Exploring generalization in deep learning},
  author={Neyshabur, Behnam and Bhojanapalli, Srinadh and McAllester, David and Srebro, Nati},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{wilson_17,
  title={The marginal value of adaptive gradient methods in machine learning},
  author={Wilson, Ashia C and Roelofs, Rebecca and Stern, Mitchell and Srebro, Nati and Recht, Benjamin},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@misc{krishnamoorthi_18,
  doi = {10.48550/ARXIV.1806.08342},
  url = {https://arxiv.org/abs/1806.08342},
  author = {Krishnamoorthi, Raghuraman},
  title = {Quantizing deep convolutional networks for efficient inference: A whitepaper},
  publisher = {arXiv},
  year = {2018},
  copyright = {Creative Commons Zero v1.0 Universal}
}

@misc{guo_18,
  doi = {10.48550/ARXIV.1808.04752},
  url = {https://arxiv.org/abs/1808.04752},
  author = {Guo, Yunhui},
  title = {A Survey on Methods and Theories of Quantized Neural Networks},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{prune_generalization,
  title={The generalization-stability tradeoff in neural network pruning},
  author={Bartoldson, Brian and Morcos, Ari and Barbu, Adrian and Erlebacher, Gordon},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={20852--20864},
  year={2020}
}

@article{gpt3,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@inproceedings{quadratic_networks,
  title={On the power of over-parametrization in neural networks with quadratic activation},
  author={Du, Simon and Lee, Jason},
  booktitle={International conference on machine learning},
  pages={1329--1338},
  year={2018},
  organization={PMLR}
}