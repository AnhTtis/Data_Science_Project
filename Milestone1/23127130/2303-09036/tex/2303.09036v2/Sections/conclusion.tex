\section{Conclusions}
We presented a novel learning strategy for 3D-aware GANs to achieve image synthesis of high-quality and strict 3D consistency. The core idea is to enforce the images synthesized by the generator's 3D rendering branch to mimic those generated by its 2D super-resolution branch. We also introduced 3D-aware convolutions to the generator to further improve the image generation quality. With the above strategies, our method largely improves the image quality among methods using direct 3D rendering, which we believe enables a new way for more realistic 3D generation. 

\vspace{-0.3cm}
\paragraph{Limitation and future works.} Our method has several limitations. The image generation quality of its 3D branch still lags behind that of the 2D branch. Certain generated 3D structures such as hairs and cat whiskers are stuck to the geometry surfaces instead of correctly floating in the volumetric space. The 3D-to-2D imitation strategy also introduces extra training time and memory costs compared to only learning the 2D branch. We expect more effective learning strategies and more advanced 3D representations to alleviate these problems.

\vspace{-0.3cm}
\paragraph{Ethics consideration.} The goal of this paper is to generate images of virtual subjects. It is not intended for creating misleading or deceptive contents of real people and we do not condone any such harmful behavior.
