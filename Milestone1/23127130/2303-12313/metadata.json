{
    "arxiv_id": "2303.12313",
    "paper_title": "Distribution Aligned Diffusion and Prototype-guided network for Unsupervised Domain Adaptive Segmentation",
    "authors": [
        "Haipeng Zhou",
        "Lei Zhu",
        "Yuyin Zhou"
    ],
    "submission_date": "2023-03-22",
    "revised_dates": [
        "2023-03-28"
    ],
    "latest_version": 2,
    "categories": [
        "cs.CV"
    ],
    "abstract": "The Diffusion Probabilistic Model (DPM) has emerged as a highly effective generative model in the field of computer vision. Its intermediate latent vectors offer rich semantic information, making it an attractive option for various downstream tasks such as segmentation and detection. In order to explore its potential further, we have taken a step forward and considered a more complex scenario in the medical image domain, specifically, under an unsupervised adaptation condition. To this end, we propose a Diffusion-based and Prototype-guided network (DP-Net) for unsupervised domain adaptive segmentation. Concretely, our DP-Net consists of two stages: 1) Distribution Aligned Diffusion (DADiff), which involves training a domain discriminator to minimize the difference between the intermediate features generated by the DPM, thereby aligning the inter-domain distribution; and 2) Prototype-guided Consistency Learning (PCL), which utilizes feature centroids as prototypes and applies a prototype-guided loss to ensure that the segmentor learns consistent content from both source and target domains. Our approach is evaluated on fundus datasets through a series of experiments, which demonstrate that the performance of the proposed method is reliable and outperforms state-of-the-art methods. Our work presents a promising direction for using DPM in complex medical image scenarios, opening up new possibilities for further research in medical imaging.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.12313v1",
        "http://arxiv.org/pdf/2303.12313v2"
    ],
    "publication_venue": null
}