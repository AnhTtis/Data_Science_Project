\vspace{-1em}
\section{Introduction}


% \lipsum[1-3]
3D digital human reconstruction has a wide range of applications in movie production, telepresence, 3D immersive communication, and AR/VR games. Traditional digital human production relies on dense camera arrays~\cite{ARF,LightStage} or depth sensors~\cite{Self-portraits, Fusion4D} followed by complex graphics rendering pipelines for high-quality 3D reconstruction, which limits the availability to the general public. 

\begin{figure}[ht]
    \centering
    \includegraphics[width=1.0\linewidth]{figures/method/teaser.png}
    \vspace{-2.5em}
    \caption{{\bf The effect of inaccurately estimated SMPL}. Compared with GNR\cite{genebody} and KeypointNeRF\cite{keypointNeRF}, our method  still yields a reasonable result.}
    \vspace{-1.5em}
    \label{fig:teaser}
\end{figure}

Reconstructing 3D humans from 2D images captured by sparse RGB cameras is very attractive due to its low cost and convenience.
This field has been studied for decades~\cite{PCMSA,Scalable3D,DSC}.
% \Liqian{to add: discuss some early representative ways in this field if available}
However, reconstruction from sparse RGB cameras is still quite challenging because of: 1) heavy self-occlusions of the articulated human body; 2) inconsistent lighting and sensor parameters between different cameras; 3) highly non-rigid and diverse clothes.



In recent years, with the rise of learning-based methods, we can reconstruct high-quality digital humans from sparse cameras. %, which has greatly reduced the cost.
% \Liqian{to add: discuss some non-nerf based DL methods}
Learning-based methods \cite{NT,NHR,TNA,SMPLpix,vid2vid} have made great processes, however, they lack multi-view geometric consistency due to the mere usage of a 2D neural rendering network. 
% \Liqian{to add: discuss some nerf based but without geometry prior DL methods}
To address this problem, many recent works\cite{PixelNeRF, ibrnet, MVSNeRF} adopt neural radiance fields as 3D representations, which achieves outstanding performance on novel view synthesis.
However, these methods are not robust to unseen poses without the guidance of human geometric prior.

% \Liqian{to add: neuralBody}
To better generalize to unseen poses, NeuralBody~\cite{neuralbody} introduces a statistical body model SMPL\cite{SMPL} into neural radiance fields which can reconstruct vivid digital humans from a sparse multi-view video. 
However, NeuralBody is designed for identity-specific scenarios, which means it requires laborious data collection and long training to obtain the model for one person.
Such a limitation restricts its application in general real-world scenarios.


In this work, we focus on synthesizing high-fidelity novel view images for arbitrary human performers from a set of sparse multi-view images.
% \Liqian{to add: neuralBody related following general methods. Add discuss on pixel-aligned-features}
Towards this goal, some very recent works \cite{NHP, genebody, gpnerf, keypointNeRF} propose to aggregate multi-view pixel-aligned features using SMPL as a geometric prior.
However, these methods usually assume perfect geometry (\eg accurate SMPL~\cite{SMPL} estimation from 2D images) which is not applicable in practical applications. In practice, the geometry error does affect the reconstruction performance significantly. 
As illustrated in the red box of \cref{fig:teaser}, when the estimated SMPL does not align well with RGB image, prior SMPL-dependent methods\cite{genebody, keypointNeRF} yield blurry and distorted results.
The such performance gap is caused by the misalignment between the 3d geometry (\ie SMPL) and the pixel space (\ie pixel-aligned feature and ground-truth image).
Specifically, the misalignment will cause: 1) blur and distortion when fusing the geometry and pixel-aligned features; 2) unsuitable supervision during training with a pixel-wise loss like L1 or L2.
% \Liqian{to add: maybe better explanations here.} 
To alleviate the issue of misalignment, we propose to take the geometry code as a proxy and then register the appearance code onto the geometry through a novel geometry-guided attention mechanism.
% to aggregate the multi-view pixel-aligned features. 
% Furthermore, we also introduce perceptual loss not only to tolerate misalignment but also to synthesize sharper images.
Furthermore, we leverage perceptual loss to reduce the influence of misalignment and promote sharp image synthesis, which is evaluated at a higher level with a larger perceptual field. 
It is non-trivial to apply perceptual loss in NeRF-based methods as the perceptual loss requires a large patch size as input which is memory-consuming through volume rendering. We introduce 2D neural rendering and partial gradient backpropagation to alleviate the memory requirement and enhance the perceptual quality.



To summarize, our work contributes as follows:

$\bullet$ A novel generalizable model-based framework GM-NeRF is proposed for the free-viewpoint synthesis of arbitrary performers.

$\bullet$ To alleviate the misalignment between 3D geometry and the pixel space, we propose geometry-guided attention to aggregate multi-view appearance and geometry proxy.

$\bullet$ To enable perceptual loss supervision to further alleviate misalignment issues, we adopt several efficient designs including 2D neural rendering and partial gradient backpropagation.



% 1）框架层面，smpl proxy 更强调 geometry 为主，规避geometry estimation不准确的ambiguity。把rgb注册到geometry
% 2）multi-view fusion 的design和choice
% 3）缓解pixel wise 和gt不一样，需要引入perceptual loss，提出一个策略（efficient training）+ neural render