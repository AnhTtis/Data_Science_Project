\documentclass[10pt,a4paper]{article}
\usepackage[latin1]{inputenc}
\usepackage[latin1]{inputenc}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{enumerate}  
\usepackage{stmaryrd}
\usepackage{color}
%\usepackage{natbib}
\usepackage{dirtytalk}
\usepackage{mathrsfs}
\usepackage{marginnote}
\usepackage{fullpage}

\newtheorem*{Theorem*}{Theorem}
\newtheorem{Theorem}{Theorem}[section]
\newtheorem{Lemma}[Theorem]{Lemma}
\newtheorem{Corollary}[Theorem]{Corollary}
\newtheorem{Proposition}[Theorem]{Proposition}

\theoremstyle{definition}
%\newtheorem{Definition}[Theorem]{Definition}
\newtheorem{Definition}{Definition}
\newtheorem{Example}[Theorem]{Example}
\newtheorem*{Question}{Question}


\theoremstyle{remark}
\newtheorem{Remark}[Theorem]{Remark}

\newcommand*{\atleast}[1]{\exists^{\ge {#1}}}
\newcommand*{\exactly}[1]{\exists^{= {#1}}}
\newcommand*{\C}{\mathsf{C}}
\newcommand*{\dom}{\mathsf{dom}}
\newcommand*{\spa}{\mathsf{span}}
\newcommand*{\as}{\mathsf{AffineSpan}}
\newcommand*{\ls}{\mathsf{LinearSpan}}
\newcommand*{\ad}{\mathsf{AffineDim}}
\newcommand*{\ld}{\mathsf{LinearDim}}


\newcommand*{\bdim}{\mathsf{bdim}}

\newcommand*{\cone}{\mathsf{Cone}}
\newcommand{\leftm}{\{\!\!\{}
\newcommand{\rightm}{\}\!\!\}}
\newcommand{\bleftm}{\bigl\{\!\!\bigl\{}
\newcommand{\brightm}{\bigl\}\!\!\bigl\}}

\newcommand*{\defin}[1]{\textbf{\emph{#1}}}


\title{Three iterations of $(d-1)$-WL test distinguish non isometric clouds of $d$-dimensional points.}
\author{Valentino Delle Rose$^{1,2}$ \and Alexander Kozachinskiy$^{1,2,3}$ \and Crist\'obal Rojas$^{1,2}$ \and Mircea Petrache$^{1,2,4}$ 
\and Pablo Barcel\'o$^{1,2,3}$}

\date{\small %
    $^1$Centro Nacional de Inteligencia Artificial, Chile\\%
    $^2$Instituto de Ingenier\'ia Matem\'atica y Computacional, Universidad Cat\'olica de Chile\\
    $^3$Instituto Milenio Fundamentos de los Datos, Chile\\%}
    $^4$Departamento de Matem\'atica, Universidad Cat\'olica de Chile}

\begin{document}

\maketitle

\begin{abstract}
The Weisfeiler--Lehman (WL) test is a fundamental iterative algorithm for checking isomorphism of graphs. It has also been observed that it underlies the design of several graph neural network architectures, whose capabilities and performance can be understood in terms of the expressive power of this test. Motivated by recent developments in machine learning applications to datasets involving three-dimensional objects, we study when the WL test is {\em complete} for clouds of euclidean points represented by complete distance graphs, i.e., when it can distinguish, up to isometry, any arbitrary such cloud. 

   Our main result states that the $(d-1)$-dimensional WL test is complete for point clouds in $d$-dimensional Euclidean space, for any $d\ge 2$, and that only three iterations of the test suffice. Our result is tight for $d = 2, 3$. We also observe that  the $d$-dimensional WL test only requires one iteration to achieve completeness.
\end{abstract}
\section{Introduction}

Recent work in machine learning has raised the need to develop effective and efficient 
tests for checking if two three-dimensional point clouds, i.e., finite sets of points in $\mathbb{R}^3$, are {\em isometric} \cite{DBLP:journals/corr/abs-2201-07136,3d-case,https://doi.org/10.48550/arxiv.2206.07697,https://doi.org/10.48550/arxiv.2302.05743}. 
Recall that, given two such point clouds $P$ and $Q$,
an isometry is a distance-preserving bijection between the points in $P$ and $Q$.  
The importance of these tests is 
that they provide the foundations for designing neural network architectures on point clouds that are capable of fully exploiting the 
structure of the data \cite{DBLP:conf/iclr/XuHLJ19,DBLP:conf/aaai/0001RFHLRG19}. It has been observed that the {\em incompleteness} of any such an architecture, i.e., the inability to recognize a 
point cloud up to isometry, can affect its learning performance \cite{PhysRevLett.125.166001}. Understanding which is the simplest test that allows detecting isometries in this scenario is thus essential not only for developing ``complete" architectures but also to make them  
as efficient as possible in terms of the computational resources they need to use. 

Point clouds can be represented as complete graphs in which each edge is labeled with the distance between the corresponding points. 
Under this representation, detecting the isometry of two point clouds is reduced to detecting an isomorphism between their graph representation.
Not surprisingly, then, much of the work on developing so-called {\em geometric} tests for detecting isometries over point clouds is inspired by the 
literature on isomorphism tests from graph theory. Of particular importance in this context 
has been the use of geometric versions of the 
well-known {\em Weisfeiler-Lehman test} (WL test) for graph isomorphism \cite{WL}. Intuitively, 
the $\ell$-dimensional geometric WL test ($\ell$-WL test), 
for $\ell \geq 1$, iteratively colors each tuple $\bar v$ of $\ell$ points in a point cloud. The color of 
$\bar v$ in round 0 is a complete description of the mutual distances between the points that belong to the tuple. 
In round $t+1$, for $t \geq 0$, the color of $\bar v$ is updated 
by combining in a suitable manner its color in iteration $t$ with 
the color of each one of its {\em neighbors}, i.e., the tuples $\bar v'$ that are obtained from $\bar v$ 
by exchanging exactly one component of $\bar v$ with another point in the cloud. The dimensionality of the WL test is therefore a measure of 
its computational cost: the higher the $\ell$, the more costly it is to implement the $\ell$-dimensional WL test.  

For checking if two point clouds are isometric, the geometric WL test compares the resulting color patterns. If they differ, 
then we can be sure the point clouds are not isometric (that is, the test is {\em sound}). An important question, therefore, is what is the minimal $\ell \geq 1$ for which the geometric $\ell$-WL test is {\em complete}, i.e., the fact that the color patterns obtained in two point clouds are the same implies that they are isometric. Two important results on this problem have been obtained recently: 
\begin{itemize}
\item First, Pozdnyakov and Ceriotti have shown that the geometric 1-WL test is incomplete for point clouds in 3D; 
that is, there exist isometric point clouds in three dimensions 
that cannot be distinguished by the geometric 1-WL test \cite{DBLP:journals/corr/abs-2201-07136}.
\item Second, Hordan et al.~have proved that in the same setting, the geometric 3-WL test is in fact complete. Moreover, when initialized with a color that encodes information about certain Gram Matrices (instead of the mutual distances as in the classical setting), no more than one round of the test is needed to achieve completeness \cite{3d-case}.  
\end{itemize} 
This shows an evident gap in our understanding of the problem: What is then the minimum $\ell$, where $\ell = 2,3$, for which the 
geometric $\ell$-dimensional WL test is complete over three-dimensional point clouds? For the reasons mentioned above, this problem is not only 
theoretically appealing but is also relevant from a practical point of view. 

In this article, we provide an answer to this question. In particular, we show that the geometric 2-WL test is complete for point clouds in $\mathbb{R}^3$. 
More in general, we prove that for any $d > 1$ the geometric $(d-1)$-WL test is complete for detecting isometries over point clouds in $\mathbb{R}^d$. 
Interestingly, in all dimensions only three rounds of the test suffice to obtain this completeness result. Since 
our main result implies that the geometric 1-WL test is complete for all point clouds in two dimensions, we conclude that the negative result 
by Pozdnyakov and Ceriotti is in fact optimal: $d = 3$ is the minimum dimension of a euclidean space over which the geometric 1-WL test is incomplete. 

An interesting open question about our work is what is the minimum number of rounds needed for the $(d-1)$-WL test to be complete 
with respect to point clouds in $\mathbb{R}^d$. Our result shows that three rounds suffice, but we do not know the completeness status of the test when only one or two rounds are allowed. We finalize by providing simple proof 
that a single round is indeed sufficient when considering the $d$-WL test instead of the
$(d-1)$-WL one. I.e., one round of the $d$-WL test is sufficient for identifying point clouds in $\mathbb{R}^d$ up to isometry, for each $d > 1$. 
This can be seen as a refinement of the result mentioned above by Hordan et al.~\cite{3d-case}, with the difference that our test is initialized with the mutual 
distances between points (as in the classical setting) while theirs is initialized with more complicated information about certain Gram Matrices. 

\subsection{The WL test and the statement of our Main Theorem} 

Consider a cloud of $n$ points $S=\{p_1, \dots, p_n\}$ in $\mathbb{R}^d$. We are interested in the problem of finding representations of such clouds that completely characterize them up to isometries, while at the same time being efficient from an algorithmic point of view. Our main motivation is to understand the expressiveness of the WL algorithm when applied to point clouds in euclidean space seen as complete distance graphs. Let us briefly recall how this algorithm works.

A function whose domain is $S^\ell$ will be called an \emph{$\ell$-coloring} of $S$. The $\ell$-WL algorithm is an iterative procedure which acts on $S$ by assigning, at iteration $i$, an $\ell$-coloring $\chi_{\ell,S}^{(i)}$ of $S$. 
The initial coloring, $\chi_{\ell,S}^{(0)}$, assigns to each $\ell$-tuple $\mathbf{x} = (x_1, \ldots, x_\ell)\in S^\ell$ the color $\chi_{\ell,S}^{(0)}(\mathbf{x})$ given by the $\ell\times \ell$ matrix $$\chi_{\ell,S}^{(0)}(\mathbf{x})_{ij} = d(x_i, x_j) \quad i,j = 1,\dots,\ell$$ of the relative distances inside the $\ell$-tuple (note that for $\ell=1$ we have a trivial coloring by the $0$ matrix). 

Then, at each iteration, the \emph{$\ell$-WL algorithm} updates the current coloring $\chi_{\ell,S}^{(i)}$ to obtain a refined coloring $\chi_{\ell,S}^{(i+1)}$. The update operation is defined slightly differently depending on whether $\ell = 1$ or $\ell\ge 2$. For $\ell = 1$, we have:
\[ \chi_{1, S}^{(i +1)}(x) = \Big(\chi_{1,S}^{(i)}(x), \leftm (d(x, y), \chi_{1,S}^{(i)}(y)) \mid y\in S\rightm\Big).\]
That is, first, $\chi_{i+1}(x)$ remembers the coloring of $x$ from the previous step. Then it goes through all points $y\in S$. For each $y$, it stores the distance from $x$ to $y$ and also the coloring of $y$ from the previous step, and it remembers the multiset of these pairs. Note that one can determine which of these pairs comes from $y = x$ itself since this is the only point with $d(x, y) = 0$. We also note that $\chi_{1,S}^{(1)}(x)$ corresponds to the multiset of distances from $x$ to the points of $S$. 

To define the update operation for $\ell \ge 2$, we first introduce additional notation. Let $\mathbf{x} = (x_1, \ldots, x_\ell) \in S^\ell$ and $y\in S$. By $\mathbf{x}[y/i]$ we mean the tuple obtained from $\mathbf{x}$ by replacing its $i$th coordinate by $y$. Then the update operation can be defined as follows:

\begin{equation}
    \chi^{(i+1)}_{\ell,S}(\mathbf{x}) = \Big(\chi^{(i)}_{\ell,S}(\mathbf{x}), \leftm \left(\chi^{(i)}_{\ell,S}(\mathbf{x}[y/1]),\ldots, \chi^{(i)}_{\ell,S}(\mathbf{x}[y/\ell])\right)
    \mid y\in S\rightm\Big).
\end{equation}
In other words, first, $ \chi^{(i+1)}_{\ell,S}(\mathbf{x})$ remembers the coloring of $\mathbf{x}$ from the previous step, as before. Then, it goes  through all $y\in S$ and considers the $\ell$ tuples $\mathbf{x}[y/1], \ldots, \mathbf{x}[y/\ell]$. It then takes the colorings of these tuples from the previous step and puts them into a tuple. The new coloring now remembers the multiset of these tuples. 

In this note we show that the coloring obtained after 3 iterations of $(d-1)$-WL is a complete isometry invariant for point clouds in $\mathbb{R}^{d}$. More precisely, we show:

\begin{Theorem}[Main Theorem]
\label{main}
    For any $d\ge 2$ and for any finite set $S\subseteq \mathbb{R}^{d}$, the following holds. Let $\chi_{d-1,S}^{(3)}$ be the coloring of $S^{d-1}$  obtained after 3 iterations of the $(d-1)$-WL algorithm  on the distance graph of $S$. Then, knowing the multiset 
    \[\mathcal{M}_{d-1}^{(3)}(S)=\leftm \chi_{d-1,S}^{(3)}(\mathbf{s})\mid \mathbf{s}\in S^{d-1} \rightm,\] one can determine $S$ up to an isometry.
\end{Theorem}



Our proof is constructive in the sense that we exhibit an algorithm which, upon input $\mathcal{M}_{d-1}^{(3)}(S)$, computes the coordinates of a point cloud $S'$ which is isometric to $S$. In particular, if $\widetilde{S}\subset \mathbb{R}^d$ is another point cloud such that $\mathcal{M}_{d-1}^{(3)}(\widetilde{S})=\mathcal{M}_{d-1}^{(3)}(S)$, then $S$ and $\widetilde{S}$ are isometric. We start in Section 2 with the proof of the two-dimensional case, which while somewhat simpler, will allow us to introduce the general strategy. In Section 3 we explain how to implement this strategy in general for $d>2$. Finally in Section 4 we discuss the completeness of one round of $d$-WL. 

\section{Three iterations of 1-WL distinguishes clouds in the plane}

Let $S\subseteq \mathbb{R}^2$ be a cloud of $n$ points in the plane. Our task is to reconstruct $S$ up to an isometry, using as input the information contained in $\chi_{1,S}^{(3)}$. This means to find a point cloud $S^\prime$ in the plane which is an image of $S$ under some isometry.


In our reconstruction algorithm, we employ the notion of the \emph{barycenter} of a point cloud (also known as the center of mass), which we denote by $b$, and is  defined by: 
\[
    b=\frac{1}{n}\sum_{w \in S} w.
\]
For simplicity, we translate $S$ by $-b$ so that the new barycenter sits at $b = 0$. For each $w\in S$, let $\|w\|$ denote its norm (its distance to $b=0$). 


\medskip
We say that two points $u, v\in S$ satisfy the \emph{cone condition} if $u\neq 0$, $v\neq 0$, and, moreover,
\begin{itemize}
    \item if $0, u, v$ lie on the same line, then all points of $S$ line on this line;
    \item if $0, u, v$ do not lie on the same line, then the interior of 
    \[
\cone(u,v)=\{\alpha u + \beta v: \alpha,\beta \in [0,+\infty)\}
\]
does not contain points from $S$.
\end{itemize}

\medskip
In order to initialize our reconstruction algorithm, we need the following information about $S$. We assume that $S$ has more than 1 point  (otherwise there is nothing to do).

\bigskip
\noindent{\textbf{\emph{Initialization Data}}: It consists of a real number $d_0\geq 0$ and two multisets $M, M'$ such that for some $u, v\in S$, satisfying the cone condition, it holds that $d_0 = d(u, v)$ and
\[
M=M_u = \bleftm (d(u,y),\|y\|) : y \in S \brightm  \text{;} \quad M'=M_v = \bleftm (d(v,y),\|y\|) : y \in S \brightm.
\]


Given the initialization data as above, our reconstruction algorithm works as follows. 
\bigskip

\noindent\textbf{\emph{Reconstruction algorithm.}} 
 Assume that initialization data $(d_0, M,M')$ is given. Our task is to determine $S$ up to isometry. 
 Note that from $M$ we can determine $\|u\|$. Indeed, in $M$ there exists exactly one element whose first coordinate is $0$, and this element is $(0, \|u\|)$. Likewise, from $M^\prime$ we can determine $\|v\|$. We are also given $d_0 = d(u, v)$. Overall, we have all the distances between $0$, $u$, and $v$. Up to a rotation of $S$, there is only one way to put $u$, it has to be somewhere on the circle of radius $\|u\|$, centered at the origin. We fix any point of this circle as $u$. After that, there are at most two points where we can have $v$. More specifically, $v$ belongs to the intersection of two circles: one of radius $\|v\|$ centered at the origin, and the other of radius $d(u, v)$ centered at $u$. These two circles are different (remember that the cone condition includes a requirement that $u\neq 0$). Hence, they intersect by at most two points. These points are symmetric w.r.t.~the line that connects the centers of the 2 circles, i.e.,  $0$ and $u$. Thus, up to a reflection through this line (which preserves the origin and $u$), we know where to put $v$.
 
 Henceforth, we can assume the coordinates of $u$ and $v$ are known to us. Note that at this point we have applied to $S$ a translation (to put the barycenter at the origin), a rotation (to fix $u$) and a reflection (to fix $v$). We claim that, up to this isometry, $S$ can be determined uniquely.

  Consider any $(d(u, y), \|y\|)\in M$. What can we learn about $y\in S$ from this pair? It gives us distances from $y$ to $u$ and to $0$. Thus, $y$ must belong to the intersection of two circles: one with the center at $u$ and radius $d(u, y)$ and the other with the center at $0$ and radius $\|y\|$. Again, since $u\neq 0$, these two circles are different. Thus, we obtain at most 2 points where one can put $y$. We will refer to these points as \emph{candidate locations} for $y$ w.r.t.~$u$. They can be obtained one from the other by the reflection $\mathsf{Refl}_u$
through the line, connecting $0$ and $u$. Now, it might be that $y$ actually lies on this line. Then there is just 1 candidate location for $y$. In other words, in this case $(d(u, y), \|y\|)$ uniquely determines $y$. Similarly, given $(d(v, y), \|y\|)\in M^\prime$ and using the fact that $v\neq 0$, one can define (at most) 2 candidate locations of $y$ w.r.t.~$v$. Now they are related to each other via the reflection $\mathsf{Refl}_v$ through the line that connects $0$ and $v$.

The idea of our reconstruction algorithm is to gradually exclude some candidate locations  so that more and more points get a unique possible location. What allows us to start is that $u$ and $v$ satisfy the cone condition; this condition gives us some area that is free of points from $S$ (thus, one can exclude candidates belonging to this area).

The easy case is when $0, u$, and $v$ belong to the same line. Then, by the cone condition, all points of $S$ belong to this line. In this case, every point of $S$ has just one candidate location. Hence, both multisets $M$ and $M^\prime$ uniquely determine $S$.


Assume now that $0, u$, and $v$ do not belong to the same line. As in the previous case, we can uniquely restore all points that belong to the line connecting $0$ and $u$, or to the line connecting $0$ and $v$ (although now these are two different lines). Indeed, these are points that have exactly one candidate location w.r.t.~$u$ or w.r.t.~$v$. They can be identified by going through $M$ and $M^\prime$. 

Let us make a general remark about our algorithm. Once we find a unique location for some $y\in S$, we remove it from our set in order to reduce everything to the smaller set  $S\setminus\{y\}$. This is implemented by updating the multisets $M$ and $M^\prime$ so that $y$ is not taken into account in them. For that, we just  remove $(d(u, y), \|y\|)$ from $M$ and $(d(v, y), \|y\|)$ from $M^\prime$ (or decrease their multiplicities by 1).

From now on, we assume that these two lines (connecting $0$ and $u$, and $0$ and $v$, respectively) are free of the points of $S$. These lines contain the border of the cone $\cone(u, v)$. At the same time, the interior of this cone is disjoint from $S$ due to the cone condition. Thus, in fact, the whole $\cone(u, v)$ is disjoint from $S$.


We now go through $M$ and $M^\prime$ in search of points for which one of the candidate locations (either w.r.t.~$u$ or w.r.t.~$v$) falls into the ``forbidden area'', that is, into $\cone(u, v)$. After restoring these points and deleting them, we notice that the   ``forbidden area'' becomes larger. Indeed, now in $S$ there are no points that fall into $\cone(u, v)$ under one of the reflections $\mathsf{Refl}_u$ or $\mathsf{Refl}_v$. In other words, the updated ``forbidden area'' is
\[
    F=\cone(u,v)\cup\mathsf{Refl}_u\cone(u,v)\cup \mathsf{Refl}_v\cone(u,v).
\]
If the absolute angle between $u$ and $v$ is $\alpha_{uv}$, then, $F$ has total amplitude $3\alpha_{uv}$. We now iterate this process, updating $F$ successively. At each step, we know that after all removals made so far, $S$ does not have points in $F$. Thus, points of $S$ that fall into $F$ under $\mathsf{Refl}_u$ or under $\mathsf{Refl}_v$ can be restored uniquely. After deleting them, we repeat the same operation with $F \cup \mathsf{Refl}_u F \cup \mathsf{Refl}_v F$ in place of $F$.

In each iteration, $F$ opens up  by $\alpha_{uv}$ to each side, increasing its amplitude by $2\alpha_{uv}$. Within at most $1+\tfrac{\pi}{\alpha_{uv}}$ such steps, $F$ covers all angular directions, thus completing the reconstruction of $S$. 

\bigskip


\noindent\textbf{\emph{Initialization step.}} Here we explain how to obtain the Initialization Data about $S$ from the multiset $\mathcal{M}_1^{(3)}(S)$. 

We start by observing that from the first iteration of 1-WL, we can compute $\|x\|$ for all $x\in S$. As the following lemma shows, this holds in any dimension, with the same proof. We temporarily omit the current hypothesis $b=0$, in order to use the lemma later without this hypothesis.
\begin{Lemma}[The Barycenter Lemma] \label{l.orbits}
Take any $n$-point cloud $S\subseteq \mathbb{R}^{d}$ and let  
\[D_x = \leftm  d(x, y) \mid y\in S\rightm. \]
Then for every $x\in S$, knowing $D_x$ and the multiset $\leftm D_y\mid y\in S\rightm$, one can determine the distance from $x$ to the barycenter of $S$. 
\end{Lemma}
\begin{proof}
Consider the function $f\colon\mathbb{R}^{d}\to [0, +\infty)$ defined by:
\[
    f(x) = \sum\limits_{y\in S} \| x - y\|^2,
\]
namely $f(x)$ is the sum of the squares of all elements of $D_x$ (with multiplicities). It follows that $\sum_{y\in S}f(y)$ is determined by $\leftm D_y\mid y\in S\rightm$. The lemma is thus proved if we prove the following equality 
\begin{equation}\label{eq:barycalc}
    \| x - b\|^2=\frac1n\left(f(x)-\frac{1}{2n}\sum_{y\in S}f(y)\right).
\end{equation}
To prove the above, we first write:
    \begin{align*}
        f(x) = &\sum\limits_{y\in S} \| x - y\|^2 = \sum\limits_{y\in S} \| (x - b) + (b- y)\|^2 \\
        &=\sum\limits_{y\in S}\Big( \| x - b\|^2 +2\langle x - b, b- y\rangle + \| b-y\|^2 \Big) \\
        &= n\cdot  \| x - b\|^2 + 2\langle x - b, n\cdot b -  \sum\limits\limits_{y\in S} y\rangle + \sum\limits_{y\in S} \| b-y\|^2\\
        &=n\cdot  \| x - b\|^2 + \sum\limits_{y\in S} \| b-y\|^2 \quad \text{ (by definition of barycenter).} 
    \end{align*}
    Then \eqref{eq:barycalc} follows from the equality:
    \begin{equation}
        \label{var}
        \frac{1}{n}\sum_{y\in S} \| b-y\|^2 = \frac{1}{2n^2}\sum_{y\in S} \sum_{z\in S} \|y - z\|^2,
    \end{equation}
    from which we see that $\sum_{y\in S} \| b-y\|^2= \frac{1}{2n}\sum_{y\in S} \sum_{z\in S} \|y - z\|^2 =  \frac{1}{2n} \cdot \sum_{y\in S}f(y)$. 
We now show \eqref{var}. Let $\mathbf{Y}$ be a random variable, uniformly distributed on $S$. Then the left-hand side of \eqref{var} is $\mathbb{E} \| \mathbf{Y}-\mathbb{E}\mathbf{Y}\|^2$. On the the other hand, the right-hand side of \eqref{var} is $\frac{1}{2}\mathbb{E} \|\mathbf{Y}- \mathbf{Z}\|^2$, where $\mathbf{Z}$ is an independent copy of $\mathbf{Y}$. But 
\begin{align*}
    \frac{1}{2}\mathbb{E} \|\mathbf{Y}- \mathbf{Z}\|^2 &= \frac{1}{2}\mathbb{E} \langle \mathbf{Y}, \mathbf{Y} \rangle + \frac{1}{2}\mathbb{E} \langle \mathbf{Z}, \mathbf{Z} \rangle - \mathbb{E} \langle \mathbf{Y}, \mathbf{Z} \rangle  \\
    &= \mathbb{E} \langle \mathbf{Y}, \mathbf{Y} \rangle - \langle \mathbb{E}\mathbf{Y}, \mathbb{E}\mathbf{Y}\rangle && \text{since } \mathbf{Y} \text{  and } \mathbf{Z} \text{ are i.i.d.} \\
    &= \mathbb{E} \langle \mathbf{Y} - \mathbb{E}\mathbf{Y}, \mathbf{Y} - \mathbb{E}\mathbf{Y}\rangle = \mathbb{E} \| \mathbf{Y}-\mathbb{E}\mathbf{Y}\|^2,
\end{align*}
    and \eqref{var} follows.    
\end{proof}

By definition, $\chi_{1,S}^{(1)}(x)$ determines the multiset $D_x = \bleftm d(x, y) \mid y\in S\brightm$ of distances from $x$ to points of $S$. 
Since we are given the multiset $\mathcal{M}_1^{(3)}(S)$, we also know the multset $\mathcal{M}_1^{(1)}(S) =\bleftm \chi_{1,S}^{(1)}(x) \mid x \in S\brightm$ (labels after the third iterations determine labels from previous iterations). In  particular, this gives us the multiset $\bleftm D_x\mid x\in S\brightm$. Overall, due to the Barycenter lemma, we conclude that $\chi_{1, S}^{(1)}(x)$ can be converted into $\|x\|$.





Now, remember that 
\[ \chi_{1, S}^{(2)}(x) = \Big(\chi_{1,S}^{(1)}(x), \leftm (d(x, y), \chi_{1,S}^{(1)}(y)) \mid y\in S\rightm\Big).\]
By converting $\chi_{1,S}^{(1)}(y)$ into $\|y\|$ for all $y\in S$ here, one can convert $\chi_{1,S}^{(2)}(x)$  into the multiset
\[M_x = \bleftm(d(x, y), \|y\|) \mid y\in S\brightm.\]
We need one more iteration to find $d(u, v), M_u, M_v$ for some $u, v\in S$ satisfying the cone condition. In fact, we only need
\[
   \chi_{1,S}^{(3)}(u)=\Bigl(\chi_{1,S}^{(2)}(u), \bleftm \bigl(d(u,y),\chi_{1,S}^{(2)}(y)\bigl):y\in S \brightm \Bigl)
\]
for arbitrary $u\in S$ with $u\neq 0$. Since $\chi_{1,S}^{(3)}(u)$ determines $\|u\|$, such $\chi_{1,S}^{(3)}(u)$  can indeed be selected from $\mathcal{M}_1^{(3)}(S)$ (and since we assume that $S$ has more than 1 point, we know that there are points in $S$ that are different from $0$).


Due to the fact that $\chi_{1,S}^{(2)}(y)$ can be converted to $M_y$, we can in turn convert $\chi_{1,S}^{(3)}(u)$ into the multiset
\[
\mathcal{A}=\bleftm \bigl(d(u,y),M_y\bigl):y\in S \brightm.\]

In particular, since $y=u$ is the only point for which $d(u,y)=0$, we can compute $M_u$ from $\mathcal{A}$. Once we have $M_u$, the rest of the initialization goes as follows. First note that for a given element $(d(u,y),M_y)$ in $\mathcal{A}$ with $d(u,y)>0$ (so that $y\neq u$), we can look in $M_y$ for the only element with $0$ as the first entry, whose second entry is then $\|y\|$. So we can obtain $(d(u,y),\|y\|)$. 
As in the Reconstruction Algorithm, we then have only two possibilities for the location of $y$ relative to $u$, say $y_1$ and $ y_2=\mathsf{Refl}_u(y_1)$. It follows that the absolute value of the angle $\alpha_{uy}$ between $u$ and $y$ is uniquely determined (if $\|y\| = 0$, we set $\alpha_{uy} = 0$), and we can compute it from $\mathcal{A}$. In order to select $v$, we go though $\mathcal{A}$ and look for $v$ such that $\alpha_{uv}$ is the smallest  angle among $\{\alpha_{uy}\mid y \in S, 0 <\alpha_{uy} < \pi\}$. If such a $v$ does not exist, all points of $S$ must lie on the line connecting $0$ and $u$. In this case, the cone condition is satisfied, for example, for $u$ and $v = u$. Thus, we can initialize with $d_0 = 0, M = M^\prime = M_u$.
 If $v$ as above exists, there can be no point in the interior of $\cone(u,v)$, since otherwise there would be $y$ with $0<\alpha_{uy}<\alpha_{uv} < \pi$, contradicting the minimality of $\alpha_{uv}$. Thus, the cone condition is satisfied for $u,v$. We can then set $d_0=d(u,v)$, $M=M_u$ and $M^\prime=M_v$. 


\input{proof}

\section{On the distinguishing power of one iteration of $d$-WL}


In this section, we discuss a somewhat different strategy to reconstruct $S$. It is clear that if for a point $z\in \mathbb{R}^d$ we are given the distances from it to  $d+1$ points in general position with known coordinates, then the position of $z$ is uniquely determined (see e.g.~Lemma \ref{l.unique}). Since $d$-WL colors $d$-tuples of points in $S$, a natural strategy to recover $S$ is to use the barycenter as an additional point. By Lemma \ref{l.orbits}, we know that distances to the barycenter from points of $S$ can be obtained after one iteration of $d$-WL. 
However, the information that allows us to match $d(z, b)$ to the distances from this $z$ to a $d$-tuple, is readily available only after two iterations of $d$-WL.  It follows that this simple strategy can be used to directly reconstruct $S$ from the second iteration of $d$-WL. We remark that this strategy is similar to the one used in \cite{3d-case} to uniquely determine $S$ up to isometries when the coloring we are initially given corresponds to certain Gram Matrices for $d$-tuples of points. 
Essentially, after one interaction of $d$-WL over this initial data, we obtain enough information to directly determine the location of each $z$ relative to a collection of $d+1$ points. In fact, it is not hard to show that from the first iteration of $d$-WL, applied to the distance graph of $S$, one can compute these Gram Matrices, thus providing an alternative proof that two iterations suffice for distinguishing graphs.  

In this section, we show that only one iteration suffices. The strategy we use to show this is different and relies on some  geometrical facts, with which we can reduce the problem to a brute search over an exponentially large set of options. 


\begin{Theorem}\label{1-iteration}
    For any $d \ge 1$ and for any finite set $S \subseteq \mathbb{R}^d$, knowing the multiset \[\leftm \chi_{d,S}^{(1)}(\mathbf{s}) \, | \, \mathbf{s} \in S^d \rightm , \]
    one can determine $S$ up to an isometry.
\end{Theorem}
\begin{proof}
    From $\chi_{d, S}^{(1)}(\mathbf{s})$, we can determine the tuple $\mathbf{s} = (s_1, \ldots, s_d)$ up to an isometry, since $\chi_{d, S}^{(1)}(\mathbf{s})$ gives us $\chi_{d, S}^{(0)}(\mathbf{s})$, which is the distance matrix of $\mathbf{s}$. In order to determine $S$, we consider two cases:
    
    \medskip {\bfseries Case 1}: \emph{For all $\mathbf{s}\in S^d$ it holds $\ad(\mathbf{s}) < d - 1$.} Then take $\chi_{d, S}^{(1)}(\mathbf{s})$ with maximal $\ad(\mathbf{s})$, and fix locations of points from $\mathbf{s}$ compatible with the distance specification, according to Lemma \ref{l.anchor}. All points of $S$ belong to $\as(\mathbf{s})$, otherwise we could increase $\ad(\mathbf{s})$. Indeed, since $\ad(\mathbf{s}) < d - 1$, we could throw away one of the points from the tuple without decreasing the dimension and replace it with a point outside $\as(\mathbf{s})$. We now can reconstruct the rest of $S$ uniquely up to an isometry. Indeed, in $\chi_{d, S}^{(1)}(\mathbf{s})$ we are given the multiset of $d$-tuples of distances to $\mathbf{s} = (s_1, \ldots, s_d)$ from the points of $S$, and it remains to use Lemma \ref{l.unique}.

    \medskip {\bfseries Case 2}: \emph{There are tuples with $\as(\mathbf{s}) = d - 1$.} We first observe that from the multiset $\leftm \chi_{d,S}^{(0)}(\mathbf{s}) \, | \, \mathbf{s} \in S^d \rightm$ we can compute the pairwise sum of distances between the points in $S$, i.e.,
    \[
    D_S = \sum_{x\in S}\sum_{y\in S} d(x, y).
    \]
    Indeed, from $\chi_{d,S}^{(0)}((s_1, \ldots, s_d))$, we determine $d(s_1, s_2)$. Hence, we can compute the sum: 
    \[
    \sum_{(s_1, \ldots, s_d)\in S^d} d(s_1, s_2) = D_S\cdot |S|^{d-2}.
    \]
    In our reconstruction of $S$, we go through all $\chi_{d, S}^{(1)}(\mathbf{s})$ with $\ad(\mathbf{s}) = d - 1$. For each of them, we fix positions of the points of the tuple $\mathbf{s}$ in any way that agrees with the distance matrix of this tuple. As before, $\chi_{d, S}^{(1)}(\mathbf{s})$ gives us the multiset of $d$-tuples of distances to $\mathbf{s}$ from the points of $S$. We call ``candidates for $S$ given $\mathbf{s}$" the set of point clouds $S'$ which have one point associated with each such $d$-tuple of distances, and realizing these distances to points in $\mathbf{s}$. We aim to find $\mathbf{s}$ for which, exactly one of these candidates can be isometric to $S$. We start with the following lemma, for which we give a sketch of proof to convince the reader and provide complete proof in the appendix. 
\begin{Lemma} \label{l.distinguish-halfspace}
    For any finite set $S\subseteq \mathbb{R}^d$ with $\ad(S)\ge d - 1$ there exist $x_1, \ldots, x_d\in S$ with $\ad(x_1, \ldots, x_d) = d - 1$ such that all points of $S$ belong to the same half-space with respect to the  hyperplane $\as(x_1, \ldots, x_d)$.
\end{Lemma}
\begin{proof}[Sketch of proof:]
    If $\ad(S)=d-1$ then the extreme points of the convex hull of $S$ contain an affinely independent set of cardinality $d$, which then gives the desired $\mathbf{s}$. The half-space condition in the lemma is automatically verified in this case. If $\ad(S)=d$ then to find $\mathbf{s}$ we can proceed by moving a $(d-1)$-plane from infinity towards $S$ until it touches $S$ in at least one point, then iteratively we rotate the plane around the subspace containing the already touched points of $S$, until a new point in $S$ prohibits to continue that rotation. We stop within at most $d$ iterations, when no further rotation is allowed, in which case the plane has an affinely independent subset in common with $S$.
\end{proof}
Next, consider the following simple geometric observation:
\begin{Lemma}\label{l.geometricobs} 
    Let $P\in \mathbb R^d$ be a hyperplane and consider two points $a,b\in \mathbb R^d\setminus P$ that lie in same half-space w.r.t. $P$. Let $a',b'$ be the reflections of $a,b$ through $P$. Then $d(a',b')=d(a,b)<d(a,b')$.
\end{Lemma}
\begin{proof}
    It suffices to restrict to the plane $\as(\{a,b,a'\})$, and thus we take $d=2$ and up to isometry we may fix $P$ to be the $x$-axis, $a=(0,y)$, $b=(x,y')$, $b'=(x,-y')$, with $y,y'>0$. Then it follows that $d(a,b)^2=x^2 + (y-y')^2<x^2+(y+y')^2=d(a,b')^2$. As reflections are isometries, $d(a,b)=d(a',b')$.
\end{proof}
{\bfseries Claim:} If $\mathbf{s}$ is as in Lemma \ref{l.distinguish-halfspace}, then we have the following:
\begin{itemize}
    \item Exactly one of the candidates for $S$ given $\mathbf{s}$, up to reflection across $\as(\mathbf{s})$, is completely contained in one of the half-spaces determined by $\as(\mathbf{s})$.
    \item A candidate $S'$ as in the previous point is the only one of the candidates for $S$ given $\mathbf{s}$, up to reflection across $\as(\mathbf{s})$, for which $D_{S'}=D_S$.
\end{itemize} 
    To prove the first item, we use only the property that $\ad(\mathbf{s})=d-1$, with which by Lemma \ref{l.symmetric}, each point of a candidate for $S$ given $\mathbf{s}$, has either two possible locations (related by a reflection across $\as(\mathbf{s})$) or a single possible location if it belongs to $\as(\mathbf{s})$. For the second item, let $S'$ be as above and let $S''$ be a candidate for $S$ given $\mathbf{s}$, which is not completely contained in one of the halfspaces determined by $\as(\mathbf{s})$. We now consider each term $d(x',y')$ in the sum defining $D_{S'}$, comparing the corresponding term $d(x'',y'')$ from $D_{S''}$, where $x''=x'$ or is a reflection across $\mathbf{s}$ of $x'$ and similarly for $y''$ and $y'$. By Lemma \ref{l.geometricobs}, either $d(x'',y'')=d(x',y')$ in case $x'',y''$ are in the same half-space determined by $\as(\mathbf{s})$, or $d(x'',y'')>d(x',y')$ otherwise. Summing all terms, by the property of $S',S''$ we find $D_{S'}<D_{S''}$. By the same reasoning with $S$ instead of $S''$, since we are assuming that $\mathbf{s}$ satisfies Lemma \ref{l.geometricobs}, we have $D_S=D_{S'}$, completing the proof of the second item and of the claim.

    The reconstruction of $S$ in Case 2, can therefore be done as follows: we run through all $\mathbf{s}$ such that $\ad(\mathbf{s})=d-1$, and for each such $\mathbf{s}$ we construct all candidates $\widetilde S$ for $S$ given $\mathbf{s}$, and calculate $D_{\widetilde S}$ for each of them. Lemma \ref{l.distinguish-halfspace} guarantees that we run into some  $\mathbf{s}$ for which, up to isometry, only one such $\widetilde{S}$ realizes $D_{\widetilde S}=D_S$. This is our unique reconstruction of $S$. 
\end{proof}



\bibliographystyle{plain}
\bibliography{bibliography}

\appendix

\section{Proof of Lemma \ref{l.distinguish-halfspace}}
\begin{proof}
    In other words, our task is to find a hyperplane $H$ such that, first, all points of $S$ belong to the same half-space w.r.t.~$H$, and second, $\ad(H\cap S) = d - 1$.

    To start, we need to find a hyperplane $H$ such that, first, all points of $S$ belong to the same half-space w.r.t.~$H$, and second, $H\cap S\neq \varnothing$. For instance, take any non-zero vector $\alpha \in\mathbb{R}^d$, consider $m = \max_{x\in S} \langle \alpha, x\rangle$ and define $H$ by the equation $\langle \alpha, x\rangle = m$. Now, take any $x_1\in H \cap S$.  After translating $S$ by $-x_1$, we may assume that $x_1 = 0$. 

Now, among all hyperplanes $H$ that contain $x_1  = 0$ and satisfy the  condition that all points of $S$ lie in the same half-space w.r.t.~$H$, we take one that contains most points of $S$. We claim that $\ad(H\cap S) = d - 1$ for this $H$. Assume for contradiction that $\ad(H\cap S) < d - 1$. Define $U = \as(H\cap S)$. Since $H\cap S$ contains $x_1 = 0$, we have that $U\subseteq H$ is a linear subspace, and its dimension is less than $d - 1$. Hence, since $\ad(S) \ge d - 1$, there exists $x_2\in S\setminus U$. Note that $x_2\notin H$ because otherwise $x_2$ belongs to $H\cap S \subseteq U$.

Let $\alpha$ be the normal vector to $H$. Since all points of $S$ lie in the same half-space w.r.t.~$H$, w.l.o.g.~we may assume that $\langle \alpha, s\rangle \ge 0$ for all $s\in S$. In particular, $\langle \alpha, x_2\rangle > 0$ because $x_2\notin H$.


Let $U^\bot$ denote the orthogonal complement to $U$. Since $\alpha$ is the normal vector to $H\supseteq U$, we have that $\alpha\in U^\bot$. We need to find some $\beta\in U^\bot$  
which is not a multiple of $\alpha$ but satisfies $\langle \beta, x_2\rangle > 0$. 
Indeed, the dimension of $U$ is at most $d - 2$, and hence the dimension of $U^\bot$   is at least 2. Now, since $\langle\alpha, x_2\rangle > 0$, we can take any  $\beta\in U^\bot$ which is sufficiently close to $\alpha$.

For any $\lambda \ge 0$, let $H_\lambda$ be the hyperplane, defined by $\langle \alpha - \lambda \beta, x\rangle = 0$ (this is a hyperplane and not the whole space because $\beta$ is not a multiple of $\alpha$). We claim that for some $\lambda > 0$, we have that $H_\lambda$ has more points of $S$ than $H$ while still all points of $S$ lie in the same half-space w.r.t.~$H_\lambda$. This would be a contradiction.

Indeed, define $S_\beta = \{s\in S\mid \langle s, \beta\rangle > 0\}$. Note that $S_\beta$, by definition of $\beta$, contains $x_2$ and hence is non-empty. Moreover, $S_\beta$ is disjoint from $H\cap S$. This is because $H\cap S\subseteq U$ and $\beta\in U^\bot$.


Define
\[\lambda = \min_{s\in S_\beta} \frac{\langle \alpha, s\rangle }{\langle \beta, s\rangle}\]
First, $H_\lambda\supseteq U\supseteq H\cap S$ because $\alpha - \lambda\beta\in U^\bot$. Moreover, $H_\lambda$ contains at least one point of $S$ which is not in $H$. Namely, it $H_\lambda$ contains any $s\in S_\beta$, establishing the minimum in the definition of $\lambda$ (and recall that $S_\beta$ is disjoint from $H\cap S$). 
 Indeed, for this $s$ we have $\lambda = \frac{\langle \alpha, s\rangle }{\langle \beta, s\rangle}$. Hence, $\langle \alpha, s\rangle - \lambda \langle \beta, s\rangle = 0 = \langle\alpha - \lambda b, s\rangle \implies s\in H_\lambda$.
 
It remains to show that all points of $S$ lie in the same half-space w.r.t.~$H_\lambda$. More specifically, we will show that $\langle \alpha - \lambda \beta, s\rangle \ge 0$ for all $s\in S$. First, assume that $\langle s, \beta\rangle = 0$. Then $\langle \alpha - \lambda \beta, s\rangle = \langle \alpha, s\rangle \ge 0$ because all points of $S$ lie in the ``non-negative'' half-space w.r.t.~$\alpha$. Second, assume that $\langle s, \beta\rangle > 0$. Then $s\in S_\beta$. Hence, by definition of $\lambda$, we have $\lambda \le \frac{\langle \alpha, s\rangle }{\langle \beta, s\rangle}$. This means that $\langle \alpha - \lambda \beta, s\rangle = \langle \alpha, s\rangle - \lambda \langle \beta, s\rangle\ge 0$, as required.
    \end{proof}


\end{document}





