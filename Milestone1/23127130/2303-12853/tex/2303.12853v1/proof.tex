\section{Proof of Main Theorem for $d>2$}

We now present the proof for the case $d>2$. The strategy of the proof has the same structure as for $d=2$. Since the objects involved now are more general, it will be convenient to introduce some terminology. Let $\mathbf{x} = (x_1, \ldots, x_k)\in(\mathbb{R}^{d})^k$ be a $k$-tuple of points in $\mathbb{R}^{d}$. The \defin{distance matrix} of $\mathbf{x}$ is the $k\times k$ matrix $A$ given by
\[
A_{ij} = d(x_i, x_j), \quad i,j=1,\dots,k.
\]

Now, let  $S\subseteq \mathbb{R}^{d}$ be a finite set. Then the \defin{distance profile} of $\mathbf{x}$ w.r.t.~$S$ is the multiset 
\[
    D_{\mathbf{x}}=\leftm\big(d(x_1,y), \ldots, d(x_k,y)\big) \mid y \in S\rightm.
\]

As before, we let $b = \frac{1}{|S|}\sum_{y\in S}y$ denote the barycenter of $S$. For a finite set $G \subset \mathbb{R}^d$, we denote by $\ls(G)$ the linear space spanned by $G$, and by  $\as(G)$ the corresponding affine one. Their respective dimensions will be denoted by $\ld(G)$ and $\ad(G)$. 

 As for the case $d=2$, we start by distilling the Initialization Data required for the reconstruction, which is described relative to the barycenter $b$ of $S$. For convenience, we have decided not to assume at this stage 
that $S$ has been translated first to put $b$ at the origin, as we did for the sake of the exposition in the case $d=2$. This is now the task of the
isometry we apply to $S$ when choosing locations for its points, which we now completely relegate to the reconstruction phase. 

\begin{Definition} Let $S\in \mathbb{R}^d$ be a finite set and let $b$ be its barycenter. A $d$-tuple $\mathbf{x}=(x_1,\dots,x_d)\in S^d$  satisfies the \defin{cone condition} if 
\begin{itemize}
    \item $\ad(b,x_1,\dots,x_d)=\ad(S)$;
    \item if $\ad(S)=d$, then there is no $x\in S$ such that $x-b$ belongs to the interior of $\cone(x_1-b,\dots,x_d-b)$. 
\end{itemize}
\end{Definition}

\begin{Definition}
    For a tuple $\mathbf{x}=(x_1, \ldots, x_{d})\in S^{d}$, we define its \defin{enhanced profile} as
    \[
    EP(x_1, \ldots, x_{d}) = (A, M_1, \ldots, M_{d}),
    \]
    where $A$ is the distance matrix of the tuple $(b, x_1, \ldots, x_{d})$ and $M_i=D_{\mathbf{x}[b/i]}$ is the distance profile of the tuple $(x_1, \ldots, x_{i-1}, b, x_{i+1}, \ldots, x_{d})$ with respect to $S$. 
\end{Definition}
\begin{Definition} Let $S\in \mathbb{R}^d$ be a finite set and let $b$ be its barycenter. An \defin{initialization data} for $S$ is a tuple $(A,M_1,\dots,M_d)$ such that 
$(A,M_1,\dots,M_d) = EP(x_1, \ldots, x_d)$ for some $d$-ple $\mathbf{x}=(x_1,\dots,x_d)\in S^d$ satisfying the cone condition. 
\end{Definition}

\begin{Remark}
The interested reader can verify that the Initialization Data condition extends the definition for $d=2$. Note that the first bullet of the Cone Condition is automatically verified for $d=2$, but is nontrivial for $d>2$.
\end{Remark}

The fact that an initialization data $(A,M_1,\dots,M_d)$ can be recovered from $\mathcal{M}_{d-1}(S)$ is ensured by the following proposition, whose proof we provide in Section \ref{s.init}. 

\begin{Proposition}[Initialization Lemma]Take any $S\subseteq \mathbb{R}^{d}$. Then, knowing the multiset $\leftm \chi_{d-1,S}^{(3)}(\mathbf{s})\mid \mathbf{s}\in S^{d-1} \rightm$, one can determine an initialization data for $S$.
\end{Proposition}

We now proceed with the reconstruction phase. 

\subsection{Reconstruction Algorithm} 


Assume an Initialization Data $(A,M_1,\dots,M_d)$ for a finite $S\subset \mathbb{R}^d$ is given. Our first task is to choose, up to isometry, positions for the points in the $(d+1)$-tuple $(b,x_1,\dots,x_d)$ corresponding to the given matrix $A$.  For this, we use the following classical lemma, whose proof is given e.g. in \cite[Sec. 2.2.1]{cox2001multidscaling}. %, the idea being that square distance matrices can be compared to Gram matrices, to which Linear Algebra arguments can be applied. 
\begin{Lemma}[Anchor Lemma]
\label{l.anchor}
     If $(u_1, \ldots, u_k) \in \mathbb{R}^d$ and $(v_1,\dots,v_k)\in \mathbb{R}^d$ have the same distance matrix, then there exists an isometry $f\colon\mathbb{R}^{d}\to\mathbb{R}^{d}$ such that $f(u_i) = v_i$ for all $i = 1, \ldots, k$.
\end{Lemma}
%\begin{proof} Without loss of generality, we may assume that $v_1 = 0$.
%    Now, we prove the statement of the lemma by induction on $k$. For $k = 1$ there is nothing to prove. Now, assume that the statement is proved for $k-1$. Using the induction hypothesis, take an isometry $g\colon\mathbb{R}^{d}\to\mathbb{R}^{d}$ such that $g(u_1) = v_1, \ldots, g(u_{k-1}) = v_{k-1}$.  Observe that for every $i = 1, \ldots, k - 1$, we have $d(u_i, u_k) = d(g(u_i), g(u_k)) = d(v_i, g(u_k)) = d(v_i, v_k)$. In other words, $g(u_k)$ and $v_k$ have the same distances to $v_1, \ldots, y_{k-1}$. Our task is to come up with an isometry that takes $g(u_k)$ to $v_k$ and does not move $v_1, \ldots, v_{k-1}$. Recall that we assumed that $v_1 = 0$. Denote $U = \ls(v_2, \ldots, v_{k - 1})$. The idea is that projections of $g(u_k)$ and $v_k$ should be the same, and the components of these vectors that are orthogonal to $U$ should have the same norm. Then we can rotate in $U^\bot$. 
%\end{proof}

As for the case $d=2$, we choose to put the barycenter of the cloud at the origin.
Then, we simply apply the Anchor Lemma to any collection of points $z_1,\dots,z_d \in \mathbb{R}^d$ such that our given $A$ is also the distance matrix of the tuple $(0,z_1,\dots,z_d)$. The Lemma then gives us an isometry $f\colon\mathbb{R}^{d}\to\mathbb{R}^{d}$ such that 
\[
f(b) = 0,  \,\,\,\,f(x_1) = z_1,   \,\,\,\,\ldots,  \,\,\,\, f(x_{d}) = z_{d}.\]
As distance profiles are invariant under isometries, our given $M_i$ is also the distance profile of the tuple $(z_1, \ldots, z_{i - 1},0, z_{i+1}, \ldots, z_{d})$ w.r.t.~$f(S)$. Our task now is, from $M_1,\dots,M_d$, to uniquely determine the locations of all  points in $f(S)$. This would give us  $S$ up to an isometry. 
Since now we have locations for $(z_1,\dots,z_d)$,  we can in fact compute $\ad(S)$:    
\[
\ad(S)=\ad(b, x_1, \ldots, x_{d}) = \ad(0, z_1, \ldots, z_{d}) = \ld(z_1, \ldots, z_{d})
\]
where the first equality is guaranteed by the cone condition. The reconstruction algorithm depends on whether $\ad(S)=d$ or not. 

Consider first the case when $ \ad(S) =  \ld(z_1, \ldots, z_{d}) < d$. Then there exists $i \in \{ 1, \ldots, d\}$ such that $\ld(z_1, \ldots, z_{d}) = \ld(z_1, \ldots, z_{i - 1}, z_{i+1}, \ldots,  z_{d})$. This means that
\[
f(S)\subset\as( z_1, \ldots, z_{i-1},0, z_{i+1}, \ldots ,z_{d}),
\] 
since otherwise $f(S)$ would have larger affine dimension. 
We claim that, in this case, from $M_i$ we can restore the location of all points in $f(S)$. Indeed, from $M_i$ we know, for each $z \in f(S)$, a tuple with the distances from $z$ to $ z_1,\dots,z_{i-1},0,z_{i+1}, \dots, z_d$. 
As the next lemma shows, this information is enough to uniquely determine the location of $z$. 

\begin{Lemma}
\label{l.unique}
    Take any $x_1, \ldots, x_m\in\mathbb{R}^{d}$. Assume that $a, b\in \as(x_1, \ldots, x_m)$ are such that $d(a, x_i) = d(b, x_i)$ for all $i = 1, \ldots, m$. Then $a = b$.
\end{Lemma}
\begin{proof}
    We claim that for every $i = 2, \ldots, m$ we have $\langle a - x_1, x_i - x_1 \rangle = \langle b - x_1, x_i - x_1\rangle$. This is because $a-x_1$ and $b-x_1$ have the same distance to $x_i - x_1$ (which is equal to $d(a, x_i) = d(b, x_i)$) and, moreover, the norms of $a-x_1$ and $b-x_1$ coincide (and are equal to $d(a, x_1) = d(b, x_1)$). Hence, both $a - x_1$ and $b - x_1$ are solutions to the following linear system of equations:
    \begin{align*}
        \langle x, x_i - x_1\rangle = \langle a - x_1, x_i - x_1\rangle, \qquad i = 2, \ldots, m.
    \end{align*}
    This system has at most 1 solution over $x\in \ls(x_2 -x_1, \ldots, x_m - x_1)$. Moreover, $a - x_1$ and $b - x_1$ are both from $\ls(x_2 -x_1, \ldots, x_m - x_1)$ because $a, b\in \as(x_1, \ldots, x_m)$. Hence, $a - x_1 = b - x_1$, and $a = b$.
\end{proof}

It remains to reconstruct $f(S)$ when $\ad(S) = d$, in which case our pivot points $z_1, \ldots, z_{d}$ are linearly independent. Recall that $M_i$ is the distance profile of the tuple $(z_1, \ldots, z_{i-1},0, z_{i+1}, \ldots, z_{d})$ w.r.t.~$f(S)$. Moreover, since no $x$ in $S$ is such that $x-b$ lies in the interior of $\cone(x_1 - b, \ldots, x_{d} - b)$, we know that $f(S)$ must be disjoint from the interior of $\cone(z_1, \ldots, z_{d})$. As the next proposition shows, this information is enough to reconstruct $f(S)$ in this case as well, which finishes the proof of Theorem \ref{main} for $d>2$. 

\begin{Proposition}[The Reconstruction Lemma]\label{l.cone}
Assume that $z_1, \ldots, z_{d}\in\mathbb{R}^{d}$ are linearly independent. 
Let $T\subseteq \mathbb{R}^{d}$ be finite and disjoint from the interior of $\cone(z_1, \ldots, z_{d})$. If, for every $i = 1, \ldots, d$, we are given $z_i$ and also the distance profile of the tuple $(z_1, \ldots, z_{i-1},0, z_{i+1}, \ldots, z_{d})$ w.r.t.~$T$,  then we can uniquely determine $T$.
\end{Proposition}
\begin{proof}
  Let $P_i = \as(z_1, \ldots, z_{i -1}, 0, z_{i+1}, \ldots, z_{d})$. As the following lemma shows, knowing the distances from $s\in T$ to $z_1, \ldots, z_{i-1}, 0, z_{i+1}, z_{d}$, we can determine the position of $s$ uniquely up to the reflection through $P_i$.

    \begin{Lemma}[The Symmetric Lemma] \label{l.symmetric}
    Let $x_1, \ldots, x_m\in\mathbb{R}^{d}$ be such that $\as(x_1, \ldots, x_m)$ has dimension $d-1$.
    Assume that $a, b\in \mathbb{R}^{d}$ are such that $d(a, x_i) = d(b, x_i)$ for all $i = 1, \ldots, m$. Then either $a = b$ or $a$ and $b$ are symmetric w.r.t.~$\as(x_1, \ldots, x_m)$. 
\end{Lemma}
    \begin{proof}
       As in the proof of Lemma \ref{l.unique}, we have that $\langle a - x_1, x_i - x_1 \rangle = \langle b - x_1, x_i - x_1\rangle$ for every $i = 2, \ldots, m$. Consider orthogonal projections of $a - x_1$ and $b- x_1$ to $\ls(x_2 -x_1, \ldots, x_m - x_1)$. Both these projections are solutions to the system
        \begin{align*}
        \langle x, x_i - x_1\rangle = \langle a - x_1, x_i - x_1\rangle, \qquad i = 2, \ldots, m.
    \end{align*}
    This system has at most one solution over $x\in \ls(x_2 -x_1, \ldots, x_m - x_1)$. Hence, projections of $a - x_1$ and $b - x_1$ coincide. We also have that $\| a - x_1\| = \|b - x_1\|$, which implies that $a-x_1$ and $b - x_1$ have the same distance to $\ls(x_2 -x_1, \ldots, x_m - x_1)$. Since the dimension of $\ls(x_2 -x_1, \ldots, x_m - x_1)$ is $d - 1$, we get that either $a - x_1 = b - x_1$ or they can be obtained  from each other by the reflection through $\ls(x_2 - x_1, \ldots, x_m - x_1)$. After translating everything by $x_1$, we obtain the claim of the lemma.
    \end{proof}
In fact, if $s$ belongs to $P_i$, then there is just one possibility for $s$. Thus, we can restore all the points in $T$ that belong to the union $\bigcup_{i=1}^{d} P_i$. Let us remove these points from $T$ and update distance profiles by deleting the tuples of distances that correspond to the points that we have removed.

From now on, we may assume that $T$ is disjoint from $\bigcup_{i=1}^d P_i$. Hence, $T$ is also disjoint from the boundary of $C=\cone(x_1, \ldots, x_d)$, not only from its interior (every face of this cone lies on  $P_i$ for some $i$).

For $x\in \mathbb{R}^d$, we define $\rho(x) = \min_{i = 1, \ldots, d}\mathsf{dist}(x, P_i)$. Since $T$ is disjoint from $\bigcup_{i=1}^d P_i$, we have that $\rho(s) > 0$ for every $s\in T$. Moreover, from, say, the distance profile of $(0, z_2, \ldots, z_d)$, we can compute some $\varepsilon > 0$ such that $\rho(s)\ge\varepsilon$ for all $s\in T$. Indeed, recall that from the distance profile of $(0, z_2, \ldots, z_d)$, we get at most 2 potential positions for each point of $T$. This gives us a finite set $T^\prime$ (at most 2 times larger than $T$) which is a superset of $T$. Moreover, as $T$ is disjoint from  $\bigcup_{i=1}^d P_i$, we have that $T^\prime\setminus \bigcup_{i=1}^d P_i \supseteq T $
Thus, we can define $\varepsilon$ as the minimum of $\rho(x)$ over $T^\prime \setminus \bigcup_{i=1}^d P_i \supseteq T$. 

We conclude that $T$ is disjoint from 
\[A_0 = C \cup \{x\in\mathbb{R}^d \mid \rho(x) < \varepsilon\}\]
(moreover, the set $A_0$ is known to us).
%Now, for $x\in\mathbb{R}^{d}$, and with notation $\mathsf{Refl}_i$ for the reflection across $P_i$, let 
%\[
   % \rho(x)=\min_{1\le i\le d}\mathsf{dist}(x,P_i), \quad \varepsilon=\min\left\{\rho(s):\ s\in T\cup \mathsf{Refl}_1(T)\text{ s.t. }\rho(s)>0\right\}.
%\]
%Since $T, C$ are disjoint and $T$ is finite, the distance from $T$ to $C$ is positive and equal to the distance to $C$'s boundary, is contained in $\bigcup_i P_i$. This and the definition of $\varepsilon$ give
%\[
%\mathsf{dist}(T,C)\ge\min_{t\in T}\rho(t)\ge \varepsilon>0.
%\]
%We claim that we can compute $T\cup\mathsf{Refl}_1(T)$ (and thus $\varepsilon$) from $M_1$ and $z_1,\dots,z_d$. To do this, going through all tuples of distances in $M_1$ we can determine $T\cup\mathsf{Refl}_1(T)$, since by the Symmetric Lemma, each tuple of distances from $M_1$ gives 2 candidates for a point in $T$ that are symmetric w.r.t.~$P_1$. Knowledge of $z_1,\dots,z_d$ allows to find $\bigcup_iP_i$, and thus to compute $\rho$. 
 Our reconstruction procedure starts as follows. We go through all distance profiles, and through all tuples of distances in them. Each  tuple gives 2 candidates for a point in $T$ (that can be obtained from each other by the reflection through $P_i$). If one of the candidates lies in $A_0$, we know that we should take the other candidate. In this way, we may possibly uniquely determine some points in $T$. If so, we remove them from $T$ and update our distance profiles.

Which points of $T$ will be found in this way? Those that, for some $i$, fall into $A_0$ under the reflection through $P_i$. Indeed, these are precisely the points that give 2 candidates (when we go through the $i$th distance profile) one of which is in $A_0$. In other words, we will determine all the points that lie in $\bigcup_{i = 1}^{d} \mathsf{Refl}_i(A_0)$, where $\mathsf{Refl}_i$ denotes the reflection through $P_i$. After we remove these points, we know that the remaining $T$ is disjoint from $A_1 = A_0 \cup \bigcup_{i = 1}^{d} \mathsf{Refl}_i(A_0)$.

We then continue in exactly the same way, but with $A_1$ instead of $A_0$, and then with $A_2 =  A_1 \cup \bigcup_{i = 1}^{d} \mathsf{Refl}_i(A_1)$, and so on. It remains to show that all the points of $T$ will be recovered in this way. In other words, we have to argue that each point of $T$ belongs to some $A_i$, where 
\[
A_0 =  C \cup \{x\in\mathbb{R}^d \mid \rho(x) < \varepsilon\}, \qquad A_{i+1} =  A_i \cup \bigcup_{i = 1}^{d} \mathsf{Refl}_i(A_i).
\]
We will show this not only for points in $T$ but for all points in $\mathbb{R}^{d}$. Equivalently, we have to show that for every $x\in \mathbb{R}^d$ there exists a finite sequence of reflections $\tau_1, \ldots, \tau_k\in\{\mathsf{Refl}_1, \ldots, \mathsf{Refl}_{d}\}$ which brings $x$ inside $A_0$, that is, $\tau_k \circ\ldots \circ \tau_1(x) \in A_0$. 

We construct this sequence of reflections as follows.  Let $x$ be outside $A_0$. In particular, $x$ is outside the cone $C =  \cone(z_1, \ldots, z_{d})$. Then there exists a face of this cone such that $C$ is from one side of this face and $x$ is from the other side. Assume that this face belongs to the hyperplane $P_i$. We then reflect $x$ through $P_i$, and repeat this operation until we get inside $A_0$. 
%If for some $i$ we have that $C$ is on one side of $P_i$ and $x$ is on the other side, then we reflect $x$ through such $P_i$. We repeat this operation until no such $i$ exists, in which case we have $x\in C$. 
We next show that the above process stops within a finite number of steps. For that, we introduce the quantity $\gamma(x)  = \langle x, z_1\rangle + \ldots +\langle x, z_{d}\rangle$. We claim that with each step, $\gamma(x)$ increases by at least $c\cdot\varepsilon$, where 
\[
c =2\min_{1\le i\le d}\mathsf{dist}(z_i,P_i).
\]
Note that $c > 0$ because, for every $i = 1, \ldots, d$, we have that $z_i\notin P_i$, by the linear independency of $z_1, \ldots, z_{d}$. Also observe that $\gamma(x)  \le |x|\sum_i|z_i|$ and reflections across the subspaces $P_i$ do not change $|x|$. Hence, $\gamma(x)$ cannot increase infinitely many times by some fixed positive amount. 

It remains to show that $\gamma(x)$ increases by at least $c \cdot \varepsilon$ at each step, as claimed. Note that reflection of $x$ across some $P_i$ does not change the scalar product of $x$ with those vectors among $z_1, \ldots, z_{d}$ that belong to $P_i$. The only scalar product that changes is $\langle x, z_i\rangle$, and the only direction which contributes to the change is the one orthogonal to $P_i$. 
Before the reflection, the contribution of this direction to the scalar product was $-d(x, P_i)\cdot d(z_i, P_i)$ (remember that $x$ and $z_i$ were from different sides of $P_i$ because $z_i\in C$). After the reflection, the contribution is the same, but with a positive sign. Thus, the scalar product increases by $2d(x, P_i)\cdot d(z_i, P_i)$. Now, we have $d(z_i, P_i) \ge c/2$ by definition of $c$ and $d(x, P_i)\ge \varepsilon$ if $x$ is not yet in $A_0$.
\end{proof}

\subsection{Proof of the Initialization Lemma}\label{s.init}
We will need the following extension of the Barycenter Lemma.


\begin{Lemma}
\label{c.radius}
Let $b$ be the barycenter of $S\subset \mathbb R^d, d>2$.
For any $\mathbf{x} = (x_1, \ldots, x_{d-1}) \in S^{d-1}$, knowing $\chi_{d-1,S}^{(1)}(\mathbf{x})$ and the multiset $\leftm \chi_{d-1,S}^{(1)}(\mathbf{y}) \mid \mathbf{y}\in S^{d-1}\rightm$, one can determine the tuple of distances $(d(x_1, b), \ldots, d(x_{d-1}, b))$.
\end{Lemma}
\begin{proof}
    Let $D_x$ be as in Lemma \ref{l.orbits}. We claim that we can determine $(D_{x_1},\dots,D_{x_{d-1}})$ and $\leftm D_y | y\in S\rightm$ from the information given in the lemma statement. By Lemma \ref{l.orbits}, this allows to determine $(d(x_1, b), \ldots, d(x_{d-1}, b))$.

    We have
    \[
        \chi^{(1)}_{d-1,S}(\mathbf{x}) = \Big(\chi^{(0)}_{d-1,S}(\mathbf{x}), \leftm \left(\chi^{(0)}_{d-1,S}(\mathbf{x}[y/1]),\ldots, \chi^{(0)}_{d-1,S}(\mathbf{x}[y/(d-1)])\right)
    \mid y\in S\rightm\Big).
    \]
    By definition, from  $\chi^{(0)}_{d-1,S}(\mathbf{x}[y/1])$ one can determine the tuple of distances $(d(x_2, y), \ldots, d(x_{d-1}, y))$. Hence, from the multiset $\leftm \chi^{(0)}_{d-1,S}(\mathbf{x}[y/1])\mid y\in S \rightm$ one can determine $(D_{x_2}, \ldots, D_{x_{d-1}})$. In turn, $D_{x_1}$ can be determined from, say, $\leftm \chi^{(0)}_{d-1,S}(\mathbf{x}[y/2])\mid y\in S \rightm$. We have just shown that $\chi_{d-1,S}^{(1)}(\mathbf{x})$ uniquely determines $D_{x_1}$. Hence, from the multiset $\leftm \chi_{d-1,S}^{(1)}(\mathbf{y}) \mid \mathbf{y}\in S^{d-1}\rightm$, one can compute the multiset $\leftm D_{y_1} \mid \mathbf{y} = (y_1, \ldots, y_{d-1})\in S^{d-1}\rightm$. But this multiset coincides with the multiset $\leftm D_{y} \mid y \in S\rightm$ except that all multiplicities are $|S|^{d-2}$ times larger.
\end{proof}

Now, we show that after the second iteration, we can restore the distance profile of $(b, x_1, \ldots, x_{d-1})$ for all $(x_1, \ldots, x_{d-1})\in S^{d-1}$.


\begin{Lemma}
    \label{l.profile}
For any $\mathbf{x} = (x_1, \ldots, x_{d-1}) \in S^{d-1}$, knowing $\chi_{{d-1},S}^{(2)}(\mathbf{x})$ and the multiset $\leftm \chi_{d-1,S}^{(1)}(\mathbf{y}) \mid \mathbf{y}\in S^{d-1}\rightm$, one can determine the distance profile of $(b, x_1, \ldots, x_{d-1})$ w.r.t.~$S$.
\end{Lemma}
\begin{proof}
   Since $d>2$, we have  
    \[\chi^{(2)}_{d-1,S}(\mathbf{x}) = \Big(\chi^{(1)}_{k,S}(\mathbf{x}), \leftm \left(\chi^{(1)}_{d-1,S}(\mathbf{x}[y/1]),\ldots, \chi^{(1)}_{d-1,S}(\mathbf{x}[y/k])\right)
    \mid y\in S\rightm\Big).\]
    From the tuple $\left(\chi^{(0)}_{d-1,S}(\mathbf{x}[y/1]),\ldots, \chi^{(0)}_{d-1,S}(\mathbf{x}[y/k])\right)$ we can restore the tuple of distances 
    $$(d(y, x_1), \ldots, d(y, x_{d-1})).$$ 
    In turn, by Lemma \ref{c.radius}, from  $\chi^{(1)}_{d-1,S}(\mathbf{x}[y/1])$ and $\leftm \chi_{d-1,S}^{(1)}(\mathbf{y}) \mid \mathbf{y}\in S^{d-1}\rightm$, we can restore $d(y, b)$. Hence, we can restore the whole distance profile of $(b, x_1, \ldots, x_{d-1})$.
\end{proof}

Finally, we show that knowing $\chi_{d-1,S}^{(3)}(\mathbf{x})$ for $\mathbf{x} = (x_1, \ldots, x_{d-1})$ and the multiset $\leftm \chi_{d-1,S}^{(1)}(\mathbf{y}) \mid \mathbf{y}\in S^{d-1}\rightm$, we can compute
\[\{EP(x_1, \ldots, x_{d-1}, y)\mid y\in S\}.\]

Since $d>2$, we have  
\[\chi^{(3)}_{d-1,S}(\mathbf{x}) = \Big(\chi^{(2)}_{d-1,S}(\mathbf{x}), \leftm \left(\chi^{(2)}_{d-1,S}(\mathbf{x}[y/1]),\ldots, \chi^{(2)}_{d-1,S}(\mathbf{x}[y/k])\right)
    \mid y\in S\rightm\Big).\]
    For every $y\in S$, knowing $\chi^{(2)}_{d-1,S}(\mathbf{x})$ and $\left(\chi^{(2)}_{d-1,S}(\mathbf{x}[y/1]),\ldots, \chi^{(2)}_{d-1,S}(\mathbf{x}[y/k])\right)$, we have to compute $EP(x_1, \ldots, x_{d-1}, y)$, that is, the distance matrix of $(b, x_1, \ldots, x_{d-1}, y)$ and the distance profiles of the tuples 
    \[
    (b, x_2, \ldots, x_{d-1}, y), \ldots, (x_1, \ldots, x_{d-2},b, y), (x_1, \ldots, x_{d-1}, b).\]
    Distance profiles can be computed by Lemma \ref{l.profile}.  The distances amongst elements of $\{x_1, \ldots, x_{d-1},y\}$ can be computed by definition from  $\chi^{(0)}_{d-1,S}(\mathbf{x})$ and $\left(\chi^{(0)}_{d-1,S}(\mathbf{x}[y/1]),\ldots, \chi^{(0)}_{d-1,S}(\mathbf{x}[y/k])\right)$. Distances to $b$ from these points can be computed by Lemma \ref{c.radius} from $\chi^{(1)}_{d-1,S}(\mathbf{x})$ and $\left(\chi^{(1)}_{d-1,S}(\mathbf{x}[y/1]),\ldots, \chi^{(1)}_{d-1,S}(\mathbf{x}[y/k])\right)$. 

Now that we have the enhanced profiles, we have to select one for which $(x_1,\dots,x_d)$ satisfies the cone condition. 
We first observe that, knowing $EP(x_1, \ldots, x_d)$, we can reconstruct $(b, x_1, \ldots, x_d)$  up to an isometry by Lemma \ref{l.anchor} (because inside $EP(x_1, \ldots, x_d)$ we are given the distance matrix of $(b, x_1, \ldots, x_d)$). This means that from $EP(x_1, \ldots, x_d)$ we can compute any function of $b, x_1, \ldots, x_d$ which is invariant under isometries. In particular, we can compute $\ad(b, x_1, \ldots, x_d)$. We will refer to $\ad(b, x_1, \ldots, x_d)$ as the  dimension of the corresponding enhanced profile.

We show that $\ad(S)$ is equal to the maximal  dimension of an enhanced profile. Indeed, first notice that $\ad(S) = \ad(\{b\}\cup S)$ because  $b$ is a convex combination of points of $S$. In turn, $\ad(\{b\}\cup S)$ is equal to the maximal $k$ for which one can choose $k$ points $x_1, \ldots, x_k\in S$ such that $x_1 - b, \ldots, x_k - b$ are linearly independent. Obviously, $k$ is bounded by the dimension of the space.  Hence, there will be an enhanced profile with the same maximal dimension $k$.

 %First, observe  that from $EP(x_1, \ldots, x_{d})$ (in particular from the distance matrix $A$ in that profile) we can restore the tuple $(b, x_1, \ldots, x_{d})$ up to an isometry by the Anchor Lemma (Lemma \ref{l.anchor}). In particular, we can compute $\ad(b, x_1, \ldots, x_{d})$. Since we are in $d$-dimensional space, the maximum of $\ad(b, x_1, \ldots, x_{d})$ over $(x_1, \ldots, x_{d})\in S^{d}$ is equal to $\ad(S)$. Thus, we can compute $\ad(S)$.
 If $\ad(S) < d$,  any enhanced profile with maximal dimension satisfies the initialization requirement, and we are done. Assume therefore that $\ad(S) = d$. Our task is to output some $EP(x_1, \ldots, x_{d})$ such that  
 \begin{enumerate}
     \item $\ad(b, x_1, \ldots, x_{d}) = d$, and
     \item there is no $x\in S$ such that $x - b$ belongs to the interior of $\cone(x_1 - b, \ldots, x_{d} - b)$. 
 \end{enumerate}
 
 For that, among all $d$-dimensional enhanced profiles, we output one which minimizes the solid angle at the origin, defined as 
\begin{equation}
    \label{int}
    \mathsf{Angle}(x_1-b,\dots,x_d-b)=\frac1d\mathsf{Vol}\left\{x\in\cone(x_1-b,\dots, x_d-b):\ \|x\|\le 1 \right\}
\end{equation}
(the solid angle is invariant under isometries, and hence can be computed from $EP(x_1, \ldots, x_d)$).
%First, knowing $EP(x_1, \ldots, x_{d})$, we can compute solid angle. Indeed, take any tuple of points $(b^\prime, x_1^\prime, \ldots, x_{d}^\prime)$ which is isometric to $(b, x_1, \ldots, x_{d})$. Observe that 
%\[
%\mathsf{Angle}(x_1^\prime - b^\prime, \ldots, x_{d}^\prime - b^\prime)=\mathsf{Angle}(x_1 - b, \ldots, x_{d} - b),
%\]
%because there is an isometry that preserves $0$ and maps  
%\[
%x_1^\prime - b^\prime \mapsto x_1 - b, \quad \ldots, \quad x_{d}^\prime - b^\prime \mapsto x_{d} - b.
%\] 
%Now, we take any $d$-dimensional $EP(x_1, \ldots, x_{d})$ that minimizes \eqref{int}. 
We have to show that for all $x\in S$ we have that $x-b$ lies outside the interior of $\cone(x_1 -  b, \ldots, x_{d} - b)$. To prove this, we need an extra lemma. We will say that a cone $C$ is \emph{simple} if $C=\cone(u_1, \ldots, u_{d})$, for some linearly independent $u_1, \ldots, u_{d}$. Observe that if $C = \cone(u_1, \ldots, u_{d})$ is a simple cone, then the interior of $C$ is the set  \[
int(C)=\{\lambda_1 u_1 +\ldots +\lambda_{d} u_{d}\mid \lambda_1, \ldots, \lambda_{d}\in (0,+\infty)\}.
\]
Note also that the boundary of $C$ consists of $d$ faces
\[F_i = C \cap \ls(u_1, \ldots, u_{i -1}, u_{i+1}, \ldots, u_{d}), \quad  i = 1, \ldots, d.
\]
\begin{Lemma}\label{l.volume}
    Let $C=\cone(\mathbf{u})\subseteq \mathbb R^d$ for $\mathbf u=(u_1,\dots,u_d)$ be a simple cone and let $y$ belong to the interior of $C$. Then  $\cone(\mathbf u[y/1])$ is a simple cone and $\mathsf{Angle}(\mathbf u[y/1]) < \mathsf{Angle}(\mathbf u)$.
   % \[
    %    \mathsf{Angle}(\mathbf u) = \sum_{i=1}^d\mathsf{Angle}(\mathbf u[y/i]) \quad \text{and}\quad \mathsf{Angle}(\mathbf u[y/i])>0, \forall i=1,\dots,d. 
    %\]
    %In particular for all $1\le i\le d$, $\mathsf{Angle}(\mathbf u[y/i])<\mathsf{Angle}(\mathbf u)$.
\end{Lemma}
\begin{proof}

Since $y$ belongs to the interior of $\cone(\mathbf u)$, we have that 
\[y = \lambda_1 u_1 +\ldots + \lambda_d u_d,\]
for some $\lambda_1 > 0, \ldots, \lambda_d > 0$. The fact that $\lambda_1 > 0$ implies that $y, u_2, \ldots, u_d$ are linearly independent, and hence $\cone(\mathbf u[y/1])$ is a simple cone. Since $y\in \cone(\mathbf{u})$, we have that $\cone(\mathbf u[y/1])\subseteq \cone(\mathbf{u})$. Thus, to show that $\mathsf{Angle}(\mathbf u[y/1]) < \mathsf{Angle}(\mathbf u)$, it suffices to show that the volume of
\[\{x\in \cone(\mathbf u):\ \|x\| \le 1\}\setminus \{x\in \cone(\mathbf u[y/1]):\ \|x\| \le 1\}\]
is positive. We claim that  for any point $x = \mu_1 u_1 + \ldots +\mu_d u_d\in \cone(\mathbf u[y/1])$ we have $\mu_1 > 0 \implies \mu_2/\mu_1 \ge \lambda_2/\lambda_1$.  This is because $x$ can be written as a non-negative linear combination of $y, u_2, \ldots, u_d$. 
Since $\mu_1 > 0$, the coefficient in front of $y$ in this linear combination must be positive. Now, if the coefficient in front of $u_2$ is $0$, then the ratio between $\mu_2$ and $\mu_1$ is exactly as the ratio between $\lambda_2$ and $\lambda_1$, and if the coefficient before $u_2$ is positive, $\mu_2$ can only increase.

This means that no point of the form
\begin{equation}
\label{no_point}
x = \mu_1 u_1 + \ldots +\mu_d u_d, \qquad 0 < \mu_1,\,\, \mu_2/\mu_1 < \lambda_2/\lambda_1
\end{equation}
belongs to $\cone(\mathbf u[y/1])$. It remains to show that the set of points that satisfy \eqref{no_point} and lie in $\{x\in \cone(\mathbf u):\ \|x\| \le 1\}$ has positive volume.

Indeed, for any  $\varepsilon > 0$ and $\delta > 0$, consider a $d$-dimensional parallelepiped:
\[P = \{\mu_1 x_1 +\ldots + \mu_d x_d \mid  \mu_1 \in [\varepsilon/2, \varepsilon], \,\mu_2, \ldots, \mu_d\in[\delta/2, \delta]\}.\]
Regardless of $\varepsilon$ and $\delta$, we have that $P$ is a subset of $\cone(\mathbf{u})$ and its volume is positive. For all sufficiently small $\varepsilon, \delta$, we have that $P$ is a subset of the unit ball $\{x\in\mathbb{R}^d\mid \|x\| \le 1\}$. In turn, by choosing $\varepsilon$ to be sufficiently big compared to $\delta$, we ensure that all points of $P$ satisfy \eqref{no_point}.



%    Each point in $\cone(\mathbf u)$ lies in one of $\cone(\mathbf u[y/i]), 1\le i\le d$ and these subcones meet at most on their boundaries, which are of dimension $d-1$ and thus have zero $d$-dimensional volume. The first claimed formula follows from the inclusion-exclusion formula for the volume of a union of sets, together with \eqref{int}.
    
 %   It remains to show that $\mathsf{Angle}(\mathbf u[y/i])>0$ for all $i$. If $y_{norm}=y/|y|$ and $\mathbf u_{norm}=(u_1/|u_1|,\dots,u_d/|u_d|)$, then note that $y_{norm}$ is at positive distance from the faces $F_i$ of $\cone(\mathbf u)=\cone(\mathbf u_{norm})$. The face with vertices $0,u_1/|u_1|,\dots,u_{i-1}/|u_{i-1}|,u_{i+1}/|u_{i+1}|,\dots,u_d/|u_d|$ has positive area, since otherwise $\cone(\mathbf u)$ would be degenerate and would have no interior. Furthermore, the height of $y_{norm}$ with respect to this face is also positive. This means that the simplex with vertices $\mathbf u_{norm}[y_{norm}/i]$ has positive volume $V_i>0$. By examining \eqref{int} we thus see that $\mathsf{Angle}(\mathbf u_{norm}[y_{norm}/i]) = \mathsf{Angle}(\mathbf u[y/i])\geq V_i>0$, thus completing the proof.
\end{proof}
%\begin{Lemma}
%\label{l.interior}
%    Let $C = \cone(u_1, \ldots, u_{d})\subseteq \mathbb{R}^d$ be a simple cone and let $y$ belong to the interior of $C$. Then $C_1 = \cone(y, u_2, \ldots, x_{d})$ is a simple cone which is a proper subset of $C$. 
%\end{Lemma}
%\begin{proof}
%Since $y, u_2, \ldots, u_{d}\in \cone(u_1, \ldots, x_{d})$, we have that $C_1\subseteq C$.
%Since $y$ is in the interior of $C$, we have that $y = \lambda_1 u_1 + \lambda_2 u_2 +\ldots + \lambda_{d} u_{d}$ for some positive $\lambda_1, \ldots, \lambda_{d}$. In particular, $\lambda_1\neq 0$ implies that $y_1, u_2, \ldots, u_{d}$ are linearly independent. Now, we claim that $u_1\notin C_1$, which implies that $C_1$ is a proper subset of $C$. Indeed, otherwise there exists $\mu_1, \mu_2, \ldots, \mu_{d}\ge 0$ such that:
%\[\mu_1(\lambda_1 u_1 + \lambda_2 u_2 +\ldots + \lambda_{d} u_{d}) + \mu_2 u_2 + \ldots +\mu_{d} u_{d} = u_1.\]
%By linear independency of $u_1, \ldots, u_{d}$, this implies that $\mu_1\lambda_1 = 1$ and $ \mu_1\lambda_2 + \mu_2 = \ldots = \ \mu_1\lambda_{d} + \mu_{d} = 0$. Since $\lambda_1, \lambda_2 > 0$, $\mu_2\ge 0$ and $\mu_1 = 1/\lambda_1$, we obtain that $\mu_1\lambda_2 + \mu_2 = \lambda_2/\lambda_1 + \mu_2 > 0$, a contradiction.
%\end{proof}
%
%\begin{Lemma}
%\label{l.volume}
%    Let $C_1, C\subseteq \mathbb{R}^{d}$ be two simple cones. If $C\setminus C_1\neq \varnothing$, then the $d$-dimensional volume of $C\setminus C_1$ is not 0.
%\end{Lemma}
%\begin{proof}
%    Take any $x\in C\setminus C_1$. It is well-known that all finitely generated cones are closed. Hence, there exists a ball $B$ with a positive radius and with the center at $x$ which is disjoint from $C_1$. We claim that a positive volume of this ball belongs to $C$. Indeed, assume that $C = \cone(u_1, \ldots, u_{d})$. Then $x = \lambda_1 u_1 + \ldots \lambda_{d}u_{d}$ for some non-negative $\lambda_1, \ldots, \lambda_{d}$. For some $\varepsilon > 0$, all points of the form:
%    \[(\lambda_1 + \theta_1\varepsilon) u_1 +  \ldots+ (\lambda_{d} + \theta_{d}\varepsilon)u_{d},\]
%    for $\theta_1, \ldots, \theta_{d}\in [0,1]$
%    belong to $B\cap C$. In turn, the set of these points forms a full-dimensional set, whose $d$-dimensional volume is positive. 
%\end{proof}

Now we can finish the proof of the Initialization Lemma. Let $\mathbf x\in S^d$ minimize $\mathsf{Angle}(x_1-b,\dots,x_d-b)$ amongst $\mathbf x\in S^d$ such that $\ad(b,x_1,\dots,x_d)=d$. Assume that $\mathbf x$ does not satisfy the cone condition, and let $x\in S$ be such that $x - b\in Int(\cone(x_1 -  b, \ldots, x_{d} - b))$ holds. Then, by Lemma \ref{l.volume},  $\mathsf{Angle}(x -  b, x_2 - b \ldots, x_{d} - b)$ is strictly smaller than $\mathsf{Angle}(x_1 -  b, x_2 - b \ldots, x_{d} - b)$. As $\cone(x -  b, x_2 - b \ldots, x_{d} - b)$ is a simple cone, $x - b, x_2 - b, \ldots, x_{d} - b$ are linearly independent, and thus $\ad(b, x, x_2, \ldots, x_{d})=d$, contradicting the minimality hypothesis on $\mathbf x$, as desired.



  


