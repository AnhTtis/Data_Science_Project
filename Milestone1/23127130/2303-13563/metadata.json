{
    "arxiv_id": "2303.13563",
    "paper_title": "Skip Connections in Spiking Neural Networks: An Analysis of Their Effect on Network Training",
    "authors": [
        "Hadjer Benmeziane",
        "Amine Ziad Ounnoughene",
        "Imane Hamzaoui",
        "Younes Bouhadjar"
    ],
    "submission_date": "2023-03-23",
    "revised_dates": [
        "2023-03-27"
    ],
    "latest_version": 1,
    "categories": [
        "cs.NE",
        "cs.CV",
        "cs.LG"
    ],
    "abstract": "Spiking neural networks (SNNs) have gained attention as a promising alternative to traditional artificial neural networks (ANNs) due to their potential for energy efficiency and their ability to model spiking behavior in biological systems. However, the training of SNNs is still a challenging problem, and new techniques are needed to improve their performance. In this paper, we study the impact of skip connections on SNNs and propose a hyperparameter optimization technique that adapts models from ANN to SNN. We demonstrate that optimizing the position, type, and number of skip connections can significantly improve the accuracy and efficiency of SNNs by enabling faster convergence and increasing information flow through the network. Our results show an average +8% accuracy increase on CIFAR-10-DVS and DVS128 Gesture datasets adaptation of multiple state-of-the-art models.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.13563v1"
    ],
    "publication_venue": "IPDPSW Scalable Deep Learning 2023"
}