% \vspace{-2mm}

\input{table/ablation-ensemble}
\section{Limitation}
%As described in our paper, we are the first to explore the contrastive language-3D pretraining with the data source from free realistic open world. Though our method enable zero-shot localization and recognition with proposed triplet proxy generation and learned transferable 3D representation, we can not provide the accurate tight bounding box for open-world 3D objects as a common detector. We believe our framework can facilitate the development of open-world 3D detector, by introducing our recognition ability on a general 3D detector or directly conduct detector training based on our present 3D proxies.
 As a pilot work for the language-3D pretraining problem, though CLIP$^2$ enables zero-shot localization and recognition with proposed triplet proxy generation and learned transferable 3D representation, it can not provide the accurate tight bounding box for open-world 3D objects as a common detector does. We believe CLIP$^2$ can facilitate the development of open-world 3D detectors by introducing the recognition ability to general 3D detectors or providing presented 3D proxies to enable further training of 3D detectors.
%  \vspace{-2mm}
\section{Conclusion}
In this paper, we present a novel contrastive language-image-point cloud pretraining framework, CLIP$^2$, which consists of a triplet proxy collection scheme and a cross-modal contrastive learning mechanism. Based on the observation that realistic scenarios contain a massive amount of open-world objects, we innovatively propose to collect triplet proxies from realistic scenes as pretraining data. We then conduct cross-modal contrastive alignment across language, image and point cloud feature space to learn transferable 3D representation. The zero-shot transfer results on various indoor and outdoor benchmarks validate the ability of  CLIP$^2$ for 3D open-world understanding.

\paragraph{Acknowledgements} We gratefully acknowledge the support of MindSpore\footnote{\url{https://www.mindspore.cn/}}, CANN (Compute
Architecture for Neural Networks) and Ascend AI Processor in this work.
