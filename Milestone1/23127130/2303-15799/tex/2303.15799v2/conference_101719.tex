\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmicx,algorithm}
% \renewcommand{\algorithmicrequire}{ \textbf{Input:}} %Use Input in the format of Algorithm
% \renewcommand{\algorithmicensure}{ \textbf{Output:}} %UseOutput in the format of Algorithm
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{algpseudocode}
\usepackage{pdfpages}
% \usepackage[numbers,sort&compress]{natbib}
% \usepackage{hyperref}
\newtheorem{assumption}{Assumption}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{remark}{Remark}
\newtheorem{corollary}{Corollary}
\newtheorem{theorem}{Theorem}
\newtheorem{example}{Example}%[section]

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}

\title{Fast Convergent Federated Learning with Aggregated Gradients\\
% {\footnotesize \textsuperscript{*}Note: Sub-titles are not captured in Xplore and
% should not be used}
\thanks{\textsuperscript{*}corresponding author.}
}


\author{\IEEEauthorblockN{Wenhao Yuan}
\IEEEauthorblockA{\textit{School of Artificial Intelligence} \\
\textit{Sun Yat-sen University}\\
Zhuhai, China \\
yuanwh7@mail2.sysu.edu.cn}
\and
\IEEEauthorblockN{Xuehe Wang\textsuperscript{*}}
\IEEEauthorblockA{\textit{School of Artificial Intelligence} \\
\textit{Sun Yat-sen University}\\
Zhuhai, China \\
\textit{and Guangdong Key Laboratory of} \\
\textit{Big Data Analysis and Processing}\\
Guangzhou, China \\
wangxuehe@mail.sysu.edu.cn}
}

\maketitle

\begin{abstract}
Federated Learning (FL) is a novel machine learning framework, which enables multiple distributed devices cooperatively to train a shared model scheduled by a central server while protecting private data locally. However, the non-independent-and-identically-distributed (Non-IID) data samples and frequent communication across participants may significantly slow down the convergent rate and increase communication costs. To achieve fast convergence, we ameliorate the conventional local updating rule by introducing the aggregated gradients at each local update epoch, and propose an adaptive learning rate algorithm that further takes the deviation of local parameter and global parameter into consideration. The above adaptive learning rate design requires all clients' local information including the local parameters and gradients, which is challenging as there is no communication during the local update epochs. To obtain a decentralized adaptive learning rate for each client, we utilize the mean field approach by introducing two mean field terms to estimate the average local parameters and gradients respectively, which does not require the clients to exchange their local information with each other at each local epoch. Numerical results show that our proposed framework is superior to the state-of-art FL schemes in both model accuracy and convergent rate for IID and Non-IID datasets.
\end{abstract}

\begin{IEEEkeywords}
Federated learning, adaptive learning rate, mean field theory
\end{IEEEkeywords}

\section{Introduction}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The pervasiveness of edge devices in modern society, such as mobile phones and wearable devices, has led to the rapid growth of private data originating from distributed sources\cite{tan2022towards}. In the near future, it has been predicted that the rate of generating data will exceed the capacity of Internet \cite{chiang2016fog}. Tremendous data source provide plenty of opportunities for artificial intelligence (AI) researchers to train Multi-modal model, such as Stable Diffusion and ChatGPT. However, due to the emergence of  important standards relating to data privacy and protection, such as Convention 108+ of the Council of Europe\cite{warnat2021swarm} and the phenomenon of "data island"\cite{yang2020vertical}, it is a significant barrier for AI applications field to access and leverage these data\cite{kaissis2020secure}. The dual challenges of privacy protection and big data present an opportunity to develop new technologies that aggregate and model the data under  the premise of meeting
data privacy, security and regulatory requirements\cite{sun2020adaptive}.

A new paradigm named Federated Learning has been introduced to achieve multi-fold performance benefits including improving communication efficiency, as well as preserving data privacy\cite{mcmahan2017communication}. Specifically, each client train the model with its own dataset and then upload the local model parameter rather than the raw data to the FL central server for aggregation. The central server aggregates all local model parameters and distributes the updated global model back to all clients for the next round training. These steps are repeated until the desired accuracy is achieved\cite{zhang2021adaptive}. 

However, one of the key challenge for FL framework is statistical heterogeneity\cite{zhang2021adaptive,smith2017federated,li2020federated}. The data on each client is independently generated which may cause the data size and distribution on each node vary significantly, resulting in client drifting and slow convergent rate. Additionally, reasonable FL framework design is also crucial as the communication burden is a critical bottleneck in federated networks. Federated networks potentially comprise a massive number of edge devices, and the communication in the network could be very slow due to limited resources such as bandwidth, energy and power\cite{bonawitz2019towards,van2009multi}.

To tackle the challenges above, many efforts have been made. McMahan et al\cite{mcmahan2017communication} are the first to present the classic federated optimization method FedAvg, which is based on iterate model averaging and effectively reduces communication costs. However, FedAvg is mainly efficient for IID dataset, and becomes unstable for Non-IID dataset. To improve the performance on Non-IID datasets, FedProx\cite{li2020federated1} introduce a proximal term to the local subproblem to adjust the impact of local updates. Karimireddy et al \cite{karimireddy2020scaffold} propose an algorithm named SCAFFOLD to alleviate the effect of client drifting by using variance reduction. Based on deep Q-learning, H.Wang et al\cite{wang2020optimizing} propose FAVOR, which selects a subset of devices in each round to maximize a reward that encourages accuracy increase and penalizes using more communication rounds. \cite{zhao2018federated} propose a strategy to improve performance on Non-IID data by creating a small subset of data which is globally shared between all the edge devices. To improve the performance under the resource constrains, Zhang et al \cite{zhang2021adaptive} propose a deep reinforcement learning based approach to adaptively control the training of local models and the phase of global aggreagtion. Wang et al \cite{wang2019adaptive} propose a control algorithm that determines the best trade-off between local update and global parameter aggregation to minimize the loss function. Sun et al  \cite{sun2020adaptive} adaptively adjust the aggregation frequency based on Lyapunov dynamic deficit queue and deep reinforcement learning (DRL) to improve the learning performance.

Nevertheless, most methods overlook the importance of learning rate which is a hyperparameter that needs to be cautiously designed and may greatly affects the convergent rate of models. In this paper, to achieve fast convergence, we propose an adaptive learning rate scheme by considering the aggregated gradients updating rule for each client and the deviations between local parameters and global parameters. To deal with the communication issues, two mean field terms are introduced in the local objective function and local updating rule for each client for decentralized learning rate design. Further, we propose an algorithm to finalize our adaptive learning rate design. Our innovation points and main contributions are summarized as follows:
% This is important because decentralized machine learning models usually need to transfer pivotal data and frequent communication may retard convergence and increase the risk of data leakage during transmission. 
\begin{itemize} 
\item \emph{Adaptive learning rate strategy:} To our best knowledge, this paper is the first work studying how to assign an adaptive learning rate for each client at each local update epoch by introducing the aggregated gradient into the local updating rules and the parameter deviations into the objective function of each client, which effectively alleviates the negative influence from heterogeneous data and accelerates the convergent rate of global model.
\item \emph{Mean-field terms for decentralized learning rate design:} As there is no communication during local training epochs, we introduce two mean-field terms to estimate the average local parameters and gradients respectively, based on which each client receives a decentralized learning rate. 
\item \emph{Algorithms for finalizing the optimal learning rate:} Through rigorous analysis, we prove that there exist fixed point for the mean-field terms, and an algorithm is introduced to calculate the fixed point, which finalizes the optimal learning rate. The experimental results show that our FL method has a faster convergent rate and higher accuracy compared to other FL algorithms.
\end{itemize}

% \subsection{Related Work}

% McMahan et al\cite{mcmahan2017communication} are the first to present the classic federated optimization method FedAvg, which is based on iterate model averaging and effectively reduces communication costs. However, when training with Non-IID data, FedAvg would be affected by client drifting. Accordingly, the model turns to be unstable and has slow convergence rate. To alleviate the negative influence of client drifting that causes weight divergence between the local and global models, FedProx\cite{li2018convergence} introduced a proximal term to the local subproblem to adjust the impact of local updates. Karimireddy et al \cite{karimireddy2020scaffold} proposed an algorithm named SCAFFOLD to alleviate the effect of client drifting by using variance reduction. To improve the performance under the resource constrains, Zhang et al \cite{zhang2021adaptive} proposed a deep reinforcement learning based approach to adaptively control the training of local models and the phase of global aggreagtion. Wang et al \cite{wang2019adaptive} proposed a control algorithm that determines the best trade-off between local update and global parameter aggregation to minimize the loss function. Sun et al  \cite{sun2020adaptive} adaptively adjusted the aggregation frequency based on Lyapunov dynamic deficit queue and deep reinforcement learning (DRL) to improve the learning performance. Then, some researchers focus on designing efficient aggregation methods  to improve training efficiency. FedCS\cite{nishio2019client} solves a client selection problem with resource constraints. \cite{ribero2020communication} proposed an optimal sampling strategy for selecting a subset of clients with significant weight updates by an Ornstein-Uhlenbeck process. For the convergence issues of the learning rate in the process of FL training, \cite{leroy2019federated} used an adaptive averaging strategy inspired from Adam to reduces the number of communication rounds. Reddi et al \cite{reddi2020adaptive} present the upper bound for the client convergent learning rate of FedAdagrad, FedAdam and FedYogi. Xu et al \cite{xu2021learning} proposed a modified FedAvg algorithm by introducing dynamic learning rate and present the convergence analysis.

The rest of this paper is organized as follows. Problem formulation is given in Section \uppercase\expandafter{\romannumeral2}. In Section \uppercase\expandafter{\romannumeral3}, the design of adaptive learning rate is presented. Experimental results are shown in Section \uppercase\expandafter{\romannumeral4}. Section \uppercase\expandafter{\romannumeral5} presents the conclusion.

\section{Problem Formulation}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Standard Federated Learning Model}%%%%%%%%%%%%%%%%%%%%%%

In general, FL method\cite{mcmahan2017communication,lim2020federated} is a decentralized machine learning mechanism, which is designed to deal with the consensus learning task. In FL, a global model is collaboratively trained by a large number of clients with locally collected data. Each client performs one epoch of mini-batch stochastic gradient descent and transfers the updated local parameter to the central server. After updating global parameter by aggregating the local parameters, the central server sends the updated global parameter to all clients to trigger a new round of local training until the global model converges or reaches the maximum iteration\cite{tu2022adaptive}.  

% \begin{table}[t]
% \caption{loss function for popular machine learning models}
% \begin{center}
% \renewcommand\arraystretch{1.5}
% \begin{tabular}{p{0.85in}|p{2.3in}}
% \hline
% \textbf{Model}&\textbf{Loss function}$f(\mathbf{w}, \mathbf{x}_{j}, y_{j})(\triangleq f_{j}(\mathbf{w}))$\\
% % \cline{2-3} 
% \hline
% Linear regression & $\frac{1}{2}\left(x_{i}^{\mathbb{T}} w-y_{i}\right)^{2}$   \\
% Logistic regression &  $-\log \left(1+\exp \left(-y_{i} x_{i}^{\mathbb{T}} w\right)\right)$  \\
% Squared-SVM & $\frac{\lambda}{2}\|\mathbf{w}\|^{2}+\frac{1}{2} \max \left\{0, 1-y_{j} \mathbf{w}^{\mathrm{T}} \mathbf{x}_{j}\right\}^{2}$  \\
% K-Means & $\frac{1}{2} \min _{l}\|\mathbf{x}_{j}-\mathbf{w}_{(l)}\|^{2}, \mathbf{w} \triangleq[\mathbf{w}_{(1)}^{\mathrm{T}}, \mathbf{w}_{(2)}^{\mathrm{T}}, \ldots]^{\mathrm{T}}$   \\
% Convolutional neural network & Cross-entropy on cascaded linear and non-linear transformers, refer to \cite{Goodfellow-et-al-2016}   \\
% \hline
% \end{tabular}
% \label{tab1}
% \end{center}
% \end{table}

In particular, we assume that a standard federated leaning framework has $N$ clients and each participating client $i \in \{1, 2, \ldots, N\}$ uses its local data $\mathcal{D}_{i}$ with datasize $D_{i}$, where $D_{i} \triangleq\left|\mathcal{D}_{i}\right|$ and $\left|\ \cdot\ \right|$ denotes the cardinality of sets. Define $\{\boldsymbol{x_{i}^{j}},y_{i}^{j} \}_{j=1}^{D_{i}}$ as the data samples in $\mathcal{D}_{i}$, where $\boldsymbol{x}_{\boldsymbol{i}}^{j} \in \mathbb{R}^{d \times 1}$ represents the input sample vector and $y_{i}^{j} \in \mathbb{R}$  denotes the labeled output value. As the object of the federated learning model is to access the optimal parameter $\boldsymbol{w} \in \mathbb{R}^{d \times 1}$ based on the loss function $f_{i}^{j}\left(\boldsymbol{w},\boldsymbol{x}\right)$, which measures the difference between real output $y_{i}^{j}$ and predicted output $\hat{y}_{i}^{j}$. The local loss function of client $i$ on dataset $\mathcal{D}_{i}$ is as follow:
\[\begin{split}
F_{i}(\boldsymbol{w})=\frac{1}{D_{i}} \sum_{j \in \mathcal{D}_{i}} f_{i}^{j}(\boldsymbol{w}, \boldsymbol{x}_{\boldsymbol{i}}^{\boldsymbol{j}}).
\end{split} \tag{1}\]

In each global training iteration $t \in\{0,1, \ldots, T\}$, each client $i$ performs $L$ ($L \geq 1$ is a positive integer) epochs of SGD training to update its local parameter in parallel as follows:
\[\begin{split}
\boldsymbol{w_{i,l+1}^{t}}=\boldsymbol{w_{i,l}^{t}}-\eta_{i} \nabla F_{i}(\boldsymbol{w_{i,l}^{t}}),
\end{split} \tag{2}\]

\noindent where $\eta_{i}$ is the learning rate of client $i$. In classic federated algorithms, such as FedAvg, $\eta_{i}$ is a constant. We denote $\boldsymbol{w_{i,l}^{t}}$ and $\nabla F_{i}(\boldsymbol{w_{i,l}^{t}})$ as the local parameter and gradient of client $i$ at the $l$-th local epoch of global iteration $t$, where $l \in \{0,1,  \ldots, L\}$.  

The central server averages the parameters sent back by $N$ training clients to generate the updated global parameters:
\[\begin{split}
\boldsymbol{\bar w^{t}}=\sum_{i=1}^{N} \frac{D_{i}}{\sum_{j=1}^{N} D_{j}} \boldsymbol{w_{i,L}^{t-1}}.
\end{split} \tag{3}\]

At the onset of every round $t$, we have $\boldsymbol{w_{i,0}^{t}} = \boldsymbol{\bar w^{t}}$, $i \in\{1, 2, \ldots, N\}$. After updating global model, the central sever sends updated global parameter back to all clients for next round's training.

The goal of federated learning method is to find the optimal global parameter $\boldsymbol{w}$ to minimize the global loss function $F(\boldsymbol{w})$:
\[\begin{split}
\min _{\boldsymbol{w}} F(\boldsymbol{w})=\sum_{i=1}^{N} \frac{D_{i}}{\sum_{j=1}^{N} D_{j}} F_{i}(\boldsymbol{w}).
\end{split} \tag{4}\]

% \begin{table}[htbp]
% \caption{loss function for popular machine learning models}
% \begin{center}
% \renewcommand\arraystretch{1.5}
% \begin{tabular}{p{0.4in}|p{2.6in}}
% % \hline
% % \textbf{Model}&\textbf{Loss function}$f(\mathbf{w}, \mathbf{x}_{j}, y_{j})(\triangleq f_{j}(\mathbf{w}))$\\
% % % \cline{2-3} 
% \hline
% $F(\boldsymbol{w})$ & Global loss function   \\
% $F_{i}(\boldsymbol{w})$ &  Local loss function for client $i$ \\
% $f_{i}^{j}(\boldsymbol{w},\boldsymbol{x})$ & Loss function for client $i$ at each batch data \\
% $t$ & Global training  iteration   \\
% $l$ & Local training epoch \\
% $\boldsymbol{w_{i,l}^{t}}$ & Local model parameter for client $i$ at local epoch $l$ and global iteration $t$ \\
% \hline
% \end{tabular}
% \label{tab2}
% \end{center}
% \end{table}

\subsection{Adaptive Learning Rate with Aggregated Gradients}%%%%%%%%%
To deal with the client drifting effect for Non-IID dataset, we first modify the client's local parameter updating rule in Eq (2) by introducing the aggregated gradients of all participating clients as follows:
\[\begin{split}
\boldsymbol{w_{i,l+1}^{t}}=\boldsymbol{w_{i,l}^{t}}-\eta_{i,l}^{t} \cdot \left[\frac{1}{N} \sum_{i=1}^{N} \nabla{F_{i}(\boldsymbol{w_{i,l}^{t})}} \right],
\end{split} \tag{5}\]
% where $\eta_{i,l}^{t}$ is the adaptive learning rate of client $i$ at the $l$-th local epoch of global iteration $t$, and $\boldsymbol{w_{i,l}^{t}}$ is the local parameter of client $i$ at the $l$-th local epoch of global iteration $t$, where $l \in \{0,1,  \ldots, L\}$. At the onset of every round $t$, we have $\boldsymbol{w_{i,0}^{t}} = \boldsymbol{\bar w^{t}} = \sum_{i=1}^{N} \dfrac{D_{i}}{\sum_{j=1}^{N} D_{j}}\boldsymbol{w_{i,L}^{t-1}}$.
where $\eta_{i,l}^{t}$ is the adaptive learning rate of client $i$ at the $l$-th local epoch of global iteration $t$.

Then, in order to achieve fast convergence for each client $i$, a penalty term that measures the deviation between the local model parameter of client $i$ and the average local model parameter at each local training epoch $l$ is introduced in the objective function $U_{i}(l)$ of each client $i$:
\begin{align}
U_{i}(l) &= \min_{\substack{\eta_{i,l}^{t}, t \in\{0,1, \ldots, T\} \\  l \in\{0,1, \ldots, L\}}}\sum_{t=0}^{T} \sum_{l=0}^{L} \alpha (\eta_{i,l}^{t})^{2}+(1-\alpha) \cdot \nonumber \\
& \qquad (\boldsymbol{w_{i,l}^{t}}-\frac{1}{N} \sum_{j=1}^{N} \boldsymbol{w_{j,l}^{t}})^{T}(\boldsymbol{w_{i,l}^{t}}-\frac{1}{N}\sum_{j=1}^{N} \boldsymbol{w_{j,l}^{t}}), \tag{6} 
\end{align} 
\begin{align}
\text { s.t. } \quad  \boldsymbol{w_{i,l+1}^{t}}=\boldsymbol{w_{i,l}^{t}}-\eta_{i,l}^{t}  \left[\frac{1}{N} \sum_{i=1}^{N} \nabla{F_{i}(\boldsymbol{w_{i,l}^{t})}} \right], \tag{7}
\end{align} 
where $\alpha \in [0, 1]$ is a hyperparameter that adjusts the weight of each part in objective function $U_{i}(l)$.

As there is no communication among clients during each local training epoch, $l \in \{0,1,  \ldots, L\}$, client $i$ can not access $\boldsymbol{w_{j,l}^{t}}$ and $\nabla{F_{j}(\boldsymbol{w_{j,l}^{t})}}$, where $j \in S \setminus \{i\}$. However, the learning rate $\eta_{i,l}^{t}$ of each client $i$ is affected by other clients' local parameters $\boldsymbol{w_{j,l}^{t}}$ and $\nabla{F_{j}(\boldsymbol{w_{j,l}^{t})}}$, which makes this multi-clients joint adaptive learning rate design over time challenging. To tackle the above challenges, we first introduce two mean field terms to estimate the average of local parameter and gradient. Then, the decentralized adaptive learning rate of each client can be derived based on the two mean field terms, without requiring the clients to frequently communicate with each other.

\section{Design of Adaptive Learning Rate}%%%%%%%%%%%%%%%%%%%%%%%%
In this section, we develop our methodology for improving the convergent rate without communication at the end of each local training epoch. We first find the optimal adaptive learning rate $\eta_{i,l}^{t}$ for each client $i$ at each local update epoch $l$ of global iteration $t$ by introducing two estimators $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$ and then prove that $\eta_{i,l}^{t}$ can be represented as linear combination of $\boldsymbol{w_{i,l}^{t}}$, $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$ (Section \uppercase\expandafter{\romannumeral3}-A). Subsequently, we utilize Brouwer’s fixed point theorem to prove the existence of mean field term $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$, then $\eta_{i,l}^{t}$ is solvable can be proved (Section \uppercase\expandafter{\romannumeral3}-B).

\subsection{Decentralized Learning Rate For Each Client}%%%%%%%%%%%%%%%%%%

To figure out the adaptive learning rate for each client, we introduce two mean field terms $\boldsymbol{\phi_{1,l}^{t}}$, $t \in\{0,1, \ldots, T\}$, $l \in\{0,1, \ldots, L\}$ to estimate the average of all clients' gradients at the $l$-th local epoch of global iteration $t$ and $\boldsymbol{\phi_{2,l}^{t}}$, $t \in\{0,1, \ldots, T\}$, $l \in\{0,1, \ldots, L\}$ to estimate the average of all clients' local parameter at the $l$-th local epoch of global iteration $t$, i.e.,
\begin{align}
\boldsymbol{\phi_{1,l}^{t}} &= \dfrac{\sum_{i=1}^{N} \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})}}{N},  \tag{8}   
\end{align}
\begin{align}
\boldsymbol{\phi_{2,l}^{t}} &= \dfrac{\sum_{i=1}^{N} \boldsymbol{w_{i,l}^{t}}}{N}. \tag{9}    
\end{align}

From the mathematical point of view, $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$ are given functions. The deviation between local parameter and average local parameter could be evaluated as $\boldsymbol{w_{i,l}^{t}}-\boldsymbol{\phi_{2,l}^{t}}$. Accordingly, the objective function of each client $i$ can be rewritten as follow:
\begin{align}
\Tilde{U}_{i}(l) &= \min_{\substack{\eta_{i,l}^{t}, t \in\{0,1, \ldots, T\} \\  l \in\{0,1, \ldots, L\}}} \sum_{t=0}^{T} \sum_{l=0}^{L} \alpha(\eta_{i,l}^{t})^{2}+(1-\alpha) \cdot \nonumber \\
& \qquad\qquad (\boldsymbol{w_{i,l}^{t}}-\boldsymbol{\phi_{2,l}^{t}})^{T}(\boldsymbol{w_{i,l}^{t}}-\boldsymbol{\phi_{2,l}^{t}}), \tag{10}
\end{align} 
\[\begin{split}
\text { s.t. } \quad  \boldsymbol{w_{i,l+1}^{t}}=\boldsymbol{w_{i,l}^{t}}-\eta_{i,l}^{t}  \boldsymbol{\phi_{1,l}^{t}}.
\end{split} \tag{11}\]

By implementing the Hamilton equation, we can solve $\eta_{i,l}^{t}$ as shown in the following proposition.

\begin{proposition} \label{proposition 1}
Given the mean field terms $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$, the optimal adaptive learning rate of client $i\in\{1, 2, \ldots, N\}$ at the $l$-th ($l \in\{0,1, \ldots, L\}$) local epoch of global iteration $t$ ($t \in\{0,1, \ldots, T\}$) is:
\begin{align}
\eta_{i,l}^{t}&=\dfrac{1-\alpha}{\alpha}(\boldsymbol{\phi_{1,l}^{t}})^{T}((L-l)\boldsymbol{w_{i,l}^{t}} \nonumber \\
& \qquad -\sum_{r=l}^{L} (L-r)\eta_{i,r}^{t}\boldsymbol{\phi_{1,r}^{t}}- \sum_{k=l+1}^{L} \boldsymbol{\phi_{2,k}^{t}}), \tag{12}
\end{align}
with $\eta_{i,L}^{t}=0$. 
\end{proposition}
\emph{Proof}: Based on mean field terms $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$ , the Hamilton equation can be constructed as follows:
\[\begin{split}
H(l)&=(1-\alpha)(\boldsymbol{w_{i,l}^{t}}-\boldsymbol{\phi_{2,l}^{t}})^{T}(\boldsymbol{w_{i,l}^{t}}-\boldsymbol{\phi_{2,l}^{t}}) \\
& \qquad +\alpha (\eta_{i,l}^{t})^{2}-\boldsymbol{\lambda(l+1)}^{T}\eta_{i,l}^{t}\boldsymbol{\phi_{1,l}^{t}},
\end{split} \tag{13}\]
where $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$ can be viewed as given functions, which are not affected by the learning rate $\eta_{i,l}^{t}$. According to the properties of Hamilton function\cite{di2012discrete}, in order to obtain the expression of $\eta_{i,l}^{t}$, we need to consider the constrains on control vector $\eta_{i,l}^{t}$, $t \in\{0,1, \ldots, T\} , l \in\{0,1, \ldots, L\}$. The first condition for a minimum is to find the first derivative of the Hamilton function with respect to $\eta_{i,l}^{t}$:
\[\begin{split}
\frac{\partial H(l)}{\partial(\eta_{i,l}^{t})}=0. 
\end{split} \tag{14}\]

Then, we have:
\[\begin{split}
2\alpha \eta_{i,l}^{t}-\boldsymbol{\lambda(l+1)}^{T} \boldsymbol{\phi_{1,l}^{t}}=0.
\end{split} \tag{15}\]

Thus, we get an expression of $\eta_{i,l}^{t}$ as follow:
\[\begin{split}
\eta_{i,l}^{t}=\frac{1}{2 \alpha}( \boldsymbol{\phi_{1,l}^{t}})^{T} \boldsymbol{\lambda(l+1)}.
\end{split} \tag{16}\]

Calculate the second-order derivative of the Hamilton function to check the second condition for a minimum:
\[\begin{split}
\frac{\partial^{2} H(l)}{\partial (\eta_{i,l}^{t})^{2}}=2 \alpha>0,
\end{split} \tag{17}\]
we get the adaptive learning rate $\eta_{i,l}^{t}$ that minimizes the objective function. According to an important property of Hamilton equation \cite{qi2021linear}, we can get the following equation:
\[\begin{split}
\boldsymbol{\lambda(l+1)}-\boldsymbol{\lambda(l)} &= -\frac{\partial H(l)}{\partial(\boldsymbol{w_{i,l}^{t}})} \nonumber \\
&= -2(1-\alpha)(\boldsymbol{w_{i,l}^{t}}-\boldsymbol{\phi_{2,l}^{t}}).
\end{split} \tag{18}\]

According to \cite{di2012discrete}, the impulse vector $\boldsymbol{\lambda}$ has a known boundary condition for final value:
\[\begin{split}
\boldsymbol{\lambda(L)}=\frac{\partial S(\boldsymbol{w_{i,L}^{t}})}{\partial (\boldsymbol{w_{i,L}^{t}})}= 2(1-\alpha)(\boldsymbol{w_{i,L}^{t}}-\boldsymbol{\phi_{2,L}^{t}}),
\end{split} \tag{19}\] 
where $S(\cdot)$ is a weighting function of the state at the local update epoch $L$. Its expression is as follows:
\[\begin{split}
S(\boldsymbol{w_{i,L}^{t}}) = (1-\alpha)(\boldsymbol{w_{i,l}^{t}}-\boldsymbol{\phi_{2,l}^{t}})^{T}(\boldsymbol{w_{i,l}^{t}}-\boldsymbol{\phi_{2,l}^{t}}).
\end{split} \tag{20}\] 

Through calculating the formula of Eq (18) iteritively, we can easily obtain the expression of $\boldsymbol{\lambda(l+1)}$, $l \in\{0,1, \ldots, L-1\}$:
\begin{align}
\boldsymbol{\lambda(L-1)} &= \boldsymbol{\lambda(L)}+2(1-\alpha)(\boldsymbol{w_{i,L-1}^{t}}-\boldsymbol{\phi_{2,L-1}^{t}}) \nonumber \\
&= 2(1-\alpha)(\boldsymbol{w_{i,L}^{t}}- \boldsymbol{\phi_{2,L}^{t}}+\boldsymbol{w_{i,L-1}^{t}}- \boldsymbol{\phi_{2,L-1}^{t}}) \nonumber \\
&=2(1-\alpha)(2 \boldsymbol{w_{i,L-1}^{t}} \nonumber \\
& \qquad -\eta_{i,L-1}^{t} \boldsymbol{\phi_{1,L-1}^{t}} -\sum_{k=L-1}^{L}\boldsymbol{\phi_{2,k}^{t}}), \nonumber \\
\boldsymbol{\lambda(L-2)} &= \boldsymbol{\lambda(L-1)}+2(1-\alpha)(\boldsymbol{w_{i,L-2}^{t}}- \boldsymbol{\phi_{2,L-2}^{t}}) \nonumber \\
&= 2(1-\alpha)(3 \boldsymbol{w_{i,L-2}^{t}} \nonumber \\
& \qquad -\sum_{r=L-2}^{L-1} (L-r) \eta_{i,r}^{t} \boldsymbol{\phi_{1,r}^{t}}-\sum_{k=L-2}^{L} \boldsymbol{\phi_{2,k}^{t}}), \nonumber \\
&\quad \vdots  \nonumber \\
\boldsymbol{\lambda(l+1)} &= 2(1-\alpha)((L-l) \boldsymbol{w_{i,l+1}^{t}} \nonumber 
\\ & \quad -\sum_{r=l+1}^{L}(L-r)\eta_{i,r}^{t} \boldsymbol{\phi_{1,r}^{t}}  -\sum_{k=l+1}^{L} \boldsymbol{\phi_{2,k}^{t}}). \tag{21}
\end{align}

Then, based on the expression of $\eta_{i,l}^{t}$ in Eq (16) and $\boldsymbol{\lambda(l+1)}$ in Eq (21), we can solve $\eta_{i,l}^{t}$ as follows:
\begin{align}
\eta_{i,l}^{t} &= \dfrac{1}{2 \alpha}(\boldsymbol{\phi_{1,l}^{t}} )^{T} \boldsymbol{\lambda(l+1)} \nonumber \\
&=\dfrac{1-\alpha}{\alpha}(\boldsymbol{\phi_{1,l}^{t}})^{T}((L-l) \boldsymbol{w_{i,l+1}^{t}} \nonumber \\
& \qquad -\sum_{r=l+1}^{L}(L-r)\eta_{i,r}^{t}\boldsymbol{\phi_{1,r}^{t}}-\sum_{k=l+1}^{L} \boldsymbol{\phi_{2,k}^{t}}) \nonumber \\
&=\dfrac{1-\alpha}{\alpha}(\boldsymbol{\phi_{1,l}^{t}})^{T}((L-l) \boldsymbol{w_{i,l}^{t}} \nonumber \\
& \qquad -\sum_{r=l}^{L} (L-r)\eta_{i,r}^{t}\boldsymbol{\phi_{1,r}^{t}}-\sum_{k=l+1}^{L}\boldsymbol{\phi_{2,k}^{t}}). \nonumber
\end{align} $\hfill\blacksquare$ 

\begin{proposition} \label{proposition 2}
$\eta_{i,l}^{t}$ can be represented as linear combination of $\boldsymbol{w_{i,l}^{t}}$, $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$,  $l \in\{0,1, \ldots, L\}$, $t \in\{0,1, \ldots, T\}$ as follows:
\begin{align}
\eta_{i,l}^{t} = \Lambda \left(\boldsymbol{w_{i,l}^{t}},\boldsymbol{\phi_{1,0}^{t}},\ldots,\boldsymbol{\phi_{1,L}^{t}}, \boldsymbol{\phi_{2,0}^{t}}, \ldots, \boldsymbol{\phi_{2,L}^{t}}\right). \nonumber
\end{align}
\end{proposition}
\emph{Proof}: By adopting Inductive Reasoning, we can find the potential rules among $\eta_{i,l}^{t}$ , $\boldsymbol{w_{i,l}^{t}}$, $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$, $l \in\{0,1, \ldots, L\}$. Based on the expression of $\boldsymbol{\lambda(L-1)}$ and $\boldsymbol{\lambda(L-2)}$ above, we can derive as follows:

First of all, $\eta_{i,L-1}^{t}$ can be derived from $\boldsymbol{\lambda(L)}$ according to Eq (16):
\begin{align}
\eta_{i,L-1}^{t} &= \dfrac{1}{2 \alpha}( \boldsymbol{\phi_{1,L-1}^{t}} )^{T} \boldsymbol{\lambda(L)}  \tag{22} \\
&= \dfrac{1-\alpha}{\alpha}(\boldsymbol{\phi_{1,L-1}^{t}})^{T} (\boldsymbol{w_{i,L-1}^{t}} \nonumber \\
& \qquad -\boldsymbol{\phi_{2,L}^{t}}-\eta_{i,L-1}^{t}\boldsymbol{\phi_{1,L-1}^{t}}). \nonumber \\
\Rightarrow \ \eta_{i,L-1}^{t} &= \dfrac{1-\alpha}{\alpha}\cdot\dfrac{(\boldsymbol{\phi_{1,L-1}^{t}})^{T}(\boldsymbol{w_{i,L-1}^{t}}-\boldsymbol{\phi_{2,L}^{t}})}{1+\dfrac{1-\alpha}{\alpha}( \boldsymbol{\phi_{1,L-1}^{t}})^{T} \boldsymbol{\phi_{1,L-1}^{t}}}. \tag{23}
\end{align} 

Then, we calculate the expression of $\eta_{i,L-2}^{t}$ based on $\boldsymbol{\lambda(L\!-\!1)}$ and $\eta_{i,L-1}^{t}$ above:
\begin{align}
\eta_{i,L-2}^{t} &= \dfrac{1}{2 \alpha}( \boldsymbol{\phi_{1,L-2}^{t}} )^{T} \boldsymbol{\lambda(L-1)} \tag{24} \\
&= \zeta_{2} (2 \boldsymbol{w_{i,L-1}^{t}}-\eta_{i,L-1}^{t}\boldsymbol{\phi_{1,L-1}^{t}}-\zeta_{1}) \nonumber \\
&= \zeta_{2} (2 (\boldsymbol{w_{i,L-2}^{t}}-\eta_{i,L-2}^{t} \boldsymbol{\phi_{1,L-2}^{t}})-\zeta_{1}-\zeta_{3}).\nonumber \\
\Rightarrow \quad \eta_{i,L-2}^{t} &= \dfrac{\zeta_{2} (2 \boldsymbol{w_{i,L-2}^{t}}-\zeta_{7})}{1+\zeta_{5}+\zeta_{8}}. \tag{25}
\end{align}
where, $\zeta_{1}=\sum_{k=L-1}^{L} \boldsymbol{\phi_{2,k}^{t}}$, $\zeta_{2}=\dfrac{1-\alpha}{\alpha}(\boldsymbol{\phi_{1,L-2}^{t}} )^{T}$, $\zeta_{3}=\dfrac{\dfrac{1-\alpha}{\alpha}( \boldsymbol{\phi_{1,L-1}^{t}})^{T}}{1+\zeta_{4}} \cdot \zeta_{6}$, $\zeta_{4}=\dfrac{1-\alpha}{\alpha}(\boldsymbol{\phi_{1,L-1}^{t}} )^{T} \boldsymbol{\phi_{1,L-1}^{t}}$, 
\[\begin{split}
\zeta_{5}&=2 \cdot \dfrac{1-\alpha}{\alpha}( \boldsymbol{\phi_{1,L-2}^{t}})^{T} \boldsymbol{\phi_{1,L-2}^{t}},\\
\zeta_{6}&=(\boldsymbol{w_{i,L-1}^{t}}-\eta_{i,L-2}^{t}\boldsymbol{\phi_{1,L-2}^{t}}-\boldsymbol{\phi_{2,L}^{t}}) \boldsymbol{\phi_{1,L-1}^{t}}, \\
\zeta_{7}&=\dfrac{1-\alpha}{\alpha}\dfrac{(\boldsymbol{\phi_{1,L-1}^{t}})^{T} (\boldsymbol{w_{i,L-2}^{t}}-\boldsymbol{\phi_{2,L}^{t}} )\boldsymbol{\phi_{1,L-1}^{t}}+\zeta_{1}}{1+\zeta_{4}},\\
\zeta_{8}&=2\cdot \left(\dfrac{1-\alpha}{\alpha}\right)^{2}\dfrac{(\boldsymbol{\phi_{2,L-2}^{t}})^{T}(\boldsymbol{\phi_{2,L-1}^{t}})^{T}\boldsymbol{\phi_{2,L-2}^{t}}\boldsymbol{\phi_{1,L-1}^{t}}}{1+\zeta_{4}}.
\end{split}\]

Repeating the process of deducing $\eta_{i,L-1}^{t}$ and $\eta_{i,L-2}^{t}$, we can acquire the expression of $\eta_{i,l}^{t}$, $l \in\{0,1, \ldots, L\}$. $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$, $l \in\{0,1, \ldots, L\}$ can be view as given functions. Besides, We note that we can always find a linear function of $\eta_{i,l}^{t}$ expressed by $\boldsymbol{w_{i,l}^{t}}$ and $\eta_{i,q}^{t}$, $q \in\{l+1, \ldots, L\}$ that we have already calculated before $\eta_{i,l}^{t}$. Therefor, $\eta_{i,l}^{t}$, $l \in\{0,1, \ldots, L-1\}$ can achieve solution in an iterative algorithm. $\hfill\blacksquare$ 

\subsection{Update of Estimator $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$ for Finalizing Learning Rate}

Given the optimal adaptive learning rate $\eta_{i,l}^{t}$ in Eq (12), we are ready to find the estimator $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$ in this section. Noted that estimators $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$ are affected by the local gradient $\nabla{F_{i}(\boldsymbol{w_{i,l}^{t})}}$ and local parameter $\boldsymbol{w_{i,l}^{t}}$ of all clients which inversely affect $\nabla{F_{i}(\boldsymbol{w_{i,l}^{t})}}$ and $\boldsymbol{w_{i,l}^{t}}$. Subsequently, we will acquire precise solutions for estimator $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$ by finding the fixed point.

According to Eq (7), we display each step of $\boldsymbol{w_{i,l+1}^{t}}$, $t \in\{0,1, \ldots, T\}$, $l \in\{0,1, \ldots, L-1\}$:
\vspace{-5pt}
\[\begin{split}
    \boldsymbol{w_{i,l+1}^{t}}&=\boldsymbol{w_{i,l}^{t}}-\eta_{i,l}^{t} \cdot \left[\frac{1}{N} \sum_{i=1}^{N} \nabla{F_{i}(\boldsymbol{w_{i,l}^{t})}}\right],\\
    &\vdots \\
    \boldsymbol{w_{i,1}^{t}}&=\boldsymbol{w_{i,0}^{t}}-\eta_{i,0}^{t} \cdot \left[\frac{1}{N} \sum_{i=1}^{N} \nabla{F_{i}(\boldsymbol{w_{i,0}^{t})}} \right].
\end{split} \tag{26}\]
\vspace{-5pt}

Add all equations in (26) together, then we can access a new expression of $\boldsymbol{w_{i,l}^{t}}$, $t \in\{0,1, \ldots, T\}$, $l \in\{0,1, \ldots, L\}$:
\begin{align}
\boldsymbol{w_{i,l}^{t}}&=\boldsymbol{w_{i,0}^{t}}-\sum_{p=0}^{l-1} \eta_{i,p}^{t} \cdot \dfrac{\sum_{i=1}^{N} \nabla{F_{i} (\boldsymbol{w_{i,p}^{t}})}}{N} \tag{27} \\ 
&= \boldsymbol{w_{i,0}^{t}}-\sum_{p=0}^{l-1} \dfrac{1-\alpha}{\alpha}\left( \dfrac{\sum_{i=1}^{N} \nabla{F_{i} (\boldsymbol{w_{i,p}^{t}})}}{N} \right)^{T} \cdot \nonumber \\ 
&\left(\left(L-p\right) \boldsymbol{w_{i,p}^{t}}-\sum_{r=p}^{L} \left(L-r\right) \eta_{i,r}^{t} \dfrac{\sum_{i=1}^{N} \nabla{F_{i} (\boldsymbol{w_{i,r}^{t}})}}{N} \right. \nonumber \\
& \left. \qquad\quad-\sum_{k=p+1}^{L} \dfrac{\sum_{i=1}^{N} \boldsymbol{w_{i,k}^{t}}}{N}\right) \dfrac{\sum_{i=1}^{N} \nabla{F_{i} (\boldsymbol{w_{i,p}^{t}})}}{N}. \tag{28}
\end{align}  

For any client $i$, substitute $\boldsymbol{\phi_{1,l}^{t}} = \dfrac{1}{N}\sum_{i=1}^{N} \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})}$, $t \in\{0,1, \ldots, T\}, l \in\{0,1, \ldots, L\}$ and $\boldsymbol{\phi_{2,l}^{t}} = \dfrac{1}{N}\sum_{i=1}^{N} \boldsymbol{w_{i,l}^{t}}$, $t \in\{0,1, \ldots, T\}, l \in\{0,1, \ldots, L\}$ into Eq (28), we can see that $\boldsymbol{w_{i,l}^{t}}$ and $\nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})}$ of client $i$ at the $l$-th local epoch of global iteration $t$ are a function of $\{\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})} \mid t \in\{0,1, \ldots, T\}, l \in\{0,1, \ldots, L\}\}$ of all clients. Define the following function as a mapping from $\{\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})} \mid t \in\{0,1, \ldots, T\}, l \in\{0,1, \ldots, L\}\}$ to client $i$'s local parameter $\boldsymbol{w_{i,l}^{t}}$ and local gradient $\nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})}$ in Eq (28) at global iteration $t$:
\begin{align}
(\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})}) &=\Gamma_{l}^{t}(\{\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})} \mid t \in\{0,1,\ldots,T\}, \nonumber\\
& \qquad  l \in\{0,1, \ldots, L\}\}). \tag{29}
\end{align}

\begin{algorithm}[t]
\caption{Iterative computation of two fixed point estimators $\boldsymbol{\phi_{1,l}^{t}}$, $\boldsymbol{\phi_{2,l}^{t}}$ and $\eta_{i,l}^{t}$, $ t \in\{0,1, \ldots, T\},l \in\{0,1, \ldots, L\}$ } %算法的名字
\hspace*{0.02in} {\bf Input: } %算法的输入， \hspace*{0.02in}用来控制位置，同时利用 \\ 进行换行
Local training epoch $L$, $\epsilon_{1}=1$, $\epsilon_{2}=1$, $\epsilon=0.001$, $j=1$, arbitrary initial $\boldsymbol{\phi_{1,l}^{t}}^{est}(0) \ge 0$, $\boldsymbol{\phi_{2,l}^{t}}^{est}(0) \ge 0$, $ t \in\{0,1, \ldots, T\}, l \in\{0,1, \ldots, L\}$ and $\boldsymbol{\phi_{1,l}^{t}}=\boldsymbol{\phi_{1,l}^{t}}^{est}(0)$, $\boldsymbol{\phi_{2,l}^{t}}=\boldsymbol{\phi_{2,l}^{t}}^{est}(0)$, $ t \in\{0,1, \ldots, T\},l \in\{0,1, \ldots, L\}$, $\boldsymbol{w_{i,0}^{t}}$, $ t \in\{0,1, \ldots, T\}, i \in\{1, 2, \ldots, N\}$, arbitrary initial $\eta_{i,l}^{t} \in (0, 1)$, $ t \in\{0,1, \ldots, T\},l \in\{0,1, \ldots, L\}, i \in\{1, 2, \ldots, N\}$
\begin{algorithmic}[1]
\For{$t=0$ to $T$}
    \While{$\epsilon_{1} > \epsilon$ and $\epsilon_{2} > \epsilon$}
        \For{each client $i \in\{0,1, \ldots, N\}$}
            \For{$l=1$ to $L-1$}
            \State Compute $\eta_{i,l}^{t}$ according to Eq (12)
            \State Compute $\boldsymbol{w_{i,l}^{t}}$ according to Eq (11)
            \State Compute $\nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})}$ according to Eq (32)   
            % according to Eq(11), Eq(35) 
            \EndFor
        \EndFor
            \For{$l=0$ to $L-1$}
            \State $\boldsymbol{\phi_{2,l}^{t}}^{est}(j)=\dfrac{\sum_{i=1}^{N} \boldsymbol{w_{i,l}^{t}}}{N}$
            \State $\boldsymbol{\phi_{2,l}^{t}}=\boldsymbol{\phi_{2,l}^{t}}^{est}(j)$
            \State $\epsilon_{2}'=\boldsymbol{\phi_{2,l}^{t}}^{est}(j)-\boldsymbol{\phi_{2,l}^{t}}^{est}(j-1)$
            \EndFor
            \State $\epsilon_{2}=\sum_{l=0}^{L} \epsilon_{2}'$
            \For{$l=0$ to $L-1$}
            \State $\boldsymbol{\phi_{1,l}^{t}}^{est}(j)=\dfrac{\sum_{i=1}^{N} \nabla{F_{i} (\boldsymbol{w_{i,l}^{t})}}}{N}$
            \State $\boldsymbol{\phi_{1,l}^{t}}=\boldsymbol{\phi_{1,l}^{t}}^{est}(j)$
            \State $\epsilon_{1}'=\boldsymbol{\phi_{1,l}^{t}}^{est}(j)-\boldsymbol{\phi_{1,l}^{t}}^{est}(j-1)$
            \EndFor
            \State $\epsilon_{1}=\sum_{l=0}^{L} \epsilon_{1}'$
            \State $j=j+1$
    \EndWhile
\EndFor
\State \Return The fixed point estimators $\boldsymbol{\phi_{1,l}^{t}}$, $\boldsymbol{\phi_{2,l}^{t}}$ and adaptive learning rate $\eta_{i,l}^{t}$, $ t \in\{0,1, \ldots, T\},l \in\{0,1, \ldots, L\}$
\end{algorithmic}
\end{algorithm}

To summarize any possible mapping $\Gamma_{l}^{t}$, we can define following vector functions as a mapping from $\{\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})} \mid t \in\{0,1, \ldots, T\},l \in\{0,1, \ldots, L\}\}$ to the set of all the clients:
\begin{align} 
& \Gamma(\{\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})} \mid t \in\{0,1, \ldots, T\}, l \in\{0,1, \ldots, L\}\}) \nonumber \\
&=(\Gamma_{0}^{0}(\{\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})} \mid t \in\{0,1, \ldots, T\}, l \in\{0,1, \ldots,  \nonumber \\
& L\}\}), \ldots, \Gamma_{L}^{0}(\{\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})} \mid t \in\{0,1, \ldots, T\},l \in\{0,1, \nonumber \\ 
& \ldots, L\}\}), \ldots, \Gamma_{0}^{T}(\{\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})} \mid t \in\{0,1, \ldots, T\}, l \in \nonumber \\
&\{0,1, \ldots, L\}\}), \ldots, \Gamma_{L}^{T}(\{\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})} \mid t \in\{0,1, \ldots,  T\}, \nonumber \\
& l \in\{0,1, \ldots, L\}\})). \tag{30}
\end{align} 

Thus, the fixed point to $\Gamma (\{\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})} \mid t \in\{0,1, \ldots, T\}, l \in\{0,1, \ldots, L\}\}) = \Gamma (\{\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})} \mid  t \in\{0,1, \ldots, T\}, l \in\{0,1, \ldots, L\}\})$ in Eq (30) should be reached to let $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$ replicate $\dfrac{1}{N}\sum_{i=1}^{N} \nabla{F_{i} (\boldsymbol{w_{i,l}^{t})}}$ and $\dfrac{1}{N}\sum_{i=1}^{N} \boldsymbol{w_{i,l}^{t}}$, respectively.

Since $F_{i}(\boldsymbol{w_{i,l}^{t}})$ is continuous differentiable, we can access the upperbound for $\nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})}$:
\[\begin{split}
\| \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})}\| \le P.
\end{split} \tag{31} \]

Based on the extension of Fundamental Theorem for Line Integrals, we have:
\[\begin{split}
dF(\boldsymbol{w_{i,l}^{t}})=d\boldsymbol{w_{i,l}^{t}} \cdot \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})}.
\end{split} \tag{32} \]

Then, according to Eq (27), we noted that both $\boldsymbol{w_{i,0}^{t}}$ and $\eta_{i,0}^{t}$, $t \in\{0,1, \ldots, T\}$ are bounded. Besides, on account of $\nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})}$, $t \in\{0,1, \ldots, T\}, l \in\{0,1, \ldots, L\}$ is bounded as we proved above and based on Proposition 2, we have each term in the Eq (27) is bounded. Thus, we also have the following upperbound for $\boldsymbol{w_{i,l}^{t}}$:
\[\begin{split}
\| \boldsymbol{w_{i,l}^{t}}\| \le Q.
\end{split} \tag{33} \]

Define continuous space $\Omega=[-Q, Q]_{0}^{0} \times \ldots \times[-Q, Q]_{L}^{0} \times \ldots \times[-Q, Q]_{0}^{T}\times \ldots \times[-Q, Q]_{L}^{T} \times [-P, P]_{0}^{0} \times \ldots \times[-P, P]_{L}^{0} \times \ldots \times[-P, P]_{0}^{T}\times \ldots \times[-P, P]_{L}^{T}$ for $\boldsymbol{w_{i,l}^{t}}$ and $\nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})}$. Since $\Gamma_{l}^{t}$ is continuous in $\Omega$, $\Gamma$ is a continuous mapping from $\Omega$ to $\Omega$. According to the Brouwer's fixed-point theorem, we have the following proposition.

\begin{proposition} \label{proposition 3}
Mapping $\Gamma (\{\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})} \mid t \in\{0,1,\\ \ldots, T\}, l \in\{0,1, \ldots, L\}\})$ has a fixed point.
\end{proposition}



In accordance with the deduction discussed before, we can figure out the fixed point of $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$ by technological process in \textbf{Algorithm 1}. Given $\boldsymbol{w_{i,0}^{t}}$, $ t \in\{0,1, \ldots, T\}, i \in\{1, 2, \ldots, N\}$, arbitrary initial $\boldsymbol{\phi_{1,l}^{t}}(0)$, $\boldsymbol{\phi_{2,l}^{t}}(0)$ and $\eta_{i,l}^{t}$, $ t \in\{0,1, \ldots, T\},l \in\{0,1, \ldots, L\}, i \in\{1, 2, \ldots, N\}$, we can easily solve $\eta_{i,l}^{t}$, $ t \in\{0,1, \ldots, T\}$, $l \in\{0,1, \ldots, L\}, i \in\{1, 2, \ldots, N\}$ according to Eq (12). Then, based on $\eta_{i,l}^{t}$ and $\boldsymbol{w_{i,0}^{t}}$, we can solve $\boldsymbol{w_{i,l}^{t}}$ and $\nabla{F_{i}(\boldsymbol{w_{i,l}^{t})}}$, $ t \in\{0,1, \ldots, T\},l \in\{0,1, \ldots, L\}, i \in\{1, 2, \ldots, N\}$ by Eq (11) and Eq (32), respectively. Accordingly, mean field terms $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$ can be updated by using $\nabla{F_{i}(\boldsymbol{w_{i,l}^{t})}}$ and $\boldsymbol{w_{i,l}^{t}}$. Repeating the process above until $\boldsymbol{\phi_{1,l}^{t}}^{est}(j+1) \rightarrow \boldsymbol{\phi_{1,l}^{t}}^{est}(j)$ and $\boldsymbol{\phi_{2,l}^{t}}^{est}(j+1) \rightarrow \boldsymbol{\phi_{2,l}^{t}}^{est}(j)$ within arbitrarily small error $\epsilon$ simultaneously, the fixed point is found. In the meanwhile, $\eta_{i,l}^{t}$, $ t \in\{0,1, \ldots, T\},l \in\{0,1, \ldots, L\}, i \in\{1, 2, \ldots, N\}$ is also obtained. Then, our adaptive federated learning process can be summarized in \textbf{Algorithm 2}.  

\begin{algorithm}[t]
\caption{Federated Learning with adaptive learning rate} %算法的名字
\hspace*{0.02in} {\bf Input: } %算法的输入， \hspace*{0.02in}用来控制位置，同时利用 \\ 进行换行
The client size $N$, hyperparameter $\alpha$, local training epoch $L$, $\boldsymbol{w_{i,0}^{t}}$, $ t \in\{0,1, \ldots, T\}$, $ i \in\{1, 2, \ldots, N\}$, fixed point estimators $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$, $ t \in\{0,1, \ldots, T\},l \in\{0,1, \ldots, L\}$, $\eta_{i,l}^{t}$, $ t \in\{0,1, \ldots, T\},l \in\{0,1, \ldots, L\}, i \in\{1, 2, \ldots, N\}$
\begin{algorithmic}[1]
\For{$t=0$ to $T$}
    \For{each client $i \in\{0,1, \ldots, N\}$}
        \For{$l=0$ to $L-1$}
            \State $\boldsymbol{w_{i,l+1}^{t}}=\boldsymbol{w_{i,l}^{t}}-\eta_{i,l}^{t} \nabla{F_{i}(\boldsymbol{w_{i,l}^{t})}}$
        \EndFor
    \EndFor
\State $\boldsymbol{\bar w^{t+1}} = \sum_{i=1}^{N} \dfrac{D_{i}}{\sum_{j=1}^{N} D_{j}} \boldsymbol{w_{i,L}^{t}}$
\EndFor
\State \Return The optimal global model parameter $\boldsymbol{\bar w^{T}}$
\end{algorithmic}
\end{algorithm}

\section{Numerical Experiments}

In this section, we implement our proposed algorithm and conduct numerous experiments to validate on model accuracy and convergent rate. Besides, we compare the performance of our algorithm and other FL models.

\subsection{Experiment Setup}

To evaluate the performance of our proposed adaptive federated learning algorithm, we conduct our experiments on a Pytorch-based platform and  experimental setup will be briefly introduced in the following part.

\begin{itemize} 
\item \emph{Dataset:} We use typical dataset MNIST\cite{deng2012mnist}, which is divided into 60,000 images as training set and 10,000 images as validation set. Besides, the images in MNIST dataset are 28 $\times$ 28 pixels, with a total of 10 classes.
\item \emph{Baseline and Control Parameters:} We choose four classic federated learning methods as our baseline. They are FedAvg\cite{mcmahan2017communication}, FedAdam\cite{reddi2020adaptive}, FedYogi\cite{reddi2020adaptive} and FedAdagrad\cite{reddi2020adaptive}. Similar to \cite{reddi2020adaptive}, we set $\beta_{1}$ = 0.9, $\beta_{2}$ = 0.99, $\tau $ = $10^{-5}$, $\eta$ = 0.01, and $\eta_{l}$ = 0.01 for FedAdam and FedYogi.
\item \emph{Model:} We use a linear model with a fully connected layer
of input channel 784 and output channel 10.
\item \emph{Hyperparameters:} By default, we set weight parameter $\alpha$ = 0.1 for Eq (6), global training rounds $T$ = 30 and local training epoch $L$ = 5. Further, we divide training set into 6,000 batches and the batchsize is 10. Then, we use $|C|$ = 10 clients and divide the Non-IID dataset similar to \cite{hsu2019measuring}.
\end{itemize} 

\begin{table}[t]
\caption{The accuracy of different FL method in MNIST}
\begin{center}
\renewcommand\arraystretch{1.3}
\begin{tabular}{|c|c|c|}
\hline
\textbf{Method}&\textbf{IID Dataset}&\textbf{Non-IID Dataset}\\
\cline{2-3} 
\hline
FedAvg & 0.9084001779556274 & 0.8172999620437622  \\
\hline
FedAdam & 0.9120998382568359 & 0.8805999755859375  \\
\hline
FedYogi & 0.914099931716919 & 0.8594000935554504  \\
\hline
FedAdagrad & 0.8804001212120056 & 0.8288999795913696  \\
\hline
\textbf{Our Algorithm} & \textbf{0.9254000782966614} & \textbf{0.8944999575614929}  \\
\hline
\end{tabular}
\label{tab3}
\end{center}
\end{table}

\begin{figure}[t]
\centerline{\includegraphics[width=0.4\textwidth, trim=45 20 50 50,clip]{MNIST_Linear_IID_minlr_0.001.pdf}}
\caption{The performance of different FL methods in IID Dataset}
\label{fig1}
\end{figure}

\begin{figure}[t]
\centerline{\includegraphics[width=0.4\textwidth, trim=45 20 50 50,clip]{MNIST_Linear_Non-IID_minlr_0.001.pdf}}
\caption{The performance of different FL methods in Non-IID Dataset}
\label{fig2}
\end{figure}


\subsection{Results}

Firstly, we compare the accuracy of different federated learning methods on MNIST dataset. As shown in Table \uppercase\expandafter{\romannumeral1}, our method achieves the highest accuracy on both IID and Non-IID dataset. Additionaly, compared with other algorithms, our method also increases the accuracy at least 1\% for both IID and Non-IID client data distribution.

For the convergent rate, it is shown in Fig.1 that our algorithm not only keeps high accuracy in all iterations, but also converges much faster than other methods on the IID client data distribution. With regard to Non-IID dataset, our method also performs well. As shown in Fig.2, our method effectively speeds up the convergence of the global model training under the premise of ensuring the accuracy.


\section{Conclusion}

In this paper, we have studied the fast convergence problem in federated learning by designing a dynamic learning rate. To deal with the client drifting issue, we first modify each client’s local parameter updating rule by considering the aggregated gradients of all participating clients. In addition, a penalty term that measures the deviation between the local parameter and average parameter is introduced into each client’s objective function. By utilizing two mean field terms to evaluate the average local parameter and gradient respectively, the optimal decentralized adaptive learning rate for each client is obtained, which makes the global model training more efficient and converge faster, especially for Non-IID data cases. Finally, the experimental results show that our adaptive learning rate algorithm achieves higher accuracy, as well as faster convergent rate on MNIST dataset.

\bibliographystyle{IEEEtran} %IEEEtran为给定模板格式定义文件名
\bibliography{references}
\end{document}
