\documentclass[10pt,journal]{IEEEtran}
\usepackage{url}
\usepackage{orcidlink}
\usepackage{amsmath,amssymb,amsfonts}
\allowdisplaybreaks[4]
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{makecell}
\usepackage{wrapfig}
\usepackage{graphicx}
% \usepackage[caption=false,font=footnotesize,labelfont=sf,textfont=sf]{subfig}
\usepackage{subfig}
\usepackage{multirow}
\usepackage{colortbl}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{cite}
\usepackage{pdfpages}
\usepackage{booktabs}
% \usepackage[numbers,sort&compress]{natbib}
\usepackage{hyperref}
\usepackage{enumitem}
% \usepackage{balance}
% \usepackage[capitalise]{cleveref}
\newtheorem{assumption}{Assumption}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{remark}{Remark}
\newtheorem{corollary}{Corollary}
\newtheorem{theorem}{Theorem}
\newtheorem{example}{Example}%[section]
\newtheorem{axiom}{Axiom}
\newenvironment{proof}{{\it Proof}.\ }{\hfill $\blacksquare$\par}
\newcommand{\refappendix}[1]{\hyperref[#1]{Appendix~\ref*{#1}}}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\definecolor{mycitecolor}{RGB}{0,113,188} 

\hypersetup{colorlinks=true,linkcolor=mycitecolor,citecolor=mycitecolor}

% \hyphenation{op-tical net-works semi-conduc-tor IEEE-Xplore}
% updated with editorial comments 8/9/2021

\begin{document}

\title{FedAgg: Adaptive Federated Learning with Aggregated Gradients}

\author{Wenhao~Yuan\orcidlink{0009-0001-6625-7496} and Xuehe~Wang\orcidlink{0000-0002-6910-468X},~\IEEEmembership{Member,~IEEE}
% \thanks{Manuscript received April 19, 2021; revised August 16, 2021.}
\thanks{This work was supported by National Natural Science Foundation of China under Grant No. 62206320. \emph{(Corresponding author: Xuehe Wang.)}}
\thanks{Wenhao Yuan and Xuehe Wang are with the School of Artificial Intelligence, Sun Yat-sen University, Zhuhai 519082, China. Xuehe Wang is also with the Guangdong Key Laboratory of Big Data Analysis and Processing, Guangzhou 510006, China. E-mail: yuanwh7@mail2.sysu.edu.cn, wangxuehe@mail.sysu.edu.cn}
}

% The paper headers
\markboth{IEEE Transactions on Networking,~Vol.~14, No.~8, August~2021}%
{Shell \MakeLowercase{\textit{et al.}}: A Sample Article Using IEEEtran.cls for IEEE Journals}

% \IEEEpubid{0000--0000/00\$00.00~\copyright~2021 IEEE}
% Remember, if you use this you must call \IEEEpubidadjcol in the second
% column for its text to clear the IEEEpubid mark.

\maketitle

\begin{abstract}
Federated Learning (FL) has become an emerging norm for distributed model training, which enables multiple devices cooperatively to train a shared model utilizing their own datasets scheduled by a central server while keeping private data localized. However, during the training process, the non-independent-and-identically-distributed (Non-IID) data generated on heterogeneous clients and frequent communication across participants may significantly influence the training performance, slow down the convergent rate, and increase communication consumption. In this paper, we ameliorate the standard stochastic gradient descent approach by introducing the aggregated gradients at each local update epoch and propose an adaptive learning rate iterative algorithm that further takes the deviation between the local parameter and global parameter into account. The aforementioned adaptive learning rate design mechanism requires local information of all clients, which is challenging as there is no communication during the local update epochs. To obtain a decentralized adaptive learning rate for each client, we introduce the mean-field approach by utilizing two mean-field terms to estimate the average local parameters and gradients respectively without exchanging clients' local information with each other over time. Through theoretical analysis, we prove that our method can provide the convergence guarantee for model training and derive a convergent upper bound for the client drifting term. Extensive numerical results show that our proposed framework is superior to the state-of-the-art FL schemes in both model accuracy and convergent rate on real-world datasets with IID and Non-IID data distribution. 
\end{abstract}

\begin{IEEEkeywords}
Federated Learning, Adaptive Learning Rate, Mean-Field Theory
\end{IEEEkeywords}

\section{Introduction}
With the flourishing proliferation of edge devices, such as mobile phones and wearable devices, private data originating from distributed sources grows geometrically as well. In the near future, it has been predicted that the rate of generating data will exceed the capacity of the Internet \cite{chiang2016fog}. Tremendous data sources provide more opportunities for artificial intelligence (AI) researchers to have a deeper insight into valuable and potential information behind and train multi-modal models, such as GPT-4. However, delivering massive amounts of data stored in edge devices to a centralized cloud is impractical and will consume considerable communication resources. With the proposal of strict standards regarding to data privacy and protection, such as the General Data Protection Regulation (GDPR) \cite{magdziarczyk2019right}, it is a significant barrier for the field of AI application to access and leverage these private data. The dual challenges of privacy protection and big data boost the development of brand-new technologies that aggregate and model the data under the premise of meeting data privacy, security, and regulatory requirements \cite{sun2020adaptive}.

Federated learning serves as a new paradigm to tackle distributed machine learning tasks and achieve multi-fold performance benefits including improving communication efficiency as well as preserving data privacy \cite{mcmahan2017communication}. Specifically, each client trains the local model with its own dataset and uploads the model parameter rather than the raw data to the FL central server for global aggregation. After aggregating all local model parameters, the central server distributes the updated global model back to all clients for the next round of training. These steps are performed iteratively until the desired accuracy is achieved \cite{zhang2021adaptive}. 

However, the FL framework also encounters several key challenges, one of which is the statistical heterogeneity. The data is independently generated on each client's geographically distributed device, which may lead to significant differences in data size and distribution followed by the appearance of client drifting and slow convergent rate. Additionally, designing an efficient FL framework is also crucial as the communication burden is a critical bottleneck for efficient federated networks. Federated networks potentially comprise numerous edge devices, and the communication efficiency could be slow due to limited resources such as bandwidth, energy and power \cite{bonawitz2019towards}.

Massive efforts have been made for the sake of solving the challenges aforementioned. McMahan \emph{et al.} \cite{mcmahan2017communication} are the first to present the classic federated optimization method FedAvg, which is based on iterating model averaging and effectively reduces communication costs. FedAvg is mainly efficient for IID datasets while it becomes unstable in Non-IID settings. To ameliorate the negative influence brought by the heterogeneity clients, asynchronous FL \cite{xu2021asynchronous,chen2020vafl} and client selection mechanism \cite{xu2020client,chai2020tifl,wang2020optimizing} are introduced. The asynchronous FL performs global aggregation as soon as the central server collects one local update from an arbitrary client. The global model might be severely destroyed by the local model from a single client, leading to poor convergence performance. For partial update, aggregating the local models from high-probability-selected clients may produce great bias on the global model. Besides, due to a certain proportion of clients not always being selected and participating in global aggregation, the model accuracy and fairness suffer. Some other approaches are also proposed to mitigate the effect of heterogeneity. Karimireddy \emph{et al.} \cite{karimireddy2020scaffold} propose SCAFFOLD algorithm to alleviate the effect of client drifting by using variance reduction. 

Nevertheless, most methods overlook the importance of learning rate which is a crucial hyperparameter that needs to be cautiously selected and designed and may greatly affect the convergent rate of models. In this paper, to achieve better model performance, we propose an adaptive learning rate scheme by considering the aggregated gradients updating rule for each client and the deviations between local parameters and global parameters. To deal with the communication issues, two mean-field terms are introduced in the local objective function and local updating rule for decentralized learning rate design of each client. Further, we propose an algorithm to finalize our adaptive learning rate design. Our innovation points and main contributions are summarized as follows:
\begin{itemize}[itemsep=0pt, leftmargin=*, align=right]

\item \emph{Adaptive learning rate strategy:} To our best knowledge, this paper is the first work studying how to assign an adaptive learning rate for each client at each local update epoch by introducing the aggregated gradient into the local updating rules and the parameter deviations into the objective function of each client, which effectively alleviates the negative influence from heterogeneous data and accelerates the convergent rate of the global model. Furthermore, we theoretically analyze the model convergence and provide a convergence upper bound for FL model training.

\item \emph{Mean-field terms for decentralized learning rate design:} As there is no communication during local training epochs, we introduce two mean-field terms to estimate the average local parameters and gradients respectively, based on which each client receives a decentralized learning rate. Moreover, an algorithm is proposed to find the appropriate mean-field estimators.

\item \emph{Algorithms for finalizing the optimal learning rate:} Through rigorous analysis, we prove that there exists a fixed point for mean-field terms, and an algorithm is introduced to iteratively calculate the fixed point, which finalizes the optimal adaptive learning rate. The experiment results show that our FL algorithm achieves a faster convergent rate and higher accuracy compared with state-of-the-art FL algorithms.
\end{itemize}

The rest of this paper is organized as follows. We review the related work in Section \ref{related work}. The preliminaries of federated learning are introduced in Section \ref{preliminaries}. Problem formulation is given in Section \ref{problem formulation}. In Section \ref{Design of Adaptive Learning Rate}, the design of adaptive learning rate is presented. We propose our convergence analysis in Section \ref{Convergence analysis}. Experimental results are shown in Section \ref{Numerical Experiments}. We conclude this paper in Section \ref{Conclusion}.

\section{Related Work} \label{related work}

\subsection{Adaptive Federated Learning}

\noindent\textbf{Adaptive hyperparameter update:} Zhang \emph{et al.} \cite{zhang2021adaptive} propose an Adaptive-B algorithm that can effectively learn the most suitable batch size through the Deep Reinforcement Learning (DRL) method. Ma \emph{et al.} \cite{9415152} study the relationship between the batch size and learning rate, and formulates a scheme to adaptively adjust the batch size with scaled learning rate so as to reduce devices' waiting time and improve the convergence rate. Wu \emph{et al.} \cite{wu2021fast} propose FedAdp to assign different weights for updating the global model based on node contribution adaptively. Fadam \cite{wu2022adaptive} adaptively adjusts the local model gradient based on the first and second order momentum of the historical gradient so as to reduce overfitting and performance fluctuation. 

\noindent\textbf{Adaptive client selection mechanism:} FedSAE \cite{li2021fedsae} automatically adjusts the training task of clients and converts the training loss of each client into selected probability, based on which the central server chooses the optimal participants. Luo \emph{et al.} \cite{luo2022tackling} design an adaptive algorithm that optimizes the client sampling probability to tackle both system and statistical heterogeneity and minimize wall-clock convergence time. FEDEMD \cite{huang2022tackling} introduces a strategy that adaptively selects clients based on Wasserstein distance between the local and global data distributions, which is supported by a proven convergence bound. 

\noindent\textbf{Adaptive asynchronous aggregation:} Liu \emph{et al.} \cite{liu2021adaptive} design AAFL mechanism, which adaptively determines the optimal fraction of clients participating in global aggregation based on resource constraints. Fed2A \cite{liu2022fed2a} allows clients to upload shallow and deep layers of deep neural networks (DNNs) adaptively so as to improve the performance in a heterogeneous and asynchronous environment. Wang \emph{et al.} \cite{wang2022asyncfeded} propose a framework named AsyncFedED, which considers the staleness of the arrived gradients measured by the Euclidean distance between the stale model and the current global model, as well as the number of local epochs that have been performed.

\subsection{Communication-Efficient Federated Learning}

\noindent\textbf{Model quantization:}
AdaQuantFL \cite{jhunjhunwala2021adaptive} adaptively changes the number of quantization levels in the stochastic uniform quantizer to achieve communication efficiency and a lower error floor. Amiri \emph{et al.} \cite{amiri2020federated} introduce a lossy FL (LFL) algorithm, in which both the global and local model updates are quantized before being transmitted. In FedPAQ \cite{reisizadeh2020fedpaq}, edge nodes send a quantized version of local information to the central server at each round which significantly reduces the communication overhead in the network.

\noindent\textbf{Model compression:}
The authors in \cite{sattler2019robust} adopt sparse ternary compression (STC) to update the weight of downstream compression, ternarization and optimal Golomb encoding to reduce the communication cost. Albasyoni \emph{et al.} \cite{albasyoni2020optimal} investigate the fundamental trade-off between the number of bits needed to encode compressed vectors and the compression error, which greatly saves the computation time.

Noted that most of the prior works on adaptive FL fail to provide detailed theoretical proof and analysis for model convergence and closed-form results for adaptive parameters. In addition, model quantization and model compression techniques ignore the harm to the model accuracy. In contrast to the previous work, we address data heterogeneity and reduce communication cost under the premise of ensuring the accuracy by adaptively adjusting the value of each client's learning rate at each local epoch of each global training iteration. Moreover, we derive the closed-form solution for the adaptive learning rate by considering a penalty term to measure the deviation between the local model parameter of the client and the average local model parameter to improve the model accuracy. Detailed theoretical proof of model convergence and key theorems are also presented in this paper.

\section{Preliminaries} \label{preliminaries}
\subsection{Standard Federated Learning Framework} 
In essence, the Federated Learning (FL) \cite{mcmahan2017communication,lim2020federated} methodology represents a decentralized machine learning paradigm explicitly designed to address the challenge of consensus learning. Within the FL framework, a global model is collaboratively trained by a substantial number of clients, each equipped with locally collected data. During each global iteration, individual clients undertake one or several epochs of mini-batch stochastic gradient descent, subsequently transmitting their updated local parameters to the central server. Following this, the central server refines the global parameter by aggregating the collected local parameters. Then, the revised global parameter is distributed to all clients, initiating a fresh round of local training. This iterative process continues until the global model achieves convergence or attains the specified maximum iteration threshold \cite{tu2022adaptive}. The key parameters that we use throughout the paper and their corresponding meanings are summarized in Table \ref{tab1}.

Under the standard federated learning framework, we assume that $N$ geographically distributed and heterogeneous clients (i.e. $S=\{1,2, \ldots, N\}$) are willing to participate in the FL training process and each participating client $i \in \{1, 2, \ldots, N\}$ utilizes their private and locally generated data $\mathcal{D}_{i}$ with datasize $D_{i}$ to perform model training, where $D_{i} \triangleq\left|\mathcal{D}_{i}\right|$ and $\left|\ \cdot\ \right|$ represent the cardinality of sets. Besides, we define $\{\boldsymbol{x_{i}^{j}},y_{i}^{j} \}_{j=1}^{D_{i}}$ as an arbitrary and single data point sampling from $\mathcal{D}_{i}$, where $\boldsymbol{x}_{\boldsymbol{i}}^{j} \in \mathbb{R}^{d}$ represents the input sample vector and $y_{i}^{j}\! \in \! \mathbb{R}$ denotes the corresponding labelled outcome, respectively. Due to the optimization objective of a federated learning model is to obtain the optimal parameter $\boldsymbol{w} \! \in \! \mathbb{R}^{d}$ based on the loss function $f_{i}^{j}\left(\boldsymbol{w},\boldsymbol{x}\right)$, which measures the difference between the real output $y_{i}^{j}$ and predicted output $\hat{y}_{i}^{j}$. The local loss function of client $i$ on dataset $\mathcal{D}_{i}$ is as follow:
\begin{align} \label{1}
F_{i}(\boldsymbol{w})=\frac{1}{D_{i}} \sum_{j \in \mathcal{D}_{i}} f_{i}^{j}(\boldsymbol{w}, \boldsymbol{x}_{\boldsymbol{i}}^{\boldsymbol{j}}). 
\end{align} 

During each global training iteration $t \in\{0,1, \ldots, T\}$, each participating client $i$ performs $L$ ($L \geq 1$ is a positive integer) epochs of mini-batch stochastic gradient descent (SGD) training to update its local model parameter parallelly as follows:
\begin{align} \label{2}
\boldsymbol{w_{i,l+1}^{t}}=\boldsymbol{w_{i,l}^{t}}-\eta_{i} \nabla F_{i}(\boldsymbol{w_{i,l}^{t}}), 
\end{align} 
where $\eta_{i}$ represents the learning rate for client $i$. In classic federated algorithms, such as FedAvg, $\eta_{i}$ is typically viewed as a constant. We denote $\boldsymbol{w_{i,l}^{t}}$ and $\nabla F_{i}(\boldsymbol{w_{i,l}^{t}})$ as the local parameter and gradient of client $i$ at the $l$-th local epoch of global iteration $t$ respectively, where $l \in \{0,1,  \ldots, L\}$. Once receiving the local parameters sent back by $N$ participating clients, the central server averages the local models to generate the updated global parameter:
\begin{align} \label{3}
\boldsymbol{\bar w^{t}}=\sum_{i=1}^{N} \frac{D_{i}}{\sum_{j=1}^{N} D_{j}} \boldsymbol{w_{i,L}^{t-1}}.
\end{align}

At the onset of each global iteration $t$, we have $\boldsymbol{w_{i,0}^{t}} = \boldsymbol{\bar w^{t}}$, $i \in\{1, 2, \ldots, N\}$. After updating the global model, the central server dispatches the updated global parameter back to all clients for the next iteration's training. The goal of the federated learning method is to find the optimal global parameter $\boldsymbol{w}$ to minimize the global loss function $F(\boldsymbol{w})$:
\begin{align} \label{4}
\min _{\boldsymbol{w}} F(\boldsymbol{w})=\sum_{i=1}^{N} \frac{D_{i}}{\sum_{j=1}^{N} D_{j}} F_{i}(\boldsymbol{w}).
\end{align}

\begin{table}[t]
\setlength{\abovecaptionskip}{0cm} 
% \setlength{\belowcaptionskip}{-0.2cm}
\caption{Key Notations and Their Physical Meaning }
\begin{center}
\renewcommand\arraystretch{1.2}
\begin{tabular}{p{0.5in}p{2.65in}}
\toprule[0.8pt]
\makecell[l]{\textbf{Symbol}}&\makecell[c]{\textbf{Description}}\\
% \cline{2-3} 
\midrule[0.8pt]
$N$ & number of participating clients   \\

$\mathcal{D}_{i}$ & private data on client $i$   \\

$D_{i}$ & the datasize of $\mathcal{D}_{i}$   \\

$\boldsymbol{w_{i,l}^{t}}$ & local model parameter of client $i$ at the $l$-th local epoch of global iteration $t$    \\

$\boldsymbol{\bar w^{t}}$ & global model parameter of client $i$ at the global iteration $t$   \\

$F_{i}(\boldsymbol{w_{i,l}^{t}})$ & loss function of client $i$  \\

$F(\boldsymbol{w})$ & the global loss function  \\

$\nabla F$ & the gradient of loss function  \\

$\eta_{i,l}^{t}$ & learning rate of client $i$ at the $l$-th local epoch of global iteration $t$  \\ 

$L$ & total number of local training epoch  \\

$T$ & total number of global training iteration  \\

$\boldsymbol{\phi_{1,l}^{t}}$, $\boldsymbol{\phi_{2,l}^{t}}$ & mean-field terms for estimating average gradient and parameter of all clients \\

\bottomrule[0.8pt]
\end{tabular}
\label{tab1}
\end{center}
\vspace{-15pt}
\end{table}

\section{Problem Formulation }\label{problem formulation}
In this section, we will introduce the adaptive learning rate mechanism in federated learning with aggregated gradients to alleviate the negative impact of client drifting and speed up the convergence rate under the premise of high model accuracy. 

\begin{figure*}[t]
\setlength{\abovecaptionskip}{2pt}
\centerline{\includegraphics[width=0.86\textwidth, trim=70 10 70 10,clip]{framework.pdf}}
\caption{The Federated Learning Framework with Aggregated Gradients. }
\label{fig1}
\vspace{-10pt}
\end{figure*}

\subsection{Adaptive Learning Rate with Aggregated Gradients} \label{adaptive learning rate with aggregated gradients}

To deal with the client drifting effect for Non-IID dataset, we first modify each client's local parameter update rule in Eq (\ref{2}) by introducing the aggregated gradients of all participating clients as follows:
\begin{align}\label{5}
\boldsymbol{w_{i,l+1}^{t}}=\boldsymbol{w_{i,l}^{t}}-\eta_{i,l}^{t} \cdot \left[\frac{1}{N}  \sum_{i=1}^{N} \nabla{F_{i}(\boldsymbol{w_{i,l}^{t})}} \right],
\end{align} 
where $\eta_{i,l}^{t}$ is the adaptive learning rate of client $i$ at the $l$-th local epoch of global iteration $t$. Then, in order to achieve fast convergence for each client $i$, a penalty term that measures the deviation between the local model parameter of client $i$ and the average local model parameter at each local training epoch $l$ is introduced in the objective function $U_{i}(l)$:
\vspace{-5pt}
\begin{align} \label{6}
U_{i}(l) &= \min_{\substack{\eta_{i,l}^{t}, t \in\{0,1, \ldots, T\} \\  l \in\{0,1, \ldots, L\}}}\sum_{t=0}^{T} \sum_{l=0}^{L} \alpha (\eta_{i,l}^{t})^{2}\!+\!(1\!-\!\alpha) \nonumber \\
& \qquad \quad (\boldsymbol{w_{i,l}^{t}}\!-\!\frac{1}{N} \sum_{j=1}^{N} \boldsymbol{w_{j,l}^{t}})^{T}(\boldsymbol{w_{i,l}^{t}}\!-\!\frac{1}{N}\sum_{j=1}^{N} \boldsymbol{w_{j,l}^{t}}), 
\end{align} 
\vspace{-15pt}
\begin{align} \label{7}
\text { s.t. } \quad  \boldsymbol{w_{i,l+1}^{t}}=\boldsymbol{w_{i,l}^{t}}-\eta_{i,l}^{t}  \left[\frac{1}{N} \sum_{i=1}^{N} \nabla{F_{i}(\boldsymbol{w_{i,l}^{t})}} \right],
\end{align} 
where $\alpha \! \in \! [0, \!1]$ is the hyperparameter that adjusts the weight of each part in objective function $U_{i}(l)$.

As there is no communication among clients during each local training epoch $\small l \! \in \! \{0,1,  \ldots, L\}$, client $i$ can not access $\small \boldsymbol{w_{j,l}^{t}}$ and $\small \nabla{F_{j}(\boldsymbol{w_{j,l}^{t})}}$, where $\small j \! \in \! S \setminus \{i\}$. However, the learning rate $\small \eta_{i,l}^{t}$ of each client $i$ is affected by other clients' local parameters $\small \boldsymbol{w_{j,l}^{t}}$ and $\small \nabla{F_{j}(\boldsymbol{w_{j,l}^{t})}}$, which makes this multi-clients joint adaptive learning rate design over time challenging. To tackle the above challenges, we first introduce two mean-field terms to estimate the average of local parameters and gradients. Then, the decentralized adaptive learning rate of each client can be derived on the basis of two mean-field terms, without requiring clients to communicate with each other frequently.

\section{Design of Adaptive Learning Rate}\label{Design of Adaptive Learning Rate}
In this section, we develop our methodology for improving the convergent rate without communication at the end of each local training epoch. We first acquire the optimal adaptive learning rate $\eta_{i,l}^{t}$ for each client $i$ at each local update epoch $l$ of global iteration $t$ by introducing two estimators $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$, and then we prove that $\eta_{i,l}^{t}$ can be represented as a linear combination of $\boldsymbol{w_{i,l}^{t}}$, $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$ (Section \ref{Decentralized Learning Rate For Each Client}). Subsequently, we utilize Brouwer’s fixed point theorem to demonstrate the existence of mean-field term $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$, thus proving the solvability of $\eta_{i,l}^{t}$ (Section \ref{Update of Estimator Finalizing Learning Rate}). We depict the complete workflow of our FL framework with aggregated gradients in Fig. \ref{fig1}. 

\subsection{Framework overview}

\begin{itemize}[itemsep=0pt, leftmargin=*, align=right]
\item \textbf{Step 1 (Initialize Estimators):} At the beginning of the process of estimating the mean-field terms, we define the arbitrary initial value for learning rate $\eta_{i,l}^{t} \! \in \! (0, 1)$, $\boldsymbol{\phi_{1,l}^{t}}\!=\!\boldsymbol{\phi_{1,l}^{t,\texttt{est}}}(0) \geq 0$, $\boldsymbol{\phi_{2,l}^{t}}\!=\!\boldsymbol{\phi_{2,l}^{t,\texttt{est}}}(0) \geq 0$, $l \! \in \! \{0,1,  \ldots, L\}$, $t  \! \in \\  \{0,1,  \ldots, T\}$, as well as the preset threshold $\epsilon$ for terminating the iteratively calculating. 

\item \textbf{Step 2 (Update Estimators and Find Fixed Point):} Once the estimator calculator receives the $\small \boldsymbol{\phi_{1,l}^{t,\texttt{est}}}(j)$ and $\small \boldsymbol{\phi_{2,l}^{t,\texttt{est}}}(j)$, they will be updates as $\small \boldsymbol{\phi_{1,l}^{t,\texttt{est}}}(j+1)$ and $\small \boldsymbol{\phi_{2,l}^{t,\texttt{est}}}(j+1)$. This process terminates until estimators $\small \boldsymbol{\phi_{1,l}^{t,\texttt{est}}}(j+1)-\boldsymbol{\phi_{1,l}^{t,\texttt{est}}}(j) \leq \epsilon$ and $\small \boldsymbol{\phi_{2,l}^{t,\texttt{est}}}(j+1)-\boldsymbol{\phi_{2,l}^{t,\texttt{est}}}(j) \leq \epsilon$ at the same time. Then, the optimal adaptive learning rate is also required.

\item \textbf{Step 3 (Data Collection and Local Training):} Each participating client collects the local data through their geographically distributed mobile devices based on the specified requirement pre-announced, downloads the global model from the central server, and then performs $L$ epochs of local training on their private database $\small \mathcal{D}_{i}$ with corresponding optimal adaptive learning rate $\small \eta_{i,l}^{t}$.

\item \textbf{Step 4 (Parameter Upload):} As $L$ epochs of local training is finished, each client uploads the local model parameter to the central server for aggregation in accordance with the predefined transmitting rules.

\item \textbf{Step 5 (Model Aggregation):} After aggregating all the local parameters from the participating clients, the central server derives a global model matrix and updates the global model. The central server further verifies the quality of the current global model on the pre-partitioned testing set. If the test accuracy is higher than the required accuracy or the number of global iteration reaches the preset value, the federated training process will be terminated. Otherwise, the central server will broadcast the latest global model parameter back to each client for the next iteration of global training by repeating the training Step 3-5.
\end{itemize}

\subsection{Decentralized Learning Rate For Each Client}\label{Decentralized Learning Rate For Each Client}

To figure out the adaptive learning rate for each client, we introduce two mean-field terms $\boldsymbol{\phi_{1,l}^{t}}$, $t \in\{0,1, \ldots, T\}$, $l \in\{0,1, \ldots, L\}$ to estimate the average of all clients' gradients at the $l$-th local epoch of global iteration $t$ and $\boldsymbol{\phi_{2,l}^{t}}$, $t \in\{0,1, \ldots, T\}$, $l \in\{0,1, \ldots, L\}$ to estimate the average of all clients' local parameter at the $l$-th local epoch of global iteration $t$, i.e.,
\begin{align} \label{8}
\boldsymbol{\phi_{1,l}^{t}} &= \dfrac{\sum_{i=1}^{N} \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})}}{N}, 
\end{align}
\vspace{-15pt}
\begin{align} \label{9}
\boldsymbol{\phi_{2,l}^{t}} &= \dfrac{\sum_{i=1}^{N} \boldsymbol{w_{i,l}^{t}}}{N}. 
\end{align}

From the mathematical point of view, $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$ are given functions. The deviation between the local parameter and the average local parameter could be evaluated as $\boldsymbol{w_{i,l}^{t}}-\boldsymbol{\phi_{2,l}^{t}}$. Accordingly, the objective function of each client $i$ can be rewritten as follows:
\begin{align} \label{10}
\Tilde{U}_{i}(l) &= \min_{\substack{\eta_{i,l}^{t}, t \in\{0,1, \ldots, T\} \\  l \in\{0,1, \ldots, L\}}} \sum_{t=0}^{T} \sum_{l=0}^{L} \alpha(\eta_{i,l}^{t})^{2}+(1-\alpha) \nonumber \\
& \qquad \quad (\boldsymbol{w_{i,l}^{t}}-\boldsymbol{\phi_{2,l}^{t}})^{T}(\boldsymbol{w_{i,l}^{t}}-\boldsymbol{\phi_{2,l}^{t}}), 
\end{align} 
\vspace{-20pt}
\begin{align} \label{11}
\text { s.t. } \quad  \boldsymbol{w_{i,l+1}^{t}}=\boldsymbol{w_{i,l}^{t}}-\eta_{i,l}^{t}  \boldsymbol{\phi_{1,l}^{t}}.
\end{align} 

Through constructing the Hamilton equation, we can derive the expression of adaptive learning rate $\eta_{i,l}^{t}$ as summarized in Theorem \ref{theorem 1}.

\begin{theorem} \label{theorem 1}
\emph{Given the mean-field terms $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$, with $\eta_{i,L}^{t}=0$, the optimal adaptive learning rate of client $i\in\{1, 2, \ldots, N\}$ at the $l$-th ($l \in\{0,1, \ldots, L\}$) local epoch of global iteration $t$ ($t \in\{0,1, \ldots, T\}$) is:}
\begin{align} \label{12}
\eta_{i,l}^{t}&=\dfrac{1-\alpha}{\alpha}(\boldsymbol{\phi_{1,l}^{t}})^{T}((L-l)\boldsymbol{w_{i,l}^{t}} \nonumber \\
& \qquad -\sum_{r=l}^{L} (L-r)\eta_{i,r}^{t}\boldsymbol{\phi_{1,r}^{t}}- \sum_{k=l+1}^{L} \boldsymbol{\phi_{2,k}^{t}}),
\end{align}
\end{theorem}

\begin{proof}
Based on the mean-field terms $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$, we construct the Hamilton equation as follows:
\begin{align} \label{13}
H(l)&=(1-\alpha)(\boldsymbol{w_{i,l}^{t}}-\boldsymbol{\phi_{2,l}^{t}})^{T}(\boldsymbol{w_{i,l}^{t}}-\boldsymbol{\phi_{2,l}^{t}}) \nonumber \\
& \qquad +\alpha (\eta_{i,l}^{t})^{2}-\boldsymbol{\lambda(l+1)}^{T}\eta_{i,l}^{t}\boldsymbol{\phi_{1,l}^{t}},
\end{align} 
where $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$ can be viewed as given functions, which are not affected by the learning rate $\eta_{i,l}^{t}$. According to the properties of Hamilton function~\cite{di2012discrete}, in order to obtain the expression of $\eta_{i,l}^{t}$, we need to consider the constrains on control vector $\eta_{i,l}^{t}$, $t \in\{0,1, \ldots, T\} , l \in\{0,1, \ldots, L\}$. The first condition for a minimum is to find the first derivative of the Hamilton function with respect to $\eta_{i,l}^{t}$:
\begin{align} \label{14}
\frac{\partial H(l)}{\partial(\eta_{i,l}^{t})}=0. 
\end{align}

Then, we have:
\begin{align} \label{15}
2\alpha \eta_{i,l}^{t}-\boldsymbol{\lambda(l+1)}^{T} \boldsymbol{\phi_{1,l}^{t}}=0.
\end{align}

Thus, we get an expression of $\eta_{i,l}^{t}$ as follow:
\begin{align} \label{16}
\eta_{i,l}^{t}=\frac{1}{2 \alpha}( \boldsymbol{\phi_{1,l}^{t}})^{T} \boldsymbol{\lambda(l+1)}.
\end{align}

Calculate the second-order derivative of the Hamilton function to check the second condition for a minimum:
\begin{align} \label{17}
\frac{\partial^{2} H(l)}{\partial (\eta_{i,l}^{t})^{2}}=2 \alpha>0,
\end{align} 

We get the adaptive learning rate $\eta_{i,l}^{t}$ that minimizes the objective function. According to an important property of Hamilton equation~\cite{qi2021linear}, we can get the following equation:
\begin{align} \label{18}
\boldsymbol{\lambda(l+1)}\!-\!\boldsymbol{\lambda(l)} \!=\! -\frac{\partial H(l)}{\partial(\boldsymbol{w_{i,l}^{t}})} \!=\! -2(1\!-\!\alpha)(\boldsymbol{w_{i,l}^{t}}\!-\!\boldsymbol{\phi_{2,l}^{t}}).
\end{align}

According to~\cite{di2012discrete}, the impulse vector $\boldsymbol{\lambda}$ has a known boundary condition for final value:
\begin{align} \label{19}
\boldsymbol{\lambda(L)}=\frac{\partial S(\boldsymbol{w_{i,L}^{t}})}{\partial (\boldsymbol{w_{i,L}^{t}})}= 2(1-\alpha)(\boldsymbol{w_{i,L}^{t}}-\boldsymbol{\phi_{2,L}^{t}}),
\end{align}
where $S(\cdot)$ is a weighting function of the state at the local update epoch $L$. Its expression is as follows:
\begin{align} \label{20}
S(\boldsymbol{w_{i,L}^{t}}) = (1-\alpha)(\boldsymbol{w_{i,L}^{t}}-\boldsymbol{\phi_{2,L}^{t}})^{T}(\boldsymbol{w_{i,L}^{t}}-\boldsymbol{\phi_{2,L}^{t}}).
\end{align}

By iteritively calculating the formula in Eq (\ref{18}), we can easily obtain the expression of $\boldsymbol{\lambda(l+1)}$, $l \in\{0,1, \ldots, L-1\}$:
\begin{align} \label{21}
\boldsymbol{\lambda(L\!-\!1)} &\!=\! \boldsymbol{\lambda(L)}\!+\!2(1\!-\!\alpha)(\boldsymbol{w_{i,L-1}^{t}}\!-\!\boldsymbol{\phi_{2,L-1}^{t}}) \nonumber \\
&\!=\! 2(1\!-\!\alpha)(\boldsymbol{w_{i,L}^{t}}\!-\! \boldsymbol{\phi_{2,L}^{t}}\!+\!\boldsymbol{w_{i,L-1}^{t}}\!-\! \boldsymbol{\phi_{2,L-1}^{t}}) \nonumber \\
&\!=\! 2(1\!-\!\alpha)(2 \boldsymbol{w_{i,L-1}^{t}}\!-\!\eta_{i,L-1}^{t} \boldsymbol{\phi_{1,L-1}^{t}} \!-\!\!\! \sum_{k=L-1}^{L}\!\!\! \boldsymbol{\phi_{2,k}^{t}}), \nonumber \\
\boldsymbol{\lambda(L\!-\!2)} &\!=\! \boldsymbol{\lambda(L\!-\!1)}\!+\!2(1\!-\!\alpha)(\boldsymbol{w_{i,L-2}^{t}}\!-\! \boldsymbol{\phi_{2,L-2}^{t}}) \nonumber \\
&\!=\! 2(1\!-\!\alpha)(3 \boldsymbol{w_{i,L-2}^{t}}\!-\!\!\!\!\! \sum_{r=L-2}^{L-1}\!\!\! (L\!-\!r) \eta_{i,r}^{t} \boldsymbol{\phi_{1,r}^{t}} \!-\!\!\!\!\! \sum_{k=L-2}^{L}\!\!\! \boldsymbol{\phi_{2,k}^{t}}), \nonumber \\
&\quad \vdots  \nonumber \\
\boldsymbol{\lambda(l\!+\!1)} &\!=\! 2(1\!-\!\alpha)((L\!-\!l) \boldsymbol{w_{i,l+1}^{t}}  \nonumber \\
& -  \sum_{r=l+1}^{L}(L-r)\eta_{i,r}^{t} \boldsymbol{\phi_{1,r}^{t}} - \sum_{k=l+1}^{L} \boldsymbol{\phi_{2,k}^{t}}). 
\end{align}

Then, based on the expression of $\eta_{i,l}^{t}$ in Eq (\ref{16}) and $\boldsymbol{\lambda(l+1)}$ in Eq (\ref{21}), we can solve $\eta_{i,l}^{t}$ as follows:
\begin{align}
\eta_{i,l}^{t} &= \dfrac{1}{2 \alpha}(\boldsymbol{\phi_{1,l}^{t}} )^{T} \boldsymbol{\lambda(l+1)} \nonumber \\
&=\dfrac{1-\alpha}{\alpha}(\boldsymbol{\phi_{1,l}^{t}})^{T}((L-l) \boldsymbol{w_{i,l+1}^{t}} \nonumber \\
& \qquad\ -\sum_{r=l+1}^{L}(L-r)\eta_{i,r}^{t}\boldsymbol{\phi_{1,r}^{t}}-\sum_{k=l+1}^{L} \boldsymbol{\phi_{2,k}^{t}}) \nonumber \\
&=\dfrac{1-\alpha}{\alpha}(\boldsymbol{\phi_{1,l}^{t}})^{T}((L-l) \boldsymbol{w_{i,l}^{t}} \nonumber \\
& \qquad\ -\sum_{r=l}^{L} (L-r)\eta_{i,r}^{t}\boldsymbol{\phi_{1,r}^{t}}-\sum_{k=l+1}^{L}\boldsymbol{\phi_{2,k}^{t}}). \nonumber
\end{align} 
\end{proof}

According to Theorem \ref{theorem 1}, we observe that the mathematical formula of $\eta_{i,l}^{t}$ at the $l$-th local epoch of global iteration $t$ is associated with the learning rate $\eta_{i,k}^{t}$, $k \in \{l+1, l+2, \ldots, L\}$. By backward induction, we demonstrate that $\eta_{i,l}^{t}$ is definitely solvable, which is summarized in Theorem \ref{theorem 2}. 

\begin{theorem} \label{theorem 2}
\emph{$\eta_{i,l}^{t}$ is solvable and can be expressed as a linear combination of $\boldsymbol{w_{i,l}^{t}}$, $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$, for $l \in \{0, 1, \ldots, L\}$, $t \in\{0,1, \ldots, T\}$, i.e.,} 
\begin{align} \label{22}
\eta_{i,l}^{t} = \Lambda (\boldsymbol{w_{i,l}^{t}},\boldsymbol{\phi_{1,0}^{t}},\ldots,\boldsymbol{\phi_{1,L}^{t}}, \boldsymbol{\phi_{2,0}^{t}}, \ldots, \boldsymbol{\phi_{2,L}^{t}}).
\end{align}
\end{theorem}

\begin{proof}
By adopting backward inductive reasoning, we can find the potential rules among $\eta_{i,l}^{t}$ , $\boldsymbol{w_{i,l}^{t}}$, $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$, $l \! \in \! \{0, \\ 1, \ldots, L\}$. Based on the expression of $\boldsymbol{\lambda(L\!-\!1)}$ and $\boldsymbol{\lambda(L\!-\!2)}$ in Eq (\ref{21}), we have following derivations. First of all, $\eta_{i,L-1}^{t}$ can be derived from $\boldsymbol{\lambda(L)}$ based on Eq (\ref{16}):
\begin{align} \label{23}
\eta_{i,L-1}^{t} &\!=\! \dfrac{1}{2 \alpha}( \boldsymbol{\phi_{1,L-1}^{t}} )^{T} \boldsymbol{\lambda(L)} \nonumber  \\
&\!=\! \dfrac{1\!-\!\alpha}{\alpha}(\boldsymbol{\phi_{1,L-1}^{t}})^{T} (\boldsymbol{w_{i,L-1}^{t}}\!\!-\!\boldsymbol{\phi_{2,L}^{t}}\!\!-\!\eta_{i,L-1}^{t}\boldsymbol{\phi_{1,L-1}^{t}}). \nonumber  \\
\Rightarrow \eta_{i,L-1}^{t} &\!=\! \dfrac{1\!-\!\alpha}{\alpha}\cdot\dfrac{(\boldsymbol{\phi_{1,L-1}^{t}})^{T}(\boldsymbol{w_{i,L-1}^{t}}\!-\!\boldsymbol{\phi_{2,L}^{t}})}{1\!+\!\dfrac{1\!-\!\alpha}{\alpha}(\boldsymbol{\phi_{1,L-1}^{t}})^{T} \boldsymbol{\phi_{1,L-1}^{t}}}. 
\end{align} 

Then, we can figure out the expression of $\eta_{i,L-2}^{t}$ based on $\boldsymbol{\lambda(L\!-\!1)}$ and $\eta_{i,L-1}^{t}$ above:
\begin{align} \label{24}
\eta_{i,L-2}^{t} &= \dfrac{1}{2 \alpha}( \boldsymbol{\phi_{1,L-2}^{t}} )^{T} \boldsymbol{\lambda(L-1)} \nonumber  \\
&= \zeta_{2} (2 \boldsymbol{w_{i,L-1}^{t}}-\eta_{i,L-1}^{t}\boldsymbol{\phi_{1,L-1}^{t}}-\zeta_{1}) \nonumber \\
&= \zeta_{2} (2 (\boldsymbol{w_{i,L-2}^{t}}-\eta_{i,L-2}^{t} \boldsymbol{\phi_{1,L-2}^{t}})-\zeta_{1}-\zeta_{3}).\nonumber \\
\Rightarrow \eta_{i,L-2}^{t} &= \dfrac{\zeta_{2} (2 \boldsymbol{w_{i,L-2}^{t}}-\zeta_{7})}{1+\zeta_{5}+\zeta_{8}}. 
\end{align}
where, 
\begin{small}
\begin{align} 
\left\{\begin{array}{l}
\vspace{10pt}
\zeta_{1}=\sum_{k=L-1}^{L} \boldsymbol{\phi_{2,k}^{t}}, \zeta_{2}=\dfrac{1-\alpha}{\alpha}(\boldsymbol{\phi_{1,L-2}^{t}} )^{T}, \\
\vspace{10pt}
\zeta_{3}=\dfrac{1-\alpha}{\alpha}\dfrac{( \boldsymbol{\phi_{1,L-1}^{t}})^{T}}{1+\zeta_{4}} \cdot \zeta_{6}, \\
\vspace{10pt}
\zeta_{4}=\dfrac{1-\alpha}{\alpha}(\boldsymbol{\phi_{1,L-1}^{t}} )^{T} \boldsymbol{\phi_{1,L-1}^{t}}, \\ 
\vspace{10pt}
\zeta_{5}=2 \cdot \dfrac{1-\alpha}{\alpha}( \boldsymbol{\phi_{1,L-2}^{t}})^{T} \boldsymbol{\phi_{1,L-2}^{t}}, \\
\vspace{10pt}
\zeta_{6}=(\boldsymbol{w_{i,L-1}^{t}}-\eta_{i,L-2}^{t}\boldsymbol{\phi_{1,L-2}^{t}}-\boldsymbol{\phi_{2,L}^{t}}) \boldsymbol{\phi_{1,L-1}^{t}}, \\
\vspace{10pt}
\zeta_{7}=\dfrac{1-\alpha}{\alpha}\dfrac{(\boldsymbol{\phi_{1,L-1}^{t}})^{T} (\boldsymbol{w_{i,L-2}^{t}}-\boldsymbol{\phi_{2,L}^{t}} )\boldsymbol{\phi_{1,L-1}^{t}}+\zeta_{1}}{1+\zeta_{4}}, \\ 
\zeta_{8}=2\cdot \left(\dfrac{1-\alpha}{\alpha}\right)^{2}\dfrac{(\boldsymbol{\phi_{2,L-2}^{t}})^{T}(\boldsymbol{\phi_{2,L-1}^{t}})^{T}\boldsymbol{\phi_{2,L-2}^{t}}\boldsymbol{\phi_{1,L-1}^{t}}}{1+\zeta_{4}}. \nonumber
\end{array}\right.
\end{align}
\end{small}

Repeating the similar derivation process of deducing $\small \eta_{i,L-1}^{t}$ and $\small \eta_{i,L-2}^{t}$, we can acquire the expression of $\small \eta_{i,l}^{t}$. $\small \boldsymbol{\phi_{1,l}^{t}}$ and $\small \boldsymbol{\phi_{2,l}^{t}}$ are both viewed as given functions. Besides, noticed that we can always find a linear function of $\small \eta_{i,l}^{t}$ expressed by $\small \boldsymbol{w_{i,l}^{t}}$ and $\small \eta_{i,q}^{t}$, $\small q \! \in \! \{l\!+\!1, \ldots, L\}$ that we have already calculated before $\small \eta_{i,l}^{t}$. Therefore, the solution of $\small \eta_{i,l}^{t}$, $\small l \! \in \! \{0,1, \ldots, L\!-\!1\}$, can be achieved via an iterative algorithm. \end{proof}

\subsection{Update of \texorpdfstring {$\boldsymbol{\phi_{1,l}^{t}}$}{} and \texorpdfstring {$\boldsymbol{\phi_{2,l}^{t}}$}{} for Finalizing Learning Rate}\label{Update of Estimator Finalizing Learning Rate}

Noted that estimators $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$ are affected by the local gradient $\nabla{F_{i}(\boldsymbol{w_{i,l}^{t})}}$ and local parameter $\boldsymbol{w_{i,l}^{t}}$ of all clients which inversely affect $\nabla{F_{i}(\boldsymbol{w_{i,l}^{t})}}$ and $\boldsymbol{w_{i,l}^{t}}$. Given the optimal adaptive learning rate $\eta_{i,l}^{t}$ according to Theorem \ref{theorem 1}, in this part,  we will derive the precise solutions for estimator $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$ by finding the fixed point and characterized as the following theorem.

\begin{theorem} \label{theorem 3}
\emph{There exists a fixed point for mapping $\Gamma (\{\boldsymbol{w_{i,l}^{t}}, \\ \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})} \mid t  \in  \{0, 1,  \ldots, T\}, l  \in  \{0,1, \ldots, L\}\})$.}
\end{theorem}

\begin{proof} According to Eq (\ref{7}), we display each step of $\boldsymbol{w_{i,l+1}^{t}}$, $t \in\{0,1, \ldots, T\}$, $l \in\{0,1, \ldots, L-1\}$:
\begin{align}\label{25}
&\boldsymbol{w_{i,l+1}^{t}}=\boldsymbol{w_{i,l}^{t}}-\eta_{i,l}^{t} \cdot \left[\frac{1}{N} \sum_{i=1}^{N} \nabla{F_{i}(\boldsymbol{w_{i,l}^{t})}} \right],\\
&\boldsymbol{w_{i,l}^{t}}=\boldsymbol{w_{i,l-1}^{t}}-\eta_{i,l-1}^{t} \cdot \left[\frac{1}{N} \sum_{i=1}^{N} \nabla{F_{i}(\boldsymbol{w_{i,l-1}^{t})}} \right], \nonumber \\
& \qquad \qquad \vdots \nonumber \\
&\boldsymbol{w_{i,1}^{t}}=\boldsymbol{w_{i,0}^{t}}-\eta_{i,0}^{t} \cdot \left[\frac{1}{N} \sum_{i=1}^{N} \nabla{F_{i}(\boldsymbol{w_{i,0}^{t})}} \right]. \nonumber
\end{align}

Adding all equations in Eq (\ref{25}) iteratively, we can obtain a fresh expression of $\boldsymbol{w_{i,l}^{t}}$, $t \in\{0,1, \ldots, T\}$, $l \in\{0,1, \ldots, L\}$:
\begin{align}\label{26&27}
\boldsymbol{w_{i,l}^{t}}&=\boldsymbol{w_{i,0}^{t}}-\sum_{p=0}^{l-1} \eta_{i,p}^{t} \cdot \dfrac{\sum_{i=1}^{N} \nabla{F_{i} (\boldsymbol{w_{i,p}^{t}})}}{N} \\ 
&= \boldsymbol{w_{i,0}^{t}}-\sum_{p=0}^{l-1} \dfrac{1-\alpha}{\alpha}\left( \dfrac{\sum_{i=1}^{N} \nabla{F_{i} (\boldsymbol{w_{i,p}^{t}})}}{N} \right)^{T} \cdot \nonumber \\ 
&\left(\left(L-p\right) \boldsymbol{w_{i,p}^{t}}-\sum_{r=p}^{L} \left(L-r\right) \eta_{i,r}^{t} \dfrac{\sum_{i=1}^{N} \nabla{F_{i} (\boldsymbol{w_{i,r}^{t}})}}{N} \right. \nonumber \\
& \left. \qquad\quad-\sum_{k=p+1}^{L} \dfrac{\sum_{i=1}^{N} \boldsymbol{w_{i,k}^{t}}}{N}\right) \dfrac{\sum_{i=1}^{N} \nabla{F_{i} (\boldsymbol{w_{i,p}^{t}})}}{N}.
\end{align}

For any client $i$, substitute $\boldsymbol{\phi_{1,l}^{t}} = \dfrac{1}{N}\sum_{i=1}^{N} \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})}$ and $\boldsymbol{\phi_{2,l}^{t}} = \dfrac{1}{N}\sum_{i=1}^{N} \boldsymbol{w_{i,l}^{t}}$, where $t \in\{0,1, \ldots, T\}, l \in\{0,1, \ldots, L\}$ into Eq (\ref{26&27}), we can see that $\boldsymbol{w_{i,l}^{t}}$ and $\nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})}$ of client $i$ at the $l$-th local epoch of global iteration $t$ are a function of $\{\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})} \mid t \in\{0,1, \ldots, T\}, l \in\{0,1, \ldots, L\}\}$ of all clients. Define the following function as a mapping from $\{\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})} \mid t \in\{0,1, \ldots, T\}, l \in\{0,1, \ldots, L\}\}$ to client $i$'s local parameter $\boldsymbol{w_{i,l}^{t}}$ and local gradient $\nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})}$ in Eq (\ref{26&27}) at global iteration $t$:
\begin{align}\label{28}
(\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})}) &=\Gamma_{l}^{t}(\{\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})} \mid t \in\{0,1,\ldots,T\}, \nonumber\\
& \qquad l \in\{0,1, \ldots, L\}\}). 
\end{align}

To summarize any possible mapping $\Gamma_{l}^{t}$, we can define following vector functions as a mapping from $\{\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})} \mid t \in\{0,1, \ldots, T\},l \in\{0,1, \ldots, L\}\}$ to the set of all the clients:
\begin{align} \label{29}
& \Gamma(\{\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})} \mid t \in\{0,1, \ldots, T\}, l \in\{0,1, \ldots, L\}\}) \nonumber \\
&=(\Gamma_{0}^{0}(\{\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})} \mid t \in\{0,1, \ldots, T\}, l \in\{0,1, \ldots,  \nonumber \\
& L\}\}), \ldots, \Gamma_{L}^{0}(\{\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})} \mid t \in\{0,1, \ldots, T\},l \in\{0,1, \nonumber \\ 
& \ldots, L\}\}), \ldots, \Gamma_{0}^{T}(\{\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})} \mid t \in\{0,1, \ldots, T\}, l \in \nonumber \\
&\{0,1, \ldots, L\}\}), \ldots, \Gamma_{L}^{T}(\{\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})} \mid t \in\{0,1, \ldots,  T\}, \nonumber \\
& l \in\{0,1, \ldots, L\}\})).
\end{align}  

Thus, the fixed point to $\Gamma (\{\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})} \mid t \!\in\!\{0,1, \ldots, \\ T\}, l \!\in\!\{0,1, \ldots, L\}\}) = \Gamma (\{\boldsymbol{w_{i,l}^{t}},  \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})} \mid  t \!\in\!\{0,1,  \ldots, \\ T\}, l \in\{0,1, \ldots, L\}\})$ in Eq (\ref{29}) should be reached to let $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$ replicate $\frac{1}{N}\sum_{i=1}^{N} \nabla{F_{i} (\boldsymbol{w_{i,l}^{t})}}$ and $\frac{1}{N}\sum_{i=1}^{N} \boldsymbol{w_{i,l}^{t}}$, respectively.

Since $F_{i}(\boldsymbol{w_{i,l}^{t}})$ is continuously differentiable, we can access the upper bound for $\nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})}$:
\begin{align} \label{30}
\| \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})}\| \le P.
\end{align} 

Based on the extension of Fundamental Theorem for Line Integrals, we have:
\begin{align} \label{31}
dF(\boldsymbol{w_{i,l}^{t}})=d\boldsymbol{w_{i,l}^{t}} \cdot \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})}.
\end{align} 

Then, according to Eq (\ref{26&27}), we note that both $\boldsymbol{w_{i,0}^{t}}$ and $\eta_{i,0}^{t}$, $t \in\{0,1, \ldots, T\}$ are bounded. Besides, on account of $\nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})}$, $t \in\{0,1, \ldots, T\}, l \in\{0,1, \ldots, L\}$ is bounded as we proved above and based on Theorem \ref{theorem 2}, we have each term in the Eq (\ref{26&27}) is bounded. Thus, we also have the following upper bound for $\boldsymbol{w_{i,l}^{t}}$:
\begin{align} \label{32}
\| \boldsymbol{w_{i,l}^{t}}\| \le Q.
\end{align} 

Define continuous space $\Omega=[-Q, Q]_{0}^{0} \times \ldots \times[-Q, Q]_{L}^{0} \times \ldots \times[-Q, Q]_{0}^{T}\times \ldots \times[-Q, Q]_{L}^{T} \times [-P, P]_{0}^{0} \times \ldots \times[-P, P]_{L}^{0} \times \ldots \times[-P, P]_{0}^{T}\times \ldots \times[-P, P]_{L}^{T}$ for $\boldsymbol{w_{i,l}^{t}}$ and $\nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})}$. Since $\Gamma_{l}^{t}$ is continuous in $\Omega$, $\Gamma$ is a continuous mapping from $\Omega$ to $\Omega$. According to the Brouwer's fixed-point theorem, the fixed point is found. \end{proof}

In addition, we summarize the technological process of figuring out the fixed point of $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$ in \textbf{Algorithm} \ref{alg1}. Given global model $\boldsymbol{w_{i,0}^{t}}$, arbitrary initial value for $\boldsymbol{\phi_{1,l}^{t}}(0)$, $\boldsymbol{\phi_{2,l}^{t}}(0)$ and $\eta_{i,l}^{t}$, $ t \! \in \! \{0,1, \ldots, T\},l \! \in \! \{0,1, \ldots, L\}, i \! \in \! \{1, 2, \\ \ldots, N\}$, we can easily acquire $\eta_{i,l}^{t}$ according to Theorem \ref{theorem 1}. Then, based on $\eta_{i,l}^{t}$ and $\boldsymbol{w_{i,0}^{t}}$, we can solve $\boldsymbol{w_{i,l}^{t}}$ and $\nabla{F_{i}(\boldsymbol{w_{i,l}^{t})}}$, $ t \! \in \! \{0,1, \ldots, T\}$, $l \! \in \! \{0,1, \ldots, L\}$, $i \! \in \! \{1, 2, \ldots, \\ N\}$ by Eq (\ref{11}) and Eq (\ref{31}) respectively. Accordingly, mean-field terms $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$ can be updated. Repeating the process until $\boldsymbol{\phi_{1,l}^{t,\texttt{est}}}(j+1)\! \rightarrow \! \boldsymbol{\phi_{1,l}^{t,\texttt{est}}}(j)$ and $\boldsymbol{\phi_{2,l}^{t,\texttt{est}}}(j+1)\! \rightarrow \! \boldsymbol{\phi_{2,l}^{t,\texttt{est}}}(j)$ within arbitrarily preset error $\epsilon$ simultaneously, the fixed point is subsequently found. In the meanwhile, $\eta_{i,l}^{t}$, $ t \! \in \!  \{0, 1, \ldots, T\}$, $l \! \in \! \{0,1, \ldots, L\}$, $i \! \in \! \{1, 2, \ldots, N\}$ is also obtained. Our adaptive federated learning process is summarized in \textbf{Algorithm} \ref{alg2}.  

\begin{algorithm}[t]
\small
\caption{Iterative computation of two fixed point estimators $\boldsymbol{\phi_{1,l}^{t}}$, $\boldsymbol{\phi_{2,l}^{t}}$ and $\eta_{i,l}^{t}$} %算法的名字
\hspace*{0.02in} {\bf Input: } %算法的输入， \hspace*{0.02in}用来控制位置，同时利用 \\ 进行换行
Local training epoch $L$, global training iteration $T$ , $\epsilon_{1}\!=\!\epsilon_{2}\!=\!1$, $\epsilon\!=\!0.001$, $j\!=\!1$, arbitrary initial value for $\boldsymbol{\phi_{1,l}^{t,\texttt{est}}}(0) \! \ge \! 0$, $\boldsymbol{\phi_{2,l}^{t,\texttt{est}}}(0) \! \ge \! 0$ and learning rate $\eta_{i,l}^{t} \! \in \! (0, 1)$, $\boldsymbol{\phi_{1,l}^{t}}\!=\!\boldsymbol{\phi_{1,l}^{t,\texttt{est}}}(0)$, $\boldsymbol{\phi_{2,l}^{t}}\!=\!\boldsymbol{\phi_{2,l}^{t,\texttt{est}}}(0)$, $\boldsymbol{w_{i,0}^{t}}$, $ t \in\{0,1, \ldots, T\},l \in\{0,1, \ldots, L\}, i \in\{1, 2, \ldots, N\}$.
\begin{algorithmic}[1]
\For{$t=0$ to $T$}
    \While{$\epsilon_{1} > \epsilon$ and $\epsilon_{2} > \epsilon$}
        \For{each client $i \in\{0,1, \ldots, N\}$}
            \For{$l=1$ to $L-1$}
            \State Compute $\eta_{i,l}^{t}$, $\boldsymbol{w_{i,l}^{t}}$ and $\nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})}$ according to
            \State Theorem \ref{theorem 1}, Eq (\ref{11}) and Eq (\ref{31}) respectively
            \EndFor
        \EndFor
            \For{$l=0$ to $L-1$}
            \State $\boldsymbol{\phi_{2,l}^{t,\texttt{est}}}(j)=\dfrac{\sum_{i=1}^{N} \boldsymbol{w_{i,l}^{t}}}{N}$
            \State $\boldsymbol{\phi_{2,l}^{t}}=\boldsymbol{\phi_{2,l}^{t,\texttt{est}}}(j)$
            \State $\epsilon_{2}'=\boldsymbol{\phi_{2,l}^{t,\texttt{est}}}(j)-\boldsymbol{\phi_{2,l}^{t,\texttt{est}}}(j-1)$
            \EndFor
            \State $\epsilon_{2}=\sum_{l=0}^{L} \epsilon_{2}'$
            \For{$l=0$ to $L-1$}
            \State $\boldsymbol{\phi_{1,l}^{t,\texttt{est}}}(j)=\dfrac{\sum_{i=1}^{N} \nabla{F_{i} (\boldsymbol{w_{i,l}^{t})}}}{N}$
            \State $\boldsymbol{\phi_{1,l}^{t}}=\boldsymbol{\phi_{1,l}^{t,\texttt{est}}}(j)$
            \State $\epsilon_{1}'=\boldsymbol{\phi_{1,l}^{t,\texttt{est}}}(j)-\boldsymbol{\phi_{1,l}^{t,\texttt{est}}}(j-1)$
            \EndFor
            \State $\epsilon_{1}=\sum_{l=0}^{L} \epsilon_{1}'$
            \State $j=j+1$
    \EndWhile
\EndFor
\State \Return The adaptive learning rate $\eta_{i,l}^{t}$, $ t \in\{0,1, \ldots, T\},l \in\{0,1, \ldots, L\}$
\end{algorithmic}
\label{alg1}
\end{algorithm}


\section{Convergence analysis}\label{Convergence analysis}

In this section, we demonstrate the theoretical analysis for our proposed FedAgg algorithm and analyze the convergence property. As all clients are aware of global descent direction at the beginning of each global iteration $t$, and our analysis on descent direction analysis is computed at $\boldsymbol{w_{i,0}^{t}} \! = \!  \boldsymbol{\bar w^{t}}$, rather than the current $l$-th local epoch of client $i$, namely $\boldsymbol{w_{i,l}^{t}}$. 

\subsection{Bounding Adaptive Learning Rate}

Firstly, we analyze the boundary of $\eta_{i,l}^{t}$. According to Theorem \ref{theorem 2}, $\eta_{i,l}^{t}$ is the linear combination of $\boldsymbol{w_{i,l}^{t}}$, $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$,  $l \! \in \! \{0,1, \ldots, L\}$, $t \! \in \! \{0,1, \ldots, T\}$, i.e., $\eta_{i,l}^{t} \!=\! \Lambda (\boldsymbol{w_{i,l}^{t}}, \boldsymbol{\phi_{1,0}^{t}}, \ldots, \\ \boldsymbol{\phi_{1,L}^{t}}, \boldsymbol{\phi_{2,0}^{t}}, \ldots, \boldsymbol{\phi_{2,L}^{t}})$. Although it is hard for us to express $\eta_{i,l}^{t}$ with a closed-form according on Theorem \ref{theorem 1}, we can still derive a tight upper bound for $\eta_{i,l}^{t}$, which is summarized in Theorem \ref{theorem 4}. 
\begin{theorem} \label{theorem 4}
\emph{For any $\eta_{i,l}^{t}$ in training epochs, there exists a tight upper bound $\delta_{i,l}^{t}$ such that $\eta_{i,l}^{t} \in (0, \delta_{i,l}^{t}]$ with $\delta_{i,l}^{t}<1$, where $l \in\{0,1, \ldots, L\}$, $t \in\{0,1, \ldots, T\}$, $i \in\{0,1, \ldots, N\}$.}
\end{theorem}
\begin{proof} 
Before formal derivation, there are some prepositive lemma and corollary that need to be proved to facilitate the demonstration of Theorem \ref{theorem 4}. Then, according to the properties of matrix norm, Eq (\ref{8}) and Eq (\ref{9}), we have following lemmas:

\begin{lemma} \label{lemma 4}
\emph{$\|\boldsymbol{\phi_{1,l}^{t}}\| \leq P$ and $\|\boldsymbol{\phi_{2,l}^{t}}\| \leq Q$.}
\end{lemma}

\begin{proof} From Eq (\ref{30}) and Eq (\ref{32}), we have:
\begin{align} \label{33&34}
\|\boldsymbol{\phi_{1,l}^{t}}\| &= \dfrac{1}{N}\|\sum_{i=1}^{N} \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})}\| \nonumber \\
&= \dfrac{1}{N}\|\nabla{F_{1}(\boldsymbol{w_{1,l}^{t}})}+\nabla{F_{2} (\boldsymbol{w_{2,l}^{t}})}+\ldots+\nabla{F_{N}(\boldsymbol{w_{N,l}^{t}})}\| \nonumber \\
&\stackrel{(a)}{\leq} \dfrac{1}{N} (\|\nabla{F_{1}(\boldsymbol{w_{1,l}^{t}})}\|
+\ldots+\|\nabla{F_{N}(\boldsymbol{w_{N,l}^{t}})}\|) \nonumber \\ 
& \leq \dfrac{1}{N} \cdot N \cdot P = P,  \\
\|\boldsymbol{\phi_{2,l}^{t}}\| &= \dfrac{1}{N}\|\sum_{i=1}^{N} \boldsymbol{w_{i,l}^{t}}\| = \dfrac{1}{N}\|\boldsymbol{w_{1,l}^{t}}+\boldsymbol{w_{2,l}^{t}} +\ldots+\boldsymbol{w_{N,l}^{t}}\| \nonumber \\
&\stackrel{(a)}{\leq} \dfrac{1}{N} (\|\boldsymbol{w_{1,l}^{t}}\|+ \|\boldsymbol{w_{2,l}^{t}}\|+\ldots +\|\boldsymbol{w_{N,l}^{t}}\|) \nonumber \\
& \leq \dfrac{1}{N} \cdot N \cdot Q = Q, 
\end{align}
where inequation (a) follows from the triangle inequality.
\end{proof}

Based on Lemma \ref{lemma 4} and the property of matrix, we can easily get the following corollary.
\begin{corollary} \label{corollary 1}
\emph{$\|(\boldsymbol{\phi_{1,l}^{t}})^{T}\| \leq P$.}
\end{corollary}

Similar to the approach of proving Theorem \ref{theorem 2} and Theorem \ref{theorem 6}, we adopt Inductive Reasoning to prove Theorem \ref{theorem 4} based on Lemma \ref{lemma 4} and Corollary \ref{corollary 1}. 

Firstly, we prove $\eta_{i,L-1}^{t}$ has an upper bound smaller than 1. Define $\| \small \boldsymbol{w_{i,l}^{t}}-\boldsymbol{\phi_{2,l}^{t}}\| \leq U $, we have:
\begin{align} \label{35}
\eta_{i,L-1}^{t} &= \dfrac{1-\alpha}{\alpha}\cdot\dfrac{(\boldsymbol{\phi_{1,L-1}^{t}})^{T}(\boldsymbol{w_{i,L-1}^{t}}-\boldsymbol{\phi_{2,L}^{t}})}{1+\dfrac{1-\alpha}{\alpha}( \boldsymbol{\phi_{1,L-1}^{t}})^{T} \boldsymbol{\phi_{1,L-1}^{t}}} \nonumber \\
&\leq \dfrac{1-\alpha}{\alpha}\cdot\dfrac{PU}{1+\dfrac{1-\alpha}{\alpha}( \boldsymbol{\phi_{1,L-1}^{t}})^{T} \boldsymbol{\phi_{1,L-1}^{t}}} \nonumber \\
\Rightarrow \  \eta_{i,L-1}^{t} &\leq \dfrac{1-\alpha}{\alpha}\cdot\dfrac{PU}{1+\dfrac{1-\alpha}{\alpha}P^{2}} = \delta_{i,L-1}^{t} < 1. 
\end{align}

Then, according to Eq (\ref{24}) and Eq (\ref{35}), we have:
\begin{align} \label{36}
&\eta_{i,L-2}^{t} = \dfrac{1}{2 \alpha}( \boldsymbol{\phi_{1,L-2}^{t}} )^{T} \boldsymbol{\lambda(L-1)} \nonumber \\
&= \dfrac{1\!-\!\alpha}{\alpha}(\boldsymbol{\phi_{1,L-2}^{t}} )^{T}(2 \boldsymbol{w_{i,L-1}^{t}} \!-\! \eta_{i,L-1}^{t}\boldsymbol{\phi_{1,L-1}^{t}}\!-\!\!\!\!\sum_{k=L-1}^{L} \!\!\boldsymbol{\phi_{2,k}^{t}}) \nonumber \\
&\leq \dfrac{1-\alpha}{\alpha}P \mid 2Q-\|\eta_{i,L-1}^{t}\boldsymbol{\phi_{1,L-1}^{t}}+\!\sum_{k=L-1}^{L} \boldsymbol{\phi_{2,k}^{t}}\| \mid \nonumber \\
\Rightarrow \ & \eta_{i,L-2}^{t} \leq \!\dfrac{1\!-\!\alpha}{\alpha}P \mid 2Q\!-\!\|\eta_{i,L-1}^{t}\boldsymbol{\phi_{1,L-1}^{t}}\|\!-\!\|\!\!\sum_{k=L-1}^{L}\!\! \boldsymbol{\phi_{2,k}^{t}}\| \mid \nonumber \\
& \quad \leq \dfrac{1-\alpha}{\alpha}(\alpha P U - \eta_{i,L-1}^{t} P^{2})^{2} = \delta_{i,L-2}^{t} < 1. 
\end{align}

Thus, based on the process of calculating the upper bound of $\eta_{i,L-1}^{t}$ and $\eta_{i,L-2}^{t}$, we can reasonably induce that all the terms in the expression of adaptive learning rate $\eta_{i,l}^{t}$ (Theorem \ref{theorem 1}) are bounded, where $\eta_{i,L-1}^{t}$, $l \in\{l+1, l+2, \ldots, L-1\}$ can be calculated iteratively similar to $\eta_{i,L-2}^{t}$. In another word, for each $\eta_{i,l}^{t}$, $i \in\{1, 2, \ldots, N\}$, $l \in\{0, 1, \ldots, L-1\}$, $t \in\{0, 1, \ldots, T\}$, there exist a corresponding upper bound $\delta_{i,l}^{t}$ smaller than 1, where $i \in\{1, 2, \ldots, N\}$, $l \in\{0, 1, \ldots, L-1\}$, $t \in\{0, 1, \ldots, T\}$. 
\end{proof}

\subsection{Bounding Global Function Change}
For theoretically analyzing our proposed federated learning algorithm (i.e., FedAgg), some standard Assumption and Lemmas concerned are stated as follows.

\begin{assumption} \label{assumption 1}
\emph{[$\beta$-Lipschitz Smoothness] $F_{i}(\boldsymbol{w})$ is $\beta$-Lipschitz smoothness for each of the participating clients $i \in\{0,1, \ldots, N\}$ with any two parameter vectors $\boldsymbol{w}$ and $\boldsymbol{w}^{\prime}$, we have $\|\nabla{F_{i}(\boldsymbol{w}})-\nabla{F_{i}(\boldsymbol{w}^{\prime}})\| \leq \beta\|\boldsymbol{w}-\boldsymbol{w}^{\prime}\|$. }
\end{assumption}

Based on Assumption \ref{assumption 1}, the definition of $F(\boldsymbol{w})$ and triangle inequality, we can easily get the Lemma \ref{lemma 1}. Additionally, we introduce mathematical Lemmas \ref{lemma 2}-\ref{lemma 3} to assist our convergence analysis. 

\begin{lemma} \label{lemma 1}
\emph{$F(\boldsymbol{w})$ is $\beta$-Lipschitz smoothness.}
\end{lemma}

\begin{lemma} \label{lemma 2}
\emph{\cite{mitra2021achieving} Given any two vectors $x, y \! \in \! \mathbb{R}^{d}$, the following holds for any $\gamma \! > \! 0$: }
\begin{align} \label{37}
\|x+y\|^{2} \leq(1+\gamma)\|x\|^{2}+(1+\frac{1}{\gamma})\|y\|^{2}. 
\end{align}
\end{lemma}

\begin{lemma} \label{lemma 3}
\emph{\cite{mitra2021achieving} Given $m$ vectors $x_{1}, x_{2}, \ldots, x_{m} \in \mathbb{R}^{d}$, according to Jensen's inequality, we have: }
\begin{align} \label{38}
\| \sum_{i=1}^{m} x_{i}\|^{2} \leq m \sum_{i=1}^{m}\|x_{i}\|^{2}.
\end{align}
\end{lemma}

Based on Theorem \ref{theorem 4} as well as Assumption and Lemmas above, we can derive an upper bound for the consecutive change of FL global loss function $F(\boldsymbol{\bar w^{t}})$, which is summarized in Theorem \ref{theorem 5}.

\begin{theorem} \label{theorem 5}
\emph{Define $\delta_{min}\!=\!\text{min}\{\eta_{i,l}^{t}\}$ and $\delta_{max}\!=\!\text{max}\{\delta_{i,l}^{t}\}$, for any two consecutive global training iterations $t$ and $t+1$, the convergent upper bound of global loss function satisfies,}
\begin{small}
\begin{align} \label{39}
F(&\boldsymbol{\bar w^{t+1}})\!-\!F(\boldsymbol{\bar w^{t}})\! \leq \! \dfrac{\beta\delta_{min}}{N}\!\!\left(\!\sum_{i=1}^{N}\!\sum_{k=0}^{L-1}\!\sum_{j=1}^{N}\theta_{i}\|\boldsymbol{w_{j,k}^{t}}\!-\boldsymbol{\bar w^{t}}\|\|\nabla{F(\boldsymbol{\bar w^{t}})}\|\!\right) \nonumber \\
&-L\delta_{min}  \|\nabla{F(\boldsymbol{\bar w^{t}})}\|^{2} +\beta L \delta_{max}^{2}\sum_{i=1}^{N} \sum_{k=0}^{L-1}\sum_{j=1}^{N} \theta_{i}^{2}\|\boldsymbol{w_{j,k}^{t}}\!-\!\boldsymbol{\bar w^{t}}\|^{2} \nonumber \\
& + \beta L^{2} \delta_{max}^{2} \left\|\nabla{F(\boldsymbol{\bar w^{t}})} \right\|^{2}. 
\end{align}
\end{small}
\end{theorem}

\begin{proof} First, we define $\theta_{i} = \dfrac{D_{i}}{\sum_{j=1}^{N} D_{j}}$. Then, according to Eq (\ref{26&27}), Eq (\ref{3}) can be rewritten as:
\begin{align} \label{40}
\boldsymbol{\bar w^{t+1}}&=\sum_{i=1}^{N} \theta_{i} \boldsymbol{w_{i,L}^{t}} =\boldsymbol{w_{i,0}^{t}}-\sum_{i=1}^{N}\sum_{k=0}^{L-1} \theta_{i}\eta_{i,k}^{t} \boldsymbol{\phi_{1,k}^{t}} \nonumber \\
& =\boldsymbol{\bar w^{t}}-\sum_{i=1}^{N}\sum_{k=0}^{L-1} \theta_{i}\eta_{i,k}^{t} \boldsymbol{\phi_{1,k}^{t}}. 
\end{align}
 
From the $\beta$-Lipschitz smoothness of $F(\boldsymbol{w})$ in Lemma \ref{lemma 1} and Taylor expansion, we have 
\begin{small}
\begin{align} \label{41}
&F(\boldsymbol{\bar w^{t+1}})\!-\!F(\boldsymbol{\bar w^{t}}) \!\leq\!  \langle \boldsymbol{\bar w^{t+1}}\!-\!\boldsymbol{\bar w^{t}}, \nabla{F(\boldsymbol{\bar w^{t}}}) \rangle \!+\!\dfrac{\beta}{2} \|\boldsymbol{\bar w^{t+1}}\!-\!\boldsymbol{\bar w^{t}} \|^{2} \nonumber\\
&= \underbrace{-\sum_{i=1}^{N}\sum_{k=0}^{L-1} \langle\theta_{i}\eta_{i,k}^{t} \boldsymbol{\phi_{1,k}^{t}}, \nabla{F(\boldsymbol{\bar w^{t}})} \rangle}_{T_{1}} + \underbrace{\dfrac{\beta}{2} \|\sum_{i=1}^{N}\sum_{k=0}^{L-1} \theta_{i}\eta_{i,k}^{t} \boldsymbol{\phi_{1,k}^{t}}\|^{2}}_{T_{2}}. 
\end{align}
\end{small}

The two terms on the right-hand side of the inequality are bounded respectively as follows.

\subsubsection{Bounding \texorpdfstring {$T_{1}$}{}}

\begin{footnotesize}
\begin{align} \label{42}
&-\sum_{i=1}^{N}\sum_{k=0}^{L-1} \langle\theta_{i}\eta_{i,k}^{t} \boldsymbol{\phi_{1,k}^{t}}, \nabla{F(\boldsymbol{\bar w^{t}})}\rangle \nonumber \\
& =\! - \! \left\langle \sum_{i=1}^{N}\!\sum_{k=0}^{L-1}\!\! \theta_{i}\eta_{i,k}^{t} (\boldsymbol{\phi_{1,k}^{t}}\!\!-\! \!\nabla{F_{i}(\boldsymbol{\bar w^{t}})})\!-\!\!\sum_{i=1}^{N}\!\sum_{k=0}^{L-1}\!\!\theta_{i}\eta_{i,k}^{t}\! \nabla{F_{i}(\boldsymbol{\bar w^{t}})}, \! \nabla{F(\boldsymbol{\bar w^{t}})}\!\! \right\rangle \nonumber\\
&\leq \!-\delta_{min}\!\left\langle \! \sum_{i=1}^{N}\!\sum_{k=0}^{L-1}\!\! \theta_{i} (\boldsymbol{\phi_{1,k}^{t}}\!\!-\!\!\nabla{F_{i}(\boldsymbol{\bar w^{t}})})\!-\!\!\sum_{i=1}^{N}\!\sum_{k=0}^{L-1}\!\theta_{i} \nabla{F_{i}(\boldsymbol{\bar w^{t}})}, \! \nabla{F(\boldsymbol{\bar w^{t}})}\!\! \right\rangle \nonumber \\
& = -\delta_{min}\!\left\langle \sum_{i=1}^{N}\!\sum_{k=0}^{L-1}\!\theta_{i}(\boldsymbol{\phi_{1,k}^{t}}\!-\!\nabla{F_{i}(\boldsymbol{\bar w^{t}})})\!+\!L\nabla{F(\boldsymbol{\bar w^{t}})}, \nabla{F(\boldsymbol{\bar w^{t}})}\!\!\right\rangle \nonumber \\
&= -\delta_{min} \left\langle \! \sum_{i=1}^{N}\!\sum_{k=0}^{L-1}\! \theta_{i}(\boldsymbol{\phi_{1,k}^{t}}\!\!-\!\!\nabla{F_{i}(\boldsymbol{\bar w^{t}})}),\nabla{F(\boldsymbol{\bar w^{t}})}\!\right\rangle \!-\! \delta_{min} L \|\nabla{F(\boldsymbol{\bar w^{t}})}\|^{2} \nonumber\\
&\stackrel{(b)}{\leq} \! \delta_{min} \left(\|\sum_{i=1}^{N}\! \sum_{k=0}^{L-1}\! \theta_{i}(\boldsymbol{\phi_{1,k}^{t}}\!-\!\nabla{F_{i}(\boldsymbol{\bar w^{t}})})\| \|\nabla{F(\boldsymbol{\bar w^{t}})}\| \!-\! L \|\nabla{F(\boldsymbol{\bar w^{t}})}\|^{2}\right) \nonumber\\
&\stackrel{(a)}{\leq} \delta_{min} \! \left(\sum_{i=1}^{N}\sum_{k=0}^{L-1}\theta_{i}\|\boldsymbol{\phi_{1,k}^{t}}\!-\!\nabla{F_{i}(\boldsymbol{\bar w^{t}})}\|\|\nabla{F(\boldsymbol{\bar w^{t}})}\| \!-\! L \|\nabla{F(\boldsymbol{\bar w^{t}})}\|^{2}\right) \nonumber\\
&\stackrel{(a)}{\leq} \dfrac{\delta_{min}}{N}\left(\sum_{i=1}^{N}\sum_{k=0}^{L-1}\sum_{j=1}^{N}\theta_{i}\|\nabla{F_{j} (\boldsymbol{w_{j,k}^{t}})}-\nabla{F_{j}(\boldsymbol{\bar w^{t}})}\| \|\nabla{F(\boldsymbol{\bar w^{t}})}\|\right) \nonumber \\
& \qquad \qquad - L \delta_{min} \|\nabla{F(\boldsymbol{\bar w^{t}})}\|^{2} \nonumber \\
&\stackrel{(c)}{\leq} \!\! \dfrac{\beta\delta_{min}}{N}\!\!\! \left(\!\sum_{i=1}^{N}\!\sum_{k=0}^{L-1}\!\sum_{j=1}^{N}\!\theta_{i}\|\boldsymbol{w_{j,k}^{t}}\!\!-\!\boldsymbol{\bar w^{t}}\|\|\nabla{F(\boldsymbol{\bar w^{t}})}\|\!\!\right)  \!\!-\!\! L \delta_{min} \|\nabla{F(\boldsymbol{\bar w^{t}})}\|^{2}. \! 
\end{align}
\end{footnotesize}

In the above steps, (a) follows from the triangle inequality, (b) follows from the Cauchy-Schwartz inequality, and (c) is a consequence of the $\beta$-Lipschitz smoothness for $F_{i}(\cdot)$ in Assumption \ref{assumption 1}.

\subsubsection{Bounding \texorpdfstring {$T_{2}$}{}}
\begin{footnotesize}
\begin{align} \label{43}
&\dfrac{\beta}{2}  \left\|\sum_{i=1}^{N} \right. \left. \sum_{k=0}^{L-1} \theta_{i}\eta_{i,k}^{t} \boldsymbol{\phi_{1,k}^{t}}\right\|^{2} \nonumber \\
& =\! \dfrac{\beta\delta_{max}^{2}}{2}\left\|\sum_{i=1}^{N}\sum_{k=0}^{L-1} \theta_{i}(\boldsymbol{\phi_{1,k}^{t}}-\nabla{F_{i}(\boldsymbol{\bar w^{t}})})+ \sum_{i=1}^{N}\sum_{k=0}^{L-1}\theta_{i}\nabla{F_{i}(\boldsymbol{\bar w^{t}})}\right\|^{2} \nonumber \\
&=\! \dfrac{\beta\delta_{max}^{2}}{2}\left\|\sum_{i=1}^{N}\sum_{k=0}^{L-1} \theta_{i}(\boldsymbol{\phi_{1,k}^{t}}-\nabla{F_{i}(\boldsymbol{\bar w^{t}})})+ L\nabla{F(\boldsymbol{\bar w^{t}})} \right\|^{2} \nonumber \\
&\stackrel{(a)}{\leq}\! \beta\delta_{max}^{2}\! \left(\left\|\sum_{i=1}^{N}\!\sum_{k=0}^{L-1} \theta_{i}(\boldsymbol{\phi_{1,k}^{t}}\!-\!\nabla{F_{i}(\boldsymbol{\bar w^{t}})})\right\|^{2} \!\! + \! L^{2} \left\|\nabla{F(\boldsymbol{\bar w^{t}})} \right\|^{2}\!\right) \nonumber \\
&\stackrel{(b)}{\leq}\! \beta\delta_{max}^{2} \!\! \left(\! N\sum_{i=1}^{N} \theta_{i}^{2} \left\|\sum_{k=0}^{L-1}(\boldsymbol{\phi_{1,k}^{t}}\!-\!\nabla{F_{i}(\boldsymbol{\bar w^{t}})})\right\|^{2} \!\!\!+\! L^{2} \left\|\nabla{F(\boldsymbol{\bar w^{t}})} \right\|^{2}\!\right) \nonumber \\
&\stackrel{(b)}{\leq}\! \beta L \delta_{max}^{2} \!\! \left(\! N \! \sum_{i=1}^{N}\! \sum_{k=0}^{L-1}\! \theta_{i}^{2} \left\|\boldsymbol{\phi_{1,k}^{t}}\!-\!\nabla{F_{i}(\boldsymbol{\bar w^{t}})}\right\|^{2}  \!+\!  L \left\|\nabla{F(\boldsymbol{\bar w^{t}})} \right\|^{2}\right) \nonumber \\
&\stackrel{(b)}{\leq}\! \beta L \delta_{max}^{2}\!\! \left(\!\sum_{i=1}^{N}\! \sum_{k=0}^{L-1}\!\sum_{j=1}^{N}\! \theta_{i}^{2}\!\left\|\nabla{F_{j} (\boldsymbol{w_{j,k}^{t}})}\!-\!\!\nabla{F_{j}(\boldsymbol{\bar w^{t}})}\right\|^{2} \!\!\! + \!\! L \! \left\|\nabla{F(\boldsymbol{\bar w^{t}})} \right\|^{2}\!\!\right) \nonumber \\
&\stackrel{(c)}{\leq}\beta L \delta_{max}^{2} \! \left(\!\sum_{i=1}^{N}\! \sum_{k=0}^{L-1}\!\sum_{j=1}^{N}\!\theta_{i}^{2}\! \left\|\boldsymbol{w_{j,k}^{t}}\!-\!\boldsymbol{\bar w^{t}}\right\|^{2} \!\!+\!  L \left\|\nabla{F(\boldsymbol{\bar w^{t}})} \right\|^{2}\!\right). 
\end{align}
\end{footnotesize}

In the above steps, (a) follows the Lemma \ref{lemma 2} with $\gamma = 1$, (b) follows the Lemma \ref{lemma 3}, and (c) is a consequence of the $\beta$-Lipschitz smoothness for $F_{i}(\cdot)$ in Assumption \ref{assumption 1}. Combining with the bound in Eq (\ref{42}) and Eq (\ref{43}) immediately leads to the Theorem \ref{theorem 5}.
\end{proof}

\begin{algorithm}[t]
\caption{Federated Learning with adaptive learning rate} %算法的名字
\hspace*{0.02in} {\bf Input: } %算法的输入， \hspace*{0.02in}用来控制位置，同时利用 \\ 进行换行
The client size $N$, hyperparameter $\alpha$, local training epoch $L$, global training iteration $T$, initial global model $\boldsymbol{w_{i,0}^{t}}$, adaptive learning rate $\eta_{i,l}^{t}$, $ t \! \in \! \{0,\! 1, \! \ldots,\! T\},l \! \in \! \{0,\! 1,\! \ldots, \! L\}, i \! \in \! \{1,\! 2,\! \ldots,\! N\}$.
\begin{algorithmic}[1]
\For{$t=0$ to $T$}
    \State Acquire corresponding adaptive learning rate $\eta_{i,l}^{t}$
    \For{each client $i \in\{0,1, \ldots, N\}$}
        \For{$l=0$ to $L-1$}
            \State Local training:  $\small \boldsymbol{w_{i,l+1}^{t}}\!=\!\boldsymbol{w_{i,l}^{t}}\!-\!\eta_{i,l}^{t} \nabla{F_{i}(\boldsymbol{w_{i,l}^{t})}}$
        \EndFor
    \EndFor
\State Update global model: $\boldsymbol{\bar w^{t+1}} = \sum_{i=1}^{N} \dfrac{D_{i}}{\sum_{j=1}^{N} D_{j}} \boldsymbol{w_{i,L}^{t}}$
\EndFor
\State \Return The optimal global model parameter $\boldsymbol{\bar w^{T}}$.
\end{algorithmic}
\label{alg2}
\end{algorithm}

\subsection{Bounding Client Drifting}

To further simplify the boundary in Theorem \ref{theorem 5} regarding to the global loss function, we rigorously derive an upper boundary for the client drifting term $\|\boldsymbol{w_{i,l}^{t}}-\boldsymbol{\bar w^{t}}\|$ as summarized in Theorem \ref{theorem 6}, which verify the robustness of our proposed algorithm under the Non-IID data distribution setting. 
\begin{theorem} \label{theorem 6}
\emph{Suppose $F_{i}(\boldsymbol{w_{i,l}^{t}})$ satisfies $\beta$-Lipschitz smoothness, for each participating client $i \in\{0,1, \ldots, N\}$, we have: }
\begin{align} \label{44}
\|\boldsymbol{w_{i,l}^{t}}-\boldsymbol{\bar w^{t}}\| \leq L P \delta_{max}.
\end{align}
\end{theorem}
\begin{proof}
First, we for any given client $i \in \{0, 1, \ldots, N\}$, according to Eq (\ref{11}), we have: 
\begin{align} \label{45}
\|\boldsymbol{w_{i,l+1}^{t}}\!-\!\boldsymbol{\bar w^{t}}\| &= \|\boldsymbol{w_{i,l}^{t}}\!-\!\boldsymbol{\bar w^{t}} \!-\! \eta_{i,l}^{t}  \boldsymbol{\phi_{1,l}^{t}}\| \nonumber \\
&\leq \|\boldsymbol{w_{i,l}^{t}}\!-\!\boldsymbol{\bar w^{t}}\| \!+\! \|\eta_{i,l}^{t}  \boldsymbol{\phi_{1,l}^{t}}\| \nonumber \\
&\leq \|\boldsymbol{w_{i,l}^{t}}\!-\!\boldsymbol{\bar w^{t}}\| \!+\! P \delta_{max}. 
\end{align}

Then, we proceed with a proof by Inductive Reasoning to establish the final result. The induction claim is as follows:
\begin{align} \label{46}
\|\boldsymbol{w_{i,l}^{t}}-\boldsymbol{\bar w^{t}}\| \leq l P \delta_{max},  
\end{align}
for all $l \in \{0, 1, \ldots, L-1\}$. First, we prove the base situation for $l = 0$ and $l = 1$. For $l = 0$, we have:
\begin{align} \label{47}
\|\boldsymbol{w_{i,1}^{t}}-\boldsymbol{\bar w^{t}}\| &= \|\boldsymbol{w_{i,0}^{t}}-\boldsymbol{\bar w^{t}} - \eta_{i,0}^{t}  \boldsymbol{\phi_{1,0}^{t}}\| \nonumber \\
& \leq \|\boldsymbol{w_{i,0}^{t}}-\boldsymbol{\bar w^{t}}\| + \|\eta_{i,0}^{t}  \boldsymbol{\phi_{1,0}^{t}}\| \nonumber \\
&\leq \|\boldsymbol{w_{i,0}^{t}}-\boldsymbol{\bar w^{t}}\| + P \delta_{max} \leq P \delta_{max}, 
\end{align}
where $\boldsymbol{w_{i,0}^{t}}=\boldsymbol{\bar w^{t}}$, $i \in \{1, 2, \ldots, N\}$, same as the definition we mentioned in Section \ref{preliminaries}.

Similarly, for $l = 1$, we have:
\begin{align} \label{48}
\|\boldsymbol{w_{i,2}^{t}}-\boldsymbol{\bar w^{t}}\| &= \|\boldsymbol{w_{i,1}^{t}}-\boldsymbol{\bar w^{t}} - \eta_{i,1}^{t}  \boldsymbol{\phi_{1,1}^{t}}\| \nonumber \\
& \leq \|\boldsymbol{w_{i,1}^{t}}-\boldsymbol{\bar w^{t}}\| + \|\eta_{i,1}^{t}  \boldsymbol{\phi_{1,1}^{t}}\| \nonumber \\
&\leq \|\boldsymbol{w_{i,1}^{t}}-\boldsymbol{\bar w^{t}}\| + U \delta_{max} \nonumber \\
& \leq \|\boldsymbol{w_{i,0}^{t}}-\boldsymbol{\bar w^{t}}\| + 2 P \delta_{max} \leq 2 P \delta_{max}. 
\end{align}

Similar to the above analysis, for any $l>1$, we have:
\begin{align}
\|\boldsymbol{w_{i,l}^{t}}-\boldsymbol{\bar w^{t}}\| \leq l P \delta_{max}, \nonumber
\end{align}

As $l \in \{0, 1, \ldots, L-1\}$, Theorem 3 can be proved as:
\begin{align}
\|\boldsymbol{w_{i,l}^{t}}-\boldsymbol{\bar w^{t}}\| \leq l P \delta_{max} \leq L P \delta_{max}. \nonumber
\end{align}
\end{proof}

\begin{figure*}[t]
\setlength{\abovecaptionskip}{2pt} 
    \centering
    \subfloat[IID]{
        \label{cifar100-IID}
        \includegraphics[width=0.32\textwidth, trim=50 20 140 40,clip]{Experiment/Distribution/Cifar100_IID_Distribution_N100.pdf}}
    \subfloat[Dir-0.6]{
        \label{cifar100-dir06}
        \includegraphics[width=0.32\textwidth, trim=50 20 140 40,clip]{Experiment/Distribution/Cifar10_Dir06_Distribution_N100.pdf}}
    \subfloat[Wasserstein Distance]{
        \label{cifar100-emd}
        \includegraphics[width=0.34\textwidth, trim=20 10 50 20,clip]{Experiment/Distribution/Cifar100_EMD_N100.pdf}}
    \caption{The data distribution on Cifar100 dataset}
\label{dirichlet distribution on cifar100}
\vspace{-10pt}
\end{figure*}

\subsection{Finalizing Convergence Analysis}
It is proved in \cite{karimireddy2020scaffold} that training on heterogeneous dataset (Non-IID dataset) will lead to model hard to converge and slow down the convergent rate. According to Eq (\ref{39}),  we can also intuitively find that the boundary of client drifting term $\|\boldsymbol{w_{j,k}^{t}}\!-\boldsymbol{\bar w^{t}}\|$ has great influence on global model convergence and convergent rate. Thus, based on Theorem \ref{theorem 6}, we finalize the deviation of global loss function between two consecutive iterations as follows:
\begin{small}
\begin{align} \label{49}
&F(\boldsymbol{\bar w^{t+1}})-F(\boldsymbol{\bar w^{t}})  \nonumber \\
& \leq \!\! \dfrac{\beta\delta_{min}}{N} \!\! \left(\! \sum_{i=1}^{N}\!\sum_{k=0}^{L-1}\!\sum_{j=1}^{N}\!\theta_{i}\|\boldsymbol{w_{j,k}^{t}}\!-\!\boldsymbol{\bar w^{t}}\|\|\nabla \! {F(\boldsymbol{\bar w^{t}})}\|\!\!\right) \!\!-\!\! L\delta_{min}  \|\nabla \! {F(\boldsymbol{\bar w^{t}})}\|^{2} \nonumber \\
& + \! \beta L \delta_{max}^{2}\sum_{i=1}^{N} \sum_{k=0}^{L-1}\sum_{j=1}^{N} \theta_{i}^{2}\|\boldsymbol{w_{j,k}^{t}}\!-\!\boldsymbol{\bar w^{t}}\|^{2}+ \beta L^{2} \delta_{max}^{2} \left\|\nabla{F(\boldsymbol{\bar w^{t}})} \right\|^{2} \nonumber \\
& \leq \! (\beta L^{2} \delta_{max}^{2} \!-\! L \delta_{min})\|\nabla{F(\boldsymbol{\bar w^{t}})}\|^{2} \!+\! L^{2} P \beta \delta_{min}\delta_{max} \|\nabla{F(\boldsymbol{\bar w^{t}})}\| \nonumber \\
& + \beta L^{4} N P^{2} \delta_{max}^{4} 
\end{align}
\end{small}

After simplifying Eq (\ref{39}) as shown in Eq (\ref{49}), we can clearly find that the convergent upper bound of the global loss function between any two consecutive global training iterations $t$ and $t+1$ is only related to the norm of the gradient of the global parameter at iteration $t$ and preset constants, which guarantees that there exists a trustworthy convergent upper bound for our model. 

\section{Numerical Experiments}\label{Numerical Experiments}

\subsection{Experiment Setups}
To evaluate the performance of our proposed adaptive federated learning algorithm FedAgg, we implement our experiments on a Pytorch-based platform and the experimental setup will be introduced in detail in the following part.

\subsubsection{Platform Setup}
Experiments are conducted on a workstation (CPU: Intel i7-8750H @2.20GHz; RAM: 8GB DDR4 2666 MHz; GPU: NVIDIA GeForce RTX 1060 with CUDA version 12.1; OS: Microsoft Windows 11 Professional with OS version 10.0.22000). The simulator is composed of three parts: (\romannumeral 1) The data partitioning part that partitions the datasets as IID and Non-IID distribution. In addition, we allocate local data to each participating client with the same data size. (\romannumeral 2) The model training part instantiates heterogeneous FL clients for local model training, aggregate and update the global model until reaching pre-fixed global training iteration or threshold. (\romannumeral 3) The estimator calculating part finds the fixed point for two mean-field terms $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$. For all parts aforementioned, we utilize the PyTorch library \cite{paszke2019pytorch} with version 0.10.0 and the environment is built on Python 3.7.

\begin{table}[t]
\setlength{\abovecaptionskip}{3pt} 
\caption{Basic Information of Datasets}
\begin{center}
\resizebox{0.49\textwidth}{!}{\begin{tabular}{c|c|c|c|c}
\toprule[1pt]
\textbf{Datasets}&\textbf{Traing Sample Size}&\textbf{Test Sample Size}&\textbf{Class} &\textbf{Image Size}  \\ \cmidrule[0.5pt](l{1pt}r{0pt}){1-5}

MNIST & 60,000 & 10,000  & 10 & 1 $\times$ 28 $\times$ 28  \\ \cmidrule[0.5pt](l{1pt}r{0pt}){1-5}

Cifar10 & 50,000 & 10,000  & 10 & 3 $\times$ 32 $\times$ 32  \\ \cmidrule[0.5pt](l{1pt}r{0pt}){1-5}

EMNIST-L & 124,800 & 20,800  & 26 & 1 $\times$ 28 $\times$ 28  \\ \cmidrule[0.5pt](l{1pt}r{0pt}){1-5}

Cifar100 & 50,000 & 10,000  & 100 & 3 $\times$ 32 $\times$ 32  \\ 
\bottomrule[1pt]
\end{tabular}}
\label{basic_information_of_datasets}
\end{center}
\vspace{-20pt}
\end{table}


\begin{table*}[t]
\centering
\setlength{\abovecaptionskip}{5pt} 
\renewcommand\arraystretch{1.3}
\caption{Accuracy on different datasets with 20\% and 100\% of 100 participating clients.}
\resizebox{1.0\textwidth}{!}{\begin{tabular}
{c|c|cc|cc|cc|cc|cc} 
\toprule[1.2pt]
\multirow{3}{*}{\multirowcell{1}{\centering\textbf{Datasets}}} & \multirow{3}{*}{\multirowcell{1}{\centering\textbf{Distribution}}} & \multicolumn{2}{c|}{\parbox{2cm}{\centering\textbf{FedAvg}\cite{mcmahan2017communication}}} & \multicolumn{2}{c|}{\parbox{2cm}{\centering\textbf{FedAdam}\cite{reddi2020adaptive}}} & \multicolumn{2}{c|}{\parbox{2cm}{\centering\textbf{FedProx}\cite{li2020federated}}} & \multicolumn{2}{c|}{\parbox{2cm}{\centering\textbf{FedDyn}\cite{durmus2021federated}}} & \multicolumn{2}{c}{\parbox{2cm}{\centering\textbf{FedAgg}(Ours)}}    \\ \cmidrule[0.5pt](l{1pt}r{0pt}){3-12}

&  & \parbox{1cm}{\centering 20\\ \vspace{-1.5pt}clients} & \parbox{1cm}{\centering 100\\ \vspace{-1.5pt}clients} & \parbox{1cm}{\centering 20\\ \vspace{-1.5pt}clients} & \parbox{1cm}{\centering 100\\ \vspace{-1.5pt}clients} & \parbox{1cm}{\centering 20\\ \vspace{-1.5pt}clients} & \parbox{1cm}{\centering 100\\ \vspace{-1.5pt}clients} & \parbox{1cm}{\centering 20\\ \vspace{-1.5pt}clients} & \parbox{1cm}{\centering 100\\ \vspace{-1.5pt}clients} & \parbox{1cm}{\centering 20\\ \vspace{-1.5pt}clients} & \parbox{1cm}{\centering 100\\ \vspace{-1.5pt}clients} \\ \cmidrule[0.8pt](l{1pt}r{0pt}){1-12}

\multirow{2}{*}{\multirowcell{2}{\textbf{MNIST} \\ \textbf{+Linear}}}
        & IID & 88.23 & 88.24 & 89.85 & 89.99 & 88.26 & 88.29 & 88.28 & 88.30 & \textbf{90.35} & \underline{90.77}  \\ \cmidrule[0.5pt](l{1pt}r{0pt}){2-12}
        
        & Non-IID & 86.28 & 86.57 & 89.08 & \underline{89.60} & 86.19 & 86.63 & 85.18 & 86.62 & \textbf{89.45} & 89.56 \\ \midrule[0.8pt]

\multirow{2}{*}{\multirowcell{2}{\textbf{MNIST} \\ \textbf{+MNIST-CNN}}}
        & IID & 93.59 & 93.94 & 96.55 & 96.59 & 93.35 & 93.62 & 93.56 & 94.06 & \textbf{97.48} & \underline{97.52} \\ \cmidrule[0.5pt](l{1pt}r{0pt}){2-12}
        
        & Non-IID & 86.93 & 85.35 & 87.59 & 90.70 & 85.96 & 87.30 & 84.48 & 86.35 & \textbf{94.91} & \underline{93.51} \\ \midrule[0.8pt]

\multirow{3}{*}{\multirowcell{2}{\textbf{Cifar10} \\ \textbf{+Cifar10-CNN}}}
        & IID & 66.97 & 67.44 & 68.22 & 69.93 & 65.31 & 66.82 & 65.89 & 66.47 & \textbf{69.21} & \underline{70.48} \\ \cmidrule[0.5pt](l{1pt}r{0pt}){2-12}
        
        & Dir-0.6 & 64.95 & 64.53 & 64.92 & 65.58 & 63.76 & 65.98 & 65.21 & 66.03 & \textbf{66.96} & \underline{67.30} \\ \cmidrule[0.5pt](l{1pt}r{0pt}){2-12}
        
        &  Dir-1.0 & 65.69 & 65.87 & 67.85 & 67.88 & 65.49 & 66.38 & 64.20 & 65.90 & \textbf{68.06} & \underline{68.46} \\ \midrule[0.8pt]

\multirow{3}{*}{\multirowcell{2}{\textbf{EMNIST-L} \\ \textbf{+LeNet-5}}}
        & IID & 92.52 & 93.14 & 93.09 & 92.79 & 92.77 & 92.79 & 92.52 & 92.80 & \textbf{94.11} & \underline{94.39} \\ \cmidrule[0.5pt](l{1pt}r{0pt}){2-12}
        
        & Dir-0.6 & 90.98 & 91.13 & 92.60 & 92.73 & 91.84 & 91.93 & 91.61 & 92.38 & \textbf{93.67} & \underline{93.68} \\ \cmidrule[0.5pt](l{1pt}r{0pt}){2-12}
        
        &  Dir-1.0 & 92.18 & 92.75 & 92.89 & 92.74 & 92.44 & 92.58 & 92.25 & 92.55 & \textbf{94.10} & \underline{93.88} \\ \midrule[0.8pt]

\multirow{3}{*}{\multirowcell{2}{\textbf{Cifar100} \\ \textbf{+VGG-11}}}
        & IID & 44.77 & 44.46 & 46.58 & 45.79 & 45.08 & 44.06 & 45.30 & 44.23 & \textbf{50.91} & \underline{51.22} \\ \cmidrule[0.5pt](l{1pt}r{0pt}){2-12}
        
        & Dir-0.6 & 44.45 & 44.44 & 47.48 & 47.43 & 44.96 & 45.25 & 45.23 & 44.93 & \textbf{49.98} & \underline{50.54} \\ \cmidrule[0.5pt](l{1pt}r{0pt}){2-12}
        
        &  Dir-1.0 & 45.04 & 45.08 & 47.85 & 46.39 & 45.53 & 45.49 & 45.26 & 45.09 & \textbf{50.59} & \underline{50.73} \\ 
\bottomrule[1.2pt]
\end{tabular}}
\vspace{-10pt}
\label{accuracy}
\end{table*}

\subsubsection{Datasets} 
We conduct our experiments on four typical and real-world datasets with different types and sorts (i.e. MNIST, EMNIST-L, Cifar10 and Cifar-100) to validate the performance of our proposed algorithm FedAgg. Specifically, (\romannumeral 1) MNIST dataset contains 70,000 gray-scale hand-written digit images in total which are divided into 60,000 images as a training set and 10,000 images as a test set. Besides, the images in MNIST dataset are 28 $\times$ 28 pixels, with a total of 10 classes. (\romannumeral 2) EMNIST-L dataset contains 145,600 gray-scale hand-written letter images in total, which are divided into 124,800 images as a training set and 20,800 images as a test set. Furthermore, the EMNIST-L dataset comprises gray-scale hand-written letter images measuring 28 $\times$ 28 pixels, encompassing a total of 26 classes. (\romannumeral 3) Cifar-10 and Cifar-100 datasets are both composed of 60,000 RGB images, which are divided into 50,000 images as a training set and 10,000 images as a test set with images 32 $\times$ 32 pixels. For Cifar10 dataset, 10 classes of images are contained, whereas the Cifar100 dataset consists of 100 classes, posing a significant challenge for model training. The basic information of the datasets we use is summarized in Table \ref{basic_information_of_datasets}.

\begin{table}[t]
\setlength{\abovecaptionskip}{1pt} 
\caption{Hyperparameter of all Datasets}
% \renewcommand\arraystretch{1.2}
\begin{center}
\resizebox{0.49\textwidth}{!}{\begin{tabular}{c|c|c|c|c}
\toprule[1pt]
\parbox{2cm}{\centering\textbf{Datasets}\\\centering\textbf{+Local Model}}&\parbox{1cm}{\centering\textbf{Learning}\\\centering\textbf{Rate}}&\textbf{Batchsize}&\parbox{1cm}{\centering\textbf{Global}\\\centering\textbf{Iteration}} &\parbox{1cm}{\centering\textbf{Local}\\\centering\textbf{Epoch}}  \\ \cmidrule[0.5pt](l{1pt}r{0pt}){1-5}

\parbox{2cm}{\centering\textbf{MNIST}\\\centering\textbf{+Linear}} & 0.01 & 32  & 30 & 3 \\ \cmidrule[0.5pt](l{1pt}r{0pt}){1-5}

\parbox{2cm}{\centering\textbf{MNIST}\\\centering\textbf{+MNIST-CNN}} & 0.01 & 32  & 30 & 3 \\ \cmidrule[0.5pt](l{1pt}r{0pt}){1-5}

\parbox{2cm}{\centering\textbf{EMNIST-L}\\\centering\textbf{+LeNet-5}} & 0.1 & 64  & 50 & 3 \\ \cmidrule[0.5pt](l{1pt}r{0pt}){1-5}

\parbox{2cm}{\centering\textbf{Cifar10}\\\centering\textbf{+Cifar10-CNN}}& 0.1 & 32  & 100 & 3 \\ \cmidrule[0.5pt](l{1pt}r{0pt}){1-5}

\parbox{2cm}{\centering\textbf{Cifar100}\\\centering\textbf{+VGG-11}}& 0.01 & 64  & 500 & 3 \\ 
\bottomrule[1pt]
\end{tabular}}
\label{hyperparameter}
\end{center}
\vspace{-20pt}
\end{table}

\begin{figure*}[t]
\setlength{\abovecaptionskip}{1pt} 
\centerline{\includegraphics[width=1.0\textwidth, trim=170 28 160 0,clip]{Experiment/MNIST.pdf}}
\caption{Experiment results on MNIST dataset with Linear and CNN local model.}
\label{MNIST}
\vspace{-15pt}
\end{figure*}

\subsubsection{Data Partition}
We adopt two different data partition methods for datasets. (\romannumeral 1) Similar to \cite{mcmahan2017communication}, we leverage the pathological Non-IID partition method for MNIST dataset. Initially, we arrange the data based on their digit labels, segmenting it into 200 shards, each containing 300 samples, and subsequently distributing two shards to each of the 100 clients, characterized by the fact that the majority of clients will possess examples from only two distinct digits. (\romannumeral 2) For the rest datasets, we utilize Dirichlet distribution \cite{hsu2019measuring} to partition datasets as Non-IID settings and vary the Dirichlet parameter $\sigma \! \in \! \{0.6, 1.0, \infty\}$ to validation the robustness of our proposed algorithm FedAgg. In Fig. \ref{dirichlet distribution on cifar100}, we display the heat map of the data distribution on Cifar100, where Fig. 5\subref{cifar100-IID} represents the labels distribution under IID setting and Fig. 5\subref{cifar100-dir06} shows the data distribution with Dirichlet parameter $\sigma \! = \! 0.6$. It is evident that the color of the heat map is shallow under the IID distribution with a close amount of labels. While for Non-IID distribution, the heat map is much deeper with a wider range of label quantity in the meantime, which indicates a higher level of data heterogeneity. Furthermore, in order to intuitively recognize the diversity among different Dirichlet parameters, we quantify the data distribution through Wasserstein distance inspired by \cite{jiao2020toward} with equation $\small \theta_{h}\!=\!\textstyle \sum_{j \in \mathcal{Y}}\left\|\mathbb{P}_{h}(y\!=\!j)\!-\!\mathbb{P}_{a}(y\!=\!j)\right\|$, as shown in Fig. 5\subref{cifar100-emd}.

\begin{figure*}[t]
\setlength{\abovecaptionskip}{5pt} 
\centerline{\includegraphics[width=1.0\textwidth, trim=0 10 0 0,clip]{Experiment/EMNIST_N20.pdf}}
\caption{Accuracy and loss on EMNIST-L dataset with 20\% of participating clients across different levels of data heterogeneity}
\label{EMNIST_N20}
\vspace{-12pt}
\end{figure*}

\begin{figure*}[t]
\setlength{\abovecaptionskip}{5pt} 
\centerline{\includegraphics[width=1.0\textwidth, trim=0 10 0 0,clip]{Experiment/Cifar10_N20.pdf}}
\caption{Accuracy and loss on Cifar10 dataset with 20\% of participating clients across different levels of data heterogeneity}
\label{Cifar10_N20}
\vspace{-12pt}
\end{figure*}

\begin{figure*}[t]
\setlength{\abovecaptionskip}{5pt} 
\centerline{\includegraphics[width=1.0\textwidth, trim=0 10 0 0,clip]{Experiment/Cifar100_N20.pdf}}
\caption{Accuracy and loss on Cifar100 dataset with 20\% of participating clients across different levels of data heterogeneity}
\label{Cifar100_N20}
\vspace{-12pt}
\end{figure*}

\subsubsection{Baselines}
We compare our proposed algorithm FedAgg with the following approaches. FedAvg \cite{mcmahan2017communication} is introduced as the fundamental framework in the field of federated learning. FedAdam \cite{reddi2020adaptive} allocates an adaptive optimizer for the global server and mini-batch SGD optimizer for the participating clients respectively, which averages the local gradient for adaptively updating global model. FedProx \cite{li2020federated} introduces a regularization prox-term during the local model training process which provides robust convergence on heterogeneous systems. FedDyn \cite{durmus2021federated} proposes a dynamic variants of the primal-dual regularizer to mitigate local inconsistencies for each client at each global iteration leading to efficient training.

\subsubsection{Local Training Model Architecture} 
In our numerical experiments, we implement five different local models with various architectures for each real-world dataset. (\romannumeral 1) For MNIST dataset, we firstly use a linear model with a fully connected layer of 784 input channels and 10 output channels which can be represented as MNIST-Linear. Besides, we also train a local model for the classification of hand-written digits in MNIST by using a convolutional neural network (CNN) and termed it as MNIST-CNN. This CNN has two 5 $\times$ 5 convolution layers, with each layer followed by 2 $\times$ 2 max pooling convolution layers, two fully connected layers with 7 $\times$ 7 $\times$ 64 and 512 units and a ReLU output layer with 10 units. (\romannumeral 2) For EMNIST-L dataset, we utilize classic LeNet-5 \cite{lecun1998gradient} as federated learning local training model for the gray-scale hand-written letters classification task. LeNet-5 contains two 5 $\times$ 5 convolution layers, each of which is followed by a 2 $\times$ 2 max pooling layer, three fully connected layers with 5 $\times$ 5 $\times$ 32, 120 and 84 units and two ReLU output layers with 26 units. (\romannumeral 3) As to Cifar10 dataset, another CNN is implemented, referred as Cifar10-CNN, which contains three 3 $\times$ 3 convolution layers, with each layer followed by 2 $\times$ 2 max pooling, two dropout layers to avoid overfitting, each of which is followed by a fully connected layer with 4 $\times$ 4 $\times$ 64 and 512 units respectively and a ReLU output layer with 10 units. (\romannumeral 4) We conduct numerical on Cifar100 dataset with standard VGG-11 \cite{simonyan2014very}, the same as the experiments of \cite{li4federated, kundu2021hire, sharmin2020inherent} to achieve well training performance.

\begin{figure*}[t]
\setlength{\abovecaptionskip}{5pt} 
\centerline{\includegraphics[width=1.0\textwidth, trim=50 70 50 70,clip]{Experiment/EMNIST_Cifar_barplot_N100.pdf}}
\caption{Accuracy on EMNIST-L/Cifar10/Cifar100 datasets with 100\% of participating clients across different data heterogeneity}
\label{EMNIST_Cifar10_Cifar100_barplot}
\vspace{-15pt}
\end{figure*}


\begin{figure*}[t]
\setlength{\abovecaptionskip}{0pt} 
\centerline{\includegraphics[width=1.0\textwidth, trim=20 40 20 30,clip]{Experiment/Adaptive.pdf}}
\caption{Accuracy on Cifar10 dataset with 20\% of participating clients across different adaptive FL algorithms}
\label{adaptive}
\vspace{-10pt}
\end{figure*}

\subsubsection{Hyperparameters Settings} 
For all datasets, we default local training epoch $L$ = 3 and weight parameter $\alpha$ = 0.1 for Eq (\ref{3}). Specifically, with regard to MNIST dataset, we set learning rate $\eta$ = 0.01, global training iteration $T$ = 30, and the batch size is 32. For both EMNIST-L and Cifar10 dataset, we configure learning rate $\eta$ as 0.1, global training iteration as $T$ = 50 and $T$ = 100, batch size as 64 and 32, respectively. Additionally, as to Cifar100 dataset, we set learning rate $\eta$ = 0.01 and share the same batch size with EMNIST-L, in the meantime, global iteration $T$ is configured as 500. We summarize all parameter configurations for each real-wold dataset in Table \ref{hyperparameter}. Specifically, for FedAdam, we default $\beta_{1}$ = 0.9, $\beta_{2}$ = 0.99 and $\tau $ = 0.001, while for FedProx and FedDyn, we set $\mu$ = 0.01 and $\alpha$ = 0.01, respectively.

\begin{table}[t]
\setlength{\abovecaptionskip}{6pt} 
\centering
\caption{Effectiveness of FedAgg compared with other adaptive FL algorithms.}
\renewcommand\arraystretch{1.5}
\resizebox{0.49\textwidth}{!}{\begin{tabular}
{c|c|ccccc} 
\toprule[1.0pt]
\textbf{Dataset} & \textbf{Distribution} & \textbf{FedAvg} & \textbf{FedAdam} & \textbf{Fedadagrad} & \textbf{FedYogi} & \textbf{FedAgg} \\ \midrule[0.8pt]

\multirow{2}{*}{\multirowcell{2}{\textbf{MNIST} \\ \textbf{+Linear}}}
        & IID & 88.23 & 89.85 & 86.72 & 89.92 & \textbf{90.35} \\ \cmidrule[0.5pt](l{1pt}r{0pt}){2-7}
        
        & Non-IID & 86.28 & 89.08 & 85.81 & 88.57 & \textbf{89.45} \\ \midrule[0.5pt]

\multirow{2}{*}{\multirowcell{2}{\textbf{MNIST} \\ \textbf{+MNIST-CNN}}}
        & IID & 93.59 & 96.55 & 94.32 & 96.48 & \textbf{97.48} \\ \cmidrule[0.5pt](l{1pt}r{0pt}){2-7}
        
        & Non-IID & 86.93 & 87.59 & 86.44 & 89.31 & \textbf{94.91} \\ \midrule[0.8pt]

\multirow{3}{*}{\multirowcell{2}{\textbf{Cifar10} \\ \textbf{+Cifar10-CNN}}}
        & IID & 66.97 & 68.22 & 64.30 & 67.96 & \textbf{69.21} \\ \cmidrule[0.5pt](l{1pt}r{0pt}){2-7}
        
        & Dir-0.6 & 64.95 & 64.92 & 62.22 & 64.51 & \textbf{66.96} \\ \cmidrule[0.5pt](l{1pt}r{0pt}){2-7}
        
        &  Dir-1.0 & 65.69 & 67.85 & 62.73 & 67.01 & \textbf{68.06} \\ \midrule[0.8pt]

\multirow{3}{*}{\multirowcell{2}{\textbf{EMNIST-L} \\ \textbf{+LeNet-5}}}
        & IID & 92.52 & 93.09 & 88.86 & 92.12 & \textbf{94.11} \\ \cmidrule[0.5pt](l{1pt}r{0pt}){2-7}
        
        & Dir-0.6 & 90.98 & 92.60 & 89.99 & 91.97 & \textbf{93.67} \\ \cmidrule[0.5pt](l{1pt}r{0pt}){2-7}
        
        &  Dir-1.0 & 92.18 & 92.89 & 90.34 & 91.64 & \textbf{94.10} \\ \midrule[0.8pt]

\multirow{3}{*}{\multirowcell{2}{\textbf{Cifar100} \\ \textbf{+VGG-11}}}
        & IID & 44.77 & 46.58 & 46.08 & 46.83 & \textbf{50.91} \\ \cmidrule[0.5pt](l{1pt}r{0pt}){2-7}
        
        & Dir-0.6 & 44.45 & 47.48 & 47.85 & 47.87 & \textbf{49.98} \\ \cmidrule[0.5pt](l{1pt}r{0pt}){2-7}
        
        &  Dir-1.0 & 45.04 & 47.85 & 48.49 & 48.41 & \textbf{50.59} \\
\bottomrule[1.0pt]
\end{tabular}}
\label{compared_with_different_adaptive_fl_algorithms}
\vspace{-20pt}
\end{table}

\subsection{Numerical Results}

\begin{table*}[t]
\setlength{\abovecaptionskip}{0pt} 
\caption{Effectiveness of FedAgg on other local model architectures.}
\begin{center}
\resizebox{0.8\textwidth}{!}{\begin{tabular}{c@{\hspace{8.2pt}}|c@{\hspace{8.2pt}}|c@{\hspace{8.2pt}}|c@{\hspace{8.2pt}}|c@{\hspace{8.2pt}}|c@{\hspace{8.2pt}}|c@{\hspace{8.2pt}}}
\toprule[1pt]
\textbf{Algorithms}&\textbf{LeNet-5}&\textbf{AlexNet}&\textbf{VGG-11} &\textbf{ResNet-18}&\textbf{GoogLeNet}&\textbf{DenseNet}  \\ \cmidrule[0.5pt](l{1pt}r{0pt}){1-7}

FedAvg & 66.27 & 70.03  & 82.09 & 82.08 & 85.11 & 81.41\\ \cmidrule[0.5pt](l{1pt}r{0pt}){1-7}

\cellcolor{gray!15}FedAgg & \cellcolor{gray!15} 67.20 & \cellcolor{gray!15}70.45  & \cellcolor{gray!15}82.63 & \cellcolor{gray!15}83.15 & \cellcolor{gray!15}86.06 & \cellcolor{gray!15}82.13 \\

\bottomrule[1pt]
\end{tabular}}
\label{different_local_model_architectures}
\end{center}
\vspace{-15pt}
\end{table*}

\subsubsection{Ablation Study on Number of Participating Clients}
To demonstrate the effectiveness of our proposed algorithm and investigate whether the enhancements introduced by FedAgg remain consistent as the ratio of participating clients increases. Firstly, we partition the four benchmark datasets (i.e., MNIST, EMNIST-L, Cifar10 and Cifar100) into 100 clients and randomly select 20\% of total participating clients to participate in federated learning training process with dynamically changed local training data and run 30, 50, 100 and 500 global communication iterations, respectively. The main experiment results are displayed in Table \ref{accuracy}. As shown in Fig. \ref{MNIST}, Fig. \ref{EMNIST_N20}, Fig. \ref{Cifar10_N20} and Fig. \ref{Cifar100_N20}, we visualize the experiment results on all datasets with 20\% client participating ratio. It is evident that FedAgg dominates other state-of-the-art baseline methods with faster convergence rate, higher model accuracy, lower training loss and faster loss descending rate, which demonstrate the immense potential of adaptive learning rate method in FL framework. Besides, we conduct experiments with 100\% participating clients to validate the effectiveness of FedAgg under the large-scale federated learning system. As shown in Table \ref{accuracy}, in most scenarios, FedAgg dominates the rest baselines and there is a consistent improvement in accuracy with increasing participating ratio. The above numerical experiment results illustrate that our proposed algorithm FedAgg performs well on both small-scale and large-scale FL systems, which demonstrates the capacity of FedAgg for widespread application in real-world federated learning scenarios involving monumental clients and random client participation. 


\subsubsection{Ablation Study on Data Heterogeneity}
To demonstrate the robustness of our proposed method across varying levels of data heterogeneity, we vary the Dirichlet parameter $\sigma \! \in \! \{0.6, 1.0, \infty\}$, where with the descending of $\sigma$, the degree of data heterogeneous increases. Besides, $\sigma = \infty$ means data across clients are IID distribution. The complete experiment results are summarized in Table \ref{accuracy}. Additionally, we visualize a subset of the numerical results on EMNIST-L, Cifar10, and Cifar100 datasets with 100\% of participating clients as shown in Fig. \ref{EMNIST_Cifar10_Cifar100_barplot}. It is evident that our proposed algorithm outperforms the other baseline methods, indicating its robustness and adaptability across diverse data heterogeneity. We also validate and simulate our FedAgg within small-scale FL system scenarios as in Table \ref{accuracy}. The results demonstrate that FedAgg still achieves better performance.

\subsubsection{Ablation Study on Extra Adaptive FL Algorithms} \label{extra adaptive baselines}
According to \cite{reddi2020adaptive}, other adaptive algorithms such as Fedadagrad and FedYogi are proposed to improve the model convergence rate under the situation of heterogeneous data. FedAdam employs adaptive learning rates and momentum by leveraging local updates from client devices to efficiently update the global model. FedAdagrad adjusts the learning rate based on the historical gradients of each model parameter, allowing the model to converge faster and achieve better performance. FedYogi, inspired by the Yogi optimizer, incorporates elements of adaptive learning rates and momentum to handle non-convex optimization problems in FL scenarios to improve global model convergence and accuracy. We conduct numerical experiments on Cifar10 with 20\% of participating clients. The experiment results are illustrated in Table \ref{compared_with_different_adaptive_fl_algorithms} and Fig. \ref{adaptive}. Compared with other adaptive FL algorithms, our proposed FedAgg still performs better with higher accuracy and a faster convergence rate.

\begin{figure}[t]
\setlength{\abovecaptionskip}{5pt}
\centerline{\includegraphics[width=0.49\textwidth, trim=50 0 50 50,clip]{Experiment/Architecture.pdf}}
\caption{Ablation study of different local model architecture on Cifar10 with 20\% of participating clients}
\label{architecture}
\vspace{-15pt}
\end{figure}

\subsubsection{Ablation Study on Different Local Model Architectures} \label{different local model architectures}

In this section, we conduct ablation experiments to demonstrate the effectiveness of our proposed algorithm FedAgg across different local model architectures. In addition to the convolutional neural network (CNN) aforementioned, we also implement experiments on LeNet-5 \cite{lecun1998gradient}, AlexNet \cite{krizhevsky2017imagenet}, VGG-11 \cite{simonyan2014very}, ResNet-18 \cite{he2016deep}, GoogLeNet \cite{szegedy2015going} and DenseNet \cite{huang2017densely}. Noted that ResNet introduces residual network architecture, GoogLeNet adopts Inception module and DenseNet employs densely connected convolutional networks to effectively alleviate vanishing gradients, enable more efficient feature propagation and increase the the model accuracy. The learning rate for each architecture is set to be 0.1 and performs $T = 100$ iterations of global training on Cifar10 dataset with IID data distribution. Our results are shown in Table \ref{different_local_model_architectures}. It is worth noting that FedAgg yields consistent enhancements in model performance across various CNN architectures and increases the convergence rate of global model. To evidently observe the improvement brought by FedAgg across all architectures, we also visualize the experiment results in Fig. \ref{architecture}. 

\section{Conclusion}\label{Conclusion}
In this paper, we study the fast convergence problem in federated learning by designing a dynamic learning rate. To deal with the client drifting issue raised by Non-IID data distribution, we first modify each client’s local parameter update rule by considering the aggregated gradients of all participating clients. In addition, a penalty term that measures the deviation between the local parameter and average parameter is introduced into each client’s objective function. By utilizing two mean-field terms to evaluate the average local parameter and gradient respectively, the optimal decentralized adaptive learning rate for each client is obtained, which makes the global model training more efficient and converges faster. Through rigorous theoretical analysis, we bound the client drifting term and prove that our FL framework provides a convergent upper bound. Finally, the experimental results show that our method achieves higher accuracy and faster convergent rate on four real-world datasets with different levels of data heterogeneity and client sampling ratio.

\bibliographystyle{IEEEtran}

\bibliography{reference}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{Wenhao_Yuan.jpg}}]{Wenhao Yuan}
received the B.S. degree from the University of Electronic Science and Technology of China in 2022. He is currently working towards the master's degree from the School of Artificial Intelligence, Sun Yat-sen University, China. His research interests include federated learning, game theory and incentive mechanism.
\end{IEEEbiography}

\vspace{-500pt}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{Xuehe_Wang.jpg}}]{Xuehe Wang}
(Member, IEEE) received her Ph.D. degree in electrical and electronic engineering from Nanyang Technological University, Singapore in 2016. She is an Associate Professor of School of Artificial Intelligence, Sun Yat-sen University, China. Before that, she was an Assistant Professor of Infocomm Technology Cluster with Singapore Institute of Technology from 2019 to 2021, and a postdoctoral research fellow with the Pillar of Engineering Systems and Design, Singapore University of Technology and Design from 2015 to 2019. Her research interests cover multi-agent systems, control theory, network economics and game theory.
\end{IEEEbiography}


\end{document}


