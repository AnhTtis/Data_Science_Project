%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,proceedings,bibtex,sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[sigconf]{acmart}
% \usepackage{amsmath,amssymb,amsfonts}
\allowdisplaybreaks[4]
% \usepackage{mdframed}
\usepackage[framemethod=tikz]{mdframed}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{makecell}
\usepackage{wrapfig}
\usepackage{graphicx}
% \usepackage[caption=false,font=footnotesize,labelfont=sf,textfont=sf]{subfig}
\usepackage{subfig}
\usepackage{multirow}
\usepackage{colortbl}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{pdfpages}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{bbding}

\newtheorem{assumption}{Assumption}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{remark}{Remark}
\newtheorem{corollary}{Corollary}
\newtheorem{theorem}{Theorem}
\newtheorem{example}{Example}%[section]
\newtheorem{axiom}{Axiom}
\newtheorem{definition}{Definition}

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmlicensed}
\copyrightyear{2024}
\acmYear{2024}
\acmDOI{XXXXXXX.XXXXXXX}

%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[MobiHoc 2024]{The 25th International Symposium on Theory, Algorithmic Foundations, and Protocol Design for Mobile Networks and Mobile Computing}{October 14-17, 2024}{Athens, Greece}
%%
%%  Uncomment \acmBooktitle if the title of the proceedings is different
%%  from ``Proceedings of ...''!
%%
%%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%%  June 03--05, 2018, Woodstock, NY}
\acmISBN{978-1-4503-XXXX-X/18/06}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

% Define the style of the box
% \mdfdefinestyle{MyFrame}{%
%     linecolor=gray,
%     outerlinewidth=1pt,
%     roundcorner=10pt,
%     innertopmargin=\baselineskip,
%     innerbottommargin=\baselineskip,
%     innerrightmargin=\baselineskip,
%     innerleftmargin=\baselineskip,
%     backgroundcolor=gray!20}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{FedAgg: Adaptive Federated Learning with Aggregated Gradients}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
% \author{Ben Trovato}
% \authornote{Both authors contributed equally to this research.}
% \email{trovato@corporation.com}
% \orcid{1234-5678-9012}
% \author{G.K.M. Tobin}
% \authornotemark[1]
% \email{webmaster@marysville-ohio.com}
% \affiliation{%
%   \institution{Institute for Clarity in Documentation}
%   \streetaddress{P.O. Box 1212}
%   \city{Dublin}
%   \state{Ohio}
%   \country{USA}
%   \postcode{43017-6221}
% }

% \author{Lars Th{\o}rv{\"a}ld}
% \affiliation{%
%   \institution{The Th{\o}rv{\"a}ld Group}
%   \streetaddress{1 Th{\o}rv{\"a}ld Circle}
%   \city{Hekla}
%   \country{Iceland}}
% \email{larst@affiliation.org}

\author{Wenhao Yuan}
\orcid{0009-0001-6625-7496}
\affiliation{%
  \institution{Sun Yat-sen University}
  \city{Zhuhai}
  \country{China}}
\email{yuanwh7@mail2.sysu.edu.cn}

\author{Xuehe Wang}
\authornote{Corresponding author.}
\orcid{0000-0002-6910-468X}
\affiliation{%
  \institution{Sun Yat-sen University}
  \city{Zhuhai}
  \country{China}}
% \affiliation{%
%   \institution{Guangdong Key Laboratory of Big Data Analysis and Processing}
%   \city{Guangzhou}
%   \country{China}}
\email{wangxuehe@mail.sysu.edu.cn}

% \author{Aparna Patel}
% \affiliation{%
%  \institution{Rajiv Gandhi University}
%  \streetaddress{Rono-Hills}
%  \city{Doimukh}
%  \state{Arunachal Pradesh}
%  \country{India}}

% \author{Huifen Chan}
% \affiliation{%
%   \institution{Tsinghua University}
%   \streetaddress{30 Shuangqing Rd}
%   \city{Haidian Qu}
%   \state{Beijing Shi}
%   \country{China}}

% \author{Charles Palmer}
% \affiliation{%
%   \institution{Palmer Research Laboratories}
%   \streetaddress{8600 Datapoint Drive}
%   \city{San Antonio}
%   \state{Texas}
%   \country{USA}
%   \postcode{78229}}
% \email{cpalmer@prl.com}

% \author{John Smith}
% \affiliation{%
%   \institution{The Th{\o}rv{\"a}ld Group}
%   \streetaddress{1 Th{\o}rv{\"a}ld Circle}
%   \city{Hekla}
%   \country{Iceland}}
% \email{jsmith@affiliation.org}

% \author{Julius P. Kumquat}
% \affiliation{%
%   \institution{The Kumquat Consortium}
%   \city{New York}
%   \country{USA}}
% \email{jpkumquat@consortium.net}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.


%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
% Federated Learning (FL) has become an emerging norm for distributed model training, which enables multiple devices cooperatively to train a shared model utilizing their own datasets scheduled by a central server while keeping private data localized. However, during the training process, the non-independent-and-identically-distributed (Non-IID) data generated on heterogeneous clients and frequent communication across participants may significantly influence the training performance, slow down the convergent rate, and increase communication consumption. In this paper, we ameliorate the standard stochastic gradient descent approach by introducing the aggregated gradients at each local update epoch and propose an adaptive learning rate iterative algorithm that further takes the deviation between the local parameter and global parameter into consideration. The aforementioned adaptive learning rate design mechanism requires local information of all clients, which is challenging as there is no communication during the local update epochs. To obtain a decentralized adaptive learning rate for each client, we introduce the mean-field approach by utilizing two mean-field terms to estimate the average local parameters and gradients respectively without exchanging clients' local information with each other over time. Through rigorous theoretical analysis, we prove that our method can provide the convergence guarantee for model training. Extensive numerical results demonstrate that our proposed framework is superior to the state-of-the-art FL schemes in both model accuracy and convergent rate on real-world datasets with IID and Non-IID data distribution.
Federated Learning (FL) has emerged as a pivotal paradigm within distributed model training, facilitating collaboration among multiple devices to refine a shared model, harnessing their respective datasets as orchestrated by a central server, while ensuring the localization of private data. Nonetheless, the non-independent-and-identically-distributed (Non-IID) data generated on heterogeneous clients and the incessant information exchange among participants may markedly impede training efficacy and retard the convergence rate. In this paper, we refine the conventional stochastic gradient descent (SGD) methodology by introducing aggregated gradients at each local training epoch and propose an adaptive learning rate iterative algorithm that concerns the divergence between local and average parameters. To surmount the obstacle that acquiring other clients' local information, we introduce the mean-field approach by leveraging two mean-field terms to approximately estimate the average local parameters and gradients over time in a manner that precludes the need for local information exchange among clients and design the decentralized adaptive learning rate for each client. Through meticulous theoretical analysis, we provide a robust convergence guarantee for our proposed algorithm and ensure its wide applicability. Our numerical experiments substantiate the superiority of our framework in comparison with existing state-of-the-art FL strategies for enhancing model performance and accelerating convergence rate under IID and Non-IID data distributions.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10003752.10003809.10010172</concept_id>
       <concept_desc>Theory of computation~Distributed algorithms</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10003752.10003809.10010170</concept_id>
       <concept_desc>Theory of computation~Parallel algorithms</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10003033.10003099</concept_id>
       <concept_desc>Networks~Network services</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Theory of computation~Distributed algorithms}
\ccsdesc[500]{Theory of computation~Parallel algorithms}
\ccsdesc[500]{Networks~Network services}


%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Federated Learning, Adaptive Learning Rate, Mean-Field Theory}
%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.

% \received{20 February 2007}
% \received[revised]{12 March 2009}
% \received[accepted]{5 June 2009}

% \settopmatter{printacmref=false}
% \setcopyright{none}
% \renewcommand\footnotetextcopyrightpermission[1]{}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
With the flourishing proliferation of edge devices, including but not limited to smartphones and wearable technology, the deluge of private data emanating from these distributed nodes has swelled exponentially. Tremendous repositories of information provide more opportunities for artificial intelligence (AI) researchers, enabling them to delve deeper into the latent value and potential of data, thereby facilitating the training of sophisticated multi-modal models like GPT-4. However, the transfer of voluminous datasets stored in edge devices to a centralized cloud is impractical and entails a significant expenditure of communication resources. The advent of stringent regulatory frameworks safeguarding data privacy, exemplified by the General Data Protection Regulation (GDPR) \cite{regulation2016regulation}, erects a formidable barrier for the realm of AI applications to access and leverage these private data. The dual challenges of privacy protection and big data boost the development of brand-new technologies that aggregate and model the data under the premise of meeting data privacy, security, and regulatory requirements \cite{sun2020adaptive}.

Federated learning serves as a new paradigm to tackle distributed machine learning tasks and achieve multi-fold performance benefits including improving communication efficiency and preserving data privacy \cite{mcmahan2017communication}. Specifically, each client undertakes one or several epochs of mini-batch stochastic gradient descent (SGD) with their dataset and subsequently uploads the model parameter rather than the raw data to the central server. After aggregating all local parameters, the central server refines the global parameter and distributes the updated global model to all clients for the next round of training. This iterative process continues until the global model converges or the specified maximum iteration threshold attains~\cite{jiao2020toward, zhang2021adaptive}. 


However, the FL framework is confronted with salient challenges, with client heterogeneity being a pivotal one, encompassing a spectrum of disparities ranging from statistical, and computational, to communicational heterogeneities. Pertaining to statistical heterogeneity, the data is independently generated on each client's geographically dispersed device, potentially yielding substantial variations in data volume and distribution, followed by precipitating a degradation in model performance and slow convergent rate. Further, within federated networks, each participant is entitled to execute several local epochs of computation prior to sharing their localized models. While such distributed training architecture is adept at alleviating the communication burden — a recognized bottleneck in FL — it simultaneously risks the emergence of client drifting thus decelerating the convergence rate of the global model~\cite{karimireddy2020scaffold, li2023anarchic}. % Federated networks potentially comprise numerous edge devices, and the model training efficiency could suffer due to limited resources such as bandwidth, energy, and power \cite{bonawitz2019towards}. 

\begin{figure*}[t]
\setlength{\abovecaptionskip}{2pt} 
    \centering
    \begin{minipage}{150pt}
    \centerline{\includegraphics[width=1.0\textwidth, trim=0 0 0 0,clip]{Intro/gradient.pdf}}
        \caption{The gradient descend comparison between the fixed and adaptive learning rate scheme.}
        \label{client_dev}
    \end{minipage}
    \hspace{5pt}
    \begin{minipage}{330pt}
        \subfloat{
            \label{MNIST_beta_acc}
            \includegraphics[width=0.5\textwidth, trim=30 0 70 20,clip]{Intro/adaptive_acc.pdf}}
        \subfloat{
            \label{MNIST_beta_loss}
            \includegraphics[width=0.5\textwidth, trim=30 0 70 20,clip]{Intro/adaptive_loss.pdf}} 
         \caption{Numerical analysis of model accuracy and training loss curves on the Cifar100 dataset featuring IID data distribution. The results underscore the substantial impact of employing the adaptive learning rate scheme based on adaptive optimizer Adam, which enhances model performance and convergence rate.}
        \label{beta}
    \end{minipage}
\vspace{-15pt}
\end{figure*}

Addressing the aforementioned challenges, substantial research endeavors have been dedicated. The seminal work by \cite{mcmahan2017communication} introduces FedAvg, a foundational approach to federated optimization that hinges on iterative model averaging, thereby significantly curtailing communication overhead. While FedAvg demonstrates commendable efficiency for IID datasets, its performance wanes and is unstable under Non-IID settings. To mitigate the adverse effects of client heterogeneity, the community has embraced asynchronous FL \cite{xu2021asynchronous,chen2020vafl} and client selection mechanism \cite{xu2020client,chai2020tifl,wang2020optimizing}. Asynchronous FL facilitates global aggregation upon the receipt of a single local update from any client. However, this approach risks the integrity of the global model, which may be disproportionately influenced by a single client's local model, leading to suboptimal convergence. Further, partial updates, where a subset of clients contribute to the global aggregation, introduce significant bias, as the global model predominantly reflects the characteristics of the selected clients, which compromises model accuracy and raises fairness concerns. 

In the context of federated networks, the potential of adaptive learning rate-based algorithms in FL remains largely underexplored. Current literature often undervalues the pivotal role of the learning rate—a hyperparameter that warrants meticulous tuning to influence the convergence speed and overall performance of FL models. As depicted in Fig. \ref{client_dev}, first-order optimization algorithms employing adaptive learning rates are instrumental in enhancing the efficiency of large-scale optimization tasks, as highlighted by \cite{zhou2018adashift}. Fig. \ref{beta} illustrates a quantitative analysis of model accuracy and training loss curves on the Cifar100 dataset, which features an IID data distribution and a 20\% client participation ratio. The results underscore the profound influence of incorporating adaptive learning rate mechanisms, which not only markedly elevate model performance but also demonstrate their efficacy in enhancing convergence rate and stability during training. 

In this paper, to achieve better model performance, we propose an adaptive learning rate scheme by considering the aggregated gradients in the local SGD process for each client and the deviations between local and average parameters. To estimate other clients' local information, two mean-field terms are introduced in the objective function and local updating rule for the decentralized learning rate design of each client. Further, we propose an algorithm to finalize our adaptive learning rate design. Our innovation points and main contributions are summarized as follows:
\begin{itemize}[itemsep=0pt, leftmargin=*, align=right]

\item \emph{Adaptive learning rate strategy:} To our best knowledge, this paper is the first work studying how to assign an adaptive learning rate for each client at each local update epoch by introducing the aggregated gradient into the local updating rules and the parameter deviations into the objective function of each client, which effectively alleviates the negative influence from heterogeneous data and accelerates the convergent rate of the global model. Furthermore, we theoretically analyze the model convergence and provide a convergence upper bound for FL model training.

\item \emph{Mean-field terms for optimal decentralized learning rate design and finalizing:} In the absence of inter-client local information exchange during local training epochs, we introduce two mean-field estimators to approximate the average of local model parameters and gradients, based on which, each client is allocated a decentralized learning rate. Through theoretical analysis, we prove the existence of the fixed point for mean-field estimators. Subsequently, we introduce an iterative algorithm to calculate the fixed point, thus finalizing the optimal adaptive learning rate.

\item \emph{Convergence insights and performance assessment :} We conduct a rigorous analysis of the convergence upper bound for FedAgg based on the aggregated gradients scheme. Through extensive experiments, we systematically showcase the superiority of FedAgg's adaptive learning rate mechanism over state-of-the-art FL benchmarks. The results elucidate that FedAgg attains an expeditious convergence rate and enhances accuracy. 
\end{itemize}

\begin{figure*}[t]
\setlength{\abovecaptionskip}{2pt}
\centerline{\includegraphics[width=0.85\textwidth, trim=90 80 70 35,clip]{framework.pdf}}
\caption{The Federated Learning Framework with Aggregated Gradients. }
\label{framework}
\vspace{-15pt}
\end{figure*}

\subsection{Related Work} \label{related work}
\emph{Adaptive hyperparameter update:} \citet{zhang2021adaptive} propose an Adaptive-B algorithm that can effectively learn the most suitable batch size through the Deep Reinforcement Learning (DRL) method. \citet{9415152} study the relationship between the batch size and learning rate and formulate a scheme to adaptively adjust the batch size with a scaled learning rate to reduce devices' waiting time and improve the convergence rate. \citet{wu2021fast} propose FedAdp to assign different weights for updating the global model based on node contribution adaptively. Fadam \cite{wu2022adaptive} adaptively adjusts the local model gradient based on the first and second-order momentum of the historical gradient to reduce overfitting and fluctuation. 

\emph{Adaptive client selection mechanism:} FedSAE \cite{li2021fedsae} automatically adjusts the training task of clients and converts the training loss of each client into selected probability, based on which the central server chooses the optimal participants. \citet{luo2022tackling} design an adaptive algorithm that optimizes the client sampling probability to tackle both system and statistical heterogeneity and minimize wall-clock convergence time. FEDEMD \cite{huang2022tackling} introduces a strategy that adaptively selects clients based on Wasserstein distance between the local and global data distributions. 

\emph{Adaptive asynchronous aggregation:} \citet{liu2021adaptive} design AAFL mechanism, which adaptively determines the optimal fraction of clients participating in global aggregation based on resource constraints. Fed2A \cite{liu2022fed2a} allows clients to upload shallow and deep layers of DNNs adaptively to improve their performance in a heterogeneous and asynchronous environment. \citet{wang2022asyncfeded} propose AsyncFedED, considering the staleness of the arrived gradients measured by the Euclidean distance between the stale and the current global model, as well as the number of local epochs.

In light of the existing literature, a significant shortfall in the domain of adaptive federated learning pertains to the absence of rigorous theoretical substantiation and close-form analytical concerning model convergence, as well as the derivation of precise expressions for adaptive parameters. Our contribution stands in stark contrast to the prevailing research by effectively bridging this gap. We tackle the challenges of data heterogeneity and client drift, all the while maintaining model accuracy through the dynamic adjustment of individual client learning rates. Furthermore, we have successfully derived a closed-form solution for the adaptive learning rate by considering a penalty term designed to quantify the divergence between local and global model parameters, thereby enhancing overall model efficacy. To underscore the robustness and broad applicability of our proposed algorithm, we present an exhaustive theoretical analysis of its convergence properties.

\section{Adaptive Federated Learning with Aggregated Gradients} \label{adaptive_learning_rate_in_FL}
In this section, we first present the problem formulation of the adaptive FL problem we study. Then, to improve FL model performance, we develop our methodology for aggregated gradients-based adaptive learning rate design. By introducing two mean-field terms $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$, the optimal adaptive learning rate $\eta_{i,l}^{t}$ for each client $i$ at local epoch $l$ of global iteration $t$ is obtained. Subsequently, we utilize Brouwer’s fixed point theorem to demonstrate the existence of mean-field terms $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$, thus proving the solvability of $\eta_{i,l}^{t}$. We depict the complete workflow of our FL framework in Fig.~\ref{framework}. 

\subsection{Federated Learning Model} 
In essence, the Federated Learning (FL) \cite{mcmahan2017communication,lim2020federated} methodology represents a decentralized machine learning paradigm explicitly designed to address the challenge of consensus learning. Within the FL framework, a global model is collaboratively trained by a substantial number of clients, each equipped with locally collected data. We assume that $N$ geographically distributed and heterogeneous clients (i.e. $S \!=\! \{1,2, \ldots, N\}$) are willing to participate in the FL training process and each client $i \!\in\! \{1, 2, \ldots, N\}$ utilizes their private and locally generated data $\mathcal{D}_{i}$ with datasize $D_{i}$ to perform model training. During each global training iteration $t \!\in\! \{0,1, \ldots, T\}$, each participating client $i$ performs $L$ ($L \!\geq\! 1$ is a positive integer) epochs of mini-batch stochastic gradient descent (SGD) training to update its local model parameter parallelly as follows:
\begin{align} \label{local_parameter_update}
\textstyle \boldsymbol{w_{i,l+1}^{t}}=\boldsymbol{w_{i,l}^{t}}-\eta_{i} \nabla F_{i}(\boldsymbol{w_{i,l}^{t}}), 
\end{align} 
where $\eta_{i}$ represents the learning rate for client $i$. In classic federated algorithms, such as FedAvg, $\eta_{i}$ is typically viewed as a constant. We denote $\boldsymbol{w_{i,l}^{t}}$ and $\nabla F_{i}(\boldsymbol{w_{i,l}^{t}})$ as the local parameter and gradient of client $i$ at the $l$-th local epoch of global iteration $t$ respectively, where $l \!\in\! \{0,1,  \ldots, L\}$. The central server averages the local models to generate the updated global parameter as soon as receiving the local parameters sent back by $N$ participating clients:
\begin{align} \label{local_model_aggregation}
\textstyle \boldsymbol{\bar w^{t}}=\sum_{i=1}^{N} \frac{D_{i}}{\sum_{j=1}^{N} D_{j}} \boldsymbol{w_{i,L}^{t-1}}.
\end{align}

At the onset of each global iteration $t$, we have $\small \boldsymbol{w_{i,0}^{t}} \!=\! \boldsymbol{\bar w^{t}}$, $\small i \!\in\! \{1, 2, \\ \ldots, N\}$. After updating the global model, the central server dispatches the updated global parameter back to all clients for the next iteration's training. The goal of the FL method is to find the optimal global parameter $\boldsymbol{w}$ to minimize the global loss function $\small F(\boldsymbol{w})$:
\begin{align} \label{fl_goal}
\min _{\boldsymbol{w}} \textstyle F(\boldsymbol{w})=\sum_{i=1}^{N} \frac{D_{i}}{\sum_{j=1}^{N} D_{j}} F_{i}(\boldsymbol{w}).
\end{align}

\subsection{Problem Formulation}
Adaptive learning rate mechanism plays an important role in deep learning due to their efficiency in solving large-scale optimization problems \cite{zhou2018adashift}. Besides, traditional FL methods introduce client drifting in the updates resulting in slow and unstable convergence \cite{karimireddy2020scaffold}. To alleviate the negative impact of client drifting brought by the Non-IID dataset and heterogeneous clients and achieve a fast model convergence rate within large-scale FL system scenarios, we introduce an adaptive learning rate for each client and aggregated gradients of all participating clients during the local model update:
\begin{align}\label{local_model_update_with_aggregated_gradient}
\textstyle \boldsymbol{w_{i,l+1}^{t}}=\boldsymbol{w_{i,l}^{t}} - \frac{\eta_{i,l}^{t}}{N}  \sum_{i=1}^{N} \nabla{F_{i}(\boldsymbol{w_{i,l}^{t})}},
\end{align} 
where $\eta_{i,l}^{t}$ is the adaptive learning rate specific to client $i$ at the $l$-th local epoch of global iteration $t \!\in\! \{0,1, \ldots, T\}$. Then, we introduce a penalty term that measures the deviation between the local model parameter of client $i$ and the average local model parameter at each local training epoch $l \!\in\! \{0,1, \ldots, L\}$. The $\ell_{2}$-norm metric is adopted for the penalty term design capitalized on its heightened susceptibility to outliers and aptitude in quantifying variable discrepancies across multidimensional spaces. Consequently, this guarantees the system's stability, offering a distinct advantage over the conventionally utilized $\ell_{1}$-norm and cosine similarity metrics \cite{pandit2011comparative}. In addition, to mitigate pronounced volatility throughout the FL training process, the determination of the learning rate parameter should also be considered. Hence, the objective function $U_{i}(l)$ of our optimization problem is constructed as follows:
\begin{align} 
\small U_{i}(l) = & \small \min_{\substack{\eta_{i,l}^{t}}} \textstyle \sum_{t=0}^{T} \sum_{l=0}^{L} \alpha (\eta_{i,l}^{t})^{2}\!+\!(1\!-\!\alpha) \nonumber \\ 
& \small \textstyle (\boldsymbol{w_{i,l}^{t}}\!-\!\frac{1}{N} \sum_{j=1}^{N} \boldsymbol{w_{j,l}^{t}})^\top (\boldsymbol{w_{i,l}^{t}}\!-\!\frac{1}{N}\sum_{j=1}^{N} \boldsymbol{w_{j,l}^{t}}),  \label{objective} \\
s.t. & \small \quad \textstyle  \boldsymbol{w_{i,l+1}^{t}}=\boldsymbol{w_{i,l}^{t}} - \frac{\eta_{i,l}^{t}}{N}  \sum_{i=1}^{N} \nabla{F_{i}(\boldsymbol{w_{i,l}^{t})}}, \nonumber
\end{align} 
where the aggregation weight $\alpha \!\in\! [0, \!1]$ is predefined to quantify the extent of focus between model parameter divergence and the adaptive learning rate adjustment in objective function $U_{i}(l)$. An elevated value of $\alpha$ signifies the pronounced impact of local parameter discrepancies on the federated learning system. 

For further demonstration and theoretical analysis, we introduce the following assumptions and lemmas which are widely used in federated optimization problems \cite{mcmahan2017communication, mitra2021achieving, li2023anarchic}. The detailed proof of Lemma \ref{lemma_bounded_parameter} is provided in Appendix \ref{proof_of_bounded_parameter} in the technical report \cite{yuan2023fedagg}.
\begin{assumption}\label{bounded_Gradients}
(Bounded Gradient) Since $F_{i}(\boldsymbol{w_{i,l}^{t}})$ is continuously differentiable, the local gradient function $\nabla F_{i}(\boldsymbol{w})$ have $P$-bound gradients, i.e., for any $i \!\in\! \{1, 2, \ldots, N\}$, we have $\|\nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})}\| \!\le\! P$.
\end{assumption}

\begin{assumption} \label{assumption 1}
($\beta$-Lipschitz Smoothness) $F_{i}(\boldsymbol{w})$ is $\beta$-Lipschitz smoothness for each clients $i \!\in\! \{0,1, \ldots, N\}$ with any two parameter vectors $\boldsymbol{w}$ and $\boldsymbol{w}^{\prime}$, we have: $\|\nabla{F_{i}(\boldsymbol{w}}) \!-\! \nabla{F_{i}(\boldsymbol{w}^{\prime}})\| \!\leq\! \beta\|\boldsymbol{w} \!-\! \boldsymbol{w}^{\prime}\|$. 
\end{assumption}

\begin{lemma}\label{lemma_bounded_parameter}
(Bounded Model Parameter) The local model parameter $\small \|\boldsymbol{w_{i,l}^{t}}\|$ is bounded for any client $\small i \!\in\! \{1, 2, \ldots, N\}$, i.e., $\small \|\boldsymbol{w_{i,l}^{t}}\| \!\le\! Q$.
\end{lemma}

% \begin{lemma} \label{PL_inequality}
% [Polyak-\L{}ojasiewicz inequality] Denote the optimal global parameter by $\boldsymbol{w}^{*}$, the $\beta$-Lipschitz continuous global loss function $\small F(\boldsymbol{w})$ satisfies Polyak-\L{}ojasiewicz condition if the following holds for $\small \mu \!>\! 0$ and $\small \boldsymbol{w} \!\in\! \mathbb{R}^{d}$, we have: $\small \frac{1}{2}\|\nabla{F(\boldsymbol{w})}\|^{2} \!\geq\! \mu(F(\boldsymbol{w}) \!-\! F(\boldsymbol{w}^{*}))$. 
% \end{lemma}

\begin{lemma} \label{PL_inequality}
[Polyak-\L{}ojasiewicz Inequality \cite{bottou2018optimization}] Denote the optimal global parameter by $\boldsymbol{w}^{*}$. Suppose the global loss function $F(\boldsymbol{w})$ satisfies $\beta$-Lipschitz continuous and Polyak-\L{}ojasiewicz condition. Then, for any $\mu \!>\! 0$ and for $\boldsymbol{w} \!\in\! \mathbb{R}^{d}$, we hold:  $\small \frac{1}{2}\|\nabla{F(\boldsymbol{w})}\|^{2} \!\geq\! \mu(F(\boldsymbol{w}) \!-\! F(\boldsymbol{w}^{*}))$.
\end{lemma}

\subsection{Decentralized Learning Rate For Each Client}\label{Decentralized Learning Rate For Each Client}

% \begin{mdframed}[style=MyFrame]
% Problem 1. \textbf{Profit Maximization for the Broker.}
% \begin{align} 
% \small U_{i}(l) = & \small \min_{\substack{\eta_{i,l}^{t}}} \textstyle \sum_{t=0}^{T} \sum_{l=0}^{L} \alpha (\eta_{i,l}^{t})^{2}\!+\!(1\!-\!\alpha) \nonumber \\ 
% & \small \textstyle (\boldsymbol{w_{i,l}^{t}}\!-\!\frac{1}{N} \sum_{j=1}^{N} \boldsymbol{w_{j,l}^{t}})^{T}(\boldsymbol{w_{i,l}^{t}}\!-\!\frac{1}{N}\sum_{j=1}^{N} \boldsymbol{w_{j,l}^{t}}), \\ \label{objective}
% s.t. & \quad \small \textstyle \boldsymbol{w_{i,l+1}^{t}}=\boldsymbol{w_{i,l}^{t}} - \frac{\eta_{i,l}^{t}}{N}  \sum_{i=1}^{N} \nabla{F_{i}(\boldsymbol{w_{i,l}^{t})}}, \nonumber
% \end{align} 
% \end{mdframed}

According to the objective function $U_{i}(l)$ in Eq. (\ref{objective}), we find that the learning rate $\eta_{i,l}^{t}$ of each client $i$ is affected by other clients' local parameters $\boldsymbol{w_{j,l}^{t}}$ and $\nabla{F_{j}(\boldsymbol{w_{j,l}^{t})}}$, where $j \! \in \! S \setminus \{i\}$. In each local epoch, as there is no exchange for model parameter among clients, client $i$ can not access other participants' local information $\boldsymbol{w_{j,l}^{t}}$ and $\nabla{F_{j}(\boldsymbol{w_{j,l}^{t})}}$, which makes this multi-client joint adaptive learning rate design over time challenging. To tackle the above challenges, we introduce two mean-field terms to estimate the average of local parameters and gradients, based on which, the decentralized adaptive learning rate of each client can be derived without requiring other clients' local information during local training. The definition of the mean-field terms is formulated as follows:
\begin{definition}\label{definition_mean_field_terms}
(Mean-Field Terms) To figure out the optimal adaptive learning rate for each participating client $i$, we introduce two mean-field terms to respectively estimate the average of all clients' local gradients and parameters at the $l$-th local epoch of global iteration $t$ with $t \in\{0,1, \ldots, T\}$, $l \in\{0,1, \ldots, L\}$:
\begin{align} 
\textstyle \boldsymbol{\phi_{1,l}^{t}} = \frac{1}{N}\sum_{i=1}^{N} \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})},\ \boldsymbol{\phi_{2,l}^{t}} = \frac{1}{N}\sum_{i=1}^{N} \boldsymbol{w_{i,l}^{t}}.
\end{align}
\end{definition}

From the mathematical point of view, terms $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$ are given functions in the our FL optimization problem. Based on Definition \ref{definition_mean_field_terms}, the deviation between the client $i$'s local parameter and the average local parameter could be refined as $\boldsymbol{w_{i,l}^{t}} \!-\! \boldsymbol{\phi_{2,l}^{t}}$. Accordingly, the objective function in Eq. (\ref{objective}) can be rewritten as follows:
\begin{align} 
\small \Tilde{U}_{i}(l) \!=\! \min_{\substack{\eta_{i,l}^{t}}} \textstyle  \sum_{t=0}^{T} \! \sum_{l=0}^{L} & \small \alpha(\eta_{i,l}^{t})^{2} \!+\! (1 \!-\! \alpha)(\boldsymbol{w_{i,l}^{t}} \!-\! \boldsymbol{\phi_{2,l}^{t}})^\top \! (\boldsymbol{w_{i,l}^{t}} \!-\! \boldsymbol{\phi_{2,l}^{t}}),  \label{objective_mean_field}  \\[-5pt] 
s.t. &  \small \quad \boldsymbol{w_{i,l+1}^{t}}=\boldsymbol{w_{i,l}^{t}}-\eta_{i,l}^{t}  \boldsymbol{\phi_{1,l}^{t}}. \label{local_model_update_mean_field}
\end{align} 

The optimization problem in Eqs. (\ref{objective_mean_field})-(\ref{local_model_update_mean_field}) can be characterized as a discrete-time linear quadratic optimal control problem. The learning rate parameter at iteration $t$ exerts a pivotal influence on the subsequent iterations, thus engendering a transformative progression through time. Thus, leveraging this insight, by constructing the Hamilton function, we can derive the close form expression of adaptive learning rate $\eta_{i,l}^{t}$ as summarized in Theorem~\ref{theorem_optimal_lr}.

\begin{theorem} \label{theorem_optimal_lr}
(Optimal Adaptive Learning Rate) Given the mean-field terms $\small \boldsymbol{\phi_{1,l}^{t}}$ and $\small \boldsymbol{\phi_{2,l}^{t}}$, with $\small \eta_{i,L}^{t}\!=\!0$, the optimal adaptive learning rate of client $i \!\in\! \{1, 2, \ldots, N\}$ at the $l$-th ($l \!\in\! \{0,1, \ldots, L\}$) local epoch of global training iteration $t \!\in\! \{0,1, \ldots, T\}$ is solvable and the close form expression is derived as follows:
\begin{align}\label{optimal_learning_rate}
\small \textstyle \eta_{i,l}^{t} \!=\! \frac{1-\alpha}{\alpha}(\boldsymbol{\phi_{1,l}^{t}})^\top((L \!-\! l)\boldsymbol{w_{i,l}^{t}} \!-\! \sum_{r=l}^{L} (L \!-\! r)\eta_{i,r}^{t}\boldsymbol{\phi_{1,r}^{t}} \!\!-\! \sum_{k=l+1}^{L} \! \boldsymbol{\phi_{2,k}^{t}}).
\end{align}
\end{theorem}

\begin{proof}
Following the discrete-time Maximum Principle and based on the mean-field terms $\small \boldsymbol{\phi_{1,l}^{t}}$ and $\small \boldsymbol{\phi_{2,l}^{t}}$, the discrete-time Hamilton function is constructed as follows:
\begin{align} \label{Hamilton}
\small H(l) \!=\! (\!1 \!-\! \alpha \!)(\!\boldsymbol{w_{i,l}^{t}} \!\!-\! \boldsymbol{\phi_{2,l}^{t}})^\top\! (\boldsymbol{w_{i,l}^{t}} \!\!-\! \boldsymbol{\phi_{2,l}^{t}}) \!+\! \alpha (\eta_{i,l}^{t})^{2} \!\!-\! \boldsymbol{\lambda(l \!+\! 1)}^\top\! \eta_{i,l}^{t}\boldsymbol{\phi_{1,l}^{t}}, \!
\end{align} 
where $\small \boldsymbol{\phi_{1,l}^{t}}$ and $\small \boldsymbol{\phi_{2,l}^{t}}$ can be viewed as given functions, which are not affected by the learning rate $\eta_{i,l}^{t}$. According to the properties of Hamilton function \cite{di2012discrete}, to obtain the expression of $\eta_{i,l}^{t}$, we need to consider the first-order constraints on the control vector $\small \eta_{i,l}^{t}$. For all time instants $t \!\in\! \{0,1, \ldots, T\} $, $l \!\in\! \{0,1, \ldots, L\}$, the first condition for a minimum holds calculating the first derivative of the Hamilton function concerning $\eta_{i,l}^{t}$, i.e., $\partial H(l)/\partial(\eta_{i,l}^{t}) \!=\! 0$. Thus, we obtain the expression of the adaptive learning rate $\eta_{i,l}^{t}$ as follows:
\begin{align} \label{eta}
\textstyle \frac{\partial H(l)}{\partial(\eta_{i,l}^{t})} \!=\! 2\alpha \eta_{i,l}^{t} \!-\! \boldsymbol{\lambda(l \!+\! 1)}^\top \! \boldsymbol{\phi_{1,l}^{t}} \!=\!0 \Rightarrow  \eta_{i,l}^{t} \!=\! \frac{1}{2 \alpha}(\boldsymbol{\phi_{1,l}^{t}})^\top \boldsymbol{\lambda(l \!+\! 1)}.
\end{align}

Through calculating the second-order derivative of the Hamilton function in Eq. (\ref{Hamilton}) to validate the second condition for a minimum, i.e., $\partial^{2} H(l) / \partial (\eta_{i,l}^{t})^{2} \!=\! 2 \alpha \!>\! 0$, we obtain the adaptive learning rate $\eta_{i,l}^{t}$ that minimizes the objective function. According to the differential property concerning the impulse vector $\boldsymbol{\lambda}$ and state vector $\boldsymbol{w}$ in Hamilton function \cite{qi2021linear}, we have the following derivation:
\begin{align} \label{lambda_difference}
\textstyle \boldsymbol{\lambda(l+1)}\!-\!\boldsymbol{\lambda(l)} \!=\! -\frac{\partial H(l)}{\partial(\boldsymbol{w_{i,l}^{t}})} \!=\! -2(1\!-\!\alpha)(\boldsymbol{w_{i,l}^{t}}\!-\!\boldsymbol{\phi_{2,l}^{t}}).
\end{align}

Based on the boundary condition \cite{di2012discrete} for the final value at $L$-th local epoch of the impulse vector $\boldsymbol{\lambda}$, we have:
\begin{align} 
\textstyle \boldsymbol{\lambda(L)}=\frac{\partial S(\boldsymbol{w_{i,L}^{t}})}{\partial (\boldsymbol{w_{i,L}^{t}})}= 2(1-\alpha)(\boldsymbol{w_{i,L}^{t}}-\boldsymbol{\phi_{2,L}^{t}}),
\end{align}
where $S(\cdot)$ is a weighting function of the state at the local update epoch $L$ and follows $S(\boldsymbol{w_{i, L}^{t}}) \!=\! (1 \!-\! \alpha)(\boldsymbol{w_{i, L}^{t}} \!-\! \boldsymbol{\phi_{2, L}^{t}})^\top(\boldsymbol{w_{i, L}^{t}} \!-\! \boldsymbol{\phi_{2, L}^{t}})$. By iteritively aggregating the formulations in Eq. (\ref{lambda_difference}), we can easily obtain the expression of $\boldsymbol{\lambda(l+1)}$, $l \!\in\! \{0,1, \ldots, L-1\}$ as follows:
\begin{align} \label{lambda}
\textstyle \small \boldsymbol{\lambda(\! l\!+\!1 \!)} \!=\! 2(\! 1\!-\!\alpha \!)(\!(L\!-\!l) \boldsymbol{w_{i,l+1}^{t}} \!\!-\!\!\! \sum_{r=l+1}^{L} \!(L \!-\! r)\eta_{i,r}^{t} \boldsymbol{\phi_{1,r}^{t}} \!\!-\!\! \sum_{k=l+1}^{L} \! \boldsymbol{\phi_{2,k}^{t}}). \!
\end{align}

Then, according to the expression of $\eta_{i,l}^{t}$ in Eq. (\ref{eta}) and $\boldsymbol{\lambda(l+1)}$ in Eq. (\ref{lambda}), we can calculate the optimal learning rate $\eta_{i,l}^{t}$ as follows:
\begin{align}
\eta_{i,l}^{t} &= \textstyle \frac{1}{2 \alpha}(\boldsymbol{\phi_{1,l}^{t}} )^\top\boldsymbol{\lambda(l+1)} \nonumber \\
&= \textstyle \frac{1-\alpha}{\alpha}(\boldsymbol{\phi_{1,l}^{t}})^\top \! ((L \!-\! l) \boldsymbol{w_{i,l+1}^{t}} \!-\! \sum_{r=l+1}^{L}(L \!-\! r)\eta_{i,r}^{t}\boldsymbol{\phi_{1,r}^{t}} \!\!-\! \sum_{k=l+1}^{L} \! \boldsymbol{\phi_{2,k}^{t}}) \nonumber \\
&= \textstyle \frac{1-\alpha}{\alpha}(\boldsymbol{\phi_{1,l}^{t}})^\top \! ((L \!-\! l) \boldsymbol{w_{i,l}^{t}} \!-\! \sum_{r=l}^{L} (L \!-\! r)\eta_{i,r}^{t}\boldsymbol{\phi_{1,r}^{t}} \!\!-\! \sum_{k=l+1}^{L}\!\boldsymbol{\phi_{2,k}^{t}}). \nonumber 
\end{align} 

Based on Eq. (\ref{optimal_learning_rate}), we observe that the mathematical formula of $\eta_{i,l}^{t}$ at the $l$-th local epoch of global iteration $t$ is associated with the learning rate $\eta_{i,k}^{t}$, $k \!\in\! \{l, l \!+\! 1, \ldots, L\}$. By backward induction, we prove that $\eta_{i,l}^{t}$ is solvable and is summarized in Proposition \ref{proposition_lr_linear_combination}.  

\begin{proposition} \label{proposition_lr_linear_combination}
$\small \eta_{i,l}^{t}$ is solvable and can be expressed as a linear combination of $\small \boldsymbol{w_{i,l}^{t}}$, $\small \boldsymbol{\phi_{1,l}^{t}}$ and $\small \boldsymbol{\phi_{2,l}^{t}}$, for $\small l \!\in\! \{0, 1, \ldots, L\}$, $\small t \!\in\! \{0,1, \ldots, T\}$, i.e., $\small \eta_{i,l}^{t} = \Lambda (\boldsymbol{w_{i,l}^{t}},\boldsymbol{\phi_{1,0}^{t}},\ldots,\boldsymbol{\phi_{1,L}^{t}}, \boldsymbol{\phi_{2,0}^{t}}, \ldots, \boldsymbol{\phi_{2,L}^{t}})$.
\end{proposition}

The detailed proof of Proposition \ref{proposition_lr_linear_combination} is provided in Appendix \ref{proof_of_proposition_lr_linear_combination} in the technical report \cite{yuan2023fedagg} and hence, the theorem holds. \end{proof}

\subsection{Finalizing Learning Rate with \texorpdfstring {$\boldsymbol{\phi_{1,l}^{t}}$}{} and \texorpdfstring {$\boldsymbol{\phi_{2,l}^{t}}$}{}}\label{Update of Estimator Finalizing Learning Rate}

Noted that mean-field estimators $\small \boldsymbol{\phi_{1,l}^{t}}$ and $\small \boldsymbol{\phi_{2,l}^{t}}$ are affected by the local gradient $\small \nabla{F_{i}(\boldsymbol{w_{i,l}^{t})}}$ and local parameter $\small \boldsymbol{w_{i,l}^{t}}$ of all clients which inversely affect the determination of the value of $\small \nabla{F_{i}(\boldsymbol{w_{i,l}^{t})}}$ and $\small \boldsymbol{w_{i,l}^{t}}$. Given the optimal adaptive learning rate $\small \eta_{i,l}^{t}$ determined according to Theorem \ref{theorem_optimal_lr}, in this part, we will derive and obtain the precise solutions for mean-field estimators $\small \boldsymbol{\phi_{1,l}^{t}}$ and $\small \boldsymbol{\phi_{2,l}^{t}}$ by finding the fixed point and characterized as the following theorem.
\begin{theorem} \label{theorem_fixed_point}
Based on the mean-field terms in Definition \ref{definition_mean_field_terms}, there exists a fixed point for the mapping $\small \Gamma (\{\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})} \!\mid\! t  \!\in\! \{0, 1, \ldots, T\}, \\ l \!\in\!  \{0,1, \ldots, L\}\})$ regarding local information $\small \boldsymbol{w_{i,l}^{t}}$ and $\small \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})}$.
\end{theorem}

\begin{algorithm}[ht]
\small
\caption{\small Pretraining for estimating $\small \boldsymbol{\phi_{1,l}^{t}}$, $\small \boldsymbol{\phi_{2,l}^{t}}$ and $\small \eta_{i,l}^{t}$} %算法的名字
\begin{algorithmic}[1]
\State {\bf Input:} %算法的输入， \hspace*{0.02in}用来控制位置，同时利用 \\ 进行换行
Local training epoch $L$, global training iteration $T$ , $\epsilon_{1} \!=\! \epsilon_{2} \!=\! 1$, $\epsilon \!=\! 0.001$, $j \!=\! 1$, initial value for $\boldsymbol{\phi_{1,l}^{t,\texttt{est}}}(0) \!\ge\! 0$, $\boldsymbol{\phi_{2,l}^{t,\texttt{est}}}(0) \!\ge\! 0$ and learning rate $\eta_{i,l}^{t} \!\in\! (0, 1)$, $\boldsymbol{\phi_{1,l}^{t}}\!=\!\boldsymbol{\phi_{1,l}^{t,\texttt{est}}}(0)$, $\boldsymbol{\phi_{2,l}^{t}}\!=\!\boldsymbol{\phi_{2,l}^{t,\texttt{est}}}(0)$, $\boldsymbol{w_{i,0}^{t}}$.
\For{$t=0$ to $T$}
    \While{$\epsilon_{1} \!>\! \epsilon$ and $\epsilon_{2} \!>\! \epsilon$}
        \For{each client $i \!\in\! \{0,1, \ldots, N\}$}
            \For{$l=1$ to $L-1$}
            \State Compute $\eta_{i,l}^{t}$, $\boldsymbol{w_{i,l}^{t}}$ and $\nabla \! F_{i} (\boldsymbol{w_{i,l}^{t}})$
            \EndFor
        \EndFor
            \For{$l=0$ to $L-1$}
            \State $\boldsymbol{\phi_{2,l}^{t,\texttt{est}}}(j)=\frac{1}{N}\sum_{i=1}^{N} \boldsymbol{w_{i,l}^{t}}$, $\boldsymbol{\phi_{2,l}^{t}}=\boldsymbol{\phi_{2,l}^{t,\texttt{est}}}(j)$
            \State $\epsilon_{2}'=\boldsymbol{\phi_{2,l}^{t,\texttt{est}}}(j)-\boldsymbol{\phi_{2,l}^{t,\texttt{est}}}(j-1)$
            \EndFor
            \State $\epsilon_{2}=\sum_{l=0}^{L} \epsilon_{2}'$
            \For{$l=0$ to $L-1$}
            \State $\boldsymbol{\phi_{1,l}^{t,\texttt{est}}}(j)=\frac{1}{N}\sum_{i=1}^{N} \nabla \! F_{i} (\boldsymbol{w_{i,l}^{t})}$, $\boldsymbol{\phi_{1,l}^{t}}=\boldsymbol{\phi_{1,l}^{t,\texttt{est}}}(j)$
            \State $\epsilon_{1}'=\boldsymbol{\phi_{1,l}^{t,\texttt{est}}}(j)-\boldsymbol{\phi_{1,l}^{t,\texttt{est}}}(j-1)$
            \EndFor
            \State $\epsilon_{1}=\sum_{l=0}^{L} \epsilon_{1}'$, $j=j+1$
    \EndWhile
\EndFor
\State \Return The adaptive learning rate $\eta_{i,l}^{t}$, $t \!\in\! \{0,1, \ldots, T\}$, $l \!\in\! \{0,1, \ldots, L\}$
\end{algorithmic}
\label{alg1}
\end{algorithm}


\begin{proof} 
By aggregating all equations in Eq. (\ref{local_model_update_with_aggregated_gradient}) iteratively, we can obtain a fresh expression of $\boldsymbol{w_{i,l}^{t}}$, $t \!\in\! \{0,1, \ldots, T\}$, $l \!\in\! \{0,1, \ldots, L\}$:
\begin{align}\label{fresh_local_update}
\boldsymbol{w_{i,l}^{t}} &\!= \textstyle \boldsymbol{w_{i,0}^{t}}-\sum_{p=0}^{l} \eta_{i,p}^{t} (\frac{1}{N}\sum_{j=1}^{N} \nabla{F_{j} (\boldsymbol{w_{j,p}^{t}})})  \\ 
&\!= \textstyle \boldsymbol{w_{i,0}^{t}} - \frac{1-\alpha}{\alpha} \sum_{p=0}^{l} (\frac{1}{N}\sum_{i=1}^{N} \nabla{F_{i} (\boldsymbol{w_{i,p}^{t}})})^\top (\frac{1}{N}\sum_{j=1}^{N} \nabla{F_{j} (\boldsymbol{w_{j,p}^{t}})}) \nonumber \\ 
& \textstyle ((L \!-\! p) \ \boldsymbol{w_{i,p}^{t}} \!\!-\! \sum_{r=p}^{L} \!\! \frac{L-r}{N} \eta_{i,r}^{t} \! \sum_{i=1}^{N} \!\! \nabla{F_{i} (\boldsymbol{w_{i,r}^{t}})} \!-\! \frac{1}{N}\!\! \sum_{k=p+1}^{L}\! \sum_{i=1}^{N} \! \boldsymbol{w_{i,k}^{t}}). \nonumber
\end{align}

For any client $i \!\in\! S$, substitute $\small \boldsymbol{\phi_{1,l}^{t}} \!=\! \frac{1}{N} \! \sum_{i=1}^{N} \! \nabla F_{i} (\boldsymbol{w_{i,l}^{t}}) $ and $\small \boldsymbol{\phi_{2,l}^{t}} \!=\! \frac{1}{N} \! \sum_{i=1}^{N} \! \boldsymbol{w_{i,l}^{t}}$, where $\small t \!\in\! \{0,1, \ldots, T\}$, $\small l \!\in\! \{0,1, \ldots, L\}$ into Eq. (\ref{fresh_local_update}), we can see that $\small \boldsymbol{w_{i,l}^{t}}$ and $\small \nabla \!F_{i} (\boldsymbol{w_{i,l}^{t}})$ of client $i$ at the $l$-th local epoch of global iteration $t$ are a function of $\small \{\boldsymbol{w_{i,l}^{t}}, \nabla \! F_{i} (\boldsymbol{w_{i,l}^{t}}) \!\mid\! t \!\in\! \{0,1, \ldots, T\}, l \!\in\! \{0,1, \ldots, L\}\}$ of all clients. Define the following function as a mapping from $\small \{\boldsymbol{w_{i,l}^{t}}, \nabla \! F_{i} (\boldsymbol{w_{i,l}^{t}}) \!\mid\! t \!\in\! \{0,1, \ldots, T\}, l \!\in\! \{0,1, \ldots, L\}\}$ to client $i$'s local parameter $\small \boldsymbol{w_{i,l}^{t}}$ and local gradient $\small \nabla \! F_{i} (\boldsymbol{w_{i,l}^{t}})$ in Eq. (\ref{fresh_local_update}) at global iteration $t$, i.e., $\small (\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})}) \!=\! \Gamma_{l}^{t}(\{\boldsymbol{w_{i,l}^{t}}, \nabla \! F_{i} (\boldsymbol{w_{i,l}^{t}}) \!\mid\! t \!\in\! \{0, \\ 1, \ldots,T\}, l \!\in\! \{0,1, \ldots, L\}\})$. To summarize any possible mapping $\small \Gamma_{l}^{t}$, we define the following vector functions as a mapping from $\small \{\boldsymbol{w_{i,l}^{t}}, \nabla \! F_{i} (\boldsymbol{w_{i,l}^{t}}) \!\mid\! t \!\in\! \{0,1, \ldots, T\},l \!\in\! \{0,1, \ldots, L\}\}$ to all clients' set:
\begin{align} \label{mapping}
& \Gamma(\{\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})} \mid t \in\{0,1, \ldots, T\}, l \in\{0,1, \ldots, L\}\}) \nonumber \\
 = (& \Gamma_{0}^{0}(\{\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})} \mid t \in \{0,1, \ldots, T\}, l \in \{0,1, \ldots, 
L\}\}), \ldots, \nonumber \\
& \Gamma_{L}^{0}(\{\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})} \mid t \in\{0,1, \ldots, T\},l \in\{0,1,\ldots, L\}\}), \ldots, \nonumber \\
& \Gamma_{0}^{T}(\{\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})} \mid t \in\{0,1, \ldots, T\}, l \in \{0,1, \ldots, L\}\}), \ldots, \nonumber \\
& \Gamma_{L}^{T}(\{\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})} \mid t \in\{0,1, \ldots,  T\}, l \in\{0,1, \ldots, L\}\})).
\end{align}  

Thus, the fixed point to $\small \Gamma (\{\boldsymbol{w_{i,l}^{t}}, \nabla \! F_{i} (\boldsymbol{w_{i,l}^{t}}) \!\mid\! t \!\in\! \{0,1, \ldots, T\}, l \!\in\! \{0, \\ 1, \ldots, L\}\}) \!=\! \Gamma (\{\boldsymbol{w_{i,l}^{t}},  \nabla \! F_{i} (\boldsymbol{w_{i,l}^{t}}) \!\mid\!  t \!\in\! \{0,1,  \ldots,  T\}, l \!\in\! \{0,1, \ldots, L\}\})$ in Eq. (\ref{mapping}) should be reached to let $\small \boldsymbol{\phi_{1,l}^{t}}$ and $\small \boldsymbol{\phi_{2,l}^{t}}$ replicate $\small \frac{1}{N}\!\!\sum_{i=1}^{N}\!\! \nabla{F_{i} (\boldsymbol{w_{i,l}^{t})}}$ and $\small \frac{1}{N}\!\! \sum_{i=1}^{N} \! \boldsymbol{w_{i,l}^{t}}$ respectively at first. Then, we define a continuous space $\small \Omega \!=\! [-Q, Q]_{0}^{0} \times \ldots \times[-Q, Q]_{L}^{0} \times \ldots \times[-Q, Q]_{0}^{T}\times \ldots \times[-Q, Q]_{L}^{T} \times [-P, P]_{0}^{0} \times \ldots \times[-P, P]_{L}^{0} \times \ldots \times[-P, P]_{0}^{T}\times \ldots \times[-P, P]_{L}^{T}$ for $\small \boldsymbol{w_{i,l}^{t}}$ and $\small \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})}$ in $LT$ dimensions. Since each $\small \Gamma_{l}^{t}$ is continuous in the space $\small \Omega$, $\small \Gamma$ is a continuous mapping from $\small \Omega$ to $\small \Omega$. According to the Brouwer's fixed-point theorem, the fixed point is found. \end{proof}

\begin{theorem} \label{theorem_fixed_point_reach}
Based on Theorem \ref{theorem_fixed_point}, the fixed point for the mapping $\Gamma (\{\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})}\})$ can be reached through iterative algorithm.
\end{theorem}

The proof of Theorem \ref{theorem_fixed_point_reach} is presented in Appendix \ref{proof_theorem_fixed_point_reach} in the technical report \cite{yuan2023fedagg}. We summarize the pretraining process of iteratively figuring out the fixed point of mean-field terms $\small \boldsymbol{\phi_{1,l}^{t}}$ and $\small \boldsymbol{\phi_{2,l}^{t}}$ in Alg. \ref{alg1}, which attains linear computation complexity $O(TNLM)$ and the detailed analysis is demonstrated in the following remark. Given global model $\small \boldsymbol{w_{i,0}^{t}}$, initial value for $\small \boldsymbol{\phi_{1,l}^{t}}(0)$, $\small \boldsymbol{\phi_{2,l}^{t}}(0)$ and $\small \eta_{i,l}^{t}$, we can easily obtain $\small \eta_{i,l}^{t}$ according to Theorem \ref{theorem_optimal_lr}. Then, based on $\small \eta_{i,l}^{t}$ and $\small \boldsymbol{w_{i,0}^{t}}$, we can calculate $\small \boldsymbol{w_{i,l}^{t}}$ and $\small \nabla{F_{i}(\boldsymbol{w_{i,l}^{t})}}$ by Eq. (\ref{local_model_update_mean_field}). Accordingly, mean-field terms $\small \boldsymbol{\phi_{1,l}^{t}}$ and $\small \boldsymbol{\phi_{2,l}^{t}}$ can be updated. Repeating the process until $\small \boldsymbol{\phi_{1,l}^{t,\texttt{est}}}(j + 1)\! \rightarrow \! \boldsymbol{\phi_{1,l}^{t,\texttt{est}}}(j)$ and $\small \boldsymbol{\phi_{2,l}^{t,\texttt{est}}}(j + 1)\! \rightarrow \! \boldsymbol{\phi_{2,l}^{t,\texttt{est}}}(j)$ within preset error $\small \epsilon$ simultaneously, the fixed point is subsequently found. In the meanwhile, $\small \eta_{i,l}^{t}$, $\small i \!\in\! \{1,  2, \ldots, N\}$ in each instant is obtained. The workflow of our proposed FedAgg is showcased in Alg.~\ref{alg2}. % In the meanwhile, $\small \eta_{i,l}^{t}$, $\small i \!\in\! \{1,  2, \ldots, N\}$ for instant $\small t \!\in\! \{0, 1, \ldots, T\}$ and $\small l \!\in\! \{0, 1, \ldots, L\}$ is also obtained. The complete training process of our proposed FedAgg is showcased in Alg. \ref{alg2}.  

\begin{remark}
(Linear Complexity with Mean-Field Terms) The optimization challenge presented by Eqs. (\ref{objective_mean_field})-(\ref{local_model_update_mean_field}) manifests as a discrete-time, nonlinear system with dynamic constraints, a scenario inherently difficult to tackle analytically due to the curse of dimensionality. However, the strategic incorporation of mean-field terms (Alg. \ref{alg1}) serves as a pivotal transformation. This methodology effectively streamlines the computational complexity to a linear scale, denoted as $O(TNLM)$, which reflects the sole dependence on the number of optimization iterations $M$ required to achieve convergence of the mean-field terms.
\end{remark}

\begin{algorithm}[t]
\small
\caption{\small Federated Learning with Adaptive Learning Rate (FedAgg)} %算法的名字
\begin{algorithmic}[1]
\State {\bf Input: } %算法的输入， \hspace*{0.02in}用来控制位置，同时利用 \\ 进行换行
The client size $N$, hyperparameter $\alpha$, local training epoch $L$, global training iteration $T$, initial global model $\boldsymbol{w_{i,0}^{t}}$, adaptive learning rate $\eta_{i,l}^{t}$, $ t \! \in \! \{0,\! 1, \! \ldots,\! T\},l \! \in \! \{0,\! 1,\! \ldots, \! L\}, i \! \in \! \{1,\! 2,\! \ldots,\! N\}$.
\For{$t=0$ to $T$}
    \State Acquire corresponding adaptive learning rate $\eta_{i,l}^{t}$
    \For{each client $i \in\{0,1, \ldots, N\}$}
        \For{$l=0$ to $L-1$}
            \State Local training:  $\boldsymbol{w_{i,l+1}^{t}}\!=\!\boldsymbol{w_{i,l}^{t}}\!-\!\eta_{i,l}^{t} \nabla{F_{i}(\boldsymbol{w_{i,l}^{t})}}$
        \EndFor
    \EndFor
\State Update global model: $\boldsymbol{\bar w^{t+1}} = \sum_{i=1}^{N} \frac{D_{i}}{\sum_{j=1}^{N} D_{j}} \boldsymbol{w_{i,L}^{t}}$
\EndFor
\State \Return The optimal global model parameter $\boldsymbol{\bar w^{T}}$.
\end{algorithmic}
\label{alg2}
\end{algorithm}

\section{Convergence analysis}\label{Convergence analysis}
In this section, we conduct a comprehensive theoretical examination and analyze the convergence upper bound for our proposed FedAgg, thereby establishing a robust theoretical foundation. At the inception of iteration $t$, it is presupposed that all clients are conversant with the global descent direction, with our descent direction analysis being executed at $\small \boldsymbol{w_{i,0}^{t}} \! = \!  \boldsymbol{\bar w^{t}}$, rather than $\small \boldsymbol{w_{i,l}^{t}}$. Firstly, we probe into the upper bound of the learning rate $\small \eta_{i,l}^{t}$. As articulated in Proposition \ref{proposition_lr_linear_combination}, $\small \eta_{i,l}^{t}$ is depicted as the linear combination of $\small \boldsymbol{w_{i,l}^{t}}$ and mean-field terms $\small \boldsymbol{\phi_{1,l}^{t}}$, $\small \boldsymbol{\phi_{2,l}^{t}}$, based on which, we formulate a more stringent upper bound for $\small \eta_{i,l}^{t}$ as encapsulated in Proposition~\ref{proposition_learning_rate_bound}.
\begin{proposition} \label{proposition_learning_rate_bound}
(Bounded Learning Rate) For any $\small \eta_{i,l}^{t}$ in training epochs, there exists a tight upper bound $\small \delta_{i,l}^{t}$ such that $\small \eta_{i,l}^{t} \!\in\! (0, \delta_{i,l}^{t}]$ with $\small \delta_{i,l}^{t} \!<\! 1$, where $\small l \!\in\! \{0,1, \ldots, L\}$, $\small t \!\in\! \{0,1, \ldots, T\}$, $\small i \!\in\! \{0,1, \ldots, N\}$.
\end{proposition}

The detailed proof of Proposition \ref{proposition_learning_rate_bound} is delineated in Appendix \ref{proof_of_proposition_learning_rate_bound} in the technical report \cite{yuan2023fedagg}. It has been proved in \cite{karimireddy2020scaffold} that training on the heterogeneous dataset (Non-IID dataset) can impede the model's convergence performance and substantially decelerate the convergence rate. Thus, we rigorously establish an upper bound for the client drifting term $\small \|\boldsymbol{w_{i,l}^{t}} \!-\! \boldsymbol{\bar w^{t}}\|$ summarized in Proposition \ref{proposition_client_drifting}, which significantly influences the efficacy of the global model and verifies the robustness of FedAgg under the Non-IID scenarios. %verifies the robustness of FedAgg in the context of the Non-IID data distribution scenarios.
\begin{proposition} \label{proposition_client_drifting}
(Bounded Client Drifting) Let $\small \delta_{l}\!=\!\text{min}\{\eta_{i,l}^{t}\}$, $\small \delta_{h}\!=\!\text{max}\{\delta_{i,l}^{t}\}$, and suppose $\small F_{i}(\boldsymbol{w_{i,l}^{t}})$ satisfies $\beta$-Lipschitz smoothness, for each participating client $i$, we have: $\small \|\boldsymbol{w_{i,l}^{t}} \!-\! \boldsymbol{\bar w^{t}}\| \!\leq\! L P \delta_{h}$. 
\end{proposition}

\begin{figure*}[t]
\setlength{\abovecaptionskip}{-2pt} 
\centerline{\includegraphics[width=0.95\textwidth, trim=170 30 160 20,clip]{Experiment/MNIST.pdf}}
\caption{Experiment results on MNIST dataset with Linear and CNN local model.}
\label{MNIST}
\vspace{-12pt}
\end{figure*}

The detailed proof of Proposition \ref{proposition_client_drifting} is presented in Appendix \ref{proof_of_proposition_client_drifting} in the technical report \cite{yuan2023fedagg}. The optimality gap $\small \|\boldsymbol{\bar w^{T}} \!-\! \boldsymbol{w^{*}}\|_{2}^{2}$ serves as a critical metric for the global model accuracy assessment, thus we derive an upper bound for this gap within the subsequent theorem, considering the aggregated gradients scheme.
\begin{theorem} \label{theorem_model_gap}
Suppose the global loss function $\small F(\boldsymbol{w})$ satisfies $\beta$-Lipschitz smoothness. If the global loss function is $\psi$-strong convex, after performing $T$-iterations adaptive federated learning global model training, the expected optimality gap of the global model satisfies, %with $L$ local epochs
\begin{align}
\textstyle \mathbb{E}[\|\boldsymbol{\bar w^{T}} - \boldsymbol{w^{*}}\|_{2}^{2}] \leq& \textstyle \ (1 - \frac{\delta_{h} L \psi}{N})^{T} \mathbb{E}[\|\boldsymbol{\bar w^{0}} -  \boldsymbol{w^{*}}\|_{2}^{2}] \nonumber \\
&+ \textstyle\sum_{k=0}^{T-1} (1 - \frac{\delta_{h} L \psi}{N})^{k} (\beta P^{2} L^{3} \delta_{h}^{3} + \delta_{h}^{2} P^{2} L^{2}).
\end{align}
Then, for the non-convex global loss function, after performing $T$-iterations adaptive FL model training, the expected optimality gap of the global model is upper bounded by:
\begin{align}
\textstyle \mathbb{E}[\|\boldsymbol{\bar w^{T}} \!-\! \boldsymbol{w^{*}}\|_{2}^{2}] \!\leq\! \frac{T (T \!-\! 1) P \delta_{h}^{2} L^{2} \|g^\top\|_{2}}{N} + \beta P^{2} L^{3} \delta_{h}^{3} + \delta_{h}^{2} P^{2} L^{2}. 
\end{align}
\end{theorem}

We provide the proof of Theorem \ref{theorem_model_gap} in Appendix \ref{proof_of_theorem_model_gap} in the technical report \cite{yuan2023fedagg}. Furthermore, according to Proposition \ref{proposition_learning_rate_bound}-\ref{proposition_client_drifting}, we proceed to formulate a convergence upper bound for the consecutive change of the federated learning global loss function $F(\boldsymbol{\bar w^{t}})$.
\begin{theorem} \label{theorem_difference}
For any two consecutive global training iterations $t$ and $t+1$, the convergent upper bound of global loss function satisfies,
\begin{align} \label{difference}
&F(\boldsymbol{\bar w^{t+1}})-F(\boldsymbol{\bar w^{t}})  \nonumber \\
\leq& \textstyle  \frac{\beta\delta_{l}}{N}  \sum_{i=1}^{N}\!\sum_{k=0}^{L-1}\!\sum_{j=1}^{N}\!\theta_{i}\|\boldsymbol{w_{j,k}^{t}}\!-\!\boldsymbol{\bar w^{t}}\|\|\nabla \! {F(\boldsymbol{\bar w^{t}})}\| \!-\! L\delta_{l}  \|\nabla \! {F(\boldsymbol{\bar w^{t}})}\|^{2} \nonumber \\
&+ \textstyle \beta^{2} L \delta_{h}^{2}\sum_{i=1}^{N} \sum_{k=0}^{L-1}\sum_{j=1}^{N} \theta_{i}^{2}\|\boldsymbol{w_{j,k}^{t}}\!-\!\boldsymbol{\bar w^{t}}\|^{2} + \beta L^{2} \delta_{h}^{2} \|\nabla{F(\boldsymbol{\bar w^{t}})} \|^{2} \nonumber \\
\leq& (\beta L^{2} \delta_{h}^{2} \!-\! L \delta_{l})\|\nabla \! F(\boldsymbol{\bar w^{t}})\|^{2} \!+\! L^{2} P^{2} \beta \delta_{l}\delta_{h} \!+\! \beta^{2} L^{4} N P^{2} \delta_{h}^{4}. 
\end{align}
\end{theorem}

The detailed proof of Theorem \ref{theorem_difference} is elaborated in Appendix \ref{proof_of_theorem_difference} in the technical report \cite{yuan2023fedagg}. As delineated by Eq. (\ref{difference}), our derivation reveals that the one-round convergence bound for our proposed adaptive FL algorithm FedAgg intrinsically pertains to the norm of the gradient of the global parameter at iteration $t$ and predetermined constants, ensuring the existence of a trustworthy convergence upper bound. Building upon the foundation of Theorem \ref{theorem_difference}, we extend our analysis to examine the upper bounds of the convergence rate and convergence error presented in Theorem \ref{theorem_convergence_rate}-\ref{theorem_convergence_error} respectively. The detailed proofs refer to Appendix \ref{proof_convergence_rate}-\ref{proof_convergence_error} in the technical report \cite{yuan2023fedagg}.

% The comprehensive proof of Theorem \ref{theorem_difference} is elaborated in Appendix \ref{proof_of_theorem_difference} of the accompanying technical report \cite{yuan2023fedagg}. As delineated by Equation (\ref{difference}), our analysis reveals that the one-round convergence bound for the proposed adaptive Federated Learning (FL) algorithm, FedAgg, is intrinsically linked to the norm of the gradient of the global parameters at iteration t and predetermined constants. This insight ensures the existence of a reliable upper bound for the convergence of our model. Building upon the foundation laid by Theorem \ref{theorem_difference}, we extend our investigation to examine the upper bounds of the convergence rate and convergence error in greater depth. These findings are systematically presented in Theorems \ref{theorem_convergence_rate} and \ref{theorem_convergence_error}, respectively. For the convenience of the reader, the detailed proofs of these theorems are provided in Appendices \ref{proof_convergence_rate} and \ref{proof_convergence_error} of the aforementioned technical report \cite{yuan2023fedagg}.

\begin{theorem} \label{theorem_convergence_rate}
(Convergence Rate) For the $T$-iterations adaptive FL training scenario, with an arbitrary set of participants, the expected reduction of global loss after $T$ iterations is bounded by:
\begin{align} \label{convergence_rate}
\mathbb{E} & [F(\boldsymbol{\bar w^{T}})] \!-\! F(\boldsymbol{w^{*}}) \!\leq\! (1 \!+\! 2 \mu (\beta L^{2} \delta_{h}^{2} \!-\! L \delta_{l}))^{T}(\mathbb{E}[F(\boldsymbol{\bar w^{0}})] \!-\! F(\boldsymbol{w^{*}})) \nonumber \\
&+ \textstyle \sum_{k=1}^{T-1} (1 \!+\! 2 \mu (\beta L^{2} \delta_{h}^{2} \!-\! L \delta_{l}))^{k} (L^{2} P^{2} \beta \delta_{l}\delta_{h} \!+\! \beta^{2} L^{4} N P^{2} \delta_{h}^{4}).
\end{align}
\end{theorem}

\begin{theorem} \label{theorem_convergence_error}
(Convergence Error) The expected average-squared $\ell_{2}$-norm of the gradient of the global loss function of FL with partial participation and multiple local updates is upper bounded by:
\begin{align} \label{convergence_error}
\textstyle \frac{1}{T} \! \sum_{t=0}^{T-1}\! \mathbb{E}[ \|\nabla \! F(\boldsymbol{\bar w^{t}})\|^{2}] \!\leq\! \frac{F(\boldsymbol{\bar w^{0}}) - F(\boldsymbol{w^{*}})}{T (L \delta_{l} -  \beta L^{2} \delta_{h}^{2})} \!+\! \frac{L P^{2} \beta \delta_{l}\delta_{h} + \beta^{2} L^{3} N P^{2} \! \delta_{h}^{4}}{\delta_{l} - \beta L \delta_{h}^{2}}. 
\end{align}
\end{theorem}

% Furthermore, regarding the assumptions underpinning the aforementioned convergence analysis, we have the following remark regarding the convex and non-convex properties of the global loss function:
Furthermore, delving into the foundational assumptions underpinning our aforementioned convergence analysis, we provide a pertinent remark concerning the characteristics of the global loss function, specific to its convex and non-convex feasibility.
\begin{remark}
(Convex \& Non-Convex Applicability) In the presented convergence analysis, the evaluation of FedAgg exclusively relies on the smoothness assumption associated with the objective function. Notably, the effectiveness of our results transcends the convexity paradigm of the function in question. Specifically, we rigorously demonstrate that the convergence assurances are applicable across both convex and non-convex domains. This aspect is pivotal as it enhances the applicability of our algorithm, rendering it a versatile mechanism for addressing a comprehensive spectrum of optimization challenges. The analysis delineates a robust framework that elucidates the pivotal role of smoothness properties in influencing the convergence dynamics, independent of the convexity attributes of the objective function.
\end{remark}

\begin{table*}[t]
\centering
\setlength{\abovecaptionskip}{1pt} 
\renewcommand\arraystretch{0.68}
\caption{Accuracy on different datasets with 20\% and 100\% participant ratio.}
\resizebox{1.0\textwidth}{!}{\begin{tabular}
{c|c|cc|cc|cc|cc|cc} 
\toprule[1.2pt]
\multirow{2}{*}{\multirowcell{1}{\centering\textbf{Datasets}}} & \multirow{2}{*}{\multirowcell{1}{\centering\textbf{Distribution}}} & \multicolumn{2}{c|}{\parbox{2cm}{\centering\textbf{FedAvg}\cite{mcmahan2017communication}}} & \multicolumn{2}{c|}{\parbox{2cm}{\centering\textbf{FedAdam}\cite{reddi2021adaptive}}} & \multicolumn{2}{c|}{\parbox{2cm}{\centering\textbf{FedProx}\cite{li2020federated}}} & \multicolumn{2}{c|}{\parbox{2cm}{\centering\textbf{FedDyn}\cite{durmus2021federated}}} & \multicolumn{2}{c}{\parbox{2cm}{\centering\textbf{FedAgg}(Ours)}}    \\ \cmidrule[0.5pt](l{1pt}r{0pt}){3-12}

&  & \parbox{1cm}{\centering 20\%} & \parbox{1cm}{\centering 100\%} & \parbox{1cm}{\centering 20\%} & \parbox{1cm}{\centering 100\%} & \parbox{1cm}{\centering 20\%} & \parbox{1cm}{\centering 100\%} & \parbox{1cm}{\centering 20\%} & \parbox{1cm}{\centering 100\%} & \parbox{1cm}{\centering 20\%} & \parbox{1cm}{\centering 100\%} \\ \cmidrule[0.8pt](l{1pt}r{0pt}){1-12}

\multirow{1}{*}{\multirowcell{2}{\parbox{2.1cm}{\centering \textbf{MNIST} \\ \textbf{+Linear}}}}
        & IID & 88.23 & 88.24 & 89.85 & 89.99 & 88.26 & 88.29 & 88.28 & 88.30 & \textbf{90.35} & \underline{90.77}  \\ \cmidrule[0.5pt](l{1pt}r{0pt}){2-12}
        
        & Non-IID & 86.28 & 86.57 & 89.08 & \underline{89.60} & 86.19 & 86.63 & 85.18 & 86.62 & \textbf{89.45} & 89.56 \\ \midrule[0.8pt]

\multirow{1}{*}{\multirowcell{2}{\parbox{2.1cm}{\centering \textbf{MNIST} \\ \textbf{+MNIST-CNN}}}}
        & IID & 93.59 & 93.94 & 96.55 & 96.59 & 93.35 & 93.62 & 93.56 & 94.06 & \textbf{97.48} & \underline{97.52} \\ \cmidrule[0.5pt](l{1pt}r{0pt}){2-12}
        
        & Non-IID & 86.93 & 85.35 & 87.59 & 90.70 & 85.96 & 87.30 & 84.48 & 86.35 & \textbf{94.91} & \underline{93.51} \\ \midrule[0.8pt]

\multirow{3}{*}{\multirowcell{2}{\textbf{Cifar10} \\ \textbf{+Cifar10-CNN}}}
        & IID & 66.97 & 67.44 & 68.22 & 69.93 & 65.31 & 66.82 & 65.89 & 66.47 & \textbf{69.21} & \underline{70.48} \\ \cmidrule[0.5pt](l{1pt}r{0pt}){2-12}
        
        & Dir-0.6 & 64.95 & 64.53 & 64.92 & 65.58 & 63.76 & 65.98 & 65.21 & 66.03 & \textbf{66.96} & \underline{67.30} \\ \cmidrule[0.5pt](l{1pt}r{0pt}){2-12}
        
        &  Dir-1.0 & 65.69 & 65.87 & 67.85 & 67.88 & 65.49 & 66.38 & 64.20 & 65.90 & \textbf{68.06} & \underline{68.46} \\ \midrule[0.8pt]

\multirow{3}{*}{\multirowcell{2}{\textbf{EMNIST-L} \\ \textbf{+LeNet-5}}}
        & IID & 92.52 & 93.14 & 93.09 & 92.79 & 92.77 & 92.79 & 92.52 & 92.80 & \textbf{94.11} & \underline{94.39} \\ \cmidrule[0.5pt](l{1pt}r{0pt}){2-12}
        
        & Dir-0.6 & 90.98 & 91.13 & 92.60 & 92.73 & 91.84 & 91.93 & 91.61 & 92.38 & \textbf{93.67} & \underline{93.68} \\ \cmidrule[0.5pt](l{1pt}r{0pt}){2-12}
        
        &  Dir-1.0 & 92.18 & 92.75 & 92.89 & 92.74 & 92.44 & 92.58 & 92.25 & 92.55 & \textbf{94.10} & \underline{93.88} \\ \midrule[0.8pt]

\multirow{3}{*}{\multirowcell{2}{\textbf{Cifar100} \\ \textbf{+VGG-11}}}
        & IID & 44.77 & 44.46 & 46.58 & 45.79 & 45.08 & 44.06 & 45.30 & 44.23 & \textbf{50.91} & \underline{51.22} \\ \cmidrule[0.5pt](l{1pt}r{0pt}){2-12}
        
        & Dir-0.6 & 44.45 & 44.44 & 47.48 & 47.43 & 44.96 & 45.25 & 45.23 & 44.93 & \textbf{49.98} & \underline{50.54} \\ \cmidrule[0.5pt](l{1pt}r{0pt}){2-12}
        
        &  Dir-1.0 & 45.04 & 45.08 & 47.85 & 46.39 & 45.53 & 45.49 & 45.26 & 45.09 & \textbf{50.59} & \underline{50.73} \\ 
\bottomrule[1.2pt]
\end{tabular}}
\vspace{-10pt}
\label{accuracy}
\end{table*}

\begin{figure*}[ht]
\setlength{\abovecaptionskip}{0pt} 
\centerline{\includegraphics[width=0.95\textwidth, trim=0 10 0 5,clip]{Experiment/EMNIST_N20.pdf}}
\caption{Accuracy and loss on EMNIST-L dataset with 20\% of participating clients across different levels of data heterogeneity}
\label{EMNIST_N20}
\vspace{-12pt}
\end{figure*}

\begin{figure*}[ht]
\setlength{\abovecaptionskip}{0pt} 
\centerline{\includegraphics[width=0.95\textwidth, trim=0 10 0 5,clip]{Experiment/Cifar10_N20.pdf}}
\caption{Accuracy and loss on Cifar10 dataset with 20\% of participating clients across different levels of data heterogeneity}
\label{Cifar10_N20}
\vspace{-12pt}
\end{figure*}

\section{Numerical Experiments}\label{Numerical Experiments}
We now conduct numerical experiments to validate FedAgg compared with several baselines, to show the advantage of our proposed adaptive learning rate scheme in the FL system. The experiments are implemented on a Pytorch-based platform \cite{paszke2019pytorch}.  

\subsection{Experiment Setups}
We conduct our experiments on four real-world datasets with different types (i.e. MNIST, EMNIST-L, Cifar10, and Cifar-100) to validate the performance of our proposed algorithm FedAgg. Additionally, we adopt two different data partition methods for datasets. Similar to \cite{mcmahan2017communication}, we leverage the pathological Non-IID partition method for the MNIST dataset. For the rest of the datasets, we utilize Dirichlet distribution \cite{hsu2019measuring} to partition datasets as Non-IID settings and vary the Dirichlet parameter $\sigma \! \in \! \{0.6, 1.0, \infty\}$ to validation the robustness of our proposed algorithm FedAgg. We utilize different convolutional neural networks as local models specific to each real-world dataset, similar to the experiment settings in \cite{mcmahan2017communication, kundu2021hire}. For all datasets, we default local training epoch $L$ = 3 and weight parameter $\alpha \!=\! 0.1$ for Eq. (\ref{local_model_aggregation}). Specifically, for FedAdam, we default $\small \beta_{1} \!=\! 0.9$, $\small \beta_{2} \!=\! 0.99$ and $\small \tau \!=\! 0.001$, while for FedProx and FedDyn, we set $\small \mu \!=\! 0.01$ and $\small \alpha \!=\! 0.01$, respectively. More detailed experimental settings are provided in Appendix \ref{detailed_experimental_setup} in the technical report~\cite{yuan2023fedagg}.

\subsection{Numerical Results}

\begin{table}[t]
\setlength{\abovecaptionskip}{1pt} 
\centering
\caption{Comparison to other adaptive FL algorithms.}
\renewcommand\arraystretch{0.88}
\resizebox{0.48\textwidth}{!}{\begin{tabular}
{c|c|ccccc} 
\toprule[1.0pt]
\textbf{Dataset} & \textbf{Distribution} & \textbf{FedAvg} & \textbf{FedAdam} & \textbf{Fedadagrad} & \textbf{FedYogi} & \textbf{FedAgg} \\ \midrule[0.8pt]

\multirow{1}{*}{\multirowcell{2}{\textbf{MNIST} \\ \textbf{+Linear}}}
        & IID & 88.23 & 89.85 & 86.72 & 89.92 & \textbf{90.35} \\ \cmidrule[0.5pt](l{1pt}r{0pt}){2-7}
        
        & Non-IID & 86.28 & 89.08 & 85.81 & 88.57 & \textbf{89.45} \\ \midrule[0.5pt]

\multirow{1}{*}{\multirowcell{2}{\textbf{MNIST} \\ \textbf{+MNIST-CNN}}}
        & IID & 93.59 & 96.55 & 94.32 & 96.48 & \textbf{97.48} \\ \cmidrule[0.5pt](l{1pt}r{0pt}){2-7}
        
        & Non-IID & 86.93 & 87.59 & 86.44 & 89.31 & \textbf{94.91} \\ \midrule[0.8pt]

\multirow{3}{*}{\multirowcell{2}{\textbf{Cifar10} \\ \textbf{+Cifar10-CNN}}}
        & IID & 66.97 & 68.22 & 64.30 & 67.96 & \textbf{69.21} \\ \cmidrule[0.5pt](l{1pt}r{0pt}){2-7}
        
        & Dir-0.6 & 64.95 & 64.92 & 62.22 & 64.51 & \textbf{66.96} \\ \cmidrule[0.5pt](l{1pt}r{0pt}){2-7}
        
        &  Dir-1.0 & 65.69 & 67.85 & 62.73 & 67.01 & \textbf{68.06} \\ \midrule[0.8pt]

\multirow{3}{*}{\multirowcell{2}{\textbf{EMNIST-L} \\ \textbf{+LeNet-5}}}
        & IID & 92.52 & 93.09 & 88.86 & 92.12 & \textbf{94.11} \\ \cmidrule[0.5pt](l{1pt}r{0pt}){2-7}
        
        & Dir-0.6 & 90.98 & 92.60 & 89.99 & 91.97 & \textbf{93.67} \\ \cmidrule[0.5pt](l{1pt}r{0pt}){2-7}
        
        &  Dir-1.0 & 92.18 & 92.89 & 90.34 & 91.64 & \textbf{94.10} \\ \midrule[0.8pt]

\multirow{3}{*}{\multirowcell{2}{\textbf{Cifar100} \\ \textbf{+VGG-11}}}
        & IID & 44.77 & 46.58 & 46.08 & 46.83 & \textbf{50.91} \\ \cmidrule[0.5pt](l{1pt}r{0pt}){2-7}
        
        & Dir-0.6 & 44.45 & 47.48 & 47.85 & 47.87 & \textbf{49.98} \\ \cmidrule[0.5pt](l{1pt}r{0pt}){2-7}
        
        &  Dir-1.0 & 45.04 & 47.85 & 48.49 & 48.41 & \textbf{50.59} \\
\bottomrule[1.0pt]
\end{tabular}}
\label{compared_with_different_adaptive_fl_algorithms}
\vspace{-15pt}
\end{table}

\subsubsection{Ablation Study on Number of Participating Clients}

To demonstrate the effectiveness of our proposed algorithm and investigate whether the enhancements introduced by FedAgg remain consistent as the ratio of participating clients increases. Firstly, we partition the four benchmark datasets (i.e., MNIST, EMNIST-L, Cifar10, and Cifar100) into 100 clients and randomly select 20\% of the total participating clients to participate in the federated learning training process with dynamically changed local training data and run 30, 50, 100 and 500 global communication iterations, respectively. The main experiment results are displayed in Table~\ref{accuracy}. As shown in Figs. \ref{MNIST}-\ref{Cifar100_N20}, we visualize the experiment results on all datasets with a 20\% client participating ratio. It is evident that FedAgg dominates other state-of-the-art baseline methods with a faster convergence rate, higher model accuracy, lower training loss, and faster loss descending rate, which demonstrate the immense potential of the adaptive learning rate method in the FL framework. Besides, we conduct experiments with 100\% participating clients to validate the effectiveness of FedAgg under the large-scale federated learning system. As shown in Table~\ref{accuracy}, in most scenarios, FedAgg dominates the rest baselines and there is a consistent improvement in accuracy with increasing participating ratio. The above numerical experiment results illustrate that our proposed algorithm FedAgg performs well on both small-scale and large-scale FL systems, which demonstrates the capacity of FedAgg for widespread application in real-world federated learning scenarios involving monumental clients and random client participation. 

\begin{figure*}[ht]
\setlength{\abovecaptionskip}{2pt} 
\centerline{\includegraphics[width=0.95\textwidth, trim=0 10 0 5,clip]{Experiment/Cifar100_N20.pdf}}
\caption{Accuracy and loss on Cifar100 dataset with 20\% of participating clients across different levels of data heterogeneity}
\label{Cifar100_N20}
\vspace{-12pt}
\end{figure*}


\begin{figure*}[ht]
\setlength{\abovecaptionskip}{2pt} 
    \centering
    \begin{minipage}{250pt}
    \centerline{\includegraphics[width=1.0\textwidth, trim=50 70 50 70,clip]{Experiment/EMNIST_Cifar_barplot_N100.pdf}}
    \caption{Accuracy on EMNIST-L/Cifar10/Cifar100 datasets with 100\% of participants across different data heterogeneity}
    \label{EMNIST_Cifar10_Cifar100_barplot}
    \end{minipage}
    \hspace{2pt}
    \begin{minipage}{250pt}
    \centerline{\includegraphics[width=1.0\textwidth, trim=50 70 50 70,clip]{Experiment/Adaptive.pdf}}
    \caption{Accuracy on Cifar10 dataset with 20\% of participating clients across different adaptive FL algorithms}
    \label{adaptive}
    \end{minipage}
\vspace{-15pt}
\end{figure*}

% \begin{figure*}
% \setlength{\abovecaptionskip}{2pt} 
%     \centering
%     \begin{minipage}[c]{150pt}
%         \centering
%         \renewcommand\arraystretch{1.2}
%         \captionof{table}{Model performance comparison with different local model architectures on the Cifar10 dataset.}
%         \resizebox{1.0\textwidth}{!}{\begin{tabular}{c@{\hspace{8.2pt}}|c@{\hspace{8.2pt}}|c@{\hspace{8.2pt}}|c@{\hspace{8.2pt}}}
%         \toprule[1pt]
%         \textbf{Algorithms}&\textbf{LeNet-5}&\textbf{AlexNet}&\textbf{VGG-11}   \\ \cmidrule[0.5pt](l{1pt}r{0pt}){1-4}
        
%         FedAvg & 66.27 & 70.03  & 82.09 \\ \cmidrule[0.5pt](l{1pt}r{0pt}){1-4}
        
%         \cellcolor{gray!15}FedAgg & \cellcolor{gray!15} 67.20 & \cellcolor{gray!15}70.45  & \cellcolor{gray!15}82.63  \\ \cmidrule[1.0pt](l{1pt}r{0pt}){1-4}

%         \textbf{Algorithms}&\textbf{ResNet-18}&\textbf{GoogLeNet}&\textbf{DenseNet}   \\ \cmidrule[0.5pt](l{1pt}r{0pt}){1-4}

%         FedAvg & 82.08 & 85.11 & 81.41 \\ \cmidrule[0.5pt](l{1pt}r{0pt}){1-4}
        
%         \cellcolor{gray!15}FedAgg & \cellcolor{gray!15}83.15 & \cellcolor{gray!15}86.06 & \cellcolor{gray!15}82.13  \\ 
        
%         \bottomrule[1pt]
%         \end{tabular}}
%         \label{different_local_model_architectures}
%     \end{minipage}
%     \hspace{2pt}
%     \begin{minipage}[c]{190pt}
%         \centerline{\includegraphics[width=1.0\textwidth, trim=50 10 50 50,clip]{Experiment/Architecture.pdf}}
%         \caption{Global model accuracy on EMNIST-L/Cifar10/Cifar100 datasets with 100\% participant ratio across different data heterogeneity}
%         \label{architecture}
%     \end{minipage}
%     \hspace{2pt}
%     \begin{minipage}[c]{150pt}
%         \centerline{\includegraphics[width=1.0\textwidth, trim=5 5 5 5,clip]{weight.pdf}}
%         \caption{Accuracy on Cifar10 dataset with 20\% participant ratio across different adaptive FL algorithms}
%         \label{weight}
%     \end{minipage}
% \vspace{-15pt}
% \end{figure*}

\subsubsection{Ablation Study on Data Heterogeneity}
To demonstrate the robustness of our proposed method across varying levels of data heterogeneity, we vary the Dirichlet parameter $\sigma \! \in \! \{0.6, 1.0, \infty\}$, where with the descending of $\sigma$, the degree of data heterogeneous increases. Besides, $\sigma \!=\! \infty$ means data across clients are IID distribution. Complete experiment results are summarized in Table~\ref{accuracy}. Additionally, we visualize a subset of the numerical results on EMNIST-L, Cifar10, and Cifar100 datasets with 100\% of participating clients as shown in Fig. \ref{EMNIST_Cifar10_Cifar100_barplot}. It is evident that our proposed algorithm outperforms the other baseline methods, indicating its robustness and adaptability across diverse data heterogeneity. We also validate and simulate our proposed FedAgg algorithm within small-scale FL system scenarios as in Table~\ref{accuracy}. The results demonstrate that FedAgg still achieves better performance.

\begin{table}[t]
\setlength{\abovecaptionskip}{0pt} 
\caption{Effectiveness on various local model architectures.}
\renewcommand\arraystretch{0.85}
\begin{center}
\resizebox{0.48\textwidth}{!}{\begin{tabular}{c@{\hspace{8.2pt}}|c@{\hspace{8.2pt}}|c@{\hspace{8.2pt}}|c@{\hspace{8.2pt}}|c@{\hspace{8.2pt}}|c@{\hspace{8.2pt}}|c@{\hspace{8.2pt}}}
\toprule[1pt]
\textbf{Algorithms}&\textbf{LeNet-5}&\textbf{AlexNet}&\textbf{VGG-11} &\textbf{ResNet-18}&\textbf{GoogLeNet}&\textbf{DenseNet}  \\ \cmidrule[0.5pt](l{1pt}r{0pt}){1-7}

FedAvg & 66.27 & 70.03  & 82.09 & 82.08 & 85.11 & 81.41\\ \cmidrule[0.5pt](l{1pt}r{0pt}){1-7}

\cellcolor{gray!15}FedAgg & \cellcolor{gray!15} 67.20 & \cellcolor{gray!15}70.45  & \cellcolor{gray!15}82.63 & \cellcolor{gray!15}83.15 & \cellcolor{gray!15}86.06 & \cellcolor{gray!15}82.13 \\

\bottomrule[1pt]
\end{tabular}}
\label{different_local_model_architectures}
\end{center}
\vspace{-15pt}
\end{table}

\begin{figure}[t]
\setlength{\abovecaptionskip}{0pt}
\centerline{\includegraphics[width=0.49\textwidth, trim=55 10 50 50,clip]{Experiment/Architecture.pdf}}
\caption{Ablation study of different local model architecture on Cifar10 with 20\% of participating clients}
\label{architecture}
\vspace{-15pt}
\end{figure}

\subsubsection{Ablation Study on Extra Adaptive FL Algorithms} \label{extra adaptive baselines}

According to \cite{reddi2021adaptive}, other adaptive algorithms such as Fedadagrad and FedYogi are proposed to improve the model convergence rate under the situation of heterogeneous data. FedAdam employs adaptive learning rates and momentum by leveraging local updates from client devices to efficiently update the global model. FedAdagrad adjusts the learning rate based on the historical gradients of each model parameter, allowing the model to converge faster and achieve better performance. FedYogi, inspired by the Yogi optimizer, incorporates elements of adaptive learning rates and momentum to handle non-convex optimization problems in FL scenarios to improve global model convergence and accuracy. We conduct numerical experiments on Cifar10 with 20\% of participating clients. The experiment results are illustrated in Table~\ref{compared_with_different_adaptive_fl_algorithms} and Fig. \ref{adaptive}. Compared with other adaptive FL algorithms, our proposed FedAgg still performs better with higher accuracy and a faster convergence rate.

\subsubsection{Ablation Study on Different Local Model Architectures} \label{different local model architectures}
We conduct ablation experiments to demonstrate the effectiveness of our proposed algorithm FedAgg across different local model architectures. In addition to the convolutional neural network (CNN) aforementioned, we also implement experiments on LeNet-5, AlexNet, VGG-11, ResNet-18, GoogLeNet, and DenseNet. Noted that ResNet introduces residual network architecture, GoogLeNet adopts the Inception module and DenseNet employs densely connected convolutional networks to effectively alleviate vanishing gradients, enable more efficient feature propagation, and increase the model accuracy. The learning rate for each architecture is set to be 0.1 and performs $T = 100$ iterations of global training on the Cifar10 dataset with IID data distribution. Our results are shown in Table~\ref{different_local_model_architectures}. It is worth noting that FedAgg yields consistent enhancements in model performance across various CNN architectures and increases the convergence rate of the global model. To observe the improvement of FedAgg across all architectures, we also visualize the experiment results in Fig. \ref{architecture}. 

\begin{figure}[t]
\setlength{\abovecaptionskip}{0pt}
\centerline{\includegraphics[width=0.36\textwidth, trim=8 5 5 5,clip]{weight.pdf}}
\caption{The model performance of our FedAgg algorithm with different aggregation weights $\alpha$ on the MNIST dataset.}
\label{weight}
\vspace{-15pt}
\end{figure}

\subsubsection{Ablation Study on the Aggregation Weight $\alpha$} 
We systematically conduct numerical experiments designed to elucidate the influence exerted by the aggregation weight $\alpha$ in the objective function presented by Eq. (\ref{objective_mean_field}), on the model efficacy. As depicted in Fig. \ref{weight}, the decrement of the hyperparameter $\alpha$ demonstrates that the FL framework accentuates the optimization of the discrepancy between the local model specific to client $i$ and the average local model, which in turn, bolsters the precision of the model and expedites the convergence rate. Our findings underscore the significance of meticulous hyperparameter tuning within the FL systems.

% In our empirical investigation, we systematically execute a series of numerical experiments designed to elucidate the influence exerted by the aggregation weight α, as articulated in the objective function presented by Equation (\ref{objective_mean_field}), on the efficacy of the model. The visualization in Figure \ref{weight} compellingly demonstrates that as the hyperparameter α undergoes a decremental adjustment, the Federated Learning (FL) framework accentuates the optimization of the discrepancy between the local model specific to client i and the mean local model. This optimization strategy, in turn, bolsters the precision of the model and expedites the rate of convergence. Our findings underscore the significance of meticulous hyperparameter tuning within the context of FL systems and offer a valuable contribution to the body of knowledge pertaining to model optimization and performance enhancement.


\section{Conclusion and Future Work}\label{Conclusion}
In this paper, we present an adaptive federated learning framework that leverages aggregated local gradients to enable each participant to ascertain their optimal decentralized adaptive learning rate with predefined mean-field terms, enhancing global model training efficiency and expediting convergence. We articulate an objective function for each client to balance the trade-off between training fluctuations and the divergence between local and average parameters. A meticulous theoretical analysis of the convergence upper bound for FedAgg offers a robust guarantee of model stability and broad applicability. The numerical experiments corroborate the superior performance of FedAgg, underscoring the merits of the adaptive learning rate strategy in federated learning scenarios.

For future works, we will investigate FedAgg under asynchronous FL settings. Moreover, the integration with the incentive mechanisms is a promising direction.

% In this paper, we study the fast convergence problem in federated learning by designing a dynamic learning rate. To deal with the client drifting issue raised by Non-IID data distribution, we first modify each client’s local parameter update rule by considering the aggregated gradients of all participating clients. In addition, a penalty term that measures the deviation between the local parameter and the average parameter is introduced into each client’s objective function. By utilizing two mean-field terms to evaluate the average local parameter and gradient respectively, the optimal decentralized adaptive learning rate for each client is obtained, which makes the global model training more efficient and converges faster. Through rigorous theoretical analysis, we bound the client drifting term and have proven that our FL framework provides a convergent upper bound. Finally, the experimental results show that our method achieves higher accuracy and faster convergent rate on four real-world datasets with different levels of data heterogeneity and client sampling ratio.

% \section{CCS Concepts and User-Defined Keywords}

% Two elements of the ``acmart'' document class provide powerful
% taxonomic tools for you to help readers find your work in an online
% search.

% The ACM Computing Classification System ---
% \url{https://www.acm.org/publications/class-2012} --- is a set of
% classifiers and concepts that describe the computing
% discipline. Authors can select entries from this classification
% system, via \url{https://dl.acm.org/ccs/ccs.cfm}, and generate the
% commands to be included in the \LaTeX\ source.

% User-defined keywords are a comma-separated list of words and phrases
% of the authors' choosing, providing a more flexible way of describing
% the research being presented.

% CCS concepts and user-defined keywords are required for for all
% articles over two pages in length, and are optional for one- and
% two-page articles (or abstracts).


% \section{Citations and Bibliographies}
% {\bfseries not allowed.}

% The use of \BibTeX\ for the preparation and formatting of one's
% references is strongly recommended. Authors' names should be complete
% --- use full first names (``Donald E. Knuth'') not initials
% (``D. E. Knuth'') --- and the salient identifying features of a
% reference should be included: title, year, volume, number, pages,
% article DOI, etc.

% The bibliography is included in your source document with these two
% commands, placed just before the \verb|\end{document}| command:
% \begin{verbatim}
%   \bibliographystyle{ACM-Reference-Format}
%   \bibliography{bibfile}
% \end{verbatim}
% where ``\verb|bibfile|'' is the name, without the ``\verb|.bib|''
% suffix, of the \BibTeX\ file.

% Citations and references are numbered by default. A small number of
% ACM publications have citations and references formatted in the
% ``author year'' style; for these exceptions, please include this
% command in the {\bfseries preamble} (before the command
% ``\verb|\begin{document}|'') of your \LaTeX\ source:
% \begin{verbatim}
%   \citestyle{acmauthoryear}
% \end{verbatim}


  % Some examples.  A paginated journal article \cite{Abril07}, an
  % enumerated journal article \cite{Cohen07}, a reference to an entire
  % issue \cite{JCohen96}, a monograph (whole book) \cite{Kosiur01}, a
  % monograph/whole book in a series (see 2a in spec. document)
  % \cite{Harel79}, a divisible-book such as an anthology or compilation
  % \cite{Editor00} followed by the same example, however we only output
  % the series if the volume number is given \cite{Editor00a} (so
  % Editor00a's series should NOT be present since it has no vol. no.),
  % a chapter in a divisible book \cite{Spector90}, a chapter in a
  % divisible book in a series \cite{Douglass98}, a multi-volume work as
  % book \cite{Knuth97}, a couple of articles in a proceedings (of a
  % conference, symposium, workshop for example) (paginated proceedings
  % article) \cite{Andler79, Hagerup1993}, a proceedings article with
  % all possible elements \cite{Smith10}, an example of an enumerated
  % proceedings article \cite{VanGundy07}, an informally published work
  % \cite{Harel78}, a couple of preprints \cite{Bornmann2019,
  %   AnzarootPBM14}, a doctoral dissertation \cite{Clarkson85}, a
  % master's thesis: \cite{anisi03}, an online document / world wide web
  % resource \cite{Thornburg01, Ablamowicz07, Poker06}, a video game
  % (Case 1) \cite{Obama08} and (Case 2) \cite{Novak03} and \cite{Lee05}
  % and (Case 3) a patent \cite{JoeScientist001}, work accepted for
  % publication \cite{rous08}, 'YYYYb'-test for prolific author
  % \cite{SaeediMEJ10} and \cite{SaeediJETC10}. Other cites might
  % contain 'duplicate' DOI and URLs (some SIAM articles)
  % \cite{Kirschmer:2010:AEI:1958016.1958018}. Boris / Barbara Beeton:
  % multi-volume works as books \cite{MR781536} and \cite{MR781537}. A
  % couple of citations with DOIs:
  % \cite{2004:ITE:1009386.1010128,Kirschmer:2010:AEI:1958016.1958018}. Online
  % citations: \cite{TUGInstmem, Thornburg01, CTANacmart}.
  % Artifacts: \cite{R} and \cite{UMassCitations}.




%%
%% The acknowledgments section is defined using the "acks" environment
%% (and NOT an unnumbered section). This ensures the proper
%% identification of the section in the article metadata, and the
%% consistent spelling of the heading.

\begin{acks}
This work was supported by National Natural Science Foundation of China under Grant No. 62206320.
\end{acks}

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{reference}

\newpage
%%
%% If your work has an appendix, this is the place to put it.
\appendix

% \section{Key Notations}
% \begin{table}[ht]
% \setlength{\abovecaptionskip}{0cm} 
% % \setlength{\belowcaptionskip}{-0.2cm}
% \caption{Key Notations and Their Corresponding Meaning}
% \begin{center}
% % \renewcommand\arraystretch{1.2}
% \begin{tabular}{p{0.45in}p{2.6in}}
% \toprule[0.8pt]
% \makecell[l]{\textbf{Symbol}}&\makecell[c]{\textbf{Description}}\\
% % \cline{2-3} 
% \midrule[0.8pt]
% $N$ & number of participating clients   \\

% $\mathcal{D}_{i}$ & private data on client $i$   \\

% $D_{i}$ & the datasize of $\mathcal{D}_{i}$   \\

% $\boldsymbol{w_{i,l}^{t}}$ & local model parameter of client $i$ at the $l$-th local epoch of global iteration $t$    \\

% $\boldsymbol{\bar w^{t}}$ & global model parameter at the global iteration $t$   \\

% $F_{i}(\boldsymbol{w_{i,l}^{t}})$ & loss function of client $i$  \\

% $F(\boldsymbol{w})$ & the global loss function  \\

% $\nabla F$ & the gradient of loss function  \\

% $\eta_{i,l}^{t}$ & learning rate of client $i$ at the $l$-th local epoch of global iteration $t$  \\ 

% $L$ & total number of local training epoch  \\

% $T$ & total number of global training iteration  \\

% $\boldsymbol{\phi_{1,l}^{t}}$, $\boldsymbol{\phi_{2,l}^{t}}$ & mean-field terms for estimating average gradient and parameter of all clients \\

% \bottomrule[0.8pt]
% \end{tabular}
% \label{tab1}
% \end{center}
% \vspace{-15pt}
% \end{table}

\section{Proof of Lemma \ref{lemma_bounded_parameter}}\label{proof_of_bounded_parameter}
\begin{proof}
Based on the extension of the Fundamental Theorem for Line Integrals, we have $dF(\boldsymbol{w_{i,l}^{t}}) \!=\! d\boldsymbol{w_{i,l}^{t}} \!\cdot\! \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})}$, Then, according to Eq. (\ref{fresh_local_update}), we note that both $\boldsymbol{w_{i,0}^{t}}$ and $\eta_{i,0}^{t}$, $t \!\in\! \{0,1, \ldots, T\}$ are bounded. Besides, on account of $\nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})}$, $t \!\in\! \{0,1, \ldots, T\}$, $l \!\in\! \{0, 1, \\ \ldots, L\}$ is bounded as we proved above and based on Proposition \ref{proposition_lr_linear_combination}, we have each term in the Eq. (\ref{fresh_local_update}) is bounded. Thus, we also have the following upper bound for $\boldsymbol{w_{i,l}^{t}}$, i.e., $\|\boldsymbol{w_{i,l}^{t}}\| \!\le\! Q$. \end{proof}

\section{Proof of Proposition \ref{proposition_lr_linear_combination}}\label{proof_of_proposition_lr_linear_combination}
\begin{proof}
By adopting backward inductive reasoning, we can find the potential rules among $\eta_{i,l}^{t}$, $\boldsymbol{w_{i,l}^{t}}$, $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$, $l \!\in\! \{0,  1, \ldots, L\}$. Based on the expression of $\boldsymbol{\lambda(L\!-\!1)}$ and $\boldsymbol{\lambda(L\!-\!2)}$ in Eq. (\ref{lambda}), we have following derivations. First of all, $\eta_{i,L-1}^{t}$ can be derived from $\boldsymbol{\lambda(L)}$ based on Eq. (\ref{eta}):
\begin{align} 
\eta_{i,L-1}^{t} &\!=\!  \frac{1}{2 \alpha}( \boldsymbol{\phi_{1,L-1}^{t}} )^\top \boldsymbol{\lambda(L)} \nonumber\\
&\!=\!  \frac{1\!-\!\alpha}{\alpha}(\boldsymbol{\phi_{1,L-1}^{t}})^\top (\boldsymbol{w_{i,L-1}^{t}}\!\!-\!\boldsymbol{\phi_{2,L}^{t}}\!\!-\!\eta_{i,L-1}^{t}\boldsymbol{\phi_{1,L-1}^{t}}). \nonumber  \\
\Rightarrow \eta_{i,L-1}^{t} &\!=\!  \frac{1\!-\!\alpha}{\alpha}\cdot\frac{(\boldsymbol{\phi_{1,L-1}^{t}})^\top(\boldsymbol{w_{i,L-1}^{t}}\!-\!\boldsymbol{\phi_{2,L}^{t}})}{1\!+\!\frac{1\!-\!\alpha}{\alpha}(\boldsymbol{\phi_{1,L-1}^{t}})^\top \boldsymbol{\phi_{1,L-1}^{t}}}. 
\end{align} 

Then, we can figure out the expression of $\eta_{i,L-2}^{t}$ based on $\boldsymbol{\lambda(L\!-\!1)}$ and $\eta_{i,L-1}^{t}$ in the above derivations:
\begin{align} \label{eta_L_minus_2}
\eta_{i,L-2}^{t} &=  \frac{1}{2 \alpha}( \boldsymbol{\phi_{1,L-2}^{t}} )^\top \boldsymbol{\lambda(L \!-\! 1)} \!=\! \zeta_{2} (2 \boldsymbol{w_{i,L-1}^{t}} \!-\! \eta_{i,L-1}^{t}\boldsymbol{\phi_{1,L-1}^{t}} \!-\! \zeta_{1}) \nonumber \\
&= \zeta_{2} (2 (\boldsymbol{w_{i,L-2}^{t}}-\eta_{i,L-2}^{t} \boldsymbol{\phi_{1,L-2}^{t}})-\zeta_{1}-\zeta_{3}).\nonumber \\
& \Rightarrow \eta_{i,L-2}^{t} = \frac{\zeta_{2} (2 \boldsymbol{w_{i,L-2}^{t}}-\zeta_{7})}{1+\zeta_{5}+\zeta_{8}}. 
\end{align}
where, 
\begin{align} 
\left\{\begin{array}{l}
% \vspace{6pt}
\zeta_{1}=\sum_{k=L-1}^{L} \boldsymbol{\phi_{2,k}^{t}}, \zeta_{2}=\frac{1-\alpha}{\alpha}(\boldsymbol{\phi_{1,L-2}^{t}} )^\top, \zeta_{3}=\frac{1-\alpha}{\alpha}\frac{( \boldsymbol{\phi_{1,L-1}^{t}})^\top}{1+\zeta_{4}} \zeta_{6}, \\[6pt]
% \vspace{6pt}
\zeta_{4}=\frac{1-\alpha}{\alpha}(\boldsymbol{\phi_{1,L-1}^{t}} )^\top \boldsymbol{\phi_{1,L-1}^{t}}, \zeta_{5}=\frac{2(1-\alpha)}{\alpha}( \boldsymbol{\phi_{1,L-2}^{t}})^\top \boldsymbol{\phi_{1,L-2}^{t}}, \\[6pt]
% \vspace{6pt}
\zeta_{6}=(\boldsymbol{w_{i,L-1}^{t}}-\eta_{i,L-2}^{t}\boldsymbol{\phi_{1,L-2}^{t}}-\boldsymbol{\phi_{2,L}^{t}}) \boldsymbol{\phi_{1,L-1}^{t}}, \\[6pt]
% \vspace{6pt}
\zeta_{7}=\frac{1-\alpha}{\alpha}\frac{(\boldsymbol{\phi_{1,L-1}^{t}})^\top (\boldsymbol{w_{i,L-2}^{t}}-\boldsymbol{\phi_{2,L}^{t}} )\boldsymbol{\phi_{1,L-1}^{t}}+\zeta_{1}}{1+\zeta_{4}}, \\[6pt]
\zeta_{8}=2 (\frac{1-\alpha}{\alpha})^{2}\frac{(\boldsymbol{\phi_{2,L-2}^{t}})^\top(\boldsymbol{\phi_{2,L-1}^{t}})^\top \boldsymbol{\phi_{2,L-2}^{t}}\boldsymbol{\phi_{1,L-1}^{t}}}{1+\zeta_{4}}. \nonumber
\end{array}\right.
\end{align}

Repeating the similar derivation process of deducing $\eta_{i,L-1}^{t}$ and $\eta_{i,L-2}^{t}$, we can acquire the expression of $\eta_{i,l}^{t}$. $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$ are both viewed as given functions. Besides, noticed that we can always find a linear function of $\eta_{i,l}^{t}$ expressed by $\boldsymbol{w_{i,l}^{t}}$ and $\eta_{i,q}^{t}$, $q \! \in \! \{l+1, \ldots, L\}$ that we have already calculated before $\eta_{i,l}^{t}$. Therefore, the solution of $\eta_{i,l}^{t}$, $l \!\in\! \{0,1, \ldots, L\!-\!1\}$, can be achieved via an iterative algorithm. \end{proof}

\section{Proof of Theorem \ref{theorem_fixed_point_reach}} \label{proof_theorem_fixed_point_reach}
\begin{proof}
According to Eq. (\ref{local_model_update_with_aggregated_gradient}) and mapping $\Gamma(\{\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i}(\boldsymbol{w_{i,l}^{t}})} \!\mid\! t \!\in\! \{0,1, \ldots, T\}, l \!\in\! \{0,1, \ldots, L\}\})$ in Eq. (\ref{mapping}), the local model update can be represented as $(\boldsymbol{w_{i,l+1}^{t}}, \nabla{F_{i}(\boldsymbol{w_{i,l+1}^{t}})}) \!=\! \Gamma_{l}^{t}(\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i}(\boldsymbol{w_{i,l}^{t}})})$. Then, we define the Complete Metric Space $\mathcal{X}$ for all model parameter pairs $(\boldsymbol{w}, \nabla{F(\boldsymbol{w}}))$ and the distance function $\Phi$ in the metric space to measure the difference between two parameter pairs can be defined as the $\ell_{2}$ norm, i.e.,
\begin{align} \label{distance}
\Phi = \sqrt{\|\boldsymbol{w_{i}}-\boldsymbol{w_{j}}\|^{2} + \|\nabla{F(\boldsymbol{w_{i}}}) - \nabla{F(\boldsymbol{w_{j}}})\|^{2}}.
\end{align}

Based on Eq. (\ref{local_model_update_with_aggregated_gradient}) and Eq. (\ref{distance}), we have the following derivations:
\begin{align}
&\Phi(\Gamma_{l}^{t}(\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i}(\boldsymbol{w_{i,l}^{t}})}), \Gamma_{l}^{t}(\boldsymbol{w_{j,l}^{t}}, \nabla{F_{j}(\boldsymbol{w_{j,l}^{t}})})) \nonumber \\
& = \sqrt{\|\boldsymbol{w_{i,l+1}^{t}}-\boldsymbol{w_{j,l+1}^{t}}\|^{2} + \|\nabla{F_{i}(\boldsymbol{w_{i,l+1}^{t}})} - \nabla{F_{j}(\boldsymbol{w_{j,l+1}^{t}})}\|^{2}} \nonumber \\
& \leq \sqrt{(\beta^{2}+1)\|\boldsymbol{w_{i,l+1}^{t}}-\boldsymbol{w_{j,l+1}^{t}}\|^{2}} \nonumber \\
& \leq  \small \sqrt{\frac{(\beta^{2} \!+\!1)\delta_{h}}{N}\|(\boldsymbol{w_{i,l}^{t}} \!-\! \boldsymbol{w_{j,l}^{t}}) \!-\! (\frac{\eta_{i,l}^{t}}{N} \!\! \sum_{i=1}^{N} \!\! \nabla{F_{i}(\boldsymbol{w_{i,l}^{t})}} \!-\!\frac{\eta_{j,l}^{t}}{N} \!\! \sum_{j=1}^{N} \!\! \nabla{F_{j}(\boldsymbol{w_{j,l}^{t})}})\|^{2}} \nonumber \\
& \leq \sqrt{\frac{(\beta^{2} \!+\!1)\delta_{h}}{N}} \sqrt{\|\boldsymbol{w_{i,l}^{t}} \!-\! \boldsymbol{w_{j,l}^{t}}\|^{2} \!+\! \|\nabla{F_{i}(\boldsymbol{w_{i,l+1}^{t}})} \!-\! \nabla{F_{j}(\boldsymbol{w_{j,l+1}^{t}})}\|^{2}}. \nonumber \\
& = \sqrt{\frac{(\beta^{2} \!+\!1)\delta_{h}}{N}} \Phi((\boldsymbol{w_{i,l}^{t}}, \nabla{F_{i}(\boldsymbol{w_{i,l}^{t}})}), (\boldsymbol{w_{j,l}^{t}}, \nabla{F_{j}(\boldsymbol{w_{j,l}^{t}})})),
\end{align}
where the constant $\sqrt{\frac{(\beta^{2} \!+\!1)\delta_{h}}{N}}$ is selected such that $0 \!\leq\! \sqrt{\frac{(\beta^{2} \!+\!1)\delta_{h}}{N}} \!<\! 1$, thereby ensures that mapping $\Gamma_{l}^{t}$ operates as a contraction mapping. In light of Banach's Fixed Point Theorem, this guarantees the existence of a unique fixed point, denoted as $(\omega_{i,l}^{t*}, \nabla{F_{i}(\omega_{i,l}^{t*})})$, for the iterative computation process. Further, following the inherent contraction property of $\Gamma_{l}^{t}$, which dictates that each subsequent application of $\Gamma_{l}^{t}$ diminishes the distance between consecutive points in the sequence by a factor of $\sqrt{(\beta^{2} \!+\!1)\delta_{h}/N}$. Consequently, for any given positive $\xi$, there exists a positive integer $C$ such that for all $u$, $v \!>\! C$ satisfies: 
\begin{align}
\Phi(\Gamma_{l}^{t}(\boldsymbol{w_{i,u}^{t}}, \nabla{F_{i}(\boldsymbol{w_{i,u}^{t}})}), \Gamma_{l}^{t}(\boldsymbol{w_{i,v}^{t}}, \nabla{F_{i}(\boldsymbol{w_{i,v}^{t}})})) < \xi,
\end{align}
which elucidates that the sequence generated by $\Gamma_{l}^{t}$ is rigorously established as a Cauchy sequence. Drawing upon the foundational tenets of Complete Metric Spaces, it is unambiguously deduced that the sequence converges to the unique fixed point $(\omega_{i,l}^{t*}, \nabla{F_{i}(\omega_{i,l}^{t*})})$. Consequently, the theorem holds. \end{proof}

\section{Proof of Proposition \ref{proposition_learning_rate_bound}}\label{proof_of_proposition_learning_rate_bound}
\begin{proof} 
Before formal derivation, there are some prepositive lemma and corollary that need to be proved to facilitate the demonstration of Proposition \ref{proposition_learning_rate_bound}. Then, according to the properties of matrix norm and Definition \ref{definition_mean_field_terms}, we have the following lemmas:

\begin{lemma} \label{lemma 4}
$\|\boldsymbol{\phi_{1,l}^{t}}\| \leq P$ and $\|\boldsymbol{\phi_{2,l}^{t}}\| \leq Q$.
\end{lemma}
\begin{proof} From Assumption \ref{bounded_Gradients} and Lemma \ref{lemma_bounded_parameter}, we have:
\begin{align}
\|\boldsymbol{\phi_{1,l}^{t}}\| &= \frac{1}{N} \textstyle \|\sum_{i=1}^{N} \nabla{F_{i} (\boldsymbol{w_{i,l}^{t}})}\| \nonumber \\
&= \frac{1}{N}\|\nabla{F_{1}(\boldsymbol{w_{1,l}^{t}})}+\nabla{F_{2} (\boldsymbol{w_{2,l}^{t}})}+\ldots+\nabla{F_{N}(\boldsymbol{w_{N,l}^{t}})}\| \nonumber \\
&\stackrel{(a)}{\leq} \frac{1}{N} (\|\nabla{F_{1}(\boldsymbol{w_{1,l}^{t}})}\|
+\ldots+\|\nabla{F_{N}(\boldsymbol{w_{N,l}^{t}})}\|) \leq P,  \\
\|\boldsymbol{\phi_{2,l}^{t}}\| &= \frac{1}{N} \textstyle \|\sum_{i=1}^{N} \boldsymbol{w_{i,l}^{t}}\| = \dfrac{1}{N}\|\boldsymbol{w_{1,l}^{t}}+\boldsymbol{w_{2,l}^{t}} +\ldots+\boldsymbol{w_{N,l}^{t}}\| \nonumber \\
&\stackrel{(a)}{\leq} \frac{1}{N} (\|\boldsymbol{w_{1,l}^{t}}\|+ \|\boldsymbol{w_{2,l}^{t}}\|+\ldots +\|\boldsymbol{w_{N,l}^{t}}\|) \leq Q, 
\end{align}
where inequation (a) follows from the triangle inequality.
\end{proof}

Based on Lemma \ref{lemma 4} and the property of matrix, we can easily get the following corollary.
\begin{corollary} \label{corollary}
$\|(\boldsymbol{\phi_{1,l}^{t}})^\top\| \leq P$.
\end{corollary}

Similar to the approach of proving Proposition \ref{proposition_lr_linear_combination} and Proposition \ref{proposition_client_drifting}, we adopt Inductive Reasoning to prove Theorem \ref{proposition_learning_rate_bound} based on Lemma \ref{lemma 4} and Corollary \ref{corollary}. 

Firstly, we prove $\eta_{i, L-1}^{t}$ has an upper bound smaller than 1. Define $\|\boldsymbol{w_{i,l}^{t}}-\boldsymbol{\phi_{2,l}^{t}}\| \leq U $, we have:
% \begin{figure*}[t]
% \hrulefill
% \begin{align} 
% \eta_{i,L-1}^{t} &= \frac{1-\alpha}{\alpha}\cdot\frac{(\boldsymbol{\phi_{1,L-1}^{t}})^{T}(\boldsymbol{w_{i,L-1}^{t}}-\boldsymbol{\phi_{2,L}^{t}})}{1+\frac{1-\alpha}{\alpha}( \boldsymbol{\phi_{1,L-1}^{t}})^{T} \boldsymbol{\phi_{1,L-1}^{t}}} \nonumber \\
% &\leq \frac{1-\alpha}{\alpha}\cdot\frac{PU}{1+\frac{1-\alpha}{\alpha}( \boldsymbol{\phi_{1,L-1}^{t}})^{T} \boldsymbol{\phi_{1,L-1}^{t}}} \nonumber \\
% \Rightarrow \  \eta_{i,L-1}^{t} &\leq \frac{1-\alpha}{\alpha}\cdot\frac{PU}{1+\frac{1-\alpha}{\alpha}P^{2}} = \delta_{i,L-1}^{t} < 1. 
% \end{align}
% \end{figure*}
\begin{align} \label{eta_L_minus_1_less_1}
\eta_{i,L-1}^{t} &= \frac{1-\alpha}{\alpha}\cdot\frac{(\boldsymbol{\phi_{1,L-1}^{t}})^\top(\boldsymbol{w_{i,L-1}^{t}}-\boldsymbol{\phi_{2,L}^{t}})}{1+\frac{1-\alpha}{\alpha}( \boldsymbol{\phi_{1,L-1}^{t}})^\top \boldsymbol{\phi_{1,L-1}^{t}}} \nonumber \\
&\leq \frac{1-\alpha}{\alpha}\cdot\frac{PU}{1+\frac{1-\alpha}{\alpha}( \boldsymbol{\phi_{1,L-1}^{t}})^\top \boldsymbol{\phi_{1,L-1}^{t}}} \nonumber \\
\Rightarrow \  \eta_{i,L-1}^{t} &\leq \frac{1-\alpha}{\alpha}\cdot\frac{PU}{1+\frac{1-\alpha}{\alpha}P^{2}} = \delta_{i,L-1}^{t} < 1. 
\end{align}

Then, according to Eq. (\ref{eta_L_minus_2}) and Eq. (\ref{eta_L_minus_1_less_1}), we have:
\begin{align} \label{eta_L_minus_2_less_1}
\eta_{i,L-2}^{t} &= \frac{1}{2 \alpha}( \boldsymbol{\phi_{1,L-2}^{t}} )^\top \boldsymbol{\lambda(L-1)} \nonumber \\
&= \frac{1\!-\!\alpha}{\alpha}(\boldsymbol{\phi_{1,L-2}^{t}} )^\top (2 \boldsymbol{w_{i,L-1}^{t}} \!-\! \eta_{i,L-1}^{t}\boldsymbol{\phi_{1,L-1}^{t}}\!-\! \textstyle \sum_{k=L-1}^{L} \!\boldsymbol{\phi_{2,k}^{t}}) \nonumber \\
&\leq \frac{1-\alpha}{\alpha}P \mid 2Q-\|\eta_{i,L-1}^{t}\boldsymbol{\phi_{1,L-1}^{t}} \!+\! \textstyle \sum_{k=L-1}^{L} \boldsymbol{\phi_{2,k}^{t}}\| \mid \nonumber \\
\Rightarrow \  \eta_{i,L-2}^{t} &\leq \!\frac{1\!-\!\alpha}{\alpha}P \mid 2Q\!-\!\|\eta_{i,L-1}^{t}\boldsymbol{\phi_{1,L-1}^{t}}\|\!-\! \textstyle \sum_{k=L-1}^{L} \! \boldsymbol{\phi_{2,k}^{t}}\| \mid \nonumber \\
& \leq \frac{1-\alpha}{\alpha}(\alpha P U - \eta_{i,L-1}^{t} P^{2})^{2} = \delta_{i,L-2}^{t} < 1. 
\end{align}

Thus, based on the process of calculating the upper bound of $\eta_{i, L-1}^{t}$ and $\eta_{i, L-2}^{t}$, we can reasonably induce that all the terms in the expression of adaptive learning rate $\eta_{i,l}^{t}$ (Theorem \ref{theorem_optimal_lr}) is bounded, where $\eta_{i, L-1}^{t}$, $l \!\in\! \{l+1, l+2, \ldots, L-1\}$ can be calculated iteratively similar to $\eta_{i, L-2}^{t}$. In another word, for each $\eta_{i,l}^{t}$, there exist a corresponding upper bound $\delta_{i,l}^{t}$ smaller than 1, where $i \!\in\! \{1, 2, \ldots, N\}$, $l \!\in\! \{0, 1, \ldots, L-1\}$, $t \!\in\! \{0, 1, \ldots, T\}$. 
\end{proof}

\section{Proof of Proposition \ref{proposition_client_drifting}} \label{proof_of_proposition_client_drifting}
\begin{proof}
First, for any given client $i \in \{0, 1, \ldots, N\}$, according to Eq. (\ref{local_model_update_mean_field}), we have: 
\begin{align}
\|\boldsymbol{w_{i,l+1}^{t}}\!-\!\boldsymbol{\bar w^{t}}\| &= \|\boldsymbol{w_{i,l}^{t}}\!-\!\boldsymbol{\bar w^{t}} \!-\! \eta_{i,l}^{t}  \boldsymbol{\phi_{1,l}^{t}}\| \leq \|\boldsymbol{w_{i,l}^{t}}\!-\!\boldsymbol{\bar w^{t}}\| \!+\! \|\eta_{i,l}^{t}  \boldsymbol{\phi_{1,l}^{t}}\| \nonumber \\
&\leq \|\boldsymbol{w_{i,l}^{t}}\!-\!\boldsymbol{\bar w^{t}}\| \!+\! P \delta_{h}. 
\end{align}

Then, we proceed with a proof by Inductive Reasoning to establish the final result. The induction claim is as follows: $\|\boldsymbol{w_{i,l}^{t}} \!-\! \boldsymbol{\bar w^{t}}\| \!\leq\! l P \delta_{h}$, for all $l \!\in\! \{0, 1, \ldots, L-1\}$. First, we prove the base situation for $l = 0$ and $l = 1$. For $l = 0$, we have:
\begin{align}
\|\boldsymbol{w_{i,1}^{t}}-\boldsymbol{\bar w^{t}}\| &= \|\boldsymbol{w_{i,0}^{t}}-\boldsymbol{\bar w^{t}} - \eta_{i,0}^{t}  \boldsymbol{\phi_{1,0}^{t}}\| \leq \|\boldsymbol{w_{i,0}^{t}}-\boldsymbol{\bar w^{t}}\| + \|\eta_{i,0}^{t}  \boldsymbol{\phi_{1,0}^{t}}\| \nonumber \\
&\leq \|\boldsymbol{w_{i,0}^{t}}-\boldsymbol{\bar w^{t}}\| + P \delta_{h} \leq P \delta_{h}, 
\end{align}
where $\boldsymbol{w_{i,0}^{t}}=\boldsymbol{\bar w^{t}}$, $i \in \{1, 2, \ldots, N\}$, same as the definition we mentioned in Section \ref{adaptive_learning_rate_in_FL}. Similarly, for $l = 1$, we have:
\begin{align} 
\|\boldsymbol{w_{i,2}^{t}} \!-\! \boldsymbol{\bar w^{t}}\| &\!=\!  \|\boldsymbol{w_{i,1}^{t}} \!-\! \boldsymbol{\bar w^{t}} \!-\! \eta_{i,1}^{t}  \boldsymbol{\phi_{1,1}^{t}}\| \!\leq\! \|\boldsymbol{w_{i,1}^{t}} \!-\! \boldsymbol{\bar w^{t}}\| \!+\! \|\eta_{i,1}^{t}  \boldsymbol{\phi_{1,1}^{t}}\| \nonumber \\
&\leq \|\boldsymbol{w_{i,1}^{t}} \!-\! \boldsymbol{\bar w^{t}}\| \!+\! U \delta_{h} \!\leq\! \|\boldsymbol{w_{i,0}^{t}} \!-\! \boldsymbol{\bar w^{t}}\| \!+\! 2 P \delta_{h} \!\leq\! 2 P \delta_{h}. 
\end{align}

Similar to the above analysis, for any $l \!>\! 1$, we have $\|\boldsymbol{w_{i,l}^{t}} \!-\! \boldsymbol{\bar w^{t}}\| \!\leq\! l P \delta_{h}$. As $l \!\in\! \{0, 1, \ldots, L-1\}$, we have the following derivation:
\begin{align}
\|\boldsymbol{w_{i,l}^{t}}-\boldsymbol{\bar w^{t}}\| \leq l P \delta_{h} \leq L P \delta_{h}. \nonumber
\end{align} 

Hence, the proposition holds. \end{proof}

\section{Proof of Theorem \ref{theorem_model_gap}} \label{proof_of_theorem_model_gap}
\begin{proof}
We first introduce the convexity and non-convexity assumptions for the following theorem proof.
\begin{assumption} \label{assumption_convexity}
[$\psi$-Strong Convexity] Global loss function $F(\boldsymbol{w})$ is $\psi$-strong convex with any $\boldsymbol{w}, \boldsymbol{w}^{\prime} \in \mathbb{R}^{d}$: 
\begin{align}
\frac{\psi}{2}\|\boldsymbol{w} - \boldsymbol{w^{*}}\|_{2}^{2} \leq F(\boldsymbol{w}) - F(\boldsymbol{w}^{*}). 
\end{align}
\end{assumption}

\begin{assumption} \label{assumption_subgradient}
[Subgradient for Non-Convexity] Global loss function $F(\boldsymbol{w})$ admits a unique subgradient $\small g \!\in\! \mathbb{R}^{d}$ for any model parameter vector $\boldsymbol{w}, \boldsymbol{w}^{\prime} \!\in\! \mathbb{R}^{d}$, it satisfies, 
\begin{align}
F(\boldsymbol{w}) - F(\boldsymbol{w}^{\prime}) \geq g^\top (\boldsymbol{w} - \boldsymbol{w}^{\prime}),
\end{align}
\end{assumption}

Then, we define the model aggregation weight $\theta_{i} \!=\! \frac{D_{i}}{\sum_{j=1}^{N} D_{j}}$. According to Eq. (\ref{fresh_local_update}), Eq. (\ref{local_model_aggregation}) can be rewritten as:
\begin{align} \label{global_model_update}
\boldsymbol{\bar w^{t+1}} &= \sum_{i=1}^{N} \theta_{i} \boldsymbol{w_{i,L}^{t}} =\boldsymbol{w_{i,0}^{t}}-\sum_{i=1}^{N}\sum_{k=0}^{L-1} \theta_{i}\eta_{i,k}^{t} \boldsymbol{\phi_{1,k}^{t}} \nonumber \\
&= \boldsymbol{\bar w^{t}}-\sum_{i=1}^{N}\sum_{k=0}^{L-1} \theta_{i}\eta_{i,k}^{t} \boldsymbol{\phi_{1,k}^{t}}. 
\end{align}

Based on Eq. (\ref{global_model_update}), the squared $\ell_{2}$-norm of the difference between the global and optimal model parameter is calculated as follows:
\begin{align} \label{parameter_gap}
&\|\boldsymbol{\bar w^{t+1}} - \boldsymbol{w^{*}}\|_{2}^{2} = \|\boldsymbol{\bar w^{t}} -  \boldsymbol{w^{*}}\|_{2}^{2} \nonumber \\
&+ \underbrace{\| \sum_{i=1}^{N}\sum_{k=0}^{L-1} \theta_{i}\eta_{i,k}^{t} \boldsymbol{\phi_{1,k}^{t}} \|_{2}^{2}}_{\Delta_{1}} \underbrace{- 2 \langle \boldsymbol{\bar w^{t}} - \boldsymbol{w^{*}}, \sum_{i=1}^{N}\sum_{k=0}^{L-1} \theta_{i}\eta_{i,k}^{t} \boldsymbol{\phi_{1,k}^{t}} \rangle}_{\Delta_{2}}.
\end{align}
The two terms on the right-hand side of the equality are bounded respectively. For term $\Delta_{1}$, taking the expectation on both sides of the equation, we have the following derivation:
\begin{align}
\mathbb{E}[\Delta_{1}] = \mathbb{E}[\| \sum_{i=1}^{N}\sum_{k=0}^{L-1} \theta_{i}\eta_{i,k}^{t} \boldsymbol{\phi_{1,k}^{t}} \|_{2}^{2}]  
&\stackrel{(a)}{\leq} \delta_{h}^{2} P^{2} \mathbb{E}[\| \sum_{i=1}^{N}\sum_{k=0}^{L-1} \theta_{i} \|_{2}^{2}] \nonumber \\
&\leq \delta_{h}^{2} P^{2} L^{2},
\end{align}
where (a) follows the upper bound of the mean-field term $\boldsymbol{\phi_{1,k}^{t}}$ in Lemma \ref{lemma 4}. Then, for the term $\Delta_{2}$, we have:
\begin{align}
\mathbb{E}[\Delta_{2}] &= \mathbb{E}[- 2 \langle \boldsymbol{\bar w^{t}} - \boldsymbol{w^{*}}, \sum_{i=1}^{N}\sum_{k=0}^{L-1} \theta_{i}\eta_{i,k}^{t} \boldsymbol{\phi_{1,k}^{t}} \rangle] \nonumber \\ 
&\leq - 2 \delta_{h}  \sum_{i=1}^{N}\theta_{i} \sum_{k=0}^{L-1} \mathbb{E} [\langle \boldsymbol{\bar w^{t}} - \boldsymbol{w^{*}}, \boldsymbol{\phi_{1,k}^{t}} \rangle] \nonumber \\
&\leq - \frac{2 \delta_{h}}{N}  \sum_{i=1}^{N}\theta_{i} \sum_{k=0}^{L-1} \sum_{j=1}^{N} \mathbb{E} [\langle \boldsymbol{\bar w^{t}} - \boldsymbol{w^{*}}, \nabla{F_{j} (\boldsymbol{w_{j,k}^{t}})} \rangle] \nonumber \\
&\stackrel{(a)}{\leq} - \frac{2 \delta_{h}}{N}  \sum_{i=1}^{N}\theta_{i} \sum_{k=0}^{L-1} (\mathbb{E}[F(\boldsymbol{\bar w^{t}}) - F(\boldsymbol{w^{*}})] - \frac{1}{2} \beta L^{2} P^{2} \delta_{h}^{2} N) \nonumber \\
&\leq - \frac{2 \delta_{h} L}{N} \mathbb{E}[F(\boldsymbol{\bar w^{t}}) - F(\boldsymbol{w^{*}})] + \beta P^{2} L^{3} \delta_{h}^{3},
\end{align}
where for (a), the inequality holds based on the following fact:
\begin{align}
&- \sum_{j=1}^{N} \langle \boldsymbol{\bar w^{t}} \!- \boldsymbol{w^{*}}, \nabla{F_{j} (\boldsymbol{w_{j,k}^{t}})} \rangle \nonumber \\[-2pt]
=  &- \sum_{j=1}^{N} (\langle \boldsymbol{\bar w^{t}} - \boldsymbol{w_{j,k}^{t}}, \nabla{F_{j} (\boldsymbol{w_{j,k}^{t}})} \rangle + \langle \boldsymbol{w_{j,k}^{t}} - \boldsymbol{w^{*}}, \nabla{F_{j} (\boldsymbol{w_{j,k}^{t}})} \rangle ) \nonumber \\
\leq &- \sum_{j=1}^{N} (F_{i}(\boldsymbol{\bar w^{t}}) \!-\! F_{i}(\boldsymbol{w_{j,k}^{t}}) \!-\! \frac{\beta}{2} \|\boldsymbol{w_{j,k}^{t}} \!\!- \boldsymbol{\bar w^{t}}\|^{2} \!+\! \langle \boldsymbol{w_{j,k}^{t}} \!- \boldsymbol{w^{*}}, \nabla{F_{j} (\boldsymbol{w_{j,k}^{t}})} \rangle) \nonumber \\
\leq &- \sum_{j=1}^{N} (F_{i}(\boldsymbol{\bar w^{t}}) \!-\! F_{i}(\boldsymbol{w_{j,k}^{t}}) \!+\! F_{i}(\boldsymbol{w_{j,k}^{t}}) \!-\! F_{i}(\boldsymbol{w^{*}})) \!+\! \sum_{j=1}^{N} \frac{\beta}{2} \|\boldsymbol{w_{j,k}^{t}} \!-\! \boldsymbol{\bar w^{t}}\|^{2} \nonumber \\
\leq &- (F(\boldsymbol{\bar w^{t}}) - F(\boldsymbol{w^{*}})) + \sum_{j=1}^{N} \frac{\beta}{2} \|\boldsymbol{w_{j,k}^{t}} - \boldsymbol{\bar w^{t}}\|^{2} \nonumber \\
\leq &- (F(\boldsymbol{\bar w^{t}}) - F(\boldsymbol{w^{*}})) + \frac{1}{2} \beta L^{2} P^{2} \delta_{h}^{2} N.
\end{align}
Thus, taking the expectation on both sides of Eq. (\ref{parameter_gap}) and combining the expected upper bound of $\mathbb{E}[\Delta_{1}]$ and $\mathbb{E}[\Delta_{2}]$, we obtain:
\begin{align} \label{parameter_gap_middle}
& \small \mathbb{E}[\|\boldsymbol{\bar w^{t+1}} - \boldsymbol{w^{*}}\|_{2}^{2}]  \nonumber \\
& \small \leq \mathbb{E}[\|\boldsymbol{\bar w^{t}} \!\!-\!  \boldsymbol{w^{*}}\|_{2}^{2}] \!-\! \frac{2 \delta_{h} L}{N} \mathbb{E}[F(\boldsymbol{\bar w^{t}}) \!-\! F(\boldsymbol{w^{*}})] \!+\! \beta P^{2} L^{3} \delta_{h}^{3} \!+\! \delta_{h}^{2} P^{2} L^{2}. \!
\end{align}

Convexity and non-convexity assumptions for the global loss function $F(\boldsymbol{w})$ will lead to different upper bounds. Under the convexity assumption, Eq. (\ref{parameter_gap_middle}) can be further derived as follows:
\begin{align} \label{parameter_gap_middle_convexity}
& \mathbb{E}[\|\boldsymbol{\bar w^{t+1}} - \boldsymbol{w^{*}}\|_{2}^{2}]  \nonumber \\
& \leq \mathbb{E}[\|\boldsymbol{\bar w^{t}} \!-  \boldsymbol{w^{*}}\|_{2}^{2}] \!-\! \frac{2 \delta_{h} L}{N} \mathbb{E}[F(\boldsymbol{\bar w^{t}}) \!-\! F(\boldsymbol{w^{*}})] + \beta P^{2} L^{3} \delta_{h}^{3} + \delta_{h}^{2} P^{2} L^{2} \nonumber \\
& \stackrel{(a)}{\leq} (1 - \frac{\delta_{h} L \psi}{N}) \mathbb{E}[\|\boldsymbol{\bar w^{t}} -  \boldsymbol{w^{*}}\|_{2}^{2}] + \beta P^{2} L^{3} \delta_{h}^{3} + \delta_{h}^{2} P^{2} L^{2},
\end{align}
where (a) follows the Assumption \ref{assumption_convexity}. Through iteratively aggregating both sides of the inequality Eq. (\ref{parameter_gap_middle_convexity}), we finalize the upper bound of the expected optimality gap after $T$-iteration global training:
\begin{align}
\mathbb{E}[\|\boldsymbol{\bar w^{T}} - \boldsymbol{w^{*}}\|_{2}^{2}] \leq& \ (1 - \frac{\delta_{h} L \psi}{N})^{T} \mathbb{E}[\|\boldsymbol{\bar w^{0}} -  \boldsymbol{w^{*}}\|_{2}^{2}] \nonumber \\
&+ \sum_{k=0}^{T-1} (1 - \frac{\delta_{h} L \psi}{N})^{k} (\beta P^{2} L^{3} \delta_{h}^{3} + \delta_{h}^{2} P^{2} L^{2}). \nonumber 
\end{align}
For the non-convexity assumption, we first introduce the following lemma to facilitate our theoretical analysis:
\begin{lemma}\label{lemma_gap}
Suppose the local loss function $F_{i}$ satisfies $\beta$-Lipschitz smoothness, for the global model $\boldsymbol{\bar w^{t}}$ at $t$-th iteration, it holds:
\begin{align}
\mathbb{E}[\|\boldsymbol{\bar w^{t}} - \boldsymbol{w^{*}}\|_{2}] \leq t L P \delta_{h}.
\end{align}
\end{lemma}
\begin{proof}
First, for any global iteration $t \in \{0, 1, \ldots, T\}$, according to Eq. (\ref{global_model_update}), we have:
\begin{align} \label{gap_middle}
\|\boldsymbol{\bar w^{t+1}} - \boldsymbol{w^{*}}\|_{2} &\leq \|\boldsymbol{\bar w^{t}} - \boldsymbol{w^{*}} - \sum_{i=1}^{N}\sum_{k=0}^{L-1} \theta_{i}\eta_{i,k}^{t} \boldsymbol{\phi_{1,k}^{t}}\|_{2} \nonumber \\
&\leq \|\boldsymbol{\bar w^{t}} - \boldsymbol{w^{*}}\|_{2} + \|\sum_{i=1}^{N}\sum_{k=0}^{L-1} \theta_{i}\eta_{i,k}^{t} \boldsymbol{\phi_{1,k}^{t}}\|_{2} \nonumber \\
&\leq \|\boldsymbol{\bar w^{t}} - \boldsymbol{w^{*}}\|_{2} + L P \delta_{h}.
\end{align}

By iteratively aggregating both sides of Eq. (\ref{gap_middle}), we have:
\begin{align} \label{gap}
\mathbb{E}[\|\boldsymbol{\bar w^{t}} - \boldsymbol{w^{*}}\|_{2}] &\leq t L P \delta_{h}. 
\end{align}

Hence, the lemma holds. \end{proof} 

Then, according to Lemma \ref{lemma_gap}, Eq. (\ref{parameter_gap_middle}) can be further simplified as follows:
\begin{align} \label{parameter_gap_middle_non_convexity}
& \mathbb{E}[\|\boldsymbol{\bar w^{t+1}} - \boldsymbol{w^{*}}\|_{2}^{2}]  \nonumber \\
& \leq \mathbb{E}[\|\boldsymbol{\bar w^{t}} \!-  \boldsymbol{w^{*}}\|_{2}^{2}] \!-\! \frac{2 \delta_{h} L}{N} \mathbb{E}[F(\boldsymbol{\bar w^{t}}) \!-\! F(\boldsymbol{w^{*}})] + \beta P^{2} L^{3} \delta_{h}^{3} + \delta_{h}^{2} P^{2} L^{2} \nonumber \\
&\stackrel{(a)}{\leq} \mathbb{E}[\|\boldsymbol{\bar w^{t}} \!-  \boldsymbol{w^{*}}\|_{2}^{2}] \!-\! \frac{2 \delta_{h} L \|g^\top\|_{2}}{N} \mathbb{E}[\|\boldsymbol{\bar w^{t}} - \boldsymbol{w^{*}}\|_{2}] + \beta P^{2} L^{3} \delta_{h}^{3} + \delta_{h}^{2} P^{2} L^{2} \nonumber \\
&\stackrel{(b)}{\leq} \mathbb{E}[\|\boldsymbol{\bar w^{t}} \!-  \boldsymbol{w^{*}}\|_{2}^{2}] \!-\! \frac{2 t P \delta_{h}^{2} L^{2} \|g^\top\|_{2}}{N} + \beta P^{2} L^{3} \delta_{h}^{3} + \delta_{h}^{2} P^{2} L^{2},
\end{align}
where (a) follows the Assumption \ref{assumption_subgradient} and (b) follows the Lemma \ref{lemma_gap}. Through iteratively aggregating both sides of the inequality Eq. (\ref{parameter_gap_middle_non_convexity}), we obtain the upper bound of the expected optimality gap after $T$-iteration global training:
\begin{align}
\mathbb{E}[\|\boldsymbol{\bar w^{T}} \!-\! \boldsymbol{w^{*}}\|_{2}^{2}] \!\leq\! \frac{T (T \!-\! 1) P \delta_{h}^{2} L^{2} \|g^\top\|_{2}}{N} + \beta P^{2} L^{3} \delta_{h}^{3} + \delta_{h}^{2} P^{2} L^{2}. \nonumber 
\end{align}

Hence, the theorem holds.  \end{proof}

\section{Proof of Theorem \ref{theorem_difference}}\label{proof_of_theorem_difference}
For theoretically analyzing our proposed federated learning algorithm (i.e., FedAgg), some standard Assumption and Lemmas concerned are stated as follows. we introduce mathematical Lemmas~\ref{lemma1}-\ref{lemma 3} \cite{bottou2018optimization, mitra2021achieving} to assist our convergence analysis.

\begin{lemma} \label{lemma1}
The global loss function $F(\boldsymbol{w})$ satifies $\beta$-Lipschitz smoothness, for any $\boldsymbol{w}$, $\boldsymbol{w}^{\prime} \!\in\! \mathbb{R}^{d}$, we have:
\begin{align}
F(\boldsymbol{w})\!-\!F(\boldsymbol{w}^{\prime}) \!\leq\! \nabla{F(\boldsymbol{w}^{\prime})}^\top(\boldsymbol{w}\!-\!\boldsymbol{w}^{\prime}) \!+\!\frac{\beta}{2} \|\boldsymbol{w}\!-\!\boldsymbol{w}^{\prime}\|_{2}^{2}.
\end{align}
\end{lemma}

\begin{lemma} \label{lemma 2}
Given any two vectors $\small x, y \! \in \! \mathbb{R}^{d}$, the following holds for any $\small \gamma \! > \! 0$: $\|x+y\|^{2} \leq(1+\gamma)\|x\|^{2}+(1+\frac{1}{\gamma})\|y\|^{2}$. 
\end{lemma}

\begin{lemma} \label{lemma 3}
Given $m$ vectors $x_{1}, x_{2}, \ldots, x_{m} \in \mathbb{R}^{d}$, according to the Jensen's inequality, we have: $\|\sum_{i=1}^{m} x_{i}\|^{2} \leq m \sum_{i=1}^{m}\|x_{i}\|^{2}$.
\end{lemma}
\begin{proof} 
From the $\beta$-Lipschitz smoothness of $F(\boldsymbol{w})$ in Assumption \ref{assumption 1} and Taylor expansion (Lemma \ref{lemma1}), we have:
\begin{align} 
& F(\boldsymbol{\bar w^{t+1}}) \!-\! F(\boldsymbol{\bar w^{t}}) \!\leq\!  \langle \boldsymbol{\bar w^{t+1}}\!-\!\boldsymbol{\bar w^{t}}, \nabla{F(\boldsymbol{\bar w^{t}}}) \rangle \!+\!\frac{\beta}{2} \|\boldsymbol{\bar w^{t+1}}\!-\!\boldsymbol{\bar w^{t}} \|^{2} \nonumber\\
&= \underbrace{ -\sum_{i=1}^{N}\sum_{k=0}^{L-1} \langle\theta_{i}\eta_{i,k}^{t} \boldsymbol{\phi_{1,k}^{t}}, \nabla{F(\boldsymbol{\bar w^{t}})} \rangle}_{\Omega_{1}} + \underbrace{ \frac{\beta}{2} \|\sum_{i=1}^{N}\sum_{k=0}^{L-1} \theta_{i}\eta_{i,k}^{t} \boldsymbol{\phi_{1,k}^{t}}\|^{2}}_{\Omega_{2}}. 
\end{align}
The two terms on the right-hand side of the inequality are bounded respectively. For the first term $\Omega_{1}$, we note that:
\begin{align} \label{Omega_1}
& \small  \Omega_{1} = -\sum_{i=1}^{N}\sum_{k=0}^{L-1} \langle\theta_{i}\eta_{i,k}^{t} \boldsymbol{\phi_{1,k}^{t}}, \nabla{F(\boldsymbol{\bar w^{t}})}\rangle \nonumber \\
& \small   =\! -  \langle \sum_{i=1}^{N}\!\sum_{k=0}^{L-1}\!\! \theta_{i}\eta_{i,k}^{t} (\boldsymbol{\phi_{1,k}^{t}}\!\!-\! \!\nabla{F_{i}(\boldsymbol{\bar w^{t}})})\!+\!\!\sum_{i=1}^{N}\!\sum_{k=0}^{L-1}\!\!\theta_{i}\eta_{i,k}^{t}\! \nabla{F_{i}(\boldsymbol{\bar w^{t}})}, \! \nabla{F(\boldsymbol{\bar w^{t}})}\! \rangle \nonumber\\
& \small  \leq -\delta_{l} \langle  \sum_{i=1}^{N}\!\sum_{k=0}^{L-1}\!\! \theta_{i} (\boldsymbol{\phi_{1,k}^{t}}\!\!-\!\!\nabla{F_{i}(\boldsymbol{\bar w^{t}})})\!+\!\!\sum_{i=1}^{N}\!\sum_{k=0}^{L-1}\!\theta_{i} \nabla{F_{i}(\boldsymbol{\bar w^{t}})}, \! \nabla{F(\boldsymbol{\bar w^{t}})}\! \rangle \nonumber \\
& \small  = -\delta_{l} \langle \sum_{i=1}^{N}\!\sum_{k=0}^{L-1}\!\theta_{i}(\boldsymbol{\phi_{1,k}^{t}}\!-\!\nabla{F_{i}(\boldsymbol{\bar w^{t}})})\!+\!L\nabla{F(\boldsymbol{\bar w^{t}})}, \nabla{F(\boldsymbol{\bar w^{t}})}\rangle \nonumber \\
&= \small  -\delta_{l} \langle  \sum_{i=1}^{N}\!\sum_{k=0}^{L-1}\! \theta_{i}(\boldsymbol{\phi_{1,k}^{t}}\!\!-\!\!\nabla{F_{i}(\boldsymbol{\bar w^{t}})}),\nabla{F(\boldsymbol{\bar w^{t}})}\!\rangle \!-\! \delta_{l} L \|\nabla{F(\boldsymbol{\bar w^{t}})}\|^{2} \nonumber\\
&\small  \stackrel{(b)}{\leq} \! \delta_{l} (\|\sum_{i=1}^{N}\! \sum_{k=0}^{L-1}\! \theta_{i}(\boldsymbol{\phi_{1,k}^{t}}\!-\!\nabla{F_{i}(\boldsymbol{\bar w^{t}})})\| \|\nabla{F(\boldsymbol{\bar w^{t}})}\| \!-\! L \|\nabla{F(\boldsymbol{\bar w^{t}})}\|^{2}) \nonumber\\
&\small  \stackrel{(a)}{\leq} \delta_{l}  (\sum_{i=1}^{N}\sum_{k=0}^{L-1}\theta_{i}\|\boldsymbol{\phi_{1,k}^{t}}\!-\!\nabla{F_{i}(\boldsymbol{\bar w^{t}})}\|\|\nabla{F(\boldsymbol{\bar w^{t}})}\| \!-\! L \|\nabla{F(\boldsymbol{\bar w^{t}})}\|^{2}) \nonumber\\
&\footnotesize  \stackrel{(a)}{\leq} \frac{\delta_{l}}{N}(\sum_{i=1}^{N}\sum_{k=0}^{L-1}\sum_{j=1}^{N}\theta_{i}\|\nabla{F_{j} (\boldsymbol{w_{j,k}^{t}})} \!-\! \nabla{F_{j}(\boldsymbol{\bar w^{t}})}\| \|\nabla{F(\boldsymbol{\bar w^{t}})}\|) \!-\! L \delta_{l} \|\nabla{F(\boldsymbol{\bar w^{t}})}\|^{2} \nonumber \\
&\footnotesize \stackrel{(c)}{\leq} \frac{\beta\delta_{l}}{N}(\sum_{i=1}^{N}\!\sum_{k=0}^{L-1}\!\sum_{j=1}^{N}\!\theta_{i}\|\boldsymbol{w_{j,k}^{t}}\!\!-\!\boldsymbol{\bar w^{t}}\|\|\nabla{F(\boldsymbol{\bar w^{t}})}\|)  \!-\! L \delta_{l} \|\nabla{F(\boldsymbol{\bar w^{t}})}\|^{2} \! \nonumber \\
&\footnotesize  \stackrel{(d)}{\leq} L^{2} P \beta \delta_{l}\delta_{h} \|\nabla \! F(\! \boldsymbol{\bar w^{t}} \!)\|  \!-\! L \delta_{l} \|\nabla \! F(\! \boldsymbol{\bar w^{t}} \!)\|^{2} \!\!\stackrel{(e)}{\leq}\!\! L^{2} P^{2} \beta \delta_{l}\delta_{h} \!-\! L \delta_{l} \|\nabla \! F(\! \boldsymbol{\bar w^{t}} \!)\|^{2}.
\end{align}
In the above steps, (a) follows from the triangle inequality, (b) follows from the Cauchy-Schwartz inequality, and (c) is a consequence of the $\beta$-Lipschitz smoothness for $F_{i}(\cdot)$ in Assumption \ref{assumption 1}, (d) follows from the bounded client drifting term as proved in Proposition \ref{proposition_client_drifting}, (e) is the consequence of the bounded gradient in Assumption \ref{bounded_Gradients}. Then, we bound the term $\Omega_{2}$ as follows:
\begin{align} \label{Omega_2}
&\small \Omega_{2} = \frac{\beta}{2}  \|\sum_{i=1}^{N} \sum_{k=0}^{L-1} \theta_{i}\eta_{i,k}^{t} \boldsymbol{\phi_{1,k}^{t}}\|^{2} \nonumber \\
& \small  = \frac{\beta\delta_{h}^{2}}{2}\|\sum_{i=1}^{N}\sum_{k=0}^{L-1} \theta_{i}(\boldsymbol{\phi_{1,k}^{t}} \!-\! \nabla{F_{i}(\boldsymbol{\bar w^{t}})}) \!+\! \sum_{i=1}^{N}\sum_{k=0}^{L-1}\theta_{i}\nabla{F_{i}(\boldsymbol{\bar w^{t}})}\|^{2} \nonumber \\
& \small  = \frac{\beta\delta_{h}^{2}}{2}\|\sum_{i=1}^{N}\sum_{k=0}^{L-1} \theta_{i}(\boldsymbol{\phi_{1,k}^{t}} \!-\! \nabla{F_{i}(\boldsymbol{\bar w^{t}})}) \!+\! L\nabla{F(\boldsymbol{\bar w^{t}})} \|^{2} \nonumber \\
&\small  \stackrel{(a)}{\leq} \beta\delta_{h}^{2} (\|\sum_{i=1}^{N}\!\sum_{k=0}^{L-1} \theta_{i}(\boldsymbol{\phi_{1,k}^{t}} \!-\! \nabla{F_{i}(\boldsymbol{\bar w^{t}})})\|^{2} \! + \! L^{2} \|\nabla{F(\boldsymbol{\bar w^{t}})} \|^{2}) \nonumber \\
&\small  \stackrel{(b)}{\leq} \beta\delta_{h}^{2}(N\sum_{i=1}^{N} \theta_{i}^{2} \|\sum_{k=0}^{L-1}(\boldsymbol{\phi_{1,k}^{t}} \!-\! \nabla{F_{i}(\boldsymbol{\bar w^{t}})})\|^{2} \!+\! L^{2} \|\nabla{F(\boldsymbol{\bar w^{t}})} \|^{2}) \nonumber \\
&\small  \stackrel{(b)}{\leq} \beta L \delta_{h}^{2} (N \sum_{i=1}^{N}\!\sum_{k=0}^{L-1}\! \theta_{i}^{2} \|\boldsymbol{\phi_{1,k}^{t}} \!-\! \nabla{F_{i}(\boldsymbol{\bar w^{t}})}\|^{2} \!+\! L \|\nabla{F(\boldsymbol{\bar w^{t}})} \|^{2}) \nonumber \\
&\small  \stackrel{(b)}{\leq} \beta L \delta_{h}^{2} (\sum_{i=1}^{N}\! \sum_{k=0}^{L-1}\!\sum_{j=1}^{N}\! \theta_{i}^{2}\|\nabla{F_{j} (\boldsymbol{w_{j,k}^{t}})} \!-\! \nabla{F_{j}(\boldsymbol{\bar w^{t}})}\|^{2} \!+\! L \|\nabla{F(\boldsymbol{\bar w^{t}})} \|^{2}) \nonumber \\
&\small \stackrel{(c)}{\leq} \beta L \delta_{h}^{2} (\sum_{i=1}^{N}\! \sum_{k=0}^{L-1}\!\sum_{j=1}^{N}\!\theta_{i}^{2} \beta \|\boldsymbol{w_{j,k}^{t}} \!-\! \boldsymbol{\bar w^{t}}\|^{2} \!+\!  L \|\nabla{F(\boldsymbol{\bar w^{t}})} \|^{2}) \nonumber \\
&\small  \stackrel{(d)}{\leq} \beta^{2} L^{4} N P^{2} \delta_{h}^{4} + \beta L^{2} \delta_{h}^{2} \|\nabla{F(\boldsymbol{\bar w^{t}})} \|^{2}.
\end{align}
In the above steps, (a) follows the Lemma \ref{lemma 2} with $\gamma = 1$, (b) follows the Lemma \ref{lemma 3}, and (c) is a consequence of the $\beta$-Lipschitz smoothness for $F_{i}(\cdot)$ in Assumption \ref{assumption 1}, (d) follows from the bounded client drifting term as proved in Proposition \ref{proposition_client_drifting}. Combining with the bound in Eq. (\ref{Omega_1}) and Eq. (\ref{Omega_2}) immediately leads to the Theorem \ref{theorem_difference}.
\end{proof}

\section{Proof of Theorem \ref{theorem_convergence_rate}} \label{proof_convergence_rate}
\begin{proof}
Based on the convergent upper bound of the global loss function with any two consecutive iterations $t$ and $t+1$ as shown in Theorem \ref{theorem_difference}, we have the following derivation:
\begin{align} \label{difference_PL_inequality}
&\small F(\boldsymbol{\bar w^{t+1}}) \!-\! F(\boldsymbol{\bar w^{t}}) \nonumber \\
&\small \leq  (\beta L^{2} \delta_{h}^{2} \!-\! L \delta_{l})\|\nabla \! F(\boldsymbol{\bar w^{t}})\|^{2} \!+\! L^{2} P^{2} \beta \delta_{l}\delta_{h} \!+\! \beta^{2} L^{4} N P^{2} \delta_{h}^{4} \nonumber \\
& \small \stackrel{(a)}{\leq} 2 \mu (\beta L^{2} \delta_{h}^{2} \!-\! L \delta_{l}) (F(\boldsymbol{\bar w^{t}}) \!-\! F(\boldsymbol{w^{*}})) \!+\! L^{2} P^{2} \beta \delta_{l}\delta_{h} \!+\! \beta^{2} L^{4} N P^{2} \delta_{h}^{4},
\end{align}
where (a) follows the Polyak-\L{}ojasiewicz inequality in Assumption \ref{PL_inequality}. Then, taking expectations and subtracting the optimal global loss function $F(\boldsymbol{w^{*}})$ on both sides of Eq. (\ref{difference_PL_inequality}), we have:
\begin{align} \label{difference_optimal_PL_inequality}
\small F(\boldsymbol{\bar w^{t+1}}) \!-\! F(\boldsymbol{w^{*}}) \leq& F(\boldsymbol{\bar w^{t}}) \!-\! F(\boldsymbol{w^{*}}) \!+\! 2 \mu (\beta L^{2} \delta_{h}^{2} \!-\! L \delta_{l}) (F(\boldsymbol{\bar w^{t}}) \!-\! F(\boldsymbol{w^{*}})) \nonumber \\
& \small + L^{2} P^{2} \beta \delta_{l}\delta_{h} \!+\! \beta^{2} L^{4} N P^{2} \delta_{h}^{4} \nonumber \\
\leq& \small (1 \!+\! 2 \mu (\beta L^{2} \delta_{h}^{2} \!-\! L \delta_{l}))(F(\boldsymbol{\bar w^{t}}) \!-\! F(\boldsymbol{w^{*}})) \nonumber \\
& \small + L^{2} P^{2} \beta \delta_{l}\delta_{h} \!+\! \beta^{2} L^{4} N P^{2} \delta_{h}^{4}.
\end{align}

Through iteratively aggregating Eq. (\ref{difference_optimal_PL_inequality}) at iteration $t \!\in\! \{0, 1,\ldots, \\ T \!-\! 1\}$, we can easily obtain the upper bound of the convergence rate of our proposed FedAgg algorithm as expressed in Eq. (\ref{convergence_rate}). \end{proof}

\section{Proof of Theorem \ref{theorem_convergence_error}} \label{proof_convergence_error}
\begin{proof}
Based on the convergent upper bound of the global loss function with any two consecutive iterations $t$ and $t+1$ as shown in Theorem \ref{theorem_difference}, Then, taking the total expectation on both sides and rearranging, we have the following derivation:
\begin{align} \label{gradient_l2_norm}
&\small \mathbb{E}[\! \|\nabla \! F(\! \boldsymbol{\bar w^{t}} \!)\|^{2} \!] \!\leq\! \frac{\mathbb{E}[\! F(\! \boldsymbol{\bar w^{t}} \!) \!] \!\!-\! \mathbb{E}[\! F(\! \boldsymbol{\bar w^{t+1}} \!) \!]}{L \delta_{l} \!-\!  \beta L^{2} \delta_{h}^{2}} \!+\! \frac{L P^{2} \beta \delta_{l}\delta_{h} \!+\! \beta^{2} L^{3} N P^{2} \delta_{h}^{4}}{\delta_{l} \!-\!  \beta L \delta_{h}^{2}}.
\end{align}

By iteratively adding both sides of the inequality in Eq. (\ref{gradient_l2_norm}) at global iteration $t \!\in\! \{0, 1,\ldots, T-1\}$, we can derive as follows:
\begin{align}
\small \sum_{t=0}^{T-1}\! \mathbb{E}[\|\nabla \! F(\boldsymbol{\bar w^{t}})\|^{2}]  & \small \!\leq\! \frac{F(\boldsymbol{\bar w^{0}}) \!-\! F(\boldsymbol{\bar w^{T}})}{L \delta_{l} \!-\!  \beta L^{2} \delta_{h}^{2}} \!+\! \frac{T(L P^{2} \! \beta \delta_{l}\delta_{h} \!+\! \beta^{2} \! L^{3} \! N P^{2} \! \delta_{h}^{4})}{\delta_{l} \!-\!  \beta L \delta_{h}^{2}} \nonumber \\
& \small \!\leq\! \frac{F(\boldsymbol{\bar w^{0}}) \!\!-\! F(\boldsymbol{w^{*}})}{L \delta_{l} \!-\!  \beta L^{2} \delta_{h}^{2}} \!+\! \frac{T(L P^{2} \! \beta \delta_{l}\delta_{h} \!+\! \beta^{2} \! L^{3} \! N P^{2} \! \delta_{h}^{4})}{\delta_{l} \!-\!  \beta L \delta_{h}^{2}} \nonumber \\
\small \Rightarrow \frac{1}{T} \!\! \sum_{t=0}^{T-1}\! \mathbb{E}[ \|\nabla \! F(\boldsymbol{\bar w^{t}})\|^{2}] & \small \!\leq\! \frac{F(\boldsymbol{\bar w^{0}}) \!\!-\! F(\boldsymbol{w^{*}})}{T (L \delta_{l} \!-\!  \beta L^{2} \! \delta_{h}^{2})} \!+\! \frac{L P^{2} \! \beta \delta_{l}\delta_{h} \!+\! \beta^{2} \! L^{3} \! N P^{2} \! \delta_{h}^{4}}{\delta_{l} \!-\! \beta L \delta_{h}^{2}}. \nonumber
\end{align}

Hence, the theorem holds. \end{proof}

\begin{figure*}[t]
\setlength{\abovecaptionskip}{0pt} 
    \centering
    \subfloat[IID]{
        \label{cifar100-IID}
        \includegraphics[width=0.32\textwidth, trim=50 20 140 40,clip]{Experiment/Distribution/Cifar100_IID_Distribution_N100.pdf}}
    \subfloat[Dir-0.6]{
        \label{cifar100-dir06}
        \includegraphics[width=0.32\textwidth, trim=50 20 140 40,clip]{Experiment/Distribution/Cifar10_Dir06_Distribution_N100.pdf}}
    \subfloat[Wasserstein Distance]{
        \label{cifar100-emd}
        \includegraphics[width=0.34\textwidth, trim=20 10 50 20,clip]{Experiment/Distribution/Cifar100_EMD_N100.pdf}}
\caption{The data distribution on Cifar100 dataset}
\label{dirichlet distribution on cifar100}
\vspace{-12pt}
\end{figure*}

\section{Detailed Experiment Setup} \label{detailed_experimental_setup}

\paragraph{Platform Setup}
Experiments are conducted on a workstation (CPU: Intel i7-8750H @2.20GHz; RAM: 8GB DDR4 2666 MHz; GPU: NVIDIA GeForce RTX 1060 with CUDA version 12.1; OS: Microsoft Windows 11 Professional with OS version 10.0.22000). The simulator is composed of three parts: (\romannumeral 1) The data partitioning part that partitions the datasets as IID and Non-IID distribution. In addition, we allocate local data to each participating client with the same data size. (\romannumeral 2) The model training part instantiates heterogeneous FL clients for local model training, aggregates, and updates the global model until reaching pre-fixed global training iteration or threshold. (\romannumeral 3) The estimator calculating part finds the fixed point for two mean-field terms $\boldsymbol{\phi_{1,l}^{t}}$ and $\boldsymbol{\phi_{2,l}^{t}}$. For all parts aforementioned, we utilize the PyTorch library \cite{paszke2019pytorch} with version 0.10.0, and the environment is built on Python 3.7.

\begin{table}[t]
\setlength{\abovecaptionskip}{0pt} 
\renewcommand\arraystretch{1.0}
\caption{Basic Information of Datasets}
\begin{center}
\resizebox{0.48\textwidth}{!}{\begin{tabular}{c|c|c|c|c}
\toprule[1pt]
\textbf{Datasets}&\textbf{Traing Sample Size}&\textbf{Test Sample Size}&\textbf{Class} &\textbf{Image Size}  \\ \cmidrule[0.5pt](l{1pt}r{0pt}){1-5}

MNIST & 60,000 & 10,000  & 10 & 1 $\times$ 28 $\times$ 28  \\ \cmidrule[0.5pt](l{1pt}r{0pt}){1-5}

Cifar10 & 50,000 & 10,000  & 10 & 3 $\times$ 32 $\times$ 32  \\ \cmidrule[0.5pt](l{1pt}r{0pt}){1-5}

EMNIST-L & 124,800 & 20,800  & 26 & 1 $\times$ 28 $\times$ 28  \\ \cmidrule[0.5pt](l{1pt}r{0pt}){1-5}

Cifar100 & 50,000 & 10,000  & 100 & 3 $\times$ 32 $\times$ 32  \\ 
\bottomrule[1pt]
\end{tabular}}
\label{basic_information_of_datasets}
\end{center}
\vspace{-16pt}
\end{table}

\paragraph{Datasets} 
We conduct our experiments on four typical and real-world datasets with different types and sorts (i.e. MNIST, EMNIST-L, Cifar10, and Cifar-100) to validate the performance of our proposed algorithm FedAgg. Specifically, (\romannumeral 1) MNIST dataset contains 70,000 gray-scale hand-written digit images in total which are divided into 60,000 images as a training set and 10,000 images as a test set. Besides, the images in the MNIST dataset are 28 $\times$ 28 pixels, with a total of 10 classes. (\romannumeral 2) EMNIST-L dataset contains 145,600 gray-scale hand-written letter images in total, which are divided into 124,800 images as a training set and 20,800 images as a test set. Furthermore, the EMNIST-L dataset comprises gray-scale hand-written letter images measuring 28 $\times$ 28 pixels, encompassing a total of 26 classes. (\romannumeral 3) Cifar-10 and Cifar-100 datasets are both composed of 60,000 RGB images, which are divided into 50,000 images as a training set and 10,000 images as a test set with images 32 $\times$ 32 pixels. For the Cifar10 dataset, 10 classes of images are contained, whereas the Cifar100 dataset consists of 100 classes, posing a significant challenge for model training. The basic information of the datasets we use is summarized in Table~\ref{basic_information_of_datasets}.

\paragraph{Data Partition}
We adopt two different data partition methods for datasets. (\romannumeral 1) Similar to \cite{mcmahan2017communication}, we leverage the pathological Non-IID partition method for the MNIST dataset. Initially, we arrange the data based on their digit labels, segmenting it into 200 shards, each containing 300 samples, and subsequently distributing two shards to each of the 100 clients, characterized by the fact that the majority of clients will possess examples from only two distinct digits. (\romannumeral 2) For the rest datasets, we utilize Dirichlet distribution \cite{hsu2019measuring} to partition datasets as Non-IID settings and vary the Dirichlet parameter $\sigma \! \in \! \{0.6, 1.0, \infty\}$ to validation the robustness of our proposed algorithm FedAgg. In Fig. \ref{dirichlet distribution on cifar100}, we display the heat map of the data distribution on Cifar100, where Fig. \ref{dirichlet distribution on cifar100}\subref{cifar100-IID} represents the labels distribution under IID setting and Fig. \ref{dirichlet distribution on cifar100}\subref{cifar100-dir06} shows the data distribution with Dirichlet parameter $\sigma \! = \! 0.6$. The color of the heat map is shallow under the IID distribution with a close amount of labels. For Non-IID distribution, the heat map is much deeper with a wider range of label quantity in the meantime, which indicates a higher level of data heterogeneity. Furthermore, to intuitively recognize the diversity among different Dirichlet parameters, we quantify the data distribution through Wasserstein distance inspired by \cite{jiao2020toward} with equation $\theta_{h}\!=\!\textstyle \sum_{j \in \mathcal{Y}}\|\mathbb{P}_{h}(y\!=\!j)\!-\!\mathbb{P}_{a}(y\!=\!j)\|$, as shown in Fig. \ref{dirichlet distribution on cifar100}\subref{cifar100-emd}.

\begin{table}[t]
\setlength{\abovecaptionskip}{1pt} 
\caption{Hyperparameter of all Datasets}
\renewcommand\arraystretch{1.0}
\begin{center}
\resizebox{0.48\textwidth}{!}{\begin{tabular}{c|c|c|c|c}
\toprule[1pt]
\parbox{3.2cm}{\centering\textbf{Datasets+Local Model}}&\parbox{2.0cm}{\centering\textbf{Learning Rate}}&\textbf{Batchsize}&\parbox{2.4cm}{\centering\textbf{Global Iteration}} &\parbox{1.7cm}{\centering\textbf{Local Epoch}}  \\ \cmidrule[0.5pt](l{1pt}r{0pt}){1-5}

\parbox{3.2cm}{\centering\textbf{MNIST+Linear}} & 0.01 & 32  & 30 & 3 \\ \cmidrule[0.5pt](l{1pt}r{0pt}){1-5}

\parbox{3.2cm}{\centering\textbf{MNIST+MNIST-CNN}} & 0.01 & 32  & 30 & 3 \\ \cmidrule[0.5pt](l{1pt}r{0pt}){1-5}

\parbox{3.2cm}{\centering\textbf{EMNIST-L+LeNet-5}} & 0.1 & 64  & 50 & 3 \\ \cmidrule[0.5pt](l{1pt}r{0pt}){1-5}

\parbox{3.2cm}{\centering\textbf{Cifar10+Cifar10-CNN}}& 0.1 & 32  & 100 & 3 \\ \cmidrule[0.5pt](l{1pt}r{0pt}){1-5}

\parbox{3.2cm}{\centering\textbf{Cifar100+VGG-11}}& 0.01 & 64  & 500 & 3 \\ 
\bottomrule[1pt]
\end{tabular}}
\label{hyperparameter}
\end{center}
\vspace{-16pt}
\end{table}

\paragraph{Baselines}
We compare our proposed algorithm FedAgg with the following approaches. FedAvg \cite{mcmahan2017communication} is introduced as the fundamental framework in the field of federated learning. FedAdam \cite{reddi2021adaptive} allocates an adaptive optimizer for the global server and a mini-batch SGD optimizer for the participating clients respectively, which averages the local gradient for adaptively updating the global model. FedProx \cite{li2020federated} introduces a regularization prox-term during the local model training process which provides robust convergence on heterogeneous systems. FedDyn \cite{durmus2021federated} proposes dynamic variants of the primal-dual regularizer to mitigate local inconsistencies for each client at each global iteration leading to efficient training.

\paragraph{Local Training Model Architecture} 
In our numerical experiments, we implement five different local models with various architectures for each real-world dataset. (\romannumeral 1) For the MNIST dataset, we first use a linear model with a fully connected layer of 784 input channels and 10 output channels which can be represented as MNIST-Linear. Besides, we also train a local model for the classification of hand-written digits in MNIST by using a convolutional neural network (CNN) and termed it MNIST-CNN. This CNN has two 5 $\times$ 5 convolution layers, with each layer followed by 2 $\times$ 2 max pooling convolution layers, two fully connected layers with 7 $\times$ 7 $\times$ 64 and 512 units, and a ReLU output layer with 10 units. (\romannumeral 2) For the EMNIST-L dataset, we utilize classic LeNet-5 as a federated learning local training model for the gray-scale hand-written letters classification task. LeNet-5 contains two 5 $\times$ 5 convolution layers, each of which is followed by a 2 $\times$ 2 max pooling layer, three fully connected layers with 5 $\times$ 5 $\times$ 32, 120 and 84 units, and two ReLU output layers with 26 units. (\romannumeral 3) As to Cifar10 dataset, another CNN is implemented, referred as Cifar10-CNN, which contains three 3 $\times$ 3 convolution layers, with each layer followed by 2 $\times$ 2 max pooling, two dropout layers to avoid overfitting, each of which is followed by a fully connected layer with 4 $\times$ 4 $\times$ 64 and 512 units respectively and a ReLU output layer with 10 units. (\romannumeral 4) We conduct numerical on the Cifar100 dataset with standard VGG-11, the same as the experiments of \cite{mcmahan2017communication, kundu2021hire} to achieve well training performance.



\paragraph{Hyperparameters Settings} 
For all datasets, we default local training epoch $L$ = 3 and weight parameter $\alpha$ = 0.1 for Eq. (\ref{local_model_aggregation}). Specifically, with regard to the MNIST dataset, we set learning rate $\eta$ = 0.01, global training iteration $T$ = 30, and the batch size is 32. For both EMNIST-L and Cifar10 datasets, we configure learning rate $\eta$ as 0.1, global training iteration as $T$ = 50 and $T$ = 100, and batch size as 64 and 32, respectively. Additionally, as to the Cifar100 dataset, we set learning rate $\eta$ = 0.01 and share the same batch size with EMNIST-L, in the meantime, global iteration $T$ is configured as 500. We summarize all parameter configurations for each real-world dataset in Table~\ref{hyperparameter}. Specifically, for FedAdam, we default $\beta_{1}$ = 0.9, $\beta_{2}$ = 0.99 and $\tau $ = 0.001, while for FedProx and FedDyn, we set $\mu$ = 0.01 and $\alpha$ = 0.01, respectively.

\end{document}
\endinput