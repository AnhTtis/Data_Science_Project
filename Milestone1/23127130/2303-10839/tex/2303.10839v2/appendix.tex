\begin{figure}[htbp]
  \centering
  % \vspace{-3.1cm}
  \includegraphics[width=1\linewidth]{mfh.pdf}
   \caption{ Implementation of MFH loss in Python and PyTorch. 
   }
   \label{fig:mf-info}
\end{figure}

\begin{figure}[htbp]
  \centering
  % \vspace{-3.1cm}
  \includegraphics[width=1\linewidth]{masked_random.pdf}
   \caption{ Implementation of masked random positive pair selection scheme when computing the hard relationship loss. 
   }
   \label{fig:random_mf}
 
\end{figure}


\section{Appendix}
In this material, we first provide the implementation of the MFH loss and more training details.
Then, we provide more results of quantitative comparisons with related strong baselines, as well as more ablation studies on the batch sizes. 
Finally, we show more qualitative comparisons between MXM-CLR and TriCoLo \cite{YueRuan2022TriCoLoTC}, and more qualitative results of MXM-CLR on Text2Shape \cite{chen2018text2shape} and Flickr30K \cite{PeterYoung2014FromID}. 


\subsection{More Technical Details}
\textbf{Implementation of MFH loss.}
We provide the code for the implementation of MFH loss in Figure \ref{fig:mf-info} and \ref{fig:random_mf}.

\begin{table}[tbp]
% \centering
\resizebox{1\columnwidth}{!}{
\setlength{\tabcolsep}{2.5pt}
\begin{tabular}{cccc}
\hline
\multirow{2}{*}{Hyper-parameters} & \multicolumn{3}{c}{Image encoder}                                                                                                                                                                      \\ \cline{2-4} 
                                  & RN101                                                            & ViT-B/32                                                         & ViT-B/16                                                         \\ \hline
Number of views                   & 6                                                                & 6                                                                & 6                                                                \\
Number of captions                & 5                                                                & 5                                                                & 5                                                                \\
Batch size                        & (420, 350)                                                       & (420, 350)                                                       & (420, 350)                                                       \\
Temperature                       & 0.03                                                             & 0.03                                                             & 0.03                                                             \\
Optimizer                         & Adam                                                             & Adam                                                             & Adam                                                             \\
Adam betas                        & (0.9, 0.999)                                                     & (0.9, 0.999)                                                     & (0.9, 0.999)                                                     \\
Adam eps                          & 0.0001                                                           & 0.0001                                                           & 0.0001                                                           \\
Learning rate                     & 1e-5                                                             & 1e-6                                                             & 1e-6                                                             \\
Weight decay                      & 0.01                                                             & 0.04                                                             & 0.04                                                             \\
Scheduler                          & Cosine                                                           & Cosine                                                           & Cosine                                                           \\
Max epoches                       & 10                                                               & 10                                                               & 10                                                               \\
Random seed                       & 2022                                                             & 2022                                                             & 2022                                                             \\
\hline
\end{tabular}
}
\caption{The detailed training parameters of MXM-CLR on Text2Shape dataset for $\langle$text, agg-image (shape)$\rangle$ retrieval tasks (Table 1 and Table 3 in main paper).
}
\label{para_1}
\vspace{-4pt}
\end{table}
\begin{table}[htbp]
\resizebox{1\columnwidth}{!}{
\setlength{\tabcolsep}{2.5pt}
\begin{tabular}{cccc}
\hline
\multirow{2}{*}{Hyper-parameters} & \multicolumn{3}{c}{Image encoder}                                                                                                                                                                      \\ \cline{2-4} 
                                  & RN101                                                            & ViT-B/32                                                         & ViT-B/16                                                         \\ \hline
Number of views                   & 6                                                                & 6                                                                & 6                                                                \\
Number of captions                & 5                                                                & 5                                                                & 5                                                                \\
Batch size                        & (420, 350)                                                       & (420, 350)                                                       & (420, 350)                                                       \\
Temperature                       & 0.03                                                             & 0.03                                                             & 0.03                                                             \\
Optimizer                         & Adam                                                             & Adam                                                             & Adam                                                             \\
Adam betas                        & (0.9, 0.999)                                                     & (0.9, 0.999)                                                     & (0.9, 0.999)                                                     \\
Adam eps                          & 0.0001                                                           & 0.0001                                                           & 0.0001                                                           \\
Learning rate                     & 1e-5                                                             & 1e-6                                                             & 1e-6                                                             \\
Weight decay                      & 0.01                                                             & 0.04                                                             & 0.04                                                             \\
Scheduler                          & Cosine                                                           & Cosine                                                           & Cosine                                                           \\
Max epoches                       & 10                                                               & 10                                                               & 10                                                               \\
Random seed                       & 2022                                                             & 2022                                                             & 2022                                                             \\
\hline
\end{tabular}
}
\caption{The detailed training parameters of MXM-CLR on Text2Shape dataset for $\langle$text, image$\rangle$ retrieval tasks (Table 2 Left in main paper).
}
\vspace{-4pt}
\label{para_2}
\end{table}

\begin{table}[htbp]
\resizebox{1\columnwidth}{!}{
\setlength{\tabcolsep}{2.5pt}
\begin{tabular}{cccc}
\hline
\multirow{2}{*}{Hyper-parameters} & \multicolumn{3}{c}{Image encoder}                                                                                                                                                                      \\ \cline{2-4} 
                                  & RN101                                                            & ViT-B/32                                                         & ViT-B/16                                                         \\ \hline
Number of views                   & 6                                                                & 6                                                                & 6                                                                \\
Number of captions                & 5                                                                & 5                                                                & 5                                                                \\
Batch size                        & (240, 200)                                                       & (240, 200)                                                       & (240, 200)                                                       \\
Temperature                       & 0.03                                                             & 0.03                                                             & 0.03                                                             \\
Optimizer                         & Adam                                                             & Adam                                                             & Adam                                                             \\
Adam betas                        & (0.9, 0.999)                                                     & (0.9, 0.999)                                                     & (0.9, 0.999)                                                     \\
Adam eps                          & 0.0001                                                           & 0.0001                                                           & 0.0001                                                           \\
Learning rate                     & 1e-5                                                             & 1e-6                                                             & 1e-6                                                             \\
Weight decay                      & 0.01                                                             & 0.04                                                             & 0.04                                                             \\
Scheduler                          & Cosine                                                           & Cosine                                                           & Cosine                                                           \\
Max epoches                       & 10                                                               & 10                                                               & 10                                                               \\
Random seed                       & 2022                                                             & 2022                                                             & 2022                                                             \\
\hline
\end{tabular}
}
\caption{The detailed training parameters of MXM-CLR on Text2Shape dataset for $\langle$agg-text, image$\rangle$ retrieval tasks (Table 4 in main paper).
}
\label{para_3}
\end{table}
\begin{table}[htbp]
\resizebox{1\columnwidth}{!}{
\setlength{\tabcolsep}{2.5pt}
\begin{tabular}{cccc}
\hline
\multirow{2}{*}{Hyper-parameters} & \multicolumn{3}{c}{Image encoder}                                                                                                                                                                      \\ \cline{2-4} 
                                  & RN101                                                            & ViT-B/32                                                         & ViT-B/16                                                         \\ \hline
Number of views                   & 1                                                                & 1                                                                & 1                                                                \\
Number of captions                & 5                                                                & 5                                                                & 5                                                                \\
Batch size                        & (80, 400)                                                        & (80, 400)                                                        & (80, 400)                                                      \\
Temperature                       & 0.03                                                             & 0.03                                                             & 0.03                                                             \\
Optimizer                         & Adam                                                             & Adam                                                             & Adam                                                             \\
Adam betas                        & (0.9, 0.999)                                                     & (0.9, 0.999)                                                     & (0.9, 0.999)                                                     \\
Adam eps                          & 0.0001                                                           & 0.0001                                                           & 0.0001                                                           \\
Learning rate                     & 1e-5                                                             & 1e-6                                                             & 1e-6                                                             \\
Weight decay                      & 0.01                                                             & 0.01                                                             & 0.01                                                             \\
Scheduler                          & Cosine                                                           & Cosine                                                           & Cosine                                                           \\
Max epoches                       & 10                                                               & 10                                                               & 10                                                               \\
Random seed                       & 2022                                                             & 2022                                                             & 2022                                                             \\
\hline
\end{tabular}
}
\caption{The detailed training parameters of MXM-CLR on Flickr30K dataset for $\langle$text, image$\rangle$ retrieval tasks  (Table 2 Right in main paper).
}
\label{para_4}
\end{table}



\textbf{More training details.}
The images from Text2Shape are rendered at $224\times224$ resolution.
All images of Text2Shape and Flickr30K are resized to $256\times256$ and transformed by conventional data augmentation techniques including random crop, random horizontal flip, random vertical flip and random rotation.
We use the Adam optimizer with momentum 0.9.
The initial learning rate is 1e-5 and updated by the cosine annealing scheduler.
In the main paper, we provide the training time of MXM-CLR for $\langle$text, image$\rangle$ and $\langle$text, agg-image (shape)$\rangle$ retrieval tasks on Text2Shape dataset.
For the $\langle$agg-text, image$\rangle$ retrieval task, it takes approximately 0.71 hours to train the MXM-CLR with ViT-B/16 \cite{AlexeyDosovitskiy2020AnII} image encoder and BERT text encoder \cite{JacobDevlin2018BERTPO}.
It can be found based on the pre-trained weights of the image and text encoders, the training of MXM-CLR, i.e., fine-tuning the pre-trained weights, is quite efficient.
The hyper-parameters for training MXM-CLR models for different tasks on Text2Shape and Flickr30K are provided in Table \ref{para_1}, \ref{para_2}, \ref{para_3} and \ref{para_4}.
For these experiments, we also set repetition time for masked random pair selection when computing the hard relationship loss as $p=10N_{Col}$.


\begin{table*}[]
\centering
\resizebox{2\columnwidth}{!}
{
\setlength{\tabcolsep}{3pt}
\begin{tabular}{cccccccccccllccccccccccll}
\hline
\multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}Loss \\ function\end{tabular}} & \multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}Image \\ Encoder\end{tabular}} & \multicolumn{11}{c}{Text2Shape}                                                                                                                          &  & \multicolumn{11}{c}{Flickr30K}                                                                                                                 \\ \cline{3-13} \cline{15-25} 
                                                                          &                                                                            & \multicolumn{3}{c}{Text$\Rightarrow$Image}                   &           & \multicolumn{3}{c}{Image$\Rightarrow$Text}                   &  & \multicolumn{3}{c}{Batch}           &  & \multicolumn{3}{c}{Text$\Rightarrow$Image}                   &  & \multicolumn{3}{c}{Image$\Rightarrow$Text}                  &  & \multicolumn{3}{c}{Batch}           \\ \cline{3-5} \cline{7-9} \cline{11-13} \cline{15-17} \cline{19-21} \cline{23-25} 
                                                                          &                                                                            & R@1            & R@5            & R@10           &           & R@1            & R@5            & R@10           &  & \multicolumn{3}{c}{(imgs,texts,GB)} &  & R@1            & R@5            & R@10           &  & R@1            & R@5            & R@10          &  & \multicolumn{3}{c}{(imgs,texts,GB)} \\ \cline{1-13} \cline{15-25} 
$\mathrm{CLIP_{Info+Soft}}$                                                                   & RN101                                                                      & 12.36          & 22.62          & 30.38          &           & 18.07          & 41.57          & 53.27          &  & \multicolumn{3}{c}{(420,420,49.16)} &  & 63.40          & 87.82          & 93.84          &  & 78.50           & 94.40           & 97.60          &  & \multicolumn{3}{c}{(400,400,44.04)} \\
Robust-XR \cite{andonian2022robust}                                                                  & RN101                                                                      & 12.56          & 23.41          & 31.12          &           & 18.07          & 41.57          & 53.27          &  & \multicolumn{3}{c}{(420,420,49.16)} &  & 64.04          & 87.84          & 93.00         &  & 80.30           & 94.30           & 97.20          &  & \multicolumn{3}{c}{(400,400,44.04)} \\
MXM-CLR                                                                & RN101                                                                      & \textbf{17.75} & \textbf{29.10} & \textbf{37.52} & \textbf{} & \textbf{27.27} & \textbf{54.50} & \textbf{66.91} &  & \multicolumn{3}{c}{(420,350,47.39)} &  & \textbf{66.60}          & \textbf{89.56} & \textbf{94.52} &  & \textbf{83.10}  & \textbf{96.80}  & \textbf{98.60} &  & \multicolumn{3}{c}{(80,400,20.69)}  \\ \cline{1-13} \cline{15-25}
$\mathrm{CLIP_{Info+Soft}}$                                                                      & ViT-B/16                                                                   & 16.04          & 27.95          & 36.38          &           & 23.45          & 48.25          & 60.20          &  & \multicolumn{3}{c}{(420,420,57.24)} &  & \textbf{79.80}          & \textbf{95.70}           & 97.80          &  & 92.90           & 98.90          & 99.60          &  & \multicolumn{3}{c}{(400,400,54.16)} \\
Robust-XR \cite{andonian2022robust}                                                                     & ViT-B/16                                                                   & 15.75          & 28.03          & 36.51          &           & 22.91          & 49.19          & 62.04          &  & \multicolumn{3}{c}{(420,420,57.24)} &  & 78.82          & 95.14           & 97.66          &  & 92.90           & 98.90          & 99.70          &  & \multicolumn{3}{c}{(400,400,54.16)} \\
% MXM-CLR                                                                 & ViT-B/16                                                                   & \textbf{16.77} & \textbf{28.52} & \textbf{36.96} &           & \textbf{24.27} & 50.68 & 63.20  &  & \multicolumn{3}{c}{(420,350,55.64)} &  & 79.18 & \textbf{95.76} & 97.86 &  & 93.00 & 99.00 & 99.80 &  & \multicolumn{3}{c}{(80,400,23.50)}  \\ 
MXM-CLR                                                                 & ViT-B/16                                                                   & \textbf{17.00} & \textbf{28.50} & \textbf{36.62} &           & \textbf{24.85} & \textbf{51.31} & \textbf{63.39}  &  & \multicolumn{3}{c}{(420,350,55.64)} &  & 79.20 & 95.66 & \textbf{97.86} &  & \textbf{93.80} & \textbf{99.10} & \textbf{99.90} &  & \multicolumn{3}{c}{(80,400,23.50)}  \\ \cline{1-13} \cline{15-25} 
$\mathrm{CLIP_{Info+Soft}}$                                                                      & ViT-B/32                                                                   & 15.12          & 27.27          & 35.00           &           & 21.30          & 46.24          & 58.41           &  & \multicolumn{3}{c}{(420,420,28.01)} &  & \textbf{73.62}          & 92.96          & 96.38           &  & 87.10           & 97.90          & 99.20          &  & \multicolumn{3}{c}{(400,400,24.07)} \\
Robust-XR \cite{andonian2022robust}                                                                       & ViT-B/32                                                                   & 15.06          & 26.89          & 35.12           &           & 21.67          & 46.98          & 59.14           &  & \multicolumn{3}{c}{(420,420,28.01)} &  & 73.18          & 92.54          & 96.22           &  & 86.90           & 97.40          & \textbf{99.40}          &  & \multicolumn{3}{c}{(400,400,24.07)} \\

MXM-CLR                                                                 & ViT-B/32                                                                   & \textbf{17.19} & \textbf{29.44} & \textbf{37.41}  &           & \textbf{24.51} & \textbf{51.16} & \textbf{63.67}  &  & \multicolumn{3}{c}{(420,350,26.82)} &  & 73.58  & \textbf{93.26} & \textbf{96.60}  &  & \textbf{88.00}  & \textbf{98.00} & 99.30 &  & \multicolumn{3}{c}{(80,400,17.07)}  \\ \hline
\end{tabular}}
\caption{
\wy{
Evaluation of MXM-CLR trained with different image encoders for $\langle$text, image$\rangle$ retrieval task.
With comparable memory cost on Text2Shape and much less memory cost on Flickr30K, MXM-CLR generally achieves superior performance than the baselines.
Note the $\mathrm{CLIP_{Info+Soft}}$ and Robust-XR \cite{andonian2022robust}  construct the batch with 1:1 ratio of images and texts and MXM-CLR performs the group-wise pairing which utilizes all available observations for the same instance, i.e., the image:text ratio is 6:5 for Text2Shape and 1:5 for Flickr.
}
}

\label{tab_6}
\vspace{-12pt}
\end{table*}

\subsection{More Quantitative Results}

\wy{\textbf{More comparison with strong baselines.}
To further demonstrate the performance of our method, we perform more experiments to compare two strong CLIP baseline models which consider soft relationships for the data pairs. As shown in Table \ref{tab_6}, \ref{tab_7} and \ref{tab_8}, MXM-CLR outperforms $\mathrm{CLIP_{Info+Soft}}$ and Robust-XR \cite{andonian2022robust} in most tasks, demonstrating its superior performance on more comprehensive representation learning.
}

% \subsection{Quantitative Results}
% \textbf{Do larger batch in MXM-CLR help?}


\begin{table}[!t]
\centering
\resizebox{1\columnwidth}{!}{
\setlength{\tabcolsep}{1.8pt}
\begin{tabular}{cccccccccccll}
\hline
\multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}Loss \\ function\end{tabular}} & \multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}Image \\ Encoder\end{tabular}} & \multicolumn{11}{c}{Text2Shape}                                                                                                                                                                                                                                                  \\ \cline{3-13} 
                                                                          &                                                                            & \multicolumn{3}{c}{Text $\Rightarrow$ Agg-Image}                                                              &                      & \multicolumn{3}{c}{Agg-Image$\Rightarrow$ Text}                                                                        &  & \multicolumn{3}{c}{Batch}           \\ \cline{3-5} \cline{7-9} \cline{11-13} 
                                                                          &                                                                            & R@1                               & R@5                               & R@10                      &                      & R@1                                & R@5                                & R@10                               &  & \multicolumn{3}{c}{(imgs,texts,GB)} \\ \hline
$\mathrm{CLIP_{Info+Soft}}$                                                                    & RN101                                                                      & 10.03                             & 27.34                             & 38.15            &                      & 12.86                              & 35.38                              & 47.18                              &  & \multicolumn{3}{c}{(600,100,55.89)} \\
Robust-XR \cite{andonian2022robust}                                                                     & RN101                                                                      & 15.35                             & 37.79                             & 49.95            &                      & \textbf{27.07}                              & 54.35                              & \textbf{67.90 }                             &  & \multicolumn{3}{c}{(600,100,55.89)} \\

MXM-CLR                                                               & RN101                                                                      & \multicolumn{1}{l}{\textbf{15.84}} & \multicolumn{1}{l}{\textbf{38.41}} & \multicolumn{1}{l}{\textbf{50.54}} & \multicolumn{1}{l}{} & \multicolumn{1}{l}{26.47} & \multicolumn{1}{l}{\textbf{56.10}} & \multicolumn{1}{l}{\textbf{67.90}} &  & \multicolumn{3}{c}{(420,350,47.39)} \\ \hline
$\mathrm{CLIP_{Info+Soft}}$                                                                    & ViT-B/16                                                                   & 15.22                              & 36.02                             & 47.38                     &                      & 24.46                              & 50.67                              & 62.20                              &  & \multicolumn{3}{c}{(600,100,66.27)} \\

Robust-XR \cite{andonian2022robust}                                                                     & ViT-B/16                                                                   & 14.08                              & 35.52                             & 47.20                     &                       & 25.07                              & 53.28                             & 65.15                              &  & \multicolumn{3}{c}{(600,100,66.27)} \\

MXM-CLR                                                               & ViT-B/16                                                                   & \textbf{16.83}                       & \textbf{39.06}                    & \textbf{51.44}            &                      & \textbf{27.48}                     & \textbf{56.03}                     & \textbf{68.23}                     &  & \multicolumn{3}{c}{(420,350,55.64)} \\ \hline
$\mathrm{CLIP_{Info+Soft}}$                                                                    & ViT-B/32                                                                   & 13.94                             & 34.00                              & 46.08                      &                      & 24.19                               & 49.53                              & 61.80                              &  & \multicolumn{3}{c}{(600,100,25.25)} \\
Robust-XR \cite{andonian2022robust}                                                                     & ViT-B/32                                                                   &  14.12                            & 34.56                              &    46.87                    &                      &  22.38                             & 48.79                              & 60.25                              &  & \multicolumn{3}{c}{(600,100,25.25)} \\
MXM-CLR                                                               & ViT-B/32                                                                   & \textbf{16.24}                    & \textbf{37.78}                    & \textbf{49.37}            &                      & \textbf{26.41}                     & \textbf{54.76 }                   & \textbf{66.02}                     &  & \multicolumn{3}{c}{(420,350,26.82)} \\ \hline

\end{tabular}
}
\caption{
\wy{Evaluation of MXM-CLR for $\langle$text, agg-image (shape)$\rangle$ retrieval task. Since six images are aggregated into one shape feature for this task, the input ratio for image-text is 6:1 for  $\mathrm{CLIP_{Info+Soft}}$ and Robust-XR \cite{andonian2022robust} .
For MXM-CLR, it computes 70 aggregated shape features from the 420 input images and pairs the 70 shapes with the 350 texts via group-wise pairing.}
}

\label{tab_7}
\vspace{-11pt}
\end{table}


\begin{table}[!t]
% \centering
\resizebox{1\columnwidth}{!}{
\setlength{\tabcolsep}{1.6pt}
\begin{tabular}{cccccccccccll}
\hline
\multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}Loss \\ function\end{tabular}} & \multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}Vision \\ Encoder\end{tabular}} & \multicolumn{11}{c}{Text2Shape}                                                                                                                            \\ \cline{3-13} 
                                                                          &                                                                            & \multicolumn{3}{c}{Agg-Text $\Rightarrow$ Image} &           & \multicolumn{3}{c}{Image  $\Rightarrow$ Agg-Text} &  & \multicolumn{3}{c}{Batch}            \\ \cline{3-5} \cline{7-9} \cline{11-13} 
                                                                          &                                                                            & R@1            & R@5            & R@10           &           & R@1             & R@5            & R@10           &  & \multicolumn{3}{c}{(imgs,texts,GB)}  \\ \hline
$\mathrm{CLIP_{Info+Soft}}$                                                                    & RN101                                                                      & 23.59          & 41.35          & 52.74          &           & 18.57           & 44.31          & 58.02          &  & \multicolumn{3}{c}{(256,1280,54.46)} \\
Robust-XR \cite{andonian2022robust}                                                                     & RN101                                                                      & 29.56          & 48.73          & 59.05          &           & 19.83           & 48.79          & 62.48          &  & \multicolumn{3}{c}{(256,1280,54.46)} \\
MXM-CLR                                                               & RN101                                                                      & \textbf{36.33} & \textbf{56.77} & \textbf{67.29} & \textbf{} & \textbf{24.69}   & \textbf{54.67} & \textbf{68.49} &  & \multicolumn{3}{c}{(240,200,27.59)}  \\ \hline
$\mathrm{CLIP_{Info+Soft}}$                                                                        & ViT-B/16                                                                   & 37.66           & 58.44          & 69.77          &           & \textbf{28.20}           & \textbf{59.53}         & 72.26          &  & \multicolumn{3}{c}{(256,1280,62.48)} \\
Robust-XR \cite{andonian2022robust}                                                                & ViT-B/16                                                                   & 39.14 & 58.71 & 69.03 &           & 28.05  & 57.94 & 70.63 &  & \multicolumn{3}{c}{(240,200,32.53)}  \\ 
MXM-CLR                                                               & ViT-B/16                                                                   & \textbf{40.28} & \textbf{59.99} & \textbf{71.31} &           & 28.14  & 59.37 & \textbf{72.54} &  & \multicolumn{3}{c}{(240,200,32.53)}  \\ \hline
$\mathrm{CLIP_{Info+Soft}}$                                                                        & ViT-B/32                                                                   & 36.93          & 57.03          & 67.29          &           & 25.63           & 54.41          & 67.88          &  & \multicolumn{3}{c}{(256,1280,42.02)} \\
Robust-XR \cite{andonian2022robust}                                                                & ViT-B/32                                                                   & 35.45 & 55.50 & 65.82 &           & 26.20  & 53.88 & 67.32 &  & \multicolumn{3}{c}{(240,200,15.85)}  \\ 
MXM-CLR                                                               & ViT-B/32                                                                   & \textbf{39.95} & \textbf{59.05} & \textbf{68.36} &           & \textbf{27.49}  & \textbf{56.76} & \textbf{70.05} &  & \multicolumn{3}{c}{(240,200,15.85)}  \\ \hline
\end{tabular}
}
\caption{
\wy{
Evaluation of MXM-CLR for  $\langle$agg-text, image$\rangle$ retrieval task. Since five texts are aggregated into one comprehensive text feature for this task, the input ratio for image-text is 1:5 for  $\mathrm{CLIP_{Info+Soft}}$ and Robust-XR \cite{andonian2022robust} .
For MXM-CLR, it computes 40 aggregated text features from the 200 input texts and pairs the 40 aggregated texts with the 240 images via group-wise pairing.
}
}
\label{tab_8}
\vspace{-11pt}
\end{table}


\begin{table}[]
% \centering
\resizebox{1\columnwidth}{!}{
\setlength{\tabcolsep}{1.8pt}
\begin{tabular}{ccccccccccc}
\hline
\multicolumn{3}{c}{Batch}                                            &  & \multicolumn{7}{c}{Flickr30K}                                                                         \\ \hline
\multirow{2}{*}{image} & \multirow{2}{*}{text} & \multirow{2}{*}{GB} &  & \multicolumn{3}{c}{Text $\Rightarrow$ Image}     &  & \multicolumn{3}{c}{Image $\Rightarrow$ Text}     \\ \cline{5-7} \cline{9-11} 
                       &                       &                     &  & R@1            & R@5            & R@10           &  & R@1            & R@5            & R@10           \\ \cline{1-3} \cline{5-11} 
20                     & 100                   & 8.01                &  & 63.16          & 89.18          & 94.22          &  & 80.60          & 95.30          & 98.40          \\
30                     & 150                   & 9.99                &  & 63.34          & 89.20          & 94.64          &  & 80.40          & 95.40          & 97.90          \\
40                     & 200                   & 11.83               &  & 64.94          & 89.38          & 94.86          &  & 81.40          & 96.00          & 98.50          \\
50                     & 250                   & 13.50               &  & 65.04          & 89.18          & 94.52          &  & 81.30          & 96.10          & 97.70          \\
60                     & 300                   & 15.35               &  & 65.92          & 89.42          & 94.44          &  & 82.60          & 96.00          & 98.90          \\
80                     & 400                   & 19.08               &  & 66.60          & 89.56          & 94.52          &  & 83.10          & 96.80          & 98.60          \\ \hline
100                    & 500                   & 22.53               &  & 67.00          & 89.94          & 94.98          &  & 82.80          & 96.50          & 98.70          \\
150                    & 750                   & 32.85               &  & 67.16          & 90.30          & \textbf{95.02} &  & 83.30          & 96.40          & 98.50          \\
200                    & 1000                  & 42.34               &  & \textbf{68.98} & \textbf{90.56} & 94.70          &  & \textbf{86.40} & \textbf{97.40} & \textbf{99.00} \\ \hline
\end{tabular}
}
\caption{ Evaluation on larger batch sizes of MXM-CLR for $\langle$ text, image $\rangle$ retrieval tasks on Flickr30K. ResNet101 is adopted as the image encoder for this experiment.
The results above the horizontal line have been reported in Figure 7 of the main paper.
}
\label{tab_large_batch}
\end{table}
\textbf{More evaluations on batch sizes in MXM-CLR.}
We perform additional experiments on Flickr30K by training MXM-CLR with larger batch size settings. 
From Table \ref{tab_large_batch}, as expected, MXM-CLR can generally achieve increasing performance as the batch size increases.
Note that we only compare the results for batch size up to (200,1000) image-text pairs due to the limit of our GPU resources.
Whether the performance could be further improved by larger batch sizes is worth investigating in the future.


\subsection{More Qualitative Results}

\textbf{More results on Text2Shape dataset.} 
In Figure \ref{fig:fig_compare}, we show more comparisons on retrieval results of MXM-CLR and TriCoLo (I)\cite{YueRuan2022TriCoLoTC} on Text2Shape dataset \cite{chen2018text2shape}. 
MXM-CLR is able to achieve more fine-grained retrieval compared to TriCoLo, due to its better learned cross-model representations. 
Furthermore, we provide more results of MXM-CLR on $\langle$text, shape$\rangle$ retrieval tasks in Figure \ref{fig:t2i} and \ref{fig:i2t}.


\textbf{More results on Flickr30K dataset.}
Figure \ref{fig:i2t_flickr} and \ref{fig:t2i_flickr} show the qualitative results on the Flicker30K dataset \cite{PeterYoung2014FromID}.
It can be seen MXM-CLR is also generalizable to learn good representations for natural images with complex content.
Meanwhile, it is interesting to see most of the top 5 results returned by MXM-CLR consist similar content instructed by the query, even though they are not annotated as ground truth in the original dataset.
This indicates MXM-CLR is able to learn the semantic features and relations embedded in both modalities.

\begin{figure*}[htbp]
  \centering
  % \vspace{-3.1cm}
  \includegraphics[width=0.95\linewidth]{compare_supplementary.pdf}
   \caption{ More comparisons between MXM-CLR and TriCoLo (I)\cite{YueRuan2022TriCoLoTC} for cross-modal retrieval on Text2Shape\cite{chen2018text2shape} dataset. The blue
or red texts are manually highlighted to indicate the parts that are matched or unmatched between the query and the retrieval result.
   }
   \label{fig:fig_compare}
\end{figure*}

\begin{figure*}[htbp]
  \centering
  % \vspace{-3.1cm}
  \includegraphics[width=0.93\linewidth]{supp_ours_retrieval_top5.pdf}
   \caption{Examples of text-to-shape retrieval results (top 5) of MXM-CLR on Text2Shape\cite{chen2018text2shape} dataset. The shape with yellow background  indicates the ground truth shape. In most cases, besides the top 1 result, other results also consist similar content to the query text. 
   }
   \label{fig:t2i}
\end{figure*}

\begin{figure*}[htbp]
  \centering
  % \vspace{-3.1cm}
  \includegraphics[width=0.85\linewidth]{i2t_top5.pdf}
  \vspace{-2pt}
   \caption{ Examples of shape-to-text retrieval results (top 5) of MXM-CLR on Text2Shape\cite{chen2018text2shape} dataset. The green texts are the ground truth captions and the blue texts are manually annotated to indicate the matched content w.r.t the query.
   }
   \label{fig:i2t}
\end{figure*}

\begin{figure*}[htbp]
  \centering
  % \vspace{-3.1cm}
  \includegraphics[width=0.86\linewidth]{flickr30K_i2t_retrieval.pdf}
  \vspace{-12pt}
   \caption{ Examples of image-to-text retrieval results (top 5) of MXM-CLR on Flickr30K\cite{PeterYoung2014FromID} dataset. The green texts are the ground truth captions and the blue texts are manually annotated to indicate the matched content w.r.t the query.
   }
   \label{fig:i2t_flickr}
\end{figure*}
\begin{figure*}[htbp]
  \centering
  % \vspace{-3.1cm}
  \includegraphics[width=0.95\linewidth]{flickr30K_t2i_retrieval.pdf}
   \caption{ Examples of text-to-image retrieval results (top 5) of MXM-CLR on Flickr30K\cite{PeterYoung2014FromID} dataset. It can be seen in most cases, the top 1 result returns the ground truth image and other results also consist certain similar content to the query text.
   }
   \label{fig:t2i_flickr}
\end{figure*}
