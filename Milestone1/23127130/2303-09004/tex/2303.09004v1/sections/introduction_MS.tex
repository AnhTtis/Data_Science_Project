\section{Introduction} \label{sec:introduction}


The goal of this paper is to develop a tractable framework for data-driven synthesis of safe control laws that are robust to $L_\infty$-bounded noise  in both data-collection and during execution. Specifically,  given noisy experimental data generated by an unknown system and some priors about its structure, the objective is to synthesize a state feedback law such that the trajectories of the closed loop system starting in a given initial condition set $\mathcal{X}_0$ are guaranteed to avoid an unsafe set $\mathcal{X}_u$, even in the presence of unknown but bounded disturbances. 
Our main result shows that, for polynomial dynamics, the safe \ac{DDC} problem can be posed as the feasibility of a \ac{SOS} program. A substantial reduction in the number of variables involved (and hence computational complexity) is achieved by exploiting the theorem of alternatives, leading to a \ac{SDP} that provides both a density-function based control law and a robust safety certificate. 

Safety verification and synthesis of safe control laws have been the subject of intense research during the past decade. Level-set methods separate the initial and unsafe set by the $0$-contour of a solved function.
Barrier functions \cite{prajna2004safety} are a level-set method to certify the safety of trajectories, given that the superlevel sets of the barrier function are invariant. This superlevel invariance can be relaxed through slack (class-$\mathcal{K}$) conditions, while ensuring that the $0$-level set is invariant \cite{ames2019control, xiao2019control}. The level-set certificate of stability may be solved jointly with a safety-guaranteeing control policy $u(\cdot)$ (\ac{CBF}). When a barrier function is given, the min-norm controller will ensure safety of trajectories, and can be found through quadratic programming \cite{ames2014control}. Robustness of given barrier functions to disturbances may be analyzed using input-to-state stability \cite{XU2015robustcbf}.
Barrier functions and funnels \cite{majumdar2013control} contain bilinearities when jointly synthesizing controllers and barriers.
An alternative level-set certificate is  Density \cite{rantzer2004analysis} functions, which are based on Dual Lyapunov methods for stability \cite{rantzer2001dual}. Controllers and density functions can be simultaneously solved in a convex manner. In some systems, density functions may exist and provide improved performance as compared to  barrier functions  \cite{chen2020densityvalue}.

We briefly compare against other methods of safety-constrained control.
Interval analyses, such as Mixed Monotonicity \cite{coogan2020mixed}, offer real-time performance at the expense of conservatism in safe generation.
Hamilton-Jacobi reachability \cite{bansal2017hamilton} performs forward and backward reachable set analysis based on level sets of a differential games' value function, whose computation could require solving PDEs or neural net approximations.
Reinforcement Learning necessitates training and prior information of safety properties (e.g. Lipschitz bounds on dynamics), and does not generally exploit physical principles and model structure \cite{brunke2022safe}. Koopman methods leverage the predictive capabilities of nonlinear models, 
%\cite{korda2020optimal, otto2021koopman}, 
but they contain error bounds that can conflict against safety certification \cite{folkestad2020data}.

 
% e\textcolor{red}{need a brief description of these and why are we not using them}



% \urg{Literature review here.}


% \urg{Safe Control}

% \urg{Data-Driven Control, Data-Driven Safety}

\ac{DDC} is a methodology that synthesizes control laws directly from acquired system observations and skips a system-identification/robust-synthesis pipeline \cite{formentin2014comparison}. Amongst the vast literature in \ac{DDC}, the closest approaches related to the present paper are those that pursue a set membership approach, which seeks to find a controller that stabilizes the set of all plants compatible with the observed data (the consistency set) \cite{dai2018moments,dai2020semi,waarde2020noisy,martin2021data,berberich2021robustmpc, bisoffi2022data, miller2022lpvqmi, miller2022eiv_short}. These approaches provide a controller together with a stability certificate, usually in the form of a common Lyapunov function.  Further, the methods can be extended to provide worst case performance bounds (e.g. the $H_2,H_\infty$ or $L_\infty$ sense), over the set of data-consistent plants.  However, these approaches cannot handle safety constraints beyond those expressed in terms of these norms.

Recent work on \ac{DDC} under safety constraints includes \cite{rosolia2018learning, lopez2021robust, dacs2022robust}. 
The method in \cite{rosolia2018learning} performs iterative model predictive control for a discrete-time system by constraining state trajectories to always lie in a sampled safe set (using integer programming). 
The work in \cite{lopez2021robust} uses contraction methods to form robust adaptive \acp{CBF} under a set membership approach, but assumes that the input relation $g(\cdot)$ is known. The approach in \cite{dacs2022robust} uses a disturbance observer to provide robust \acp{CBF} by separating known and unknown dynamics. In our setting, we assume only prior knowledge of the system model (polynomial up to a specified degree) and cannot generally provide this separation. 
%\textcolor{red}{What are the shortcomings of these approaches? why is ours needed?} 
Our work involves continuous-time dynamics and interpretable (density) certificates of robust safety.
To the best of our knowledge, our approach is the first \ac{DDC} method under safety constraints that simultaneously considers data-collection and online-dynamics noise.
% \vspace{-2cm}
% \urg{(outside of $H_2$ noise?)}.


% \urg{What makes our algorithm novel.}
