\documentclass{article}


\usepackage{PRIMEarxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}
\usepackage{graphicx}
\usepackage{comment}
\usepackage{outlines}
\usepackage{enumitem}
\graphicspath{{media/}}
\usepackage{tabularx}
\usepackage{todo}
\usepackage{colortbl}
\usepackage{booktabs}
\usepackage{array}
\usepackage[table]{xcolor}

% organize your images and other figures under media/ folder

  
%% Title (provisional)
\title{GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models
%%%% Cite as
%%%% Update your official citation here when published 
\thanks{\textit{\underline{Citation}}: 
\textbf{Authors. Title. Pages.... DOI:000000/11111.}} 
}

\author{
  Tyna Eloundou, Sam Manning, Pamela Mishkin\thanks{Corresponding author.} \\
  OpenAI \\
  \texttt{\{tyna, sam.manning, pamela\}@openai.com} \\
  %% examples of more authors
   \And
  Daniel Rock \\
  University of Pennsylvania \\
  \texttt{rockdi@wharton.upenn.edu} \\
  %% \AND
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
}


\begin{document}
\maketitle


\begin{abstract}

% We explore the degree to which jobs in the US economy are vulnerable to augmentation and/or automation by large language models (LLMs). By employing humans and artificial intelligence (AI) to classify occupations according to their automation potential, required skills, and work context, we are able to estimate the likely impact of future models and associated tools on US labor market outcomes. Our analysis suggests that around 50\% of the US labor market has at least 50\% of their tasks at risk of being significantly transformed by the use of large language models and the applications we expect could be built on top of them within the next five years. This effect is true across the wage distribution, though we find evidence that higher-income jobs may be slightly more vulnerable to automation from the class of technologies we consider.

We investigate the vulnerability of jobs in the US economy to augmentation and/or automation by large language models (LLMs), a type of artificial intelligence (AI) that can generate human-like text. Using human and AI-based classification of occupations according to their automation potential, required skills, and work context, we estimate the likely impact of future LLMs and related applications on US labor market outcomes. Our analysis reveals that approximately 50\% of the US labor market has at least 50\% of their tasks at risk of significant transformation due to LLMs and anticipated applications within the next five years. This effect is observed across the wage distribution, with some evidence suggesting that higher-income jobs may be slightly more susceptible to automation from the technologies examined. These findings have critical implications for economic, social, and policy considerations as LLMs continue to advance and become more widespread in the workforce.

\end{abstract}


% keywords can be removed
\keywords{Large language models \and Labor markets}

\begin{comment}
- We need 3-4 Figures to really make the paper appealing to gensci journals.

Candidate Figure 1: Flow showing how the measures are produced (1-3 panels... one for each approach)
Panel with the automation/augmentation correlation scatterplot at the task level
Panel with the agreement / disagreement areas

Candidate Figure 2: Binscatters on wages and employment; Regional map + industry info (employment + productivity growth stuff). Demo stats w/variance breakdown into occupational variation, maybe age, gender, etc.

Candidate Figure 3: All about validity. Not sure how to plot / visualize. Earlier effort plot can be bar charts?
External validity component can be a table with use cases and maybe growth in API queries. Job postings... need to scope what we'd do there... same table idea for companies with products?

Candidate Figure 4: Growth of language models (papers, api usage etc.). Diff-in-diff plot with ChatGPT launch on github stats for huggingface relative to other libraries. Others?

\end{comment}

\section{Introduction}
%Daniel

The remarkable progress in the domain of machine learning (ML) over the past few years has been particularly evident in the realm of large language models (LLMs). Often associated with generative pre-trained transformers (GPTs) in the public's perception, LLMs encompass a wide range of architectures, not limited to transformer-based models. This extraordinary growth can be attributed to breakthroughs in the Transformer architecture \cite{vaswani2017attention} and the development of scaling laws \cite{kaplan2020scaling}. LLM architecures possess the unique ability to process and produce various forms of sequential data, transcending linguistic applications alone. The rapid evolution of LLM capabilities across different modalities has presented a challenge in fully comprehending their progression or forecasting their potential impacts.

\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{figures/image_capabilities.png}
    \caption{On the left is the trajectory of GAN progress on face generation as compiled by Ian Goodfellow from \cite{Goodfellow2014-sy, Radford2015-dd, Liu2016-uc, Karras2017-th, Karras2018-gh}, on the right is an image generated from DALL-E 2.0 \cite{dalle2} using outpainting. Today's image generators can create images of arbitrary size and, accordingly, resolution of any subject and in every framing.}
    \label{fig:goodfellow}
\end{figure}

To begin to ground this progression and these predictions, we defined a new rubric for understanding the capabilities of LLMs and how they might effect jobs. In Summer 2022, the authors labeled every task in the O*NET dataset for how relevant it was to what they understood to be the "out-of-the-box" capabilities of three LLMs: GPT-3 \cite{brown2020language}, Codex \cite{chen2021evaluating}, and DALL-E 2. This initial analysis suggested that LLMs had the capacity to "expose" tasks and occupations across the wage distribution to automation.

After seeing the public reception of ChatGPT, we updated this rubric to ask not just "Would people trust GPT-3 to do this task today?" but:
\begin{enumerate}
    \item How much of this task could be done by an LLM?
    \item How much could an LLM assist a human with this?
    \item What aspects of this task are relevant to whether an LLM could do this?
    \item What aspects of this task are relevant to whether people would adopt an LLM to do this?
\end{enumerate}
Where we didn't necessary link an "LLM" to any particular model but rather considered a model we expect is similar in capability level to GPT-4 \cite{gpt4} and also the suite of capabilities we expect the ecosystem to unlock in the next few years, by building applications on top of GPT-4.

We launched this second stage of our research in December, 2023. We relied primarily on a LLM to label tasks according to a given taxonomy, though also collected human labels for some and did some manual review of the model's "work." Using this approach, we find that 50\% of jobs have at least 50\% of their tasks at risk of automation when we consider both the latest model capabilities and the tools we anticipate will be built on top of them. Even since this second data collection stage, our and the public's understanding of the suite of capabilities unlocked by these models has transformed. 

\begin{outline}
    \1 We find potential applications that we expect will:
    \2 1) be pervasive, \2 2) improve over time, \2 3) spawn complementary innovation 
    \3 \textbf{Together, this implies that models are general-purpose technologies.}
    \1 The "right" kind of AI? General-purpose AI or generative AI models aren't the level where this choice is made: applications are. We find evidence that, according to the A-R categorization, this slate of models is/is not... 
\end{outline}

While we believe this finding is important, and should be enough to motivate more attention to the pace of development and the need for attention from policymakers \cite{milesblog}, we also believe there are likely many additional findings in the datasets we collected and methods we've considered. This working paper presents a few analyses of this data, and we expect to follow shortly with additional ones.


\section{Literature Review}
\label{sec:litreview}

In recent years, LLMs have emerged as a prominent area of AI research, demonstrating their potential to perform a variety of complex language-based tasks. These advancements have been driven by multiple factors such as increases in model parameter count, training data volume, and training duration \cite{brown2020language, radford2019language, hernandez2021scaling, kaplan2020scaling}. State-of-the-art LLMs, such as LaMDA \cite{thoppilan2022lamda} and GPT-4 \cite{gpt4}, are capable of diverse applications including translation, creative writing, and code generation. Such capabilities were previously impossible to achieve or required specialized task-specific models developed by skilled engineers with domain-specific data.

As part of these developments, researchers have also enhanced the steerability, reliability, and utility of LLMs through methods such as fine-tuning, reinforcement learning with human feedback \cite{ouyang2022training, bai_training_2022} and prompt modification \cite{wei_chain--thought_2023,nye_show_2021,kojima_large_2023}. These efforts can improve task performance either through suggestions to users, being incorporated in the system "under-the-hood" or by being built into the model during training.

The modular nature of most current LLMs (different models trained for different modalities) enables individual components to be used in conjunction. However, we anticipate a future where these components may be integrated into unified systems. Recent studies have shown the potential of using LLMs to themselves program and control digital tools such as other LLMs, APIs, and search engines \cite{schick2023toolformer, mialon2023augmented}. This implies that many tasks involving digital input-output transformations could potentially be transformed by LLM utilization. At its limit, it suggests a future where any task currently done sitting at a computer could be completed by an LLM.

Despite these trends in model utility, challenges persist in the deployment and use of LLMs. Notably, these models can exhibit factual inaccuracies, ingrained biases, and disinformation risks \cite{abid_persistent_2021, schramowski_large_2022, goldstein_generative_2023}. While general-purpose LLMs may not be reliable for all tasks, specialized tooling or applications can improve performance in specific applications. Such applications, in domains such as writing assistance (e.g. Jasper \cite{noauthor_jasper_nodate}, coding (e.g. GitHub Copilot \cite{noauthor_github_nodate}, or legal research (e.g. Casetext \cite{noauthor_casetext_2022}) -- to name just a few examples -- can facilitate wider adoption of LLMs by businesses and individuals.

Moreover, a positive feedback loop may arise as LLMs themselves can assist in building the very tooling that makes them more useful and usable in various contexts. This can reduce the cost and engineering expertise required for creating such tools, further accelerating LLM adoption and integration.\cite{chen2021evaluating, sida_copilot} Moreover, LLMs themselves can be helpful tools for AI engineers building and training models. Both of these trends in turn come with their own risks.\cite{hazard_analysis}

Past work, as discussed below, has looked at exposure of tasks by LLMs largely in isolation, however we consider them as an especially important building block in the future of technology and software.

Finally, at a certain level of performance, models themselves become helpful tools in model development: as coding assistants for researchers, labeling services for data, and data creators themselves in the form of synthetic data. At a particular level of performance we expect that LLMs by definition improve over time as they "learn" to better align to users' preferences.

\textbf{To do: economics literature review}

This paper attempts to build on this literature in several ways. 
\begin{itemize}
    \item We focus specifically on the impact of language models and generative AI, rather than automation technologies broadly.
    \item We introduce a new method of assessing worker exposure to these models by prompting GPT-4 to classify exposure scores based on a variety of exposure and automation taxonomies.
    \item We estimate task and occupation-level exposure (which includes task-augmenting and task-automating effects) as well as forward-looking automation potential of generative models, and the relationship between the automation and exposure broadly defined.
    \item We provide updated estimates using this new methodology of the distribution of LLM exposure across industries, regions, and demographic variables.
\end{itemize}

\begin{comment}
    \1 uniqueness here: 
    \2 focus on generative models as an especially important domain for software
    \2 identification of potential for heterogeneous impact
    \2 dataset for researchers across a few fronts
    \3 expert-validated scoring  
    \3 task-level 
    \3 automation/augmentation
    \3 characterization of differences between human and machine answers
    \4 where humans think machines can do it but machines don't
    \4 where machines think machines can do it but humans don't
    \3 early evidence of fast pace of adoption (partly due to UI...)
    \3 early evidence on the emergence (or lackthereof) of new skills and tasks
\end{comment}  

\section{Methods and Data Collection}
\label{sec:data}

\subsection{Data on Activities and Tasks Performed by Occupation in the US}
\label{subsec:task_data}

We use the O*NET database, which contains information on 1,016 occupations and the tasks and Detailed Work Activities (DWAs) they involve. A DWA is a broad action that is part of completing task, such as "Study scripts to determine project requirements." A task is a more occupation-specific unit of work that may involve one or more DWAs, such as "Learn about characters in scripts and their relationships to develop role interpretations" for Actors or “Study and research scripts to determine how they should be directed” for Set and Exhibit Designers. A larger sample is provided in Table \ref{tab:onet}.

This yields two different datasets:
\begin{itemize}
    \item 19,265 tasks, where each task has both a "task description" and an associated occupation, and most tasks are associated with one or more DWAs, and
    \item 2087 DWAs, where most DWAs are associated with one more tasks, and tasks may be associated with one or more DWAs, though some tasks are also associated with no DWAs.
\end{itemize}

\input{tables/onet_tables}
% \input{onet_tables}

\subsection{Data on Wages, Employment, and Demographics}

We use O*NET and the Bureau of Labor Statistics. Specifically, we drew down the 

\subsection{Exposure}

We define exposure as whether access to an LLM or system would reduce the time it takes a human to complete a task by half. To determine the exposure of DWAs and tasks to LLM capabilities, we used the following guidelines:

Firstly, we labeled activities/tasks as having no exposure (E0) if any reduction in the time it would take to complete the activity/task with equivalent quality is minimal and/or using any combination of the capabilities described in the below criteria would decrease the quality of the activity/task output.

Secondly, we labeled activities/tasks as having direct exposure (E1) if direct access to ChatGPT or OpenAI playground alone can reduce the time it takes to complete the activity/task with equivalent quality by at least half.

Finally, we labeled activities/tasks as having exposure by LLM-powered applications (E2) if having access to the LLM alone would not reduce the time it takes to complete the activity/task by at least half, but additional software could be built on to the LLM that could reduce the time it takes to complete the specific activity/task with equivalent quality by at least half. These systems include modular access to image generation systems.\footnote{In practice, as can be seen in the full taxonomy in the appendix, we actually break out access to image capabilities to a separate class (E3) to help streamline labeling, though we combine E2 and E3 for all analysis.}

We set the threshold for exposure at a perceived 50\% possible reduction in time taken to complete a given task/activity while holding quality constant. Although this threshold is somewhat arbitrary, we chose it for its ease of interpretation.

We then collected both human and model labels on this rubric:
\begin{itemize}
    \item \textit{Human 2023 Exposure:} We applied this rubric to each DWA and a subset of all tasks (including those with no associated DWAs) and then aggregated those DWA scores to the task and occupation level. To ensure the accuracy of our labels, we sourced human labelers who have significant experience reviewing LLM outputs as part of OpenAI's alignment work \cite{ouyang2022training}. The authors labeled activities that clearly required a high degree of physicality or manual dexterity , and the external labelers labeled the remaining activities, along with some tasks including those with no associated DWAs and those for which there was no clear label in aggregate.
    \item \textit{Model 2023 Exposure:} We gave a similar taxonomy (with some tweaks to increase agreement) to an LLM. We made tweaks to maximize agreement with the human labels. Like humans, even the most powerful models can be noisy with their labels. We find that slight tweaks to the prompt can lead to wide disagreement. We find a kappa score of .61 (with E1 and E2 as different) and .66 (with E1 and E2 as one class) between the two different prompts. This demonstrates both a limitation with the "homo silicus" approach, as well as the noise and imprecision in our exposure taxonomy.
\end{itemize}

These two sets of labels underlie the bulk of the analyses presented in this paper. We analyze over a number of different coefficients attached to tasks with the E2 label, that is, we assume that tasks with an E1 label are fully ``exposed" to augmentation, but consider whether E2-labeled tasks are fully exposed (coefficient 1), partially exposed (coeffient .5), or not exposed (coefficient 0).

\subsection{Automation (and Augmentation)}

We define automation as the \textbf{amount} of a task a model can complete without human assistance, and sweep over five values: T4 (full automation -- model can do 100\% of the task), T3 (high automation -- model can do 90-100\% of the task, with human oversight), T2 (moderate automation -- model can do 50-90\% of the task), T1 (low automation -- model can do 0-50\% of the task), T0 (no automation -- model cannot perform a meaningful percentage of the task).

Similar to exposure, we defin augmentation as the \textbf{time saving} a human gets by having access to an LLM.

\subsubsection{Augmentation}

\subsection{Skills and Suitability}

\subsection{Sweeps}

\input{tables/kappa_scores}

\section{Results @drock to draft after analysis is done}
\label{sec:econimpact}

Our evaluation procedures admit a wide variety of possibilities as we evaluate the potential impact of LLMs on economic activity in general and the workforce in particular. General-purpose technologies are relatively rare, but should be pervasive, improve over time, and lead to extensive coinvention and spillovers. \cite{lipsey2005economic} Testing the general-purpose nature of LLM technologies by evaluating labor market impact potential is restrictive because it ignores total factor productivity or capital input potential. The capabilities of these models are certainly expanding over time. Growth of complementary applications and systems is easier to verify in the long run. Our primary test at this early stage then is to test the hypothesis that the potential impact of LLMs is pervasive throughout the economy. This is similar in spirit to the analysis of Goldfarb et. al \cite{goldfarb2023could}, which uses job postings to measure the diffusion of machine learning as a means of testing the general-purpose technology potential of machine learning as an algorithmic category. Instead of using job postings or studying machine learning in general, following the task evaluation approach with both human and LLM raters might reveal that LLM impacts are concentrated within a small group of similar tasks (or roles). We find instead strong early indications that LLMs are general-purpose technologies. As a subclass of machine learning, GPTs are very likely to be GPTs. Below we discuss results across roles, wage structure, industries, and regions for the U.S. economy.

\subsection{Summary Statistics}

The simplest way of evaluating exposure to LLMs is to look for possible GPT (text) or Codex (code) model exposure as a binary variable. We take the binary variables from our Exposure taxonomy to define 3 exposure measures, depending on how we wish to bound

We describe our dependent variable of interest, namely, exposure to GPT models and GPT-based technologies. We construct 3 principal measures: (i) \textbf{$\alpha$} exposure, which corresponds to E1 in our taxonomy, and is expected to be the lower bound, as judged by humans and models of GPT-relevance of tasks within a given occupation, (ii) \textbf{$\beta$} exposure, which is a weighted sum of E1 and 0.5*E2, designed to convey exposure if manifesting the technology through tools requires additional costs that some developers are not willing to pay, and (ii) \textbf{$\zeta$} exposure, which is simply the sum of E1 and E2, an upper bound of exposure that assumes that exposure through tools and other platforms is equivalent to direct exposure through the raw model or an API. For the remainder of the analysis, if not specified, you may assume that we're pointing to $\beta$ exposure.

Whether we aggregate across tasks or across occupations and whether annotated by humans or the model, we observe that the $E_\alpha$ hovers between 0.14 and 0.15, meaning that both 15\% of tasks are GPT-relevant and the average occupation has 15\% GPT-relevant tasks. Naturally, this number climbs to be above 30\% for $E_\beta$ and above 0.50 for $E_\zeta$.



Using $E_\alpha$, we estimate that 78\% of workers are in an occupation where at least one task is GPT-relevant (E1)  and 2.6\% of workers are in an occupation where over half the tasks are GPT-relevant. These numbers are similar in trend to the M23 : 80\% for exp\_min and 20.3\%. 


\ref{exposure_final} shows the exposure intensity across the economy, displayed in the first plot in terms of total workers and in the second plot in terms of total occupations. Each point designated the estimated number of workers (and occupations) that are expected to have the threshold percentage of above of GPT-relevant occupations.


\begin{center}
\input{tables/summary_stats}
\end{center}

For each of these 3 measures, we plot the exposure frontier, by occupation and total number of workers. For instance, we see that XX number of workers are in occupations where at least 10\% of tasks are $\alpha$-exposed 

\subsection{Wages and Employment}
\label{subsec:labor}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/exposure_final.png}
    \caption{Exposure by Threshold}
\end{figure}
\label{exposure_final}



Binscatter results showing the average occupational binary value weighted by task importance against the log annual wage of the occupation are shown in Figure \ref{fig:codex_binscatter}. To a point, higher wage occupations tend to be more exposed to GPT-related models and language models for coding. The red line denotes a third-order polynomial approximation.

\includegraphics[width=0.5\textwidth]{figures/codex_logsal_binscatter.png}
\label{fig:codex_binscatter} \\


\includegraphics[width=0.5\textwidth]{figures/medianhuman_logsal_binscatter.png}
\label{fig:human_binscatter} \\
In Figure \ref{fig:human_binscatter}, we show the human label for LLM exposure averaged over all tasks in the occupation. In this case, we code a completely unexposed task as a 0, a fully exposed task as a 1, and a task with impact potential subject to additional conditions or partial exposure as 0.5. The overall trend is highly similar to the naive binary encodings for GPT or Codex-style model relevance. Higher wage occupations tend to be more exposed, though the very highest wage occupations have slightly less exposure than the peak. 

\includegraphics[width=0.5\textwidth]{figures/dv_logsal_binscatter.png}
\label{fig:dve_binscatter} \\
Figure \ref{fig:dve_binscatter} shows the GPT-4 evaluation of LLM exposure by occupation (and therefore, the model's estimate of its own potential). Algorithmic and human rater evaluations, aggregated at the occupation level, are qualitatively similar and broadly in agreement. Algorithmic evaluations from the LLM estimate a slightly higher exposure for high wage occupations than human counterparts. In both cases there are numerous lower wage occupations with high exposure and also high wage occupations with low exposure, but the binscatter plot shows the overall trend as wages increase: higher wage is associated with higher exposure to LLMs.

\includegraphics[width=0.5\textwidth]{figures/dvT_logsal_binscatter.png}
\label{fig:dvt_binscatter} \\
Figure \ref{fig:dvt_binscatter} refers explicitly to the automation ("T") rubric, which asks the GPT-4 model to evaluate its own potential to automate tasks instead of impacting them in some general sense. For these labels, we code no exposure as 0, partial exposure of the lowest level as 0.25, partial exposure at the medium level as 0.5, partial exposure at a high level as 0.75, and full exposure as 1. Automation exposure ratings follow a similar trend to general exposure ratings. Higher wage occupations tend to be more likely to have automatable tasks. No occupation is fully automatable under this rubric, though many occupations have high levels of exposure that suggest they might be reconfigured entirely. Occupations with the highest automation exposure include telephone operators (0.88), travel agents (0.78), word processors and typists (0.78), credit authorizers, checkers, and clerks (0.775), desktop publishers (0.774), and telemarketers (0.76). 

%\todo{create regression table and partial out automation from exposure}. 

Regressing exposure scores (the ``E'' rubric) on the automation scores (the "T" rubric), we find a strong positive relationship. The automation score has a coefficient of 0.87 (standard error 0.008). Overall exposure and automation exposure are highly correlated, with an $R^2$ of 46.4 percent in a univariate regression of exposure scores on automation scores at the task-level. This means that where automation is high, it is likely the case that exposure, which includes augmentation potential, is also relatively high. Automation and augmentation potential will often co-occur, as in \cite{autor2022new}. In light of this fact, emphasizing augmentation instead of automation may not be useful in charting a path forward for designing jobs. Even in cases where it is possible to prioritize augmentation, market-level factors like price and income elasticities of supply and demand (among others) dictate the extent to which individual workers are aided or displaced by new configurations of work \cite{brynjolfsson2017can}. Our evidence suggests a murky path forward for GPTs as GPTs. Whether workers are displaced or complemented on balance will depend on the particulars of the application and emergent use cases as new systems and complements emerge. Based on this evidence, it is also premature to suggest that high broad-based exposure implies the wholesale elimination of jobs for similar reasons.

\includegraphics[width=0.5\textwidth]{figures/meanhuman_totemp_binscatter.png}
\label{fig:meanhuman_totemp}
\includegraphics[width=0.5\textwidth]{figures/dvE_totemp_binscatter.png}
\label{fig:dve_totemp} \\
Employment overall appear to be unrelated to LLM exposure. In Figure \ref{fig:meanhuman_totemp} we can see human ratings of overall exposure aggregated to the occupation-level (y-axis) against log total employment (x-axis), and in Figure \ref{fig:dve_totemp} we see the same for GPT-4 ratings. Neither plot shows meaningful differences across employment quantities in the exposure to LLMs.




% In \ref{fig:exposure_thresh_e1e2}, we see that 



% \includegraphics[width=0.5\textwidth]{figures/exposure_2023_expected_human_emp.png}




% \1 distribution of impact by wage / skill level (people push back against high wage = high skill)


Futher, we study the relationship between the importance of a skill for an occupation (as annotated the O*NET data set) and our exposure measures. We first normalize skill importance across our dataset to improve interpretability and regress on our exposure measures to study the strength of associations.

We find that the importance of *science* and *critical thinking* is strongly negatively correlated with all our exposure measures, while the importance of *programming* and *writing* is strongly positively correlated with all of our exposure measures.

\input{tables/skill_correlation}


\1 Differences between the augmentation and automation components
\end{outline}

\subsection{Regional, Industrial, and Productivity Exposure}
\label{subsec:aggregates}
\begin{outline}[enumerate]

\1 which regions are most exposed (map) to automation and augmentation

\includegraphics[width=0.5\textwidth]{figures/industryexp.png}
\label{fig:meanhuman_indexp}
\includegraphics[width=0.5\textwidth]{figures/industryexp_dve.png}
\label{fig:dve_indexp}

Figures \ref{fig:meanhuman_indexp} and \ref{fig:dve_indexp} show the overall employment-weighted relative exposure of 3-digit NAICS industries according to human raters and our algorithmic exposure rubric respectively. The impact potential is present across nearly all industries, with wide heterogeneity. Table XX (PUT A TABLE SHOWING RELATIVE EXPOSURES) describes the relative exposures according to different evaluation regimes. Both methods agree generally on relative exposures: data processing, information processing, and hospitals all have high exposure.

\includegraphics[width=0.5\textwidth]{figures/tfpemp_dv_facetscatter.png}
\label{fig:tfp_dv}
\includegraphics[width=0.5\textwidth]{figures/laborprodemp_dv_facetscatter.png}
\label{fig:lp_dv}
Recent productivity growth (both total factor and labor) appears uncorrelated with exposure as well. Figures \ref{fig:tfp_dv} and \ref{fig:lp_dv} show little relationship between productivity growth since 2012 and current exposure to LLMs as rated by our "Homo Silicus" approach. A high correlation between already fast-growing productive industries and exposure might mean an exacerbation of Baumol's cost disease. In other words, if LLMs are likely to increase productivity differentially across industries, one concern is that the most productive would become even more productive. With inelastic demand for the production of those industries, the most productive sectors would shrink as a proportion of inputs in the economy. We see little to suggest this will be the case. Productivity growth since 2012 and exposure to LLM technologies appear unrelated. 


\end{outline}

% \subsection{Demographic Variation in Exposure @tyna or @pamela}
% \label{subsec:demographics}
% \begin{outline}[enumerate]
% \1 which groups are more / less exposed to each tech?

% \begin{tabular}{lrrrr}
% \toprule
% {} &  H22 &  M22 &  H23 &  M23 \\
% \midrule
% Women &       0.080 &       0.002 &       0.293 &       0.177 \\
% White  &      -0.149 &       0.004 &      -0.013 &      -0.193 \\
% Black  &      -0.055 &      -0.216 &      -0.066 &       0.046 \\
% Asian  &       0.316 &       0.287 &       0.125 &       0.237 \\
% Latino &      -0.302 &      -0.394 &      -0.284 &      -0.150 \\
% \bottomrule
% \end{tabular}
% From the table above, we see that the proportion of women employed in an occupation is totally uncorrelated with GPT-relevance in the 2022 measures, but positively correlated for the 2023 measures. Across all measures, we see the proportion of Asian people to be positively correlated with GPT-exposure and that of Latino people to be negatively correlated.

% Obviously, different demographic groups are unevenly distributed across occupations.
% % part of the effects are simply that people are unevenly distributed in occupations.
% \end{outline}

\section{Barriers to Entry}

We draw inspiration from \cite{autor2022new} to examine, under another dimension another set of identified important features of the work.


\subsection{Exposure vs Barriers to Entry}

From the O*Net Website: \url{https://www.onetonline.org/help/online/zones#zone1}

\input{tables/job_zone_summary}




% Job Zone 1: Little or No Preparation Needed (up to 3 months), some occupations may require a high school diploma or GED certificate. Examples include food preparation workers, dishwashers, floor sanders and finishers, landscaping and groundskeeping workers, logging equipment operators, and baristas.

% Job Zone 2: Some (3 months to 1 year) Preparation Needed, typically requires a high school diploma and some previous work-related skill is helpful. Examples include orderlies, counter and rental clerks, customer service representatives, security guards, upholsterers, tellers, and dental laboratory technicians.

% Job Zone 3: Medium (1-2 years) Preparation Needed, typically require training in vocational schools, on-the-job experience or an associate's degree. Examples include hydroelectric production managers, desktop publishers, electricians, agricultural technicians, barbers, court reporters and simultaneous captioners, and medical assistants.

% Job Zone 4: Considerable (2-4 years) Preparation Needed, typically require a four-year bachelor's degree. A considerable amount of work-related skill, knowledge or experience is needed. Examples include real estate brokers, sales managers, database administrators, graphic designers, conservation scientists, art directors, and cost estimators.

% Job Zone 5: Extensive (4+ Years) Preparation Needed, may require a master's degree and some require a Ph.D, M.D. or J.D. 
% Extensive skill, knowledge, and experience are needed for these occupations. Many require more than five years of experience. Examples include pharmacists, lawyers, astronomers, biologists, clergy, physician assistants, and veterinarians.



% \begin{tabular}{lrr}
% \toprule
% {}  & H23 & M23 \\
% Work Tranche 1 &             \\
% \midrule
% Manual Work   & 3.71 & 3.84 \\
% Routine Work   & 8.85 & 12.67 \\
% Abstract Work  & 22.74 & 15.87 \\
% \bottomrule
% \end{tabular}
\begin{figure}
    \centering
    \includegraphics[width=.95\textwidth]{figures/figuresexposure_2023_expected_human_jobzone_final.png}
    \caption{This figure shows the relative exposure ratings of occupations in the five Job Zones, which are groups of similar occupations that are classified according to the level of education, experience and on-the-job training needed to perform them. Using E2 coefficient 0.5.}
    \label{fig:my_label}
\end{figure}


\section{Validation of Measures @drock to draft}
\label{sec:validation}

\subsection{Comparison to Earlier Efforts}
\label{subsec:othermeasures}
This paper aims to build on a number of previous empirical studies examining the occupational exposure to advances in AI. Previous studies have used a variety of methods, including:
\begin{itemize}
    \item Mapping text descriptions of tasks to descriptions of technological advances in patents. \cite{NBERw29552, Webb2020}
    \item Linking capabilities of AI systems to occupational abilities and aggregating exposure estimates to the occupations where those abilities are required. \cite{SeamansRajFelten2018, felten2023will}
    \item Mapping the results of AI task benchmark evaluations (ImageNet, Robocup, etc.) to 59 worker tasks through a set of 14 cognitive abilities drawn from the cognitive science literature. \cite{Tolan2021}
    \item Expert labeling of automation potential for a set of O*NET occupations where experts had high confidence, combined with a probabilistic classifier to estimate automation potential for the remainder of O*NET occupations. \cite{FreyOsborne2017}
    \item Developing a rubric for evaluating the "suitability for machine learning" (sml) of activities that workers are completing in the economy \cite{Brynjolfsson2018}
\end{itemize}

In terms of methodology, this paper builds perhaps most directly on the SML approach by developing a number of taxonomies that are used to evaluate the overlap between LLM and generative model capabilities and worker tasks as reported in the O*NET database. Table 2 presents the results of an OLS regression of the occupation-level exposure measures from Felten, Raj, and Seamans (2018) ("FRS" in the table) \cite{SeamansRajFelten2018} , Frey and Osborne (2017) (FreyOsborne) \cite{FreyOsborne2017}, and Brynjolfsson, Rock, and Mitchell (2018) \cite{Brynjolfsson2018} (SML). Encouragingly, the SML exposure scores by occupation are significantly and positively associated with the exposure scores we develop in this paper. This demonstrates some level of results cohesion across the two studies. Importantly, however, the SML coefficient is statistically significant only when controlling for normalized\_r\_cog and normalized\_r\_man at the occupation-level. We do not observe a significant relationship between the GPT-4 exposure labels and either the Felten, Raj, Seamans (2018) exposure scores or the Frey and Osborne (2017) scores. This could potentially be explained by differences in scores between this paper and the RFS approach that focuses squarely on linking AI capabilities to worker abilities or the FreyOsborne approach that scored exposure directly on the occupation's characteristics, rather than aggregating up to occupation from DWA or task-level scoring (as in the SML paper and our own). 



\input{tables/reg_results_other_measures}


\begin{comment}
\begin{outline}[enumerate]
\1 SML
\1 Felten, Raj, and Seamans
\1 Webb
\1 Arntz et al
\1 Current slate of models vs. other efforts and why it's not automation
\1 SML validity comparison (new)
\end{outline}

\subsection{External Validity}
\label{subsec:externalval}
\begin{outline}[enumerate]
\1 @drock: job postings analysis?
\1 @drock: companies with products matched to tasks -- publicly available products
\end{outline}
\end{comment}

%\includegraphics{}

\subsection{Caveats to our measures}
\label{sec:caveats}
\begin{outline}[enumerate]
\1 Relative vs. absolute measures

We instructed external reviewers to assess exposure based on the LLM capabilities described in the labeling guidelines. However, it is worth noting that these reviewers have significant experience working with advanced LLMs, so it is reasonable to expect some bias to have influenced their exposure assessments. In a survey, half of reviewers report that their knowledge likely biased them towards higher exposure scores, while half said their knowledge had a neutral or negative impact.

\1 Prompt-sensitivity of model-generated labels
Second, while the use of LLMs to classify tasks and DWA exposure based on a labeling taxonomy shows promise, this method also presents certain weaknesses. The results are highly sensitive to variations in the wording of the taxonomy, how it is translated into a prompt, the inclusion or exclusion of certain examples within the taxonomy, the level of detail provided, and the definitions of key terms given to the model. To effectively communicate the intended taxonomy to a LLM, prompt-tuning may be necessary. Indeed we tuned the taxonomies used for our core measures in order to communicate the instructions given to human labelers in a way that better suited the LLM. However, this process can lead to taxonomies evaluated by an LLM that differ slightly from those designed for human labelers, even while attempting to measure the same outcome. This reduces the ability to compare across human-model labeling sources and can obscure the interpretation of which label should be considered the closest approximation of the truth. This suggests that there is still substantial room for improvement and innovation in designing effective taxonomies for a "homo silicus" model.

\1 Forward-looking and subject to change, with some early evidence
    #Note: 2 extremes for automatability. e.g. make a reservation (some Rezy processes are already automated, does LLM really add any delta? Another extreme is the case where in a sense the model could automate things like "negotiations" or multi-people interactions.
Our projections are inherently forward-looking, based on current trends and evidence, and are therefore subject to change as new developments emerge in the field. For instance, certain tasks that may seem improbable for automation today may become feasible with advancements in LLM capabilities. Conversely, certain tasks that appear automatable may present unforeseen challenges that limit technological intervention. As such, our estimations should be regarded as an evolving reflection of the field's trajectory.

    Why half? (i) Easy to interpret for most people. (ii) Over 50\% maybe a good enough to think about "serious" automation.
    \2 we frame in a particularly assistive way -- you are a human worker using the model to complete the task (augmenting) -- instead of you are a model doing the task what quality can you achieve
    In our analysis, we have framed the potential integration of LLMs into the workforce in an assistive capacity. This implies that human workers may utilize LLMs to augment their capabilities and complete tasks more efficiently, rather than having their roles entirely supplanted by the technology. The degree to which tasks can be automated and the implications thereof may vary based on this framing.

\1 Very difficult to make predictions, esp. about future or to imagine/believe that capabilities that don't exist yet could emerge.

As the field of AI and language models is rapidly evolving, making accurate predictions about its future developments remains a formidable challenge, even for domain experts.\cite{gpt4} There are various factors that contribute to this complexity, including emergent capabilities, human perception biases, and shifts in technological development. These factors can impact the accuracy and reliability of predictions about LLMs' potential for automating tasks.

\1 Very difficult to understand jobs that aren't your own -- all the failure cases, etc. how the average worker does a task vs. how you would do a task

Similarly, we find that it is very difficult to understand jobs that aren't ones own, ...

\1 Point-in-time evaluation. New information brings new judgments.

We have tried to move this away from being a point-in-time evaluation by rooting in where we see the technology going in the next year, but still we expect new information to bring new judgments, updating for example our expectations of how LLMs may lead to breakthroughs in robotics, and cognitive tasks that somehow stay out of reach for the models.

\2 Over the course of our second data collection effort, which began in January 2023, we witnessed significant changes in the landscape of GPT capabilities. Not only did we observe users discovering new capabilities of ChatGPT, but also increased adoption of older released models. For example, we saw increased interest in applications that combined Whisper and text-to-speech features and video style-transfer models. Another notable trend we observed was the integration of multiple modalities and APIs into GPTs, allowing them to perform more complex and diverse tasks. For instance, Toolformer is a model that can self-learn to use external tools via simple APIs, massively expanding the scale and scope of achievable tasks to most that involve using a website. Similarly, PaLM-E from Google shows that the GPT paradigm can be used to learn robotics and to navigate the physical world.
\end{outline}


\section{An Early Look at LLM Adoption @unclear}
\label{sec:adoption}

Cite adoption paper by Acemoglu et al 2022 \cite{acemoglu_2022_automation_survey} showing current low levels of AI adoption by firms but high worker exposure due to larger firms being more likely to adopt. Contrast with recent uptick in both individual use and interest in ChatGPT and explosion of new apps being built on top of models deployed through APIs. Quick synthesis of twitter and Hackernews scraping for ChatGPT use. Mention early studies on LLM integration into worker processes: Additionally, early studies show that these models are useful.

Recent studies show that language models like ChatGPT and GitHub Copilot can significantly enhance work efficiency and quality. On a narrow task performed by Upwork workers, ChatGPT reduced task completion time by 0.8 SDs and increased output quality by 0.4 SDs, particularly benefiting low-ability workers and reducing productivity inequality. The model also led to task restructuring, with workers focusing on idea generation and editing, and relying on the model for drafting. This resulted in higher job satisfaction and self-efficacy. \cite{Noy2023} Similarly, GitHub Copilot users reported increased job fulfillment and reduced frustration. The tool allowed developers to focus on satisfying tasks while offloading repetitive work, helping maintain flow state and conserving mental energy. \cite{sida_copilot}

These results align with forthcoming findings on the impact of integrating GPT-3 into the workflow of customer service agents, wherein the productivity gap between experienced an inexperienced workers shrunk, and the work became more enjoyable. (cite Lindsey Raymond paper)

Taken together we see early signs

\begin{comment}
\begin{outline}[enumerate]
\1 summary stats on growth of language model stuff
\1 difference-in-difference on huggingface github stats following chatGPT launch @drock
\1 news/tweet 

Anecdotally, we see reports that people are using the models in their jobs and finding them useful. 
\2 https://www.cnn.com/2023/01/28/tech/chatgpt-real-estate/index.html -- 41-9022.00
\2 

Additionally, early studies show that these models are useful.

Recent studies show that language models like ChatGPT and GitHub Copilot can significantly enhance work efficiency and quality. On a narrow task performed by Upwork workers, ChatGPT reduced task completion time by 0.8 SDs and increased output quality by 0.4 SDs, particularly benefiting low-ability workers and reducing productivity inequality. The model also led to task restructuring, with workers focusing on idea generation and editing, and relying on the model for drafting. This resulted in higher job satisfaction and self-efficacy.

These results align with earlier findings on the impact of integrating GPT-3 into the workflow of customer service agents, wherein the productivity gap between experienced an inexperienced workers shrunk, and the work became more enjoyable. (cite Lindsey Raymond paper)

Similarly, GitHub Copilot users reported increased job fulfillment and reduced frustration. The tool allowed developers to focus on satisfying tasks while offloading repetitive work, helping maintain flow state and conserving mental energy.



\1 funding
\1 publicly reported stuff on number of users of xyz
\1 other ideas in this area?
\end{outline}
\end{comment}

\section{Discussion @all draft after rest is filled in}

The implementation of automation technologies has been linked to heightened economic disparity, which may give rise to adverse downstream effects.\cite{acemoglu2022demographics, Acemoglu2002, Moll2021, Klinova2021} A widening chasm of intranational income inequality has been observed to instigate socio-political unrest, which may subsequently erode the foundational principles of democracy. This phenomenon poses a formidable challenge to the maintenance of political stability and democratic governance, further exacerbated by LLMs' potential to generate false information. Against this backdrop, there's one way to look at our results as promising -- by exposing workers across the wage distribution, LLMs may actually increase equality compared to previous waves of automation technologies.


\textbf{Impact of Software Innovations Enabled by LLMs}
This figure offers one illustration of the potential economic impact of software built on top of LLMs that are released via API. While we expect that out of the box these models are relevant to a large share of workers and tasks, as GPTs, we expect them to enable software innovations that otherwise wouldn't have happened, unlocking the development of use-case specific software applications specialized for various domains and work environments. The power of relatively simple UI advances was evident in the rollout of ChatGPT -- in which the underlying model had been previously available via API, but usage skyrocketed after the release of the ChatGPT interface. Similarly, software tools such as (highlight some launch partners here? Or just existing software that has built useful wrappers around GPT-3?) expand the range of tasks and occupations where LLMs can play a relevant role in the production process. Future work to understand the differential impacts of various software integrations as well as the adoption process for both software developers and their users would be invaluable. 

\textbf{Implications for public policy}

Our findings suggest that LLMs and multi-modal generative models will have diffuse and transformative impacts on work in the United States. The pace of progress in model capabilities also suggests that impacts could begin to come about rather quickly as more applications are developed that leverage increasingly powerful models. 

Research has shown that the adoption of automation technologies over the past forty years has led to increased wage inequality in the US, namely through task displacement and the decline of relative wages to workers specialized in routine tasks.\cite{Acemoglu2022} As our results show, exposure to augmentation and automation risk is not uniform across all workers, and policymakers should therefore expect reductions in the demand for various skills to affect some workers more than others, leading to differential impacts on the frequency of AI-induced job loss and the need to transition between jobs and occupations. Job loss of any kind can cause significant long-lasting harms, though public policy actions can play a role in reducing these harms while maximizing the positive economic impact of these systems. (cite)

We highlight three areas of potential public policy opportunities in light of our findings. \footnote{Several of these ideas are drawn from the \href{https://workofthefuture.mit.edu/wp-content/uploads/2021/01/2020-Final-Report4.pdf}{final report of the MIT Task Force on the Work of the Future}, which has a much more detailed analysis of policy options to consider in response to the labor market impacts of advances in artificial intelligence} 

\begin{outline}[enumerate]

\1 \textbf{Increased economic security through enhanced worker safety nets}

Expanded wage insurance options for workers who are displaced from a job and transition to lower-wage employment can help smooth job transitions for workers and provide added economic security, relieving constraints that may allow for investments in skill development and increasing earnings and employment. \cite{hyman2021wage} One example of a similar program is the Reemployment Trade Adjustment Assistance (RTAA) program, in which eligible workers who are displaced from their job due to a trade-related event can receive up to fifty percent of the gap between their pre-and post-displacement wages for up to two years. 

Similarly, reforms to unemployment insurance in the U.S. can help safeguard against the harms associated with shocks to labor demand. Several proposals to modernize UI benefits such as determining eligibility based on hours worked rather than earnings, and expanding eligibility to workers seeking part-time work and those working as independent contractors warrant consideration by policymakers.


\1 \textbf{Investment in the development and evaluation of innovative worker training programs and AI literacy initiatives}

Investment in worker training and AI literacy initiatives can help prepare workers for the changing labor market and ensure they have the skills needed to succeed in the future of work. One approach is to invest in apprenticeship programs that combine on-the-job training with classroom instruction. These programs can help workers gain the technical skills and practical experience needed to succeed in high-demand occupations. \cite{Reed2012} Policymakers should consider investing in initiatives that promote AI literacy, such as training programs that teach workers how to use and understand AI technologies. \cite{AIliteracy2020} Establishing public-private partnerships and providing incentives for businesses to invest in workforce development alongside AI adoption is another promising approach to help workers adapt to the changing nature of many jobs.


\1 \textbf{Investments in technology and information systems to make job transitions easier for workers}

Improving the quality and accessibility of labor market information for workers and employers through, for example, expanded public-private data sharing partnerships between employers and American Job Centers can help provide up-to-date information on job openings, reducing search costs and mitigating the effects of job transitions for workers.  

\end{outline}

In the longer term, larger-scale policy innovation may be needed if model capabilities advance to the point where aggregate labor demand diminishes. Given the difficulty of predicting long-run labor market impacts, it is worthwhile to experiment and prototype large-scale safety net expansions such as Universal Basic Income and consider updated tax policy proposals in a future with significantly less demand for human labor.



\textbf{Discussion of relationship between our results here and other outcomes like job satisfaction, overreliance/dependency, impacts on skill development.}

In light of our findings that subsequent generations of LLMs possess the capacity to significantly transform and modify the employment landscape in the US, it becomes imperative to contextualize these results within the broader milieu of workforce dynamics and human development. In this discussion, we elucidate three key areas that warrant attention in understanding the implications of LLMs in these domains:

1. Job Satisfaction: The proliferation of LLMs in various occupational sectors may precipitate shifts in job roles and responsibilities, altering the nature of work and potentially impacting employee job satisfaction. As tasks traditionally performed by humans are increasingly automated, workers may experience a reconfiguration of their roles that could engender a sense of diminished agency and fulfillment. Conversely, the reduction of repetitive and menial tasks may also present opportunities for employees to engage in more meaningful work. We recommend further empirical inquiry into the nuanced relationships between LLM integration and job satisfaction..

2. Overreliance and skill development: The increased integration of LLMs into various occupational sectors raises concerns about overreliance and dependency on these technologies.\cite{passi2022overreliance} Studies have found that overreliance on AI systems, characterized by acceptance of incorrect recommendations and modification of responses to align with AI suggestions, can contribute to diminished human autonomy and critical thinking. Furthermore, dependency on LLMs for decision-making and task completion may result in the underdevelopment of critical human skills, such as problem-solving, analysis, and creativity. This can lead to increased vulnerability in the face of technological failures or security breaches. As the demand for certain skills diminishes in light of LLM-driven automation, there may be a concomitant need to reorient skill development initiatives to equip the workforce with competencies that are complementary to LLMs. This includes skills such as AI literacy and the ability to check sources. Our research underscores that reskilling to jobs that are available today may not be sufficient to make workers robust to changes in the labor market given the rapid development of AI technologies.

\textbf{Why you should care about economic impacts}

\textbf{Case for this being different, research on how much automation jobs/industries can absorb or withstand}

\subsection{Limitations and future work}

This study has several limitations that we hope to address in future work. For one, we focus on the US given data availability, but we acknowledge that adoption and impacts of generative models will vary across different countries and contexts due to technological infrastructure, regulatory frameworks, linguistic diversity, and cultural contexts. We hope to expand this study in the future both by doing further analysis ourselves and by releasing our methods so that others can replicate it across different datasets and by using different exposure scoring methods that leverage LLMs.

We hope to follow this work with two additional studies: one that investigates the adoption patterns and barriers of ChatGPT and similar systems across different sectors and occupations, and another that examines the actual capabilities and limitations of the latest models as they relate to worker activity, beyond what our exposure scores capture. In some respects, we expect that our exposure scores map reasonably onto the capabilities of the latest models, given what labelers reported when we asked them. Moreover, given the latest models' performance on various evaluations and standardized tests, it does seem reasonable to suggest that they could complete many low-stakes and low-variability closed tasks. However, we also recognize that there may be gaps between theoretical and practical performance, especially when it comes to more complex, open-ended, and domain-specific tasks. Moreover, our scores do not account for the actual ease. Some closed tasks are likely so routine that an expert can likely complete them on their own faster than they can using ChatGPT. This also may change once the models have been more closely embedded into existing systems (note: add something about automation/augmentation).

We are excited by the uptick in experimental studies on how using generative models assists individual workers in various tasks, such as writing and coding. We believe that these studies provide valuable insights into the potential benefits and challenges of integrating generative models into work processes. However, as discussed above, there are limitations to the task-framing of jobs altogether. We expect more research into what drives systemic adoption of generative models will be necessary, particularly when it comes to understanding what kind of bottlenecks exist. For instance, one important factor that affects how useful these models are for decision-making is the level of confidence that humans have in their summaries. If humans still need to check the original documents or do their own research, then the models will not save much time or effort. However, if humans can trust the models to accurately and comprehensively capture the relevant information, then they can make faster and better decisions based on the summaries. The adoption of these models will also vary depending on the cost and flexibility of the technology, as well as the preferences and incentives of different workers and firms. For example, courts may be more reluctant to use generative models than other legal actors, because they have more formal and conservative procedures, or because they face less competitive pressure to reduce costs or increase efficiency. This means that even if generative models can make legal services more accessible and affordable by allowing lawyers to handle more cases and, accordingly, charge lower fees, it may not speed up the resolution of cases if the courts are still slow to process them. Similar barriers and differences may exist in other sectors of the economy, where the adoption of these models may depend on the availability of data, the quality of regulation, the culture of innovation, or the distribution of power and interests.

We expect that ease of adoption will be primary driver here -- time saved will be more important quality improvement for majority of tasks, focus on both capabiltiies and AGI misses that -- eventually will be about cost savings but not for initial adoption (augmentation first, then automation -- in part because this helps work/jobs become more precarious before automation)

\input{tables/top_jobs_sample}


\section{Conclusion @all draft after rest is filled in}
\label{sec:conclusion}

Conclusion: We want to emphasize diversified job design. No job fully lines up to the canonical setup. There are definitely cases where the role can be fully automated. Industrial organization. Jobmakers should think about what jobs should look like. Sometimes we design jobs to act as machines. Let's think about what constitutes a job or a function that is suited to a person.

\begin{comment}
The documentation for \verb+natbib+ may be found at
\begin{center}
  \url{http://mirrors.ctan.org/macros/latex/contrib/natbib/natnotes.pdf}
\end{center}
Of note is the command \verb+\citet+, which produces citations
appropriate for use in inline text.  For example,
\begin{verbatim}
   \citet{hasselmo} investigated\dots
\end{verbatim}
produces
\begin{quote}
  Hasselmo, et al.\ (1995) investigated\dots
\end{quote}

\begin{center}
  \url{https://www.ctan.org/pkg/booktabs}
\end{center}






\begin{figure}
  \centering
  \fbox{\rule[-.5cm]{4cm}{4cm} \rule[-.5cm]{4cm}{0cm}}
  \caption{Sample figure caption.}
  \label{fig:fig1}
\end{figure}

\subsection{Tables}
\lipsum[12]
See awesome Table~\ref{tab:table}.

\begin{table}
 \caption{Sample table title}
  \centering
  \begin{tabular}{lll}
    \toprule
    \multicolumn{2}{c}{Part}                   \\
    \cmidrule(r){1-2}
    Name     & Description     & Size ($\mu$m) \\
    \midrule
    Dendrite & Input terminal  & $\sim$100     \\
    Axon     & Output terminal & $\sim$10      \\
    Soma     & Cell body       & up to $10^6$  \\
    \bottomrule
  \end{tabular}
  \label{tab:table}
\end{table}
\end{comment}

\section*{Acknowledgments}
Thank you to the group of labelers who helped us annotate task exposure, including Muhammad Ahmed Saeed, Bongane Zitha, Merve Özen Şenen, J.J., Peter Hoeschele, +other openai people. We also thank Lauryn Fuld, Ashley Glat, and Julia Susser for excellent research assistance. We thank various OpenAI engineers and researchers for help setting up the infrastructure for running the taxonomies, for training the models, and for advice on writing taxonomies for these models including Todor Markov, Andrea Vallone, and Vik Goel. We thank XYZ for feedback and edits at various stages of the project.

\appendix

\section{Taxonomies}

\subsection{Exposure}

\input{exposure_taxonomy}

\subsection{Augmentation}

\subsection{Automation}

\subsection{SLLM}

\subsection{Skills}

%Bibliography
% \bibliographystyle{unsrt}  

\bibliographystyle{apalike} 

\bibliography{references}  


\end{document}


