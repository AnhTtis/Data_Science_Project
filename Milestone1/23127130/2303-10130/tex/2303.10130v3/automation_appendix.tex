Our automation exposure measures are a proof-of-concept that GPT-4 may be able to evaluate its own potential to automate specific tasks, but we have not validated the GPT-4 evaluations against the judgement of human raters. Of course this rubric has all of the same weaknesses as the exposure rubric, but additionally was not validated with human evaluation. The results we find, however, suggest some intuitive findings and broadly have high correlation with the exposure measures. Still, these are still early results. To convert our automation labels from the rubric into numerical scores, we consider T0 (no exposure to automation) as a score of 0, T4 as full exposure to have a score of 1, then T1, T2, and T3 to have scores of 0.25, 0.5, and 0.75 respectively. This maps our T rubric scores into numerical scores between 0 and 1. Preliminary results suggest exposure as defined in the E rubric scores from GPT-4 and automation as defined in the T rubric have a strong positive association. Table \ref{tab:autoscores_sumstats} contains summary statistics on our GPT-4 evaluations of the automation rubric.  \ref{tab:expauto_regression} shows the regression results from a regression of GPT-4 $\beta$ exposure scores on GPT-4 automation ratings. Figure \ref{fig:autoexp_totalexp} shows the scatterplot of the same exposure scores against the automation scores we generate at the task level, and Figure \ref{fig:dvt_binscatter} shows the binscatter of automation score exposure against log wage rated at the occupation-level. We see similar trends in these early GPT-4 measures of automation as we do in overall exposure.

\input{tables/automation_sum_stats}

\begin{table}[]
\begin{threeparttable}
    \centering
    \resizebox{\textwidth}{!}{
    \input{tables/exposure_automation_regression}
    }
    \caption{Regression of GPT-4 Exposure Rubric Scores on GPT-4 Automation Rubric Scores}
    \label{tab:expauto_regression}
    \begin{tablenotes}
        \item Table Notes: The table shows the regression of our GPT-4 Exposure Rubric scores following the $\beta$ convention described above on the GPT-4 Automation Score as defined by the Automation ("T") rubric. The unit of observation is the task. T0, T1, T2, T3, and T4 are mapped to scores of 0, 0.25, 0.5, 0.75, and 1 respectively. In both cases, the automation score explains about half of the variance of the exposure scores.
    \end{tablenotes}
\end{threeparttable}
\end{table}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/autovexp.png}
    \caption{GPT-4 Ratings of Automation Exposure ("T") vs. Overall Exposure ("E")}
\label{fig:autoexp_totalexp}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/dvT_logsal_binscatter.png}
    \caption{Binscatter of GPT-4 Automation Exposure Ratings by Occupation vs. Log Wages}
\label{fig:dvt_binscatter}
\end{figure}

To measure exposure, we keep the 50\% constant and vary the tools the subject has access to. To measure automation and augmentation we keep the tools constant and vary the amount of time access to the tools saves a human. 

\subsubsection{Automation Exposure}
We define automation as the share of a task GPT-powered system may be able to complete with high quality when prompted by a human, and over five values ranging form full automatability to no automatability. We define high quality as whether a human receiving or reviewing the process or output would notice, realize, or care the work was done by a GPT-powered system. The full rubric can be reviewed in \ref{automation_tax}.

%: T4 (full automation -- model can do 100 percent of the task), T3 (high automation -- model can do 90-100 percent of the task, with human oversight), T2 (moderate automation -- model can do 50-90 percent of the task), T1 (low automation -- model can do 0-50 percent of the task), T0 (no automation -- model cannot perform a meaningful percentage of the task). We prompted GPT-4 with taxonomy \ref{automation_tax} to generate annotations for automation on each O*NET task. We did not collect human annotations based on this automation taxonomy.

 \input{tables/automation_sum_stats}

 Regressing exposure scores on the automation scores (the \ref{automation_tax} rubric), we find a strong positive relationship (see Table \ref{tab:expauto_regression}. The automation score has a coefficient of 0.87 (standard error 0.008). Overall exposure and automation exposure are highly correlated, with an $R^2$ of 46.4 percent in a univariate regression of exposure scores on automation scores at the task-level. This means that where automation is high, it is likely the case that exposure, which includes augmentation potential, is also relatively high. Automation and augmentation potential will often co-occur, as in \cite{autor2022new}.

Automation exposure ratings follow a similar trend to general exposure ratings (see Figure \ref{fig:dvt_binscatter}). Higher wage occupations tend to be more likely to have automatable tasks. No occupation has 100 percent of tasks exposed to automation by GPT under this rubric, though many occupations have high levels of exposure that suggest they might be reconfigured entirely. Occupations with the highest automation exposure include telephone operators (88 percent of tasks), travel agents (78 percent), word processors and typists (78 percent), credit authorizers, checkers, and clerks (77.5 percent), desktop publishers (77.4 percent), and telemarketers (76 percent).

In light of this, emphasizing augmentation instead of automation may not be useful in charting a path forward for designing jobs. Even in cases where it is possible to prioritize augmentation, market-level factors like price and income elasticities of supply and demand (among others) dictate the extent to which individual workers are aided or displaced by new configurations of work \cite{brynjolfsson2017can}. Our evidence suggests an unclear path forward for LLMs as general purpose technologies. Whether workers are displaced or complemented on balance will depend on the particulars of the application and emergent use cases as new systems and complements emerge. Based on this evidence, it is also premature to suggest that high broad-based exposure implies the wholesale elimination of jobs for similar reasons.

\subsection{Automation vs. Augmentation}
\begin{comment}
We find a strong positive relationship between our measures of exposure and automation (see Table X). This means that where automation is high, it is likely the case that exposure, which includes augmentation potential, is also relatively high. 

    

\begin{figure}
    \centering
\includegraphics[width=0.52\textwidth]{figures/dvT_logsal_binscatter.png}
    \caption{This figure refers explicitly to the automation ("T") rubric \ref{automation_tax}, which asks GPT-4 to evaluate the potential of an LLM plus additional software to automate tasks instead of impacting them in some general sense. For these annotations, we code no exposure as 0, partial exposure of the lowest level as 0.25, partial exposure at the medium level as 0.5, partial exposure at a high level as 0.75, and full exposure as 1.}
\label{fig:dvt_binscatter}\end{figure}
 \end{comment}

 % Figure \ref{fig:dvt_binscatter} refers explicitly to the automation ("T") rubric, which asks the GPT-4 model to evaluate its own potential to automate tasks instead of impacting them in some general sense. For these labels, we code no exposure as 0, partial exposure of the lowest level as 0.25, partial exposure at the medium level as 0.5, partial exposure at a high level as 0.75, and full exposure as 1. 


%Comparing our GPT-4-generated exposure scores to the GPT-4 automation scores, we find that tasks with high exposure overall tend to also have high exposure to automation. Regressing exposure on automation scores, we find that automation scores explain 55.6 percent of the variation in overall exposure (coefficient of 0.936 with robust standard error 0.006).\footnote{This is following our $\beta$ measurement convention, details below.} One interpretation of this coefficient is that automation potential describes a little more than half of overall LLM exposure. Another is that occupations with high automation exposure might also have high augmentation exposure. Despite calls to focus on augmentation applications \cite{frank2019toward, brynjolfsson2022turing}, these results suggest it may be difficult in practice to identify the augmentation or automation facets of LLM implementationin advance. 