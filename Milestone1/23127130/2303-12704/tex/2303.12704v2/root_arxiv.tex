\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper
\usepackage[utf8]{inputenc}
\usepackage[parfill]{parskip}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage[final]{pdfpages}


\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.

%In case you encounter the following error:
%Error 1010 The PDF file may be corrupt (unable to open PDF file) OR
%Error 1000 An error occurred while parsing a contents stream. Unable to analyze the PDF file.
%This is a known problem with pdfLaTeX conversion filter. The file cannot be opened with acrobat reader
%Please use one of the alternatives below to circumvent this error by uncommenting one or the other
%\pdfobjcompresslevel=0
%\pdfminorversion=4

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
%\usepackage{amsmath} % assumes amsmath package installed
%\usepackage{amssymb}  % assumes amsmath package installed

\title{\LARGE \bf
AptSim2Real: Approximately-Paired Sim-to-Real Image Translation }


% \author{Charles Y Zhang$^{1*}$ and Ashish Shrivastava$^{2}$% <-this % stops a space
% \thanks{$*$Work done during internship at Cruise LLC.}% <-this % stops a space
% \thanks{$^{1}$University of Waterloo, Canada
%         {\tt\small cy9zhang@uwaterloo.ca}}%
% \thanks{$^{2}$Cruise LLC, San Francisco, CA, USA.
%         {\tt\small ashish.shrivastava@getcruise.com}}%
% }


\author{{\textbf {Charles Y Zhang}$^*$} \\
{ \small University of Waterloo, Canada}\\
 {\tt\small cy9zhang@uwaterloo.ca}
\and
{\textbf {Ashish Shrivastava}} \\
{ \small Cruise LLC, United States}\\
{\tt\small ashish.shrivastava@getcruise.com}
\thanks{$^*$Work done during internship at Cruise LLC.}% <-this % stops a space
}

% \author{Charles Y Zhang$^{1*}$} and \author{Ashish Shrivastava$^{2}$% <-this % stops a space
% \thanks{$*$Work done during internship at Cruise LLC.}% <-this % stops a space
% \thanks{$^{1}$University of Waterloo, Canada
%         {\tt\small cy9zhang@uwaterloo.ca}}%
% \thanks{$^{2}$Cruise LLC, San Francisco, CA, USA.
%         {\tt\small ashish.shrivastava@getcruise.com}}%
% }


\graphicspath{{figures/}} %Setting the graphicspath

% \usepackage[switch, displaymath, mathlines]{lineno}
% \linenumbers

\begin{document}
   
\maketitle
\thispagestyle{empty}
\pagestyle{empty}

\begin{abstract}
\input{abstract.tex}
\end{abstract}

\section{Introduction}
\input{intro.tex}

\section{Related Works}
\input{related_works.tex}
\section{Method}
\input{method.tex}

\section{Experiments}
\input{experiments.tex}

% \section{Ablation}

\input{ablation.tex}
\input{training_details.tex}


\input{conclusion.tex}

\textbf{Acknowledgement:} 
We are grateful to our colleagues Surya Dwarakanath, Luyu Yang, Abhishek Sharma, Ambrish Tyagi, Zhao Chen, and Yuning Chai for their unwavering support and valuable suggestions.

% \bibliographystyle{IEEEtran}
% \bibliography{mybib}
\begin{thebibliography}{10}
    \providecommand{\url}[1]{#1}
    \csname url@rmstyle\endcsname
    \providecommand{\newblock}{\relax}
    \providecommand{\bibinfo}[2]{#2}
    \providecommand\BIBentrySTDinterwordspacing{\spaceskip=0pt\relax}
    \providecommand\BIBentryALTinterwordstretchfactor{4}
    \providecommand\BIBentryALTinterwordspacing{\spaceskip=\fontdimen2\font plus
    \BIBentryALTinterwordstretchfactor\fontdimen3\font minus
      \fontdimen4\font\relax}
    \providecommand\BIBforeignlanguage[2]{{%
    \expandafter\ifx\csname l@#1\endcsname\relax
    \typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
    \typeout{** loaded for the language `#1'. Using the pattern for}%
    \typeout{** the default language instead.}%
    \else
    \language=\csname l@#1\endcsname
    \fi
    #2}}
    
    \bibitem{akkaya2019solving}
    I.~Akkaya \emph{et~al.}, ``Solving rubik's cube with a robot hand,''
      \emph{arXiv preprint arXiv:1910.07113}, 2019.
    
    \bibitem{lee2020learning}
    J.~Lee, J.~Hwangbo, L.~Wellhausen, V.~Koltun, and M.~Hutter, ``Learning
      quadrupedal locomotion over challenging terrain,'' \emph{Science robotics},
      2020.
    
    \bibitem{wang2020tartanair}
    W.~Wang, D.~Zhu, X.~Wang, Y.~Hu, Y.~Qiu, C.~Wang, Y.~Hu, A.~Kapoor, and
      S.~Scherer, ``Tartanair: A dataset to push the limits of visual slam,'' in
      \emph{Proc. IROS}, 2020.
    
    \bibitem{wood2021fake}
    E.~Wood, T.~Baltrusaitis, C.~Hewitt, S.~Dziadzio, M.~Johnson, V.~Estellers,
      T.~Cashman, and J.~Shotton, ``Fake it till you make it: Face analysis in the
      wild using synthetic data alone,'' in \emph{Proc. ICCV}, 2021.
    
    \bibitem{haiderbhai2022dvrksim2real}
    M.~Haiderbhai, R.~Gondokaryono, T.~Looi, J.~M. Drake, and L.~A. Kahrs, ``Robust
      sim2real transfer with the da vinci research kit: A study on camera,
      lighting, and physics domain randomization,'' in \emph{Proc. IROS}, 2022.
    
    \bibitem{simgan2017}
    A.~Shrivastava, T.~Pfister, O.~Tuzel, J.~Susskind, W.~Wang, and R.~Webb,
      ``Learning from simulated and unsupervised images through adversarial
      training,'' in \emph{Proc. CVPR}, 2017.
    
    \bibitem{pmlr-style-equalization}
    J.-H.~R. Chang, A.~Shrivastava, H.~Koppula, X.~Zhang, and O.~Tuzel, ``Style
      equalization: Unsupervised learning of controllable generative sequence
      models,'' in \emph{Proc. ICML}, 2022.
    
    \bibitem{park2020cut}
    T.~Park, A.~A. Efros, R.~Zhang, and J.-Y. Zhu, ``Contrastive learning for
      unpaired image-to-image translation,'' in \emph{Proc. ECCV}, 2020.
    
    \bibitem{CycleGAN2017}
    J.-Y. Zhu, T.~Park, P.~Isola, and A.~A. Efros, ``Unpaired image-to-image
      translation using cycle-consistent adversarial networks,'' in \emph{Proc.
      ICCV}, 2017.
    
    \bibitem{gan_2014}
    I.~Goodfellow, J.~Pouget-Abadie, M.~Mirza, B.~Xu, D.~Warde-Farley, S.~Ozair,
      A.~Courville, and Y.~Bengio, ``Generative adversarial nets,'' in \emph{Proc.
      NeuRIPS}, 2014.
    
    \bibitem{biggan_iclr_2019}
    A.~Brock, J.~Donahue, and K.~Simonyan, ``Large scale {GAN} training for high
      fidelity natural image synthesis,'' in \emph{Proc. ICLR}, 2019.
    
    \bibitem{adain_cvpr_2017}
    X.~Huang and S.~Belongie, ``Arbitrary style transfer in real-time with adaptive
      instance normalization,'' in \emph{Proc. ICCV}, 2020.
    
    \bibitem{msggan_cvpr_2020}
    A.~Karnewar and O.~Wang, ``{MSG-GAN}: Multi-scale gradients for generative
      adversarial networks,'' in \emph{Proc. CVPR}, 2020.
    
    \bibitem{progressive_gan_2017}
    T.~Karras, T.~Aila, S.~Laine, and J.~Lehtinen, ``Progressive growing of {GAN}s
      for improved quality, stability, and variation,'' in \emph{Proc. ICLR}, 2018.
    
    \bibitem{stylegan}
    T.~Karras, S.~Laine, and T.~Aila, ``A style-based generator architecture for
      generative adversarial networks,'' in \emph{Proc. CVPR}, 2019.
    
    \bibitem{WasserstineGAN_2017}
    I.~Gulrajani, F.~Ahmed, M.~Arjovsky, V.~Dumoulin, and A.~C. Courville,
      ``Wasserstine {GAN},'' in \emph{Proc. NeuRIPS}, 2017.
    
    \bibitem{SAGAN_2018}
    H.~Zhang, I.~Goodfellow, D.~Metaxas, and A.~Odena, ``Self-attention generative
      adversarial networks,'' \emph{CoRR, abs/1805.08318}, 2018.
    
    \bibitem{stackgan_2018}
    H.~Zhang, T.~Xu, H.~Li, S.~Zhang, X.~Huang, X.~Wang, and D.~N. Metaxas,
      ``{StackGAN}: Text to photo-realistic image synthesis with stacked generative
      adversarial networks,'' in \emph{Proc. ICCV}, 2017.
    
    \bibitem{stackgan_pp_2017}
    H.~Zhang, T.~Xu, H.~Li, S.~Zhang, X.~Wang, X.~Huang, and D.~N. Metaxas,
      ``{StackGAN++}: Realistic image synthesis with stacked generative adversarial
      networks,'' \emph{CoRR}, vol. abs/1710.10916, 2017.
    
    \bibitem{cogan_2016}
    M.-Y. Liu and O.~Tuzel, ``Coupled generative adversarial networks,'' in
      \emph{Proc. NeuRIPS}, 2016.
    
    \bibitem{lsgan_2017}
    X.~Mao, Q.~Li, H.~Xie, R.~Y.~K. Lau, and Z.~Wang, ``Multi-class generative
      adversarial networks with the {L2} loss function,'' in \emph{Proc. ICCV},
      2016.
    
    \bibitem{karras2021_stylegan3aliasfree}
    T.~Karras, M.~Aittala, S.~Laine, E.~H{\"a}rk{\"o}nen, J.~Hellsten, J.~Lehtinen,
      and T.~Aila, ``Alias-free generative adversarial networks,'' in \emph{Proc.
      NeuRIPS}, 2021.
    
    \bibitem{isola2017_pix2pix}
    P.~Isola, J.-Y. Zhu, T.~Zhou, and A.~A. Efros, ``Image-to-image translation
      with conditional adversarial networks,'' in \emph{Proc. CVPR}, 2017.
    
    \bibitem{Qu_2019_CVPR}
    Y.~Qu, Y.~Chen, J.~Huang, and Y.~Xie, ``Enhanced pix2pix dehazing network,'' in
      \emph{Proc. CVPR}, 2019.
    
    \bibitem{cond_gan_cvpr_2020}
    T.~Wang, M.~Liu, J.~Zhu, A.~Tao, J.~Kautz, and B.~Catanzaro, ``High-resolution
      image synthesis and semantic manipulation with conditional gans,'' in
      \emph{Proc. CVPR}, 2020.
    
    \bibitem{instaformer_2022}
    S.~Kim, J.~Baek, J.~Park, G.~Kim, and S.~Kim, ``{InstaFormer}: Instance-aware
      image-to-image translation with transformer,'' in \emph{Proc. CVPR}, 2022.
    
    \bibitem{Scribbler_cvpr_2017}
    P.~Sangkloy, J.~Lu, C.~Fang, F.~Yu, and J.~Hays, ``Scribbler: Controlling deep
      image synthesis with sketch and color,'' in \emph{Proc. CVPR}, 2017.
    
    \bibitem{attr_layout_to_img_2016}
    L.~Karacan, Z.~Akata, A.~Erdem, and E.~Erdem, ``Learning to generate images of
      outdoor scenes from attributes and semantic layouts,'' \emph{CoRR}, vol.
      abs/1612.00215, 2016.
    
    \bibitem{unsup_img2img_gen_prior_2022}
    S.~Yang, L.~Jiang, Z.~Liu, and C.~C. Loy, ``Unsupervised image-to-image
      translation with generative prior,'' in \emph{Proc. CVPR}, 2022.
    
    \bibitem{unsup_im2im_dense_consistensy_2022}
    M.~Ko, E.~Cha, S.~Suh, H.~Lee, J.-J. Han, J.~Shin, and B.~Han,
      ``Self-supervised dense consistency regularization for image-to-image
      translation,'' in \emph{Proc. CVPR}, 2022.
    
    \bibitem{paired_and_unpaired_accv_2018}
    S.~Tripathy, J.~Kannala, and E.~Rahtu, ``Learning image-to-image translation
      using paired and unpaired training samples,'' in \emph{Proc. ACCV}, 2019.
    
    \bibitem{Mustafa_eccv_2020}
    A.~Mustafa and R.~K. Mantiuk, ``Transformation consistency regularization- {A}
      semi-supervised paradigm for image-to-image translation,'' in \emph{Proc.
      ECCV}, 2020.
    
    \bibitem{onesided_gan_2017}
    S.~Benaim and L.~Wolf, ``One-sided unsupervised domain mapping,'' in
      \emph{Proc. NeuRIPS}, 2017.
    
    \bibitem{Resnet_He2015}
    K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Deep residual learning for image
      recognition,'' in \emph{Proc. CVPR}, 2016.
    
    \bibitem{Karras2019stylegan2}
    T.~Karras, S.~Laine, M.~Aittala, J.~Hellsten, J.~Lehtinen, and T.~Aila,
      ``Analyzing and improving the image quality of {StyleGAN},'' in \emph{Proc.
      CVPR}, 2020.
    
    \bibitem{Projected_gans}
    A.~Sauer, K.~Chitta, J.~M\"{u}ller, and A.~Geiger, ``Projected {GANs} converge
      faster,'' in \emph{Proc. NeuRIPS}, 2021.
    
    \bibitem{gantutorial}
    I.~J. Goodfellow, ``{NIPS} 2016 tutorial: Generative adversarial networks,''
      \emph{CoRR}, vol. abs/1701.00160, 2017.
    
    \bibitem{adam}
    D.~P. Kingma and J.~Ba., ``Adam: A method for stochastic optimization,'' in
      \emph{ICLR}, 2015.
    
    \bibitem{gan_ema}
    Y.~Yazıcı, C.-S. Foo, S.~Winkler, K.-H. Yap, G.~Piliouras, and
      V.~Chandrasekhar, ``The unusual effectiveness of averaging in {GAN}
      training,'' \emph{CoRR}, vol. abs/1806.04498, 2018.
    
    \end{thebibliography}
    
\end{document}
