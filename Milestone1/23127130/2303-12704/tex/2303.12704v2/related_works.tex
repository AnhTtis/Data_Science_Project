
Generative Adversarial Networks (GANs)~\cite{gan_2014} employ a critic, also known as a discriminator, to differentiate between real and fake data inputs.
GANs are widely used in image translation, as training a generative model to fool the critic (discriminator) has proven effective in closing distribution gaps.
As GAN methods have advanced (~\cite{biggan_iclr_2019, adain_cvpr_2017, msggan_cvpr_2020, progressive_gan_2017, stylegan, WasserstineGAN_2017, gan_2014, SAGAN_2018, stackgan_2018, stackgan_pp_2017, cogan_2016, lsgan_2017, karras2021_stylegan3aliasfree}), the performance of image translation has also improved.

Paired image translation uses an input, typically in the form of a label such as a semantic segmentation map or edge map, to generate a new output image~\cite{isola2017_pix2pix, Qu_2019_CVPR, cond_gan_cvpr_2020, instaformer_2022, Scribbler_cvpr_2017, attr_layout_to_img_2016}. 
Paired image translation uses pixel-wise correspondences to jointly optimize an L1 loss between the predicted and target images alongside an adversarial loss to achieve high accuracy.

Unpaired image translation lacks the pixel-wise correspondences of paired image translation and instead utilizes alternative loss functions. For example, SimGAN~\cite{simgan2017}  regularizes the difference between the input and output of the model, CycleGAN~\cite{CycleGAN2017} optimizes for cycle-consistency, and CUT~\cite{park2020cut} maximizes mutual information between the input and output of the generator. 
While other methods have been proposed(~\cite{CycleGAN2017, park2020cut, simgan2017, unsup_img2img_gen_prior_2022, unsup_im2im_dense_consistensy_2022}), CycleGAN and CUT remain popular choices for unpaired image translation.

Combining paired and unpaired image translation has also been proposed for datasets that have a mix of paired and unpaired images~\cite{paired_and_unpaired_accv_2018,Mustafa_eccv_2020}. 
In contrast, our method does not rely on pixel-wise correspondences, generates approximately-paired synthetic images through simulation, and leverages these approximate pairings with state-of-the-art GAN techniques.