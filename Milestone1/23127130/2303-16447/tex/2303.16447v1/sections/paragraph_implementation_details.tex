\subsection{Training details}
We initialize the MLP parameters such that the initial zero level set approximates a sphere with a radius $0.6$~\cite{sal2020cvpr}.
We set $\lambda_1=100$ and $\lambda_2=0.1$ for the loss function. 
ADAM optimizer is used with an initial learning rate $1\times 10^{-4}$.
We optimize the MLP parameters for $50$ epochs with a batchsize $4096$ pixels.
The learning rate and $\alpha$ in silhouette loss are divided by $2$ every $10$ epochs.

As most pixels from the input images are outside silhouette, randomly sampling from all pixels can be inefficient for training.
To improve the efficiency, we dilate the silhouette (\ie, the boundary of the mask) for $30$ times and sample pixels from the expanded regions as input.
For \diligentmv~\cite{li2020multi} objects, we use their provided masks.
For \pandora~\cite{dave2022pandora} and our captured images, we use an automatic image background removal tool~\cite{removebg} to generate the masks.
The input image dimensions are $612 \times 512$ for \diligentmv~\cite{li2020multi}, $1224 \times 1024$ for \pandora~\cite{dave2022pandora},  and $1566 \times 1045$ for our objects.

The training took about $3$ hours per \diligentmv object~\cite{li2020multi}, about $7$ hours per PANDORA object~\cite{dave2022pandora}, and about $10$ hours for our captured objects using one GTX 2080Ti graphics card.
As a comparison, \psnerf took about $22$ hours to train one  \diligentmv object~\cite{yang2022psnerf}.
It took us about 30 hours to reproduce \pandora results per object~\cite{dave2022pandora}.