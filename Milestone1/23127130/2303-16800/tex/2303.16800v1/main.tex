% \documentclass{uai2023}
\documentclass[accepted]{uai2023}
\usepackage[utf8]{inputenc}
\usepackage{philip}

\newcommand\xqed[1]{%
  \leavevmode\unskip\penalty9999 \hbox{}\nobreak\hfill
  \quad\hbox{#1}}
\newcommand\exqed{\xqed{$\triangle$}}

\setlength{\tabcolsep}{5pt}

\title{Correcting for Selection Bias and Missing Response \\ in Regression using Privileged Information}
% \title{Correcting for Nonignorable Selection Bias and Missing Response \\ in Regression using Privileged Information}
% Repeated regression in titel?
% \title{Correcting for Missing Not at Random Selection Bias and Missing Response \\ in Regression using Privileged Information}
% \title{Correcting for Selection Bias and Missing Response in Regression}
% \title{Correcting for Selection Bias and Missing Response in Regression\\ and an Empirical Evaluation of Paradigms}
% \title{On Regression with Selection Bias or Missing Labels}
% \title{Regression with Selection Bias or Missing Labels using Privileged Information}

\author[1,2]{\href{mailto:philip.boeken@gmail.com?subject=Your UAI 2023 paper}{Philip~Boeken}}
\author[1]{Noud~de~Kroon}
\author[2]{Mathijs~de~Jong}
\author[1]{Joris~M.~Mooij}
\author[2]{Onno~Zoeter}
\affil[1]{%
    Korteweg-de Vries Institute for Mathematics\\
    University of Amsterdam\\
    The Netherlands
}
\affil[2]{%
    Booking.com\\
    The Netherlands
}

\begin{document}

\maketitle

\begin{abstract}
    When estimating a regression model, we might have data where some labels are missing, or our data might be biased by a selection mechanism.
    When the response or selection mechanism is \emph{ignorable} (i.e., independent of the response variable given the features) one can use off-the-shelf regression methods; in the \emph{nonignorable} case one typically has to adjust for bias. We observe that \emph{privileged data} (i.e.\ data that is only available during training) might render a nonignorable selection mechanism ignorable, and we refer to this scenario as \emph{Privilegedly Missing at Random} (PMAR). We propose a novel imputation-based regression method, named \emph{repeated regression}, that is suitable for PMAR. We also consider an importance weighted regression method, and a doubly robust combination of the two. The proposed methods are easy to implement with most popular out-of-the-box regression algorithms. We empirically assess the performance of the proposed methods with extensive simulated experiments and on a synthetically augmented real-world dataset. We conclude that repeated regression can appropriately correct for bias, and can have considerable advantage over weighted regression, especially when extrapolating to regions of the feature space where response is never observed.
\end{abstract}

% {\small\noindent\textbf{Keywords}: Regression, Selection Bias, Missingness, Privileged Information, Imputation, Pseudo-labels, Semi-supervised learning, Importance Weighting, Double Robustness.}

\section{Introduction}
Regression is a primary technique in data science, machine learning and statistics. When presented with data $(X_1, Y_1), ..., (X_n, Y_n)$ sampled from the distribution $\PP(X, Y)$, the goal is to find the conditional expectation of $Y$ given $X$, i.e.\ estimate the function $\mu(x) = \EE[Y|X=x]$. Practitioners are often presented with either incomplete data (where some values are missing) or data that is not representative of the population (drawn from some other $\tilde{\PP}(X, Y)$ with $\tilde{\PP} \neq \PP$), and hence have to correct for the bias that is present in their training data. The discrepancy between $\tilde{\PP}$ and $\PP$ can for example be induced by a selection mechanism.

Consider the following example of a follow-up study of HIV-positive individuals, where we are interested in the prediction of the 3-year risk of death ($Y$) after a certain antiretroviral drug dosage ($X$) has been administered \citep{hernan2021causal}. Severe side effects of the drug ($Z$) might cause the patient to drop out of the study, censoring the measurement of $Y$. When other factors than drug dosage influence the side effects $Z$ and the outcome $Y$, one must include measurements of $Z$ in the dataset for correct estimation of the model $\EE[Y|X]$. As these side effects cannot be known before the drug has been administered, including $Z$ in the features of the model is undesirable when the model is used for e.g.\ optimising drug dosage (assuming the dosages are administered in a Randomized Controlled Trial). In this work, we demonstrate how one can incorporate such \emph{privileged information} in a regression model.

An important line of work on selection bias is by \cite{pearl2012solution} and \cite{bareinboim2014recovering}, who consider the problem of estimating $\PP(Y|X)$ from a potentially biased dataset by leveraging knowledge of the underlying causal graph. They derive an expression of $\PP(Y|X)$ as an integral of quantities that can be estimated from readily available biased and additional (`external') unbiased data. Although identification of a conditional distribution might be useful in certain scenarios, this does not tell the practitioner how to estimate a regression model, especially when dealing with continuous variables. In this work we address this problem, keeping in mind the applicability of the proposed methods.

Missingness problems are often characterised by the presence of certain conditional independencies in the data. Typically these independencies are untestable, making it unclear whether these conditional independence assumptions are appropriate for the data at hand. Drawing a causal graph of the data generating process is often helpful for gaining a better understanding of the problem. Moreover, the causal graph identifies conditional independencies in the data, and thereby allows the practitioner to motivate these conditional independence assumptions. As posed by \cite{rubin1976inference}:

\textit{``The inescapable conclusion seems to be that when dealing with real data, the practising statistician should explicitly consider the process that causes missing data far more often than he does. However, to do so, he needs models for this process and these have not received much attention in the statistical literature.''}
% \footnote{Quote taken from \cite{mohan2021graphical}.}

Contrary to what is often seen in the literature we do not need a full probabilistic model of the missingness mechanism, as the identification of certain conditional independencies can already be sufficient for estimating a regression model.

Our contributions are as follows. First, this paper serves a pedagogical purpose by reviewing literature of missingness and selection bias, as addressed in Section \ref{sec:missingness}. We address what the consequences of certain conditional independencies are for the practitioner. While doing so, we motivate the use of \emph{privileged information} \citep{vapnik2009new} when missingness or selection is nonignorable, and introduce the \emph{Privilegedly Missing at Random} setting (PMAR).
Secondly, in Section \ref{sec:methods} we formulate a novel imputation-based estimator for the PMAR setting, which we refer to as \emph{repeated regression}. We point out that importance weighted regression is also suitable for the PMAR setting, and combine the two methods into a doubly robust estimator.
These estimators are formulated such that they are easy to implement using out-of-the box regression algorithms.
We then address the intricacies of evaluation under selection bias and missingness in Section \ref{sec:evaluation}. We warn the practitioner that, to our knowledge, there is no appropriate way of evaluating a regression method on a finite, biased dataset without relying on auxiliary models.
Lastly, in Section \ref{sec:experiments} we assess the performance of the formulated methods on extensive simulated experiments and on synthetically augmented real-world data.\footnote{Code for the experiments will be made publicly available.} We observe that repeated regression has considerable advantage over importance weighting, especially when extrapolating.

\section{Missing data, selection bias and privileged information}\label{sec:missingness}
\subsection{Missing data mechanisms}
A very general framework for handling missing data is proposed by \cite{rubin1976inference}. When modelling the distribution of a set of random variables $X_1, ..., X_m$, this framework takes into account potential missing values of any of the $X_i$ by considering a random vector of \emph{response indicators}: binary variables $S_1, ..., S_m$, where $S_i = 1$ indicates that variable $X_i$ is observed. The process that determines whether we observe $X_i$ can be explicitly modelled as $\PP(S_i | X_1, ..., X_m)$. We then define the \emph{observed} random vector $X_1^o, ..., X_m^o$ where $X_i^o = X_i$ if $S_i=1$ and $X_i = ?$ if $S_i = 0$, where `?' denotes the value that is missing in the dataset.

\cite{rubin1976inference} proposed the following classification of missing data mechanisms, which approximately categorises the difficulty of many inference problems.
\begin{definition}{\citep{rubin1976inference}}
    Given variables $X, Y$, and response indicator $S$ for $Y$, we say that $Y$ is
    \begin{itemize}
        \item Missing Completely at Random (MCAR) if the missingness mechanism is independent of all other observed variables, i.e.\ $S\Indep X, Y$;
        \item Missing at Random (MAR) if the missingness mechanism is independent of the missing variable given all other fully observed variables, i.e.\ $Y \Indep S \given X$;
        \item Missing Not at Random (MNAR) if it is neither MCAR nor MAR.
    \end{itemize}
\end{definition}
% A missingness mechanism is often called \emph{ignorable} if one does not have to correct for bias in the inference problem at hand. Otherwise, it is called \emph{nonignorable}.
% Originally, \citeauthor{rubin1976inference} defined MCAR, MAR and MNAR in terms of independencies of events instead of variables.\footnote{According to \cite{mohan2021graphical}, it is rare that ``knowledge can be articulated in terms of event based independencies that are not implied by variable based independencies''.} For a comprehensive overview of missingness mechanisms, see \cite{little2021missing}. For a graphical approach to missingness, see \cite{thoemmes2015graphical} and \cite{mohan2021graphical}.

A large body of literature has been written about inference under missingness. Important works are the EM algorithm \citep{dempster1977maximum}, Nobel prize winning work by \cite{heckman1979sample} on correcting for selection bias in linear regression, \cite{rosenbaum1984reducing} which laid the foundations of propensity score based methods in causal inference, and a series of generalised estimating equations (GEE) based methods for inference under missingness \citep{robins1994estimation, robins1995semiparametric,rotnitzky1998semiparametric,scharfstein1999adjusting}. For an overview of the field, see \cite{little2019statistical}. In this work we focus on  correcting for bias in regression using privileged data, which is not treated in the aforementioned literature.

\paragraph{S-recoverability}
As proposed by \cite{pearl2012solution} and further developed in \cite{bareinboim2014recovering}, \emph{s-recoverability} is a method to deal with selection bias.
% A special case of the missingness framework is for dealing with selection bias, as proposed by \cite{pearl2012solution} and further developed in \cite{bareinboim2014recovering}. 
Consider again the case of modelling the distribution of $X_1, ..., X_m$. Instead of having one response indicator for each $X_i$ as in the missingness framework, \cite{pearl2012solution} considers one selection variable $S$ where $S=1$ indicates that all variables are observed (\emph{selected}), and $S=0$ indicates that no variable is observed, i.e. there is no row for this observation in our dataset. Any data that we observe is drawn from the distribution $\PP(X_1, ..., X_m | S=1)$.

\cite{bareinboim2014recovering} prove that for discrete variables and under certain positivity assumptions, $\PP(Y|X)$ is recoverable from $\PP(X, Y|S=1)$ if and only if $Y\Indep S \given X$. The `if' part is straightforward, since the conditional independence implies $\PP(Y|X) = \PP(Y|X, S=1)$, and the right-hand-side can be estimated from the data.
% \red{Only if is without further assumptions on the generating model.}
When this conditional independence is not satisfied, \cite{bareinboim2014recovering} consider joint measurement of $X, Y$ and some other variable $Z$ in the biased dataset (so availability of $\PP(X, Y, Z | S=1)$), satisfying the conditional independence $Y\Indep S\given X, Z$. Additionally, they assume availability of unbiased measurements of $(X, Z)$, i.e.\ sampled from $\PP(X, Z)$, which they refer to as `external data'. For discrete $Z$, the quantity $\PP(Y|X)$ is then identified with:
\begin{align}\label{eqn:s-recoverability}
    \begin{split}
        \PP(Y|X) &= \sum_{z} \PP(Y|X, Z=z) \PP(Z=z|X) \\
        &= \sum_{z} \PP(Y|X, Z=z, S=1) \PP(Z=z|X).
    \end{split}
\end{align}
One can straightforwardly replace the sum with an integral when $Z$ is continuous. However, when the domain of $Z$ is countably infinite or continuous, estimating this quantity is not straightforward. The repeated regression estimator proposed in Section \ref{subsec:rr} is a solution to this problem.

The proposed methods can be applied to the selection bias and missingness settings. In either case, we require availability of i.i.d.\ observations of $(X, Y, Z) \sim \PP(X, Y, Z | S=1)$ whose index set we denote with $\Scal$, and i.i.d.\ observations of $(X, Z) \sim \PP(X, Z)$ whose index set we denote with $\Dcal$. In the missingness setting, both samples are readily available and we have $\Scal \subseteq \Dcal$. In the selection bias setting the sample $\Dcal$ consists of `external' data and we typically have $\Scal \cap \Dcal = \emptyset$. For the methods of Sections \ref{subsec:ipw} and \ref{subsec:dr} we additionally require knowledge of the selection mechanism $\PP(S=1 | X, Z)$, which is directly estimable in the missingness setting, and which has to be assumed under selection bias. Throughout this paper, any distinctions between missingness and selection bias will be pointed out when necessary. Otherwise, either setting can be assumed.
% \red{For a schematic display of the available data in missingness and selection bias, we refer to the supplements.}

% The methods that are proposed in Section \ref{sec:methods} are directly applicable to the missingness setting, where we have $n_S$ observations $(X_1, Y_1, Z_1), ..., (X_{n_s}, Y_{n_s}, Z_{n_s}) \sim \PP(X, Y, Z | S=1)$. We denote the index set of these observations with $\Scal$. Note that $(X_i, Z_i)\sim \PP(X, Z)$ for all $i\in\Scal$. For application to the selection bias setting we require extra assumptions: for the method of Section \ref{subsec:rr} we require availability of `external data' $\PP(X, Z)$, and for the methods of Sections \ref{subsec:ipw} and \ref{subsec:dr} we additionally require knowledge of the selection mechanism $\PP(S=1 | X, Z)$. Throughout this paper, any distinctions between missingness and selection bias will be pointed out when necessary. Otherwise, either setting can be assumed.

\subsection{Regression under different missingness mechanisms}
Suppose we are interested in estimating $\EE[Y|X]$ with univariate, continuous or binary $Y$, and arbitrary $X$.\footnote{Note that this setting includes binary classification.} We might be confronted with a dataset with missing values of $Y$, or we might suspect that some selection mechanism is in play which makes certain $(X, Y)$ pairs unobserved. In this section, we investigate whether there is need for any bias correction, i.e.\ whether selection/missingness is ignorable. As this investigation is based on conditional independence assumptions, we first elaborate how such assumptions can be motivated.
\paragraph{Causal modelling} Missingness mechanisms can be characterised by independencies. This is everything we need: all proposed methods will only require certain conditional independencies in the data, and no causal assumptions. However, the conditional independencies that are assumed are typically untestable. For example, the independence $Y\Indep S$ is not testable, as we have not observed any data $Y$ for $S=0$. To motivate such an independence assumption, one could model the data generating process with a graphical causal model, and infer from d-separations in the graph that there must be certain independencies in the data \citep{pearl2009causality}.
% Especially when we control the data source, one is likely able to confidently write down the graphical model.
In the missingness setting where only $Y$ can be missing (with indicator $S$), we can draw a more simplified graph and discard the $Y^o$ variable, as in Figure \ref{fig:ignorable}. In the graphical framework of s-recoverability, $S$ is implicitly required to be a sink node (i.e.\ a node without children) \citep{bareinboim2014recovering}. We do not adopt this convention.
% NOTE: proof of thm 1 only considers any dependence S_||_Y|X to be of the form Y -> ... -> S or Y <- ... <- A -> ... -> S, and not S -> Y.

\begin{figure}
    \centering
    \begin{subfigure}[t]{.3\linewidth}
        \centering
        \begin{tikzpicture}
            \node[var] (Y) at (1.3, 0) {$Y$};
            \node[var] (X) at (0, 0) {$X$};
            \node[var] (S) at (0, -1.3) {$S$};
            \draw[arr] (X) to (Y);
            \draw[arr] (X) to (S);
        \end{tikzpicture}
        \caption{Ignorable}
        \label{fig:ignorable}
    \end{subfigure}
    \begin{subfigure}[t]{.3\linewidth}
        \centering
        \begin{tikzpicture}
            \node[var] (Y) at (1.3, 0) {$Y$};
            \node[var] (X) at (0, 0) {$X$};
            \node[var] (S) at (0, -1.3) {$S$};
            \draw[arr] (X) to (Y);
            \draw[arr] (X) to (S);
            \draw[biarr, color=red] (Y) to (S);
        \end{tikzpicture}
        \caption{Nonignorable}
        \label{fig:non_ignorable}
    \end{subfigure}
    \begin{subfigure}[t]{.3\linewidth}
        \centering
        \begin{tikzpicture}
            \node[var] (Y) at (1.3, 0) {$Y$};
            \node[var] (Z) at (1.3, -1.3) {$Z$};
            \node[var] (X) at (0, 0) {$X$};
            \node[var] (S) at (0, -1.3) {$S$};
            \draw[arr] (X) to (Y);
            \draw[arr] (X) to (S);
            \draw[arr] (Z) to (Y);
            \draw[arr] (Z) to (S);
        \end{tikzpicture}
        \caption{Privilegedly ignorable}
        \label{fig:cond_ignorable}
    \end{subfigure}
    \caption{Examples of missingness or selection bias settings, where $S$ indicates whether $Y$ is observed or not.}
    \label{fig:missingness}
\end{figure}

\paragraph{Ignorable missingness/selection bias} When the data is MCAR or MAR, we have the conditional independence $Y\Indep S \given X$ and thus
\begin{equation}
    \EE[Y|X] = \EE[Y|X, S=1],
\end{equation}
in which case we call the missingness/selection mechanism \emph{ignorable} for estimating $\EE[Y|X]$. An example of an ignorable (MAR) missingness or selection mechanism is given in Figure \ref{fig:ignorable}. When this mechanism is ignorable, any correctly specified model could directly be learned as \emph{Empirical Risk Minimization} (ERM) is consistent \citep{sugiyama2007covariate}, and hence, there is no need for bias correction.
% The MAR setting is a case of \emph{covariate shift}, which for example happens in the \emph{active learning} framework, where $\PP(X|S=1)$ is controlled for better prediction \citep{shimodaira2000improving}.

Although in this case the missingness or selection mechanism can in principle be ignored, one should beware that under model misspecification, ERM is not consistent anymore. Also, efficiency of the estimation procedure can be affected by MCAR and MAR.
\cite{zadrozny2004learning} and \cite{weifan2005improved} investigate the performance of multiple popular classification algorithms under covariate shift.
% In more recent work, \cite{klusowski2021universal} identifies a functional form of $\EE[Y|X]$ for which decision trees are consistent.
\cite{robins1995semiparametric} investigate the asymptotic efficiency of semi-parametric estimation of the regression function via Generalised Estimating Equations (GEE). Note that in the missingness setting, we can use the values of $X$ where $Y$ is unobserved as additional (unlabelled) input of a \emph{semi-supervised learning} algorithm. When doing \emph{anticausal} prediction (i.e., when $Y$ is the cause of $X$), these additional samples could benefit performance \citep{scholkopf2012causal}.

\paragraph{Privilegedly ignorable missingness/selection bias}
It might be the case that the missingness or selection mechanism is nonignorable. For example, we may suspect that $S$ and $Y$ are confounded by some variable that is not contained in $X$, as depicted in Figure \ref{fig:non_ignorable}. In this case we typically have $\EE[Y|X, S=1] \neq \EE[Y|X]$, so naive regression on the available data yields a biased model. However, we might be able to identify the latent confounder, or more generally, any variable (e.g.\ mediator or confounder of $Y$ and $S$) that induces a dependence between $Y$ and $S$ after conditioning on $X$.

More specifically, we are looking for a set of variables $Z$ such that $Y\Indep S \given X, Z$, such as depicted in Figure \ref{fig:cond_ignorable}. Having identified $Z$, one might include it into the features of the model and deploy the unbiased model $\hat{\EE}[Y|X, Z, S=1]$. However, in practice it might be costly or impossible to measure $Z$ during deployment, e.g.\ when $Z$ can only be measured after making a prediction with the regression model. In these settings, it is undesirable to incorporate $Z$ into the features of the deployed model. When $Z$ is only available during training it is referred to as \emph{privileged information}, following \cite{vapnik2009new}. The specific setting that we consider in this work is formally defined as follows:
\begin{definition}[PMAR]\label{def:pmar}
    Given variables $X$ and $Y$, response indicator $S$ for $Y$, and privilegedly observed variable $Z$, we say that $Y$ is
    \emph{Privilegedly Missing at Random} (PMAR)
    if the missingness mechanism is independent of the missing variable given all other fully or privilegedly observed variables, i.e.\ $Y \Indep S \given X, Z$.
\end{definition}
% \begin{definition}[PMAR]\label{def:pmar}
%     Let variables $X$ and $Y$, privilegedly observed variable $Z$, and variable $S$ be given, where $S$ is either a response indicator for $Y$ or a selection variable for $(X, Z, Y)$, in which case we assume availability of unbiased measurements of $(X, Z)$. We say that $Y$ is
%     \emph{Privilegedly Missing at Random} (PMAR)
%     if the missingness/selection mechanism is independent of the missing variable given all other fully or privilegedly observed variables, i.e.\ $Y \Indep S \given X, Z$.
% \end{definition}
% In the case of selection biased data for $(X, Y, Z)$ with additional unbiased samples of $(X, Z)$ and where $Z$ is privilegedly observed, we also refer to the target variable $Y$ as PMAR when $Y\Indep S \given X, Z$.
When the data used for regression is PMAR, we refer to the missingness/selection mechanism as \emph{privilegedly ignorable}.

As a motivation of the PMAR setting, we revisit the example from the introduction on the follow-up study of HIV-positive individuals \citep{hernan2021causal}. Recall that we have a certain antiretroviral drug dosage ($X$), the 3-year risk of death ($Y$), and the severity of side-effects ($Z$). For the treated individuals, high levels of immunosuppression ($U$) induce a greater risk of death, but also increase the severity of their symptoms ($Z$). When symptoms become too severe, patients may drop out of the study, censoring the measurement of $Y$. Additional to the described causal relations, any other dependencies might be present between $U, X, Y$ and $Z$, in which case we still remain in the PMAR setting. A compatible causal graph is depicted in Figure \ref{fig:pmar:graph}, suppressing any bidirected edges to reduce clutter. Practically, when gathering data for training a prediction model of outcome $Y$ given a dosage $X$, one should measure the symptoms $Z$ to correct for any bias that is induced via $U$. In this example one can only measure symptoms \emph{after} the drug has been administered, which makes the information $Z$ privileged.

Another setting where PMAR is applicable, is when individuals or items are actively selected or rejected using predictions from an existing model $\hat{Y} = \hat{\EE}[Y|X]$, e.g.\ in the selection of patients for costly CT scans, dismissal of patients from the intensive care, but also in industrial applications as targeted sales, fraud detection etc. When data was gathered under a selection process based on such a model and on additional information $Z$ (e.g.\ an experts opinion, represented by variable $Z$ in Figure \ref{fig:pmar:selection:1}), and one wants to retrain the model on this data, one has to correct for the bias that is induced by this additional selection mechanism.
% When available data that is affected by such a model is used to retrain the model, and selection is not \emph{only} determined by the old model (but for example also by an experts opinion, variable $Z$ in Figure \ref{fig:pmar:selection:1}), one has to correct for the bias that is induced by this additional selection mechanism. 

Similarly, one might want to replace a current selection model $\hat{\EE}[Y|Z]$ with a new model $\hat{\EE}[Y|X]$ that uses a different feature set (Figure \ref{fig:pmar:selection:2}), or we might have a combination of both. In either case, one should correct for any bias induced via $Z$ when estimating $\EE[Y|X]$ by jointly measuring $X$ and $Z$ while gathering training data, and then appropriately correcting for any bias, as demonstrated in the following section.
\begin{figure}[!htb]
    \centering
    \begin{subfigure}[t]{0.32\linewidth}
        \centering
        \begin{tikzpicture}
            \node[var] (U) at (1.3, 0) {$U$};
            \node[var] (Y) at (1.3, -1.2) {$Y$};
            \node[var] (X) at (0, 0) {$X$};
            \node[var] (Z) at (0, -1.2) {$Z$};
            \node[var] (S) at (0, -2.4) {$S$};
            \draw[arr] (X) to (Z);
            \draw[arr] (U) to (Z);
            \draw[arr] (U) to (Y);
            \draw[arr] (X) to (Y);
            \draw[arr] (Z) to (S);
            % \draw[biarr] (U) to (Y);
            % \draw[biarr] (Z) to (Y);
            % \draw[biarr] (Z) to (U);
        \end{tikzpicture}
        \caption{}
        \label{fig:pmar:graph}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \centering
        \begin{tikzpicture}
            \node[var] (X) at (0, 0) {$X$};
            \node[var] (Yhat) at (0, -1.2) {$\hat{Y}$};
            \node[var] (Y) at (1.3, 0) {$Y$};
            \node[var] (Z) at (1.3, -1.2) {$Z$};
            \node[var] (S) at (0, -2.4) {$S$};
            \draw[biarr] (X) to (Y);
            \draw[biarr] (X) to (Z);
            \draw[arr] (X) to (Yhat);
            \draw[arr] (Yhat) to (S);
            \draw[arr] (Z) to (S);
            \draw[biarr] (Z) to (Y);
        \end{tikzpicture}
        \caption{}
        \label{fig:pmar:selection:1}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \centering
        \begin{tikzpicture}
            \node[var] (X) at (0, 0) {$X$};
            \node[var] (Z) at (1.3, -1.2) {$Z$};
            \node[var] (Yhat) at (0, -1.2) {$\hat{Y}$};
            \node[var] (Y) at (1.3, 0) {$Y$};
            \node[var] (S) at (0, -2.4) {$S$};
            \draw[biarr] (Z) to (Y);
            \draw[biarr] (X) to (Y);
            \draw[biarr] (X) to (Z);
            \draw[arr] (Z) to (Yhat);
            \draw[arr] (Yhat) to (S);
        \end{tikzpicture}
        \caption{}
        \label{fig:pmar:selection:2}
    \end{subfigure}
    \caption{Causal graphs relating to examples of PMAR.}
\end{figure}
% To identify certain diseases or ailments Say we have an old machine for measurement of patients ($Z$), and based on these measurements we predict whether the patient is ill ($Y$), which can only be measured by a CAT scan. The CAT scan is costly, so we select patients $S=\I\{\hat{\EE}[Y|Z] < U_S\}$ for a CAT scan.
% We want to start using a new testing procedure $X$ as this has new technology which is way more indicative of $Y$; but still, we will have to send patients through a CAT scan to be sure. To train the model $\EE[Y|X]$, we can do this directly on the data, but precisely the cases of false negatives of $\EE[Y|Z]$ is under represented. This should be corrected for. For a while we take both measurements $X, Z$, and still select on $\EE[Y|Z]$. Then, if we have sufficient data, we can train $\EE[Y|X]$ from the data $\PP(X, Z, Y|S=1)$ using the proposed methods.}
% \red{Especially when we act on current model $S = \I\{\hat{\EE}(Y=1|Z) < U_s\}$ (predictive policing, cat scan, etc) and we want to either re-train the model with a new technology, or switch to a new set of features $X$, then we can train $\hat{EE}[Y|X]$.
% For missingness, \red{PMAR} means\red{/requires} that we have data from $\PP(X, Y, Z | S=1)$ and $\PP(X, Z, S)$ during training. For selection bias this describes the setting from \cite{bareinboim2014recovering}, where we have $\PP(X, Y, Z | S=1)$ and external data $\PP(X, Z)$. For the methods in Section \ref{subsec:ipw} and \ref{subsec:dr} we additionally require knowledge of $\PP(S=1 | X, Z)$, making it equivalent to the missingness setting in the sense that we then have access to $\PP(X, Y, Z | S=1)$ and $\PP(X, Z, S) = \PP(S|X, Z)\PP(X, Z)$.

% In the following section, we propose an estimator for $\EE[Y|X]$ that leverages privileged information $Z$ in the PMAR setting.
% \red{It might be that some mediators or confounders that induce a dependence between $Y$ and $S$ given $X$ are identified and collected in $Z$, but not all. Here, we still have a dependence $Y\nIndep S \given X, Z$, and we expect our proposed methods not to be consistent. We do however consider this situation in the experiments, to investigate whether correcting for some dependence can yield an improvement over not correcting at all, i.e.\ naively estimating $\EE[Y|X, S=1]$.}

\section{Imputation, Weighting, and Double Robustness under PMAR}\label{sec:methods}
In this section, we propose three estimation procedures for training a regression model $\EE[Y|X]$ in the PMAR setting: a repeated regression method, a weighted regression method, and a doubly robust regression method. Throughout, we consider the following example.
\begin{example}\label{ex:1}
    Consider the data generating process
    \begin{align}\label{eqn:ex1}
        \begin{split}
            X &= \varepsilon_X \\
            Z &= 3\sin(X) + \varepsilon_Z \\
            Y &= \frac{1}{2}X + Z + \varepsilon_Y \\
            S &\sim \textrm{Bernoulli}(p_S(X, Z))
            % S &= \I\{U_S < p_S(X, Z)\}
        \end{split}
    \end{align}
    with independent Gaussian random variables $\varepsilon_X, \varepsilon_Z$ and $\varepsilon_Y$. The selection probability is defined as $p_S(x, z) := \sigma(x)\ell(\sigma(z))$ with sigmoid $\sigma(x) = 1/(1+e^x)$ and $\ell(x) := \tfrac{19}{20} x +\tfrac{1}{20}$, i.e. a linear scaling of $\sigma(z)$ between 0.05 and 1 to ensure positivity in the $z$ direction.
\end{example}
\begin{wrapfigure}[6]{r}{0.28\linewidth}
    \centering
    \vspace{-25pt}
    \begin{tikzpicture}
        \node[var] (Y) at (1.3, 0) {$Y$};
        \node[var] (Z) at (1.3, -1.3) {$Z$};
        \node[var] (X) at (0, 0) {$X$};
        \node[var] (S) at (0, -1.3) {$S$};
        \draw[arr] (X) to (Z);
        \draw[arr] (X) to (Y);
        \draw[arr] (Z) to (Y);
        \draw[arr] (X) to (S);
        \draw[arr] (Z) to (S);
    \end{tikzpicture}
    \caption{}
    \label{fig:ex1:graph}
\end{wrapfigure}
Figure \ref{fig:ex1:graph} displays the graphical model related to this data generating process. Note that we can indeed read off that $Y \Indep S \given X, Z$, so if $Z$ is only available during training, the missingness mechanism is PMAR. Figure \ref{fig:ex1:true_and_naive} depicts $n=400$ draws from the generating model (\ref{eqn:ex1}). In this example, we have $\#\{S=1\}=123$. The black dots indicate $(X, Y)$ pairs where $Y$ is observed ($S=1$), and the grey dots indicate $(X, Y)$ pairs where $Y$ is unobserved ($S=0$). The green line shows the true regression line $\EE[Y|X=x] = \tfrac{1}{2}x + 3\sin(x)$, and the black line shows the regression line of the naive, biased estimate $\hat{\EE}[Y|X, S=1]$. In this example and throughout this paper we use thin plate splines regression \citep{duchon1977splines, wood2003thin} as implemented in the \href{https://cran.r-project.org/package=mgcv}{\code{mgcv}} package \citep{wood2015package}.\\
Note that, additional to what is shown in Figure \ref{fig:ex1:true_and_naive}, we have all $(X, Z)$ pairs available. Our goal is to fit a regression model that is close to the green line, $\EE[Y|X]$. \exqed

\begin{figure}[!htb]
    \centering
    \fbox{\includegraphics[width=.95\linewidth]{figures/1c_true_and_naive.pdf}}
    \caption{Dataset from Example \ref{ex:1}, with observed (black) and unobserved data (grey); the true regression line $\EE[Y|X]$ (green) and the naively estimated regression line $\hat{\EE}[Y|X, S=1]$ (black).}
    \label{fig:ex1:true_and_naive}
\end{figure}


\paragraph{Extrapolation and positivity}
Many missingness methods assume \emph{positivity} of the selection mechanism, i.e.\ $\PP(S=1 | X, Z, Y) > 0$ a.s., as is for example required for the identification equation (\ref{eqn:s-recoverability}). This assumption ensures that asymptotically, we do not run into the problem of extrapolation. For finite samples, we might run into extrapolation issues already when $\PP(S=1 | X, Z, Y)$ is close to zero. In the example of Figure \ref{fig:ex1:true_and_naive} we have no positivity for large values of $X$; we will see that extrapolation is still possible by using privileged data $Z$ that is highly predictive of $Y$.

\subsection{Repeated regression}\label{subsec:rr}
By the law of total expectation and the PMAR conditional independence $Y\Indep S \given X, Z$ we can write the conditional expectation $\EE[Y|X]$ as follows
\begin{align}
    \begin{split}
        \EE[Y|X] &= \EE[\EE[Y|X, Z] | X] \\
        &= \EE[\EE[Y|X, Z, S=1] | X],
    \end{split}
\end{align}
similar to equation (\ref{eqn:s-recoverability}). We formulate an estimation procedure based on this expression by estimating each conditional expectation with a regression model. That is, we first regress $Y$ on $X$ and $Z$ using the data $\Scal$, which results in the regression model $\hat{\EE}[Y|X, Z, S=1]$. Using the unbiased data $(x_i, z_i)$ for $i\in\Dcal$ we construct \emph{pseudo-labels} $\tilde{Y}_i := \hat{\EE}[Y|X=x_i, Z_i=z_i, S=1]$. Now, we regress $\tilde{Y}$ on $X$ using the data $(X_i, \tilde{Y}_i)_{i\in\Dcal}$, which yields the final model:
\begin{equation}\label{eqn:rr}
    \hat{\mu}_{RR}(x) = \hat{\EE}[\tilde{Y}|X = x].
\end{equation}
Note that this method requires datasets $\Scal$ and $\Dcal$, and assumes that $Y\Indep S \given X, Z$. So, if this conditional independence is satisfied, it can be directly applied in both the missingness setting, and in the selection bias setting where we have `external data' $\PP(X, Z)$.

\setcounter{example}{0}
\begin{example}[\textit{continued}]\label{ex:1:imputed}
    Recall that the data for $Y$ is generated by $Y = \frac{1}{2}X + Z + \varepsilon_Y$, so for fitting a model $\hat{\EE}[Y|X, Z, S=1]$, although we can only fit this model on a small part of the data (123 out of 400 observations) it is a relatively easy (linear) model to fit. We compute the pseudo-labels $\tilde{Y}_i := \hat{\EE}[Y|X = x_i, Z = z_i, S=1]$, as depicted with orange crosses in Figure \ref{fig:ex1:imputed_gam}. Regressing these imputed values on $X$ yields the final model $\hat{\mu}_{RR}$ (orange line in Figure \ref{fig:ex1:imputed_gam}). \exqed
    \begin{figure}[!htb]
        \centering
        \fbox{\includegraphics[width=.95\linewidth]{figures/2c_imputed.pdf}}
        \caption{Repeated regression. Orange crosses indicate imputed values, and the orange line is the regression line resulting from repeated regression.}
        \label{fig:ex1:imputed_gam}
    \end{figure}
    % \begin{figure}[!htb]
    %     \centering
    %     \fbox{\includegraphics[width=.95\linewidth]{figures/2a_imputed.pdf}}
    %     \caption{We're able to impute $Y$ so well, because we have observed $X$ and $Z$, and we essentially only have to fit a linear model of $Y$ given $X$ and $Z$.}
    %     \label{fig:ex1:imputed_values}
    % \end{figure}
\end{example}

% A well known method for imputation with linear regression models is Buck's method \citep{buck1960method, little2019statistical}.
Regression imputation is explicitly used for estimating the mean under missingness via $\EE[Y] = \EE[\EE[Y|X, S=1]]$ by \cite{bang2005doubly}. Similarly, the \emph{average causal effect} can be estimated by $\EE[Y|\Do(X)] = \EE[\EE[Y|X, Z]]$ for a valid \emph{adjustment set} $Z$; this method is known as \emph{standardization} \citep{hernan2021causal}. For these estimators, the inner expectation is estimated with a regression model, and the outer expectation is calculated by taking the mean of the pseudo-labels. The novelty in estimator (\ref{eqn:rr}) lies in the fact that the outer expectation is estimated by regression instead of the empirical mean, and the observation that this estimator is applicable to the PMAR setting.
Note that in general, automatically generated confidence intervals resulting from the outer regression $\hat{\EE}[\tilde{Y}|X]$ are not valid. To this end, \emph{multiple imputation} methods are often used. As this requires the modelling of the full distribution $\PP(Y|X, Z)$, we do not consider this. For an overview of multiple imputation methods in GEE regression, see \cite{ditlhong2018comparative}.

\subsection{Importance Weighting}\label{subsec:ipw}
For estimating the parameter $\beta^*$ in the regression model $\EE[Y|X] = g(X; \beta^*)$ we often specify a loss function $\ell$ and do empirical risk minimisation (\ref{eqn:erm}) as an approximation of the parameter that is optimal in terms of the true risk (\ref{eqn:risk}).
\begin{align}
    \hat{\beta} & = \argmin_\beta \frac{1}{|\Dcal|}\sum_{i\in\Dcal} \ell(g(X_i; \beta), Y_i) \label{eqn:erm} \\
    \beta^*     & = \argmin_\beta \EE[\ell(g(X; \beta), Y)] \label{eqn:risk}
\end{align}
Writing $f(x, y) := \ell(g(x; \beta), y)$, we can express the risk in terms of the distribution conditional on $S=1$ using importance weighting:
\begin{align}
    \begin{split}
        \EE[f(X, Y)]
        % &= \int f(x, y)p(x, y, z)\diff (x, y, z) \\
        % &= \int f(x, y)\frac{p(x, y, z)p(x, y, z | S=1)}{p(x, y, z | S=1)}\diff (x, y, z) \\
        % &= \int f(x, y)w(x, z)p(x, y, z | S=1)\diff (x, y, z) \\
        &= \EE[w(X, Z)f(X, Y) | S=1],
    \end{split}
\end{align}
% where we use that
% \begin{align}
%     \begin{split}
%         p(x, y, z) &= p(x, y, z)\frac{p(x, y, z | S=1)}{p(x, y, z | S=1)} \\
%         &= \frac{p(x, y, z)\PP(S=1)}{p(x, y, z, S=1)}p(x, y, z | S=1) \\
%         &= \frac{\PP(S=1)}{\PP(S=1 | x, y, z)}p(x, y, z | S=1)
%     \end{split}
% \end{align}
with \emph{importance weights} $w(x, z) := \PP(S=1) / \PP(S=1 | X=x, Z=z)$. A derivation of these importance weights can be found in the supplementary material.
Since $\beta^* = \arg\min_\beta \EE[w(X, Z)\ell(g(X; \beta), Y) | S=1]$, when we have observations $(X_i, Z_i, Y_i) \sim \PP(X, Z, Y | S=1)$ for $i\in\Scal$, we can directly do empirical risk minimization on this dataset using the weighted loss:
\begin{equation}
    \hat{\beta}_w := \argmin_\beta \frac{1}{|\Scal|}\sum_{i\in\Scal} w(X_i, Z_i)\ell(g(X_i; \beta), Y_i),
\end{equation}
and use $\hat{\beta}_w$ as an estimate of $\beta^*$. Many implementations of regression algorithms allow the user to specify such sample weights. When the weights are not known in the missingness setting, they can be estimated \citep{cortes2008sample}. Practically, when the selection probability $\PP(S=1 | x_i, z_i)$ is nearly zero for particular drawn values $x_i, z_i$, these probabilities are `clipped' (i.e.\ transformed to remain lower bounded by some pre-specified strictly positive value) to reduce variance.
% \cite{lee2011weight} consider probability clipping by projecting all values onto $[q, 1]$ for some lower quantile $q$ of $(\PP(S=1 | x_i, z_i))_{i=1}^n$.
In the experiments, we consider a linear map of the array of selection probabilities to $[1/20, 1]$, as this yields the best performance among different clipping strategies.
% In practice, the clipping bounds can be based on prior knowledge of the selection mechanism, even when the precise conditional selection probabilities are unknown.
\setcounter{example}{0}
\begin{example}[\textit{continued}]\label{ex:1:ipw}
    The fitted IW regression model is depicted in Figure \ref{fig:ex1:ipw_known_weights}. Here, we used the true weights $w(x_i, z_i)$. The size of the observed points indicate the associated weight. Note that the IW regression only uses the black points (i.e.\ the $(x_i, y_i)$ pairs for which $S_i=1$).
    % \begin{figure}[t]{\linewidth}
    %     \centering
    %     \fbox{\includegraphics[width=.95\linewidth]{figures/3_iw_estimated_weights.pdf}}
    %     \caption{Estimated weights}
    %     \label{fig:ex1:ipw_estimated_weights}
    % \end{figure}
    \begin{figure}[!htb]
        \centering
        \fbox{\includegraphics[width=.95\linewidth]{figures/4_iw_true_weights.pdf}}
        \caption{IW regression with true weights.}
        \label{fig:ex1:ipw_known_weights}
    \end{figure}
    Comparing to repeated regression (Figure \ref{fig:ex1:imputed_gam}), we see that IW extrapolates poorly, possibly due to the effect of importance weighting on regularization \citep{xu2021understandinga}. On the other hand, IW interpolates better than the naive model. \exqed
\end{example}

The idea of weighting observations stems from the Horvitz-Thompson estimator for the population mean \citep{horvitz1952generalization}. The use of importance weights in GEE regression in the MAR setting is analysed by \citep{robins1994estimation,robins1995semiparametric}, and its MNAR counterpart is described by \cite{scharfstein1999adjusting}. For weighted SVM- and kernel regression under covariate shift and target shift, see \cite{zhang2013domain}.
% Our contribution lies in the precise formulation of the weights $w$ that is suitable for the PMAR setting.

\subsection{Doubly Robust Regression}\label{subsec:dr}
We now follow a relatively standard procedure to combine the two previous models into a doubly robust model \citep{bang2005doubly, kang2007demystifying, dudik2014doubly}. First, we consider the repeated regression method $\hat{\mu}_{RR}$ from Section \ref{subsec:rr}. We calculate the residuals of this method on the available $Y$ values: we set $R_i := Y_i - \hat{\mu}_{RR}(X_i)$ for all $i\in \Scal$. We model the conditional expectation of the residuals given $X$ using the IW regression method from Section \ref{subsec:ipw}, as
\begin{equation}
    \hat{r}_{IW}(x) := g(X; \hat{\beta}_w) \approx \EE[R | X]
\end{equation}
where $\hat{\beta}_w = \argmin_\beta |\Scal|^{-1}\sum_{i\in\Scal} w(X_i, Z_i)\ell(g(X_i; \beta), R_i)$ and where we use the same importance weights $w$ as in Section \ref{subsec:ipw}. Then we define the \emph{doubly robust} model
\begin{equation}
    \hat{\mu}_{DR}(x) := \hat{\mu}_{RR}(x) + \hat{r}_{IW}(x).
\end{equation}
Here, double robustness refers to the fact that for this model to be consistent, only one of $\hat{\mu}_{RR}$ and $\hat{r}_{IW}$ has to be consistent.

\setcounter{example}{0}
\begin{example}[\textit{continued}]\label{ex:1:dr}
    For sake of exposition, we apply the doubly robust method with a misspecified model $\hat{\mu}_{RR}(x)$. Recall that $\hat{\mu}_{RR}(x) = \hat{\EE}[\tilde{Y}|X= x]$, where $\tilde{Y}$ are the values that are imputed with the model $\hat{\EE}[Y|X, Z, S=1]$. To make the model deliberately misspecified, we use the same $\tilde{Y}$ as in Section \ref{subsec:rr} (more specifically, as in Figure \ref{fig:ex1:imputed_gam}), but for the outer regression $\hat{\EE}[\tilde{Y}|X]$ we employ polynomial regression with degree 5. The resulting models are depicted in Figure \ref{fig:ex1:dr}.
    % The residuals $r_i$ are shown in the same figure. The size of the residuals indicate the associated weight $\PP(S=1)/\PP(S=1 |x, z)$. Doing weighted regression on these residuals gives the model $\hat{r}_{IW}(x)$ (yellow). Finally, adding the direct model $\hat{\mu}_{RR}$ and residual model $\hat{r}_{IW}$ gives the doubly robust model (orange).
    We see that $\hat{\mu}_{DR}$ extrapolates poorly, but it interpolates better than the misspecified model $\hat{\mu}_{RR}$. \exqed
    \begin{figure}[!htb]
        \centering
        \fbox{\includegraphics[width=.95\linewidth]{figures/5_dr_true_weights}}
        \caption{Doubly robust regression. At the top the $(X,Y)$ pairs are plotted, with the true model (green) and misspecified RR model (black). The residuals of the misspecified model are plotted at the bottom. The IW regression model for the residuals (yellow) is then added to the misspecified model, which yields the doubly robust model (orange).}
        \label{fig:ex1:dr}
    \end{figure}
\end{example}
For overview papers on doubly robust estimation of the mean, see \cite{bang2005doubly} and \cite{kang2007demystifying}. For doubly robust regression in the MNAR setting, see \cite{rotnitzky1998semiparametric} and \cite{scharfstein1999adjusting}. Doubly robust estimation of causal effects is treated by \cite{bhattacharya2022semiparametrica}, among others.

\section{Evaluation}\label{sec:evaluation}
% In Example \ref{ex:1}, we can easily assess the quality of a fitted regression line by comparing with the true model $\EE[Y|X]$, and by comparing against the unobserved values. 
% In practice this information is absent, and evaluating the model is not straightforward.
% Recall that $\Dcal$ denotes indices of unbiased observations of $(X, Z)$, and $\Scal$ denotes the observations from $\PP(X, Y, Z | S = 1)$.
% Ultimately, we are interested in how well our estimated function $\hat{\mu}(x)$ estimates the function $\EE[Y|X=x]$, which can be defined as $\|\hat{\mu} - \EE[Y|X]\|_{L_2}$. Calculating this integral is cumbersome and we don't have access to the true $\EE[Y|X]$, so we can approximate the square of this quantity with $\textrm{MSE-t} := \tfrac{1}{|\Dcal|}\sum_{i\in\Dcal}(\hat{y}_i - \hat{\EE}[Y|X=x_i])^2$, where we let $\hat{y}_i := \hat{\mu}(x_i)$.
Consider the setup where we split the available data $\Dcal = \Dcal'' \dot{\cup} \Dcal'$ into train- and test test respectively, and where we split $\Scal$ accordingly. When all values of $Y$ are known, performance is typically assessed using $\textrm{MSE} := |\Dcal'|^{-1}\sum_{i\in\Dcal'}(\hat{y}_i - y_i)^2$. Under missingness or selection bias, this quantity cannot be calculated as it requires the unobserved values $y_i$ for $i\notin \Scal'$. Quantities that \emph{can} be calculated on the test set are as follows:
\begin{align}
    \textrm{MSE-n}         & := \frac{1}{|\Scal'|}\sum_{i \in \Scal'} (\hat{y}_i - y_i)^2            \\
    \textrm{MSE-}w         & := \frac{1}{|\Scal'|}\sum_{i \in \Scal'} w(x_i, z_i)(\hat{y}_i - y_i)^2 \\
    \textrm{MSE-}\tilde{y} & := \frac{1}{|\Dcal'|}\sum_{i \in \Dcal'} (\hat{y}_i - \tilde{y}_i)^2,
\end{align}
which are respectively the naively calculated MSE, the re-weighted MSE using the true weights, and the MSE calculated as if the imputed values $\tilde{y}$ were true. We define $\textrm{MSE-}\hat{w}$ similarly, in terms of the estimated weights.
\setcounter{example}{0}
\begin{example}[\textit{continued}]\label{ex:1:eval}
    The IW and DR models are learned both with true and estimated weights (denoted with -t and -e respectively), and all weights are clipped. We calculate the different mean squared error metrics for the estimated models on 500 independently drawn test sets of $n=400$ samples. The results are provided in Table \ref{tab:ex1:eval}.
    \begin{table}[!htb]
        \centering
        \begin{tabular}{lccccc}\toprule
                  & $\textrm{MSE}$ & $\textrm{MSE-n}$ & $\textrm{MSE-}\tilde{y}$ & $\textrm{MSE-}w$ & $\textrm{MSE-}\hat{w}$ \\ \midrule
            Naive & 24.07          & \textbf{7.56}    & 19.54                    & 16.19            & 19.79                  \\
            RR    & \textbf{8.81}  & 8.13             & \textbf{4.44}            & \textbf{8.50}    & \textbf{9.34}          \\
            IW-t  & 40.42          & 8.40             & 35.58                    & 22.22            & 24.67                  \\
            IW-e  & 38.44          & 8.28             & 33.60                    & 21.49            & 23.08                  \\
            DR-t  & 25.91          & 8.13             & 21.27                    & 14.82            & 16.65                  \\
            DR-e  & 24.09          & 8.00             & 19.43                    & 13.96            & 15.52                  \\\midrule
            True  & 8.03           & 7.78             & 4.63                     & 7.87             & 8.87                   \\
            \bottomrule
        \end{tabular}
        \caption{Mean squared errors of different regression methods applied to Example \ref{ex:1:eval}, averaged over 500 test sets.}
        \label{tab:ex1:eval}
    \end{table}
    We emphasize that MSE is not calculable in practice, and note that MSE-n, MSE-$w$ and MSE-$\hat{w}$ yield qualitatively different results than the oracle MSE. MSE-$\tilde{y}$ provides the same ordering as MSE, but in practice the reliance on the imputation model can be undesirable. We observe that RR appropriately corrects for bias, as its MSE lies close to the MSE of the true function $\EE[Y|X]$. Additional to the oracle MSE, we calculate the MSEs specifically for data points where the regression model is interpolating (between the minimum and maximum values of $X$ for which $S=1$) and extrapolating (the complement of these values):
    \begin{table}[!htb]
        \centering
        \small
        \begin{tabular}{lccccc}\toprule
                 & $\textrm{MSE}$ & $\textrm{MSE-interp.}$ & $\textrm{MSE-extrap.}$ \\ \midrule
            RR   & \textbf{8.81}  & \textbf{8.43}          & \textbf{10.17}         \\
            IW-t & 40.42          & 12.00                  & 138.22                 \\
            IW-e & 38.44          & 11.77                  & 129.41                 \\
            \bottomrule
        \end{tabular}
    \end{table}\\
    % \red{For RR this yields average MSEs of 9.43, 8.26 and 11.25 respectively. For e.g.\ IW-t, this yields 25.80, 9.28, and 51.36 respectively}, 
    We observe that IW extrapolates poorly, especially compared to RR. \exqed
\end{example}

When the true weights are not known, one can only evaluate the proposed bias correction methods on biased data by relying on an auxiliary model, i.e. either the imputation model $\hat{\EE}[Y|X, Z, S=1]$ or $\hat{\PP}(S=1 | X, Z)$. In general, if the practitioner is able to evaluate on an unbiased random sample of $(X, Y)$, this would be much more reliable than evaluating on a biased sample.
% For work on offline evaluation of a contextual bandit policy, see \cite{dudik2014doubly}.

\section{Experiments}\label{sec:experiments}
The example that is used throughout this paper is quite extreme in the sense that the model $\EE[Y|X, Z]$ is relatively simple and $\EE[Y|X]$ is rather complex, which gives RR a clear advantage over IW. To investigate the proposed methods in a more general setting, we assess performance on an extensive simulation setup and on the Boston Housing dataset.

\subsection{Simulations}\label{subsec:exp:sim}
To assess the performance of the proposed methods empirically, we first identify which graphs with variables $X, Y, Z$ and $S$ satisfy the pattern of d-separations $X\nPerp Y$ (such that regression $\EE[Y|X]$ makes sense), $Y\nPerp S|X$ and $Y\Perp S\given X, Z$ (PMAR). There are 126 \emph{Acyclic Directed Mixed Graphs} (ADMGs) that fit this pattern. An overview of the valid ADMGs is provided in the supplements.
For each ADMG we simulate 60 datasets, and for each dataset we draw $n=1000$ samples according to an additive noise structural equation model, where all equations for $X, Y, Z$ are random functions, independently drawn from a Gaussian process, and the additive noise is the pushforward of a $\textrm{Unif}[0,1]$ distribution through a random function that is also drawn from a Gaussian process \citep{mooij2016distinguishing}. We let the selection probability be $p(x, z) = \sigma(x)\sigma(z)$, when $X$ and $Z$ are parents of $S$ in the ADMG. For a complete description of the simulation setup, we refer to the supplements.
On each dataset, we fit a `naive' model $\hat{\EE}[Y|X, S=1]$ and the models $\hat{\mu}_{RR}, \hat{\mu}_{IW}$ and $\hat{\mu}_{DR}$ from Section \ref{sec:methods}. We also fit a `true' model $\hat{\EE}[Y|X]$ for comparison.
\begin{table}[!htb]
    \centering
    \begin{tabular}{lcccc}\toprule
              & $\textrm{MSE}$               & $\textrm{MSE-}\tilde{y}$     & $\textrm{MSE-}w$             & $\textrm{MSE-}\hat{w}$       \\ \midrule
        Naive & 2.75 {\small (8.5)}          & 2.47 {\small (8.3)}          & 0.80 {\small (0.8)}          & 0.81 {\small (0.8)}          \\
        RR    & \textbf{1.80} {\small (1.8)} & \textbf{0.56} {\small (0.8)} & 1.09 {\small (0.9)}          & 1.05 {\small (0.9)}          \\
        IW-t  & 3.90 {\small (12.1)}         & 3.57 {\small (11.9)}         & 0.82 {\small (0.9)}          & 0.82 {\small (0.8)}          \\
        IW-e  & 3.62 {\small (11.3)}         & 3.26 {\small (10.8)}         & 0.82 {\small (0.9)}          & 0.81 {\small (0.8)}          \\
        DR-t  & 4.16 {\small (14.0)}         & 4.18 {\small (15.5)}         & \textbf{0.69} {\small (0.4)} & 0.72 {\small (0.4)}          \\
        DR-e  & 3.70 {\small (11.9)}         & 3.68 {\small (13.2)}         & 0.71 {\small (0.4)}          & \textbf{0.71} {\small (0.4)} \\ \midrule
        True  & 0.88 {\small (0.4)}          & 1.49 {\small (2.2)}          & 0.94 {\small (0.6)}          & 0.92 {\small (0.5)}          \\ \bottomrule
    \end{tabular}
    \caption{MSE results over 7560 simulated datasets.}
    \label{tab:exp1_pos_indep}
\end{table}
In Table \ref{tab:exp1_pos_indep} we report the different mean squared error metrics of the methods, averaged over all 7560 tests sets (standard deviations are shown in parentheses). We see that the average MSE of RR is half that of the best IW method. The median MSEs follow the relation $\textrm{RR} < \textrm{Naive} < \textrm{IW-t}$, confirmed with respective p-values $1.5\cdot 10^{-40}$ and $3.9\cdot 10^{-25}$ of Wilcoxon's signed rank test. In ADMGs where $X$ is a parent of $S$ there is a clear region of the support of $X$ with no positivity of $S$, hence a clear region where the regression model is extrapolating, similar to Example \ref{ex:1}. When singling out these ADMGs we calculate the average MSE, and additionally the MSEs on the parts where the regression model is inter- and extrapolating, as shown in the table below. These results indicate that IW does not extrapolate well, while RR does.
\begin{table}[!htb]
    \centering
    \small
    \begin{tabular}{lccccc}\toprule
             & $\textrm{MSE}$               & $\textrm{MSE-interp.}$       & $\textrm{MSE-extrap.}$       \\ \midrule
        RR   & \textbf{2.02} {\small (2.2)} & 1.17 {\small (1.1)}          & \textbf{3.06} {\small (4.7)} \\
        IW-t & 7.11 {\small (16.9)}         & 1.08 {\small (0.6)}          & 13.82 {\small (32.6)}        \\
        IW-e & 6.27 {\small (15.5)}         & \textbf{1.08} {\small (0.6)} & 11.85 {\small (28.8)}        \\
        \bottomrule
    \end{tabular}
\end{table}

% In the supplementary material, we investigate the sensitivity of the results with respect to the positivity of the selection mechanism, and with respect to the strength of any remain dependence $Y\nIndep S \given X, Z$, so when the settings is nearly PMAR. \red{TODO conclusion.}

\subsection{Boston Housing data}\label{subsec:exp:rw}
% Although considerable efforts are made to make the simulation setup very general, it's not guaranteed that these results generalise to a real-world setting.
In absence of a real-world dataset where there is missingness \emph{and} the missing value is known,
% To our knowledge there is no dataset available where both the selection/missingness variable is available \emph{and} the value of the potentially missing variable. Instead, 
we consider the Boston Housing dataset \citep{harrison1978hedonic} and simulate a selection mechanism ourselves.
We consider the problem of predicting the value of owner-occupied homes in US Dollars ($Y$) from the number of rooms per dwelling ($X$). We let selection depend on $X$, and on the `percentage of people of lower status of the population in the town where the house is situated' ($Z$), which strongly correlates with $Y$. Selection is simulated by setting $\PP(S=1|X, Z) := \sigma(f_1(X))\sigma(f_2(Z))$, where $f_1, f_2$ are random functions drawn from a Gaussian process. For each dataset, the 506 available observations are randomly split into evenly sized train and test sets. The average MSEs are provided in Table \ref{tab:exp2}, and show the same qualitative results as the simulations.
When calculating the MSE of the inter- and extrapolation regions, we observe that RR performs better than IW at both tasks (table shown in supplements).
\begin{table}[!htb]
    \centering
    \begin{tabular}{lccccc}\toprule
              & $\textrm{MSE}$               & $\textrm{MSE-}\tilde{y}$     & $\textrm{MSE-}w$             & $\textrm{MSE-}\hat{w}$       \\ \midrule
        Naive & 1.23 {\small (2.5)}          & 0.84 {\small (2.3)}          & 0.48 {\small (0.7)}          & 1.79 {\small (5.9)}          \\
        RR    & \textbf{0.71} {\small (0.3)} & \textbf{0.26} {\small (0.3)} & 0.44 {\small (0.4)}          & 1.63 {\small (4.8)}          \\
        IW-t  & 2.18 {\small (4.9)}          & 1.77 {\small (4.9)}          & 0.56 {\small (1.5)}          & 2.40 {\small (9.2)}          \\
        IW-e  & 1.75 {\small (4.4)}          & 1.40 {\small (4.7)}          & 0.50 {\small (0.9)}          & 1.98 {\small (7.4)}          \\
        DR-t  & 1.92 {\small (3.7)}          & 1.65 {\small (3.4)}          & \textbf{0.23} {\small (0.2)} & 0.39 {\small (1.2)}          \\
        DR-e  & 2.43 {\small (5.4)}          & 2.20 {\small (5.5)}          & 0.25 {\small (0.2)}          & \textbf{0.21} {\small (0.3)} \\\midrule
        True  & 0.45 {\small (0.1)}          & 0.54 {\small (0.4)}          & 0.36 {\small (0.3)}          & 0.85 {\small (2.2)}          \\
        \bottomrule
    \end{tabular}
    \caption{Results of $500$ biased instantiations of the Boston Housing dataset.}
    \label{tab:exp2}
\end{table}
\vspace{-1pt}
\section{Discussion and conclusion}
In this work, we have motivated the use of \emph{privileged information} when selection or missingness is nonignorable for estimating a regression model, and introduced the \emph{Privilegedly Missing at Random} (PMAR) setting. We formulated the repeated regression method, the IW regression method, and the doubly robust combination of the two. We note that evaluation of regression methods on biased data is not straightforward and relies on auxiliary models. Experiments show that repeated regression can appropriately correct for bias, and with considerable advantage over IW regression. In particular, in recursive regression, extrapolation is facilitated by privileged data $Z$ that is predictive of $Y$. IW does not have such a property, and extrapolates worse than RR.

Further research can be done on the statistical properties of the proposed methods, e.g.\ on bounding the regret of DR in terms of the regret of RR and IW (possibly under misspecification), or on the interplay of importance weighting, regularization, and extrapolation.

\begin{acknowledgements}
    We thank Kees Jan de Vries for fruitful discussions and Christina Katsimerou, Kostas Tokis and Nils Skotara for feedback on the manuscript.
\end{acknowledgements}

\bibliographystyle{abbrvnat}
% \bibliographystyle{plainnat}
\renewcommand{\bibsection}{\subsubsection*{References}}
\bibliography{philip}

% \todo{\begin{itemize}
%   \item check math of IW
%         % \item Repeated regression: show $X-Z$ plot.
%         \item Doubly Robust regression: That DR lies between IW and RR differs from the results of \cite{bang2005doubly}, \cite{kang2007demystifying}, and \cite{dudik2014doubly} (CHECK THIS!), where DR either outperforms IW and the direct method or has worse performance, albeit on a different task with a different estimator.
%         \item Doubly Robust regression: From \cite{kang2007demystifying}: \textit{A particular case of (12) was proposed by Scharfstein, Rotnitzky and Robins (1999) who took $S_i = \pi_i^{-1}$ . Using the inverse-propensity as a single additional covariate is sufficient to achieve double robustness, because the estimate then becomes the solution to an AIW estimating equation (Bang and Robins, 2005).} We can't do this (can't add it to the final model as this requires $Z$, and adding it to the imputation model makes no sense). Perhaps make a note on this.
%         \item Doubly Robust regression: Prove that \textit{... for this model to be consistent, only one of $\hat{\mu}_{RR}$ \emph{or} $\hat{r}_{IW}$ has to be consistent}.
%         \item Evaluation section: evaluate on test set instead of training error.
%         \item Simulation: SSL co-regression as 'naive' method. No R implementation available. Co-regularized least squares regression by Brefeld et al.\ (2006).
%         \item Simulation: Scale simulated variables? Then the MSEs won't be so small.
%         \item Simulation: Make positivity and dependence a continuous parameter, and replace Tables \ref{tab:exp1_npos_indep}--\ref{tab:exp1_npos_dep} with plots of these parameters vs the MSE (MSE-t?) of the methods.
%         \item Simulation: Perhaps also do a sensitivity analysis of the auxiliary models $\hat{\EE}[Y|X, Z, S=1]$ for RR and $\hat{\PP}(S=1|X, Z)$ for IW/DR, by adding noise with continuous parameter $\sigma$ to their predictions, and plot $\sigma$ vs MSE? Adding noise to the imputation model is straightforward by adding it to its output, but how does this work for $\hat{\PP}(S=1|X, Z)$?
%         \item Simulation: identify for every graph where $X \to S$, for which values of $X$ the model is interpolating/extrapolating ($x_i < mean(x)$ and $mean(x) < x_i$ resp.), and compute MSE of the models separately on those parts. Then perhaps we can conclude that IW interpolates nicely but extrapolates poorly, and RR does both jobs well. IW extrapolates poorly as observations at the edge of the support have heavy weights, which messes up the <regularization?>. Then, we must also compare with lightgbm, as this does flat extrapolation.
%         \item Check bib file
%         \item Page limit: 8 pages. References 2 pages.
%     \end{itemize}}

\end{document}
