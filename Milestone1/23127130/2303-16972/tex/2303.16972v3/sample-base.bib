@misc{indaba,
	title = {Deep Learning Indaba},
	url = {https://deeplearningindaba.com/2023/}
}

@misc{khipu,
	author = {Khipu},
	url = {https://khipu.ai/committee-2023/},
        year = {(n.d.)}
}

@misc{northafricans,
	author = {{N}orth {A}fricans in {ML}},
	url = {https://sites.google.com/view/northafricansinml},
        year = {(n.d.)}
}

@misc{disai,
	author = {{Dis}Ability in AI},
	url = {https://elesa.github.io/ability_in_AI},
        year = {(n.d.)}
}

@misc{muslimsinml,
    author = {{Muslims in ML}},
    url = {http://www.musiml.org/},
    year = {(n.d.)}
}

@misc{tehiku,
    author = {{Muslims in ML}},
    url = {http://www.musiml.org/},
    year = {(n.d.)}
}

@inbook{10.1145/3461702.3462621,
	title        = {What's Fair about Individual Fairness?},
	author       = {Fleisher, Will},
	year         = 2021,
	booktitle    = {Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	pages        = {480–490},
	isbn         = 9781450384735,
	url          = {https://doi.org/10.1145/3461702.3462621},
	abstract     = {One of the main lines of research in algorithmic fairness involves individual fairness (IF) methods. Individual fairness is motivated by an intuitive principle, similar treatment, which requires that similar individuals be treated similarly. IF offers a precise account of this principle using distance metrics to evaluate the similarity of individuals. Proponents of individual fairness have argued that it gives the correct definition of algorithmic fairness, and that it should therefore be preferred to other methods for determining fairness. I argue that individual fairness cannot serve as a definition of fairness. Moreover, IF methods should not be given priority over other fairness methods, nor used in isolation from them. To support these conclusions, I describe four in-principle problems for individual fairness as a definition and as a method for ensuring fairness: (1) counterexamples show that similar treatment (and therefore IF) are insufficient to guarantee fairness; (2) IF methods for learning similarity metrics are at risk of encoding human implicit bias; (3) IF requires prior moral judgments, limiting its usefulness as a guide for fairness and undermining its claim to define fairness; and (4) the incommensurability of relevant moral values makes similarity metrics impossible for many tasks. In light of these limitations, I suggest that individual fairness cannot be a definition of fairness, and instead should be seen as one tool among several for ameliorating algorithmic bias.},
	numpages     = 11
}
@inproceedings{abeba22power,
	title        = {Power to the People? Opportunities and Challenges for Participatory AI},
	author       = {Birhane, Abeba and Isaac, William and Prabhakaran, Vinodkumar and Diaz, Mark and Elish, Madeleine Clare and Gabriel, Iason and Mohamed, Shakir},
	year         = 2022,
	booktitle    = {Equity and Access in Algorithms, Mechanisms, and Optimization},
	location     = {Arlington, VA, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {EAAMO '22},
	doi          = {10.1145/3551624.3555290},
	isbn         = 9781450394772,
	url          = {https://doi.org/10.1145/3551624.3555290},
	abstract     = {Participatory approaches to artificial intelligence (AI) and machine learning (ML) are gaining momentum: the increased attention comes partly with the view that participation opens the gateway to an inclusive, equitable, robust, responsible and trustworthy AI. Among other benefits, participatory approaches are essential to understanding and adequately representing the needs, desires and perspectives of historically marginalized communities. However, there currently exists lack of clarity on what meaningful participation entails and what it is expected to do. In this paper we first review participatory approaches as situated in historical contexts as well as participatory methods and practices within the AI and ML pipeline. We then introduce three case studies in participatory AI. Participation holds the potential for beneficial, emancipatory and empowering technology design, development and deployment while also being at risk for concerns such as cooptation and conflation with other activities. We lay out these limitations and concerns and argue that as participatory AI/ML becomes in vogue, a contextual and nuanced understanding of the term as well as consideration of who the primary beneficiaries of participatory activities ought to be constitute crucial factors to realizing the benefits and opportunities that participation brings.},
	articleno    = 6,
	numpages     = 8,
	keywords     = {Participatory AI, Justice, Machine Learning, Power}
}
@misc{aclanth,
	title        = {ACL Anthology},
        year = {(n.d.)},
	url          = {https://aclanthology.org/}
}
@misc{aclanthbib,
	title        = {ACL Anthology Bib File},
	url          = {https://aclanthology.org/anthology.bib.gz}
}
@misc{aclweb,
        author        = {Association for Computational Linguistics},
        year = {(n.d.)},
	url          = {https://www.aclweb.org/},
}
@misc{acm-dl,
	title        = {ACM Digital Library},
	year = {(n.d.)},
	url          = {https://dl.acm.org/},
	key          = {ACM Digital Libray}
}

@misc{brazil-qstem,
    title = {Brazil LGBTQ activists, HIV/AIDS service providers fear Bolsonaro reelection},
    year = {2022},
    url = {https://www.washingtonblade.com/2022/05/19/brazil-lgbtq-activists-hiv-aids-service-providers-fear-bolsonaro-reelection/}
}

@misc{SA-qstem,
    title = {Some African Countries Are Trying to Use Science to Make Homophobic Laws, Now African Scientists are Pushing Back},
    year = {2015},
    url = {https://www.smithsonianmag.com/smart-news/africans-scientists-speak-out-against-homophobic-laws-180955579/}
}

@misc{india-qstem,
    title = {A constant uneasy state: Trans people in STEM in India},
    year = {2020},
    url  = {https://thelifeofscience.com/2020/11/09/transgender-people-in-science/}
}

@misc{agnew2021rebuilding,
	title        = {Rebuilding Trust: Queer in AI Approach to Artificial Intelligence Risk Management},
	author       = {QueerInAI, Organizers of and Ashwin S and William Agnew and Hetvi Jethwani and Arjun Subramonian},
	year         = 2021,
	journal      = {Queer in AI Workshop at NeurIPS 2021},
	url          = {queerinai.org/risk-management}
}

@article{yadav2020forgotten,
  title={The forgotten scholar: underrepresented minority postdoc experiences in STEM fields},
  author={Yadav, Aman and Seals, Christopher D and Sullivan, Cristina M Soto and Lachney, Michael and Clark, Quintana and Dixon, Kathy G and Smith, Mark JT},
  journal={Educational Studies},
  volume={56},
  number={2},
  pages={160--185},
  year={2020},
  publisher={Taylor \& Francis}
}

@article{mcmillon2021implementing,
  title={Implementing diversity, equity and inclusion efforts at conferences},
  author={McMillon-Brown, Lyndsey},
  journal={Nature Energy},
  volume={6},
  number={11},
  pages={1000--1002},
  year={2021},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{katell2020toward,
  title={Toward situated interventions for algorithmic equity: lessons from the field},
  author={Katell, Michael and Young, Meg and Dailey, Dharma and Herman, Bernease and Guetler, Vivian and Tam, Aaron and Bintz, Corinne and Raz, Daniella and Krafft, PM},
  booktitle={Proceedings of the 2020 conference on fairness, accountability, and transparency},
  pages={45--55},
  year={2020}
}


@article{collins2018community,
  title={Community-based participatory research (CBPR): Towards equitable involvement of community in psychology research.},
  author={Collins, Susan E and Clifasefi, Seema L and Stanton, Joey and Straits, Kee JE and Gil-Kashiwabara, Eleanor and Rodriguez Espinosa, Patricia and Nicasio, Andel V and Andrasik, Michele P and Hawes, Starlyn M and Miller, Kimberly A and others},
  journal={American Psychologist},
  volume={73},
  number={7},
  pages={884},
  year={2018},
  publisher={American Psychological Association}
}

@incollection{ferree2016discursive,
  title={The discursive politics of feminist intersectionality},
  author={Ferree, Myra Marx},
  booktitle={Framing Intersectionality},
  pages={55--65},
  year={2016},
  publisher={Routledge}
}


@article{casey2019discrimination,
  title={Discrimination in the United States: Experiences of lesbian, gay, bisexual, transgender, and queer Americans},
  author={Casey, Logan S and Reisner, Sari L and Findling, Mary G and Blendon, Robert J and Benson, John M and Sayde, Justin M and Miller, Carolyn},
  journal={Health services research},
  volume={54},
  pages={1454--1466},
  year={2019},
  publisher={Wiley Online Library}
}


@book{meyer2015violence,
  title={Violence against queer people: Race, class, gender, and the persistence of anti-LGBT discrimination},
  author={Meyer, Doug},
  year={2015},
  publisher={Rutgers University Press}
}

@article{Richey2019GenderAS,
  title={Gender and sexual minorities in astronomy and planetary science face increased risks of harassment and assault},
  author={Christina R. Richey and Katharine M N Lee and Erica M. Rodgers and Kathryn B. H. Clancy},
  journal={Bulletin of the American Astronomical Society},
  year={2019},
  volume={51},
  pages={0206}
}

@misc{aclanthocorrections,
    title        = {Requesting Corrections},
    author       = {ACL Anthology},
    year         = {(n.d.)},
    note         = {\url{https://aclanthology.org/info/corrections/} [Accessed Feb 2023]}
}

@misc{naaclnamechange,
    title        = {NAACL Citation Name Change Procedure},
    author       = {NAACL DEI Team},
    year         = {(n.d.)},
    note         = {\url{https://2021.naacl.org/blog/name-change-procedure/} [Accessed Feb 2023]}
}

@misc{ieeenamechange,
    title        = {IEEE Author Name Change Policy},
    author       = {IEEE},
    year         = {(n.d.)},
    note         = {\url{https://conferences.ieeeauthorcenter.ieee.org/author-ethics/guidelines-and-policies/ieee-author-name-change-policy/} [Accessed Feb 2023]}
}

@misc{neuripsnamechange,
    title = {NeurIPS Proceedings: Name Change Policy},
    author = {NeurIPS},
    year = {(n.d.)},
    note = {\url{https://papers.nips.cc/}, ``Name Change Policy'' link in footer [Accessed Feb 2023]}
}

@misc{pmlrnamechange,
    title = {Comment on pull request: Fix author name},
    author = {Neil Lawrence},
    year = {2021},
    url = {https://github.com/mlresearch/v119/pull/4#issuecomment-760081621},
}

@misc{openreviewnamechange,
    title = {Comment on issue: Transphobic name and email policy},
    author = {Melisa Bok},
    year = {2022},
    url = {https://github.com/openreview/openreview/issues/28#issuecomment-1124245541},
}

@misc{arxivnamechange,
    title = {ar{X}iv Proceedings: Name Change Policy},
    author = {ar{X}iv},
    year = {2021},
    note = {\url{https://blog.arxiv.org/2021/03/11/update-name-change-policy}, Name Change Policy blog}
}

@misc{acmnamechange,
    title = {ACM Publications Policy on Author Name Changes},
    author = {ACM Publications Board},
    year = {2019},
    url = {https://www.acm.org/publications/policies/author-name-changes},
}

@misc{danicaslides,
    title = {Name Change Policies: A Brief (Personal) Tour},
    author = {Danica J. Sutherland},
    year = {2022},
    note = {Queer in AI workshop, NeurIPS 2022; \url{https://djsutherland.ml/slides/qai-name-change}},
}

@misc{aclpubcheck,
    author       = {ACL Pubcheck},
    year         = {(n.d.)},
    note         = {\url{https://github.com/acl-org/aclpubcheck} [Accessed Feb 2023]}
}

@article{agrawal2021aadhaar,
	title        = {Privacy and Security of Aadhaar: A Computer Science Perspective},
	author       = {Agrawal, Shweta and Banerjee, Subhashis and Sharma, Subodh},
	journal      = {Economic and Political Weekly},
	url          = {https://www.epw.in/journal/2017/37/special-articles/privacy-and-security-aadhaar.html}
}
@article{alasuutari2021necro,
	title        = {What do we talk about when we talk about queer death? 2/ {LGBTQ+} necropolitics},
	author       = {Alasuutari, Varpu and Whitestone, Stephenson Brooks and Hansen, Laura Goret and Jaworski, Katrina and Doletskaya, Olga and Zubillaga-Pow, Jun},
	year         = 2021,
	journal      = {Whatever. A Transdisciplinary Journal of Queer Theories and Studies}
}
@article{ali2021classification,
	title        = {classication},
	author       = {Ali, Safinah Arshad},
	year         = 2021,
	journal      = {Queer in AI Workshop at Conference on Neural Information Processing Systems 2021},
	url          = {https://sites.google.com/view/queer-in-ai/neurips-2021#h.p8mb6qvi3v9m}
}
@misc{allenai,
        author       = {Allen Institute for Artificial Intelligence},
        year = {(n.d.)},
	url          = {https://allenai.org/},
}

@misc{gathertown,
    title = {Gather},
    year = {(n.d.)},
    url = {https://gather.town}
}

@article{AlphaFold2021,
	title        = {Highly accurate protein structure prediction with {AlphaFold}},
	author       = {Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and {\v{Z}}{\'\i}dek, Augustin and Potapenko, Anna and Bridgland, Alex and Meyer, Clemens and Kohl, Simon A A and Ballard, Andrew J and Cowie, Andrew and Romera-Paredes, Bernardino and Nikolov, Stanislav and Jain, Rishub and Adler, Jonas and Back, Trevor and Petersen, Stig and Reiman, David and Clancy, Ellen and Zielinski, Michal and Steinegger, Martin and Pacholska, Michalina and Berghammer, Tamas and Bodenstein, Sebastian and Silver, David and Vinyals, Oriol and Senior, Andrew W and Kavukcuoglu, Koray and Kohli, Pushmeet and Hassabis, Demis},
	year         = 2021,
	journal      = {Nature},
	volume       = 596,
	number       = 7873,
	pages        = {583--589},
	doi          = {10.1038/s41586-021-03819-2}
}
@article{anderson1994representations,
	title        = {Representations and requirements: The value of ethnography in system design},
	author       = {Anderson, Robert J},
	year         = 1994,
	journal      = {Human-computer interaction},
	publisher    = {Taylor \& Francis},
	volume       = 9,
	number       = 2,
	pages        = {151--182}
}
@article{animesh2018neuralparscit,
	title        = {Neural ParsCit: A Deep Learning Based Reference String Parser},
	author       = {Prasad, Animesh and Kaur, Manpreet and Kan, Min-Yen},
	year         = 2018,
	journal      = {International Journal on Digital Libraries},
	publisher    = {Springer},
	volume       = 19,
	pages        = {323--337},
	url          = {https://link.springer.com/article/10.1007/s00799-018-0242-1}
}
@misc{arxiv,
	title        = {arXiv},
	year = {(n.d.)},
	url          = {https://arxiv.org/},
	key          = {arXiv}
}
@misc{aven,
	author        = {The Asexual Visibility and Education Network},
	year = {(n.d.)},
	url          = {http://www.asexuality.org/}
}
@book{barocas-hardt-narayanan,
	title        = {Fairness and Machine Learning},
	author       = {Solon Barocas and Moritz Hardt and Arvind Narayanan},
	year         = 2019,
	publisher    = {fairmlbook.org},
	note         = {\url{http://www.fairmlbook.org}}
}
@article{barocas2017bias,
	title        = {The Problem With Bias: Allocative Versus Representational Harms in Machine Learning},
	author       = {Barocas, Solon and Crawford, Kate and Shapiro, Aaron and Wallach, Hanna},
	year         = 2017,
	journal      = {SIGCIS}
}
@article{belone2016community,
	title        = {Community-based participatory research conceptual model: Community partner consultation and face validity},
	author       = {Belone, Lorenda and Lucero, Julie E and Duran, Bonnie and Tafoya, Greg and Baker, Elizabeth A and Chan, Domin and Chang, Charlotte and Greene-Moton, Ella and Kelley, Michele A and Wallerstein, Nina},
	year         = 2016,
	journal      = {Qualitative health research},
	publisher    = {Sage Publications Sage CA: Los Angeles, CA},
	volume       = 26,
	number       = 1,
	pages        = {117--135}
}
@inproceedings{bender2021dangers,
	title        = {On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?},
	author       = {Bender, Emily M and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
	year         = 2021,
	booktitle    = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
	pages        = {610--623}
}
@article{birhane2021multimodal,
	title        = {Multimodal datasets: misogyny, pornography, and malignant stereotypes},
	author       = {Birhane, Abeba and Prabhu, Vinay Uday and Kahembwe, Emmanuel},
	year         = 2021,
	journal      = {arXiv},
	url          = {https://arxiv.org/abs/2110.01963}
}
@misc{blackinai,
	url          = {https://blackinai.github.io},
	key          = {Black in AI},
        year         = {(n.d.)}, 
}
@article{Bolukbasi2016ManIT,
	title        = {Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings},
	author       = {Tolga Bolukbasi and Kai-Wei Chang and James Y. Zou and Venkatesh Saligrama and Adam Tauman Kalai},
	year         = 2016,
	journal      = {Advances in Neural Information Processing Systems},
	volume       = 29
}
@book{bowker2000sorting,
	title        = {Sorting things out: Classification and its consequences},
	author       = {Bowker, Geoffrey C and Star, Susan Leigh},
	year         = 2000,
	publisher    = {MIT press}
}
@article{brindaalakshmi2020aadhaar,
	title        = {Gendering of Development Data in India: Beyond the Binary},
	author       = {K., Brindaalakshmi},
	year         = 2020,
	journal      = {The Centre for Internet and Society},
	url          = {https://cis-india.org/raw/brindaalakshmi-k-gendering-development-data-india}
}
@article{brindaalakshmi2021aadhaar,
	title        = {Is digital colonisation redefining the understanding of agency, bodily autonomy and being human?},
	author       = {K., Brindaalakshmi},
	year         = 2021,
	journal      = {Queer in AI Workshop at International Conference on Machine Learning 2021},
	url          = {https://sites.google.com/view/queer-in-ai/icml-2021#h.lx7wo16mt2ax}
}
@inproceedings{cao-daume-iii-2020-toward,
	title        = {Toward Gender-Inclusive Coreference Resolution},
	author       = {Cao, Yang Trista  and Daum{\'e} III, Hal},
	year         = 2020,
	month        = jul,
	booktitle    = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {4568--4595},
	doi          = {10.18653/v1/2020.acl-main.418},
	url          = {https://aclanthology.org/2020.acl-main.418},
	abstract     = {Correctly resolving textual mentions of people fundamentally entails making inferences about those people. Such inferences raise the risk of systemic biases in coreference resolution systems, including biases that can harm binary and non-binary trans and cis stakeholders. To better understand such biases, we foreground nuanced conceptualizations of gender from sociology and sociolinguistics, and develop two new datasets for interrogating bias in crowd annotations and in existing coreference resolution systems. Through these studies, conducted on English text, we confirm that without acknowledging and building systems that recognize the complexity of gender, we build systems that lead to many potential harms.}
}
@article{cech2021systemic,
	title        = {Systemic inequalities for {LGBTQ} professionals in {STEM}},
	author       = {Cech, EA and Waidzunas, TJ},
	year         = 2021,
	journal      = {Science advances},
	publisher    = {American Association for the Advancement of Science},
	volume       = 7,
	number       = 3,
	pages        = {eabe0933}
}
@article{ceres_2022,
	title        = {Kids are back in classrooms and laptops are still spying on them},
	author       = {Ceres, Pia},
	year         = 2022,
	month        = {Aug},
	journal      = {Wired},
	publisher    = {Conde Nast},
	url          = {https://www.wired.com/story/student-monitoring-software-privacy-in-schools/}
}
@inproceedings{cobb2014designing,
	title        = {Designing for the deluge: understanding \& supporting the distributed, collaborative work of crisis volunteers},
	author       = {Cobb, Camille and McCarthy, Ted and Perkins, Annuska and Bharadwaj, Ankitha and Comis, Jared and Do, Brian and Starbird, Kate},
	year         = 2014,
	booktitle    = {Proceedings of the 17th ACM conference on Computer supported cooperative work \& social computing},
	pages        = {888--899}
}
@book{collins2019intersectionality,
	title        = {Intersectionality as critical social theory},
	author       = {Collins, Patricia Hill},
	year         = 2019,
	publisher    = {Duke University Press}
}
@book{collins2020intersectionality,
	title        = {Intersectionality},
	author       = {Collins, Patricia Hill and Bilge, Sirma},
	year         = 2020,
	publisher    = {John Wiley \& Sons}
}
@misc{community-based-participatory-action-research,
	title        = {What can we learn from longitudinal studies on the
impacts of college internships?},
        author      = {Tu, Fangjing},
        year           = {2022},
	journal      = {Community-Based Participatory Action Research},
	publisher    = {Center for Research on College to Workforce Transitions (CCWT)},
	url          = {https://ccwt.wisc.edu/wp-content/uploads/2022/04/Final_CCWT_report_LR-What-can-we-learn-from-longitudinal-studies-on-the-impacts-of-college-internships.pdf}
}
@BOOK{cooke2001participation,
  title     = "Participation",
  author    = "Cooke, Bill and Kothari, Uma",
  editor    = "Cooke, Bill and Kothari, Uma",
  publisher = "Zed Books",
  month     =  feb,
  year      =  2001,
  address   = "London, England",
  language  = "en"
}
@inproceedings{Cooper_2021,
	title        = {Emergent Unfairness in Algorithmic Fairness-Accuracy Trade-Off Research},
	author       = {A. Feder Cooper and Ellen Abrams and NA NA},
	year         = 2021,
	month        = {jul},
	booktitle    = {Proceedings of the 2021 {AAAI}/{ACM} Conference on {AI}, Ethics, and Society},
	publisher    = {{ACM}},
	doi          = {10.1145/3461702.3462519},
	url          = {https://doi.org/10.1145%2F3461702.3462519}
}
@article{corbett2018measure,
	title        = {The measure and mismeasure of fairness: A critical review of fair machine learning},
	author       = {Corbett-Davies, Sam and Goel, Sharad},
	year         = 2018,
	journal      = {arXiv preprint arXiv:1808.00023},
	url          = {https://arxiv.org/abs/1808.00023}
}
@article{guyan2022fixing,
    author = {Kevin Guyan},
    title = {Fixing the Wrong Problems: Queer Communities and the False Promise of Unbiased and Equal Data Systems},
    journal = {European Data Protection Law Review},
    volume = {8},
    number = {4},
    year = {2022},
    abstract = {},
    url = {https://doi.org/10.21552/edpl/2022/4/5},
    doi = {10.21552/edpl/2022/4/5}
}
@misc{beyondfairness2021,
    title = {Beyond Fairness},
    author = {Gebru, Timnit and Denton, Emily},
    url = {https://neurips.cc/virtual/2021/tutorial/21889},
    year = 2021
}
@article{costanza2018design,
	title        = {Design justice: Towards an intersectional feminist framework for design theory and practice},
	author       = {Costanza-Chock, Sasha},
	year         = 2018,
	journal      = {Proceedings of the Design Research Society}
}
@inproceedings{councill-etal-2008-parscit,
	title        = {{P}ars{C}it: an Open-source {CRF} Reference String Parsing Package},
	author       = {Councill, Isaac  and Giles, C. Lee  and Kan, Min-Yen},
	year         = 2008,
	month        = may,
	booktitle    = {Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08)},
	publisher    = {European Language Resources Association (ELRA)},
	address      = {Marrakech, Morocco},
	url          = {http://www.lrec-conf.org/proceedings/lrec2008/pdf/166_paper.pdf},
	abstract     = {We describe ParsCit, a freely available, open-source implementation of a reference string parsing package. At the core of ParsCit is a trained conditional random field (CRF) model used to label the token sequences in the reference string. A heuristic model wraps this core with added functionality to identify reference strings from a plain text file, and to retrieve the citation contexts. The package comes with utilities to run it as a web service or as a standalone utility. We compare ParsCit on three distinct reference string datasets and show that it compares well with other previously published work.}
}
@article{crenshaw1989intersectionality,
	title        = {Demarginalizing the Intersection of Race and Sex: A Black Feminist Critique of Antidiscrimination Doctrine, Feminist Theory and Antiracist Policies},
	author       = {Crenshaw, Kimberle},
	year         = 1989,
	journal      = {University of Chicago Legal Forum},
	volume       = 1989,
	number       = 1,
	pages        = {139--167},
	url          = {http://chicagounbound.uchicago.edu/uclf/vol1989/iss1/8/}
}
@book{d2020data,
	title        = {Data feminism},
	author       = {D'ignazio, Catherine and Klein, Lauren F},
	year         = 2020,
	publisher    = {MIT press}
}
@misc{dblp,
	title        = {DBLP},
	year = {(n.d.)},
	url          = {https://dblp.org/},
	key          = {DBLP}
}
@misc{denton2021beyond,
	title        = {Beyond Fairness in Machine Learning},
	author       = {Timnit Gebru and Emily Denton},
	year         = 2021,
	journal      = {Conference on Neural Information Processing Systems 2021},
	booktitle    = {Conference on Neural Information Processing Systems 2021}
}
@misc{department_of_health_and_human_services_2015,
	author       = {Department of health and human services},
	year         = 2015,
	month        = {Jun},
	journal      = {PRINCIPLES OF COMMUNITY ENGAGEMENT},
	publisher    = {Department of health and human services},
	url          = {https://www.atsdr.cdc.gov/communityengagement/index.html}
}
@inproceedings{dev2021harms,
	title        = {Harms of Gender Exclusivity and Challenges in Non-Binary Representation in Language Technologies},
	author       = {Dev, Sunipa  and Monajatipoor, Masoud  and Ovalle, Anaelia  and Subramonian, Arjun  and Phillips, Jeff  and Chang, Kai-Wei},
	year         = 2021,
	month        = nov,
	booktitle    = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
	publisher    = {Association for Computational Linguistics},
	address      = {Online and Punta Cana, Dominican Republic},
	pages        = {1968--1994},
	doi          = {10.18653/v1/2021.emnlp-main.150},
	url          = {https://aclanthology.org/2021.emnlp-main.150},
	abstract     = {Gender is widely discussed in the context of language tasks and when examining the stereotypes propagated by language models. However, current discussions primarily treat gender as binary, which can perpetuate harms such as the cyclical erasure of non-binary gender identities. These harms are driven by model and dataset biases, which are consequences of the non-recognition and lack of understanding of non-binary genders in society. In this paper, we explain the complexity of gender and language around it, and survey non-binary persons to understand harms associated with the treatment of gender as binary in English language technologies. We also detail how current language representations (e.g., GloVe, BERT) capture and perpetuate these harms and related challenges that need to be acknowledged and addressed for representations to equitably encode gender information.}
}
@article{devito2018too,
	title        = {'Too Gay for {F}acebook': Presenting {LGBTQ+} Identity Throughout the Personal Social Media Ecosystem},
	author       = {DeVito, Michael A and Walker, Ashley Marie and Birnholtz, Jeremy},
	year         = 2018,
	journal      = {Proceedings of the ACM on Human-Computer Interaction},
	publisher    = {ACM New York, NY, USA},
	volume       = 2,
	number       = {CSCW},
	pages        = {1--23}
}
@inproceedings{devito2020queer,
	title        = {Queer in HCI: Supporting LGBTQIA+ Researchers and Research Across Domains},
	author       = {DeVito, Michael A and Walker, Ashley Marie and Lustig, Caitlin and Ko, Amy J and Spiel, Katta and Ahmed, Alex A and Allison, Kimberley and Scheuerman, Morgan and Dym, Briana and Brubaker, Jed R and others},
	year         = 2020,
	booktitle    = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
	pages        = {1--4}
}
@misc{diverseinai,
	url          = {http://www.diverseinai.org},
	key          = {Diversity in AI},
        year         = {(n.d.)}, 
}
@misc{dlindaba,
	year         = 2017,
	url          = {https://deeplearningindaba.com/2021/},
	key          = {Deep Learning Indaba}
}
@article{dodge2021documenting,
	title        = {Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus},
	author       = {Dodge, Jesse and Sap, Maarten and Marasovi{\'c}, Ana and Agnew, William and Ilharco, Gabriel and Groeneveld, Dirk and Mitchell, Margaret and Gardner, Matt},
	year         = 2021,
	month        = nov,
	journal      = {arXiv preprint arXiv:2104.08758},
	booktitle    = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
	publisher    = {Association for Computational Linguistics},
	address      = {Online and Punta Cana, Dominican Republic},
	pages        = {1286--1305},
	doi          = {10.18653/v1/2021.emnlp-main.98},
	url          = {https://aclanthology.org/2021.emnlp-main.98}
}
@inproceedings{dourish_implications,
	title        = {Implications for Design},
	author       = {Dourish, Paul},
	year         = 2006,
	booktitle    = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
	location     = {Montr\'{e}al, Qu\'{e}bec, Canada},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CHI '06},
	pages        = {541–550},
	doi          = {10.1145/1124772.1124855},
	isbn         = 1595933727,
	url          = {https://doi.org/10.1145/1124772.1124855},
	abstract     = {Although ethnography has become a common approach in HCI research and design, considerable confusion still attends both ethnographic practice and the criteria by which it should be evaluated in HCI. Often, ethnography is seen as an approach to field investigation that can generate requirements for systems development; by that token, the major evaluative criterion for an ethnographic study is the implications it can provide for design. Exploring the nature of ethnographic inquiry, this paper suggests that "implications for design" may not be the best metric for evaluation and may, indeed, fail to capture the value of ethnographic investigations.},
	numpages     = 10,
	keywords     = {design, ethnography}
}
@article{drage2021recruitment,
	title        = {Queering Classifications in Recruitment AI},
	author       = {Drage, Eleanor},
	year         = 2021,
	journal      = {Queer in AI Workshop at International Conference on Machine Learning 2021},
	url          = {https://sites.google.com/view/queer-in-ai/icml-2021#h.lx7wo16mt2ax}
}
@article{drescher2015out,
	title        = {Out of DSM: Depathologizing homosexuality},
	author       = {Drescher, Jack},
	year         = 2015,
	journal      = {Behavioral sciences},
	publisher    = {Multidisciplinary Digital Publishing Institute},
	volume       = 5,
	number       = 4,
	pages        = {565--575}
}
@inproceedings{Dwork2011FairnessTA,
	title        = {Fairness through awareness},
	author       = {Cynthia Dwork and Moritz Hardt and Toniann Pitassi and Omer Reingold and Richard S. Zemel},
	year         = 2012,
	booktitle    = {Proceedings of the 3rd Innovations in Theoretical Computer Science Conference},
	doi          = {10.1145/2090236.2090255}
}
@book{dynes1970organized,
	title        = {Organized behavior in disaster},
	author       = {Dynes, Russell Rowe},
	year         = 1970,
	publisher    = {Heath Lexington Books}
}
@article{eichelberger2017uncovering,
	title        = {Uncovering Barriers to Financial Capability: Underrepresented Students' Access to Financial Resources.},
	author       = {Eichelberger, Brenda and Mattioli, Heather and Foxhoven, Rachel},
	year         = 2017,
	journal      = {Journal of Student Financial Aid},
	publisher    = {ERIC},
	volume       = 47,
	number       = 3,
	pages        = 5
}
@article{elefante2021lips,
	title        = {Lips},
	author       = {Elefante, Val},
	year         = 2021,
	journal      = {Queer in AI Workshop at International Conference on Machine Learning 2021},
	booktitle    = {Queer in AI Workshop at International Conference on Machine Learning 2021},
	url          = {https://sites.google.com/view/queer-in-ai/icml-2021#h.lx7wo16mt2ax}
}
@misc{emnlp,
	url          = {https://emnlp.org/},
	author          = {Conference on Empirical Methods in Natural Language Processing},
        year = {(n.d.)}
}
@inproceedings{feldman2015disparate,
	title        = {Certifying and Removing Disparate Impact},
	author       = {Feldman, Michael and Friedler, Sorelle A. and Moeller, John and Scheidegger, Carlos and Venkatasubramanian, Suresh},
	year         = 2015,
	booktitle    = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	location     = {Sydney, NSW, Australia},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {KDD '15},
	pages        = {259–268},
	doi          = {10.1145/2783258.2783311},
	isbn         = 9781450336642,
	url          = {https://doi.org/10.1145/2783258.2783311},
	abstract     = {What does it mean for an algorithm to be biased? In U.S. law, unintentional bias is encoded via disparate impact, which occurs when a selection process has widely different outcomes for different groups, even as it appears to be neutral. This legal determination hinges on a definition of a protected class (ethnicity, gender) and an explicit description of the process.When computers are involved, determining disparate impact (and hence bias) is harder. It might not be possible to disclose the process. In addition, even if the process is open, it might be hard to elucidate in a legal setting how the algorithm makes its decisions. Instead of requiring access to the process, we propose making inferences based on the data it uses.We present four contributions. First, we link disparate impact to a measure of classification accuracy that while known, has received relatively little attention. Second, we propose a test for disparate impact based on how well the protected class can be predicted from the other attributes. Third, we describe methods by which data might be made unbiased. Finally, we present empirical evidence supporting the effectiveness of our test for disparate impact and our approach for both masking bias and preserving relevant information in the data. Interestingly, our approach resembles some actual selection practices that have recently received legal scrutiny.},
	numpages     = 10,
	keywords     = {disparate impact, machine learning, fairness}
}
@article{fine2006intimate,
	title        = {Intimate details: Participatory action research in prison},
	author       = {Fine, Michelle and Torre, Mar{\'\i}a Elena},
	year         = 2006,
	journal      = {Action Research},
	publisher    = {Sage Publications Sage CA: Thousand Oaks, CA},
	volume       = 4,
	number       = 3,
	pages        = {253--269}
}
@article{floridi2019establishing,
	title        = {Establishing the rules for building trustworthy AI},
	author       = {Floridi, Luciano},
	year         = 2019,
	journal      = {Nature Machine Intelligence},
	publisher    = {Nature Publishing Group UK London},
	volume       = 1,
	number       = 6,
	pages        = {261--262}
}
@misc{forbes2021guadiano,
	title        = {Exposure doesn’t pay: Why tech conferences should compensate their speakers},
	author       = {Paolo Gaudiano},
	year         = 2021,
	month        = {June},
	journal      = {Forbes},
	url          = {https://www.forbes.com/sites/paologaudiano/2021/06/07/how-to-make-conference-speaker-fees-more-inclusive-and-equitable/},
	howpublished = {\url{https://www.forbes.com/sites/paologaudiano/2021/06/07/how-to-make-conference-speaker-fees-more-inclusive-and-equitable/}}
}
@article{gaventa1988participatory,
	title        = {Participatory research in North America},
	author       = {Gaventa, John},
	year         = 1988,
	journal      = {Convergence},
	publisher    = {International Council for Adult Education},
	volume       = 21,
	number       = 2,
	pages        = 19
}
@article{gay2013out,
	title        = {Out online: The experiences of lesbian, gay, bisexual and transgender youth on the Internet},
	author       = {Gay, Lesbian and Network, Straight Education and others},
	year         = 2013,
	journal      = {New York, NY}
}
@misc{gdprpersonaldata,
	title        = {GDPR Personal Data},
	year = {(n.d.)},
	url          = {https://gdpr-info.eu/issues/personal-data/},
	key          = {GDPR Personal Data}
}
@article{geeng2021lgbtq,
	title        = {{LGBTQ} privacy concerns on social media},
	author       = {Geeng, Christine and Hiniker, Alexis},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2112.00107},
	booktitle    = {CHI 2018 Workshop: Exploring Individual Differences in Privacy}
}
@article{geengqueer,
	title        = {Queer Security Advice in the US},
	author       = {Geeng, Christine and Harris, Mike and Redmiles, Elissa and Roesner, Franziska},
	year         = 2021,
	booktitle    = {6th Workshop on Inclusive Privacy and Security (WIPS)}
}
@article{gomes2019drag,
	title        = {Drag queens and artificial intelligence. Should computers decide what is toxic on the internet},
	author       = {Gomes, A and Antonialli, D and Dias-Oliva, T},
	year         = 2019,
	journal      = {Internet Lab blog},
	url          = {https://internetlab.org.br/en/news/drag-queens-and-artificial-intelligence-should-computers-decide-what-is-toxic-on-the-internet/}
}
@article{goochscholarcy,
	title        = {How Scholarcy contributes to and makes use of open citations},
	author       = {Gooch, Phil},
	year         = 2018,
	url          = {https://www.scholarcy.com/how-scholarcy-contributes-to-and-makes-use-of-open-citations/}
}
@book{gray2019ghost,
	title        = {Ghost work: How to stop Silicon Valley from building a new global underclass},
	author       = {Gray, Mary L and Suri, Siddharth},
	year         = 2019,
	publisher    = {Eamon Dolan Books}
}
@incollection{green2003appendix,
	title        = {Appendix C: Guidelines for participatory research in health promotion},
	author       = {Green, LW and George, MA and others},
	year         = 2003,
	booktitle    = {Community-based participatory research for health},
	publisher    = {San Francisco, CA, Jossey-Bass},
	editor       = {M. Minkler and N. Wallerstein}
}
@article{grindrpolice,
	title        = {Egyptian police 'are using {Grindr} to find and arrest {LGBT} people'},
	author       = {Payton, Matt},
	year         = 2021,
	journal      = {The Independent},
	url          = {https://www.independent.co.uk/news/world/africa/egyptian-police-grindr-dating-app-arrest-lgbt-gay-antigay-lesbian-homophobia-a7211881.html}
}
@article{gringeri2010mapping,
	title        = {What Makes it Feminist?: Mapping the Landscape of Feminist Social Work Research},
	author       = {Christina E. Gringeri and Stéphanie Wahab and Ben Anderson-Nathe},
	year         = 2010,
	journal      = {Affilia},
	volume       = 25,
	number       = 4,
	pages        = {390--405},
	doi          = {10.1177/0886109910384072},
	url          = {https://doi.org/10.1177/0886109910384072},
	eprint       = {https://doi.org/10.1177/0886109910384072},
	abstract     = {Social work as an academic discipline has long included women and gender as central categories of analysis; the social work profession, started and maintained largely by women, has been home to several generations of feminists. Yet, social work is curiously and strikingly absent from broader multidisciplinary discussions of feminist research. This article explores contemporary feminist social work research by examining 50 randomly selected research-based articles that claimed feminism within their work. The analysis focused on the authors’ treatment of the gender binary, their grounding in theory, their treatment of methodology, and their feminist claims. Feminist social work researchers are invited to reconceptualize feminisms to include third-wave feminist thought and more explicitly engage theory and reflexivity in their work.}
}
@article{gutierrez2018privacy,
	title        = {Data Privacy Is Crucial for the LGBT Community},
	author       = {Carlos Gutierrez},
	year         = 2018,
	url          = {https://staysafeonline.org/blog/data-privacy-crucial-lgbt-community/}
}
@misc{hacker-taylor,
	title        = {Community-Engaged Research 101},
	author       = {Hacker, Karen and Taylor, J. Glover},
	year         = 2011,
	journal      = {Community-Engaged Research 101 - Harvard Catalyst},
	publisher    = {Harvard Catalyst},
	url          = {https://catalyst.harvard.edu/publications-documents/community-engaged-research-101-2/}
}
@book{hammack2009story,
	title        = {The story of sexual identity: Narrative perspectives on the gay and lesbian life course},
	author       = {Hammack, Phillip L and Cohler, Bertram J},
	year         = 2009,
	publisher    = {Oxford University Press}
}
@inproceedings{hanna2020race,
	title        = {Towards a Critical Race Methodology in Algorithmic Fairness},
	author       = {Hanna, Alex and Denton, Emily and Smart, Andrew and Smith-Loud, Jamila},
	year         = 2020,
	booktitle    = {Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
	location     = {Barcelona, Spain},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {FAT* '20},
	pages        = {501–512},
	doi          = {10.1145/3351095.3372826},
	isbn         = 9781450369367,
	url          = {https://doi.org/10.1145/3351095.3372826},
	abstract     = {We examine the way race and racial categories are adopted in algorithmic fairness frameworks. Current methodologies fail to adequately account for the socially constructed nature of race, instead adopting a conceptualization of race as a fixed attribute. Treating race as an attribute, rather than a structural, institutional, and relational phenomenon, can serve to minimize the structural aspects of algorithmic unfairness. In this work, we focus on the history of racial categories and turn to critical race theory and sociological work on race and ethnicity to ground conceptualizations of race for fairness research, drawing on lessons from public health, biomedical research, and social survey research. We argue that algorithmic fairness researchers need to take into account the multidimensionality of race, take seriously the processes of conceptualizing and operationalizing race, focus on social processes which produce racial inequality, and consider perspectives of those most affected by sociotechnical systems.},
	numpages     = 12,
	keywords     = {critical race theory, algorithmic fairness, race and ethnicity}
}
@article{harper2016internet,
	title        = {The internet’s multiple roles in facilitating the sexual orientation identity development of gay and bisexual male adolescents},
	author       = {Harper, Gary W and Serrano, Pedro A and Bruce, Douglas and Bauermeister, Jose A},
	year         = 2016,
	journal      = {American journal of men's health},
	publisher    = {Sage Publications Sage CA: Los Angeles, CA},
	volume       = 10,
	number       = 5,
	pages        = {359--376}
}
@incollection{Iantaffi2017,
	title        = {Future Directions},
	author       = {Iantaffi, Alex},
	year         = 2017,
	booktitle    = {Genderqueer and Non-Binary Genders},
	publisher    = {Palgrave Macmillan UK},
	address      = {London},
	pages        = {283--296},
	doi          = {10.1057/978-1-137-51053-2_14},
	isbn         = {978-1-137-51053-2},
	url          = {https://doi.org/10.1057/978-1-137-51053-2_14},
	editor       = {Richards, Christina and Bouman, Walter Pierre and Barker, Meg-John},
	abstract     = {This chapter provides some reflections and speculations on the future direction of non-binary genders and the impact of non-binary genders across a range of disciplines, as well as considering this in relationship to the movement towards decolonization of identities and experiences in White western contexts. An intersectional perspective is adopted throughout the chapter, which is essentially interdisciplinary in nature, including consideration from feminist science to science fiction. Areas such as identity politics and structural repercussions are addressed, before imagining what a world that adopted a systemic and intersectional approach to all genders might actually look like. The chapter ends with an invitation to practise living with uncertainty, and to hold any possibilities for the future directions of non-binary genders lightly and with open hands.}
}
@misc{icml,
	url          = {https://icml.cc/},
	author          = {International Conference on Machine Learning},
 year = {(n.d.)}
}
@misc{indigenousinai,
	url          = {https://indigenousinai.org/},
	key          = {Indigenous in AI},
        year         = {(n.d.)}, 
}
@inproceedings{jacobs2021measurement,
	title        = {Measurement and Fairness},
	author       = {Jacobs, Abigail Z. and Wallach, Hanna},
	year         = 2021,
	booktitle    = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
	location     = {Virtual Event, Canada},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {FAccT '21},
	pages        = {375–385},
	doi          = {10.1145/3442188.3445901},
	isbn         = 9781450383097,
	url          = {https://doi.org/10.1145/3442188.3445901},
	abstract     = {We propose measurement modeling from the quantitative social sciences as a framework for understanding fairness in computational systems. Computational systems often involve unobservable theoretical constructs, such as socioeconomic status, teacher effectiveness, and risk of recidivism. Such constructs cannot be measured directly and must instead be inferred from measurements of observable properties (and other unobservable theoretical constructs) thought to be related to them---i.e., operationalized via a measurement model. This process, which necessarily involves making assumptions, introduces the potential for mismatches between the theoretical understanding of the construct purported to be measured and its operationalization. We argue that many of the harms discussed in the literature on fairness in computational systems are direct results of such mismatches. We show how some of these harms could have been anticipated and, in some cases, mitigated if viewed through the lens of measurement modeling. To do this, we contribute fairness-oriented conceptualizations of construct reliability and construct validity that unite traditions from political science, education, and psychology and provide a set of tools for making explicit and testing assumptions about constructs and their operationalizations. We then turn to fairness itself, an essentially contested construct that has different theoretical understandings in different contexts. We argue that this contestedness underlies recent debates about fairness definitions: although these debates appear to be about different operationalizations, they are, in fact, debates about different theoretical understandings of fairness. We show how measurement modeling can provide a framework for getting to the core of these debates.},
	numpages     = 11,
	keywords     = {construct reliability, fairness, construct validity, measurement}
}
@article{kalluri2021don,
	title        = {Don’t ask if artificial intelligence is good or fair, ask how it shifts power},
	author       = {Kalluri, Pratyusha},
	year         = 2020,
	journal      = {Nature},
	volume       = 583,
	number       = 169
}
@article{katyal2021panopticon,
	title        = {The Gender Panopticon: Artificial Intelligence, Gender, and Design Justice},
	author       = {Katyal, Sonia and Jung, Jessica},
	year         = 2021,
	journal      = {UCLA Law Review},
	url          = {https://ssrn.com/abstract=3760098}
}
@article{keyes2018misgendering,
	title        = {The misgendering machines: Trans/HCI implications of automatic gender recognition},
	author       = {Keyes, Os},
	year         = 2018,
	journal      = {Proceedings of the ACM on human-computer interaction},
	publisher    = {ACM New York, NY, USA},
	volume       = 2,
	number       = {CSCW},
	pages        = {1--22},
	url          = {https://doi.org/10.1145/3274357}
}
@article{keyes2019counting,
	title        = {Counting the Countless: Why data science is a profound threat for queer people},
	author       = {Keyes, Os},
	year         = 2019,
	journal      = {Real Life},
	volume       = 2
}
@article{khari2022wrongful,
	title        = {How Wrongful Arrests Based on AI Derailed 3 Men's Lives},
	author       = {Johnson, Khari},
	year         = 2022,
	journal      = {Wired},
	url          = {https://www.wired.com/story/wrongful-arrests-ai-derailed-3-mens-lives/}
}
@book{khera2018aadhaar,
	title        = {Dissent On Aadhaar: Big Data Meets Big Brother},
	author       = {Khera, Reetika},
	year         = 2018,
	publisher    = {Orient Blackswan},
	url          = {https://sites.google.com/view/queer-in-ai/icml-2021#h.lx7wo16mt2ax}
}
@inproceedings{kong2022intersectional,
	title        = {Are “Intersectionally Fair” AI Algorithms Really Fair to Women of Color? A Philosophical Analysis},
	author       = {Kong, Youjin},
	year         = 2022,
	booktitle    = {2022 ACM Conference on Fairness, Accountability, and Transparency},
	location     = {Seoul, Republic of Korea},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {FAccT '22},
	pages        = {485–494},
	doi          = {10.1145/3531146.3533114},
	isbn         = 9781450393522,
	url          = {https://doi.org/10.1145/3531146.3533114},
	abstract     = {A growing number of studies on fairness in artificial intelligence (AI) use the notion of intersectionality to measure AI fairness. Most of these studies take intersectional fairness to be a matter of statistical parity among intersectional subgroups: an AI algorithm is “intersectionally fair” if the probability of the outcome is roughly the same across all subgroups defined by different combinations of the protected attributes. This paper identifies and examines three fundamental problems with this dominant interpretation of intersectional fairness in AI. First, the dominant approach is so preoccupied with the intersection of attributes/categories (e.g., race, gender) that it fails to address the intersection of oppression (e.g., racism, sexism), which is more central to intersectionality as a critical framework. Second, the dominant approach faces a dilemma between infinite regress and fairness gerrymandering: it either keeps splitting groups into smaller subgroups or arbitrarily selects protected groups. Lastly, the dominant view fails to capture what it really means for AI algorithms to be fair, in terms of both distributive and non-distributive fairness. I distinguish a strong sense of AI fairness from a weak sense that is prevalent in the literature, and conclude by envisioning paths towards strong intersectional fairness in AI.},
	numpages     = 10,
	keywords     = {Feminist and Critical Race Social Philosophy, Intersectionality, Fairness and Bias in AI, Philosophical Analysis of Fairness}
}
@book{kreps1994organizing,
	title        = {Organizing, role enactment, and disaster: A structural theory},
	author       = {Kreps, Gary A and Bosworth, Susan Lovegren},
	year         = 1994,
	publisher    = {University of Delaware Press}
}
@misc{latinxinai,
	url          = {https://www.latinxinai.org},
	key          = {LatinX in AI},
        year         = {(n.d.)}, 
}
@inbook{leavy2021curation,
	title        = {Ethical Data Curation for AI: An Approach Based on Feminist Epistemology and Critical Theories of Race},
	author       = {Leavy, Susan and Siapera, Eugenia and O'Sullivan, Barry},
	year         = 2021,
	booktitle    = {Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	pages        = {695–703},
	isbn         = 9781450384735,
	url          = {https://doi.org/10.1145/3461702.3462598},
	abstract     = {The potential for bias embedded in data to lead to the perpetuation of social injustice though Artificial Intelligence (AI) necessitates an urgent reform of data curation practices for AI systems, especially those based on machine learning. Without appropriate ethical and regulatory frameworks there is a risk that decades of advances in human rights and civil liberties may be undermined. This paper proposes an approach to data curation for AI, grounded in feminist epistemology and informed by critical theories of race and feminist principles. The objective of this approach is to support critical evaluation of the social dynamics of power embedded in data for AI systems. We propose a set of fundamental guiding principles for ethical data curation that address the social construction of knowledge, call for inclusion of subjugated and new forms of knowledge, support critical evaluation of theoretical concepts within data and recognise the reflexive nature of knowledge. In developing this ethical framework for data curation, we aim to contribute to a virtue ethics for AI and ensure protection of fundamental and human rights.},
	numpages     = 9
}
@article{lewis2020indigenous,
	title        = {Indigenous protocol and artificial intelligence position paper},
	author       = {Lewis, Jason Edward and Abdilla, Angie and Arista, Noelani and Baker, Kaipulaumakaniolono and Benesiinaabandan, Scott and Brown, Michelle and Cheung, Melanie and Coleman, Meredith and Cordes, Ashley and Davison, Joel and others},
	year         = 2020,
	publisher    = {Indigenous Protocol and Artificial Intelligence Working Group and the~…}
}
@article{lgbtq2013privacy,
	title        = {Social Media, Ethics, and Exposing Private Information About {LGBT} Users},
	author       = {Leone Kraus},
	year         = 2013,
	journal      = {LGBTQ Policy Journal}
}
@misc{lgbtqvrmuseum,
	title        = {LGBTQ+ VR MUSEUM},
	author       = {Antonia Forster and Thomas Terkildsen},
	url          = {https://lgbtqvrmuseum.com/}
}
@inproceedings{li2021on,
	title        = {On Dyadic Fairness: Exploring and Mitigating Bias in Graph Connections},
	author       = {Peizhao Li and Yifei Wang and Han Zhao and Pengyu Hong and Hongfu Liu},
	year         = 2021,
	booktitle    = {International Conference on Learning Representations},
	url          = {https://openreview.net/forum?id=xgGS6PmzNq6}
}
@article{long2021agr,
	title        = {Automatic Gender Recognition: Perspectives from Phenomenological Hermeneutics},
	author       = {Long, Yanan},
	year         = 2021,
	journal      = {Queer in AI Workshop at International Conference on Machine Learning 2021},
	booktitle    = {Queer in AI Workshop at International Conference on Machine Learning 2021},
	url          = {https://sites.google.com/view/queer-in-ai/icml-2021#h.lx7wo16mt2ax}
}
@article{maiter2008reciprocity,
	title        = {Reciprocity: An ethic for community-based participatory action research},
	author       = {Maiter, Sarah and Simich, Laura and Jacobson, Nora and Wise, Julie},
	year         = 2008,
	journal      = {Action research},
	publisher    = {Sage Publications Sage UK: London, England},
	volume       = 6,
	number       = 3,
	pages        = {305--325}
}
@misc{masakhane,
	url          = {https://www.masakhane.io},
	key          = {Masakhane},
        year         = {(n.d.)}, 
}
@article{mclean2020safe,
	title        = {Creating safe spaces: Digital as an enabling environment for TNB people},
	author       = {Nyx McLean},
	year         = 2020,
	journal      = {Social Work and Health Care Practice with Transgender and Nonbinary Individuals and Communities},
	publisher    = {Routledge},
	pages        = {331––342}
}
@misc{mcrsftcmt,
	title        = {Microsoft CMT},
	year = {(n.d.)},
	url          = {https://cmt3.research.microsoft.com},
	key          = {Microsoft CMT}
}
@article{mementorium2021,
	title        = {Mementorium: Learning about {LGBTQ+} marginalization in {STEM} fields using virtual reality},
	author       = {Paré, Dylan and Windsor, Scout and Craig, John},
	year         = 2021,
	journal      = {Queer in AI Workshop at Conference on Neural Information Processing Systems 2021},
	url          = {https://sites.google.com/view/queer-in-ai/neurips-2021#h.p8mb6qvi3v9m}
}
@article{Meyer2014ResistingHC,
	title        = {Resisting Hate Crime Discourse: Queer and Intersectional Challenges to Neoliberal Hate Crime Laws},
	author       = {Doug Meyer},
	year         = 2014,
	journal      = {Critical Criminology},
	volume       = 22,
	pages        = {113--125}
}
@article{mikesell2013ethical,
	title        = {Ethical community-engaged research: A literature review},
	author       = {Mikesell, Lisa and Bromley, Elizabeth and Khodyakov, Dmitry},
	year         = 2013,
	journal      = {American journal of public health},
	publisher    = {American Public Health Association},
	volume       = 103,
	number       = 12,
	pages        = {e7--e14}
}
@article{mittelstadt2019principles,
	title        = {Principles alone cannot guarantee ethical AI},
	year         = 2019,
	journal      = {Nature Machine Intelligence},
	volume       = 1,
	pages        = {501––507},
	url          = {https://doi.org/10.1038/s42256-019-0114-4},
	name         = {Mittelstadt, Brent}
}
@misc{naacl,
	url          = {https://naacl.org},
	author         = {North American Chapter of the Association for Computational Linguistics},
 year = {(n.d.)}
}
@misc{naacl2021,
	title        = {{NAACL Citation Name Change Procedure}},
	author       = {Pranav A and Ryan Cotterell},
	year         = 2021,
	url          = {https://2021.naacl.org/blog/name-change-procedure/}
}
@misc{naacl2021deiprogram,
	title        = {Social Programs––NAACL 2021},
	author       = {NAACL 2021 D\&I Committee},
	url          = {https://2021.naacl.org/program/social/}
}
@misc{neurips,
	url          = {https://neurips.cc/},
	author          = {Conference on Neural Information Processing Systems},
        year = {(n.d.)}
}
@misc{newclothes,
	title        = {Physiognomy’s New Clothes},
	author       = {Agüera y Arcas, Blaise and Mitchell, Margaret and Todorov, Alexander},
	year         = 2017,
	url          = {https://medium.com/@blaisea/physiognomys-new-clothes-f2d4b59fdd6a}
}
@misc{nike,
	url          = {https://sportai.splashthat.com/},
	author          = {Nike, Inc},
        year = {(n.d.)}
}
@inproceedings{NIPS2017_a486cd07,
	title        = {Counterfactual Fairness},
	author       = {Kusner, Matt J and Loftus, Joshua and Russell, Chris and Silva, Ricardo},
	year         = 2017,
	booktitle    = {Advances in Neural Information Processing Systems},
	publisher    = {Curran Associates, Inc.},
	volume       = 30,
	pages        = {},
	url          = {https://proceedings.neurips.cc/paper/2017/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf},
	editor       = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett}
}
@misc{nistrfi,
	title        = {{NIST} Requests Information to Help Develop an {AI} Risk Management Framework},
	author       = {{NIST}},
	url          = {https://www.nist.gov/news-events/news/2021/07/nist-requests-information-help-develop-ai-risk-management-framework},
 year = {(n.d.)}
}
@article{noaccess,
	title        = {No Access: {LGBTIQ} Website Censorship in Six Countries},
	author       = {Dalek, Jakub and Dumlao, Nica and Kenyon, Miles and Poetranto, Irene and Senft, Adam and Wesley, Caroline and Filastò, Arturo and Xynou, Maria and Bishop, Amie},
	year         = 2021,
	url          = {https://citizenlab.ca/2021/08/no-access-lgbtiq-website-censorship-in-six-countries/}
}
@misc{nsf,
	url          = {https://www.nsf.gov/},
	author          = {National Science Foundation},
 year = {(n.d.)}
}
@book{nygaard1987computers,
	title        = {Computers and democracy: A Scandinavian challenge},
	author       = {Nygaard, Kristen},
	year         = 1987,
	publisher    = {Aldershot [Hants, England]; Brookfield [Vt.], USA: Avebury}
}
@article{olympiansouted,
	title        = {{TikTokers} Are Using {Grindr} to Out {LGBTQ+} Olympians, Potentially Endangering Their Lives},
	author       = {Haug, Oliver},
	year         = 2021,
	journal      = {Them},
	url          = {https://www.them.us/story/tiktokers-use-grindr-out-lgbtq-olympians/}
}
@misc{onscensus,
	title        = {National identity, ethnic group, language and religion question development for Census 2021},
	author       = {Office for National Statistics},
	year         = 2021,
	url          = {https://www.ons.gov.uk/census/censustransformationprogramme/questiondevelopment/nationalidentityethnicgrouplanguageandreligionquestiondevelopmentforcensus2021}
}
@misc{orcid,
	title        = {Open Researcher and Contributor ID (ORCID)},
	year         = {(n.d.)},
	url          = {https://orcid.org/},
	key          = {ORCID}
}
@misc{ostem,
	url          = {https://ostem.org/},
	key          = {Out in Science, Technology, Engineering, and Mathematics (oSTEM)},
        year         = {(n.d.)}
}
@misc{PARDefin38:online,
	title        = {PAR Definitions.indd},
	author       = {},
	year         = {(n.d.)},
	month        = {},
	note         = {(Accessed Feb 2023)},
	howpublished = {\url{https://nature.berkeley.edu/community_forestry/Fellowships/parinfo/PAR\%20Definitions.pdf}}
}
@article{paris2019audio,
	title        = {Deepfakes \& Cheap Fakes: The Manipulation of Audio and Visual Evidence},
	author       = {Paris, Britt and Donovan, Joan},
	year         = 2019,
	journal      = {Data \& Society Research Institute}
}
@article{paris2021fakes,
	title        = {Configuring Fakes: Digitized Bodies, the Politics of Evidence, and Agency},
	author       = {Britt Paris},
	year         = 2021,
	journal      = {Social Media + Society},
	volume       = 7,
	number       = 4,
	pages        = 20563051211062919,
	doi          = {10.1177/20563051211062919},
	url          = {https://doi.org/10.1177/20563051211062919},
	eprint       = {https://doi.org/10.1177/20563051211062919},
	abstract     = {This comparative case study analysis used more than 200 examples of audiovisual manipulation collected from 2016 to 2021 to understand manipulated audiovisual and visual content produced by artificial intelligence, machine learning, and unsophisticated methods. This article includes a chart that categorizes the methods used to produce and disseminate audiovisual content featuring false personation as well as the harms that result. The article and the findings therein answer questions surrounding the broad issues of politics of evidence and harm related to audiovisual manipulation, harassment, privacy, and silencing to offer suggestions towards reconfiguring the public’s agency over technical systems and envisioning ways forward that meaningfully promote justice.}
}
@article{PAULLADA2021100336,
	title        = {Data and its (dis)contents: A survey of dataset development and use in machine learning research},
	author       = {Amandalynne Paullada and Inioluwa Deborah Raji and Emily M. Bender and Emily Denton and Alex Hanna},
	year         = 2021,
	journal      = {Patterns},
	volume       = 2,
	number       = 11,
	pages        = 100336,
	doi          = {https://doi.org/10.1016/j.patter.2021.100336},
	issn         = {2666-3899},
	url          = {https://www.sciencedirect.com/science/article/pii/S2666389921001847},
	keywords     = {datasets machine learning},
	abstract     = {Summary In this work, we survey a breadth of literature that has revealed the limitations of predominant practices for dataset collection and use in the field of machine learning. We cover studies that critically review the design and development of datasets with a focus on negative societal impacts and poor outcomes for system performance. We also cover approaches to filtering and augmenting data and modeling techniques aimed at mitigating the impact of bias in datasets. Finally, we discuss works that have studied data practices, cultures, and disciplinary norms and discuss implications for the legal, ethical, and functional challenges the field continues to face. Based on these findings, we advocate for the use of both qualitative and quantitative approaches to more carefully document and analyze datasets during the creation and usage phases.}
}
@article{pdcacm,
	title        = {Participatory Design},
	author       = {Muller, Michael J. and Kuhn, Sarah},
	year         = 1993,
	month        = {jun},
	journal      = {Commun. ACM},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	volume       = 36,
	number       = 6,
	pages        = {24–28},
	doi          = {10.1145/153571.255960},
	issn         = {0001-0782},
	url          = {https://doi.org/10.1145/153571.255960},
	issue_date   = {June 1993},
	numpages     = 5
}
@phdthesis{pereira2018using,
	title        = {Using supervised machine learning and sentiment analysis techniques to predict homophobia in portuguese tweets},
	author       = {Pereira, Vinicius Gomes},
	year         = 2018
}
@article{peters2020responsible,
	title        = {Responsible AI—two frameworks for ethical design practice},
	author       = {Peters, Dorian and Vold, Karina and Robinson, Diana and Calvo, Rafael A},
	year         = 2020,
	journal      = {IEEE Transactions on Technology and Society},
	publisher    = {IEEE},
	volume       = 1,
	number       = 1,
	pages        = {34--47}
}
@article{peterson2014social,
	title        = {The Effect of Social Media on Public Awareness and Extra-Judicial Effects: The Gay Marriage Cases and Litigating for New Rights},
	author       = {Peterson, Sarahfina Aubrey},
	year         = 2014,
	institution  = {Portland State University}
}
@article{pinter2021entering,
	title        = {Entering Doors, Evading Traps: Benefits and Risks of Visibility During Transgender Coming Outs},
	author       = {Pinter, Anthony T and Scheuerman, Morgan Klaus and Brubaker, Jed R},
	year         = 2021,
	journal      = {Proceedings of the ACM on Human-Computer Interaction},
	booktitle    = {Proceedings of the ACM on Human-Computer Interaction},
	publisher    = {ACM New York, NY, USA},
	volume       = 4,
	number       = {CSCW3},
	pages        = {1--27}
}
@article{powell2020digital,
	title        = {Digital harassment and abuse: Experiences of sexuality and gender minority adults},
	author       = {Powell, Anastasia and Scott, Adrian J and Henry, Nicola},
	year         = 2020,
	journal      = {European journal of criminology},
	publisher    = {SAGE Publications Sage UK: London, England},
	volume       = 17,
	number       = 2,
	pages        = {199--223}
}
@article{priestouted,
	title        = {A Prominent Priest Was Outed for Using Grindr. Experts Say It’s a Warning Sign.},
	author       = {Olmstead, Molly},
	year         = 2021,
	journal      = {Slate},
	url          = {https://slate.com/technology/2021/07/catholic-priest-grindr-data-privacy.html}
}
@misc{qaiicml2021,
	year         = 2021,
	url          = {http://queerinai.org/icml-2021},
	key          = {Queer in AI at ICML 2021}
}
@misc{qaineurips2021,
	year         = 2021,
	url          = {http://queerinai.org/neurips-2021},
	key          = {Queer in AI at NeurIPS}
}
@misc{qinaisponsorship,
	title        = {An Open Letter to {G}oogle},
	author       = {{Black in AI} and {Queer in AI} and {Widening NLP}},
	url          = {queerinai.org/google-sponsorship-statement},
        year         = {2021}
}
@misc{qinaisurvey,
	title        = {Queer in {AI} Demographic Survey},
	url          = {https://docs.google.com/forms/d/e/1FAIpQLSes-lzwkKHruQrAmH3Tnz1tJsTUl-YP51V8wDtHbfb8Z9FoNg/viewform}
}
@misc{qinaiyoutube,
	url          = {https://www.youtube.com/channel/UCXyVUke1cCnYNBwLsxCxQxg/videos},
	key          = {Queer in AI YouTube Channel},
 year = {(n.d.)},
 title = {Queer in AI YouTube Channel}
}
@inproceedings{queer-in-ai-dni-guide,
	title        = {How to Make Virtual Conferences Queer-Friendly: A Guide},
	author       = {QueerInAI, Organizers of and Pranav, A and Bleile, MaryLena and Subramonian, Arjun and Soldaini, Luca and Sutherland, Danica J. and Weber, Sabine and Xu, Pan},
	year         = 2021,
	month        = nov,
	booktitle    = {Proceedings of the 2021 Workshop on Widening NLP},
	publisher    = {Conference on Empirical Methods in Natural Language Processing},
	address      = {Punta Cana, Dominican Republic},
	url          = {queerinai.org/diversity-guide}
}
@inproceedings{Quraishi2015ResearchingRA,
	title        = {Researching Racism: A Guide Book for Academics \& Professional Investigators},
	author       = {Muzammil Quraishi and Rob Philburn},
	year         = 2015,
	publisher    = {Sage}
}
@article{qureshi2021evolution,
	title        = {The Evolution of Right to Privacy in India: A Look at the Past, Present \& Future},
	author       = {Qureshi, Mehab and Rizvi, Kazim},
	year         = 2021,
	journal      = {the quint},
	url          = {https://www.thequint.com/tech-and-auto/the-evolution-of-right-to-privacy-a-look-at-the-past-present-and-the-future}
}
@article{ravuri2021skilful,
	title        = {Skilful precipitation nowcasting using deep generative models of radar},
	author       = {Ravuri, Suman and Lenc, Karel and Willson, Matthew and Kangin, Dmitry and Lam, Remi and Mirowski, Piotr and Fitzsimons, Megan and Athanassiadou, Maria and Kashem, Sheleem and Madge, Sam and others},
	year         = 2021,
	journal      = {Nature},
	publisher    = {Nature Publishing Group},
	volume       = 597,
	number       = 7878,
	pages        = {672--677}
}
@article{razzano2021biometric,
	title        = {Digital and Biometric Identity Systems (AI4D)},
	author       = {Razzano, Gabriella},
	journal      = {Research ICT Africa},
	url          = {https://researchictafrica.net/publication/policy-paper-ai4d-digital-and-biometric-identity-systems/}
}
@article{redden2020dataharm,
	title        = {Data Harm Record (Updated)},
	author       = {Joanna Redden and Jessica Brand and Vanesa Terzieva},
	year         = 2020,
	url          = {https://datajusticelab.org/data-harm-record/}
}
@misc{reid2021speaker,
	title        = {How To Make Conference Speaker Fees More Inclusive And Equitable},
	author       = {Eva Reid},
	year         = 2021,
	month        = {July},
	url          = {https://technical.ly/2021/07/22/conferences-pay-speakers/},
	howpublished = {\url{hhttps://technical.ly/2021/07/22/conferences-pay-speakers//}}
}
@misc{russell2008acquire,
	title        = {ACQUIRE Project Working Paper},
	author       = {Russell, Nancy and Igras, Susan and Johri, Nalin and Kuoh, Henrietta and Pavin, Melinda and Wickstrom, Jane},
	year         = 2008,
	publisher    = {ACQUIRE/USAID},
	url          = {https://pdf.usaid.gov/pdf_docs/Pnadm497.pdf}
}
@article{salty,
	title        = {Censorship of Marginalized Communities on Instagram},
	author       = {Smith, Shakira and Haimson, Oliver L and Fitzsimmons, Claire and Brown, Nikki Echarte},
	year         = 2021,
	journal      = {Salty},
	url          = {https://saltyworld.net/exclusive-report-censorship-of-marginalized-communities-on-instagram-2021-pdf-download/}
}
@article{samuel2021inclusiveweb,
	title        = {Towards Understanding and Building a Multilingual and Inclusive Web},
	author       = {Samuel, John},
	year         = 2021,
	journal      = {Queer in AI Workshop at International Conference on Machine Learning 2021},
	url          = {https://sites.google.com/view/queer-in-ai/icml-2021#h.lx7wo16mt2ax}
}
@article{sanders2008co,
	title        = {Co-creation and the new landscapes of design},
	author       = {Sanders, Elizabeth B-N and Stappers, Pieter Jan},
	year         = 2008,
	journal      = {Co-design},
	publisher    = {Taylor \& Francis},
	volume       = 4,
	number       = 1,
	pages        = {5--18}
}
@article{scheuerman2019computers,
	title        = {How computers see gender: An evaluation of gender classification in commercial facial analysis services},
	author       = {Scheuerman, Morgan Klaus and Paul, Jacob M and Brubaker, Jed R},
	year         = 2019,
	journal      = {Proceedings of the ACM on Human-Computer Interaction},
	publisher    = {ACM New York, NY, USA},
	volume       = 3,
	number       = {CSCW},
	pages        = {1--33}
}
@article{scheuerman2021auto,
	title        = {Auto-essentialization: Gender in automated facial analysis as extended colonial project},
	author       = {Scheuerman, Morgan Klaus and Pape, Madeleine and Hanna, Alex},
	year         = 2021,
	journal      = {Big Data \& Society},
	publisher    = {SAGE Publications Sage UK: London, England},
	volume       = 8,
	number       = 2,
	pages        = 20539517211053712
}
@inproceedings{scheuerman2021revisiting,
	title        = {Revisiting Gendered Web Forms: An Evaluation of Gender Inputs with (Non-) Binary People},
	author       = {Scheuerman, Morgan Klaus and Jiang, Aaron and Spiel, Katta and Brubaker, Jed R},
	year         = 2021,
	booktitle    = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
	pages        = {1--18}
}
@article{schiff2020principles,
	title        = {Principles to practices for responsible {AI}: Closing the gap},
	author       = {Schiff, Daniel and Rakova, Bogdana and Ayesh, Aladdin and Fanti, Anat and Lennon, Michael},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2006.04707}
}
@article{scholarfailed,
	title        = {Google {S}cholar has failed us.},
	author       = {Speer, Robyn},
	year         = 2021,
	url          = {https://scholar.hasfailed.us/}
}
@book{schulman2021let,
	title        = {Let the Record Show: A Political History of ACT UP New York, 1987-1993},
	author       = {Schulman, Sarah},
	year         = 2021,
	publisher    = {Farrar, Straus and Giroux}
}
@article{seamster2017predatory,
	title        = {Predatory Inclusion and Education Debt: Rethinking the Racial Wealth Gap},
	author       = {Louise Seamster and Raphaël Charron-Chénier},
	year         = 2017,
	journal      = {Social Currents},
	volume       = 4,
	number       = 3,
	pages        = {199--207},
	doi          = {10.1177/2329496516686620},
	url          = {https://doi.org/10.1177/2329496516686620},
	eprint       = {https://doi.org/10.1177/2329496516686620},
	abstract     = {Analyses of the recent surge in racial wealth inequality have tended to focus on changes in asset holdings. Debt patterns, by contrast, have remained relatively unexplored. Using 2001 to 2013 data from the Survey of Consumer Finances, we show that after peaking in 2007, racial inequalities for most debt types returned to prefinancial crisis levels. The exception has been educational debt—on which we focus in this article. Our analyses show that educational debt has increased substantially for blacks relative to whites in the past decade. Notably, this unequal growth is not attributable to differences in educational attainment across racial groups. Rather, and as we argue, this trend reflects a process of predatory inclusion—a process wherein lenders and financial actors offer needed services to black households but on exploitative terms that limit or eliminate their long-term benefits. Predatory inclusion, we propose, is one of the mechanisms behind the persistence of racial inequality in contemporary markets.}
}
@misc{semanticscholar,
	url          = {https://semanticscholar.org/},
        year = {(n.d.)},
        title = {Semantic Scholar},
	key          = {Semantic Scholar}
}
@inproceedings{seymore1999learning,
	title        = {Learning hidden Markov model structure for information extraction},
	author       = {Seymore, Kristie and McCallum, Andrew and Rosenfeld, Roni and others},
	year         = 1999,
	booktitle    = {AAAI-99 workshop on machine learning for information extraction},
	pages        = {37--42}
}
@inproceedings{sloan2020participation,
	title        = {Participation is not a design fix for machine learning (pp. 1--7)},
	author       = {Sloan, Mona and Moss, Emanuel and Awomolo, Olaitan and Forlano, Laura},
	year         = 2020,
	booktitle    = {Proceedings of the International Conference on Machine Learning, Vienna, Austria}
}
@inproceedings{sloane22participation,
	title        = {Participation Is Not a Design Fix for Machine Learning},
	author       = {Sloane, Mona and Moss, Emanuel and Awomolo, Olaitan and Forlano, Laura},
	year         = 2022,
	booktitle    = {Equity and Access in Algorithms, Mechanisms, and Optimization},
	location     = {Arlington, VA, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {EAAMO '22},
	doi          = {10.1145/3551624.3555285},
	isbn         = 9781450394772,
	url          = {https://doi.org/10.1145/3551624.3555285},
	abstract     = {This paper critiques popular modes of participation in design practice and machine learning. It examines three existing kinds of participation in design practice and machine learning participation as work, participation as consultation, and as participation as justice – to argue that the machine learning community must become attuned to possibly exploitative and extractive forms of community involvement and shift away from the prerogatives of context independent scalability. Cautioning against “participation washing”, it argues that the notion of “participation” should be expanded to acknowledge more subtle, and possibly exploitative, forms of community involvement in participatory machine learning design. Specifically, it suggests that it is imperative to recognize design participation as work; to ensure that participation as consultation is context-specific; and that participation as justice must be genuine and long term. The paper argues that such a development can only be scaffolded by a new epistemology around design harms, including, but not limited to, in machine learning. To facilitate such a development, the paper suggests developing we argue that developing a cross-sectoral database of design participation failures that is cross-referenced with socio-structural dimensions and highlights “edge cases” that can and must be learned from.},
	articleno    = 1,
	numpages     = 6,
	keywords     = {machine learning, participatory methods, design}
}
@article{Smith427,
	title        = {Treatments of homosexuality in {B}ritain since the 1950s{\textemdash}an oral history: the experience of patients},
	author       = {Smith, Glenn and Bartlett, Annie and King, Michael},
	year         = 2004,
	journal      = {BMJ},
	volume       = 328,
	number       = 7437,
	pages        = 427,
	doi          = {10.1136/bmj.328.427.37984.442419.EE},
	issn         = {0959-8138}
}
@incollection{spade2015admin,
	title        = {{Administrating Gender}},
	author       = {Dean Spade},
	year         = 2015,
	month        = {07},
	booktitle    = {{Normal Life: Administrative Violence, Critical Trans Politics, and the Limits of Law}},
	publisher    = {Duke University Press},
	doi          = {10.1215/9780822374794-005},
	isbn         = {978-0-8223-5989-0},
	url          = {https://doi.org/10.1215/9780822374794-005},
	abstract     = {{This  chapter shows how by applying a more complex and accurate understanding of power, our attention is turned from winning legal recognition through civil rights reforms to understanding how the gender binary is enforced in administrative systems. The chapter focuses on three key administrative barriers to trans survival: access to ID, placement in sex-segregated facilities such as shelters and prisons, and access to health care. In each of these realms, binary gender categorization is rigidly enforced on everyone and endangers those whose lives and identities defy the rules and norms of that binary. The chapter argues that this administrative violence is the most widespread harm facing trans people, but is not addressed by a civil rights strategy. This generates a different way to think about the relationship between law reform and social movement demands for relief from conditions of subjection.}}
}
@book{spade2020mutual,
	title        = {Mutual aid: Building solidarity during this crisis (and the next)},
	author       = {Spade, Dean},
	year         = 2020,
	publisher    = {Verso Books}
}
@inproceedings{starbird2011voluntweeters,
	title        = {"Voluntweeters" self-organizing by digital volunteers in times of crisis},
	author       = {Starbird, Kate and Palen, Leysia},
	year         = 2011,
	booktitle    = {Proceedings of the SIGCHI conference on human factors in computing systems},
	pages        = {1071--1080}
}
@article{stark2021physiognomic,
	title        = {Physiognomic Artificial Intelligence},
	author       = {Stark, Luke and Hutson, Jevan},
	year         = 2021,
	journal      = {Available at SSRN 3927300},
	volume       = 32,
	number       = 4,
	pages        = 922
}
@article{studentloan,
	title        = {Survey: 60\% of {LGBTQ} Student Borrowers Regret Taking Out Student Loans},
	author       = {Marquit, Miranda},
	year         = 2018,
	url          = {https://www.lendingtree.com/student/lgbtq-student-borrowers-regret-loans-survey/}
}
@article{subramonian2020queer,
	title        = {Queer | Inclusive | Badass},
	author       = {Subramonian, Arjun},
	year         = 2020,
	journal      = {Resistance AI Workshop at Conference on Neural Information Processing Systems 2020},
	url          = {https://sites.google.com/view/resistance-ai-neurips-20/accepted-papers-and-media}
}
@inproceedings{subramonian2022ondyadicfairness,
	title        = {On Dyadic Fairness: Exploring and Mitigating Bias in Graph Connections},
	author       = {Arjun Subramonian},
	year         = 2022,
	booktitle    = {ICLR Blog Track},
	url          = {https://iclr-blog-track.github.io/2022/03/25/dyadic-fairness/},
	note         = {https://iclr-blog-track.github.io/2022/03/25/dyadic-fairness/}
}
@inproceedings{suresh22pml,
	title        = {Towards Intersectional Feminist and Participatory ML: A Case Study in Supporting Feminicide Counterdata Collection},
	author       = {Suresh, Harini and Movva, Rajiv and Dogan, Amelia Lee and Bhargava, Rahul and Cruxen, Isadora and Cuba, Angeles Martinez and Taurino, Guilia and So, Wonyoung and D'Ignazio, Catherine},
	year         = 2022,
	booktitle    = {2022 ACM Conference on Fairness, Accountability, and Transparency},
	location     = {Seoul, Republic of Korea},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {FAccT '22},
	pages        = {667–678},
	doi          = {10.1145/3531146.3533132},
	isbn         = 9781450393522,
	url          = {https://doi.org/10.1145/3531146.3533132},
	abstract     = {Data ethics and fairness have emerged as important areas of research in recent years. However, much work in this area focuses on retroactively auditing and “mitigating bias” in existing, potentially flawed systems, without interrogating the deeper structural inequalities underlying them. There are not yet examples of how to apply feminist and participatory methodologies from the start, to conceptualize and design machine learning-based tools that center and aim to challenge power inequalities. Our work targets this more prospective goal. Guided by the framework of data feminism, we co-design datasets and machine learning models to support the efforts of activists who collect and monitor data about feminicide&nbsp;—&nbsp;gender-based killings of women and girls. We describe how intersectional feminist goals and participatory processes shaped each stage of our approach, from problem conceptualization to data collection to model evaluation. We highlight several methodological contributions, including 1) an iterative data collection and annotation process that targets model weaknesses and interrogates framing concepts (such as who is included/excluded in “feminicide”), 2) models that explicitly focus on intersectional identities rather than statistical majorities, and 3) a multi-step evaluation process&nbsp;—&nbsp;with quantitative, qualitative and participatory steps&nbsp;—&nbsp;focused on context-specific relevance. We also distill insights and tensions that arise from bridging intersectional feminist goals with ML. These include reflections on how ML may challenge power, embrace pluralism, rethink binaries and consider context, as well as the inherent limitations of any technology-based solution to address durable structural inequalities.},
	numpages     = 12
}
@unpublished{sweeney2000privacy,
	title        = {Simple Demographics Often Identify People Uniquely},
	author       = {Sweeney, Latanya},
	year         = 2000,
	journal      = {Carnegie Mellon University, Data Privacy},
	url          = {http://dataprivacylab.org/projects/identifiability/},
	type         = {Working paper},
	institution  = {Carnegie Mellon University}
}
@article{tandon1988social,
	title        = {Social transformation and participatory research},
	author       = {Tandon, Rajesh},
	year         = 1988,
	journal      = {Convergence},
	publisher    = {International Council for Adult Education},
	volume       = 21,
	number       = 2,
	pages        = 5
}
@article{tanenbaum2020publishers,
	title        = {Publishers: let transgender scholars correct their names},
	author       = {Tanenbaum, Theresa Jean},
	year         = 2020,
	journal      = {Nature},
	publisher    = {Nature Publishing Group},
	volume       = 583,
	number       = 7817,
	pages        = {493--494}
}
@article{theilen2021protection,
	title        = {Feminist data protection: an introduction},
	author       = {Theilen, Jens T. and Baur, Andreas and Bieker, Felix and Quinn, Regina Ammicht and Hansen, Marit and Fuster, Gloria González},
	year         = 2021,
	journal      = {Internet Policy Review},
	url          = {https://policyreview.info/articles/analysis/feminist-data-protection-introduction}
}
@misc{TheTrevo41:online,
	title        = {The Trevor Project | For Young LGBTQ Lives},
	author       = {The Trevor Project},
	year = {(n.d.)},
	month        = {},
	url          = {https://www.thetrevorproject.org/},
	note         = {(Accessed Feb 2023)}
}
@article{tomasev2021fairness,
	title        = {Fairness for Unobserved Characteristics: Insights from Technological Impacts on Queer Communities},
	author       = {Tomasev, Nenad and McKee, Kevin R and Kay, Jackie and Mohamed, Shakir},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2102.04257},
	booktitle    = {Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society},
	publisher    = {Association for Computing Machinery},
	url          = {https://doi.org/10.1145/3461702.3462540}
}
@misc{tpl,
	url          = {https://www.crowdcast.io/e/tpl_aiequityinclusion},
	key          = {Toronto Public Library},
        year         = {2022}
}
@misc{trans-lifeline,
	url          = {https://translifeline.org},
	key          = {Trans Lifeline}
}
@misc{lgbt-colombia-2019,
    title = {STRESS, HEALTH, AND WELL-BEING OF LGBT PEOPLE IN COLOMBIA},
    author = {Choi, Soon Kyu and Divsalar, Shahrzad and Flórez-Donado, Jennifer and Kittle, Krystal and Lin, Andy and Meyer, Ilan H. and Torres-Salazar, Prince},
    year = {2019},
    month = {December},
    url = {https://www.ohchr.org/sites/default/files/Documents/Issues/SexualOrientation/IESOGI/Academics/1912_Colombia_Report_English_FINAL.pdf}
}
@misc{TransLif20:online,
	title        = {Trans Lifeline – Peer support services, hotline and resources for Transgender People},
	author       = {Trans Lifeline},
	year         = {2022},
	month        = {},
	note         = {(Accessed Feb 2023)},
	howpublished = {\url{https://translifeline.org/}}
}
@article{transpublishing,
	title        = {A vision for a more trans-inclusive publishing world: guest article},
	author       = {Jean Tanenbaum, Theresa and Rettig, Irving and Schwartz, H Michael and Watson, BM and G Goetz, Teddy and Spiel, Katta and Hill, Mike},
	year         = 2021,
	url          = {https://publicationethics.org/news/vision-more-trans-inclusive-publishing-world}
}
@article{treebridge2021dogwhistle,
	title        = {Crowdsourcing a Corpus of Dogwhistle Transphobia},
	author       = {Treebridge, Paige Yes},
	year         = 2021,
	journal      = {Queer in AI Workshop at International Conference on Machine Learning 2021},
	booktitle    = {Queer in AI Workshop at International Conference on Machine Learning 2021},
	url          = {https://sites.google.com/view/queer-in-ai/icml-2021#h.lx7wo16mt2ax}
}
@article{trevorproject,
	title        = {The Trevor Project Launches New AI Tool To Support Crisis Counselor Training},
	author       = {Josh Weaver},
	year         = 2021,
	url          = {https://www.thetrevorproject.org/blog/the-trevor-project-launches-new-ai-tool-to-support-crisis-counselor-training/}
}
@misc{trevorproject-org,
	title        = {The Trevor Project},
	year = {(n.d.)},
	url          = {https://www.thetrevorproject.org},
	key          = {The Trevor Project}
}
@misc{ncpwg,
	title        = {{N}ame {C}hange {P}olicy {W}orking {G}roup},
	year = {(n.d.)},
	url          = {https://ncpwg.org/},
	key          = {{N}ame {C}hange {P}olicy {W}orking {G}roup}
}
@BOOK{Malatino2020-bw,
  title     = "Trans Care",
  author    = "Malatino, Hil",
  publisher = "University of Minnesota Press",
  month     =  jul,
  year      =  2020,
  address   = "Minneapolis"
}
@article{mehrabi2021,
author = {Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
title = {A Survey on Bias and Fairness in Machine Learning},
year = {2021},
issue_date = {July 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3457607},
doi = {10.1145/3457607},
abstract = {With the widespread use of artificial intelligence (AI) systems and applications in our everyday lives, accounting for fairness has gained significant importance in designing and engineering of such systems. AI systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that these decisions do not reflect discriminatory behavior toward certain groups or populations. More recently some work has been developed in traditional machine learning and deep learning that address such challenges in different subdomains. With the commercialization of these systems, researchers are becoming more aware of the biases that these applications can contain and are attempting to address them. In this survey, we investigated different real-world applications that have shown biases in various ways, and we listed different sources of biases that can affect AI applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined to avoid the existing bias in AI systems. In addition to that, we examined different domains and subdomains in AI showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and ways they have tried to address them. There are still many future directions and solutions that can be taken to mitigate the problem of bias in AI systems. We are hoping that this survey will motivate researchers to tackle these issues in the near future by observing existing work in their respective fields.},
journal = {ACM Comput. Surv.},
month = {jul},
articleno = {115},
numpages = {35},
keywords = {deep learning, natural language processing, Fairness and bias in artificial intelligence, representation learning, machine learning}
}
@article{Keyes2021TruthFT,
  title={Truth from the machine: artificial intelligence and the materialization of identity},
  author={Os Keyes and Zo{\"e} Hitzig and Mwenza Blell},
  journal={Interdisciplinary Science Reviews},
  year={2021},
  volume={46},
  pages={158 - 175}
}
@inproceedings{blodgett-etal-2020-language,
    title = "Language (Technology) is Power: A Critical Survey of {``}Bias{''} in {NLP}",
    author = "Blodgett, Su Lin  and
      Barocas, Solon  and
      Daum{\'e} III, Hal  and
      Wallach, Hanna",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.485",
    doi = "10.18653/v1/2020.acl-main.485",
    pages = "5454--5476",
    abstract = "We survey 146 papers analyzing {``}bias{''} in NLP systems, finding that their motivations are often vague, inconsistent, and lacking in normative reasoning, despite the fact that analyzing {``}bias{''} is an inherently normative process. We further find that these papers{'} proposed quantitative techniques for measuring or mitigating {``}bias{''} are poorly matched to their motivations and do not engage with the relevant literature outside of NLP. Based on these findings, we describe the beginnings of a path forward by proposing three recommendations that should guide work analyzing {``}bias{''} in NLP systems. These recommendations rest on a greater recognition of the relationships between language and social hierarchies, encouraging researchers and practitioners to articulate their conceptualizations of {``}bias{''}---i.e., what kinds of system behaviors are harmful, in what ways, to whom, and why, as well as the normative reasoning underlying these statements{---}and to center work around the lived experiences of members of communities affected by NLP systems, while interrogating and reimagining the power relations between technologists and such communities.",
}
@article{triumphs2021art,
	title        = {Using {AI} tools for producing artwork that reflect {LGBTQ+} struggles \& triumphs},
	author       = {Anonymous},
	year         = 2021,
	journal      = {Queer in AI Workshop at International Conference on Machine Learning 2021},
	url          = {https://sites.google.com/view/queer-in-ai/icml-2021#h.lx7wo16mt2ax}
}
}
@article{vamathevan2019applications,
	title        = {Applications of machine learning in drug discovery and development},
	author       = {Vamathevan, Jessica and Clark, Dominic and Czodrowski, Paul and Dunham, Ian and Ferran, Edgardo and Lee, George and Li, Bin and Madabhushi, Anant and Shah, Parantu and Spitzer, Michaela and others},
	year         = 2019,
	journal      = {Nature Reviews Drug discovery},
	publisher    = {Nature Publishing Group},
	volume       = 18,
	number       = 6,
	pages        = {463--477}
}
@article{vanzyl2021contact,
	title        = {The Ethical Implications of Digital Contact Tracing For {LGBTQIA+} Communities},
	author       = {Van Zyl, Izak and McLean, Nyx},
	year         = 2021,
	journal      = {Proceedings of the 1st Virtual Conference on Implications of Information and Digital Technologies for Development}
}
@article{viswanathan2004community,
	title        = {Community-based participatory research: Assessing the evidence: Summary},
	author       = {Viswanathan, Meera and Ammerman, Alice and Eng, Eugenia and Garlehner, Gerald and Lohr, Kathleen N and Griffith, Derek and Rhodes, Scott and Samuel-Hodge, Carmen and Maty, Siobhan and Lux, Linda and others},
	year         = 2004,
	journal      = {AHRQ evidence report summaries},
	publisher    = {Agency for Healthcare Research and Quality (US)}
}
@article{weinberg2022rethinking,
	title        = {Rethinking Fairness: An Interdisciplinary Survey of Critiques of Hegemonic ML Fairness Approaches},
	author       = {Weinberg, Lindsay},
	year         = 2022,
	journal      = {Journal of Artificial Intelligence Research},
	volume       = 74,
	pages        = {75--109}
}
@misc{wilson2020homelessness,
	title        = {Homelessness among {LGBT} adults in the US},
	author       = {Wilson, Bianca DM and Choi, Soon Kyu and Harper, Gary W and Lightfoot, Marguerita and Russell, Stephen and Meyer, Ilan H},
	year         = 2020,
	url          = {https://williamsinstitute.law.ucla.edu/publications/lgbt-homelessness-us/}
}
@misc{wiml,
	url          = {https://wimlworkshop.org},
	key          = {Women in Machine Learning},
        year         = {(n.d.)}
}
@misc{winlp-org,
	url          = {http://www.winlp.org},
	key          = {Widening NLP},
        year         = {(n.d.)}, 
}
@article{wiredlbnoobw,
	title        = {{AI} and the List of Dirty, Naughty, Obscene, and Otherwise Bad Words},
	author       = {Simonite, Tom},
	year         = 2021,
	journal      = {Wired},
	url          = {https://www.wired.com/story/ai-list-dirty-naughty-obscene-bad-words/}
}
@article{zalnieriute2017governance,
	title        = {The Anatomy of Neoliberal Internet Governance: Queer Critical Political Economy Perspective},
	author       = {Zalnieriute, Monika},
	year         = 2017,
	journal      = {International Law: Possibilities, Alliances, Complicities and Risks},
	publisher    = {Routledge},
	pages        = {53--73},
	url          = {https://ssrn.com/abstract=2894136}
}
@article{Cech2017QueerIS,
  title={Queer in STEM Organizations: Workplace Disadvantages for LGBT Employees in STEM Related Federal Agencies},
  author={Erin A. Cech and Michelle Pham},
  journal={The Social Sciences},
  year={2017},
  volume={6},
  pages={12}
}
@article{jethwani2022,
author = {Jethwani, Hetvi and Subramonian, Arjun and Agnew, William and Bleile, MaryLena and Arora, Sarthak and Ryskina, Maria and Xiong, Jeffrey},
title = {Queer in AI},
year = {2022},
issue_date = {Summer 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {28},
number = {4},
issn = {1528-4972},
url = {https://doi.org/10.1145/3538543},
doi = {10.1145/3538543},
abstract = {Queer in AI is an organization that aims to combat the harms faced by queer researchers within AI. Several inclusion initiatives are outlined, including those centered on policy and financial aid.},
journal = {XRDS},
month = {jul},
pages = {18–21},
numpages = {4}
}
@article{Freeman2020MeasuringAR,
  title={Measuring and Resolving LGBTQ Disparities in STEM},
  author={Jonathan B. Freeman},
  journal={Policy Insights from the Behavioral and Brain Sciences},
  year={2020},
  volume={7},
  pages={141 - 148}
}
@misc{nsf-data-collection,
    title={NSF still won’t track sexual orientation among scientific workforce, prompting frustration},
    author={Katie Langin},
    journal={Science},
    year={2023},
    url={https://www.science.org/content/article/nsf-still-won-t-track-sexual-orientation-among-scientific-workforce-prompting}
}

@inproceedings{lu2022subverting,
  title={Subverting machines, fluctuating identities: Re-learning human categorization},
  author={Lu, Christina and Kay, Jackie and McKee, Kevin},
  booktitle={2022 ACM Conference on Fairness, Accountability, and Transparency},
  pages={1005--1015},
  year={2022}
}


@article{morgan-safe,
author = {Scheuerman, Morgan Klaus and Branham, Stacy M. and Hamidi, Foad},
title = {Safe Spaces and Safe Places: Unpacking Technology-Mediated Experiences of Safety and Harm with Transgender People},
year = {2018},
issue_date = {November 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {CSCW},
url = {https://doi.org/10.1145/3274424},
doi = {10.1145/3274424},
abstract = {Transgender individuals in the United States face significant threats to interpersonal safety; however, there has as yet been relatively little research in the HCI and CSCW communities to document transgender individuals' experiences of technology-mediated safety and harm. In this study, we interviewed 12 transgender and non-binary individuals to understand how they find, create, and navigate safe spaces using technology. Managing safety was a universal concern for our transgender participants, and they experienced complex manifestations of harm through technology. We found that harmful experiences for trans users could arise as targeted or incidental affronts, as sourced from outsiders or insiders, and as directed against individuals or entire communities.. Notably, some violations implicated technology design, while others tapped broader social dynamics. Reading our findings through the notions of 'space" and 'place," we unpack challenges and opportunities for building safer futures with transfolk, other vulnerable users, and their allies.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {155},
numpages = {27},
keywords = {transgender, safe space, gender identity, place, lgbtq, intersectionality., harm}
}

 @misc{jacobs_2019, title={Why Pronouns?}, url={https://naacl.org/naacl-hlt-2019/blog/why-pronouns/}, journal={NAACL 2019}, publisher={NAACL}, author={Jacobs, Cassandra L.}, year={2019}, month={Mar}, howpublished = "\url{https://naacl.org/naacl-hlt-2019/blog/why-pronouns/}"}
 
 @misc{winlp, title={{WiNLP} {BIG} Directory}, url={ http://www.winlp.org/big-directory/}, author={{Widening NLP organizers}}, year={2021}, publisher={Widening NLP}, howpublished = "\href{http://www.winlp.org/big-directory/}{Link}"}
 
@misc{data-collection, title={A guide to {LGBTIQ}-inclusive data collection}, url={https://meridianact.org.au/wp-content/uploads/LGBTIQ-Inclusive-Data-Collection-a-Guide.pdf}, author={Barclay, Alison and Russell, Melissa}, year={2017}, publisher={Canberra LGBTIQ Community Consortium}, howpublished = "\href{https://meridianact.org.au/wp-content/uploads/LGBTIQ-Inclusive-Data-Collection-a-Guide.pdf}{https://meridianact.org.au}"}


@misc{conrod-multi-pronouns, title={intermediate pronoun studies: multiple pronouns
}, url={https://web.archive.org/web/20220104205638/https://kconrod.medium.com/intermediate-pronoun-studies-multiple-pronouns-71e34cd28c54}, 
author={Kirby Conrod}, year={2021}, publisher={Medium Corporation}, 
howpublished = "\href{https://kconrod.medium.com/intermediate-pronoun-studies-multiple-pronouns-71e34cd28c54}"}

@misc{johnson_2019, title={Why you can't just take pictures at the {Q}ueer in {AI} workshop at {NeurIPS}}, url={https://venturebeat.com/2019/12/10/why-you-cant-just-take-pictures-at-the-queer-in-ai-workshop-at-neurips/}, howpublished={{VentureBeat, \href{https://venturebeat.com/2019/12/10/why-you-cant-just-take-pictures-at-the-queer-in-ai-workshop-at-neurips/}{Link}}}, publisher={VentureBeat}, author={Johnson, Khari}, year={2019}}
 
@Article{socsci6010012,
AUTHOR = {Cech, Erin A. and Pham, Michelle V.},
TITLE = {Queer in {STEM} Organizations: Workplace Disadvantages for {LGBT} Employees in {STEM} Related Federal Agencies},
JOURNAL = {Social Sciences},
VOLUME = {6},
YEAR = {2017},
NUMBER = {1},
ARTICLE-NUMBER = {12},
URL = {https://www.mdpi.com/2076-0760/6/1/12},
ISSN = {2076-0760},
DOI = {10.3390/socsci6010012}
}

@misc{ubicomp_2020, title={UBICOMP / ISWC 2020 Accessibility FAQ}, url={https://ubicomp.org/ubicomp2020/accessibility/faq/}, author={Jennifer Rode}, journal={UBICOMP / ISWC 2020}, publisher={UBICOMP}, year={2020}, howpublished = "\url{https://ubicomp.org/ubicomp2020/accessibility/faq/}"}

@misc{robyn_doc, title={Google {S}cholar deadnames trans authors and obstructs their name change}, url={https://docs.google.com/document/d/1st05rXL1wcBBdgcMVqgN0X3L-6HGqORGfgnHMfXHKvE}, author={Robyn Speer}, 
year={2021}, 
howpublished = "\href{https://docs.google.com/document/d/1st05rXL1wcBBdgcMVqgN0X3L-6HGqORGfgnHMfXHKvE}{Link}"}

@misc{camera_ready, title={Accessibility for Camera-Ready Papers}, url={https://acl2020.org/blog/accessibility-for-camera-ready/}, author={Sushant Kafle and Masoud Rouhizadeh, and Naomi Saphra}, journal={ACL 2020}, publisher={ACL}, year={2020}, howpublished={\url{https://acl2020.org/blog/accessibility-for-camera-ready/}}}

@misc{accessible_presentations, title={Accessible Presentations at ACL 2020}, url={https://acl2020.org/blog/Accessible-Presentations-at-ACL-2020/}, author={Naomi Saphra and Sushant Kafle and Masoud Rouhizadeh}, journal={ACL 2020}, publisher={ACL}, year={2020}, howpublished={\url{https://acl2020.org/blog/Accessible-Presentations-at-ACL-2020/}}}

@misc{rebiber,
title = {Rebiber},
author = {Yuchen Lin},
howpublished = {\href{https://github.com/yuchenlin/rebiber}{Repo Link}},
year = {2021}
}

@inproceedings{morgan_gender,
author = {Scheuerman, Morgan Klaus and Jiang, Aaron and Spiel, Katta and Brubaker, Jed R.},
title = {Revisiting Gendered Web Forms: An Evaluation of Gender Inputs with (Non-)Binary People},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445742},
doi = {10.1145/3411764.3445742},
abstract = { Gender input forms act as gates to accessing information, websites, and services online. Non-binary people regularly have to interact with them, though many do not offer non-binary gender options. This results in non-binary individuals having to either choose an incorrect gender category or refrain from using a site or service—which is occasionally infeasible (e.g., when accessing health services). We tested five different forms through a survey with binary and non-binary participants (n = 350) in three contexts—a digital health form, a social media website, and a dating app. Our results indicate that the majority of participants found binary “male or female” forms exclusive and uncomfortable to fill out across all contexts. We conclude with design considerations for improving gender input forms and consequently their underlying gender model in databases. Our work aims to sensitize designers of (online) gender web forms to the needs and desires of non-binary people.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {400},
numpages = {18},
keywords = {Gender, survey methodology, web forms, input fields, user interface design},
location = {Yokohama, Japan},
series = {CHI '21}
}

@misc{cope-vision,
author = {Theresa Jean Tanenbaum and Irving Rettig and H Michael Schwartz and BM Watson and Teddy G Goetz and Katta Spiel and Mike Hill},
title = {A vision for a more trans-inclusive publishing world: guest article},
howpublished = {Committee on Publication Ethics. \url{https://publicationethics.org/news/vision-more-trans-inclusive-publishing-world}},
year = {2021},
}

@article{morgan-safe,
author = {Scheuerman, Morgan Klaus and Branham, Stacy M. and Hamidi, Foad},
title = {Safe Spaces and Safe Places: Unpacking Technology-Mediated Experiences of Safety and Harm with Transgender People},
year = {2018},
issue_date = {November 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {CSCW},
url = {https://doi.org/10.1145/3274424},
doi = {10.1145/3274424},
abstract = {Transgender individuals in the United States face significant threats to interpersonal safety; however, there has as yet been relatively little research in the HCI and CSCW communities to document transgender individuals' experiences of technology-mediated safety and harm. In this study, we interviewed 12 transgender and non-binary individuals to understand how they find, create, and navigate safe spaces using technology. Managing safety was a universal concern for our transgender participants, and they experienced complex manifestations of harm through technology. We found that harmful experiences for trans users could arise as targeted or incidental affronts, as sourced from outsiders or insiders, and as directed against individuals or entire communities.. Notably, some violations implicated technology design, while others tapped broader social dynamics. Reading our findings through the notions of 'space" and 'place," we unpack challenges and opportunities for building safer futures with transfolk, other vulnerable users, and their allies.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {155},
numpages = {27},
keywords = {transgender, safe space, gender identity, place, lgbtq, intersectionality., harm}
}

@incollection{conrodpronouns,
  title={Pronouns and Gender in Language},
  author={Conrod, Kirby},
  booktitle={The Oxford Handbook of Language and Sexuality},
  editor = {Kira Hall and Rusty Barrett},
  publisher = {Oxford University Press},
  year = {2020}
}

@incollection{mclean2020creating,
  title={Creating safe spaces: Digital as an enabling environment for {TNB} people},
  author={McLean, Nyx},
  booktitle={Social Work and Health Care Practice with Transgender and Nonbinary Individuals and Communities},
  pages={331--342},
  year={2020},
  publisher={Routledge}
}

@inproceedings{schluter2018glass,
  title={{The glass ceiling in NLP}},
  author={Schluter, Natalie},
  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  pages={2793--2798},
  year={2018}
}
@misc{queerinai_code_of_conduct,
      author={{Queer in AI Organizers}},
      title  = "{Code of Conduct}",
      howpublished = "\url{https://sites.google.com/view/queer-in-ai/code-of-conduct}",
      year=2019
}
@misc{wiml_code_of_conduct,
      author={{Women in Machine Learning}},
      title  = "{Code of Conduct}",
      howpublished = "\url{https://wimlworkshop.org/conduct/}",
      year=2021
}

@misc{pronoun_guide,
      author={Slattery, Fen},
      title  = "An Organizer's Guide to Pronoun Buttons",
      url = {https://dev.to/sublimemarch/an-organizers-guide-to-pronoun-buttons-afb},
      year=2018
}

@misc{queerinai2020survey,
      author={{Queer in AI organizers}},
      title  = "{Queer in AI 2020 Demographic Survey}",
      howpublished = "\href{https://sites.google.com/view/queer-in-ai/home}{Queer in AI}",
      year=2020
}

@book{stanford2021artificial,
      author={Zhang, Daniel and Mishra, Saurabh and Brynjolfsson, Erik and Etchemendy, John and Ganguli, Deep and Grosz, Barbara and Lyons, Terah and Manyika, James and Niebles, Juan Carlos and Sellitto, Michael and others},
      title  = "{{Artificial Intelligence Index Report 2021}}",
      year = 2021,
      publisher={{Stanford HAI}},
      address={{Stanford, CA, USA}}
}


@misc{ashedryden2014,
      author={Ashe Dryden},
      title  = "{CODES OF CONDUCT 101 + FAQ}",
      howpublished = "\href{https://www.ashedryden.com/blog/codes-of-conduct-101-faq}{Link}",
      year=2013
}


@misc{ashedryden2013,
      author={Ashe Dryden},
      title  = "{Increasing Diversity at Your Conference}",
      howpublished = "\href{https://www.ashedryden.com/blog/increasing-diversity-at-your-conference}{Link}",
      year=2013
}


@misc{ffffff,
      author={Erica Joy},
      title  = "{\#FFFFFF Diversity}",
      howpublished = "{\href{https://web.archive.org/web/20181225205655/https://medium.com/this-is-hard/ffffff-diversity-1bd2b3421e8a}{Medium Link}}",
      year=2015
}

@article{tulloch2020improving,
  title={Improving sex and gender identity equity and inclusion at conservation and ecology conferences},
  author={Tulloch, Ayesha IT},
  journal={Nature Ecology \& Evolution},
  volume={4},
  number={10},
  pages={1311--1320},
  year={2020},
  publisher={Nature Publishing Group}
}

@misc{trans-inclusive-design,
    author = {Erin White},
    title = {Trans-inclusive Design},
    year = {2019},
    howpublished = {\url{https://alistapart.com/article/trans-inclusive-design/}}
}
@article{khari2021drop,
	title        = {Black and Queer AI Groups Say They'll Spurn Google Funding},
	author       = {Johnson, Khari},
	year         = 2021,
	journal      = {Wired},
	url          = {https://www.wired.com/story/black-queer-ai-groups-spurn-google-funding/}
}

@misc{freeman2023,
      author={Freeman, Jon},
      title  = {Letter to the NSF Director},
      url = {https://static1.squarespace.com/static/545d3fabe4b0811b5cc48193/t/63c867aefb89f3761070a5a3/1674078140137/Letter+to+NSF+Director+-+LGBTQ\%2B+Data_redacted.pdf},
      year=2023
}

@article{time-chatgpt,
title = {OpenAI Used Kenyan Workers on Less Than \$2 Per Hour to Make ChatGPT Less Toxic},
author = {Billy Perrigo},
year = {2023},
journal = {Time},
url={https://time.com/6247678/openai-chatgpt-kenya-workers/},
}

@misc{blackinai-ac-program,
title = {Academic Program},
year = {2020},
author = {{Black in AI}},
url = {https://blackinai.github.io/#/programs/academic-program},
}

@misc{ellis-call,
title = {{ELLIS PhD} Program: Call for applications 2022},
author = {ELLIS},
year = {2022},
url = {https://ellis.eu/news/ellis-phd-program-call-for-applications-2022},
}

@article{kormilitzin2023participatory,
  title={A participatory initiative to include LGBT+ voices in AI for mental health},
  author={Kormilitzin, Andrey and Tomasev, Nenad and McKee, Kevin R and Joyce, Dan W},
  journal={Nature Medicine},
  pages={1--2},
  year={2023},
  publisher={Nature Publishing Group US New York}
}

@article{microsoft-palestine,
title = {{Why did Microsoft fund an Israeli firm that surveils West Bank Palestinians?}},
author = {Olivia Solon},
journal = {NBC News},
year = {2019},
url = {https://www.nbcnews.com/news/all/why-did-microsoft-fund-israeli-firm-surveils-west-bank-palestinians-n1072116},
}

@inproceedings{finn2022developing,
  title={Developing a Part-Of-Speech tagger for te reo M{\=a}ori},
  author={Finn, Aoife and Jones, Peter-Lucas and Mahelona, Keoni and Duncan, Suzanne and Leoni, Gianna},
  booktitle={Proceedings of the Fifth Workshop on the Use of Computational Methods in the Study of Endangered Languages},
  pages={93--98},
  year={2022}
}
