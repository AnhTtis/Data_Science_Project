% !TEX root = ../main.tex
\section{Findings and Discussion}
\label{sec:conclusions}

%% Restate what we did, primary findings
%% What is the future work in this area?
While it may be unsurprising that the network used to derive content distance also performed the best at it, MUNIT also performed reasonably well on the other measures and visual inspection found it displayed a good variety of palette and structural differences. This would argue for approaches that make a distinction between content and style that can be used to implement our criteria.


\begin{figure}[h]
\begin{center}
\includegraphics[width=1\columnwidth]{figures/sparsity1.pdf}
\end{center}
\caption{The effect of sparsity on image-to-image generative methods.  A sparse conceptual sketch (left) results in poor results using highly trained models such as MUNIT (right).}
\label{fig:sparsity}
\end{figure}

A cursory inspection of validation results overall appeared to give impressive results.  However, the actual performance on conceptual sketches was considerably poorer.
This first issue stems from the comparative sparsity of conceptual sketches.  Most image-to-image frameworks, particularly those that explicitly model and style and content differentiation \cite{cyclegan_ref, munit_ref}, tend to have relatively complex source and target images.  In the case of conceptual sketches, these are informationally impoverished, often resulting in poorer renders.  Figure \ref{fig:sparsity} gives an example of a conceptual sketch (left) being rendered by the MUNIT model (right).

\begin{figure}[]
\begin{center}
\includegraphics[width=\columnwidth]{figures/ID_vs_OOD_munit.pdf}
\end{center}
\caption{Distributional differences between automatically inferred sketches versus hand-drawn sketches.  Renders created by the MUNIT model (top-right) with input from an automatically generated edge map designed to resemble a hand-drawn sketch (top-left) are high quality.  In contrast, when the same model is given a hand-drawn conceptual sketch, the results are less desirable (bottom row). }
\label{fig:idvsood}
\end{figure}

Another major issue lies with distributional mismatches between automatically generated sketch inputs and actual hand-drawn conceptual sketches.  Figure \ref{fig:idvsood} provides an illustrative example using the MUNIT model trained to convert automatically detected edges into a variety of realistic renders.  The top row shows an input sketch and candidate renders generated by the model.  The bottom shows an actual hand-drawn conceptual sketch and corresponding renders using the same model.  While the automatically derived sketch may appear hand-drawn, there are significant enough differences between them that the overall quality of the hand-drawn renders is lower.

%% 

Finally, there is a lack of examples from the conceptual sketch domain.  While automatically generated sketches are available, we have found them to be different enough that models trained on them consider hand sketches to be out of distribution inputs.

Future work will need to address this distributional gap between conceptual sketches and automatically generated ones.  The simplest and most correct solution would be to elicit a larger corpus of conceptual sketches, but this would also be the most 
% expensive 
% or costly one. 
expensive given the cost.  
Possible avenues of investigation include the use of image-to-image translation methods for domain adaptation to map between conceptual sketches and artificially generated sketches \cite{img2img_domain_adaptation_ref}.
In addition to the above, we intend to develop human studies to identify correlation between human judgements of intent preservation, realism, and structural variety with our proposed automated measures.
% 