
% Our approach to multi-robot shared autonomy is based on scheduling the two robot executions. The simplest scheduling solution would be to optimize the start times of the robot executions such that the times requiring corrections in the executions are non-overlapping. For example, as shown in Figure \ref{fig:teaser}, two sanding robots could sequence their behaviors such that one robot is doing a variable sanding pass while the other moves between passes. However, this would require that the profile of times needing corrections is convenient for scheduling (e.g., alternating equal length low-confidence and high-confidence sections), which is unlikely in practice. Our key idea is to leverage the flexibility in task timing from the demonstrations to both aid in finding a scheduling solution and to help the robots adapt in real-time when the operator corrections affect the timing of the robots.

% \subsubsection{Overview of Method}

% In the following subsections we build toward the multi-robot scheduling optimization by describing (1) how demonstrations can determine the robot behavior and expose temporal flexibility, (2) how we can extract corrections the operator can make from the demonstration variability, (3) how we can estimate the likelihood of operator corrections from demonstration variability and shared autonomy rollouts, (4) how we can schedule the multiple robot executions around low-confidence times, and (5) how we can assure that our solution is robust to any timing changes from the operator corrections.

% Define demonstrations, etc.


% \begin{tcolorbox}
%     imo the method is cluttered by text that makes it hard to figure out what is important. The problem statement above should formalize the key aspects of the problem. Fill in with what you need for demonstrations / corrections / objective, right now they are a bit vague. Then once you have the problem, start proposed approach here. When reading I was often confused what was part of the problem statement and what was part of your solution.
% \end{tcolorbox}

% Following previous work in Shared Autonomy \cite{hagenow2021informing}, we show how the variability between expert demonstrations of the task can be used as an indicator of what corrections may be necessary. Furthermore, the demonstrations also can be used to identify flexibility in the task execution rate that can be used to aid the multi-agent scheduling. We also show how the task segments where corrections may be needed can be estimated using the demonstration variability and Bayesian inference on past data of the corrections an operator provides. Scheduling coordinated Shared Autonomy among multiple robots also exposes new challenges that are investigated in this work. When an operator provides corrections, it can impact the timing of the robots (e.g., corrections during sanding can slow down or speed up a sanding pass). In this work, we investigate how to assure the multi-robot scheduling solution accounts for the worst-case changes to timing induced by the corrections.


% For example, an expert sander may use sound and a variety of subtle visual cues (e.g., watching material, moving around to get different looks at the surface) to choose an appropriate action.

% Real-time corrections are provided using a joystick-like device that allows for differential changes to the robot command. The corrections that the operator can provide are determined directly from the demonstration variability. For example, the corrections during sanding may modulate abrasiveness which is a combination of applied force, tool pitch, and the tangential speed of the tool, which may also impact the task duration. Our method automatically sequences the robot executions such that only one robot is low-confidence at a given time, meaning that it might need corrections. Our method iteratively estimates the robot's confidence across the task to determine the time steps at which the robot behavior may need corrections. Initially, the behaviors will be mostly low-confidence and executed serially, however, as the system estimates through experience that certain times don't require corrections, it will schedule the robot executions with a higher degree of overlap. The key challenges in scheduling this multi-agent Shared Autonomy are determining what times in a robot behavior could need corrections, scheduling the multiple robot executions such that the operator can provide corrections at the appropriate times during each robot execution, taking into account that operator corrections impact the timing of the robots. In this section, we describe the problem setting and preliminaries, we formulate the multi-robot Shared Autonomy problem as an optimization, and we briefly discuss technical methods that can be used for scheduling.

% Our objective is to coordinate two robots and one supervisor to maximize task performance (i.e., reward) while minimizing the total time to complete two instances of the task. In this work, we focus on episodic tasks (i.e., the two robots each complete a single instance of the task). We assume the robot has a nominal task model from expert demonstrations that is insufficient to properly complete the task, but that the operator is able to provide real-time corrections to address any mistakes by the robot (i.e., to help maximize task reward). We assume the robots do not have access to the human's observations and consequently the human's reward function.

%Let $\mathcal{D} = \{(s_0, a_0), \ldots (s_N, a_N)\}$ be a set of $N$ state-action pairs demonstrated by the human expert.


% To draw parallels with previous work in human corrections to robot behaviors \cite{bajcsy2017learning,bobu2018learning}, if we assume that the human behaves in a noisily rational manner \cite{baker2007goal}, the likelihood of the operator providing a correction, $\delta \textbf{x}^{+}$, at a particular time in the task can be based on the human's reward function and how much a correction improves reward:

% \begin{equation}
%  P(\delta \textbf{x}^{+} \mid t) \propto e^{\beta_R \left( R \left ( \textbf{x}^{+}(t)+\delta \textbf{x}^{+} \right) \right)} \\
% \end{equation}
% where $R$ is the human's reward function and $\beta_R$ is the rationality parameter. Following similar assumptions about human rationality, it is also possible to express the relative likelihood of the event of any correction being given, $c \in \mathbb{B}$, at every time by maximizing over the possible operator corrections.

% \begin{equation}
%  P(t \mid c=1) \propto e^{\beta_R \max\limits_{\delta \textbf{x}^{+}} \left( R \left ( \textbf{x}^{+}(t)+\delta \textbf{x}^{+} \right) \right)} \\
% \end{equation}
% With this likelihood function, the expected probability of a correction, $p(c=1 \mid t$), could estimated via Bayes rule.
% As we do not have access to the human's reward function
% However, most of the time, we cannot assume we have access to the human reward function. Furthermore, the human may use additional observations beyond the robot state (and that the robot cannot observe) to assess the reward. Thus, we desire an alternate way to estimate $p(c=1 \mid t)$. For brevity, we denote the probability of corrections as $p_{c\mid t}$ (i.e., $p_{c\mid t} \equiv p(c=1|t)$) going forward. 




% is this needed somewhere
% (i.e., $\psi_{\mathcal{D}_2 \rightarrow \mathcal{D}_1}^{-1} \equiv \psi_{\mathcal{D}_1 \rightarrow \mathcal{D}_2}$)


%Also, even with changes to the mean behavior at each iteration of the system, the previous scheduling solution can be shown to be valid. From the margin checking in Algorithm \ref{alg:margin}, we know that any permissible correction can be accommodated by the scheduling solution. The shifted mean in Equation \ref{eq:dagger} can be viewed as a special case of a permissible correction.



% \smallskip
% \noindent \textbf{Online Corrections.} In addition to providing the offline demonstrations, the human may intervene during the task to correct a robot's behavior. We emphasize that the human can only attend to and \textit{correct one robot at a time.} During these corrections, the human uses a joystick to provide differential changes to the robot action.

% \smallskip
% \noindent \textbf{Objective.} During this multi-agent interaction, the human's goal is two-fold. First, the human wants to maximize performance across the two robot tasks by applying corrections when the robots make errors. Second, the human wants to minimize the total amount of time spent to complete both robot tasks.


 %(see Figure \ref{fig:teaser}). 
% If the two robots attempt to perform the task in \textit{parallel} without coordination, the human will be unable to correct each robot when they both make errors at the same time. On the other hand, if the robots complete the task in \textit{sequence}, the overall task duration increases and we lose the benefits of having two separate robots. Accordingly, we develop an algorithmic approach that \textit{optimizes} task scheduling between the robots. Under our proposed approach, at any time only one robot is in a region of the task where there is a high probability it will need human assistance. 
%In this section we describe the problem setting and assumptions, we formulate our method for multi-robot shared autonomy as an optimization problem, and we describe our solution's pertinent implementation details.


% Even when there are no opportunities for simultaneous executions, identifying high-confidence samples allows the scheduling to choose faster executions rates to reduce time on task.



% Features for scheduling

% Extending to multi-modal distributions over trajectories

% demonstrations expose variability -- might need a large number of demonstrations to see infrequent corrections. alternatively, some inference...

% Extending to heterogeneous -- introduces order of tasks

% Many human factors to explore: sit awareness, collocation, task setup
% SA presumes same time for each variable action, whereas it may be action dependent

% Personalization -- eliciting prefernces (e.g., SA, etc)

% correspondence -- assumes robot platform is capable of executing any admissible demonstration rate

% dependent on the results of the DTW

% episodic vs non-episodic -- each robot does the task once... might also scale to other

% Not all tasks amenable (particularly if not a lot of low-correction or short no-correction) & a first attempt into the coordinated space

% Latent corrections limitation.

% Given time warps of heterogeneous tasks, should accommodate the optimization, but might have considerations for human factors

% Extending to more than 2 robots.

% More work on real-time adaptation

% The scheduling solution is dependent on the number of robotic agents completing the task, $n_a$. In this work, we assume the number of robots is given. Choosing this number is based on available hardware, the percentage of variability within the task (i.e., the fan-out plateau \cite{olsen2004fan}), as well environmental factors (e.g., collocation of operator, context switching). The choice of number of robots is further discussed in Section \ref{sec:discussion}.

% \subsection{Conclusion}
% In this work, we presented and evaluated a method for coordinated multi-robot shared autonomy based on scheduling and demonstrations. Our method enables the scheduling of two robots based on iterative estimates of confidence and proposes algorithms for adjusting in real-time when operators provide corrections to the robot that affect timing. Through an experimental evaluation, we demonstrated how our method can reduce time on task and improve operator utilization by scheduling robot executions based on confidence.


% Finally, as corrections from the operator can impact the timing of the robots, we propose a strategy to update the robot execution rates in real time to best adhere to the original schedule. We also show how we can ensure the scheduling solution is robust (i.e., avoiding two low-confidence actions at the same time) to the worst-case timing deviations induced by the operator corrections. 


% We only require operator oversight when a time in the task is both \emph{critical} and \emph{variable}. For example, there may be passes during sanding that are critical to completing the task, but have low variability and don't require aid from the operator. Thus, we can set up our confidence function:

% \begin{equation}
%     c(t)=\left\{
% \begin{array}{ll}
%       e^{-\alpha \cdot var(t)} & f_{crit}(t) \\
%       1 & else 
% \end{array} 
% \right.
% \end{equation}