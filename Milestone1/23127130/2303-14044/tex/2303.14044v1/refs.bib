@article{1,
  title={Solar sail halo orbits at the Sun--Earth artificial L$_{1}$ point},
  author={Baoyin,H and Mcinnes, CR.},
  journal={Celestial Mechanics and Dynamical Astronomy},
  volume={94},
  number={2},
  pages={155--171},
  year={2006},
}


@misc{Authors12,
 author = {Authors},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture  submission ID 324. Supplied as additional material {\tt fg324.pdf}},
 year = 2012
}

@misc{Authors12b,
 author = {Authors},
 title = {Frobnication tutorial},
 note = {Supplied as additional material {\tt tr.pdf}},
 year = 2012
}

@article{Alpher02,
author = {A. Alpher},
title = {Frobnication},
journal = {Journal of Foo},
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {A. Alpher and  J.~P.~N. Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {A. Alpher and J.~P.~N. Fotheringham-Smythe and G. Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Our references

@INPROCEEDINGS{paysan20093d,
  author={Paysan, Pascal and Knothe, Reinhard and Amberg, Brian and Romdhani, Sami and Vetter, Thomas},
  booktitle={2009 Sixth IEEE International Conference on Advanced Video and Signal Based Surveillance}, 
  title={A 3D Face Model for Pose and Illumination Invariant Face Recognition}, 
  year={2009},
  volume={},
  number={},
  pages={296-301},
  doi={10.1109/AVSS.2009.58}}


@INPROCEEDINGS{c2,
  author={Baltrušaitis, Tadas and Robinson, Peter and Morency, Louis-Philippe},
  booktitle={2016 IEEE Winter Conference on Applications of Computer Vision (WACV)}, 
  title={OpenFace: An open source facial behavior analysis toolkit}, 
  year={2016},
  volume={},
  number={},
  pages={1-10},
  doi={10.1109/WACV.2016.7477553}}


@article{c3,
  title={Facewarehouse: A 3d facial expression database for visual computing},
  author={Cao, Chen and Weng, Yanlin and Zhou, Shun and Tong, Yiying and Zhou, Kun},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  volume={20},
  number={3},
  pages={413--425},
  year={2013},
  publisher={IEEE}
}



@inproceedings{c4,
  title={Music-driven motion editing: Local motion transformations guided by music analysis},
  author={Cardle, Marc and Barthe, Loic and Brooks, Stephen and Robinson, Peter},
  booktitle={Proceedings 20th Eurographics UK Conference},
  pages={38--44},
  year={2002}
}

@article{c5,
  title={Music similarity-based approach to generating dance motion sequence},
  author={Lee, Minho and Lee, Kyogu and Park, Jaeheung},
  journal={Multimedia tools and applications},
  volume={62},
  number={3},
  pages={895--912},
  year={2013},
  publisher={Springer}
}

@article{c6,
  title={Dancing-to-music character animation},
  author={Shiratori, Takaaki and Nakazawa, Atsushi and Ikeuchi, Katsushi},
  booktitle={Computer Graphics Forum},
  volume={25},
  number={3},
  pages={449--458},
  year={2006},
}

@article{c7,
  title={GrooveNet: Real-time music-driven dance movement generation using artificial neural networks},
  author={Alemi, Omid and Fran{\c{c}}oise, Jules and Pasquier, Philippe},
  journal={networks},
  volume={8},
  number={17},
  pages={26},
  year={2017}
}

@article{c8,
  title={Dance with melody: An lstm-autoencoder approach to music-oriented dance synthesis},
  author={Tang, Taoran and Jia, Jia and Mao, Hanyang},
  booktitle={Proceedings of the 26th ACM international conference on Multimedia},
  pages={1598--1606},
  year={2018}
}

@article{c9,
  title={Weakly-supervised deep recurrent neural networks for basic dance step generation},
  author={Yalta, Nelson and Watanabe, Shinji and Nakadai, Kazuhiro and Ogata, Tetsuya},
  booktitle={2019 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--8},
  year={2019},
}

@article{c10,
  title={Towards 3D Dance Motion Synthesis and Control},
  author={Zhuang, Wenlin and Wang, Yangang and Robinson, Joseph and Wang, Congyi and Shao, Ming and Fu, Yun and Xia, Siyu},
  journal={arXiv preprint arXiv:2006.05743},
  year={2020}
}

@article{c11,
  title={Temporally Guided Music-to-Body-Movement Generation},
  author={Kao, Hsuan-Kai and Su, Li},
  booktitle={Proceedings of the 28th ACM International Conference on Multimedia},
  pages={147--155},
  year={2020}
}

@article{c12,
  title={Dancing to music},
  author={Lee, Hsin-Ying and Yang, Xiaodong and Liu, Ming-Yu and Wang, Ting-Chun and Lu, Yu-Ding and Yang, Ming-Hsuan and Kautz, Jan},
  journal={arXiv preprint arXiv:1911.02001},
  year={2019}
}

@article{c13,
  title={DeepDance: music-to-dance motion choreography with adversarial learning},
  author={Sun, Guofei and Wong, Yongkang and Cheng, Zhiyong and Kankanhalli, Mohan S and Geng, Weidong and Li, Xiangdong},
  journal={IEEE Transactions on Multimedia},
  volume={23},
  pages={497--509},
  year={2020},
  publisher={IEEE}
}

@article{c14,
  title={Dance Revolution: Long-Term Dance Generation with Music via Curriculum Learning},
  author={Huang, Ruozi and Hu, Huang and Wu, Wei and Sawada, Kei and Zhang, Mi and Jiang, Daxin},
  journal={arXiv preprint arXiv:2006.06119},
  year={2020}
}

@article{c15,
  title={Learning to generate diverse dance motions with transformer},
  author={Li, Jiaman and Yin, Yihang and Chu, Hang and Zhou, Yi and Wang, Tingwu and Fidler, Sanja and Li, Hao},
  journal={arXiv preprint arXiv:2008.08171},
  year={2020}
}

@article{c16,
  title={Learn to Dance with AIST++: Music Conditioned 3D Dance Generation},
  author={Li, Ruilong and Yang, Shan and Ross, David A and Kanazawa, Angjoo},
  journal={arXiv preprint arXiv:2101.08779},
  year={2021}
}

@article{c17,
  title={Listen to dance: Music-driven choreography generation using autoregressive encoder-decoder network},
  author={Lee, Juheon and Kim, Seohyun and Lee, Kyogu},
  journal={arXiv preprint arXiv:1811.00818},
  year={2018}
}

@inproceedings{c18,
  title={Choreonet: Towards music to dance synthesis with choreographic action unit},
  author={Ye, Zijie and Wu, Haozhe and Jia, Jia and Bu, Yaohua and Chen, Wei and Meng, Fanbo and Wang, Yanfeng},
  booktitle={Proceedings of the 28th ACM International Conference on Multimedia},
  pages={744--752},
  year={2020}
}

@inproceedings{c19,
  title={Voice puppetry},
  author={Brand, Matthew},
  booktitle={Proceedings of the 26th annual conference on Computer graphics and interactive techniques},
  pages={21--28},
  year={1999}
}

@inproceedings{c20,
  title={Video rewrite: Driving visual speech with audio},
  author={Bregler, Christoph and Covell, Michele and Slaney, Malcolm},
  booktitle={Proceedings of the 24th annual conference on Computer graphics and interactive techniques},
  pages={353--360},
  year={1997}
}

@article{c21,
  title={Trainable videorealistic speech animation},
  author={Ezzat, Tony and Geiger, Gadi and Poggio, Tomaso},
  journal={ACM Transactions on Graphics (TOG)},
  volume={21},
  number={3},
  pages={388--398},
  year={2002},
  publisher={ACM New York, NY, USA}
}

@inproceedings{c22,
  title={Text driven 3d photo-realistic talking head},
  author={Wang, Lijuan and Han, Wei and Soong, Frank K and Huo, Qiang},
  booktitle={Twelfth Annual Conference of the International Speech Communication Association},
  year={2011}
}


@INPROCEEDINGS{c23,
  author={Shimba, Taiki and Sakurai, Ryuhei and Yamazoe, Hirotake and Lee, Joo-Ho},
  booktitle={2015 IEEE/SICE International Symposium on System Integration (SII)}, 
  title={Talking heads synthesis from audio with deep neural networks}, 
  year={2015},
  volume={},
  number={},
  pages={100-105},
  doi={10.1109/SII.2015.7404961}}


@inproceedings{VOCA2019,
    title = {Capture, Learning, and Synthesis of {3D} Speaking Styles},
    author = {Cudeiro, Daniel and Bolkart, Timo and Laidlaw, Cassidy and Ranjan, Anurag and Black, Michael},
    booktitle = {Proceedings IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)},
    pages = {10101--10111},
    year = {2019},
    url = {http://voca.is.tue.mpg.de/}
}

@article{suwajanakorn2017synthesizing,
  title={Synthesizing obama: learning lip sync from audio},
  author={Suwajanakorn, Supasorn and Seitz, Steven M and Kemelmacher-Shlizerman, Ira},
  journal={ACM Transactions on Graphics (ToG)},
  volume={36},
  number={4},
  pages={1--13},
  year={2017},
  publisher={ACM New York, NY, USA}
}

@inproceedings{wav2lip,
  title={A lip sync expert is all you need for speech to lip generation in the wild},
  author={Prajwal, KR and Mukhopadhyay, Rudrabha and Namboodiri, Vinay P and Jawahar, CV},
  booktitle={Proceedings of the 28th ACM International Conference on Multimedia},
  pages={484--492},
  year={2020}
}

@inproceedings{NeuralVoicePuppetry,
  title={Neural voice puppetry: Audio-driven facial reenactment},
  author={Thies, Justus and Elgharib, Mohamed and Tewari, Ayush and Theobalt, Christian and Nie{\ss}ner, Matthias},
  booktitle={European Conference on Computer Vision},
  pages={716--731},
  year={2020},
}

@inproceedings{zhou2019talking,
  title={Talking face generation by adversarially disentangled audio-visual representation},
  author={Zhou, Hang and Liu, Yu and Liu, Ziwei and Luo, Ping and Wang, Xiaogang},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={33},
  number={01},
  pages={9299--9306},
  year={2019}
}

@inproceedings{li2021write,
  title={Write-a-speaker: Text-based emotional and rhythmic talking-head generation},
  author={Li, Lincheng and Wang, Suzhen and Zhang, Zhimeng and Ding, Yu and Zheng, Yixing and Yu, Xin and Fan, Changjie},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={3},
  pages={1911--1920},
  year={2021}
}

@article{yao2021iterative,
  title={Iterative text-based editing of talking-heads using neural retargeting},
  author={Yao, Xinwei and Fried, Ohad and Fatahalian, Kayvon and Agrawala, Maneesh},
  journal={ACM Transactions on Graphics (TOG)},
  volume={40},
  number={3},
  pages={1--14},
  year={2021},
  publisher={ACM New York, NY}
}

@article{fried2019text,
  title={Text-based editing of talking-head video},
  author={Fried, Ohad and Tewari, Ayush and Zollh{\"o}fer, Michael and Finkelstein, Adam and Shechtman, Eli and Goldman, Dan B and Genova, Kyle and Jin, Zeyu and Theobalt, Christian and Agrawala, Maneesh},
  journal={ACM Transactions on Graphics (TOG)},
  volume={38},
  number={4},
  pages={1--14},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@inproceedings{Speech-Driven,
  title={Speech-driven facial animation using cascaded gans for learning of motion and texture},
  author={Das, Dipanjan and Biswas, Sandika and Sinha, Sanjana and Bhowmick, Brojeshwar},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XXX 16},
  pages={408--424},
  year={2020}
}


@inproceedings{guo2021ad,
  title={Ad-nerf: Audio driven neural radiance fields for talking head synthesis},
  author={Guo, Yudong and Chen, Keyu and Liang, Sen and Liu, Yong-Jin and Bao, Hujun and Zhang, Juyong},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5784--5794},
  year={2021}
}


@inproceedings{xie2021towards,
  title={Towards realistic visual dubbing with heterogeneous sources},
  author={Xie, Tianyi and Liao, Liucheng and Bi, Cheng and Tang, Benlai and Yin, Xiang and Yang, Jianfei and Wang, Mingjie and Yao, Jiali and Zhang, Yang and Ma, Zejun},
  booktitle={Proceedings of the 29th ACM International Conference on Multimedia},
  pages={1739--1747},
  year={2021}
}


@article{c28,
  title={Photorealistic Audio-driven Video Portraits},
  author={Wen, Xin and Wang, Miao and Richardt, Christian and Chen, Ze-Yin and Hu, Shi-Min},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  volume={26},
  number={12},
  pages={3457--3466},
  year={2020},
  publisher={IEEE}
}

@misc{chen2020talkinghead,
      title={Talking-head Generation with Rhythmic Head Motion}, 
      author={Lele Chen and Guofeng Cui and Celong Liu and Zhong Li and Ziyi Kou and Yi Xu and Chenliang Xu},
      year={2020},
      eprint={2007.08547},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{yi2020audio,
  title={Audio-driven talking face video generation with learning-based personalized head pose},
  author={Yi, Ran and Ye, Zipeng and Zhang, Juyong and Bao, Hujun and Liu, Yong-Jin},
  journal={arXiv preprint arXiv:2002.10137},
  year={2020}
}

@article{c31,
  title={FACIAL: Synthesizing Dynamic Talking Face with Implicit Attribute Learning},
  author={Zhang, Chenxu and Zhao, Yifan and Huang, Yifei and Zeng, Ming and Ni, Saifeng and Budagavi, Madhukar  and Guo, Xiaohu},
  journal={arXiv preprint arXiv:2108.07938},
  year={2021}
}

@inproceedings{c32,
  title={Generative moment matching networks},
  author={Li, Yujia and Swersky, Kevin and Zemel, Rich},
  booktitle={International Conference on Machine Learning},
  pages={1718--1727},
  year={2015},
}


@article{c33,
  title={SYNC-NET: distributed time synchronization in clustered sensor networks},
  author={Younis, Ossama and Fahmy, Sonia},
  journal={Wireless Communications and Mobile Computing},
  volume={8},
  number={6},
  pages={797--809},
  year={2008},
  publisher={Wiley Online Library}
}

@inproceedings{c34,
  title={Audio-driven emotional video portraits},
  author={Ji, Xinya and Zhou, Hang and Wang, Kaisiyuan and Wu, Wayne and Loy, Chen Change and Cao, Xun and Xu, Feng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14080--14089},
  year={2021}
}


@inproceedings{c35,
  title={Neural voice puppetry: Audio-driven facial reenactment},
  author={Thies, Justus and Elgharib, Mohamed and Tewari, Ayush and Theobalt, Christian and Nie{\ss}ner, Matthias},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XVI 16},
  pages={716--731},
  year={2020},
}

@inproceedings{c36,
  title={Ganimation: Anatomically-aware facial animation from a single image},
  author={Pumarola, Albert and Agudo, Antonio and Martinez, Aleix M and Sanfeliu, Alberto and Moreno-Noguer, Francesc},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={818--833},
  year={2018}
}

@inproceedings{c37,
  title={Few-shot adversarial learning of realistic neural talking head models},
  author={Zakharov, Egor and Shysheya, Aliaksandra and Burkov, Egor and Lempitsky, Victor},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9459--9468},
  year={2019}
}

@article{c38,
  title={One-shot face reenactment},
  author={Zhang, Yunxuan and Zhang, Siwei and He, Yue and Li, Cheng and Loy, Chen Change and Liu, Ziwei},
  journal={arXiv preprint arXiv:1908.03251},
  year={2019}
}

@inproceedings{c39,
  title={A neural virtual anchor synthesizer based on seq2seq and gan models},
  author={Wang, Zipeng and Liu, Zhaoxiang and Chen, Zezhou and Hu, Huan and Lian, Shiguo},
  booktitle={2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)},
  pages={233--236},
  year={2019}
}

@article{c40,
  title={Face2Face: Real-time Face Capture and Reenactment of RGB Videos},
  author={Thies, Justus and Zollhofer, Stamminger and Marc, Kyogu and Theobalt, Christian and Nießner, Matthias},
  journal={arXiv preprint arXiv:2007.14808},
  year={2020}
}

@article{c41,
  title={A realistic, virtual head for human--computer interaction},
  author={Marcos, Samuel and G{\'o}mez-Garc{\'\i}a-Bermejo, Jaime and Zalama, Eduardo},
  journal={Interacting with Computers},
  volume={22},
  number={3},
  pages={176--192},
  year={2010},
  publisher={Oxford University Press Oxford, UK}
}

@article{c42,
  title={A video, text, and speech-driven realistic 3-D virtual head for human--machine interface},
  author={Yu, Jun and Wang, Zeng-Fu},
  journal={IEEE transactions on cybernetics},
  volume={45},
  number={5},
  pages={991--1002},
  year={2014},
  publisher={IEEE}
}

@inproceedings{c43,
  title={Accurate 3d face reconstruction with weakly-supervised learning: From single image to image set},
  author={Deng, Yu and Yang, Jiaolong and Xu, Sicheng and Chen, Dong and Jia, Yunde and Tong, Xin},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops},
  pages={0--0},
  year={2019}
}

@inproceedings{zhou2021pose,
  title={Pose-controllable talking face generation by implicitly modularized audio-visual representation},
  author={Zhou, Hang and Sun, Yasheng and Wu, Wayne and Loy, Chen Change and Wang, Xiaogang and Liu, Ziwei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4176--4186},
  year={2021}
}

@InProceedings{c45,
    author    = {Ji, Xinya and Zhou, Hang and Wang, Kaisiyuan and Wu, Wayne and Loy, Chen Change and Cao, Xun and Xu, Feng},
    title     = {Audio-Driven Emotional Video Portraits},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {14080-14089}
}

@article{c46,
  title={Speech2Video: Cross-Modal Distillation for Speech to Video Generation},
  author={Si, Shijing and Wang, Jianzong and Qu, Xiaoyang and Cheng, Ning and Wei, Wenqi and Zhu, Xinghua and Xiao, Jing},
  journal={arXiv preprint arXiv:2107.04806},
  year={2021}
}

@inproceedings{syncnet,
  title={Out of time: automated lip sync in the wild},
  author={Chung, Joon Son and Zisserman, Andrew},
  booktitle={Asian conference on computer vision},
  pages={251--263},
  year={2016},
}

@inproceedings{wang2022one,
  title={One-shot talking face generation from single-speaker audio-visual correlation learning},
  author={Wang, Suzhen and Li, Lincheng and Ding, Yu and Yu, Xin},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={3},
  pages={2531--2539},
  year={2022}
}

@inproceedings{zhang2021facial,
  title={FACIAL: Synthesizing Dynamic Talking Face with Implicit Attribute Learning},
  author={Zhang, Chenxu and Zhao, Yifan and Huang, Yifei and Zeng, Ming and Ni, Saifeng and Budagavi, Madhukar and Guo, Xiaohu},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3867--3876},
  year={2021}
}
@article{zhou2020makelttalk,
  title={MakeltTalk: speaker-aware talking-head animation},
  author={Zhou, Yang and Han, Xintong and Shechtman, Eli and Echevarria, Jose and Kalogerakis, Evangelos and Li, Dingzeyu},
  journal={ACM Transactions on Graphics (TOG)},
  volume={39},
  number={6},
  pages={1--15},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@article{wang2021audio2head,
  title={Audio2head: Audio-driven one-shot talking-head generation with natural head motion},
  author={Wang, Suzhen and Li, Lincheng and Ding, Yu and Fan, Changjie and Yu, Xin},
  journal={arXiv preprint arXiv:2107.09293},
  year={2021}
}

@inproceedings{chen2019hierarchical,
  title={Hierarchical cross-modal talking face generation with dynamic pixel-wise loss},
  author={Chen, Lele and Maddox, Ross K and Duan, Zhiyao and Xu, Chenliang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7832--7841},
  year={2019}
}

@article{spleeter2020,
  doi = {10.21105/joss.02154},
  url = {https://doi.org/10.21105/joss.02154},
  year = {2020},
  publisher = {The Open Journal},
  volume = {5},
  number = {50},
  pages = {2154},
  author = {Romain Hennequin and Anis Khlif and Felix Voituret and Manuel Moussallam},
  title = {Spleeter: a fast and efficient music source separation tool with pre-trained models},
  journal = {Journal of Open Source Software},
  note = {Deezer Research}
}

@misc{hu2019squeezeandexcitation,
      title={Squeeze-and-Excitation Networks}, 
      author={Jie Hu and Li Shen and Samuel Albanie and Gang Sun and Enhua Wu},
      year={2019},
      eprint={1709.01507},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{hu2018squeeze,
  title={Squeeze-and-excitation networks},
  author={Hu, Jie and Shen, Li and Sun, Gang},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7132--7141},
  year={2018}
}

@misc{sinha2020identitypreserving,
      title={Identity-Preserving Realistic Talking Face Generation}, 
      author={Sanjana Sinha and Sandika Biswas and Brojeshwar Bhowmick},
      year={2020},
      eprint={2005.12318},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{chen2018lip,
  title={Lip movements generation at a glance},
  author={Chen, Lele and Li, Zhiheng and Maddox, Ross K and Duan, Zhiyao and Xu, Chenliang},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={520--535},
  year={2018}
}

@misc{mao2017squares,
      title={Least Squares Generative Adversarial Networks}, 
      author={Xudong Mao and Qing Li and Haoran Xie and Raymond Y. K. Lau and Zhen Wang and Stephen Paul Smolley},
      year={2017},
      eprint={1611.04076},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{mao2017least,
  title={Least squares generative adversarial networks},
  author={Mao, Xudong and Li, Qing and Xie, Haoran and Lau, Raymond YK and Wang, Zhen and Paul Smolley, Stephen},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2794--2802},
  year={2017}
}

@InProceedings{Genova_2018_CVPR,
  author = {Genova, Kyle and Cole, Forrester and Maschinot, Aaron and Sarna, Aaron and Vlasic, Daniel and Freeman, William T.},
  title = {Unsupervised Training for 3D Morphable Model Regression},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month = {June},
  year = {2018}
}

@article{lin2021robust,
  title={Robust High-Resolution Video Matting with Temporal Guidance},
  author={Lin, Shanchuan and Yang, Linjie and Saleemi, Imran and Sengupta, Soumyadip},
  journal={arXiv preprint arXiv:2108.11515},
  year={2021}
}

@inproceedings{zhang2021flow,
  title={Flow-guided one-shot talking face generation with a high-resolution audio-visual dataset},
  author={Zhang, Zhimeng and Li, Lincheng and Ding, Yu and Fan, Changjie},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3661--3670},
  year={2021}
}

@incollection{iwase2020song2face,
  title={Song2Face: Synthesizing Singing Facial Animation from Audio},
  author={Iwase, Shohei and Kato, Takuya and Yamaguchi, Shugo and Yukitaka, Tsuchiya and Morishima, Shigeo},
  booktitle={SIGGRAPH Asia 2020 Technical Communications},
  pages={1--4},
  year={2020}
}



@InProceedings{voxceleb2,
  author       = "Chung, J.~S. and Nagrani, A. and Zisserman, A.",
  title        = "VoxCeleb2: Deep Speaker Recognition",
  booktitle    = "INTERSPEECH",
  year         = "2018",
}


@inproceedings{lrs2,
  title={Lip reading sentences in the wild},
  author={Son Chung, Joon and Senior, Andrew and Vinyals, Oriol and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6447--6456},
  year={2017}
}

@article{lu2021live,
  title={Live speech portraits: real-time photorealistic talking-head animation},
  author={Lu, Yuanxun and Chai, Jinxiang and Cao, Xun},
  journal={ACM Transactions on Graphics (TOG)},
  volume={40},
  number={6},
  pages={1--17},
  year={2021},
  publisher={ACM New York, NY, USA}
}


@article{ismail2019deep,
  title={Deep learning for time series classification: a review},
  author={Ismail Fawaz, Hassan and Forestier, Germain and Weber, Jonathan and Idoumghar, Lhassane and Muller, Pierre-Alain},
  journal={Data mining and knowledge discovery},
  volume={33},
  number={4},
  pages={917--963},
  year={2019},
  publisher={Springer}
}

@article{zhang20213d,
  title={3d talking face with personalized pose dynamics},
  author={Zhang, Chenxu and Ni, Saifeng and Fan, Zhipeng and Li, Hongbo and Zeng, Ming and Budagavi, Madhukar and Guo, Xiaohu},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  year={2021},
  publisher={IEEE}
}
