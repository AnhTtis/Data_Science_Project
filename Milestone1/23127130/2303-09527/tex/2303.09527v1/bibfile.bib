@inproceedings{yang2022differentially,
  title={Differentially private sgda for minimax problems},
  author={Yang, Zhenhuan and Hu, Shu and Lei, Yunwen and Vashney, Kush R and Lyu, Siwei and Ying, Yiming},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={2192--2202},
  year={2022},
  organization={PMLR}
}

@inproceedings{yang2021stability,
  title={Stability and differential privacy of stochastic gradient descent for pairwise learning with non-smooth loss},
  author={Yang, Zhenhuan and Lei, Yunwen and Lyu, Siwei and Ying, Yiming},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2026--2034},
  year={2021},
  organization={PMLR}
}

@article{bu2020deep,
  title={Deep learning with gaussian differential privacy},
  author={Bu, Zhiqi and Dong, Jinshuo and Long, Qi and Su, Weijie J},
  journal={Harvard data science review},
  volume={2020},
  number={23},
  pages={10--1162},
  year={2020},
  publisher={NIH Public Access}
}

@article{wang2022differentially,
  title={Differentially private SGD with non-smooth losses},
  author={Wang, Puyu and Lei, Yunwen and Ying, Yiming and Zhang, Hai},
  journal={Applied and Computational Harmonic Analysis},
  volume={56},
  pages={306--336},
  year={2022},
  publisher={Elsevier}
}

@article{yang2022minimax,
  title={Minimax AUC Fairness: Efficient Algorithm with Provable Convergence},
  author={Yang, Zhenhuan and Ko, Yan Lok and Varshney, Kush R and Ying, Yiming},
  journal={arXiv preprint arXiv:2208.10451},
  year={2022}
}

@inproceedings{he2016ups,
  title={Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering},
  author={He, Ruining and McAuley, Julian},
  booktitle={proceedings of the 25th international conference on world wide web},
  pages={507--517},
  year={2016}
}

@article{zehlike2021fairness,
  title={Fairness in ranking: A survey},
  author={Zehlike, Meike and Yang, Ke and Stoyanovich, Julia},
  journal={arXiv preprint arXiv:2103.14000},
  year={2021}
}

@inproceedings{zhu2022cali3f,
  title={Cali3F: Calibrated Fast Fair Federated Recommendation System},
  author={Zhu, Zhitao and Si, Shijing and Wang, Jianzong and Xiao, Jing},
  booktitle={2022 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--8},
  year={2022},
  organization={IEEE}
}


@inproceedings{maeng2022towards,
  title={Towards fair federated recommendation learning: Characterizing the inter-dependence of system and data heterogeneity},
  author={Maeng, Kiwan and Lu, Haiyu and Melis, Luca and Nguyen, John and Rabbat, Mike and Wu, Carole-Jean},
  booktitle={Proceedings of the 16th ACM Conference on Recommender Systems},
  pages={156--167},
  year={2022}
}

@inproceedings{li2021cikm,
  title={Tutorial on Fairness of Machine Learning in Recommender Systems},
  author={Li, Yunqi and Ge, Yingqiang and Zhang, Yongfeng},
  booktitle={Proceedings of the 30th CIKM},
  year={2021}
}

@inproceedings{li2021user,
  title={User-oriented Fairness in Recommendation},
  author={Li, Yunqi and Chen, Hanxiong and Fu, Zuohui and Ge, Yingqiang and Zhang, Yongfeng},
  booktitle={Proceedings of the Web Conference 2021},
  pages={624--632},
  year={2021}
}

@inproceedings{10.1145/3397271.3401431,
author = {Ge, Yingqiang and Zhao, Shuya and Zhou, Honglu and Pei, Changhua and Sun, Fei and Ou, Wenwu and Zhang, Yongfeng},
title = {Understanding Echo Chambers in E-Commerce Recommender Systems},
year = {2020},
isbn = {9781450380164},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3397271.3401431},
doi = {10.1145/3397271.3401431},
abstract = {Personalized recommendation benefits users in accessing contents of interests effectively. Current research on recommender systems mostly focuses on matching users with proper items based on user interests. However, significant efforts are missing to understand how the recommendations influence user preferences and behaviors, e.g., if and how recommendations result in echo chambers. Extensive efforts have been made in examining the phenomenon in online media and social network systems. Meanwhile, there are growing concerns that recommender systems might lead to the self-reinforcing of user's interests due to narrowed exposure of items, which may be the potential cause of echo chamber. In this paper, we aim to analyze the echo chamber phenomenon in Alibaba Taobao --- one of the largest e-commerce platforms in the world.Echo chamber means the effect of user interests being reinforced through repeated exposure to similar contents. Based on the definition, we examine the presence of echo chamber in two steps. First, we explore whether user interests have been reinforced. Second, we check whether the reinforcement results from the exposure of similar contents. Our evaluations are enhanced with robust metrics, including cluster validity and statistical significance. Experiments are performed on extensive collections of real-world data consisting of user clicks, purchases, and browse logs from Alibaba Taobao. Evidence suggests the tendency of echo chamber in user click behaviors, while it is relatively mitigated in user purchase behaviors. Insights from the results guide the refinement of recommendation algorithms in real-world e-commerce systems.},
booktitle = {Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2261–2270},
numpages = {10},
keywords = {echo chamber, e-commerce, filter bubble, recommender systems},
location = {Virtual Event, China},
series = {SIGIR '20}
}

@inproceedings{10.1145/3308558.3313725,
author = {Ge, Yingqiang and Xu, Shuyuan and Liu, Shuchang and Geng, Shijie and Fu, Zuohui and Zhang, Yongfeng},
title = {Maximizing Marginal Utility per Dollar for Economic Recommendation},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308558.3313725},
doi = {10.1145/3308558.3313725},
abstract = {Understanding the economic nature of consumer decisions in e-Commerce is important to personalized recommendation systems. Established economic theories claim that informed consumers always attempt to maximize their utility by choosing the items of the largest marginal utility per dollar (MUD) within their budgets. For example, gaining 5 dollars of extra benefit by spending 10 dollars makes a consumer much more satisfied than having the same amount of extra benefit by spending 20 dollars, although the second product may have higher absolute utility value. Meanwhile, making purchases online may be risky decisions that could cause dissatisfaction. For example, people may give low ratings towards purchased items that they thought they would like when placing the order. Therefore, the design of recommender systems should also take users' risk attitudes into consideration to better learn consumer behaviors. Motivated by the first consideration, in this paper, we propose a learning algorithm to maximize marginal utility per dollar for recommendations. With the second, economic theory shows that rational people can be arbitrarily close to risk neutral when stakes are arbitrarily small, and this is generally applicable to consumer online purchase behaviors because most people spend a small portion of their total wealth for a single purchase. To integrate this theory with machine learning, we propose to augment MUD optimization with approximate risk-neural constraint to generate personalized recommendations. Experiments on real-world e-Commerce datasets show that our approach is able to achieve better performance than many classical recommendation methods, in terms of both traditional recommendation measures such as precision and recall, as well as economic measures such as MUD.},
booktitle = {The World Wide Web Conference},
pages = {2757–2763},
numpages = {7},
keywords = {Recommendation Systems, Personalization, Computational Economics, Marginal Utility per Dollar, Risk Attitude},
location = {San Francisco, CA, USA},
series = {WWW '19}
}

@inproceedings{ge2021towards,
  title={Towards Long-term Fairness in Recommendation},
  author={Ge, Yingqiang and Liu, Shuchang and Gao, Ruoyuan and Xian, Yikun and Li, Yunqi and Zhao, Xiangyu and Pei, Changhua and Sun, Fei and Ge, Junfeng and Ou, Wenwu and Zhang, Yongfeng},
  booktitle={Proceedings of the 14th ACM International Conference on Web Search and Data Mining},
  pages={445--453},
  year={2021}
}

@inproceedings{fu2020fairness,
  title={Fairness-aware explainable recommendation over knowledge graphs},
  author={Fu, Zuohui and Xian, Yikun and Gao, Ruoyuan and Zhao, Jieyu and Huang, Qiaoying and Ge, Yingqiang and Xu, Shuyuan and Geng, Shijie and Shah, Chirag and Zhang, Yongfeng and others},
  booktitle={Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={69--78},
  year={2020}
}

@inproceedings{liu2022fairness,
  title={Fairness-aware federated matrix factorization},
  author={Liu, Shuchang and Ge, Yingqiang and Xu, Shuyuan and Zhang, Yongfeng and Marian, Amelie},
  booktitle={Proceedings of the 16th ACM Conference on Recommender Systems},
  pages={168--178},
  year={2022}
}

@article{hardt2016equality,
  title={Equality of opportunity in supervised learning},
  author={Hardt, Moritz and Price, Eric and Srebro, Nati},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{wang2017differentially,
  title={Differentially private empirical risk minimization revisited: Faster and more general},
  author={Wang, Di and Ye, Minwei and Xu, Jinhui},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{zhou2020private,
  title={Private stochastic non-convex optimization: Adaptive algorithms and tighter generalization bounds},
  author={Zhou, Yingxue and Chen, Xiangyi and Hong, Mingyi and Wu, Zhiwei Steven and Banerjee, Arindam},
  journal={arXiv preprint arXiv:2006.13501},
  year={2020}
}

@article{andrew2021differentially,
  title={Differentially private learning with adaptive clipping},
  author={Andrew, Galen and Thakkar, Om and McMahan, Brendan and Ramaswamy, Swaroop},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{pichapati2019adaclip,
  title={AdaCliP: Adaptive clipping for private SGD},
  author={Pichapati, Venkatadheeraj and Suresh, Ananda Theertha and Yu, Felix X and Reddi, Sashank J and Kumar, Sanjiv},
  journal={arXiv preprint arXiv:1908.07643},
  year={2019}
}

@article{van2018three,
  title={Three tools for practical differential privacy},
  author={van der Veen, Koen Lennart and Seggers, Ruben and Bloem, Peter and Patrini, Giorgio},
  journal={arXiv preprint arXiv:1812.02890},
  year={2018}
}

@inproceedings{
brendan2018learning,
title={Learning Differentially Private Recurrent Language Models},
author={H. Brendan McMahan and Daniel Ramage and Kunal Talwar and Li Zhang},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=BJ0hF1Z0b},
}

@article{dwork2014algorithmic,
  title={The algorithmic foundations of differential privacy.},
  author={Dwork, Cynthia and Roth, Aaron and others},
  journal={Found. Trends Theor. Comput. Sci.},
  volume={9},
  number={3-4},
  pages={211--407},
  year={2014}
}

@inproceedings{shokri2017membership,
  title={Membership inference attacks against machine learning models},
  author={Shokri, Reza and Stronati, Marco and Song, Congzheng and Shmatikov, Vitaly},
  booktitle={2017 IEEE Symposium on Security and Privacy (SP)},
  pages={3--18},
  year={2017},
  organization={IEEE}
}

@inproceedings{liu2019differentially,
  title={Differentially private recommender system with autoencoders},
  author={Liu, Xiaoqian and Li, Qianmu and Ni, Zhen and Hou, Jun},
  booktitle={2019 International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData)},
  pages={450--457},
  year={2019},
  organization={IEEE}
}

@article{mcmahan2017learning,
  title={Learning differentially private recurrent language models},
  author={McMahan, H Brendan and Ramage, Daniel and Talwar, Kunal and Zhang, Li},
  journal={arXiv preprint arXiv:1710.06963},
  year={2017}
}

@article{xie2018differentially,
  title={Differentially private generative adversarial network},
  author={Xie, Liyang and Lin, Kaixiang and Wang, Shu and Wang, Fei and Zhou, Jiayu},
  journal={arXiv preprint arXiv:1802.06739},
  year={2018}
}

@inproceedings{erlingsson2014rappor,
  title={Rappor: Randomized aggregatable privacy-preserving ordinal response},
  author={Erlingsson, {\'U}lfar and Pihur, Vasyl and Korolova, Aleksandra},
  booktitle={Proceedings of the 2014 ACM SIGSAC conference on computer and communications security},
  pages={1054--1067},
  year={2014}
}

@inproceedings{xu2018dpne,
  title={DPNE: Differentially private network embedding},
  author={Xu, Depeng and Yuan, Shuhan and Wu, Xintao and Phan, HaiNhat},
  booktitle={Pacific-Asia Conference on Knowledge Discovery and Data Mining},
  pages={235--246},
  year={2018},
  organization={Springer}
}

@article{parra2014optimal,
  title={Optimal forgery and suppression of ratings for privacy enhancement in recommendation systems},
  author={Parra-Arnau, Javier and Rebollo-Monedero, David and Forn{\'e}, Jordi},
  journal={Entropy},
  volume={16},
  number={3},
  pages={1586--1631},
  year={2014},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@inproceedings{mcsherry2009differentially,
  title={Differentially private recommender systems: Building privacy into the netflix prize contenders},
  author={McSherry, Frank and Mironov, Ilya},
  booktitle={Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={627--636},
  year={2009}
}

@inproceedings{singh2018fairness,
  title={Fairness of exposure in rankings},
  author={Singh, Ashudeep and Joachims, Thorsten},
  booktitle={Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={2219--2228},
  year={2018}
}

@inproceedings{beutel2019fairness,
  title={Fairness in recommendation ranking through pairwise comparisons},
  author={Beutel, Alex and Chen, Jilin and Doshi, Tulsee and Qian, Hai and Wei, Li and Wu, Yi and Heldt, Lukasz and Zhao, Zhe and Hong, Lichan and Chi, Ed H and others},
  booktitle={Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={2212--2220},
  year={2019}
}

@article{ge2022survey,
  title={A survey on trustworthy recommender systems},
  author={Ge, Yingqiang and Liu, Shuchang and Fu, Zuohui and Tan, Juntao and Li, Zelong and Xu, Shuyuan and Li, Yunqi and Xian, Yikun and Zhang, Yongfeng},
  journal={arXiv preprint arXiv:2207.12515},
  year={2022}
}

@inproceedings{abdollahpouri2017controlling,
  title={Controlling popularity bias in learning-to-rank recommendation},
  author={Abdollahpouri, Himan and Burke, Robin and Mobasher, Bamshad},
  booktitle={Proceedings of the eleventh ACM conference on recommender systems},
  pages={42--46},
  year={2017}
}

@inproceedings{gao2021addressing,
  title={Addressing bias and fairness in search systems},
  author={Gao, Ruoyuan and Shah, Chirag},
  booktitle={Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={2643--2646},
  year={2021}
}



@inproceedings{zhu2018fairness,
  title={Fairness-aware tensor-based recommendation},
  author={Zhu, Ziwei and Hu, Xia and Caverlee, James},
  booktitle={Proceedings of the 27th ACM International Conference on Information and Knowledge Management},
  pages={1153--1162},
  year={2018}
}

@inproceedings{chen2018investigating,
  title={Investigating the impact of gender on rank in resume search engines},
  author={Chen, Le and Ma, Ruijun and Hann{\'a}k, Anik{\'o} and Wilson, Christo},
  booktitle={Proceedings of the 2018 chi conference on human factors in computing systems},
  pages={1--14},
  year={2018}
}

@article{abdollahpouri2019unfairness,
  title={The unfairness of popularity bias in recommendation},
  author={Abdollahpouri, Himan and Mansoury, Masoud and Burke, Robin and Mobasher, Bamshad},
  journal={arXiv preprint arXiv:1907.13286},
  year={2019}
}

@inproceedings{mehrotra2018towards,
  title={Towards a fair marketplace: Counterfactual evaluation of the trade-off between relevance, fairness \& satisfaction in recommendation systems},
  author={Mehrotra, Rishabh and McInerney, James and Bouchard, Hugues and Lalmas, Mounia and Diaz, Fernando},
  booktitle={Proceedings of the 27th acm international conference on information and knowledge management},
  pages={2243--2251},
  year={2018}
}


@inproceedings{mnih2008probabilistic,
  title={Probabilistic matrix factorization},
  author={Mnih, Andriy and Salakhutdinov, Russ R},
  booktitle={Advances in neural information processing systems},
  pages={1257--1264},
  year={2008}
}

@article{chaudhuri2011differentially,
  title={Differentially private empirical risk minimization.},
  author={Chaudhuri, Kamalika and Monteleoni, Claire and Sarwate, Anand D},
  journal={Journal of Machine Learning Research},
  volume={12},
  number={3},
  year={2011}
}

@article{mcmahan2018general,
  title={A general approach to adding differential privacy to iterative training procedures},
  author={McMahan, H Brendan and Andrew, Galen and Erlingsson, Ulfar and Chien, Steve and Mironov, Ilya and Papernot, Nicolas and Kairouz, Peter},
  journal={arXiv preprint arXiv:1812.06210},
  year={2018}
}

@inproceedings{he2017neural,
  title={Neural collaborative filtering},
  author={He, Xiangnan and Liao, Lizi and Zhang, Hanwang and Nie, Liqiang and Hu, Xia and Chua, Tat-Seng},
  booktitle={Proceedings of the 26th international conference on world wide web},
  pages={173--182},
  year={2017}
}

@inproceedings{10.1145/3523227.3546767,
author = {Geng, Shijie and Liu, Shuchang and Fu, Zuohui and Ge, Yingqiang and Zhang, Yongfeng},
title = {Recommendation as Language Processing (RLP): A Unified Pretrain, Personalized Prompt \&amp; Predict Paradigm (P5)},
year = {2022},
isbn = {9781450392785},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3523227.3546767},
doi = {10.1145/3523227.3546767},
abstract = {For a long time, different recommendation tasks require designing task-specific architectures and training objectives. As a result, it is hard to transfer the knowledge and representations from one task to another, thus restricting the generalization ability of existing recommendation approaches. To deal with such issues, considering that language can describe almost anything and language grounding is a powerful medium to represent various problems or tasks, we present a flexible and unified text-to-text paradigm called “Pretrain, Personalized Prompt, and Predict Paradigm” (P5) for recommendation, which unifies various recommendation tasks in a shared framework. In P5, all data such as user-item interactions, user descriptions, item metadata, and user reviews are converted to a common format — natural language sequences. The rich information from natural language assists P5 to capture deeper semantics for personalization and recommendation. Specifically, P5 learns different tasks with the same language modeling objective during pretraining. Thus, it serves as the foundation model for various downstream recommendation tasks, allows easy integration with other modalities, and enables instruction-based recommendation. P5 advances recommender systems from shallow model to deep model to big model, and will revolutionize the technical form of recommender systems towards universal recommendation engine. With adaptive personalized prompt for different users, P5 is able to make predictions in a zero-shot or few-shot manner and largely reduces the necessity for extensive fine-tuning. On several benchmarks, we conduct experiments to show the effectiveness of P5. To help advance future research on Recommendation as Language Processing (RLP), Personalized Foundation Models (PFM), and Universal Recommendation Engine (URE), we release the source code, dataset, prompts, and pretrained P5 model at https://github.com/jeykigung/P5.},
booktitle = {Proceedings of the 16th ACM Conference on Recommender Systems},
pages = {299–315},
numpages = {17},
keywords = {Unified Model, Personalized Prompt, Recommender Systems, Natural Language Processing, Multitask Learning, Language Modeling},
location = {Seattle, WA, USA},
series = {RecSys '22}
}

@inproceedings{10.1145/3442381.3449864,
author = {Liu, Shuchang and Sun, Fei and Ge, Yingqiang and Pei, Changhua and Zhang, Yongfeng},
title = {Variation Control and Evaluation for Generative Slate Recommendations},
year = {2021},
isbn = {9781450383127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442381.3449864},
doi = {10.1145/3442381.3449864},
abstract = {Slate recommendation generates a list of items as a whole instead of ranking each item individually, so as to better model the intra-list positional biases and item relations. In order to deal with the enormous combinatorial space of slates, recent work considers a generative solution so that a slate distribution can be directly modeled. However, we observe that such approaches—despite their proved effectiveness in computer vision—suffer from a trade-off dilemma in recommender systems: when focusing on reconstruction, they easily over-fit the data and hardly generate satisfactory recommendations; on the other hand, when focusing on satisfying the user interests, they get trapped in a few items and fail to cover the item variation in slates. In this paper, we propose to enhance the accuracy-based evaluation with slate variation metrics to estimate the stochastic behavior of generative models. We illustrate that instead of reaching to one of the two undesirable extreme cases in the dilemma, a valid generative solution resides in a narrow “elbow” region in between. And we show that item perturbation can enforce slate variation and mitigate the over-concentration of generated slates, which expand the “elbow” performance to an easy-to-find region. We further propose to separate a pivot selection phase from the generation process so that the model can apply perturbation before generation. Empirical results show that this simple modification can provide even better variance with the same level of accuracy compared to post-generation perturbation methods.},
booktitle = {Proceedings of the Web Conference 2021},
pages = {436–448},
numpages = {13},
keywords = {Slate Recommendation, Generative Recommendation, Conditional Variational Auto-Encoder},
location = {Ljubljana, Slovenia},
series = {WWW '21}
}

@inproceedings{amin2019bounding,
  title={Bounding user contributions: A bias-variance trade-off in differential privacy},
  author={Amin, Kareem and Kulesza, Alex and Munoz, Andres and Vassilvtiskii, Sergei},
  booktitle={International Conference on Machine Learning},
  pages={263--271},
  year={2019},
  organization={PMLR}
}

@article{bassily2019private,
  title={Private stochastic convex optimization with optimal rates},
  author={Bassily, Raef and Feldman, Vitaly and Talwar, Kunal and Thakurta, Abhradeep},
  journal={arXiv preprint arXiv:1908.09970},
  year={2019}
}

@article{bassily2020stability,
  title={Stability of stochastic gradient descent on nonsmooth convex losses},
  author={Bassily, Raef and Feldman, Vitaly and Guzm{\'a}n, Crist{\'o}bal and Talwar, Kunal},
  journal={arXiv preprint arXiv:2006.06914},
  year={2020}
}

@inproceedings{blondel2020fast,
  title={Fast differentiable sorting and ranking},
  author={Blondel, Mathieu and Teboul, Olivier and Berthet, Quentin and Djolonga, Josip},
  booktitle={International Conference on Machine Learning},
  pages={950--959},
  year={2020},
  organization={PMLR}
}

@inproceedings{zhang2021graph,
  title={Graph Embedding for Recommendation against Attribute Inference Attacks},
  author={Zhang, Shijie and Yin, Hongzhi and Chen, Tong and Huang, Zi and Cui, Lizhen and Zhang, Xiangliang},
  booktitle={Proceedings of the Web Conference 2021},
  pages={3002--3014},
  year={2021}
}

@inproceedings{beigi2020privacy,
  title={Privacy-aware recommendation with private-attribute protection using adversarial learning},
  author={Beigi, Ghazaleh and Mosallanezhad, Ahmadreza and Guo, Ruocheng and Alvari, Hamidreza and Nou, Alexander and Liu, Huan},
  booktitle={Proceedings of the 13th International Conference on Web Search and Data Mining},
  pages={34--42},
  year={2020}
}

@inproceedings{abadi2016deep,
  title={Deep learning with differential privacy},
  author={Abadi, Martin and Chu, Andy and Goodfellow, Ian and McMahan, H Brendan and Mironov, Ilya and Talwar, Kunal and Zhang, Li},
  booktitle={Proceedings of the 2016 ACM SIGSAC conference on computer and communications security},
  pages={308--318},
  year={2016}
}

@article{yao2017beyond,
  title={Beyond Parity: Fairness Objectives for Collaborative Filtering},
  author={Yao, Sirui and Huang, Bert},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  pages={2921--2930},
  year={2017}
}

@inproceedings{zhu2020measuring,
  title={Measuring and Mitigating Item Under-Recommendation Bias in Personalized Ranking Systems},
  author={Zhu, Ziwei and Wang, Jianling and Caverlee, James},
  booktitle={Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={449--458},
  year={2020}
}

@inproceedings{liu2015fast,
  title={Fast differentially private matrix factorization},
  author={Liu, Ziqi and Wang, Yu-Xiang and Smola, Alexander},
  booktitle={Proceedings of the 9th ACM Conference on Recommender Systems},
  pages={171--178},
  year={2015}
}

@article{shin2018privacy,
  title={Privacy enhanced matrix factorization for recommendation with local differential privacy},
  author={Shin, Hyejin and Kim, Sungwook and Shin, Junbum and Xiao, Xiaokui},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={30},
  number={9},
  pages={1770--1782},
  year={2018},
  publisher={IEEE}
}

@inproceedings{Hua2015DifferentiallyPM,
  title={Differentially Private Matrix Factorization},
  author={Jingyu Hua and Chang Xia and Sheng Zhong},
  booktitle={IJCAI},
  year={2015}
}

@inproceedings{berlioz2015applying,
  title={Applying differential privacy to matrix factorization},
  author={Berlioz, Arnaud and Friedman, Arik and Kaafar, Mohamed Ali and Boreli, Roksana and Berkovsky, Shlomo},
  booktitle={Proceedings of the 9th ACM Conference on Recommender Systems},
  pages={107--114},
  year={2015}
}

@article{rendle2012bpr,
  title={BPR: Bayesian personalized ranking from implicit feedback},
  author={Rendle, Steffen and Freudenthaler, Christoph and Gantner, Zeno and Schmidt-Thieme, Lars},
  journal={arXiv preprint arXiv:1205.2618},
  year={2012}
}

@inproceedings{kamishima2011fairness,
  title={Fairness-aware learning through regularization approach},
  author={Kamishima, Toshihiro and Akaho, Shotaro and Sakuma, Jun},
  booktitle={2011 IEEE 11th International Conference on Data Mining Workshops},
  pages={643--650},
  year={2011},
  organization={IEEE}
}

@inproceedings{dwork2006calibrating,
  title={Calibrating noise to sensitivity in private data analysis},
  author={Dwork, Cynthia and McSherry, Frank and Nissim, Kobbi and Smith, Adam},
  booktitle={Theory of cryptography conference},
  pages={265--284},
  year={2006},
  organization={Springer}
}

@inproceedings{dwork2012fairness,
  title={Fairness through awareness},
  author={Dwork, Cynthia and Hardt, Moritz and Pitassi, Toniann and Reingold, Omer and Zemel, Richard},
  booktitle={Proceedings of the 3rd innovations in theoretical computer science conference},
  pages={214--226},
  year={2012}
}

@article{bagdasaryan2019differential,
  title={Differential privacy has disparate impact on model accuracy},
  author={Bagdasaryan, Eugene and Poursaeed, Omid and Shmatikov, Vitaly},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  pages={15479--15488},
  year={2019}
}

@inproceedings{cummings2019compatibility,
  title={On the compatibility of privacy and fairness},
  author={Cummings, Rachel and Gupta, Varun and Kimpara, Dhamma and Morgenstern, Jamie},
  booktitle={Adjunct Publication of the 27th Conference on User Modeling, Adaptation and Personalization},
  pages={309--315},
  year={2019}
}

@inproceedings{jagielski2019differentially,
  title={Differentially private fair learning},
  author={Jagielski, Matthew and Kearns, Michael and Mao, Jieming and Oprea, Alina and Roth, Aaron and Sharifi-Malvajerdi, Saeed and Ullman, Jonathan},
  booktitle={International Conference on Machine Learning},
  pages={3000--3008},
  year={2019},
  organization={PMLR}
}

@article{xu2020removing,
  title={Removing Disparate Impact of Differentially Private Stochastic Gradient Descent on Model Accuracy},
  author={Xu, Depeng and Du, Wei and Wu, Xintao},
  journal={arXiv preprint arXiv:2003.03699},
  year={2020}
}

@article{tran2021differentially,
  title={Differentially Private Deep Learning under the Fairness Lens},
  author={Tran, Cuong and Dinh, My H and Fioretto, Ferdinando},
  journal={arXiv preprint arXiv:2106.02674},
  year={2021}
}

@article{tran2020differentially,
  title={Differentially Private and Fair Deep Learning: A Lagrangian Dual Approach},
  author={Tran, Cuong and Fioretto, Ferdinando and Van Hentenryck, Pascal},
  journal={arXiv preprint arXiv:2009.12562},
  year={2020}
}

@inproceedings{xu2019achieving,
  title={Achieving differential privacy and fairness in logistic regression},
  author={Xu, Depeng and Yuan, Shuhan and Wu, Xintao},
  booktitle={Companion Proceedings of The 2019 World Wide Web Conference},
  pages={594--599},
  year={2019}
}

@inproceedings{ding2020differentially,
  title={Differentially private and fair classification via calibrated functional mechanism},
  author={Ding, Jiahao and Zhang, Xinyue and Li, Xiaohuan and Wang, Junyi and Yu, Rong and Pan, Miao},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34(01)},
  pages={622--629},
  year={2020}
}

@article{chang2020privacy,
  title={On the Privacy Risks of Algorithmic Fairness},
  author={Chang, Hongyan and Shokri, Reza},
  journal={arXiv preprint arXiv:2011.03731},
  year={2020}
}

@inproceedings{mozannar2020fair,
  title={Fair learning with private demographic data},
  author={Mozannar, Hussein and Ohannessian, Mesrob and Srebro, Nathan},
  booktitle={International Conference on Machine Learning},
  pages={7066--7075},
  year={2020},
  organization={PMLR}
}

@article{sengupta2021fairly,
  title={Fairly Private Through Group Tagging and Relation Impact},
  author={Sengupta, Poushali and Mishra, Subhankar},
  journal={arXiv preprint arXiv:2105.07244},
  year={2021}
}

@article{khalili2020improving,
  title={Improving Fairness and Privacy in Selection Problems},
  author={Khalili, Mohammad Mahdi and Zhang, Xueru and Abroshan, Mahed and Sojoudi, Somayeh},
  journal={arXiv preprint arXiv:2012.03812},
  year={2020}
}