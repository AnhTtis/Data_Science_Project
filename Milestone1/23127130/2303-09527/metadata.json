{
    "arxiv_id": "2303.09527",
    "paper_title": "Fairness-aware Differentially Private Collaborative Filtering",
    "authors": [
        "Zhenhuan Yang",
        "Yingqiang Ge",
        "Congzhe Su",
        "Dingxian Wang",
        "Xiaoting Zhao",
        "Yiming Ying"
    ],
    "submission_date": "2023-03-16",
    "revised_dates": [
        "2023-03-17"
    ],
    "latest_version": 1,
    "categories": [
        "cs.IR",
        "cs.CR",
        "cs.LG"
    ],
    "abstract": "Recently, there has been an increasing adoption of differential privacy guided algorithms for privacy-preserving machine learning tasks. However, the use of such algorithms comes with trade-offs in terms of algorithmic fairness, which has been widely acknowledged. Specifically, we have empirically observed that the classical collaborative filtering method, trained by differentially private stochastic gradient descent (DP-SGD), results in a disparate impact on user groups with respect to different user engagement levels. This, in turn, causes the original unfair model to become even more biased against inactive users. To address the above issues, we propose \\textbf{DP-Fair}, a two-stage framework for collaborative filtering based algorithms. Specifically, it combines differential privacy mechanisms with fairness constraints to protect user privacy while ensuring fair recommendations. The experimental results, based on Amazon datasets, and user history logs collected from Etsy, one of the largest e-commerce platforms, demonstrate that our proposed method exhibits superior performance in terms of both overall accuracy and user group fairness on both shallow and deep recommendation models compared to vanilla DP-SGD.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.09527v1"
    ],
    "publication_venue": null,
    "doi": "10.1145/3543873.3587577"
}