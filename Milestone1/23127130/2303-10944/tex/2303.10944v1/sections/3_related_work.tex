%------------------------------------------------------------------------
\section{Related Work} % 0.5-1 pages

%------------------------------------------------------------------------
\subsection{SGG with Location Supervision}
Previous methods for SGG have typically relied on two-stage architectures. The first stage consists of an object detector, often a pretrained Faster-R-CNN model~\cite{ren_faster_2016}.
The detected localized objects are used as proposals for the scene graph. The proposed objects and visual relationships between them are then classified in the second stage of the architecture, which can take the form of Iterative Message Passing~\cite{xu_scene_2017, zareian_weakly_2020}, Graph Convolutional Neural Networks~\cite{zhang_graphical_2019, lin_gps-net_2020, yang_graph_2018, wald_learning_2020, wu_scenegraphfusion_2021}, and Recurrent Neural Networks~\cite{zellers_neural_2018, tang_learning_2019}.
Lately, some works have tried to move away from this paradigm towards end-to-end approaches~\cite{teng_structured_2022, cong_reltr_2022, shit_relationformer_2022, yang_panoptic_2022}, closely integrating the generation of localized objects and their relationships. These methods are sometimes described as detection-free because they omit an explicit object detector, but they still localize the entities in the output scene graph. All of the methods mentioned above rely on location supervision in the form of bounding box labels, regardless of architectural choice.

\subsection{Weakly-Supervised Scene Graph Generation}
Recently, some works have attempted Weakly-Supervised Scene Graph Generation (WS-SGG), omitting the costly location labels in their training. Zareian et al. (VSPNet~\cite{zareian_weakly_2020}) take object proposals from a pretrained object detector, build them into a semantic bipartite graph as a different formulation of a scene graph and classify and refine the entities through message passing. Shi et al.~\cite{shi_simple_2021} use a weakly-supervised graph matching method to match object proposals from a pretrained object detector to the ungrounded scene graph labels. This matching generates a localized scene graph as a pseudo-label to train conventional fully-supervised SGG methods. Other methods utilize natural language from image captions as a weak supervision source, matching linguistic structures to object proposals~\cite{zhong_learning_2021, ye_linguistic_2021, li_integrating_2022}.

We argue that the reliance of the WS-SGG methods mentioned above on pretrained object detectors is still a major limitation. While this approach does not require location labels in the scene graph datasets itself, a dataset from the same domain that contains location labels for all relevant objects is still required to pretrain the object detector. Shi et al.~\cite{shi_simple_2021} notice a considerable domain gap for the detector pre-training. This manifests in subpar performance if Faster-R-CNN is pretrained on Open Images~\cite{kuznetsova_open_2020} and applied to Visual Genome data, although both contain natural images. This issue becomes even more apparent when SGG is attempted in domains where large-scale image datasets are not readily available, such as the medical domain~\cite{ozsoy_4d-or_2022}. We therefore aim to enable Scene Graph Generation without the use of pretrained object detectors to eliminate the need for location supervision completely.

The methods mentioned in this section output localized scene graphs without training on location labels and are therefore considered weakly supervised. While our suggested LF-SGG task also does not include location labels, it further works without an intermediate generation of localized scene graphs. We, therefore, do not consider LF-SGG weakly supervised.

\subsection{Scene Graph Matching}

Fully Supervised location-based Scene Graph Generation methods rely on the location to match scene graph nodes of prediction and ground truth for evaluation by simply thresholding bounding box IoU~\cite{xu_scene_2017}. When location-free (ungrounded) scene graphs are used, this simple solution for graph matching is no longer available.
The WS-SGG methods shown in the previous section also address some graph-matching problems. VSPNet~\cite{zareian_weakly_2020} aligns their predicted semantic bipartite graph with the ground truth with an iterative optimization algorithm. Shi et al.~\cite{shi_simple_2021} leverage the simple and efficient Hungarian matching algorithm~\cite{kuhn_hungarian_1955} to find a first-order graph matching of node to node without considering graph structure. Both of these approaches, however, can rely on visual features extracted from the used object detector to find a strong node-to-node similarity. In ungrounded scene graphs, such as in LF-SGG, visual features are no longer available. We, therefore, introduce a new scene graph matching algorithm that is capable of matching scene graphs purely based on node labels, edge labels, and graph structure by heuristic tree search.
%------------------------------------------------------------------------
\subsection{Autoregressive Decoding}
Previous SGG methods generally leverage object proposals to initialize a scene graph. Direct prediction of ungrounded scene graphs at once from an image without this intermediary step requires an exceedingly complex output vector. This could impede training and lack the potential to model the interdependencies between the entities and relations of the scene graph. 

We, therefore, look at autoregressive decoding, which allows a model to make multiple predictions from one data object sequentially. Given the similarity of scene graphs to texts regarding grammatical and semantic structure, we take inspiration from natural language processing (NLP).
Transformers and Autoregressive Decoding have enabled great progress in this domain lately~\cite{devlin_bert_2019, alayrac_flamingo_2022, brown_language_2020}. Chen et al. (Pix2Seq~\cite{chen_pix2seq_2022}) showed that autoregressive decoding could also be used successfully with images for object detection. We argue that we can leverage the advantages of Autoregressive Decoding even more so in the field of SGG, as there are interdependencies in the semantic structure of the scene graph, which can profit from more congruent sequential predictions. We introduce Pix2SG, a model featuring autoregressive sequence decoding for LF-SGG.\looseness=-1

