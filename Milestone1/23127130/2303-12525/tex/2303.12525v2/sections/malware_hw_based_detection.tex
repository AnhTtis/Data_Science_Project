\section{Hardware-based Malware Detection Basics}
\label{sec:hw_based_detection_app}

This section focuses on \gls{HMD} techniques, outlining their key components. 

\subsection{Hardware events and performance counters}
\label{subsec:hw_events_perf_count}

Modern processors have units to monitor hardware events. In 2002, Sprunt \cite{Sprunt_2002} published a seminal paper on the basics of \glspl{PMU}. These units were developed to collect data about the performance of applications, operating systems, and processors and to help programmers tune algorithms and codes. Software dynamically adjusted to resource utilization would also benefit from the information collected. The proven advantages of utilizing the \glspl{PMU}, the continuous improvements of these units, and their constant spreading among different devices have led to their leverage for safety and security purposes~\cite{Dutto:2021aa,Kasap:2023aa,Carelli:2018aa,Carelli:2019aa}.

Nowadays, \glspl{PMU} can monitor several hardware events (see Figure \ref{fig:HW_events_counters}). Complex devices like high-end processors have hundreds of events to monitor. These events include retired instructions (branches, load, store, etc.), branch predictions, cache hits and misses, floating-point operations, hardware interrupts, elapsed core clock ticks, core frequency, and temperature. However, to minimize hardware complexity, only a few \glspl{HPC} (e.g., 2 to 8 in high-end processors) are generally available, thus limiting the number of parallel events that can be monitored. Each \gls{HPC} has an event detector and an associated counter \cite{Doyle_2017}.

\Figure[htb]()[width=0.98\columnwidth]{Figures/HW_events_counters}
   {Hardware events and performance counters in a processor. Elaborated by the author. \label{fig:HW_events_counters}}

\subsection{Hardware-based detection framework}
\label{subsec:hardware-based_detection_framework}

A generic framework can be a guiding structure to facilitate the implementation of \gls{HMD}, as illustrated in Figure \ref{fig:generic_hardware-based_framework}. The framework leverages the existing \gls{PMU} within the processor and consists of two primary components: (i) data collection and preprocessing and (ii) malware detection. This section provides a detailed overview of the implementation process.

\Figure[htb]{Figures/generic_hardware-based_framework}
   {A generic hardware-based detection framework. Elaborated by the author. \label{fig:generic_hardware-based_framework}}
   
Data collection involves \gls{FE} and \gls{FS} \cite{Abdulwahab_2022, Chandrashekar_Sahin_2014}. \gls{FE} captures and stores \glspl{HPC} in a vector space, enabling the \gls{FS} to select a subset that efficiently describes the input data while minimizing noise and irrelevant variables, ensuring optimal prediction results. \gls{FE} can occur in the time or event domain \cite{Sprunt_2002}. In the time-based domain, the application execution is periodically interrupted to record \gls{HPC} values. Conversely, the event domain triggers interruptions based on specific events or a set number of executed instructions rather than regular intervals.

In terms of strategies to perform \gls{FE}, we envision four alternatives: (i) instrument the source code with the employment of a library, like \texttt{PAPI} \cite{PAPI_1999}; (ii) develop of a proprietary kernel module or driver, as performed in \cite{Tang_2014}; (iii) use of an available utility that performs tasks mainly in the \gls{OS} kernel, like \texttt{PERF} \cite{PERF_2009}; and (iv) use of a micro-architectural simulator to model the processor as it executes the application, like \texttt{gem5} \cite{Binkert_2011} and \texttt{GVSoC} \cite{Bruschi_2021}.

During \gls{FE}, the sampling strategy is crucial. In the time-based domain, parameters such as period, frequency, or number of cycles determine when \glspl{HPC} are sampled. In the event-based domain, sampling depends on the number of event or instruction occurrences. The chosen \gls{FE} strategy influences these definitions. A proprietary kernel module or driver allows programmers to choose between time-based or event-based domains, set parameters for sampling triggering, and specify values. However, configurations are limited when libraries like \texttt{PAPI} and \texttt{PERF} are used.
Regarding sampling values, in time-based sampling, there is no fixed ideal period or frequency, varying based on the experiment and goal. Hardware-based detection experiments typically use periods in the order of milliseconds or seconds. Striking a balance between low and high sampling frequencies is essential, considering the trade-off between computational processing, data quantity, and system effects.

\gls{FS} offers multiple advantages, including addressing the Curse of Dimensionality in \gls{ml} \cite{Goodfellow_2016}, enhancing data understanding, reducing computation requirements, and improving predictor performance. Filter-based algorithms dominate the \gls{FS} in the \gls{HMD} field, ranking features based on a scoring criterion, using a threshold for variable selection. They are valued for simplicity and practical application success, focusing on the relevancy of features. Prominent methods include \gls{PCA} (used by \cite{Zhou_2018, Sayadi_2019, Gao_2021, Sayadi_2021}), Fisher Score \cite{Duda_2000} (used by \cite{Tang_2014, Torres_Liu_2022}), Pearson Correlation Coefficient \cite{Pearson_1895} (used by \cite{Patel_2017, Sayadi_2018, Sayadi_2019, Gao_2021, Sayadi_2021}) and Information Gain (Mutual Information) \cite{Peng_2005} (used by \cite{Singh_2017, Kwan_2020}). The Scikit-learn \cite {Scikit-learn} library for the Python and Weka \cite{Frank:2005aa} are tools frequently used in the \gls{HMD} field for \gls{FS}.

Since the number of events that can be potentially monitored exceeds the available \glspl{HPC}, some studies (for example, \cite{Patel_2017, Malone_2011, Khasawneh_2015}) also perform a preliminary manual \gls{FS} before data collection, thus reducing the number of software executions required to collect data. The selection is based on architectural and micro-architectural knowledge and other studies.

Eventually, in \gls{HMD}, \gls{ml} algorithms play a crucial role. Supervised and unsupervised learning techniques are employed in hardware-based malware detection. While for supervised detection, both benign and malignant samples, adequately annotated, are necessary, in unsupervised malware detection, the classifier is trained only with benign applications to perform anomaly detection \cite{Chandola_2009}. Unsupervised detection has two exciting advantages: (i) it does not require a malware dataset for training, and (ii) the classifier can detect zero-day malware~\cite{He:2021aa}. On the other side, unsupervised algorithms are complex, requiring more sophisticated analysis and resulting in complex hardware implementations.

%For the first time, Tang et al. \cite{Tang_2014} showed the feasibility of unsupervised techniques for hardware-based malware detection. In the following year, Garcia-Serrano \cite{Garcia-serrano_2015} also investigated the application of unsupervised technique, trying to simplify the approach of Tang et al.

Several traditional classification algorithm families are employed in \gls{HMD}: linear regression (LinearRegression and SimpleLinearRegression), logistic regression (Logistic and SimpleLogistic), Bayesian network (BayesNet and NaiveBayes), decision trees (J48 and REPTree), rule-based (JRIP, OneR and PART), \gls{ann} (MultiLayerPerceptron), \gls{KNN} (IBk), ensemble learning (AdaBoostM1, Bagging and RandomForest) and \gls{SVM} (SMO) \cite{Goodfellow_2016}. The algorithms in parentheses refer to specific Weka implementations, which are commonly used in the context of \gls{HMD}. Further details on these families and their implementations in Weka can be found in \cite{Frank:2005aa}.

Eventually, a crucial consideration is the trade-off between monitoring more events for better application characterization and detector performance and the impact on runtime applicability. Some studies used many events, exceeding available \glspl{HPC}, necessitating multiple application runs \cite{Demme_2013, Singh_2017, Sayadi_2017}. This trade-off is further addressed in \gls{ml} solutions discussed in Section \ref{subsec:machine_learning_techniques}.