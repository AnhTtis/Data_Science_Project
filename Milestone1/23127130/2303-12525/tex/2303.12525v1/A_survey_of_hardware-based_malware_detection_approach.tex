\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{amsmath,amssymb,amsfonts,mathtools}
\usepackage{algorithmic}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{makecell}
\usepackage{array,multirow,graphicx}
\usepackage{comment}
\usepackage{hyperref}
\usepackage{xcolor}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{A survey of hardware-based \\ malware detection approach\thanks{This work was partially supported by project SERICS (PE00000014) under the MUR National Recovery and Resilience Plan funded by the European Union - NextGenerationEU and by the Vitamin-V project (Project number: 101093062) funded by the European Union. Views and opinions expressed are, however, those of the author(s) only and do not necessarily reflect those of the European Union or the HaDEA. Neither the European Union nor the granting authority can be held responsible for them.}}

\author{\IEEEauthorblockN{Cristiano Pegoraro Chenet}
\IEEEauthorblockA{\textit{Control and Computer Eng. Dep.} \\
\textit{Politecnico di Torino}\\
Torino, Italy \\
ORCID: 0000-0003-3974-9310}
\and
\IEEEauthorblockN{Alessandro Savino}
\IEEEauthorblockA{\textit{Control and Computer Eng. Dep.} \\
\textit{Politecnico di Torino}\\
Torino, Italy \\
ORCID: 0000-0003-0529-7950}
\and
\IEEEauthorblockN{Stefano Di Carlo}
\IEEEauthorblockA{\textit{Control and Computer Eng. Dep.} \\
\textit{Politecnico di Torino}\\
Torino, Italy \\
ORCID: 0000-0002-7512-5356}
}

\maketitle

\begin{abstract}
Malware is the most significant threat to computer security. This paper aims to overview the malware detection field, focusing on the recent and promising hardware-based approach. This approach leverages the Hardware Performance Counters already available in modern processors and the power of Machine Learning, offering attractive advantages like resilience to disabling the protection, resilience to unknown malware, low complexity/overhead/cost, and run-time detection. The approach is deeply analyzed in light of a generic hardware-based detection framework. Some challenges related to the approach are presented: the necessary accuracy improvements, how to deal with the classification error, better correlating the hardware events behavior with the malware, and essential improvements on the hardware performance monitor.
\end{abstract}

\begin{IEEEkeywords}
Cybersecurity, malware, hardware-based detection, hardware-based framework
\end{IEEEkeywords}

\section{Introduction}

\begin{comment}
    \begin{itemize}
        \item A brief introduction of the context. Here you must introduce the following elements (the order is not necessarily the one mentioned here)
        \begin{itemize}
        \item What is a malware
        \item Which kind of systems are in danger today (or we want to consider in this review)
        \item What kind of risks (attacks) derive from malware
        \item A taxonomy of malware
        \end{itemize}
        \end{itemize}
\end{comment}

Malware is the most significant threat to computer security. Acronym for malicious software, malware is any code added, changed, or removed from a software system to intentionally cause harm or subvert the intended function of the system \cite{McGraw_Morrisett_2000}. The problem represented by the malware was first analyzed in the scientific community by Fred Cohen in 1987 \cite{Cohen_1987}, coinciding with the increase in data sharing due to the developing computer networks. In an allusion to biological processes, the paper discussed the primary attack mechanisms and the protection possibilities regarding computer viruses.

Any computing system is susceptible to malware since any running software may be attacked: personal computers, mobile phones, the internet of things and 5G devices, cyber-physical systems that control critical infrastructures (such as power grids), and enterprise-wide systems used by businesses or governments. The growing complexity and size of modern systems, possibly measured by an ever-increasing number of lines of code, contribute to the concern with malware. The high number of bugs, unsafe programming languages (like C and C++), improper configuration, and facility to hide or mask malicious code represent potential vulnerabilities for the attackers. Besides this, the growing connectivity of all these computer systems through the Internet increases the security problem and makes all devices possible targets for attackers. 

Some practical examples of malware attacks are: spying on a device in a not allowed form, launching annoying pop-up advertisements, sending emails from an account without the knowledge of the owner, harming the system from the inside, hijacking the information until the payment of a ransom, slowing down a computer, replace a web page in the browser and the control by the attacker of sensitive information (like bank details, credit card number, personal data and even injure information). The consequences from successful attacks can be generally classified into four groups according to \cite{Stallings_Brown_2014}:

    \begin{itemize}
    \item \textbf{Unauthorized disclosure}: a not authorized entity gains access to data;
    \item \textbf{Deception}: an authorized entity receives false data believing it to be true;
    \item \textbf{Disruption}: an event that interrupts or prevents the correct operation of system services and functions;
    \item \textbf{Usurpation}: an event that results in unauthorized control of system services or functions.
    \end{itemize}

The cybercrimes performed using malware nowadays have substantial implications for the institution's finances. According to the 2022 Cybersecurity Almanac published by Cisco and Cybersecurity Ventures \cite{cybersecurity_almanac_2022}, global cybercrime costs will reach \$10.5 trillion annually by 2025, the advertisement industry will lose \$100 billion annually in 2023 with digital advertisement fraud, and ransomware will cost its victims around \$265 billion (USD) annually by 2031.

Knowing the malware taxonomy is a way to understand it better. Malware is categorized according to the propagation method and the purpose/working way. Viruses, worms, and trojan horses are categories based on the propagation method, composing the canonical examples of malware. The remaining categories refer to their purpose/working way and can relate to one or more canonical types. Categorizing malicious code has increasingly become more complex as newer versions appear to be combinations of those that belong to existing categories. Here are summarized the main categories:

    \begin{itemize}
    \item \textbf{Viruses}: malicious code that propagates by inserting itself into other programs \cite{McGraw_Morrisett_2000, Christodorescu_2007};
    \item \textbf{Worms}: malicious code that propagates across the network \cite{McGraw_Morrisett_2000,Christodorescu_2007};
    \item \textbf{Trojan horses}: malicious code that  masquerade as useful program \cite{McGraw_Morrisett_2000,Christodorescu_2007};
    \item \textbf{Spywares}: malicious code that is secretly or surreptitiously installed into an information system to transmit private user data to an external entity \cite{Christodorescu_2007,NIST_Glossary_2023};
    \item \textbf{Adwares}: malicious code that displays computer advertisement. Its basic purpose is to get financial benefits;
    \item \textbf{Ransomwares}: malicious code that attempts to deny access to a user’s data, usually by encrypting the data with a key known only to the hacker who deployed the malware, until a ransom is paid \cite{NIST_Glossary_2023};
    \item \textbf{Back doors}: malicious code that opens the system to external entities by subverting the local security policies to allow remote access and control over a network \cite{NIST_Glossary_2023};
    \item \textbf{Keyloggers}: malicious code designed to record which keys are pressed on a computer keyboard used to obtain passwords or encryption keys and thus bypass other security measures \cite{NIST_Glossary_2023};
    \item \textbf{Botnets}: the word comes from “robot” and “network.” It consists of a piece of malicious code (bot) that infects a set of computers and gets orders from a remote criminal (master) \cite{NIST_Glossary_2023,ENISA_Botnets_2023};
    \item \textbf{Rootkits}: set of malicious applications used by an attacker after gaining root-level access to a host to conceal the attacker’s activities and permit the attacker to maintain root-level access to the host through covert means \cite{NIST_Glossary_2023}.
    \end{itemize}

The threat represented by this vast diversity of malware must be minimized, and malware detection is the first step forward. This paper aims to overview the malware detection field, focusing on the recent and promising hardware-based approach. It is organized as follows. Section \ref{sec:malware_detection} presents an overview of malware detection approaches and analysis techniques. Section \ref{sec:hw_based_detection_app} discusses the state-of-the-art on hardware-based malware detection approach. Section \ref{sec:conclusion} presents the conclusions and research challenges.

\section{Malware detection overview}
\label{sec:malware_detection}
\begin{comment}
    Here you have to discuss the different techniques you can use for Malware detection. It is essential that at the end of this section, it is clear why there is a need for hardware-based methods to justify this paper.
\end{comment}

Until 2013, malware detection was purely based on software, and antivirus software is yet the most common protection. Antivirus uses known detection approaches to detect and remove several malware categories besides viruses. In 2013, Demme et al. \cite{Demme_2013} proved the feasibility of the then-innovative detection approach based on hardware, which exploits the behavior of performance counters. \autoref{fig:overview_malware_detection_approaches} gives an overview of the contemporary malware detection approaches, including the hardware-based possibility.

\begin{figure}[htb]
\centerline{\includegraphics[width=\columnwidth]{Overview_malware_detection_approaches}}
\caption{Overview of the contemporary malware detection approaches. Elaborated by the author based on \cite{Aslan_Samet_2020}.}
\label{fig:overview_malware_detection_approaches}
\end{figure}

There are a considerable number of detection approaches based on software \cite{Aslan_Samet_2020}. The three most common are addressed here:

    \begin{itemize}
    \item \textbf{Signature-based}: the signature is a malware feature that uniquely encapsulates the program structure and identifies each malware. This is the approach widely used within commercial antivirus. The detection works as follows: features extracted from the executable generate a signature which is stored in a signature database; when a sample program needs to be marked as malware or benign, the signature of the related sample is compared with signatures on the database; based on the comparison, the sample program is marked as malware, or benign \cite{Aslan_Samet_2020};
    \item \textbf{Behaviour-based}: it observes the program behaviors with monitoring tools and determines whether the program is malware or benign. The following procedures are used to determine the behavior: automatic analysis by using sandbox; monitoring of system calls; tracking of file changes; comparison of registry snapshots; monitoring network activities, and process monitoring. The detection works as follows: a dataset is built based on one of the procedures above; then, specific features from the dataset are obtained and classification done by using Machine Learning (ML) algorithms \cite{Aslan_Samet_2020};
    \item \textbf{Heuristic-based}: a complex detection method that uses experiences and techniques such as rules and ML. It is accomplished in two phases: in the first, the detector system must be trained with normal and abnormal data to capture characteristics of interest; the second is the monitoring or detection phase, where the trained detector makes intelligent decisions about new samples \cite{Aslan_Samet_2020,Alzarooni_2012}.
    \end{itemize}

The protection against malware can also be classified according to the malware analysis technique, the process of determining the malware's functionality and answering questions like how malware works, which machines and programs are affected, which data is being damaged and stolen, etc. There are mainly three techniques to analyze malware: static, dynamic, and hybrid \cite{Idika_Mathur_2007}. Static uses syntax or structural properties of the program/process (e.g., sequence of bytes) and, in general, attempts to detect malware before the program under inspection executes. Dynamic analysis is more sophisticated and attempts to detect malicious behavior during or after program execution, leveraging runtime information. The hybrid one combines the two approaches.

The protection by hardware proposed by Demme et al. in 2013 \cite{Demme_2013} is a behavioral approach based on a dynamical analysis of micro-architectural events of the system. These events, registered by the Hardware Performance Counters (HPCs), are analyzed by ML classification algorithms to distinguish between malicious and benign programs.

Some fundamental differences between software and hardware-based malware detections turn the research community's attention toward the hardware approach. Three fundamental points differentiate the methods \cite{Demme_2013}:

    \begin{itemize}
    \item \textbf{Resilience to disabling the protection}: the antivirus used on software-based detection are themselves software, bugs or oversights on them or underlying system software can be exploited to attack and disable the protection. In hardware-based detection, secure hardware (with minimum reliance on system software) significantly reduces the possibility of malware subverting the protection mechanisms;
    \item \textbf{Resilience to code variants and unknown malware}: the static technique analysis employed on most software-based production antivirus is insufficient to detect unknown malware and can be easily subverted by many different code variants functionally equivalent. The dynamic analysis used on a hardware-based approach makes the detection of code variants and unknown malware easier;
    \item \textbf{Complexity/overhead/cost}: dynamic software analysis (alternative to static technique analysis) requires sophisticated computation, often at the cost of significant overhead. Also, the increasing software size makes parsing difficult. Conversely, the HPCs used on the hardware-based approach are often already available in modern processors (no redesign effort), considerably reducing the cost/overhead analysis.  
    \end{itemize}

The problem of the computational overhead imposed by the software-based detection approach was probably already observed by many computer users with antivirus software installed on the operating system. When the antivirus scans, the computational overhead frequently makes the user experience a slowdown in the applications, sometimes even making usability unfeasible. Another advantage of the hardware-based detection approach is the possibility of run-time detection, needing just a few clock cycles or seconds/milliseconds to find the threat.

\section{Hardware-based detection approaches}
\label{sec:hw_based_detection_app}
\begin{comment}
    Here is where you have to review hardware-based techniques.
\end{comment}

The intuition that malware can be detected based on HPCs comes from the idea that programs have a phase behavior \cite{Sherwood_2003,Isci_2006}. Programs perform one activity A for a while, then switch to activity B, then to activity C, possibly repeating some phases. These phases often correspond to patterns in architectural and micro-architectural events. Another important property is that the program phases differ radically between programs. These enable differentiating programs based on time-behavioral patterns of the HPCs, thus allowing the distinction between malicious and benign applications.

\autoref{fig:generic_hardware-based_framework} presents a generic hardware-based detection framework. Its primary goal is to differentiate applications between benign and malicious. The framework can be viewed as three basic blocks: (i) the processor with its HPCs, (ii) the data collection process, and (iii) the malware detection itself, made by a ML classifier. The evaluation of the detector is made considering performance. This section presents an in-depth overview of the hardware-based detection approaches in light of this framework.

\begin{figure*}[!t]
\centerline{\includegraphics{generic_hardware-based_framework}}
\caption{A generic hardware-based detection framework and its evaluation. Elaborated by the author.}
\label{fig:generic_hardware-based_framework}
\end{figure*}

\subsection{Hardware events and performance counters}
\label{subsec:hw_events_perf_count}
The complexity of processors has enormously increased over the last decades. Hierarchical cache subsystems, non-uniform memory, simultaneous multithreading, and out-of-order execution significantly impact the performance and computing capacity. Software that understands and dynamically adjusts to resource utilization has performance and efficiency advantages. In this way, modern processors have units to monitor architecture and micro-architecture events, like retired instructions (branches, load, store, etc.), branch predictions, cache hits and misses, floating-point operations, hardware interrupts, elapsed core clock ticks and core frequency. Many of these events may be monitored (sometimes more than 100 for high-performance devices), but the processors have few registers to store them (for example, from 2 to 8). Therefore, few HPCs are available at one time. This limitation is due to the design complexity and cost of concurrent monitoring of events \cite{Sprunt_2002,Malone_2011,Doyle_2017}. Deep pipelines, complex prefetchers, branch predictors, modern cache design, etc., impose a challenge to add HPCs, considering counting multiple events and maintaining counter accuracy simultaneously under speculative execution \cite{Sprunt_2002,Sayadi_2018}. In mobile and internet of things devices, the limitation in the number of HPCs is even more significant, given the strict resource constraint characteristics of these domains.

When considering malware detection using performance counters, the trade-off between the number of hardware events and the detection accuracy is critical. The greater the number of events analyzed, the better the application characterization and the detector's accuracy. To achieve reasonable accuracy, some works used many events (e.g., 16 or 32), more than the number of HPCs available in the processor, requiring running the application multiple times \cite{Demme_2013,Singh_2017,Sayadi_2017}. This factor is critical because it limits the run-time applicability of hardware-based malware detection. To compensate for the worse application characterization due to the fewer events analyzed, \cite{Sayadi_2018,Sayadi_2019} propose improvements in the ML classifier. These works will be addressed deeper in \autoref{subsec:mal_det_process}, but the attempts offer some advantages in improving accuracy. 

\subsection{Data collection process}
\label{subsec:data_col_process}
The data collection process is composed of the selection of events, feature extraction, and feature reduction. For those without a background in the machine/deep learning field, these three concepts may not be trivial, and thus we will define them here, considering the context of the hardware-based detection approach. To facilitate the understanding, they can be thought of in the sequence (chronological) they appear on the framework detector (\autoref{fig:generic_hardware-based_framework}). 

    \begin{itemize}
    \item \textbf{Selection of events}: a choice between the several hardware events available in the processor to be considered in the malware detector;
    \item \textbf{Feature extraction}: the capture and storing in a vector space of the registered HPCs to be analyzed by the ML model;
    \item \textbf{Feature reduction}: also called reduction of dimensions, is a data processing to deal with the Curse of Dimensionality. The \textbf{Curse of Dimensionality} is a problem in ML because models in a high-dimensional space have lower detection rates than models in lower-dimensional spaces \cite{Goodfellow_2016}. The redundant dimensions in high dimensions contribute to the measurement of noise in the training dataset, which decreases the detection rates of testing.
    \end{itemize}

The definitions proposed here clearly distinguish between the whole process (data collection), the processes involving the architecture and micro-architecture hardware events, and the processes affecting the HPCs.

The selection of events and feature reduction aims to select the most relevant/predictive data for malware detection. Since the number of hardware events available in the processors is at most in the range of a few hundred, it is possible to perform the selection of events in the manual form through the empirical knowledge of the representation of each event in the architecture and micro-architecture, or even based on other studies. However, in some cases, the researchers need this information and start collecting all the hardware events available in the processor, generating big data. In this case, that is also the case of feature reduction, the mentioned manual analysis is not possible, and it is necessary to use some feature selection technique. Some examples of these techniques commonly used are Principal Component Analysis (PCA), Fisher Score \cite{Duda_2000}, Pearson Correlation Coefficient \cite{Pearson_1895} based-techniques, and Information Gain (also called Mutual Information) \cite{Peng_2005}.

A feature extraction characteristic is the sampling period of the HPC. There is no rule for this value, but in the hardware-based detection experiments, they generally remain in the order of milliseconds or seconds or even as processor cycles multiples or instruction epochs multiples.

\subsection{Malware detection process}
\label{subsec:mal_det_process}

ML classifiers help automate tasks that previously had to be done manually. After training with input data, they can automatically order or categorize data into one or more classes (since the training and tested data have similar statistical distribution). In malware detection, classifying a program as benign or malicious is just an example of a task that classifiers can perform.

The classifiers are categorized based on the mathematical formula/algorithms they implement. Each type delivers different results across various metrics, including performance, efficiency, and hardware design overhead. Also, specifically in the case of malware detection, the classifiers perform differently across the different malware categories. Therefore, studies in this field sometimes choose a set of classifiers to discover the best classifier for their experiment. The \autoref{tab:overview_classifiers_employed} shows an overview of the classifier relevant studies employ.

\begin{table}[htbp]
\caption{Overview of ML classifiers types employed by relevant studies on hardware-based detection. Compilation elaborated by the author.}
\begin{center}
\begin{tabular}{ | m{3cm} | m{1.5cm}| m{3cm} | } 
  \hline
  \textbf{\makecell{ML classifier type}} & \textbf{\makecell{Study}} & \textbf{\makecell{ML classifier subtype}} \\ 
  \hline
  \hline
  \makecell{Neural Network (NN)} & \makecell{\cite{Zhou_2018} \cite{Sayadi_2019} \\ \cite{Sayadi_2022} \cite{Patel_2017}} & \makecell{Multilayer perceptron \\ (MLP)} \\ 
  \hline
  \makecell{Generalized Linear Models} & \makecell{\cite{Sayadi_2019} \cite{Sayadi_2022} \\ \cite{Patel_2017} \cite{Patel_2017}} & \makecell{Logistic Regression \\ (LR), Multinomial Logistic \\ Regression (MLR), \\ Simple Logistic, \\ Linear Discriminant \\ Analysis (LDA)} \\ 
  \hline
  \makecell{Decision Trees} & \makecell{\cite{Demme_2013} \cite{Singh_2017} \cite{Zhou_2018} \\ \cite{Sayadi_2019} \cite{Sayadi_2022} \cite{Patel_2017}} & \makecell{J48, PART} \\ 
  \hline
  \makecell{Rule-based} & \makecell{\cite{Sayadi_2019} \cite{Patel_2017}} & \makecell{JRIP, OneR} \\ 
  \hline
  \makecell{Bayesian Methods} & \makecell{\cite{Singh_2017} \cite{Zhou_2018} \\ \cite{Sayadi_2022} \cite{Patel_2017} } & \makecell{BayesNet, NaiveBayes, \\ Gaussian NaiveBayes} \\ 
  \hline
  \makecell{Support Vector \\ Machines (SVM)} & \makecell{\cite{Tang_2014} \cite{Singh_2017} \\ \cite{Sayadi_2022} \cite{Torres_2022} \cite{Patel_2017}} & \makecell{One-class Support Vector \\ Machine (OC-SVM), \\ Two-class Support  Vector \\ Machine (TC-SVM), \\ Sequential minimal \\ optimization (SMO)} \\ 
  \hline
  \makecell{K-Nearest \\ Neighbors (KNN)} & \makecell{\cite{Demme_2013} \cite{Zhou_2018} \cite{Sayadi_2022}} & \makecell{-} \\ 
  \hline
  \makecell{Ensemble Learning} & \makecell{\cite{Demme_2013} \cite{Sayadi_2018} \cite{Zhou_2018} \\ \cite{Zhou_2018} \cite{Sayadi_2019} \cite{Sayadi_2022}} & \makecell{Bagging (Bootstrap \\ Aggregation), Boosting \\ (AdaBoost), \\ Random Forest} \\ 
  \hline
  \makecell{Artificial Neural \\ Network (ANN)} & \makecell{\cite{Demme_2013}} & \makecell{-} \\ 
  \hline
  \makecell{Convolutional Neural \\ Network (CNN)} & \makecell{\cite{Sayadi_2022}} & \makecell{-} \\ 
  \hline
  \makecell{Stockastic Gradient \\ Descent (SGD)} & \makecell{\cite{Patel_2017}} & \makecell{-} \\ 
  \hline
  \makecell{Restricted Boltzmann \\ Machine (RBM)} & \makecell{\cite{Sayadi_2022}} & \makecell{-} \\ 
  \hline
  \makecell{Long Short-Term Memory \\ Network (LSTMN)} & \makecell{\cite{Sayadi_2022}} & \makecell{-} \\ 
  \hline
\end{tabular}
\label{tab:overview_classifiers_employed}
\end{center}
\end{table}

Sayadi et al. \cite{Sayadi_2018} propose using Ensemble Learning techniques to improve the accuracy of hardware-based-malware detectors. Ensemble Learning is a branch of ML in which the final decision is a combination of a set of base learners. It fully exploits complementary information of different classifiers to improve decision accuracy and performance. Considering the trade-off mentioned in the \autoref{subsec:hw_events_perf_count}, between the number and diversity of hardware events analyzed and the detection accuracy, they claim classifiers based on Ensemble Learning can enable the use of a minimal number of hardware events for the run-time malware detection. The authors deploy and analyze two Ensemble Learning methods, Boosting (AdaBoost implementation \cite{Freund_Schapire_1997}) and Bagging (Bootstrap Aggregation) \cite{Breiman_1996}. They compared eight general ML classifiers and two Ensemble Learning classifiers, also considering a different number of HPCs (16, 8, 4, and 2). They reported positive results that sometimes reduce the number of HPCs to 2 or 4. Thanks to Ensemble Learning techniques, they achieve a higher or similar accuracy level to 8/16 HPCs models. Despite this, just one significant gain was observed with the addition of the Ensemble Learning technique. A case in which a specific classifier (REPTree) achieves close to 88\% accuracy with 16 HPCs and preserves the same accuracy when reducing the number of vital performance counters to 2 (in this last case using classifiers with AdaBoost Ensemble Learning technique).

Another work from Sayadi et al. \cite{Sayadi_2019} also focused on the accuracy improvement of the detectors. They proposed a run-time detector with a complex classifier, a specialized two-stage. The first stage classifies applications using a Multinomial Logistic Regression (MLR) technique into either benign or one malware class (Virus, Rootkit, Backdoor, and Trojan). The second stage deploys a ML model that works best for each type of malware, using the AdaBoost Ensemble Learning technique. The general classifiers used to build AdaBoost are from different branches of ML: Regression, Neural Network, Decision Tree, and Rule-based. They compared the accuracy improvement in a scenario from 8 performance counters to 4 Boosted performance counters and in a second scenario from 4 performance counters to 4 Boosted performance counters. They found a significant accuracy increase in most cases, showing the solution's effectiveness.

The high number of studies using Ensemble Learning techniques (\autoref{tab:overview_classifiers_employed}) and these studies from Sayadi et al. \cite{Sayadi_2018,Sayadi_2019} indicate the increasing complexity of classifiers as a way to accuracy improvement. The employment of Ensemble Learning techniques (more complex than general classifiers) and classifiers specialized for each malware category justify this direction. 

The feasibility of using unsupervised ML on hardware-based detectors was investigated for the first time by Tang et al. \cite{Tang_2014}. The idea comes from the anomaly-based detection approach. It is possible to build baseline models of benign program execution and use these profiles to detect deviations due to malware exploitation. They modeled per-program baseline characteristics for Internet Explorer 8 and Adobe PDF Reader 9 (common vulnerable programs) and reached an accuracy level up to 90\% and 99.9\%, respectively.  

\subsection{Performance Evaluation}
\label{subsec:perf_evaluation}

The detection performance is crucial in determining the adoption of a hardware-based malware detection approach. This is one of the main reasons why the data collection process and the malware detection process are deeper studied by the scientific community. There are diverse metrics to measure the performance \cite{Burkov_2019}: confusion matrix, precision, recall, accuracy, F1-score, Receiver Operating Characteristic (ROC curve), and Area Under the Curve (AUC). To make precise quantitative comparisons is necessary to have the same metric for all the compared elements, which is only sometimes possible. As all the metrics can be expressed as a percentage (considering 100\% the ideal case), it is possible to make rough comparisons between different metrics. Doing this rough evaluation for experiments like \cite{Demme_2013,Tang_2014,Singh_2017,Sayadi_2018,Sayadi_2019,Zhou_2018}, it is possible to appreciate that not rarely the detectors have performance close to or lower than 90\%. Based on an observation like this, \cite{Zhou_2018} question the effectiveness of the hardware-based malware detection approach. They argue that if we consider an accuracy of 80\%, from 1323 executable files in a default Windows 7 installation, 264 would be classified incorrectly as malware, confirming the necessity of having high-performance detectors.

\section{Conclusions and research challenges}
\label{sec:conclusion}

\begin{comment}
    Here it would be best to summarize the current status of the hardware-based techniques and then draft a list of challenges to address.
\end{comment}

This paper overviewed malware detection, focusing on the recent and promising hardware-based approach. We presented a brief review of malware categories, a precise overview of the contemporary malware detection approaches, and a deep analysis of the target approach, the hardware-based. This approach leverages the HPCs already available in modern processors and the power of ML, offering attractive advantages like resilience to disabling the protection, resilience to unknown malware, low complexity/overhead/cost, and run-time detection.

The discussion in this paper allowed us to point out some challenges still existing in the hardware-based malware detection approach:

    \begin{itemize}
    \item The accuracy is the more significant challenge, and the ML classifiers are targets to work around it. These classifiers have a statistical nature, thus, their results are not deterministic (they always have some error). The focus is to minimize as much as possible this error, and research on this is going in the direction of complex classifiers; 
    \item If it is impossible to achieve high accuracy or if the error is unacceptable, it is necessary to think of a way to deal with it. A visualized possibility is having detectors based on mixed approaches (software and hardware) working concurrently;
    \item The correlation between hardware events behavior and malware needs to be better understood. The improvement in this understanding could also enable the construction of better hardware performance monitors;
    \item The substantial limitation in the number of HPCs in mobile and internet of things devices can limit the approach feasibility in this area. Countermeasures on this are necessary;
    \item The execution and reporting of experiments in this field have many details and significant complexity. The standardization could help more precise experiments and enable fair comparisons.    
    \end{itemize}


\bibliographystyle{IEEEtran}  
\bibliography{bibliography} 

\end{document}
