\begin{table*}[!ht]
    \centering
    \begin{tabular}{cccrr}
    \hline
        \multirow{2}{*}{Defense} & \multirow{2}{*}{Type} & \multirow{2}{*}{Evaluation Method} & \multicolumn{2}{c}{Robust Accuracy (\%)} \\
         & & & reported & ours \\ \hline
        ADP~\citep{Yoon2021AdversarialPW} & DSM+LD & PGD+EOT (BPDA+EOT) & 68.98±0.90* & 37.27±1.22 \\
        DiffPure~\citep{Nie2022DiffusionMF} & Diffusion & PGD+EOT (AutoAttack) & 77.80±1.24* & 51.25±0.67 \\
        GDMP~\citep{Wang2022GuidedDM} & Diffusion & PGD+EOT (BPDA+EOT) & 76.72±0.59* & 30.82±1.33 \\ \hline
        SODEF~\citep{kang2021stable}** & ODE & AutoAttack (AutoAttack) & 57.76 (53.69) & 49.28 \\
        DISCO~\citep{ho2022disco} & Implicit function & AutoAttack (BPDA) & 47.18 & 0.00 \\ \hline
    \end{tabular}
    \caption{Results of our evaluation of the five adaptive test-time defenses. The robust accuracy of each defense is measured using the evaluation method (and the parenthesis used in the original paper) with $\ell_\infty$-norm bounded perturbations of size $\epsilon = 8/255$ on CIFAR-10. * This is evaluated with a classifier different from that used in the original paper. ** This method uses an adversarially trained classifier. The robust accuracy of the underlying static classifier is 53.69\% (which is denoted in parentheses).}
    \label{table:overal_evaluation}
\end{table*}