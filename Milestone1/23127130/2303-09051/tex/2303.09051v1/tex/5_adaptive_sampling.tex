\input{tables/best_cifar}
\input{tables/best_linf_imagenet.tex}

%\section{Adaptive Sampling Strategy for Diffusion-Based Purification}
\section{Gradual Noise-Scheduling for Multi-Step Purification}
\label{sec:gradual_sampling}

In this section, we propose a new sampling strategy for diffusion-based purification and compare the performance with other state-of-the-art defenses.

\textbf{Gradual noise-scheduling strategy.} 
As highlighted in \autoref{sec:hyperparameter}, selecting appropriate hyperparameter values is essential to improve robustness. Thus, we conduct an extensive exploration of hyperparameter settings to maximize robust accuracy. In particular, we mainly focus on the fact that each purification step can contain a different number of forward steps. We empirically find that fewer forward steps in the first few purification steps can improve robustness.

Based on this observation, for CIFAR-10, we set the number of forward steps as $\{30 \times 4, 50 \times 2, 125 \times 2\}$ for eight purification steps. For ImageNet and SVHN, we set the number of forward steps as $\{30 \times 4, 50 \times 2, 200 \times 2\}$ and $\{30 \times 4, 50 \times 2, 80 \times 2\}$, respectively. We set the number of denoising steps to equal the number of forward steps for all purification steps. We use the DDPM and an ensemble of ten purification runs.

\textbf{Experimental settings.} 
We conduct evaluations on three datasets, CIFAR-10~\citep{krizhevsky2009learning}, ImageNet~\cite{deng2009imagenet}, and SVHN~\citep{Netzer2011ReadingDI}. We use three diffusion model architectures, DDPM++~\citep{Song2020ScoreBasedGM}, Guided Diffusion~\citep{Dhariwal2021DiffusionMB}, and DDPM~\citep{Ho2020DenoisingDP} for each dataset. We use pretrained models for CIFAR-10 and ImageNet, but we trained a model for SVHN. Pretrained WideResNet-28-10, WideResNet-70-16, and ResNet-50-based~\citep{Zagoruyko2016WideRN, He2015DeepRL} classifiers are served as baseline classifiers. We compare our method with adversarial training and diffusion-based purification methods. We evaluate all methods on the PGD attack with 20 update iterations. For diffusion-based purification methods, we set the number of EOT to 20. Randomly sampled 512 images are used to evaluate diffusion-based purification methods. For our method, we report the worst robust accuracy with surrogate processes. We explain the detailed settings in \autoref{app:gradual_sampling}.


\textbf{Results.}
\autoref{table:best_cifar10} shows the defense performance against $\ell_\infty (\epsilon = 8/255)$ and $\ell_2 (\epsilon = 0.5)$ threat models on CIFAR-10, respectively.
Our method outperforms other diffusion-based purification methods. Specifically, compared to DiffPure on $\ell_\infty$ PGD attack, our method improves robust accuracy by 10.16\% with WideResNet-28-10 and by 6.35\% with WideResNet-70-16, respectively. Despite the improvement in robustness, the purification methods perform worse than the adversarial training methods.
\autoref{table:linf_imagenet_resnet50} shows the performance against $\ell_\infty (\epsilon = 4/255)$ threat model on ImageNet. Our method outperforms both adversarial training and purification methods. Compared to DiffPure and \citet{Salman2020DoAR}, our method improves robust accuracy by 4.34\% and 3.94\%, respectively. Evaluations with SVHN, BPDA, and other attacks can be found in \autoref{app:gradual_sampling}.
