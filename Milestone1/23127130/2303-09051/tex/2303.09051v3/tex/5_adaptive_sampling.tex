\input{tables/best_linf_imagenet.tex}

\section{Gradual Noise-Scheduling for Multi-Step Purification}
\label{sec:gradual_sampling}

In this section, we propose a new sampling strategy for diffusion-based purification and compare the performance with other state-of-the-art defenses.

\textbf{Gradual noise-scheduling strategy.} 
As highlighted in \autoref{sec:hyperparameter}, selecting appropriate hyperparameter values is essential to improve robustness. Thus, we conduct an extensive exploration of hyperparameter settings to maximize robust accuracy. In particular, we mainly focus on the fact that each purification step can contain a different number of forward steps. We empirically find that fewer forward steps in the first few purification steps can improve robustness.

Based on this observation, for CIFAR-10, we set the number of forward steps as $\{30 \times 4, 50 \times 2, 125 \times 2\}$ for eight purification steps. For ImageNet and SVHN, we set the number of forward steps as $\{30 \times 4, 50 \times 2, 200 \times 2\}$ and $\{30 \times 4, 50 \times 2, 80 \times 2\}$, respectively. We set the number of denoising steps to equal the number of forward steps for all purification steps. We use the DDPM and an ensemble of ten purification runs.

\input{tables/best_svhn}

\textbf{Experimental settings.} 
We conduct evaluations on three datasets, CIFAR-10~\citep{krizhevsky2009learning}, ImageNet~\cite{deng2009imagenet}, and SVHN~\citep{Netzer2011ReadingDI}. We use three diffusion model architectures, DDPM++~\citep{Song2020ScoreBasedGM}, Guided Diffusion~\citep{Dhariwal2021DiffusionMB}, and DDPM~\citep{Ho2020DenoisingDP} for each dataset. We use pretrained models for CIFAR-10 and ImageNet, but we trained a model for SVHN. Pretrained WideResNet-28-10, WideResNet-70-16, and ResNet-50~\citep{Zagoruyko2016WideRN, He2015DeepRL} are served as baseline classifiers. We compare our method with adversarial training and diffusion-based purification methods. 
We evaluate diffusion-based purification methods on the PGD+EOT attack with 200 update iterations, except for ImageNet, which uses 20 iterations. We set the number of EOT to 20. For adversarial training methods, we use 20 update iterations for the PGD attack.
For our method, we report the worst robust accuracy with surrogate processes. We explain the detailed settings in \autoref{app:gradual_sampling}.


\textbf{Results.}
\autoref{table:best_cifar10} shows the defense performance against $\ell_\infty (\epsilon = 8/255)$ and $\ell_2 (\epsilon = 0.5)$ threat models on CIFAR-10, respectively.
Our method outperforms other diffusion-based purification methods. Specifically, compared to DiffPure on $\ell_\infty$ PGD attack, our method improves robust accuracy by 8.98\% with WideResNet-28-10 and by 5.75\% with WideResNet-70-16, respectively. Despite the improvement in robustness, the purification methods perform worse than the adversarial training methods.
\autoref{table:linf_imagenet_resnet50} shows the performance against $\ell_\infty (\epsilon = 4/255)$ threat model on ImageNet. Our method outperforms both adversarial training and purification methods. Compared to DiffPure and \citet{Salman2020DoAR}, our method improves robust accuracy by 4.34\% and 3.94\%, respectively. 
Results on SVHN against threats model $\ell_\infty (\epsilon = 8/255)$ are similar with CIFAR-10. Although our method improves robust accuracy by 15.35\% compared to the DiffPure framework, which uses $t^* = 0.075$, our method performs worse than the adversarial training methods.

We additionally compare the robustness of our defense strategy with other adversarial purification methods against BPDA ($\ell_\infty (\epsilon = 8/255)$). As shown in \autoref{table:best_BPDA}, our proposed method outperforms all other adversarial purification methods, achieving a robust accuracy of 88.40\%, 6.95\% greater than the robust accuracy of DiffPure. Furthermore, \autoref{table:best_other_attack} shows our robustness against other attacks, including the Square attack~\citep{Andriushchenko2019SquareAA}, a black-box attack. Our defense shows strong robustness higher than 80\% against all attacks.

\input{tables/best_bpda}
\input{tables/best_other_attacks}