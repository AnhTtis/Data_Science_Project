The target is defined as an uncooperative object tumbling freely in 6-\acrshort{dof}, with constant velocities and with very simple markers imprinted on its body.
The environment is considered as a frictionless, gravity-free, non-interacting, infinite space with sufficient lighting. A chaser is assumed to be a robotic system, capable of 6-\acrshort{dof} motion in the environment and equipped with a monocular camera. The odometry of the \gls{chaser} is assumed to be known at any given time in relation to a static world frame.

The problem scenario discussed in this article is divided in to two parts. Initially, the synchronization problem is considered where the satellites will track the target and try to match it's tumbling path by maintaining a predefined pose $ref$, relative to the target. Later, satellites will slowly approach the target while maintaining their relative orientation until they are close enough to be considered docked to the target.

\subsection{Reference Frames}

% It is important to introduce from the beggining the reference frames used in this work.
The reference frames used are presented in Fig. (\ref{fig:1_ref_frames}).

\begin{description}
    \item[WRF] the \textit{world frame}, is an arbitrary reference frame which will be used as a global reference.
    \item[CRF] the \textit{chaser frame} is a frame aligned with the \gls{chaser}'s chassis and fixed on its center of mass.
    The \textbf{X}-axis of ${CRF}$ aligns with the direction that the chaser's camera is looking towards.
    The \textbf{Z}-axis points towards the top of the chaser's chassis and \textbf{Y}-axis completes the right handed coordinate frame.
    \item[TRF] the \textit{target frame} is a frame fixed at the center of mass of the target and arbitrarily aligned.
    \item[IRM] the \textit{image frame}, is a necessary transformation to properly align the reference frames with the notation used by \gls{opencv} %(\ref{fig:2_pinhole_camera_model}).
\end{description}

\begin{figure}[h]
    \includegraphics[width=.45\textwidth]{ref_frames.pdf}
    \centering
    \caption{The reference frames used in this work.}
    \label{fig:1_ref_frames}
\end{figure}

\subsection{System Dynamics} \label{ch:chap3:sec2}

It is assumed that both the target and chasers are rigid bodies. In terms of inertial properties, target and chasers are considered to be rectangular cuboids as well as there are no gravity or any external forces are acting on the system.

\subsubsection{Chaser}
The chaser can be described as a rigid body with forces and/or torques acting on it's center of gravity representing thruster actuation.
The chaser's state is defined by 13 variables:
% The chaser's state is defined by the following variables:
% \begin{subequations}\label{eq:3_state}
%     \begin{equation}
%         x_T = [x, y, z, q_w, q_x, q_y, q_z, \dot{x}, \dot{y}, \dot{z}, \omega_x, \omega_y, \omega_z]^T
%     \end{equation}
%     \begin{equation}
%         x_T=[x, \dot{x}, \bm{q}, \omega]^T
%     \end{equation}
% \end{subequations}
$p=[p_x, p_y, p_z]^\top$ is the position, $q=[q_w, q_x, q_y, q_z]^\top \in [-1, 1]^4$ is a rotation quaternion representing the orientation and $v=[\dot{p_x}, \dot{p_y}, \dot{p_z}]^\top$ and $\omega=[\omega_x, \omega_y, \omega_z]^\top$ are the linear and angular velocities in Euler form, respectively.

It is assumed that all the forces and torques are acting on its center of gravity and are relative to the $CRF$ reference system.
To model the physics of the chaser the Euler-Newton equations for translational and rotational dynamics of a rigid body \eqref{eq:3_euler_newton} are used.
\begin{equation}\label{eq:3_euler_newton}
    \begin{bmatrix} F \\ \tau \end{bmatrix} = \begin{bmatrix} mI_3 & 0 \\ 0 & I_{cm} \end{bmatrix}
    \begin{bmatrix} \dot{v}(t) \\ \dot{\omega}(t) \end{bmatrix} + 
    \begin{bmatrix} 0 \\ \omega(t) \times (I_{cm} \cdot \omega(t))\end{bmatrix}
\end{equation}
where $F$ and $\tau$ are the forces and torques acting on the bodys center of gravity, $m$ and $I_{cm}$ are the mass and the moment of inertia matrix of the body. %, $\alpha_{cm}$ and $\omega$ are the linear acceleration and angular velocity of the body. 

% When trying to differentiate the equations of motion of the chaser, the problem of the quaternion derivative arises.
% \cite{nikolako_1} describe a method differentiating quaternions used in a similar MPC application on quadcopter UAVs.
Equation.~\eqref{eq:3_chaser_dynamics} presents the complete linear and angular dynamics of the chaser spacecraft.
\begin{equation}\label{eq:3_chaser_dynamics}
    \left\{ \begin{matrix*}[l]
        \dot{p}(t) = v(t)\\
        \dot{v}(t) = \frac{1}{m}I_3\bm{\hat{F}}\\
        \dot{q}(t) = -\frac{1}{2} \begin{bmatrix} 0 \\ \omega(t) \end{bmatrix} \otimes q(t)\\
        \dot{\omega}(t) = I^{-1}_{cm} \cdot \bm{\hat{\tau}} - I^{-1}_{cm}[ \omega(t) \times (I_{cm} \cdot \omega(t)) ]
    \end{matrix*} \right.
\end{equation}
$\bm{\hat{\tau}}$ and $\bm{\hat{F}}$ represent the forces and torques acting on the center of mass of the chaser rotated back to the $WRF$ reference system.
This can be performed by using the following equations \eqref{forcerotate} of quaternions rotating vectors:
\begin{equation} \label{forcerotate}
    \begin{matrix}
        \bm{\hat{F}}=q\bm{F}q^*\\
        \bm{\hat{\tau}}=q\bm{\tau}q^*
    \end{matrix}
\end{equation}


\subsubsection{Target}
The target is also a rigid-body but with constant-velocity and no forces acting on it.
The target has similar state variables to the chaser's, i.e. $[p^{tar},q^{tar},v^{tar},\omega^{tar}]^\top$  while the system dynamics can be described by \eqref{eq:3_target_dynamics}.
\begin{equation}\label{eq:3_target_dynamics}
    \left\{ \begin{matrix*}[l]
        \dot{p}^{tar}(t) = v^{tar}(t)\\
        \dot{v}^{tar}(t) = 0\\
        \dot{q}^{tar}(t) = -\frac{1}{2} \begin{bmatrix} 0 \\ \omega^{tar}(t) \end{bmatrix} \otimes q^{tar}(t)\\
        \dot{\omega}^{tar}(t) = 0
    \end{matrix*} \right.
\end{equation}

% Wanting to simulate a scenario as close to real-world as possible, it is assumed that the chaser can only apply forces and/or torques of fixed amplitute to predifined positions on its body.
% The \acrfull{tsl} node is responsible for calculating the actuation levels for these on-off thrusters.
% Finally, the \acrshort{pwm} node is responsible for generating \acrshort{pwm} signals that can simulate values between the minimum and maximum of the on-off thrusters.

% A very popular method for estimating the pose of a camera relative to an environment is by utilizing fiducial markers.
% Fiducial markers are objects with a known shape and size that are placed in the environment and can act as a reference point for the camera.
% In fields such as \acrshort{ar}, \acrshort{vr}, robotics and visual navigation, square markers have gained popularity.
% This is because they are easy to detect and their four distinct corners can be used to extract the camera pose.

% \begin{figure}[h]
%     \includegraphics[width=0.49\textwidth]{examples_fiducial.png}
%     \centering
%     \caption{Examples of different fiducial markers proposed in various works \citep{aruco_1}}
%     \label{fig:2_fiducial_examples}
% \end{figure}

% Many implementations of squared fiducial markers have been introduced in the literature.
% One of the first and most famous was ARToolKit, introduced by \cite{artoolkit}.
% These markers are composed of a wide black border and an inner pattern which must be validated agains a set of valid patterns.
% Other implementations, like ARTag \citep{artag}, use a table of binary values as an inner pattern.
% This allows for more features to be implemented such as error detection and correction.
% \cite{aruco_1} make a detailed comparission between the different implementations.

% \subsection{ArUco}

% The implementation of the squared, fiducial markers used in this project was introduced by \cite{aruco_1} and later improved by \cite{aruco_2}.
% The, so-called, ArUco marker system, is the state-of-the-art marker system for visual navigation and tracking, able to achieve over 1000fps in 4k images on it's latest version.
% ArUco can identify different markers and track them according to their ID.

% The process of ArUco for detecting markers in an image was not an entirely novel contribution.
% It's contributions are methods of marker code identification and error correction.
% These add a layer of stability and robustness to the algorithm.
% On their follow-up paper, \cite{aruco_2} introduce ways to speed up this process and make it even more robust.
% For this project, the ArUco implementation of \Gls{opencv} is used.

% \subsection{Perspective-n-Point Problem} 

% The \acrlong{pnp} problem is the problem of determining the pose of a \textit{calibrated camera} given a set of $n$ 3D points in the world and their corresponding 2D projections in the image \citep{springer_robotics:ch32, pnp_1}.
% Equation \ref{eq:pinhole} describes the pinhole camera model, which is a relatively simple method of linking the 3D world coordinates ($M$) to the 2D image coordinates ($m$) through the intrinsic ($A$) and extrensic ($[R|t]$) parameters of the camera.
% In a calibrated camera, the intrinsic parameters are known.
% This problem is comparable to the simpler problem of camera calibration where the extrinsic parameters are known and the intrinsic parameters are solved for.

% \begin{subequations} \label{eq:pinhole}
%     \begin{equation}
%         s m' = A [R|t] M'
%     \end{equation}
%     \begin{equation}
%         s \begin{bmatrix} u \\ v \\ 1 \end{bmatrix} = 
%         \begin{bmatrix}
%             f_x & 0 & c_x \\
%             0 & f_y & c_y \\
%             0 & 0 & 1
%         \end{bmatrix} 
%         \left[
%         \begin{array}{ccc|c}
%             R_{11} & R_{12} & R_{13} & T_1\\
%             R_{21} & R_{22} & R_{23} & T_2\\
%             R_{31} & R_{32} & R_{33} & T_3
%         \end{array}
%         \right]
%         \begin{bmatrix} X \\ Y \\ Z \\ 1 \end{bmatrix}
%     \end{equation}
% \end{subequations}

% In its simplest form, the problem is P3P and can be simplified as a system of 3 equations solvable in closed form.
% However, this method gives up to four real, geometrically possible solutions \citep{pnp_2}. and a fourth point is needed to resolve the ambiguity.
% This method is very prone to noise and can only be used robustly in noise-free scenarios.

% For higher orders of the problem, many solutions have been proposed in literature.
% For example, the problem can also be interpeted as an optimization problem trying to minimize the reprojection error of a point in 3D space.
% This enables it to be solved by optimization and iterative methods.
% More recently, \cite{epnp} published a method called \acrfull{epnp}, solving \acrshort{pnp} for $n \ge 4$ with $O(n)$ complexity.
% To reduce the problems sensitivity to errors, noise and outliers, \acrshort{ransac} is in combination with one of the solutions to make estimations more robust against outliers.

% \subsection{Target Pose Estimation Using OpenCV \& ArUco}

% Using a combination of fiducial marker tracking and algorithms that solve the \acrshort{pnp} problem, an elegant method is developed to estimate the \gls{target}s pose.
% By placing ArUco markers on predefined positions on the targets body, a set $P_{TRF}$ is defined containing the 3D coordinates the marker's corners in $TRF$.
% In an image taken by the camera, these corners can be recognized as they belong on different ArUco markers.
% A set $P_{IRF}$ is also defined containing the 2D coordinates of these corners in the image frame $IRF$.

% Having previously calibrated the camera, this problem is now a \acrshort{pnp} problem, since a set of 3D-2D correspondences is known.
% Note that since ArUco is used as a tracking method, at least 4 points are always contained in $P_{TRF}$ and $P_{IRF}$ (while the \gls{chaser} maintains line-of-sight with the \gls{target}), corresponding to the 4 corners of a single marker.
% This ensures a single solution of the \acrshort{pnp} problem.

% \Gls{opencv} provides implementations of the P3P, \acrshort{epnp} and \acrshort{ransac} algorithms.
% It also offers a package that recognizes ArUco markers and extracts the positions of their corners.
