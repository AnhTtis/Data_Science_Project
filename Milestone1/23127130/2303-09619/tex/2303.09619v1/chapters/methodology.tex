% \subsection{Processing Flow}\label{ch:chap1:sec3}

To tackle the scenario at hand, a centralized control scheme was designed as shown in Fig. (\ref{fig:1_chaser_flow}).
Each \gls{chaser} will process the images taken with its camera sensor on-board.
The images are un-distorted using a camera calibration model and then passed to the pose estimator.

\insertfig{1_chaser_flow}{Processing flow of a chaser swarm composed of two agents.}
% \footnotetext[\numexpr \value{footnote} - 2 \relax]{\acrfull{mpc}}
% \footnotetext[\numexpr \value{footnote} - 1 \relax]{\acrfull{tsl}}
% \footnotetext{\acrfull{pwm}}

The pose estimator starts by detecting the ArUco markers \citep{aruco_1}, \citep{aruco_2} imprinted on the target.
The positions of the marker's corners in the $TRF$ frame define a set $P_{TRF}$.
The method for ArUco marker recognition allows extraction of the pixel coordinates of each individual corner of each marker.
Each marker is also uniquely identifiable.
A set $P_{IRF}$ is defined containing these 2D coordinates of the corners visible on a given image capture.

Next, a \acrlong{pnp} (PnP) problem is defined using $P_{TRF}$ and $P_{IRF}$.
The \acrshort{pnp} problem is the problem of determining the pose of a calibrated camera given a set of $n$ 3D points in the world and their corresponding 2D projections in the image \citep{springer_robotics:ch32, pnp_1}.
Basically, solving the pinhole camera model in (\ref{eq:pinhole}) for the extrinsic parameters ($[R|t]$), provided some 3D world coordinates ($M$) and 2D image coordinates ($m$) and with the intrinsic parameters ($A$) known.

\begin{subequations} \label{eq:pinhole}
    \begin{equation}
        s m' = A [R|t] M'
    \end{equation}
    \begin{equation}
        s \begin{bmatrix} u \\ v \\ 1 \end{bmatrix} = 
        \begin{bmatrix}
            f_x & 0 & c_x \\
            0 & f_y & c_y \\
            0 & 0 & 1
        \end{bmatrix} 
        \left[
        \begin{array}{ccc|c}
            R_{11} & R_{12} & R_{13} & T_1\\
            R_{21} & R_{22} & R_{23} & T_2\\
            R_{31} & R_{32} & R_{33} & T_3
        \end{array}
        \right]
        \begin{bmatrix} X \\ Y \\ Z \\ 1 \end{bmatrix}
    \end{equation}
\end{subequations}

Implementations for both ArUco marker detection algorithm and the EPnP \citep{epnp} solver used in this project were provided in the OpenCV library.

The target's pose estimations are sent to a TF system responsible for calculating transfer functions between different reference frames.
An estimation combiner node is responsible to process the pose estimates of the \gls{chaser}s and to combine them into a single estimate for the \gls{target}s odometry (pose \& velocities).
The combiner works by averaging the latest available estimations by each chaser that has line-of-sight to the target.
It also uses a moving average filter for noise reduction, outlier detection and removal methods.

This combined estimation is fed, together with the chaser's odometry, to the controller.
The controller then uses the estimated odometry to generate an optimal control signal for each chaser (see Ch. \ref{ch:chap3}).
% A single, central controller is responsible for the control of the entire swarm, including a collision avoidance system and docking sequence.
% See Chapter \ref{ch:chap3} for more details on the controller implementation and Chapter \ref{ch:chap4:sec2} and Chapter \ref{ch:chap4:sec1} for simulation results showcasing docking and collision avoidance.
The control signals, consisting of a set of 3-dimensional forces and torques, are sent to the \gls{chaser}'s Thruster Selection Logic (TSL) and finally to a Pulse Width Modulation (PWM) signal generator.
The TSL module is considered as a black box for now and will be implemented later ad-hoc.