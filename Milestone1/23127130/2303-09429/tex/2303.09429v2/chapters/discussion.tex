\section{Discussion}
We shed more light on the task of \coir. Data labeling for \coir appears to be difficult and costly, exposed to serious biases (\eg, redundancy of the image-query), bounded by inevitable flaws (\eg, false-negatives), and eventually ending up with a low quality and size of data. We suggest a remedy for most of these shortcomings via an inexpensive solution: leveraging labels from a popular related task, to create a new labeled dataset, \ourDS. We extensively analyze current \coir datasets, in order to show their effectiveness, generalization and the capability of a certain model (trained on specific dataset) in handling the desired compositionality in the \coir task. We also suggest the \our baseline, that relies on early fusion of the query modalities through a cross-attention module. We demonstrate the effectiveness of \our by achieving top results on labelled \coir benchmarks from two different domains. To the best of our knowledge, our new baseline, also leverages the smallest dimension of the search space (shared embedding space) among the methods being compared, resulting in a further reduction in computational expenses. 
We believe this work, including our newly introduced dataset, might serve as a useful and practical tool 
not solely limited to the intricate \coir task but also extending to the broader realm of multi-modal learning.