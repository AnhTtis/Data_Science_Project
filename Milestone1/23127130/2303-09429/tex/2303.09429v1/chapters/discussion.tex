\section{Discussion}
This work seeks to shed more light on the task of \coir, through the two fundamental aspects of data and methods. Data labeling for \coir appears to be difficult and costly, exposed to serious biases (\eg, redundancy of the image-query), bounded by inevitable flaws (\eg, false-negatives) and eventually ending up with a low quality and size of data. We suggest a remedy for most of these shortcomings via an inexpensive solution: leveraging labels from a popular related task, to create a new labeled dataset iof \ourDS.
For the method aspect, we suggest \our, a new approach that relies on early fusion of the query modalities through a cross-attention module. We demonstrate the effectiveness of \our by achieving top results on labelled \coir benchmarks from two different domains. To the best of our knowledge, our method uses the lowest dimension of the search space (shared embeddings space) in the compared methods, further reducing computational cost. We extensively analyze current datasets, in order to show their effectiveness and generalization and the capability of a certain model (trained on specific dataset) in handling the desired compositionality in the \coir task.
We believe this work, including our newly introduced dataset, might serve as a useful and practical tool for further studies in the challenging task of \coir in the multi-modal learning domain.