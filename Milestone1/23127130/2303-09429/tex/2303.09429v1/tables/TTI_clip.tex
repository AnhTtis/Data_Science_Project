\begin{table}[ht]
\begin{center}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lcccccc|c}
\hline
Dataset & R@1 & R@5 & R@10 & R@50 & R@100 & \multicolumn{1}{l|}{R@500} & \multicolumn{1}{l}{\%CT2I} \\ \hline
COCO & 32.69 & 57.76 & 68.23 & 90.07 & 96.21 & 99.56 & 60.17 \\
CIRR & 19.97 & 44.61 & 57.07 & 80.12 & 86.70 & 97.03 & 48.23 \\
FashionIQ & 6.07 & 12.55 & 16.84 & 31.85 & 41.57 & 66.74 & 16.82 \\
LaSCo & \textbf{1.47} & \textbf{3.81} & \textbf{5.89} & \textbf{14.56} & \textbf{20.89} & \textbf{45.64} & \textbf{6.61} \\ \hline
\end{tabular}
}
\end{center}
\caption{Results of CLIP Text-to-Image (CT2I) baseline on several datasets. Retrieval on datasets that require compositional capabilities is expected to be low, since query-text is used. \%CT2I score is the average of R@\{1,10,50\}.}
\label{tab:tti_clip}
\end{table}