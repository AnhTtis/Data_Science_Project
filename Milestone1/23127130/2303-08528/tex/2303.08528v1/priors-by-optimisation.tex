% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  10pt,
  a4paper,
]{article}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage[]{tgpagella}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=2.25cm]{geometry}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{amsmath,amssymb,mathtools,bbm}
% I always seem to need tikz for something
\usepackage{tikz}
\usetikzlibrary{positioning, shapes, intersections, through, backgrounds, fit, decorations.pathmorphing}

\usepackage{algorithm}
\usepackage{algpseudocode}

\usepackage{setspace}
\onehalfspacing

\usepackage{lineno}
% \linenumbers

% required for landscape pages. beware, they make build times very long.
\usepackage{pdflscape}
\usepackage{placeins}

% table - `gt' package uses these, often unimportant
\usepackage{longtable}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{colortbl}

\usepackage{color}
\definecolor{myredhighlight}{RGB}{180, 15, 32}
\definecolor{mydarkblue}{RGB}{0, 33, 79}
\definecolor{mymidblue}{RGB}{44, 127, 184}
\definecolor{mylightblue}{RGB}{166, 233, 255}
\definecolor{mywhwlow}{RGB}{234, 164, 99}

\usepackage{accents}
\newlength{\dhatheight}
\newcommand{\doublehat}[1]{%
    \settoheight{\dhatheight}{\ensuremath{\hat{#1}}}%
    \addtolength{\dhatheight}{-0.35ex}%
    \hat{\vphantom{\rule{1pt}{\dhatheight}}%
    \smash{\hat{#1}}}}

\setcounter{secnumdepth}{3}

% \renewcommand{\floatpagefraction}{0.8}
% \renewcommand{\topfraction}{0.8}
% \renewcommand{\bottomfraction}{0.8}
% \renewcommand{\textfraction}{0.25}

% pd stands for: probability distribution and is useful to distringuish
% marignals for probabilities specifically p(p_{1}) and the like.
\newcommand{\pd}{\text{p}}
\newcommand{\Pd}{\text{P}}
\newcommand{\q}{\text{q}}
\newcommand{\Q}{\text{Q}}
\newcommand{\w}{\text{w}}
\newcommand{\pdr}{\text{r}}
\newcommand{\pdrh}{\hat{\text{r}}}

% pbbo stuff
\newcommand{\tc}{\text{T}}
\newcommand{\tp}{\text{t}}

% melding
\newcommand{\ppoolphi}{\pd_{\text{pool}}(\phi)}
\newcommand{\ppool}{\pd_{\text{pool}}}
\newcommand{\pmeld}{\pd_{\text{meld}}}

% the q(x)w(x), "weighted target" density 
% for the moment I'm going to call it s(x), as that is the next letter of the 
% alphabet. Can change it later
\newcommand{\s}{\text{s}}
% direct density estimate - replaces lambda.
\newcommand{\ddest}{\text{s}}
% target weighting function
\newcommand{\tarw}{\text{u}}

% constants - usually sizes of things
\newcommand{\Nx}{N}
\newcommand{\Nnu}{\text{N}_{\text{nu}}}
\newcommand{\Nde}{\text{N}_{\text{de}}}
\newcommand{\Nmc}{\text{N}_{\text{mc}}}
\newcommand{\Nw}{W}
\newcommand{\Nm}{M}
\newcommand{\Ns}{S}

% locales - could switch to x and x'
\newcommand{\xnu}{x_{\text{nu}}}
\newcommand{\xde}{x_{\text{de}}}
\newcommand{\phinu}{\phi_{\text{nu}}}
\newcommand{\phide}{\phi_{\text{de}}}

% sugiyama stuff
\newcommand{\pdnu}{\pd_{\text{nu}}}
\newcommand{\pdde}{\pd_{\text{de}}}

% indices 
\newcommand{\wfindex}{w}
\newcommand{\sampleindex}{n}
\newcommand{\modelindex}{m}
\newcommand{\stageindex}{s}

\DeclarePairedDelimiterX{\infdivx}[2]{(}{)}{%
  #1\;\delimsize\|\;#2%
}
\newcommand{\infdiv}{D\infdivx}
\newcommand{\kldiv}{D_{\text{KL}}\infdivx}
\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}

\newcommand{\lse}{\text{logSumExp}}

\newcommand*\Let[2]{\State #1 $\gets$ #2}
\algrenewcommand\alglinenumber[1]{
    {\sf\footnotesize\color{lightgray}#1}}
\algrenewcommand\algorithmicrequire{\textbf{Inputs:}}
\algrenewcommand\algorithmicensure{\textbf{Postcondition:}}

\def\dodoi#1{doi: \href{https://doi.org/#1}{\nolinkurl{#1}}}
\def\dourl#1{\href{http://#1}{\nolinkurl{#1}}}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{jasaauthyear}
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Translating predictive distributions into informative priors},
  pdfauthor={Andrew A. Manderson; Robert J. B. Goudie},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Translating predictive distributions into informative priors}
\author{Andrew A. Manderson\footnote{MRC Biostatistics Unit, the
  University of Cambridge and The Alan Turing Institute.
  \texttt{andrew.manderson@mrc-bsu.cam.ac.uk}} \and Robert J. B.
Goudie\footnote{MRC Biostatistics Unit, the University of Cambridge.
  \texttt{robert.goudie@mrc-bsu.cam.ac.uk}}}
\date{March, 2023}

\begin{document}
\maketitle
\begin{abstract}
When complex Bayesian models exhibit implausible behaviour, one solution
is to assemble available information into an informative prior.
Challenges arise as prior information is often only available for the
observable quantity, or some model-derived marginal quantity, rather
than directly pertaining to the natural parameters in our model. We
propose a method for translating available prior information, in the
form of an elicited distribution for the observable or model-derived
marginal quantity, into an informative joint prior. Our approach
proceeds given a parametric class of prior distributions with as yet
undetermined hyperparameters, and minimises the difference between the
supplied elicited distribution and corresponding prior predictive
distribution. We employ a global, multi-stage Bayesian optimisation
procedure to locate optimal values for the hyperparameters. Three
examples illustrate our approach: a nonlinear regression model; a
setting in which prior information pertains to \(R^{2}\) -- a
model-derived quantity; and a cure-fraction survival model, where
censoring implies that the observable quantity is \emph{a priori} a
mixed discrete/continuous quantity.
\end{abstract}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

A key asset to the Bayesian paradigm is the conceptual ease with which
prior information is incorporated into models. For complex, nonlinear,
overparameterised, or otherwise partially identified
\citep{gustafson_bayesian_2015} models, including such prior information
is essential to exclude model behaviours that conflict with reality,
and/or known qualities of the phenomena being modelled. Prior
information can also improve computation of estimates of the posterior,
making otherwise unusable models suitable for inference. However, it is
for precisely the models for which prior information is so important
that setting appropriate priors for parameters is hardest.

We consider in this paper the task of forming such appropriate
informative priors. We distinguish two tasks: predictive elicitation;
and the subsequent translation into a prior for a given model.
Predictive elicitation is an approach in which elicitation
\citep{ohagan_uncertain_2006, falconer_methods_2021, low_choy_priors_2012}
proceeds via predictive distributions, often for observable quantities,
and is thought to be the most reliable and available form of information
\citep{kadane_experiences_1998}. Predictive elicitation is also
model-agnostic, meaning the complex, time-consuming process of
elicitation does not need to be repeated for each variant of a model. A
recent, comprehensive review of elicitation is undertaken by
\citet{mikkola_prior_2021}.

Translation is the process of using information from predictive
elicitation to set the corresponding informative prior for a model.
Translation, as a distinct step in the prior specification process, has
received less attention than elicitation. A simple predictive approach
is to directly model the elicited, observable quantity. This direct
approach requires no translation. For example, the Bayesian
quantile-parameterised likelihood
\citep{hadlock_quantile-parameterized_2017, keelin_quantile-parameterized_2011}
approach of \citet{perepolkin_hybrid_2021} involves updating directly
elicited information in light of observations. Such direct approaches
are currently only feasible for simple models with no latent structure.
For models with simple latent structure, it is sometimes possible to
elicit information about an invertible function of the parameters
\citep[e.g.][]{chaloner_graphical_1993}. In these cases it is possible
to analytically translate the elicited information into a prior for the
parameters. Translation is also clear for conjugate models
\citep{percy_bayesian_2002}, as if we specify the target prior
predictive distribution using the conjugate distribution, then the prior
predictive distribution determines the values for the hyperparameters of
the prior \citep[related to the idea of ``reverse Bayes''
in][]{held_reverse-bayes_2022}. Translation, however, is unclear in
general for nonconjugate models \citep{gribok_backward_2004}, although
techniques for specific models with specific latent structure are
numerous, and include linear regression \citep{ibrahim_properties_1997},
logistic regression \citep{bedrick_bayesian_1997, chen_prior_1999}, Cox
models \citep{chaloner_graphical_1993}, contingency table analyses
\citep{good_bayesian_1967}, hierarchical models \citep[noting that the
space of possible hierarchical models is vast]{hem_robustifying_2021},
and autoregressive time-series models \citep{jarocinski_priors_2019}.
Nevertheless, a model-agnostic approach with a corresponding generic
implementation would be preferable, as noted by
\citet{gelman_prior_2017} and \citet{mikkola_prior_2021}.

Our approach to translation builds on the idea of predictive checks
\citetext{\citealp{gabry_visualization_2019}; \citealp{gelman_prior_2017}; \citealp{box_sampling_1980}; \citealp[the
``hypothetical future samples''
of][]{winkler_assessment_1967}; \citealp{van_zundert_prior_2022}}, which
are an important, and often recommended
\citep{gelman_bayesian_2020, van_zundert_prior_2022}, tool in assessing
the concordance of the prior predictive distribution and the elicited
predictive information or elicited data distribution. If concordance
between these two distributions is low for a certain prior distribution,
then the Bayesian workflow \citep{gelman_bayesian_2020} proceeds by
adjusting the prior to better match the prior predictive distribution to
the elicited information. However, for many classes of models, manually
adjusting the prior in this manner is infeasible; the complexity
required to describe the phenomena of interest muddies the relationship
between the prior and the data distribution, and so a more automated
method is required. One instance of this is the history matching idea of
\citet{wang_using_2018}, in which specific regions of observable space
are labelled as (im)plausible, and the prior is deemed acceptable if it
places a sufficiently (small) large amount of the prior predictive
density the (im)plausible region. Modern elicitation techniques can also
simultaneously specify priors and incorporate information from multiple
experts. For example, \citet{thomas_probabilistic_2020} develop a
``human in the loop'' method for elicitation; data simulated from a
given model are judged as plausible or implausible by experts, and these
judgements drive a hyperparameter optimisation process that maximises
the plausibility of generated data. \citet{albert_combining_2012}
propose a hybrid, hierarchical elicitation/specification method intended
for multiple experts, which is capable of representing uncertainty in
the elicited quantities; and, when analytically possible, adopts a
predictive approach. Another approach, and the closest in motivation and
methodology to ours, is \citeauthor{hartmann_flexible_2020}
\citetext{\citeyear{hartmann_flexible_2020}; \citealp[which is partly
inspired by][]{da_silva_prior_2019}}, which uses elicited predictive
quantiles and a novel estimation method to acquire a suitable prior
distribution for a given model. \citet{hartmann_flexible_2020} employ a
stochastic algorithm using implicit reparameterisation gradients
\citep{figurnov_implicit_2018} to expedite the process. Doing so limits
the applicability of their method to those models with gradients we can
compute using the reparameterisation trick, and implementations with
access to automatic differentiation.

In this paper we develop a method, and software package, for
constructing an informative prior distribution for model parameters that
results in a desired prior predictive distribution. Our method begins
from elicited predictive information about the data, which we call the
\emph{target} prior predictive distribution. We then define a suitable
loss function between the prior predictive distribution, given specific
values for the hyperparameters of the prior, and this target
distribution. The loss function is intentionally generic and permits
data that are discrete, continuous, or a mixture thereof. We minimise
this loss via a generic, simulation-based, global optimisation process
to locate optimal hyperparameters. Solutions to this optimisation
problem are rarely unique, so to regularise the problem we adopt a
multiple objective approach. The global optimisation approach is also
selected with generality in mind, rendering our method applicable to
models where derivative information is unavailable. We make our method
available in an \texttt{R} package \texttt{pbbo}\footnote{The release
  used in this paper is available at
  \url{https://doi.org/10.5281/zenodo.7736707}.}
\citep{r_core_team_r_2022}. Our method is illustrated in three
challenging, moderate dimension problems; a nonlinear regression model,
a model using predictive information on a model-derived quantity -- a
situation not explicitly covered by prior predictive elicitation; and a
cure fraction survival model.

\hypertarget{translating-elicited-prior-predictive-distributions}{%
\section{Translating elicited prior predictive
distributions}\label{translating-elicited-prior-predictive-distributions}}

In this section we introduce the desired properties for any translation
method, and our mathematical framework and optimisation strategy that
together constitute our prior specification methodology. We aim to
minimise the difference between the prior predictive distribution and
our elicited target distribution, whilst also promoting the marginal
variance of the model's parameters. Satisfying the first of these goals
produces priors faithful to the supplied information; the second
promotes uniqueness and replicability -- we elaborate on the precise
meaning of these properties momentarily. We adopt a multi-objective
optimisation approach to locate priors satisfying these requirements.

\hypertarget{desiderata}{%
\subsection{Desiderata}\label{desiderata}}

We now postulate three key properties that we would like our method to
satisfy: faithfulness, uniqueness, and replicability.

\emph{Faithfulness}~~ We consider a prior faithful if it accurately
encodes the target data distribution provided by the elicitation
subject. Faithfulness is a property of both the model, as it must be
possible for the model to represent the information, and the procedure
employed to obtain the prior. Especially with simple models and prior
structures, not all target prior predictive distributions can be
encoded.

\emph{Uniqueness}~~ In a complex model there may be many prior
distributions that imply the same prior predictive distribution. These
prior distributions will all be equally faithful. Should uniqueness be
desired -- and it seems a reasonable enough desiderata most of the time
-- we must distinguish between priors based on other properties. In
Section
\ref{regularising-estimates-of-lambda-by-promoting-the-marginal-standard-deviation-secondary-objective}
we propose to distinguish priors based on their marginal standard
deviations, but other properties are easily incorporated into our
method.

\emph{Replicability}~~ We call a procedure/method consistent if it
obtains the same, or very similar, prior across independent
replications, given the same target. This property is particularly
important to assess for methods, like ours, that make use of
simulation-based or otherwise stochastic estimates. Global,
gradient-free optimisers, when applied to noisy loss functions, offer no
guarantee of finding the global minimum in finite time
\citep{liberti_introduction_2008, mullen_continuous_2014}. We assess
replicability empirically in all our examples.

These properties are partly inspired by other works in the prior
elicitation and specification literature. Faithfulness is closely
related to \citet{johnson_methods_2010}'s definition of \emph{validity}
\citep[see also][]{johnson_valid_2010} and
\citet{ohagan_uncertain_2006}'s use of \emph{faithful} in Chapter 8 (and
throughout the book). However, their concerns are specific to the
elicitation process -- do the quantities elicited represent what the
experts believe? -- and not to the subsequent translational step. Our
conception of uniqueness and the need for regularisation is noted by
\citet{da_silva_prior_2019} and \citet{stefan_practical_2022}, and is
similar to the notion of model \emph{sloppiness} of
\citet{gutenkunst_universally_2007}.

We have introduced our desiderata in what we believe to be their order
of importance. Firstly, without faithfulness the procedure has not
achieved the main aim of translating our knowledge into the prior
distribution. Subsequently, given a suite of faithful priors,
regularising the problem until it is unique allows us to select one in a
clear and replicable way. Such uniqueness inducing regularisation
schemes often improve a procedure's replicability and, given we often
only elicit information on the scale or other broad properties of a
phenomena, it is unsurprising that such information is associable with
many prior distributions. Replicability ultimately also relies on the
empirical behaviour of the procedure when applied to the model of
interest. We note that the desiderata are not binary, and at times we
may wish to sacrifice some amount of the latter properties for improved
faithfulness. We also envisage settings where sacrificing some model
flexibility, and thus faithfulness, for a marked increase in
replicability increases the usefulness or persuasiveness of a model.

\hypertarget{the-target-predictive-distribution-tcy}{%
\subsection{\texorpdfstring{The target predictive distribution
\(\tc(Y)\)}{The target predictive distribution \textbackslash tc(Y)}}\label{the-target-predictive-distribution-tcy}}

Our methodology assumes a target predictive distribution (a cumulative
distribution function, CDF) for the observable quantity, \(\tc(Y)\), has
been chosen using predictive elicitation
\citep{kadane_experiences_1998}. In brief, such an elicitation proceeds
by querying experts about the observable quantity at a small number
quantiles, then fitting an appropriate parametric distribution to the
elicited values \citep[see Chapter 6 of][]{ohagan_uncertain_2006}. We
assume a (mixture of) standard distributions can describe the target
predictive distribution function \(\tc(Y)\), and that we can draw
samples from this distribution.

We often wish to elicit information about the observable quantity \(Y\)
conditional on some known values of a covariate. For example, when using
the linear model \(Y = X\beta + \varepsilon\) we may elicit information
about \(Y\) at a fixed set of values for \(X\). Further suppose \(X\) is
an experimental design specified before collecting observations of
\(Y\), or comprises observational covariates whose values are known
prior to model construction. In such settings we can elicit
\(r = 1, \ldots, R\) conditional target distributions
\(\tc(Y \mid X_{r})\).

We elect to describe our methodology in this covariate-specific setting,
as it readily reduces to the covariate-independent case.

\hypertarget{total-predictive-discrepancy-primary-objective}{%
\subsection{Total predictive discrepancy (primary
objective)}\label{total-predictive-discrepancy-primary-objective}}

Consider a joint model for observables
\(Y \in \mathcal{Y} \subseteq{} \mathbb{R}\) and parameters
\(\theta \in \Theta \subseteq \mathbb{R}^{Q}\), given hyperparameters
\(\lambda \in \Lambda \subset \mathbb{R}^{L}\) and covariates
\(X \in \mathcal{X} \subseteq \mathbb{R}^{C}\). This joint model has CDF
\(\Pd(Y, \theta \mid \lambda, X)\) and prior predictive CDF for \(Y\),
\(\Pd(Y \mid \lambda, X)\). Choosing the CDF as the basis for our
methodology enables us to be agnostic to whether the observable is
continuous, discrete, or a mixture thereof. We will use
\emph{distribution} to refer to the CDF of a stochastic quantity, and
\emph{density} to refer to the corresponding probability density
function (where it exists).

Further suppose the target CDF \(\tc(Y \mid X_{r})\) has been elicited
at \(R\) values of the covariate vector denoted
\(\{X_{r}\}_{r = 1}^{R}\), which we stack in the covariate matrix
\(\boldsymbol{X} = \left[X_{1}^{\top} \cdots X_{R}^{\top}\right] \in \boldsymbol{\mathcal{X}} \subseteq \mathbb{R}^{R \times C}\).
We assume that each target \(\tc(Y \mid X_{r})\) has identical support
to \(\Pd(Y \mid \lambda, X_{r})\). Lastly, it will be convenient to
denote
\(\tc(Y \mid \boldsymbol{X}) = \prod_{r = 1}^{R} \tc(Y \mid X_{r})\),
with \(\Pd(Y \mid \lambda, \boldsymbol{X})\) and
\(\Pd(\theta \mid \lambda, \boldsymbol{X})\) defined analogously.

We now quantify the difference between the prior predictive and target
by the \emph{covariate-specific predictive discrepancy}, which we define
to be
\input{tex-input/pbbo-methodology/0012-theoretical-discrep-definition-covariate.tex}\noindent
for some discrepancy function \(d(\cdot, \cdot)\). The Riemann-Stieltjes
integral in Equation~\ref{eqn:theoretical-discrep-definition-covariate}
is necessary because \(\mathcal{Y}\) can be continuous, discrete, or a
mixture thereof. Minimising Equation
\eqref{eqn:theoretical-discrep-definition-covariate} admits the optimal
hyperparameter
\(\lambda^{*} = \min_{\lambda \in \Lambda} \tilde{D}(\lambda \mid \boldsymbol{X})\).
The covariate-independent equivalent \(\tilde{D}(\lambda)\) is obtained
by setting \(R = 1\) and ignoring all conditioning on \(X_{r}\) in
Equation \eqref{eqn:theoretical-discrep-definition-covariate}.

The discrepancy function \(d(\cdot, \cdot)\) takes two CDFs as its
arguments. Inspired by the CramÃ©r-von Mises
\citep{von_mises_asymptotic_1947} and Anderson-Darling
\citep{anderson_asymptotic_1952} distributional tests we define, for
arbitrary CDFs \(\text{M}(Y)\) and \(\Pd(Y)\), two options for our
discrepancy function,
\input{tex-input/pbbo-methodology/0013-discrepancies-definitions.tex}\noindent
Both discrepancies are proper scoring rules
\citep{gneiting_strictly_2007} as they are minimised iff
\(\text{M}(Y) = \Pd(Y)\) for all \(Y \in \mathcal{Y}\). Supposing
\(\Pd(Y \mid \lambda, X_{r})\) is flexible enough to exactly match
\(\tc(Y \mid X_{r})\) for some unique \(\lambda^{*}\), then both
discrepancies will yield the same \(\lambda^{*}\). Differences arise
when \(\Pd(Y \mid \lambda, X_{r})\) is insufficiently flexible.
Furthermore, we will have to resort to a finite-sample approximation to
Equation \eqref{eqn:theoretical-discrep-definition-covariate} (which we
detail momentarily), and in this setting the Anderson-Darling
discrepancy \(d^{\text{AD}}\) places more emphasis on matching the tails
of two CDFs under consideration, but is more challenging to accurately
compute.

\hypertarget{regularising-estimates-of-lambda-by-promoting-the-marginal-standard-deviation-secondary-objective}{%
\subsection{\texorpdfstring{Regularising estimates of \(\lambda^{*}\) by
promoting the marginal standard deviation (secondary
objective)}{Regularising estimates of \textbackslash lambda\^{}\{*\} by promoting the marginal standard deviation (secondary objective)}}\label{regularising-estimates-of-lambda-by-promoting-the-marginal-standard-deviation-secondary-objective}}

The optimisation problem of minimising Equation
\eqref{eqn:theoretical-discrep-definition-covariate} is often
underspecified. Specifically, there are many optimal values
\(\lambda^{*}\) that yield values of
\(\tilde{D}(\lambda^{*} \mid \boldsymbol{X})\) that are practically
indistinguishable \citep[noted by][]{da_silva_prior_2019}, and yet the
prior distributions \(\Pd(\theta \mid \lambda^{*}, \boldsymbol{X})\) and
the corresponding marginals for components of \(\theta\) can differ
immensely. In terms of our desiderata, there are many equally faithful
priors (which immediately implies a lack of uniqueness), thus we have an
optimisation problem with solutions that are difficult to replicate due
to nonuniqueness. This is not surprising because we are providing
information only on \(Y\), which is typically of lower dimension than
\(\theta\). To address this underspecification we seek to encode the
following principle into our methodology: given two estimates of
\(\lambda^{*}\) which have equivalent values of
\(\tilde{D}(\lambda^{*} \mid \boldsymbol{X})\), we prefer the one with
the larger variance for
\(\Pd(\theta \mid \lambda^{*}, \boldsymbol{X})\). This preference
induces less of a restriction on the possible values of \(\theta\) in
the posterior.

We make use of this principle by adopting a multi-objective approach to
prior construction and, therefore, now derive a suitable mathematical
quantity measuring the variability of \(\theta\). There are numerous
suitable functions measuring such variability, and our methodology is
agnostic to the particular functional form. Most generally, we define
the secondary objective \(\tilde{N}(\lambda \mid \boldsymbol{X})\) as
comprising any such suitable function \(n(\theta)\) with
\input{tex-input/pbbo-methodology/0040-generic-secondary-objective.tex}\noindent
In this paper we consider only one form for \(n(\theta)\), and so
hereafter the second objective, which we also seek to minimise, is
always
\input{tex-input/pbbo-methodology/0041-second-objective-def.tex}\noindent
where \(\text{SD}_{\Pd(Z)}[Z]\) is the standard deviation of \(Z\) under
distribution \(\Pd(Z)\). This quantity is the mean of the marginal log
standard deviations of each of the \(Q\) components of
\(\theta \in \Theta \subseteq \mathbb{R}^{Q}\), which we negate so as to
promote marginal variability when performing minimisation. We work with
the standard deviation (instead of the variance) and take the logarithm
thereof to minimise the contribution of any particularly extreme
marginal (i.e.~marginal with relatively low or high variance). Equations
\eqref{eqn:generic-secondary-objective} and
\eqref{eqn:second-objective-def} make explicit the dependence on
\(\Pd(\theta \mid \lambda, \boldsymbol{X})\), and thus \(\lambda\), for
clarity. We often have analytic expressions for\footnote{Note that
  Equation \eqref{eqn:second-objective-def} assumes
  \(\text{SD}_{\,\Pd(\theta_{q} \mid \lambda, \boldsymbol{X})}[\theta_{q}]\)
  exists, and is nonzero and finite for all \(q\) and
  \(\lambda \in \Lambda\). Should this not be true, for example if one
  of the marginals of \(\Pd(\theta_{q} \mid \lambda, \boldsymbol{X})\)
  is a Cauchy distribution, we can instead employ alternative, robust
  estimators of scale
  \citep{kravchuk_hodges-lehmann_2012, rousseeuw_alternatives_1993}.}
\(\text{SD}_{\Pd(\theta \mid \lambda, \boldsymbol{X})}[\theta_{q}]\),
but precise estimates are also simple to obtain using Monte Carlo.

\hypertarget{post-optimisation-decision-step}{%
\subsection{Post optimisation decision
step}\label{post-optimisation-decision-step}}

We jointly minimise Equations
\eqref{eqn:theoretical-discrep-definition-covariate} and
\eqref{eqn:second-objective-def} using a multi-objective optimisation
algorithm, which we will cover in detail momentarily. By adopting a
multiple objective approach to the translation problem, we obtain a set
of possible \(\lambda\) values which comprise the Pareto frontier
\(\mathcal{P} = \{\lambda_{l}\}_{l = 1}^{\lvert \mathcal{P} \rvert}\)
\citep[for an introduction to multi-objective optimisation problems see
Chapter 2 of][]{deb_multi-objective_2001}. For each \(\lambda\) in
\(\mathcal{P}\) we compute the loss
\input{tex-input/pbbo-methodology/0042-loss-definition.tex}\noindent
where the value of \(\kappa > 0\) expresses our relative belief in the
importance of the secondary objective. We take the log of
\(\tilde{D}(\lambda \mid \boldsymbol{X})\) to aid in selecting an
appropriate \(\kappa\), given our definition of
\(\tilde{N}(\lambda \mid \boldsymbol{X})\) in Equation
\eqref{eqn:second-objective-def}, but stress that this not necessary
should there be a more appropriate scale on which to define
\(\tilde{L}(\lambda)\). The optimal value is then chosen such that
\(\lambda^{*} := \min\limits_{\lambda \in \mathcal{P}} \tilde{L}(\lambda)\).
This optimum is clearly sensitive to the choice of \(\kappa\), but it is
computationally inexpensive to test many values of \(\kappa\) (the set
of which we denote with \(\mathcal{K}\)), and plots of the Pareto
frontier coloured by loss greatly aid our decision about the appropriate
choice of \(\kappa\).

Advantages of multi-objective optimisation are most immediately apparent
when the scales of our objectives differ markedly. Consider the
equivalent linearised approach, where we select \(\kappa\) \emph{before}
optimisation and directly optimise
\(\tilde{L}(\lambda \mid \boldsymbol{X})\). It is generally not possible
to know the range of the values of
\(\tilde{D}(\lambda \mid \boldsymbol{X})\) and
\(\tilde{N}(\lambda \mid \boldsymbol{X})\) before optimisation.
Selecting an appropriate \(\kappa\) without this knowledge is
prohibitively difficult, leaving only the computationally expensive
trial-and-error approach -- where we re-run the optimiser for each new
possible value of \(\kappa\) -- as a plausible strategy for choosing
\(\kappa\). In contrast, given \(\mathcal{P}\) it is computationally
trivial to recompute \(\lambda^{*}\) for many possible values of
\(\kappa\) \emph{after} optimisation (e.g.~each panel of Figure
\ref{fig:kappa_cov} is trivial to compute). We can thus select
\(\kappa\) in a problem-specific manner for practically no additional
computational cost to that of the multi-objective optimiser. Note that
the multi-objective optimisation approach is more expensive that the
linearised approach, but this additional cost is dwarfed by the number
of re-runs of the latter typically required to select \(\kappa\).

\hypertarget{optimisation-strategy}{%
\subsection{Optimisation strategy}\label{optimisation-strategy}}

With the mathematical framework defined, we now turn to discuss the many
practicalities of optimisation. We use a two-stage global optimisation
process to construct a prior with the desiderata listed in Section
\ref{desiderata}. The first stage focuses entirely on faithfulness by
minimising only \(\tilde{D}(\lambda \mid \boldsymbol{X})\), using the
variant of controlled random search 2 \citep[CRS2,][]{price_global_1983}
proposed by \citet{kaelo_variants_2006}. Stage one output is then used
to initialise stage two, which additionally focuses on uniqueness and
replicability by employing multi-objective Bayesian optimisation
\citep{frazier_tutorial_2018, zaefferer_mspot_2012} to jointly minimise
\(\tilde{D}(\lambda \mid \boldsymbol{X})\) and
\(\tilde{N}(\lambda \mid \boldsymbol{X})\). We focus on faithfulness,
and thus \(D(\lambda \mid \boldsymbol{X})\), as a separate stage because
minimising \(D(\lambda \mid \boldsymbol{X})\) is considerably more
challenging than minimising \(N(\lambda \mid \boldsymbol{X})\). By
initialising stage two with faithful estimates for \(\lambda\) we can,
in the second stage, spend more computational resources on finding
points along the Pareto frontier. The resulting optimal prior should
suitably encode the information in the target predictive distribution,
without being overly confident for model parameters. An idealised form
of this process is illustrated in Figure \ref{fig:idealised_process}.

Note that almost all global optimisation methods require, in the absence
of other constraints, \(\Lambda\) to be compact subset of
\(\mathbb{R}^{L}\). We require that the practitioner specify the
upper/lower limits for each dimension of \(\Lambda\).

\begin{figure}

{\centering \includegraphics{plots/tuning-parameters/idealised-process.pdf} 

}

\caption{An idealised depiction of the methodology we introduce in this paper when the corresponding densities are available. The starting point, or "stage zero" (S0) depicts the elicited target prior predictive distribution for the observable quantity $Y$ depicted and denoted by its density $\tp(Y)$ (red line). Stage one starts (S1 -- start) from an initial prior (blue line), which does not match the target and is uninformative for the model parameter $\theta$. Optimisation proceeds by using controlled random search to minimise the predictive discrepancy (grey shaded area) and produces optimal hyperparameters $\lambda^{*}$. Stage one produces (S1 -- end) a very faithful prior predictive distribution, but is overly confident for the model parameter. Stage two (S2) uses multi-objective Bayesian optimisation and corrects this overconfidence for $\theta$ with only a small increase in predictive discrepancy.}\label{fig:idealised_process}
\end{figure}

\hypertarget{evaluating-the-objectives}{%
\subsubsection{Evaluating the
objectives}\label{evaluating-the-objectives}}

Optimisation cannot proceed until we have practical means to evaluate
\(\tilde{D}(\lambda \mid \boldsymbol{X})\) and
\(\tilde{N}(\lambda \mid \boldsymbol{X})\). As noted previously,
evaluating \(\tilde{N}(\lambda \mid \boldsymbol{X})\) for models where
analytic results or simple Monte Carlo estimates are available is
straightforward, and we denote the corresponding estimate (or, if
available, the analytic form) of
\(\tilde{N}(\lambda \mid \boldsymbol{X})\) with
\(N(\lambda \mid \boldsymbol{X})\). However, there are two immediate
challenges to evaluating \(\tilde{D}(\lambda \mid \boldsymbol{X})\):

\begin{enumerate}
  \tightlist
  \item the prior predictive CDF $\Pd(Y \mid \lambda, \boldsymbol{X})$ is often analytically unavailable;
  \item the integral in Equation \eqref{eqn:theoretical-discrep-definition-covariate} is almost always intractable.
\end{enumerate}

We address the former with a Monte Carlo based empirical CDF (ECDF), and
the latter with importance sampling. Specifically, given a particular
value of \(\lambda\) and \(X_{r}\), we draw \(S_{r}\) samples
\(\boldsymbol{y}_{r}^{(\Pd)} = (y_{s, r})_{s = 1}^{S_{r}}\) with
\(\boldsymbol{y}_{r}^{(\Pd)} \sim \Pd(Y \mid \lambda, X_{r})\) to form
the ECDF
\(\hat{\Pd}(Y \mid \lambda, X_{r}, \boldsymbol{y}_{r}^{(\Pd)})\). To
apply importance sampling we rewrite the integral in Equation
\eqref{eqn:theoretical-discrep-definition-covariate} with respect to
importance distribution \(\Q(Y \mid X_{r})\) and importance density
\(\q(Y \mid X_{r})\), such that
\input{tex-input/pbbo-methodology/0014-theoretical-discrep-definition-covariate-importance.tex}\noindent
When \(Y\) is discrete or of mixed type, \(\q(Y \mid X_{r})\) is instead
a probability mass function or an appropriate mixture of discrete and
continuous densities. Supposing we draw \(I_{r}\) importance samples
\((y_{i, r})_{i = 1}^{I_{r}} \sim \Q(Y \mid X_{r})\), we denote the
importance sampling approximation to
\(\tilde{D}(\lambda \mid \boldsymbol{X})\) with
\(D(\lambda \mid \boldsymbol{X})\) such that
\input{tex-input/pbbo-methodology/0015-practical-discrep-definition-covariate-importance.tex}\noindent

Note that we write \(\Q(Y \mid X_{r})\), and thus \(\q(Y \mid X_{r})\),
to make clear that the importance distribution could be
covariate-specific, but in straightforward settings a common \(\Q(Y)\)
for all \(R\) covariate values will be appropriate.

We select \(\Q(Y \mid X_{r})\) using information about the support
\(\mathcal{Y}\), and samples from \(\Pd(Y \mid \lambda, X_{r})\) and
\(\tc(Y \mid X_{r})\). For more details see Appendix
\ref{importance-sampling}. Finally, for numerical stability we evaluate
\(D(\lambda \mid \boldsymbol{X})\) on the log scale, with details
available in Appendix \ref{evaluating-dlambda-mid-boldsymbolx}. This
process is summarised in Algorithm
\ref{alg:tpd-algorithmic-description}.

\input{tex-input/pbbo-methodology/0051-tpd-algorithmic-description.tex}

\hypertarget{optimisation-stage-1}{%
\subsubsection{Optimisation, stage 1}\label{optimisation-stage-1}}

In this stage we focus solely on faithfulness by minimising
\(D(\lambda \mid \boldsymbol{X})\). We do so using CRS2
\citep{price_global_1983} with local mutation
\citep{kaelo_variants_2006}, which we run for \(N_{\text{CRS2}}\)
iterations. We make use of the final optimum value \(\lambda^{*}\), as
well as each of the \(N_{\text{CRS2}}\) trial points to obtain a design
\(\mathcal{D}\) for the next stage. The design comprises values of
\(\lambda\), and their corresponding values of
\(\log(D(\lambda \mid \boldsymbol{X}))\). A (small) number of padding
points \(N_{\text{pad}}\) are added to \(\mathcal{D}\) for numerical
robustness in stage 2. The result is the design
\(\mathcal{D} = \left\{\lambda_{i}, \log(D(\lambda_{i} \mid \boldsymbol{X}))\right\}_{i = 1}^{N_{\text{design}} + N_{\text{pad}}}\),
whose construction is detailed in Algorithm
\ref{alg:crs2-algorithmic-description} in Appendix
\ref{algorithmic-descriptions-of-the-optimisation-process}.

Whilst CRS2 was not designed to minimise noisy functions, it appears
empirically robust to small quantities of noise. We can make the noise
in \(D(\lambda \mid \boldsymbol{X})\) arbitrarily small, but doing so
usually incurs an enormous computational cost. Carefully balancing the
noise in the objective, and thus quality of the stage one solution,
against the cost of evaluation yields a faithful optimum \(\lambda^{*}\)
and useful design \(\mathcal{D}\) in an acceptable amount of time.

\hypertarget{optimisation-stage-2}{%
\subsubsection{Optimisation, stage 2}\label{optimisation-stage-2}}

Stage two focuses on uniqueness and replicability in addition to
faithfulness. We adjust our optimisation technique to affect this change
in emphasis, and use multi-objective Bayesian optimisation, via MSPOT
\citep{zaefferer_mspot_2012}, to jointly minimise
\(D(\lambda \mid \boldsymbol{X})\) and
\(N(\lambda \mid \boldsymbol{X})\). MSPOT uses a separate Gaussian
process (GP) approximation to each of the objectives, and evaluates
these approximations at many points from Latin hypercube designs
\citep{stein_large_1987}. In each of the \(N_{\text{BO}}\) iterations,
the best points under the current GP approximations are evaluated using
the actual objectives. These evaluations accumulate and thus iteratively
improve the GP approximations. After \(N_{\text{BO}}\) iterations, the
evaluated points are reduced to their Pareto frontier
\citep{kung_finding_1975}, which we use in Equation
\eqref{eqn:loss-definition}. Algorithm
\ref{alg:mspot-algorithmic-description} in Appendix
\ref{algorithmic-descriptions-of-the-optimisation-process} describes in
detail the MSPOT algorithm as applied to two objectives.

The noisy and computationally expensive nature of our objectives,
particularly \(D(\lambda \mid \boldsymbol{X})\), necessitates an
approach such as MSPOT. Employing approximate GP models for the
objectives allows us to screen potential values of
\(\lambda \in \Lambda\) inexpensively, and avoid evaluating the actual
objectives at values of \(\lambda\) far from optimal. Moreover, the GP
is a flexible yet data efficient model to use as an approximation and
can, through appropriate choice of kernel, capture correlation or other
complex relationships between components of \(\lambda\) and the
objective.

Stage two also adopts an optional batching technique because we
encounter computational limits for large values of \(N_{\text{BO}}\).
This is due to the computational cost of evaluating the GP growing
cubically in the number of points in its construction. Batching
partially removes this limitation, and can produce equivalent or better
priors in less time than a single batch of many iterations. It achieves
this by subsampling to remove similar, or otherwise uninformative,
points from the collection used to form the surrogate GP model.
Specifically, we run MSPOT for a fixed number of iterations, then select
a subsample of the points evaluated in the completed batch as
initialisation points for the following batch. The exact subsampling
strategy is detailed in
Algorithm~\ref{alg:resample-batch-algorithmic-description} in Appendix
\ref{algorithmic-descriptions-of-the-optimisation-process}.

\hypertarget{benchmarking-and-other-empirical-considerations}{%
\subsection{Benchmarking and other empirical
considerations}\label{benchmarking-and-other-empirical-considerations}}

We will at times compare results between this multi-objective
optimisation approach with the ``single objective'' approach, which is
identical other than stage 2 of the optimisation also only considers
\(D(\lambda \mid \boldsymbol{X})\). This single objective approach
inherently discards our uniqueness and replicability desiderata, but is
occasionally an informative benchmark.

Finally, it should be noted that global optimisation methods lack
guarantees of finding the global optimum in finite time, so we cannot
generalise the performance of this optimisation process to all problems.
We do, however, empirically validate the performance of this strategy in
the examples we consider, and note that the optimisation process has a
number of tuning parameters that control robustness and/or speed which
may prove useful in other settings.

\hypertarget{summary}{%
\subsection{Summary}\label{summary}}

Our method for specifying a prior given predictive information requires:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  a method for sampling \(\Pd(Y \mid \lambda, \boldsymbol{X})\);
\item
  upper and lower limits that render \(\Lambda\) a compact subset of
  \(\mathbb{R}^{L}\);
\item
  a target CDF \(\tc(Y \mid \boldsymbol{X})\) and corresponding PDF
  \(\tp(Y \mid \boldsymbol{X})\) which, for numerical stability, must
  both be implemented on the log-scale;
\item
  a method for generating samples from \(\tc(Y \mid \boldsymbol{X})\),
  as the importance sampler depends on information contained in such
  samples;
\item
  a choice of \(\kappa\) (and we will present a diagnostic plot--see
  e.g.~Figure \ref{fig:kappa_cov}--which assists in making this
  decision).
\end{enumerate}

Algorithm~\ref{alg:pbbo-overall-algorithmic-description} describes, in
pseudocode, our proposed methodology.

\input{tex-input/pbbo-methodology/0055-pbbo-overall-algorithmic-description.tex}

\hypertarget{the-pbbo-r-package}{%
\subsection{\texorpdfstring{The \texttt{pbbo} \texttt{R}
package}{The pbbo R package}}\label{the-pbbo-r-package}}

We implement our methodology in an \texttt{R} package
\citep{r_core_team_r_2022} called \texttt{pbbo}, available from
\url{https://github.com/hhau/pbbo}. \texttt{pbbo}\footnote{The release
  associated with this paper is available at
  \url{https://doi.org/10.5281/zenodo.7736707}.} builds on top of
\texttt{mlrMBO} \citep{bischl_mlrmbo_2018} for multi-objective Bayesian
optimisation, \texttt{nlopt} and \texttt{nloptr}
\citep{ypma_nloptr_2022, johnson_nlopt_2014} for global optimisation
using CRS2 \citep{kaelo_variants_2006}, and other packages for internal
functionality and logging
\citep{wickham_welcome_2019, rowe_futilelogger_2016, maechler_rmpfr_2021}.
The code implementing the examples we consider in Sections
\ref{a-human-aware-prior-for-a-human-growth-model} to
\ref{calibrating-a-cure-fraction-survival-model}, which further
illustrate \texttt{pbbo}, can be found at
\url{https://gitlab.com/andrew-manderson/pbbo-paper}.

\hypertarget{a-human-aware-prior-for-a-human-growth-model}{%
\section{A human-aware prior for a human growth
model}\label{a-human-aware-prior-for-a-human-growth-model}}

We now consider a nonlinear regression model for human growth. There are
a number of properties of this example that make it an interesting test
for our methodology. First, we find it difficult to specify priors
congruent with desired prior predictive distributions for such models;
both the nonlinearity and the need to condition on specific values of
the regressor complicate prior specification. Data for human growth are
also readily available, so we can assess the impact of the prior on many
distinct data and posteriors. Second, the model we consider is also
poorly behaved under the flat prior, so some prior information is
required to stabilise and/or regularise the estimate of the posterior.
Finally, this example is also considered by
\citet{hartmann_flexible_2020}, and so there is a suitable comparator
for our results.

Suppose an individual has their height measured at age \(t_{m}\) (in
years) for \(m = 1, \ldots, M\), with corresponding measurement
\(y_{m}\) (in centimetres). The first Preece-Baines model
\citep{preece_new_1978} for human height is,
\input{tex-input/preece-baines-growth/0061-preece-baines-model-definition.tex}\noindent
with \(\varepsilon_{m} \sim \text{N}(0, \sigma^{2}_{y})\). Some
constraints are required to identify this model and ensure its physical
plausibility: specifically, we require \(0 < h_{0} < h_{1}\) and
\(0 < s_{0} < s_{1}\). A parameterisation that respects these
constraints and is easier to work with uses
\(\delta_{h} = h_{1} - h_{0}\) instead of \(h_{1}\), and
\(\delta_{s} = s_{1} - s_{0}\) in place of \(s_{1}\). All of
\((h_{0}, \delta_{h}, s_{0}, \delta_{s})\) thus have the same positivity
constraint. Finally, we also constrain \(\gamma\) such that
\(\gamma \in (\min_{m}(t_{m}), \max_{m}(t_{m}))\). However, these
constraints are not sufficient to make the model plausible for all
permissible parameter values -- the denominator of the fraction can be
very small, yielding negative heights.

To align with the notation introduced in Section
\ref{translating-elicited-prior-predictive-distributions} we denote the
parameters by
\(\theta = (h_{0}, \delta_{h}, s_{0}, \delta_{s}, \gamma)\). As in
\citet{hartmann_flexible_2020}, we choose for each of the
\(q = 1, \ldots, 5\) elements of \(\theta\) an independent
\(\text{LogNormal}(\mu_{q}, s^{2}_{q})\) prior. We will seek to identify
the optimal values of
\(\lambda = \left(\mu_{q}, s^{2}_{q}\right)_{q = 1}^{5}\). Table
\ref{tab:pb-cap-lambda-def} in Appendix \ref{tab:pb-cap-lambda-def}
lists the upper and lower limits we choose for each component of
\(\lambda\).

We do not consider the measurement error variance \(\sigma_{y}^{2}\) as
part of \(\theta\). Doing so introduces a degenerate solution for
\(\lambda\), where all variability in \(Y\) is singularly attributable
to \(\varepsilon_{m}\) and thus \(\sigma^{2}_{y}\). Such a prior seems
undesirable, so instead we fix the prior for \(\sigma_{y}^{2}\) to
reflect the measurement process for human height; measurement errors are
unlikely to be more than one or two centimetres, so values of
\(\sigma_{y}^{2} \approx 1\) seem reasonable. Thus we set
\(\sigma_{y} \sim \text{LogNormal}(0, 0.2^2)\). More generally, in
models with additive forms such as Equation
\eqref{eqn:preece-baines-model-definition-one} it is challenging to
avoid attributing all the variability in \(Y\) to the noise term (if the
prior for the noise is to be specified) and so it will generally be
necessary to fix a prior for \(\sigma^{2}_{y}\) using knowledge of the
measurement process.

\hypertarget{what-information-are-we-supplying}{%
\subsection{What information are we
supplying?}\label{what-information-are-we-supplying}}

Our data are assumed to originate from a sample of adolescent humans,
uniformly distributed between ages 2 and 18, and evenly split between
sexes. We consider supplying two types of target prior predictive
distributions. A \emph{covariate-independent} prior predictive density
\(\tp(Y)\), and corresponding CDF \(\tc(Y)\), for human heights across
the entire age-range, derived by summarising external data. This target
(Figure \ref{fig:pop_target_discreps}) is a mixture of 3 gamma densities
specified to approximate the external data, which is multimodal due to
the fact that humans grow in spurts. We also consider a
\emph{covariate-specific} \(\tc(Y \mid X_{r})\) in which we specify the
target predictive distribution \(\tc(Y \mid X_{r})\) of human heights at
ages \(X_{r} \in (2, 8, 13, 18)\) with \(r = 1, \ldots, 4\). Each
\(\tc(Y \mid X_{r})\) is normal (Figure \ref{fig:cov_target_discreps}).

Specifically, denote with \(\text{Gamma}(Y; \alpha, \beta)\) the CDF of
the gamma distribution with shape parameter \(\alpha\) and rate
\(\beta\); and \(\text{Normal}(Y; \xi, \omega^{2})\) the CDF of the
normal distribution with mean \(\xi\) and standard deviation \(\omega\).
We define the covariate-independent target
\input{tex-input/preece-baines-growth/0021-target-definition-pop.tex}\noindent
and the covariate-specific target
\input{tex-input/preece-baines-growth/0022-target-definition-cov.tex}\noindent

\hypertarget{example-details-and-tuning-parameters}{%
\subsection{Example details and tuning
parameters}\label{example-details-and-tuning-parameters}}

For covariate-independent and covariate-specific targets densities, we
obtain \(\lambda^{*}\) using both the single objective and
multi-objective optimisation processes (see Sections
\ref{optimisation-strategy} and
\ref{benchmarking-and-other-empirical-considerations}). We assess
replicability using 30 independent runs of each objective/target pair.
For each replicate, we run \texttt{pbbo} using \(S = 5 \times 10^4\)
samples from \(\pd(Y \mid \lambda)\) and likewise
\(S_{r} = 5 \times 10^4\) samples from \(\pd(Y \mid \lambda, X_{r})\)
for each of the 4 values of \(X_{r}\). We use \(I = 5 \times 10^3\) and
\(I_{r} = 5 \times 10^3\) importance samples, with
\(N_{\text{CRS2}} = 2000\) CRS2 iterations, \(N_{\text{batch}} = 5\)
Bayesian optimisation batches each of \(N_{\text{BO}} = 250\)
iterations, and carry forward \(N_{\text{design}} = 50\) points per
batch. We use only the CramÃ©r-Von Mises discrepancy in this example,
because we were not able to reliably compute the Anderson-Darling
discrepancy due to numerical instabilities.

\hypertarget{results}{%
\subsection{Results}\label{results}}

\hypertarget{choosing-kappa}{%
\subsubsection{\texorpdfstring{Choosing
\(\kappa\)}{Choosing \textbackslash kappa}}\label{choosing-kappa}}

The optimal choice of \(\kappa\) is target specific, and so we
separately choose an appropriate
\(\kappa \in \mathcal{K} = \{0.05, 0.1, \ldots, 0.5\}\) for the
covariate-independent and covariate-specific targets. As a heuristic, we
choose the value of \(\kappa\) that yields the minimum variability of
\(L(\lambda \mid \boldsymbol{X})\) for \(\lambda \in \mathcal{P}\)
amongst the replicates, though this heuristic is unsuitable if, as we
expect to be more commonly the case, only one run of the optimiser is
made. In such settings we recommend plotting the Pareto frontiers as in
Figure \ref{fig:kappa_cov} and visually checking that the minimum loss
point is not at either extrema of the frontier.

We select \(\kappa = 0.2\) for the covariate-specific target given our
minimum variability heuristic. The Pareto frontiers and minimum loss
points displayed in Figure \ref{fig:kappa_cov}, though for brevity we
display the results only for \(\kappa \in \{0.1, 0.2, 0.3, 0.4\}\). The
results for the covariate-independent target are similar (See Appendix
\ref{additional-information-for-the-preece-baines-example} Figure
\ref{fig:kappa_pop}) and there we select \(\kappa = 0.15\). Visible in
most replicates is an inflection point at values of
\(N(\lambda) \approx 1.5\) (the Y-axis in Figure \ref{fig:kappa_cov})
around which the minimum loss points cluster. Any of these points likely
admits a reasonable value for \(\lambda^{*}\).

Figure \ref{fig:kappa_cov} displays notable inter-replicate variability,
with the Pareto frontier for some replicates being totally dominated by
other replicates. This is due to the stochastic properties of the global
optimisers we employ.

\begin{figure}

{\centering \includegraphics{plots/preece-baines-growth/cov-kappa.pdf} 

}

\caption{Pareto frontiers for each $\kappa \in \mathcal{K}$ for the \textbf{covariate-specific} example. The minimum loss point for each replicate is plotted with $\color{myredhighlight}{+}$. Note also that the loss scales differ between plots.}\label{fig:kappa_cov}
\end{figure}

\hypertarget{final-discrepancies-and-faithfulness}{%
\subsubsection{Final discrepancies and
faithfulness}\label{final-discrepancies-and-faithfulness}}

Having selected \(\kappa\) we compute the optimal \(\lambda\) by
minimising \(L(\lambda)\). Given \(\lambda^{*}\), we compare \(\tp(Y)\)
against \(\pd(Y \mid \lambda^{*})\), and likewise \(\tp(Y \mid X_{r})\)
against \(\pd(Y \mid \lambda, X_{r})\). These comparisons are intended
to convince us that the optimal prior \(\pd(\theta \mid \lambda^{*})\)
indeed encodes the information in the prior predictive target, and is
thus faithful to the target.

Figure \ref{fig:pop_target_discreps} displays the targets and prior
predictive density estimates for the covariate-independent target. In
the covariate-independent target case, we see that introducing the
secondary objective (right panel) produces estimates of \(\lambda^{*}\)
that are congruent with estimates from the single objective case, though
with an additional outlier or two. Both single and multi-objective
approaches result in reasonably, but not entirely, faithful densities
for \(\pd(Y \mid \lambda^{*})\), However, most optimum priors seem to
result in individual trajectories attaining their adult height \(h_{1}\)
for younger than expected ages \(t\) (which we will later confirm in
Figure \ref{fig:regression_prior_pred}), and thus the prior predictive
\(\pd(Y \mid \lambda^{*})\) accumulates additional probability
surrounding \(Y = h_{1} \approx 155\).

For the covariate-specific target, displayed in Figure
\ref{fig:cov_target_discreps}, the secondary objective introduces a
number of outlying estimates for \(\pd(Y \mid \lambda^{*}, X_{r})\) most
clearly visible for \(X_{1} = 2\) and \(X_{2} = 8\). Both the single and
multi-objective approaches struggle to match the prior predictive
distribution at all ages, with consistently poorer performance for
\(X_{1} = 2\). This is the youngest age at which the model is intended
to be used, and some numerical instabilities are encountered here. It
may also not be possible to match all four target prior predictive
distributions simultaneously, and the narrowness of
\(\tp(Y \mid X_{1} = 2)\) may make it contribute less to the predictive
discrepancy under the CramÃ©r-Von Mises discrepancy.

\begin{figure}

{\centering \includegraphics{plots/preece-baines-growth/population-target-comparsion.pdf} 

}

\caption{The covariate-independent marginal target density $\tp(Y)$ (red) and prior predictive densities $\pd(Y \mid \lambda^{*})$ for each of the 30 replicates (blue lines). The replicates in the right panel are obtained after an optimum value $\kappa = 0.15$ is chosen.}\label{fig:pop_target_discreps}
\end{figure}

\begin{figure}

{\centering \includegraphics{plots/preece-baines-growth/covariate-target-comparsion.pdf} 

}

\caption{Covariate-specific target densities $\tp(Y \mid X_{r})$ (red lines) and prior predictive densities $\pd(Y \mid \lambda^{*}, X_{r})$ for each of the 30 replicates (blue lines). The replicates in the right column are obtained after an optimum value of $\kappa = 0.2$ is chosen.}\label{fig:cov_target_discreps}
\end{figure}

\hypertarget{comparison-with-hartmann_flexible_2020}{%
\subsubsection{\texorpdfstring{Comparison with
\citet{hartmann_flexible_2020}}{Comparison with @hartmann\_flexible\_2020}}\label{comparison-with-hartmann_flexible_2020}}

Before continuing with our results, we detail the specifics of
\citet{hartmann_flexible_2020} to contextualise our subsequent
comparisons.

\citet{hartmann_flexible_2020} also consider the problem of prior
specification given information about the prior predictive distribution
for the model in Equation
\eqref{eqn:preece-baines-model-definition-two}. However, there are key
differences between our approaches that must be kept in mind when
comparing results. \citet{hartmann_flexible_2020} elicit 6 predictive
quantiles at ages \(t = (0, 2.5, 10, 17.5)\), as opposed to entire
predictive distributions at ages \(t = (2, 8, 13, 18)\) which underpin
the covariate-specific version of our method. We use different ages
because the model of \citet{preece_new_1978} is stated to be accurate
and robust for ages greater than 2. \citet{hartmann_flexible_2020}
include a noise parameter in their definition of \(\theta\). The exact
interpretation of this parameter is complicated by their choice of
Weibull likelihood, rendering the distribution of the measurement errors
sensitive to conditional mean of the model (this is still the case
despite their choice of Weibull parameterisation). Finally,
\citet{hartmann_flexible_2020} elicit quantiles from 5 different users
and report an estimated \(\lambda^{*}\) for each user. These estimates,
extracted from the supplementary material to
\citet{hartmann_flexible_2020} and reproduced in Appendix
\ref{hartmann_flexible_2020-priors}, allow us to compare optimal priors
\(\pd(\theta \mid \lambda^{*})\) and functions thereof. They do not
report whether each user's estimate is consistent over repeated runs of
their optimisation algorithm, and do not discuss the issue of estimate
replicability.

\hypertarget{prior-faithfulness-in-the-conditional-mean}{%
\subsubsection{Prior faithfulness in the conditional
mean}\label{prior-faithfulness-in-the-conditional-mean}}

Do the priors we estimate produce reasonable and appropriately uncertain
data \emph{a priori}? This is also a question of faithfulness, but for
all possible values of \(t\). Inspecting the prior predictive for the
model without noise \(\pd(h(t; \theta) \mid \lambda^{*})\), to exclude
uncertainty due to the negligible measurement error, in Figure
\ref{fig:regression_prior_pred} suggests that both the
covariate-independent and covariate-specific targets yield plausible
typical growth trajectories. However, the covariate-independent priors
are significantly more uncertain and as a result are not particularly
plausible. This contrasts with the covariate-specific priors, which
interpolate between the supplied targets with an acceptable degree of
uncertainty. We also see why the covariate-specific target struggles to
match all the targets simultaneously, as achieving an appropriate level
of uncertainty at age 18 involves being similarly uncertain at age 2.
All 5 of the priors from \citet{hartmann_flexible_2020}, for a narrower
uncertainty interval, are implausible in both shape and width when
viewed on this scale. It also seems unlikely that these priors
accurately reflect the information provided by the experts in
\citet{hartmann_flexible_2020}, but this information is not reported.

\begin{figure}

{\centering \includegraphics{plots/preece-baines-growth/regression-prior-preds.pdf} 

}

\caption{\textbf{Prior} predictive for the model without noise $\pd(h(t; \theta) \mid \lambda^{*})$ for each replicate/user from Hartmann et al.~(top right panel), the covariate-independent target (middle row) and covariate-specific target (bottom row) for the single objective and multi-objective settings (left column and right column respectively). Note that this quantity does not include measurement error. Solid lines depict the mean, with the grey regions representing the 95\% prior predictive intervals, \textit{except} for the Hartmann panel, where the intervals are only \textcolor{mywhwlow}{75\%} wide for visualisation purposes. The y-axis is truncated to $(70, 200)$ and uncertainty intervals are also truncated to this range. The red lines in the covariate row correspond to our supplied $\tp(Y \mid X_{r})$ densities, and represent the same information as in Figure \ref{fig:cov_target_discreps}.}\label{fig:regression_prior_pred}
\end{figure}

\hypertarget{posterior-replicability}{%
\subsubsection{Posterior replicability}\label{posterior-replicability}}

Selecting values of \(\lambda^{*}\) with similar minimum loss, as
displayed in e.g.~Figure \ref{fig:kappa_pop}, is a necessary but not
sufficient step in demonstrating the replicability of our estimates for
\(\pd(\theta \mid \lambda^{*})\). We must also inspect the marginal
prior densities \(\pd(\theta_{q} \mid \lambda^{*})\). Replicability is
also important for the posterior; our prior ideally admits a posterior
amenable to sampling (i.e.~removes spurious modes and eliminates
computational difficulties present when using a noninformative prior).
It also seems desirable that similar priors should yield similar
posteriors.

With these properties in mind, we compare the priors and posteriors
produced by our methodology with the results from
\citet{hartmann_flexible_2020} and, as benchmark, the posteriors
produced using a flat, improper prior. For data we consider, separately,
each of the 93 individuals in the \texttt{growth} data
\citep{tuddenham_physical_1954} provided by the \texttt{fda} package
\citep{ramsay_fda_2022} in \texttt{R} \citep{r_core_team_r_2022}. This
is a form of prior sensitivity analysis, but distinct from the ideas of
\citet{roos_sensitivity_2015} which consider only one particular
realisation of the data. By considering each individual in the
\texttt{growth} data independently, as opposed to jointly in a
hierarchical model, we heighten the importance of including appropriate
prior information. We sample each posterior using \texttt{Stan}
\citep{stan_development_team_rstan_2021}, setting
\texttt{adapt\_delta\ =\ 0.95} and \texttt{max\_treedepth\ =\ 12} to
minimise false positive warning messages.

\texttt{Stan} has exceedingly robust sampling diagnostics. Should any
diagnostic flag an issue with the sampling of the posterior we can be
confident that something is amiss with the model. The converse is not
immediately true; a lack of warnings does not imply the model is
behaving appropriately, but it suggests we continue with further
posterior predictive checks
\citep{gabry_visualization_2019, gelman_bayesian_2020}. Figure
\ref{fig:warnings_all_priors} displays whether, for a specific
posterior, the call to \texttt{Stan} emits a warning message. The flat
prior consistently produces posteriors that emit warnings, with some
individuals particularly prone to warning messages (i.e.~warnings are
very correlated within individual columns), suggesting that their data
are less informative than other individuals. Warnings are correlated
within rows for the Hartmann et. al.~priors, indicating that some of the
priors are more suitable (replications 1 and 5) for the individuals in
the \texttt{growth} data. Amongst our results we note that the
covariate-specific approach produces fewer warnings than the
covariate-independent approach in both the single- or multi-objective
cases. This reflects the additional information available in the
covariate-specific setting, and that this information results in
improved priors. Warnings are particularly correlated within specific
priors (i.e.~across rows) for the covariate-independent approach,
suggesting that these priors are inappropriate for many individuals. The
multi-objective approach (third row of Figure
\ref{fig:warnings_all_priors}) produces a small number of additional
warnings above the equivalent single-objective approach (fifth row of
Figure \ref{fig:warnings_all_priors}), illustrating the trade-off
between priors that are as informative as possible (single-objective),
and those, that by being slightly less informative (multi-objective, and
thus better for more individuals), perform worse in settings where
additional information is required.

\begin{figure}

{\centering \includegraphics{plots/preece-baines-growth/fda-all-any-warnings-plot.png} 

}

\caption{Presence/absence of \texttt{Stan} warnings for all individuals (columns) in the FDA package \texttt{growth} data and replicate prior estimates (rows). Each replicate corresponds to a run of the optimisation process and thus a different prior, except the flat, improper prior which is identical for each replicate.}\label{fig:warnings_all_priors}
\end{figure}

\hypertarget{posteriors-for-an-individual-whose-data-are-uninformative}{%
\paragraph{Posteriors for an individual whose data are
uninformative}\label{posteriors-for-an-individual-whose-data-are-uninformative}}

The visual disparity between priors, displayed in Figure
\ref{fig:regression_prior_pred}, is still visible, but reduced, when
considering the posterior conditional mean
\(\pd(h(t; \theta) \mid Y_{n}, \lambda^{*})\) for individual \(n = 26\)
who, along with individuals \(n = 21, 27\), is the most warning-prone
individual under the flat-prior. We select this individual because we
are most interested in settings where additional regularisation by the
prior is necessary for stable and plausible posteriors. Figure
\ref{fig:regression_post_pred} displays the aforementioned posterior
conditional means and uncertainty intervals. We observe that the data
for individual \(26\) are unlikely to be fit well by this model, as it
lacks an obvious upper asymptote and mid-trajectory inflection that is
more typical of human growth, which the model is designed to capture.
The warnings are thus indicative of a lack of model flexibility.
However, we can improve the fit by adding information via the prior, as
the covariate-independent and covariate-specific posteriors,
particularly the multi-objective cases, seem to improve the fit for the
average posterior. The Hartmann et al.~posteriors are more plausible
than their corresponding prior, but struggle to capture the \emph{lack}
of growth spurts in this individual.

We reiterate here that the example intentionally difficult, and would be
challenging for any prior specification methodology. There is only one
individual's data, and these data are not equally informative for all
parameters. Thus the posterior is sensitive to the specific prior
information included in the model.

\begin{figure}

{\centering \includegraphics{plots/preece-baines-growth/regression-post-preds.pdf} 

}

\caption{\textbf{Posterior} for the model without noise $\pd(h(t; \theta) \mid Y_{n}, \lambda^{*})$ for individual $n = 26$, with this individual's data displayed using crosses (red \textcolor{myredhighlight}{+}). Panels are otherwise identical to Figure \ref{fig:regression_prior_pred}, \textit{except} that all intervals are now 95\% wide (though many are too narrow to be visible).}\label{fig:regression_post_pred}
\end{figure}

\hypertarget{connecting-replicability-in-the-prior-with-the-posterior}{%
\subsubsection{Connecting replicability in the prior with the
posterior}\label{connecting-replicability-in-the-prior-with-the-posterior}}

Does the relative similarity in prior and posterior conditional means
translate into similarity, and thus replicability, in the distributions
of \(\theta\) between replicates? We address this question by inspecting
the prior and posterior marginal densities of \(\theta\) again for
individual \(n = 26\). The priors and posteriors for all parameters are
displayed in Appendix
\ref{additional-information-for-the-preece-baines-example} {[}Figures
\ref{fig:pb_pop_prior_post_compare} and
\ref{fig:pb_cov_prior_post_compare}{]}, but it is difficult to pick out
performance trends from these plots. Instead we focus only on
\((h_{0}, \delta_{s}) \in \theta\), which are displayed in Figure
\ref{fig:small_cov_prior_post}. The flat prior produces a multimodal
posterior\footnote{We run \texttt{Stan} with the default 4 chains to
  detect convergence warnings for Figure \ref{fig:warnings_all_priors},
  but in Figure \ref{fig:small_cov_prior_post} we plot only one chain
  per replicate to better highlight multi-modal posteriors.} for our
parameters of interest, demonstrating the lack of stability when
computing the posterior and the need for some prior information. Subtle
differences in \(h(t; \theta)\) magnify considerably when we consider
\(\theta\) directly, with both the priors and posteriors for our
covariate-specific target exhibiting substantial variability. There
appears to be two distinct unimodal priors for \(h_{0}\) with similar
loss, suggesting that \(\tc(Y \mid \boldsymbol{X})\) does not provided
enough information to uniquely determine a prior distribution. However
both priors are significantly broader than the Hartmann et.~al.~priors.
The marginal priors, and posteriors, are more consistent for
\(\delta_{s}\) but variability persists. All of our priors remove the
possibility of a posterior for \(\delta_{s}\) with significant mass
above 2, as is desirable, because such solutions are both
physiologically implausible (they correspond to extremely fast growth
spurts) and are unsupported by the data from individual \(n = 26\).

\begin{figure}

{\centering \includegraphics{plots/preece-baines-growth/small-cov-priors-posteriors.pdf} 

}

\caption{A comparison of the priors (\textcolor{mymidblue}{blue}) produced by our method using the covariate-specific target (bottom two rows) using the multiple objective function ($\kappa = 0.2$) and the single objective function ($\kappa = \text{NA}$); Hartmann et al. (2020) (second row); with no prior displayed for the flat prior scenario (top row). The corresponding posteriors for individual $n = 26$ under each of these priors are displayed in (\textcolor{myredhighlight}{red}). Note that the y-axis is limited to values that clip some of the priors/posteriors for readability.}\label{fig:small_cov_prior_post}
\end{figure}

\hypertarget{example-summary}{%
\subsection{Example summary}\label{example-summary}}

The priors estimated by our procedure in this example are faithful to
the supplied information, but are partly constrained by the model's
inflexibility making it difficult to simultaneously match the \(t = 2\)
and \(t = 18\) targets in the covariate-specific case. They regularise
the posterior sufficiently enabling accurate posterior sampling (model
inadequacy notwithstanding), with the covariate-specific,
multi-objective method proving most useful, but are arguably over
concentrated and occasionally prevent the model from fitting the data
well. Uniqueness is improved by our secondary objective, but perfect
uniqueness across all replicates remains illusive and may not be
possible with only the information provided in
\(\tc(Y \mid \boldsymbol{X})\). We observe a small improvement in
replicability attributable to the secondary objective (see Appendix
\ref{additional-information-for-the-preece-baines-example} {[}Figures
\ref{fig:pb_pop_prior_post_compare} and
\ref{fig:pb_cov_prior_post_compare}{]}), with some amount of the
persistent variability a result of the stochastic optimisation procedure
proposed in Section
\ref{translating-elicited-prior-predictive-distributions}.

\hypertarget{priors-from-model-derived-quantities}{%
\section{Priors from model-derived
quantities}\label{priors-from-model-derived-quantities}}

Consider the linear model
\(Y = \boldsymbol{X}\boldsymbol{\beta} + \varepsilon\) for
\(n \times p\) design matrix \(\boldsymbol{X}\) and \(p\)-vector of
coefficients \(\boldsymbol{\beta}\) indexed by \(j = 1, \ldots, p\), and
where the noise \(\varepsilon\) has zero mean and variance
\(\sigma^{2}\). Suppose information about the fraction of variance
explained by the model is available -- from previous similar
experiments, or from knowledge of the measurement process -- in the form
of a plausible distribution for the coefficient of determination,
\(R^{2}\), which for this model can be computed as
\input{tex-input/r2-examples/0010-r2-definition.tex}\noindent assuming
that the columns of \(\boldsymbol{X}\) have been centred. Our aim is to
use our knowledge of \(R^{2}\) to set suitable priors for the regression
coefficients \(\beta\). This idea was the inspiration for a class of
shrinkage priors \citep{zhang_variable_2018, zhang_bayesian_2022}, but
we would like to make this idea applicable to a wider selection of prior
structures.

To illustrate the effect of including knowledge of \(R^{2}\) on
increasingly complicated priors, we investigate the selection of
appropriate hyperparameters for three priors for the regression
coefficients: two shrinkage priors, and a simple Gaussian prior. We
simultaneously vary the covariate-independent target distribution
\(\tc(R^{2})\) to assess:

\begin{itemize}
\tightlist
\item
  each prior's ability to faithfully encode the information present
  across a wide variety of target distributions;
\item
  uniqueness of the optimisation problem, and replicability of the
  single-objective variant of our optimisation algorithm, for each
  prior/target pair.
\end{itemize}

Note that we assume throughout that the noise \(\varepsilon\) is
distributed according to a Gaussian distribution with zero mean and
variance \(\sigma^{2}\), with an \(\text{InverseGamma}(a_{1}, b_{1})\)
prior on \(\sigma^{2}\), and we will seek to select suitable \(a_{1}\)
and \(b_{1}\) using our methodology. Finally, some asymptotic results
are known for the Gaussian prior, and in Appendix
\ref{additional-information-for-the-r2-example} we further assess
replicability by benchmarking our optimisation process against suitable
`true' (asymptotically) values.

\hypertarget{gaussian-prior}{%
\paragraph{Gaussian prior}\label{gaussian-prior}}

The Gaussian prior has only one hyperparameter \(\gamma\), which
controls the ratio of prior variability due to \(\boldsymbol{\beta}\) to
that of \(\varepsilon\), and is
\input{tex-input/r2-examples/0011-gaussian-prior-def.tex}\noindent
Hence, we denote hyperparameters
\(\boldsymbol{\lambda}_{\text{GA}} = (\gamma, a_{1}, b_{1})\) (for which
we seek optimum values) and parameters
\(\boldsymbol{\theta}_{\text{GA}} = (\boldsymbol{\beta}, \sigma^{2})\).

\hypertarget{dirichlet-laplace-prior-dir.-lap.}{%
\paragraph{Dirichlet-Laplace prior (Dir.
Lap.)}\label{dirichlet-laplace-prior-dir.-lap.}}

\citet{bhattacharya_dirichletlaplace_2015} introduce the
Dirichlet-Laplace shrinkage prior, which is defined for the
\(j\)\textsuperscript{th} coefficient such that
\input{tex-input/r2-examples/0012-dirichlet-laplace-definition.tex}\noindent
There is a single hyperparameter \(\alpha\), with smaller values of
\(\alpha\) yielding more sparsity in \(\boldsymbol{\beta}\). Thus we
denote \(\boldsymbol{\lambda}_{\text{DL}} = (\alpha, a_{1}, b_{1})\) and
\(\boldsymbol{\theta}_{\text{DL}} = (\boldsymbol{\beta}, \sigma^{2}, \phi_{1}, \ldots, \phi_{p}, \tau)\).

\hypertarget{regularised-horseshoe-prior-reg.-horse.}{%
\paragraph{Regularised horseshoe prior (Reg.
Horse.)}\label{regularised-horseshoe-prior-reg.-horse.}}

The regularised horseshoe of \citet{piironen_sparsity_2017} is the most
complex of the priors. With more intermediary stochastic quantities
between the hyperparameters and \(R^{2}\), as well as less linearity in
the relationship between the aforementioned, it is the most flexible of
the priors. These properties make finding optimal values of the
hyperparameters more challenging. The prior is
\input{tex-input/r2-examples/0013-regularised-horseshoe-def.tex}\noindent
where \(\text{Cauchy}^{+}\) denotes the Cauchy distribution truncated to
\([0, \infty)\). Equation \ref{eqn:regularised-horseshoe-def} leaves us
free to choose three prior-specific hyperparameters,
\((p_{0}, \nu, s^{2})\). Thus
\(\boldsymbol{\lambda}_{\text{HS}} = (p_{0}, \nu, s^{2}, a_{1}, b_{1})\)
and
\(\boldsymbol{\theta}_{\text{HS}} = (\boldsymbol{\beta}, \sigma^{2}, c^{2}, \omega, \delta_{1}, \ldots \delta_{p})\).
Whilst the regularised horseshoe is carefully designed to make
\((p_{0}, \nu, s^{2})\) interpretable and easy to choose, here we aim to
see if values of these hyperparameters can be chosen to match an
informative prior for \(R^{2}\).

\hypertarget{an-experiment-to-assess-prior-faithfulness}{%
\subsection{An experiment to assess prior
faithfulness}\label{an-experiment-to-assess-prior-faithfulness}}

How faithfully can we represent our knowledge of \(R^{2}\) in
\(\Pd(\theta \mid \lambda^{*})\) using each of the aforementioned
priors? To answer this question we consider several different
\(\text{Beta}(s_{1}, s_{2})\) distributions as our target
\(\tc(R^{2})\), and compare these to the prior predictive
\(\Pd(R^{2} \mid \lambda^{*})\) for optimal hyperparameter values
\(\lambda^{*}\). We choose \(\mathcal{S}\), the set of possible values
for which \(\{s_{1}, s_{2}\} \in \mathcal{S} \times \mathcal{S}\), to be
7 exponentially-spaced values between and including \(1 \mathop{/} 3\)
and \(3\) (i.e.~equally-spaced between \(\log(1 \mathop{/} 3)\) and
\(\log(3)\)). These values represent a variety of shapes and forms for
the supplied target predictive distribution for \(R^2\). Finally, we fix
\(n = 50\) and \(p = 80\) with entries in \(\boldsymbol{X}\) drawn from
a standard Gaussian distribution, and assess replicability using 10
independent runs for each prior and target.

\hypertarget{hyperparameter-support-lambda-and-tuning-parameters}{%
\subsubsection{\texorpdfstring{Hyperparameter support (\(\Lambda\)) and
tuning
parameters}{Hyperparameter support (\textbackslash Lambda) and tuning parameters}}\label{hyperparameter-support-lambda-and-tuning-parameters}}

The support \(\Lambda\) for the hyperparameters is defined in Table
\ref{tab:cap-lambda-def} in Appendix
\ref{additional-information-for-the-r2-example}. Note that for the
Dirichlet-Laplace prior, \citet{zhang_variable_2018} suggest bounding
\(\alpha \in [(\max(n, p))^{-1}, 1 \mathop{/} 2]\). In our experiments
we regularly encountered optimal values of \(\alpha\) on the lower
boundary, so we use instead \(1 \mathop{/} (3\max(n, p))\) as a lower
bound.

We run \texttt{pbbo} with \(S = 2 \times 10^{4}\) samples from the prior
predictive distribution, use \(d^{\text{AD}}\) as the discrepancy
function, and evaluate the log predictive discrepancy using
\(I = 2 \times 10^{4}\) samples from a \(\text{Uniform}(0, 1)\)
importance distribution. We run the first stage of the optimiser for
\(N_{\text{CRS2}} = 2000\) iterations, and subsequently perform single
objective Bayesian optimisation for \(N_{\text{batch}} = 1\) batch of
\(N_{\text{BO}} = 150\) iterations, using \(N_{\text{design}} = 50\)
points from the first stage. We choose to adopt the single objective
approach here to illustrate that the differences in flexibility also
induce differences in uniqueness, and to highlight issues in choosing a
prior for the additive noise parameter \(\sigma^{2}\).

\hypertarget{results-1}{%
\subsubsection{Results}\label{results-1}}

We first evaluate the faithfulness of the resulting prior distributions
by inspecting the densities \(\pd(R^{2} \mid \lambda^{*})\) and
\(\tp(R^{2})\) for the various targets (all distributions in this
example have corresponding densities). A selected subset of the pairs of
\((s_{1}, s_{2})\) values are displayed in Figure
\ref{fig:r2_roundtrip_full} (complete results are in Appendix
\ref{additional-information-for-the-r2-example} Figure
\ref{fig:r2_roundtrip_full_supp}). The faithfulness of the Gaussian
prior is universally poor, which we investigate further in Appendix
\ref{additional-information-for-the-r2-example}. Both shrinkage priors
perform better in cases where one of \(s_{1}\) or \(s_{2}\) is less than
1, with the regularised horseshoe performing better for the
\(s_{1} = s_{2} > 1\) cases. Interestingly, the results are not
symmetric in \(s_{1}\) and \(s_{2}\); the Dirichlet-Laplace prior is
able to match the \(s_{1} = 3, s_{2} = 0.69\) target well, with many of
regularised horseshoe replicates performing poorly; whilst the relative
performance is reversed for \(s_{1} = 0.69, s_{2} = 3\). There is also
perceptibly more variability in the regularised horseshoe replicates,
which suggests the optimisation problem is more challenging and the
predictive discrepancy objective is noisier. Finally, as the values of
\(s_{1}\) and \(s_{2}\) increase, the performance of the shrinkage
priors generally decreases. Across the full set of simulations, the
regularised horseshoe is evidently the most flexible (Appendix
\ref{additional-information-for-the-r2-example} Figure
\ref{fig:r2_roundtrip_full_supp}).

\begin{figure}

{\centering \includegraphics{plots/r2-examples/roundtrip-target-plot-small.pdf} 

}

\caption{Optimal prior predictive densities $\pd(R^{2} \mid \lambda^{*})$ for the three priors considered, for selected target densities. The title of each subpanel denotes the target, which is also plotted as a black dashed line. Each replicate of the Gaussian ('Gaussian' -- green), Dirichlet-Laplace ('Dir. Lap.' -- red), and regularised horseshoe ('Reg. Horse.' -- blue) is drawn in their respective colours. Density values are trimmed to $[0, 10]$ for readability.}\label{fig:r2_roundtrip_full}
\end{figure}

To assess replicability and uniqueness, we consider estimated optimal
hyperparameter values \(\lambda^{*}\) in each replicate. Figure
\ref{fig:r2_roundtrip_lambda} displays the estimates for \(s_{1} = 3\)
and \(s_{2} \in \{0.33, 0.69, 1.44, 3\}\), which corresponds to the
bottom row of Figure \ref{fig:r2_roundtrip_full}. The estimates for
\(\gamma\) and \(\alpha\), for the Gaussian and Dirichlet-Laplace priors
respectively, are consistent across replicates. This remains true even
for targets where the prior is not faithful to the target, e.g.~the
\(\text{Beta}(3, 3)\) target. There is more variability in the
hyperparameters of the regularised horseshoe prior, with \(p_{0}\) and
\(s^{2}\) seemingly nonunique and not replicable for only some targets,
and \(\nu\) consistently nonunique for all targets. Nonuniqueness in
\((a_{1}, b_{1})\) is visible for almost all prior/target combinations.
It is particularly striking for the Dirichlet-Laplace prior when
\(s_{2} \in \{0.33, 0.69\}\), where we observe consistent and excellent
fits/faithfulness to the target, but these do not correspond to
replicable estimates for \((a_{1}, b_{1})\). Such replicability
illustrates the anticipated difficulties of learning about the noise
(\(\sigma^{2}\)) and the corresponding hyperparameters.

We further assess uniqueness by inspecting the value of the objective at
the optima. The top row of Figure
\ref{fig:r2_roundtrip_discrep_at_optima} displays
\(\log(D(\lambda^{*}))\) using the Anderson-Darling discrepancy function
(as is used during optimisation) for each replicate, for the same subset
of targets considered in Figure \ref{fig:r2_roundtrip_lambda} (we
discuss the bottom row of Figure
\ref{fig:r2_roundtrip_discrep_at_optima} momentarily). Each value of
\(\log(D(\lambda^{*}))\) is the mean of 10 evaluations of
\(\log(D(\lambda))\) at each \(\lambda^{*}\) to minimise residual noise
in the objective. Figure \ref{fig:r2_roundtrip_discrep_at_optima}
suggests that a small fraction of the variability in
\(\boldsymbol{\lambda}_{\text{HS}}^{*}\) observed in Figure
\ref{fig:r2_roundtrip_lambda} is attributable to imperfect optimisation
because \(\log(D(\boldsymbol{\lambda}^{*}_{\text{HS}}))\) is the least
replicable. Conversely, we see that essentially none of the variability
in \(\boldsymbol{\lambda}^{*}_{\text{DL}}\), particularly
\((a_{1}, b_{1})\), is due to incomplete optimisation, but is instead an
issue of nonuniqeness inherent to the optimisation problem.

Our optimisation procedure has minimised \(\log(D(\lambda))\) using the
Anderson-Darling discrepancy function. This places extra emphasis on the
matching tails of the target, and thus the values in the top row of
Figure \ref{fig:r2_roundtrip_discrep_at_optima} differ from our
expectations given the results in the bottom row of Figure
\ref{fig:r2_roundtrip_full}. Take, for example, the
\(s_{1} = 3, s_{2} = 0.69\) case. It is plainly evident from Figure
\ref{fig:r2_roundtrip_full} that the regularised horseshoe prior
provides a better fit to the target distribution at
\(\boldsymbol{\lambda}^{*}_{\text{HS}}\). And yet the corresponding
\(\log(D(\boldsymbol{\lambda}_{\text{HS}}^{*}))\) values in Figure
\ref{fig:r2_roundtrip_discrep_at_optima} suggest that it is considerably
worse that the Gaussian prior at
\(\boldsymbol{\lambda}_{\text{GA}}^{*}\). To reconcile this apparent
contradiction, we recompute \(\log(D(\lambda))\) at the same optima but
use the CramÃ©r-Von Mises discrepancy function. These values are
displayed in the bottom row of Figure
\ref{fig:r2_roundtrip_discrep_at_optima}, whose values closely match our
expectations given Figure \ref{fig:r2_roundtrip_full}. Given the range
of behaviours of \(\pd(R^{2} \mid \lambda^{*})\) for all the optima, we
can conclude that the Anderson-Darling more heavily penalises
over-estimation of the tails of \(\pd(R^{2} \mid \lambda^{*})\) than
under-estimation. This does not discount it as an optimisation
objective, but does complicate comparisons between competing priors.

\begin{figure}

{\centering \includegraphics{plots/r2-examples/roundtrip-target-lambda-tiny.pdf} 

}

\caption{Optimal values $\lambda^{*}$ for each of the three priors considered. Columns contain (possibly prior-specific) hyperparameters, with the point colour corresponding to a specific prior.  The target beta densities (denoted by the row panel titles) correspond to the bottom row of Figure \ref{fig:r2_roundtrip_full}.}\label{fig:r2_roundtrip_lambda}
\end{figure}

\begin{figure}

{\centering \includegraphics{plots/r2-examples/roundtrip-discrep-at-optima.pdf} 

}

\caption{Total log predictive discrepancy at the optima $\log(D(\lambda^{*}))$. The target densities (denoted in the column titles) correspond to the bottom row of Figure \ref{fig:r2_roundtrip_full} (i.e. the same as Figure \ref{fig:r2_roundtrip_lambda}). Each point corresponds to one of the 10 distinct replicates, and its value is the mean of 10 evaluations of $\log(D(\lambda^{*}))$ for the same $\lambda^{*}$. The top row displays the final values of $\log(D(\lambda^{*}))$ using the Anderson-Darling discrepancy function, used during optimisation. For comparison, the bottom row also displays $\log(D(\lambda^{*}))$ at the same optima but instead uses the CramÃ©r-von Mises discrepancy functionton when evaluating $\log(D(\lambda^{*}))$.}\label{fig:r2_roundtrip_discrep_at_optima}
\end{figure}

\hypertarget{example-summary-1}{%
\subsection{Example summary}\label{example-summary-1}}

This example illustrates the use of a model-derived, nonobservable
quantity about which we have prior information as the basis for an
informative prior. The most flexible shrinkage model (the regularised
horseshoe prior) was clearly the most faithful to the supplied
information in almost all cases. Conversely, the Gaussian prior has the
most replicability and uniqueness, but the lack of faithfulness means it
is unsuitable to use as a prior when seeking to use a Beta prior on
\(R^{2}\). The example also illustrates the difficulty of learning about
the prior for the additive noise term, which is related but distinct
from our idea of uniqueness. Future attempts to ameliorate this
difficulty by adopting the multi-objective approach would merely hide
the issue; we would always select the inverse gamma prior that maximises
the standard deviation of \(\sigma^{2}\) by being on the boundary of
\(\Lambda\). Such a prior for \(\sigma^{2}\) would unlikely prove
appropriate nor represent our prior knowledge.

\hypertarget{calibrating-a-cure-fraction-survival-model}{%
\section{Calibrating a cure fraction survival
model}\label{calibrating-a-cure-fraction-survival-model}}

Cure models \citep{peng_cure_2014, amico_cure_2018} for survival data
are useful when a cure mechanism is physically plausible \emph{a
priori}, and when individuals are followed up for long enough to be
certain all censored individuals in our data are ``cured''. Such lengthy
follow ups are not always possible, but a cure model remains plausible
when a large fraction of the censored observations occur after the last
observed event time. However, we cannot distinguish in the right tail of
the survival time distribution between censored uncured individuals and
genuinely cured individuals.

Suppose we possess prior knowledge on the fraction of individuals likely
to be cured, and the distribution of event times amongst the uncured. In
this example we ask: can we translate this information into a reasonable
prior for the parameters in a cure model?

There are several properties of this model that make it an interesting
subject for prior specification methodology. The observed quantity, and
thus the target distribution, is of mixed discrete/continuous type due
to censoring. Additionally, we specify a model with a nontrivial
correlation structure, about which we wish to specify an informative
prior. Eliciting informative priors for correlation structures is known
to be challenging. Finally, identifiability is known to be challenging
in cure models \citep{peng_cure_2014}, and so the model is a demanding
test of our regularisation procedure.

\hypertarget{target-survival-time-distribution-and-covariate-generation}{%
\subsection{Target survival time distribution and covariate
generation}\label{target-survival-time-distribution-and-covariate-generation}}

Consider individuals \(n = 1, \ldots, N\) with event times \(Y_{n}\) and
censoring times \(C_{n}\), such that \(Y_{n} \in (0, C_{n}]\). The
assumptions underlying a cure fraction model imply almost complete
separation between event times and censoring times. Suppose that
individuals are followed up for an average of 21 units of time, with
those who experience the event doing so a long time before the end of
follow up. Furthermore, suppose we believe that, \emph{a priori},
\(5\%\) of the patients will be cured, with \(0.2\%\) of events censored
due to insufficient follow up.

A target distribution that is consistent with our beliefs comprises a
point mass of \(0.05\) at \(C_{n}\), and a lognormal distribution with
location \(\mu^{\text{LN}} = \log(3)\) and scale
\(\sigma^{\text{LN}} = 2 \mathop{/} 3\) for \(Y_{n} < C_{n}\). This
choice of lognormal has \(99.8\%\) of its mass residing below 21, and
thus produces event times that are ``well separated'' from the censoring
time. Denoting the lognormal CDF with
\(\text{LogNormal}(Y; \mu, \sigma^{2})\), we define the target CDF
\input{tex-input/surv-example/0021-surv-target-cdf-definition.tex}\noindent
where
\(Z_{n} = \text{LogNormal}(C_{n}; \mu^{\text{LN}}, \left(\sigma^{\text{LN}}\right)^{2})\)
is the required normalising constant. This individual-specific
construction of \(\tc(Y_{n} \mid C_{n})\) implies that \(R = N\) (where
\(R\) is the upper limit of the sum in Equation
\ref{eqn:theoretical-discrep-definition-covariate}) as the censoring
time \(C_{n}\) functions as a covariate.

We simulate data for this example with \(N = 50\) individuals, each with
\(B = 4\) correlated covariates. In line with our target distribution,
simulated censoring times are distributed such that
\(C_{n} \sim 20 + \text{Exp}(1)\). We sample a single correlation matrix
\(\boldsymbol{Q} \sim \text{LKJ}(5)\)
\citep{lewandowski_generating_2009} and subsequently covariates
\(\tilde{\mathbf{x}}_{n} \sim \text{MultiNormal}(\boldsymbol{0}, \boldsymbol{Q})\).
This results in marginally-standardised yet correlated covariates.

\hypertarget{model}{%
\subsection{Model}\label{model}}

A cure model for survival data, expressed in terms of its survival
function, is
\input{tex-input/surv-example/0009-cure-model-surv-def.tex}\noindent
where a proportion \(\pi \in (0, 1)\) of the population are \emph{cured}
and never experience the event of interest. The survival times for the
remaining \(1 - \pi\) proportion of the population are distributed
according to the \emph{uncured} survival function
\(\tilde{S}(Y \mid \tilde{X}, \tilde{\theta})\). We use the tilde in
\(\tilde{X}\) and \(\tilde{\theta}\) to denote quantities specific to
the uncured survival distribution, and denote
\(\theta = (\pi, \tilde{\theta})\) to align with our general notation.

A right censored event time has \(Y_{n} = C_{n}\). The censoring
indicator \(\delta_{n} = \mathbbm{1}_{\left\{Y_{n} < C_{n}\right\}}\) is
zero for right censored events, and is one for uncensored/observed
events. We denote with \(\tilde{\mathbf{x}}_{n}\) the
\(n\)\textsuperscript{th} row of the \(N \times B\) covariate matrix
\(\tilde{\boldsymbol{X}}\). Our model supposes that the uncured event
times are distributed according to a Weibull regression model, with
survival function
\(\tilde{S}(Y_{n} \mid \tilde{\theta}, \tilde{\mathbf{x}}_{n}, C_{n})\)
and hazard
\(\tilde{h}(Y_{n} \mid \tilde{\theta}, \tilde{\boldsymbol{x}}_{n}, C_{n})\)
such that
\input{tex-input/surv-example/0010-weibull-surv-and-hazard-def.tex}\noindent
with \(\tilde{\theta} = (\gamma, \beta_{0}, \boldsymbol{\beta})\). The
likelihood for the \(n\)\textsuperscript{th} individual is
\input{tex-input/surv-example/0011-weibull-likelihood-def.tex}\noindent
We complete the model by specifying a \(\text{Beta}(a_{\pi}, b_{\pi})\)
prior for \(\pi\). To align the notation in this example with that
introduced in Section
\ref{translating-elicited-prior-predictive-distributions} we denote
\(Y = (Y_{n})_{n = 1}^{N}\) and
\(X = (C_{n}, \tilde{\mathbf{x}}_{n})_{n = 1}^{N}\). Note that we are
using \(X\) to represent \emph{all} information that must be conditioned
on, including the censoring times. This is necessary because, in our
more general notation, the support of \(Y \mid X_{r}\) is truncated to
an interval that depends on \(X_{r}\), making the censoring times
necessary to fully-specify \(Y \mid X_{r}\).

Our use of the multivariate skew-normal distribution has two
motivations. The skewness is necessary to incorporate the nonlinear
relationship between the hazard and the effect of the covariates, and a
covariance structure is used to account for fact that not all the
elements of \(\boldsymbol{\beta}\) can be large simultaneously. We
assume that \(\tilde{\boldsymbol{X}}\) is marginally (column-wise)
standardised, and can thus decompose
\(\boldsymbol{S} = \text{diag}(s_{\beta}) \,\, \boldsymbol{\Omega} \,\, \text{diag}(s_{\beta})\)
where \(s_{\beta}\) is the scale of the prior marginals of
\(\boldsymbol{\beta}\). The standardisation allows us to use only one
\(s_{\beta}\) instead of one per covariate. We elect to parameterise
\(\boldsymbol{\Omega}\) using the \((B - 1)! = 6\) elements that
uniquely determine its Cholesky factor, which we denote
\(\boldsymbol{\omega} = (\omega_{1}, \ldots, \omega_{6})^{\top} \in [-1, 1]^{6}\).
These elements are transformed into \(\boldsymbol{\Omega}\) using the
partial correlation method of \citet{lewandowski_generating_2009}, also
employed by the \texttt{Stan} math library
\citep{stan_development_team_stan_2022}. The \(B\)-vector
\(\boldsymbol{\eta}\) controls, but is not equal to, the marginal
skewness for each element of \(\boldsymbol{\beta}\) using the
multivariate skew-normal definition of
\citet{azzalini_multivariate_1996}, as implemented in the \texttt{sn}
package \citep{azzalini_sn_2022}. We can now define
\(\lambda = (\alpha, \beta, \mu_{0}, \sigma^{2}_{0}, s_{\beta}, \boldsymbol{\omega}, \boldsymbol{\eta}, a_{\pi}, b_{\pi})^{\top}\),
with the upper and lower limits that define \(\Lambda\) specified in
Table \ref{tab:surv-cap-lambda-def} in Appendix
\ref{additional-information-for-the-cure-fraction-survival-example}.

\hypertarget{tuning-parameters-and-further-details}{%
\subsection{Tuning parameters and further
details}\label{tuning-parameters-and-further-details}}

In this example we again employ the multi-objective approach with
\(N(\lambda)\) as defined in Equation \ref{eqn:second-objective-def}. We
use \(N_{\text{CRS2}} = 2000\) CRS2 iterations, followed by
\(N_{\text{batch}} = 3\) batches of multi-objective Bayesian
optimisation using \(N_{\text{BO}} = 200\) iterations per batch,
carrying forward \(N_{\text{design}} = 60\) points between batches. The
predictive discrepancy function, \(D(\lambda)\), is evaluated
empirically using \(S_{r} = 2 \times 10^{4}\) samples from the prior
predictive, and evaluated using \(I_{r} = 5 \times 10^3\) importance
samples from an appropriate mixed discrete/continuous importance
density. To facilitate assessing uniqueness issues in this model, we
also run single-objective optimisation with the same tuning parameters.

\hypertarget{results-2}{%
\subsection{Results}\label{results-2}}

\hypertarget{choosing-kappa-for-the-multi-objective-approach}{%
\subsubsection{\texorpdfstring{Choosing \(\kappa\) for the
multi-objective
approach}{Choosing \textbackslash kappa for the multi-objective approach}}\label{choosing-kappa-for-the-multi-objective-approach}}

We inspect the Pareto frontiers and compute the minimum loss points for
6 values of \(\kappa \in \{0.1, 0.2, 0.3, 0.5, 1, 2\}\). These are
displayed in Figure \ref{fig:surv_ex_pareto_fronts}. To reiterate, the
assumption is that nearby points on the Pareto frontier are ``similar''
priors for \(\pd(\theta \mid \lambda)\).

Maximum and minimum values for \(\kappa\) yield a number of minimum loss
points on the extremes of the Pareto frontier. These points correspond
to unsuitable values for \(\lambda\) due to a lack of faithfulness,
which we will demonstrate momentarily. The remaining options for
\(\kappa\) result in similar minimum loss points, illustrating that the
minimum loss point is constant, or very similar, across a range of
\(\kappa\) values. Such insensitivity is ideal as we can obtain sensible
solutions for a wide variety of \(\kappa\) values. Made to choose, we
would select \(\kappa = 0.3\) as this simultaneously minimises the
variability in loss and both objective functions.

\begin{figure}

{\centering \includegraphics{plots/synthetic-survival/all-pareto-fronts-by-kappa.pdf} 

}

\caption{Pareto frontiers for the survival example and different values of $\kappa$. Note that the range associated with the colour scale differ between panels. The red crosses ($\color{myredhighlight}{+}$) indicate the minimum loss point on each frontier, for each value of $\kappa$.}\label{fig:surv_ex_pareto_fronts}
\end{figure}

\hypertarget{faithfulness}{%
\subsubsection{Faithfulness}\label{faithfulness}}

We assess faithfulness by inspecting the prior predictive distributions
at the optima for similarity to the target, which Figure
\ref{fig:surv_ex_ppd_y} displays for the randomly selected individual
\(n = 9\) in our simulated population (other individuals are not
visually distinguishable). In addition to the possible values of
\(\kappa\), the optimal prior predictive distributions are also
displayed using the single objective approach for reference. The fits
are similar across different \(\kappa\) and close to those obtained
using the single objective approach, except for the maximum value of
\(\kappa\). By overly valuing the secondary objective, the negative log
mean standard deviation, a fraction of the maximum \(\kappa\) fits are
considerably worse. The poor fits correspond to the minimum loss points
in the bottom-right corner of the \(\kappa = 2\) panel in Figure
\ref{fig:surv_ex_pareto_fronts}. This similarity does little to
alleviate the uniqueness issues we will discuss in the following
section.

\begin{figure}

{\centering \includegraphics{plots/synthetic-survival/subset-indivs-ppd-y-dens.png} 

}

\caption{Estimated optimal prior predictive densities $\pd(Y_{n} \mid \lambda^{*})$ (red/blue lines and dots) and target densities $\tp(Y_{n} \mid C_{N})$ (black lines and crosses) for randomly selected individual $n = 9$. The continuous portions of the densities are displayed as lines, with the discrete/censored portion displayed as a point at $Y_{n} = C_{n}$. The top rows (red) correspond to the multi-objective approach using the values of $\kappa$ in the row titles, with the bottom row (blue) displaying the single objective results. Densities are truncated to $[0, 0.45]$ for readability.}\label{fig:surv_ex_ppd_y}
\end{figure}

\hypertarget{replicability-and-uniqueness}{%
\subsubsection{Replicability and
uniqueness}\label{replicability-and-uniqueness}}

\begin{landscape}

\begin{figure}

{\centering \includegraphics{plots/synthetic-survival/all-theta-over-kappa.png} 

}

\caption{Estimated optimal prior marginal densities of $\pd(\theta \mid \lambda^{*})$ for each component of $\theta$ in the survival example. The top six rows (red) are obtained using the multi-objective approach, with the $\kappa$ value specified in each row. The bottom row (blue) uses the single, predictive discrepancy objective. Densities are truncated to $[0, 1]$ for readability.}\label{fig:surv_ex_ppd_theta}
\end{figure}
\end{landscape}

We now evaluate both the replicability of our multi-objective approach
and the uniqueness of the optimisation problem. Figure
\ref{fig:surv_ex_ppd_theta} displays the marginals of \(\theta\) for
each value of \(\kappa\) and independent replicate. The single objective
approach consistently locates the degenerate, non-unique solution where
all the variation in the uncensored event times is attributed to the
baseline hazard shape \(\gamma\) and the intercept \(\beta_{0}\): note
that all the mass for \(\boldsymbol{\beta}\) (the regression
coefficients) is close to 0. This combination is evidently poorly
identified, and further calculation reveals that only the derived
product \(\gamma \exp{\beta_{0}}\) is uniquely determined. Furthermore,
the concentration around \(\boldsymbol{\beta} = 0\) means these priors
are unlikely to be efficient for inferring the (possible) relationship
between covariates and outcome -- a very strong signal in the data would
be needed to overcome this prior.

Our multi-objective approach produces a more reasonable and disperse
prior, but still does not admit a unique optimal prior\footnote{To be
  certain that the lack of uniqueness is attributable to the
  specification of the optimisation problem, and not due to numerically
  imperfect or incomplete optimisation, we investigate the objective
  values at the final optima in Appendix
  \ref{objective-values-at-optima}.}. The typical marginal prior for
\(\boldsymbol{\beta}\) has been widened, yet for small values of
\(\kappa\) the optimal priors are still far from unique for
\((\gamma, \beta_{0})\). When \(\kappa = 2\) the process regularly
produces a marginal prior for the cure fraction \(\pi\) that gives
considerable mass to values of \(\pi > 0.3\), which is incongruent with
our target. This is also visible in the censored portions of the prior
predictive estimates \(\pd(Y_{n} \mid \lambda^{*}, C_{n})\) displayed in
Figure \ref{fig:surv_ex_ppd_y}.

\begin{figure}

{\centering \includegraphics{plots/synthetic-survival/beta-covariance-pair.pdf} 

}

\caption{Contours of the log prior density $\log(\pd(\beta_{3}, \beta_{4} \mid \lambda^{*}))$ at the optima. The left column corresponds to the single objective approach, with the multi-objective approach using $\kappa = 0.3$ displayed in the right column. Note that, for clarity, we only plot the final 12 of 30 replicates, with unique colouring for each replicate.}\label{fig:surv_ex_beta_cov}
\end{figure}

Eliciting covariance structures is challenging, and in this example we
opt to include a covariance matrix in the hyperparameters for our model.
In Figure \ref{fig:surv_ex_beta_cov} we display the bivariate prior
marginal densities for two elements of \(\boldsymbol{\beta}\),
specifically \(\beta_{3}\) and \(\beta_{4}\), for both the
multi-objective approach with \(\kappa = 0.3\) and the single objective
approach. Nonuniqueness is visible in both sets of estimates. There are
marginal densities of both positive and negative marginal skewness, and
pairwise correlation. The wider typical marginal for
\((\beta_{3}, \beta_{4})\) obtained using the multi-objective approach
is again visible in the right panel of Figure
\ref{fig:surv_ex_beta_cov}.

\hypertarget{example-summary-2}{%
\subsection{Example summary}\label{example-summary-2}}

Our procedure estimates priors that faithfully represent provided
information about the survival distribution. Uniqueness, known to be
challenging for these models, is very difficult to induce and results in
suboptimal marginal priors for \(\boldsymbol{\beta}\). We specifically
highlight the difficulties with uniqueness associated with the
covariance structure for a vector of covariate coefficients. Our
procedure is moderately replicable -- the noise in Figure
\ref{fig:surv_ex_pareto_fronts} would, ideally, be smaller.

In the information we supply via \(\tc(Y_{n} \mid C_{n})\), we are
completely certain of the fraction of cured patients \emph{a priori}.
Such certainty is unlikely to be uncovered when eliciting information
from experts. A more elaborate construction of
\(\tc(Y_{n} \mid C_{n})\), or elaborate methodology, may be able to
represent such uncertainty, but the example remains challenging without
this additional complication.

\hypertarget{conclusion}{%
\section{Conclusion}\label{conclusion}}

In this paper we develop methodology, and software, for specifying
priors given predictive information about an observable or model-derived
quantity. We employ a CDF-based, multi-objective global optimisation
approach to this translation problem to make our approach widely
applicable. Adopting a global optimisation approach allows any kind of
model to be specified and optimised, not just those for which we can
compute reparameterisation gradients. The global optimisation approach
also allows us to provide our functionality directly in \texttt{R}, with
which we envisage the majority of the users of our method will be
familiar. Our CDF-based predictive discrepancy is also generic as it
permits continuous, discrete, and mixed observable types. We apply our
methodology in three challenging example models, each of which we
interrogate for faithfulness, identifiability, and uniqueness. Each
example is of moderate dimension (3--17), with each representing a
difficult structural elicitation problem. Finally, our delineation
between elicitation and translation, with our emphasis on the latter, is
a contribution to an under-explored area of prior specification.

Our inspiration, for both methodology and examples, arises from
applications and models we have encountered in applied work. The
Preece-Baines model is a typical complex, nonlinear regression model for
an intuitive and well understood observable quantity, but for which the
model parameters are not easily understood. Setting a prior for models
congruent with our knowledge is difficult without a method for
translation such as we have proposed. We previously considered a
survival model similar to the cure fraction model, where we knew \emph{a
priori} the fraction of cured/censored observations and a distribution
of likely survival times, in our earlier work
\citep{manderson_combining_2022}. Setting an appropriate prior for this
model proved challenging, and would have benefited greatly from the
translation methodology introduced in this paper. Finally, prior
knowledge on \(R^{2}\) has proved a valuable mathematical basis for the
R2-D2 shrinkage prior \citep{zhang_bayesian_2022}, and more generally
there are numerous model-derived quantities about which practitioners
possess prior information. Methods for translation are valuable in this
setting, as information about such model-derived quantities is often
difficult to express. An envisaged future example of this type considers
clustering models. In that setting we elicit an informative prior for
number of clusters, or the typical size of a cluster, which are derived
from the clustering model. Such quantities are readily reasoned about by
experts, as opposed to the parameters governing each cluster. Including
this type of information in complex models seems critical for stable and
reliable Bayesian inference.

One limitation of the current work is that we only partly address
non-uniqueness for flexible models and uninformative target
distributions. In these settings we emphases that our methodology
remains valuable as a means to assess the implications of a particular
target distribution on a specific model. For specific model-target pairs
where uniqueness remains challenging, our methodology can still provide
useful insight into consequences of certain
\(\tc(Y \mid \boldsymbol{X})\). We can delineate between components of
\(\lambda\) that are well identified and thus consistently estimated,
and those that are not. Furthermore, we can directly inspect
\(\tc(Y \mid X_{r})\) different significantly from
\(\Pd(Y \mid \lambda^{*}, X_{r})\), and consider if such differences are
attributable to model inflexibility or implausible targets. Finally, we
are compelled to assess our choice of which components should make up
\(\lambda\), and whether we have other information that we could employ
to fix certain components within \(\lambda\) (e.g.~the fixed prior for
the noise in the human height example).

\hypertarget{acknowledgments-and-data-availability}{%
\section*{Acknowledgments and data
availability}\label{acknowledgments-and-data-availability}}
\addcontentsline{toc}{section}{Acknowledgments and data availability}

We thank Daniela De Angelis and Mevin Hooten for their feedback on an
earlier version of this manuscript.

This work was supported by The Alan Turing Institute under the UK
Engineering and Physical Sciences Research Council (EPSRC)
{[}EP/N510129/1{]} and the UK Medical Research Council {[}programme
codes MC\_UU\_00002/2 and MC\_UU\_00002/20{]}. No original data were
generated as part of this study, the \texttt{growth} data used in
Section \ref{a-human-aware-prior-for-a-human-growth-model} are available
as part of the \texttt{fda} package for \texttt{R}
\citep{ramsay_fda_2022} available on \texttt{CRAN}
(\url{https://cran.r-project.org/}).

\newpage

\renewcommand{\thesubsection}{\Alph{subsection}}
\setcounter{subsection}{0}

\hypertarget{appendices}{%
\section*{Appendices}\label{appendices}}
\addcontentsline{toc}{section}{Appendices}

\hypertarget{importance-sampling}{%
\subsection{Importance sampling}\label{importance-sampling}}

Appropriate importance distributions are crucial to obtaining an
accurate and low variance estimate of
\(D(\lambda \mid \boldsymbol{X})\). For values of \(\lambda\) far from
optimal, \(\Pd(Y \mid \lambda, \boldsymbol{X})\) can differ considerably
from \(\tc(Y \mid \boldsymbol{X})\). Given a specific \(X_{r}\) we
require an importance distribution \(\Q(Y \mid X_{r})\) that places
substantial mass in the high probability regions of both
\(\tc(Y \mid X_{r})\) and \(\Pd(Y \mid \lambda, X_{r})\), as it is in
these regions that \(d(\cdot, \cdot)\) is largest. But we cannot exert
too much effort on finding these densities as they are specific to each
value of \(\lambda\), and must be found anew for each \(\lambda\).

We use three quantities to guide our choice of \(\Q(Y \mid X_{r})\),
these being the support \(\mathcal{Y}\), the samples
\(\boldsymbol{y}_{r}^{(\Pd)} \sim \Pd(Y \mid \lambda, X_{r})\), and the
samples \(\boldsymbol{y}_{r}^{(\tc)} \sim \tc(Y \mid X_{r})\). Of
primary concern is the support. If \(\mathcal{Y} = \mathbb{R}\) then we
use a mixture of Student-\(t_{5}\) distributions; for
\(\mathcal{Y} = \mathbb{R} = (0, \infty)\) we employ a mixture of gamma
distributions; and for \(\mathcal{Y} = (0, a]\) with known \(a\), we opt
for a mixture of Beta distributions with a discrete component at
\(Y = a\). The parameters of the mixture components are estimated using
the method of moments. Specifically, denoting the empirical mean of
\(\boldsymbol{y}_{r}^{(\Pd)}\) as \(\hat{\mu}^{(\Pd)}\) and the
empirical variance by \(\hat{v}^{(\Pd)}\), with \(\hat{\mu}^{(\tc)}\)
and \(\hat{v}^{(\tc)}\) defined correspondingly for
\(\boldsymbol{y}_{r}^{(\tc)}\), Table
\ref{tab:importance-sampling-appendix-table} details our method of
moments estimators for the mixture components.

In this paper we limit ourselves to one dimensional \(\mathcal{Y}\),
where importance sampling is mostly well behaved or can be tamed using a
reasonable amount of computation. This covers many models, and with the
covariate-specific target it includes regression models. It is harder to
elicit \(\tc(Y \mid \boldsymbol{X})\) for higher dimensional data
spaces, and the difficulties with higher dimensional importance sampling
are well known.

\input{tex-input/pbbo-methodology/0071-importance-sampling-appendix-table.tex}

\hypertarget{evaluating-dlambda-mid-boldsymbolx}{%
\subsection{\texorpdfstring{Evaluating
\(D(\lambda \mid \boldsymbol{X})\)}{Evaluating D(\textbackslash lambda \textbackslash mid \textbackslash boldsymbol\{X\})}}\label{evaluating-dlambda-mid-boldsymbolx}}

For both numerical stability and optimisation performance
\citep{eriksson_scalable_2021, snoek_input_2014} we evaluate
\(D(\lambda \mid \boldsymbol{X})\) on the log scale. This is because far
from optimal values of \(\lambda\) have corresponding
\(D(\lambda \mid \boldsymbol{X})\) many orders of magnitude larger than
near optimal values of \(\lambda\). Furthermore, the Gaussian process
approximation that underlies Bayesian optimisation assumes constant
variance, necessitating a log or log-like transformation.

Suppose again that we sample
\(\boldsymbol{y}_{r}^{(\Pd)} \sim \Pd(Y \mid \lambda, X_{r})\), from
which we form the ECDF
\(\hat{\Pd}(Y \mid \lambda, X_{r}, \boldsymbol{y}_{r}^{(\Pd)})\). We
also select an appropriate importance distribution \(\Q(Y \mid X_{r})\)
and density \(\q(Y \mid X_{r})\) using Appendix
\ref{importance-sampling}, and sample importance points
\((y_{i, r})_{i = 1}^{I_{r}} \sim \Q(Y \mid X_{r})\). Define the
intermediary quantity \(z(y_{i, r})\) as
\input{tex-input/pbbo-methodology/0020-log-discrep-func-defs.tex}\noindent
and then rewrite Equation
\eqref{eqn:practical-discrep-definition-covariate-importance} to read
\input{tex-input/pbbo-methodology/0022-importance-discrepancy-covariate-definition.tex}\noindent
All \(\log(\sum \exp\{\cdot\})\) terms are computed using the
numerically stable form \citep{blanchard_accurately_2021}.

Accurately evaluating \(\log(d(\cdot, \cdot))\) in Equation
\eqref{eqn:log-discrep-func-def} involves managing the discrete nature
of the ECDF (that it returns exactly zero or one for some inputs), and
using specialised functions for each discrepancy to avoid issues with
floating point arithmetic. We compute
\(\log(d^{\text{CvM}}(\cdot, \cdot))\) using
\input{tex-input/computing-log-discrep-functions/0010-computing-log-cvm.tex}\noindent
where \(\mathcal{T}(y_{i, r}) = \log(\tc(y_{i, r}))\). The log-CDF
(LCDF) is often more numerically accurate for improbable values of
\(y_{i, r}\), and so our methodology assumes that it is this LCDF form
in which the target distribution is supplied. However, because the ECDF
can return exact zero/one values there is no way to perform this
computation on the log scale. We thus employ high precision floating
point numbers when exponentiating the LCDF values, using \texttt{Rmpfr}
\citep{maechler_rmpfr_2021}, to avoid evaluating \(\log(0)\).

For \(\log(d^{\text{AD}}(\cdot, \cdot))\), additional care must be taken
as the denominator of \(d^{\text{AD}}\) in Equation
\eqref{eqn:discrepancies-definitions} tends to underflow to zero. Thus
we evaluate it using
\input{tex-input/computing-log-discrep-functions/0011-computing-log-ad.tex}\noindent
where \(\texttt{log1mexp}(x) = \log(1 - \exp\{-x\})\) is implemented by
the \texttt{Rmpfr} package \citep{maechler_accurately_2012}. Such
precision is necessary for improbably large values of \(y_{i, r}\) under
\(\tc\), as the CDF/LCDF often rounds to 1/0 (respectively). It is not
always feasible to evaluate Equation \eqref{eqn:computing-log-ad} with
sufficient accuracy to avoid under/over-flow issues -- it requires a
high-precision implementation of \(\mathcal{T}(y_{i, r})\) for extreme
\(y_{i, r}\) and many additional bits of precision for both \(y_{i, r}\)
and the result. In these settings we revert to
\(\log(d^{\text{CvM}}(\cdot, \cdot))\).

\hypertarget{algorithmic-descriptions-of-the-optimisation-process}{%
\subsection{Algorithmic descriptions of the optimisation
process}\label{algorithmic-descriptions-of-the-optimisation-process}}

\hypertarget{crs2-as-an-initialiser-for-bayesian-optimisation}{%
\subsubsection{CRS2 as an initialiser for Bayesian
optimisation}\label{crs2-as-an-initialiser-for-bayesian-optimisation}}

Algorithm \ref{alg:crs2-algorithmic-description} describes our use of
CRS2 \citep{kaelo_variants_2006} to obtain a suitable design to
initialise the Bayesian multi-objective optimisation approach in step 2.

\input{tex-input/pbbo-methodology/0052-crs2-algorithmic-description.tex}

\noindent

\hypertarget{mspot}{%
\subsubsection{MSPOT}\label{mspot}}

Algorithm \ref{alg:mspot-algorithmic-description} describes, in our
notation, the MSPOT \citep{zaefferer_mspot_2012} algorithm for two
objectives. Note that within the algorithm we suppress each objective's
dependence on \(\boldsymbol{X}\) for brevity.

\input{tex-input/pbbo-methodology/0053-mspot-algorithmic-description.tex}

\hypertarget{inter-batch-resampling}{%
\subsubsection{Inter batch resampling}\label{inter-batch-resampling}}

Algorithm \ref{alg:resample-batch-algorithmic-description} describes our
inter-batch resampling algorithm that we occasionally adopt in stage two
of our optimisation process.

\input{tex-input/pbbo-methodology/0054-resample-batch-algorithmic-description.tex}

\FloatBarrier

\hypertarget{additional-information-for-the-preece-baines-example}{%
\subsection{Additional information for the Preece-Baines
example}\label{additional-information-for-the-preece-baines-example}}

\hypertarget{hyperparameter-support-lambda}{%
\subsubsection{\texorpdfstring{Hyperparameter support
\(\Lambda\)}{Hyperparameter support \textbackslash Lambda}}\label{hyperparameter-support-lambda}}

Table \ref{tab:pb-cap-lambda-def} contains the upper and lower limits
for each hyperparameter, thus defining the feasible region \(\Lambda\).

\input{tex-input/preece-baines-growth/0011-pb-cap-lambda-def.tex}

\noindent

\hypertarget{hartmann_flexible_2020-priors}{%
\subsubsection{\texorpdfstring{\citet{hartmann_flexible_2020}
priors}{@hartmann\_flexible\_2020 priors}}\label{hartmann_flexible_2020-priors}}

Table \ref{tab:hartmann-priors-data} contains the priors elicited by
\citet{hartmann_flexible_2020} for the parameters in the Preece-Baines
example. To generate the prior predictive samples displayed in Figure
\ref{fig:regression_prior_pred} we draw, for each user, \(\theta\) from
the corresponding lognormal distribution then compute \(h(t; \theta)\)
using Equation \eqref{eqn:preece-baines-model-definition-two} (without
the error term) and 250 values of \(t\) spaced evenly between ages \(2\)
and \(18\).

\input{tex-input/preece-baines-growth/0031-hartmann-priors-data.tex}

\hypertarget{pareto-frontiers-for-the-covariate-independent-target}{%
\subsubsection{Pareto frontiers for the covariate-independent
target}\label{pareto-frontiers-for-the-covariate-independent-target}}

The Pareto frontier for the covariate-independent target and all values
of \(\kappa \in \mathcal{K}\) is displayed in Figure
\ref{fig:kappa_pop}.

\begin{figure}

{\centering \includegraphics{plots/preece-baines-growth/pop-kappa.pdf} 

}

\caption{Pareto frontiers for each $\kappa \in \mathcal{K}$ for the \textbf{covariate-independent} example. The minimum loss point for each replicate is plotted with $\color{myredhighlight}{+}$. Note also that the loss scales differ between plots.}\label{fig:kappa_pop}
\end{figure}

\hypertarget{full-marginal-prior-and-posterior-comparison-plots}{%
\subsubsection{Full marginal prior and posterior comparison
plots}\label{full-marginal-prior-and-posterior-comparison-plots}}

Figures \ref{fig:pb_pop_prior_post_compare} and
\ref{fig:pb_cov_prior_post_compare} are extended versions of Figure
\ref{fig:small_cov_prior_post}, and display the prior and posterior
estimates for all the parameters in \(\theta\). Consistency and
uniqueness remain, evidently, challenging and as yet unobtainable.

\begin{landscape}
\begin{figure}

{\centering \includegraphics{plots/preece-baines-growth/pop-priors-posteriors-compare.png} 

}

\caption{A comparison of the priors (\textcolor{mymidblue}{blue}) produced by our method using the covariate-independent marginal target (bottom two rows); and Hartmann et al. (2020) (second row), with no prior displayed for the flat prior scenario. The corresponding posteriors (\textcolor{myredhighlight}{red}) for individual $n = 26$ under each of these priors are displayed as dashed lines. Note that y-axes change within columns and are limited to values that clip some of the priors/posteriors for readability.}\label{fig:pb_pop_prior_post_compare}
\end{figure}

\begin{figure}

{\centering \includegraphics{plots/preece-baines-growth/cov-priors-posteriors-compare.png} 

}

\caption{Otherwise identical to Figure \ref{fig:pb_pop_prior_post_compare} but the bottom two rows display the results obtained using the covariate-specific target.}\label{fig:pb_cov_prior_post_compare}
\end{figure}
\end{landscape}

\FloatBarrier

\hypertarget{additional-information-for-the-r2-example}{%
\subsection{\texorpdfstring{Additional information for the \(R^{2}\)
example}{Additional information for the R\^{}\{2\} example}}\label{additional-information-for-the-r2-example}}

\hypertarget{hyperparameter-support-lambda-faithfulness-experiment}{%
\subsubsection{\texorpdfstring{Hyperparameter support \(\Lambda\) --
faithfulness
experiment}{Hyperparameter support \textbackslash Lambda -- faithfulness experiment}}\label{hyperparameter-support-lambda-faithfulness-experiment}}

See Table \ref{tab:cap-lambda-def}

\input{tex-input/r2-examples/0014-cap-lambda-def.tex}

\hypertarget{a-comparison-to-an-asymptotic-result}{%
\subsubsection{A comparison to an asymptotic
result}\label{a-comparison-to-an-asymptotic-result}}

The poor fit for the Gaussian prior observed in Figure
\ref{fig:r2_roundtrip_full} could be attributed to issues in the
optimisation process, or to the lack of flexibility in the prior. To
investigate, we compare the results for \(\lambda_{\text{GA}}\) to
Theorem 5 of \citet{zhang_variable_2018}, which is an asymptotic result
regarding the optimal value of \(\lambda_{GA}\) for a target
\(\text{Beta}(s_{1}, s_{2})\) density for \(R^{2}\). We compare pairs of
\((n_{k}, p_{k})\) for \(k = 1, \ldots, 5\), noting that assumption (A4)
of Zhang and Bondell requires that \(p_{k} = \text{o}(n_{k})\) as
\(k \rightarrow \infty\) (for strictly increasing sequences \(p_{k}\)
and \(n_{k}\)). Thus we consider values of \(p\) such that
\(p_{1} = 80\) with \(p_{k} = 2p_{k - 1}\) and \(n\) with \(n_{1} = 50\)
and \(n_{k} = n_{k - 1}^{1.2}\), both for \(k = 2, \ldots, 5\). Each
\((n_{k}, p_{k})\) pair is replicated 20 times, and for each replicate
we generate a different \(\boldsymbol{X}\) matrix with standard normal
entries. As the target density we choose \(s_{1} = 5, s_{2} = 10\) -- a
``more Gaussian'' target than previously considered and thus, we
speculate, possibly more amenable to translation with a Gaussian prior
for \(\beta\). We also use this example as an opportunity to assess if
there are notable differences between the CramÃ©r-Von Mises discrepancy
and the Anderson-Darling discrepancy as defined in Equation
\eqref{eqn:discrepancies-definitions}. The support \(\Lambda\) for
\(\lambda_{\text{GA}}\) differs slightly from the example in the main
text, and is defined in Table \ref{tab:cap-lambda-def-asymp}, as
matching our target with larger design matrices requires considerably
larger values of \(\gamma\).

The computation of \(R^{2}\) becomes increasingly expensive as \(n_{k}\)
and \(p_{k}\) increase, which limits the value of some of our method's
tuning parameters. The approximate discrepancy function uses
\(S = 2000\) samples from the prior predictive and is evaluated using
\(I = 500\) importance samples. We run CRS2 for
\(N_{\text{CRS2}} = 500\) iterations, using \(N_{\text{design}} = 50\)
in the initial design for the subsequent single batch of Bayesian
optimisation, which uses \(N_{\text{BO}} = 100\) iterations.

\input{tex-input/r2-examples/0015-cap-lambda-def-aysmp.tex}

\hypertarget{results-3}{%
\paragraph{Results}\label{results-3}}

Figure \ref{fig:r2_asymp_plot} displays the results in terms of the
normalised difference between the \(\gamma\) we estimate
\(\gamma_{\text{pbbo}}^{*}\), and the asymptotic result of Zhang and
Bondell \(\gamma_{\text{asym}}^{*}\). Our typical finite sample estimate
is slightly larger than the asymptotic result, and the difference
increases with \(n_{k}\) and \(p_{k}\). The variability of the
normalised difference remains roughly constant, and thus reduces on an
absolute scale, though extrema seem to occur more frequently for larger
\(n_{k}\) and \(p_{k}\). These simulations suggest that the asymptotic
regime has not been reached even at the largest \(n_{k}\) and \(p_{k}\)
values we assessed.

\begin{figure}

{\centering \includegraphics{plots/r2-examples/gamma-diff-plot.pdf} 

}

\caption{Relative difference between the value of $\gamma$ obtained using our methodology ($\gamma_{\text{pbbo}}^{*}$) and Theorem 5 of Zhang and Bondell (2018) ($\gamma_{\text{asym}}^{*}$).}\label{fig:r2_asymp_plot}
\end{figure}

The estimates of \(\gamma\) are not themselves particularly
illuminating: we should instead look for differences in the distribution
of \(R^{2}\) at the optima, which is to say on the ``data'' scale.
Figure \ref{fig:r2_target_vs_opt_prior} displays the target distribution
and the prior predictive distribution at the optima
\(\pd(R^{2} \mid \lambda^{*}_{GA})\). The fit is increasingly poor as
\(n\) and \(p\) increase, and there is little difference both between
the two discrepancies and with each discrepancies replications. The lack
of difference implies that the optimisation process is consistently
locating the same minima for \(D(\lambda)\). We conclude that either 1)
the ability of the model to match the target depends on there being
additional structure in \(\boldsymbol{X}\), or 2) it is not possible to
encode the information in a \(\text{Beta}(5, 10)\) prior for \(R^{2}\)
into the Gaussian prior.

\begin{figure}

{\centering \includegraphics{plots/r2-examples/optimal-pf-draws-plot.pdf} 

}

\caption{The target density $\tp(R^{2})$ and optimal prior predictive densities $\pd(R^{2} \mid \lambda^{*})$ under both the CramÃ©r-von Mises (red, left column) and Anderson-Darling (blue, right column) discrepancies. There are 20 replicates of each discrepancy in this plot.}\label{fig:r2_target_vs_opt_prior}
\end{figure}

This example also further illustrates the difficulties inherent in
acquiring a prior for additive noise terms. Specifically, in this
example it is difficult to learn \((a_{1}, b_{1})\), despite the fact
that the contribution of \(\sigma^{2}\) to Equation
\eqref{eqn:r2-definition} is not purely additive. However, as we see in
Figure \ref{fig:r2_noise_hypers_plot}, estimates are uniformly
distributed across the permissible space, except for bunching at the
upper and lower bounds of \(\Lambda\). Note that for numerical and
computational stability, we constrain \(a_{1} \in (2, 50]\) and
\(b_{1} \in (0.2, 50]\) in this example. This contrasts with similarity
between replicates visible in Figure \ref{fig:r2_target_vs_opt_prior},
and is thus evidence that \((\hat{a}_{1}, \hat{b}_{1})\) have no
apparent effect on the value of \(D(\lambda^{*})\). We should instead
set the prior for \(\sigma^{2}\) based on external knowledge of the
measurement process for \(Y\).

\begin{figure}

{\centering \includegraphics{plots/r2-examples/normal-noise-hyperpars-plot.pdf} 

}

\caption{Histograms of \textit{scaled} estimates of $(a_{1}^{*}, b_{1}^{*})$ for the settings considered in Section \ref{a-comparison-to-an-asymptotic-result}. Estimates have been scaled to $[0, 1]$ for visualisation purposes using the upper and lower limits defined in Table \ref{tab:cap-lambda-def}.}\label{fig:r2_noise_hypers_plot}
\end{figure}

The regularisation method we employ in the two other examples in the
main text is unlikely to assist in estimating \((a_{1}, b_{1})\).
Promoting a larger mean log marginal standard deviation, with the
knowledge \(D(\lambda)\) is insensitive to the value of
\((a_{1}, b_{1})\), would simply pick the largest possible value for
\(b_{1}^{2} \mathop{/} \left((a_{1} - 1)^{2}(a_{1} - 2)\right)\), which
occurs when \(a_{1}\) is at its minimum allowable value and \(b_{1}\)
its corresponding maximum.

\hypertarget{full-faithfulness-results}{%
\subsubsection{Full faithfulness
results}\label{full-faithfulness-results}}

The complete results from the faithfulness experiment are displayed in
Figure \ref{fig:r2_roundtrip_full_supp}.

\begin{figure}

{\centering \includegraphics{plots/r2-examples/roundtrip-target-plot-big.pdf} 

}

\caption{As in Figure \ref{fig:r2_roundtrip_full} but for all values of $(s_{1}, s_{2})$ denoted in the facet panels titles. The performance of the regularised horseshoe is superior to the Dirichlet-Laplace, both of which are vast improvements over the Gaussian.}\label{fig:r2_roundtrip_full_supp}
\end{figure}

\FloatBarrier

\hypertarget{additional-information-for-the-cure-fraction-survival-example}{%
\subsection{Additional information for the cure fraction survival
example}\label{additional-information-for-the-cure-fraction-survival-example}}

\hypertarget{hyperparameter-support-lambda-1}{%
\subsubsection{\texorpdfstring{Hyperparameter support
\(\Lambda\)}{Hyperparameter support \textbackslash Lambda}}\label{hyperparameter-support-lambda-1}}

See Table \ref{tab:surv-cap-lambda-def}

\input{tex-input/surv-example/0022-surv-cap-lambda-def.tex}

\hypertarget{objective-values-at-optima}{%
\subsubsection{Objective values at
optima}\label{objective-values-at-optima}}

We can assure ourselves that behaviour apparent in Figure
\ref{fig:surv_ex_ppd_theta} is a manifestation of nonuniqueness in the
optimisation problem, rather than incomplete optimisation or
nonreplicability, by inspecting the values of
\(D(\lambda \mid \boldsymbol{X}), N(\lambda \mid \boldsymbol{X})\), and
\(L(\lambda \mid \boldsymbol{X})\) at the replicate optima
\(\lambda^{*}\). Figure \ref{fig:surv_ex_final_objective_values}
displays these values for \(\kappa = 0.3\), and we observe a tight
distribution of optimum values, particularly for
\(D(\lambda^{*} \mid \boldsymbol{X})\). This implies that the
optimisation process is locating equally good -- in terms of
\(D(\lambda^{*} \mid \boldsymbol{X})\) -- optima that correspond to
different \(\Pd(\theta \mid \lambda^{*})\), which is precisely our
definition of nonuniquness.

\begin{figure}

{\centering \includegraphics{plots/synthetic-survival/final-objective-values.pdf} 

}

\caption{Value of the objectives $D(\lambda^{*})$,  $N(\lambda^{*})$, and the loss $L(\lambda \mid \boldsymbol{X})$ at the replicated optima $\lambda^{*}$ for $\kappa = 0.2$. The values of these objectives are displayed as red points, with the bounded grey area depicting a truncated kernel density estimate of these points. The points have been randomly perturbed along the x-axis for this visualisation.}\label{fig:surv_ex_final_objective_values}
\end{figure}

\FloatBarrier

  \bibliography{priors-by-optimisation.bib}

\end{document}
