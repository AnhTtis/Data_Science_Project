\begin{algorithm}
  \caption{Importance sampling and ECDF approximation $D(\lambda \mid \boldsymbol{X})$}
    \label{alg:tpd-algorithmic-description}
  \begin{algorithmic}[1]
    \Require{Targets $\tc(Y \mid X_{r})$ for $r = 1, \ldots, R$; samplers for generating points from $\tc(Y \mid X_{r})$ and $\Pd(Y \mid \lambda, X_{r})$; discrepancy $d(\cdot, \cdot)$; number of samples to draw $S_{r}$; number of importance samples $I_{r}$; observable support $\mathcal{Y}$}
    \Statex
    \Function{Evaluate \textsc{log} $(D$}{$\lambda \mid \boldsymbol{X})$}
      \For{$r$ in $1 \ldots R$}
        \State Sample prior predictive $\boldsymbol{y}^{(\Pd)}_{r} = (y_{s, r}^{(\Pd)})_{s = 1}^{S_{r}} \sim \Pd(Y \mid \lambda, X_{r})$
                \State Use $\boldsymbol{y}^{(\Pd)}_{r}$ to form the ECDF $\hat{\Pd}(Y \mid \lambda, X_{r}, \boldsymbol{y}^{(\Pd)}_{r})$
        \State Sample target $\boldsymbol{y}^{(\tc)}_{r} = (y_{s, r}^{(\tc)})_{s = 1}^{S_{r}} \sim \tc(Y \mid X_{r})$
        \State Choose importance distribution $\Q(Y \mid X_{r})$ via Appendix \ref{importance-sampling}
        \State Sample importance points $(y_{i, r})_{i = 1}^{I_{r}} \sim \Q(Y \mid X_{r})$
      \EndFor
      \State Compute $\log(D(\lambda \mid \boldsymbol{X}))$ using Equations \eqref{eqn:log-discrep-func-def} -- \eqref{eqn:computing-log-ad} in Appendix \ref{evaluating-dlambda-mid-boldsymbolx}
      \State \textbf{return:} Value of $\log(D(\lambda \mid \boldsymbol{X}))$
    \EndFunction
  \end{algorithmic}
\end{algorithm}

