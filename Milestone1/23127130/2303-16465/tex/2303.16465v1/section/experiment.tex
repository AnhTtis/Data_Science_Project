\section{Experiment}
\label{sec:exp}

In this section, we evaluate the effectiveness of our method with learning-based methods~\cite{yu2018ec,wang2020pie,matveev2022def} and a traditional method~\cite{merigot2010voronoi}. Then we test the robustness by adding noise or changing the sampling density of a point cloud, and provide an ablation study to explore the effects of certain choices in our method.

% ------------ figure ----------------
\input{figures/comp_edgepoints_vis}
% ------------ figure ----------------

% ------------ figure ----------------
\input{figures/comp_param_visualize}
% ------------ figure ----------------

\subsection{Experiment Setup}
\noindent \textbf{Dataset.} We train and test our model on the ABC dataset~\cite{koch2019abc}, which has one million CAD models in total created by human users.  We use the first chunk for our experiments, which is already enough for use. Following~\cite{wang2020pie,matveev2022def,chen2022neural}, we consider \textit{sharp} curves in CAD models. However, some models need to be filtered due to data missing, shape repetition, or lack of sharp edges. The final filtered dataset contains 2364 models and is randomly split into a train set (80\%) and a test set (20\%). We provide additional details on dataset cleaning and data preparation in the supplemental.
% Due to the high repetition rate of shapes in~\cite{koch2019abc},  No repetition rate found 

\vspace{1mm}
\noindent \textbf{Implementation.} In our experiments, we set the resolution of NerVE grid at $32^3$. The effects of using higher resolutions are discussed in our ablation study (see Sec.~\ref{exp:ablation}). All input point clouds are normalized into $[-1,1]^3$. We train our networks on a NVIDIA RTX 3090 for 60 epochs. The Adam optimizer is used with an initial learning rate of 5e-4. We follow NDC~\cite{chen2022neural} and set the batch size as 1. The input point number varies for different shapes. On average, it is around 22,000. For more details like layer specifications and time cost, we provide them in the supplemental.
%It turns out training can converge at the end with batch size 1 and it makes it flexible to use input points of varying numbers and masks of varying shapes.

\vspace{1mm}
\noindent \textbf{Metrics.} We quantitatively evaluate the prediction of our networks using average recall \RecallCube{} and precision \PrecisionCube{} for edge occupancy, average correct rate \CorrectFace{} for edge orientations and average $L_2$ distance \DistancePoint{} for edge point positions. To define \CorrectFace{}, in the evaluation of edge orientation, a cube is regarded correct if all of its predictions of three faces are identical to GT, otherwise the cube is wrong. \CorrectFace{} is defined as the ratio of correct cubes in all considered cubes in an input. Note that the metrics are calculated under the cube masks defined in Sec.~\ref{sec:training}. 

To compare the quality of both PWL curves and parametric curves with other methods, we adopt the typical Chamfer distance (CD) and average Hausdorff distance (HD), %\xiangyu{average version HD means divide by 2} 
which assess the similarity between two point sets. Assume $X,Y$ are two finite point sets, CD and HD can be calculated as:
\begin{align*}
    \text{CD} &= \frac{1}{|X|} \sum_{p \in X} \min_{q \in Y} \lVert p-q \rVert_2^2 + \frac{1}{|Y|} \sum_{q \in Y} \min_{p \in X} \lVert q-p \rVert_2^2,
\end{align*}
\begin{align*}
    \text{HD} &= \frac{1}{2} (\max_{p \in X} \min_{q \in Y} \lVert p-q \rVert_2 + \max_{q \in Y} \min_{p \in X} \lVert p-q \rVert_2).
\end{align*}

\subsection{Comparisons}
\noindent \textbf{Edge Estimation.} We evaluate our predicted PWL curves on our test set by comparing them with the baseline methods: VCM~\cite{merigot2010voronoi}, EC-NET~\cite{yu2018ec} and PIE-NET~\cite{wang2020pie}.
%\xiangyu{In fact not SOTA in terms of edge estimation} 
To measure the error between predicted edge points and the ground-truth, we convert PWL curves into point sets by sampling the midpoints of all edges. Numerical results are reported in Table~\ref{tab:comp_edgepoints} and visual comparisons are shown in Fig.~\ref{fig:comp_edgepoints_vis}. We provide the settings of baseline methods in the supplemental.

\input{tables/comp_edgepoints}
\vspace{1mm}

The quantitative and qualitative results show that our method significantly outperforms the baselines, where we produce accurate and uniformly distributed points visually. VCM and EC-NET are prone to generate redundant points around the ground-truth edges, thus producing higher CD and HD values. PIE-NET has a thinner band of outputs, but it tends to miss some edge points. 
% \dong{As our method adopts masks and only chooses surface cubes for calculation to reduce consumption, it is more efficient than other approaches. The average inference times of VCM, EC-Net, PIE-Net, and Ours are 2.06, 0.84, 0.52, 0.15 seconds, respectively. For post-processing, our method takes 0.02s on average, which is more efficient than the post-processing of PIE-Net (3.01s). }


\input{figures/stress_test_edgepoint}

% Xiangyu: If space is enough
% VCM~\cite{merigot2010voronoi} is a non-learning method for sharp point detection. EC-NET~\cite{yu2018ec} predicts point positions on sharp edges for shape reconstruction, using deep networks. PIE-NET~\cite{wang2020pie}, also a learning based method, detect sharp curves in its first stage for next parametric inference.

\vspace{1mm}
\noindent \textbf{Parametric Curves.} With the predicted PWL curves as input, our method fit them to generate parametric curves.
We compare our parametric curves with the state-of-the-art method DEF~\cite{matveev2022def} both quantitatively and qualitatively on the DEF-Sim~\cite{matveev2022def} dataset, which has 68 carefully selected shapes from ABC dataset. Since the official code of DEF is not available, we use the input data in DEF-Sim and their results of parametric curves provided by DEF's authors. We directly use the reported results of PIE-Net and DEF from DEF's paper~\cite{matveev2022def} for quantitative comparisons (shown in Table~\ref{tab:comp_paramcurve}). Since PIE-NET does not provide the official implementation for its parametric curve inference, we only compare with DEF qualitatively in Fig.~\ref{fig:comp_paramcurve}.

\input{tables/comp_paramcurve_error}
\vspace{1mm}


% \footnote{DEF does not publish their codes by CVPR23 deadline. The author of DEF provides us with input data in DEF-Sim and their results of parametric curves. Values of PIE-NET and DEF in Table~\ref{tab:comp_paramcurve} are from Table 5 in DEF~\cite{matveev2022def}. PIE-NET does not provide codes for its parametric curve inference, so we only compare with DEF in Figure~\ref{fig:comp_paramcurve}. },

The results in Table~\ref{tab:comp_paramcurve} show that our method presents significantly better performance than DEF and PIE-NET, where the CD and HD errors of PIE-NET primarily arise from missing curve instances, which usually happen when keypoints (e.g., corner points or edge points) are wrongly predicted or simply missed. As shown in Fig.~\ref{fig:comp_paramcurve}, DEF performs well around sharp corners but struggles in processing structures with circle curves. In contrast, our method can handle closed curves and sharp corners consistently and produce convincing parametric curves in visual. 

\subsection{Stress Tests}
We investigate the robustness of our method using point clouds with varying noise or sampled point numbers. We train and test networks on our dataset with augmentation by adding Gaussian noise and random resampling. 

\vspace{1mm}
\noindent \textbf{NerVE Prediction.} Table~\ref{tab:stresstest_network} shows the effects of noise intensity and sampled point number on the prediction of our NerVE representation. We observe that even with a large noise intensity ($\sigma=l/2$, where $l$ is the edge length of a cube in the grid) or much fewer sampled points (4,096), our method still can produce reasonable results of PWL curves with low-level CD and HD errors.
% Xiangyu: hard to explain
% except the case of 4096 resampling points. In this undersampling case, our network could not obtain good enough per cube feature from input 
\input{tables/stresstest_network}
\vspace{1mm}

\noindent \textbf{Edge Estimation.} We also compare with VCM~\cite{merigot2010voronoi}, EC-NET~\cite{yu2018ec} and PIE-NET\cite{wang2020pie} on noisy or resampled inputs. Table~\ref{tab:stresstest_edgepoints} shows that our method achieves the best numerical performance. Fig.~\ref{fig:stress_test} further demonstrates that our method outperforms baseline methods and presents robustness against noisy or resampled inputs.

\input{tables/stresstest_edgepoints}

\subsection{Ablation Study}
\label{exp:ablation}
\noindent \textbf{Resolution.} Table~\ref{tab:ablation_reso} shows the performance of our method under different NerVE grid resolution, where we observe that using resolution $32^3$ achieves slightly better performance on occupancy prediction of edge cubes. As a binary classification problem, data imbalance of edge occupancy is aggravated as resolution increases since the number of non-edge points grows faster than edge points number. Therefore, using resolution $64^3$ meets a more challenging classification problem, producing slightly worse \RecallCube{} and \PrecisionCube{} than using resolution $32^3$. Nevertheless, we notice that using resolution $64^3$ can achieve better CD and HD. Meanwhile, the parametric curves under resolution $64^3$ present better performance as shown in Table~\ref{tab:comp_paramcurve}. Fig.~\ref{fig:ablation_reso} shows the visualizations and provides some insights to explain the phenomenon.
% We also notice that using resolution $64^3$ predicts better point position (\DistancePoint{}), and this is natural since higher resolution has smaller cubes delivering more precise per-point position.

\input{figures/ablation_reso}

\input{tables/ablation_reso}

\vspace{1mm}

% Moreover, we also observe that using resolution $64^3$ produces larger CD error in PWL curve prediction. Meanwhile, the parametric curves under resolution $64^3$ present better results as shown in Table~\ref{tab:comp_paramcurve}. Fig.~\ref{fig:ablation_reso} shows the visualizations and provides some insight to explain the contradiction. 

% For simple shapes, e.g., the left side of Fig.~\ref{fig:ablation_reso}, using higher resolution (e.g., $64^3$) could disconnect at several positions on curves (although it can be fixed by simple post- processing), which makes the CD error of its PWL curves larger.
% However, for parametric curve extraction, using resolution $32^3$ suffers from representing complicated shapes (right side in Fig.~\ref{fig:ablation_reso}) where using resolution $64^3$ performs better. 
% In summary, this is a trade-off between resolution and representation difficulty in NerVE, where a higher resolution usually brings more details to process complicated shapes, but also indicates higher learning difficulty. In our experiments, we observe that using resolution $32^3$ generally yields better results for normal shapes in the dataset.

For simple shapes, e.g., the left side of Fig.~\ref{fig:ablation_reso}, using a higher resolution (e.g., $64^3$) could disconnect at several positions on curves, which will degrade the edge occupancy accuracy of its PWL curves, but these artifacts (e.g., disconnection) can be well addressed by a simple post-processing in the following parametric curve extraction. On the contrary, using resolution $32^3$ suffers from representing complicated shapes (right side in Fig.~\ref{fig:ablation_reso}) while using resolution $64^3$ performs better and brings more geometric details. More experiments and analysis are provided in the supplemental. %\dongc{I put the results of $128^3$ and other ablation study of our rebuttal in the supplemental.}

% \dong{In our experiments, we find the ABC dataset~\cite{koch2019abc} is biased toward simpler shapes. Thus, we use resolution $32^3$ for default, which already performs well for our \modelName{}.}

\noindent \textbf{Cube Point Choice.} As stated in Sec.~\ref{sec:method}, edge point position in a cube is defined as the midpoint of the truncated curve. Another option is to use a point which minimizes a quadratic error function (QEF), similar to the point definition in Dual Contouring~\cite{ju2002dual}. We provide the details in our supplemental. We validate our choice by restoring curves from ground-truth NerVE with two different definitions of point position. As shown in Table~\ref{tab:ablation_cubepoint_choice}, current definition of the point position clearly has better performance on curve restoration. 

\input{tables/ablation_cubepoint_choice}

\vspace{1mm}
\input{figures/limitation}

% \input{figures/more_results}
% \subsection{More Results} For more instances of our extracted parametric curves, refer to Fig.~\ref{fig:more_results}.