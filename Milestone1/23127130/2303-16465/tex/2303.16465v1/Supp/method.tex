In this supplementary material, we provide additional details of our method in Sec.~\ref{sec:supp_method}, data collection setup in Sec.~\ref{sec:supp_dataset}, and additional ablation study, numerical and visual results in Sec.~\ref{sec:supp_exp}.

\section{Details of Method}
\label{sec:supp_method}
In this section, we present network specifications for learning \modelName{} and list the post-processing details for the PWL curves refinement and the final parametric curve fitting.

\subsection{Network Details}

\paragraph{Encoder.} We use a simplified dense PointNet++~\cite{qi2017pointnet++} as our encoder. Specifically, given a point cloud of shape $(N,3)$ ($N$ is the point number), we first find k-nearest neighbors ($k=8$ as in~\cite{chen2022neural}) of each point and reform them into a tensor of shape $(N,8,3)$ as input. Then we apply a network consisting of 4 layers of MLP, where the latent size is $128$ and the output shape is $(N,8,128)$. We finally obtain point features of $(N,128)$ by using a max pooling function in the second dimension. After that, the point features are fused as cube features $(32,32,32,128)$ (32 is the grid resolution) by average pooling when multiple points appear in the same cube. Three 3D-convolution layers are then applied to the cube features, where the kernel size, stride, and padding are 3, 1, and 1 respectively. 
We use Leaky ReLU as the activation function. The final shape of the feature grid is $(32,32,32,128)$.

\paragraph{Decoder.}We adopt a 5-layer MLP as the decoder to predict edge occupancy, orientations, and edge point position. The latent layer size of the MLP is $128$. Each cube in the feature grid has a feature size of $128$, which is directly decoded by the occupancy decoder into a one-dimensional scalar. It is decoded by a position decoder into three floats. For the orientations decoder, as shown in Figure 2 in our paper, we first concatenate the cube feature with its three adjacent cube features, which means the input to the orientations decoder is of shape $(3, 128+128)$. The orientations decoder takes the concatenated feature as the input and produces three one-dimensional scalars.
Sigmoid activation is used as the last layer in both the occupancy decoder and the orientations decoder. 
The output of our position decoder is clipped into $[-1,1]^3$ to be consistent with the coordinate system of the input point cloud (see \emph{Input Point Cloud Pre-processing} in Sec.~\ref{sec:supp_dataset} for more details on coordinate transform).
% since we actually first predict the local coordinates of points in a cube and then convert them to global coordinates. 

\subsection{Parametric Curve Extraction}
We introduce the processing details in parametric curve extraction, including the refinement of PWL curves and parametric fitting.
Note that the whole procedure of extraction is fast, where the parametric curve extraction takes only 0.018 seconds per shape on average from all shapes in the test set (472 shapes), where the average vertex number on shape curves is about 22000.

\paragraph{PWL Curves Refinement.}To refine the predicted PWL curves from our network for parametric curve extraction, we propose several post-processing steps. 
In the following settings, the predicted PWL curves are regarded as an undirected graph, where the definition of vertex degree is the same as in general graph theory. 

\input{figures/Supp_post_reconnection}
\noindent \textbf{Step 1: Point Reconnection.}
We first find all vertices with degree 1 and denote such vertices as \DegreeOne vertices. Then we add an edge between two \DegreeOne vertices if the distance of these vertices is smaller than a given threshold $\delta_r$ meanwhile, their tangent vectors should be consistent enough. See Fig.~\ref{fig:post_reconnection} for an illustration of reconnection as well as the definition of consistency between tangent vectors. Take Fig.~\ref{fig:post_reconnection} (b) as an example, the consistency of tangent vectors is defined by $\Vec{t}_1 \cdot \Vec{t}_2 + \Vec{t}_2 \cdot \Vec{t}_3$. If $\lVert \overrightarrow{p_1p_2}\rVert < \delta_r$ and $\Vec{t}_1 \cdot \Vec{t}_2 + \Vec{t}_2 \cdot \Vec{t}_3 > \sqrt{2}$ ($\sqrt{2}$ is fixed, which works well in all our experiments), we can connect $p_1$ and $p_2$. 

\input{figures/Supp_post_extra_line}
\noindent \textbf{Step 2: Extra Edges Removal.}
As shown in Fig.~\ref{fig:post_extra_line}, there could be extra edge segments in the space. To remove these outliers, we first find all paths which start with a \DegreeOne vertex. A path on the PWL curves graph is defined by adding constraints: $\deg (V_{\text{in}}) =2, \deg (V_{\text{end}}) \neq 2$, where $V_{\text{in}}$ is interior vertex and $V_{\text{end}}$ is the end vertex of the path and $\deg(V)$ means the degree of vertex $V$ on PWL curves graph. 
Then we remove one from these paths if its vertex number is less than $N_p$. In this way, short extra edges can be removed, and there remain long extra edges that failed to reconnect in \emph{Step 1}. 
We provide an option on keeping long protruding edges according to users' preference on conforming to the B-Rep constraints.
In particular, long protruding edges are removed if B-Rep constraints are strictly required and kept otherwise.
In our experiments, we choose to impose the B-Rep constraints for final parametric curves and remove such long protruding edges.
% If we allow open curves (\DegreeOne endpoints exist) to exist in final parametric curves, we can still save and fit these long extra edges. 
% However, as seen in Section 3.3 of the main paper, open curves are not allowed due to the B-Rep constraints. Therefore, if we do not strictly require the B-Rep constraints, it will accept such long extra edges. 
% In our experiments, we decide to remove these long extra edges to satisfy the B-Rep constraints for final parametric curves, but it also causes some missing curves and produces larger CD and HD errors than PWL curves. 

\input{figures/Supp_post_multipath}
\noindent \textbf{Step 3: Multi-paths Handling.}
In our method, all vertices with degree $>2$ are regarded as endpoints of curves. However, there could be multiple close paths between two endpoints as shown in Fig.~\ref{fig:post_multipath}, When curves are close to edges or faces of the cube, the network might predict the additional point causing multiple paths. To handle this issue, we can randomly select one of the paths and delete others since all paths are close in geometry, and we finally fit the paths in the sense of least squares. Two paths from the same pair of endpoints are defined to be close if the Chamfer distance of these two paths is lower than a given threshold $\delta_p$. We repeat this process until all extra paths are eliminated. 

\input{tables/Supp_parameters}
\paragraph{Choices of Parameters.}Three parameters are discussed in PWL curves refinement: $\delta_r, N_p,\delta_p$. To choose appropriate values, we compare the CD and HD errors of the final parametric curves in different parameter settings, as shown in Table~\ref{tab:Supp_parameters}. Based on the comparison, we choose $\delta_r=4l, N_p=5, \delta_p=2l$, where $l=2/r$ ($r=64$ for resolution $64^3$) is the edge length of a cube in the grid.

\paragraph{Parametric Curve Fitting.}After obtaining paths between pairs of endpoints or closed paths, we can use an off-the-shelf spline fitting library for parametric curve fitting on these paths. Specifically, we use the function \emph{make\_lsq\_spline} from \emph{Scipy}, which can fit given points in the sense of least squares with BSpline functions. For our setting of BSpline functions, the order of spline is $3$; the number of knots (except the knots for start and end points) is half of the number of path vertices; knots are uniformly sampled in $[0,1]$. 
Note that the positions of all endpoints are fixed during fitting.

For closed paths, we first try direct 3D circle fitting on one closed path since most closed curves in the ABC dataset are circles~\cite{wang2020pie}. If the fitting error is large, which means the closed path is probably not a circle, we simply apply the previous spline fitting to it. Here, the threshold for the fitting error is fixed as $0.001$, which works fine in all our experiments. For 3D circle fitting, we use a feasible and simple approach. We first use principal component analysis (PCA) on points and then convert it to a 2D circle fitting problem, which can be easily solved, finally we map the fitted 2D circle into $\mathbb{R}^3$ by PCA and obtain the 3D circle. 