Software Quality Assurance (SQA) attributes have been studied for many years \citep{McCall1977FactorsIS,10.5555/48813,10.5555/121025}. Delineated in the ISO 9126 standard \citep{ISO9126}, they were later extended and superseded by ISO 25010 \citep{ISO/IEC2010}, having production code as the main target. However, as they are desirable for any codebase, here we analyze how each attribute has an effect on research code and work.

\textbf{Portability} and \textbf{usability} respectively refer to the possibility to execute the same experiments in diverse hardware or software environments and the effort required to use the software (i.e., how easy is to run the code).
As such, they pertain to the reproducibility of a paper, which, according to ACM,\footnote{\url{https://www.acm.org/publications/policies/artifact-review-and-badging-current}} holds when \enquote{\textit{an independent group can obtain the same result using the authorâ€™s own artifacts}}, a definition that is aligned with those given in NLP \citep{ulmer2022experimental} and other fields \citep{doi:10.1128/mBio.00525-18}.
Regarding these aspects, ample literature already discussed the need to go beyond code openness in research \citep{Chen2019,Trisovic2022}, highlighting the role of proper documentation and validation in
different environments.
However, as many research groups lack access to a wide range of hardware options, we argue that research works can hardly target portability due to the significant economic and human resources it requires.
On the contrary, proper documentation of the code is a reasonable demand and, in addition to increasing reproducibility, it eases code reuse and its adoption as the foundation for future works.


Code reusability also pertains to the
%attribute of \textbf{maintainability},
\textbf{maintainability} attribute, which denotes the effort required for implementing targeted modifications. 
%In addition to proper documentation, the maintainability of a codebase depends on its structure
Alongside comprehensive documentation, software maintainability \mn{hinges} on code structure,
%(
i.e. the organization of the software into building blocks %\citealt{10.1145/141874.141884,intro_soft_architectures}).
\citep{10.1145/141874.141884,intro_soft_architectures}.
%While there is currently no incentive to develop reusable code \citep{barba-2019-praxis}, a commitment to this objective would greatly benefit the research community in the long term: it
While there is currently no incentive to develop reusable code \citep{barba-2019-praxis},  the research community would greatly benefit in the long term from a commitment to this objective, which would reduce the time spent in replicating prior work and accelerate the implementation of new techniques upon existing code.
% the testing of novel hypotheses built upon existing code.


The 
expeditiousness 
% \mn{speed}
of testing new methods also depends on the \textbf{efficiency} and \textbf{reliability} of the codebase.
Efficiency refers to the amount of resources a software uses, e.g. the number of GPU hours or VRAM GBs needed for training.
Increasing efficiency constitutes a research direction on its own and can hardly be considered a prerequisite for orthogonal investigations.
Reliability, instead, is  the capability of the software to seamlessly operate in all conditions and for a long time: software causing frequent crashes (i.e. terminations due to errors) or whose efficiency is not constant over time is not reliable.
Although both properties would contribute to reducing the environmental footprint of NLP research by avoiding computing-resource wastes or unexpected failures \citep{strubell-etal-2019-energy,Shterionov2023},
%we argue that 
a commitment in this direction
%\mg{arguably} 
represents an excessive demand for research works \mg{not expressly dedicated to it}.
% \mn{[PERCHE'? NON VI PARE UN PO' FORTE E APPESO?]}



Last but not least, \textbf{functionality} or \textbf{functional correctness} (hereinafter: correctness)  pertains to the \enquote{\textit{extent to which a program satisfies its specifications}}  \citep{McCall1977FactorsIS}. In research, this holds when the code exactly performs the operations described in  a paper, thereby establishing the validity of the reported findings.
Achieving correctness requires the creation and execution of tests, as they are the sole mechanism that guarantees the correct behavior of software.
For example, when designing a causal model (i.e. a model that cannot look at future elements in 
% a sequence), 
the input sequence),
researchers should test that the model predictions always remain unaffected by future elements. If a bug  breaks the causality property, any observed gains may not stem from the proposed solutions but from undue access to forbidden information.
It is worth emphasizing that the validity of these tests expires after any code alteration, regardless of its apparent relevance. Therefore, tests should be executed after each modification to  ensure correctness and, in turn, 
the trustworthiness of the findings.





In summary, we have observed that, in the context of research software, \textit{i)} portability and usability support reproducibility, \textit{ii)} maintainability promotes reusability, \textit{iii)} efficiency and reliability reduce environmental costs, and \textit{iv)} correctness plays a 
%pivotal
crucial
role in ensuring trustworthy findings and research soundness. 
However, despite its importance, we show in the next section that the research community has largely neglected correctness, 
focusing primarily on reproducibility.

