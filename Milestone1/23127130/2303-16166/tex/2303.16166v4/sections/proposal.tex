After demonstrating
that the current tendency to assess  code correctness solely based on the reported results (\S\ref{sec:core-idea}) potentially leads to wrong findings (\S\ref{sec:case-study}), in this section we propose countermeasures. Specifically, we aim at 
%increasing the correctness of research codebases by 
\mg{fostering} the adoption of SQA best practices in two ways: \textit{1)} by releasing a  Python package
%\footnote{\url{https://anonymous.4open.science/r/pangolinn/}} 
(\texttt{pangoliNN}) for testing neural networks and  assisting researchers in the verification of code correctness (\S\ref{subsec:pangolinn});  \textit{2)} by  proposing the integration of current conference checklists with recommendations for SQA best practices (\S\ref{subsec:checklist}).

\subsection{\texttt{pangoliNN}}
\label{subsec:pangolinn}
As discussed in \S\ref{sec:sqa}, testing a software is the only way to enforce that it works correctly. Therefore, as the first and foremost method to increase code correctness, we recommend the extensive implementation and adoption  of Unit Tests (UTs) to check that the code has the expected behavior \citep{10.1145/987305.987309,10.1145/800027.808473,10.5555/1349795,8048665}.
Ideally, this should be done prior to writing the actual code, following the so-called ``test-driven development practice'' \citep{beck2002driven}.
UTs should cover all the assumptions about how the code works (e.g., ensuring that the presence of padding does not alter the results). While achieving complete test coverage is a utopian objective, the higher the coverage, the higher the quality of the codebase.


To ease this work, we introduce \texttt{pangoliNN},\footnote{\mn{As a pangolin looks for bugs and catches them, this library aims at finding bugs in neural networks (NN). Hence the name.}} a Python package specifically designed for testing neural modules. Built upon the widely used PyTorch library \citep{Paszke-2019-pytorch}, \texttt{pangoliNN} offers a collection of pre-defined tests that enforce specific behaviors of the modules.
Its primary objective is to simplify and expedite the process of testing neural networks, alleviating researchers from the burden of creating UTs from scratch.
Indeed, writing UTs may initially be perceived as
% Although some of them may initially perceive writing UTs as
an additional and undesirable cost, although ample literature dispels this perception. \citet{Williams-2003-TDD}, for instance, proved that the inclusion of UTs does not hamper code-writing productivity, 
%while 
\citet{oro3667,Ellims2006} showed that the perceived cost is \enquote{\textit{exaggerated}}, and \citet{google-ut}
%proved 
that the initial overhead\footnote{Estimated in 16\%-35\% of the overall software development cost \citep{George-2003-tdd,google-ut}.} pays off by saving time spent on manual experiments.
% Furthermore, since such experiments are often resource-intensive and environmentally impactful \citep{strubell-etal-2019-energy}, as a byproduct, UTs would also contribute to the environmental sustainability of NLP research, facilitating the transition to Green AI~\citep{greenai}.

% Indeed, the 
% %tests in \texttt{pangoliNN} (and UTs in general)
% \mg{UTs} are lightweight \mg{in general} and do not require a pre-trained model, being executed prior to any training phase. Their nature and  goal greatly differ from assessing the quality of a trained model, as recently proposed with behavioral checklists \citep{ribeiro-etal-2020-beyond}.



Furthermore, unlike manual experiments that are often resource-intensive and environmentally impactful \citep{strubell-etal-2019-energy}, UTs are generally lightweight (e.g., they do not involve any training phase). As such, writing UTs would contribute to the environmental sustainability of NLP research,
facilitating the transition to Green AI~\citep{greenai}. Also, UTs do not require any pre-trained model to run, as their nature and goal greatly differ from assessing the quality of a trained model, as recently proposed with behavioral checklists \citep{ribeiro-etal-2020-beyond}.
Through behavioral checklists, we test whether a specific instance properly handles different aspects, such as linguistic phenomena (e.g., negation, co-references) and/or produces correct outputs with challenging inputs. 
Through UTs, instead, we assess the behavior and robustness of the code itself (rather than of model instances), by verifying whether assumptions about properties of the network or about its behavior in specific conditions (e.g., not being influenced by the presence of padding) are respected.


Currently, \texttt{pangoliNN} includes tests for two aspects: \textit{i)} proper handling of padding and batching, ensuring consistent output of neural modules irrespective of padding presence; and \textit{ii)} addressing causality by verifying the independence of module output from future elements in the input sequence, which is crucial for autoregressive and other sequence-to-sequence models.
It also features comprehensive documentation with simple examples to guide researchers in its usage. Moreover, \texttt{pangoliNN} itself is extensively unit tested, and these UTs provide additional implicit guidance on how to effectively utilize the package.

Despite being in its initial stage, we argue that the first release of \texttt{pangoliNN} represents a milestone toward increasing the quality and trustworthiness of NLP research code and, in turn, outcomes.
We hope that it will be embraced and expanded upon by the research community, with the integration of additional tests, ultimately growing it into a comprehensive testing library for neural networks.


\subsection{Code-quality Checklist}
\label{subsec:checklist}

As a complementary initiative, we also propose to integrate the existing conference checklists with questions targeting the improvement of code correctness and quality in research (Table \ref{tab:checklist}). 
It is worth mentioning that we have strictly adhered to these guidelines throughout
%It is needless to remark that these guidelines have been strictly followed for 
the development of both \texttt{pangoliNN} and of our padding-safe implementation of the Conformer architecture.

The first questions (\textbf{Q1-2}) focus on the adoption of UTs (possibly leveraging \texttt{pangoliNN}), whose importance has been stressed
in the previous section.
However, the only presence of UTs does not guarantee that the code works.
Indeed, UTs should be executed every time the codebase is modified, even in case of a seemingly \textit{unrelated change}, as the validity of a test expires whenever the software is edited (as seen in \S\ref{sec:sqa}).
This is commonly enforced through continuous integration (CI), which executes all UTs at every code change~\citep{Duvall-2007-ci}. 
A running and successful CI  offers the supplementary advantage of providing implicit guidance on the installation and execution of the code for individuals attempting to replicate a study.
Furthermore, it mitigates the occurrence of replication failures due to syntax or runtime errors, as it often happens in current NLP artifacts \citep{arvan-etal-2022-reproducibility-code}.
Such failures can arise because the released version of the code might slightly differ from those used for the experiments due to small refactorings prior to the release.
For this reason, \textbf{Q3} and \textbf{Q4} respectively focus on test execution and on the presence of a CI, so as to ensure that the checks of the UTs are actually respected.


\begin{table}[!tb]
\setcounter{table}{7}
\begin{tcbitemize}[%
        raster columns=1,
        raster equal height,
        raster width=.47\textwidth,
        before=,after=\hfill,
        boxsep=3pt, left=4pt, right=6pt, %bottom=6pt,
        colframe=teal!75!black,colback=white,
        fonttitle=\large\bfseries,
        halign=left,
        ]
\tcbitem
\begin{enumerate}[itemsep=1pt,leftmargin=*]
\small
\justifying
\item \textsf{\mn{Have you tested your code with relevant tests \mg{(including those in \texttt{pangoliNN})?}}}
%in \texttt{pangoliNN}?}}
\item \textsf{Have you tested assumptions about code behavior with Unit Tests (UTs)?}
\item \textsf{Have UTs been executed on the code version used for the experiments and, if applicable, the publicly released version?}
\item \textsf{Does the repository contain a continuous integration that 
%installs it and 
runs the UTs?}
\item \textsf{Has every contribution to the codebase been reviewed by at least one person?}
\end{enumerate}
\end{tcbitemize}
\caption{Code-quality Checklist.}
\label{tab:checklist}
\end{table}


Lastly, we encourage (\textbf{Q5}) the adoption of a code reviewing practice \citep{7589787}, in which all changes are reviewed and approved by a person different from the code author.\footnote{The reviewer(s) can be any \mn{person}
%who is not the author of the code 
with basic knowledge of the codebase, such as lab teammates or advisors.}
Code review is a lightweight and informal process compared to code inspection \citep{fagan-1976} and has been shown to cause little overhead for most code changes \citep{10.1145/3183519.3183525}.
It consists in reading and commenting on the source code for a change, which should be kept small and focused on one single aspect or new feature.
This aims not only at avoiding bugs, but also at improving code readability and documentation \citep{10.1007/978-3-319-69926-4_9,Chen2019,Bahaidarah-2022-toward,Trisovic2022}, and, in turn, reusability and reproducibility.
In addition, it serves as a powerful tool for knowledge transfer \citep{10.5555/2486788.2486882}, thus novices would particularly benefit from it.

As a final note, we would like to emphasize that our proposed \enquote{Code-quality Checklist} should be interpreted as the \enquote{Reproducibility Checklist} now required by many top-tier venues: though strongly encouraged, following
the checklist is not mandatory for paper submissions and its intent is fostering software quality and correctness rather than certifying it. Specifically, it will encourage awareness of SQA concepts and coding best practices, especially among researchers who have not been exposed to them during their education.
