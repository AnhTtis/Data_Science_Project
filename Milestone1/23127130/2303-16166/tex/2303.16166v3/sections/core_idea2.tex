%\url{https://aaai.org/conference/aaai/aaai-23/reproducibility-checklist/}

In NLP, as in many 
%experimental 
empirical
fields, a scientific contribution typically
builds on
%\mg{has}
three main constituent elements:
%(Fig. \ref{fig:scientificartifact}):
\textbf{concept} (the
%original idea
idea
or hypothesis being tested), \textbf{implementation} (the software developed to test the concept), and \textbf{outcomes} (the results
%obtained from the
of the
experiments carried out by using the code).

%The concept is the foundation of the publication. In the reviewing process, it 
%\mn{In the reviewing process, the concept}
The concept, the foundation of the 
%publication,
work,
is typically evaluated based on its 
%\textit{novelty} (i.e., how original the idea is),
%\textit{novelty}  \mn{(how original the idea is),}
novelty (\textit{is the idea original?}),
%\textit{soundness} (i.e., if the idea is grounded on solid theoretical bases),
%\textit{soundness} \mn{(if the idea is grounded on solid theoretical bases),}
soundness (\textit{is the idea grounded on solid theoretical bases?}),
and  
%\textit{impact} (i.e., how important the idea is for the scientific community).
%\textit{impact} \mn{(how important the idea is for the scientific community).}
impact (\textit{is the idea important for the scientific community?}).
%The implementation is a scientific artifact created to realize and test the concept. When present, it 
The implementation, when present,
is 
%generally 
evaluated 
%by looking at its \textit{accessibility} (i.e., if the code is released open source), and its \textit{usefulness}  (i.e., if the research community will benefit from the use of the software).
in terms of 
% \textit{accessibility} (if the code is released open source) 
accessibility (\textit{is the code released open-source?})
and  
%\textit{usefulness} (if the research community will benefit from the use of the software).
usefulness (\textit{will the research community benefit from the use of the software?}).
% The outcomes are usually checked in comparison either with the  state of the art (\textit{are the results  competitive with those reported in recent literature?}) or with a strong baseline in absence of related works, looking at their significance (\textit{are the improvements robust to statistical fluctuations?}).
The outcomes are usually assessed in terms of significance (\textit{are the reported improvements robust to statistical fluctuations?}) with respect 
%either to 
to either
the state of the art (\textit{are the results competitive with those reported in recent literature?}) or strong baselines.

%Aside from 
Besides considering these elements separately, it is also important to consider how they are interconnected.
Evaluating the link between implementation and outcomes
corresponds to answering the question: \textit{``Can the results be actually produced by the codebase?''} or, in other words, \textit{``Are the results \textbf{reproducible} with the code?''.}
According to the Association for Computing Machinery,
%(ACM), 
%a code is reproducible if
reproducibility holds when
\enquote{\textit{an independent group can obtain the same result using the authorâ€™s own artifacts}},\footnote{\url{https://www.acm.org/publications/policies/artifact-review-and-badging-current}} which is coherent with the definition given 
both in other fields \citep{doi:10.1128/mBio.00525-18} and in NLP \citep{ulmer2022experimental}.
%in various fields \citep{doi:10.1128/mBio.00525-18} including NLP \citep{ulmer2022experimental}.
%by related works on experimental standards in NLP 
Several works have been dedicated to this topic, 
%claiming the presence of a \enquote{reproducibility crisis}, as their systematic analyses questioned the reproducibility of a large portion of published papers
and 
%stigmatized
denounced a \enquote{reproducibility crisis} 
% problem that hinders the 
% \sara{reproducibility}
% %\mn{replication}
% of 
that affects
a large portion of published papers
\citep{prinz2011believe,Baker2016,Gundersen_Kjensmo_2018,NEURIPS2019_c429429b,Gundersen_2019}, also in the specific context of 
%
%
%
% NLP \citep{wieling-etal-2018-squib,belz-etal-2021-systematic,belz-etal-2022-quantified}.
% Most of them argue that the published works lack consistent evaluation settings \citep{marie-etal-2021-scientific,gehrmann2022repairing} and cannot be reproduced \citep{narang-etal-2021-transformer}, even 
% %if codebases are available 
% with codebases available
% \citep{arvan-etal-2022-reproducibility-code}.
%
NLP \citep{wieling-etal-2018-squib,belz-etal-2021-systematic,marie-etal-2021-scientific,narang-etal-2021-transformer,gehrmann2022repairing,belz-etal-2022-quantified}, and even 
when codebases are available
\citep{arvan-etal-2022-reproducibility-code}.
%
%
%
%To mitigate this issue, 
To tackle this problem,
numerous scientific organizations and associated journals and conferences, such as NeurIPS,\footnote{\url{https://neurips.cc/Conferences/2021/PaperInformation/PaperChecklist}} AAAI,\footnote{\url{https://aaai.org/Conferences/AAAI-22/reproducibility-checklist/}} and the ACL community,\footnote{\url{https://aclrollingreview.org/responsibleNLPresearch/}} have recently introduced 
%the completion of checklists
checklists
aimed at enhancing the reproducibility of published material \citep{dodge-etal-2019-show,pineau2021improving,rogers-etal-2021-just-think}.
%The emphasis on the topic is further confirmed 
Such a growing concern is also attested
by the organization of dedicated workshops and shared tasks on this theme
\citep{Pineau:2019,belz-etal-2021-reprogen}, and its inclusion as part of
%recent 
conference theme tracks.\footnote{\url{https://2022.emnlp.org/calls/main_conference_papers/\#emnlp-2022-theme-track}, \url{https://2023.aclweb.org/calls/main_conference/\#theme-track-reality-check}}

%\begin{figure}[!t]
%    \centering
%    \includegraphics[width=0.45\textwidth]{img/idea.png}
%    \caption{Elements of a scientific publication.}
%    \label{fig:scientificartifact}
%\end{figure}

\begin{table}[!tb]
    \centering
    \small
    \setlength{\tabcolsep}{8pt}
    \begin{tabular}{l||c|c}
    \specialrule{.1em}{.05em}{.05em} 
        %\multirow{2}{*}{\textbf{Venue}} & \multicolumn{2}{c}{\textbf{Review Form Content}} \\
        %\cline{2-3}
        \textbf{Venue} & \textbf{Reproducibility} & \textbf{Correctness} \\
        \specialrule{.1em}{.05em}{.05em} 
        %\multirow{2}{*}{AAAI} & Reproducibility & \smallcorrect{} Yes/No questions for each record of the Reproducibility Checklist\tnote{*} \\
        %    & Correctness & Evaluated by... \\
        % \hline
        *ACL &  \smallcorrect{} & \smallwrong{} \\
        ARR & \smallcorrect{} & \smallwrong{} \\
        ICASSP & \smallwrong{} & \smallcorrect{} \\
        ICML & \smallwrong{} & \smallwrong{} \\
        ICLR & \smallcorrect{} & \smallcorrect{} \\
        Interspeech & \smallcorrect{} & \smallwrong{} \\
        NeurIPS & \smallwrong{} & \smallwrong{} \\
        TACL & \smallcorrect{} & \smallcorrect{} \\
    \specialrule{.1em}{.05em}{.05em} 
    \end{tabular}
    % \caption{Which major conferences/journals in NLP explicitly require a score for reproducibility and correctness in the review forms?}
    \caption{Reproducibility and correctness in the review forms of major conferences/journals in the NLP field.}
    %\mn{[PAURA! Sicuri, vero, che a NeurIPS e ICML non c'e' alcun check nemmeno sulla riproducibilita'???]}
    \label{tab:nlp}
    %\enquote{\smallcorrect{}} means the aspect is mentioned in the form, \enquote{\smallwrong{}} otherwise.
\end{table}

\begin{figure*}[!t]
    \centering
    \includegraphics[width=0.95\textwidth]{img/conformer_con.drawio.png}
    \caption{Convolution module in the Conformer encoder layer. All convolutional blocks are 1D convolutions.}
    \label{fig:conf_conv}
\end{figure*}

But what about the link between 
%the 
concept and 
%the 
implementation?
Evaluating this connection corresponds to 
%answer
answering
the question: \textit{``Does the 
%developed
code exactly 
%realize the idea
implement the concept?''.}
This 
equals to
%\mn{implies}
assessing the \enquote{\textit{extent to which a program satisfies its specifications}}  \citep{McCall1977FactorsIS}, which is a fundamental attribute of a codebase, known as \textit{functionality} \citep{ISO9126,ISO/IEC2010} or functional \textbf{correctness} in the field of software quality assurance \citep{Buckley-1984-sqa,tripathy2011software}.
If this characteristic is not enforced, there is no guarantee that the code actually does what it is 
%expected, i.e. 
expected and, in turn,
that the results of a paper actually validate the concept.
%
%
%
%
% Therefore, we posit that 
% %enforcing
% \mn{fostering}
% code correctness represents a crucial aspect of research code. 
However, differently from reproducibility, code correctness has been so far 
%neglected 
overlooked by the research community.
%in the peer-review process.
%is not a currently evaluated aspect of the reviewing process of a paper.

To demonstrate this phenomenon, we scraped the latest review forms\footnote{Checked on January 15th 2023.} of the most popular conferences/journals in the NLP field, namely: 
*ACL (AACL-IJCNLP, ACL, EACL, EMNLP, NAACL), ACL Rolling Review (ARR),
ICASSP, ICML, ICLR, Interspeech, NeurIPS, and TACL.
Table \ref{tab:nlp} shows that an explicit score is assigned to reproducibility in most of the 
%conferences/journals
venues
(5 out of 8). 
% In addition, at NeurIPS, although there is no explicit score, reproducibility is listed
% among the factors that should contribute to the overall score.
%\mn{Although
In addition, although
there is no explicit score at NeurIPS, reproducibility is listed
among the factors that should contribute to the overall evaluation.
Conversely, correctness is 
%only mentioned in TACL, ICASSP, and ICLR, 
mentioned in fewer cases (3)
and its definition varies. 
%In
At ICLR and ICASSP, the scope of the term is not clearly defined, while in TACL it is 
% \sara{considered together with the \textit{soundness}} of the approach and results/experiments. 
included in the broader concept of \textit{soundness} of the experiments/results.
%The soundness of the experiments/results
The soundness is also 
%present in 
assessed at
NeurIPS and ICML but, again, 
%the 
correctness is never explicitly mentioned. Notably, 
%Interspeech's review form 
Interspeech
contemplates a score for \enquote{Technical Correctness}, which, however, refers 
%,though, 
to the reproducibility of the paper (\enquote{\textit{[...] are enough details provided to be able to reproduce the experiments?}}).
% A score related to the software is present in the ARR form, but it comprises only the usefulness and documentation of newly-released open-source code, not its correctness.
A score related to the software is present in the ARR form, but it only refers to the usefulness and documentation of newly-released open-source code rather than to its correctness.
%
%
%We can conclude that code correctness is largely neglected in the peer-review process and it is assessed only in terms of the soundness of the results and experimental settings.

% \mn{[ALLORA: QUI CI VUOLE UN PO' DI ATTENZIONE. COME GIA' DISCUSSO OGGI, SEMBRA CHE IL PROBLEMA SIA NEL PROCESSO DI BLIND REVIEW, COSA CHE NON VOGLIAMO ARRIVARE A DIRE PER NON METTERE IL CULO SULLE PEDATE...PIUTTOSTO, LE INDICAZIONI PER LE REVIEW, ANCHE NELLE TOP VENUES (E DIREI INEVITABILMENTE PERCHE' SAREBBE COMPLICATO FARE ALTRIMENTI), DIMOSTRANO UNA SCARSA ATTENZIONE ALLA CORRETTEZZA CODICE CHE E' POSSIBILE SI RIFLETTA SUGLI AUTORI...LA CHIUSA DI QUESTA SEZIONE DOVREBBE RUOTARE SU QUESTA POSSIBILITA' (\textbf{SENZA BLAMING DEL PEER REVIEW}), CHE VERRA' VERIFICATA NELLA PROSSIMA SEZIONE.]}

%In the next section, through a case study based on the open-source implementations of the Conformer architecture, we discuss the risks of this practice of evaluating the correctness solely by looking at the results. Specifically, we show how results can provide misleading indications about the correctness of the code and how building on incorrect code can lead to incorrect findings.

It is important to remark that
%our
the above discussion of 
%the
current
%above 
%peer-review
review guidelines is not meant to advocate for
code quality checks by peers, which would be hard and costly (if not impossible) to  implement systematically. Its purpose, instead, is to 
highlight that 
%
%
%
%
% the current reproducibility-centered
% %evaluation conditions
% evaluation reflects and can induce
their common emphasis on reproducibility-centered evaluation reflects and can induce
%in the authors
a reduced sensitivity towards code correctness, which 
comes with
%carries
inherent risks.
%\mg{assess the scarce sensitivity towards code correctness that comes with inherent risks.}  
%The next section discusses these risks through a case study based on open-source implementations of the widely used Conformer architecture.
In the next section, we dive into these risks by analyzing, as a case study, the open-source implementations of the state-of-the-art architecture for two tasks.
% In 
% %the next section, 
% \S\ref{sec:case-study},
% we dive into these risks by discussing a case study involving 
% %open-source implementations of 
% a state-of-the-art architecture used in two tasks and different language settings. In \S\ref{sec:checklist}, we  propose a list of recommendations aimed at mitigating these risks.}
% \mg{IO METTEREI SOLO: In the next section we dive into .... Abbiamo bisogno di spazio e forse in un paper basta collegarsi alla sezione dopo secondo me}










%%%%% NON CANCELLARE :-)
% \mn{It is important to remark that our discussion of the above peer-review guidelines is not meant to stigmatize the lack of code quality checks, which would be hard and costly (if not impossible) to  implement systematically. Its purpose, instead, is to acknowledge that these unavoidable ``environmental'' conditions can induce a reduced sensitivity towards code correctness that comes with inherent risks. 
% %The next section discusses these risks through a case study based on open-source implementations of the widely used Conformer architecture.
% In the next section, we dive into these risks by discussing a case study involving 
% %two tasks and different language settings.
% open-source implementations of a state-of-the-art architecture used in two tasks and different language settings. In Section QUATTRO...we will propose a chcklist of ... BEST PRATICES...aimed at mitigating these risks.}
