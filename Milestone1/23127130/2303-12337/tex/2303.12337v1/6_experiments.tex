

\section{Experiments}
\subsection{\textbf{\textsf{AIOZ-GDANCE}} Statistic}
\label{sec:dataAnalysis}



\begin{table}[!t]
\centering
\resizebox{\linewidth}{!}{
\setlength{\tabcolsep}{0.2 em}
{\renewcommand{\arraystretch}{1.2}
\begin{tabular}{l|c|c|c|c}
\hline
\multicolumn{1}{l|}{{Criteria}} & {Train} & {Validate} & {Test} & {Total} \\ \hline
Duration (hours) &$13.5$  &$1.6$  & $1.6$ &$16.7$   \\ \hline
Total Frames & $1,459$K & $175$K  & $174$K  & $1,808$K \\ \hline
\end{tabular}
}
}
    \caption{Train/val/ test split of our \textsf{AIOZ-GDANCE} dataset.}
    \label{tab:datasetSplit}
\end{table}




\begin{figure}[!t]
 \centering	
\subfloat[]{
	\begin{minipage}[c]{
	   0.23\textwidth}
	   \label{fig_stat_music_genre}
	   \centering
	   \includegraphics[width=0.97\textwidth]{images/Statistical/MusicGenreDis.pdf}
	\end{minipage}}
 \hspace{0ex}	
  \subfloat[]{
	\begin{minipage}[c]{
	   0.23\textwidth}
	   \label{fig_stat_dance_style}
	   \centering
	   \includegraphics[width=1.0\textwidth]{images/Statistical/DanceStyleDis.pdf}
	\end{minipage}}
\caption{Distribution (\%) of music genres (a) and dance styles (b) in our dataset.}
\label{fig:vis_Full_Balanced_Stat}
\end{figure}




\begin{figure}[!t]
 \centering	
\subfloat[]{
	\begin{minipage}[c]{
	   0.23\textwidth}
	   \label{fig_corr_dancegroup_number}
	   \centering
	   \includegraphics[width=1\textwidth]{images/Statistical/DancevsGroup.pdf}
	\end{minipage}}
 \hspace{0ex}	
  \subfloat[]{
	\begin{minipage}[c]{
	   0.23\textwidth}
	   \label{fig_corr_dancemusic}
	   \centering
	   \includegraphics[width=1.0\textwidth]{images/Statistical/MusicvsDance.pdf}
	\end{minipage}}
\caption{The correlation between dance styles and number of dancers (a); and between dance styles and music genres (b).}
\label{fig_correlation}
\end{figure}

\textbf{Dataset Split.} \textsf{AIOZ-GDANCE} comprises $16.7$ hours of whole-body motion and music audio of group dancing.
The duration of each video in our dataset is ranging from $15$ to $60$ seconds. We decode all videos at $30$ FPS.
We randomly sample all videos into train, validation and test sets with $80\%$; $10\%$; and $10\%$ of total videos, respectively. Table~\ref{tab:datasetSplit} shows the details about the training, validation, and testing splits of our dataset.


\begin{figure*}[ht] 
  \centering
  \Large
\resizebox{\linewidth}{!}{
\setlength{\tabcolsep}{2pt}
\begin{tabular}{ccccccc}
\shortstack{\includegraphics[width=0.33\linewidth]{images/DatasetVis/Input/40.png}}&
\shortstack{\includegraphics[width=0.33\linewidth]{images/DatasetVis/Input/81.png}}&
\shortstack{\includegraphics[width=0.33\linewidth]{images/DatasetVis/Input/91.png}}&
\shortstack{\includegraphics[width=0.33\linewidth]{images/DatasetVis/Input/105.png}}&
\shortstack{\includegraphics[width=0.33\linewidth]{images/DatasetVis/Input/164.png}}\\[3pt]
\shortstack{\includegraphics[width=0.33\linewidth]{images/DatasetVis/Front/40.png}}&
\shortstack{\includegraphics[width=0.33\linewidth]{images/DatasetVis/Front/81.png}}&
\shortstack{\includegraphics[width=0.33\linewidth]{images/DatasetVis/Front/91.png}}&
\shortstack{\includegraphics[width=0.33\linewidth]{images/DatasetVis/Front/105.png}}&
\shortstack{\includegraphics[width=0.33\linewidth]{images/DatasetVis/Front/164.png}}\\[3pt]
\shortstack{\includegraphics[width=0.33\linewidth]{images/DatasetVis/Top/40.png}}&
\shortstack{\includegraphics[width=0.33\linewidth]{images/DatasetVis/Top/81.png}}&
\shortstack{\includegraphics[width=0.33\linewidth]{images/DatasetVis/Top/91.png}}&
\shortstack{\includegraphics[width=0.33\linewidth]{images/DatasetVis/Top/105.png}}&
\shortstack{\includegraphics[width=0.33\linewidth]{images/DatasetVis/Top/164.png}}
\end{tabular}
}
    \caption{Example motion sequence from our dataset from front-view and top-view.}
    \label{fig:Dataset_Sequence}
\end{figure*}


\textbf{Dataset Analysis.} In Figure~\ref{fig:vis_Full_Balanced_Stat}, we show the distribution of music genres and dance styles in our dataset. As illustrated in Figure~\ref{fig_stat_music_genre}, \texttt{Pop} and \texttt{Electronic} are popular music genres while other music genres nearly share the same distribution. In Figure~\ref{fig_stat_dance_style}, \texttt{Zumba}, \texttt{Aerobic}, and \texttt{Commercial} are dominant dance styles. 

Figure~\ref{fig_corr_dancegroup_number} shows the number of dancers in each dance styles. Naturally, we see that \texttt{Zumba}, \texttt{Aerobic}, and \texttt{Commercial} have more dancers. Figure~\ref{fig_corr_dancemusic} shows the correlation between music genres and dance styles. In Figure~\ref{fig:Dataset_Sequence}, we show an example sequence of a dancing motion from our \textsf{AIOZ-GDANCE} dataset.
We recommend the readers to check our Supplementary Material and Demonstration Video for more detailed analysis and illustration.




\subsection{Group Dance Generation Result}

\subsubsection{Implementation Details}

The MLP in Equation~\ref{eq:initial_pose_generator} and~\ref{eq:decoder} has the same architecture with three hidden layers of $512$ neurons each. We apply layer normalization~\cite{ba2016layernorm} and ReLU non-linearity at each hidden layer. The Transformer Music Encoder has 2 transformer layers with 8 attention heads. Both the hidden audio and hidden motion have dimension $d_a = d_h = 1024$. We stack $L=3$ identical Group Encoder layers in the Group Motion Generator to enhance the learning capacity of the model. For the Cross-entity Attention, we also employ multi-head attention strategy with 8 heads and the dimension of query, key, and value for each head is set to $d_k=d_v = 64$. 
During training, we randomly sample the dance motion with the sequence length $T=240$ frames and train the model using $L2$ loss as in \cite{li2021AIST++}. 
We also use scheduled sampling~\cite{bengio2015scheduled} to improve the model robustness and enable long-term generation. The whole model is trained end-to-end using Adam optimizer~\cite{kingma2014adam} with batch size of 16 and learning rate of $10^{-4}$.  At test time, the group dance motions are generated in an auto-regressive manner based on the given inputs.

\subsubsection{Evaluation Protocol}
\label{sec:metric}

We use the following metrics to evaluate the quality of single dancing motion:~ Frechet Inception Distance (FID)~\cite{heusel2017ganfid,li2021AIST++}, Motion-Music Consistency (MMC)~\cite{li2021AIST++}, Generation Diversity (GenDiv)~\cite{Dance_Revolution, lee2019_dancing2music,li2021AIST++}. To evaluate the group dancing quality, we propose three new metrics: Group Motion Realism (GMR), Group Motion Correlation (GMC), and Trajectory Intersection Frequency (TIF). Please see our Supplementary Material for more discussion.

\subsubsection{Experimental Results}
\label{sec:quantitative}
We compare our method with FACT~\cite{li2021AIST++}. FACT is designed for single dance generation, thus giving our method an advantage. However, it is still the closest competing method as we propose a new group dance dataset that is not available for benchmarking before. We also analyse our method with and without using the Cross-entity Attention. We train all methods with mini-batch containing all dancers within the group instead of sampling each dancer independently as in FACT's original implementation.


\textbf{ Cross-entity Attention Analysis.} Table~\ref{tab:baseline} shows the method comparison between the baseline FACT~\cite{li2021AIST++} and our proposed GDanceR with and without Cross-entity Attention. The results show that GDanceR, especially with the Cross-entity Attention, out-performs the baseline by a large margin in all metrics. In Figure~\ref{fig:AblCompare}, we also visualize the example outputs of FACT and GDanceR. It is clear that FACT does not handle well the intersection problem. This is understandable as FACT is not designed for group dance generation, while our method with the Cross-entity Attention can deal with this problem better.




\begin{table}[!t]
\centering
\resizebox{\linewidth}{!}{
\setlength{\tabcolsep}{0.2 em} 
{\renewcommand{\arraystretch}{1.2}
\begin{tabular}{lc|ccc|ccc}
\hline
\multicolumn{2}{l|}{\multirow{2}{*}{{Method}}} & \multicolumn{3}{c|}{{Single-dance Metric}} & \multicolumn{3}{c}{{Group-dance Metric}}  \\ \cline{3-8} 
\multicolumn{2}{l|}{} & \multicolumn{1}{c|}{FID$\downarrow$} & \multicolumn{1}{c|}{MMC$\uparrow$} & GenDiv$\uparrow$ & \multicolumn{1}{c|}{GMR$\downarrow$} & \multicolumn{1}{c|}{GMC$\uparrow$} & TIF$\downarrow$ \\ \hline
\multicolumn{2}{l|}{FACT~\cite{li2021AIST++}} & \multicolumn{1}{c|}{56.20} & \multicolumn{1}{c|}{0.222} & 8.64 & \multicolumn{1}{c|}{101.52} & \multicolumn{1}{c|}{62.68} & 0.321 \\ \hline
\multicolumn{1}{l|}{\multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}GDanceR \\ (ours)\end{tabular}}}} & \textit{w/o} CA & \multicolumn{1}{c|}{63.83} & \multicolumn{1}{c|}{0.218} & 8.99 & \multicolumn{1}{c|}{109.80} & \multicolumn{1}{c|}{68.47} & 0.379\\ 
\cline{2-8} 
\multicolumn{1}{l|}{} & \textbf{\textit{w} CA} & \multicolumn{1}{c|}{\textbf{43.90}} & \multicolumn{1}{c|}{\textbf{0.250}} & \textbf{9.23} & \multicolumn{1}{c|}{\textbf{51.27}} & \multicolumn{1}{c|}{\textbf{79.01}} & \textbf{0.217}\\ \hline
\end{tabular}
}}
\caption{The generation results on our dataset. \textit{w/o} CA denotes without using Cross-entity Attention.}
    \label{tab:baseline}
\end{table}



\begin{figure}[ht] 
  \centering
  \footnotesize
\resizebox{\linewidth}{!}{
\setlength{\tabcolsep}{2pt}
\begin{tabular}{ccc}
\shortstack{\includegraphics[width=0.33\linewidth]{images/BaselineVis/Local1.png}}&
\shortstack{\includegraphics[width=0.33\linewidth]{images/BaselineVis/Global1.png}}\\[3pt]
\shortstack{\includegraphics[width=0.33\linewidth]{images/BaselineVis/Local2.png}}&
\shortstack{\includegraphics[width=0.33\linewidth]{images/BaselineVis/Global2.png}}\\[3pt]
\shortstack{\scriptsize (a) FACT~\cite{li2021AIST++}}&
\shortstack{\scriptsize (b) GDanceR}
\end{tabular}
}
\vspace{-2ex}
    \caption{Comparison between FACT~\cite{li2021AIST++} and our GDanceR. Our method handles better the consistency and cross-body intersection problem between dancers.}
    \label{fig:AblCompare}
\end{figure}


\textbf{Number of Dancers Analysis.}
Table~\ref{tab:n_dancers} demonstrates the generation results of our method when we want to generate different numbers of dancers. In general, the FID, GMR, and GMC metric do not show much correlation with the numbers of generated dancers since the results are varied. On the other hand, MMC shows its stability among all setups ($\sim 0.248$), which indicates that our network is robust in generating motion from given music regardless of the changing of initial positions. The generation diversity (GenDiv) decreases while the intersection frequency (TIF) increases when more dancers are generated. These results show that dealing with the collision during the group generation process is worth further investigation. 

\begin{table}[!t]
\centering
\resizebox{\linewidth}{!}{
\setlength{\tabcolsep}{0.3 em} 
{\renewcommand{\arraystretch}{1.2}
\begin{tabular}{c|ccc|ccc}
\hline
\multirow{2}{*}{{\begin{tabular}[c]{@{}c@{}}$N$ Generated\\ Dancers\end{tabular}}} & \multicolumn{3}{c|}{{Single-dance Metric}} & \multicolumn{3}{c}{{Group-dance Metric}} \\ \cline{2-7} 
 & \multicolumn{1}{c|}{FID$\downarrow$} & \multicolumn{1}{c|}{MMC$\uparrow$} & GenDiv$\uparrow$ & \multicolumn{1}{c|}{GMR$\downarrow$} & \multicolumn{1}{c|}{GMC$\uparrow$} & TIF$\downarrow$ \\ \hline
\textit{2} & \multicolumn{1}{c|}{48.82} & \multicolumn{1}{c|}{0.248} & 9.66 & \multicolumn{1}{c|}{53.83} & \multicolumn{1}{c|}{75.44} & 0.086 \\ 
\textit{3} & \multicolumn{1}{c|}{44.47} & \multicolumn{1}{c|}{0.245} & 9.46 & \multicolumn{1}{c|}{52.85} & \multicolumn{1}{c|}{74.07} & 0.104 \\ 
\textit{4} & \multicolumn{1}{c|}{47.32} & \multicolumn{1}{c|}{0.248} & 9.24 & \multicolumn{1}{c|}{58.79} & \multicolumn{1}{c|}{77.71} & 0.162 \\ 
\textit{5} & \multicolumn{1}{c|}{44.19} & \multicolumn{1}{c|}{0.249} & 9.38 & \multicolumn{1}{c|}{55.05} & \multicolumn{1}{c|}{78.72} & 0.218 \\ 
\textit{6} & \multicolumn{1}{c|}{50.95} & \multicolumn{1}{c|}{0.250} & 9.25 & \multicolumn{1}{c|}{59.05} & \multicolumn{1}{c|}{75.24} & 0.319 \\ 
\textit{7} & \multicolumn{1}{c|}{48.86} & \multicolumn{1}{c|}{0.250} & 9.19 & \multicolumn{1}{c|}{56.23} & \multicolumn{1}{c|}{76.01} & 0.367 \\ \hline
\end{tabular}
}}
\caption{Performance of our proposed method when we increase the number of generated dancers.}
    \label{tab:n_dancers}
\vspace{-1ex}
\end{table}


\textbf{Dance Style Analysis.} Different dance styles exhibit different challenges in group dance generation. 
As shown in Table~\ref{tab:danceStyle_baseline}, \texttt{Aerobic} and \texttt{Zumba} are quite similar for generating choreography as they usually focus on workout and sporty movements.
Besides, while \texttt{Commercial} and \texttt{Irish} are easier for the model to generate, \texttt{Bollywood} and \texttt{Samba} contain highly skilled movements that are challenging to capture and represent accurately. In Figure~\ref{fig:result_Vis}, we show the generated results of GDanceR with different dance styles. Our Supplementary Material and Demonstration Video also provide more examples.


\begin{figure}[ht] 

\setlength{\tabcolsep}{2 pt}
\begin{tabular}{ccccccc}
\shortstack{\includegraphics[width=0.32\linewidth]{images/MethodGen/1I.png}}&
\shortstack{\includegraphics[width=0.32\linewidth]{images/MethodGen/3I.png}}&
\shortstack{\includegraphics[width=0.32\linewidth]{images/MethodGen/6I.png}}\\[3pt]
\shortstack{\includegraphics[width=0.32\linewidth]{images/MethodGen/1A.png}}&
\shortstack{\includegraphics[width=0.32\linewidth]{images/MethodGen/5A.png}}&
\shortstack{\includegraphics[width=0.32\linewidth]{images/MethodGen/6A.png}}\\[3pt]
\shortstack{\includegraphics[width=0.32\linewidth]{images/MethodGen/1C.png}}&
\shortstack{\includegraphics[width=0.32\linewidth]{images/MethodGen/3C.png}}&
\shortstack{\includegraphics[width=0.32\linewidth]{images/MethodGen/6C.png}
}
\end{tabular}
\vspace{-1ex}
    \caption{Examples of generated group motions from our method.} 
    \label{fig:result_Vis}
\end{figure}



\begin{table}[!t]
\centering
\resizebox{\linewidth}{!}{
\setlength{\tabcolsep}{0.3 em}
{\renewcommand{\arraystretch}{1.2}
\begin{tabular}{c|ccc|ccc}
\hline
\multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Dance Styles\end{tabular}} & \multicolumn{3}{c|}{{Single-dance Metric}} & \multicolumn{3}{c}{{Group-dance Metric}} \\ \cline{2-7} 
  & \multicolumn{1}{c|}{FID$\downarrow$} & \multicolumn{1}{c|}{MMC$\uparrow$} & GenDiv$\uparrow$ & \multicolumn{1}{c|}{GMR$\downarrow$} & \multicolumn{1}{c|}{GMC$\uparrow$} & TIF$\downarrow$ \\ \hline
\texttt{Zumba} & \multicolumn{1}{c|}{45.86} & \multicolumn{1}{c|}{0.268} & 9.77 & \multicolumn{1}{c|}{50.97} & \multicolumn{1}{c|}{72.70} & 0.133 \\ 
\texttt{Aerobic} & \multicolumn{1}{c|}{38.68} & \multicolumn{1}{c|}{0.252} & 6.57 & \multicolumn{1}{c|}{63.62} & \multicolumn{1}{c|}{75.12} & 0.249 \\ 
\texttt{Commercial} & \multicolumn{1}{c|}{46.22} & \multicolumn{1}{c|}{0.232} & 8.58 & \multicolumn{1}{c|}{51.18} & \multicolumn{1}{c|}{81.02} & 0.056 \\ 
\texttt{Bollywood} & \multicolumn{1}{c|}{81.89} & \multicolumn{1}{c|}{0.211} & 2.14 & \multicolumn{1}{c|}{101.49} & \multicolumn{1}{c|}{74.00} & 0.377\\ 
\texttt{Irish} & \multicolumn{1}{c|}{42.02} & \multicolumn{1}{c|}{0.219} & 8.56 & \multicolumn{1}{c|}{42.73} & \multicolumn{1}{c|}{82.00} & 0.083\\
\texttt{Rumba} & \multicolumn{1}{c|}{69.62} & \multicolumn{1}{c|}{0.273} & 3.91 & \multicolumn{1}{c|}{68.00} & \multicolumn{1}{c|}{71.85} & 0.228\\ 
\texttt{Samba} & \multicolumn{1}{c|}{71.00} & \multicolumn{1}{c|}{0.228} & 7.77 & \multicolumn{1}{c|}{98.83} & \multicolumn{1}{c|}{67.76} & 0.441\\ \hline
\end{tabular}
}}
\caption{The results of different dance styles. Note that these results are obtained by training the model on each dance style.}
    \label{tab:danceStyle_baseline}
\end{table}



\begin{table}
\centering

\resizebox{\linewidth}{!}{
\setlength{\tabcolsep}{0.3 em} 
{\renewcommand{\arraystretch}{1.2}
\begin{tabular}{c|c|c|c|c|c|c} 
\hline
\multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Fusion\\Strategy\end{tabular}} & \multicolumn{3}{c|}{{Single-dance Metric}} & \multicolumn{3}{c}{{Group-dance Metric}} \\ 
\cline{2-7}
 & FID$\downarrow$ & MMC$\uparrow$  & GenDiv$\uparrow$ & GMR$\downarrow$ & GMC$\uparrow$ & TIF$\downarrow$ \\ 
\hline
No Fusion & 47.19 & 0.242 & 9.14 & 57.84  & 69.67 & 0.221 \\ 

Concatenate & 52.25 & 0.223 & 9.23 & 54.23 & 72.46 & 0.242 \\ 

\textbf{Add} & \textbf{43.90} & \textbf{0.250} & \textbf{9.23}  & \textbf{51.27} & \textbf{79.01} & \textbf{0.217} \\
\hline
\end{tabular}}}
\caption{Ablation study on different fusion strategies for the motion representation.}
\label{tab:motion_fusion}
\vspace{-2ex}
\end{table}

\textbf{Latent Motion Fusion Analysis.} We investigate different fusion strategies between the local motion $h^i$ and global-aware motion $g^i$ to obtain the final motion representation $z^i$. Specifically, we experiment with three settings: \textit{(i)} No Fusion: the final motion is the global-aware motion obtained from our Cross-entity Attention ($z^i = g^i$); \textit{(ii)} Concatenate: the final motion is the concatenation of the local and global-aware motion ($z^i = [h^i; g^i]$); \textit{(iii)} Add: the final motion is the addition between local and global ($z^i = h^i + g^i$). Table~\ref{tab:motion_fusion} summarizes the results. We find that fusing the motion by adding both the local and global motion features achieves the best results.






























