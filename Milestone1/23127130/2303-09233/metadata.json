{
    "arxiv_id": "2303.09233",
    "paper_title": "SwinVFTR: A Novel Volumetric Feature-learning Transformer for 3D OCT Fluid Segmentation",
    "authors": [
        "Sharif Amit Kamran",
        "Khondker Fariha Hossain",
        "Alireza Tavakkoli",
        "Salah A. Baker",
        "Stewart Lee Zuckerbrod"
    ],
    "submission_date": "2023-03-16",
    "revised_dates": [
        "2023-03-20"
    ],
    "latest_version": 2,
    "categories": [
        "eess.IV",
        "cs.CV"
    ],
    "abstract": "Accurately segmenting fluid in 3D volumetric optical coherence tomography (OCT) images is a crucial yet challenging task for detecting eye diseases. Traditional autoencoding-based segmentation approaches have limitations in extracting fluid regions due to successive resolution loss in the encoding phase and the inability to recover lost information in the decoding phase. Although current transformer-based models for medical image segmentation addresses this limitation, they are not designed to be applied out-of-the-box for 3D OCT volumes, which have a wide-ranging channel-axis size based on different vendor device and extraction technique. To address these issues, we propose SwinVFTR, a new transformer-based architecture designed for precise fluid segmentation in 3D volumetric OCT images. We first utilize a channel-wise volumetric sampling for training on OCT volumes with varying depths (B-scans). Next, the model uses a novel shifted window transformer block in the encoder to achieve better localization and segmentation of fluid regions. Additionally, we propose a new volumetric attention block for spatial and depth-wise attention, which improves upon traditional residual skip connections. Consequently, utilizing multi-class dice loss, the proposed architecture outperforms other existing architectures on the three publicly available vendor-specific OCT datasets, namely Spectralis, Cirrus, and Topcon, with mean dice scores of 0.72, 0.59, and 0.68, respectively. Additionally, SwinVFTR outperforms other architectures in two additional relevant metrics, mean intersection-over-union (Mean-IOU) and structural similarity measure (SSIM).",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.09233v1",
        "http://arxiv.org/pdf/2303.09233v2"
    ],
    "publication_venue": null
}