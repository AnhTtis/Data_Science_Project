\section{Numerical evaluation}

\textbf{Experimental scenario}. We consider a Mobile Virtual Network Operator (MVNO) which aims to acquire network resources that constitute the end-to-end network slice dedicated to its specific network service. Confronted with unknown and evolving traces such as the users' demand, the prices, and contributions of the network resources, the MVNO will follow the online reservation strategy designed by our OOLR solution. We consider the base case where the MVNO faces the incoming demand at one Base Station (BS) and must reserve $m=3$ types of resources to deliver its network service, encompassing radio resources at the BS, backhaul link capacity, and computing resources at the core. This base case falls under the scope of our system model. 

To model user demand, we use a real-world data set that contains the aggregated traffic volumes seen across multiple BSs owned by a major MNO of Shanghai \cite{jb-icc20}. Traffic volumes
have been recorded over a one-month period, spanning from
Friday 1 August 2014 00:00 to Sunday 31 August 2014 23:50,
with each recording averaged over a period of 10 minutes.
Hence, there are 6 measurements per hour and a total of 4464
measurements for each BS over this period.

%The data set we use contains the aggregated traffic volumes
%seen across 20 base stations owned by a major MNO within
%the city of Shanghai. For each base station, traffic volumes
%have been recorded over a one-month period, spanning from
%Friday 1 August 2014 00:00 to Sunday 31 August 2014 23:50,
%with each recording averaged over a period of 10 minutes.
%Hence, there are 6 measurements per hour and a total of 4464
%%measurements for each base station over this period. 
%We model the SP demand with the traffic load observed at one base station in a residential area. 

We assume the network resources prices vary with non-stationary dynamics. We model such variations with an AR($1$) (Auto-Regressive with $1$ lag) process, the discrete-time equivalent of the Ornstein-Ulhenbeck (OU) process. This stochastic process is applied in financial mathematics to model stock prices. %\cite{OU}. 
We model the contribution parameters -items of vector $\bm \theta_t$- as varying and non-stationary. Each item follows a seasonal trend (sine wave), with an offset and added OU stochastic process.

We compare the OOLRgrad solution to the FTRL baseline. The latter consists of the update as defined in equation \eqref{eq:ftrl}. We introduce the parameter $\zeta$ to control the quality of different prediction models, where $\zeta$ is the average relative error rate of the prediction $\grad \hat{f}_{t+1}(\boldsymbol{\hat{z}}_{t+1})$ against the real value $\grad f_{t+1}(\boldsymbol{z}_{t+1})$. We set $\zeta=0, 0.3$ and $4$ to represent prediction models from perfect accuracy to arbitrarily bad. This allows us to introduce three OOLR baselines, with different levels of prediction accuracy.

\textbf{Prediction module}. The solution OOLR is \emph{optimistic} in the sense it allows the SP to use the predicted gradient term $\grad \hat{f}_{t+1}(\boldsymbol{\hat{z}}_{t+1})$ of the next slot. In \eqref{eq:regret_bound}, we concluded that accurate predictions can greatly enhance the performance, as the regret bound goes from $\mathcal{O}(\sqrt{T})$ when predictions are arbitrarily bad to $\mathcal{O}(1)$ when predictions are perfect. This observation paves the way to the introduction of a prediction module, in support of our OOLR decision algorithm. We aim to find an accurate, robust and computationally low model. The algorithm ARMA-OGD created by Anava et al. in \cite{anava} presents these three key advantages. It consists of learning the AR($q$) signal of the trace where the $q$ lag coefficients are updated online at each slot by the gradient descent method. The algorithm guarantees that the total loss is no more on average than the loss of the best ARMA predictor with full hindsight. 

First, we show in Fig. \ref{fig:ARMAOGD} that the model is accurate against two intricate signals. The SP demand is based on multiple latent factors, which makes the signal non-stationary and hard to predict. Yet, we observe the predicted signal is able to track the SP demand. The $2m$ gradient items are composed of multiple signals, namely the SP demand, the prices and contributions of the network resources. %, as the reader can observe in the following expression of the gradient:
%\begin{align}
%    \grad f_t(\bm z_t) &= \begin{bmatrix}
 %          -V \frac{a_t \theta_{t,1}}{1+ (\bm x_t + \bm y_t)^\top \bm \theta_t  } + p_{t,1} \\
  %          -V \frac{a_t \theta_{t,2}}{1+ (\bm x_t + \bm y_t)^\top \bm \theta_t  } + p_{t,2} \\
   %        \vdots \\
    %       -V \frac{a_t \theta_{t,m}}{1+ (\bm x_t + \bm y_t)^\top \bm \theta_t  } + p_{t,m} \\
     %      -V \frac{a_t \theta_{t,1}}{1+ (\bm x_t + \bm y_t)^\top \bm \theta_t  } + q_{t,1} \\
      %     -V \frac{a_t \theta_{t,2}}{1+ (\bm x_t + \bm y_t)^\top \bm \theta_t  } + q_{t,2} \\
       %    \vdots \\
        %   -V \frac{a_t \theta_{t,m}}{1+ (\bm x_t + \bm y_t)^\top \bm \theta_t  } + q_{t,m}
        % \end{bmatrix} \label{eq:gradient}
 % \end{align}
Yet again, the model is able to give an accurate predicted signal. Secondly, ARMA-OGD provides guarantees of performance against all types of traces, which ensures its robustness. The total squared loss of the model is a $\mathcal{O}(\sqrt{T})+ Res$, where $Res$ represents the residual squared loss of the best ARMA predictor with full hindsight of the target signal. We show in Fig. \ref{fig:squaredloss} the convergence of the average squared loss towards $Res$. Finally, the ARMA-OGD is based on the OGD update step, which is very low computationally and allows us to develop the algorithm alongside the OOLR solution. We insist here that the two combined solutions having both low time complexity allow the SP to take \emph{optimistic decisions in real time}. There exists other models which employ advanced techniques such as Neural Networks that would obtain better accuracy than the ARMA-OGD. Nevertheless, these models necessitate an offline training phase, do not provide guarantees of performance, and have higher time complexity.

%Algorithm OOLR allows to use predictions through the term $\grad \hat{f}_{t+1}(\boldsymbol{\hat{z}}_{t+1})^\top \bm z$. From \eqref{eq:regret_bound}, we know that accurate prediction can greatly enhance the performance of the decisions. Thus, we combine our OOLR decision algorithm with a prediction module, which is both low computationally and accurate. To this aim, we use the algorithm ARMA-OGD from Anava et al. \cite{anava}. This algorithm forecasts the next point of the signal by creating an AR($q$) process, where the $q$ lag coefficients are updated at each observation thanks to an online gradient descent step. The algorithm guarantees with minimal assumptions the performance is no worse than the best ARMA predictor with full hindsight.

%In Fig. \ref{fig:ARMAOGD}, we show the predicted signal of the ARMA-OGD method against the actual SP demand signal. Although the initialization is rather imprecise as the first lags coefficients are chosen randomly, we observe that the predicted signal matches the actual signal over time, which means the online gradient descent update of the $2$ lags coefficients allows the generated AR($2$) process to track the actual signal. 

%In Fig. \ref{fig:pred_demand}, we compare the performance of ARMA-OGD and the best ARMA model. First, we clarify that the ARMA model is fitted to the demand signal, which means it knows the signal \emph{beforehand}. On the other hand, the signal value is revealed to the ARMA-OGD method only after the prediction. We observe in Fig. \ref{fig:pred_demand} that the ARMA-OGD performance in terms of squared loss and relative error rate slowly converges towards the best ARMA model performance. The average relative error rate is close to the variance of the trace ($0.24$), as the generated AR($2$) process is unable to predict the noise feature. We observe that the ARMA($10$,$1$) can understand better the noise feature, thanks to its moving-average component, leading to a smaller average relative error rate.


\begin{figure}
    \centering
    \includegraphics[width=1.\linewidth]{images/ARMAOGD.pdf}
    \caption{\small{The x-axis encompasses the first week of August period. \emph{Upper part:} the predicted signal against the real-world MVNO demand signal. The y-axis values are normalized. \emph{Lower part:} the predicted signal against the first of the gradient $2m$ items.}}
    \label{fig:ARMAOGD}
    \vspace{-6mm}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=1.\linewidth]{images/squaredloss.pdf}
    \caption{\small{We evaluate the accuracy of the models on the first week of August. \emph{Left side:} We observe the convergence of the average squared loss of the predicted gradient first item towards the best ARMA in hindsight. \emph{Right side:} We observe the convergence of the average squared loss of the predicted MVNO demand toward the best ARMA in hindsight.}}
    \label{fig:squaredloss}
    \vspace{-6mm}
\end{figure}




\textbf{Impact of the quality of predictions}. The SP can reserve $m=3$ kinds of resources. We assume the NO sets the upper bound constraint to $D_i=1,\forall i$. This means the SP reserves normalized values for each type of resource. %We recall from our system model that the slice capacity is a linear combination of those normalized values and the SP utility is a logarithmic function of the obtained slice capacity. 
 Our goal is to maximize the SP utility while avoiding excessive reservation cost. We balance between the two terms (utility and cost) using the hyper-parameter $V$. % As one term is approximately $V*2\log(1+X)$, the other term is $X$ and $X$ is around $1$, we set $V=2$ to have both terms of the same order.
 We calibrate $V=2$ to have both terms of the same order.

We call OOLRgrad the online decision algorithm OOLR because the prediction method ARMA-OGD is directly applied to the gradient items. %We omit to show the OOLRsignal version where the prediction method is applied to the feedback signals (demand, prices, etc.) as it does not provide any regret bound guarantee.
%We expect a regret bound of $\mathcal{O}(\sqrt{Res+\sqrt{T}})\sim\mathcal{O}(T^{1/4})$, at the condition the residual error $Res$ of the best ARMA fitted model is a $\mathcal{O}(\sqrt{T})$. 
We show in Fig. \ref{fig:static} against the static benchmark as defined in \eqref{eq:static_regret} the performance of the OOLRgrad solution, the classical FTRL algorithm with euclidean regularizer and the different OOLR models $\zeta=0, 0.3$ and $4$. We first observe the convergence of the average regret $R_T/T$ towards $0$ for the five models, which confirm the regret bound of $\mathcal{O}(\sqrt{T})$ even for arbitrarily bad predictions (represented by the OOLR $\zeta=4$ model). Secondly, we observe a negative regret for the other four models, which confirm the $\mathcal{O}(1)$ regret bound when the predictions are accurate and the accumulated error $\sum_{t=1}^T ||\grad f_t(\boldsymbol{z}_t) - \grad \hat{f}_t(\hat{\boldsymbol{z}}_t)||^2$ is close to $0$. Zooming in the last slots, we remark that our OOLRgrad solution based on the ARMA-OGD predictor shows better performance than the OOLR solution with a $70\%$ accurate predictor ($\zeta=0.3$) and is inferior to the OOLR with perfect predictor ($\zeta=0$). The OOLRgrad and the OOLR $\zeta=0, 0.3$ solutions outperform the FTRL baseline, which shows that the incorporation of accurate predictions enhances the performance. One needs to be cautious as arbitrarily bad predictions (OOLR $\zeta=4$) worsens the performance.  %, which is a thrilling result.
In Fig. \ref{fig:dynamic}, we show the performance of the same solutions against the optimal benchmark, defined by the dynamic sequence $\{\bm z_t^* \}$, where $\forall t$, $$\bm z_t^* = \arg\min_{\bm z \in \mathcal{Z}} f_t(\bm z).$$ Against such competitive benchmark, the regret cannot be sublinear and thus the convergence of $R_T/T$ towards $0$ is not achieved. Nevertheless, we observe that the OOLRgrad solution displays good performance when compared to the different baselines.

%Therefore, we can either predict the $2m$ items of the gradient or predict the $3m+1$ signals the SP receives (the demand $\{a_t\}_t$, the network resources prices $\{p_{t,i}\}_{t,i}$ and $\{q_{t,i}\}_{t,i}$,  the network resources contributions $\{\theta_{t,i}\}_{t,i}$). We consider the two approaches in the sequel. On the one hand, the predictions on the gradient itself imply to predict $2m$ different signals, instead of $3m+1$. On the other hand, the variance of the $2m$ signals is higher as they are composed of multiple signals.

%We introduce the parameter $\beta$ to control the quality of the predictions and we look at two specific values of $\beta$ which are $0.3$ and $4$, being the average relative error rate on the sequence of gradients $\grad f_1(\bm z_1), \ldots \grad f_T(\bm z_T)$, of the good predictor and the bad predictor, respectively.

%In Fig. \ref{fig:reg}, we observe 4 different solutions. The solutions $\beta=0.3$ and $\beta=4$ correspond to the OOLR with good predictor and bad predictor, respectively. In the OGDs solution, we directly predict the $3m+1$ signals, while in the OGDg solution, we predict the resulting $2m$ signals within the gradient. We observe that the $\beta=0.3$ solution is the best. The OGDs solution is second, with an average relative error rate of $0.8$ on the gradient. Finally, $\beta=4$ and OGDg performances are similarly worse due to similar relative error rates. We still obtain a negative regret for the two worst solutions, which confirms the regret bound stated in Section II. We observe as expected a degradation of the performance when the prediction quality worsens.
\begin{figure}
\begin{subfigure}{.24\textwidth}
    \centering
    \includegraphics[width=1.\linewidth]{images/new_regret.pdf}
    \vspace{-6mm}    
    \caption{Static benchmark}
    \label{fig:static}
\end{subfigure}
\begin{subfigure}{.24\textwidth}
    \centering
    \includegraphics[width=1.\linewidth]{images/new_dynamicregret.pdf}
    \vspace{-6mm}
    \caption{Optimal benchmark}
    \label{fig:dynamic}
\end{subfigure}
\vspace{-3mm}
\caption{\small{\emph{Evolution of $R_T/T$:} Horizon $T=1008$, $m=3$, $V=2$, $\bm D=[1,1,1]$, $D=\sqrt{3}$, $\sigma = \sqrt{2}/D$.}}
\label{fig:regret}
\end{figure}


%\begin{figure}
 %   \centering
  %  \includegraphics[width=1.\linewidth]{images/new_regret.pdf}
   % \caption{\small{\emph{Evolution of $R_T/T$:} Horizon $T=1008$, $m=3$, $V=2$, $\bm D=[1,1,1]$, $D=\sqrt{3}$, $\sigma = \sqrt{2}/D\sqrt{T}$.}}
    %\label{fig:static}
%\end{figure}

%\begin{figure}
 %   \centering
 %   \includegraphics[width=1.\linewidth]{images/new_dynamicregret.pdf}
 %   \caption{\small{\emph{Evolution of $R_T/T$:} Horizon $T=1008$, $m=3$, $V=2$, $\bm D=[1,1,1]$, $D=\sqrt{3}$, $\sigma = \sqrt{2}/D\sqrt{T}$.}}
 %   \label{fig:dynamic}
%\end{figure}

%\textbf{Doubling trick}.
%An essential feature of the OOLRgrad solution is the selection of the hyper-parameter $\sigma = \sqrt{2}/D\sqrt{T}$. Only this specific value of $\sigma$ gives a sublinear upper-bound on the regret. In the case the horizon $T$ is unknown, which might probably arise in real-world settings, it becomes necessary to find a good alternative to the selection of $\sigma$. As detailed previously in section \ref{sec:algo}, \emph{Remark 4}, the doubling trick allows us to select $\sigma = \sqrt{2}/D\sqrt{2^{k+1}}$ when $t\in[2^k,\ldots2^{k+1}-1]$. The regret bound only worsens by a factor of $\sqrt{2}/(\sqrt{2}-1)$, which keep the sublinear guarantee of our solution. We observe in Fig. \ref{fig:dt} that the doubling trick actually improves slightly the performance, while it provides the same regret guarantee.

%\begin{figure}
%\begin{subfigure}{.24\textwidth}
%    \centering
%    \includegraphics[width=1.\linewidth]{images/doublingtrick.pdf}
%    \vspace{-6mm}    
%    \caption{Doubling trick}
%    \label{fig:dt}
%\end{subfigure}
%\begin{subfigure}{.24\textwidth}
%    \centering
%    \includegraphics[width=1.\linewidth]{images/extensionSLAcomparison.pdf}
%    \vspace{-6mm}
%    \caption{Extension}
%    \label{fig:ex}
%\end{subfigure}
%\vspace{-1.5mm}
%\caption{\small{\emph{Evolution of $R_T/T$:} Horizon $T=1008$, $m=3$, $V=2$, $\bm D=[1,1,1]$, $D=\sqrt{3}$, $\sigma = \sqrt{2}/D$ when $T$ is known.}}
%\label{fig:extra}
%\vspace{-6mm}
%\end{figure}


%\begin{figure}
 %   \centering
 %   \includegraphics[width=1.\linewidth]{images/doublingtrick.pdf}
 %   \caption{\small{\emph{Evolution of $R_T/T$:} Horizon $T=1008$, $m=3$, $V=2$, $\bm D=[1,1,1]$, $D=\sqrt{3}$, $\sigma = \sqrt{2}/D\sqrt{T}$ when $T$ is known.}}
 %   \label{fig:DT}
%\end{figure}


\textbf{Extension}.
Now we evaluate the OOLRgrad solution in the scenario where the NO is unable to fulfill the SP request in its entirety.
We focus on a basic scenario in which the NO ensures a minimum ratio of $\alpha$ for in-advance resources -- in a more complex scenario the NO commits to a ratio of $\alpha_i$ for each resource $i$, where $\alpha_i$ are possibly different. Thus, for each resource $i$ at slot $t$, the SP expect to receive a ratio $\alpha_{i,t}$ that belongs to the set $[\alpha,1]$. We draw the $\{\alpha_{i,t}\}_t$ from the uniform distribution on $[\alpha,1]$.  We assume that the NO consistently deliver all requested spot resources, thus we keep $\beta=1$.
We observe in Fig. \ref{fig:SLA} the regret performance of the OOLRgrad solution for three different SLAs, which are $\alpha\in\{0.5, 0.8, 0.95\}$. We observe that the performance stays similar regardless of the SLA the SP has complied for, which implies our OOLRgrad solution is consistently applicable.

\begin{figure}
    \centering
    \includegraphics[width=7cm, height=5cm]{images/extensionSLAcomparison.pdf}
    \caption{\small{\emph{Evolution of $R_T/T$:} Horizon $T=1008$, $m=3$, $V=2$, $\bm D=[1,1,1]$, $D=\sqrt{3}$, $\sigma = \sqrt{2}/D$.}}
    \label{fig:SLA}
    \vspace{-5mm}
\end{figure}


%\subsection{Estimation step method of the next point}
%Which method to use, and in which scenario?
%\subsection{Doubling trick}