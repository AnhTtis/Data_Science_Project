\section{Conclusions}
\label{sec:conc}

We have presented and solved a linearized minimal model of Barlow Twins (Sections \ref{sec:linear_th} and \ref{sec:kernel_th}).
Our solution reveals that, as training proceeds, the model sequentially learns the top $d$ eigenmodes of a certain kernel in a discrete fashion, stopping when the embeddings are full rank.
Turning to bona fide ResNets in near-realistic training settings, we see precisely this learning behavior for Barlow Twins, SimCLR, and VICReg in both their embeddings and hidden representations.
This paints a new, useful picture of the training dynamics of SSL: rather than a black-box optimization process that magically converges on final representations, we can perhaps think of self-supervised training as an iterative process of selecting desirable rank-one functions and tacking them onto a growing representation.

Our theory has several clear limitations.
First, practical deep neural networks are \textit{not} kernel methods: the NTK is known to change over time \citep{yang:2021-tensor-programs-IV, vyas:2022-limitations-of-the-ntk-for-generalization}.
This suggests that our theory's predicted representations will not closely match those predicted by the initial NTK in practical cases, though it is plausible that they \textit{will} match those predicted by the empirical NTK \textit{after} training in light of similar results for supervised learning \citep{long:2021-after-kernel, atanasov:2021-silent-alignment}.
Second, in practice, downstream tasks in self-supervised pipelines are usually trained not on the final embeddings of the SSL model but rather on the hidden representation some layers prior, while our theory (like virtually all current SSL theory) only describes the embeddings.
We partially surmount this limitation by empirically observing stepwise behavior in representations, though developing theory for this observation appears a worthwhile pursuit.
We note that it is not currently known why the use of hidden representations is preferable, but having a theory of final embeddings like that we have given may aid efforts to understand how they differ from hidden representations.

This work opens new avenues of research from both theoretical and empirical angles.
For theory, we draw new connections between SSL, matrix factorization, and questions of inductive bias which admit further study.
Empirically, it seems plausible that our a picture of SSL learning can enable algorithmic improvements that give faster, more robust, or better-generalizing training.
The prospects for accelerating the training of SSL methods, which typically require many more steps to converge than standard supervised methods, seem particularly promising.
For example, our experiments suggest that this slow training may be due to the long times required for lower-eigenvalue modes to emerge, and that an optimizer or loss function that focuses updates on near-zero eigendirections in the embedding space may speed up training without sacrificing stability or generalization.
We describe several potential paths for realizing this speedup in Appendix \ref{app:speedup} and encourage practitioners to explore their implementation.

The clear occurrence of stepwise learning far outside the NTK regime suggests it ought to be derivable from a far less restrictive set of assumptions on the model.
We leave the development of a more generic theory for future work.
A promising starting point may be the view of stepwise learning as a consequence of symmetry-breaking which is discussed in Appendix \ref{app:symm}.

Another interesting direction is the observation of stepwise behavior in masked-image modeling frameworks, which currently constitute a large fraction of the SSL literature \citep{baevski:2022-data2vec, he:2022-mae, assran:2023-i-jepa}.
We suspect that, upon small initialization, their hidden representations may also exhibit stepwise dimensionality growth as the system learns to pass more and more information from input to output.






