\section{Dual Contract and Principal Heterogeneity}\label{dualcontract}

\indent This section extends our analysis from a single-principal-agent model (see \Cref{single}) to a more realistic dual-contract scenario. In this setting, a single agent simultaneously engages in contracts with two distinct principals. This structure closely resembles the dynamics of various real-world scenarios, such as venture capital funding rounds, freelance work arrangements, and multi-client consulting engagements. While offering benefits like diversified experience and combined expertise, it also presents unique challenges in terms of transparency, fairness, and potential agent exploitation. Our goal is to understand how two principals, each employing a Q-learning algorithm, learn to set contract terms ("tax rates") when interacting with an  agent.\footnote{This dynamic closely resembles the venture capital market, where startups often secure funding from multiple investors simultaneously. This parallel highlights several key similarities: 
\begin{itemize}
\item Negotiation Power: Startups with multiple investors have greater leverage to negotiate better terms, just like an individual with multiple job offers can negotiate better compensation or benefits. 
\item Access to Diverse Expertise: Venture capital firms often have specialized expertise in different industries. Similarly, working for multiple companies can expose individuals to a broader range of perspectives and skillsets.
\item Risk Management: Diversifying funding sources can mitigate risk for startups and individuals alike, reducing dependence on a single revenue stream and enhancing resilience to financial instability.
\end{itemize}} 

\subsection{Model Setup}

\indent \indent We consider two principals ($P_1$ and $P_2$) who offer contracts to a single agent $A$. Each principal has a project ($Project_1$ and $Project_2$) requiring initial investments $I_1$ and $I_2$, respectively. The agent can allocate their effort ($e_{1,t}$ and $e_{2,t}$) between these projects in each period $t$, subject to the constraint $e_{1,t} + e_{2,t} \leq 1$.

\paragraph{Contract Terms and Payoffs:}
\indent Principals independently choose tax rates ($p_{1,t}$ and $p_{2,t}$) in each period, representing the fraction of project revenue they retain. The payoffs are structured as follows:
\begin{itemize}
\item \textbf{Principal 1's Profit: } $\Pi_t^{P_1} = I_1 + (R_1 - I_1)e_{1,t}p_{1,t}$
\item \textbf{Principal 2's Profit: } $\Pi_t^{P_2} = I_2 + (R_2 - I_2)e_{2,t}p_{2,t}$
\item \textbf{Agent's Profit:} $\Pi^{A}_{t} = (1 - p{1,t})[I_1 + (R_1 - I_1)e_{1,t}] + (1 - p_{2,t})[I_2 + (R_2 - I_2)e_{2,t}] - C(e_{1,t}, e_{2,t})$
\end{itemize}
where $R_1$ and $R_2$ are the maximum potential revenues for the projects. The agent's cost function, $C(e_{1,t}, e_{2,t})$, incorporates the cost parameter $c$ and the heterogeneity parameter $\kappa$ (explained below):

\begin{equation}
C(e_{1,t}, e_{2,t}) = \frac{1}{2}c(e_{1,t} + e_{2,t})^2 (1 - \kappa + 2 \kappa e_{2,t} / (e_{1,t} + e_{2,t}))
\end{equation}

\paragraph{Profit Alignment and Heterogeneity:}

\begin{itemize}
\item We introduce a "rate of identity of interests," $\gamma \in [0, 0.5]$, to capture varying degrees of profit alignment between the principals. Higher $\gamma$ indicates greater alignment, with $\gamma = 0$ representing pure competition and $\gamma = 0.5$ representing pure collusion.
\item To model principal heterogeneity, we use the parameter $\kappa \in [0,1)$ in the agent's cost function. A higher $\kappa$ gives Principal 1 an advantage by making the agent's per-unit effort cost lower for Project 1, reflecting potential real-world biases. This bias reflects real-world scenarios where factors like reputation, pre-existing relationships, or project attributes might make one principal more appealing to the agent.
\end{itemize}


\subsection{Optimization with Q-Learning}

\indent In contrast to the single-principal-agent model, deriving closed-form solutions for the optimization problem in this dynamic dual-contract setting proves analytically intractable. To circumvent this, we employ multi-agent reinforcement-learning (MARL), enabling the principals to progressively learn optimal contract terms (tax rates) through repeated interactions with the agent and each other. Each principal maintains an independent Q-table, updating it based on their own realized profits.

\paragraph{Q-Learning Dynamics:}
\indent Both principals utilize Q-learning to optimize their strategies. Their Q-functions $Q^{P_i}(s^{P_i},p_i)$, where $i \in {1,2}$, map state-action pairs to expected profits. The Q-tables are initialized arbitrarily, and the Q-values are updated using the following rule:
\begin{equation}
Q_{t+1}^{P_i}(s_t^{P_i}, p_{i,t}) = (1 - \alpha) Q_t^{P_i}(s_t^{P_i}, p_{i,t}) + \alpha [\Pi_{i,t}^P + \delta \max_{p_{i,t+1}} Q_t^{P_i}(s^{P_i}_{t+1}, p_{i,t+1})],
\end{equation}
where:
\begin{itemize}
\item $s_t^{P_i}$ is the state of Principal $i$ at time $t$, which includes information about past tax rates offered by both principals, past profits, and potentially other relevant information.
\item $p_{i,t}$ is the tax rate chosen by Principal $i$ at time $t$.
\item $\alpha$ is the learning rate.
\item $\delta$ is the discount factor.
\item $\Pi_{i,t}^P$ is the profit of Principal $i$ at time $t$, which depends on the tax rate offered by Principal $i$, the tax rate offered by the other principal, and the agent's effort allocation.
\end{itemize}
\paragraph{Agent's Strategy:}
\indent The agent's Q-function, $Q^A(s^A, e_1, e_2)$, maps state-action pairs to expected rewards. The agent's state $s_t^A$ includes the current tax rates from both principals: $s_t^A = (p_{1,t}, p_{2,t})$. The agent's action space consists of all possible effort levels on Project 1 and Project 2, subject to the constraint $e_{1,t} + e_{2,t} \leq 1$. The agent updates their Q-function using the following rule:
\begin{equation}
Q_{t+1}^A(s_t^A, e_{1,t}, e_{2,t}) = (1 - \alpha) Q_t^A(s_t^A, e_{1,t}, e_{2,t}) + \alpha [\Pi^{A}_{t} + \delta \max_{e_{1,t+1}, e_{2,t+1}} Q_t^A(s_{t+1}^A, e_{1,t+1}, e_{2,t+1})],
\end{equation}
where $\alpha$ is the learning rate, $s_{t+1}^A$ is the next period's state, which includes the next period's tax rates from both principals ($p_{1,t+1}$, $p_{2,t+1}$), $\Pi^{A}_{t}$ is the agent's profit in period $t$ (as defined above).

In each period, the agent observes the tax rates from both principals, chooses the effort levels on both projects that maximize the estimated Q-value, and then updates their Q-table based on the observed profits. This iterative process allows the agent to learn and adapt their effort allocation strategy in response to the changing contract terms offered by the two principals.

\subsection{Baseline Parametrization and Initialization}

\indent To systematically investigate the dynamics of the dual-contract model, we define a baseline economic setting and explore variations across four key parameter grids. These parameters are summarized in \Cref{table:parameters}:

\paragraph{Baseline Economic Setting:}
\begin{itemize}
\item $I_1 = I_2 = 1$: The initial investments required for both projects are set equal to normalize the project scales.
\item $R_1 = R_2 = 2$: The maximum potential revenue for both projects is fixed at twice the initial investment, reflecting a common return target.
\item $c = I_1 + I_2 = 2$: The agent's cost parameter is set equal to the sum of the initial investments. This ensures that at maximum effort ($e_1 + e_2 = 1$), the combined project profit equals the agent's effort cost, leading to a net profit of 0 for the principals collectively.
\end{itemize}

\paragraph{Parameter Grids:}
We discretize the parameter space of the learning rate $\alpha$, exploration rate $\beta$, profit alignment $\gamma$, and principal heterogeneity $\kappa$ to systematically explore their impact on contract negotiation outcomes. The specific grids are defined as follows:
\begin{enumerate}
\item \textbf{Learning Rate $\alpha$:} The learning rate dictates how much weight principals give to new information versus their existing beliefs. We explore 100 equally spaced values between 0.025 and 0.25. This range captures a balance between slow and fast learning, allowing us to investigate the effect of learning speed on the negotiation dynamics.
\item \textbf{Exploration Rate $\beta$:} The exploration rate determines the principals' tendency to explore new tax rates versus exploiting those that have yielded high profits in the past. We vary $\beta$ over 100 equally spaced values between $10^{-6}$ and $10^{-5}$. This range ensures sufficient exploration at the beginning of the simulations while allowing for exploitation as the principals gain experience.
\item \textbf{Profit Alignment $\gamma$:} To model varying degrees of alignment between the principals' interests, we consider three distinct values for $\gamma$: 0, 0.25, and 0.5. These values represent pure competition ($\gamma = 0$), a mixed-sum game ($\gamma = 0.25$), and pure collusion ($\gamma = 0.5$). This allows us to investigate how the level of competition or cooperation influences the negotiated contract terms and the resulting profits.
\item \textbf{Principal Heterogeneity $\kappa$:} We consider two levels of principal heterogeneity, $\kappa = 0$ (non-heterogeneity) and $\kappa = 0.25$. The inclusion of $\kappa$ allows us to examine the impact of asymmetry in the agent's effort cost on the bargaining power dynamics and effort allocation. Specifically, we can analyze how even a slight advantage for one principal might affect the agent's effort allocation and the final distribution of profits.
\end{enumerate}


\indent This parametrization allows us to isolate the effects of varying $\gamma$ and $\kappa$ on the contract outcomes. For the Q-learning algorithms, we employ the following settings:

\begin{itemize}
\item \textbf{Initial Q-values $Q_0$:} All Q-tables are initialized with random values drawn uniformly from the interval [0, 1], representing a lack of prior knowledge about the optimal contract terms.
\item \textbf{Discount Factor $\delta$:} We use a discount factor of 0.9, reflecting the importance of future rewards in the principals' decision-making.
\item \textbf{Memory Length $k$:} This parameter, set to 1 in our baseline, determines the number of past tax rates that are included in the state representation. This allows us to investigate the impact of memory on the negotiation dynamics.
\end{itemize}


\subsection{Results and Discussion}
This section presents the findings from simulating the dual-contract model across varying levels of profit alignment $\gamma$ and principal heterogeneity $\kappa$. We focus on three key aspects: the convergence of tax rates chosen by the principals, the agent's effort allocation across the two projects, and the resulting profit distribution among the stakeholders.

\subsubsection{Impact of Learning and Exploration Rates}

\begin{figure}[htbp]
\centering
\includegraphics[width=1\textwidth]{results/dual/combined_heatmaps_group1_gamma_0_kappa_0_memory_1.png}
\caption{Average values for Principal 1 profit, Principal 2 profit, effort for Project 1, effort for Project 2, tax rate for Principal 1, and tax rate for Principal 2 for $\gamma=0, \kappa=0$. The heatmaps illustrate the impact of learning rate $\alpha$ and exploration rate $\beta$ on these six variables.}
\label{fig:heatmaps-gamma-0}
\end{figure}
The learning rate $\alpha$ and exploration rate $\beta$ significantly influence the dynamics of the Q-learning process and, consequently, the contract negotiation outcomes. To illustrate this impact, we analyze the heatmaps depicting average Principal 1 profit, average Principal 2 profit, average effort for Project 1, average effort for Project 2, average tax rate for Principal 1, and average tax rate for Principal 2 across different values of $\alpha$ and $\beta$, under pure competition scenario ($\gamma=0$, $\kappa=0$) shown in Figure \ref{fig:heatmaps-gamma-0}.

A clear pattern emerges: higher $\alpha$ values generally lead to faster convergence of both tax rates and profits. This is because principals with higher learning rates adapt more quickly to new information, reaching stable outcomes faster. This observation highlights the importance of learning agility in dynamic negotiation environments. Conversely, larger $\beta$ values, corresponding to higher exploration rates, introduce more volatility in the early stages of the negotiation process. This is because principals experiment with a wider range of tax rates before converging, leading to fluctuations in profits and effort allocations. This highlights the trade-off between exploration (gathering information) and exploitation (leveraging seemingly profitable strategies) in reinforcement learning.


\begin{figure}[htbp]
\centering
\includegraphics[width=1\textwidth]{results/dual/combined_heatmaps_group2_gamma_0_kappa_0_memory_1.png}
\caption{Convergence Iteration for Principal 1 and Principal 2 for $\gamma=0, \kappa=0$. The heatmap illustrates the impact of learning rate $\alpha$ and exploration rate $\beta$ on the convergence iteration.}
\label{fig:heatmaps-profits_2}
\end{figure}

Remarkably, larger $\beta$ values, corresponding to higher exploration rates, might delay the convergence to a stable strategy as principals experiment with a wider range of tax rates. This delay is reflected in \Cref{fig:heatmaps-profits_2}, which shows that higher $\beta$ values generally lead to more iterations required for convergence, especially for certain learning rates. This exploration, while crucial for gathering information about the system dynamics, could potentially prolong the period of fluctuating profits before the principals settle on a fixed strategy.


\subsubsection{Profit Alignment and Emergent Cooperation}

The level of profit alignment $\gamma$ between the principals significantly shapes the negotiation outcomes, directly influencing their achieved profits. We can observe these dynamics by analyzing the average principal profits visualized in heatmaps across different learning rates $\alpha$ and exploration rates $\beta$ under varying degrees of profit alignment, specifically $\gamma = 0$, $\gamma = 0.25$, and $\gamma = 0.5$, while keeping principal heterogeneity constant $\kappa = 0$.

\begin{figure}[htbp]
\centering
\includegraphics[width=1\textwidth]{results/dual/combined_heatmaps_group1_gamma_0.25_kappa_0_memory_1.png}
\caption{Average values for Principal 1 profit, Principal 2 profit, effort for Project 1, effort for Project 2, tax rate for Principal 1, and tax rate for Principal 2 for $\gamma=0.25, \kappa=0$. The heatmaps illustrate the impact of learning rate $\alpha$ and exploration rate $\beta$ on these six variables.}
\label{fig:heatmaps-gamma-0.25}
\end{figure}

\Cref{fig:heatmaps-gamma-0} depicts the outcomes for $\gamma=0$, while \Cref{fig:heatmaps-gamma-0.25} displays the results for  $\gamma=0.25$, and \Cref{fig:heatmaps-gamma-0.5} illustrates the case when $\gamma=0.5$. As $\gamma$ increases, we observe a noticeable upward shift in the average profits for both principals. For instance, focusing on the top-left heatmaps in each figure, which represent average Principal 1 profit, we can see a clear trend of increasing profit as $\gamma$ changes from 0 to 0.25 and then to 0.5. This difference suggests that even a small degree of profit alignment can incentivize a degree of implicit cooperation between the principals, leading to higher tax rates and, consequently, higher average profits. 


\begin{figure}[htbp]
\centering
\includegraphics[width=1\textwidth]{results/dual/combined_heatmaps_group1_gamma_0.5_kappa_0_memory_1.png}
\caption{Average values for Principal 1 profit, Principal 2 profit, effort for Project 1, effort for Project 2, tax rate for Principal 1, and tax rate for Principal 2 for $\gamma=0.5, \kappa=0$. The heatmaps illustrate the impact of learning rate $\alpha$ and exploration rate $\beta$ on these six variables.}
\label{fig:heatmaps-gamma-0.5}
\end{figure}

Furthermore, examining the heatmaps for average effort for Project 1 and Project 2, we observe that as $\gamma$ increases, the difference in effort allocation between the two projects becomes less pronounced. This observation indicates that with higher profit alignment, the competition for the agent's effort becomes less intense, leading to a more balanced effort allocation across both projects. 

These observations underscore the significant influence of profit alignment on the strategic dynamics in multi-principal settings. Even a small degree of shared interest can incentivize more cooperative behavior, leading to higher average profits for the principals and potentially a more balanced effort allocation from the agent. As the alignment of incentives increases, the potential for emergent cooperation strengthens, ultimately shifting the system away from cutthroat competition towards strategies that benefit all parties involved.

As we shift to a scenario with partial profit alignment, represented by $\gamma = 0.25$ in Figure \ref{fig:heatmaps-gamma-0.25}, a noticeable shift occurs. The average profits for Principal 1 are markedly higher compared to the purely competitive case. This difference suggests that even a small degree of profit alignment can incentivize a degree of implicit cooperation between the principals, leading to higher tax rates and, consequently, higher average profits.


In a purely competitive scenario ($\gamma = 0$), both principals, driven solely by their profit maximization, engage in a race to the bottom, consistently converging to the lowest possible tax rate, as depicted in Figure \ref{fig:four}. 

\begin{figure}[htbp]
\centering
\subfigure[]{
\includegraphics[width=2.5in]{beta0_1.png}
}
\subfigure[]{
\includegraphics[width=2.5in]{beta0_2.png}
}
\quad
\subfigure[]{
\includegraphics[width=2.5in]{beta0_3.png}
}
\subfigure[]{
\includegraphics[width=2.5in]{beta0_4.png}
}
\caption{Convergence of tax rates under pure competition ($\gamma=0$). Both Q-learning algorithms converge to the lowest possible positive tax rate.}
\label{fig:four}
\end{figure}

However, a striking phenomenon emerges when the principals' profits are perfectly aligned ($\gamma = 0.5$). Figure \ref{fig:five} illustrates this scenario, where despite the absence of explicit communication or coordination mechanisms, the Q-learning algorithms demonstrate emergent cooperative behavior. 

\begin{figure}[htbp]
\centering
\subfigure[]{
\includegraphics[width=2.6in]{beta5_0.png}
}
\subfigure[]{
\includegraphics[width=2.6in]{beta5_2.png}
}
\quad
\subfigure[]{
\includegraphics[width=2.6in]{beta5_3.png}
}
\quad
\subfigure[]{
\includegraphics[width=2.6in]{beta5_4.png}
}
\caption{Convergence of tax rates under pure collusion ($\gamma=0.5$). The Q-learning algorithms learn to implicitly cooperate, converging on higher tax rates than in the competitive scenario.}
\label{fig:five}
\end{figure}

This implicit collusion is evident in the convergence towards higher tax rates compared to the competitive cases. This spontaneous coupling effectively allows the principals to extract more surplus from the agent, maximizing their joint profit, reflected in the higher average profits observed in the heatmaps for  $\gamma = 0.5$.

Further reinforcing these observations, Figure \ref{fig:six} demonstrates the impact of varying levels of profit alignment on the effective tax rate convergence. As $\gamma$ increases, we observe a gradual shift from competitive to more cooperative dynamics, resulting in higher converged tax rates. 

\begin{figure}
\centerline{\includegraphics[width=5in]{betaResult.png}}
\caption{Effective tax rate convergence for varying levels of profit alignment $\gamma$. As $\gamma$ increases, the simulations demonstrate a gradual shift from competitive to more cooperative dynamics.}
\label{fig:six}
\end{figure}

The principals, even without explicit communication, learn to balance their self-interest with the potential gains from coordinated action, leading to intermediate levels of cooperation and subsequently impacting the average profits observed in the heatmaps.

\subsubsection{Principal Heterogeneity and Bargaining Asymmetry}

Introducing heterogeneity between the principals ($\kappa > 0$) by making the agent's effort cost asymmetric significantly impacts the bargaining power dynamics. This asymmetry creates a distinct advantage for the favored principal (Principal 1 in our model).

\begin{figure}[htbp]
\centering
\includegraphics[width=1\textwidth]{results/dual/combined_heatmaps_group1_gamma_0.25_kappa_0_memory_1.png}
\caption{Average Effort for Project 1 for $\gamma=0.25, \kappa=0$. The heatmap demonstrates the impact of principal heterogeneity on the agent's effort allocation.}
\label{fig:heatmaps-efforts-1}
\end{figure}

Figure \ref{fig:heatmaps-efforts-1} presents a heatmap of the agent's average effort for Project 1 across different learning and exploration rates for a symmetric scenario ($\gamma=0.25, \kappa=0$). 

\begin{figure}[htbp]
\centering
\includegraphics[width=1\textwidth]{results/dual/combined_heatmaps_group1_gamma_0.25_kappa_0.25_memory_1.png}
\caption{Average Effort for Project 2 for $\gamma=0.25, \kappa=0.25$. The heatmap demonstrates the impact of principal heterogeneity on the agent's effort allocation.}
\label{fig:heatmaps-efforts-2}
\end{figure}

Conversely, Figure \ref{fig:heatmaps-efforts-2} showcases the same information, but for an asymmetric scenario ($\gamma=0.25, \kappa=0.25$). These figures reveal that Principal 1, benefiting from the agent's lower effort cost, can sustain higher tax rates without losing the agent's effort, even under competitive pressure. This "protection effect" arises from the agent's rational preference for the less costly project, granting Principal 1 greater bargaining power. 


The agent's rational behavior is further reflected in the effort allocation, as illustrated in Figure \ref{fig:seven}. The agent allocates more effort toward the less costly project offered by Principal 1, reinforcing the protection effect and further amplifying Principal 1's profit advantage.

\begin{figure}[htbp]
\centering
\subfigure[Agent's effort in Project 1]{
\includegraphics[width=1.7in]{ae1.png}
}
\subfigure[Agent's effort in Project 2]{
\includegraphics[width=1.7in]{ae2.png}
}
\subfigure[Agent's maximum profit given $p_{1}$ and $p_{2}$]{
\includegraphics[width=1.7in]{aProfit.png}
}
\caption{Agent's optimal strategy under principal heterogeneity ($\kappa > 0$). The agent allocates more effort toward the less costly project offered by Principal 1.}
\label{fig:seven}
\end{figure}

\subsubsection{Spontaneous Coupling and its Implications}
Our findings highlight the potential for spontaneous coupling to emerge in multi-principal settings, even without explicit collusion. Figure \ref{fig:eight} depicts the convergence of the effective tax rate – the lower of the two offered tax rates – under varying levels of $\gamma$ in the presence of principal heterogeneity. We observe that higher $\gamma$ values lead to stronger spontaneous coupling, resulting in higher converged tax rates and greater surplus extraction from the agent. Furthermore, principal heterogeneity introduces an additional layer of complexity. While both principals might benefit from spontaneous coupling when $\gamma$ is high, the advantaged principal (Principal 1) consistently secures a larger share of the surplus due to the protection effect. This is illustrated by the higher effective tax rate for Principal 1 across different $\gamma$ values.
\begin{figure}
\centerline{\includegraphics[width=5in]{asymBeta.png}}
\caption{Effective tax rate convergence under principal heterogeneity for varying levels of profit alignment ($\gamma$). The advantaged principal (Principal 1) consistently secures a higher effective tax rate.}
\label{fig:eight}
\end{figure}
\subsubsection{Discussion}
The emergence of spontaneous coupling in our model raises important questions about its implications for market dynamics and agent welfare. Future research should explore the robustness of these findings across different learning algorithms, information structures, and agent behaviors. Furthermore, designing mechanisms to mitigate the potentially negative consequences of spontaneous coupling on agent welfare presents a significant challenge for future work.