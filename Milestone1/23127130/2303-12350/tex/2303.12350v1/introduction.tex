\section{Introduction}\label{introduction}

\indent Platforms are increasingly adopting Artificial Intelligence (henceforth, AI) algorithms (for example, the ChatGPT (\cite{ouyang2022training}) and \cite{eloundou2023gpts}) to intelligentize services and price their products, and this tendency is likely to be extended to other business areas, particularly contract design. In this paper, we ask whether contracting algorithms may "autonomously" learn to be incentive compatible, especially for the contracting problem with multiple sides, which we also refer to as the \emph{multi-sided contracting} problem. We emphasize that AI algorithms can be used to automatically optimize the terms of a contract by taking into account the preferences of both sides and the legal and economic environment in which the agreement must be implemented. Note that this contract negotiation process is automatic, requiring very little external guidance.


\indent In light of these developments, concerns have been voiced by scholars and organizations alike, that AI algorithms may create an \emph{AI alignment problem} due to differences between the specified reward function and what relevant humans (the designer, the user, others affected by the agent's behavior) actually value (see \cite{hadfield2019incomplete} and \cite{gabriel2020artificial}). We highlight that this AI alignment problem has a clear analogy to the principal-agent problem (see \cite{hadfield2019incomplete}), and the analysis of incentive compatibility for the incomplete contracting via AI algorithms can provide an insightful framework for understanding the alignment among algorithms.

\indent But how real is the risk of misalignment among AI algorithms? That is a difficult question to answer, both empirically and theoretically. On the empirical side, alignment is notoriously hard to detect from market outcomes, and firms typically do not disclose details of the financial or employment contracts they have.\footnote{For instance, executive compensation is a complex and contentious subject for investigating agency problems; however, there are still several unresolved issues, especially in the digital era. Because compensation arrangements are endogenous and correlated with many unobservables, measuring their causal effects on behavior and firm value is extremely difficult and remains one of the most important challenges for research on executive pay. (see \cite{frydman2010ceo}). Moreover, the development of e-commerce, fintech firms, and the platform economy generate large numbers of digital contracts, for example, Amazon, Uber, and PayPal. However, these contracts are unobservable due to users' privacy concerns.} On the theoretical side, the interaction among reinforcement-learning algorithms in dynamic agency problems generates dynamic stochastic multi-agent systems so complex that analytical results seem currently out of reach.

\indent To make some progress, this paper takes an experimental approach. The possibility arises from the recent evolution of AI algorithms from rule-based to multi-agent reinforcement learning (hereafter referred to as MARL)\footnote{See \cite{zhang2021multi} for more details about the MARL.} programs, which are able to learn from data and adapt to changing environments. We construct AI-based principals and agents, thereby allowing them to interact repeatedly in computer-simulated marketplaces. The challenge of this approach is to choose reasonable economic environments and algorithms that are representative of those used in realistic contract design scenarios. Specifically, we start from a conventional principal-agent problem as a reference and thereafter consider a three-sided contracting problem, where the parties have different preferences for the contract terms, also referred to as the \emph{dual-contract} problem. To this end, the MARL algorithms tackle the "Dual-Contract" problem and analyze its performance regarding its ability to learn incentive-compatible contract; our findings do suggest that algorithmic incentive compatibility is more than a remote theoretical possibility.


\indent To clarify the basic contribution of this paper, we start by comparing the following concepts 

\begin{itemize}
\item \textbf{Classical Principal-Agent Problem} is a well-studied issue in economics and contract theory. It arises when one side (the principal) delegates decision-making authority to another side (the agent). The principal provides the resources and capital for the project, while the agent is responsible for completing it. Incentives must be set by the principal to ensure that the project is completed efficiently and effectively. This two-sided problem has been studied extensively in the literature and applied to various areas.

\item \textbf{Dual-Contracting Problem} is a three-sided version of the classical principal-agent problem. In this case, there are two principals: both project owners provide resources and capital for the project. The two principals can have the same or different objectives and interests, which need to be colluded or competed with in order to ensure that the project is completed efficiently and effectively. This problem has rarely been studied in the literature, particularly in dynamic scenarios, as solving the three (or more)-agent Markov games remain a challenge for conventional methods.\footnote{This problem is also closely associated with the studies of the internal capital market (e.g. \cite{stein1997internal}, \cite{scharfstein2000dark}, and most recently \cite{dai2020q}). In particular, \cite{dai2020q} attempt to solve a dynamic $q$ theory of investment model for a multi-division firm, yet their setup avoids the dynamic contract setting (multi-agent repeated game) to remain the model tractable.} To our knowledge, this paper can also be recognized as the first investigation of the well-defined dual-contracting problem via novel methods. such as AI algorithms.

\item \textbf{AI for Mechanism Design} have been proposed to detect the mechanism design problem via AI algorithms (e.g., \cite{calvano2020artificial}). These algorithms are typically multi-agent reinforcement learning (MARL) programs, which are able to learn from data and adapt to multi-agent interactions. These algorithms can be used to optimize the terms of a mechanism design problem and detect the AI's behavior, in order to maximize the expected utility of both sides.
\end{itemize}

\indent Along with investigating the AI alignment problem, we are interested in studying how to design contracts by AI algorithms for three alternative reasons. Firstly, it might be applicable to online contracting scenarios, especially for decentralized multi-sided platforms.

\indent Second, when online contracting occurs in decentralized platforms, it is common for agents to rely on incentive optimization tools provided by the decentralized systems (blockchain or smart contract). As Web 3.0 applications become more popular, it is a natural question to ask how to compete in such contracts that would evolve when multiple agents use similar algorithmic tools, each optimizing on behalf of its owner.

\indent Third, understanding how AI algorithms interact with contract design can help us to design contracts more effectively for AI-driven applications. By understanding how AI algorithms interact with contract design, we can create contracts that incentivize the desired behavior of the AI algorithm. Additionally, understanding how AI algorithms interact with contract design can help us better identify and mitigate potential risks associated with related AI-driven applications.

\indent The dual-contracting problem is a challenging one due to the complexity of the task and the need for both principals to coordinate their efforts. To tackle this problem, AI algorithms have been proposed to learn from data and adapt to multi-agent interactions. Starting from a dynamic version of the static moral hazard model as a benchmark reference model, we find that the proposed relatively simple contracting algorithms dynamically learn to play incentive-compatible strategies and catch up with a rule-based reference analytical model solution in terms of the number of iterations needed to reach a Nash equilibrium. The baseline case indicates that, indeed, the initial conditions are no longer relevant to the equilibrium outcome given the same environment setup.
 
\indent In this paper, the main difference between the classical principal-agent problem and the dual-contracting problem is that the former is a single-principal problem, which cannot account for the mixed-sum behavior (collusion or competition) between principals and their effect on contract design. To understand the economic forces behind the dual-contract problem, we can notice multiple differences between the standard principal-agent problem and dual-contract problem formats that can contribute to different outcomes. This is because the dual-contract problem can induce multi-sided information asymmetry. In particular, we point out that:

\begin{itemize}
    \item Principals gain reduced benefits if their contract incentives are misaligned.
    
    \item The principal reacts to changes in the behavior of other participants, including agents and other principals.
    
    \item Advantageous principals get protection from competition and enjoy increased benefits.
    
\end{itemize}

\indent The AI-based principles typically coordinate on contract incentive designs that are somewhat above the pure collusion equilibrium (single principal-agent equilibrium), but substantially above the pure competition equilibrium. The strategies that generate these outcomes involve an intelligent level of AI algorithms, which is reflected in their memory ability. These algorithms learn these strategies through trial and error, and those with higher memory capacity can guard against myopic preferences and make better choices in the long term. Remarkably, these AI-based principals are not designed or instructed to collude or compete; they do not communicate with one another, nor do they have prior knowledge of the environment in which they operate.

\indent Our baseline model is a symmetric duopoly principal with an agent, and we conduct an extensive robustness analysis for the principal's heterogeneity. The results indicates that, the principal has an advantage over another principal and can get protection from his competitor; this protection effect increases as the degree of competition rises. Specifically, this protection effect results in the tax rate $p$ (benefit rate to the principal) is much higher than zero in the pure competition region, increasing the profit for the principal with advantage without worry about the competition from another principal. Moreover, in the pure collusion region, the two principals divide the revenue from both contracts evenly; therefore, both principals would like the agent to put effort into the advantaged principal's project.\footnote{This scenario is analogous to the corporate socialism that has been documented in \cite{dai2020q}. Here, this corporate socialism can be endogenously generated by our experimental design. }

\indent We designed a series of experiments/simulations to tell these possible explanations apart. It turns out that the main reason for the difference is the fact that there are multiple principals, and there are different levels of how much the principals' interests are aligned with each other. This force is fundamentally different between the standard contract and the dual-contract problems. It also helps us understand why the multi-sided information asymmetry seems to lead to reduced overall benefit for a party suffering from a conflict of interest among its members. 


\indent This work provides proof of concept that AI algorithms can be used to autonomously learn incentive compatibility in contract design. The proposed multi-agent reinforcement learning (MARL) algorithm is a promising approach to the problem of contract design and negotiation, as it can autonomously learn incentive compatibility and reach a Nash equilibrium in a reasonable number of iterations.\footnote{Although we focus on algorithms that learn in a completely unsupervised fashion by design, and in our simulations we allow them to explore widely and interact as many hundreds of thousands of times as is necessary to stabilize their behavior, the whole experiments can be finished within a few minutes. Specifically, we use C++ programming for parallel computing to facilitate high-performance computing in our experiments. Most importantly, with the rapid development of AI computing technology (GPUs and TPUs), contract design programs will be able to be completed in seconds shortly.} This work could be extended to other multi-sided contracting problems, such as the three-sided problem, and other AI algorithms, such as deep reinforcement learning. Furthermore, the proposed MARL algorithm could be used to optimize the terms of a contract to maximize the expected utility for both sides.

Additionally, AI algorithms is hopefully to identify potential risks associated with a given contract and suggest mitigation changes. Alternatively, AI algorithms can help automate the contract negotiation process by offering terms most likely to be accepted by both sides, potentially leading to faster and more efficient contract negotiations and reducing the costs associated with the process. Ultimately, AI algorithms can help organizations make better decisions when designing and negotiating contracts, resulting in better outcomes for both sides.

\subsection{Related Literature}

\indent Our paper contributes to the literature by proposing a MARL algorithm to solve the dual-contract problem and demonstrating its ability to learn incentive compatibility autonomously. The proposed algorithm is a promising tool for contract design, as it can help organizations make better decisions when online designing and negotiating contracts.

The literature on the use of AI algorithms to solve the mechanism design problem is still in its infancy. However, there have been some recent works that have explored this topic. For example, \cite{banchio2022artificial} proposed an autonomous AI-based auction design using a reinforcement learning algorithm. \cite{hansen2021frontiers} show how misspecified implementation results in collusion by simulating a different algorithm from the bandit literature. In contrast to those works, the present paper is the first to explore the use of AI algorithms to solve the dual-contracting problem with incentive compatibility. We propose a MARL algorithm to solve the dual-contracting problem and analyze its performance regarding its ability to learn incentive compatibility. Our results suggest that AI algorithms can be used to autonomously learn incentive compatibility in dual-contract design.

\indent This paper contributes to an emerging literature that applies AI modeling in economics and finance. Recent literature in AI economics has been actively studying reinforcement learning that particularly utilizes the Q-learning method as the tool for experimental economics. These include \cite{erev1998predicting}, \cite{10.1257/aer.102.5.2018}, \cite{calvano2020artificial}, \cite{https://doi.org/10.1111/1756-2171.12383}, \cite{kasy2021adaptive}, \cite{10.1257/pandp.20221059}, among many others. In contrast, our application of AI is motivated economically by the challenges observed in conventional dynamic contract theory and the pressing need for theoretically approximating humanity. We contribute conceptually by introducing a novel quantitative framework to solve the AI-based dual-contracting problem in a relatively transparent and interpretable modeling space.


\indent This paper hopes to usefully complement the rich theoretical literature on optimal contracting and principal-agent problems, such as \cite{innes1990limited}, \cite{schmidt1997managerial}, \cite{levin2003relational}, \cite{demarzo2006optimal}, \cite{demarzo2007optimal}, \cite{biais2007dynamic}, \cite{sannikov2008continuous} \cite{he2009optimal}, \cite{biais2010large}, \cite{garrett2012managerial}, \cite{demarzo2012dynamic}, \cite{edmans2012dynamic}, \cite{zhu2013optimal}, \cite{garrett2015dynamic}, and \cite{zhu2018myopic}. The optimal contract in these papers is typically highly complex, and they must engage several bounded assumptions or conditions to ensure the model's tractability. Note that most of these studies must suppose a specific scenario, such as one principal and one agent. In contrast, our paper considers a fairly general dual-contract setting with two principals and one agent, under a tractable AI setting, the model is to deliver quantitative analysis in a dynamic multi-period setting and calibrate the model parameters using real data. 


\indent Our paper is organized as follows. In Section \Cref{Qlearning}, we provide a brief overview of Q-learning and multi-agent reinforcement learning. In \Cref{contracts}, adopt a two-agent Q-learning algorithm to analyze the single-principal-agent problem. \Cref{dualcontract} describes our proposed multi-agent Q-learning algorithm for the dual-contracting problem. In \Cref{asymmetry}, we present the results of the dual-contracting problem with heterogeneous principals. \Cref{conclusion} concludes. The omitted algorithm details are presented in \Cref{appendix}.


 