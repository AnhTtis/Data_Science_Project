In this work, we introduce a novel camera-based multi-view 3D object detection framework that learns from viewpoint equivariance regularization. 
\Acronym employs a transformer decoder with a set of view-conditioned queries to decode bounding boxes from image features with geometric positional encodings.
The view-conditioning of queries enables us to enforce viewpoint equivariance on predictions made from different viewpoints, and therefore generate richer geometric learning signals to guide the model in better understanding the 3D structure of the scene. \Acronym achieves state-of-the-art 3D detection performance, and we conduct extensive experiments to show the effectiveness of its components. We also point out a few meaningful limitations for future works.