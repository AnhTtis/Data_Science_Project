\begin{figure}[]
    \centering
    \includegraphics[width=0.97\linewidth]{media/fig1-teaser_v5.pdf}
    \caption{
    \textbf{Our proposed \Acronym} encodes the 3D scene from multi-view images, and decodes objects with view-conditioned queries. The predicted 3D bounding boxes are expressed in the underlying views of the queries, which enables us to enforce viewpoint equivariance among predictions from multiple views. Virtual query views are generated during training and together with the viewpoint equivariance regularization bring richer geometric learning signals to guide the model to better understand the 3D structure in the scene. During inference, the global predictions can be obtained by simply choosing the global frame as the query view. 
    }
    \label{fig:teaser}
\end{figure}