\begin{figure*}[t!]
    \centering
    \includegraphics[width=0.9\textwidth]{media/fig2-architecture-v3.pdf}
    \caption{The framework of our proposed \Acronym: Given $N$ multi-view input cameras, an image encoder first extracts image features. For each feature embedding, we provide geometric positional encoding (PE) based on pixel location as well as camera geometrics (\cref{sec:encoding}). At the decoding stage, we apply a view-conditioned query constructed by 3D query points and Query Views to predict view-conditioned predictions (Sec.~\ref{sec:decoding}). Finally, we optimize the network through a novel viewpoint equivariance loss (Sec.~\ref{sec:mtv}).}
    \label{fig:overallarch}
\end{figure*} 