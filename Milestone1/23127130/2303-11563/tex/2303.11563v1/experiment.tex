\begin{figure*}[t!]
    \centering
    \begin{subfigure}[b]{0.31\textwidth}
         \centering
         \includegraphics[width=\textwidth]{plots/ROC/MICU_transfer_RF.png}
        %  \caption{RF}
         \label{fig:MICU_transfer_ROC_RF}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.31\textwidth}
         \centering
         \includegraphics[width=\textwidth]{plots/ROC/MICU_transfer_LR.png}
        %  \caption{LR}
         \label{fig:MICU_transfer_ROC_LR}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.31\textwidth}
         \centering
         \includegraphics[width=\textwidth]{plots/ROC/MICU_transfer_MLP.png}
        %  \caption{MLP}
         \label{fig:MICU_transfer_ROC_MLP}
     \end{subfigure}
\caption{ ROC curves for \ourmethod (in orange), \ourmethodp (in red) and the baselines 
% baseline \jodie, domain specific baselines, and RNN, LSTM 
for MICU transfer prediction task.
Each figure corresponds to a different classifier: random forest (left), logistic regression (middle) and multi-layer preceptron (right).
Both variants of \ourmethod outperform all other methods consistently.
}
\label{fig:MICU_transfer_ROC}
\end{figure*}


We describe our experimental setup next.
We provide code for academic purposes
\footnote{\url{https://github.com/HankyuJang/DECEnt-dynamic-healthcare-embeddings}}
% \footnote{\url{https://www.dropbox.com/sh/y9g1pdunqbyb1f4/AACIGZW5YZeT-r1aM0yDsf2Na?dl=0}}
% \footnote{\url{https://www.dropbox.com/sh/mh1wcxeu7rp07ku/AACbiuXKztqWQY6hV5tQC1tma?dl=0}}.
% \footnote{\url{https://www.dropbox.com/sh/6ajtnkmafjsclvs/AABiyD1SSkcD_F7IUtYNDiGsa?dl=0}}.
Experiments were conducted on Intel(R) Xeon(R) machine with 528GB memory and 4 GPUs (GeForce GTX 1080 Ti).

\par \noindent \textbf{Data: }We evaluate \ourmethod on the real world hospitals operation data collected from University of Iowa Hospitals and Clinics (UIHC). UIHC is a large (800-bed) tertiary care teaching hospital located in Iowa City, Iowa.
% . 
The dataset consists of de-identified electronic medical records (EMR), and admission-discharge-transfer (ADT) records on
% xx in-patient visits by 
6,496 patients between January 01, 2010 and March 31, 2010.
Each patient visit has a set of diagnoses, a timestamped record on a set of medications prescribed, and a procedures performed by physicians. For each patient room transfer event during the visit, the source room and the destination room are recorded with a timestamp.
The 
patients in our dataset interacted with 575 doctors where 23,085 physician interactions were observed during the time-frame.
686 unique medicines were prescribed to patients, with a total of 349,345 medication interactions.
Moreover, patients visited 557 rooms, with a total of 16,771 spatial interactions.




\par \noindent \textbf{Baselines: }We compare performance of \ourmethod and \ourmethodp against natural and state-of-the-art baselines in all of our applications.
The first group of baselines include popular static network embeddings \nodevec~\cite{grover2016node2vec} and \deepwalk~\cite{perozzi2014deepwalk} and dynamic network embedding \dynamictriad~\cite{Nguyen2018CTDNE}.
% We also construct domain specific baselines (\domain). 
After extensive literature review~\cite{li2019using, min2019predictive}, we find that predictive modelling tasks in healthcare analytics consist of an off-the-shelf classifier and a set of handcrafted feature. 
To this end, we design \domain baselines by augmenting classifiers with feature selection targeted for each predictive task. We also compare against
time-nested deep recurrent neural models \lstm and \rnn.
Our final baseline is the state-of-the-art co-evolutionary neural network \jodie \cite{kumar2019predicting}.

% \par \noindent \textbf{Run time: }\ourmethod \hankyu{training time per epoch takes \textbf{xxx} seconds on UIHC data.}


\subsection{Application 1: MICU Transfer Prediction}


The first application we consider seeks to forecast whether a patient is at risk of transfer to a Medical Intensive Care Unit (MICU). The MICU provides care for patients at a critical stage. A patient is only transferred to the MICU when there is a necessity for constant monitoring and intensive care. Therefore, an early indication of the high risk of transfer to a MICU can guide healthcare professionals to increase patient care. On the other hand, MICU beds are a scarce resource, and hence, an early indication of potential MICU transfer helps hospital officials allocate resources better.



Here we pose MICU transfer prediction as a binary classification problem.
The input to a classifier is the embedding generated by \ourmethod at time $t$.
The output is a label representing whether a patient will be transferred to a MICU at time $t+1$.
Here we only consider the cases where a Non-MICU to MICU transfer occurs at least three days from admission.
We construct the positive instances (+) based on the actual MICU transfer events.
If there is more than one transfer for a patient, we only consider the latest event.
We randomly sample one day of their embedding for patients with no such event and use it as negative instances (-).
 Note that the MICU transfers are rare events. In order to remain faithful to the problem, we ensure that there is a significant class imbalance of greater than 100:1.



We train three independent off-the-shelf classifiers, logistic regression (LR), random forest (RF), and multi-layer perceptrons (MLP), to predict MICU transfers.
We perform 5-fold cross-validation. Due to the extreme class imbalance, we randomly undersample the majority class training data to match the size of the minority class. However, we retain the class imbalance in the test set.
% We repeat the experiments 30 times for robust training.
We use the area under the ROC curve, AUC, as an evaluation metric robust under class imbalance.
Finally, we report the average AUC over 30 repetitions and the standard deviation.
We repeat the entire process with the baseline methods. 
% We also compute the performance of a variant of \ourmethod without the domain specific loss described in Section \ref{section:method}. 
Results are presented in Fig \ref{fig:MICU_transfer_ROC}.
% Table \ref{tab:MICU_transfer}. 

As seen in the % table, 
figure, \ourmethod outperforms all the baselines regardless of the underlying classifier. The gain of \ourmethod over the most competitive baseline \domain is 6.4\%. 
A significant advantage \ourmethod has over the baselines, is that it is able to distinguish entity types from each other and it is specifically designed to model the heterogeneous dynamic interactions. 
The results show that \ourmethod indeed learns embeddings that are useful for predictive modelling. 
This highlights the importance of principally encoding the heterogeneous nature of interactions that occur in a healthcare setting. 

Another interesting observation we make is that \ourmethod outperforms \ourmethodp in two out of three classifiers implying that restrictively enforcing the embeddings to respect the domain specific distances may lead to poorer performance in some cases while being useful in other. Impressively, even in the classifier where \ourmethod performs the poorest, it still outperforms the most competitive baseline.

% Compute gain. 6.4%
% Ourmethod: 0.931
% Best baseline: 0.875
% As observed in the table, \ourmethod outperforms all other approaches. 
% Here we notice that \jodiep outperforms \jodie indicating that that the domain specific static features are helpful for CDI prediction task, despite having derogetory effect on future interaction prediction task (Table \ref{tab:next_interaction_prediction}).  

\subsection{Application 2: CDI Prediction}

% Like other HAIs, 
CDI spreads in a healthcare setting, infecting patients who are already in a weakened state. Acquiring CDI increases a patient's mortality risk and prolongs hospital stay. Hence, early identification of patients at risk of CDI gives healthcare providers valuable lead time to combat the infection. 
It also helps prevent infection spread as practitioners can employ contact precaution and additional sanitary measures with special attention to the area around a patient at risk. Note that according to current practice, a patient is tested for CDI after three days of symptoms~\cite{monsalve2015improving}. This means that pathogen may have spread even before positive test results. 

Here we pose CDI prediction as a classification problem. 
The goal here is to accurately predict a label indicating if a patient would get infected within the next three days, given the embeddings learned by \ourmethod and baselines.
For the patients who get CDI, we use their embeddings three days before the positive report as positive class instances.
We randomly sample one day of their visit for each of the rest of the patients and use it as negative class instances.
We have a class imbalance of 89:1 as CDI cases are rare.
Our experimental setup is the same as Application 1. 
We present our results in Table \ref{tab:CDI}.



\begin{table}[h]
\centering
\caption{Average AUC and the corresponding s.t.dev. for various approaches for the CDI prediction task.
\ourmethod and \ourmethodp outperform all the baselines.
}
\label{tab:CDI}
% \small
% \footnotesize
% \setlength\tabcolsep{1.5pt}
\begin{tabular}{|c|c|c|c|}
% \hline
% \multicolumn{4}{c}{\textbf{CDI prediction}} \\
\hline
Method & \multicolumn{3}{c|}{AUC} \\
\hline
\rnn & \multicolumn{3}{c|}{0.56 (0.119)} \\
\lstm & \multicolumn{3}{c|}{0.585 (0.103)} \\
\hline
-             & LR            & RF            & MLP           \\
\hline
\domain                     & 0.655 (0.123) & 0.709 (0.104) & 0.582 (0.137) \\
\deepwalk      & 0.494 (0.087) & 0.487 (0.093) & 0.492 (0.103) \\
\nodevec & 0.453 (0.098) & 0.43 (0.106)  & 0.478 (0.1)   \\
% node2vec\_DFS & 0.474 (0.095) & 0.455 (0.095) & 0.491 (0.101) \\
\dynamictriad & 0.463 (0.101) & 0.528 (0.079) & 0.483 (0.116)\\
\jodie                      & 0.552 (0.192) & 0.377 (0.177) & 0.469 (0.176) \\
\hline
\ourmethod       & 0.732 (0.069) & 0.711 (0.08)  & 0.668 (0.082) \\
\ourmethod+ & \textbf{0.736 (0.064)} & 0.717 (0.078) & 0.664 (0.091) \\
\hline
\multicolumn{4}{l}{$^{\mathrm{a}}$The value in bold denotes best performance}
\end{tabular}
\end{table}

As observed in the table \ourmethod and \ourmethodp outperform all the baselines with the gain over the best performing baseline \domain of 3.81\%. As in the previous applications static embedding approaches perform the worst, followed by the dynamic embedding baseline \dynamictriad, and finally \jodie.

\subsection{Application 3: Mortality and Case Severity Risk Prediction}



The Agency for Health Research and Quality (AHRQ) is a federal agency that performs mortality and case severity analysis on inpatient visits across hospitals in the US. Hospitals submit records on each patient visit to the agency. The agency then reports the severity and mortality along with the ``expected'' severity and mortality risk for each patient. 
The agency's report acts as a quality control metric for hospitals via retrospective analysis.
% . Note that the analysis is performed retrospectively. 
Predicting case severity and mortality while the patient is in the hospital has many applications, ranging from personalized patient care to resource allocation.   


\begin{table}[h]
\centering
\caption{Average F1 Macro and the corresponding s.t.dev.
for various methods 
% for the predictive tasks of mortality and severity. 
for mortality and severity prediction.
\ourmethod and \ourmethodp outperform all the baseline methods.}
\label{tab:mortality_severity_f1macro}
% \small
% \footnotesize
\begin{tabular}{|c|c|c|}
\hline
Method  & \textbf{Mortality}     & \textbf{Severity}      \\
\hline
\rnn     & 0.276 (0.039) & 0.31 (0.032)  \\
\lstm    & 0.289 (0.033) & 0.308 (0.026) \\
\domain  & 0.22 (0.017)  & 0.258 (0.007) \\
\deepwalk      & 0.172 (0.034) & 0.192 (0.019) \\
\nodevec & 0.172 (0.02)  & 0.196 (0.009) \\
% node2vec\_DFS & 0.183 (0.031) & 0.197 (0.015) \\
\dynamictriad & 0.184 (0.019) & 0.199 (0.007) \\
\jodie   & 0.143 (0.039) & 0.193 (0.014) \\
\hline
\ourmethod  & 0.421 (0.027) & 0.34 (0.014)  \\
\ourmethodp & \textbf{0.428 (0.022)} & \textbf{0.349 (0.015)} \\
\hline
\multicolumn{3}{l}{$^{\mathrm{a}}$The value in bold denotes best performance}
\end{tabular}
\end{table}



AHRQ classifies each case into four categories, namely \emph{Minor}, \emph{Moderate}, \emph{Major}, and \emph{Extreme} for both mortality and case severity. 
Hence, we model both these tasks as multi-label classification problem.
The input to a classifier is the embedding generated by DECEnt by the time of discharge.
% As in previous applications, 
We report the results on logistic regression classifier on F1-Macro scores in Table \ref{tab:mortality_severity_f1macro}.
The results show that \ourmethod and \ourmethodp consistently outperform all the baselines for both mortality and case severity prediction, with a gain of up to 48.1\% over LSTM and 12.58\% over RNN, respectively, compared to the best performing baselines for each prediction task.
% \ourmethod is a close second. However, both \ourmethod and \ourmethod(LAPx) outperform both versions of \jodie. 
This result reinforces our conclusion from previous applications that \ourmethod is superior to state-of-the-art baselines in predictive modeling tasks in the healthcare setting.
% In the Appendix, we present comprehensive results trained on random forest and multi-layer perceptron classifiers, evaluated using F1-Micro and F1-Macro scores.

% Mortality
% Compute gain. 6.4%
% Ourmethod: 0.428
% Best baseline: 0.289

% Severity
% Compute gain. 12.58%
% Ourmethod: 0.349
% Best baseline: 0.31


\begin{comment}
\subsection{Data}

% The data consists of de-identified electronic medical records (EMR) and admission-discharge-transfer (ADT) records on in-patient visits (154K) during 2007-2011 at the University of Iowa Hospitals and Clinics (UIHC).
The dataset used for training the patient embedding consists of de-identified electronic medical records (EMR), and admission-discharge-transfer (ADT) records on 10,298 in-patient visits by 8,432 patients at a large (800-bed) tertiary care teaching hospital from January 01, 2010 - March 31, 2010.
Each visit has a set of diagnoses, a timestamped record on a set of medications prescribed to the patient, and a timestamped record on which the physician performed what procedure to the patient.
Also, whenever a patient is transferred to another room during the visit, the source room and the destination room are recorded with a timestamp.

We evaluated the patient embeddings if the patient re-visited the hospital shortly after the discharge.
Specifically, the dataset used for evaluating the visit embedding is from visit records in April 2010;
for any patient that was in the hospital during the training period, if any of them made re-visit to the hospital, we predicted the severity risk, mortality risk, and whether the patient would get CDI in the later visit. 

% Furthermore we utilized hospital graph of UIHC where nodes (19K) represent room and spaces in a corridor and edges (47K) represent direct passage between node pairs that are roughly less than 30m apart from each other \cite{curtis2013healthcare}.
Among the patient visits that occurred on January-March 2010, 
1,285 unique procedures were performed on 5,716 patients by 591 unique doctors. There was a total of 27,122 patient-doctor interactions during the time-frame. 
Similarly, 703 unique medications were prescribed to 6,465 patients, with a total of 426,876 patient-medication interactions.
Moreover, 558 rooms in the hospital were visited by 5,741 patients, with a total of 16,771 patient-room interactions.
As shown in Table~\ref{table:temporal_interaction_record}, we generated temporal interaction records between patients and doctors, medications, and rooms.

\begin{table}[b!]
\small
\caption{\textbf{Temporal interaction record.}}
\label{table:temporal_interaction_record}
\begin{tabular}{|c|c|c|c|c|}
\hline
User-Item & Users & Items & Interactions\\
\hline
Patient-Doctor  & 5,716  & 591   & 27,122 \\
Patient-Medication & 6,465  & 703   & 426,876 \\
Patient-Room       & 5,741  & 558   & 16,771 \\
\hline
\end{tabular}
\end{table}

Fig~\ref{fig:temporal_interactions} depicts Patient-Doctor, Patient-Medication, and Patient-Room interactions in the hospital.
Patients get medications prescription frequently, compared to getting procedures or room transfers.
Also, interactions frequently occur during the weekdays (bump) and occur less during the weekends (dip).
% The number of interactions are low at the beginning and at the end of the month, because there are less number of visits in this period since our data consists of visits that starts on January 1 or later and ends on January 31 or earlier.

\subsection{Evaluation Strategy of Patient Embedding}

We evaluate the patient embeddings learned from the proposed HIDEP by performing various prediction tasks.

\subsubsection{Classification Task}
\hfill\\
\textbf{Predicting severity and mortality risk:}
Each patient visit record has severity and mortality risk, which are precomputed based on the treatments patients received during the visit.
% obtained from the data aggregator once UIHC reports its data for inclusion in HCUP.
Each of the severity and mortality risks is in one of the following categories [``Minor," ``Moderate," ``Major," ``Extreme"].
Given the learned patient embeddings from the history of the treatments received, the goal of the classification is to predict the severity risk and mortality risk of the patient visit in the near future.
Specifically, we used the learned patient embeddings until $t-1$'th visit to predict the severity and mortality in $t$'th visit.

\begin{table}[b!]
\small
\caption{\textbf{Number of patients in each evaluation category.}
For severity and mortality, labels 0, 1, 2, and 3 denote minor, moderate, major, and extreme risk, respectively.
For CDI, labels of 0 and 1 denote non-CDI and CDI.}
\label{table:data_for_evaluation}
\begin{tabular}{|c|c|c|c|}
\hline
Label & Severity & Mortality & CDI\\
\hline
0 & 217 & 57 & 429\\
1 & 141 & 183 & 12 \\
2 & 67 & 138 & -\\
3 & 16 & 63 & -\\
\hline
\end{tabular}
\end{table}

\noindent \textbf{Predicting C. Diff infection:}

C. diff infection (CDI) is a common hospital-acquired infection (HAI).
CDI patients typically show noticeable symptoms such as unexplained severe diarrhea and get tested for CDI.
Among the patients that were in the hospital during January-March 2010, 
441 patients re-visited the hospital in April, and among them, 12 patients got CDI in their later visit in April.
Here, our goal is to use the dynamic embedding of patients to predict if patients would get CDI in their future visit to the hospital.

\noindent \textbf{Transfer into MICU:} ...


Table~\ref{table:data_for_evaluation} shows the number of patients in each category of the label in the three classification tasks.
The labels in each category are unbalanced in that the imbalance ratio in severity was 217: 16, and the imbalance ratio in mortality was 183: 57.
The problem of classifying CDI had the most imbalanced label with a ratio of 429: 12.


% \textbf{Sequential diagnoses:}
% Each patient is diagnosed to one or more disease during their visit.
% Here, our goal is to predict diagnoses of the patient's $t$'th visit using the patient embedding until $t-1$'th visit.

% We have timestamped records on the patients who were tested positive for Clostridioides Difficile (C. Diff), which is a common hospital acquired infection (HAI) among inpatients, and
% there were 32 CDI cases that occurred in January 2010.
% We labeled each patient visit based on the mortality risk (4 categories), severity risk (4 categories), and C. Diff infection (2 categories).

\end{comment}

\begin{comment}
\subsubsection{Experiment Setting}
\hfill\\
\textbf{Predicting severity and mortality risk:}
For each patient embedding that is learned using different methods, we perform the multi-class classification on 2-fold cross-validation using machine learning classifiers: logistic regression (LOGIT), random forest (RF), and multi-layer perceptron (MLP).
We used lbfgs solver for the modeling parameters for LOGIT and used 1000 trees with a max depth of 2 for the RF.
We used one fully connected hidden layer with 16 neurons, each with the Relu activation for the structure of MLP, and trained using Adam optimizer, categorical cross-entropy for the loss function, and a dropout rate of 0.5 for all neurons.
Training MLP is done in a mini-batch of 20 instances per batch on 200 epochs;
we imposed an early stopping on the training when the loss on the validation set (20\% of the training set is used for validation only) stop decreasing for 10 epochs.
We report the mean micro F1 and mean macro F1 scores.

\noindent \textbf{Predicting C. Diff infection:}
We use the same set of classifiers and modeling parameters as in predicting severity and mortality risk and performed binary classification on 2-fold cross-validation.
We report mean AUC values for this experiment.

\noindent \textbf{MICU transfer:}...

\subsubsection{Baselines}
We use the following baselines to compare the performance of our proposed approach:

\subsection{Evaluation Strategy of Embedding of Doctors, Medications, and Rooms}
We evaluate the learned representations of doctors, medications, and rooms by plotting the projected 2-dimensional space of the embeddings using t-SNE. We investigate if similar entities (doctors, medications, or rooms) are represented in similar vector space, and gives us meaningful interpretation.

\subsubsection{Doctor embedding}
We project the embeddings of doctors into 2-dimensional space using t-SNE, then visualize as a scatter plot by coloring each doctor specialty differently.
Each doctor has one specialty, where there is a total of 21 mapped specialties of the doctors, including `unknown.'
Among the 21 specialties, we selected the three most frequent specialties and showed them as a scatter plot.

\subsubsection{Medication embedding}
 We project the embeddings of medications into 2-dimensional space using t-SNE, then visualize as a scatter plot by coloring each medication according to its major level (there are four levels of the medications: 
%  mid (2493) < subminor (563) < minor (224) < major (35). 
 mid < subminor < minor < major. 
 Here, the medication codes we used in learning embedding are from mids that are in the lowest level of the hierarchy.).
 We selected the three most frequent specialties and showed them as a scatter plot.

\subsubsection{Room embedding}
We project the embeddings of rooms into 2-dimensional space using t-SNE, then visualize as a scatter plot by coloring each room according to its room type.
Each room has one assigned type, where there is a total of 7 room types.
Among the room types, we excluded the `inpatient accommodations' type, which includes the majority of rooms and two unassignable room types. 
Thus, we plotted rooms belonging to the rest of the 4 room types on a scatter plot.

\subsection{Results}

\subsubsection{Evaluating Patient Embedding}

\begin{table*}[b!]
\caption{Results of evaluating patient embedding over 4 classification tasks over 30 repetitions. Values in the parenthesis are s.t.dev.}
\label{table:classification results}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
Task              & CDIFF         & MICU transfer & \multicolumn{2}{c|}{MORTALITY} & \multicolumn{2}{c|}{SEVERITY}  \\
\hline
Evaluation metric & AUC           & AUC           & F1\_micro     & F1\_macro     & F1\_micro     & F1\_macro     \\
\hline
JODIE             & 0.622 (0.046) & 0.566 (0.099) & 0.199 (0.065) & 0.104 (0.032) & 0.414 (0.205) & 0.157 (0.035) \\
JODIE\_pf         & 0.744 (0.039) & 0.854 (0.031) & 0.427 (0.005) & 0.342 (0.027) & 0.629 (0.003) & 0.302 (0.035) \\
HIDEP             & 0.755 (0.035) & 0.857 (0.034) & 0.445 (0.007) & 0.394 (0.008) & *0.638 (0.003) & *0.333 (0.01)  \\
HIDEP\_v2         & *0.784 (0.025) & *0.904 (0.001) & *0.457 (0.006) & *0.41 (0.0)    & 0.637 (0.005) & 0.328 (0.018) \\
\hline
\end{tabular}
\end{table*}

\begin{table*}[b!]
\caption{Results of evaluating patient embedding on 4 classification tasks over 30 repetitions. Values in the parenthesis are s.t.dev.}
\label{table:classification results}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
Task              & CDIFF         & MICU transfer & \multicolumn{2}{c|}{MORTALITY} & \multicolumn{2}{c|}{SEVERITY}  \\
\hline
Evaluation metric & AUC           & AUC           & F1\_micro     & F1\_macro     & F1\_micro     & F1\_macro     \\
\hline
JODIE             & 0.622 (0.046) & 0.566 (0.099) & 0.199 (0.065) & 0.104 (0.032) & 0.414 (0.205) & 0.157 (0.035) \\
JODIE\_pf         & 0.744 (0.039) & 0.854 (0.031) & 0.427 (0.005) & 0.342 (0.027) & 0.629 (0.003) & 0.302 (0.035) \\
% HIDEP             & 0.755 (0.035) & 0.857 (0.034) & 0.445 (0.007) & 0.394 (0.008) & *0.638 (0.003) & *0.333 (0.01)  \\
Our method         & *0.784 (0.025) & *0.904 (0.001) & *0.457 (0.006) & *0.41 (0.0)    & *0.637 (0.005) & *0.328 (0.018) \\
\hline
\end{tabular}
\end{table*}

\subsubsection{Evaluating doctors, medications, and room embeddings}
 
\textbf{2-d Physician embedding} ...

\begin{figure}[t!]
    \centering
    \includegraphics[width=\columnwidth]{plots/physician_embedding_top.png}
    \caption{\textbf{-.} }
    \label{fig:results_physician_embedding}
\end{figure}

\textbf{Dispersion matrices?}
\end{comment}