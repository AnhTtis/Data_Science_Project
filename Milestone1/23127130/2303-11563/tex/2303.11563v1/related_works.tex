
\par \noindent \textbf{Network Embeddings for Healthcare Analytics.}
Network embedding~\cite{grover2016node2vec,perozzi2014deepwalk} has gained much research interest lately. 
Recently, several approaches to learn embeddings of nodes in a dynamic network have been proposed. 
These approaches aim to capture both structural similarity and temporal evolution
% \cite{Singer2019NodeEmbedding,Torricelli2020}. 
\cite{Torricelli2020}. 

%proposed a method that learns the temporal evolution of nodes started from a static embedding and by aligning the representation at different time points. Weg2vec \cite{Torricelli2020} learns the low dimensional representation of a temporal network by leveraging the temporal and structural similarity of events associated with different nodes. 

Similar approaches have been explored for medical data. 
%MedGraph \cite{Bhagya2020MedGraph} generates the embedding by temporal sequencing of patient visits represented as a bipartite network of visits and corresponding medical codes.
A class of approaches
% \cite{choi2016multi,choi2017gram} 
\cite{choi2018mime}
preserve the similarity of the medical codes in consecutive hospital visits by the same patient. 
eNRBM \cite{Tran2015eNRBM} uses restricted Boltzmann Machines, and \cite{Zhu2016CNN} uses convolutional neural network to represent abstract medical concepts. 
% Some of the other related approaches include \cite{Choi2017, pmid27885364, pham2017deepcare, Bhagya2020MedGraph}.
%Med2Vec, GRAM, Mime, ...

\par \noindent \textbf{Coevolving Networks.}
User-item interaction based embedding has gained a lot of attention recently. It has become a powerful tool for representing the evolution of users and items based on dynamic interactions
% \cite{beutel2018latent, FarajtabarWGLZS15COEVOLVE, ZhangYS17aa}.
\cite{FarajtabarWGLZS15COEVOLVE}.
DeepCoevolve \cite{dai2016deep} uses RNN to learn the user and item embedding through 
% modeling 
the complex mutual influence in any interaction over the time. JODIE \cite{kumar2019predicting} extends \cite{dai2016deep} by adding a new projection operator that can predict user-item interaction at any future point of the time. 


\par \noindent \textbf{Healthcare Analytics.} An area closely related to the current paper is that of Healthcare Analytics. Li et al. explored applicability of machine learning for CDI prediction using manual feature engineering~\cite{li2019using}.
Several other approaches have been proposed for case detection tasks 
% \cite{MaCZYSG17,oh2018generalizable,makar2018learning}. 
\cite{makar2018learning}. 
A separate line of work focuses on mortality prediction~\cite{sherman2017leveraging}.
Other loosely related works include outbreak detection~\cite{adhikari2019fast}, missing infection inference~\cite{sundareisan2015hidden}, and architectural analysis~\cite{jang2019evaluating}.

\par \noindent \textbf{Autoencoders for Representation Learning.}
SDNE \cite{wang2016structural} uses autoencoders to preserve second-order proximity of the network.
NetRAs \cite{yu2018learning} uses graph encoder-decoder framework using LSTM networks and rooted random walks.
Deep Patient \cite{Miotto2016DeepPatient} uses stacked autoencoders to encode patients.

\begin{comment}
% \subsection{Embedding of Patients and Doctors}

% When a patient visits the hospital, the patient gets diagnoses and receives medications or procedures during the visit.
% In Med2vec \cite{choi2016multi}, a visit of a patient is represented by a multi-hot medical code vector which contains diagnosis codes, medication codes, and procedure codes for a visit.
% From consecutive visits of a patient, Med2vec learns visit embedding via Skip-gram \cite{mikolov2013distributed} like structure; 
% A visit (here, multi-hot medical code vector) is trained to predict nearby visits of the patient based on the assumption that diagnosis, prescriptions, and procedures would be similar for nearby visits of a patient.
% In GRAM \cite{choi2017gram}, a visit of a patient is represented by the multi-hot medical code vector multiplied by medical code embedding, which is learned via medical ontology;
% hierarchical relationship of the medical codes is represented as a directed acyclic graph (DAG), and medical code embedding is learned with Glove \cite{pennington2014glove} objective function.
% Then, a sequence of $t$ visits (multi-hot medical code vectors multiplied by medical code embedding) is trained to predict $t+1$'th visit in the RNN structure.
% MiME \cite{choi2018mime}, which is an extension of \cite{choi2016multi, choi2017gram}, captures relationship between diagnosis codes and treatment codes within a visit.

% Doctor2Vec \cite{biswal2020doctor2vec} leverages patient to doctor interaction to learn doctor embedding from the patient EHR data and the clinical trial embedding dynamically.
% Doctor2Vec model takes in three inputs; (1) sequence of patients that the doctor has seen, (2) unstructured text, and (3) categorical features of clinical trials.
% The embedding of doctors is obtained from the embedding of patients and clinical trials;
% the embedding of the unstructured text of clinical trials is pre-trained using BERT \cite{devlin2018bert}, whereas the embedding of categorical features of clinical trials and patients (obtained from patient visits using Bi-LSTM with attention module) are learned during the prediction task of enrollment rate 
% % (classification of enrollment rates in 5 bins, e.g. 0-20\%, 20-40\%, ... 80-100\%) 
% of the clinical trial.

% \subsection{Dynamic Embedding}

% Joint Dynamic User-Item Embeddings (JODIE) \cite{kumar2019predicting} is the model that generates network embedding on the user-item trajectories over time.
% The temporal user-item networks represent the trajectory history at a certain timestamp, such as the purchasing of an item by a user. 
% Since the interactions change over time, it is crucial to capture the temporal properties and predict future connections based on the network's previous states.
% In JODIE, user and items' embeddings are represented by updating the embeddings when new interactions are made. The updated user and item embeddings are computed based on the previous embeddings of user and item, interaction features, and the duration of time elapsed since the user's last interaction.
% In addition, the future embeddings of users and items after a certain time are predicted.
% After the elapsed time, the user embeddings are predicted by projecting the current user embedding vector with a temporal attention vector.
% Therefore, as more time elapsed, the user embedding differs more.
% The item embeddings are predicted by incorporating both the static and dynamic embeddings of users and the previously interacted items.
% The prediction tasks are useful to predict future interactions by computing the similarity of user and item embeddings at a certain point in time.


\end{comment}
