Here we propose our method $\ourmethod$ (short for \ourmethodFull), a novel auto-encoding heterogeneous co-evolving dynamic neural network, to solve Problem \ref{prob:problem}. \ourmethod models heterogeneous interactions using a set of jointly learned co-evolving networks.
It has three main components at a high level, each of which models one of the interaction types.
As the interactions occur, the dynamic embeddings of the entities involved are updated simultaneously. 
These dynamic embeddings are jointly trained to reconstruct the entity that the patients interacts with while preserving similarities imposed by $G_{\mathrm{entity type}}$.
% These dynamic embeddings are jointly trained to ensure that the learnt embeddings are predictive of future interactions. 
We describe each of the components in detail next.

\subsection{Physician Module}

Consider a physician interaction $(p,d,t) \in \Pro$ between a patient $p$ and a doctor $d$ at time $t$. To reflect that $p$ and $d$ interacted with each other, our method simultaneously updates the maintained dynamic embeddings $\ed_{p,t}$ and $\ed_{d,t}$ of both $p$ and $d$.
To do so, we design a pair of co-evolving deep neural networks $\prodmod_p$ and $\prodmod_{d}$ to update the patient's and doctor's embedding, respectively.  

Following the literature in the co-evolutionary neural networks~\cite{kumar2019predicting, dai2016deep}, we design $\prodmod_p$ and $\prodmod_{d}$ to be mutually recursive, i.e., the patient's embedding at time $t$, $\ed_{p,t}$ generated by the  $\prodmod_p$ depends on both the patient's embedding at time $t^-$ (just before time $t$) $\ed_{p,t^-}$ and the doctor's embedding $\ed_{d,t^-}$ prior to the interaction as well as the time elapsed between the patient's previous and the current interaction $\Delta_{p,t}$. 

However, relying only on interactions is not enough for patient care predictive modeling applications. While the interactions capture the medical events of a particular patient, they do not capture the inherent risk the patient is at due to the patient's own underlying health conditions and demographic features. Hence, we ensure that the patient's dynamic embedding $\ed_{p,t}$ also depends on the patient's static feature $\ps_p$ and the dynamic feature $\pd_{p,t}$ at time $t$. 
We ensure that the doctor's dynamic embedding $\ed_{d,t}$ depends on $\ps_p$ and $\pd_{p,t}$ to better track all the patients the doctor $d$ has interacted with.
% Figure \ref{fig:model_doctor} shows an example of how the Physician Module processes an interaction to update embeddings. 

Following are the update equations for  $\prodmod_p$ and  $\prodmod_d$ respectively.

% \begin{equation}
% \small
% \label{eq:hidep_update}
% \begin{aligned}
% \ed_{p,t} &=\sigma\left[ \W_{1}^{p} \ed_{p,t^-} +\W_{2}^{p} \ed_{d,t^-}+ \W_{3}^{p} \Delta_{p,t} +\W_{4}^{p} \ps_p  +\W_{5}^{p} \pd_{p,t}  \right] \\
% \ed_{d,t} &=\sigma\left[ \W_{6}^{p} \ed_{d,t^-} +\W_{7}^{p} \ed_{p,t^-}+ \W_{8}^{p} \Delta_{d,t} +\W_{9}^{p} \ps_p  +\W_{10}^{p} \pd_{p,t}  \right] \\
% \end{aligned}
% \end{equation}

% Here, $\W_{1}^{p}$ to $\W_{5}^{p}$ are the weight matrices parameterizing $\prodmod_p$. Similarly, $\W_{6}^{p}$ to $\W_{10}^{p}$ are the weight matrices for $\prodmod_d$ and finally $\sigma$ is a non-linear activation function. In our experiments, we set $\sigma$ to be the relu function.

\begin{equation}
\small
\label{eq:hidep_update}
\begin{aligned}
\ed_{p,t} &=\sigma\left[ \W_{p}^{PM} [\ed_{p,t^-} \mathbin| \ed_{d,t^-} \mathbin| \Delta_{p,t} \mathbin| \ps_p  \mathbin| \pd_{p,t}] + \mathbf{B}_{p}^{PM} \right] \\
\ed_{d,t} &=\sigma\left[ \W_{d}^{PM} [\ed_{d,t^-} \mathbin| \ed_{p,t^-} \mathbin| \Delta_{d,t} \mathbin| \ps_p  \mathbin| \pd_{p,t}] + \mathbf{B}_{d}^{PM} \right]
\end{aligned}
\end{equation}
Here, $\W_{p}^{PM}$ is the weight matrix parameterizing $\prodmod_p$ and
$\W_{d}^{PM}$ is the weight matrix for $\prodmod_d$.
$\mathbf{B}_{p}^{PM}$ and $\mathbf{B}_{d}^{PM}$ are bias. 
$[\mathbf{a} \mathbin| \mathbf{b}]$ denotes concatenation of the two vectors $\mathbf{a}$ and $\mathbf{b}$. Finally $\sigma$ is a non-linear activation function, and in our experiments, we set $\sigma$ to be the tanh activation.

Note that $\ed_{p,t^-}$ in Equation \ref{eq:hidep_update} is the patient embedding immediately prior to the interaction $(p,d,t)$. In earlier related approaches,  $\ed_{p,t^-}$ is taken to be the embedding generated by $\prodmod_p$ for patient $p$'s last interaction before time $t$. However, in cases where the gap between consecutive interactions are too large, this approach is sub-optimal. Hence, in this paper, we use the embedding projection operation~\cite{kumar2019predicting}. Specifically, a patient $p$'s embedding after time $\Delta$ is projected to be,
\begin{equation}
    \ed_{p,t + \Delta} = (1 + \W\times \Delta) + \ed_{p,t}
    \label{eq:projection}
\end{equation}
where $\W$ is a linear weight matrix. We use Equation \ref{eq:projection} to generate $\ed_{p,t^-}$ by projecting the embedding generated by $\prodmod_p$ for $p$'s previous interaction.
% Doctor $d$'s embedding is projected in a similar fashion. 

\subsection{Medication Module}
Similar to the Physician module, we maintain a pair of co-evolving deep neural networks $\medmod_{p}$ and $\medmod_{m}$ to update the embeddings $\ed_{p,t}$ and $\ed_{m,t}$ post a medication interaction $(p,m,t)$. Recall that a medication interaction $(p,m,t) \in \Med$ represents that a medication $m$ was prescribed to a patient $p$ at time $t$. Here, $\medmod_{p}$ updates the dynamic embedding of $p$ at time $t$ and $\medmod_{m}$ does the same for medicine $m$. The update equation for the medication module are similar to the physician module,

\begin{equation}
\small
\label{eq:medication_update}
\begin{aligned}
\ed_{p,t} &=\sigma\left[ \W_{p}^{MM} [ \ed_{p,t^-} \mathbin| \ed_{m,t^-} \mathbin| \Delta_{p,t} \mathbin| \ps_p  \mathbin| \pd_{p,t} ] + \mathbf{B}_{p}^{MM}  \right] \\
\ed_{m,t} &=\sigma\left[ \W_{m}^{MM} [\ed_{m,t^-} \mathbin| \ed_{p,t^-} \mathbin| \Delta_{m,t} \mathbin| \ps_p \mathbin| \pd_{p,t} ] + \mathbf{B}_{m}^{MM} \right]
\end{aligned}
\end{equation}
where $\W_{p}^{MM}$ and $\W_{m}^{MM}$ are the weight matrices for $\medmod_p$ and $\medmod_m$, respectively. $\mathbf{B}_{p}^{MM}$ and $\mathbf{B}_{m}^{MM}$ are bias.

\subsection{Transfer Module}
Similar to the previous two modules, the transfer module also consist of two co-evolving neural networks. 
$\transmod_{p}$ updates the patient embedding $\ed_{p,t}$  and $\transmod_{r}$ updates the room embedding post a transfer interaction $(p,r,t) \in \Tra$. The update equations for the transfer module are as follows:

\begin{equation}
\small
\label{eq:room_update}
\begin{aligned}
\ed_{p,t} &=\sigma\left[ \W_{p}^{TM} [\ed_{p,t^-} \mathbin| \ed_{r,t^-} \mathbin| \Delta_{p,t} \mathbin| \ps_p  \mathbin| \pd_{p,t} ] + \mathbf{B}_{p}^{TM}  \right] \\
\ed_{r,t} &=\sigma\left[ \W_{r}^{TM} [\ed_{r,t^-} \mathbin| \ed_{p,t^-} \mathbin| \Delta_{r,t} \mathbin| \ps_p  \mathbin| \pd_{p,t} ] + \mathbf{B}_{r}^{TM} \right]
\end{aligned}
\end{equation}
where $\W_{p}^{TM}$ and $\W_{r}^{TM}$ are the weight matrices for $\transmod_p$ and $\transmod_r$, respectively. $\mathbf{B}_{p}^{TM}$ and $\mathbf{B}_{r}^{TM}$ are bias.

\subsection{Reconstruction Module}
\label{sec:prediction}

Consider the interaction $(p,e,t_2)$ such that a patient $p$ interacted with an entity $e$ at time $t_2$ and that $p$'s previous interaction occurred at time $t_1$ such that $t_1 < t_2$.
To learn a meaningful representations of patient $p$ and an entity $e$ in the latent space, we train $\ourmethod$ to update embeddings of both $p$ and $e$ such that they are capable of reconstructing the embedding of $e$ at time $t_2$.
Specifically, while processing the interaction $(p,e,t_2)$, 
our goal is to learn dynamic embeddings $\ed_{p,t_2^-}$ and $\ed_{e,t_2^-}$ immediately before time $t_2$ such that they are useful in reconstructing both
dynamic embedding $\ed_{e,t_2^-}$  and the 
static embedding $\es_{e}$ of entity $e$.

In order to reconstruct the dynamic and the static embeddings of entity $e$, we feed in 
static embeddings $\es_{p}$ and $\es_{e}$ of patient $p$ and entity $e$ along with the projection of the generated 
dynamic embeddings $\ed_{p,t_2^-}$ and 
dynamic embeddings of $e$ that is updated via consecutive interactions with other patients $\ed_{e,t_2^-}$ to the reconstruction module.
Each entity type (e.g., doctor, medication, room) has its own reconstruction module (e.g., \textit{RECONST}\textsubscript{D},
\textit{RECONST}\textsubscript{M},
\textit{RECONST}\textsubscript{R}), 
which is defined as follows:
\begin{equation}
\small
\label{eq:hidep_predict}
\begin{aligned}
\pred_{d,t_2^-}&=\W_d \left[\ed_{p,t_2^-} \mathbin| \es_{p} \mathbin| \ps_{p} \mathbin| \ed_{d,t_2^-} \mathbin| \es_{d}\right] + \mathbf{B}_d\\
\pred_{m,t_2^-}&=\W_m \left[\ed_{p,t_2^-} \mathbin| \es_{p} \mathbin| \ps_{p} \mathbin| \ed_{m,t_2^-} \mathbin| \es_{m}\right] + \mathbf{B}_m\\
\pred_{r,t_2^-}&=\W_r \left[\ed_{p,t_2^-} \mathbin| \es_{p} \mathbin| \ps_{p} \mathbin| \ed_{r,t_2^-} \mathbin| \es_{r}\right] + \mathbf{B}_r\\
\end{aligned}
\end{equation}
where $\W_d$, $\W_m$, and $\W_r$ are the learnable weight matrices for reconstructing embeddings of doctor, medication, and room and $\mathbf{B}_d$, $\mathbf{B}_m$, and $\mathbf{B}_r$ are bias. Note that $\pred_{e,t_2^-}$ is the predicted embedding of size $|\ed_{e,t_2^-}| + |\es_{e}|$.

\begin{comment}
\subsection{Prediction Module}
\label{sec:prediction}
{\color{red} Modify this section. Auto-encoder.}
Consider two consecutive interactions, $(p,e_1,t_1)$ and $(p,e_2,t_2)$ such that $t_1 < t_2$, involving patient $p$ and entities $e_1$ and $e_2$ of the same type. 
To learn a meaningful representations of patient $p$ and an entity $e$ in the latent space, we train $\ourmethod$ to update embeddings of both $p$ and $e_1$ such that they are capable of forecasting $p$'s next interaction with $e_2$ at time $t_2$ following related works~\cite{kumar2019predicting}. Specifically while processing the interaction $(p,e_1,t_1)$, our goal is to learn dynamic embeddings $\ed_{p,t_1}$ and $\ed_{e_1,t_1}$, such that they are useful in predicting both dynamic embedding $\ed_{e_2,t_2^-}$ immediately before time $t_2$ and the static embedding $\es_{e_2}$ of entity $e_2$.

In order to predict the dynamic and the static embeddings of entity $e_2$, we feed in static embeddings  $\es_{p}$ and $\es_{e_1}$ of patient $p$ and entity $e_1$ along with the projection of the generated dynamic embeddings $\ed_{p,t_2^-}$ and $\ed_{e_1,t_2^-}$ to the prediction module \predmod, which is defined as follows.  

\begin{equation}
\small
\label{eq:hidep_predict}
\pred_{e_2,t_2^-}=\W [\ed_{p,t_2^-} \mathbin| \es_{p} \mathbin| \ps_{p} \mathbin| \ed_{e_1,t_2^-} \mathbin| \es_{e_1}] + \mathbf{B}
\end{equation}

where $\W$ is the learnable weight matrices and $\mathbf{B}$ is a bias. $\pred_{e_2,t_2^-}$ is the predicted embedding. 
\end{comment}

\ourmethod uses onehot vector for static embeddings.
We have another model \ourmethodp, which we use Bourgain embeddings \cite{Bourgain1986TheMI} for static embeddings of $v \in \doc \cup \med \cup \room$, which we compute from static graphs $G_{\mathrm{entity type}}$.

\subsection{Overall Framework}

While our primary goal is to train $\ourmethod$ to 
encode the entity that a patient interacts with,
% predict future interactions, 
we also want to enforce additional losses to ensure that the generated embeddings are interpretable. We analyze our learned embeddings with the help of a domain expert (See Section \ref{section:experiment}). We describe the losses used to train \ourmethod next.

\par\noindent\textbf{Reconstruction Loss:} \emph{Reconstruction loss} is encoded as the error between the predicted and the ground truth embeddings of the entity a patient interacts with.
Continuing with our example from Section \ref{sec:prediction}, we want to minimize the difference between 
the reconstructed embedding $\pred_{e,t_2^-}$ and the 
ground truth embedding $[\ed_{e,t_2^-} \mathbin| \es_{e_2}]$, where $\mathbin|$ is the concatenation operation. We enforce the reconstruction loss on all interactions including procedure interactions $\Pro$, medication interactions $\Med$, and transfer interactions $\Tra$.

Formally, reconstruction loss is defined as follows:
\begin{align}
 \small
    L_{reconst} &= \sum_{(p,d,t) \in \Pro} ||\pred_{d,t^-}  - [\ed_{d,t^-}|\es_{d}]||_2  \nonumber\\
    &+ \sum_{(p,m,t) \in \Med} ||\pred_{m,t^-}  - [\ed_{m,t^-}|\es_{m}]||_2   \nonumber \\
     &+ \sum_{(p,r,t) \in \Tra} ||\pred_{r,t^-}  - [\ed_{r,t^-}|\es_{r}]||_2
\end{align}
where $||\mathbf{v}||_2$ is the $L_2$ norm of the vector $\mathbf{v}$. 

\par\noindent\textbf{Temporal Consistency Loss:} We want to ensure that the embeddings of entities do not vary dramatically between consecutive interactions. To this end, we define \emph{temporal consistency} loss as the $L_2$ norm of the difference between the embeddings of each entity between each consecutive interaction.  Formally, it is defined as follows:

\begin{equation}
\small
    L_{temp} = \sum_{(p,e,t) \in \Int} ||\ed_{p,t} -\ed_{p,t^-}||_2 +  ||\ed_{e,t} -\ed_{e,t^-}||_2
\end{equation}

As defined earlier, $\Int$ is the set of all interactions, i.e., $\Int = \Pro \cup \Med \cup \Tra$. 

\par\noindent\textbf{Domain Specific Loss:}
% In addition to the ones above, 
Furthermore, we also implement a set of losses to ensure that the entities known to be similar as per domain knowledge have similar embeddings. To this end, we first compute the Laplacian matrices, $\mathbf{L}_{\mathrm{room}}$, $\mathbf{L}_{\mathrm{med}}$, and $\mathbf{L}_{\mathrm{doc}}$ corresponding to the static graphs, $G_{\mathrm{room}}$, $G_{\mathrm{med}}$, and $G_{\mathrm{doc}}$ representing similarities between the entities (see Section \ref{sec:setup} for details on the graphs). We then compute the graph Laplacian based \emph{domain specific loss} as follows:

\begin{align}
\small
    L_{dom} &= \lambda_{dom}^D \sum_{t \in [0,T], d \in \doc} \ed_{d,t}^T  \mathbf{L}_{\mathrm{doc}} \ed_{d,t}\\
    &+ \lambda_{dom}^M \sum_{t \in [0,T], m \in \med} \ed_{m,t}^T  \mathbf{L}_{\mathrm{med}} \ed_{m,t} \nonumber \\ 
    &+ \lambda_{dom}^R \sum_{t \in [0,T], r \in \room} \ed_{r,t}^T  \mathbf{L}_{\mathrm{room}} \ed_{r,t} \nonumber
\end{align}

Note that $\ed_{r,t}^T$ is a transpose of $\ed_{r,t}$ and $\lambda_{dom}^D$, $\lambda_{dom}^M$ and $\lambda_{dom}^R$ are scaling constants in the equation above. 
Note that the $L_{dom}$ decreases in magnitude if entities connected by an edge have similar embeddings.

\par \noindent \textbf{Overall Loss and Training: } Our overall loss is the weighted aggregation of the previous three losses. 
%Our overall approach is presented in Figure \ref{fig:model}. 
Note that we jointly train all three modules along with the reconstruction module after pre-training each individual module. 
We optimize the overall loss using the Adam optimization algorithm~\cite{kingma2014adam}.  
% In Table \ref{tab:model_paramters}, we provide the detailed architecture of the model and the hyperparameters used in training the model.
We use Adam optimizer with the learning rate of 1e-3 and the weight decay of 1e-5.
The size of the dynamic embeddings of \ourmethod and \ourmethodp are set to 128.
We train \ourmethod and \ourmethodp for 1000 epochs with an early stopping on the training loss with the patience of 10 epochs.


%We also leveraged a modified version of t-Batching~\cite{} to ensure temporal consistency while generating batches for training, where we further divide temporally consistent batches generated by t-Batching by interaction type.
