\section{Background and Related Work}
\label{sec:backgrond-related}

\subsection{FL Algorithms}
A great deal of effort has been devoted to FL algorithm research \cite{wang2021field,li2020federated, advancesopenfl, nguyen2021federated}. 
Typically, FL algorithms adopt the following workflow similar to the well-known FedAvg \cite{fedavg}: 
At the $t$-th FL round, the server first selects $n$ available clients $\mathcal{C}_{ava}$ from all the $N$ participated clients, and sends the current global model weight $\bm{\theta_g^{t}}$  to the selected clients.
Then the selected client $i$ trains the received model with their local private data, and uploads the updated weight $\bm{\theta_i^{t+1}}$ to the server.
Finally, the server aggregates the model updates from $n'$ responded clients $\mathcal{C}_{res} \subseteq \mathcal{C}_{ava}$ to generate the next-round global model as
$\bm{\theta_g^{t+1}}= \sum_{i=1}^{n'}w_i\bm{\theta_i^{t+1}}$ where $w_i$ is the aggregation weight that is usually defined as the ratio of the number of training data of client $i$ and the total number for all the $n'$ clients.
This process is repeated until $\bm{\theta_g}$ converges or the round reaches the pre-defined maximum number $T$.

In real-world FL scenarios, $N$ can be in various scales and even be very large with highly heterogeneous data distribution, and the clients usually have limited device resources and spotty connections.
These pose difficulties to learn high-quality FL models with fast convergence speed and low resource cost. 
Researchers have proposed fruitful algorithms to improve FedAvg such as personalization with client-specific model $\bm{\theta_i}$ \cite{towardspfl,fedbn,li2021ditto,oh2022fedbabu, fedrep}, heterogeneity-aware sampling protocols \cite{fedbalancer,Oort-osdi21}, communication compression \cite{konevcny2016federated, Haddadpour2020FederatedLW, xu2020ternary} and asynchronous aggregation \cite{chen2020asynchronous, xie2019asynchronous, lu2019differentially}.
However, most existing FL algorithms are studied and validated in homogeneous device simulation environments, in which the responded clients $\mathcal{C}_{res}$ at each round will \textit{differ} from the one in heterogeneous device setting, and subsequently leads to \textit{inconsistent} available clients $\mathcal{C}_{ava}$,  convergence round $T'$ and aggregated model sequence $\{\bm{\theta_g^2, \theta_g^3, \cdots, \theta_g^{T'}}\}$. 
In this work, different from most existing homogeneous device works, we focus on real heterogeneous device scenarios and study the effect of various heterogeneous device scales.



\subsection{FL Systems and Tools}
There are a number of FL systems and tools that make efforts to translate academic FL progress into real-world or scalable solutions.
Some industrial systems have performed FL on real heterogeneous runtime mobile devices with $n'$ in the hundreds to thousands scale, such as Google FL stack \cite{googlefl}, Papaya proposed by Facebook \cite{papaya}, and Apple FL \cite{afl}.
However, these works are closed-source.
Among the many open-source frameworks, benchmarks and tools such as LEAF \cite{leaf}, TensorFlow Federated \cite{tff}, PySyft \cite{pysyft}, FedML \cite{fedml}, Flower \cite{flower}, OpenFL \cite{openfl_citation}, IBM FL \cite{ibmfl},  FederatedScope \cite{fs}, FLARE \cite{nvidiaFlare}, large-scale realistic heterogeneous device runtime is not yet well supported.
Ideally, one can approximate the response time of an individual device as $|\bm{\theta}|/B_{up} + |\bm{\theta}|/B_{down} + |D|s + t_{other}$, where $|\bm{\theta}|$ indicates the model size, $B_{up}$ and $B_{down}$ indicates the upload and download speeds respectively, $|D|$ is the size of the local training data, $s$ is the training speed and $t_{other}$ indicates the total delay of other processings such as I/O. 
Any one of these factors can vary by orders of magnitude on different devices (e.g. $B_{up}$ on a 4G network can be 200 times faster than on a 3G network) and consequently cascade to cause huge inter-device response differences. In addition, some device states tend to change dynamically and become unavailable according to conditions defined by specific FL protocols and applications, such as network type switching, FL executor being shut down by the user or OS, device running low on power, etc.
FedScale \cite{fedscale} and FLASH \cite{flash} consider introducing heterogeneous message arrival times with cost models and virtual timestamps, but their fidelity is still limited by the capability of the cost models, and the precision and coverage of the device capacity values (\eg, $s$ and $t_{other}$ mentioned above).
Our work differs from theirs by supporting real and scalable heterogeneous device runtime with an efficient device training engine, and high-fidelity simulation with different mobile types and device distributions.

Besides, these above works mainly focus on functionality and usability of system or tool.
Different from them, we studied the impact of different device runtime distributions and scales on the FL, especially in conjunction with some of the recent FL algorithms such as personalization, compression, and asynchronous aggregation. 
