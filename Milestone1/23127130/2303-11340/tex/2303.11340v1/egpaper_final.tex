\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{algorithm}
\usepackage{algorithmic}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{11459} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ificcvfinal\pagestyle{empty}\fi

\begin{document}

%%%%%%%%% TITLE
\title{HDformer: A Higher Dimensional Transformer for Diabetes Detection Utilizing Long Range Vascular Signals}

\author{Ella Lan
% First Author \\
% Institution1\\
% Institution1 address\\
% {\tt\small firstauthor@i1.org}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
% \and
% Second Author\\
% Institution2\\
% First line of institution2 address\\
% {\tt\small secondauthor@i2.org}
}

\maketitle
% Remove page # from the first page of camera-ready.
\ificcvfinal\thispagestyle{empty}\fi


%%%%%%%%% ABSTRACT
\begin{abstract}
   Diabetes mellitus is a worldwide concern, and early detection can help to prevent serious complications. Low-cost, non-invasive detection methods, which take cardiovascular signals into deep learning models, have emerged. However, limited accuracy constrains their clinical usage. In this paper, we present a new Transformer-based architecture, Higher Dimensional Transformer (HDformer), which takes long-range photoplethysmography (PPG) signals to detect diabetes. The long-range PPG contains broader and deeper signal contextual information compared to the less-than-one-minute PPG signals commonly utilized in existing research. To increase the capability and efficiency of processing the long range data, we propose a new attention module Time Square Attention (TSA), reducing the volume of the tokens by more than 10x, while retaining the local/global dependencies. It converts the 1-dimensional inputs into 2-dimensional representations and groups adjacent points into a single 2D token, using the 2D Transformer models as the backbone of the encoder. It generates the dynamic patch sizes into a gated mixture-of-experts (MoE) network as decoder, which optimizes the learning on different attention areas. Extensive experimentations show that HDformer results in the state-of-the-art performance (sensitivity 98.4, accuracy 97.3, specificity 92.8, and AUC 0.929) on the standard MIMIC-III dataset, surpassing existing studies. This work is the first time to take long-range, non-invasive PPG signals via Transformer for diabetes detection, achieving a more scalable and convenient solution compared to traditional invasive approaches. The proposed HDformer can also be scaled to analyze general long-range biomedical waveforms. A wearable prototype finger-ring is designed as a proof of concept.
\end{abstract}

%%%%%%%%% BODY TEXT
\begin{figure*}[t]
  \centering
  \includegraphics[width=0.9\linewidth]{HDformerArchitecture.png}
   \caption{HDformer Architecture.}
   \label{fig:figure9}
\end{figure*}



\section{Introduction}


%-------------------------------------------------------------------------
Diabetes mellitus is a clinical condition that results in a high amount of glucose in the blood due to the lack of insulin in the body - otherwise known as insulin resistance \cite{martin1992role}. Diabetes can raise the risk of diseases, affecting nearly every organ system: coronary heart disease, kidney failure, blindness, stroke, etc. According to the World Health Organization (WHO), roughly 422 million people have been diagnosed with diabetes. Its mortality rate is also increasing each year. It accounts for 1.5 million deaths each year, making diabetes the 7th global leading cause of mortality. These statistics disproportionately affect those in lower-income communities.

Diabetes is often referred to as the “silent killer” and is commonly overlooked until its later progression into more critical stages. The lack of early detection results in cases where diabetic patients are not treated until later stages when the patient’s blood sugar is uncontrollable and acutely above the standard. According to data from the International Diabetes Federation, almost 50\% of people with diabetes are unaware of their diagnosis and its risks to their health, hence leaving the disease untreated.

To minimize side effects and worsening of the disease, actions such as early prevention, drug treatments, and changes in lifestyle are essential. Effective prevention through regular monitoring of the blood glucose levels (BGL) is necessary for diabetes management. Currently, only invasive methods (blood glucose laboratory tests and glucometers) are commercially available for accurate monitoring of BGL, including the fasting plasma glucose (FPG) test and the hemoglobin A1C (HbA1c) test. However, such treatments are expensive, time consuming, painful for patients, and ultimately, are unable to measure long-term progression. To overcome these limitations, research on non-invasive methods has emerged. A continuous, non-invasive, painless, easy-to-operate, and low-cost solution can help improve patient compliance with routine blood glucose monitoring, potentially leading to an early detection of diabetes. The development of such technologies capable of detecting the onset of diabetes can lead to large-scale prevention. However, the accuracy and general applicability of these non-invasive approaches have not proven to be competitive with current invasive methods. This paper aims to address this gap.

Photoplethysmography (PPG) is an optically obtained signal that can be used to detect blood volume changes in the microvascular bed of tissues; it can be used to extract key information such as blood oxygen saturation, heart rate, blood pressure, cardiac output, cardiac respiration, arterial aging, endothelial function, microvascular blood flow, and autonomic function \cite{elgendi2019use}. 

Diabetes is associated with vascular changes and is often used in blood glucose estimation and diabetes detection due to its cost-effectiveness and simplicity of usage. A decrease of HR variability (HRV) is associated with diabetes, resulted from the harmful effects of altered glucose metabolism which leads to cardiac autonomic neuropathy. Resting HR largely increases in diabetes, implicating mechanisms ranging from metabolism to endothelial aging. Endothelial dysfunction, an early hallmark of diabetic vascular disease, is reflected in the PPG waveform. Diabetes increase arterial stiffness, which can be reflected in SDPTG (second-derivative of PPG). The increase of blood viscosity and modification of heart polarization and depolarization presented in diabetes groups also change PPG wave shape. 

The utilization of deep learning can further enhance PPG usability in clinics.

To address the gap of accuracy, we take long range PPG waveforms as the input, 10+ minutes, compared to the common input of less-than-one-minute in existing research. The long range vascular signals (PPG) contain richer features for the diabetes classification. In this study, we propose a Higher Dimensional Transformer (HDformer), capturing the global representation and long distance feature dependencies among the waveforms via attention modules. A new Time-Square Attention (TSA) is created to aggregate 1-dimensional dependencies from  2-dimensional representations. The proposed ML model has achieved the SOTA results on the standard MIMIC-III dataset.

The contributions of this paper include:

\begin{itemize}
\item A scalable, non-invasive approach to take long range vascular signals (PPG) for diabetes detection for the first time, achieving SOTA results.

\item A Transformer-based deep learning architecture HDformer to perform long range biomedical waveforms processing.

\item A proposed attention module TSA to capture 1-dimensional dependencies from 2-dimensional representations, adaptable to input into existing 2D Transformer models, while applying a gated network of mixture-of-experts for the dynamic patch size of each 2D shape.

\item A deep learning-based, in-depth, long-range data analysis on the blood volume changes (measured from PPG) and blood glucose estimation (indicator of diabetes), for diabetes detection. 

\item A general Transformer based framework capable of time-series learning and prediction for 1-dimensional long-range sequences.

\end{itemize}

\section{Related Work}


%-------------------------------------------------------------------------
\subsection{Photoplethysmography (PPG) and Electrocardiography (ECG)}

PPG and ECG are commonly used digital biomarkers for cardiovascular disease (CVD) analysis. Since both PPG and ECG are measured by non-invasive methods, they have recently been used in blood glucose estimation and diabetes detection through machine learning approaches. One of the first studies in this area was by ~\cite{moreno2016type}, who used the inverse Fourier transform (IFT) to extract features to feed into several machine learning models; ~\cite{hettiarachchi2019machine} identified features related to diabetes from PPG and established the feasibility of prediction with its linear discriminant analysis (LDA); ~\cite{qawqzeh2020classification} developed logistic regression (LR) modeling to use PPG to perform the classification of diabetes. However, to obtain reliable results, these methods required an abundant amount of attention on dataset processing for the feature extraction. Additionally, each study collected their own datasets which causes a lack of result standardization. These limits make the traditional machine learning methods challenging to scale to broader usage. The recent rise of deep learning led to the application of convolutional neural networks for PPG prediction of diabetes. ~\cite{avram2020digital} utilized smartphone-based PPG signals and CNN to achieve an area under the curve (AUC) of 0.75 for diabetes prediction. ~\cite{panwar2020cardionet} presented a reconfigurable deep learning framework, combining CNN and the inherent capabilities of PPG feature extraction. ~\cite{wang2020igrnet} and ~\cite{srinivasan2021deep} proposed two-dimensional CNN models, one taking ECG and another taking PPG, in combination with age, gender, and the presence of hypertension. However, their training required larger datasets to be generated by themselves. Because of the nature of locality-sensitive CNN, the accuracy of these models are also limited in the range of 70\% to 80\%, lower than those from the feature-extraction-based machine learning models. In our research, we choose PPG over ECG due to its increased ability to be measured continually, and we pick Transformers over CNN to apply its capability of capturing the global contextual information and long-range dependencies, for the diabetes classification.

\subsection{Long Range Transformers}

Although Transformer ~\cite{vaswani2017attention} originated in the world of Natural Language Processing (NLP), it has also become prevalent in the field of computer vision (CV), surpassing many CNN-based models in performing tasks such as image classification and segmentation ~\cite{dosovitskiy2020image} ~\cite{carion2020end}. Much of Transformer’s success comes from its self-attention mechanism, which not only simplifies the architectural complexity by removing convolutions entirely, but also allows models to capture the global contextual information for both short-range and long-range relationships. Recently, studies have shown the potential of improving architectures like the Transformer to increase the prediction capacity to be more adaptable to analyzing longer range data, through optimizing key components such as its self-attention mechanism and its memory usage efficiency. These proposals, built on top of the vanilla Transformer, include the memory-optimization-based LongFormer ~\cite{beltagy2020longformer}, lower-dimensional representation-based LinFormer ~\cite{wang2020linformer}, recurrence-based Transformer XL ~\cite{dai2019transformer}, down-sampling-based Informer ~\cite{zhou2021informer}, and learnable patterns-based Reformer ~\cite{kitaev2020reformer}, etc. In this study, we propose a new Transformer architecture HDformer, to process 1-dimensional PPG waveforms into 2-dimensional representation via our attention model TSA, optimizing model efficiency while retaining the key information of the signals.

\section{Methods}

\begin{figure}[t]
  \centering
  \includegraphics[width=0.9\linewidth]{HDformer_1D_to_2D_Attention_Mechanism.png}
   \caption{Various Attentions Comparison and TSA.}
   \label{fig:figure2}
\end{figure}


%-------------------------------------------------------------------------
\subsection{Long Range Vascular Signals}

Recent deep learning-based research which take vascular signals for diabetes detection have shown promising results, but there is room to improve its accuracy. PPG is an optical method for measuring blood volume changes at the surface of the skin (non-invasive), and it can be easily measured by healthcare wearables in a continuous time window, e.g. hourly or even daily. Heart rate variability (HRV), usually measured by PPG and shown a correlation with the glucose level, is suggested to measure at 5 minutes as a minimal analysis window. Long range PPG helps to provide a complete picture for HRV. Its long range data collection can contain more long distance features which are missed in a short duration of PPG or ECG. Most existing research only takes 5 to 20 seconds of PPG/ECG signals as the input for their CNN (and LSTM) models. Our Transformer based method is capable of taking 10+ minutes of PPG signals as the input. In order to capture the long distance features, we propose a new Transformer – Higher Dimensional Transformer (HDformer) to process the long range PPG waveforms for diabetes classification.


\begin{figure*}[t]
  \centering
  \includegraphics[width=0.9\linewidth]{TSA_Dynamic_Various_Patches_Attention_Mechanism.png}
   \caption{Concept of Dynamic Patch Sizes in TSA.}
   \label{fig:figure3}
\end{figure*}

\subsection{Overall Design}

 It is an encoder/decoder structure. First, the raw PPG signals are de-noised and normalized in a pre-processing module. After the standard segmentation, each sequence represents a 10-minute PPG waveform. Then, a patch partition operation is taken to create patches of the PPG waveforms, which are then constructed into a 2-dimensional waveform representation (more details in the following section). Each group of the Transformer encoders, containing Time Square Attention (TSA), processes these 2-dimensional representations by applying existing 2D Transformer algorithms (e.g. ViT ~\cite{dosovitskiy2020image} or Swin ~\cite{liu2021swin}), and performs its own classification. Finally, the results from these models (experts) will be feeded into a gated network of mixture-of-experts framework as decoders to perform the final diabetes detection, as illustrated in Figure~\ref{fig:figure9}.

\subsection{Time Square Attention}

\begin{algorithm}[tb]
\caption{Time Square Attention Algorithm}
\label{alg:algorithm1}
\textbf{Input}: 1D PPG Waveforms\\
\textbf{Parameter}: Original Patch Size T, Targeted 2D Representation Size (N, T), Dynamical Patch Size D, Neural Network Layer Config\\
\textbf{Output}: Diabetes Classification
\begin{algorithmic}[1] %[1] enables line numbers
\STATE Initial patch partition.
\WHILE{current 2D representation size is smaller than (N, T)}
\IF {$\mbox{D} > $\mbox{T}}
\STATE Fetch the length of D from PPG waveforms 
\STATE Perform down-sampling from D to T
\STATE Add into 2D representation
\ENDIF
\IF {$\mbox{D} <= $\mbox{T}}
\STATE Fetch the length of D * N from PPG waveforms
\STATE Partition into N patch of the D size
\STATE Add into 2D representation
\ENDIF
\ENDWHILE
\STATE Feed 2D representation into Transformer Encoder (in our study, we take Swin Transformer)
\STATE Add MLP layer for diabetes classification
\STATE \textbf{return} Diabetes prediction
\end{algorithmic}
\end{algorithm}


\begin{figure*}[t]
  \centering
  \includegraphics[width=0.9\linewidth]{TSA_Design.png}
   \caption{TSA Dynamic Patch Size Design.}
   \label{fig:figure4}
\end{figure*}

\begin{table*}
  \begin{center}
  \begin{tabular}{@{} |c|c|c|c|c| @{}}
    \hline
    Approaches & Sensitivity & Accuracy & Specificity & AUC \\
    \hline\hline
    Avram \etal~\cite{avram2020digital} & 75.0 & 76.7 & 65.5 & 0.830\\
    Wang \etal~\cite{wang2020igrnet} & 80.8 & 77.8 & 77.5 & 0.830\\
    Srinivasan \etal~\cite{srinivasan2021deep} & 76.7 & 76.3 & 76.1 & 0.830\\
    FPG\cite{srinivasan2021deep} & 79.0 & - & 82.8 & 0.890\\
    HbA1c\cite{srinivasan2021deep} & 86.3 & - & 75.8 & 0.859\\
    HDformer & \textbf{98.4} & \textbf{97.3} & \textbf{92.8} & \textbf{0.929}\\
    \hline
  \end{tabular}
  \end{center}
  \caption{Comparison of Our Results with Related Work}
  \label{tab:sota}
\end{table*}

While much of the successes of Transformer rely on its self-attention module, its computational complexity and memory usage grow quadratically along with the length of the sequence. Understandably, the increased length from a 20-second to a 10-minute PPG waveform segment makes it inefficient and infeasible for the standard Transformer to process this long range data. Hence, TSA is proposed to handle the PPG waveforms as a 2-dimensional representation, rather than the 1-dimensional sequence. Concretely, we create 2D representation by partitioning the 1D waveform into patches and then constructing these patches into 2D data, inspired by the fact that the PPG waveforms contain the repeating patterns. To address the limitation of self-attention on long range data, various attention models are illustrated and compared in Figure~\ref{fig:figure2}.

Figure~\ref{fig:figure2}A shows the vanilla Full Attention, in which one token is calculated against every other token in the sequence, with the maximal dependency \& computational complexity. Figure~\ref{fig:figure2}B presents Sparsity Attention, chunking input sequences into blocks to reduce token size and computational complexity. It represents an existing effort to apply the block patterns of fixed strides to sparsify the attention matrix. Figure~\ref{fig:figure2}C describes Time-based Sparsity Attention, in which the frequency of the token is defined by timing, and more weight is assigned to closer tokens than tokens farther away. 

Figure~\ref{fig:figure2}D decorates a fixed-patch aggregation on a new dimension Y to compose a 2D representation of the PPG waveforms. Existing dimension X carries each time-sequence wave with a patch width of T; Y decorates a fixed-patch aggregation, to compose a 2D representation. Since the second dimension Y is also time-based, we name this as Time Square Attention (TSA). Each token in TSA is a square (2D) formed by the adjacent points, with the extended coverage, 2 * 2, 3 * 3, 4 * 4, 5 * 5, etc., as depicted on the left. This approach effectively reduces the \# of tokens required to process e.g. 10 minute long PPG waveforms in a frequency of 128 Hz would include roughly 77K sampled points; TSA is required, effectively tokenizing those points for Transformer to analyze sequences of such length while retaining both local representation and global contextual information, connecting points in both short and long distance via 2D tokenization, and calculating the relationship of each token to every other token in the X \& Y dimensions.
\begin{table*}
  \begin{center}
  \begin{tabular}{@{} |c|c|c|c|c| @{}}
    \hline
    Attentions & Sensitivity & Accuracy & Specificity & AUC \\
    \hline\hline
    1D 1T & 75.8 & 72.5 & 68.9 & 0.791\\
    TSA 1T & 86.8 & 85.6 & 82.9 & 0.879\\
    TSA T/4 & 78.9 & 77.5 & 75.2 & 0.835\\
    TSA T/2 & 81.8 & 79.9 & 78.0 & 0.858\\
    TSA 2T & 87.5 & 86.2 & 84.5 & 0.890\\
    TSA 4T & 89.6 & 89.1 & 87.8 & 0.895\\
    TSA with MoE & \textbf{98.4} & \textbf{97.3} & \textbf{92.8} & \textbf{0.929}\\
    \hline
  \end{tabular}
  \end{center}
  \caption{TSA Configuration Comparison}
  \label{tab:comp}
\end{table*}

\subsection{Dynamic Patch Sizes in 2D Transformer}
To optimize the shape of the patches and to learn the best performing patch size of TSA, we explore a series of patch sizes to generate a group of dynamically 2D representations in different shapes, as displayed in Figure~\ref{fig:figure3}.

Since each 2-dimensional patch can be processed as a 2D tensor representation, we simply apply the existing 2D Transformer algorithms to perform the image classification training. As a result, either the classic ViT or hierarchical Swin is capable of capturing both the local and global dependencies within 2-dimensional representations, as presented in Figure~\ref{fig:figure4}. 

A detailed approach on the generation of different sized 2D representations is explained in Algorithm~\ref{alg:algorithm1}. In our experiment, we mark T as 1024 points, representing 8 seconds of PPG waveforms.

\subsection{A Gated Network of Mixture-of-Experts (MoE)}

To learn the optimal patch size from the dynamic patches in TSA, we deploy the hierarchical structures of the patches in dynamic sizes and propose a gated network of mixture-of-experts (MoE), as demonstrated in Figure~\ref{fig:figure9}. A group of 2D representations in the different shapes are computed in each TSA, which connects the MLP layers for the diabetes classifier generating a likelihood estimation score via softmax. Each expert contributes into the MoE with its weight computed in MoE learning, to generate the final diabetes detection from these models. In our study, we take the configuration of 5 TSA modules, with the dynamic patch sizes {T, 2T, 4T, T/2, T/4}.

\section{Experiments}


%-------------------------------------------------------------------------
\subsection{Datasets}

We take the public dataset MIMIC-III ~\cite{johnson2016mimic}. It is a large, single-centered database covering 38,597 distinct adult patients admitted to critical care units at a large tertiary care hospital. Data includes vital signs (like PPG and ECG), medications, laboratory measurements, procedure codes, diagnostic codes (ICD9 code starting with 250 labeled as diabetic patients), imaging reports, and more. One of the major reasons for choosing MIMIC-III is to evaluate our model in a standard comparison, rather than in a self-collected private dataset. All the PPG waveforms are re-sampled at 128Hz, and the regular de-noising and normalization are performed as part of the pre-processing.

\subsection{Discussions}

HDformer is implemented via Pytorch and the model was trained on AWS instances with GPU NVIDIA A10G. We performed the evaluation by generating the confusion matrix on both patient level and records level, showed in Figure~\ref{fig:figure6}. The model performs with an accuracy higher than 95\%, substantially outperforming previous research. 

\begin{figure}[t]
  \centering
  \includegraphics[width=0.9\linewidth]{Confusion_Matrix.png}
   \caption{Confusion Matrix.}
   \label{fig:figure6}
\end{figure}

As explained in Table~\ref{tab:sota}, HDformer has achieved the SOTA results on MIMIC III, compared with the related work, when evaluated on the metrics of sensitivity, accuracy, specificity, and AUC. In addition to exceeding the existing deep-learning-based, non-invasive approaches, HDformer also achieves higher performance than current clinically-used invasive approaches (FPG and HbA1c).

\begin{table*}
  \begin{center}
  \begin{tabular}{@{} |c|c|c|c|c| @{}}
    \hline
    Attentions & Sensitivity & Accuracy & Specificity & AUC \\
    \hline\hline
    1D 8s & 75.8 & 72.5 & 68.9 & 0.791\\
    1D 30s & 78.1 & 74.5 & 70.5 & 0.806\\
    1D 60s & 71.5 & 68.8 & 65.6 & 0.728\\
    TSA 30s & 77.8 & 75.1 & 72.5 & 0.808\\
    TSA 60s & 81.9 & 79.1 & 78.5 & 0.815\\
    TSA 180s & 83.2 & 81.5 & 80.9 & 0.829\\
    TSA 6m & 88.1 & 85.9 & 85.8 & 0.891\\
    TSA 10m & \textbf{98.4} & \textbf{97.3} & \textbf{92.8} & \textbf{0.929}\\
    \hline
  \end{tabular}
  \end{center}
  \caption{Signals Lengths Study.}
  \label{tab:leng}
\end{table*}

\begin{table*}
  \begin{center}
  \begin{tabular}{@{} |c|c|c|c|c| @{}}
    \hline
    Attentions & Sensitivity & Accuracy & Specificity & AUC \\
    \hline\hline
    2D Image 8s & 61.8 & 59.9 & 57.8 & 0.678\\
    2D Image 30s & 65.9 & 62.8 & 59.5 & 0.686\\
    2D Image 60s & 58.1 & 56.5 & 53.7 & 0.645\\
    2D Image 180s & 52.9 & 51.9 & 50.8 & 0.618\\
    TSA 30s & 77.8 & 75.1 & 72.5 & 0.808\\
    TSA 60s & 81.9 & 79.1 & 78.5 & 0.815\\
    TSA 180s & 83.2 & 81.5 & 80.9 & 0.829\\
    TSA 6m & 88.1 & 85.9 & 85.8 & 0.891\\
    TSA 10m & \textbf{98.4} & \textbf{97.3} & \textbf{92.8} & \textbf{0.929}\\
    \hline
  \end{tabular}
  \end{center}
  \caption{Signals Study 2D Tensor vs 2D Image Representation.}
  \label{tab:1d2dpv}
\end{table*}

\begin{table*}
  \begin{center}
  \begin{tabular}{@{} |c|c|c|c|c| @{}}
    \hline
    Attentions & Sensitivity & Accuracy & Specificity & AUC \\
    \hline\hline
    TSA 10m with ViT & 96.8 & 95.9 & 91.9 & 0.910\\
    TSA 10m with Swin & \textbf{98.4} & \textbf{97.3} & \textbf{92.8} & \textbf{0.929}\\
    \hline
  \end{tabular}
  \end{center}
  \caption{Swin vs ViT on TSA.}
  \label{tab:vision}
\end{table*}

The experiments suggest the effectiveness of HDformer and TSA through their novel design. This solution is capable of analyzing long range PPG signals to perform the final diabetes classification, achieving promising results both in terms of accuracy as well as through optimization metrics like time, memory, and computation by using (1) the proposed TSA self-attention to aggregate a new dimension to compose 2D representations of the 1D PPG waveforms and (2) the gated MoE layer to concatenate expert predictions via the gathered information regarding context and relationships among waveforms in the dynamic patch sizes.

\subsection{TSA in Depth}

\begin{figure}[t]
  \centering
  \includegraphics[width=0.9\linewidth]{TSA_Deeper.png}
   \caption{TSA 2-Dimensional Representation.}
   \label{fig:figure7}
\end{figure}

A sample of 2-dimensional representation PPG in our experiments is illustrated in Figure~\ref{fig:figure7}. The 1D PPG can be split into 2D image as Figure~\ref{fig:figure7}(A), while our design in TSA is to represent the raw PPG values in a 2-dimensional tensor as Figure~\ref{fig:figure7}(B). The main benefit for such a design is to reduce the total volume of the tokens to process from 2D image to 2D tensor, which can be visualized as Figure~\ref{fig:figure7}(C). TSA 2D allows Transformer to capture the long distance relationship from a new time-series dimension (Y axis, in addition to X axis) without introducing additional tokens (pixels in 2D image). On the other side, the Vision Transformers (ViT or Swin) are not capable for processing the standard 2D image containing 10 minutes PPG data, because of the computation complexity. 

We experiment with different PPG inputs with different model parameter configurations, shown in Table~\ref{tab:comp}. The 2D representation in TSA helps to generally achieve better results than the original 1D waveform in the standard self-attention mechanism. It is interesting to find that the larger size patches (2T and 4T) lead to higher performances than the smaller sizes (T/2 and T/4). The additional ensemble network from the gated MoE also yields a considerable enhancement on the model performance.

\subsection{Ablation Study}

To deeply understand the effects of the different sizes of TSA and the MoE, we also perform an ablation study on the different model parameter configurations.

To evaluate the length of the long-range PPG, a sensitivity analysis of different PPG wave lengths on diabetes detections is presented in Table~\ref{tab:leng}. For 1D sequences, performance metrics enhance when the wavelength increases from 8s to 30s, as a result of adding more features and extending long-distance dependencies into training. However, continuously increasing the length to 60s dilutes the performance when the computational capacity is overloaded. TSA processing 1D waveform via 2D representation significantly reduces the size of tokens without compromising long-term and short-term dependencies. The increase of wavelength consistently improved the performance, depicting the value of long range PPG while using TSA to optimize the computation capacity. We also perform a comparison between TSA and the 2D image-based representations which convert 1-dimensional PPG data into 2-dimensional images, and it reveals 2D image-based representations reduce the efficiency of the long-range data processing by introducing more tokens (pixels) than 1D PPG, as illustrated in Table~\ref{tab:1d2dpv}.

To evaluate the different Vision Transformer algorithms on the 2-dimensional TSA representations, we also compare the results between the standard ViT and the hierarchical Swin Transformer, as illustrated in Table~\ref{tab:vision}. While ViT performs with high accuracy, Swin Transformer achieves better results. It is caused by the hierarchical structure of Swin which captures the longer distance dependencies of the 2-dimensional PPG with different window sizes.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.9\linewidth]{PPG_Finger_Design.png}
   \caption{The Design of PPG Wearable.}
   \label{fig:figure8}
\end{figure}

\subsection{Medical Applications}

Having the efficiency of long range PPG processing, HDformer has presented the potential to detect diabetes in a non-invasive, scalable way, which is low-cost and easy to measure on continuous monitoring. A PPG-based finger-ring wearable prototype, as presented in Figure~\ref{fig:figure8}, is being developed as a proof of concept of our model. We have hosted the trained HDformer model into the Cloud, which takes the PPG waveforms from the wearable and inferences the 2-dimensional representation classification as diabetes prediction. Due to the convenient nature of wearing rings, the wearable can collect long range PPG signals consistently and can be easily adapted to most users. 


\section{Conclusion}

We propose HDformer, a Transformer-based model that is capable of processing long range vascular signals of PPG, to predict diabetes, achieving the SOTA model performance. It enables a new non-invasive method for early diabetes detection and is scalable to clinical usage,  leading to an overcoming of challenges in our current diabetes handling. Our TSA module demonstrates the high efficiency for processing the long range data with 2D representations and makes it compatible with the existing Vision Transformer models, while a gated MoE layer helps to ensemble the classification from the dynamic patch sizes of the 2D TSA. This approach can also be generalized to process long range biomedical waveforms beyond PPG via Transformer.

Future work will include the experiment with a variety of waveform frequencies, e.g. from 128Hz to 256Hz/512Hz, to evaluate whether increased frequency can help reduce the wavelength needed for HDformer performance. Additionally, we plan to explore the possibility to estimate the glucose level via PPG analysis, by taking the 2nd derivative PPG for HDformer/TSA analysis.

{\small
\bibliographystyle{ieee_fullname}
%\bibliography{egbib}
}

\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{avram2020digital}
Robert Avram, Jeffrey~E Olgin, Peter Kuhar, J~Weston Hughes, Gregory~M Marcus,
  Mark~J Pletcher, Kirstin Aschbacher, and Geoffrey~H Tison.
\newblock A digital biomarker of diabetes from smartphone-based vascular
  signals.
\newblock {\em Nature medicine}, 26(10):1576--1582, 2020.

\bibitem{beltagy2020longformer}
Iz Beltagy, Matthew~E Peters, and Arman Cohan.
\newblock Longformer: The long-document transformer.
\newblock {\em arXiv preprint arXiv:2004.05150}, 2020.

\bibitem{carion2020end}
Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander
  Kirillov, and Sergey Zagoruyko.
\newblock End-to-end object detection with transformers.
\newblock In {\em European conference on computer vision}, pages 213--229.
  Springer, 2020.

\bibitem{dai2019transformer}
Zihang Dai, Zhilin Yang, Yiming Yang, Jaime Carbonell, Quoc~V Le, and Ruslan
  Salakhutdinov.
\newblock Transformer-xl: Attentive language models beyond a fixed-length
  context.
\newblock {\em arXiv preprint arXiv:1901.02860}, 2019.

\bibitem{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock {\em arXiv preprint arXiv:2010.11929}, 2020.

\bibitem{elgendi2019use}
Mohamed Elgendi, Richard Fletcher, Yongbo Liang, Newton Howard, Nigel~H Lovell,
  Derek Abbott, Kenneth Lim, and Rabab Ward.
\newblock The use of photoplethysmography for assessing hypertension.
\newblock {\em NPJ digital medicine}, 2(1):1--11, 2019.

\bibitem{hettiarachchi2019machine}
Chirath Hettiarachchi and Charith Chitraranjan.
\newblock A machine learning approach to predict diabetes using short recorded
  photoplethysmography and physiological characteristics.
\newblock In {\em Conference on Artificial Intelligence in Medicine in Europe},
  pages 322--327. Springer, 2019.

\bibitem{johnson2016mimic}
Alistair~EW Johnson, Tom~J Pollard, Lu Shen, Li-wei~H Lehman, Mengling Feng,
  Mohammad Ghassemi, Benjamin Moody, Peter Szolovits, Leo Anthony~Celi, and
  Roger~G Mark.
\newblock Mimic-iii, a freely accessible critical care database.
\newblock {\em Scientific data}, 3(1):1--9, 2016.

\bibitem{kitaev2020reformer}
Nikita Kitaev, {\L}ukasz Kaiser, and Anselm Levskaya.
\newblock Reformer: The efficient transformer.
\newblock {\em arXiv preprint arXiv:2001.04451}, 2020.

\bibitem{liu2021swin}
Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and
  Baining Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted
  windows.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 10012--10022, 2021.

\bibitem{martin1992role}
Blaise~C Martin, James~H Warram, Andrzej~S Krolewski, JS Soeldner, CR Kahn, and
  RN Bergman.
\newblock Role of glucose and insulin resistance in development of type 2
  diabetes mellitus: results of a 25-year follow-up study.
\newblock {\em The Lancet}, 340(8825):925--929, 1992.

\bibitem{moreno2016type}
Enrique~Monte Moreno, Maria Jose~Anyo Lujan, Montse~Torrres Rusinol,
  Paqui~Juarez Fernandez, Pilar~Nunez Manrique, Cristina~Aragon Trivino,
  Magda~Pedrosa Miquel, Marife~Alvarez Rodriguez, and M~Jos{\'e}~Gonz{\'a}lez
  Burguillos.
\newblock Type 2 diabetes screening test by means of a pulse oximeter.
\newblock {\em IEEE Transactions on Biomedical Engineering}, 64(2):341--351,
  2016.

\bibitem{panwar2020cardionet}
Madhuri Panwar, Arvind Gautam, Rashi Dutt, and Amit Acharyya.
\newblock Cardionet: Deep learning framework for prediction of cvd risk
  factors.
\newblock In {\em 2020 IEEE International Symposium on Circuits and Systems
  (ISCAS)}, pages 1--5. IEEE, 2020.

\bibitem{qawqzeh2020classification}
Yousef~K Qawqzeh, Abdullah~S Bajahzar, Mahdi Jemmali, Mohammad~Mahmood Otoom,
  and Adel Thaljaoui.
\newblock Classification of diabetes using photoplethysmogram (ppg) waveform
  analysis: Logistic regression modeling.
\newblock {\em BioMed Research International}, 2020, 2020.

\bibitem{srinivasan2021deep}
Venkatesh~Bharadwaj Srinivasan and Foroohar Foroozan.
\newblock Deep learning based non-invasive diabetes predictor using
  photoplethysmography signals.
\newblock In {\em 2021 29th European Signal Processing Conference (EUSIPCO)},
  pages 1256--1260. IEEE, 2021.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{wang2020igrnet}
Liyang Wang, Yao Mu, Jing Zhao, Xiaoya Wang, and Huilian Che.
\newblock Igrnet: a deep learning model for non-invasive, real-time diagnosis
  of prediabetes through electrocardiograms.
\newblock {\em Sensors}, 20(9):2556, 2020.

\bibitem{wang2020linformer}
Sinong Wang, Belinda~Z Li, Madian Khabsa, Han Fang, and Hao Ma.
\newblock Linformer: Self-attention with linear complexity.
\newblock {\em arXiv preprint arXiv:2006.04768}, 2020.

\bibitem{zhou2021informer}
Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong,
  and Wancai Zhang.
\newblock Informer: Beyond efficient transformer for long sequence time-series
  forecasting.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~35, pages 11106--11115, 2021.

\end{thebibliography}

\end{document}




















