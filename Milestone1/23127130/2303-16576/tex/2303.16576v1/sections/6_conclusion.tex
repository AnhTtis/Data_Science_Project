\section{Conclusion}
\label{sec:conclusion}

We presented WordStylist, a latent diffusion-based system for styled text-to-text-content image generation on word-level.
Our model manages to capture the style and content without the use of any adversarial training, text recognition and writer identification.
Qualitative and quantitative evaluation results show that our method produces high quality images which outperform significantly the state-of-art systems used for comparison.
Also we show that our synthetic word images can be used as extra training data to improve HTR accuracy.
The verisimilitude of the synthetic handwriting styles is proven by two experiments.
Using a CNN for writer identification, we obtain a classification accuracy of 70\% with our synthetic data, while the other generative methods used for comparison do not get higher than 5\%.
Also, t-SNE projections of the features learned by the CNN exhibit structures very similar to real data in the case of the proposed method only.
Moreover, we showed that using a recognized writer retrieval pipeline, there is no significant difference between results on our synthetic data and real data, both having a mAP slightly below 98\%.
The other generative methods do not perform as well, obtaining mAP below 8\%.
For future work, we aim to investigate the parameters and sampling of the model.
We further plan on extending this work for sentences and whole pages, focusing also on the layout of the document.