\begin{abstract}

%Generative Adversarial Networks are considered the standard method for image synthesis since their introduction.
%Text-to-Image synthesis, which refers to generating an image according to a specific text description.
%Recent work in Denoising Diffusion Probabilistic Models has shown remarkable results in Text-to-Image synthesis, which refers to generating an image according to a specific text description.
Text-to-Image synthesis is the task of generating an image according to a specific text description.
Generative Adversarial Networks have been considered the standard method for image synthesis virtually since their introduction.
Denoising Diffusion Probabilistic Models are recently setting a new baseline, with remarkable results in Text-to-Image synthesis, among other fields.
Aside its usefulness \emph{per se}, it can also be particularly relevant as a tool for data augmentation to aid training models for other document image processing tasks.
In this work, we present a latent diffusion-based method for styled text-to-text-content-image generation on word-level.
Our proposed method is able to generate realistic word image samples from different writer styles, by using class index styles and text content prompts without the need of adversarial training, writer recognition, or text recognition.
We gauge system performance with the Fr\'{e}chet Inception Distance, writer recognition accuracy, and writer retrieval.
We show that the proposed model produces samples that are aesthetically pleasing, help boosting text recognition performance, and get similar writer retrieval score as real data.
Code is available at: \url{https://github.com/koninik/WordStylist}.

%

%To tackle this issue, we generate a synthetic dataset of 1M word images of 10 different fonts and their corresponding transcriptions for Text-to-Text-Content-Image generation. 
%We propose a method that combines \acrshort{ddpm} with \acrshort{gan}s and present the FID score for IAM database on word-level.
%We compare the generation of images using the pre-trained model and training the model from scratch on standard DIAR datasets.    

\keywords{Diffusion Models \and Synthetic Image Generation \and Text Content Generation \and Handwriting Generation \and Data Augmentation \and Handwriting Text Recognition}
\end{abstract}