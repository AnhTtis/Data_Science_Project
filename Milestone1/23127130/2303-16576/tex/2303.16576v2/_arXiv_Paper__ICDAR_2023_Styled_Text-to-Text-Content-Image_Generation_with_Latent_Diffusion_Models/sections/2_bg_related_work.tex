\section{Related Work}
\label{sec:bg_related_work}

%\subsection{\acrfull{gan}}




%\subsection{Text-to-Text-Content-Image Synthesis}

\textbf{Text-to-Text-Content-Image synthesis} refers to the task of generating an image that depicts a specific text, whether it is on the character-, word-, sentence-, or page-level, given that text as the input condition.
%A field directly related to this task is Document Image Analysis and Recognition, notably one of the suffering domains considering the limitation of annotated data, compared to natural images~\cite{5206848},~\cite{Lin2014MicrosoftCC}.
A field directly related to this task is Document Image Analysis and Recognition, notably one of the resource-constrained domains with respect to the availability of annotated data, at least compared to the current state in natural image-related tasks~\cite{5206848,Lin2014MicrosoftCC}.

Most existing works focus on conditioning on a string prompt and a writer style to generate images of realistic handwritten text using GAN-based approaches.
GANwriting~\cite{kang2020ganwriting} creates realistic handwritten word images conditioned on text and writer style by guiding the generator.
The method is able to produce out-of-vocabulary words.
The authors extend this work in~\cite{kang2021content}, generating realistic handwritten text-lines.
SmartPatch~\cite{mattick2021smartpatch} fixes artifact issues that GANwriting faces by deploying a patch discriminator loss.
ScrabbleGAN~\cite{Fogel2020ScrabbleGANSV} uses a semi-supervised method to generate long handwritten sentences of different style and content.
A Transformer-based method is presented in~\cite{Bhunia_2021_ICCV}, using a typical Transformer Encoder-Decoder architecture that takes as inputs style features of handwritten sentence images extracted by a CNN encoder and a query text in the decoding part.
The model is trained with a four-part loss function, including an adversarial loss, a text recognition loss, a cycle loss, and a reconstruction loss.

%~\cite{Nikolaidou2022ASO}, making the use of generative models to augment datasets inevitable.
Related to Historical Document Analysis~\cite{lombardi2020deep,Nikolaidou2022ASO}, the work presented in~\cite{8893115} initially generates modern documents using \LaTeX\ and then attempts to convert them into a historical style with the use of CycleGAN~\cite{zhu2017unpaired}.
%As the generation of a whole page seems to be a quite challenging task, the results they present are more convincing on crops of images.
The work is further extended in~\cite{vogtlin2021generating}, by adding text recognition to the framework and the loss function, which gives better readable text in the image synthesis.
