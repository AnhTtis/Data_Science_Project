\section{Experiments}
We evaluated the effectiveness of NLOS-NeuS on publicly available NLOS datasets.
We compared it with the NeTF \cite{Shen2021} and directional LCT (DLCT) \cite{Young2020}, which is a state-of-the-art surface-reconstruction method for NLOS scenes.
Note that we retrained the NeTF with the author's code.

\begin{figure*}[tb]
\centering
\includegraphics[width=1.\textwidth]{figure/bunny_result.pdf}
\caption{Results from NeTF \cite{Shen2021} and NLOS-NeuS on synthetic bunny scene. (a) Rendered directional albedo, (b) depth reconstruction, and (c) surface-normals reconstruction. Neural implicit surface representation achieved geometrically consistent reconstruction.
}
\label{fig:bunny_result}
\end{figure*}

\begin{figure}[tb]
\centering
\includegraphics[width=0.48\textwidth]{figure/bunny_mesh.pdf}
\caption{Surface reconstruction of bunny. (a) Ground-truth mesh, (b) mesh from NeTF \cite{Shen2021}, (c) mesh from DLCT \cite{Young2020}, and (d) mesh from NLOS-NeuS.
}
\label{fig:bunny_mesh}
\end{figure}

\begin{figure*}[tb]
\centering
\includegraphics[width=0.9\textwidth]{figure/znlos_result.pdf}
\caption{Results on Lucy and Indonesian with  (b) NeTF \cite{Shen2021} and (c) NLOS-NeuS. Results contain directional albedos and reconstructed surface. Note that each object is located on floor and measured transient is highly affected by reflected light from floor. }
\label{fig:znlos_result}
\end{figure*}

\begin{figure*}[tb]
\centering
\includegraphics[width=0.95\textwidth]{figure/fk_result.pdf}
\caption{Results of surface reconstruction on real dataset with (a) NeTF \cite{Shen2021}, (b) DLCT \cite{Young2020}, and (c) NLOS-NeuS.
}
\label{fig:fk_mesh}
\end{figure*}

\begin{figure*}[tb]
\centering
\includegraphics[width=0.9\textwidth]{figure/ablation_loss.pdf}
\caption{Ablation study of loss functions for learning zero level-set surface. By using both  $\mathcal{L}_z$ and $\mathcal{L}_{en}$, MLP can correctly learn zero level-set surface. We also show effectiveness of $\mathcal{L}_f$, which improves overall accuracy of reconstructed geometry.}
\label{fig:ablation_loss}
\end{figure*}

\begin{figure*}[tb]
\centering
\includegraphics[width=0.9\textwidth]{figure/limitation.pdf}
\caption{Challenging scenes for SDF. (a) This scene consists of two planes, one of which is partially occluded. SDF is not suitable for such non-closed surface. (b) This scene consists of thin structures, which are also difficult for SDF to correctly represent geometry.}
\label{fig:limitation}
\end{figure*}

\subsection{Implementation}

\paragraph{Network architecture} 
We use the same networks with that of NeuS \cite{Wang2021neus} with geometric initialization \cite{Atzmon2020} for $d$ and $\rho$.
The inputs of the networks are a scene position and direction to the relay wall with positional encoding \cite{Mildenhall2020}.
Differing from NeuS, we do not use a surface normal for the input of $\rho$ due to heavy computational cost.
For the background network, we use a three-layers MLP with positional encoding for both position and time.

\paragraph{Surface reconstruction}
After training NLOS-NeuS, we use the sphere tracing algorithm \cite{Hart1996} to extract a point cloud instead of using the marching cubes algorithm \cite{Lorensen1987} because an optimized SDF is not correctly closed due to the NLOS setup.
Note that we first create an object mask with estimated directional albedo then apply the sphere tracing algorithm to only the object region.
After extracting the point cloud with this algorithm, we can obtain a surface normal at each point by evaluating the gradient of $d$.
We then use the Poisson surface reconstruction \cite{Kazhdan2013} to obtain the object surface.

\paragraph{Dataset}
We use two datasets preprocessed in the NeTF \cite{Shen2021}.
The first one is the ZNLOS dataset \cite{Galindo19}, which was synthetically created with the transient renderer \cite{Jarabo2014}.
The other one is the f-k dataset \cite{Lindell2019}, which is a real capture using gated SPADs avoiding strong direct reflection from a relay wall.
The temporal resolution of the SPAD system is approximately 70 pico seconds.

\begin{table}[tb]
\centering
\caption{Quantitative comparison of NLOS-NeuS with NeTF \cite{Shen2021} and DLCT \cite{Young2020} on bunny scene. We computed end-point-error for surface normals. Errors dramatically reduced with NLOS-NeuS compared with NeTF, and NLOS-NeuS is also comparable with DLCT.}
\label{tab:quantitative_comparison}
  \begin{tabular}{ccccc} \toprule
    & \multicolumn{2}{c}{Depth [cm]} & \multicolumn{2}{c}{Normal [cm]} \\
    & RMSE & MAE & RMSE & MAE \\ \midrule
    NeTF \cite{Shen2021} & 8.26 & 3.67 & 0.81 & 0.63 \\
    DLCT \cite{Young2020} & 5.27 & {\bf 1.59} & 0.40 & {\bf 0.30} \\
    NLOS-NeuS & {\bf 4.63} & 1.84 & {\bf 0.39} & {\bf 0.30} \\ \bottomrule
  \end{tabular}
\end{table}

\subsection{Results on synthetic data}
Figure \ref{fig:bunny_result} shows the comparison of the NeTF and NLOS-NeuS on the synthetic bunny scene.
Figure \ref{fig:bunny_result}(a) visualizes the rendered directional albedos with the NeTF and NLOS-NeuS.
The directional albedo of the NeTF was simply extracted as the highest $\sigma \rho$ on a ray from the relay wall.
The directional albedo of NLOS-NeuS was generated with volume rendering.
In the supplementary material, we
present our directional albedos rendered from different views, which is similar to novel-view synthesis with the NeRF \cite{Mildenhall2020}.
Figure \ref{fig:bunny_result}(b) shows the results of depth reconstruction.
Note that the results are masked with the ground-truth depth map.
The neural implicit surface representation with NLOS-NeuS dramatically improved the accuracy of the depth reconstruction.
We also show the reconstructed surface normals in (c), where the NeTF normal is computed as the normalized gradient of the density network, demonstrating the geometrically consistent reconstruction of NLOS-NeuS.
Table \ref{tab:quantitative_comparison} shows the quantitative comparison with the NeTF and DLCT \cite{Young2020} on depth and surface normals.
The errors dramatically reduced with NLOS-NeuS compared with the NeTF, and NLOS-NeuS is also comparable with the DLCT, which is the state-of-the-art surface reconstruction in NLOS scenes.

Figure \ref{fig:bunny_mesh} shows the qualitative comparison of reconstructed meshes with the NeTF, DLCT and NLOS-NeuS.
Due to the lack of geometric representation, the NeTF mesh contains large errors.
On the other hand, NLOS-NeuS enables high quality 3D surface reconstruction.
Although the result with the DLCT is comparable with that with NLOS-NeuS on this synthetic data, its discretized representation is limited in real data, as shown in Fig. \ref{fig:nlos_setup}(c).

Figure \ref{fig:znlos_result} summarize the comparison with the NeTF for the Lucy and Indonesian scenes.
Note that each object is located on a floor and the measured transient is highly affected by the reflected light from the floor.
In the supplementary material, we present the learned transients of the floor reflection.
We present the directional albedos and meshes of both methods.
NLOS-NeuS can reconstruct the complicated structure in the Lucy.
Although there are some missing parts in our results of the Indonesian, NLOS-NeuS can obtain geometrically plausible results compared with the NeTF.

\subsection{Results on real capture}
Figure \ref{fig:fk_mesh} shows the results with the real data captured using a SPAD.
We present the directional albedos and reconstructed meshes for both scenes.
The NeTF fails to reconstruct the correct geometry in these scenes.
DLCT can reconstruct the object structures, while the quality of the reconstructed geometry is limited due to its discrete representation.
NLOS-NeuS, on the other hand, can reconstruct the fine details and smooth surface compared with DLCT because of its continuous representation of the neural implicit surface.
These results indicate the effectiveness of NLOS-NeuS for real scenes.

\subsection{Ablation study on loss functions}
We introduce several losses for training an SDF.
Figure \ref{fig:ablation_loss} shows the comparison between the several patterns of the loss functions on the bunny.
As discussed in Sec. \ref{sec:nonzero_levelset}, the simple extension of the NeTF with the neural implicit surface incorrectly estimates non-zero level-set surfaces.
When we train the MLP without both $\mathcal{L}_z$ and $\mathcal{L}_{en}$ (a), most parts of the shape are missing due to such non-zero level-set surfaces.
When we train the MLP only with $\mathcal{L}_z$ (b) or $\mathcal{L}_{en}$ (c), the results dramatically improve, while the shape near the object boundary cannot be reconstructed.
By using both loss functions (e), we can correctly estimate the shape near the object boundary.
We also show the effectiveness of $\mathcal{L}_f$, which improves the overall accuracy of the reconstructed geometry (d,e).

\subsection{Limitations}
We finally discuss the limitations due to our geometric representation.
Figure \ref{fig:limitation} shows an example of a challenging scene.
In Fig. \ref{fig:limitation}(a), two planes are located and one is partially occluded. 
The figure also shows learned SDF, where the black lines indicate the positions of the ground-truth planes.
Although the zero level-set is extracted on the front plane, the SDF around the back plane is not correct.
Such a non-closed surface is difficult for an SDF to represent the geometry.
Figure \ref{fig:limitation}(b) is another example of a challenging scene for an SDF, where the target object consists of thin structures.
One approach for these scenes is to use more flexible geometric representation such as unsigned distance field \cite{Chibane2020udf}.


