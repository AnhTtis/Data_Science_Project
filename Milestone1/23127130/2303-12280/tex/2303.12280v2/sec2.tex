\section{Related work}
\paragraph{Non-line-of-sight imaging}
NLOS imaging is attracting much more attention with the development of computational imaging devices \cite{Kirmani2011,Velten2012}.
While the typical inputs of NLOS-imaging methods are transients on a diffuse relay wall, output scene representations differ depending on applications and methodology.

A voxel grid is one of the most commonly used representations \cite{Arellano2017,Lindell2019,Liu2019,OToole2018,Velten2012}.
For example, with back-projection-based methods \cite{Arellano2017,LaManna2019,Velten2012}, the measured intensity is back-projected to each voxel to estimate the probabilities of object existence.
Oâ€™Toole et al. \cite{OToole2018} proposed the light-corn transform (LCT), with which a closed-form solution is derived under volumetric albedo representation.
Lindell et al. \cite{Lindell2019} formulated the NLOS problem as f-k migration in seismology, where electromagnetic radiation at each scene-grid point is recovered with the Fast Fourier Transform.
However, such discrete representations are limited for representing scenes with fine details due to memory cost.
Shen et al. \cite{Shen2021} proposed the NeTF, with which volumetric density and reflectance are implicitly modeled by a continuous MLP with arbitrary resolution.
Mu et al. \cite{Mu2022} extended the NeTF to feedforward inference, which enables fast NLOS imaging with a non-confocal setup.

Although these methods model object existence or volumetric albedo in NLOS scenes, accurate 3D reconstruction requires explicit geometric representations,
e.g., some methods incorporate surface normals into voxel representations \cite{Young2020}, directly estimate a point cloud \cite{Xin2019}, or optimize object surface with a differentiable renderer \cite{Iseringhausen2020,Plack2023,Tsai2019}.
Our method extends continuous volumetric representation \cite{Shen2021} with an SDF for surface reconstruction with arbitrary resolution.

\paragraph{Neural implicit surface}
Park et al. \cite{Park2019} and Mescheder et al. \cite{Mescheder2019} respectively proposed the DeepSDF and Occupancy Networks, with which a scene is represented using a SDF and occupancy field parameterized with an MLP. 
In contrast to the traditional discretized representations such as voxels, these implicit representations are memory-efficient, and an object surface can be extracted as level-set at any resolution, which enables dense surface reconstruction from a coarse voxel grid or sparse point cloud with feedforward inference \cite{Chibane2020,Peng2020} or test-time optimization \cite{Atzmon2020,Chabra2020,Ma2022,Williams2022}.

Other research directions include neural implicit surfaces from multi-view 2D images, where the implicit function is optimized by minimizing reconstruction loss between the input and rendered images.
The key to optimization is how to connect the implicit function and surface rendering in a differentiable manner \cite{Niemeyer2020,Yariv2020}.
In contrast to surface-rendering-based methods, Yariv et al. \cite{Yariv2021} and Wang et al. \cite{Wang2021neus} respectively proposed VolSDF and NeuS, with which images are rendered with volume rendering similar to the NeRF \cite{Mildenhall2020}.
Differing from the surface-rendering approach, 
images are rendered with multiple points on a ray with $\alpha$-compositions, which enables back-propagation from not only the surface points but also points far from the surface.
NLOS-NeuS uses a neural implicit surface with volume rendering for NLOS surface reconstruction.