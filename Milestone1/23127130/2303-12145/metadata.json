{
    "arxiv_id": "2303.12145",
    "paper_title": "Efficient Feature Distillation for Zero-shot Detection",
    "authors": [
        "Zhuoming Liu",
        "Xuefeng Hu",
        "Ram Nevatia"
    ],
    "submission_date": "2023-03-21",
    "revised_dates": [
        "2023-06-27"
    ],
    "latest_version": 3,
    "categories": [
        "cs.CV"
    ],
    "abstract": "The large-scale vision-language models (e.g., CLIP) are leveraged by different methods to detect unseen objects. However, most of these works require additional captions or images for training, which is not feasible in the context of zero-shot detection. In contrast, the distillation-based method is an extra-data-free method, but it has its limitations. Specifically, existing work creates distillation regions that are biased to the base categories, which limits the distillation of novel category information and harms the distillation efficiency. Furthermore, directly using the raw feature from CLIP for distillation neglects the domain gap between the training data of CLIP and the detection datasets, which makes it difficult to learn the mapping from the image region to the vision-language feature space - an essential component for detecting unseen objects. As a result, existing distillation-based methods require an excessively long training schedule. To solve these problems, we propose Efficient feature distillation for Zero-Shot Detection (EZSD). Firstly, EZSD adapts the CLIP's feature space to the target detection domain by re-normalizing CLIP to bridge the domain gap; Secondly, EZSD uses CLIP to generate distillation proposals with potential novel instances, to avoid the distillation being overly biased to the base categories. Finally, EZSD takes advantage of semantic meaning for regression to further improve the model performance. As a result, EZSD achieves state-of-the-art performance in the COCO zero-shot benchmark with a much shorter training schedule and outperforms previous work by 4% in LVIS overall setting with 1/10 training time.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.12145v1",
        "http://arxiv.org/pdf/2303.12145v2",
        "http://arxiv.org/pdf/2303.12145v3"
    ],
    "publication_venue": null
}