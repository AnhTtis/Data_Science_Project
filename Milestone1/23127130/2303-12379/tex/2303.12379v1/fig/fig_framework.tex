\begin{figure*}[t]
    \begin{center}
        \includegraphics[width=1.0\linewidth]{src/framework_0309.pdf}
    \end{center}
    \caption{\textbf{Overview of the proposed \frameworkname~framework} for video-music matching. Given a pair of video and music, the video encoder is applied to extract video features and the music encoder is adopted to collect music features(Sec.~\ref{m_e}). There are two parts of the music encoder, and we concatenate their output as music features. In the training step, we calculate the \faceloss{} for the video and music separately from video features and music features by utilizing the same shared head (Sec.~\ref{loss_class}). Hence, calculate the similarity loss between video features and music features(Sec.~\ref{loss_sim}). In the testing step (the right side of the figure), we treat the task as a classification problem on seen music set and calculate the cosine similarity between video and music on unseen music set to match video with appropriate music (Sec.~\ref{matching}).}
    \label{fig:framework}
\end{figure*}