\section{Theoretical Characterization}
\label{sec:th_considerations}


Since the problem addressed by this paper is undecidable, the success of any algorithmic approach to solving the problem must necessarily depend on heuristics. Still, in this section, we contribute some results that provide insight into when one can reasonably expect an approach such as the one presented in this paper to succeed. 

Especially, we address a sensitive part of our method---the reduction from an under-constrained system of equations to a well-constrained subsystem (Section \ref{subsec:instantiations}). Indeed, given a system of equations in $m$ variables and $n$ equations ($m>n$), %and a candidate approximate solution $p$, 
in order to obtain a well-constrained system, we need to either instantiate $k:= m-n$ variables, or, alternatively, to add $k$ equations. The contribution of this section is threefold:
\begin{itemize}
	\item We bound the class of problems solvable through the variable instantiation method, both from below and from above.
	\item We prove that the class of problems solvable through the variable instantiation method is a (possibly non-strict) subset of the class of problems solvable through the equation adding method.
	\item We show that for bounded systems of equations and inequalities a certain strategy in the certificate search method presented in Section~\ref{sec:method} will always succeed in determining satisfiability under certain robustness assumptions.%
\end{itemize}

For ease of discussion, first, we will 	consider only systems of equations (i.e., without inequalities). It is however straightforward to see that including inequalities does not change any of the results. 
We will then treat the general case of conjunction and disjunctions of systems of equations and inequalities 	when discussing the last contribution. 
%



We will start by introducing some notation for the relevant classes of problems. For now, we will introduce these classes only informally, and define them precisely, later. We will denote by $\FRobI$ and $\FRobLEq$ the problem classes, for which the two methods (instantiation and adding equations, respectively) result in a robust system. More precisely, we will denote by  $\FRobI$ 
the class of \Cone functions $F:B\subseteq \mathbb{R}^{n+k}\to \mathbb{R}^{n}$ 
for which there exists a point $p\in \mathbb{R}^{n+k}$ such that the instantiation of $k$ variables to the corresponding $k$ values of $p$ leads to a robust system in $\mathbb{R}^n\rightarrow\mathbb{R}^n$ (we will call such functions \emph{robust under instantiation}), and we will denote by $\FRobLEq$ the class of \Cone functions $F:B\subseteq \mathbb{R}^{n+k}\to \mathbb{R}^{n}$  for which adding $k$ linear equations leads to a robust system in  $\mathbb{R}^{n+k}\rightarrow\mathbb{R}^{n+k}$.

First, we will bound $\FRobI$ from above by the class $\FRob$
of \Cone functions $F:B\subseteq \mathbb{R}^{n+k}\to \mathbb{R}^{n}$ that have 
 a robust solution, and from below by
the class $\FReg$ of \Cone functions 
$F:B\subseteq \mathbb{R}^{n+k}\to \mathbb{R}^{n}$ 
that have a solution that is regular in the sense of topology.

Based on this, we will prove the following:
\begin{theorem}
	\label{thm:FRobIbounds}
	%$\FReg \mysubsetneq  \FRobI = \FRobLEq \mysubsetneq \FRob $
	$\FReg \mysubsetneq  \FRobI  \mysubsetneq \FRob $ 
\end{theorem}

As can be seen from the disequalities, the lower and upper bounds are strict, here.

% This theorem effectively provides strict lower and upper bounds to the class of problems that our method is able to solve. The existence of stricter bounds is an open problem. 

Secondly, we prove that every problem that can be solved via variable instantiation can be solved via adding equation, i.e. we have the following theorem:

\begin{theorem}
\label{thm:instVersusEq}      
	$  \FRobI  \subseteq \FRobLEq $ 
\end{theorem}

Note that the inclusion, in this case, is not strict. Indeed, we conjecture that the equality holds, but will leave the proof to future work.

Finally, we present a variation of our method that is guaranteed to always terminate on problems in $\FRobI$, and that will serve to prove the following theorem:

\begin{theorem}
	\label{thm:quasiquasidecidability}
	There exists a procedure that, given a bounded system of equations and inequalities $F=0 \wedge G \leq 0$,
	\begin{itemize}
        \item always returns the correct answer ``satisfiable'' or ``unsatisfiable'', if it terminates, 
        \item always terminates successfully when $F=0 \wedge G \leq 0$ is robustly satisfiable  and  $F\in \FRobI$,
        \item always terminates successfully when $F=0 \wedge G \leq 0$ is robustly unsatisfiable.
	\end{itemize}
\end{theorem}

This theorem can be seen as an extension of an earlier result~\cite{Franek:12} showing
that the class of bounded systems of equations and inequalities in $m$ variables and $n$ equations, with $n\geq m$ or $n=0$, is quasi-decidable in the sense that there exists a procedure that always terminates on robust instances, and that never returns a wrong answer.
 
Our contribution is to cover the case of under-constrained systems (i.e. when $n < m$), to a certain extent. 
Indeed, it is not possible to simply remove the restriction on the number of equations versus the number of variables~\cite[Theorem 2]{Franek:12}. 
We overcome this by guaranteeing termination in the satisfiable case only for problems for which the system of equations is robust under instantiation (which is a stricter condition than general robustness). 
In this sense, our procedure is not a quasi-decision procedure, 
as it does not terminate for \emph{all} robust instances, 
but it will cover a meaningful sub-class.%(known problems that are robust but not robust under instantiation derive more from mathematical counter-examples rather than from real-world verification cases)
%\footnote{We could say that our procedure is \emph{quasi} a quasi-decidability procedure. }. 

\

% More compactly, we have:

% \begin{itemize}
% 	\item $\mathcal{F}_{RobI} \defas \{F:B\subseteq \mathbb{R}^{n+k}\to \mathbb{R}^{n} | \text{ $F$ has a solution robust under instantiation} \}$
% 	\item $\mathcal{F}_{Rob} \defas \{F:B\subseteq \mathbb{R}^{n+k}\to \mathbb{R}^{n} | \text{ $F$ has a robust solution} \}$
% 	\item $\mathcal{F}_{Reg} \defas \{F:B\subseteq \mathbb{R}^{n+k}\to \mathbb{R}^{n} | \text{ $F$ has a regular solution} \}$
% 	\item $\mathcal{F}_{RobLEq} \defas \{F:B\subseteq \mathbb{R}^{n+k}\to \mathbb{R}^{n} | \text{there exist $k$ linear eq. that added to $F$  yield a  system with a robust solution} \}$
% \end{itemize}

% First, we will show that for every system that has a regular solution, there exists a candidate approximate solution and a variable instantiation that yield a robust sub-system ($\FReg \subseteq \FRobI$). Then, we will show that the variable instantiation method is not limited to succeed only on systems having a regular solution, i.e. we have a strict lower bound ($\FReg \mysubsetneq \FRobI$). We also provide a strict upper bound: indeed, the variable instantiation method is able to solve only systems that admit at least one robust solution ($\FRobI \subseteq \FRob$), and there exist counter-examples of systems that have a robust solution but for which no variable instantiation yields a robust sub-system (i.e. $\FRob \not\subset \FRobI$).  Finally, we will show that the class of system of equations that can be solved via variable instantiation  coincides with the class of system of equations that can be solved via equation adding ($\FRobI = \FRobLEq$).




% \

The section is organized as follows. In Section \ref{subsec:BackgroundRobustness}, we formalize
the problem classes mentioned by the two theorems and provide some further 
definitions and properties that will be useful in the following subsections.
%introduce some definitions regarding  robustness and robust solutions. 
In Section \ref{subsec:GuaranteesRegularity},  we will prove the lower bound $\FReg \subseteq \FRobI$ (Lemma \ref{thm:FRegsubsetFRob}) and that ${\FRobI \not\subseteq \FReg}$ (Lemma~\ref{lemma:FRobInotsubsetFReg}). In Section~\ref{subsec:RobPreservationAfterVarInst} we will prove the upper bound $\FRob \not\subseteq \FRobI$ (Lemma~\ref{lemma:FRobnotsubsetFRobI}) and that $\FRobI \subseteq \FRob$ (Lemma~\ref{lemma:FRobIimpliesFRob}). Then, in Section \ref{subsec:InstVarVsAddEq}, we prove that $\FRobI \subseteq \FRobLEq$.
Finally, in Section~\ref{subsec:termination},  we prove Theorem \ref{thm:quasiquasidecidability}.
%First, we prove that a system obtained by instantiating $\{x_i \mapsto p_i \}$ is equi-robustly sat to the system obtained by adding equations $\{x_i - p_i = 0\}$ (Lemma~\ref{lemma:instVarVsAddEq}, one side still not proved), which implies that $\FRobI \subseteq \FRobLEq$.\\
%Then we want to prove that $\FRobLEq \subseteq \FRobI$. This proof is not concluded yet.






\subsection{Background on robustness and regularity}
\label{subsec:BackgroundRobustness}




In this section, we first give a formal definition of robustness, and then proceed to provide all the definitions needed to formally define our four classes of interest. 
We will also present some results regarding these definitions that will be used for proving the main theorem.

\

\emph{Notation}: Given a multivalued function $F:\Omega \subseteq \mathbb{R}^m\to \mathbb{R}^n$, we will denote with $F_1, \dots, F_n: \Omega \subseteq \mathbb{R}^m\to \mathbb{R}$ the univalued functions such that $F= (F_1, \dots, F_n)$. 
With a slight abuse of terminology, we will say that a function $F:\Omega \subseteq \mathbb{R}^m\to \mathbb{R}^n$ is \emph{satisfiable} %in $\Omega'\subseteq \Omega$ 
if and only if it has a zero.% in $\Omega$.

%\

\subsubsection{Robustness.}
First, we provide a formal definition of the concept of robustness. Since our main focus are systems of equations, we will provide a definition of robustness only in terms of multivalued functions. This concept, however, can be generalized and formalized for general formulas. The definition that we give here is just a special case of the more general definition presented in  \cite{Franek:12}. In fact, a multivalued function $F$ is robustly satisfiable if and only if the logical formula representing the equation $F=0$ is. We will make use of the general definition of robustness only in the last section, when discussing Theorem \ref{thm:quasiquasidecidability}.

We first introduce the concept of distance between functions.


\begin{definition}[Distance between two functions]
	Let $F:\Omega_1 \subseteq \mathbb{R}^m\to \mathbb{R}^n$  and $F':\Omega_2 \subseteq \mathbb{R}^m\to \mathbb{R}^n$ be two multivalued continuous functions. 	Given $\Omega \subseteq \mathbb{R}^m$ such that $\Omega \subseteq \Omega_1$ and $\Omega \subseteq \Omega_2$,
	we define the distance between $F$ and $F'$ in $\Omega$ as
	$$\dist_{\Omega}(F,F') \defas \underset{k\in [1,n]}{\max}( \|F_k-F'_k\|_{\Omega} )$$	
	where $\|F_k-F'_k\|_{\Omega} \defas \sup \{|F_k({x})-F'_k({x})| : {x} \in {\Omega}\}$.
\end{definition}

When $\Omega$ is clear from the context, with an abuse of notation we will 
drop the subscript and just write $\dist(F,F')$. 
We say that $F'$ is an \emph{$\epsilon$-small perturbation} of $F$ if $\dist(F,F')< \epsilon$.


\begin{definition}[Robustness of a function]
	Given $\alpha\in \mathbb{R}_{> 0}$, we say that a continuous function $F:\Omega\subseteq \mathbb{R}^m\to \mathbb{R}^n$ is $\alpha$-robust iff for every continuous function $F'$ s.t. $\dist_{\Omega}(F,F') < \alpha$, either both $F$ and $F'$ have a zero in $\Omega$, or none of them has.
	A function $F$ is\textbf{ robust} iff there exists $\alpha\in \mathbb{R}_{> 0}$ s.t. $F$ is $\alpha$-robust in $\Omega'$.
	
\end{definition}

For $\Omega'\subseteq \Omega$, we say that $F$ is robust in $\Omega'$ iff $F_{|\Omega'}:\Omega'\subseteq \mathbb{R}^m\to \mathbb{R}^n$ is robust.



\begin{definition}[Robustly satisfiable function]
	\label{def:robustlysat}
	A function $F$ is \textbf{robustly satisfiable} iff
	% it is satisfiable and $\exists \delta>0$ s.t. $\forall \phi'$ with $d(\phi, \phi')<\delta$, $\phi'$ is satisfiable.
	it is robust and satisfiable.	
\end{definition}



\subsubsection{Robust solutions ($\FRob$).}
Robust satisfiability of a function---as defined by Definition~\ref{def:robustlysat}---does not depend on any specific solution. Indeed, it is the entirety of the solution set that accounts for the robust satisfiability of the function.  However, it will be useful to talk about the robustness of a function around a specific solution, which also formalizes the definition of the class $\FRob$.
% (i.e., \emph{local} robustness).

\

	\begin{definition}[Robust solution]
		Given a function $F:\mathbb{R}^m\to \mathbb{R}^n$, we say that a point $p\in \mathbb{R}^m$ is a \textbf{robust solution} iff
		\begin{enumerate}
			\item $F(p)=0$, and
			\item for all $\epsilon>0$ there exists a $\delta > 0$ such that for all $F'$ with
			$\dist(F,F')<\delta$, there exists $p'$ such that 
			$F'(p')=0$ 
			%robustly satisfies $\phi'$ 
			and $\dist(p,p')<\epsilon$.
		\end{enumerate}
	\end{definition}
	
	It follows by the definition of robust solution that if $F$ has a robust solution, then $F$ is robustly sat. 
	
Note that the converse, however, is not true in general:

\begin{example}[Robustly sat formula with no robust solution]
	Let $F: \mathbb{R}\to \mathbb{R}$ defined by 
	$$F:x\mapsto
	\begin{cases}
		-x^2 & \text{ if } x<0 \\
		0        & \text{ if } 0 \leq x\leq 1 \\
		(x-1)^2        & \text{ if } 1<x\\
	\end{cases} $$
This function is robustly sat, since every $F'$ obtained by a small perturbation of $F$ has still a solution either near $0$ or near $1$. 
But no point in the solution set of $F$ (i.e. the points in $[0,1]$) is a robust solution.
Indeed, $0$ is not a robust solution, since, given $\epsilon = 0.1$, for every $\delta>0$, the function $F'_\delta$ defined by $F'_\delta(x)\mapsto F(x)-\delta$; 
for $0$ has no solution in the open ball $\openball{B}{0.1}(0)$. Symmetrically, for $1$ we can take $F''_\delta$ defined by $F''_\delta(x)\mapsto F(x)+\delta$. 
And for every point $p\in(0, 1)$, we can take $\epsilon=\min(\dist(p,0), \dist(p,1))$, and for every $\delta$ either $F'_\delta$ or $F''_\delta$.

\end{example}







\ 

A partial converse is the following result, which states that if a function is locally robustly satisfiable around a solution, the solution is robust.
\begin{proposition}
	\label{prop:locallyRobustlysat}
	If $p$ is a solution for $F$, and for every $\epsilon > 0$ there exists a neighborhood  $\Omega_\epsilon \subseteq \openball{B}{\epsilon}(p)$ of $p$ such that       
	$F$ is robustly sat in $\Omega_\epsilon$, then $p$ is a robust solution for $F$.
\end{proposition}

\begin{proof}
	For every $\epsilon>0$, $F$ is robustly sat in $\Omega_\epsilon$ if and only if  (by replacing the definition of robustly satisfiable function) $\forall \epsilon$, $\exists \delta$ s.t. $\forall F'$ with $\dist(F,F')<\delta$, $F'$ has a solution in $\Omega_\epsilon$.
	$F'$ has a solution in $\Omega_\epsilon$ if and only if there exists $p'$ s.t.  $F'(p')=0$ and $p'\in \Omega_\epsilon$ (i.e. $\dist(p, p')<\epsilon$).
	So we obtain: $\forall \epsilon$, $\exists \delta$ s.t. $\forall F'$ with $\dist(F,F')<\delta$, $\exists p'$ s.t. $p'$ is a solution for  $F'$ and $\dist(p, p')<\epsilon$ which is the definition of robust solution for $p$.
\end{proof}
	

%\

\subsubsection{Robust under instantiation ($\FRobI$)}

%Since in our method, given a system of equations $F=0$, with $F:\mathbb{R}^{n+k}\to \mathbb{R}^n$, we instantiate $k$ variables, the following definitions will be useful.
%Now we introduce a few definitions in order to provide a formal definition of $\FRobI$. 

In general, even if a solution is robust, after the instantiation of some variables, the projection of the solution may not be a robust solution for the function obtained after variable instantiation.

Now we provide some notation and some definitions regarding variable instantiation. We start by formalizing the fact that $k$ coordinates of a point have a finite representation in the form of a dyadic rational number.
\begin{definition}[$k$-finite point]
	A point ${p=(p_1,\cdots, p_m)\in \mathbb{R}^{m}}$ 
	is a \textbf{\kfinite{k}} 
	(with $0\leq k\leq m$)
	if for at least $k$ coordinates $i\in\{1,\dots,m\}$
 there exist integers $n_i$ and $r_i$ such that $p_i= n_i 2^{-{r_i}}$.
      \end{definition}
Here, we use base $2$ just for convenience. Any other base would work equally well for our purposes.    

%\begin{definition}[Function instantiation via an assignment] Let ${F: B\subseteq \mathbb{R}^{n+k}\to \mathbb{R}^n}$ be a smooth function and $p=(p_1, \dots, p_{n+k})\in \mathbb{R}^{n+k}$ a \kfinite{k} (with $I$ denoting the set of the $k$ indices finitely representable)
%	Then, given the partial assignment $\nu_I \defas \{x_i \mapsto p_i\}_{i \in I}$,
%	we define the \mbox{\textbf{instantiation of $F$ via $\nu_I$}} as the function
%	$F_{|\nu_I}: B_{|\mathbb{R}^n} \subseteq \mathbb{R}^n\to \mathbb{R}^n$ 
%	obtained by
%	replacing $x_i$ with $p_i$ for every $i\in I$.
	%
%end{definition}


\begin{definition}[Robust instantiation of a point]
	Let ${F: B\subseteq \mathbb{R}^{n+k}\to \mathbb{R}^n}$ be a \Cone function  and $p=(p_1, \dots, p_{n+k})\in \mathbb{R}^{n+k}$ a \kfinite{k} (with $I$ denoting a set of  $k$ finitely representable indices).
	%and  ${I\subseteq [1,n+k]}$ a set of indices,  with $|I|=k$ and $p_i$ finitely representable for every $i\in I$.
	
	Given the partial assignment $\nu_I \defas \{x_i \mapsto p_i\}_{i \in I}$,
	we define the {\emph{instantiation of $F$ via $\nu_I$}} as the function
	$F_{|\nu_I}: B_{|\mathbb{R}^n} \subseteq \mathbb{R}^n\to \mathbb{R}^n$ 
%	obtained by	replacing $x_i$ with $p_i$ for every $i\in I$.
        such that for every $(x_1,\dots,x_n)\in\mathbb{R}^n$,
        $F_{|\nu_I}(x_1,\dots,x_n)= F(y_1,\dots,y_{n+k})$, where 
                \[ \text{for } i\in \{1,\dots, n+k\},\:
          y_i=
          \left\{\begin{array}{l}
            p_i, \text{if } i\in I,\\
            x_i, \text{if } i\not\in I
          \end{array}\right.. \]

        
	We say that the partial assignment $\nu_I$ 
	is a \textbf{robust instantiation of $p$} if and only if the point $p_{|\nu_I} = (p_i)_{i\not\in I} \in \mathbb{R}^n$  
	 is a robust solution for $F_{|\nu_I}$.
      \end{definition}
      If an instantiation is not a robust instantiation, then we say it is a \emph{\mbox{non-robust} instantiation}. Note that assignments are defined as maps to the set of finitely representable values. So if $p$ is not a \kfinite{k}, then it admits no instantiations, and hence no robust instantiations.



For our method to succeed, we only need the existence of a single robust instantiation. 
So we are not interested in solutions that are robust under \emph{all} instantiations, but in solutions that are robust under \emph{at least one}  instantiation.
Finally, we have the following definition (from which the definition of $\FRobI$ follows):


\begin{definition}[Robust under instantiation] Given a continuous function ${F: B\subseteq \mathbb{R}^{n+k}\to \mathbb{R}^n}$ and a point $p$, we say that $p$ is \textbf{\mbox{robust under instantiation}}  if there exists at least one robust instantiation of $p$.
\end{definition}
If no robust instantiation of $p$ exists, then we say that $p$ is \emph{non-robust under instantiations}. If $p$ is not a \kfinite{k}, then, by definition, $p$ is non-robust under instantiations.

\

In the following, for ease of notation and without loss of generality, we will assume that ${I=\{n+1, \dots, n+k\}}$, unless otherwise specified.  
In this case, we will write 
$\nu$ instead of $\nu_I$, and we will denote
$\pn \defas (p_1 ,\dots, p_n)$ for the projection of $p$ to the first $n$ coordinates (i.e. the ones not instantiated by $\nu$), 
and $\pnk$ for the projection of $p$ to the last $k$ coordinates (i.e. the ones not instantiated by $\nu$).



\subsubsection{Robustness after equation adding ($\FRobLEq$).} 
We define $\FRobLEq$ as the set of \Cone functions $F: \mathbb{R}^{n+k}\to \mathbb{R}^{n}$ such that there exists a linear function $L: \mathbb{R}^{n+k}\to \mathbb{R}^k $ such that the function ${F_{leq}: \mathbb{R}^{n+k}\to \mathbb{R}^{n+k}}$, defined by $F_{leq}: x \mapsto (F(x), L(x))$,
has a robust solution.


\subsubsection{Regular solutions ($\FReg$).} We now define the last of our classes of interest. For doing so, we provide a brief background on the notion of regularity from the field of differential topology.
%\myparagraphB{Background on regularity.} 


\begin{definition}[Regular point]
	Let $F: B\subseteq \mathbb{R}^m \to \mathbb{R}^n$ be a \Cone function, with $m-n = k \geq 0$. 
	We say that $p\in B$ is a \textbf{regular point} for $F$ 
	%if and only if ${dF_x:T_x\interior{B}\to T_{F(x)}\mathbb{R}^n }$ is surjective, or, in equivalent, 
	if and only if the Jacobian matrix of $F$ at $x$ has maximal rank.
\end{definition}
If $F(p)=0$ and $p$ is a regular point, we will say that $p$ is a \emph{regular solution} of $F$. 
If $p$ is not a regular point, we say that $p$ is a \emph{critical point}.  
We say that $q\in \mathbb{R}^n$ is a \emph{regular value} if and only if for every $p$ such that $F(p)=q$, $p$ is a regular point.
If $q$ is not a regular value, we say it is a \emph{critical value}.


Regularity is a very meaningful property, as it guarantees the "well-behavior" of the system. In particular, a regular point $p$ satisfies the hypothesis of the Implicit Function Theorem~\cite{Munkres1991AnalysisOM}, that we now recall and that we will use in Section \ref{subsec:GuaranteesRegularity}:


\emph{Implicit Function Theorem}: If  ${F(p_1 , \dots, p_n, p_{n+1}, \dots, p_{n+k}) = 0}$, and the Jacobian matrix of $F$ with respect to the first $n$ coordinates has non-zero determinant in $p$ (i.e. $\det(J_{F, x_{|n}}(p)) \neq 0$), 
then there exists a neighborhood $U\subseteq \mathbb{R}^k$ of $(p_{n+1}, \dots, p_{n+k})$ and a \Cone function $H: U \to \mathbb{R}^n$ such that $H(p_{n+1}, \dots, p_{n+k})=(p_1 , \dots, p_n)$, 
and such that, for all $q\in U$, ${F(H(q), q)=0}$. 
%(Note that, while the Jacobian matrix of $F$ is a $(n \times m)$ rectangular matrix, we are only interested in  the determinant of $J_{F, x_{|n}}$, 
%i.e. the determinant of the left-hand $(n \times n)$ sub-matrix of $J_F$, which depends only on the first $n$ coordinates.) 



%\subsubsection{Relation with topological degree}


%\subsection{Guarantees under assumption of regularity}
\subsection{Regularity and robustness under instantiation}
\label{subsec:GuaranteesRegularity}




In this section, we prove that the existence of a regular solution is a sufficient---but not necessary---criterion for the existence of a solution robust under instantiation.
% candidate approximate solution and of a variable instantiation that leads to a robustly satisfiable sub-system.


%under the assumption of the existence of an algorithm able to find arbitrarily precise finite approximations of a solution, 
%we provide a sufficient condition for the existence 
%of an approximate solution and 
%of a variable instantiation that generates a robust subsystem.


  We prove that, if $F$ has at least one regular solution $q$, then there exists at least one regular solution $p$ such that at least $k$ coordinates of $p$ are finitely representable rational numbers, and such that the subsystem induced from the instantiation of the $k$ corresponding variables is robustly sat. 


%We first give a brief background on the notion of regular points and on the \emph{Implicit Function Theorem}, which will play an important role for proving our statement. We assume that the reader is familiar with some basic concepts of differential analysis and topology.


% differential topology, such as \emph{smooth manifolds} and the related concepts (e.g. \emph{smooth map}, \emph{tangent space}, etc.). The interested reader can find a detailed discussion of these concepts on any differential topology textbook (e.g. \cite{Milnor1965TopologyFT}\cite{Michor}\cite{TuIntroManifolds}). We then present a few Lemmas, that will be used to prove our main statement at the end of the Section. 
 


%If $c$ is a regular value for $F$, then the set $F^{-1}(c)$ is a smooth submanifold of $\mathbb{R}^{m}$ of dimension $k$. 
%This result is known in the literature as the the \emph{Regular Value Theorem} or the \emph{Preimage Theorem} \cite{TuIntroManifolds}. 
%In our case, where $c=0$, this theorem guarantees that the solution space of $F$ is a submanifold of maximum dimension.

%Note that, by the definition of regular value, in order for $0$ to be defined as such, we need every counter-image $p$ of $0$ to be a regular point. 
%But in practice, for our goal, it suffices a weaker condition, that is the existence of a single regular point $p$ such that $F(p)=0$. 
%Indeed, if $p$ is a regular point, then there exists a neighborhood $U$ of $p$ such that every $p'\in U$ is a regular point. 
%So if we take a sub-box $\hat{B}\subseteq U$ of $B$, then $0$ is a regular value for $F_{|\interior{\hat{B}}}$.%, and we can apply the Regular Value Theorem for $F_{|\interior{\hat{B}}}$. 
%In the following, when we write the condition "$p$ is a regular solution for $F$", we imply "$0$ is a regular value for $F$", by the assumption that for a suited domain of $F$, the two conditions are equivalent.
	
	
	%	Thm 2.2.19  \ \ \url{https://people.math.ethz.ch/~salamon/PREPRINTS/diffgeo.pdf} 
	
	%See Lemma 1 on Section 2 of \cite{Milnor1965TopologyFT}
	

%Let $F: \interior{B}\subseteq \mathbb{R}^m \to \mathbb{R}^n$ be a $C^{\infty}$ function with $m-n = k$ $(\neq 0$) that has a robust zero $\mathbf{p}$. Suppose that $\textbf{0}$ is a regular value for $f$ (i.e. for all $\mathbf{p}\in F^{-1}(\mathbf{0})$ the map $d F_x:T_x\interior{B}\to T_0\mathbb{R}^n $ is surjective, i.e. the Jacobian matrix has maximal degree in every point of the zeroset).



%We can use the following two results: 
%\begin{theorem}[Inverse function]
%	\label{thm:inverseFunction}
%	Let $F:\interior{B}\subseteq \mathbb{R}^{n+k}\to \mathbb{R}^n$ be a $C^1$-function. Given $(\mathbf{a}, \mathbf{ b})=(\mathrm{a_1},\cdots, \mathrm{a_n}, \mathrm{b_1}, \cdots, \mathrm{b_k})$ s.t. $F(\mathbf{a},\mathbf{b})=\mathbf{0}$, if Jacobian matrix has max degree in $(\mathbf{a}, \mathbf{ b})$, then there exists an open $U\subseteq \mathbb{R}^k$ with $\mathbf{a}\in U$ s.t. there exists an unique function $H: U\to \mathbb{R}^n$ s.t.  $H(\mathbf{a})=\mathbf{b}$ and for all $\mathbf{x}\in U$ $F(\mathbf{x},H(\mathbf{x}))=0$.
%\end{theorem}

%\begin{theorem}[Regular values]
	%\label{thm:regvalues2}
	%Let $F$ as in the previous theorem. Then the set $F^{-1}(\mathbf{0})$ is a submanifold of $\mathbb{R}^{n+k}$ of %dimension $k$.
%\end{theorem}

 

We first show that any regular solution is also a robust solution (Lemma \ref{lemma:regulImpliesRobust}), which will be useful to prove the main result of this section, Lemma \ref{thm:FRegsubsetFRob}, which implies  $\FReg \subseteq \FRobI$.  Then, we will show that this inclusion is strict by providing a counter-example in the form of a system of equations that has a solution robust under instantiation but no regular solutions (Lemma \ref{lemma:FRobInotsubsetFReg}).







\begin{lemma}
	\label{lemma:regulImpliesRobust}
	Given a \Cone function $F:B\subseteq\mathbb{R}^n\to \mathbb{R}^n$, if $p$ is a regular solution for $F$, then $p$ is a robust solution for $F$.
\end{lemma}

\begin{proof}
	Assume that $p$ is a regular solution of $F$. 
	Hence the Jacobian of $F$ at $p$ has maximal rank. We prove that $p$ is a robust solution of $F$. 
	So let $\varepsilon>0$ be arbitrary, but fixed
	%Let $\varepsilon'\leq \varepsilon$
	and such that $p$ is the unique solution of $F$ in $\openball{B}{\epsilon}(p)$.
	Such $\varepsilon$ always exists, %since the solution space of $F$ is a submanifold of dimension $n-n = 0$ (by Thm 9.9 \cite{TuIntroManifolds}
        since by the inverse function theorem $F$ maps a neighborhood of $p$ diffeomorphically onto an open set of $\mathbb{R}^n$~\cite[Chapter 1.2]{Milnor1965TopologyFT}.
	%i.e. the solution space is made of disconnected points.
	Hence $0\not\in \partial \openball{B}{\epsilon}(p)$, and, since $p$ is the only solution of $F$ in   $\openball{B}{\epsilon}(p)$, and it is regular, then, by definition,
	$\deg(F, \openball{B}{\epsilon}(p), 0) = |\det(J_F(p))| \neq 0$.	
	%the topological degree of $F$ in $\openball{B}{\epsilon}(p)$ is non-zero
	Let $\delta<\min_{x\in\partial \openball{B}{\epsilon}(p)} |F(x)|$. 
	 %Let $\phi \equiv F=0$. 
	 By Lemma~1~\cite{Franek:12}, every $F'$ with $\dist(F, F')<\delta$ has a zero in $\openball{B}{\epsilon}(p)$. 
	This proves that $p$ is a robust solution for $F$.
\end{proof}


\begin{lemma}
	\label{thm:FRegsubsetFRob}
	%Let $F=0$ be a system of equations with $F:\mathbb{R}^{n+k}\to \mathbb{R}^n$. If $0$ is a regular value for $F$, then there exists $p$ such that at least $k$ coordinates of $p$ are non-periodic rational numbers and $p$ is a robust solution of $F$.
	Let $F:B\subseteq\mathbb{R}^{m}\to \mathbb{R}^n$ (with $m=n+k$) be a \Cone function. If there exists a regular solution $q$ of $F$, then there exists a regular solution $p$ of $F$  in a neighborhood of $q$ such that $p$ is robust under instantiation.
	
	%\
	%a \kfinite{k}, and such that the projection $p_{|n}$ of $p$ over the first $n$ coordinates  
	%is a robust solution for the system of equations $F_{|n}: B_{|n} \subseteq \mathbb{R}^n \to \mathbb{R}^n$ obtained by instantiating the $k$ variables corresponding to the $k$ coordinates of $p$.% (and where $B_{|k}$ is the projection of $B$).
\end{lemma} 

\begin{proof}
	%Thm\ref{thm:regvalues}+Lemma\ref{lemma:submanifFloats}+Lemma\ref{lemma:regulImpliesRobust}.
	
	%\ \\
	If $q$ is a regular solution for $F$, then $J_F(q)$ has maximum rank. 
	Since a rectangular matrix has maximum rank if and only if one of its maximal square sub-matrix has maximum rank,
	 then, without loss of generality, we can reorder the variables so that the square sub-matrix given by the first $n$ columns has maximum rank, 
	 i.e. $\det(J_{F, \projn{x}}(q)) \neq 0$. 
	By the Implicit Function Theorem, there exists a neighborhood $U\subseteq \mathbb{R}^k$ of $(q_{n+1}, \dots, q_{n+k})$ and a \Cone function ${H: U \to \mathbb{R}^n}$ such that $H(q_{n+1}, \dots, q_{n+k})=(q_1 , \dots, q_n)$, and such that, for all $q'\in U$, ${F(H(q'), q')=0}$.
	
	In general, it is not guaranteed that every $(H(q'), q')$ will be a regular point for $F$. 
	However, since the Jacobian $J_F: \mathbb{R}^m \to \mathbb{R}^{m \times n}$%
	, the projection ${\pi_{n \times n}: \mathbb{R}^{m \times n} \to \mathbb{R}^{n \times n}}$
	(that projects a $m\times n$ matrix onto the $n\times n$ sub-matrix of its first $n$ columns)
	and the determinant $\det: \mathbb{R}^{n \times n} \to \mathbb{R}$ are all continuous functions, then the set $U_r \subseteq \mathbb{R}^m$, 
	consisting of all the  points $q'$ for which $\det(J_{F,\projn{x}}(q'))\neq 0$, is open, since  $\mathbb{R} \setminus \{0\}$ is open and, by definition, $U_r = (det \circ \pi_{n \times n} \circ J_F)^{-1}(\mathbb{R} \setminus \{0\})$.
	
	Let us consider the projection of $U_r$ over $\mathbb{R}^k$, i.e. $U_{r_{|k}} = \pi_k(U_r) = \{(q'_{n+1}, \dots, q'_{n+k}) \in \mathbb{R}^k | (q'_1 , \dots, q'_n, q'_{n+1}, \dots, q'_{n+k}) \in U_r  \}$. Since projections are open maps, then $U_{r_{|k}}$ is open.  Since both $U$ and $U_{r_{|k}}$ are neighborhoods of $(q_{n+1}, \dots, q_{n+k})$, then their intersection $U'\defas U \cap U_{r_{|k}}$ is again a neighborhood of $(q_{n+1}, \dots, q_{n+k})$.
	
	
	Now we prove that $U'$ contains at least one  \kfinite{k} $p'$. 
	The set of \kfinites{k} in $\mathbb{R}^k$ is exactly the set of points having coordinates with finite representation.
	Let us call this set $A$.  
	We have that $A$ is dense in $\mathbb{R}^k$, as, for every point ${z=(z_1,\dots , z_k) \in  \mathbb{R}^k}$, $z$ is the limit of the sequence $\{([z_1]_i, \dots , [z_k]_i) \}_{i\in \mathbb{N}} \subseteq A$, where $[z_j]_i$ is the truncation of $z_j$ to the $i$-th digit after the zero. 
	Since $A$ is dense in $\mathbb{R}^k$, then $A$ intersects every non-empty open of $\mathbb{R}^k$. 
	In particular $A \cap U' \neq \emptyset$, hence there exists $p'\in A \cap U'$. 
	%So $p'$ is a $k$-decimal point for which $F(H(p'), p')=0$. 
	
	Let $p\defas(H(p'), p')\in \mathbb{R}^m$. 
	We have that $p$ is a solution for $F$ (since $F(p) = F(H(p'), p')=0$). 
	Moreover, $p$ is also regular, since $p'\in U' \subseteq U_{r_{|k}}$ and hence $(H(p'), p') \in U_r$.
	
	Let $\nu \defas \{x_i \mapsto p_i\}_{i \in [n+1,  n+k]}$. 
	We have that the point $\pn = H(p') \in \mathbb{R}^n$ is a regular point for $\Fv$. Indeed, since $p$ is a regular point, and $J_{F, x_{|n}}(p)$ depends only on the first $n$ coordinates, then $\det(J_{\Fv}(\pn)) \neq 0$.
	
	Since $\pn$ is a regular solution for $\Fv$,  by  Lemma~\ref{lemma:regulImpliesRobust}, $\pn$ is also a robust solution for $\Fv$. Hence $p$ is robust under instantiation.
\end{proof}

Modifying the proof by choosing directly  $p$ as $q$ we get:
\begin{corollary}
	\label{corollary:kfiniteAndRegImpliesRobI}	
	Let $F:B\subseteq\mathbb{R}^{m}\to \mathbb{R}^n$ (with $m=n+k$) be a \Cone function
	  If $q$ is  both a regular solution and a \kfinite{k}, then $q$ is robust under instantiation.
\end{corollary}



Now we show that the converse of Lemma \ref{thm:FRegsubsetFRob} does not hold, i.e. that the existence of a solution robust under instantiation does not imply the existence of a regular solution. Consider the following example:
\begin{example}[Critical solution, but robust under instantiation]
	Let $F: [0, 1]^2 \subseteq \mathbb{R}^2\to \mathbb{R}$ defined by $F(x,y) = (x^2-y^3)$,
	and let $p = (0, 0)$. $J_F(p)=(0,0)$ has non-maximum rank (hence $p$ is a critical solution), but the instantiation $\{x\mapsto 0 \}$ leads to the subsystem $-y^3 = 0$, which is robust.
\end{example}

In this example, we could have chosen a different point, say $p'=(1,1)$, which is both robust under instantiation and regular. 

However, this is not always possible. A system can have a solution robust under instantiation, but no regular solutions. Indeed:



\begin{lemma}
	\label{lemma:FRobInotsubsetFReg}
	$\FRobI \not\subseteq \FReg$
\end{lemma}
\begin{proof}
	%\begin{example}[Robust under instantiation, but with no regular solutions]
	Let ${F:[-1,1]^3\subseteq \mathbb{R}^3\to \mathbb{R}^2}$ defined by 
	\begin{equation*}
		F(x_1, x_2, x_3)=
		\begin{cases}
			x_1^3 & (F_1)\\
			x_2+x_3 & (F_2)
		\end{cases}
	\end{equation*}
	
	\ \\
	The point $(0,0,0)$ is robust under instantiation. Indeed, the instantiation ${\{x_3 \mapsto 0 \}}$ leads to the following system of equations
	\begin{equation*}
		F'(x_1, x_2)=
		\begin{cases}
			x_1^3 & (F'_1)\\
			x_2 & (F'_2)
		\end{cases}
	\end{equation*}
	which has non-zero degree, hence it is robustly sat. % (and so $F\in \FRobI$). 
	It is easy to show that the degree of $F'$ in $[-1,1]^2$ is non-zero. 
	In fact, $F'_1$ depends only on $x_1$ and $F'_2$ only on $x_2$,
	and for both $F'_1$ and $F'_2$ it suffices to apply the Intermediate Value Theorem 
	to prove that $\deg(F'_i, [-1,1], 0) \neq 0$ (for $i=1,2$).
	Since the degree of the Cartesian product is the product of the degrees~\cite[Theorem 7.1.1]{BrouwerDegreeDincaMawhin},
	$\deg(F', [-1,1]^2, 0) = \deg(F'_1, [-1,1], 0) * \deg(F'_2, [-1,1], 0)  \neq 0 $.
	
	
	%	which has non-zero degree, hence it is robustly sat (and so $F\in \FRobI$). To prove that the degree of $F'$ in $[-1,1]^2$ is non-zero without resorting to software such as \textsc{TopDeg}, we can compute the degree manually.
	
	
	So $F\in \FRobI$.	
	However, $F$ does not have any regular solution. 
	Indeed, the first equation implies that for every every solution  $p$ its first coordinate has to be $p_1 = 0$.
	Since, for such a solution $p$, the first row of $J_F(p)$ is everywhere $0$, then the Jacobian cannot have maximum rank. 
	Hence every solution $p$ is not regular, i.e. $F\not\in \FReg$.
	%\end{example}
\end{proof}





\subsection{Robustness preservation after variable instantiation}
\label{subsec:RobPreservationAfterVarInst}

In the previous section, we have proven that, under the  assumption of the existence of a regular solution, there exists a solution that is robust under instantiation.


But what happens if we drop the assumption of regularity? In general, if we don't put any restriction on the functions we are considering, the solution space can be arbitrarily complicated. 
Indeed, for every closed subset $K \subseteq \mathbb{R}^m$, there exists a smooth function $F$ such that $F^{-1}(0)=K$ (\cite[Theorem 2.29]{LeeIntroSmooth}).

One may hope that, by restricting to functions that have a robust solution, we can always find a solution robust under instantiation. In this section, we show that this, unfortunately, does not hold. Consider the following example.
\begin{example}[Robust solution, but non-robust under instantiations]
	\label{ex:robButNonrobUnderInst}
	Let ${F: [-1,1]^2\subseteq \mathbb{R}^2\to \mathbb{R}}$ defined by $F(x,y) = (x^2 - y^2)$,
	and let $p = (0, 0)$. It is easy to show that $p$ is a robust solution. However, whether we instantiate $\{x\mapsto0\}$ or $\{y\mapsto 0\}$, 
	the resulting subfunctions (resp. $F_{|\{x\mapsto0\}}(y)=y^2$ and $F_{|\{y\mapsto0\}}(x)=x^2$)  are not robust.
\end{example}
In this example, we could have chosen another point, for example ${p'=(1,1)}$, which is regular (since $J_F(p')=(2,-2)$), and hence, by Corollary \ref{corollary:kfiniteAndRegImpliesRobI}, robust under instantiation. But in general, this is not always possible. Indeed, we have the following result:

\begin{lemma}
	\label{lemma:FRobnotsubsetFRobI}
	$\FRob \not\subseteq \FRobI$
\end{lemma}
\begin{proof}
%	We will provide a counter-example to $\FRob \subseteq \FRobI$
%\begin{example}[Robust formula, with only \nonRobustUnderInst solutions]
	\label{ex:robNotRobI}
	Let $F: [-1, 1]^4\subseteq \mathbb{R}^4 \to \mathbb{R}^3$ defined by 
	
	\begin{equation*}
		F(x_1, x_2, x_3, x_4)=
		\begin{cases}
			x_1^2+x_2^2-x_3^2-x_4^2 \\
			
			2(x_1 x_4+x_2 x_3) \\
			
			2(x_2 x_4-x_1 x_3)  \\
		\end{cases}
	\end{equation*}
	
	It is easy to show that $p=(0,0,0,0)$ is the only solution of $F$. Moreover, $p$ is robust (see the discussion about Hopf maps in 
	%\cite{RobsatImplementation}
	\cite{FranekHopf})
	, hence $F\in \FRob$. However, no instantiation $\nu_i \defas \{x_i \mapsto 0\}$ is robust. Indeed,  $(0, 0, 0)$ is the only solution of $F_{|\nu_i}$ in $[-1,1]^3$, but $\deg(F_{|\nu_i}, [-1,1]^3, 0) = 0$ (remember that, if a system of equations $F$ has an isolated robust solution in $B$, then $\deg(F, B, 0)\neq 0$). So $F\not\in \FRobI$.
%\end{example}
\end{proof}


%Notation: $I_{x_i = q_i}$ is the function $I(x_1,\dots x_m)\subseteq \mathbb{R}^m\to \mathbb{R}^n$ defined by $I(x_1, \dots, x_m) = x_i - q_i$

Now we show that the converse holds, i.e. that  every solution robust under instantiation is robust:

\begin{lemma}
	\label{lemma:FRobIimpliesFRob}
	Let $F:B\subseteq \mathbb{R}^{n+k}\to \mathbb{R}^n$. If $p$ is a solution robust under instantiation, then $p$ is a robust solution. 
\end{lemma}

\begin{proof}
	% Using variable instantiations
	If $p$ is a solution robust under instantiation, then there exists a set of indices $I$ (w.l.o.g. say $I=\{n+1, \dots, n+k\}$) 
	and a corresponding instantiation $\nu$ such that $\pn$ is a robust solution for $\Fv : B_{|\mathbb{R}^n} \subseteq \mathbb{R}^n\to \mathbb{R}^n$, that is,
	 for every $\epsilon>0$ there is a $\delta$ such that for all $\Fv'$ with $\dist(\Fv,\Fv')<\delta$, 
	there exists a solution $\pn'$ of $\Fv'$ with $\dist(\pn, \pn')<\epsilon$.
	 
	
	To prove that $p$ is a robust solution for $F$ let $\epsilon>0$ be arbitrary, but fixed, and take the corresponding $\delta$ as ensured by robustness under instantiation.
	For every $F'$ with $\dist(F,F')<\delta$,
	we have that also $\dist(\Fv,
	\Fv')<\delta$, hence there exists $\pn'$ that satisfies $\Fv'$ with $\dist(\pn, \pn')<\epsilon$. If $\pn'$ satisfies $\Fv'$, then $p'\defas (\pn', \pnk)$ satisfies $F'$. Since $\dist(p, p') = \dist(\pn, \pn')< \epsilon$,  $p$ satisfies the definition of robust solution for~$F$.
\end{proof}





A straightforward corollary of Lemma \ref{lemma:FRobIimpliesFRob}, is that  $\FRobI \subseteq \FRob$
%
which
concludes the proof that $\FRobI \mysubsetneq \FRob$.  Together with Lemma~\ref{lemma:FRobInotsubsetFReg} and Lemma~\ref{thm:FRegsubsetFRob}, this implies Theorem~\ref{thm:FRobIbounds}.





\subsection{Variable instantiation vs. equation adding}
\label{subsec:InstVarVsAddEq}

Given an under-constrained system of equations, we showed that there are two different ways to reduce to a well-constrained system of equations: decreasing the number of variables (i.e. instantiations) or increasing the number equations. In this section we will show that the class of systems that can be solved via variable instantiation is a subset of the class of systems that can be solved via adding equations.


Recall our definition of $\FRobLEq$ as the set of functions $F: B \subseteq \mathbb{R}^{n+k}\to \mathbb{R}^{n}$ such that there exists a linear function $L: \mathbb{R}^{n+k}\to \mathbb{R}^k $ such that the function ${F_{leq}: B \subseteq \mathbb{R}^{n+k}\to \mathbb{R}^{n+k}}$, defined by $F_{leq}: x \mapsto (F(x), L(x))$,
 has a robust solution.

%The main result of this section will be to prove that $\FRobI \subseteq \FRobLEq$.



Given any partial assignment $\nu \defas \{x_i \mapsto p_i\}_{i \in [n+1, n+k]}$, 
we can consider the function $F_{leq} = (F, L)$, given by $F$ and by the linear function ${L: B\subseteq \mathbb{R}^{n+k}\to \mathbb{R}^k}$
defined by ${L:(x_1,\dots, x_{n+k})\mapsto (x_{n+1} - p_{n+1}, \dots, x_{n+k}-p_{n+k})}$. Equivalently, since $L$ only depends on the last $k$ variables, we can consider it as a function ${L: B_{|\mathbb{R}^k}\subseteq \mathbb{R}^k\to \mathbb{R}^k}$. 

%While it is trivial to show that there is a one-to-one correspondence between the solutions of $F_{|\nu}$ and the solutions of $F_{leq}$, we need to prove that also the robustness of a solution is preserved. 
%This will be shown in the following lemma, that straight-forwardly implies that $\FRobI \subseteq \FRobLEq$.
 
 While it is trivial to show that every solution of $F_{|\nu}$  is also a solution of $F_{leq}$, we need to prove that also the robustness of a solution is preserved. 

\begin{lemma}
	\label{lemma:instVarVsAddEq}
	Given a system of equations $F = 0$ (with $F: B \subseteq \mathbb{R}^{n+k}\to \mathbb{R}^n$),
	a point $p=(p_1, \dots, p_{n+k}) \in B$ and subset of indexes $I:=\{n+1 , n+2, \dots, n+k\}$, let us consider the following statements:
	
	\begin{enumerate}
		\item For the function $\Fv:  B_{|\mathbb{R}^n} \subseteq \mathbb{R}^n\to \mathbb{R}^n$, obtained by instantiating variables via $\nu = \{x_i \mapsto p_i\}_{i\in I}$, the point $\pn \defas (p_1,\dots, p_n)$ is a robust solution 
		\item For the function $F_{leq}:  B \subseteq \mathbb{R}^{n+k}\to \mathbb{R}^{n+k}$, defined by
		$$F_{leq}(x_1, \dots, x_{n+k}) \mapsto (F(x_1, \dots, x_{n+k}), L(x_{n+1}, \dots, x_{n+k}))$$ where
		$L: B_{|\mathbb{R}^k} \subseteq  \mathbb{R}^k\to \mathbb{R}^k$ is defined by \[{L:(x_{n+1},\dots, x_{n+k})\mapsto (x_{n+1} - p_{n+1}, \dots, x_{n+k}-p_{n+k})},\] the point $p$ is a robust solution.
	\end{enumerate}
	\ 
Then, it holds that $1.$ implies $2.$.
\end{lemma}

\begin{proof}
	
	
	To prove that
	1. $\Rightarrow$ 2., it will be useful to consider a third auxiliary condition:
	\begin{enumerate}
		\item[\emph{3.}] 
		\emph{For the function $F_{{|\nu}_{leq}} \defas F_{|\nu} \times L : B \subseteq \mathbb{R}^{n+k}\to \mathbb{R}^{n+k}$ obtained by the Cartesian product between $F_{|\nu}$ and the linear function $L$, the point $p$ is a robust solution
	}
		%\item The system $F_{leq} \defas F \times \{x_i- p_i\}_{i \in I}$ obtained by adding equalities ${\{x_i - p_i = 0\}_{i\in I}}$ has a robust solution
	\end{enumerate}
	and prove first that 
	$1. \Rightarrow 3.$ and then that  
	$3. \Rightarrow 2.$
	%First, consider  $F_{{|\nu}_{leq}} \defas F_{|\nu} \times L$.  
	 %$F_{leq_{|\nu}}$ is the Cartesian product of the two functions of $ F_{|\nu}$ and $L$. 
	 
	 ($1. \Rightarrow 3.$ )
	By Theorem 7.1.1 \cite{BrouwerDegreeDincaMawhin}, the degree of the Cartesian product is the product of the degrees,
	i.e., for every $\Omega = \Omega_1 \times \Omega_2 \subseteq \mathbb{R}^{n}\times \mathbb{R}^k$,
	\begin{equation}
		\deg(F_{{|\nu}_{leq}}, \Omega, 0) = \deg(F_{|\nu}, \Omega_1, 0) * \deg(L, \Omega_2, 0 ) 
	\end{equation}
	Since $J_L(\pnk)$ is the identity matrix, the point $\pnk$ is a regular solution for $L$. Since $\pnk$ is the only solution of $L$, then, for every $\Omega_2 \subseteq \mathbb{R}^{k}$ such that $\pnk \in \Omega_2$, $\deg(L, \Omega_2, 0 ) = \det(J_L(\pnk)) = 1$.
	  
	Thus, for every $\Omega = \Omega_1 \times \Omega_2 \subseteq \mathbb{R}^{n}\times \mathbb{R}^k$ such that $p\in \Omega$, we have that
	\begin{equation}
		\label{eq:Thm711}
		\deg(F_{{|\nu}_{leq}}, \Omega, 0)  = \deg(F_{|\nu}, \Omega_1, 0)
	\end{equation} 


	 If 1. holds, then,  by Thm. 6 \cite{Franek:12}, for every $\epsilon>0$ there exists an open ${\Omega_{1,\epsilon} \subseteq \openball{B}{\epsilon}(\pn)}$ such that $\deg(F_{|\nu}, \Omega_{1,\epsilon}, 0) \neq 0$. 
	 Let 
	 %$\Omega_2 \defas \openball{B}{1}(\pnk)$
	 $\Omega_2$ be any neighborhood of $\pnk$ 
	 s.t. $\Omega_2 \subseteq \openball{B}{\epsilon}(\pnk)$,
	 and let $\Omega_\epsilon \defas \Omega_{1,\epsilon} \times \Omega_2$. 	 
	 By Equation \ref{eq:Thm711}, ${\deg(F_{{|\nu}_{leq}}, \Omega_\epsilon, 0) \neq 0}$. 
	 Hence,
	 for every $\epsilon>0$, $F_{{|\nu}_{leq}}$ is robustly sat in $ \Omega_{1,\epsilon}$. 
	 So we have constructed, for every $\epsilon>0$, a neighborhood $\Omega_{1,\epsilon} \subseteq \openball{B}{\epsilon}(p)_{\epsilon}$ of $p$ in which $F_{{|\nu}_{leq}}$ is robustly sat.  
	 By Proposition \ref{prop:locallyRobustlysat}, this implies that $p$ is a robust solution for $F_{{|\nu}_{leq}}$.
	
	  
	 \ 
	 
	($3. \Rightarrow 2.$ )
	Now we show that if $p$  is a robust solution for $F_{{|\nu}_{leq}}$ then it is a robust solution for    $F_{leq}$.	We will construct a homotopy between $F_{{|\nu}_{leq}}$  and    $F_{leq}$, and then rely on the Homotopy Invariance Property of the topological degree to prove the claim.
	
	Let $S:  \mathbb{R}^{n+k }\times [0,1] \to \mathbb{R}^{n+k }$ be defined by
        \vspace*{-0.32cm}\begin{multline*}
          S:((x_1, \dots, x_n, x_{n+1},\dots x_{n+k}), t) \mapsto\\
              (x_1, \dots, x_n, \ tx_{n+1} + (1-t)p_{n+1},\ \dots \ ,\ tx_{n+k} + (1-t)p_{n+k})
        \end{multline*}          
	
	The map $H: B \times [0,1]  \subseteq   \mathbb{R}^{n+k} \times [0,1]  \to \mathbb{R}^{n+k}$ 
	defined by
	%defined as ${H\defas( F\circ S) \times L}$. 
	$$H:(x_1, \dots, x_{n+k}, t)\mapsto (( F\circ S)(x_1, \dots, x_{n+k}, t) \ , \ L((x_{n+1}, \dots, x_{n+k}))) $$
	 is a homotopy between $F_{{|\nu}_{leq}}$ and $F_{leq}$ since
	 $H(\cdot, 0) \equiv F_{{|\nu}_{leq}}$, $H(\cdot, 1) \equiv F_{leq}$, and $H$ is continuous, being the composition of continuous functions. 
	
	It is easy to see that the functions $F_{leq}$ and $F_{{|\nu}_{leq}}$ have exactly the same solution space. Indeed, every solution of $F_{leq}$ has to satisfy the equations given by $L$, i.e. ${x_{n+1}=p_{n+1}, \dots, x_{n+k}=p_{n+k}}$. 
	By replacing in $F_{leq}$  every $x_i$ with $p_i$, for ${i\in [n+1, n+k]}$, we obtain exactly $F_{{|\nu}_{leq}}$. 
	
	Furthermore, for every $t\in [0,1]$ the solution space of $H(\cdot , t)$ is the same as $H(\cdot , 0) \equiv F_{{|\nu}_{leq}}$. 
	Indeed, for every $t$, a solution of $H(\cdot , t)$ has to satisfy the equations given by $L.$ 
	Then, by replacing  every $x_i$ with $p_i$ for $i\in[n+1, n+k]$, we have that every $tx_i + (1-t)p_i $ is replaced by $tp_i + (1-t)p_i$, which is equal to $p_i$. Thus we reduced  again to  $F_{{|\nu}_{leq}}$.
	
	%Now we can check that, if 3. holds, then $H$ satisfies the conditions required to apply the  Homotopy Invariance Property, 
	%i.e. that  $0\not\in H(\partial B \times [0,1])$.
	
	Now, suppose that 3. holds. Then, for every $\epsilon>0$, there exists $\Omega_\epsilon \subseteq \openball{B}{\epsilon}(p) $ such that $\deg(F_{{|\nu}_{leq}}, \Omega_\epsilon, 0)\neq 0$. 
	%$p$ is the a solution for   $F_{leq}$ (resp. $F_{{|\nu}_{leq}}$) in $\Omega_\epsilon$. 
	This implies that  ${0\not \in F_{{|\nu}_{leq}}(\partial  \Omega_\epsilon)}$, hence  ${0\not \in H(\partial  \Omega_\epsilon, 1)}$.
	 So, by the previous observation, $0\not \in H(\partial  \Omega_\epsilon, t)$ for every $t\in [0,1]$. Hence $0\not \in H(\partial  \Omega_\epsilon, [0,1])$, and we can apply the Homotopy Invariance Property.
	
	The Homotopy Invariance Property of the topological degree states that, if $0\not\in H(\partial  \Omega_\epsilon \times [0,1])$, then $\deg(H(\cdot, 0),  \Omega_\epsilon, 0) = \deg(H(\cdot, 1),  \Omega_\epsilon, 0)$, i.e. ${\deg(F_{{|\nu}_{leq}},  \Omega_\epsilon, 0) = \deg(F_{leq},  \Omega_\epsilon, 0)}$. 
	So we have constructed, for every $\epsilon >0$, a neighborhood $\Omega_\epsilon \subseteq \openball{B}{\epsilon}(p)$ of $p$ in which $F_{leq}$ is robustly sat. By Proposition~\ref{prop:locallyRobustlysat}, this implies that $p$ is a robust solution for  $F_{leq}$.
	
\end{proof}

So robustness of the system obtained by variable instantiation implies robustness of  the system obtained by adding the equalities corresponding to this variable instantiation.
Theorem~\ref{thm:instVersusEq} is a straight-forward consequence.


 


\subsection{Termination}
\label{subsec:termination}
The method discussed in Section \ref{sec:certificate-search} made use of numerical optimization to enumerate the points over which the variable instantiation method is applied. This technique, while practically very efficient---as shown by our experiments---is not guaranteed to terminate, in general. Indeed, even in the bounded case, numerical optimization does not guarantee full coverage of the space.

In this section, we present a variation of our method that uses a different technique for enumerating points, and that is guaranteed to terminate on problems in $\FRobI$. While this variation is not intended to be of practical use, it will serve the purpose of proving Theorem \ref{thm:quasiquasidecidability}.

\ 

Given $F: B \subseteq \mathbb{R}^{n+k} \to \mathbb{R}^n$, if $F \in \FRobI$, by definition we know that there exists a \kfinite{k} $p$ that is robust under instantiation. 
Such a point~$p$ is, in general, not a \kfinite{(n+k)} (indeed,  there are problems for which no solution is a \kfinite{(n+k)}).
Hence no point enumeration technique is guaranteed to find precisely $p$, 
since only \kfinites{(n+k)}  can be expressed explicitly. 
However, this is not an actual limitation. 
Indeed, for our method to succeed, we don't necessarily need to explicitly produce a solution. We just need to find a point sufficiently close to an actual solution, and that shares with the solution $k$ indices, so that, after the instantiation of the corresponding $k$ variables, we end up with a subproblem that is robustly satisfiable. This suffices to produce a certificate.

The following lemma shows that, for every problem in $\FRobI$, it is always possible to find a \kfinite{(n+k)} and a partial assignment such that the resulting subproblem is robustly satisfiable.

\begin{lemma}
	\label{lemma:nkfinite}
	 Let $F : B \subseteq \mathbb{R}^{n+k} \to \mathbb{R}^n$. If $F \in \FRobI$, then there exist a {\kfinite{(n+k)}}  $p'\in B$ and a partial assignment $\nu' \defas \{x_i \to p'_i\}_{i\in I}$ (with $I$ being a set of $k$ indices), such that the function ${F_{|\nu'}: B_{|\mathbb{R}^n} \subseteq \mathbb{R}^n \to \mathbb{R}^n}$ is robustly satisfiable.
 \end{lemma}
\begin{proof}
	$F \in \FRobI$ means that there exists a \kfinite{k} $p$ 
	(w.l.o.g. say the $k$ finitely representable indices are $[n+1, n+k]$) 
	that is robust under instantiation,
	i.e. there exists a partial assignment $\nu\defas \{x_i \mapsto p_i\}_{i\in [n+1, n+k]}$ 
	such that $p_{|\nu}$ is a robust solution for $\Fv$. 
	This implies that $\Fv$ is robustly satisfiable in  $B_{|\mathbb{R}^n}$.
	
	Now, given any $p' \in B$ such that $p'_{n+1} = p_{n+1}, \dots, p'_{n+k} = p_{n+k}$, 
	and, given $\nu'\defas \{x_i \mapsto p'_i\}_{i\in [n+1, n+k]}$, 
	we have that $\nu' \equiv \nu$, hence $\Fv' \equiv F_{|\nu}$, 
	which implies that $F_{|\nu'}$ is robustly satisfiable in  $B_{|\mathbb{R}^n}$. 
	In order to find a $p'$ that respects the statement conditions, first we fix the last $k$ coordinates to be equal to $(p_{n+1},\dots,p_{n+k})$. 
	Then, since the set of \kfinites{n} is dense in $\mathbb{R}^{n}$, and hence intersects $\interior{B_{|\mathbb{R}^n}}$ (being an open), 
	there exists a \kfinite{n} $(p'_1, \dots, p'_n) \in \interior{B_{|\mathbb{R}^n}}$.
	%, 
	%then we construct an infinite sequence of \kfinites{n} in $\mathbb{R}^n$ having limit point $(p_1, \dots, p_n)$ 
	%(this is always possible since the set of \kfinites{n} is dense in $\mathbb{R}^{n}$). 
	%Eventually, the points in the sequence will be contained in $B_{|\mathbb{R}^n}$. 
	If we take such point, and append the last $k$ coordinates previously fixed, 
	we obtain a point $p'\defas (p'_1, \dots, p'_n, p_{n+1}, \dots, p_{n+k})$. Since the last $k$ coordinates of $p'$ coincides with the last $k$ coordinates of $p$, we have that $F_{|\nu'}$ is robustly satisfiable in  $B_{|\mathbb{R}^n}$. 
	Moreover, such $p'$ is a \kfinite{(n+k)}. 
	Indeed, the part consisting of the first $n$ coordinates is $n$-finite by construction, 
	while the second part consisting of the last $k$ coordinates is $k$-finite because $p_{n+1},\dots,p_{n+k}$ is.
\end{proof}


Considering a bounded system of equations and inequalities satisfiable iff it is satisfiable by
a variable assignment the assigns values within the corresponding interval to all variables,
it is straightforward to extend the definitions from Section~\ref{subsec:BackgroundRobustness} analogically from systems of equations to bounded systems of equations and inequalities. Based on this, we can prove the following theorem. 
%	In the statement, we will use the more general notion of robust (un)satisfiability as defined in \cite{Franek:12}.
\begin{theorem}
	\label{thm:quasiquasidecidability}
	There exists a procedure that, given a bounded system of equations and inequalities $F=0 \wedge G \leq 0$,
	\begin{itemize}
        \item always returns the correct answer ``satisfiable'' or ``unsatisfiable'', if it terminates,
        \item always terminates successfully when $F=0 \wedge G \leq 0$ is robustly satisfiable  and  $F\in \FRobI$,
        \item always terminates successfully when $F=0 \wedge G \leq 0$ is robustly unsatisfiable.
	\end{itemize}
\end{theorem}

	\begin{proof}
	 
	We first concentrate on the second point, by showing a procedure that always correctly terminates on problems in $\FRobI$.


	
By Lemma \ref{lemma:nkfinite}, we have that,
for every $F: B \subseteq \mathbb{R}^{n+k}\to \mathbb{R}^n $ such that $F \in \FRobI$, there exists a \kfinite{(n+k)}~$p'$ and a partial assignment $\nu'$ such that $F_{|\nu'}$ is robustly satisfiable.
We can always find such $p'$ and $\nu'$. 
Indeed,
since the set of \kfinites{(n+k)} is countable, we can construct a well-order: 
say, for example, we first take the finite set of points whose  coordinates are represented by at most $1$ digit 
(and sort it by lexicographic order),
then the finite set of points  whose coordinates are represented by at most $2$ digits, and so on
\footnote{Note that this is independent by the Axiom of Choice, which is needed only in the case of uncountable sets.}.
For each such point $p$, and for each instantiation $\nu$ (note that the set of possible instantiations is finite), we can consider the   
resulting subsystem $F_{|\nu'} : B_{|\mathbb{R}^n}\subseteq \mathbb{R}^n \to \mathbb{R}^n$, 
and then apply the box-gridding procedure
discussed in Section \ref{subsec:box}, which---without the stopping criterion---is guaranteed to terminate on robust instances~\cite{Franek:12}. Note that box-gridding method also handles inequalities.



The procedure described so far is not yet guaranteed to converge. 
Indeed, while box-gridding is guaranteed to terminate on robust instances, it could diverge on non-robust instances, thus preventing the general procedure to terminate (either because one point yielded
%yeeted\SRtodo{never heard about this word} 
before $p'$ was non-robust, or because one instantiation tried before $\nu'$ was a non-robust instantiation).

We can overcome this problem by using, instead of depth-first search, a technique called dove-tailing. 
Indeed, we have an infinite sequence of problems (given by the combination of points and instantiations), and, for each, a (possibly infinite) sequence of box-gridding iterations. 
We outline the following iterative procedure:
\begin{itemize}
	\item For $i=1$, we perform the $1$-st box-gridding iteration on the $1$-st problem.
	\item For $i=2$, we perform the $2$-nd box-gridding iteration on the first problem, and then the $1$-st box-gridding iteration on the second problem.
	\item \dots
	\item For $i=N$, we perform the $N$-th box-gridding iteration on the first problem, then the $(N-1)$-th box-gridding iteration on the second problem, \dots, and then the $1$-st box-gridding iteration on the $N$-th problem.	
\end{itemize}
First, we are guaranteed to find the problem given by the point $p'$ and the variable instantiation $\nu'$  after a finite amount of steps. Given such problem, we are guaranteed that also the box-gridding procedure will terminate after finitely many iterations. Hence, also our general procedure is guaranteed to terminate. 
\ 

The third point regarding robustly unsatisfiable problems simply follows by the use of box-gridding on the whole system using the bounds of the given system of equations and inequations as its starting box. Indeed, if the system is robustly unsatisfiable, then this  is guaranteed to terminate with a correct result.

To finalize the proof of the theorem, it suffices to consider the procedure that runs  the two previous procedures in parallel.


\end{proof}

Note that for formulas of the given form (bounded system of equations and inequalities), the procedure described in the proof of Theorem~\ref{thm:quasiquasidecidability} can be seen as an instantiation of the certificate search method presented in Section~\ref{sec:method} that uses exhaustive enumeration on the level of points and instantiations, and directly uses the given bounds as the starting box for box gridding. The theorem shows that 
%under the assumption of robustness, 
under robustness assumptions, 
such an instantiation will always terminate successfully for bounded system of equations and inequalities. However, complete enumeration makes this instantiation hopelessly inefficient in practice, and goal oriented methods, as discussed in the first part of the paper, are necessary for practical efficiency. Also, there is no known way of algorithmically deciding whether a given formula satisfies the robustness precondition that ensures termination of the procedure, and hence Theorem~\ref{thm:quasiquasidecidability} is \emph{not} a decidability result.



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
