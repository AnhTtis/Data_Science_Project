
\section{Computational Experiments}
\label{sec:experiments}



\input{exp_table}

\myparagraph{Implementation.} 
We implemented the different heuristics presented in the paper in a prototype tool called \ugotNL (firstly presented in \cite{ATVApaper}). In order to make the results comparable with the ones obtained earlier, in addition to the search method discussed in Section~\ref{sec:certificate-search}, we preserve the following heuristics used by \ugotNL: If the local minimizer cannot find any minimum of $\LtoO(\phi)$ for which for every clause $C\in\phi$, the set of approximately satisfiable literals $L_C$ is non-empty, we restart the procedure on every conjunction resulting from the DNF of $\phi$.
The tool handles strict inequalities of the form $f<0$ directly until the box construction phase, where they are replaced by $f\leq -\varepsilon$  (with $\varepsilon=10^{-20}$).
For computing the topological degree, we use \textsc{TopDeg}\footnote{Available at \url{https://www.cs.cas.cz/~ratschan/topdeg/topdeg.html}.}. For the symbolic simplifications used in \checkForcedLiterals, we use the \textit{simplify} and the \textit{solve-eqs} tactics provided by \textsc{Z3}~\cite{z3}
\footnote{For a description of the two tactics: \url{https://microsoft.github.io/z3guide/docs/strategies/summary}. The version of Z3 used is 4.5.1.0.}. For the computation of the rank used in \filterRankDeficient, we observe that the rank of a matrix is equal to the number of non-zero singular values, hence we consider a matrix far from rank-deficiency iff all its singular values are bigger than some threshold (to account for approximation errors). We use a threshold widely used by algorithms for determining the matrix rank, which is $\sigma_{\max} dim(A) \varepsilon$, where $\sigma_{\max}$ is the largest singular value of $A$, and $\varepsilon$ is the machine epsilon.


\myparagraph{Setup.} We run the experiments\footnote{The results of the experiments are available at \url{https://doi.org/10.5281/zenodo.7774117}} on a cluster of identical machines equipped with 2.6GHz AMD Opteron 6238 processors.	We set a time limit of 1000 seconds, and a memory limit of 2Gb. We considered all \smtnta benchmarks from the dReal distribution~\cite{dreal} and other \smtnta benchmarks coming from the discretization of Bounded Model Checking of hybrid automata~\cite{HARE,HYST}, totaling 1931 benchmarks. All of these benchmarks come with ``unknown'' status. According to experiments performed on other solvers ($\cvctool$, $\drealtool$, $\isattool$, $\mathsat$), among these benchmarks 736 (respectively, 174) are claimed to be unsatisfiable (satisfiable) by at least one solver\footnote{For the results of such experiments, see \cite{ATVApaper}.}. 
%The benchmarks also contain strict inequalities of the form $f<0$ that the Logic-to-Optimization approach can handle directly~\cite{ATVApaper}, but that we replace by $f\leq -\varepsilon$ with with $\varepsilon=10^{-20}$ in the box construction phase.
We tested our tool with different heuristics configurations (Table \ref{fig:experiments}), and, for each configuration, we checked that our tool never contradicts the other tools. We have arranged the heuristics into 3 columns (Literals, Instantiations, and Boxes) according to the search level they are used in. As the number of possible configurations is quite high, we proceed as follows: We start with the simpler configurations (just one method for finding a box that contains a solution), and then we add heuristics.
The configurations that use the equation adding method are discussed separately at the end of the section.


\input{exp_cactus_fig}
\myparagraph{Results.} In the first configurations we tested the 3 possible ways to search for a box. We note that \boxGridding \citeexpid{1}{a} performs  considerably worse than the other two, \epsInflation \citeexpid{1}{b} and \epsInflation+\boxGridding \citeexpid{1}{c}, which produce comparable results. Because of that, and for readability's sake, we did not use \boxGridding alone with other heuristics in the next configurations, but only considered the other two options. We then added heuristics based on the following criteria: first heuristics for the ``Literals'' choice, then heuristics for the ``Instantiations'' choice, and first ordering heuristics (i.e. \sortWrtCost and \KearfottOrdering), then filtering heuristics (all the others). At every new heuristic added, we see that the number of benchmarks solved grows regardless of the ``Boxes'' choice, with the best configuration reaching 427 benchmarks using 7 heuristics. If we consider the virtual best (i.e. run in parallel all the configurations and stop as soon as a certificate is found) we are able to solve 441 benchmarks. This is because in cases such as \epsInflation vs. \epsInflation+\boxGridding, or such as \filterOverconstrV vs. \filterRankDeficient, there is no dominant choice, with each configuration solving benchmarks that the other does not solve and vice-versa. 
The cactus plot in Figure~\ref{fig:cactus}---in which we included only a subset of the configurations in Table~\ref{fig:experiments} for graphical reasons--- 
substantiates the claim that new heuristics improve not only effectiveness, but also performances. 
The plot of the virtual best remarks the complementarity between different configurations.


\input{exp_cactus_compare_fig}

\myparagraph{Discussion.}  The first configuration \citeexpid{1}{a} essentially uses a method proposed earlier~\cite{ATVApaper} and implemented in a tool called \ugotNLeager (of which the tool presented in this paper is an upgrade). Already in the previous paper, \ugotNLeager outperformed the other solvers able to prove satisfiability in $\smtnta$, solving more than three times the benchmarks than \mathsat\cite{mathsat5}, \cvctool \cite{cvc5}, and \isattool\cite{iSAT3}, and almost as twice as the benchmarks solved by the \emph{lazy} version \msatUgot (where \ugotNL had been integrated \emph{lazily} inside \mathsat). The introduction of new heuristics further improved the performances of our tool, that is now able to solve around 100 benchmarks more.
Moreover, the best configuration of our tool, \citeexpid{7}{b}, was able to prove the satisfiability of 334 benchmarks among the 1021 that had status ``unknown'', i.e. that had not been solved by any other solver. 
Now, considering all the state-of-the-art SMT solvers that are able to prove satisfiability of \nta benchmarks, including ours, 
the virtual best 
%(i.e., a virtual portfolio that runs in parallel all solvers and stops as soon as one solver terminated)
 is able to solve 508 benchmarks, compared to the 174 previously solved without the inclusion of our tool. This is depicted in Figure \ref{fig:cactusCompare}, which also shows the complementarity between the different solvers. As can be noted, %in the Figure
 the plot of \ugotNL is less steep than the plots of other solvers. This is in part due to the eager approach of the tool, that first generates several candidate points, and only then chooses one of these points to narrow down the search, in part due to the tool been a prototype written in Python, compared to highly optimized solvers written in C/C++. 
 %While now we have focused on improving the effectiveness  (which ), improving nc

\myparagraph{Run-time of the certificate checker.} In Section \ref{sec:goal} we claimed that, with our approach, checking a certificate requires less run-time than the certificate search itself. Here we experimentally quantify this amount: for each benchmark solved by the best configuration \citeexpid{7}{b}, we observe the run-time required to check the certificate (which amounts, essentially, to the computation of topological degree and interval arithmetic for the successful box). In terms of median (respectively, mean), checking the certificate requires $0.10\%$ ($1.07\%$) of the run-time used by the solver.


\myparagraph{Variable instantiations vs. equation adding}
In Section \ref{subsec:instantiations} we presented two different approach to reduce to a square system of equations: variable instantiation and equation adding. 
In Table \ref{fig:experimentsOrth} we experimentally compare these two approaches. In order not to overload the table, we compare the new heuristics only against representative configurations: \citeexpid{7}{b} - being the one that solved more benchmarks - and \citeexpid{4}{b} - being the one where only "Literals" heuristics are used. 
We observe that the use of \orthogonal does not seem to pay off particularly well: comparing \citeexpid{4}{b} to \citeexpid{orth}{1}, it increases the number of benchmarks solved just by a small margin, while comparing \citeexpid{7}{b} to \citeexpid{orth}{3}, the number of benchmarks solved decreases. If we consider the configurations that use the sub-heuristic \gaussel\ - \citeexpid{orth}{2} and \citeexpid{orth}{4} - we see that in both cases the performance are even worsened.

\myparagraphB{Discussion.} While from a mathematical perspective the orthogonal method should perform better, as it yields a more robust system and obviates the iteration through all the possible variable instantiations, 
its effectiveness can be severely limited by the well-known numerical instability of algorithms that compute orthogonal matrices. 
Moreover, the systems of equations obtained via equation adding have a higher dimension than the ones obtained via variable instantiations, leading to a more complex problem to solve for the topological degree test and interval arithmetic.
One could hope to lighten this negative effect by using the sub-heuristic \gaussel  
that reduces the dimension to the same obtained via variable instantiation. 
Unfortunately, this procedure generates equations which are more complex then the ones obtained by variable instantiation, 
as it substitutes the exceeding variables by a linear combination of the remaining variables, 
and since our technique for proving satisfiability relies on interval arithmetic 
(which is quite sensitive to syntactic manipulations and rounding bounds propagation)
this can severely impact on the effectiveness of the check.
While we do not rule out that a more engineered implementation of the equation adding approach could yield better results, our experimental results show that the more straight-forward approach of variable instantiation is more effective on the considered benchmarks.

\input{exp_table_orth}



%\newpage

%\textcolor{orange}{Instead of variable instantiations, add additional linear equations} (that can then \textcolor{orange}{be eliminated by Gaussian elimination}). In first experiments, this did not work too well. The reason might be that it makes interval evaluation and topological degree computation more difficult.



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "./main.tex"
%%% End:
