\section{Conclusion}
\label{sec:conclusion}
In this work we have introduced RGI, a simple yet effective framework for self-supervised learning on graphs based on the propagation of node embeddings to generate supervision signals. The objective function maximizes the mutual information between node embeddings and their propagation by addressing the reconstruction between them and regularizing the covariance matrix of the representations to avoid the total and dimensional collapse. We have shown that, in spite of its simplicity and that it does not require training for too long, it achieves state-of-the-art performance on multiple transductive and inductive datasets following the linear evaluation protocol on downstream tasks.