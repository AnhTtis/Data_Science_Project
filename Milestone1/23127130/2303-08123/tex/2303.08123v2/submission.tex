% !TeX spellcheck = en_GB
\PassOptionsToPackage{x11names}{xcolor}
\documentclass[12pt]{article}

\usepackage[colorinlistoftodos, textwidth=30mm, shadow]{todonotes}
%\renewcommand\familydefault{\sfdefault}

%%%%%%% packages
\usepackage{scicite}
\usepackage{times}
\usepackage{array}
\usepackage{amsmath}
\usepackage{tabularx}
\usepackage{txfonts}
\usepackage{enumerate}
%\usepackage{cite}
\usepackage{float}
\usepackage{xspace}
\usepackage[x11names]{xcolor}
\usepackage{multirow}
\usepackage{algpseudocode,algorithmicx}
\usepackage{booktabs}
\usepackage{siunitx}
\usepackage{nameref}
\usepackage{makecell}
\usepackage[colorlinks=true,citecolor=red,linkcolor=DarkOrange1]{hyperref}

\usepackage{subcaption}
%\usepackage{subfig}

\usepackage{pdflscape}

%\usepackage{lineno}

%\usepackage{tikz}
%\usepgflibrary{shapes}
%\usetikzlibrary{spy}
%\usepackage{pgfplots}
%\pgfplotsset{compat=1.11}

%\usepackage{showkeys}
%%\usepackage{showlabels}

\usepackage[T1]{fontenc}
\usepackage[cp1250]{inputenc}

% \usepackage[margin=2.5cm]{geometry}
%\usepackage[margin=2cm]{geometry} %optimal
%\usepackage[margin=2.5cm,head=15pt]{geometry}


%\usepackage{showlabels}

%% SCI MARGINS
\topmargin 0.0cm
\oddsidemargin 0.2cm
\textwidth 16cm 
\textheight 21cm
\footskip 1.0cm




%\usepackage{listings}
%\lstset{basicstyle=\footnotesize\ttfamily,breaklines=true, tabsize=2}

\usepackage{placeins} % FloatBarrier

% More pictures allowed per page
\renewcommand{\topfraction}{0.9}
\renewcommand{\bottomfraction}{0.8}
\renewcommand{\floatpagefraction}{0.8}
\renewcommand{\dblfloatpagefraction}{0.8}
\setcounter{topnumber}{3}
\setcounter{bottomnumber}{3}
\setcounter{totalnumber}{4}
% More pictures allowed per page (end)

%\renewcommand\thesection{S\arabic{section}}
%\renewcommand{\thefigure}{S\arabic{figure}}

%\usepackage[T1,plmath]{polski} % pakiet ustawiajcy polskie wzorce 





\newenvironment{sciabstract}{%
\begin{quote} \bf}
{\end{quote}}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  
% Authors' definitons
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\abs}[1]{\left\vert#1\right\vert}
\newcommand{\norm}[1]{\left\Vert#1\right\Vert}
\newcommand{\scal}[1]{\langle #1\rangle}
\DeclareMathOperator{\sign}{\mathrm{sign}}
\DeclareMathOperator{\e}{\mathrm{e}}
\DeclareMathOperator{\dd}{\mathrm{d\!}}
\DeclareMathOperator{\Int}{\mathrm{Int}}
%\DeclareMathOperator{\mod}{\mathrm{mod}}

\newcommand*{\dwd}[1][]{{\par\noindent\bfseries {\em Proof#1: }}}
\newcommand*{\cbdo}{\hspace*{\fill} $\rule{1.5ex}{1.5ex}${\par}\vspace{2em}}
\newcommand{\etal}{\textit{et al.}\xspace}



\renewcommand{\Re}{\textrm{Re}}
\renewcommand{\Im}{\textrm{Im}}

\newcommand{\N}{\varmathbb{N}}
\newcommand{\R}{\varmathbb{R}}
\newcommand{\C}{\varmathbb{C}}
\newcommand{\Cb}{\mathcal{C}}
\newcommand{\Kb}{\mathcal{K}}

\newcommand*{\kryt}{\textrm{cr}}
\newcommand*{\vp}{\mathbf{p}}
\newcommand*{\vq}{\mathbf{q}}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{cor}[theorem]{Corollary}
\newtheorem{rem}[theorem]{Remark}
\newtheorem{defs}[theorem]{Definition}

\newenvironment{proof}[1][]{\par\noindent\textbf{Proof#1: }}{\hfill\rule{1.3ex}{1.3ex}\vspace{0.5cm}\par}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% end of authors' definitions
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \numberwithin{equation}{section}

\title{Identifying Promising Candidate Radiotherapy Protocols via GPU-GA \textit{in-silico}}

\author
{Wojciech Ozimek$^{1}$, Rafa\l{} Bana{\'s}$^{2}$, Pawe\l{} Gora$^{3,\ast}$,\\ Simon D. Angus$^{4}$, Monika J. Piotrowska$^{5}$\\
\\
\normalsize{$^{1}$Ardigen SA, 76 Podole Street, 30-394 Krakow, Poland}\\
\normalsize{ORCID ID: 0000-0003-2588-1353}\\\\

\normalsize{$^{2}$NVIDIA Corporation, al. Chmielna 73, 00-801, 00-001 Warsaw, Poland}\\
\normalsize{ORCID ID: 0000-0002-1811-1206}\\\\


\normalsize{$^{3}$Institute of Informatics, University of Warsaw,}\\
\normalsize{Banacha 2, 02-097 Warsaw, Poland}\\
\normalsize{ORCID ID: 0000-0002-8037-5704}\\\\

\normalsize{$^{4}$Department of Economics and SoDa Laboratories, Monash Business School,}\\
\normalsize{Monash University}\\
\normalsize{Wellington Rd, Clayton, 3800, Australia}\\
\normalsize{ORCID ID: 0000-0001-7095-5054}\\\\

\normalsize{$^{5}$Institute of Applied Mathematics and Mechanics, University of Warsaw}\\
\normalsize{Banacha 2, 02-097 Warsaw, Poland}\\
\normalsize{ORCID ID: 0000-0003-0156-8290}
\\
\\
\normalsize{$^\ast$To whom correspondence should be addressed; E-mail: p.gora@mimuw.edu.pl}
}


\date{}

\begin{document}
% Double-space the manuscript.
\baselineskip24pt
\maketitle

\begin{sciabstract}

% \mon{The abstract should be a single paragraph (no more than 150 words) written in plain language that a general reader can understand. It should include:
% An opening sentence that states the question/problem addressed by the research AND
% Enough background content to give context to the study AND
% A brief statement of primary results AND
% A short concluding sentence.}

Around half of all cancer patients, world-wide, will receive some form of radiotherapy (RT) as part of their treatment. And yet, despite the rapid advance of high-throughput screening to identify successful chemotherapy drug candidates, there is no current analogue for RT protocol screening or discovery at any scale. Here we introduce and demonstrate the application of a high-throughput/\-high-fidelity coupled tumour--irradiation simulation approach, we call `GPU-GA', and apply it to human breast cancer analogue -- EMT6/Ro spheroids. By analysing over 9.5 million candidate protocols, GPU-GA yields significant gains in tumour suppression versus prior state-of-the-art high-fidelity/\-low-throughput computational search under two clinically relevant benchmarks. By extending the search space to hypofractionated areas ($>2$~Gy/day) yet within total dose limits, further tumour suppression of up to 33.7\% compared to state-of-the-art is obtained. GPU-GA could be applied to any cell line with sufficient empirical data, and to many clinically relevant RT considerations.

%BMII    - 36.3
%BMII-1  - 33.7
%GA2.0-1 - 30.6

% [147 words]
% [148 ]

% In this paper we introduce computational techniques applied to high-fidelity modelling and optimisation of EMT6/Ro tumour growth under multi-day radiotherapy treatment protocols. The original model, utilising cellular automata, implemented in MATLAB, and applying genetic algorithm (GA) search techniques to only a single protocol parameter to identify candidate irradiation protocols, was re-implemented in C++ and enhanced with  Graphical Processor Units (GPUs) to achieve large execution speedups, enabling the search of a much larger, multi-parameter search space. Further, new operators were developed in the GA re-implementation to conduct selection, crossover and mutation. Together these computational design and implementation developments resulted in improvements of c. 760x solution execution speedup  compared to the original architecture, and 6-8\% protocol fitness improvement.

% Here we introduce and demonstrate the validation of a high fidelity, high performance computational model of EMT6/Ro spheroids leveraging state-of-the-art computational approaches on GPU architectures coupled to GA search, an approach we call `GPU-GA', and apply this approach to optimal radiotherapy scheme discovery, at scale.



\end{sciabstract}

%-------------------------------------------------------------------------


% \section*{TEST}
% \mon{
% The manuscript should be a maximum of 15,000 words.\\
% There is only one reference list for all sources cited in the main text, figure and table legends, and Supplementary Materials, and this main list should not exceed 40 citations.\\
% from template file: You may include up to a total of six figures and/or tables (combined) throughout the manuscript.\\ web page info: You may include up to ten figures and/or tables and about 60 references.
% }%mon


%-------------------------------------------------------------------------
\section*{Introduction}

Radiotherapy (RT), and specifically small-dose or fractionated RT, is widely considered to be a cost effective, and potent tool in the treatment of many varieties of cancer with 40 to 50\% of cancer patients receiving some form of RT during their treatment, regardless of the relative prosperity of their context~\cite{Thompson2018}. However, clinical treatment protocols -- the schedule of RT dose size and timing -- are remarkably \emph{singular} in practice despite the wide range of cancers and their pathologies in the human body: `2~Gy per day' being perhaps \emph{the} signature protocol of the last few decades~\cite{Rosenstein:2004vs,ORourke:2009,BoardoftheFacultyofClinicalOncology:2006wq}. Encouragingly, long-running and laborious clinical trials~\cite{Haviland2013,Whelan2010} of slight variations in protocol design (e.g. `3~Gy per day') have shown benefits leading to practice-changing adoptions in clinical settings. As such, given the high cost, and long delays inherent in gathering robust clinical evidence on candidate protocols, there is a pressing need for pre-clinical protocol candidate screening and discovery such that clinical trials examine the most promising alternative candidates. However, away from the tiny number of standard protocols, combinatorial considerations mean that there is an overwhelming number of ways to create a fractionated RT protocol. Consider that, with an alphabet of just five fractional dose sizes, and 10 possible wait-times for the next fraction, a 10 fraction protocol can be constructed in any one of almost $1\times 10^{17}$ ways ($(10\times 5)^{10}$). To make any progress in such a vast search space, any pre-clinical discovery strategy must deliver \emph{high-throughput} screening coupled to \emph{high-fidelity} modelling.


% In contrast, calibrated, high-fidelity, cellular automata (CA) models coupled to highly non-linear search via genetic algorithms (GAs) have demonstrated promising opportunities to efficiently identify more effective candidate protocols~\cite{Angus2014}. However, the full potential of the GA approach requires a very fast execution time, and previous methods were highly constrained in this regard, requiring over 40~min for a single candidate radiotherapy scheme to be tested. As such, prior work fixed the dose fraction (1.25 or 2.0 Gy), and explored only the fractional delay dimension space. To truly leverage the power of high-fidelity numerical simulation, a step-change in candidate protocol testing throughput is needed.

% Wojtek calculations on total candidates tested:
% V1: 100 * 80 * 4 * 8 = 256 000
% V2: 200 * 80 * 4 * 24 = 1 536 000
% V3: 200 * 80 * 4 * 12 = 768 000
% V4: 200 * 80 * 4 * 22 = 1 408 000
% V5: 100 * 80 * 4 * 25 = 800 000
% V6: 100 * 80 * 4 * 25 = 800 000 - retain 10% = 0.9*99 + 1 = 90.1 = 720 800
% V7: 50 * 20 * 4 * 30 = 120 000 - retain 10% = 45.1 = 108 120
% V8: 50 * 80 * 4 * 272 = 4 352 000 - retain 10% = 45.1 = 3 921 152

% Total: 9 518 072
% Total without retain: 10 040 000

Here we introduce and demonstrate the validation of a high-fidelity, high-performance computational model of human breast cancer analogue, EMT6/Ro spheroids, leveraging state-of-the-art computational approaches on Graphical Processor Unit (GPU) architectures coupled to GA search, an approach we call `GPU-GA', and apply this approach to optimal radiotherapy scheme discovery, at scale. By analysing over 9.5 million candidate protocols, the GPU-GA approach yields improved tumour suppression outcomes of between 4.0\% and 4.5\% versus prior state-of-the-art computational search outcomes under two clinically relevant benchmark constraints, respectively. Significantly, by extending the search space beyond the state-of-the-art constraints, we identify candidate protocols with improved fitness scores of as much as 33.7\% over the best protocols identified in the past work~\cite{Angus2014} under the benchmark conditions studied. By pooling all highly effective protocols discovered in the GPU-GA search activity, we enumerate, and model, the frequency surface of these potent [dose,delay] sub-modules, finding an imputed maximum potency frequency location of 1.4~Gy fraction administered with a 15.5~h delay (after interpolation). Finally, by leveraging the outcomes of the response surface activity, we demonstrate how hand-crafted candidate protocols composed of the most potent sub-modules can be formed and tested, in the framework of computationally-supported treatment design.

Our work extends a previous rather low throughput/high-fidelity methodology~\cite{Angus2014} and builds on the promising field of `computational oncology' (c.f.~\cite{Gerlee2007,Patel2001,Dormann2002,Kansal2000,Kansal2000a,Kempf2015}) which aims to offer a~better understanding of cancer dynamics {\it `in silico'} being the base for improving therapeutic outcomes {\it in vivo}. Importantly, we based on our previous work (c.f.~\cite{Piotrowska:2009gj,Angus:2010mo,Angus:2013id}) where we show that computational cellular automaton (CA)~models of EMT6/Ro spheroid growth can be successfully calibrated to a broad range of experimental data including 18 independent experimental multi-fraction studies~\cite{Otsuka2011,Sugie2006}. Achieving that designed model required  direct modelling of cell metabolism (depending on the local environmental conditions), cell division, DNA damage and repair processes following known biological systems. This provides an extremely promising baseline for the introduction of radiotherapy and/or chemotherapy modules to investigate therapeutic approaches. To this point, of the few authors that have attempted to implement a~computational tumour with a~therapeutic model 
(e.g.~\cite{Zacharaki2004,Stamatakos2006,Kempf2010, Powathil2012,Powathil2013,Kempf2013}) none of them have fully, if at all, calibrated the computational model to experimental data nor applied a~systematic search of the possible treatment protocols. On the other hand, our quasi-3D CA models of avascular tumour growth, built over several years and rigorously calibrated and tested at each stage of development, provide a rich, \emph{high-fidelity} computational model of tumour growth under irradiation.

Central to the high throughput approach, we develop in the present work, is the translation of an existing high-fidelity EMT6/Ro CA model of avascular tumour growth from its parallelised, classical CPU-based {\sc Matlab} language implementation into a parallelised GPU-architecture C++ implementation, delivering c. 717x speed up in candidate protocol evaluation times. As such, we leverage similar approaches in the rapidly emerging field of high-throughput screening (HTS), where a mixture of processor-, big-data-, statistical search/learning tools-, and novel computational architectures are converging to deliver rapid breakthroughs in molecular candidate identification~\cite{Liu2017,Lightbody2019}.

Taken together, we demonstrate the power of GPU-GA computational biology to rapidly and effectively search within a vast solution space for candidate protocols that could be explored in the clinic. Indeed, GPU-GA has much potential for computational oncology research, as it could be applied to any cell line with sufficiently available validation data, and could lead to the rapid identification of radiotherapy schemes to be tried in the clinical setting.

% 0.18s per evaluation; "We achieved an average speed of 8 0000 simulations per hour using 4 NVIDIA V100 GPUs com-pared to about 110 simulations per hour using 13 10-core CPUs reported in"  -- section 4.4
% Num_candidates tested .. ~ 100k vs. ~ 1k
% 0.18sec vs. 15mins
% previous: 1.75 sim/minute
% new: 1333sim/minute


% Next, using GAs, we explored thousands of alternative multi-fraction protocols 
% and compared their performance to clinical baseline approaches. The protocols obtained by this method gave an average improvement of 9.4\% (max benefit 16.5\%) and 7.1\% (13.3\%) improvement (reduction) on tumour cell count compared to the two considered benchmark protocols, respectively, over just a~ single week of equivalent treatment. Hence, by implementing and analysing calibrated computational CA~models of tumours, we are well placed to discover novel clinically relevant, treatment protocols in this innovative research area.
% \madd{
% Nevertheless, due to the stochastic nature of our CA,~every treatment or benchmark protocol should be 
% tested over varying digital tumours and with several random seeds and the results 
% should be compiled and reduced using standard statistical methods (including 
% statistical tests), generating computational costs.  
% Moreover, even the use of cellular 
% automata models to investigate a~vast space of possible protocols is 
% challenging. For instance, to define the multi-fraction protocol one needs to 
% give a~number of fractions per day, timing of each fraction within a~day and 
% intensity (dosage) of each fraction. So, considering only a~`10 fraction' 
% program with fixed dosage, with time-gaps between fractions in 
% \{18,18.5,...,29.5,30\} hours, one obtains 95 trillion different protocols. In the presented work, we rise beyond previous restrictions regarding the investigated protocols (fixed fractional doses) and considered much bigger protocol space. To reach that aim, a very fast simulator is required. Thus, we decided to convert our existing CPU-based paralleled code implemented in the {\sc Matlab} programming environment (that can be downloaded from http://dx.doi.org/10.6084/m9.figshare.1227531) to GPU-based paralleled code implemented in C++.}

%-------------------------------------------------------------------------

\section*{Results}


\subsection*{Defining the search problem}

Following previous work \cite{Angus2014}, we focus our attention on two clinically relevant benchmark protocols \cite{Rosenstein:2004vs,Bentzen2008, Whelan2002}, both delivering 10~Gy total irradiation in multi-fractions~\cite{Rosenstein:2004vs,ORourke:2009,BoardoftheFacultyofClinicalOncology:2006wq}, over a virtual 5 day period (e.g. Mon-Fri): 
\begin{enumerate}
    \item a two fraction per day, 1.25~Gy per fraction protocol, with 6~h/18~h time delays between doses given at e.g. 9am/3pm, daily --- hereafter `Benchmark I', or BMI,
    \item a one fraction per day, 2~Gy per fraction protocol with doses given every 24~h e.g. at 9am ---  hereafter, `Benchmark II', or BMII.
\end{enumerate}

Let $\mathfrak{P}$ be a set of all protocols $p_i$ composed of a sequence of $k$ pairs of an irradiation dose, $d_i^j \in \mathfrak{D}$ (where $\mathfrak{D}$ is a set of allowed sizes of doses, in Gy, $j\in \{1,\ldots, k\}$), and a time delay  representing wait-times between the previous fraction and the current one, $t_i^j \in \mathfrak{T}$ (where $\mathfrak{T}$ is a set of allowed wait-times, in h), such that  $p_i = ((d_i^1,t_i^1),\dots,(d_i^k,t_i^k))\in \mathfrak{P}$ (for the first given dose, the corresponding wait-time should be interpreted as the time from the beginning of the simulation). Then, according to the definition, BMI and BMII protocols can be represented as $p_{BMI} \equiv ((1.25,0),(1.25,6),(1.25,18),(1.25,6),(1.25,18),(1.25,6),(1.25,18),(1.25,6))$ and $p_{BMII} \equiv ((2.0,0),(2.0,24),(2.0,24),(2.0,24),(2.0,24))$, respectively.

Now, given a function $f$ to determine the fitness of a protocol (see the \nameref{sec:materialsandmethods} section for the definition and the methodology applied to obtain the fitness over multiple synthetic tumours), the general search problem resolves to,
\[
\max_{p_i\in \mathfrak{P}} f(p_i), \quad \text{such that} \quad \sum^k_{m=1} d^m_i \leq 10.
\]
The constraint $\sum^k_{m=1} d^m_i \leq 10$ is added to limit the total sum of irradiation doses by a reasonable amount taking into account negative health consequences~\cite{Rosenstein:2004vs,ORourke:2009,BoardoftheFacultyofClinicalOncology:2006wq}. Note that for protocols with a sum lower than 10~Gy we can always improve (or not worsen, at least) the fitness function, but for $2$ protocols with a similar fitness function, the radiologists may prefer the one with a lower sum of doses, so in the search space we consider also protocols with a sum of doses lower than $10$~Gy.


In \cite{Angus2014}, for BMI, the fractional dose was constrained to $\mathfrak{D}' = \{1.25\}$, and time-delays were explored in 30 minute gradations with a minimum interval of 4~h, up to 26~h, $\mathfrak{T}' = \{4,4.5,\dots,25.5,26\}$, while for BMII $\mathfrak{D}'' = \{2.0\}$ and $\mathfrak{T}'' = \{10,10.5,\dots,31.5,32\}$, meaning that for each benchmark case the delay options considered had a 22~h span available and so $|\mathfrak{T}'|=|\mathfrak{T}''|=45$. It was also assumed that the first dose is always given in the first possible time slot, at the beginning of the simulation. The total dose constraint ($\leq$ 10~Gy) implies that $k \leq 8$ under BMI and $k\leq 5$ under BMII search conditions, respectively. To estimate the number of feasible protocols, under given constrains, we implemented and ran a simple program~\cite{SourceCUDA}, which for BMI and BMII gave as about $3.0\times 10^{11}$  and $4.1\times 10^6$ protocols, respectively, showing the size of the space for considered problem.


Nevertheless, the high-speed throughput gain of the present approach encourages a dramatic increase in the search space for a second phase of experiments, where in addition to searching over $\mathfrak{T}$ we also search over a range of irradiation \emph{doses} from 0.25~Gy up to a given maximal fractional dose, $d^{max}$, i.e. $\mathfrak{D} = \{0.25,0.50,\dots,d^{max}\}$. In the considered research, it was assumed that the minimum considered delay and wait-time is 6~h, which means that up to 20 fractions might be delivered over a 5 day treatment, implying that $k\leq 20$. It was also assumed that the total delivered dose must be lower or equal to 10~Gy. This leads to an enlarged search space size, for (say) $d^{max} = 5.0$~Gy, with at least $1.39 x 10^{15}$ protocols, estimated as follows: first, we easily estimate the number of all protocols with doses summing up to $10$~Gy, without the limit for a single dose equal to $5$~Gy, by realising that such a number is just equal to the number of distributing 40 minimal doses ($0.25$~Gy) in 20 time slots which is $\binom{59}{19}$. Then, we subtract protocols that have a single dose greater than $5$~Gy. If such a dose is equal to $K$~Gy ($K \in \{5.25, 5.5, \ldots, 10\}$, so such a dose would have a number of minimal doses ($0.25$~Gy) from the set $\{21, 22,\ldots, 40\}$), then we have $2\times \binom{59 - 4\times K - 1}{40 - 4\times K}$ protocols in which such a dose is in the first or in the last time slot and $(59 - 4\times K - 1)\times \binom{59 - 4\times K - 2}{40 - 4\times K}$ protocols in which such a dose is in one of the time slots in the middle. Such combinatorial considerations imply that exhaustive, brute-force, search is not applicable under current computational architectures, but instead lend themselves to highly non-linear search strategies such as evolutionary search, as is undertaken here.

\subsection*{Establishing the fidelity of the GPU model}

First, the fidelity of the C++/GPU implementation of the underlying model to the original parallelised {\sc Matlab} version~\cite{Angus2014} was verified. An intermediate version of the code was written in C++~\cite{SourceCPU}, which accurately represented the dynamics of the original model, but was fast enough to permit baseline comparisons with the developed GPU code. Two forms of verification were conducted -- single step tests (unit tests) and whole run test (integration tests). Using a single tumour from the library, under two different irradiation protocols (a single 20~Gy dose, and a 5 day/2~Gy per day program) the output of the {\sc Matlab} and C++ code were compared and found to exactly match over both unit- and integration- testing regimes~\cite{BachelorThesis}. Next, the GPU implementation~\cite{SourceCUDA} was compared to the intermediate C++ implementation (run on CPU) by comparing the number of occupied sites at the end of an equivalent 5 day treatment period followed by 5 day regrowth period, for 60 randomly generated protocols having total dose less than or equal to 10~Gy. Each protocol was run over 10 test tumours (for details see \nameref{sec:lib} section), for a total of 100 (GPU) or 48 (C++/CPU) replications each. The GPU implementation was found to provide high-fidelity to the base C++ implementation (Fig. \ref{fig:CPUvsGPU_normal}, panel A). Two statistical tests were conducted. First, t-test~\cite{SciPyTTest} was carried out to compare the averages of the results of both (GPU and CPU) implementations (Fig.~\ref{fig:CPUvsGPU_normal}, panel B). Second, Kolmogorov-Smirnov test~\cite{SciPyKSTest} was conducted to investigate the normality of the distribution of the new implementation (Fig.~\ref{fig:CPUvsGPU_normal}, panels C). Finally, 2\,000 evaluations of a single randomly selected protocol were conducted and the distribution of the final number of occupied sites was visualised (see Fig.~\ref{fig:CPUvsGPU_normal}, panel D).


\subsection*{Performance comparison of candidate protocols discovered by GPU-GA}

\subsubsection*{Search under BMI \& BMII}

To accurately assess the fitness of any candidate protocol against a standard benchmark, the fitness methodology (described in \nameref{sec:materialsandmethods} section below) was undertaken for both the clinical benchmarks (BMI and BMII), and the top three state-of-the-art candidate protocols discovered by a previous study~\cite{Angus2014} (i.e. BMI-1, -2, -3, BMII-1, -2, -3). For each protocol, the mean fitness scores and standard deviation was calculated based on fitness function~\eqref{eq:final_fit_fun} over 100 evaluations (random seeds) for each of 10 synthetic tumours from the study library (for details see \nameref{sec:materialsandmethods} section).

%% BMI - table
\input{bm1_table} % tab:ga_bmi_results

%% Results figure


Panel A of Fig.~\ref{fig:benchmark_comparison} and Panel A of Table~\ref{tab:ga_bmi_results} present the results of the performance comparison between the BMI standard and the previous state-of-the-art~\cite{Angus2014} under the fitness methodology of the present work. In Panel B of Table~\ref{tab:ga_bmi_results} the best performing protocol candidates identified under GPU-GA search are reported where fractional doses of \emph{up to} 1.25~Gy were considered, with the top, average fitness outcome of 1153.62, representing a 4.0\% improvement over the prior BMI state-of-the-art, or 9.1\% gain over the BMI outcome (in terms of tumour suppression, based on formula \eqref{eq:supression}). In all cases, the top three GPU-GA protocols were discovered by a GA search strategy (see \nameref{sec:GA_approach} section for more details on GA methodology).

%% BMII - table
\input{bm2_table} % tab:ga_bmi_results

Panel B of Fig.~\ref{fig:benchmark_comparison} and Panels A and B of Table~\ref{tab:ga_bmii_results} give the equivalent results under the BMII environment. Here, fitness gains of 4.5\% and 8.2\% were obtained relative to the prior state-of-the-art and baseline BMII protocol, respectively (according to formula \eqref{eq:supression}). Under BMII settings the GPU-GA strategies with the best performance were found to be even distributed from tournament, simple or roulette selection.

\subsubsection*{Multi-parameter search beyond BMII}

In a second phase of search, the maximum fractional dose, $d^{max}$ was incrementally stepped beyond 2.0~Gy (as in BMII), in 0.5~Gy steps towards 4.5~Gy, whilst keeping the total, 5 day, treatment dose at or below 10~Gy. As noted earlier, by relaxing the constraints on $d^{max}$ the search space increases dramatically, potentially frustrating the GPU-GA technique in discovering more promising protocols. However, results presented in Table~\ref{tab:best_ga_larger_dose_results} and given in Panel C of Fig.~\ref{fig:benchmark_comparison} demonstrate that the GPU-GA technique was highly effective in identifying potent candidate protocols under each set of search constraints provided.

%% BEST - larger doses - table
\input{best_table} % tab:best_ga_larger_dose_results

%Tumour suppression gains over the best performing GPU-GA candidate from the BMII ($d^{max} = 2.0$~Gy) from 6.1\% ($f(p)=1193.99$, $d^{max}=2.5$~Gy, GA2.5-1 protocol) to 30.6\% ($f(p)=1273.7$, $d^{max}=4$~Gy, GA4.0-1 protocol) were observed in the discovered candidate protocols. As the experiment settings moved from $d^{max} = 2.5$~Gy to $d^{max} = 4.0$~Gy, in reference to the best state-of-the-art BMII protocol (BMII-3, Table~\ref{tab:ga_bmii_results} Panel A) gains of 10.4\% and 33.7\% were observed. Comparing to the baseline BMII protocol (BMII Table~\ref{tab:ga_bmii_results} Panel A), gains are 13.8\% and 36.3\% respectively. A natural progression can be observed in the fitness outcomes discovered in the 10 best performing candidate protocols of the GPU-GA search in Fig.~\ref{fig:benchmark_comparison} from the $d^{max}$ 2.5~Gy to 4.0~Gy settings, before a decline is observed for the 4.5~Gy setting.

Tumour suppression gains over the best performing GPU-GA candidate from the BMII ($d^{max} = 2.0$~Gy, GA2.0-1 protocol) from 6.1\% ($f(p)=1193.99$, $d^{max}=2.5$~Gy, GA2.5-1 protocol) to 30.6\% ($f(p)=1273.7$, $d^{max}=4$~Gy, GA4.0-1 protocol) were observed in the discovered candidate protocols. 
As the experiment settings gradually moved from $d^{max} = 2.5$~Gy to $d^{max} = 4.0$~Gy, in reference to the best state-of-the-art BMII protocol (BMII-3, Table~\ref{tab:ga_bmii_results} Panel A) gains of 10.4\% (GA2.5-1 protocol) and 33.7\% (GA4.0-1 protocol) were observed. Comparing these GPU-GA results with the baseline clinical BMII protocol (BMII Table~\ref{tab:ga_bmii_results} Panel A), we can observe gains of 13.8\% and 36.3\% respectively. A natural progression can be observed in the fitness outcomes discovered in the 10 best performing candidate protocols of the GPU-GA search in Fig.~\ref{fig:benchmark_comparison} from the $d^{max}$ 2.5~Gy to 4.0~Gy settings, before a decline is observed for the 4.5~Gy settings.

By inspection of the discovered protocols in Table~\ref{tab:best_ga_larger_dose_results} (GA4.5-1 and -2) it can be seen that a high degree of heterogeneity was present in the fractional doses for the 4.5~Gy setting, compared with the more even fractional doses of the GA4.0-1 and -2 candidates. It can be hypothesised that as the fractional dose approaches the total dose allowable, the optimisation surface becomes much more complex with a larger fraction of illegal protocols (i.e. failing the total dose constraint) adjacent to a legal, but well performing protocols.

\subsection*{Hand-crafted high-potential candidates through sub-modular pooling}

A natural question arises from the GPU-GA search phase described above -- what might be driving the success of the discovered protocols? and, could a \emph{hand-crafted} protocol, informed by the characteristics of the GPU-GA discovered protocols, obtain similar, or even better, performance? Previous work has already hinted at likely reasons for the value of certain protocol dose--delay sub-modules, finding that cell cycle synchronicity might play a role~\cite{Angus2014}. Following this intuition, we take the best 10 performing protocols from each of the seven $d^{max}$ constraints applied across the BMI, BMII and multi-parameter search phases $\{$1.25~Gy, 2.0~Gy, 2.5~Gy, $\dots$, 4.5~Gy$\}$ (the top 2 of which are shown in Table~\ref{tab:best_ga_larger_dose_results}), decompose them into dose--delay sub-modules and then pool all of these together to compute the occurrence density of each sub-module across these high performing protocols (see Fig.~\ref{fig:density_composite}). As can be seen in the figure, a highly frequent peak arises around a fractional dose of 1.4~Gy and delay of 15.5~h, with a sharp, tightly defined peak at 0.7~Gy, 0.5~h also present. The existence of these peaks strongly suggests the presence of particular modalities of multi-fraction protocol design which are potent for the EMT6/Ro cell line, at the stage of growth modelled. If this were not the case, one might expect, for example, either a uniform or Gaussian-like density pattern (somewhat random relationship), or a density pattern matching a particular heuristic (e.g. dividing the given $d^{max}$ by a given number of fractional doses, over 120~h).

%% Hand-crafted table
\input{hc_table} % tab:manual_results

Taken together, a variety of hand-crafted protocols were developed to examine whether a protocol which repeats the high-frequency sub-module, or modules, would be as potent as candidate protocols discovered by GPU-GA (see Table~\ref{tab:manual_results}). Three protocols were developed on the basis of the (1.4~Gy, 15.5~h) sub-module peak: HC-1 repeats the module 7 times; protocols HC-2 and HC-3 replaces the first fraction with the (0.7~Gy, 0.5~h) module (HC-2, HC-3) and then additional adds the same to the end of the protocol (HC-3). Finally, HC-4 was also developed with a simple heuristic based on the findings of the sub-module density surface, namely to adjust the timing slightly from HC-1 so as to deploy uniform dose fractions evenly across the 120~h treatment window but sill close to the main density peak, reaching as close as possible to the 10~Gy total dose limit.

With a maximum dose of 1.4~Gy, the hand-crafted protocols can be compared to previous results lying between BMI (1.25~Gy) and BMII (2.0~Gy) constraints. There, GA1.25-1 (Table~\ref{tab:ga_bmi_results}) with fitness 1153.62 and GA2.0-1 (Table~\ref{tab:ga_bmii_results}) with fitness 1173.96 can be compared to the performance of the hand-crafted protocols HC-1 and HC-2 with fitness of 1147.05 and 1148.79, respectively. Linear interpolation between the performance of GA1.25-1 and GA2.0-1 would suggest that a fitness of 1157.7 would be an approximate ceiling for GPU-GA discovery at 1.4~Gy per fraction. Of the hand-crafted protocols, HC-1 and HC-3 reach close to this level, but the heuristically guided HC-4 achieves an almost identical, theorised GPU-GA like fitness ($f(p) = 1157.83$). These results lend support to the potential of computationally-supported treatment design to efficiently locate candidate protocols for future examination in the clinical setting.


%-------------------------------------------------------------------------
% \subsection{GA results} general idea of GA approach, {\bf fig.2} representing the scheme (like in Plos One paper), estimation of the size of the possible protocol space(?) , GA performance with constraints (e.g. total dose < 10 Gy; fractional dose < Y Gy; + no more than X/fractions per day), presentation of the best protocols ({\bf table 1 continuation or table 2}), information about the convergence ({\bf supp fig.S1}) + {\bf fig.3 combined} presenting results

% \subsection{Comparison of benchmark and GA algorithm results}
% \wadd{To compare benchmark protocols BMI and BMII and their corresponding best sub-protocols found in~\cite{Angus2014} (BMI 1 - BMI 3 and BMII 1 - BMII 3 respectively) with the best protocols found by our GA algorithm (GA1.25 1-GA4.5-2), we focused on protocol fitness score. For each protocol configuration, we calculated the mean fitness scores and standard deviations calculated based on fitness function~\eqref{eq:final_fit_fun} defined in Section~\ref{sec:GPU:implem} evaluated 100 times for each of 10 tumours from study library, for details see Section~\ref{sec:lib}. Besides, we calculate the p-value using a one-tailed test to assert the greater fitness score values of GA algorithm protocols over the benchmark results. For the statistical test, we compare the fitness scores for protocols with constraints of 1.25~Gy dose, GA1.25 1 - GA1.25 3 with the BMI, and for all protocols with the maximum doses of 2.0~Gy or above, GA2.0 1 - GA4.5 2 with the BMII protocol. The formula used for p-value calculation is available in \cite{SciPyTTest}.}






%-------------------------------------------------------------------------


%-------------------------------------------------------------------------

\section*{Discussion}

% \mon{Include a Discussion that summarizes (but does not merely repeat) your conclusions and elaborates on their implications. There should be a paragraph outlining the limitations of your results and interpretation, as well as a discussion of the steps that need to be taken for the findings to be applied. Please avoid claims of priority.}

%% Summary of main findings
We have shown the development and application of a high-throughput, high-fidelity, computational screening approach to therapeutic irradiation design for EMT6/Ro spheroids, GPU-GA, which effectively combines state-of-the-art computational architectures with highly non-linear search technology to discover high potential candidates for further study. Through careful calibration of the underlying model, and then translation to GPU articulated form, high-fidelity irradiation protocol evaluations were achieved with c. 717x speed-up relative to the prior, high-fidelity, low-throughput, state-of-the-art~\cite{Angus2014}. The GPU-GA strategy thus enabled the facile exploration of the immense search space produced by even discretised irradiation protocol composition over a multi-day treatment window.

By searching near two clinically relevant benchmarks, the GPU-GA strategy yielded significant tumour suppression gains over both simulated clinical benchmark outcomes and prior, throughput-limited GA search. Beyond the clinical benchmarks, relaxed search constraints saw even larger potential gains. Furthermore, by pooling modular components of the most successful discovered candidates, simple, heuristic-led candidate protocols could be built and tested, yielding close to hypothetical optimal results, even though GPU-GA search was not conducted specifically near the hand-crafted protocol location. 

%% Relationship to other theoretical/in-silico -like studies
Our results thus contribute to, and advance, the emerging consensus from theoretical and simulation studies which have identified significant opportunities for treatment efficacy gains beyond the strictures of received, clinical practice. Be it via simulations of ordinary differential equations~\cite{Alfonso2020}, non-linear or linear surrogate modelling~\cite{Montaseri2020}, or agent-based \emph{in silico} modelling~\cite{Kempf2015}, studies that examine deviations from standard `2~Gy per (week) day' treatment modalities have shown that shorter total treatment regimes, hypofractionation, or harnessing immune-response dynamics with immunotherapy drug targeting each present opportunities for treatment optimisation. Whilst none of these related works present high-fidelity model \emph{validation} to a given cell-line, as has been achieved in the current work, all of them present the same conclusion despite their independent and differing model assumptions and approaches, namely that opportunities exist for treatment advance relative to the standard RT approach, and that these opportunities can be explored economically via \emph{in-silico} means.


%% Relationship to clinical work
Our results also align with the findings of the limited clinical experimentation in protocol design that has been conducted in recent years. Notable among these is that of the UK Standardisation of Breast Radiotherapy (START) trials conducted over 1999 and 2001 (START-A $n=2236$, START-B $n=2215$)~\cite{Bentzen2008, Whelan2002}. Ten year follow up studies of the cohorts confirmed that shorter, `more convenient', hypofractionated (RT fractions $> 2.0$~Gy) were no less effective than the world standard longer, 2.0~Gy RT fraction protocols, and were thus adopted by UK cancer treatment centres~\cite{Whelan2010, Haviland2013}. In our multi-parameter search phase, all of which was conducted within a fixed total dose hypofractionated setting, significant, and increasing, potential gains were discovered from 2.5~Gy to 4.0~Gy RT fractions (Fig.~\ref{tab:best_ga_larger_dose_results}). Yet, interestingly, the GPU-GA protocols identified did not follow a regular, 24~h `daily' schedule as the clinical trials considered. Given the success of the computationally-supported protocol design (Table~\ref{tab:manual_results}), together with the clinical findings, a reasonable proposal for next-phase testing would be a hypofractionated, sub-24~h regular, protocol fashioned along the lines of HC-4.

%% Opportunities
With the benefit of high-throughput, high-fidelity numerical screening that GPU-GA affords, several promising lines of inquiry are now open. First, whilst the present study is built on the EMT6/Ro mammary mouse cell line, GPU-GA could effectively be extended to any cell-line where sufficient \emph{in vitro} empirical data are available. Given the widespread use of the rigid, accepted protocols in the clinical setting across cell lines~\cite{Thompson2018} there seems a high likelihood that similar potential tumour suppression gains will be achieved in other cell lines. Second, and of particular interest for clinical settings of low-compliance due to a variety of factors, GPU-GA could be used to explore the robustness of a given protocol under perturbation. For example, what is the relative impact of a single missed fraction? what if the fraction is missed early, or late in the treatment period? can down-stream impacts of protocol non-compliance be mitigated by adapting the later sequence of fractions? in what way? Whilst these questions are easy to pose, rigorous clinical exploration of these variations would be prohibitively expensive, and time-consuming, yet these are simply alternative specifications to run under GPU-GA and would be entirely feasible for future studies to tackle. Third, and in line with recent calls for more preclinical and clinical trials to `unravel' the best approach to combined RT and immunotherapy scheduling~\cite{Wang2018} GPU-GA could be extended by the development of a combined RT---immunotherapy module to enable rapid prototyping, screening and discovery of candidate joint therapy schedules to be taken to the next phase.

%% Limitations
Of course, the GPU-GA strategy outlined herein is not without limitations. First, high-fidelity model calibration depends strongly on the empirical evidence available. Not all cell lines have been studied so rigorously as EMT6/Ro, and, the calibration of the underlying mechanisms of the present model was only achieved under a relatively small (but clinically relevant) spheroidal scale. The dynamics of other cell lines, or growth dynamics under vascularisation will differ substantially and must be organically modelled prior to GPU-GA implementation. Second, the path from candidate protocol discovery to clinical translation will require all of the usual caveats, and lead to some additional challenges. For instance, the optimal fractional delay of the present work, in line with the findings of previous findings~\cite{Angus2014}, of around 15-17~h for EMT6/Ro cells, would translate to RT fractions being administered at variable times through the 24~h period over a treatment regime (e.g. 9~am, 1~am, 5~pm, 9~am, ...). Clinical implementation would require a substantial change to standard day-light hour practices in clinical settings, not to mention patients may require significant support to meet the timetable. Given the complex nature of human systems, irregular RT fractions could also see interactions with other circadian-rhythms of human biology. And, larger fractions, delivered as part of an irregular, quasi-optimal treatment program, may have deleterious side-effects, relative to regular, low-dose fractions. These considerations provide fertile ground for future modelling and discovery across a range of scales.



%-------------------------------------------------------------------------
\section*{Materials and Methods}
\label{sec:materialsandmethods}

\subsection*{Underlying model: source, validation \& calibration}

The high throughput GPU-GA methodology introduced and demonstrated in this study implements exactly a previously published low-throughput, high-fidelity computational model of avascular EMT6/Ro spheroid growth~~\cite{Piotrowska:2009gj, Angus:2010mo, Angus:2013id, Angus2014}. The most recent version of the model~\cite{Angus2014} was re-implemented in C++ \cite{SourceCPU} and then prepared for GPU architectures~\cite{SourceCUDA} in this study. The model takes into account several biologically important components of tumour growth and cellular response to irradiation such as: the diffusion of nutrients (oxygen, glucose) and metabolic waists; cell cycles with distinguishable cell phases;  differentiated cellular metabolism (aerobic or anaerobic, proliferating or quiescent) which is responsive to the cell's environmental nutrient concentrations and local pH. The model was developed to replicate the biological dynamics of a specific mouse cancer cell line (EMT6/Ro), a widely used analogue of human breast cancer which also has abundant experimental studies available. Moreover, the model was calibrated at each step of development, including its response to 18 independent multi-fraction irradiation protocols tested in the laboratory~\cite{Otsuka2011,Sugie2006}. The calibration and validation of the model's performance was accomplished with reference to a~broad spectrum of tumour characteristics including: number of cells; saturation size; tumour volume; tumour doubling time; thickness of the proliferating rim; cell phase population fraction; onset and progression of necrosis; and effective dose induced by multi-fraction irradiation. For details, see~\cite{Angus2014} and Supplementary Information within.

% The previously established high-fidelity numerical simulation model of avascular EMT6/Ro growth and response to irradiation 

% In this work, we extend our high-fidelity numerical 
% simulation approach to examine yet untried protocols within the vast space 
% of available protocols to find candidate protocols that offer statistically significant improvements over benchmark protocols presently used in 
% radiotherapy clinics. Our simulation model described in~\cite{Angus2014}

%\subsection*{Benchmark protocols}
%-------------------------------------------------------------------------
\subsection*{The tumour case library}\label{sec:lib}

Due to the stochastic nature of the tumour growth and radiation response model, we follow the approach presented in~\cite{Angus2014} and perform evaluation of all considered protocols across a multi-tumour case library. The case library consists of ten 10-day old tumours developed {\it in-silico} as described in~\cite{Angus:2013id} from an initial seed population of 200 cancer cells (10 cellular automata lattice grid sites) placed in a well-mixed replenished substrate (glucose concentration: 5.5~mM, oxygen concentration: 0.28~mM, with pH level maintained at 7.4). The tumours were then grown {\it in silico} for 10 days without any radiation interference. For the full characterisation of the developed tumour library we refer the reader to~\cite[Supp. Inf., Table ~S2]{Angus2014}. At the end of the 10-day growth period, the state of each tumour was saved, and stored in the case library for the future use.


\subsection*{GPU implementation: acceleration, fidelity \& normality} 

The key feature of the present study is to articulate the original EMT6/Ro {\sc Matlab} model implementation~\cite{Angus2014} to a new general-purpose C++/GPU implementation to obtain a step-change in protocol evaluation. Applying general purpose GPU programming to obtain high-throughput numerical simulation of candidate protocols was considered highly promising due to the parallelizable nature of cellular automata computation and the fact that evaluation of a radiation protocol requires multiple independent simulation runs. The architectural idea of the new implementation was to use leverage massive parallelism of the GPUs not only to parallelize the processing of single cells within a simulation but also to concurrently run a batch of simulations. With the new GPU implementation~\cite{SourceCUDA}, an average speed of 80\,000 simulations per hour was achieved using 4 NVIDIA V100 GPUs. This compares to about 111 simulations per hour using 13 10-core CPUs as reported in~\cite[Supp. Inf., Numerical Implementation: Details]{Angus2014}, giving c. 717 improvement.

To ensure fidelity of the new GPU implementation~\cite{SourceCUDA}, an intermediate version of the code written in standard C++ was used, which accurately copied the behaviour of the original {\sc Matlab} simulation but was fast enough to provide a convenient baseline to compare the GPU implementation with~\cite{SourceCPU}.  Given the importance of stochastic dynamics in the underlying model, the C++ implementation required replicating exactly the {\sc Matlab} random number generator (Mersenne Twister with 19937 bits) and associated state initiation. The C++ implementation was rigorously analysed for any biases or implementation errors, until an exact replication of the original {\sc Matlab} implementation under both unit (single simulation step) and integration (outcome over a series of steps) compliance was achieved. Integration testing obtained an exact state match between 14,400 reference points between the {\sc Matlab} and C++ implementations (i.e. the model state every 10 steps) over a simulated 10 day tumour growth period.  From there, the C++/GPU accelerated articulation of the C++/CPU code was prepared. A series of randomly generated protocols was evaluated with both CPU and GPU simulations and the results were statistically compared. For details, c.f.~Fig.~\ref{fig:CPUvsGPU_normal} panel A together with ~Fig.~\ref{fig:CPUvsGPU_normal} panel B where p-values of the two-tailed t-test comparing corresponding GPU and CPU distributions are reported.

Finally, the normality of the GPU implementation was examined using the fast GPU implementation of the model. The final number of occupied grid sites was chosen as a representative measure of the tumour state because it is used to calculate the GA fitness function. To check if a data set can be well described by a normal distribution, a single irradiation protocol was randomly selected, and then 2\,000 evaluation of that protocol were run on the randomly selected tumour from the library. In Fig.~\ref{fig:CPUvsGPU_normal} (D)  a histogram of the results is plotted which, together with the Kolmogorov-Smirnov test (p-value = 0.38), indicate that the null-hypothesis, i.e. that the distribution is normal, cannot be rejected. In Fig.~\ref{fig:CPUvsGPU_normal} (C)  p-values of Kolmogorov-Smirnov test for 60 randomly generated protocols comparing GPU and CPU implementations are presented.


\subsection*{The Genetic Algorithm (GA)}

\subsubsection*{GA Overview}\label{sec:GA_approach}

In order to find heuristically optimal protocols, we use genetic algorithms (GAs)~\cite{Holland:2012, goldberg} to explore the vast, combinatorial space of possible protocols. GAs are well suited to high dimensional, non-linear search, especially where quasi-optimal solutions are likely composed of modular sub-components.  In the GA approach irradiation protocols are encoded as genotypes represented as vectors. The quality (fitness) of genotypes is evaluated by a fitness function~\eqref{eq:final_fit_fun} for which the values are calculated using the main GPU implementation of the underlying computational model. The best genotypes are selected using a selection operator, and are later used to create new genotypes using crossover and mutation operators. This procedure is schematically presented in Fig.~\ref{fig:GA_scheme}. Together, the aim of the GA approach is to amplify the abundance of the most effective protocols, and protocol sub-modules, whilst retaining (and introducing) sufficient novelty to each generation to avoid the population becoming `stuck' within a locally-optimal (but perhaps not globally optimal) basin of attraction. Since each problem will have its own solution landscape, it is common practice to experiment with a variety of GA operators (see below) within the main selection, crossover, and mutation steps.

\subsubsection*{GA Resolution, constraints}
The CA model is designed with a resolution such that each hour between doses is split into 600 units of model time (a step). For our treatment protocols, we used a minimal step equal to 300 units, i.e. 30~min, given that smaller intervals between fractions may be difficult to deliver in the clinic. The full treatment time is set to 5~days (120~hours), which implies that each protocol should direct irradiation treatment over 240~time-steps. Additional constraints were established for possible fractional doses. First, following~\cite{Angus2014}, we assume that the sum of all dose values for a~single protocol should not be higher than 10~Gy to ensure that total delivered dose, affecting both the tumour and the healthy tissues, do not exceed a standard clinical practice for low-dose, multi-fraction, irradiation schemes \cite{Rosenstein:2004vs,ORourke:2009,BoardoftheFacultyofClinicalOncology:2006wq}. Moreover, the value of an acceptable single dose should be at a minimum 0.25~Gy and could be increased by 0.25~Gy per step, up to the maximal single dose ($d^{max}$), between 1.25~Gy and 4.5~Gy, depending on a particular experimental setting. In addition, to simulate realistic treatment protocols with doses given to the patient according to the scheduled intervals, we restricted the minimal time interval between doses to vary from 6 to 48 hours.

\subsubsection*{Protocol Representation}
In the implemented code, for GA, each protocol is represented by a sparse vector of 240 dose values, where each position corresponds to a specific point in time. Zeroed values in this representation indicate lack of dose at a corresponding time. A non-zero value in this representation indicates the fractional dose to deliver, at that time point. For example, a value of 1.25 in the fourth vector position would indicate that a 1.25~Gy fraction is delivered 2 hours (four times 30 minutes) after the initialisation of the treatment.

% For the GA model, a protocol is represented as a key-value pair of the absolute time-step and the value of the dose given at this time-step. This is a difference comparing to the original CA model, where the key-value pair consisted of dose value and time-step between previous and the current dose (time to the second dose), instead of the absolute time of application 
% The reason behind using two different representations is that the CA model was created first with the key-value pair representation. Now, during development of the GA model, performing various types of selection, crossover, and mutation operations might be non-trivial for such a representation. Thus, the new vector representation was introduced, which is more similar to standard candidates representation as an array of bits. Because conversion between two representations is very fast and computationally inexpensive, the CA model remained untouched and we convert protocols in each experiment.

\subsubsection*{The Main GA Loop}

% PoC, high-level concept:
% generation_0, G0
% step 1: COPY 4 'best' protocols from G0 via simple selection and take straight to G1. (leave the originals in the pool)
% step 2: SELECT 16 PARENTS from the G0 pool by some method.
% step 3: with 16 PARENTS, run Cross-over + Mutation to generate 36 CHILDREN which enter G1

Each GA generation $T$ consists of 40 protocols which, after fitness determination in the full EMT6/Ro GPU computational model, is used as the genetic material for the formation of the subsequent generation, $T+1$ (c.f. Fig.~\ref{fig:GA_scheme}). In the initial step of the GA algorithm, 10\% (i.e., 4) of the best protocols in generation $T$ (according to simple selection) are \emph{copied} from generation $T$ into generation $T+1$ without modification (and retained in the genetic pool of generation $T$). Next, 40\% of the best protocols (i.e., 16) are selected from generation $T$ to become \emph{parents} using one of three \textit{selection} operators: \textit{roulette}, \textit{simple}, or \textit{tournament}. Note, \emph{selection} may cause one or more protocols from the initial copy step to be also present in the parent set. In a third step \emph{crossover} and \emph{mutation} operators are carried out in sequence to form 36 \emph{child} protocols. Crossover uses one of the available operators: \textit{single-point crossover}, \textit{two-point crossover}, or \textit{uniform crossover}. Mutation uses one of the available operators: \textit{swap mutation}, \textit{split mutation}, \textit{dose time mutation}, or \textit{dose value mutation}. Thus, the 36 generated \textit{child} protocols are combined together with the initial 4, copied protocols, to create the new generation $T+1$. Each protocol in the $T+1$ generation is evaluated using EMT6/Ro GPU computational model and \textit{fitness} function. After a prearranged number of iterations, representing a five-day treatment period, followed by a five-day re-growth period, the experiment is finished. The particular type of \textit{selection}, \textit{crossover} and \textit{mutation} operators used is set in the configuration of a given experiment.



%-------------------------------------------------------------------------

\subsubsection*{The fitness function \& experimental setup}
\label{sec:fitness_function}

One of the crucial elements of our experiments is to determine the value of a fitness function $f$, required for GA as the fitness indicator. We use
\begin{equation}\label{eq:final_fit_fun}
   f(p_{i,j}) = 1\,500 - n_{i,j}, 
\end{equation}
where $p_{i,j}$ denotes the considered protocol $i$ evaluated on a single tumour $j$, 1\,500 is the maximal number of possibly occupied sites, $n_{i,j}$ denotes the number of the occupied sites after testing protocol $i$ on tumour $j$ (at day 10). In the performed experiments, we pass the treatment protocol into the CA model and obtain the fitness score. In order to assess the robustness of these results, each protocol is evaluated on 10 different tumours from the library using 2 GPUs, 4 times per GPUs per tumour. This allows us to calculate 80 samples for every single treatment protocol. Thus, the fitness for the particular tested protocol is the mean from the fitnesses of all its evaluations.

\subsubsection*{Calculating tumour suppression improvement}

To estimate the improvement of tumour suppression for a considered protocol $i$ ($ITS_i$) versus a reference protocol evaluated over 10 tumours we calculate the relative difference between the average number of occupied sites after testing protocol $i$ on 10 tumours ($\bar n_{i}$) and the average number of occupied sites for a reference protocol (tested on the same 10 tumours, $\bar n_{ref}$)
\begin{equation}\label{eq:supression}
    ITS_i=\frac{\bar n_{ref}-\bar n_{i}}{\bar n_{ref}}.
\end{equation}

% \subsubsection*{Experimental setup}

% A~single experiment starts with initial steps -- random protocols initialization and initial \textit{fitness} value calculation. Next, we perform the specified number of iterations through GA, each consisting of the creation of a new generation of protocols using \textit{selection} and \textit{crossover operators}, application of \textit{mutation operators} and  calculation of \textit{fitness} function value. Finally, all output data from the whole experiments are saved.


% The above rules for creating new protocols hold for all experiments, however, for all generations except the first one, we additionally transferred 10\% of the best protocols from the previous generation.

% After initializing the first generation, newly created protocols are passed into the CA model to compute a value of the fitness function. At this point, it is important to describe the representation of the protocols. 



% Section about different experiments and setups we were running.


%-------------------------------------------------------------------------

%\bibliography{scibib}

%\bibliographystyle{Science}

\begin{thebibliography}{10}

\bibitem{Thompson2018}
M.~K. Thompson, {\it et~al.\/}, {Practice-changing radiation therapy trials for
  the treatment of cancer: where are we 150 years after the birth of Marie
  Curie?}, {\it British Journal of Cancer 2018 119:4\/} {\bf 119}, 389--407
  (2018).

\bibitem{Rosenstein:2004vs}
B.~Rosenstein, S.~Lymberis, S.~C. Formenti, {Biologic comparison of partial
  breast irradiation protocols}, {\it International Journal of Radiation
  Oncology*Biology*Physics\/} {\bf 60}, 1393--1404 (2004).

\bibitem{ORourke:2009}
S.~F.~C. O'Rourke, H.~McAneney, T.~Hillen, Linear quadratic and tumour control
  probability modelling in external beam radiotherapy., {\it J Math Biol\/}
  {\bf 58}, 799--817 (2009).

\bibitem{BoardoftheFacultyofClinicalOncology:2006wq}
{Board of the Faculty of Clinical Oncology}, {Radiotherapy Dose-Fractionation},
  Royal College of Radiologists, London (2006).

\bibitem{Haviland2013}
J.~Haviland, {\it et~al.\/}, {The UK Standardisation of Breast Radiotherapy
  (START) trials of radiotherapy hypofractionation for treatment of early
  breast cancer: 10-year follow-up results of two randomised controlled
  trials}, {\it The Lancet. Oncology\/} {\bf 14}, 1086--1094 (2013).

\bibitem{Whelan2010}
T.~Whelan, {\it et~al.\/}, {Long-term results of hypofractionated radiation
  therapy for breast cancer}, {\it The New England journal of medicine\/} {\bf
  362}, 513--520 (2010).

\bibitem{Angus2014}
S.~D. Angus, M.~J. Piotrowska, A matter of timing: Identifying significant
  multi-dose radiotherapy improvements by numerical simulation and genetic
  algorithm search, {\it PLoS ONE\/} {\bf 9}, e114098 (2014).

\bibitem{Gerlee2007}
P.~Gerlee, A.~Anderson, An evolutionary hybrid cellular automaton model of
  solid tumour growth, {\it J. Theor. Biol.\/} {\bf 246}, 583--603 (2007).

\bibitem{Patel2001}
A.~Patel, E.~Gawlinski, S.~Lemieux, R.~Gatenby, A cellular automaton model of
  early tumor growth and invasion: The effects of native tissue vascularity and
  increased anaerobic tumour metabolism, {\it J. Theor. Biol.\/} {\bf 213},
  315--331 (2001).

\bibitem{Dormann2002}
S.~Dormann, A.~Deutsch, Modeling of self-organized avascular tumor growth with
  a hybrid cellular automaton, {\it In Silico Biol.\/} {\bf 2}, 0035 (2002).

\bibitem{Kansal2000}
A.~Kansal, S.~Torquato, E.~Chioccaeb, T.~Deisboeck, Emergence of a
  subpopulation in a computational model of tumor growth., {\it J. Theor.
  Biol.\/} {\bf 207}, 431--441 (2000).

\bibitem{Kansal2000a}
A.R.Kansal, S.~Torquato, G.~H. IV, E.~Chioccaeb, T.~Deisboeck, Simulated brain
  tumor growth dynamics using a three-dimensional cellular automaton, {\it J.
  Theor. Biol.\/} {\bf 203}, 367--382. (2000).

\bibitem{Kempf2015}
H.~Kempf, M.~Bleicher, M.~Meyer-Hermann, Spatio-temporal dynamics of hypoxia
  during radiotherapy, {\it PLOS ONE\/} {\bf 10}, e0133357 (2015).

\bibitem{Piotrowska:2009gj}
M.~J. Piotrowska, S.~D. Angus, {A quantitative cellular automaton model of in
  vitro multicellular spheroid tumour growth}, {\it Journal of Theoretical
  Biology\/} {\bf 258}, 165--178 (2009).

\bibitem{Angus:2010mo}
S.~D. Angus, M.~J. Piotrowska, The onset of necrosis in a 3d cellular automaton
  model of emt6 multi-cellular spheroids, {\it Applicationes Mathematicae
  (Warsaw)\/} {\bf 37(1)}, 69-88 (2010).

\bibitem{Angus:2013id}
S.~D. Angus, M.~J. Piotrowska, {A numerical model of EMT6/Ro spheroid dynamics
  under irradiation: Calibration and estimation of the underlying
  irradiation-induced cell survival probability}, {\it Journal of Theoretical
  Biology\/} {\bf 320}, 23--32 (2013).

\bibitem{Otsuka2011}
S.~Otsuka, {\it et~al.\/}, Compatibility of the linear-quadratic formalism and
  biologically effective dose concept to high-dose-per-fraction irradiation in
  a murine tumor., {\it Int J Radiat Oncol Biol Phys\/} {\bf 81}, 1538--1543
  (2011).

\bibitem{Sugie2006}
C.~Sugie, {\it et~al.\/}, Radiobiologic effect of intermittent radiation
  exposure in murine tumors., {\it Int J Radiat Oncol Biol Phys\/} {\bf 64},
  619--624 (2006).

\bibitem{Zacharaki2004}
E.~Zacharaki, G.~Stamatakos, K.~Nikita, N.~Uzunoglu, Simulating growth dynamics
  and radiation response of avascular tumour spheroids---model validation in
  the case of an emt6/ro multicellular spheroid, {\it Computer methods and
  programs in biomedicine\/} {\bf 76}, 193--206 (2004).

\bibitem{Stamatakos2006}
G.~Stamatakos, V.~Antipas, N.~Uzunoglu, R.~Dale, A four-dimensional computer
  simulation model of the in vivo response to radiotherapy of glioblastoma
  multiforme: studies on the effect of clonogenic cell density, {\it Brit. J.
  Radiol.\/} {\bf 79}, 389--400 (2006).

\bibitem{Kempf2010}
H.~Kempf, M.~Bleicher, M.~Meyer-Hermann, Spatio-temporal cell dynamics in
  tumour spheroid irradiation, {\it Eur. Phys. J. D\/} {\bf 60}, 177--193
  (2010).

\bibitem{Powathil2012}
G.~G. Powathil, K.~E. Gordon, L.~A. Hill, M.~A. Chaplain, Modelling the effects
  of cell-cycle heterogeneity on the response of a solid tumour to
  chemotherapy: Biological insights from a hybrid multiscale cellular automaton
  model, {\it Journal of Theoretical Biology\/} {\bf 308}, 1-19 (2012).

\bibitem{Powathil2013}
G.~G. Powathil, D.~J.~A. Adamson, M.~A.~J. Chaplain, Towards predicting the
  response of a solid tumour to chemotherapy and radiotherapy treatments:
  Clinical insights from a computational model, {\it PLoS Computational
  Biology\/} {\bf 9}, e1003120 (2013).

\bibitem{Kempf2013}
H.~Kempf, H.~Hatzikirou, M.~Bleicher, M.~Meyer-Hermann, In silico analysis of
  cell cycle synchronisation effects in radiotherapy of tumour spheroids, {\it
  PLoS Comput Biol\/} {\bf 9}, e1003295 (2013).

\bibitem{Liu2017}
R.~Liu, X.~Li, K.~S. Lam, {Combinatorial chemistry in drug discovery}, {\it
  Current Opinion in Chemical Biology\/} {\bf 38}, 117--126 (2017).

\bibitem{Lightbody2019}
G.~Lightbody, {\it et~al.\/}, {Review of applications of high-throughput
  sequencing in personalized medicine: barriers and facilitators of future
  progress in research and clinical application}, {\it Briefings in
  Bioinformatics\/} {\bf 20}, 1795--1811 (2019).

\bibitem{Bentzen2008}
S.~Bentzen, {\it et~al.\/}, {The UK Standardisation of Breast Radiotherapy
  (START) Trial B of radiotherapy hypofractionation for treatment of early
  breast cancer: a randomised trial}, {\it Lancet (London, England)\/} {\bf
  371}, 1098--1107 (2008).

\bibitem{Whelan2002}
T.~Whelan, {\it et~al.\/}, {Randomized trial of breast irradiation schedules
  after lumpectomy for women with lymph node-negative breast cancer}, {\it
  Journal of the National Cancer Institute\/} {\bf 94}, 1143--1150 (2002).

\bibitem{SourceCUDA}
R.~Bana\'s, {EMT6-Ro CUDA implementation source code},
  \url{https://github.com/banasraf/EMT6-Ro} (Online accessed 11-May-2021).

\bibitem{SourceCPU}
R.~Bana\'s, J.~Bazi\'nska, O.~\L{}obo\.zewicz, A.~Strza\l{}ka, Emt6-ro c++
  implementation source code, \url{https://github.com/lamyiowce/tumor-ca}
  (Online accessed 11-May-2021).

\bibitem{BachelorThesis}
R.~Bana\'s, J.~Bazi\'nska, O.~\L{}obo\.zewicz, A.~Strza\l{}ka, Optimization of
  cancer treatment, Bachelor's thesis, University of Warsaw (2019).

\bibitem{SciPyTTest}
P.~P. E.~Jones, T.~Oliphant, Scipy: Open source scientific tools for python -
  \texttt{ttest\_ind} documentation,
  \url{https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html}
  (Online accessed 22-Dec-2021).

\bibitem{SciPyKSTest}
P.~P. E.~Jones, T.~Oliphant, Scipy: Open source scientific tools for python -
  \texttt{kstest} documentation,
  \url{https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kstest.html}
  (Online accessed 22-Dec-2021).

\bibitem{Alfonso2020}
J.~C.~L. Alfonso, L.~A. Papaxenopoulou, P.~Mascheroni, M.~Meyer-Hermann,
  H.~Hatzikirou, On the immunological consequences of conventionally
  fractionated radiotherapy, {\it iScience\/} {\bf 23}, 100897 (2020).

\bibitem{Montaseri2020}
G.~Montaseri, J.~C.~L. Alfonso, H.~Hatzikirou, M.~Meyer-Hermann, A minimal
  modeling framework of radiation and immune system synergy to assist
  radiotherapy planning, {\it Journal of Theoretical Biology\/} {\bf 486},
  110099 (2020).

\bibitem{Wang2018}
Y.~Wang, {\it et~al.\/}, Combining immunotherapy and radiotherapy for cancer
  treatment: Current challenges and future directions, {\it Frontiers in
  Pharmacology\/} {\bf 0}, 185 (2018).

\bibitem{Holland:2012}
J.~H. Holland, Genetic algorithms, {\it Scholarpedia\/} {\bf 7}, 1482 (2012).

\bibitem{goldberg}
D.~Goldberg, {\it Genetic Algorithms in Search, Optimization, and Machine
  Learning\/} (Addison-Wesley, Reading, Massachusetts, 1989).

\bibitem{ICM}
Interdisciplinary centre for mathematical and computational modelling,
  university of warsaw, \url{https://icm.edu.pl/en} (Online accessed
  21-07-2021).

\end{thebibliography}




\section*{Acknowledgements}

% Acknowledgments, when needed, should include the following information in the order listed below, a single paragraph, starting with the word "Acknowledgments:" in bold. Please use the subhead and boldface layout as shown below.).

This work was supported by grant no.~2015/19/B/ST1/01163 of National Science Centre, Poland, ``Mathematical models and methods in description of tumour growth and its therapies''. This research was carried out with the support of the Interdisciplinary Centre for Mathematical and Computational Modelling at the University of Warsaw (ICM UW \cite{ICM}) under grants no G74-17 and GR79-29. Author contributions: All authors designed the study, WO, RB and PG carried out the experiments, all authors contributed to the analysis of the results, and to writing and editing the paper. The authors declare no competing interests. Code and data to reproduce the numerical experiments in this paper are available to reviewers at \cite{SourceCUDA}.

\section*{Supplementary Materials}
\label{appendix_a}
For Supplementary Materials see additional pdf file.


% \mon{You may include up to a total of ten figures and/or tables (combined) throughout the supplemental text. Include supporting text (including supplementary materials and methods, tables, and figures) at the end of the main manuscript file, in a separate section titled Supplementary Materials, if this can be easily done and if the total file size does not exceed 6 MB.  Alternatively, Supplementary Materials can be included as a separate file that can be uploaded as the final figure file within the 6 MB upload limit. In that case, use one of the file types specified above (.doc or .docx preferred).

% If you have any Supplemental Materials please list them by sections in the following order: supplementary materials and methods (if any), supplementary figures, supplementary tables, and other supplementary files (such as movies, data, interactive images, or database files). Be sure to submit all Supplementary Materials with the manuscript. Example:\\

% Materials and Methods\\
% % Fig. S1. Title of the first supplementary figure.\\
% Fig. S2. Title of the second supplementary figure.\\
% Table S1. Title of the first supplementary table.\\
% Data file S1. Title of the first supplementary data file.\\
% Movie S1. Title of the first supplementary movie.}

%	\FloatBarrier

%\appendix
%\section{Appendix A}

% \input{chapters/appendix}

\section*{Figures}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{figs/benchmark_comparison_top10_v0h.pdf}
    \caption{{\bf Performance comparison of candidate protocols versus BMI, BMII and in the multi-parameter case.} Fitness scores (higher values indicate greater tumour suppression) for the clinical (circle markers) and state-of-the-art~\cite{Angus2014} (squares) protocols of prior work, and discovered via GPU-GA in the current study (open triangles), under the constraints of BMI (A), BMII (B) and the multi-parameter case (C). Markers for the GPU-GA represent the top 10 discovered protocols (n.b.: x-position randomly moved to prevent over-plotting). Note: in all cases $\sum^k_{m=1} d^m_i \leq 10$.}\label{fig:benchmark_comparison}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{figs/density_composite.pdf}
    \caption{{\bf Pooling density plots of $(t,d)$ pairs from the top 10 protocols from each of the seven $d^{max}$ constraints discovered via the pooled GPU-GA BMI, BMII \& multi-parameter search phases.} All sub-modules are pooled, and a 2-Dimensional kernel density surface is computed (blue indicates low density, red peak density, 3-D visualisation in (D)) (A), with 1-Dimensional smoothed densities provided for sequence delay only (B) and dose fraction only (C) also. The position of prominent peaks are labelled.}\label{fig:density_composite}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width = 0.9\textwidth]{figs/CPU_GPU_comparison_v2}
    \caption{{\bf Examining the fidelity and stability of the GPU implementation of the numerical model.} 60 randomly generated protocols (total dose $\leq$ 10~Gy) were developed and run through 48 and 100 iterations of the CPU and GPU code respectively, against each of 10 tumours in the library for 10 days: (A) shows 95\% confidence intervals for CPU (blue) and GPU (orange) relative deviations from the mean number of occupied sites at the end of each replicate; (B) provides t-test p-values (two sided) comparisons between the CPU and GPU implementations, with 0.1 (black) and 0.05 (red) significance lines shown; (C) provides p-values for Kolmogorov-Smirnov test (KS-test) for the normality of the GPU 100 evaluations over each of 60 protocols, against each of $10$ tumours. In (D)  the histogram arising from 2\,000 GPU evaluations of final occupied sites of a single randomly selected protocol (against a single randomly selected tumour) compared to the normal distribution with the same mean and standard deviation is shown.}\label{fig:CPUvsGPU_normal}
    \end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.9\textwidth]{figs/GA_scheme_v5.pdf}
    \caption{{\bf The Genetic Algorithm (GA) scheme.} A single generation consists of 40 candidate protocols. A new generation is formed by graduating 10\% (4) protocols directly without any alteration (A). A further 16 protocols are selected in one of three ways: Roulette (proportional chance by fitness), Simple (simple sort and take the top few), or Tournament (pair-wise competition on fitness). Next 36  protocols are formed from the 16 parents via applying the crossover (C) and mutation (D) operators.}
    \label{fig:GA_scheme}
\end{figure}


\end{document}

% // In terms of journal --

% I think if the above plan was achievable, then at least /JTB/ if not trying for /Plos-CB/?

% PLOS-CB is a tough but good review system .. quite fast. They have good exposure, and rate well.

% I think the paper would need to demonstrate a sufficient level of novelty beyond the previous paper we did .. i.e. to show that the GPU effort was worth it -- significantly increasing the quality of results, and in various clinically feasible setups (hence, the constraints I suggest).

% Or, one could try with /Science Advances/?

