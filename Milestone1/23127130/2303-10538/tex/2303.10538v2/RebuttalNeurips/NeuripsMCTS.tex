\section{Local Search}
\subsection{Heat Map Guided Best-first Local Search}
We employ the best-first local search guided by the heat map to generate the final solution. Best-first search is a heuristic search that explores the search space by expanding the most promising node selected w.r.t. an evaluation function $f(node)$. In our framework, each node of the search tree is a complete TSP solution. For the initialization of one search tree, we randomly generate a valid TSP solution and improve it using the 2-opt heuristic until no better solution is found. The expand action of the search node refers to \cite{fu2021generalize} and is  based on the widely used k-opt heuristic \cite{2opt}, where it replaces $k$ old edges (in the current solution) with $k$ new edges, i.e., transforms the old solution to a new solution. More formally, we use a series of cities, $u_1, v_1, u_2, \ldots, u_k, v_{k + 1}$, to represent an action, where $v_{k + 1} = u_1$ to ensure it is a valid solution. All the edges $(u_i, v_i) \ (1 \leq i \leq k)$ are removed from the tour and $(v_i, u_{i + 1}) (1 \leq i \leq k)$ are added to the tour. Note that once we know $u_i$, $v_i$ is deterministically decided.  $u_1$ is randomly selected for each expansion, and $v_1$ is decided subsequently. Then we select $u_{i + 1} (i \geq 1)$ as follows: (1) if $u_{i + 1} = u_1$, i.e., forms a new TSP tour, leads to an improved solution then we set $u_{i + 1} = u_1$ and have a candidate solution. (2) if $i \geq K$, then we will discard this action and start a new expand action, where $K$ is a hyper-parameter which controls the maximal edges we can remove in one action. (3) otherwise,  we select $u_{i + 1}$ based on the heat map stochastically. We use $N_{u, v}$ to denote the times the edge $(u, v)$ is selected during the entire search procedure. The likelihood of selecting the edge $(u, v)$ is denoted by $
    L_{u, v} \ = \ \mathcal{H}^\prime_{u, v} + \alpha \sqrt{\frac{\log(S + 1)}{N_{u, v} + 1}}$, 
where $\alpha$ is a hyper-parameter and $S$ is the local search's total number of expand actions. The first term encourages the algorithm to select the edge with a high heat map value, while the second term diversifies the selected edges.
Moreover, when selecting the city $v$ given $u$, we only consider the cities from the candidate set of $v$. This candidate set consists of cities with the top $M$ heat map value or the nearest $M$ cities 
%We use $K$ to denote the maximal edges we can remove in one transformation. We will stop the transformation when we find an improved solution or reach the maximal edges $K$.

Among all the possible new solutions, we use the tour's length as the evaluation function $f$, i.e., we select the solution of the shortest tour length as the next search node. For each search node, we try at most $T$ expand actions. From these $T$ expand actions, if no improved solution is found, we randomly generate a new initial solution and start another round of best-first local search. 

\subsection{Updating the Heat Map}
We borrow the idea of 
 the backpropagation used in Monte Carlo Tree Search (MCTS). We use $s$ to denote the current search node, $s^\prime$ to denote the next search node ($s^\prime$ has to improve $s$), and $L(s)$ to represent the tour length of node $s$. The heat map $\mathcal{H}^\prime$ is updated as: $$
 \mathcal{H}_{v_i, u_{i + 1}}^\prime = \mathcal{H}_{v_i, u_{i + 1}}^\prime + \beta [\text{exp}(\frac{L(s) - L(s^\prime)}{L(s)}) - 1],$$ where $\beta$ is a search parameters and $(v_i, u_{i + 1}) (1 \leq i \leq k)$ is the actions used to transform $s$ to $s^\prime$. We raise the importance of the edges that lead to a better solution. If we cannot find an improved solution for the current node, then no update is executed for the heat map.

\subsection{Leveraging Randomness}
Randomness is shown to be very powerful in the local search community \cite{random1, random2, random3}. Our local search procedure also employs it to improve performance. When we stop the current round of local search by not finding an improved solution within $T$ expand actions and switch to a new best-first local search with a new initial solution, we randomly modify the parameter $K$. A larger $K$ value results in more time searching from one initial solution. The intuition is that sometimes we want more initial solutions while sometimes we want to search deeper (replace more edges in k-opt) for a specific solution. Besides that, we also randomly decide how we construct the candidate set (based on the heat map or pairwise distance) for each city before the new round of local search.