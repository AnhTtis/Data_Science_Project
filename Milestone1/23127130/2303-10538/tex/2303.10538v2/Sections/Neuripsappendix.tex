\section{Discussion}
\subsection{Definition of heat map}
We can write  $\mathcal{H}$ as:
\begin{equation}\label{eq:Hij}
\mathcal{H} = \mathbb{T} \mathbb{V} \mathbb{T}^T,
\end{equation}
where $$\mathbb{V}  = 
\begin{pmatrix}
0 & 1 & 0 & 0 & \cdots & 0  & 0 & 0 \\
0 & 0 & 1 & 0 & \cdots & 0  & 0 & 0\\
0 & 0 & 0 & 1 & \cdots & 0  & 0 & 0\\

\vdots  & \vdots  & \vdots & \ddots  & \ddots & \vdots & \vdots  & \vdots  \\
0 & 0 & 0 & 0 & \ddots & 1 & 0 & 0\\
0 & 0 & 0 & 0 & \cdots & 0 & 1 & 0\\
0 & 0 & 0 & 0 & \cdots & 0 & 0 & 1\\
1 & 0 & 0 & 0 & \cdots & 0 & 0 & 0
\end{pmatrix}$$ is the Sylvester shift matrix~\cite{sylvester1909collected}, $\mathbb{V} \in \mathbb{R}^{n\times n}$. We can interpret $\mathbb{V}$ as a cyclic permutation operator that performs a circular shift.
\subsection{Unsupervised Loss}
We can also  write Equation~\ref{eq:loss} in a more compact form: 
\begin{equation} \label{eq:loss2}
\begin{aligned}
    \mathcal{L} =   
 \lambda_1 \underbrace{\sum_{i=1}^n (\sum_{j=1}^n \mathbb{T}_{i,j} - 1)^2}_{\text{Row-wise constraint}}  +   \underbrace{\sum_{i=1}^n \sum_{j=1}^n \mathbf{\tilde{D}}_{i,j} \mathcal{H}_{i,j}}_{\text{Minimize the distance }},
\end{aligned}
\end{equation}
where $\mathbf{\tilde{D}} = \mathbf{D} + \lambda_2 \mathcal{I}_n$, $\mathcal{I}_n \in \mathbb{R}^{n \times n}$ is the identity matrix.
\begin{table}[h]
    \centering
    \caption{Search parameters for all the TSP experiments.}
    \begin{tabular}{lllllll}
        \toprule
        & $\alpha$ & $\beta$ & $M$ & $K$ & $T$  \\
        
        \midrule
        TSP-20 & 0 & 10 & 8 & 10 & 60  \\
        TSP-50 & 0 & 10 & 8 & [5, 15) & 150  \\
        TSP-100 & 0 & 10 & 8 & [5, 35) & 300  \\
        TSP-200 & 0 & 10 & 8 & [10, 90) & 600  \\
        TSP-500 & 0 & 50 & 5 & [30, 130) & 1000  \\
        TSP-1000 & 0 & 50 & 5 & [10, 110) & 2000  \\
        % TSP-10000 & & & & & & \\
        \bottomrule
    \end{tabular}
    \label{tb:sp}
\end{table}

\section{Training and Search Details}
We train our model using Adam~\citet{kingma2014adam}. All models are trained using Nvidia V100 GPU. 
All the search-related parameters are listed in Table \ref{tb:sp}. $M$ is the size of the candidate set of each city. $K$ is the maximal number of edges we can remove in one action, and for each round of local search, we randomly select one number from the listed interval. $T$ is the total number of actions we will try to expand one node. Here, we set $\alpha = 0$ to show that our unsupervised model generates an informative heat map. Lower $\alpha$ means the local search algorithm focuses more on the edges with higher heat map value. Actually, in the experiments, we find the results are similar with $\alpha \leq 1$.


\section{Running Time Discussion}
\label{sec:append_runtime}
As discussed in \citet{kool2018attention}, running time is important but hard to compare since it is affected by many factors. In the table \ref{table:Exps01}, we report the  time for solving all the test instances.

For the UTSP (our method) and the state-of-the-art learning-based method Att-GCRN \citet{fu2021generalize}, we run the search algorithm on exactly the same environment (one Intel  Xeon Gold 6326) for a fair comparison.  And for other baselines, we refer to the results from \citet{fu2021generalize}. So, the time there is only for indicative purposes since the computing hardware is different.

\section{Proof}\label{sec:proof}
\begin{lemma}\label{lem:bijection}
Let $q_i$ denote the row index of the non-zero element in $i$-th column in $\mathbb{T}$, $\mathbb{T}_{q_i,i}=1$, $q_i \in \{1,2,3,4,...,n\}$.  When each row and column in  $\mathbb{T} $ have one value 1 (True) and $n-1$ value 0 (False), then $q_i = q_j$ if and only if $i = j$.
\end{lemma}
\begin{proof}
    If there exist a $(i,j)$ pair where $q_i = q_j$ when $i \neq j$, then $\mathbb{T}_{q_i,i} = 1$ and $\mathbb{T}_{q_j,j} = \mathbb{T}_{q_i,j} = 1$. This means $q_i$-th row has two non-zero elements, which leads to a contradiction.
\end{proof}

\begin{lemma}\label{lem:binary}
Consider graph $\mathcal{G}$ with $n$ nodes, for any $\mathbb{T} \in \mathbb{R}^{n \times n}$ with $\mathbb{T}_{i,j} \geq 0$, when each row and column in  $\mathbb{T} $ have one value 1 (True) and $n-1$ value 0 (False). Then, each row and column in $\mathcal{H} $ also have one value $1$ (True) and $n-1$ value $0$ (False), which means each city corresponds to only one beginning point and one ending point.

\end{lemma}

\begin{proof}
First, it is clear that for $\forall a,b$, $\mathcal{H}_{a,b} \in  \mathbb{Z}_{\geq 0}$. Let's assume $\mathbb{T}_{a,l} = \mathbb{T}_{b,m} =  1 (a \neq b, l \neq m)$, since
$
\mathcal{H}_{i,j} = \sum_{k=1}^n \mathbb{T}_{i,k} \mathbb{T}_{j,k (\mathrm{mod}\; n) + 1},
$
we then have
\begin{align*}
\sum_{j=1}^n \mathcal{H}_{a,j}  & = \sum_{j=1}^n  \sum_{k=1}^n \mathbb{T}_{a,k} \mathbb{T}_{j,k (\mathrm{mod}\; n) + 1}  \\ & =
\sum_{k=1}^n  \mathbb{T}_{a,k} \{ \sum_{j=1}^n \mathbb{T}_{j,k (\mathrm{mod}\; n) + 1}   \} \\ 
& =  \sum_{k=1}^n  \mathbb{T}_{a,k}   = 1.
\end{align*}
This implies that the summation of each row in $\mathcal{H}$ is 1. Similarly,
\begin{align*}
\sum_{i=1}^n \mathcal{H}_{i,b} & =   \sum_{i=1}^n \sum_{k=1}^n   \mathbb{T}_{i,k} \mathbb{T}_{b,k (\mathrm{mod}\; n) + 1}    \\ 
% & =   \sum_{k=1}^n    \mathbb{T}_{b,k (\mathrm{mod}\; n) + 1} \sum_{i=1}^n \mathbb{T}_{i,k}    \\ 
& = \sum_{k=1}^n    \mathbb{T}_{b,k (\mathrm{mod}\; n) + 1} \{\sum_{i=1}^n \mathbb{T}_{i,k}\}   \\ 
& = \sum_{k=1}^n    \mathbb{T}_{b,k (\mathrm{mod}\; n) + 1}  = 1.
\end{align*}
This suggests the summation of each column in $\mathcal{H}$ is $1$. Since each element in $\mathcal{H}_{i,j} \in  \mathbb{Z}_{\geq 0}$, we can then conclude that each row and column in  $\mathcal{H} $ have one value $1$ (True) and $n-1$ value $0$ (False). 
Also, 
$\mathcal{H}_{ii} = \sum_{k=1}^n   \mathbb{T}_{i,k (\mathrm{mod}\; n) + 1} \mathbb{T}_{i,k}  = 0$, this indicates that the elements in the main diagonal of $\mathcal{H}$ are 0, which implies no self-loops.

 
As mentioned, the $i$-th row in $\mathcal{H}$ is the probability distribution of directed edges start from city $i$, and the $j$-th column is the probability distribution of directed edges end in city $j$. Because each row and column in  $\mathcal{H} $ have one value 1 (True) element and $\mathcal{H}$'s diagonal entries are all zero, this means that each city is the beginning point of one 
 directed edge and is also the ending point of another different directed edge.
 \end{proof}

\begin{figure}[ht]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=0.8\columnwidth]{Figures/HamiltonianCycle.png}}
\caption{Illustration of building a cycle from transition matrix $\mathbb{T}$. Here $q_{k-1} = 3$, $q_k = n -2$, $q_{k+1} = 2$, $q_{n-1} = 1$, $q_n = n$ and $q_1 = 4$, this means $\mathcal{H}$ contains  the following four directed edges: $3\rightarrow n-2$, $n-2 \rightarrow 2$, $1 \rightarrow n$ and $n \rightarrow 4$.  }
\label{fig:HamiltonianCycle}
\end{center}
\vskip -0.2in
\end{figure}
\begin{lemma}\label{lem:HamiltonianCycle}
There is at least one cycle in $\mathcal{H}$ which contains $n$ edges and visits all cities when each row and column in  $\mathbb{T} $ have one value 1 (True) and $n-1$ value 0 (False). 
\end{lemma}

%Then, the corresponding heat map denotes one Hamiltonian Cycle on $\mathcal{G}$.
\begin{proof}
\textbf{Lemma}~\ref{lem:bijection} indicates that $q_i \neq q_j$ when $i \neq j$ and $q_i \in \{1,2,3,4,...,n\}$, then $\cup_{i=1}^n q_i = \{1,2,3,4,...,n\}$. From Equation~\ref{eq:Hij}, we have
\begin{align*}
\mathcal{H}_{q_i,q_{i+1}} & = \sum_{k=1}^n \mathbb{T}_{q_i,k} \mathbb{T}_{q_{i+1},k (\mathrm{mod}\; n) + 1} \\
& \geq \mathbb{T}_{q_i,i} \mathbb{T}_{q_{i+1},i (\mathrm{mod}\; n) + 1} \\
& \geq 1.
\end{align*}
Using \textbf{Lemma}~\ref{lem:binary}, since each row and column in $\mathcal{H}$ have one value $1$ (True) and $n-1$ value $0$ (False),  it suffices to show that $1 \geq \mathcal{H}_{q_i,q_{i+1}} \geq 1$, therefore $\mathcal{H}_{q_i,q_{i+1}} = 1$. This suggests that there is a directed edge from city $q_i$ to $q_{i+1}$. We can then construct a cycle $\mathcal{C}$ from $\mathcal{H}$,  we can write $\mathcal{C}$ as
\begin{align*}
    q_1 \rightarrow q_2 \rightarrow q_3 \rightarrow q_4 \rightarrow ... \rightarrow q_n \rightarrow q_1,
\end{align*}
where $\rightarrow$ is a directed edge. Since $\cup_{i=1}^n q_i = \{1,2,3,4,...,n\}$, cycle $\mathcal{C}$ visits all $n$ cities and have $n$ edges. One example of how to build $\mathcal{H}_{q_i,q_{i+1}}$ from $\mathbb{T}$ is shown in Figure~\ref{fig:HamiltonianCycle}.
\end{proof}
\begin{corollary}\label{corly:1}
$\mathcal{H}$ represents one Hamiltonian Cycle when each row and column in  $\mathbb{T} $ have one value 1 (True) and $n-1$ value 0 (False). 
\end{corollary}
\begin{proof}
    From \textbf{Lemma}~\ref{lem:HamiltonianCycle}, cycle $\mathcal{C}$ contains $n$
edges and visits all cities, if there exists another edge $(i,j)$ which does not belong to $\mathcal{C}$, then city $i$ is the starting point of at least two edges and  city $j$ is the ending point of at least two edges. This results in a contradiction with \textbf{Lemma}~\ref{lem:binary}. Thus, it suffices to conclude that $\mathcal{C}$  visits each city exactly once and  $\mathcal{H}$ only contains the edges in $\mathcal{C}$. This implies that $\mathcal{H}$ represents one Hamiltonian Cycle.
\end{proof}

