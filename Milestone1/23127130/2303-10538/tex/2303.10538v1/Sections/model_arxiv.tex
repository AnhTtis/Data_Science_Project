\section{Model}
In this paper, we study symmetric TSP on 2D plane. Given $n$ cities and the  coordinates $(x_i,y_i) \in \mathbb{R}^2$ of these cities, our goal is to find the shortest possible route that visits each city exactly once and returns to the origin city, where $i\in \{1,2,3,...,n\}$ is the index of the city.
\subsection{Graph Neural Network}
Given a TSP instance, let $\mathbf{D}_{i,j}$ denote the Euclidean distance between city $i$ and city $j$. $\mathbf{D} \in \mathbb{R}^{n \times n}$ is the distance matrix. We first build adjacency matrix $\mathbf{W} \in \mathbb{R}^{n \times n}$ with $\mathbf{W}_{i,j} = e^{-\mathbf{D}_{i,j}/\tau}$ and node feature  $\mathbf{F} \in \mathbb{R}^{n \times 2}$ based on the input coordinates, where $\mathbf{F}_{i} = (x_i,y_i)$ and $\tau$ is the temperature.
The node feature matrix $\mathbf{F}$ and the weight matrix $\mathbf{W}$ are then fed into a GNN to generate a transition matrix $\mathbb{T} \in \mathbb{R}^{n\times n}$. 

In our model, we use Scattering Attention GNN (SAG), SAG has both low-pass and band-pass filters and can build adaptive representations by implicitly learning node-wise weights for combining multiple different channels in the network using attention-based architecture.
Recent studies show that SAG can output expressive representations for graph combinatorial problems such as maximum clique while remaining lightweight~\cite{min2022can}. 

Let $\mathcal{S} \in \mathbb{R}^{n\times n}$  denote the output of SAG,  we first apply a column-wise Softmax activation to 
 the GNN's output and we can summarize
this operation in matrix notation as $\mathbb{T}_{i,j} = {e^{\mathcal{S}_{i,j}}}/{\sum_{k=1}^n e^{\mathcal{S}_{k,j}}}$. This ensures that each element in $\mathbb{T}$ is greater than zero and the summation of each column is 1. 
We then use $\mathbb{T}$ to build a heat map $\mathcal{H}$, where $\mathcal{H} \in   \mathbb{R}^{n\times n}$. 
In our model, we use $\mathcal{H}$  to estimate the probability of each edge
 belonging to the optimal solution and use
 $\mathbb{T}$ to build a surrogate loss of the Hamiltonian Cycle constraint. 
 As illustrated in Figure~\ref{fig:Transition},  our approach aims to generate an expressive transition matrix $\mathbb{T}$ which assigns large weights (close to 1) on the transition elements and small weights (close to 0) on others.
This will allow us to build a non-smooth heat map $\mathcal{H}$ and improve the performance of the local search.
\begin{figure}[htb]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=\columnwidth]{Figures/diagramtransition.png}}
\caption{We use a SAG to generate a non-smooth transition matrix $\mathbb{T}$. The SAG model is a function of the coordinates and the weighted adjacency matrix.}
\label{fig:Transition}
\end{center}
\vskip -0.2in
\end{figure}
\subsection{Building the  Heat Map using the Transition Matrix}
We build the heat map $\mathcal{H}$ based on $\mathbb{T}$. As mentioned, $\mathcal{H}_{i,j}$ is the probability for edge ($i$,$j$) to belong to the optimal TSP solution or not. We define $\mathcal{H}$ as:
\begin{equation}\label{eq:Hij}
\mathcal{H} = \mathbb{T} \mathbb{V} \mathbb{T}^T,
\end{equation}
where $$\mathbb{V}  = 
\begin{pmatrix}
0 & 1 & 0 & 0 & \cdots & 0  & 0 & 0 \\
0 & 0 & 1 & 0 & \cdots & 0  & 0 & 0\\
0 & 0 & 0 & 1 & \cdots & 0  & 0 & 0\\

\vdots  & \vdots  & \vdots & \ddots  & \ddots & \vdots & \vdots  & \vdots  \\
0 & 0 & 0 & 0 & \ddots & 1 & 0 & 0\\
0 & 0 & 0 & 0 & \cdots & 0 & 1 & 0\\
0 & 0 & 0 & 0 & \cdots & 0 & 0 & 1\\
1 & 0 & 0 & 0 & \cdots & 0 & 0 & 0
\end{pmatrix}$$ is the Sylvester shift matrix~\cite{sylvester1909collected}, $\mathbb{V} \in \mathbb{R}^{n\times n}$. We can interpret $\mathbb{V}$ as a cyclic permutation operator that performs a circular shift. The elements in $\mathcal{H}$ can be written as:
$
\mathcal{H}_{i,j} = \sum_{k=1}^n \mathbb{T}_{i,k} \mathbb{T}_{j,k+1 (\mathrm{mod}\; n)}.
$
$\mathcal{H}_{i,j}$ is the sum of element-wise multiplication on two terms:
the $i$-th row of the $\mathbb{T}$ and the $j$-th row of the $\mathbb{T}$ with left translation. For example, given the transition matrix in Figure~\ref{fig:Transition}, Figure~\ref{fig:TSP} illustrates the corresponding heat map and the TSP solution\footnote{We build $\mathcal{H}$ using Equation~\ref{eq:Hij} instead of directly using $\mathbb{T}$ because, under binary assumption, the output of SAG does not satisfy the Hamiltonian Cycle constraint. An example is shown in Figure~\ref{fig:Transition}. }.
\begin{figure}[htb]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=0.9\columnwidth]{Figures/diagramTSP.png}}
\caption{Left: the heat map corresponds to the transition matrix in Figure~\ref{fig:Transition}; right: the corresponding TSP path.}
\label{fig:TSP}
\end{center}
\vskip -0.2in
\end{figure}

The first row in $\mathcal{H}$ is the probability distribution of directed edges start from city $1$, and since the third element is the only non-zero one in the first row, we then add directional edge $1 \rightarrow 3 $ to our TSP solution. Similarly, the first column in $\mathcal{H}$ can be regarded as the probability distribution of directed edges which end in city $1$.  Ideally, given a graph $\mathcal{G}$ with $n$ nodes, we want to build a transition matrix where  each row and column are assigned with one value 1 (True) and $n-1$ values 0 (False), so that the heat map will only contain one valid solution. 
In practice, we will build a transition matrix $\mathbb{T}$ whose heat map $\mathcal{H}$ assigns large probabilities to the edges in the TSP solution and small probabilities to the other edges.
\begin{figure}[h]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=0.8\columnwidth]{Figures/HamiltonianCycle.png}}
\caption{Illustration of builing a cycle from transition matrix $\mathbb{T}$. Here $q_{k-1} = 3$, $q_k = n -2$, $q_{k+1} = 2$, $q_n = n$ and $q_1 = 4$, this means $\mathcal{H}$ contains the following four directed edges: $3 \rightarrow n -2$, $n-2 \rightarrow 2$, $1 \rightarrow n$ and $n \rightarrow 4$.  }
\label{fig:HamiltonianCycle}
\end{center}
\vskip -0.2in
\end{figure}
\begin{lemma}\label{lem:bijection}
Let $q_i$ denote the row index of the non-zero element in $i$-th column in $\mathbb{T}$, $\mathbb{T}_{q_i,i}=1$, $q_i \in \{1,2,3,4,...,n\}$.  When each row and column in  $\mathbb{T} $ have one value 1 (True) and $n-1$ value 0 (False), then $q_i = q_j$ if and only if $i = j$.
\end{lemma}
\begin{proof}
    If there exist a $(i,j)$ pair where $q_i = q_j$ when $i \neq j$, then $\mathbb{T}_{q_i,i} = 1$ and $\mathbb{T}_{q_j,j} = \mathbb{T}_{q_i,j} = 1$. This means $q_i$-th row has two non-zero elements, which leads to a contradiction.
\end{proof}
\begin{lemma}\label{lem:binary}
Consider graph $\mathcal{G}$ with $n$ nodes, for any $\mathbb{T} \in \mathbb{R}^{n \times n}$ with $\mathbb{T}_{i,j} \geq 0$, when each row and column in  $\mathbb{T} $ have one value 1 (True) and $n-1$ value 0 (False). Then, each row and column in $\mathcal{H} $ also have one value $1$ (True) and $n-1$ value $0$ (False), which means each city corresponds to only one beginning point and one ending point.
\end{lemma}

\begin{proof}
First, it is clear that for $\forall a,b$, $\mathcal{H}_{a,b} \in  \mathbb{Z}_{\geq 0}$. Let's assume $\mathbb{T}_{a,l} = \mathbb{T}_{b,m} =  1 (a \neq b, l \neq m)$, since
$
\mathcal{H}_{i,j} = \sum_{k=1}^n \mathbb{T}_{i,k} \mathbb{T}_{j,k+1 (\mathrm{mod}\; n)},
$
we then have
\begin{align*}
\sum_{j=1}^n \mathcal{H}_{a,j}  & = \sum_{j=1}^n  \sum_{k=1}^n \mathbb{T}_{a,k} \mathbb{T}_{j,k+1 (\mathrm{mod}\; n)}  \\ & =
\sum_{k=1}^n  \mathbb{T}_{a,k} \{ \sum_{j=1}^n \mathbb{T}_{j,k+1 (\mathrm{mod}\; n)}   \} \\ 
& =  \sum_{k=1}^n  \mathbb{T}_{a,k}   = 1.
\end{align*}
This implies that the summation of each row in $\mathcal{H}$ is 1. Similarly,
\begin{align*}
\sum_{i=1}^n \mathcal{H}_{i,b} & =   \sum_{i=1}^n \sum_{k=1}^n   \mathbb{T}_{i,k} \mathbb{T}_{b,k+1 (\mathrm{mod}\; n)}    \\ 
& = \sum_{k=1}^n    \mathbb{T}_{b,k+1 (\mathrm{mod}\; n)} \{\sum_{i=1}^n \mathbb{T}_{i,k}\}   \\ 
& = \sum_{k=1}^n    \mathbb{T}_{b,k+1 (\mathrm{mod}\; n)}  = 1.
\end{align*}
This suggests the summation of each column in $\mathcal{H}$ is $1$. Since each element in $\mathcal{H}_{i,j} \in  \mathbb{Z}_{\geq 0}$, we can then conclude that each row and column in  $\mathcal{H} $ have one value $1$ (True) and $n-1$ value $0$ (False). 
Also,
$\mathcal{H}_{ii} = \sum_{k=1}^n  \sum_{i=1}^n   \mathbb{T}_{i,k+1 (\mathrm{mod}\; n)} \mathbb{T}_{i,k}  = 0$, this indicates that the elements in the main diagonal of $\mathcal{H}$ are 0, which implies no self-loops.
As mentioned, the $i$-th row in $\mathcal{H}$ is the probability distribution of directed edges start from city $i$, and the $j$-th column is the probability distribution of directed edges end in city $j$. Because each row and column in  $\mathcal{H} $ have one value 1 (True) element and $\mathcal{H}$'s diagonal entries are all zero, this means that each city is the beginning point of one 
 directed edge and is also the ending point of another different directed edge.
 \end{proof}
\begin{lemma}\label{lem:HamiltonianCycle}
There is at least one cycle in $\mathcal{H}$ which contains $n$ edges and visits all cities when each row and column in  $\mathbb{T} $ have one value 1 (True) and $n-1$ value 0 (False). 
\end{lemma}

\begin{proof}
\textbf{Lemma}~\ref{lem:bijection} indicates that $q_i \neq q_j$ when $i \neq j$ and $q_i \in \{1,2,3,4,...,n\}$, then $\cup_{i=1}^n q_i = \{1,2,3,4,...,n\}$. From Equation~\ref{eq:Hij}, we have
\begin{align*}
\mathcal{H}_{q_i,q_{i+1}} & = \sum_{k=1}^n \mathbb{T}_{q_i,k} \mathbb{T}_{q_{i+1},k+1 (\mathrm{mod}\; n)} \\
& \geq \mathbb{T}_{q_i,i} \mathbb{T}_{q_{i+1},i+1 (\mathrm{mod}\; n)} \\
& \geq 1.
\end{align*}
Using \textbf{Lemma}~\ref{lem:binary}, since each row and column in $\mathcal{H}$ have one value $1$ (True) and $n-1$ value $0$ (False),  it suffices to show that $1 \geq \mathcal{H}_{q_i,q_{i+1}} \geq 1$, therefore $\mathcal{H}_{q_i,q_{i+1}} = 1$. This suggests that there is a directed edge from city $q_i$ to $q_{i+1}$. We can then construct a cycle $\mathcal{C}$ from $\mathcal{H}$,  we can write $\mathcal{C}$ as
\begin{align*}
    q_1 \rightarrow q_2 \rightarrow q_3 \rightarrow q_4 \rightarrow ... \rightarrow q_n \rightarrow q_1,
\end{align*}
where $\rightarrow$ is a directed edge. Since $\cup_{i=1}^n q_i = \{1,2,3,4,...,n\}$, cycle $\mathcal{C}$ visits all $n$ cities and have $n$ edges. One example of how to build $\mathcal{H}_{q_i,q_{i+1}}$ from $\mathbb{T}$ is shown in Figure~\ref{fig:HamiltonianCycle}.
\end{proof}
\begin{corollary}\label{corly:1}
$\mathcal{H}$ represents one Hamiltonian Cycle when each row and column in  $\mathbb{T} $ have one value 1 (True) and $n-1$ value 0 (False). 
\end{corollary}
\begin{proof}
    From \textbf{Lemma}~\ref{lem:HamiltonianCycle}, cycle $\mathcal{C}$ contains $n$
edges and visits all cities, if there exists another edge $(i,j)$ which does not belong to $\mathcal{C}$, then city $i$ is the starting point of at least two edges and  city $j$ is the ending point of at least two edges. This results in a contradiction with \textbf{Lemma}~\ref{lem:binary}. Thus, it suffices to conclude that $\mathcal{C}$  visits each city exactly once and  $\mathcal{H}$ only contains the edges in $\mathcal{C}$. This implies that $\mathcal{H}$ represents one Hamiltonian Cycle.
\end{proof}
 \subsection{Unsupervised Loss}
In order to generate such an expressive transition matrix $\mathbb{T}$, we minimize the following objective function:
\begin{equation} \label{eq:loss}
\begin{aligned}
    \mathcal{L} =  & 
 \lambda_1 \underbrace{\sum_{i=1}^n (\sum_{j=1}^n \mathbb{T}_{i,j} - 1)^2}_{\text{Row-wise constraint}}  +  \lambda_2   \underbrace{\sum_{i}^n \mathcal{H}_{i,i}}_{\text{No self-loops}} \\
     & + \underbrace{\sum_{i=1}^n \sum_{j=1}^n \mathbf{D}_{i,j} \mathcal{H}_{i,j}}_{\text{Minimize the distance }}. 
\end{aligned}
\end{equation}

The first term in $\mathcal{L}$ encourages the summation of each row in $\mathbb{T}$ to be close to 1. As mentioned, we normalize each column of $\mathbb{T}$ using  Softmax activation. So when the first term is minimized to zero, each row and column in $\mathbb{T}$ are normalized. The second term penalizes the weight on the main diagonal of $\mathcal{H}$, this discourages self-loops in  TSP solutions. The third term can be regarded as the expectation TSP length of the heat map $\mathcal{H}$, where $\mathbf{D}_{i,j}$ is the distance between city $i$ and $j$. As mentioned, since $\mathcal{H}$ corresponds to one Hamiltonian Cycle given an ideal transition matrix with one value $1$ (True)
and $n-1$ value $0$ (False) in each row and column. Then the minimum value of $\sum_{i=1}^n \sum_{j=1}^n \mathbf{D}_{i,j} \mathcal{H}_{i,j}$ is the shortest Hamiltonian Cycle on the graph, which corresponds to the optimal solution of TSP. 

Given a heat map $\mathcal{H}$, we consider  $M$ largest elements in each row (without diagonal elements) and set other $n-M$ elements as 0. Let $\Tilde{H}$ denote the new heat map, we then symmetrize the new heat map by $\mathcal{H}' = \Tilde{H} + \Tilde{H}^T$. 
Let $\mathbf{E}_{ij} \in \{0,1\}$ denote whether an undirected edge ($i,j$)  is in our prediction or not. Without loss of generality, we can assume $0<i<j\leq n$ and  define $\mathbf{E}_{ij}$ as :
$$
\mathbf{E}_{ij} = 
    \begin{cases}
      1, & \text{if}\ \mathcal{H}'_{ij} = \mathcal{H}'_{ji} > 0 \\
      0, & \text{otherwise}
    \end{cases}.
$$
Let $\Pi$ denote the set of undirected edges $(i,j)$ with $\mathbf{E}_{ij} = 1$. Ideally, we would build a prediction edge set $\Pi$ with a small $M$ value, and $\Pi$ can cover all the ground truth edges so that we are able to reduce search space size from $n(n-1)/2$ to  $|\Pi|$. In practice, generating small-size edge sets $\Pi$ which always cover the ground truth solutions is very difficult. We aim to let  $\Pi$ cover as many ground truth edges as possible and use $\mathcal{H}'$ to guide the local search process. 
