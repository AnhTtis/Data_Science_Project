
\section{Background \& preliminaries}\label{sec:prem}

In this section, we first describe the definitions of key concepts as well as some common assumptions in causal discovery. 
Then, we will introduce three graphical representations as causal notations under temporal conditions.
Moreover, the problem definitions of causal discovery from MTS and causal discovery from event sequences are provided respectively.





\begin{table}[h]
    % \tiny %\scriptsize %\footnotesize  %\small
    \label{tab:overall_notation}
    \caption{Main notations used in this survey.}
    \centering
    \begin{tabular}{cc}
       \toprule
       Notation & Description \\
       \midrule
        % $d,N,T$ & number of time-series variate, of observations and of time points, respectively  \\ % constant
        $d, E$ & number of time-series variate, and of event types, respectively \\
        $x_i^t$ & the $i$-th time series at time $t$ in multivariate time series \\
        $N_e(t)$ & the number of the event $e$ occurrences before time $t$ \\
        $\perp \!\!\! \perp, \not \! \perp \!\!\! \perp$ & independent, and not independent\\
        $V,U$ & the set of endogenous variables, and of exogenous variables, respectively  \\
        $G$ & causal graph \\
        $Pa(x_i)$ & the parent nodes of $x_i$ \\  % to edit
        % Consider to add x->y, sepset, dsepset...
       \bottomrule
    \end{tabular}
\end{table}






\subsection{Key concepts and assumptions in causal discovery}
\label{subsection:key_concepts}
Before introducing the research works, we provide some key concepts as the common ground for inferring causal relations from temporal data. Next, we describe the structural causal model, causal Markov condition and $d$-separation formally with notations summarized in Table \ref{tab:overall_notation}.

\begin{figure}
    \centering
	\includegraphics[width=1.0\textwidth]{figs/6figs_v2.pdf}
	% \vspace{-3ex}
	\caption{Basic DAGs and a simple structural causal model.}
	% \vspace{-5ex}
	\label{fig:6figs}
\end{figure}


\textbf{Structural Causal Model (SCM).} The \cite{pearl2009causality} provides a comprehensive theory of causality, which enables us to draw causal conclusions from observations according to Pearl's causal hierarchy (PCH) \cite{General/book_of_why_pearl2018book}.
The SCM can be represented in a 4-tuple $<V,U,F,P(U)>$ form, where $V,U$ denote the set of endogenous and exogenous variables respectively, $P(U)$ is the distribution of exogenous variables, and $F$ represents the set of the mapping function.
Specifically, for $f_i \in F$, $x_i \in V$ and $i=1,...,d$, the model $x_i := f_i(Pa(x_i), u_i),$ indicates the assignment of the value $x_i$ to a function of its structural parents $Pa(x_i)$ and exogenous variable $u_i$.  % 为统一起见，配图也用x1, x2, x3好了
For each SCM, we can yield a causal graph DAG $G$ by adding one vertex for each $x_i$ and directing edges from each parent variable in $Pa(x_i)$ (the causes) to child $x_i$ (the effect).
The relationship of the SCM and the corresponding DAG is shown in Figure \ref{fig:6figs} (a)(b). 
The descriptive power of SCMs lies in the modular structure, which can be separated from randomness \cite{intro/ts_surveys/peters2022causal}.
Besides, given two disjoint sets of variables $X, Y$ with the causal effect of $X$ on $Y$, a precise formulation of \textit{intervention} is indicated as \textit{do} notation where the value of $x$ is set to a specific quantity, i.e., $P(y|do(x))$.
Different from conditioning on a variable, the intervention changes the underlying causal mechanism, thus enabling causal estimation.


\textbf{Causal Markovian Condition.} In the causal graph, the Markovian condition means that the implied joint distribution factorizes according to the following recursive decomposition (characteristic of Bayesian networks) \cite{pearl2009causality}:
\begin{equation}
    P(\mathbf{x}) = \prod_{i=1}^d P(x_i | Pa(x_i)) \nonumber
\end{equation}


\textbf{\textit{d}-separation.} Based on the causal Markovian condition, we can define the $d$-separation.  
In general, a set of variables $S$ \textit{d}-separates two variables if $S$ blocks all paths between them. 
For the given causal graph in Figure \ref{fig:6figs} (d)(e)(f), two vertices $x_1,x_3$ are \textit{d}-separated by the set of vertices $S$ if $x_2 \in S$. 
As for the relations in Figure \ref{fig:6figs} (c) (a.k.a., a \textit{v-structure} or \textit{collider}), $x_1,x_3$ are also \textit{d}-separated if $x_2$ and none of the descendants of $x_2$ are in set $S$.
The graph's \textit{d}-separation property, implying conditional independence constraints, is of importance to explain causal concepts.



\textbf{Causal Identifiability.}
The causal structure is identifiable if causal relationships can be determined exclusively based on observed data without unverifiable restrictions. However, identifying causal structures based on observed data is not always sufficient due to the identifiability problem, which arises from the fact that different causal structures may share the same conditional independence constraints.
\textit{Markov Equivalence Class} (MEC) denotes graphs entailing the same conditional independencies that can be used to formulate this problem. 
Structures belong to the same equivalent class when they have the same skeleton and the same v-structure.
For example, the causal diagrams in Figure \ref{fig:6figs} (d)(e)(f) imply the same \textit{d}-seperation information $x_1 \perp \!\!\! \perp  x_3 | x_2$ and belong to the same MEC.


Based on the up-mentioned concepts, we introduce two assumptions, \ie, causal faithfulness and sufficiency, which are the untestable foundations in causal discovery.

\textbf{Causal Faithfulness.}
Causal faithfulness is the property of a causal model that accurately reflects the independence relations present in the data. 
Under causal faithfulness and Markov assumptions,
the causal graph can be recovered up to its MEC~\cite{MTS/CB/PC_origin}.




\textbf{Causal Sufficiency.}
A set of variables is causally sufficient if all common causes of all variables are observed \cite{MTS/CB/PC_origin}. 
The unobserved confounder is a nonnegligible issue as it may induce biased effect estimation in observational settings.


\subsection{Causal Structure for Temporal Data}

\begin{figure}
    \centering
	\includegraphics[width=0.9\textwidth]{figs/full_window_summary_graph_v3.pdf}
	% \vspace{-3ex}
	\caption{Causal graphs for discrete-time observations.}
	% \vspace{-5ex}
	\label{fig:full_window_summary_graph}
\end{figure}


For temporal data, the causal relationship can be intuitively defined by the temporal precedence \cite{eichler2012causal} indicating the causes precede their effects. It reveals the causality asymmetric in time and is of use to orient a causal relation when two variables are known to be causally related. 
Based on the temporal precedence, there exist three graphical representations of causal structure, \ie, \textit{full time causal graph}, \textit{window causal graph}, and \textit{summary causal graph}. 


As illustrated in Figure \ref{fig:full_window_summary_graph} (a), the \textit{full-time causal graph} represents a complete graph of the dynamic systems. For $d$-variate time series $\mathbf{x}$, the measurement at each time point $t$ is a vector $(x_1^t, ..., x_d^t)$. Vertices in full-time causal graph consist of the set of component $x_1,...,x_d$ at each time point $t$ with lag-specific directed links such as $x_i^{t-k} \to x_j^t$. 
However, it's usually difficult to infer full time causal graphs due to the single observation for each series at each time point.

To remedy this, \textit{window causal graph} is proposed. It assumes a time-homogeneous causal structure such that the dynamics of observation vector $\mathbf{x}$ are governed by $\mathbf{x}^t:=f(\mathbf{x}^{<t}, \mathbf{u}^t)$ where the function $f$ determines the following observation based on past $\mathbf{x}^{<t}$ and the noise $\mathbf{u}^t$.   % 注意，这样表示有个问题就是无法表示瞬时因果效应。
As illustrated in Figure \ref{fig:full_window_summary_graph} (b), the window causal graph is represented in a time window, the size of which amounts to the maximum lag in the full-time causal graph.

As shown in Figure \ref{fig:full_window_summary_graph} (c), each time series component is collapsed into a node to form the \textit{summary causal graph}.
The summary graph represents causal relations between time series without referring to time lags \cite{MTS/FCM/nips_PetersJS13}. In many applications,  it is sufficient to model the relations between temporal variables without precisely knowing the interaction between time instants.


For causal discovery from temporal data, most works aim to find the summary causal graph. Nevertheless, summary graphs do not always correspond to an SCM, which means they do not enable interventional predictions that are consistent with the underlying time-resolve SCM \cite{background/cg/janzing2018structural,background/cg/uai_RubensteinWBMJG17}.


\subsection{Problem Definitions}

\begin{figure}
    \centering
	\includegraphics[width=1.0\textwidth]{figs/problem_def_v6.pdf}
	% \vspace{-3ex}
	\caption{The problem description: (a) causal discovery from MTS data, (b) causal discovery from event sequence data.}
	% \vspace{-5ex}
	\label{fig:problem_def}
\end{figure}


As illustrated in Figure \ref{fig:problem_def}, the tasks can be divided into causal discovery from MTS and causal discovery from event sequence. We define the two problems respectively.  


\textbf{Causal Discovery from MTS.} Consider a time series with $d$ variables: $\{ \mathbf{x}^t \}_{t \in \mathbb{Z}^+} = \{ ({x}^t_1\ {x}^t_2 \ ... \ {x}^t_d )^{\top}  \}_{t \in \mathbb{Z}^+} $. 
Assume that causal relationships between variables are given by the following structural equation model:
\begin{equation}
    x^t_i := f_i( Pa(x^t_i), u^t_i),\ i=1,...,d, \nonumber
\end{equation}
where for any $i \in \{1,...,d\}$ at time instance $t$, $Pa(x^t_i)$ is the set of direct parents of $x^t_i$ which can be both in the past and at the same time instance. 
$u^t_i$ denotes the independent noise and can denote either measurement noise or driving noise \cite{intro/ts_surveys/peters2022causal} without losing generality.
Causal discovery from MTS aims to find either of the two kinds of outputs, \ie summary causal graph or window causal graph.
As for the summary graph, the output is the adjacency matrix $A \in \mathbb{Z}^{d \times d}$ which summarizes the causal structure, the $(i,j)$-th entry of the matrix $A$ is $1$ if past observations of $x_j$ enter the structural equation of $x_i^t$ and $0$ otherwise. We say that `$x_i$ causes $x_j$' if $A_{ij}=1$.
As for window graph with maximum time lag $p$, the output matrices $W$ and $A^k\ (k \in \{1,...,p\})$ correspond to intra-slice and inter-slice edges, respectively. 
For example, $W_{ij}=1$ denotes the instantaneous dependency $x^t_i \to x^t_j$, while $A_{ij}^k=1$ denotes a lagged dependency $x^{t-k}_i \to x^t_j$ for $k>0$.



\textbf{Causal Discovery from Event Sequence.}  For an event sequence: $\{(t_1,e_1),(t_2,e_2),...\}$, its first dimension indicates the time at which the event occurred, while its second dimension stands for the corresponding event type. We aim to discover the causal relationships between each event type. Hence, we set up a temporal point process for each event type, and use the point process's intensity function $\lambda_e$ to infer the causal relationships between the corresponding event types. In general, we can construct a causal graph $G$, where each node represents a point process, or say a type of event sequence. Our mission is to discover the edge in the causal graph. 



















