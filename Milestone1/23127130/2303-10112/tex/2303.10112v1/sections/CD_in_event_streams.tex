\section{Causal Discovery in Event Sequences}\label{sec:event}

% \label{sec:others}
An important assumption in multivariate time series is that the timestamps are discrete and the time intervals are fixed. However, in the real-world scenario, the vast majority of events will not occur at fixed intervals. In consequence, we need to come up with some methods to deal with these irregular and asynchronous data. We can construct event sequences as $\{(t_1, e_1),(t_2,e_2),...\}$, where the first dimension represents the time at which the corresponding event happens, and the second dimension stands for the corresponding event type. In this section, we will focus on inferring causal relationships in event sequences.
First, the multivariate point process is introduced, which is preliminary for causal discovery in event sequences.
Then, we review approaches based on the Granger causal model, which are well-developed. 
Lastly, other approaches including constraint-based and score-based methods are given.




\subsection{Multivariate Point Process}
    
    An event sequence records the occurrence of one specific type of event (or `event type' for simplicity). Meanwhile, we can characterize an event sequence through a point process. To discover the relationships between different types of events, we consider its high-dimensional cases, which is to model event sequences through \textit{Multivariate Point Processes (MPPs)}. Therefore, our problem can be defined as inputting a set of point processes, where each point process represents an event sequence, and outputting a causal graph $G$ established by different processes. In the causal graph $G$, each node represents a point process, and each directed edge captures a directed interaction from one point process to another.
    In this part, we will detail MPPs, including their intensity functions and log-likelihood functions.



    \textbf{Intensity Functions of MPPs.} A temporal point process is a stochastic or random process composed of a time series of binary events that occur in continuous time~\cite{daley2003introduction}. MPPs are high-dimensional point processes, implying that they can involve multiple types of events. % $\{e_1, e_2, ..., e_n\}$. 
    $\mathcal{E}=\{1, …, E\}$ is the set of event types. 
    The occurring time of these events $\{t_1, t_2, …, t_n|t_i\in[0,T]\}$ are unevenly-distributed. 
    The multivariate point process with $E$ types of events can be represented by $E$ counting processes $\{N_e\}_{e=1}^E$, where $N_e = \{ N_e(t)|t \in [0,T]  \}$. 
    The core of a point process is its conditional intensity function, in which the process’s pattern is captured. A type-$u$ intensity function can be defined as the expected instantaneous rate of type-$e$ event’s occurrence given the history:
    \begin{equation}
       \lambda_e(t)=\frac{\mathbb{E}[dN_e(t)|\mathcal{H}_{last}]}{dt} \nonumber
    \end{equation}
    Here $\mathcal{H}_{last} = \{(t_i,e_i)|t_i\textless t, e_i\in\mathcal{E}\}$ represents all types of events happened before time $t$.


    \textbf{Log-likelihood Functions of MPPs.} Next, we show the relationship between the intensity function and the Probability Density Function(PDF) of the joint distribution: $f((t_1,e_1),...,(t_n,e_n)|(t_0,e_0))$. Using the chain rule, there is $f((t_1,e_1),...,(t_n,e_n)|(t_0,e_0))=\prod_{j=1}^{n}f((t_j,e_j)|\mathcal{H}_{lastj})$. Then, we can set up the likelihood function for estimating the joint distribution:
    \begin{equation} \label{eq2}
        \widetilde{L_0} \triangleq \sum_{j=1}^{n}ln f(t_j|e_j,\mathcal{H}_{lastj})+\sum_{j=1}^{n}ln f(e_j|\mathcal{H}_{lastj})
    \end{equation}
    Since the goal is to infer the causal relationship between different events, here we focus on the first term and omit the second term: $L_0 \triangleq \sum_{j=1}^{n}ln f(t_j|e_j,\mathcal{H}_{lastj})$. The intensity function reflects the expectation of the event happening in $[t, t+dt]$ given the information of $\mathcal{H}_{n-1}$. Similar to the calculation of the force of mortality in survival analysis, there holds,
    \begin{equation}
    \begin{aligned}
        \lambda_e(t|\mathcal{H}_{n-1})&=\frac{\mathbb{E}[N_e(t+dt)-N_e(t)|\mathcal{H}_{n-1}]}{dt}\\
        &=\frac{\int_{t_{n-1}}^{t+dt}f(l|d,\mathcal{H}_{n-1})dl-\int_{t_{n-1}}^{t}f(l|d,\mathcal{H}_{n-1})dl}{1-\int_{t_{n-1}}^{t}f(l|d,\mathcal{H}_{n-1})dl}\\
        &=-\frac{d}{dt}ln(1-\int_{t_{n-1}}^{t}f(l|d,\mathcal{H}_{n-1})dl)\nonumber
    \end{aligned}
    \end{equation}
    Integrating the equation above and substituting $f$'s expression into \cref{eq2}, we have,
    \begin{equation} \label{eq3}
        L_0 = \sum_{j=1}^{n}\{ln\lambda_{e_n}(t_n|\mathcal{H}_{n-1})-\int_{t_{n-1}}^{t}\lambda_e(l|\mathcal{H}_{n-1})dl\} 
    \end{equation}
    We have briefly introduced Multivariate Point Processes and constructed likelihood functions to characterize MPPs in the above. Next, we aim to discover the causal relationships within MPPs using Granger-based, as well as constraint-based and score-based methods.\\


\subsection{Granger Causality Based Approaches}

In this subsection, we consider the task to infer Granger causalities in event sequences. Similar to that in MTS, we say $e_j$-type events Granger cause $e_i$ if $\{e_j(t)|t<t_0\}$ is useful in forecasting $e_i(t)$.
The detailed methods can be categorized according to the following model specifications, \ie, GLM point process, Hawkes process, Wold process, and neural point process.



    % \subsubsection{Utilize GLM Point Processes}
    \subsubsection{Methods for GLM point processes}
    We first introduce causal discovery approaches for event sequences which are modeled via \textit{Generalized Linear Model (GLM)} of point processes~\cite{doi:10.1152/jn.00697.2004}.
    The GLM assumes that the logarithm of the intensity function has a linear format, i.e., $ln\lambda_e(t|\mathcal{H}_{n-1})=\beta_0+\beta_1 X_1+\beta_2 X_2$. Specifically, in our mission, the intensity functions follow,
    \begin{equation} \label{eq4}
        ln\lambda_i(t|\gamma_i,H_i(t)) = \gamma_{i,0}+\sum_{j=1}^{J}\sum_{m=1}^{M_i}\gamma_{i,j,m}R_{j,m}(t)
    \end{equation}
    Here $\gamma_{i,0}$ can be interpreted as the background intensity of event $e_i$, $\gamma_{i,j,m}$ is the intensity on type-$e_i$ events triggered by type-$e_j$ events and $R_{j,m}(t)$ is the number of occurrence of $e_j$-type events happened in $[t-mW,t-(m-1)W]$ ($W$ is a small number which refers to the length of time range). By looking at the sign of $\sum_{m=1}^{M_i}\gamma_{i,j,m}$, we can distinguish whether type-$e_j$ events have excitatory or inhibitory effects on type-$e_i$ events.
    
    To infer the Granger Causality between type-$e_j$ and type-$e_i$ events, we substitute \cref{eq4} into the likelihood function \cref{eq3}. Next, we follow a simple thought that we can exclude a certain type of event and then infer the Granger causality by comparing its intensity with the original case. Specifically, we obtain both the likelihood of type-$e_i$’s occurrence with and without type-$e_j$’s effect: $L_i(\gamma_i)$, $L_i(\gamma_i^j)$. Then, consider that $\sum_{m=1}^{M_i}\gamma_{i,j,m}$ is an indicator of the effection type, the Granger causality from type-$e_j$ to type-$e_i$ events can be proposed as~\cite{10.1371/journal.pcbi.1001110}:
    \begin{equation}
    \begin{aligned}
        \phi_{ij} &= -sign(\sum_{m=1}^{M_i}\gamma_{i,j,m})\Gamma_{ij}\\
        &= -sign(\sum_{m=1}^{M_i}\gamma_{i,j,m})log\frac{L_i(\gamma_i^j)}{L_i(\gamma_i)} \nonumber
    \end{aligned}
    \end{equation}
    Apparently, there exists $L_i(\gamma_i) \geq L_i(\gamma_i^j)$, hence, $\Gamma_{ij} = log\frac{L_i(\gamma_i^j)}{L_i(\gamma_i)} \leq 0$. Only if '$<$' is satisfied, type-$e_j$ events will be the Granger cause to type-$e_i$ events. In the next step, Kim et al.~\cite{10.1371/journal.pcbi.1001110} presented a significance test of these causal interactions by conducting $H_0$ hypothesis: $\theta_0=\gamma_i^j$ and $H_1$ hypothesis: $\theta_1=\gamma_i$. 
    Passing through an FDR significance test, the final causal relationships could be estimated by $\widetilde{\phi_{ij}}$: (1) type-$e_j$ events are an excitatory cause of type-$e_i$ events when $\widetilde{\phi_{ij}}>0$, (2) the cause is inhibitory when $\widetilde{\phi_{ij}}<0$, (3) there exists no causal relationship between type-$e_j$ and type-$e_i$ events when $\widetilde{\phi_{ij}}=0$.
    

    \subsubsection{Methods for Hawkes processes}
    In this part, we review methods for Hawkes process. As a particular type of point process, the basics of the Hawkes process are first given.
    Then we detail approaches based on MLE to infer causal relations, including (1) parameterization strategies and (2) regularization methods. Next, we review other estimation approaches, including (1) graphical event models, (2) generalized method of moments, (3) event sequence separation, and (4) minimum description length.
    We note that there exists a plethora of literature in this category since a natural match-up between Granger causality and Hawkes processes.

    The Hawkes process is a type of point process that has a fixed form of intensity function:
    \begin{equation} \label{eq6}
        \lambda_{e_i}(t) = \mu_{e_i} + \sum_{e_j=1}^{E}\int_{0}^{t}\phi_{e_ie_j}(s)dN_{e_j}(t-s)
    \end{equation}\\
    Here, $\mu_{e_i}$ is called the baseline intensity, which can only be affected by exogenous events, hence, is a constant over time. And $\phi_{e_ie_j}(s)$, the impact function, measures the decay of the excitement on future type-$e_i$ events triggered by historical type-$e_j$ events. That is to say, it captures the endogenous intensity from $e_j$ to $e_i$. Considering the similarity between definitions of $\phi$ and the Granger causality, we can directly infer Granger causality by analyzing $\phi$:
    
    \begin{prop} \label{prop1}
        (Eichler et al.~\cite{https://doi.org/10.1111/jtsa.12213}, 2017)
        \begin{equation}
            e_j \ \text{does not Granger-cause} \ e_i \iff \phi_{e_ie_j}(s)=0, \forall s \in R  \nonumber
        \end{equation}  
    \end{prop} 
    
    Therefore, we aim to model $\phi_{e_ie_j}(t)$ for each event and all $t\in R$. However, due to the complexity and heterogeneity of event sequences, this mission could be extremely difficult to accomplish.
    Zhou et al.~\cite{pmlr-v31-zhou13a} parameterize $\phi_{e_ie_j}(s)$ as $a_{e_ie_j}g(s)$. By this means, $\phi$ is split into events-interaction and time-decaying parts. 
    
    \textbf{MLE Approaches.} The Maximum Likelihood Estimation (MLE) can be performed for estimating parameters in \cref{eq6}. We take $\lambda$'s expression into \cref{eq3}, which results in the corresponding likelihood function: $L(A,\mu)$. Here, $A$ is composed of $(a_{e_ie_j})$, and $\mu$ is built up by $\mu_{e_i}$. Next, consider that in real-world scenarios, most events can only influence a small fraction of other events, and the community structures in the influence networks tend to be low-ranked~\cite{pmlr-v31-zhou13a}, we should add penalty entries to the MLE loss function. Specifically, the following objective function can be constructed in order to achieve matrix $A$'s low rank and sparsity:
    \begin{equation}
        \underset{A\geq0,\mu\geq0}{min}-L(A,\mu)+\lambda_1\Vert A \Vert_*+\lambda_2\Vert A \Vert_1  \nonumber
    \end{equation}
    
    Here, $\Vert \cdot \Vert_*$ is the nuclear norm, of which performance in reducing the matrix's rank has been proven. And $\Vert \cdot \Vert_1$ is the L1 norm. It can enforce matrix A to gain more sparsity. $\lambda_1$, $\lambda_2$ are parameters to control the strength of these two penalties. We denoted the object function as $f(A,\mu)$. Apart from this, an EM-based algorithm could be conducted to solve the optimization problem for $A$ and $\mu$. In details, Zhou used the surrogate function $Q(A,\mu;A^{(m)},\mu^{(m)})$ as a tight upper bound of $f(A,\mu)$. By optimizing $Q(A,\mu;A^{(m)},\mu^{(m)})$ iteratively, $f(A,\mu)$ was forced to decrease and, thus, successfully optimized. We summarize this in algorithm \ref{alg:Algorithm1}.

    \begin{algorithm}[t]
        \caption{Learning Granger causality on Hawkes Processes with EM-MLE method}
        \label{alg:Algorithm1}
        \KwIn{Event sequences $S=\{(t_1, e_1),(t_2,e_2),...\}$}
	\KwOut{Granger causality graph $G=[g_{e_ie_j}]$}
        \BlankLine
        Initialize $\mu=[\mu_{e_i}]$ and $A=[a_{e_ie_j}]$ randomly;\quad\quad\quad\quad\# EM-based learning\\
        \textbf{repeat}\\
        \quad\quad Update $A$ and $\mu$ by optimizing the surrogate function $Q(A,\mu;A^{(m)},\mu^{(m)})$\\
        \textbf{until convergence}\\
        \textbf{for $e_i, e_j=1:U$}\\
        \quad\quad \textbf{if} a specific threshold function holds, $a_{e_ie_j}=0$\\
        \quad\quad \textbf{if} $a_{e_ie_j}=0$ holds, $g_{e_ie_j}=0$
    \end{algorithm}

    \textit{(1) Parameterization Strategies}: The parameterization method $\phi_{e_ie_j}(s)$ = $a_{e_ie_j}g(s)$ mentioned above may suffer from bad performance if the data do not fit its strong assumption. Therefore, to gain robustness in different types of event sequences, Xu et al.~\cite{pmlr-v48-xuc16} came up with a strategy to choose a family of basic functions and used their linear combination, $\sum_{m=1}^{M}a_{e_ie_j}^m \kappa_m(s)$, to model the targeted intensity function. 
    
    However, in \textbf{NPHC}~\cite{pmlr-v70-achab17a}, Achab et al. put forward that the \emph{basic function} strategies would have extraordinary computing complexities when there exist too many types of events (i.e., $E$ is large). Given that our goal is only to infer the Granger causality, there is no need to totally parameterize the Hawkes process, and thus, we only need to estimate the corresponding integral $\int_{0}^{+\infty}\phi_{ee'}(s)ds$. Achab denoted the integral as $g_{ee'}$ while $(g_{ee'})$ formed matrix G. Then, from Eichler's proof~\cite{https://doi.org/10.1111/jtsa.12213} as well as $\phi_{ee'}(s)>0, \forall s>0$, it is clear that $(g_{ee'})=0 \iff e' \ \text{does not Granger-cause} \ e$.
    
    Other works considered the underlying topological relationships within event sequences. In THP~\cite{Cai2021THPTH}, Cai et al. assumed the existence of a hidden undirected graph structure $G_N$ between events. And the corresponding intensity function is formed as $\lambda_{e_i}(n,t)=\mu_{e_i}+\sum_{e_j\in E}(g_{e_ie_j}*s_{e_i,e_j,t})_{G_N}(n)$. Here, $g_{e_ie_j}$ is the graph convolution kernel that could capture the effect from the graph neighbors. And $s_{e_i,e_j,t}$ is the time convolution kernel representing the sum of the past impact function $\phi_{e_ie_j}(s), s<t$. This is based on the assumption that the hidden topological structure will not change during the process.


    \textit{(2) Regularization Methods}: In an aforementioned method we presented $A$'s nuclear norm $\Vert A \Vert_*$ and L1 norm $\Vert A \Vert_1$ as regularizers. And in \emph{basic function} methods, a special sparse-group-lasso regularizer~\cite{simon2013sparse} is applied to fit their summation parameterization. Specifically, Xu et al.~\cite{pmlr-v48-xuc16} conducted a group-lasso penalty as well as a lasso penalty simultaneously in order to enforce $a_{e_ie_j}^m=0$ for all $m$, i.e., group sparsity, in addition to a regular sparsity for all the entries $a_{e_ie_j}^m$. Nevertheless, in $L_0$ Hawkes~\cite{NEURIPS2021_15cf7646}, Ide et al. proved that EM-based MLE algorithms with L1-regularization cannot offer sparse solutions mathematically. Hence, their sparse solutions can appear only as numerical artifacts. Sequentially, Ide presented an L0-regularized EM-MLE algorithm to circumvent this problem. Here, the L0-norm $\Vert A\Vert_0$ indicates the number of non-zero entries in matrix $A$.
    
    Similar to the aforementioned topological parameterization strategies, Xu et al.~\cite{pmlr-v48-xuc16} considered the underlying topological relationships between event types in constructing our regularizers. Specifically, pairwise similarity $\sum_{e_i=1}^{E}\sum_{e_j\in C_e}\Vert a_{e_i\cdot} - a_{e_j\cdot}\Vert_F^2 + \Vert a_{\cdot e_i} - a_{\cdot e_j}\Vert_F^2$ could be presented in order to enforce that similar events could have similar intensity functions. However, we must add that this regularizer requires a predefined cluster structure and thus can be optimized.
    
    Prior domain knowledge could be of great use when discovering the Granger causality. Due to the event sequences' high dimensionality and heterogeneity, existing algorithms regularly suffer from underfitting and poor interpretability. Hence, it is natural to consider adding domain knowledge from humans to the causal-inferring model. In specific, a bottom-up visualization model with user feedback was established~\cite{9222294}. Jin et al. set up their based model with the traditional MLE method in MLE-SGLP. During the training process, the user could either confirm or remove a causal relation depending on their domain knowledge from the network. And the model will change its optimization target corresponding to the user's choice. For example, in accordance with the idea in MLE-SGLP~\cite{pmlr-v48-xuc16}, Jin~\cite{9222294} constructed their intensity function as $\phi_{e_ie_j}=\sum_{m=1}^{M}a_{e_ie_j}^m \kappa_m(s)$, and set $a_{e_ie_j}$ as $[a_{e_ie_j}^1,...,a_{e_ie_j}^n]$. Correspondingly, their objective function could be: $\underset{\mu,\alpha}{argmin}\quad -L+\alpha\sum_{e_i,e_j}\Vert a_{e_ie_j}\Vert_2$. After the user made their choice to either confirm or delete edges in the causal graph $\hat{G}$, Jin updated the object function as follows:
    \begin{equation} \label{eq9}
    \begin{split}
        \underset{\mu,\alpha}{argmin}\quad -L+\alpha_v\sum_{e_i,e_j}\Vert a_{e_ie_j}(\hat{G})\Vert_2 \\
        \text{s.t.} \quad a_{e_ie_j}=0 \quad\text{for}\quad (e_j\rightarrow e_i) \notin \hat{G}
    \end{split}
    \end{equation}
    
    \begin{equation} \label{eq10}
        a_{e_ie_j}(\hat{G})=
        \begin{cases}
            0; \quad \text{if} \quad (e_j\rightarrow e_i) \quad \text{is confirmed}\\
            a_{e_ie_j}; \quad \text{otherwise}
        \end{cases}
    \end{equation}
    
    Here the constraints in \cref{eq9} fit the removal operations, and the updates in \cref{eq10} represent the user's confirmations.
    
    \textbf{Other estimation approaches}
    
    \textit{(1) Graphical Event Models}: The aforementioned methods use Maximum Likelihood Estimation to model the Hawkes processes of event sequences. However, these attempts lack interpretability and require fine-tuning processes for parameters to achieve a good performance. Therefore, entirely data-driven, graph-based, and dependency-captured Graphical Event Models (GEMs) could be presented to infer Granger causalities in the event sequences.
    
    We will elaborate more on GEM's attributes in \cref{subsec43}. Here, we only focus on its relationship with the Granger causality. Suppose There is a directed graph $\mathcal{G}=(\mathcal{E},\mathcal{A})$, in which the edges represent dependencies between different event types. For each event-type $e$, we assumed that its conditional intensity could only be affected by its parent type, i.e., it follows $\lambda_e(t|h_t)=\lambda_e(t|[h_t]_{P_a(e)})$, where $P_a(e)\subseteq\mathcal{E}$ is $e$'s parent event in a graph $\mathcal{G}$, and $[h_t]_{P_a(e)}$ is the history of events which types are listed in the set $P_a(e)$. In accordance with \cref{prop1}, there holds,

    \begin{prop} \label{prop2}
        \text{(Granger Causality in GEMs, Yu et al., 2020~\cite{pmlr-v138-yu20a})}\\
        For two event types $e_i$ and $e_j$ in $\mathcal{G}=(\mathcal{E},\mathcal{A})$, $e_j$ does not Granger-cause $e_i \iff \phi_{e_ie_j}(t)=0, \forall t>0 \iff e_j \notin Pa(e_i)$
    \end{prop}

    Hence, one can apply traditional score-based structure learning methods to discover the Granger causality. For example, BIC scores can be presented for learning the optimized graph $\mathcal{G^*}$. The optimization approach is consistent. At the same time, Yu conducted a Forward-Backward Search (FBS) to learn the parent types of a certain event type independently~\cite{pmlr-v138-yu20a}. The Forward-Backward Search with BIC scores is proved to be sound and complete for a family of GEMs~\cite{pmlr-v51-gunawardana16}.
    
    \textit{(2) Generalized Method of Moments}: In NPHC, the optimization object is a matrix $G=(g_{ee'}=\int_{0}^{+\infty}\phi_{ee'}(s)ds$. Therefore, the Generalized Method of Moments (GMM) can be used to address this problem~\cite{hall2004generalized}. Achab et al. presented a GMM-based NPHC algorithm to model the first, second, and third-order cumulants of matrix $G$~\cite{pmlr-v70-achab17a}. Afterward, the Granger causality could be directly attained from $G$. This moment estimation approach is proven consistent and robust to certain observation noise~\cite{pmlr-v139-trouleau21a}. However, this approach might receive poor results in specific datasets, e.g., datasets with long tails. That is mainly due to GMMs' general issue: they can only capture the information within a statistical distribution's moments.
    
    \textit{(3) Event Sequences Separation}: Another intriguing idea is separating the event sequences into multiple sub-sequences and applying the Hawkes Process model in each sub-sequence correspondingly. In GC-nsHP~\cite{CHEN202222}, Chen et al. divided the event sequences $\mathcal{H}_{n}=[(t_1,e_1),...,(t_n,e_n)]$ into $K$ different patterns, where $K$ should be predefined according to its applying scenario. 'Events' in the same pattern are supposed to build up a stationary sub-process of $\mathcal{H}_{n}$. Then, $K$ different Hawkes processes were established specifically for $K$ patterns, and the Granger causality can only be learned inside each pattern. Within each iteration, a Viterbi-path-based pattern reassignment algorithm and an EM-MLE-based parameter-updating algorithm were conducted alternately. In the parameter updating part, consider that $X_{t-1}$ and $X_{t}$ are more likely to be in the same pattern, Chen added a penalty term to help to put the adjacent sequences into the same pattern.

    \textit{(4) Minimum Description Length}: Following the Minimum Description Length (MDL) principle~\cite{rissanen1998stochastic, grunwald2019minimum}, Jalaldoust et al. conducted a trade-off between the goodness-of-fit and the model complexity~\cite{Jalaldoust_Hlaváčková-Schindler_Plant_2022}. In detail, they partitioned the parameter space $\Theta$ into $\{\Theta_\gamma:\gamma \in \Gamma\}$, defined a luckiness function $v:\Theta \rightarrow \mathbb{R}$, and set the normalized maximum likelihood distribution for each model $\gamma \in \Gamma$ to be:
    \begin{equation}
        p_{v|\gamma}^{NML}(x)=\frac{max_{\theta \in \Theta_\gamma}p(x|\theta)v(\theta)}{\int_{x\in\mathcal{X}}max_{\theta \in \Theta_\gamma}p(s|\theta)v(\theta)ds}
    \end{equation}
    The logarithm of the integral can be seen as the model complexity:
    \begin{equation}
        COMP(M_\gamma;v)=log\int_{x\in\mathcal{X}}max_{\theta \in \Theta_\gamma}p(s|\theta)v(\theta)ds
    \end{equation}
    Jalaldoust picked the optimized model $\hat{\gamma}^{MDL}\in\Gamma$ using 
    \begin{equation} \label{eq13}
        \hat{\gamma}^{MDL}=\mathop{\arg\min}_{\gamma\in\Gamma}L_v(\gamma;x)
        =\mathop{\arg\min}_{\gamma\in\Gamma}(-log\pi(\gamma)-r_v(\hat{\theta}_{v|\gamma}(x);x)+COMP(M_\gamma;v))
    \end{equation}
    where $\pi$ is a uniform distribution and $r_v(\hat{\theta}_{v|\gamma}(x);x)$ is the goodness-of-fit relevant to $p$, $v$, and $\Theta_\gamma$.

    Moreover, consider a one-to-one mapping from $\gamma \in \Gamma$ to a $p\times p$ adjacent matrix of a causal graph within the set of all binary $p\times p$ matrices. By optimizing the \cref{eq13}, one can choose the most appropriate model from their predefined model family, hence, infer the Granger causal relationships between event types.\\
    
    \subsubsection{Methods for Wold processes}
    While most of the existing algorithms concerning discovering Granger causality from event sequences are based on Hawkes Processes, we can also model these relationships on another type of process - Wold Processes, which bear less complexity in nature. Suppose we denote $\delta_i=t_i-t_{i-1}$ to be the waiting time for $i$-th event from the occurrence of $(i-1)$-th event. Wold Processes are built upon a simple assumption that the current waiting time $\delta_i$ is only related to the closest past waiting time $\delta_{i-1}$. That is to say, the set $\{\delta_i, i\in \mathrm{N}\}$ forms a Markov chain. The inherent Markov property within the Wold processes makes them suitable for modeling the dynamics of certain complex systems. Besides, Figueiredo et al.~\cite{NEURIPS2018_aff0a6a4}) have measured the correlation between $\delta_i$ and $\delta_{i-1}$ on certain datasets. The result shows that in most of their datasets, the median Pearson correlation is above 0.7, which is a sign of the adequacy of the Wold model. Accordingly, following Alve et al.~\cite{10.1145/2939672.2939852} and Figueiredo et al.~\cite{NEURIPS2018_aff0a6a4}'s idea, the intensity function can be performed as
    \begin{equation}
        \lambda_{e_i}(t)=\mu_{e_i}+\sum_{e_j\in E}\frac{\alpha_{e_ie_j}}{\beta_{e_j}+\Delta_{e_ie_j}(t)}  \nonumber
    \end{equation}
    based on the BuSca model. Here, $\mu_{e_i}$ is the base intensity as in Hawkes Processes. $\Delta_{e_ie_j}(t)$ denote the time interval between the last $e_i$ type occurrence and $e_j$ type occurrence on time t. That is, if we define the closest $e_i$ type event before time $t$ happened at time $t_{e_i}$, and $e_j$ type before time $t_{e_i}$ happened at time $t_{e_j}$, there is $\Delta_{e_ie_j}(t)=t_{e_i}-t_{e_j}$. Hence, the cross-type entry $\sum_{e_j\in E}\frac{\alpha_{e_ie_j}}{\beta_{e_j}+\Delta_{e_ie_j}(t)}$ in our intensity function will be larger if $\Delta_{e_ie_j}(t)$ decrease. This perfectly matches the fact that if type-$e_i$ events always happen just before type-$e_j$ events occur, we see a greater probability that $e_j$ has a certain effect on $e_i$. $\alpha_{e_ie_j}$ is the normalizing entry satisfying $\sum_{e_j\in E}\alpha_{e_ie_j}=1$, while $\beta_{e_j}$ is the base rate such that when the time interval $\Delta_{e_ie_j}(t)$ between two types are infinitesimal at time $t$, the cross-type entry will converge to $\frac{\alpha_{e_ie_j}}{\beta_{e_j}}$.
    
    The Granger causality can be learned through this Wold-based model by inspecting $\alpha_{e_ie_j}$. Specifically, if $\alpha_{e_ie_j}\neq0$, it is considered that $e_j$ Granger-cause $e_i$. Since the approaches to learning the processes may not have an adequately sparse solution, Figueiredo tested the statistical significance of these possible Granger causal relationships and discard those with low significance. Moreover, the Wold-based model can be learned through MCMC, Expectation Maximization (EM)~\cite{NEURIPS2018_aff0a6a4} and Variational Inference~\cite{pmlr-v130-etesami21a} approaches. The task is to infer the parameters $\{\alpha_{e_ie_j}, \beta_{e_j}, \mu_{e_i} |\forall e_i, e_j\}$ in the intensity functions, which could reveal all the properties inside event sequences. Here we do not elaborate on the details of these learning methods.\\

    \subsubsection{Methods for neural point processes}
    % \subsubsection{Utilize Neural Point Processes}
    %% \textcolor{red}{(this section needs reorganization)}
    
    With the rapid development of neural networks, \textit{Neural Point Processes(NPPs)} have gradually been utilized to model event sequences and infer causal relations.
    The core idea of these NPP algorithms is to use neural networks to infer the intensity function $\lambda_e(t)$. In specific, they encode an event sequence into the hidden state, during which they capture the feature of the sequence. Then, they use decoders to infer the future intensity function. And there are two major types of NPPs. One is based on the autoregressive(AR) model; its hidden states $h_i$ only update when an event occurs. The other follows the hypothesis that the hidden state $h(t)$ changes continuously in time. The continuous-time models hold advantages that they are natural and more suitable for estimating attributes at any time $t$ because of their continuous traits. Nonetheless, this flexibility comes at a cost. Continuous hidden models could suffer from a slower training speed compared with AR-based discrete models. This is because the evolution, likelihood, and sampling processes might demand numerical approximations.
    In this part, we will first give the basics of NPPs and then introduce how to learn the Granger causality in NPPs.
    

    \textbf{Basics of NPPs.} The general process of using the AR-based NPP model to infer Granger causality~\cite{pmlr-v119-zhang20v} is presented as follows. First, we embed each event into a vector $v_i=[\theta(t_i-t_{i_1});V^T z_i$], where $\theta(\cdot)$ is a predefined function, V is the embedding function for events' type, $[\cdot;\cdot]$ could be concatenation and $z_i$ could be the one-hot coding for event type $u_i$. Then, we utilize a sequence encoder(e.g. LSTM or GRU) to encode $\{v_j; j\leq i\}$ to $h_i=Enc(h_{i-1}, v_i)$. Also, there exists a different encoding method in which the encoding is done independently for each i using, e.g., self-attention. This can better capture the long-range dependencies between events but have heavy computing complexity as well.
    
    Next, we aim to decode the hidden state $h_i$ into the intensity function $\lambda_e(t)$. To do this, we need to make some assumptions about $\lambda$. For example, we could predict that the intensity function can be divided into the sum of some interaction-related and time-related functions $\lambda_e(t)=\sum_{m=1}^{M}a_{em} \kappa_m(s)$ similar to what Xu did~\cite{pmlr-v48-xuc16}. Sequentially, we could only infer the $a_{em}$ entries since $\kappa_m(s)$ can be chosen from a large function family in which the functions can represent a wide variety of time-varied patterns. Hence,
    \begin{equation}
        \mathbf{\alpha}:\mathbb{R}^{rank(h_i)}\rightarrow \mathbb{R}_+^{K*S} \nonumber
    \end{equation}
    is the corresponding decoder for this model. Here, $k$ and $S$ are the numbers of event types and basic functions correspondingly. However, the aforementioned method could not fit the continuous hidden state model. Under this circumstance, since $h(t)$ is continuous, thus carrying a lot more time-varying information than $h_i$ do, we can simply define the intensity as:
    \begin{equation}
        \lambda_e(t)=g_e(h(t))
    \end{equation}
    Here, $g_e:\mathbb{R}^{rank(h_i)}\rightarrow R_{>0}$ is a non-linear function (e.g. softplus function) which maps $h(t)$ to the corresponding intensity function for event-type $e$ at time $t$.
    
    As for the training process, most of the NPPs nowadays use the Maximum Likelihood Estimation(MLE) method as most of the traditional PP methods do. They take the negative log-likelihood of MLE as the objective function and use the neural network to optimize it. Besides, there exist alternative methods to use for learning the MLE. For example, if we set the objective as $\mathbb{E}_{X\sim p(X)}[f(X)]$, we can model the point process $P(X)$ using $f(X)$ by variational inference or reinforcement learning.

    \textbf{Inferring Granger Causal Relations from NPPs.} When it comes to inferring the Granger causality, attribution methods need to be used~\cite{pmlr-v119-zhang20v}. That is because, in neural methods, most of the algorithms do not follow the parametrization in the Hawkes processes. On the contrary, their goal is to directly model the processes' intensity function in order to loosen the strictness of Hawkes process and thus gain more accuracy. Since those intensity functions captured all the characteristics of event sequences, we should take full advantage of them. To do that, Zhang et al. first denoted $x_p=[t_1,e_1,...,t_p,e_p,t_{p+1}]$, $\underline{x_p}=[t_1,0,...,t_p,0,t_{p+1}]$ as the baseline input, and $f_k(x_p)=\int_{t_p}^{t_{p+1}}\lambda_e(s)ds$ as the impact function~\cite{pmlr-v119-zhang20v}. For each event type k, we have:
    \begin{equation}
        f_k(x_p)-f_k(\underline{x_p})=\sum_{q=1}^{p}A_q(f_k,x_p,\underline{x_p}) \nonumber
    \end{equation}
    where $A_q(f_k,x_p,\underline{x_p})$ is the attribution(e.g. Integrated Gradients) for the event type of $z_q$. Hence, $A_q(f_k,x_p,\underline{x_p})$ can be regarded as the contribution of $z_j$-type events to the prediction of k-type events given the history $x_p$. Next, Zhang conducted a normalization on $A_q(f_k,x_p,\underline{x_p})$ as
    \begin{equation}
        Y_{e_i,e_j}=\frac{\sum_{s=1}^{s}\sum_{p=1}^{n_s}\sum_{q=1}^{i}\mathbb{I}(k_q^s=e_j)A_q(f_{e_i},x_p^s,\underline{x_p^s})}{\sum_{s=1}^{s}\sum_{p=1}^{n_s}\mathbb{I}(k_q^s=e_j)} \nonumber
    \end{equation}
    Consecutively, the Granger causality between $u_i$ and $u_j$-type events can be inferred from $Y_{e_ie_j}$. This method can measure not only the inhibitive causality but also the magnitude of the causality.
    
    Interestingly, some other neural algorithms just model the intensity function as in Hawkes processes. They set $\mu$ and $\alpha$ as matrices and directly put $H$ and $A$ into the neural networks. Since the input structure is much easier, we could add other hypotheses, like the topological structure between events, and let the neural network(in this case, GCN) optimize $H$ and $A$ iteratively. Then, we could directly infer Granger causality from the matrix $A$.\\
    

\subsection{Other Inferring Approaches}
\label{subsec43}
    In this section, we will not directly model intensity functions in point processes. Instead, we focus on discovering the relationships between different processes (i.e., different types of events). To do that, we could utilize the Graphical Event Model mentioned before and loosen the assumption that each node follows the Hawkes Processes. Historically, Didelez et al. and Meek et al. first introduced the Graph Event Models to capture dependencies among events. Based on common graph methods, they assumed that an event type's intensity function is only related to its parental type. GEMs capture dependencies between various types of events over time, providing a general framework to model the dependency in graph methods. Therefore, similar to the stationary as well as the discrete-time case, constraint-based and score-based approaches can be utilized.\\
    
    \subsubsection{Constraint-based methods}
    Just like the notion \textit{independence} between different random variables, we can define \textit{process independence} for point processes:
    \begin{Definition} (Didelez, 2008~\cite{https://doi.org/10.1111/j.1467-9868.2007.00634.x}; Bhattacharjya et al., 2022~\cite{Bhattacharjya2022ProcessIT})\\
        For processes $X, Y, Z$, s.t. $Y\cap Z=0$, $X$ is a process independent of $Y$ given $Z$ if all events in $X$ have conditional intensities such that if historical information of events in $Z$ is known, then those events in process $Y$ do not provide any further information.
    \end{Definition}
    Meek et al.~\cite{article} and Bhattacharjya et al.~\cite{Bhattacharjya2022ProcessIT} introduced the notion of $\delta^*$-separation, which is based on $d$-separation but released its restriction of not having self-loops and made each self-loop independent of their own history. Then, they proposed a causal dependence assumption with $\delta^*$-separation analogous to the faithfulness assumption. Based on the causal dependence assumption, several constraint-based methods, such as the PC and max-min parents algorithms, are proposed to learn the causal relationships between different types.\\
    
    \subsubsection{Score-based methods}
    Similarly, there are score-based methods that can be applied to GEMs. Bhattacharjya et al.~\cite{NEURIPS2018_f1ababf1} proposed PGEM - a model that assumed its intensity functions are only influenced by whether or not parent types happened in some recent time window. In addition, they used the BIC criterion on conditional intensities $\lambda_{x|u}$ to search for the optimal parent sets for each event type, that is, to infer the graph structure in their PGEM model. The graph structure is a representation of the causal relationships between different types of events. There exist other score testers for inferring the graph structure. For example, we have the NI tester:
    \begin{equation}
        \text{NI score} = \frac{1}{2}\frac{\sum_{z}(\lambda_{x|y,z}-\lambda_{x|\hat{y},z})^2}{\sum_{z}\lambda_{x|y,z}+\lambda_{x|\hat{y},z})^2}
    \end{equation}
    where $y$ and $\hat{y}$ indicate the parental state where $Y$ has or has not appeared in its window. We also have the LR tester:
    \begin{equation}
        \text{LR score} = F_{\chi_{2^{|Z|}}^2}(-2[logL^*(X|Y,Z)-logL^*(X|Z)])
    \end{equation}
    Here, $F(\cdot)$ is the cumulative distribution function of a chi-squared random variable with $2^{|Z|}$ degrees of freedom. Then, we apply a threshold $\tau$ for each tester, that is, when the score is less than $\tau$, there is no causal relationship between type $X$ and type $Y$.\\
    
    \subsubsection{Transfer entropy}
    Recall that Transfer Entropy (TE) can be used to discover causal relationships in discrete-time cases. Here, we can also apply TE to event sequences (i.e., point processes) to identify our continuous-time causal relationships. Specifically, Spinney et al.~\cite{PhysRevE.95.032319} constructed a continuous-time pairwise Transfer Entropy:
    \begin{equation}
        \mathbf{T}_{Y\rightarrow X}=\lim\limits_{\tau\to\infty}\frac{1}{\tau}\sum_{i=1}^{N_X}ln\frac{\lambda_{x|\mathbf{x}<t,\mathbf{y}<t}[\mathbf{x}_{<x_i},\mathbf{y}_{<y_i}]}{\lambda_{x|\mathbf{x}<t}[\mathbf{x}_{<x_i}]}
    \end{equation}
    where $N_X$ is the number of events in the target process and $\tau$ is the length of time when there holds the corresponding intensity function $\lambda_{x|\mathbf{x}<t,\mathbf{y}<t}[\mathbf{x}_{<x_i},\mathbf{y}_{<y_i}]$ and $\lambda_{x|\mathbf{x}<t}[\mathbf{x}_{<x_i}]$. The processes are independent when $\mathbf{T}_{Y\rightarrow X}=0$. We can define the conditional TE similarly. There are some existing consistent methods for estimating the continuous-time TE and its conditional form~\cite{10.1371/journal.pcbi.1008054}.\\
