\section{Background \& preliminaries}\label{sec:prem}

This section begins with the definition of key concepts and assumptions in causal discovery, followed by an overview of three causal graph representations applicable to temporal data. Finally, the problem definitions for causal discovery from MTS and event sequences will be presented.

\begin{table}[h]
    % \tiny %\scriptsize %\footnotesize  %\small
    \caption{Main notations used in this survey.}
    \label{tab:overall_notation}
    \centering
    \begin{tabular}{cc}
       \toprule
       Notation & Description \\
       \midrule
        % $d,N,T$ & number of time-series variate, of observations and of time points, respectively  \\ % constant
        $d, E$ & number of time-series variate, and of event types, respectively \\
        $x_i^t$ & the $i$-th time series at time $t$ in multivariate time series \\
        $N_e(t)$ & the number of the event $e$ occurrences before time $t$ \\
        $\perp \!\!\! \perp, \not \! \perp \!\!\! \perp$ & independent, and not independent\\
        $V,U$ & the set of endogenous variables, and of exogenous variables, respectively  \\
        $\mathcal{G}$ & causal graph \\
        $Pa(x_i)$ & the parent nodes of $x_i$ \\  % to edit
        % Consider to add x->y, sepset, dsepset...
       \bottomrule
    \end{tabular}
\end{table}

\subsection{Key concepts and assumptions in causal discovery}
\label{subsection:key_concepts}
Some key concepts serve as the foundation for inferring causal relationships from temporal data. We establish this common ground before discussing research works. Afterward, we present formal definitions for the structural causal model, $d$-separation, causal Markov condition, causal identifiability and causal minimality with notations detailed in Table \ref{tab:overall_notation}.

\begin{figure*}
    \centering
	\includegraphics[width=1.0\textwidth]{figs/6figs_v2.pdf}
	% \vspace{-3ex}
	\caption{Basic DAGs and a simple structural causal model.}
	% \vspace{-5ex}
	\label{fig:6figs}
\end{figure*}


\textbf{Structural Causal Model (SCM).} Pearl's comprehensive theory of causality, as presented in \cite{pearl2009causality}, enables us to draw causal conclusions from observations using causal hierarchy (PCH) \cite{General/book_of_why_pearl2018book}. From that, the structural causal model is defined as a graphical representation of causal relationships that captures how interventions on one or more variables affect the values of other variables in the data generation mechanism.
Formally, SCM can be represented in a 4-tuple $<V,U,F,P(U)>$, where $V,U$ denote the set of endogenous and exogenous variables respectively, $P(U)$ is the distribution of exogenous variables, and $F$ represents the set of the mapping function.
Specifically, for $f_i \in F$, the model $x_i := f_i(Pa(x_i), u_i), i=1,...,d$ indicates the assignment of the value $x_i$ to a function of its structural parents $Pa(x_i)$ and exogenous variable $u_i$.  % 为统一起见，配图也用x1, x2, x3好了
For each SCM, we can yield a causal graph DAG $G$ by adding one vertex for each $x_i$ and directing edges from each parent variable in $Pa(x_i)$ (the causes) to child $x_i$ (the effect).
The relationship of the SCM and the corresponding DAG is shown in figure \ref{fig:6figs} (a)(b). 


\textbf{\textit{d}-separation.} $d$-separation is a criterion for determining the absence of causal effects between two sets of variables in a graphical model. Two sets of variables are said to be $d$-separated if every path between them is blocked. 
In formal, a set of variables $\mathbf{S}$ \textit{d}-separates two variables if $\mathbf{S}$ blocks all paths between them. 
For the given causal graph in figure \ref{fig:6figs} (d)(e)(f), two vertices $x_1,x_3$ are \textit{d}-separated by the set of vertices $\mathbf{S}$ if $x_2 \in \mathbf{S}$. 
As for the relations in figure \ref{fig:6figs} (c) (a.k.a., a \textit{v-structure} or \textit{collider}), $x_1,x_3$ are also \textit{d}-separated if $x_2$ and none of the descendants of $x_2$ are in set $\mathbf{S}$.

$d$-separation is a fundamental concept in causal discovery because it provides a criterion for determining whether two sets of variables are causally related. If two sets of variables are $d$-separated, then there is no direct or indirect causal effect between them, and they can be considered independent given the observed variables. Conversely, if two sets of variables are not $d$-separated, then there may be a direct or indirect causal effect between them that needs to be accounted for when inferring causal relationships from data. Thus, $d$-separation is an essential tool for identifying causal relationships in graphical models.

\textbf{Causal Markov Condition.} In the causal graph of SCM, each variable is independent of its non-effects given its direct causes \cite{pearl2009causality}. In other words, a variable is conditionally independent of its non-effects (i.e., variables that do not directly cause it) given its parents (i.e., variables that directly cause it). This condition plays an essential role in causal inference. It enables the identification of causal effects from non-experimental data. Formally, the causal Markov condition implies the joint distribution can be factorized according to the following decomposition:
\begin{equation}
    P(\mathbf{x}) = \prod_i^d P(x_i | Pa(x_i)) \nonumber
\end{equation}


\textbf{Markov Equivalence Class(MEC).} Two graphical models belong to the same MEC if they entail the same set of conditional independence relations among the observed variables, regardless of the specific structure of the graph. 
For example, the causal diagrams in Figure \ref{fig:6figs} (d)(e)(f) imply the same \textit{d}-seperation information $x_1 \perp \!\!\! \perp  x_3 | x_2$ and belong to the same MEC. MEC is important because it enables us to identify the minimal set of conditions necessary for inferring causal relationships from non-experimental data.


\textbf{Causal Identifiability.}
A causal effect is identifiable if it can be estimated without making any untestable assumptions or invoking additional information beyond the observed variables. This means that all causal graphs in the same MEC represent equivalent causal structures from an observational viewpoint. In general, causal identifiability requires that the causal graph is acyclic and that all backdoor paths between the treatment and outcome variables are blocked. If these conditions are met, the causal effect can be identified using the $do$-calculus or other causal inference techniques. Thus, the prerequisite of causal discovery is that causal relationships can be identifiable.

\textbf{Causal Minimality.} Consider a DAG $\mathcal{G}$ and a probability distribution $P$, $P$ is said to satisfy the causal minimality with respect to  $\mathcal{G}$ if $P$ is Markovian with respect to $\mathcal{G}$ but not to any proper subgraph of $\mathcal{G}$. It indicates that all the variables are necessary and sufficient to accurately represent the causal relationships while excluding any variables that do not contribute to the causal mechanism. A distribution is minimal with respect to the causal graph if and only if there is no node that is conditionally independent of any of its parents, given the remaining parents. In other words, all the parents are “active”.


Building on the aforementioned concepts, we introduce three assumptions, causal sufficiency, faithfulness, and temporal priority, which are the untestable foundations of causal discovery.

\textbf{Causal Sufficiency.}
A set of variables is causally sufficient if all common causes of all variables are observed \cite{MTS/CB/PC_origin}. This assumption indicates that the causal graph in SCM can reflect the truth data generation process and there is no hidden confounder. Under the assumption of causal sufficiency, the majority of causal discovery algorithms presume that the causal structure can be depicted as a DAG. 
% The unobserved confounder is a nonnegligible issue as it may induce biased effect estimation in observational settings.

\textbf{Faithfulness.}
% We first introduce the \textit{causal faithfulness assumption}.  
Faithfulness asserts that all conditional independence relations of $P$ that hold in the observed data are entailed by the causal model $\mathcal{G}$, and conversely, all conditional independence relations implied by the causal model are also held in the observed data. Note that faithfulness implies causal minimality. If $P$ is faithful and Markovian with respect to $\mathcal{G}$, then the causal minimality is satisfied.

\begin{figure*}
    \centering
	\includegraphics[width=0.7\textwidth]{figs/faithfulness.png}
	% \vspace{-3ex}
	\caption{Example of the faithfulness and causal minimality.}
	% \vspace{-5ex}
	\label{fig:faithfulness}
\end{figure*}

Intuitively, faithfulness is not easy to understand. We try to clarify it with an example \cite{peters2017elements}. As shown in Figure \ref{fig:faithfulness}, we assume the generation process of $\mathcal{G}_1$ as a linear Gaussian SCM:
\begin{align*}
    X &:= N_X\\
    Y &:= aX + N_Y\\
    Z &:= bY + cX + N_Z
\end{align*}
The noise variables $N_X \sim \mathcal{N}(0, \sigma_x^2)$, $N_Y \sim \mathcal{N}(0, \sigma_y^2)$ and $N_Z \sim \mathcal{N}(0, \sigma_z^2)$ are jointly independent. Let us consider a special case that $a \cdot b + c = 0$. In this setting, the variables $X$ and $Z$ are independent. The direction of $Y \rightarrow Z$ would be inverted and the causal model $\mathcal{G}_1$ is degraded to $\mathcal{G}_2$. According to the definition, $\mathcal{G}_1$ and $\mathcal{G}_2$ satisfy the causal minimality. But the faithfulness is violated in this special case, \ie $\mathcal{G}_2$ is not a proper subgraph of $\mathcal{G}_1$.  Thus, the probability of this linear Gaussian model is not faithfulness with respective to $\mathcal{G}_1$. Although $\mathcal{G}_2$ is a proper subgraph of $\mathcal{H}$, the distribution does not satisfy causal minimality because the probability is not Markovian with respect to $\mathcal{H}$.

While faithfulness is untestable in practice, it is crucial for deriving valid causal inferences from data because it ensures that the model correctly represents the data-generating mechanisms. If this assumption is violated, the causal relationships are uncertain which is a disaster for causal discovery methods~\cite{MTS/CB/PC_origin}.

\textbf{Temporal priority.} For two variables, temporal priority means that the cause must have occurred before its effect. It is a foundation assumption of causal discovery from temporal data and creates an asymmetric time relationship in causal processes. The temporal priority helps us to establish the direction of a causal relationship when two variables are causally linked. However, if the sampling frequencies of time series are high, the time difference between events associated with the time series may be indistinguishable. In such cases, two events that occurred at different times could be perceived as instantaneous in the observational time series, leading to contemporaneous causal relationships between causes and effects occurring at different time instants.


\subsection{Causal Structure for Temporal Data}

\begin{figure}
    \centering
	\includegraphics[width=0.9\textwidth]{figs/full_window_summary_graph_v3.pdf}
	% \vspace{-3ex}
	\caption{Causal graphs for discrete-time observations.}
	% \vspace{-5ex}
	\label{fig:full_window_summary_graph}
\end{figure}


For temporal data, the causal relationship can be intuitively defined by the temporal precedence \cite{eichler2012causal} indicating the causes precede their effects. It reveals the causality asymmetric in time and can be used to orient a causal relation when two variables are known to be causally related. 
Based on the temporal precedence, there exist three graphical representations of causal structure, \ie, \textit{full-time causal graph}, \textit{window causal graph}, and \textit{summary causal graph}. 

As illustrated in Figure \ref{fig:full_window_summary_graph} (a), the \textit{full-time causal graph} represents a complete graph of the dynamic systems. For $d$-variate time series $\mathbf{x}$, the measurement at each time point $t$ is a vector $(x_1^t, ..., x_d^t)$. Vertices in full-time causal graphs consist of the set of component $x_1,...,x_d$ at each time point $t$ with lag-specific directed links such as $x_i^{t-k} \to x_j^t$. 
However, it's usually difficult to discover full-time causal graphs due to the single observation for each series at each time point.

To remedy this problem, \textit{window causal graph} is proposed. It assumes a time-homogeneous causal structure such that the dynamics of observation vector $\mathbf{x}$ are governed by $\mathbf{x}^t:=f(\mathbf{x}^{<t}, \mathbf{u}^t)$ where the function $f$ determines the following observation based on past $\mathbf{x}^{<t}$ and the noise $\mathbf{u}^t$.   
As illustrated in Figure \ref{fig:full_window_summary_graph} (b), the window causal graph is represented in a time window, the size of which amounts to the maximum lag in the full-time causal graph.

As shown in Figure \ref{fig:full_window_summary_graph} (c), each time series component is collapsed into a node to form the \textit{summary causal graph}.
The summary graph represents causal relations between time series without referring to time lags \cite{MTS/FCM/nips_PetersJS13}. In many applications,  it is sufficient to model the relations between temporal variables without precisely knowing the interaction between time instants.

For causal discovery from temporal data, most works aim to find the summary causal graph. Nevertheless, summary causal graphs do not always correspond to an SCM, which means they do not enable interventional predictions that are consistent with the underlying time-resolve SCM \cite{background/cg/janzing2018structural,background/cg/uai_RubensteinWBMJG17}.




\subsection{Problem Definitions}

\begin{figure*}
    \centering
	\includegraphics[width=1.0\textwidth]{figs/problem_def_v6.pdf}
	% \vspace{-3ex}
	\caption{The problem description: (a) causal discovery from MTS data, (b) causal discovery from event sequence data.}
	% \vspace{-5ex}
	\label{fig:problem_def}
\end{figure*}


As illustrated in Figure \ref{fig:problem_def}, causal discovery from temporal data can be divided into two problems, \ie, causal discovery from MTS and causal discovery from event sequence. Next, we formally define them respectively.  


\textbf{Causal Discovery from MTS.} Consider a time series with $d$ variables: $\{ \mathbf{x}^t \}_{t \in \mathbb{Z}^+} = \{ ({x}^t_1\ {x}^t_2 \ ... \ {x}^t_d )^{\top}  \}_{t \in \mathbb{Z}^+} $. 
Assume that causal relationships between variables are given by the following structural equation model:
\begin{equation}
    x^t_i := f_i( Pa(x^t_i), u^t_i),\ i=1,...,d, \nonumber
\end{equation}
where for any $i \in \{1,...,d\}$ at time instance $t$, $Pa(x^t_i)$ is the set of direct parents of $x^t_i$ which can be both in the past and at the same time instance. 
$u^t_i$ denotes the independent noise and can denote either measurement noise or driving noise \cite{intro/ts_surveys/peters2022causal} without losing generality.
Causal discovery from MTS aims to find either of the two kinds of outputs, \ie, summary causal graph or window causal graph.
As for the summary causal graph, the output is the adjacency matrix $A \in \mathbb{Z}^{d \times d}$ which summarizes the causal structure, and the $(i,j)$-th entry of the matrix $A$ is $1$ if past observations of $x_i$ enter the structural equation of $x_j^t$ and $0$ otherwise. We say that `$x_i$ causes $x_j$' if $A_{ij}=1$.
As for window causal graph with maximum time lag $K$, the output matrices $W$ and $A^k\ (k \in \{1,...,K\})$ correspond to intra-slice and inter-slice edges, respectively. 
For example, $W_{ij}=1$ denotes the instantaneous dependency $x^t_i \to x^t_j$, while $A_{ij}^k=1$ denotes a lagged dependency $x^{t-k}_i \to x^t_j$ for $k>0$.

\textbf{Causal Discovery from Event Sequence.}  For an event sequence: $\{(t_1,e_1),(t_2,e_2),...\}$, $t_i,i=1,2,...$ indicates the time at which the event occurred, while $e_i,i=1,2,...$ stands for the corresponding event type. We aim to discover the causal relationships between different event types. In general, we can construct a causal graph $G=(g_i),i=1,2,...,n$, where each node represents a type of event sequence. Our mission is to discover the edge in the causal graph. For example, if there is a directed edge from node $g_j$ to node $g_i$, we say event-type $g_j$ is a cause of event-type $g_i$.

