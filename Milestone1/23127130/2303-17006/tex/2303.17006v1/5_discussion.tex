\section{Discussion}
Contrary to our expectations, we find non-uniformity to be a more desirable property in machine-generated responses. Overall, UID scores and surprisal do not correlate with human judgments (Table \ref{tab:judgments}). But when controlled for surprisal, we observe that UID score is correlated with human judgments for certain intervals (examples in Figure \ref{fig:sent_example} and Table \ref{tab:mturk_examples}). Our results suggest that optimizing UID to generate uniform text might not be the right objective for regularizing decoding algorithms. Instead we find that non-uniform information density could be a potential solution to the ``likelihood trap" problem according to which models generate lower quality text (as per human judgments) when sampling from the extremities of their likelihood space \cite{trading}. Consequently, we suggest that decoding algorithms be tuned to follow the information density patterns of human-generated non-uniform data when generating responses outside of the ``safe'' likelihood range as a means to generate higher quality responses across the entire likelihood space.

