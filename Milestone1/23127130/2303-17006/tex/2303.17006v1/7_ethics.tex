\section{Ethical considerations}
In this work, we collected human annotations on dialogue response quality using MTurk. Each HIT in our MTurk study contained one dialogue history and four candidate responses. The annotators could read the history and rate the responses that followed using mouse clicks on their response choices. We provided an additional feedback field for annotators to write comments in. We received very positive feedback on the task from all the annotators who used this feature. There were no restrictions on the minimum or maximum number of examples the annotators had to rate. From a pilot study on MTurk, we found the average time to complete one HIT to be slightly under 2.5 minutes. After considering the average time required and the task difficulty (expressed to be clearly and easily understood by annotators in their comments) we set the payment amount to \$0.5 per HIT for an hourly rate of about \$12 per hour.