@article{alkaissi2023artificial,
  title={Artificial hallucinations in chatgpt: Implications in scientific writing},
  author={Alkaissi, Hussam and McFarlane, Samy I},
  journal={Cureus},
  volume={15},
  number={2},
  year={2023},
  publisher={Cureus}
}

@misc{bing,
title={Reinventing search with a new AI-powered Microsoft Bing and Edge, your copilot for the web},
url= {bit.ly/3mcgskl},
author = {The Official Microsoft Blog}, 
year={2023}, 
month={Feb} 
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@inproceedings{bender2021dangers,
  title={On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?},
  author={Bender, Emily M and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
  booktitle={Proceedings of the 2021 ACM conference on fairness, accountability, and transparency},
  pages={610--623},
  year={2021}
}

@article{carlini2020extracting,
  title={Extracting training data from large language models. arXiv},
  author={Carlini, N and Tramer, F and Wallace, E and Jagielski, M and Herbert-Voss, A and Lee, K and Roberts, A and Brown, T and Song, D and Erlingsson, {\'U} and others},
  journal={Preprint posted online December},
  volume={14},
  year={2020}
}
‌
@misc{chatgpt,
    title={ChatGPT: Optimizing Language Models for Dialogue},
    author={OpenAI},
    year={2022},
    url={https://openai.com/blog/chatgpt/}
}

@article{dodge2021documenting,
  title={Documenting large webtext corpora: A case study on the colossal clean crawled corpus},
  author={Dodge, Jesse and Sap, Maarten and Marasovi{\'c}, Ana and Agnew, William and Ilharco, Gabriel and Groeneveld, Dirk and Mitchell, Margaret and Gardner, Matt},
  journal={arXiv preprint arXiv:2104.08758},
  year={2021}
}


@article{dowling2023chatgpt,
  title={ChatGPT for (finance) research: The Bananarama conjecture},
  author={Dowling, Michael and Lucey, Brian},
  journal={Finance Research Letters},
  pages={103662},
  year={2023},
  publisher={Elsevier}
}

@article{frieder2023mathematical,
  title={Mathematical capabilities of chatgpt},
  author={Frieder, Simon and Pinchetti, Luca and Griffiths, Ryan-Rhys and Salvatori, Tommaso and Lukasiewicz, Thomas and Petersen, Philipp Christian and Chevalier, Alexis and Berner, Julius},
  journal={arXiv preprint arXiv:2301.13867},
  year={2023}
}

@article{garg2022can,
  title={What can transformers learn in-context? a case study of simple function classes},
  author={Garg, Shivam and Tsipras, Dimitris and Liang, Percy and Valiant, Gregory},
  journal={arXiv preprint arXiv:2208.01066},
  year={2022}
}

@article{kocon2023chatgpt,
  title={ChatGPT: Jack of all trades, master of none},
  author={Koco{\'n}, Jan and Cichecki, Igor and Kaszyca, Oliwier and Kochanek, Mateusz and Szyd{\l}o, Dominika and Baran, Joanna and Bielaniewicz, Julita and Gruza, Marcin and Janz, Arkadiusz and Kanclerz, Kamil and others},
  journal={arXiv preprint arXiv:2302.10724},
  year={2023}
}

@article{kuccuk2020stance,
  title={Stance detection: A survey},
  author={K{\"u}{\c{c}}{\"u}k, Dilek and Can, Fazli},
  journal={ACM Computing Surveys (CSUR)},
  volume={53},
  number={1},
  pages={1--37},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@article{kung2023performance,
  title={Performance of ChatGPT on USMLE: Potential for AI-assisted medical education using large language models},
  author={Kung, Tiffany H and Cheatham, Morgan and Medenilla, Arielle and Sillos, Czarina and De Leon, Lorie and Elepa{\~n}o, Camille and Madriaga, Maria and Aggabao, Rimel and Diaz-Candido, Giezel and Maningo, James and others},
  journal={PLOS Digital Health},
  volume={2},
  number={2},
  pages={e0000198},
  year={2023},
  publisher={Public Library of Science}
}

@inproceedings{li2021p,
  title={P-stance: A large dataset for stance detection in political domain},
  author={Li, Yingjie and Sosea, Tiberiu and Sawant, Aditya and Nair, Ajith Jayaraman and Inkpen, Diana and Caragea, Cornelia},
  booktitle={Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021},
  pages={2355--2365},
  year={2021}
}

@inproceedings{mohammad2016semeval,
  title={Semeval-2016 task 6: Detecting stance in tweets},
  author={Mohammad, Saif and Kiritchenko, Svetlana and Sobhani, Parinaz and Zhu, Xiaodan and Cherry, Colin},
  booktitle={Proceedings of the 10th international workshop on semantic evaluation (SemEval-2016)},
  pages={31--41},
  year={2016}
}

@article{mohammad2017stance,
  title={Stance and sentiment in tweets},
  author={Mohammad, Saif M and Sobhani, Parinaz and Kiritchenko, Svetlana},
  journal={ACM Transactions on Internet Technology (TOIT)},
  volume={17},
  number={3},
  pages={1--23},
  year={2017},
  publisher={ACM New York, NY, USA}
}

@incollection{mccloskey1989catastrophic,
  title={Catastrophic interference in connectionist networks: The sequential learning problem},
  author={McCloskey, Michael and Cohen, Neal J},
  booktitle={Psychology of learning and motivation},
  volume={24},
  pages={109--165},
  year={1989},
  publisher={Elsevier}
}

@misc{milmo2023chatgpt,
    title={ChatGPT reaches 100 million users two months after launch},
    author={Dan Milmo},
    year={2023},
    url={bit.ly/3SvdJPj}
}

@article{min2022rethinking,
  title={Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?},
  author={Min, Sewon and Lyu, Xinxi and Holtzman, Ari and Artetxe, Mikel and Lewis, Mike and Hajishirzi, Hannaneh and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2202.12837},
  year={2022}
}

@article{gpt4,
  title={GPT-4 Technical Report},
  author={OpenAI},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{patel2023chatgpt,
  title={ChatGPT: the future of discharge summaries?},
  author={Patel, Sajan B and Lam, Kyle},
  journal={The Lancet Digital Health},
  volume={5},
  number={3},
  pages={e107--e108},
  year={2023},
  publisher={Elsevier}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{sobania2023analysis,
  title={An analysis of the automatic bug fixing performance of chatgpt},
  author={Sobania, Dominik and Briesch, Martin and Hanna, Carol and Petke, Justyna},
  journal={arXiv preprint arXiv:2301.08653},
  year={2023}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{stokel2023chatgpt,
  title={What ChatGPT and generative AI mean for science},
  author={Stokel-Walker, Chris and Van Noorden, Richard},
  journal={Nature},
  volume={614},
  number={7947},
  pages={214--216},
  year={2023},
  publisher={Nature}
}

@article{taecharungroj2023can,
  title={“What Can ChatGPT Do?” Analyzing Early Reactions to the Innovative AI Chatbot on Twitter},
  author={Taecharungroj, Viriya},
  journal={Big Data and Cognitive Computing},
  volume={7},
  number={1},
  pages={35},
  year={2023},
  publisher={MDPI}
}

@book{terwiesch, 
title={Would Chat GPT3 Get a Wharton MBA? A Prediction Based on Its Performance in the Operations Management Course}, 
url={whr.tn/41pxDzn}, 
author={Terwiesch, Christian} }

‌@article{van2023chatgpt,
  title={ChatGPT: five priorities for research},
  author={van Dis, Eva AM and Bollen, Johan and Zuidema, Willem and van Rooij, Robert and Bockting, Claudi L},
  journal={Nature},
  volume={614},
  number={7947},
  pages={224--226},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{wu2023large,
  title={Large Language Models Can Be Used to Estimate the Ideologies of Politicians in a Zero-Shot Learning Setting}, 
  author={Patrick Y. Wu and Joshua A. Tucker and Jonathan Nagler and Solomon Messing},
  year={2023},
  eprint={2303.12057},
  archivePrefix={arXiv},
  primaryClass={cs.CY}
}

@article{zhang2022would,
  title={How would Stance Detection Techniques Evolve after the Launch of ChatGPT?},
  author={Zhang, Bowen and Ding, Daijun and Jing, Liwen},
  journal={arXiv preprint arXiv:2212.14548},
  year={2022}
}