\documentclass{article}

\usepackage{arxiv}

\usepackage{microtype}
\usepackage{graphicx}
% \usepackage{subfigure}

\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
\usepackage{hyperref}

\usepackage{natbib}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

\usepackage{algorithm}
\usepackage{algorithmic}


% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{assumption}{Assumption}
\theoremstyle{remark}
\newtheorem{remark}{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}





% ===================================================================================
\usepackage{caption}
\usepackage{subcaption}

\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Assumption:}}


\renewcommand{\t}{\text}
\newcommand{\op}[1]{\operatorname{#1}}
% Math fonts +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\newcommand{\C}[1]{{\mathcal{#1}}} % math Calligraphy
\newcommand{\B}[1]{{\mathbb{#1}}} % math Black board
\newcommand{\E}[1]{{\mathscr{#1}}} % Euler script
\newcommand{\F}[1]{{\mathfrak{#1}}}

% \pagecolor[HTML]{B6B2B0}
% ===================================================================================

\title{Stochastic Submodular Bandits with Delayed Composite Anonymous Bandit Feedback}

\renewcommand{\headeright}{}
\renewcommand{\undertitle}{}
% \renewcommand{\shorttitle}{delayed submodular bandits}


\author{ Mohammad Pedramfar \\
	\texttt{m.pedramfar15@alumni.imperial.ac.uk} \\
	\And
	Vaneet Aggarwal \\
    Purdue University, West Lafayette, Indiana, USA \\
	\texttt{vaneet@purdue.edu} \\
}

\date{}

\begin{document}

\maketitle

\begin{abstract}
This paper investigates the problem of combinatorial multiarmed bandits with stochastic submodular (in
expectation) rewards and full-bandit delayed feedback, where the delayed feedback is assumed to be composite and anonymous. In other words, the delayed feedback is composed of components of rewards from past actions, with unknown division among the sub-components. Three models of delayed feedback: bounded adversarial, stochastic independent, and stochastic conditionally independent are studied, and regret bounds are derived for each of the delay models. Ignoring the problem dependent parameters, we show that regret bound for all the delay models is $\tilde{O}(T^{2/3} + T^{1/3} \nu)$ for time horizon $T$, where $\nu$ is a delay parameter defined differently in the three cases, thus demonstrating an additive term in regret with delay in all the three delay models.  The considered algorithm is demonstrated to outperform other full-bandit approaches with delayed composite anonymous feedback. 


\end{abstract}

% ===============================================================================================

\section{Introduction}


Many real world sequential decision problems can be modeled using the framework of stochastic multi-armed bandits (MAB), such as  scheduling,  assignment problems, ad-campaigns, and product recommendations. In these problems, the decision maker sequentially selects actions and receives stochastic rewards from an unknown distribution. The objective is to maximize the expected cumulative reward over a time horizon. Such problems result in a trade-off between trying actions to learn the system (\textit{exploration}) and  taking the action that is empirically the best seen so far (\textit{exploitation}). 

Combinatorial MAB (CMAB) involves the problem of  finding the best subset of
$K$ out of $N$ items to optimize a possibly nonlinear function of reward of each item. Such a problem has  applications in cloud storage \cite{xiang2014joint},  cross-selling item selection \cite{wong2003mpis}, social influence maximization \cite{agarwal2022stochastic}, etc. The key challenge in CMAB is the combinatorial $N$-choose-$K$ decision space, which can be very large. This problem can be converted to standard MAB with an exponentially large action space, although needing an exponentially large time horizon to even explore each action once. Thus, the algorithms for CMAB aim to not have this exponential complexity while still providing regret bounds. An important class of combinatorial bandits is submodular bandits; which is based on the intuition that opening additional restaurants in
a small market may result in diminishing returns due to
market saturation. A set
function $f : 2^\Omega \to \mathbb{R}$ defined on a finite ground set $\Omega$ is
said to be submodular if it satisfies the diminishing return
property: for all $A \subseteq B \subseteq \Omega$, and $x \in  \Omega \setminus B$, it holds that $f(A \cup \{x\}) - f(A) \geq f(B \cup \{x\}) - f(B)$ \cite{nemhauser1978analysis}. 
Multiple applications for  CMABs with submodular rewards have been described in detail in \cite{nie22_explor_then_commit_algor_for}, including social influence maximization, recommender systems, and crowdsourcing. 
In these setups, the function is also monotone (adding more restaurants give better returns, adding more seed users give better social influence), where for all $A \subseteq B \subseteq \Omega$, $f(A) \leq f(B)$, and thus we also assume monotononicity in the submodular functions. 

Feedback plays an important role in how challenging the CMAB problem is.  When the decision maker only observes a (numerical) reward for the action taken, that is known as bandit or full-bandit feedback. When the decision maker observes additional information, such as contributions of each base arm in the action, that is semi-bandit feedback. Semi-bandit feedback greatly facilitates learning. Furthermore, there are two common formalizations depending on the assumed nature of environments: the stochastic
setting and the adversarial setting. In the adversarial setting, the reward sequence is generated
by an unrestricted adversary, potentially based on the history of decision makerâ€™s actions. In the
stochastic environment, the reward of each arm is drawn independently from a fixed distribution. For  CMAB with submodular and monotone rewards, stochastic setting is not a special case of the adversarial setting since in the adversarial setting, the
environment chooses a sequence of monotone and submodular functions $\{f_1, \cdots , f_T \}$, while the stochastic setup assumes $f_t$ to be monotone and submodular in expectation \cite{nie22_explor_then_commit_algor_for}.  In this paper, we study the impact of full-bandit feedback in the stochastic setting for  CMAB with submodular rewards and cardinality constraints. In this case,  the regret analysis with full-bandit feedback has been studied in the adversarial setting in \cite{niazadeh2021online}, and in stochastic setting in \cite{nie22_explor_then_commit_algor_for}. 


In the prior works on  CMAB as mentioned earlier, the feedback is available immediately after the action is taken. However, this may not always be the case. Instead of receiving the reward in a single step, it can be
spread over multiple number of time steps after the action was chosen. After every action choice,
the player receives the sum total of all the rewards from the previous actions which are due at this
particular step. The difficulty of this setting is due to the fact that the agent does not know how
this aggregated reward has been constituted from the previous actions chosen. This setting is called delayed composite anonymous feedback. Such feedback arise in multiple practical setups. As an example, we consider a social influence maximization problem. Consider a case of social network where a company developed an application and wants
to market it through the network. The best way to do this
is selecting a set of highly influential users and hope they
can love the application and recommend their friends to use
it. Influence maximization is a problem of finding a small
subset (seed set) in a network that can achieve maximum influence. This subset selection problem in social networks is
commonly modeled as an offline submodular optimization
problem \cite{domingos2001mining,kempe2003maximizing,chen2010scalable}. However, when the seed set is selected, the propagation
of influence from one person to another may incur a certain
amount of time delay and is not immediate \cite{chen2012time}. The time-delay phenomena in information diffusion
has also been explored in statistical physics \cite{iribarren2009impact,karsai2011small}. The spread of influence diffusion, and that at each time we can only observe the aggregate reward limits us to know the composition of the rewards into the different actions in the past. Further, the application developer, in most cases, will only be able to see the aggregate reward leading to this being a bandit feedback. This motivates our study of stochastic  CMAB with submodular rewards and delayed composite anonymous bandit feedback.



To the best of our knowledge, this is the first work on CMAB with delayed feedback. For stochastic  CMAB with monotone and submodular rewards, cardinality constraint, and bandit feedback, the regret bounds have been studied in \cite{nie22_explor_then_commit_algor_for}, where the regret was shown to be upper bounded by $\tilde{O}(kn^{1/3} T^{2/3})$. We note that with bandit feedback for  CMABs with submodular rewards, there are no results on better than $\tilde{O}(T^{2/3})$ regret in any of adversarial or stochastic settings. The problem becomes further challenging in the presence of delayed composite anonymous  feedback. In this paper, we consider three models of delays. The first model of delay is `Unbounded Stochastic Independent Delay'. In this model, different delay distributions can be chosen at each time, and these delay distributions are independent of each other. The second model is `Unbounded Stochastic Conditionally Independent Delay'. In this model, the delay distribution does not only depend on time, but also on the set chosen. The third model is `Bounded Adversarial Delay'. In this model, the maximum delay at each time can be chosen arbitrarily as long as it is bounded. We note that in stochastic cases, the delay is not bounded, while is governed by the tight family of distributions. In the adversarial case, there is a bound on the maximum delay, while the process generating this delay does not need to have any independence or other assumption. Thus, the results of stochastic and adversarial setups do not follow from each other. In particular, this is the first work where the delay distribution is allowed to change over time. This gives new models for delayed composite anonymous feedback which are more general than that considered in the literature.  In each of the three models of delay, this paper derives novel regret bounds. 




In our analysis, we define the notion of upper tail bounds, which measures the tightness of a family of distributions, and use it to bound the regret. This notion allows us to reduce the complexity of considering a family of delay distributions to considering only a single delay distribution. Then we use Bernstein inequality to control the effect of past actions on the observed reward of the current action that is being repeated. This allows us to obtain a regret upper bound in terms of the expected value of the upper tail bound. The use of upper tail bounds for studying regret in bandits with delayed feedback is novel and has not been considered in the literature earlier, to the best of our knowledge. 

The main contributions of this paper can be summarized as follows

\begin{itemize}
\item We study the regret bounds for a stochastic CMAB problem with a monotone and submodular reward function (in expectation), cardinality constraint, and composite anonymous bandit feedback. The regret bound with delayed feedback has been studied for the first time for any CMAB problem with submodular rewards in this paper, to the best of our knowledge. 



\item We study the ETCG algorithm, first proposed in \cite{nie22_explor_then_commit_algor_for}, and find its guarantee in the three delayed feedback models. The models are: bounded adversarial delay,  stochastic independence delay, and stochastic conditional independence delay model. 


\item The analysis in this paper shows that we can achieve expected cumulative $(1-1/e)$-regret of ETCG algorithm which is bounded by $O(kn^{1/3} T^{2/3} (\log(T))^{1/2}) + O(kn^{2/3}T^{1/3} d)$ for the bounded adversarial delay of $d$, by $O(kn^{1/3}T^{2/3}\log(T))
      + O(kn^{2/3}T^{1/3}\B{E}(\tau))$ for the stochastic independent delay with the upper tail bound of expected delay $\tau$ (described formally in the results), and $O(k^2n^{4/3}T^{2/3}\log(T))
      + O(k^2n^{5/3}T^{1/3}\B{E}(\tau))$ for stochastic conditionally independent delay with the upper tail bound of expected delay $\tau$ (described formally in the results). We note that while the stochastic independence is a special case of stochastic conditional independence, the regret bounds with stochastic independence are better as expected. Further, ignoring the problem dependent parameters, this show that regret bound for all the delay models is $\tilde{O}(T^{2/3} + T^{1/3} \nu)$, where $\nu=d$ in the bounded adversarial delay model and $\nu = \B{E}(\tau)$ in the stochastic delay model. 

\item We also demonstrate the generalizability of our analysis of the delayed composite anonymous feedback in combinatorial bandits as long as there exists an algorithm for the offline problem satisfying a certain robustness condition. 
We obtain regret bounds for a general meta-algorithm described in (\cite{nie2023framework}), where ETCG is a special case of, for delayed composite anonymous feedback. As a special case, we achieve regret bounds for submodular bandits with knapsack constraints, non-submodular bandits, reserve pricing, etc. 


\item Through simulations  with synthetic data, we demonstrate that ETCG outperforms other full-bandit methods in the presence of delayed composite anonymous feedback.
\end{itemize}

\section{Related Work}
We note that  this is the first work to derive regret bounds for CMAB with submodular and monotone rewards and delayed feedback. Thus, the most related work can be divided into the results for CMAB with submodular and monotone rewards, and that for MAB with delayed feedback, as will be described next. 

\subsection{Combinatorial Submodular Bandits}

CMABs have been widely studied due to multiple applications. While the problem of CMAB is general and there are multiple studies that do not use submodular rewards \cite{agarwal2021dart,agarwal2022stochastic,dani2008stochastic,rejwan2020top}, we consider CMAB with monotone and submodular rewards. The assumption of monotonicity and submodularity in reward functions is common in the literature \cite{streeter2010online,niazadeh2021online,nie22_explor_then_commit_algor_for}. For CMAB with monotone and submodular rewards, without any further constraints, the optimal selection will be the entire set. Thus, additional assumptions are introduced in the model, including cardinality constraint \cite{nemhauser1978analysis} and knapsack constraints \cite{sviridenko2004note}. This paper considers CMAB with submodular and monotone rewards and cardinality constraint. 

Further, we note that feedback pays an important role in CMAB decision making.  CMAB with submodular and monotone rewards and cardinality constraint has been studied with semi-bandit feedback \cite{lin2015stochastic,niazadeh2021online,zhang2019online,zhu2021projection,chen2018projection,takemori2020submodular}. The semi-bandit feedback setting provides more information as compared to the full-bandit setting which is why we consider the full-bandit (or bandit) feedback. CMAB with submodular and monotone rewards,  cardinality constraint, and full-bandit feedback has been studied in both adversarial setting \cite{niazadeh2021online} and in stochastic setting \cite{nie22_explor_then_commit_algor_for}. This paper studies the stochastic setting. 

It is worth noting that for submodular bandits, the stochastic reward case is not a special case of the adversarial reward case and the guarantees for the stochastic reward case are not necessarily better than the adversarial reward case.
In the adversarial setting, the environment chooses a sequence of monotone and submodular functions $\{f_1 , \cdots , f_T \}$.
This is incompatible with the stochastic reward setting since we only require the set function $f_t$ to be monotone and submodular in expectation.
Thus, the results on adversarial submodular bandits will not lead to results for the stochastic submodular setting.

These works for CMAB do not study regret bound with delayed feedback, which is the focus of this paper. 



\subsection{Bandits With Delayed Rewards}

The bandit problem with (non-anonymous) delayed feedback was first studied by \cite{pmlr-v28-joulani13}.
In the non-anonymous setting, the reward will be delayed and at each time-step, the agent observers a set of the form $\{(t, r_t) \mid t \in I_t\}$ where $I_t$ is a set of time-steps in the past.
In the aggregated anonymous setting, first studied by \cite{pike-burke18_bandit_delay_aggreg_anony_feedb}, the reward for each arm is obtained at some point in the future, so that the agent will receive the aggregated reward for some of the past actions at each time-step.
\cite{pmlr-v75-cesa-bianchi18a} extended the reward model so that the reward of an action is not immediately observed by the agent, but rather spread over at most $d$ consecutive steps in an adversarial way.
However, they also assumed that the bandit is adversarial.
\cite{garg19_stoch_bandit_delay_compos_anony_feedb} considered the stochastic case and provided an algorithm with a sub-linear regret bound of $\tilde{O}(n^{1/2}T^{1/2}) + O(n\log(T)d)$.
In this setting, for each arm $a$, the there is a random distribution $\Delta_a$ over the set $\{0, 1, \cdots, d\}$ and at each time-step, when the agent plays $a$, the delay is sampled from $\Delta_a$.
\cite{Wang_Wang_Huang_2021} also considers unbounded delay and proves the regret bound of $\tilde{O}(n^{1/2}T^{1/2}) + O(\nu)$, where $\nu$ depends on the delay distribution and $n$ but not on $T$.
They also considered the case with adversarial but bounded delay and proved a regret bound of $\tilde{O}(n^{1/2}T^{2/3}) + O(T^{2/3} d)$.

Note that, in the submodular setting, any algorithm that does not exploit the combinatorial structure of the arms must take at least every action once which can be suboptimal since the number of arms is at least $\binom{n}{k}$ which grows exponentially.

In this paper, we extend the delay model further by letting the random delay distribution also depend on time (See Remark~\ref{R:new_general_delay} for more details).

\section{Problem Statement}
Let $T$ be the time horizon, $\Omega$ be the ground set of base arms, and $n := |\Omega|$.
Also let $\C{T}$ be a family of probability distributions on non-negative integers.
At each time-step $t \geq 1$, the agent chooses an action $S_t$ from the set 
$\C{S} = \{S | S \subseteq \Omega,\; |S| \leq k\}$,
where $k$ is the a given positive integer.

The environment chooses a delay distribution $\delta_t \in \C{T}$.
The observation $x_t$ will be given by the formula
\[
x_t = \sum_{i = 1}^t f_i(S_i) \delta_i(t-i),
\]
where $f_t(S)$ is sampled from $F_t(S)$, the stochastic reward function taking its values in $[0, 1]$.
Moreover, we assume that $\B{E}[F_t(S)] = f(S)$, where $f : 2^{\Omega} \rightarrow [0, 1]$ a monotone and submodular function. We will use $X_t$ to denote the random variable representing the observation at time $t$.


For $\alpha \in (0, 1]$, the $\alpha$-regret is defined by
\[
\C{R}_\alpha :=
\sum_{t = 1}^{T} \left( \alpha f(S^*) - f(S_t) \right),
\]
where $S^* := \op{argmax}_{S \in \C{S}} f(S)$ is the optimal action.
In the offline problem with deterministic $f$, finding the optimal action $S^*$ is NP-hard.
In fact, for $\alpha > 1 - 1/e$, \cite{feige98} showed that finding an action which is at least as good as $\alpha f(S^*)$ is NP-hard.
However, the standard greedy approach obtains a set which is at least as good as $(1-1/e)f(S^*)$ \cite{nemhauser1978analysis}.
Therefore, throughout this paper, we will focus on minimizing $(1-1/e)$-regret and drop the subscript when there is no ambiguity.

We consider three settings: bounded adversarial delay and unbounded stochastic independent delay, and unbounded stochastic conditionally independent delay, described next.


\subsection{Unbounded Stochastic Independent Delay}
In the unbounded stochastic independent delay case, we assume that there is a sequence of random delay distributions $(\Delta_t)_{t=1}^{\infty}$ that is pair-wise independent, such that
\[
X_t = \sum_{i = 1}^t F_i(S_i) \Delta_i(t-i).
\]
In other words, at each time-step $t$, the observed reward is based on all the actions that have been taken in the past and the action taken in time-step $i \leq t$ contributes to the observation proportional to the value of the delay distribution at time $i$, $\Delta_i$, evaluated at $t-i$.
We call this feedback model \textit{composite anonymous unbounded stochastic independent delay feedback}.

To define $\Delta_t$, let $(\delta_i)_{i \in \C{J}}$ be distributions chosen from $\C{T}$, where $\C{J}$ is a finite index set and each 
$\delta_i$ is represented by a vector of its probability mass function. 
Thus, $\delta_i(x) = \B{P}(\delta_i = x)$, for all $x \geq 0$.
Let $P_t$ be a random variables taking values in $\C{J}$, where $P_t(i) = \B{P}(P_t = i)$.
Further, we define $\Delta_t(x) := \sum_{i \in \C{J}} P_t(i) \delta_i(x)$, for all $x \geq 0$.
Finally, $\Delta_t$ is defined as a vector $(\Delta_t(0), \Delta_t(1), \cdots)$.
Note that $\sum_{i = 0}^\infty \Delta_t(i) = 1$.
The expectation of $\Delta_t$ over the randomness of $P_t$ is denoted by $\B{E}_{\C{T}}(\Delta_t)$ which is a distribution given $\delta_i$'s are distributions.

More generally, we may drop the assumption that $\C{J}$ is finite and define $\Delta_t$ more directly as follows.
Each $\Delta_t$ is a random variable taking values in the set $\C{T}$.
In other words, for all $x \geq 0$, the value of $\Delta_t(x) = \Delta_t(\{x\})$ is a random variable taking values in $[0, 1]$ such that $\sum_{i = 0}^\infty \Delta_t(i) = \Delta_t(\{0, 1, 2, \cdots\}) = 1$.
We define $\B{E}_{\C{T}}(\Delta_t)$ as the distribution over the set of non-negative integers for which we have
\[
\forall x \geq 0
,\quad
\B{E}_{\C{T}}(\Delta_t)(\{x\}) = \B{E}_{\C{T}}(\Delta_t(\{x\})) \in [0, 1].
\]

We will also explain these definitions by an example. 
Let $\C{T}$ be a family of distributions supported on $\{0, 1, 2\}$.
We choose $\C{J} = \{1, 2\}$, with $\delta_i$ as the uniform distribution over $\{0, 1\}$
and $\delta_2$ as the uniform distribution over $\{0, 2\}$.
Then, we have $\delta_1(0) = \delta_1(1) = 1/2$ and $\delta_2(0) = \delta_2(2) = 1/2$.
Further, let $P_1$ be a random variable such that $P_1(1) + P_1(2) = 1$.
Then, $\Delta_1(x) = \sum_{i = 1,2} P_1(i) \delta_i(x)$ gives 
$\Delta_1(0) = P_1(1)/2 + P_1(2)/2$, $\Delta_1(1) = P_1(1)/2$ and $\Delta_1(2) = P_1(2)/2$.


Note that the independence implies that $\Delta_t$ can not depend on the action $S_t$, as this action depends on the history of observations, which is not independent from $(\Delta_j)_{j = 1}^{t-1}$.

Without any restriction on the delay distributions, there may not be any reward within time $T$ and thus no structure of the rewards can be exploited.
Thus, we need to have some guarantee that the delays do not escape to infinity.
An appropriate formalization of this idea is achieved using the following tightness assumption.

\textbf{Assumption: }
The family of distributions $(\B{E}_{\C{T}}(\Delta_t))_{t = 1}^{\infty}$ is tight.

Recall that a family $(\delta_i)_{i \in I}$ is called tight if and only if for every positive real number $\epsilon$, there is an integer $j_{\epsilon}$ such that 
$\delta_i( \{ x \geq j_{\epsilon} \} ) \leq \epsilon$, for all $i \in I$. (See e.g. \cite{billingsley1995probability})


\begin{remark}
If $\C{T}$ is tight, then $(\B{E}_{\C{T}}(\Delta_t))_{t = 1}^{\infty}$ is trivially tight.
Note that if $\C{T}$ is finite, then it is tight.
Similarly, if $(\B{E}_{\C{T}}(\Delta_t))_{t = 1}^{\infty}$ is constant and therefore only takes one value, then it is tight.
As a special case, if $(\Delta_t)_{t=1}^{\infty}$ is identically distributed, then $(\B{E}_{\C{T}}(\Delta_t))_{t = 1}^{\infty}$ is constant and therefore tight.
\end{remark}

To quantify the tightness of a family of probability distribution, we define the notion of \textit{upper tail bound}.

\begin{definition}
Let $(\delta_i)_{i \in I}$ be a family of probability distributions over the set of non-negative integers.
We say $\delta$ is an \textit{upper tail bound} for this family if
\[ 
\delta_i( \{ x \geq j \} ) \leq \delta( \{ x \geq j \} ),
\]
for all $i \in I$ and $j \geq 0$.
\end{definition}

In the following result, we show that the  tightness and the existence of upper tail bounds are equivalent.

\begin{lemma}\label{L:tightness_equiv_upper_bound}
Let $(\delta_i)_{i \in I}$ be a family of probability distributions over the set of non-negative integers. 
Then this family is tight, if and only if it has an upper tail bound.
\end{lemma}
\begin{proof}
The detailed proof is provided in Appendix \ref{proof_lem_tightness_equiv_upper_bound}.  
\end{proof}

A tail upper bound allows us to estimate and bound the effect of past actions on the current observed reward.
More precisely, the effect of an action taken at time $i$ on the observer reward at $t$ is proportional to $\Delta_i(t-i)$, which can be bounded in expectation by $\tau$.
\[
  \B{E}_{\C{T}}(\Delta_i(t-i)) \leq \B{E}_{\C{T}}(\Delta_i(\{x \geq t-i\})) \leq \tau(\{x \geq t-i\}).
\]
As we will see, only the expected value of the upper tail bound appears in the regret bound.



\subsection{Unbounded Stochastic Conditionally Independent Delay}
In the unbounded stochastic conditionally independent delay case, we assume that there is a family of random delay distributions $\{\Delta_{t, S}\}_{t \geq 1, S \in \C{S}}$ such that for any $S \in \C{S}$, the sequence $(\Delta_{t, S})_{t=1}^{\infty}$ is pair-wise independent and
\[
X_t = \sum_{i = 1}^t F_i(S_i) \Delta_{i, S_i}(t-i).
\]
We call this feedback model \textit{composite anonymous unbounded stochastic conditionally independent delay feedback}.

In this case the delay $\Delta_{t} = \Delta_{t, S_t}$ can depend on the action $S_t$, but conditioned on the current action, it is independent of (some of the) other conditional delays.

In this setting, similar to the stochastic independent delay setting, we assume that the sequence $\{\B{E}_{\C{T}}(\Delta_{t, S})\}_{t \geq 1, S \in \C{S}}$ is tight.

\begin{remark}\label{R:new_general_delay}
  In previously considered stochastic composite anonymous feedback models (e.g.~\cite{Wang_Wang_Huang_2021, garg19_stoch_bandit_delay_compos_anony_feedb}),
  the delay distribution is independent of time.
  In other words, every action $S$ has a corresponding random delay distribution $\Delta_S$, and the sequence $(\Delta_{t, S})_{t = 1}^{\infty}$ is independent and identically distributed.
  Therefore, the number of distributions in the set $\{\B{E}_{\C{T}}(\Delta_{t, S})\}_{t \geq 1, S \in \C{S}}$ is less than or equal to the number of arms, which is finite.
  Hence the family $\{\B{E}_{\C{T}}(\Delta_{t, S})\}_{t \geq 1, S \in \C{S}}$ is tight.
\end{remark}


\subsection{Bounded Adversarial Delay}
In the bounded adversarial delay case, we assume that there is an integer $d \geq 0$ such that for all $\delta \in \C{T}$, we have $\delta(\{ x > d\}) = 0$. 
Here we have
\[
X_t = \sum_{i = \max\{1, t-d\}}^t F_i(S_i) \delta_i(t-i),
\]
where $(\delta_t)_{t = 1}^{\infty}$ is a sequence of distributions in $\C{T}$ chosen by the environment.
Here we used $\delta$ instead of $\Delta$ to emphasize the fact that these distributions are not chosen according to some random variable with desirable properties.
In fact, the environment may choose $\delta_t$ non-obliviously, that is with the full knowledge of the history up to the time-step $t$.
We call this feedback model \textit{composite anonymous bounded adversarial delay feedback}.


\section{Algorithm}

For the algorithm design, we use the algorithm Explore-Then-Commit-Greedy (ETCG) algorithm, as proposed in \cite{nie22_explor_then_commit_algor_for}.
We start with $S^{(0)} = \emptyset$ in phase $i=0$.
In each phase $i \in \{1, \cdots, k\}$, we go over the list of all base arms $\Omega \setminus S^{(i-1)}$.
For each such base arm, we take the action $S^{(i-1)} \cup \{a\}$ for $m$ times and store the empirical mean in the variable $\bar{X}_{i, a}$.
Afterwards, we let $a_i$ to be the base arm which corresponded to the highest empirical mean and define $S^{(i)} := S^{(i-1)} \cup \{a_i\}$.
After the end of phase $k$, we  keep taking the action $S^{(k)}$ for the remaining time. The algorithm is summarized in Algorithm \ref{ALG:main}. 


\begin{algorithm}[ht]
  \caption{ETCG algorithm}\label{ALG:main}
  \begin{algorithmic}[1]
    \REQUIRE{ Set of base arms $\Omega$, horizon $T$, cardinality constraint $k$ }
    \ENSURE{ $n \leq T$  }
    
    \STATE{ $S^{(0)} \leftarrow \emptyset$, $n \leftarrow |\Omega|$ }
    \STATE{ $m \leftarrow \lceil (T/n)^{2/3} \rceil$ }
    \FOR{ phase $i \in \{1, 2, \cdots, k \}$ }
      \FOR{ arm $a \in \Omega \setminus S^{(i-1)}$ }
        \STATE{ Play $S^{(i-1)} \cup \{a\}$ arm $m$ times }
        \STATE{ Calculate the empirical mean $\bar{x}_{i, a}$ }
      \ENDFOR
      \STATE{ $a_i \leftarrow \op{argmax}_{a \in \Omega \setminus S^{(i-1)}} \bar{x}_{i, a}$ }
      \STATE{ $S^{(i)} \leftarrow S^{(i-1)} \cup \{a_i\}$ }
    \ENDFOR
    \FOR{ remaining time }
      \STATE{ Play action $S^{(k)}$ }
    \ENDFOR
  \end{algorithmic}
\end{algorithm}


\section{Regret Analysis}
In this section, we provide the main results of the paper that shows the regret bound of Algorithm \ref{ALG:main} with delayed composite feedback for different feedback models. 

We define two main events that control the delay and the randomness of the observation.
Let 
\[
  I = \{ (i, a) \mid 1 \leq i \leq k, a \in \Omega \setminus S^{i-1} \}
\]
and define
\[ \C{E} := \left\{
    |\bar{F}_{i, a} - f(S^{i-1}\cup\{a\})| \leq \op{rad}
    \mid 
    (i, a) \in I
\right\}, \]
and
\[ \C{E}'_d := \left\{
    |\bar{F}_{i, a} - \bar{X}_{i, a}| \leq \frac{2d}{m}
    \mid 
    (i, a) \in I
\right\}, \]
where $\op{rad} = \sqrt{\frac{\log(T)}{m}}$ and $d > 0$ is a real number that will be specified separately in each setting.
We may drop the subscript $d$ when it is clear from the context.
When $\C{E}$ happens, the average observed reward associated with each arm stays close its expectation, which is the value of the submodular function.
When $\C{E}'_d$ happens, the average observed reward for each arm remains close to the average total reward associated with playing that arm.
Using arguments similar to the ones used in~\cite{nie22_explor_then_commit_algor_for}, we prove that
\begin{theorem}\label{T:regret_bound_main}
  For all $d > 0$, we have
  \begin{align*}
    \B{E}(\C{R}) 
    &\leq 
    mnk + 2kT\op{rad} + \frac{4kTd}{m} \\
    &+ 2nkT\exp(-2m\op{rad}^2) + T(1 - \B{P}(\C{E}'_d)).
  \end{align*}
\end{theorem}
See Appendix~\ref{apx:base_lemmas} for a detailed proof.

To obtain the regret bounds for different settings, we only need to find lower bounds for $\B{P}(\C{E}'_d)$ and use Theorem~\ref{T:regret_bound_main}.



\begin{theorem}[Bounded Adversarial Delay]\label{T:regret_uniformly_bounded_delay}
  If the delay is uniformly bounded by $d$, then we have
  \[
    \B{E}(\C{R})
    = O(kn^{1/3} T^{2/3} (\log(T))^{1/2}) + O(kn^{2/3}T^{1/3} d).
  \]
\end{theorem}
\begin{proof}
  The detailed proof is provided in Appendix \ref{apdx_ubd}. Here, we describe the proof outline.
  In this setting, there is an integer $d \geq 0$ such that $\delta_t(\{x > d\}) = 0$, for all $t \geq 1$.
  Therefore, for any $m$ consecutive time-steps $t_{i, a} \leq t \leq t'_{i, a}$, the effect of delay may only be observed in the first $d$ and the last $d$ time-steps.
  It follows that 
  \[
    \left|
      \sum_{t=t_{i, a}}^{t'_{i, a}} X_t - \sum_{t=t_{i, a}}^{t'_{i, a}} F_t
    \right| \leq 2d,
  \]
  for all $(i, a) \in I$.
  Therefore, in this case, we have $\B{P}(\C{E}'_d) = 1$.
  Note that we are not making any assumptions about the delay distributions.
  Therefore, the delay may be chosen by an adversary with the full knowledge of the environment, the algorithm used by the agent and the history of actions and rewards.
  Plugging this in the bound provided by Theorem~\ref{T:regret_bound_main} completes the proof.
\end{proof}


\begin{theorem}[Stochastic Independent Delay]\label{T:regret_stochastic_independent}
  If the delay sequence is stochastic and independent and tight in expectation, then we have
  \[
    \B{E}(\C{R})
    = O(kn^{1/3}T^{2/3}\log(T))
      + O(kn^{2/3}T^{1/3}\B{E}(\tau)),
  \]
  where $\tau$ is an upper tail bound for $\{\B{E}_{\C{T}}(\Delta_t)\}_{t = 1}^{\infty}$.
\end{theorem}
\begin{proof}
  The detailed proof is provided in Appendix \ref{apdx_ubed}. Here, we describe the proof outline. 
  We start by defining the random variables
  \[
    C_{i, a} = \sum_{j = 1}^{t'_{i, a}} \Delta_j(\{x > t'_{i, a} - j\}),
  \]
  for all $(i, a) \in I$.
  This random variable measure the effect of actions taken up to $t'_{n, i}$ on the observed rewards after $t'_{n, i}$.
  In fact, we will see that $m|\bar{X}_{i, a} - \bar{F}_{i, a}|$ may be bounded by the sum of two terms.
  One $C_{i, a}$ which bounds the amount of reward that ``escapes" from the time interval $[t_{i, a}, t'_{i, a}]$.
  The second one $C_{i', a'}$, where $(i', a')$ corresponds to the action taken before $S^{i-1}\cup\{a\}$.
  This bound corresponds to the total of reward of the past actions that is observed during $[t_{i, a}, t'_{i, a}]$.
  Therefore, in order for the event $\C{E}'_d$ to happen, it is sufficient to have $C_{i, a} \leq d$, for all $(i, a) \in I$.
  Since $C_{i, a}$ is a sum of independent random variables, we may use Bernstein's inequality to see that
  \begin{align*}
    \B{P}(C_{i, a} > \B{E}(C_{i, a}) + \lambda)
    \leq \exp\left(-\frac{\lambda^2}{2(\B{E}(\tau) + \lambda/3)}\right).
  \end{align*}


  It follows from the definition that $\B{E}(C_{i, a}) \leq \B{E}(\tau)$.
  Therefore, by setting $d = \B{E}(\tau) + \lambda$, we get
  \begin{align*}
    \B{P}(C_{i, a} > d) 
    \leq \exp\left(-\frac{\lambda^2}{2(\B{E}(\tau) + \lambda/3)}\right).
  \end{align*}
   
  Therefore, we have
  \begin{align*}
    \B{P}(\C{E}'_d) 
    &\geq \B{P}\left( \bigcap_{i, a} \{ C_{i, a} \leq d \} \right) \\
    &= 1 - \B{P}\left( \bigcup_{i, a} \{ C_{i, a} > d \} \right) \\
    &\geq 1 - \sum_{i, a}\B{P}\left( \{ C_{i, a} > d \} \right) \\
    &\geq 1 - \sum_{i, a} \exp\left(-\frac{\lambda^2}{2(\B{E}(\tau) + \lambda/3)}\right) \\
    &\geq 1 - nk\exp\left(-\frac{\lambda^2}{2(\B{E}(\tau) + \lambda/3)}\right).
  \end{align*}
  Plugging this in Theorem~\ref{T:regret_bound_main} and choosing appropriate $\lambda$ gives us the desired result.
\end{proof}
 

\begin{theorem}[Stochastic Conditionally Independent Delay]\label{T:regret_stochastic_conditionally_independent}
  If the delay sequence is stochastic, conditionally independent and tight in expectation, then we have
  \begin{align*}
    \B{E}(\C{R})
    = O(k^2n^{4/3}T^{2/3}\log(T))
      + O(k^2n^{5/3}T^{1/3}\B{E}(\tau))
  \end{align*}
  where $\tau$ is an upper tail bound for $(\B{E}_{\C{T}}(\Delta_{t, S}))_{t \geq 1, S \in \C{S}}$.
\end{theorem}
\begin{proof}
  The detailed proof is provided in Appendix \ref{apdx_ubed} and is similar to the proof of Theorem~\ref{T:regret_stochastic_independent}.
  The main difference is that here we define 
  \[
    C'_{i, a} = \sum_{j = t_{i, a}}^{t'_{i, a}} \Delta_j(\{x > t'_{i, a} - j\}),
  \]
  instead of $C_{i, a}$. 
  Note that the sum here is only over the time-steps where the action $S^{i-1}\cup\{a\}$ is taken. 
  Therefore $C'_{i, a}$ is the sum of $m$ independent term.
  On the other hand, when we try to bound $m|\bar{X}_{i, a} - \bar{F}_{i, a}|$, we decompose it into the amount of total reward that ``escapes" from the time interval $[t_{i, a}, t'_{i, a}]$ and the contribution of all the time intervals of the form $[t_{i', a'}, t'_{i', a'}]$ in the past.
  Since the total number of such intervals is bounded by $nk$, here we find the probability that $C'_{i, a} \leq \frac{2d}{nk}$ instead of $C_{i, a} \leq d$ as we did in the proof of Theorem~\ref{T:regret_stochastic_independent}.
  This is the source of the multiplicative factor of $nk$ which appears behind the regret bound of this setting when compared to the stochastic independent delay setting.
\end{proof}


We note that  \citep{nie2023framework} provided a generalized framework for combinatorial bandits with full bandit feedback, where under a robustness guarantee, explore-then-commit (ETC) based algorithm have been used to get provable regret guarantees. More precisely, let $\C{A}$ be an algorithm for the combinatorial optimization problem of maximizing a function $f : \C{S} \to \B{R}$ over a finite domain $\C{S} \subseteq 2^\Omega$ with the knowledge that $f$ belongs to a known class of functions $\C{F}$.
for any function $\hat{f} : \C{S} \to \B{R}$, let $\C{S}_{\C{A}, \hat{f}}$ denote the output of $\C{A}$ when it is run with $\hat{f}$ as its value oracle.
The algorithm $\C{A}$ called $(\alpha, \delta)$-robust if for any $\epsilon > 0$ and any function $\hat{f}$ such that $|f(S) - \hat{f}(S)| < \epsilon$ for all $S \in \C{S}$, we have
\[
f(S_{\C{A}, \hat{f}}) \geq \alpha f(S^*) - \delta \epsilon.
\]

It is shown in \cite{nie2023framework} that if $\C{A}$ is  $(\alpha, \delta)$-robust, then the C-ETC algorithm achieves $\alpha$-regret bound of $O(N^{1/3} \delta^{2/3} T^{2/3} (\log(T))^{1/2})$, where $N$ is an upper-bound for the number of times $\C{A}$ queries the value oracle. 
In this work, we show that the result could be extended directly with delayed composite anonymous bandit feedback. 
The detailed results are given in Appendix \ref{apdx:general}. 
This shows that the proposed approach in this paper that deals with feedback could be applied on wide variety of problems. 
The problems that satisfy the robustness guarantee include submodular bandits with knapsack constraints, non-submodular bandits, and reserve pricing. 




\section{Experiments}

In our experiments, we consider two classes of submodular functions and and four types of delay.

\textbf{Submodular functions:}

\begin{enumerate}

\item[(F1)] Linear:

Here we assume that $f$ is a linear function of the individual arms.
In particular, for a function $g : \Omega \to [0, 1]$, we define
\[
f(S) := \frac{1}{k} \sum_{a \in S} g(a).
\]
More specifically, we let $n = 20$ and $k = 4$ and choose $g(a)$ uniformly from $[0.1, 0.9]$, for all $a \in \Omega$ and define $F(S) := \frac{1}{k} \sum_{a \in S} g(a) + N^c(0, 0.1)$ where $N^c(0, 0.1)$ is the truncated normal distribution with mean $0$ and standard deviation $0.1$, truncated to the interval $[-0.1, 1.0]$.

\item[(F2)] Weight Cover: 

Here we assume that $(C_j)_{j \in J}$ is a partition of $\Omega$ and there is a weight function $w_t : J \to [0, 1]$.
Then $f_t(S)$ is the sum of the weights of the the indexes $j$ where $C_j \cap S \neq \emptyset$, divided by $k$.
In other words, if $\op{1}$ is the indicator function, then
\[
f_t(S) := \frac{1}{k} \sum_{j \in J} w_t(j) \op{1}_{S \cap C_j \neq \emptyset}.
\]
More specifically, we let $n = 20$ and $k = 4$.
We divide $\Omega$ into 4 categories of sizes $6, 6, 6, 2$ and let $w_t(j) = U([0, j/5])$ be samples uniformly from $[0, j/5]$ for $j \in {1, 2, 3, 4}$.

Stochastic set cover may be viewed as a simple model for product recommendation.
Assume $n$ is the number of the products and each product belongs to exactly one of $c$ categories.
Then the reward will be equal to the sum of the weights of the categories that have been covered by the user divided by $k$.
\end{enumerate}


\textbf{Delay settings:}


\begin{enumerate}
\item[(D1)] No Delay

% StochasticDiscountedDelay
\item[(D2)] (Stochastic Independent Delay)
 For all $t \geq 1$ and $i \geq 0$, $\Delta_t(i) = (1 - X_t) X_t ^ i$, where $(X_t)_{t = 1}^{\infty}$ is an i.i.d sequence of random variables with the uniform distribution $U([0.5, 0.9])$.
The reward for time-step $t$ will be distributed over $[t, \infty)$ according to $\Delta_t$.
In this example $(\Delta_t)_{t = 1}^{\infty}$ is independent.

% StochasticIntervalDelay
\item[(D3)] (Stochastic Independent Delay)
For all $t \geq 0$, $\Delta_t$ is a distribution over $[10, 30]$ is sampled uniformly from the probability simplex using the flat Dirichlet distribution.
The reward for time-step $t$ will be distributed over $[t+10, t+30]$ according to $\Delta_t$.
In this example $(\Delta_t)_{t = 1}^{\infty}$ is independent.

% ConditionalDiscountedDelay
\item[(D4)] (Stochastic Conditionally Independent Delay)
For all $t \geq 1$ and $i \geq 0$, we have $\Delta_t(i) = (1 - Y_t) Y_t ^ i$, where $Y_t = 0.5 + f_t * 0.4 \in [0.5, 0.9]$.
The reward for time-step $t$ will be distributed over $[t, \infty)$ according to $\Delta_t$.
In this example $(\Delta_{t, S})_{t \geq 1, S \in \C{S}}$ is independent.


% AdvDiracDelay
\item[(D5)] (Stochastic Conditionally Independent Delay)
At each time-step $t$, a number $l_t$ is chosen from $[10, 30]$ according to the following formula.
\[
l_t = \lfloor 20 f_t \rfloor + 10
\]
The reward for time-step $t$ will be observed at $t+l_t$.
In other words, the higher the reward, the more it will be delayed.
In this example $(\Delta_{t, S})_{t \geq 1, S \in \C{S}}$ is independent.

\item[(D6)] (Adversarial Delay)
Let $l_1 = 15$ and for all $t > 1$, define $l_t$ according to the following formula
\[
l_t = \lfloor 20 x_{t-1} \rfloor + 10
\]
In other words, the higher the previous observation, the more the current reward will be delayed.
\end{enumerate}

\input{figfile}

\textbf{Baselines:}

We use three algorithms designed for CMAB with full-bandit feedback without delay and and algorithm designed for MAB with composite anonymous feedback as the baseline.
\begin{itemize}
\item \textbf{CMAB-SM}
\cite{agarwal2022stochastic}
This algorithm assumes the expected reward functions are Lipschitz continuous of individual base arm rewards.
CMAB-SM has a theoretical $1$-regret guarantee of $\tilde{O}(T^{2/3})$ with the assumption that if arm $a$ is better than arm $b$, then replacing $b$ by $a$ in any set not including $a$ will give better reward function. 

\item \textbf{DART}
\cite{agarwal2021dart}
This algorithm assumes the expected reward functions are Lipschitz continuous of individual base arm rewards and the reward functions have an additional property related to the marginal gains of the base arms. 
DART has a theoretical $1$-regret guarantee of $\tilde{O}(T^{1/2})$ with the assumption that if arm $a$ is better than arm $b$, then replacing $b$ by $a$ in any set not including $a$ will give better reward function. 

\item \textbf{OG$^o$}
\cite{streeter2010online}
This algorithm is designed for oblivious adversarial setting with submodular rewards.
Therefore the sequence of monotone and submodular functions is fixed in advance.
It has an $(1-1/e)$-regret guarantee of $\tilde{O}(T^{2/3})$.

\item \textbf{ARS-UCB}
\cite{Wang_Wang_Huang_2021}
This algorithm is designed for MAB with composite anonymous delayed feedback.
The delay model is a special case of \textit{unbounded stochastic conditionally independent composite anonymous feedback delay} that we described.
However, they assume that $\Delta_{t, S}$ does not depend on time.
For our experiments, we use all subsets of $\Omega$ of size $k$ as the set of arms.
ARS-UCB has a 1-regret guarantee of $\tilde{O}( \binom{n}{k}^{1/2}T^{1/2})$ plus a constant term that depends on delay and the number of its arms.
\end{itemize}

\textbf{Experiment details and results:}

For both setups, we use $n = 20$ base arms and cardinality constraint $k = 4$.
The details of the choice of the submodular functions and delay settings are explained above.
We run each experiment for different time horizons $T = \{10^2, 10^3, 10^4, 10^5\}$.
For each horizon, we run the experiment 10 times.
As we see, ETCG outperforms almost all other baselines.
The linear submodular function satisfies the conditions under which DART and CMAB-SM were designed.
However, the weighed cover function does not satisfy such conditions and therefore more difficult for those algorithms to run.
In both cases, we see that any kind of delay worsens the performance of DART and CMAB-SM compared to ETCG.
OG$^o$ explores actions (including those with cardinality smaller then $k$) with a constant probability, which could account for its lower performance compared to ETCG, DART, and CMAB-SM.


While ARS-UCB does not perform well in these experiments, it should be noted that, given enough time, it should outperform ETCG.
Also note that ARS-UCB has a linear storage complexity with respect to its number of arms.
This translates to an $O(\binom{n}{k})$ storage complexity in the combinatorial setting.
Therefore, even for $n = 50$ and $k = 25$, it would require hundreds of terabytes of storage to run.
In these experiments, we have $n=20$ and $k=4$, so it has only $\binom{20}{4} = 4845$ arms.



\section{Conclusion}


This paper considered the problem of combinatorial multiarmed bandits with stochastic submodular (in
expectation) rewards and delayed composite anonymous bandit feedback. Three models of delayed feedback: bounded adversarial, stochastic independent, and stochastic conditionally independent are studied, and regret bounds are derived for each of the delay models. The regret bounds demonstrate an additive impact of delay in the regret term.

This work provides the first regret bound results for CMAB with monotone and submodular rewards and delayed feedback. We note that the proof techniques and feedback models can be applied in other setups in CMAB, and exploring the generality of the proof techniques to other CMAB setups (e.g., continuous DR-submodular maximization) is an important direction. 




\nocite{Streeter2008AnOA}
\bibliography{references}
\bibliographystyle{icml2023}


\newpage
\appendix
\onecolumn



\section{Proof of Lemma~\ref{L:tightness_equiv_upper_bound}}\label{proof_lem_tightness_equiv_upper_bound}

\begin{proof}
If an upper tail bound $\delta$ exists, then we may simply define 
\[
j_{\epsilon} := \min\{j \mid \delta( \{ x \geq j \} ) \leq \epsilon \},
\]
to see that the family is tight.
Next we assume that the family is tight and prove the existence of an upper tail bound.

Let $\delta$ be the measure defined by
\[
\forall j \geq 0
,\quad
\delta(j) := \sup_{i \in I} \delta_i(\{x \geq j\}) - \sup_{i \in I} \delta_i(\{x \geq j+1\}).
\]
Clearly we have $\delta(j) \geq 0$, for all $j \geq 0$.
To show that $\delta$ is a probability distribution, we sum the terms and see that
\begin{align*}
\delta(\{t \mid a \leq t \leq b\}) 
= \sum_{t=a}^{b} \delta(t) 
&= \sum_{t=a}^{b} \left(
\sup_{i \in I} \delta_i(\{x \geq t\}) - \sup_{i \in I} \delta_i(\{x \geq t+1\})
\right) \\
&= \sup_{i \in I} \delta_i(\{x \geq a\}) - \sup_{i \in I} \delta_i(\{x \geq b+1\})
\end{align*}
According to the definition of tightness, for all $\epsilon > 0$ and $b \geq j_{\epsilon}$, we have
\[
\delta(\{t \mid a \leq t \leq b\}) 
= \sup_{i \in I} \delta_i(\{x \geq a\}) - \sup_{i \in I} \delta_i(\{x \geq b+1\})
\geq \sup_{i \in I} \delta_i(\{x \geq a\}) - \epsilon.
\]
Hence we have
\[
\delta(\{t \geq 0\}) 
= \lim_{j \to \infty} \delta(\{t \mid 0 \leq t \leq j\}) 
= 1 - \lim_{j \to \infty} \sup_{i \in I} \delta_i(\{x \geq j+1\})
= 1.
\]
Finally, to see that $\delta$ is indeed an upper tail bound, we note that
\[
\delta(\{t \mid a \leq t \leq b\}) 
= \sup_{i \in I} \delta_i(\{x \geq a\}) - \sup_{i \in I} \delta_i(\{x \geq b+1\})
\leq \sup_{i \in I} \delta_i(\{x \geq a\}).
\]
Therefore
\[
\delta(\{t \geq a\}) 
= \lim_{b \to \infty} \delta(\{t \mid a \leq t \leq b\}) 
\leq \sup_{i \in I} \delta_i(\{x \geq a\}).
\qedhere
\]
\end{proof}


\section{Lemmas used in the proofs}\label{apx:base_lemmas}

In this section, we will provide the Lemmas that will be used in the proof of the main results. Let $t_{i, a}$ denote the first time-step where the action $S^{(i-1)}\cup\{a\}$ is played in the exploration phase and let $t'_{i, a} := t_{i, a} + m - 1$ be the last such time-step.
Therefore, we have
\[
  \bar{F}_{i, a} = \frac{1}{m}\sum_{t = t_{i, a}}^{t'_{i, a}} F_t
  ,\quad
  \bar{X}_{i, a} = \frac{1}{m}\sum_{t = t_{i, a}}^{t'_{i, a}} X_t.
\]
Similarly, the realized value of these random variables are
\[
  \bar{f}_{i, a} = \frac{1}{m}\sum_{t = t_{i, a}}^{t'_{i, a}} f_t
  ,\quad
  \bar{x}_{i, a} = \frac{1}{m}\sum_{t = t_{i, a}}^{t'_{i, a}} x_t.
\]

For any phase $i$ and arm $a \in \Omega \setminus S^{i-1}$, define the event
\[ \C{E}_{i, a} := \left\{
    |\bar{F}_{i, a} - f(S^{i-1}\cup\{a\})| \leq \op{rad}
  \right\}, \]
where $\op{rad}$ is a non-negative real number to be specified later.
Using these events, we define
\[
  \C{E}_{i} := \bigcap_{a \in \Omega \setminus S^{(i-1)}} \C{E}_{i, a}
  ,\quad
  \C{E} := \bigcap_{i = 1}^k \C{E}_i.
\]


\begin{lemma}\label{L:bound_P_E}
  We have
  \[ \B{P}(\C{E}) \geq 1 - 2nk\exp(-2m\op{rad}^2). \]
\end{lemma}
\begin{proof}
  We have $F_t \in [0, 1]$.
  Therefore, using Hoeffding's inequality, we have
  \begin{align*}
    \B{P}(|\bar{F}_{i, a} - f(S^{i-1}\cup\{a\})| > \op{rad}) 
    &= \B{P}\left(
      \left| 
        \sum_{t_{i, a}}^{t'_{i, a}} F_{t} - mf(S^{i-1}\cup\{a\}) 
      \right| > m\op{rad} \right) \\
    &\leq 2\exp\left( -\frac{2 (m\op{rad})^2}{m} \right)
    = 2\exp(-2m\op{rad}^2).
  \end{align*}
  Hence
  \begin{align*}
    \B{P}(\C{E}) 
    &= \B{P}\left( \bigcap_{i, a}^k \C{E}_{i, a} \right) \\
    &= 1 - \B{P}\left( \bigcup_{i, a}^k (\C{E}_{i, a})^c \right) \\
    &\geq 1 - \sum_{i, a} \B{P}((\C{E}_{i, a})^c) \\
    &= 1 - \sum_{i, a} \B{P}(|\bar{F}_{i, a} - f(S^{i-1}\cup\{a\})| > \op{rad}) \\
    &\geq 1 - \sum_{i, a} 2\exp(-2m\op{rad}^2) \\
    &\geq 1 - 2nk \exp(-2m\op{rad}^2).
    \qedhere
  \end{align*}
\end{proof}



Next we define another set of events where the delay is controlled.
Let
\[ \C{E}'_{d, i, a} := \left\{
    |\bar{X}_{i, a} - \bar{F}_{i, a}| \leq \frac{2d}{m}
  \right\}, \]
for some $d > 0$ which will be specified later.
Similar to above, we use these events to define
\[
  \C{E}'_{d, i} := \bigcap_{a \in \Omega \setminus S^{(i-1)}} \C{E}_{d, i, a}
  ,\quad
  \C{E}'_d := \bigcap_{i = 1}^k \C{E}'_{d, i}.
\]
Note that $\C{E}'_d$ can happen even if the delay is not bounded.
Later in Lemmas~\ref{L:bound_P_E_prime_uniformly_bounded_delay} and~\ref{L:bound_P_E_prime_uniformly_bounded_tail}, we will find lower bounds on the probability of $\C{E}'_d$ in both the adversarial and the stochastic setting.

\begin{lemma}\label{L:f_S_i_minus_f_S_i_minus_one}
  Under the event $\C{E} \cap \C{E}'_d$, for all $1 \leq i \leq k$ and $d > 0$, we have
  \[
    f(S^{(i)}) - f(S^{(i-1)})
    \geq
    \frac{1}{k} \left[
      f(S^*) - f(S^{(i-1)})
    \right]
    - 2 \op{rad} - \frac{4d}{m}.
  \]
\end{lemma}
\begin{proof}
Recall that $a_i$ is the sole element in $S^i \setminus S^{i-1}$.
That is,
\[
a_i = \op{argmax}_{a \in \Omega \setminus S^{(i-1)}} \bar{x}_{i, a}.
\]
Define
\[
a_i^* := \op{argmax}_{a \in \Omega \setminus S^{(i-1)}} f(S^{i-1} \cup \{a\}).
\]
Then we have
\begin{align*}
  f(S^i)
  &= f(S^{i-1} \cup \{a_i\}) \\
  &\geq \bar{f}_{i, a_i} - \op{rad} 
    &&\t{(definition of } \C{E} \t{)} \\
  &\geq \bar{x}_{i, a_i} - \frac{2d}{m} - \op{rad}
    &&\t{(definition of } \C{E}' \t{)} \\
  &\geq \bar{x}_{i, a_i^*} - \frac{2d}{m} - \op{rad}
    &&\t{(definition of } a_i^* \t{)} \\
  &\geq \bar{f}_{i, a_i^*} - \frac{4d}{m} - \op{rad}
    &&\t{(definition of } \C{E}' \t{)} \\
  &\geq f(S^{i-1} \cup \{a_i^*\}) - \frac{4d}{m} - 2\op{rad}.
    &&\t{(definition of } \C{E} \t{)}
\end{align*}
Hence we have
\[
f(S^i) - f(S^{i-1})
\geq f(S^{i-1} \cup \{a_i^*\}) - f(S^{i-1}) - \frac{4d}{m} - 2\op{rad}.
\]
Therefore
\begin{align*}
  f(S^i) - f(S^{i-1})
  &\geq f(S^{i-1} \cup \{a_i^*\}) - f(S^{i-1}) - \frac{4d}{m} - 2\op{rad} \\
  &= \op{max}_{a \in \Omega \setminus S^{(i-1)}} f(S^{i-1} \cup \{a\})  - f(S^{i-1}) - \frac{4d}{m} - 2\op{rad}
    &&\t{(definition of } a_i^* \t{)} \\
  &\geq \op{max}_{a \in S^* \setminus S^{(i-1)}} f(S^{i-1} \cup \{a\})  - f(S^{i-1}) - \frac{4d}{m} - 2\op{rad}
    && (S^* \subseteq \Omega) \\
  &\geq \frac{1}{|S^* \setminus S^{i-1}|} \sum_{a \in S^* \setminus S^{(i-1)}} f(S^{i-1} \cup \{a\})  - f(S^{i-1}) - \frac{4d}{m} - 2\op{rad}
    && \t{(maximum} \geq \t{mean)} \\
  &= \frac{1}{|S^* \setminus S^{i-1}|} \sum_{a \in S^* \setminus S^{(i-1)}} \left[ 
    f(S^{i-1} \cup \{a\})  - f(S^{i-1})
    \right]  - \frac{4d}{m} - 2\op{rad}  \\
  &\geq \frac{1}{k} \sum_{a \in S^* \setminus S^{(i-1)}} \left[ 
    f(S^{i-1} \cup \{a\})  - f(S^{i-1})
    \right]  - \frac{4d}{m} - 2\op{rad}
    && (|S^* \setminus S^{i-1}| \leq |S^*| = k) \\
  &\geq \frac{1}{k} \left[ 
    f(S^*)  - f(S^{i-1})
    \right]  - \frac{4d}{m} - 2\op{rad},
\end{align*}
where the last line follows from a well-known inequality for submodular functions.
\end{proof}

\begin{corollary}\label{C:explotation_regret_bound_per_timestep}
  Under the event $\C{E} \cap \C{E}'_d$, for all $d > 0$, we have
  \[
    f(S^{(k)}) \geq (1 - \frac{1}{e})f(S^*) - 2k \op{rad} - \frac{4kd}{m}.
  \]
\end{corollary}
\begin{proof}
Using Lemma~\ref{L:f_S_i_minus_f_S_i_minus_one}, we have
\[
  f(S^{i}) 
  \geq f(S^{i-1}) + \frac{1}{k}(f(S^*) - f(S^{i-1})) - 2\op{rad} - \frac{4d}{m}
  = \left[  \frac{1}{k} f(S^*) - 2\op{rad} - \frac{4d}{m} \right] + (1 - \frac{1}{k})f(S^{i-1}).
\]
Applying this inequality recursively, we get
\begin{align*}
  f(S^k) 
  &\geq \left[ \frac{1}{k} f(S^*) - 2\op{rad} - \frac{4d}{m} \right] + (1 - \frac{1}{k})f(S^{k-1}) \\
  &\geq \left[ \frac{1}{k} f(S^*) - 2\op{rad} - \frac{4d}{m} \right] + (1 - \frac{1}{k})
    \left(
      \left[ \frac{1}{k} f(S^*) - 2\op{rad} - \frac{4d}{m} \right] + (1 - \frac{1}{k})f(S^{k-2})
    \right) \\
  &= \left[ \frac{1}{k} f(S^*) - 2\op{rad} - \frac{4d}{m} \right] \sum_{l=0}^1 (1 - \frac{1}{k})^l + (1 - \frac{1}{k})^2 f(S^{k-2}) \\
  &\vdots \\
  &\geq \left[ \frac{1}{k} f(S^*) - 2\op{rad} - \frac{4d}{m} \right] \sum_{l=0}^{k-1} (1 - \frac{1}{k})^l + (1 - \frac{1}{k})^k f(S^{0}) \\
  &= \left[ \frac{1}{k} f(S^*) - 2\op{rad} - \frac{4d}{m} \right] \sum_{l=0}^{k-1} (1 - \frac{1}{k})^l
\end{align*}
Note that we have
\[
\sum_{l=0}^{k-1} (1 - \frac{1}{k})^l
= \frac{1 - (1 - \frac{1}{k})^k}{1 - (1 - \frac{1}{k})}
= k \left( 1 - (1 - \frac{1}{k})^k \right).
\]
Hence
\begin{align*}
  f(S^k) 
  &\geq \left[ \frac{1}{k} f(S^*) - 2\op{rad} - \frac{4d}{m} \right] k \left( 1 - (1 - \frac{1}{k})^k \right) \\
  &= \left( 1 - (1 - \frac{1}{k})^k \right) f(S^*) - 
    \left( 2k\op{rad} - \frac{4kd}{m} \right)\left( 1 - (1 - \frac{1}{k})^k \right) \\
  &\geq \left( 1 - (1 - \frac{1}{k})^k \right) f(S^*) - 2k\op{rad} - \frac{4kd}{m}.
\end{align*}
Using the well known inequality $(1 - \frac{1}{k})^k \leq \frac{1}{e}$, we get
\[
  f(S^k) 
  \geq \left( 1 - \frac{1}{e} \right) f(S^*) - 2k\op{rad} - \frac{4kd}{m}.
  \qedhere
\]
\end{proof}




\begin{lemma}\label{L:regret_conditioned_on_both}
  For all $d > 0$, we have
  \[
    \B{E}(\C{R} | \C{E} \cap \C{E}'_d) \leq mnk + 2kT\op{rad} + \frac{4kTd}{m}.
  \]
\end{lemma}
\begin{proof}
Let $\C{R} = \C{R}_{\t{exploration}} + \C{R}_{\t{exploitation}}$.
The exploration phase is at most $mnk$ steps, therefore we always have 
\[ \C{R}_{\t{exploration}} \leq mnk. \]
At each time-step in the exploitation phase, $(1 - \frac{1}{e})f(S^*) - f(S^k)$ to is added to the expected regret.
Hence we have
\begin{align*}
  \B{E}(\C{R} | \C{E} \cap \C{E}_d') 
  &= \B{E}(\C{R}_{\t{exploration}} | \C{E} \cap \C{E}'_d) + \B{E}(\C{R}_{\t{exploitation}} | \C{E} \cap \C{E}'_d) \\
  &\leq mnk + T \left[ (1 - \frac{1}{e})f(S^*) - f(S^k) \right] \\
  &\leq mnk + 2kT\op{rad} + \frac{4kTd}{m},
\end{align*}
where we used Corollary~\ref{C:explotation_regret_bound_per_timestep} in the last inequality.
\end{proof}


\begin{theorem}[Theorem~\ref{T:regret_bound_main} in the main text]
  For all $d > 0$, we have
  \[
    \B{E}(\C{R}) 
    \leq 
    mnk + 2kT\op{rad} + \frac{4kTd}{m} + 2nkT\exp(-2m\op{rad}^2) + T(1 - \B{P}(\C{E}'_d)).
  \]
\end{theorem}

\begin{proof}
  Using Lemmas~\ref{L:regret_conditioned_on_both} and~\ref{L:bound_P_E}, we have
  \begin{align*}
    \B{E}(\C{R})
    &= \B{E}(\C{R} | \C{E} \cap \C{E}'_d) \B{P}(\C{E} \cap \C{E}'_d)
    + \B{E}(\C{R} | (\C{E} \cap \C{E}'_d)^c ) \B{P}((\C{E} \cap \C{E}'_d)^c) \\
    &\leq \B{E}(\C{R} | \C{E} \cap \C{E}'_d) + T \B{P}((\C{E} \cap \C{E}'_d)^c) \\
    &= \B{E}(\C{R} | \C{E} \cap \C{E}'_d) + T \B{P}(\C{E}^c \cup (\C{E}'_d)^c) \\
    &\leq \B{E}(\C{R} | \C{E} \cap \C{E}'_d) + T \B{P}(\C{E}^c) + T \B{P}((\C{E}'_d)^c) \\
    &\leq (mnk + 2kT\op{rad} + \frac{4kTd}{m}) + 2nkT\exp(-2m\op{rad}^2) + T(1 - \B{P}(\C{E}'_d)).  \qedhere
  \end{align*}
\end{proof}



\section{Uniformly Bounded Delay}\label{apdx_ubd}

\begin{lemma}\label{L:bound_P_E_prime_uniformly_bounded_delay}
  If delay is uniformly bounded by $d$, then $\B{P}(\C{E}'_d) = 1$.
\end{lemma}

\begin{proof}
  For all $t \leq 0$, let $F_t = 0$ and let $\delta_t$ be any distribution over non-negative integers.
  We have
  \begin{align*}
    \left|
      \sum_{t=t_{i, a}}^{t'_{i, a}} X_t - \sum_{t=t_{i, a}}^{t'_{i, a}} F_t
      \right|
    &= \left|
      \sum_{j = t_{i, a} - d}^{t'_{i, a}} F_j \delta_j({\{t_{i, a} -j \leq x \leq t'_{i, a}-j\}})
      - \sum_{t=t_{i, a}}^{t'_{i, a}} F_t
      \right| \\
    &= \left|
      \sum_{j = t_{i, a} - d}^{t_{i, a}-1} F_j \delta_j({\{t_{i, a} -j \leq x \leq t'_{i, a}-j\}})
      + \sum_{j = t_{i, a}}^{t'_{i, a}} F_j \delta_j({\{x \leq t'_{i, a}-j\}})
      - \sum_{t=t_{i, a}}^{t'_{i, a}} F_t
      \right| \\
    &= \left|
      \sum_{j = t_{i, a} - d}^{t_{i, a}-1} F_j \delta_j({\{t_{i, a} -j \leq x \leq t'_{i, a}-j\}})
      - \sum_{j = t_{i, a}}^{t'_{i, a}} F_j \delta_j({\{x > t'_{i, a}-j\}})
      \right| \\
    &\leq 
      \sum_{j = t_{i, a} - d}^{t_{i, a}-1} \delta_j({\{t_{i, a} -j \leq x \leq t'_{i, a}-j\}})
      + \sum_{j = t_{i, a}}^{t'_{i, a}} \delta_j({\{x > t'_{i, a}-j\}}) \\
    &\leq
      d + \sum_{j = t_{i, a}}^{t'_{i, a}} \delta_j({\{x > t'_{i, a}-j\}}).
  \end{align*}
  Note that for $j \leq t_{i, a} + m - d - 1$, we have
  \[
    \delta_j({\{x > t'_{i, a}-j\}})
    = \delta_j({\{x > t_{i, a}+m-1-j\}})
    \leq \delta_j({\{x > d\}})
    = 0.
  \]
  Therefore we have
  \begin{align*}
    \sum_{j = t_{i, a}}^{t'_{i, a}} \delta_j({\{x > t'_{i, a}-j\}}) 
    &= \sum_{j = \max\{t_{i, a}, t_{i, a} + m-d\}}^{t_{i, a} + m-1} \delta_j({\{x > t'_{i, a}-j\}}) \\
    &\leq (t_{i, a} + m-1) - \max\{t_{i, a}, t_{i, a} + m-d\} + 1 \\
    &= \min\{m, d\} \leq d.
  \end{align*}
  Hence 
  \[
    |\bar{X}_{i, a} - \bar{F}_{i, a}|
    =\frac{1}{m} \left|
      \sum_{t=t_{i, a}}^{t'_{i, a}} X_t - \sum_{t=t_{i, a}}^{t'_{i, a}} F_t
      \right|
    \leq \frac{2d}{m}.
    \qedhere
  \]
\end{proof}


\begin{theorem}[Theorem~\ref{T:regret_uniformly_bounded_delay} in the main text]
  If the delay is uniformly bounded by $d$, then we have
  \[
    \B{E}(\C{R})
    = O(kn^{1/3} T^{2/3} (\log(T))^{1/2}) + O(kn^{2/3}T^{1/3} d).
  \]
\end{theorem}
\begin{proof}
  Using Theorem~\ref{T:regret_bound_main} and Lemma~\ref{L:bound_P_E_prime_uniformly_bounded_delay}, we see that
  \[
    \B{E}(\C{R})
    \leq
    mnk + 2kT\op{rad} + \frac{4kTd}{m} + 2nkT\exp(-2m\op{rad}^2).
  \]
  Let \(\op{rad} := \sqrt{\frac{\log(T)}{m}}\).
  Then
  \[
    \exp(-2m \op{rad}^2) = T^{-2},
  \]
  and
  \begin{align*}
    \B{E}(\C{R})
    &\leq mnk + 2kT\op{rad} + \frac{4kTd}{m} + 2nkT \exp(-2m \op{rad}^2) \\
    &= mnk + 2kT\sqrt{\frac{\log(T)}{m}} + \frac{4kTd}{m} + 2nk/T \\
    &\leq mnk + 2kT\sqrt{\frac{\log(T)}{m}} + \frac{4kTd}{m} + 2k
  \end{align*}
  where we used \(T \geq n\) in the last inequality.
  Since $m = \lceil (T/n)^{2/3} \rceil$, we have $(T/n)^{2/3} \leq m \leq (T/n)^{2/3} + 1$.
  Therefore
  \begin{align*}
    \B{E}(\C{R})
    &\leq mnk + 2kT\sqrt{\frac{\log(T)}{m}} + \frac{4kTd}{m} + 2k \\
    &\leq ((T/n)^{2/3} + 1)nk + 2kT\sqrt{\log(T)/(T/n)^{2/3}} + \frac{4kTd}{(T/n)^{2/3}} + 2k \\
    &= kn^{1/3} T^{2/3} + nk + 2kn^{1/3} T^{2/3} (\log(T))^{1/2}) + 4 kn^{2/3}T^{1/3} d +2k \\
    &\leq 4 kn^{1/3} T^{2/3} (\log(T))^{1/2}) + 4 kn^{2/3}T^{1/3} d + 2k \\
    &= O(kn^{1/3} T^{2/3} (\log(T))^{1/2}) + O(kn^{2/3}T^{1/3} d).
    \qedhere
  \end{align*}
\end{proof}


\section{Unbounded Stochastic Independent Delay}\label{apdx_ubed}

\begin{lemma}\label{L:bound_P_E_prime_uniformly_bounded_tail}
  If $(\Delta_j)_{j = 1}^{\infty}$ is independent and $(\B{E}_{\C{T}}(\Delta_j))_{j = 1}^{\infty}$ is tight, then we have
  \[
    \B{P}(\C{E}'_d) \geq 1 - nk \exp\left(-\frac{\lambda^2}{2(\B{E}(\tau) + \lambda/3)}\right),
  \]
  where $d > 0$ is a real number, $\tau$ is a tail upper bound for the family $(\B{E}_{\C{T}}(\Delta_j))_{j = 1}^{\infty}$ 
  and $\lambda = \max\{0, d - \B{E}(\tau)\}$.
\end{lemma}

\begin{proof}
  If $\lambda = 0$, then the statement is trivially true.
  So we will assume that $\lambda > 0$ and $d = \B{E}(\tau) + \lambda$.
  Define 
  \[
    C_{i, a} = \sum_{j = 1}^{t'_{i, a}} \Delta_j(\{x > t'_{i, a} - j\}).
  \]
  Using the fact that $\tau$ is an upper tail bound for $(\B{E}_{\C{T}}(\Delta_j))_{j = 1}^{\infty}$, 
  we can see that
  \begin{align*}
    \B{E}(C_{i, a})
    &= \sum_{j = 1}^{t'_{i, a}} \B{E}(\Delta_j(\{ x > t'_{i, a} - j \}))
    \leq \sum_{j = 1}^{t'_{i, a}} \tau(\{ x > t'_{i, a} - j \}) \\
    &= \sum_{j = 1}^{t'_{i, a}} \tau(\{ x \geq j \})
    \leq \sum_{j = 0}^{\infty} \tau(\{ x \geq j \})
    = \B{E}(\tau).
  \end{align*}
  Using Bernstein's inequality, we have
  \begin{align*}
    \B{P}(C_{i, a} > d) 
    &= \B{P}(C_{i, a} > \B{E}(\tau) + \lambda) \\
    &\leq \B{P}(C_{i, a} > \B{E}(C_{i, a})+ \lambda) \\
    &\leq \exp\left(-\frac{\lambda^2}{2(\sum_{j = 1}^{t'_{i, a}}\B{E}(\Delta_j(\{ x > t'_{i, a}-j \})^2) + \lambda/3)}\right) \\
    &\leq \exp\left(-\frac{\lambda^2}{2(\sum_{j = 1}^{t'_{i, a}}\B{E}(\Delta_j(\{ x > t'_{i, a} - j \})) + \lambda/3)}\right) \\
    &= \exp\left(-\frac{\lambda^2}{2(\B{E}(C_{i, a}) + \lambda/3)}\right) \\
    &\leq \exp\left(-\frac{\lambda^2}{2(\B{E}(\tau) + \lambda/3)}\right).
  \end{align*}


  We have
  $ X_t = \sum_{j = 1}^t F_j(S_j) \Delta_j(t-j) $.
  Therefore
  \begin{align*}
    m|\bar{X}_{i, a} - \bar{F}_{i, a}|
    &=\left|
      \sum_{t=t_{i, a}}^{t'_{i, a}} X_t - \sum_{t=t_{i, a}}^{t'_{i, a}} F_t
      \right| \\
    &= \left|
      \sum_{j = 1}^{t'_{i, a}} F_j \Delta_j({\{t_{i, a} -j \leq x \leq t'_{i, a}-j\}})
      - \sum_{t=t_{i, a}}^{t'_{i, a}} F_t
      \right| \\
    &= \left|
      \sum_{j = 1}^{t_{i, a}-1} F_j \Delta_j({\{t_{i, a} -j \leq x \leq t'_{i, a}-j\}})
      + \sum_{j = t_{i, a}}^{t'_{i, a}} F_j \Delta_j({\{x \leq t'_{i, a}-j\}})
      - \sum_{t=t_{i, a}}^{t'_{i, a}} F_t
      \right| \\
    &= \left|
      \sum_{j = 1}^{t_{i, a}-1} F_j \Delta_j({\{t_{i, a} -j \leq x \leq t'_{i, a}-j\}})
      - \sum_{j = t_{i, a}}^{t'_{i, a}} F_j \Delta_j({\{x > t'_{i, a}-j\}})
      \right| \\
    &\leq 
      \sum_{j = 1}^{t_{i, a}-1} \Delta_j({\{t_{i, a} -j \leq x \leq t'_{i, a}-j\}})
      + \sum_{j = t_{i, a}}^{t'_{i, a}} \Delta_j({\{x > t'_{i, a}-j\}}) \\
    &\leq 
      \sum_{j = 1}^{t_{i, a}-1} \Delta_j({\{x \geq t_{i, a}-j\}})
      + \sum_{j = 1}^{t'_{i, a}} \Delta_j({\{x > t'_{i, a}-j\}}) \\
    &= \sum_{j = 1}^{t_{i, a}-1} \Delta_j({\{x > t_{i, a}-1-j\}}) + C_{i, a}.
  \end{align*}
  If $t_{i, a} = 1$, then the first sum will be zero and we have
  \[
    m|\bar{X}_{i, a} - \bar{F}_{i, a}| \leq C_{i, a}.
  \]
  Otherwise, there exists $(i', a')$ such that $t'_{i', a'} = t_{i, a} - 1$ and
  \[
    m|\bar{X}_{i, a} - \bar{F}_{i, a}| \leq C_{i', a'} + C_{i, a}.
  \]
  Let $\C{E}^*_{i, a}$ be the event that $C_{i, a} \leq d$ and define
  \[
  \C{E}^* := \bigcap_{i, a} \C{E}^*_{i, a}.
  \]
  Our discussion above shows that we have
  \[
    \B{P}(\C{E}'_d) \geq \B{P}(\C{E}^*).
  \]
  On the other hand, we have
  \begin{align*}
    \B{P}(\C{E}^*) 
    &= \B{P}\left( \bigcap_{i, a} \C{E}^*_{i, a} \right) \\
    &= 1 - \B{P}\left( \bigcup_{i, a} (\C{E}^*_{i, a})^c \right) \\
    &= 1 - \B{P}\left( \bigcup_{i, a} \{ C_{i, a} > d \} \right) \\
    &\geq 1 - \sum_{i, a}\B{P}\left( \{ C_{i, a} > d \} \right) \\
    &\geq 1 - \sum_{i, a} \exp\left(-\frac{\lambda^2}{2(\B{E}(\tau) + \lambda/3)}\right) \\
    &\geq 1 - nk\exp\left(-\frac{\lambda^2}{2(\B{E}(\tau) + \lambda/3)}\right),
  \end{align*}
  which completes the proof.
\end{proof}

\begin{theorem}[Theorem~\ref{T:regret_stochastic_independent} in the main text]
  If the delay sequence is stochastic, then we have
  \[
    \B{E}(\C{R})
    = O(kn^{1/3}T^{2/3}\log(T))
      + O(kn^{2/3}T^{1/3}\B{E}(\tau)),
  \]
  where $\tau$ is an upper tail bound for $(\B{E}_{\C{T}}(\Delta_t))_{t = 1}^{\infty}$.
\end{theorem}

\begin{proof}
  Let $\op{rad} := \sqrt{\frac{\log(T)}{m}}$. Then, using $T \geq n$, we have
  \[
    2nkT\exp(-2m\op{rad}^2)
    = 2nkT\exp(-2\log(T))
    = 2nkT^{-1}
    \leq 2k.
  \]
  We choose $d := \B{E}(\tau) + \max\{6\B{E}(\tau), 2\log(T)\}$
  and 
  $\lambda = d - \B{E}(\tau) = \max\{6\B{E}(\tau), 2\log(T)\}$.
  Then we have
  \begin{align*}
    \exp\left(-\frac{\lambda^2}{2(\B{E}(\tau) + \lambda/3)}\right)
    \leq \exp\left(-\frac{\lambda^2}{2(\lambda/6 + \lambda/3)}\right)
    = \exp(-\lambda)
    \leq \exp(-2\log(T))
    = T^{-2}.
  \end{align*}
  Therefore
  \[
    nkT\exp\left(-\frac{\lambda^2}{2(\B{E}(\tau) + \lambda/3)}\right)
    \leq nkT^{-1} \leq k.
  \]
  So, using Theorem~\ref{T:regret_bound_main} and Lemma~\ref{L:bound_P_E_prime_uniformly_bounded_tail}, we have
  \begin{align*}
    \B{E}(\C{R})
    & \leq 
    mnk + 2kT\op{rad} + \frac{4kTd}{m} + 2nkT\exp(-2m\op{rad}^2) + T(1 - \B{P}(\C{E}'_d)) \\
    & \leq 
    mnk + 2kT\op{rad} + \frac{4kTd}{m} + 2nkT\exp(-2m\op{rad}^2) + nkT\exp\left(-\frac{\lambda^2}{2(\B{E}(\tau) + \lambda/3)}\right) \\
    & \leq
    mnk + 2kT\op{rad} + \frac{4kTd}{m} + 3k \\
    & =
      mnk + 2kT\sqrt{\frac{\log(T)}{m}}
      + 4k\frac{T}{m} \left( \B{E}(\tau) + \max\{6\B{E}(\tau), 2\log(T)\} \right)
      + 3k \\
    & \leq
      mnk + 2kT\sqrt{\frac{\log(T)}{m}}
      + 4k\frac{T}{m} \left( 7\B{E}(\tau) +  2\log(T) \right)
      + 3k.
  \end{align*}

  Since $m = \lceil (T/n)^{2/3} \rceil$, we have $(T/n)^{2/3} \leq m \leq (T/n)^{2/3} + 1$.
  Therefore
  \begin{align*}
    \B{E}(\C{R})
    &\leq
      mnk + 2kT\sqrt{\frac{\log(T)}{m}}
      + \frac{4 k T}{m} \left( 7\B{E}(\tau) +  2\log(T) \right)
      + 3k \\
    &\leq
      ((T/n)^{2/3} + 1)nk + 2kT\sqrt{\frac{\log(T)}{(T/n)^{2/3}}}
      + \frac{4 k T}{(T/n)^{2/3}} \left( 7\B{E}(\tau) +  2\log(T) \right)
      + 3k \\
    &=
      kn^{1/3}T^{2/3} + kn + 2kn^{1/3}T^{2/3}\log(T)^{1/2}
      + 28 kn^{2/3}T^{1/3}\B{E}(\tau)
      + 8 kn^{2/3}T^{1/3}\log(T)
      + 3k \\
    &\leq
      12 kn^{1/3}T^{2/3}\log(T)
      + 28 kn^{2/3}T^{1/3}\B{E}(\tau)
      + 3k \\
    &= O(kn^{1/3}T^{2/3}\log(T))
      + O(kn^{2/3}T^{1/3}\B{E}(\tau)).  \qedhere
  \end{align*}
\end{proof}

\section{Unbounded Stochastic Conditionally Independent Delay}\label{apdx_ubed_ad}

\begin{lemma}\label{L:bound_P_E_prime_uniformly_bounded_tail_arm_dependent}
  If $(\Delta_{j, S})_{j = 1}^{\infty}$ is pairwise independent for all $S \in \C{S}$ and $\{\B{E}(\Delta_{j, S})\}_{j \geq 1, S \in \C{S}}$ is tight, then we have
  \[
    \B{P}(\C{E}'_d) \geq 1 - nk \exp\left(-\frac{\lambda^2}{2(\B{E}(\tau) + \lambda/3)}\right),
  \]
  where $d > 0$ is a real number, $\tau$ is a tail upper bound for the family $\{\B{E}_{\C{T}}(\Delta_{j, S})\}_{j \geq 1, S \in \C{S}}$ 
  and $\lambda = \max\left\{0, \frac{2d}{nk} - \B{E}(\tau)\right\}$.
\end{lemma}

\begin{proof}
  If $\lambda = 0$, then the statement is trivially true.
  So we will assume that $\lambda > 0$ and $d = \frac{nk}{2}(\B{E}(\tau) + \lambda)$.
  Define 
  \[
    C'_{i, a} = \sum_{j = t_{i, a}}^{t'_{i, a}} \Delta_j(\{x > t'_{i, a} - j\}).
  \]
  Note that the sum is only over the time-steps where the action $S^{i-1}\cup\{a\}$ is taken. 
  Therefore $C'_{i, a}$ is the sum of $m$ independent term.
  Using the fact that $\tau$ is an upper tail bound for $\{\B{E}_{\C{T}}(\Delta_{j, S})\}_{j \geq 1, S \in \C{S}}$, 
  we can see that
  \begin{align*}
    \B{E}(C'_{i, a})
    &= \sum_{j = t_{i, a}}^{t'_{i, a}} \B{E}(\Delta_j(\{ x > t'_{i, a} - j \}))
    \leq \sum_{j = t_{i, a}}^{t'_{i, a}} \tau(\{ x > t'_{i, a} - j \}) \\
    &\leq \sum_{j = 1}^{t'_{i, a}} \tau(\{ x > t'_{i, a} - j \})
    = \sum_{j = 1}^{t'_{i, a}} \tau(\{ x \geq j \})
    \leq \sum_{j = 0}^{\infty} \tau(\{ x \geq j \})
    = \B{E}(\tau).
  \end{align*}
  Using Bernstein's inequality, we have
  \begin{align*}
    \B{P}\left(C'_{i, a} > \frac{2d}{nk}\right) 
    &= \B{P}(C'_{i, a} > \B{E}(\tau) + \lambda) \\
    &\leq \B{P}(C'_{i, a} > \B{E}(C'_{i, a})+ \lambda) \\
    &\leq \exp\left(-\frac{\lambda^2}{2(\sum_{j = t_{i, a}}^{t'_{i, a}}\B{E}(\Delta_j(\{ x > t'_{i, a}-j \})^2) + \lambda/3)}\right) \\
    &\leq \exp\left(-\frac{\lambda^2}{2(\sum_{j = t_{i, a}}^{t'_{i, a}}\B{E}(\Delta_j(\{ x > t'_{i, a} - j \})) + \lambda/3)}\right) \\
    &= \exp\left(-\frac{\lambda^2}{2(\B{E}(C'_{i, a}) + \lambda/3)}\right) \\
    &\leq \exp\left(-\frac{\lambda^2}{2(\B{E}(\tau) + \lambda/3)}\right).
  \end{align*}


  We have
  $ X_t = \sum_{j = 1}^t F_j(S_j) \Delta_j(t-j) $.
  Therefore
  \begin{align*}
    m|\bar{X}_{i, a} - \bar{F}_{i, a}|
    &=\left|
      \sum_{t=t_{i, a}}^{t'_{i, a}} X_t - \sum_{t=t_{i, a}}^{t'_{i, a}} F_t
      \right| \\
    &= \left|
      \sum_{j = 1}^{t'_{i, a}} F_j \Delta_j({\{t_{i, a} -j \leq x \leq t'_{i, a}-j\}})
      - \sum_{t=t_{i, a}}^{t'_{i, a}} F_t
      \right| \\
    &= \left|
      \sum_{j = 1}^{t_{i, a}-1} F_j \Delta_j({\{t_{i, a} -j \leq x \leq t'_{i, a}-j\}})
      + \sum_{j = t_{i, a}}^{t'_{i, a}} F_j \Delta_j({\{x \leq t'_{i, a}-j\}})
      - \sum_{t=t_{i, a}}^{t'_{i, a}} F_t
      \right| \\
    &= \left|
      \sum_{j = 1}^{t_{i, a}-1} F_j \Delta_j({\{t_{i, a} -j \leq x \leq t'_{i, a}-j\}})
      - \sum_{j = t_{i, a}}^{t'_{i, a}} F_j \Delta_j({\{x > t'_{i, a}-j\}})
      \right| \\
    &\leq 
      \sum_{j = 1}^{t_{i, a}-1} \Delta_j({\{t_{i, a} -j \leq x \leq t'_{i, a}-j\}})
      + \sum_{j = t_{i, a}}^{t'_{i, a}} \Delta_j({\{x > t'_{i, a}-j\}}) \\
    &\leq \sum_{j = 1}^{t_{i, a}-1} \Delta_j({\{x > t_{i, a}-1-j\}}) + C'_{i, a}.
  \end{align*}
  Define
  \[
  I_{i, a} = \{(i', a') \mid t_{i', a'} < t_{i, a}\}.
  \]
  Then we have
  \begin{align*}
    \sum_{j = 1}^{t_{i, a}-1} \Delta_j({\{x > t_{i, a}-1-j\}})
    &= \sum_{(i',a') \in I_{i, a}} \sum_{j = t_{i', a'}}^{t'_{i', a'}} \Delta_j({\{x > t_{i, a}-1-j\}}) \\
    &\leq \sum_{(i',a') \in I_{i, a}} \sum_{j = t_{i', a'}}^{t'_{i', a'}} \Delta_j({\{x > t'_{i', a'}-j\}})
    = \sum_{(i',a') \in I_{i, a}} C'_{i',a'}.
  \end{align*}
  Therefore, we have
  \[
    m|\bar{X}_{i, a} - \bar{F}_{i, a}|
    \leq \sum_{i, a} C'_{i, a}
    \leq nk \max_{i, a}\{C'_{i, a}\}.
  \]
  
  Let $\C{E}^{**}_{i, a}$ be the event that $C_{i, a} \leq \frac{2d}{nk}$ and define
  \[
  \C{E}^{**} := \bigcap_{i, a} \C{E}^{**}_{i, a}.
  \]
  Our discussion above shows that we have
  \[
    \B{P}(\C{E}'_d) \geq \B{P}(\C{E}^{**}).
  \]
  On the other hand, we have
  \begin{align*}
    \B{P}(\C{E}^{**}) 
    &= \B{P}\left( \bigcap_{i, a} \C{E}^{**}_{i, a} \right) \\
    &= 1 - \B{P}\left( \bigcup_{i, a} (\C{E}^{**}_{i, a})^c \right) \\
    &= 1 - \B{P}\left( \bigcup_{i, a} \left\{ C'_{i, a} > \frac{2d}{nk} \right\} \right) \\
    &\geq 1 - \sum_{i, a}\B{P}\left( \left\{ C'_{i, a} > \frac{2d}{nk} \right\} \right) \\
    &\geq 1 - \sum_{i, a} \exp\left(-\frac{\lambda^2}{2(\B{E}(\tau) + \lambda/3)}\right) \\
    &\geq 1 - nk\exp\left(-\frac{\lambda^2}{2(\B{E}(\tau) + \lambda/3)}\right),
  \end{align*}
  which completes the proof.
\end{proof}

\begin{theorem}[Theorem~\ref{T:regret_stochastic_conditionally_independent} in the main text]
  If the delay sequence is stochastic and conditionally independent, then we have
  \begin{align*}
    \B{E}(\C{R})
    &= O(kn^{1/3}T^{2/3}(\log(T))^{1/2}
      + k^2n^{5/3}T^{1/3}\log(T))
      + O(k^2n^{5/3}T^{1/3}\B{E}(\tau)) \\
    &= O(k^2n^{4/3}T^{2/3}\log(T))
      + O(k^2n^{5/3}T^{1/3}\B{E}(\tau))
  \end{align*}
  where $\tau$ is an upper tail bound for $(\B{E}_{\C{T}}(\Delta_t))_{t = 1}^{\infty}$.
\end{theorem}

\begin{proof}
  Let $\op{rad} := \sqrt{\frac{\log(T)}{m}}$. Then, using $T \geq n$, we have
  \[
    2nkT\exp(-2m\op{rad}^2)
    = 2nkT\exp(-2\log(T))
    = 2nkT^{-1}
    \leq 2k.
  \]
  We choose $d := \frac{nk}{2}(\B{E}(\tau) + \max\{6\B{E}(\tau), 2\log(T)\})$
  and 
  $\lambda = \frac{2d}{nk} - \B{E}(\tau) = \max\{6\B{E}(\tau), 2\log(T)\}$.
  Then we have
  \begin{align*}
    \exp\left(-\frac{\lambda^2}{2(\B{E}(\tau) + \lambda/3)}\right)
    \leq \exp\left(-\frac{\lambda^2}{2(\lambda/6 + \lambda/3)}\right)
    = \exp(-\lambda)
    \leq \exp(-2\log(T))
    = T^{-2}.
  \end{align*}
  Therefore
  \[
    nkT\exp\left(-\frac{\lambda^2}{2(\B{E}(\tau) + \lambda/3)}\right)
    \leq nkT^{-1} \leq k.
  \]
  So, using Theorem~\ref{T:regret_bound_main} and Lemma~\ref{L:bound_P_E_prime_uniformly_bounded_tail_arm_dependent}, we have
  \begin{align*}
    \B{E}(\C{R})
    & \leq 
    mnk + 2kT\op{rad} + \frac{4kTd}{m} + 2nkT\exp(-2m\op{rad}^2) + T(1 - \B{P}(\C{E}'_d)) \\
    & \leq 
    mnk + 2kT\op{rad} + \frac{4kTd}{m} + 2nkT\exp(-2m\op{rad}^2) + nkT\exp\left(-\frac{\lambda^2}{2(\B{E}(\tau) + \lambda/3)}\right) \\
    & \leq
    mnk + 2kT\op{rad} + \frac{4kTd}{m} + 3k \\
    & =
      mnk + 2kT\sqrt{\frac{\log(T)}{m}}
      + \frac{2nk^2T}{m} \left( \B{E}(\tau) + \max\{6\B{E}(\tau), 2\log(T)\} \right)
      + 3k \\
    & \leq
      mnk + 2kT\sqrt{\frac{\log(T)}{m}}
      + \frac{2nk^2T}{m} \left( 7\B{E}(\tau) +  2\log(T) \right)
      + 3k.
  \end{align*}

  Since $m = \lceil (T/n)^{2/3} \rceil$, we have $(T/n)^{2/3} \leq m \leq (T/n)^{2/3} + 1$.
  Therefore
  \begin{align*}
    \B{E}(\C{R})
    &\leq
      mnk + 2kT\sqrt{\frac{\log(T)}{m}}
      + \frac{2 n k^2 T}{m} \left( 7\B{E}(\tau) +  2\log(T) \right)
      + 3k \\
    &\leq
      ((T/n)^{2/3} + 1)nk + 2kT\sqrt{\frac{\log(T)}{(T/n)^{2/3}}}
      + \frac{2 n k^2 T}{(T/n)^{2/3}} \left( 7\B{E}(\tau) +  2\log(T) \right)
      + 3k \\
    &=
      kn^{1/3}T^{2/3} + kn + 2kn^{1/3}T^{2/3}\log(T)^{1/2}
      + 14 k^2n^{5/3}T^{1/3}\B{E}(\tau)
      + 4 k^2n^{5/3}T^{1/3}\log(T)
      + 3k \\
    &= O(kn^{1/3}T^{2/3}(\log(T))^{1/2})
      + O(k^2n^{5/3}T^{1/3}\log(T))
      + O(k^2n^{5/3}T^{1/3}\B{E}(\tau)) \\
    &= O(k^2n^{4/3}T^{2/3}\log(T))
      + O(k^2n^{5/3}T^{1/3}\B{E}(\tau)).  \qedhere
  \end{align*}
\end{proof}

\section{ Extension to general combinatorial bandits }\label{apdx:general}

The results of this paper could be generalized to settings beyond monotone submodular bandits with cardinality constraint.
As we will see, instead of these assumptions, we only need a setting where we have an algorithm for the offline problem satisfying a specific notion of robustness.

As before, let $\Omega$ be the set of base arms and let $\C{S}$ be a subset of $2^\Omega$.
Let $\C{F}$ be a class of functions from $\C{S} \to [0, 1]$ where we know that $f \in \C{F}$.
We use $S^*$ to denote the optimal value of $f$.

\begin{definition}[\cite{nie2023framework}]
Let $\C{A}$ be an algorithm for the combinatorial optimization problem of maximizing a function $f : \C{S} \to \B{R}$ over a finite domain $\C{S} \subseteq 2^\Omega$ with the knowledge that $f$ belongs to a known class of functions $\C{F}$.
for any function $\hat{f} : \C{S} \to \B{R}$, let $\C{S}_{\C{A}, \hat{f}}$ denote the output of $\C{A}$ when it is run with $\hat{f}$ as its value oracle.
The algorithm $\C{A}$ called $(\alpha, \delta)$-robust if for any $\epsilon > 0$ and any function $\hat{f}$ such that $|f(S) - \hat{f}(S)| < \epsilon$ for all $S \in \C{S}$, we have
\[
f(S_{\C{A}, \hat{f}}) \geq \alpha f(S^*) - \delta \epsilon.
\]
\end{definition}

In this setting, $N$ is an upper-bound for the number of $\C{A}$'s queries to the value oracle.


In the previous sections, the set $\C{S}$ was the set of all subsets of $\Omega$ with size at most $k$ and $\C{F}$ was the set of monotone submodular functions on $\C{S}$.
Corollary~\ref{C:explotation_regret_bound_per_timestep} simply states that the greedy algorithm is $(1 - 1/e, 2k)$-robust.
If we choose $\C{A}$ to be the offline greedy algorithm, $\alpha = 1-1/e$, $\delta = 2k$ and $N = nk$, then Algorithm~\ref{ALG:CETC} will reduce to Algorithm~\ref{ALG:main}.


\begin{algorithm}[ht]
  \caption{C-ETC algorithm (\cite{nie2023framework}}\label{ALG:CETC}
  \begin{algorithmic}[1]
    \REQUIRE{ Set of base arms $\Omega$, horizon $T$, an offline  $(\alpha, \delta)$-robust algorithm $\C{A}$, and an upper-bound $N$ on the number of $\C{A}$'s queries to the value oracle}
    \ENSURE{ $N \leq T$  }
    
    \STATE{ $m \leftarrow \lceil (\delta T/N)^{2/3} \rceil$ }
    \WHILE{ $\C{A}$ queries the value of some action $S$ }
      \STATE{ Play $S$ arm $m$ times }
      \STATE{ Calculate the empirical mean $\bar{x}$ }
      \STATE{ Return $\bar{x}$ to $\C{A}$ }
    \ENDWHILE
    \FOR{ remaining time }
      \STATE{ Play action $S_{\C{A}}$ output by algorithm $\C{A}$ }
    \ENDFOR
  \end{algorithmic}
\end{algorithm}


The proof only needs minor changes to adapt for Algorithm~\ref{ALG:CETC}.
Lemma~\ref{L:bound_P_E} immediately generalizes to
\[ \B{P}(\C{E}) \geq 1 - 2N\exp(-2m\op{rad}^2), \]
where $nk$ is replaced by $N$.
Instead of Corollary~\ref{C:explotation_regret_bound_per_timestep}, we need the following statement.

\begin{corollary}\label{C:explotation_regret_bound_per_timestep_for_CETG}
  Under the event $\C{E} \cap \C{E}'_d$, for all $d > 0$, we have
  \[
    f(S_{\C{A}}) \geq \alpha f(S^*) - \delta \left( \op{rad} + \frac{2d}{m} \right).
  \]
\end{corollary}
\begin{proof}
Consider a time interval of length $m$, namely $t, t+1, \cdots, t+m-1$, where an action $S$ is repeated and the empirical mean $\bar{x}$ is observed.
We have
\begin{align*}
  m|\bar{x} - f(S)| 
  &= \left| \sum_{i = t}^{t + m-1} (x_t - f(S)) \right| 
  \leq \left| \sum_{i = t}^{t + m-1} (x_t - f_t) \right| 
    + \left| \sum_{i = t}^{t + m-1} (f_t - f(S)) \right|.
\end{align*}
Under the event $\C{E}$, we have 
\[
    \left| \sum_{i = t}^{t + m-1} (f_t - f(S)) \right| \leq m \op{rad},
\]
and under the event $\C{E}_d$, we have
\[
    \left| \sum_{i = t}^{t + m-1} (x_t - f_t) \right| \leq 2d.
\]
Therefore, we have
\[
|\bar{x} - f(S)| \leq \op{rad} + \frac{2d}{m}.
\]
Now the claim follows from the definition of $(\alpha, \delta)$-robustness of $\C{A}$.
\end{proof}

The proofs of Lemma~\ref{L:regret_conditioned_on_both} and Theorem~\ref{T:regret_bound_main} could be applied almost verbatim to give us
  \[
    \B{E}(\C{R}_\alpha) 
    \leq 
    mN + \delta T\op{rad} + \frac{2 \delta  Td}{m} + 2NT\exp(-2m\op{rad}^2) + T(1 - \B{P}(\C{E}'_d)),
  \]
for all $d > 0$.
The results below follow.
\begin{theorem}
  If the delay is uniformly bounded by $d$, then we have
  \[
    \B{E}(\C{R}_\alpha)
    = O(N^{1/3} \delta^{2/3} T^{2/3} (\log(T))^{1/2}) + O(N^{2/3} \delta^{1/3} T^{1/3} d).
  \]    
\end{theorem}

\begin{theorem}
  If the delay sequence is stochastic, then we have
  \[
    \B{E}(\C{R}_\alpha)
    = O(N^{1/3} \delta^{2/3} T^{2/3} \log(T))
      + O(N^{2/3} \delta^{1/3} T^{1/3} \B{E}(\tau)),
  \]
  where $\tau$ is an upper tail bound for $(\B{E}_{\C{T}}(\Delta_t))_{t = 1}^{\infty}$.
\end{theorem}

\begin{theorem}
  If the delay sequence is stochastic and conditionally independent, then we have
  \[
    \B{E}(\C{R}_\alpha)
    = O(N^{4/3} \delta^{2/3} T^{2/3} \log(T))
      + O(N^{5/3} \delta^{1/3} T^{1/3} \B{E}(\tau)),
  \]
  where $\tau$ is an upper tail bound for $(\B{E}_{\C{T}}(\Delta_t))_{t = 1}^{\infty}$.
\end{theorem}


\end{document}
