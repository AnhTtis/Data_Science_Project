\documentclass[11pt,draftclsnofoot, onecolumn]{IEEEtran}
%\documentclass[journal]{IEEEtran}

\usepackage{graphicx,cite,epsfig,amssymb,amsmath,subfigure,url,stfloats,latexsym}
\usepackage{array}
\usepackage{arydshln}
\usepackage{amsfonts}
\usepackage{pgfplots}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
%\usepackage{tikz}
%\usepackage{tkz-orm}
\usepackage{epstopdf}
\usepackage{amsfonts,amsthm}
\usepackage{multirow}
\usepackage{mathrsfs}
\usepackage{subfigure}
\usepackage{xcolor}
%\usepackage{subcaption}


%\usepackage[noend]{algpseudocode}
%\usepackage{algorithm}
%\usepackage[ruled]{algorithm2e}
%\usepackage[linesnumbered,ruled]{algorithm2e}%[ruled,vlined]{
%\usepackage[ruled]{algorithm2e}                 %算法排版样式1
%\renewcommand{\algorithmicrequire}{\textbf{Input:}}  % Use Input in the format of Algorithm
%\renewcommand{\algorithmicensure}{\textbf{Output:}} % Use Output in the format of Algorithm

\definecolor{mygray}{gray}{.9}
%\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}
\graphicspath{{figures/}}
\hyphenation{op-tical net-works semi-conduc-tor}
\newcolumntype{C}[1]{>{\PreserveBackslash\centering}p{#1}}
\newcolumntype{R}[1]{>{\PreserveBackslash\raggedleft}p{#1}}
\newcolumntype{L}[1]{>{\PreserveBackslash\raggedright}p{#1}}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{property}{Property}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newtheorem{remark}{Remark}
\newtheorem{conjecture}{Conjecture}
\newtheorem{example}{Example}[section]

\usepackage[flushleft]{threeparttable}


\begin{document}


%\markboth{IEEE TRANSACTIONS ON Information Theory, Vol. XX, No. Y, Month 2024} { \ldots}
\title{\mbox{}\vspace{0.5cm}\\
\textsc{\huge Finite Field Multiple Access} \vspace{1.5cm}}

\vspace{1.2cm}
\author{\normalsize
Qi-yue~Yu, {\it IEEE Senior Member},
Jiang-xuan~Li,
and Shu~Lin, {\it IEEE Life Fellow} 
%\thanks{Q.-Y.~Yu (email: yuqiyue@hit.edu.cn) and J.-X.~Li (email: 21S005095@stu.hit.edu.cn) are with the Communication Research Center, Harbin Institute of Technology, China. S. Lin (email: shulin@ucdavis.edu) is in University of California, Davis, U.S.}
%\thanks{
%This paper was presented [in part] at ... [and ...]
%A part of this paper has been submitted to \textit{IEEE International Symposium on Information Theory-Proceedings 2024, ISIT 2024}. Now, the conference paper is under review. }
%\thanks{The paper was submitted on Feb. 14, 2024, and revised on \today.}\\
}

\maketitle

\begin{abstract}
In the past several decades, various techniques have been developed and used for multiple-access (MA) communications. With the new applications for 6G, it is desirable to find new resources, physical or virtual, to confront the fast development of MA communication systems. For binary source transmission, this paper proposes an element-pair (EP) coding scheme for supporting massive users with short packet traffic, which solves the finite block length of multiuser reliability transmission problem. Each user is assigned to a unique EP and the collection of EPs assigned to the users has the unique sum-pattern mapping (USPM) structural property. In this paper, we first present methods for constructing two specific types of EP codes with USPM structural property based on the prime fields and extension fields of prime fields, respectively. Based on the EP-coding, we propose finite-field MA (FFMA) systems, in which an EP is viewed as a virtual resource for MA communications. The proposed FFMA is then applied to network layer and forms network FFMA systems for pure digital networks. Simulation results show that the error performance of the proposed FFMA over a Gaussian multiple-access channel can approach the error performance as that of the single-user transmission. 
%For network FFMA systems, a large prime factor can simultaneously multiplex more users, improving the multiplex efficiency.
\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
Multiple access, finite field, binary source transmission, 
element pair (EP), additive inverse element pair (AIEP) code,
finite-field multi-access (FFMA), digital network, 
Gaussian multiple-access channel (GMAC), network FFMA.
\end{IEEEkeywords}




\newpage
%\setcounter{page}{1}
%\vspace{-0.1in}
\section{Introduction}
\IEEEPARstart{M}{ultiple} access (MA) is one of the most important techniques for wireless communications. During the past several decades, various MA techniques have been developed for mobile communications to support various users and services \cite{FAdachi1, YChen_2018}. There is a need to explore specific MA techniques for supporting some new applications of next generation wireless communications. 


For the next generation of wireless communications, a series of appealing applications are taken into consideration\cite{6G, 6G_white}, such as ultra massive machine type communications (um-MTC) for massive connectivity, full digital world (e.g., digital twin), vehicle to everything (V2X), wireless data center, immersive extended reality (XR), wireless brain-machine interface, emergency rescue communications, and etc. In this paper, we investigate MA techniques for two specific applications, namely um-MTC and digital twin. 
\begin{itemize}
  \item
   In um-MTC communications, the communication network is required to support a very large number of devices simultaneously. With increasing number of devices, the connection density of an um-MTC system is around $10^{6} \sim 10^{8}$ devices/km$^2$ \cite{6G, UMA_2022}. The required MA technique for this scenario should simultaneously support massive users (or devices) with short packet traffic and achieve an acceptable \textit{per-user probability of error (PUER)} \cite{MIT_2017}.
  \item
  For the digital network scenario, the digital twin is expected to map between the digital world and the physical world, which can help us predict and reflect the physical world \cite{6G}. However, to design MA systems for digital networks, few \textit{physical resources} can be used to distinct users. Evidently, the conventional MA techniques, e.g., FDMA (frequency division multiple access), SDMA (space division multiple access), are not suitable for a pure digital network.
\end{itemize}


Currently, unsourced MA (UMA) technique is popular for the um-MTC communications, since it can support massive users with lower latency and power consumption. For an UMA system, all users use a common codebook to send their packets randomly, thus, the coordination center can be removed \cite{UMA_2022, UMA_PZ}. 
In \cite{MIT_2017}, the author presented a random-access code for a $J$-user Gaussian multiple-access channel (GMAC) and deduces the asymptotic limits. In usual, an UMA system is assumed that the total number of users is a large number (sometime to be an infinite number), and the active duration is set to be the length of a frame (or codeword) $N$, in which the active users may generate collision. Many works have been done on the theoretical bound analyses in a GMAC \cite{Capacity_GMC_2017, Capacity_GMC_2020, Capacity_GMC_2021, Capacity_GMC_Yury}. 


Besides the asymptotic limit analyses, the key issue of realizing UMA systems is to design suitable MA codes. To support massive users with short packet traffic, the payload of each user is always a short packet, i.e., 10 bits $\sim$ 100 bits. With finite block length (FBL), it is very difficult to design MA codes to approach the asymptotic limit. 
The popular MA codes are 
\textit{Bose–Chaudhuri–Hocquenghem (BCH) MA code} \cite{MIT_2017_2, BCH_MA}, 
\textit{coded compressed sensing (CCS) MA code} \cite{CCS_1, CCS_2}, 
\textit{polar MA code} \cite{Polar_1, Polar_2, Polar_3}, 
\textit{interleave division multiple-access (IDMA) MA code} \cite{IDMA_1}, 
\textit{sparse vector code} \cite{SVC_1, SVC_2} and etc.
A BCH MA code is a \textit{concatenated code} with a forward error correction (FEC) code as the inner code and a BCH code as the outer code \cite{BCH_MA}. The outer BCH MA code is used to resolve collisions by using the arithmetic character of the syndrome, and the inner FEC code can improve the error-correction performance to approach the asymptotic limit. 
A CCS MA code with a tree code can be used to reduce the decoding complexity \cite{CCS_2}. 
A polar MA code is a concatenation of a polar code and a spreading code, which can be decoded by a list decoding with successive interference cancellation (SIC) \cite{Polar_3}. 
Only an IDMA system is not enough for realizing UMA communications, thus, an IDMA is always jointly designed with a pilot code, e.g., CCS code, to form a joint IDMA MA code. 
All these MA codes are \textit{two-level concatenated codes}, whose decoding complexity are generally very high \cite{UMA_2022}. 
More importantly, the current MA codes cannot perfectly cancel the multiuser-interference (MUI) to achieve an essentially single-user BER (bit error rate) performance for each user. Hence, it is appealing to design a simple MA code for the um-MTC scenario, which can provide single-user performance for each user \cite{Capacity_GMC_Yury}. 
For digital networks case, it is difficult to utilize the current physical resources to identify individual users. Hence, it is necessary to find \textit{virtual resources} to distinct users and realize MA. 


In this paper, we propose an MA technique to provide some solutions to what needed for supporting massive simultaneous information transmissions from multiusers and solving the MUI problem. The proposed MA technique is devised based on EP-coding which provides virtual resources for MA communications. 
Since EP codes are constructed based on finite fields (FFs), we refer the proposed MA technique based on EP-coding as \textit{finite-field MA (FFMA)} technique (or coding). An MA communication system using FFMA-coding is referred to as an FFMA system for simplicity.

 
The work in this paper consists of four parts. In the first part, we first define the conception of EP-coding and present two methods for constructions of \textit{additive inverse EP (AIEP)} codes based on finite fields, including both \textit{prime fields} and \textit{extension fields} of prime fields. 
In the second part, we first present the encoding of an EP code, and then introduce the conceptions of \textit{finite-field multiple module (FFMM)} and \textit{finite-field multiuser code (FFMC)} which are generally used together with an EP encoder.
In the third part of this paper, we first present the FFMA technique based on the \textit{orthogonal uniquely decodable EP (UD-EP)} code ${\Psi}_{\rm B}$ over GF($2^m$) for MA communication systems, which is a type of \textit{MA code} with error correction ability.
The proposed FFMA system can solve the MUI issue with only a simple detector. 
More importantly, it can simultaneously support massive users with well-behaved PUER performance by designing a suitable channel code, instead of using complex detection algorithms.
In the fourth part, we apply the proposed FFMA to network layer and form \textit{network FFMA} systems for pure digital networks. 
Then, a finite-field multiuser channel code is proposed for the network FFMA systems, which is a joint design of EP-coding and channel coding.



The rest of this paper is organized as follows. 
Section II introduces the conception of EP-coding and gives constructions of two types of AIEP codes over finite fields. 
Bounds on the number of UD-EP codes that can be constructed for a given finite field are derived. 
Section III presents encoding of AIEP codes. Section IV presents an FFMA system over GF($2^m$) by using an orthogonal UD-EP code $\Psi_{\rm B}$ for a massive MA scenario. In Section V, a network FFMA system over GF($p^m$) is presented for a pure digital network scenario. In Section VI, simulations of the error performances of the proposed FFMA systems are given. Section VII concludes the paper with some remarks. 


In this paper, the symbol $\mathbb B = \{0, 1\}$ and $\mathbb {C}$ are used to denote the binary-field and complex-field. 
The notions $\bigoplus$, $\bigotimes$, $\sum$ and $\prod$ are used to denote modulo-$q$ addition, 
modulo-$q$ multiplication, complex addition, and complex product, respectively.
The symbols $\lceil x \rceil$ and $\lfloor x \rfloor$ denote the smallest integer that is equal to or larger than $x$ and the largest integer that is equal to or smaller than $x$, respectively.
The notation $(a)_q$ stands for modulo-$q$, and/or an element in GF($q$).
%${\bf I}_{m}$ is an $m \times m$ identity matrix.


%\vspace{-0.1in}

\section{AIEP Codes over Finite Fields}

Suppose GF($q$) is a finite-field with $q$ elements, where $q$ is a prime number or a power of the prime number. Let $\alpha$ denote a primitive element of GF($q$), and the powers of $\alpha$, i.e.,
$\alpha^{-1} = 0, \alpha^0=1, \alpha, \alpha^2, \ldots, \alpha^{(q - 2)}$, 
give all the $q$ elements of GF($q$). 
For a binary source transmission system, a transmit bit is either $(0)_2$ or $(1)_2$.
Hence, we can use two different elements in a finite-field GF($q$) to express the bit information, 
i.e., $(0)_2 \mapsto \alpha^{l_{j,0}}$ and $(1)_2 \mapsto \alpha^{l_{j,1}}$, 
where $\alpha^{l_{j,0}}, \alpha^{l_{j,1}} \in$ GF($q$) and $l_{j,0} \neq l_{j,1}$. We define the selected two elements $(\alpha^{l_{j,0}}, \alpha^{l_{j,1}})$ as an \textit{element pair (EP)}. 



In this section, we construct \textit{additive inverse element pair (AIEP) codes} based on finite fields. 
The first part of this section presents a method for constructing AIEP codes based on the \textit{prime fields}, and the second part presents a class of \textit{orthogonal} AIEP codes which are constructed based on the \textit{extension fields} of a prime field. 

Note that, $C_j$ and $\Psi$ stand for an EP and an EP code, respectively.
The subscripts of $C_j$ and $\Psi$ are used to describe the structural property.


%\vspace{-0.1in}
\subsection{AIEP Codes Based on Prime Fields}

Let GF($p$) = $\{0, 1, \ldots, p-1\}$ be a prime-field with $p > 2$.  
Partition the $p - 1$ nonzero elements GF($p$) into $(p - 1)/2$ 
\textit{mutually disjoint element-pairs} (\textit{EPs}), 
each EP consisting of a nonzero element $j$ in $\text{GF}(p)\backslash 0$ and 
its additive inverse $p - j$ (or simply $- j$). 
We call each such pair $(j, p - j)$ an \textit{additive inverse EP (AIEP)}. 
The partition of $\text{GF}(p)\backslash \{0\}$ into AIEPs, denoted by $\mathcal P$, is referred to as 
\textit{AIEP-partition}.
When $p = 2$, there is only one EP $C_{\rm B} =(0, 1)$ referred as the base EP, and the subscript ``B'' stands for binary (or $p=2$). 


Let $C_1^{\rm s}, C_2^{\rm s}, \ldots, C_{J}^{\rm s}$ be $J$ AIEPs in $\mathcal P$, 
where $J$ is a positive integer less than or equal to $(p - 1)/2$, i.e., $1 \le J \le (p - 1)/2$, 
and the subscript ``s'' stands for ``single symbol''.
For $1 \le j \le J$, let the AIEP be $(j, p - j)$, i.e., $C_j^{\rm s} = (j, p - j)$.
Denote $C_j^{\rm s}$'s \textit{reverse order AIEP (R-AIEP)} by $C_{j,{\rm R}}^{\rm s} = C_{p-j}^{\rm s} = (p - j, j)$, where the subscript ``R'' of $C_{j,{\rm R}}^{\rm s}$ stands for ``reverse order''.


The $J$ AIEPs $C_1^{\rm s}, C_2^{\rm s}, \ldots, C_J^{\rm s}$ form a partition of a subset of $2J$ elements in GF$(p) \backslash \{0\}$, a sub-partition of $\mathcal P$. 
Let $\Psi_{\rm s}$ denote the set $\{C_1^{\rm s}, C_2^{\rm s}, \ldots, C_J^{\rm s}\}$, 
i.e., ${\Psi}_{\rm s} = \{C_1^{\rm s}, C_2^{\rm s}, \ldots, C_J^{\rm s} \}$.  
The $J$ R-AIEPs $C_{1,{\rm R}}^{\rm s}, C_{2,{\rm R}}^{\rm s}, \ldots, C_{J,{\rm R}}^{\rm s}$ of 
$C_1^{\rm s}, C_2^{\rm s}, \ldots, C_J^{\rm s}$ form a \textit{reverse order set} of $\Psi_{\rm s}$, 
denoted by 
${\Psi}_{\rm s,R} = \{C_{1,{\rm R}}^{\rm s}, C_{2,{\rm R}}^{\rm s}, \ldots, C_{J,{\rm R}}^{\rm s} \}$ 
or ${\Psi}_{\rm s, R} = \{C_{p-1}^{\rm s}, C_{p-2}^{\rm s}, \ldots, C_{p-J}^{\rm s}\}$.


Let $(u_1, u_2, \ldots, u_j, \ldots, u_J)$  be a $J$-tuple over GF($p$) in which the $j$-th component $u_j$ is an element from $C_j^{\rm s}$, where $1 \le j \le J$. The $J$-tuple $(u_1, u_2, \ldots, u_J)$ is an element in the \textit{Cartesian product} $C_1^{\rm s} \times C_2^{\rm s} \times \ldots \times C_J^{\rm s}$ of the AIEPs in $\Psi_{\rm s}$. 
We view each $J$-tuple ${\bf u} = (u_1, u_2, \ldots, u_j, \ldots, u_J)$ in
$C_1^{\rm s} \times C_2^{\rm s} \times \ldots \times C_J^{\rm s}$ as a $J$-user AIEP codeword, 
where ${\Psi}_{\rm s} = C_1^{\rm s} \times C_2^{\rm s} \times \ldots \times C_J^{\rm s}$ forms a $J$-user AIEP code over GF($p$) with $2^J$ codewords.
Note that, ${\Psi}$ stands for an EP set and also an EP code.



The modulo-$p$ sum $w = \oplus_{j=1}^{J} u_j$ of the $J$ components in $(u_1, u_2, \ldots, u_{J})$ 
is called as the \textit{finite-field sum-pattern (FFSP)} of the $J$-tuple $(u_1, u_2, \ldots, u_{J})$, 
which is an element in GF($p$). 
The $J$-tuple $(p-u_1, p-u_2, \ldots, p-u_{J})$ is also an element in $C_1^{\rm s} \times C_2^{\rm s} \times \ldots \times C_{J}^{\rm s}$. 
The FFSP of $(p-u_1, p-u_2, \ldots, p-u_{J})$ is $p - w = p -  \oplus_{j=1}^{J} u_j$. 
If the FFSP of $(u_1, u_2, \ldots, u_{J})$ is the zero element $0$ in GF($p$), the FFSP of $(p-u_1, p-u_2, \ldots, p-u_{J})$ is also the zero element $0$ in GF($p$), i.e., $w = 0$ and $p - w = 0$ (modulo $p$). 




Let $(u_1, u_2, \ldots, u_{J})$ and $(u_1', u_2', \ldots, u_{J}')$ be \textit{any two} $J$-tuples in 
$\Psi_{\rm s} = C_1^{\rm s}  \times C_2^{\rm s} \times \ldots \times C_{J}^{\rm s}$. 
If $\oplus_{j=1}^{J} u_j \neq \oplus_{j=1}^{J} u_j'$, 
then an FFSP $w$ uniquely specifies a $J$-tuple in $C_1^{\rm s} \times C_2^{\rm s} \times \ldots \times C_{J}^{\rm s}$. 
That is to say that the mapping 
%\vspace{-0.1in}
\begin{equation} \label{e.UDmap}
(u_1, u_2, \ldots, u_{J}) \Longleftrightarrow w = \bigoplus_{j=1}^{J} u_j
\end{equation} 
is a one-to-one mapping. 
In this case, given the FFSP $w = \bigoplus_{j=1}^{J} u_j$, 
we can uniquely recover the $J$-tuple $(u_1, u_2, \ldots, u_{J})$ \textit{without ambiguity}. 
We say that the Cartesian product $\Psi_{\rm s} = C_1^{\rm s} \times C_2^{\rm s} \times \ldots \times C_{J}^{\rm s}$ has a \textit{unique sum-pattern mapping (USPM) structural property}.



If we view each $J$-tuple $(u_1, u_2, \ldots, u_{J})$ in $C_1^{\rm s} \times C_2^{\rm s} \times \ldots \times C_{J}^{\rm s}$ with the USPM structural property as a \textit{$J$-user codeword}, then we call ${\Psi}_{\rm s} = C_1^{\rm s} \times C_2^{\rm s} \times \ldots \times C_{J}^{\rm s}$ a $J$-user \textit{uniquely decodable AIEP (UD-AIEP) code} over GF($p$), simply a $J$-user UD-AIEP code. 
It means that an UD-AIEP code is a special case of an AIEP code. 
In other words, if an AIEP code has an USPM structural property, the AIEP code is an UD-AIEP code. 
When this code is used for an MA communication system with $J$ users, the $j$-th component $u_j$ in a codeword $(u_1, u_2, \ldots, u_{J})$ is the symbol to be transmitted by the $j$-th user for $1 \le j \le J$. 


Note that, for a $J$-user UD-AIEP code ${\Psi}_{\rm s}$, we can replace any AIEP $C_j^{\rm s}$ in ${\Psi}_{\rm s}$ by its R-AIEP $C_{j,{\rm R}}^{\rm s}$, and still obtain a $J$-user UD-AIEP code,
i.e., ${\Psi}_{\rm s} = C_1^{\rm s} \times C_2^{\rm s} \times \ldots \times C_{j,{\rm R}}^{\rm s} \times \ldots \times C_J^{\rm s}$.


\begin{figure}[t]
  \centering
  \includegraphics[width=0.7\textwidth]{GF5.pdf} 
  \caption{A diagram in table-form of Example 1. 
  (a) The FFSPs of $C_1^{\rm s} = (1, 4)$ and $C_2^{\rm s} = (2, 3)$ in GF($5$); 
  (b) the FFSPs of $C_1^{\rm s} = (1, 4)$ and $C_{2,{\rm R}}^{\rm s} = (3, 2)$ in GF($5$).
  } \label{Fig_GF5}
%  \vspace{-0.2in}
\end{figure}



\textbf{Example 1:} 
Consider the prime field GF($5$). 
Using this prime field, two AIEPs $C_1^{\rm s} = (1, 4)$ and $C_2^{\rm s} = (2, 3)$ can be constructed. 
The R-AIEPs of $C_1$ and $C_2$ are $C_{1,{\rm R}}^{\rm s} = (4, 1)$ and $C_{2,{\rm R}}^{\rm s} = (3, 2)$, respectively.
The Cartesian product $C_1^{\rm s} \times C_2^{\rm s}$ of $C_1^{\rm s}$ and $C_2^{\rm s}$ satisfies Eq. (\ref{e.UDmap}) as shown in Fig. \ref{Fig_GF5} (a). Hence, ${\Psi}_{\rm s} = C_1^{\rm s} \times C_2^{\rm s}$ is a 2-user UD-AIEP code over GF($5$).

When we replace $C_2^{\rm s}$ by $C_{2,{\rm R}}^{\rm s}$, the Cartesian product 
$C_1^{\rm s} \times C_{2,{\rm R}}^{\rm s}$ of $C_1^{\rm s}$ and $C_{2,{\rm R}}^{\rm s}$ still satisfies Eq. (\ref{e.UDmap}), thus $C_1^{\rm s} \times C_{2,{\rm R}}^{\rm s}$ also forms a 2-user UD-AIEP code over GF($5$) as shown in Fig. \ref{Fig_GF5} (b).
$\blacktriangle \blacktriangle$




For a $J$-user UD-AIEP code $\Psi_{\rm s}$ over GF($p$) where $p > 2$, 
no codeword can have FFSP equal to the zero element $0$ of GF($p$). 
Since the FFSPs of the $2^J$ codewords in $\Psi_{\rm s}$ must be distinct elements in GF($p$), 
$2^{J}$ must be less than or equal to $p - 1$, 
i.e., $2^J \le p - 1$. 
Hence, the number of users $J$ for an UD-AIEP code over GF($p$) is upper bounded as follows:
\begin{equation} \label{e2.1}
  J \le \log_2 (p-1).
\end{equation}
Summarizing the results developed above, we have the following theorem.

\begin{theorem}
The Cartesian product of $J$ AIEPs over a prime field GF($p$) with $p > 2$ is a $J$-user UD-AIEP code 
if and only if the FFSPs of all its $2^J$ codewords are different nonzero elements in GF($p$) 
with $J$ upper bounded by $\log_2 (p-1)$.
\end{theorem}



Note that, there are totally $(p-1)/2$ AIEPs in GF($p$), 
and $\log_2 (p-1)$ of them can form an UD-AIEP code.
Owing to the feature of finite-field,
we can totally have
$\eta_p = \lfloor \frac{p-1}{2\log_2 (p-1)}\rfloor$ UD-AIEP codes over GF($p$) for $p>3$, 
which form an UD-AIEP code set $\Xi$, i.e.,
%\begin{equation*}
 $ \Xi = \{ {\Psi}_{\rm s}(1), {\Psi}_{\rm s}(2), \ldots, 
   {\Psi}_{\rm s}(\eta_p)\},$
%\end{equation*}
where ${\Psi}_{\rm s}(1), {\Psi}_{\rm s}(2), \ldots, {\Psi}_{\rm s}(\eta_p)$ are $\log_2 (p-1)$-user UD-AIEP codes.




\begin{figure}[t]
  \centering
    \includegraphics[width=0.75\textwidth]{GF17.pdf}
  \caption{A diagram in table-form of Example 2. 
  (a) A $4$-user UD-AIEP code ${\Psi}_{\rm s}(1)$ over GF($17$) with $C_1 = (1,16), C_2 =(2,15), C_4 = (4,13), C_8=(8,9)$; and
  (b) a $4$-user UD-AIEP code ${\Psi}_{\rm s}(2)$ over GF($17$) with $C_3 = (3,14), C_5 =(5,12), C_6 = (6,11), C_7=(7,10)$.} \label{Fig_GF17}
%  \vspace{-0.2in}
\end{figure}




\textbf{Example 2:} 
Suppose we use the prime field GF($17$) for UD-AIEP codes construction. 
Eight AIEPs over GF($17$) can be constructed, which are 
$C_1^{\rm s} = (1, 16), C_2^{\rm s} = (2, 15), C_3^{\rm s} = (3, 14), C_4^{\rm s} = (4, 13), 
C_5^{\rm s} = (5, 12), C_6^{\rm s} = (6, 11), C_7^{\rm s} = (7, 10), C_8^{\rm s} = (8, 9)$. 
Since $\log_2 (17-1) = 4$, there are at most $4$ AIEPs whose Cartesian product satisfies the necessary and sufficient condition given by Theorem 1. 


Based on the $8$ AIEPs, we can construct two $4$-user UD-AIEP codes.
One of these two $4$-user UDAIEP code is formed by the following set of $4$ AIEPs:
\begin{equation*}
  {\Psi}_{\rm s}(1) = \{C_1^{\rm s} = (1, 16), C_2^{\rm s} = (2, 15), 
  C_4^{\rm s} = (4, 13), C_8^{\rm s} = (8, 9)\},
\end{equation*}
whose Cartesian product 
${\Psi}_{\rm s}(1) = C_1^{\rm s} \times C_2^{\rm s} \times C_4^{\rm s} \times C_8^{\rm s}$ 
gives a $4$-user UD-AIEP code as shown in Fig. \ref{Fig_GF17} (a). 
The other $4$-user UD-AIEP code is formed by the following set of $4$ AIEPs:
\begin{equation*}
  {\Psi}_{\rm s}(2) =\{C_3^{\rm s} = (3, 14), C_5^{\rm s} = (5, 12), 
  C_6^{\rm s} = (6, 11), C_7^{\rm s} = (7, 10)\},
\end{equation*}
whose Cartesian product 
${\Psi}_{\rm s}(2) = C_3^{\rm s} \times C_5^{\rm s} \times C_6^{\rm s} \times C_7^{\rm s}$ 
gives a $4$-user UD-AIEP code as shown in Fig. \ref{Fig_GF17} (b). 
All the AIEPs are different between ${\Psi}_{\rm s}(1)$ and ${\Psi}_{\rm s}(2)$.
$\blacktriangle  \blacktriangle$


%\textbf{Example 3:}
%Suppose we use the prime field GF($257$) for UDAIEP code construction. We can construct $16$ UD-AIEP codes, each consisting of $8$ AIEPs. $\blacktriangle  \blacktriangle$





\subsection{Orthogonal AIEP Codes Based on Extension Fields of Prime Fields}


In this subsection, we present a class of AIEP codes constructed based on extension fields of prime fields.
Let $m$ be a positive integer with $m \ge 2$ and GF($p^m$) be the extension field of the prime field GF($p$). 
The extension field GF($p^m$) is constructed based on a primitive polynomial 
${\bf g}(X) = g_0 + g_1 X + g_2 X^2 + \ldots + g_m X^m$
of degree $m$ with coefficients from GF($p$) which consists of $p^m$ elements and contains GF($p$) as a subfield \cite{Shu2009}.



Let $\alpha$ be a primitive element in GF($p^m$). 
Then, the powers of $\alpha$, namely $\alpha^{-1} = 0, \alpha^0 = 1, \alpha, \alpha^2, \ldots, 
\alpha^{(p^m - 2)}$, give all the $p^m$ elements of GF($p^m$). 
Each element $\alpha^{l_{j}}$, with $l_{j} = -1, 0, \ldots, p^m - 2$, in GF($p^m$) can be expressed as a linear sum of $\alpha^0 = 1, \alpha, \alpha^2, \ldots, \alpha^{(m - 1)}$ with coefficients from GF($p$) as 
\begin{equation} \label{e2.2}
    \alpha^{l_{j}} = a_{j,0} + a_{j,1} \alpha + a_{j,2} \alpha^2 + \ldots + 
    a_{j,m-1} \alpha^{(m-1)}.      
\end{equation}
From (\ref{e2.2}), we see that the element $\alpha^{l_{j}}$ can be uniquely represented by the $m$-tuple 
$(a_{j,0}, a_{j,1}, a_{j,2},\ldots, a_{j,m-1})$ over GF($p$), which is a linear combination of 
$\alpha^0, \alpha^1, \ldots, \alpha^{m-1}$, i.e., $\alpha^{l_{j}} = \oplus_{i=0}^{m-1} a_{j,i} \alpha^i$.

The field GF($p^m$) can form a vector space ${\mathbb V}_p(m)$ over GF($p$) of dimension $m$. 
Each vector in ${\mathbb V}_p(m)$ is an $m$-tuple over GF($p$). 
For $0 \le i < m$, it is known that $\alpha^i = (0, 0, \ldots, 1, 0,\ldots, 0)$ is an $m$-tuple with a 1-component at the $i$-th location and 0s elsewhere. 
The $m$ $m$-tuples $\alpha^0, \alpha^1, \alpha^2, \ldots, \alpha^{m-1}$ form an \textit{orthogonal (or normal) basis} of ${\mathbb V}_p(m)$. 
Hence, an element in GF($p^m$) can be expressed in three forms, namely \textit{power, polynomial and $m$-tuple forms}.


The sum of two elements 
$\alpha^{l_{j,0}} = \oplus_{i=0}^{m-1} a_{j_0,i} \alpha^i$
and
$\alpha^{l_{j,1}} = \oplus_{i=0}^{m-1} a_{j_1,i} \alpha^i$
is equal to
\begin{equation*}
\alpha^{l_{j,0}}+\alpha^{l_{j,1}} = (a_{j_0,0}+a_{j_1,0}) \alpha^0 + (a_{j_0,1}+a_{j_1,1}) \alpha^1 + \ldots
      +(a_{j_0,m-1}+a_{j_1,m-1}) \alpha^{m-1}.
\end{equation*}
The $m$-tuple representation of the sum $\alpha^{l_{j,0}} + \alpha^{l_{j,1}}$ is
%\vspace{-0.07in}
\begin{equation*}
    \left((a_{j_0,0} + a_{j_1,0}), (a_{j_0,1} + a_{j_1,1}), \ldots, (a_{j_0,m-1} + a_{j_1,m-1})\right). 
\end{equation*}
For $0 \le i < m$, if $(a_{j_0,i}, a_{j_1,i})$ is an additive inverse pair over GF($p$) or a pair of zero elements $(0, 0)$, then $a_{j_0,i} + a_{j_1,i} = 0$ and $\alpha^{l_{j,0}} + \alpha^{l_{j,1}}  = 0$, 
i.e., $\alpha^{l_{j,0}}$ and $\alpha^{l_{j,1}}$ are additive inverse to each other. 
In this case, $(\alpha^{l_{j,0}}, \alpha^{l_{j,1}})$ forms an AIEP over GF($p^m$). 


Now, we construct a type of \textit{orthogonal AIEP code}. 
If $(a_{j_0,i}, a_{j_1,i})$ is an nonzero AIEP over GF($p$), then 
\begin{equation*}
\alpha^i  (a_{j_0,i}, a_{j_1,i}) \triangleq (a_{j_0,i} \cdot \alpha^i, a_{j_1,i} \cdot \alpha^i),
\end{equation*}
is an AIEP over GF($p^m$).


Let ${\Psi}_{\rm s} = \{C_1^{\rm s}, C_2^{\rm s}, \ldots, C_l^{\rm s}, \ldots, C_{L}^{\rm s}\}$ be a set of $L$ AIEPs over GF($p$), where $C_l^{\rm s} = (l, p - l)$ with $1 \le l \le L$.
For $0 \le i < m$,
%let $\psi_i(l, p - l)$ denote the AIEP $\alpha^i C_l = (l \alpha^i, (p - l) \alpha^i)$ over GF($p^m$), i.e., $\psi_i(l, p - l) = \alpha^i C_l = (l \alpha^i, (p - l) \alpha^i)$. 
%Then, for $0 \le i < m$,
\begin{equation} \label{e2.5}
\Psi_{{\rm o},i} = \{\alpha^i \cdot C_1^{\rm s}, \alpha^i \cdot C_2^{\rm s}, \ldots, 
\alpha^i \cdot C_l^{\rm s}, \ldots, \alpha^i \cdot C_{L}^{\rm s} \},
\end{equation}
is a set of $L$ AIEPs over GF($p^m$) with the USPM structural property,
where the subscript ``o'' stands for ``orthogonal''.
Hence, the Cartesian product
\begin{equation*} % \label{e2.6}
\Psi_{{\rm o},i} \triangleq (\alpha^i \cdot C_1^{\rm s}) \times (\alpha^i \cdot C_2^{\rm s}) \times \ldots \times 
(\alpha^i \cdot C_L^{\rm s})
\end{equation*}
of the $L$ AIEPs in $\Psi_{{\rm o},i}$ forms an $L$-user UD-AIEP code over GF($p^m$) with $2^L$ codewords,
each consisting of $2^L$ nonzero elements in GF($p^m$).
With $i = 0, 1, \ldots, m-1$, we can form $m$ $L$-user UD-AIEP codes over GF($p^m$),
$\Psi_{{\rm o},0}, \Psi_{{\rm o},1}, \ldots, \Psi_{{\rm o},m-1}$, which are \textit{mutually disjoint}, 
i.e., $\Psi_{{\rm o},k} \bigcap \Psi_{{\rm o},i} = \emptyset$ for $k \neq i$ and $0 \le k, i < m$.


If we represent an element in GF($p^m$) as an $m$-tuple over GF($p$), 
the two additive inverse elements in the pair 
$\alpha^i \cdot C_l^{\rm s} = (l \cdot \alpha^i, (p - l) \cdot \alpha^i)$ is a pair of two $m$-tuples with nonzero components, $l$ and $p - l$, at the $i$-th location, respectively,
and $0$s at all the other locations, 
i.e., $(0, 0, \ldots, l, 0, \ldots, 0)$ and $(0, 0,\ldots, p - l, 0, \ldots, 0)$. 
Hence, in $m$-tuple form, all the $L$ AIEPs in $\Psi_{{\rm o},i}$ have either $l$ and $p - l$ at the $i$-th location and $0$'s elsewhere with $1 \le l \le L$, i.e., 
%\begin{small}
\begin{equation*}
  \begin{aligned}
\alpha^i \cdot C_l^{\rm s} = \{(0, 0, \ldots, l, 0, \ldots, 0), (0, 0, \ldots, p-l, 0, \ldots, 0) \}.\\
  \end{aligned}
\end{equation*}
%\end{small}


From $m$-tuple point of view, $\Psi_{{\rm o}, 0}, \Psi_{{\rm o}, 1}, \ldots, 
\Psi_{{\rm o}, m-1}$ are \textit{orthogonal} to each other, and they form $m$ orthogonal sets of AIEPs over GF($p$). 
Hence, $\Psi_{{\rm o}, 0}, \Psi_{{\rm o}, 1}, \ldots, \Psi_{{\rm o}, m-1}$ give $m$ orthogonal $L$-user UD-AIEP codes over GF($p^m$) (or over GF($p$) in $m$-tuple form). 
In $m$-tuple form, each codeword in $\Psi_{{\rm o},i}$ consists of $L$ $m$-tuples over GF($p$), 
each consisting of a single nonzero element from GF($p$) at the same location.
%
The union $\Psi_{\rm o} \triangleq \Psi_{{\rm o}, 0} \bigcup \Psi_{{\rm o}, 1} \bigcup \ldots 
\bigcup \Psi_{{\rm o}, m-1}$ forms an $Lm$-user orthogonal UD-AIEP code over GF($p^m$) with $2^{Lm}$ codewords over GF($p^m$) (or over GF($p$) in $m$-tuple form).
$\Psi_{\rm o}$ can be viewed as a \textit{cascaded} UD-AIEP code obtained by cascading the $m$ $L$-user UD-AIEP codes $\Psi_{{\rm o}, 0}, \Psi_{{\rm o}, 1}, \ldots, \Psi_{{\rm o}, m-1}$. 
We call $\Psi_{{\rm o}, 0}, \Psi_{{\rm o}, 1}, \ldots, \Psi_{{\rm o}, m-1}$ the \textit{constituent codes} of $\Psi_{\rm o}$. 


Now, we consider a special case of the orthogonal UD-AIEP code $\Psi_{\rm o}$.
For the popular finite-field GF($2^m$) which is an extension field of the binary field GF($2$),
let ${\Psi}_{\rm B}$ be the orthogonal UD-EP code constructed over GF($2^m$).
In this case, there is only one base EP over GF($2$), not an additive inverse pair, 
defined by $C_{\rm B} =(0,1)$.
Hence, it is able to derive that
\begin{equation*}
  \begin{aligned}
  {\Psi}_{\rm B} %= \{ {\Psi}_{{\rm o},0}, {\Psi}_{{\rm o},1}, \ldots, {\Psi}_{{\rm o},m-1} \}  
  = \{C_1^{\rm td}, C_2^{\rm td}, \ldots, C_j^{\rm td}, \ldots, C_J^{\rm td} \} \\
  %= \{ \alpha^{0} \cdot C_0, \alpha^{1} \cdot C_0, \ldots, \alpha^{m-1} \cdot C_0 \},
  \end{aligned}
\end{equation*}  
where $C_j^{\rm td} = {\Psi}_{{\rm o},j-1} = \alpha^{j-1} \cdot C_{\rm B} = \alpha^{j-1} \cdot (0,1)$ 
for $1 \le j \le m$.
%The number of UD-AIEPs over GF($2^m$) is equal to $m$. 
The subscript ``td'' of $C_j^{\rm td}$ stands for ``time division'', which will be introduced in a later section.



\textbf{Example 3:} 
For $p = 5$ and $m = 4$, consider the extension field GF($5^4$) of the prime field GF($5$). 
As shown in Example 1, using the prime field GF($5$), 
two AIEPs $C_1^{\rm s} = (1, 4)$ and $C_2^{\rm s} = (2, 3)$ can be constructed whose Cartesian product $C_1^{\rm s} \times C_2^{\rm s}$ is a 2-user UD-AIEP code over GF($5$). 
Based on this code, $8$ UD-AIEP codes over GF($5^4$) can be formed. 
They form $4$ orthogonal groups,
%\vspace{-0.1in}
%\begin{small}
\begin{equation*}
  \begin{aligned}
    \Psi_{{\rm o},0} = \{\alpha^{0} \cdot C_1, \alpha^{0} \cdot C_2\} = 
                    \{(1 \cdot \alpha^{0}, 4\cdot \alpha^{0}), (2 \cdot \alpha^{0}, 3\cdot \alpha^{0})\},\\
    \Psi_{{\rm o},1} = \{\alpha^{1} \cdot C_1, \alpha^{1} \cdot C_2\} = 
                    \{(1 \cdot \alpha^{1}, 4\cdot \alpha^{1}), (2 \cdot \alpha^{1}, 3\cdot \alpha^{1})\},\\
    \Psi_{{\rm o},2} = \{\alpha^{2} \cdot C_1, \alpha^{2} \cdot C_2\} = 
                    \{(1 \cdot \alpha^{2}, 4\cdot \alpha^{2}), (2 \cdot \alpha^{2}, 3\cdot \alpha^{2})\},\\
    \Psi_{{\rm o},3} = \{\alpha^{3} \cdot C_1, \alpha^{3} \cdot C_2\} = 
                    \{(1 \cdot \alpha^{3}, 4\cdot \alpha^{3}), (2 \cdot \alpha^{3}, 3\cdot \alpha^{3})\}.\\
   \end{aligned}
\end{equation*}
%\end{small}
The Cartesian products of these $4$ groups give $4$ orthogonal 2-user UD-AIEP codes 
$\Psi_{{\rm o},0}, \Psi_{{\rm o},1}$, $\Psi_{{\rm o},2}, \Psi_{{\rm o},3}$ over GF($5^4$). 
%(or over GF($5$) in $4$-tuple from). 
Their union gives an orthogonal $8$-user UD-AIEP code $\Psi_{\rm o}$ over GF($5^4$) with $2^{8} = 256$ codewords. 
$\blacktriangle  \blacktriangle$


%\vspace{-0.1in}
\section{Encoding of EP Codes}

In this section, we first introduce the encoding of an EP code, which is realized based on a \textit{binary to finite-field GF($q$) transform function}.
Then, we introduce the conceptions of \textit{finite-field multiple module (FFMM)} for the AIEP codes $\Psi_{\rm s}$ constructed over GF($p$), and \textit{finite-field multiuser code (FFMC)} for the orthogonal AIEP codes $\Psi_{\rm o}$ constructed over GF($p^m$).
Next, we investigate the orthogonal AIEP codes $\Psi_{\rm o}$ encoded by a channel encoder ${\bf C}_{gc}$, which is called orthogonal encoding of an error-correcting code over GF($p^m$).
The subscript ``gc'' of ${\bf C}_{gc}$ stands for ``globe code'', since the channel code ${\bf C}_{gc}$ is used through the MA transmission.




%\vspace{-0.1in}
\subsection{Binary to Finite-field GF($q$) Transform Function}

Let the bit-sequence at the output of the $j$-th user be ${\bf b}_j = (b_{j,0}, b_{j,1},\ldots, b_{j,k}, \ldots, b_{j,K-1})$, where $K$ is a positive integer, $1 \le j \le J$ and $0 \le k < K$.
The EP encoder is to map each bit-sequence ${\bf b}_j$ uniquely into a symbol-sequence 
${\bf u}_j = (u_{j,0},u_{j,1},\ldots, u_{j,k},\ldots, u_{j,K-1})$ 
by a \textit{binary to finite-field GF($q$) transform function} ${\rm F}_{{\rm B}2q}$, 
i.e., $u_{j,k} = {\rm F}_{{\rm B}2q}(b_{j,k})$.
Similarly, we can decode the EP code by an inverse function ${\rm F}_{q2{\rm B}}$ which transforms \textit{from finite-field GF($q$) to binary field}, i.e., $b_{j,k} = {\rm F}_{q2{\rm B}}(u_{j,k})$.


Assume each user is assigned an EP, e.g., the EP of $C_j = (\alpha^{l_{j,0}}, \alpha^{l_{j,1}})$ is assigned to the $j$-th user for $1 \le j \le J$.
The subscript ``$j$'' of ``$l_{j,0}$'' and ``$l_{j,1}$'' stands for the $j$-th EP,
and the subscripts ``$0$'' and ``$1$'' of ``$l_{j,0}$'' and ``$l_{j,1}$'' represent the input bits are $(0)_2$ and $(1)_2$, respectively. 
For $1 \le j \le J$, we can set the $k$-th component $u_{j,k}$ of ${\bf u}_j$ as
\begin{equation} \label{F_b2q}
  u_{j,k} = {\mathrm F}_{{\mathrm B}2q}(b_{j,k}) \triangleq b_{j,k} \odot C_j = 
  \left\{
    \begin{aligned}
      \alpha^{l_{j,0}}, \quad b_{j,k} = (0)_2  \\
      \alpha^{l_{j,1}}, \quad b_{j,k} = (1)_2  \\
    \end{aligned},
  \right.
\end{equation}
where $b_{j,k} \odot C_j$ is defined as a \textit{switching function}.
If the input bit is $b_{j,k} = (0)_2$, the transformed symbol component is $u_{j,k} = \alpha^{l_{j,0}}$;
otherwise, if the input bit is $b_{j,k} = (1)_2$, $u_{j,k}$ is equal to $u_{j,k} = \alpha^{l_{j,1}}$.
Let the input \textit{bit-block} of $J$ users of the $k$-th component denote by ${\bf b}[k]$, 
i.e., ${\bf b}[k] = (b_{1,k}, b_{2,k}, \ldots, b_{J,k})$, where $0 \le k < K$.
We also call the EP codeword $(u_{1,k}, u_{2,k}, \ldots, u_{J,k})$ in $\Psi$ as the output \textit{symbol-block} of $J$ users of the $k$-th component, expressed as 
${\bf u}[k] = (u_{1,k}, u_{2,k}, \ldots, u_{J,k})$.



\subsection{FFMM of an AIEP Code $\Psi_{\rm s}$}

A \textit{finite-field multiplex module (FFMM)} is used together with the EP code $\Psi$ for multiplexing the symbol-sequences of $J$-user.
There are various FFMMs for different EP codes.


For the AIEP codes $\Psi_{\rm s}$ constructed over GF($p$), 
let ${\mathcal A}_{{\rm M}}$ be an FFMM over a prime field GF($p$), which is a $J \times T$ binary matrix, i.e., ${\mathcal A}_{{\rm M}} \in {\mathbb B}^{J \times T}$, given by
%\setcounter{equation}{11}
\begin{equation}
  {\mathcal A}_{{\rm M}} = \left[
  \begin{matrix}
    a_{1,1} & a_{1,2} & \ldots & a_{1,T}\\
    a_{2,1} & a_{2,2} & \ldots & a_{2,T}\\
    \vdots  & \vdots  & \ddots & \vdots \\
    a_{J,1} & a_{J,2} & \ldots & a_{J,T}\\
  \end{matrix}
  \right],
\end{equation}
where $1 \le T \le J$, and the subscript ``M'' stands for ``multiplex''.
Then, the \textit{finite-field sum-pattern (FFSP) block} ${w}_{k}$ of the symbol-block ${\bf u}[k]$ is calculated as 
\begin{equation*}
  {w}_{k} = {\bf u}[k] \cdot {\mathcal A}_{{\rm M}},
\end{equation*}
which is a $1 \times T$ vector, i.e., $w_k = (w_{k,1}, \ldots, w_{k,t},\ldots, w_{k, T})$.
If each EP codeword (or symbol-block) ${\bf u}[k]$ in ${\Psi}_{\rm s}$ is mapped into a unique FFSP block $w_k$, we can uniquely recover ${\bf u}[k]$ from the FFSP block $w_k$
i.e., ${\bf u}[k] \leftrightarrow {w}_{k}$.
In this case, we must have $2^J \le p^T$ (or $J \le T \cdot \log_2 p$).
While, if $T=1$ and $J \le \log_2 (p-1)$, the AIEP code becomes as an UD-AIEP code with the USPM structural property.

To measure the performance of an AIEP code $\Psi_{\rm s}$, \textit{loading factor (LF)} $R_q$ is defined as the ratio of the number of served users to the number of occupied resources. 
For the FFMM of the AIEP constructed over GF($p$), the LF $R_q$ is calculated as  
\begin{equation}
R_q = {J}/{T},
\end{equation}
which is upper bounded by $\log_2 p$, because of $J \le T \cdot \log_2 p$.
Hence, the range of LF is $1 \le R_q \le \log_2 p$.
If $T = J$, the LF is equal to one, i.e., $R_q = 1$.

Note that, the LF $R_q$ of an UD-AIEP code over GF($p$) is equal to ${\log_2 (p-1)}$. 
Then, the LF of an AIEP code can be approximately upper bounded by an UD-AIEP code.
Although the AIEP code cannot improve the LF, it can support more users than an UD-AIEP code for a given prime-field GF($p$). 



%\vspace{-0.1in}
\subsubsection{FFMM of an UD-AIEP code}
For an UD-AIEP code over GF($p$), the number of served users $J$ is equal to or smaller than $\log_2 (p-1)$, i.e., $J \le \log_2 (p-1)$. 
In this case, the FFMM ${\mathcal A}_{\rm M}$ is a $J \times 1$ vector, i.e.,
%\setcounter{equation}{6}
\begin{equation} \label{e.G_M_addition}
  {\mathcal A}_{{\rm M}} = \left[
    \begin{matrix}
      1, 1, \ldots, 1\\
     \end{matrix}
    \right]^{\rm T},
\end{equation}
and computing the FFSP as $w_k = {\bf u}[k] \cdot {\mathcal A}_{{\rm M}} = \bigoplus_{j=1}^{J} u_{j,k}$, which is a simple \textit{finite-field addition operation} to the symbol-block ${\bf u}[k]$ (or EP codeword $(u_{1,k}, u_{2,k}, \ldots, u_{J,k})$ in $\Psi_{\rm s}$).



To explain the multiplexing of an UD-AIEP code, let us consider the 2-user UD-AIEP code over GF($5$) given in Example 1 which consists of two AIEPs $C_1^{\rm s} = (1, 4)$ and $C_2^{\rm s} = (2, 3)$ whose FFSPs are shown in Fig. 1 (a). First, we assign $C_1^{\rm s}$ and $C_2^{\rm s}$ to users $1$ and $2$, respectively. 
The two input bits $(0)_2$ and $(1)_2$ of user-$1$ are mapped into two elements $(1)_5$ and $(4)_5$ in GF($5$), respectively. For user-$2$, the two input bits $(0)_2$ and $(1)_2$ are mapped into two elements $(2)_5$ and $(3)_5$ in GF($5$), respectively. The multiplex process is an addition operation, i.e., $w = u_1 \oplus u_2$, which is sent to the channel. Based on the FFSP table given by Fig. 1 (a), we can recover the bit information of the two users from an FFSP appearing in the FFSP table. For example, if the received FFSP of the two-users in GF($5$) is $(3)_5$, the nonbinary elements of users $1$ and $2$ are $(1)_5$ and $(2)_5$, respectively, which indicate the bits from users 1 and 2 are $(0)_2$ and $(0)_2$, respectively.




\subsubsection{FFMM of an AIEP code}
As presented early, there are a total of $(p-1)/{2}$ AIEPs in a finite-field GF($p$).
However, only $\log_2 (p-1)$ AIEPs can form UD-AIEPs.
If $p > 3$, we have $\frac{p-1}{2} > \log_2 (p-1)$.
This indicates that $\frac{p-1}{2} - \log_2 (p-1)$ AIEPs are unused.
These unused AIEPs can also be assigned to users by designing FFMM ${\mathcal A}_{{\rm M}} \in {\mathbb B}^{J \times T}$.



There are various methods to construct FFMM. 
In the following, we present a \textit{concatenated multiple UD-AIEP codes (C-UDCs)} method, which consists of two steps:
  \begin{enumerate}
    \item
    Step one is to find all the UD-AIEP codes in the finite-field GF($p$), i.e.,
    \begin{equation*} 
     \Xi = \{ {\Psi}_{\rm s}(1), {\Psi}_{\rm s}(2), \ldots, {\Psi}_{\rm s}(\eta_p)\},
    \end{equation*}
    where ${\Psi}_{\rm s}(1), {\Psi}_{\rm s}(2), \ldots, {\Psi}_{\rm s}(\eta_p)$ are $\log_2 (p-1)$-user UD-AIEP codes, with $\eta_p = \lfloor \frac{p-1}{2\log_2(p-1)} \rfloor$.
    \item
    Step two is to make each output FFSP $w_{k,t}$ of ${w}_k$ for $1 \le t \le T$ belong to an UD-AIEP code in $\Xi$, i.e., $w_{k,t} \in {\Psi_{\rm s}}(t)$,
    where ${w}_k = (w_{k,1}, \ldots, w_{k,t}, \ldots, w_{k,T})$ and $T \le \eta_p$.  
  \end{enumerate}

  

\textbf {Example 4:} For the finite-field GF(17), its eight AIEPs have been given in Example 2,
which provide two UD-AIEP codes 
${\Psi}_{\rm s}(1) = \{C_1^{\rm s} =(1, 16), C_2^{\rm s} =(2, 15), 
                       C_4^{\rm s} = (4, 13), C_8^{\rm s} = (8, 9)\}$ 
and ${\Psi}_{\rm s}(2) = \{C_3^{\rm s} =(3, 14), C_5^{\rm s} =(5, 12), C_6^{\rm s} = (6, 11), C_7^{\rm s} = (7, 10)\}$.
If there are $J = 8$ users, the UD-AIEP code cannot support $8$ users.
We can design a $8 \times 2$ binary FFMM ${\mathcal A}_{{\rm M}}$ as follows:
\begin{equation*}
  {\mathcal A}_{{\rm M}}^{\rm T} = \left[
  \begin{matrix}
    1 & 1 & 0 & 1 & 0 & 0 & 0 & 1\\
    0 & 0 & 1 & 0 & 1 & 1 & 1 & 0\\
  \end{matrix}
  \right].
\end{equation*}
With this FFMM, ${w} = {\bf u} \cdot {\mathcal A}_{\rm M}$ is a $1 \times 2$ vector in GF($17$).
The two components of ${w}$ are:
\begin{equation*}
  \begin{aligned}
  w_1 = u_1 \oplus u_2 \oplus u_4 \oplus u_8 \in {\Psi}_{\rm s}(1), \\
  w_2 = u_3 \oplus u_5 \oplus u_6 \oplus u_7 \in {\Psi}_{\rm s}(2). \\
  \end{aligned}
\end{equation*}
Since ${\Psi}_{\rm s}(1)$ and ${\Psi}_{\rm s}(2)$ are UD-AIEP codes, 
the LF of ${\mathcal A}_{\rm M}$ is ${R_q} = 4$, 
which is also equal to the LF of an UD-AIEP code over GF(17).

For example, if ${w} = (w_1, w_2) = (15, 4)_{17}$, following from the Fig. 2 (a) and (b),
we find that $u_1 = (1)_{17}, u_2 = (2)_{17}, u_4 = (4)_{17}, u_8 = (8)_{17}$, 
and $u_3 = (3)_{17}, u_5 = (5)_{17}, u_6 = (6)_{17}, u_7 = (7)_{17}$.
$\blacktriangle \blacktriangle$


%\vspace{-0.07in}
\subsection{FFMM and FFMC of an Orthogonal UD-EP Code $\Psi_{\rm o}$}

For the orthogonal UD-EP code $\Psi_{\rm o}$ over GF($p^m$), 
set the FFMM ${\mathcal A}_{\rm M}$ is the same as Eq. (\ref{e.G_M_addition}), i.e.,
 ${\mathcal A}_{{\rm M}} = \left[1, 1, \ldots, 1 \right]^{\rm T}$,
resulting in a finite-field addition operation.


Now, we introduce the conception of \textit{finite-field multiuser code (FFMC)}, which is presented for an EP code constructed over an extension field GF($p^m$) where $m \ge 2$.
We take the UD-EP code $\Psi_{\rm B}$ constructed over GF($2^m$) as an example.
The UD-EP code $\Psi_{\rm B}$ is used to support an $m$-user FFMA. 
We assign $C_j^{\rm td}$ to the $j$-th user for $1 \le j \le m$, and the FFSP is calculated as 
\begin{equation} \label{e.w_tdma}
\begin{aligned}
w_k &\overset{(a)}{=} {\bf u}[k] \cdot {\mathcal A}_{{\rm M}} = u_{1,k} + u_{2,k} + \ldots + u_{m,k} \\
    &\overset{(b)}{=} b_{1,k} \alpha^0 + b_{2,k} \alpha^1 + \ldots + b_{m,k} \alpha^{m-1} 
     {=} {\bf b}[k] \cdot {\bf G}_{\rm M}^{\bf 1}
\end{aligned},
\end{equation}
in which (a) indicates that the symbol-block ${\bf u}[k]$ is encoded by the FFMM ${\mathcal A}_{{\rm M}}$ which is a finite-field addition operation,
and (b) is deduced based on (\ref{F_b2q}) and the orthogonal EPs $C_j^{\rm td}$ for $1 \le j \le m$.
We call ${\bf G}_{\rm M}^{\bf 1}$ the \textit{generator matrix} of \textit{finite-field multiuser code (FFMC)}, which is used to encode the input bit-block ${\bf b}[k]$ of $J$-user.


For the orthogonal UD-EP code $\Psi_{\rm B}$ over GF($2^m$), the generator matrix of FFMC,
i.e., ${\bf G}_{\rm M}^{\bf 1} = [\alpha^0, \alpha^1, \ldots, \alpha^{m-1}]^{\rm T}$, is given as
\begin{equation*}
{\bf G}_{\rm M}^{\bf 1} = \left[ 
\begin{matrix}
\alpha^{0}\\
\alpha^{1}\\
\vdots\\
\alpha^{m-1}
\end{matrix}
\right] =
\left[ 
\begin{matrix}
1 & 0 & \ldots & 0\\
0 & 1 & \ldots & 0\\
\vdots & \vdots &\ddots &\vdots\\
0 & 0 & \ldots & 1\\
\end{matrix}
\right],
\end{equation*}
which is an $m \times m$ identity matrix. 
Thus, based on the orthogonal UD-EP code $\Psi_{\rm B}$ over GF($2^m$), the proposed system is \textit{a type of TDMA in finite-field (FFMA-TDMA)}, in which the outputs of the $m$ users completely occupy $m$ locations in an $m$-tuple (similarly to the $m$ time slots).

For an EP code constructed over an extension field of a prime field GF($p^m$) where $m \ge 2$,
if its FFMM is a $J \times 1$ full one vector, i.e., ${\mathcal A}_{{\rm M}} = \left[1, 1, \ldots, 1 \right]^{\rm T}$, then its LF $R_q$ is only determined by the size of its FFMC. 
For the orthogonal UD-EP code over GF($2^m$), its LF is equal to $R_q = 1$.




%\vspace{-0.1in}
\subsection{Orthogonal Encoding of an Error-correcting Code}

In the following, we present an encoding of an error-correcting code over GF($p^m$) in a form to match the orthogonal UD-EP code $\Psi_{\rm o}$.
In a latter section, orthogonal UD-EP codes will be used in conjunction with error-correcting codes for error control in FFMA systems. 


Suppose ${\bf w} = (w_0, w_1, \ldots, w_k, \ldots, w_{K-1})$ is a sequence over GF($p^m$),
where $K$ is a positive integer.  
For $0 \le k < K$, let $(u_{0,k}, u_{1,k},\ldots, u_{j,k},\ldots, u_{m-1,k})$ be the $m$-tuple representation of the $k$-th component $w_k$ of ${\bf w}$, i.e.,
\begin{equation*} 
  \begin{aligned}
w_k &= (u_{0,k}, u_{1,k},\ldots, u_{j,k},\ldots, u_{m-1,k}) \\
    &= u_{0,k} \alpha^0 + u_{1,k} \alpha^1 + \ldots + u_{j,k} \alpha^j + \ldots + u_{m-1,k} \alpha^{m-1},
  \end{aligned}
\end{equation*}
where $u_{j,k} \in$ GF($p$) and $ 0 \le j < m$.

Hence, $w_k$ can be viewed as the FFSP of the $m$ symbols $u_{0,k}, u_{1,k},\ldots, u_{j,k},\ldots, u_{m-1,k}$. It is a one-to-one mapping between $w_k$ and the symbol-block ${\bf u}[k]$, 
where ${\bf u}[k] = (u_{0,k}, u_{1,k},\ldots, u_{j,k},\ldots, u_{m-1,k})$.

For $0 \le j < m$, we form the following symbol-sequence over GF($p$), i.e.,
${\bf u}_j = (u_{j,0}, u_{j,1}, \ldots, u_{j,k},\ldots, u_{j,K-1})$,                           
where $u_{j,k}$ is the $j$-th component of $w_k$. 
Define the following $K$ $m$-tuples over GF($p$) as
\begin{equation} \label{e2.11}
    {\bf u}_j \cdot \alpha^j \triangleq (u_{j,0} \alpha^j, u_{j,1} \alpha^j, \ldots, 
    u_{j,k} \alpha^j, \ldots, u_{j,K-1} \alpha^j).   
\end{equation}


Then, the $K$-tuple $\bf w$ over GF($p^m$) can be decomposed into the following ordered sequence of $K$ 
$m$-tuples over GF($p$),
\begin{equation} \label{e2.12}
    {\bf w} \triangleq  
    {\bf u}_0 \cdot \alpha^0 + {\bf u}_1 \cdot \alpha^1 + \ldots + 
    {\bf u}_j \cdot \alpha^j + \ldots + {\bf u}_{m-1} \cdot \alpha^{m-1},  
\end{equation}
which is the \textit{orthogonal $m$-tuple decomposition of $\bf w$}.
This orthogonal form indicates a sequence ${\bf w}$ over GF($p^m$) can be decomposed into $m$ symbol-sequences ${\bf u}_0, {\bf u}_1, \ldots, {\bf u}_{m-1}$.
In other words, ${\bf w}$ is the FFSP sequence of the $m$ symbol sequences ${\bf u}_0, {\bf u}_1, \ldots, {\bf u}_{m-1}$.
%This orthogonal form will be used in presentation an uplink FFMA scheme in a later section.



Let ${\bf G}_{gc}$ be the generator matrix of a $p^m$-ary $(N, K)$ linear block code ${\bf C}_{gc}$ over GF($p^m$) with $m \ge 2$. Let ${\bf g}_0, {\bf g}_1, \ldots, {\bf g}_{K-1}$ be the $K$ rows of ${\bf G}_{gc}$, each an $N$-tuple over GF($p^m$). 
Let ${\bf w} = (w_0, w_1, \ldots, w_k, \ldots, w_{K-1})$ be a message over GF($p^m$) whose orthogonal decomposition is given by (\ref{e2.12}). 
Then, we encode $\bf w$ into a codeword $\bf v$ in ${\bf C}_{gc}$ using the generator ${\bf G}_{gc}$, i.e.,
\begin{equation*} 
  {\bf v} = {\bf w} \cdot {\bf G}_{gc} = (v_0, v_1, v_2, \ldots, v_{N-1}).
\end{equation*}

The orthogonal $m$-tuple decomposition of $\bf v$ is given by (\ref{e2.13}), 
%\begin{figure*}[htb]
%\setcounter{equation}{10}
%\begin{small}
\begin{equation} \label{e2.13}
  \begin{aligned}
{\bf v} =& {\bf w} \cdot {\bf G}_{gc} 
        = w_0 {\bf g}_0 + w_1 {\bf g}_1 + \ldots + w_{K-1} {\bf g}_{K-1}\\
        =& \left(u_{0,0}  \alpha^0 \oplus u_{1,0} \alpha^1 \oplus \ldots \oplus 
                     u_{m-1,0} \alpha^{m-1} \right) {\bf g}_0 +
               \left(u_{0,1}  \alpha^0 \oplus u_{1,1} \alpha^1 \oplus \ldots \oplus 
                     u_{m-1,1} \alpha^{m-1} \right) {\bf g}_1 + \ldots +\\
               &\left(u_{0,K-1} \alpha^0 \oplus u_{1,K-1} \alpha^1 \oplus \ldots \oplus 
                     u_{m-1,K-1} \alpha^{m-1} \right) {\bf g}_{K-1} \\
        =& \left(u_{0,0} \alpha^0 {\bf g}_0 + u_{0,1} \alpha^0 {\bf g}_1 + \ldots 
                    + u_{0,K-1} \alpha^0 {\bf g}_{K-1}\right) \oplus
           \left(u_{1,0} \alpha^1 {\bf g}_0 + u_{1,1} \alpha^1 {\bf g}_1 + \ldots 
                    + u_{1,K-1} \alpha^1 {\bf g}_{K-1}\right) \oplus \ldots \oplus\\
          &\left(u_{m-1,0} \alpha^{m-1} {\bf g}_0 + u_{m-1,1} \alpha^{m-1} {\bf g}_1 + \ldots 
                    + u_{m-1,K-1} \alpha^{m-1} {\bf g}_{K-1}\right) \\
        =& ({\bf u}_0 \cdot {\bf G}_{gc}) \alpha^0 \oplus 
           ({\bf u}_1 \cdot {\bf G}_{gc}) \alpha^1 \oplus \ldots \oplus 
           ({\bf u}_{m-1} \cdot {\bf G}_{gc}) \alpha^{m-1}
        {=} {\bf v}_0 \alpha^0 \oplus {\bf v}_1 \alpha^1 \oplus \ldots \oplus {\bf v}_{m-1}\alpha^{m-1}.    
  \end{aligned}
\end{equation}
%\end{small}
%\hrulefill
%\end{figure*}
where ${\bf v}_j = {\bf u}_j {\bf G}_{gc}$ is the codeword of ${\bf u}_j$ for $0 \le j < m$. The codeword $\bf v$ in orthogonal form is referred to as \textit{orthogonal encoding} of the message $\bf w$, indicating the codeword $\bf v$ is the FFSP of the codewords ${\bf v}_0, {\bf v}_1, \ldots, {\bf v}_{m-1}$.



Note that the orthogonal encoding is also applicable to the linear bock code ${\bf C}_{gc}$ constructed over GF($p$). In this case, ${\bf C}_{gc}$ is a $(N, Km)$ linear block code over GF($p$).





\section{An FFMA System for a Massive MA Communication Scenario}
This section presents an uplink FFMA system for a GMAC, based on the UD-EP code $\Psi_{\rm B}$ constructed over the extension field GF($2^m$) of the binary field GF($2$), i.e., 
\begin{equation*}
  \Psi_{\rm B} = \{C_1^{\rm td}, C_2^{\rm td}, \ldots, C_j^{\rm td}, \ldots, C_J^{\rm td} \},
\end{equation*}
where $C_j^{\rm td} = \alpha^{j-1} \cdot C_{\rm B}$ for $1 \le j \le J$.
The parameter $m$ indicates the number of finite-field time slots which can be viewed as \textit{virtual resource blocks (VRBs)}. The VRB will be further discussed in the following section.
The number of users $J$ that the system can support is equal to or smaller than $m$, i.e., $J \le m$.
The UD-EP $C_j^{\rm td}$ is assigned to the $j$-th user. 
For a massive MA case, $m$ is a large number.
The block diagram for such a system is shown in Fig. \ref{Fig_UL}.


\begin{figure*}[t]
  \centering
  \includegraphics[width=0.9\textwidth]{Fig_UL.pdf}
  \label{Fig_UL}
  \caption{A block diagram of an FFMA system in a GMAC,
  where ${\rm F}_{{\rm B}2q}$ and ${\rm F}_{q2{\rm B}}$ stand for ``binary to finite-field GF($q$) transform'' and ``finite-field GF($q$) to binary transform''; 
  ${\rm F}_{q2Q}$ and ${\rm F}_{Q2q}$ are ``finite-field GF($q$) to finite-field GF($Q$) transform'' and ``finite-field GF($Q$) to finite-field GF($q$) transform''; 
  $\rm F_{F2C}$ and $\rm F_{C2F}$ stand for ``finite-field to complex-field transform'' and ``complex-field to finite-field transform''.} 
  \label{Fig_UL}
%  \vspace{-0.2in}
\end{figure*}


%\vspace{-0.1in}
\subsection{Transmitter of a Sparse-form-based FFMA System}

Let ${\bf b}_j = (b_{j,0}, b_{j,1},\ldots, b_{j,k}, \ldots, b_{j,K-1})$ be the bit-sequence at the output of the $j$-th user, where $1 \le j \le J$ and $0 \le k < K$.
The transmitter maps each bit-sequence ${\bf b}_j$ uniquely into a symbol-sequence 
${\bf u}_j = (u_{j,0},u_{j,1},\ldots, u_{j,k},\ldots, u_{j,K-1})$ by ${\rm F}_{{\rm B}2q}$, 
i.e., $u_{j,k} = {\rm F}_{{\rm B}2q}(b_{j,k})$, 
which is determined by the EP $C_j^{\rm td} = \alpha^{j-1} \cdot C_{\rm B}$.
For $0 \le k < K$, the $k$-th symbol $u_{j,k}$ of ${\bf u}_j$ is represented by its corresponding $m$-tuple representation over GF($2$),
i.e., $u_{j,k} =(u_{j,k,0}, u_{j,k,1},\ldots, u_{j,k,i},\ldots, u_{j,k,m-1})$, where $0 \le i < m$.
Then, the $m$-tuple form of $u_{j,k}$ is

%\vspace{-0.1in}
%\setcounter{equation}{11}
%\begin{small}
\begin{equation} \label{e.u_j_k}
{u}_{j,k} = {\rm F}_{{\rm B}2q}(b_{j,k}) = b_{j,k} \odot C_j^{\rm td} = (0,\ldots, 0, b_{j,k}, 0,\ldots, 0),
\end{equation} 
%\end{small}
and the $i$-th component of $u_{j,k}$ is 
\begin{equation} \label{e.u_j}
u_{j,k,i} =
\left\{
  \begin{matrix}
    b_{j,k}, & i = j-1\\
    0,       & i \neq j-1 \\
  \end{matrix}. \right.
\end{equation}
For a large $m$, $u_{j,k}$ is a {sparse vector} with only one element.


Next, the symbol-sequence ${\bf u}_j$ is encoded into a codeword ${\bf v}_j$ of an $(N_Q, K_Q)$ linear block code ${\bf C}_{gc}$ of length $N_Q$ over GF($Q$) specified by a $K_Q \times N_Q$ generator matrix ${\bf G}_{gc}$.
Since $Q$ can be different from $q$, a \textit{finite-field GF($q$) to finite-field GF($Q$) transform function} ${\rm F}_{q2Q}$ is required. In this paper, we only consider two cases.



In the first case, $Q$ is equal to $q=2^m$, i.e., $Q=q=2^m$, and the block code ${\bf C}_{gc}$ is constructed based on the same field GF($2^m$) as that of the UD-EP code $\Psi_{\rm B}$. 
The transform function ${\rm F}_{q2Q}$ is used to transform the \textit{$m$-tuple form} of ${u}_{j,k}$ into the \textit{power form} of ${u}_{j,k}$. 
In this case, set $K_Q = K$, and the generator matrix ${\bf G}_{gc}$ becomes as a $K \times N_Q$ matrix.
Then, we encode ${\bf u}_j$ by the generator matrix ${\bf G}_{gc}$, 
and obtain the codeword ${\bf v}_j$ of ${\bf u}_j$ as
\begin{equation*} \label{e5.3}
   {\bf v}_j = {\bf u}_j {\bf G}_{gc} = (v_{j,0}, v_{j,1},\ldots, v_{j,n_q}, \ldots, v_{j,N_Q-1}),   
\end{equation*}
where $v_{j,n_q} \in$ GF($2^m$) and $0 \le n_q < N_Q$.


Express each symbol $v_{j,n_q}$ in ${\bf v}_j$ into an $m$-tuple over GF(2), i.e., 
$v_{j,n_q} = (v_{j,n_q,0}, v_{j,n_q,1},\ldots, v_{j,n_q,i}, \ldots, v_{j,n_q,m-1})$.
Then, the codeword ${\bf v}_j$ for ${\bf u}_j$ becomes an $m N_Q$-tuple over GF($2$).
If we set $N = mN_Q$, then ${\bf v}_j$ is an $N$-tuple over GF(2), 
i.e., ${\bf v}_j = (v_{j,0}, v_{j,1},\ldots, v_{j,n}, \ldots, v_{j,N-1})$, 
where $v_{j,n} \in {\mathbb B}$ and $0 \le n < N$.
We say that the codeword ${\bf v}_j$ for ${\bf u}_j$ in binary-form.
Hence, in this case, encoding of the bit-sequence ${\bf b}_j$ to its binary-form codeword ${\bf v}_j$ is binary.


In the second case, we set $Q=2$ and $q=2^m$.
In this case, the function of ${\rm F}_{q2Q}$ is the same as the transform function ${\rm F}_{{\rm B}2q}$. Hence, the transform function ${\rm F}_{q2Q}$ in encoding can be removed.
Let $K_Q = K \cdot m$ and $N_Q = N$.
Then, the generator matrix ${\bf G}_{gc}$ is a $Km \times N$ matrix over GF($2$). 
The encoded codeword ${\bf v}_j$ is a vector over GF($2$).
%The second case is simply a special case of the first case.


Generally, the generator matrix ${\bf G}_{gc}$ is either in systematic form ${\bf G}_{gc,sym}$ or non-systematic form ${\bf G}_{gc,nonsym}$. Both forms of ${\bf G}_{gc}$ can be used in the proposed FFMA systems.
Nevertheless, a systematic form of the generator ${\bf G}_{gc,sym}$ may provide more flexibility in designing FFMA systems. This will be shown later in this section.


Suppose the $Km \times N$ generator matrix over GF($2$) is in systematic form, 
defined by ${\bf G}_{gc,sym}$.
Then, the codeword ${\bf v}_j$ is of the following form
%\vspace{-0.2in}
%\begin{small}
\begin{equation*}
  {\bf v}_j = {\bf u}_j \cdot {\bf G}_{gc,sym}
  = ({\bf u}_j, {\bf v}_{j,red}) = (u_{j,0}, u_{j,1}, \ldots, u_{j,K-1}, \textcolor{blue}{{\bf v}_{j,red})},
\end{equation*}
%\end{small}
where $u_{j,k}$ is a sparse vector given by (\ref{e.u_j_k}),
and ${\bf v}_{j,red}$ is the parity-check (or called redundancy) block, and the subscript ``red'' stands for ``redundancy''.

In systematic form, the codewords of $m$ users can be arranged in an $m \times N$ codeword matrix
${\bf V} = [{\bf v}_1, {\bf v}_2, \ldots, {\bf v}_j, \ldots, {\bf v}_m]^{\mathrm T}$,
where $1 \le j \le J$ and $J = m$.
The codeword matrix ${\bf V}$ can be divided into two sub-matrices, ${\bf U}$ and ${\bf E}$, as shown in (\ref{e.TM_sparse}).


%\begin{figure*}[t]
\begin{small}
\begin{equation} \label{e.TM_sparse}
  \begin{aligned}
  {\bf V} =
  \left[
  \begin{matrix}
  {\bf v}_1 \\
  {\bf v}_2 \\
   \vdots   \\
  {\bf v}_{J} 
  \end{matrix}
  \right] = [
  {\bf U},{\bf E}
  ]
  =\left[
  \begin{array}{cccc:c}
  u_{1,0} & u_{1,1} & \ldots & u_{1,K-1} & \textcolor{blue}{{\bf v}_{1,red}}\\
  u_{2,0} & u_{2,1} & \ldots & u_{2,K-1} & \textcolor{blue}{{\bf v}_{2,red}}\\
  \vdots  & \vdots  & \ddots &  \vdots   & \vdots  \\
  u_{J,0} & u_{J,1} & \ldots & u_{J,K-1} & \textcolor{blue}{{\bf v}_{J,red}}\\
  \end{array}
  \right] 
  %&\overset{(a)}
  {=} 
  \left[
  \begin{array}{c:c:c:c}
    \textcolor{red}{b_{1,0}}, 0,\ldots,0    & \ldots & \textcolor{red}{b_{1,K-1}},0, \ldots, 0  & \textcolor{blue}{{\bf v}_{1,red}}\\
    0, \textcolor{red}{b_{2,0}}, \ldots, 0  & \ldots & 0, \textcolor{red}{b_{2,K-1}}, \ldots, 0 & \textcolor{blue}{{\bf v}_{2,red}}\\
    \vdots                 & \ddots &  \vdots                 & \vdots\\
    0, 0, \ldots, \textcolor{red}{b_{J,0}}  & \ldots & 0, 0, \ldots, \textcolor{red}{b_{J,K-1}} & \textcolor{blue}{{\bf v}_{J,red}}\\
  \end{array}
  \right].
  \end{aligned}
\end{equation}
\end{small}
%\hrulefill
%\end{figure*}




The sub-matrix ${\bf U}$ of ${\bf V}$ is a $1 \times K$ information array, i.e.,
${\bf U} = [{\bf U}_0, {\bf U}_1, \ldots, {\bf U}_k, \ldots, {\bf U}_{K-1}]$,
and ${\bf U}_k$ for $0 \le k < K$ is an $m \times m$ matrix.
When $J = m$, $J$ information bits $b_{1,k}, b_{2,k}, \ldots, b_{J,k}$ from the $J$ users are lying on the main diagonal of $ {\bf U}_k$.
When $J < m$, the $J$ information bits $b_{1,k}, b_{2,k}, \ldots, b_{J,k}$ are still lying on the main diagonal of ${\bf U}_k$, and the rest rows and/or columns of ${\bf U}_k$ are all zeros.
The sub-matrix ${\bf E}$ of ${\bf V}$ is a $J \times (N-Km)$ matrix which consists of all the parity-check bits formed based on the generator matrix.

To support massive users with short packet transmission scenario, $m$ may be very large. 
In this case, ${\bf V}$ is a sparse matrix, and we call ${\bf V}$ a \textit{sparse codeword matrix}.


Then, each codeword ${\bf v}_j$ is modulated with BPSK signaling and mapped to a complex-field signal sequence ${\bf x}_j \in {\mathbb C}^{1 \times N}$, i.e., 
${\bf x}_j = (x_{j,1}, x_{j,2}, \ldots, x_{j, n}, \ldots, x_{j, N-1})$. 
For $0 \le n < N$, the $n$-th component $x_{j, n}$ is given by
\begin{equation}  \label{e.x_j}
{x}_{j,n} = 2 {v}_{j,n} - 1,
\end{equation}
where $x_{j,n} \in \{-1, +1\}$. 
The mapping from ${\bf v}_j$ to ${\bf x}_j$ is regarded as 
\textit{finite-field to complex-field transform}, 
denoted by $\rm F_{F2C}$, i.e., ${x}_{j,n} = {\rm F}_{\rm F2C}(v_{j,n})$. 
Then ${\bf x}_j$ is sent to a GMAC. 


%\vspace{-0.15in}
\subsection{Receiver of a Sparse-form-based FFMA System}

At the receiving end, the received signal sequence ${\bf y} \in {\mathbb C}^{1 \times N}$ is the combined outputs of the $J$ users plus noise, i.e.,
%\vspace{-0.1in}
\begin{equation} 
{\bf y} = \sum_{j=1}^{J} {\bf x}_j + {\bf z} = {\bf r} + {\bf z},
\end{equation}
where ${\bf z} \in \mathbb{C}^{1 \times N}$ is an AWGN vector
with ${\mathcal N}(0, N_0/2)$.
The sum in ${\bf y}$ is called \textit{complex-field sum-pattern (CFSP)} signal sequence, i.e., ${\bf r} = (r_0, r_1, \ldots, r_n, \ldots, r_{N-1}) \in \mathbb{C}^{1 \times N}$, 
which is the sum of the $J$ modulated signal sequences ${\bf x}_1, {\bf x}_2,\ldots, {\bf x}_J$. 
For $0 \le n < N$, the $n$-th component $r_n$ of ${\bf r}$ is given by 
%$r_{n} = \sum_{j=1}^J x_{j,n} = 2 \sum_{j=1}^J v_{j,n} - J$.
\begin{equation} \label{e5.7}
    r_{n} = \sum_{j=1}^J x_{j,n} = 2 \sum_{j=1}^J v_{j,n} - J.              
\end{equation}

To separate the superposition signals, the classical method is to utilize \textit{multiuser interference cancellation} algorithms, e.g., SIC algorithm.
In our paper, we present another solution based on the USPM structural property of the UD-EP code $\Psi_{\rm B}$.
We only need to map each CFSP signal $r_n$ to a unique FFSP symbol $v_n$, i.e., $r_n \mapsto v_n$, and then the bit-sequences of $J$-user can be recovered by decoding the EP codeword.

Thus, the first step of the detection process is to transform the received CFSP signal sequence 
${\bf r} = (r_0, r_1, \ldots, r_n, \ldots, r_{N-1})$ into its corresponding FFSP codeword sequence 
${\bf v} = (v_0, v_1, \ldots, v_n, \ldots, v_{N-1})$ 
by a \textit{complex-field to finite-field (C2F)} transform function $\rm F_{C2F}$, 
i.e., ${v}_n = {\rm F_{C2F}}({r}_n)$ for $0 \le n < N$. 
It is important to find the transform function $\rm F_{C2F}$, otherwise, the system is ineffective.
It is able to find the following facts of the CFSP ${r}_n$ and FFSP ${v}_n$.
\begin{enumerate}
\item
The value of CFSP $r_{n}$ is determined by the number of users who send ``$+1$'' and the number of users who send ``$-1$''. Thus, the maximum and minimum values of $r_{n}$ are $J$ and $-J$, respectively. 
The set of $r_{n}$'s values in ascendant order is $\Omega_r = \{-J, -J+2, \ldots, J-2, J\}$, 
in which the difference between two adjacent values is $2$. 
The total number of $\Omega_r$ is equal to $|\Omega_r| = J+1$. 
\item
Since $v_{n} \in {\mathbb B}$, the possible values of $v_{n}$ are $(0)_2$ and $(1)_2$. 
Then, $v_{n}$ is uniquely determined by the number of $(1)_2$ bits coming from the $J$ users, 
i.e., $v_{1,n}, v_{2,n}, \ldots, v_{J,n}$. 
If there are odd number of bits $(1)_2$ from the $J$ users, i.e., $v_{1,n}, v_{2,n}, \ldots, v_{J,n}$, 
then $v_{n} = (1)_2$; otherwise, $v_{n} = (0)_2$. 
Since the values of $r_{n}$ are arranged in ascendant order, 
the corresponding FFSP set $\Omega_v$ of $\Omega_r$ is $\Omega_v = \{0, 1, 0, 1, \ldots\}$, 
in which $(0)_2$ and $(1)_2$ appear alternatively. 
The number of $|\Omega_v|$ is also equal to $J+1$, i.e., $|\Omega_v| = |\Omega_r|$.
\item
Let $C_J^\iota$ denote the number of users which send ``+1''. 
The values of $\iota$ are from $0$ to $J$. 
When $\iota = 0$, it indicates that all the $J$ users send $(0)_2$, 
i.e., $v_{j,n} = (0)_2$ for all $1 \le j \le J$, 
thus, $v_{n} = \bigoplus_{j=1}^J v_{j,n} = (0)_2$. 
If $\iota$ increases by one, the number of $(1)_2$ bits coming from $J$ users increases by one accordingly. Therefore, the difference between two adjacent values is $2$, and the bits $(0)_2$ and $(1)_2$ appear alternatively.
\end{enumerate}

%\vspace{-0.1in}
\begin{figure}[t] 
  \centering
  \label{Fig_MapTable}
  \includegraphics[width=0.7\textwidth]{Fig_MapTable.pdf}
 \caption{The relationship between CFSP sequence ${\bf r}$ and FFSP sequence ${\bf v}$ of a $J$-user FFMA system, where each user utilizes BPSK signaling.} \label{Fig_MapTable}
 \vspace{-0.15in}
\end{figure}


Based on the above facts, the transform function $\rm F_{C2F}$ maps each CFSP signal $r_{n}$ to a unique FFSP symbol $v_{n}$, i.e., ${\rm F_{C2F}}: r_{n} \mapsto v_{n}$. 
Assume that $v_{n} = (0)_2$ and $v_{n} = (1)_2$ are equally likely, 
i.e., ${\rm Pr}(v_{n}=0) = {\rm Pr}(v_{n} = 1) = 0.5$. 
Then, the probabilities of the elements in $\Omega_r$ are
 \begin{equation*} 
  {\mathcal P}_r = \left\{ {C_J^0}/{2^J}, {C_J^{1}}/{2^J},\ldots, {C_J^{J-1}}/{2^J}, {C_J^J}/{2^J} \right\}.
 \end{equation*} 
With $r_{n} \in \{-J, -J+2, \ldots, J-2, J\}$ and $v_{n} \in \{0,1\}$, 
$\rm F_{C2F}$ is a many-to-one mapping function, as summarized in Fig. \ref{Fig_MapTable}.



Next, we calculate the posterior probabilities used for decoding ${\bf y}$. 
Based on the relationship between $r_{n}$ and $v_{n}$, 
the conditional probability $v_{n}$ given by $y_{n}$ is

%\vspace{-0.05in}
%\begin{small}
\begin{equation} \label{e5.11}
  P(v_{n}|y_{n}) = \frac{{\rm Pr}(v_{n})P(y_{n}|v_{n})}{P(y_{n})} ,                   
\end{equation}
%\end{small}
%\vspace{-0.15in}
where $P(y_{n})$ is the probability of $y_{n}$.
Since $y_{n}$ is determined by $r_{n}$ that is selected from the set $\Omega_r$, thus,

%\vspace{-0.1in}
%\begin{small}
\begin{equation} \label{e_MAP}
  \begin{aligned}
  P(y_{n}) &= \sum_{\iota=0}^{J} {\mathcal P}_r(\iota) \cdot 
         \frac{1}{\sqrt{\pi N_0}} \exp \left\{
         - \frac{\left[y_{n} - \Omega_r(\iota) \right]^2}{N_0} 
         \right\},  \\
  \end{aligned}
\end{equation}
%\end{small}
%\vspace{-0.05in}
where ${\mathcal P}_r(\iota)$ and $\Omega_r(\iota)$ stand for the $\iota$-th element in the sets ${\mathcal P}_r$ and $\Omega_r$, respectively. 
When $v_{n} = (0)_2$, the corresponding $r_{n}$ equals to $\{-J, -J+4, -J+8, \ldots\}$. 
The posteriori probability of $v_{n} = (0)_2$ is

%\vspace{-0.15in}
%\begin{small}
\begin{equation}
  P(v_{n}=0|y_{n}) = \frac{1}{{P(y_{n})}} 
  \sum_{\iota=0,\iota+2}^{\iota \le J} {\mathcal P}_r(\iota)\cdot \frac{1}{\sqrt{\pi N_0}}
  \exp \left\{
  -\frac{\left[y_{n} - \Omega_r(\iota) \right]^2}{N_0}
  \right\},
\end{equation}
%\end{small}

%\vspace{-0.2in}
Similarly, when $v_{n} = (1)_2$, it indicates $r_{n}$ belongs to $\{-J+2, -J+6, -J+10,\ldots\}$, 
and the posteriori probability of $v_{n} = (1)_2$ is

%\vspace{-0.15in}
%\begin{small}
\begin{equation}
  P(v_{n}=1|y_{n}) = \frac{1}{{P(y_{n})}} 
  \sum_{\iota=1,\iota+2}^{\iota \le J} {\mathcal P}_r(\iota)\cdot \frac{1}{\sqrt{\pi N_0}}
  \exp \left\{
  -\frac{\left[y_{n} - \Omega_r(\iota) \right]^2}{N_0}
  \right\}.
\end{equation}
%\end{small}

%\vspace{-0.2in}
Then, $P(v_{n} = 0|y_{n})$ and $P(v_{n} = 1|y_{n})$ are used for decoding $\bf y$. 
If a binary LDPC code is utilized, we can directly calculate log-likelihood ratio (LLR) based on 
$P(v_{n} = 0|y_{n})$ and $P(v_{n} = 1|y_{n})$. 
If a NB-LDPC code is utilized, the probability mass function (pmf) can be computed based on 
$P(v_{n} = 0|y_{n})$ and $P(v_{n} = 1|y_{n})$.
When the generator matrix ${\bf G}_{gc,sym}$ in systematic form is utilized,
the decoded FFSP codeword sequence $\hat{\bf v}$ can be expressed as $\hat{\bf v} = ({\hat{\bf w}}, {\hat{\bf v}}_{red})$, where ${\hat{\bf w}}$ and ${\hat{\bf v}}_{red}$ are the detected FFSP sequence and parity-check block, respectively.

After removing the parity-check block ${\hat{\bf v}}_{red}$ from $\hat{\bf v}$, the detected FFSP sequence ${\hat{\bf w}}$ can be divided into $K$ FFSP blocks, and each block consists of $m$ bits formed an $m$-tuple,
i.e., ${\hat{\bf w}} = ({\hat w}_0, {\hat w}_1, \ldots, {\hat w}_k,\ldots, {\hat w}_{K-1})$, 
where ${\hat w}_k = ({\hat w}_{k,0}, {\hat w}_{k,1}, \ldots, {\hat w}_{k,i}, \ldots, {\hat w}_{k,m-1})$, with $0 \le k < K$ and $0 \le i < m$.
Finally, we separate the detected FFSP block ${\hat{w}}_k$ into $J$ bits as 
$\hat{b}_{1,k}, \hat{b}_{2,k}, \ldots, \hat{b}_{j,k}, \ldots, \hat{b}_{J,k}$ by using an \textit{inverse transform function} ${\rm F}_{q2{\rm B}}$.
According to (\ref{e.w_tdma}),
the inverse transform function ${\rm F}_{q2{\rm B}}$ is given as
%\vspace{-0.25in}
\begin{equation}
  {\hat b}_{j,k} = {\rm F}_{q2{\rm B}}({\hat w_k}) = {\hat w}_{k,j-1},
\end{equation}
%\vspace{-0.2in}
where ${\hat w}_{k,j-1}$ is the $(j-1)$-th component of ${\hat w}_k$. 
%and ${\hat w}_{k,j-1} \in {\mathbb B}$.

\begin{figure}[t] 
  \centering
    \label{Fig7}
  \includegraphics[width=0.9\textwidth]{Fig_MultiuserCode.pdf}
 \caption{A diagram of Example 5. Assume there are $J = 3$ users and each user transmit $K  = 3$ bits. The bit-sequences of the 3-user are respectively ${\bf b}_1 = (1, 1, 0)$, ${\bf b}_2 = (1, 0, 1)$, and ${\bf b}_3 = (0, 0, 1)$.}
\end{figure}


It is noted that, if there is no channel code ${\bf C}_{gc}$, $\Omega_r$ and ${\mathcal P}_r$ can be calculated in another manner.
Without a channel code, it means that ${\bf v}_j = {\bf u}_j$.
According to (\ref{e.u_j}) and (\ref{e.x_j}),
$r_n$ can be computed as follows:

%\vspace{-0.15in}
%\begin{small}
\begin{equation*}
r_{n} = \sum_{j=1}^{J} x_{j,n} = (2 b_{j-1,n} - 1) + \sum_{j' \neq j-1}^{J} (-1)
      = -J + 2 b_{j-1,n},
\end{equation*}
%\end{small}
where $0 \le n < N$ and $1 \le j \le J$.
If $b_{j-1,n}= (0)_2$, it is able to know the corresponding CFSP signal $r_n$ is $r_n = -J$;
otherwise, if $b_{j-1,n}= (1)_2$, then $r_n$ is equal to $r_n = -J+2$. 
Hence, the value set of CFSP ${\bf r}$ is $\Omega_r = \{-J, -J+2\}$, 
with equiprobability ${\mathcal P}_r = \{0.5, 0.5\}$.
The Euclidean distance between $-J$ and $-J+2$ is the same as that of BPSK modulation. 
Therefore, without channel coding, we can directly utilize BPSK demodulation to detect the CFSP signals.


Moreover, for the different forms of the generator ${\bf G}_{gc}$, we can further classify the probabilities set into two cases. 
For systematic encoding, we can separately compute the posteriori probabilities of the information symbols and the redundancy symbols, respectively. 
For non-systematic encoding, we can exploit the proposed $\Omega_r$ and ${\mathcal P}_r$, 
as shown in Fig. \ref{Fig_MapTable}.





\textbf{Example 5:}
In this example, we use an FFMA system over the field GF($2^4$) to illustrate the transmission and receiving process, as shown in Fig. 5. The field GF($2^4$) can support $4$ or fewer users. Suppose we design an FFMA system to support $J = 3$ users and each user transmits $K = 3$ bits.
The UD-EP code used is
  \begin{equation*}
    \Psi_{\rm B} = \{C_1^{\rm td}, C_2^{\rm td}, C_3^{\rm td} \},
  \end{equation*}
and the UD-EP assigned to the $j$-th user is $C_j^{\rm td}$. 
Let ${\bf b}_1 = (1, 1, 0)$, ${\bf b}_2 = (1, 0, 1)$ and ${\bf b}_3 = (0, 0, 1)$ be bit-sequences of the users $1, 2$, and $3$, respectively. 
The transmission process consists of three steps, ${\rm F}_{{\rm B}2q}$ mapping (or EP encoding), channel code encoding, and ${\rm F}_{\rm F2C}$ mapping (or BPSK modulation).


In the first step of transmission, each bit $b_{j,k}$ is mapped into a symbol $u_{j,k} = {\rm F}_{{\rm B}2q}(b_{j,k})$ which is represented by a $4$-tuple over GF($2$). The transform function ${\rm F}_{{\rm B}2q}$ maps the 3 bit-sequences into three symbol-sequences over GF($2^4$) in $4$-tuple form as follows:
%\vspace{-0.1in}
\begin{equation*} \label{e.Ex4_1}
  \begin{array}{c}
{\bf b}_1 = (1, 1, 0) \Rightarrow
{\bf u}_1 = (\textcolor{red}{1} 0 0 0, \textcolor{red}{1} 0 0 0, \textcolor{red}{0} 0 0 0)\\
{\bf b}_2 = (1, 0, 1) \Rightarrow
{\bf u}_2 = (0 \textcolor{red}{1} 0 0, 0 \textcolor{red}{0} 0 0, 0 \textcolor{red}{1} 0 0)\\
{\bf b}_3 = (0, 0, 1) \Rightarrow
{\bf u}_3 = (0 0 \textcolor{red}{0} 0, 0 0 \textcolor{red}{0} 0, 0 0 \textcolor{red}{1} 0)\\ 
  \end{array}.
\end{equation*}
The FFSP sequence of ${\bf u}_1$, ${\bf u}_2$, and ${\bf u}_3$ is 
\begin{equation*}
{\bf w} = \oplus_{j=1}^{3} {\bf u}_j = (1100, 1000, 0110),
\end{equation*}
which will be used at the receiving end to recover the $3$ transmitted bit-sequences.



In the second step of transmission process, each symbol-sequence ${\bf u}_j$ is encoded into a codeword 
${\bf v}_j = {\bf u}_j {\bf G}_{gc}$ in the channel code ${\bf C}_{gc}$. 
The channel code used is a $(16, 12)$ linear block code of length $16$ and dimension $12$ with the following generator matrix ${\bf G}_{gc}$ over GF($2$) in systematic form:

%\vspace{-0.1in}
%\begin{small}
\begin{equation*} \label{e.G}
  \begin{array}{ll}
  {\bf G}_{gc} = 
  \left[
  \begin{array}{cccccccccccc:cccc}
   1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
   0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\
   0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\
   0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
   0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
   0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
   0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\
   0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\
   0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\
   0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1 \\
   0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 0 \\
   0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 1 & 0 & 0 \\
  \end{array}
  \right].
  \end{array}
\end{equation*}
%\end{small}

%\vspace{-0.1in}
Hence, the three channel codewords are
%\vspace{-0.1in}
\begin{equation*}
  \begin{array}{c}
{\bf v}_1 = {\bf u}_1 \cdot {\bf G}_{gc}  =
(\textcolor{red}{1} 0 0 0, \textcolor{red}{1} 0 0 0, \textcolor{red}{0} 0 0 0, \textcolor{blue}{1 0 0 1})\\
{\bf v}_2 = {\bf u}_2 \cdot {\bf G}_{gc}  =
(0 \textcolor{red}{1} 0 0, 0 \textcolor{red}{0} 0 0, 0 \textcolor{red}{1} 0 0, \textcolor{blue}{0 1 0 1})\\
{\bf v}_3 = {\bf u}_3 \cdot {\bf G}_{gc}  =
(0 0 \textcolor{red}{0} 0, 0 0 \textcolor{red}{0} 0, 0 0 \textcolor{red}{1} 0, \textcolor{blue}{1 0 0 0})
  \end{array},
\end{equation*}
and the last $4$ bits of each codeword are parity-check bits.

Following, each channel codeword ${\bf v}_j$ is modulated with BPSK into a signal sequence ${\bf x}_j$ as follows:
%\vspace{-0.15in}
% \begin{small}
  \begin{equation*}
  \begin{array}{c}
{\bf v}_1  
%(\textcolor{red}{1} 0 0 0, \textcolor{red}{1} 0 0 0, \textcolor{red}{0} 0 0 0, \textcolor{blue}{1 0 0 1})
\Rightarrow
{\bf x}_1 = (+1, -1, -1, -1, +1, -1, -1, -1, -1, -1, -1, -1, +1, -1, -1, +1)\\
{\bf v}_2  
%(0 \textcolor{red}{1} 0 0, 0 \textcolor{red}{0} 0 0, 0 \textcolor{red}{1} 0 0, \textcolor{blue}{0 1 0 1})
\Rightarrow
{\bf x}_2 = (-1, +1, -1, -1, -1, -1, -1, -1, -1, +1, -1, -1, -1, +1, -1, +1)\\
{\bf v}_3  
%(0 0 \textcolor{red}{0} 0, 0 0 \textcolor{red}{0} 0, 0 0 \textcolor{red}{1} 0, \textcolor{blue}{1 0 0 0})
\Rightarrow
{\bf x}_3 = (-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, +1, -1, +1, -1, -1, -1)\\
  \end{array}.
  \end{equation*}
 % \end{small}

%\vspace{-0.1in}
Then, the three modulated signal sequences ${\bf x}_1$,  ${\bf x}_2$, and  ${\bf x}_3$ are sent to a GMAC.

At the receiving end, assuming no effect of noise, the process of recovering the transmitted bit-sequences consists of $3$ steps, namely ${\rm F}_{\rm C2F}$ mapping (or demodulation), channel decoding, and ${\rm F}_{q2{\rm B}}$ mapping (or EP decoding). In the first step of recovering process, the ${\rm F}_{\rm C2F}$ function transforms the received CFSP sequence,
%\vspace{-0.05in}
\begin{equation*}
  \begin{array}{c}
{\bf r} = \sum_{j=1}^{3} {\bf x}_j =   
  (-1, -1, -3, -3, -1, -3, -3, -3, -3, -1,  -1, -3,  +1, -1, -3, +1),
  \end{array}
\end{equation*}
to a FFSP codeword sequence $\hat{\bf v}$. 
For $J = 3$, we have $\Omega_r = \{-3, -1, +1, +3\}$ and $\Omega_v = \{0, 1, 0, 1\}$. 
Hence, ${\rm F_{C2F}}(-3) = (0)_2$, ${\rm F_{C2F}}(-1) = (1)_2$, ${\rm F_{C2F}}(+1) = (0)_2$, and ${\rm F_{C2F}}(+3) = (1)_2$.
This complex-field to finite-field transformation gives the following sequence:
  \begin{equation*}
  \hat{\bf v} = {\rm F_{C2F}}({\bf r}) = 
  (1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0).
  \end{equation*}
In the second step of recovering process, the receiver decodes the sequence $\hat{\bf v}$ based on a designed parity check matrix ${\bf H}_{gc}$ of the channel code ${\bf C}_{gc}$. 
Since no noise effect is assumed, the decoded FFSP sequence is given as
\begin{equation*}
  \hat{\bf w} = (1100, 1000, 0110),
\end{equation*}
which has been divided into $K = 3$ blocks, each block consisting of $4$ bits formed an $4$-tuple.


In the third step of the receiving process, decode the FFSP sequence $\hat{\bf w}$ by using the inverse transform function ${\rm F}_{q2{\rm B}}$. Decoding recovers the transmitted bit-sequences as
% \vspace{-0.07in}
 \begin{equation*} 
  \begin{array}{c}
  \hat{\bf b}_1 = (1, 1, 0), \quad
  \hat{\bf b}_2 = (1, 0, 1), \quad
  \hat{\bf b}_3 = (0, 0, 1).
  \end{array}
\end{equation*}

%In above, we assume that there is no noise effect during the transmission over the GMAC. 
If transmission is affected by noise, the channel decoder has to perform error-correction process in the second step to estimate the transmitted sequences. 
$\blacktriangle \blacktriangle$


\begin{figure}[t]
  \centering
  \includegraphics[width=0.5\textwidth]{Fig_TimeSlots.pdf}
  \caption{A diagram of the sparse-form-based and diagonal-form-based FFMA systems, where $m=4$, $K = 3$ and a $(16, 12)$ channel code ${\bf C}_{gc}$ used.} \label{Fig_TimeSlots}
%  \vspace{-0.2in}
\end{figure}


%\vspace{-0.2in}
\subsection{A Diagonal-form-based FFMA System}

As presented early, if the generator ${\bf G}_{gc}$ is constructed over GF($2$) and in systemic form,
we can obtain the \textit{sparse form codeword matrix} ${\bf V}$, as shown in (\ref{e.TM_sparse}).
For the $1 \times K$ information array ${\bf U}$ of ${\bf V}$,
each entry ${\bf U}_k$ of ${\bf U}$ is an $m \times m$ matrix, and the $m$ information bits $b_{1,k}, b_{2,k}, \ldots, b_{j,k}, \ldots, b_{m,k}$ are located on the main diagonal of $ {\bf U}_k$, 
and the other locations are all $0$s,
where $0 \le k < K$ and $1 \le j \le J \le m$.

Permuting the columns of the $1 \times K$ information array ${\bf U}$ of ${\bf V}$ and rearranging the bit sequences, we can obtain an $m \times m$ information array ${\bf U}_{\rm D}$,
in which ${\bf b}_1, {\bf b}_2, \ldots, {\bf b}_j,\ldots, {\bf b}_{m}$ are lying on the main diagonal of ${\bf U}_{\rm D}$ and the other entries are all $\bf 0$s, given by
\begin{equation}
  {\bf U}_{\rm D} =
  \left[
  \begin{array}{cc}
  {\bf u}_{1, \rm D} \\
  {\bf u}_{2, \rm D} \\
   \vdots   \\
  {\bf u}_{m, \rm D} 
  \end{array}
  \right]
  =
  \left[
  \begin{array}{cccc}
    {\bf b}_1 &           &        &            \\
              & {\bf b}_2 &        &            \\
              &           & \ddots &            \\
              &           &        & {\bf b}_m  \\
 
  \end{array}
  \right],
\end{equation}
where ${\bf b}_1, {\bf b}_2, \ldots, {\bf b}_j,\ldots, {\bf b}_{m}$ are $1 \times K$ vectors,
and the subscript ``D'' stands for ``diagonal''.
Let ${\bf u}_{j, \rm D}$ denote as a $1 \times mK$ information sequence of the $j$-th user, 
i.e., ${\bf u}_{j, \rm D} = ({\bf 0}, \ldots, {\bf 0}, {\bf b}_j, {\bf 0}, \ldots, {\bf 0})$,
in which the $1 \times K$ bit-sequence of the $j$-th user ${\bf b}_j$ is located at the $(j-1)$-th entry of ${\bf u}_{j, \rm D}$ and ${\bf 0}$ is a $1 \times K$ zero vector.
Note that, if $J < m$, the $(m-J)$ rightmost entries of ${\bf U}_{\rm D}$ are all zeros, 
forming an $(m-J) \times (m-J)K$ zero matrix.


Then, we encode ${\bf u}_{j, \rm D}$ by the generator matrix ${\bf G}_{gc, sym}$ in systemic form, and obtain the codeword ${\bf v}_{j,\rm D}$ of ${\bf u}_{j, \rm D}$, i.e., 
${\bf v}_{j, \rm D} = ({\bf u}_{j,\rm D}, \textcolor{blue}{{\bf v}_{j,red,\rm D}})$,
where ${\bf v}_{j,red,\rm D}$ is the parity-check block of ${\bf v}_{j, \rm D}$,
which is a $(N-mK)$-tuple.
The codewords of ${\bf v}_{1,\rm D}, {\bf v}_{2,\rm D}, \ldots, {\bf v}_{J,\rm D}$ together can form a \textit{diagonal form} codeword matrix ${\bf V}_{\rm D}$, given as follows:
%\begin{small}
\begin{equation}
  {\bf V}_{\rm D} =
  \left[
  \begin{array}{cc}
  {\bf v}_{1, {\rm D}} \\
  {\bf v}_{2, {\rm D}} \\
   \vdots   \\
 % {\bf v}_j \\
 %  \vdots   \\
  {\bf v}_{m, {\rm D}} 
  \end{array}
  \right]
 % = \left[{\bf U}_D, {\bf E}_D \right]
  =
 % \left[{\bf U}_{\rm D}, {\bf E}_{\rm D}\right]=
  \left[
  \begin{array}{cccc:c}
    {\bf b}_1 &           &        &             & \textcolor{blue}{{\bf v}_{1, red, {\rm D}}}\\
              & {\bf b}_2 &        &             & \textcolor{blue}{{\bf v}_{2, red, {\rm D}}}\\
              &           & \ddots &             & \vdots\\
              &           &        & {\bf b}_m   & \textcolor{blue}{{\bf v}_{m, red, {\rm D}}}\\
 
  \end{array}
  \right],
\end{equation}
%\end{small}
consisting of an $m \times m$ information array ${\bf U}_{\rm D}$ and an $m \times 1$ parity-check array ${\bf E}_{\rm D}$, where ${\bf E}_{\rm D} = [{\bf v}_{1,red,{\rm D}}, {\bf v}_{2,red,{\rm D}}, \ldots, {\bf v}_{m,red,{\rm D}}]^{\rm T}$.


From the codeword ${\bf v}_{j,\rm D}$, it is found that the useful vectors 
(i.e., ${\bf b}_j$ and ${\bf v}_{j,red,{\rm D}}$) 
are only located at the $(j-1)$-th entry of ${\bf u}_{j, {\rm D}}$ and the parity-check entry ${\bf v}_{j,red, {\rm D}}$, and the other entries are all zeros.
Thus, for the diagonal-form-based codeword ${\bf v}_{j, {\rm D}}$, we can directly modulate and transmit the shorten codeword, defined by ${\bf v}_{j,{\rm D,S}} = [{\bf b}_j, {\bf v}_{j,red, \rm D}]$, 
instead of ${\bf v}_{j,{\rm D}}$, to reduce the transmit power.
The subscript ``S'' indicates ``shorten''.
The codeword length of ${\bf v}_{j,{\rm D, S}}$ is equal to $N - (m-1)K$.
For a short packet transmission, e.g., $K$ is an extremely small number, 
the length of ${\bf v}_{j,{\rm D, S}}$ is approximately equal to the length of parity-check block ${\bf v}_{j,red,{\rm D}}$.




Note that, the permuting and rearranging operations do not affect the properties of FFMA system.
Actually, the diagonal-form-based FFMA is a special case of the sparse-form-based FFMA.
Hence, the diagonal-form-based FFMA system can be decoded like the aforementioned sparse-form-based FFMA system. A diagram of the diagonal-form-based FFMA system is shown in Fig. \ref{Fig_TimeSlots}, which is similarly to the TDMA system.


For an FFMA system in diagonal form, the bit-sequences of $J$ users are transmitted in orthogonal mode and the $J$ parity-check sequences are appended to them.
Obviously, the diagonal-form-based FFMA system is appealing for the massive users with short data packet transmission scenario, which can solve the FBL limitation and obtain a large coding gain from all the massive users with a low-complexity decoder.





%\vspace{-0.15in}
\section{An FFMA System for a Digital network scenario}
In this section, we present FFMA systems for a digital network scenario.
Since AIEPs consist of integers, elements from a prime field GF($p$) or powers of a primitive element from an extension field GF($p^m$) of a prime field GF($p$), they are naturally suitable for applications in a digital network.
The AIEPs can be viewed as virtual resources, and an AIEP forms a \textit{virtual resource block (VRB)}.
Before we present our proposed FFMA systems based on AIEPs, we relook some of the properties of AIEPs developed in Sections II and III. 

As shown in Section II, 
for a prime field GF($p$) with $p > 2$, we can construct an AIEP code 
${\Psi}_{\rm s} = C_1^{\rm s} \times \ldots \times C_l^{\rm s} \ldots \times C_L^{\rm s}$ 
with $C_l^{\rm s} = (l, p-1)$ which is the $l$-th AIEP of the AIEP code ${\Psi}_{\rm s}$.
Each AIEP $C_l^{\rm s}$ forms a VRB and the number $L$ of VRBs in ${\Psi}_{\rm s}$ is determined by the designed FFMM for an AIEP code.
If ${\Psi}_{\rm s}$ is an UD-AIEP code, the number $L$ of VRBs is at most $L = \log_2(p-1)$.
If ${\Psi}_{\rm s}$ is an AIEP code without USPM structural property, then $L$ is at most $(p-1)/2$.
In this case, VRBs in an AIEP code ${\Psi}_{\rm s}$ only depends on the parameter $p$, 
which is called \textit{prime factor (PF)}.


For an extension field GF($2^m$) with $m > 1$, 
we can construct an $m$-dimension orthogonal UD-EP code ${\Psi}_{\rm B}$, 
i.e., ${\Psi}_{\rm B} = \{C_{1}^{\rm td}, \ldots, C_{i+1}^{\rm td}, \ldots, C_{m}^{\rm td}\}$. 
%where $C_{i+1}^{\rm td} = \alpha^{i} \cdot C_{\rm B}$ and $0 \le i < m$.
The difference between UD-EPs in ${\Psi}_{\rm B}$ is determined by the location $i$.
Thus, we denote the location $i$ of $\alpha^{i} \cdot C_{\rm B}$ as a VRB.
The number of VRBs is equal to $m$, which is called \textit{extension factor (EF)}.


For an extension field GF($p^m$) with $p > 2$ and $m > 1$, 
an $m$-dimension orthogonal AIEP code $\Psi_{\rm o}$, i.e., $\Psi_{\rm o} = \{\Psi_{{\rm o},0}, \Psi_{{\rm o},1}, \ldots, \Psi_{{\rm o},i}, \ldots, \Psi_{{\rm o},m-1}\}$, 
is an $m$-dimension orthogonal AIEP code over GF($p$) in which each $\alpha^i \cdot C_l^{\rm s}$ of 
$\Psi_{{\rm o},i} = \{\alpha^i \cdot C_1^{\rm s}, \alpha^i \cdot C_2^{\rm s}, \ldots,  \alpha^i \cdot C_l^{\rm s},\ldots, \alpha^i \cdot C_L^{\rm s}\}$ is an AIEP over GF($p$). 
An $m$-dimension orthogonal AIEP code $\Psi_{\rm o}$ may be viewed as a two concatenated code, including both the EP code $\Psi_{\rm B}$ constructed over GF($2^m$) and the AIEP code ${\Psi}_{\rm s}$ constructed over GF($p$). 
%Thus, an AIEP $\psi_i(C_l)$ in $\Psi$ is determined by both the location $i$ and the AIEP $C_l$. 
The number of VRBs of the finite-field GF($p^m$) is equal to $m \cdot L$.


%\vspace{-0.1in}
\begin{figure}[t]
  \centering
  \includegraphics[width=0.9\textwidth]{Fig_NetFFMA.pdf}
  \caption{A diagram of a network FFMA system for a pure digital network scenario over a DSC.} \label{Fig_NetFFMA}
%  \vspace{-0.1in}
\end{figure}

%\vspace{-0.2in}
\subsection{An overview of FFMA systems} 
Commonly known MA systems are complex-field (CF) MA (CFMA) systems in which physical RBs, such as time, frequency, and other types, are used to distinguish users, and different users are assigned with different RBs.
The basic components of a physical CFMA system are a source encoder, a channel encoder, a modulation module, and a CF multiplex module determined by the physical RBs. 



In the proposed FFMA system for network communications, each user is assigned with an AIEP (or multiple AIEPs) as VRB(s), and the users are distinguished by using AIEPs over finite-fields. 
An AIEP encoder plays a role as a type of mapping function, as introduced in Section III. 
In a network FFMA system, the basic components are a source encoder, an AIEP encoder, a channel encoder, and an FFMM. The FFMM combines the $J$ transmitted symbols, $u_1,u_2,\ldots,u_J$, and forms an FFSP $w$ which is then passed to the physical transmission system. When the receiver receives the transmitted FFSP codewords correctly, the $J$ transmitted symbols can be uniquely recovered without ambiguity. 


The core issue in an FFMA system is to establish transforms between different fields, especially, transform from \textit{finite-field symbol(s) to complex-field signal(s)}, and transform from \textit{complex-field signal(s) to finite-field symbol(s)}. 
If proper mapping functions ${\rm F}_{\rm F2C}$ and ${\rm F}_{\rm C2F}$ are used, the MA design issue can be moved to the finite-field, and the physical-layer plays as a ``physical road''. 
If the network FFMA system is viewed as a unified module, the transmitter and receiver of the network FFMA system can be regarded as \textit{equivalent source} and \textit{equivalent destination}, respectively.

   

The proposed FFMA can be used in conjunction with CFMA in an MA system. Such an MA system is called a \textit{fusion} MA systems. 
In this case, the FFMA is operated at network layer (or called \textit{network FFMA}), and the CFMA works at physical layer.    



%\begin{figure}[t]
%  \centering
%  \includegraphics[width=0.99\textwidth]{Fig_FFandCF.pdf}
%  \caption{A diagram of a fusion MA system, including both network FFMA and physical CFMA.} \label{Fig_FFandCF}
%\end{figure}


%\vspace{-0.1in}
\subsection{A Network FFMA over GF($p^m$) System}
In the following, we present a network FFMA over GF($p^m$) system for a digital network.
%, as shown in Fig. \ref{Fig_NetFFMA}.
Suppose the system is designed to support $J$ users. 
We choose an orthogonal AIEP code $\Psi_{\rm o} = \{\Psi_{{\rm o},0}, \Psi_{{\rm o},1}, \ldots, \Psi_{{\rm o},i}, \ldots, \Psi_{{\rm o},m-1}\}$. 
Assume the $j$-th user is assigned the AIEP $\alpha^i \cdot C_l^{\rm s}$, 
i.e.,
\begin{equation*}
\alpha^i \cdot C_l^{\rm s} = \{(0, 0, \ldots, l, 0, \ldots, 0), (0, 0, \ldots, p-l, 0, \ldots, 0)\},
\end{equation*}
where $0 \le i < m$, $1 \le l \le L=(p-1)/2$ and $J \le m \cdot L$.



The transceiver of the proposed network FFMA mainly depends on different encoders.
This paper utilizes a \textit{finite-field multiuser channel code}, which is a joint design of an orthogonal AIEP code and a linear block channel code.




\subsubsection{Transmitter}
Let ${\bf b}_j = (b_{j,0}, b_{j,1}, \ldots, b_{j,k},\ldots, b_{j,K-1})$ be the bit-sequence at the output of user-$j$, where $b_{j,k} \in {\mathbb B}$ and $0 \le k < K$. 
Based on the orthogonal UD-EP code $\Psi_{\rm B}$, we first encode the bit-sequence ${\bf b}_j$ by using the ${\rm F}_{{\rm B}2q}$ transform function,
i.e., $u_{j,k} = {\rm F}_{{\rm B}2q}(b_{j,k})$, into a symbol-sequence ${\bf u}_j$ over GF($2^m$).
Next, the symbol-sequence ${\bf u}_j$ is encoded by a binary linear block code ${\bf C}_{gc}$ into a binary codeword ${\bf v}_j = (v_{j,0}, v_{j,1},\ldots, v_{j,n}, \ldots, v_{j,N-1})$, where $v_{j,n} \in {\mathbb B}$ and $0 \le n < N$. The encoding process of $\Psi_{\rm B}$ and ${\bf C}_{gc}$ are the same as the process in Section IV.
The overall encoding may be viewed as a two-level concatenated encoding, with the EP encoding as the inner encoding and the block code ${\bf C}_{gc}$ encoding as the outer encoding.
We refer this encoding as $\Psi_{\rm B}$/${\bf G}_{gc}$-encoding.


After $\Psi_{\rm B}$/${\bf G}_{gc}$-encoding, 
we cluster the codewords ${\bf v}_j$ into $L$ groups.
If the users $j_1, j_2, \ldots, j_{c_l}$ are assigned to the same AIEP $C_l^{\rm s}$ in $\Psi_{\rm s}$ but at different locations in $\Psi_{\rm B}$, i.e., $\alpha^i \cdot C_l^{\rm s}$ for $0 \le i < m$, the codewords of the users $j_1, j_2, \ldots, j_{c_l}$ are clustered into one group, i.e., 
${\bf V}_{c_l} = \{ {\bf v}_{j_1}, {\bf v}_{j_2}, \ldots, {\bf v}_{j_{c_l}}\}$.
The FFSP of the codewords in ${\bf V}_{c_l}$ is 
%\vspace{-0.1in}
%\begin{small}
\begin{equation*}
{\bf v}_{c_l} = \bigoplus_{j \in {\bf V}_{c_l}} {\bf v}_j 
= {\bf v}_{j_1} \oplus {\bf v}_{j_2} \oplus \ldots \oplus {\bf v}_{j_{c_l}},
\end{equation*}
%\end{small}
%\vspace{-0.1in}
where the subscript $l$ of ``$c_l$'' is ranged from $1 \le l \le L$,
and ${\bf v}_{c_l} = (v_{c_l,0}, v_{c_l,1}, \ldots, v_{c_l,n}, \ldots, v_{c_l,N-1})$.

The $L$ FFSP codewords ${\bf v}_{c_1}, {\bf v}_{c_2}, \ldots, {\bf v}_{c_L}$ correspond to the $L$ AIEPs in $\Psi_{\rm s}$.
Then, each component $v_{c_l,n}$ in ${\bf v}_{c_l}$ is mapped into an element $s_{c_l,n}$ in $C_l$,
i.e., $s_{c_l,n} = {\rm F}_{{\rm B}2q}(v_{c_l,n})$, given by
\begin{equation}
  s_{c_l,n} = \left\{
    \begin{matrix}
      (l)_p,   & v_{c_l,n} = (0)_2 \\
      (p-l)_p, & v_{c_l,n} = (1)_2 \\
    \end{matrix}
    \right.
\end{equation}
where $C_l^{\rm s} = (l, p-l)$ is an AIEP of $\Psi_{\rm s}$.
The mapping ${\rm F}_{{\rm B}2q}$ of the components of ${\bf v}_{c_l}$ results in a sequence
${\bf s}_{c_l} = (s_{c_l,0}, s_{c_l,1}, \ldots, s_{c_l,n}, \ldots, s_{c_l,N-1})$ over GF($p$).
Next, the $L$ sequences ${\bf s}_{c_1}, {\bf s}_{c_2}, \ldots, {\bf s}_{c_L}$ 
are multiplexed into a sequence ${\bf x} = (x_0, x_1, \ldots, x_{N-1})$ over GF($p$) by the FFMM ${\mathcal A}_{\rm M}$. 
If ${\Psi}_{\rm s}$ is an UD-AIEP code, ${\mathcal A}_{\rm M}$ is a finite-field addition operation, 
where $x_n = \bigoplus_{l=1}^{L} s_{c_l, n}$ and $x_n \in {\rm GF}(p)\backslash \{0\}$. 
If ${\Psi}_{\rm s}$ is not an UD-AIEP code, we should design ${\mathcal A}_{\rm M}$ for different finite-fields, e.g., C-UDCs method.
The multiplexed sequence $\bf x$ is a sequence of FFSPs of the orthogonal AIEP code $\Psi_{\rm o}$ over GF($p^m$), which will be transmitted to the discrete channel.



\subsubsection{Receiver}
In this paper, the proposed FFMA system is used for transmission over a discrete symmetric channel (DSC).
Thus, the input and output discrete digits of the DSC are both from ${\rm GF}(p)\backslash \{0\} = \{1, 2, \ldots, p-1\}$. 

Let ${\bf y} = (y_0, y_1, \ldots, y_n, \ldots, y_{N-1})$ be the received sequence, where $y_n \in {\rm GF}(p)\backslash \{0\}$. The transition probability of the DSC is defined as
\begin{equation}
  P(y_n|x_n) = \left\{
  \begin{matrix}
    \beta,           & y_n \neq x_n\\
    1 - (p-2)\beta,  & y_n = x_n\\
  \end{matrix},
  \right.
\end{equation}
where $\beta$ is decided by the practical physical channel.



To recover the transmit bit-sequences, we first recover the sequences ${\bf w}_{c_1}, {\bf w}_{c_2}, \ldots, {\bf w}_{c_L}$ of the $L$ groups from ${\bf r}$ by lookup FFSP decoding tables, e.g., Figs. 1 and 2.
Then, the AIEP coded sequences ${\bf s}_{c_1}, {\bf s}_{c_2}, \ldots, {\bf s}_{c_L}$ are decoded through the inverse function of ${\rm F}_{{\rm B}2q}$, denoted by ${\rm F}_{q2{\rm B}}$, 
i.e., ${\bf v}_{c_l} = {\rm F}_{q2{\rm B}}({\bf s}_{c_l})$,
to obtain the binary codewords ${\bf v}_{c_1}, {\bf v}_{c_2}, \ldots, {\bf v}_{c_L}$.
Next, channel decoding is performed on the codewords ${\bf v}_{c_1}, {\bf v}_{c_2}, \ldots, {\bf v}_{c_L}$,
to obtain the sequences ${\bf u}_{c_1}, {\bf u}_{c_2}, \ldots, {\bf u}_{c_L}$.
Through decoding the UD-AIEP code $\Psi_{\rm B}$, we recover all the transmit bit-sequences ${\bf b}_j$.
The decoding process is similarly to that presented in Section IV.



\textbf{Example 6:} 
In Example 3, we showed that a total $8$ UD-AIEPs can be construct based on the field GF($5^4$). Suppose we want to design an FFMA system to support $J = 4$ users, and each user transmits $K = 3$ at a time. Suppose user-$1$, user-$2$, user-$3$, and user-$4$ are respectively assigned the UD-AIEPs $\alpha^0 \cdot C_1^{\rm s}$, $\alpha^1 \cdot C_1^{\rm s}$, $\alpha^2 \cdot C_1^{\rm s}$, and $\alpha^0 \cdot C_2^{\rm s}$. 
With the above assignment, user-$1$, user-$2$ and user-$3$ have the same AIEP $C_1^{\rm s}=\left(1,4\right)$ of $\Psi_{\rm s}$, but are with different AIEPs of $\Psi_{\rm B}$ (e.g., $i=0, i=1$ and $i=2$) to distinct users. In addition, user-$1$ and user-$4$ have the same AIEP of $\Psi_{\rm B}$ (e.g., $i=0$), but are with different AIEPs of $\Psi_{\rm s}$ (e.g., $C_1^{\rm s}$ and $C_2^{\rm s}$), thus user-$1$ and user-$4$ can be separated. 

For channel coding, we use the $(16, 12)$ linear block code ${\bf C}_{gc}$ whose generator matrix ${\bf G}_{gc}$ has been given in Example 5. Let ${\bf b}_1 = (1, 1, 0)$, ${\bf b}_2 = (1, 0, 1)$, ${\bf b}_3 = (0, 0, 1)$, and ${\bf b}_4 = (0, 1, 0)$ be bit-sequences to be transmitted by the $4$ users, respectively. Transmission of these $4$ bit-sequences consists of $4$ steps.


In the first step, each bit $b_{j,k}$ is encoded by UD-AIEP code $\Psi_{\rm B}$ into a symbol $u_{j,k} = {\rm F}_{{\rm B}2q}(b_{j,k})$. Then, encode the symbol-sequence ${\bf u}_j$ into a codeword in the channel code ${\bf C}_{gc}$, i.e., ${\bf v}_{j} = {\bf u}_j \cdot {\bf G}_{gc}$ as shown below.
%  \begin{small}
%  \vspace{-0.15in}
  \begin{equation*} \label{e.Ex7_1}
  \begin{array}{ll}
  \alpha^0 \cdot C_1^{\rm s}: {\bf b}_1 = (1, 1, 0) &\Rightarrow
  {\bf u}_1 = (\textcolor{red}{1} 0 0 0, \textcolor{red}{1} 0 0 0, \textcolor{red}{0} 0 0 0) \\
  &\Rightarrow 
  {\bf v}_1 = {\bf u}_1 \cdot {\bf G}  =
  (\textcolor{red}{1} 0 0 0, \textcolor{red}{1} 0 0 0, \textcolor{red}{0} 0 0 0, \textcolor{blue}{1 0 0 1})
  \\
  \alpha^1 \cdot C_1^{\rm s}: {\bf b}_2 = (1, 0, 1) &\Rightarrow
  {\bf u}_2 = (0 \textcolor{red}{1} 0 0, 0 \textcolor{red}{0} 0 0, 0 \textcolor{red}{1} 0 0) \\
  &\Rightarrow 
  {\bf v}_2 = {\bf u}_2 \cdot {\bf G}  =
  (0 \textcolor{red}{1} 0 0, 0 \textcolor{red}{0} 0 0, 0 \textcolor{red}{1} 0 0, \textcolor{blue}{0 1 0 1})
  \\
  \alpha^2 \cdot C_1^{\rm s}: {\bf b}_3 = (0, 0, 1) &\Rightarrow
  {\bf u}_3 = (0 0 \textcolor{red}{0} 0, 0 0 \textcolor{red}{0} 0, 0 0 \textcolor{red}{1} 0) \\
  &\Rightarrow 
  {\bf v}_3 = {\bf u}_3 \cdot {\bf G}  =
  (0 0 \textcolor{red}{0} 0, 0 0 \textcolor{red}{0} 0, 0 0 \textcolor{red}{1} 0, \textcolor{blue}{1 0 0 0})
  \\
  \hdashline
  \alpha^0 \cdot C_2^{\rm s}: {\bf b}_4 = (0, 1, 0) &\Rightarrow
  {\bf u}_4 = (\textcolor{red}{0} 0 0 0, \textcolor{red}{1} 0 0 0, \textcolor{red}{0} 0 0 0) \\
  &\Rightarrow 
   {\bf v}_4 = {\bf u}_1 \cdot {\bf G}  =
  (\textcolor{red}{0} 0 0 0, \textcolor{red}{1} 0 0 0, \textcolor{red}{0} 0 0 0, \textcolor{blue}{0 0 0 1})
  \\  
  \end{array}.
  \end{equation*}
%  \vspace{-0.15in}
%  \end{small}
 
In the second step, we cluster the codewords ${\bf v}_j$ into ${\bf V}_{c_1} =\{{\bf v}_1, {\bf v}_2, {\bf v}_3 \}$ and ${\bf V}_{c_2} =\left\{ {\bf v}_4 \right\}$, and compute the FFSPs ${\bf v}_{c_1}$ and ${\bf v}_{c_2}$ of the codewords in ${\bf V}_{c_1}$ and ${\bf V}_{c_2}$, as follows:
%\vspace{-0.05in}
% \begin{small}
  \begin{equation*}
   \begin{aligned}
   {\bf v}_{c_1} &= \bigoplus_{j=1}^{3} {\bf v}_j = (1 1 0 0, 1 0 0 0, 0 1 1 0, 0 1 0 0), \\
   {\bf v}_{c_2} &= {\bf v}_4 = ({0} 0 0 0, {1} 0 0 0, {0} 0 0 0, {0 0 0 1}).\\
    \end{aligned}
  \end{equation*}
%\end{small}

%\vspace{-0.1in}
Next, we encode ${\bf v}_{c_1}$ and ${\bf v}_{c_2}$ by the AIEPs $C_1^{\rm s}$ and $C_2^{\rm s}$, i.e., ${\bf s}_{c_1} = {\rm F}_{{\rm B}2q}({\bf v}_{c_1})$ and ${\bf s}_{c_2} = {\rm F}_{{\rm B}2q}({\bf v}_{c_2})$ as shown below.
%\vspace{-0.05in}
  \begin{equation*}
   \begin{aligned}
  {\bf s}_{c_1} = (4 4 1 1, 4 1 1 1, 1 4 4 1, 1 4 1 1)_5,\\
  {\bf s}_{c_2} = (2 2 2 2, 3 2 2 2, 2 2 2 2, 2 2 2 3)_5.\\
    \end{aligned}
  \end{equation*}
%\vspace{-0.1in}
Following, we multiplex ${\bf s}_{c_1}$ and ${\bf s}_{c_2}$ into the sequence ${\bf x}$,
%\vspace{-0.07in}
  \begin{equation*}
    {\bf x} = {\bf s}_{c_1} \oplus {\bf s}_{c_2} = (1 1 3 3, 2 3 3 3, 3 1 1 3, 3 1 3 4)_5.
  \end{equation*}
Then, the multiplexed sequence ${\bf x}$ is transmitted.

At the receiving end, through the FFSP decoding table given by Fig. 1, we can recover ${\bf s}_{c_1}$ and ${\bf s}_{c_2}$ from ${\bf x}$. Then, do opposite operations of the transmitter, the bit-sequences can be recovered. $\blacktriangle  \blacktriangle$




%\vspace{-0.1in}
\section{Simulation results}

In this section, we show the PUER performances of our proposed FFMA systems.
Since ${\bf b}_j \in {\mathbb B}^{1 \times K}$ for $1 \le j \le J$, the PUER of the proposed FFMA system is defined by
\begin{equation}
P_{e,u} = \frac{1}{J \cdot K} \sum_{j=1}^{J} \sum_{k=0}^{K-1} {\mathbb P}[{b}_{j,k} \neq \hat {b}_{j,k}].
\end{equation}
When there is only one user, i.e., $J=1$, the PUER performance is equivalent to the BER (bit error rate) performance. 
For the proposed FFMA systems in a GMAC, the PUER performances are shown in Figs. 8 and 9,
and the PUER performances of the network FFMA in a DSC are shown in Fig. 10.

%\begin{figure}[t!]
%  \centering
%  \subfigure[\label{fig:a}][PUER in a GMAC.]{
%    \includegraphics[scale=0.12]{Graph_NB.pdf}}
%  \subfigure[\label{fig:b}][PUER in a GMAC.]{
%    \includegraphics[scale=0.12]{Graph_FFMA_TDMA.pdf} } 
%  \subfigure[\label{fig:c}][PUER in a DSC.]{
%    \includegraphics[scale=0.12]{Graph_Net.pdf}}
%  \caption{Simulation results of the proposed FFMA systems. 
%  (a) PUER performance of the FFMA over GF($2^4$) in a GMAC, where $J = 1, 2, 3, 4$ and a $16$-ary $(864, 576)$ NB-LDPC code ${\bf C}_{gc, q}$ is used for error control. 
%  (b) PUER performances of different systems in a GMAC. The sparse-form-based and diagonal-form-based FFMA-TDMA systems are used a binary $(6000, 3000)$ LDPC code ${\bf C}_{gc}$ for error control, and the classical TDMA system utilizes repetition code for error control, where $N = 6000$, $K = 10$ bits, and $J = 1, 100, 300$ for comparisons. 
%  (c) PUER performance of the network FFMA system in a DSC. } \label{Fig_Simulation}
%  \vspace{-0.2in}
%\end{figure}

\begin{figure}[t]
  \centering
  \includegraphics[width=0.5\textwidth]{Graph_NB.pdf}
  \caption{PUER performance of the sparse-form-based FFMA over GF($2^4$) in a GMAC, where $J = 1, 2, 3, 4$ and a $16$-ary $(864, 576)$ NB-LDPC code ${\bf C}_{gc, q}$ is used for error control. The data rate is decided by ${\bf C}_{gc, q}$ and fixed as ${2}/{3}$. }
  \vspace{-0.15in}
\end{figure}



Fig. 8 shows the PUER performance of the sparse-form-based FFMA system over GF($2^4$) in a GMAC, which includes both systematic and non-systematic forms of the generator matrix of a $16$-ary $(864, 576)$ NB-LDPC code ${\bf C}_{gc, q}$ over GF($2^4$).
The horizontal coordinate-axis is the ratio of energy-per-bit $E_b$ to noise power spectral density $N_0$, i.e., $E_b/N_0$. During the simulation, the data rate is decided by ${\bf C}_{gc, q}$ and fixed as $2/3$. 
An orthogonal UD-EP code $\Psi_{\rm B}$ is constructed over GF($2^4$), so that the system can support up to $4$ users. In simulating the error performance of the system, decoding is carried out with $50$ iterations of the FFT-QSPA \cite{LinBook3}.  
Note that for $J = 1$ (the single-user case), the BER performance of the system is simply bit-error performance of the $16$-ary $(864,576)$ NB-LDPC code ${\bf C}_{gc, q}$ in an AWGN channel. 


The PUER performance very much depends on the probabilities of the elements in $\Omega_r$. 
Two different sets of probabilities of the elements in $\Omega_r$ may results in a big gap in decoding of the error control code ${\bf C}_{gc, q}$. To show this, we consider both the non-systematic form and systematic form with $J = 4$. 
In non-systematic form, we directly exploit the given $\Omega_r$ and ${\mathcal P}_r$, 
i.e., $\Omega_r=\{-4,-2,0,+2,+4\}$ and ${\mathcal P}_r= \{0.0625,0.25,0.375,0.25,0.0625\}$.
For the systematic form, we can set $\Omega_r = \{-4,-2\}$ and ${\mathcal P}_r = \{0.5,0.5\}$ to the first 
$K_Q = 576$ received information symbols; and $\Omega_r = \{-4,-2,0,+2,+4\}$ and ${\mathcal P}_r=\{0.0625,0.25,0.375,0.25,0.0625\}$ to the next $N_Q-K_Q=288$ received parity symbols. 
From Fig. 6, we see that the system in systematic form performs better than the system in non-systematic form, because more accurate probabilities of the elements $\Omega_r$ are used. The PUER performance becomes slightly worse as the number of user increases. In addition, without channel coding, the BER performance of the FFMA system is exactly in accord with the theoretical BER performance of BPSK modulation.



\begin{figure}[t]
  \centering
  \includegraphics[width=0.5\textwidth]{Graph_FFMA_TDMA.pdf}
  \caption{PUER performances of different systems in a GMAC. The sparse-form-based and diagonal-form-based FFMA-TDMA systems are used a binary $(6000, 3000)$ LDPC code ${\bf C}_{gc, b}$ for error control, and the classical TDMA system utilizes repetition code for error control, where $N = 6000$, $K = 10$ bits, and $J = 1, 100, 300$ for comparisons.}
  \vspace{-0.15in}
\end{figure}

In an FFMA system using a NB-LDPC code for error control, it is difficult to support massive users' transmission, because of the high decoding complexity. In practice, a binary LDPC code is preferred. 
In the following, we present an example of an FFMA system to support up to $300$ users, where the horizontal coordinate-axis is the signal-to-noise power ratio (SNR) of each user, as shown in Fig. 9.


In simulation of the error performance for the systems, suppose the total number of resources (e.g., time) is $N = 6000$, each user transmits $K = 10$ bits, and the numbers of users are $J = 1, 100$ and $300$.
For the proposed FFMA-TDMA systems, we construct a binary $(6000, 3000)$ LDPC code ${\bf C}_{gc,b}$ for error control. The generator matrix of ${\bf C}_{gc, b}$ is put in systematic form, and decoding is carried out with $50$ iterations of the MSA (min-sum algorithm). 
To support $J = 300$ users, we set $m = 300$, and then construct an orthogonal UD-EP code $\Psi_{\rm B}$ constructed over GF($2^{300}$).
For the classical TDMA system, repetition codes are used for error control.
Actually, for a classical TDMA system, each user occupies the same orthogonal resources, 
i.e., $\frac{N}{J}$ resources, thus each bit will be repeated $\frac{N}{JK}$ times.
The coding gain of the repetition code can be approximately calculated as $10 \log_{10}(\frac{N}{JK})$,
which decreases with the increased number of users $J$.

For the sparse-form-based FFMA system, as the number of users gets large, the gaps between the PUER curves become smaller. For example, when $J = 100$ and $300$, the PUERs of the two cases are almost the same, verifying the efficiency of the proposed FFMA system. In addition, when the PUER is $P_b = 10^{-5}$, the gap between the PUERs of $J=1$ and $300$ is only $1.5$ dB.
Then, we investigate the PUER between sparse-form-based and diagonal-form-based FFMA systems.
Under the same simulation conditions, the diagonal-form-based FFMA provides better PUER than that of the sparse-form-based FFMA, since the default bits are $0$s which are available at the receiving end.
However, with the increased number of users, the differences between the sparse-form-based and diagonal-form-based FFMA systems become smaller. When $J = 300$, both the sparse-form-based and diagonal-form-based FFMA systems have the same PUER.


Next, we compare our proposed FFMA-TDMA with the classical TDMA systems.
When the number of users is small, e.g., $J = 1$, the TDMA with repetition code can provide much better PUER performance, since the coding gain is around $10 \log_{10}(\frac{6000}{10}) \approx 27.78$ dB.
However, for a large number of arrival users, e.g., $J \ge 100$, our proposed FFMA-TDMA systems provide much better PUER performance. When $P_b = 10^{-5}$ and $J = 300$, the FFMA-TDMA system can provide about $6$ dB coding gain than the TDMA system, verifying the proposed FFMA system can improve the PUER performance for a massive users scenario.



\begin{figure}[t]
  \centering
  \includegraphics[width=0.5\textwidth]{Graph_Net.pdf}
  \caption{PUER performance of a network FFMA over GF($2^8$) system in a DSC, where the $(255, 205)$ RS code is used for error control. }
  \vspace{-0.22in}
\end{figure}

Finally, we investigate the PUER performance of a network FFMA over GF($2^8$) system, where the $(255, 205)$ RS code is used for error control with a hard-decision decoding. 
The UD-AIEP code is performed in three different fields GF($2^m$), GF($5^m$) and GF($17^m$) to support $m$, $2m$, and $4m$ users, respectively. 
The PUER performances of the systems using $3$ different base prime fields GF($2$), GF($5$) and GF($17$) are shown in Fig. 10. From the figure, we see that the PUER performances become poorer as the PF $p$ increases. This is due to the fact, for a given transition probability $\beta$, as the PF $p$ of the prime base field increases, the correct receiving probability, $1-(p-2)\beta$, becomes smaller. 
However, using a large PF $p$, more users can be simultaneously multiplexed, and the \textit{multiplex efficiency} is equal to $\log_2 (p-1)$.
This provides a tradeoff between the multiplexed number of users and the PUER performance. 
Fig. 10 shows that the RS code improves the PUER performance significantly.  







%\vspace{-0.1in}
\section{Conclusion and Remarks}
In this paper, we proposed an FFMA technique to support massive users with short packet traffic, to solve the FBL of multiuser reliability transmission problem. To achieve this objection, each user is assigned to a unique EP of elements over a prime field or its extension field. Each output bit of a user is mapped one-to-one into an element of its assigned AIEP, which is called EP-coding. The collection of AIEPs assigned to the users has USPM structural property. 
The \textit{Cartesian product} of the AIEPs assigned to the users are said to AIEP-coding. In an FFMA system, an AIEP is regarded as a virtual resource block (VRB) for MA communications. 

In this paper, we have constructed two classes of UD-EP codes which are based on prime fields and their extension fields, and their encoding and decoding in conjunction with a channel error-control code are used for both error control and resolving MUI issue.
Based on the orthogonal UD-EP code $\Psi_{\rm B}$ constructed over GF($2^m$), we presented both sparse-form-based and diagonal-form-based FFMA systems, which can also be viewed as TDMA in finite-field (FFMA-TDMA).
%we first presented FFMA systems for a massive users with short packet transmission scenario, which can solve the FBL limitation and achieve a large coding gain with a low-complexity decoder. 
In addition, we proposed a network FFMA over the extension field GF($p^m$) of a prime field GF($p$) for a pure digital communication scenario, in which we assigned different VRBs to different users for separating users without ambiguity. 
Simulation results showed that the proposed FFMA system can support massive users with well-behaved PUER performance in a GMAC.
For network FFMA systems, more users can be simultaneously multiplexed by using a large PF $p$, and the multiplex efficiency is equal to $\log_2 (p-1)$.


There are many unsolved works left. For example, developing FFMA systems for fading channel is desirable. 
It is also appealing to design T-fold ALOHA FFMA system over a random access channel.



\vspace{-0.1in}
\begin{thebibliography}{99}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%Following is references on Power & data rate & channel.


\bibitem{FAdachi1}
F. Adachi, D. Garg, S. Takaoka, and K. Takeda, ``Broadband CDMA Techniques," \textit{IEEE Wireless Communications}, vol. 12, no. 2, pp. 8-18, April 2005.


%\bibitem{ZDing2017_survey}
%Z. Ding, X. Lei, G. K. Karagiannidis, R. Schober, J. Yuan, and V. K. Bhargava, ``A Survey on Non-Orthogonal Multiple Access for 5G Networks: Research Challenges and Future Trends," \textit{IEEE Journal on Selected Areas in Communications}, vol. 35, no. 10, pp. 2181 - 2195, July 2017.


\bibitem{YChen_2018}
Y. Chen et al., ``Toward the Standardization of Non-Orthogonal Multiple Access for Next Generation Wireless Networks," \textit{IEEE Communications Magazine}, vol. 56, no. 3, pp. 19-27, March 2018.


\bibitem{6G}
C. -X. Wang et al., ``On the Road to 6G: Visions, Requirements, Key Technologies, and Testbeds,'' \textit{IEEE Communications Surveys \& Tutorials}, vol. 25, no. 2, pp. 905-974, Secondquarter 2023.

\bibitem{6G_white}
``6G typical scenarios and key capabilities,'' IMT-2030 (6G) Promotion Group, White Paper, Jul. 2022. [Online]. 


\bibitem{UMA_2022}
Y. Li et al., ``Unsourced multiple access for 6G massive machine type communications,'' \textit{China Communications}, vol. 19, no. 3, pp. 70-87, March 2022.

\bibitem{UMA_PZ}
P. Fan et al., ``Random access for massive Internet of things: current status, challenges and opportunities,'' \textit{Journal on Communications}, vol. 42, no. 4, pp. 1-21, April 2021.


\bibitem{MIT_2017}
Y. Polyanskiy, ``A perspective on massive random-access,'' \textit{IEEE International Symposium on Information Theory-Proceedings, ISIT 2017}, 2017, pp. 2523–2527. 


\bibitem{Capacity_GMC_2017}
X. Chen, T.-Y. Chen and D. Guo, ``Capacity of Gaussian many-access channels,'' \textit{IEEE Trans. Information Theory}, vol. 63, no. 6, pp. 3516-3539, Jun. 2017.


\bibitem{Capacity_GMC_2020}
J. Gao, Y. Wu and W. Zhang, ``Energy-efficiency of Massive Random Access with Individual Codebook,'' \textit{IEEE Global Communications Conference, Globecom 2020}, Taipei, Taiwan, 2020, pp. 1-6.

\bibitem{Capacity_GMC_2021}
R. C. Yavas, V. Kostina and M. Effros, ``Gaussian Multiple and Random Access Channels: Finite-Blocklength Analysis,'' \textit{IEEE Trans. Information Theory}, vol. 67, no. 11, pp. 6983-7009, Nov. 2021.

\bibitem{Capacity_GMC_Yury}
S. S. Kowshik and Y. Polyanskiy, ``Fundamental Limits of Many-User MAC With Finite Payloads and Fading,'' \textit{IEEE Trans. Information Theory}, vol. 67, no. 9, pp. 5853-5884, Sept. 2021.



\bibitem{MIT_2017_2}
O. Ordentlich and Y. Polyanskiy, ``Low complexity schemes for the random access Gaussian channel,'' \textit{IEEE International Symposium on Information Theory-Proceedings, ISIT 2017}, 2017, pp. 2528–2532. 


\bibitem{BCH_MA}
I. Bar-David, E. Plotnik, et al., ``Forward Collision Resolution A Technique for Random Multiple-Access to the Adder Channel,'' \textit{IEEE Trans. Information Theory}, vol. 39, no. 5, 1993, pp. 1671–1675. 




\bibitem{CCS_1}
V. K. Amalladinne, G. S. Member, et al., ``A Coded Compressed Sensing Scheme for Unsourced Multiple Access,'' \textit{IEEE Trans. on Information Theory}, vol. 66, no. 10, 2020, pp. 6509–6533.

\bibitem{CCS_2}
R. Calderbank and A. Thompson, ``CHIRRUP: A practical algorithm for unsourced multiple access,'' \textit{Information and Inference}, vol. 9, no. 4, 2020. 


\bibitem{Polar_1}
J. Dai, K. Niu, et al., ``Polar-Coded Non-Orthogonal Multiple Access,'' \textit{IEEE Trans. Signal Processing}, vol. 66, no. 5, 2018, pp. 1374–1389. 

\bibitem{Polar_2}
E. Abbe and E. Telatar, ``Polar Codes for The $m$-user Multiple Access Channel,'' \textit{IEEE Trans.  Information Theory}, vol. 58, no. 8, 2012. 


\bibitem{Polar_3}
M. Zheng, Y. Wu, et al., ``Polar Coding and Sparse Spreading for Massive Unsourced Random Access,'' \textit{IEEE Vehicular Technology Conference, VTC 2020}, Nov. 2020, pp. 8–13.

\bibitem{IDMA_1}
A. K. Pradhan, V. K. Amalladinne, et al., ``Sparse IDMA: A Joint Graph-Based Coding Scheme for Unsourced Random Access,'' \textit{IEEE Trans. Communications}, vol. 70, no. 11, pp. 7124-7133, Nov. 2022.


\bibitem{SVC_1}
H. Ji, S. Park, and B. Shim, ``Sparse Vector Coding for Ultra Reliable and Low Latency Communications,'' \textit{IEEE Trans. Wireless Communications}, vol. 17, no. 10, pp. 6693–6706, Oct. 2018.


\bibitem{SVC_2}
L. Yang and P. Fan, ``Improved Sparse Vector Code Based on Optimized Spreading Matrix for Short-Packet in URLLC,'' \textit{IEEE Wireless Communications Letters}, vol. 12, no. 4, pp. 728-732, April 2023.



%\bibitem{QWang_2018}
%Q. Wang, R. Zhang, L. Yang, and L. Hanzo, ``Non-Orthogonal Multiple Access: A Unified Perspective,'' \textit{IEEE Wireless Communications}, vol. 25, no. 2, pp. 10-16, April 2018.


%\bibitem{QY_ISJ_2019}
%Q. Yu, H. Chen and W. Meng, ``A Unified Multiuser Coding Framework for Multiple Access Technologies,'' \textit{IEEE Systems Journal}, vol. 13, no. 4, pp. 3781-3792, 2019. 


%\bibitem{LDai2015}
%L. Dai, B. Wang, Y. Yuan, S. Han, C. I, and Z. Wang, ``Nonorthogonal multiple access for 5G: Solutions, challenges, opportunities, and future research trends," \textit{IEEE Communication Magazine}, vol. 53, no. 9, pp.74-81, Sept. 2015.


%\bibitem{HNiko2013}
%H. Nikopour and H. Baligh, ``Sparse code multiple access," \textit{in Proc. IEEE 24th International Symposium on Personal Indoor and Mobile Radio Communications (PIMRC)}, pp. 332-336, Nov. 2013.


%\bibitem{HNiko2014}
%H. Nikopour, E. Yi, A. Bayesteh, K. Au, M. Hawryluck, H. Baligh, and J. Ma, ``SCMA for downlink multiple access of 5G wireless networks," \textit{in Proc. IEEE GLOBECOM}, pp. 3940-3945, Dec. 2014.





%%%%% Below is about uniquely-decodable codes
%\bibitem{Liao1972}
%H. H. J. Liao, ``Multiple access channels," Ph.D dissertation, Dept. Electrical Engineering, Univ. Hawaii, Honolulu, HI, 1972.

\bibitem{Kasami1976}
T. Kasami, and Shu Lin, ``Coding for a Multiple-Access Channel," \textit{IEEE Trans. Information Theory}, vol. IT-22, no. 2, pp. 129-137, March 1976.

%\bibitem{Chang1976}
%S. C. Chang and E. J. Weldon, ``Coding for a T-user Multiple Access Channel," \textit{IEEE Trans. Information Theory}, Vol.IT-25, No.5, pp.684-691, Sept.1979.


\bibitem{Kasami1978}
T. Kasami, and Shu Lin, ``Bounds on the Achievable Rates of Block Coding for a Memoryless Multiple-Access Channel," \textit{IEEE Trans. Information Theory}, vol. IT-24, no. 2, pp. 187-197, March 1978.


%\bibitem{Peterson1979}
%Peterson R, Costello D., ``Binary convolutional codes for a multiple-access channel,'' \textit{IEEE Trans. Information Theory}, vol. 25, no. 1, pp. 101-105, 1979.


%\bibitem{Chevillat1981}
%P. Chevillat, `` N-user trellis coding for a class of multiple-access channels,'' \textit{IEEE Trans. Information Theory}, vol. 27, no. 1, pp. 114-120, 1981.


\bibitem{Kasami1983}
T. Kasami, Shu Lin, Victor K. Wei, and Saburo Yamamura, ``Graph Theoretic Approaches to the Code Construction for the Two-User Multiple-Access Binary Adder Channel," \textit{IEEE Trans. Information Theory}, vol. IT-29, no. 1, pp. 114-130, 1983.


%\bibitem{Van1983}
%V. Tilborg H., ``Upper bounds on $|C_2|$ for a uniquely decodable code pair $(C_1,C_2)$  for a two-access binary adder channel," \textit{IEEE Trans. on Information Theory}, vol. 29, no. 3, pp. 386-389, May 1983.


%\bibitem{Vanroose1992}
%Vanroose, P., Van Der Meulen, E. C., ``Uniquely decodable codes for deterministic relay channels," \textit{IEEE Trans. on Information Theory}, vol.38, no.4, pp. 1203-1212, July 1992.

%\bibitem{Jevtic1992}
%Jevtic, D. B., ``Disjoint uniquely decodable codebooks for noiseless synchronized multiple-access adder channels generated by integer sets," \textit{IEEE Trans. on Information Theory}, vol.38, no.3, pp. 1142-1146, May 1992.


\bibitem{Fan1995}
P. Fan, M. Darnell, and B. Honary, ``Superimposed codes for the multi-access binary adder channel'', \textit{IEEE Trans. Information Theory}, vol. 41, no. 4, pp. 1178-1182, 1995.

%\bibitem{Khachatrian1998}
%Khachatrian G H, Martirossian S S. ``Code construction for the T-user noiseless adder channel,'' \textit{IEEE Trans. Information Theory}, vol. 44, no. 5, pp. 1953-1957, 1998.

%\bibitem{Bross1998}
%Bross, S. I., Blake, I.F., ``Upper bound for uniquely decodable codes in a binary input N-user adder channel," \textit{IEEE Trans. on Information Theory}, vol. 44, no. 1, pp. 334-340, Jan 1998.


%\bibitem{Cheng2001}
%Cheng J, Watanabe Y, ``A multiuser $k$-ary code for the noisy multiple-access adder channel,'' \textit{IEEE Trans. Information Theory}, vol. 47, no. 6, pp. 2603-2607, 2001.


%\bibitem{Kiviluoto2007}
%Kiviluoto, L., Ostergard, P. R. J., ``New Uniquely Decodable Codes for the T-User Binary Adder Channel With $3 \le T \le 5$," \textit{IEEE Trans. on Information Theory}, vol. 53, no. 3, pp. 1219-1220, March 2007.

%\bibitem{Yu_P2P}
%Q. Yu, W. Meng, and S. Lin, ``Packet Loss Recovery Scheme with Uniquely-Decodable Codes for Streaming Multimedia over P2P Networks," \textit{IEEE Journal on Selected Areas in Communications}, vol.31, no.9, pp. 142-154, Aug. 2013.


%\bibitem{R1}
%J. Zhu and M. Gastpar, ``Gaussian Multiple Access via Compute-and-Forward,'' IEEE Transactions on Information Theory, vol. 63, no. 5, pp. 2678-2695, May 2017.

%\bibitem{R2}
%M. Qiu, Y. -C. Huang, S. -L. Shieh and J. Yuan, ``A Lattice-Partition Framework of Downlink Non-Orthogonal Multiple Access Without SIC,'' \textit{IEEE Transactions on Communications}, vol. 66, no. 6, pp. 2532-2546, June 2018.


\bibitem{R3}
R. Ahlswede, Ning Cai, S. Li and R. W. Yeung, ``Network information flow,'' \textit{IEEE Trans. on Information Theory}, vol. 46, no. 4, pp. 1204-1216, July 2000.




%%%%%% LDPC 
%\bibitem{Gallager}
%R. G. Gallager, ``Low-Density Parity-Check Codes, " \textit{IRE Trans. Information Theory}, vol. 8, no. 1, pp. 21- 28, Jan. 1962.

%\bibitem{Tanner}
%R. M. Tanner, ``A recursive approach to low complexity codes, " \textit{IEEE Trans. Information Theory}, vol. 27, no. 9, pp. 533-547, Sept. 1981.

\bibitem{Polar2009}
Erdal Arikan, ``Channel Polarization: A Method for Constructing Capacity-Achieving Codes for Symmetric Binary-Input Memoryless Channels,'' \textit{IEEE Trans. Information Theory}, vol. 55, no. 7, pp. 3051-3073, July 2009.

\bibitem{JDai2016}
J. Dai, K. Niu, Z. Si, and J. Lin, ``Polar coded non-orthogonal multiple access," \textit{IEEE International Symposium on Information Theory-Proceedings, ISIT 2016}, Barcelona, pp. 988-992, June 2016.


%\bibitem{GDF1989_1}
%G. D. Forney Jr., and L. Wei, ``Multidimensional constellations. Part.I: Introduction, figures of merit, and generalized cross constellations," \textit{IEEE Journal on Selected Areas in Communications}, vol. 7, no. 6, pp. 877-892, Aug. 1989.


%\bibitem{GDF1989_2}
%G. D. Forney Jr., ``Multidimensional constellations. Part. II: Voronio Constellations," \textit{IEEE Journal on Selected Areas in Communications}, vol. 7, no. 6, pp.941-958, Aug. 1989.




%\bibitem{Yu_UDAS}
%Q. Yu, and K. Song, ``Uniquely Decodable Multi-Amplitude Sequence for Grant-Free Multiple-Access Adder Channels,'' \textit{IEEE Transactions on Wireless communications}, 2023, Early Access.



\bibitem{Shu2009}
William E. Ryan and Shu Lin, Channel Codes classical and Modern, Cambridge University Press, 2009.

%\bibitem{John2009}
%John G. Proakis, Digital Communications, Fifth Edition, Beijing, Publishing House of Electronics Industry, 2009.

\bibitem{LinBook3}
J. Li, S. Lin, K. Abdel-Ghaffar, W. E. Ryan, and D. J. Costello, ``LDPC Code Designs, Constructions, and Unification," Cambridge University Press, 2017.

\bibitem{Thomas}
Thomas M. Cover, and Joy A. Thomas, ``Elements of Information Theory,'' Tsinghua University Press, 2010.

%\bibitem{Yi-Jing}
%https://ctext.org/book-of-changes/yi-jing 


\end{thebibliography}


\vfill
\end{document}

