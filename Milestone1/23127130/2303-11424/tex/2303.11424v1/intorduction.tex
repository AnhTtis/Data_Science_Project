%!TEX root = main.tex
\section{Introduction}

% GAN is awesome and sota, diffusion time taking
% conv based GAN and problem
% recent boom in coordinate based GAN, good things for inr and not been scaled to large diverse data
%Our method and inspiration
%contributions 1) INR in forms of polynomial 2) architecture only made up of linear and relu, 3) scale it to imagenet datasets 4) best of style gan and inr

Deep learning-based generative models are a very active area of research with numerous advancements in recent years \cite{kingma2013auto, goodfellow2020generative, dhariwal2021diffusion}. 
% In particular, generative adversarial networks (GANs) \cite{goodfellow2020generative} have shown remarkable performance for various generative tasks such as image-to-image translation \cite{liu2017unsupervised, isola2017image, zhu2017toward, park2019semantic}, image manipulation \cite{zhu2020domain, wang2022high, harkonen2020ganspace}, disentanglement \cite{karras2019style, tran2017disentangled, kazemi2019style}, inverse problems \cite{shah2018solving, yang2021gan}, domain adaptation \cite{huang2018auggan, tzeng2017adversarial}, and video generation \cite{skorokhodov2022stylegan, li2018video}. 
Most widely, generative models are based on convolutional architectures. However, recent developments such as implicit neural representations (INR)  \cite{mildenhall2021nerf, sitzmann2020implicit} represent an image as a continuous function of its coordinate locations, where each pixel is synthesized independently. Such a function is approximated by using a deep neural network. INR provides flexibility for easy image transformations and high-resolution up-sampling through the use of a coordinate grid. Thus, INRs have become very effective for $3$D scene reconstruction and rendering from very few training images \cite{mildenhall2021nerf, mescheder2019occupancy, barron2022mip, martin2021nerf,yu2021pixelnerf}. However, they are usually trained to represent a single given scene, signal, or image. Recently, INRs have been implemented as a generative model to generate entire image datasets \cite{anokhin2021image, skorokhodov2021adversarial}. They perform comparably to CNN-based generative models on perfectly curated datasets like human faces \cite{karras2019style}; however, they have yet to be scaled to large, diverse datasets like ImageNet \cite{deng2009imagenet}. 

% The weights in this CNN-based model are modulated by some low-dimension latent code sampled from a known distribution \cite{karras2019style}. The model can generate plausible images over the distribution of real datasets by modulating the CNN weights. However, CNN kernels are not inherently equivariant for transformation like rotation; hence, even simple image transformations in GAN space are not trivial. 
% Convolution neural network (CNN) is generally used in the generative model.


%inr, inrgan , blur mlp, siren
INR generally consists of a positional encoding module and a multi-layer perceptron model (MLP). The positional encoding in INR is based on sinusoidal functions, often referred to as Fourier features. Several methods \cite{mildenhall2021nerf, sitzmann2020implicit, tancik2020fourier} have shown that using MLP without sinusoidal positional encoding generates blurry outputs, i.e., only preserves low-frequency information. Although, one can remove the positional encoding by replacing the ReLU activation with a periodic or non-periodic activation function in the MLP \cite{sitzmann2020implicit, ramasinghe2022beyond, chng2022gaussian}. However, in INR-based GAN \cite{anokhin2021image}, using a periodic activation function in MLP leads to subpar performance compared to positional encoding with ReLU-based MLP.  

Sitzmann et al. \cite{sitzmann2020implicit} demonstrate that ReLU-based MLP fails to capture the information contained in higher derivatives. This failure to incorporate higher derivative information is due to ReLU's piece-wise linear nature, and second or higher derivatives of ReLU are typically zero. This can be further interpreted in terms of the Taylor series expansion of a given function. The higher derivative information of a function is included in the coefficients of a higher-order polynomial derived from the Taylor series. Hence, the inability to generate high-frequency information is due to the ineffectiveness of the ReLU-based MLP model in approximating higher-order polynomials. 

%non linear combination of periodic, not very natural
Sinusoidal positional encoding with MLP has been widely used, but the capacity of such INR can be limiting for two reasons. First, the size of the embedding space is limited; hence only a finite and fixed combination of periodic functions can be used, limiting its application to smaller datasets. Second, such an INR design needs to be mathematically coherent. These INR models can be interpreted as a non-linear combination of periodic functions where periodic functions define the initial part of the network, and the later part is often a ReLU-based non-linear function. Contrary to this, classical transforms (Fourier, sine, or cosine) represent an image by a linear summation of periodic functions. However, using just a linear combination of the positional embedding in a neural network is also limiting, making it difficult to represent large and diverse datasets. Therefore, instead of using periodic functions, this work models an image as a polynomial function of its coordinate location. 
% Therefore,  we design our MLP in a way that can represents higher-order polynomials.

The main advantage of polynomial representation is the easy parameterization of polynomial coefficients with MLP to represent large datasets like ImageNet. However, conventionally MLP can only approximate lower-order polynomials. One can use a polynomial positional embedding of the form $x^py^q$ in the first layer to enable the MLP to approximate higher order. However, such a design is limiting, as a fixed embedding size incorporates only fixed polynomial degrees. In addition, we do not know the importance of each polynomial degree beforehand for a given image. 

Hence, we do not use any positional encoding, but we progressively increase the degree of the polynomial with the depth of MLP. We achieve this by element-wise multiplication between the feature and affine transformed coordinate location, obtained after every ReLU layer. The affine parameters are parameterized by the latent code sampled from a known distribution. This way, our network learns the required polynomial order and represents complex datasets with considerably fewer trainable parameters. In particular,  the key highlights are summarized as follows:
\begin{compactitem}
\item We propose a Poly-INR model based on polynomial functions and design a MLP model to approximate higher-order polynomials.
\item Poly-INR as a generative model performs comparably to the state-of-the-art CNN-based GAN model (StyleGAN-XL \cite{sauer2022stylegan}) on the ImageNet dataset with $~3-4\times$ fewer trainable parameters (depending on output resolution).
\item Poly-INR outperforms the previously proposed INR models on the FFHQ dataset \cite{karras2019style}, using a significantly smaller model.
\item We present various qualitative results demonstrating the benefit of our model for interpolation, inversion, style-mixing, high-resolution sampling, and extrapolation.
\end{compactitem}







