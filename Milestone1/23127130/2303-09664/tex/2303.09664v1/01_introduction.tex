\section{Introduction} \label{sec:introduction}

Group-level analysis plays an important role in social sciences. With the rise of big data, artificial intelligence (AI), and data mining techniques, group analysis has increasingly become a powerful tool in many applications, ranging from policy-making, direct marketing, education, to healthcare.
%For example, {\it group profiling}, an important analysis strategy that extracts and ascribes characteristics to groups of people \cite{hildebrandt2006profiling}, has been commonly used for customized recommendation to overcome the sparseness and missingness in personal data \cite{dehghani2016generalized}. 
For example, an important analysis strategy is {\it group profiling}, which extracts and describes the characteristics of groups of people \cite{hildebrandt2006profiling}; it has been commonly used for customized recommendations to overcome sparse and missing personal data \cite{dehghani2016generalized}. 
The same strategy is also used for mining social media, educational, and healthcare data to understand the shared characteristics of online communities or student/patient cohorts \cite{zhang2015iterative,krause_supporting_2016,cao2015g}. While it may help to support public and private services or product creations that are better tailored to different communities, group profiles resulted from mathematical inference are typically not valid for every individual regarded as a member in the group (this is known as {\it non-distributive} group profiles) \cite{hildebrandt2006profiling}. The shared group characteristics extracted from data can have social ramifications such as stereotyping, stigmatization, or lead to pernicious consequences in decision making because individuals might be judged by group characteristics they do not posses \cite{custers2004power,mendoza2017right,gdpr}.

Given the extensive use of group-level analysis, researchers have begun to examine its ramifications. Prior work has dealt with issues ranging from model evaluation to contextualized group interpretability \cite{zhang2015iterative,krause_supporting_2016,cao2015g}, and recent progress in interpretable Machine Learning (iML) and eXplainable Artificial Intelligence (XAI) have brought much attention and methods to diagnose and produce more explainable models \cite{adadi2018peeking,guidotti2018survey}. However, explainable models alone will not solve this problem. Even if the algorithms or models are completely accurate, understandable and trustworthy, the risk of overgeneralization of group characteristics still exists, especially when most group-level analytic seem to highlight such generalization backed up by mathematical inference -- rather than to examine groups more conscientiously. 

While there is a clear need to provide analytics to enable users to characterize groups of interest, at the same time, the appropriate assessment must also be provided to mind the potential overgeneralization of group characteristics. How can analytic tools facilitate a more conscientious practice in such analyses? We address this larger question by answering two sub-questions: (1) What are the design requirements for developing such analytic tools? (2) What technical methods and concepts are needed to create group-level analytic tools that meet these requirements? We first conduct multiple rounds of requirement interviews with domain experts to identify a set of design guidelines for {\it accountable group analytic}. Following the design guidelines, we develop {\it\name}, a visual analytic suite that leverages interpretable machine learning algorithms and visualization to enable inference assessment, model explanation, data corroboration and sense-making analysis. 

As an example, suppose a data journalist wants to understand social media users' conversations about  ``gun control" issues. One possible question might be: ``{\it how do conservatives and liberals talk differently on the gun issues?}'' Using \name and carefully curated social media samples, the journalist may begin with a summary view of the major sociolinguistic differences between the two camps -- for example, after a mass shooting event, one camp might {\it generally} post with a more positive tone, expressing more solidarity and care, or blaming suspects or legislation, compared to the other (Fig.~\ref{fig:teaser}a:~\grouptrend). But {\it how do such sociolinguistic differences manifest in users' communications?}  \name allows the journalist to look for quotes from the users' posts that support the characterization of sociolinguistic attributes (Fig.~\ref{fig:teaser}d:~\languagescope), or see how a camp itself may exhibit diverse patterns in terms of any attribute (Fig.~\ref{fig:teaser}b,c:~\variscope, \depscope). The journalist can see the extent to which those attributes explain the political leaning of users (Fig.~\ref{fig:teaser}c:~\depscope). Moreover, using model explanation tool (Fig.~\ref{fig:teaser}f:~\rationalescope), the journalist can see {\it why} a model might categorize an individual as more conservatives than liberals (or vice versa) given his/her sociolinguistic tendency.

Our key contributions include: (1) We identify a set of design guidelines for creating group-level analysis tools to facilitate a critical inspection of groups. This is the first work that explores the design issues concerning non-distributive group profiles and the risk of group overgeneralization. (2) We propose a new visual analytic toolkit, \name, that incorporates (a) a suite of visual analytic components to help quantitatively and qualitatively inspect the shared and varied characteristics of groups, and (b) interpretable machine learning algorithms, including multi-task predictive models and contrastive explanatory models, to identify qualitative evidence and rationale for individuals regarded as group members. Despite that our \name is developed for a specific scenario -- the inspection of ideological groups using social media data, the visual and algorithmic components can be applied to the analysis of social groups in many domains.

To evaluate the utility of our proposed design, we conduct interview studies with experts from three different domains. Our study suggests that the critical inspection design in \name not only enables domain experts to identify distinctions between groups but also allows them to search and test new hypotheses, explore borderline and edge cases, and find qualitative cues for the group characteristics, which together leads to a richer understanding of the data being grouped.

