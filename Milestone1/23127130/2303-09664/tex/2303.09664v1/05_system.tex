\begin{figure}
    \vspace{-1em}
    \includegraphics[width=\columnwidth]{figures/system-task-pipeline.pdf}
    \vspace{-1em}
    \caption{\label{fig:system-task-analytic-pipeline}
    Our system in (a) operates on the analytic pipeline in (b) consisting of: \textit{contrastive explanatory models} for predicting and discovering the group difference being rendered in \grouptrend and \evalscope, and providing rationales for explaining the prediction of any instance in \rationalescope, and \textit{multi-task prediction models} for generating language cues from the tweet dataset to support the visual inspection in \languagescope.
    }
\end{figure}

\section{\name}
\name is built following the design guideline described earlier. As shown in Fig.~ \ref{fig:system-task-analytic-pipeline}, \name consists of two main components:  (a) visualization and (b) analytic pipeline. The visualization component is comprised of a number of visual interactive tools to support the six main tasks described in Section~\ref{sec:goalsandtasks}, including \grouptrend ({\bf T1}), \evalscope ({\bf T2}), \variscope ({\bf T3}), \depscope ({\bf T4}), \languagescope ({\bf T5}), and \rationalescope ({\bf T6}) (Fig.~\ref{fig:teaser}). Together, these six ``scopes'' allow users to access to qualitative differences ({\bf G1}) and variability ({\bf G2}) of groups, qualitative details from user-generated text ({\bf G2}), and model explanation ({\bf G3}). The analytic component (Fig. \ref{fig:system-task-analytic-pipeline}) includes two major machine learning modules: (1) {\it multi-task prediction models}  generate language cues from the tweet dataset to support the visual inspection in \languagescope, and (2) {\it contrastive explanatory models} generate rationales for explaining the membership prediction. Built up as a web-based tool, our system was implemented as a full-stack application with a python based back-end framework called Django \footnote{https://www.djangoproject.com/} to process API calls and data processing, and a front-end framework called ReactJS and React hooks\footnote{https://reactjs.org/}, and Postgres database \footnote{https://www.postgresql.org/}. Any dataset with all features and metadata is required to be stored in a file and processed into the database before running the tool. Below, we summarize our implementation of the visualization and analytic components.

\subsection{Visualization}\label{sec:vis}
Fig.~\ref{fig:system-overview} captures the user interface of \name. To facilitate users to navigate the dataset and select data/attributes of interest, two interactive tools, \instanceviewer and \scopecontroller are provided as shown on the left and the top of the user interface (Fig.~ \ref{fig:system-overview}a,b).
Once users specify the attributes of interest (e.g., which features, or sociopsychological dimensions) through the \scopecontroller, the main visualization panel with various ``scopes'' will be updated accordingly. These scopes provide distinct functionality to support tasks ({\bf T1}--{\bf T6}) in the design requirements. 
The main visualization panel seamlessly integrates multiple scopes so that the users' data exploration can be loosely guided. For example, \grouptrend can guide users' gaze from left to right through its polylines, and from top to bottom through its vertical axes. This integrated visual layout is designed to make users be contentious about what the group patterns entail. When staring at certain group patterns along the horizontal direction, users can be immediately hinted by the variability and predictive confidence of the patterns via \variscope and \evalscope. Along the vertical direction, users can easily find evidence for the patterns via \languagescope or \rationalescope.
%The main visualization panel seamlessly integrates multiple scopes while users' data exploration is loosely guided by the visual flow created by the featured component, \grouptrend -- with the polylines guiding users' gaze from left to right, and the vertical axes from top to bottom. This integrated visual layout is designed to make users be contentious about what the group patterns entail. For example, when staring at certain group patterns, users should be immediately hinted by the variability and predictive confidence of the patterns (through the horizontal direction with \variscope and \evalscope) and by the readily available evidence for the patterns (through the vertical direction with \languagescope or \rationalescope below the \grouptrend). 
These views also help users to make connection between the specific observations from an individual scope view and the overall group patterns. We describe the specific functions of each scope below.
% Note that the users will be able to see both the visualization components that support showing the overall trend derived from a top-down, or quantitative approach (Fig.~\ref{fig:system-overview}c-i,ii,iii,iv) and that alternatively support showing qualitative details for further bottom-up inquiry (Fig.~\ref{fig:system-overview}d).}

%visual components that are dedicated to the overview of group trend and variance (Fig.~\ref{fig:system-overview}c-i,ii,iii,iv) and qualitative details (Fig.~\ref{fig:system-overview}d) will be updated accordingly. Note that the visual component showing the overall trend and qualitative difference are displaced adjacently to each other, so users can inspect both at the first glance, decide the components they would like to focus depending on their approaches and meanwhile inspect the patterns from both the top-down (more quantitative, big trends) and bottom-approach (more qualitative, language cues.
%\rev{After adjusting the group analysis setting, visual components dedicated to the overview of the group trend and variance (Fig.~\ref{fig:system-overview}c-i,ii,iii,iv) and qualitative details (Fig.~\ref{fig:system-overview}d) are updated accordingly. 

%Note that visual components are displayed together being adjacent to each other, in order to reflect the feedback from the pilot study (refer to \textbf{C3} in Section \ref{sec:goalsandtasks}), so that our system allows to trace the link between the top-down and bottom-approach or quantitative group difference and qualitative language cues by overviewing them at a glance. 

%The data and attributes of interest, once identified by users, are visualized in the main visualization panel through various scopes. 

Unless otherwise specified, \redclr and \blueclr colors are used to differentiate the group membership, with color saturation representing the proportion of tweets in the \red or \blue groups. 

\begin{figure*}[!ht]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/system-overview.pdf}
    % \vspace{-1.8em}
    \caption{\label{fig:system-overview}
    The system overview of \name. The system integrates visualization and analytic pipeline to support the group analysis tasks. On the user interface, (a) \instanceviewer and (b) \scopecontroller support navigation, data retrieval, selection, and control. The data and attributes of interest are visualized in the main visualization panel through various ``scopes.'' For example, (c) \grouptrend visually captures the major ``trends'' of groups across attributes, and (d) \languagescope provides a visual summary of the language evidence for every sociolinguistic attribute, enabling users to further retrieve qualitative details from the tweet instances. (e) \rationalescope provides the instance-level explanation on why a tweet was classified as certain group in comparison with another tweet.
    % The overview of \name and analytic pipeline to support the group analysis tasks. (a) \instanceviewer provides the list of tweets to support the exploration of individual tweets. (b) In \scopecontroller, users can (i) overview the summary of group trend, (ii) select attribute of interest, and (iii) adjust the weights of the language-level criteria to extract the important sequences. The system represents the group difference (c) in the attribute-level features quantitatively by (i) visualizing the group difference in \grouptrend, (ii) representing the attribute importance in \depscope and (iii) inference quality in \evalscope from (f) the contrastive explanatory model, and (iv) clusters identified from Agglomerative Hierarchical clustering with the selected attributes in \clusterview. (d) \languagescope visualizes the most important qualitative details in the language-level extracted from (g) the multi-task model described in Fig. \ref{fig:multi-model}.  (e) \rationalescope provides the instance-level explanation on why a tweet was classified as certain group in comparison with another tweet. 
    }
    \label{fig:system-overview}
    \vspace{-0.8em}
\end{figure*}

\subsubsection{\bf Retrieve, Select \& Control}
Once the system is initialized, it allows users to retrieve tweets and select a particular tweet to take a closer look at it (in \instanceviewer), and control which tweets and attributes to include in the analysis (in \scopecontroller). First, \instanceviewer (Fig.~\ref{fig:system-overview}a) allows users to search and retrieve tweets by search terms. The retrieved tweets are displayed as a list of boxes. Each box contains a tweet with its group information on the top-left corner (a square glyph with its annotated group label colored as \redclr or \blueclr), the ``psycholinguistic score chart'' on the top-right corner (where each bar height represents annotated attribute value), and the tweet text. This \instanceviewer also serves as a selection tool allowing users to look into a particular tweet. For example, users can click the ``tweet handle'' located at the bottom-right corner to highlight the tweet in \grouptrend, or click an attribute on the psycholinguistic score chart to highlight the language sequence corresponding to the selected attribute in the tweet text. \scopecontroller (Fig.~\ref{fig:system-overview}b) provides an overview of all the available group attributes with statistical significance information in a ``Psycholinguistic Summary Bar Chart'' (Fig. \ref{fig:system-overview}b-i). Such overview helps users to determine which attributes to be included in (or excluded from) further group analysis. The selection of attributes can be done using the ``Features'' menu (Fig.~\ref{fig:system-overview}b-ii). The ``Sequence'' menu includes four sliders allowing users to determine the important aspects of retrieved language cues, which will be described later in the analytic modules. 

\begin{figure}
    \vspace{-1em}
    \includegraphics[width=0.95\columnwidth]{figures/system-overview-depscope-variscope.pdf}
    \vspace{-1em}
    \caption{\label{fig:system-overview-depscope-variscope}
    Two modes of Axes in \grouptrend: \depscope and \variscope.
    }
    \vspace{-1.5em}
\end{figure}

\subsubsection{\bf Overview and Inspect group difference and variance.} After setting up the configuration of analysis in \scopecontroller, users can overview the group difference in \grouptrend (Fig. \ref{fig:system-overview}c-i) with \depscope (Fig. \ref{fig:system-overview-depscope-variscope}a) or \variscope (Fig. \ref{fig:system-overview-depscope-variscope}b) as its axes in rectangular boxes allowing the inspection of feature importance and subgroups. The system also supports the inspection of the model inference results in \evalscope (Fig. \ref{fig:system-overview}c-iii).
\paragraph{\bf \grouptrend}
\grouptrend (Fig. \ref{fig:system-overview}c-i) allows users to visually capture the ``trends'' of groups and contrast the differences between them through a parallel set ({\bf T1}), where the trends are captured when polylines from a group, representing the multidimensional attribute values of data instances, agglomerate due to close attribute values. In \grouptrend, each psycholinguistic attribute is represented as a vertical axis; tweets are represented as polylines, colored by their annotated group membership, and bundled whenever appropriated to reduce the visual clutter and to enhance the rendering performance.

\paragraph{\bf \depscope \& \variscope}
The parallel axes in the \grouptrend are further augmented with \depscope and \variscope, to provide an in-context inspection of group variability on top of the group trends. Users can switch between the two modes as shown in Fig.~\ref{fig:system-overview-depscope-variscope}. The \depscope (Fig.~\ref{fig:system-overview-depscope-variscope}a) allows users to inspect the attribute importance through a ``conditional partial dependence plot'' (PDP) where the marginal probability density of each group is shown on the $x$-axes against the attribute values on the $y$-axes. This enables users to visually assess the extent to which the groups are differentiable by a given single attribute ({\bf T4}), which supports the evaluation of a hypothesis relevant to this attribute. \variscope (Fig.~\ref{fig:system-overview-depscope-variscope}b), on the other hand, allows users to inspect the group variance through a set of ``subgroup attribute glyphs'' ({\bf T3}), where each rectangle glyph represents the attribute summary of a subgroup with vertical position indicating the central tendency, height indicating the variance, width indicating the size of the subgroup, and color reflecting the probability of group membership. The subgroups were automatically detected based on the attribute values of tweets using Agglomerative Hierarchical Clustering method with the number of subgroups determined by the elbow method evaluated with the total intra-cluster variation. This enables users to visually capture the coherence or variability within a group and across attributes -- e.g., a less coherent group will have several subgroups spreading vertically along one or more attribute axes. Moreover, it serves as a hypothesis evaluation and seeking tool as the subgroup patterns may support/disconfirm an existing hypothesis, and any emerging, cross-attribute subgroup tendency may inform a new hypothesis. 

\paragraph{\bf \evalscope}
\evalscope (Fig. \ref{fig:system-overview}c-iii) allows users to closely examine the model inference results of tweet group membership by comparing the predictive membership against the ground-truth (human annotated) labels (\textbf{T2}). The predictive membership is generated from a decision tree model, which is the same as the contrastive explanatory model described later in Section~\ref{sec:contrastive-exp}. The comparison is achieved through a ``dual-sided histograms'' of classification probability (from top to bottom: from the most likely \blue to the most likely \red), where correct and wrong classifications are separately shown on the left and right side of the histogram plot. To facilitate the inspection of particular prediction cases, users can click any location of the histogram bars to highlight a particular set of instances within the corresponding range of classification probabilities.  

\subsubsection{\bf Back up with qualitative details.}
\languagescope (Fig. \ref{fig:system-overview}d) provides a visual summary of the language evidence for every sociolinguistic attribute, which enables users to capture and further retrieve qualitative details from the tweet instances (\textbf{T5}). \languagescope is comprised of multiple parallel axes arranged in the same way as the \grouptrend. The language cues are text snippets extracted from the tweet text to represent a particular attribute having a particular value (or value range) -- e.g., the text snippet \tweet{out until the house votes to address gun violence} are extracted to represent an expression for attribute \domi around the value 0.85 (Fig. \ref{fig:teaser}d). The language cues are represented as squared glyphs along each attribute axis. Each glyph is represented with its size indicating the sequence importance (described in Section~\ref{sec:multi}), with color indicating the group membership probability, and vertical position indicating the mean attribute value. These language cues are learned automatically from the multi-task prediction models, which will be described in a later section. The extracted cues are associated with an importance score that reflect both the model prediction and users' preference (as described in the \scopecontroller). By default, the system displays ten most important language cues for each attribute and the cues with an importance score greater than a threshold will be shown with the corresponding text snippets. 

\subsubsection{\bf Offer the rationale behind group profiling.}
\rationalescope (Fig. \ref{fig:system-overview}d) allows users to closely examine how individual tweets may be predicted to be in a certain group (or not) according to its attribute values, through a ``contrastive explanation dialog box'' ({\bf T6}). The dialog box presents a ``rationale'' as an answer to a question about the prediction. Users can select tweets of interest (from browsing the \instanceviewer or other scopes) and ask two types of reasoning questions \cite{van2002remote}: (1) {\it p-mode}: focuses on the ``properties'' of an object or instance (e.g., ``{\it Why is tweet X classified as \red rather than \blue}?''), and (2) {\it o-mode}: focuses on the contrast of two objects (e.g, ``{\it Why are tweet X classified as \red whereas another tweet Y classified as \blue }?''). Such rationales are automatically generated from the contrastive explanatory models, which will be described in a later section. The extracted rationales are shown using natural language with counterfactual examples in the dialog box. \\

\begin{table}[]
\resizebox{\textwidth}{!}{%
\begin{tabular}{llll}
\hline \\[-10pt]
\textbf{Layout} &
  \textbf{Design scheme} &
  \textbf{Advantage} &
  \textbf{Disadvantage} \\[2pt] \hline \\[-7pt]
\textbf{\begin{tabular}[c]{@{}l@{}}Scatterplot\\ matrix\end{tabular}} &
  \begin{tabular}[c]{@{}l@{}}A layout with a set of scatter plots \\ representing bivariate relationships \\ in a two-dimensional matrix\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Well-represents the pairwise \\ relationship between attributes\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Does not show the trends \\ over multiple attributes\end{tabular} \\[15pt]
\textbf{\begin{tabular}[c]{@{}l@{}}Radial\\ layout\end{tabular}} &
  \begin{tabular}[c]{@{}l@{}}A two-dimensional plot encoding \\ multivariate attributes of instances \\ along with radial axes\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Reveals the instance-level \\ differences by the overall \\ association with attributes\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Does not reveal \\ the attribute-wise trend\end{tabular} \\[18pt]
\textbf{\begin{tabular}[c]{@{}l@{}}Glyph-based\\ layout\end{tabular}} &
  \begin{tabular}[c]{@{}l@{}}Instances are represented as glyphs \\ encoding attribute values\\ (e.g., in case of a glyph design \\ with small radial bars)\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Visualize both instance-wise \\ characteristics and the differences \\ over multivariate attributes \\ between instances \\ in two-dimensional plot\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Hard to show attribute-wise \\ trend and group differences\end{tabular} \\[30pt]
\textbf{\begin{tabular}[c]{@{}l@{}}Parallel\\ coordinates/\\ sets\end{tabular}} &
  \begin{tabular}[c]{@{}l@{}}A axis-based layout with its polylines\\ as instances passing through multiple \\ axes for multivariate characteristics\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Provides the overall trends \\ of instances' attributes\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}Less space-efficient compared \\ to other layouts\end{tabular} \\[15pt] \hline
\end{tabular}%
}
\label{table:design_choice}
\caption{\label{table:design_choice} The summary of visual layouts in the design process of \grouptrend.}
\end{table}

\subsubsection{\bf Design choice and consideration.} To decide the proper design of visual components and integrated layout methods, we went through multiple phases of the design process defining the underlying visualization tasks/problems and examining prior research especially in multi-dimensional visualization. Following the Munzner’s Nested Model \cite{munzner2009nested}, we started with defining the core domain problem, “visualizing group difference”, and the specific design requirements listed in Section \ref{sec:goalsandtasks} above. We then identified the possible data types (i.e., continuous, ordinal, or categorical attributes of group characteristics, and text data) and the operations (i.e., predictive analysis and its attribute-wise interpretation) to be considered in our system. 


To support the visualization of domain problems, tasks, data types, and operations all together, we break down the whole design process into two phases: First, we define a visual layout for it to serve the core domain problem, ``visualizing the group differences''. In the system, we let \grouptrend play an central role, and investigated multi-dimensional visualization to determine the design of 
\grouptrend. Second, we define other visual components in accordance with \grouptrend to serve the aforementioned tasks and operations. In summary, in these steps we compared alternative choices of organizing visual space and layouts for multidimensional dataset and their potential to be extended to support machine learning and interpretability functionality. In the final layout, other layout components such as \depscope, \variscope, \evalscope are tightly coupled and integrated with the design of \grouptrend so that the visual layout as a whole not only serves the requirements of our system but visually associates with each other. We illustrate the two considerations of the design process in detail below.

First, to find out the design of \grouptrend for visualizing the group differences, we investigated 10 designs in the multi-dimensional visualization studies. In the literature review, we first categorized visual layouts in four types of multi-dimensional visualization based on the classifications in two surveys \cite{liuVisualizingHighDimensionalData2017a, hoffman2002survey}, then searched for literature by the name of layout types and selected 10 visual layouts. The design alternatives as a result of this process can be categorized into four typical multidimensional visual layouts: parallel coordinates and sets \cite{kosara2006parallel, richerEnablingHierarchicalExploration, vosoughParallelHierarchiesVisualization2018, weideleAutoAIVizOpeningBlackbox2020, novotnyOutlierPreservingFocusContext2006} and radial layout \cite{albuquerque2010improving, wang2019polarviz}, scatterplot matrix \cite{wilkinson2006high}, and glyph-based layout \cite{zhaoSkyLensVisualAnalysis2018, cao2018z}. 

Table \ref{table:design_choice} provides a summary of advantages and disadvantages of visual layouts examined in the design decision. Among them, scatterplot matrix is a well-known visual layout with a set of scatter plots representing bivariate relationships in a two-dimensional matrix. While it effectively reveals how data is correlated with respect to any combinations of two variables, we find that it has a limitation of showing trends throughout multiple variables in our application. Radial and glyph-based layout are other types of layout which encode multivariate attributes of an instance as a vector with a point or glyph being projected and coordinated in two dimensional plot. It is advantageous by its two-sided strategy, encoding the overall similarity between instances by their coordinates and attribute-wise properties of instances by radial axes or glyphs with small radial bars, however, it does not facilitate the overview of agglomerative group-wise trends.

We compare the pros and cons of all possible visual layout candidates, as summarized in Table \ref{table:design_choice}, and decided that the parallel sets/coordinates are most suitable to meet the required data types and operations.
It provides the overview of multivariate group trends especially with polylines colored by group memberships along with multiple axes. To support heterogeneous data types, we combine the layout of parallel sets and coordinates. For example, in our dataset, the {\it affect} attributes (e.g., \vale) are continuous variables and the {\it moral} attributes (e.g., \care, \fair) are categorical/ordinal variables. When different types of variables are involved, a polyline indicates either an instance (for continuous variable) or a group of instances belonging to a category (for categorical/ordinal variable). These polylines pass through the vertical parallel axes that are arranged in a way that the highest to lowest possible values of continuous variables are shown from the top to the bottom, while the values in categorical variables are shown in the same or similar orders (e.g., ``virtue,'' ``both,'' ``none,'' and ``vice''). 

Second, considering the visualization of classification results and attribute-wise interpretation, we find that the choice of the parallel sets as a visual layout benefits from its extendability, with which we turned it into “parallel sets for classification” with several visual components being integrated and connected to \grouptrend as an extension of traditional parallel sets. Specifically, we extend the visual space of parallel sets to incorporate the classification results and interpretation in two ways: 1) Utilizing unused visual space - by utilizing the axes of parallel sets for attribute-wise interpretation (presented as \depscope or \variscope). The vertical parallel axes in the traditional layout are typically of no use without any functionality. We expand it to a vertical space to encode the attribute-wise interpretation (details in the \depscope or \variscope section), 2) Connecting to other layouts - with the histogram plot of prediction results (\evalscope) being aligned and connected on the right side of \grouptrend (as shown in Fig. \ref{fig:system-overview}c-i and Fig. \ref{fig:system-overview}c-iii). The polylines in \grouptrend flow through the vertical axes and lead to \evalscope, which can show how group trends are associated with the inference results (details in the \evalscope section).


\subsection{Analytic pipeline}\label{sec:analytic}

The analytic pipeline, as shown in Fig.~ \ref{fig:system-task-analytic-pipeline}b, includes data processing and machine learning modules to extract information to be shown on the visualization interface. As complete details of the implementation are beyond the scope of this paper, here we provide our methodology for implementing the two major machine learning modules. We propose two machine learning algorithms to enhance the interpretability and explainability of group analysis: (1) Multi-task predictive model: We introduce a multi-task prediction neural architecture predicting jointly both group membership and attribute values from language sequences enables to extract attribute-wise linguistic cues as qualitative evidence from the attention mechanism with better predictive performance. (2) Contrastive explanatory model: We provide the module of generating contrastive explanations to present the minimal and sufficient information of group classification results. By leveraging a contrastive explanation approach \cite{van2018contrastive}, our pipeline introduces our criteria and methods to retrieve counterfactual examples in fact-foil tree in addition to explanation itself for better explainability.

\subsubsection{Generating Language Cues via Multi-task Prediction}\label{sec:multi}
\input{figures/model_diagram}
The {\it multi-task prediction models\footnote{The code is available at: \url{https://github.com/picsolab/TRIBAL-multi-task-prediction}}} are developed to extract text snippets as language cues from the tweet dataset. Compared to language models with a bottom-up approach for discovering latent dimensions of semantics such as topic modeling, our model was designed to enable the theory-driven analysis where attributes to be included in the analysis are given by users in a top-down manner, and allow them to find linguistic cues with respect to each attribute. Our model is thus advantageous in interpreting the group difference based on (a) attributes that are  theoretically meaningful (e.g., emotional/moral attributes) or (b) data-driven features indicative of behavioral patterns (e.g., the number of retweets). Language cues identified from the model allows users to make sense of an attribute (e.g., ``{\it What dose high \vale mean in this context}?'') through retrieving qualitative details from the tweet instances (e.g., ``{\it What would the language expressing high \vale look like from the \red or \blue groups}?'')  ({\bf T5}), which are shown in the \languagescope. To automatically learn the language cues that are {\it representative for both groups and attribute values}, we introduce a new multi-task prediction neural network architecture, where the objective is to jointly predict (a) attribute values and (b) group labels (\red or \blue) from the language sequence of a given tweet.  As a result, the neural network architecture can learn to identify what language sequences are more predictive to a particular group and attribute information. Because the representative language cues for different attributes will be different, we train a set of models with similar architectures but different objective functions (one model for each attribute).

Take the \vale attribute as an example. Fig~\ref{fig:multi-model} illustrates the neural network architecture that jointly predicts \vale value and group label. The input tweet text is represented by a pre-trained embedding, where each tweet word is represented as a high-dimensional vector. Due to the specific emphasis on sociolinguistic values in this context, we leverage two pre-trained embedding methods: (1) a word2vec \cite{mikolov2013efficient} embedding trained on a standard Twitter corpus \cite{baziotis2018ntua}, and (2) the attribute-aligned embedding trained with MimicProp algorithm \cite{yan2020mimicprop} that is optimized for sociolinguistic lexicons. We concatenate the two equal-sized embeddings to generate a 600-dimensional vector for each word.

Let the $\mat{X}= \{\vec{x}_{1}, \vec{x}_2, …, \vec{x}_t, ... \vec{x}_n\}$ represent the embedding language sequence for a tweet with $n$ words,  where $\vec{x}_t$ represents the embedding vector for the $t^{th}$ word in the tweet. Let $l$ and $s$ denote the ground-truth label and attribute value of a tweet. The objective is to minimize the total loss per tweet:
\begin{equation}
    loss = \lambda\cdot loss_{group}  + (1 - \lambda)\cdot loss_{attr},
\end{equation}

where the $loss_{group} = CrossEntropy(pr_{group}, l)$ is the cross-entropy loss for predicting group label by comparing the posterior label probability $pr_{group}$ with the true label $l$, and $loss_{attr} = MSE(logit_{attr}, s)$ is the mean squared error for predicting attribute value by comparing the logit $logit_{attr}$ with the true value $s$, and $\lambda$ is a hyper-parameter determining the trade-off between two types of loss. 

For continuous attributes (e.g., \vale in this case), we use $MSE(\cdot)$ to model the loss, whereas for categorical attributes, the loss is computed using $CrossEntropy(\cdot)$ similar to the loss for group prediction. We leverage a bi-LSTM encoder \cite{huang2015bidirectional} with an attention mechanism \cite{cho2014learning} in order to learn {\it which specific portion} of the language sequence serves predictive features to the prediction. The bi-LSTM encoder learns a latent representation recursively for an input word at location $t$, as $\vec{h}_t = f[(\vec{x}_t) , \vec{h}_{t-1}]$, with $\vec{h}_{0}$ a trainable bias parameter. The latent representation is then taken as the input for the attention layer to learn the attention weight $a_{t}$ by: $a_{t} = \frac{exp(e_{t})}{\sum_{k = 1}^{n}exp(e_{k})}, e_{t} = attn(\vec{h}_{t})$, where $attn(\cdot)$ is a dense layer with trainable weights $\vec{w}$ and bias parameter $b$ which transforms $\vec{h}_{t}$ as $e_{t} = \vec{w} \cdot \vec{h}_{t} + b$.
The latent vector $\vec{h}_{t}$ is then weighted by the learned attention weight $a_t$ as an input for the dense layers for computing the loss. 

The attention weights can be seen as the importance of each word in the prediction. As our goal is to retrieve a sequence (of consecutive words) rather than individual words, we compute the cumulative attention for a length-$k$ sequence $\vec{w} = \{w_i … w_{i+k-1}\}$ with attention weights $\vec{a} = \{a_i ... a_{i+k-1}\}$ where the length is determined when adding the next word to the current sequence decreases the mean attention of the sequence to a great extent (specifically, $k$ is automatically detected when increase of $k$ leads to the drop of mean attention exceeding a threshold $\theta = a_t - \frac{1}{2} \sigma^2(\vec{a})$). 

We evaluate our multi-task prediction models using a hold-out experiment. The experiment results suggest that our multi-task models can significantly improve group prediction without sacrificing the performance for single attribute prediction. 
In the experiments, we determine the hyperparameter $\lambda$ by searching on the space from 0 to 1 with 0.1 interval.
Our empirical results suggest 0.5 to be the optimal $\lambda$.
Experiment results reported in Section~\ref{sec:holdout} are all from models with $\lambda=0.5$.

Lastly, to compare the ``representativeness'' among all language sequences extracted from the data through this process, we define an importance score for each sequence based on four information criteria: (1) {\it Predictive Impact} reflects the predictive contribution of the sequence across all training tweet samples, which is computed as the percentile rank of the aforementioned cumulative attention for an extracted sequence. (2) {\it Concept Representativeness} captures how closely the tweet containing the sequence is aligned with the joint objective, which is measured using the normalized posterior probability of the tweet. (3) {\it Length} is the desired length of the extracted sequences, where longer sequences are usually preferred. (4) {\it Prevalence} reflect the frequency of an extracted sequence. While similar or identical sequences in the training data may aggregately achieve higher predictive power, retrieving similar sequences adds little to human interpretation. We thus consider the relative occurrence of a sequence in the data as an indicator for its (lack of) uniqueness. Together the four criteria are used to compute the sequence importance score as:
$\vec{w}_{seq} = \frac{p + log(l + \epsilon)}{r + log(f + \epsilon)}$,
where $\epsilon$ is a smoothing term, $p, l, r$ and $f$ denote the \textit{\textbf{p}osterior score}, \textit{sequence \textbf{l}ength}, \textit{attention weight \textbf{r}anking} and \textit{sequence \textbf{f}requency}, respectively. To enable users to retrieve language cues with different characteristics, the weights of the four criteria can be adjusted in the \scopecontroller as described in Section~\ref{sec:vis} (Fig.~\ref{fig:system-overview}b-iii).

\subsubsection{Generating Rationales via Contrastive Explanatory Models}\label{sec:contrastive-exp}

The {\it contrastive explanatory models} was developed to generate a rationale behind the membership classification of any given tweet ({\bf T6}). Instead of offering a more complete and well-rounded explanation, in this work, we leverage the contrastive explanation approach proposed by van der Waa et al. \cite{van2018contrastive} to generate a simple interpretation in a more user-friendly manner -- to present the minimal and sufficient information required to understand the current output by contrasting with another one that is absent. Specifically, we use fact-foil trees (locally trained one-versus-all decision trees) to identify the disjoint set of rules on important features to answer a question like ``{\it why this output (the fact) instead of that output (the foil)}?'' We further contextualize such question in our application scenario to produce two types of questions -- the {\it p-mode} (``{\it group \red instead of group \blue}?'') and {\it o-mode} (``{\it tweet X instead of tweet Y}?'') questions as described in \rationalescope (Section~\ref{sec:vis}). Our \textit{contrastive explanatory model} consists of three steps. The first and second steps were to generate a set of contrastive explanations from the decision rules based on the fact-foil tree model \cite{van2018contrastive}. However, there could be numerous instances falling into this explanation set, and showing all the instances will be overwhelming. Therefore, we introduce a third step to select contrastive examples that best represent a contrastive explanation.
\begin{enumerate}
\vspace{-0.2em}
\item {\it Identifying a foil leaf}: In a fact-foil decision tree, the leaves are considered as a contrasting unit of classification. 
We first identify a leaf that includes the selected instance of our interest (e.g., tweet $X$ classified as \red), and then find the counterfactual leaf to contrast the selected leaf (e.g., tweet $Y$ classified as \blue), with their differences extracted as an explanation. If a tweet $X$ is placed in leaf $l$, the contrastive leaf is the closest one but classified as \blue. 
\item {\it Generate contrastive explanation with decision rules}: In the decision tree, the decision rules along the path from the root to a selected leaf can be considered as a full explanation on why a tweet was classified as a certain class. To generate a minimal and sufficient explanation, we extract only the difference between the two paths to the fact and foil leaves. 
\item {\it Select a contrastive example}: To generate a contrastive explanation to show in the \rationalescope, we need not only the minimal information from the decision rules (about what attribute or attributes are most important) but also a tweet example to illustrate such decision rules. We identify the most appropriate tweet example within the set of instances that belong to the foil leaves based on two criteria -- the closest (base on Gower distance between the tweets' attribute values \cite{gower1971general}) and reliable (correctly classified as in another class/group) tweet. 
\end{enumerate}
