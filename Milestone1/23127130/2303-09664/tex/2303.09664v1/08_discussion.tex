\section{Discussion and Future Work}

\indent \textbf{Discussion.} We discuss the findings and feedback collected during the evaluation with domain experts, and the development process.

\begin{itemize}
    \item \textbf{System utility.} The feedback from the three domain experts are generally positive. The experts mostly agreed that the overall design of \name enabled them to immediately see the trends of each group and subgroup and was useful for testing and refining their analysis hypotheses. The \languagescope was heavily used by Experts 1 and 2 to find qualitative evidence either for supporting existing hypotheses or for generating a more in-depth understanding of how group members may behave differently. The \evalscope and \rationalescope were used more by Expert 3 who concerned the decisions derived from the data and prediction models. Interestingly, all three experts paid significant attention to the ``boundary'' of a group, and the system allows them to check the boundary from different perspectives -- the within-group variability (e.g., \variscope), the language diversity (\languagescope), and the edge cases (e.g., \evalscope).
    \item \textbf{Data generation policy.} Data about people may be generated through certain selection criteria or human coding. For example, our dataset was augmented with human-annotated labels and attributes. However, if the data generation process is not properly communicated, users may misuse or misinterpret the data. We recommend that the data generation policy should be made transparent to the users to the extent possible, and the communication of the data generation process should be incorporated into future design guidelines for accountable group-level analytics.
\end{itemize}


\textbf{Limitation and future work.} Despite that we define our system requirements to be applicable to general scenarios in group analysis, the illustration of our system in this paper is bound to the given dataset and scenario. We discuss the extandability of our system to broader settings of group analysis towards a variety of datasets and applications, and towards multiple groups and social issues. The following paragraphs summarize the limitation and future work with respect to each point.

\begin{itemize}
    \item \textbf{Generalizability.} Our system was demonstrated and evaluated with a twitter data described in Section \ref{sec:appanddata} with seven psycholinguistic attributes, however, we note that our system can incorporate any dataset with a set of attributes in different types (sentiment, topics, behavior, etc.), which are applicable to other domains such as education, business, etc (e.g., inspecting behavioral attributes in team communication). In practice, those attributes can be either manually annotated or automatically derived by automatic methods such as keyword count, latent representation, topic modeling, or log data. 
    While our visualization design is generally applicable for group analysis on text datasets, the language analysis component in the analytic pipeline has limitations. Our system assumes annotations were adequately generated along with the text corpora. Generating proper annotations for different kinds of text corpora -- including texts from various domains such as law, medical, and education -- is beyond the scope of this research. In this work, we use social media texts (tweets written in English) to demonstrate our framework, and thus the language models in our analytic pipeline are trained to have an optimal performance to process social media texts alike. Since the language models are sensitive to the text input, we recommend that the language models should be re-trained and tested based on the text input to ensure the best performance for different kinds of text corpora. Specialized text corpora that require more sophisticated natural language processing modules (e.g., sentence parsing, argument understanding) are also beyond the scope of this work.
    \item \textbf{Scalability.}
    The current design of \name is capable of summarizing group-level patterns, which can be considered as a way of information reduction from large dataset. Nevertheless, the current design is not scalable when exploring a larger number of instances and attributes. In our experiments to test the scalability with number of instances increasing from 3,000 to 20,000, we found that the system experienced degradation in rendering performance with more than 15,000 visual elements. The dataset we use in this paper has 3000 instances. This limited scalability can be potentially improved by using visual aggregation techniques such as edge bundling methods~\cite{holten2006hierarchical}. In case of the large set of attributes, we found that a dataset with more than 20 attributes does not allow enough room for vertical axes to be placed in the visual space. To cope with the issue, our current design supports users to pre-select a smaller set of attributes, which prevents visualization clutter (e.g., from showing too many horizontal axes in the \grouptrend) so the users can inspect the patterns in a more manageable way. 
    % \rev{DELETE THE RED PART. For example,  \grouptrend consists of visual components including polylines and vertical axes with complexity linear to the number of instances and attributes respectively. For the scalability issue with the large number of instances, we found that the system experienced degradation in the rendering performance with more than 15,000 visual elements according to our experiment for testing different number of instances ranging from 3,000 to 20,000 instances. The system is currently tolerable in this regard because there are currently 3,000 polylines, as many as the number of instances in our Twitter dataset. Based on our experiment, we designed our system to render up to 15,000 polylines which can be selected by their higher confidence towards either class (i.e., predictive probability) in the group prediction. This limited scalability also can be potentially improved by using visual aggregation techniques such as edge bundling methods~\cite{holten2006hierarchical}. In case of the large set of attributes, we found that a dataset with more than 20 attributes does not allow enough room for vertical axes to be placed in the visual space. To cope with the issue, our current design supports users to pre-select a smaller set of attributes.}. 
    Future work can consider incorporating feature selection techniques with filter methods~\cite{guyon2003introduction, chandrashekar2014survey} to help users identify the most interesting set of attributes given appropriate criteria.

    \item \textbf{Perceived reliability.} As described in the design guideline in Section \ref{sec:goalsandtasks}, our tool not only aims to interpret the group difference but supports examining the quality of the model. In the system, \evalscope, which encodes the predictions being rendered as bipolar chart, allows users to observe the distribution of predictions and interactively examine the instances, e.g., whether instances predicted as certain group have particular characteristics. This feature was highlighted by one of the expert interviewee (see Section \ref{sec:expert}) as a novel capability for users to calibrate their confidence of the machine learning model.
    Despite the novel feature, users with different knowledge about machine learning models may see the reliability of the model outcome differently, e.g., users may over-trust a model or overlook the statistical details of the model performance~\cite{nothdurftProbabilisticHumanComputerTrust2014, berkovskyHowRecommendUser2017}. Future work should examine how such ``perceive reliability'' impact the visual analytic system design.
    \item \textbf{Multiple groups.} The current design was optimized for contrasting the trends between two groups. This can be extended to visualize a few more groups -- e.g., by using the multi-color scheme, or using a dichotomous color scheme to generate the one-versus-all comparison. However, the representation of the boundary or edge cases may be not as efficient as that in the current scenario. Future work may explore other visualization and interactive design to help inspect the boundary cases in a multi-group scenario.
    \item \textbf{Multiple social issues.} In our current implementation, we only focus on a single social issue -- the gun-control debates. Future work may look at the group differences across multiple social issues, which creates another level of complexity for exploring the language and attribute distributions within and across groups. One may incorporate approaches such as dynamic queries (interaction), topic modeling (data mining) or hierarchical representation (visualization) to reduce complexity.
\end{itemize}