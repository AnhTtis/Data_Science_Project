% figure
\begin{figure*}[t]
\centering
\includegraphics[width=6in]{figs/multiscale.pdf}
\caption{{\bf Cross-scale Prediction.} Average pooling is used in encoding to progressively generate multiscale representations. The decoded/processed lower-scale attributes are used to approximate the attribute probability of the current scale. Rounding-based quantization is used. The scale-wise {quantization residual} is randomly distributed and compressed assuming the {uniform} distribution.  The SAPA leverages SparseCNN to effectively characterize neighborhood correlation for probability estimation.}
\label{fig:multiscale}
\end{figure*}


\begin{figure*}[b]
\centering
\includegraphics[width=5.5in]{figs/network.pdf}
\caption{{\bf SAPA.} SparseCNN-based Attribute Probability Approximation.}
\label{fig:network}
\end{figure*}


\section{Method}
Let {\{$x_i^{(S)},i=1,2,\ldots, N^{(S)}$\}} represent the original PCA tensor at the highest scale $S$. $N^{(S)}$ is the total number of positively-occupied voxels (POV) at scale $S$ and
$x_i^{(S)}$ is the attribute intensity for $i$-th POV which is an integer in general. Here single-channel attributes are exemplified with the intensities annotated  in Fig.~\ref{fig:multiscale}.


\subsection{Cross-scale Prediction}

\textbf{Average Pooling \& Quantization.}
As in Fig.~\ref{fig:multiscale}, for the {$s$-th} scale PCA tensor \{$\hat{x}_i^{(s)}, i=1,2,\ldots, N^{(s)}$\}, $k$ valid POVs in a $2\times2\times2$ cube are merged into one POV at $(s-1)$-th scale with its attribute value
%\begin{align}
    $x^{(s-1)} = \frac{1}{k}\sum_{m=1}^k\hat{x}_{m}^{(s)}$,
%\end{align}
 having ${k \in \{1,2,\cdots,8\}}$. 
% quantization
$x^{(s-1)}$ is then rounded to an integer, e.g., $\hat{x}^{(s-1)}=\lfloor x^{(s-1)} \rceil$, producing the residual $r^{(s-1)}=x^{(s-1)}-\hat{x}^{(s-1)} \in \{0,-\frac{1}{2},\cdots\}$ and the $(s-1)$-th scale tensor \{$\hat{x}_j^{(s-1)}$\}. The same pooling and quantization process will be repeated until the arrival of the lowest-scale tensor that only contains one POV as the global average of the input tensor, e.g., \{$\hat{x}_{j=1}^{(s=1)}$\}.  As a result, the PCAC problem is reformulated as the compression of 
% \delete{\{$\hat{x}_j^{(s)}$\} and \{${r}_j^{(s)}$\} with $s\in[1, S]$ and $j\in[1, N^{(s)}]$,} 
{\{$\hat{x}_i^{(s)}$\} and \{${r}_j^{(s-1)}$\} with $s\in[1, S]$,  $i\in[1, N^{(s)}]$ and $j\in[1, N^{(s-1)}]$},
where the key challenge is to estimate an accurate probability for each element to be coded. 


For the compression of quantized residual \{${r}_j^{(s-1)}$\}, we directly encode them under the uniform distribution, because it is randomly distributed among values 0, $-\frac{1}{k}$ and $\frac{1}{k}$. Here $k$ is the number of valid POVs in a local $2\times2\times2$ cube.
Next, to encode/decode each element in \{$\hat{x}_i^{(s)}$\},  $i\in[1, N^{(s)}]$,  we perform the probability estimation by using decoded lower-scale attributes \{$\hat{x}_j^{(s-1)}$\}, $j\in[1, N^{(s-1)}]$. More specifically, \{$\hat{x}_j^{(s-1)}$\} is first augmented with decoded quantization residual \{$r_j^{(s-1)}$\} to recover  \{$x_j^{(s-1)}=\hat{x}_j^{(s-1)}+r_j^{(s-1)}$\}.
Each element in \{$x_j^{(s-1)}$\} is associated with a corresponding $j$-th POV, which is then dyadically upscaled to eight child nodes as a local $2\times$2$\times2$ cube $j$. Since the geometry occupancy is available in advance, all $k$ valid POVs in this cube $j$ are filled  with the same attribute intensity $x_j^{(s-1)}$, e.g., 
% \delete{$\tilde{x}_m^{(s)} = x_m^{(s-1)}$, $m\in[1, k]$}
{$\{\tilde{x}_{m}^{(s)}\}_{j} = x_j^{(s-1)}$, $m\in[1, k]$; $\{\tilde{x}_{m}^{(s)}\}_{j}$ contains $k$ POVs in $j$-th $2\times$2$\times2$ cube}
% $\{\tilde{x}_{m}^{(s)}, m=1,2,\cdots,k\} = x_j^{(s-1)}$, 
\footnote{Normally $k<8$ because of the sparsity nature of the point clouds.}. Apparently, it is the unpooling process that  produces the upscaled tensor \{$\tilde{x}_i^{(s)}$\}.  Subsequently, this upscaled tensor \{$\tilde{x}_i^{(s)}$\} is fed into the SAPA to produce element-wise probability  for \{$\hat{x}_i^{(s)}$\}. This scale-wise processing is repeated across all scales.


\textbf{SAPA.} Figure~\ref{fig:network} shows the SAPA model which consists of multiple sparse convolutional layers (SConv), nonlinear activation layers (ReLU), and residual links. Let us take the process from the scale $s-1$ to  $s$ as an example. The input to the SAPA model is \{$\tilde{x}_i^{(s)}$\}, and the outputs are respective mean \{$\mu_i$\} and variance \{$\sigma_i$\} for each element in Laplacian distributed \{$\hat{x}_i^{(s)}$\}. As a result, the probability  can be computed by integrating the Laplacian distribution $\mathcal{L}$ via 
\begin{align}
    p(\{\hat{x}_i^{(s)}\}) 
    =\prod_i\nolimits\Bigl(\mathcal{L}(\mu_{i}, \sigma_{i})*\mathcal{U}(-\tfrac{1}{2},\tfrac{1}{2})\Bigr)(\hat{x}_{i}^{(s)})
    \quad
    \text{with~}\mu_i, \sigma_i=\text{SAPA}(\{\tilde{x}_i^{(s)}\}),
\label{eq:entropy}
\end{align} 
where $\mathcal{U}(-\tfrac{1}{2},\tfrac{1}{2})$ is the uniform distribution ranging from $-\tfrac{1}{2}$ to $\tfrac{1}{2}$. 
Finally, with the probability, we use arithmetic coding to losslessly encode the attribute intensity into the bitstream or decode it from the bitstream. The corresponding bits can be approximated using $R^{(s)} = \sum\nolimits_i-\log_2(p(\hat{x}_{i}^{(s)}))$.



\subsection{Cross-group Prediction}


\begin{figure*}[t]
\centering
\includegraphics[width=5.6in]{figs/multistage.pdf}
\caption{{\bf Cross-group Prediction.} Group-wise processing improves the probability estimation through the utilization of lower-scale and inter-group correlations while still maintaining high-throughput computation due to intra-group parallel processing.}
\label{fig:multistage}
\end{figure*}

\begin{figure*}[b]
\centering
\includegraphics[width=4in]{figs/multichannel.pdf}
\caption{{\bf Cross-color Prediction.} Color-wise processing further exploits cross-color redundancy. YCoCg color space is used following the same rule in G-PCC~\cite{GPCC}.}
\label{fig:multichannel}
\end{figure*}

In addition to cross-scale prediction, the accuracy of probability estimation can be further improved by implementing cross-group prediction at the same scale.
As in Fig.~\ref{fig:multistage}, after the dequantization (dQ) and unpooling operations, each POV in the scale $(s-1)$ is expanded to a local 2$\times$2$\times$2 cube with eight child nodes which are partitioned into eight groups {$\{\hat{x}^{(s,g)}, g=1,2,\cdots,8\}$,} according to the geometric positions depicted in the bottom-right part of the plot. Since we have the full knowledge of geometry occupancy,  $k$ valid POVs in this local cube are properly filled with attribute intensities from {\{$\tilde{x}_i^{(s)}$\}}, which are unpooled from the lower-scale as mentioned above.

% multistage
We then  group-wisely process the probability prediction and encode/decode associated attributes of corresponding POVs from one group to another. For those POV elements in the same group {$\{\hat{x}_{i}^{(s,g)}\}$}, parallel computations are applied.
%in a multi-stage manner. 
The SAPA model mentioned above inputs the attribute of valid neighbors in close proximity, e.g., some are already decoded (or inferred) and some are initiated using \{$\tilde{x}_i^{(s)}$\} upscaled from the decoded lower-scale attributes, to derive more accurate probability for the attribute compression of upcoming POVs. 

% update
An additional Update step is introduced at each stage to correct the attribute of those unprocessed POVs initiated using  \{$\tilde{x}_i^{(s)}$\} with the help of previously-processed POVs in proceeding groups, i.e., 
\begin{equation}
    \text{U}(\hat{x}_{i}^{(s,m)}) = \frac{k \times x^{(s-1)} - \sum (\hat{x}^{(s,1)}, \hat{x}^{(s,2)},\cdots,\hat{x}^{(s,g)})}{k-g}
    \quad
    \text{with~} g < m \leq 8.
    \label{eq:update}
\end{equation}
where $\{\hat{x}^{(s,1)},\hat{x}^{(s,2)},\cdots,\hat{x}^{(s,g)}\}$ are processed groups, $\{\hat{x}_{i}^{(s,m)}, m=g+1, \cdots, 8\}$ are unprocessed groups, 
$x^{(s-1)}$ are the average values of these groups generated by $2\times2\times2$ average pooling aforementioned, and $k$ is the number of POVs in each $2\times2\times2$ cube.
This Update process initializes a more accurate attribute value for subsequent computations.
When there is only one unprocessed POV left in each $2\times2\times2$ cube, we can directly infer its ground-truth value without any signaling. 
In total, we only need to compress $N^{(s)} - N^{(s-1)}$ attribute values of POVs at the scale $s$, further saving the compression bitrate.


\subsection{Cross-color Prediction}

Inspired by inter-color correlations studied in~\cite{CCP_HEVC}, we propose the cross-color prediction that first processes the Y channel component, then the Co with the help of Y and Cg with the help of both Y and Co. To accelerate the prediction speed, we process Co and Cg components in parallel in our implementation as shown in Fig.~\ref{fig:multichannel}.  




