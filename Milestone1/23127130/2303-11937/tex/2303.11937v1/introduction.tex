% \vspace{-2mm}
\section{INTRODUCTION}
While in general set functions are hard to optimize over, the subclass of submodular functions have useful properties that allow us to predictably achieve a certain approximation of the true optimal value in polynomial time \cite{wolsey1982analysis}. Submodular functions exhibit a natural diminishing returns property and appear in a wide variety of applications such as sensor placement \cite{10.1145/1127777.1127782}, graph cuts \cite{Jegelka2011SubmodularityBS}, data summarization \cite{Lin2011ACO}, marketing \cite{Kempe2003Maximizing} and clustering \cite{NIPS2005_b0bef4c9}. Thus, theoretical bounds on what optimization methods can achieve have important real-world implications. Continuous submodular functions (CSF) extend the notion of submodularity to continuous domains and provide an interesting class of non-convex functions that are still tractable to optimize over \cite{bian2017guaranteed}. 
CSFs have several applications, including non-convex/non-concave quadratic programming \cite{bian2017guaranteed}, robust budget allocation \cite{staib2017robust,soma2017non}, sensor energy management \cite{bian2017guaranteed}, online resource allocation \cite{eghbali2016designing}, learning assignments \cite{golovin2014online}, and e-commerce and advertising \cite{mehta2007adwords}.
In addition, they enable solving many discrete submodular problems efficiently through their
continuous relaxation such as multi-linear \cite{doi:10.1137/110839655} or Lovas extensions \cite{lovasz1982}. 
This has motivated a body of work on optimizing CSFs 
\cite{bian2017continuous,bian2017guaranteed,chekuri2015multiplicative}. 

More recently, constrained maximization of \textit{stochastic} submodular functions has gained a lot of attention \cite{Hassani2017gradient,karbasi2019stochastic,mokhtari2018conditional, zhang2022stochastic}. A stochastic CSF can be formulated as the expected value of 
stochastic functions $\Fn:\X\times\Z\rightarrow\R_+$:
\begin{equation}\label{eq:problem}
    \max_{\x\in \C} F(\x) = \max_{\x\in \C}\mathbb{E}_{\z\sim P}[ \Fn(\x, \z)],
\end{equation}
where $\C\subseteq \R^d_+$ is a bounded convex set,
$\x \!\in\! \X$ is the optimization variable, 
and $\z\!\in\!\Z$ is a random variable drawn from a (potentially unknown) distribution $P\!$.
Note that Problem \eqref{eq:problem} only assumes that $F(\x)$ is DR-submodular, and not necessarily the stochastic functions $\Fn(\x, \z)$. 
The continuous greedy algorithm \cite{bian2017guaranteed} can produce arbitrarily bad
solutions for Problem \eqref{eq:problem}, due to the non-vanishing variance of gradient approximations \cite{Hassani2017gradient}.
To address this, Projected Gradient Ascent (PGA) with diminishing step-sizes is first %proposed and 
shown to provide a $[OPT/2\!-\!\epsilon]$ guarantee \cite{Hassani2017gradient}.
Later, Stochastic Continuous Greedy (SCG) suggested to reduce the noise of gradient approximations via a momentum term and provided a tight $[(1\!-\!1/e)OPT\!-\epsilon]$ guarantee \cite{mokhtari2018conditional}.
This work was followed by Stochastic Continuous Greedy++ (SCG++), which improved the complexity of SCG \cite{karbasi2019stochastic}, by leveraging a variance reduction technique %, namely SPIDER
\cite{fang2018spider}. {Most recently, boosted PGA algorithm using a non-oblivious function is proposed \cite{zhang2022stochastic}, which also achieves a $[(1\!-\!1/e)OPT\!-\epsilon]$ approximation guarantee. }\looseness=-1

However, the above algorithms only guarantee the performance of the solution \textit{in expectation}.
This implies that it is indeed possible that for a particular run of the algorithms, the optimizer gets extremely unlucky with its gradient estimates, and return a solution that is drastically 
worse than the provided guarantee in expectation.
Indeed, as we confirm by our experiments, all the algorithms for stochastic CSF, namely PGA, {boosted PGA}, SCG, and SCG++, 
may have a very high variance in their returned solution, as the noise gets larger. Crucially, the provided expectation bounds do not provide much insight, besides perhaps a basic Markov inequality, into the probability of getting these bad solutions.
%%%%%%%%%%%%%%%%%%%
This is because expected guarantees 
rely on bounding the variance of the gradient estimation error, and cannot bound the total accumulated error required for deriving high probability bounds. \looseness=-1
%%%%%%%%%%%%%%%%%%%%%

In this paper, we address the above question by providing the first 
high probability analysis of the existing methods for stochastic CSF maximization.
%%%%%%%%%%%%%%%
% While 
High-probability bounds have been explored very recently for 
the most popular optimization methods, namely, SGD \cite{harvey2019simple}, and momentum SGD \cite{li2020high}.
But, deriving high-probability bounds
for submodular optimization has remained unaddressed.
Different than the analysis of the expectation bounds for stochastic CSF maximization algorithms \cite{Hassani2017gradient,karbasi2019stochastic,mokhtari2020stochastic}, our analysis leverages two different strategies to bound the distance between the algorithmic solution and the optimal value. The first strategy is using a martingale process to model functions of the gradient noise, allowing for the use of Azuma-Hoeffding inequality to provide high-probability bounds on the algorithmic solution. The second strategy is to use Chebyshev's inequality to bound
sum of squared errors in gradient estimators, with a high probability. 
Table \ref{tbl:summary} summarizes our results.\looseness=-1

Our contributions are as follows.  
We derive the first high-probability analysis for stochastic CSF methods (under the same assumptions used for their expectation bounds), and show that after $K$ queries to the stochastic gradient oracle:
\begin{itemize}
    \vspace{-2mm}\item 
    For Projected Gradient Ascent (PGA) \cite{Hassani2017gradient} {and Boosted PGA \cite{zhang2022stochastic},} the lower-bound on the average function value during a run of the algorithm converges at rate $O(\frac{1}{K^{1/2}})$. 
    
    \vspace{-1mm}\item For Stochastic Continuous Greedy (SCG) \cite{mokhtari2018conditional}, the lower-bound on the final solution
    %leads to worst-case 
    converges at rate $\mathcal{O}(\!\frac{\delta}{K^{1/3}})$, where $\delta$ depends on the confidence threshold.
    
    \vspace{-1mm}\item For Stochastic Continuous Greedy++ (SCG++)  \cite{karbasi2019stochastic}, the lower-bound on the final solution converges at rate 
    $\!\mathcal{O}(\!\frac{\delta}{K^{1/4}})$, where $\delta$ depends on the confidence threshold. 
    
    
    \vspace{-1mm}\item 
    Under the sub-Gaussian assumption on the stochastic gradient oracle, we derive an improved high-probability bound on the final solution of SCG that converges to $(1-\frac{1}{e})OPT$ at a faster $\mathcal{O}(\frac{1}{K^{1/2}})$ rate. Interestingly, this rate even exceeds the %previous best 
    rate of convergence to the
    \emph{expected} solution provided by \cite{mokhtari2018conditional}.
    %%%%%%%%%%%%%%
    Our analysis involves providing the first high probability bound for adaptive momentum optimization methods, which can be  applied to other smooth function classes to provide superior convergence and generalization properties \cite{sun2021training}. Hence, it is of independent interest.
    
    \vspace{-1mm}\item Our extensive experiments on a non-concave quadratic programming example (NQP) and a realistic optimal budget allocation problem
    confirm the validity of our bounds and show that even in the worst-case PGA still converges to the $OPT/2$, 
    and  
    boosted PGA,
    SCG, SCG++ still converge to $(1\!-\!1/e)OPT$, 
    but at a slower rate. \looseness=-1
\end{itemize}
\vspace{-2mm}
Our results characterize the full distribution of the solutions for stochastic CSF maximization methods. In doing so, they allow an algorithm designer to answer questions about worst and best-case performance and even make modifications to mitigate the risk of getting a {bad solution}. 
%%%%%

\begin{table*}[t]
\centering
\caption{Comparison of existing expectation and our high-probability bounds for three stochastic monotone DR-submodular maximization algorithms, namely PGA, SCG, SCG++. Here $k$ is the number of queries to the stochastic gradient oracle $\nabla \Fn$. Note that while our original bound is not tight for SCG, by using the slightly stronger condition of a sub-Gaussian gradient noise one can achieve an $\mathcal{O}(1/K^{1/2})$ bound (see Sec. \ref{sec:improve_bounds}).}
    \begin{tabular}{l|lll}
    \toprule
    \textbf{Algorithm} & \textbf{Expectation Bound}                            & \textbf{Original Noise Assumptions}                                                      & \textbf{Bound Converges w.h.p?} \\ \midrule
    PGA \cite{Hassani2017gradient}                & $(\frac{1}{2})OPT - \mathcal{O}(\frac{1}{K^{1/2}})$   & $\nabla \tilde{F}$ bounded                                                        & Yes, at $\mathcal{O}(1/K^{1/2})$ rate                           \\
    {Boosted PGA \cite{zhang2022stochastic} }               & $(1-\frac{1}{e})OPT - \mathcal{O}(\frac{1}{K^{1/2}})$   & $\nabla \tilde{F}$ bounded                                                        & Yes, at $\mathcal{O}(1/K^{1/2})$ rate                           \\
    SCG \cite{mokhtari2018conditional}                & $(1-\frac{1}{e})OPT - \mathcal{O}(\frac{1}{K^{1/3}})$ & $Var(\nabla \tilde{F})$ bounded, sub-Gaussian*                                                   & Yes*, at $\mathcal{O}(1/K^{1/2})$ rate                                                              \\
    SCG++ \cite{karbasi2019stochastic}              & $(1-\frac{1}{e})OPT - \mathcal{O}(\frac{1}{K^{1/2}})$ & $\tilde{F}, \nabla \tilde{F}, \nabla^2\tilde{F}, \log(p(\z))$ bounded & Yes, at $\mathcal{O}(1/K^{1/4})$ rate \\\bottomrule
    \end{tabular}
\label{tbl:summary}
\end{table*}