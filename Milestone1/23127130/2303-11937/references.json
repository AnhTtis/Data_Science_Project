{
  "2110-09057": {
    "title": "Training Deep Neural Networks with Adaptive Momentum Inspired by the Quadratic Optimization",
    "authors": [
      "Tao Sun",
      "Huaming Ling",
      "Zuoqiang Shi",
      "Dongsheng Li",
      "Bao Wang"
    ],
    "submission_date": "2021-10-18",
    "revised_dates": [],
    "arxiv_id": "2110.09057",
    "venue": "arXiv.org",
    "year": 2021
  },
  "2007-14294": {
    "title": "A High Probability Analysis of Adaptive SGD with Momentum",
    "authors": [
      "Xiaoyun Li",
      "Francesco Orabona"
    ],
    "submission_date": "2020-07-28",
    "revised_dates": [],
    "arxiv_id": "2007.14294",
    "venue": "arXiv.org",
    "year": 2020
  },
  "1909-00843": {
    "title": "Simple and optimal high-probability bounds for strongly-convex stochastic gradient descent",
    "authors": [
      "Nicholas J. A. Harvey",
      "Christopher Liaw",
      "Sikander Randhawa"
    ],
    "submission_date": "2019-09-02",
    "revised_dates": [],
    "arxiv_id": "1909.00843",
    "venue": "arXiv.org",
    "year": 2019
  },
  "1807-01695": {
    "title": "SPIDER: Near-Optimal Non-Convex Optimization via Stochastic Path Integrated Differential Estimator",
    "authors": [
      "Cong Fang",
      "C. J. Li",
      "Zhouchen Lin",
      "T. Zhang"
    ],
    "submission_date": "2018-07-01",
    "revised_dates": [],
    "arxiv_id": "1807.01695",
    "venue": "Neural Information Processing Systems",
    "year": 2018
  },
  "1804-09554": {
    "title": "Stochastic Conditional Gradient Methods: From Convex Minimization to Submodular Maximization",
    "authors": [
      "Aryan Mokhtari",
      "Hamed Hassani",
      "Amin Karbasi"
    ],
    "submission_date": "2018-04-24",
    "revised_dates": [],
    "arxiv_id": "1804.09554",
    "venue": "Journal of machine learning research",
    "year": 2018
  },
  "1711-02515": {
    "title": "Continuous DR-submodular Maximization: Structure and Algorithms",
    "authors": [
      "Yatao Bian",
      "K. Levy",
      "Andreas Krause",
      "J. Buhmann"
    ],
    "submission_date": "2017-11-04",
    "revised_dates": [],
    "arxiv_id": "1711.02515",
    "venue": "Neural Information Processing Systems",
    "year": 2017
  },
  "1711-01660": {
    "title": "Conditional Gradient Method for Stochastic Submodular Maximization: Closing the Gap",
    "authors": [
      "Aryan Mokhtari",
      "S. Hassani",
      "Amin Karbasi"
    ],
    "submission_date": "2017-11-01",
    "revised_dates": [],
    "arxiv_id": "1711.01660",
    "venue": "International Conference on Artificial Intelligence and Statistics",
    "year": 2017
  },
  "1708-03949": {
    "title": "Gradient Methods for Submodular Maximization",
    "authors": [
      "Hamed Hassani",
      "M. Soltanolkotabi",
      "Amin Karbasi"
    ],
    "submission_date": "2017-08-13",
    "revised_dates": [],
    "arxiv_id": "1708.03949",
    "venue": "Neural Information Processing Systems",
    "year": 2017
  },
  "1702-08791": {
    "title": "Robust Budget Allocation Via Continuous Submodular Functions",
    "authors": [
      "Matthew Staib",
      "S. Jegelka"
    ],
    "submission_date": "2017-02-28",
    "revised_dates": [],
    "doi": "10.1007/s00245-019-09567-0",
    "arxiv_id": "1702.08791",
    "venue": "Applied Mathematics and Optimization",
    "year": 2017
  },
  "1702-02030": {
    "title": "Empirical Risk Minimization for Stochastic Convex Optimization: $O(1/n)$- and $O(1/n^2)$-type of Risk Bounds",
    "authors": [
      "Lijun Zhang",
      "Tianbao Yang",
      "Rong Jin"
    ],
    "submission_date": "2017-02-07",
    "revised_dates": [],
    "arxiv_id": "1702.02030",
    "venue": "Annual Conference Computational Learning Theory",
    "year": 2017
  },
  "1612-00960": {
    "title": "Non-Monotone DR-Submodular Function Maximization",
    "authors": [
      "Tasuku Soma",
      "Yuichi Yoshida"
    ],
    "submission_date": "2016-12-01",
    "revised_dates": [],
    "doi": "10.1609/aaai.v31i1.10653",
    "arxiv_id": "1612.00960",
    "venue": "AAAI Conference on Artificial Intelligence",
    "year": 2016
  },
  "1606-05615": {
    "title": "Guaranteed Non-convex Optimization: Submodular Maximization over Continuous Domains",
    "authors": [
      "Yatao Bian",
      "Baharan Mirzasoleiman",
      "J. Buhmann",
      "Andreas Krause"
    ],
    "submission_date": "2016-06-17",
    "revised_dates": [],
    "arxiv_id": "1606.05615",
    "venue": "International Conference on Artificial Intelligence and Statistics",
    "year": 2016
  },
  "1407-1082": {
    "title": "Online Submodular Maximization under a Matroid Constraint with Application to Learning Assignments",
    "authors": [
      "D. Golovin",
      "Andreas Krause",
      "Matthew J. Streeter"
    ],
    "submission_date": "2014-07-03",
    "revised_dates": [],
    "arxiv_id": "1407.1082",
    "venue": "arXiv.org",
    "year": 2014
  },
  "1105-4593": {
    "title": "Submodular function maximization via the multilinear relaxation and contention resolution schemes",
    "authors": [
      "C. Chekuri",
      "Jan Vondr'ak",
      "R. Zenklusen"
    ],
    "submission_date": "2011-05-23",
    "revised_dates": [],
    "doi": "10.1145/1993636.1993740",
    "arxiv_id": "1105.4593",
    "venue": "SIAM journal on computing (Print)",
    "year": 2011
  },
  "2201-00703": {
    "title": "Stochastic Continuous Submodular Maximization: Boosting via Non-oblivious Function",
    "authors": [
      "Qixin Zhang",
      "Zengde Deng",
      "Zaiyi Chen",
      "Haoyuan Hu",
      "Yu Yang"
    ],
    "submission_date": "2022-01-01",
    "revised_dates": [],
    "arxiv_id": "2201.00703",
    "venue": "International Conference on Machine Learning",
    "year": 2022
  }
}