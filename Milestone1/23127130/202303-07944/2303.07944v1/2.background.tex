\section{Related Work}

\subsection{Remote Photoplethysmography (rPPG)}
The primary class of approaches for remote pulse estimation have shifted over the last decade from blind source separation~\cite{Poh2010,Poh2011}, through linear color transformations~\cite{DeHaan2013,DeHaan2014,Wang2017,Wang2019} to training supervised deep learning-based models~\cite{Niu2018,Chen2018,Yu2019,Niu2020,Liu_MTTS_2020,Lee_ECCV_2020,Lu2021,Speth_CVIU_2021,Zhao_2021,Yu_2022_CVPR}. While the color transformations generalize well across many datasets, deep learning-based models give better accuracy when tested on data from a similar distribution to the training set. To this end, deep learning research has focused on optimizing neural architectures for extracting robust spatial and temporal features from the limited benchmark datasets.

To get around the data bottleneck, large synthetic physiological datasets have recently been proposed~\cite{Kadambi2022,mcduff2022scamps}. The SCAMPS dataset~\cite{mcduff2022scamps} contains videos for 2,800 synthetic avatars in various environments with a range of corresponding labels including PPG, EKG, respiration, and facial action units. The UCLA-synthetic dataset~\cite{Kadambi2022} contains 480 videos, and they show that training models with real and synthetic data gives the best results. Another strength of synthetic datasets is their ability to cover the broad range of skin tones, which may be difficult when collecting real data.

Another solution to the lack of physiological data is unsupervised learning, where a large set of videos and periodic priors on the output signal is sufficient~\cite{Gideon_2021_ICCV,Sun_2022_ECCV,Wang_SSL_2022,Yuzhe_SimPer_2022}. We discuss these methods in more detail in section \ref{sec:background_SSL_rPPG}.

\subsection{Unsupervised Learning}
Self-supervised learning is progressing quickly for image representation learning. Two main classes of approaches have been competing: contrastive and non-contrastive (or regularized) learning~\cite{bardes2022vicreg}. Contrastive approaches~\cite{Misra2019,Caron2020, Chen2020} define criteria for distinguishing whether two or more samples are the same or different, then pull or push the predicted embeddings. Non-contrastive methods augment positive pairs, and enforce variance in the predictions over batches to avoid {\it collapse}, in which the model's embeddings reside in a small subspace of the feature space, instead of spanning a larger or entire embedding space~\cite{bardes2022vicreg}. Distillation methods only use positive samples and avoid collapse by applying a moving average and stop-gradient operator~\cite{Grill2020,Chen2021}. Another class of approaches maximize information content of embeddings~\cite{Zbontar2021,ermolov2021whitening}.

\subsection{Unsupervised Learning for rPPG}\label{sec:background_SSL_rPPG}
All existing unsupervised rPPG approaches are contrastive~\cite{Gideon_2021_ICCV,Sun_2022_ECCV,Wang_SSL_2022,Yuzhe_SimPer_2022}. In the contrastive framework, pairs of input videos are input to the same model, and the predictions over similar videos are pulled closer, while the predictions from dissimilar videos are repelled.

Gideon \etal~\cite{Gideon_2021_ICCV} were the first to train a deep learning model without labels for rPPG using the contrastive framework. The core of their approach is frequency resampling to create negative samples. Although spatially similar, a resampled video clip contains a different underlying pulse rate, so the model must learn to attend to the temporal dynamics.
For their distance function between pairs, they calculated the mean square error between power spectral densities of the model's waveform predictions. While their approach learns to estimate the pulse, their formulation with negative samples is imprecise.
The resampled frequency for the negative sample is known, so the relative translation of the power spectrum from the anchor sample can be directly computed. Thus, rather than repelling the estimated spectra, it is more accurate to penalize differences from the known spectra. Furthermore, resampling close to the original sampling rate causes overlap in the power spectra, so repelling the pair is inaccurate.

Yuzhe \etal~\cite{Yuzhe_SimPer_2022} incorporated the previously ignored resampling factor for a soft modification to the InfoNCE loss~\cite{Oord2018} that scales the desired similarity between pairs by their relative sampling rate. A downside is that their learning framework is not end-to-end unsupervised and requires fine-tuning with PPG labels after the self-supervised stage.

Differently from \cite{Gideon_2021_ICCV}, Contrast-Phys~\cite{Sun_2022_ECCV} and SLF-RPM~\cite{Wang_SSL_2022} consider all samples different from the anchor to be negatives. This assumes that the power spectra will vary between subjects or sufficiently long windows for the same subject.
This runs into similar issues with negative pairs as Gideon's approach. Different subjects may have the same pulse rate, so punishing the model for predicting similar frequencies is common during training.
Furthermore, the Fast Fourier Transform (FFT) does not produce perfectly sparse decompositions, resulting in spectral overlap even if the heart rate differs by several beats per minute (bpm). As an example, the last column of the second row in Fig. \ref{fig:losses} shows the nulls of the main lobe are nearly 30 bpm apart.
% Furthermore, even if the heart rate differs by several beats per minute (bpm), the Fast Fourier Transform (FFT) does not produce perfectly sparse decompositions (see last column of second row in Fig. \ref{fig:losses}, where the nulls of the main lobe are nearly 30 bpm apart), resulting in significant spectral overlap.

