\subsection{Losses}

\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{figures/losses.png}
    \caption{Each column shows predictions from models trained with one or all of the losses for 20 epochs on UBFC-rPPG. The first two rows show a sample in the time and frequency domain, respectively. The last row shows the signal power over the validation set computed by taking the sum of normalized power spectral densities from each sample, then dividing the result by the number of validation samples. The \textbf{bandwidth} loss penalizes signal power outside predefined bandlimits (40 to 180 bpm) to constrain the output space. The \textbf{sparsity} loss encourages a narrow spectrum containing a strong periodic component. By itself, the model learns the simplest solution characterized by very low frequencies. The \textbf{variance} loss encourages diverse power spectra over a batch, preventing the model from collapsing to a narrow bandwidth. When \textbf{combined}, the model learns to estimate periodic signals within the desired bandlimits.}
    \label{fig:losses}
\end{figure*}

One of the advantages of unsupervised learning for periodic signals is that we can constrain the solution space significantly. For physiological signals such as respiration and blood volume pulse, we know the healthy upper and lower bounds of the frequencies. We also desire the extracted signal to be sparse in the frequency domain, and that our model filters out noise signals present in the video. With these constraints, we can greatly simplify the problem of finding good features for the desired signal in the data.

\subsubsection{Bandwidth Loss}
One of the most powerful constraints we can place on the model is frequency bandlimits. Past unsupervised methods have used the irrelevant power ratio (IPR) as a validation metric~\cite{Gideon_2021_ICCV,Gideon_2021_ICCVW,Sun_2022_ECCV} for model selection. We find that it is also effective during model training. The IPR penalizes the model for generating signals outside the desired bandlimits. With lower and upper bandlimits of $a$ and $b$, respectively, our bandwidth loss becomes:
\begin{equation}\label{eq:L_b}
    L_b = \dfrac{\sum\limits_{i=-\infty}^a F_i + \sum\limits_{i=b}^{\infty} F_i}{\sum\limits_{i=-\infty}^\infty F_i},
\end{equation}
\noindent
where $F_i$ is the power in the $i$th frequency bin of the predicted signal. This simple loss enforces learning of many invariants, such as movement from respiration, talking, or facial expressions which typically occupy low frequencies. In our experiments we specify the limits as $a=0.\overline{66}$ Hz to $b=3$ Hz, which corresponds to a common pulse rate range from 40 bpm to 180 bpm. The first column of Fig. \ref{fig:losses} shows the result of training exclusively with the bandwidth loss $L_b$. The last row shows that the model concentrates signal power between the bandlimits.

\subsubsection{Sparsity Loss}
The pulse rate is the most common physiological marker associated with the blood volume pulse. Since we are primarily interested in the frequency, we can further improve our model by preventing wideband predictions. This also reveals the true signal we aim to discover by ignoring visual dynamics that are not strongly periodic.

We penalize energy within the bandlimits that is not near the spectral peak:
\begin{equation}\label{eq:L_s}
    L_s = \dfrac{\sum\limits_{i=a}^{\mathrm{argmax}(F) - \Delta_F} F_i + \sum\limits_{i=\mathrm{argmax}(F) + \Delta_F}^b F_i}{\sum\limits_{i=a}^b F_i},
\end{equation}
where $\mathrm{argmax}(F)$ is the frequency of the spectral peak, and $\Delta_F$ is the frequency padding around the peak.
All experiments are performed with a $\Delta_F$ of 6 beats per minute~\cite{Nowara_BOE_2021}. Figure \ref{fig:losses} shows result of training only with the sparsity loss in the second column. For a single sample, the power spectrum is very sparse. For the whole dataset, we see that it is easiest to predict sparse solutions when high frequencies are ignored entirely and visual features corresponding to low frequencies are learned. 

\subsubsection{Variance Loss}
One of the risks of non-contrastive methods is the model collapsing into trivial solutions and making predictions independently of the input features. In regularized methods such as VICReg~\cite{bardes2022vicreg}, a hinge loss on the variance over a batch of predictions is used to enforce diverse outputs. We use a similar strategy to avoid model collapse, but instead spread the variance in power spectral densities towards a uniform distribution over the desired frequency band.
Our variance loss processes a uniform prior distribution $P$ over $d$ frequencies, and a batch of $n$ spectral densities, $F = [v_1,...,v_n]$, where each vector is a $d$-dimensional frequency decomposition of a predicted waveform. We calculate the normalized sum of densities over the batch, $Q$, and define the variance loss as the squared Wasserstein distance~\cite{hou_emd_2017} to the uniform prior:
\begin{equation}
    L_v = \frac{1}{d} \sum_{i=1}^d \left( \mathrm{CDF}_i(Q) - \mathrm{CDF}_i(P) \right)^2,
\end{equation}
\noindent
where CDF is a cumulative distribution function. The third column of Fig. \ref{fig:losses} shows the effect of the variance loss during training. For a single sample, wide-band signals containing multiple frequencies are predicted, and the frequencies over the predicted dataset cover the task's bandwidth. In our experiments we use a batch size of 20 samples. See Appendix \ref{sec:app_batch_size} for an ablation experiment on the impact of smaller batch sizes.

\subsubsection{Combining All Losses}
Summarizing, our training loss function is a simple sum of the aforementioned losses:
\begin{equation}
    L = L_b + L_s + L_v.
\end{equation}
While one could weight particular components of the loss more than others, we specifically formulated the losses to scale them between 0 and 1. In our experiments, we find that a simple summation without weighting gives good performance. \textbf{The combined loss function encourages the model to search over the supported frequencies to discover visual features for a strong periodic signal.} Remarkably, we find that this simple framework is sufficient for learning to regress the blood volume in video, as shown in the last column of Fig. \ref{fig:losses}.

% One of the strengths of this loss is that it allows us to specify the prior, $P$. If the distribution of frequencies in the training environment is well-known, it can further guide the model to the desired signal. For example, if data was collected while subjects were at rest the prior could have more weight near low pulse rates, since high frequencies found during adverse health events or exercise would be unlikely. 


% \subsection{Equivariance Loss}
% The role of the signal priors losses is intuitive and perhaps simple for the model to learn. However, without the aid of the equivariance loss, the model is free to effectively ignore the input. For example, consider a model trained with only bandwidth and sparsity criteria. The simplest solution for the model is to produce a single frequency within the bandwidth bounds regardless of the input.

% Model collapse is typically avoided in two ways for unsupervised methods. Contrastive learning repels the outputs between an anchor sample and a negative sample. Since negative pairs are shown throughout training, the model quickly finds features in the input space that separate the samples. In many cases this leads to useful feature extraction, and enforces a dependence on the input, thereby avoiding collapse.

% Non-contrastive methods, also called regularized methods~\cite{bardes2022vicreg}, avoid negative samples entirely by penalizing low variance in the predictions over a batch. This avoids collapse by giving high loss values if the model settles on predicting a constant value.

% While past unsupervised rPPG papers rely on contrastive methods, we show that a regularized approach lends itself nicely to the signal regression problem, and even argue that the contrastive approach is imprecise in previous rPPG works. The rest of this paper will focus on the regularized formulation.

% Initially, the bandwidth, sparsity, and variance losses may seem sufficient for learning periodic signals from video. Empirically, we find they are ineffective at enforcing a useful dependence between the input and prediction. In fact, we believe the models can amplify subtle
% features in the inputs to get variance over the outputs, yet the predictions are entirely useless. Surpassing this hurdle is perhaps the most difficult for unsupervised signal regression. To address this, we propose another loss function between a sample that has undergone two independent equivariant transformations.

% Equivariant transformations are uniquely simple for the rPPG problem for two reasons. The first is that our predictions lie on a shared domain with the input. Specifically, transformations to the video along the time domain can act equivalently on the underlying pulse signal. Equation 1 reflects the invariance property, where predicting over a transformed input should produce the same result as transforming the prediction over the original input.

% Secondly, we know that the cardiac pulse is quasi-periodic, with limits to the changes in frequency over short time periods. We select short windows, so the signal power is concentrated on a single frequency for the entirety of the sequence. By assuming periodicity, we can apply resampling and interpolation on the input samples with an understanding of the effects on the
% frequency of the underlying signal.

% Consider a video clip, $X$, with $N$ frames, and accordingly, $N$ uniformly spaced samples to predict on the cardiac pulse, $Y$. The sampling frequency of $X$ and $Y$ is that of the video's frame rate, and is considered the reference frequency, $s$. Accordingly, the samples are $N/s$ seconds. Since most deep learning models consume static input dimensions, we scale the frequency by adjusting the time length of the clip, then linearly interpolate the video clip back to N frames.

% Figure 1 shows an example of resampling a video clip by linearly interpolating to $N$ frames between adjusted time endpoints. In the figure, the time endpoint is scaled by $c$, which results in a lower frequency to the signal when viewed from the original sampling rate, $s$. Since the model effectively has no access to the sampling time points, all inputs are assumed to be sampled at the same rate. From this perspective, we've effectively scaled the frequency of our signal by $c$.

% It more difficult to formulate a relation between resampled pairs in the time domain. However, the relation is very simple in the frequency domain, as shown in Fig. 2. Scaling the sampling frequency results in a translation of the spectra in the frequency domain when the sampling rate is the same. However, if the frequency decomposition takes $cs$ as the sampling rate for $Y$, then the spectra of $Y$ and $Y'$ become identical. In our case, we used the Fast Fourier Transform (FFT) from the PyTorch library for frequency decomposition. With this property, if we pass videos and $X'$ through the same network $f(\cdot)$, we can minimize the difference in the spectra to enforce a dependence between input frames and the predicted signals:
% \begin{equation}
% L_e = d(\mathrm{FFT}(f(X), cs), \mathrm{FFT}(f(\Phi(X,c)), s)).
% \end{equation}
% In the above equation we again use the squared Wasserstein distance~\cite{hou_emd_2017} between power spectra to calculate the loss.

% This simple formulation is very effective for two reasons: (1) the signal value at a certain time point should be the same across different sampling frequencies, enforcing that the model learn visual features from the video to regress common signal values, and (2) it further pushes
% the model to vary the frequency of the predicted waveforms via the frequency resampling augmentation. 

% \subsection{Comparison to Contrastive rPPG Methods}
% Gideon \etal~\cite{Gideon_2021_ICCV} calculated the mean square error between power spectral densities to pull positive pairs closer and repel negative pairs apart. In their approach, negative samples are created by frequency resampling. While they show that their approach learns to estimate the pulse, we argue that the formulation with negative samples is imprecise.

% The resampling frequency for the negative sample is known, so the relative translation of the power spectrum from the anchor sample can be inferred. Thus, rather than repelling the estimated spectra, it is more accurate to penalize differences from the known spectra, which effectively treats them as positive samples. Furthermore, if they resample close to the original sampling rate, there will be substantial overlap in the power spectra, so repelling the pair can be harmful.

% Differently from \cite{Gideon_2021_ICCV}, Contrast-Phys~\cite{Sun_2022_ECCV} consider all other samples in the training set from the anchor to be negatives, assuming that the power spectra will vary between subjects or sufficiently long windows in time. This runs into similar issues with negative pairs as Gideon's approach. Different subjects may have the same pulse rate, so treating them as a negative pair and punishing the model for predicting similar spectral densities could lead to issues during training. 