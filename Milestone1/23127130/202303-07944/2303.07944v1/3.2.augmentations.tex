\subsection{Augmentations}\label{sec:augmentations}
Unlike Gideon \etal's~\cite{Gideon_2021_ICCV} approach, which only applies frequency augmentations, we apply several augmentations to both the spatial and temporal dimensions to learn invariances to noisy visual signals. In fact, we found that without augmentations, models did not converge during training (see Appendix \ref{sec:app_no_augmentations}).

{\bf Image Intensity Augmentations.} Random Gaussian noise is added to each pixel location in a clip with a mean of 0 and a standard deviation of 2 on the original image scale from 0 to 255. The illumination is augmented by adding a constant sampled from a Gaussian distribution with mean 0 and standard deviation of 10 to every pixel in a clip, which darkens or brightens the video.

{\bf Spatial Augmentations.} We randomly horizontally flip a video clip with 50\% probability. The spatial dimension of a clip are randomly square cropped down to between half the original length and the original length. The cropped clip is then linearly interpolated back to the original dimensions.

{\bf Temporal Augmentations.} With the general assumption that the desired signal is strongly periodic and sparsely represented in the Fourier domain, we randomly flip a video clip along the time dimension with a probability of 50\%. Note that the Fourier decomposition of a time-reversed sinusoid is identical to that of the original sinusoid.

{\bf Frequency Augmentations.} Perhaps the most important augmentation is frequency resampling~\cite{Gideon_2021_ICCV}, where the video is linearly interpolated to a different frame rate. This augmentation is particularly interesting for rPPG, because it transforms the video input and target signal equivalently along the time dimension, making it equivariant. Given the aforementioned transformations that are invariant, $\tau(\cdot) \sim \mathcal{T}$, the equivariant frequency resampling operation, $\phi(\cdot) \sim \Phi$, and a model $f(\cdot)$ that infers a waveform from a video we have the following:
\begin{equation}
    \phi(f(\tau(x))) = f(\phi(\tau(x))).
\end{equation}

This is a powerful augmentation, because it allows us to augment the target distribution along with the video input. In our experiments we randomly resample input clips by a factor $c \sim U(0.6, 1.4)$. After applying the resampling augmentation, we scale the bandlimits by $c$, to avoid penalizing the model if the augmentation pushed the underlying pulse frequency outside of the original bandlimits.

% Critically, if the equivariant operation is invertible, then the prediction can be transformed as if another view was passed to the model. This is powerful, because it establishes a continuous and known relationship between input and prediction after augmentation.

% As an example we can examine the problem of object segmentation under the equivariant transformation of translation. If we translate the input along the x-dimension 10 pixels to the right, segment the input, then invert the segmentation estimate back 10 pixels to the left, the result should be the same as passing the untranslated input. As an additional benefit over invariance, this property inherently prevents model collapse by encouraging variance over predictions.