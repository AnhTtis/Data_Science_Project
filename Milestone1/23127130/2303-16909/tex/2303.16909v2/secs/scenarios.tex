
\section{Demonstration Scenarios}
\label{sec:scenarios}




For the demonstration, we have prepared 13 datasets from 9 different domains (\eg football matches, movies, and smartphone products), with 40 tables as the data lake. % to explore the  different scenarios. 
%Attendees can also upload other datasets.



\stitle{Initial Setup.}
To use \sys for data cleaning, the user needs to upload a table and indicate the dirty column requiring cleaning, as shown in the top left of Figure~\ref{fig:scenarios}. 

\vspace{1mm}
\stitle{Scenario 1:} 
{\em Data cleaning with public models.}
By default, users can simply click the ``Run'' button located on the bottom left-hand side of Figure~\ref{fig:scenarios}. 
%
Optionally, the user can select certain columns as the pivot column(s) from the drop-down list. 
As we will demonstrate, such selection is important as it eliminates noisy (irrelevant) columns before passing the content to the backend of \sys. As such, the backend modules 
(\att{Indexer}, \att{Reranker}, \att{Reasoner}) focus only on the data that matters. 
This scenario exclusively relies on the selected LLM knowledge to generate the cleaned data values (the 
right-most green-marked column in Figure~\ref{fig:scenarios}). 
%The user is responsible for determining whether to accept or reject the generated values.
%This option may be chosen for various reasons, such as the existence of  functional dependencies involving the column to be cleaned, which would make the cleaning process more focused, or for privacy concerns.
%The dirty column in need of cleaning will be highlighted in red, while the cleaning results will be displayed in an extended column, highlighted in green. %This column contains the repaired values for the corresponding rows of the dirty column.

%\etitle{Discussion.} This scenario exclusively relies on \chat's knowledge to generate cleaned data values. %, without any interpretation of the data source. 
%The user is responsible for determining whether to accept or reject the generated values.

%This can provide quick results, and is useful in cases where the appropriate data is well known (NEED A BETTER TERM). 

\vspace{1mm}
\stitle{Scenario 2:} 
{\em Retrieval-based data cleaning with public models.}
Consider the case that the user's data is not part of the world knowledge, e.g.,  
very recent movie data. 
In this case, the user can connect their local data lake (e.g., database or  CSV files), and request the \sys cleaning procedure to perform retrieval-based data cleaning (based on RAG). This approach utilizes different indexers, either syntactic or semantic, to retrieve relevant tuples from the data lake (see the ``Indexer'' option in Figure~\ref{fig:scenarios}). These tuples serve as the context that contains the relevant information, and then \sys leverages the LLM powerful language reasoning to extract the relevant information from these retrieved tuples.
%
The cleaning results are presented in the same manner as in Scenario 1. However, there is one main difference: when the user clicks the "\Info" button, the system displays the source tuple from the data lake that the value was extracted from (the bottom box in Figure~\ref{fig:scenarios}). 


%This scenario leverages the power of \chat in the \att{Reasoner} module to extract accurate values while showing the lineage of these values from the data lake. 
%However, for highly sensitive data, the user may prefer not to interact with \chat.

\vspace{1mm}
\stitle{Scenario 3:} 
{\em Retrieval-based data cleaning with local models.}
In this scenario, we use a small local model for reasoning and extracting the correct value from the retrieved tuples. Hence, the data is not sent anywhere, making it suitable for sensitive information. 

In the retrieval-based scenarios (Scenarios 2 and 3), users can optionally select a \att{Reranker} to reorder the retrieved tuples to potentially obtain higher-quality cleaning results (more details are presented in Section~\ref{sec:details}). 


% In the first scenario, querying models like ChatGPT alone does not provide the evidence of its answers, and therefore the results may be questionable for certain repairs. A valuable aspect in the last two retrieval-based scenarios is that RetClean will provide the source tuple and table that was referenced for each repair.

