%!TEX root = ../main.tex
\vspace{-1.8ex}
\section{Introduction}
\label{sec:intro}

Data plays a crucial role in any decision-making process, but real-world data is often riddled with missing values and errors.
Despite decades of efforts, human intervention remains the norm for practical data cleaning solutions. 
One reason is that data cleaning frequently requires domain knowledge and/or external information that may not be readily available within the data to be cleaned.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[t]
    \centering 
    \includegraphics[width=.8\textwidth, height = 6cm]{figs/overview-2.pdf}
    %\vspace{-2em}
    \caption{An Overview of \sys.}
    \label{fig:overview} 
    %\vspace{-1em}
 \end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Large language models, e.g., OpenAI's GPT family, LLaMA, CLaude, Google Gemini, 
among others, have exhibited considerable potential in a wide range of tasks, including language-based tasks, code generation/debugging, and many others.
Recently, LLMs have been envisioned to support data wrangling~\cite{DBLP:journals/pvldb/NarayanCOR22} (\eg data cleaning and entity matching) and querying data lakes~\cite{symphony, Zhang2023LargeLM}
Furthermore, even smaller fine-tuned LLMs, e.g., 7B and 13B models, have shown comparable capabilities in several data cleaning tasks compared to the powerful GPT family~\cite{Zhang2023JellyfishAL}.  

In this demo proposal, we present \sys, an end-to-end LLM-powered data cleaning solution that supports three different data cleaning scenarios (see Figure~\ref{fig:overview}). 
Using \sys, the audience will have a hands-on experience 
in testing few different models on various datasets.

\vspace{1mm}
\stitle{Scenario 1: Data cleaning with public cloud-based LLMs (e.g., GPT family and Google Gemini).}
We first showcase how our system harnesses the capabilities of such massive LLMs.
The process is simple: the user uploads a table and identifies the column 
that may contain errors. Next, we serialize each tuple as a prompt 
and utilize the selected LLM to suggest the correct value(s) for the dirty cells.
Several prompt templates can be tried to get the best results from these LLMs.


%It is important to note that while LLMs hold promise in data cleaning, they are not a silver bullet solution. There may be instances where the models produce errors, such as imputing missing values with incorrect values. In addition, since these models are generative in nature, they may not be able to provide an explanation for how the imputed values were generated, which may limit their usefulness in certain applications.


\vspace{1mm}
\stitle{Scenario 2: Retrieval-based data cleaning with public cloud-based LLMs (e.g., GPT family and Google Gemini).}
To overcome the limitations where public LLMs may struggle with datasets that they have never
seen before and the lack of explainability of the results they return, we demonstrate the effectiveness of {\em retrieval-based} data cleaning  based on the RAG (Retrieval Augmented Generation) approach. Specifically, the domain expert provides a data lake that serves as a source of domain knowledge that could potentially contain data that can be used for cleaning the input table. \sys indexes this data lake either offline for massive data lakes 
or online  at cleaning time for small data lakes. 
Then, at cleaning time and given a dirty tuple, \sys retrieves the top-$k$ tuples 
from the data lake that could potentially help the cleaning task. 
Then, we utilize the selected LLM to make inferences about which value to use along with its source tuple--providing a better explainability compared to Scenario 1.


\vspace{1mm}
\stitle{Scenario 3: Retrieval-based data cleaning with local models (e.g., Dolly-v2-3B and LLaMA-7B).}
For both Scenarios 1 and 2, one legitimate concern when using 
externally hosted models is data privacy. 
However, locally deployable models, which are small-scale models that can be easily hosted by any organization in a variety of settings, including cloud-based environments or on-premise servers, would be ideal if one is worried about data privacy.  
Typically, they are around 3B to 13B parameter models.
To this end,  we demonstrate the effectiveness of such small models, especially when fine-tuned for a given domain. The local model takes a pair of tuples (i.e., a query tuple with a missing value and a retrieved tuple), and then infers the missing value when possible. 

\sys is designed to seamlessly support the three above scenarios. 
With its user-friendly GUI supporting different configurations, the VLDB audience can effortlessly experiment with the system and explore each of the scenarios in detail.
