%!TEX root = ../main.tex
\vspace{-1.8ex}
\section{Introduction}
\label{sec:intro}

Data plays a crucial role in any decision-making process, but real-world data is often riddled with  missing values and errors.
Despite decades of effort, human intervention remains the norm for practical data cleaning solutions. 
One  reason is that data cleaning frequently requires domain knowledge and/or external information that may not be readily available within the data to be cleaned.


Foundation models, which are pre-trained  language models, such as OpenAI's GPT-3 and \chat, have exhibited considerable potential in a wide range of tasks, including language-based tasks, code generation/debugging, and many others.
%
Recently, foundation models have been envisioned to support data wrangling~\cite{DBLP:journals/pvldb/NarayanCOR22} (\eg data cleaning and entity matching) and querying data lakes~\cite{symphony}.
In this demo proposal, we present an end-to-end data cleaning solution that supports three different scenarios (see Figure~\ref{fig:overview}).

\vspace{1mm}
\stitle{Scenario 1: Data cleaning with \chat.}
We first showcase how our system harnesses the capabilities of \chat.
%Our demonstration will showcase an end-to-end data cleaning solution that harnesses the capabilities of \chat. 
The process is simple: the user uploads a table and identifies the column that may contain errors. Next, we serialize each tuple as a prompt and utilize \chat to suggest the correct value(s) for the dirty cells.


It is important to note that while foundation models hold promise in data cleaning, they are not a silver bullet solution. There may be instances where the models produce errors, such as imputing missing values with incorrect values. In addition, since these models are generative in nature, they may not be able to provide an explanation for how the imputed values were generated, which may limit their usefulness in applications that require explicit explanations.


\vspace{1mm}
\stitle{Scenario 2: Retrieval-based data cleaning with \chat.}
To overcome the limitations where \chat may struggle with datasets it has never
seen before and the lack of explainability, we developed a {\em retrieval-based} 
data cleaning approach. Specifically, the domain expert provides a data lake that  serves as a source of domain knowledge. \sys indexes this data lake either offline for massive data lakes or online  at cleaning time for small data lakes (both modes are supported). 
Then, at cleaning time and given a dirty tuple, \sys retrieves the top-$k$ tuples from the data lake that could potentially help  the cleaning task. 
Then, we utilize \chat to make inferences about which value to use along with its source 
tuple--providing a better explainability compared to Scenario 1.

For both Scenarios 1 and 2, one legitimate concern when using 
externally hosted  foundation models such as \chat is data privacy.
The model could potentially learn and retain sensitive information from the data it has seen. To
ensure the confidentiality of the data being processed, companies with sensitive data will not use \chat for data cleaning. That motivates our third scenario.

\vspace{1mm}
\stitle{Scenario 3: Retrieval-based data cleaning with local models.}
Locally deployable foundation models are foundation models that can be easily hosted by any organization in a variety of settings, including cloud-based environments or on-premise servers. 
For that purpose,  we  developed a  custom two-step RoBERTa-based model that takes a pair of tuples (i.e., a query tuple with a missing value and a retrieved tuple), and then infers the missing value when possible (more details in Section~\ref{sec:details}). 
In Scenario 3, we demonstrate that such local foundation models can effectively make inferences without sacrificing data privacy.

Our system, called \sys, is designed to seamlessly support the three scenarios mentioned above. 
With its user-friendly GUI supporting different configurations, the VLDB audience can effortlessly experiment with the system and explore each of the scenarios in detail.
The purpose of the demo is to spark interest and promote discussions around the potential of using retrieval-based methods and foundation models for data cleaning.
%
Our demonstration of \sys marks the first instance of showcasing its capabilities. The code is available at GitHub: \url{https://github.com/qcri/RetClean}.
%Moreover, it is the first demonstration of a retrieval-based data cleaning system that is powered by foundation models. %, highlighting a unique and innovative approach that our system takes towards data cleaning.