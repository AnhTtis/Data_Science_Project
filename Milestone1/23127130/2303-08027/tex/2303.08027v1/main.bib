@article{Cowen2022HumeVB,
     title={The Hume Vocal Burst Competition Dataset {(H-VB)}},
     author={Cowen, Alan and Bard, Alice and Tzirakis, Panagiotis and Opara, Michael and Kim, Lauren and Brooks, Jeff and Metrick, Jacob},
     journal={Zenodo}, 
     doi = {https://doi.org/10.5281/zenodo.6308780},
     year={2022}}

@misc{BairdA-VB2022,
    author = {Baird, Alice and Tzirakis, Panagiotis and Batliner, Anton and  Schuller, Bj√∂rn and Keltner, Dacher and Cowen, Alan},
    title = {The {ACII} 2022 Affective Vocal Bursts Workshop and Competition: Understanding a critically understudied modality of emotional expression},
    publisher = {arXiv},
    doi = {[to appear]},
    year = {2022}}

@article{scherer1986vocal,
  title={Vocal affect expression: a review and a model for future research.},
  author={Scherer, Klaus R},
  journal={Psychological bulletin},
  year={1986},
  publisher={American Psychological Association}
}

@article{hawk2009worth,
  title={"Worth a thousand words``: absolute and relative decoding of nonlinguistic affect vocalizations.},
  author={Hawk, Skyler T and Van Kleef, Gerben A and Fischer, Agneta H and Van Der Schalk, Job},
  journal={Emotion},
  year={2009},
  publisher={American Psychological Association}
}

@article{simon2009voice,
  title={The voice conveys specific emotions: evidence from vocal burst displays.},
  author={Simon-Thomas, Emiliana R and Keltner, Dacher J and Sauter, Disa and Sinicropi-Yao, Lara and Abramson, Anna},
  journal={Emotion},
  year={2009},
  publisher={American Psychological Association}
}

@article{xin2022exploring,
  title={Exploring the Effectiveness of Self-supervised Learning and Classifier Chains in Emotion Recognition of Nonverbal Vocalizations},
  author={Xin, Detai and Takamichi, Shinnosuke and Saruwatari, Hiroshi},
  journal={arXiv preprint arXiv:2206.10695},
  year={2022}
}

@article{wang2021fine,
  title={A Fine-tuned Wav2vec 2.0/HuBERT Benchmark For Speech Emotion Recognition, Speaker Verification and Spoken Language Understanding},
  author={Wang, Yingzhi and Boumadane, Abdelmoumene and Heba, Abdelwahab},
  journal={arXiv preprint arXiv:2111.02735},
  year={2021}
}

@article{baevski2020wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  journal={Advances in Neural Information Processing Systems},
  year={2020}
}

@article{conneau2020unsupervised,
  title={Unsupervised cross-lingual representation learning for speech recognition},
  author={Conneau, Alexis and Baevski, Alexei and Collobert, Ronan and Mohamed, Abdelrahman and Auli, Michael},
  journal={arXiv preprint arXiv:2006.13979},
  year={2020}
}

@article{ardila2019common,
  title={Common voice: A massively-multilingual speech corpus},
  author={Ardila, Rosana and Branson, Megan and Davis, Kelly and Henretty, Michael and Kohler, Michael and Meyer, Josh and Morais, Reuben and Saunders, Lindsay and Tyers, Francis M and Weber, Gregor},
  journal={arXiv preprint arXiv:1912.06670},
  year={2019}
}

@article{cariani1996neural,
  title={Neural correlates of the pitch of complex tones. II. Pitch shift, pitch ambiguity, phase invariance, pitch circularity, rate pitch, and the dominance region for pitch},
  author={Cariani, Peter A and Delgutte, Bertrand},
  journal={Journal of neurophysiology},
  year={1996},
  publisher={American Physiological Society Bethesda, MD}
}

@article{colosi1998efficient,
  title={Efficient numerical simulation of stochastic internal-wave-induced sound-speed perturbation fields},
  author={Colosi, John A and Brown, Michael G},
  journal={The Journal of the Acoustical Society of America},
  year={1998},
  publisher={Acoustical Society of America}
}

@article{santos2016attentive,
  title={Attentive pooling networks},
  author={Santos, Cicero dos and Tan, Ming and Xiang, Bing and Zhou, Bowen},
  journal={arXiv preprint arXiv:1602.03609},
  year={2016}
}

@article{anuchitanukul2022burst2vec,
  title={Burst2Vec: An Adversarial Multi-Task Approach for Predicting Emotion, Age, and Origin from Vocal Bursts},
  author={Anuchitanukul, Atijit and Specia, Lucia},
  journal={arXiv preprint arXiv:2206.12469},
  year={2022}
}

@article{shaqra2019recognizing,
  title={Recognizing emotion from speech based on age and gender using hierarchical models},
  author={Shaqra, Ftoon Abu and Duwairi, Rehab and Al-Ayyoub, Mahmoud},
  journal={Procedia Computer Science},
  year={2019},
  publisher={Elsevier}
}

@article{schubert1999measuring,
  title={Measuring emotion continuously: Validity and reliability of the two-dimensional emotion-space},
  author={Schubert, Emery},
  journal={Australian Journal of Psychology},
  year={1999},
  publisher={Taylor \& Francis}
}

@inproceedings{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={International conference on machine learning},
  year={2015},
  organization={PMLR}
}

@article{cowen2019mapping,
  title={Mapping 24 emotions conveyed by brief human vocalization.},
  author={Cowen, Alan S and Elfenbein, Hillary Anger and Laukka, Petri and Keltner, Dacher},
  journal={American Psychologist},
  year={2019},
  publisher={American Psychological Association}
}

@article{baird2022acii,
  title={The ACII 2022 Affective Vocal Bursts Workshop \& Competition: Understanding a critically understudied modality of emotional expression},
  author={Baird, Alice and Tzirakis, Panagiotis and Brooks, Jeffrey A and Gregory, Christopher B and Schuller, Bj{\"o}rn and Batliner, Anton and Keltner, Dacher and Cowen, Alan},
  journal={arXiv preprint arXiv:2207.03572},
  year={2022}
}

@inproceedings{sharma2022multi,
  title={Multi-Lingual Multi-Task Speech Emotion Recognition Using wav2vec 2.0},
  author={Sharma, Mayank},
  booktitle={ICASSP},
  year={2022},
  organization={IEEE}
}

@article{baird2022icml,
  title={The ICML 2022 Expressive Vocalizations Workshop and Competition: Recognizing, Generating, and Personalizing Vocal Bursts},
  author={Baird, Alice and Tzirakis, Panagiotis and Gidel, Gauthier and Jiralerspong, Marco and Muller, Eilif B and Mathewson, Kory and Schuller, Bj{\"o}rn and Cambria, Erik and Keltner, Dacher and Cowen, Alan},
  journal={arXiv preprint arXiv:2205.01780},
  year={2022}
}

@article{jing2022redundancy,
  title={Redundancy Reduction Twins Network: A Training framework for Multi-output Emotion Regression},
  author={Jing, Xin and Song, Meishu and Triantafyllopoulos, Andreas and Yang, Zijiang and Schuller, Bj{\"o}rn W},
  journal={arXiv preprint arXiv:2206.09142},
  year={2022}
}

@article{song2022dynamic,
  title={Dynamic Restrained Uncertainty Weighting Loss for Multitask Learning of Vocal Expression},
  author={Song, Meishu and Yang, Zijiang and Triantafyllopoulos, Andreas and Jing, Xin and Karas, Vincent and Jiangjian, Xie and Zhang, Zixing and Yoshiharu, Yamamoto and Schuller, Bjoern W},
  journal={arXiv preprint arXiv:2206.11049},
  year={2022}
}

@article{purohit2022comparing,
  title={Comparing supervised and self-supervised embedding for ExVo Multi-Task learning track},
  author={Purohit, Tilak and Mahmoud, Imen Ben and Vlasenko, Bogdan and Doss, Mathew Magimai},
  journal={arXiv preprint arXiv:2206.11968},
  year={2022}
}

@article{russell1980circumplex,
  title={A circumplex model of affect.},
  author={Russell, James A},
  journal={Journal of personality and social psychology},
  year={1980},
  publisher={American Psychological Association}
}

@article{lawrence1989concordance,
  title={A concordance correlation coefficient to evaluate reproducibility},
  author={Lawrence, I and Lin, Kuei},
  journal={Biometrics},
  year={1989},
  publisher={JSTOR}
}

@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@inproceedings{tzirakis2018end,
  title={End-to-end speech emotion recognition using deep neural networks},
  author={Tzirakis, Panagiotis and Zhang, Jiehao and Schuller, Bjorn W},
  booktitle={ICASSP},
  year={2018},
  organization={IEEE}
}

@article{li2022context,
  title={Context-aware Multimodal Fusion for Emotion Recognition},
  author={Li, Jinchao and Wang, Shuai and Chao, Yang and Liu, Xunying and Meng, Helen},
  journal={INTERSPEECH},
  year={2022}
}

@article{liang2021multibench,
  title={Multibench: Multiscale benchmarks for multimodal representation learning},
  author={Liang, Paul Pu and Lyu, Yiwei and Fan, Xiang and Wu, Zetian and Cheng, Yun and Wu, Jason and Chen, Leslie and Wu, Peter and Lee, Michelle A and Zhu, Yuke and others},
  journal={arXiv preprint arXiv:2107.07502},
  year={2021}
}

@inproceedings{adoma2020comparative,
  title={Comparative analyses of bert, roberta, distilbert, and xlnet for text-based emotion recognition},
  author={Adoma, Acheampong Francisca and Henry, Nunoo-Mensah and Chen, Wenyu},
  booktitle={Proc. ICCWAMTIP},
  year={2020},
  organization={IEEE}
}

@article{singh2022systematic,
  title={A systematic literature review of speech emotion recognition approaches},
  author={Singh, Youddha Beer and Goel, Shivani},
  journal={Neurocomputing},
  year={2022},
  publisher={Elsevier}
}

@article{pepino2021emotion,
  title={Emotion Recognition from Speech Using wav2vec 2.0 Embeddings},
  author={Pepino, Leonardo and Riera, Pablo and Ferrer, Luciana},
  journal={INTERSPEECH},
  year={2021}
}

@inproceedings{liu2020temporal,
  title={Temporal Attention Convolutional Network for Speech Emotion Recognition with Latent Representation.},
  author={Liu, Jiaxing and Liu, Zhilei and Wang, Longbiao and Gao, Yuan and Guo, Lili and Dang, Jianwu},
  booktitle={INTERSPEECH},
  year={2020}
}

@article{wen2021crossmodal,
  title = {Cross-modal dynamic convolution for multi-modal emotion recognition},
  journal = {Journal of Visual Communication and Image Representatio},
  year = {2021},
  issn = {1047-3203},
  author = {Wen, Huanglu and You, Shaodi and Fu, Ying},
}

@inproceedings{schuller2013interspeech,
  title={The INTERSPEECH 2013 computational paralinguistics challenge: Social signals, conflict, emotion, autism},
  author={Schuller, Bj{\"o}rn and Steidl, Stefan and Batliner, Anton and Vinciarelli, Alessandro and Scherer, Klaus and Ringeval, Fabien and Chetouani, Mohamed and Weninger, Felix and Eyben, Florian and Marchi, Erik and others},
  booktitle={INTERSPEECH},
  year={2013}
}

@article{eyben2015geneva,
  title={The Geneva minimalistic acoustic parameter set (GeMAPS) for voice research and affective computing},
  author={Eyben, Florian and Scherer, Klaus R and Schuller, Bj{\"o}rn W and Sundberg, Johan and Andr{\'e}, Elisabeth and Busso, Carlos and Devillers, Laurence Y and Epps, Julien and Laukka, Petri and Narayanan, Shrikanth S and others},
  journal={IEEE transactions on affective computing},
  year={2015},
  publisher={IEEE}
}

@inproceedings{huang2019speech,
  title={Speech emotion recognition using deep neural network considering verbal and nonverbal speech sounds},
  author={Huang, Kun-Yi and Wu, Chung-Hsien and Hong, Qian-Bei and Su, Ming-Hsiang and Chen, Yi-Hsuan},
  booktitle={ICASSP},
  year={2019},
  organization={IEEE}
}

@article{hsu2021speech,
  title={Speech emotion recognition considering nonverbal vocalization in affective conversations},
  author={Hsu, Jia-Hao and Su, Ming-Hsiang and Wu, Chung-Hsien and Chen, Yi-Hsuan},
  journal={IEEE/ACM TASLP},
  year={2021},
  publisher={IEEE}
}

@article{chochlakis2022leveraging,
  title={Leveraging Label Correlations in a Multi-label Setting: A Case Study in Emotion},
  author={Chochlakis, Georgios and Mahajan, Gireesh and Baruah, Sabyasachee and Burghardt, Keith and Lerman, Kristina and Narayanan, Shrikanth},
  journal={arXiv preprint arXiv:2210.15842},
  year={2022}
}

