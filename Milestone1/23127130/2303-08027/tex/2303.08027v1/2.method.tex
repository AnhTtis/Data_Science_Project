\section{Methodology}
\label{sec:method}
% Hierarchical MTL architecture
The proposed hierarchical multitask learning framework is illustrated in Fig.~\ref{fig:overview}, mainly consisting of a high-level feature extractor (see left side Fig.~\ref{fig:overview}), and a structured output layer with a bi-directional regression chain (see right side Fig.~\ref{fig:overview}).
In the following, we will describe our proposed framework from the bottom levels of feature extraction, to the representation aggregation across different pre-trained model layers, and to the top structured output layer. 
%It is mainly composed In the following, we will describe each component separately.

\input{figs/overview}

\subsection{Preprocessing}
We preprocess the vocal burst data with peak normalization in the time domain for internal consistency of the data.
In addition, we use data augmentation to enrich the data and improve the robustness by slightly changing the acoustic characteristics with minor distortions. Specifically, we applied pitch-shifting and speed-perturbation for each input waveform during the training stage (corpus size not changed)~\cite{cariani1996neural,colosi1998efficient}.
The shifted ranges of pitch and speed are [-100, 100] semitones and [-0.05, +0.05] rates, respectively.

\subsection{High-level Feature Extractor}
% wav2vec2, weighted sum, attentive pooling, batch norm, proj, shared -> cnt, two, type, high, culture
The recent success of large pre-trained models motivates this work to adopt hidden embeddings from SSL models~\cite{adoma2020comparative,wang2021fine}.
We use the Wav2vec 2.0-Large XLSR (``w2v2-lg-xlsr'')~\cite{baevski2020wav2vec} to extract cross-lingual contextualised speech representations~\cite{conneau2020unsupervised}. The Wav2vec 2.0 Large XLSR is trained on the CommonVoice corpus~\cite{ardila2019common} by solving a contrastive task over masked latent speech representations and jointly learning a quantization of the latent representations shared across various languages.

The ``w2v2-lg-xlsr'' model contains one convolutional feature encoding layer and 24 stacked Transformer layers.
The convolutional layer contains temporal convolutions with kernel widths (10,3,3,3,3,2,2) and strides (5,2,2,2,2,2,2), which yield a receptive field of about 320 samples. Through this convolutional layer, we can obtain a feature map with a shape of $49\times1024$ (dimensions of time and the embedding, respectively) for each one-second segment with a 16kHz sampling rate from input vocal burst signals. To avoid information loss caused by only using the last Transformer layer of the Wav2vec model, we leverage both the Transformer layers and the convolutional layer. We use learnable weights to sum up all the hidden states of the 24 stacked Transformer layers and the output feature map from the convolutional layer.

An attentive time pooling layer~\cite{santos2016attentive} follows the weighted summed features and is used to compress the feature sequence with variable lengths into a fixed-length vector. The attention mechanism also enables flexible focus on important frames for target prediction, by allocating more weights to the corresponding frames in the summation. Then, we project the features into a lower-dimensional vector to reduce redundancy, while retaining the intra-class variability. A batch normalization layer \cite{ioffe2015batch} is applied to standardize the high-level features before the features are fed to the subsequent classifiers and regressors.


\input{figs/low_high}
\subsection{Hierarchical Multi-task Learning}
% shaqra2019recognizing (hierarchical)
% russell1980circumplex (2->high)
% anuchitanukul2022burst2vec (shared specific)
%The whole hierarchical multi-task framework is illustrated in Fig.~\ref{fig:overview}. 
We propose an elaborate hierarchical framework to explicitly model the relationships between the tasks. There are five tasks investigated in our framework \cite{baird2022acii}:
\begin{itemize}
    \item \textbf{TWO} This task aims to predict the emotion of AB in a space with two dimensions, i.e., arousal and valence, based on the circumplex model of affect \cite{russell1980circumplex}.
    \item \textbf{HIGH} The HIGH task is to predict the emotion intensity in a higher-dimensional space of 10 emotion classes, including  \textit{surprise}, \textit{sadness}, \textit{excitement}, \textit{fear}, etc.
    \item \textbf{COUNTRY} We design this classification task to consider the relationship between VB and habitation locations. There are 4 countries considered in this task, i.e., U.S., China, Venezuela and South Africa.
    \item \textbf{CULTURE} This is a 10-dimensional, 4-country culture-specific emotion intensity regression task.
    \item \textbf{TYPE} This task focuses on the prediction of 8 VB types, i.e., \textit{cry}, \textit{gasp}, \textit{groan}, \textit{grunt}, \textit{laugh}, \textit{pant}, \textit{scream}, and \textit{other}.
\end{itemize}
Following \cite{anuchitanukul2022burst2vec}, we used different layers to disentangle task-agnostic and task-specific information. The shared feature extractor is trained to extract features that are generally useful for the different prediction tasks, while each task-specific feature extractor captures information that is more related to the corresponding task.


In terms of the relationship between emotion dimensions, 
%From the perspective of emotion dimension, the labels of the TWO, HIGH and CULTURE tasks are from low to high dimensions. Specifically, 
the arousal and valence values in the TWO task can imply the emotion classes in the high-dimensional emotion space in the HIGH or TYPE tasks \cite{schubert1999measuring}. As shown in Fig.~\ref{fig:low_high}, distributions of the VB types, \textit{laugh}, \textit{cry} and \textit{scream}, are different in the arousal-valence space.
The labels in the CULTURE task are combinations of emotions and countries. Therefore, the predictions of the HIGH, TYPE, CULTURE and COUNTRY tasks are conditioned on the predicted results of the TWO task, i.e., the predicted arousal and valence values. Since CULTURE task targets are combinations of emotion classes and countries, the system is designed to generate the CULTURE outputs based on the predictions from the HIGH and the COUNTRY tasks.
%Therefore, we use the prediction from the TWO task to all the other tasks, the prediction from Country and TYPE to the HIGH and CULTURE tasks, and the prediction from HIGH to the CULTURE task.


\subsection{Bi-directional Regression Chain}
\input{figs/high_corr}
It is noteworthy that the emotion classes are not independent, for example, a higher score in \textit{amusement} implies higher score in \textit{excitement} and lower scores in \textit{fear} and \textit{horror}.
We visualize the Pearson correlation coefficients between the emotion classes on the training subset in Fig.~\ref{fig:high_corr}. It is clearly shown that some pairs demonstrate significant correlation, which needs to be explicitly considered.

To model such relationships between emotion classes, we used a bi-directional regression chain to explicitly model the label dependency for the HIGH and CULTURE tasks. In a regression chain, with the predictor of the $i$-th emotion and the extracted feature denoted as $f_i$ and $z$, respectively, the emotion score is calculated by: $\hat{y}_i=\sigma(f_i(z\bigoplus \hat{y}_{<i}))$, where $\sigma$ is the sigmoid function, $\bigoplus$ is the vector concatenation operator, and $\hat{y}_{<i}$ is the previous predicted emotion scores before the \textit{i}-th emotion prediction.

To mitigate the effect from the emotion order of the chain, we accumulate absolute coefficients of each emotion, and arrange the order from higher accumulated values to lower ones, as shown in the x-axis in Fig.~\ref{fig:high_corr}. We then modify the chain regression layer to be bi-directional by adding another chain in the reverse direction.

% Following Xin \textit{et al.}~\cite{xin2022exploring}, we 


\subsection{Loss Functions}

For the countries and labels in TYPE task, categorical cross entropy (CE) is used as the main loss function. For the labels in the TWO, HIGH and CULTURE tasks, averaged biased concordance correlation coefficient (CCC) is adopted as the main loss function \cite{lawrence1989concordance}. The biased CCC is defined in Eq.~\ref{eq:ccc}.
\begin{equation}
\label{eq:ccc}
CCC(x_i, y_i) =\frac{1}{N}\sum\frac{2*cov(x_i, y_i)}{\sigma^{2}_{x_i} + \sigma^{2}_{y_i} + (\mu_{x_i} + \mu_{y_i})^2},
\end{equation}
where $N$ is the number of labels, and $\mu_{x_i}, \mu_{y_i}$ is the mean of $i$-th prediction and the corresponding ground truth values, respectively. The biased covariance is defined as $cov(x_i, y_i) = \sum(x_i - \mu_{x_i})(y_i - \mu_{y_i})$.

% \textcolor{red}{How do you combine the cross entorpy loss and the CCC loss??? weights??}
% Since multi-task learning can efficiently model the relationships between the labels, 
The total loss function is a weighted combination of the losses in the main task and the auxiliary tasks:
\begin{equation}
\label{eq:loss}
\mathcal{L}_{Target} = \lambda \mathcal{L}_{Target} + (1 - \lambda) * \sum(\mathcal{L}_{Auxiliary}),
\end{equation}
where $\mathcal{L}_{Target}$ and $\mathcal{L}_{Auxiliary}$ are the loss functions for the target and the auxiliary tasks, respectively, and $\lambda$ is a hyperparameter of the loss weights.

