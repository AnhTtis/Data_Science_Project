\begin{abstract}
%Vocal bursts, non-linguistic vocalizations, play important roles in robust and general speech emotion recognition. We present our approach for modeling affective vocal bursts in the ACII Affective Vocal Burst Workshop \& Challenge 2022 (A-VB).
%The proposed methods use self-supervised acoustic model to extract features, and a hierarchical bi-chain regression framework to model the labels' dependency.
%Experimental results show the effectiveness of proposed components, and give a superior performance compared to several baseline methods, e.g., mean concordance correlation coefficients of 0.6854, 0.7237, 0.6017 for the TWO, HIGH and CULTURE tasks.
As a common way of emotion signaling via non-linguistic vocalizations, vocal burst (VB) plays an important role in daily social interaction. Understanding and modeling human vocal bursts are indispensable for developing robust and general artificial intelligence. Exploring computational approaches for understanding vocal bursts is attracting increasing research attention. In this work, we propose a hierarchical framework, based on chain regression models, for affective recognition from VBs, that explicitly considers multiple relationships: (i) between emotional states and diverse cultures; (ii) between low-dimensional (arousal \& valence) and high-dimensional (10 emotion classes) emotion spaces; and (iii) between various emotion classes within the high-dimensional space. To address the challenge of data sparsity, we also use self-supervised learning (SSL) representations with layer-wise and temporal aggregation modules. The proposed systems participated in the ACII Affective Vocal Burst (A-VB) Challenge 2022 and ranked first in the ``TWO'' and ``CULTURE'' tasks. Experimental results based on the ACII Challenge 2022 dataset demonstrate the superior performance of the proposed system and the effectiveness of considering multiple relationships using hierarchical regression chain models.

\end{abstract}
\begin{keywords}
affective computing, vocal bursts, emotional expression, multi-label, multi-culture, multi-task learning
\end{keywords}
