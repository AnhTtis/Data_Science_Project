\section{Experiments}
\label{sec:exp}

\subsection{The A-VB Data}
We use the HUME-VB dataset of emotional non-linguistic vocalizations (vocal bursts)~\cite{Cowen2022HumeVB} that is used in the ACII A-VB Competition 2022 \cite{BairdA-VB2022}. The competition aims to promote research on modeling emotion in vocalizations, and proposes four tasks utilizing the HUME-VB data: the Two-Dimensional (TWO), High-Dimensional (HIGH), Cross-Cultural High-Dimensional (CULTURE) regression tasks, and the Expressive Burst-Type (TYPE) classification task.
The HUME-VB data contains about 37 hours of vocal burst data from 1702 speakers from China, South Africa, the U.S., and Venezuela. Each vocal burst is labeled with intensities in [1:100] of ten different expressed emotions or category in 8 classes from an average of 85.2 raters. The data is subsequently partitioned into training (19,990 VBs from 571 speakers), validation (19,396 VBs from 568 speakers), and test (19,815 VBs from 563 speakers) splits, with consideration of speaker independence and balances across countries and vocalization types.
% , as shown in Table ~\ref{tab:data}.
% \input{tables/data}

In this work, our target tasks are the TWO, HIGH and CULTURE tasks, while the classifications of COUNTRY and TYPE are used as auxiliary tasks. The TWO task aims to predict values of arousal and valence (based on 1=unpleasant/subdued, 5=neutral, 9=pleasant/stimulated), while The HIGH task aims to predict a higher dimension, i.e., the intensity of the aforementioned 10 emotions. The CULTURE task is a 10-dimensional, 4-country culture-specific emotion intensity regression task, i.e., it aims to predict the 40 intensity values of emotion (10 from each culture).

% \input{tables/data}
% \vspace{-1em}

\subsection{Experimental Setup}
% \textcolor{red}{Introduce the parameters for preprocessing (feature extraction window length, shift, augmentation parameters), parameters of attentive pooling (width), projection layer structure, shared layer, task-specific layers.
% Baseline systems introduction}
In this work, we set the dimensions of projection and shared layers to 128 and 64, respectively. The task-specific Bi-directional chains consist of two linear layers with sigmoid activation that are concatenated and averaged. The $\lambda$ in Eq.~\ref{eq:loss} is set to 0.9. We use  AdamW~\cite{loshchilov2017decoupled} as our optimizer with a learning rate of $1e-5$ for the Wav2vec 2.0 model finetuning and $1e-3$ for the downstream module training. To obtain a stabler CCC loss and alleviate the variance from the large pretrained model, we train the system with a large batch size of 1024 and a weight decay of $1e-3$. A 0.25 dropout is added between every two modules. We also apply early stopping (patience of 10, maximum of 25 epochs) to avoid overfitting the model.
The systems are evaluated on the validation and test datasets with the averaged biased CCC metric for the target tasks.

\subsection{Baselines}
The baseline systems in this challenge include feature-based and end-to-end methods~\cite{BairdA-VB2022}. The feature-based approach extracts 6,373-dimensional ComParE~\cite{schuller2013interspeech}, 88-dimensional eGeMAPS~\cite{eyben2015geneva} acoustic feature sets, and models the features with three fully-connected layers with layer normalization. While the end-to-end approach uses Emo-18~\cite{tzirakis2018end} convolutional neural networks followed by a 2-layer Long-short term memory (LSTM) network.

\subsection{Experimental Results}
% performance of each task
% Cross Comparison
\input{tables/results}
We compare our system with the baselines on the TWO, HIGH and CULTURE tasks in Table~\ref{tab:results}. It can be found that the proposed system outperforms the baselines on all three tasks by a significant margin. This demonstrates the effectiveness of the proposed hierarchical framework. 

\input{tables/ablation}
We also conducted experiments to verify the effectiveness of the integrated pre-trained representations and the regression chains on the HIGH task. As shown in Table~\ref{tab:ablation}, when the SSL representations are directly used without further fine-tuning on the HUME-VB dataset, the performance drops from 0.7351 to 0.6103, but still outperforms the baseline systems. If the regression chains are removed, the performance also decreases significantly, which demonstrates the effectiveness of the regression chains for the HIGH task. These results also suggest that the combination of fine-tuned SSL representations that implicitly borrow from external data, and the regression chains that model interactions between emotion classes, are both beneficial for performance.  

\input{tables/two}
We further analyze the performance of the arousal and valence prediction in the TWO task. The breakdown of performance is shown in Table~\ref{tab:two}. It can be observed that the CCC of predicted valence values is much higher than that of predicted arousal values. This matches well with the characteristics of the HUME-VB dataset -- that the distribution of human valence annotation is more diffuse than the arousal distribution \cite{baird2022acii}. 

\input{tables/high}

For the HIGH task, the performances of different emotion classes are shown in Table~\ref{tab:high}. It can be seen that all 10 classes have satisfactory performance.  In particular, the \textit{awkward} class is relatively more difficult with a slightly lower performance, which is also observed in \cite{xin2022exploring}.



% \input{tables/culture}
\input{tables/country_dist}
In the CULTURE task, it can be found that the performance for the data from Venezuela is significantly worse than the other locations. This is probably caused by the unbalanced distribution in the dataset.  This is shown in Table~\ref{tab:country}, where the training and validation data for Venezuela is much less compared to the data for U.S. and South Africa. Similarly, the performance for China is also inferior to the those for U.S. and South Africa.
%It can be observed that the classes of \textit{excitement} and \textit{distress} have relatively lower performance.
% points (obs from table)


% \textcolor{red}{labels dependency (figs: type_two, high_corr)}
% insights (label dependency)
% figs/type_two: the relationship between low-dimensional labels (valence, arousal) and part of high-dimensional voc_type labels
% figs/high_corr: Pearson's correlation coefficients among 10 high-dimensional labels

% \textcolor{red}{Ablation Study (-Chain, -Hierarchical)}


