\section{RELATED WORK}
\label{sec::related_work}
In this section, we review related work in social robot navigation and learning from human datasets. 

\subsection{Social Robot Navigation}
% 1. Why learning for social navigation is a good idea (it's difficult to define cost functions, etc.)
 % Learning a socially compliant policy has always been the goal of roboticists to empower public robots and their service. To obtain the optimal policy, Reinforcement Learning (RL) is credited by its ability to learn a large number of tasks. Despite its success with many real-world results, RL depends heavily on simulations to utilize online episodic learning algorithms. It requires long training time and a robust simulation environment, which can be difficult to achieve. Another drawback of RL is that its reward function needs to be well-designed because the policy is learned on the reward feedback. To meet this problem, Kret-zschmar et al. use Inverse Reinforcement Learning~\cite{irl} (IRL) to learns the utility function from demonstrations for social navigation policy. Besides RL and IRL, Imitation Learning and behavior cloning are also supervised learning algorithms that allow mobile robots to learn human way of navigating in public. To fuel those algorithms, a large-scale dataset of social navigation demonstrations is a huge need to be met.

To organically integrate service robots into the fabric of our society, these robots must be capable of moving in human-inhabited spaces in a socially compliant manner. One difficulty in creating such socially compliant navigation systems is to hand-craft appropriate rules or cost functions to cope with unwritten social norms in public spaces~\cite{mirsky2021prevention}. Therefore, researchers have sought help from machine learning and aimed at \emph{learning} socially compliant navigation behaviors in a data-driven manner~\cite{xiao2022motion}. 

RL has shown success in learning a variety of behaviors from simulated trial-and-error experiences~\cite{chen2017socially, xu2021applr, xu2023benchmarking}. However, the high fidelity of simulated social interactions required by RL for social navigation poses its own challenges and requires a good understanding and  then analytical representation of the unwritten social norms to create such simulated interactions, which is the difficulty in social navigation in the first place. Additionally, the reward function in RL needs to be carefully-designed but can still be brittle~\cite{knox2023reward}. 

To address such issues, IL~\cite{bojarski2016end} utilizes expert demonstrations to learn socially compliant navigation behaviors~\cite{xiao2022learning, xiao2020appld}. Kretzschmar et al.~\cite{kretzschmar2016socially} has proposed Inverse Reinforcement Learning (IRL) to learn the reward function from demonstrations for social navigation policies. Behavior Cloning~\cite{bojarski2016end} has treated the social navigation problem as supervised learning and regressed to an end-to-end motion policy that maps from perception to actions. However, to facilitate IL, a large corpus of socially compliant navigation demonstration data is essential. For example, the Socially Compliant Navigation Dataset (\textsc{scand})~\cite{karnan2022scand} is a recent effort to provide social robot navigation behaviors demonstrated by human teleoperation. 



\subsection{Learning from Human Datasets}
% The Ego4D dataset can be included here, and other datasets. We should emphasize those datasets do not have sufficient information for robots to learn from (depth, pointcloud, actions, odometry, etc.).

% One of the recent dataset to tackle these challenges is the Socially Complaint Navigation Dataset (\textsc{scand})~\cite{karnan2022scand} conducted at the University of Texas at Austin.  contains 8.7 hours, 138 trajectories, 25 miles of socially compliant, human teleoperated driving demonstrations that comprises multi-modal data streams including 3D LiDAR, joystick commands, Odometry, Visual and Inertial information, collected on two morphologically different mobile robots–a Boston Dynamics Spot and a Clearpath Jackal–by four different human demonstrators in both indoor and outdoor environments. Using \textsc{scand}, researchers at UT Austin was able to train a Behavior Cloning (BC) Imitation Learning algorithm for end-to-end socially-aware global and local planners for robot navigation. However promising \textsc{scand} is, it also has some limits: lack of less frequent and novel social interactions, geographical bias (only collected on UT campus), navigations are not human-level plus there is always at least one human behind the robot, making it less likely for other passengers to interact naturally. 
\textsc{scand}~\cite{karnan2022scand} is a recent dataset that aims at tackling the challenges of socially compliant robot navigation. \textsc{scand} includes socially compliant, human teleoperated robot navigation demonstrations in indoor and outdoor environments on The University of Texas at Austin campus. Using \textsc{scand}, researchers have shown that IL policies can be trained end-to-end for socially-aware global and local planners for robot navigation. However, \textsc{scand} requires a significant amount of cost and effort to set up and deploy the robot platforms in the wild and to collect large-scale human-teleoperated robot navigation demonstrations to cover the plethora of interesting social interactions in public spaces. Furthermore, how people react differently to a teleoperated mobile robot followed by a human operator is also unclear. 

Considering the difficulty in acquiring large-scale real-world data, researchers have also looked into utilizing recorded videos of human activities in the wild. For example Ego4D~\cite{grauman2022ego4d} is an egocentric video dataset, which offers daily-life activity video of different scenarios (house-hold, outdoor, workplace, leisure, etc.) captured by different humans wearing cameras from different locations worldwide. 
Ego4D offers a solution to the scalability of datasets by introducing a standard and wearable design so many people can collect data in real-world, daily settings from different parts of the world. However, Ego4D is not specifically designed for robotics (hence the lack of common robot sensors and perception like LiDAR, depth camera, IMU, and odometry), so it is difficult for mobile robots to directly learn socially compliant navigation behaviors from the raw video feed in Ego4D.

Inspired by the pros and cons of both \textsc{scand} and Ego4D, we introduce a wearable data collection sensor suite specifically designed to provide data to enable social robot navigation. It allows us to collect social human navigation data from the perspective of a suite of multi-modal robotic sensors in our daily life with a small setup overhead (i.e., with a wearable helmet). We provide a large-scale social human navigation dataset, which can be easily extended in the future by robotics researchers all around the world, show that human-like social robot navigation behaviors can be learned through such a dataset, and point out future research directions and anticipated use cases of our dataset. 