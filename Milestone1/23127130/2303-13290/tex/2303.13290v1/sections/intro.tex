\vspace{-0.3cm}
\section{Introduction}\label{sec:intro}
Rigid point cloud registration aims at determining the optimal transformation to align two partially overlapping point clouds into one coherent coordinate system~\cite{huang2020feature,mei2022overlap,mei2021point,mei2022partial}. This task dominates the performance of systems in many areas, such as robotics~\cite{Zhou2022}, augmented reality~\cite{borrmann2018large}, autonomous driving~\cite{nagy2018real,wang2019robust}, radiotherapy~\cite{li2019noninvasive}, etc. 
Recent advances have been monopolized by learning-based approaches due to the development of 3D point cloud representation learning and differentiable optimization~\cite{qin2022geometric}. 

Existing deep learning-based point cloud registration methods can be broadly categorized as \textit{correspondence-free}~\cite{aoki2019pointnetlk,huang2020feature,mei2021point,mei2022partial,xu2021omnet} and \textit{correspondence-based}~\cite{choy2020deep,bai2021pointdsc,huang2021predator,yew2022regtr}.
The former minimizes the difference between global features extracted from two input point clouds.
These global features are typically computed based on all the points of a point cloud, making correspondence-free approaches inadequate to handle real scenes with partial overlap~\cite{zhang2020deep,choy2020deep}. 
Correspondence-based methods first extract local features used for the establishment of point-level~\cite{choy2020deep,huang2020feature,huang2021predator,fu2021robust} or distribution-level~\cite{magnusson2009evaluation,stoyanov2012point,evangelidis2017joint,yuan2020deepgmr} correspondences, and finally, estimate the pose from those correspondences.
However, point-level registration does not work well under conditions involving varying point densities or repetitive patterns~\cite{mei2022overlap}. 
This issue is especially prominent in indoor environments, where low-texture regions or repetitive patterns sometimes dominate the field of view.
Distribution-level registration, which compensates for the shortcomings of point-level methods, aligns two point clouds without establishing explicit point correspondences. 
Unfortunately, to the best of our knowledge, the existing methods are inflexible and cannot handle point clouds with partial overlaps in real scenes~\cite{mei2022overlap,li2022gaussian}.  
Moreover, the success of learning-based methods mainly depends on large amounts of ground truth transformations or correspondences as the supervision signal for model training. 
Needless to say, the required ground truth is typically difficult or costly to acquire, thus hampering their application in the real world~\cite{shen2022reliable}. 

We thus propose an unsupervised deep probabilistic registration framework to alleviate these limitations. 
Specifically, we extend the distribution-to-distribution (D2D) method to solve partial point cloud registration by adopting the Sinkhorn algorithm~\cite{cuturi2013sinkhorn} to predict correspondences of distribution.
In order to make the network learn geometrically and semantically consistent features, we design distribution-consistency losses, i.e., self-consistency and cross-consistency losses, to train the networks without using any ground-truth pose or correspondences. Besides, we also introduce a local contrastive loss to learn more discriminative features by pushing features of points belonging to the same clusters together while pulling dissimilar features of points coming from different clusters apart. 

Our \ourmethod is motivated by OGMM~\cite{mei2023overlap} and UGMM~\cite{huang2022unsupervised} but differs from them in several ways. Firstly, unlike OGMM, which is a supervised method, our approach is unsupervised. Secondly, while UGMM~\cite{huang2022unsupervised} treats all clusters equally in the matching process, our method aligns different clusters with varying levels of importance. This enables our approach to handle partial point cloud registration successfully.
To enable unsupervised learning, the designed self-consistency loss encourages the extracted features to be geometrically consistent by compelling the features and coordinates to share the posterior probability. The cross-consistency loss prompts the extracted features to be geometrically consistent by forcing the partially overlapping point clouds to share the same clusters.  
We evaluate our \ourmethod on 3DMatch\cite{zeng20173dmatch}, 3DLoMatch\cite{huang2021predator}, ModelNet\cite{wu20153d} and ModelLoNet\cite{huang2021predator}, comparing our approach against traditional and deep learning-based point cloud registration approaches.
\ourmethod achieves state-of-the-art results and significantly outperforms unsupervised methods on all the benchmarks.

In summary, the main contributions of this work are:
\begin{itemize} [leftmargin=*]
    \item We propose an unsupervised learning-based probabilistic framework to register point clouds with partial overlaps.
    \item We provide a deep probabilistic framework to solve partial point cloud registration by adopting the Sinkhorn algorithm to predict distribution-level correspondences.
    \item We formulate self-consistency, cross-consistency, and local-contrastive losses, to make the posterior probability in coordinate and feature spaces consistent so that the feature extractor can be trained in an unsupervised way.
    \item We achieve state-of-the-art performance on a comprehensive set of experiments, including synthetic and real-world datasets\footnote{\url{https://github.com/gfmei/UDPReg}}.
\end{itemize}