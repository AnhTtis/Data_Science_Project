% %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\twocolumn[
\begin{@twocolumnfalse}
\section*{\centering{Unsupervised Deep Probabilistic Approach for Partial Point Cloud Registration \\ --Supplementary Material--}}
\vspace{1cm}
\end{@twocolumnfalse}]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Appendix}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
In this supplementary material, we first describe the detailed feature extractors in Sec.~\ref{sec:afe}, then we provide the details of the Transformer in Sec.~\ref{sec:attn}, followed by solving Eq.~\eqref{eq:sgamma} in Sec.~\ref{sec:opt}. We also give the definitions of evaluation metrics in Sec.~\ref{sec:metric}.
Finally, we provide more registration results in Sec.~\ref{sec:m_res}.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Feature Extractor}~\label{sec:afe}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Our \ourmethod adopts a KPConv~\cite{thomas2019kpconv}-based encoder-decoder architecture for feature
extraction, where we add a lightweight Transformer for context aggregation.
The configurations of KPConv and ResBlock are the same as in~\cite{huang2021predator}.
On 3DMatch, following~\cite{qin2022geometric}, we first downsample the input point clouds with
a voxel size of 2.5cm, then send the downsampled point clouds into the feature extractor.
The detailed network configurations are shown in Table~\ref{tb:arch}.

\begin{table}[!hbt]
    \centering
    \caption{Network architecture for 3DMatch and ModelNet.}
    \label{tb:arch}
    \resizebox{1\linewidth}{!}{%
    \begin{tabular}{c|c c}
    \toprule
    Stage & 3DMatch & ModelNet\\
    \midrule
    \multirow{2}{*}{1}    
    & KPConv($1{\rightarrow} 64$) & KPConv($1{\rightarrow} 256$) \\
    & ResBlock($64{\rightarrow} 128$) & ResBlock($256{\rightarrow} 256$) \\
    \midrule
    \multirow{3}{*}{2}
    & ResBlock($64{\rightarrow} 128$, strided) & ResBlock($256{\rightarrow} 512$, strided) \\
    & ResBlock($128{\rightarrow} 256$) & - \\
    & ResBlock($256{\rightarrow} 256$) & - \\
    \midrule
    \multirow{3}{*}{3}
    & ResBlock($256{\rightarrow} 256$, strided) & ResBlock($512{\rightarrow} 512$, strided) \\
    & ResBlock($256{\rightarrow} 512$) & ResBlock($512{\rightarrow} 512$) \\
    & ResBlock($512{\rightarrow} 512$) & - \\
    \midrule
    \multirow{3}{*}{4}
    & ResBlock($512{\rightarrow} 512$, strided) & ResBlock($1024{\rightarrow} 1024$, strided) \\
    & ResBlock($512{\rightarrow} 1024$) & - \\
    & ResBlock($1024{\rightarrow} 1024$) & - \\
    \midrule
    \multirow{2}{*}{5} 
    & -                                       & ResBlock($1024{\rightarrow} 1024$, strided) \\
    & -                                       & ResBlock($1024{\rightarrow} 1024$) \\
    \midrule
    6 & -                                   & ResBlock($1024{\rightarrow} 1024$, strided) \\
    \midrule
    \multirow{2}{*}{7} 
    & Conv1D($1024{\rightarrow}256$) & Conv1D($1024{\rightarrow}256$) \\
    & Transformer($256{\rightarrow}256$) & Transformer($256{\rightarrow}256$) \\
    \midrule
    \multirow{2}{*}{8}
    & NearestUpsampling & NearestUpsampling \\
    & UnaryConv($1537{\rightarrow}512$) 
    & UnaryConv($1537{\rightarrow}512$) \\
    \midrule
    \multirow{2}{*}{9}
    & NearestUpsampling & NearestUpsampling \\
    & UnaryConv($768{\rightarrow}256$) 
    & UnaryConv($768{\rightarrow}512$) \\
    \midrule
    10  & Linear($512{\rightarrow}257$) & Linear($256{\rightarrow}129$) \\
    \bottomrule
    \end{tabular}
    }
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Transformer}~\label{sec:attn}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The transformer is composed of three main components: self-attention, positional encoding, and cross-attention. Geometric self-attention is utilized to capture long-range dependencies, while positional encoding assigns intrinsic geometric properties to each point feature, thereby increasing differentiation among features in areas where they may be indistinct. The cross-attention module leverages the connections between the source and target point clouds, enabling the encoding of contextual information between partially overlapping point clouds. The individual parts will be described in detail below.

\paragraph{Self-Attention.} 
We use the geometric self-attention provided in GeoTransformer~\cite{qin2022geometric} for self-attention.

\paragraph{Positional Encoding.} 
Following~\cite{mei2022overlap}, incorporating a positional encoding approach, which imparts intrinsic geometric attributes to individual point features through the inclusion of unique positional information, improves differentiation among point features in less distinctive regions. To begin with, we choose the $k=10$ nearest neighbors $\mathcal{K}_i$ of $\bar{\bm{p}}_i^s$ and calculate the centroid $\bar{\bm{p}}^s_c=\sum_{i=1}^{\bar{N}_s}\bar{\bm{p}}^s_i$ of $\bar{\bm{\mathcal{P}}}^s$, where $\bar{\bm{p}}^s_i$ and $\bar{\bm{p}}^s_j$ represent two superpoints of $\bar{\bm{\mathcal{P}}}^s$.
For each $\bar{\bm{p}}^s_x\in \mathcal{K}_i$, we denote the angle between two vectors $\bar{\bm{p}}^s_i-\bar{\bm{p}}^s_c $ and $ \bar{\bm{p}}^s_x-\bar{\bm{p}}^s_c$ as $\alpha_{ix}$.
The position encoding $\bar{\bm{g}}^s_i$ of $\bar{\bm{p}}_i$ is defined as follows: 
\begin{equation}\label{eq:pos}
	\bar{\bm{g}}^s_i= \varphi\left(\|\bar{\bm{p}}^s_i-\bar{\bm{p}}^s_c\|_2\right) +\max_{x\in \mathcal{K}_i}\{\phi\left(\alpha_{ix}\right)\},
\end{equation}
where $\varphi$ and $\phi$ are two MLPs, and each MLP consists of a linear layer and one ReLU nonlinearity function.


\paragraph{Cross-Attention.} 
Let ${^{(l)}\bar{\bm{\mathcal{F}}}^s}$ be the intermediate representation for $\bar{\bm{\mathcal{P}}}$ at layer $l$ and let ${^{(0)}\bar{\bm{\mathcal{F}}}^s}{=}\{\bar{\bm{g}}^s_i{+}\bar{\bm{f}}^s_i\}_{i=1}^{\bar{N}_s}$. We use a multi-attention layer consisting of four attention heads to update the ${^{(l)}\bar{\bm{\mathcal{F}}}^s}$ via
\begin{equation}\label{eq:sim}
	\begin{aligned}
			&\bm{S}^s{=} {^{\left(l\right)}\bm{W}}_1{^{(l)}\bar{\bm{\mathcal{F}}}^s} {+} {^{(l)}\bm{b}}_1, \bm{K}^{t} {=} {^{\left(l\right)}\bm{W}}_2 {^{(l)}\bar{\bm{\mathcal{F}}}^t} {+} {^{(l)}\bm{b}}_2, \\
			&\bm{V}^{x}{=} {^{\left(l\right)}\bm{W}}_3{^{(l)}\bar{\bm{\mathcal{F}}}^t} {+} {^{(l)}\bm{b}}_3, \bm{A} {=} \mbox{softmax}\left(\frac{{\bm{S}^s}^\top \bm{K}^{t}}{\sqrt{b}}\right), \\
			&{^{(l+1)}\bar{\bm{\mathcal{F}}}^s} {=}{^{(l)}\bar{\bm{\mathcal{F}}}^s} {+} {^{(l)}h}\left(\bm{A}\bm{V}^x\right).
		\end{aligned}
\end{equation}
Here, $^{(l)}h\left(\cdot\right)$ is a three-layer fully connected network consisting of a linear layer, instance normalization, and a LeakyReLU activation. The same attention module is also simultaneously performed for all points in point cloud $\bar{\bm{\mathcal{P}}}^t$. 
The final outputs of attention module are $\bar{\bm{\mathcal{F}}}^s$ for $\bar{\bm{\mathcal{P}}}^s$ and $\bar{\bm{\mathcal{F}}}^t$ for $\bar{\bm{\mathcal{P}}}^t$. The latent features $\bar{\bm{\mathcal{F}}}^s$ have the knowledge of $\bar{\bm{\mathcal{F}}}^t$ and vice versa.

\paragraph{Overlap Score.} 
After computing $\bar{\bm{\mathcal{F}}}^s$ and $\bar{\bm{\mathcal{F}}}^t$, a network acts on them to extract overlap scores $\bar{\bm{O}}^s=\{\bar{\bm{o}}^s_i\in [0, 1]\}_{i=1}^{\bar{N}}$ and $\bar{\bm{O}}^t=\{\bar{\bm{o}}^t_j\in [0, 1]\}_{j=1}^{\bar{M}} \in [0, 1]$ for $\bar{\bm{\mathcal{P}}}^s$ and $\bar{\bm{\mathcal{P}}}^t$, respectively, to identify the overlapping regions~\cite{huang2021predator}.
The overlap scores and features are sent to the decoder, which outputs the point-wise feature descriptor $\bm{\mathcal{F}}^{s}{\in}\mathbb{R}^{N_s\times d}$ and $\bm{\mathcal{F}}^t{\in}\mathbb{R}^{N_t\times d}$ and overlap scores $\bm{O}^s{=}\{o_i^s\}{\in}\mathbb{R}_+^{N_s}$ and $\bm{O}^t=\{o_j^t\}{\in}\mathbb{R}_+^{N_t}$. 
$d$ is the dimension of features. 


\subsection{Optimization}\label{sec:opt}
Now, we introduce how to address the optimization objective presented in Eq.~\eqref{eq:sgamma} of the main paper:
%-------------------------------------
\vspace{-.2cm}
\begin{equation}\label{eq:agamma}
\begin{aligned}
& \min_{\bm{\gamma}}\sum_{i,j}\bm{\gamma}_{ij}\|\bm{p}_i-\bm{\mu}_j\|^2_2,\\
& \mbox{s.t.,}~ \sum_i\bm{\gamma}_{ij} {=} N\bm{\pi}_j, \sum_j\bm{\gamma}_{ij} {=} 1, \bm{\gamma}_{ij}\in[0, 1].
\end{aligned}
\end{equation}
%-------------------------------------
The constraint $\sum_j\bm{\gamma}_{ij}{=}1$ is imposed based on the property of probability that the sum of all probabilities for all possible events is equal to one. The constraint $\sum_i\bm{\gamma}_{ij} {=} N\bm{\pi}_j$ represents the mixture weights' constraints.

Let $\bm{\Gamma}=\frac{\bm{\gamma}}{N}$ with elements defined as $\Gamma_{ij}=\frac{\gamma_{ij}}{N}$. By replacing the variable $\bm{\gamma}$ with $\bm{\Gamma}$ in Eq. (\ref{eq:agamma}), the joint objective can be formulated as an optimal transport (OT) problem~\cite{peyre2019computational} as
%-------------------------------------
\begin{equation}\label{eq:poster}
    \min_{\bm{\Gamma}} \left<\bm{\Gamma}, \bm{D}\right>, ~ \mbox{s.t.} ~ \bm{\Gamma}^\top\bm{1}_N=\bm{\pi}, \bm{\Gamma}\bm{1}_L=\frac{1}{N}\bm{1}_N.
\end{equation}
%-------------------------------------
While the minimization of Eq. (\ref{eq:poster}) can be solved in polynomial time as a linear program, it becomes challenging when dealing with millions of data points and thousands of classes as traditional algorithms do not scale well \cite{cuturi2013sinkhorn}. To overcome this limitation, we utilize an efficient version of the Sinkhorn-Knopp algorithm\cite{cuturi2013sinkhorn}.
This requires the following regularization term:
%-------------------------------------
\begin{equation}\label{eq:opt}
	\begin{aligned}
		& \min_{\bm{\Gamma}} \left<\bm{\Gamma}, \bm{D}\right> - \epsilon H\left(\bm{\Gamma}\right), \\
		& \mbox{s.t.} ~ \bm{\Gamma}^\top\bm{1}_N=\bm{\pi}, \,\,\,
		\bm{\Gamma}\bm{1}_L=\frac{1}{N}\bm{1}_N,
	\end{aligned}
\end{equation}
%-------------------------------------
where $H\left(\bm{\Gamma}\right)=\left<\bm{\Gamma},\log\bm{\Gamma}-1\right>$ represents the entropy of $\bm{\Gamma}$, and $\epsilon > 0$ is a regularization parameter. When $\epsilon$ is very large, optimizing Eq.~\eqref{eq:opt} is equivalent to optimizing Eq.~\eqref{eq:poster}, but even for moderate values of $\epsilon$, the objective function tends to have approximately the same optimal solution \cite{cuturi2013sinkhorn}. Choosing the appropriate value of $\epsilon$ involves a trade-off between convergence speed and proximity to the original transport problem \cite{cuturi2013sinkhorn}. In our scenario, a fixed value of $\epsilon$ is suitable since our focus is on obtaining the final clustering and representation learning outcomes rather than solving the transport problem exactly. The solution to Eq.~(\ref{eq:opt}) can be expressed as a normalized exponential matrix, as stated in \cite{cuturi2013sinkhorn},
%-------------------------------------
\begin{equation}\label{eq:gamma}
	\bm{\Gamma} = \mbox{diag}\left(\bm{\mu}\right)\exp\left(\bm{D}\big/\epsilon\right)\mbox{diag}\left(\bm{\nu}\right),
\end{equation}
%-------------------------------------
where $\bm{\mu}=(\mu_1, \mu_2,\cdots,\mu_N)$ and $\bm{\nu}=(\nu_1,\nu_2,\cdots,\nu_L)$ are renormalization vectors in $\mathbb{R}^N$ and $\mathbb{R}^L$. Iterating the updates via $\bm{\mu}_i=\left[\exp\left(\bm{D}\big/\epsilon\right)\bm{\nu}\right]^{-1}_i$ and $\bm{\nu}_j=\left[\exp\left(\bm{D}\big/\epsilon\right)^\top\bm{\mu}\right]^{-1}_j$ with initial values $\bm{\mu}=\frac{1}{N}\bm{1}_N$ and $\bm{\nu}=\bm{\pi}$, respectively, yields the vectors $\bm{\mu}$ and $\bm{\nu}$. Although any distribution can be used for the initialization of $\bm{\mu}$ and $\bm{\nu}$, setting them as the constraints results in faster convergence~\cite{cuturi2013sinkhorn}. In our experiments, we used 20 iterations as it worked well in practice. After solving Eq. (\ref{eq:gamma}), we obtain the probability matrix $\bm{\gamma}$ as
%-------------------------------------
\begin{equation}\label{eq:soft_labels}
    \bm{\gamma}=N\cdot\bm{\Gamma}.
\end{equation}
%-------------------------------------
Eqs.~\eqref{eq:mgamma}, ~\eqref{eq:feature}, and \eqref{eq:point} can be solved in a similar way.

\subsection{Metrics}\label{sec:metric}
Following Predator~\cite{huang2021predator} and CoFiNet~\cite{yu2021cofinet}, we use three metrics, \textit{Registration Recall} ($RR$), \textit{Relative Rotation Error} ($RRE$), and \textit{Relative Translation Error} ($RTE$), to evaluate the performance of the proposed registration algorithm. RRE and RTE are respectively defined as 
\begin{equation}
\begin{aligned}
RRE &= \arccos\left(\frac{\textbf{Tr}\left(\bm{R}^\top\bm{R}^\star\right)-1}{2}\right),\\
RTE &=\|\bm{t}-\bm{t}^\star\|_2,
\end{aligned}
\end{equation}
where $\bm{R}^\star$ and $\bm{t}^\star$ denote the ground-truth rotation matrix and the translation vector, respectively. \textit{Registration Recall} (RR), the fraction of point cloud pairs whose root mean square error (RMSE) of transformation is smaller than a certain threshold (i.e., $RMSE<0.2m$).
Specifically, we denote the set of ground truth correspondences as $\mathcal{H}$ and the estimated transformation $T$, their root mean square error are calculated as:
\begin{equation}
    \mbox{RMSE} = \sqrt{\frac{1}{|\mathcal{H}|}\sum_{(\bm{p},\bm{q})\in\mathcal{H}}\|T(\bm{p})-\bm{q}\|_2^2}.
\end{equation}
Follow~\cite{huang2021predator}, Chamfer distance (CD) is used to measure the registration quality on ModelNet40. We use the modified Chamfer distance metric:
\begin{equation}
\begin{aligned}
    CD\left(\mathcal{\bm{P}},\mathcal{\bm{Q}}\right)&{=}
    \frac{1}{|\mathcal{\bm{P}}|}\sum_{\bm{p}\in\mathcal{\bm{P}}}\min_{\bm{q}\in\mathcal{\bm{Q}}}\|T\left(\bm{p}\right){-}\bm{q}\| \\
    &
    {+}\frac{1}{|\mathcal{\bm{Q}}|}\sum_{\bm{q}\in\mathcal{\bm{Q}}}\min_{\bm{p}\in\mathcal{\bm{P}}}\|T\left(\bm{p}\right){-}\bm{q}\|, 
\end{aligned}
\end{equation}
where $\mathcal{\bm{P}}$ and $\mathcal{\bm{Q}}$ are
input source and target point clouds.


\subsection{More Results}\label{sec:m_res}
\paragraph{Visualize the Gaussian mixtures.}
Fig.~\ref{fig:color} shows the visual results by coloring the points using GMM labels. We use different colors to differentiate clusters.

\begin{figure}[t]
\centering 
\begin{overpic}[width=1.0\columnwidth]{figures/cluster}
 % \put(10,19.0){\color{red}\footnotesize{\textbf{(a) Failure case}}}
 % \put(60,19.0){\color{red}\footnotesize{\textbf{(b) Gaussian mixture}}}
 % \put(8,19.0){\color{black}\footnotesize{\textbf{Ours}}}
 % \put(28,19.0){\color{black}\footnotesize{\textbf{Ground truth}}}
 \put(20,36.0){\color{black}\footnotesize{\textbf{Source}}}
 \put(70,36.0){\color{black}\footnotesize{\textbf{Target}}}
\end{overpic}
\caption{Coloring the points using learned GMM labels.} \label{fig:color}
\end{figure}

\paragraph{KITTI results.}
Table~\ref{tab:kitti} shows the generalization results from 3DMatch to KITTI.
\ourmethod outperforms baselines, showing its robustness and generalization.
%++++++++++++++++++++++++++++++++++++++
\begin{table}[!hbt]
\centering
\caption{Results of generalization from 3DMatch to KITTI.}\label{tab:kitti}
\resizebox{0.99\linewidth}{!}
{%
\begin{tabular}{l c c c c}
\toprule
Method & RTE($\uparrow$) & RRE($\uparrow$) & Success($\uparrow$) & Time ($\downarrow$) \\
\toprule
Predator     & 16.5 & 1.38 & 46.13 & 0.44 \\
SGP          & 13.8 & 0.49 & 62.22 & \bf 0.12 \\
UDPReg(Ours) & \bf8.81 & \bf0.41 & \bf64.59 & 0.26 \\
\bottomrule
\end{tabular}
 }
\end{table}

\paragraph{Complexity Analysis.} 
% The complexity relies on the chosen network. 
{\footnotesize$O(N{\times} L),L{<}N$} complexity for clustering and $O(N^2)$ for attention represents the memory bottleneck of UDPReg. $N, L$ are point and cluster numbers, respectively. 
Table~\ref{tab:kitti} reports the inference time on a Tesla V100 GPU (32G) and two Intel(R) 6226 CPUs.



