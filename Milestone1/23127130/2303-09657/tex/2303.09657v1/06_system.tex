\section{System Components}
\label{sec:system}
\begin{figure*}[!ht]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/system.pdf}
    \caption{\label{fig:system}
    \textbf{The overview of \name system.} Once the system is initialized, (A) \diagnosisview provides the overview in the degree of misclassifications and model confidence. By selecting a pair of classes, (B) all instances are visually highlighted and can be filtered and observed for their patterns. (C) A group of instances in a focal area are visually contrasted in their true and predicted classes, which can be (D) segmented and (E) defined with a group of semantically coherent segments as a concept. (F) All defined concepts are visually represented in terms of how each of them is biased towards a certain class in the training set and influential towards misclassifications. (G) Once an undesirable concept-class association is identified, users can determine whether to attempt a debiasing strategy to remove the proportion of concepts from the training set and evaluate whether it has mitigated the associations.
    }
    \vspace{-5pt}
\end{figure*}

\name is designed to support the aforementioned workflow of inspecting spurious concept associations by incorporating a suite of visual interfaces and proposed statistical methods, which consists of several components, as illustrated in Fig. \ref{fig:system}A-G. Throughout the system, multiple color schemes are applied: (1) two true negative and positive classes are represented as orange and purple. These two colors are further diverged into lighter or darker orange/purple to differentiate four confusion cases (Fig. \ref{fig:system}A-ii). (2) Two types of misclassifications are presented as red colors, either pink or dark red to indicate low or high confidence that is referred to as known-unknowns and unknown-unknowns respectively. 

\subsection{Misclassification Diagnosis View}
\label{sec:misclassification-diagnosis-view}
\diagnosisview (Fig. \ref{fig:system}A) provides the diagnostic modules (\textbf{T1}) for summarizing the degree of misclassification at instance-level in \performancechart (Fig. \ref{fig:system}A-i) and class-level in \confusionmatrix (Fig. \ref{fig:system}A-ii). 

\confusionmatrix (Fig. \ref{fig:system}A-ii) is a confusion matrix visualization that is designed to highlight misclassifications and unknown-unknowns. In this view, false confusion cases are highlighted with two overlapping circles, consisting of a pink outer circle indicating (1) the number of misclassifications and dark red inner circle indicating (2) unknown-unknowns per class. The number of unknown-unknowns is presented per class as red bars along with row labels in the matrix. In the system, there are two \confusionmatrix s presented in a tab interface, representing all classes or a pair of selected binary cases. In \name, the rest of components are provided to support the inspection of a selected binary case. This design choice serves two objectives: (1) to highlight systematic errors that rarely appear without using visual spaces to represent all cases, and (2) to allow users to perform a careful inspection on spurious associations between two classes without the cognitive overload.

\subsection{Instance Space} \label{sec:instance-space}
\instancespace (Fig. \ref{fig:system}B-i) allows users to inspect the patterns of instances in a pair of classes (\textbf{T2}) selected from \confusionmatrix. In a two-dimensional scatter plot, all instances in the test set are represented as a circle, whose high-dimensional vectorized representations are projected into a 2D space using UMAP \cite{mcinnes2018umap}. In this view, all instances are represented with respect to their true and predicted cases either as hollow circles for true predictions (Fig.\ref{fig:system}B-i-a) or as filled circles for false predictions with its lighter/darker red color indicating low or high confidence in misclassifications (Fig.\ref{fig:system}B-i-b). These instance circles are stroked with either orange or purple based on actual classes (Fig.\ref{fig:system}B-i-a). In combination with two visual clues, misclassifications in two classes are visually highlighted as filled and bigger circles over \instancespace. When users hover over each instance circle, a tooltip shows the actual image of the instance, with its k nearest neighbors with k adjustable with a slider interface (Fig. \ref{fig:system}B-ii). 

These instances can be filtered based on confusion cases in \confusionmatrix by clicking on desirable cases and model confidence with \confidencescorefilter (Fig. \ref{fig:system}B-ii), which summarizes the distribution of unknown-unknown scores. We use brier score \cite{brier1950verification} to compute the discrepancy between a predictive distribution and true distribution in each instance, ranging from 0 (true prediction) to 1 (largest discrepancy in error). A group of instances can be selected by clicking on a region to appear in \contrastiveview.

\subsection{Contrastive Analysis View}
\label{sec:contrastive-analysis-view}

\contrastiveview (Fig. \ref{fig:system}C) allows users to compare the patterns of a group of instances within different confusion cases. Once selected in \instancespace, a group of instances are displayed in \contrastiveview. In a flow-based layout, four confusion cases are presented as an arrow connecting from actual to predicted class, with its thickness indicating the size of instances in the confusion case. Each arrow points to an image panel on the right side for displaying images belonging to each confusion case. These image panels are vertically aligned side by side, helping users observe the differences in the pattern of instances in different confusion cases, especially as to how images predicted as negative class (two top panes) vs. positive class (two bottom panes) are different from each other. 

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.95\columnwidth]{figures/contrastive-analysis-view.pdf}
    \caption{\label{fig:contrastive-analysis-view}
    \textbf{Two examples of \contrastiveview.} \contrastiveview allows users to inspect how a group of images in a similar pattern were learned to be a pattern of either class, (A) two cat images with person misclassified as dogs are identified as similar to a group of dog images with yellow fur or person. (B) A group of cat and dog images with cages are all predicted as cats. 
    }
\end{figure}

\subsection{Segment View}
\label{sec:segment-view}
\segmentview (Fig. \ref{fig:system}D) supports the segmentation of images and allows users to select a set of semantically coherent segments to be defined as a concept. Once identifying specific concepts from images in \contrastiveview, users can select one or two image panes among four and click the segmentation button to generate segments. Once generated, all segment vectors are projected and visualized in a 2D scatter plot (Fig. \ref{fig:system}D-i) as rectangle glyphs with their color indicating based on confusion cases. Once a segment rectangle is hovered over, a tooltip highlights the k nearest segments to allow users to select a group of segments (k=10) that are visually coherent. When a segment is clicked, the nearest neighbors are selected together in the panel (Fig. \ref{fig:system}D-ii). This panel for defining a set of segments as a concept is editable in two ways: users can delete undesirable segment images by clicking or can type in the name of concept.

\subsection{Concept Inspection View}
\label{sec:system-concept-inspection-view}
\conceptinspectionview (Fig. \ref{fig:system}F) provides the visual summary of two aspects of systematic errors, association, and attribution (details in Section \ref{sec:introduction}), for all concepts defined by users in the system to allow users to inspect the concept association against misclassifications (\textbf{T3}). This view consists of two sub-components: \conceptassociationplot and \conceptdetailview. 

First, \conceptassociationplot (Fig. \ref{fig:system}F-i) visualizes two aspects of concept associations, association, and attribution in a 2D scatterplot. In the plot, each concept is represented as a vertically aligned pair of two circles, each representing the degree of false positive (FP) as an upper circle, and false negative (FN) as a lower circle with its size indicating the number of instances in FP and FN. These circle pairs are located in a 2D scatter plot indicating two concept associations in the $x$ and $y$-axis: First, the between-class disparity of concepts (details in Section \ref{sec:method-between-class-disparity}) is represented as the $x$-axis. Second, the concept influences towards two misclassifications (FP and FN) (details in Section \ref{sec:method-concept-influence}) are presented in the $y$-axis, consisting of the top half for the concept influence towards FN and the bottom half for FP. As circles are placed further from the center (towards the top (FP) or bottom (FN)), it indicates higher influence towards misclassifications.

\conceptdetailview (Fig. \ref{fig:system}F-ii) is designed to illustrate the details of two aspects of associations and attributions for a certain concept and to display the most associated instances. In the horizontally aligned panels, two aspects of associations visualized in \conceptassociationplot are illustrated as a form of questions, ``What did the model learn?" and ``What did the model fail?". In each panel, the class-level concept associations (details in Section \ref{sec:method-between-class-disparity}) are presented as bar charts with a list of the most concept-associated instances.

\subsection{Debias View}
\label{sec:debias-view}
\debiasview (Fig. \ref{fig:system}G) enables users to confirm how the associations between concepts and certain classes can be mitigated via the debiasing method (\textbf{T4}) (Section \ref{sec:method-debiasing}). In a line chart layout, each concept is represented as a line showing how biases can be gradually decreasing. The chart shows the ratio of remaining associations compared to one before debiasing presented as 1.0 in the $y$-axis (Equation \ref{equation:remaining-bias-ratio}) as the number of concept-associated instances in the $x$-axis is increasingly debiased. We also provide a slider interface where users can determine their tolerance in the amount of instances to be debiased, to help them gauge the trade-off between the number of instances and the degree of biases. As a user adjusts the slider between 0 and 1 (from less to more number of instances), the optimal point based on user's preference is adjusted and highlighted with its red stroke. In the below of \debiasplot, we summarize how the between-class disparity changed before and after removing biases in the form of a textual description to better illustrate the effect of debiasing spurious associations.
