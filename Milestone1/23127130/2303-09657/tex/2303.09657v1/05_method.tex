\section{Measuring and mitigating spurious concept association via concept space}
\label{sec:method}

In this section, we present statistical approaches (1) to measure two aspects of systematic error: the associations between a concept and instances (especially misclassifications) (Section \ref{sec:method-concept-association}) and the attribution of predictions to certain concepts (Section \ref{sec:method-concept-influence}) for Validation phase (\textbf{T3}), and (2) to mitigate spurious associations (Section \ref{sec:method-debiasing}) in Mitigation phase (\textbf{T4}).

\subsection{Measuring concept associations}
\label{sec:method-concept-association}
First, we present a method of measuring the association between a concept and instances. We start by defining two different levels of associations, (1) Instance-level association: It quantifies how a concept is closely aligned with an individual instance at a fine-grained level. (2) Class-level association: By aggregating instance-level associations into classes, we compute how a concept is associated with a group of instances in each target class. This measure can be extended to quantify the between-class disparity over concept associations.

To compute these measures, we take the well-known perspective of concept space where the association between two subspaces, concepts, and instances,  can be measured. Suppose that $N$ images are given in a machine learning task using a deep classifier $f$ consisting of a group of layers. Given a specific layer $l$ of interest, a subset of images $X$ and segments $S$ are vectors $\{\vec{v}_x\}_{x \in X}$ and $\{\vec{v}_s\}_{s \in S}$ in the space of activations of layer $l$. An interpretable concept $c$ is represented as a group of segment images $S_c$ that share the semantics of the target concept. We define a concept vector $\vec{v_{c}}$ as a mean vector of a group of segment vectors (e.g., two segment sets colored red and yellow in Fig. \ref{fig:method-subspace-alignment}a).

\subsubsection{Instance-level concept association} First, we define the instance-level association between a concept $c$ and images $\vec{X}$ in the space of layer $l$. Given an image vector $\vec{v}_x$ and a concept vector $\vec{v}_c$, the association can be computed via cosine similarity:

\begin{equation}
    \label{equation:concept-association}
    CA_{(x, c)} = \frac{\vec{v}_x \times \vec{v}_c}{\|\vec{v}_x\| \|\vec{v}_c\| }
\end{equation}

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.95\columnwidth]{figures/subspace-alignment.pdf}
    \vspace{-12.5pt}
    \caption{\label{fig:method-subspace-alignment}
    \textbf{The preprocessing steps for aligning instances and segments.} In the original space (a), two different concepts are not well-distinguishable. For better alignment, (b) the image subspace is normalized as shown, and (c) the segment subspace is then projected into the normalized image space. After preprocessing, two concept vectors are better discriminated in their directions.
    }
    \vspace{-2.5pt}
\end{figure}

\textbf{Subspace alignment.} These concept associations are measured via pairwise cosine similarity as angles between images $\{\vec{v_x}\}_{x \in X}$ and a concept $\vec{c}$ that seemingly work well; however, they are not distinguishable (Fig. \ref{fig:method-subspace-alignment}a), as pointed out in \cite{ConceptWhiteningInterpretable2020}. In our case, two subspaces of instances and segments are misaligned and placed far away from each other, so that two distinct concepts in Fig. \ref{fig:method-subspace-alignment}a result in indistinguishable cosine similarities, thus misleading associations between instances and concepts.

To address the misalignment problem, we perform the preprocessing to make two spaces better align with each other, consisting of two steps as illustrated in Fig. \ref{fig:method-subspace-alignment}: First, we normalize all instances to project them into the standardized space. Second, to align the segment space with the instance space, we project segment vectors into the normalized instance space using mean and standard deviation of instance vectors. As a result of the preprocessing steps, two concept vectors are well-distinguishable in their directions as much as they are semantically different (Fig. \ref{fig:method-subspace-alignment}c).

\textbf{Exclusive concept association.} After the preprocessing for subspace alignment, we compute exclusive concept association. This measure identifies which concepts within each image are relatively more influential than others as the top-associated concept.


\begin{figure}[!ht]
    \centering
    \includegraphics[width=\columnwidth]{figures/exclusive-concept-association.pdf}
    \caption{\label{fig:method-ex}
    \textbf{Three detailed steps for measuring exclusive concept association.}
    }
\end{figure}

Specifically, we take the following steps to compute exclusive association scores: (1) Measuring absolute concept associations: for a group of instances $X$ and concepts $C$, we calculate the pairwise cosine similarity (Equation \ref{equation:concept-association}) between $\{\vec{v_x}\}_{x \in X}$ and $\{\vec{v_c}\}_{c \in C}$ to measure how a concept and instance is associated in an absolute manner (Fig. \ref{fig:method-ex}a). From this matrix, by ranking instances in order of absolute scores for each row, we can obtain absolute concept associations as a set of per-concept image rankings $R_{raw(C)}=\{r_{raw(c)}\}_{c \in C}$. (2) Normalizing concept associations per image: for each image, association scores are standardized to convert them to relative association scores (i.e., column-wise standardization of the matrix in Fig. \ref{fig:method-ex}a). From the normalized matrix, each row as relative concept associations for each image is converted to a ranking, resulting in a set of per-image concept rankings (Fig. \ref{fig:method-ex}b). (3) Extracting the most associated concepts: From the per-image rankings, we extract the most-associated concept in each image, resulting in a obtain a list of top-associated concepts for each instance $\{(x, c_{top(x)})\}$. (4) Ranking the most-associated images per concept: These pairs are further grouped by each concept whose images are in the order of associations, resulting in a set of per-concept image rankings (Fig. \ref{fig:method-ex}d). These rankings $R_{ex(C)}=\{r_{ex(c)}\}_{c \in C}$ indicate how a concept is exclusively associated with a set of instances. 

\textbf{Combined association score.} Given two types of ranked associations, $R_{raw(C)}$ and $R_{ex(C)}$, we aim to combine them to find out instances that are the most associated with a concept absolutely and exclusively than other concepts. We use FREX score \cite{bischof2012summarizingfrex}, which was originally introduced in topic modeling, to combine raw and exclusive associations $R_{raw(C)}$ and $R_{ex(C)}$ across topic words:

\begin{equation}
    CA_{comb} = (\frac{w}{ECDF_{R_{ex}}} + \frac{1-w} {ECDF_{R_{raw}}})^{-1}
    \label{equation:combined-association-score}
\end{equation}

where $w$ is the weight between 0 and 1 given to exclusivity and ECDF is the empirical CDF function. We set $w=0.2$ to combine two rankings in our setting. Based on FREX score, we derive the combined ranking $R_{comb}$ to identify the list of concept-associated instances for the subsequent tasks.

\subsubsection{Class-level concept association and Between-class disparity}
\label{sec:method-between-class-disparity}

Based on the underlying measure of combined concept associations in Equation \ref{equation:combined-association-score}, we compute the between-class disparity to measure how a concept is more biased towards a certain class to compare the class-wise magnitude of concept associations. In the system, we use this metric over training examples to identify concept-wise biases towards classes in the training phase. It allows us to trace back to which concepts were learned to be patterns of one class relative to another. The between-class disparity is computed via taking the difference between the sum of combined concept associations based on the following equation:

\begin{equation}
    \label{equation:between-disparity}
    Disparity_{(c,X)} = \sum_{x \in X_{pos}}{CA_{comb(c,x)}} - \sum_{x \in X_{neg}}{CA_{comb(c,x)}}
\end{equation}

where $X_{neg}$ and $X_{pos}$ are two sets of instances belonging to either positive and negative class. When the difference is greater than zero, it indicates the concept is biased towards the positive class, otherwise negative class.

\subsection{Quantifying concept influences}
\label{sec:method-concept-influence}
Next, we quantify the influence of concepts on certain predictions, especially to measure how false predictions are attributed to a specific concept. We employ the approach of TCAV \cite{InterpretabilityFeatureAttributionQuantitative}, which uses directional derivatives to quantify how predictions over a group of instance vectors $\{\vec{v_x}\}_{x \in X}$ towards a certain class are sensitive to the direction of a concept vector $\vec{v_c}$. Compared to TCAV leveraging a concept activation vector (CAV) as an orthogonal direction of a hyperplane of trained linear classifier, we identify a concept vector $\vec{v_c}$ from a centroid of segment vectors $\vec{v_S}/\|S\|$, which is cost-effective in computations without having to train linear classifiers multiple times.

\subsection{Debiasing spurious concept associations}
\label{sec:method-debiasing}
In the workflow, the Mitigation phase aims to reduce the degree of spurious associations between a certain concept and target class. This requires a strategy to correct the spurious concept-class associations. While there are various approaches, such as active learning (i.e., adding training examples with desirable patterns), our goal is to prevent any undesirable concepts from being associated with a certain class. In this context, we propose a method to debias the proportion of concepts from instances that are highly associated with those concepts. We take the approach of debiasing from the line of work in fair representation \cite{sutton2018biased, bolukbasi2016man, zhao2018learning} (e.g., removing the gender bias from gender-specific words). For internal representations of instances containing undesirable attributes, it projects the target instances into the orthogonal direction of the unwanted attribute such as job or gender to neutralize them. This approach is applicable to our context to remove the property of a concept (as a vector $\vec{v_c}$) from each concept-associated instance (as a vector $\vec{v_i}, i \in I$). We apply this step to a group of training samples in $r_{comb(c)}$ that are identified as the most associated with a concept $c$:

\begin{equation}
    Debias_{(i,c)}: {\vec{v_i}} - \frac{{\vec{v_i}}*{\vec{v_c}}}{\|{\vec{v_c}} \times {\vec{v_c}}\| } \times {\vec{v_c}}
    \label{equation:debias}
\end{equation}

After this step, we compute the remaining bias ratio, the degree of the between-class disparity in Equation \ref{equation:between-disparity} being mitigated before and after debiasing:

\begin{equation}
    \label{equation:remaining-bias-ratio}
    Remaining \ Bias \ Ratio_{(c, X)} = 1 - \frac{(Disparity_{AF(c, X)} - Disparity_{BF(c, X)})}{Disparity_{BF(c, X)}}
\end{equation}


