\section{Usage scenarios}
\label{sec:case-studies}

\subsection{Usage scenario I: Identifying concept associations from a biased dataset}
\label{sec:case-study-1}
In the first case study, we present a use case scenario to demonstrate how biased concepts can be detected with the use of \name under the skewed Cats \& Dogs setting described in Section \ref{sec:evaluation}. We aim to validate the effectiveness of the system with diverse ground truth concepts that were intentionally designed to induce systematic errors. We interviewed two experts E1 and E2, who have expertise in predictive modeling for the research in statistics and chemical engineering. 

\textbf{Diagnose the potential of systematic failures (T1)}. When they started navigating the system, E1 noticed that \performancechart gave a summary of two types of misclassifications, ``\textit{It gives me a perspective of how I can further differentiate two types of misclassifications and figure out how the degree of unknown-unknowns are severe.}'' After confirming a high portion of unknown-unknowns, they further investigated how predictions are distributed over four confusion cases in \confusionmatrix (Fig. \ref{fig:system}A-ii). E2 immediately captured that the matrix showed higher degree of misclassifications in two classes with circles with darker and lighter red, ``\textit{I can easily notice I need to take the case of misclassified cats into account more seriously}''. It made him decide to closely examine the possibility of systematic errors in cat class.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.95\columnwidth]{figures/case-study-1.pdf}
    \vspace{-7.5pt}
    \caption{\label{fig:case-study-1}
    \textbf{Identifying and contrasting cases for hypothesizing concept associations.} \confidencescorefilter is adjusted to allow users to examine (A) unknown-unknowns exclusively or (B) all true and false instances. 
    }
    \vspace{-7.5pt}
\end{figure}

\textbf{Filter, contrast, and hypothesize} (\textbf{T2}). To find why cats were falsely predicted with high confidence than dogs, E1 used \instancespace and adjusted confidence score filter to exclusively examine misclassified cats with high confidence (Fig. \ref{fig:case-study-1}A). When hovering over two regions of misclassified cats of his interest, he identified that cat images with \textbf{person} and \textbf{grass} background appeared in the tooltip (Fig. \ref{fig:case-study-1}A-i, B-i). When extending the filter to investigate both true and false predictions (Fig. \ref{fig:case-study-1}B), he found that those misclassified cats were mixed up with a number of true dog images. Several cat images with person were in the middle of dog images with yellow or white furs (Fig. \ref{fig:case-study-1}B-ii). This led him to hypothesize that personsâ€™ skin were misunderstood as furs with bright colors by the classifier. E1 also identified there is a subregion where a number of grass images were grouped together. A click showed that those images appearing in \contrastiveview were all found to be predicted as dogs, including a few cat images falsely predicted as dogs. On the other hand, E2 paid attention to a region where images were a group of misclassified dog with \textbf{cage} (Fig. \ref{fig:case-study-1}A-ii). It made him hypothesize the spurious association between \textbf{cage} concept and cat class. 


\textbf{Validate concept associations (T3)}. 
To validate the concept association, they began to explore \conceptassociationplot (Fig. \ref{fig:system}F-i). In the plot, a total of seven concepts was shown with four automatically detected concepts and three additional concepts created by E1 and E2 separately, and four other predefined concepts that were also added by the researcher to let them explore a variety of concept influences. They captured at first sight that \conceptassociationplot showed a clear pattern between two types of associations (Fig. \ref{fig:system}F-i). E2 mentioned that, ``\textit{I can see that there is a positive association along two axes. For example, like a grass concept, the concepts biased towards dogs tend to be influential towards misclassified cats. And other concepts biased towards cats like black concept at the leftmost part have the opposite pattern}''. E2 first looked at \textbf{cage} concept to verify his first hypothesis. When selecting \textbf{cage} concept in \conceptassociationplot, it was attributed similarly to both misclassified cats and dogs. But in \conceptdetailview, the top-associated images with cage contained several types of objects such as \textbf{tiles}, \textbf{leashes}, \textbf{walls}, or \textbf{floor rugs}. Those objects were in their stripe or grid-like patterns in common. In the dog images, leashes noticeablely appeared. It indicated that, despite cage concept was intentionally biased to be a pattern of cats in our setting, the model learned various similar objects as a consistent pattern.

E1 previously made a hypothesis on \textbf{person} concept, so he clicked on it in \conceptassociationplot, whose detailed concept associations appeared in \conceptdetailview (Fig. \ref{fig:system}F-ii). In the left panel of \conceptdetailview, he found in the top-associated instance list that his observation on \instancespace was consistent with patterns in images containing cats with yellow furs, which meant the most associated instances towards person concept were white and yellow cats, then it led to the misclassified cats with person or hands. On the other hand, for grass concept, \conceptdetailview (Fig. \ref{fig:system}F-ii) showed a number of grass-associated images with a bar chart indicating a higher degree of grass concept associated with dogs than with cats. 

\textbf{Mitigate spurious associations via debiasing (T4).} After the investigation, E1 decided that grass concept is the most noticeable in spurious concept associations, ``\textit{I think \textbf{grass} concept is a background concept and highly biased toward dogs, so I want to debias it.}'' When E1 clicked debiasing button, the debiasing effect of grass concept was highlighted in \debiasview with 413 concept-associated instances  at the maximum as candidates of debiasing process. The plot also highlighted the optimal number of instances based on the preference over tolerance slider. E1 said, ``\textit{I think debiasing 200 instances are better because where the decreasing trend starts to flatten}''.

\begin{figure*}[!ht]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/case-study-2.pdf}
    \caption{\label{fig:case-study-2}
    \textbf{Exploring the spurious associations in Pascal Voc dataset using \name.} In the second case study, (A) Jane found in \confusionmatrix that some classes had more unknown-unknowns (indicated as red bars on the row labels) and began to take a closer look at three competing pairs of classes. (B) Using \contrastiveview (top) and \conceptinspectionview (bottom), she hypothesized five concepts (shown in C-i). (C) Three competing pairs of classes (i-iii) result in spurious associations between  concepts and certain class, leading to misclassifications in the opposite class.}
\end{figure*}

\subsection{Usage scenario II: Exploring spurious associations from real-world multiclassification images}
\label{sec:case-study-2}
In the second scenario, we present a case study of  exploring spurious associations in the second real-world dataset using \name (Fig. \ref{fig:case-study-2}). In the scenario, we take an example of a data scientist named Jane, who wants to inspect systematic errors in a multi-class image classification tasks with Pascal Voc dataset described in Section \ref{sec:evaluation}.

\textbf{Narrow down to regions of systematic errors (T1)}. After the system was initially loaded, she checked the higher proportion of unknown-unknowns in \performancechart and found in \confusionmatrix (Fig. \ref{fig:case-study-2}) that some classes such as aeroplane, bird, cat, and dog classes had more number of unknown-unknowns indicated as the length of red bars. By hovering over specific confusion cases in \confusionmatrix, she observed that misclassified images in some confusion cases commonly include some semantic concepts. For example, two groups of bottle images misclassified as either car or chair (Fig. \ref{fig:case-study-2}A-i) showed a stark difference in patterns (details below). After exploring coherent patterns to detect the potential regions of systematic errors, she decided to closely inspect three pairs of classes (bird/aeroplane, train/aeroplane, and chair/car/bottle, as highlighted with red, green, and blue in Fig. \ref{fig:case-study-2}A).

\textbf{Explore and validate concepts and the spurious associations over pairs of classes (T2, T3)}. First, she paid attention to the binary case of bird and aeroplane by clicking two class names in \confusionmatrix. When she moved on to \instancespace and selected a region containing a group of bird images falsely predicted as aeroplanes and other images as well, \contrastiveview diverged (Fig. \ref{fig:case-study-2}B-1) them into two different groups of bird images. In two different panes (colored light and dark purple), a group of the correctly classified bird images were in the forest or tree background, whereas in a group of falsely predicted bird images, birds appeared in a fence, cage, or shelter that share \textbf{straight} or \textbf{grid}-like patterns. After she further explored other regions of aeroplane \& bird, she defined \textbf{grass}, \textbf{sky}, \textbf{cloud}, \textbf{red \& blue stripe}, and \textbf{straight} in \conceptlist. In \conceptassociationplot (Fig. \ref{fig:case-study-2}B-2), four concepts except for grass were located in the left side of the plot, indicating they were biased towards in aeroplanes. As shown in Fig. \ref{fig:case-study-2}C-i, the top-associated images included aeroplanes leaving contrails over the sky (as cloud), in the middle of the runway airport (as straight), or with red \& blue prints (red\&blue stripes). She was wondering how the aspect of associations differs in the case of aeroplanes \& trains (Fig. \ref{fig:case-study-2}C). She clicked two classes in \confusionmatrix, explored the associations with the same concept set. Interestingly, the \textbf{red\&blue stripe} concepts were biased towards train class in this case. As summarized in Fig. \ref{fig:case-study-2}C-ii, the top-associated images were mostly trains with vivid prints on their bodies that are zoomed in thus take the most spaces in the images.

While further exploring \confusionmatrix (Fig. \ref{fig:case-study-2}A-i), she found that two sets of bottle images misclassified as cars or chairs were mostly colored as \textbf{red}, or \textbf{yellow} or placed in a house with many furnitures respectively, meaning the associated patterns were bound to the opposite class. She hypothesized multiple colors including \textbf{yellow}, \textbf{red}, \textbf{blue}, and \textbf{gray}, and \textbf{wood} as brown. she could find in the system that chair class was highly biased towards \textbf{yellow} and \textbf{wood}. As shown in Fig. \ref{fig:case-study-2}C-iii, the top-associated images in \textbf{yellow} concept in the training set were mostly chairs made of woods or placed in the wood floor exhibiting yellow colors.
