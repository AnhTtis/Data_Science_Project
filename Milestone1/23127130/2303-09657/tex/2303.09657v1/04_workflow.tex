\begin{figure*}[!ht]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/workflow.pdf}
    \caption{\label{fig:workflow}
    \textbf{The proposed workflow to guide the inspection of systematic errors and spurious concept associations.} A user starts with (T1) inspecting the degree of misclassifications to narrow down the scope of analysis to the potential regions with systematic errors. (T2) By observing interpretable concepts that exclusively appear in a certain class, users are provided to easily identify and hypothesize spurious associations between concepts and target classes. (T3) User-generated hypotheses can be validated via two aspects of systematic errors, associations, and attribution. (T4) Undesirable associations can be mitigated with a debias strategy in the system and evaluated how it helped mitigate the concept-class associations.
    }
\end{figure*}

\section{Workflow}

To address the challenges, we propose a workflow supported by our system to guide the inspection of systematic errors and spurious concept associations. Our workflow (Fig. \ref{fig:workflow}) consists of a range of four guided tasks (T1-T4) to diagnose, identify, validate, and mitigate the undesirable associations between concepts and target classes. We also describe how our system facilitates these tasks to address the aforementioned challenges in existing tools. \\

\hangindent=2em \textbf{T1. Diagnosis phase. Inspect the degree of misclassifications at the instance-level and class-level.} In Diagnosis phase (Fig. \ref{fig:workflow}-T1), users are guided to inspect the degree of misclassifications and model confidence and narrow down the scope of inspection to a subset of classes and instances that are vulnerable to systematic failures. To highlight systematic errors (C1), \name summarizes the degree of misclassifications and model confidence at the instance-level and class-level in the diagnostic modules highlighting misclassifications and unknown-unknowns. \\\vspace{-5pt}
    
\hangindent=2em \textbf{T2. Identification phase. Identify and hypothesize a biased association between patterns and target classes.} In Identification phase (Fig. \ref{fig:workflow}-T2), users are allowed to explore the patterns to hypothesize the associations between patterns and target classes. To support the task of hypothesizing suspicious patterns (C2), the system provides visual components that facilitate the comparison of patterns in different confusion cases. This helps users observe any patterns or concepts that are exclusively associated with a certain class. To test their hypotheses, users are provided with system modules to easily define a group of semantically coherent segments as concepts using the segmentation module in the system. \\\vspace{-5pt}
    
\hangindent=2em \textbf{T3. Validation phase. Verify the hypotheses over spurious concept association.} 
    In Validation phase (Fig. \ref{fig:workflow}-T3), users test their hypotheses by checking how concepts are associated with a certain class and influential towards misclassifications (C3). The system supports two-sided validations, associations, and attribution (details in Section \ref{sec:introduction}) quantified with statistical metrics described in Section \ref{sec:method}. These two aspects of associations are visualized for users to intuitively capture the concept associations and inspect the top-associated instances. \\\vspace{-5pt}
    
\hangindent=2em \textbf{T4. Mitigation phase. Remove the source of biases and mitigate the spurious associations.} In Mitigation phase (Fig. \ref{fig:workflow}-T4), users determine whether spurious associations between a concept and classes should be removed. When a strategy to mitigate the biases is performed, they need to evaluate whether spurious associations were removed (C4). In the system, we provide a statistical method to debias the training samples that are the most associated with a concept by neutralizing the representation of target instances via projection. In the system, this mitigation process is supported with interactive modules to visualize the effect of mitigation and help users determine the debiasing process.