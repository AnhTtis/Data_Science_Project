\section{Evaluation}
\label{sec:evaluation}

To validate the effectiveness of our system and methods, we conduct the evaluation in three ways. First, we conduct a quantitative evaluation on our two statistical methods, combined concept association (Section \ref{sec:method-concept-association}) and debiasing spurious concept association (Section \ref{sec:method-debiasing}). Second, we demonstrate the utility of \name with two case studies, expert interview and user study. Third, we conduct a controlled user experiment to evaluate how ML practitioners can successfully perform the workflow of inspecting systematic errors using \name. Throughout the evaluations, we use two different benchmark datasets to demonstrate the application of our approach as follows:

\begin{itemize}
    \item \textbf{Cats \& Dogs dataset (skewed/original)} \cite{cats_dogs}: In the first setting, we train two versions of the image classifier over original or skewed Cats \& Dogs dataset. First, the original dataset with 2,600 cats and dogs images was used as a setting to identify systematic errors of a model trained. On the other hand, the skewed dataset, where spurious associations from the original data were intensified by removing concept-related images in the minor classes in the training set, was also used to 1) simulate systematic errors to have more diverse concepts in the analysis and 2) have a set of ground truth concepts that are intentionally attribute systematic errors to validate how those concepts were effectively discovered and mitigated via our methods and system. These concepts include grass, person, jean/skyblue (biased towards dogs), cage, and red/pink objects (biased towards cats). We use the skewed setting to present a case study to demonstrate the usage scenario (Section \ref{sec:case-study-1}) and (3) to conduct a user study to validate the usefulness of the system with ML practitioners (Section \ref{sec:user-study}).
    \item \textbf{Pascal Voc dataset} \cite{pascalvoc}: This dataset demonstrates a multi-classification scenario with 20 classes including animals and objects to present a case study in Section \ref{sec:case-study-2}. We showcase systematic errors over four classes (bird, train, aeroplane, chair, and car) over five concepts (grass, sky, cloud, red\&blue, and straight).
    \item \textbf{CelebAMask-HQ} \cite{celeba-hq}: This dataset includes face images with 40 annotated attributes. We train a classifier on two gender classes (female and male) to demonstrate systematic errors over five classes (smiling, eyeglasses, wearing hat, not smiling, and blond hair).
\end{itemize}

\textbf{Implementation.} Throughout the settings, we implement the image classifications using Resnet50, a convolutional neural network with residual components consisting of 16 blocks of bottleneck layers in a total of 50 individual layers. We employ a pre-trained ResNet50 model \cite{he2016deep} over ImageNet dataset from Pytorch\footnote{https://pytorch.org/} as a base model and train it with either Cats \& Dogs or Pascal Voc dataset described above. Throughout the analysis, we choose 14th bottleneck layer located in the later part of the layer structure with the 8x8x2048 dimension of internal representations of instances and segments.