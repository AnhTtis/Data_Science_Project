% string{icassp = "Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"}
% string{interspeech = "Proceedings of Conference of the International Speech Communication Association"}
@string{asru = "Proceedings of IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU)"}
@string{lrec = "Proceedings of International Conference on Language Resources and Evaluation (LREC)"}
@string{ieee-taslp = "IEEE Transactions on Audio, Speech, and Language Processing"}
% string{ieee-acm-taslp = "IEEE/ACM Transactions on Audio, Speech and Language Processing"}
@string{ieee-pami = "IEEE Transactions on Pattern Analysis and Machine Intelligence"}
@string{mlsp = "Proceedings of International Workshop on Machine Learning for Signal Processing (MLSP)"}
% string{waspaa = "IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)"}
% string{ijcnn = "International Joint Conference on Neural Networks (IJCNN)"}
@string{csl = "Computer speech \& language"}
string{slt = "Proceedings of IEEE Spoken Language Technology Workshop (SLT)"}
% @string{naacl = "Proceedings of Conference of the North {A}merican Chapter of the Association for Computational Linguistics (NAACL)"}
@string{emnlp = "Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP)"}
@string{prcv = "Proceedings of Chinese Conference on Pattern Recognition and Computer Vision (PRCV)"}
@string{ismir = "Proceedings of International Society for Music Information Retrieval"}
@string{aaai = "Proceedings of the AAAI Conference on Artificial Intelligence"}

@string{icassp = "Proc. IEEE ICASSP"}
@string{interspeech = "Proc. ISCA Interspeech"}
% string{asru = "Proc. IEEE ASRU"}
@string{waspaa = "Proc. IEEE WASPAA"}
% string{lrec = "Proc. LREC"}
@string{icml = "Proc. ICML"}
@string{ijcnn = "Proc. IJCNN"}
% @string{mlsp = "Proc. MLSP"}
@string{nips = "Proc. NIPS"}
% string{csl = "Comput. Speech Lang."}
% @string{slt = "Proc. IEEE SLT"}
@string{acl = "Proc. ACL"}
@string{naacl = "Proc. NAACL"}
@string{dcase = "Proc. DCASE"}
@string{iclr = "Proc. ICLR"}
@string{cvpr = "Proc. CVPR"}
@string{iccv = "Proc. ICCV"}
@string{eccv = "Proc. ECCV"}
@string{bmvc = "Proc. BMVC"}
@string{cikm = "Proc. CIKM"}
@string{ism = "Proc. ISM"}
% string{emnlp = "Proc. EMNLP"}
% @string{eusipco = "Proc. IEEE EUSIPCO"}
@string{cvprw = "Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)"}
@string{acm-mm = "Proc. ACM MM"}
@string{ieee-acm-taslp = "IEEE/ACM TASLP"}

@string{iccvw = "Proceedings of the IEEE International Conference on Computer Vision Workshops (ICCVW)"}
@string{bmvc = "British Machine Vision Conference (BMVC)"}
% string{acm-mm = "Proceedings of ACM International Conference on Multimedia"}
@string{conll = "Proceedings of Conference on Computational Natural Language Learning (CoNLL)"}
@string{eacl = "Proceedings of the European Chapter of the Association for Computational Linguistics"}
@string{iscslp = "Proceedings of the International Symposium on Chinese Spoken Language Processing (ISCSLP)"}
@string{sigir = "International ACM SIGIR Conference on Research \& Development in Information Retrieval"}

%Entries

@article{van2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Van den Oord and others},
  journal={arXiv preprint arXiv:1807.03748},
  volume={2},
  number={3},
  pages={4},
  year={2018}
}

@article{kong2020panns,
  title={Panns: Large-scale pretrained audio neural networks for audio pattern recognition},
  author={Kong, Qiuqiang and Cao, Yin and Iqbal, Turab and Wang, Yuxuan and Wang, Wenwu and Plumbley, Mark D},
  journal=ieee-acm-taslp,
  volume={28},
  pages={2880--2894},
  year={2020}
}

@inproceedings{gong2021audio,
  author = {Gong, Yuan and Chung, Yu An and Glass, James},
  booktitle = interspeech,
  pages = {56--60},
  title = {AST: Audio Spectrogram Transformer},
  year = {2021}
}

@article{turc2019well,
  title={Well-read students learn better: On the importance of pre-training compact models},
  author={Turc, Iulia and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1908.08962},
  year={2019}
}

@inproceedings{devlin2019bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristin},
  booktitle=naacl,
  pages={4171--4186},
  year={2019}
}

@inproceedings{kim2019audiocaps,
  author = {Kim, Chris Dongjoo and Kim, Byeongchang and Lee, Hyunmin and Kim, Gunhee},
  booktitle=naacl,
  pages = {119--132},
  title = {AudioCaps: Generating Captions for Audios in The Wild},
  year = {2019}
}

@inproceedings{drossos2020clotho,
  title={Clotho: An audio captioning dataset},
  author={Drossos, Konstantinos and Lipping, Samuel and Virtanen, Tuomas},
  booktitle=icassp,
  pages={736--740},
  year={2020}
}

@inproceedings{martin2021diversity,
    author = "Martin, Irene and Mesaros, Annamaria",
    title = "Diversity and Bias in Audio Captioning Datasets",
    booktitle = dcase,
    year = "2021",
    pages = "90--94",
}

@inproceedings{font2013freesound,
  title={Freesound technical demo},
  author={Font, Frederic and Roma, Gerard and Serra, Xavier},
  booktitle=acm-mm,
  pages={411--412},
  year={2013}
}

@article{loshchilov2016sgdr,
  title={Sgdr: Stochastic gradient descent with warm restarts},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1608.03983},
  year={2016}
}

@inproceedings{zhou2022can,
  title={Can audio captions be evaluated with image caption metrics?},
  author={Zhou, Zelin and Zhang, Zhiling and Xu, Xuenan and Xie, Zeyu and Wu, Mengyue and Zhu, Kenny Q},
  booktitle=icassp,
  pages={981--985},
  year={2022}
}

@inproceedings{guzhov2022audioclip,
  title={Audioclip: Extending clip to image, text and audio},
  author={Guzhov, Andrey and Raue, Federico and Hees, J{\"o}rn and Dengel, Andreas},
  booktitle=icassp,
  year={2022},
  pages={976--980},
}

@inproceedings{zhao2022connecting,
    title = "Connecting the Dots between Audio and Text without Parallel Data through Visual Knowledge Transfer",
    author = "Zhao, Yanpeng and Hessel, Jack and Yu, Youngjae and Lu, Ximing and Zellers, Rowan and Choi, Yejin",
    booktitle = naacl,
    year = "2022",
    pages = "4492--4507",
}

@inproceedings{wu2022wav2clip,
  title={Wav2CLIP: Learning Robust Audio Representations From CLIP},
  author={Wu, Ho-Hsiang and Seetharaman, Prem and Kumar, Kundan and Bello, Juan Pablo},
  booktitle=icassp,
  year={2022}
}

@inproceedings{bengio2015scheduled,
  title={Scheduled sampling for sequence prediction with recurrent Neural networks},
  author={Bengio, Samy and Vinyals, Oriol and Jaitly, Navdeep and Shazeer, Noam},
  booktitle=nips,
  pages={1171--1179},
  year={2015}
}

@inproceedings{szegedy2016rethinking,
  title={Rethinking the inception architecture for computer vision},
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle=cvpr,
  pages={2818--2826},
  year={2016}
}

@article{izmailov2018averaging,
  title={Averaging weights leads to wider optima and better generalization},
  author={Izmailov, Pavel and Podoprikhin, Dmitrii and Garipov, Timur and Vetrov, Dmitry and Wilson, Andrew Gordon},
  journal={arXiv preprint arXiv:1803.05407},
  year={2018}
}

@article{koizumi2020audio,
  title={Audio Captioning using Pre-Trained Large-Scale Language Model Guided by Audio-based Similar Caption Retrieval},
  author={Koizumi, Yuma and Ohishi, Yasunori and Niizumi, Daisuke and Takeuchi, Daiki and Yasuda, Masahiro},
  journal={arXiv preprint arXiv:2012.07331},
  year={2020}
}

@inproceedings{eren2020semantic,
  author = {Eren, Ay{\c{s}}eg{\"u}l {\"O}zkaya and Sert, Mustafa},
  booktitle = ism,
  title = {{Audio Captioning Based on Combined Audio and Semantic Embeddings}},
  year = {2020},
  pages={41--48},
}

@inproceedings{zhang2021enriching,
  title={Enriching Ontology with Temporal Commonsense for Low-Resource Audio Tagging},
  author={Zhang, Zhiling and Zhou, Zelin and Tang, Haifeng and Li, Guangwei and Wu, Mengyue and Zhu, Kenny Q},
  booktitle=cikm,
  pages={3652--3656},
  year={2021}
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle=eccv,
  pages={740--755},
  year={2014},
  organization={Springer}
}

@inproceedings{sharma2018conceptual,
  title={Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning},
  author={Sharma, Piyush and Ding, Nan and Goodman, Sebastian and Soricut, Radu},
  booktitle=acl,
  pages={2556--2565},
  year={2018}
}

@inproceedings{chen2020uniter,
  title={Uniter: Universal image-text representation learning},
  author={Chen, Yen-Chun and Li, Linjie and Yu, Licheng and El Kholy, Ahmed and Ahmed, Faisal and Gan, Zhe and Cheng, Yu and Liu, Jingjing},
  booktitle=eccv,
  pages={104--120},
  year={2020},
  organization={Springer}
}

@inproceedings{li2020oscar,
  title={Oscar: Object-semantics aligned pre-training for vision-language tasks},
  author={Li, Xiujun and Yin, Xi and Li, Chunyuan and Zhang, Pengchuan and Hu, Xiaowei and Zhang, Lei and Wang, Lijuan and Hu, Houdong and Dong, Li and Wei, Furu and others},
  booktitle=eccv,
  pages={121--137},
  year={2020},
  organization={Springer}
}


@inproceedings{lu2019vilbert,
  title={ViLBERT: pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
  author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  booktitle=nips,
  pages={13--23},
  year={2019}
}

@inproceedings{su2019vl,
  title={VL-BERT: Pre-training of Generic Visual-Linguistic Representations},
  author={Su, Weijie and Zhu, Xizhou and Cao, Yue and Li, Bin and Lu, Lewei and Wei, Furu and Dai, Jifeng},
  booktitle=iclr,
  year={2019},
  pages={1--16}
}

@article{krishna2017visual,
  title={Visual genome: Connecting language and vision using crowdsourced dense image annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  journal={IJCV},
  volume={123},
  number={1},
  pages={32--73},
  year={2017}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle=icml,
  pages={8748--8763},
  year={2021}
}

@inproceedings{jia2021scaling,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle=icml,
  pages={4904--4916},
  year={2021},
  organization={PMLR}
}

@inproceedings{wang2021simvlm,
  title={SimVLM: Simple Visual Language Model Pretraining with Weak Supervision},
  author={Wang, Zirui and Yu, Jiahui and Yu, Adams Wei and Dai, Zihang and Tsvetkov, Yulia and Cao, Yuan},
  booktitle=iclr,
  year={2021},
  pages={1--17}
}


@inproceedings{wang2022ofa,
  title={Ofa: Unifying architectures, tasks, and modalities through a simple sequence-to-sequence learning framework},
  author={Wang, Peng and Yang, An and Men, Rui and Lin, Junyang and Bai, Shuai and Li, Zhikang and Ma, Jianxin and Zhou, Chang and Zhou, Jingren and Yang, Hongxia},
  booktitle=icml,
  pages={23318--23340},
  year={2022},
  organization={PMLR}
}

@inproceedings{chen2020vggsound,
  title={Vggsound: A large-scale audio-visual dataset},
  author={Chen, Honglie and Xie, Weidi and Vedaldi, Andrea and Zisserman, Andrew},
  booktitle=icassp,
  pages={721--725},
  year={2020}
}

@inproceedings{drossos2017automated,
  title={Automated audio captioning with recurrent neural networks},
  author={Drossos, Konstantinos and Adavanne, Sharath and Virtanen, Tuomas},
  booktitle=waspaa,
  pages={374--378},
  year={2017}
}

@inproceedings{oncescu21audio,
  author={Andreea-Maria Oncescu and A. Sophia Koepke and Jo√£o F. Henriques and Zeynep Akata and Samuel Albanie},
  title={{Audio Retrieval with Natural Language Queries}},
  booktitle = interspeech,
  year = "2021",
  pages={2411--2415}
}

@inproceedings{akbari2021vatt,
  title={Vatt: Transformers for multimodal self-supervised learning from raw video, audio and text},
  author={Akbari, Hassan and Yuan, Liangzhe and Qian, Rui and Chuang, Wei-Hong and Chang, Shih-Fu and Cui, Yin and Gong, Boqing},
  booktitle=nips,
  volume={34},
  year={2021},
  pages = {24206--24221},
}

@inproceedings{alayrac2020self,
  title={Self-supervised multimodal versatile networks},
  author={Alayrac, Jean-Baptiste and Recasens, Adria and Schneider, Rosalia and Arandjelovi{\'c}, Relja and Ramapuram, Jason and De Fauw, Jeffrey and Smaira, Lucas and Dieleman, Sander and Zisserman, Andrew},
  booktitle=nips,
  volume={33},
  pages={25--37},
  year={2020}
}

@inproceedings{miech2019howto100m,
  title={Howto100m: Learning a text-video embedding by watching hundred million narrated video clips},
  author={Miech, Antoine and Zhukov, Dimitri and Alayrac, Jean-Baptiste and Tapaswi, Makarand and Laptev, Ivan and Sivic, Josef},
  booktitle=iccv,
  year={2019},
  pages={2630--2640},
}

@article{fonseca2022fsd50k,
  title={Fsd50k: an open dataset of human-labeled sound events},
  author={Fonseca, Eduardo and Favory, Xavier and Pons, Jordi and Font, Frederic and Serra, Xavier},
  journal=ieee-acm-taslp,
  volume={30},
  pages={829--852},
  year={2022}
}

@inproceedings{mesaros2018multi,
  title={A multi-device dataset for urban acoustic scene classification},
  author={Mesaros, Annamaria and Heittola, Toni and Virtanen, Tuomas},
  booktitle=dcase,
  pages={9--13},
  year={2018}
}

@inproceedings{gemmeke2017audio,
  title={Audio set: An ontology and human-labeled dataset for audio events},
  author={Gemmeke, Jort F and Ellis, Daniel PW and Freedman, Dylan and Jansen, Aren and Lawrence, Wade and Moore, R Channing and Plakal, Manoj and Ritter, Marvin},
  booktitle=icassp,
  pages={776--780},
  year={2017}
}

@inproceedings{cakir2015polyphonic,
  title={Polyphonic sound event detection using multi label deep neural networks},
  author={Cakir, Emre and Heittola, Toni and Huttunen, Heikki and Virtanen, Tuomas},
  booktitle=ijcnn,
  pages={1--7},
  year={2015}
}

@article{gong2021psla,
  author = {Gong, Yuan and Chung, Yu-An and Glass, James},
  journal = ieee-acm-taslp,
  pages = {3292--3306},
  title = {{PSLA: Improving Audio Tagging With Pretraining, Sampling, Labeling, and Aggregation}},
  volume = {29},
  year = {2021}
}

@inproceedings{antol2015vqa,
  title={Vqa: Visual question answering},
  author={Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Zitnick, C Lawrence and Parikh, Devi},
  booktitle=iccv,
  pages={2425--2433},
  year={2015}
}

@inproceedings{zellers2019recognition,
  title={From recognition to cognition: Visual commonsense reasoning},
  author={Zellers, Rowan and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},
  booktitle=cvpr,
  pages={6720--6731},
  year={2019}
}

@inproceedings{kazakos2021slow,
  title={Slow-fast auditory streams for audio recognition},
  author={Kazakos, Evangelos and Nagrani, Arsha and Zisserman, Andrew and Damen, Dima},
  booktitle=icassp,
  pages={855--859},
  year={2021}
}

@techreport{chen2019integrating,
    Author = "Chen, Hangting and Liu, Zuozhen and Liu, Zongming and Zhang, Pengyuan and Yan, Yonghong",
    title = "Integrating the Data Augmentation Scheme with Various Classifiers for Acoustic Scene Modeling",
    institution = "DCASE2019 Challenge",
    year = "2019",
    month = "June",
}

@inproceedings{saeed2021contrastive,
  title={Contrastive learning of general-purpose audio representations},
  author={Saeed, Aaqib and Grangier, David and Zeghidour, Neil},
  booktitle=icassp,
  pages={3875--3879},
  year={2021}
}

@inproceedings{al2021clar,
  title={Clar: Contrastive learning of auditory representations},
  author={Al-Tahan, Haider and Mohsenzadeh, Yalda},
  booktitle={Proc. AISTATS},
  pages={2530--2538},
  year={2021},
  organization={PMLR}
}

@inproceedings{baevski2020wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  booktitle=nips,
  volume={33},
  pages={12449--12460},
  year={2020}
}

@article{hsu2021hubert,
  title={Hubert: Self-supervised speech representation learning by masked prediction of hidden units},
  author={Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
  journal=ieee-acm-taslp,
  volume={29},
  pages={3451--3460},
  year={2021}
}

@article{chen2022wavlm,
  title={Wavlm: Large-scale self-supervised pre-training for full stack speech processing},
  author={Chen, Sanyuan and Wang, Chengyi and Chen, Zhengyang and Wu, Yu and Liu, Shujie and Chen, Zhuo and Li, Jinyu and Kanda, Naoyuki and Yoshioka, Takuya and Xiao, Xiong and others},
  journal={IEEE JSTSP},
  year={2022},
  volume={16},
  number={6},
  pages={1505--1518},
}

@inproceedings{niizumi2021byol,
  title={BYOL for audio: Self-supervised learning for general-purpose audio representation},
  author={Niizumi, Daisuke and Takeuchi, Daiki and Ohishi, Yasunori and Harada, Noboru and Kashino, Kunio},
  booktitle=ijcnn,
  pages={1--8},
  year={2021}
}

@inproceedings{koutini2022efficient,
  author={Koutini, Khaled and Schl{\"u}ter, Jan and Eghbal-zadeh, Hamid and Widmer, Gerhard},
  title={Efficient Training of Audio Transformers with Patchout},
  year=2022,
  booktitle=interspeech,
  pages={2753--2757},
}

@inproceedings{elizalde2023clap,
  title={Clap learning audio concepts from natural language supervision},
  author={Elizalde, Benjamin and Deshmukh, Soham and Al Ismail, Mahmoud and Wang, Huaming},
  booktitle=icassp,
  pages={1--5},
  year={2023},
  organization={IEEE}
}

@techreport{xu2022sjtu,
    Author = "Xu, Xuenan and Xie, Zeyu and Wu, Mengyue and Yu, Kai",
    title = "The {SJTU} System for {DCASE2022} Challenge Task 6: Audio Captioning with Audio-Text Retrieval Pre-training",
    institution = "DCASE2022 Challenge",
    year = "2022",
}

@inproceedings{xu2021investigating,
  title={Investigating local and global information for automated audio captioning with transfer learning},
  author={Xu, Xuenan and Dinkel, Heinrich and Wu, Mengyue and Xie, Zeyu and Yu, Kai},
  booktitle=icassp,
  pages={905--909},
  year={2021}
}

@inproceedings{chen2020audio,
  title={Audio Captioning Based on Transformer and Pre-Trained CNN.},
  author={Chen, Kun and Wu, Yusong and Wang, Ziyue and Zhang, Xuan and Nian, Fudong and Li, Shengchen and Shao, Xi},
  booktitle=dcase,
  pages={21--25},
  year={2020}
}