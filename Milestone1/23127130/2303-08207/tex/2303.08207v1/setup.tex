\section{Problem Setup and Metrics} \label{sec:problem_setup}

We consider a supervised continual learning setting consisting of a sequence of tasks $\taskset = \{T_1, \cdots, T_N\}$.
%
A task $T_j$ is defined by a dataset $\dataset_j = \{(x_i, y_i, t_i)_{i=1}^{n_j}\}$, consisting of $n_j$ triplets, where $x \in \ipspace$, $y \in \opspace$, and $t \in \taskspace$ are input, label and task id, respectively.
%
Each $\dataset_j = \{\datasettr_j, \datasetval_j, \datasette_j\}$ consists of train, validation and test sets. 
%
At a given task `j', the learner may have access to all the previous tasks' datasets $\{\dataset_i\}_{i < j}$, but it will not have access to the future tasks.  
%
We define a feed-forward neural network consisting of a feature extractor $\representation: \ipspace \mapsto \representationspace$ and a task-specific classifier $\classifier_j: \mathbb{R}^D \times \taskspace \mapsto \opspace_j$, that implements an input to output mapping $f_j = (\classifier_j \circ \representation): \ipspace \times \taskspace \mapsto \opspace_j$.
%
The neural network is trained by minimizing a loss $\ell_j: f_j(\ipspace, \taskspace) \times \opspace_j \mapsto \real^+$ using stochastic gradient descent (SGD) \citep{bottou2010large}.
%
While we consider image classification tasks and use cross-entropy loss for each task, the approach would be applicable to other tasks and loss functions as well. 

The learner updates a shared feature extractor ($\representation$) and task-specific heads ($\classifier_j$) throughout the continual learning experience.
%
After training on each task `i', we measure the performance of the learner on all the tasks observed so far.
%
Let $\acc(i, j)$ be the accuracy of the model on $\datasette_j$ after the feature extractor is updated with $T_i$.
%
We define the average forgetting metric at task `i' similar to \citep{lopez2017gradient}:

\begin{equation*}
    \fgt_i = \frac{1}{i-1} \sum_{j=1}^{i-1} \acc(i, j) - \acc(j, j) .
\end{equation*}

The average forgetting metric ($\in [-1, 1]$) throughout the continual learning is then defined as,

\begin{equation} \label{eq:avgfgt}
    \avgfgt = \frac{1}{N-1} \sum_{i=2}^N \fgt_i .
\end{equation}

A negative value of $\fgt_i$ indicates that the learner has lost performance on the previous tasks, and the more negative \avgfgt\ is the more forgetful the representations are of the previous knowledge.


\begin{figure*}[t]
\centering
  \includegraphics[scale=0.4]{figs/k_shot_eval.pdf}
  \negspace{-1mm}
  \caption{\small Illustration of continual learning and k-shot evaluation process. We continuously train the feature extractor and the classification head on a task sequence  $T_1, \dots, T_N$. $\classifier_j \circ \representation_j$ is the model obtained after training on $T_j$. To evaluate the forward transfer of $\representation_j$, we use linear probing on k-shot samples from the next task $T_{j+1}$ to learn a classifier $\hat{\classifier}$ and then evaluate the accuracy of $\hat{\classifier} \circ \representation_j$ on the test set $\datasette_{j+1}$ from the task $T_{j+1}$.}
\label{fig:kshot_linear_probing}
\negspace{-3mm}
\end{figure*}


\paragraph{Forward Transfer through K-Shot Probing} 

We measure forward transfer in terms of how \emph{easy} it is to learn a new task given continually trained representations.
%
The easiness is measured by learning a linear classifier on top of the \emph{fixed} representations using a small subset of the data of the new task (refer to \Figref{fig:kshot_linear_probing} for illustration). 
%
Specifically, let $\sample_{j+1}^k \stackrel{k}{\sim} \datasettr_{j+1}$ denote a sample consisting of `k' examples per class from $\datasettr_{j+1}$, and let $\representation_j$ be the representations obtained after training on task `j' (see the bottom blob of \Figref{fig:kshot_linear_probing}).
%
Let $\hat{\classifier}$ be the temporary (linear) classifier head learned on top of fixed $\representation_j$ using $\sample_{j+1}^k$.
%
We measure the accuracy of this temporary classifier on the test set of task `j+1' and denote it as $\fwt_j$.
%
This is called the forward transfer of learned representations $\representation_j$ to the next task `j+1'.
%
The average forward transfer throughout the continual learning is then defined as,

\begin{equation} \label{eq:avgfwt}
    \avgfwt = \frac{1}{N-1} \sum_{j=1}^{N-1} \fwt_j .
\end{equation}

We note that linear probing is an auxiliary evaluation process where model updates during evaluation remain distinct from the updates made by the continual learner while observing a task sequence.
%We note that our linear probing is an auxiliary evaluation process performed prior to the updating the representations using the current task's data.
%
Contrary to this, in most prior works~\citep{wolczyk2021continual, lopez2017gradient}, forward transfer is measured after the continual learner has made updates on the task.
%
Such updates typically restrict the learning on current task to alleviate catastrophic forgetting on the previous tasks.
%
This causes the learner to perform worse on the current task compared to a learner that is not trying to mitigate catastrophic forgetting.
%to the current task is measured either during or after training on the task, in which case the representations learned at the start of the current task have been modified.
%
%However, such modifications to the learned representations on the current task, which typically involve  alleviating catastrophic forgetting on the previous tasks, can lead the learner to perform worse on the current task as compared to a learner that is not trying to mitigate catastrophic forgetting.
%
We sidestep this dilemma by separating the updates made by the continual learner on a new task from the temporary updates made during auxiliary evaluation on a copy of the model.
%
We also note that similar to linear probing, one could finetune the whole model, including the representations, during the auxiliary evaluation.
%
The main argument is to decouple the notion of forward transfer from modifications made by the continual learning algorithm to preserve knowledge of the previous tasks.

%linear probing is just one of the ways of decoupling the nptio
%evaluating a separate copy of the model that is finetuned just on the incoming task. 
%measuring performa

% modifications made to the learning algorithm to preserve knowledge of the previous tasks.
%a learner's performance on a task separately from a continual training 

%on new tasks in a way that keeps the learned representations from prior tasks fixed thereby decouples the notion of measuring forward transfer from learning modifications made to preserve previous tasks.
% 

%Further, the proposed evaluation allows us to reason about the transferability of a representation at a given time step independent of the continual learning algorithm used at that step which is important for this study as we seek to answer \emph{are less forgetful representations more transferable?}

\paragraph{Feature Diversity}

In addition to $\avgfgt$ (\Eqref{eq:avgfgt}) and $\avgfwt$ (\Eqref{eq:avgfwt}), we also measure how diverse and easily separable the features of our trained models are for analyzing the transferability of the representations.
%
Specifically, let $\representationmat_j \in \real^{m \times D}$ be the feature matrix computed using the feature extractor $\representation_j$ (obtained after training on task `j') on the `$m$' test examples of task `j+1'.
%
Let $\representationmat_j^c$ be a sub-matrix constructed by collecting the rows of $\representationmat_j$ that belong to class `c'.
%Here, the entries of $\Psi_j$ are normalized on a per-class basis so that the square of the Frobenius norm of each $\Psi_j^c$ is equal to $m_j$, the number of elements of class $c$ in task `j'.
%
Similar to \citep{wu2021incremental,yu2020learning}, we define the feature diversity score of $\representation_j$ as
%
\begin{equation*}
    \fdiv_j = \log |\alpha \representationmat_j^{\top}\representationmat_j + \mathbf{I}| - \sum_{c=1}^{C_{j}} \log |\alpha_j \representationmat_j^c{}^{\top}\representationmat_j^c + \mathbf{I}|,
\end{equation*}

where $|\cdot|$ is a matrix determinant operator, $\alpha = D/ (m \epsilon^2)$, $\alpha_j = D/ (m_j \epsilon^2)$, $\epsilon=0.5$, and $C_j$ denotes the number of classes for task `j'.
%
The average feature score throughout the continual learning experience is then defined as,

\begin{equation}  \label{eq:fdiv}
    \avgfdiv = \frac{1}{N-1}\sum_{j=1}^{N-1} \fdiv_j.
\end{equation}
%
The intuition behind using this score is that features that enforce high inter-class separation and low intra-class variability should make it easier to learn a classifier head on top leading to a better transfer to next tasks. 

