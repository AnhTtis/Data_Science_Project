\section{Introduction} \label{sec:introduction}
%% Outline
% reducing forgetting is the main goal of many existing cl works. 

% However, it is not clear if in many applications performance on the past data needs to be maintained. Instead ability to quickly learn new tasks is preferred. 

% Some recent works in fact argue that focusing on forgetting may not be the right thing to do and one should instead design methods that explicitly encourage forward transfer. 

% With a focus of few-shot forward transfer, we studied how forgetting interacts with transfer. Our main finding is that a less forgetful model transfer better. Our analysis of less forgetful models reveal that their features remain more diverse compared to a forgetful model resulting in an improved forward transfer.

Continual learning aims to improve learned representations over time without having to train from scratch as more data or tasks become available.
%
% In a typical continual learning setting, a learner observes a sequence of tasks and attempts to maintain a single model capable of performing well on all the tasks observed so far.
%
This objective is especially relevant in the context of large scale models trained on massive scale data, where training from scratch is prohibitively costly.
%
However, the standard stochastic gradient descent (SGD) training, relying on the IID assumption of data, results in a severely degraded performance on old tasks when the model is continually updated on new tasks.
%In a continual learning setting, a model accrues knowledge from a sequence of tasks to learn new tasks more efficiently -- either using less training data, less compute, better final performance or any combination thereof.
%
This phenomenon is referred to as catastrophic forgetting~\citep{McCloskey1989CatastrophicII, goodfellow2016deep} and has been an active area of research \citep{Kirkpatrick2016EWC,lopez2017gradient,PackNet}.
%
Intuitively, the reduction in catastrophic forgetting allows the learner to accrue knowledge from the past, and use it to learn new tasks more efficiently -- either using less training data, less compute, better final performance or any combination thereof.
%
This phenomenon of efficiently learning new tasks using previous information is referred to as forward transfer.
%On the flip side, instead of focusing on old tasks, there is the phenomenon of forward transfer that involves efficiently learning new tasks using previous information.

Catastrophic forgetting and forward transfer are often thought of as competing desiderata of continual learning where one has to strike a balance between the two depending on the application at hand \citep{hadsell2020embracing}.
%
Specifically, \citet{wolczyk2021continual} recently studied the interplay of forgetting and forward transfer in the robotics context, and found that many continual learning approaches alleviate catastrophic forgetting at the expense of forward transfer. 
%
This is indeed unavoidable if the capacity of the model is less than the amount of information we intend to store. 
%
However, assuming that the model has sufficient capacity to learn all the tasks simultaneously, as in multitask learning, one might think that a less forgetful model could transfer its retained knowledge to future tasks when they are similar to past ones. 
%
%\sout{Even if the future tasks are different, less forgetting implies larger knowledge base that could be relied upon when learning a new task, which should improve the forward transfer (unless forgetting is reduced trivially by restricting the model capacity to learn a new task).}

In this work, therefore, we argue for looking at the trade-off between forgetting and forward transfer
in the right perspective.
%
Typically, forward transfer is measured as the learning accuracy on a task after the continual learner has already made training updates from the task~\citep{wolczyk2021continual, chaudhry2018efficient, lopez2017gradient}.
%
However, since such training updates are usually modified to preserve performance on previous tasks (e.g. EWC~\citep{Kirkpatrick2016EWC}), a competition arises between maximizing learning accuracy and mitigating catastrophic forgetting. 
%\sout{Since a continual learning algorithm modifies the learning on the current task to preserve performance on previous tasks, the learning accuracy, as a measure of forward transfer, creates a competition between the notion of transfer and catastrophic forgetting such that the improvement in the latter may not lead to an improvement in the former.}
%
%\sout{For example, EWC~\citep{Kirkpatrick2016EWC}, a regularization-based continual learning algorithm, regularizes the training on new tasks to preserve the performance on previous tasks.
%
%In doing so, it may restrict the learning on new tasks creating a tension between reduction in catastrophic forgetting and forward transfer to new tasks.}
%
\emph{Therefore, we argue for a measure of forward transfer that is unconstrained from any training modifications made to preserve previous knowledge.}
%
We propose to use \emph{auxiliary evaluation} of continually trained representations as a measure of forward transfer which is separate from the continual training of the model. 
%
Specifically, at the arrival of a new task, we fix the representations learned on the previous task and evaluate them on the new task.
%
This evaluation is done by learning a temporary classifier using a small subset of data from the new task and measuring performance on the test set of the task.
%
The continual training on the new task then proceeds with the updates to the representations (and the classifier) with the full training dataset of the task.
%The evaluation is done by appending a temporary classifier head on the representations learned so far and learning it using a small subset of the dataset from the new task and measuring performance on the test set of the task, before updating the representations with the full data of the new task.
%
We note that this notion of forward transfer removes the tug of war between forgetting the previous tasks and transfer to the next task, and it is with this notion of transfer that we ask the question \emph{are less forgetful representations more transferable?}

We analyze the interplay of catastrophic forgetting and forward transfer on several supervised continual learning benchmarks and algorithms.
%We analyze the forward transfer of representations learned through various continual learning algorithms on a variety of supervised classification benchmarks.
%
For this work, we restrict ourselves to the task-based continual learning setting, where task information is assumed at both train and test times as it makes the aforementioned evaluation based on auxiliary classification at fixed points easily interpretable.
%
Our results demonstrate that \emph{a less forgetful model in fact transfers better} (cf. \Figref{fig:split_cifar100_fgt_fwt}).
%
We find this observation to be true for both randomly initialized models as well as for models that are initialized from a pre-trained model.
%
We further analyse the reasons of this better transferability and find that less forgetful models result in more diverse and easily separable representations making it easier to learn a classifier head on top.
%
We note that with these results, we want to emphasize that the continual learning community should look at the trade-off between forgetting and forward transfer in the right perspective.
%
The learning accuracy based measure of forward transfer is useful for end-to-end learning on a fixed benchmark and it creates a trade-off between forgetting and forward transfer as rightly demonstrated by \citet{hadsell2020embracing, wolczyk2021continual}.
%
However, in the era of foundation models where pretrain-then-finetune is a dominant paradigm and where one often does not know a priori the tasks where a foundation model will be finetuned, a measure of forward transfer that looks at the capability of a backbone model to be finetuned on several downstream tasks is perhaps a more apt measure. 
%
%\sout{Under this perspective of forward transfer, we found that continual learning with reduced catastrophic forgetting leads to more transferable representations.}
%indeed creates a trade-off between forgetting and forward transfer as demonstrated by 
%we do not claim that the findings of previous studies \citep{hadsell2020embracing, wolczyk2021continual} are in conflict with ours.
%
%The forward transfer metric used in those studies focused on end-to-end learning of tasks. 
%
%Whereas, we provide a different lens for evaluating forward transfer -- one that looks at the suitability of a backbone model that can be finetuned to different downstream tasks. 
%
%This new way of looking at forward transfer in continual learning is particularly suitable for pretrain-then-finetune paradigm that is prevalent in large-scale (foundation) models.
%
%We found that under this notion of forward transfer, continual learning with reduced catastrophic forgetting leads to more transferable representations.} 

The rest of the paper is organized as follows. In \Secref{sec:problem_setup}, we describe the training and evaluation setups considered in this work. In \Secref{sec:experiments}, we provide experimental details followed by the main results of the paper. \Secref{sec:related_works} lists down most relevant works to our study. We conclude with \Secref{sec:conclusion} providing some hints to how the findings of this study can be useful for the future research. 


\begin{figure}[t]
\centering
\begin{subfigure}{.48\textwidth}
      \centering
      \includegraphics[width=.99\linewidth]{figs/split_cifar100_Random_init_avg_forgetting.pdf}
      \caption{\small Average Forgetting ($\uparrow$ better)}
\end{subfigure}\hfill
\begin{subfigure}{.48\textwidth}
      \centering
      \includegraphics[width=.99\linewidth]{figs/split_cifar100_Random_init_avg_fwt.pdf}
      \caption{\small Average Forward Transfer ($\uparrow$ better)}
\end{subfigure}\hfill

\negspace{-1mm}
\caption{Comparing average forgetting with average forward transfer for different continual learning methods using random initialization on the Split CIFAR-100 benchmark. FOMAML has less forgetting and thus better forward transfer. }
\label{fig:split_cifar100_fgt_fwt}
\negspace{-5mm}
\end{figure}









