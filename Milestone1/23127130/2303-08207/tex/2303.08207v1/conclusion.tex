\section{Conclusion} \label{sec:conclusion}
\negspace{-1mm}
%The question of how to accrue knowledge from the past tasks to learn new tasks more efficiently has been an active area of research.
%
%This question is ever more relevant with the recent advancements in the large scale models trained using internet scale data.
%
%The observation that the performance on earlier tasks degrades during the course of training on newer tasks (catastrophic forgetting) led to the development of continual learning algorithms that try to alleviate catastrophic forgetting.
%
%Similar to some previous work, here we question what effect alleviating catastrophic forgetting has on the efficiency of learning new tasks.
%
%However, by contrast, we study forward transfer from the lens of evaluating the power of representations learned through the course of training on a sequence of tasks. 
%

%We evaluated several training algorithms on a sequence of tasks and find that, our forward transfer metric is highly correlated with the amount of knowledge retention (i.e. less negative forgetting score), indicating that forgetting less may serve as a good inductive bias for forward transfer.
%
%This is a significant outcome as it suggests that it is possible to improve the representation power of a model, and therefore achieve forward transfer, when continuously adapting models to new data while preserving earlier knowledge by utilizing techniques to alleviate catastrophic forgetting.
%

%Our suggested measure of forward transfer, that evaluates continually trained representations, also fits nicely in the context of ranking different large scale models, aka foundation models, where a model that can transfer to multiple downstream tasks is preferred. 
%
%The extrapolation of our findings could mean that a less forgetful foundation model -- where forgetting is evaluated on the upstream data -- should be preferred over a forgetful model, as the former could transfer better to downstream tasks. 
%\dg{Discuss future work. Mention utility in large scale models.}

%
%\dg{ rewrite attempt:
We are interested in understanding how to continuously accrue knowledge for sample efficient learning of downstream tasks.
%
Similar to some previous works, here we question what effect alleviating catastrophic forgetting has on the efficiency of learning new tasks.
%
However, by contrast, we study forward transfer by the auxiliary evaluation of continually trained representations learned through the course of training on a sequence of tasks.
%
To this end, we evaluated several training algorithms on a sequence of tasks and find that our forward transfer metric is highly correlated with the amount of knowledge retention (i.e. less negative forgetting score), indicating that forgetting less may serve as a good inductive bias for forward transfer.
%
%\sout{This is a significant outcome as it suggests that it is possible to improve the representation power of a model, and therefore achieve forward transfer when continuously adapting models to new data, provided model capacity is large enough.
%
%Most interestingly, forward transfer benefits from preserving earlier knowledge by utilizing techniques to alleviate catastrophic forgetting.}

The question of how to accrue knowledge from the past tasks to learn new tasks more efficiently is ever more relevant with the recent advancements in the large scale models trained using internet scale data,  aka foundation models, where we would want to avoid initialization from scratch to save computation time. 
%
Our suggested measure of forward transfer, that evaluates continually trained representations, also fits nicely in the context of comparing generalization of different large scale models, where a model that can transfer to multiple downstream tasks is preferred. 
%
We are in the era of discovering new capabilities of models, as new capabilities emerge with larger scale.
%
The extrapolation of our findings could mean that a less forgetful foundation model -- where forgetting is evaluated on the upstream data -- should be preferred over a forgetful model, as the former could transfer better to downstream tasks. This serves as a useful model selection mechanism which can be further explored in future research. 