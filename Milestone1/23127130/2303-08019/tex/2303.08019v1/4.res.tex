\subsection{Results}


\subsubsection{Results using Extracted Embeddings}

We compare the performance of acoustic and linguistic features with different aggregation strategies on the layer and time dimensions, including weighted-sum (WS) or single selected (Top, MS) for the layers, and mean (Mean) or attentive (Attention) pooling for the time-axis, as listed in the Table.~\ref{tab:feat}.

\input{tables/feat_compare}

It can be observed that, (i) the best single selected method outperforms the weighted-sum method for layer-wise representations; (ii) the attentive pooling method outperforms the mean pooling for the time-axis information; (iii) Whisper outperforms other acoustic models with the MS and attentive pooling methods; and (iv) linguistic representations generally outperform the acoustic representations.

For the first observation, we find that the weights in the WS method are not well-matched with the performance distributions using a single layer. For example, as shown in Fig.~\ref{fig:layer}, the topmost layers (larger layer No.) of Whisper and the middle layers of BERT show higher performance for the AD detection task, but the learned weights may also be distracted by the bottom layers in the WS method, which harms the performance. We study the performance on each layer in depth.
For the acoustic models, the observation of that the topmost layers outperforms others coincides with previous research that higher layers capture more word and semantic information \cite{pasad2021layer}, which are crucial for AD detection. This also supports the way of using the topmost layer for AD detection that is widely adopted in previous research \cite{koo2020exploiting,balagopalan2021comparing,syed2021automated}.
For the linguistic models, the observation of that middle layers outperforms others implies that the syntactic information is more important than the semantic information \cite{jawahar2019bert} for the AD detection, which is also intuitive, since the syntactic information can model the cognitive disorder better. 

\input{figs/layer_compare}

The second observation supports that the attentive pooling method captures richer statistics of temporal features than the mean pooling method.
The first and second observations also show that the layer and time dimensions of pretrained models have different importance in the AD detection task. Take the Whisper model as an example, the Attention-based time aggregation improves the accuracy scores by about 2.7\% relatively, while the MS layer aggregation is more effective and further improves it by about 9\% relatively.

The third observation reflects the robustness and effectiveness of the Whisper model for AD detection.
And the forth observation coincides with previous research \cite{pulido2020alzheimer,li2021comparative}.
% It is also interesting to find that the acoustic Whisper with Attentive pooling is comparable with linguistic features, which could be more robust and generalizable in multilingual tasks and more helpful for fully automatic AD-related tasks.
% It is also interesting to find that the performance of acoustic features is now comparable with that of linguistic ones, which could be more helpful for the fully automatic AD detection.
% Moreover, since acoustics can share universal characteristics across languages, the use of acoustic features from pretrained models contribute towards achieving language-independent AD detection.
It is also interesting to find that the performance of acoustic models is now comparable with that of linguistic ones, which worse a lot than the latter in the past.
The underlying mechanism of pretrained encoders is difficult to interpret, but we could intuitively explain the finding in terms of representation and pathology.
On the one hand, the high-level pretrained acoustic encoders could extract the semantic 
information, especially from the top layers, that is similar to the linguistic features and helpful for the AD detection task.
On the other hand, AD affects the participants' phonology and articulation~\cite{croot2000phonological,gayraud2011syntactic}, such as dysfluencies (aphasic to some degree) and hesitations, while acoustic encoders could also extract these features that may not be easily extracted from the text.
These encoded semantic and acoustic features could make acoustic models comparable to linguistic methods in the AD detection task.
The promising performance of acoustic models not only promotes the fully-automation of the AD detection task, but also could be helpful for multilingual generalization since some acoustic characteristics are more ``universal" across languages than linguistic ones.


% \input{tables/attn_viz}
\subsubsection{Results using Task-related Information}
\input{tables/corr}

We also compare the task-related correlation features with different keyword lists, including ``None'' (empty), ``Nouns''-only (named entities), ``Verbs''-only (actions) and combination of ``Nouns'' and ``Verbs''. It can be found that using keywords of ``Nouns`` performs better than using that of ``Verbs'' for AD detection task, which implies the ability of named entities retrieval are affected by Alzheimer's Disease and coincides with the fact that Named Task is important in the clinical cognitive tasks.
We also decouple the effect of task-related correlation by using an empty keyword list, and the performance drops to 52.34\%, which can be view as a random guess.
It can be also observed that using correlation with task-related keywords can achieve over 80\% accuracy scores, which is better than the linguistic measures in \cite{luz2020alzheimer}.

\subsubsection{Feature Combination Results}

Finally, we compare the performance of a combination of the acoustic (Whisper), linguistic (BERT) and task-related correlation (Corr.) features, as listed in Table~\ref{tab:mm}.
Generally, the combination of different modalities outperforms the other systems with a superior performance of 91.41\% accuracy, which implies that complementary information from various modalities helps AD detection.


\input{tables/multimodal}
