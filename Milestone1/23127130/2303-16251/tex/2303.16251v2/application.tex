\section{Application}
\label{sec:apx:application}

In this section, we will first show how he $L_2$ norm bounds of the previous sections can be 
extended to $L_\infty$ (supremum) norm bounds when the target function $f\in\Cs(\Kc)$ is 
differentiable at the origin and Lipschitz on a convex compact set $\Kc\subset\R^n$ including 
the origin. Then we will apply the theory to an approximate extension of the Model Reference 
Adaptive Control (MRAC) setup in \cite{lavretsky2013robust}.

\subsection{Extending the Error Bound to $L_\infty$ for Lipschitz Functions on Convex Compact
Sets}
\label{sec:apx:extLinf}

We assume that $\Kc$ is full dimension, with nonzero Lebesgue measure (volume) 
$\Vc=\mu(\Kc)>0$ and diameter $\Dc>0$. It also must hold that $\Kc\subseteq B_0(\rho)$ for a 
sufficiently large radius $0<\rho\leq\Dc$.

Then, for any approximation $\fhN$ of the form \eqref{eq:apx:baseApx} using an activation
function $\sigma$ satisfying Assumption~\ref{sigAsmpt}, we have
%=\sum_{i=1}^N\theta_i\,\sigma(\pariX)$,
that
\begin{align*}
&\abs{\sum_{i=1}^N \theta_i\,\sigma(\pariX) - \sum_{i=1}^N \theta_i\,\sigma(\pariY)} \\ 
&\leq \sum_{i=1}^N \abs{\theta_i\,\sigma(\pariX) - \theta_i\,\sigma(\pariY)} 
\\
&= \sum_{i=1}^N |\theta_i|\!\abs{\sigma(\pariX) - \sigma(\pariY)}
\leq
\sum_{i=1}^N |\theta_i|\Lsig\abs{\pariX - \pariY}\\
& =  
\sum_{i=1}^N |\theta_i|\Lsig\abs{w_i^\top\!(x-y)} 
\ \leq \  
\sum_{i=1}^N |\theta_i|\!\norm{w_i}_2\,\norm{x-y}_2
\end{align*}
holds for all $x,y\in\R^n$, recalling that $X:=[x_1\ \cdots\ x_n\ 1]^\top$ and $Y:=[y_1\ \cdots\ 
y_n\ 1]^\top$, since $\abs{\sigma(u)-\sigma(v)}\leq\Lsig\abs{u-v}$ for any $u,v\in\R$ by the 
Lipschitz condition of Assumption~\ref{sigAsmpt}. Thus, such approximations are 
$\widehat\Lc$-Lipschitz with constant
\begin{equation}\label{eq:apx:Lhat}
\widehat\Lc \ = \ \Lsig\sum_{i=1}^N |\theta_i|\!\norm{w_i}_2 \ \ .
\end{equation}

A similar calculation gives that such approximations are $\widehat\Ds$-bounded with constant
\begin{equation}\label{eq:apx:Dhat}
\widehat\Ds \ = \ \Dsig\sum_{i=1}^N |\theta_i|
\end{equation}
if $\abs{\sigma(u)-\sigma(v)}\leq\Dsig$ for any $u,v\in\R$ by the bounded condition of 
Assumption~\ref{sigAsmpt}.

Let an affine shift to function $f$ be defined as
\begin{equation}\label{eq:apx:fshift}
\fch(x) \ := \ f(x) - \as^\top x - \bs
\end{equation}
for any $\as\in\R^n$ and $\bs\in\R$.
Thus, if $f$ is $\Lc$-Lipschitz, then
\begin{align*}
&\abs{\fch(x)-\fch(y)} \ = \ 
%\abs{f(x) - \as^\top x - f(0_n) - f(y) + \as^\top y + f(0_n)} \\
\abs{f(x)-f(y) - \as^\top(x-y)} \\
&\leq \ 
\abs{f(x)-f(y)} + \abs{\as^\top(x-y)} \\
&\leq\ \Lc\norm{x-y}_2 + \norm{\as}_2\norm{x-y}_2
\end{align*}
holds for all $x,y\in\R^n$. And so, $\fch$ is also Lipschitz, with constant
$\widecheck\Lc = \Lc + \norm{\as}_2$.


\begin{lemma}\label{lem:apx:extLinf}
\textit{
Let $f:\R^n\to\R$ be $\Lc$-Lipschitz on a convex compact set $\Kc\subset\R^n$ containing the 
origin and differentiable at the origin. Let there also be an approximation $\fh:\R^n\to\R$
which is $\widehat\Ds$-bounded or $\widehat{\Lc}$-Lipschitz on $\Kc$ and such that the 
approximation error $\fw(x)=\fch(x)-\fh(x)$, with $\fch$ as in \eqref{eq:apx:fshift}, satisfies 
the $L_2(\Kc,\mubKc)$ norm bound}
$$
\normK{\fw} = \sqrt{\int_\Kc\abs{\fw(x)}^2\mubKcdx} \ \leq \ \epsbase
$$\noindent
\textit{
where the bound $\epsbase>0$ is a finite constant and $\mubKcdx$ is the uniform probability
measure on $\Kc$ with $\int_\Kc\mubKcdx=1$.}

\textit{
Assume $\Kc$ is full dimension with diameter $\Dc>0$, and it holds that $\Kc\subseteq 
B_0(\rho)$ for a ball of sufficiently large radius $0<\rho\leq\Dc$.}
\textit{
Then, the approximation error also satisfies the $L_\infty(\Kc)$ norm bound}
\begin{align}\label{eq:apx:lemDLinfBound}
&\sup_{x\in\Kc}\abs{\fw(x)} \ \leq \ 
2\,
\left(\frac{r}{\Dc(r+\sqrt{r^2+\Dc^2})}\right)^{\!\frac{-n}{n+2}}\,K(\epsbase)
\end{align}
\textit{where}
\begin{align*}
K(\epsbase) \ = \\
i)& \hspace{30pt} \left(\left(\Lc + \norm{\as}_2\right)^n
\epsbase^{\,2}\right)^{\frac{1}{n+2}}+\widehat{\Ds}
\\
ii)& \hspace{30pt}
\left(\left(\Lc + \norm{\as}_2 + \widehat{\Lc}\right)^n
\epsbase^{\,2}\right)^{\frac{1}{n+2}}
\end{align*}
\textit{
and $r$ is the largest radius ball within $\Kc$ centered at its centroid.}
\end{lemma}
\begin{proof}
\if\ARXIV1
Given in Appendix~\ref{app:apx:lemLinfProof}.
\fi
\if\ARXIV0
Given in Appendix III of \cite{lekang2023functionfull}.
\fi
\end{proof}

\subsection{Application to MRAC}
\label{sec:apx:LMRAC}

In Chapter 12 of \cite{lavretsky2013robust}, an approximate extension to the general linear MRAC 
setup (see Chapter 9) is introduced which allows for nonlinearities $f:\R^n\to\R^\ell$ as
$
f(x) \ = \ \Theta^\top\!\Psi(x) + \epsilon_f(x)
$
such that the plant is given by
\begin{align}\nonumber
\dot{x}_t \ &= \ A\,x_t + B\big(u_t + f(x)) \\\label{eq:apx:plant}
&= \ A\,x_t + B\big(u_t + \Theta^\top\!\Psi(x_t) + \epsilon_f(x)\big) \ \ ,
\end{align}
where $A$ is a known $n\times n$ state matrix for the plant state $x_t\in\R^n$, $B$ is a known
$n\times\ell$ input matrix for the input $u_t\in\R^\ell$, and $\Theta$ is an \underline{unknown}
$N\times\ell$ matrix which linearly parameterizes the known vector function $\Psi:\R^n\to\R^N$.
We assume $(A,B)$ is controllable. The general setup also includes an unknown diagonal scaling 
matrix $\Lambda$, such that the overall input matrix is $B\Lambda$, and assumes that $A$ is 
unknown. For simplicity, we assume $A$ is known and omit $\Lambda$.

It is assumed that there exists an $n\times\ell$ matrix of feedback gains $K_x$ and an
$\ell\times\ell$ matrix of feedforward gains $K_r$ satisfying the \textit{matching conditions}
\begin{align*}\nonumber
A + BK_x^\top = A_r \\
BK_r^\top = B_r
\end{align*}
to a controllable, linear reference model
\begin{equation*}
\dot{x}_t^r = A_r\,x_t^r + B_r\,r_t \ \ ,
\end{equation*}
where $A_r$ is a known Hurwitz $n\times n$ reference state matrix for the reference state
$x^r_t\in\R^n$, $B_r$ is a known $n\times\ell$ reference input matrix, and $r_t\in\R^\ell$ is a
bounded reference input. Here, we assume that $K_x$ and $K_r$ can be directly calculated 
from known $A$ and $B$, and used directly in the control law.

It is required that the nonlinearity satisfy the bound
\begin{equation}\label{eq:apx:epsf}
\norm{\epsilon_f(x)}_2 \ \leq \ \bar\varepsilon
\end{equation}
for some constant $\bar\varepsilon>0$ and for all $x\in B_0(r)$ with some radius $r>0$. Then,
the adaptive control law
$$
u_t \ = \ K_x^\top x_t - \Thetah_t^\top\!\Psi(x_t) + \left(1-\mu(x)\right)K_r^\top r_t + 
\mu(x)\uw(x_t)
$$
is shown to stabilize the state tracking error $e_t = x_t-x_t^r$ down to a compact set about the 
origin, where the $N\times\ell$ matrix of parameter estimates $\Thetah_t$ is dynamically updated 
with the update rule
\begin{equation*}
\dot{\Thetah}_t = \Gamma\,\Psi(x_t)\,e_t^\top P_xB \ \ .
\end{equation*}
%(see Chapter 9 of \cite{lavretsky2013robust} for further details).
The scalar function $\mu:\R^n\to[0,1]$
transitions the control law from tracking the reference input to simply returning the plant 
state $x_t$ to the bounded region $B_0(r)$ within which \eqref{eq:apx:epsf} is valid, using an 
appropriately defined $\uw(x_t)$ based on assumptions about the growth of $\epsilon_f(x)$ 
outside of $B_0(r)$. (See Chapter~12 of \cite{lavretsky2013robust} for details.)

And so, if the vector function $\Psi(x)$ is constructed as
\begin{equation}\label{eq:pe:Psi}
\Psi(x)
= 
\begin{bmatrix}
\sigma(\upgamma_1^\top X) \\
\vdots \\
\sigma(\upgamma_N^\top X)
\end{bmatrix} \ ,
\end{equation}
with an activation function $\sigma$ satisfying the bounded (growth) conditions of 
Assumption~\ref{sigAsmpt} with constant $\Dsig$ or $\Lsig$, then the above setup is valid for
any nonlinearity $f = [f_1\ \cdots\ f_\ell]$ where we 
can show that
$$
\sup_{x\in\Kc}\abs{f_i(x)-\Theta_i^\top\Psi(x)} \ \leq \ \bar\varepsilon_i
$$
holds for some constants $\bar\varepsilon_1,\dots,\bar\varepsilon_\ell>0$. Here, 
$f_1,\dots,f_\ell:\R^n\to\R$ and each $\Theta_i^\top\in\R^N$ is the corresponding row of the 
true parameters $\Theta^\top$.
