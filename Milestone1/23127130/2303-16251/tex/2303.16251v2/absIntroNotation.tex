\begin{abstract}
Classical results in neural network approximation theory show how arbitrary continuous functions 
can be approximated by networks 
with a single hidden layer, under mild assumptions on the activation function. However, the 
classical theory does not give a constructive means to generate the network parameters that 
achieve a desired accuracy. Recent results have demonstrated that for specialized activation 
functions, such as ReLUs, high accuracy can be achieved via linear combinations of 
\textit{randomly initialized} activations. 
%
These recent works utilize specialized integral representations of target functions that depend 
on the specific activation functions used. 
%
This paper defines \textit{mollified integral representations}, which provide a means to form 
integral representations of target functions using activations for which no direct integral 
representation is currently known.
%
The new construction enables approximation guarantees for randomly initialized networks using 
any activation for which there exists an established base approximation which may not be 
constructive.
We extend the results to the supremum norm and show how this enables application to an extended, 
approximate version of (linear) model reference adaptive control.
\end{abstract}

\section{Introduction}

%Machine learning is a wide-ranging umbrella topic that encompasses many different 
%methods and models, which can be used to bestow onto a machine or system the ability to 
%complete 
%various tasks without specific experience being hard coded or otherwise already possessed by 
%the 
%system \cite{mahesh2020machine}.
Adaptive control lies at the intersection of machine learning methods and the control of 
dynamics systems \cite{gaudio2019connections}, and has considerable development in the controls 
literature \cite{slotine1991applied,sastry1989adaptive,khalil2017high}. Deep neural network 
based machine learning approaches have achieved unprecedented levels of performance and utility
in areas such as language processing \cite{otter2020survey}, medical computer vision
\cite{esteva2021deep}, and reinforcement learning \cite{degrave2022magnetic}. In this paper, we
aim to contribute novel ideas to function approximation techniques and apply them to an 
approximate extension of Model Reference Adaptive Control (MRAC) established in 
\cite{lavretsky2013robust}.

A key challenge in function approximation work is that many theorems describe the existence of 
approximations that are linear combinations of some activation function (such as a sigmoid), but 
are not constructive. In \cite{pinkus1999approximation}, many of these results are reviewed, 
including classic results on the universal approximation properties of continuous 
sigmoidal activations 
\cite{cybenko1989approximation,hornik1989multilayer,funahashi1989approximate}, as well as 
another classic result by \cite{barron1993universal} for arbitrary sigmoidal
activations, which was expanded to arbitrary hinge functions by \cite{breiman1993hinging}.

Random approximation provides a key way to avoid the non-constructiveness by randomly sampling 
the internal parameters of the activations from a known set, if the target function of interest 
has an integral representation. However, determining these representations for general classes 
of target functions and activations is a nontrivial task.
\cite{irie1988capabilities} gives a constructive
method, but only for target and activation functions in $L_1$. In \cite{kainen2010integral} and 
\cite{petrosyan2020neural}, they propose constructive
methods for a class of target functions with unit step and ReLU activations respectively. In 
\cite{hsu2021approximation}, functions are approximated using trigonometric polynomial ridge 
functions, which can then be shown in expectation to be equivalent to randomly initialized ReLU 
activations.

There are several interesting and important results in the literature having to do with
neural networks with random (typically Gaussian) parameter initialization, sometimes as a 
consequence of using randomly initialized gradient descent for training the network. A classic
result by \cite{neal1994priors} shows that the output of a single hidden-layer network with
Gaussian randomly initialized parameters goes to a Gaussian Process as the width goes to
infinity. Similar results are then achieved in \cite{lee2017deep} for deep fully-connected
networks as all hidden layer widths go to infinity. Also for deep fully-connected networks, in
\cite{jacot2018neural} the authors define the Neural Tangent Kernel and propose that its limit,
as the hidden layer widths go to infinity, can be used to study the timestep evolution and
dynamics of the parameters, and the corresponding network output function, in gradient descent.
In \cite{poole2016exponential}, the authors show that single hidden-layer networks cannot achieve
the same rates of increase in a measure of curvature produced by the network output, as deep
networks can, with parameters Gaussian randomly initialized and bounded activation functions. In
\cite{arora2019fine}, the authors show that single hidden-layer networks of a sufficient width
can use Gaussian randomly initialized gradient descent on values of a target function, and
achieve guaranteed generalization to the entire function. And in \cite{du2019gradient}, the
authors show that deep fully-connected networks, where each hidden layer width meets a
sufficient size, can be trained with Gaussian randomly initialized gradient descent and be
guaranteed to reach the global minimum at a linear rate.

Our primary contributions in this paper are: developing a novel method for bridging convex 
combinations of activation functions (eg. step and ReLU) with unknown parameters to
approximations using randomly initialized parameters by using a mollified integral 
representation, obtaining a main overall result bounding the approximation error for the random 
approximations in the $L_2$ norm, extending these results to the $L_\infty$ norm under certain 
conditions, and then applying those results to an approximate extension of MRAC adaptive control.


The organization of the remaining parts of the paper are as follows. Section~\ref{sec:notation}
presents preliminary notation. Section~\ref{sec:apx:background} presents background on function 
approximation with neural networks. Section~\ref{sec:apx:mollApx} presents theoretical results 
on 
mollified approximations, while Section~\ref{sec:apx:random} gives an overall approximation 
error 
bound in $L_2$ norm for randomly initialized approximations. Section~\ref{sec:apx:application}
presents an extension to $L_\infty$ norm bounds and an application on approximate MRAC, and we 
provide closing remarks in Section~\ref{sec:conclusion}.


\section{Notation}
\label{sec:notation}

We use $\R,\N$ to denote the real and natural numbers. $\Ind$ denotes the indicator 
function, while $\Exp$ denotes the expected value. We use $\Bc,\Kc$ to denote bounded and 
compact convex subsets of $\R^n$. The integer set $\{1,\dots,k\}$ is denoted by $[k]$. 
$B_x(r)\subset\R^n$ denotes the radius $r$ Euclidean ball centered at $x\in\R^n$.
%For any $n,m\in\N$, we interpret $x,y\in \R^n$ as length $n$ column vectors and their transposes
%$x^\top,y^\top$ as length $n$ row vectors. $\norm{x}_2=\sqrt{x^\top\!x}$ will always denote the 
%standard Euclidean vector norm and inner product, with $x^\top\!y$ the dot product of two equal 
%length vectors. $0_n$, $1_n$ denote the length $n$ vector of zeros and ones respectively. 
%The notation that $A$ is a $n\times m$ matrix assumes real entries, thus $A\in\R^{n\times m}$ 
%and its transpose $A^\top\in\R^{m\times n}$.
%If $A$ is a square matrix its trace is denoted by $\tr(A)$. $I_n$ denotes the $n\times n$
%identity matrix. $A\prec B$ ($\preceq$) denotes that the matrix $B-A$ is positive 
%(semi)definite. And so, $aI_n\preceq A\preceq bI_n$ denotes that $\text{eig}(A)\in[a,b]$.
%
%Index subscripts on vectors and matrices denote the row index, for example $A_i^\top$ is the
%$i$th row of $A^\top$. The Frobenius matrix norm is denoted $\|A\|_F$. We denote the product of
%matrix $A\in\R^{n\times m}$ with vector $x\in\R^m$ as $Ax$,
%which is a length $n$ (column) 
%vector where the $i$th (row) element is the inner product $(Ax)_i$. If $A\in\R^{n\times m}$ and 
%$x\in\R^n$, then the matrix product $A^\top\!x$ results in a length $m$ vector where we denote 
%the $i$th element $(A^\top\!x)_i$ equivalently as the inner product $A_i^\top\!x$.
%
%We denote time indices using subscripts, for all (scalar, vector, or matrix valued) functions 
%of 
%time. For example, $x_t$ or $A_t$, instead of $x(t)$ or $A(t)$. Random variables are denoted in 
%bold, eg. $\xb$, and so stochastic processes also have a time subscript, eg. $\xb_t$. The $i$th 
%row of a time-varying vector or matrix is denoted with $t,i$ subscript.
We interpret $w,x\in\R^n$ as column vectors and denote their inner product as $w^\top\!x$.
Similarly, we denote the product of matrix $W\in\R^{n\times N}$ with vector $x$ as $W^\top\!x$,
which is a length $N$ vector where the $i$th element is the inner product $W_i^\top\!x$.
Subscripts on vectors and matrices denote the row index, for example $W_i^\top$ is the $i$th row
of $W^\top$. The standard Euclidean norm is denoted
$\|w\|$.
% The integer set $\{1,\dots,k\}$ is denoted by $[k]$.
We use subscripts on
time-dependent variables to reduce parentheses, for example $\phi(x(t))$ is instead denoted
$\phi(x_t)$. The $i$th row of a time-varying vector or matrix is then $x_{t,i}$.
