{
    "arxiv_id": "2303.14672",
    "paper_title": "Sat2Density: Faithful Density Learning from Satellite-Ground Image Pairs",
    "authors": [
        "Ming Qian",
        "Jincheng Xiong",
        "Gui-Song Xia",
        "Nan Xue"
    ],
    "submission_date": "2023-03-26",
    "revised_dates": [
        "2023-03-28"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV"
    ],
    "abstract": "This paper aims to develop an accurate 3D geometry representation of satellite images using satellite-ground image pairs. Our focus is on the challenging problem of generating ground-view panoramas from satellite images. We draw inspiration from the density field representation used in volumetric neural rendering and propose a new approach, called Sat2Density. Our method utilizes the properties of ground-view panoramas for the sky and non-sky regions to learn faithful density fields of 3D scenes in a geometric perspective. Unlike other methods that require extra 3D information during training, our Sat2Density can automatically learn the accurate and faithful 3D geometry via density representation from 2D-only supervision. This advancement significantly improves the ground-view panorama synthesis task. Additionally, our study provides a new geometric perspective to understand the relationship between satellite and ground-view images in 3D space.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.14672v1"
    ],
    "publication_venue": "Project Page: https://sat2density.github.io"
}