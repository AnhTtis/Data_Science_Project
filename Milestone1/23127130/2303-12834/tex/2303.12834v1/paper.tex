\documentclass[reprint,
%prl,
aps,superscriptaddress,twocolumn,showpacs,longbibliography,nofootinbib]{revtex4-2}
\usepackage{graphicx,color}
\usepackage{amsmath,amsfonts,enumerate,amsthm,amssymb,bbm}
\usepackage[colorlinks=true,citecolor=blue,linkcolor=magenta]{hyperref}
\usepackage{multirow}
\usepackage{bbold}
\usepackage{braket}
\usepackage{soul}
% \usepackage{float}
% \usepackage{dblfloatfix}
\usepackage[caption = false]{subfig}
% \usepackage[a4paper, total={7in, 9.5in}]{geometry}
\usepackage[normalem]{ulem}
\usepackage{scrextend}
\usepackage{xcolor}
\usepackage{dsfont}
\usepackage{nicefrac}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
% \usepackage{algorithm}
% \usepackage{algpseudocode}
%\usepackage{quantikz}
\usepackage{apptools}
\usepackage{physics}
\usepackage[utf8]{inputenc}

\def\NoNumber#1{{\def\alglinenumber##1{}\State #1}\addtocounter{ALG@line}{-1}}

\mathchardef\ordinarycolon\mathcode`\:
\mathcode`\:=\string"8000
\begingroup \catcode`\:=\active
  \gdef:{\mathrel{\mathop\ordinarycolon}}
\endgroup

%%START THEOREMS DEFINITIONS

\theoremstyle{plain}
\newtheorem{thm}{Theorem}
\newtheorem{corol}{Corollary}
\newtheorem{lem}{Lemma}
\newtheorem{propos}{Proposition}
\theoremstyle{definition}
\newtheorem{defn}{Definition}
\theoremstyle{remark}
\newtheorem{rmk}{Remark}
\newtheorem{ex}{Example}

\AtAppendix{\counterwithin{thm}{section}}
\AtAppendix{\counterwithin{corol}{section}}
\AtAppendix{\counterwithin{lem}{section}}
\AtAppendix{\counterwithin{propos}{section}}
\AtAppendix{\counterwithin{defn}{section}}
\AtAppendix{\counterwithin{rmk}{section}}
\AtAppendix{\counterwithin{ex}{section}}

%% END THEOREMS DEFINITIONS

%% START MATHS SHORTCUTS DEFINITIONS



\renewcommand{\P}{\ensuremath{\mathcal{P}}}
\newcommand{\Pt}{\ensuremath{\widetilde{\mathcal{P}}}}
\newcommand{\Q}{\ensuremath{\mathcal{Q}}}
\newcommand{\Qt}{\ensuremath{\widetilde{\mathcal{Q}}}}
\newcommand{\R}{\ensuremath{\mathcal{R}}}
\newcommand{\Rt}{\ensuremath{\widetilde{\mathcal{R}}}}
\newcommand{\D}{\ensuremath{\mathcal{D}}}
\newcommand{\E}{\ensuremath{\mathbb{E}}}
\renewcommand{\O}{\ensuremath{\mathcal{O}}}
\renewcommand{\S}{\ensuremath{\mathcal{S}}}
\newcommand{\Psiin}{\ensuremath{\ket{\psi_\text{in}}}}
\newcommand{\bPsiin}{\ensuremath{\bra{\psi_\text{in}}}}
\newcommand{\rhoin}{\ensuremath{\rho_\text{in}}}
\newcommand{\rhou}{\ensuremath{\rho_U}}
\newcommand{\rhov}{\ensuremath{\rho_V}}
\newcommand{\rhoui}{\ensuremath{\rho_{U,i}}}
\newcommand{\rhovi}{\ensuremath{\rho_{V,i}}}
\newcommand{\0}{\ensuremath{\ket{0}}}
\newcommand{\1}{\ensuremath{\ket{1}}}
\newcommand{\+}{\ensuremath{\ket{+}}}
\renewcommand{\-}{\ensuremath{\ket{-}}}
\renewcommand{\i}{\ensuremath{\ket{i}}}
\newcommand{\mi}{\ensuremath{\ket{-i}}}
\newcommand{\kb}[1]{\ensuremath{\ket{#1}\!\bra{#1}}}
\newcommand{\TV}{\text{TV}}
\newcommand{\SWAP}{\text{SWAP}}


\def\<{\langle}
\def\E{ {\mathbb{E}} }
\def\H{ {\cal H} }
\def\F{{\cal F}}
\def\P{ {\cal P} }
\def\M{ {\cal M} }
\def\A{ {\cal A} }
\def\B{ {\cal B} }
\def\C{ {\mathbb{C}} }
\def\P{ {\cal P} }
\def\O{ {\cal O} }
\def\D{ {\cal D} }
\def\T{ {\cal T} }
\def\R{ {\cal R} }
\def\N{ {\cal N} }
\def\U{ {\cal U} }
\def\W{ {\cal W} }
\def\I{ \mathbb{1} }
\def\non{ \nonumber\\}
\def\x{\boldsymbol{x}}
\def\y{\boldsymbol{y}}
\def\p{\boldsymbol{p}}
\def\I{ \mathbbm{1} }
\def\tr{ \mbox{tr} \,}
\def\>{\rangle}
\def\<{\langle}
%\DeclareMathOperator{\Tr}{Tr} 
\DeclareMathOperator{\Var}{Var} 
\DeclareMathOperator{\poly}{poly}

\renewcommand{\0}{\ensuremath{\ket{0}}}
\renewcommand{\1}{\ensuremath{\ket{1}}}
\renewcommand{\+}{\ensuremath{\ket{+}}}
\renewcommand{\-}{\ensuremath{\ket{-}}}
\renewcommand{\i}{\ensuremath{\ket{i}}}
\renewcommand{\mi}{\ensuremath{\ket{-i}}}

\newcommand{\thv}{\vec{\theta}}
\newcommand{\gav}{\vec{\gamma}}
\newcommand{\alv}{\vec{\alpha}}
\newcommand{\gamv}{\vec{\gamma}}
\newcommand{\opt}{\rm opt}

\renewcommand{\norm}[1]{\left\lVert#1\right\rVert}


\newcommand{\avg}[1]{\langle #1\rangle }
\renewcommand{\ket}[1]{|#1\rangle}               %ket
\newcommand{\colo}{\,\hbox{:}\,}              %colon in math with less space
\renewcommand{\bra}[1]{\langle #1|}              %bra
\newcommand{\dya}[1]{\ket{#1}\!\bra{#1}}
%\newcommand{\dyad}[2]{\ket{#1}\!\bra{#2}}   

%% END MATHS SHORTCUTS DEFINITIONS

\renewcommand{\vec}[1]{\boldsymbol{#1}}  % Bold vectors instead of arrow vectors

% Matthias Caro comments
\newcommand{\mcc}[1]{{\color[RGB]{220, 20, 60}{[MCC: #1]}}}

% revision commenting tools
\newcommand{\stkout}[1]{\ifmmode\text{\sout{\ensuremath{#1}}}\else\sout{#1}\fi}
\newif\ifverbose
% verbose: true: show corrections, false: hide corrections
\verbosetrue
%\verbosefalse
% ins: stuff that is new
\newcommand{\ins}[1]{\ifverbose\textcolor{blue}{#1}\else#1\fi}
% edit: stuff that has been replaced with other stuff
\newcommand{\edit}[2]{\ifverbose\textcolor{red}{\stkout{#1} #2}\else#2\fi}
% del: stuff that has been removed
\newcommand{\del}[1]{\ifverbose\textcolor{red}{\stkout{#1}}\fi}

\usepackage{notes2bib}
\bibnotesetup{note-name=}
\setlength{\skip\footins}{0.75cm}
\interfootnotelinepenalty=10000

\makeatletter 

\renewcommand\onecolumngrid{% <<<<<<
\do@columngrid{one}{\@ne}%
\def\set@footnotewidth{\onecolumngrid}% <<<<<<<<<<<<<<<<
\def\footnoterule{\kern-6pt\hrule width 1.5in\kern6pt}%
}

\begin{document}

\title{The power and limitations of learning quantum dynamics incoherently}

\author{Sofiene Jerbi}
\affiliation{Theoretical Division, Los Alamos National Laboratory, Los Alamos, NM, USA.}
\affiliation{Institute for Theoretical Physics, University of Innsbruck, Austria}

\author{Joe Gibbs}
\affiliation{Department of Physics, University of Surrey, Guildford, GU2 7XH, UK}
\affiliation{AWE, Aldermaston, Reading, RG7 4PR, UK}

\author{Manuel S. Rudolph}
\affiliation{Institute of Physics, Ecole Polytechnique F\'{e}d\'{e}rale de Lausanne (EPFL), CH-1015 Lausanne, Switzerland}

\author{Matthias C.~Caro}
\affiliation{Institute for Quantum Information and Matter, Caltech, Pasadena, CA, USA.}
\affiliation{Dahlem Center for Complex Quantum Systems, Freie Universit\"{a}t Berlin, Berlin, Germany.}

\author{Patrick~J.~Coles} 
\affiliation{Theoretical Division, Los Alamos National Laboratory, Los Alamos, NM, USA.}
\affiliation{Normal Computing Corporation, New York, New York, USA.}

\author{Hsin-Yuan Huang}
\affiliation{Institute for Quantum Information and Matter, Caltech, Pasadena, CA, USA.}
\affiliation{Department of Computing and Mathematical Sciences, Caltech, Pasadena, CA, USA}

\author{Zo\"{e} Holmes}
\affiliation{Theoretical Division, Los Alamos National Laboratory, Los Alamos, NM, USA.}
\affiliation{Institute of Physics, Ecole Polytechnique F\'{e}d\'{e}rale de Lausanne (EPFL), CH-1015 Lausanne, Switzerland}



\date{\today}

\begin{abstract}
Quantum process learning is emerging as an important tool to study quantum systems. While studied extensively in coherent frameworks, where the target and model system can share quantum information, less attention has been paid to whether the dynamics of quantum systems can be learned without the system and target directly interacting. Such incoherent frameworks are practically appealing since they open up methods of transpiling quantum processes between the different physical platforms without the need for technically challenging hybrid entanglement schemes. Here we provide bounds on the sample complexity of learning unitary processes incoherently by analyzing the number of measurements that are required to emulate well-established coherent learning strategies. We prove that if arbitrary measurements are allowed, then any efficiently representable unitary can be efficiently learned within the incoherent framework; however, when restricted to shallow-depth measurements only low-entangling unitaries can be learned. We demonstrate our incoherent learning algorithm for low entangling unitaries by successfully learning a 16-qubit unitary on \texttt{ibmq\_kolkata}, and further demonstrate the scalabilty of our proposed algorithm through extensive numerical experiments.  
\end{abstract}

\maketitle

\section{Introduction}

Classical computing power and classical machine learning are currently routinely used to process data from quantum experiments. However, as these are \textit{quantum} experiments, it would perhaps be more natural to use a \textit{quantum} computer to process their data. 
Within this line of thought, a particularly promising application of quantum hardware is \textit{quantum process learning}~\cite{bisio2010optimal, poland2020no, sharma2020reformulation, khatri2019quantum, Jones2022robustquantum,heya2018variational, cirstoiu2020variational,gibbs2021long, gibbs2022dynamical, huang2021information, huang2021quantum, caro2021generalization, caro2022outofdistribution, huang2022learning, caro2022learning}. At its simplest, the process to be learned will be the unitary dynamics of an experimental system that one wishes to study, and the machine learning model to be optimized will be a quantum circuit representation or a classical description of the target process. In this manner, quantum process learning is a means of digitizing an analogue quantum process and uploading it to a quantum or classical computer for further study. 

Quantum process learning has thus far been predominantly investigated in the \textit{coherent} setting. That is, it is assumed that the target and model system can coherently interact and quantum information can be shared between them. In this setting, the training data typically takes the form of `input-output' pairs of quantum states. 
While the coherent setting is theoretically powerful (in the sense that one can learn efficiently implementable unitaries using only a polynomial number of `easy-to-prepare' product states~\cite{caro2022outofdistribution}), engineering the coherent interaction of the target and model system can be experimentally challenging. In particular, if the target and model system are made up of physically different constituents, then a reliable quantum transducer is required in this framework (see Fig.~\ref{fig:schematic}). However, hybrid-entanglement engineering is still in its infancy~\cite{mao2021perspective, Waks2009Protocol, Eichler2012Observation, Stute2012Tunable, Craddock2019Quantum, scarlino2019coherent} and it may be many years before such transducers are widely available. More fundamentally, given the need for the target and model system to coherently interact, the model system cannot be purely classical.

The \textit{incoherent} setting, where the training is performed using classical data (i.e., numerical values collected from measurement outcomes, see Fig.~\ref{fig:schematic}), is considerably more practical. Crucially, as there is no need for the target system and model system to physically interact in this case, the target system and model system can be radically different. In some cases, namely those where the target unitary is classically simulable, the trained unitary could even be a fully classical model such as those enabled by tensor network methods~\cite{Vidal2003Efficient, orus2014practical}. 
Thus, the incoherent framework provides a way of transpiling quantum processes between quantum and classical platforms. The appeal of this flexibility is reflected in the growing body of literature studying so-called `distributed learning' benchmarking protocols~\cite{anshu2022distributed}, as well as various proposed algorithms for learning Hamiltonians that implicitly assume an incoherent setting~\cite{wang2017experimental, Wiebe2014Quantum, wiebe2014hamiltonian, Gentile2021Learning, wilde2022scalably, gebhart2022learning, stilck-franca2022efficient, haah2021optimal, anshu2021sample-efficient}. 

Recently, the power of the incoherent setting has begun to be investigated from a learning theory perspective. For example, Ref.~\cite{huang2022learning} develops an algorithm for predicting local properties of the output states of an unknown process using only local measurements, and Ref.~\cite{fanizza2022learning} investigates the power of the incoherent setting in the context of hypothesis testing. Here we take a different approach and investigate the extent to which the full coherent setting can be emulated within the incoherent setting in the context of learning unitary processes. 

We start by considering the power of the incoherent paradigm when arbitrary measurements can be performed on the system. In this case, using results from random measurement theory~\cite{huang2020predicting, elben2022randomized} and covering net arguments~\cite{caro2021generalization}, we argue that it is possible to incoherently learn arbitrary efficiently representable unitaries using Clifford shadows and an efficient number of samples. This result highlights that quantum transducers are not strictly always needed for quantum process learning. 

However, there are two crucial caveats to this first result. Firstly, Clifford shadows require the ability to implement circuits of linear depth and so are impractical on many near-term platforms. More fundamentally, there are good reasons to believe (due to the globality of the cost and difficulties surrounding computing it efficiently on quantum or classical hardware) that the algorithm we use for our sampling complexity proof is not computationally efficient in general. As such, we see this algorithm as a predominantly a tool to understand the sampling complexity of the incoherent setting rather than a practical proposal.  

\begin{figure}[t]
\centering
\includegraphics[width =\columnwidth]{figures/coherent-vs-incoherent.pdf}
\vspace{-6mm}
\caption{\textbf{Coherent versus incoherent unitary learning.} We consider the task of learning a target unitary $U$ using a variational ansatz $V(\thv)$. As opposed to a coherent setting where quantum information can be shared or entangled between the quantum computer running $V(\thv)$ and the system implementing $U$, we consider an incoherent setting. This setting is divided into two phases: 1.)~a measurement phase where information is collected about $U$, and 2.)~a training phase where this information is used to train $V(\thv)$.}
\label{fig:schematic}
\vspace{-1.5em}
\end{figure}
 
Thus, the core of this paper investigates the more realistic situation where the experimentalist is limited to performing \textit{shallow} measurements, that is, those that can be implemented using shallow depth circuits. In this case, we prove that low-entangling unitaries can be efficiently learned using only Pauli product measurements. However, arbitrary unitaries cannot be learned in this setting even if they are efficiently implementable (that is, even if they can be approximated using a parameterized circuit with a polynomial number of trainable parameters). Our negative result here provides a fundamental limit to quantum process learning in the incoherent paradigm. In particular, contrasting our results with those portrayed in Ref.~\cite{huang2020predicting}, this result highlights that learning to predict the output states of a unitary is a substantially harder learning task than learning to simply predict local measurement outcomes.

In parallel, our positive result for low-entangling unitaries opens up a family of new tools for studying the short-time dynamics of locally interacting systems. We demonstrate the scalability, and plausible computational efficiency, of these tools via numerical simulations for different entangling rates and different system sizes. We further establish the suitability of the algorithm for near-term hardware by successfully learning a 16-qubit unitary on real quantum hardware (\texttt{ibmq\_kolkata}).

\section{Background}

In this work we consider the task of learning to optimize the parameters $\vec{\theta}$ of $V(\vec{\theta})$, an $n$-qubit parameterized unitary, such that, for the optimized parameters $\vec{\theta}_{\rm opt}$, $V(\vec{\theta}_{\rm opt})$ well approximates an unknown $n$-qubit unitary $U\in\mathcal{U}(\mathbb{C}^{2^n})$. The Hilbert-Schmidt inner product between $U$ and $V(\vec{\theta})$ provides a natural measure of the success of the training. Thus our goal is to minimize the Hilbert-Schmidt test cost~\cite{khatri2019quantum},
\begin{equation}
    C_{\text{HST}}(\vec{\theta}) := 1 - \frac{1}{d^2}\abs{\Tr[U^\dagger V(\vec{\theta})]}^2 \, ,
\end{equation}
which can be measured on quantum hardware using Choi states~\cite{khatri2019quantum}. 

The Hilbert-Schmidt cost is operationally meaningful in virtue of its equivalence to the average fidelity between a state $\ket{\psi}$ evolved under $U$ and a state $\ket{\psi}$ evolved under $V(\vec{\theta})$. That is,
\begin{equation}
    C_{\text{HST}}(\vec{\theta}) = \frac{d+1}{d} \E_{\ket{\psi}\sim\text{Haar}_n} \left[1-\abs{\bra{\psi}U^\dagger V(\vec{\theta})\ket{\psi}}^2\right]  \, ,
\end{equation}
where $\ket{\psi}$ is drawn from the (Haar) uniform distribution of states. 
This suggests an alternative approach to training, where the learner has access to a training data set consisting of input-output pairs of pure $n$-qubit states, 
\begin{equation}\label{eq:training-data-general}
    \mathcal{D}_{Q}(N) = \{(\ket{\psi^{(j)}}, U\ket{\psi^{(j)}}) \}_{j=1}^{N} \, ,
\end{equation}
where the $N$ input states $\ket{\psi^{(j)}}$ are drawn independently from the distribution $Q$. In particular, taking $Q$ to be the Haar distribution, $ V(\vec{\theta})$ can be trained using the loss
\begin{equation}\label{eq:GlobalTrainingCost}
    C_{\D_{Q}(N)}(\vec{\theta}) := 1 - \frac{1}{N}\sum_{i=1}^{N} \abs{\bra{\psi^{(i)}}U^\dagger V(\vec{\theta})\ket{\psi^{(i)}}}^2 \, .
\end{equation}
Prior results on \textit{in-distribution} generalization give bounds on the number of training pairs $N$ needed to ensure that this training loss is faithful to the Hilbert-Schmidt cost. In particular, for a variational circuit $V(\vec{\theta})$, with $T$ trainable gates, $N \sim T\log(T)$ training pairs suffice~\cite{caro2021generalization}. 

In fact, more recent results on \textit{out-of-distribution} generalization~\cite{caro2022outofdistribution} imply that simple products of single-qubit stabilizer states suffice to generalize well on globally Haar random states. That is, the training ensemble $Q$ can be taken to be the uniform distribution over the set of stabilizer states $\text{Stab}_1^{\otimes n} := \{\0, \1, \+, \-, \i, \mi\}^{\otimes n}$.
This is practically useful because, in contrast to Haar random states which require deep circuits, a complete gate set, and cannot be classically simulated, random stabilizer product-states are classically simulatable and can be prepared using a single layer of single qubit rotations. 

In practise, to avoid cost-function-dependent barren plateaus~\cite{cerezo2021cost}, it is necessary to use a local variant of the training loss. A natural choice using product state training data is 
\begin{equation}\label{eq:localtrainingloss}
\begin{aligned} \small
        &C_{\rm N}^{\ell}(\vec{\theta}) 
         = 1 -\frac{1}{N}\sum\limits_{j=1}^N \Tr \left[  \ket{\psi^{(j)}}\bra{\psi^{(j)}}  U^\dagger V(\vec{\theta}) H_{\ell}^{(j)} V^\dagger(\vec{\theta}) U\right].
\end{aligned}
\end{equation}
\normalsize
Here $\ket{\psi^{(j)}} = \bigotimes_{i=1}^n \ket{\psi_i^{(j)} } \sim \text{Stab}_1^{\otimes n}$ for all $j$ and $ H_{\ell}^{(j)} = \frac{1}{n} \sum_{i=1}^n \ket{\psi_i^{(j)}} \bra{\psi_i^{(j)} }\otimes \mathds{1}_{\bar{i}}$ is a 1-local measurement (i.e. each term acts non-trivially on at most one qubit). This local cost is faithful to the global product state training cost in the sense that it vanishes under the same conditions~\cite{khatri2019quantum}, but enjoys trainability guarantees for shallow depth circuits~\cite{cerezo2021cost}.
More concretely, in the coherent setting, the following bound holds    
\begin{equation*}
    \begin{aligned}    
        C_{\text{HST}}(\vec{\theta})
        \leq \, &\frac{2 n (d+1)}{d} C^{\ell}_{  N}(\vec{\theta}) + \mathcal{O} \left( n\sqrt{\frac{T \log (T)}{N}} \right)\, , 
    \end{aligned}
    \end{equation*}
with high probability over the choice of product state training data of size $N$~\cite{caro2022outofdistribution}. Thus the local-product-state cost in Eq.~(\ref{eq:localtrainingloss}) can be used to indirectly train the Hilbert-Schmidt Test cost and thereby learn the target unitary $U$.

It is natural to compute the product-state training cost, and its local variants, in the coherent framework. This can be done via a Loschmidt echo type circuit as sketched in Fig.~\ref{fig:schematic} (the top left circuit).
While such circuits are relatively straightforward to run on a single quantum device, they are much harder to implement if the system implementing the target unitary and the platform implementing the trained unitary are distinct. In such cases, experimentally challenging quantum transducers are required to pass the quantum information between the target and learning systems. This motivates considering the incoherent learning paradigm where the target and model systems do not need to interact. The key question tackled in this paper is: 
\emph{Is it possible to emulate the \textit{coherent} learning setting using only \textit{incoherent} learning  protocols?} More precisely, is it possible to rigorously estimate the training losses used coherently, without the target and test system directly interacting?

\section{Results}

\subsection{Deep measurements}

Let us start by considering what can be computed in the incoherent learning paradigm if we suppose that arbitrary measurements can be performed on the system. In this case, we can use random Clifford measurements to generate the Clifford shadow of each of the $N$ output states in our training ensemble~\cite{huang2020predicting}. This allows us to compute the fidelities of our target output states with an exponential number of guess output states (i.e., parameter settings for the parametrized circuit) after collecting a polynomial-sized shadow. Combining this observation with a covering set argument of all efficiently representable unitaries, we show it is possible to train a variational unitary $V(\thv)$ to achieve $C_{\text{HST}}(\vec{\theta}) \leq \epsilon$ for any target accuracy $\epsilon$ with a polynomial sampling complexity. As proven and stated more formally in Appendix~\ref{app:DeepMeasurements}, this is captured by the following theorem \bibnote{We note that a similar argument was made in passing in Ref.~\cite{caro2022outofdistribution}, but the argument was not formalized and its implications for incoherent learning were not appreciated.}.

\begin{thm}[Power of incoherent learning with deep measurements (informal)]\label{thm:powerofdeep}
For any efficiently representable $n$-qubit unitary $U$, that is a unitary that can be implemented using a quantum circuit of size $\poly(n)$, at most $\poly(n)$ calls to $U$ are required to incoherently train a parameterized unitary $V(\vec{\theta})$ to achieve $1/\poly(n)$ Hilbert-Schmidt cost between $V(\vec{\theta})$ and $U$. 
\end{thm}

In showing this theorem, we also prove that, if random Clifford measurements on the target system are allowed, then it is possible to fully emulate the coherent setting. That is, it is possible to efficiently (in terms of sampling complexity) train $V(\vec{\theta})$ to learn $U$ in the incoherent setting.
It follows that if the target system allows for a Clifford gate set and long coherence times (all $n$-qubit Clifford operations can be implemented in depth $\O(n)$ \cite{maslov2018shorter}) then quantum transducers are not strictly needed for quantum process learning.

However, there are two important caveats here. Firstly, Clifford shadows are only well-suited to compute global fidelities and therefore a global cost (of the form of Eq.~(\ref{eq:GlobalTrainingCost})). However, global costs exhibit barren plateaus. Thus, using generic ans\"{a}tze, the time complexity of this approach will typically be exponential~\cite{cerezo2021cost}. One way around this would be to build prior knowledge about the target unitary into the guess ansatz. It has been shown, for example, that highly symmetrized ans\"{a}tze can avoid globality induced barren plateaus~\cite{schatzki2022theoretical}. Nonetheless, such approaches are unlikely to work in all cases. Secondly, while Clifford shadows are guaranteed information-theoretically to allow the computation of fidelities with other quantum states, this computation is by no means guaranteed to be efficient. When computing fidelities using Clifford shadows, we are indeed considering observables of the form $V(\thv)\ket{\psi^{(i)}}\bra{\psi^{(i)}}V^\dagger(\thv)$, which cannot be efficiently represented/computed classically for deep circuits $V(\thv)$. Even when we consider access to a quantum computer to compute the overlap between these operators, we face the problem that classical shadows are completely unphysical operators that cannot be efficiently encoded into quantum states and whose expectation values are costly to estimate (see Appendix~\ref{app:ComputComplexIncoherent} for an in-depth discussion).

These two constraints limit the breadth of applicability of Theorem \ref{thm:powerofdeep}. Hence, we will now turn our attention to the focus of this work: the power and limitation of the incoherent framework if we limit ourselves to shallow measurements. 

\subsection{Shallow measurements}

\begin{figure}[t]
\centering
\includegraphics[width =\columnwidth]{figures/incoherent-Pauli.pdf}
\vspace{-6mm}
\caption{\textbf{Learning low-entangling unitaries using Pauli shadows.} Our learning protocol for low-entangling unitaries makes use of three results. 1.~Out-of-distribution generalization allows to consider locally-scrambled training states with generalization guarantees to global Haar random states. 2.~Cost concentration results allow us to consider a local version of the training loss. 3.~For shallow-depth ans\"{a}tze $V(\thv)$ (e.g., depth $\O(\log(n))$), the observables appearing in the training loss remain local ($k\in\O(\log(n))$), and therefore Pauli shadow allow to efficiently simulate this training loss incoherently.}
\label{fig:lightcone}
\vspace{-3mm}
\end{figure}

We can follow a similar approach as above with Clifford shadows, but this time restrict ourselves to Pauli shadows. In this case, since the sample complexity of Pauli shadows scales exponentially with the locality of the operators measured, we can only efficiently compute the effect of measuring operators that scale at most logarithmically with the size of the system. It follows that we can only emulate the coherent setting and estimate $C_{N}^\ell(\thv)$ for low-entangling unitaries that transform $1$-local operators into $O(\log(n))$-local operators, as sketched in Fig.~\ref{fig:lightcone} and further detailed in Appendix~\ref{app:ShallowMeasurements}. Thus, we show that the following theorem holds. 

\begin{thm}[Power of incoherent learning with shallow measurements (informal)]\label{thm:powerofshallow}
For any \textit{low entangling} $n$-qubit unitary $U$, that is a unitary that transforms $1$-local operators into $O(\log(n))$-local operators, at most $\poly(n)$ calls to $U$ are required to incoherently train a parameterized unitary $V(\vec{\theta})$ to achieve $1/\poly(n)$ Hilbert-Schmidt cost between $V(\vec{\theta})$ and $U$. 
\end{thm}

As opposed to the deep-measurement protocol, the shallow-measurement protocol is also computationally efficient in simulating the coherent training loss $C_{\rm N}^{\ell}(\vec{\theta})$ (see Eq.~(\ref{eq:localtrainingloss})). Since the observables $V(\vec{\theta}) H_{\ell}^{(j)} V^\dagger(\vec{\theta})$ are $\O(\log(n))$-local, they can be represented and computed efficiently classically, along with their contribution to the training loss. This allows one to train $V(\thv)$ classically (see Appendix~\ref{app:ComputComplexIncoherent} for an in-depth discussion) and thereby learn a classical representation of the target process. If $V(\thv)$ is parameterized such that it can be implemented on a different quantum system, this approach further provides a way of transpiling the quantum process between (potentially rather different) quantum platforms. 
 
The Pauli shadow based approach for learning low entangling unitaries via shallow measurements in the incoherent framework breaks down if the target unitary is too entangling as the sample complexity of our method scales as $4^k$ where $k$ is the locality of the operator $V(\vec{\theta}) H_\ell V(\vec{\theta})^\dagger$. It turns out that this is not a limitation of our algorithm but rather a fundamental limitation of incoherent learning with shallow measurements. In particular, we prove that there exist efficiently implementable unitaries such that an exponential sample complexity is required to learn them in the incoherent framework with only single qubit measurements. This is captured by the following theorem. 

\begin{figure}[t]
\centering
\includegraphics[width =\columnwidth]{figures/ICL_hardware_final.pdf}
\vspace{-8mm}
\caption{\textbf{Incoherent Learning of 16-qubit Dynamics on Quantum Hardware.}  A short-time Trotterisation of a 16-qubit Transverse-Field Ising Model implemented on the \texttt{ibmq\_kolkata} device is incoherently compiled using shallow measurements.  The PQC's rotation angles are initialized from the uniform distribution $\theta_i \sim \mathcal{U}(-1, 1)$. a) and b) shows typical training and testing curves. The errors decrease as the optimization progresses, indicating the target unitary is being successfully compiled. In c), the testing error upon convergence is shown to decrease for an increasing number of shadows trained on. Here the mean and standard deviation shown here are produced from 10 repeats of training on independent sets of shadows. The star markers emphasize that the testing losses plotted in c) are produced from the statistics of the converged final testing losses of repeated optimizations.}
\label{fig:Hardware_plot}
\vspace{-3mm}
\end{figure}

\begin{figure*}[t!]
\centering
\includegraphics[width =\textwidth]{figures/ICL_simulation_final.pdf}
\vspace{-6mm}
\caption{\textbf{Scalability of Incoherent Learning.} For a range of system sizes ($n$), shadow sizes ($M$), Trotter timesteps ($\Delta t$) and number of ansatz layers, we perform the Incoherent Learning algorithm using shallow measurements. For each configuration, we save the final testing loss (a product state overlap approximation of the Hilbert-Schmidt Test), and 10 repeats generate the mean and standard deviation plotted. The insets show the corresponding training loss upon termination of the optimization.}
\label{fig:Simulation_plot}
\end{figure*}

\begin{thm}[Limit of incoherent learning with shallow measurements (informal)]\label{thm:limitofshallow}
There exist efficiently representable unitaries $U$ such that when restricted to performing only shallow measurements, at least $2^{\Omega(n)}$ calls to $U$ are required to achieve a Hilbert-Schmidt cost $C_\textnormal{HST}(\thv)\leq 1/4$ in the incoherent framework. 
\end{thm}

As discussed in more detail in Appendix \ref{app:lower-bounds-shallow}, we prove this theorem by reduction of the task of distinguishing between orthogonal unitaries that can be used to prepare GHZ-like states. We show that the distinguishing task requires exponential sample complexity for shallow measurements. Moreover, the unitaries we consider are implementable using a linear depth circuit (see Fig.~\ref{fig:GHZ-unitaries} in the Appendix). It follows that there exist efficiently representable unitaries that cannot be efficiently learned using Pauli- (or more general product-) measurements in the incoherent setting. Theorem~\ref{thm:limitofshallow} amounts to a fundamental no-go theorem for the incoherent learning framework and prohibits the emulation of the coherent framework using single qubit Pauli measurements~\cite{huang2021information, chen2021exponential, huang2021quantum, aharonov2022quantum, caro2022learning}. 

\subsection{Implementations}


\paragraph*{Quantum Hardware.}

We demonstrate the ability of our shallow-measurement incoherent-learning algorithm to learn a 16-qubit low-entangling unitary on \texttt{ibmq\_kolkata}. Specifically, the target unitary is a first-order short-time ($\Delta t = 0.1$) Trotterisation for the Transverse-Field Ising Model with Hamiltonian 
\begin{equation}
    H_{\rm Ising} = \sum_{i=0}^{14} Z_i Z_{i+1} + \sum_{i=0}^{15}\alpha_i X_i \, ,
\end{equation} where $\alpha_i$ are randomly drawn from the normal distribution $\mathcal{N}(\mu\,{=}\,0, \sigma\,{=}\,0.5)$. As described in detail in Appendix~\ref{app:ShallowMeasurements}, a Pauli classical shadow of size $280000$ is created for only two training states $\{ U(\Delta t)|\psi_i\rangle \}_{i=0}^1$, where $|\psi_i\rangle$ is a Haar random product state. (Random product states enjoy the same out-of-distribution generalization guarantees as products of random single qubit stabilizer states~\cite{caro2022outofdistribution}).
These shadows are used to compute the local training cost, which is minimised classically by training a simulated parameterized quantum circuit (PQC) with the same gate structure as the target Trotterised unitary. We compute the testing loss $C_{\mathcal{D}_{\text{Haar}_1^{\otimes n}(N)}}(\thv)$ for a set of $N=100$ random product states. This coherent product-state overlap is an operationally meaningful quantity, since it correlates, up to a factor of 2 and additive error $\mathcal{O}\Big(\sqrt{\frac{1}{N}}\Big)$, with the Hilbert-Schmidt cost between the target and learned unitaries, $C_{\text{HST}}(\vec{\theta})$~\cite{caro2022outofdistribution}.

\medskip

Fig.~\ref{fig:Hardware_plot}a) shows the training loss decreasing as the L-BFGS optimizer~\cite{liu1989limited} minimises the cost function, Fig.~\ref{fig:Hardware_plot}b) shows the corresponding testing loss decreasing and Fig.~\ref{fig:Hardware_plot}c) shows the final testing error as a function of shadow size. The differed sized shadows used here are created from randomly chosen subsets of the full 280000 sample shadow originally collected on the quantum computer. For small shadow sizes the final testing loss decreases (signifying improved generalization) as the shadow size increases, but for shadows above $\sim 10^4$ the improvement to the final testing error plateaus. This indicates that a shadow of size $\sim 10^4$ suffices to well reproduce the true underlying output states.

\medskip

\paragraph*{Simulations.}
We now investigate the scalability of the incoherent-learning algorithm with classical simulations of the technique. Here we focus on the $n$-qubit Heisenberg Hamiltonian with open boundary conditions,
\begin{equation}
    H_{\rm Heis}
     = \sum_{i=0}^{n-1} X_i X_{i+1}+Y_i Y_{i+1}+Z_i Z_{i+1} \, .
\end{equation}
We learn a first order (1-layer) and second order (2-layer) Trotterisation of $H_{\rm Heis}$ using an ansatz of the same structure and using two training states $\{ U(\Delta t)|\psi_i\rangle \}_{i=0}^1$ where $|\psi_i\rangle$ are product states. Fig.~\ref{fig:Simulation_plot} compares the final testing loss found for a range of system sizes, shadow sizes and number of layers in the ansatz. Similarly to the hardware results in Fig.~\ref{fig:Hardware_plot}, the testing error is measured by an approximation to the Hilbert-Schmidt Test, computed using product state overlaps. 

We find that for increasing system sizes, there is not a significant decline in the testing performance. Conversely, as the degree of entanglement in the target unitary and ansatz increases, by increasing $\Delta t$ and the number of layers, the testing performance degrades. This can be explained by the growth of the light-cone of the local measurement operators under $V^\dagger(\vec{\theta})$ as sketched in Fig.~\ref{fig:lightcone}. Interestingly, the shadow size required for training depends more strongly on $\Delta t$ than on the number of layers, indicating that it is not the absolute size of the light cone, but rather its effective size (namely the region on which the back-propagated local operator has non-negligible weight) that matters. We discuss this phenomenon further in Appendix~\ref{ap:approxlocal}.

\section{Discussion}

In this paper we have established a fundamental limitation on our ability to learn a target process without coherent interaction between the target and guess unitaries. Namely, Theorem~\ref{thm:limitofshallow} shows that there exist efficiently representable unitaries such that exponentially many shallow measurements (e.g., Pauli measurements) are required to emulate the coherent setting. Crucially, our metric for success here is an average fidelity between the true and learned output states. This is to be contrasted with Ref.~\cite{huang2020predicting} which presents an efficient (both in terms of sampling and computational complexity) incoherent learning algorithm for predicting local measurements outcomes on the outputs of arbitrary processes. Thus our no-go theorem highlights that learning to predict the output states of a process, and thereby fully emulate the coherent setting, is a substantially harder learning task than learning to predict local measurement outcomes.

This makes it especially noteworthy that it is possible, as demonstrated by our proposed algorithm, to fully emulate the coherent setting in the case of low-entangling unitaries. Crucially, our algorithm uses only easy-to-prepare product training states and simple Pauli measurements, making it NISQ friendly~\cite{preskill2018quantum}. We have proven (Theorem~\ref{thm:powerofshallow}) that the sample complexity of this approach scales polynomially with the size of the target unitary. While the computational complexity of this algorithm is unknown, we have good reasons to expect it to be efficient, since it uses a local cost which can be efficiently computed and which enjoys trainability guarantees~\cite{cerezo2021cost}.
This optimism is further supported by our successful implementation of the algorithm to learn a 16-qubit physical process from real quantum hardware.

Finally, it is worth mentioning that both here and in Ref.~\cite{huang2020predicting}, as well as numerous other papers on quantum process learning~\cite{khatri2019quantum, cirstoiu2020variational, caro2022outofdistribution, mizuta2022local, younisqfast2021, patelquest2022}, it is tacitly assumed that we are interested in learning the output of a quantum process over randomly chosen input states (or equivalently we are interested in maximizing the Hilbert-Schmidt inner product). However, in practise one may well be interested in learning to predict the output of a quantum process for a given set of physically interesting input states~\cite{caro2022learning}. Generalizing our results to this setting is an important direction for future work. Other potential extensions include the generalization to quantum channels and/or continuous variable systems.\\

\begin{acknowledgments}
    SJ was supported by the U.S. Department of Energy (DOE) through a quantum computing program sponsored by the Los Alamos National Laboratory (LANL) Information Science and Technology Institute. SJ acknowledges support from the Austrian Science Fund (FWF) through the projects DK-ALM:W1259-N27 and SFB BeyondC F7102. SJ also acknowledges the Austrian Academy of Sciences as a recipient of the DOC Fellowship. 
    MCC was supported by a DAAD PRIME fellowship. PJC acknowledges initial support from the Los Alamos National Laboratory (LANL) ASC Beyond Moore's Law project and subsequent support by the U.S. DOE, Office of Science, Office of Advanced Scientific Computing Research, under the Accelerated Research in Quantum Computing (ARQC) program. HH is supported by a Google PhD Fellowship. ZH acknowledges initial support from the LANL Mark Kac Fellowship and subsequent support from the Sandoz Family Foundation-Monique de Meuron
program for Academic Promotion.
\end{acknowledgments}

\bibliography{quantum}

\clearpage 
\input{Supplementary}

\end{document}
