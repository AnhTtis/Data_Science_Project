{
    "arxiv_id": "2303.11028",
    "paper_title": "MAQA: A Quantum Framework for Supervised Learning",
    "authors": [
        "Antonio Macaluso",
        "Matthias Klusch",
        "Stefano Lodi",
        "Claudio Sartori"
    ],
    "submission_date": "2023-03-20",
    "revised_dates": [
        "2023-03-21"
    ],
    "latest_version": 1,
    "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
    ],
    "abstract": "Quantum Machine Learning has the potential to improve traditional machine learning methods and overcome some of the main limitations imposed by the classical computing paradigm. However, the practical advantages of using quantum resources to solve pattern recognition tasks are still to be demonstrated.\n  This work proposes a universal, efficient framework that can reproduce the output of a plethora of classical supervised machine learning algorithms exploiting quantum computation's advantages. The proposed framework is named Multiple Aggregator Quantum Algorithm (MAQA) due to its capability to combine multiple and diverse functions to solve typical supervised learning problems. In its general formulation, MAQA can be potentially adopted as the quantum counterpart of all those models falling into the scheme of aggregation of multiple functions, such as ensemble algorithms and neural networks. From a computational point of view, the proposed framework allows generating an exponentially large number of different transformations of the input at the cost of increasing the depth of the corresponding quantum circuit linearly. Thus, MAQA produces a model with substantial descriptive power to broaden the horizon of possible applications of quantum machine learning with a computational advantage over classical methods. As a second meaningful addition, we discuss the adoption of the proposed framework as hybrid quantum-classical and fault-tolerant quantum algorithm.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.11028v1"
    ],
    "publication_venue": "1 Figure",
    "doi": "10.1007/s11128-023-03901-w"
}