\section{Pairs of vector group representations}\label{se:pairs}
	
	Now we introduce some notation that we will use during the following sections. We introduce some operators $\mu, \nu$ which depend on a pair of representations of vector groups. These operators will be useful if one wants, for example, to consider the group generated by two vector group representations.
	
	We choose to focus on the conjugation $(g,h) \mapsto ghg^{-1}$ to express the relation between the groups, however using $(g,h) \mapsto gh, (g,h) \mapsto [g,h]$ one could define similar operators replacing the $\mu$ we shall define, to which everything else can be translated.

\begin{definition}
	Let $G^+,G^-$ be vector groups and let $$(\rho^+_i : G^+ \longrightarrow A)_i$$
	and
	$$ (\rho^-_i : G \longrightarrow A)_i$$ be vector group representations. 
	Consider the functions $$\mu_{i,j},\nu_{i,j} : G^+ \times G^- \longrightarrow A,$$ uniquely defined from
	$$\rho^+_{[s]}(x) \rho^-_{[t]}(y) \rho^+_{[s]}(x^{-1}) = \sum_{(i,j) \in \mathbb{N \times \mathbb{N}}} s^it^j \mu_{i,j}(x,y),$$ 
	$$\rho^+_{[s]}(x) \rho^-_{[t]}(y) \rho^+_{[s]}(x^{-1}) = \prod_{\substack{\gcd(i,j) = 1\\ (i,j) \in \mathbb{N} \times (\mathbb{N}_{>0})}} \left(1 + \sum_{k = 1}^\infty s^{ki}t^{kj}\nu_{ki,kj}(x,y)\right),$$ where the order of multiplication on the $(i,j),(k,l) \in \mathbb{N} \times (\mathbb{N}_{>0})$ corresponds to $il < jk$.
	Similarly, we define $\mu,\nu : G^- \times G^+ \longrightarrow A$.
\end{definition}



\begin{lemma}
	The maps $\mu_{i,j}, \nu_{i,j} : G^+ \times G^- \longrightarrow A$ are well-defined.
	\begin{proof}
		This is obviously the case for $\mu$.
		For $\nu$, one can use recursion on the degrees to compute the $\nu$'s uniquely.
		Specifically, we can compute $\nu_{l,m}$ using induction on $l + m$, by observing that $\nu_{l,m}$ is, recursively, the only undefined term of 
		$$\rho^+_{[s]}(x) \rho^-_{[t]}(y) \rho^+_{[s]}(x^{-1}) = \prod_{\substack{\gcd(i,j) = 1\\ (i,j) \in \mathbb{N} \times (\mathbb{N}_{>0})}} \left(1 + \sum_{k = 1}^\infty s^{ki}t^{kj}\nu_{ki,kj}(x,y)\right)$$
		when both expressions are considered in
		$ A[s,t]/(s^{l+1},t^{m+1})$.
	\end{proof}
\end{lemma}

\begin{remark}
	We remark that $\mu_{i,j}(x,y) = \sum_{a + b = i} x_a y_j (x^{-1})_b$.
	The maps $\nu_{i,j}$ can be computed recursively, starting from $\nu_{0,i} = \mu_{0,i}, \nu_{i,1} = \mu_{i,1}$ and then
	$\nu_{i,2} + \sum_{\substack{a + b = i\\a < b}} \nu_{a,1}\nu_{b,1} = \mu_{i,2}$.
	For higher $k$ we can also find formulas for $\nu_{i,k}$ corresponding to the previous lemma.	
\end{remark}

\begin{remark}
	The maps $\mu,$ and $\nu$ are homogeneous in both arguments. Namely, if $x \mapsto f(x)$ is homogneous, then $x \mapsto f(x^{-1})$ is homogeneous as well and if $f$ and $g$ are homogeneous of degree $i$ and $j$, then $x \mapsto f(x) \otimes g(x)$ is homogeneous of degree $i + j$. This is easily proved by using the Hopf algebra structure of the universal representation and the property that each homogeneous map factors through the universal representation as a linear map.
\end{remark}

We also use 
$$\exp(o_{i,j}(x,y),l) = \left(1 + \sum_{k = 1}^\infty l^k\nu_{ki,kj}(x,y)\right),$$
to denote the formal power series which are used to define the $\nu_{i,j}(x,y)$, where we use $l$ as the formal scalar instead of $s^it^j$.

\begin{lemma}
	\label{lemma grouplike}
	Consider a pair of vector group representations $(\rho^+_i:G^+ \longrightarrow A,\rho^-_i:G^- \longrightarrow A)$ to a Hopf algebra $A$.
	Suppose that $\rho^\pm_{[t]}(g)$ is group-like for all $g \in G^+ \cup G^-$, then 
	$\exp(o_{i,j}(g,h),t)$ is group-like as well for all $i,j$.
	\begin{proof}
		Parallel to the recursion used to define the $\nu$ one can prove inductively that 
		$ \exp(o_{i,j}(x,y),s^it^j)$ is a group-like element in $A[s,t]/(s^{ki+1}t^{kj+1})$ when one determines $\nu_{ki,kj}$.
		Specifically, in the inductive step one has
		$$\rho^+_{[s]}(x) \rho^-_{[t]}(y) \rho^+_{[s]}(x^{-1}) = \prod_{\substack{\gcd(i,j) = 1\\ (i,j) \in \mathbb{N} \times \mathbb{N}_{>0}}} \left(1 + \sum_{k = 1}^\infty s^{ki}t^{kj}\nu_{ki,kj}(x,y)\right) \mod (s^{ki+1}t^{kj+1}),$$
		where the left-hand side is group-like and the right-hand side is $ \exp(o_{i,j}(x,y),s^it^j)$ multiplied with group-like elements.
		Since the group-like elements form a group, we proved the induction step.	
	\end{proof}
\end{lemma}



\begin{remark}
	The definition of the $\nu_{i,j}$ is roughly the same as Ditter-Shay Bi-isobaric decomposition, cfr. \cite[Theorem 3.5]{Haz07}.
	We defined $\exp(o_{i,j}(x,y),l)$. It will be useful to abstract the $\exp$ and $l$ away.
	Specifically, we consider
	$ o_{i,j} $ as a sequence of maps
	$$ (\nu_{ki,kj} : G^+ \times G^- \cup G^- \times G^+ \longrightarrow A)_k,$$
	which will be able to play a similar role as $\rho^+, \rho^-$.
	The $o_{i,j}$ have the nice property that they can coincide with group elements of $G^+$ and $G^-$. Furthermore, by considering the $o_{i,j}$ as similar to $\rho^\pm$ it makes sense to speak about $\nu_{k,l}(x,o_{i,j}(y))$, etc..
\end{remark}

\begin{definition}
	Let $\rho_i : G \longrightarrow A$ be a vector group representation.
	We use $\hat{\rho}(G)$ to denote the subalgebra of $A$ generated by all $\rho_i(g).$ 
	Furthermore, we use $\mathcal{H}(G^+,G^-,\rho)$ to denote the algebra $$\langle \nu_{i,i}(x,y) | x \in G^+, y \in G^-, i \in \mathbb{N} \rangle.$$
\end{definition}

\begin{remark}
	Now, we will formulate a theorem involving seemingly random conditions. The conditions can be interpreted as requiring that the pair of representations corresponds to a representation of an operator Jordan-Kantor pair (which we will not define formally), similar to a divided power representation of Jordan pair as introduced by Faulkner \cite{FLK00}.
\end{remark}

\begin{theorem}
	\label{thm main}
	Suppose that $(\rho^\pm_i : G^\pm \longrightarrow A)_i$ are vector group representations such that for $x \in G^\pm, y \in G^\mp$,
	\begin{itemize}
		\item $\exp(o_{2,1}(x,y),s) \in \rho^\pm_{[s]}(G^\pm)$, 
		\item $\exp(o_{3,1}(x,y),s^2) \in \rho^\pm_{[s]}(G^\pm)$ ,
		\item $\exp(o_{i,j}(x,y),s) = 1$ for $i > 2j$ and $i\neq 3j$,
		\item there exists $z \in G^\pm$ such that $\rho_{[s]}(z) = 1 + s\nu_{3,2}(x,y) + O(s^2)$,
	\end{itemize}
	over all scalar extensions,
	then $\hat{\rho}(G^-)\mathcal{H}(G^+,G^-,\rho)\hat{\rho}(G^+)$ is a subalgebra of $A$.
	
	Moreover, if $\rho^+$ and $\rho^-$ are injective on projective vector groups $G^\pm$, then the unique map from the algebra $F$ freely generated by $\mathcal{U}(G^+)$ and $\mathcal{U}(G^-)$ to $A$ corresponding to this representation factors through an algebra structure on the coalgebra $$H = \mathcal{U}(G^-) \otimes \hat{\mathcal{H}}(G^+,G^-,F) \otimes \mathcal{U}(G^+)$$ 
	in which $y \otimes \hat{h} \otimes x$ represents the element $yhx$ in $F$ and $\hat{\mathcal{H}}(G^+,G^-,F)$ is a quotient of $\mathcal{H}(G^+,G^-,F)$. This algebra is $\mathbb{Z}$-graded, if one combines the $\mathbb{N}$-grading of $\mathcal{U}(G^+)$, with the opposite of the $\mathbb{N}$-grading of $\mathcal{U}(G^-)$ and sets $\mathcal{H}(G^+,G^-,F)$ to be $0$-graded.
	\begin{proof}
		Proof in appendix \ref{section proof}.
	\end{proof}
\end{theorem}

\begin{remark}
	If the vector groups $G^\pm$ are not projective, the moreover part of the previous theorem still holds if one replaces $\mathcal{U}(G^\pm)$ by a suitable quotient in the definition of $H$.
\end{remark}

Now, we prove a technical lemma to obtain the necessity of certain linearisation formulas which will be useful in the following sections.
We extend the domains of $\mu_{i,j}$, $\nu_{i,j}$, so that they can also take $o_{k,l}(x,y)$ as input. 
We use $\nu_{(a,b),(c,d)}$ to express certain $((a,b),(c,d))$-linearisations of $\nu_{a+b,c+d}$, corresponding to linearizing the homogeneous maps $G^+ \longrightarrow \text{Hom}(G^-,A),G^- \longrightarrow \text{Hom}(G^+,A).$

\begin{lemma}
	\label{lemma linearizations mu}
	Consider a pair of vector group representations $(\rho^+_i:G^+ \longrightarrow A,\rho^-_i:G^- \longrightarrow A)$. 
	The linearisations of $\mu$ can be computed as
	$$ \mu_{(i,j),k}(x,z,y) = \sum_{a + b = i} x_a \mu_{j,k}(z,y) (x^{-1})_b, \quad \mu_{i,(j,k)}(x,z,y) = \sum_{a + b = i} \mu_{a,j}(x,z)\mu_{b,k}(x,y).$$
	\begin{proof}
		This follows easily if one computes both sides from conjugations and products of $\rho_{[s]}(x), \rho_{[t]}(z),$ and $\rho_{[u]}(y)$.
	\end{proof}
\end{lemma}

\begin{lemma}
	\label{Lemma equations}
		Suppose that $\rho^\pm_i : G^\pm \longrightarrow A$ are vector group representations.
		The following formulas hold for $x,g \in G^+, y \in G^-$
		\begin{enumerate}
			\item $\sum t^{k+l} \nu_{ki,kj}(x^{-1},y^{-1})\nu_{li,lj}(y,x) = 1,$
			\item \label{REP EQ V1}$[\nu_{1,1}(y^{-1},x^{-1}),\rho_1(g)] = \nu_{(1,1),1}(g,x,y)$,
			\item \label{REP EQ Tau1}$\nu_{2,1}(o_{1,1}(y^{-1},x^{-1}), g) = \nu_{(1,2),2}(g,x,y)$,
			\item \label{REP EQ V 2}$[\nu_{1,1}(y^{-1},x^{-1}),\rho_2(g)] = \nu_{(2,1),1}(g,x,y) + \nu_{(1,1),1}(g,x,y)\rho_1(g)$,
			\item $\nu_{(2,1),2}(g,x,y) = \nu_{2,1}(g,o_{2,1}(y^{-1},x^{-1})) - [\mu_{1,1}(x,y),\mu_{2,1}(g,y)],$
			\item $\nu_{(3,1),2}(g,x,y) = \nu_{3,1}(g,o_{2,1}(y^{-1},x^{-1})) - [\mu_{1,1}(x,y),\mu_{3,1}(g,y)] + \nu_{2,1}(g,y)\nu_{(1,1),1}(g,x,y)$,
			\item $\nu_{(1,3),2}(x,g,y) = [\rho_1(x),\nu_{3,2}(g,y)] + \nu_{(1,1),1}(x,g,y)\nu_{2,1}(g,y).$			
			\item 
			Furthermore, if $\nu_{4,1}(x,y) = 0$ for all $x \in G^+,y \in G^-$, then we also have
			\begin{enumerate}				
				\item \label{REP EQ Tau2}$\nu_{2,2}(o_{1,1}(y^{-1},x^{-1}), g) = \nu_{(2,2),2}(g,x,y) - \nu_{2,1}(g,y)\nu_{2,1}(x,y)).$
				\item $\nu_{3,(1,1)}({y,g,x}) = [\nu_{3,1}(y,g),\rho_1(x)] - [\nu_{1,1}(y,x),\nu_{2,1}(y,g)],$
				\item $\nu_{4,(1,1)}({y,g,x}) = [\nu_{3,1}(y,g),\nu_{1,1}(y,x)] + \nu_{2,1}(y,g)\nu_{2,1}(y,x).$
			\end{enumerate}
		\end{enumerate}		
	\begin{proof}
		The first equation follows from
		$$ (\rho^-_{[t]}(y^{-1})\rho^+_{[s]}(x)\rho^-_{[t]}(y)\rho^+_{[s]}(x^{-1}))^{-1} = \rho^+_{[s]}(x)\rho^-_{[t]}(y^{-1})\rho^+_{[s]}(x^{-1})\rho^-_{[t]}(y),$$
		since this proves, using the defining expressions for $o_{i,j}$ with slightly different indices so that they correspond to commutators, that
		$$ \left(\prod_{\gcd(i,j) = 1, (i,j) \in (\mathbb{N}_{>0})^2} \exp(o_{i,j}(x,y),s^it^j) \right)^{-1} = \prod_{\gcd(i,j) = 1, (i,j) \in (\mathbb{N}_{>0})^2} \exp(o_{i,j}(y^{-1},x^{-1}),s^jt^i).$$
		In the rest, we write $g_i$ for $\rho_i(g)$.
		
		The rest are just calculations involving linearisations. 
		These equations can be proved by rewriting the $\nu$ on the left-hand side in terms of $\mu$, and smartly using
		$$ \mu_{(a,b),c}(g,x,y) = \sum_{i + j = a}g_i \mu_{b,c}(x,y) (g^{-1})_j$$
		and 
		$$ \mu_{a,(b,c)}(y,g,x) = \sum_{i + j = a} \mu_{i,b}(y,g)\mu_{j,c}(y,x). $$
		
		We prove, as an example, equation $8.a$, since the proof of this equation showcases all techniques needed to prove the other cases.
		From the decomposition of $$\exp(o_{1,1}(y^{-1},x^{-1}),l)\rho_{[s]}(g)\exp(o_{1,1}(x,y),l)\rho_{[s]}(g^{-1})  = \exp(o_{1,1}(y^{-1},x^{-1}),l) \sum s^il^j \mu_{i,j}(g,o_{1,1}(x,y))$$
		as a product
		$$ \prod_{\gcd(i,j) = 1, (i,j) \in (\mathbb{N}_{>0})^2}
		\exp(o_{i,j}(o_{1,1}(y^{-1},x^{-1}),g),l^is^j),$$ we learn that 
		\begin{equation}
			\label{equation lemma equations 1}
			\nu_{2,2}((o_{1,1}(y^{-1},x^{-1}), g) = \mu_{2,2}(g,o_{1,1}(x,y)) - \mu_{1,1}(x,y)\mu_{2,1}(g,o_{1,1}(x,y))
		\end{equation}
		by comparing the terms belonging to $l^2s^2$ and using that $\nu_{l,1} = \mu_{l,1}$.
		The ordinary definitions of $\nu$ and $\mu$ yield \[\nu_{2,2}(x,y) = \mu_{2,2}(x,y) - y_1\mu_{2,1}(x,y),\] so that
	    \begin{equation}
	    	\label{equation lemma equations}
	    	\mu_{2,2}(g,o_{1,1}(x,y)) = \mu_{(2,2),2}(g,x,y) - \sum_{i + j = 2} g_i y_1 \mu_{2,1}(x,y) (g_j)^{-1}
	    \end{equation}
	    must hold since $\nu_{2,2}(x,y)$ is the second coordinate of $o_{1,1}(x,y)$, using the definition of $\mu_{2,\cdot}(g,\cdot)$.
	    Equation (\ref{equation lemma equations}) can be rewritten further as
	    \begin{equation}
	    	\label{equation lemma equations 2}
	    	\mu_{2,2}(g,o_{1,1}(x,y)) = \mu_{(2,2),2}(g,x,y) - \sum_{k + l= 2} \mu_{k,1}(g,y) \mu_{(l,2),1}(g,x,y),
	    \end{equation}
       using $\sum_{i + j = 2} g_i y_1 \mu_{2,1}(x,y) (g_j)^{-1} = \sum_{k + l= 2} \mu_{k,1}(g,y) \mu_{(l,2),1}(g,x,y)$ by Lemma \ref{lemma linearizations mu}.
	   Similarly, we have
	    \begin{equation}
	    	\label{equation lemma equations 3}
	    	- \mu_{1,1}(x,y)\mu_{2,1}(g,o_{1,1}(x,y)) = - \mu_{1,1}(x,y)\mu_{(2,1),1}(g,x,y).
	    \end{equation}
	    Combining Equations (\ref{equation lemma equations 1}), (\ref{equation lemma equations 2}), and (\ref{equation lemma equations 3}), we obtain
	     $$ \nu_{2,2}(g,o_{1,1}(y^{-1},x^{-1})) = \nu_{(2,2),2}(g,x,y) - \mu_{2,1}(g,y)\mu_{2,1}(x,y), $$
	     by using
	     $$ \nu_{(2,2),2}(g,x,y) = \mu_{(2,2),2}(g,x,y) - \mu_{1,1}(g,y)\mu_{(1,2),1}(g,x,y) - \mu_{1,1}(x,y)\mu_{(2,1),1}(g,x,y)$$
	     and that $\mu_{(2,2),1}(g,x,y) = 0$.
	     Using $\mu_{2,1} = \nu_{2,1}$ yields the equation we wanted to prove.	     
	\end{proof}	
\end{lemma}

\begin{remark}
	Once one understands how to work with the linearisations, the previous equations are not that hard to prove. They are just very tedious to write down. All of the computations can be expressed relatively compactly, however.
	For example, if one schematically writes $(\cdot,\cdot)$ for $\mu_{\cdot,\cdot}$ and $[\cdot,\cdot]$ for $\nu_{\cdot,\cdot}$, the previous computation can be restated as
	\begin{align*}
		[2,2]_{o,g} & = (2,2)_{g,o} - (1,1)_{x,y}(2,1)_{g,o} = ((2,2),2) - ((0,1),1)((2,1),1) -\sum_{i + j = 2} ((i,0),1)((j,2),1) \\
		& = [(2,2),2] - ((2,0),1)((0,2),1) - ((0,0),1)((2,2),1) = [(2,2),2] - [(2,0),1][(0,2),1], 
	\end{align*}
	where we did not write evaluations in $(g,x,y)$, used the linearisation properties of $\mu$ and used expressions for $\nu_{i,j}$'s in terms of $\mu_{i,j}$'s. For this computation, one can express the $\nu$'s in terms of $\mu$'s using
	$$ [2,2] = (2,2) - (0,1)(2,1), \quad [4,2] = (4,2) - (1,1)(3,1).$$
	In this last expression we dropped the term $(0,1)(4,1)$, since we assume that $(4,1) = 0$ in the lemma.
	Another relation that is useful in proving the previous lemma is
	$$ [3,2] = (3,2) - (0,1)(3,1) - (1,1)(2,1).$$
\end{remark}