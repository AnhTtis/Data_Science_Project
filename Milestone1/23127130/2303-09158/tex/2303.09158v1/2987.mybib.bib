@inproceedings{li2022hybrid,
  title={Hybrid Multimodal Feature Extraction, Mining and Fusion for Sentiment Analysis},
  author={Li, Jia and Zhang, Ziyang and Lang, Junjie and Jiang, Yueqi and An, Liuwei and Zou, Peng and Xu, Yangyang and Gao, Sheng and Lin, Jie and Fan, Chunxiao and others},
  booktitle={Proceedings of the 3rd International on Multimodal Sentiment Analysis Workshop and Challenge},
  pages={81--88},
  year={2022}
}

@inproceedings{kollias2022abaw,
  title={Abaw: Valence-arousal estimation, expression recognition, action unit detection \& multi-task learning challenges},
  author={Kollias, Dimitrios},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2328--2336},
  year={2022}
}

@article{ekman1978facial,
  title={Facial action coding system},
  author={Ekman, Paul and Friesen, Wallace V},
  journal={Environmental Psychology \& Nonverbal Behavior},
  year={1978}
}

@article{zhang1999feature,
  title={Feature-based facial expression recognition: Sensitivity analysis and experiments with a multilayer perceptron},
  author={Zhang, Zhengyou},
  journal={International journal of pattern recognition and Artificial Intelligence},
  volume={13},
  number={06},
  pages={893--911},
  year={1999},
  publisher={World Scientific}
}

@inproceedings{poria2016convolutional,
  title={Convolutional MKL based multimodal emotion recognition and sentiment analysis},
  author={Poria, Soujanya and Chaturvedi, Iti and Cambria, Erik and Hussain, Amir},
  booktitle={2016 IEEE 16th international conference on data mining (ICDM)},
  pages={439--448},
  year={2016},
  organization={IEEE}
}

@inproceedings{eyben2009openear,
  title={OpenEARâ€”introducing the Munich open-source emotion and affect recognition toolkit},
  author={Eyben, Florian and W{\"o}llmer, Martin and Schuller, Bj{\"o}rn},
  booktitle={2009 3rd international conference on affective computing and intelligent interaction and workshops},
  pages={1--6},
  year={2009},
  organization={IEEE}
}

@inproceedings{chen2019efficient,
  title={Efficient spatial temporal convolutional features for audiovisual continuous affect recognition},
  author={Chen, Haifeng and Deng, Yifan and Cheng, Shiwen and Wang, Yixuan and Jiang, Dongmei and Sahli, Hichem},
  booktitle={Proceedings of the 9th International on Audio/Visual Emotion Challenge and Workshop},
  pages={19--26},
  year={2019}
}

@inproceedings{zhao2018multi,
  title={Multi-modal multi-cultural dimensional continues emotion recognition in dyadic interactions},
  author={Zhao, Jinming and Li, Ruichen and Chen, Shizhe and Jin, Qin},
  booktitle={Proceedings of the 2018 on audio/visual emotion challenge and workshop},
  pages={65--72},
  year={2018}
}

@article{mikolov2013distributed,
  title={Distributed representations of words and phrases and their compositionality},
  author={Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  journal={Advances in neural information processing systems},
  volume={26},
  year={2013}
}

@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={1532--1543},
  year={2014}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{meng2022multi,
  title={Multi-modal emotion estimation for in-the-wild videos},
  author={Meng, Liyu and Liu, Yuchen and Liu, Xiaolong and Huang, Zhaopei and Jiang, Wenqiang and Zhang, Tenggan and Deng, Yuanyuan and Li, Ruichen and Wu, Yannan and Zhao, Jinming and others},
  journal={arXiv preprint arXiv:2203.13032},
  year={2022}
}

@inproceedings{zhang2022transformer,
  title={Transformer-based multimodal information fusion for facial expression analysis},
  author={Zhang, Wei and Qiu, Feng and Wang, Suzhen and Zeng, Hao and Zhang, Zhimeng and An, Rudong and Ma, Bowen and Ding, Yu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2428--2437},
  year={2022}
}

@article{satar2022rome,
  title={RoME: Role-aware Mixture-of-Expert Transformer for Text-to-Video Retrieval},
  author={Satar, Burak and Zhu, Hongyuan and Zhang, Hanwang and Lim, Joo Hwee},
  journal={arXiv preprint arXiv:2206.12845},
  year={2022}
}

@inproceedings{lin2022stvgformer,
  title={STVGFormer: Spatio-Temporal Video Grounding with Static-Dynamic Cross-Modal Understanding},
  author={Lin, Zihang and Tan, Chaolei and Hu, Jian-Fang and Jin, Zhi and Ye, Tiancai and Zheng, Wei-Shi},
  booktitle={Proceedings of the 4th on Person in Context Workshop},
  pages={1--5},
  year={2022}
}

@inproceedings{chen2017multimodal,
  title={Multimodal multi-task learning for dimensional and continuous emotion recognition},
  author={Chen, Shizhe and Jin, Qin and Zhao, Jinming and Wang, Shuai},
  booktitle={Proceedings of the 7th Annual Workshop on Audio/Visual Emotion Challenge},
  pages={19--26},
  year={2017}
}

@article{jiang2022facial,
  title={Facial action unit recognition with multi-models ensembling},
  author={Jiang, Wenqiang and Wu, Yannan and Qiao, Fengsheng and Meng, Liyu and Deng, Yuanyuan and Liu, Chuanhe},
  journal={arXiv preprint arXiv:2203.13046},
  year={2022}
}

@article{jin2021multi,
  title={A multi-modal and multi-task learning method for action unit and expression recognition},
  author={Jin, Yue and Zheng, Tianqing and Gao, Chao and Xu, Guoqiang},
  journal={arXiv preprint arXiv:2107.04187},
  year={2021}
}

@inproceedings{zhang2022continuous,
  title={Continuous emotion recognition using visual-audio-linguistic information: A technical report for abaw3},
  author={Zhang, Su and An, Ruyi and Ding, Yi and Guan, Cuntai},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2376--2381},
  year={2022}
}

@article{kim2022facial,
  title={Facial expression recognition with swin transformer},
  author={Kim, Jun-Hwa and Kim, Namho and Won, Chee Sun},
  journal={arXiv preprint arXiv:2203.13472},
  year={2022}
}

@article{tallec2022multi,
  title={Multi-label transformer for action unit detection},
  author={Tallec, Gauthier and Yvinec, Edouard and Dapogny, Arnaud and Bailly, Kevin},
  journal={arXiv preprint arXiv:2203.12531},
  year={2022}
}

@article{wang2022multi,
  title={Multi-modal multi-label facial action unit detection with transformer},
  author={Wang, Lingfeng and Wang, Shisen and Qi, Jin},
  journal={arXiv preprint arXiv:2203.13301},
  year={2022}
}

@article{zhang2020multimodal,
  title={Multimodal intelligence: Representation learning, information fusion, and applications},
  author={Zhang, Chao and Yang, Zichao and He, Xiaodong and Deng, Li},
  journal={IEEE Journal of Selected Topics in Signal Processing},
  volume={14},
  number={3},
  pages={478--493},
  year={2020},
  publisher={IEEE}
}


@article{nagrani2021attention,
  title={Attention bottlenecks for multimodal fusion},
  author={Nagrani, Arsha and Yang, Shan and Arnab, Anurag and Jansen, Aren and Schmid, Cordelia and Sun, Chen},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={14200--14213},
  year={2021}
}

@article{martinez2017automatic,
  title={Automatic analysis of facial actions: A survey},
  author={Martinez, Brais and Valstar, Michel F and Jiang, Bihan and Pantic, Maja},
  journal={IEEE transactions on affective computing},
  volume={10},
  number={3},
  pages={325--347},
  year={2017},
  publisher={IEEE}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{han2022survey,
  title={A survey on vision transformer},
  author={Han, Kai and Wang, Yunhe and Chen, Hanting and Chen, Xinghao and Guo, Jianyuan and Liu, Zhenhua and Tang, Yehui and Xiao, An and Xu, Chunjing and Xu, Yixing and others},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={45},
  number={1},
  pages={87--110},
  year={2022},
  publisher={IEEE}
}

@article{giannakopoulos2015pyaudioanalysis,
  title={pyAudioAnalysis: An Open-Source Python Library for Audio Signal Analysis},
  author={Giannakopoulos, Theodoros},
  journal={PloS one},
  volume={10},
  number={12},
  year={2015},
  publisher={Public Library of Science}
}

@inproceedings{zhang2018attention,
  title={Attention based fully convolutional network for speech emotion recognition},
  author={Zhang, Yuanyuan and Du, Jun and Wang, Zirui and Zhang, Jianshu and Tu, Yanhui},
  booktitle={2018 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)},
  pages={1771--1775},
  year={2018},
  organization={IEEE}
}

@inproceedings{stuhlsatz2011deep,
  title={Deep neural networks for acoustic emotion recognition: Raising the benchmarks},
  author={Stuhlsatz, Andr{\'e} and Meyer, Christine and Eyben, Florian and Zielke, Thomas and Meier, G{\"u}nter and Schuller, Bj{\"o}rn},
  booktitle={2011 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={5688--5691},
  year={2011},
  organization={IEEE}
}

@article{lieskovska2021review,
  title={A review on speech emotion recognition using deep learning and attention mechanism},
  author={Lieskovsk{\'a}, Eva and Jakubec, Maro{\v{s}} and Jarina, Roman and Chmul{\'\i}k, Michal},
  journal={Electronics},
  volume={10},
  number={10},
  pages={1163},
  year={2021},
  publisher={MDPI}
}

@article{kratzwald2018deep,
  title={Deep learning for affective computing: Text-based emotion recognition in decision support},
  author={Kratzwald, Bernhard and Ili{\'c}, Suzana and Kraus, Mathias and Feuerriegel, Stefan and Prendinger, Helmut},
  journal={Decision Support Systems},
  volume={115},
  pages={24--35},
  year={2018},
  publisher={Elsevier}
}

@article{zadeh2016multimodal,
  title={Multimodal sentiment intensity analysis in videos: Facial gestures and verbal messages},
  author={Zadeh, Amir and Zellers, Rowan and Pincus, Eli and Morency, Louis-Philippe},
  journal={IEEE Intelligent Systems},
  volume={31},
  number={6},
  pages={82--88},
  year={2016},
  publisher={IEEE}
}

@inproceedings{perez2013utterance,
  title={Utterance-level multimodal sentiment analysis},
  author={P{\'e}rez-Rosas, Ver{\'o}nica and Mihalcea, Rada and Morency, Louis-Philippe},
  booktitle={Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={973--982},
  year={2013}
}

@inproceedings{truong2019vistanet,
  title={Vistanet: Visual aspect attention network for multimodal sentiment analysis},
  author={Truong, Quoc-Tuan and Lauw, Hady W},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={33},
  number={01},
  pages={305--312},
  year={2019}
}

@article{li2021align,
  title={Align before fuse: Vision and language representation learning with momentum distillation},
  author={Li, Junnan and Selvaraju, Ramprasaath and Gotmare, Akhilesh and Joty, Shafiq and Xiong, Caiming and Hoi, Steven Chu Hong},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={9694--9705},
  year={2021}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{AshishVaswani2017AttentionIA,
  title={Attention is All you Need},
  author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  journal={Neural Information Processing Systems},
  year={2017}
}

@article{HaifengChen2021TransformerEW,
  title={Transformer Encoder With Multi-Modal Multi-Head Attention for Continuous Affect Recognition},
  author={Haifeng Chen and Dongmei Jiang and Hichem Sahli},
  journal={IEEE Transactions on Multimedia},
  year={2021}
}

@article{luo2022learning,
  title={Learning multi-dimensional edge feature-based au relation graph for facial action unit recognition},
  author={Luo, Cheng and Song, Siyang and Xie, Weicheng and Shen, Linlin and Gunes, Hatice},
  journal={arXiv preprint arXiv:2205.01782},
  year={2022}
}

 @article{schuller2009interspeech,
  title={The interspeech 2009 emotion challenge},
  author={Schuller, Bj{\"o}rn and Steidl, Stefan and Batliner, Anton},
  year={2009}
}

@inproceedings{schuller2013interspeech,
  title={The INTERSPEECH 2013 computational paralinguistics challenge: Social signals, conflict, emotion, autism},
  author={Schuller, Bj{\"o}rn and Steidl, Stefan and Batliner, Anton and Vinciarelli, Alessandro and Scherer, Klaus and Ringeval, Fabien and Chetouani, Mohamed and Weninger, Felix and Eyben, Florian and Marchi, Erik and others},
  booktitle={Proceedings INTERSPEECH 2013, 14th Annual Conference of the International Speech Communication Association, Lyon, France},
  year={2013}
}

@inproceedings{hershey2017cnn,
  title={CNN architectures for large-scale audio classification},
  author={Hershey, Shawn and Chaudhuri, Sourish and Ellis, Daniel PW and Gemmeke, Jort F and Jansen, Aren and Moore, R Channing and Plakal, Manoj and Platt, Devin and Saurous, Rif A and Seybold, Bryan and others},
  booktitle={2017 ieee international conference on acoustics, speech and signal processing (icassp)},
  pages={131--135},
  year={2017},
  organization={IEEE}
}

@article{amiriparian2017snore,
  title={Snore sound classification using image-based deep spectrum features},
  author={Amiriparian, Shahin and Gerczuk, Maurice and Ottl, Sandra and Cummins, Nicholas and Freitag, Michael and Pugachevskiy, Sergey and Baird, Alice and Schuller, Bj{\"o}rn},
  year={2017}
}

@inproceedings{gemmeke2017audio,
  title={Audio set: An ontology and human-labeled dataset for audio events},
  author={Gemmeke, Jort F and Ellis, Daniel PW and Freedman, Dylan and Jansen, Aren and Lawrence, Wade and Moore, R Channing and Plakal, Manoj and Ritter, Marvin},
  booktitle={2017 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={776--780},
  year={2017},
  organization={IEEE}
}

@inproceedings{zhang2022learn,
  title={Learn from all: Erasing attention consistency for noisy label facial expression recognition},
  author={Zhang, Yuhang and Wang, Chengrui and Ling, Xu and Deng, Weihong},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXVI},
  pages={418--434},
  year={2022},
  organization={Springer}
}

@inproceedings{li2017reliable,
  title={Reliable crowdsourcing and deep locality-preserving learning for expression recognition in the wild},
  author={Li, Shan and Deng, Weihong and Du, JunPing},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2852--2861},
  year={2017}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{mollahosseini2017affectnet,
  title={Affectnet: A database for facial expression, valence, and arousal computing in the wild},
  author={Mollahosseini, Ali and Hasani, Behzad and Mahoor, Mohammad H},
  journal={IEEE Transactions on Affective Computing},
  volume={10},
  number={1},
  pages={18--31},
  year={2017},
  publisher={IEEE}
}

@article{zheng2022poster,
  title={POSTER: A Pyramid Cross-Fusion Transformer Network for Facial Expression Recognition},
  author={Zheng, Ce and Mendieta, Matias and Chen, Chen},
  journal={arXiv preprint arXiv:2204.04083},
  year={2022}
}

@article{mao2023poster,
  title={POSTER V2: A simpler and stronger facial expression recognition network},
  author={Mao, Jiawei and Xu, Rui and Yin, Xuesong and Chang, Yuanqi and Nie, Binling and Huang, Aibin},
  journal={arXiv preprint arXiv:2301.12149},
  year={2023}
}

@inproceedings{baltrusaitis2018openface,
  title={Openface 2.0: Facial behavior analysis toolkit},
  author={Baltrusaitis, Tadas and Zadeh, Amir and Lim, Yao Chong and Morency, Louis-Philippe},
  booktitle={2018 13th IEEE international conference on automatic face \& gesture recognition (FG 2018)},
  pages={59--66},
  year={2018},
  organization={IEEE}
}


@article{AlbertHaque2018MeasuringDS,  
 title={Measuring Depression Symptom Severity from Spoken Language and 3D Facial Expressions.},  
 author={Albert Haque and Michelle Guo and Adam S. Miner and Li Fei-Fei},
 journal={arXiv: Computer Vision and Pattern Recognition},  
 year={2018}
 }



@article{GulbadanSikander2019DriverFD,  
 title={Driver Fatigue Detection Systems: A Review},  
 author={Gulbadan Sikander and Shahzad Anwar},  
 journal={IEEE Transactions on Intelligent Transportation Systems},  
 year={2019}
 }

 @article{VaradaKolhatkar2020TheSO,  
  title={The SFU Opinion and Comments Corpus: A Corpus for the Analysis of Online News Comments.},  
  author={Varada Kolhatkar and Hanhan Wu and Luca Cavasso and Emilie Francis and Kavan Shukla and Maite Taboada},  
  journal={Corpus pragmatics},  
  year={2020}
  }

@inproceedings{PaulEkman2019FacialAC,  
  title={Facial action coding system},  
  author={Paul Ekman and Wallace V. Friesen},  
  year={2019}
  }

@inproceedings{PaulEkman1992AnAF,  
 title={An argument for basic emotions},  
 author={Paul Ekman},  
 year={1992}
 }

 @article{JamesARussell1980ACM,  
  title={A CIRCUMPLEX MODEL OF AFFECT},  
  author={James A. Russell},  
  journal={Journal of Personality and Social Psychology},  
  year={1980}
  }