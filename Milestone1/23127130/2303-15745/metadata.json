{
    "arxiv_id": "2303.15745",
    "paper_title": "On Feature Scaling of Recursive Feature Machines",
    "authors": [
        "Arunav Gupta",
        "Rohit Mishra",
        "William Luu",
        "Mehdi Bouassami"
    ],
    "submission_date": "2023-03-28",
    "revised_dates": [
        "2023-03-29"
    ],
    "latest_version": 1,
    "categories": [
        "cs.LG",
        "cs.AI"
    ],
    "abstract": "In this technical report, we explore the behavior of Recursive Feature Machines (RFMs), a type of novel kernel machine that recursively learns features via the average gradient outer product, through a series of experiments on regression datasets. When successively adding random noise features to a dataset, we observe intriguing patterns in the Mean Squared Error (MSE) curves with the test MSE exhibiting a decrease-increase-decrease pattern. This behavior is consistent across different dataset sizes, noise parameters, and target functions. Interestingly, the observed MSE curves show similarities to the \"double descent\" phenomenon observed in deep neural networks, hinting at new connection between RFMs and neural network behavior. This report lays the groundwork for future research into this peculiar behavior.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.15745v1"
    ],
    "publication_venue": null
}