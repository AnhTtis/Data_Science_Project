\section{Introduction}
Software vulnerabilities can have a significant impact and result in serious consequences for modern software. They cause billions of dollars in losses each year in large software systems~\cite{realvul2020}. As a result, effective and efficient detection and repair of software vulnerabilities are crucial. To defend against vulnerabilities, many techniques have been proposed. Among them, vulnerability detection is one of the most important domains of defense. Consequently, numerous vulnerability detection techniques have been proposed and have achieved success in their evaluations.

%Software vulnerabilities are harmful and they cause serious consequences to modern software. Each year they cause billions of dollars loss in large software systems~\cite{realvul2020}. Thus, effective and efficient detection and repair for software vulnerabilities are very important. To defend the vulnerabilities, many techniques are purposed. Among them, vulnerability detection is one of the most important domains of the defend. Thus, many vulnerability detection techniques are proposed and they achieve successes in their evaluations.


However, there is a lack of understanding and benchmarking of vulnerability detection techniques. Some papers only propose techniques without evaluating them with benchmarking datasets~\cite{holzmann2002static, kroening2014cbmc, cuoq2012frama}. Other papers simply evaluate the techniques by computing the number of vulnerabilities found in several real-world projects~\cite{austin2011one, austin2013comparison, pozza2006comparing, antunes2009comparing}. However, their benchmarking datasets do not have ground truths, making it impossible to compute precision, recall, and F1 scores. As a result, it is challenging to benchmark the techniques fairly and comprehensively.

%However, there is a lack of understanding and benchmarking on these vulnerability detection techniques. Some of the papers only purpose their techniques without evaluation with benchmarking datasets~\cite{holzmann2002static, kroening2014cbmc, cuoq2012frama}. Other papers simply evaluate the techniques by computing the numbers of vulnerabilities found in several real-world projects~\cite{austin2011one, austin2013comparison, pozza2006comparing, antunes2009comparing}. Their benchmarking datasets do not have ground truths and thus no precision, recall, and F1 can be computed. In this case, it is difficult to benchmark the techniques fairly and comprehensively.

In this paper, we review the current literature on benchmarking vulnerability detection techniques. First, we examine the benchmarking approaches used when introducing these techniques. Next, we review third-party empirical studies on benchmarking the techniques. Finally, we summarize the challenges encountered during benchmarking and provide an overview of possible solutions for addressing these challenges.

%In this paper, we review the current literature on benchmarking vulnerability detection. We first review the benchmarking approaches used when the techniques are introduced. We then review the third-party empirical studies on benchmarking the techniques. Finally, we summarize the challenges encountered for the benchmarking and review some of the possible solutions for solving the challenges.

In summary, we make the following contributions:
\begin{itemize}
    \item We analyze the lack of benchmarking for software vulnerability detection and the difficulties that arise from this lack.
    \item To the best of our knowledge, our study is the first to comprehensively investigate and summarize the current state of software vulnerability detection benchmarking.
    \item Based on our survey, we discuss the major challenges associated with benchmarking software vulnerability detection and describe some possible solutions for addressing these challenges in the future.
\end{itemize}