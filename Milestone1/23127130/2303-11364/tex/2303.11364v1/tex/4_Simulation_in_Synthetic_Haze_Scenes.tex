\begin{figure*}[htbp]
\setlength{\tabcolsep}{0pt}
\renewcommand{\arraystretch}{0.8}\footnotesize
\centering\begin{tabular}{*{6}{>{\centering\arraybackslash}M{0.166\textwidth}}}
NeuS & COLMAP + NeuS &ImDehaze+NeuS& VidDehaze + NeuS & \moniker{} & Ground Truth  \\
\includegraphics[width=\linewidth]{images/qualitative/syn_new/scan24/scan24_neus.jpg}&
\includegraphics[width=\linewidth]{images/qualitative/syn_new/scan24/scan24_colmap.jpg} &
\includegraphics[width=\linewidth]{images/qualitative/syn_new/scan24/scan24_dehaze.jpg}&
\includegraphics[width=\linewidth]{images/qualitative/syn_new/scan24/scan24_video.jpg}&
\includegraphics[width=\linewidth]{images/qualitative/syn_new/scan24/scan24_ours.jpg}&
\hspace*{+0.4cm}\includegraphics[width=\linewidth]{images/qualitative/syn_new/scan24/scan24_gt.jpg}
\\
\includegraphics[width=\linewidth]{images/qualitative/syn_new/scan97/scan97_neus.jpg}&
\includegraphics[width=\linewidth]{images/qualitative/syn_new/scan97/scan97_colmap.jpg} &
\includegraphics[width=\linewidth]{images/qualitative/syn_new/scan97/scan97_dehaze.jpg}&
\includegraphics[width=\linewidth]{images/qualitative/syn_new/scan97/scan97_video.jpg}&
\includegraphics[width=\linewidth]{images/qualitative/syn_new/scan97/scan97_ours.jpg}&
\hspace*{-0.2cm}\includegraphics[width=\linewidth]{images/qualitative/syn_new/scan97/scan97_gt.jpg}
\\
\includegraphics[width=\linewidth]{images/qualitative/syn_new/scan110/scan110_neus.jpg}&
\includegraphics[width=\linewidth]{images/qualitative/syn_new/scan110/scan110_colmap.jpg}&
\includegraphics[width=\linewidth]{images/qualitative/syn_new/scan110/scan110_dehaze.jpg}&
\includegraphics[width=\linewidth]{images/qualitative/syn_new/scan110/scan110_video.jpg}&
\includegraphics[width=\linewidth]{images/qualitative/syn_new/scan110/scan110_ours.jpg}&
\hspace*{+0.6cm}\includegraphics[width=\linewidth]{images/qualitative/syn_new/scan110/scan110_gt.jpg}
\\

\includegraphics[width=\linewidth]{images/qualitative/syn_new/scan118/scan118_neus.jpg}&
\includegraphics[width=\linewidth]{images/qualitative/syn_new/scan118/scan118_colmap.jpg}&
\includegraphics[width=\linewidth]{images/qualitative/syn_new/scan118/scan118_dehaze.jpg}&
\includegraphics[width=\linewidth]{images/qualitative/syn_new/scan118/scan118_video.jpg}&
\includegraphics[width=\linewidth]{images/qualitative/syn_new/scan118/scan118_ours.jpg}&
\hspace*{+0.9cm}\includegraphics[width=\linewidth]{images/qualitative/syn_new/scan118/scan118_gt.jpg}\\
\end{tabular}
\caption{\textbf{Qualitative comparison on synthetic data.} Our method successfully removes heterogeneous haze in the synthesized views, showing the best appearance fidelity compared with baseline methods. The reconstructed geometry is more accurate, less noisy, and contains more details.
}\vspace{-0.5cm}
\label{fig:dtu_qualitative}
\end{figure*}

\section{Experiments with Synthetic Scenes}
In this section, we detail our experiments using synthetic data.
Our goal is to quantifiably evaluate the contribution of each proposed component in a controlled setting.
We report our main findings here and refer the readers to the supplement for more detailed evaluations.
\subsection{Data Preparation}
We synthesize haze using 10 scenes from the DTU dataset~\cite{jensen2014large}.
% The haze synthesis follows the 2D haze generation method~\cite{li2018benchmarking} based on Koschmieder's model~\cref{eq:koschmider}.
% The depth used for haze generation is computed using the meshes reconstructed by public available NeuS models~\cite{wang2021neus}.
% We set the atmospheric light and scattering coefficient to a constant value sampled in range $\sigma_s\in[0.2, 0.6]$ and $c_{s}\in[0.5, 0.9]$.\todo{change to Gaussian blob}
The scattering coefficient is modeled using the sum of 4 scaled Gaussian blobs located inside the spatial bounding box with a standard deviation uniformly sampled from 1.0 to 3.0;
the 3-D atmospheric light is sampled from a uniform distribution in the range $[0.7, 0.9]$.
10\% of the images in each synthetic scene are held out as the test set.

\subsection{Comparisons}\label{sec:comparisons}
\paragraph{Baselines.}
We compare {\moniker} with the following baselines:
%
\begin{compactenum}
\item \textbf{NeuS}: train HF-NeuS~\cite{wang2022hfs} on hazy images,
\item \textbf{ImDehaze+NeuS}: train HF-NeuS on dehazed images obtained using the state-of-the-art single-image dehazing method~\cite{guo2022image},
\item \textbf{VidDehaze+NeuS}: train HF-NeuS on dehazed images obtained using the state-of-the-art video dehazing method~\cite{zhang2021learning},
\item \textbf{COLMAP+NeuS}: train HF-NeuS on dehazed images obtained  by estimating the transmission maps using the dense depth map from COLMAP~\cite{schoenberger2016sfm,schoenberger2016mvs}.
\end{compactenum}\label{lst:baseline5}
%
With HF-NeuS as the backbone surface model~\cite{wang2022hfs}, all approaches observe the same surface prior.
While the first baseline neglects haze entirely, baselines 2 to 4 increasingly incorporate more multiview information for haze modeling, with ours being the most 3D-aware and physically accurate, as it models the spatial-variant scattering coefficient in 3D space and optimizes the 3D geometry, surface appearance, and the haze parameters jointly.
For the last baseline, we use the method proposed by~\cite{he2010single} to estimate the global airlight from the object regions (masked by~\cite{yariv2020multiview}) in all images.
Then we use 300 pairs of feature correspondences to estimate the global scattering coefficient, where each pair computes a candidate scattering coefficient as follows
\(\frac{1}{D_{b}\left( \x_{b} \right) - D_{a}\left( \x_{a} \right)}\ln\left( \frac{I_{a}\left( \x_{a} \right) - \bar{c}_{s}}{I_{b}\left( \x_{b} \right) - \bar{c}_{s}} \right)\).
\(\left( I_{a}, D_{a} \right)\) and \(\left( I_{b}, D_{b} \right)\) are RGB images and depth maps in two views, and \(\x_{a}\) and \(\x_{b}\) are the image coordinates of a pair of matched SIFT features.
The final result is obtained after filtering out negative or invalid estimations, which may occur due to specularities and noisy depth estimation.

\noindent\textbf{Qualitative Evaluation.}
We demonstrate some examples of the dehazed results and reconstructed geometry in \cref{fig:dtu_qualitative}.
Despite having a surface prior, naÃ¯vely training HF-NeuS directly from hazy images is equivalent to averaging the scattering-induced geometry-dependent irradiance variance observed across different views and attributing it the surface color.
Consequently, the view synthesis is hazy and blurred.
For two-stage strategies, the rendered results have color distortion of various degrees, as indicated by the PSNR evaluation in \cref{tab:dtu_quantitative}, since it is difficult to accurately estimate the airlight and coefficient when the presented data does not comply with the specific assumptions or fall in the distribution of the training data.
Moreover, our method clearly reconstructs the geometry with more surface details compared to all other baselines that adopt the surface prior formulated in NeuS, since our method can dehaze different views more consistently thanks to the underlying geometry that is optimized jointly.

\noindent\textbf{Quantitative Evaluation.} We measure the image quality using peak signal-to-noise ratio (PSNR), structural similarity (SSIM), and perceptual similarity (LPIPS).
The geometry quality is measured using Chamfer Distances (CD) using the DTU standard protocol.
As shown in \cref{tab:dtu_quantitative},
\moniker~achieves the best results compared to all baselines,
with superior performance in PSNR, a metric sensitive to low-frequency color shift.
This indicates that while other methods struggle to estimate the true air light and scattering coefficient from either statistical or data priors, our method benefits from jointly optimizing these quantities along with the scene appearance and geometry.



\begin{figure}
    \centering
    \begin{subfigure}[b]{0.155\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/ablation/3D/ablation-nodc.png}{}
        \caption{Without $\loss_{\textrm{dcp}}$}
        \label{fig:ablation_dcp_baseline}
    \end{subfigure}
    \begin{subfigure}[b]{0.155\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/ablation/3D/ablation-dc.png}{}
        \caption{With $\loss_{\textrm{dcp}}$}
        \label{fig:ablation_dcp_ours}
    \end{subfigure}
        \begin{subfigure}[b]{0.155\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/ablation/3D/ablation-gt.png}{}
        \caption{Ground Truth}
        \label{fig:ablation_dcp_gt}
    \end{subfigure}
	% \label{fig:ablation_visual}
% \end{figure}

% \begin{figure}
%     \centering
    \begin{subfigure}[b]{0.155\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/ablation/5-1.png}{}
        \caption{Without $\loss_{\textrm{2D}}$}
        \label{fig:ablation_cyle_base}
    \end{subfigure}
    \begin{subfigure}[b]{0.155\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/ablation/5-2.png}{}
        \caption{With $\loss_{\textrm{2D}}$}
        \label{fig:ablation_cyle_ours}
    \end{subfigure}
        \begin{subfigure}[b]{0.155\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/ablation/5-3.png}{}
        \caption{Ground Truth}
        \label{fig:ablation_cyle_gt}
    \end{subfigure}
    \label{fig:ablation_3d}\vspace{-3ex}
    \caption{\textbf{Ablation:} $\loss_{\textrm{dcp}}$ and \(\loss_{\textrm{2D}}\) lead to more accurate clear-view color photometric details.}
    \vspace{-0.5cm}
	\label{fig:ablation_visual}
\end{figure}


\begin{figure}
    \centering
    \begin{subfigure}[b]{0.23\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/ablation/psnr-iter-eps-converted-to.pdf}
    \end{subfigure}
        \begin{subfigure}[b]{0.23\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/ablation/ssim-iter-eps-converted-to.pdf}
    \end{subfigure}
 \caption{\textbf{Ablation on \(\loss_{\textrm{2D}}\).} We compare the validation results during training with and without \(\loss_{\textrm{2D}}\): With \(\loss_{\textrm{2D}}\) the image quality continuously improve.}
 \label{fig:ablation_2D_loss_curve}
\end{figure}


\begin{table}[t!]
\centering\small
\resizebox*{\linewidth}{!}{
\begin{tabular}{ccccc}\toprule
Method & PSNR ($\uparrow$) & SSIM ($\uparrow$) & LPIPS ($\downarrow$) & Chamfer ($\downarrow$)\\\midrule
        %  NeRF & 19.038	& 0.865 & 0.156	& 3.584 \\
         NeuS & 16.722 & 0.879 & 0.087 & 2.635 \\
         COLMAP + NeuS & 16.750 & 0.785 & 0.225 & 5.971 \\
         ImDehaze\cite{guo2022image} + NeuS & 17.887 & 0.899 & \underline{0.078} & \underline{2.298} \\
         VidDehaze\cite{zhang2021learning} + NeuS & \underline{18.324} & \underline{0.901} & 0.087 & 2.349 \\
         \moniker{} & \textbf{25.702} & \textbf{0.920} & \textbf{0.052} & \textbf{2.066}
\\\bottomrule
\end{tabular}
}
\caption{\textbf{Quantitative comparison using synthetic data with heterogeneous haze}. \moniker{} yields better reconstruction both in image quality and geometry accuracy.}
\label{tab:dtu_quantitative}
\vspace{-3ex}
\end{table}

\subsection{Ablation Study}\label{sec:ablation}
We conduct ablation studies for the optimization regularizers on 3 scenes and report their average in \cref{tab:ablation_1}.

As \cref{tab:ablation_1} shows, both \(\loss_{\textrm{2D}}\) and \(\loss_{\textrm{dcp}}\) contribute positively to the image quality and surface reconstruction accuracy.
The \(\loss_{\textrm{dcp}}\) has a prominent effect in reducing global color shift as indicated by the PSNR value.
Similarly, from the visual comparison in \cref{fig:ablation_dcp_baseline,fig:ablation_dcp_ours,fig:ablation_dcp_gt}, we can observe that by adopting \(\loss_{\textrm{dcp}}\), the residual haze can be suppressed effectively.
Moreover, as shown in~\cref{fig:ablation_cyle_base,sub@fig:ablation_cyle_ours,sub@fig:ablation_cyle_gt}, the results optimized with \(\loss_{\textrm{2D}}\) show more accurate structure (see orange bounding boxes).
In addition, we plot the evolution of validation PSNR and SSIM in \cref{fig:ablation_2D_loss_curve}.
%One can observe that
\(\loss_{\textrm{2D}}\) improves the convergence behavior and yields better validation results.

\begin{table}[t!]
\centering
\resizebox*{\linewidth}{!}{
\begin{tabular}{ccccc}\toprule
Method & PSNR ($\uparrow$) & SSIM ($\uparrow$) & LPIPS ($\downarrow$) & Chamfer ($\downarrow$)\\\midrule
w/o $\loss_{\textrm{2D}} + \loss_{\textrm{dcp}}$ & 18.21 & 0.88 & 0.09 & 2.47 \\
w $\loss_{\textrm{2D}}$ & 18.53 & 0.89 & 0.09 & 2.44  \\
w $\loss_{\textrm{dcp}}$ & 24.02 & 0.90 & 0.06 & 2.44 \\
\moniker{} & \textbf{25.23} & \textbf{0.91} & \textbf{0.05} & \textbf{2.41} \\
\bottomrule
\end{tabular}
}
\caption{\textbf{Ablations on regularization}. Each of the proposed two regularizations can individually improve the image and geometry reconstruction, and the best quality is achieved with both. The results are averaged from 10 test scenes from the DTU dataset.}
\vspace{-0.2cm}
\label{tab:ablation_1}
\end{table}

\begin{figure*}[t!]
\setlength{\tabcolsep}{0pt}
\renewcommand{\arraystretch}{0.75}\footnotesize
\centering\begin{tabular}{*{6}{>{\centering\arraybackslash}M{0.165\textwidth}}}
 NeuS & COLMAP + NeuS& ImDehaze + NeuS & VidDehaze + NeuS & \moniker{} & Ground Truth \\
\includegraphics[width=0.98\linewidth, clip, trim={2cm 2cm 0cm 5cm}]{images/qualitative/real/bear/neus-APC_0287.jpg} &
\includegraphics[width=0.98\linewidth, clip, trim={2cm 2cm 0cm 5cm}]{images/qualitative/real/bear/colmap-APC_0287.jpg} &
\includegraphics[width=0.98\linewidth, clip, trim={2cm 2cm 0cm 5cm}]{images/qualitative/real/bear/dehaze-APC_0287.jpg} &
\includegraphics[width=0.98\linewidth, clip, trim={2cm 2cm 0cm 5cm}]{images/qualitative/real/bear/video-APC_0287.jpg} &
\includegraphics[width=0.98\linewidth, clip, trim={0.5cm 0.5cm 0cm 1.25cm}]{images/qualitative/real/bear/00050000_0_32_res8_clear.png} &
\includegraphics[width=0.98\linewidth, clip, trim={2cm 2cm 0cm 5cm}]{images/qualitative/real/bear/gt-APC_0287.jpg}
\\
\includegraphics[width=0.98\linewidth, clip, trim={0cm 1cm 0.5cm 0cm}]{images/qualitative/real/elephant/neus-APC0202.jpg} &
\includegraphics[width=0.98\linewidth, clip, trim={0cm 1cm 0.5cm 0cm}]{images/qualitative/real/elephant/colmap-APC0202.jpg} &
\includegraphics[width=0.98\linewidth, clip, trim={0cm 1cm 0.5cm 0cm}]{images/qualitative/real/elephant/dehaze-APC0202.jpg} &
\includegraphics[width=0.98\linewidth, clip, trim={0cm 1cm 0.5cm 0cm}]{images/qualitative/real/elephant/video-APC0202.jpg} &
\includegraphics[width=0.98\linewidth, clip, trim={0cm 1cm 0.5cm 0cm}]{images/qualitative/real/elephant/ours-58.png} &
\includegraphics[width=0.98\linewidth, clip, trim={0cm 1cm 0.5cm 0cm}]{images/qualitative/real/elephant/gt-APC0202.jpg}
\\
\includegraphics[width=0.98\linewidth, clip, trim={0cm 2.5cm 0cm 0cm}]{images/qualitative/real/lion/neus-0006.jpg} &
\includegraphics[width=0.98\linewidth, clip, trim={0cm 2.5cm 0cm 0cm}]{images/qualitative/real/lion/colmap-0006.jpg} &
\includegraphics[width=0.98\linewidth, clip, trim={0cm 2.5cm 0cm 0cm}]{images/qualitative/real/lion/dehaze-0006.jpg} &
\includegraphics[width=0.98\linewidth, clip, trim={0cm 2.5cm 0cm 0cm}]{images/qualitative/real/lion/video-0006.jpg} &
\includegraphics[width=0.98\linewidth, clip, trim={0cm 2.5cm 0cm 0cm}]{images/qualitative/real/lion/05.png} &
\includegraphics[width=0.98\linewidth, clip, trim={0cm 2.5cm 0cm 0cm}]{images/qualitative/real/lion/gt-0006.jpg}
\\
\end{tabular}
\caption{\textbf{Qualitative comparison on captured data}. Our method recovers the haze-free scenes with more image details and colors closer to the ground truth.}
\vspace{-3ex}
\label{fig:real_qualitative}
\end{figure*}

\begin{table}[t!]
\resizebox*{\linewidth}{!}{
\begin{tabular}{cccc}\toprule
Method & PSNR ($\uparrow$) & SSIM ($\uparrow$) & LPIPS ($\downarrow$) \\\midrule
% NeRF & 11.98&0.48 &0.37 \\
NeuS & 12.60& 0.48& 0.38\\
COLMAP + NeuS &9.27 & 0.38&0.47 \\
ImDehaze + NeuS  & 13.35 & 0.49& 0.36\\
VidDehaze + NeuS  &\underline{14.56} & \underline{0.50}& \underline{0.34} \\
\moniker{} & \textbf{17.47} & \textbf{0.68} & \textbf{0.16}\\\bottomrule
\end{tabular}
}
\caption{\textbf{Quantitative evaluation on experimentally captured data} averaged over 3 scenes. Our method outperforms other methods by a large margin.}
\label{tab:real_quantitative}
\vspace{-0.5cm}
\end{table}
