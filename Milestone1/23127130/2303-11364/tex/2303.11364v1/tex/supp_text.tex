\input{tex/supp_tab_dtu.tex}



\section{Data generation}
\subsection{Synthetic Data}
An example of our synthesized results are shown in \cref{fig:synthetic_data}.
The scattering coefficient is modeled using the sum of 4 scaled Gaussian blobs located inside the spatial bounding box with a standard deviation uniformly sampled from 1.0 to 3.0;
the 3-D atmospheric light is sampled from a uniform distribution in the range $[0.7, 0.9]$.


\begin{figure}[htbp]
    \centering
\includegraphics[width=0.49\linewidth]{images/fig-3-1.png}%
\includegraphics[width=0.49\linewidth]{images/fig-3-2.png}
    \caption{\textbf{An example of the synthetic data.} Right: original input image. Left: synthetic hazy input with heterogeneous scattering.}
    \label{fig:synthetic_data}
\end{figure}

\subsection{Real Data Collection}
We use two professional haze machines to generate a dense vapor. These haze generators adopt cast or platen-type aluminum heat exchangers, which make evaporation of the water-based haze liquid. We capture our scenes in a hermetic chamber.
First, we captured clear reference images from different view directions.
Then, we employed 2 minutes for both haze machines and waited for another 2 minutes until the haze was temporally stable.
We then captured hazy images from different viewpoints.
An iPhone 12 was used as our camera.
The camera's settings including exposure, iso, and focal length were the same for all captures.

After the capturing, we merge hazy images and clear images under the same scene and run COLMAP~\cite{schoenberger2016sfm,schoenberger2016mvs} to register camera positions.
% Then, we adopt hazy images to train our network and clear images to test our network.

\section{Evaluation}

\paragraph{Quantitative Evaluation on Synthetic Dataset}
We present the complete quantitative results on DTU dataset~\cite{jensen2014large} in~\cref{tab:dtu_quantitative}. One can see that the proposed \moniker{} outperforms other baselines in most of the scenes in terms of image quality and geometric reconstruction.

% \paragraph{Dehazing under Different Haze Densities}
% We present the comparison of our method in different haze densities and atmospheric light intensities with other baselines in \cref{tab:haze_density}. Our method is better than other baselines in different haze densities and atmospheric light intensities.
% Also, one can observe that the performance of dehazing degrades when the haze density increases (i.e., $\beta$). On the other hand, when the atmospheric light intensity increases (i.e., $A$), the performance of dehazing becomes better.

\begin{table}
\center\small
\begin{tabular}{ccccc}\toprule
Surface Prior & PSNR$\uparrow$ & SSIM$\uparrow$ & LPIPS$\downarrow$ & Chamfer$\downarrow$\\\midrule
None & 21.331 & 0.901 & 0.071 & 4.013 \\
via NeuS & \textbf{26.039} & \textbf{0.921} & \textbf{0.056} & \textbf{2.863}
\\\bottomrule
\end{tabular}
\caption{The effect of NeuS surface prior evaluated on 5 test scenes.}
\label{tab:ablation_backbone}
\end{table}

\paragraph{Additional Ablation}
Here, we present an additional ablation to demonstrate the effect of using the NeuS surface prior.
To this end, we replace the NeuS backbone with a NeRF~\cite{mildenhall2020nerf} backbone and compare the image quality and geometry reconstruction performance.
As shown in~\cref{tab:ablation_backbone}, by adopting a surface prior, implemented via the surface-based parameterization of the volume density~NeuS, the model can converge to a better solution in terms of haze-surface disambiguation leading to significantly better image and geometry reconstruction quality.

\section{Implementation Detail}
\paragraph{Network architecture}
We adopt a similar network architecture as HF-NeuS~\cite{wang2022hfs}. It contains two MLPs to encode surface SDF and surface color respectively. The SDF MLP consists of 8 hidden layers with hidden size of 256. A skip connection is applied from the input to the fourth hidden layer.
The color MLP contains 4 hidden layers with size of 256. It takes the spatial location \textbf{p}, the view direction \textbf{d}, the normal vector of SDF, and a 256-dimensional feature vector from the SDF MLP.
Positional encoding is applied to spatial location and view direction with 6 and 4 frequencies, respectively.

For the spatially variant scattering coefficient, we adopt band-limited coordinate networks~\cite{lindell2022bacon} using 3 hidden layers, where each layer has 32 channels and the frequency parameter set to 10.

\paragraph{Training and inference details}
We train the proposed \moniker{} by using the Adam optimizer~\cite{kingma2014adam}. We set the learning rate linearly from 0 to $5\times10^{-4}$ by warmed up strategy in the first 5k iterations. Then, we reduce the learning rate by the cosine decay schedule to the minimum learning rate $2.5\times10^{-5}$. We train our model for 24 hours (for the ‘w/ mask’ setting) and 26 hours (for the ‘w/o mask’ setting) on a single Nvidia Tesla V100 GPU with batch size 512, respectively. For the first 300k iterations, we set the scattering coefficients and atmospheric light as zero and train the model based on the vanilla HF-NeuS. In this stage, we disable the Koschmieder Consistency and dark channel losses. After 300k iterations, the scattering coefficients and atmospheric light are introduced and optimized with the Koschmieder Consistency and dark channel losses. We train our network for 800k and 50k iterations for synthetic and captured data, respectively. The scale factors $\lambda$, $\alpha$, and $\beta$ in the loss function are set to 0.1, 5000, and 0.01 for synthetic data and 0.1, 1.0, and 0.01 for the captured dataset, respectively. The scale factor of mask loss is set to 0.1. For the inference stage, it takes 200 seconds to render an image in resolution of $1600\times1200$.



\section{Deriving \moniker{}}

\subsection{Radiative Transfer Equation}
Radiative transfer equation (RTE)~\cite{chandrasekhar2013radiative,van1999multiple} describes the behaviour of light in a medium that absorbs, scatters and emits radiation.
Assuming, a ray \(\r\left( t \right) = \mathbf{o} + t\d\) hits a surface point at \(\r\left( t_{0} \right)\), the incident radiance at the near image plane \(t_{n}\) can be divided into three parts~\cite{pharr2016physically}:

\begin{align}\begin{split}
C(\r, \d)=&
\underbrace{\int_{t_{n}}^{t_{0}}\epsilon\left(\r\left( t\right),\d\right)T_{\sigma_{t}}\left( t\right)dt}_{\textrm{emission}}\\
&+\underbrace{\int_{t_{n}}^{t_{0}}c_{\textrm{s}}\left( \r\left( t \right), \d \right)\sigma_{s}\left(\r\left( t \right)\right)T_{\sigma_{t}}\left( t \right)dt}_{\textrm{in-scattering}}\\
&+\underbrace{C_e\left(\r\left( t_{0} \right),\d\right)T_{\sigma_{t}}\left( t_{0}\right)}_{\textrm{surface reflection}},\label{eq:RTE}
\end{split}
\end{align}
where \(\epsilon\) is the emission, \(C_{e}\) is the outgoing radiance at the surface intersection, \(c_{\textrm{s}}\left(\r\left( t \right), \d \right)\) is the in-scattered light and \(\sigma_{s}\) is the scattering coefficient.
In particular the transmittance here is computed from the attenuation coefficient \(\sigma_{t}\), \ie,
\(T_{\sigma_{t}}\left( t\right)=\exp\left( -\int_{t_{n}}^{t}\sigma_{t}(t')dt' \right)\),
where \(\sigma_{t}=\sigma_{a} + \sigma_{s}\) including the absorption and out-scattering effect.

Based on this equation, we then connect it to the neural radiance field (NeRF) and hazy image formation model.

\subsection{From RTE to NeRF}
\label{sec:4.2}
For the volume rendering equation adopted in NeRF, there are two assumptions: (i) no scattering and (ii) only absorption and emission are considered. The volume rendering equation can be derived by the RTE equation by dropping the in-scattering term and combining the surface reflection term into the emission term. It can be presented as:
\cite{max1995optical,wang2021neus,yariv2021volume}
% \yifan{I think it would be better if you directly replace \(\sigma_{t}\) with \(\sigma_{a}\) here, since you mentioned we drop scattering.}
\begin{align}\begin{split}
C(\r, \d)=&
\underbrace{\int_{t_{n}}^{t_{0}}\epsilon\left(\r\left( t\right),\d\right)T_{\sigma_{a}}\left( t\right)dt}_{\textrm{emission}}
\\&+\underbrace{C_e\left(\r\left( t_{0} \right),\d\right)T_{\sigma_{a}}\left( t_{0}\right)}_{\textrm{surface reflection}}.
\label{eq:RTE_haze_formation}
\end{split}
\end{align}

Since NeRF treats each point as an emission point, the radiance of the surface can be considered as emission at $t_0$. Thus, the surface reflection in \cref{eq:RTE_haze_formation} becomes
\begin{equation}
\resizebox{0.9\linewidth}{!}{
\(
    C_e\left(\r\left( t_{0} \right),\d\right)T_{\sigma_{a}}\left( t_{0}\right) = \int_{t_n}^{t_0}\epsilon_{o}\left(\r\left( t_{0} \right),\d\right)\delta(t- t_{0})T_{\sigma_{a}}\left( t\right)dt.
    \)

}
\label{eq:replace_surface}\end{equation}
Therefore \cref{eq:RTE_haze_formation} can be written as:
\begin{align}
\begin{split}
C(\r, \d)&=
% \int_{t_{n}}^{t_{0}}\left(\epsilon\left(\r\left( t\right),\d\right)+\epsilon_{o}\left(\r\left( t_{0} \right),\d\right)\right)\delta(t -t_{0})T_{\sigma_{a}}\left( t\right)dt\\
\int_{t_{n}}^{t_{0}}\epsilon_{\textrm{combined}}\left(\r\left( t\right),\d\right)T_{\sigma_{a}}\left( t\right)dt,
\label{eq:NeRF_RTE}
\end{split}\end{align}
where \(\epsilon_{\textrm{combined}}=\epsilon\left(\r\left( t\right),\d\right)+\epsilon_{o}\left(\r\left( t_{0} \right),\d\right)\delta(t-t_{0})\).

By further setting $\epsilon_{\textrm{combined}}\left(\r\left( t\right),\d\right)=c(\r(t), \mathbf{d})\sigma(\r(t))$ and \(\sigma_{a} = \sigma\), we can see \cref{eq:NeRF_RTE} is the same as famous NeRF rendering equation below:

\begin{gather}
\begin{split}
{C}(\r, \d)=\int_{t_n}^{t_f}c(\r(t), \mathbf{d})\sigma(\r(t))T(t) \ dt.
\label{eq:NeRF}
\end{split}
\end{gather}

% We can see \cref{eq:NeRF} can be derived from \cref{eq:NeRF_RTE} by setting $\epsilon_{\textrm{combined}}\left(\r\left( t\right),\d\right)=c(\r(t), \mathbf{d})\sigma(\r(t))$ and denoting \(\sigma_{a} = \sigma\).
In practice, absorption coefficient $\sigma_{a}(\r(t))$ describes the probability of a photon being absorbed at position $\r\left( t \right)$, while $\sigma(\r(t))$ (called volume density in NeRF) illustrates the probability of a ray terminating at location $\r\left( t \right)$.
That is, $\sigma_{a}$ is the same meaning as $\sigma$ physically since NeRF only considers the absorption.
Moreover, generally, we can assume that when the ray hits the object, the attenuation term (accumulative transmittance) may become zero. That is, $T(t)\cong0$ when $t>t_{0}$. Thus, the integral from $t_n$ to $t_f$ is approximately equal to that from $t_n$ to $t_0$.

\subsection{From RTE to Koschmieder Model}
For the conventional haze formation model, there are three assumptions\cite{middleton1957vision,narasimhan2004models}: (i) no emission, (ii) only consider single scattering, and (iii) only consider scattering since absorption in atmospheric particles is relatively small. Therefore, \cref{eq:RTE} simplifies to
\begin{align}
C(\r, \d)=&
\underbrace{\int_{t_{n}}^{t_{0}}c_{\textrm{s}}\left( \r\left( t \right), \d \right)\sigma_{s}\left(\r\left( t \right)\right)T_{\sigma_{s}}\left( t \right)dt}_{\textrm{in-scattering}}\nonumber\\
&+\underbrace{C_e\left(\r\left( t_{0} \right),\d\right)T_{\sigma_{s}}\left( t_{0}\right)}_{\textrm{surface reflection}}.\label{eq:RTE_Haze}
\end{align}

Assuming the scattering coefficient and atmospheric light are isotropic and homogeneous, \ie, \(\sigma_{s}\left( \r\left( t \right) \right) \equiv \bar{\sigma}_{s}\) and \(c_{s}\left( \r\left( t \right), \d\right)\equiv\bar{c}_{s}\), setting $t_{n}=0$ and \(C_e\left(\r\left( t_{0} \right),\d\right)=C_{\textrm{clear}}\), we can rewrite \cref{eq:RTE_Haze} to the Koschmieder model~\cite{israel1959koschmieders}, namely
\begin{equation}
 \resizebox{1\hsize}{!}{
 $
\begin{split}
C(\r, \d)&={\bar{c}_{\textrm{s}}\int_{0}^{t_0}\bar{\sigma}_{s}\underbrace{e^{-\int_{0}^{t}\bar{\sigma}_{s}dt^{'}}}_{T_{\bar{\sigma}_{s}}\left( t \right)}dt}
+
{C_e\left(\r\left( t_{0} \right),\d\right)\underbrace{e^{-\int_{0}^{t}\bar{\sigma}_{s}dt^{'}}}_{T_{\bar{\sigma}_{s}}\left( t \right)}\left( t_{0}\right)}\\
&=\bar{c}_{s}(1-\exp(-\bar{\sigma}_{s} t_{0})) + C_{\textrm{clear}}\exp(-\bar{\sigma}_{s} t_{0}).
\end{split}\label{eq:koschmieder}$}
\end{equation}

\subsection{3D Haze Formation in \moniker{}}
In this part, we bring \cref{eq:RTE_Haze} to a similar form as NeRF so that we can learn the geometry and color through samples in the 3D space.

First, we bring back volume density $\sigma$, \ie, replace \(\sigma_{s}\) with \(\sigma_{t} =\sigma_{s} + \sigma\):
\begin{equation}
\begin{split}
C(\r, \d)=
\int_{t_{n}}^{t_{0}}c_{\textrm{s}}\left( \r\left( t \right), \d \right)\sigma_{s}\left(\r\left( t \right)\right)T_{\sigma_{t}}\left( t \right)dt\\
+
C_e\left(\r\left( t_{0} \right),\d\right)T_{\sigma_{t}}\left( t_{0}\right),
\end{split}
\end{equation}
which corresponds to Eq. (3) in the main paper.
Using the same trick in \cref{eq:replace_surface}, we can combine the surface reflection term into the integral and obtain the rendering equation used in \moniker{} (Eq. (4) in the main paper):
\begin{align}
C(\r, \d)=&
\int_{t_{n}}^{t_{0}}c_{\textrm{s}}\left( \r\left( t \right), \d \right)\sigma_{s}\left(\r\left( t \right)\right)T_{\sigma_{t}}\left( t \right)dt\nonumber\\
&+
\int_{t_n}^{t_0}\underbrace{\epsilon_{\textrm{surface}}\left(\r\left( t_{0} \right),\d\right)}_{\epsilon_{o}\left(\r\left( t_{0} \right),\d\right)\delta(t-t_{0})}T_{\sigma_{t}}\left( t\right)dt\nonumber\\
=&{\int_{t_{n}}^{t_{0}}c_{\textrm{s}}\left( \r\left( t \right), \d \right)\sigma_{s}\left(\r\left( t \right)\right)T_{\sigma_{t}}\left( t \right)dt}\nonumber\\
&+
{\int_{t_{n}}^{t_{0}}\underbrace{c\left( \r\left( t \right), \d \right)\sigma\left(\r\left( t \right)\right)}_{\epsilon_{\textrm{surface}}\left(\r\left( t_{0} \right),\d\right)}T_{\sigma_{t}}\left( t \right)dt}.
\end{align}
The first term (denoted as $C_{\text{haze}}$) captures the radiance caused by haze scattering. The second term (denoted as $C_{\textrm{surface}}$) is equivalent to NeRF for a scene with only solid surfaces.
