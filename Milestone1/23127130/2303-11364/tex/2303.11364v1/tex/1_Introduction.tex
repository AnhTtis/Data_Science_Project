\section{Introduction}
Neural radiance fields (NeRFs)~\cite{mildenhall2020nerf} have emerged as a powerful approach to solving 3D computer vision problems, such as novel view synthesis and 3D reconstruction~\cite{tewari2022advances}. Existing NeRF\footnote{We refer to neural radiance fields and neural surfaces~\cite{wang2021neus} collectively as ``NeRF'' in this paper.} approaches are successful in many scenarios, but they fail to accurately reconstruct the geometry and appearance of a 3D scene in adverse weather conditions such as haze (see \cref{fig:real_qualitative}). This poses a critical limiting factor for many real-life applications, including autonomous driving among others.

The problem of applying NeRF to hazy input images is the ambiguity between light-reflecting solid surfaces and light-scattering atmospheric particles in free space -- both are interchangeably modeled as a light-emitting volume by NeRF and cannot be disambiguated.
Most state-of-the-art dehazing methods adopt feedforward neural networks~\cite{singh2019comprehensive,ancuti2019ntire}, but applying these to the input views as a preprocessing step to standard NeRFs leads to poor reconstruction results, in part because these techniques tend to overfit to the training data and generalize poorly to real-world data~\cite{Qu_2019_CVPR,shao2020domain}.

\begin{figure}[t!]
\centering \includegraphics[width=0.8\linewidth]{images/teasor/teaser.png}
\makeatother
    \caption{Given a set of posed hazy images, our method estimates the haze-free scene using a neural radiance field that includes physically based terms for scattering. Here, we show results of an experimentally captured scene.}
	\vspace{-0.5cm}\label{fig:teaser_figure}
\end{figure}
To address this limitation, we develop a differentiable physically based 3D haze model that seamlessly integrates into the volume rendering framework used by NeRF.
In the absence of scattering, our model is equivalent to NeRF. %and, for single image input, it adequately models the image formation used by existing single image dehazing methods.
For the inverse problem of estimating the scene parameters from multiple posed input views, our 3D haze model is used in conjunction with several regularization strategies that disentangle solid object surfaces from scattering volumetric particles.
Our proposed framework jointly learns the 3D shape and haze components of a scene and allows for significantly improved and multi-view-consistent novel view synthesis as well as more accurate 3D shape reconstruction compared to previous work.
Our approach does not require large collections of paired hazy-clear images and it circumvents the sim2real gap of data-driven dehazing methods by building an inductive bias based on the physics of scattering into the network architecture.

Specifically, our contributions include:
\begin{compactitem}
\item extending the volume rendering equation of NeRF by a physically based 3D haze image formation model to accurately model the in-scattering phenomenon prevalent in hazy conditions;
\item introducing multiple physically inspired inductive biases as well as optimization regularizers to effectively disambiguate the surface appearance thus achieving accurate clear-view appearance and geometry reconstruction using only hazy image as inputs.
\end{compactitem}
We demonstrate state-of-the-art results using simulation and experimental data for 3D multi-view construction and novel view synthesis under hazy condition.
Code and data will be made available \footnote{\url{https://www.computationalimaging.org/publications/dehazenerf}} for research purposes.










