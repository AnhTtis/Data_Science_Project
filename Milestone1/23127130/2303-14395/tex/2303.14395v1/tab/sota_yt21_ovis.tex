\begin{table*}[t]
\begin{center}
\setlength{\tabcolsep}{0.5mm}{
      \linespread{2}
      \begin{tabular}
      % [t]{cclccccccccc}
      {p{0.11\textwidth}<{\centering}p{0.15\textwidth}|
      p{0.055\textwidth}<{\centering}p{0.05\textwidth}<{\centering}p{0.05\textwidth}<{\centering}
      p{0.05\textwidth}<{\centering}p{0.06\textwidth}<{\centering}|p{0.055\textwidth}<{\centering}p{0.05\textwidth}<{\centering}p{0.05\textwidth}<{\centering}p{0.05\textwidth}<{\centering}p{0.06\textwidth}<{\centering}|p{0.06\textwidth}<{\centering}p{0.06\textwidth}<{\centering}}
         \Xhline{0.8pt}
         \multirow{2}{*}{Type} & \multirow{2}{*}{Methods} & \multicolumn{5}{c|}{YouTube-VIS 2021} & \multicolumn{5}{c|}{OVIS} &  \multirow{2}{*}{FPS}  & \multirow{2}{*}{Params} \\
          & &AP &AP$_{50}$ &AP$_{75}$ &AR$_{1}$ &AR$_{10}$ &AP&AP$_{50}$&AP$_{75}$&AR$_{1}$&AR$_{10}$ &  & \\
         \Xhline{0.6pt}
         \multirow{6}{*}{\shortstack{Per-frame \\ (360p)}}
         &MaskTrack {\small  \cite{yang2019video}}     & 28.6 & 48.9 & 29.6 &- &- & 10.8 & 25.3 & 8.5 & 7.9 & 14.9  & 20.0 & 58.1M\\
         % &SipMask \cite{cao2020sipmask}              & 29.6 &48.9 & 31.1 & 28.9 & 36.1 & 10.2 & 24.7 & 7.8 & 7.9 & 15.8  & 30.0 & 33.2M\\
         &STMask{\small \cite{Li_2021_CVPR}}                  & 31.1 & 50.4 & 33.5 & 26.9 & 35.6 & 15.4 & 33.9 & 12.5 & 8.9 & 21.4 & 28.0 & -\\      
         % &&QueryInst\cite{QueryInst}                  &R50   & 2   & 34.6 & 55.8 & 36.5  &35.4 &42.4 \\
         &CrossVIS {\small \cite{yang2021crossover}}          & 33.3 & 53.8 & 37.0 & 30.1 & 37.6 & 14.9 & 32.7 & 12.1 & 10.3 & 19.8 & 39.8 & 37.5M\\ 
         % & Mask2Former-VIS                           & 46.4 & 68.0 & 50.0 & – & – \\
         & InstFormer{\small \cite{koner2022instanceformer}}  & 40.8  & 62.4 & 43.7 & 36.1 & 48.1 & 20.0 & 40.7 & 18.1 & 12.0 & 27.1 & - & 44.3M\\
         & IDOL {\small \cite{IDOL}}                          & 43.9 & \textbf{68.0} & \textbf{49.6} & 38.0 & 50.9 & 24.3 & 45.1 & 23.3 & 14.1 & \underline{33.2} & 30.6  & 43.1M\\
         & MinVIS {\small \cite{huang2022minvis}}             & 44.2 & 66.0 & 48.1 &\underline{39.2}  &\underline{51.7}  & \underline{26.3} & \underline{47.9} & \underline{25.1} & \textbf{14.6} & {30.0} & 52.4 & 44.0M \\
         % & MDQE$^\dag$ (ours)                        & 44.9 & 67.8 & 48.1 & 37.8 & 49.4 \\
         
         \Xhline{0.5pt}
         \multirow{6}{*}{\shortstack{Per-clip \\ (360p)}} 
         % &STEm-Seg \cite{Athar_Mahadevan20stemseg}  & - &- & - &- & - & 13.8 & 32.1 & 11.9 & 9.1 & 20.0 & 7 & 50.5M\\
         % &Propose-Reduce \cite{lin2021video}        & 40.4 & 63.0 & 43.8 & 41.1 & 49.7 & 41.7 &- & 54.9 &- & - & - & -\\ 
         &VisTR$^*$  {\small \cite{wang2020vistr}}          & 31.8 & 51.7 & 34.5 & 29.7 & 36.9 & 10.2 & 25.7 & 7.7 & 7.0 & 17.4 & 30.0 & 57.2M \\
         % &EfficentVIS \cite{wu2022trackletquery}    & & & & & & 34.0 & 57.5 & 37.3 & 33.8 & 42.5 \\
         &IFC$^*$  {\small \cite{hwang2021video}}           & 36.6 & 57.9 & 39.3 &- &- & 13.1 & 27.8 & 11.6 & 9.4 & 23.9 & 46.5 & 39.3M\\
         % &SeqFromer\cite{seqformer}               & 47.4 & 69.8 & 51.8 & 45.5 & 54.8 & 40.5 & 62.4 & 43.7  & 36.1  & 48.1\\
         & TeViT {\small \cite{yang2022TempEffi}}            & 37.9 & 61.2 & 42.1 & 35.1 & 44.6 & 17.4 & 34.9 & 15.0 & 11.2 & 21.8 & 68.9 & 161.8M\\
         & SeqFromer$^*$ {\small \cite{seqformer}}           & 40.5 & 62.4 & 43.7 & 36.1 & 48.1 & 15.1 & 31.9 & 13.8 & 10.4 & 27.1 & 72.3 &  49.3M\\
         & VITA {\small \cite{heo2022vita}}                   & \textbf{45.7} & \underline{67.4} & \underline{49.5} & \textbf{40.9} & \textbf{53.6} & 19.6 & 41.2 & 17.4 & 11.7 & 26.0 & 33.7 & 57.2M\\
         &MDQE (our)                               & \underline{44.5} & {67.1} & {48.7} & 37.9 & 49.8 & \textbf{29.2} & \textbf{55.2} & \textbf{27.1} & \underline{14.5} & \textbf{34.2} & 37.8 & 51.4M\\
         % \textbf{30.4} & \textbf{54.5} & \textbf{30.3} & \textbf{14.9} & \textbf{35.7} & 37.8 & 51.4M\\
         \Xhline{0.6pt}
         \multirow{2}{*}{720p} 
         & IDOL \cite{IDOL}                         & - & - & - & - & - & 30.2 & 51.3 & 30.0 & 15.0 & 37.5 & - & 43.1M\\
         & MDQE (ours)                              & - & - & - & - & - & \textbf{33.0} & \textbf{57.4} & \textbf{32.2} & \textbf{15.4} & \textbf{38.4} & 13.5 & 51.4M \\
        \Xhline{0.8pt}

      \end{tabular}
}
\end{center}
\vspace{-5mm}
\caption{ Quantitative performance comparison of VIS methods with ResNet50 backbone on benchmark YouTube-VIS 2021 and OVIS datasets. 
Note that MinVIS and VITA adopt stronger masked-attention decoder layers proposed in Mask2Former \cite{cheng2021mask2former}. FPS is computed on YouTube-VIS 2021 valid set, and symbol "-" means the results are not available or applicable. 
% On OVIS, IDOL with input videos of 720p needs more than 48G GPU RAM to inference, which is beyond our computational resources. 
Best in \textbf{bold}, second with \underline{underline}.
% We also report the performance of MDQE using a single overlapping frame $T_o=1$ between clips, called near-online inference.
}\label{tab:sota_yt21_ovis}
\vspace{-3mm}
\end{table*}
