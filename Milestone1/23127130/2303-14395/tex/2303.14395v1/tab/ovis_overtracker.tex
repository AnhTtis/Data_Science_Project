\begin{table*}[t]
\begin{center}
\setlength{\tabcolsep}{0.5mm}{
      \linespread{2}
      \begin{tabular}
      % [t]{cclccccccccc}
      {p{0.09\textwidth}<{\centering}p{0.14\textwidth}|
      p{0.05\textwidth}<{\centering}p{0.05\textwidth}<{\centering}p{0.05\textwidth}<{\centering}
      p{0.05\textwidth}<{\centering}p{0.055\textwidth}<{\centering}|p{0.05\textwidth}<{\centering}p{0.05\textwidth}<{\centering}p{0.05\textwidth}<{\centering}p{0.05\textwidth}<{\centering}p{0.055\textwidth}<{\centering}|p{0.05\textwidth}<{\centering}p{0.05\textwidth}<{\centering}p{0.06\textwidth}<{\centering}}
         \Xhline{1pt}
         \multirow{2}{*}{Type} & \multirow{2}{*}{Method} & \multicolumn{5}{c|}{YouTube-VIS 2021} & \multicolumn{5}{c|}{OVIS} &  \multirow{2}{*}{FPS} &  \multirow{2}{*}{Times} & \multirow{2}{*}{Params} \\
          & &AP &AP$_{50}$ &AP$_{75}$ &AR$_{1}$ &AR$_{10}$ &AP&AP$_{50}$&AP$_{75}$&AR$_{1}$&AR$_{10}$ &  & \\
         \Xhline{1pt}
         \multirow{7}{*}{\shortstack{Per-frame \\ (360p)}}
         &MaskTrack \cite{yang2019video}             & 28.6 & 48.9 & 29.6 &- &- & 10.8 & 25.3 & 8.5 & 7.9 & 14.9  & 20.0 & 1 & 58.1M\\
         &SipMask \cite{cao2020sipmask}              & 29.6 &48.9 & 31.1 & 28.9 & 36.1 & 10.2 & 24.7 & 7.8 & 7.9 & 15.8  & 30.0 & 1 & 33.2M\\
         &STMask\cite{Li_2021_CVPR}                  & 31.1 & 50.4 & 33.5 & 26.9 & 35.6 & 15.4 & 33.9 & 12.5 & 8.9 & 21.4 & 28.0 & 1 & -\\      
         % &&QueryInst\cite{QueryInst}                  &R50   & 2   & 34.6 & 55.8 & 36.5  &35.4 &42.4 \\
         &CrossVIS \cite{yang2021crossover}          & 33.3 & 53.8 & 37.0 & 30.1 & 37.6 & 14.9 & 32.7 & 12.1 & 10.3 & 19.8 & 39.8 & 1 & 37.5M\\ 
         % & Mask2Former-VIS                           & 46.4 & 68.0 & 50.0 & – & – \\
         & InstFormer\cite{koner2022instanceformer}  & 40.8  & 62.4 & 43.7 & 36.1 & 48.1 & 20.0 & 40.7 & 18.1 & 12.0 & 27.1 & - & 1 & 44.3M\\
         & IDOL \cite{IDOL}                          & 43.9 & 68.0 & 49.6 & 38.0 & 50.9 & & & & & & 30.6  & 1 & 43.1M\\
         & MinVIS \cite{huang2022minvis}             & 44.2 &66.0 &48.1 &\underline{39.2}  &\underline{51.7}  & 26.3 & 47.9 & 25.1 & 14.6 & 30.0 & & 1 & 44.0M \\
         
         \Xhline{0.5pt}
         \multirow{8}{*}{\shortstack{Per-clip \\ (360p)}} 
         &STEm-Seg \cite{Athar_Mahadevan20stemseg}  & - &- & - &- & - & 13.8 & 32.1 & 11.9 & 9.1 & 20.0 & 7 & - & 50.5M\\
         % &Propose-Reduce \cite{lin2021video}        & 40.4 & 63.0 & 43.8 & 41.1 & 49.7 & 41.7 &- & 54.9 &- & - & - & -\\ 
         &VisTR$^*$  \cite{wang2020vistr}          & 31.8 & 51.7 & 34.5 & 29.7 & 36.9 & 10.2 & 25.7 & 7.7 & 7.0 & 17.4 & 30.0 & 1 & 57.2M \\
         % &EfficentVIS \cite{wu2022trackletquery}    & & & & & & 34.0 & 57.5 & 37.3 & 33.8 & 42.5 \\
         &IFC$^*$  \cite{hwang2021video}           & 36.6 & 57.9 & 39.3 &- &- & 13.1 & 27.8 & 11.6 & 9.4 & 23.9 & 46.5 & $r_0$ & 39.3M\\
         % &SeqFromer\cite{seqformer}               & 47.4 & 69.8 & 51.8 & 45.5 & 54.8 & 40.5 & 62.4 & 43.7  & 36.1  & 48.1\\
         & TeViT$^{*\dag}$ \cite{yang2022TempEffi}  & 37.9 & 61.2 & 42.1 & 35.1 & 44.6 & 17.4 & 34.9 & 15.0 & 11.2 & 21.8 & 68.9 & $r_0$ & 161.8M\\
         &SeqFromer$^*$ \cite{seqformer}           & 40.5 & 62.4 & 43.7 & 36.1 & 48.1 & 15.1 & 31.9 & 13.8 & 10.4 & 27.1 & 72.3 & $r_0$ & 49.3M\\
         &VITA \cite{heo2022vita}                   & \textbf{45.7} & \textbf{67.4} & \textbf{49.5} & \textbf{40.9} & \textbf{53.6} & 19.6 & 41.2 & 17.4 & 11.7 & 26.0 & &1 & 57.2M\\
         &MDQE (ours)                               & 43.8 & 67.0 & 48.2 & 38.4 & 50.7 & \underline{28.5} & \underline{52.8} & \underline{29.1} & \underline{14.7} & \underline{33.4} & &$\sim$1 & 51.4M\\
         &MDQE$^*$ (ours)                               & \underline{44.5} & \underline{67.1} & \underline{48.7} & 37.9 & 49.8 & \textbf{30.8} & \textbf{56.9} & \textbf{31.1} & \textbf{14.8} & \textbf{36.8} & & $r_0$ & 51.4M\\
         \Xhline{1pt}
         \multirow{2}{*}{720p} 
         & IDOL \cite{IDOL}                         & - & - & - & - & - & 30.2 & 51.3 & 30.0 & 15.0 & 37.5 & & 1 & 43.1M\\
         & MDQE$^*$ (ours)                              & - & - & - & - & - & \textbf{33.0} & \textbf{57.4} & \textbf{32.2} & \textbf{15.4} & \textbf{38.4} & & $r_0$ & 51.4M \\
        \Xhline{1pt}

      \end{tabular}
}
\end{center}
\vspace{-6mm}
\caption{ Quantitative performance comparison of methods with ResNet50 backbone on benchmark OVIS and YouTube-VIS 2021 datasets, where $\dag$ using MsgShifT backbone. For those per-clip input methods, we adopt video-in video-out online inference on YouTube-VIS valid sets (less than 84 frames). $^*$ denotes that the method employs clip-in clip-out offline inference with $T_o=T-1$ overlapping frames between adjacent clips on OVIS (at most 292 frames). Here each frame needs to be processed $r_o=T/(T-T_o)=T$ times in average. We also report the performance of MDQE using a single overlapping frame $T_o=1$ between clips, called near-online inference.
}\label{tab:sota_yt21_ovis}
\vspace{-1mm}
\end{table*}
