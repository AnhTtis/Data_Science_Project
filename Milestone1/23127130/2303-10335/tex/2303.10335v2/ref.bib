@article{sandbach2012static,
  title={Static and dynamic 3D facial expression recognition: A comprehensive survey},
  author={Sandbach, Georgia and Zafeiriou, Stefanos and Pantic, Maja and Yin, Lijun},
  journal={Image and Vision Computing},
  volume={30},
  number={10},
  pages={683--697},
  year={2012},
  publisher={Elsevier}
}

@article{mckeown2011semaine,
  title={The semaine database: Annotated multimodal records of emotionally colored conversations between a person and a limited agent},
  author={McKeown, Gary and Valstar, Michel and Cowie, Roddy and Pantic, Maja and Schroder, Marc},
  journal={IEEE transactions on affective computing},
  volume={3},
  number={1},
  pages={5--17},
  year={2011},
  publisher={IEEE}
}

@inproceedings{ringeval2013introducing,
  title={Introducing the RECOLA multimodal corpus of remote collaborative and affective interactions},
  author={Ringeval, Fabien and Sonderegger, Andreas and Sauer, Juergen and Lalanne, Denis},
  booktitle={2013 10th IEEE international conference and workshops on automatic face and gesture recognition (FG)},
  pages={1--8},
  year={2013},
  organization={IEEE}
}

@article{soleymani2011multimodal,
  title={A multimodal database for affect recognition and implicit tagging},
  author={Soleymani, Mohammad and Lichtenauer, Jeroen and Pun, Thierry and Pantic, Maja},
  journal={IEEE transactions on affective computing},
  volume={3},
  number={1},
  pages={42--55},
  year={2011},
  publisher={IEEE}
}

@article{kossaifi2019sewa,
  title={Sewa db: A rich database for audio-visual emotion and sentiment research in the wild},
  author={Kossaifi, Jean and Walecki, Robert and Panagakis, Yannis and Shen, Jie and Schmitt, Maximilian and Ringeval, Fabien and Han, Jing and Pandit, Vedhas and Toisoul, Antoine and Schuller, Bjoern W and others},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  year={2019},
  publisher={IEEE}
}

@article{stappen2021multimodal,
  title={The multimodal sentiment analysis in car reviews (muse-car) dataset: Collection, insights and improvements},
  author={Stappen, Lukas and Baird, Alice and Schumann, Lea and Schuller, Bj{\"o}rn},
  journal={arXiv preprint arXiv:2101.06053},
  year={2021}
}

@inproceedings{kollias2020analysing, title={Analysing Affective Behavior in the First ABAW 2020 Competition}, author={Kollias, D and Schulc, A and Hajiyev, E and Zafeiriou, S}, booktitle={2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020)(FG)}, pages={794--800}}

@article{kollias2021distribution, title={Distribution Matching for Heterogeneous Multi-Task Learning: a Large-scale Face Study}, author={Kollias, Dimitrios and Sharmanska, Viktoriia and Zafeiriou, Stefanos}, journal={arXiv preprint arXiv:2105.03790}, year={2021} }

@article{kollias2021affect, title={Affect Analysis in-the-wild: Valence-Arousal, Expressions, Action Units and a Unified Framework}, author={Kollias, Dimitrios and Zafeiriou, Stefanos}, journal={arXiv preprint arXiv:2103.15792}, year={2021}}

@article{kollias2019expression, title={Expression, Affect, Action Unit Recognition: Aff-Wild2, Multi-Task Learning and ArcFace}, author={Kollias, Dimitrios and Zafeiriou, Stefanos}, journal={arXiv preprint arXiv:1910.04855}, year={2019} }

@article{kollias2019face,title={Face Behavior a la carte: Expressions, Affect and Action Units in a Single Network}, author={Kollias, Dimitrios and Sharmanska, Viktoriia and Zafeiriou, Stefanos}, journal={arXiv preprint arXiv:1910.11111}, year={2019}}

@article{kollias2019deep, title={Deep affect prediction in-the-wild: Aff-wild database and challenge, deep architectures, and beyond}, author={Kollias, Dimitrios and Tzirakis, Panagiotis and Nicolaou, Mihalis A and Papaioannou, Athanasios and Zhao, Guoying and Schuller, Bj{\"o}rn and Kotsia, Irene and Zafeiriou, Stefanos}, journal={International Journal of Computer Vision}, pages={1--23}, year={2019}, publisher={Springer} }

@inproceedings{zafeiriou2017aff, title={Aff-wild: Valence and arousal ‘in-the-wild’challenge}, author={Zafeiriou, Stefanos and Kollias, Dimitrios and Nicolaou, Mihalis A and Papaioannou, Athanasios and Zhao, Guoying and Kotsia, Irene}, booktitle={Computer Vision and Pattern Recognition Workshops (CVPRW), 2017 IEEE Conference on}, pages={1980--1987}, year={2017}, organization={IEEE} }

@article{scherer2007component,
  title={Component models of emotion can inform the quest for emotional competence. U: G. Mathews, M. Zeidner, RD Roberts (Ur.)},
  author={Scherer, KR},
  journal={The science of emotional intelligence: knowns and unknowns},
  pages={101--126},
  year={2007}
}

@book{darwin2015expression,
  title={The expression of the emotions in man and animals},
  author={Darwin, Charles},
  year={2015},
  publisher={University of Chicago press}
}

@article{tian2001recognizing,
  title={Recognizing action units for facial expression analysis},
  author={Tian, Y-I and Kanade, Takeo and Cohn, Jeffrey F},
  journal={IEEE Transactions on pattern analysis and machine intelligence},
  volume={23},
  number={2},
  pages={97--115},
  year={2001},
  publisher={IEEE}
}

@inproceedings{hershey2017cnn,
  title={CNN architectures for large-scale audio classification},
  author={Hershey, Shawn and Chaudhuri, Sourish and Ellis, Daniel PW and Gemmeke, Jort F and Jansen, Aren and Moore, R Channing and Plakal, Manoj and Platt, Devin and Saurous, Rif A and Seybold, Bryan and others},
  booktitle={2017 ieee international conference on acoustics, speech and signal processing (icassp)},
  pages={131--135},
  year={2017},
  organization={IEEE}
}

@article{bai2018empirical,
  title={An empirical evaluation of generic convolutional and recurrent networks for sequence modeling},
  author={Bai, Shaojie and Kolter, J Zico and Koltun, Vladlen},
  journal={arXiv preprint arXiv:1803.01271},
  year={2018}
}

@article{shrout1979intraclass,
  title={Intraclass correlations: uses in assessing rater reliability.},
  author={Shrout, Patrick E and Fleiss, Joseph L},
  journal={Psychological bulletin},
  volume={86},
  number={2},
  pages={420},
  year={1979},
  publisher={American Psychological Association}
}

@article{waibel1989phoneme,
  title={Phoneme recognition using time-delay neural networks},
  author={Waibel, Alex and Hanazawa, Toshiyuki and Hinton, Geoffrey and Shikano, Kiyohiro and Lang, Kevin J},
  journal={IEEE transactions on acoustics, speech, and signal processing},
  volume={37},
  number={3},
  pages={328--339},
  year={1989},
  publisher={IEEE}
}

@article{liu2019aff,
  title={Aff-Wild Database and AffWildNet},
  author={Liu, Mengyao and Kollias, Dimitrios},
  journal={arXiv preprint arXiv:1910.05318},
  year={2019}
}

@inproceedings{deng2020multitask,
  title={Multitask emotion recognition with incomplete labels},
  author={Deng, Didan and Chen, Zhaokang and Shi, Bertram E},
  booktitle={2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020)(FG)},
  pages={828--835},
  year={2020},
  organization={IEEE Computer Society}
}

@article{kuhnke2020two,
  title={Two-stream aural-visual affect analysis in the wild},
  author={Kuhnke, Felix and Rumberg, Lars and Ostermann, J{\"o}rn},
  journal={arXiv preprint arXiv:2002.03399},
  year={2020}
}

@inproceedings{eyben2010opensmile,
  title={Opensmile: the munich versatile and fast open-source audio feature extractor},
  author={Eyben, Florian and W{\"o}llmer, Martin and Schuller, Bj{\"o}rn},
  booktitle={Proceedings of the 18th ACM international conference on Multimedia},
  pages={1459--1462},
  year={2010}
}


@inproceedings{guo2016ms,
  title={Ms-celeb-1m: A dataset and benchmark for large-scale face recognition},
  author={Guo, Yandong and Zhang, Lei and Hu, Yuxiao and He, Xiaodong and Gao, Jianfeng},
  booktitle={European conference on computer vision},
  pages={87--102},
  year={2016},
  organization={Springer}
}

@inproceedings{barsoum2016training,
  title={Training deep networks for facial expression recognition with crowd-sourced label distribution},
  author={Barsoum, Emad and Zhang, Cha and Ferrer, Cristian Canton and Zhang, Zhengyou},
  booktitle={Proceedings of the 18th ACM International Conference on Multimodal Interaction},
  pages={279--283},
  year={2016}
}

@article{zhang2020m,
  title={M\textsuperscript{3}T: Multi-Modal Continuous Valence-Arousal Estimation in the Wild},
  author={Zhang, Yuan-Hang and Huang, Rulin and Zeng, Jiabei and Shan, Shiguang and Chen, Xilin},
  journal={arXiv preprint arXiv:2002.02957},
  year={2020}
}

@inproceedings{ringeval2019avec,
  title={AVEC 2019 workshop and challenge: state-of-mind, detecting depression with AI, and cross-cultural affect recognition},
  author={Ringeval, Fabien and Schuller, Bj{\"o}rn and Valstar, Michel and Cummins, Nicholas and Cowie, Roddy and Tavabi, Leili and Schmitt, Maximilian and Alisamir, Sina and Amiriparian, Shahin and Messner, Eva-Maria and others},
  booktitle={Proceedings of the 9th International on Audio/Visual Emotion Challenge and Workshop},
  pages={3--12},
  year={2019}
}

@inproceedings{valstar2016avec,
  title={Avec 2016: Depression, mood, and emotion recognition workshop and challenge},
  author={Valstar, Michel and Gratch, Jonathan and Schuller, Bj{\"o}rn and Ringeval, Fabien and Lalanne, Denis and Torres Torres, Mercedes and Scherer, Stefan and Stratou, Giota and Cowie, Roddy and Pantic, Maja},
  booktitle={Proceedings of the 6th international workshop on audio/visual emotion challenge},
  pages={3--10},
  year={2016}
}

@inproceedings{ringeval2017avec,
  title={Avec 2017: Real-life depression, and affect recognition workshop and challenge},
  author={Ringeval, Fabien and Schuller, Bj{\"o}rn and Valstar, Michel and Gratch, Jonathan and Cowie, Roddy and Scherer, Stefan and Mozgai, Sharon and Cummins, Nicholas and Schmitt, Maximilian and Pantic, Maja},
  booktitle={Proceedings of the 7th Annual Workshop on Audio/Visual Emotion Challenge},
  pages={3--9},
  year={2017}
}

@inproceedings{ringeval2018avec,
  title={AVEC 2018 workshop and challenge: Bipolar disorder and cross-cultural affect recognition},
  author={Ringeval, Fabien and Schuller, Bj{\"o}rn and Valstar, Michel and Cowie, Roddy and Kaya, Heysem and Schmitt, Maximilian and Amiriparian, Shahin and Cummins, Nicholas and Lalanne, Denis and Michaud, Adrien and others},
  booktitle={Proceedings of the 2018 on audio/visual emotion challenge and workshop},
  pages={3--13},
  year={2018}
}


@article{zhang2014bp4d,
  title={Bp4d-spontaneous: a high-resolution spontaneous 3d dynamic facial expression database},
  author={Zhang, Xing and Yin, Lijun and Cohn, Jeffrey F and Canavan, Shaun and Reale, Michael and Horowitz, Andy and Liu, Peng and Girard, Jeffrey M},
  journal={Image and Vision Computing},
  volume={32},
  number={10},
  pages={692--706},
  year={2014},
  publisher={Elsevier}
}

@article{fanelli20103,
  title={A 3-d audio-visual corpus of affective communication},
  author={Fanelli, Gabriele and Gall, Juergen and Romsdorfer, Harald and Weise, Thibaut and Van Gool, Luc},
  journal={IEEE Transactions on Multimedia},
  volume={12},
  number={6},
  pages={591--598},
  year={2010},
  publisher={IEEE}
}

@inproceedings{yin20063d,
  title={A 3D facial expression database for facial behavior research},
  author={Yin, Lijun and Wei, Xiaozhou and Sun, Yi and Wang, Jun and Rosato, Matthew J},
  booktitle={7th international conference on automatic face and gesture recognition (FGR06)},
  pages={211--216},
  year={2006},
  organization={IEEE}
}


@misc{2106.15318,Author = {Dimitrios Kollias and Irene Kotsia and Elnar Hajiyev and Stefanos Zafeiriou}, Title = {Analysing Affective Behavior in the second ABAW2 Competition}, Year = {2021}, Eprint = {arXiv:2106.15318},}

@article{guo2016ms,
  title={Ms-celeb-1m: Challenge of recognizing one million celebrities in the real world},
  author={Guo, Yandong and Zhang, Lei and Hu, Yuxiao and He, Xiaodong and Gao, Jianfeng},
  journal={Electronic imaging},
  volume={2016},
  number={11},
  pages={1--6},
  year={2016},
  publisher={Society for Imaging Science and Technology}
}


@inproceedings{cao2018vggface2,
  title={Vggface2: A dataset for recognising faces across pose and age},
  author={Cao, Qiong and Shen, Li and Xie, Weidi and Parkhi, Omkar M and Zisserman, Andrew},
  booktitle={2018 13th IEEE international conference on automatic face \& gesture recognition (FG 2018)},
  pages={67--74},
  year={2018},
  organization={IEEE}
}

@inproceedings{cowie2000feeltrace,
  title={'FEELTRACE': An instrument for recording perceived emotion in real time},
  author={Cowie, Roddy and Douglas-Cowie, Ellen and Savvidou*, Susie and McMahon, Edelle and Sawey, Martin and Schr{\"o}der, Marc},
  booktitle={ISCA tutorial and research workshop (ITRW) on speech and emotion},
  year={2000}
}


@article{deng2021towards,
  title={Towards Better Uncertainty: Iterative Training of Efficient Networks for Multitask Emotion Recognition},
  author={Deng, Didan and Wu, Liang and Shi, Bertram E},
  journal={arXiv preprint arXiv:2108.04228},
  year={2021}
}


@article{zhang2021prior,
  title={Prior Aided Streaming Network for Multi-task Affective Recognitionat the 2nd ABAW2 Competition},
  author={Zhang, Wei and Guo, Zunhu and Chen, Keyu and Li, Lincheng and Zhang, Zhimeng and Ding, Yu},
  journal={arXiv preprint arXiv:2107.03708},
  year={2021}
}

@article{vu2021multitask,
  title={Multitask Multi-database Emotion Recognition},
  author={Vu, Manh Tu and Beurton-Aimar, Marie},
  journal={arXiv preprint arXiv:2107.04127},
  year={2021}
}

@article{wang2021multi,
  title={A Multi-task Mean Teacher for Semi-supervised Facial Affective Behavior Analysis},
  author={Wang, Lingfeng and Wang, Shisen},
  journal={arXiv preprint arXiv:2107.04225},
  year={2021}
}


@inproceedings{zhang2021continuous,
  title={Continuous Emotion Recognition with Audio-visual Leader-follower Attentive Fusion},
  author={Zhang, Su and Ding, Yi and Wei, Ziquan and Guan, Cuntai},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3567--3574},
  year={2021}
}

@inproceedings{kollias2021analysing,
  title={Analysing affective behavior in the second abaw2 competition},
  author={Kollias, Dimitrios and Zafeiriou, Stefanos},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3652--3660},
  year={2021}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@inproceedings{sun2020multi,
  title={Multi-modal continuous dimensional emotion recognition using recurrent neural network and self-attention mechanism},
  author={Sun, Licai and Lian, Zheng and Tao, Jianhua and Liu, Bin and Niu, Mingyue},
  booktitle={Proceedings of the 1st International on Multimodal Sentiment Analysis in Real-life Media Challenge and Workshop},
  pages={27--34},
  year={2020}
}


@article{kollias2022abaw, title={ABAW: Valence-Arousal Estimation, Expression Recognition, Action Unit Detection \& Multi-Task Learning Challenges}, author={Kollias, Dimitrios}, journal={arXiv preprint arXiv:2202.10659}, year={2022}}


@book{schuller2013intelligent,
  title={Intelligent audio analysis},
  author={Schuller, Bj{\"o}rn W},
  year={2013},
  publisher={Springer}
}

@incollection{stappen2021muse,
  title={Muse-toolbox: The multimodal sentiment analysis continuous annotation fusion and discrete class transformation toolbox},
  author={Stappen, Lukas and Schumann, Lea and Sertolli, Benjamin and Baird, Alice and Weigell, Benjamin and Cambria, Erik and Schuller, Bj{\"o}rn W},
  booktitle={Proceedings of the 2nd on Multimodal Sentiment Analysis Challenge},
  pages={75--82},
  year={2021}
}


@article{meng2022multi,
  title={Multi-modal Emotion Estimation for in-the-wild Videos},
  author={Meng, Liyu and Liu, Yuchen and Liu, Xiaolong and Huang, Zhaopei and Jiang, Wenqiang and Zhang, Tenggan and Deng, Yuanyuan and Li, Ruichen and Wu, Yannan and Zhao, Jinming and others},
  journal={arXiv preprint arXiv:2203.13032},
  year={2022}
}

@article{nguyen2022ensemble,
  title={An Ensemble Approach for Facial Expression Analysis in Video},
  author={Nguyen, Hong-Hai and Huynh, Van-Thong and Kim, Soo-Hyung},
  journal={arXiv preprint arXiv:2203.12891},
  year={2022}
}

@article{zhang2022transformer,
  title={Transformer-based Multimodal Information Fusion for Facial Expression Analysis},
  author={Zhang, Wei and Zhang, Zhimeng and Qiu, Feng and Wang, Suzhen and Ma, Bowen and Zeng, Hao and An, Rudong and Ding, Yu},
  journal={arXiv preprint arXiv:2203.12367},
  year={2022}
}


@article{savchenko2022frame,
  title={Frame-level Prediction of Facial Expressions, Valence, Arousal and Action Units for Mobile Devices},
  author={Savchenko, Andrey V},
  journal={arXiv preprint arXiv:2203.13436},
  year={2022}
}

@article{karas2022continuous,
  title={Continuous-Time Audiovisual Fusion with Recurrence vs. Attention for In-The-Wild Affect Recognition},
  author={Karas, Vincent and Tellamekala, Mani Kumar and Mallol-Ragolta, Adria and Valstar, Michel and Schuller, Bj{\"o}rn W},
  journal={arXiv preprint arXiv:2203.13285},
  year={2022}
}


@article{rajasekar2022joint,
  title={A Joint Cross-Attention Model for Audio-Visual Fusion in Dimensional Emotion Recognition},
  author={Rajasekar, Gnana Praveen and de Melo, Wheidima Carneiro and Ullah, Nasib and Aslam, Haseeb and Zeeshan, Osama and Denorme, Th{\'e}o and Pedersoli, Marco and Koerich, Alessandro and Cardinal, Patrick and Granger, Eric},
  journal={arXiv preprint arXiv:2203.14779},
  year={2022}
}


@misc{myers2004psychology,
  title={Psychology},
  author={Myers, David G},
  year={2004},
  publisher={New York: Worth Publishers}
}

@inproceedings{hussein2019timeception,
  title={Timeception for complex action recognition},
  author={Hussein, Noureldien and Gavves, Efstratios and Smeulders, Arnold WM},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={254--263},
  year={2019}
}

@article{sankaran2020domain,
  title={Domain adaptive representation learning for facial action unit recognition},
  author={Sankaran, Nishant and Mohan, Deen Dayal and Lakshminarayana, Nagashri N and Setlur, Srirangaraj and Govindaraju, Venu},
  journal={Pattern Recognition},
  volume={102},
  pages={107127},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{zhang2022continuous,
  title={Continuous emotion recognition using visual-audio-linguistic information: A technical report for abaw3},
  author={Zhang, Su and An, Ruyi and Ding, Yi and Guan, Cuntai},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2376--2381},
  year={2022}
}


@article{tzirakis2018end2you,
  title={End2You--The Imperial Toolkit for Multimodal Profiling by End-to-End Learning},
  author={Tzirakis, Panagiotis and Zafeiriou, Stefanos and Schuller, Bjorn W},
  journal={arXiv preprint arXiv:1802.01115},
  year={2018}
}

@inproceedings{sun2020multi,
  title={Multi-modal continuous dimensional emotion recognition using recurrent neural network and self-attention mechanism},
  author={Sun, Licai and Lian, Zheng and Tao, Jianhua and Liu, Bin and Niu, Mingyue},
  booktitle={Proceedings of the 1st International on Multimodal Sentiment Analysis in Real-life Media Challenge and Workshop},
  pages={27--34},
  year={2020}
}

@misc{zhang2023multimodal,
      title={Multi-modal Facial Affective Analysis based on Masked Autoencoder}, 
      author={Wei Zhang and Bowen Ma and Feng Qiu and Yu Ding},
      year={2023},
      eprint={2303.10849},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{zhou2023continuous,
      title={Continuous emotion recognition based on TCN and Transformer}, 
      author={Weiwei Zhou and Jiada Lu and Zhaolong Xiong and Weifeng Wang},
      year={2023},
      eprint={2303.08356},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{zhang2023facial,
      title={Facial Affect Recognition based on Transformer Encoder and Audiovisual Fusion for the ABAW5 Challenge}, 
      author={Ziyang Zhang and Liuwei An and Zishun Cui and Ao xu and Tengteng Dong and Yueqi Jiang and Jingyi Shi and Xin Liu and Xiao Sun and Meng Wang},
      year={2023},
      eprint={2303.09158},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{savchenko2023emotieffnet,
      title={EmotiEffNet Facial Features in Uni-task Emotion Recognition in Video at ABAW-5 competition}, 
      author={Andrey V. Savchenko},
      year={2023},
      eprint={2303.09162},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{vu2023vision,
      title={Vision Transformer for Action Units Detection}, 
      author={Tu Vu and Van Thong Huynh and Soo Hyung Kim},
      year={2023},
      eprint={2303.09917},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{nguyen2023transformerbased,
      title={A transformer-based approach to video frame-level prediction in Affective Behaviour Analysis In-the-wild}, 
      author={Dang-Khanh Nguyen and Ngoc-Huynh Ho and Sudarshan Pant and Hyung-Jeong Yang},
      year={2023},
      eprint={2303.09293},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{wang2023facial,
      title={Facial Affective Behavior Analysis Method for 5th ABAW Competition}, 
      author={Shangfei Wang and Yanan Chang and Yi Wu and Xiangyu Miao and Jiaqiang Wu and Zhouan Zhu and Jiahe Wang and Yufei Xiao},
      year={2023},
      eprint={2303.09145},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{kollias2023abaw,
      title={ABAW: Valence-Arousal Estimation, Expression Recognition, Action Unit Detection & Emotional Reaction Intensity Estimation Challenges}, 
      author={Dimitrios Kollias and Panagiotis Tzirakis and Alice Baird and Alan Cowen and Stefanos Zafeiriou},
      year={2023},
      eprint={2303.01498},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}