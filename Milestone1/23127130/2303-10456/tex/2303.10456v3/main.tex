\documentclass[peerreview]{IEEEtran}

\pdfminorversion=7

%
\usepackage[square,numbers,sort&compress]{natbib}
\bibliographystyle{IEEEtran}
%


\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{mathrsfs}
\usepackage{amssymb} 
\usepackage{bbm,dsfont}   
\usepackage{enumerate} 
%
\usepackage[table]{xcolor}
\usepackage{tikz}
\usetikzlibrary{calc}

\usepackage{physics}

\usepackage{xcolor}

%
\usepackage{hyperref} %
\usepackage%
{hyperref} %
\hypersetup{
    colorlinks,
    linkcolor={blue!80!black},%
    citecolor={green!30!black},
    urlcolor={blue!80!black}
}


\input{commands}




\title{The Multiple-Access Channel with Entangled Transmitters}



\author{
		%\vspace{0.1cm}
    \IEEEauthorblockN{Uzi Pereg\IEEEauthorrefmark{1}\IEEEauthorrefmark{2}, Christian Deppe\IEEEauthorrefmark{3}, and Holger Boche\IEEEauthorrefmark{4}\IEEEauthorrefmark{5}\IEEEauthorrefmark{7}} \\
		\vspace{0.25cm}
    \IEEEauthorblockA{\normalsize
		\IEEEauthorrefmark{1}Faculty of Electrical and Computer Engineering, Technion \\
		\IEEEauthorrefmark{2}Helen Diller Quantum Center, Technion \\
		\IEEEauthorrefmark{3}Institute of Communication Engineering, Technical University of Munich \\
		\IEEEauthorrefmark{4}Theoretical Information Technology, Technical University of Munich\\
		\IEEEauthorrefmark{5}Munich Center for Quantum Science and Technology (MCQST)\\
		\IEEEauthorrefmark{7}Cyber Security in the Age of Large-Scale Adversaries Exzellenzcluster (CASA)\\
    Email: {\tt uzipereg@technion.ac.il, $\{$christian.deppe,boche$\}$@tum.de}}
}




\begin{document}
\maketitle

{}


\begin{abstract}
Communication over a classical multiple-access channel (MAC) with  entanglement resources is considered,
%
whereby two transmitters share entanglement resources a priori before communication begins.
Leditzki et al. (2020)  presented an example of a classical MAC, defined in terms of a pseudo telepathy game, such that the sum rate with entangled transmitters is strictly higher than the best achievable sum rate without such resources. 
%
Here, we determine %a full characterization of 
the capacity region for the \emph{general} MAC with entangled transmitters, and show that the previous result can be obtained as a special case. 
Furthermore, it has long been known %
that the capacity region of the classical MAC
under a message-average error criterion can be strictly larger than with a maximal error criterion (Dueck, 1978).
We observe that given entanglement resources, the regions coincide.
\end{abstract}

\begin{IEEEkeywords}
Quantum communication, multiple-access channel, entanglement resources.
\end{IEEEkeywords}

%
%


\maketitle

\setcounter{page}{1}

\section{Introduction}
%
%
Cooperation in quantum communication networks has  gained considerable attention recently driven by both experimental advancements and theoretical discoveries
%
%
\cite{vanLoockAltBecherBensonBocheDeppe:20p,Pereg:22p,BFSDBFJ:20b}. 
The multiple-access channel (MAC) is a fundamental model for network communication.
Quantum resources in communication over the MAC are considered in the literature in various settings. %
Winter \cite{Winter:01p}  derived a regularized characterization for the classical capacity region of the quantum MAC (see also \cite{Savov:12z}). Furthermore, 
the authors of the present paper \cite{PeregDeppeBoche:22p} considered the quantum MAC with cribbing encoders, whereby Transmitter 2 has access to (part of) the environment of Transmitter 1.
 Boche and N\"otzel \cite{BocheNoetzel:14p} studied the cooperation setting of a classical-quantum %
MAC with conferencing encoders, where the encoders exchange messages between them in a constant rate (see also \cite{DiadamoBoche:19a}).
 Hsieh et al.  \cite{HsiehDevetakWinter:08p} and Shi et al.  \cite{ShiHsiehGuhaZhangZhuang:21p} addressed the model where each transmitter shares entanglement resources with the receiver independently.
 


Leditzky et al.  \cite{LeditzkyAlhejjiLevinSmith:20p} presented an example of a classical MAC
such that  sharing entanglement between transmitters strictly increases the achievable sum rate.
Recently, the classical upper bound has been improved showing that the sum rate increases from at most
$3.02$ to $3.17$ bits per transmission \cite{SeshadriLeditzkySiddhuSmith:22c}. 
The channel construction in \cite{LeditzkyAlhejjiLevinSmith:20p} is based on  a pseudo-telepathy game \cite{BrassardBroadbentTapp:05p} where quantum strategies guarantee a certain win and outperform classical strategies.
Additional observations are developed in 
\cite{DoolittleChitambarLeditzky:22c} as well.
%
 Fawzi and Ferm\'e \cite{FawziFerme:22c} have also  established  separation in a more fundamental example, the binary adder channel, when the transmitters are provided with non-singaling correlations.
By analyzing the zero-error capacity region, it was shown that the sum rate increases from $1.5$ without correlation resources, to $1.5425$ bits per transmission in this case \cite{FawziFerme:22c}. 
We   have shown that the dual property does not hold for the broadcast channel, i.e., entanglement between receivers does not increase achievable rates \cite{PeregDeppeBoche:21p2}. %
%
 
The potential benefits of the sixth generation of cellular networks (6G) are significant, with anticipated improvements in latency, resilience, computation power, and trustworthiness for future communication systems, such as the tactile internet
\cite{FettwisBoche:21m},
which involves not only data transfer but also the control of physical and virtual objects. Quantum resources are expected to play a crucial role in achieving these gains, as highlighted by \cite{DangAminShihadaAlouini:20p} and \cite{FettwisBoche:21m}. By enabling cooperation between trusted hardware and software components, future communication systems could isolate untrusted components and substantially reduce the attack surface of the communication system  \cite{FettwisBoche:21m,FettwisBoche:22p}. Quantum resources and cooperation also offer additional advantages, such as improved performance gains for communication tasks and the reduction of the attack surface, making them highly promising for 6G networks, as discussed in \cite{TKWIBD:20p} and \cite{FitzekBoche:21p2}. Investigating communication with cooperation in the form of entanglement resources could lead to more efficient protocols for future applications, making this an interesting avenue for further research.



%
%
\begin{figure*}[tb]
\includegraphics[scale=0.75,trim={-2cm 9cm 2cm 9cm},clip]{Entangled_MAC_Diag.pdf} %[trim={left bottom right top},clip]

\caption{The classical multiple-access channel $P_{Y|X_1,X_2}$ with pre-shared entanglement resources between the transmitters. The entanglement resources (quantum systems) of Transmitter 1 and Transmitter 2 are marked in red and blue, respectively.
%
}
\label{fig:MentangledTx}
\end{figure*}

Here, %
we consider
%
communication over a two-user classical MAC with  entanglement resources shared
%
between the transmitters, a priori before communication begins.
We derive a full characterization of the capacity region for the \emph{general} MAC with entangled transmitters (see Figure~\ref{fig:MentangledTx}), and show that the  result by Leditzky et al.  \cite{LeditzkyAlhejjiLevinSmith:20p} can be obtained as a special case. 
We also point out the following change of behavior.
In general, achievable communication rates may also depend on the error criterion.
% 
Without entanglement resources, %
Dueck \cite{Dueck:78p} showed that
the relaxation of a message-average error criterion can lead to strictly higher achievable rates, when compared with a maximal error criterion.
Here, however, we show that the capacity region with entangled transmitters remains the same, whether we consider a message-average or a maximal error criterion.

The remainder of this paper is organized as follows.
Section~\ref{Section:Preliminaries} includes  basic definitions and the model description.
In Section~\ref{Section:Main_Results}, we present our main results on the classical MAC with entangled transmitters, where the entanglement resources  can be either unlimited (Section~\ref{Subsection:Main_Result}), or at a limited rate (\ref{Subsection:Rate_Limit_EA}).
In addition, we examine the example by Leditzky et al. 
\cite{LeditzkyAlhejjiLevinSmith:20p} in Section~\ref{Subsection:Magic_Example}.
 We prove the main results in
 Sections \ref{app:CardCl} and \ref{app:etMAC}:
%
%
In Section \ref{app:CardCl},
%
we show that our capacity formula is exhausted with finite-cardinality auxiliary variables, and in Section~\ref{app:etMAC}, we prove the capacity theorem.
In Section~\ref{Section:Discussion}, we summarize, and
%
in the appendix, we show  that the capacity region associated with the average and maximal error criteria is identical.

%
%


\section{Definitions and Channel Model
}
\label{Section:Preliminaries}
%
\subsection{Basic Definitions%
}
\label{subsec:notation}


 We use the following notation conventions. %
%
Script letters $\Xset,\Yset,...$ are used for finite sets.
%
Lowercase letters $x,y,\ldots$  represent constants and values of classical random variables, and uppercase letters $X,Y,\ldots$ represent classical random variables.  
 The distribution of a  random variable $X$ is specified by a probability mass function (pmf) 
	$p_X(x)$ over a finite set $\Xset$.
	The respective product distribution is denoted by $p_X^n$.	%
%
 We use $x^r=\left(x[i] \right)_{i=1}^r$ to denote  a sequence of letters from $\Xset$, where $r$ is a positive integer. %
 A random sequence $X^n$ and its distribution $p_{X^n}(x^n)$ are defined accordingly. 
%
The %
typical set $\tset(p_X)$ is the set of sequences $x^n\in\Xset^n$ such that $\left| p_X(a) -\frac{1}{n}N(a|x^n)%
%
\right|\leq \delta \cdot p_X(a)$, 
for every $a\in\Xset$, where $N(a|x^n)$ is the number of occurrences of the letter $a\in\Xset$ in the sequence $x^n$.
The definition is extended to a joint distribution $p_{X,Y}$ in a natural manner.
%
%


%
The state of a quantum system $A$ is a density operator $\rho$ on the Hilbert space $\Hset_A$.
A density operator is an Hermitian, positive semidefinite operator, with unit trace, i.e., 
 $\rho^\dagger=\rho$, $\rho\succeq 0$, and $\trace(\rho)=1$. The set of all density operators acting on $\Hset_A$ is denoted by $\mathscr{D}(\Hset_A)$. The state is said to be pure if $\rho=\kb{\psi}$, for some vector $|\psi\rangle\in\Hset_A$.
%
A measurement of a quantum system is specified a positive operator-valued measure (POVM), i.e., a set of positive semi-denfinite operators  $\{ K_x \}_{x\in\Xset}$
such that $\sum_x K_x=\identity$.
%
According to the Born rule, if the system is in state $\rho$, then the probability to measure $x$ is  $p_X(x)=\trace(K_x \rho)$.
%
%
A quantum channel $\Pset_{A\to B}$ is a completely-positive trace-preserving (cptp) linear map from $\mathscr{D}(\Hset_A)$ to $\mathscr{D}(\Hset_B)$.
A measurement channel is a quantum-classical channel $\mathcal{K}_{A\to X}$, mapping 
$\rho\mapsto\mathcal{K}_{A\to X}(\rho)=\sum_x \trace(K_x \rho)\ketbra{x}$, where $\{ K_x \}_{x\in\Xset}$ forms a POVM
\cite[Def. 4.6.7]{Wilde:17b}.




% \subsection{Classical Multiple-Access Channel}
% \label{subsec:MAC}
A discrete memoryless multiple-access channel (MAC) $(\Xset_1,\Xset_2,P_{Y|X_1,X_2},\mathcal{Y})$ consists of finite input alphabets $\Xset_1$, $\Xset_2$, a finite output alphabet $\mathcal{Y}$, and a collection of conditional probability mass functions 
$P_{Y|X_1,X_2}(\cdot|x_1,x_2)$ on $\Yset$, for every $(x_1,x_2)\in\Xset_1 \times \Xset_2$.
We assume that the channel is memoryless. That is, if the inputs are $x_1^n=(x_{1}[i])_{i=1}^n$ and $x_2^n=(x_{2}[i])_{i=1}^n$ are sent through $n$ channel uses, then the output is distributed according to 
$P_{Y|X_1,X_2}^n(y^n|x_1^n,x_2^n)=\prod_{i=1}^n P_{Y|X_1,X_2}\big(y[i] \,\big| x_1[i],x_2[i] \big)$.
%
%
 The transmitters and the receiver are often called Alice 1, Alice 2, and Bob. 




\subsection{Coding with Entangled Transmitters}
\label{sec:Coding}
We consider coding for the classical MAC $P_{Y|X_1,X_2}$ with entanglement resources between the transmitters. 
%
%
%
We denote the entanglement resources of Transmitter 1 and Transmitter 2 by $E_1$ and $E_2$, respectively. Let 
$\Hset_{E_1 E_2}\equiv \Hset_{E_1}\otimes \Hset_{E_2}$ denote the corresponding Hilbert space.

\begin{definition} %
\label{def:ClcapacityE}
A $(2^{nR_1},2^{nR_2},%
n)$   code for the classical MAC $P_{Y|X_1,X_2}$ with
entangled transmitters  consists of the following: 
\begin{itemize}
\item
an entangled state $\Psi_{E_1 E_2}\in\mathscr{D}(\Hset_{E_1 E_2})$ that is shared between the transmitters.
\item 
two message sets  $[1:2^{nR_1}]$ and $ [1:2^{nR_2}]$, assuming $2^{nR_k}$ is an integer;
\item
a pair of encoding POVMs $\Fset_1^{(m_1)}=\{ F^{(m_1)}_{x_1^n} \}_{x_1^n\in\mathcal{X}_1^n}$ and 
$\Fset_2^{(m_2)}=\{ F^{(m_2)}_{x_2^n} \}_{x_2^n\in\Xset_2^n}$ on $E_1$ and $E_2$, respectively; and
\item
a decoding function   $g:\Yset^n\to [1:2^{nR_1}]\times [1:2^{nR_2}] $.
	%
%
 %
\end{itemize}
We denote the code by $\mathscr{C}=(\Psi,\Fset_1,\Fset_2,g)$.
\end{definition}


The communication scheme is depicted in Figure~\ref{fig:MentangledTx}.  
The senders share the entangled pair  $E_1 E_2$. 
Alice $k$ chooses a message $m_k$ from the message set, %
$[1:2^{nR_k}]$, for $k=1,2$.
 To send the message $m_1\in [1:2^{nR_1}]$,
Alice 1 applies the encoding measurement $\Fset_1^{(m_1)}$ to her share of the entanglement resource, $E_1$, and obtains a measurement outcome $x_1^n\in\mathcal{X}_1^n$.
She sends $x_1^n$ through $n$ uses of the classical MAC $P_{Y|X_1,X_2}$. %
Similarly, Alice 2 measures the system $E_2$ using the measurement $\Fset_2^{(m_2)}$, and transmits the outcome $x_2^n$. 
%
%
%
%
%
The joint input distribution is thus
\begin{align}%
f(x_1^n,x_2^n|m_1,m_2)
= \trace \left[  \left(F^{(m_1)}_{x_1^n}\otimes F^{(m_2)}_{x_2^n} \right) \Psi_{E_1 E_2} \right] \,.
\end{align}%



Bob receives the channel output $y^n$, and estimates the message pair as $(\htm_1,\htm_2)=g(y^n)$.
%
%
%
The conditional probability of error of the code $\mathscr{C}=(\Psi,\Fset_1,\Fset_2,g)$ is
\begin{align}
&P_{e}^{(n)}(\mathscr{C}|m_1,m_2)= %
\sum_{y^n: g(y^n)\neq (m_1,m_2)} \left[  \sum_{(x_1^n,x_2^n)\in \Xset_1^n\times \Xset_2^n} f(x_1^n,x_2^n|m_1,m_2) P_{Y|X_1,X_2}^n(y^n|x_1^n,x_2^n) \right] %\,.
\end{align}
for $(m_1,m_2)\in [1:2^{nR_1}]\times [1:2^{nR_2}]$.
 Hence, the maximal probability of error is 
\begin{align}
&P_{e}^{(n)}(\mathscr{C})\equiv %
\max_{m_1,m_2}    P_{e}^{(n)}(\mathscr{C}|m_1,m_2) \,.
\label{Equation:Message_Max_Error}
\end{align}
%
%


A $(2^{nR_1},2^{nR_2},n,\eps)$  code satisfies 
$%
P_{e}^{(n)}(\mathscr{C})\leq\eps $. %
%
%
A rate pair $(R_1,R_2)$ is called achievable with  entangled transmitters   if for every $\eps>0$ and sufficiently large $n$, there exists a 
$(2^{nR_1},2^{nR_2},n,\eps)$ code. 
%
%
 The capacity region $\opC_{\text{ET}}(P_{Y|X_1,X_2})$ of the classical MAC with entangled transmitters
is defined as the set of achievable pairs $(R_1,R_2)$, where the subscript `ET' indicates entanglement resources between the transmitters. %

\begin{remark}
\label{Remark:Classical_Maximal_Error}
% In the classical literature, there is a distinction between communication with deterministic encoding functions or randomized encoding functions.
% Furthermore
In general, achievable communication rates may also depend on the error criterion. In particular, we say that
 a rate pair $(R_1,R_2)$ is achievable with 
a \emph{message-average} error criterion 
 if for every $\eps>0$ and sufficiently large $n$, there exists a 
$(2^{nR_1},2^{nR_2},n)$ code such that
$%
\overline{P}_{e}^{(n)}(\mathscr{C})\leq\eps $, where $\overline{P}_{e}^{(n)}(\mathscr{C})$ denotes the message-average error probability:
\begin{align}
&\overline{P}_{e}^{(n)}(\mathscr{C})\equiv %
\frac{1}{2^{n(R_1+R_2)}}\sum_{m_1=1}^{2^{nR_1}}\sum_{m_2=1}^{2^{nR_2}}    P_{e}^{(n)}(\mathscr{C}|m_1,m_2) \,.
\label{Equation:Message_Avg_Error}
\end{align}
The capacity region with a message-average error criterion is defined accordingly.
%
Without entanglement resources, % nor randomness at the encoders, 
the capacity region with a message-average error criterion can be strictly larger than with a maximal error criterion \cite{Dueck:78p} \cite[Sec. 2.2]{Cai:14p}.
For a general MAC without entanglement resources, the capacity region under a maximal error criterion is an open problem.
In the appendix, we show that in our model, this is not the case. 
That is, the capacity region with entangled transmitters remains the same, whether we consider a message-average or a maximal error criterion.

% it is also important to distinguish between achievable rates with a maximal error probability 
\end{remark}


\section{Main Results}
\label{Section:Main_Results}

\subsection{Communication With Unlimited Entanglement Resources}
\label{Subsection:Main_Result}
We state our results on the classical MAC $P_{Y|X_1,X_2}$ with entanglement resources between the transmitters.
%
 Define the rate region $\mathcal{R}_{\text{ET}}(P_{Y|X_1,X_2})$ as follows,
\begin{align}%
\mathcal{R}_{\text{ET}}(P_{Y|X_1,X_2})=
\bigcup_{ p_{V_0} p_{V_1|V_0} p_{V_2|V_0} \,,\; \varphi_{A_1 A_2} \,,\; \Lset_1 \otimes \Lset_2 }
\left\{ \begin{array}{rl}
  (R_1,R_2) \,:\;
	R_1 &\leq I(V_1;Y|V_0 V_2)  \\
  R_2 &\leq I(V_2;Y|V_0 V_1) \\
	R_1+R_2 &\leq I(V_1 V_2;Y|V_0)
	\end{array}
\right\} \,.
\label{eq:inRetx}
\end{align}%
The union on the right-hand side of (\ref{eq:inRetx}) is over the set of all
 entangled states $\varphi_{A_1 A_2}
 \in
\mathscr{D}( \Hset_{A_1}\otimes \Hset_{ A_2})$, classical auxiliary variables $(V_0,V_1,V_2)\sim p_{V_0} p_{V_1|V_0} p_{V_2|V_0}$, and collection of POVMs $\Lset_k(v_0,v_k)=\{L_k(x_k|v_0,v_k)\}_{x_k\in\Xset_k}$, for $v_0\in\Vset_0$, $v_k\in\Vset_k$, $k=1,2$. Given such a state, variables, and POVMs, the joint distribution of $(V_0,V_1,V_2,X_1,X_2,Y)$ is 
\begin{multline}
p_{V_0,V_1,V_2,X_1, X_2, Y}(v_0,v_1,v_2,x_1,x_2,y)=%
 p_{V_0}(v_0) p_{V_1|V_0}(v_1|v_0)p_{V_2|V_0}(v_2|v_0)\\ \cdot\trace\left[ \left( L_1(x_1|v_0,v_1)\otimes L_2(x_2|v_0,v_2) \right)\varphi_{A_1 A_2}  \right] \cdot P_{Y|X_1,X_2}(y|x_1,x_2) \,.
\label{eq:inRsc_Distribution}
\end{multline}
%
%
Before we state the capacity theorem, we give the following lemma. 
%In principle, one may use
 The property stated below in Lemma~\ref{lemm:CardCl} can simplify the computation of %in order to compute 
 of the region $\mathcal{R}_{\text{ET}}(P_{Y|X_1,X_2})$  %
%in (\ref{eq:inRetx}),
for a given channel.
\begin{lemma}
\label{lemm:CardCl}
The union in (\ref{eq:inRetx}) is exhausted by %
auxiliary variables $V_0$, $V_1$, $V_2$ 
with $|\Vset_0|\leq 3$, $|\Vset_k|\leq 3(|\Xset_1||\Xset_2|+2)$, $k=1,2$, and 
%
%
pure states $\varphi_{A_1 A_2}\equiv \ketbra{\phi_{A_1 A_2}}$.
\end{lemma}
The proof of  is based on the Fenchel-Eggleston-Carath\'eodory lemma \cite{Eggleston:66p}, using similar arguments as 
in \cite{YardHaydenDevetak:08p} \cite[App. B]{Pereg:22p}.
The details are given in Section%
~\ref{app:CardCl}. 
%
\begin{remark}
\label{Remark:Dimension}
In this section, we consider the capacity region given unlimited entanglement resources between the transmitters. 
We note that the dimension of the entangled systems $A_1$ and $A_2$ in the rate formula (\ref{eq:inRetx}) is unbounded. That is, the rate formula
$\mathcal{R}_{\text{ET}}(P_{Y|X_1,X_2})$ involves a union over the limit of finite-dimensional quantum correlations
with $\mathrm{dim}(\mathcal{H}_{A_k})\to\infty$.
This family of correlations is often denoted in the literature by 
$C_{qa}$ \cite{Slofstra:20p}.
As we will discuss in Section~\ref{Section:Discussion}, there are case where the union cannot be exhausted with finite-dimensional entangled systems \cite{LeditzkyAlhejjiLevinSmith:20p,Slofstra:20p}
(see Example~\ref{Example:Slofstra_Vidick} below).
\end{remark}
%
Next, we state our capacity theorem.

\begin{theorem}
\label{theo:etMAC}
The capacity region of a classical MAC $P_{Y|X_1,X_2}$ with entangled transmitters is given by
\begin{align}
\mathcal{C}_{\text{ET}}(P_{Y|X_1,X_2})= \mathcal{R}_{\text{ET}}(P_{Y|X_1,X_2}) \,.
\end{align}
\end{theorem}
The proof of Theorem~\ref{theo:etMAC} is given in Section%
~\ref{app:etMAC}.

\begin{remark}
\label{rem:Uncomput}
In the basic point-to-point communication problem, Bennett et al.  
\cite{BennettShorSmolin:99p,BennettShorSmolin:02p} showed that entanglement assistance between the transmitter and the \emph{receiver} leads to a characterization that is easy to compute.
In other words, in Bennett et al.'s model, introducing 
entanglement resources  transforms the capacity
evaluation from an uncomputable task to an optimization
that can be easily performed, numerically
\cite[Remark 5]{PeregDeppeBoche:21p}.
% the characterization in various settings is easy to compute given entanglement assistance.
Unfortunately,  this is not the case in the present work. Clearly, our characterization of the capacity region  has a single-letter form with respect to the channel dependency. However, there is no upper bound on the necessary dimension of the auxiliary systems $A_1$ and $A_2$ in Theorem~\ref{theo:etMAC}
(see Remark~\ref{Remark:Dimension}).
%
Note that one can always compute achievable rates by choosing an arbitrary dimension, but the optimal rates cannot be  computed with absolute precision in general. 
In the discussion section, we affirm that this is an inherent limitation to our problem
 (see Section~\ref{Section:Discussion}).
 %
\end{remark}

\subsection{Rate-Limited Entanglement Resources}
\label{Subsection:Rate_Limit_EA}
Now, we consider a setting where the entanglement resources are limited.
A code with rate-limited entanglement resources
is defined such that 
 the encoders have access to Hilbert spaces which grow as a function of the channel uses in a rate limited fashion.
%the encoders can use up to $n\theta_E$ maximally entangled qubit pairs.
The precise definition is given below.
\begin{definition} %
\label{def:ClcapacityE_Limited}
A $(2^{nR_1},2^{nR_2},%
n)$   code for the classical MAC $P_{Y|X_1,X_2}$ with an entanglement rate $\theta_E$ between the
 transmitters  consists of the following: 
\begin{itemize}
\item
an entangled state $\Psi_{E_1 E_2}$ that is shared between the transmitters, with $\mathrm{dim}(\mathcal{H}_{E_k})\leq 2^{n\theta_E}$ for $k=1,2$.
\item 
two message sets  $[1:2^{nR_1}]$ and $ [1:2^{nR_2}]$, assuming $2^{nR_k}$ is an integer;
\item
a pair of encoding POVMs $\Fset_1^{(m_1)}=\{ F^{(m_1)}_{x_1^n} \}_{x_1^n\in\mathcal{X}_1^n}$ and 
$\Fset_2^{(m_2)}=\{ F^{(m_2)}_{x_2^n} \}_{x_2^n\in\Xset_2^n}$ on $E_1$ and $E_2$, respectively; and
\item
a decoding function   $g:\Yset^n\to [1:2^{nR_1}]\times [1:2^{nR_2}] $.
	%
%
 %
\end{itemize}
%We denote the code by $\mathscr{C}=(\Psi,\Fset_1,\Fset_2,g)$.
\end{definition}
The communication scheme is as in
Subsection~\ref{sec:Coding}
(see
%
Figure~\ref{fig:MentangledTx}).  
% The senders share the entangled pair  $E_1 E_2$. 
% Alice $k$ chooses a message $m_k$ according to a uniform distribution over $[1:2^{nR_k}]$, for $k=1,2$.
%  To send the message $m_1\in [1:2^{nR_1}]$,
% Alice 1 applies the encoding measurement $\Fset_1^{(m_1)}$ to her share of the entanglement resource, $E_1$, and obtains a measurement outcome $x_1^n\in\mathcal{X}_1^n$.
% She sends $x_1^n$ through $n$ uses of the classical MAC $P_{Y|X_1,X_2}$. %
% Similarly, Alice 2 measures the system $E_2$ using the measurement $\Fset_2^{(m_2)}$, and transmits the outcome $x_2^n$. 
%
%
% The joint input distribution is thus
% \begin{align}%
% f(x_1^n,x_2^n|m_1,m_2)
% = \trace \left[  \left(F^{(m_1)}_{x_1^n}\otimes F^{(m_2)}_{x_2^n} \right) \Psi_{E_1 E_2} \right] \,.
% \end{align}%
%
% Bob receives the channel output $y^n$, and estimates the message pair as $(\htm_1,\htm_2)=g(y^n)$.
% %
% %
% %
% The conditional probability of error of the code $\mathscr{C}=(\Psi,\Fset_1,\Fset_2,g)$ is
% \begin{align}
% &P_{e}^{(n)}(\mathscr{C}|m_1,m_2)= %
% \sum_{y^n: g(y^n)\neq (m_1,m_2)} \left[  \sum_{(x_1^n,x_2^n)\in \Xset_1^n\times \Xset_2^n} f(x_1^n,x_2^n|m_1,m_2) P_{Y|X_1,X_2}^n(y^n|x_1^n,x_2^n) \right] \,.
% \end{align}
% Hence, the average probability of error is 
% \begin{align}
% &P_{e}^{(n)}(\mathscr{C})= %
% \frac{1}{2^{n(R_1+R_2)}}\sum_{m_1=1}^{2^{nR_1}}\sum_{m_2=1}^{2^{nR_2}}    P_{e}^{(n)}(\mathscr{C}|m_1,m_2) \,.
% \end{align}
As before,
a $(2^{nR_1},2^{nR_2},n,\eps)$  code satisfies that the average probability of error is bounded by $\eps$. 
% $%
% P_{e}^{(n)}(\mathscr{C})\leq\eps $. %
%
%
%
%
A rate pair $(R_1,R_2)$ is said to be achievable with  an entanglement rate $\theta_E$    if for every $\eps>0$ and sufficiently large $n$, there exists a 
$(2^{nR_1},2^{nR_2},n,\eps)$ code such that the transmitters share entanglement resources at a rate $\theta_E$. 
%
%
 The  capacity region $\opC_{\text{ET}}(P_{Y|X_1,X_2},\theta_E)$ with rate-limited  entanglement between the transmitters
is defined as the set of achievable pairs $(R_1,R_2)$, with an  entanglement rate $\theta_E$ between the transmitters. %

We  note that by definition, the capacity region with unlimited entanglement between the transmitters is $\mathcal{C}_{\text{ET}}(\cdot)\equiv \mathcal{C}_{\text{ET}}(\cdot,+\infty)$.
Therefore, for every entanglement rate
$\theta_E>0$, we have
$\mathcal{C}_{\text{ET}}(\cdot,\theta_E)\subseteq
\mathcal{C}_{\text{ET}}(\cdot)$.

Based on the achievability proof in Section%
~\ref{app:etMAC} and Lemma~\ref{lemm:CardCl}, we obtain the following consequence.
\begin{corollary}
\label{coro:etMAC_Limited}
Let $\theta_E>0$ be a given entanglement rate.
A rate pair $(R_1,R_2)$ is achievable with entanglement at rate $\theta_E$ between the transmitters if 
\begin{align}%
%\mathcal{R}_{\text{ET}}(P_{Y|X_1,X_2})=
%\bigcup_{ p_{V_0} p_{V_1|V_0} p_{V_2|V_0} \,,\; \varphi_{A_1 A_2} \,,\; \Lset_1 \otimes \Lset_2 }
%\left\{ 
\begin{array}{rl}
%  (R_1,R_2) \,:\;
	R_1 &\leq I(V_1;Y|V_0 V_2)  \\
  R_2 &\leq I(V_2;Y|V_0 V_1) \\
	R_1+R_2 &\leq I(V_1 V_2;Y|V_0)
	\end{array}
%\right\}
\label{eq:inRetx_Limited}
\end{align}%
for a pure state $\ket{\phi_{A_1 A_2}}$
with entropy
\begin{align}
H(A_1)_\phi=H(A_2)_\phi\leq \theta_E \,,
\end{align}
some classical variables $(V_0,V_1,V_2)\sim p_{V_0} p_{V_1|V_0} p_{V_2|V_0}$, 
  and conditional measurement $\Lset_k(v_0,v_k)=\{L_k(x_k|v_0,v_k)\}_{x_k\in\Xset_k}$, for $v_0\in\Vset_0$, $v_k\in\Vset_k$, $k=1,2$. 
%
%
 \end{corollary}
%
%


% \begin{discussion*}
% For the applications in future communication systems mentioned in the introduction, it is important that the capacity region can also be used numerically as a basis for resource allocation. This requirement can be fulfilled by Corollary~\ref{coro:Sufficient_Entanglement}. Another practical requirement is the robust dependence of the communication system performance on the channel parameters. Corollary~\ref{coro:Sufficient_Entanglement} implies that the capacity region of the  MAC with pre-shared entanglement between the transmitters is continuously dependent on the channel matrix for finite alphabets. This result can be shown immediately with the representation of the capacity region in Corollary~\ref{coro:Sufficient_Entanglement} by adapting the proof technique from \cite{BocheSchaeferPoor:20p2}.
 % \end{discussion*}
%
%




\begin{table}
\renewcommand{\arraystretch}{1.3}
\caption{The magic square game: Deterministic strategies}
\label{Table:Magic_Classical}
\centering
\begin{tabular}{| c| c| c| }
\hline
 0 & 0 & 0 \\ 
\hline
 0 & 1 & 1 \\  
\hline
 1 & 0 & ?    \\
\hline
\end{tabular}
\end{table}

\begin{table}
\renewcommand{\arraystretch}{1.3}
\caption{The magic square game: Quantum strategies}
\label{Table:Magic_Quantum}
\centering
\begin{tabular}{| c| c| c| }
\hline
 $\mathsf{X}\otimes\identity$ & $\mathsf{X}\otimes \mathsf{X}$ & $\identity\otimes \mathsf{X}$ \\ 
\hline
 $-\mathsf{X}\otimes \mathsf{Z}$ & $\mathsf{Y}\otimes \mathsf{Y}$ & $-\mathsf{Z}\otimes \mathsf{X}$ \\  
\hline
 $\identity\otimes \mathsf{Z}$ & $\mathsf{Z}\otimes \mathsf{Z}$ & $\mathsf{Z}\otimes \identity$    \\
\hline
\end{tabular}
\end{table}


\subsection{Pseudo-Telepathy Example}
\label{Subsection:Magic_Example}
As an example, we consider two 
channels that were introduced by Leditzki et al.  \cite{LeditzkyAlhejjiLevinSmith:20p}.

\begin{example}[Magic-square channel]
\label{Example:Magic_Square}
The channel is defined in terms of a pseudo-telepathy game, i.e., a non-local game such that quantum strategies outperform classical strategies and guarantee winning with certainty. 
In the magic square game,  a referee selects one out of nine cells uniformly at random.
Suppose that the referee selected $(r,c)$.
Then, the referee informs Player 1 of the row index $r$, and Player 2 of the column index $c$.
Each player fills three bits in the respective row $r$ and column $c$. 
% 
In order to win the game, they need to satisfy three requirements: they agree on the bit value in $(r,c)$, the row $r$ has even parity, and the column $c$ has odd parity. 
Tables \ref{Table:Magic_Classical}
and \ref{Table:Magic_Quantum}
demonstrate 
 a classical strategy and a quantum strategy, respectively.
If the game is limited to a classical deterministic strategy, then winning is impossible. An attempt towards winning the game is shown in Table~\ref{Table:Magic_Classical}. 
Furthermore, using randomized strategies, the probability of winning is at most $\frac{8}{9}$.
On the other hand, it can be shown that the following quantum strategy wins the game with probability 1:
\begin{itemize}
\item
Before the game begins,
prepare the state
\begin{align}
\ket{\phi_{A_1' A_1'' A_2' A_2''}}=
\frac{1}{2}\left(
\ket{00} \ket{11}+\ket{11} \ket{00}- \ket{01} \ket{10} - \ket{10} \ket{01} \right) \,.
\label{eq:Magic_A1A2}
\end{align}
Send $A_1',A_1''$ to Player 1, and $A_2',A_2''$ to Player 2.  

\item
Play the game using the following strategy.
Having received the row and column indices, each player measures the observables in Table~\ref{Table:Magic_Quantum} simultaneously, and inserts the measurement outcomes into the corresponding cells, where
$\mathsf{X}$, $\mathsf{Y}$, and $\mathsf{Z}$ are the Pauli operators.
 The observables can be measured simultaneously because the three operators in each row and each column commute.
For example, if the referee selected $r=1$ and $c=2$, then Player 1 measures $\mathsf{X}\otimes\identity$, $\mathsf{X}\otimes \mathsf{X}$, and $\identity\otimes \mathsf{X}$, whereas Player 2 measures $\mathsf{X}\otimes \mathsf{X}$, $\mathsf{Y}\otimes \mathsf{Y}$, and $\mathsf{Z}\otimes \mathsf{Z}$.

\end{itemize}
Leditzki et al.  \cite{LeditzkyAlhejjiLevinSmith:20p} defined a MAC such that the channel is ideal for input strategies that win the game, and pure-noise otherwise. 
The precise definition is given below.


In the general description of the non-local game, a referee selects two questions $q_1\in\mathcal{Q}_1$ and $q_2\in\mathcal{Q}_2$ uniformly at random, and
sends the respective question to each player.
The players choose their respective answers $a_1\in\mathcal{A}_1$ and $a_2\in\mathcal{A}_2$ using either deterministic or random strategies $f_k:\mathcal{Q}_k\to \mathcal{A}_k$, for $k=1,2$.
The game is won if $(q_1,q_2,a_1,a_2)\in\mathscr{G}$, where $\mathscr{G}$ is the winning set.
The CHSH game and magic square game are special cases of this description.
%
Leditzki et al.  \cite{LeditzkyAlhejjiLevinSmith:20p} defined a classical MAC $P_{Y|X_1,X_2}$, with
\begin{align}
\Xset_k &=\mathcal{Q}_k\times \mathcal{A}_k \,,\; k=1,2\\
\Yset&= \mathcal{Q}_1\times \mathcal{Q}_2
\intertext{such that}
P_{Y|X_1,X_2}\big( (\hat{q}_1,\hat{q}_2) \,\big|  q_1,a_1,q_2,a_2  \big)&=
\begin{cases}
\delta_{q_1, \hat{q}_1} \delta_{q_2, \hat{q}_2} &\text{ if } (q_1,q_2,a_1,a_2)\in\mathscr{G}\,,\\
\frac{1}{|\mathcal{Q}_1| |\mathcal{Q}_2|} &\text{otherwise.}
\end{cases}
\label{Equation:MS_channel}
\end{align}
In words, if the inputs $X_1=(q_1,a_1)$ and $X_2=(q_2,a_2)$ win the game, then the decoder receives the question pair precisely, i.e.,
$Y=(q_1,q_2)$ with probability $1$. Otherwise, if the game is lost, then the output $Y$ is uniformly distributed over the question set.

Formally, the magic square game is specified by questions $(q_1,q_2)$ from $\{1,2,3\}\times \{1,2,3\}$,
answers $a_1,a_2$ from $\Aset_1=\Aset_2=\{ 0,1 \}^3$, and the winning set $\mathscr{G}=\big\{$ $\big( q_1,q_2, 
(a_1[j],a_2[j])_{j=1,2,3} \big)
\in\Qset_1\times\Qset_2\times\Aset_1\times\Aset_2:$ $a_1[q_1]=a_2[q_2]$,
 $ a_1[1]+ a_1[2] + a_1[3] \mod 2=0 $, and
 $a_2[1]+ a_2[2] + a_2[3] \mod 2=1$
$\big\}$. Without entanglement resources, the sum-rate  is bounded by \cite{SeshadriLeditzkySiddhuSmith:22c}
\begin{align}
R_1+R_2\leq 3.02 \,.
\end{align}
Based on \cite{LeditzkyAlhejjiLevinSmith:20p}, the sum rate $R_1+R_2=2\log(3)\approx 3.17$ is achievable with entangled transmitters.
This can also be obtained as a consequence of our result.
By Theorem~\ref{theo:etMAC}, the capacity region with entangled transmitters is given by 
\begin{align}
\mathcal{C}_{\text{ET}}(P_{Y|X_1,X_2})=
\left\{ \begin{array}{rl}
  (R_1,R_2) \,:\;
	&R_1 \leq \log(3)  \\
  &R_2 \leq \log(3) 
	\end{array}
\right\} \,.
\label{eq:Cet_Magic}
\end{align}
To see why, consider the region in (\ref{eq:inRetx}). The converse part is immediate since 
the set on the right hand side of (\ref{eq:Cet_Magic}) is the capacity region of the noiseless MAC
$\widetilde{P}_{Y|X_1,X_2}\big( (\hat{q}_1,\hat{q}_2) \,\big|  q_1,a_1,q_2,a_2  \big)=\delta_{q_1, \hat{q}_1} \delta_{q_2, \hat{q}_2}$ (with or without entanglement resources).
%the classical conditional mutual information is bounded by $I(X;Y|Z)\leq \log|\Xset|$.
%
As for the direct part, we choose an entangled state, classical variables, and POVMs as follows. Let the entangled state $\ket{\phi_{A_1 A_2}}$ be as in (\ref{eq:Magic_A1A2}), where
$A_k\equiv A_k' A_k''$ for $k=1,2$.
Furthremore, we let $\Vset_0=\emptyset$ and set the joint distribution $p_{V_k}$ to be uniform over $\Vset_k=\{1,2,3\}$, for $k=1,2$.
Thus, the random pair $(V_1,V_2)$ is distributed as the referee's questions.
Given $V_k$, Alice $k$ performs a measurement $\Lset_k(V_k)$ as follows. Alice 1 measures the observables in row number $r=V_1$ in Table~\ref{Table:Magic_Quantum},  obtains a random triplet
$W_1\equiv (a_1[j])_{j=1,2,3}$, and transmits $X_1=(V_1,W_1)$.
Similarly, Alice 2 measures the observables in column number $c=V_2$,  obtains 
$W_2\equiv (a_2[j])_{j=1,2,3}$, and transmits $X_2=(V_2,W_2)$. Since $(V_1,V_2,W_1,W_2)$ win the game, we have $Y=(V_1,V_2)$  with probability 1, hence
$I(V_1 V_2;Y)=H(V_1 V_2)=2\log(3)$, $I(V_1;Y|V_2)=H(V_1)=\log(3)$, and $I(V_2;Y|V_1)=H(V_2)=\log(3)$.
This requires an entanglement rate of 
$\theta_E=2$ qubit pairs per transmission.
\end{example}

\begin{example}[Slofstra-Vidick channel]
\label{Example:Slofstra_Vidick}
Another example by Leditzki et al.  \cite{LeditzkyAlhejjiLevinSmith:20p} is  defined in terms of the following non-local game.
Consider a linear system of equations, $\mathbf{H}\mathbf{x}=\mathbf{b}$, over $\mathrm{GF}(2)$, with fixed $\mathbf{H}$ and $\mathbf{b}$, where $\mathbf{H}$ is a  
 binary matrix of size $K\times N$, and $\mathbf{b}$ is a binary vector of length $K$.
That is, the system consists of 
$K$ equations of the form
\begin{align}
\mathbf{h}_k\cdot\,\mathbf{x}=
b_k 
\label{Equation:k_row}
\end{align}
for $k\in \{1,\ldots,K\}$,
where $\mathbf{h}_k$ is the $k$th row in $\mathbf{H}$.
%
% Let $J_k$ be the set of indices of variables that appear in the
% $k$th equation, i.e.,
% \begin{align}
% J_k=\{ \ell\in [1:N] \,:\; H[k,\ell]=1
%  \}
% \end{align}

 
In the linear-system game \cite{SlofstraVidick:18p},  a referee selects two indices, an equation index 
$k\in \{1,\ldots,K\}$ and a variable index $j\in\{ 1,\ldots,N \}$, 
uniformly at random.
Then, the referee informs Player 1 of the index $k$, and Player 2 of the index $j$.
Player 1 responds with a vector
$\mathbf{a}_1 \in \{0,1\}^N$, which is interpreted as an assignment for 
$\mathbf{x}$,
 and  Player 2 responds with a single  bit
$a_2\in\{0,1\}$ that is interpreted as the value of $\mathbf{x}[j]$.
% 
In order to win the game, they need to satisfy two requirements:
\begin{enumerate}[1)]
\item
The response of Player 1 satisfies the $k$th equation. That is, (\ref{Equation:k_row}) holds for
%$\mathbf{H}^{(k)}\cdot\mathbf{x}=\mathbf{b}[k]$ for 
$\mathbf{x}=\mathbf{a}_1$.

\item
Their responses satisfy
$\mathbf{H}[k,j]\cdot(\mathbf{a}_1[j]-a_2)=0$.
That is, either the $j$th variable is not included in the $k$th equation
(i.e., $\mathbf{H}[k,j]=0$), or the players must agree on the value of 
$\mathbf{x}[j]$ (namely, $\mathbf{a}_1[j]=a_2$).
\end{enumerate}
Suppose that the players share entangled systems of dimension $d_E$.
Slofstra and Vidick \cite{SlofstraVidick:18p} showed that quantum strategies outperform classical strategies in this game.
However, the minimal entanglement dimension $d_{E,\min}$ that is required 
in order to win the game with a probability of 
$1-e^{-T}$ is bounded by
\begin{align}
Ce^{T/6}%\frac{C}{\alpha^{1/6}}
\leq d_{E,\min}\leq
C' e^{T/2} %\frac{C'}{\alpha^{1/2}}
\label{Equation:SV_dimension}
\end{align}
for all $T>0$, where $C,C'$ are positive constants.
It follows that the game can be won with certainty for
$d_E\to \infty$, and cannot be won with certainty if the entanglement dimension is bounded.


Leditzki et al.  \cite{LeditzkyAlhejjiLevinSmith:20p} considered a classical MAC $P_{Y|X_1,X_2}$ defined as in
(\ref{Equation:MS_channel}), where $\mathscr{G}$ is the winning set for the Slofstra-Vidick game \cite{SlofstraVidick:18p}, as described above,
where $\mathcal{Q}_1=\{1,\ldots,K\}$,
$\mathcal{Q}_2=\{1,\ldots,N\}$,
$\mathcal{A}_1=\{0,1\}^N$, and
$\mathcal{A}_2=\{0,1\}$.
%
As before, if the inputs $X_1=(q_1,\mathbf{a}_1)$ and $X_2=(q_2,a_2)$ win the game, then the decoder receives the question pair precisely, i.e.,
$Y=(q_1,q_2)$ with probability $1$. Otherwise, if the game is lost, then the output $Y$ is uniformly distributed over the question set.
%
The capacity region of the classical MAC with unlimited entanglement resources between the transmitters is given by  \cite{LeditzkyAlhejjiLevinSmith:20p}
\begin{align}
\mathcal{C}_{\text{ET}}(P_{Y|X_1,X_2})=
\left\{ \begin{array}{rl}
  (R_1,R_2) \,:\;
	&R_1 \leq \log(K)  \\
  &R_2 \leq \log(N) 
	\end{array}
\right\} \,.
\label{eq:Cet_SV}
\end{align}
This result can also be obtained from Theorem~\ref{theo:etMAC} following similar arguments as in Example~\ref{Example:Magic_Square}.

Furthermore, we obtain an achievable rate region with entanglement resources at a limited rate.
%
By Lemma~\ref{coro:etMAC_Limited}, we have that a rate pair $(R_1,R_2)$ is achievable given entanglement resources at a limited rate of 
$\theta_E=\frac{1}{2}T+\log(C')$, if
\begin{align*}
R_1 &\leq \left( 1-4e^{-T} \right)\log(K)-2(1+e^{-T})h_2\left(
\frac{e^{-T}}{1+e^{-T}}
\right) \,,
\\
R_2 &\leq \left( 1-4e^{-T} \right)\log(N)-2(1+e^{-T})h_2\left(
\frac{e^{-T}}{1+e^{-T}}
\right)
\end{align*}
for all $T>0$,
where $h_2(p)=-p\log(p)-(1-p)\log(1-p)$ is the binary entropy function over $(0,1)$.
To show this, we use the
Slofstra-Vidick bound in
(\ref{Equation:SV_dimension}), along with entropy continuity bounds
(see \cite[Th. 1.1]{SlofstraVidick:18p} and \cite[Sec. 11.10]{Wilde:17b}).






\end{example}

% \section*{Acknowledgment}
% U. Pereg was supported by the Israel VATAT Junior Faculty Program for Quantum Science and Technology through Grant 86636903, and the Chaya Career Advancement Chair, Grant 8776026.
%  C. Deppe and H. Boche were supported by
% %
% the German Federal
% Ministry of Education and Research (BMBF) through Grants
% 16KISQ028 (Deppe) and 16KISQ020 %
% (Boche). 
% This work of H. Boche was supported in part by the BMBF within the national initiative for
% ``Post Shannon Communication (NewCom)" under Grant 16KIS1003K, and in
% part by the DFG within the Gottfried Wilhelm
% Leibniz Prize under Grant BO 1734/20-1 and within Germany's Excellence
% Strategy EXC-2092 – 390781972 and EXC-2111 – 390814868. 
% U. Pereg was also supported by the Helen Diller Quantum Center at the Technion.



%\begin{appendices}




\section{Proof of Lemma~\ref{lemm:CardCl} %(Purification and Cardinality Bounds)
}
\label{app:CardCl}
In this section, we prove Lemma~\ref{lemm:CardCl} and show that the region $\mathcal{R}_{\text{ET}}(P_{Y|X_1,X_2})$ can be exhausted with pure states and bounded cardinality.

\subsection{Purification}
First, we consider a given Hilbert space
$\Hset_{A_1}\otimes \Hset_{A_2}$, and
show that the union over entangled states $\varphi_{A_1 A_2}$ is exhausted by pure states.
Fix a Hilbert space $\Hset_{A_1}\otimes \Hset_{A_2}$.
Consider a given distribution $\{ p_{V_1|V_0}(\cdot|v_0)p_{V_2|V_0}(\cdot|v_0)\}$, an entangled state 
$\varphi_{A_1 A_2}$, and measurements $\Lset_1(v_0,v_1)$ and $\Lset_2(v_0,v_2)$ on $A_1$ and $A_2$, respectively.
Let $\mathfrak{R}(\varphi,\Lset_1,\Lset_2)$ denote the associated rate region,
\begin{align}%
\mathfrak{R}(\varphi,\Lset_1,\Lset_2)=
%\bigcup_{ p_{V_0} p_{V_1|V_0} p_{V_2|V_0} \,,\; \varphi_{A_1 A_2} \,,\; \Lset_1 \otimes \Lset_2 }
\left\{ \begin{array}{rl}
  (R_1,R_2) \,:\;
	R_1 &\leq I(V_1;Y|V_0 V_2)  \\
  R_2 &\leq I(V_2;Y|V_0 V_1) \\
	R_1+R_2 &\leq I(V_1 V_2;Y|V_0)
	\end{array}
\right\} \,.
\label{eq:inRphi}
\end{align}%
%
%
Given a joint state $\varphi_{A_1 A_2}$,
consider a spectral decomposition,
\begin{align}
\varphi_{A_1 A_2}=\sum_{z\in\Zset} p_Z(z) \ketbra{ \phi_z }_{A_1 A_2} \,,
\label{eq:Cardinality_Spectral}
\end{align}
where $p_Z$ is a probability distribution, such that the pure states, $\ket{\phi_z}_{A_1 A_2}$, $z\in\Zset$, form an orthonormal basis for 
$\Hset_{A_1} \otimes \Hset_{A_2}$.
Then, $\varphi_{A_1 A_2}$ has the following purification,
\begin{align}
\ket{\psi_{A_1 A_2 E_1 E_2}}= \sum_{z\in\Zset} \sqrt{p_Z(z)} \ket{ \phi_z }_{A_1 A_2}\otimes \ket{z}_{E_1} \otimes \ket{z}_{E_2}
\,.
\end{align}
Now, we consider rate region $\mathfrak{R}(\psi,\Lset_1',\Lset_2')$ that is associated with the following choice of state, distribution, and measurements.
Set the distribution $\{ p_{V_1|V_0}(\cdot|v_0)p_{V_2|V_0}(\cdot|v_0)\}$ as before. Let
Alice 1 and Alice 2 share the state $\ket{\psi_{A_1 E_1 A_2  E_2}}$, and 
suppose that Alice 1 performs a measurement on $(A_1,E_1)$, and Alice 2 on $(A_2,E_2)$, with the following POVMs,
\begin{align}
L_1'(x_1,z|v_0,v_1)&= L(x_1|v_0,v_1)\otimes \ketbra{z}_{E_1} \,,\\
L_2'(x_2,z|v_0,v_2)&= L(x_2|v_0,v_2)\otimes \ketbra{z}_{E_2} \,,
\end{align}
for $(v_0,v_1,v_2,x_1,x_2,z)\in \Vset_0\times\Vset_1\times\Vset_2\times\Xset_1\times\Xset_2\times \Zset$.
The corresponding input distribution $p'_{X_1,X_2|V_0,V_1,V_2}$ is given by
\begin{align}
p'_{X_1,X_2|V_0,V_1,V_2}(x_1,x_2|v_0,v_1,v_2)&=
\sum_{z\in\Zset} p_Z(z) \trace\left[ \left( L_1(x_1|v_0,v_1)\otimes L_2(x_2|v_0,v_2) \right) \ketbra{ \phi_z }_{A_1 A_2}  \right]
\\
&=
 \trace\left[ \left( L_1(x_1|v_0,v_1)\otimes L_2(x_2|v_0,v_2) \right)\left(\sum_{z\in\Zset}  p_Z(z)\ketbra{ \phi_z }_{A_1 A_2} \right) \right]
\\
&=
 \trace\left[ \left( L_1(x_1|v_0,v_1)\otimes L_2(x_2|v_0,v_2) \right)\varphi_{A_1 A_2} \right]
\\
&=
p_{X_1,X_2|V_0,V_1,V_2}(x_1,x_2|v_0,v_1,v_2)
\end{align}
where the third equality follows from (\ref{eq:Cardinality_Spectral}), and the last from (\ref{eq:inRsc_Distribution}).
Therefore, $\mathfrak{R}(\psi,\Lset_1',\Lset_2')=\mathfrak{R}(\varphi,\Lset_1,\Lset_2)$.
We deduce that the entire region $\mathcal{R}_{\text{ET}}(P_{Y|X_1,X_2})$, as in (\ref{eq:inRetx}), can be obtained from pure states.

 
\subsection{Cardinality Bounds}
Next, we bound the cardinality of the alphabet $\Vset_0$. Consider a given distribution $\{ p_{V_1|V_0}(\cdot|v_0)p_{V_2|V_0}(\cdot|v_0)\}$, a joint state 
$\varphi_{A_1 A_2}$, and POVM collections, $\Lset_1(v_0,v_1)$ and $\Lset_2(v_0,v_2)$.
%
%
Define a map $\tau_0:\Vset_0\rightarrow \mathbb{R}^{3}$ by
\begin{align}%
\tau_{0}(v_0)= \Big(  %
   I(V_1;Y|V_2, V_0=v_0)   \,,\; I(V_2;Y|V_1, V_0=v_0)  \,,\; I(V_1, V_2;Y|V_0=v_0)  \Big) \,.
\end{align}%
%
The map $\tau_0$ can be extended to a map that  acts on probability distributions as follows,
\begin{align}%
T_{0} \,:\; p_{V_0}(\cdot)  \mapsto
\sum_{v_0\in\Vset_0} p_{V_0}(v_0) \tau_{0}(v_0)= \Big(  I(V_1;Y|V_0 V_2) \,,\; I(V_2;Y|V_0 V_1)   \,,\; I(V_1 V_2;Y|V_0 )   \Big)  \,.
\end{align}%
According to the Fenchel-Eggleston-Carath\'eodory lemma \cite{Eggleston:66p}, any point in the convex closure of a connected compact set within $\mathbb{R}^d$ belongs to the convex hull of $d$ points in the set. 
Since the map $T_{0}$ is linear, it maps  the set of distributions on $\Vset_0$ to a connected compact set in $\mathbb{R}^{3}$. %
Thus, for every  $p_{V_0}$, 
there exists a probability distribution $p_{\bar{V}_0}$ on a subset $\bar{\Vset}_0\subseteq \Vset_0$ of size $%
3$, such that 
$%
T_{0}(p_{{\bar{V}_0}})=T_{0}(p_{V_0}) %
$. %
We deduce that alphabet size can be restricted to $|\Vset_0|\leq 3$, while preserving $I(V_1;Y|V_0 V_2)$, $ I(V_2;Y|V_0 V_1)$, and $I(V_1 V_2;Y|V_0 )$. 

Next, we bound the alphabet size for the auxiliary variables $V_1$ and $V_2$.
Every probability distribution $p_X$ can be represented by %
%
 $|\Xset|-1$ parameters. 
%
%
Then, for every $v_0\in\Vset_0$, define a map $\tau_{12|v_0}:\Vset_1\times \Vset_2\rightarrow \mathbb{R}^{|\Xset_1| |\Xset_2|+2}$ by
\begin{multline}%
\tau_{12|v_0}(v_1,v_2)= \Big(  (p_{X_1,X_2|V_0,V_1,V_2}(\cdot|v_0,v_1,v_2)) \,,\; H(Y|V_0=v_0,V_1=v_1)  \,,\; \\
H(Y|V_0=v_0,V_2=v_2)  \,,\; H(Y|V_0=v_0,V_1=v_1,V_2=v_2)      \Big) \,,
\end{multline}%
where $p_{X_1,X_2|V_0,V_1,V_2}(x_1,x_2|v_0,v_1,v_2)=\trace\left[ (L_1(x_1|v_0,v_1)\otimes L_2(x_2|v_0,v_2)) \varphi_{A_1 A_2} \right]$.
Then, the map $\tau_{12|v_0}$ is extended to %
\begin{align}%
T_{12|v_0} \,:\; p_{V_1,V_2|V_0}(\cdot|v_0)  \mapsto &
\sum_{(v_1,v_2)\in\Vset_1\times \Vset_2} p_{V_1,V_2|V_0}(v_1,v_2|v_0) \tau_{12|v_0}(v_1,v_2)= \nonumber\\& \Big(  
(p_{X_1,X_2|V_0}(\cdot|v_0)) \,,\;  H(Y|V_0=v_0,V_1) \,,\;  H(Y|V_0=v_0,V_2)  \,,\; H(Y|V_0=v_0,V_1,V_2)   \Big) %
\end{align}%
with
\begin{align}
p_{X_1,X_2|V_0}(x_1,x_2|v_0)\equiv \sum_{v_1,v_2}  p_{V_1|V_0}(v_1|v_0) p_{V_2|V_0}(v_2|v_0)\trace\left[ (L_1(x_1|v_0,v_1)\otimes L_2(x_2|v_0,v_2)) \varphi_{A_1 A_2} \right] \,.
\label{eq:thetaU}
\end{align} 
Thus, by the Fenchel-Eggleston-Carath\'eodory lemma \cite{Eggleston:66p}, for every  $p_{V_1,V_2|V_0}(\cdot|v_0)$, 
there exists a probability distribution $p_{\bar{V}_1,\bar{V}_2|V_0}(\cdot|v_0)$ on a subset $\bar{\Vset}_1\times \bar{\Vset}_2\subseteq \Vset_1\times \Vset_2$ of size $%
|\Xset_1| |\Xset_2|+2$, such that 
$%
F_{12|v_0}(p_{{\bar{V}_1,\bar{V}_2|V_0}}(\cdot|v_0))=F_{12|v_0}(p_{V_1,V_2|V_0}(\cdot|v_0))) %
$. %
We deduce that alphabet size can be restricted to $|\Vset_k|\leq 3(|\Xset_1| |\Xset_2|+2)$, while preserving  $H(Y|V_0 V_1)$, $H(Y|V_0 V_2)$, 
$H(Y|V_0 V_1 V_2)$,  and  $p_{X_1,X_2|V_0}$.
%
%
%
 This implies that the distribution $p_{X_1,X_2,Y|V_0}(x_1,x_2,y|v_0)=p_{X_1,X_2|V_0}(x_1,x_2|v_0) P_{Y|X_1,X_2}(y|x_1,x_2)$ remains the same, and so do $H(Y|V_0)$, $I(V_1;Y|V_0 V_2)=
H(Y|V_0 V_2)-H(Y|V_0 V_1 V_2)$, and $I(V_2;Y|V_0 V_1)=
H(Y|V_0 V_1)-H(Y|V_0 V_1 V_2)$, as well as
 $H(Y|V_0)$, $I(V_1 V_2;Y|V_0)=H(Y|V_0)-H(Y|V_0 V_1 V_2)$.
%
%
 This completes the proof for the cardinality bounds.
\qed










\section{Proof of Theorem~\ref{theo:etMAC}}
\label{app:etMAC}
Consider the classical MAC $P_{Y|X_1,X_2}$ with entanglement resources between the transmitters.

\subsection{Achievability Proof}
We show that for every $\delta_1,\delta_2,\eps_0>0$, there exists a $(2^{n(R_1-\delta_1)},2^{n(R_2-\delta_2)},n,\eps_0)$ code for $P_{Y|X_1,X_2}$ with entangled transmitters, provided that $(R_1,R_2)\in \mathcal{R}_{\text{ET}}(P_{Y|X_1,X_2})$. 
To prove achievability, we use coded time sharing.





%
Fix a joint distribution $p_{V_0} p_{V_1|V_0} p_{V_2|V_0}$, an entangled state $\varphi_{A_1 A_2}$, and collection of POVMs $\Lset_k(v_0,v_k)=\{ L_k(x_k|v_0,v_k) \}$ for $k=1,2$. 
Suppose that Alice 1 and Alice 2 share an $n$ copies of the  entangled state, 
\begin{align}
\varphi_{A_1^n A_2^n}\equiv \varphi_{A_1 A_2}^{\otimes n} \,.
\end{align}
%
%\vspace{0.2cm}
%
%
The code construction, encoding with shared entanglement, and decoding procedures are described below.

\vspace{0.2cm}
\subsubsection{Code Construction}
Select a random time-sharing sequence $v_0^n$, according to an i.i.d. distribution, $\prod_{i=1}^n p_{V_0}(v_{0,i})$. Furthermore, select
$2^{nR_1}$ conditionally independent sequences, $v_1^n(m_1)$, $m_1\in [1:2^{nR_1}]$,  each distributed as 
$\prod_{i=1}^n p_{V_1|V_0}\big(v_{1}[i] \,\big| v_{0}[i] \big)$.
In a similar manner,
select
$2^{nR_2}$ sequences,  $v_2^n(m_2)$, %$m_2\in [1:2^{nR_2}]$,    
according to  $\prod_{i=1}^n p_{V_2|V_0}\big(v_{2}[i] \,\big| v_{0}[i] \big)$.

%
%
The auxiliary codebooks above are revealed to Alice 1, Alice 2, and Bob.

\vspace{0.2cm}
\subsubsection{Encoder k}
%
%
Given the message $m_k\in [1:2^{nR_k}]$ and the codebooks above,  perform the measurement $\bigotimes_{i=1}^n\left(
\Lset_k\big(v_{0}[i],v_{k}[i] \big) \right)$ on the entangled system $A_k^n$, and transmit the measurement outcome $x_k^n$ through the channel, for $k=1,2$. 

This yields the following input distribution,
\begin{align}
f(x_1^n,x_2^n|m_1,m_2)&=  \trace\left[ \left( L_1^n\big(x_1^n \,\big| v_0^n,v_1^n(m_1) \big) \otimes 
L_2^n \big( x_2^n \,\big| v_0^n,v_2^n(m_2) \big)   \right)  
\varphi_{A_1^n A_2^n}
  \right]
\nonumber\\
&= \prod_{i=1}^n  \trace\left[ \left( L_1\big( x_{1}[i] \,\big| v_{0}[i],v_{1}(m_1)[i] \big) \otimes 
L_2\big( x_{2}[i] \,\big| v_{0}[i],v_{2}(m_2)[i] \big)   \right)  
\varphi_{A_1 A_2}
  \right]	
	\,,
%
\end{align}
where we use the short notations  $L_k^n\big( x_k^n \,\big| v_0^n,v_k^n \big)\equiv 
\bigotimes_{i=1}^n L_k \big( x_{k}[i] \,\big| v_{0}[i],v_{k}[i] \big)  $, 
for $k=1,2$. %
%

\vspace{0.2cm}
\subsubsection{Decoder}
%
%
Let $\delta>0$.
Find a unique pair $(\hm_1,\hm_2)$ such that $(v_0^n,v_1^n(\hm_1),v_2^n(\hm_2),y^n)\in\Aset_\delta^{(n)}(p_{V_0,V_1, V_2, Y})$, where the marginal distribution $p_{V_0,V_1, V_2, Y}$ 
 is induced by the following joint distribution,
\begin{multline}
p_{V_0,V_1,V_2,X_1,X_2,Y}(v_0,v_1,v_2,x_1,x_2,y)= p_{V_0}(v_0) p_{V_1|V_0}(v_1|v_0) p_{V_2|V_0}(v_2|v_0)\\ \cdot \trace\left[ \left( L_1(x_{1}|v_0,v_{1}) \otimes L_2(x_{2}|v_0,v_{2})   \right) \varphi_{A_1 A_2}
  \right]
		\cdot P_{Y|X_1,X_2}(y|x_1,x_2) \,.
	\label{eq:DirectJointDistribution}
\end{multline}

%
%

\vspace{0.2cm}
\subsubsection{Analysis of Probability of Error}
 We use the notation $\eps_i(\delta)$, $i=1,2,\ldots$,
for terms that tend to zero as $\delta\rightarrow 0$.
%
At first, suppose that the messages are chosen at random according to a uniform distribution.
By symmetry, we may assume without loss of generality that the transmitters send the messages $M_1=M_2=1$.
Consider the following error events,
\begin{align}
%
\mathscr{E}_0=& \{  (V_0^n,V_1^n(1),V_2^n(1),Y^n)\notin \Aset_{\delta_1}^{(n)}(p_{V_0,V_1,V_2,Y}) \} \\
\mathscr{E}_1=& \{  (V_0^n,V_1^n(m_1),V_2^n(1),Y^n)\in \Aset_{\delta}^{(n)}(p_{V_0,V_1,V_2,Y})\text{, for some $m_1\neq 1$}  \}\\
\mathscr{E}_2=& \{  (V_0^n,V_1^n(1),V_2^n(m_2),Y^n)\in \Aset_{\delta}^{(n)}(p_{V_0,V_1,V_2,Y})\text{, for some $m_2\neq 1$}  \}\\
\mathscr{E}_3=& \{  (V_0^n,V_1^n(m_1),V_2^n(m_2),Y^n)\in \Aset_{\delta}^{(n)}(p_{V_0,V_1,V_2,Y})\text{, for some $m_1\neq 1$ and $m_2\neq 1$}  \}
\end{align}
 with $\delta_1\equiv \delta/(2 |\Vset_0| |\Vset_1| |\Vset_2|)$.
By the union of events bound, the expected probability of error is bounded by
\begin{align}
\mathbb{E}\left[
P_{e}^{(n)}(\mathscr{C}|1,1)\right] %
&\leq %
 \prob{ \mathscr{E}_0 }%
+ \cprob{ \mathscr{E}_1 }{ \mathscr{E}_0^c }
+ \cprob{ \mathscr{E}_2 }{ \mathscr{E}_0^c }
+ \cprob{ \mathscr{E}_3 }{ \mathscr{E}_0^c } 
\label{eq:PeBsc}
\end{align}
where the expectation on the left-hand side is with respect to the random auxiliary codebooks, and
%
the conditioning on $M_1=M_2=1$ is omitted from the right-hand side for convenience of notation.
Observe that the (classical) codewords $V_0^n$, $V_1^n(1)$, $V_2^n(1)$,  channel inputs $X_1^n$, $X_2^n$, and channel output $Y^n$, are jointly i.i.d. according to $p_{V_0,V_1,V_2,X_1,X_2,Y}$, as in (\ref{eq:DirectJointDistribution}).
Hence,
%
by the weak law of large numbers, the first probability term, $\prob{ \mathscr{E}_0 }$, tends to zero as $n\rightarrow\infty$
\cite{CsiszarKorner:82b} \cite[Th. 1.1]{Kramer:08n}.
%

As for the second error term, we have by the union bound:
\begin{align}
\cprob{ \mathscr{E}_1 }{ \mathscr{E}_0^c }\leq 
\sum_{m_1\neq 1} \cprob{(V_0^n,V_1^n(m_1),V_2^n(1),Y^n)\in \Aset_{\delta}^{(n)}(p_{V_1,V_2,Y})}{ \mathscr{E}_0^c } \,.
\label{eq:E1bound1}
\end{align}
%
 Given $\mathscr{E}_0^c$, it follows that $(V_0^n,V_2^n(1))\in \Aset^{\delta}(p_{V_2}) $. %
Thus, each summand %probability term 
is bounded by
\begin{align}
%
\sum_{(v_0^n,v_2^n)\in \Aset_{\delta}^{(n)}(p_{V_0,V_2})} p_{V_0,V_2}^n(v_0^n,v_2^n) \left[
\sum_{v_1^n,y^n \,:\; (v_0^n,v_1^n,v_2^n,y^n)\in \Aset_{\delta}^{(n)}(p_{V_0,V_1,V_2,Y})}
p_{V_1|V_0}^n(v_1^n|v_0^n)\cdot p_{Y^n|V_0^n,V_2^n}(y^n|v_0^n,v_2^n) \right]
\end{align}
since for every $m_1\neq 1$, the codeword $V_1^n(m_1)$ is conditionally independent of the sequence pair $(V_2^n(1),Y^n)$, given $V_0^n=v_0^n$. 
Then, by standard method-of-types arguments,
the sum within the square brackets is bounded by $2^{-n(I(V_1;Y|V_0 V_2)-\eps_1(\delta))}$ 
\cite{CsiszarKorner:82b} \cite[Th. 1.3]{Kramer:08n}. %(see Lemmas 2.5 and 2.13 in \cite{CsiszarKorner:82b}). 
Hence, by (\ref{eq:E1bound1}),
%
\begin{align}
\cprob{ \mathscr{E}_1 }{ \mathscr{E}_0^c }\leq 
2^{-n[I(V_1;Y|V_0 V_2)-R_1-\eps_1(\delta)]} \,.
\label{eq:E1bound2}
\end{align}
Thereby, the term $\cprob{ \mathscr{E}_1 }{ \mathscr{E}_0^c }$  tends to zero as $n\to\infty$, provided that 
\begin{align}
R_1<I(V_1;Y|V_0 V_2)-\eps_1(\delta) \,.
\end{align}
Following similar arguments, the probability terms $ \cprob{ \mathscr{E}_2 }{ \mathscr{E}_0^c }$ and
$ \cprob{ \mathscr{E}_3 }{ \mathscr{E}_0^c } $ also tend to zero, provided that
\begin{align}
R_2<I(V_2;Y|V_0 V_1)-\eps_2(\delta)
\intertext{and}
R_1+R_2<I(V_1 V_2;Y|V_0)-\eps_3(\delta)
 \,.
\end{align}
%
%
We conclude that the average probability of error, $\mathbb{E}\left[\overline{P}_e^{(n)}(\code)\right]$, averaged over the messages and the class of random codebooks above, tends to zero as $n\to\infty$ (see (\ref{Equation:Message_Avg_Error})).
Therefore, there must exist a $(2^{nR_1},2^{nR_2},n)$ code such that the message-average error probability, as defined in (\ref{Equation:Message_Avg_Error}), is bounded by 
$\overline{P}_e^{(n)}(\code)< \frac{1}{9}\varepsilon_0$, for a sufficiently large $n$. Based on the arguments in \cite{Cai:14p}, it follows that the rate pair $(R_1,R_2)$ is also achievable with a maximal error criterion, i.e., such that $P_e^{(n)}(\code)\leq \varepsilon_0$.
For completeness, we show this in the appendix.
This completes the achievability proof.

\subsection{Converse Proof}
Consider the classical MAC with entanglement resources between the transmitters. 
%
We now show the converse part. 
%
 Suppose that Alice 1 and Alice 2 share an entangled state $\Psi_{E_1 E_2}$. Then, Alice $k$ chooses a message $m_k$, uniformly at random from $[1:2^{nR_k}]$, for $k=1,2$. 
%
%
She encodes her message by performing a measurement $\Fset_k^{(m_k)}=\{ F_{x_k^n}^{(m_k)} \}$ on her share of the entangled resources, $E_k$, and sends the measurement outcome $X_k^n$ over the channel. 
%
%
 Bob receives the output $Y^n$ and finds an estimate $(\hm_1,\hm_2)=g(Y^n)$ of the message pair.

Now, consider a sequence of codes $(\Psi_n,\Fset_{1n},\Fset_{2n},g_n)$ such that the average probability of error tends to zero, hence
the error probabilities $\prob{ \hm_1\neq m_1 |m_2}$, $\prob{ \hm_2\neq m_2 |m_1}$, and $\prob{ (\hm_1,\hm_2)\neq (m_1,m_2)}$,  are bounded by some
$\alpha_n$ which tends to zero as $n\rightarrow \infty$.
%
%
By Fano's inequality \cite{CoverThomas:06b}, it follows that%
\begin{align}
H(m_1|\hm_1,m_2) &\leq n\eps_{1n}\,,\\
H(m_2|\hm_2,m_1) &\leq n\eps_{2n}\,,\\
H(m_1,m_2|\hm_1,\hm_2) &\leq n\eps_{3n}
\label{eq:AFWC2c}
\end{align}
where $\eps_{k\,n}$ tend to zero as $n\rightarrow\infty$.
Hence, 
\begin{align}
%
nR_1&= H(m_1|m_2)=I(m_1;\hm_1|m_2)+H(m_1|\hm_1 m_2) 
\nonumber\\
&\leq I(m_1;\hm_1|m_2)+n\eps_{1n} \nonumber\\
&\leq I(m_1;Y^n |m_2)+n\eps_{1n}
\label{eq:ConvIneq1SC}
\end{align}
where the last inequality follows from the data processing inequality. Applying the chain rule, we can rewrite this %inequality 
as
\begin{align}
%
n(R_1-\eps_{1n})
&\leq \sum_{i=1}^n I\left(m_1;Y[i] \,\big|\; Y^{i-1}, m_2 \right) \,. %\nonumber\\
%&\leq \sum_{i=1}^n I(m_1 Y^{i-1};Y_i ) \nonumber\\
%&\leq \sum_{i=1}^n I(m_1 X_1^{i-1} X_2^{i-1};Y_i ) 
\label{eq:ConvIneq1}
\end{align}
where $Y^{i-1}\equiv Y[1],\ldots,Y[i-1]$,
for $i=2,\ldots,n$, and $Y^0\equiv \emptyset$.
Define $V_{0}[i]\equiv Y^{i-1}$, $V_{1}[i]=(m_1,Y^{i-1})$, and $V_{2}[i]=(m_2,Y^{i-1})$, for $i=1,\ldots,n$.
Notice that $V_{1}[i]$ and $V_{2}[i]$ are  conditionally independent given $V_{0}[i]$.




Furthermore, since \mbox{Alice 1} performs a measurement that depends on her message $m_1$ alone, and similarly for \mbox{Alice 2},
the channel inputs $X_{1}[i]$ and $X_2[i]$ can also be obtained as the output of a measurement  as defined below.
Consider a measurement channel
\begin{align}
\Lambda^{(i,m_1)}_{E_1\to X_1}\otimes 
\Gamma^{(i,m_2)}_{E_2\to X_2}
\end{align}
such that 
\begin{align}
\Lambda^{(i,m_1)}_{E_1\to X_1}(S')&=
\sum_{a_1\in\mathcal{X}_1}
\Bigg[ \sum\limits_{x_1^n\in\Xset_1^n\,:\; x_1[i]=a_1} \trace\left( F_{x_1^n}^{(m_1)}S' \right) \Bigg]
\ketbra{a_1}
\\
\Gamma^{(i,m_2)}_{E_2\to X_2}(S'')&=
\sum_{a_2\in\mathcal{X}_2}
\Bigg[ \sum\limits_{x_2^n\in\Xset_2^n\,:\; x_2[i]=a_2} \trace\left( F_{x_2^n}^{(m_2)}S'' \right) \Bigg]
\ketbra{a_2}
\end{align}
for every pair of operators $S'$ and $S''$ on $\Hset_{E_1}$
and $\Hset_{E_2}$, respectively. 
Let $\Psi_{E_1 E_2}=\sum_{t,r} S'_t\otimes S''_r$ be an arbitrary decomposition of the entangled state. Hence, by linearity,
\begin{align}
&\left(
\Lambda^{(i,m_1)}_{E_1\to X_1}\otimes 
\Gamma^{(i,m_2)}_{E_2\to X_2}\right)(\Psi_{E_1 E_2})
\nonumber\\
&=\sum_{t,r} \left(
\Lambda^{(i,m_1)}_{E_1\to X_1}\otimes 
\Gamma^{(i,m_2)}_{E_2\to X_2}\right)(S'_t\otimes S''_r)
\nonumber\\
&=
\sum_{t,r}
\sum_{a_1\in\mathcal{X}_1}
\Bigg[ \sum\limits_{x_1^n\in\Xset_1^n\,:\; x_1[i]=a_1} \trace\left( F_{x_1^n}^{(m_1)}S_t' \right) \Bigg]
\ketbra{a_1}\otimes 
\sum_{a_2\in\mathcal{X}_2}
\Bigg[ \sum\limits_{x_2^n\in\Xset_2^n\,:\; x_2[i]=a_2} \trace\left( F_{x_2^n}^{(m_2)}S_r'' \right) \Bigg] \ketbra{a_2}
\nonumber\\
&=
\sum_{(a_1,a_2)\in\mathcal{X}_1\times \mathcal{X}_2}
\left[ \sum_{\substack{ (x_1^n,x_2^n)\in\Xset_1^n\times \Xset_2^n\,:\; \\ x_1[i]=a_1\,,\;
 x_2[i]=a_2}}\; \sum_{t,r} \trace\left( (F_{x_1^n}^{(m_1)}\otimes F_{x_2^n}^{(m_2)})(S_t'\otimes S_r'') \right) \right]
\ketbra{a_1,a_2} 
\nonumber\\
&=
\sum_{(a_1,a_2)\in\mathcal{X}_1\times \mathcal{X}_2}
\left[ \sum_{\substack{ (x_1^n,x_2^n)\in\Xset_1^n\times \Xset_2^n:\; \\ x_1[i]=a_1\,,\;
 x_2[i]=a_2}} \trace\left( (F_{x_1^n}^{(m_1)}\otimes F_{x_2^n}^{(m_2)})\Psi_{E_1 E_2} \right) \right]
\ketbra{a_1,a_2} 
\end{align}
as expected.
We deduce that the channel inputs $X_{1}[i]$ and $X_2[i]$ can be obtained from a product of  measurements of the form $L_1(x_{1}|i,V_{0}[i],V_{1}[i])$ and $L_2(x_{2}|i,V_{0}[i],V_{2}[i])$, as required.


 Then, we can rewrite (\ref{eq:ConvIneq1SC}) as
\begin{align}
%
R_1-\eps_{1n}
&\leq \frac{1}{n}\sum_{i=1}^n I\left(V_{1}[i];Y[i] \,\big|\; V_{0}[i], V_{2}[i] \right) \nonumber\\
&=  I\left(V_{1}[J];Y[J] \,\big|\; V_{0}[J], V_{2}[J], J \right) 
\label{eq:ConvIneq1a}
\end{align}
where the index $J$ is drawn  uniformly at random from $\{1,\ldots,n\}$, and it is uncorrelated with the previous systems.
%
Following the same considerations,
\begin{align}
%
R_2-\eps_{2n}
&\leq  I\left(V_{2}[J];Y[J] \,\big|\; V_{0}[J], V_{1} [J], J \right) 
\label{eq:ConvIneq2}
\intertext{and}
R_1+R_2-\eps_{3n}
&\leq  I\left(V_{1}[J] V_{2}[J];Y[J] \,\big|\; V_{0}[J], J \right) \,. 
\label{eq:ConvIneq3}
\end{align}
The proof follows by defining $V_0\equiv (J,V_{0}[J])$, $V_k\equiv V_{k}[J] $, for $k=1,2$, then
$X_k\equiv X_{k}[J]$, and $Y\equiv Y[J]$. 
\qed







\section{Summary and Discussion
}
\label{Section:Discussion}
To summarize, 
we have considered
%
communication over a two-user classical multiple-access channel
(MAC) $P_{Y|X_1,X_2}$ with  entanglement resources shared
%
between the transmitters a priori, before communication begins, as illustrated in Figure~\ref{fig:MentangledTx}.
Our main result is a full characterization of the capacity region for the \emph{general} MAC with entangled transmitters.
We have also  shown that the 
examples by Leditzky et al.  \cite{LeditzkyAlhejjiLevinSmith:20p} are a special case and follow from our main result in 
Theorem~\ref{theo:etMAC}.


In addition, we  observed the following change of behavior.
In general, achievable communication rates may also depend on the error criterion.
% 
For a classical MAC
without entanglement resources, % nor randomness at the encoders, 
it has long been known that
the relaxation to a message-average error criterion can lead to strictly higher achievable rates, when compared with a maximal error criterion \cite{Dueck:78p} (see Remark~\ref{Remark:Classical_Maximal_Error}).
Here, however,  the capacity region with entangled transmitters remains the same, whether we consider a message-average or a maximal error criterion.


 The auxiliary systems $A_1$ and $A_2$ in our characterization have unbounded dimensions, as mentioned in Remarks \ref{Remark:Dimension}-\ref{rem:Uncomput}. % (\cf \cite[Remark 5]{QiSharmaWilde:18p} and Discussion section in \cite{DupuisHaydenLi:10p}).
Although one can always compute an achievable region by simply choosing the dimension of $A_1$ and $A_2$, the optimal rates cannot be 
 computed exactly in general. 
 The lack of a dimension bound for the reference system plagues many other 
 quantum models in network information theory, such as 
the MAC with entangled transmitter and receiver \cite{HsiehDevetakWinter:08p},
the  broadcast channel (see Discussion section in \cite{DupuisHaydenLi:10p}), wiretap channel \cite[Remark 5]{QiSharmaWilde:18p},
and squashed entanglement \cite[Section 1]{LiWinter:14p}.
Here, the problem is inherent to the communication scenario.
%
The examples due to 
Leditzky et al.  
\cite{LeditzkyAlhejjiLevinSmith:20p}
demonstrate that for some channels,
the capacity region can be achieved with a finite entanglement rate (see Example~\ref{Example:Magic_Square}), while for other channels,
achieving the full capacity region requires an infinite amount of entanglement resources (see Example~\ref{Example:Slofstra_Vidick}).
%Yet, we have derived an achievable region with rate-limited entanglement resources.


%Consider the rate region formula for $\mathcal{R}_{\text{ET}}(\cdot)$ in (\ref{eq:inRetx}).
In the resource theory literature,
the set of conditional distributions
$p_{X_1,X_2|V_1,V_2}$ arising from all choices of finite dimensional Hilbert space $\mathcal{H}_{A_1}$ and $\mathcal{H}_{A_2}$, all measurements $\mathcal{L}_1(v_1)\otimes \mathcal{L}_2(v_2)$, and all $\ket{\phi_{A_1 A_2}}$, is called the family of quantum spatial correlation matrices, and it is denoted by \cite{DykemaPaulsen:16p}
\begin{align*}
C_{ q s}(|\mathcal{X}_1|,|\mathcal{X}_2|)
\,.
\end{align*}
%
Furthermore, the quantum commuting family,
$C_{qc}(|\mathcal{X}_1|,|\mathcal{X}_2|)$,
is the set of commuting quantum correlation matrices,
i.e.,  such that the measurement operators for Alice 1 and Alice 2 commute, and the quantum approximate family $C_{qa}(|\mathcal{X}_1|,|\mathcal{X}_2|)$ is the closure of the quantum spatial family, $C_{qa}(|\mathcal{X}_1|,|\mathcal{X}_2|)\equiv
\overline{C_{qs}(|\mathcal{X}_1|,|\mathcal{X}_2|)}$.
The quantum commuting family
$C_{qc}(|\mathcal{X}_1|,|\mathcal{X}_2|)$
is a closed set as well.

There are different conjectures related to the Tsirelson problem \cite{Tsirelson:93p};
the strong conjecture states that the commuting and spatial families are identical, i.e.,
$C_{qs}=C_{qc}$; the weak version that the commuting and approximate families are identical, i.e.,
$C_{qc}=C_{qa}$; and the middle states that the spatial and approximate families are identical, i.e., $C_{qs}=C_{qa}$. The weak Tsirelson conjecure is equivalent to Conne's embedding conjecture \cite{Ozawa:13p}.
%It is known that $C_{qc}(|\mathcal{X}_1|,|\mathcal{X}_2|)$ is a closed set.
%
The  Tsirelson conjecture is closely related to the study of nonlocal quantum   games:
$C_{qs}\neq C_{qa}$ is true if and only there exists a nonlocal game that can be won with certainty using a limit of finite-dimensional entanglement resources, but cannot be won with certainty for a bounded dimension.

Slofstra \cite{Slofstra:19p} has shown that indeed there exists a game that can only be one in the limit of finite-dimensional entangelemnt, hence $C_{qs}$ is not closed, and both the strong and middle Tsirelson conjectures are false ($C_{qs}\neq C_{qc}$ and $C_{qs}\neq C_{qa}$).
More recently, Ji et al.  \cite{JNVWY:21p} constructed 
%
a game such that the entangled value differs from
its commuting-operator value, proving that the weak Tsirelson conjecture is also false.


As the dimension of our entangled systems $A_1$ and $A_2$ in the rate formula (\ref{eq:inRetx}) is unbounded, the formula for
$\mathcal{R}_{\text{ET}}(P_{Y|X_1,X_2})$ involves a union over  the approximate family
$C_{qa}$ \cite{Slofstra:20p}.
Since $C_{qs}\neq C_{qa}$, it follows that the union cannot necessarily be exhausted by finite-dimensional entangled states.


\section*{Acknowledgment}
The authors wish to thank Andreas Winter (Universitat Aut\`onoma de Barcelona) for useful discussions and important observations on the dimension problem.

U. Pereg was supported by the Israel VATAT Junior Faculty Program for Quantum Science and Technology through Grant 86636903,  the Chaya Career Advancement Chair, Grant 8776026,  and the German-Israeli Project Cooperation (DIP), Grant 2032991.
 C. Deppe and H. Boche were supported by
%
the German Federal
Ministry of Education and Research (BMBF) through Grants
16KISQ028 (Deppe) and 16KISQ020 %
(Boche). 
This work of H. Boche was supported in part by the BMBF within the national initiative for
``Post Shannon Communication (NewCom)" under Grant 16KIS1003K, and in
part by the DFG within the Gottfried Wilhelm
Leibniz Prize under Grant BO 1734/20-1 and within Germany's Excellence
Strategy EXC-2092 – 390781972 and EXC-2111 – 390814868. 
U. Pereg was also supported by the Helen Diller Quantum Center at the Technion.


\begin{appendix}[Maximal Error Criterion]
We show here that if a rate pair $(R_1,R_2)$ is achievable with  a 
message-average error criterion, then it is also achievable with a maximal error criterion (see (\ref{Equation:Message_Max_Error}), \cf  (\ref{Equation:Message_Avg_Error})). 
As pointed out in Remark~\ref{Remark:Classical_Maximal_Error}, this property 
does \emph{not} hold for a classical MAC without entanglement resources
\cite{Dueck:78p} \cite[Sec. 2.2]{Cai:14p}.
Nonetheless, Cai \cite{Cai:14p} considered the classical MAC without entanglement resources, and showed that
 the capacity region of the classical MAC  with a message-average error criterion is also achievable with a maximal error criterion, if the encoders are provided with a random key. Since the entanglement resources in our model can also be used in order to generate a random key, the arguments by 
 Cai \cite{Cai:14p} extend to our model as well. For completeness, we give the details below.
 It can easily be seen from the calculations below that the new codes only require rate-constrained entanglement resources.

We note that if $(R_1,R_2)=(0,0)$ is the best  achievable pair with a message-average error criterion, then the capacity region with a maximal error criterion is  $\mathcal{C}_{\text{ET}}(P_{Y|X_1,X_2})=\{(0,0)\}$, and there is nothing to show. Hence, we may assume without loss of generality that $R_1>0$ is achievable with entangled transmitters subject to a message-average error criterion.
%
 Let $\mathscr{C}=(\Psi,\Fset_1,\Fset_2,g)$ be a code with entangled transmitters such that the message-average error probability is bounded by
 \begin{align}
&\overline{P}_{e}^{(n)}(\mathscr{C})\equiv %
\frac{1}{2^{n(R_1+R_2)}}\sum_{m_1=1}^{2^{nR_1}}\sum_{m_2=1}^{2^{nR_2}}    P_{e}^{(n)}(\mathscr{C}|m_1,m_2)< \gamma %\frac{1}{12}\varepsilon_0 
\label{Equation:Message_Avg_Error_App}
\end{align}
where $\gamma$ %$\varepsilon_0 $ 
is arbitrarily small.
For every $m_2\in [1:2^{nR_2}]$, define the semi-average probability of error by
 \begin{align}
&e(m_2)\equiv %
\frac{1}{2^{nR_1}}\sum_{m_1=1}^{2^{nR_1}}    P_{e}^{(n)}(\mathscr{C}|m_1,m_2) 
\,.
\label{Equation:Message_1_Avg_Error}
\end{align}


Consider the following subset of ``good" messages for User 2,
\begin{align}
\Mset_{2}'&=\left\{ m_2\in [1:2^{nR_2}] \,:\; e(m_2)< 2\cdot\gamma
%\frac{1}{6}\varepsilon_0 
\right\} \,.
% \\
% \Mset_{2}''&=\{ m_2\in [1:2^{nR_2}] \,:\; e(m_2)\geq\frac{1}{6}\varepsilon_0 \}
% \,.
\label{Equation:Mset_2_p}
\end{align}
%
Observe that by (\ref{Equation:Message_Avg_Error_App}), the average value of 
$e(m_2)$ is bounded by
\begin{align}
\frac{1}{2^{nR_2}}\sum_{m_2=1}^{2^{nR_2}}    e(m_2)< 
\gamma
%\frac{1}{12}\varepsilon_0
\,.
\label{Equation:Average_e_m2}
\end{align}
This, in turn, implies that the subset
$\Mset_{2}'$ is at least as large as half the original set, i.e.,
\begin{align}
|\Mset_{2}'|&\geq \frac{1}{2}\cdot 2^{nR_2}
\\
&= 2^{n\left( R_2-\frac{1}{n} \right)}
\,.
\end{align}
Otherwise, the average value of $e(m_2)$ would have been greater than or equal to 
$\gamma$, %$\frac{1}{12}\varepsilon_0$, 
in contradiction to (\ref{Equation:Average_e_m2}).
Therefore, \mbox{User 2} can throw away the messages outside $\Mset_{2}'$, and transmit at a rate of $R_2'=R_2-\frac{1}{n}$, arbitrarily close to $R_2$.

We now construct a new code that is reliable under the maximal error criterion.
%
In this construction, Encoder 1 first performs a measurement on an ancilla of dimension $n^2$ to obtain a uniformly distributed key $L_1\in [1:n^2]$. 
%
Then, the transmission consists of two consecutive blocks.
In the first block, Encoder 1 sends the key $L_1$ to the receiver using a code based on a \emph{message-average} error criterion. At the same time, Encoder 2 sends $L_2=1$.
Since the key set size is sub-exponential and we have assumed that User 1 can communicate at a positive rate, the key can be sent using a code of length $\nu=o(n)$.
% and a message-average error of 
% \begin{align}
% \Pr(\hat{L}_1\neq L_1)=
% \frac{1}{n^2} \sum_{\ell=1}^{n^2}
% \overline{P}_{e}^{(\nu)}(\mathscr{C}_1|\ell,1)< 2\gamma %\frac{1}{6}\varepsilon_0 
% %\,.
% \end{align}
% for sufficiently large $n$.
As for the second block,
given a key outcome $L_1$, Encoder 1 chooses a permutation $\pi_{L_1}$
on the message set $[1:2^{nR_1}]$, and encodes by applying the encoding map
$\, \Fset_1^{(\tilde{m}_1)}$ with
$\tilde{m}_1\equiv \pi_{L_1}(m_1)$. At the same time, Encoder 2  encodes using 
$\Fset_2^{(m_2)}$, as in the original code.
Bob receives the output sequence $(\bar{Y}^{\nu},Y^n)$ of length $\nu+n$, and decodes as follows. He uses the first part, $\bar{Y}^{\nu}$, in order to find an estimate  $\hat{L}_1$ and $\hat{L}_2=1$ for the keys.
Then, Bob declares his estimation for the messages as 
$(\hat{m}_1,\hat{m_2})=(\pi_{\hat{L}_1}^{-1}\times \identity_2)g(Y^n)$,
using the output $Y^n$ of the second block,
 where $\identity_2$ is the identity permutation on $\Mset_2'$.
 We denote the code that is used in the second block by $\pi_L(\mathscr{C})=(\Psi,\pi\Fset_1,\Fset_2,\pi^{-1}g)$.

% Then, he uses the output $Y^n$ of the second block.
% Let $g(Y^n)=(g_1(Y^n),g_2(Y^n))$ be the output of the original code.
% Here, Bob declares 
% $\hat{m}_1=\pi_{\hat{L}_1}^{-1} \left( g_1(Y^n) \right)$ and $\hat{m}_2= g_2(Y^n)$.

% \begin{align}%
% f(x_1^n,x_2^n|m_1,m_2)
% = \trace \left[  \left(F^{(m_1)}_{x_1^n}\otimes F^{(m_2)}_{x_2^n} \right) \Psi_{E_1 E_2} \right] \,.
% \end{align}%

Having assumed that the key $L_1$ is uniformly distributed, the probability of decoding the wrong key is the semi-average probability of error for the first block. That is, 
\begin{align}
\Pr(\hat{L}_1\neq L_1)=
\frac{1}{n^2} \sum_{\ell=1}^{n^2}
P_{e}^{(\nu)}(\mathscr{C}_1|\ell,1)
%=\overline{P}_{e}^{(\nu)}(\mathscr{C}_1)
< 2\gamma %\frac{1}{6}\varepsilon_0 
\,.
\end{align}

Now, consider the second block.
Let $\mathfrak{P}$ denote the permutation group  on the message set $[1:2^{nR_1}]$ of User 1.
Furthermore, let $\Pi_1,\ldots,\Pi_{n^2}$ be an i.i.d. sequence of random permutations, each uniformly distributed over $\mathfrak{P}$. 
Then, for a given $m_1$,
\begin{align}
\Pr(\Pi_\ell(m_1)=\tilde{m}_1)=\frac{ (2^{nR_1}-1)! }{(2^{nR_1})!}=\frac{1}{2^{nR_1}}
\label{Equation:Permutation_Distribution}
\end{align}
for all
$\tilde{m}_1\in [1:2^{nR_1}]$ and $\ell\in [1:n^2]$.
Thus, for every message pair $(m_1,m_2)\in [1:2^{nR_1}]\times \Mset_2'$,
\begin{align}
\mathbb{E}\left[ P_e^{(n)}(\Pi_\ell(\mathscr{C})|m_1,m_2) \right]
&=\sum_{\tilde{m}_1} \Pr(\Pi_\ell(m_1)=\tilde{m}_1) \cdot
P_e^{(n)}(\mathscr{C}| \tilde{m}_1,m_2 )
\\
&=\frac{1}{2^{nR_1}} \sum_{\tilde{m}_1} 
P_e^{(n)}(\mathscr{C}| \tilde{m}_1,m_2 )
\\
&= e(m_2)
\\
&<2\gamma %\frac{1}{6} \varepsilon_0
\end{align}
where the first equality follows from the construction of the code
$\pi_\ell(\mathscr{C})$, the second equality is due to (\ref{Equation:Permutation_Distribution}),
the third is due to (\ref{Equation:Message_1_Avg_Error}), and the last inequality 
follows from the definition of $\Mset_2'$ in (\ref{Equation:Mset_2_p}).
Hence, based on the Chernoff bound, we have
\begin{align}
\Pr\left( \frac{1}{n^2}\sum_{\ell=1}^{n^2}  P_e^{(n)}(\Pi_\ell(\mathscr{C})|m_1,m_2)
> 7\gamma
\right)\leq e^{-\gamma\cdot n^2}
\end{align}
%
(see \cite[Lemma 3.1]{Cai:14p}, taking $L\leftarrow n^2$, $\alpha\leftarrow 2\gamma$,
$\beta\leftarrow 7\gamma$).
This means that the probability that the random code $\Pi_L(\mathscr{C})$ has an error higher than 
$7\gamma$
tends to zero in a super-exponential rate.
Thus, by the union bound,
\begin{align}
\Pr\left(\exists (m_1,m_2) \,:\; \frac{1}{n^2}\sum_{\ell=1}^{n^2}  P_e^{(n)}(\Pi(\mathscr{C})|m_1,m_2)
> 7\gamma
\right)&\leq 2^{n(R_1+R_2')}\cdot e^{-\gamma\cdot n^2} 
\\
&\leq  e^{-\frac{1}{2}\gamma\cdot n^2} 
\end{align}
for sufficiently large $n$.
Therefore, there exists a realization $(\pi_1,\ldots,\pi_{n^2})$, such that
\begin{align}
P_e^{(n)}(\pi_L(\mathscr{C})|m_1,m_2)=
\frac{1}{n^2}\sum_{\ell=1}^{n^2}  P_e^{(n)}(\pi_\ell(\mathscr{C})|m_1,m_2)
\leq 7\gamma
\end{align}
for all $(m_1,m_2)\in [1:2^{nR_1}]\times\Mset_2'$.
In other words, the maximal error probability for the second block is bounded by $7\gamma$.
By choosing $\gamma=\frac{1}{9}\varepsilon_0$, we have that the maximal error probability of the overall code of length $n+o(n)$ %$\pi_L(\mathscr{C})$ 
is bounded by $\varepsilon_0$, as we wanted to show.
By increasing the code length $n$, 
 the overall transmission rates
$\frac{n}{n+o(n)}R_1$ and $\frac{n}{n+o(n)}\left(R_2-\frac{1}{n}\right)$ can be made arbitrarily close to
 $R_1$ and $R_2$, respectively. \qed

\end{appendix}

\bibliography{References}{}

%
%


\end{document}
