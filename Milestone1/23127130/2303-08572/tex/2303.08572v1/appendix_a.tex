\section{Proof of Theorem \ref{identifiability}}
\label{app_proof}
{\noindent\bf Proof}: Let us denote $\boldsymbol{\theta}^X = \boldsymbol{\beta}  \in \Delta_{|\mathcal{X}|-1}$ and recall that under the UC assumption, matrix $\boldsymbol \theta^{X\rightarrow Y}$ has the form
\[
\boldsymbol \theta^{X\rightarrow Y} = \begin{bmatrix}
\gamma_{\sigma_1(1)} & \gamma_{\sigma_1(2)} & \cdots & \gamma_{\sigma_1(|\mathcal{Y}|)}\\
\gamma_{\sigma_2(1)} & \gamma_{\sigma_2(2)} & \cdots & \gamma_{\sigma_2(|\mathcal{Y}|)} \\
\vdots & \vdots & \ddots & \vdots \\
\gamma_{\sigma_{|\mathcal{X}|}(1)} & \gamma_{\sigma_{|\mathcal{X}|}(2)} & \cdots & \gamma_{\sigma_{|\mathcal{X}|}(|\mathcal{Y}|)}
\end{bmatrix},
\]
where $\sigma_1,...,\sigma_{|\mathcal{X}|}\in \mathbb{S}_{|\mathcal{Y}|}$ are permutations and 
$\boldsymbol{\gamma} = (\gamma_1, ...., \gamma_{|\mathcal{Y}|} )\in \Delta_{|\mathcal{Y}|-1}$. The assumption that the rows of this matrix are not all equal to each other precludes the two following condition from holding: $\sigma_1 = \sigma_2 = \cdots = \sigma_{|\mathcal{X}|}$ and  $\boldsymbol{\gamma} = (1,1,...,1)/|\mathcal{Y}|$.
%Without loss of generality, we can assume that $\sigma_1 = \iota$, the identity permutation, thus $\boldsymbol{\gamma}$ is the first row of the matrix. 

Using Bayes' law, it is trivial to obtain the reverse channel, the elements of which are given by
\begin{equation}
{\theta}_{y,x}^{Y\rightarrow X} = p_{X|Y}(x|y) = \frac{p_{Y|X}(y|x)\, p_X(x)}{p_{Y}(y)} = \frac{ \gamma_{\sigma_x(y)} \, \beta_x }{ \sum_{x'\in\mathcal{X}} \gamma_{\sigma_{x'}(y)} \, \beta_{x'}  } =  \frac{a_{y,x}}{A_y} , \label{eq:reverse_theta}
\end{equation}
where $a_{y,x} = \beta_x \gamma_{\sigma_x(y)} $ and $A_y = p_Y(y) \neq 0$ (by assumption).
As in the binary example, using variables $Y$ and $X$ to index rows and columns, respectively, $\boldsymbol{\theta}^{Y\rightarrow X}$ is a row-stochastic matrix:
\[
\boldsymbol{\theta}^{Y\rightarrow X} = \begin{bmatrix} 
a_{1,1}/A_1  & \cdots & a_{1,|\mathcal{X}|}/A_1\\
\vdots & \ddots & \vdots \\
a_{|\mathcal{Y}|,1}/A_{|\mathcal{Y}|} & \cdots & a_{|\mathcal{Y}|,|\mathcal{X}|}/A_{|\mathcal{Y}|}
\end{bmatrix}.
\]
For $\boldsymbol{\theta}^{Y\rightarrow X}$ to correspond to a UC, its rows must be permutations of each other, which is equivalent to all being permutations of one of them, say the first, without loss of generality. We exclude the case where these permutations are all equal to identity, since that would correspond to all rows of $\boldsymbol{\theta}^{Y\rightarrow X}$ being equal to each other, \textit{i.e.}, $X \perp\!\!\!\perp Y$,  which is excluded in the conditions of the theorem. The condition that all the rows are permutations of the first one can be written formally as
\begin{equation}
\exists (\rho_2, ..., \rho_{|\mathcal{Y}|}) \in \mathbb{L}   : \forall y\in \mathcal{Y}\setminus \{1\}, \,\forall x\in\mathcal{X}, \; a_{1,x} / A_1 = a_{y,\rho_y(x)} / A_y , \label{eq:condition}
\end{equation}
where $\mathbb{L} = (\mathbb{S}_{|\mathcal{X}|})^{|\mathcal{Y}|-1} \setminus \mathbb{I}$, with $\mathbb{I} = \left\{\rho_2, ..., \rho_{|\mathcal{Y}|}: \rho_2 = ... =  \rho_{|\mathcal{Y}|} = \iota \right\}$, and $\iota$ is the identity permutation. In words, $\mathbb{L}$ is the set of all $(|\mathcal{Y}|-1)$-tuples of permutations of $|\mathcal{X}|$ elements, except for the one in which all permutations are identity. 

The equality $a_{1,x} / A_1 = a_{y,\rho_y(x)} / A_y$ is equivalent to $(a_{1,x} \, A_y  - a_{y,\rho_y(x)} \, A_1 )^2 = 0$,
thus the following equivalence holds:
\[
\bigl(\forall y\in \mathcal{Y}\setminus \{1\}, \,\forall x\in\mathcal{X}, \; a_{1,x} / A_1 = a_{y,\rho_y(x)} / A_y\bigr) \;\;\; \Leftrightarrow  \;\;\; Q_{\boldsymbol{\rho}}(\boldsymbol{\theta})  = 0,
\]
with 
\begin{equation}
Q_{\boldsymbol{\rho}}(\boldsymbol{\theta}) = \sum_{y\in \mathcal{Y}\setminus \{1\}} \sum_{x\in\mathcal{X}} (a_{1,x} \, A_y  - a_{y,\rho_y(x)} \, A_1 )^2,\label{eq_Qrho}
\end{equation}
where we have written the model parameters compactly as $\boldsymbol{\theta} = (\boldsymbol{\beta} ,\boldsymbol{\gamma}) \in \Delta_{|\mathcal{X}|-1} \times \Delta_{|\mathcal{Y}|-1} \subset \mathbb{R}^{|\mathcal{X}|} \times \mathbb{R}^{|\mathcal{Y}|}$, and denoted $\boldsymbol{\rho} = ( \rho_2, ..., \rho_{|\mathcal{Y}|} ) \in \mathbb{L}$. A key observation is that $Q_{\boldsymbol{\rho}}(\boldsymbol{\theta})$ is a polynomial in the elements of $\boldsymbol{\theta}$, since the $a_{y,x}$ and the $A_y$ are themselves polynomials (either products of two elements or sums of products of pairs of elements) as is clear in \eqref{eq:reverse_theta}.  

Finally, the existential quantifier  in  \eqref{eq:condition} can be re-written using a product, \textit{i.e.},
\[
\bigl( \exists \boldsymbol{\rho} \in \mathbb{L} :\;  Q_{\boldsymbol{\rho}}(\boldsymbol{\theta}) = 0 \bigr) \;\;\;\Leftrightarrow \;\;  R(\boldsymbol{\theta}) = 0, \hspace{0.7cm} \mbox{where}\;\; R(\boldsymbol{\theta}) \; =\!\!  \prod_{\boldsymbol{\rho} \in \mathbb{L} } Q_{\boldsymbol{\rho}}(\boldsymbol{\theta}).
\]
Since $R(\boldsymbol{\theta})$ a product of polynomials, it is itself a polynomial. Consequently, we have shown that the UC condition in \eqref{eq:condition} corresponds to having $\boldsymbol{\theta}$ as a root of a polynomial. 

The rest of the proof relies on a classical result about polynomials \citep{Federer1969}: let $S:\mathbb{R}^n\rightarrow \mathbb{R}$ be a polynomial that is not identically zero; then, the set $S^{-1}(0) = \{{\bf u}\in\mathbb{R}^n: \, S({\bf u})=0\}$ has zero Labesgue measure in $\mathbb{R}^n$. All that is left to show then is that $R(\boldsymbol{\theta})$ is not identically zero. For this purpose, we can ignore the valid parameter space $\Delta_{|\mathcal{X}|-1} \times \Delta_{|\mathcal{Y}|-1}$, because if $R^{-1}(0)$ has zero Lebesgue measure in $\mathbb{R}^{|\mathcal{X}|} \times \mathbb{R}^{|\mathcal{Y}|}$, so does the intersection $R^{-1}(0) \cap (\Delta_{|\mathcal{X}|-1} \times \Delta_{|\mathcal{Y}|-1})$. We can also ignore the condition  $\boldsymbol{\gamma} \neq (1,...,1)/|\mathcal{Y}|$, since this is a single point, thus a set of zero measure. 

A sufficient and necessary condition for $R(\boldsymbol{\theta})$ not to be identically zero is that none of its factors $Q_{\boldsymbol{\rho}}(\boldsymbol{\theta})$ is identically zero\footnote{Recall that a product of two polynomials with real coefficients is identically zero only if at least one of the factors is identically zero. This is a classical result from abstract algebra, which in the language thereof is stated as follows: the ring of all polynomials in $n$ variables with real coefficients is an \textit{integral domain} or \textit{entire ring}, that is, it does not have divisors of zero \citep{Lang}. The result generalizes trivially, by induction, to products of more than two polynomials.}. To show that no $Q_{\boldsymbol{\rho}}(\boldsymbol{\theta})$ is  identically zero, let us write it explicitly, using the definitions of $a_{y,x}$ and $A_y$ in \eqref{eq:reverse_theta}:
\begin{equation}
Q_{\boldsymbol{\rho}}(\boldsymbol{\theta}) = \sum_{y\in \mathcal{Y}\setminus \{1\}} \sum_{x\in\mathcal{X}} \Bigl( \beta_x \gamma_{\sigma_x(1)} \sum_{x'\in \mathcal{X}} \beta_{x'} \gamma_{\sigma_{x'}(y)} - \beta_{\rho_{y}(x)} \gamma_{\sigma_{\rho_y(x)}(y)}\sum_{x'\in \mathcal{X}} \beta_{x'} \gamma_{\sigma_{x'}(1)} \Bigr)^2.\label{eq_Qrho2}
\end{equation}
Since $Q_{\boldsymbol{\rho}}(\boldsymbol{\theta})$ is a sum of non-negative terms, to show that it is not identically zero, it suffices to show that one of the terms in the sum is strictly positive for some choice of $\boldsymbol{\theta}$. The condition $\boldsymbol{\rho} = (\rho_2,...,\rho_{|\mathcal{Y}|}) \in \mathbb{L}$ means that at least one of the permutations  $\rho_2,...,\rho_{|\mathcal{Y}|}$ is not the identity, which implies that there is at least one pair $(x,y)$ such that $\rho_y (x) \neq x$. Let $y$ and $x$ be one such pair. Choosing $\boldsymbol{\gamma} = (1,...,1)$ and $\boldsymbol{\beta} \in \Delta_{|\mathcal{X}|-1}$ such that all components are different from each other ($i\neq j\, \Rightarrow \beta_i \neq \beta_j$), we have (noticing that $\sum_{x'\in\mathcal{X}}\beta_{x'} = 1$)
\begin{align}
Q_{\boldsymbol{\rho}}(\boldsymbol{\theta}) & = \Bigl( \beta_x  \sum_{x'\in \mathcal{X}} \beta_{x'} - \beta_{\rho_{y}(x)} \sum_{x'\in \mathcal{X}} \beta_{x'} \Bigr)^2 +  
\sum_{y' \neq y } \sum_{x'\neq x } (\cdots)^2 \label{eq_Qrho3}\\
& = \bigl( \beta_x - \beta_{\rho_{y}(x)} \bigr)^2 +\; \mbox{non-negative terms} > 0.
\end{align}
In conclusion, since none of the $Q_{\boldsymbol{\rho}}(\boldsymbol{\theta})$ polynomials is identically zero, $R(\boldsymbol{\theta})$ is also not identically zero, consequently its zero set has zero Lebesgue measure. 
\hfill $\blacksquare$
