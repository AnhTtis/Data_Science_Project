
\section{Threats to Validity}\label{sec:threats-to-validity}


Despite careful research design, there exist threats and limitations to the validity of our evaluation, which we report below.

\paragraph{Threats to Internal Validity}
Cloud platforms in general allow only making little assumptions regarding the underlying hardware or software infrastructure~\cite{Bermbach2017}. Cloud-native containerized deployments as in this study further abstract this.
We consciously chose a representative, Kubernetes-based execution environment, which, however, limits control of possible influences on our result. 
To obtain statistically grounded benchmarking results, we build these evaluations upon the results of benchmarking method's evaluation~\cite{EMSE2022}.
Nevertheless, we only found that the selected configuration options provide good estimates.
Hence, resource demands obtained in these evaluations should also only be considered  estimates. Repeating individual experiments more often and for longer time periods as well as using our \textit{full search} strategy is likely to produce very similar, but not necessarily identical results.
Moreover, we evaluate a larger set of SUTs, load types, resource types, SLOs, and benchmarks in this study compared to our method's evaluation.
We address this limitation by carefully observing the benchmark execution but do not conduct as extensive experiments as in our method's evaluation.
We refer to our previous publication for further discussion on balancing statistical grounding and time-efficient execution for scalability benchmarking~\cite{EMSE2022}.




\paragraph{Threats to External Validity}


We conduct all experiments in this evaluation with our Theodolite benchmark task samples.
As discussed in previous work~\cite{BDR2021}, these benchmarks represent relevant use cases.
However, we cannot directly generalize our findings to arbitrary other applications, where other frameworks, configuration options, or deployment options might perform differently than our experiments.
We conduct all experiments in this evaluation in our private cloud environment and in Google Cloud.
For the private cloud, we use comparatively large bare metal nodes, while for Google Cloud we use large virtual machines.
Although our evaluations in \cref{sec:experimental-results:public-private} show only small deviations between both environments, we cannot necessarily conclude that we would obtain the same results in other cloud environments.

