
\section{Background}\label{sec:background}



In the following, we first discuss the concepts of stream processing within microservice architectures before outlining our Theodolite scalability benchmarking method used for this research.

\subsection{Stream Processing within Microservice Architectures}

At the time of this research, combining microservice architectures and distributed stream processing is covered only superficially in scientific literature.
While there are a couple of case studies reporting on stream processing-based microservices, research is still lacking a systematic evaluation of this new architectural style.
On the other hand, some textbooks for practitioners~\cite{Bellemare2020, Stopford2018} have recently been published, which also serve as references for this work.
Despite the lack of systematic studies, stream processing within microservices is named an emerging trend~\cite{Davoudian2020,Fragkoulis2023,KarabeyAksakalli2021} and the need for further research on this topic is recognized~\cite{Katsifodimos2019,Laigner2021}.
\Cref{fig:background:example-architecture} shows an exemplary architecture with microservices applying stream processing frameworks.\footnote{In practice, one can typically observe a combination of different communication methods, such as additional HTTP-based communication)~\cite{KarabeyAksakalli2021}. Depending on the microservice-specific use case, such architectures may also include microservices relying on other mechanisms to process data streams, such as simple producers/consumers or Function-as-a-Service deployments~\cite{Bellemare2020}.} %
The following attributes can often be observed for such microservices and are particularly relevant to this study.

\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{img/example-architecture.pdf}
	\caption{Example microservice architecture of a software system, in which microservices communicate via asynchronous messages and process these messages using stream processing frameworks. With such frameworks, the dataflow inside microservices is modeled as directed graphs of (potentially stateful) \textit{operators}. In this study, we benchmark different state-of-the-art stream processing frameworks with task samples, representing microservices such as those depicted in this example architecture.}
	\label{fig:background:example-architecture}
\end{figure}



\paragraph{Self-contained and loosely coupled}
In microservice architectures, a software system is composed of multiple small services that are built around business capabilities~\cite{Hasselbring2018}. Individual microservices run in their own processes, may use different technology stacks, and communicate via lightweight, fault-tolerant mechanisms over the network.
For microservices employing distributed stream processing techniques, this means each service can use its own stream processing framework.
In contrast to traditional big data stream processing systems running on top of resource management systems such as Apache Hadoop YARN or Apache Mesos, %
this also leads to smaller jobs and a single job per stream processing cluster.




\paragraph{Independently scalable}

In contrast to monolithic systems, individual microservices can be scaled independently due to their loose coupling. %
In fact, scalability has been reported as one of the most important drivers for and benefits of adopting microservice architectures in several systematic literature reviews \cite{Pahl2016, Li2021, Kratzke2017, Soldani2018, Laigner2021}, interview studies \cite{Taibi2017, Fritzsch2019, Knoche2019, Laigner2021, Zhou2023}, and experience reports \cite{Balalaie2016b, Hasselbring2017, Bucchiarone2018}.
Typically, horizontal duplication, data partitioning, and function decomposition are distinguished as methods for scaling microservice architectures. 
From an operation's perspective, also microservices apoting stream processing frameworks can be scaled by horizontal duplication. Internally, however, duplicating services leads to data partitioning, meaning that each instance of a service handles only messages with certain \textit{keys}.
The actual data partitioning as well as the necessary state management and fault tolerance is managed by modern stream processing frameworks.



\paragraph{Cloud-native deployment}
Microservice architectures are a pattern, particularly suited for building cloud-native applications~\cite{Balalaie2016,Gannon2017,Pahl2018}.
They are mostly deployed as containers in public or private cloud environments, with Kubernetes~\cite{Burns2016} being the de-facto standard orchestration tool for cloud-native applications~\cite{CNCF2022}.
With Kubernetes, microservice deployments including, for example, resource restrictions or numbers of replicas, are defined purely declaratively.


\paragraph{Asynchronous communication via messaging system}

Microservices that process and consume streams of messages often employ log-based messaging systems for their communication~\cite{KarabeyAksakalli2021}.
To eventually reach consistency among individual microservices, the log must be durable, append-only, fault-tolerant, partitioned, and it must support sequential reads~\cite{Kleppmann2019}.
Probably the most prominent messaging system fulfilling these properties is Apache Kafka~\cite{Kreps2011,Wang2015}, which is intensively used in industry.\footnote{\url{https://kafka.apache.org/powered-by}}
Log-based messaging systems such as Kafka are required by modern stream processing frameworks to provide strict processing guarantees and fault tolerance while scaling out~\cite{Fragkoulis2023}.


\paragraph{Adoption of distributed stream processing techniques}





Modern stream processing frameworks are designed to run in a distributed fashion on commodity hardware in order to scale with massive amounts of data~\cite{Fragkoulis2023}. Besides high throughput, these systems focus on low latency, fault tolerance, and coping with out-of-order streams.
Modern stream processing frameworks process data in jobs, where a job is defined as a dataflow graph of processing operators. They can be started with multiple instances (e.g., on different compute nodes, containers, or with multiple threads). For each job, each instance processes only a portion of the data. Whereas isolated processing of data records is not affected by the assignment of data portions to instances, processing that relies on previous data records (e.g., aggregations over time windows) requires the management of state. Similar to the MapReduce programming model, keys are assigned to records and the stream processing frameworks guarantee that all records with the same key are processed by the same instance. Hence, no state synchronization among instances is required. When a processing operator changes the record key and a subsequent operator performs a stateful operation, the stream processing framework splits the dataflow graph into subgraphs that can be processed independently by different instances.
We refer to the recent surveys of \citet{Fragkoulis2023} and \citet{Margara2022} for detailed information on state-of-the-art stream processing models and patterns.



\subsection{Scalability Benchmarking with Theodolite}

Our study builds upon our Theodolite scalability benchmarking method for cloud-native applications~\cite{EMSE2022}.
According to the ACM SIGSOFT Empirical Standard for benchmarking as a software engineering research method~\cite{Ralph2021,PROPSER2021}, we briefly summarize the quality, metric, measurement method, and task samples used in this study.\footnote{\url{https://acmsigsoft.github.io/EmpiricalStandards/docs/?standard=Benchmarking}}

\paragraph{Quality}
The quality evaluated in this study is scalability. Scalability is defined as ``the ability of [a] system to sustain increasing workloads by making use of additional resources''~\cite{Herbst2013}.
It should not be confused with elasticity, which describes how fast or how precise a system (automatically) adapts to varying workloads~\cite{Herbst2013,Lehrig2015}.

\paragraph{Metric}
The Theodolite scalability benchmarking method provides two alternative scalability metrics, the \textit{resource demand} metric and the \textit{load capacity} metric. In this study, we focus on the \textit{resource demand} metric.
It is a function, mapping the load intensity on a system under test (SUT) to the minimal amount of resources that must be provisioned for the SUT such that the SUT fulfills all specified service-level objectives (SLOs).
In \cref{sec:experimental-setup:method}, we describe how load, resources, and SLOs are defined in this study.

\paragraph{Measurement method}
To measure scalability according to the metric, we chose discrete subsets of the load and resource domains and run isolated performance experiments for different load and resource combinations to assess whether the specified SLOs can be fulfilled.
Experiment duration, warm-up periods, and the number of repetitions are configurable and have to be adjusted to the context. By using appropriate search strategies, not all combinations of load and resources have to be executed.

\paragraph{Task samples}
Our Theodolite benchmarking method is not restricted to specific task samples, but allows also using existing benchmarks for cloud-native applications.
Based on real-world use cases for Industrial Internet of Things analytics~\cite{DIMA2021}, we proposed four task samples of different complexity for stream processing frameworks in previous work~\cite{BDR2021}.
As we discuss in \cref{sec:related-work}, these are the only benchmarks focusing on modern stream processing frameworks deployed as cloud-native microservices.
In \cref{sec:experimental-setup:task-samples},
we describe how we configure these task samples for our evaluation.
