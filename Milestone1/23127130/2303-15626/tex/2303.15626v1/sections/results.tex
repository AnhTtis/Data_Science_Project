\section{Results and Discussion}~\label{s:results}
\begin{figure*}[htb]
    \centering
    \includegraphics[width =0.9\linewidth]{figures/Training_plots.pdf}
    \caption{\textbf{A quality-based generalization comparison between QCBMs, RNNs, TFs, WGANs and VAEs.} Here, we plot the quality coverage, utility, and minimum value for the two tracks, T1 (top row) and T2 (bottom row) for $N_{\text{var}} = 20$ binary variable. Additionally, the models are trained using $N_{\text{seeds}} = 10$ random seeds, and the outcomes of the metrics are averaged over these seeds with error bars estimated as one standard deviation, which can be computed for each metric as $\sqrt{\text{Variance}/N_{\text{seeds}}}$. Panel (a) corresponds to $\epsilon = 0.01$, hence to a size of the training dataset of $5242$. Here the VAE provides the best overall performance for T1 whereas the WGAN is superior compared to the other models for T2. Panel (b) corresponds to $\epsilon = 0.001$, hence to a smaller size of the training dataset equal to $524$. From the T1 point of view, we observe that the QCBM obtains the lowest utility compared to the other models while having a competitive diversity of high-quality solutions. From the perspective of T2, QCBMs are competitive with the VAE and ahead of the WGAN, the TF, and the RNN. These results highlight the efficiency of the QCBMs in the scarce-data regime. Note that the dashed horizontal lines correspond to the minimum cost of $-12$ in the training data.}
    \label{fig:quality_metrics}
\end{figure*}

In this section, we show the generalization results of the different generative models for the two levels of data availability, $\epsilon = 0.01, 0.001$, and for the two different tracks, T1 and T2. We start our analysis with $\epsilon = 0.01$ as illustrated in Fig.~\ref{fig:quality_metrics}(a). By looking at the first track T1, and focusing on the $MV$ results, we observe that the models experience a quick drop for the first 100 training steps. It is also interesting to see that all the models produce samples with a cost lower than the minimum cost value provided in the training set samples. Furthermore, we can see that VAEs, WGANs, and QCBMs converge to the lowest minimum value of $-19$, whereas RNNs and TFs jump to higher minimum values with more training steps. In this case, these two models gradually overfit the training data and generalize less to the low-cost sectors. This point highlights the importance of early stopping or monitoring our models during training to obtain their best performances. The utility (T1) provides a complementary picture, where we observe the VAE providing the lowest utility throughout training, followed by the QCBM and then by the other generative models. This ranking highlights the value of QCBMs compared to the other classical generative models. One interesting feature of QCBMs compared to the other models is the monotonic decrease of the utility in addition to its competitive diversity of samples, as illustrated by the quality coverage (T1). The quality coverage also shows the ability of QCBMs, in addition to VAEs and WGANs, to generate a diverse pool of unseen solutions with a lower cost compared to the costs shown in the training data. From the point of view of the second track T2, we observe that the WGAN has the best performance in terms of the three metrics. Additionally, all the models are still generalizing to configurations with a lower cost compared to what was seen in the training data. A complementary picture of the best quality metrics throughout training is provided in Fig.~\ref{fig:best_quality_metrics}(a) for clearer visibility of the ranking of generative models in our race.

\begin{figure*}[htp]
    \centering
    \includegraphics[width =0.9\linewidth]{figures/BarPlots.pdf}
    \caption{\textbf{Summary of the best quality-based metrics of QCBMs, RNNs, TFs, VAEs and WGANs where the setup is the same as Fig.~\ref{fig:quality_metrics}.} In panel (a), we represent the best quality metrics with $\bm{\epsilon = 0.01}$. Here we observe that the VAE has the best performance for track T1, whereas the WGAN is the best model for track T2. In panel (b), we represent our best results for $\bm{\epsilon = 0.001}$. Here we remark that the QCBM has optimal performances for track T1 and is competitive with the other models on track T2 in terms of $MV$ and $U$ while providing a better $C_q$.}
    \label{fig:best_quality_metrics}
\end{figure*}

We now focus our attention on the results obtained for the degree of data availability corresponding to $\epsilon = 0.001$ as illustrated in Fig.~\ref{fig:quality_metrics}(b). We again observe that all the models are generalizing to unseen configurations with a lower cost than the minimum cost seen in the training data. Remarkably, for T1, we highlight that the QCBM provides the lowest utility compared to the other models while maintaining a competitive minimum value and diversity of high-quality solutions. For the second track, T2, we observe that the QCBM is competitive with the VAE while providing the best quality coverage $C_q$. This point is clearer when analyzing and comparing the best quality-based metrics values in Fig.~\ref{fig:best_quality_metrics}(b).

Overall, QCBMs provide the best quality-based generalization performances compared to the other generative models in the low-data regime with the limited sampling budget, i.e., for $\epsilon = 0.001$ and T1 with a sampling budget of $Q = 10^4$ queries. This efficiency in the low-data regime is a highly desirable feature compared to classical generative models, which are known in real-world settings to be data-hungry~\cite{Deep_learning_appraisal2018, zhang2018strategy, Austin2020}. It is worthwhile to note that the used QCBM has the lowest number of parameters compared to the other generative models as outlined in App.~\ref{app:architectures}. Although using the parameters count to compare substantially different generative models is not necessarily a well-founded method (even if widespread), we highlight that the quantum models are able to achieve results that are competitive with classical models that have significantly more parameters, sometimes one to two order(s) of magnitude more. Overall, these findings are promising steps toward identifying scenarios where quantum models can provide a potential advantage in the scarce data regime. More details about the best results obtained by our generative models can be found in App.~\ref{app:additional_data}.

Finally, we would like to note that QCBMs are also competitive with RNNs and TFs in terms of pre-generalization and validity-based generalization metrics for both data availability settings, $\epsilon = 0.001, 0.01$, as outlined in App.~\ref{app:generalization_metrics}. The VAE and the WGAN tend to sacrifice these aspects of generalization compared to quality-based generalization (see App.~\ref{app:generalization_metrics}). Remarkably, the QCBM provides the best balance between quality-based and validity-based generalization.


