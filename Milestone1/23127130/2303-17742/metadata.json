{
    "arxiv_id": "2303.17742",
    "paper_title": "MemPool: A Scalable Manycore Architecture with a Low-Latency Shared L1 Memory",
    "authors": [
        "Samuel Riedel",
        "Matheus Cavalcante",
        "Renzo Andri",
        "Luca Benini"
    ],
    "submission_date": "2023-03-30",
    "revised_dates": [
        "2023-04-03"
    ],
    "latest_version": 1,
    "categories": [
        "cs.AR"
    ],
    "abstract": "Shared L1 memory clusters are a common architectural pattern (e.g., in GPGPUs) for building efficient and flexible multi-processing-element (PE) engines. However, it is a common belief that these tightly-coupled clusters would not scale beyond a few tens of PEs. In this work, we tackle scaling shared L1 clusters to hundreds of PEs while supporting a flexible and productive programming model and maintaining high efficiency. We present MemPool, a manycore system with 256 RV32IMAXpulpimg \"Snitch\" cores featuring application-tunable functional units. We designed and implemented an efficient low-latency PE to L1-memory interconnect, an optimized instruction path to ensure each PE's independent execution, and a powerful DMA engine and system interconnect to stream data in and out. MemPool is easy to program, with all the cores sharing a global view of a large, multi-banked, L1 scratchpad memory, accessible within at most five cycles in the absence of conflicts. We provide multiple runtimes to program MemPool at different abstraction levels and illustrate its versatility with a wide set of applications. MemPool runs at 600 MHz (60 gate delays) in typical conditions (TT/0.80V/25Â°C) in 22 nm FDX technology and achieves a performance of up to 229 GOPS or 192 GOPS/W with less than 2% of execution stalls.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.17742v1"
    ],
    "publication_venue": "14 pages, 17 figures, 2 tables"
}