\documentclass[a4paper,10pt]{amsart}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{wasysym}
\usepackage{lmodern}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{hyperref}
\hypersetup{breaklinks=true}
\usepackage{todonotes}
\usepackage{mathtools}
%\mathtoolsset{showonlyrefs}

% \usepackage[foot]{amsaddr}
\definecolor{darkred}{rgb}{0.5,0,0}
\definecolor{darkgreen}{rgb}{0,0.5,0}
\definecolor{darkblue}{rgb}{0,0,0.5}
\hypersetup{colorlinks,
linkcolor=darkblue,
filecolor=darkgreen,
urlcolor=darkred,
citecolor=darkblue}
%\usepackage[notcite,notref]{showkeys}

\usepackage{geometry}

\numberwithin{equation}{section}

\usepackage{enumitem}
\setlist{nosep}
\setlist{noitemsep}
\setlist{leftmargin=*}


\usepackage[normalem]{ulem}

\usepackage{mathtools}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}


\newtheorem{theorem}{Theorem}
\newtheorem{theoremstar}{Theorem}

\newtheorem{proposition}{Proposition}[section]
\newtheorem{lemma}[proposition]{Lemma}
\newtheorem{corollary}[proposition]{Corollary}
\newtheorem{conj}{Conjecture}
\newtheorem{claim}[proposition]{Claim}
\newtheorem{informal}[proposition]{Informal claim}
\newtheorem{remark}[proposition]{Remark}

\theoremstyle{definition}
\newtheorem{definition}[proposition]{Definition}
%\newtheorem{remark}[proposition]{Remark}

\newcommand{\g}{\mathrm{g}}
\newcommand{\blue}{\color{blue}}

\newcommand{\R}{\mathbb{R}}
\renewcommand{\div}{\mathrm{div}}
\renewcommand{\det}{\mathrm{det}}
\newcommand{\Ob}{O_{\bullet}}
\newcommand{\Oun}{\Ob(1)}
\newcommand{\Obeta}{O_{\beta}(1)}
\newcommand{\obeta}{o_{\beta}(1)}


\newcommand{\mm}{\mathbf{m}}
\newcommand{\tmm}{\widetilde{\mm}}
\newcommand{\mms}{\mm_s}
\newcommand{\mmt}{\mm_t}
\newcommand{\tmms}{\widetilde{\mm}_s}


\renewcommand{\rm}{\mathrm{m}}
\newcommand{\trm}{\widetilde{\rm}}
\newcommand{\rms}{\rm_s}
\newcommand{\rmt}{\rm_t}
\newcommand{\trms}{\widetilde{\rm}_s}

%\newcommand{\hmu}{\mathfrak{h}^{\mm_0}}
\newcommand{\hmu}{\mathfrak{h}_0}
\newcommand{\hh}{\mathfrak{h}}
\newcommand{\rhoze}{\rho_{z, \epsilon}}
\newcommand{\fze}{\varphi_{z, \epsilon}}

\newcommand{\KNbeta}{\mathrm{K}_{N}^{\beta}}
\newcommand{\id}{\mathrm{Id}}
\newcommand{\Dd}{\mathsf{D}}
\renewcommand{\phi}{\varphi}
\renewcommand{\epsilon}{\varepsilon}
\newcommand{\phiN}{\phi_N}
\newcommand{\D}{\mathrm{D}}

\newcommand{\1}{\mathsf{1}}
\newcommand{\2}{\mathsf{2}}
\newcommand{\3}{\mathsf{3}}
\newcommand{\hal}{\frac{1}{2}}

\newcommand{\XN}{\mathrm{X}_N}
\newcommand{\YN}{\mathrm{Y}_N}
\newcommand{\FT}{\mathcal{F}}
\newcommand{\LT}{\mathcal{L}}
\newcommand{\Esp}{\mathbb{E}}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\Teps}{\mathrm{T}_{\epsilon}}
\newcommand{\vTeps}{\vec{\mathrm{T}}_{\epsilon}}
\newcommand{\F}{\mathsf{F}}


\newcommand{\tphiz}{\widetilde{\phi}_z}
\newcommand{\Pot}{\mathrm{Pot}_N}
\newcommand{\PotXN}{\mathrm{Pot}_{\XN}}
\newcommand{\tPot}{\widetilde{\Pot}}
\newcommand{\tPotXN}{\tPot}
\newcommand{\kk}{\mathsf{k}}
\newcommand{\loc}{\mathrm{loc}}
\newcommand{\T}{\mathrm{T}}
\newcommand{\vT}{\vec{\T}}
\newcommand{\hlogz}{\widehat{\logz}}
\newcommand{\hPot}{\widehat{\Pot}}

\newcommand{\Ani}{\mathsf{Ani}}
\newcommand{\Ele}{\mathsf{Ele}}
\newcommand{\Points}{\mathsf{Points}}


\newcommand{\indic}{\mathsf{1}}
\newcommand{\ErrorCE}{\mathrm{ErrorCE}}
\newcommand{\rr}{\mathsf{r}}
\newcommand{\vr}{\vec{\rr}}
\newcommand{\bord}{\mathrm{Bound}}
\newcommand{\cbeta}{c_{\beta}}
\newcommand{\Max}{\mathfrak{M}_N}
\newcommand{\Maxr}{\mathfrak{M}_{N,r}}

% \newcommand{\Aa}{\mathsf{A}}
% \newcommand{\Bb}{\mathsf{B}}
% \newcommand{\Cc}{\mathsf{C}}
\newcommand{\ocar}{^{\otimes 2}}
\newcommand{\muep}{\mu_{\epsilon}}
\newcommand{\I}{\mathrm{I}}
\newcommand{\II}{\mathrm{II}}
\newcommand{\III}{\mathrm{III}}
\newcommand{\ZN}{\mathrm{Z}_N}
\newcommand{\Ocross}{O_{\star}}
\newcommand{\llN}{\ell_N}
\newcommand{\EF}{\nabla H^{\muz}_{N}}
\newcommand{\EFs}{\nabla H^{\muz}_{N, s \vr}}
\newcommand{\EFr}{\nabla H^{\muz}_{N, \vr}}
\newcommand{\cA}{\mathcal{A}}
\newcommand{\LN}{\mathbf{L}_N}
\newcommand{\bXN}{\mathbf{X}_N}
\newcommand{\bxN}{\bar{x}_N}
\newcommand{\Cbeta}{C_{\beta}}

\renewcommand{\d}{\mathrm{d}}
\newcommand{\dx}{\d x}
\newcommand{\diagc}{\left(\R^2 \times \R^2\right) \setminus \triangle}
\newcommand{\OmN}{\Omega_N}
\newcommand{\supp}{\mathrm{supp }}
\newcommand{\logz}{\log_z}
\newcommand{\tlogz}{\widetilde{\log}_z}
\newcommand{\tlogzp}{\widetilde{\log}_{z'}}

\newcommand{\epNz}{\epsilon}
\newcommand{\epNu}{\epsilon_{1}}
\newcommand{\epNd}{\epsilon_{2}}

\newcommand{\El}{\mathrm{E}}
\renewcommand{\r}{\mathsf{r}}
\newcommand{\Els}{\El_{s \vr}}
\newcommand{\Elsp}{\El_{s' \vr}}
\newcommand{\Elr}{\El_{\vr}}


\newcommand{\veta}{\vec{\eta}}
\newcommand{\Eleta}{\El_{\veta}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\G}{\mathcal{G}}
\newcommand{\EXz}{\El^{(0, \mathrm{X})}}
\newcommand{\EXzs}{\EXz_{s\vr}}
\newcommand{\EYz}{\El^{(0, \mathrm{Y})}}
\newcommand{\EYzs}{\EYz_{\hal \vr}}
\newcommand{\EYe}{\El^{(\epsilon, \mathrm{Y})}}
\newcommand{\EYes}{\EYe_{\hal \vr}}
\newcommand{\AniXz}{\Ani^{(0, \mathrm{X})}}
\newcommand{\AniYz}{\Ani^{(0)}}
\newcommand{\AniYe}{\Ani^{(\epsilon)}}
\newcommand{\tAniYe}{\widetilde{\Ani}^{(\epsilon, \mathrm{Y})}}
\newcommand{\bYN}{\mathbf{Y}_N}
\newcommand{\tEYe}{\widetilde{\El}^{(\epsilon, \mathrm{Y})}}
\newcommand{\tEYes}{\tEYe_{s\vr}}
\newcommand{\Error}{\mathsf{Error}}
\newcommand{\LL}{\mathcal{L}}
\newcommand{\Mt}{M_t}
\newcommand{\Mz}{M_{0}}
\newcommand{\Tt}{\mathrm{T}_{t}}
\newcommand{\psit}{\psi_{t}}
\newcommand{\0}{\mathsf{0}}
\newcommand{\vTt}{\vec{\mathrm{T}}_t}
\newcommand{\Latt}{\Lambda_\delta}
\newcommand{\Ddr}{\Dd_{r}}
\newcommand{\A}{\mathsf{A}}
\newcommand{\B}{\mathsf{B}}
\newcommand{\Pk}{P_k(z,z',x)}
\newcommand{\Ba}{\B_{a}}
\newcommand{\Baa}{\B_{b}}
\newcommand{\Ring}{\mathsf{Ring}}
\newcommand{\vzeta}{\vec{\zeta}}
\newcommand{\Lploc}{\mathrm{L}^p_{\mathrm{loc}}}
\newcommand{\tmax}{\mathsf{t}_{\mathrm{max}}}
\newcommand{\Mbeta}{M_{\beta}}
\newcommand{\Num}{\mathrm{Num}}
\newcommand{\Rzzp}{\mathsf{R}_{z,z'}}
\newcommand{\EFep}{\nabla_{N}^{\muep}}

\newcommand{\TDOCP}{\textrm{2DOCP}}
\newcommand{\Meas}{\mathcal{M}_{\star}}
\newcommand{\MPM}{\mathrm{M}_{\varphi, \mm}}

\newcommand{\ddx}{\mathbf{\d x}}
\newcommand{\dist}{\mathrm{dist}}
\newcommand{\Elecr}{\mathrm{E}_{\vec{r}}}
\newcommand{\Elec}{\mathrm{E}}
\newcommand{\Pts}{\mathsf{Pts}}
\newcommand{\bX}{\mathbf{X}}
\newcommand{\EE}{\mathcal{E}}
\newcommand{\DD}{\mathrm{D}}
\newcommand{\Cc}{\mathtt{C}}
\newcommand{\Cmm}{\Cc_{\ref{prop:compar1}}}
\newcommand{\Cmmb}{\Cc_{\ref{prop:compar2}}}
\newcommand{\FNl}{\mathrm{F}^{(z,\ell)}}
\newcommand{\EnerPts}{\mathsf{EnerPts}}
\newcommand{\Pbeta}{\mathbb{P}^\beta}
\newcommand{\PNbetamu}{\Pbeta_{N, \mm}}
\renewcommand{\AA}{\mathsf{A}_{\mathsf{1}}}
\newcommand{\PNbeta}{\Pbeta_N}
\newcommand{\ZNbeta}{\mathrm{Z}_{N, \beta}}
\newcommand{\LNmu}{\LN^{\mm}}
\newcommand{\ellA}{\ell_a}
\newcommand{\ellB}{\ell_b}
\newcommand{\fA}{f_a}
\newcommand{\fB}{f_b}
\newcommand{\zA}{z_a}
\newcommand{\zB}{z_b}
\newcommand{\Cff}{\mathrm{C}_f}
\newcommand{\sstar}{s_\star}
\newcommand{\PNep}{\mathrm{Pot}_{N, \epsilon}}
\newcommand{\chiep}{\chi_{\epNd}}
\newcommand{\elld}{\ell_\delta}
\newcommand{\elle}{\ell_\eta}
\newcommand{\chie}{\chi_{\eta}}
\newcommand{\logzp}{\log_{z'}}
\newcommand{\rhoep}{\rho_\epsilon}
\newcommand{\tlog}{\widetilde{\log}}
\newcommand{\Gzz}{G^{z,z'}}
\newcommand{\trhob}{\widetilde{\rho}_\beta}
\newcommand{\tG}{\widetilde{G}^{z,z'}}
\newcommand{\rmsi}{\rms^{(i)}}
\newcommand{\mmsi}{\mms^{(i)}}
\newcommand{\rmsip}{\rms^{(i+1)}}
\newcommand{\mmsip}{\mms^{(i+1)}}
\newcommand{\fii}{f^{(i)}}
\newcommand{\Lell}{\mathcal{L}_{z,\ell}}

\newcommand{\red}{\color{red}}
\newcommand{\N}{\mathbb{N}}



\newcommand{\HN}{\mathsf{H}_N}

\newcommand{\corO}{\textcolor{red}}
\newcommand{\corT}{\textcolor{purple}}


\author{Gaultier Lambert}
\address[Gaultier Lambert]{KTH Royal Institute of technology, Matematik, Lindstedtsv\"agen 25, 11428 Stockholm}
\thanks{G.L. acknowledges the supports of the Ambizione grant S-71114-05-01 from the Swiss National Science Foundation and of the starting grant 2022-04882 from the  Swedish Research Council.}
\email{glambert@kth.se}

\author{Thomas Lebl\'{e}}
\address[Thomas Lebl\'{e}]{Universit\'{e} de Paris-Cit\'{e}, CNRS, MAP5 UMR 8145, F-75006 Paris, France.}
\thanks{T.L. acknowledges the support of JCJC grant ANR-21-CE40-0009 from Agence Nationale de la Recherche.}
\email{thomas.leble@math.cnrs.fr}

\author{Ofer Zeitouni}
\address[Ofer Zeitouni]{Department of Mathematics, Weizmann Institute of Science, Rehovot 76100, Israel.}
\thanks{The third author was partially supported by Israel Science Foundation grant number 421/20.}
\email{ofer.zeitouni@weizmann.ac.il}
\email{}

\title[LLN for the maximum of the 2D Coulomb gas potential]{Law of large numbers for the maximum of the two-dimensional Coulomb gas potential}
\begin{document}
\date{}

\begin{abstract}
  We derive the leading order asymptotics of the logarithmic potential
  of a two dimensional Coulomb gas at arbitrary positive temperature. The proof is based on precise evaluation
  of exponential moments, and the theory of Gaussian multiplicative chaos.
\end{abstract}
\maketitle

\section{Introduction}

\subsection{Setting and main result}
We are interested in proving a law of large numbers for the maximal value of the random electrostatic (or logarithmic) potential generated by the particles of a two-dimensional Coulomb gas - sometimes also called a 2d log-gas, or ``two-dimensional, one-component plasma'' (\TDOCP). We start by recalling the definition of the \TDOCP.

\subsubsection*{The \TDOCP}
Let $N \geq 1$ and let $\XN := (x_1, \dots, x_N)$ be a $N$-tuple of (distinct)
points in $\R^2$. Let $\bXN := \sum_{i=1}^N \delta_{x_i}$ be the associated purely atomic measure of  total mass $N$ on $\R^2$. Let $\Dd(z,r)$ denote  the (closed)
disk of center $z$ and radius $r$ in $\R^2$
and set $\Dd_r=\Dd(0,r)$ and $\Dd=\Dd_1$.
Let $\mm_0$ be the probability measure with uniform density, denoted $\rm_0$, on the unit disk $\Dd$.

We define the \textit{logarithmic interaction energy} $\F(\XN, \mm_0)$ as:
\begin{equation}
\label{def:FXN}
\F(\XN, \mm_0) := \hal \iint_{\diagc} - \log|x-y| (\d\bXN - N \d\mm_0)(x) (\d\bXN - N \d\mm_0)(y),
\end{equation}
where $\triangle$ denotes the diagonal in $\R^2 \times \R^2$. Recalling that $-\log$ is (up to a multiplicative constant) the Coulomb kernel in $\R^2$, we can think of $\F(\XN, \mm_0)$ as being the electrostatic interaction energy of a neutral system made of $N$ point charges placed at $(x_1, \dots, x_N)$ together with a continuous background $N \mm_0$ of opposite charges.


We also introduce an auxiliary function $\zeta$, which vanishes on $\Dd$ and is set to:
\begin{equation}
\label{def:zeta}
\zeta(x) := - \log |x| + \frac{1}{2} |x|^2 - \frac{1}{2} \text{ on $\R^2 \setminus \Dd$.}
\end{equation}


Let $\beta>0$ be fixed. Throughout this paper, we will work with the probability measure $\PNbeta$ on $\left(\R^2\right)^N$ whose density is given by:
\begin{equation}
\label{eq:Pnbetav1}
\d\PNbeta(\XN) := \frac{1}{\KNbeta} \exp\left( - \beta \left( \F(\XN, \mm_0) + 2N \sum_{i=1}^N \zeta(x_i) \right) \right) \d\XN,
\end{equation}
where $\d\XN := \d x_1 \dots \d x_N$ is the Lebesgue measure on $(\R^2)^N$ and $\KNbeta$ is the normalizing constant, or \emph{partition function}, namely the following integral:
\begin{equation}
\label{def:KNbeta}
\KNbeta := \int_{\left(\R^2\right)^N} \exp\left( - \beta \left( \F(\XN, \mm_0) + 2N \sum_{i=1}^N \zeta(x_i) \right) \right) \d\XN.
\end{equation}
The measure $\PNbeta$ is called the \textit{canonical Gibbs measure} of a \TDOCP \ at \textit{inverse temperature} $\beta$.

\begin{remark}
  \label{rem-1.1}
Some authors define the two-dimensional log-gas in a seemingly different way. To a $N$-tuple $\XN$, one first associates an energy $\HN(\XN)$ given by the sum of all the pairwise logarithmic interactions between points plus the effect of a strong harmonic (``confining'') potential on each particle, namely:
\begin{equation}
  \label{eqHN}
\HN(\XN) := \hal \sum_{1 \leq i \neq j \leq N} - \log |x_i - x_j| + N \sum_{i=1}^N |x_i|^2,
\end{equation}
and then one defines the canonical Gibbs measure of a \TDOCP \ as:
\begin{equation}
\label{eq:Pnbetav2}
\d\PNbeta(\XN) := \frac{1}{\ZNbeta} \exp\left( - \beta \left( \HN(\XN) \right) \right) \d\XN, \quad \ZNbeta := \int_{\left(\R^2\right)^N} \exp\left( - \beta \left( \HN(\XN) \right) \right) \d\XN.
\end{equation}
In fact, both \eqref{eq:Pnbetav1} and \eqref{eq:Pnbetav2} give rise to \emph{the same probability measure} on $(\R^2)^N$, and the expression \eqref{eq:Pnbetav1} can be obtained from \eqref{eq:Pnbetav2} by introducing the so-called equilibrium measure $\mm_0$ and ``splitting'' the interaction energy as in \cite[Sec.~2]{sandier20152d}. For convenience, here we prefer to work with the 
``next-order'' formulation of the interaction energy as in \eqref{def:FXN}.

In the physics literature about the \TDOCP, the Gibbs measure is often written down as in \eqref{eq:Pnbetav1} but with an ``effective confinement''
$\zeta$ set to $+\infty$ outside $\Dd$ (``perfect confinement''). Our analysis in the present paper applies to this model as well (the only differences would appear when studying properties close to the boundary, which is not our purpose).
\end{remark}

\textbf{Henceforth, we fix $N \geq 2$ and an arbitrary value of $\beta > 0$. We let $\XN$ be a random variable in $(\R^2)^N$ distributed according to the Gibbs measure $\PNbeta$, and let $\bXN$ be the associated random point measure on $\R^2$ as defined above. Unless specified otherwise, expectations in what follows  are taken under $\PNbeta$.}


\subsubsection*{Main result}
Define the ``Coulomb gas potential'' generated by $\XN = (x_1, \dots, x_N)$ as the following random scalar field on $\R^2$:
\begin{equation}
\label{def:PotXN}
\Pot : z \mapsto \sum_{i=1}^N \log |z-x_i| - N \int_{\Dd} \log |z -x| \d \mm_0(x).
\end{equation}
In physical terms, $\Pot(z)$ corresponds to the value at $z$ of the electrostatic potential generated by the system of charges and the background measure $\mm_0$. Obviously $\Pot(z)$ is equal to $-\infty$ whenever $z$ coincides with one of the point charges. Our main result is the following description of the \textit{maximum} of $\Pot$ over closed disks in the interior of~$\Dd$:

\begin{theorem}[LLN for the max of the 2D Coulomb gas potential]
\label{theo:main}
For all $r \in (0,1)$ we have:
\begin{equation}
\frac{1}{\log N} \max_{z \in  \Dd(0,r)} \Pot(z) \longrightarrow \frac{1}{\sqrt{\beta}}\text{ as } {N \to \infty}, \text{ in probability.}
\end{equation}
\end{theorem}
The case $\beta=2$ of Theorem \ref{theo:main} corresponds to the 
Ginibre ensemble of (complex) random matrices, and was obtained in \cite{Lambert_2020} based on its determinantal structure.

As a byproduct of our proof, we obtain a control on a certain regularization of $\Pot$ at microscopic scale (see Corollary~\ref{cor:UB}), which allows us to state a uniform control on the fluctuations of linear statistics for a certain class of $C^2$ test functions (see Proposition~\ref{prop:unibound}). 

\subsection{Connections with the literature}
Our interest in Theorem \ref{theo:main} is motivated by connections with the theory of random matrices and the theory of logarithmically correlated fields.

\subsubsection*{The Ginibre ensemble and normal matrix models}
{For the specific value $\beta =2$ of the inverse temperature in \eqref{eq:Pnbetav2}, $\PNbeta$} describes the joint distribution of eigenvalues for \textit{Ginibre} matrices, i.e. matrices whose entries are i.i.d. complex Gaussians normalized by $1/\sqrt{N}$ (see \cite{Forrester} or the recent survey \cite{Forrester_review} for background). 
 {In this case, } as proved (using determinantal methods) in \cite{RV07} following a prediction of Forrester, the counting  measure of eigenvalues minus  $N\mm_0$, converges to the sum of a 2d-Gaussian free field (GFF) supported on $\Dd$ and an independent 1d-GFF on the unit circle. {There the Coulomb gas potential $\Pot$ can be interpreted as} the logarithm of the (absolute value of the) determinant of the 
associated (complex) Ginibre matrix, and as noted above the counterpart of Theorem~\ref{theo:main} was proved in \cite{Lambert_2020}.

For more general normal matrix models ({still} with $\beta=2$ {but replacing $|x|^2$ in \eqref{eqHN} by suitable polynomial potentials}), a CLT for the log-characteristic polynomial (with variance $\log N /4$) has been obtained in \cite{Ameur_2021} together with a description of the local (determinantal) point process around the singularity. {Such a connection with Gaussian fields motivates the study of the maximum, as we now explain.}


\subsubsection*{{Logarithmically correlated structure at arbitrary temperature}}
{More generally, for all $\beta > 0$,} the central limit theorems of \cite{bauerschmidt2019two} and \cite{LebSerCLT} {imply that $\Pot$ converges in some weak sense to a Gaussian Free Field (even in mesoscopic scales). Is it thus natural to ask whether the maximum of $\Pot$ behaves like the maximum of a 2d logarithmically correlated field, and Theorem \ref{theo:main} shows that the leading order is indeed the expected one.}

\subsubsection*{{One-dimensional analogues.}}
The density \eqref{eq:Pnbetav2} restricted to either the real line or to the unit circle $S^1$ in the complex plane gives rise to the classical G$\beta$E and C$\beta$E ensembles. For these, similar logarithmically correlated fields can be constructed (see e.g. \cite{DS} and \cite{HKO}
for early results concerning the CUE). The  extremes for the (logarithm of the) characteristic polynomial of
these matrix models have generated much interest (especially in the case of the CUE, corresponding to $\beta=2$) due to a celebrated
conjecture of Fyodorov, Hiary and Keating \cite{FHK12} that predicts the limiting form of the fluctuations of the maximum and links these to analogous fluctuations for the Riemann zeta-function.
This has stimulated much recent work, starting with \cite{ABB}, \cite{PaquetteZeitouni02} (for the CUE), \cite{CMN} and \cite{PZarXiv} (for the C$\beta$E); the last article indeed proves a version of the FHK conjecture. 
 On a related subject, it has been established that powers of the CUE characteristic polynomial converges to Gaussian multiplicative chaos (GMC) measures in the so-called $L^1$ phase \cite{NWS20} and that these measures describe the fluctuations of thick points (extreme level sets) of the characteristic polynomial \cite{JLW22}. 
Weaker analogous results for the case of GUE are contained in \cite{LambertPaquette01} and \cite{CFLW21}, see also \cite{BMP22} and \cite{ABZ22} for the G$\beta$E.

\subsection{{Comments on the strategy.}}
A general methodology to handle extremes of Gaussian logarithmically correlated fields has been developed in the last decades; due to space limitations, we do not review here the history, and refer instead to \cite{DRZ17} and \cite{biskup} for details. When applied outside the Gaussian context, this methodology requires the evaluation of exponential moments and characteristic functions
of the field, together with the introduction of certain barriers. These seem crucial in obtaining sharp results (at the level of $O(1)$ fluctuations for the extremes), and are often hard to implement
outside the Gaussian setup. The above works concerning the extremes of the electrostatic potential of
Coulomb gases on the real line or $S^1$ use, at different levels of precision, variants of these methods, with much technical work going into inserting appropriate barriers and controlling comparisons with the Gaussian setup.

For our needs, a crucial observation was made in \cite{LOS18} and \cite{CFLW21},
by using the theory of Gaussian multiplicative chaos (GMC):
in order to obtain the leading order of fluctuations, one can bypass the
use of barriers, at the cost of obtaining sharp estimates on
exponential moments (without need to consider characteristic functions). This
is the approach taken in this paper.

The evaluation of exponential moments in the context of Coulomb gases
is at the heart of many proofs of the central limit theorem for linear statistics. An early application
of this method is due to Johansson \cite{johansson1998fluctuations} in the context
of one-dimensional log gases, and for the two-dimensional case this was done in \cite{LebSerCLT,bauerschmidt2019two,serfaty2020gaussian}. Here we crucially use some key results of the latter paper, together with the general ``energy'' 
approach to 2DOCP's as developed by Serfaty and co-authors, starting with
\cite{sandier20152d} - in particular we will rely on the more recent \cite{armstrong2019local}. As in \cite{LebSerCLT,serfaty2020gaussian} we follow a fairly general approach based on transportation of measures (and not on ``loop equations''
as e.g. in \cite{bauerschmidt2019two}, although the two methods are related), a technique that has proven to be fruitful in the one-dimensional case - see for example \cite{Shcherbina_2014,BFG15,Bekerman_2018}.
Our method relies on computing the asymptotics of (joint) exponential moments of $\Pot$, the potential with the 2d Coulomb gas and the background measure $\mm_0$. These asymptotics are also related to the problem of determining the statistics of types of quantum quasi-particles arising in fractional Hall experiments by considering a certain modification of Laughlin function as a trial state. This connection is explained in further details in \cite[Section~1.3]{LLR22}, we just emphasize that the estimates required for that problem go beyond the precision achieved here.

\subsection{{Open problems}}
Theorem \ref{theo:main} only gives the \emph{leading order} of the maximum of $\Pot$. {In order to} actually see the influence of the underlying logarithmically correlated structure, one needs to evaluate (at least) the next order correction, which is expected {to be $\frac{3}{4 \sqrt{\beta}} \log\log N (1 + o(1))$ due to the log-correlated structure}. The techniques for achieving that go beyond our methods.

{In a different direction, it} is natural to consider replacing $|x|^2$ in \eqref{eqHN} by other growing (real) functions~$f$.
Applying our methods to that case requires three ingredients: first, one needs regularity of the background density $\rm_0$, and to modify 
the
electrostatic potential $\hmu$, see \eqref{def:hmu} accordingly. Second, one would need 
to modify the background function $\g$ of \eqref{eq:g}, which
is easy to do in the radial case. And third, one should look for
a replacement for Claim \ref{claim_scalin}, whose proof is
based on a scaling argument.
In the case of monomials $f(x)=|x|^q$, it is simple to carry out the adaptations, but already in the case of a general (even) polynomial $f(|x|)$ one needs to find a
replacement for 
the scaling argument.

A particular case of interest, concerns the \textit{real} Ginibre ensemble, see \cite{FN07}. There, one needs to deal with the symmetry of the point configuration $\XN$, as well as with the special role of the real axis. This would require significant changes in our derivation, and we leave this as an open problem.

Finally, we expect the result of Theorem \ref{theo:main} to remain true if one considers the maximum of $\Pot$ over the whole unit disk (or even the whole plane).
 We also expect that Proposition~\ref{prop:MC} holds without any regularization; see Remark~\ref{rk:MC}. 

\subsection{Sketch of the proof and plan of the paper}
In the evaluation of exponential moments, a crucial role is played by a version of the logarithmic interaction energy \eqref{def:FXN} {defined locally} at scale $\ell\geq N^{-1/2}$, denoted
$\EnerPts$, see \eqref{def:EnerPts}, for which a-priori
exponential moment bounds are available from \cite{armstrong2019local}, see
\eqref{loc_laws}.

Exponential moments of linear statistics for smooth enough test functions of a single (possibly mesoscopic or microscopic) scale can be controlled either by purely energy-based considerations (see Lemma~\ref{lem_fluct_uniform}) or in a more precise fashion in terms of the $H^1$ norm of the test function and the ratio of two partition functions corresponding to the original background measure $\mm_0$ and to a perturbed version $\mm_s$. This ratio can itself be studied using the transportation technique, see Lemmas \ref{lem:rewrite_Laplace} and \ref{prop:compar1}.

Since the linear statistics we care about is generated by the
logarithm, it is not based on a single scale. We thus need to be able to consider
test functions living on different scales, and we develop the required tool in Proposition
\ref{prop:compar2}. All these preliminary steps are carried out in
Section \ref{sec:prelim}, with proofs (building on \cite{serfaty2020gaussian})
postponed to the appendices.

The proof of Theorem \ref{theo:main} is split into an upper bound
(provided in Section \ref{sec-UB}) and a lower bound (provided in Section
\ref{sec-LB}). Concerning the former, since the logarithm is not smooth and not compactly supported\footnote{Technically speaking, the real issue is not the lack of compact support, but rather the fact that the total mass of its Laplacian is not $0$.},
to apply the estimates discussed in the preliminaries we need to
regularize it and center\footnote{Namely, we substract some well-chosen test function so that the Laplacian of the difference has total mass 0.} it; the centering is constructed in
Section \ref{subsec-center}, and Proposition \ref{prop:expo_hmu} gives an
a-priori control of the centering term. The exponential moments
of the regularized (at scale $\ell$)
test function has exponential moments that can be evaluated using the
preliminary results of Section \ref{sec:prelim}. Those estimates are
enough (using Chebyshev's inequality and a union bound) to yield the claimed
upper bound on a lattice of stepsize of order $N^{-1/2-\delta}$ with $\delta$
small, see
Lemma \ref{lat-est}. To extend the result {from a lattice to the whole of} $\Dd_r$ requires a
multi-scale estimation of the difference between the logarithm centered at different points, and is presented in Proposition \ref{prop:lattice}.


The proof of the lower bound is provided in Section \ref{sec-LB}.
As mentioned above, it follows the recipe of \cite{CFLW21}, and is based on the construction of a sequence of measures obtained from
exponentiating a regularized version of the linear statistic constructed from
the (shifted) logarithm function, see \eqref{eq-mugamma}. The heart of the
proof is to show that this sequence of measures converges to a Gaussian Multiplicative Chaos (GMC), which is
the limit of similar measures constructed from a Gaussian process, see
Proposition \ref{prop:GMC}. The general recipe from \cite{CFLW21} establishes
that these measures converge if one obtains asymptotics of exponential moments of linear combinations of the regularized logarithm, centered at different points, see \eqref{asymp_mom}.
The proof of the latter
is done by induction, using in a crucial way the two-scale
asymptotics of Proposition~\ref{prop:compar2}.




\subsection{Notation} \label{sec:not}
\begin{itemize}
	\item If $\Omega$ is a measurable subset, $\bXN(\Omega)$ denotes the number of points of $\XN$ contained in $\Omega$.
	\item We denote measures with a bold typeface (e.g. $\mm$) and their densities with respect to the Lebesgue measure on $\R^2$ with a roman typeface (e.g. $\rm$).
	\item If $\varphi$ is a function, whenever applicable we denote by $|\varphi|_\0$ a uniform bound on $\varphi$, and
	  by $|\varphi|_{k}$ a uniform bound on its $k$th derivative(s).
	\item Integrals with respect to the Lebesgue measure are often written without explicitly mentioning the volume form, ie $\int \varphi =\int \varphi(x) \d x$.
	\item If $A, B$ are two quantities (depending on various parameters) we write $A \preceq B$ {(or $A=O(B)$)} when $|A|$ is bounded by some universal constant times $|B|$. We write $A=o(B)$ or $A\ll B$
	  if $A/B\to 0$ when a (sometimes implicit)
	  parameter goes to infinity. When no parameter is mentioned, it is understood that the parameter is $N$. {We write $A \asymp B$ when $A = O(B)$ and $B = O(A)$.}
	\item When $\mm$ is a probability measure on $\R^2$ with continuous density $\rm$, we denote its relative entropy (with respect to Lebesgue) by $\EE(\rm) := \int_{\R^2} \rm \log \rm$.
\end{itemize}


\subsection*{Acknowledgment}
\emph{We thank Sylvia Serfaty for communicating early versions of \cite{serfaty2020gaussian} to us and making some statements thereof more easily citable for our purposes.}

\section{Preliminaries}
\label{sec:prelim}

\subsection{Energy at global and local scales}
\label{sec:Energy}
{Let $\mm$ be a probability measure on $\Dd$ with a density that is continuous and bounded below by a positive constant on the interior of $\Dd$.}

\subsubsection*{Global energy}
If $\XN$ is a $N$-tuple of points and $\bXN$ is the associated atomic measure of mass $N$, we {extend the definition \eqref{def:FXN}} and define the ``global energy'' $\F(\XN, \mm)$ as:
\begin{equation}
  \label{def:globalenergy}
\F(\XN, \mm) := \hal \iint_{\diagc} - \log|x-y| (\d\bXN - N \d\mm)(x) (\d\bXN - N \d\mm)(y).
\end{equation}
We introduce the associated Gibbs measure (where\footnote{{The function $\zeta$ plays almost no role in our analysis, as we are focused on the bulk of the system. For simplicity we keep “the same $\zeta$” in all cases.}} $\zeta$ is as in \eqref{def:zeta})
\begin{equation}
\label{def:PNbetamu}
\d \PNbetamu(\XN) := \frac{1}{\KNbeta(\mm)} \exp\left(- \beta \left( \F(\XN, \mm) + 2N \sum_{i=1}^N \zeta(x_i) \right) \right) \d \XN,
\end{equation}
with the corresponding partition function:
\begin{equation}
\label{def:KNbetamu}
\KNbeta(\mm) := \int_{(\R^2)^N} \exp\left(- \beta \left( \F(\XN, \mm) + 2N \sum_{i=1}^N \zeta(x_i) \right) \right) \d \XN.
\end{equation}
It is known (see e.g. the pioneering analysis of \cite[Thm. 1]{sandier20152d}) that {for all $\beta > 0$}:
\begin{equation}
\label{global_law}
\log \KNbeta(\mm) = \frac{\beta}{4} N \log N + O_\beta(N).
\end{equation}
One should {thus} think of the energy $\F(\XN, \mm)$ as being equal to $-\frac{1}{4} N \log N$ plus a {random} term which is typically of order~$N$.


\subsubsection*{Length scales and local laws}
For many interesting questions it is crucial to understand the system at \emph{local} scales i.e. in squares (or disks) of size $\ell \ll 1$. One distinguishes between \emph{mesoscopic} scales $\ell$ such that $N^{-1/2} \ll \ell \ll 1$ and the \emph{microscopic} scale $\ell \simeq N^{-1/2}$. {A constant $\rho_\beta \geq 1$ depending only on $\beta$ was introduced in \cite[(1.15)]{armstrong2019local}, it corresponds to the “minimal lengthscale” above which good controls on the energy can be obtained. In this paper when considering a length scale $\ell$ we will always assume that}\footnote{{Since \cite{armstrong2019local} work with a different scaling than us, we need to rescale their $\rho_\beta$ by $N^{-1/2}$.}}  {$\ell \geq \trhob := \rho_\beta N^{-1/2}$ (note that since $\rho_\beta \geq 1$, we always have $N \ell^2 \geq 1$).}


 The proper notion of a \emph{local energy}, however, is a bit subtle due to the long-range nature of the logarithmic potential. Suitable definitions were given in \cite{leble2017local,armstrong2019local}, unfortunately they are rather involved and for simplicity we will use them as a black box. For $z\in\Dd$ and any length scale $\ell$, we denote by $\FNl(\XN, \mm)$ the ``local energy in the disk
$\Dd(z, \ell)$''
as defined in {\cite[(2.24)]{armstrong2019local}} (they {mostly}
consider small squares rather than small disks but the distinction is irrelevant). {In this paper, we denote by $\EnerPts(z,\ell)$ the quantity
\begin{equation}
\label{def:EnerPts}
\EnerPts(z,\ell)(\XN) := \left(\FNl(\XN, \mm) + \frac{1}{4} n \log N \right) + n, \quad n = \bXN \left(\Dd(z, \ell) \right).
\end{equation}
Due to a weaker understanding of the system near the boundary $\partial \Dd$, one needs to introduce the following condition on $(z, \ell)$ (where $z$ is a point of $\Dd$ and $\ell$ is a length scale):
\begin{equation}
\label{condiell}
\dist\left( \Dd(z, \ell), \partial \Dd\right) \geq \Cc_\beta N^{-1/4},
\end{equation}
where $\Cc_\beta$ is some constant depending only on $\beta$ introduced in the assumptions of \cite[Thm.1]{armstrong2019local}. Then \cite{armstrong2019local} prove the following “local laws”:
\begin{lemma}[Local laws for $\EnerPts$]
If $(z, \ell)$ satisfies \eqref{condiell} and the parameter $t$ is smaller than some constant depending only on $\beta$, then:
\begin{equation}
\label{loc_laws}
\log \Esp_{\PNbetamu} \left[ \exp\left(t \EnerPts(z, \ell) \right) \right] = O\left(t N \ell^2\right),
\end{equation}
with an implicit constant depending only on $\beta$.
\end{lemma}
Thus the local laws of \cite{armstrong2019local} ensure that $\FNl$ is equal to  $- \frac{1}{4} n \log N$, where $n$ is the number of points in $\Dd(z, \ell)$, plus a  (fluctuation) term of order $N \ell^2$ in exponential moments, and so \emph{down to the microscopic scale} $\ell \simeq N^{-1/2}$ (a {crucial} improvement over \cite{leble2017local}). The number of points $n$ is also of order $N \ell^2$.}


\begin{remark}
To be specific, the statement of \cite[Theorem~1]{armstrong2019local} treats the electric energy and the number of points separately. They work with a different scaling so their length scale $R$ corresponds to $N^{1/2} \ell$ for us. \\
Their statement concerning the electric energy (\cite[(1.17)]{armstrong2019local}) involves the quantity $\F^{\square_R(x)}$ (their notation) which is short for $\F^{\square_R(x)}(\XN, U)$ with $U = \R^2$ as defined in \cite[(2.24)]{armstrong2019local}. The potential $u$ appearing there is defined in \cite[Sec. 2.3]{armstrong2019local} but as used in the main statement of \cite{armstrong2019local} it coincides with the true potential (because, with their notation,
$U = \R^2$ in this case). It remains to observe that Theorem 1 in \cite{armstrong2019local} states a control on $\F^{\square_R(x)}$ which can be turned into a control on the electric energy only, this is precisely the purpose of \cite[Lemma B.2]{armstrong2019local} and in particular their equation (B.8), which shows that one can indeed control the electric energy in terms of $\F^{\square_R(x)}$. As a last technical comment for the careful reader: note that since here
$U = \R^2$ (in their notation) the various truncations $\mathsf{r}, \tilde{\mathsf{r}}, \tilde{\tilde{\mathsf{r}}}$ all coincide. \\
In \cite[Theorem~1]{armstrong2019local} there are two statements concerning the number of points, here we can use \cite[(1.18)]{armstrong2019local} which controls exponential moments of the \emph{discrepancy} (which corresponds to $\bXN \left(\Dd(z, \ell) \right) - \pi {N}\ell^2$). It is not hard to see that it implies (and is in fact a lot stronger than) a bound on the number of points of the form; under \eqref{condiell} and for $t$ smaller than a constant depending only on $\beta$,
\begin{equation} \label{nbest}
\log \Esp_{\PNbetamu} \left[ \exp\left(t \bXN({D(z, \ell))} \right) \right] = O\left(t N \ell^2\right).
\end{equation}
\end{remark}



\subsection{Fluctuations}
When $\phi$ is a $\mm$-integrable test function, we define ``the fluctuation $\LN^{\mm}(\phi)$ of the linear statistics associated to $\phi$ {for the configuration $\XN$'',}  as:
\begin{equation}
\label{def:fluctuations} \LN^{\mm}(\phi) := \sum_{i=1}^N \phi(x_i) - N \int_{\Dd} \phi(x) \d \mm(x).
\end{equation}
{We write $\LN(\varphi)$ for $\LN^{\mm_0}(\varphi)$.} If $\varphi$ is Lipschitz, one can always use the following possibly non-optimal but \emph{uniform} control on $\LN(\varphi)$:

\begin{lemma}
\label{lem_fluct_uniform}
Let $z$ be a point of $\Dd$ and $\ell$ be a length scale such that $(z,\ell)$ satisfies \eqref{condiell}. {Denote} by $\Lell$ the set of all functions that are $\frac{1}{\ell}$-Lipschitz and compactly supported on $\Dd(z, \ell)$. Then for all $t$ such that $|t|$ is smaller than some constant depending on $\beta$, we have:
\begin{equation}
\label{eq:}
\log \Esp \left[ \sup_{\varphi \in \Lell} \exp\left(t \LN(\varphi) \right) \right] = O\left( t \left(N \ell^2\right)^\hal \right),
\end{equation}
with an implicit constant depending only on $\beta$.
A similar estimate holds for $\mathcal{L}$, the set of all 1-Lipschitz function with compact support in  $\Dd(0,2)$ with $\ell=1$.
\end{lemma}
\begin{proof}
This can be traced back to the analysis of \cite[Lemma 3.9]{sandier20152d}, see also \cite[Theorem 5]{rougerie2016higher}. The basic idea is that we have a configuration-wise bound of the form:
\begin{equation*}
|\LN(\varphi)| \leq |\varphi|_{\1} \times \ell \times \EnerPts(z, \ell)^{\hal} \leq |\varphi|_{\1} \times \ell \times \left( {\frac{\EnerPts(z, \ell)}{(N\ell^2)^\hal} + (N\ell^2)^\hal} \right),
\end{equation*}
(see e.g. \cite[Lemma B.5]{armstrong2019local} for a precise statement), and the result follows from an application of the
``local laws'' as presented in the previous section, see e.g. \eqref{loc_laws}, and our convention that $\ell\geq N^{-1/2}$.
\end{proof}

If $\varphi$ is assumed to have more regularity, the results of \cite{LebSerCLT,bauerschmidt2019two,serfaty2020gaussian} give a much better estimate on the exponential moments of $\LN(\varphi)$, but they are only stated \emph{function-wise}. Our method, which relies on those results, yields a \emph{uniform} control for the fluctuations of a certain class of $C^2$ linear statistics; see Corollary~\ref{cor:UB} and Proposition~ \ref{prop:unibound} below.

\subsection{Re-writing the Laplace transform}
\begin{lemma}[Laplace transforms as ratio of partition functions]
\label{lem:rewrite_Laplace}
Let $\varphi$ be a $C^2$ function whose Laplacian is supported on $\Dd$ and  satisfies $\int \Delta\varphi=0$. Let $t, s$ be such that:
\begin{equation}
\label{condi:t}
|t| \leq \beta N |\varphi|^{-1}_{\2}, \quad s := \frac{-t}{2\pi N \beta}.
\end{equation}
Let $\mms$ be the probability measure on $\Dd$ with density $\rms := \rm_0 + s \Delta \varphi$. The following identity holds:
\begin{equation*}
\Esp \left[ e^{t \LN(\varphi)} \right] = \exp\left( \frac{t^2}{4\pi \beta} \int_{\R^2} - \varphi \Delta \varphi \right) \frac{\KNbeta(\mms)}{\KNbeta(\mm_0)}.
\end{equation*}
\end{lemma}
Of course, if $\nabla \varphi$ is compactly supported then one can integrate by parts and write the ``variance'' term as $\int_{\R^2} |\nabla \varphi|^2$.

\begin{proof}
This follows from elementary manipulations that can be found e.g. in \cite[Section 2.6]{LebSerCLT}. It is, however, a much older idea see \cite{johansson1998fluctuations} or \cite[Sec 7.2]{ameur2011fluctuations} and the references therein.
\end{proof}

\subsection{Comparison of partition functions}
\newcommand{\tell}{\tilde{\ell}}
\newcommand{\tf}{\tilde{f}}
\begin{proposition}[Main comparison result]
\label{prop:compar1}
Let $\ell$ be a lengthscale and let $z\in \Dd$ such that $(z,{\ell})$ satisfies \eqref{condiell}. Let $\Cc$ be some positive constant. Let $\mm$ be a probability measure on $\Dd$, {whose density $\rm$ is of class $C^3$ and satisfies:}
\begin{equation}
\label{assum-Main-non-bound-m}
\hal \leq \rm \leq 2, \quad  |\rm|_\kk \leq \Cc \ell^{-k} \text{ for } \kk = 1, 2, 3.
\end{equation}
Moreover, let $f$ be a function of class $C^2$ supported in $\Dd(z, \ell)$, such that:
\begin{equation}
\label{assum-Main-non-bound-f}
\int_{\R^2} f = 0, \quad |f|_\kk \leq \Cc \ell^{-(\kk+2)} \text{ for } \kk = 0, 1, 2.
\end{equation}

Then there exists a constant $\Cc'$ depending only on $\Cc$ and $\beta$ such that the following holds. For all $s \in \R$ such that:
\begin{equation}
\label{eq:condi_s}
|s| \leq \frac{1}{\Cc'} \ell^{3/2} N^{-1/4},
\end{equation}
let $\mms$ be the probability measure with density $\rms := \rm + s f$.  We have:
\begin{equation}
\label{eq:compar1}
\log \frac{\KNbeta(\mms)}{\KNbeta(\mm)}
= N \left(\frac{\beta}{4} - 1 \right) \left( \EE(\rms) - \EE(\rm) \right)  +  s O \left(N^{3/4} \ell^{-1/2} \left(1 + \log\left(N \ell^2 \right) \right)^\hal\right),
\end{equation}
with an implicit multiplicative constant depending only on $\Cc$ and $\beta$.
\end{proposition}

We postpone the proof of Proposition \ref{prop:compar1} to Section \ref{sec:ProofCompar1}.
\begin{remark}
\label{rem:order_error}
In the statement of Proposition \ref{prop:compar1} we assume that the parameter $s$ is smaller than $O\left(\ell^{3/2} N^{-1/4}\right)$, but we eventually apply this result with $s$ of order $N^{-1}$ as in \eqref{condi:t}, which is always a valid choice for $\ell\ge \rho_\beta  N^{-1/2}$. On the other hand, the well-definiteness of $\rms$ as $\rm + s f$ only requires $s$ to be $O(\ell^{-2})$. However, for values of $s$ between $\ell^{3/2} N^{-1/4}$ and $\ell^{2}$ we do not get an interesting estimate.
\end{remark}

In Proposition \ref{prop:compar1}, we assumed
that $(z,{\ell})$ satisfies \eqref{condiell} to avoid the 
case where the perturbation is near the boundary. 
The following auxiliary lemma treats the latter case for a ``macroscopic perturbation'' ($\ell=1$), which will be enough for our purposes.

\begin{lemma}[Main comparison - macroscopic case]
\label{lem:compar_nice_bound} Let $f = 2 \pi \left( \chi - \rm_0 \right)$, where $\rm_0$ is the uniform density on $\Dd$ and $\chi$ is a smooth, radially symmetric function which is compactly supported in $\Dd_{r}$ for some $r< 1$, such that $\int \chi = 1$ and $|\chi|_{\kk} \leq \Cc$ for $\kk = 0, 1, 2$. Then there exists a constant $\Cc'$ depending only on $\Cc, \beta$ and $r$ such that the following holds: for all $s \in \R$ with $|s| \leq \frac{1}{\Cc'}$, let $\mms'$ be the probability measure with density $\rm'_s := \rm_0 + s f$.  We have:
\begin{equation}
\label{conclu-boundary}
\log \frac{\KNbeta(\mm'_s)}{\KNbeta(\mm_0)} = s O(N),
\end{equation}
with an implicit multiplicative constant depending on $\Cc, \beta$ and $r$.
\end{lemma}
Lemma \ref{lem:compar_nice_bound} is proven along the same lines as Proposition \ref{prop:compar1}, the radial symmetry of both $f$ and $\rm_0$ provides a simplification which allows us to efficiently treat the boundary case (note also that we are aiming at a less precise estimate, compare \eqref{conclu-boundary} with \eqref{eq:compar1}). We give the proof in Section \ref{sec:ProofCompar1}.


The next result builds upon Proposition~\ref{prop:compar1} and treats a situation where the perturbation $f$ is made of two pieces living at different scales.

\begin{proposition}[Comparison with mass transfer between scales]
\label{prop:compar2}
Let $\ellA< \ellB$ be two length scales and let $\zA, \zB \in \Dd$ be two points such that both $(\zA, \ellA)$ and $(\zB, \ellB)$ satisfy \eqref{condiell}.
Let $\Cc$ be some positive constant and let $\mm$ be a probability measure on $\Dd$ with a density $\rm$ is of class $C^3$ such that:
\begin{equation}
\label{assum-2-Main-non-bound-m}
\frac{3}{4} \leq \rm \leq \frac{3}{2}, \quad |\rm|_\kk \leq \Cc \ellB^{-\kk} \text{ for } \kk = 1, 2, 3.
\end{equation}
Moreover, let $\fA, \fB$ be two functions of class $C^2$ supported on $\Dd(\zA, \ellA)$ (resp. $\Dd(\zB, \ellB)$), such that, with $f=\fA+\fB$,:
\begin{equation} \label{condclt}
\int_{\R^2}  f  = 0, \quad |\fA|_\kk \leq \Cc \ellA^{-(\kk+2)},\  |\fB|_\kk \leq \Cc \ellB^{-(\kk+2)} \text{ for } \kk = 0, 1, 2.
\end{equation}
{Assume that $\Dd(\zA, \ellA)$ and $\Dd(\zB, \ellB)$ are both contained in $\Dd_r$ for some $r < 1$, so that for $N$ large enough (depending on $r$), condition \eqref{condiell} is satisfied.}
Then there exists a constant $\Cc'$ depending only on $\Cc$ and $\beta$ such that the following holds. For all $s \in \R$ such that:
\begin{equation}
\label{condi:s2}
|s| \leq \frac{1}{\Cc'} \ellA^{3/2} N^{-1/4},
\end{equation}
let $\mms$ be the probability measure with density $\rms := \rm + s f$.
%\left(\fA + \fB \right)$.
We have:
\begin{equation}
\label{eq:compar2}
\log \frac{\KNbeta(\mms)}{\KNbeta(\mm)}
= N \left(\frac{\beta}{4} - 1 \right) \left( \EE(\rms) - \EE(\rm) \right) +  O \left( s N^{3/4} \ellA^{-1/2} \left(1 + {\log(N \ellA^2)} \right)^\hal \right),
\end{equation}
with a multiplicative constant depending only on $\Cc, \beta$ {and $r$}.
\end{proposition}
We postpone the proof of Proposition \ref{prop:compar2} to Section \ref{sec:ProofCompar2}.
\begin{remark}
It is important to observe that in the conclusions of Proposition~\ref{prop:compar1} (resp. Proposition~\ref{prop:compar2}), if we work at the \emph{microscopic} scale $\ell = {\rho_\beta} N^{-1/2}$ (resp. $\ellA = {\rho_\beta} N^{-1/2}$), then for $s$ of order $N^{-1}$ (which will be our choice later on) the error term is $O(1)$, whereas as soon as $\ell$ (resp. $\ellA$) is \emph{mesoscopic} there is a gain and the error term becomes $o(1)$.
\end{remark}

{As we record in the next remark,}
Proposition~\ref{prop:compar1} yields the classical CLT for (arbitrary smooth mesoscopic) test functions supported inside $\Dd$, see \cite{LebSerCLT} and \cite{bauerschmidt2019two} for the original results.
{A CLT-like precision will be required} to show that the exponential of a regularization of $\Pot$ converges to a certain GMC measure in Section~\ref{sec-LB}, which in turn is instrumental in obtaining a lower-bound for the maximum of $\Pot$.


\begin{remark}\label{rk:clt}
Let $\varphi \in C^4(\R^2\to\R)$ be a function (possibly depending on $N$) and assume that $\Delta \phi =f$, where $f$ {is as in Proposition \ref{prop:compar1} or Proposition \ref{prop:compar2}}
Then by combining Lemma~\ref{lem:rewrite_Laplace} and Propositions~\ref{prop:compar1} or \ref{prop:compar2}, we get:
\begin{equation*}
\Esp \left[ e^{\LN(\varphi)} \right] = \exp\left( \frac{-1}{4\pi \beta} \int_{\R^2}  \varphi f\right) \exp\left(N \left(\tfrac{\beta}{4} - 1 \right) \EE(\mm) + o(1)
\right)
\end{equation*}
where $\mm =\mm_0 - \frac{f}{2\pi N \beta}$. Here we used that $\mm_0$ satisfies the conditions \eqref{assum-Main-non-bound-m} and \eqref{assum-2-Main-non-bound-m} and that $\EE(\mm_0) =0$. Moreover, since $f$ is supported in $\Dd$ with $\int f = 0$ and $ |f|_0 \leq \Cc \ell^{-2}$, we have
\[
\EE(\mm)  = \int_{\R^2} \log\big(1- \tfrac{f(x)}{2\pi N \beta}\big)
\big(1 - \tfrac{f(x)}{2\pi N \beta}\big) \d x
= o(N^{-1}).
\]
{In particular, 
$\LN(\varphi)$ converges in distribution {to a Gaussian random variable} with mean 0 and variance $\frac{1}{2\pi \beta} \int_{\R^2} |\nabla \varphi|^2$ (this last expression follows by an integration by parts).}
\end{remark}

\section{Law of large numbers: upper bound}
\label{sec-UB}
The goal of this section is to prove the upper bound part of Theorem \ref{theo:main}, namely:
\begin{proposition}
\label{prop:UB}
Recall {the definition \eqref{def:PotXN} of $\Pot$}.
For all fixed $r \in (0,1)$ and all $\alpha > 1$, we have:
\begin{equation}
\label{eq:LLNUB}
\lim_{N \to \infty} \PNbeta \left( \max_{z \in \Dd(0,r)} \Pot(z) \geq \frac{\alpha \log N}{\sqrt{\beta}} \right) = 0.
\end{equation}
\end{proposition}
{In the rest of this section we fix some $r < 1$.}

\subsection{An auxiliary linear statistics}
\label{subsec-center}
For $z \in \Dd$, let $\logz : x \mapsto \log |z-x|$. The value $\Pot(z)$ of the Coulomb gas potential at $z$ corresponds to the fluctuations $\LN(\logz)$ of the linear statistics associated to $\logz$, see \eqref{def:fluctuations}.
An important technical observation is that $\int \Delta \logz =1$ so that (even after a mesoscopic regularization), one cannot directly apply Proposition~\ref{prop:compar1} to control the exponential moments of $\LN(\logz)$.
To fix this issue, we can consider instead the fluctuation of the test function $\logz-\g$ where $\g$ is any nice function with $\int \Delta \g =1$.
It is particularly convenient to make the following choice: {we take $\chi$ to be a radially symmetric smooth function (independent of $N$) supported in $\Dd_r$}, and we let
\begin{equation}\label{eq:g}
\text{$\g$ be a solution of Poisson's equation $\Delta \g = 2\pi \chi$}.
\end{equation}
Then, the following estimate shows that the fluctuations of $\LN(\g)$ are negligible compared to the maximum of $\Pot$.

\begin{proposition}
\label{prop:expg}
One has {(for $N$ large enough depending on $\beta, r$)}
\begin{equation*}
\PNbeta \left[ |\LN(\g)| \geq (\log N)^{0.8} \right] \leq \exp\left( - \hal (\log N)^{1.5} \right).
\end{equation*}
\end{proposition}
The value $0.8$ is arbitrary, the point being that $0.8 < 1$ while $1.5>1$ and thus the probabilistic tail is better than algebraic {in $N$}.
The proof of Proposition will be given in Section~\ref{sec:proofexpo_hmu} and the argument actually shows that $\LN(\g)$ is typically of order 1 as expected, see Corollary~\ref{cor:expo_hmu}.


\subsection{A regularized version of the potential}
\label{sec:regu_pot}
 Let $\rho$ be a radial $C^\infty$ mollifier supported on the unit disk and for $\epsilon \in (0,1)$, let $\rhoep := \epsilon^{-2} \rho\left( \frac{\cdot}{\epsilon}\right)$ and let $\fze$ be defined as:
\begin{equation*}
\fze := \rhoep \star \logz - \g
\end{equation*}
where $\g$ satisfying \eqref{eq:g} is independent of $N,z$ and $\varepsilon$.
We think of $\fze$ as being an alternative to $\logz$ which is regularized in two ways: the singularity near $z$ is removed by convolving with a mollifier, and  the Laplacian of $\fze$ has total mass $0$.
Then, in view of Proposition~\ref{prop:expg}, in order to prove Proposition~\ref{prop:UB},
we first focus on controlling the exponential moments of $\LN(\fze)$.

\begin{proposition}
\label{prop:expo_fze}
For some constant {$\Cc\geq 1$} depending only on $\beta$, for all fixed $r \in (0,1)$, for all $N$ large enough (depending on $r$,$\beta$), for all $\epsilon$ {such that $\Cc N^{-1/2} \leq \epsilon \leq \frac{1 - r}{2}$} and for all $t$ such that $|t| \leq \Cc^{-1} N \epsilon^{2}$, for any $z\in\Dd_r$, we have:
\begin{equation}
\label{eq:expo_fze}
\Esp \left[ e^{t \LN(\fze)} \right] = \exp\left(\frac{t^2 \log {\epsilon^{-1}}}{2 \beta} + t^2 O_\epsilon(1) + t O_N(1) \right),
\end{equation}
with $O_\epsilon(1)$ depending only on $\beta$ and $O_N(1)$ depending on $\beta, r$.
\end{proposition}
\begin{proof}[Proof of Proposition \ref{prop:expo_fze}]
  First, we impose that $\Cc$ is large enough (depending only on $\beta$) so that the length scale $\Cc N^{-1/2}$ is larger than the minimal length scale $\trhob$ {mentioned in Section \ref{sec:Energy}}. Next, observe that $\fze$ is a $C^\infty$ function whose Laplacian is supported in {$\Dd_{r + \epsilon}$} and has mean zero. Moreover, $|\fze|_k$ is of order $\epsilon^{-k}$ for any $k\in\N$. Hence, for $|t|\le \Cc^{-1} N \epsilon^{2}$ (with $\Cc$ large enough depending only on $\beta$) we may apply Lemma \ref{lem:rewrite_Laplace} and write:
\begin{equation*}
\Esp \left[ e^{t \LN(\fze)} \right] = \exp\left( \frac{t^2}{4\pi \beta} \int_{\R^2} - \fze \Delta \fze \right) \frac{\KNbeta(\mms)}{\KNbeta(\mm_0)},
\end{equation*}
with $s = \frac{-t}{2\pi N \beta}$ and $\rms := \rm_0 + s \Delta \fze$. We have:
\begin{equation*}
 -  \int_{\R^2} \fze \Delta \fze = - 2\pi \int_{\R^2} \left( \log |\cdot| \star \rhoep \right) \rhoep + O_\epsilon(1),
\end{equation*}
and by scaling we can see that: $\int_{\R^2} \left( \log |\cdot| \star \rhoep \right) \rhoep =  \log \epsilon + O_\epsilon(1)$, so we may write:
\begin{equation}
\label{variance_treated}
\Esp \left[ e^{t \LN(\fze)} \right] \leq \exp\left( - \frac{t^2 \log \epsilon}{2 \beta} + t^2O_{\epsilon}(1) \right)  \frac{\KNbeta(\mms)}{\KNbeta(\mm_0)}.
\end{equation}
%{In order to study the ratio of partition functions in the right-hand side of \eqref{variance_treated}, let us introduce an auxiliary measure $\mm'_s$ as follows: let $\chi$ be some smooth, radially symmetric, non-negative function of total mass $1$, compactly supported on $\Dd_{r + (1-r)/10}$, such that $|\chi|_{\kk} \leq \Cc'$ for some constant $\Cc'$ depending only on $1-r$, and let:
%\begin{equation}
%\label{rpms}
%\rm'_s := \rm + s 2 \pi \left( \chi - \rm_0 \right).
%\end{equation}
%We may of course write:
%\begin{equation}
%\label{decompo_with_chi}
%\frac{\KNbeta(\mms)}{\KNbeta(\mm_0)} = \frac{\KNbeta(\mms)}{\KNbeta(\mm'_s)} \times \frac{\KNbeta(\mm'_s)}{\KNbeta(\mm_0)}.
%\end{equation}
%For the first term in the right-hand side, observe that the density $\rms$ can be written as:
%\begin{equation}
%\label{rms}
%\rms = \rm_0 + s \left(2\pi \rhoep \star \delta_z - 2\pi \rm_0\right),
%\end{equation}
%and that by combining \eqref{rpms} and \eqref{rms} we have:
%\begin{equation*}
%\rm_s = \rm'_s + s \left( 2\pi \rhoep \star \delta_z - 2 \pi \chi \right).
%\end{equation*}
%}
The assumptions of Proposition \ref{prop:compar2} are fulfilled with
$\mm= \mm_0$, $\fA = 2 \pi \rhoep$, $\fB = - 2\pi \chi$, $\zA = z$, $\zB = 0$, $\ellA = \epsilon$ and $\ellB$ fixed ({independent of $\epsilon$ and $N$}). We obtain:
\begin{equation*}
\log \frac{\KNbeta(\mms)}{\KNbeta(\mm_0)} =  N \left(\frac{\beta}{4} - 1 \right) \EE(\rms) +  O \left( s N^{3/4} \epsilon^{-1/2} \left(1 + \log (N \epsilon^2) \right)^{{\hal}}\right),
\end{equation*}
where we used that $\EE(\rm_0) =0$ and we recall that the implicit multiplicative constant depends only on $\beta$ and $r$.
A direct computation shows that $\EE(\rms)$ is $s=O(t/N)$ -- cf.~Remark~\ref{rk:clt} -- so we conclude that
\begin{equation*}
\log \frac{\KNbeta(\mms)}{\KNbeta(\mm_0)} =  O(t)+  O \left( s N^{3/4} \epsilon^{-1/2} \left(1 + \log (N \epsilon^2) \right)^\hal \right),
\end{equation*}
Using that $\epsilon \geq \Cc N^{-1/2}$, this completes the proof, the dominant error term being the first one in the right-hand side.
\end{proof}

\begin{corollary}
\label{coro:fze}
There exists $\Cc \geq 1$ depending only on $\beta$, such that for all $\lambda \geq \Cc$, taking $\epsilon = \lambda N^{-1/2}$ and $|t| \leq \lambda^2 \Cc^{-1} $ we have:
\begin{equation}
\label{eq:corofze}
\Esp \left[ e^{t \LN(\fze)} \right] \leq \exp\left(\frac{t^2 \log N}{4 \beta} + O(t^2 + t) \right),
\end{equation}
with an implicit constant depending on $\beta, r, {\lambda}$.
\end{corollary}


\subsection{Lattice approximation and {proof of the LLN upper bound}}
\label{sec:approximation}
{We have obtained in Corollary \ref{coro:fze} a control on the exponential moments of $\LN(\fze)$ \emph{for a fixed} $z \in \Dd_r$. In the first step below, we show that it yields an upper bound on $\Pot(z)$ (still for a fixed $z$). Then we get a bound controlling the values of $\Pot$ at \emph{all points $z$ on a sub-microscopic lattice} contained in $\Dd_r$. Finally, we turn it into a uniform control of $\Pot$ over $\Dd_r$.}

\subsubsection*{1. Regularization and one-point tail estimate.}
First, we observe {in Lemma \ref{lem:regulPot} below} that we can regularize the $\log$ in the definition of $\Pot$ at the microscopic scale with a small cost. For $\epsilon > 0$, let $\PNep$ be the map:
\begin{equation}
\label{def:PNep}
\PNep : z \mapsto \LN\left( \rhoep \star \logz  \right),
\end{equation}
with $\rhoep$ as in Section \ref{sec:regu_pot}. The test function $\tlog_z := \rhoep \star \logz$ is smooth, and for $z, x \in \R^2$, we have:
\begin{equation}
\label{eq:bound_tlog}
|\nabla \tlog_z (x)| \preceq \max\left(\epsilon, |z-x|\right)^{-1},\quad  \|\D^2 \tlog_z (x)\| \preceq \max\left(\epsilon, |z-x|\right)^{-2}.
\end{equation}

\begin{lemma}
\label{lem:regulPot}
For $\epsilon > 0$ and $z \in \Dd$ we have, with a universal implicit constant:
\begin{equation*}
\Pot(z) \leq \PNep(z) + O\left(N \epsilon^2 \right).
\end{equation*}
\end{lemma}
\begin{proof}
By subharmonicity of $\log$, we have $\logz \leq \rhoep \star \logz$ pointwise. On the other hand, for the centering term, a direct computation (using e.g. Newton's theorem) yields:
\begin{equation*}
\left| \int_{\R^2} \logz(x) \d \mm_0(x) - \int_{\R^2} \left( \rhoep \star \logz \right) (x) \d \mm_0(x) \right| = O\left(\epsilon^2\right).
\end{equation*}
\end{proof}
For the rest of the section, we fix:
\begin{equation}
\label{eq:choix_lambda}
\epsilon = \lambda N^{-1/2}, \quad \lambda^2 = \Cc^2 \max\left(4\sqrt{\beta},1 \right),
\end{equation}
where the constant $\Cc$ is as in Corollary \ref{coro:fze} (depending only on $\beta$). By Lemma \ref{lem:regulPot} we have, with an implicit constant depending only on $\beta$:
\begin{equation}
\label{eq:PotRegPot}
\Pot(z) \leq \PNep(z) + O\left(1 \right).
\end{equation}


\begin{lemma}
\label{lem:one_point_estimate}
Fix a point $z\in \Dd_r$ and let $\alpha\in(1, 2)$. We have:
\begin{equation}
\label{eq:one_point}
\PNbeta \left[ |\PNep(z)| \geq \frac{\alpha \log N}{\sqrt{\beta}} \right] \leq \exp\left( - \alpha^2 \log N + O(1) \right),
\end{equation}
{with an implicit constant depending on $\beta, r$}.
\end{lemma}
\begin{proof}
Take $t : = 2 \alpha \sqrt{\beta} \leq 4 \sqrt{\beta}$ so that, in view of \eqref{eq:choix_lambda}, $t\le \lambda^2 \Cc^{-2} \leq \lambda^2 \Cc^{-1}$ with $\Cc$ as in Corollary \ref{coro:fze}. Then, we may thus use \eqref{eq:corofze} and write:
\begin{equation*}
\Esp \left[ e^{t \LN(\fze)} \right] = \exp\left(\frac{t^2 \log N}{4 \beta} + O(t^2 + t) \right) = \exp\left( \alpha^2 \log N + O(1) \right),
\end{equation*}
with an implicit constant depending only on $r, \beta$. So, Markov's inequality yields:
\begin{equation}
\label{controlfze}
\begin{aligned}
\PNbeta \left[ \LN(\fze) \geq \frac{\alpha \log N}{\sqrt{\beta}}  \right]
&\leq \exp\left( - \frac{t \alpha \log N}{\sqrt{\beta}}  \right)\Esp \left[ e^{t \LN(\fze)} \right]\\
&\leq \exp\left( - \alpha^2 \log N + O(1) \right).
\end{aligned}
\end{equation}
 Note that since \eqref{coro:fze} is valid for $t\in\R$, the same bound holds for $- \LN(\fze)$ as well.
On the other hand,  by Proposition~\ref{prop:expg}, we have $|\LN(\g)| \leq (\log N)^{0.8}$ with probability $1 - \exp\left( - (\log N)^{1.5}\right)$. Since by definition $\LN(\fze) = \PNep(z) + \LN(\g)$, we may convert the control \eqref{controlfze} on $\LN(\fze)$ into a similar estimate for {$\PNep(z)$, as stated.}
\end{proof}

\subsubsection*{2. Tail estimate on a lattice.}
For $\alpha\in(1, 2)$ and fix $\delta$ (depending on $\alpha$) such that:
\begin{equation}
\label{choixdelta}
0 < \delta < \frac{\alpha^2 -1}{2}
\end{equation}
Let $\elld := N^{-\hal - \delta}$ (in particular, $\elld$ is sub-microscopic) and consider the square lattice $\Latt:=\left(\elld \Z\right)^2$.
\begin{lemma}[Tail estimate on the lattice]
  \label{lat-est}
Let $\alpha$ be in $(1, 2)$. We have:
\begin{equation}
\label{eq:tail_on_lattice}
\PNbeta \left[ \max_{z \in \Latt \cap \Dd(0,r)} |\PNep(z)| \geq \frac{\alpha \log N}{\sqrt{\beta}}  \right]  \leq \exp\left( (1 + 2\delta) \log N - \alpha^2 \log N + O(1) \right),
\end{equation}
with an implicit constant depending on $\beta, r$. {In particular we have:
\begin{equation}
\label{one-point-decay}
\PNbeta \left[ \max_{z \in \Latt \cap \Dd(0,r)} |\PNep(z)| \geq \frac{\alpha \log N}{\sqrt{\beta}}  \right] \to 0,
\end{equation}
as $N \to \infty$  -- the decay being algebraic in $N$.}
\end{lemma}
\begin{proof}
The number of points of $\Latt$ that fall into $\Dd_r$ is bounded above and below by positive constants (depending only on $r$) times $N^{1 + 2 \delta}$. Thus \eqref{eq:tail_on_lattice} follows from a simple union bound, using the one-point estimate \eqref{eq:one_point}. {From our choice \eqref{choixdelta} for $\delta$ we easily deduce \eqref{one-point-decay}.}
\end{proof}


\subsubsection*{{3. Extension to the whole disk}}
It remain to prove a result comparing the maximum of the Coulomb gas potential over the lattice points versus the whole unit disk.
Recall that $\varepsilon$ corresponds to the ``microscopic'' scale, see \eqref{eq:choix_lambda}.
\begin{proposition}[The lattice vs. the whole disk]
\label{prop:lattice}
One has
\begin{equation}
\label{eq:lattice_vs_disk}
\PNbeta \left[ \max_{z \in \Dd(0,r)} \PNep(z) \geq 1 + \max_{z' \in \Latt \cap \Dd(0,r)} \PNep(z') \right] \to 0 \text{ as } N \to \infty.
\end{equation}
\end{proposition}

\begin{proof}[Proof of Proposition \ref{prop:lattice}]
Let $z\in \Ddr$, there exists a point $z'$ in $\Latt \cap \Ddr$ such that $|z-z'| \leq 4 \elld$. We now show that, with high probability, the values of the regularized potential at $z$ and $z'$ are close. Recall the definition \eqref{def:PNep} of $\PNep$. We can write the difference $\PNep(z) -  \PNep(z')$ as $\LN( \Gzz)$, where $\Gzz$ is the function
\begin{equation*}
\Gzz(x) := \rhoep \star \logz(x) - \rhoep \star \logzp(x) = \tlog_x(z) - \tlog_x(z').
\end{equation*}
In view of the bounds \eqref{eq:bound_tlog} on the derivatives of $\tlog$, and since $|z-z'| \leq 4 \elld$, we get:
\begin{equation*}
|\Gzz(x)| \preceq  \elld \epsilon^{-1}, \quad |\nabla \Gzz(x)| \preceq \elld \epsilon^{-2} \text{ for } x \in \Dd(z', 4 \epsilon),
\end{equation*}
\begin{equation*}
|\Gzz(x)| \preceq  \elld |z-x|^{-1}, \quad |\nabla \Gzz(x)| \preceq \elld |z-x|^{-2}  \text{ for } x \notin \Dd(z', 4 \epsilon).
\end{equation*}
We introduce a sequence of intermediate length scales $\ell_0 < \dots < \ell_n$ by taking $c, n$ such that:
\begin{equation*}
n = \floor{\log \left( \frac{1 -r}{4 \epsilon} \right)}, \quad \log c := \frac{1}{n} \log \left( \frac{1 -r}{4 \epsilon} \right),
\end{equation*}
and by setting $\ell_k := c^k \epsilon$ for $k = 0, \dots, n$. Note that
$c\in [1,2]$, that $n = O(\log N)$, that $\ell_0 = \epsilon$ and that $\ell_n = \frac{1 -r}{4}$. We also set $\ell_{n+1} = M$, with $M$ large (depending on $\beta$ but not on $N$) to be chosen later. Next, we take a family $(\chi_i)_{0 \leq i \leq n+1}$ of functions such that:
\begin{equation*}
\sum_{i=0}^{n+1} \chi_i \equiv 1 \text{ on } \Dd(0, M), \quad \sum_{i=0}^{n+1} \chi_i \equiv 0 \text{ outside } \Dd(0, 2M),
\end{equation*}
each $\chi_i$ living at scale $\ell_i$ around $z'$, namely:
\begin{equation*}
|\chi_i|_\0 \leq 1, \quad |\chi_i|_\1 \preceq \ell_i^{-1}, \quad \chi_i \equiv 0 \text{ outside } \Dd(z', 4 \ell_i)\setminus \Dd(z',\ell_1/2),
\end{equation*}
%\todo{G: zero near $z'$}
and we let $\Gzz_i := \chi_i \Gzz$ for $0 \leq i \leq n$. Using the bounds on $\Gzz, \nabla \Gzz$ and the ones on $\chi, \nabla \chi_i$, a direct computation ensures that $\Gzz_i$ is (up to some multiplicative constant) $\elld \ell_i^{-2}$-Lipschitz for each $i$ - in other words, the function $\tG_i := \frac{\ell_i}{\elld} \Gzz_i$ is $\frac{1}{\ell_i}$-Lipschitz and thus satisfies the assumptions of Lemma \ref{lem_fluct_uniform}. We may write, using a convexity inequality for $\exp$:
\begin{multline*}
\exp\left( N^{\delta/2} \sum_{i=0}^{n+1} \LN(\Gzz_i) \right) = \exp\left(N^{\delta/2} \sum_{i=0}^{n+1} \frac{\elld}{\ell_i} \LN(\tG_i) \right) \\
\preceq \frac{1}{\log N} \sum_{i=0}^{n+1} \exp\left( \frac{N^{\delta/2} \elld \log N}{\ell_i} \LN(\tG_i) \right),
\end{multline*}
where we used that $n$ is of order $\log N$. Since $\frac{N^{\delta/2} \elld \log N }{\ell_i} \ll 1$, we may use the control in exponential moments given by Lemma \ref{lem_fluct_uniform} and write:
\begin{equation*}
\log \Esp \left[  \exp\left(\frac{N^{\delta/2} \elld \log N }{\ell_i} \LN(\tG_i) \right) \right] = O\left(\frac{N^{\delta/2} \elld \log N }{\ell_i} \left(N \ell_i^2\right)^\hal   \right) = O\left(N^{-\delta/2} \log N \right).
\end{equation*}
We obtain a similar control for the (macroscopic) scale $\ell_{n+1}$, see the last comment in Lemma~\ref{lem_fluct_uniform}. Then Markov's inequality yields:
\begin{equation}
\label{eq:sumGismall}
\PNbeta \left[  \sum_{i=0}^{n+1} \LN(\Gzz_i)  \geq 1 \right] \leq \exp\left(- N^{\delta/2} \right).
\end{equation}
We emphasize that since we are using Lemma \ref{lem_fluct_uniform}, which provides uniform control for fluctuations of all Lipschitz functions living at scale $\ell$ around a given point, then for fixed $z'$, the control \eqref{eq:sumGismall} is in fact uniform in $z$ i.e.
\begin{equation}
\label{comparaison_reseau}
\PNbeta \left[ \max_{z, |z-z'| \leq 4 \elld}  \sum_{i=0}^{n+1} \LN(\Gzz_i) \geq 1 \right] \leq \exp\left(- N^{\delta/2} \right).
\end{equation}

On the other hand, since by construction $\sum_{i=0}^{n+1} \chi_i \equiv 1 \text{ on } \Dd(0, M)$, any difference between $\PNep(z) -  \PNep(z') = \LN(\Gzz)$ and $\sum_{i=0}^{n+1} \LN(G_i)$ comes from hypothetical outliers living far away from the unit disk, namely outside $\Dd(0, M)$. A simple large deviation
estimate (see e.g. \cite[(1.48)]{sandier20152d})
shows that the probability of any point being outside $\Dd(0, M)$ decays as $\exp\left(-\beta N M^2\right)$ as $N \to \infty$ for $M$ large enough depending only on $\beta$ (indeed the non-negative confinement term $2 \zeta(x)$ appearing in the Boltzmann factor grows as $|x|^2$ for large $x$ as can be seen in \eqref{def:zeta}).
%\todo{G: maybe a ref for the LD?}

Finally, we obtain (by symmetry) for any fixed $z'$:
\begin{equation}
\label{comparaison_reseau_2}
\PNbeta \left[ \max_{z, |z-z'| \leq 4 \elld} \left|  \PNep(z) -  \PNep(z') \right| \geq 1 \right] \leq  \exp\left(- N^{\delta/2} \right).
\end{equation}
A union bound over $z' \in \Latt \cap \Dd$ concludes the proof.
\end{proof}

{Combining Lemma~\ref{lat-est} and Lemma \ref{prop:lattice} proves the LLN upper bound stated in Proposition~\ref{prop:UB}. Moreover, using \eqref{comparaison_reseau_2}, we obtain a quantitative tail estimate}:
\begin{corollary}\label{cor:UB}
For all $\alpha > 1$, there is a small $\nu>0$ (depending on $\alpha$) such that
\begin{equation*}
\PNbeta \left[ \max_{z \in \Dd(0,r)} \left| \PNep(z) \right| \geq \frac{\alpha \log N}{\sqrt{\beta}}  \right]  \leq \exp\left(- \nu\log N  + O(1) \right).
\end{equation*}
\end{corollary}

\subsection{Uniform control of fluctuations for smooth linear statistics}

A direct consequence of the previous estimates is a uniform bound for the fluctuations of linear statistics for a class of $C^2$ test functions with, say, $|\cdot|_2 \le 1$. Let
\begin{equation*}
\mathcal{F}_N : = \left\lbrace f \in C^2({\mathrm{D}_r}), \text{ $f$ {is supported in some disk} $\Dd(z, \ell)$ \text{ with } $\ell \ge \lambda N^{-1/2}$, and $|f|_2 \le \ell^{-2}$}\right\rbrace,
\end{equation*}
where $\lambda$ is the constant depending only on $\beta$ chosen above in~\eqref{eq:choix_lambda}.
\begin{proposition}\label{prop:unibound}
For any $k\in\N$, there is a constant $C_k = C_k(\beta)$ so that if $N$ is sufficiently large (depending on $\beta$, $k$ and $r$), 
\begin{equation*}
\PNbeta \left[ \sup_{f\in\mathcal{F}_N} \left| \LN(f) \right| \geq C_k \log N  \right]  \leq N^{-k}
\end{equation*}
\end{proposition}
\begin{proof}
  We use again $\epsilon = \lambda / \sqrt{N}$. Let $(\square_j = \square(z_j,\epsilon))_{j=1}^M$ be a collection of squares centered at points $z_j\in \epsilon \Z^2$ such that $\Dd(0,r) \subset \bigcup_{j=1}^M \square_j \subset \Dd(0,1-\delta)$ for a small $\delta>0$. {The collection can be chosen so that}
  $M \leq \Cc_\beta N$ for some constant depending on $\beta$. Using the local laws \eqref{nbest} and a union bound, we deduce that for all $k\in\N$, there is a constant $C_k = C_k(\beta)$ such that if $N$ is sufficiently large, 
\begin{equation} 
\label{eventsquare}
\PNbeta \left[ \max_{j\le M} \bXN(\square_j) \le C_k \log N \right] \ge 1- N^{-k}. 
\end{equation}
Let $f\in \mathcal{F}_N$, $\ell$ be the associated length scale, and let $f_\epsilon = f \star \rho_\epsilon$. 
Since $\rho$ is a radial mollifier (with compact support in $\Dd$) and $|f|_2\le \ell^{-2}$, one has 
\[
|f_\epsilon - f |_0  \le  (\epsilon/\ell)^2
\]
and both $f,f_\epsilon$ are compactly supported in $ \Dd(z, 2\ell)$  since $\ell\ge \epsilon$. One can tile $\Dd(z, 2\ell)$ with at most $16(\ell/\epsilon)^2$ squares of sidelength $\epsilon$, thus on the event introduced in \eqref{eventsquare} we have:
\begin{equation} \label{fapprox}
| \LN(f_\epsilon)-  \LN(f)| \le 16 C_k (1+\log N) . 
\end{equation}
Moreover, by an integration by parts we can write $\int \Delta f \,  \PNep = \LN(f_\epsilon)$, and using again that $|f|_2\le \ell^{-2}$ and that  $\Delta f$ supported in $\Dd(0,r)$, we deduce: 
\[
 |\LN(f_\epsilon)| \le \max_{z \in \Dd(0,r)} \left| \PNep(z) \right| .
\]
The RHS is controlled by Corollary~\ref{cor:UB} and, by \eqref{fapprox}, on the event introduced in \eqref{eventsquare} we can use this to control $\LN(f)$ \emph{uniformly} for all $f\in \mathcal{F}_N$. 
Adjusting the constants $C_k$, this proves the claim. 
\end{proof}

\section{Regularized multiplicative chaos: lower bound}
\label{sec-LB}
This section is devoted to the proof of the lower bound in Theorem \ref{theo:main}.

\subsection{{Reduction to a regularized version of the potential}}
Recall that  $\fze := \rhoep \star \logz - \g$, see \eqref{eq:g}, is a regularization of $\logz$ at scale $\epsilon>0$ and let $\mathcal{U} \subset \Dd$ be a (non-empty) open set.
By Proposition~\ref{prop:expg}, we know that for any (small) $\delta>0$:
\begin{equation*}
\liminf_{N\to\infty}\P\left[ \sup_{z\in\mathcal{U}} \LN(\rhoep \star \logz)  \ge (\beta^{-1/2}-\delta) \log N \right] \ge \liminf_{N\to\infty} \P\left[ \sup_{z\in\mathcal{U}} \LN(\fze)  \ge (\beta^{-1/2}-\delta/2) \log N \right].
\end{equation*}
In addition, recall that $\Pot(z) = \LN(\logz)$ so that
\[
\LN(\rhoep \star \logz) =  \LN\bigg( \int \rhoep(x) \log_{z-x}(\cdot) {\d x} \bigg)
= \int \rhoep(x) \Pot(z-x) {\d x}.
\]
The right-hand side is the convolution of the function $\Pot$ {with a non-negative function of total mass $1$} and as such
\[
\max_{z\in \mathcal{K}}  \Pot(z) \ge \sup_{z\in \mathcal{U}}   \LN({\rhoep \star \logz})
\]
where $\mathcal{K}$ is a closed ${\epsilon}$-neighborhood of $\mathcal{U}$.

Altogether, this implies that for any (small) $\delta>0$,
\begin{multline} 
\label{LB1}
\liminf_{N\to\infty}\P\left[ \max_{z\in \mathcal{K}}  \Pot(z) \ge (\beta^{-1/2}-\delta) \log N \right] \\
 \ge \liminf_{N\to\infty} \P\left[ \sup_{z\in\mathcal{U}}  \LN(\fze)  \ge (\beta^{-1/2}-\delta/2) \log N \right].
\end{multline}

Let $\mathcal{U} \subset \D$ be {some fixed} (small) ball, it suffices to show that the probability on the RHS of \eqref{LB1} converges to 1 as $N\to\infty$. It turns out that this is the case if the scale $\epsilon(N) \le N^{\nu-1/2} $ for some $\nu>0$
sufficiently small (depending on $\delta>0$).
For technical reasons, we also need that $\epsilon(N) \gg N^{-1/2} $ is larger than the microscopic scale. We claim the following:

\begin{proposition} \label{prop:maxLB}
Let $\epsilon(N)$ be a sequence so that $\epsilon(N) \to 0$ as $N\to\infty$ in such a way that  $\epsilon(N) \gg N^{-1/2} $.
Then, for any $\alpha>2$,
\begin{equation}
\label{maxLB1}
 \lim_{N\to\infty} \P\left[ \sqrt{\beta} \sup_{z\in\mathcal{U}}  \LN(\fze)  \ge \alpha \log \epsilon(N) ^{-1} \right]  = 1 .
\end{equation}
\end{proposition}
Combining \eqref{LB1} and \eqref{maxLB1}, we get: $\lim_{N\to\infty}\P\left[ \sup_{z\in \mathcal{U}}  \Pot(z) \ge \bar\alpha \log N \right] =1$ for any value $\bar\alpha > \beta^{-1/2}$, which yields the lower bound in Theorem \ref{theo:main}.

The proof of Proposition~\ref{prop:maxLB} relies on the theory of Gaussian multiplicative chaos and in particular on {\cite{CFLW21} and \cite{LOS18}.}
We review these results in the next section and present the main steps of the proof.

\subsection{Multiplicative chaos.}
We  introduce new notations.
Let $\ell(k)= e^{-k}$ for $k\in\N$ and set
\[
\Phi_{k}(z) := \sqrt{\beta}\, \LN(\varphi_{z,\ell(k)})  , \qquad z\in \Dd.
\]
For $\gamma>0$, define a sequence of random measure $(\boldsymbol\mu_k^\gamma)_{k\in\N}$ with density function
\begin{equation}
  \label{eq-mugamma}
\mu_{k}^\gamma = \frac{e^{\gamma\Phi_k}}{\Esp e^{\gamma \Phi_k}} .
\end{equation}
This density obviously depends on the $N$ and $\beta$ even though it is not emphasized {in the notation.}

\medskip

According to Proposition~\ref{prop:expo_fze}, if  $\ell(k)\geq \Cc N^{-1/2}$, it holds uniformly for $x\in\mathcal{K}$,
\begin{equation} \label{bd1}
\Esp[ e^{\gamma \Phi_k(x)} ] = \exp\left(\frac{\gamma^2 k}{2}  +  O_N(1) \right)
\asymp \ell(k)^{-\gamma^2/2} .
\end{equation}
These asymptotics corresponds to {\cite[Assumptions 3.1]{CFLW21}.}
In fact, using the method developed in  {\cite[Section 3]{CFLW21}, \cite[Section 2]{LOS18},}
we will obtain the following  convergence result (with respect to the vague topology for positive measures on $\Dd$).

\begin{proposition} \label{prop:MC}
Let $n(N)$ be a sequence such that $n(N)\to\infty$ and ${\ell(n):=\ell(n(N))} \gg N^{-1/2}$ as $N\to\infty$.
Then for any $)<\gamma<2$, $\boldsymbol\mu_{n(N)}^\gamma \to  \operatorname{GMC}_\gamma$ in distribution as $N\to\infty$ where $\operatorname{GMC}_\gamma$ is a Gaussian multiplicative chaos measure which is defined shortly. \end{proposition}

\begin{remark} \label{rk:MC}
If one consider the sequence of random measures with densities
\(
\hat\mu_{N}^\gamma = \frac{e^{\gamma\sqrt{\beta} \Pot }}{\Esp e^{\gamma\sqrt{\beta} \Pot}} 
\)
for $N\in\N$ instead of \eqref{eq-mugamma}, we expect that the result of Proposition~\ref{prop:MC} remains true, that is, for any $0<\gamma<2$,  $\boldsymbol{\hat\mu}_{N}^\gamma \to  \operatorname{GMC}_\gamma$ in distribution as $N\to\infty$ for a slightly different GMC (associated to the GFF with \emph{free boundary condition} on $\Dd$). 
Note that the regime $0<\gamma<2$ corresponds to the whole GMC $L^1$-phase, as $\gamma=2$ is the critical value with our normalization. 
\end{remark}

We now turn to the definitions of the random measures $(\operatorname{GMC}_\gamma)_{0<\gamma<2}$.
We consider the following log-correlated field.

\begin{definition} \label{def:GMC}
Let  $\Psi$ be a (distribution-valued) Gaussian process on $\D$ with mean zero and the following correlation structure: for any $f,g \in \mathcal{C}_c(\Dd)$ with $\int f = \int g =1$,
\begin{equation} \label{GFF}
\Esp\big[\Psi(f) \Psi(g)\big] %=  - \int f \log \star f
:=  \frac1{(2\pi)^2} \iint \big(f(x)-\chi(x)\big)\big(g(z)-\chi(z)\big) \log|x-z|^{-1} \d x \d z
\end{equation}
with $\chi$ as in~\eqref{eq:g}.
It is well-known that the RHS defines the covariance of a Gaussian process 
(this also follows from the CLT of Remark~\ref{rk:clt} which implies that with $\varphi =- \Delta^{-1}(f-\chi) : z\mapsto 2\pi\int \log|x-z|^{-1} (f(x)-\chi(x)) \d x$, one has $\LN(\varphi) \to \Psi(f)/\sqrt\beta$ in distribution),
so that the field $\Psi$ has correlation kernel,
\[
\Sigma(x,z) =  \log|x-z|^{-1} + \g(x) + \g(z) + c
\]
where $c\in \R$ is a constant.

For any $k\in\N$, we define $\Psi_k :=  \rho_{\ell(k)} \star \Psi $. This is a (smooth) approximation of $\Psi$ as $k\to\infty$ and, for $\gamma>0$, we also let
$\boldsymbol\nu_{k}^\gamma$ be a random measure on $\D$ with density function
\[
\boldsymbol\nu_{k}^\gamma(x) = \frac{e^{\gamma\Psi_k(x)}}{\Esp e^{\gamma \Psi_k(x)}}  ,  \qquad x\in \Dd .
\]
\end{definition}

Then, the following convergence result follows from the general theory of multiplicative chaos; e.g.~\cite{Berestycki17}.

\begin{proposition} \label{prop:GMC}
For any $\gamma <2$ (subcritical phase), the random measure $\boldsymbol\nu_{k}^\gamma \to \operatorname{GMC}_\gamma$ in probability as $k\to\infty$.
Moreover, for any (non-empty) open set $A \subset \Dd$,
$\operatorname{GMC}_\gamma(A)>0$ almost surely.
\end{proposition}


Hence, in the \emph{subcritical phase} ($\gamma<2$), as a consequence of Proposition~\ref{prop:MC} and \cite[Theorem 3.4]{CFLW21}, we
obtain Proposition~\ref{prop:maxLB}.
Finally, the proof of  Proposition~\ref{prop:MC} will be a direct application of {\cite[Theorem 2.4]{CFLW21} (reproduced there from \cite[Theorem 1.7]{LOS18}).}
Namely, it suffices to show that for any $j\in\N$, $k_1, \cdots , k_j \le n(N)$ and $\gamma_1,\cdots, \gamma_j \in
\R$,
\begin{equation} \label{asymp_mom}
\Esp\big[ e^{\gamma_1 \Phi_{k_1}(x_1) + \cdots + \gamma_j \Phi_{k_j}(x_j) } \big] =
\Esp\big[ e^{\gamma_1 \Psi_{k_1}(x_1) + \cdots + \gamma_j \Psi_{k_j}(x_j) } \big] \big(1+{o(1)} \big)
\end{equation}
uniformly for $x_1, \cdots, x_j\in \Dd_r$ (here $r<1$ is fixed).
The error term is also uniform for $k_1, \cdots k_j \le n(N)$, in which case the condition
 $\ell(n) \gg N^{-1/2}$ as $N\to\infty$ is crucial.
The next section is devoted to the proof of \eqref{asymp_mom}.


\subsection{Exponential moments asymptotics.}
We deduce \eqref{asymp_mom} from the estimates of Proposition~\ref{prop:compar2} by a simple induction.

First observe that since $\Phi_{k}(x) = \sqrt{\beta}\, \LN(\varphi_{x,\ell(k)})$ with $\Delta \varphi_{x,\ell}=  \rho_{x,\ell}- \g$,  as a consequence of Remark~\ref{rk:clt} (with $f_a = \rho_{x,\ell}=\rho((\cdot-x)\ell^{-1})\ell^{-2}$ and  $f_b = \g$ so that the conditions \eqref{condclt} hold), we have
\[
\Esp\big[ e^{\gamma \Phi_{k}(x)}\big]
 =  \exp\left( \frac{-\gamma^2}{4\pi} \int_{\R^2}  \varphi_{x,\ell(k)} \Delta \varphi_{x,\ell(k)} \right) \big(1+o(1) \big)
\]
uniformly for $x\in \Dd_r$, $\ell(k) \gg N^{-1/2}$ and locally uniformly for $\gamma\in\R$.
Moreover (by definition of the 2d Green's function for $-\Delta$ and by Fubini's theorem), according to Definition~\ref{def:GMC}, we have for $k,n \in\N$  and $x,z \in\Dd$,
\begin{align}\notag
 \frac{-1}{2\pi} \int  \varphi_{x,\ell(k)} \Delta \varphi_{z,\ell(n)}
& = \iint  \big(\rho_{x,\ell(k)}(u)-\g(u)\big)\big(\rho_{z,\ell(n)}(v)-\g(v)\big) \log|u-v|^{-1} \d u \d v  \\
\label{cov}& = \Esp[\Psi_k(x) \Psi_n(z)] .
\end{align}
Thus, since $\Psi$ is a (mean-zero) Gaussian process, we obtain for any $x\in \Dd$, $\gamma \in\R$ and  $k\ll N^{-1/2}$,
\[
\Esp\big[ e^{\gamma \Phi_{k}(x)}\big] = \Esp\big[ e^{\gamma \Psi_{k}(x)}\big] \big(1+
{o(1)} \big)
\]
with the required uniformity. This establishes that \eqref{asymp_mom} holds when $j=1$.


We now proceed by induction to extend these asymptotics for any $j\in \N$ with $j\ge 2$.
Without loss of generality, we assume that $k_1\le \cdots \le  k_j \le n(N)$. Then, according to Lemma~\ref{lem:rewrite_Laplace}, we have
\[\begin{aligned}
\Esp\big[ e^{\gamma_1 \Phi_{k_1}(x_1) + \cdots + \gamma_j \Phi_{k_j}(x_j) } \big]
&= \Esp \big[ e^{\sqrt{\beta} \LN(\varphi_j)} \big]  \\
&= \exp\left( \frac{-1}{4\pi} \int_{\R^2} \varphi_j \Delta \varphi_j \right) \frac{\KNbeta(\mm_0 +  s \Delta \varphi_j)}{\KNbeta(\mm_0)}
\end{aligned}\]
where $\varphi_j =\sum_{i\le j}  \gamma_i \varphi_{x_i,\ell(k_i)} $ and $s= \frac{-1/\beta^{1/2}}{2\pi N}$.
Moreover, using \eqref{cov}, we obtain
\[
\Esp\Big[ e^{ \sum_{i\le j}\gamma_i \Phi_{k_i}(x_i)} \Big]
=\Esp\big[ e^{\gamma_1 \Psi_{k_1}(x_1) + \cdots + \gamma_j \Psi_{k_j}(x_j) } \big]  \frac{\KNbeta(\mm_0 +  s \Delta \varphi_j)}{\KNbeta(\mm_0)}
\]
and, by taking a ratio,
\[
\frac{\Esp\Big[ e^{ \sum_{i\le j}\gamma_i \Phi_{k_i}(x_i)} \Big]}{\Esp\Big[ e^{ \sum_{i\le j}\gamma_i \Psi_{k_i}(x_i)} \Big]}
= \frac{ \Esp\Big[ e^{ \sum_{i< j}\gamma_i \Phi_{k_i}(x_i)} \Big]} { \Esp\Big[ e^{ \sum_{i< j}\gamma_i \Psi_{k_i}(x_i)} \Big]}   \frac{\KNbeta(\mm_0 +  s \Delta \varphi_j)}{\KNbeta(\mm_0+  s \Delta \varphi_{j-1})} .
\]
We now apply Proposition~\ref{prop:compar2} with $f_a =  \gamma_j \rho_{x_j,\ell(k_j)}$ and
$f_b= \gamma_j\g$ as above.
We emphasize that the conditions \eqref{condclt} hold while the reference measure $\mm = \mm_0 +  s \Delta \varphi_{j-1}$ also satisfies $|\rm - 1| \le \Cc \ell(n)^2/N$.
In particular, in the regime $\ell(n) \ll \sqrt{N}$, we obtain
\[
\log\bigg( \frac{\KNbeta(\mm_0 +  s \Delta \varphi_j)}{\KNbeta(\mm_0+  s \Delta \varphi_{j-1})} \bigg)
= N \left(\frac{\beta}{4} - 1 \right) \left( \EE(\rm+  s \Delta \varphi_j) - \EE(\rm+  s \Delta \varphi_{j-1}) \right) + {o(1),}
\]
with the required uniformity.
Now, repeating the argument from Remark~\ref{rk:clt}, the entropy
$ \EE(\rm+  s \Delta \varphi_j)  = o(N^{-1})$ for any $j\in\N$ which implies that
\[
 \frac{\KNbeta(\mm_0 +  s \Delta \varphi_j)}{\KNbeta(\mm_0+  s \Delta \varphi_{j-1})} = 1+{o(1)}  .
\]
By induction, this concludes the proof of the asymptotics \eqref{asymp_mom}.
\qed


\appendix
\section{Auxiliary proofs}

\subsection{A technical remark about partition functions}
\label{sec:tech_rem}
We import below several results from \cite{serfaty2020gaussian}, notably we use the comparison between partition functions associated to measures that coincide outside a small disk (see  \eqref{compa_relat} below). It is worth noting that our definition of the partition function $\KNbeta(\mm)$ associated to a probability measure $\mm$ on $\Dd$, as given above in \eqref{def:KNbetamu}, differs from the one in \cite{serfaty2020gaussian} by a small detail: we always integrate against the Lebesgue measure whereas $\KNbeta(\mm)$ is defined in \cite[Sec 3.3]{serfaty2020gaussian} as an integral against the product measure $\mm^{\otimes N}$. Thus the integrands differ by:
\begin{equation*}
\prod_{i=1}^N \rm(x_i) = \exp\left( \sum_{i=1}^N \log \rm(x_i) \right) = \exp\left(N \int \log \rm(x) \d \mm(x) + \LNmu(\log \rm) \right).
\end{equation*}
In the first term we recognize $N \EE(\rm)$, where $\EE$ is the relative entropy as in Section~\ref{sec:not}, which is the reason why our statement of e.g. Lemma \ref{lem:relative_expansion} has an extra relative entropy term in \eqref{compa_relat} compared to the corresponding expressions in \cite{serfaty2020gaussian}. On the other hand, the fluctuation term $\LNmu(\log \rm)$ contributes $O(1)$, which always gets absorbed into our main error term. This follows from the fact that fluctuations of smooth enough test functions are bounded in exponential moments, see e.g. \cite[Sec. 2.3]{serfaty2020gaussian}.


\subsection{Proof of Proposition \ref{prop:compar1} and Lemma \ref{lem:compar_nice_bound}}
\label{sec:ProofCompar1}

\subsubsection{Proof of Proposition \ref{prop:compar1}}
We combine the following tools from \cite{LebSerCLT,serfaty2020gaussian}. 
\begin{enumerate}
\item Approximate transport and estimates on the approximation error.
\item Comparison of partition functions along  the approximate transport \& the anisotropy term.
\item Relative expansion of partition functions.
\item ``Serfaty's trick'' for proving smallness of the anisotropy term.
\end{enumerate}
{We next review the main arguments.}

\paragraph{\emph{1. Approximate transport.}}
By assumption, the perturbation $f$ is supported in $\Dd(z, \ell)$ and thus in a square $\square(z, \ell)$ of sidelength $\ell$. Using \cite[Lemma 4.8]{serfaty2020gaussian} together with \cite[(4.31)]{serfaty2020gaussian} and applying our assumptions \eqref{assum-Main-non-bound-m} and \eqref{assum-Main-non-bound-f}, we can find a vector field $\psi$, supported on $\square(z, \ell)$, such that
\begin{equation}
\label{assum_psi}
- \div(\rm \psi) = f, \quad |\psi|_\kk \leq \bar \Cc \Cc \ell^{-1 - \kk}, \text{ for } \kk = 0, 1, 2, 3,
\end{equation}
where $\Cc$ is as in the statement and $\bar \Cc$ is a universal constant.

For $s \in \R$, we define a map $\Phi_s$ and another probability measure $\tmms$ by:
\begin{equation}
\label{approx_objects}
\Phi_s := \id + s \psi, \quad \tmms := \Phi_s \# \mm.
\end{equation}
In view of \eqref{assum_psi} we can guarantee that $|\Phi_s - \id|_\1 \leq \hal$ as long as the parameter $s$ is chosen smaller than $\frac{1}{\Cc} \ell^2$ for some $\Cc$ large enough, a condition which is implied by the stronger constraint \eqref{eq:condi_s} ({recall that $N \ell^2$ is always larger than $1$}). We think of $\Phi_s$ as an \emph{approximate transport map}, pushing $\mm$ forward not quite onto $\mms$ (whose density is $\rm + s f$) but rather on $\tmms$. The following lemma quantifies the error in terms of partition functions.

\begin{lemma}
\label{lem:ApproxError}
The partition functions associated to $\tmms$ and $\mms$ are close:
\begin{equation*}
\left|\log \KNbeta(\tmms) - \log \KNbeta(\mms) \right| = O\left(s^2 N \ell^{-2} \right),
\end{equation*}
and so are their relative entropies:
\begin{equation*}
\left| \EE(\trms) - \EE(\rms) \right| = O\left(s^2 N \ell^{-2}\right),
\end{equation*}
with implicit constants depending only on \eqref{assum_psi} and $\beta$.
\end{lemma}
\begin{proof}
The first point follows from combining \cite[Lemma 5.1]{serfaty2020gaussian}, which bounds $|\trms - \rms|_{\kk}$ for $\kk = 1, 2$ in terms of the norms of $\psi$ (controlled in \eqref{assum_psi}) and $\mm$ (controlled by assumption), and \cite[Lemma 4.9]{serfaty2020gaussian}, which states a direct comparison of the partition functions in terms of $\tmms - \mms$. To prove the second point, we use again \cite[Lemma 5.1]{serfaty2020gaussian}, which bounds $|\trms - \rms|_{\0}$ by $O(s^2 \ell^{-4})$, and plug that estimate into the definition of $\EE$.
\end{proof}


\paragraph{\emph{2. Comparison of partition functions along a transport.}}
\newcommand{\ErrorF}{\mathsf{ErrorF}}
The so-called ``anisotropy term'' was introduced in \cite{LebSerCLT}, cf. also the ``angle term'' in \cite[Section 8]{bauerschmidt2019two}. We refer to \cite[Section~4]{serfaty2020gaussian} for a careful study of its properties. It can be understood as the first-order correction to the energy when one pushes \emph{both the configuration and the background measure} by a small perturbation of the identity map. Here we will not go into the details and we treat the anisotropy as a black box. The key estimates that we need to import are contained in the following lemma. Let $s, \psi, \Phi_s, \tmms$ be as above (in particular $\psi$ is  supported on $\square(z, \ell)$) and recall that $\EnerPts(z, \ell)$ (defined in \eqref{def:EnerPts}) controls both the energy and the number of points at scale $\ell$ near $z$, and is typically of order $N\ell^2$. 

\begin{lemma}
\label{lem:AAAni}
There exists a term $\AA[\psi, \mm, \XN]$ (independent of $s$) satisfying:
\begin{equation}
\label{boundAni}
\AA[\psi, \mm, \XN] = \ell^{-2}  O\left(\EnerPts(z,\ell)\right),
\end{equation}
and such that provided $|s|$ is smaller than $\ell^2$:
\begin{equation}
\label{Ani_ordre_2}
\F\left( \Phi_s(\XN), \tmms \right) = \F(\XN, \mm) + s \Ani[\psi, \XN, \mm] + s^2 \ErrorF,
\end{equation}
with a ``second order'' error term $\ErrorF$ bounded by:
\begin{equation}
\label{ErrorF}
\ErrorF = O \left( \ell^{-4} (1 + \log(\ell N^{1/2})) \right) \EnerPts(z,\ell).
\end{equation}
with implicit constants in \eqref{boundAni} and \eqref{ErrorF} depending only {on the constant $\Cc$ in \eqref{assum-Main-non-bound-m}, \eqref{assum-Main-non-bound-f}}.
\end{lemma}


\begin{proof}[Proof of Lemma \ref{lem:AAAni}]
  We apply \cite[Prop. 4.2]{serfaty2020gaussian} to the vector field $\psi$ chosen above. The main task is to check that {\cite[(4.7)]{serfaty2020gaussian}}, which bounds the second derivative of the energy along a transport, can itself be controlled by our $\ErrorF$.
\begin{itemize}
	\item We use \eqref{assum_psi} to bound $\psi$ and its derivatives.
	\item Using our assumptions on $\rm$ and $f$ we can control the derivatives of $\rm_s$ by:
	\begin{equation*}
	|\rm_s|_\kk \leq |\rm|_\kk + s |f|_\kk \leq \Cc \ell^{-\kk} + s \Cc \ell^{-\kk +2},
	\end{equation*}
	but we are taking $|s| \ll \ell^2$ (see \eqref{eq:condi_s}  and \eqref{condiell}) so we can replace $|\rm_s|_\kk$ by $\Cc \ell^{-\kk}$ for $\kk = 1, 2$.
In particular, $N^{-\kk/2} |\rm_s|_\kk \preceq 1$   for $\kk = 1, 2$.
\end{itemize}
Combining these observations and studying \cite[(4.8)]{serfaty2020gaussian}, we are left with:
\begin{equation*}
\left(\ell^{-4} \Cc + \ell^{-5} N^{-1/2} \log( \ell N^{1/2} ) \Cc\right) \times \log ( \ell N^{1/2} ) \EnerPts(z, \ell) +
\Cc \ell^{-5} N^{-1/2} \EnerPts(z, \ell).
\end{equation*}
Simplifying a bit and using that $\frac{1}{\ell^2 N} \leq 1$, we can indeed take $\ErrorF$ as in \eqref{ErrorF}.
\end{proof}


For convenience, we denote by $\Ani$ the quantity:
%such that:
\begin{equation}
\label{eq:defAni}
\Ani[\psi, \mm, \XN] := \AA[\psi, \mm, \XN] - \frac{1}{4} \sum_{i=1}^N \div\ \psi(x_i).
\end{equation}
We can now state the conclusion of this paragraph:
\begin{lemma}[Comparison of partition functions along a transport]
\label{lem:transport}
We have:
\begin{multline}
\label{compa_transport}
\log \frac{\KNbeta(\tmms)}{\KNbeta(\mm)} = \left(\frac{\beta}{4} - 1 \right) N \left( \EE(\trms) - \EE(\rm) \right) \\ + \log \Esp_{\Pbeta_{N, \mm}} \left[\exp\left(s \Ani[\psi, \XN, \mm] + s^2 \ErrorF \right) \right].	
\end{multline}
\end{lemma}
We recall that the notation $\Pbeta_{N, \mm}$ was introduced in \eqref{def:PNbetamu}.
\begin{proof}[Proof of Lemma \ref{lem:transport}] It follows the same steps as \cite[Prop. 4.3]{LebSerCLT}. In short:
\begin{enumerate}
	\item We change variables {by $\Phi_s$} in the integral defining $\KNbeta(\tmms)$ and use Lemma \ref{lem:AAAni} to expand the interaction energy, hence the terms $\AA$ and $\ErrorF$ appear in the exponential. We replace $\AA$ by $\Ani$ up to the correction mentioned in \eqref{eq:defAni}.
	\item The Jacobian of this change of variables is $\exp\left(\sum_{i=1}^N \log \det \D \Phi_s(x_i)\right)$. {The exponent} can be related to the difference of entropies between $\mms$ and $\mm$, up to a fluctuation term (the fluctuations of $x \mapsto \log \det \D \Phi_s(x)$), which itself is bounded using Lemma \ref{lem_fluct_uniform} and is negligible compared to the estimate \eqref{ErrorF} for
	  the ``second order'' error $\ErrorF$.
	\item The difference between $\Ani$ and $\AA$ as in \eqref{eq:defAni} also happens to be equal to the difference of relative entropies (up to some multiplicative factor) plus an error term that is negligible compared to $\ErrorF$.
\end{enumerate}
\end{proof}


\paragraph{\emph{3. Relative expansion of partition functions.}}
The following is contained in \cite[Prop. 6.4]{serfaty2020gaussian} (keeping in mind the remark of Section \ref{sec:tech_rem}).
\begin{lemma}[Relative expansion of partition functions]
\label{lem:relative_expansion}
Let $(z, \ell)$ such that \eqref{condiell} holds, and let $\mm, \tmm$ be two probability measures on $\Dd$ such that $\rm = \trm$ outside $\Dd(z, \ell)$. Assume that $\rm, \trm$ are of class $C^1$ and satisfy $\hal \leq \rm, \trm \leq 2$ on $\Dd$. Assume also that $|\rm|_\1 + |\trm|_\1 \leq \Cc \ell^{-1}$ for some constant $\Cc$. Then:
\begin{equation}
\label{compa_relat}
\log \frac{\KNbeta(\tmm)}{\KNbeta(\mm)} = \left(\frac{\beta}{4} - 1 \right) N \left( \EE(\trm) - \EE(\rm) \right) + O \left( N \ell^2 \right)^\hal \left(1 + \log \left(N \ell^2\right) \right)^\hal,
\end{equation}
with an implicit constant depending only on $\Cc$ and $\beta$.
\end{lemma}

\paragraph{\emph{4. Serfaty's trick.}}
It is hard to prove a bound on $\Ani$ that is better than \eqref{boundAni} and holds \emph{configuration-wise}. However one can improve the control on $\Ani$ \emph{in exponential moments}, using the following trick.
Recall the assumption  \eqref{condiell}.
%\todo[inline]{G: Assumption \eqref{condiell}?}

\begin{lemma}[Smallness of the anisotropy]
\label{lem:AniSmall}
There exists $\Cc'$ depending only on {on the constant $\Cc$ in \eqref{assum-Main-non-bound-m}, \eqref{assum-Main-non-bound-f}} such that if $|s| \leq \frac{1}{\Cc'} \ell^{3/2} N^{-1/4}$, we have:
\begin{equation}
\label{ani_small}
\log \Esp_{\Pbeta_{N, \mm}} \left[\exp\left(s \Ani[\psi, \XN, \mm]\right) \right] = O\left(s N^{3/4} \ell^{-1/2} \left(1 + \log\left(N \ell^2 \right) \right)^\hal \right) ,
\end{equation}
with an implicit constant depending only on $\Cc'$ and $\beta$.
\end{lemma}
\begin{proof}[Proof of Lemma \ref{lem:AniSmall}]
We first take $s = \sstar := \frac{1}{\Cc'} \ell^{3/2} N^{-1/4}$ for some large enough constant $\Cc'$ (if $\ell$ is of order $N^{-1/2}$ then $\ell^2$ and $\ell^{3/2} N^{-1/4}$ are comparable, thus we need to divide by $\Cc'$ large enough in order to match our previous assumptions on $s$. For mesoscopic length scales, this is irrelevant). By comparing the two expressions \eqref{compa_transport} and \eqref{compa_relat} and discarding negligible terms one gets:
\begin{equation}
\label{sstar}
\log \Esp_{\Pbeta_{N, \mm}} \left[\exp\left(\sstar \Ani[\psi, \XN, \mm] + \sstar^2 \ErrorF \right) \right] = O\left( \left(N \ell^2 \right)^\hal \left(1 + \log \left(N \ell^2\right) \right)^\hal \right).
\end{equation}
Using the expression \eqref{ErrorF} for $\ErrorF$ and the local law \eqref{loc_laws} we know that:
\begin{equation}
\label{usingErrorF}
\log \Esp_{\Pbeta_{N, \mm}} \left[\exp\left( \sstar^2 \ErrorF \right) \right] \leq O\left(  \ell^{-1} N^{-1/2} \log(\ell N^{1/2}) N \ell^2  \right)   =  O\left( \ell N^{1/2} \log(\ell N^{1/2}) \right)  .
\end{equation}
Combining \eqref{sstar} and \eqref{usingErrorF} and using Cauchy-Schwarz's inequality we deduce that:
\begin{equation*}
\log \Esp_{\Pbeta_{N, \mm}} \left[\exp\left(\hal \sstar \Ani[\psi, \XN, \mm] \right) \right] \leq O\left( \left(N \ell^2 \right)^\hal \left(1 + \log \left(N \ell^2\right) \right)^\hal \right) + O\left( \ell N^{1/2} \log(\ell N^{1/2}) \right),
\end{equation*}
and thus for $s = \hal \sstar$:
\begin{equation*}
\log \Esp_{\Pbeta_{N, \mm}} \left[\exp\left(\hal \sstar \Ani[\psi, \XN, \mm] \right) \right] = O\left( \left(N \ell^2 \right)^\hal \left(1 + \log \left(N \ell^2\right) \right)^\hal \right)
\end{equation*}
For smaller values of $s$, we apply Hölder's inequality and obtain \eqref{ani_small}.
\end{proof}

\paragraph{\emph{5. Conclusion}}
We compare $\KNbeta(\mms)$ and $\KNbeta(\tmms)$ using Lemma \ref{lem:ApproxError} and then apply Lemma \ref{lem:transport} to compare $\KNbeta(\tmms)$ and $\KNbeta(\mm)$, using Lemma \ref{lem:AniSmall} to control the anisotropy term. Lemma \ref{lem:ApproxError} also allows us to replace $\EE(\trms)$ by $\EE(\rms)$ up to some error. Finally one can check that for $|s| \leq \sstar$ the dominant error term is the one coming from \eqref{ani_small}, which yields \eqref{eq:compar1}. \qed

\begin{remark}
In view of the remark made in Section \ref{sec:tech_rem}, one could wonder whether a difference of order $O(1)$ between the value of $\log \KNbeta(\mm)$ as defined in \cite{serfaty2020gaussian} and the definition used here might not create a problem when the length scale $\ell$ is mesoscopic. Indeed in that case Proposition~\ref{prop:compar1} is stated with an error term that is $o(1)$, see Remark~\ref{rem:order_error}. In fact, one only  needs a comparison of partition functions as stated in \cite{serfaty2020gaussian}  in steps 3 and 4 of the proof of Proposition~\ref{prop:compar1}, and we apply Lemma~\ref{lem:relative_expansion} (which is a direct consequence of \cite[Prop. 2.4]{serfaty2020gaussian}) for a ``large'' value of $s$ (namely $s = \sstar$ of order $\ell^{3/2} N^{-1/4} \gg N^{-1}$ for $\ell$ mesoscopic). At that point the effective error term is larger than $1$ (see \eqref{sstar}) and thus one can harmlessly incorporate an additional $O(1)$ error.

On the other hand, the comparison result of Lemma \ref{lem:transport}  does not rely on \cite{serfaty2020gaussian} regarding the definition of partition functions.
\end{remark}

\subsubsection{Proof of Lemma \ref{lem:compar_nice_bound}}
Compared to the previous proof, we dispense with Step 1 as one can easily find an exact transport, as well as Steps 3 and 4 because we are not aiming for precise estimates on the anisotropy. \\
Since the reference measure is $\mm_0$ and since $f$ has radial symmetry, it is easy to construct a bijective, ``radial rearrangement'' map $\Phi_s : \Dd \to \Dd$ that pushes $\mm_0$ onto $\mm_0 + s f$ and can be written as $\Phi_s = \id + \alpha_s(x) x$ on $\Dd$, for some radial function $\alpha_s$ whose derivative is bounded on $\Dd$ by $s \Cc''$ for some constant $\Cc''$ depending only on $\Cc$ and $r$. We can always extend $\alpha_s$ into a $C^1$, compactly supported function on $\Dd_2$ with $|\alpha_s| \leq \hal, |\alpha_s|_1 \leq s \Cc''$.\\
Applying \cite[Prop 4.2]{serfaty2020gaussian} (note that now, compared to the proof of Proposition \ref{prop:compar1}, we are only able to use - and in fact only need - results where the vector field $\psi$ is simply assumed to be $C^1$, see in particular \cite[(4.6)]{serfaty2020gaussian}) to $\Phi_s$ and changing variables as in the previous proof, we obtain (see also \cite[(4.3)]{serfaty2020gaussian})
\begin{equation*}
\log \frac{\KNbeta(\mm'_s)}{\KNbeta(\mm_0)} = \log \Esp \left[ \exp\left( s 
\Cc'' \EnerPts(\Dd_2) \right) \right],
\end{equation*}
but the number of points in $\Dd_2$ is always $\leq N$ and the (fluctuations of the) global energy %(after adding $\frac{1}{4} N \log N$ as in \eqref{def:EnerPts})
have exponential moments of order $N$ (this “global law” follows from \eqref{global_law}). We thus get \eqref{conclu-boundary}.
\qed


\subsection{Proof of Proposition \ref{prop:compar2}}
\label{sec:ProofCompar2}
\begin{proof}[Proof of Proposition \ref{prop:compar2}]
We introduce a sequence of intermediate length scales $\ellA = : \ell_0 < \dots < \ell_n : = \ell :=   \min\left(\ellB, \frac{1}{4}\left(1 - \dist(\zA, \partial \Dd)\right) \right)$ by defining $c, n$ as:
\begin{equation*}
n = \floor{\log \left( \ell / \ellA \right)}, \quad \log c := \frac{1}{n} \log \left( \ell/\ellA \right),
\end{equation*}
and by setting $\ell_k := c^k \ellA$ for $k = 0, \dots, n$. Note that $c \in [1,2]$  and $(\zA, \ell_i)$ satisfy \eqref{condiell} for all $i\le n$ even if the larger length scale $\ellB$ is macroscopic. Moreover, $\ellB$ and $\ell$ are always comparable.

For each $i = 0, \dots, n$ we fix a smooth cut-off function $\chi^{(i)}$ such that:
\begin{equation*}
\chi^{(i)} \equiv 1 \text{ on } \Dd(\zA, \ell_i), \quad \chi^{(i)} \equiv 0 \text{ outside } \Dd(\zA, 2 \ell_i), \quad |\chi^{(i)}|_{\kk} \leq 100 \ell_i^{-\kk} \text{ for } \kk = 1, 2, 3,
\end{equation*}
and we define $\mmsi$ as the probability measure with the following density:
\begin{equation}
\label{def:rmsi}
\rmsi := \rm + s \fB + s  \left(\int_{\R^2} \fA\right) \frac{\chi^{(i)}}{\int_{\R^2} \chi^{(i)}}.
\end{equation}
 In particular, in case $\int \fA =0$, this construction is not relevant and we can directly apply
Proposition \ref{prop:compar1} twice to compare ${\KNbeta(\mms)}$ to ${\KNbeta(\mm+s \fB)}$ and then ${\KNbeta(\mm+s \fB)}$ to ${\KNbeta(\mm)}$.
This is also the case if the scales $\ellA$ and $\ellB$ are comparable, which corresponds to the case where $n$ is independent of $N$.

Using our assumptions on $\mm, \fA, \fB, \chi^{(i)}$ and the fact that \eqref{condi:s2} and \eqref{condiell} imply that $|s|$ is of order at most $\ellA^2$ (the minimal scale in this problem), we obtain that on $\Dd$ the density $\rmsi$ satisfies:
\begin{equation}
\label{reg_msi}
\frac{1}{2} \leq \rmsi \leq 2, \quad |\rmsi|_\kk \preceq \Cc \ell_i^{-\kk} \text{ for } \kk = 1, 2, 3.
\end{equation}

We decompose the ratio of partition functions as :
\begin{equation*}
\frac{\KNbeta(\mms)}{\KNbeta(\mm)} = \frac{\KNbeta(\mms)}{\KNbeta(\mms^{(0)})} \times \prod_{i=0}^{n-1} \frac{\KNbeta(\mmsi)}{\KNbeta(\mmsip)} \times \frac{\KNbeta(\mms^{(n)})}{\KNbeta(\mm)}.
\end{equation*}
For each $i = 0, \dots, n-1$, in view of \eqref{def:rmsi} we may write:
\begin{equation*}
\rmsi = \rmsip + s \fii, \text{ with } \fii := s \left(\int_{\R^2} \fA\right) \left( \frac{\chi^{(i)}}{\int_{\R^2} \chi^{(i)}} - \frac{\chi^{(i+1)}}{\int_{\R^2} \chi^{(i+1)}} \right).
\end{equation*}
Since $\int \fA$ is of order $1$ (this follows from \eqref{condclt}), while $\int \chi^{(i)}$ is of order $\ell_i^2$, the perturbation $\fii$ satisfies:
\begin{equation}
\label{reg_fii}
|\fii|_{\kk} \preceq \ell_i^{-(\kk+2)} \text{ for } \kk = 0, 1, 2.
\end{equation}
In view of \eqref{reg_msi} and \eqref{reg_fii} we can apply Proposition \ref{prop:compar1} with the length scale chosen as $\ell_i$ and we obtain:
\begin{equation*}
\log \frac{\KNbeta(\mmsip)}{\KNbeta(\mmsi)}\\
= N \left(\frac{\beta}{4} - 1 \right) \left( \EE(\rmsip) - \EE(\rmsi) \right) +  O \left( s N^{3/4} \ell_i^{-1/2} \left(1 + \log\left(N \ell_i^2 \right) \right)^\hal\right),
\end{equation*}
The same reasoning applies for $\frac{\KNbeta(\mms)}{\KNbeta(\mm^{(0)})}$ (which corresponds to the smallest length scale $\ellA$) and for $\frac{\KNbeta(\mm_s^{(n)})}{\KNbeta(\mm)}$ (which corresponds to the largest length scale $\ell$ --  either equal to $\ellB$ or  of order $1$). Summing the contributions, we obtain:
\begin{equation*}
\log \frac{\KNbeta(\mms)}{\KNbeta(\mm)} = N \left(\frac{\beta}{4} - 1 \right) \left( \EE(\rms) - \EE(\rm) \right) + O\left( s \sum_{i=0}^n  N^{3/4} \ell_i^{-1/2} \left(1 + \log\left(N \ell_i^2 \right) \right)^\hal \right).
\end{equation*}
The sum over dyadic scales can be compared to an integral and we get:
\begin{equation*}
\sum_{i=0}^n  N^{3/4} \ell_i^{-1/2} \left(1 + \log\left(N \ell_i^2 \right) \right)^\hal = O \left( N^{3/4} \ellA^{-1/2} \left(1 + \log(N\ellA^2) \right)^\hal \right),
\end{equation*}
which yields \eqref{eq:compar2} as claimed.
\end{proof}


\subsection{Proof of Proposition \ref{prop:expg}}
\label{sec:proofexpo_hmu}

Let $\hmu$ denote the electrostatic potential generated by the uniform background $\mm_0$, namely:
\begin{equation*}
\hmu : z \mapsto \int_{\Dd} \log|z-x| \d \mm_0(x) = \int_{|x| \leq 1} \log|z-x| \frac{\d x}{\pi},
\end{equation*}
a quantity that already appeared in the definition \eqref{def:PotXN} of $\Pot$. An explicit computation gives the following expression
\begin{equation}
\label{def:hmu}
\hmu : z \mapsto \begin{cases}
\log |z| & \text{if } |z| \geq 1 \\
-\frac{1 - |z|^2}{2} & \text{ if } |z| \leq 1.
\end{cases}
\end{equation}
The potential $\hmu$ satisfies Poisson's equation $\Delta \hmu = 2\pi \mm_0$. In particular, $\Delta \hmu$ does \emph{not} have total mass $0$. Yet, using a simple trick that is totally unrelated to the methods of \cite{LebSerCLT,serfaty2020gaussian}, we are able to control the size of $\LN(\hmu)$ as expressed in the following proposition:
\begin{proposition}[Exponential moments of $\hmu$]
\label{prop:expo_hmu}
We have, for $|t| \leq \frac{N \beta}{100}$:
\begin{equation*}
\log \Esp \left[ \exp\left( t \LN(\hmu) \right) \right] = O(t + t^2),
\end{equation*}
with an implicit constant depending only on $\beta$.
\end{proposition}
{Proposition \ref{prop:expo_hmu}} gives us the crucial freedom to
substract a multiple of $\hmu$ from a given test function and to cancel out the masses of their Laplacians, while making a (typically) bounded error on the size of the linear statistics. We postpone the proof of Proposition \ref{prop:expo_hmu} for now and deduce from it a generalization of Proposition \ref{prop:expg}.

\begin{corollary} \label{cor:expo_hmu}
 Let $\chi$ be a $C^2$, radially symmetric function which is compactly supported in $\Dd_{r}$ for some $r< 1$, such that $|\chi|_{\kk} \leq \Cc$ for $\kk = 0, 1, 2$.
 Let $\g$ be a solution of Poisson's equation $\Delta \g =  2\pi\chi$. Then, one has for $|t| \ll N$,
\[
\log\Esp [ e^{t \LN(\g)}]  = O(t + t^2)
\]
where the implied constant depends only on $\beta$.
\end{corollary}


\begin{proof}
Let $c=\int \chi$ which is of order 1 (by assumptions) and let $\varphi = \g - c\hmu$.
By Lemmas~\ref{lem:rewrite_Laplace} and~\ref{lem:compar_nice_bound}, one has for $|t| \ll N$,
\[
\log\Esp [ e^{t \LN(\varphi)}]  = O(t + t^2) .
\]
This estimate is comparable to that of Lemma~\ref{prop:expo_hmu}, thus the claim follows directly from H\"older's inequality.
\end{proof}

\begin{proof}[Proof of Proposition \ref{prop:expo_hmu}]
This relies on the following two claims:
\begin{claim}
\label{claim_zeta}
For $|t| \leq \beta N$, we have:
\begin{equation}
\label{eq:zeta_does_not_matter}
\log \Esp\left[ e^{t  \sum_{i=1}^N \zeta(x_i) } \right] =  o(t).
\end{equation}
\end{claim}
\begin{proof}
This follows from the analysis of \cite{LebSerCLT}. We return to the notation of \eqref{def:KNbeta}, \eqref{def:KNbetamu} for partition functions and make them more explicit
 by writing:
\begin{equation*}
\KNbeta(\mm_0, \zeta) := \int_{\left(\R^2\right)^N} \exp\left( - \beta \left( \F(\XN, \mm_0) + 2N \sum_{i=1}^N \zeta(x_i) \right) \right) \d\XN,
\end{equation*}
where we explicitly keep track of both the background measure (as in \eqref{def:KNbetamu}) \emph{and} the ``effective confining potential'' $\zeta$. By \cite[Corollary 1.1]{LebSerCLT} or \cite[(4.12)]{LebSerCLT} one finds an expansion for $\log \KNbeta(\mm_0, \zeta)$ up to order $o(N)$ which \emph{does not depend on $\zeta$} (see \cite[Remark 4.3]{LebSerCLT}). Thus in particular, taking $t = \pm \beta N$ in the left-hand side of \eqref{eq:zeta_does_not_matter} we get:
\begin{equation*}
\log \Esp\left[ e^{ \pm \beta N  \sum_{i=1}^N \zeta(x_i) } \right] = \log \KNbeta(\mm_0, \zeta \mp \frac{1}{2} \zeta) - \log \KNbeta(\mm_0, \zeta) = o(N).
\end{equation*}
The claim follows from H\"{o}lder's inequality.
\end{proof}


\begin{claim}
\label{claim_scalin}
For $|t| \leq \frac{N \beta}{2}$, we have:
\begin{equation}
\label{scaling_xi}
\Esp\left[ e^{t \sum_{i=1}^N |x_i|^2 } \right] = \exp\left(-\log\left( 1 - \frac{t}{\beta N} \right) \left(\frac{\beta N(N-1)}{4} + N \right)  \right).
\end{equation}
\end{claim}
\begin{proof}
It follows by a scaling argument using the equivalent expression \eqref{eq:Pnbetav2} for the joint law of the particles.
\end{proof}

We may now prove Proposition \ref{prop:expo_hmu}. On the one hand, using the expression \eqref{def:hmu} of $\hmu$ and an elementary computation we get:
\begin{equation*}
\int \hmu(x)  \d \mm_0(x) = \int \frac{|x|^2 - 1}{2} \d \mm_0(x) = - \frac{1}{4}.
\end{equation*}
On the other hand, a Taylor's expansion of \eqref{scaling_xi} gives (for $\frac{|t|}{\beta N}$ small):
\begin{equation*}
\Esp\left[ e^{t \sum_{i=1}^N |x_i|^2} \right] = \exp\left( \frac{t N}{4} + O(t + t^2) \right),
\end{equation*}
and we deduce that:
\begin{multline}
\label{esp_presque_hmu}
\Esp\left[ e^{ t \left( \sum_{i=1}^N \frac{|x_i|^2 - 1}{2} \right) - t N \int \hmu(x)  \d \mm_0(x) } \right] = \Esp\left[ e^{ \frac{t}{2}  \sum_{i=1}^N |x_i|^2  - \frac{tN}{2} + \frac{tN}{4} } \right] \\
= \Esp\left[ e^{ \hal \left( \frac{t N}{4} + O(t + t^2) \right) - \frac{t N}{8} } \right]  = \Esp\left[ e^{ O(t + t^2) } \right].
\end{multline}
Since the expression of $\hmu(x)$ is not always $\frac{|x|^2 - 1}{2}$ but rather $\frac{|x|^2 - 1}{2} - \zeta(x)$ in general (compare \eqref{def:hmu} with \eqref{def:zeta}), we can write:
\begin{equation*}
\Esp\left[ e^{ t \LN(\hmu)} \right] = \Esp\left[ e^{ t \left( \sum_{i=1}^N \frac{|x_i|^2 - 1}{2} \right) - t N \int \hmu(x)  \d \mm_0(x) - t \sum_{i=1}^N \zeta(x_i)} \right].
\end{equation*}
Using Cauchy-Schwarz's inequality combined with \eqref{eq:zeta_does_not_matter} and \eqref{esp_presque_hmu} we prove Proposition \ref{prop:expo_hmu}.
\end{proof}


\bibliographystyle{alpha}
\bibliography{LLNMaxPotbib}

\end{document}
