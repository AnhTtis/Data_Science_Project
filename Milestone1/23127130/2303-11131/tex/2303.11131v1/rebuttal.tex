% Template for ICASSP-2021 paper; to be used with:
%          spconf.sty  - ICASSP/ICIP LaTeX style file, and
%          IEEEbib.bst - IEEE bibliography style file.
% --------------------------------------------------------------------------

\documentclass{article}
\usepackage{spconf,amsmath,graphicx}
\usepackage{adjustbox}
\usepackage{color}
\usepackage{xcolor}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{url}

\def\arrvline{\hfil\kern\arraycolsep\vline\kern-\arraycolsep\hfilneg}
\definecolor{weining}{HTML}{246FFF}
\definecolor{maryam}{HTML}{12b637}
\definecolor{todo}{HTML}{E74C3C}

% Macro
\newcommand{\hubert}{HuBERT}

\newcommand{\wn}[1]{{\textcolor{weining}{[weining: #1]}}}
% \newcommand{\wn}[1]{}
\newcommand{\maryam}[1]{{\textcolor{maryam}{[maryam: #1]}}}
% \newcommand{\maryam}[1]{}
\newcommand{\todo}[1]{{\textcolor{todo}{#1}}}

% Title.
% ------
% \title{Cocktail HuBERT: Generalizing Self-Supervised Pre-training to\\Mixture Speech with Masked Pseudo Source Separation}
\title{Cocktail HuBERT: Generalized Self-Supervised Pre-training \\for Mixture and Single-Source Speech}
%
% Single address.
% ---------------
\name{Maryam Fazel-Zarandi and Wei-Ning Hsu}
\address{
    Meta FAIR\\
    \texttt{\{maryamfazel,wnhsu\}@meta.com}
}

%
% For example:
% ------------
%\address{School\\
%	Department\\
%	Address}
%
% Two addresses (uncomment and modify for two-address case).
% ----------------------------------------------------------
%\twoauthors
%  {A. Author-one, B. Author-two\sthanks{Thanks to XYZ agency for funding.}}
%	{School A-B\\
%	Department A-B\\
%	Address A-B}
%  {C. Author-three, D. Author-four\sthanks{The fourth author performed the work
%	while at ...}}
%	{School C-D\\
%	Department C-D\\
%	Address C-D}
%
\begin{document}
\ninept

\noindent We thank the reviewers for the thoughtful and constructive feedback. We will incorporate our itemized responses below in the final version of our paper.

\vspace{1em}
\noindent \textbf{R1.1}: My main concern is about author’s claim in Section 6.3. The authors state “C-HuBERT shows strong performance on speech enhancement and source separation.” I disagree with this statement as the improvements are very marginal. With additional project heads, C-HuBERT shows no advantage compared to WavLM on speech enhancement and source separation tasks.

\noindent \textbf{A1.1}: C-HuBERT BASE archives a PESQ score of 2.63 on speech enhancement and 11.08 Si-SDR on source separation. In comparison, WavLM BASE has 2.58 and 10.37 respectively. The LARGE model numbers of C-HuBERT and WavLM cannot be directly compared because the WavLM model was trained on more data as noted in the caption. The additional projection heads are only added at the output of the final Transformer layer to predict pseudo labels for each stream for pre-training. They are not used during fine-tuning, and therefore C-HuBERT does not introduce additional parameters compared to WavLM.

\vspace{1em}
\noindent \textbf{R1.2}: Minor issues. 

\noindent \textbf{A1.2}: We thank the reviewer and will update that in the camera ready version. Regarding the values of K, we mentioned in the first paragraph of section 5 that K=5/3 for Base/Large if not otherwise specified.

\vspace{1em}
\noindent \textbf{R2.1}: However, to be more convinced, the authors may need to benchmark it with heavily data augmentation approaches in ASR and speaker diarization to prove that building and additional layer of robust representation is beneficial for any ASR system.

\noindent \textbf{A2.1}: We thank the reviewer for the suggestion. In our current presentation, for single speaker and multi-speaker ASR, we follow the wav2vec / HuBERT fine-tuning protocols where SpecAug-like techniques are used for augmentation. We also compare with WavLM, which can be considered as a heavy noise augmentation method for pre-training, on both SD and ASR tasks.


\vspace{1em}
\noindent \textbf{R3.1}: If the validating work is performed on the real mixture-ASR and natural speaker darization tasks, that would be even greater.

\noindent \textbf{A3.1}: We thank the reviewer for the suggestion and we plan to work on evaluating the models on real mixture data in the future.


\vspace{1em}
\noindent \textbf{R4.1}: Were target sequences for all the audio sources obtained from a single and unified K-means? Or was it the case that each audio source was trained for k-means separately?

\noindent \textbf{A4.1}: The target sequences for all sources are obtained from a single K-means (the public L9 km500:  \url{https://dl.fbaipublicfiles.com/hubert/hubert_base_ls960_L9_km500.bin}).


\bibliographystyle{IEEEbib}
% \bibliography{refs}

\end{document}
