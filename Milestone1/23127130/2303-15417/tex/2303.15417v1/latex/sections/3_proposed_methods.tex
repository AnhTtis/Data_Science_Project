\section{BlurHand dataset}
\label{sec:blurhand_dataset}
%
% \jaeha{5 frame average, relation to the 5fps, camera view sampling, pcf annotation}
%
% Even though hands commonly undergo blur artifacts from their dynamic motion, conventional hand benchmark dataset~\cite{zimmermann2019freihand, moon2020interhand2} lacks consideration on motion blur degradation.
% %
% To tackle the limitation, we propose a novel blurry hand dataset, namely, BlurHand. 
% % \jaeha{InterHand-B?}
%
% Our BlurHand dataset consists of 121,839 training and 34,057 test blurry hand images, where the original InterHand2.6M~\cite{moon2020interhand2} dataset consists of sharp hand frames captured from 30fps.
%



%To construct a blurry hand with corresponding 3D annotations, we employ InterHand2.6M 30fps~\cite{moon2020interhand2}, which contains hand images from 36 recordings taken from a multi-camera.
% 
\figref{manufacture_diagram} shows the overall pipeline for constructing our BlurHand.
Our BlurHand dataset is synthesized using 30 frames per second (fps) version of InterHand2.6M~\cite{moon2020interhand2}, which contains large-scale hand videos with diverse poses.
% 
%We synthesize a single blurry hand by averaging five sequential frames in InterHand2.6M 30fps following conventional deblurring dataset manufacture~\cite{Nah_2017_CVPR, zhou2019davanet, HA2019hide}.
We first apply a video interpolation method~\cite{Niklaus_ICCV_2017} to increase 30 fps videos to 240 fps ones.
% Since averaging sharp images from the low fps video causes unnatural blur in case of large motion~\cite{Nah_2019_CVPR_Workshops_REDS}, we first apply a video interpolation method~\cite{Niklaus_ICCV_2017} to increase 30 fps videos to 240 fps ones.
Then, a single blurry hand image is synthesized by averaging 33 sequential frames, which are interpolated from 5 sharp sequential frames, following the conventional deblurring dataset manufacture~\cite{Nah_2017_CVPR, zhou2019davanet, HA2019hide}.
% Such video interpolation is necessary when synthesizing blurs as averaging frames from a low frame rate induces unnatural artifacts such as spikes and steps~\cite{Nah_2019_CVPR_Workshops_REDS}.
We note that video interpolation is necessary when synthesizing blurs, as averaging frames from a low frame rate induces unnatural artifacts such as spikes and steps~\cite{Nah_2019_CVPR_Workshops_REDS}.
% 
% Each synthesized blurry image is assigned 3D GTs of \emph{1st}, \emph{3rd}, and \emph{5th} sharp frames from InterHand2.6M 30fps as initial, middle, and final, respectively.
For each synthesized blurry image, 3D GTs of \emph{1st}, \emph{3rd}, and \emph{5th} sharp frames from InterHand2.6M 30fps are assigned as 3D GTs of initial, middle, and final, respectively.
% 
% We note that constructing temporal annotations is essential for training the proposed Unfolder module.
% 
% We further report the generation pipeline for the presented BlurHand in \figref{manufacture_diagram}.
% 
% In the end, the presented BlurHand consists of 121,839 training and 34,057 test blurry hand images.
In the end, the presented BlurHand consists of 121,839 training and 34,057 test samples containing single and interacting blurry hand images.
% 
% Train : RH 36,459 LH 38,180, IH 47,200
% Test : RH 16,914 LH: 17,143
% 
During the synthesis of blurry frames, we skip the frames if two neighboring frames are not available, and further adopt camera view sampling to mitigate the redundancy of samples.
% sequences with lengths less than the five frames in the InterHand2.6M 30fps and further adopt camera view sampling to mitigate the redundancy of samples.
% During synthesizing blurry frames, we skip the sequences with lengths less than the five frames in the InterHand2.6M 30fps and further adopt camera view sampling to mitigate the redundancy of samples.
% 
% We also report a more detailed fabrication procedure and statistics of the BlurHand in the supplementary materials.
We report sample statistics of the BlurHand in the supplementary materials.
% 

\input{latex/figures/manufacture/manufacture}
\input{latex/sections/figures/model}

% following the conventional deblurring dataset manufacture~\cite{Nah_2019_CVPR_Workshops_REDS, Nah_2017_CVPR}, we increase the InterHand2.6M 30fps dataset to 240fps using video interpolation~\cite{Niklaus_ICCV_2017}, then average the 33 frames to synthesize a single blurry hand frame.
% then assign 1st, 3rd, 5th 3D annotations as past, current, future, respectively.
% 
% We average the interpolated multiple frames to generate natural blur, following the conventional deblurring dataset manufacture~\cite{Nah_2019_CVPR_Workshops_REDS, Nah_2017_CVPR}.
% %
% In detail, we increase the InterHand2.6M 30fps dataset to 240fps using video interpolation~\cite{Niklaus_ICCV_2017}, then average the 33 frames to synthesize a single blurry frame.
% 
%
% \figref{example_of_dataset} shows the examples of the proposed BlurHand dataset.
%
% We note that our synthetic blur dataset contains realistic but challenging blurry hands.
