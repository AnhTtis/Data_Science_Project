\begin{abstract}
% Hands, one of the most dynamic parts of our body, suffer from blur due to their active movements.
% However, previous 3D hand mesh recovery methods have mainly focused on sharp hand images rather than considering blur due to the absence of datasets providing blurry hand images.
% We first present a novel dataset BlurHand, which contains blurry hand images with 3D groundtruths (GTs).
% The BlurHand is constructed by synthesizing motion blur from sequential sharp hand images, imitating realistic and natural motion blurs.
% In addition to the new dataset, we propose BlurHandNet, a baseline network for accurate 3D hand mesh recovery from a blurry hand image.
% Our BlurHandNet unfolds a blurry input image to a 3D hand mesh sequence to utilize temporal information in the blurry input image, while previous works output a static single hand mesh.
% We demonstrate the usefulness of the BlurHand for the 3D hand mesh recovery from blurry images in our experiments.
% The proposed BlurHandNet produces much more robust results on blurry images while generalizing well to in-the-wild images.
% We will publicly release our dataset and codes.
Hands, one of the most dynamic parts of our body, suffer from blur due to their active movements.
However, previous 3D hand mesh recovery methods have mainly focused on sharp hand images rather than considering blur due to the absence of datasets providing blurry hand images.
We first present a novel dataset BlurHand, which contains blurry hand images with 3D groundtruths.
The BlurHand is constructed by synthesizing motion blur from sequential sharp hand images, imitating realistic and natural motion blurs.
In addition to the new dataset, we propose BlurHandNet, a baseline network for accurate 3D hand mesh recovery from a blurry hand image.
Our BlurHandNet unfolds a blurry input image to a 3D hand mesh sequence to utilize temporal information in the blurry input image, while previous works output a static single hand mesh.
We demonstrate the usefulness of BlurHand for the 3D hand mesh recovery from blurry images in our experiments.
The proposed BlurHandNet produces much more robust results on blurry images while generalizing well to in-the-wild images.
% We will publicly release our dataset and codes.
The training codes and BlurHand dataset are available at \href{https://github.com/JaehaKim97/BlurHand_RELEASE}{https://github.com/JaehaKim97/BlurHand\_RELEASE}.
% The code is publicly available\footnote{\url{https://github.com/JaehaKim97/BlurHand_RELEASE}}. % This could be one way to open the code

\end{abstract}

%The proposed BlurHandNet has two distinctive points compared to the previous 3D hand mesh recovery approaches.
%First, it outputs not a single static 3D hand mesh but a temporal sequence, \ie, unfolding, providing profitable information to understand the motion.
%Second, we propose a kinematic temporal Transformer (KTFormer) which effectively employs the kinematic and temporal information from unfolded sequences.
% Second, we propose a kinematic temporal Transformer (KTFormer) which effectively employs the kinematic and temporal information from unfolding.
%Since hand information in each time step is highly correlated, exploiting temporal information can be of benefit to predicting accurate hand meshes.
% Since hand features in each time step are highly correlated, exploiting temporal information can be of benefit to predicting accurate hand meshes.
% Hand images often contain motion blur as hand is one of the most dynamic parts of human.
% However, most researches in 3D hand mesh recovery have focused on clean hand images without considering the blur.
% In this work, we propose BlurHandNet which robustly reconstructs 3D hand mesh for blurry hand images.
% In order to train and validate our BlurHandNet, we build a new dataset by synthetically generating blur hand images with clean hand images from InterHand2.6M dataset.

% Hands are often suffer from motion blur due to camera motion and moving hands.
% However, most researches in 3D hand mesh recovery have concentrated on clean hand images without considering the blur.
% While the simple blur augmentations have been adopted to cope with the blurriness in images, it is still difficult to manage real-like blur.
% To solve this issue, in this work, we propose a new blurry hand dataset, BlurHand, by synthetically generating the blur in InterHand 2.6M dataset.
% Our BlurHand dataset contains temporal~(past, current, and future) hands information, which makes network difficult to focus on target current hand information.
% Although removing the past and future hands information could be a nice solution to cope with above problem, we find that utilizing temporal hands can further enhance the current hand mesh recovery.


% On this basis, we propose voxel Transformer~(VoT) to deliver temporal information to enhance the current hand feature.
% Our VoT takes 3D voxels from temporal sequences as inputs and conveys information by considering the proper attentive correlation.
% By generating realistic blur hands images, imitating the real world, and applying appropriate approaches, our BlurHandNet suggests a new direction to cope with blurry hand mesh recovery.

% First, the proposed BlurHandNet outputs not a single static 3D hand mesh but sequence of 3D hand meshes.
% This process, we call temporal unfolding, provides profitable information to understand 3D motion of hand.
% First, the proposed BlurHandNet outputs not only 3D mesh from the mid-point of the blur but also both ends, \ie, temporal unfolding, providing profitable information to understand motion.
% Second, we propose a spatio-temporal joint transformer~(STJ) which employs additional temporal information from unfolding.

% Since blurry hand images lack enough information at a certain timestep, exploiting temporal information benefits in predicting accurate hand meshes.
% Since blurry hand images lack information at a certain timestep, properly exploiting the temporal information is beneficial.

% Since blurry hand images lack enough information at a certain timestep, exploiting temporal information can be of benefit to predicting accurate hand meshes.
% Extensive experimental results demonstrate that the proposed BlurHandNet significantly outperforms the previous methods on the BlurHand dataset, and generalizes well to in-the-wild images.

%% original
% Hands often suffer from blur due to camera motion and moving hands.
% However, previous 3D hand mesh recovery methods have mainly focused on clean hand images without blur due to the absence of datasets that provide blurry images with 3D groundtruths~(GTs).
% We present BlurHand, the first dataset that contains blurry hand images with 3D GTs, and its baseline network, BlurHandNet.%, for estimating 3D hand mesh from a single blurry hand image.
 %, and its baseline network, BlurHandNet.%, for estimating 3D hand mesh from a single blurry hand image.
% The proposed BlurHand is generated by synthetically imitating realistic motion blurs from sequential clean hand images.
% Our BlurHandNet unfolds a single blurry hand image into three temporal hand joint features, each corresponding to the past, current, and future hands.
% Since blurry hand lacks rich information in the certain timestep, hand divided into different temporal space could compensate for the insufficient information, finally helpful for predicting sequential hand meshes.
% By extracting temporal hand joint features from a single blurry image, a single blurry hand could be regarded as sequential hands.
% On this basis, to fully take advantages of temporal information, we propose (1) Unfolder, which replaces a blurry hand with sequential hands in temporal space, and (2) Joint Transformer~(JFormer), a Transformer-based module that can exploit the spatio-temporal joint information to support regressing the accurate 3D hand meshes.
% On this basis, to fully take advantages of temporal information, we propose Transformer-based module, named temporal joint Transformer~(TJFormer), which can manage the spatio-temporal dependency in a sequential hand joints.
% Our BlurHandNet utilizes temporal information from blurry image to enhance the representation of the hand.
% To this end, we first unfold blurry hand images into three timesteps~(past, current, and future), and generates three hand joint features for the corresponding timesteps.
% Then, each joint feature is refined by Transformer-based module, called temporal joint Transformer~(TJFormer).
% Thus, the final output of our BlurHandNet is three temporal meshes regressed by the corresponding joint features.
% By proposing BlurHand, containing realistic blurry hands, and utilizing temporal information from a single blurry hand image, our BlurHandNet could capture accurarte 3D mesh from blurry hands.
% By imitating realistic blur hands images and utilizing temporal information from the blurry hand, our BlurHandNet could capture accurate 3D mesh from blurry hands.
% suggests a new direction to cope with blurry hand mesh recovery.
% Our dataset and code will be released.



% In this regard, we present a new blurry hand dataset, BlurHand, by synthetically imitating the real-like motion blur from temporal clean hand images.
% Our BlurHand dataset contains temporal~(past, current, and future) hands information, which makes network difficult to focus on hand information in current timestep.
% Although deblurring the blurry image then estimate the mesh could be a nice solution to cope with blurry hand image, temporal information itself can be utilized to further enhance the current hand mesh recovery.
% On this basis, we propose BlurHandNet which robustly reconstruct 3D hand mesh for blurry hand images.