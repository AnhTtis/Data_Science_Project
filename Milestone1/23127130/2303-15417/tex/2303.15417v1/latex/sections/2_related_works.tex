\section{Related works}

\noindent\textbf{3D hand mesh estimation.}
% \paragraph{3D hand pose and shape estimation.}
% After hand benchmark datasets with 3D annotations have been introduced, such as Friehand~\cite{zimmermann2019freihand} and InterHand 2.6M~\cite{moon2020interhand2}, 
% Since the introduction of RGB-based hand benchmark datasets with accurate 3D annotations, such as Friehand~\cite{zimmermann2019freihand} and InterHand 2.6M~\cite{moon2020interhand2},
% various 3D hand mesh estimation methods~\cite{moon2020i2l, choi2020pose2mesh, kulon2020weakly, lin2021end, lin2021mesh, park2022handoccnet,moon2022accurate} from monocular RGB image have been proposed.
Since after the introduction of RGB-based hand benchmark datasets with accurate 3D annotations, \eg, Friehand~\cite{zimmermann2019freihand} and InterHand 2.6M~\cite{moon2020interhand2},
various monocular RGB-based 3D hand mesh estimation methods~\cite{moon2020i2l, choi2020pose2mesh, kulon2020weakly, lin2021end, lin2021mesh, park2022handoccnet,moon2022accurate} have been proposed.
Pose2Mesh~\cite{choi2020pose2mesh} proposed a framework that reconstructs 3D mesh from the skeleton pose based on graph convolutional networks. Kulon~\etal~\cite{kulon2020weakly} utilized encoder-decoder architecture with a spiral operator to regress the 3D hand mesh.
I2L-MeshNet~\cite{moon2020i2l} utilized a 1D heatmap for each mesh vertex to model the uncertainty and preserve the spatial structure.
I2UV-HandNet~\cite{chen2021i2uv} proposed UV-based 3D hand shape representation and 3D hand super-resolution module to obtain high-fidelity hand meshes.
Pose2Pose~\cite{moon2022accurate} introduced joint features and proposed a 3D positional pose-guided 3D rotational pose prediction framework.
More recently, LISA~\cite{corona2022lisa} captured precise hand shape and appearance while providing dense surface correspondence, allowing for easy animation of the outputs.
SeqHAND~\cite{yang2020seqhand} incorporated synthetic datasets to train a recurrent framework with temporal movement information and consistency constraints, improving general pose estimations.
Meng~\etal~\cite{meng20223d} decomposed the 3D hand pose estimation task and used the HDR framework to handle occlusion.



% Stepping forward, after the success of the attention-based mechanism, Transformer~\cite{vaswani2017attention} has been adopted to recover 3D hand meshes.
After the success of the attention-based mechanism, Transformer~\cite{vaswani2017attention} has been adopted to recover more accurate 3D hand meshes.
% Specifically, METRO~\cite{lin2021end} and MeshGraphormer~\cite{lin2021mesh} presented Transformer-based 
% architecture which models vertex-vertex and vertex-joint interactions.
METRO~\cite{lin2021end} and MeshGraphormer~\cite{lin2021mesh} proposed Transformer-based architecture, which models vertex-vertex and vertex-joint interactions.
Liu~\etal~\cite{liu2022spatial} utilizes spatial-temporal parallel Transformer to model inter-correlation between arm and hand.
% Liu~\etal~\cite{liu2022spatial} utilizes inter-correlation between arm and hand by obtaining their correlation with the proposed spatio-temporal parallel Transformer.
% HandOccNet~\cite{park2022handoccnet} proposed a feature injection mechanism by modifying the architecture of the Transformer to robustly reconstruct 3D hand mesh when occlusions are severe.
HandOccNet~\cite{park2022handoccnet} proposed a Transformer-based feature injection mechanism to robustly reconstruct 3D hand mesh when occlusions are severe.
% Rather than utilizing a Transformer to obtain the correlation between hand and other objects, including other body parts, Huang~\etal~\cite{huang2020hand}, Li~\etal~\cite{li2022interacting}, and Hampali~\etal~\cite{hampali2022keypoint} focused on finding the correlation between two hands.
Although the above methods showed promising results for the sharp hand images, none of them carefully considered the hand with blur scenario.
% Since the lack of a proper dataset is the main reason for less consideration of blurry hands, we present BlurHand.
As the lack of an appropriate dataset is the main reason for the less consideration, we present BlurHand.
%We also introduce temporal unfolding, which is especially effective in hand images with blur.
% We also introduce a baseline network, BlurHandNet, which consists of a temporal unfolding module and kinematic temporal Transformer.
Furthermore, we introduce a baseline network, BlurHandNet, which consists of a temporal unfolding module and kinematic temporal Transformer.


% Since the lack of proper dataset is the main reason for less consideration of blurry hand, we present BlurHand.


\noindent\textbf{Restoring the motion from a single blurry image.}
% \paragraph{Single blurry image to motion.}
%
Rather than reconstructing only a single sharp image in the middle of the motion, recent deblurring methods~\cite{Jin_2018_CVPR, Purohit_2019_CVPR, Zhang_2020_ACMMM, PAN_2019_CVPR, Argaw_2021_CVPRW} have witnessed predicting the sequence of sharp frames from a single blurry image, which constructs the blurry input image.
Such a sequence of sharp frames can provide useful temporal information.
%
Jin~\etal~\cite{Jin_2018_CVPR} proposed temporal order invariant loss to overcome the temporal order ambiguity problem.
%
Purohit~\etal~\cite{Purohit_2019_CVPR} proposed an RNN-based solution without constraining the number of frames in sequence.
%
% Argaw~\etal~\cite{Argaw_2021_CVPRW} proposed an encoder-decoder-based spatial Transformer network with carefully designed loss function and regularizing terms.
Argaw~\etal~\cite{Argaw_2021_CVPRW} proposed an encoder-decoder-based spatial Transformer network with regularizing terms.
%
% Unlike previous methods focusing on predicting the video from a single blurry image, we aim to exploit the meaningful temporal information for hand mesh estimation.
% Unlike previous methods that proposed to restore deblurred images, our BlurHandNet aims to recover 3D hand mesh sequences.
Unlike previous methods that proposed to restore a single sharp image, our BlurHandNet aims to recover 3D hand mesh sequences from a single blurry image.
%focusing on a single 2D blurry image, we first propose the methods predicting sequential 3D meshes from the single blurry image.
%
% Our motivation lies in using the temporal information in blurry hand images to improve the hand joint accuracy on the center frame, rather than using simply deblurred images.
%We further demonstrate that incorporating temporal information in blurry hand images benefits estimating 3D hand mesh, rather than simply using deblurred images.

%improving hand joint accuracy, rather than using simply deblurred images.
% %

% \noindent\textbf{Temporal Transformer.}
% Given temporal information, \emph{how} to extract relevant information from it can play a key role in addressing the temporal information appropriately.
% On this basis, recent researches~\cite{vaswani2017attention,dosovitskiy2020image,wang2018non} have focused on utilizing temporal information based on attention.
% Among the attention-based methods, Transformer~\cite{vaswani2017attention} has applied to various temporal tasks, especially in videos~\cite{arnab2021vivit,yan2021learning,zhang2021temporal}.
% Specifically, ViViT~\cite{arnab2021vivit} proposed pure Transformer architectures for video classification.
% They experimentally justified the Transformer's effectiveness in handling both spatial and temporal information.
% On this basis, temporal Transformers also have been widely adopted to capture the kinematic dependencies across the human pose from sequential frames~\cite{Zheng_2021_ICCV,li2021lifting}.
% PoseFormer~\cite{Zheng_2021_ICCV} first proposed the Transformer-based model for human pose estimation to manage the temporal relationship between human body joints.
% STE~\cite{li2021lifting} suggested strided Transformer to produce 3D pose by handling the temporal 2D pose sequence.
% Since our BlurHandNet incorporates temporal information from a single blurry hand image, we also adopted a temporal Transformer-based module, KTFormer, to manage the temporal information between the hand joints.
