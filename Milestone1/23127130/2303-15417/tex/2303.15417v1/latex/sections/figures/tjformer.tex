\begin{figure}[t]
\begin{center}
\includegraphics[width=0.98\linewidth]{latex/figures/model/tjformer7.pdf}
\end{center}
\vspace{-8mm}
% \caption{\textbf{Overall architecture of kinematic temporal Transformer~(KTFormer).}
\caption{\textbf{Overall architecture of KTFormer.}
% KTFormer refines temporal joint features $\mathbf{F}_{\text{E1}}$, $\mathbf{F}_{\text{E2}}$, and $\mathbf{F}_{\text{M}}$.
KTFormer refines temporal joint features $\mathbf{F}_{\text{J}_{\text{E1}}}$, $\mathbf{F}_{\text{J}_{\text{E2}}}$, and $\mathbf{F}_{\text{J}_{\text{M}}}$.
First, kinematic and temporal positional embeddings are introduced.
Then, the following self-attention mechanism refines joint features by leveraging attentive correlation between them, producing $\mathbf{F}^{\prime}_{\text{J}_{\text{E1}}}$, $\mathbf{F}^{\prime}_{\text{J}_{\text{E2}}}$, and $\mathbf{F}^{\prime}_{\text{J}_{\text{M}}}$.}
% The final outputs~$\mathbf{F}^{\prime}_{\text{J}_{\text{E1}}}$, $\mathbf{F}^{\prime}_{\text{J}_{\text{E2}}}$, and $\mathbf{F}^{\prime}_{\text{J}_{\text{M}}}$ are obtained by dividing the MLP output across the joint dimensions.}
\vspace{-3mm}
\label{fig:tjformer}
\end{figure}