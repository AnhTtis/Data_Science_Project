@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}
@article{ghadiyaram2017capture,
  title={In-capture mobile video distortions: A study of subjective behavior and objective algorithms},
  author={Ghadiyaram, Deepti and Pan, Janice and Bovik, Alan C and Moorthy, Anush Krishna and Panda, Prasanjit and Yang, Kai-Chieh},
  journal={IEEE Trans. Circuits Syst. Video Technol.},
  volume={28},
  number={9},
  pages={2061--2077},
  year={2017},
}
@inproceedings{berns2019v3c1,
  title={V3C1 dataset: an evaluation of content characteristics},
  author={Berns, Fabian and Rossetto, Luca and Schoeffmann, Klaus and Beecks, Christian and Awad, George},
  booktitle={Proc. ACM Int. Conf. Multimed. Retr.},
  pages={334--338},
  year={2019}
}
@misc{hosu2020konstanz,
  title={The Konstanz natural video database},
  author={Hosu, V and Hahn, F and Jenadeleh, M and Lin, H and Men, H and Szir{\'a}nyi, T and Li, S and Saupe, D},
  year={2020}
}
@article{sinno2018large,
  title={Large-scale study of perceptual video quality},
  author={Sinno, Zeina and Bovik, Alan Conrad},
  journal={IEEE Trans. Image Process.},
  volume={28},
  number={2},
  pages={612--627},
  year={2018},
}
@article{thomee2016yfcc100m,
  title={YFCC100M: The new data in multimedia research},
  author={Thomee, Bart and Shamma, David A and Friedland, Gerald and Elizalde, Benjamin and Ni, Karl and Poland, Douglas and Borth, Damian and Li, Li-Jia},
  journal={Commun. ACM},
  volume={59},
  number={2},
  pages={64--73},
  year={2016},
}
@article{getreuer2012automatic,
  title={Automatic color enhancement (ACE) and its fast implementation},
  author={Getreuer, Pascal},
  journal={Image Process. On Line},
  volume={2},
  pages={266--277},
  year={2012}
}@inproceedings{zhang2022deep,
  title={Deep color consistent network for low-light image enhancement},
  author={Zhang, Zhao and Zheng, Huan and Hong, Richang and Xu, Mingliang and Yan, Shuicheng and Wang, Meng},
  booktitle={Proc. IEEE Comput. Soc. Conf. Comput. Vision Pattern Recognit.},
  pages={1899--1908},
  year={2022}
}
@article{gupta2016minimum,
  title={Minimum mean brightness error contrast enhancement of color images using adaptive gamma correction with color preserving framework},
  author={Gupta, Bhupendra and Tiwari, Mayank},
  journal={Optik},
  volume={127},
  number={4},
  pages={1671--1676},
  year={2016},
}
@article{wang2005brightness,
  title={Brightness preserving histogram equalization with maximum entropy: a variational perspective},
  author={Wang, Chao and Ye, Zhongfu},
  journal={IEEE Trans. Consum. Electron.},
  volume={51},
  number={4},
  pages={1326--1334},
  year={2005},
  publisher={IEEE}
}
@inproceedings{lv2018mbllen,
  title={MBLLEN: Low-Light Image/Video Enhancement Using CNNs.},
  author={Lv, Feifan and Lu, Feng and Wu, Jianhua and Lim, Chongsoon},
  booktitle={BMVC},
  volume={220},
  number={1},
  pages={4},
  year={2018}
}
@inproceedings{zheng2022semantic,
  title={Semantic-guided zero-shot learning for low-light image/video enhancement},
  author={Zheng, Shen and Gupta, Gaurav},
  booktitle={Proc. IEEE/CVF Winter Conf. Appl. Comput. Vis.},
  pages={581--590},
  year={2022}
}
@article{wang2018deep,
  title={Deep online video stabilization with multi-grid warping transformation learning},
  author={Wang, Miao and Yang, Guo-Ye and Lin, Jin-Kun and Zhang, Song-Hai and Shamir, Ariel and Lu, Shao-Ping and Hu, Shi-Min},
  journal={IEEE Trans. Image Process.},
  volume={28},
  number={5},
  pages={2283--2292},
  year={2018},
}
@article{liu2013bundled,
  title={Bundled camera paths for video stabilization},
  author={Liu, Shuaicheng and Yuan, Lu and Tan, Ping and Sun, Jian},
  journal={ACM Trans. Graph. },
  volume={32},
  number={4},
  pages={1--10},
  year={2013},
}
@inproceedings{james2023globalflownet,
  title={GlobalFlowNet: Video Stabilization using Deep Distilled Global Motion Estimates},
  author={James, Jerin Geo and Jain, Devansh and Rajwade, Ajit},
  booktitle={Proc. IEEE/CVF Winter Conf. Appl. Comput. Vis.},
  pages={5078--5087},
  year={2023}
}
@article{choi2020deep,
  title={Deep iterative frame interpolation for full-frame video stabilization},
  author={Choi, Jinsoo and Kweon, In So},
  journal={ACM Trans. Graph.},
  volume={39},
  number={1},
  pages={1--9},
  year={2020},
}
@article{zhao2020pwstablenet,
  title={Pwstablenet: Learning pixel-wise warping maps for video stabilization},
  author={Zhao, Minda and Ling, Qiang},
  journal={IEEE Trans. Image Process.},
  volume={29},
  pages={3582--3595},
  year={2020},
}
@inproceedings{yu2020learning,
  title={Learning video stabilization using optical flow},
  author={Yu, Jiyang and Ramamoorthi, Ravi},
  booktitle={Proc. IEEE Comput. Soc. Conf. Comput. Vision Pattern Recognit.},
  pages={8159--8167},
  year={2020}
}
@inproceedings{sun2022deep,
  title={A deep learning based no-reference quality assessment model for ugc videos},
  author={Sun, Wei and Min, Xiongkuo and Lu, Wei and Zhai, Guangtao},
  booktitle={Proc. ACM Int. Conf. Multimed.},
  pages={856--865},
  year={2022}
}
@article{saad2014blind,
  title={Blind prediction of natural video quality},
  author={Saad, Michele A and Bovik, Alan C and Charrier, Christophe},
  journal={IEEE Trans. Image Process.},
  volume={23},
  number={3},
  pages={1352--1365},
  year={2014},
}
@article{tu2021ugc,
  title={UGC-VQA: Benchmarking blind video quality assessment for user generated content},
  author={Tu, Zhengzhong and Wang, Yilin and Birkbeck, Neil and Adsumilli, Balu and Bovik, Alan C},
  journal={IEEE Trans. Image Process.},
  volume={30},
  pages={4449--4464},
  year={2021},
}
@article{tu2021rapique,
  title={RAPIQUE: Rapid and accurate video quality prediction of user generated content},
  author={Tu, Zhengzhong and Yu, Xiangxu and Wang, Yilin and Birkbeck, Neil and Adsumilli, Balu and Bovik, Alan C},
  journal={IEEE Open J. Signal Process.},
  volume={2},
  pages={425--440},
  year={2021},
}
@inproceedings{wu2022fast,
  title={Fast-vqa: Efficient end-to-end video quality assessment with fragment sampling},
  author={Wu, Haoning and Chen, Chaofeng and Hou, Jingwen and Liao, Liang and Wang, Annan and Sun, Wenxiu and Yan, Qiong and Lin, Weisi},
  booktitle={Proc. Eur. Conf. Comput. Vis.},
  pages={538--554},
  year={2022},
}
@article{korhonen2019two,
  title={Two-level approach for no-reference consumer video quality assessment},
  author={Korhonen, Jari},
  journal={IEEE Trans. Image Process.},
  volume={28},
  number={12},
  pages={5923--5938},
  year={2019},
}
@article{li2022blindly,
  title={Blindly assess quality of in-the-wild videos via quality-aware pre-training and motion perception},
  author={Li, Bowen and Zhang, Weixia and Tian, Meng and Zhai, Guangtao and Wang, Xianpei},
  journal={IEEE Trans. Circuits Syst. Video Technol.},
  volume={32},
  number={9},
  pages={5944--5958},
  year={2022},
}
@inproceedings{wang2019youtube,
  title={YouTube UGC dataset for video compression research},
  author={Wang, Yilin and Inguva, Sasi and Adsumilli, Balu},
  booktitle={Proc. IEEE Int. Workshop Multimed. Signal Process.},
  pages={1--5},
  year={2019},
}
@article{madhusudana2021subjective,
  title={Subjective and objective quality assessment of high frame rate videos},
  author={Madhusudana, Pavan C and Yu, Xiangxu and Birkbeck, Neil and Wang, Yilin and Adsumilli, Balu and Bovik, Alan C},
  journal={IEEE Access},
  volume={9},
  pages={108069--108082},
  year={2021},
}
@article{mackin2018study,
  title={A study of high frame rate video formats},
  author={Mackin, Alex and Zhang, Fan and Bull, David R},
  journal={IEEE Trans. Multimedia},
  volume={21},
  number={6},
  pages={1499--1512},
  year={2018},
  publisher={IEEE}
}
@inproceedings{zhong2020efficient,
  title={Efficient spatio-temporal recurrent neural network for video deblurring},
  author={Zhong, Zhihang and Gao, Ye and Zheng, Yinqiang and Zheng, Bo},
  booktitle={Proc. Eur. Conf. Comput. Vis.},
  pages={191--207},
  year={2020},
}
@inproceedings{kupyn2019deblurgan,
  title={Deblurgan-v2: Deblurring (orders-of-magnitude) faster and better},
  author={Kupyn, Orest and Martyniuk, Tetiana and Wu, Junru and Wang, Zhangyang},
  booktitle={Proc. IEEE Int. Conf. Comput. Vision},
  pages={8878--8887},
  year={2019}
}
@article{lin2022flow,
  title={Flow-guided sparse transformer for video deblurring},
  author={Lin, Jing and Cai, Yuanhao and Hu, Xiaowan and Wang, Haoqian and Yan, Youliang and Zou, Xueyi and Ding, Henghui and Zhang, Yulun and Timofte, Radu and Van Gool, Luc},
  journal={arXiv preprint arXiv:2201.01893},
  year={2022}
}
@inproceedings{chan2022basicvsr++,
  title={BasicVSR++: Improving video super-resolution with enhanced propagation and alignment},
  author={Chan, Kelvin CK and Zhou, Shangchen and Xu, Xiangyu and Loy, Chen Change},
  booktitle={Proc. IEEE Comput. Soc. Conf. Comput. Vision Pattern Recognit.},
  pages={5972--5981},
  year={2022}
}
@article{seshadrinathan2010study,
  title={Study of subjective and objective quality assessment of video},
  author={Seshadrinathan, Kalpana and Soundararajan, Rajiv and Bovik, Alan Conrad and Cormack, Lawrence K},
  journal={IEEE Trans. Image Process.},
  volume={19},
  number={6},
  pages={1427--1441},
  year={2010},
}
@article{vu2014vis,
  title={Vi {S}3: an algorithm for video quality assessment via analysis of spatial and spatiotemporal slices},
  author={Vu, Phong V and Chandler, Damon M},
  journal={J. Electron. Imaging},
  volume={23},
  number={1},
  pages={013016--013016},
  year={2014},
}
@article{lin2015mcl,
  title={ {MCL-V}: A streaming video quality assessment database},
  author={Lin, Joe Yuchieh and Song, Rui and Wu, Chi-Hao and Liu, TsungJung and Wang, Haiqiang and Kuo, C-C Jay},
  journal={J. Vis. Commun. Image Represent.},
  volume={30},
  pages={1--9},
  year={2015},
}
@inproceedings{wang2016mcl,
  title={ {MCL-JCV}: a  {JND}-based  {H. 264/AVC} video quality assessment dataset},
  author={Wang, Haiqiang and Gan, Weihao and Hu, Sudeng and Lin, Joe Yuchieh and Jin, Lina and Song, Longguang and Wang, Ping and Katsavounidis, Ioannis and Aaron, Anne and Kuo, C-C Jay},
  booktitle={Proc. IEEE Int. Conf. Image Process.},
  pages={1509--1513},
  year={2016},
}
@article{nuutinen2016cvd2014,
  title={ {CVD2014â€”A} database for evaluating no-reference video quality assessment algorithms},
  author={Nuutinen, Mikko and Virtanen, Toni and Vaahteranoksa, Mikko and Vuori, Tero and Oittinen, Pirkko and H{\"a}kkinen, Jukka},
  journal={IEEE Trans. Image Process.},
  volume={25},
  number={7},
  pages={3073--3086},
  year={2016},
}
@article{li2016toward,
  title={Toward a practical perceptual video quality metric},
  author={Li, Zhi and Aaron, Anne and Katsavounidis, Ioannis and Moorthy, Anush and Manohara, Megha},
  journal={The Netflix Tech Blog},
  volume={6},
  number={2},
  pages={2},
  year={2016}
}
@article{soundararajan2012video,
  title={Video quality assessment by reduced reference spatio-temporal entropic differencing},
  author={Soundararajan, Rajiv and Bovik, Alan C},
  journal={IEEE Trans. Circuits Syst. Video Technol.},
  volume={23},
  number={4},
  pages={684--694},
  year={2012},
}
@article{bampis2018spatiotemporal,
  title={Spatiotemporal feature integration and model fusion for full reference video quality assessment},
  author={Bampis, Christos G and Li, Zhi and Bovik, Alan C},
  journal={IEEE Trans. Circuits Syst. Video Technol.},
  volume={29},
  number={8},
  pages={2256--2270},
  year={2018},
}
@article{wang2004image,
  title={Image quality assessment: from error visibility to structural similarity},
  author={Wang, Zhou and Bovik, Alan C and Sheikh, Hamid R and Simoncelli, Eero P},
  journal={IEEE Trans. Image Process.},
  volume={13},
  number={4},
  pages={600--612},
  year={2004},
}
@inproceedings{kim2018deep,
  title={Deep video quality assessor: From spatio-temporal visual sensitivity to a convolutional neural aggregation network},
  author={Kim, Woojae and Kim, Jongyoo and Ahn, Sewoong and Kim, Jinwoo and Lee, Sanghoon},
  booktitle={Proc. Eur. Conf. Comput. Vis.},
  pages={219--234},
  year={2018}
}
@inproceedings{rossetto2019v3c,
  title={V3C--a research video collection},
  author={Rossetto, Luca and Schuldt, Heiko and Awad, George and Butt, Asad A},
  booktitle={Proc. MultiMedia Model.},
  pages={349--360},
  year={2019},
  organization={Springer}
}
@inproceedings{li2019quality,
  title={Quality assessment of in-the-wild videos},
  author={Li, Dingquan and Jiang, Tingting and Jiang, Ming},
  booktitle={Proc. ACM Int. Conf. Multimedia},
  pages={2351--2359},
  year={2019}
}