\section{Pitchclass2vec model}\label{sec:model}
% 1. nlp embeddings/chord2vec problems and limitations
% 2. how to overcome them and why
% 3. our encoding
% 4. encoding implementation

Embedding approaches used in natural language processing have obvious limitations when it comes to dealing with musical content, such as musical chords.
While relying on purely syntactical representations has been show to correctly encapsulate some forms of domain knowledge \cite{anzuoni2021historical}, more advanced representations are needed to obtain accurate results when dealing with harmonic progressions \cite{madjiheurem2016chord2vec}.

There are, however, some ambiguous cases in which both vector representations might introduce wrong similarities between chords.
Let us take for instance the chords \textit{C:maj} and \textit{C:maj13}\footnote{In Harte\cite{harte2005symbolic} notation}, whose notes are respectively $\mathcal{C}_{\textit{C:maj}} = \{C, E, G\}$ and $\mathcal{C}_{\textit{C:maj13}} = \{ C, E, G, B, D, A \}$. Both chords' labels only differ by two characters, however the difference between the notes that they are composed of can't be neglected. A method exclusively based on syntactical information would wrongly represent the vectors as similar between each other.
Conversely, only relying on the notes that compose a chord results in ambiguous representations of some particular classes of chords, called \textit{enharmonic} chords.
For instance, the \textit{enharmonic} chords \textit{C:dim} and \textit{Eb:dim} share the exact same set of notes, $\mathcal{C}_{\textit{C:dim}} = \mathcal{C}_{\textit{Eb:dim}} = \{C, Eb, Gb, A\}$ but need to be represented as different chords as they serve different harmonic purposes. \textit{Chord2vec} would wrongly represents both chords as the same exact vector.


In order to overcome the aforementioned limitations, we propose an encoding which requirements can be summarised as follows:
\begin{enumerate*}
    \item it has to be based on the constituent notes of a chord, rather than its label; and
    \item it must take into account the relation between those notes instead of the notes themselves.
\end{enumerate*}

The proposed encoding is grounded on tonal music theory: each chord $c$ is composed of a set of notes $\mathcal{C} \subset \mathcal{N}$, where $\mathcal{N}$ is the set of all notes and $C$ is called the \textit{pitch class} of a chord. An important distinction is represented by the \textit{root} note, which names the chord and plays an important role in its harmonic function.
 
\medskip
\begin{figure}
\centering
\begin{subfigure}{.48\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/similar_chord_diagram.drawio.png}
  \caption{C:maj and C:maj9 chord embeddings. The final representation is computed from common elements and will hence share some aspects.}
  \label{fig:pitchclass2vec-similarlabel-embedding}
\end{subfigure}
\hfill
\begin{subfigure}{.48\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/same_dim_chord_diagram.drawio.png}
  \caption{C:dim and Eb:dim chord embeddings. Both chords are composed of the same notes but using mostly different components.}
  \label{fig:pitchclass2vec-enharmonic-embedding}
\end{subfigure}
\caption{Visual reference on pitchclass2vec embedding method.}
\end{figure}

We encode each chord as the Cartesian product $\mathcal{I}_c = \textit{root}_c \times \mathcal{C}_c$ between the \textit{root} note and the \textit{pitch class} of the chord. The vector representation $\mathbf{u}_c$ of a chord $c$ is computed as
\begin{displaymath}
  \mathbf{u}_c = \sum_{i \in \mathcal{I}_c} \mathbf{u}_i
\end{displaymath}
where $\mathbf{u}_i$ is the vector representation of the tuple $x_i \in \mathcal{I}_c$. 
See Figure \ref{fig:pitchclass2vec-enharmonic-embedding} for a visual reference on how \textit{pitchclass2vec} handles \textit{enharmonic} chords and Figure \ref{fig:pitchclass2vec-similarlabel-embedding} on how chords with common components are handled.
This formalization can be seen as an extension of the chord2vec \cite{madjiheurem2016chord2vec} method, in which the chord inner structure is taken into consideration as well.

% mixed encoding: nlp + pitchclass2vec

Nevertheless, the label of a chord has a well-defined semantic. Chords composed of the same set of notes may have different harmonic functions. For example, the chords \textit{G:min7} and \textit{Bb:6}, despite different labels contain the exact same notes: $\mathcal{C}_{\textit{G:min7}} = \mathcal{C}_{\textit{Bb:6}} = \{G, Bb, D, F\}$. 
This problem is particularly evident in datasets containing annotations made by experts, where the choice of label is the result of a meticulous analysis. 
For this reason, we have implemented two different variants of \textit{pitchclass2vec}: 
\begin{enumerate*}[label=(\roman*)]
    \item a variant combining the approach proposed by \textit{word2vec} with \textit{pitchclass2vec}; and 
    \item a variant combining \textit{fasttext} with \textit{pitchclass2vec}.
\end{enumerate*}

In order to obtain mixed embeddings we test different hybrid combinations before passing the new representation to the LSTM model:
\begin{enumerate}[label=(\roman*)]
    \item concatenating the embeddings;
    \item concatenating the embeddings and projecting the result in a $N$-dimensional vector, using a fully connected layer;
    \item projecting the embeddings in the same $N$-dimensional space by using two different fully connected layer and summing the $N$-dimensional vectors;
    \item computing a new representation of each embedding by using two separate LSTM layers and summing the resulting vectors;
    \item computing a new representation of each embedding by using two separate LSTM layers and concatenating the resulting vectors.
\end{enumerate}
None of the combination used proved to be able to outperform the others and we decided to stick to the first simpler and faster approach.

\subsection{Implementation details}
\label{sec:implementation-details}
The model is implemented using \texttt{pytorch}. We train the model on a set of $\approx 16000$ chord progressions (with a total number of over $1M$ chord instances), taken from the Chord Corpus (ChoCo) dataset \cite{deberardinis2022choco}. ChoCo is a chord dataset consistsing of more than $20000$ tracks taken from $18$ different professionally curated datasets. 
All datasets have been parsed in JAMS \cite{humphrey2014jams} format and converted in Harte Notation \cite{harte2005symbolic}.
We train the model for at most $10$ epochs on an \textit{NVIDIA RTX 3090} with batch sizes of $512$ harmonic progressions. 
We manually tune the batch size to efficiently train the model on our available resources.
For each chord we take a window of $4$ context chords as positive examples, $2$ preceding and $2$ succeeding, as it has been done in the original \emph{fasttext} implementation \cite{bojanowski2018fasttext}. Then, we sample $20$ random chords as negative examples. Even though it has been shown that windows of different sizes yields different results depending on the task they are applied to \cite{caselles2018word2vec} here we will rely on a fixed size window to better compare it to the related works.
%For each chord we take a window of $4$ context chords, $2$ preceding and $2$ succeeding, as positive examples and sample $20$ random chords as negative examples.
We subsample our corpus to obtain a more balanced one by removing some of the most frequent chords instances.  We use a factor of $t = 10^{-5}$ as suggested by \cite{mikolov2013word2vec} to allow a faster and more accurate training phase.
The model is trained using a standard training procedure where a binary cross entropy loss between a chord and its positive and negative examples is minimized using Adam optimizer, with fixed learning rate of $0.025$.
We set the embedding dimension to $10$ as the result of manual trials.
