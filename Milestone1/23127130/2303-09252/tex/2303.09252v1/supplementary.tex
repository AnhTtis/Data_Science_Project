\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

\usepackage{multirow}% lin
\usepackage{xcolor} % lin
\usepackage{subfiles}  % lin
\usepackage{subfigure} % lin
% \renewcommand{\thesubfigure}{\normalfont(\alph{subfigure})}  % lin
\usepackage{array} % lin
\usepackage{booktabs} % lin

\usepackage{xcolor} % lin
\newcommand{\sgg}[1]{{\color{black}#1}}
\newcommand{\cmt}[1]{{\color{black}#1}}
\newcommand{\jy}[1]{{\color{black}#1}}
\newcommand{\jl}[1]{{\color{black}#1}}
% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{****} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ificcvfinal\pagestyle{empty}\fi

\begin{document}

% \subsection{Main Effect of test time: NMS}

%   As for the inference 
%   and the threshold of the classification score is set to be 0.05 as default in MMDetection.
% The IOU threshold of Non-Maximum Suppression is 0.5.


\section{Implementation Details}
For data augmentation, a training image 
is first flipped with a probability of 0.5 
and then resized with the long edge set to
1333 and the short edge to 800 pixels, 
followed by the normalization with the mean and standard deviation in CLIP. 
For the input image of the fixed CLIP image encoder in image-level alignment, 
we follow the original processing in CLIP. 
When comparing with other SOTA approaches, we adopt multi-scale training with the sizes of
    (1333, 640), (1333, 672), (1333, 704), (1333, 736), (1333, 768), (1333, 800) similar to ViLD and random cropping augmentation where the cropped edge is not less than 0.5 of the original edge. 
    
For the training process,
     GridCLIP is trained for a 2$\times$ (24 LVIS epochs) schedule.
     GridCLIP uses AdamW optimizer with the learning rate as 1e-4
    and the decay weight as 1e-4, where the learning rate of the CLIP
    image encoder is 0.1 of the other parameters to better preserve the
    pre-trained weights.
The learning rate multiplied by 0.1 at epoch 16 and 22. We use linear warmup for the first 500 iterations, from learning rate 1e-3. 
    GridCLIP also adopts gradient clipping with 
    a max $L_2$ norm of 0.1 
    similar to that adopted in DenseCLIP. 
    Repeat factor sampling~\cite{gupta2019lvis} is adopted as in ~\cite{gu2021open,zhou2022detecting}. 
The batch size is 16.
During the inference stage, the maximum number of detection objects per image is 300,  and the threshold of the classification score is set to be 0.05 as default in MMDetection.
The IOU threshold of Non-Maximum Suppression is 0.5. 





{\small
\bibliographystyle{ieee_fullname}
\bibliography{GridCLIP}
}

\end{document}