\section{Conclusion, limitation, and future work}
\label{sec:future}

%\am{We present a method to automatically generate artistic typography for a given letter or a word. This is an extremely challenging task since one cannot simply deform a given letter to a target semantic in an artistic way as prior knowledge about the visual domain of the semantic is necessary. To address this challenge, we incorporated language-based generative models in our approach. Through several quantitative and qualitative experiments, along with user studies, we demonstrated the efficacy of our method and showed that solely using state-of-the-art language-based generative models will not produce satisfactory results.
%Our method is one of the first attempts to combine adversarial learning and diffusion in a single framework. 
%Using diffusion's powerful capabilities for generation and having a discriminator, we can ensure that our generated artistic typography stays faithful to the given letter.}

We developed an automatic method to generate artistic typography for a letter or word by using language-based generative models equipped with a discriminator. We demonstrated the effectiveness of our method, coined DS-Fusion, through extensive experiments and user studies. Our approach combines adversarial learning and diffusion, which helps ensure the fidelity of the generated typography. 



%which is a difficult task as one cannot simply deform a given letter to a target semantic in an artistic way as prior knowledge about the visual domain of the semantic is necessary.


% We have presented a method to generate artistic typography for a given letter or a word. This is an extremely challenging task since one cannot simply deform a given letter to a target semantic in an artistic way as prior knowledge about the visual domain of the semantic is necessary. To address this challenge, we incorporated language-based generative models in our approach. Through several quantitative and qualitative experiments, along with user studies, we demonstrated the efficacy of our method and showed that solely using state-of-the-art language-based generative models will not produce satisfactory results.
% Our method is one of the first attempts to combine adversarial learning and diffusion in a single framework. 
% Using diffusion's powerful capabilities for generation and having a discriminator, we can ensure that our generated artistic typography stays faithful to the given letter.

Our method is generally effective but it still has some limitations that require further investigation. When dealing with multi-letter inputs, our method may struggle to generate satisfactory results if the style images and letters are too dissimilar (Figure~\ref{fig:res_limitations}).
At present, our method is optimized for each specific combination of style and glyph. However, future work could involve training a network for a particular style that can generate any letter during inference.
Despite having an automatic selection strategy, it may not always generate the most visually plausible outcome. Rather, it can generate a range of plausible results to choose from. A stronger selection mechanism could be a future work.

\input{figs/fig_limitations.tex}

Our glyph is potentially an image in various forms, including alphanumeric fonts, foreign language characters, or even a 2D shape. It is interesting to creatively modify such shapes to display a semantic (e.g., a flower-shaped chair). 
In addition, for personalization, style images can be manually prepared or drawn if desired. We explored these ideas and presented preliminary results in the supplementary material, but further research is necessary to solidify the outcomes.

% \vspace{7pt}

% \mypara{Glyph as general shape}
% %
% \rz{In general, a glyph depicts a graphic form that can be an alphabetic or numeric font, a character or script from a foreign language such as Chinese, or a combination of them. In its most general form, our input glyph can represent a general 2D shape.}
% As shown in Figure~\ref{fig:res_extensions}, we can transfer the given styles onto other objects like chair, toys and cars etc. 
% \input{figs/fig_extension.tex}

% \vspace{7pt}

% \mypara{Personalized stylization}
% %
% If desired, these style images could also be prepared manually, e.g., for personalization.




%Furthermore, because the method fine-tunes the generator to output results in a specific shape, it can affect prompts other than those used in the method. Therefore, the method should only be used to generate results as designed, otherwise, unexpected outputs might be generated. This can be extended to future work, where the whole generator can be adapted to a specific shape or glyph. However, we did not explore this extension currently.