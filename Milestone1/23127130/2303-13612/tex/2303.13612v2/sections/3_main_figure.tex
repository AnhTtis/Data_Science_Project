\begin{figure*}[!t]
    \begin{center}
    \includegraphics[width=1\linewidth]{figures/method/framework.png}
    \end{center}
    \vspace{-20pt}
    \caption{
        \label{fig:framework}
        {\bf Overview.} During training, we train a U-Net to predict the embedding of a novel view of an object, given a reference image of the object and a relative pose. The U-Net is conditioned on an embedding of the relative pose computed using an MLP, which we train jointly with the U-Net. 
        At inference, our method first takes as input a reference image of a new object and predicts the embeddings of views of the object under many relative poses. This inference takes around 1 second on a single GPU V100.
        Then, given a query image of the object, we first compute its embedding and match it against the set of predicted embeddings.  This gives us a distribution over the possible relative poses between the reference and query images, where the maximum corresponds to the predicted pose. 
        %, which takes about 0.2s
        \vspace{-5pt} 
        }
\end{figure*} 
