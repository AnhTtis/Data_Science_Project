\begin{table}[t]\centering%\ra{1.1}
\resizebox{0.48\textwidth}{!}{
\begin{tabular}{lccS[table-format=2.2]S[table-format=2.2]S[table-format=2.2]S[table-format=2.2]}
% \sisetup{detect-weight=true,detect-inline-weight=math}
\toprule
\multirow{2}{*}{arch} & \multirow{2}{*}{pre-trained} & \multirow{2}{*}{classif} & \multicolumn{2}{c}{SS only} & \multicolumn{2}{c}{SS + DS} \\
\cmidrule(lr){4-5} \cmidrule(lr){6-7}
 &  &  & \multicolumn{1}{c}{AUROC$\uparrow$} & \multicolumn{1}{c}{OSCR$\uparrow$} &  \multicolumn{1}{c}{AUROC$\uparrow$} & \multicolumn{1}{c}{FPR95$\downarrow$} \\
\midrule
    \multirow{2}{*}{ViT-L/16}     & ImageNet & LP & 91.82           & 86.92           & 95.98           & 21.20 \\
                                  & ImageNet & NM & 77.67           & 69.05           & 81.48           & 69.34 \\
    \multirow{2}{*}{ViT-L/14}     & CLIP     & LP & \first{94.35} & \first{91.10}     & 97.01           & \pz8.73 \\
                                  & CLIP     & NM & 85.05           & 79.26           & \first{98.06} & \first{\pz8.62} \\
\bottomrule
\end{tabular}
}
\caption{
The CLIP representation consistently outperforms the ImageNet pre-trained
    representation  on a range of OOD tasks. The scores are averages over many
    semantic-shift-only (SS) and mixed SS and domain shift (SS+DS) tasks. The
    SS experiments are MNIST, SVHN, CIFAR10, CIFAR+10, CIFAR+50 and TIN,  SS+DS
    experiments include  CIFAR10 vs. SVHN, MNIST, Textures, Places365,
    CIFAR-100, iNaturalist, TIN and LSUN. Evaluation for different network
    architectures and per-dataset results are provided in the supplementary
    material.}

\label{tab:repr_comparison}
\end{table}
