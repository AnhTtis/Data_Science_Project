\begin{table}[t]
\caption{
The generic representation models (CLIP, DIHT) consistently outperforms the ImageNet pre-trained
    representation  on a range of OOD tasks. The scores are averages over many
    semantic-shift-only (SS) and mixed SS and domain shift (SS+DS) tasks. The
    SS experiments are the same as in Tab~\ref{tab:osr_results} and SS+DS
    as in Tab~\ref{tab:ood_results}. Evaluation for different network
    architectures and per-dataset results are provided in the supplementary
    material.}
\vspace*{0.3em}
\centering%\ra{1.1}
\resizebox{0.48\textwidth}{!}{
\begin{tabular}{lccS[table-format=2.2]S[table-format=2.2]S[table-format=2.2]S[table-format=2.2]}
% \sisetup{detect-weight=true,detect-inline-weight=math}
\toprule
\multirow{2}{*}{arch} & \multirow{2}{*}{pre-trained} & \multirow{2}{*}{classif} & \multicolumn{2}{c}{SS only} & \multicolumn{2}{c}{SS + DS} \\
\cmidrule(lr){4-5} \cmidrule(lr){6-7}
 &  &  & \multicolumn{1}{c}{AUROC$\uparrow$} & \multicolumn{1}{c}{OSCR$\uparrow$} &  \multicolumn{1}{c}{AUROC$\uparrow$} & \multicolumn{1}{c}{FPR95$\downarrow$} \\
\midrule
    \multirow{2}{*}{ViT-L/16}     & ImageNet & LP & 91.82           & 86.92           & 95.98           & 21.20 \\
                                  & ImageNet & NM & 77.67           & 69.05           & 81.48           & 69.34 \\
    \multirow{2}{*}{ViT-L/14}     & DIHT     & LP & 93.62 & 89.91&\first{99.27} & \first{\pz2.68}\\
                                  & DIHT     & NM & 88.44 & 81.80 & 99.15 & \pz4.26\\
    \multirow{2}{*}{ViT-L/14}     & CLIP     & LP & \first{94.35} & \first{91.10}     & 97.01           & \pz8.73 \\
                                  & CLIP     & NM & 85.05           & 79.26           & 98.06 & \pz8.62 \\
\bottomrule
\end{tabular}
}

\label{tab:repr_comparison}
\end{table}
