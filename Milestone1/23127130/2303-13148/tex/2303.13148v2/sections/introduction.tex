\section{Introduction}

The problem of detection of out-of-distribution data points, OOD in short, is
important in many computer vision
applications~\cite{Bergmann2021,Kuo2019,chan2021_bench}. One can even argue
that no model obtained by machine learning on a training set $\mathcal{T}$
should be deployed  without the  OOD ability, since in practice it is almost
never the case that all the models input data will be
drawn from the same distribution that generated~$\mathcal{T}$~\cite{Zhao2021}.
For undetected out-of-distribution data, the prediction will in general be
arbitrary, with possibly grave real-world consequences, especially in
safety-critical applications. 
The importance and ubiquity of OOD is evidenced
by the fact that virtually the same problem has emerged in different contexts
under different names - open set recognition, anomaly or outlier detection, and
one-class classification. 

The reasons for test data not being from the training set distribution are
diverse; they often influence the terminology used. In open set
recognition (OSR)~\cite{Mahdavi2021,yang2021generalized}, the semantic shift is
considered, \ie the introduction of new classes at test time. Failures of the
measurements system generate outlier data. In anomaly detection, the presence
of out-of-distribution data is assumed rare. A domain shift, e.g. when
a classifier trained on real-world images is applied to clip art, leads to
a severe data distribution change.

So far, prior art has mainly developed OOD detection models by supervised
training on in-distribution (ID)
data~\cite{yang2021generalized,Bogdoll2022,Bitterwolf2022}. We follow the recent success of 
self-supervised representation  model training~\cite{Radenovic_2023_CVPR, radford2021learning}, 
we apply it to out-of-distribution detection, our approach produces a calibrated 
decision strategy and we analyze its performance in various scenarios.

The performance of the proposed method is predicated by the use of a \textit{good generic representation}. 
Any {\it good} representation should enable solving a given, a priori unknown,
downstream task. A good {\it generic} representation should enable solving
multiple tasks without the need of fine-tuning on the task data. To verify the
goodness and generality of tested representations, we first exploit two commonly used
simple classifiers: (i) linear probe (LP), and (ii) the nearest mean (NM)
classifier. These simple classifiers already
outperform the state-of-the-art on a broad range of OOD detection problems, often by a large
margin, however, without apriori knowledge about the specificity of the OOD data its 
unclear which of these simple methods (or any other score based methods build on top of 
generic representation) should be preferred.

Since the LP and NM methods perform each well on different classes of the OOD
problems, we formulate a Neyman-Pearson task~\cite{Schlesinger2002,
Neyman1928, Neyman1933} on their combination. We call this approach \grood
(for Generic Representation based OOD detection). It models the in-distribution (ID)
as a 2D Gaussian in the space of LP and NM responses and provides a robust
solution to the OOD problem. It also naturally results in well calibrated rejection scores, which
allow us to define a global threshold for data rejection, \ie OOD identification. The global threshold 
can be set to incur user-specified pre-defined error on ID data and is calibrated for 
all classes, meaning, the pre-defined error is the same for all classes.
In contrast, most current state-of-the-art methods work on basis of similarity scores with no simple 
mechanism for selecting a single threshold for OOD rejection.
This novel approach significantly improves OOD performance and the experiments also confirm
the superiority of using the generic representation over problem-specific approaches
that train or fine-tune the feature extractor on a particular ID training set. 

The \grood does not require any information about the out-of-distribution data, \eg in the form of a few examples of the anomalies, and is
thus applicable to all the standard setting of the OOD and OSR
problems~{\cite{yang2021generalized}}. To summarize, the contributions of the paper are:

\begin{itemize} 
\item We show that using a generic pre-trained representation together with
    a simple classifier achieves state-of-the-art performance on a number of
        OOD benchmarks.

\item We formulate the OOD detection as a Neyman-Pearson task in the space of LP and NM
    scores. The operating point is selected by the allowed false negative rate
        for {\it all} ID classes. This results in a well calibrated
        classification score on the ID task.

\item We evaluate the method on a wide range of OOD problems. The proposed method outperforms the state-of-the-art by a large margin on
most of the problems and even saturates several commonly used benchmarks.

\end{itemize}
