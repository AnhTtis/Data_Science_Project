{
    "arxiv_id": "2303.13148",
    "paper_title": "Calibrated Out-of-Distribution Detection with a Generic Representation",
    "authors": [
        "Tomas Vojir",
        "Jan Sochman",
        "Rahaf Aljundi",
        "Jiri Matas"
    ],
    "submission_date": "2023-03-23",
    "revised_dates": [
        "2023-03-24"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV"
    ],
    "abstract": "Out-of-distribution detection is a common issue in deploying vision models in practice and solving it is an essential building block in safety critical applications. Existing OOD detection solutions focus on improving the OOD robustness of a classification model trained exclusively on in-distribution (ID) data. In this work, we take a different approach and propose to leverage generic pre-trained representations. We first investigate the behaviour of simple classifiers built on top of such representations and show striking performance gains compared to the ID trained representations. We propose a novel OOD method, called GROOD, that achieves excellent performance, predicated by the use of a good generic representation. Only a trivial training process is required for adapting GROOD to a particular problem. The method is simple, general, efficient, calibrated and with only a few hyper-parameters. The method achieves state-of-the-art performance on a number of OOD benchmarks, reaching near perfect performance on several of them. The source code is available at https://github.com/vojirt/GROOD.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.13148v1"
    ],
    "publication_venue": "10 pages, submitted to conference"
}