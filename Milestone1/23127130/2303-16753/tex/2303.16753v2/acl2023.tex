% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Remove the "review" option to generate the final version.
% \usepackage[review]{ACL2023}
\usepackage[]{ACL2023}


% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary and may be commented out.
% However, it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}
% =========== custom package
% add by gzf
\usepackage{amssymb}
\usepackage{amsmath} 
\usepackage{booktabs}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{xspace}
\usepackage{float}
\usepackage{bbm}
\usepackage{bm}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{color}
\usepackage{framed}
\usepackage{stfloats}
\usepackage{iitem}
% End by gzf
\usepackage{makecell}
\definecolor{shadecolor}{RGB}{180,180,180}
\usepackage{colortbl}
\usepackage{color, xcolor}
% \newtheorem{theorem}{Theorem}[section]
% \newtheorem{lemma}[theorem]{Lemma}
% \newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}{Definition}[section]
\newtheorem{thm}{\bf Theorem}
\newtheorem{lem}{\bf Lemma}
\newtheorem{defi}{\bf Definition}
\newtheorem{cor}{\bf Corollary}
\newcommand{\paratitle}[1]{\vspace{1.5ex}\noindent\textbf{#1}}
\newcommand\Vector{\bm}
\newcommand\Matrix{\mathbf} 
\newcommand\Tensor{\mathcal}
\newcommand{\ie}{\emph{i.e.,}\xspace}
\newcommand{\aka}{\emph{i.e.,}\xspace}
\newcommand{\eg}{\emph{e.g.,}\xspace}
\newcommand{\etal}{\emph{et al.}\xspace}
\newcommand{\ignore}[1]{}
\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}
% =========== custom package
%%%%%%%%% algorithm
\usepackage{algorithm}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\usepackage{algpseudocode}
% \usepackage{amsthm}
\usepackage{amsmath}
\usepackage{tikz}
\renewcommand{\algorithmicrequire}{\textbf{Require:}}
\renewcommand{\algorithmicensure}{\textbf{Output}}
% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

% \title{Instructions for ACL 2023 Proceedings}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a seperate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

% \author{First Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\\And
%   Second Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\}
% Scaling Transformers more deeper base on MPO
% \title{Scaling Transformers to Deeper with Fewer Parameters 
% \\ and Faster Convergence}
\title{Scaling Pre-trained Language Models to Deeper \\ via Parameter-efficient Architecture}

\author{
	Peiyu Liu$^{1,3}$\thanks{$\ $ Authors contributed equally.},
	Ze-Feng Gao$^{1*}$,
        Yushuo Chen$^{1,3}$,
	Wayne Xin Zhao$^{1,3}$\thanks{$\ $ Corresponding author.},\and
	\textbf{Ji-Rong Wen}$^{1,2,3}$
	\\
	$^1$Gaoling School of Artificial Intelligence, Renmin University of China\\
	$^2$ School of Information, Renmin University of China\\
	$^3$Beijing Key Laboratory of Big Data Management and Analysis Methods\\
	% $^4$Beijing Academy of Artificial Intelligence, Beijing, 100084, China\\
	{\tt\{liupeiyustu,zfgao,jrwen\}@ruc.edu.cn, }\\ 
	{\tt batmanfly@gmail.com,chenyushuo1999@foxmail.com}
}

\begin{document}
\maketitle

\begin{abstract}
In this paper, we propose a highly parameter-efficient approach to scaling pre-trained language models~(PLMs) to a deeper model depth. 
Unlike prior work that shares all parameters or uses extra blocks, we design a more capable parameter-sharing architecture based on  matrix product operator~(MPO). 
MPO decomposition can reorganize and factorize the information of a parameter matrix into two parts: the major part that contains the major information (\emph{central tensor}) and the supplementary part that only has a small proportion of parameters (\emph{auxiliary tensors}). Based on such a decomposition,  our architecture shares the central tensor 
across all layers for reducing the model size and meanwhile keeps layer-specific auxiliary tensors (also using adapters) for enhancing  the adaptation flexibility.   To improve the model training,  
we further propose a stable initialization algorithm tailored for the MPO-based architecture.
Extensive experiments have demonstrated the effectiveness of our proposed model in reducing the model size and achieving highly competitive performance. 

\end{abstract}

\input{section/sec-introduction.tex}
\input{section/sec-relatedwork.tex}
% \input{section/sec-preliminary.tex}
\input{section/sec-method_lpy.tex}
\input{section/sec-experiment.tex}
\input{section/sec-conclusion.tex}
\input{section/sec-limitation.tex}
\input{section/sec-ethic.tex}

% Entries for the entire Anthology, followed by custom entries
\bibliography{anthology,custom}
\bibliographystyle{acl_natbib}

\appendix
\input{section/sec-appendix.tex}

\end{document}
