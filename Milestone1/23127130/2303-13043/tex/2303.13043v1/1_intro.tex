\section{Introduction}
\label{sec:intro}


% Attention, which dynamically adjusts the focus of the visual systems, is an indispensable mechanism to make human and machine visual systems efficient and versatile. Recently self-attention has emerged and played a key role in the dominating vision transformer~\cite{dosovitskiy2020image} models in computer vision. Self-attention can be seen as a type of bottom-up attention, meaning that it solely depends on the input image and is attracted to any salient objects or regions regardless of the high-level goals or tasks at test time (\cref{fig:intro}(a)). 

% Top-down attention, which conversely attends to regions or objects conditioned on high-level goals and tasks (\cref{fig:intro}(b-c)), is shown existing in human visual systems~\cite{zhaoping2014understanding,carrasco2011visual}. Top-down attention is goal driven and can potentially lead to more versatile models in practice. For example, given a task to detect cups, top-down attention can direct the model to only focus on the necessary regions related to the task instead of highlighting all the salient objects in the image as bottom-up attention does.  Additionally, by simply adjusting the task priors at test time, top-down attention can redirect the model for new tasks and scenarios. 

Human visual attention is often \textit{task-guided}, \ie, we tend to focus on different objects when processing different tasks~\cite{zhaoping2014understanding,carrasco2011visual}. For example, when we answer different questions about one image, we only attend to the objects that are relevant to the question (\cref{fig:intro} (b-c)). This stands in contrast with the widely-used self-attention~\cite{dosovitskiy2020image}, which is completely \textit{stimulus-driven}, \ie, it highlights all the salient objects in the image without task-guided selection (\cref{fig:intro} (a)). While the stimulus-driven bottom-up attention has shown promising results in visual representation learning~\cite{caron2021emerging}, current vision transformers still lack the ability of task-guided top-down attention, which provides task-adaptive representation and potentially improves task-specific performances~\cite{anderson2018bottom,xu2015show,xu2016ask}.
Although some algorithms of top-down attention are proposed in the literature~\cite{pang2021tdaf,chen2021look,anderson2018bottom,xu2015show,xu2016ask}, they are incompatible with self-attention-based transformers and principled and unified designs are still missing.


% Attention appears to be an indispensable mechanism for biological visual systems. There are two types of visual attention, bottom-up and top-down~\cite{zhaoping2014understanding,carrasco2011visual}. Bottom-up attention is \textit{stimulus-driven}, which solely depends on the input image and is attracted to any salient objects or regions regardless of the high-level goals or tasks at test time (\cref{fig:intro} (a)). In contrast, top-down attention is \textit{goal-directed}, \ie, it only attends to objects or regions that are related to the high-level task or goal and 
% % voluntarily ignores the others 
% suppresses the attention on the rest of the objects. 
% (\cref{fig:intro} (b-c)).
% This helps models focus on the regions highly related to the given task and can be useful for real-world applications. 

% This 
% helps a model extract a more 
% focused representation of the 
% task being processed and is 
% essential for real-world 
% scenarios.

% adapted first paragraph

%Unlike the bottom-up attention algorithms that have played a key role in the dominating vision transformers~\cite{dosovitskiy2020image}, the mechanism behind top-down attention is less understood. Although previous work proposed various algorithms~\cite{pang2021tdaf,chen2021look,anderson2018bottom,xu2015show,xu2016ask} of top-down attention, they are incompatible with self-attention based transformers and a principled and unified design is still missing.

\begin{figure}[t]
\begin{center}
\centerline{\includegraphics[width=1\columnwidth]{figures/intro.pdf}} \vspace{-2mm}
\caption{\textbf{Top-down \vs bottom-up attention}. (a) Bottom-up attention is stimulus-driven, \ie, any salient objects (dog and cat) in the image may attract attention. (b-c) Top-down attention is task-guided. For example, when the task is to answer a question about a specific object, the attention will only center on that object and ignore the others. In this way, a more focused representation can be extracted for the current goal.}
\label{fig:intro}
\end{center}
\vskip -0.4in
\end{figure}

%However, top-down attention~\cite{} is less used in computer vision nowadays partly due to the challenges of understanding its mechanism and designing top-down attention in a way that is compatible with widely used model architectures like vision transformers. 
Previous work~\cite{lee2002top,chikkerur2010and,borji2012object,rao2005bayesian,lee2003hierarchical} has studied the mechanism of top-down attention in human vision systems, hypothesizing top-down attention is a result of the human visual system performing Analysis by Synthesis (AbS). AbS~\cite{knill1996perception,yuille2006vision} is a classic idea that suggests the human visual perception depends on both the input image and a high-level prior about the latent cause of the image, and different priors can lead to different ways to perceive the same image (\eg, visual illusion~\cite{lee2003analysis} and bistable perception~\cite{schrater2006theory}). This is formulated as Bayesian inference $\max_\bfz p(\bfh | \bfz) p(\bfz)$, where $\bfh$ is the input image, and $\bfz$ is the latent representation. It is hypothesized that the high-level goal can be formulated as a prior to direct the low-level recognition of different objects through AbS, achieving top-down attention. Still, existing works~\cite{yu2004inference,chikkerur2010and,mirza2019introducing} are  conceptual and hardly guide model designs in practice. 

% One possible explanation for top-down attention mechanism in human vision comes from another classic idea in the literature, Analysis by Synthesis (AbS)~\cite{knill1996perception,yuille2006vision}. AbS hypothesizes that our visual perception depends both on the input image and a high-level prior about the latent cause of the image. Specifically, visual perception is formulated as the Bayesian inference $\max_\bfz p(\bfh | \bfz) p(\bfz)$, where $\bfh$ is the input image and $\bfz$ is our representation of the image. In other words, we are finding the latent representation that can explain the image ($p(\bfh | \bfz)$) and is also consistent with the prior $p(\bfz)$. By changing the prior, we may perceive the same image in different ways. AbS has been used to explain phenomena such as visual illusions~\cite{lee2003analysis} and bistable perception~\cite{schrater2006theory}.

% %The two seemingly unrelated concepts of top-down attention and AbS may have a deeper connection than we thought. 
% In fact, it has long been hypothesized by visual neuroscience community that top-down attention is a result of human visual system performing AbS~\cite{lee2002top,chikkerur2010and,borji2012object,rao2005bayesian,lee2003hierarchical}. The intuition is that, for an image with multiple objects, if our prior is centered at the representation of one specific object (\ie, we expect the extracted representation to be close to the selected object), then the visual system needs to focus on that single object and ignore the others so that the output representation is consistent with the prior. However, existing computational models~\cite{yu2004inference,chikkerur2010and,mirza2019introducing} are either oversimplified or based on toy examples, and the relationship between top-down attention and AbS in general visual models is still vague. 

In this work, we present a novel perspective on how AbS entails top-down attention, followed by a new Analysis-by-Synthesis Vision Transformer (\model) based on the findings.  We start from previous work~\cite{shi2022visual}, which shows that visual attention (\eg, self-attention) is functionally equivalent to sparse reconstruction which reconstructs the input using a dictionary containing templates of separate objects in the input.  
% Specifically, sparse reconstruction uses a dictionary containing templates of different objects, and tries to reconstruct the input with as few templates as possible, thus only the salient objects are preserved. Then
We show that AbS optimizes a similar \emph{sparse reconstruction} objective modulated by a top-down signal. The top-down signal depends on the prior and acts as a preference on which object templates to choose to reconstruct the input. Therefore, only the objects consistent with the high-level prior are selected, equivalent to top-down attention.

Inspired by the connection, we propose \model, a ViT~\cite{dosovitskiy2020image} model with prior-conditioned top-down modulation trained to approximate AbS in a variational way. \model contains a feedforward (encoding) and a feedback (decoding) pathway. The feedforward path is a regular ViT, and the feedback path contains linear decoders for each layer. Each inference starts with an initial feedforward run. The output tokens are manipulated by the prior and fed back through the decoders to each self-attention module as top-down input for the final feedforward pass (\cref{fig:model}). 

When only pretrained on ImageNet~\cite{deng2009imagenet}, which contains mostly single-object images, \model can attend to different objects in multi-object scenes controllably. For real-world applications, we observe consistent improvements from \model on Vision-Language tasks such as VQA~\cite{antol2015vqa} and zero-shot image retrieval, where language is used as a prior to guide attention. For tasks without a strong prior, such as ImageNet classification and semantic segmentation, \model can also serve as a general backbone and achieve substantial improvements. 
% The key to success, as we  demonstrate, is cleaner object-centric attention  
Additionally, the object-centric representation resulting from the top-down attention design enables 
% which also enables 
better generalization to corrupted, adversarial, and out-of-distribution images. We hope this work can encourage future exploration of task-guided attention designs and visual representation learning. 
% We summarize our key contributions as follows:
% \begin{itemize}
%     \item We provide a novel perspective on the mechanism of top-down attention by explaining it as an outcome of an Analysis-by-Synthesis visual system.
%     \item We propose \model, a top-down modulated ViT that variationally approximates AbS, and achieves controllable top-down attention.
%     \item \model improves over baselines on Vision-Language tasks such as VQA and zero-shot image retrieval, and also boosts performance on ImageNet classification and model robustness.
% \end{itemize}
