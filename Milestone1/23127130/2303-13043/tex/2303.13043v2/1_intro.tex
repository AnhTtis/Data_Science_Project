\section{Introduction}
\label{sec:intro}




Human visual attention is often \textit{task-guided}, \ie, we tend to focus on different objects when processing different tasks~\cite{zhaoping2014understanding,carrasco2011visual}. For example, when we answer different questions about one image, we only attend to the objects that are relevant to the question (\cref{fig:intro} (b-c)). This stands in contrast with the widely-used self-attention~\cite{dosovitskiy2020image}, which is completely \textit{stimulus-driven}, \ie, it highlights all the salient objects in the image without task-guided selection (\cref{fig:intro} (a)). While the stimulus-driven bottom-up attention has shown promising results in visual representation learning~\cite{caron2021emerging}, current vision transformers still lack the ability of task-guided top-down attention, which provides task-adaptive representation and potentially improves task-specific performances~\cite{anderson2018bottom,xu2015show,xu2016ask}.
Although some algorithms of top-down attention are proposed in the literature~\cite{pang2021tdaf,chen2021look,anderson2018bottom,xu2015show,xu2016ask}, they are incompatible with self-attention-based transformers and principled and unified designs are still missing.






\begin{figure}[t]
\begin{center}
\centerline{\includegraphics[width=1\columnwidth]{figures/intro.pdf}} \vspace{-2mm}
\caption{\textbf{Top-down \vs bottom-up attention}. (a) Bottom-up attention is stimulus-driven, \ie, any salient objects (dog and cat) in the image may attract attention. (b-c) Top-down attention is task-guided. For example, when the task is to answer a question about a specific object, the attention will only center on that object and ignore the others. In this way, a more focused representation can be extracted for the current goal.}
\label{fig:intro}
\end{center}
\vskip -0.4in
\end{figure}

Previous work~\cite{lee2002top,chikkerur2010and,borji2012object,rao2005bayesian,lee2003hierarchical} has studied the mechanism of top-down attention in human vision systems, hypothesizing top-down attention is a result of the human visual system performing Analysis by Synthesis (AbS). AbS~\cite{knill1996perception,yuille2006vision} is a classic idea that suggests the human visual perception depends on both the input image and a high-level prior about the latent cause of the image, and different priors can lead to different ways to perceive the same image (\eg, visual illusion~\cite{lee2003analysis} and bistable perception~\cite{schrater2006theory}). This is formulated as Bayesian inference $\max_\bfz p(\bfh | \bfz) p(\bfz)$, where $\bfh$ is the input image, and $\bfz$ is the latent representation. It is hypothesized that the high-level goal can be formulated as a prior to direct the low-level recognition of different objects through AbS, achieving top-down attention. Still, existing works~\cite{yu2004inference,chikkerur2010and,mirza2019introducing} are  conceptual and hardly guide model designs in practice. 



In this work, we present a novel perspective on how AbS entails top-down attention, followed by a new Analysis-by-Synthesis Vision Transformer (\model) based on the findings.  We start from previous work~\cite{shi2022visual}, which shows that visual attention (\eg, self-attention) is functionally equivalent to sparse reconstruction which reconstructs the input using a dictionary containing templates of separate objects in the input.  
We show that AbS optimizes a similar \emph{sparse reconstruction} objective modulated by a top-down signal. The top-down signal depends on the prior and acts as a preference on which object templates to choose to reconstruct the input. Therefore, only the objects consistent with the high-level prior are selected, equivalent to top-down attention.

Inspired by the connection, we propose \model, a ViT~\cite{dosovitskiy2020image} model with prior-conditioned top-down modulation trained to approximate AbS in a variational way. \model contains a feedforward (encoding) and a feedback (decoding) pathway. The feedforward path is a regular ViT, and the feedback path contains linear decoders for each layer. Each inference starts with an initial feedforward run. The output tokens are manipulated by the prior and fed back through the decoders to each self-attention module as top-down input for the final feedforward pass (\cref{fig:model}). 

When only pretrained on ImageNet~\cite{deng2009imagenet}, which contains mostly single-object images, \model can attend to different objects in multi-object scenes controllably. For real-world applications, we observe consistent improvements from \model on Vision-Language tasks such as VQA~\cite{antol2015vqa} and zero-shot image retrieval, where language is used as a prior to guide attention. For tasks without a strong prior, such as ImageNet classification and semantic segmentation, \model can also serve as a general backbone and achieve substantial improvements. 
Additionally, the object-centric representation resulting from the top-down attention design enables 
better generalization to corrupted, adversarial, and out-of-distribution images. We hope this work can encourage future exploration of task-guided attention designs and visual representation learning. 
