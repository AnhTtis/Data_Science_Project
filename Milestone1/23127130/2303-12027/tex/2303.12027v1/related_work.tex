\subsection{Tracking with bounding box specification}
The classical visual trackers~\cite{ECO, DaSiam, DiMP, PrDiMP} initialize their tracking procedure based on the given bounding box in the first frame. 
Inspired by the success of transformer~\cite{vaswani2017attention} in recognition~\cite{dosovitskiy2020image} and detection~\cite{DETR,Deformerble-DETR}, most of the recent trackers~\cite{TransMeetTracker, stark, ostrack, GTELT, ToMP, CSWinTT} are developed based on the transformer structure and achieve impressive performance on many tracking benchmarks.
To improve the discriminative of the features, TrDiMP~\cite{TransMeetTracker}, TrTr~\cite{zhao2021trtr}, and TransT~\cite{chen2021transformer} use the self-attention in the transformer encoder for feature enhancement and the cross-attention in the transformer decoder for information propagation between the template feature and the search feature.
Differently, STARK~\cite{stark} employs an encoder-decoder transformer architecture to effectively capture the global feature dependencies of both spatial and temporal information in video sequences, which achieves impressive performance.

The above-mentioned methods employ a two-stage approach, separating the feature extraction and feature interaction processes.
MixFormer~\cite{cui2022mixformer} and OSTrack~\cite{ostrack} construct a one-stream tracking pipeline and achieve state-of-the-art tracking performance.
Despite the promising performance on many tracking benchmarks, classical visual trackers are still hard to be straightly applied in the real world due to the limitation of the manually specified initialization method. 

\subsection{Tracking with natural language description}
Inspired by the development of the visual grounding task, Li \etal~\cite{li2017tracking} define the task of tracking by natural language specification. Yang \etal~\cite{GTI} decompose the problem into three sub-tasks, \ie~grounding, tracking, and integration, and process each sub-task separably by three modules. Differently, Feng \etal~\cite{feng2020real} solve this task following the tracking-by-detection formulation, which utilizes natural language to generate global proposals on each frame for tracking.
To provide a specialized platform for the task of tracking by natural language specification, Wang \etal~\cite{TNL2K} release a new benchmark for natural language-based tracking named TNL2K and propose two baselines initialized by natural language and natural language with bounding boxes, respectively.
Li \etal~\cite{li2022cross} employ a target-specific retrieval module to localize the target, which is used to initialize a local tracker.
Previous works either employ the off-the-shelf visual grounding model~\cite{2019onestagevg} or use a dedicated grounding module~\cite{feng2020real, TNL2K} to detect the target, inevitably separating the connection between visual grounding and tracking.
In this work, we propose a unified visual grounding and tracking framework for the task of tracking by natural language specification, which can perform visual grounding or tracking conditioned on different inputs.
