We have presented a joint visual grounding and tracking framework to connect two tasks by unifying the relation modeling among the multi-source references and test image, which includes the cross-modality (visual and language) relation and cross-temporal (historical target patch and current search frame) relation.
Besides, we propose a semantics-guided temporal modeling module modeling the historical target states with global semantic information as guidance, which effectively improves tracking performance.
Our method achieves favorable performance against state-of-the-art algorithms on three natural language tracking datasets and one visual grounding dataset.
