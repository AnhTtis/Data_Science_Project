% =========================================================================
% SciPost LaTeX template
% Version 2019-08
%
% Submissions to SciPost Journals should make use of this template.
%
% INSTRUCTIONS: simply look for the `TODO:' tokens and adapt your file.
%
% You can also make use of our empty "skeleton" templates for each Journals,
% e.g. SciPostPhys_skeleton.tex
% =========================================================================

% TODO: uncomment ONE of the class declarations below

% Class declaration format: \documentclass[submission, {DOI label of journal}]{SciPost}
% where the DOI label of the journal should be one of:
% Phys          (for SciPost Physics)
% PhysLectNotes (for SciPost Physics Lecture Notes)
% PhysProc      (for SciPost Physics Proceedings -> !! Please use the conference-specific template which you will find on our website !!
% Astro         (for SciPost Astronomy)
% Bio           (for SciPost Biology)
% Chem          (for SciPost Chemistry)
% CompSci       (for SciPost Computer Science)
% Math          (for SciPost Mathematics)


%% PHYSICS:
% If you are submitting a paper to SciPost Physics: uncomment next line
\documentclass[submission, Phys]{SciPost}
% If you are submitting a paper to SciPost Physics Lecture Notes: uncomment next line
%\documentclass[submission, PhysLectNotes]{SciPost}
% If you are submitting a paper to SciPost Physics Proceedings: uncomment next line
%\documentclass[submission, Proceedings]{SciPost}

%% ASTRONOMY:
% If you are submitting a paper to SciPost Astronomy: uncomment next line
% \documentclass[submission, Astro]{SciPost}

%% BIOLOGY:
% If you are submitting a paper to SciPost Biology: uncomment next line
% \documentclass[submission, Bio]{SciPost}

%% CHEMISTRY:
% If you are submitting a paper to SciPost Chemistry: uncomment next line
% \documentclass[submission, Chem]{SciPost}

%% COMPUTER SCIENCE:
% If you are submitting a paper to SciPost Computer Science: uncomment next line
% \documentclass[submission, CompSci]{SciPost}

%% MATHEMATICS:
% If you are submitting a paper to SciPost Mathematics: uncomment next line
% \documentclass[submission, Math]{SciPost}



% Prevent all line breaks in inline equations.
\binoppenalty=10000
\relpenalty=10000

\hypersetup{
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}

\usepackage[bitstream-charter]{mathdesign}
\urlstyle{sf}

% Fix \cal and \mathcal characters look (so it's not the same as \mathscr)
\DeclareSymbolFont{usualmathcal}{OMS}{cmsy}{m}{n}
\DeclareSymbolFontAlphabet{\mathcal}{usualmathcal}


%%%%%%% Our added libraries and definitions 

\usepackage[utf8]{inputenc}

\setlength {\marginparwidth }{2cm} 
\usepackage{todonotes}
\newcommand{\toall}[1]{\todo[inline,color=purple!20!white]{\textbf{To All:} #1}}

\usepackage{amsmath}        % extensions for typesetting of math
%\usepackage{amsfonts}       % math fonts
\usepackage{amsthm}         % theorems, definitions, etc.
%\usepackage{bbding}         % various symbols (squares, asterisks, scissors, ...)
\usepackage{bm}             % boldface symbols (\bm)
\usepackage{graphicx}       % embedding of pictures
%\usepackage{fancyvrb}       % improved verbatim environment
%\usepackage{dcolumn}        % improved alignment of table columns
\usepackage{booktabs}       % improved horizontal lines in tables
%\usepackage{paralist}       % improved enumerate and itemize


\usepackage{bm}             % boldface symbols (\bm)
%%%%%%% MY PACKAGES
\usepackage{xcolor}
\usepackage{slashed,physics,braket} %fyzika
\usepackage[version=4]{mhchem}
%\usepackage{gnuplot-lua-tikz}
%\usepackage{tikz}
%\usetikzlibrary{shapes, calc, shapes, arrows, positioning}
%\usepackage{mathtools}
%\usepackage{cite}
%\usepackage{lscape, threeparttable, multirow, longtable} 
% table in the appendix

%%%%%% MY MACROS
\newcommand{\im}[0]{\text{i}}
\newcommand{\eu}{\text{e}}
\renewcommand{\d}{\text{d}}
\newcommand{\vect}[1]{\bm{#1}} %3-vektor
\newcommand{\mat}[1]{{\bf{#1}}} %matice
\newcommand{\ha}[1]{\hat{#1}} %operátor %\mathsf
\newcommand{\have}[1]{\hat{\boldsymbol{#1}}} %vektorový operátor
\newcommand{\hect}[1]{{{\hat{\bm{#1}}}}} %vektor & operátor
\newcommand{\psiw}{\psi_{\vect{\theta}}} %variational wave function
\newcommand{\statAver}[1]{\left\langle \left\langle #1 \right\rangle\right\rangle}
\newcommand{\loc}{\text{loc}}

\newcommand{\Omicron}{\mathcal{O}}
\newcommand{\DS}{{\text{DS}}}
\newcommand{\PS}{{\text{PS}}}
\newcommand{\SL}{{\text{SL}}}
\newcommand{\AF}{{\text{AF}}}
\newcommand{\MSR}{{\text{MSR}}}
\newcommand{\ord}[1]{\abs{#1}}

\begin{document}

% TODO: write your article's title here.
% The article title is centered, Large boldface, and should fit in two lines
\begin{center}{\Large \textbf{
Neural Network Quantum States Analysis of the Shastry-Sutherland Model\\
}}\end{center}

% TODO: write the author list here. Use first name (+ other initials) + surname format.
% Separate subsequent authors by a comma, omit comma and use "and" for the last author.
% Mark the corresponding author with a superscript star.
\begin{center}
Mat\v{e}j Mezera\textsuperscript{1,2},
Jana Men\v{s}\'ikov\'a\textsuperscript{3,4},
Pavel Bal\'a\v{z}\textsuperscript{3$\dagger$},
Martin \v{Z}onda\textsuperscript{1$\star$}
\end{center}

% TODO: write all affiliations here.
% Format: institute, city, country
\begin{center}
{\bf 1} Department of Condensed Matter Physics, Faculty of Mathematics and Physics, Charles University, Ke Karlovu 5, Praha 2 CZ-121 16, Czech Republic
\\
{\bf 2} Department of Mathematics and Computer Science, Freie Universität Berlin, Arnimallee 12, 14195 Berlin, Germany
\\

{\bf 3} FZU -- Institute of Physics of the Czech Academy of Sciences, Na Slovance 1999/2, 182 21 Prague 8, Czech Republic 
\\
{\bf 4} Institute of Theoretical Physics, Faculty of Mathematics and Physics, Charles University, V Hole\v{s}ovi\v{c}k\'ach 747/2, 180 00 Praha 8, Czech Republic

% TODO: provide email address of corresponding author
${}^\dagger$ {\small \sf balaz@fzu.cz\\}
${}^\star$ {\small \sf martin.zonda@matfyz.cuni.cz}
\end{center}

\begin{center}
\today
\end{center}

% For convenience during refereeing (optional),
% you can turn on line numbers by uncommenting the next line:
%\linenumbers
% You should run LaTeX twice in order for the line numbers to appear.

\section*{Abstract}
{\bf
We utilize neural network quantum states (NQS) to investigate the ground state properties of the Heisenberg model on a Shastry-Sutherland lattice using the variational Monte Carlo method. We show that already relatively simple NQSs can be used to approximate the ground state of this model in its different phases and regimes. We first compare several types of NQSs with each other on small lattices and benchmark their variational energies against the exact diagonalization results. We argue that when precision, generality, and computational costs are taken into account, a good choice for addressing larger systems is a shallow restricted Boltzmann machine NQS.  We then show that such NQS can describe the main phases of the model in zero magnetic field. Moreover, NQS based on a restricted Boltzmann machine correctly describes the intriguing plateaus forming in magnetization of the model as a function of increasing magnetic field.   
}


% TODO: include a table of contents (optional)
% Guideline: if your paper is longer that 6 pages, include a TOC
% To remove the TOC, simply cut the following block
\vspace{10pt}
\noindent\rule{\textwidth}{1pt}
\tableofcontents\thispagestyle{fancy}
\noindent\rule{\textwidth}{1pt}
\vspace{10pt}


\section{Introduction}
\label{sec:intro}

The neural network quantum states (NQSs)~\cite{carleo2017_solving,carleo2018_constructing,cai2018_approximating,glasser2018neural,chooSymmetriesManyBodyExcitations2018,jia2019quantum,misawa2019mvmc,buffoni2020_new,vicentini2022_netket,schatzle2023deepQMC} have recently emerged as a promising alternative to common trial states in variational Monte Carlo (VMC) studies of quantum many-body problems, especially lattice spin models. This research is driven by the fact that neural networks (NNs) are universal function approximators~\cite{hornik1989_multilayer} as well as by the astonishing progress in the field of machine learning (ML) in general. These advancements already led to a number of effective ML applications suitable for the basic research of quantum systems and technologies~\cite{torlai2018neural,carleo2019_machine,schutt2020machine,dawid2022quantum}. 
For example, even simple NQSs, such as the restricted Boltzmann machine (RBM), allow us to investigate the ground-state properties of various quantum spin models. It was already shown that RBM can outperform standard trial states in the variational search of the ground-state energies of the antiferromagnetic Heisenberg model~\cite{carleo2017_solving}. Very promising results have also been obtained for frustrated spin systems, such as the $J_1-J_2$ model~\cite{choo2019_twodimensional,ferrari2019neural,szabo2020_neural,viteritti2022accuracy}. Here NQSs can be trained to capture the nontrivial sign structure of the ground state and in some cases have even achieved state-of-the-art accuracy~\cite{nomura2021dirac} that delivers cutting edge results. Nevertheless, two-dimensional frustrated quantum spin models continue to be a challenge for NQSs as well as for other methods~\cite{Wu2023variotional}. For example, it is not clear yet how to choose an optimal neural network architecture for a particular frustrated system, how important is the role of the trial state symmetries in the learning process, or if an NQS with favorable variational energy also encodes a physically correct state.  

Not all of these issues are specific to NQSs. Results of any VMC calculations are dictated to a large extent by the properties and limitations of the trial states used. An inappropriately chosen variational state, that is, one with a small overlap with the ground state, can still give a good estimate of the ground-state energy~\cite{gubernatis2016_quantum}. If some additional information is known about the ground state,  e.g., its symmetries, one can pick a more restrictive variational state function. However, this is often not an optimal strategy if the goal is to find new phases or to locate a phase boundary. In principle, NQSs could be a remedy for such problems. It is reasonable to expect that a single, but expressive enough, NQS can be used to approximate distinct phases. This assumption is supported by the results of Sharir et al.~\cite{sharir2021_neural} who showed that NQSs can have even higher expressive power than matrix product states~\cite{DMRG1992} and projected entangled pair states~\cite{MPS2008} as these can be efficiently mapped to a subset of NQSs. In other words, NQSs can
be effectively utilized to a larger class of quantum states than these powerful formalisms which are known primarily from their usage in Density Matrix Renormalization Group (DMRG) but are also utilized as variational states in VMC~\cite{gubernatis2016_quantum,carleo2017_solving,sandvik2007_variational}.

    
In practice, it is not yet clear how to achieve this in a general case. Despite tremendous progress, the research of frustrated quantum spin magnets is still in the stage of testing and developing NQS architectures for simple models, often focusing primarily on reaching the best variational energy in particular regimes~\cite{choo2019_twodimensional,ferrari2019neural,jia2019quantum,viteritti2022accuracy}. In the present work, we aim for a different target. We want to demonstrate that even shallow NQSs can be sufficient for the investigation of qualitatively different ground-state orderings including states forming only in a finite magnetic field. To this goal, we focus on the ground state of antiferromagnetic Heisenberg Hamiltonian on Shastry-Sutherland lattice known as the Shastry-Sutherland model (SSM)~\cite{shastry1981_exact} which we introduce in more detail in Sect.~\ref{sec:SSM}. To our knowledge, this model of frustrated quantum spin system has not been previously addressed within the NQS context, yet it seems to be an ideal testbed for our purposes. 

SSM was already investigated by a number of methods, including exact diagonalization (ED) techniques~\cite{miyagara1999_exact,momoi2000magnetization,koga2000_quantum,nakano2018_third,abendschein2008effective}, quantum Monte Carlo~\cite{wessel2018_thermodynamic}, 
various versions of DMRG~\cite{jaime2012magnetostriction,matsuda2013_magnetization,corboz2013_tensor,corboz2014_crystals,lee2019_signatures,yang2022_quantum}, perturbation theory~\cite{SSplateaus2008,nemec2012microscopic,foltin2014exotic,verkholyak2022_fractional} and even quantum annealing~\cite{kairys2020_simulating}. These studies have shown that SSM has a rich ground-state phase diagram. In a zero magnetic field these include regions such as singlet spin dimer phase, antiferromagnetic Néel state, spin plaquette singlet phase and probably other phases. The introduction of a finite magnetic field further complicates the picture. Consequently, it is challenging to find a single variational function that can correctly approximate the whole ground-state phase diagram.  

In addition, there are still open questions related to the ground-state phase diagram in zero as well as in the finite magnetic field, even in some experimentally relevant regimes of the model. This is important because several magnetic materials have a structure topologically equivalent to SSM. The most notable examples are $\ce{SrCu2(BO3)2}$, $\ce{BaNd2ZnO5}$ and rare earth tetraborides $\ce{RB_4}$ ($\ce{R=Dy}$, $\ce{Er}$, $\ce{Tm}$, $\ce{Tb}$, $\ce{Ho}$)~\cite{kageyama1999exact,onizuka2000_magnetization, siemensmeyer2008_fractional,orendac2021_ground, ishii2021_magnetic,ogunbunmi2021magnetic}. All exhibit an intriguing step-like dependence of the overall magnetization on the external magnetic field, which has been found to be inherent to SSM~\cite{miyahara2003_theory,takigawa2011_magnetization}. Here, each plateau reflects a stable nontrivial spin ordering. The magnetic behavior of these materials is not yet fully understood. This together with other open problems, e.g., the prospect of a narrow spin liquid phase in a zero magnetic field, further motivates the investigation of SSM and its generalizations~\cite{sakurai2018_direct,guo2020_quantum,shi2022_discovery,verkholyak2022_fractional}. 

Therefore, SSM presents a model system that has the right combination of properties that are well understood and can be used to benchmark various NQSs, and of open problems that can be potentially illuminated by these variational techniques. This includes the possibility to address the rather complex behavior of a system in relation to a changing magnetic field.

The present work consists of two main parts. In the first one we explore SSM by employing a number of NQS architectures and we test them against ED results for small lattices in zero magnetic field. Here the primarily goal is to find one or few networks that are able to capture the main well-understood ground-state orderings of SSM. Simultaneously, we require these NQSs to have a high chance to describe the magnetization plateaus as well. This means that the ideal network has to give a solid approximation of the ground-state orderings even when no conditions on the total magnetization are imposed. Consequently, we do not focus on getting the best possible variational energy for a particular set of parameters. Rather, we require a good approximation of the energy in distinct regimes of the model, a correct description of the particular orderings, and reasonable computational complexity that allows the usage of the NQS on larger lattices. We argue that when precision, generality, and computational costs are taken into account, a shallow RBM with complex parameters is still a good choice. 

In the second part, we introduce a refined learning protocol for RBM NQS and test it for a wide range of model parameters and different network sizes. We then utilize this protocol in the study of larger systems. We first investigate the zero magnetic field scenario and demonstrate that RBM is expressive enough to capture all main phases of the system. We then move to the model in a finite magnetic field and show that, with the right learning strategy, RBM is able to capture the magnetization plateaus crucial for the description of real materials. This opens a possibility that NQSs could be used to investigate several open problems, such as the existence of still opaque spin-liquid phase and other orderings predicted but not yet confirmed in SSM. 
   

\section{Shastry-Sutherland model}

\label{sec:SSM}
SSM is described by the Hamiltonian
\begin{align}
	\ha{H}  &=  J \sum\limits_{\langle i,j \rangle} \have{S}_{i}\cdot \have{S}_{j} + J'\sum\limits_{\phantom{{}'}{\langle i,j \rangle'}} \have{S}_{i}\cdot\have{S}_{j} - h\sum\limits_{i} \ha{S}^z_{i},
\end{align}
where $\have{S}_i = \frac{1}{2}\have{\sigma}_i$ is the spin-${1/2}$ operator at the $i$-th site with $\have{\sigma}_i$ being the vector of Pauli matrices. The first term represents the exchange coupling between the nearest neighbors on a square lattice (solid lines in Fig.~\ref{fig01:SS_lattice}). The second term is a sum over specific diagonal bonds arranged in a checkerboard pattern (dashed lines in Fig.~\ref{fig01:SS_lattice}). Note that these sums are interpreted in terms of nodes, i.e., there is no double counting. 
%-----
\begin{figure}[ht]
	\centering
	\includegraphics{fig01.pdf}
	% \includegraphics[width=0.3\textwidth]{fig01.pdf}\hspace{1.0cm}	
	\caption{(a) The Shastry-Sut\-her\-land lattice. Bonds with coupling strength $J$ are represented by solid lines, while bonds with $J'$ by dashed ones. The letters A and B divide the "empty" squares into two subsets, which are used to define the plaquette order parameter.  
     }
	\label{fig01:SS_lattice}
\end{figure} 
%------
Both coupling constants are antiferromagnetic ($J, J' > 0$) and we set $J'$ as the unit of energy in the whole paper. The last term describes the influence of the external magnetic field $h$ pointing to the $z$-direction. 

\subsection{Basic properties of the ground state}
The basic structure of the SSM ground state phase diagram is well understood. 
As illustrated in Fig.~\ref{fig02:phd}, the SSM at $h=0$ has at least three distinct ground-state orderings. These are the \emph{dimer singlet} (DS) state for ($J'\gg J$), the \emph{Néel antiferromagnetic} (AF) ordering ($J'\ll J$) and the \emph{plaquette singlet} (PS) state in between. The phase transition from the DS to the PS state is of the first order\cite{koga2000_quantum}, but the nature of the transition from PS to AF is still in debate. The~ED study of Nakano and Sakai~\cite{nakano2018_third} suggests that the supposed PS phase actually consists of at least two distinct phases. In addition, some recent studies argue that there is a so-called \emph{deconfined quantum critical point} (DQCP),
which separates a line of first-order transitions or, potentially, a  narrow gapless \emph{spin liquid} (SL) phase~\cite{lee2019_signatures,yang2022_quantum,keles2022_rise}. 

Nevertheless, even without focusing on the possible DQCP and SL phase, the three main orderings, namely DS, PS, and AF, already pose a sufficient challenge for a single variational state because of their distinctive character and symmetries.

\begin{figure}[!ht]
	\centering
	\includegraphics{fig02.pdf}\hspace{1.0cm}	
	\caption{Illustration of the SSM phase diagram for small $h$ based on the results from Ref. ~\cite{yang2022_quantum}. There is a first-order transition at $J/J' \approx 0.675$ between DS and PS phases. The gray squares in PS depict the plaquette singlets. The nature of the transition between the PS and AF phases remains unresolved. It is not clear whether there is a narrow spin liquid phase, a DQCP or just a second order transition in the region labeled with a question mark.}
	\label{fig02:phd}
\end{figure} 

The \emph{\textbf{DS phase}} is formed by an exactly (analytically) accessible state \cite{shastry1981_exact}. Numerous analytical and numerical methods have verified that it remains the ground state up to $J/J' \approx 0.675$~\cite{koga2000_quantum,lee2019_signatures,nakano2018_third}. In the limiting case of $J\ll J'$, the system is equivalent to an ensemble of independent spin dimers, each of which forms a singlet ground state.  The DS ground state is thus a direct product of dimer singlet states
\begin{align}
	\ket{\psi}_{\DS} = \bigotimes\limits_{\phantom{{}'}{\langle i,j \rangle'}} \frac{1}{\sqrt{2}}\left(\ket{\uparrow \downarrow}_{i,j} - \ket{\downarrow\uparrow}_{i,j}\right)\,.\label{eq01:DS_ground}
\end{align} 
As such, it is antisymmetric with respect to the exchange of two intradimer spins and symmetric with respect to transformations rearranging only the spin pairs without swapping the intradimer spins. The energy of the ground state of the dimer is
\begin{align}
	E_{\rm DS} = -\frac{3}{4}J'N_{\rm D}\,,\label{eq01:DS_asymp}
\end{align}
where $N_{\rm D}$ is the number of dimers and $N_{\rm D}=N/2$ for lattice with periodic boundary conditions.

The \emph{\textbf{PS phase}} can be understood as weakly coupled plaquette singlet states illustrated in Fig.~\ref{fig02:phd}. Plaquette singlet is a ground state of an isolated 4-spin Heisenberg cluster with four bonds arranged in a cycle~\cite{koga2000_quantum}. The pattern of the plaquette singlets in Fig.~\ref{fig02:phd} indicates that the PS state is two-fold degenerate. 

It is important to stress again that the relevant range $J/J'$ discussed here ($0.675 \lesssim J/J'$ $\lesssim 0.82$) could be much more complex. As mentioned above, it has been argued that at $J/J'\approx 0.70$ the PS phase splits into two distinct regions with quantitatively different behaviors~\cite{nakano2018_third,lee2019_signatures,yang2022_quantum,keles2022_rise}. For the sake of simplicity, we omit this possibility in most of our discussion. Nevertheless, this might be important for more detailed future studies.

The \emph{\textbf{AF phase}} stabilizes when $J/J'\gtrsim 0.82$. When $J'$ becomes negligible, the ground state of SSM is approaching the ground state of the antiferromagnetic Heisenberg model with only nearest-neighbor bonds on a square lattice. Although this state is not analytically accessible, it has previously been explored by Monte Carlo (MC) simulations~\cite{miyagara1999_exact}. Using the first-order correction to these quantum MC results, the energy of the SSM in the AF phase was estimated~\cite{miyagara1999_exact} to be
\begin{align}
	E_{\text{AF}} = (0.102J'-0.669J)N\,\label{eq01:AF_asymp}
\end{align}
where $N$ is assumed to be large. 

A more detailed discussion of the symmetries of these three states is postponed to the Appendix~\ref{app:Symmetries}. Note that the three main phases DS, PS, and AF are reasonably understood, and simultaneously, they differ qualitatively. 
This is one of several qualities of the model that make the SSM a suitable testbed for NQSs.

So far we have discussed the $h=0$ case. When we introduce a finite magnetic field to the DS phase in Eq.~\eqref{eq01:DS_ground}, some dimers can morph into triplet states. These triplets are formed in repeating patterns, e.g., checkerboard, stripes, or more complex configurations (for illustration, see Fig.~\ref{fig01:plateaux}), giving rise to stable plateaus of constant magnetization in increasing magnetic field.
\begin{figure}[ht]\centering
        \includegraphics{fig03.pdf}
	\caption{A simplified illustration of magnetization as a function of the external magnetic field $h$ and coupling constant $J$ inspired by Ref.~\cite{SSplateaus2008}. A more detailed illustration would contain additional steps (e.g., supersolid phase); however, their actual position and width are not clear yet. Singlet and triplet arrangements are displayed for some of the plateaus (namely, $m^z=1,1/2,1/3$ and $1/4$ plateaus are shown).}
	\label{fig01:plateaux}
\end{figure}

Because each plateau signals a distinct stable ordering, it also presents a challenge for the NQSs. Particularly so because a finite magnetic field does not allow for a simple restriction of the Hilbert space to its zero magnetization part. This restriction was heavily utilized in previous NQS investigations of quantum spin models. 
Note that it is mostly these plateaus that make SSM interesting experimentally. Good examples are $\ce{SrCu2(BO3)2}$, $\ce{BaNd2ZnO5}$, $\ce{$\ce{CaCo_2Al_8}$}$ and rare-earth tetraborides $\ce{RB_4}$ ($\ce{R=Dy}$, $\ce{Er}$, $\ce{Tm}$, $\ce{Tb}$, $\ce{Ho}$))~\cite{kageyama1999exact,onizuka2000_magnetization, siemensmeyer2008_fractional,orendac2021_ground, ishii2021_magnetic,ogunbunmi2021magnetic} which all exhibit the intriguing step-like dependence of the overall magnetization on the external magnetic field or show magnetic frustration and can be modeled by SSM or its generalizations. 



\section{Methods}
\label{sec:Methods}

\subsection{Variational Monte Carlo and machine learning}
\label{sec:VMC}
VMC is a standard method that allows us to stochastically evaluate the expectation values of quantum operators without the need to probe the full Hilbert space. Suppose $\ha{H}$ is a fixed Hamiltonian operator and $\ket{\psiw}$ is a trial wave function that depends continuously on a set of parameters $\vect{\theta}$.
VMC searches for a ground state of $\ha{H}$ or its approximation in a variational way. The goal is to minimize the variational energy
\begin{align}
	E_{\vect{\theta}} = \braket{\ha{H}}_{\vect{\theta}} :=\frac{\braket{\psiw | \ha{H} | \psiw}}{\braket{\psiw | \psiw}} \geq E_0 
	\label{eq02:varE}
\end{align}
with respect to the vector of parameters $\vect{\theta}$, where $E_0$ is the true ground-state energy providing the lower energy bound. We utilize a fixed orthonormal basis $\left\{\ket{\vect{\sigma}^z}\right\}$ of the $z$-projected $\frac{1}{2}$-spins and use the following notation 
\begin{align}
	\ket{\psiw} = \sum\limits_{\vect{\sigma}^z} \psiw(\vect{\sigma}^z) \ket{\vect{\sigma}^z},\text{ where } \braket{\vect{\sigma}^z | \psiw} \equiv \psiw(\vect{\sigma}^z)
\end{align} 
as is typical in NQS studies~\cite{carleo2019_netket}. The variational energy in Eq.~\eqref{eq02:varE} is, in the jargon of ML, a \emph{loss function}. Using this loss function, the parameters $\vect{\theta}$ are optimized to obtain the lowest energy state that the chosen variational function can represent. In our calculations, we use the VMC implementation from the NetKet NQS toolbox~\cite{carleo2019_netket,vicentini2022_netket}. 

In general, the form of the trial wave function $\psiw(\vect{\sigma}^z)$ restricts the optimization process to a subset of the Hilbert space. An improper choice of the ansatz can bias the approximation towards a wrong phase or even can make the approach to the correct state impossible. Clearly, this is where one can expect that NQSs could outperform standard variational states due to their high expressiveness.  


\subsection{Neural network quantum states}

Here, we explore several NQS architectures~\cite{jia2019quantum,vicentini2022_netket}. We chose these particular networks due to their successful application in previous studies of other Heisenberg models. 

\emph{\textbf{Restricted Boltzmann machine (RBM)}} is a generative artificial NN constituted of a visible layer with $N$ nodes (one for each lattice site) fully connected with a single hidden layer with $M=\alpha N$ nodes (hidden degrees of freedom) where $\alpha$ is the \emph{hidden layer density}~\cite{carleo2017_solving}. It can be used to define an NQS 
\begin{align}
	\log \psiw(\vect{\sigma}^z) &= \sum\limits_i \sigma^z_i a_i +  \sum_j \log \left[ 2\cosh(\sum_i W_{ij}\sigma^z_i + b_j)\right]\,,
	\label{eq:RBM}
\end{align}
where the vector $\vect{\theta}$ contains the variation network parameters $\vect{\theta} = \{\vect{a},\vect{b},\mat{W}\}$. This NQS can be interpreted as a one-layered fully-connected neural network with $\log \cosh$ activation function followed by a summation of the outputs and additional summation of visible biases~\cite{carleo2017_solving}. Note that complex-valued parameters are necessary in order to represent generally complex-valued wave function outputs.

The size of the visible layer $N$ is fixed by the size of the investigated spin system. However, the expressive power of RBM can be modified by changing $\alpha$. The number of variation parameters of RBM is $\Omicron(\alpha N^2)$.
%According to the universal approximation theorem~\cite{universal_approx1989}, the RBM is theoretically capable of expressing any wave function to any desired degree of accuracy when $\alpha$ can be arbitrarily large. In practice, we aim for a reasonably small $\alpha$ to restrict the total number of RBM variation parameters, which is $MN + M + N = \Omicron(\alpha N^2)$.

\emph{\textbf{Modulus-phase split real-valued RBM (rRBM):}}\label{sec03:RBMModPhase}
Complex parameters, which generally make the learning process harder, can be avoided by introducing two independent real-valued NNs~\cite{torlai2018_neural, szabo2020_neural} to represent the modulus $A(\vect{\sigma}^z)$ and the phase  $\Phi(\vect{\sigma}^z)$ of the wave function separately
\begin{align}
	\log \psiw (\vect{\sigma}^z) = A(\vect{\sigma}^z) + \im \Phi(\vect{\sigma}^z). \label{eq03:RBMModPhase}
\end{align}
Unlike in the Ref.~\cite{torlai2018_neural} where rRBM architecture proved to be advantageous in the investigation of transverse-field Ising model, we have experienced that for SSM, the rRBM shows worse results than complex-valued RBM. This is in accord with the recent study of other frustrated systems, namely the $J_1-J_2$ model~\cite{viteritti2022accuracy}. Consequently, we discuss the results of this network only briefly in Chapter~\ref{chap04:results} and focus predominately on complex-valued architectures. 


\emph{\textbf{Symmetric variant of RBM (sRBM):}} \label{ssec03:RBMSymm} Carleo and Troyer~\cite{carleo2017_solving} used translational symmetries to reduce the number of variational parameters in RBM. They replaced the fully connected layer with a convolutional layer and set the visible biases to the constant value $a^f$ across each convolutional filter $f$. The resulting expression for its output is
\begin{flalign}
	\log \psiw(\vect{\sigma}^z) = \sum_{f=1}^F \sum_{g\in G} \Bigg\{\! a^f \underbrace{\sum\limits_{i=1}^{N} T_g( \vect{\sigma}^z)_i}_{\quad\sum\limits_i^N \sigma^z_i = m^z} +  \log\left[2\cosh(\sum_{i=1}^N w_i^f T_g(\vect{\sigma}^z)_i + b^f)\!\right]\!\!\Bigg\}\,. \label{eq03:RBMSymm}
\end{flalign}
Here $\vect{T}_g$ denotes a symmetry transformation of a spin configuration according to an element $g$ from the symmetry group $G$ of order $\ord{G}$. The index $f$ denotes different feature filters. The number of these filters $F$ determines the size of the network $M = F \abs{G}$. The resulting sRBM has fewer variational parameters than the RBM  by a factor of $\ord{G}$. We can view this approach as binding the values of some of the $\Omicron(\alpha N^2)$ parameter making the total asymptotic number of parameters $\Omicron\left(\alpha N\right)$. Carleo and Troyer~\cite{carleo2017_solving} also showed that this approach significantly improves the convergence and accuracy of the ground states of the antiferromagnetic Heisenberg model on a square lattice. However, this approach suffers from two crucial disadvantages in more general circumstances. The first drawback is that visible biases are inherently constant for each filter $f$ which significantly lowers the expressiveness of the network as discussed later in this section. As we show in Appendix~\ref{app:sRBM}, the sRBM architecture cannot be modified to ease this condition while preserving symmetries. The second drawback is that sRBM is not applicable if the ground state does not transform under the trivial irreducible representation (irrep) of a given symmetry group.

To illustrate the problem, let us consider
a single spin dimer (i.e., a single bond of SSM with $J=0$,  $J'=1$ and $h=0$). Its ground state is a singlet $\ket{\psi_0} = \left(\ket{\uparrow\downarrow} - \ket{\uparrow \downarrow}\right)/\sqrt{2}$.
The symmetry group of the single-dimer Hamiltonian contains just two operations -- an identity and a swap of both spins $G = \left\{ g_{12}, g_{21} \right\}$. If we apply the swap operation to the ground state, we obtain $\have{T}_{g_{21}} \ket{\psi_0} = \left(\ket{\downarrow\uparrow} - \ket{\downarrow\uparrow}\right)/\sqrt{2} = -\ket{\psi_0}$.
Although this state is a multiple of the ground state, we see that it does not transform under the trivial irrep because one of its characters is $\chi_{g_{21}} = -1$. Since sRBM represents only states with $\forall g\in G: \have{T}_{g} \ket{\psi} = \ket{\psi}$, this symmetry should not be used in sRBM. Note that we do not strictly follow this rule and sometimes use all available lattice symmetries. The reason is that this leads to NQS with a small number of parameters that are easy to optimize. The resulting variational energy can then be compared with the energy obtained with RBM with the same $\alpha$ to check how well the full network is optimized, i.e., if it leads to lower energy than sRBM. If not, this signals that the variational energy of RBM can be lowered by better learning.      


\emph{\textbf{Projected RBM (pRBM)}:} Recently, Nomura~\cite{nomura2021_helping} introduced an alternative way to symmetrize RBM (or any other NN) using a quantum-number projection (also called \emph{incomplete symmetrization operator})
\begin{align}
	\psi_{\vect{\theta}}^{G}(\vect{\sigma}^z) = \sum_{g\in G} \chi_{g^{-1}} \psi_{\theta}(\vect{T}_{g}(\vect{\sigma}^z)) \,,\label{eq03:symmetrizedRBM}
\end{align}
{\sloppy
where $g$ is an element of the given symmetry group $G$ and $\chi_g$ is its character from the irrep in question. The wave function on the right-hand side may be arbitrary and it can be shown that the function on the left-hand side satisfies the desired transformation property $\psi_{\vect{\theta}}^G(\vect{T}_g(\vect{\sigma}^z)) = \chi_g\psi_{\vect{\theta}}^G(\vect{\sigma}^z)$ in case of one-dimensional representation
or $\psi_{\vect{\theta},a}^G(\vect{T}_g(\vect{\sigma}^z)) = \sum_{b=1}^d D(g)_{b}^{a}\psi_{\vect{\theta},b}^G(\vect{\sigma}^z)$ for more-dimensional irreps, where functions $\psi_{\vect{\theta},a}^G$ form a basis of $d$-dimensional irrep $D(g)_{b}^{a}$.
Unfortunately, pRBM makes the learning process of NN much more expensive than sRBM. The computational time increases by a factor of $\ord{G}$ producing a computational cost $\Omicron(\alpha N^2 \abs{G})$. 
On the other hand, pRBM implementation does not suffer from the problems mentioned for sRBM
and it can be generalized by setting mutually independent visible biases (see Appendix~\ref{app:sRBM}).

}
\emph{\textbf{Group-convolutional NN (GCNN)}}\label{sec03:GCNN}: Group equivariant convolutional NNs represent a pro\-mis\-ing class of NNs built inherently on symmetries. They were proposed by Cohen and Ni~\cite{GCNN_original} as a natural extension of the well-known convolutional neural networks. While convolutional networks preserve invariance under translations, GCNN are equivariant under the action of an arbitrary group $G$ (which may contain a subgroup of translations). Roth and MacDonald~\cite{GCNN_physics} further improved GCNNs so that they can transform under an arbitrary irreducible representation of $G$, which is more suitable for NQSs for SSM. GCNN can be composed of any number of hidden layers. The first and subsequent layers are given by
\begin{align}
	\vect{f}^1_g &= \vect{f}\left(\sum\limits_{i=1}^N \vect{W}^0_{g^{-1}i} \sigma^z_i + \vect{b}^0 \right),\hspace{0.3cm} 
	\vect{f}^{k+1}_g = \vect{f}\left(\sum\limits_{h\in G} \vect{W}^k_{g^{-1}h}\vect{f}^k_{h} + \vect{b}^k\right)\,,
	\label{eq03:GCNN_1}
\end{align}
where $\vect{f}$ is a nonlinear activation function (the output is typically a vector since GCNN can have multiple parallel feature filters) and $\vect{f}^1_g$ is a 1st-layer feature vector corresponding to group element $g$.
The result of the last layer $\vect{f}^K_g = f^{(j)K}_g$, where $(j)$ denotes the individual features of the layer, is then projected in a fashion similar to that of pRBM
\begin{align}
	\psi(\vect{\sigma}^z) = \sum\limits_{g\in G}  \sum_{j}  \chi_{g^{-1}} \exp(f^{(j)K}_g)\,.
\end{align}
The main advantage over symmetrizing an arbitrary deep network by the formula form Eq.~\eqref{eq03:symmetrizedRBM} is that we do not need to evaluate the forward pass of the nonsymmetric wave function $\ord{G}$ times. This is achieved because each layer of the GCNN fulfills \emph{equivariance}. GCNN with $K$ layers and a typical number of feature filters $F$ in each layer has $\Omicron(F N + K F^2 |G|)$ parameters. 

\emph{\textbf{Jastrow network:}} As a baseline, we also use a Jastrow network based on the standard Jastrow ansatz~\cite{jastrow1955,VMC2017}
\begin{align}
	\psiw = \exp\left({\sum\limits_{i,j} \vect{\sigma}^z_i W_{i,j} \vect{\sigma}^z_j}\right)\,,\label{eq02:Jastrow}
\end{align}
where the variational parameters $\vect{\theta} = \left\{W_{i,j}\right\}$ form a matrix of size $N\times N$. The Jastrow ansatz is physically motivated by two-body interactions and assigns trainable parameters $W_{i,j}$ to pairwise spin correlations. The number of its parameters scales as $\Omicron(N^2)$.

\paragraph{}
The complicated sign structure of the complex phases of the basis coefficients that form the ground-state wave function presents a major challenge in optimizing the parameters of a variational function of a frustrated spin system. In case of Heisenberg model on a bipartite lattice consisting of sublattices $\mathcal{A}$ and $\mathcal{B}$ (i.e., SSM with $J'=0$), this can be solved using the Marshal sign rule (MSR)~\cite{Marshall1955}. The MSR states that the sign of $\psi(\sigma^z)$ is given by $(-1)^{N^{\uparrow}_\mathcal{A}(\sigma^z)}$ where $N^{\uparrow}_\mathcal{A}(\sigma^z)$ is the total number of up-spins on a sublattice $\mathcal{A}$. Because this alternates with a spin-flip, it can be difficult for NN to learn the correct signs. However, it is possible to circumvent this problem in two analogous ways.

If the sign structure is dictated by MSR, the Hamiltonian can be gauge transformed by changing the signs of some terms to make all wave function coefficients positive in the transformed basis. In particular, we change $\forall \sigma \in \mathcal{A}: \sigma^x\rightarrow -\sigma^x \text{ and } \sigma^y\rightarrow -\sigma^y$. The same result can be also obtained by setting the visible biases to $a_i = \text{i}\pi/2$ for $i\in \mathcal{A}$ and $a_i = 0$ for $i\in \mathcal{B}$ as this exactly reconstructs the Marshall sign factor (up to an overall constant factor). 
In other words, the biases can be set to play the role of a Marshall basis. What is important here is that in the general case the simple Marshall sign rule is not always applicable. Especially problematic are systems with strong frustration~\cite{szabo2020_neural,liang2021_hybrid,viteritti2022accuracy}. 
The advantage of using the visible biases instead is that their setting does not have to be known ahead, as it can be, despite possible technical difficulties, learned. 
Therefore, it is beneficial to include visible biases whenever allowed by the architecture. An additional bonus is that free visible biases also allow one to overcome an improper initialization of weights. 

%---------------------------------------------
\section{Results}
\subsection{Comparison of different NQSs architectures}\label{chap04:results}

It is too expensive to apply all NQSs introduced above to investigate the ground-state phase diagram of SSM at large lattices. Therefore, in the first part of our investigation, we benchmark these NQSs against the exact results on smaller lattices 
obtained by the Lanczos ED method. The aim is to identify a network that is both expressive enough to cover various phases and computationally tractable even for large lattices. We focus on a regular lattice with $N=4\times 4=16$ points and an irregular lattice with $N=20$ (see Appendix~\ref{ses:App_tiles}). 
Throughout this paper, we apply periodic boundary conditions for all lattices used, unless explicitly stated otherwise. The irregular $N=20$ is considered because $N=16$ lattice has some undesirable properties,  e.g., some extra symmetries with trivial irrep which favor symmetric networks. It also suffers from stronger finite-size effects and does not exhibit the PS phase. On the other hand, it is regular and easy to calculate.

We initially focus on the cases represented by $J/J'=0.2$ (DS phase), $J/J'=0.9$ (AF phase), and $J/J'=0.63$. Case $J/J'=0.63$ was chosen because it represents a realistic case, namely, it is the exchange parameter ratio for $\ce{SrCu2(BO3)2}$ at ambient pressure~\cite{matsuda2013_magnetization}. However, because its results are qualitatively in agreement with the case $J/J'=0.2$, we discuss them together as the DS results. Note that we investigate the model with and without MSR. Since the goal here is to compare different networks, we estimate the accuracy of each architecture by comparing the average energy of the last 50 learning iterations $E_{50}$ with the exact result $E_{\textrm{ex}}$. Note that this means that we are not using just the lowest obtained energies but also test stability of the learning method. Consequently, the value of $E_{50}$ is typically greater than zero even when the network is able to reproduce the state exactly. The same computational protocol is used for each architecture. In particular, we used 2000 MC samples\footnote{For $N=16$, exact samples were used. For details, see ExactSampler in \cite{vicentini2022_netket}.} and 1000 training iterations for three values of fixed learning rates ($0.2, 0.05, 0.01$). Each particular combination of architecture and basis (MSR or direct) was computed four times for each learning rate (yielding 12 independent runs for each case of interest). This is to eliminate occasional events when NN gets stuck in a local energy minimum too far from the ground state. Zero magnetization was not implicitly assumed (i.e., we used local single-spin-flip Metropolis updates in VMC). We summarize our results in Table~\ref{tab04:4x4benchmarks} where the values are $\min \limits_{i} \frac{\abs{{E}_{50}^i - E_{\text{ex}}}}{E_{\text{ex}}}$, with $i$ enumerating the twelve independent runs.

\addtolength{\tabcolsep}{-2pt} 
\begin{table}[th]
	\centering
	\begin{tabular}{lr|ll|c|ll}
		\toprule
		\multicolumn{2}{c}{$N=4\times 4$} & \multicolumn{2}{|c|}{$J/J'=0.2$ (DS)}                  & \multicolumn{1}{c|}{$J/J'=0.63$}                & \multicolumn{2}{c}{$J/J'=0.9$ (AF)}                  \\
		\multicolumn{1}{l}{architecture}  &  \multicolumn{1}{c}{params}  & \multicolumn{1}{|c}{direct} & \multicolumn{1}{c|}{MSR} & \multicolumn{1}{c|}{direct} & \multicolumn{1}{c}{direct} & \multicolumn{1}{c}{MSR} \\\midrule
		Jastrow               & 256       & $5.8{\times}10^{-5}$        & $1.1{\times}10^{-5}$     & $6.3{\times}10^{-6}$  & $6.2{\times}10^{-2}$       & $2.1{\times}10^{-2}$    \\
		RBM ($\alpha = 2$)    & 560       & $1.9{\times}10^{-5}$        & $1.6{\times}10^{-5}$     & $1.7{\times}10^{-5}$                          & $4.7{\times}10^{-3}$       & $5.1{\times}10^{-3}$    \\
		RBM ($\alpha = 16$)   & 4368      & $2.8{\times}10^{-5}$        & $1.4{\times}10^{-5}$     & $1.9{\times}10^{-5}$                         & $1.6{\times}10^{-3}$       & $1.1{\times}10^{-3}$    \\
		rRBM ($\alpha = 2$)   & 1088      & $2.3{\times}10^{-4}$        & $2.1{\times}10^{-4}$     & $5.2{\times}10^{-5}$                        & $8.3{\times}10^{-3}$       & $7.9{\times}10^{-3}$    \\
		rRBM  ($\alpha = 8$)  & 4352      & $2.3{\times}10^{-4}$        & $2.2{\times}10^{-4}$     & $1.1{\times}10^{-5}$                        & $9.3{\times}10^{-3}$       & $7.8{\times}10^{-3}$    \\
		sRBM ($\alpha = 4$)   & 18        & $0.0$                       & $0.0$                    & $3.8{\times}10^{-6}$                        & $4.8\times10^{-3}$         & $2.5\times 10^{-3}$     \\
		sRBM ($\alpha = 16$)  & 69        & $0.0$                       & $0.0$                    & $2.7{\times}10^{-6}$                        & $8.9{\times}10^{-4}$       & $3.8{\times}10^{-4}$    \\
		sRBM ($\alpha = 128$) & 545       & $0.0 $                      & $0.0$                    & $4.9{\times}10^{-6}$                       & $1.3{\times}10^{-3}$       & $8.5{\times}10^{-5}$    \\
		pRBM ($\alpha = 0.5$) & 136       & $7.9{\times}10^{-5}$        & $1.2{\times}10^{-4}$     & $6.9{\times}10^{-5}$                       & $1.5{\times}10^{-3}$       & $8.5{\times}10^{-4}$    \\
		pRBM  ($\alpha = 2$)  & 544       & $9.1{\times}10^{-6}$        & $2.2{\times}10^{-5}$     & $6.5{\times}10^{-6}$                       & $7.1{\times}10^{-5}$       & $2.0{\times}10^{-5}$    \\
		GCNN                  & 2188      & $6.2{\times}10^{-6}$        & $3.6{\times}10^{-6}$     & $1.2{\times}10^{-5}$                        & $3.2{\times}10^{-5}$       & $3.6{\times}10^{-5}$    \\
		GCNNt                 & 268       & $4.2{\times}10^{-7}$        & $5.1{\times}10^{-7}$     & $4.0{\times}10^{-7}$              & $4.9{\times}10^{-3}$       & $4.7{\times}10^{-3}$    \\
		\bottomrule
		
	    \toprule
		\multicolumn{2}{c}{$N=20$}        & \multicolumn{2}{|c|}{$J/J'=0.2$ (DS)}                  & \multicolumn{1}{|c|}{$J/J'=0.63$}                & \multicolumn{2}{c}{$J/J'=0.9$ (AF)}                   \\\midrule
		Jastrow               & 400       & $1.1{\times}10^{-5}$        & $1.0{\times}10^{-3}$     & $2.5{\times}10^{-3}$                         & $1.4{\times}10^{-1}$       & $3.0{\times}10^{-2}$     \\
		RBM  ($\alpha=2$)     & 860       & $2.2{\times}10^{-5}$        & $1.4{\times}10^{-5}$     & $7.5{\times}10^{-4}$                         & $6.6{\times}10^{-3}$       & $6.2{\times}10^{-3}$     \\
		RBM  ($\alpha=8$)     & 3380      & $1.2{\times}10^{-5}$        & $1.7{\times}10^{-5}$     & $1.7{\times}10^{-3}$                         & $2.2{\times}10^{-3}$       & $2.1{\times}10^{-3}$     \\
		sRBM  ($\alpha=4$)    & 85	  & $1.2{\times}10^{-1}$        & $1.5{\times}10^{-1}$     & $1.4{\times}10^{-1}$                         &   $5.0{\times}10^{-2}$     & $1.4{\times}10^{-3}$     \\
		pRBM (for AF)   & 336       & $2.3{\times}10^{-1}$        & $2.3{\times}10^{-1}$     & $5.2{\times}10^{-2}$                          & $3.5{\times}10^{-3}$       & $3.0{\times}10^{-3}$     \\
		pRBM (for DS)   & 336       & $7.1{\times}10^{-4}$        & $6.8{\times}10^{-5}$     & $1.2{\times}10^{-3}$                         & $4.4{\times}10^{-2}$       & $4.7{\times}10^{-2}$     \\
		\bottomrule
	\end{tabular}
	\caption{Comparison of the precision (lower is better) of NQS variational results on lattices $N = 16$ and $N = 20$. The listed values were calculated as $\min \limits_{i} \frac{\abs{{E}_{50}^i - E_{\text{ex}}}}{E_{\text{ex}}}$, where ${E}_{50}^i$ is the average energy of the last 50 iterations of the $i$-th run. A number of variational parameters are also shown for each architecture.  The difference between GCNN and GCNNt is that for GCNN we used all the symmetries and the correct characters for the expected ground state, whereas GCNNt utilized only the translation symmetry. The error $0.0$ here means a relative error less than $10^{-7}$ which we consider as a "numerical precision" due to the standard MC errors which are typically larger even for $L=16$.}
	\label{tab04:4x4benchmarks}
\end{table}

There are several results in Table~\ref{tab04:4x4benchmarks} which were important for our decision on which network should be used in the detailed study of the phase diagram in larger lattices. Starting with RBM, one can see that networks with $\alpha = 2$ (560 parameters for $N=16$ and 860 for $N=20$) and $8$ (3380 parameters for $N=20$) and $16$ (4398 parameters for $N=16$) show similar precision, where the significantly larger networks are notably better (approximately three times) only in the AF phase. For the general case, considering the computational costs, this favors the computationally less demanding network with $\alpha =2$. Also interesting is the comparison with the Jastrow network. Both architectures have comparable precision in the DS phase for $N=16$, however, in the AF phase and in the DS phase for $N=20$ with MSR, RBM is one or even two orders of magnitude more precise than the Jastrow ansatz.

For $N=16$, the sRBM architecture demonstrates superior performance. The full automorphism group of the finite lattice has been used in its implementation. Despite the resulting small number of variational parameters, it shows excellent precision. In fact, a significant increase of $\alpha$ is not that advantageous (compare the cases $\alpha=4$ and $\alpha=128$). In the DS phase, the use of symmetries allowed sRBM to find the ground-state energies within the numerical precision (hence the zero error). Since sRBM can be thought of as RBM with additional constraints on the values of the weights, this already suggests that the learning protocol for RBM can be improved, which we demonstrate in the next section. However, it is important to stress that the excellent results are a consequence of the special symmetries of the $N=16$ lattice. Both the DS and AF states transform under the trivial irreducible representation, and the automorphism group is therefore applicable without special treatment. This is not true for the DS ground state in different tiles, including regular ones such as $N=6\times6$ (for a more detailed discussion of the symmetries, see Appendix~\ref{app:Symmetries}). This is illustrated in the second part of Table~\ref{tab04:4x4benchmarks} where sRBM with $\alpha=4$ gives very poor results in the DS phase of $N=20$ due to the improper treatment of symmetries. In short, using symmetries in sRBM for states that do not transform under a trivial irrep can make the variational energy significantly worse than for simple RBM.  
For $N=20$, sRBM also fails in the AF phase, but only when adopting a direct basis. This implies that sRBM has trouble learning the correct sign structure of the state for larger lattices, which can be attributed to the fixed visible biases.  
 
The remaining architectures, namely pRBM and GCNN, show excellent accuracy for $N=16$. They clearly outperform all other networks in the AF phase. 
However, the results at $N=20$ are less convincing, especially when one takes into account that these networks are more computationally demanding than RBM even for cases when RBM contains more parameters.
Furthermore, the precision reached required the usage of correct symmetries of
the expected state, i.e., the proper line form Table~\ref{tab03:point_group} in Appendix~\ref{app:Symmetries}. If one uses an improper one, i.e., if different state is expected, as illustrated by the last two lines in Table~\ref{tab04:4x4benchmarks}, the precision can drop by several orders of magnitude. Similarly, precision decreases significantly for both GCNN and pRBM when we use only the group of translations instead of the full symmetry group, as illustrated by GCNNt in Table~\ref{tab04:4x4benchmarks}. Note that for this case, the precision in the AF phase drops to the level of a simple RBM with $\alpha=2$. The network is much better in the DS phase, but in the following chapter, we will demonstrate that even RBM with $\alpha=2$ and modified learning protocol can reach the numerical precision in this phase. Although we cannot exclude that much better results could be obtained for the symmetrized pRBM and GCNN networks with a different learning protocol, considering their much higher computational demands and the necessity to identify a priori the correct irrep symmetries for each lattice type to make the learning efficient, the presented results favor RBM for the study of larger clusters. 

The last question to be addressed here is whether using MSR would be beneficial. Table~\ref{tab04:4x4benchmarks} shows several cases where MSR is favorable in the AF phase (e.g., for sRBM and $N=16$), but this is not a general rule. In addition, its usage comes with a price as well. We have noticed that the MSR basis seems to strongly favor the AF ordering even for $J/J'$ where PS is already the ground state in exact results. We will discuss this briefly when addressing larger lattices.  
      
To wrap it up, in general, the usage of MSR basis does not lead to significantly better results. With some exceptions, the networks presented here are able to approximate the ground-state energy quite well even without MSR. Therefore, we will mostly omit the MSR from further discussion. Furthermore, if the symmetry of the ground state is known, it is worth using this information in building the NN. If not, then the usage of just translations does not lead to a significant improvement of the precision.  
Fortunately, the complex-valued RBM with visible biases can give a very good approximation of the ground-state energy without any restrictions. Its clear advantage is that no preliminary information about the ground-state properties is needed. As such, it is suitable for problems where the character of the ground state or position of the phase boundary is unknown. In addition, the precision of RBM for SSM can be significantly improved using a different learning strategy discussed in the following section.  

\subsection{Investigation of the ground-state phase diagrams}

Focusing solely on RBM allowed us to test several learning strategies and employ more precise MC calculations. What follows is a description of the best learning protocol we have found, which we used to produce all the results discussed below. It proved to be beneficial to use more precise MC calculations already during training. We typically generate 4000--12000 MC samples at every sampling step. It was also more advantageous to run 10--30 independent learnings (with random initial variational parameters) with shorter learning times than to use few runs with a lot of learning iterations. We used approximately 2000 training iterations in each run. During learning, we have been lowering the learning rate $\eta$ by several discrete steps. Typically, we started with $\eta=0.08$ ($\approx$200 iterations), then changed it to $\eta=0.04$ ($\approx$1600 iterations), followed by $\eta=0.02$ ($\approx$100 iterations), $\eta=0.01$ ($\approx$100 iterations) and $\eta=0.003$ ($\approx$50 iterations). The trained RBM was then used to calculate the expectation values of the energy and order parameters, introduced in the next section, where we used 12--60 thousand evaluation steps. Consequently, the Monte Carlo error bars in all the figures presented are negligible for small lattices. The relevant absolute error comes from the learning process or limitations of the NQS used. The state with the lowest energy (evaluated more precisely after training) of all independent runs was kept as the final result in the following discussion. Due to the stochastic fluctuations in the learned parameters, it was for some cases advantageous to refine the results by fine-tuning the final state multiple times with a high number of MC samples but a small number (5-10) of iterations and a small learning rate ($\eta\leq0.001$) keeping the result with the lowest energy. Moreover, transfer learning was employed in some problematic regimes, as described below.        

\subsubsection{Ground-state orderings}

As already discussed, good agreement of the variational energy with the exact one does not guarantee that the variational state correctly captures the character of the exact ground state, i.e., that it reflects the correct phase. To examine this and with the aim to see if RBM NQS can correctly describe the transitions between the phases, we calculate the order parameters for the three main expected orderings. They are constructed to be large (close to one) whenever the state is in the respective phase and small in other domains.      

In particular, we define the order parameter for the DS phase as  
\begin{align}
	\mathcal{P}_{\DS} = -\frac{4}{3N} \mkern-18mu\sum\limits_{\phantom{{}_{SS}}{\langle i,j \rangle'}} \left\langle \have{S}_i\cdot\have{S}_j\right\rangle\,,
\end{align}
which reflects the fact that operator $\have{S}_1\cdot\have{S}_2$ has for isolated dimer the expectation value $-\frac{3}{4}$~(singlet state). Therefore, $\mathcal{P}_{\DS}$ is one in the DS phase and strictly lower in other phases.

For the PS order parameter, we use a definition based on order parameter from Ref.~\cite{yang2022_quantum}
\begin{align}
	\mathcal{P}_{\PS} = \frac{1}{\bar{N}}\abs{\left\langle\sum_{\vect{r} \in A} \ha{Q}_{\vect{r}} - \sum_{\vect{r} \in B} \ha{Q}_{\vect{r}}\right\rangle}\,,
	\label{eq:mPS}
\end{align}
where the order parameter is given by the difference $\ha{Q}_{\vect{r}} = \frac{1}{2}\left(\ha{P}_{\vect{r}} + \ha{P}_{\vect{r}}^{-1}\right)$, with $\ha{P}_{\vect{r}}$ being the permutation operator. This operator performs a cyclic permutation of four spins on a plaquette (a square on the lattice without the diagonal bond $J'$) at position $\vect{r}$. Here, the first sum in Eq.~\eqref{eq:mPS} runs over the subset of squares A (see Fig.~\ref{fig01:SS_lattice}) and the second sum runs over the subset B. The meaning of this construction can be understood by looking at Fig.~\ref{fig02:phd}. Note that in the investigation of the plaquete ordering we utilized in addition to periodic boundary conditions (torus geometry) also a lattice with mixed ones. For periodic boundary conditions, we have $\bar{N}=N/4$ as all squares are used. For mixed ones, we followed Ref.~\cite{yang2022_quantum} and use regular lattices with open boundary conditions in the $x$-direction with $L_x = 2L$ and periodic in the $y$-direction with $L_y=L$ so that $N=2L^2$. However, the order parameter is calculated only in the central $L\times L$ square to mitigate the boundary effects. Hence, $\bar{N}=L^2/4$. The operator $\ha{Q}_{\vect{r}}$ gives a large mean value in the plaquette singlet (gray square) and a value close to zero in the empty square between four plaquette singlets. For periodic lattices, we do not know which set of squares will become singlets, as the state is degenerate, therefore, we use the absolute value. 

For the AF phase we employ the standard structure factor
\begin{align}
	\mathcal{P}_{\AF} = \frac{1}{N^{2}} \sum_{ij} \eu^{\im \vect{q}\cdot \vect{r}_{ij}} \left\langle\have{S}_i\cdot \have{S}_j\right\rangle\,,
\end{align}
where $\vect{r}_{ij}$ denotes the difference in discrete coordinates of spin $i$ and $j$, and we take $\vect{q} = (\pi,\pi)$ which measures the antiferromagnetic checkerboard ordering.
Finally, in the case of finite magnetic field we use the normalized magnetization in the $z$-direction
\begin{align}
	\mathcal{M} = \frac{2}{N} \sum_{i} \left\langle\have{S}_i^z\right\rangle
\end{align}
to identify the expected plateaus in the magnetization. These expectation values are calculated using VMC for trained RBM NQS.   
 

\subsubsection{Zero magnetic field}

We first investigate the phases of SSM in a zero magnetic field. Unlike the procedure used to compare different network architectures, here we restrict the Hilbert space by the condition $\mathcal{M}=0$. Before moving to larger lattices, we test the RBM for $N=20$ in a wide range of $J/J'$. We use the irregular lattice $N=20$ because it shows an onset of the PS ordering (see the black dashed line in Fig.~\ref{fig:L20h0}(a)) not present for smaller regular lattices. We also readdress the role of the parameter $\alpha$ within the new learning protocol, but start our discussion with the case $\alpha=2$. 
\begin{figure}[!ht]\centering
	\includegraphics[width=0.9\textwidth]{fig04.pdf}
	\caption{Comparison of exact (lines) and various RBM  variational results (symbols) at irregular lattice $N=20$. (a) Evolution of the order parameters. Here blue solid line (ED), pure blue diamonds (RBM with $\alpha=2$) and blue diamonds with red edge (RBM with $\alpha=16$) show the DS order parameter; black dashed line (ED), black circles (RBM with $\alpha=2$) and black circles with yellow edge (RBM with $\alpha=16$) show the PS order parameter; and red dot-dashed line (ED), red crosses (RBM with $\alpha=2$) and red crosses with blue edge (RBM with $\alpha=16$) show the AF order parameter. The results of symmetric variants of RBM are not shown, as they were comparable to the results presented for $J/J' > 0.68$ and well off the exact results for $J/J' \leq 0.68$. (b) The exact (red line) and RBM $\alpha=2,16$ ground-state energies. (c) Relative error in ground-state energy for the RBM with $\alpha=2$ (blue circles), $4$ (red pluses), $8$ (green crosses) and $16$ (black-yellow diamonds). Note that the relative error in the DS phase for RBM $\alpha=2$ is at the level of numerical precision.}
	\label{fig:L20h0}
\end{figure}

As is clear from the comparison of the ground-state energies in panels Fig.~\ref{fig:L20h0}(b) and Fig.~\ref{fig:L20h0}(c), the RBM variational energy agrees very well with the ED. The updated learning protocol ensures that the relative error in the $J/J' < 0.68$ region, i.e., for the DS phase, is of the order of the numerical precision already for $\alpha=2$ despite not using any symmetries except for the condition $\mathcal{M}=0$. The largest error is in the vicinity of the expected first-order phase transition from the DS to PS phases, but only from the side of the expected PS phase. Nevertheless, even here, the largest observed relative error in energy was approximately 1\% for $\alpha=2$.% and much lower for larger $\alpha$s.    

Given the focus of our study, even more important than the energy error is the nature of optimized variational states.  Panel (a) in Fig.~\ref{fig:L20h0} shows that a shallow network, i.e., RBM with complex parameters and $\alpha=2$ is expressive enough to correctly capture the formation of the distinct DS (blue diamonds) and AF ordering (red crosses), as well as the onset of the PS phase (black circles). The agreement is far from perfect, though. Consistent with the results for the energy, the largest differences in order parameter values between RBM and ED are in the right vicinity of the expected phase transition. Here an error of 1\% and less in the estimation of the ground-state energy translates into an error of tens of percents in the order parameters. Still, even here the RBM gives a correct qualitative picture. The position of the abrupt change of phase matches the exact result and there is a clear onset of the PS ordering. With increasing $J/J'$, the RBM results align again with the exact ones.


This benchmark shows that RBM with $\alpha=2$ can easily capture the correct state in the DS phase, but gives worse results above the critical $J/J'\approx 0.68$. What is not clear is if the relative errors in panel (c) represent some inherent limitation of the RBM with small $\alpha$, e.g., a difficulty to set the correct sign structure of the frustrated state, or are related to the learning process. Gradually increasing $\alpha$ from $2$ (blue circles) to $4$ (red pluses), $8$ (green pluses) and $16$ (black diamonds with yellow cores) in the problematic region lowers the relative error in energy. However, this significant improvement in energy leads only to a small improvement for the order parameters near the critical point. This is shown in panel (a) where the results calculated with RBM with $\alpha=16$ are marked with the same symbols as for $\alpha=2$ but highlighted via differently colored edges. 

Using symmetric NQS symmetries did not significantly improve the results. We have tested the sRBM architecture with $\alpha=4$ in direct as well as MSR basis using the same protocol as for RBM. The sRBM results have been comparable to RBM for  $J/J' > 0.68$ and much worse than the RBM results below this critical value. This suggests that the issue is not entirely due to insufficient learning. On the other hand, the learning was the most difficult in the vicinity of the observed discontinuity. A significant fraction (often more than half) of the independent runs for $0.69 \leq J/J' \leq 0.72$ ended either in the wrong phase (DS) or even in a state with an energy much higher than the real ground state. This was not true for the rest of the $J/J'$ interval, where most of the independent runs with the same $\alpha$ showed very similar variational energies. Furthermore, the relative errors for all investigated RBM variants (including those not presented here) follow the same pattern. They are maximal just above the critical point and then, if we neglect some noise, they monotonically decrease with increasing $J/J'$.  Yet, increasing $\alpha$ significantly lowers the variational energy even for $J/J'>0.74$. This again suggests that the problem is indeed small $\alpha$. Ultimately, both statements seem to be correct. Significantly larger $\alpha$ than $\alpha=16$ is needed to capture the critical region together with high-precision learning, that is, many independent runs.        

After testing the RBM on small lattices and understanding its strength and limitations, we can now approach larger ones. We focus on $\alpha=2$ as the increase in the precision of the variational energy obtained with larger $\alpha$'s does not significantly improve the estimates of the order parameters. Although we can not easily compare the VMC results with the exact diagonalization for larger lattices, we can use the exact asymptotic results for the energy in DS Eq.~\eqref{eq01:DS_asymp} and AF phase Eq.~\eqref{eq01:AF_asymp} to guide us. 
\begin{figure}[!ht]\centering
	\includegraphics[width=1.0\textwidth]{fig05.pdf}
	\caption{Evolution of order parameters for DS (a), PS (b),  AF (c) and variational energy (d) as a function of $J/J'$ for $h=0$ and various lattice sizes. All results in panels (a)-(d) have been obtained using RBM NQS with $\alpha=2$ and VMC with exchange updates (simultaneous flip of two opposite spins in the basis state) for the Hilbert subspace restricted to $\mathcal{M} = 0$. The black dashed lines in panels (d) and (e) show the asymptotic energies for the DS (horizontal) and AF phase (tilted). The black crosses represent the results with $N=64$ for which we have utilized transfer learning. The inset (e) shows the details of the variational energy for $N=64$ in the vicinity of the phase transition calculated using RBM (green diamonds), sRBM in direct base (blue stars), sRBM with MSR (red empty diamonds) and three points calculated with RBM utilizing transfer learning (black crosses). The empty purple squares show the RBM results for $N=100$, and the orange triangles are infinite DMRG results taken graphically from Ref.~\cite{lee2019_signatures}. }
	%	\label{plt01:ED_op}
	\label{fig:Lvarh0}
\end{figure} 

Fig.~\ref{fig:Lvarh0} shows the evolution of the order parameters and energy for $N=20,\,36,\,64$ and $N=100$. The results agree very well with the exact result in the assumed DS phase and are between the exact energy of $N=20$ and the asymptotic energy for large $N$ in the supposed $AF$ phase up to several points in a very narrow region near the discontinuous phase transition discussed later.

Fig.~\ref{fig:Lvarh0} illustrates the usability of RBM for larger clusters.  The presented results support the overall picture of the DS and AF phase separated by a narrow PS or at least its indication. Nevertheless, a much more thorough finite-size analysis would be necessary to assess the phase boundaries. For example, $\mathcal{P}_\text{AF}$ decreases with increasing system size in the whole relevant range of $J'$ which is in agreement with previous studies, e.g.~\cite{yang2022_quantum}. Consequently, a careful and precise extrapolation of $\mathcal{P}_\text{AF}$ to the thermodynamic limit is needed to identify $J$ above which the AF ordering prevails. However, even in this respect, there is an issue. The point of the discontinuous phase transition from the DS phase to the PS phase should be $J/J'\simeq 0.675$, but our results at larger lattices push it to $J/J' \simeq 0.7$. Besides finite-size effects, this could also be related to two technical problems. The first is the difficulty of training the NQS in the vicinity of the discontinuous phase transition. The second is the tendency of the direct base to prefer DS over AF ordering. Both these issues can be seen in panel (e) (inset of panel (d)) with details of the $N=64$ (and $N=100$) results. Here, green diamonds show the RBM data, red empty diamonds are sRBM data with MSR basis, and blue stars are sRBM data for direct basis, all with $\alpha=2$ for $N=64$. Clearly, all these networks show (different) problems around the expected point of the phase transition. For $J/J'=0.7$ and $0.72$ sRBM with MSR gives energy lower than RBM and even lower than the energy of DS ordering. Therefore, the sharp transition must be placed below $J/J'=0.7$. However, sRBM with MSR cannot correctly capture the onset of DS ordering. The sRBM network with direct basis illustrates the opposite problem. It overestimates the stability of the DS ordering. 
 
Investigation of sRBM showed that the RBM results at $J/J' = 0.7$ are not yet fully converged. Because we have not been able to solve this problem using the direct approach, we utilized transfer learning. We used the RBM parameters trained for $J/J' = 0.74$ as a starting point to train the network at $J/J' = 0.72$, then used these results as a starting point for $J/J' = 0.70$, and finally these results for $0.69$. That way we obtained lower variational energies for $J/J' = 0.72$ and $0.70$ than in the direct approach or in the sRBM results, and the $J/J'=0.72$ result dropped even below the DS energy. Interestingly, this also leads to an observable change in the order parameters (black crosses in all panels). In contrast to the $N=20$ case, the PS ordering is especially sensitive to this change, as seen from the comparison of black crosses and green diamonds in panel (d). Even if it is suggested by the order parameters, the transfer learning technique has not reached the point of the expected phase transition below $J/J'=0.69$. The reason is that the energy obtained at this point exceeds the DS energy already reproduced by the direct approach. This shows that, although useful, transfer learning has to be used with care. What is confusing is that the variational energies appear to be stable. They follow almost a straight line, with only small differences between various versions of the RBM and even lattice size, as illustrated by the $N=100$ data. Yet, these energies are approximately $2\%$ higher than the energy of infinite DMRG (iDMRG) results in the expected PS phase, which were taken graphically from Ref.~\cite{lee2019_signatures} and are marked by the orange triangles. However, the iDMRG results were obtained using a different type of lattice. Namely, an infinite cylinder with a circumference of $10$ lattice points. Therefore, they are not directly comparable due to the finite-size effects. Nevertheless, the predicted position of the DS-PS transition point just below $J/J'=0.69$ is too high and presents a conundrum.   

Another, but related issue is the plaquette order parameter. Our results for the lattices with periodic boundary conditions suggest that there might be some fundamental problem with accessing the PS phase using RBM, because not all lattices show a significant PS order parameter where expected. However, this might be related to the problem of degeneracy of plaquette ordering. To shed more light on this problem, we tested other variants of the SSM lattices. In particular, a version where a perfect PS is expected and SSM with mixed boundary conditions that break the degeneracy. 

\paragraph{PS and mixed boundary conditions:}

We performed a simple numerical experiment. We took the SSM lattice from Fig.~\ref{fig01:SS_lattice} but set all interactions to zero except around the squares of type A. That is, we constructed a lattice of interacting spins on otherwise independent squares A. Starting with random initial conditions, MC with complex RBM and $\alpha=2$ was able to converge and correctly capture the expected plaquette states on all accessible lattices.  This means that there is no fundamental problem with PS ordering, and even a small RBM is expressive enough to describe this state. We then used these ideal plaquette states as an initial state for the MC calculations of the full SSM model at the respective lattices. Interestingly, for periodic boundary conditions, this did not lead to an improvement. PS ordering was strongly suppressed in the learning process, and we did not reach more favorable variational energies compared to those already obtained when starting from random initialization.

\begin{figure}[!ht]\centering
	 \includegraphics[width=1.0\textwidth]{fig05B.pdf}
	\caption{Comparison of finite size scaling of the order parameters for PS (a),(b) and variational energy (c) for $J/J'= 0.74$ and $0.8$ between different methods and lattice boundary conditions. The empty green diamonds show the results for complex-valued RBM with $\alpha=2$ for periodic boundary conditions ($L=\sqrt{N}$). The black squares and the red circles show the mixed boundary conditions ($L=\sqrt{N/2}$), where the former have been randomly initialized and the latter in the ideal PS ordering. Blue stars are DMRG results taken graphically from Ref.~\cite{yang2022_quantum}.  In panel (c), the upper half shows the $J/J'= 0.74$ results compared with the iDMRG result for an infinite cylinder with a circumference of $L=10$ taken graphically from Ref.~\cite{lee2019_signatures}. The bottom half compares our results for $J/J'=0.8$ with the DMRG results from Ref.~\cite{yang2022_quantum}. Panel (d) shows the evolution of the RBM variational energy as a function of $J/J'$ when initialized in a ideal PS and with transfer learning utilized in the learning process. The horizontal blue line shows the exact DS energy for $N=20\times10$. The diagonal dashed gray line shows the asymptotic (large lattice) energy of AF ordering. Inset (e) shows the respective order parameter $\mathcal{P}_{PS}$. }
	%	\label{plt01:ED_op}
	\label{fig:RBMvsDMRG}
\end{figure} 

In accordance with, e.g., the recent work of Yang et al.~\cite{yang2022_quantum}, we decided to break the twofold degeneracy of expected PS ordering by changing periodic conditions to mixed ones. Following Ref.~\cite{yang2022_quantum}, we investigated cylinders with open boundary conditions in the $x$-direction with $L_x = 2L$ and periodic in the $y$-direction with $L_y=L$ so that $N=2L^2$. In this geometry, the SSM has a preferred singlet plaquette pattern, and significant PS ordering is expected in the PS phase. We show in Appendix~\ref{app:DSPS} that this ordering can be learned by a complex RBM with $\alpha=2$ even for the lattice $N=20\times10$. In addition, using this geometry also allowed us to compare our result directly with the DMRG results of Ref.~\cite{yang2022_quantum}. Therefore, we first focus here on the parameters investigated there, although they are far away from the DS-PS boundary and, therefore, show smaller $\mathcal{P}_\text{PS}$. In particular, we study $J/J'=0.8$, for which we used random initial conditions, and $J/J'=0.74$ where both the random and ideal plaquette states were used as initial states in the variational MC. 

A comparison of the finite-size scaling of the PS order parameter and the variational energy obtained for periodic and mixed boundary conditions and different RBM strategies with the results of DMRG~\cite{yang2022_quantum} (or iDMRG~\cite{lee2019_signatures}) are shown in panels (a), (b), and (c) of Fig.~\ref{fig:RBMvsDMRG}. In general, periodic boundary conditions lead to lower variational energies, as demonstrated in Fig.~\ref{fig:RBMvsDMRG}(c), where the green diamonds closely follow the finite-size scaling predicted by DMRG results for $J/J'=0.74$. RBM for lattices with mixed boundary conditions proved to be more difficult to train. On the other hand, they show a significant PS ordering. Although the RBM variational energy is generally larger than that of the DMRG and iDMRG studies, their PS order parameters are in reasonable agreement. However, here we draw attention to two observations. For $J/J'=0.8$, where $\mathcal{P}_{\text{PS}}$ is low, a strategy with random initial conditions was sufficient to reproduce the DMRG results, as illustrated in Fig.~\ref{fig:RBMvsDMRG}(b). However, for $N=20\times10$ three independent learnings lead to almost identical variational energies with difference smaller than $0.2\%$ and therefore imperceptible in Fig.~\ref{fig:RBMvsDMRG}(b). Yet these states showed a noticeable difference in $\mathcal{P}_\text{PS}$ as visible in Fig.~\ref{fig:RBMvsDMRG}(b) (three black squares below each other). We attribute this problem to the combination of the overall low value of $\mathcal{P}_\text{PS}$ and its sensitivity to fluctuation of plaquete ordering between the squares of the lattice. The situation worsened for weaker coupling $J$. For $J/J'=0.74$, learning with random initial states worked only for small lattices. For larger ones, the strategy where we initialized the RBM in an ideal PS gave much better results. The same number of iterations lead to lower energies and the expected $\mathcal{P}_{\text{PS}}$. This suggests that although the RBM with $\alpha=2$ is capable of describing plaquette orderings, this state is difficult to learn without some help. Nevertheless, we utilized the strategy where an ideal plaquette state is used as an initial state to address another problem opened in the previous section.

We tested the position of the DS-PS phase transition point by focusing on $N=20\times 10$ with mixed boundary conditions. We started from the ideal plaquette ordering (see Fig.~\ref{fig:plaq} in Appendix~\ref{app:DSPS}) at $J/J'=0.66$, therefore still in the expected DS phase, and then used transfer learning by sequentially increasing $J/J'$ for all points plotted in Fig.~\ref{fig:RBMvsDMRG}(d). Here, the blue horizontal line signals the exact energy of the dimer state. Although still slightly higher than the iDMRG result $J/J'=0.675$, this lattice significantly reduced the estimate of $J$ up to which DS survives to $J/J'\approx 0.68$ compared to the above results with the periodic lattice $J/J'\approx 0.69$. Fig.~\ref{fig:RBMvsDMRG}(d) also shows that, in contrast to the periodic lattices, the PS ordering is robust here (see inset (e)). Actually, when artificially initialized, it can survive the learning process even for $J/J'<0.68$ where the DS is the true ground state, although the learning rate plays an important role in this process. We used $\eta=0.02$ ($\approx$ 300 iterations) followed by $\eta = 0.003$ ($\approx$ (1000 iterations) at each step. 


During our analysis, we have avoided the discussion of the possible SL and related DQCP which are compelling scenarios in part of a region here assigned to the PS. The reason is that due to several difficulties discussed above, e.g., the fact that our RBM results underestimate the PS order parameter even for $N=20$ and large $\alpha$, a reliable analysis of SL and DQCP is currently beyond our reach. Nevertheless, here demonstrated expressiveness of a simple RBM with $\alpha=2$ suggests that the problem can be indeed attacked by larger, more expressive, or specialized networks. A good candidate might be a composed GCNN that would combine networks for different characters of the symmetry group for particular lattice size and boundary conditions.



\subsubsection{Magnetization plateaus ~\label{chap06:mag_field}}

\begin{figure}[!ht]\centering
	\includegraphics[width=1.0\textwidth]{fig06.pdf}
	\caption{Comparison of ED (blue solid lines) and RBM with $\alpha=2$ (symbols) results for $N=20$ and $J/J'=0.45$. Panels (a) and (b) show the magnetization and dimer state order parameter as functions of magnetic field. Panel (c) presents the relative error of the variational energy with respect to the ED result where blue dotted lines are just a guide to the eyes. Panel (d) shows the evolution of the normalized energy on external magnetic field. Blue filled diamonds represent the direct approach, empty red diamonds were obtained by utilizing the transfer learning discussed in the main text and the empty red squares by fixing $\mathcal{M}N$ to integer values from the vicinity of the direct approach. }
	\label{fig:hdepl20}
\end{figure}

Historically, the most intriguing property of the SSM is its ability to describe fractional plateaus in magnetization as a function of an external magnetic field, which are also observed in real materials. To address this problem through VMC, one has to drop the restriction of fixed $\mathcal{M}=0$. In addition to significantly enlarging the Hilbert space, this also makes the optimization (learning) process a harder task. Moreover, each plateau represents a different ordering, and therefore, a challenge for NQS. However, as already demonstrated here, a simple RBM NQS with $\alpha=2$ is sufficiently expressive to capture the main plateaus.

We assume only periodic boundary conditions and focus on the case $J/J'=0.45$, which is inside the DS phase (at $h=0$), where several broad plateaus are expected to form. The most stable ones, if allowed by the lattice size, should be the $\mathcal{M}=1/2$ and $1/3$ plateaus~\cite{momoi2000magnetization,verkholyak2022_fractional}. We start the discussion by benchmarking the RBM NQS results (blue filled diamonds in all panels of Fig.~\ref{fig:hdepl20}) against the ED results for the $N=20$ lattice (blue solid lines). Clearly, the variational energy in panel (d) is in very good agreement with the exact one. The relative error plotted in panel (c) is much lower than 1\% in the whole range of $h$. In addition, it shows a structure which can be understood by comparing the profile of the relative error dependence on $h$ with the normalized magnetization plotted in panel (a) and the DS order parameter in panel (b).
Panel (a) shows that RBM NQS with $\alpha=2$ is able to capture all main steps of the magnetization observed in the ED curve. The most stable are ${\cal M} = 0$, $1/2$ and $1$, followed by plateaus $1/5$ and $3/10$ that form in the range $ 0.7 \lesssim h/J' \lesssim 1.2$. 

The stability of these plateaus is also reflected in the relative error. Although we do not use any restriction on ${\cal M}$, the relative error for $h/J' < 0.7$, where $\mathcal{M}=0$, is negligible. In this region, the system stays in the DS ordering as revealed by panel (b). A similar situation exists for $h/J' \geq 2.1$. Here, the state is fully polarized ($\mathcal{M}=1$) and, therefore, easy to reproduce with variational techniques. Other regions with very small errors in the variational energy are the central parts of the stable plateaus discussed above, as best illustrated by the $1/2$ one. Here RBM NQS gives a relative error below 0.1\%. Consequently, the regions with the highest errors are related to the transitions between the stable plateaus. Here we also observe the largest deviations of the NQS magnetization (and $\mathcal{P}_\text{DS}$) from the ED results. These problematic regions can be divided into two types. The first one includes the step edges, i.e., the abrupt changes of the magnetization for $\mathcal{M}\leq 1/2$.  The related convergence problems are similar to the difficulties of correctly capturing the precise position of the discontinuous phase transition discussed for $h=0$ and $J/J'\approx 0.69$. As such, they can be also treated by the transfer learning. The red hollow diamonds in Fig.~\ref{fig:hdepl20} were obtained by approaching the step edges from left and right using the RBM parameters learned in the centers of the neighboring plateaus as the initial input. Transfer learning clearly suppresses errors and gives the correct value of $\mathcal{M}$ even very close to discontinuities.  

The second problematic region is at large magnetic field where the $\mathcal{M} = 1/2$ plateau transits into saturation $\mathcal{M}=1$. It was shown only recently that this region can host exotic quantum states including several spin-supersolid phases~\cite{nomura2023unveiling}. Only one additional step-like rise of $\mathcal{M}$ from $1/2$ is expected here in the thermodynamic limit, which is followed by a continuous increase of magnetisation to $\mathcal{M}=1$ as $h$ get larger. Nevertheless, the finite $N=20$ lattice shows a number of very narrow transient steps in this region. This makes this region unsuitable for transfer learning, unless a much more refined grid of $h$'s is applied. On the other hand, the small lattice allowed us to test the actual expressiveness of  RBM by fixing $\mathcal{M}N$ to integer values taken from the vicinity of the direct RBM results for $\mathcal{M}N$. The results with the lowest energies are depicted by the empty red squares, and they reproduce both $\mathcal{M}$ and the DS of the exact study. This proves that with correct learning strategy, RBM with $\alpha=2$ is sufficient for the description of this rather complex evolution of the SSM ground state in the increasing magnetic field.             
\begin{figure}[!ht]\centering
	\includegraphics[width=0.9\textwidth]{fig07.pdf}
	\caption{Comparison of the exact (red solid line) magnetization (a) and variational energy (b) results with VMC calculations utilizing RBM NQS with $\alpha=2$ for lattices $N=20, 36$ and $N=64$ as functions of external magnetic field.}
	\label{fig:hdeplvar}
\end{figure}                  
 
The stability of the magnetization plateaus must be confirmed on large lattices because the magnetization could be always discrete on finite clusters, yet continuous in the thermodynamic limit. Moreover, the lattice $N=20$ is not divisible by three, so it cannot hold the important $1/3$ plateau. To show that RBM NQS can really capture these features, we address larger clusters. Fig.~\ref{fig:hdeplvar} presents, in addition to the exact (solid red line) and RBM (red diamonds) results for $N=20$, the RBM results for $N=36$ (blue squares) and $N=64$ (yellow triangles). We stress here that these results were obtained with the direct approach. We have not used the transfer learning and fixed $\mathcal{M}$ to avoid the possibility that in this way we introduce a bias towards seemingly stable plateaus. Still, the results for $N=36$ show stable flat steps in the magnetization which holds both the $1/2$ and the $1/3$ plateaus. Although the results for $N=64$ are less stable, they confirm the $1/2$ plateau and clearly signal the formation of two additional plateaus for $h/J'<1.2$. These are very encouraging results, as they again show that a simple RBM with small number of parameters is expressive enough to correctly capture the complicated magnetization dependence reflecting the underlying complex ordering of the quantum spins.  

\section{Conclusion}

We have investigated the ground-state properties of the Shastry-Sutherland model via variational Monte Carlo with NQS variational functions. Our main goal was to show that a single and relatively simple NQS architecture can be used to approximate a wide range of regimes of this model. We have first tested and benchmarked several NQS architectures that are known from the literature to be suitable for different variations of the Heisenberg model. We discuss the role, advantages, and drawbacks of the NQSs that incorporate lattice symmetries and biases on the visible layer. We conclude that when precision, generality and computational costs are taken into account, a good choice for addressing larger SSM lattices without as well as with external magnetic field is a restricted Boltzmann machine NQS with complex parameters. 

Focusing on RBM NQS allowed us to refine the learning strategy. We discovered that if a more precise MC sampling is used, then it is advantageous to run several (tens) short independent optimizations instead of a few long learnings. Using this strategy for the lattice $N=20$ with periodic boundary conditions, we have demonstrated that already an RBM NQS with $\alpha=2$ can accurately approximate the DS and AF phases and shows the onset of the PS ordering. It also gives a correct point of the discontinuous change of the DS regime to PS/AF. However, in its vicinity, there are the largest deviations from the exact results. Here, the variational energy can be significantly reduced by increasing $\alpha$, but this leads only to a small improvement in the estimation of the order parameters. Consequently, we used RBM NQS with $\alpha=2$ to address larger lattices.  Although reliable in the DS and AF phases in all lattices up to $N=100$, PS proved to be more difficult to reach. However, this is partially a consequence of the degeneracy of the PS order. When broken by the usage of mixed boundary conditions, we were able to reproduce the DMRG result of Ref.~\cite{yang2022_quantum} for the order DS parameter. Furthermore, we showed that the RBM NQS with $\alpha=2$ is expressive enough to hold the PS order, although it might be difficult to train from a random initial state. To overcome this limitation, we introduced a strategy in which the RBM NQS is first trained on a lattice that enforces PS ordering and then this state is used as an initial state for the network in the relevant regime of SSM. This strategy allowed us to estimate the position of DS-PS phase transition to be $J/J' \approx 0.68$ for $N=20\times10$, which is, taking into account the finite-size effects, in good accordance with the iDMRG result $J/J'=0.675$. However, even when this strategy was used together with transfer learning, the training of RBM NQS for lattices with mixed boundary conditions proved to be more challenging than for periodic ones. For example, the finite-size scaling of the variational energy at $J/J' = 0.74$ closely follows the DMRG result; however, for mixed boundary conditions and $N=20\times10$ the variational energy is still approximately $4\%$ above the DMRG result~\cite{yang2022_quantum}.                   
 
A gradual increase of the magnetic field in SSM leads to formation of stable plateaus in the magnetization, each reflecting a different ground-state ordering. We have shown that RBM with $\alpha=2$ can capture the relevant plateaus that form for the lattice sizes studied here. Transfer learning can then be utilized to refine the results.  

To wrap it up, we have demonstrated that SSM is a good system for benchmarking NQSs and that a simple RBM NQS can be used to address its ground state in a broad range of regimes. This opens the possibility for NQSs to be used to address some unresolved questions related to the SSM, e.g., the existence of the spin-liquid phase, DQCP and other exotic quantum phases expected in a finite magnetic field, or to precisely capture the size and character of additional steps in the magnetization for larger lattices. We, however, leave this for future more focused studies.

    

\section*{Acknowledgements}
We thank Artur Slobodeniuk for the helpful discussions and Alberto Marmodoro for helping us access additional computational resources.  

% TODO: include author contributions
%\paragraph{Author contributions}
%This is optional. If desired, contributions should be succinctly described in a single short paragraph, using %author initials.

% TODO: include funding information
\paragraph{Funding information}
This research was supported by the project e-INFRA CZ (ID:90140) of the Czech Ministry of Education, Youth and Sports (M.M., J.M.), P.B. acknowledges a support from the Czech Science Foundation via Project No. 19-28594X, and M.Ž. acknowledges a support from the Czech Science Foundation via Project No. 23-05263K.

\begin{appendix}
	
	\section{Lattice tiles}
	\label{ses:App_tiles}
	\begin{figure}[ht]\centering
		% \includegraphics[width=0.4\textwidth]{fig08app.pdf}
        \includegraphics[width=0.45\textwidth]{fig09app.pdf}
		\caption{Shapes of tilted tiles of sizes $N = 4, 8, 16, 20$ used with periodic boundary conditions.}
		\label{fig01:tiles}
	\end{figure}
	To benchmark various architectures we utilize ED. We use the Lanczos algorithm implemented in the {\tt SciPy} library~\cite{scipy2020}.  The only square (regular) systems tractable by this implementation, without extensive utilization of expected state symmetries, are of size $2\times2$ and $4\times4$. Therefore, we also constructed the so-called tilted regular-square clusters. They are depicted in figure~\ref{fig01:tiles} and each of them can be thought of as a single repeating building block of the infinite lattice. Clusters of sizes $N = 4, 8, 16, 20$ are accessible through ED and used to benchmark our NQS implementations (in the text we discuss only the results for $N\geq16$).
	
	\section{Visible biases in sRBM and pRBM}
	\label{app:sRBM}
	Here we show by contradiction that allowing uneven biases for sRBM is equivalent to constant biases when we enforce enough symmetries. Let us suppose that visible biases are kept nonconstant $\left(a^f \rightarrow a^f_i\right)$ in the Eq.~\eqref{eq03:RBMSymm}. We further assume the condition that $\forall i{,}j~\exists g :$ $g\sigma_i = \sigma_j$. This condition holds for every SSM tile. 
	
	It follows that $\sum\limits_{g \in G} T_g(\vect{\sigma}^z)_i = C\sum\limits_{i=1}^{N} {\sigma}^z_i = C m^z$, where $C$ is the number of unique $g$ that fulfill the condition above. The first term in Eq.~\eqref{eq03:RBMSymm}, after the generalization $a^f \rightarrow a^f_i$, can be rewritten as
	\begin{align}
		\sum_{f=1}^F \sum_{g\in G} \sum\limits_{i=1}^{N} a^f_iT_g( \vect{\sigma}^z)_i = \sum_{f=1}^F  \sum\limits_{i=1}^{N} a^f_i \sum_{g\in G}T_g( \vect{\sigma}^z)_i = C m^z \sum_{f=1}^F \sum\limits_{i=1}^{N} a^f_i = C m^z \sum_{f=1}^F a^f\,.\label{eq03:visible_bias_reduction}
	\end{align}
	Thus, non-constant biases can be replaced by a constant value without loss of generality. Therefore, visible biases cannot be built into the sRBM as independent variational parameters.
	
	On the other hand, pRBM is not limited in this way.
	This can be clearly seen after rewriting both ans\"atze into similar forms. First, the sRBM
	\begin{align*}
		\resizebox{\hsize}{!}{$\displaystyle 
			\log \psiw(\vect{\sigma}^z) = \log \prod_{g\in G} \exp\sum_{f=1}^F\left\{ a^f \sum\limits_{\vphantom{j}i=1}^{N} T_g(\vect{\sigma}^z)_i +  \log \left[2\cosh(\sum_{i=1}^N w_i^f T_g(\vect{\sigma}^z)_i + b^f)\!\right]\!\right\}\,\!
			,$}
	\end{align*}
	and then pRBM
	\begin{align*}
		\resizebox{\hsize}{!}{$\displaystyle 
			\log \psiw^G(\vect{\sigma}^z) = \log \!\sum_{g\in G} \!\chi_{g^{\scalebox{0.75}[1.0]{\( \scriptscriptstyle - \)}1}} \exp\!\left\{\sum\limits_{i=1}^N a_i T_g(\vect{\sigma}^z)_i  +  \!\sum_{j=1}^M \log \left[2\cosh(\sum_{i=1}^N W_{ij}T_g(\vect{\sigma}^z)_i + b_j)\!\right]\!\right\}\,\!.
			$}
	\end{align*}
	The sum (rather than the product) of exponentials makes it impossible to use an analogous reduction of visible biases as in Eq.~\eqref{eq03:visible_bias_reduction}. Note that the usage of visible biases does not typically lead to a significant increase of parameters ($+N$). Yet, they usually improve the convergence of the learning process for frustrated systems because they help to set the correct sign structure of the approximated state. Therefore, it is beneficial to include visible biases in the NQS parameters whenever possible.    
	
	
	\section{Symmetries}\label{app:Symmetries}
	
	An infinite Shastry-Sutherland lattice has a \emph{p4g} wallpaper group symmetry whose point group is $C_{4v} $~\cite{wang2018dynamics}. The character table of $C_{4v}$ is shown in Table~\ref{tab03:point_group}. Each eigenstate of the SSM at infinite lattice must transform following one of the rows in the character table which, however, do not include the translations or glide reflections.
	
    \begin{table}[ht]
		\centering
		\begin{tabular}{c|rrrrr}%[c|ccccc]
			\toprule
			& $E$ & $2C_4$ & $C_2$ & $2\sigma_v$ & $2\sigma_d$\\\midrule
			$A_1$ & $1$ &   $ 1$ &  $ 1$ &        $ 1$ &        $ 1$\\
			$A_2$ & $1$ &   $ 1$ &  $ 1$ &        $-1$ &        $-1$\\
			$B_1$ & $1$ &   $-1$ &  $ 1$ &        $ 1$ &        $-1$\\
			$B_2$ & $1$ &   $-1$ &  $ 1$ &        $-1$ &        $ 1$\\
			$E$   & $2$ &   $ 0$ &  $-2$ &        $ 0$ &        $ 0$\\\bottomrule
		\end{tabular} 
		\caption{Character table of the $C4v$ point group describing symmetries of Shastry-Sutherland lattice.}
		\label{tab03:point_group}
	\end{table}
	
	For finite lattices investigated in the paper, the table and the number of additional translations depend on the system size and shape (note that we are also using irregular lattices). Different small clusters can have different character tables with varying numbers of irreducible representations (irreps)~\cite{saito1989possible,ishino1990symmetry}. A detailed analysis of each lattice goes beyond the scope of our paper. In practical implementations, we used the automorphisms of the graph using routines implemented in NetKet~\cite{carleo2019_netket,vicentini2022_netket} and a particular line from its character table. For illustrative purposes, it is still useful to discuss the irreps of individual phases of the SSM on the infinite lattice.
	
	\emph{\textbf{DS}}, described by Eq.~\eqref{eq01:DS_ground}, changes sign when we swap the spins in a dimer. More generally, the parity of the permutation determines the sign change. Consider a $L\times L$ square lattice, where $L$ is even, and a reflection symmetry along its diagonal axis ($\sigma_v$) within the squares containing the $J'$\!-bonds. The number of $J'$\!-bonds intersected by the axis is $L/2$ (considering the toroidal periodicity). For each of these bonds, a sign change occurs during the reflection while the sign of other dimers does not change. A similar argument can be constructed for the $C_4$ rotation. This has an important implication even for finite lattices. Namely, for regular lattices, the ground state of DS transforms under the trivial irrep $A_1$ if $L$ is divisible by 4, and under the antisymmetric irrep (corresponding to $B_2$) otherwise. This has some important consequences for the use of symmetries of some finite lattices, as discussed in the main text.
	
	\emph{\textbf{PS}} is twofold degenerate. Leaving out the translations, this means that it transforms under irrep E, which is the only irrep of dimension 2. 
	
	\emph{\textbf{AF}} state analysis for finite lattices is rather complicated~\cite{saito1989possible,ishino1990symmetry}. If needed, we have assumed that AF transforms under trivial irrep $A_1$ (with and without the application of MSR).

\section{DS and PS in the RBM}\label{app:DSPS}

\paragraph{DS:} In principle, the complex-valued RBM is capable of representing a DS. For example, it can take advantage of visible biases (first term in Eq.~\eqref{eq:RBM}) and set them to reproduce the correct sign structure according to MSR. Since all nonzero weight coefficients have the same absolute value, the dense layer (second term in Eq.~\eqref{eq:RBM}) then needs only to identify these zero configurations and return a constant otherwise. An example of such construction is $b_j=0$ and

\begin{equation}\label{eq:DS_RBM_params}
W_{ij} = \begin{cases}
\im\frac{\pi}{2} & \text{spin } i \in \text{dimer }j\\
0 & \text{otherwise}
\end{cases}\,.
\end{equation}

We number the dimers by index $j$ and $\cosh(\sum_i W_{ij} \sigma^z_i + b_j)$ is then one if the spins in dimer $j$ are antiparallel and zero otherwise. The size of the hidden layer corresponds to the number of dimers, specifically $N/2$, in this construction. By substituting Eq.~\eqref{eq:DS_RBM_params} into Eq.~\eqref{eq:RBM}, the DS state from Eq.~\eqref{eq01:DS_ground} is reproduced. Notably, $W_{ij}$ nullifies all basis states that are not present in the DS state, while $a_i$ ensures the correct sign and $b_j$ can be adjusted to give a correct normalization. This shows that the RBM is, in theory, able to represent the DS state exactly. Whether, however, such a state can be learned, is in principle a different question. Nevertheless, the results in Fig.~\ref{fig:hdeplvar} clearly show that it can. 

\paragraph{PS:} A complex RBM with $\alpha=2$ is expressive enough to encompass plaquette ordering even for large lattices. We demonstrate this for the $N=20\times10$ lattice with mixed boundary conditions (open in the $x$ direction and periodic in $y$). We start with a toy model, namely an SSM lattice with $J_A=1$ and $J_B=J'=0$, where $J_A$ ($J_B$) is the coupling strength at the edges surrounding the squares of type A (B), see Fig.~\ref{fig01:SS_lattice}. Starting from random initial state, the VMC converged to the plaquette ordering illustrated in the left panel of Fig.~\ref{fig:plaq}. We then use this state as an initial condition in the learning process for finite $J=J_A=J_B$ and $J'=1$ in the range of values where plaquette ordering is expected. These results are shown in Fig.~\ref{fig:RBMvsDMRG} and are discussed in the main text. In the central and right panels of Fig.~\ref{fig:plaq} we show how the increase in $J$ suppresses the ordering of plaquettes in SSM.  

	\begin{figure}[ht]\centering
	\includegraphics[width=1.0\textwidth]{fig10app.pdf}

		\caption{Plaquette ordering $Q_{\vect{r}}$ in the central part of the SSM lattice $N=20\times10$ with mixed boundary conditions. Here $Q_{\vect{r}}=\left<\ha{Q}_{\vect{r}}\right>$ where $\ha{Q}_{\vect{r}} = \frac{1}{2}\left(\ha{P}_{\vect{r}} + \ha{P}_{\vect{r}}^{-1}\right)$, with $\ha{P}_{\vect{r}}$ being the cyclic permutation operator in square $\vect{r}$. The left panel shows a toy model with $J_A=1$ and $J_B=J'=0$ where $J_A$ ($J_B$) is the coupling strength at the edges surrounding the squares of type A (B). The center and right panels show $Q_{\vect{r}}$ for SSM with $J=0.68$ (just below the DS-PS transition) and $J=0.8$. The values of $Q_{\vect{r}}$ for squares with diagonal bonds are not shown.}
		\label{fig:plaq}
	\end{figure}

\end{appendix}

%\bibliography{paper_v07.bib}

\input{paper_v07.bbl}

\nolinenumbers

\end{document}
