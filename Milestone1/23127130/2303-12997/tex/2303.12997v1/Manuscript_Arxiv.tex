\documentclass[lettersize,journal]{IEEEtran}
\usepackage{amsmath,amsfonts}
\usepackage{algorithmic}
\usepackage{array}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{booktabs}
\usepackage{multirow}
\hyphenation{op-tical net-works semi-conduc-tor IEEE-Xplore}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\usepackage{balance}

\begin{document}
\title{FER-former: Multi-modal Transformer for Facial Expression Recognition}
\author{Yande Li, Mingjie Wang, Minglun Gong, Yonggang Lu, Li Liu
\thanks{%This work was supported by grands from China Scholarship Council (Grant No. 202006180033) and was done when Yande Li studied at the University of Guelph. (\emph{Corresponding author: Minglun Gong; Yonggang Lu; Li Liu}.)\par
Yande Li is with the School of Information Science and Engineering, Lanzhou University, Lanzhou, 730000, China and also with the School of Computer Science, University of Guelph, Guelph, N1G 2W1, Canada (e-mail: liyd19@lzu.edu.cn). \par
Mingjie Wang is with the School of Science, Zhejiang Sci-Tech University, Hangzhou, 310018, China (e-mail: mingjiew@zstu.edu.cn). \par
Minglun Gong is with the School of Computer Science, University of Guelph, Guelph, N1G 2W1, Canada (e-mail: minglun@uoguelph.ca). \par
Yonggang Lu is with the School of Information Science and Engineering, Lanzhou University, Lanzhou, 730000, China (e-mail: ylu@lzu.edu.cn). \par
Li Liu is with the School of Big Data and Software Engineering, Chongqing University, Chongqing, 401331, China (e-mail: dcsliuli@cqu.edu.cn).}}

\markboth{Journal of Arxiv}%
{How to Use the IEEEtran \LaTeX \ Templates}

\maketitle

\begin{abstract}
The ever-increasing demands for intuitive interactions in Virtual Reality has triggered a boom in the realm of Facial Expression Recognition (FER).
To address the limitations in existing approaches (e.g., narrow receptive fields and homogenous supervisory signals) and further cement the capacity of FER tools, a novel multifarious supervision-steering Transformer for FER in the wild is proposed in this paper.
Referred as FER-former, our approach features multi-granularity embedding integration, hybrid self-attention scheme, and heterogeneous domain-steering supervision.
In specific, to dig deep into the merits of the combination of features provided by prevailing CNNs and Transformers, a hybrid stem is designed to cascade two types of learning paradigms simultaneously.
Wherein, a FER-specific transformer mechanism is devised to characterize conventional hard one-hot label-focusing and CLIP-based text-oriented tokens in parallel for final classification.
To ease the issue of annotation ambiguity, a heterogeneous domains-steering supervision module is proposed to make image features also have text-space semantic correlations by supervising the similarity between image features and text features.
On top of the collaboration of multifarious token heads, diverse global receptive fields with multi-modal semantic cues are captured, thereby delivering superb learning capability. Extensive experiments on popular benchmarks demonstrate the superiority of the proposed FER-former over the existing state-of-the-arts.
\end{abstract}

\begin{IEEEkeywords}
Annotation ambiguity, CLIP, facial expression recognition, multi-modal, vision Transformer.
\end{IEEEkeywords}

%%%%%%%%% BODY TEXT

\input{introduction}
\input{related}
\input{method}
\input{experiment}

%-------------------------------------------------------------------------
\section{Conclusion}
This paper presents a multifarious supervision-steering Transformer for FER in the wild, namely FER-former, which features multi-granularity embedding integration, hybrid self-attention scheme and multifarious supervisory signals from heterogeneous domains.
In general, a pre-trained prevailing CNNs (features pyramid) and a scratch-trained Transformer (global receptive fields) are combined to take full advantage of their merits.
In particular, a FER-specific encoder containing a hybrid self-attention scheme is well devised to characterize ambiguity-robust tokens involving rich one-hot and text semantic.
More importantly, a heterogeneous domains-steering supervision module is proposed to mitigate annotation ambiguity by supervising the cosine similarity between image features and text features, which plays an important role in our FER-former.
Finally, on top of the collaboration of heterogeneous token heads, fine-grained global interrelationships with diverse semantic cues among tokens are enriched and modeled.
Results on several benchmarks show the superiority of our FER-former over other state-of-the-art methods.

%%%%%%%%% REFERENCES
{\small
\bibliographystyle{IEEEtran}
\bibliography{references}
}

\end{document}


