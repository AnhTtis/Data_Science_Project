\documentclass[a4paper,12pt]{article}
\usepackage[top=1in,bottom=1in,left=1in,right=1in]{geometry}


\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{color}
%\usepackage[dvipdfmx]{graphicx}
\usepackage[]{graphicx}
%\usepackage[dvipdfmx]{hyperref}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{natbib}
\usepackage{tikz}
\usepackage{setspace}
\usepackage{subfiles}
\usepackage{comment}
\usepackage{bookmark}
				
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}


\theoremstyle{definition}
\newtheorem{defi}{Definition}
\providecommand*{\defiautorefname}{Definition}
\newtheorem{exmp}{Example}
\providecommand*{\exmpautorefname}{Example}

\newtheorem{conj}{Conjecture}
\newtheorem{lem}{Lemma}
\providecommand*{\lemautorefname}{Lemma}
\newtheorem{claim}{Claim}
\providecommand*{\claimautorefname}{Claim}
\newtheorem{them}{Theorem}
\providecommand*{\themautorefname}{Theorem}
\providecommand*{\figureautorefname}{Figure}

%\theoremstyle{plain}
\newtheorem{coro}{Corollary}
\providecommand*{\coroautorefname}{Corollary}
\newtheorem{prop}{Proposition}
\providecommand*{\propautorefname}{Proposition}
\newtheorem{ass}{Assumption}
\providecommand*{\assautorefname}{Assumption}
\newtheorem{step}{Step}


\title{Characterizing the Feasible Payoff Set of OLG Repeated Games\thanks{We thank seminar and conference participants at 2023 Asian Meeting of the Econometric Society (Beijing), 2023 Africa Meeting of the Econometric Society (Nairobi) and CIRJE Microeconomics Workshop at Tokyo University. We are grateful to Michihiro Kandori and Akihiko Matsui for helpful suggestions. Chihiro Morooka was supported by the Japan Society for the Promotion of Science (JSPS) KAKENHI Grant Number JP22K13360. All errors are ours.}}
\author{Daehyun Kim\thanks{Division of Humanities and Social Sciences, POSTECH. Email: \href{mailto:dkim85@outlook.com}{dkim85@outlook.com}}\and Chihiro Morooka\thanks{School of Science and Engineering, Tokyo Denki University. Email: \href{mailto:c-morooka@mail.dendai.ac.jp}{c-morooka@mail.dendai.ac.jp}}}
\date{February 7, 2024}

\begin{document}
\maketitle
\begin{abstract}
We study the set of feasible payoffs of OLG repeated games with general stage games. Our first main result completely characterizes the set of feasible payoffs given any fixed discount factor of players and the length of interaction. We can use this result to obtain the feasible payoff set in closed form. Second, we provide a novel comparative statics of the feasible payoff set with respect to the discount factor and the length of interaction. Perhaps interestingly, the feasible payoff set becomes \emph{smaller} as players' discount factor becomes larger. In addition, we identify a necessary and sufficient condition for this monotonicity to be strict. 
\end{abstract}


\textbf{Keywords:} Overlapping generation, repeated games

\strut

\textbf{JEL Classification Numbers:} C72, C73 


\onehalfspacing

\newpage


\section{Introduction}
%\subfile{section1}
\label{sec:1}
In overlapping generation (OLG) repeated games, players play for finite periods and are replaced by their next generation. This class of games has been used to study cooperation among finitely-lived players in long-run organizations (e.g., \cite{Hammond_1975} and \cite{Cremer_1986_QJE}).

In this paper, we study the feasible payoff set of OLG repeated games. In the literature of OLG repeated games, including studies of the folk theorems, the convex hull of the stage game payoffs is mostly used as the feasible payoff set of interest. However, the overlapping structure allows players to achieve average discounted payoffs beyond the convex hull of the static payoffs: Although players share the same discount factor, depending on where they are located in their lifecycle, players discount payoffs differently. Thus, it is not obvious which payoffs are feasible. Our purpose in this paper is to understand how the OLG structure affects what players could obtain. 

 We study the feasible payoff set when players' discount factor and the period of overlap are fixed, departing from the most studies in the literature, which usually focus on the asymptotic case. On the other hand, as typical in the literature, we focus on ``periodic'' feasible payoffs in which each generation of the same player plays the same sequence of actions during their lifetime.\footnote{More generally, each generation of the same player plays different sequences of action profiles. In this case, each player has an infinite sequence of feasible payoffs. We discuss more about it in Section 6.1.} 

		
		
Our first main result concerns a complete characterization of the feasible payoff set of OLG repeated games. We find that it can be characterized by the convex hull of the set of the average discounted payoffs that can be achieved by playing $n$-length sequences of action profiles, where $n$ is the number of players and each of the action profiles is supposed to be played for $T$ (the interaction length) times consecutively. For such sequences of action profiles, we could calculate the average discounted payoff \emph{as if} players play $n$-length sequence (rather than $nT$), while effectively discounting by $\delta^T$ (rather than by $\delta$). Thus, this characterization substantially simplifies the set of action profiles we should consider in obtaining the feasible payoff set. In fact, our characterization allows a closed-form expression of the feasible payoff set given any stage game.

Our second main result is about a comparative statics of the feasible payoff set with respect to $\delta$ and $T$. We find that the feasible payoff set is decreasing  (in the set-inclusion sense) in the effective discount factor $\delta^T$. Perhaps surprisingly, this implies that the set is \emph{decreasing} in $\delta$. When the effective discount factor is $1$, the feasible payoff set coincides with the convex hull of the static payoffs. When it is close to $0$, it is an $n$-dimensional cube, where for each player the maximum (resp. minimum) feasible payoff coincides with the maximum (resp. minimum) stage payoff. For intermediate effective discount factors, it is an $n$-dimensional polytope. 

We also examine the condition where the above monotonicity holds in a strict sense. Under a very mild condition ― unless the one-shot feasible set is already a (multidimensional) cube ― it is shown that the OLG feasible set satisfies the strict monotonicity with respect to the parameters.





	
\textbf{Related Literature} 
	
	Previous researches on OLG repeated games have mainly focused on folk-theorem-like approaches as in \cite{Kandori_1992_RES} and \cite{Smith_1992_GEB}.\footnote{Recently,  \cite{Morooka_2021_IJGT} provides an alternative folk theorem with an opposite order of choosing parameters: It shows that if $\delta$ is chosen first and then $T$ is chosen, any feasible and strictly individually rational payoffs can be achieved by subgame perfect equilibrium payoffs. The feasible payoff set considered is larger than the convex hull of the stage game payoffs.} Alternatively, in this paper, we study the OLG repeated games with fixed $\delta$ and $T$. By studying the feasible payoff set, we provide a natural benchmark for the equilibrium payoff set which one might be more interested in.
	


The present paper is also related to the literature of repeated games with differential discounting of players, which has been studied since \cite{LP_1999_ECMA}. They study infinitely repeated games between two players who have different discount factors, and show that some payoffs outside the convex hull of the stage game payoffs can be obtained by intertemporal trading of payoffs: The more patient player gives payoffs in early periods to have more in later periods. Allowing differential discounting of players, \cite{Sugaya_2015_TE} proves a folk theorem for $n$-player infinitely repeated games with imperfect public monitoring. \cite{DG_2022_JET} provides a more constructive approach to study feasible and equilibrium payoffs of repeated games with perfect monitoring. On the other hand, \cite{Chen_2007_EL} and \cite{CF_2013_IJGT} study finitely repeated games between two players. These papers examine whether the feasible payoff set becomes larger as the length of the game becomes longer. The latter paper, based on the result of the former, shows that for any two-player stage games, this is indeed the case.\footnote{They leave the question for more general case of arbitrary number of players as open.} 



Comparing to the literature of repeated games with differential discounting, in our model of OLG repeated games, players share the \emph{same} discount factor. Nevertheless, players can trade payoffs across periods due to the overlapping generation structure: In a given period, players are located in a different position in their lifecycle (``age''), resulting in different discounting of some future payoffs. Notice that players discount their payoffs in the same way when they have the same age. In this sense, their discounting is ``symmetric'', which makes our analysis relatively tractable. It results in our characterization of the feasible payoff set, allowing a closed-form expression of the feasible payoff set given any stage game for each discount factor and the length of each generation's lifespan.\footnote{In the literature of repeated games with differential discounting, \cite{Chen_2007_EL} provides an explicit characterization of the feasible payoffs of finitely repeated games for a specific two-player stage game. \cite{Sugaya_2015_TE} provides a recursive characterization of the feasible payoff set of infinitely repeated games for general stage games. \cite{DG_2022_JET} provides several characterizations of the feasible payoff set; in particular, they characterize it when players can have some large discount factors.} 



	

	


The remainder of the paper is organized as follows. In Section 2, we introduce the model of OLG repeated games. In Section 3, we present our first main result which is a complete characterization of the feasible payoff set of OLG repeated games. In Section 4, we provide comparative statics results of the feasible payoff set with respect to $\delta$ and $T$. We provide two examples in Section 5 to illustrate our main results. Section 6 concludes after discussions.

\section{Model}
%\subfile{section2}
\label{sec:2}
\subsection{Stage Game}
A stage game is defined as a triple $G=(N,(A_i)_i,(u_i)_i)$, where $N=\{ 1,2,\cdots ,n\}$, for some $n\geq 2$, is the set of one-shot players, $A_i$ is a finite set of pure actions available to player $i$,\footnote{As long as a Public Randomizing Device is available, our result by mixed actions is the same with the one by pure actions. Therefore, we only consider pure actions throughout this paper.} and  $u_i: \prod_i A_i \to \mathbb{R}$ is player $i$'s one-shot payoff function. Let $A \equiv \prod_{i \in N} A_i$ be the set of action profiles. 

Given a set $B \subseteq \mathbb{R}^N$, let $co (B)$ be the convex hull of $B$. Let $V \subseteq \mathbb{R}^n$ be the feasible set of one-shot payoffs, defined as follows:
$$V \equiv co \{ u(a) : a \in A\}.$$
And denote 
$$F^*\equiv \prod _{i\in N} \left [\min _{a\in A}u_i(a),\ \max _{a\in A}u_i(a) \right].$$

\subsection{OLG Repeated Game}
Given a stage game $G$ defined above, $\delta \in (0,1]$ and $T \in \mathbb{N}$, we define the OLG repeated game $OLG(G,\delta ,T)$ as follows (also see Table 1):
\begin{itemize}
	\item In every period $t \in \mathbb{N}$, $G$ is played by $n$ finitely-lived players.
	\item For $i\in N$ and $d \in \mathbb{N}$, the player with $A_i$ in generation $d$ joins in the game at the beginning of period $(d-1)nT+(i-1)T+1$, and lives for the following $n$ \emph{overlaps} each of which consists of $T$ periods, until he retires at the end of period $dnT+(i-1)T$. The only exceptions are the players with $A_i$ for $i\in N\setminus\{ 1\}$ in generation 0, who participates in the game between periods 1 and $(i-1)T$.
	\item Each player's per-period payoffs are discounted at a common discount factor $\delta$.
\end{itemize}
\begin{table}[t]
\centering
\scalebox{0.7}{
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}\hline
Period&$1\sim T$&$T+1\sim 2T$&$2T+1\sim 3T$&$3T+1\sim 4T$&$4T+1\sim 5T$&$5T+1\sim 6T$&$6T+1\sim 7T$&$\cdots$\\\hline
$A_1$&\multicolumn{3}{c|}{Generation 1}&\multicolumn{3}{c|}{Generation 2}&\multicolumn{2}{c|}{Generation 3 $\cdots$}\\\hline
$A_2$&Generation 0&\multicolumn{3}{c|}{Generation 1}&\multicolumn{3}{c|}{Generation 2}&$\cdots$\\\hline
$A_3$&\multicolumn{2}{c|}{Generation 0}&\multicolumn{3}{c|}{Generation 1}&\multicolumn{3}{c|}{Generation 2 $\cdots$}\\\hline
\end{tabular}
}
\caption{Structure of OLG repeated game with $n=3$}
\label{o1}
\end{table}
When a sequence of actions $(a (t)) _{t=1}^{nT}\in A^{nT}$ is played throughout a player's life with $A_i$, her/his average payoff is as follows:$\footnote{For the player with $A_i$ for $i\in N\setminus\{ 1\}$ in generation 0, replace $nT$ with $(i-1)T$.}$
\begin{eqnarray}
\frac{1}{\sum _{t=1}^{nT}\delta^{t-1}}\sum _{t=1}^{nT}\delta ^{t-1}u_i(a (t)).
\nonumber\end{eqnarray}

We assume that players can access a Public Randomizing Device (henceforth PRD) uniformly distributed over the unit interval at the beginning of every period.\footnote{This assumption is employed also by \cite{Chen_2007_EL} and \cite{CF_2013_IJGT}.} We assume each player can observe the realization of the PRD at each period after her/his birth.

\section{A Complete Characterization of the Feasible Payoff Set}
\label{sec:3}
%\subfile{section3.tex}
We are interested in the set of payoffs that can be achieved by a sequence of action profiles in which every generation of players plays the same sequence of action profiles. We call such action sequences \emph{periodic}. Periodic sequences are employed as equilibrium paths for folk theorems \cite[]{Kandori_1992_RES, Smith_1992_GEB}. We shall provide a complete characterization of feasible payoffs from periodic sequences for any $\delta$ and $T$.





As we restrict our attention to periodic sequences, we focus on the payoffs of players in generation $d\geq 1$.\footnote{For $i \in N$, we refer to any player whose action set is $A_i$ as ``player $i$."} For $a^{[nT]}=(a^1,a^2,\cdots ,a^{nT})\in A^{nT}$, we define the average discounted payoff $U_i(a^{[nT]})$ of player $i$ as follows:
$$
U_i(a^{[nT]}):=\frac{1}{\sum _{k=1}^{nT}\delta ^{k-1}}\left(\sum _{k=1}^{nT}\delta ^{k-1}u_i(a^{(i-1)T+k}) \right),
$$
where $a^{s}=a^{s-nT}$ for $s\geq nT+1$. 

In the OLG repeated games, whether a payoff is feasible may depend on the observability of the results of PRDs before this player is born: Between any two overlaps, there is always some player who retires. The most permissible assumption is that players are able to observe all the previous outcomes of PRDs, which results in the following definition.
$$
F(\delta,T)=co \left(\bigcup _{a^{[nT]}\in A^{nT}}\{ U(a^{[nT]})\} \right).
$$
The RHS represents the feasible payoffs that can be achieved by PRD which arises every $nT$-period, which is the longest given stationary payoffs.


We will show that in fact any payoff in this set can be achieved under a weaker assumption that players only can observe the result of PRDs after they are born. 


	




It is convenient to introduce an additional notation. Given $a^{[n]}=(a^1,a^2,\cdots ,a^n)\in A^n$ and $i\in N$, we define the value $v_i(a^{[n]})$ as follows: 
\begin{align*}
v_i(a^{[n]})&:=\frac{1}{\sum _{k=1}^n\delta ^{(k-1)T}}\left(\sum _{k=1}^n\delta ^{(k-1)T}u_i(a^{i+k-1}) \right),
\end{align*}
where $a^{s}=a^{s-n}$ for $s\geq n+1$. Let $v( a^{[n]}) \equiv (v_i (a^{[n]}))_{ i\in N}.$ That is, $v_i (a^{[n]})$ represents the average discounted payoff of player $i$ from repeatedly playing the same action profile $a^k$ during the $k$-th overlap:
$$U_i ( \underbrace{a^1, \dots, a^1}_{\text{$T$ times}}, \dots, \underbrace{a^n, \dots, a^n}_{\text{$T$ times}}) = v_i (a^1,  \dots, a^n).$$
We call such sequences of action profiles \emph{stable}.
Alternatively, $v_i ( a^{ [n]})$ can be interpreted as the average discounted payoff over $n$ periods, where the ``effective'' discount factor is $\delta^T$. 



\begin{them} 
\label{them:1}
For any $\delta \in (0,1]$ and $T \in \mathbb{N}$, 
\begin{equation}
\label{eq:nn1}
F(\delta,T) =co\left( \left \{v(a^{[n]}): {a^{[n]}\in A^n} \right \} \right).
\end{equation}


\end{them}



In words, the feasible payoff set is the convex hull of the average discounted payoffs of length-$n$ sequences of action profiles (i.e., stable paths), each of which is to be played $T$ times. Notice that we could interpret the average discounted payoff of such a sequence of action profiles as the average discounted payoff of length-$n$ sequence of action profiles, discounted by $\delta^T$. 

The characterization is useful since it substantially reduces the number of sequences of action profiles we need to consider: Regardless of $T$, it is sufficient to consider length-$n$ sequences. The result also means that $\delta$ and $T$ affect the feasible payoff set only through $\delta^T$. Thus, any $(\delta, T)$ and $(\delta', T')$ with $\delta^T ={\delta'}^{T'}$ would result in the same feasible payoff set. For instance, for the Prisoners' Dilemma game, where each player has two actions (so 4 action profiles), the result implies, it is sufficient to consider $4 \times 4 = 16$ sequences of action profiles to obtain the feasible payoff set, regardless of $\delta$ and $T$. In particular, this is true even when $T$ is a large number. 












One may wonder whether the RHS of (1) suggests that the feasible payoffs may not be implemented under our assumption on the observability of PRDs. That is, we assumed that a result of a PRD is observed only by the contemporary generation, whereas for each $T$ period (i.e., overlap), there is a player to be replaced; so it might require a stronger informational assumption, for instance, the results of PRDs are observed also by future generations. In the proof, however, we construct a sequence of PRDs each of which is executed every overlap that generates the same average discounted payoff from a sequence of action profiles. 

The underlying idea of the proof is as follows: Within an overlap, no player retires so every player discounts their payoff at $t+1$ relatively more than payoff at $t$ in the overlap by $\delta$, although they discount payoffs differently depending on their ``age.'' This allows us to generate the same average discounted payoff for a given sequence of action profiles for a given overlap using a PRD at the beginning of this overlap, where the probability of playing a certain action profile during this overlap is determined in a way to mimic the sum of discounted payoffs whenever this action profile is played in the original sequence of action profiles.  On the other hand, across overlaps, some player should retire and for such a player the relative discounting between $t$ and $t+1$ is different, which makes a similar construction of a PRD between overlaps unavailable. 



\begin{proof}


We show 
$$ F(\delta,T) \subseteq co\left(\{v(a^{[n]}): {a^{[n]}\in A^n}\} \right) .$$
Consider an arbitrary sequence $a^{[nT]} = (a^1, \dots, a^{nT}) \in A^{nT}$. We claim that the same average discounted payoff can be obtained by a convex combination of ``$n$-length action sequences.'' 

To see this, we first claim that for each overlap $k=1, \dots n$, the average discounted payoff within the overlap can be achieved by playing constant action profiles resulting from a PRD. 

In each $k$-th overlap, the following PRD is exercised at the beginning of the overlap: An action profile $a \in A$ is randomly drawn with probability $\alpha^k (a)$ defined by 
$$\alpha^k (a) := \sum_{t=(k-1)T+1}^{kT} \frac{\delta^{t-1 - (k-1)T}}{ 1+ \dots + \delta^{T-1}}\mathbf{1}_{ \{{a}^t = {a} \}}.$$
Clearly, $\sum_{ a \in A} \alpha^k ({a}) = 1$. The players are supposed to play the realized action profile $a$ consecutively until the end of the overlap. To see that this PRD generates the same average discounted payoff as that of $a^{[nT]}$ for each player during the overlap, note that the PRD is constructed in that way so that it mimics discounting. Namely, if $a^t = a$ in $a^{ [nT]}$ for some $t  \in \{ 1, 2, \dots, T\}$, then the probability of playing $(a,\dots, a)$ increases by $\frac{\delta^{t-1- (k-1)T}}{\sum_{t=1}^T \delta^{t-1} }$. This construction is possible because no player retires within the overlap so that every player discounts $t+1$-period payoff by $\delta$ times than $t$-period payoff. This is not the case as long as some player retires and is reborn (i.e., across overlaps). 

Lastly, observe that the average discounted payoff of each player from this sequence of PRDs $(\alpha^1, \dots, \alpha^n)$ is a convex combination of $\{v(a^{[n]}):a^{[n]}\in A^n\}$, where the weight is $\alpha^1 (a^1)\times \cdots \times \alpha^n (a^n)$ for each $(a^1, \dots, a^n ) \in A^n$.

For the converse, observe that each element of $\{v(a^{[n]}):a^{[n]}\in A^n\}$ is in $F(\delta, T)$ and $F(\delta, T)$ is convex by definition. 
\end{proof}

\section{Comparative Statics of the Feasible Payoff Set}
\label{sec:4}
%\subfile{section4.tex}
In this section, we study comparative statics of the feasible set w.r.t. both $T$ and $\delta$. From Theorem 1 in the previous section, we know that the feasible payoff set depends on $\delta$ and $T$ only through $\delta^T$. 



\subsection{Monotonicity}
Our main result in this section asserts that the feasible payoff set is non-increasing in $\delta^T$, implying, perhaps surprisingly, it is \emph{non-increasing} in $\delta$.





\begin{them}
\label{them:2}
The following hold:
\begin{enumerate}
	\item For any $\delta, \delta'$ with $0< \delta <\delta ' \leq 1$, $F(\delta ',\ T)\subseteq F(\delta ,\ T)$.
\item Given any $\delta \in (0,1]$, $F(\delta ,\ T)\subseteq F(\delta ,\ T+1)$.	
\end{enumerate} \end{them}

The rest of this section devotes to proving Theorem 2.\footnote{The weak set-inclusions in the result cannot be strengthened to be strict. For instance, if the stage game payoff set is an $n$-dimensional rectangle, the feasible payoff set of the corresponding OLG repeated game would be unchanged with respect to the parameters.} In doing so, we shall also provide a characterization of players' optimal play to maximize the welfare given some weights for players, which might have some independent interest. 

Theorem 1 implies that it is without loss of generality to consider a sequence of $n$ pure action profiles for studying the monotonicity. That is, players play the same action profile during an overlap which consists of $T$ periods. In addition, since the feasible payoff set is convex, it is enough to show the maximum ``score'' increases as $\delta$ (resp. $T$) becomes smaller (resp. larger) for each non-zero direction. 

Fix $\lambda \in \mathbb{R}^n \setminus \{ \mathbf{0}\}$. For a given $\delta \in (0,1]$ and $T \in \mathbb{N}$, let $\Delta \equiv  \Delta (\delta, T) =  \delta^T$.  Define $\lambda$-weighted welfare as
\begin{equation}
\label{eq:nn2}
W_{ \lambda}^*(\Delta) :=\max_{ a^{[n]} =(a^1, \dots, a^n) \in A^n} W_\lambda (a^{[n]},\Delta),
\end{equation}
where
$$W_\lambda (a^{[n]}, \Delta ) := \sum_{i=1}^n \lambda_i v_i (a^1, \dots, a^n), \quad \forall a^{[n]} \in A^n.$$

We want to show that $W_{ \lambda}^* (\Delta)$ is non-increasing in $\Delta$ (as a result, non-decreasing in $T$ and non-increasing in $\delta$). 







We introduce a few more notations. Denote the set of optimal solutions of (2) by $\mathcal{A}^*_\lambda (\Delta) \subseteq A^n$. Let $\mathcal{U}^*_\lambda (\Delta) = \left \{ (u^k)_k : u^k = u (a^k), a^{[n]} \in \mathcal{A}_\lambda^* (\Delta) \right \} \subseteq \mathbb{R}^{n\times n}$. That is, the set of sequences of the optimal payoff vectors. Notice that $\mathcal{U}^*_\lambda (\Delta)$ may be a singleton even when $\mathcal{A}^*_\lambda (\Delta)$ is not.  Lastly, given $u^{[n]} = (u^1, \dots, u^n) \in \mathbb{R}^{n \times n}$, for each $k \in \{ 1, \dots, n\}$, let
%\begin{equation}
%\label{eq:nnn3}
$$w_k (u^{[n]}) := \sum_{ i =1}^n \lambda_i u_i^{i+k-1},$$
%\end{equation}
where $u_i^m=u_i^{m-n}$ if $m>n$. That is, $w_k (u^{[n]})$ is the weighted sum of players' payoffs when their ``age'' is $k$ (i.e., they are in the $k$-th overlap in their lifetime). For instance, given $u^{[3]} = (u^1, u^2, u^3) \in \mathbb{R}^{3 \times 3}$ and $\lambda = (1,1,1)$, $w_1 (u^{[3]}) = u^1_1  + u^2_2   + u^3_3 $, $w_2 (u^{[3]}) = u^2_1  + u^3_2  + u^1_3  $, $w_3 (u^{[3]}) =u^3_1   + u^1_2  + u^2_3 $. 







Observe that for each $u^{ [n]}=(u^1,\dots, u^n) \in \mathcal{U}^*_\lambda (\Delta)$. 
\begin{equation}
\label{eq:nn3}
W_{ \lambda}^* (\Delta) = \frac{\sum_{k=1}^n \Delta^{k-1} w_k (u^{[n]}) }{\sum_{k=1}^n \Delta^{k-1}}.
\end{equation}

The following lemma is the key to prove the monotonicity. 
\begin{lem}
\label{lem:1}
Let $\Delta \in (0,1]$ and $u^{[n]}\in \mathcal{U}^*_\lambda (\Delta)$. For each $m =1, \dots, n-1$, 
\begin{equation}
\label{eq:2}
\sum_{k=1}^m \Delta^{k-1} w_k (u^{[n]}) \geq  \sum_{k=1}^m \Delta^{k-1} w_{n-m+k} (u^{[n]}).
\end{equation}
\end{lem}
\begin{proof}
See Appendix A.1.
\end{proof}





In words, the lemma means, at optimum, the payoffs in the earlier stages of a player are higher than those of later stages (in the sense that for any $m \leq n-1$, the first $m$ payoffs should be larger than the last $m$ payoffs). When there are only two players, this reduces to the condition that the payoffs when they are ``young'' must be larger than those when they are ``old'' for optimality. When there are more than two players, it is \emph{a priori} not clear what could be the corresponding expression. According to the lemma, for the case of three players, it is $w_1 (u^{[3]}) \geq w_3 (u^{[3]}) $ and $w_1 (u^{[3]})   + \Delta w_2 (u^{[3]})  \geq w_2 (u^{[3]})  + \Delta w_3 (u^{[3]}) $. 


Let us explain the crux of the idea of the proof with 3 players and $\lambda = (1,1,1)$. Assume $u^{[3]} = (u^1, u^2, u^3)$ be an optimal sequence of payoff vectors. From optimality of $u^1$ at $k=1$, it should be $u^1_1 + \Delta^2 u^1_2 + \Delta u^1_3 \geq u^2_1 + \Delta^2 u^2_2+ \Delta u^2_3$. By multiplying both sides by $\Delta$, 
		$$\Delta u^1_1 + \Delta^3 u^1_2 + \Delta^2 u^1_3 \geq \Delta u^2_1 + \Delta^3 u^2_2 + \Delta^2 u^2_3.$$
On the other hand, by optimality of $u^2$ at overlap $k=2$,
		$$\Delta u^2_1 + u^2_2 + \Delta^2 u^2_3\geq \Delta u^1_1 + u^1_2 + \Delta^2 u^1_3.$$
		From the two inequalities, we can conclude $u^2_2 \geq u^1_2$. Intuitively, since the same generation of player 1 and 3 is active both at $k=1$ and $k=2$, while player 2 is replaced by the next generation, in order for $u^2$ to give a larger aggregate payoff at $k=2$, player 2 should have a larger payoff at $u^2$ than at $u^1$. A symmetric argument results in $u^3_3 \geq u^2_3$ and $u^1_1 \geq u^3_1$, and summing them up results in $w_1 (u^{[3]}) \geq w_3 (u^{[3]}) $. Applying a similar argument to ``two-overlap apart,'' we have $\Delta u_2^1 + u_3^1 \leq \Delta u_2^3 + u_3^3$ (as a result, $w_1 (u^{[3]})   + \Delta w_2 (u^{[3]})  \geq w_2 (u^{[3]})  + \Delta w_3 (u^{[3]})$).














Perhaps surprisingly, the following lemma says that the inequality (4) in Lemma 1 is sufficient to prove that the derivative of the aggregate payoff is non-positive. 
\begin{lem}
\label{lem:2}
For $\Delta \in (0,1)$,
$$\frac{\partial W_{ \lambda} }{\partial \Delta }(a^{[n]},\Delta)  \leq 0$$
for any $a^{[n]}  \in \mathcal{A}_\lambda^* (\Delta)$.
\end{lem}
\begin{proof}
See Appendix A.2.
\end{proof}










\begin{proof}[Proof of Theorem 2]




We first observe that $W_\lambda^*(\Delta)$ is continuous in $\Delta$ everywhere because it is the maximum of continuous functions. 

In addition, we argue that $W_\lambda^*(\Delta)$ is differentiable at all but finite $\Delta$. To see this, observe that for any $a^{[n]}, \tilde{a}^{[n]} \in A^n$ with $\lambda \cdot u(a^k) \neq \lambda \cdot u(\tilde{a}^k)$ for some $k \in \{1,\dots, n\}$, the number of solutions of the equation $W_\lambda (a^{[n]}, \Delta) - W_\lambda (\tilde{a}^{[n]}, \Delta)=0$ is at most $n-1$, because it is a polynomial equation of degree $(n-1)$. Thus, the total number of intersections of $W_\lambda ( \cdot, \Delta)$ which any pair of action sequences can make is at most $\frac{|A^n||A^n -1|}{2} (n-1)$. This implies that we can find a partition $\{ (\underline{b}_l,\overline{b}_l]: l = 1,\dots, L \}$ of $(0,1]$, where $L \in \mathbb{N}$, such that for each $l = 1, \dots, L$, there is a unique payoff sequence $u_l^{[n]} = (u(a_l^k))_{k=1}^n$ corresponding to a solution $a_l^{[n]} =(a_l^k)_{k=1}^n$ which is optimal for any $\Delta \in (\underline{b}_l,\overline{b}_l]$. Hence, $W_\lambda^* (\Delta)$ is differentiable in the interior of $(\underline{b}_l,\overline{b}_l]$.\footnote{For $\Delta$ on the boundary, the derivative may not exist. For instance, in the OLG repeated game with the Prisoners' Dilemma depicted in Figure 1, for large $\Delta$ and $T=1$, when the direction is $\lambda = (1,1)$, $(CC, CC)$ is optimal, while for some small $\Delta$, the optimal sequence is $(DC,CD)$. There is a cutoff $\Delta$ for this change, and neither $(CC,CC)$ or $(DC,CD)$ does not satisfy the description above: $(CC, CC)$ (or the corresponding payoff sequence) remains optimal for $(\Delta, \Delta + \epsilon)$, while $(DC, CD)$ remains optimal for $(\Delta - \epsilon, \Delta)$ for some small $\epsilon>0$.
 } And the derivative is non-positive by Lemma 2, i.e.,
\begin{equation}
\label{eq:nn6}
\frac{d W^*_\lambda (\Delta) }{d\Delta } = \frac{\partial W_{ \lambda} }{\partial \Delta }(a_l^{[n]},\Delta) \leq 0.
\end{equation}
Together with the continuity of $W^*_\lambda (\Delta)$, this implies the monotonicity. 
\end{proof}





\subsection{A Limit Characterization of the Feasible Payoff Set}

For the asymptotic cases (i.e., $\delta^T \nearrow 1$ or $\delta^T \searrow 0$), we can be more explicit about the shape of the feasible payoff set. 

When the players' effective discount factor $\delta^T$ is close to 1, there is not much difference in discounting of young and old players. So, the scope of intertemporal trade of payoffs is little and what is the best is to maximize the stage game payoffs for a given welfare weight. On the other hand, when the effective discount factor is close to 0, the difference in discounting of young and old players is large. Hence intertemporal trading can be very helpful. The extreme form of such trading is to maximize the youngest player's (weighted) payoff. We summarize this discussion as a corollary:

\begin{coro}
The following hold:
\begin{enumerate}
\item For $\delta^T$ sufficiently close to 1, the solution of the optimization problem (2) is to play some $a^k \in \argmax_{a' \in A} \lambda \cdot u(a')$ for each overlap $k$. As a result, $\lim_{ \delta^T \nearrow 1} F(\delta, T) = V.$
	\item For $\delta^T$ sufficiently close to 0, the solution of the optimization problem (2) is to play $a^k \in \argmax_{a' \in A} \lambda_{i_k} u_{i_k} (a')$, where $i_k \in N$ is the youngest player in overlap $k$. As a result, $\lim _{\delta^T\searrow 0}F(\delta, T)=  \prod _{i\in N} \left [\min _{a\in A}u_i(a),\ \max _{a\in A}u_i(a) \right]$.	 	
\end{enumerate}

\end{coro}

Thus, for any $\delta \in (0,1)$, as $T \to \infty$, the feasible set converges to the $n$-dimensional cube. Similarly, for any $T$, as $\delta \to 0$, the feasible set converges to the $n$-dimensional cube. 


   




\subsection{Strict Monotonicity}


In this subsection, we identify a necessary and sufficient condition for the strict expansion of the feasible set as $\Delta \equiv  \Delta (\delta, T) = \delta^T$ becomes smaller. 


Denote the OLG feasible set by $F(\Delta)  \equiv  F(\delta ,T)$. We show that, when $V\neq F^*$, the OLG feasible set satisfies the following strict monotonicity:
\begin{prop}
\label{prop:nnn1}
Suppose that $V\neq F^*$ holds. Then $F(\Delta ')\subsetneq F(\Delta)$ holds for $\Delta <\Delta '$. Conversely, if $V = F^*$, then $F(\Delta)=V$ for any $\Delta$.
\end{prop}

That is, unless the one-shot feasible set is already a (multidimensional) cube, the OLG feasible set satisfies the strict monotonicity with respect to $\Delta$.


Intuitively, if $\Delta <1$ and $V \neq F^*$, players can find some opportunity of intertemporally trading payoffs (i.e., playing a non-constant action profile sequence) so that they can achieve payoffs beyond $V$ toward some direction $\lambda$. It turns out that the benefit from the most efficient trading (i.e., that achieves $W^*_\lambda (\Delta)$) is strictly larger with smaller $\Delta$.


\begin{proof}
See Appendix A.3.
\end{proof}

\section{Examples}
\label{sec:5}
%\subfile{section5}
In this section we illustrate our main results using well-known stage games in the repeated game literature.  

\subsection{OLG Prisoners' Dilemma}
\label{subsec:pd}

\begin{figure}[t]
\centering
\begin{tabular}{|c|c|c|}
\hline
    & $C$      & $D$      \\ \hline
$C$ & $1,1$    & $-1,2$ \\ \hline
$D$ & $2,-1$ & $0,0$    \\ \hline
\end{tabular}
\caption{The Prisoners' Dilemma}
\label{fig:1}
\end{figure}
\begin{figure*}
\centering
\includegraphics[width=0.45\textwidth]{fig_pd1.pdf}
\includegraphics[width=0.45\textwidth]{fig_pd2.pdf}
\includegraphics[width=0.45\textwidth]{fig_pd3.pdf}
	\caption{In each figure, the Grey region represents the feasible payoff set (for $\Delta =\frac{2}{3}$, $\Delta = \frac{1}{3}$ and $\Delta \to 0$ clockwise) of the OLG PD game. In each figure, the region surrounded by the dotted lines is the convex hull of the stage game payoffs; the Red region represents the convex hull of the four payoffs, $v(CC, a^2)$, $a^2 \in \{ C,D\}^2$ in (6). Similarly, the Green, Orange and Blue represent the counterparts for $DC, DD$ and $CD$, respectively.    }
	\label{fig:n1}
\end{figure*}

Consider the OLG repeated games with the stage game of Prisoners' Dilemma (see Figure 1). By Theorem 1 
\begin{equation}
\label{eq:n2}
	F(\delta, T) = co  \left( \bigcup_{ a \in \{CC, DC, DD, CD\}}  \{ v( a, CC), v( a, DC), v(a, DD), v(a, CD)  \}  \right ), 
\end{equation}
where $v (a^1, a^2) = \left (\frac{u_1 (a^1)  + \Delta u_1 (a^2) }{1+ \Delta}, \frac{\Delta u_2 
(a^1)  + u_2 (a^2)}{1 + \Delta } \right)$ for any $(a^1, a^2) \in A^2$ as previous (see Figure 2). 




It is notable that as $\Delta$ changes the sequences of action profiles that generate the extreme points of the feasible payoff set may change. For instance, when $\Delta$ is large enough (e.g., $\Delta = 2/3$), $(CC, CC)$ yields an extreme point. As $\Delta$ becomes smaller (e.g., $\Delta = 1/3$), it is not anymore an extreme point while $(DC, CD)$ becomes a new sequence corresponding one of the extreme points. As $\Delta$ becomes even smaller, $(CC, CD)$ is ``dominated'' by $(DC, CD)$. Intuitively, when $\Delta$ is sufficiently small each player should play the action profile that maximizes her/his payoff in order to be on the efficient frontier. 




\subsection{A 3-player Example from Fudenberg and Maskin (1986)}
\label{subsec:fm}
The second example (see Figure 3) involves three players. \cite{FM_1986_ECMA} used this stage game to show that the folk theorem fails for the standard repeated games with infinitely-lived players. In particular, this stage game does not satisfy the full dimensionality, a sufficient condition of their folk theorem.\footnote{\cite{Smith_1992_GEB} shows that the full-dimensionality is not necessary for his folk theorem for OLG repeated games. Since the folk theorem first chooses $T$ then chooses sufficiently large $\delta$, it concerns the case when $\delta^T$ is close to 1. The feasible payoff set in this case is the ``smallest'' according to our characterization, which is the line segment between $(0,0,0)$ and $(1,1,1)$.} 
\begin{figure}
\centering
\begin{tabular}{|c|c|c|}
\hline
    & $A$     & $B$     \\ \hline
$A$ & $1,1,1$ & $0,0,0$ \\ \hline
$B$ & $0,0,0$ & $0,0,0$ \\ \hline
\end{tabular}
\quad 
\begin{tabular}{|c|c|c|}
\hline
    & $A$     & $B$     \\ \hline
$A$ & $0,0,0$ & $0,0,0$ \\ \hline
$B$ & $0,0,0$ & $1,1,1$ \\ \hline
\end{tabular}
\caption{The stage game of a 3-player pure coordination game}	
\label{fig:2}
\end{figure}

Nevertheless we observe that the feasible payoff set of the OLG repeated game exhibits the full dimension for any $\Delta \in (0,1)$. When $\Delta = 1$, it is the line segment between $(0,0,0)$ and $(1,1,1)$, which coincides with the convex hull of the stage game payoffs. On the other hand, when $\Delta \in (0,1)$, it is a polytope with nonempty interior. 
\begin{figure}[t]
\centering
\includegraphics[width=0.5\textwidth]{fig_fm.pdf}
\caption{The OLG feasible payoff set of the pure coordination game when $\Delta = 1$ (Black) $\Delta = 2/3$ (Yellow), $\Delta = 1/2$ (Orange), $\Delta = 1/3$ (Red) and $\Delta= 0$ (Gray).}
\label{}
\end{figure}




\section{Discussion}
\label{sec:6}
%\subfile{section6}
\subsection{Non-periodic Play}
\label{subsec:discuss}



Thus far we have restricted our attention to periodic feasible payoffs. In this subsection, we discuss how the relaxation of this restriction would affect the monotonicity result in terms of $\delta$. We consider non-stationary sequences of action profiles of players, in which different generations of the same player may play different sequences of action profiles during their lifetime. One way to extend the concept of the monotonicity in this case would be as follows: Given a sequence $(\bar{u}^y(\delta))_{y \in \mathbb{N}}$ of players' average discounted payoffs for each generation $y=1,2,\dots$, which is feasible with discount factor $\delta$, we ask whether the same sequence is feasible with $\delta' < \delta$. 

The following example shows that this is not the case: Consider the OLG repeated game with two players with two possible stage game payoffs of $(1,0)$ and $(0,1)$. Suppose $T=1$. Consider the following sequence of payoff vectors for each $t = 1,2, \dots$:
$(1,0), (1,0), (0,1), (0,1), \dots.$
 That is, the first two periods gives $(1,0)$, followed by $(0,1)$ forever. The corresponding average payoff for each generation of player 1 is $\bar{u}_1^1 = 1$ for the first generation, and $\bar{u}_1^y= 0$ for any $y \geq 2$. Observe that player 2 in the first generation, who is born at $t=2$, obtains the average payoff $\bar{u}_2^1 = \frac{ \delta}{ 1+ \delta}$ and $\bar{u}_2^y = 1$ for any $y \geq 2$.

Now consider $\delta' < \delta$. Since $\bar{u}_1^1= 1$. the first two period must give players $(1,0), (1,0)$. Note that the maximum payoff of player 2 in the first generation is obtained when $(0,1)$ is given at $t=3$, yielding the average payoff $\frac{\delta'}{1+\delta'}$, which is strictly smaller than $\frac{\delta}{ 1+ \delta}$. 


 \subsection{Implications on Equilibrium Payoffs}
 \label{sec:6.2}


We note that our monotonicity result of the feasible payoff set can also shed light on the equilibrium (Nash equilibrium or subgame perfect equilibrium) payoff set. 

In particular, it is almost immediate from our result that the set of stationary equilibrium (i.e., each generation of a player employs the same strategy) payoffs is, in general, not increasing in $\delta$. This contrasts from the case of repeated games with infinitely-lived players with a PRD \cite[]{APS_1990_ECMA}.\footnote{When there is no PRD, the monotonicity might not hold (see \cite{MOS_2002_GEB,Yamamoto_2010_IJGT}).} As an example, consider the OLG repeated game with the stage game of the Battle of the Sexes, where the coordination gives $(2,1)$ or $(1,2)$ and mis-coordination results in $(0,0)$ (see Figure 5). 
\begin{figure}[t]
\centering
\begin{tabular}{|c|c|c|}
\hline
    & $A$   & $B$   \\ \hline
$A$ & $2,1$ & $0,0$ \\ \hline
$B$ & $0,0$ & $1,2$ \\ \hline
\end{tabular}
\caption{The Battle of the Sexes}
\label{fig:5}
\end{figure}
In this case, the Pareto efficient payoffs, $(2,1)$ and $(1,2)$ can be achieved from playing static Nash equilibria and so any convex combination of playing the two equilibria is also a subgame perfect equilibrium. Our result of the decreasing feasible payoff set then translates into the decreasing efficient equilibrium payoffs as $\delta$ increases. 


The previous case where the best equilibrium payoff can be achieved from playing static Nash equilibria is somewhat special in the sense that there is no incentive problem of players. In general, there may be a trade-off of player being more patient in OLG repeated games: When players are more patient, they are easier to be disciplined as they care more about future payoffs. On the other hand, it is also costly as it makes players more difficult to make intertemporal trades of their payoffs. This suggests that the ``optimal'' discount factor of players may be some intermediate value for some games. 

Let us consider a simple example to make the point of the previous paragraph. Consider the OLG repeated games with $T=1$, where the stage game is described in Figure 6 and let $\lambda = (\frac{1}{2} , \frac{1}{2})$. We claim that the optimal $\delta$ that maximizes the weighted sum of players' average discounted payoffs in (``stationary'' subgame perfect) equilibrium is $\delta = \frac{1}{2}$. To see this, we first observe that if $\delta \geq 1/2$, playing $(L, L),(R,R)$ (they are the action profiles that give the maximum sum of players' payoffs) for odd and even periods, respectively, can be achieved by a stationary subgame perfect equilibrium. This is because when players are old, each of them has no incentive to deviate; and each player's play when they are young can be supported by punishing any deviation from it by $(M,M)$ (this is a one-shot Nash profile and gives the minmax payoff to each player): $2 + \delta  \geq 3 - \delta$ or $\delta \geq \frac{1}{2}$. Then the monotonicity result implies that the smallest $\delta = \frac{1}{2}$ yields the largest weighted sum of payoffs. 
\begin{figure}
\centering
\begin{tabular}{|c|c|c|c|}
\hline
    & $L$     & $R$     & $M$     \\ \hline
$L$ & $2,1$   & $-3,-3$ & $-3,-3$ \\ \hline
$R$ & $-3,-3$ & $1,2$   & $-5,3$  \\ \hline
$M$ & $3,-5$  & $-3,-3$ & $-1,-1$ \\ \hline
\end{tabular}
\caption{The stage game used in the example in Section 6.2}
\label{fig:6}
\end{figure}






\section{Conclusion} 

In the present paper we study the feasible payoff set of OLG repeated games. In our first result, we show that the set can be characterized by a convex combination of the average discounted payoffs of $n$-period sequences of action profiles, where each of the action profiles is played for $T$ periods consecutively. Our second main result shows that the feasible payoff set is monotonely decreasing in $\delta$ and increasing in $T$. 


A natural and important direction of research in the future is to study the set of equilibrium payoffs. In particular, it should be meaningful to extend our understanding of the trade-off of having more patient players, which is briefly described in Section 6.2. One might also think of a recursive characterization of the subgame perfect equilibrium payoff set as in \cite{APS_1990_ECMA}. Note that even in stationary equilibria, where each generation plays the same action, players' payoffs keep changing during their lifetime, so the equilibrium payoff set is indeed a $nT$-tuple of sets. We leave them as future research topics.


\appendix
\section{Omitted Proofs}
\label{sec:app}
%\subfile{section_app}
\subsection{Proof of Lemma 1}
\label{sec:proof_lem1}

\begin{proof}
 

Denote the ``age'' of player $i$ at overlap $k$ by $y_k (i) \in \{ 1,\dots, n\}$. 


Consider overlap $k  \in \{ 1, \dots, n\}$ and $m \in \{ 1,\dots, n-1\}$. Let $k' = k +m \text{ (mod $n$)}$. Then, from optimality of $u^k$ at overlap $k$, 
		$$\sum_{ i =1}^n   \Delta^{ y_k (i)-1 } \lambda_i  u_i^k   \geq \sum_{i=1}^n \Delta^{y_k(i)-1} \lambda_i u_i^{k'} .$$
		By multiplying both sides by $\Delta^m$,
$$\sum_{ i =1}^n   \Delta^{ y_k (i)+ m-1 } \lambda_i  u_i^k  \geq \sum_{i=1}^n \Delta^{y_k(i) + m-1} \lambda_i u_i^{k'} .$$
Note that $y_{k'} (i) = y_k (i) + m$ if $y_k (i) + m \leq n$; otherwise $y_{k'} (i)= y_k (i) + m-n$.
\begin{multline*}
\sum_{ i : y_k(i) + m \leq n}   \Delta^{ y_{k'} (i)-1 } \lambda_i  u_i^k + \Delta^n \sum_{ i : y_k(i) + m >n}   \Delta^{ y_{k'} (i)-1 } \lambda_i  u_i^k \\
\geq \sum_{i : y_k(i) + m \leq n} \Delta^{y_{k'}(i)-1} \lambda_i u_i^{k'}  +\Delta^n\sum_{i : y_k(i) + m >n} \Delta^{y_{k'}(i)-1} \lambda_i u_i^{k'},	
\end{multline*}
or equivalently, 
\begin{multline}
\label{eq:nnn6}
\sum_{ i : y_k(i) + m \leq n}   \Delta^{ y_{k'} (i)-1 } \lambda_i  u_i^k - \sum_{i : y_k(i) + m \leq n} \Delta^{y_{k'}(i)-1} \lambda_i u_i^{k'}  \\
\geq   \Delta^n \left ( \sum_{i : y_k(i) + m >n} \Delta^{y_{k'}(i)-1} \lambda_i u_i^{k'} -  \sum_{ i : y_k(i) + m >n}   \Delta^{ y_{k'} (i)-1 } \lambda_i  u_i^k \right).	
\end{multline}
On the other hand, from optimality at overlap $k'$, we have 
\begin{multline*}
\sum_{ i : y_k(i) + m \leq n}   \Delta^{ y_{k'} (i)-1 } \lambda_i  u_i^{k'}  + \sum_{ i : y_k(i) + m >n}   \Delta^{ y_{k'} (i)-1 } \lambda_i  u_i^{k'}  \\
\geq \sum_{i : y_k(i) + m \leq n} \Delta^{y_{k'}(i)-1} \lambda_i u_i^k  +\sum_{i : y_k(i) + m >n} \Delta^{y_{k'}(i)-1} \lambda_i u_i^k, 
\end{multline*}
or
\begin{multline}
\label{eq:nnn7}
\sum_{i : y_k(i) + m \leq n} \Delta^{y_{k'}(i)-1} \lambda_i u_i^k- \sum_{ i : y_k(i) + m \leq n}   \Delta^{ y_{k'} (i)-1 } \lambda_i  u_i^{k'}    \\
\leq     \sum_{ i : y_k(i) + m >n}   \Delta^{ y_{k'} (i)-1 } \lambda_i  u_i^{k'} -\sum_{i : y_k(i) + m >n} \Delta^{y_{k'}(i)-1} \lambda_i u_i^k.
\end{multline}
In order to satisfy both (7) and (8), it must be 
$$\sum_{ i : y_k(i) + m >n}   \Delta^{ y_{k'} (i)-1 } \lambda_i  u_i^{k'}  \geq \sum_{i : y_k(i) + m >n} \Delta^{y_{k'}(i)-1} \lambda_i u_i^k,$$
or equivalently,
$$\sum_{ i : y_{k'}(i) \in \{ 1, \dots, m\} }   \Delta^{ y_{k'} (i)-1 } \lambda_i  u_i^{k'}  \geq \sum_{i : y_{k'}(i) \in \{ 1, \dots, m\}} \Delta^{y_{k'}(i)-1} \lambda_i u_i^k .$$
Summing up over $k \in \{1, \dots, n\}$ both sides, we have the inequality in the statement.
	\end{proof}


\subsection{Proof of Lemma 2}
\label{proof:lem2}
\begin{proof}








For $a^{[n]} \in \mathcal{A}^{*}_{\lambda}(\Delta)$, denote the numerator of $\frac{\partial W_{ \lambda}}{\partial \Delta } (a^{[n]},\Delta )$ by $\eta(\Delta)$. We will show that $\eta (\Delta) \leq 0$, thereby $\frac{\partial W_{ \lambda}}{\partial \Delta } (a^{[n]},\Delta ) \leq 0$. From (3), observe that, for $u^{[n]} \in \mathcal{U}^{*}_{\lambda}(\Delta)$,
\begin{align*}
\eta (\Delta) &= \left (\sum_{k=1}^n \frac{d\Delta^{k-1} }{d\Delta }w_k (u^{[n]}) \right) \left(\sum_{m=1}^n \Delta^{m- 1} \right) - \left( \frac{d \sum_{m=1}^{n} \Delta^{m-1}} { d\Delta}\right)  \sum_{k=1}^n \Delta^{k-1} w_k(u^{[n]})\\
&=\left (\sum_{k=1}^n (k-1)\Delta^{k-2} w_k(u^{[n]}) \right) \left(\sum_{m=1}^n \Delta^{m-1} \right) - \left(\sum_{k=m}^{n} (m-1) \Delta^{m-2}\right)  \sum_{k=1}^n \Delta^{k-1} w_k(u^{[n]})\\
&=\sum_{k=1}^n \left ((k-1) \Delta^{k-2} \sum_{m=1}^{n} \Delta^{m-1} - \left( \sum_{m=1}^n (m-1) \Delta^{m-1}  \right) \Delta^{k-2}  \right) w_k(u^{[n]})\\
&=\sum_{k=1}^n  \left( \sum_{m=1}^n (k-m) \Delta^{k+m-3} \right)w_k(u^{[n]}).
\end{align*}
Recall $m$-th constraint, $m \in \{ 1, \dots, n-1\}$, is
$$-\sum_{k=1}^m \Delta^{k-1} w_k (u^{[n]})  + \sum_{k=1}^m \Delta^{k-1} w_{n-m+k} (u^{[n]})\leq 0.   \quad (\# m)$$
We will show that 
$$\eta (\Delta) = \sum _{m=1}^{n-1}p_m\times (\text{LHS of } \# m),$$
where for $1\leq m\leq n-1$
$$p_m \equiv \Delta ^{n-2}+\Delta ^{n-3}+\cdots +\Delta ^{n-m-1}.$$
Note that as $p_m \geq 0$, this implies $\eta (\Delta) \leq 0$. To see the equality, fix $j \in \{ 1,\dots, n\}$. Observe for any constraint $m\geq j$, there exists a non-positive term $- \Delta^{j-1}w_j (u^{[n]})$. And for any constraint $m$ with $j \geq n-m+1$, there exists a non-negative term $\Delta^{j-n+m-1} w_j (u^{[n]})$. Therefore the coefficient of $w_j (u^{[n]})$ is 
\begin{align*}
&\sum_{m = j}^{n-1} p_m (-\Delta ^{j-1} ) + \sum_{m =n+1-j}^{n-1} p_m \Delta^{j-n+m-1}\\
&=\sum_{m = j}^{n-1} (\Delta^{n-2} + \cdots + \Delta^{n-m-1}) (-\Delta^{j-1}) + \sum_{ m=n+1-j}^{n-1} (\Delta^{n-2} + \cdots + \Delta^{n-m-1}) \Delta^{j-n+m-1} \\
&=\sum_{ m=j}^{n-1} (-\Delta^{n+j-3} - \cdots - \Delta^{n-m+j-2})  + \sum_{m=n+1-j}^{n-1} (\Delta^{j+m-3} +\cdots + \Delta^{j-2})\\
&=(- \Delta^{n+j-3}- \cdots - \Delta^{n-2}) + (- \Delta^{n+j-3} - \cdots - \Delta^{n-1}) + \cdots + (-\Delta^{n+j-3} - \cdots - \Delta^{j-1})  \\
&+ (\Delta^{n-2} + \cdots + \Delta^{j-2}) + (\Delta^{n-1} + \cdots + \Delta^{j-2})  + \cdots + (\Delta^{j+n-4} + \cdots + \Delta^{j-2})\\
&=- \Delta^{n+j-3} ((n-j)-0) - \Delta^{n+j-4} ((n-j)-1)- \cdots - \Delta^{n-2} ((n-j) -(j-1))\\
&- \Delta^{n-3} ((n-j-1)- (j-1))- \cdots - \Delta^{j-1} (1- (j-1))- \Delta^{j-2} (0-(j-1))\\
&=\sum_{m=1}^n (j-m) \Delta^{j+m-3}.
\end{align*}
\end{proof}

\subsection{Proof of Proposition 1}
\label{proof:prop1}



Let $S^0 \equiv \{a^{[n]}\in A^n: u(a^1)=u(a^2)=\dots =u(a^n)\}\subset A^n$ and $S^C \equiv A^n\setminus S^0$. We first provide a few lemmas. 


\begin{lem}
\label{lem:nn3}
$V \neq  F^*$ holds if and only if there exist two points $u$, $\tilde{u} \in V$ with $u \neq \tilde{u}$ which satisfy the following two conditions:
\begin{enumerate}
	\item There exists $\lambda \in \mathbb{R}^n \setminus \{ \mathbf{0} \}$ such that $\bar{u} \in \argmax_{ u' \in V} \lambda  \cdot u'$ holds if and only if
$\bar{u}  \in \{  t u +(1- t)\tilde{u} : t \in [0,1]\}.$
\item There exists at least two player $i$ such that $u_i \neq \tilde{u}_i$.
\end{enumerate}
	
\end{lem}

\begin{proof}
	$(\Leftarrow)$ Suppose not, i.e., $V = F^*$. Observe that any $u$ and $\tilde{u}$ on an edge of $F^*$ can have only one player whose payoff differs.
	
	$(\Rightarrow)$ Suppose not. Then, either $V$ does not have an edge or any edge of $V$ should not satisfy Condition 2. In the first case, trivially $V = F^*$. In the second case, there is only one player $i$ such that $u_i \neq \tilde{u}_i$. That is, any edge is parallel to some axis. Since $V$ is convex, this implies that $V$ is an $n$-dimensional cube. In turn, this implies that $V = F^*$ as $V$ contains the best and worst stage payoff profile for each player $i$ (i.e., $u(a)$ for some $a \in \argmax_{a' \in A} u_i (a')$ and $u(a)$ for some $a \in \argmin_{a' \in A} u_i (a')$). A contradiction. 
\end{proof}











\begin{lem}
\label{lem:nn4}
Suppose that there exist $\lambda \in\mathbb{R}^n \setminus \{\mathbf{0}\}$ and two points $u$, $\tilde{u} \in V$ that satisfy Condition 1 and 2 in Lemma 3. Then, for any $\Delta \in (0,1)$, $W^*_\lambda (\Delta )>\lambda \cdot u$ holds. 
\end{lem}
\begin{proof}
WLOG let $u=(0,\dots,0)$. Let $a \in A$ and $\tilde{a} \in A$ be such that $u(a) = u$ and $u(\tilde{a} ) = \tilde{u}$. When $\tilde{a}$ (resp. $a$) is played when player $n$ is the youngest (resp. not the youngest), players' payoff vector is $u' \equiv c(\Delta ^{n-1}\tilde{u}_1,\Delta ^{n-2} \tilde{u}_2,\dots,\Delta \tilde{u}_{n-1},\tilde{u}_n)$, where $c \equiv \frac{1}{1+\Delta+\dots +\Delta ^{n-1}}$. 

On the other hand, when $a$ (resp. $\tilde{a}$) is played when player $n$ is the youngest (resp. not the youngest), their payoff vector is $u'' \equiv \tilde{u}-c(\Delta ^{n-1}\tilde{u}_1,\Delta ^{n-2}\tilde{u}_2,\dots, \Delta \tilde{u}_{n-1}, \tilde{u}_n)$. Note that $u'' = \tilde{u}-u'$.


We claim that either $u'$ and $u''$ should not be in $V$. To see this, suppose $u' \in V$. Observe that for any $\Delta \in (0,1)$, $u'$ is not on the line segment between $u$ and $\tilde{u}$ (this is because $\tilde{u}$ has at least two non-zero components due to Condition 2). This implies that $\lambda \cdot u' <0$ (by Condition 1). Then, $\lambda \cdot u'' = \lambda \cdot \tilde{u} - \lambda \cdot u'=- \lambda \cdot u' >0$; hence, $u'' \notin V$. Then $W^*_\lambda (\Delta) \geq \max\{ \lambda \cdot u', \lambda \cdot u'' \}>0.$
\end{proof}








\begin{lem}
\label{lem:nnn5}
When $\mathcal{A}^*_\lambda (\Delta )\subset S^C$ for some $\lambda$, the following strict inequality holds for some $m\in \{1,\dots,n-1\}$:\\
$$-\sum_{k=1}^m \Delta^{k-1} w_k (u^{[n]})  + \sum_{k=1}^m \Delta^{k-1} w_{n-m+k} (u^{[n]})<0.$$
\end{lem}
\begin{proof}
We use the proof-by-contradiction. Suppose that the above inequality does not hold for any $m$. Then, the following equation holds for all $m\in \{1,\dots,n-1\}$:
$$\sum_{k=1}^m \Delta^{k-1} w_k (u^{[n]})  - \sum_{k=1}^m \Delta^{k-1} w_{n-m+k} (u^{[n]})=0.$$
We claim that this implies $w_1(u^{[n]})=w_2(u^{[n]})=\cdots =w_n(u^{[n]})$. To show it, let us regard $w_n (u^{[n]})$ as a parameter (and the rest as unknowns) and observe that $w_1 (u^{[n]}) = w_n (u^{[n]}), \cdots, w_{n-1} (u^{[n]}) = w_n (u^{[n]})$ is a solution of the system. Next we argue that it is a unique solution. To see this, consider the submatrix consisting of the column 1 to $n-1$ of the coefficient matrix (i.e., the matrix consisting of the coefficients of the equations), which is an $(n-1) \times (n-1)$ matrix. Our purpose is to show that this has the full rank. Let $r_k$ be the $k$-th row of the submatrix, $k=1, \dots, n-1$. To show that this matrix is invertible, we show that $r_1, \dots, r_{n-1}$ are linearly independent, or equivalently we show that $(\alpha_k)_k \in \mathbb{R}^{n-1}$ satisfies $\sum_{k=1}^{n-1} \alpha_k r_k = \mathbf{0}$ if and only if $\alpha_k = 0$ for all $k$. 
By rearranging each column $l = 1, \dots, n-1$ of $\sum_{k=1}^{n-1} \alpha_k r_k =\mathbf{0}$, we have
\begin{align*}
(\alpha_1 + \cdots + \alpha_{n-1})  &=0,\\
\Delta (\alpha_2 + \cdots + \alpha_{n-1}) &=\alpha_{n-1},\\
\Delta^2 (\alpha_3 + \cdots + \alpha_{n-1}) &= \alpha_{n-2} + \Delta \alpha_{n-1},\\
\vdots\\
\Delta^{n-2} \alpha_{n-1} &= \alpha_2 + \cdots + \Delta^{n-3}  \alpha_{n-1}.
\end{align*}
Using $\alpha_1 + \alpha_2 + \cdots + \alpha_{n-1} =0$,
\begin{align*}
- \alpha_1 \Delta &= \alpha_{n-1},\\
- (\alpha_1 + \alpha_2) \Delta^2 &= \alpha_{n-2} + \alpha_{n-1} \Delta,\\
\vdots\\
- (\alpha_1 +  \cdots + \alpha_{n-2})\Delta^{n-2} &= \alpha_2 + \alpha_3 \Delta   + \cdots +  \alpha_{n-1}\Delta^{n-3}.\\
\end{align*}
By substituting each equation into the next, we have 
\begin{align*}
- \alpha_1 \Delta &= \alpha_{n-1},\\
- \alpha_2 \Delta^2 &= \alpha_{n-2},\\
\vdots\\
- \alpha_{n-2} \Delta^{n-2} &= \alpha_2.	
\end{align*}
Then, comparing the equations with the same variables (for instance, the second one with the last), we obtain $\alpha_2 =\alpha_3 = \cdots = \alpha_{n-2}=0$ and using the first equation and $\alpha_1 + \cdots + \alpha_{n-1}=0$, we have $\alpha_1 = \alpha_{n-1}=0$. This concludes the proof of the claim.





By the definition of each $w_k(u^{[n]})$ and the above claim, playing $(u^1,\cdots, u^1)$ yields the same $\lambda -$weighted score as by playing $u^{[n]}$. Therefore, $(u^1,\cdots, u^1)\in\mathcal{U}^* _{\lambda}(\Delta )$ must hold and there exists an action profile $a\in A$ which satisfies $u^1=u(a)$ and $(a,\cdots ,a)\in\mathcal{A}^*_\lambda (\Delta )$. This contradicts $\mathcal{A}^*_\lambda (\Delta )\subset S^C$, completing the proof.
\end{proof}


\begin{proof}[Proof of Proposition 1] 
Observe that Lemma 3 and Lemma 4 imply the following: $V\neq F^*$ holds if and only if for any $\Delta  \in (0,1)$, $F(\Delta )\neq V$ holds.	




Suppose that $\Delta  \in (0, 1)$ and $F^* \neq V$ so that $F(\Delta )\neq V$. Then, clearly for some $\lambda \neq 0$, $\mathcal{A}^*_\lambda (\Delta )\subset S^C$ holds. 
Then by Lemma 5, the inequality (4) strictly holds for at least one particular direction $\lambda \in \mathbb{R}^n \setminus \{ \mathbf{0} \}$ and it concludes the proof.
	
\end{proof}


\bibliography{FeasibleOLG_bib}
\bibliographystyle{chicago}


\end{document}
