\documentclass{FeasibleOLG_main.tex}{subfiles}

\begin{document}


We are interested in the set of payoffs that can be achieved by a sequence of action profiles in which every generation of players plays the same sequence of action profiles. We shall provide a complete characterization of this set, which allows us to obtain the feasible payoff set for any given $\delta$ and $T$.


\subsection{A complete characterization}


Hereafter, we focus on the payoffs of players in generation $d\geq 1$.\footnote{For $i \in N$, we refer to any player whose action set is $A_i$ as ``player $i$."} For $a^{[nT]}=(a^1,a^2,\cdots ,a^{nT})\in A^{nT}$, we define the average discounted payoff $U_i(a^{[nT]})$ of player $i$ as follows:
$$
U_i(a^{[nT]}):=\frac{1}{\sum _{k=1}^{nT}\delta ^{k-1}}\left(\sum _{k=1}^{nT}\delta ^{k-1}u_i(a^{(i-1)T+k}) \right),
$$
where $a^{s}=a^{s-nT}$ for $s\geq nT+1$. 

Since in the OLG repeated games, whether a payoff is feasible may depend on the observability of the results of PRDs before this player is born: Between any two overlaps, there is always some player who retires. The most permissible assumption is that players are able to observe all the previous outcomes of PRDs, which results in the following definition.
$$
F(\delta,T)=co \left(\bigcup _{a^{[nT]}\in A^{nT}}\{ U(a^{[nT]})\} \right).
$$
The RHS represents the feasible payoffs that can be achieved by PRD which arises every $nT$-period, which is the longest given stationary payoffs.


We will show that in fact any payoff in this set can be achieved under a weaker assumption that players only can observe the result of PRDs after they are born. 


	




It is convenient to introduce an additional notation. For $a^{[n]}=(a^1,a^2,\cdots ,a^n)\in A^n$ and $i\in N$, we define the value $v_i(a^{[n]})$ as follows: 
\begin{align*}
v_i(a^{[n]})&:=\frac{1}{\sum _{k=1}^n\delta ^{(k-1)T}}\left(\sum _{k=1}^n\delta ^{(k-1)T}u_i(a^{i+k-1}) \right),
%&= U_i (\underbrace{a^1,\dots, a^1}_{\text{$T$ times}}, a^2 \dots, a^2, \dots, a^n, \dots, a^n).	
\end{align*}
where $a^{s}=a^{s-n}$ for $s\geq n+1$. That is, $v_i (a^{[n]})$ is the average discounted payoff when players play the same action $a^k$ during the $k$-th overlap. Notice that this can be interpreted as the average discounted payoff over $n$ periods, where the ``effective'' discount factor is $\delta^T$.



\begin{them} 
\label{them:1}
For any $\delta \in (0,1]$ and $T \in \mathbb{N}$, 
\begin{equation}
\label{eq:nn1}
F(\delta,T) =co\left( \left \{v(a^{[n]}): {a^{[n]}\in A^n} \right \} \right).
\end{equation}


\end{them}



In words, the feasible payoff set is the convex hull of the average discounted payoffs of length-$n$ sequences of action profiles, each of which is to be played $T$ times. Notice that we could interpret the average discounted payoff of such a sequence of action profiles as the average discounted payoff of length-$n$ sequence of action profiles, discounted by $\delta^T$. 

The characterization is useful since it substantially reduces the number of sequences of action profiles we need to consider: regardless of $T$, it is sufficient to consider length-$n$ sequences. The result also means that $\delta$ and $T$ affect the feasible payoff set only through $\delta^T$. Thus, any $(\delta, T)$ and $(\delta', T')$ with $\delta^T ={\delta'}^{T'}$ would result in the same feasible payoff set. In \Cref{sec:5}, using this characterization we shall obtain $F(\delta, T)$ for two stage games, varying $\delta^T$.









One may wonder whether the RHS of \eqref{eq:nn1} suggests that the feasible payoffs may not be implemented under our assumption on the observability of PRDs. That is, we assumed that a result of a PRD is observed only by the contemporary generation, whereas for each $T$ period (i.e., overlap), there is a player to be replaced; so it might require a stronger informational assumption, for instance, the results of PRDs are observed also by future generations. In the proof, however, we construct a sequence of PRDs each of which is executed every overlap that generates the same average discounted payoff from a sequence of action profiles. 

The underlying idea of the proof is as follows: Within an overlap, no player retires so every player discounts their payoff at $t+1$ relatively more than payoff at $t$ in the overlap by $\delta$, although they discount payoffs differently depending on their ``age.'' This allows us to generate the same average discounted payoff for a given sequence of action profiles for a given overlap using a PRD at the beginning of this overlap, where the probability of playing a certain action profile during this overlap is determined in a way to mimic the sum of discounted payoffs whenever this action profile is played in the original sequence of action profiles.  On the other hand, across overlaps, some player should retire and for such a player the relative discounting between $t$ and $t+1$ is different, which makes a similar construction of a PRD between overlaps unavailable. 



\begin{proof}


We show 
$$ F(\delta,T) \subseteq co\left(\{v(a^{[n]}): {a^{[n]}\in A^n}\} \right) .$$
Consider an arbitrary sequence $a^{[nT]} = (a^1, \dots, a^{nT}) \in A^{nT}$. We claim that the same average discounted payoff can be obtained by a convex combination of ``$n$-length action sequences.'' 

To see this, we first claim that for each overlap $k=1, \dots n$, the average discounted payoff within the overlap can be achieved by playing constant action profiles resulting from a PRD. 

In each $k$-th overlap, the following PRD is exercised at the beginning of the overlap: An action profile $a \in A$ is randomly drawn with probability $\alpha^k (a)$ defined by 
$$\alpha^k (a) := \sum_{t=(k-1)T+1}^{kT} \frac{\delta^{t-1 - (k-1)T}}{ 1+ \dots + \delta^{T-1}}\mathbf{1}_{ \{{a}^t = {a} \}}.$$
Clearly, $\sum_{ a \in A} \alpha^k ({a}) = 1$. The players are supposed to play the realized action profile $a$ consecutively until the end of the overlap. To see that this PRD generates the same average discounted payoff as that of $a^{[nT]}$ for each player during the overlap, note that the PRD is constructed in that way so that it mimics discounting. Namely, if $a^t = a$ in $a^{ [nT]}$ for some $t  \in \{ 1, 2, \dots, T\}$, then the probability of playing $(a,\dots, a)$ increases by $\frac{\delta^{t-1- (k-1)T}}{\sum_{t=1}^T \delta^{t-1} }$. This construction is possible because no player retires within the overlap so that every player discounts $t+1$-period payoff by $\delta$ times than $t$-period payoff. This is not the case as long as some player retires and is reborn (i.e., across overlaps). 

Lastly, observe that the average discounted payoff of each player from this sequence of RPDs $(\alpha^1, \dots, \alpha^n)$ is a convex combination of $\{v(a^{[n]}):a^{[n]}\in A^n\}$, where the weight is $\alpha^1 (a^1)\times \cdots \times \alpha^n (a^n)$ for each $(a^1, \dots, a^n ) \in A^n$.

For the converse, observe that each element of $\{v(a^{[n]}):a^{[n]}\in A^n\}$ is in $F(\delta, T)$ and $F(\delta, T)$ is convex by definition. 

\begin{comment}

$2\Rightarrow 3$
$$\alpha^* (a_1, a_2) := \alpha^1 (a^1) \alpha^2 (a^2).$$
$$\frac{1}{1+ \delta^T} \sum_{a^1 \in A} \alpha^1 (a^1) u_1 (a^1) + \frac{\delta^T}{ 1+ \delta^T} \sum_{a^2 \in A} \alpha^2 (a^2)u_1 (a^2)$$
$$= \sum_{ (a^1, a^2) \in A^2} \alpha^1 (a^1) \alpha^2 (a^2) \left( \frac{1}{ 1+ \delta} u_1 (a^1) + \frac{\delta^T}{ 1+ \delta^T} u_1 (a^2) \right) $$

$$co\left(\bigcup _{a^{[n]}\in A^n}\{v(a^{[n]})\} \right) \subseteq F(\delta , T).$$

$3 \Rightarrow 2$

Let $w = \beta v(a^{[n]}) + (1- \beta) v (\tilde{a}^{[n]})$, where $a^{[n]} = (a^1, a^2, \dots, a^n)$ and $\tilde{a}^{[n]} = (\tilde{a}^1, \tilde{a}^2, \dots, \tilde{a}^n)$, and $\beta \in [0,1]$.  


Let 
$$\hat{a}^k : = \beta a^k \oplus (1-\beta) \tilde{a}^k, \quad  \forall k = 1, \dots, n$$
and so 
$$u( \hat{a}^k) = \beta u(a^k) + (1-\beta) u(\tilde{a}^k) \in V$$
for each $k$. It is not difficult to see that playing $(\hat{a}^1, \cdots, \hat{a}^n)$ gives the average discounted payoff of $w$. 

This means that we don't need a stronger assumption on the observability of PRDs.
\end{comment}

\begin{comment}
Observe that
$$w_1 = \frac{1}{ 1+ \delta} ( \beta u_1 (a^1) + (1-\beta) u_1 (\tilde{a}^1)) + \frac{\delta}{1+\delta} (\beta u_1 (a^2) + (1-\beta) u_1 (\tilde{a}^2)) $$ 
$$w_2 = \frac{\delta}{ 1+ \delta} ( \beta u_2 (a^1) + (1- \beta) u_2 (\tilde{a}^1))  + \frac{1}{1+\delta} (\beta u_2 (a^2 ) + (1-\beta) u_2 (\tilde{a}^2)).$$
Note that 
$$( \beta u_1 (a^1) + (1-\beta) u_1 (\tilde{a}^1), \beta u_2 (a^1) + (1- \beta) u_2 (\tilde{a}^1))) \in V $$
$$(\beta u_1 (a^2) + (1-\beta) u_1 (\tilde{a}^2),\beta u_2 (a^2 ) + (1-\beta) u_2 (\tilde{a}^2)) \in V.$$
	
\end{comment}




\begin{comment}
Daehyun (9/23): * For the time being, let me prove when $n=2$ for simple exposition. After I wrote the proof, it looks trivial, though.

Let $w = \beta v(a^{[2]}) + (1- \beta) v (\tilde{a}^{[2]})$, where $a^{[2]} = (a^1, a^2)$ and $\tilde{a}^{[2]} = (\tilde{a}^1, \tilde{a}^2)$, and $\beta \in [0,1]$.  
$$w_1 = \beta \left( \frac{1}{1+ \delta} u_1 (a^1) + \frac{ \delta}{ 1+ \delta} u_1 (a^2) \right) + (1-\beta) \left( \frac{1}{1+ \delta} u_1 (\tilde{a}^1) + \frac{ \delta}{ 1+ \delta} u_1 (\tilde{a}^2)\right) $$ 
and 
$$w_2 = \beta \left( \frac{\delta}{1+ \delta} u_2 (a^1) + \frac{ 1}{ 1+ \delta} u_2 (a^2) \right) + (1-\beta) \left( \frac{\delta}{1+ \delta} u_2 (\tilde{a}^1) + \frac{ 1}{ 1+ \delta} u_2 (\tilde{a}^2)\right) $$ 
Observe that
$$w_1 = \frac{1}{ 1+ \delta} ( \beta u_1 (a^1) + (1-\beta) u_1 (\tilde{a}^1)) + \frac{\delta}{1+\delta} (\beta u_1 (a^2) + (1-\beta) u_1 (\tilde{a}^2)) $$ 
$$w_2 = \frac{\delta}{ 1+ \delta} ( \beta u_2 (a^1) + (1- \beta) u_2 (\tilde{a}^1))  + \frac{1}{1+\delta} (\beta u_2 (a^2 ) + (1-\beta) u_2 (\tilde{a}^2)).$$
Note that 
$$( \beta u_1 (a^1) + (1-\beta) u_1 (\tilde{a}^1), \beta u_2 (a^1) + (1- \beta) u_2 (\tilde{a}^1))) \in V $$
$$(\beta u_1 (a^2) + (1-\beta) u_1 (\tilde{a}^2),\beta u_2 (a^2 ) + (1-\beta) u_2 (\tilde{a}^2)) \in V.$$	
\end{comment}


\end{proof}


\begin{comment}
	\subsection{Simple Characterization with Large $T$ (Generic Pareto-frontier, 2-player Case)}

\textcolor{red}{Daehyun: maybe we omit this part.}

Let $L\geq 2$, $x_1>x_2>\cdots >x_L=0$, and $0=y_1<y_2<\cdots <y_L$. And let $V=co(\{ (0,\ 0)\}\cup\bigcup _{1\leq l\leq L}\{ (x_l,\ y_l)\})$. The one-shot Pareto-frontier of this game has negative slopes. Let $E=co(\{ (0,\ 0),\ (x_1,\ y_1),\ (x_L,\ y_L)\} )\setminus co(\{ (x_1,\ y_1)\},\ \{ (x_L,\ y_L)\})$. For $1\leq l\leq L$, let $H_l=\{ \frac{1}{1+\delta ^T}(x_1+\delta ^Tx_l,\ y_l+\delta ^Ty_1)\}$ and for $2\leq l\leq L$, let $H_{L+l-1}=\{\frac{1}{1+\delta ^T}(x_l+\delta ^Tx_L,\ y_L+\delta ^Ty_l)\}$, and let $H=\bigcup _{1\leq l\leq 2L-1}H_l$.
\begin{eqnarray}
(i)\ F^{\delta ,T}=E\cup co(H),\ and
\end{eqnarray}
\begin{eqnarray}
(ii)\ E\cup co(H\setminus H_l)\neq F^{\delta ,T}\ for\ 1\leq l\leq 2L-1.
\end{eqnarray}

We prove (ii). It suffices to show that each point in $H$ is Pareto-optimal.
\begin{eqnarray}
x_1>\frac{1}{1+\delta ^T}(x_1+\delta ^Tx_2)>\cdots >\frac{1}{1+\delta ^T}(x_1+\delta ^Tx_L)>\frac{1}{1+\delta ^T}(x_2+\delta ^Tx_L)>\cdots >\frac{1}{1+\delta ^T}(x_{L-1}+\delta ^Tx_L)>x_L,
\end{eqnarray}
\begin{eqnarray}
y_1<\frac{1}{1+\delta ^T}(y_2+\delta ^Ty_1)<\cdots <\frac{1}{1+\delta ^T}(y_L+\delta ^Ty_1)<\frac{1}{1+\delta ^T}(y_L+\delta ^Ty_2)<\cdots <\frac{1}{1+\delta ^T}(y_L+\delta ^Ty_{L-1})<y_L.
\end{eqnarray}
\end{comment}





\subsection{Limit Characterization}

For the asymptotic cases (i.e., $\delta^T \to 1$ or $\delta^T \to 0$), we can say more about the shape of the feasible payoff set. 

\begin{coro}
The following hold:
\begin{enumerate}
\item For $\delta^T$ sufficiently large, in each period, players play the same action profile at the optimum. In addition, $\lim_{ \delta^T \to 1} F(\delta, T) = V.$
	\item For $\delta^T$ sufficiently close to 0, in each period, players play an action profile that maximizes the youngest player's payoff at the optimum. In addition, $\lim _{\delta^T\rightarrow 0}F(\delta, T)=  \prod _{i\in N} \left [\min _{a\in A}u_i(a),\ \max _{a\in A}u_i(a) \right]$.	 	
\end{enumerate}

\end{coro}

Thus, for any $\delta \in (0,1)$, as $T \to \infty$, the feasible set converges to the $n$-dimensional cube. Similarly, for any $T$, as $\delta \to 0$, the feasible set converges to the $n$-dimensional cube. 





\begin{proof}
Choose any $v\in \prod _{i\in N}[\min _{a\in A}u_i(a),\ \max _{a\in A}u_i(a)]$. For each $i$, there exists a vector $w^i\in V$ which satisfies $w^i_i=v_i$. When $i$ is the youngest, players play correlated actions which generate $w^i_i$. Such sequence converges to $v$ as $T\rightarrow\infty$.	
\end{proof}






\end{document}
