{
    "arxiv_id": "2303.16214",
    "paper_title": "Tetra-AML: Automatic Machine Learning via Tensor Networks",
    "authors": [
        "A. Naumov",
        "Ar. Melnikov",
        "V. Abronin",
        "F. Oxanichenko",
        "K. Izmailov",
        "M. Pflitsch",
        "A. Melnikov",
        "M. Perelshtein"
    ],
    "submission_date": "2023-03-28",
    "revised_dates": [
        "2025-02-14"
    ],
    "latest_version": 1,
    "categories": [
        "cs.LG",
        "quant-ph"
    ],
    "abstract": "Neural networks have revolutionized many aspects of society but in the era of huge models with billions of parameters, optimizing and deploying them for commercial applications can require significant computational and financial resources. To address these challenges, we introduce the Tetra-AML toolbox, which automates neural architecture search and hyperparameter optimization via a custom-developed black-box Tensor train Optimization algorithm, TetraOpt. The toolbox also provides model compression through quantization and pruning, augmented by compression using tensor networks. Here, we analyze a unified benchmark for optimizing neural networks in computer vision tasks and show the superior performance of our approach compared to Bayesian optimization on the CIFAR-10 dataset. We also demonstrate the compression of ResNet-18 neural networks, where we use 14.5 times less memory while losing just 3.2% of accuracy. The presented framework is generic, not limited by computer vision problems, supports hardware acceleration (such as with GPUs and TPUs) and can be further extended to quantum hardware and to hybrid quantum machine learning models.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.16214v1"
    ],
    "publication_venue": null,
    "doi": "10.3390/app15041852"
}