@article{NetWotkCompression,
  doi = {10.48550/ARXIV.2006.03669},
  
  url = {https://arxiv.org/abs/2006.03669},
  
  author = {Neill, James O'},
  
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {An Overview of Neural Network Compression},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{pruning,
author = {Anwar, Sajid and Hwang, Kyuyeon and Sung, Wonyong},
title = {Structured Pruning of Deep Convolutional Neural Networks},
year = {2017},
issue_date = {July 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {3},
issn = {1550-4832},
url = {https://doi.org/10.1145/3005348},
doi = {10.1145/3005348},
journal = {J. Emerg. Technol. Comput. Syst.},
articleno = {32},
numpages = {18},
keywords = {feature map pruning, Deep convolutional neural networks, structured pruning, intra-kernel strided sparsity}
}

@Article{IoT,
author={Kumar, Sachin
and Tiwari, Prayag
and Zymbler, Mikhail},
title={Internet of Things is a revolutionary approach for future technology enhancement: a review},
journal={Journal of Big Data},
year={2019},
day={09},
volume={6},
number={1},
pages={111},
issn={2196-1115},
doi={10.1186/s40537-019-0268-2},
url={https://doi.org/10.1186/s40537-019-0268-2}
}

@article{AlexNet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
  journal={Advances in Neural Information Processing Systems},
  volume={25},
  pages={1097--1105},
  year={2012},
  doi={10.1145/3065386},
  url={https://doi.org/10.1145/3065386}
}

@article{pruning_quantization,
  title={A survey of model compression and acceleration for deep neural networks},
  author={Cheng, Yu and Wang, Duo and Zhou, Pan and Zhang, Tao},
  journal={arXiv preprint arXiv:1710.09282},
  year={2017}
}

@article{increasing_costs,
Author = {Chen Sun and Abhinav Shrivastava and Saurabh Singh and Abhinav Gupta},
Title = {Revisiting Unreasonable Effectiveness of Data in Deep Learning Era},
Year = {2017},
Eprint = {arXiv:1707.02968},
}

@article{dalle,
Author = {Aditya Ramesh and Prafulla Dhariwal and Alex Nichol and Casey Chu and Mark Chen},
Title = {Hierarchical Text-Conditional Image Generation with CLIP Latents},
Year = {2022},
Eprint = {arXiv:2204.06125},
}

@article{Quantization,
  title={A white paper on neural network quantization},
  author={Nagel, Markus and Fournarakis, Marios and Amjad, Rana Ali and Bondarenko, Yelysei and Van Baalen, Mart and Blankevoort, Tijmen},
  journal={arXiv preprint arXiv:2106.08295},
  year={2021}
}

@article{PruningProblems,
  doi = {10.48550/ARXIV.2009.08576},
  
  url = {https://arxiv.org/abs/2009.08576},
  
  author = {Frankle, Jonathan and Dziugaite, Gintare Karolina and Roy, Daniel M. and Carbin, Michael},
  
  keywords = {Machine Learning (cs.LG), Computer Vision and Pattern Recognition (cs.CV), Neural and Evolutionary Computing (cs.NE), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Pruning Neural Networks at Initialization: Why are We Missing the Mark?},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{NAS,
  title={An introduction to neural architecture search for convolutional networks},
  author={Kyriakides, George and Margaritis, Konstantinos},
  journal={arXiv preprint arXiv:2005.11074},
  year={2020}
}

@article{UsingDL,
author = {Maeda, Iwao and deGraw, David and Kitano, Michiharu and Matsushima, Hiroyasu and Sakaji, Hiroki and Izumi, Kiyoshi and Kato, Atsuo},
year = {2020},
pages = {71},
title = {Deep Reinforcement Learning in Agent Based Financial Market Simulation},
volume = {13},
journal = {Journal of Risk and Financial Management},
doi = {10.3390/jrfm13040071}
}

@article{Bayesian,
  doi = {10.48550/ARXIV.1910.11858},
  
  url = {https://arxiv.org/abs/1910.11858},
  
  author = {White, Colin and Neiswanger, Willie and Savani, Yash},
  
  keywords = {Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {BANANAS: Bayesian Optimization with Neural Architectures for Neural Architecture Search},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{he2021automl,
  title={{AutoML: A survey of the state-of-the-art}},
  author={He, Xin and Zhao, Kaiyong and Chu, Xiaowen},
  journal={Knowledge-Based Systems},
  volume={212},
  pages={106622},
  year={2021},
  publisher={Elsevier}
}

@book{audet2017_black_box,
  title={Derivative-free and blackbox optimization},
  author={Audet, Charles and Hare, Warren},
  volume={2},
  year={2017},
  publisher={Springer}
}

@article{sozykin2022ttopt,
  title={TTOpt: A Maximum Volume Quantized Tensor Train-based Optimization and its Application to Reinforcement Learning},
  author={Sozykin, Konstantin and Chertkov, Andrei and Schutski, Roman and Phan, Anh-Huy and Cichocki, Andrzej and Oseledets, Ivan},
  journal={arXiv preprint arXiv:2205.00293},
  year={2022}
}


@article{lebedev2014_tt_cnn,
  title={Speeding-up convolutional neural networks using fine-tuned cp-decomposition},
  author={Lebedev, Vadim and Ganin, Yaroslav and Rakhuba, Maksim and Oseledets, Ivan and Lempitsky, Victor},
  journal={arXiv preprint arXiv:1412.6553},
  year={2014}
}

@article{novikov2015tensorizing,
  title={Tensorizing neural networks},
  author={Novikov, Alexander and Podoprikhin, Dmitrii and Osokin, Anton and Vetrov, Dmitry P},
  journal={Advances in Neural Information Processing Systems},
  volume={28},
  year={2015}
}

@article{NATS,
	doi = {10.1109/tpami.2021.3054824},
  
	url = {https://doi.org/10.1109%2Ftpami.2021.3054824},
  
	year = 2021,
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  
	pages = {1--1},
  
	author = {Xuanyi Dong and Lu Liu and Katarzyna Musial and Bogdan Gabrys},
  
	title = {{NATS}-Bench: Benchmarking {NAS} Algorithms for Architecture Topology and Size},
  
	journal = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence}
}

@article{lee2021qttnet,
  title={{QTTNet: Quantized tensor train neural networks for 3D object and video recognition}},
  author={Lee, Donghyun and Wang, Dingheng and Yang, Yukuan and Deng, Lei and Zhao, Guangshe and Li, Guoqi},
  journal={Neural Networks},
  volume={141},
  pages={420--432},
  year={2021},
  publisher={Elsevier}
}

@article{oseledets2011tensor,
  title={Tensor-train decomposition},
  author={Oseledets, Ivan V},
  journal={SIAM Journal on Scientific Computing},
  volume={33},
  number={5},
  pages={2295--2317},
  year={2011},
  publisher={SIAM}
}

@inproceedings{falkner2018bohb,
  title={BOHB: Robust and efficient hyperparameter optimization at scale},
  author={Falkner, Stefan and Klein, Aaron and Hutter, Frank},
  booktitle={International Conference on Machine Learning},
  pages={1437--1446},
  year={2018},
  organization={PMLR}
}

@article{TQ_whitepaper,
  title={Practical application-specific advantage through hybrid quantum computing},
  author={Perelshtein, Michael and Sagingalieva, Asel and Pinto, Karan and Shete, Vishal and Pakhomchik, Alexey and Melnikov, Artem and Neukart, Florian and Gesek, Georg and Melnikov, Alexey and Vinokur, Valerii},
  journal={arXiv preprint arXiv:2205.04858},
  year={2022}
}
@article{biamonte2017_QML,
  title={Quantum machine learning},
  author={Biamonte, Jacob and Wittek, Peter and Pancotti, Nicola and Rebentrost, Patrick and Wiebe, Nathan and Lloyd, Seth},
  journal={Nature},
  volume={549},
  number={7671},
  pages={195--202},
  year={2017},
  publisher={Nature Publishing Group UK London}
}

@article{melnikov2023_QML,
author = {Alexey Melnikov and Mohammad Kordzanganeh and Alexander Alodjants and Ray-Kuang Lee},
title = {Quantum machine learning: from physics to software engineering},
journal = {Advances in Physics: X},
volume = {8},
number = {1},
pages = {2165452},
year  = {2023},
publisher = {Taylor & Francis},
doi = {10.1080/23746149.2023.2165452}
}

@article{sagingalieva2022hyperparameter,
  title={Hyperparameter optimization of hybrid quantum neural networks for car classification},
  author={Sagingalieva, Asel and Kurkin, Andrii and Melnikov, Artem and Kuhmistrov, Daniil and Perelshtein, Michael and Melnikov, Alexey and Skolik, Andrea and Von Dollen, David},
  journal={arXiv preprint arXiv:2205.04878},
  year={2022}
}

@article{sagingalieva2022_QML_drug,
  title={Hybrid quantum neural network for drug response prediction},
  author={Sagingalieva, Asel and Kordzanganeh, Mohammad and Kenbayev, Nurbolat and Kosichkina, Daria and Tomashuk, Tatiana and Melnikov, Alexey},
  journal={arXiv preprint arXiv:2211.05777},
  year={2022}
}

@article{ML_overview,
    title = {Machine learning: Trends, perspectives, and prospects},
    author = {M. I. Jordan  and T. M. Mitchell },
    journal = {Science},
    volume = {349},
    number = {6245},
    pages = {255-260},
    year = {2015},
    doi = {10.1126/science.aaa8415},
    URL = {https://www.science.org/doi/abs/10.1126/science.aaa8415},
    eprint = {https://www.science.org/doi/pdf/10.1126/science.aaa8415},
    abstract = {Machine learning addresses the question of how to build computers that improve automatically through experience. It is one of todayâ€™s most rapidly growing technical fields, lying at the intersection of computer science and statistics, and at the core of artificial intelligence and data science. Recent progress in machine learning has been driven both by the development of new learning algorithms and theory and by the ongoing explosion in the availability of online data and low-cost computation. The adoption of data-intensive machine-learning methods can be found throughout science, technology and commerce, leading to more evidence-based decision-making across many walks of life, including health care, manufacturing, education, financial modeling, policing, and marketing.}
}

@article{rainjonneau2023quantum,
  title={Quantum algorithms applied to satellite mission planning for {E}arth observation},
  author={Rainjonneau, Serge and Tokarev, Igor and Iudin, Sergei and Rayaprolu, Saaketh and Pinto, Karan and Lemtiuzhnikova, Daria and Koblan, Miras and Barashov, Egor and Kordzanganeh, Mohammad and Pflitsch, Markus and others},
  journal={arXiv preprint arXiv:2302.07181},
  year={2023}
}

@article{morozov2023protein,
  title={Protein-protein docking using a tensor train black-box optimization method},
  author={Morozov, Dmitry and Melnikov, Artem and Shete, Vishal and Perelshtein, Michael},
  journal={arXiv preprint arXiv:2302.03410},
  year={2023}
}

@inproceedings{sevilla2022compute,
  title = {Compute trends across three eras of machine learning},
  author = {Sevilla, Jaime and Heim, Lennart and Ho, Anson and Besiroglu, Tamay and Hobbhahn, Marius and Villalobos, Pablo},
  booktitle = {2022 International Joint Conference on Neural Networks (IJCNN)},
  pages = {1--8},
  year = {2022},
  organization = {IEEE}
}

@article{patterson2021carbon,
  title = {Carbon emissions and large neural network training},
  author = {Patterson, David and Gonzalez, Joseph and Le, Quoc and Liang, Chen and Munguia, Lluis-Miquel and Rothchild, Daniel and So, David and Texier, Maud and Dean, Jeff},
  journal = {arXiv preprint arXiv:2104.10350},
  year = {2021}
}


@inproceedings{tjandra2017rnn,
  title={Compressing recurrent neural network with tensor train},
  author={Tjandra, Andros and Sakti, Sakriani and Nakamura, Satoshi},
  booktitle={2017 International Joint Conference on Neural Networks (IJCNN)},
  pages={4451--4458},
  year={2017},
  organization={IEEE}
}

@inproceedings{pham2022_transformer,
  title={{TT}-{V}i{T}: Vision Transformer Compression Using Tensor-Train Decomposition},
  author={Pham Minh, Hoang and Nguyen Xuan, Nguyen and Tran Thai, Son},
  booktitle={Computational Collective Intelligence: 14th International Conference, ICCCI 2022, Hammamet, Tunisia, September 28--30, 2022, Proceedings},
  pages={755--767},
  year={2022},
  organization={Springer}
}