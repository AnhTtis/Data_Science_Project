\section{Experiments and Results}
\begin{table}[hbt]
    \centering
    \small
    \begin{tabular}{cccc}
    \toprule
        Input Feature & Feed Forward & Heads & Layers\\
    \midrule
        32 & 64 & 8 & 6\\
        64 & 128 & 8 & 8\\ 
        128 & 256 & 8 & 8\\
        128 & 256 & 8 & 6\\
        128 & 256 & 2 & 8\\
        256 & 512 & 2 & 6\\
        256 & 256 & 4 & 8\\
        512 & 1024 & 2 & 4\\
        512 & 256 & 2 & 12\\
    \bottomrule
        \underline{768} & \underline{256} & \underline{2} & \underline{3}
    \end{tabular}
    \caption{A set of parameters for SnakeVoxFormer}\label{tab:ablation}\vspace{-3mm}
\end{table}

\subsection{Ablation}
We performed several ablation experiments and  decided to use three layers, 768 as the size of input features and 256 as the dimension of the feed-forward network. We use two heads in the multi-head-attention layers. We set the dropout rate to 0.2 to avoid over-fitting (see Tab.~\ref{tab:ablation}).

We perform an extensive parameter search to provide the best performance. We found that  if the number of heads is greater than four, models start to generate incorrect results and it does not even perform well on the training data. We also test it by increasing the number of layers, but the model started to overfit the training data quickly.

\subsection{Metric}
We tested the four trained models for 4, 8, 16, and 20 different view images of a single object. We computed the performance based on Intersection over Union (IoU) between the ground truth voxels and reconstructed voxels using the trained models. A higher IoU corresponds to a better reconstruction performance. We define IoU as:
\begin{equation}
    IoU = 
    \frac{\Sigma_{(i,j,k)} I(y(i,j,k))I(\hat{y}(i,j,k))}{\Sigma_{(i,j,k)}I(I(y(i,j,k))+I(\hat{y}(i,j,k))  )}
\end{equation}
where, $y(i,j,k)$ is a generated occupancy voxel and $\hat{y}(i,j,k)$ is a ground truth voxel and $I(\cdot)$ represent an indicator function.

We used 130,060, 399,380, and 78,000 images to train models using Snake, Raster Scanning, and Spiral indexing traversal for 13 categories.

We tested our models from 1,300 images from unseen data during the training process and report average IoU values per different views in Tab.~\ref{tab:comparison}. We also provide detailed IoU values for each category from models that are trained on different views in Tab.~\ref{tab:detailedMetricSnake}, Tab.~\ref{tab:detailedMetricRaster} and Tab.~\ref{tab:detailedMetricSpiral}.

\begin{table}[hbt]
    \centering
    \small
    \begin{tabular}{lcccc}
    \toprule
        IoU/Views & 4 & 8 & 16 & 20 \\
    \midrule
        3D-R2N2~\cite{3dr2n2}  & 0.625 & 0.635 & 0.636 & 0.636\\
        AttSets~\cite{yang2020robust} &  0.675 & 0.685 & 0.688 & 0.693 \\ 
        Pix2Vox-A~\cite{pix2vox}  &  0.697 & 0.702 & 0.705 & 0.706\\
        Pix2Vox++/A~\cite{pix2voxpp}  &  0.708 & 0.715 & 0.718 & 0.719\\
        VoIT~\cite{wang2021multi}  &  0.605 & 0.681 & 0.706 & 0.711\\
        VoIT+~\cite{wang2021multi}  &  0.695 & 0.707 & 0.714 & 0.715\\
        EVoIT~\cite{wang2021multi} &  0.609 & 0.698 & \underline{0.729} & \underline{0.735}\\
        TMVNet~\cite{TMVNet} & \underline{0.718} & \underline{0.719} & 0.721 & - \\
    \bottomrule
        Ours (Snake) &  \textbf{0.843} & \textbf{0.874} & \textbf{0.904} & 0.912\\
        Ours (Raster) &  0.746 & 0.834 & 0.865 & 0.861\\
        Ours (Spiral) &  0.829 & 0.864 & 0.889 & \textbf{0.933}\\
    \end{tabular}
    \caption{Mean IoU metrics for 13 categories.}\label{tab:comparison}\vspace{-3mm}
\end{table}
\subsection{Result}
Figure.~\ref{fig:generation_result} shows examples of 3D voxels generated by SnakeVoxFormer and Table~\ref{tab:comparison} shows the comparison to eight models include 3D-R2N2~\cite{3dr2n2}, AttSets~\cite{yang2020robust}, Pix2Vox-A~\cite{pix2vox}, Pix2Vox++/A~\cite{pix2voxpp}, VoIT~\cite{wang2021multi}, VoIT+~\cite{wang2021multi}, EVoIT~\cite{wang2021multi}, and TMVNet~\cite{TMVNet}.
We underline the state-of-the-art performance of the previous works and we put our performance in bold text at the bottom line. 

Table.~\ref{tab:comparison} shows that our models have a higher mean IoU value compared to previous works.

We compare the snake and spiral traversal strategies in Tab.~\ref{tab:comparison}. We show the percentage differences between our metrics and the best values from the previous works. Our snake model scores  12.5\%, 15.5\%, 17.5\%, and 17.7\% better than TMVNet~\cite{TMVNet}, TMVNet~\cite{TMVNet}, EVoIT~\cite{wang2021multi}, EVoIT~\cite{wang2021multi} in 3D reconstruction using 4, 8, 16, 20 views reconstruction respectively.
\begin{table}[hbt]
    \centering
    \small
    \begin{tabular}{cllll}
    \toprule
        Category(IoU) & 4 Views& 8 Views& 16 Views& 20 Views\\
    \midrule
        airplane  & 0.7506 & 0.7882 & 0.8805 & 0.8786\\
        bench  &  0.8694 & 0.8960 & 0.9311 & 0.9349\\ 
        cabinet  &  0.9095 & 0.9511 & 0.9621 & 0.9531\\
        car  &  0.9074 & 0.9411 & 0.9582 & 0.9671\\
        chair  &  0.8521 & 0.8860 & 0.9348 & 0.9327\\
        display  &  0.7551 & 0.8210 & 0.8576 & 0.9092\\
        lamp &  0.8658 & 0.8756 & 0.8718 & 0.8746\\
        speaker &  0.8240 & 0.8588 & 0.9010 & 0.9321\\
        rifle &  0.7276 & 0.7538 & 0.7838 & 0.7875\\
        sofa &  0.8930 & 0.9067 & 0.9025 & 0.9444\\
        table &  0.8844 & 0.9221 & 0.9249 & 0.9607\\
        telephone &  0.9070 & 0.9296 & 0.9480 & 0.9044\\
        watercraft &  0.8173 & 0.8255 & 0.8896 & 0.8742\\
    \bottomrule
        Overall &  0.8433 & 0.8735 & 0.9035 & 0.9118\\
    \end{tabular}
    \caption{IoU metrics per category using Snake Traversal method.}\label{tab:detailedMetricSnake}\vspace{-3mm}
\end{table}

\begin{table}[hbt]
    \centering
    \small
    \begin{tabular}{cllll}
    \toprule
        Category(IoU) & 4 Views& 8 Views& 16 Views& 20 Views\\
    \midrule
        airplane  & 0.660 & 0.793 & 0.822 & 0.798\\
        bench  &  0.776 & 0.840 & 0.875 & 0.911 \\ 
        cabinet  &  0.816 & 0.875 & 0.910 & 0.896\\
        car  &  0.757 & 0.855 & 0.883 & 0.871\\
        chair  &  0.724 & 0.833 & 0.868 & 0.858\\
        display  &  0.646 & 0.790 & 0.816 & 0.805\\
        lamp &  0.823 & 0.897 & 0.934 & 0.940\\
        speaker &  0.771 & 0.867 & 0.887 & 0.893\\
        rifle &  0.630 & 0.731 & 0.743 & 0.706\\
        sofa &  0.801 & 0.849 & 0.897 & 0.879\\
        table &  0.783 & 0.864 & 0.882 & 0.924\\
        telephone &  0.811 & 0.863 & 0.886 & 0.888\\
        watercraft &  0.695 & 0.788 & 0.845 & 0.826\\
    \bottomrule
        Overall &  0.746 & 0.834 & 0.865 & 0.861\\
    \end{tabular}
    \caption{IoU metrics per category using Raster Scanning Traversal method.}\label{tab:detailedMetricRaster}\vspace{-3mm}
\end{table}

\begin{table}[hbt]
    \centering
    \small
    \begin{tabular}{cllll}
    \toprule
        Category(IoU) & 4 Views& 8 Views& 16 Views& 20 Views\\
    \midrule
        airplane  & 0.737 & 0.796 & 0.829 & 0.907\\
        bench  &  0.727 & 0.844 & 0.877 & 0.933 \\ 
        cabinet  &  0.893 & 0.886 & 0.915 & 0.957\\
        car  &  0.917 & 0.936 & 0.923 & 0.970\\
        chair  &  0.816 & 0.851 & 0.860 & 0.931\\
        display  &  0.842 & 0.818 & 0.869 & 0.899\\
        lamp &  0.896 & 0.914 & 0.939 & 0.957\\
        speaker &  0.891 & 0.895 & 0.931 & 0.927\\
        rifle &  0.790 & 0.793 & 0.837 & 0.887\\
        sofa &  0.778 & 0.869 & 0.897 & 0.983\\
        table &  0.807 & 0.890 & 0.915 & 0.920\\
        telephone &  0.855 & 0.895 & 0.894 & 0.917\\
        watercraft &  0.883 & 0.844 & 0.871 & 0.947\\
    \bottomrule
        Overall &  0.829 & 0.864 & 0.889 & 0.933\\
    \end{tabular}
    \caption{IoU metrics per category using Spiral Traversal method.}\label{tab:detailedMetricSpiral}\vspace{-3mm}
\end{table}


\begin{figure*}[hbt]
\centering
\includegraphics[width=0.95\linewidth,height=\textheight,keepaspectratio]{images/result.pdf}
  \caption{3D reconstruction results on ShapeNet from our trained model. The left column is the input image, the middle column is the ground truth voxel and the right column shows our reconstructed  voxel.}\vspace{-3mm}
  \label{fig:generation_result}
\end{figure*}
