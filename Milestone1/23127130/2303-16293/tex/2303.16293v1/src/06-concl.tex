\section{Conclusion}
\begin{figure}[hbt]
\centering
\includegraphics[width=0.99\linewidth,height=0.5\textheight,keepaspectratio]{images/failure.pdf}
  \caption{Our model fails on small parts of objects. Input image (left), ground truth (middle), SnakeVoxFormer (right).}\vspace{-3mm}
  \label{fig:failure}
\end{figure}
We introduced SnakeVoxFormer, a transformer-based 3D reconstruction that traverses 3D space and Run Length Encodes the voxel. Our algorithm uses lossless compression of the ShapeNet dataset to only around 1\% of its original size while encoding the RLE chunks into tokens suitable for NLP-based training. Moreover, we show that SnakeVoxFormer outperforms the new state-of-the-art algorithms for multi-view reconstruction from 2D images to voxels.

One of the limitations of our model is that RLE assumes non-noisy structures that make SnakeVoxFormer suitable for man-made objects. Also, our method fails on small structures such as sharp edges and small object parts. Another limitation is that it is suitable only for individual objects (see Fig.~\ref{fig:failure}).

Possible future work includes exploring different traversing strategies and their effect on the overall model performance. It would also be interesting to see how our method would generalize for the entire scene.

We will provide the source code of SnakeVoxFormer.