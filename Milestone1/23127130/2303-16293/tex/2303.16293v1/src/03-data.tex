\section{Overview}
The input to SnakeVoxFormer (see the overview in Fig.~\ref{fig:overview}) is an RGB image of a single object, and the output is its voxel representation. In the first step, we resize the image to $224\times{2}24$ and input it to the encoder, which is a pre-trained Vision Transformer based on ImageNet in order to  extract image features. The image features are then input to the decoder, which is a transformer with two attention heads that generate the RLE tokens. We then use the dictionary-based encoding (the codebook) (see Tab.~\ref{tab:codebook}) that contains indices to the RLE codes that are then used as reference values. The output of SnakeVoxFormer is a set of tokens that are then used to reconstruct the 3D voxel fully.

\begin{figure*}[hbt]
\centering
\includegraphics[width=0.95\linewidth]{images/shapenet_images.pdf}
  \caption{Images from ShapeNet. Top row: airplane, bench, cabinet, car, cellphone, chair.
  Bottom row: couch, firearm, lamp, monitor, table, speaker}\vspace{-3mm}
  \label{fig:inputImage}
\end{figure*}

\section{Data Preprocessing}\label{section:preproc}
We use all 13 categories of objects (airplane, bench, cabinet, car, chair, monitor, lamp, speaker, firearm, couch, table, cellphone, and watercraft)  from the ShapeNet dataset~\cite{shapenet} (see Fig.~\ref{fig:inputImage}). Each object is viewed from 24 different angles. We store the pairs i.e., the image and the voxel representation, for training.

The voxel data is stored in the Binvox file format  $32^3$ (width $\times$ depth $\times$ height). The voxels are sparse, so we compress them in a linear array as RLE (Sec.~\ref{section:RLE}) and we report the compression factor in Tab.~\ref{tab:compressionFactor}.

The RLE-encoded sequences (see Sec.~\ref{section:token}) are analyzed, and repeating sequences are substituted by tokens that are used for the transformer training. Removing the duplicities further reduces the  size of the dataset, which improves learning as compared to learning the raw RLE string with numerous duplicates.

\subsection{Run Length Encoding of Voxels}\label{section:RLE}
RLE~\cite{RLE} stores the data as a sequence of couples of numbers $[rep,val]$, where~$rep$ indicates the number of repetitions and~$val$ the voxel value, so e.g., the couple $[7,0]$ indicates seven consecutive empty voxels. Note that this compression is lossless and symmetric i.e., compression and decompression have the same complexity $\mathcal{O}(n)$, where $n$ is the length of the encoded sequence.
\begin{figure}[hbt]
\centering
\includegraphics[width=0.99\linewidth]{images/spiral_direction.pdf}
\caption{Different traversing strategies used for the RLE: a spiral, snake, and raster style scanning.}\vspace{-3mm}  \label{fig:traversal}
\end{figure}

\textbf{Voxel space traversing:} The key to the linearization of the 3D voxel space is its traversing and we have experimented with three different strategies in our approach (Fig.~\ref{fig:traversal}). At each location, the entire array is parsed in the $z$-axis and the voxels are RL encoded. The arrow indicates what is the next column to be encoded.

The first strategy starts on the outer border and spirals down to the center of the voxel space. The second strategy traverses the voxel space like a snake, and the third strategy mimics the scan algorithm of CRT monitors by starting each new line at the beginning. We compare these strategies in Tab.~\ref{tab:RLEcomparison}.

The different traversing strategies depend on the data that they encode. If the scene is almost empty and most of the voxels are centered, the spiral will provide better coherence. 

\textbf{RLE:} We start a string by concatenating a value \textit{E} (empty) and \textit{F} (full) cell. We run RLE to compress the concatenated string so that we actually compress 3D data into 1D array. For example, if an array has values \textit{EEFFF} its RLE will become  \textit{2E3F}. Note that a sequence of \textit{EFEF} will be encoded to \textit{1E1F1E1F} that provides negative compression (inflation). However, these are rare cases and the RLE provides very good compression in most real-world scenarios.

We compute the space efficiency of the RLE by calculating the compression factor $cf$ as 
\begin{equation}
cf=\frac{RLE}{VOX},
\end{equation}
where $RLE$ is the size of the model in RLE representation and $VOX$ is its size in voxels. We report $cf$ of all ShapeNet categories in Tab.~\ref{tab:compressionFactor}. Please note that the $VOX=32^3$ across all objects.
\begin{table}[hbt]
    \centering
    \small
    \begin{tabular}{cccc}
    \toprule
        Category & Snake[B] & Spiral[B] & Raster Scanning[B]\\
    \midrule
        airplane  & 329.91 & 169.89 & 329.91\\
        bench  &  217.63 & 615.06 & 221.37\\ 
        cabinet  &  656.04 & 1428.76 & 660.23\\
        car  &  602.57 & 308.33 & 602.58\\
        chair  &  772.571 & 1063.95 & 774.94\\
        display  &  224.73 & 1446.17 & 229.40\\
        lamp & 600.54 & 589.01 & 600.68\\
        speaker & 820.61 & 1302.15 & 840.17\\
        rifle & 297.88 & 77.24 & 297.88\\
        sofa &  282.63 & 822.60 & 306.49\\
        table &  466.80 & 598.81 & 475.83\\
        telephone & 255.67 & 1114.53 & 256.50\\
        watercraft & 435.09 & 189.73 & 435.10\\
    \bottomrule
        Average &  458.97 & 748.17 & 463.93\\
    \end{tabular}
    \caption{A size of Run Length Encoding per category from Snake, Spiral, Raster scanning traversal.}\label{tab:RLEcomparison}\vspace{-3mm}
\end{table}


\begin{table}[hbt]
    \centering
    \small
    \begin{tabular}{ccc}
    \toprule
        Category & Compression Factor  & RLE Length [B]\\
    \midrule
        airplane  & 0.01007 & 329.91\\
        bench  &  0.00664 & 217.63\\ 
        cabinet  &  0.02002 & 656.04\\
        car  &  0.01839 & 602.57\\
        chair  &  0.02358 & 772.57\\
        display  &  0.00686 & 224.73\\
        lamp & 0.01833 & 600.54\\
        speaker &  0.02504 & 820.61\\
        rifle &  0.00909 & 297.88\\
        sofa &  0.00875 & 286.63\\
        table &  0.01425 & 466.80\\
        telephone &  0.00780 & 255.67\\
        watercraft &  0.01328 & 435.09\\
    \bottomrule
        Overall &  0.01401 & 458.97\\
    \end{tabular}
    \caption{Average of snake traversal compressed factor using RLE and its own length using $32^3$ voxels from ShapeNet.}\label{tab:compressionFactor}\vspace{-3mm}
\end{table}

\subsection{Tokenization}\label{section:token}
Compressing all 3D data into the 1D format improves the space complexity. We compress this further by creating a codebook that stores the RLE sequences as short tokens.

Inspired by Huffman encoding~\cite{huffman1952method}, we find the longest most repeating RLE sequence and substitute it with a single token such as $T_i$, where $i$ is an index of the codebook (see Tab.~\ref{tab:codebook}).
Note, that the transformer's generated tokens are later used to decode their values back to voxels. We use $T_i$ as a key to query the codebook to get $V_i$, a value that corresponds to its original value of RLE compressed data.

The tokens $T_i$ are then used in the decoder (Sec.~\ref{section:decoder}), so it references the codebook to convert it to compressed RLE strings, \textit{$V_i$}, that leads to an occupancy voxel, which corresponds to 3D object to reconstruct. 
\begin{table}[hbt]
    \centering
    \small
    \begin{tabular}{|c|c|}
    \hline
        Token & Value\\
    \hline
        T0  & 2E 3F 1E\\
    \hline
        T1  &  1022E 10F 5E\\ 
    \hline
        T2  &  1E 2F 2E 3F\\
    \hline
        $\dots$ & $\dots$\\
    \hline
    \end{tabular}
    \caption{An example of how the codebook assigns RLE blocks assigned to tokens.}\label{tab:codebook}\vspace{-3mm}
\end{table}
