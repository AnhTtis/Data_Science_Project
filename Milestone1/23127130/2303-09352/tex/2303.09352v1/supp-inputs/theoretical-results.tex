\subsection*{Proof of Proposition~\ref{prop:conLE}}
    \begin{proof}
        We have
        \begin{align}
            \Lalign &= -\kappa \sums{i, j}{} p_{ij} \vec z_i\T \vec z_j \\
                    &= - 2 \sums{i, j}{} \frac{1}{2} \kappa p_{ij} \vec z_i\T \vec z_j + \sums{i, j}{} 2 \frac{1}{2} \kappa p_{ij} - \kappa  \\
                    & \nonumber(\sums{i, j}{} p_{ij} = 1) \\
                    &= - 2 \sums{i, j}{} \vec z_i\T \vec z_j W_{ij} + \sums{i, j}{}(\|\vec z_i\| + \|\vec z_j\|) W_{ij} - \kappa \\
                    &\nonumber (\|\vec z_i\| = \|\vec z_j\| = 1) \\
                    &= \sums{i, j}{}( \| \vec z_i \| - 2 \vec z_i\T \vec z_j + \| \vec z_j \|) W_{ij} - \kappa \\
                    &= \sums{i, j}{} {| \vec z_i - \vec z_j\|^2 W_{ij}} - \kappa.
        \end{align}
    \end{proof}

\subsection*{Proof of Proposition~\ref{prop:maxEntropy}}
    \begin{proof}
        Using a Gaussian kernel, the 2-order R\'enyi entropy can be estimated as~\cite[Eq.~(2.13)]{principeInformationTheoreticLearning2010}
        \begin{align}
            H_2(\vec z_1, \dots, \vec z_n) = -\log \left( \frac{1}{n^2} \sums{l, m}{} \exp(-\frac{1}{2}\kappa \|\vec z_l - \vec z_m \|^2) \right)
        \end{align}
        Thus, we have
        \begin{align}
            &\ARGMAX H_2(\vec z_1, \dots, \vec z_n) \\
            &\qquad= \ARGMAX -\log \Biggl( \frac{1}{n^2} \sums{l, m}{} \exp(-\frac{1}{2}\kappa \|\vec z_l - \vec z_m \|^2) \Biggr) \\
            &\qquad= \ARGMIN \log \Biggl( \sums{l, m}{} \exp(-\frac{1}{2}\kappa \|\vec z_l - \vec z_m \|^2) \Biggr) \\
            &\qquad= \ARGMIN \log \Biggl( \sums{l, m}{} \exp(-\frac{1}{2}\kappa (\|\vec z_l\|^2 \\
            &\qquad - 2 \vec z_l\T \vec z_m + \|\vec z_m \|^2) \Biggr) \\
            &\qquad= \ARGMIN \log \Biggl( \sums{l, m}{} \exp(-\kappa (1 - \vec z_l\T \vec z_m)) \Biggr) \\
            &\nonumber\qquad (\|\vec z_l\| = \|\vec z_m\| = 1) \\
            &\qquad= \ARGMIN \log \Biggl( \exp(-\kappa) \sums{l, m}{} \exp(\kappa \vec z_l\T \vec z_m) \Biggr) \\
            &\qquad= \ARGMIN \log \sums{l, m}{} \exp(\kappa \vec z_l\T \vec z_m) \\
            &\qquad= \ARGMIN \Lunif.
        \end{align}
    \end{proof}

\subsection*{Proof of Proposition~\ref{prop:minLunif}}
    \begin{proof}
        We have
        \begin{align}
            &\ARGMIN \Lunif \\
            &\qquad= \ARGMIN \log \sums{l, m}{} \exp(\kappa \vec z_l\T \vec z_m) \\
            &\qquad= \ARGMIN \sums{l, m}{} \exp(\kappa \vec z_l\T \vec z_m) \\
            & \nonumber\qquad\text{(monotonicity of logarithm)} \\
            &\qquad= \ARGMIN \sums{1 \le l < m \le n}{} \exp(\kappa \vec z_l\T \vec z_m) \\
            & \nonumber\qquad\text{(symmetry of inner product)} \\
            &\qquad= \ARGMIN \sums{1 \le l < m \le n}{} \underbrace{\exp(-\kappa ||\vec z_l - \vec z_m||_2^2)}_{\eqqcolon ~ G(\vec z_l, \vec z_m)} \\
            & \nonumber\qquad\text{(multiplication by positive constant)} \\
            &\qquad= \ARGMIN \sums{1 \le l < m \le n}{} G(\vec z_l, \vec z_m)
        \end{align}
        The result then follows directly from~\cite[Proposition 2]{wangUnderstandingContrastiveRepresentation2020}.
    \end{proof}
