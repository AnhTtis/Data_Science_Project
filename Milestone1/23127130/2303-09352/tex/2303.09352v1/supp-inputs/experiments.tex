\begin{figure}[t]
    \centering
    \begin{subfigure}{0.99\columnwidth}
        \centering
        \includegraphics[width=0.7\textwidth]{fig/kappa}
    \end{subfigure}
    \begin{subfigure}{0.99\columnwidth}
        \centering
        \includegraphics[width=0.7\textwidth]{fig/epsilon}
    \end{subfigure}
    \caption{Accuracy for different values for \( \kappa \) and \( \epsilon \). Neither \method nor \methodS are particularly sensitive the the choice of these parameters.}
    \label{fig:kappaEpsilon}
\end{figure}

\subsection{Implementation details}
    This section covers the additional implementation details not provided in the main paper.
    These include the initialization of the embeddings in Algorithm 1, hyperparameters, additional transformations wherever required, the architectures used, and a note on accessing the code, datasets, and dataset splits.

    \customparagraph{Initialization and normalization}
        Instead of a random initialization of our embeddings $Z_0$, we follow a PCA based initialization, as in~\cite{Maaten}.
        The weights are computed using the cached features from the base classes, the support and query features are then transformed using these weights.
        This procedure is also fast as we do not need to compute the PCA weights on every episode.
        To ensure that the resulting features lie on the hypersphere after each gradient update in \method and \methodS, we re-normalize the embeddings using L2 normalization.
    
    \customparagraph{Hyperparameters}
        \method and \methodS have the following hyperparameters.
        \begin{itemize}
            \item \( P \) -- perplexity for computing the \( \kappa_i \).
            \item \( T \) -- number of iterations.
            \item \( \alpha \) -- tradeoff parameter in the loss (\( \Lfinal = \alpha\Lalign + (1-\alpha) \Lunif \)).
            \item \( \eta \) -- learning rate for the Adam optimizer.
            \item \( \kappa \) -- concentration parameter for the embeddings.
            \item \( \epsilon \) -- exaggeration of similarities between supports from different classes.
            \item \( d \) -- dimensionality of embeddings.
        \end{itemize}
        All hyperparameter values used in in \method and \methodS are given in Table~\ref{tab:hyperparameters}

        \begin{table*}
            \centering
            \small
            \input{tab/hyperparameters.tex}
            \caption{Hyperparameter values used in our experiments.}
            \label{tab:hyperparameters}
        \end{table*}

    \customparagraph{Code}
        The code for our experiments is available at: \githubLink

    \customparagraph{Data splits}
        Details to access the datasets used with the requisite splits (both are consistent with~\cite{veilleuxRealisticEvaluationTransductive2021}) are available in the code repository.
    
    \customparagraph{Base feature extractors}
        \begin{itemize}
            \item \textbf{Resnet-18}: As in~\cite{boudiafTransductiveInformationMaximization2020,veilleuxRealisticEvaluationTransductive2021}, we use the  weights from~\cite{veilleuxRealisticEvaluationTransductive2021}.
                The model is trained using a cross-entropy loss on the base classes.
            \item \textbf{WideRes28-10}: Following~\cite{manglaChartingRightManifold2020,zhuEASEUnsupervisedDiscriminant2022}, we use the weights from~\cite{manglaChartingRightManifold2020}.
                The model is pre-trained using a combination of cross-entropy and rotation prediction~\cite{gidarisUnsupervisedRepresentationLearning2018}, and then fine-tuned with Manifold Mixup~\cite{vermaManifoldMixupBetter2019}.
        \end{itemize}

\subsection{Results}
    \customparagraph{FSL performance}
        The complete lists of accuracies and hubness metrics for all embeddings, classifiers, and feature extractors, are given in Tables~\ref{tab:main-tim-resnet18-1},~\ref{tab:main-s2m2-wrn-s2m2-1},~\ref{tab:main-tim-resnet18-5}, and~\ref{tab:main-s2m2-wrn-s2m2-5}.
        The exhaustive results in these tables form the basis of Table 1, Table 2 and Table 3 in the main text.
        The two proposed approaches consistently outperform prior embeddings across several classifiers, feature extractors and datasets.

    \customparagraph{Effect of the \( \kappa \) and \( \epsilon \) hyperparameters}
        The plots in Figure~\ref{fig:kappaEpsilon} show accuracy on \textit{tiered} \(5\)-shot with SIAMESE for increasing \( \kappa \) and \( \varepsilon \).
        Neither method is particularly sensitive to the choice of \( \kappa \) and \( \varepsilon \), and \methodS is less sensitive to variations in \( \kappa \), than \method.
        Choosing \( \kappa \in [0.5, 1] \) and \(\epsilon \in [3, 20] \) will result in high classification accuracy

    \begin{table*}
        {\scriptsize\centering\input{tab/main-results/all_tim-resnet18_1shot.tex}}
        \caption{Resnet-18: 1-shot}
        \label{tab:main-tim-resnet18-1}
    \end{table*}
    \begin{table*}
        {\scriptsize\centering\input{tab/main-results/all_s2m2-wrn-s2m2_1shot.tex}}
        \caption{WideRes28-10: 1-shot}
        \label{tab:main-s2m2-wrn-s2m2-1}
    \end{table*}
    \begin{table*}
            {\scriptsize\centering\input{tab/main-results/all_tim-resnet18_5shot.tex}}
        \caption{Resnet-18: 5-shot}
        \label{tab:main-tim-resnet18-5}
        \end{table*}
    \begin{table*}
        {\scriptsize\centering\input{tab/main-results/all_s2m2-wrn-s2m2_5shot.tex}}
        \caption{WideRes28-10: 5-shot}
        \label{tab:main-s2m2-wrn-s2m2-5}
    \end{table*}
