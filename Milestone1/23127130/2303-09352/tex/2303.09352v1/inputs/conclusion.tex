In this paper we have addressed the hubness problem in FSL.
We have shown that hubness is eliminated by embedding representations uniformly on the hypersphere.
The hyperspherical uniform distribution has zero mean and zero density gradient at all points along all directions tangent to the hypersphere -- both of which are identified as causes of hubness in previous work~\cite{radovanovicHubsSpacePopular2010,haraFlatteningDensityGradient2016}.
Based on our theoretical findings about hubness and hyperspheres, we proposed two new methods to embed representations on the hypersphere for FSL.
The proposed \method and \methodS leverage a decomposition of the KL divergence between similarity distributions, and optimize a tradeoff between LSP and uniformity on the hypersphere -- thus reducing hubness while maintaining the class structure in the representation space.
We have provided theoretical analyses and interpretations of the LSP and uniformity losses, proving that they optimize LSP and uniformity, respectively.
We comprehensively evaluate the proposed methods on several datasets, features extractors, and classifiers, and compare to a number of recent state-of-the-art baselines. 
Our results illustrate the effectiveness of our proposed methods and show that we achieve state-of-the-art performance in transductive FSL. 
