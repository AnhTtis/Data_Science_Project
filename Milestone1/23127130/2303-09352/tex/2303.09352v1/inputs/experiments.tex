\subsection{Setup}
    \begin{table*}
    \setlength{\tabcolsep}{3.5mm}
        \centering
        {\tableFontSize \input{tab/top-accs/all.tex}}
        \caption{Accuracies~({\footnotesize Confidence interval}) with the SIAMESE~\cite{zhuEASEUnsupervisedDiscriminant2022} classifier for different embedding approaches. Best and second best performance are denoted in  {\textbf{bold}} and \underline{underlined}, respectively. $^*$The SIAMESE classifier is sensitive to the norm of the embedding, thus leading to detrimental performance for some of the embedding approaches.}
        \label{tab:siameseAcc}
    \end{table*}
    \vspace{-0.2cm}
    \customparagraph{Implementation details}
        Our implementation is in PyTorch~\cite{paszkePytorch2019}.
        We optimize \method and \methodS for \( T = 150 \) iterations, using the Adam optimizer~\cite{adam} with learning rate \( \eta = 0.1 \).
        The other hyperparameters were chosen based on validation performance on the respective datasets\footnote{Hyperparameter configurations for all experiments are included in the supplementary.}.
        We analyze the effect of \( \alpha \) in Sec.~\ref{subsec:results}.
        Analyses of the \( \kappa \) and \( \epsilon \) hyperparameters are provided in the supplementary.

    \customparagraph{Initialization}
        Since \method and \methodS reduce the embedding dimensionality (\( d = 400 \)), we initialize embeddings with Principal Component Analysis (PCA)~\cite{jolliffe2002principal}, instead of a na√Øve, random initialization.
        The PCA initialization is computationally efficient, and approximately preserves global structure.
        It also resulted in faster convergence and better performance, compared to random initialization.
    
    
    \customparagraph{Base feature extractors}
        We use the standard networks
        ResNet-18~\cite{HeResnet2016} and Wide-Res28-10~\cite{ZagoruykoWideResNet2016} as the base feature extractors with pretrained weights from~\cite{veilleuxRealisticEvaluationTransductive2021} and~\cite{manglaChartingRightManifold2020}, respectively.
        
    \customparagraph{Datasets}
        Following common practice, we evaluate FSL performance on the \textit{mini-ImageNet (mini)}~\cite{vinyalsMatchingNetworksOne2016}, \textit{tiered-ImageNet (tiered)}~\cite{renMetalearningSemisupervisedFewshot2018}, and \textit{CUB-200 (CUB)}~\cite{CUB200} datasets.

    \customparagraph{Classifiers}
        We evaluate the baseline embeddings and our proposed methods using both established and recent FSL classifiers: \textit{SimpleShot}~\cite{wangSimpleShotRevisitingNearestNeighbor2019}, \textit{LaplacianShot}~\cite{zikoLaplacianRegularizedFewShot2020}, $\mathit{\alpha}-$\textit{TIM}~\cite{veilleuxRealisticEvaluationTransductive2021}, \textit{Oblique Manifold (OM)}~\cite{qiTransductiveFewShotClassification2021}, \textit{iLPC}~\cite{lazarouIterativeLabelCleaning2021}, and \textit{SIAMESE}~\cite{zhuEASEUnsupervisedDiscriminant2022}.

    \customparagraph{Baseline Embeddings}
        We compare our proposed method with a wide range of techniques for embedding the base features: \textit{None} (No embedding of base features), \textit{L2}~\cite{wangSimpleShotRevisitingNearestNeighbor2019}, \textit{Centered L2}~\cite{wangSimpleShotRevisitingNearestNeighbor2019}, \textit{ZN}~\cite{feiZScoreNormalizationHubness2021}, \textit{ReRep}~\cite{cuiParameterlessTransductiveFeature2021},  \textit{EASE}~\cite{zhuEASEUnsupervisedDiscriminant2022}, and \textit{TCPR}~\cite{xuAlleviatingSampleSelection2022}.

    \customparagraph{Evaluation protocol}
        We follow the standard evaluation protocol in FSL and calculate the accuracy for 1-shot and 5-shot classification with 15 images per class in the query set.
        We evaluate on \( 10000 \)  episodes, as is standard practice in FSL.
        Additionally, we evaluate the hubness of the representations after embedding using two common hubness metrics, namely the skewness (Sk) of the k-occurrence distribution~\cite{radovanovicHubsSpacePopular2010} and the hub occurrence (HO)~\cite{flexer2015choosing}, which measures the percentage of hubs in the nearest neighbour lists of all points.


\subsection{Results}
    \label{subsec:results}
    \customparagraph{Comparison to the state-of-the-art}
        To illustrate the effectiveness of \method and \methodS as an embedding approach for FSL, we consider the current state-of-the-art FSL method, which leverages the EASE embedding and obtains query predictions with SIAMESE~\cite{zhuEASEUnsupervisedDiscriminant2022}.
        We replace EASE with our proposed embedding approaches \method and \methodS, as well as other baseline embeddings, and evaluate performance on all datasets in the 1 and 5-shot setting.
        As shown in Table~\ref{tab:siameseAcc}, \method and \methodS outperform all baseline approaches in both settings across all datasets, illustrating \method's and \methodS' ability to provide useful FSL embeddings, and updating the state-of-the-art in transductive FSL.

    \customparagraph{Aggregated FSL performance}
        To further evaluate the general applicability of \method and \methodS as embedding approaches, we perform extensive experiments for all classifiers and all baseline embeddings on all datasets.
        Tables~\ref{tab:agg1shot} and~\ref{tab:agg5shot} provide the results averaged over classifiers\footnote{The detailed results for all classifiers are provided in the supplementary.}.
        To clearly present the results, we aggregate the accuracy and a ranking \emph{score} for each embedding method across all classifiers.
        The ranking score is calculated by performing a paired Student's t-test between all pairwise embedding methods for each classifier.
        We then average the ranking scores across all classifiers.
        A high ranking score then indicates that a method often significantly outperforms the competing embedding methods.
        We set the significance level to 5\%.
        \method and \methodS consistently outperform previous embedding approaches -- sometimes by a large margin.
        Overall, we further observe that \methodS outperforms \method in most settings and is particular beneficial in the 1-shot setting, which is more challenging, given that fewer samples are likely to generate noisy embeddings.

        \begin{table}
            \setlength{\tabcolsep}{0.9mm}
            \begin{subtable}{\columnwidth}
                \centering
                {\tableFontSize \input{tab/agg/1shot.tex}}
                \caption{ 1-shot}
                \label{tab:agg1shot}
            \end{subtable}
            \begin{subtable}{\columnwidth}
                \centering
                {\tableFontSize \input{tab/agg/5shot.tex}}
                \caption{5-shot}
                \label{tab:agg5shot}
            \end{subtable}
            \caption{Aggregated FSL performance for all embedding approaches on the mini-ImageNet, tiered-ImageNet, and CUB-200 datasets. Results are averaged over FSL classifiers. Best and second best performance are denoted in  {\textbf{bold}} and \underline{underlined}, respectively.}
            \label{tab:agg}
            \vspace{-0.3cm}
        \end{table}

\customparagraph{Hubness metrics}
        To further validate \method's and \methodS' ability to reduce hubness, we follow the same procedure of aggregating results for the hubness metrics and average over classifiers.
        Compared to the current state-of-the-art embedding approaches, Table~\ref{tab:hubnessMetrics} illustrates that \method and \methodS consistently result in embeddings with lower hubness.
        
        \begin{table}
            \centering
            \setlength{\tabcolsep}{1.2mm}
            \begin{subtable}{\columnwidth}
                \centering
                {\tableFontSize \input{tab/hubness/1shot.tex}}
                \caption{ 1-shot}
                \label{tab:hubness1shot}
            \end{subtable}
            \begin{subtable}{\columnwidth}
                \centering
                {\tableFontSize \input{tab/hubness/5shot.tex}}
                \caption{5-shot}
                \label{tab:hubness5shot}
            \end{subtable}
            \caption{Aggregated hubness metrics for all embedding approaches on the Mini-ImageNet, Tiered-ImageNet and CUB-200 dataset. Results are averaged over FSL classifiers. Best and second best performance are denoted in  {\textbf{bold}} and \underline{underlined}, respectively.}
            \label{tab:hubnessMetrics}
            \vspace{-0.3cm}
        \end{table}

    \customparagraph{Visualization of similarity matrices}
        As discussed in Sec.~\ref{sec:method}, completely eliminating hubness by distributing points uniformly on the hypersphere is not sufficient to obtain good FSL performance.
        Instead, representations need to also capture the inherent class structure of the data.
        To further evaluate the embedding approaches, we therefore compute the pairwise inner products for the embeddings of a random 5-shot episode on tiered-ImageNet with ResNet-18 features in Figure~\ref{fig:innerProductMatrices}.
        It can be observed that the block structure is considerably more distinct for \method and \methodS, with \methodS slightly improving upon \method.
        These results indicate that (i) samples are more uniform, indicating the reduced hubness;
        and (ii) classes are better separated, due to the local similarity preservation.

        \begin{figure*}
            \centering
            \includegraphics[width=\textwidth]{fig/inner-product-matrices-cividis}
            \caption{Inner product matrices between features for a random episode for all embedding approaches.}
            \label{fig:innerProductMatrices}
        \end{figure*}

    \customparagraph{Tradeoff between uniformity and similarity preservation}
        We analyze the effect of \(\alpha \) on the tradeoff between LSP and Uniformity in the loss function in Eq.~\eqref{eq:Lfinal}, on tiered-ImageNet with ResNet-18 features in the 5-shot setting and with the SIAMESE~\cite{zhuEASEUnsupervisedDiscriminant2022} classifier.
        The results are visualized in Figure~\ref{fig:alphas}.
        We notice a sharp increase in performance when we have a high emphasis on uniformity.
        This demonstrates the impact of hubness on accuracy in FSL performance.
        As we keep increasing the emphasis on LSP, however, after a certain point we notice a sharp drop off in performance.
        This is due to the fact that the classifier does not take into account the uniformity constraint on the features, resulting in a large number of misclassifications.
        In general, we observe that \methodS is slightly more robust compared to \method.
    
        \begin{figure}
            \centering
            \includegraphics[width=0.7\columnwidth]{fig/alphas}
            \vspace{-.3cm}
            \caption{Accuracies for different values of the weighting parameter, \( \alpha \), which quantifies the tradeoff between $\Lalign$ and $\Lunif$.}
            \label{fig:alphas}
        \end{figure}

        \begin{figure}
            \centering
            \includegraphics[width=0.7\columnwidth]{fig/increasing_ways}
            \vspace{-.3cm}
            \caption{Accuracies for an increasing number of classes (ways) for \method and \methodS.}
            \label{fig:increasingWays}
        \end{figure}
    
    \customparagraph{Increasing number of classes}
    We analyze the behavior of \method and \methodS for an increasing number of classes (ways) on the tiered-ImageNet dataset with SIAMESE~\cite{zhuEASEUnsupervisedDiscriminant2022} as classifier.
        While classification accuracy generally decreases with an increasing number of classes, which is expected, we observe from Figure~\ref{fig:increasingWays} that \methodS has a slower decay and is able to leverage the label guidance to obtain better performance for a larger number of classes.
    
    \customparagraph{Effect of label information in $\Lalign$ and $\Lunif$}
        To validate the effectiveness of using label guidance in \methodS, we study the result of including label information in \(\Lalign\) and \(\Lunif\) (Eqs.~\eqref{eq:modpij1}--\eqref{eq:moduni}).
        We note that the default setting of \method is that none of the two losses include label information.
        Ablation experiments are performed on tiered-ImageNet with the ResNet-18 feature extractor and the SimpleShot and SIAMESE classifier~\cite{zhuEASEUnsupervisedDiscriminant2022}.
         In Table~\ref{tab:ablation}, we generally see improvements of \methodS when \textit{both} the loss terms are label-informed, indicating the usefulness of label guidance.

         We further observe that incorporating label information in \( \Lunif \) tends to have a larger contribution than doing the same for \( \Lalign \).
        This aligns with our observations in Figure~\ref{fig:alphas}, where a small \( \alpha \) yielded the best performance.

    \begin{table}
        \flushleft
        {\setlength{\tabcolsep}{0.5mm} \tableFontSize \input{tab/ablation.tex}}
        \caption{Ablation study with the label-informed losses in \methodS. Check marks (\TRUE) indicate that the loss uses information from the support labels.}
        \label{tab:ablation}
    \end{table}

