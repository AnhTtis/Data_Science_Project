@inproceedings{zhang2020transformer,
  title={Transformer transducer: A streamable speech recognition model with transformer encoders and {RNN-T} loss},
  author={Zhang, Qian and Lu, Han and Sak, Hasim and Tripathi, Anshuman and McDermott, Erik and Koo, Stephen and Kumar, Shankar},
  booktitle={Proc. ICASSP},
  year={2020},
  address={Barcelona}
}

@inproceedings{Li2017LargeScaleDA,
  title={Large-Scale Domain Adaptation via Teacher-Student Learning},
  author={Jinyu Li and Michael L. Seltzer and Xi Wang and Rui Zhao and Yifan Gong},
  booktitle={Proc. Interspeech},
  year={2017},
  address={Stockholm}
}

@inproceedings{hinton2015knowledgedistillation,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  booktitle={Proc. NIPS Deep Learning Workshop},
  year={2014},
  address={Montreal}
}

@inproceedings{JeremyDecisionTree,
author = {Wong, Jeremy and Gales, M.J.F.},
year = {2017},
title = {Student-Teacher Training with Diverse Decision Tree Ensembles},
booktitle={Proc. Interspeech},
address={Stockholm}
}

@inproceedings{Wong2016SequenceST,
  title={Sequence Student-Teacher Training of Deep Neural Networks},
  author={Jeremy Heng Meng Wong and Mark John Francis Gales},
  booktitle={Proc. Interspeech},
  year={2016},
  address={San Francisco}
}

@inproceedings{gulati2020conformer,
  title={Conformer: Convolution-augmented transformer for speech recognition},
  author={Gulati, Anmol and Qin, James and Chiu, Chung-Cheng and Parmar, Niki and Zhang, Yu and others},
  booktitle={Proc. Interspeech},
  address={Shanghai},
  year={2020}
}

@inproceedings{graves2012RNNT,
  title={Sequence transduction with recurrent neural networks},
  author={A. Graves},
  booktitle={Proc. ICML Workshop on Representation Learning},
  year={2012},
  address={Edinburgh}
}

@inproceedings{chan2015listen,
  title={Listen, attend and spell},
  author={Chan, William and Jaitly, Navdeep and Le, Quoc V and Vinyals, Oriol},
  booktitle={Proc. ICASSP},
  year={2016},
  address={Shanghai}
}

@article{watanabeHybrid,
    author={Watanabe, Shinji and Hori, Takaaki and Kim, Suyoun and Hershey, John R. and Hayashi, Tomoki},  
    journal={IEEE Journal of Selected Topics in Signal Processing},   
    title={Hybrid {CTC}/Attention Architecture for End-to-End Speech Recognition},   
    year={2017},  
    volume={11},  
    pages={1240-1253},
}

@inproceedings{Bahdanau2015EndtoendAL,
  title={End-to-end attention-based large vocabulary speech recognition},
  author={Dzmitry Bahdanau and Jan Chorowski and Dmitriy Serdyuk and Philemon Brakel and Yoshua Bengio},
  booktitle={Proc. ICASSP},
  year={2016},
  address={Shanghai}
}

@inproceedings{Lu2015,
  title={A study of the recurrent neural network encoder-decoder for large vocabulary speech recognition},
  author={L. Lu, X. Zhang, K. Cho and S. Renals},
  booktitle={Proc. Interspeech},
  year={2015},
  address={Dresden}
}

@inproceedings{Kim2017,
  title={Joint {CTC}-attention based end-to-end speech recognition using multi-task learning},
  author={S. Kim, T. Hori and S. Watanabe},
  booktitle={Proc. ICASSP},
  year={2017},
  address={New Orleans}
}

@Article{SSLloss,
AUTHOR = {Jaiswal, Ashish and Babu, Ashwin Ramesh and Zadeh, Mohammad Zaki and Banerjee, Debapriya and Makedon, Fillia},
TITLE = {A Survey on Contrastive Self-Supervised Learning},
JOURNAL = {Technologies},
VOLUME = {9},
YEAR = {2021},
NUMBER = {1},
DOI = {10.3390/technologies9010002}
}

@inproceedings{Graves2013,
  title={Speech recognition with deep recurrent neural networks},
  author={A. Graves, A. Mohamed and G. Hinton},
  booktitle={Proc. ICASSP},
  year={2013},
  address={Vancouver}
}

@inproceedings{graves2006CTC,
  title={Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks},
  author={Graves, Alex and Fern{\'a}ndez, Santiago and Gomez, Faustino and Schmidhuber, J{\"u}rgen},
  booktitle={Proc. ICML},
  address={Pittsburgh},
  year={2006}
}

@inproceedings{baevski2020wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  booktitle={NeurIPS},
  year={2020},
  address={Vancouver}
}

@article{hsu2021hubert,
  title={{HuBERT}: Self-supervised speech representation learning by masked prediction of hidden units},
  author={Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and others},
  journal={IEEE/ACM Transactions on Audio, Speech, Language Processing},
  year={2021},
  pages={3451--3460},
  volumn={29},
}

@article{chen2022wavlm,
  title={{WavLM}: Large-scale self-supervised pre-training for full stack speech processing},
  author={Chen, Sanyuan and Wang, Chengyi and Chen, Zhengyang and Wu, Yu and Liu, Shujie and Chen, Zhuo and Li, Jinyu and Kanda, Naoyuki and Yoshioka, Takuya and Xiao, Xiong and others},
  journal={IEEE Journal of Selected Topics in Signal Processing},
  volume={16},
  year={2022},
}
@inproceedings{kreyssig2022biased,
  title={Biased Self-supervised learning for {ASR}},
  author={Kreyssig, Florian L and Shi, Yangyang and Guo, Jinxi and Sari, Leda and Mohamed, Abdelrahman and Woodland, Philip C},
  booktitle={arXiv preprint arXiv:2211.02536},
  year={2022}
}

@inproceedings{Shen2020,
  author={Guang Shen and Riwei Lai and Rui Chen and Yu Zhang and Kejia Zhang and Qilong Han and Hongtao Song},
  title={{WISE}: Word-Level Interaction-Based Multimodal Fusion for Speech Emotion Recognition},
  year={2020},
  booktitle={Proc. Interspeech},
  address={Shanghai}
}

@inproceedings{pepino2021emotion,
  title={Emotion Recognition from Speech Using wav2vec 2.0 Embeddings},
  author={Pepino, Leonardo and Riera, Pablo and Ferrer, Luciana},
  booktitle={Proc. Interspeech},
  year={2021},
  address={Brno}
}

@inproceedings{hwang2014fixed,
  title={Fixed-point feedforward deep neural network design using weights+ 1, 0, and- 1},
  author={Hwang, Kyuyeon and Sung, Wonyong},
  booktitle={Proc. SiPS},
  year={2014},
  address={Belfast},
}

@inproceedings{courbariaux2015binaryconnect,
  title={Binaryconnect: {T}raining deep neural networks with binary weights during propagations},
  author={Courbariaux, Matthieu and Bengio, Yoshua and David, Jean-Pierre},
  booktitle={Proc. NIPS},
  year={2015},
  address={Montreal}
}

@inproceedings{yang2022knowledge,
  title={Knowledge Distillation for Neural Transducers from Large Self-Supervised Pre-Trained Models},
  author={Yang, Xiaoyu and Li, Qiujia and Woodland, Philip C},
  booktitle={Proc. ICASSP},
  year={2022},
  address={Singapore}
}

@inproceedings{panchapagesan2021efficient,
  title={Efficient knowledge distillation for {RNN}-transducer models},
  author={Panchapagesan, Sankaran and Park, Daniel S and Chiu, Chung-Cheng and Shangguan, Yuan and Liang, Qiao and Gruenstein, Alexander},
  booktitle={Proc. ICASSP},
  year={2021},
  address={Toronto}
}

@article{guo2022predicting,
  title={Predicting Multi-Codebook Vector Quantization Indexes for Knowledge Distillation},
  author={Guo, Liyong and Yang, Xiaoyu and Wang, Quandong and Kong, Yuxiang and Yao, Zengwei and Cui, Fan and Kuang, Fangjun and Kang, Wei and Lin, Long and Luo, Mingshuang and others},
  journal={arXiv preprint arXiv:2211.00508},
  year={2022}
}

@inproceedings{swaminathan2021codert,
  title={{CoDERT}: Distilling encoder representations with co-learning for transducer-based speech recognition},
  author={Swaminathan, Rupak Vignesh and King, Brian and Strimel, Grant P and Droppo, Jasha and Mouchtaris, Athanasios},
  booktitle={Proc. Interspeech},
  year={2021},
  address={Brno}
}

@inproceedings{jang2016gumbelsoftmax,
  title={Categorical reparameterization with gumbel-softmax},
  author={Jang, Eric and Gu, Shixiang and Poole, Ben},
  booktitle={Proc. ICLR},
  address={Toulon},
  year={2017}
}

@article{menghani2019learning,
  title={Learning from a teacher using unlabeled data},
  author={Menghani, Gaurav and Ravi, Sujith},
  journal={arXiv preprint arXiv:1911.05275},
  year={2019}
}


@book{zhou2012ensemble,
  title     = {Ensemble Methods: {F}oundations and Algorithms},
  author    = {Zhou, Zhi-Hua},
  year      = 2012,
  publisher = {Chapman & Hall Book},
  address   = {Boca Riton}
}

@incollection{zhou2021ensemble,
  title={Ensemble learning},
  author={Zhou, Zhi-Hua},
  booktitle={Machine learning},
  pages={181--210},
  year={2021},
  publisher={Springer}
}



@inproceedings{zheng2022tandem,
  title={Tandem multitask training of speaker diarisation and speech recognition for meeting transcription},
  author={Zheng, Xianrui and Zhang, Chao and Woodland, Philip C},
  booktitle={Proc. Interspeech},
  year={2022},
  address={Incheon}
}

@article{bommasani2021foundation,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}

@inproceedings{brown2020GPT3,
 author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal},
 booktitle={Proc. NeurIPS},
 title={Language models are few-shot learners},
 year={2020},
 address={Vancouver}
}

@article{radford2022whisper,
  title={Robust speech recognition via large-scale weak supervision},
  author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  journal={OpenAI Blog},
  year={2022}
}

@inproceedings{wang2021unispeech,
  title={Unispeech: {U}nified speech representation learning with labeled and unlabeled data},
  author={Wang, Chengyi and Wu, Yu and Qian, Yao and Kumatani, Kenichi and Liu, Shujie and Wei, Furu and Zeng, Michael and Huang, Xuedong},
  booktitle={Proc. ICML},
  address={Baltimore},
  year={2021},
}

@inproceedings{chen2020big,
  title={Big self-supervised models are strong semi-supervised learners},
  author={Chen, Ting and Kornblith, Simon and Swersky, Kevin and Norouzi, Mohammad and Hinton, Geoffrey E},
  booktitle={Proc. NeurIPS},
  address={Vancouver},
  year={2020}
}

@inproceedings{takashima2018investigation,
  title={An investigation of a knowledge distillation method for {CTC} acoustic models},
  author={Takashima, Ryoichi and Li, Sheng and Kawai, Hisashi},
  booktitle={Proc. ICASSP},
  year={2018},
  address={Calgary}

}

@InProceedings{ensembledistribution,
author = {{L}indqvist, {J}. and {O}lmin, {A}. and {L}indsten {F}. and {S}vensson {L}.},
title = {{A} general framework for ensemble distribution distillation},
booktitle = {{Proc. MLSP}},
address={Espoo},
year = 2020,
}

@inproceedings{dietterich2000ensemble,
  title={Ensemble methods in machine learning},
  author={Dietterich, Thomas G},
  booktitle={proc. MCS},
  year={2000},
  address={Cagliari},
}

@incollection{polikar2012ensemble,
  title={Ensemble learning},
  author={Polikar, Robi},
  booktitle={Ensemble Machine Learning},
  pages={1--34},
  year={2012},
  publisher={Springer}
}


@inproceedings{lakshminarayanan2017simple,
  title={Simple and scalable predictive uncertainty estimation using deep ensembles},
  author={Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
  booktitle={Proc. NIPS},
  year={2017},
  address={Long Beach}
}

@inproceedings{fukuda2017efficient,
  title={Efficient Knowledge Distillation from an Ensemble of Teachers},
  author={Fukuda, Takashi and Suzuki, Masayuki and Kurata, Gakuto and Thomas, Samuel and Cui, Jia and Ramabhadran, Bhuvana},
  booktitle={Proc. Interspeech},
  address={Shanghai},
  year={2017}
}

@inproceedings{kurata20_interspeech,
  author={Gakuto Kurata and George Saon},
  title={Knowledge Distillation from Offline to Streaming {RNN} Transducer for End-to-End Speech Recognition},
  year={2020},
  booktitle={Proc. Interspeech},
  address={Shanghai}
}

@article{peng2021shrinking,
  title={Shrinking bigfoot: Reducing wav2vec 2.0 footprint},
  author={Peng, Zilun and Budhkar, Akshay and Tuil, Ilana and Levy, Jason and Sobhani, Parinaz and Cohen, Raphael and Nassour, Jumana},
  journal={arXiv preprint arXiv:2103.15760},
  year={2021}
}

@inproceedings{chang2022distilhubert,
  title={{DistilHuBERT}: Speech representation learning by layer-wise distillation of hidden-unit BERT},
  author={Chang, Heng-Jui and Yang, Shu-wen and Lee, Hung-yi},
  booktitle={Proc. ICASSP},
  address={Toronto},
  year={2022},
}

@article{liu2020adaptive,
  title={Adaptive multi-teacher multi-level knowledge distillation},
  author={Liu, Yuang and Zhang, Wei and Wang, Jun},
  journal={Neurocomputing},
  volume={415},
  year={2020},
  pages={106-113},
}


@article{rokach2010ensemble,
  title={Ensemble-based classifiers},
  author={Rokach, Lior},
  journal={Artificial Intelligence Review},
  volume={33},
  year={2010},
  pages={1â€“39},
}

@article{sahraeian2018cross,
  title={Cross-entropy training of {DNN} ensemble acoustic models for low-resource {ASR}},
  author={Sahraeian, Reza and Van Compernolle, Dirk},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={26},
  year={2018},
  pages={1991--2001},
}

@article{sau2016deep,
  title={Deep model compression: Distilling knowledge from noisy teachers},
  author={Sau, Bharat Bhusan and Balasubramanian, Vineeth N},
  journal={arXiv preprint arXiv:1610.09650},
  year={2016}
}

@article{zhao2020highlight,
  title={Highlight every step: Knowledge distillation via collaborative teaching},
  author={Zhao, Haoran and Sun, Xin and Dong, Junyu and Chen, Changrui and Dong, Zihe},
  journal={IEEE Transactions on Cybernetics},
  year={2020},
  volume={52},
  pages={2070--2081},
}

@inproceedings{panayotov2015librispeech,
  title={Librispeech: an {ASR} corpus based on public domain audio books},
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={Proc. ICASSP},
  year={2015},
  address={Brisbane}
}

@inproceedings{kahn2020libri,
  title={Libri-light: A benchmark for {ASR} with limited or no supervision},
  author={Kahn, Jacob and Rivi{\`e}re, Morgane and Zheng, Weiyi and Kharitonov and others},
  booktitle={Proc. ICASSP},
  year={2020},
  address={Barcelona}
}

@inproceedings{kudo2018sentencepiece,
  title={{SentencePiece}: A simple and language independent subword tokenizer and detokenizer for neural text processing},
  author={Kudo, Taku and Richardson, John},
  booktitle={Proc. EMNLP},
  year={2018},
  address={Brussels}
}

@inproceedings{park2019specaugment,
  title={{SpecAugment}: A simple data augmentation method for automatic speech recognition},
  author={Park, Daniel S and Chan, William and Zhang, Yu and Chiu, Chung-Cheng and Zoph, Barret and others},
  booktitle={Proc. Interspeech},
  address={Graz},
  year={2019}
}

@inproceedings{vaswani2017transformer,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Proc. NIPS},
  address = {Long Beach},
  year={2017}
}

@inproceedings{oord2016wavenet,
  title={{WaveNet}: A generative model for raw audio},
  author={A{\"a}ron van den Oord and Sander Dieleman and Heiga Zen and Karen Simonyan and Oriol Vinyals and others},
  booktitle={Proc. SSW},
  year={2016},
  address={Sunnyvale}
}

@inproceedings{watanabe2018espnet,
  author={Shinji Watanabe and Takaaki Hori and Shigeki Karita and Tomoki Hayashi and Jiro Nishitoba and others},
  title={{ESP}net: End-to-end speech processing toolkit},
  year={2018},
  booktitle={Proc. Interspeech},
  address={Hyderabad}
}

@inproceedings{xu2020iterative,
  title={Iterative pseudo-labeling for speech recognition},
  author={Xu, Qiantong and Likhomanenko, Tatiana and Kahn, Jacob and Hannun, Awni and Synnaeve, Gabriel and Collobert, Ronan},
  booktitle={Proc. Interspeech},
  year={2020},
  address={Shanghai}
}

@inproceedings{higuchi2021momentum,
  title={Momentum pseudo-labeling for semi-supervised speech recognition},
  author={Higuchi, Yosuke and Moritz, Niko and Roux, Jonathan Le and Hori, Takaaki},
  booktitle={Proc. Interspeech},
  year={2021},
  address={Brno}
}