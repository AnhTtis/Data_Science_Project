\section{Introduction}
\label{sec:introduction}


Recommender models typically learn user preference representations from historical interactions (\eg clicks and ratings)~\cite{he2020lightgcn}. 
% However, Most recommender models rely on the Independent and Identically Distributed (IID) assumption between training and testing interactions,
However, most recommender models assume the training and testing interactions are Independent and Identically Distributed (IID),
which is infeasible in real-world applications. 
As shown in Figure~\ref{fig:example}, there are user preference shifts across different environments~\cite{zafari2019modelling, wang2022causal} where each environment denotes a short time period. Some user features and environmental factors will change over time such as becoming pregnant, causing the shifts of user preference and interaction distributions in Out-of-Distribution (OOD) environments.
Such drifts can frustrate the recommender models trained over historical interactions~\cite{wang2022causal}. 
% Table~\ref{tab:iid_ood} presents the empirical evidence for the negative effect of preference shifts: the results of recommender models drop significantly on the OOD testing (chronologically splitting users' interactions) as compared to the IID testing (randomly splitting the interactions). 
Consequently, the inferior performance of recommender models will degrade user experience and reduce user activities, hurting the health of the whole recommender system. 
Therefore, it is essential to capture user preference shifts and pursue generalizable recommendation.


% \begin{figure}[t]
% \setlength{\abovecaptionskip}{0.2cm}
% \setlength{\belowcaptionskip}{0.1cm}
% \centering
% \includegraphics[scale=0.8]{figures/example.pdf}
% \caption{A toy example to illustrate preference shifts. We assume that user preference is stable within a short period, thus treating a short time period as an environment. Some user preference is stable across environments, \eg the preference over seafood; while partial preference is shifting due to the changes of user features (\eg becoming pregnant).}
% \label{fig:example}
% \end{figure}

\begin{figure}[t]
\setlength{\abovecaptionskip}{0.2cm}
\setlength{\belowcaptionskip}{0.1cm}
\centering
\includegraphics[scale=0.45]{figures/intro_ab.pdf}
  \caption{{(a) is a toy example to illustrate preference shifts. We assume that user preference is stable within a short period, thus treating a short time period as an environment. Some user preference is stable across environments, \eg the preference over seafood; while partial preference is shifting due to the changes of user features (\eg becoming pregnant).} {(b) shows the cosine similarity of item categories interacted by users in different environments of Amazon Book. The environments are chronologically split, starting from E0 to E5. It shows that item similarity decreases over time, revealing the interaction distribution shifts.}}
  \label{fig:example}
\end{figure}





Existing work mainly handles preference shifts from two perspectives: 
% 1) model re-training~\cite{zhang2020retrain} can refresh the user representations while it is limited by the training frequency and computation costs;
\begin{itemize}[leftmargin=*]
    \item \textit{Robust models against preference shifts.} The most representative approach is disentangled recommendation~\cite{ma2019learning, ma2020disentangled}, which disentangles several independent representations to represent different user preference. Disentangled representations are less sensitive to preference shifts~\cite{ma2019learning} since only partial representations are shifted while most are robust in the OOD environment. Nevertheless, existing work usually ignores the temporal shifting patterns of user preference across environments, limiting the generalization ability of recommender models. 
    
    \item \textit{Sequential models to predict the shifts.} Sequential recommendation~\cite{zhang2021cause, xie2021adversarial} recognizes the preference shifts by modeling the temporal patterns within the interaction sequence. 
    %However, user preference is probably invariant in a short period (\eg an environment in Figure~\ref{fig:example}), which is usually neglected by current methods.
    % However, these methods would overemphasize the shifts, neglecting the invariant parts, \eg user preference is probably invariant in a short period (\eg an environment in Figure~\ref{fig:example})~\cite{SeqHyper}.
    However, these sequential models typically overlook the sparse influence of user preference on interactions: partial preference shifts between environments only affect a small portion of user interactions. Ignoring such sparse influence may harm the interaction predictions over extensive irrelevant items, resulting in many inappropriate recommendations in OOD environments. 
    % Overemphasizing the latest interactions by sequential modeling might forget earlier interactions within an environment. 
\end{itemize}



% There lacks a comprehensive view that reveals the factors causing preference shifts. % or keeping preference invariant.
% We resort to causal language to inspect the causal relations in the generation procedure of user-item interaction sequences. 
% As shown in Figure~\ref{fig:causal_graph}, user interaction sequence is divided into multiple short time periods, where each period is viewed as an environment. 
% $E_t$ represents the unobserved user features (\eg pregnancy) or environmental factors (\eg hot events) in the environment $t$, which affect the user preference $Z_t$ and subsequent interactions $X_t$. 
% From the figure, we conclude that: 
% 1) within each environment, user preference is relatively stable; 
% 2) however, the changes of $E_t$ from $E_{t-1}$ (\eg becoming pregnant) will shift some user preference from $Z_{t-1}$ to $Z_t$; and 3) in a specific environment, different interactions in $X_t$ are sparsely affected by different preference in $Z_t$ as shown in the right figure of Figure \ref{fig:causal_graph}.
% Therefore, preference shifts should be considered at a fine-grained level.  

There lacks a comprehensive view to reveal the underlying factors regarding user preference shifts. 
As such, we resort to causal language to inspect the causal relations behind the generation procedure of user interaction sequences. 
As shown in Figure~\ref{fig:causal_graph}, the interaction sequence is divided into multiple short time periods, where each period is viewed as an environment. 
$E_t$ represents the unobserved user features (\eg pregnancy) or environmental factors\footnote{Recommender models can observe few factors affecting preference due to privacy restriction and technical challenges~\cite{wang2018toward}.} (\eg hot events) in the environment $t$, which affect the user preference $Z_t$ and interactions $X_t$. 
Within each environment, user preference is relatively stable; however, some changes from $E_{t-1}$ to $E_t$ (\eg becoming pregnant) will shift user preference from $Z_{t-1}$ to $Z_t$. 
As to the effect of $Z_t$ on $X_t$, various category-level preference in $Z_t$ sparsely affects the interactions in $X_t$ as shown in the right part of Figure \ref{fig:causal_graph}. For instance, the preference over the category ``Toy'' influences the interactions with toy products. Due to the sparse influence, partial preference shifts from $Z_{t-1}$ to $Z_t$ only affect some interactions. 



% Therefore, preference shifts should be considered at a fine-grained level.  

% 存在的问题：
% 1. 三个considerations之间的逻辑关系
% 2. 合并考虑两者的优势
% 3. 对于三个considerations的具体实现

% 第三段：causal分析preference shifts 背后的因素。
% 1. invariant preference: within environment. cross-environment 强调第二点。
% 2. shifted preference.
% 3. sparse influence: 突出sparse influence有利于鲁棒。
% 总结：要合并两者考虑，并且建模sparse influence。因为这样可以1）更好地估计user preference，2）更好地建模user preference的影响。
% 基于causal relationships 去建模数据生成过程，从而实现更鲁棒的preference预测in OOD environments

% 第四段，讲实现的idea。
% 1. invariant preference: within environment -> ignore temporal info. cross-environment -> invariance loss.
% 2. shifted preference -> sequential modeling
% 3. sparse influence  -> disentangled representations.

% 第五段讲具体实现。

% Accordingly, we consider learning disentangled representations across environments with preference shifts. In this way, 1) the temporal preference shifts across environments can be captured by sequential modeling, 
% and 2) within each environment, we assume the user preference is stable and learn the invariant user preference by ignoring the temporal information and fairly considering every user interaction.
% Moreover, the division of environments is beneficial for learning disentangled representations~\cite{locatello2020weakly}. 
% The core of disentangled representation learning is a structure between several independent user representations and interactions on different items. The structure describes that each interaction is affected by which factorized user representation. An invariant structure learned from multiple environments rather than one environment will generalize better in the future OOD environments~\cite{locatello2019challenging}. 
% Therefore, our targets are: 1) capturing the temporal preference shifts across environments; 2) modeling the invariant user preference within each environment; and 3) learning the invariant structure from multiple environments.

% Accordingly, we consider learning disentangled representations across environments with preference shifts. 
% Specifically, 1) for invariant preference modeling, we assume that the user preference during a short period is stable, and some preference across environments (\eg stable preference over seafood in Figure \ref{fig:example}) is also invariant. To learn the former invariant preference, we ignore the temporal information and fairly consider every user interaction within an environment. Besides, the invariant preference across environments is modeled by pursuing robust predictions over multiple environments. 
% 2) The temporal preference shifts from $Z_{t-1}$ to $Z_t$ across environments can be captured by sequential modeling.
% And 3) to model the sparse effect of $Z_t$ on $X_t$, we aim to learn a structure between several factorized preference representations and interactions on different items, which describes which interaction is affected by which preference. By this sparse structure, the shifted preference representations only decide the interactions over partial items, further improving the robustness against preference shifts. 
% To summarize, our objectives are: 1) capturing the invariant user preference; 2) modeling the temporal preference shifts across environments; and 3) learning the sparse structure for disentangled representations.
%  we consider modeling the interaction generation procedure 

According to the causal relations, the key of handling user preference shifts lies in simultaneously 1) capturing the temporal shifts across environments ($Z_{t-1} \rightarrow Z_t$), \ie accurate preference prediction, and 2) disentangling the sparse influence from user preference to the interactions ($Z_t \rightarrow X_t$), \ie accurate effect estimation of preference. Disentangling such influence is essentially discovering the causal structure from  $Z_t$ to $X_t$~\cite{pearl2009causality, he2021daring}.
However, it is non-trivial to model the temporal preference shifts and the sparse influence due to the following challenges: 1) the changes of $E_t$ between environments are usually unobserved, hindering the accurate preference prediction; and 2) the causal structure from hidden user preference to interactions also lacks supervision, which requires us to find additional signals for the structure discovery between $Z_t$ and $X_t$. 



% \begin{table}[t]
% \setlength{\abovecaptionskip}{0.1cm}
% \setlength{\belowcaptionskip}{0cm}
% \caption{Performance comparison on IID and OOD testings. We obtain the IID testing by randomly splitting the training and testing data to ensure their distributions are the same. By contrast, we divide the OOD testing by chronologically splitting the training and testing data, where the preference shifts over time so that the interaction distributions are drifted. We only present the results on two representative models and the Book dataset to save space. Other models on more datasets have similar observations.}
% \label{tab:iid_ood}
% \begin{center}
% \setlength{\tabcolsep}{1.2mm}{
% %\resizebox{0.46\textwidth}{!}{
% \begin{tabular}{l|cc|cc}
% \hline
% Dataset: Book & \multicolumn{2}{c|}{IID testing} & \multicolumn{2}{c}{OOD testing} \\ \hline
% Method & Recall@10 & NDCG@10 & Recall@10 & NDCG@10 \\ \hline
% LightGCN~\cite{he2020lightgcn} & 0.1132 & 0.0912 & 0.0252 & 0.0170 \\ 
% MacridVAE~\cite{ma2019learning} & 0.1396 & 0.1188 & 0.0409 & 0.0288 \\ \hline
% \end{tabular}
% %}
% }
% \end{center}
% \end{table}


% To this end, we propose a Causal Disentangled Recommendation (CDR) framework, which follows the interaction generation procedure in Figure~\ref{fig:causal_graph}.
% In particular, we instantiate CDR on a temporal Variational AutoEncoder (VAE), where an encoder is used to infer unobserved $E_t$ from observed $X_t$ and a decoder is to model the effect of $E_t$ on $X_t$ via $Z_t$. 
% Specifically, 1) the VAE captures the invariant preference within each environment by fairly considering each interaction, and models the invariant preference across environments via a variance regularization loss over multiple environments. 
% 2) Meanwhile, $Z_t$ is iteratively updated to model the temporal preference shifts across environments. 
% And 3) we introduce two learnable matrices to formulate the structure from $Z_t$ to $X_t$ for the disentanglement, and then control their sparsity via regularization. 
% During training and inference, we can flexibly adjust the division of environments to balance the modeling of shifted and invariant preference. 
% Extensive experiments on three real-world datasets validate the effectiveness of CDR on capturing preference shifts and achieving superior performance in the OOD environments. We release the code and data at \url{https://github.com/Linxyhaha/CDR}.

To this end, we propose a Causal Disentangled Recommendation (CDR) framework, which models the interaction generation procedure in Figure~\ref{fig:causal_graph}. 
Specifically, 1) to estimate the unobserved $E_t$, CDR introduces a temporal Variational AutoEncoder (VAE), where an encoder uses variational inference to infer unobserved $E_t$ from observed interactions $X_t$. Besides, a decoder is to estimate the effect of $E_t$ on $X_t$ via $Z_t$, where $Z_t$ is iteratively updated to model the temporal shifts across environments. 
2) Furthermore, we introduce two learnable matrices to formulate the causal structure from $Z_t$ to $X_t$. The two matrices disentangle the representations of $Z_t$ into category-level preference, which then sparsely affects the interactions in corresponding categories. 
Due to lacking supervision, we propose to learn the two matrices from multiple environments, where the distribution shifts shed light on the sparse structure learning between $Z_t$ and $X_t$~\cite{scholkopf2021toward, liu2021heterogeneous}.
In particular, we utilize the variance regularization to balance the predictions across environments and adopt the sparsity regularization to control the sparsity of the structure.
Note that the VAE ignores the temporal information and fairly considers each interaction within each environment, and thus it captures the invariant preference in a short period. As such, during training and inference, we can flexibly adjust the division of environments to balance the modeling of invariant preference within environments and shifted preference between environments. 
Extensive experiments on three real-world datasets validate the effectiveness of CDR in capturing preference shifts and achieving superior performance in the OOD environments. We release the code and data at \url{https://github.com/Linxyhaha/CDR}.


The main contributions of this work are threefold:
\begin{itemize}[leftmargin=*]
    \item We retrospect user preference shifts across multiple environments from a causal view and inspect the underlying causal relations via a causal graph. 
    \item 
    % We propose a CDR framework, which captures the shifted and invariant preference from multiple environments via a novel VAE and learns an invariant structure for the disentanglement.
    We propose a CDR framework, which captures the preference shifts between environments via a temporal VAE and learns a sparse structure between user preference and interactions for the robust interaction prediction. 
    % leverages invariant structure learning to disentangle user representations and adopts the temporal VAE to capture the preference trend. 
    \item Empirical results on three public datasets demonstrate the superiority of CDR over the baselines \wrt the OOD generalization ability under preference shifts. 
    
\end{itemize}

