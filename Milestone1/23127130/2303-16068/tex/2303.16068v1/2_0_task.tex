\section{Method}
In this section, we present the causal mechanism and task formulation of recommendation with consideration of preference shifts in Section \ref{sec:problem}. 
% inspect the causal relations behind user preference shifts via a causal graph, and then formulate generalizable recommendation 
Thereafter, we detail the proposed CDR framework in Section \ref{sec:method}. 

\subsection{Recommendation with Preference Shifts}
\label{sec:problem}


\begin{figure}[t]
\setlength{\abovecaptionskip}{0.2cm}
\setlength{\belowcaptionskip}{0cm}
\centering
\includegraphics[scale=0.7]{figures/causal_graph.pdf}
\caption{{Causal graph behind the interaction generation procedure with multiple environments. We assume that the observed user preference is affected by some hidden user features, and various user preference sparsely controls the interactions with different items.}}
\label{fig:causal_graph}
\end{figure}

Existing recommender models usually rely on the IID interaction distributions from training to testing stages. Without considering user preference shifts over time, 
these recommender models will encounter significant performance drop in OOD environments. 
To improve the generalization ability, we build recommender models with considering the preference shifts. 
In this subsection, we first scrutinize the causal relations regarding user preference shifts, and then formulate the task of generalizable recommendation to evaluate the generalization ability under preference shifts. 

% \vspace{3pt}
% % \noindent$\bullet\quad$\textbf{Causal View of Preference Shifts.}
% \noindent\textbf{Causal View of Preference Shifts.}
\subsubsection{\textbf{Causal View of Preference Shifts}}
We present the causal relations in Figure \ref{fig:causal_graph} and explain its rationality as follows:
\begin{itemize}[leftmargin=*]
    \item $E_t$ denotes unobserved user features (\eg pregnancy) or environmental factors (\eg hot events) in the environment $t$; $Z_t$ and $X_t$ represent the user preference and interactions, respectively. Because of the privacy restriction~\cite{wang2018toward}, we seldom utilize user features for recommendation, and thus we ignore the modeling of observed user features in Figure \ref{fig:causal_graph}, which can be easily incorporated as the input of the CDR framework if necessary. 
    
    \item $E_t \rightarrow Z_t$: user features and various environmental factors affect user preference.
    
    \item $Z_t \rightarrow X_t$: user interactions are determined by current user preference. {In particular, $Z_t$ covers the preference over multiple item categories (\eg seafood and toy). Some factors in $Z_t$ may represent the preference over an item category (\eg seafood), which sparsely affects a category of interactions as shown in Figure \ref{fig:causal_graph}}.
    
    \item $Z_{t-1} \rightarrow Z_t$: the user preference $Z_t$ in the environment $t$ is updated from previous $Z_{t-1}$, which exhibits the preference shifts over time. {From the causal graph, we find that various factors in $E_t$ can affect user preference $Z_t$ and cause the preference shifts $Z_{t-1} \rightarrow Z_t$, leading to the variation of user interaction distributions.
    % Such user preference shifts naturally exist in the real world, and thus we should capture the shifts for better recommendation instead of solving it. 
    Besides, the preference shifts between environments only influence partial interactions due to the sparse influence from $Z_t$ to $X_t$.}
    {\item $E_{t-1} \dashrightarrow E_t$ and $X_{t-1} \dashrightarrow Z_t$: $E_{t-1}$ might affect $E_{t}$ because user features might have conditional relations, \eg pregnancy $\rightarrow$ having child. Besides, user preference $Z_t$ can be influenced by previous interactions $X_{t-1}$. However, these conditional relations are not easy to be inferred from pure interactions, and the effects of these conditional relations on $Z_t$ and $X_t$ are relatively weaker than $(E_t, Z_{t-1})\rightarrow Z_t$ and $Z_t \rightarrow X_t$. As such, we omit the modeling of $E_{t-1} \dashrightarrow E_t$ and $X_{t-1} \dashrightarrow Z_t$ in this work to pursue a simple model with fewer parameters. Empirical evidence in Section~\ref{sec:condition_rel} also validates the superiority of our choice.}
\end{itemize}




% \vspace{3pt}
% % \noindent$\bullet\quad$\textbf{Generalizable Recommendation.}
% \noindent\textbf{Generalizable Recommendation.}
\subsubsection{\textbf{Task Formulation}}\label{sec:task}
To evaluate the generalization ability under preference shifts, we formulate the task of generalizable recommendation. Formally, we utilize $u \in \{1,2,...,U\}$, $i\in \{1,2,...,I\}$, and $t\in \{1,2,...,T\}$ to index the user, item, and environment, respectively. The interactions of user $u$ in $T$ environments are denoted as $\bm{x}_{1:T}$\footnote{For notation brevity, we omit the subscript $u$ for $\bm{x}_{1:T}$ and $\bm{z}_{1:T}$ of user $u$.}, where $\bm{x}_{t}\in \{0,1\}^I$ is a multi-hot vector, and $x_{t,i}$ implies that user $u$ likes item $i$ ($x_{t,i}=1$) or not ($x_{t,i}=0$). 
Generally, given the observed $\bm{x}_{1:T}$ of user $u$, \textbf{generalizable recommendation} aims to capture the hidden preference shifts in $\bm{z}_{1:T}$ and estimates the latest user preference $\bm{z}_T$. 

% generate satisfying recommendations. 
% even if $\bm{z}_T$ is shifted from $\bm{z}_{1:T-1}$.


\vspace{3pt}
\noindent$\bullet\quad$\textbf{Environment division.}
We can divide the environments by time, for instance, equally splitting the user interaction sequence into $T$ pieces, or clustering adjacent interactions according to the time interval. In this work, we choose the first one to simplify the data pre-processing.

\vspace{3pt}
\noindent$\bullet\quad$\textbf{{Inference for future environments.}}
{To evaluate the generalization ability of recommender models, we can utilize the interactions in the environment $T+1$ for testing. To infer the interaction probability in this unknown environment, we consider three strategies:
1) using the latest user preference $\bm{z}_T$ for prediction; 2) uniformly averaging the predictions in $T$ training environments; 3) considering the average user features $\bm{e}_{T+1}=\frac{1}{T}\sum^T_{t=1}\bm{e}_t$ and $\bm{z}_T$ to predict $\bm{z}_{T+1}$, and then using $\bm{z}_{T+1}$ for interaction prediction. Because the testing environment is unknown, these inference strategies inevitably make some assumptions. 
The first strategy requires the small preference shifts from environment $T$ to $T+1$. Meanwhile, the second and third strategies need the average over $T$ training environments, losing some temporal shifting patterns. In practice, we set the first strategy as the default due to its better performance on real-world datasets (refer to Section~\ref{sec:infer_unk}).
}


\vspace{3pt}
\noindent$\bullet\quad$\textbf{Difference from sequential recommendation.}
The main difference between generalizable and sequential recommendations is that generalizable recommendation emphasizes the preference shifts across environments and the invariant preference within an environment. Moreover, generalizable recommendation focuses on the predictions of multiple interactions in an OOD environment, which differs from the next-item prediction in sequential recommendation. 
