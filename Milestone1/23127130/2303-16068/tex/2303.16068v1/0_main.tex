
\documentclass[acmsmall]{acmart}
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

\setcopyright{acmcopyright}
\copyrightyear{2021}
\acmYear{2021}
\acmDOI{10.nn/nnnnnnn.nnnnnnn}


%%
%% These commands are for a JOURNAL article.
\acmJournal{JACM}
\acmVolume{1}
\acmNumber{1}
\acmArticle{111}
\acmMonth{1}

%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}
\usepackage{booktabs}
\usepackage{array}
\usepackage{balance} 
\usepackage{lipsum}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{subfigure}
% \usepackage{subcaption}
\usepackage{algorithm}  
\usepackage{algorithmicx}  
\usepackage{algpseudocode}  
\usepackage{amsmath}  
\usepackage{enumitem}
\usepackage{tabularx}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsthm}
\usepackage{bm}
\newcommand{\ie}{\emph{i.e., }}
\newcommand{\eg}{\emph{e.g., }}
\newcommand{\etal}{\emph{et al. }}
\newcommand{\st}{\emph{s.t. }}
\newcommand{\etc}{\emph{etc.}}
\newcommand{\wrt}{\emph{w.r.t. }}
\newcommand{\cf}{\emph{cf. }}
\newcommand{\aka}{\emph{a.k.a. }}

% for algorithm
\newlength\myindent
\setlength\myindent{2em}
\newcommand\bindent{%
    \begingroup
    \setlength{\itemindent}{\myindent}
    \addtolength{\algorithmicindent}{\myindent}
}
\newcommand\eindent{\endgroup}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}{Proposition}[section]
% \newtheorem{lemma}[theorem]{Lemma}

\usepackage[normalem]{ulem}
\useunder{\uline}{\ul}{}

\floatname{algorithm}{Algorithm}
\renewcommand{\algorithmicrequire}{\textbf{Input:}} 
\renewcommand{\algorithmicensure}{\textbf{Output:}}

% \newcommand{\wenjie}[1]{\textcolor{blue}{[Wenjie: {#1}]}}
\newcommand{\edit}[1]{\textcolor{blue}{#1}}
\newcommand{\editsec}[1]{\textcolor{orange}{#1}}

\clubpenalty=10000
\widowpenalty = 10000
\hyphenpenalty=7000
\tolerance=7000
% \usepackage[algoruled]{algorithm2e}
% \usepackage{algorithmic}
% \setlength{\interspacetitleruled}{8pt}
% \usepackage{listings}
% \usepackage{fancyvrb}
% \fvset{fontsize=\small}



%%
%% end of the preamble, start of the body of the document source.
\begin{document}

% \fancyhead{}
% \title{Invariant Structure Learning for Out-of-Distribution Recommendation}
% \title{Invariant Structure Learning for Generalizable Recommendation}
\title{Causal Disentangled Recommendation Against User Preference Shifts}

% \subtitle{Submission ID: 470}

\author{Wenjie Wang}
\email{wenjiewang96@gmail.com}
\affiliation{%
  \institution{National University of Singapore}
  \country{Singapore}
}
\author{Xinyu Lin}
\email{xylin1028@gmail.com}
\affiliation{%
  \institution{National University of Singapore}
  \country{Singapore}
}
\author{Liuhui Wang}
\email{wangliuhui0401@pku.edu.cn}
\affiliation{%
  \institution{Peking University}
  \country{China}
}
\author{Fuli Feng}
\authornote{Corresponding author: Fuli Feng (fulifeng93@gmail.com).}
\email{fulifeng93@gmail.com}
\affiliation{%
  \institution{University of Science and Technology of China}
  \country{China}
}

\author{Yunshan Ma}
\email{yunshan.ma@u.nus.edu}
\affiliation{%
  \institution{National University of Singapore}
  \country{Singapore}
}

\author{Tat-Seng Chua}
\email{dcscts@nus.edu.sg}
\affiliation{%
  \institution{National University of Singapore}
  \country{Singapore}
}

% \thanks{$*$ Corresponding author: Fuli Feng (fulifeng93@gmail.com). This research is supported by the Sea-NExT Joint Lab, and the National Natural Science Foundation of China (62121002).}

\begin{abstract}

% Recommender systems easily face the issue of user preference shifts. User representations will become out-of-date and lead to inappropriate recommendations if user preference has shifted over time.
% % To solve the issue, existing work focuses on learning the representations of invariant preference or recognizing the pattern of shifts. 
% To solve the issue, existing work focuses on learning robust representations or predicting the shifting pattern. 
% % There lacks an overall consideration from both perspectives, \ie ingeniously modeling both the invariant and shifted parts of user preference to achieve better generalization. 
% % In this work, we analyze and address this issue from a causal view. 
% There lacks a comprehensive view to discover the underlying reasons for user preference shifts. 
% To understand the preference shift, we abstract a causal graph to describe the generation procedure of user interaction sequences. 
% Assuming user preference is stable within a short period, we abstract the interaction sequence as a set of chronological environments. From the causal graph, we find that the changes of some unobserved factors (\eg becoming pregnant) cause preference shifts between environments. Besides, the fine-grained user preference over categories sparsely affects the interactions with different items.
% % Inspired by the causal graph, our key considerations to solving this issue lie in modeling the interaction generation procedure by:
% % 1) learning the invariant preference; 2) capturing the preference shifts across environments; and 3) learning robust disentangled representations for interaction generation. 
% Inspired by the causal graph, our key considerations to handle preference shifts lie in modeling the interaction generation procedure by: 1) capturing the preference shifts across environments for accurate preference prediction, and 2) disentangling the sparse influence from user preference to interactions for accurate effect estimation of preference.
% To this end, we propose a Causal Disentangled Recommendation (CDR) framework, which captures preference shifts via a temporal variational autoencoder and learns the sparse influence from multiple environments. 
% Specifically, an encoder is adopted to infer the unobserved factors from user interactions while a decoder is to model the interaction generation process. 
% Besides, we introduce two learnable matrices to disentangle the sparse influence from user preference to interactions. Lastly, we devise a multi-objective loss to optimize CDR. 
% Extensive experiments on three datasets show the superiority of CDR on enhancing the generalization ability under user preference shifts. 

Recommender systems easily face the issue of user preference shifts. User representations will become out-of-date and lead to inappropriate recommendations if user preference has shifted over time. To solve the issue, existing work focuses on learning robust representations or predicting the shifting pattern. There lacks a comprehensive view to discover the underlying reasons for user preference shifts. To understand the preference shift, we abstract a causal graph to describe the generation procedure of user interaction sequences. Assuming user preference is stable within a short period, we abstract the interaction sequence as a set of chronological environments. From the causal graph, we find that the changes of some unobserved factors (\eg becoming pregnant) cause preference shifts between environments. Besides, the fine-grained user preference over categories sparsely affects the interactions with different items. Inspired by the causal graph, our key considerations to handle preference shifts lie in modeling the interaction generation procedure by: 1) capturing the preference shifts across environments for accurate preference prediction, and 2) disentangling the sparse influence from user preference to interactions for accurate effect estimation of preference. To this end, we propose a Causal Disentangled Recommendation (CDR) framework, which captures preference shifts via a temporal variational autoencoder and learns the sparse influence from multiple environments. Specifically, an encoder is adopted to infer the unobserved factors from user interactions while a decoder is to model the interaction generation process. Besides, we introduce two learnable matrices to disentangle the sparse influence from user preference to interactions. Lastly, we devise a multi-objective loss to optimize CDR. Extensive experiments on three datasets show the superiority of CDR in enhancing the generalization ability under user preference shifts. 

\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
% <concept>
% <concept_id>10002951.10003260.10003261.10003271</concept_id>
% <concept_desc>Information systems~Personalization</concept_desc>
% <concept_significance>500</concept_significance>
% </concept>
<concept>
<concept_id>10002951.10003317.10003347.10003350</concept_id>
<concept_desc>Information systems~Recommender systems</concept_desc>
<concept_significance>500</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}
% \ccsdesc[500]{Information systems~Personalization}
\ccsdesc[500]{Information systems~Recommender systems}

\keywords{Causal Disentangled Recommendation, Preference Shifts, Generalizable Recommendation, Out-of-Distribution Generalization}


\maketitle

\input{1_intro}
\input{2_0_task}
\input{2_1_method}
\input{3_exp}
\input{4_related_work}
\input{5_conclusion}

% \clearpage



{
\tiny
\bibliographystyle{ACM-Reference-Format}
\balance
\bibliography{bibtex}
}
\appendix
% \input{6_SI}


\end{document}
\endinput