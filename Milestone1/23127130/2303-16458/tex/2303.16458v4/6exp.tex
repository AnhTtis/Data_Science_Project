\section{Experiments}


In this section, we evaluate the effectiveness of W2PGNN
with the goal of answering the following questions: (1) Given the pre-training and downstream data, is the feasibility of pre-training estimated by W2PGNN positively correlated with the downstream performance (Use case 2)? 
(2) When the downstream data is provided, 
does the pre-training data selected by W2PGNN actually help improve the downstream performance (Use case 3)? 

Note that it is impractical to empirically evaluate the application scope of graph pre-trained models  (Use case 1), as we cannot enumerate all graphs in the possible downstream space. 
By answering question (1), it can be indirectly verified that a part of graphs in the possible downstream space, \emph{i.e.}, the downstream graphs with high feasibility, indeed benefit from the pre-training.

\begin{table*}[!t]
\centering
\resizebox{1.8\columnwidth}{!}{
\begin{tabular}{lcccccccccc}
\toprule[1pt]
\multicolumn{1}{c}{\multirow{2}{*}{}} & \multicolumn{5}{c}{$N=2$}                & \multicolumn{5}{c}{$N=3$}              \\
\cmidrule[1pt](r){2-6}\cmidrule[1pt](r){7-11} \multicolumn{1}{c}{}                         & US-Airport & Europe-Airport & H-index & Chameleon & Rank & US-Airport & Europe-Airport & H-index & Chameleon & Rank \\ \midrule[1pt]
Graph Statistics                             & -0.6068    & 0.3571         & -0.6220 & -0.2930   & 10   & -0.7096    & -0.5052        & -0.2930 & -0.8173   & 10  \\
EGI                                          & 0.0672     & -0.6077        & -0.2152 & -0.2680   & 9   & -0.2358    & -0.5540        & -0.2822 & -0.6511   & 9   \\
Clustering Coefficient                       & -0.0273    & 0.1519         & 0.3622  & 0.3130    & 5    & -0.0039    & 0.2069         & 0.4829  & 0.2279    & 4    \\
Spectrum of Graph Laplacian                  & -0.2023    & 0.1467         & 0.0794  & 0.0095    & 8    & -0.7648    & -0.4311        & 0.2611  & -0.2300   & 8    \\
Betweenness Centrality           & -0.2739    & -0.2554        & 0.2051  & 0.2241    & 7    & -0.3421    & -0.5903        & 0.1364  & 0.0849    & 7    \\ \midrule
W2PGNN (intergr)                             & 0.3579     & 0.1224         & 0.3313  & 0.1072    & 6    & 0.0841     & 0.5310         & 0.4213  & -0.0916   & 6    \\
W2PGNN (domain)                   & \textbf{0.4774}     & 0.4666         & 0.6775  & 0.3460    & 3    & \textbf{0.7132}     & 0.5523         & \textbf{0.7381}  & 0.1857    & 3    \\
W2PGNN (topo)                                & 0.2059     & 0.3908         & 0.3745  & 0.4464    & 4    & 0.4900     & 0.5061         & 0.4072  & 0.1497    & 5    \\
W2PGNN ($\alpha=1$)                          & 0.4172     & 0.5206         & 0.6829  & 0.4391    & 2    & 0.5282     & 0.6663         & 0.7240  & \textbf{0.3246}    & 1    \\
W2PGNN                                       & 0.3941     & \textbf{0.5336}         & \textbf{0.7162}  & \textbf{0.4838}    & 1    & 0.5089     & \textbf{0.6706}         & 0.6754  & 0.3166    & 2    \\ \bottomrule[1pt]
\end{tabular}
}
\caption{Pearson correlation coefficient between the estimated pre-training feasibility and the best downstream performance on node classification. {$N$ denotes the number of candidate pre-training datasets that form the pre-training data.} \textbf{Bold} indicates the highest coefficient. ``Rank'' represents the overall ranking on all downstream datasets.} 
 \vspace{-0.2in}
\label{tab:node_classification_results}
\end{table*} 

\begin{table*}[!t]
\centering
% \setlength{\tabcolsep}{4pt}
\resizebox{1.8\columnwidth}{!}{
\begin{tabular}{lcccccccccccc}
\toprule[1pt]
\multicolumn{1}{c}{\multirow{2}{*}{}} & \multicolumn{6}{c}{$N=2$}              & \multicolumn{6}{c}{$N=3$}            \\
\cmidrule[1pt](r){2-7}\cmidrule[1pt](r){8-13} \multicolumn{1}{c}{}                         & BACE    & BBBP    & MUV     & HIV     & ClinTox & Rank & BACE    & BBBP    & MUV     & HIV     & ClinTox & Rank \\ \midrule[1pt]
Graph Statistics                             & -0.4118 & -0.1328 & 0.3858  & 0.0174  & -0.3577 & 9    & -0.3093 & -0.1430 & 0.1946  & 0.3545  & -0.1372 & 7    \\
EGI                                          & 0.2912  & -0.6862 & 0.4488  & 0.0587  & 0.0452  & 7    & 0.4570  & 0.3230  & 0.3024  & 0.4144  & -0.0085 & 3    \\
Clustering Coefficient                       & -0.5098 & -0.5097 & 0.3754  & 0.4738  & 0.5154  & 8    & -0.4080 & 0.3217  & -0.1190 & -0.2483 & -0.4248 & 9   \\
Spectrum of Graph Laplacian                  & -0.0633 & -0.4878 & -0.3413 & -0.1125 & -0.2562 & 10   & -0.3563 & -0.1611 & -0.2294 & -0.2448 & 0.3001  & 8    \\
Betweenness Centrality           & -0.0021 & 0.7755  & 0.4040  & 0.0339  & 0.3411  & 6    & -0.3695 & -0.4568 & -0.2752 & -0.3035 & -0.2129 & 10   \\ \midrule
W2PGNN (intergr)                             & 0.7547  & \textbf{0.7790}  & 0.2907  & 0.7033  & 0.5639  & 3    & 0.4081  & 0.4687  & -0.0567 & 0.3802  & 0.4354  & 5    \\
W2PGNN (domain)                   & 0.7334  & 0.7689  & 0.5395  & 0.6831  & 0.5431  & 5    & 0.0864  & 0.3680  & 0.0187  & 0.4784  & 0.3765  & 6    \\
W2PGNN (topo)                                & 0.6656  & 0.7164  & {0.8131}  & \textbf{0.7391}  & 0.5406  & 2    & 0.1109  & 0.5357  & 0.0514  & 0.3265  & 0.4724  & 4    \\
W2PGNN ($\alpha=1$)                          & 0.6549  & 0.7690  & 0.6730  & 0.7033  & 0.5639  & 4    & 0.5287  & \textbf{0.7102}  & 0.1925  & 0.5893  & 0.5430  & 2    \\
W2PGNN                                       & \textbf{0.7549}  & 0.7776  & \textbf{0.8131}  & 0.7044  & \textbf{0.5784}  & 1    & \textbf{0.6207}  & 0.6696  & \textbf{0.5227}  & \textbf{0.6529}  & \textbf{0.5994}  & 1    \\ \bottomrule[1pt]
\end{tabular}
}
\caption{Pearson correlation coefficient between the  feasibility and the best downstream performance on graph classification.} 
 \vspace{-0.2in}
\label{tab:graph_classification_results}
\end{table*}




 \vspace{-0.1in}
\subsection{Experimental Setup}

We validate our proposed framework on both node classification and graph classification task. 

\vpara{Datasets.} 
For node classification task, we directly adopt six datasets from~\cite{Qiu2020GCCGC} as the candidates of pre-training data, which consists of Academia, DBLP(SNAP),
DBLP(NetRep), IMDB, Facebook and LiveJournal (from academic, movie and social domains). Regarding the downstream datasets, we adopt US-Airport and  H-Index from~\cite{Qiu2020GCCGC} and additionally add two more datasets Chameleon and Europe-Airport for a more comprehensive results.
For graph classification task, we choose the large-scale datasets ZINC15~\cite{Sterling2015ZINC1} containing 2 million unlabeled molecules.
To enrich the follow-up experimental analysis, we use scaffold split to partition the ZINC15 into five datasets ({ZINC15-0, ZINC15-1, ZINC15-2, ZINC15-3 and ZINC15-4}) according to their scaffolds~\cite{hu2019strategies}, such that the scaffolds are different in each dataset.
Regarding the downstream datasets, we use 5 classification benchmark
datasets BACE, BBBP, MUV, HIV and ClinTox  contained in MoleculeNet~\cite{wu2018moleculenet}. 
% The dataset details are summarized in Appendix~\ref{app:data}.






\vpara{Baseline of graph pre-training measures.} 
The baselines can be divided into 3 categories: 
(1) EGI~\cite{Zhu2021TransferLO} computes the difference between the graph Laplacian of (sub)graphs from pre-training data and downstream data;
(2) Graph Statistics, {by which} we merge average degree,  degree variance,  density,  degree assortativity coefficient,  transitivity and  average clustering coefficient to
construct a topological vector for each (sub)graph.
(3) Clustering Coefficient,
Spectrum of Graph Laplacian, and Betweenness Centrality, {by which} we adopt the distributions of graph properties as topological vectors.
For (2) and (3), we calculate the negative value of Maximum Mean Discrepancy distance between the obtained topological vectors of the (sub)graph from pre-training data and that from downstream data.
% For baselines, the distance/difference is computed between one ego-network (for node classification) or graph (for graph classification) from pre-training data and another one from downstream data.
For efficiency, when conducting node classification, we randomly sample 10\% nodes for each candidate pre-training dataset and all nodes for each downstream dataset, then extract their 2-hop ego-networks. 
The final measure is the average of distances/differences between each pair of pre-training and fine-tuning graphs.
% The final measure is the \JR{average?} of all distances/differences of each pair of pre-training and finetuning graphs.

    
\vpara{Implementation Details.} 
For node classification tasks, we randomly sample 1000 nodes for each pre-training dataset and extract 2-hops ego-networks of sampled nodes to compose our input space, and extract 2-hops ego-networks of all nodes in each downstream dataset to estimate the graphon.
For graph classification tasks, we take all graphs in each pre-training dataset to compose our input space and use all graphs in each downstream dataset to estimate graphon.
When constructing topological graphon basis, we set the the number of clusters $k=5$. The maximum iterations number of K-Means is set as $300$.  When constructing domain graphon basis, we take each pre-training dataset as a domain. 
For graphon estimation, we use the largest gap~\cite{channarond2012classification} approach and let {the block size of graphon } as the average number of nodes in all graphs.
When learning  ${\alpha_i}$,
we adopt Adam as the optimizer and set the learning rate $\eta$ as 0.05.
For the GW distance, we adopt its differential and efficient version entropic regularization GW distance with default hyperparameters~\cite{peyre2016gromov}. We
provide an open-source implementation of our model W2PGNN at https://github.com/caoyxuan/W2PGNN.
% \vspace{-0.2in}
\subsection{Results of Pre-training Feasibility}
\label{subsec:6.2}
\vpara{Setup.}
% When evaluating the pre-training feasibility, since its ground truth is unavailable,  we adopt the best downstream performance among a set of graph pre-training models as the ground truth.
{As a pre-judgement to assess the necessity of pre-training before conducting any pre-training/fine-tuning attempts, the graph pre-training feasibility should reveal the optimal case that downstream data can benefit from pre-training data. However, it is impractical to obtain the optimal case, because we cannot enumerate all factors affecting model performance, \emph{e.g.}, pre-training strategies, fine-tuning strategies, backbone models. Hence we use the best downstream performance achieved among existing commonly-used pre-training models as an approximation.}


For node classification tasks, we use the following 4 graph pre-training models: GraphCL~\cite{you2020graph} and GCC models~\cite{Qiu2020GCCGC} with three different  hyper-parameter (\emph{i.e.,}  128, 256 and 512 rw-hops).
For graph classification tasks, we adopt 7 SOTA
pre-training models:  AttrMasking~\cite{hu2019strategies}, ContextPred~\cite{hu2019strategies}, EdgePred~\cite{hu2019strategies},
Infomax~\cite{hu2019strategies}, GraphCL~\cite{you2020graph}, GraphMAE~\cite{hou2022graphmae} and JOAO~\cite{you2021graph}. 
When pre-training, we directly use the default hyper-parameters of pre-training models except the rw-hops in GCC.
During fine-tuning, we freeze the parameters of pre-trained models and utilize the logistic regression as classifier for node classification  and SVM as classifier for graph classification, following~\cite{Qiu2020GCCGC} and its fine-tuning  hyper-parameters. The downstream results are reported as the average of Micro F1 and  ROC-AUC under 10 runs on node classification and graph classification respectively. For each downstream task, we take the best performance among all methods. 

\begin{figure*}[!pt]
 \centering{\includegraphics[width=\linewidth]{figure/Figure_2.pdf}}
\caption{{Pre-training feasibility vs. the best downstream performance on node classification 
when the selection buget is 2.}  }
\label{fig:corre}
\vspace{-0.1in}
\end{figure*}


\begin{table*}[!h]
\centering
\resizebox{1.8\columnwidth}{!}{
\begin{tabular}{lcccccccccc}
\toprule[1pt]
\multicolumn{1}{c}{\multirow{2}{*}{}} & \multicolumn{5}{c}{$N=2$}                                                                                                                    & \multicolumn{5}{c}{$N=3$}     \\
\cmidrule[1pt](r){2-6}\cmidrule[1pt](r){7-11} \multicolumn{1}{c}{}                         & \multicolumn{1}{c}{US-Airport} & \multicolumn{1}{c}{Europe-Airport} & \multicolumn{1}{c}{H-index} & \multicolumn{1}{c}{Chameleon} & \multicolumn{1}{c}{Rank} & \multicolumn{1}{c}{US-Airport} & \multicolumn{1}{c}{Europe-Airport} & \multicolumn{1}{c}{H-index} & \multicolumn{1}{c}{Chameleon} & \multicolumn{1}{c}{Rank}  \\ \bottomrule[1pt]
\cellcolor{ggray!90} All Datasets                                      & \cellcolor{ggray!90} 65.62                          & \cellcolor{ggray!90} 55.65                              & \cellcolor{ggray!90}75.22                       & \cellcolor{ggray!90}46.81                         &   \cellcolor{ggray!90}-                     & \cellcolor{ggray!90}65.62                          & \cellcolor{ggray!90}55.65                              & \cellcolor{ggray!90}75.22                       & \cellcolor{ggray!90}46.81                                         &     \cellcolor{ggray!90} -                 \\
\toprule
Graph Statistics                             & 64.20                         &  53.36                            & 74.30                       & 44.31                         & 4                        & 62.27                          & 54.58                              & 72.88                        & 43.87                         & 5                           \\
EGI                                          &  \textbf{64.96}  &         57.37   &  74.30  &    43.21 & 2                        &  62.27    &       57.36 &   72.88 &45.93                        & 3                          \\
Clustering Coefficient                       &  62.61  &         52.87 &   \textbf{77.74}     & 43.21   & 3                        & 62.94      &     54.58 &   75.18     & 44.66 & 4                      \\
Spectrum of Graph Laplacian                  &  61.76 &          \textbf{57.88} &    73.14   &   42.20  & 5                        & \textbf{63.95}        &   54.87  &  73.90    &  44.66    & 2                         \\
Betweenness Centrality           &  \textbf{64.96} &          52.87 &   73.50   &   41.63  & 6                      & 62.27         &  54.87&  75.18 &     43.87    & 6                       \\ \midrule
W2PGNN                                       & \textbf{64.96}                       & \textbf{57.88}                             & 77.24               & \textbf{45.54}                         & 1                        & \textbf{63.95}                         & \textbf{57.59}                            & \textbf{75.68}                      & \textbf{46.07}                         & 1  \\  \bottomrule[1pt]  
\end{tabular}
}
\caption{Node classification results when performing pre-training on different selected pre-training data. We also provide the results of using all pre-training data without selection for your reference (see ``All Datasets'' in the table).}
\label{tab:node_classification_data_selection_results}
 \vspace{-0.2in}
\end{table*}


For a comprehensive evaluation on the correlation between the estimated pre-training feasibility and the best downstream performance, we need to construct multiple $\langle \mathcal G_\text{train}, \mathcal G_\text{down} \rangle$ sample pairs as our evaluation samples.
When constructing the $\langle \mathcal G_\text{train}, \mathcal G_\text{down} \rangle$ sample pairs for each downstream data, multiple pre-training data are required to be paired with it.
Hence we adopt the following two settings to augment the choice of pre-training data for more possibilities. 
We use $N$ as the number of dataset candidates contained in pre-training data.
% (1) For $N=2$, we randomly select 2 pre-training dataset candidates as pre-training data and enumerate all possible cases.
% (2) For $N=3$, we randomly select 3 pre-training dataset candidates as pre-training data. 
{For $N=2$ and $N=3$, we randomly select 2 and 3 pre-training dataset candidates, respectively as pre-training data.}
We enumerate all possible combination cases for graph classification tasks and randomly select 40\% of all cases for node classification tasks for efficiency.


\vpara{Results.} 
Table~\ref{tab:node_classification_results} (for node classification) and Table~\ref{tab:graph_classification_results} (for graph classification) show the Pearson correlation coefficient between the best downstream performance and the estimated pre-training feasibility by W2PGNN and baselines for each downstream dataset.  A higher coefficient indicates a better estimation of pre-training feasibility.
We also include 4 variants of W2PGNN:  W2PGNN (intergr), W2PGNN (domain) and W2PGNN (topo) only utilize the integrated graphon basis, domain graphon basis and topological graphon basis to approximate feasibility respectively, and W2PGNN ($\alpha=1$) set the learnable  combination weights $\{\alpha_i\}$ as constant 1.
We have the following observations.
(1) The results show that our model achieve the highest overall ranking in most cases, indicating the superiority of our proposed framework. 
(2) We find that the measures provided by other baselines sometimes show no correlation or negative correlation with the best downstream performance. 
(3) Comparing W2PGNN and its variants, we find that although the variants sometimes achieve superior performance on some downstream datasets, they cannot consistently perform well on all datastes. In contrast, the top-ranked W2PGNN can provide a more comprehensive picture with various graph bases and learnable combination weights.

To provide a deeper understanding of the feasibility estimated by W2PGNN, Figure~\ref{fig:corre} shows our estimated pre-training feasibility (in x-axis) versus the best downstream performance on node classification (in y-axis) of all <pre-training data, downstream data> pairs (one point represents the result of one pair) when the selection budget is 2.
The plots when the selection budget is 3 and the plots under graph classification can be found in Appendix~\ref{app:graph_class_res}.
We find that there is a strong positive correlation between estimated pre-training feasibility and the best downstream performance on all downstream datasets, which also suggests the significance of our feasibility.

 \vspace{-0.15in}
\subsection{Results of Pre-Training Data Selection}
Given the downstream data,  a collection of pre-training dataset candidates and a selection budget (\emph{i.e.}, the number of datasets selected for pre-training) due to limited resources, we aim to select the pre-training data with the highest feasibility, so as to benefit the downstream performance.


\vpara{Setup.} 
We here adopt two settings, \emph{i.e.}, selection budget is set as 2 and 3 respectively. The datasets that are augmented for more pre-training data choices in Section~\ref{subsec:6.2} can be directly used as the candidates of pre-training datasets here.
Then, the selected pre-training data serves as the input of graph pre-training model.
For node classification tasks, we adopt GCC as the pre-training model as an example, because it is the   pre-training model that can be generalized across domains and most of the datasets used for node classification are taken from it~\cite{Qiu2020GCCGC}.
For graph classification tasks, we take GraphCL as the pre-training model as it provides multiple graph augmentation approaches and is more general~\cite{you2020graph}.

\vpara{Results.}
Table~\ref{tab:node_classification_data_selection_results} shows the results of pre-training data selection on node classification task. (The results on graph classification is included in Appendix~\ref{app:graph_class_res2}). We have the following observations.
(1) We can see that the pre-training data selected by W2PGNN ranks first, which is the most suitable one for downstream.
(2) We find that sometimes simple graph property like clustering coefficient serves as a good choice on a specific dataset (\emph{i.e.,} H-index), when the budget of pre-training data is 2. It is because that H-index exhibits the largest clustering coefficient compared to other downstream datasets,  which facilitates the data selection via clustering coefficient.
However, such simple graph property is only applicable when the downstream dataset shows a strong indicator of the property,
and is not helpful when you need to select more datasets for pre-training (see results under $N$=3).
(3) Moreover, it is also interesting to see that using all pre-training data for pre-training is not always a {reliable} choice. We find that carefully selecting pre-training data can not only benefit downstream performance but also reduce computation resources.

