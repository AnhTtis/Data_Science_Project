{
    "arxiv_id": "2303.09421",
    "paper_title": "Team SheffieldVeraAI at SemEval-2023 Task 3: Mono and multilingual approaches for news genre, topic and persuasion technique classification",
    "authors": [
        "Ben Wu",
        "Olesya Razuvayevskaya",
        "Freddy Heppell",
        "Jo√£o A. Leite",
        "Carolina Scarton",
        "Kalina Bontcheva",
        "Xingyi Song"
    ],
    "submission_date": "2023-03-16",
    "revised_dates": [
        "2023-03-17"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CL"
    ],
    "abstract": "This paper describes our approach for SemEval-2023 Task 3: Detecting the category, the framing, and the persuasion techniques in online news in a multi-lingual setup. For Subtask 1 (News Genre), we propose an ensemble of fully trained and adapter mBERT models which was ranked joint-first for German, and had the highest mean rank of multi-language teams. For Subtask 2 (Framing), we achieved first place in 3 languages, and the best average rank across all the languages, by using two separate ensembles: a monolingual RoBERTa-MUPPETLARGE and an ensemble of XLM-RoBERTaLARGE with adapters and task adaptive pretraining. For Subtask 3 (Persuasion Techniques), we train a monolingual RoBERTa-Base model for English and a multilingual mBERT model for the remaining languages, which achieved top 10 for all languages, including 2nd for English. For each subtask, we compare monolingual and multilingual approaches, and consider class imbalance techniques.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.09421v1"
    ],
    "publication_venue": null
}