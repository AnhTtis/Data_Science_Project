\section{Algorithm for $k$-Center Against an Adaptive Adversary}
\label{sec:app-det-upper}

\NewDocumentCommand{\subtree}{O{T} m}{%
	#1(#2)
}
\NewDocumentCommand{\subtreepoints}{m}{%
	\mathcal{P}(#1)
}
\NewDocumentCommand{\detcen}{m}{%
	C_{#1}%
}

\SetKwFunction{FnInsertNode}{InsertIntoNode}
\SetKwFunction{FnDeleteNode}{DeleteFromNode}
\SetKwFunction{FnTryCenter}{TryMakeCenter}
\SetKwFunction{FnInsert}{InsertPoint}
\SetKwFunction{FnDelete}{DeletePoint}
\SetKwData{iscen}{isCenter}
\SetKwData{islowb}{lowerBoundWitness}

We describe a deterministic algorithm for $k$-center that \aw{maintains an $O(\min\{\log(n/k) / \log \log (n + \Delta),k\})$-approximate solution
with an update time of $O(k \log n \cdot \log\Delta \cdot \log (n+\Delta))$.
Given some constant $\epsilon >0$, we maintain one data structure for each value
$\OPT'$ that is a power of $1+\epsilon$ in $[1,\Delta]$, i.e.,
$O(\log_{1+\epsilon}\Delta)$ many. The data structure for each such
value $\OPT'$ outputs a solution of cost at most $O(\min\{\log(n/k) / \log \log (n+\Delta),k\})\OPT'$
or asserts that $\OPT>\OPT'$. We output the solution with smallest
cost which is hence a $O(\min\{\log(n/k) / \log \log (n+\Delta),k\})$-approximation.

Given the value $\costbound$, our algorithm maintains} a hierarchy on the input represented by a $B$-ary tree $T$, which we call \emph{clustering tree}, where $B = \log (n + \Delta)$. The main property of the clustering tree is that the input points are stored in the leaves and each inner node stores a $k$-center set for the $Bk$ centers that are stored at its $B$ children.

\begin{definition}[clustering tree]
	\label{def:clustree}
	Let $\costbound > 0$, let $P$ be a set of points and let $T$ be a $B$-ary tree, where $B \geq 2$. We call $T$ a \emph{clustering tree} on $P$ with \emph{node-cost} $\costbound$ if the following conditions hold:
	\begin{enumerate}
		\item each node $u$ stores at most $Bk$ points from $P$, denoted $\points{u}$, \label{enum:ct-leaf-node}
		\item for each node $u$, at most $k$ points, denoted $\detcen{u}$, are marked as centers. Either, their $k$-center cost is at most $\costbound$ on all points stored in $u$, or $u$ is marked as a witness that there is no center set with cost at most $\costbound/2$, \label{enum:ct-cost}
		\item each inner node stores the at most $Bk$ centers of its children. \label{enum:ct-innernode}
	\end{enumerate}
\end{definition}

For each node $u$ in $T$, the algorithm maintains a corresponding graph on the at most $Bk$ points $\points{u}$ it stores, which is called \emph{blocking graph}. Without loss of generality, we assume that $T$ is a full $B$-ary tree with $n/(Bk)$ leaves. We explain in the proof of \cref{lem:det-main-kcenter} how to get rid of this assumption. For the sake of simplicity, we identify a node $u$ with its associated blocking graph $N=(V,E)$ in the following. For each node $N=(V,E)$, at most $k$ points are marked as centers (\iscen in \cref{alg:det-guess-node}), and the algorithm maintains the invariant that two centers $u,v \in V$ have distance at least $\costbound$ by keeping record of \emph{blocking} edges in the blocking graph between centers and points that have distance less than $\costbound$ to one of these centers. We say that a center $u$ \emph{blocks} a point $v$ (from being a center) if there is an edge $(u,v)$ in the blocking graph. In addition, the algorithm records whether $N$ contains more than $k$ points with pairwise distance greater than $\costbound$ (\islowb in \cref{alg:det-guess-node,alg:det-guess}).

\paragraph*{Insertions (see \FnInsert).} When a point $u$ is inserted into $T$, a node $N=(V,E)$ with less than $Bk$ points is selected and it is checked whether $d(v,u) \leq \costbound$ for any center $v \in V$. If this is the case, the algorithm inserts an edge $(u,v)$ for every such center $v$ into $E$ and terminates afterwards. Otherwise, the algorithm checks whether the number of centers is less than $k$. If this is the case, it marks $u$ as a center and inserts an edge $(u,w)$ for \emph{each point} $w \in V$ with $d(u,w) \leq \costbound$ and recurses on the parent of $N$. Otherwise, if there are more than $k-1$ centers in $u$, the algorithm marks $N$ as witness and terminates.

\paragraph*{Deletions (see \FnDelete).} When a point $u$ is deleted from $T$, the point is first removed from the leaf $N$ (and the blocking graph) where it is stored. If $u$ was not a center, the algorithm terminates. Otherwise, the algorithm checks whether any points were unblocked (have no adjacent node in the blocking graph) and, if this is the case, proceeds by attempting to mark these points as centers and inserting them into the parent of $N$ one by one (after marking the first point as center, the remaining points may be blocked again). Afterwards, the algorithm recurses on the parent of $N$.

\begin{algorithm}
	\SetKwData{neigh}{neighbors}
	\SetKwData{newcen}{newCenters}
	\KwData{$\iscen$ is a boolean array on the elements of $V$, $\islowb$ is a boolean array on the nodes of $T$}
	\Fn{\FnInsertNode{$N = (V,E), p, \costbound$}}{
		insert $p$ into $V$ \;
		\ForEach{$v \in V \setminus \{ p \}$}{
			\If{$\iscen[v] \wedge d(p,v) \leq \costbound$}{
				insert $(v,p)$ into $E$ \;
			}
		}
		\Return \FnTryCenter($G, p, \costbound$) \;
	}
	\Fn{\FnDeleteNode{$N = (V,E), p, \costbound$}}{
		$\newcen \gets \emptyset$ \;
		$\neigh \gets \ngh{p}$ \;
		delete $p$ from $N$ \;
		\If{$\iscen[p] = true$}{
			\ForEach{$u \in \neigh$}{
				$\newcen \gets \newcen \cup \FnTryCenter{N, u, \costbound}$ \;
			}
		}
		\Return{$\newcen$} \;
	}
	\Fn{\FnTryCenter{$N = (V,E), p, \costbound$}}{
		\If{$\dg{p} = 0 \wedge \lvert \{ v \mid v \in V \wedge \iscen[v] \} \rvert < k$}{
			$\iscen[p] \gets true$ \;
			\ForEach{$v \in V \setminus \{ p \}$}{
				\If{$d(p,v) \leq \costbound$}{
					insert $(p,v)$ into $E$ \;
				}
			}
			$\islowb[N] \gets false$ \;
			\Return{$\{ p \}$} \;
		}
		\ElseIf{$\dg{p} = 0$}{
			$\islowb[N] \gets true$ \;
		}
		\Return{$\emptyset$} \;
	}
	\caption{\label{alg:det-guess-node} Insertion and deletion of a point $P$ in a node of the clustering tree $T$ (represented by a blocking graph $G$).}
\end{algorithm}

\begin{algorithm}
	\SetKwData{cen}{centers}
	\SetKwData{newcen}{newCenters}
	\SetKwData{failed}{failed}
	\KwData{$\islowb$ is a boolean array on the nodes of $T$}
	\Fn{\FnInsert{$T, p, \costbound$}}{
		$N \gets$ leaf in $T$ that contains less than $Bk$ elements \;
		\Do{$\cen = \{ p \}$}{
			$\cen \gets \FnInsertNode{$N, p$}$ \;
			$N \gets N.parent$ \;
		}
	}
	\Fn{\FnDelete{$T, p, \costbound$}}{
		$N \gets$ leaf in $T$ that contains $p$ \;
		$\cen \gets \emptyset; \failed \gets false$ \;
		\Do{$N \neq null$}{
			$\cen \gets \cen \cup \FnDeleteNode{$N, p$}$ \;
			$\newcen \gets \emptyset$ \;
			\ForEach{$v \in \cen$}{
				$\newcen \gets \newcen \cup \FnInsertNode{N.parent, v}$ \;
			}
			$\cen \gets \newcen$ \;
			$N \gets N.parent$ \;
		}
	}
	\caption{\label{alg:det-guess} Insertion and deletion of a point $p$ in the clustering tree $T$.}
\end{algorithm}

Given a rooted tree $T$ and a node $u$ of $T$, we denote the subtree of $T$ that is rooted at $u$ by $\subtree{u}$. For a clustering tree $T$, we denote the set of all points stored at the leaves of $\subtree{u}$ by $\subtreepoints{u}$. Recall that the points directly stored at $u$ are denoted by $\points{u}$. Observe that for each node $u$ in a clustering tree, $\subtree{u}$ is a clustering tree of $\subtreepoints{u}$.

\subsection{Structural Properties of the Algorithm}

We show that \cref{alg:det-guess} maintains a clustering tree.

\begin{lemma}
	\label{lem:det-clustree-insert}
	Let $T$ be a clustering tree on a point set $P$. After calling $\FnInsert(T, p)$ (see \cref{alg:det-guess}) for some point $p \notin P$, $T$ is a clustering tree on $P \cup \{ p \}$.
\end{lemma}
\begin{proof}
	We prove the statement by induction over the recursive calls of \FnInsertNode in \FnInsert. Let $N=(V,E)$ be the leaf in $T$ where $p$ is inserted. Condition~\ref{enum:ct-leaf-node} in \cref{def:clustree} is guaranteed for $N$ by \FnInsert. The algorithm \FnInsertNode ensures that $p$ is marked as a center only if it is not within distance $\costbound$ of any other center. Let $C$ be the center set of $N$ before inserting $p$. By condition~\ref{enum:ct-cost}, $C$ has $\cost[V]{C} \leq \costbound$. Let $C'$ be the center set of any optimal solution on $V$. If $\cost[V]{C'} \leq \costbound / 2$, each center of $C$ covers at least one cluster of $C'$. By pigeonhole principle, $p$ is not blocked by a center in $C$ if and only if $\lvert C \rvert < k$. Otherwise, if $\cost[V]{C'} > \costbound/2$, $p$ is chosen if no center in $C$ covers $p$ and $\lvert C' \rvert < k$, or $N$ is marked as witness. It follows that condition~\ref{enum:ct-cost} is still satisfied for $N$ after \FnInsertNode terminates.
	
	Now, let $N=(V,E)$ be any inner node in a call to $\FnInsertNode(N,p)$. We note that such call is only made if $p$ was marked as a center in its child $N'$ on which $\FnInsertNode$ was called before by $\FnInsert$. Thus, $p$ is inserted into $V$ if and only if $p$ is a center in $N'$. Therefore, condition~\ref{enum:ct-cost} is satisfied for $N$. By the above reasoning, condition~\ref{enum:ct-innernode} is also satisfied.
\end{proof}

\begin{lemma}
	Let $T$ be a clustering tree on a point set $P$. After calling $\FnDelete(T, p)$ (see \cref{alg:det-guess}) for some point $p \in P$, $T$ is a clustering tree on $P \setminus \{ p \}$.
\end{lemma}
\begin{proof}
	We prove the statement by induction over the loop's iterations in \FnDelete. Let $N=(V,E)$ be the leaf in $T$ where $p$ was inserted. \FnDeleteNode deletes $p$ from $N$ and iterates over all unblocked points to mark them as centers one by one. After deleting $p$, condition~\ref{enum:ct-leaf-node} holds for $N$. Let $U$ be the set of unblocked points after removing $p$, let $C$ be the center set after removing $p$ from $V$, and let $C'$ be the center set of any optimal solution on $V \setminus \{ p \}$. If $\cost[V]{C'} \leq \costbound / 2$, each unblocked point from $U$ covers at least one cluster of $C'$ with cost $\costbound$. Therefore, any selection of $k - \lvert C \rvert$ points from $U$ that do not block each other together with $C$ is a center set for $V$ with cost $\costbound$. Otherwise, if $\cost[V]{C'} > \costbound / 2$, a set of at most $k - \lvert C \rvert$ points from $U$ is chosen, or $N$ is marked as witness. It follows that condition~\ref{enum:ct-cost} is still satisfied for $N$ after \FnDeleteNode terminates. Let $C''$ be the center set that is returned by \FnDeleteNode. \FnDelete inserts all points from $C''$ into the parent node. This reinstates condition~\ref{enum:ct-innernode} on the parent node. Then, \FnDeleteNode recurses on the parent.
\end{proof}

\subsection{Correctness of the Algorithm}

We use the following notion of super clusters and its properties to prove the $O(k)$ upper bound on the approximation ratio of the algorithm.

\begin{definition}[super cluster]
	\label{def:supercluster}
	Let $P$ be a set of points and let $C$ be a center set with $\cost[P]{C} \leq 2\costbound$. Consider the graph $G = (C, E)$, where $E = \{ (u,v) \mid d(u,v) \leq 2\costbound \}$. For every connected component in $G$, we call the union of clusters corresponding to this component a \emph{super cluster}.
\end{definition}

\begin{lemma}
	\label{lem:clustree-supercluster}
	Let $T$ be a clustering tree constructed by \cref{alg:det-guess} with node-cost $\costbound$ and no node marked as witness. For any node $N$ in $T$, $N$ contains one point from each super cluster in $\subtreepoints{N}$ that is marked as center.
\end{lemma}
\begin{proof}
	Let $S$ be a supercluster of $P$. Let $N$ be a node in $T$ that contains a point $p \in S$. For the sake of contradiction, assume that there exists no point $q \in S \cap N$ that is marked as center. By \cref{def:supercluster}, the $k$-center clustering cost of the centers in $N$ is greater than $\costbound$. By \cref{def:clustree}.\ref{enum:ct-cost}, this implies that a point must be marked as witness. This is a contradiction to the assumption that no node is marked as witness.
\end{proof}

The following simple observation leads to the bound of $O(\log (n/k) / \log \log (n+\Delta))$ on the approximation ratio.


\begin{observation}
	\label{lem:kcenter-of-cluster}
	Let $c > 0$, $\ell \in \mathbb{N}$, let $P_1, \ldots, P_\ell$ be sets of points and let $C_1, \ldots, C_\ell$ so that $\cost[P_i]{C_i} \leq c$ for every $i \in [\ell]$. For every $k$-center set $C'$ with $\cost[\cup_i C_i]{C'} \leq c'$ we have $\cost[\cup_i P_i]{C'} \leq c + c'$ by the triangle inequality.
\end{observation}

We combine the previous results and obtain the following approximation ratio for our algorithm.

\begin{lemma}
	\label{lem:det-kcenter-cost}
	Let $T$ be a clustering tree on a point set $P$ that is constructed by \cref{alg:det-guess} with node-cost $\costbound$. Let $C$ be the points in the root of $T$ that are marked as centers. If no node in $C$ is marked as witness, $ \cost[P]{C} \leq \min\{k, \log(n/k) / \log B \} \cdot 4 \opt{P}$. Otherwise, $\opt{P} \geq \costbound / 2$.
\end{lemma}
\begin{proof}
	Assume that $\opt{P} \leq \costbound / 2$, as otherwise, there exists a node that stores at least $k+1$ points that have pairwise distance $\costbound$, which implies the claim. First, we prove $\cost[P]{C} \leq \log(n/(Bk)) / \log B \cdot \costbound$. It follows from \cref{lem:kcenter-of-cluster} that $C$ has $k$-center cost $2\costbound$ on the points stored in the root's children. Since $T$ has depth at most $\log(n/(Bk)) / \log B$, it follows by recursively applying \cref{lem:kcenter-of-cluster} on the children that $C$ also has cost $\log(n/(Bk)) / \log B \cdot 2 \costbound$ on $P$.
	
	Now, we prove $\cost[P]{C} \leq k$. Let $p \in P$, and let $S$ be the super cluster of $p$ with corresponding optimal center set $C'$. We have $d(p,C') \leq \costbound / 2$. By \cref{lem:clustree-supercluster}, there exists a center $q \in C$ so that $d(q,C') \leq \costbound / 2$. By the definition of super clusters, for every $x,y \in C'$, $d(x,y) \leq (k-1) \cdot 2\costbound$. It follows from the triangle inequality that $d(p,q) \leq 2k \costbound$.
\end{proof}

\subsection{Update Time Analysis}

\begin{lemma}
	\label{lem:det-time}
	The amortized update time of \cref{alg:det-guess} is $O(Bk \log (n/k) / \log B)$.
\end{lemma}
\begin{proof}
	To maintain blocking graphs efficiently, the graphs are stored in adjacency list representation and the degrees of the vertices as well as the number of centers are stored in counters. When a point $p$ is inserted, $3Bk \log (n/(Bk)) / \log B$ tokens are paid into the account of $p$. Each token pays for a (universally) constant amount of work.
	
	Each point is inserted at most once in each of the $\log (n/(Bk)) / \log B$ nodes from the leaf where it is inserted up to the root. The key observation is that it is marked as a center in each of these nodes at most once (when it is inserted, or later when a center is deleted): Marking a point as center is irrevocable until it is deleted. For each node $N$ and point $p \in N$, it can be checked in constant time whether $p$ can be marked as a center in $N$ by checking its degree in the blocking graph. Marking $p$ as a center takes time $O(Bk)$ because it is sufficient to check the distance to all other at most $Bk$ points in $N$ and insert the corresponding blocking edges. For each point $p$, we charge the time it takes to \emph{mark} $p$ as a center to the account of $p$. Therefore, marking $p$ as center withdraws a most $Bk \log (n/(Bk))$ tokens from its account in total.
	
	Consider the insertion of a point $p$ into a node. As mentioned, $p$ is inserted in at most $\log (n/(Bk)) / \log B$ nodes, and in each of these nodes, it is inserted at most once (when it is inserted into the tree, or when it is marked as a center in a child node). Inserting a point into a node $N$ requires the algorithm to check the distance to all at most $k$ centers in $N$ to insert blocking edges, which results in at most $k \log (n/(Bk)) / \log B$ work in total.
	
	It remains to analyze the time that is required to update the tree when a point $p$ is deleted. For any node $N$, if $p$ is not a center in $N$, deleting $p$ takes constant time. Otherwise, if $p$ is a center, the algorithm needs to check its at most $Bk$ neighbors in the blocking graph one by one whether they can be marked as centers. Checking a point $q$ takes only constant time, and marking $q$ as a center has already been charged to $q$ by the previous analysis. All centers that have been marked have to be inserted into the parent of $N$, but this has also been charged to the corresponding points. Therefore, deleting $p$ consumes at most $Bk \log (n/(Bk)) / \log B$ tokens from the account of $p$.
\end{proof}

\begin{lemma}
	\label{lem:det-time-worstcase}
	The worst-case insertion time of \cref{alg:det-guess} is $O(Bk \log(n/k) / \log B)$, and the worst-cast deletion time is $O(Bk^2 \log(n/k) / \log B)$.
\end{lemma}
\begin{proof}
	To maintain blocking graphs efficiently, the graphs are stored in adjacency list representation and the degrees of the vertices as well as the number of centers are stored in counters.
	
	Each point is inserted at most once in each of the $\log (n/(Bk)) / \log B$ nodes from the leaf where it is inserted up to the root. For each node $N$ and point $p \in N$, it can be checked in constant time whether $p$ can be marked as a center in $N$ by checking its degree in the blocking graph. Marking $p$ as a center takes time $O(Bk)$ because it is sufficient to check the distance to all other at most $Bk$ points in $N$ and insert the corresponding blocking edges.
	
	Consider the insertion of a point $p$ into the tree. As mentioned, $p$ is inserted in at most $\log (n/(Bk)) / \log B$ nodes. Therefore, during the initial insertion of $p$ into the tree, the insertion procedure may insert $p$ into at most $\log (n/(Bk)) / \log B$ nodes. Inserting a point into a node $N$ requires the algorithm to check the distance to all at most $k$ centers in $N$ to insert blocking edges and possibly marking it as a center, which results in at most $O(Bk \log (n/(Bk)) / \log B)$ time in total.
	
	Now, consider the deletion of $p$ from the tree. For any node $N$, if $p$ is not a center in $N$, deleting $p$ takes constant time. Otherwise, if $p$ is a center, the algorithm needs to check its at most $Bk$ neighbors in the blocking graph one by one whether they can be marked as centers. Checking a point $q$ takes only constant time, and marking $q$ as a center takes time $O(Bk)$. All at most $k$ points that have been marked have to be inserted into the parent of $N$, which takes time $O(Bk \cdot k)$. As the length of any path from a leaf to the root is at most $\log(n/(Bk)) / \log B$, deleting $p$ requires at most $O(Bk^2 \log (n/(Bk)) / \log B)$ time.
\end{proof}

\subsection{Main Theorem}

It only remains to combine all previous results to obtain \cref{thm:mpt-det-upper}.

\begin{theorem}[\cref{thm:mpt-det-upper}]
	\label{lem:det-main-kcenter}
	Let $\epsilon, k > 0$ and $B \geq 2$. There exists a deterministic algorithm for the dynamic $k$-center problem that has amortized update time $O(Bk \log n \log(\dmax) / \log(1+\epsilon))$ and approximation factor $(1+\epsilon) \cdot \min\{4k, 4\log(n/k) / \log B\}$. The worst-cast insertion time is $O(Bk \log n \log\Delta / \log(1+\epsilon))$, and the worst-case deletion time is $O(Bk^2 \log n \log\Delta / \log(1+\epsilon))$.
\end{theorem}
\begin{proof}
	Since $P = (\points{1}, \ldots, \points{n})$ is a dynamic point set, its size $n_i := \lvert \points{i} \rvert$ can increase over time. Therefore, we need to remove the assumption that the clustering tree has depth $\log(\max_{t \in [n]} n_t)$. First, we note that we can insert and delete points so that the clustering tree $T$ is a complete $B$-ary tree (the inner nodes induce a full $B$-tree, and all leaves on the last level are aligned left): We always insert points into the left-most leaf on the last level of $T$ that is not full; when a point is deleted from a leaf $N$ that is not the right-most leaf $N'$ on the last level of $T$, we delete an arbitrary point $q$ from $N'$ and insert $q$ into $N$. Deleting and reinserting points this way can be seen as two update operations, and therefore, it can only increase time required to update the tree by a factor of $3$. Furthermore, any leaf can be turned into an inner node by adding a copy of itself as its left child and adding an empty node as its right child. Vice versa, an empty leaf and its (left) sibling can be contracted into its parent. This way, the algorithm can guarantee that the depth of the tree is between $\lfloor \log(n_t/(Bk)) / \log B \rfloor$ and $\lceil \log(n_t/(Bk)) / \log B \rceil$ at all times $t \in [n]$.
	
	Recall that $d(x,y) \geq 1$ for every $x,y \in \cX$, and $\dmax = \max_{x,y \in \cX} d(x,y)$. For every $\Gamma \in \{ (1+\epsilon)^i \mid i \in [\lceil \log_{1+\epsilon} (\dmax) \rceil]$, the algorithm maintains an instance $T_\Gamma$ of a clustering tree with node-cost $\costbound = (1+\epsilon)^\Gamma$ by invoking \cref{alg:det-guess}. After every update, the algorithm determines the smallest $\Gamma$ so that no node in $T_\Gamma$ is marked as witness, and it reports the center set of the root of $T_\Gamma$. The bound on the cost follows immediately from \cref{lem:det-kcenter-cost}. Since there are at most $\log(\dmax) / \log(1+\epsilon)$ instances, the bounds on the running time follow from \cref{lem:det-time,lem:det-time-worstcase}.	
\end{proof}
