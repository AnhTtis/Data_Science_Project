\section{Algorithms for $k$-Sum-of-Radii and $k$-Sum-of-Diameters}

\label{sec:primal-dual}

In this section we present our (randomized) dynamic $(13.008+\epsilon)$-approximation
algorithm for $k$-sum-of-radii with an amortized update time of $k^{O(1/\epsilon)}\log\Delta$,
against an oblivious adversary. Our strategy is to maintain a 
bi-criteria approximation with $O(k/\epsilon)$ clusters whose sum of radii is at most $(6+\epsilon)\OPT$
(and which covers all input points). We show how to use an arbitrary
offline $\alpha$-approximation algorithm to turn this solution into
a $(6+2\alpha+\eps)$-approximate solution with only $k$ clusters.
Using the algorithm in \cite{CharikarP04} (for which $\alpha=3.504+\eps$),
this yields a dynamic $(13.008+\epsilon)$-approximation for $k$-sum-of-radii,
and hence a $(26.015+\eps)$-approximation for $k$-sum-of-diameters. %
We provide the algorithm and a high-level overview of its analysis in \cref{sec:pd-bicriteria,sec:pd-dynamic}. The details of the formal proofs can be found in \cref{sec:pd-proofs}.

\subsection{Bicriteria Approximation}
\label{sec:pd-bicriteria}

Assume that we are given an $\epsilon>0$ such that w.l.o.g.~it holds
that $1/\epsilon\in\N$. We maintain one data structure for each value
$\OPT'$ that is a power of $1+\epsilon$ in $[1,\Delta]$, i.e.,
$O(\log_{1+\epsilon}\Delta)$ many. The data structure for each such
value $\OPT'$ outputs a solution of cost at most $(13.008+\epsilon)\OPT'$
or asserts that $\OPT>\OPT'$. We output the solution with smallest
cost which is hence a $(13.008+O(\epsilon))$-approximation.
We describe first how to maintain the mentioned bi-criteria approximation.
We define $z:=\epsilon\OPT'/k$. Our strategy is to maintain a solution
for an auxiliary problem based on a Lagrangian relaxation-type approach.
More specifically, we are allowed to select an arbitrarily
large number of clusters, however, for each cluster we need to pay
a fixed cost of $z$ plus the radius of the cluster.
For the radii we allow only integral multiples of $z$ that are bounded
by $\OPT'$, i.e., only radii in the set $R=\{z,2z,...,\OPT'-z,\OPT'\}$.

This problem can be modeled by an integer program. We formulate the
problem as an LP $(P)$ which has a variable
$x_{p}^{(r)}$ for each combination of a point $p$ and a radius~$r$
from a set of (suitably discretized) radii $R$, and a constraint
for each point $p$. Let $(D)$ denote its dual LP, see below, where
$z:=\epsilon\OPT'/k$.

\begin{alignat*}{9}
	\min & \,\,\, & \sum_{p\in P}\sum_{r\in R}x_{p}^{(r)}(r+z) &  &  &  &  &  &  &  & \max & \,\,\, & \sum_{p\in P}y_{p}\,\,\,\,\,\,\,\,\,\,\,\\
	\mathrm{s.t.} &  & \sum_{p'\in P}\sum_{r:d(p,p')\le r}x_{p'}^{(r)} & \ge1 & \,\,\, & \forall p\in P & \,\,\,\,\,\,\,\: & (P) & \,\,\,\,\,\,\,\,\,\,\,\,\,\,\, &  & \mathrm{s.t.} &  & \sum_{p'\in P:d(p,p')\le r}y_{p'} & \le r+z & \,\,\, & \forall p\in P,r\in R & \,\,\,\,\,\,\,\:(D)\\
	&  & x_{p}^{(r)} & \ge0 &  & \forall p\in P\,\,\forall r\in R &  &  &  &  &  &  & y_{p} & \ge0 &  & \forall p\in P
\end{alignat*}

We describe first an offline
primal-dual algorithm that computes an integral solution to~$(P)$ and
a fractional solution to the dual $(D)$, so that their costs differ
by at most a factor $6$. By weak duality, this implies that our solution
for $(P)$ is a $6$-approximation. 
We initialize $x\equiv0$ and $y\equiv0$, define $U_{1}:=P$, and
we say that a pair $(p',r')$ \emph{covers a point }$p$ if $d(p',p)\le r'$.
Our algorithm works in iterations. %

At the beginning of the $i$-th iteration, assume that we are given
a set of points $U_{i}$, a vector $\big(x_{p}^{(r)}\big)_{p\in P,r\in R}$,
and a vector $\left(y_{p}\right)_{p\in P}$, such that $U_{i}$ contains
all points in $P$ that are not covered by any pair $(p,r)$ for which
$x_{p}^{(r)}=1$ (which is clearly the case for $i=1$ since $U_{1}=P$
and $x\equiv0$). We select a point $p\in U_{i}$ uniformly at random
among all points in $U_{i}$. We raise its dual variable $y_{p}$
until there is a value $r\in R$ such that the dual constraint for
$(p,r)$ becomes \emph{half-tight, }meaning that %
$\sum_{p':d(p,p')\le r}y_{p'}=r/2+z.$ %

Note that it might be that the constraint is already at least half-tight
at the beginning of iteration $i$ in which case we do not raise $y_{p}$
but still perform the following operations. Assume that $r$ is the
largest value for which the constraint for $(p,r)$ is at least half-tight.
We define $x_{p}^{(2r)}:=1$, $(p_{i},r_{i}):=(p,2r)$ and set $U_{i+1}$
to be all points in $U_{i}$ that are not covered by $(p,2r)$. 
\begin{lemma}
	\label{lem:pd-iteration-time} Each iteration $i$ needs a running
		time of $O(\lvert U_{i}\rvert+ik/\epsilon)$. \end{lemma} 
We stop
when in some iteration $i^{*}$ it holds that $U_{i^{*}}=\emptyset$
or if we completed the $(2k/\epsilon)^{2}$-th iteration and $U_{(2k/\epsilon)^{2}+1}\ne\emptyset$.
Suppose that $x$ and $y$ are the primal and dual vectors after the
last iteration. In case that $U_{(2k/\epsilon)^{2}}\ne\emptyset$
we can guarantee that our dual solution has a value of more than $\OPT'$
from which we can conclude that $\OPT>\OPT'$; therefore, we stop
the computation for the estimated value $\OPT'$ in this case. 
\begin{lemma}[{restate=[name=]lemPdIterationsBound}]
	\label{lem:pd-iterations-bound}
	If $U_{(2k/\epsilon)^2 + (2k/\epsilon)}\ne\emptyset$ then $\OPT>\OPT'$. 
\end{lemma}
If $U_{(2k/\epsilon)^{2}}=\emptyset$
we perform a pruning step in order to transform $x$ into a
solution whose cost is at most by a factor $3$ larger than the cost
of $y$. We initialize $\bar{S}:=\emptyset$.
Let $S=\{(p_{1},r_{1}),(p_{2},r_{2}),...\}$ denote the set
of pairs $(p,r)$ with $x_{p}^{(r)}=1$. We sort the pairs in $S$
non-increasingly by their respective radius $r$. Consider a pair
$(p_{j},r_{j})$. We insert the cluster $(p_{j},3r_{j})$ in our solution $\bar{S}$
and delete from $S$ all pairs $(p_{j'},r_{j'})$ such that $j'>j$
and $d(p_{j},p_{j'})<r_{j}+r_{j'}$. Note that $(p_{j},3r_{j})$ covers
all points that are covered by any deleted pair $(p_{j'},r_{j'})$
due to our ordering of the pairs. Let $\bar{S}$ denote
the solution obained in this way and let $\bar{x}$ denote the corresponding
solution to $(P)$, i.e., $\bar{x}_{p}^{(r)}=1$ if and only if $(p,r)\in\bar{S}$.
We will show below that $\bar{S}$ is a feasible solution to~$(P)$
with at most $O(k/\epsilon)$ clusters. Let $\bar{C}\subseteq P$
denote their centers, i.e., $\bar{C}=\{p\mid\exists r\in R:(p,r)\in\bar{S}\}$.
\begin{lemma} \label{lem:mpt-pd-pruning-time} Given $x$ we can
	compute $\bar{x}$ in time $O((k/\epsilon)^{4})$ and $\bar{x}$ selects
	at most $O(k/\epsilon)$ centers. %
\end{lemma} 
We transform now the bi-criteria approximate solution $\bar{x}$ into a feasible solution
$\tilde{x}$ with only $k$ clusters. To this end, we invoke the offline
$(3.504+\epsilon)$-approximation algorithm from \cite{CharikarP04}
on the input points $\bar{C}$. Let $\hat{S}$ denote the set of pairs
$(\hat{p},\hat{r})$ that it outputs (and note that not necessarily
$\hat{r}\in R$ since we use the algorithm as a black-box). Note that
$\hat{S}$ covers only the points in $\bar{C}$, and not necessarily
all points in $P$. 
On the other hand, the solution $\hat{S}$ has a cost of at most $2\OPT$ since
	we can always find a solution with this cost covering $\bar{C}$, even if we are only allowed
	to select centers from $\bar{C}$.
Thus, based on $\bar{S}$ and $\hat{S}$ we compute
a solution $\tilde{S}$ with at most $k$ clusters that covers $P$.
We initialize $\tilde{S}:=\emptyset$. For each pair $(\hat{p},\hat{r})\in\hat{S}$
we consider the points $\bar{C}'$ in $\bar{C}$ that are covered
by $(\hat{p},\hat{r})$. Among all these points, let $\bar{p}$ be
the point with maximum radius $\bar{r}$ such that $(\bar{p},\bar{r})\in\bar{S}$.
We add to $\tilde{S}$ the pair $(\hat{p},\hat{r}+\bar{r})$ and remove
$\bar{C}'$ from $\bar{C}$. We do this operation with each pair $(\hat{p},\hat{r})\in\hat{S}$.
Let $\tilde{S}$ denote the resulting set of pairs. 
\begin{lemma}[{restate=[name=]lemPdOfflineTime}]
	\label{lem:pd-offline-time}
	Given $\bar{S}$ and $\hat{S}$ we can compute $\tilde{S}$ in time
	$O(k^3/\epsilon^2)$. 
\end{lemma}

We show that $\tilde{S}$ is a feasible solution with small cost.
We start by bounding the cost of $\bar{x}$ via $y$. 
\begin{lemma}[{restate=[name=]lemPdCostA}]
	\label{lem:pd-cost-a}
	We have that $\bar{x}$ and $y$ are feasible solutions to (P) and
	(D), respectively, for which we have that 
	$
	\sum_{p\in P}\sum_{r\in R}\bar{x}_{p}^{(r)}(r+z)\le 6\cdot\sum_{p\in P}y_{p}\le6\OPT'.
	$
\end{lemma}
Next, we argue that $\tilde{S}$ is feasible and bound
its cost by the cost of $S'$ and the cost of $\bar{x}$. 
\begin{lemma}[{restate=[name=]lemPdCostB}]
	\label{lem:pd-cost-b}
	We have that $\tilde{S}$ is a feasible solution with cost at most
	$\sum_{(\hat{p},\hat{r})\in \hat{S}}\hat{r}+\sum_{p\in P}\sum_{r\in R}\bar{x}_{p}^{(r)}(r+z)\le(13.008+\epsilon)\OPT'$. 
\end{lemma}

\subsection{Dynamic Algorithm}
\label{sec:pd-dynamic}

We describe now how we maintain the solutions $x,\bar{x},y,S,\bar{S}$,
and $\tilde{S}$ dynamically when points are inserted or deleted.
Our strategy is similar to \cite{ChaFul18}.

Suppose that a point $p$ is inserted. For each $i\in\{1,...,2k/\epsilon+1\}$
we insert $p$ into the set $U_{i}$ if $U_{i}\ne\emptyset$ and $p$
is not covered by a pair $(p_{j},r_{j})$ with $j\in\{1,...,i-1\}$.
If there is an index $i\in\{1,...,2k/\epsilon+1\}$ such that $U_{i-1}\ne\emptyset$
(assume again that $U_{0}\ne\emptyset$), $U_{i}=\emptyset$, and
$p$ is not covered by any pair $(p_{j},r_{j})$ with $j\in\{1,...,i-1\}$,
we start the above algorithm in the iteration $i$, being initialized
with $U_{i}=\{p\}$ and the solutions $x,y$ as being computed previously.

Suppose now that a point $p$ is deleted. We remove $p$ from each
set $U_{i}$ that contains $p$. If there is no $r\in R$ such that
$(p,r)\in S$ then we do not do anything else. Assume now that $(p,r)\in S$
for some $r\in R$. %
The intuition is that this does not happen very often since in each
iteration $i$ we choose a point uniformly at random from $U_{i}$.
More precisely, in expectation the adversary needs to delete a constant
fraction of the points in $U_{i}$ before deleting $p$. Consider
the index $i$ such that $(p,r)=(p_{i},r_{i})$. We restart the algorithm
from iteration $i$. More precisely, we initialize $y$ to the values
that they have after raising the dual variables $y_{p_{1}},...,y_{p_{i-1}}$
in this order as described above until a constraint for the respective
point $p_{j}$ becomes half-tight. We initialize $x$ to the corresponding
primal variables, i.e., $x_{p_{j}}^{(2r_{j})}=1$ for each $j\in\{1,...,i-1\}$
and $x_{p'}^{(r')}=0$ for all other values of $p',r'$. Also, we
initialize the set $U_{i}$ to be the obtained set after removing
$p$. With this initialization, we start the algorithm above in iteration
$i$, and thus compute like above the (final) vectors $y,x$ and based
on them $S,\bar{S}$, and $\tilde{S}$.

When we restart the algorithm in some iteration $i$ then it takes
time $O(|U_{i}|k^{2})$ to compute the new set $S$. We can charge
this to the points that were already in $U_{i}$ when $U_{i}$ was
recomputed the last time %
and to the points that were inserted into $U_{i}$ later. After a
point $p$ was inserted, it is charged at most $O(k/\epsilon)$ times
in the latter manner since it appears in at most $O(k/\epsilon)$
sets $U_{i}$. Finally, given $S$, we can compute the sets $\bar{S}$,
$\hat{S}$, and $\tilde{S}$ in time $O(k^{3}/\epsilon^{2})$. The
algorithm from \cite{CharikarP04} takes time $n^{O(1/\epsilon)}$ if the input has size $n$.
One can show that this yields an update time of $k^{O(1/\epsilon)}+(k/\epsilon)^{4}$
for each value $\OPT'$. Finally, the same set $\tilde{S}$ yields
a solution for $k$-sum-of-diameters, increasing the approximation
ratio by a factor of~2. 

\thmPdMain*

\subsection{Deferred Proofs}
\label{sec:pd-proofs}

\SetKwFunction{FnPrimalDual}{PrimalDual}
\SetKwFunction{FnPrune}{Prune}

In this section, we formally prove the correctness of \cref{alg:pd} for the $k$-sum-of-radii and the $k$-sum-of-diameter problem. To compute a solution in the static setting, the algorithm is invoked as $\FnPrimalDual(P, \emptyset, R, z, k, \epsilon, 0, 0, 0)$, where $P$ is the set of input points, $R$ is the set of radii, $z = \epsilon \OPT' / k$ is the facility cost and $k$ is the number of clusters. \Cref{alg:pd} is a pseudo-code version of the algorithm described earlier.

\begin{algorithm}
	\SetKwData{null}{null}
	\KwData{point set $P$, unassigned point sets $U = \{ U_0, \ldots \}$, radii set $R$, facility cost $z$, number of clusters $k$, precision $\epsilon$, primal vector $x = \{ x^{(r)}_p \mid r \in R \wedge p \in P \}$, dual vector $Y = \{ y_p \mid p \in P \}$}
	\Fn{\FnPrimalDual($P, U, R, z, k, \epsilon, x, y, i$)}{
		\While{$U_i \neq \emptyset$}{
			$p_i \gets$ uniformly random point from $U_i$ \;
			$\delta_i \gets \max ( \{ 0 \} \cup \{\delta' \mid \delta' \in \R \wedge \forall r' \in R : \sum_{p' \in P : d(p_i, p') \le r'} y_{p'} + \delta' \leq r'/2 + z \} )$ \;
			\If{$\delta_i > 0$}{
				$r_i \gets \max \{r' \mid r' \in R \wedge \sum_{p' \in P : d(p_i, p')\le r'} y_{p'} + \delta_i = r'/2 + z \}$ \;
			}
			\Else{
				$r_i \gets \max \{r' \mid r' \in R \wedge \sum_{p' \in P : d(p_i, p')\le r'} y_{p'} \geq r'/2 + z \}$ \;
			}
			$y_{p_i} \gets \delta_i$; $x^{(2r_i)}_{p_i} \gets 1$ \;
			$U_{i+1} \gets U_i \setminus \{ p' \mid p' \in U_i \wedge d(p_i, p') \leq 2r_i \}$ \;
			$i \gets i + 1$ \;
			\If{$i > (2k/\epsilon)^2$}{
				\Return{``$\OPT' < \OPT$''} \;
			}
		}
		$\bar{S} \gets \emptyset$; $S \gets$ sort $(p_j, r_j)_{j \in [i-1]}$ non-increasingly according to $r_j$ \;
		\ForAll{$(p,r) \in S$}{
			\If{$\nexists (p_j,r_j) \in \bar{S} : d(p, p_j) \leq r + r_j$}{
				$\bar{S} \gets \bar{S} \cup \{ (p, 3r) \}$ \;
			}
		}
		\Return{$\bar{S}, U, x, y, r, i$} \;
	}
	\caption{\label{alg:pd} Pseudo code of the primal-dual algorithm for $k$-sum-of-radii as described in \cref{sec:primal-dual}.}
\end{algorithm}

\paragraph{Proof of \cref{lem:pd-iteration-time}}

We bound the running time of a single primal-dual step. This implies \cref{lem:pd-iteration-time}.

\begin{lemma}[\cref{lem:pd-iteration-time}]
	The running time of the $i$\xth/ iteration of the while-loop in \FnPrimalDual is $O(ik / \epsilon + \lvert U_i \rvert)$.
\end{lemma}
\begin{proof}
	In each iteration, at most one entry of $y$, i.e., $y_{p_i}$, increases. Therefore, at most $i-1$ entries of $y$ are non-zero at the beginning of iteration $i$. By keeping a list of non-zero entries, each sum corresponding to a constraint of the dual program can be computed in time $O(i)$. Since $\lvert R \rvert \leq k / \epsilon$, it follows that $\delta_i$ and $r_i$ can be computed in time $O(ik/\epsilon)$. To construct $U_{i+1}$, it is sufficient to iterate over $U_i$ once.
\end{proof}

\paragraph{Proof of \cref{lem:pd-iterations-bound}}

We show that our choice of $z = \epsilon \OPT' / k$ will result in a solution $\bar{S}$ if $\OPT \leq \OPT'$.

\lemPdIterationsBound*
\begin{proof}
	Since, by weak duality, $\sum_{p \in P} y_p$ is a lower bound to the optimum value of $(P)$, we bound the number of iterations that are sufficient to guarantee $\sum_{p \in P} y_p > \OPT'$. Call an iteration of the while-loop in \FnPrimalDual \emph{successful} if $\delta_i > 0$, and \emph{unsuccessful} otherwise. First, observe that for each successful iteration $i$, the algorithms increases $y_{p_i}$ by at least $z/2$. This is due to the fact that all values in $R$ are multiples of $z$, and therefore $r/2 + z$ is a multiple of $z/2$ for any $r \in R$. Since the algorithm increases $y_{p_i}$ as much as possible, all $y_{p_i}$ are multiples of $z/2$. Therefore, after $\OPT' / (z/2) +1= 2k / \epsilon +1$ successful iterations, it holds that $\OPT \geq \sum_{p \in P} y_p > \OPT'$.
	
	Now, we prove that for each successful iteration, there are at most $\lvert R \rvert$ unsuccessful iterations. Then, it follows that after $((2k/\epsilon)+1) \cdot \lvert R \rvert \leq (2k/\epsilon)^2 + (2k/\epsilon)$ iterations, $\OPT > \OPT'$. Let $i$ be an unsuccessful iteration. The crucial observation for the following argument is that for the maximum $r_i \in R$ so that $(p_i, r_i)$ is at least half-tight and for any $j < i$ so that $d(p_i, p_j) \leq r_i$ and $y_{p_j} > 0$, we have $r_j < r_i$: otherwise, $p_i$ would have been removed from $U_j$. On the other hand, such $p_j$ must exist because the dual constraint $(p_i, r_i)$ is at least half-tight but $y_{p_i} = 0$. Now, we \emph{charge} the radius $r_i$ to the point $p_j$ and observe that we will never charge $r_i$ to $p_j$ again. This is due to the fact that all points $p \in U_{i-1}$ with distance $d(p_j, p) \leq r_i$ are removed from $U_i$ because $d(p_i, p) \leq d(p_i, p_j) + d(p_j, p) \leq 2r_i$. Therefore, for any successful iteration $j$ and any $r \in R$, there is at most one $i > j$ so that $r = r_i$ is charged to $p_j$, each accounting for an unsuccessful iteration. 
\end{proof}

\paragraph{Proof of \cref{lem:mpt-pd-pruning-time}}

We argue that the pruning step has running time $\textrm{poly}(k/\epsilon)$ to prove \cref{lem:mpt-pd-pruning-time}.

\begin{lemma}[\cref{lem:mpt-pd-pruning-time}]
	\label{lem:pd-pruning-time}
	The for-loop in \FnPrimalDual has running time $O((k/\epsilon)^4)$.
\end{lemma}
\begin{proof}
	Since $i \leq 2(2k/\epsilon)^2$, it holds that $\lvert S \rvert \leq \lvert \{ p \in P \mid \exists  r \in R : x^{(r)}_p > 0 \} \rvert \leq 2(2k/\epsilon)^2$. Therefore, sorting $S$ requires at most $O((2k/\epsilon)^2 \log (2k/\epsilon))$ time. In each iteration of the loop, it suffices to iterate over $\bar{S}$. Since $\lvert \bar{S} \rvert \leq \lvert S \rvert$, the claim follows.
\end{proof}

\paragraph{Proof of \cref{lem:pd-offline-time}}

\lemPdOfflineTime*
\begin{proof}
	Recall that we sort points in $S$ non-increasingly. Therefore, for every point $p$, there exists only one $(p,r) \in S$ that is inserted into $\bar{S}$. It follows that $\lvert \bar{S} \rvert \leq \lvert S \rvert \leq (2k/\epsilon)^2$ and since $\lvert \hat{S} \rvert \leq k$, it suffices to iterate over $\bar{S}$ for every $(\hat{p}, \hat{r}) \in \hat{S}$.
\end{proof}

\paragraph{Proof of \cref{lem:pd-cost-a}}

We turn to the feasibility and approximation guarantee of the solution that is computed by \cref{alg:pd}. First, we observe that the dual solution is always feasible.

\begin{lemma}
	\label{lem:always-dual-feasible}
	During the entire execution of \cref{alg:pd}, no dual constraint $(p, r)$ is violated.
\end{lemma}
\begin{proof}
	For the sake of contradiction, let $i$ be the first iteration of the while-loop in \FnPrimalDual after which there exists $(p,r)$ such that $\sum_{p' \in P : d(p, p') \leq r} > r + z$. From this definition, it follows that $d(p, p_i) \leq r$ as only $y_{p_i}$ has increased in iteration $i$. By the triangle inequality, for all $p' \in P$ so that $d(p,p') \leq r$, we have that $d(p_i,p') \leq 2r$. Therefore, the dual constraint $(p_i, 2r)$ is more than half-tight:
	\begin{align*}
		\sum_{p' \in P : d(p_i, p') \leq 2r} y_{p'}
		\geq \sum_{p' \in P : d(p, p') \leq r} y_{p'}
		> r + z
		= \frac{2r}{2} + z .
	\end{align*}
	This is a contradiction to the choice of $(p_i, r_i)$.
\end{proof}

The primal solution is also feasible to the LP, and its cost is bounded by $6\OPT'$.

\lemPdCostA*
\begin{proof}
	Since $U_i = \emptyset$, $x$ is feasible at the end of \cref{alg:pd}. By the construction of $\bar{S}$, it follows that $\bar{x}$ is feasible. By \cref{lem:always-dual-feasible}, $y$ is always feasibile for (D). It remains to bound the cost of $\bar{S}$.
	
	By the construction of $\bar{S}$, for any $(p, r) \in \bar{S}$, $x^{(r/3)}_p = 1$ and $(p, r/3)$ is at least half-tight in $y$. In other words, $r + z \le 6 \cdot (r/(2 \cdot 3) + z) = 6 \sum_{d(p,p') \leq r/3} y_p$. Let $\bar{S}(p,r) = \{ p' \in P \mid d(p, p') \leq r \}$. For all $(p_1,r_1), (p_2,r_2) \in \bar{S}$, $p_1 \neq p_2$, we have that $\bar{S}(p_1,r_1/3)$ and $\bar{S}(p_2,r_2/3)$ are disjoint due to the construction of $\bar{S}$. Therefore, it holds that
	\begin{equation*}
		\sum_{p\in P}\sum_{r\in R}\bar{x}_{p}^{(r)}(r+z)
		= \sum_{(p,r) \in \bar{S}} (r+z)
		\leq 6\cdot\sum_{p\in P}y_{p} .
	\end{equation*}
	By weak duality, $6\cdot\sum_{p\in P}y_{p} \leq 6\OPT'$.
\end{proof}

\paragraph{Proof of \cref{lem:pd-cost-b}}

Finally, we prove that the pruned solution is a feasible $k$-sum-of-radii solution with cost bounded by $(13.008 + \epsilon)\OPT'$.

\lemPdCostB*
\begin{proof}
	First observe that the cost of $\hat{S}$ is bounded by $2\cdot 3.504 \cdot \OPT$ since we can construct a solution with cost at most $2\OPT$ that covers $\bar{C}$ using only centers from $\bar{C}$: for each point $p \in \bar{C}$, take the point $p' \in \OPT$ covering $p$ with some radius $r'$, and select $p$ with  radius $2r'$.
	
	Let $p \in P$, let $(\bar{p}, \bar{r}) \in \bar{S}$ so that $d(p, \bar{p}) \leq \bar{r}$ and let $(\hat{p}, \hat{r}) \in \hat{S}$ that was chosen to cover $\bar{p}$. By the triangle inequality, $d(p, \bar{p}) \leq \hat{r} + \bar{r}$. 
	Let $(\hat{p}, \tilde{r})$ be the corresponding tuple in $\tilde{S}$. By the construction of $\tilde{S}$, we have that $\hat{r} + \bar{r} \leq \tilde{r}$. Therefore, $\tilde{S}$ is feasible. It follows that the cost of $\tilde{S}$ is at most
	
	\begin{equation*}
		\sum_{(\hat{p},\hat{r})\in \hat{S}}\hat{r}+\sum_{p\in P}\sum_{r\in R}\bar{x}_{p}^{(r)}(r+z)
		\leq (2\cdot3.504 + 6 + \epsilon) \OPT'. \qedhere
	\end{equation*}
\end{proof}

\paragraph{Proof of \cref{thm:pd-main}}

\thmPdMain*
\begin{proof}
	Consider a fixed choice of $\OPT'$. This assumption will be removed at the end of the proof. We invoke \cref{alg:pd} on the initial point set as for the static setting. Consider an operation $t$, and let $\breve{S}, \breve{U}, \breve{x}, \breve{y}, \breve{r}, \breve{i}$ be the state before this operation.
	
	If a point $p$ is inserted, the algorithm checks, for every $j \in \{ 1, \ldots, i-1 \}$, if $d(p_j, p) \leq 2r_i$. If this is not the case for any $j$, $p$ is added to $\breve{U_j}$ and the algorithm proceeds. Otherwise, the algorithm stops. If the last check fails and $i > (2k/\epsilon)^2$, the algorithm stops, too. Otherwise, it runs $\FnPrimalDual(P, \breve{U}, R, z, k, \epsilon, x, y, i)$ with the updated $\breve{U}$. In any case, the point $p$ deposits a budget of $2k/\epsilon$ tokens for each possible $U_i$, $i \in [2k/\epsilon]$, i.e., $(2k / \epsilon)^2$ tokens in total. By \cref{lem:pd-iteration-time,lem:pd-pruning-time}, the total running time is $O((2k/\epsilon)k/\epsilon + 0 + (k/\epsilon)^4 + (2k / \epsilon)^2) = O((k/\epsilon)^4)$.
	
	If a point $p$ is deleted, the algorithm deletes $p$ from all $\breve{U_i}$ it is contained in. If for all radii $r \in R$ we have that $\breve{x}^{(r)}_p = 0$ then the algorithms stops. Otherwise, let $j$ be so that $p \in \breve{U}_j \setminus{\breve{U}}_{j+1}$, i.e., $p$ is the center of the $j$\xth/ cluster. The algorithm sets, for all $r \in R$ and all $j' \geq j$, $\breve{x}^{(r)}_{p_{j'}} = 0$, $\breve{y}_{p_{j'}} = 0$ and, for all $j' > j$, $\breve{U}_{j'} = \emptyset$. Then, it calls $\FnPrimalDual(P, \breve{U}, R, z, k, \epsilon, \breve{x}, \breve{y}, j)$. By \cref{lem:pd-iteration-time,lem:pd-pruning-time}, the total running time is $O((2k/\epsilon)^2 k/\epsilon + (2k/\epsilon)\lvert U_j \rvert + (k/\epsilon)^4)$.
	
	The correctness of the algorithm follows from the fact that if $\OPT' \geq \OPT$, the algorithm produces a feasible solution irrespective of the choice of the $p_i$, $i \in [2k / \epsilon]$, by \cref{lem:pd-cost-b} and observing that the procedure described above simulates a valid run of the algorithm for $P = P_{t-1} \cup \{ p \}$ and $P = P_t \setminus \{ p \}$, respectively. Finally, we prove that the expected time to process all deletions up to operation $t$ is bounded by $O(t \cdot 2k/\epsilon)$. The argument runs closely along the running time analysis in~\cite{ChaFul18}.
	
	Let $t' \leq t$, $j \in [2k/\epsilon]$ and let $\bar{U}^{(t')}_j$ be the set $U^{(t')}_i$ that was returned by \FnPrimalDual after the last call that took place before operation $t'$ so that the argument $i$ is such that $i \leq j$. Note that this is the last call to \FnPrimalDual before operation $t'$ when $U_j$ is reclustered. We decompose $U^{(t')}_j$ into $A^{(t')}_j = U^{(t')}_j \setminus \bar{U}^{(t')}_j$ and $B^{(t')}_j = U_j \cap \bar{U}^{(t')}_j$ and define the random variable $T^{t'}_i$, where $T^{t'}_i = \lvert B^{(t')} \rvert$ if operation $t'$ deletes center $p_i$ and $T^{t}_i = 0$ otherwise. Next, we bound $E[\sum_{t' < t} \sum_{i \in [2k / \epsilon]} T^{(t')}_i]$. For $t' <t$ and $i \in [2k / \epsilon]$, consider $E[T^{(t')}_i]$. Since $p_i$ was picked uniformly at random from $B^{(t')}$, the probability that operation $t'$ deletes $p_i$ is $1 / \lvert B^{(t')} \rvert$. Therefore, $E[T^{t'}_i] = 1$. By linearity of expectation, $E[\sum_{t' < t} \sum_{i \in [2k / \epsilon]} T^{(t')}_i] \leq 2k/\epsilon$. If operation $t'$ deletes $p_j$, $U_j$ is reclustered at operation $t'$ and any point in $A$ is not in $A^{(T^{t'}_i)}$ for any $t'' \geq t'$. Therefore, each point $p \in A$ can pay $(2k/\epsilon)$ tokens from its insertion budget if $p_j$ is deleted. The expected amortized cost for all operations up to operation $t$ is therefore at most $O((2k/\epsilon)^2 k/\epsilon + (2k/\epsilon)^2 + (k/\epsilon)^4) = O((k/\epsilon)^4)$.
	
	
	Now, we remove the assumption that $\OPT'$ is known. Recall that $d(x,y) \geq 1$ for every $x,y \in X$, and $\dmax = \max_{x,y \in \cX} d(x,y)$. For every $\Gamma \in \{ (1+\epsilon)^i \mid i \in [\lceil \log_{1+\epsilon} (k \dmax) \rceil]$, the algorithm maintains an instance of the LP with $\costbound = (1+\epsilon)^\Gamma$. After every update, the algorithm determines the smallest $\Gamma$ for which a solution is returned. Recall that the algorithm from \cite{CharikarP04} takes time $O(n^{O(1/\epsilon)})$. The total expected amortized cost is $O(k^{O(1/\epsilon)} \log \dmax)$.
\end{proof}