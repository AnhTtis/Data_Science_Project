 % ****** Start of file apssamp.tex ******
%
%   This file is part of the APS files in the REVTeX 4.1 distribution.
%   Version 4.1r of REVTeX, August 2010
%
%   Copyright (c) 2009, 2010 The American Physical Society.
%
%   See the REVTeX 4 README file for restrictions and more information.
%
% TeX'ing this file requires that you have AMS-LaTeX 2.0 installed
% as well as the rest of the prerequisites for REVTeX 4.1
%
% See the REVTeX 4 README file
% It also requires running BibTeX. The commands are as follows:
%
%  1)  latex apssamp.tex
%  2)  bibtex apssamp
%  3)  latex apssamp.tex
%  4)  latex apssamp.tex
%

\documentclass[%
reprint,
superscriptaddress,
%groupedaddress,
%unsortedaddress,
%runinaddress,t
%frontmatterverbose,
%preprint,
showpacs,preprintnumbers,
%nofootinbib,
%nobibnotes,
%bibnotes,
 amsmath,amssymb,
aps,
pre,
%pra,
%prb,
%rmp,
%prstab,
%prstper,
floatfix,
%draft
]{revtex4-1}
\usepackage{amsmath}
\usepackage{graphicx}
\DeclareMathSizes{12}{17.28}{9}{7}


% \addbibresource{refs.bib}
%\usepackage{epstopdf}
\usepackage{float}
%\usepackage{nidanfloat}
%\usepackage{dblfloatfix}
\pagestyle{plain}
%\usepackage{graphicx}% Include figure files
\usepackage{dcolumn}% Align table columns on decimal point
\usepackage{bm}% bold math
\usepackage{bbold}
\usepackage[multidot]{grffile}
\usepackage[colorlinks=true, breaklinks=true]{hyperref}% add hypertext capabilities
%\usepackage{url}
\usepackage[mathlines]{lineno}% Enable numbering of text and display math
%\linenumbers\relax % Commence numbering lines
\newcommand{\vect}[1]{\bm{\mathrm{#1}}}
\newcommand{\netj}{\mathcal{J}}
\newcommand{\netl}{\mathcal{L}}
\DeclareMathOperator{\dd}{d\!} % pour avoir un d de dérivée droit
\newcommand{\dr}{\mathrm{d}} % derivative in roman
\DeclareMathOperator{\tr}{tr}



\usepackage{xcolor}
\newcommand{\note}[1]{\textit{\textcolor{gray}{Note: #1}}}
\usepackage{xspace}
\newcommand{\ie}{\emph{i.e.}\xspace}
%\usepackage[showframe,%Uncomment any one of the following lines to test
%%scale=0.7, marginratio={1:1, 2:3}, ignoreall,% default settings
%%text={7in,10in},centering,
%%margin=1.5in,
%%total={6.5in,8.75in}, top=1.2in, left=0.9in, includefoot,
%%height=10in,a5paper,hmargin={3cm,0.8in},
%]{geometry}
%\usepackage{layouts}
\usepackage[utf8]{inputenc}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric,fit,arrows,babel}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
%\usepackage{hyperref}       % hyperlinks
\usepackage{hyperref}
\hypersetup{colorlinks,
citecolor=blue
}
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}
\usepackage{amsmath,amssymb,amsthm}
\usepackage[normalem]{ulem}
%\usepackage[pdftex,dvipsnames]{xcolor}  % Coloured text etc.
% 
\usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}
\usepackage{graphicx}
\usepackage{wrapfig}
\newcommand{\Dat}[2][inline]{\todo[#1,color=blue!40,size=\scriptsize]{Dat: #2}}

%%% COLORS %%%
\newcommand{\B}[1]{\textcolor{blue}{{#1}}} % color in blue
\newcommand{\R}[1]{\textcolor{red}{{#1}}} % color in red
\definecolor{Agreen}{rgb}{0.1, 0.6, 0.1} % define new green
\newcommand{\G}[1]{\textcolor{Agreen}{{#1}}} % color in green
%\newcommand{\Gt}[1]{\textcolor{Agreen}{{\tt [{#1}]}} % color in green
\newcommand{\red}[1]{\textcolor{red}{#1}}
\usepackage{multirow}

\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage[noend]{algpseudocode}
\SetKwInput{KwInput}{Input}                % Set the Input
\SetKwInput{KwOutput}{Output}              % set the Output
\newcommand\mycommfont[1]{\footnotesize\ttfamily\textcolor{blue}{#1}}
\SetCommentSty{mycommfont}


\newcommand{\marius}[1]{\textcolor{black}{#1}}

 % \usepackage{lineno}
 % \linenumbers

\setlength {\marginparwidth }{2cm} 
\begin{document}
%\preprint{APS/123-QED}

\title{Combined effects of STDP and homeostatic structural plasticity on coherence resonance}

\author{Marius E. Yamakou}
\email{marius.yamakou@fau.de}
\affiliation{Department of Data Science, Friedrich-Alexander-Universit\"{a}t Erlangen-N\"{u}rnberg, Cauerstr. 11, 91058 Erlangen, Germany}
\affiliation{Max-Planck-Institut f\"ur Mathematik in den Naturwissenschaften, Inselstr. 22, 04103 Leipzig, Germany}

%
\author{Christian Kuehn}
\email{ckuehn@ma.tum.de}
\affiliation{Faculty of Mathematics, Technical University of Munich, Boltzmannstrasse 3, 85748 Garching bei München, Germany}
\affiliation{Complexity Science Hub Vienna, Josefstädter Strasse 39, 1080 Vienna, Austria}

\date{\today}

\begin{abstract}
Efficient processing and transfer of information in neurons have been linked to noise-induced resonance phenomena such as coherence resonance (CR), and adaptive rules in neural networks have been mostly linked to two prevalent mechanisms: spike-timing-dependent plasticity (STDP) and homeostatic structural plasticity (HSP). Thus, this paper investigates CR in small-world and random adaptive networks of Hodgkin-Huxley neurons driven by STDP and HSP. Our numerical study indicates that the degree of CR strongly depends, and in different ways, on the adjusting rate parameter $P$, which controls STDP, on the characteristic rewiring frequency parameter $F$, which controls HSP, and on the parameters of the network topology. In particular, we found two robust behaviors: (i) Decreasing  $P$ (which enhances the weakening effect of STDP on synaptic weights) and decreasing $F$ (which slows down the swapping rate of synapses between neurons) always leads to higher degrees of CR in small-world and random networks, provided that the synaptic time delay parameter $\tau_c$ has some appropriate values. (ii) Increasing the synaptic time delay $\tau_c$ induces multiple CR (MCR) \marius{--- the occurrence of multiple peaks in the degree of
coherence as $\tau_c$ changes ---} in small-world and random networks, with MCR becoming more pronounced at smaller values of $P$ and $F$. Our results imply that STDP and HSP can jointly play an essential role in enhancing the time precision of firing necessary for optimal information processing and transfer in neural systems and could thus have applications in designing networks of noisy artificial neural circuits engineered to use CR to optimize information processing and transfer.
\end{abstract}

\maketitle

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{widetext}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    
\section{Introduction}\label{Sec. I}
Noise is an inherent part of many complex systems and has been observed to induce a wide variety of phenomena \cite{benzi1982stochastic,hou2005transfer,hanggi2002stochastic,horsthemke1984noise,mcdonnell2011benefits}. In the case of neural systems,  noise-induced resonance phenomena, such as stochastic resonance \cite{hanggi2002stochastic,longtin1993stochastic,gluckman1998stochastic,bulsara1991stochastic}, self-induced stochastic resonance (SISR) \cite{muratov2005self,yamakou2022levy,yamakou2022diversity,yamakou2017simple}, inverse stochastic resonance \cite{yamakou2017simple,gutkin2009inhibition,buchin2016inverse,yamakou2018weak} and coherence resonance (CR) \cite{pikovsky1997coherence,yamakou2022optimal,yamakou2019control,yamakou2023coherence}, have been shown to play important functional roles in information processing, including amongst others, the detection of weak input signals in neural networks \cite{vazquez2017stochastic}, and the local optimal information transfer between the input and output spike in neurons \cite{buchin2016inverse}. 

Due to the importance of these noise-induced resonance phenomena in neural information processing and transfer, the
research on their dynamics in single neurons and neural networks with different levels of complexity has been extensively investigated over the last decades. The literature on the topic is abundant, including: \marius{the effects of different types of noise \cite{sun2008spatial,yamakou2022levy,lu2020inverse},
network size and topology \cite{gao2001stochastic,guo2009stochastic,liu2014effects,gosak2010optimal,toral2003system,semenova2018weak},
various spatial distributions on resonance \cite{tuckwell2011effects},
electrical synaptic couplings \cite{uzuntarla2017inverse,yamakou2022optimal}, 
inhibitory or excitatory chemical synaptic couplings \cite{uzuntarla2017inverse}, 
hybrid of electrical and chemical synaptic couplings \cite{yilmaz2013stochastic}, 
time delay in the synaptic couplings \cite{wang2009delay,liu2014effects}, and time-varying strength of synaptic couplings \cite{yilmaz2015enhancement}.
The interplay between different noise-induced resonance phenomena has also been investigated; e.g., the interplay between CR and SISR in multiplex neural networks \cite{yamakou2022optimal,yamakou2019control} and the interplay between SR and ISR \cite{zamani2020concomitance} in a basic neural circuit.
The control of stochastic resonance in experiments \cite{gammaitoni1999controlling,gluckman1996stochastic} and the resonance induced by chaos has also been extensively studied \cite{sinha1998deterministic,zambrano2007chaos,sinha1999noise,nobukawa2019controlling}.}

However, to this day, insufficient attention has been devoted to the behavior of these noise-induced resonance phenomena in adaptive neural networks. The effects of the inherently adaptive nature of neural networks on these noise-induced phenomena and hence on neural information processing and transfer are important and cannot be overlooked, especially when a deep understanding of neural dynamics is required. Adaptation in neural networks precisely refers to the ability to change the strength of the synaptic couplings over time and/or the architecture of the neural network topology via some specific rules. Adaptive rules in neural networks have been mostly linked to two important mechanisms: (i) spike-timing-dependent plasticity (STDP) and (ii) structural plasticity (SP). 

STDP describes how the synaptic weights get modified by repeated pairings of pre-and post-synaptic membrane potentials with the sign and the degree of the modification dependent on the relative timing of the neurons firing. Depending on the precise timing of the pre-and post-synaptic action potentials, the synaptic weights can exhibit either long-term potentiation (LTP) --- persistent strengthening of synapses --- or long-term depression (LTD) --- persistent weakening of synapses \cite{gerstner1996neuronal,markram1997regulation,morrison2007spike}. 

On the other hand, SP describes the mechanisms that rewire connectivity between neurons over time by altering (creating, pruning, or swapping) synaptic connections between neurons, thereby changing the architecture of the network or the brain as a whole. The initial evidence for SP came from histological studies of spine density following new sensory experience or training~\cite{greenough1988anatomy}. Today, there is good evidence that the micro-connectome, which describes the connectome at the level of individual synapses, rewires~\cite{van2017rewiring,bennett2018rewiring}.
 Moreover, experiments suggest that the rewiring of cortical circuits contributes to the reorganization of neural firing during developmental experience-dependent plasticity in the visual cortex~\cite{ko2013emergence}, and the rewiring involves changing either the number of synapses or the location of those synapses~\cite{holtmaat2009experience}.

The question of brain networks adhering to specific architectures, including small-world and random networks, despite their time-varying dynamics was recently considered \cite{hilgetag2016brain,valencia2008dynamic}. Homeostasis is the ability of a system to maintain a relatively stable state that persists despite changes in the system's evolution. It is argued that SP must be accompanied by some homeostatic mechanisms that prevent neural networks from losing the architectures required for optimal information processing and transfer \cite{turrigiano2012homeostatic}. It has been shown that small-world and random networks can benefit from homeostasis via an increase in the efficiency of information processing \cite{butz2014homeostatic}. 
Thus, in the present study, we focus on small-world and random networks driven by homeostatic structural plasticity (HSP), i.e., time-varying small-world and random networks that adhere to their respective topology over time.

Combining STDP and other forms of homeostatic plasticity rules, such as synaptic scaling \cite{pozo2010unraveling}, has provided knowledge on how to keep neural network dynamics in a stable and biologically plausible regime \cite{watt2010homeostatic} and to support non-trivial computations underlying many optimization tasks \cite{galtier2013biological}. Motivated by these studies, we focus, in the present paper, on one noise-induced resonance phenomenon, namely, CR in adaptive neural networks driven by both STDP and HSP. 

\marius{CR occurs when the regularity of noise-induced oscillations of an excitable system without a periodic input signal is a non-monotonic function of the noise amplitude, or another system parameter \cite{pikovsky1997coherence,gosak2010optimal}. Important cases of CR occur when the system remains sufficiently close to a Hopf bifurcation 
\cite{pikovsky1997coherence,yamakou2019control}, or a saddle-node bifurcation of limit cycles \cite{jia2011coherence}.} As we pointed out earlier, most of the previous literature on CR reports that the behavior of this noise-induced phenomenon is in non-adaptive neural networks. The studies investigating CR in adaptive neural networks have considered only STDP. For example, in \cite{yu2015spike}, it is found that CR depends significantly on the features of STDP and connectivity in Newman–Watts small-world neural networks. It is also demonstrated that the network structure plays a constructive role in the degree of CR: the degree of CR reaches a peak when the number of random shortcuts is intermediate. Moreover, as the adjusting rate parameter of the STDP increases, the average coupling strength of the network is weakened. Consequently, the degree of CR largely deteriorates. The same study also shows that more connections are needed to optimize the temporal coherence-related random shortcuts with a larger adjusting rate of the STDP. 

In \cite{xie2016effect}, it is found that in a Newman–Watts small-world neural network, multiple CR induced by the time delay of the STDP can be either enhanced or suppressed as the adjusting rate of STDP changes, depending on the number of added random shortcuts is the network. 
In \cite{xie2018spike}, it is found that in a scale-free neural network with autaptic time delay, as the adjusting rate parameter of STDP increases, multiple coherence resonance enhances and becomes strongest at an intermediate value of this adjusting rate parameter, indicating that there is optimal STDP that can most strongly enhance the multiple CR induced by \marius{time delay}.

\marius{To the best of our knowledge, no previous study has considered CR in time-varying neural networks driven by STDP and HSP. Thus, the overarching scientific question of this work is to determine whether and, if so, how can STDP and HSP jointly affect the degree of CR in small-world and random neural networks. To address this main question, we investigate the following questions in small-world and random networks:
(i) How do the adjusting rate of the STDP rule and the characteristic rewiring frequency of the HSP rule jointly affect the degree of CR? (ii) How do the synaptic time delay, the rewiring frequency of the HSP rule, and the adjusting rate of the STDP rule jointly affect the degree of CR? (iii) How do the average degree of network connectivity, the rewiring frequency of the HSP rule, and the adjusting rate of the STDP rule jointly affect the degree of CR? (iv) How do the rewiring probability of the Watts-Strogatz small-world network, the rewiring frequency of the HSP rule, and the adjusting rate of the STDP rule jointly affect the degree of CR? We address these questions using extensive numerical simulations.}


The numerical results indicate that the degree of CR depends in one general way on parameters controlling STDP and HSP, and in various ways, on the interval in which network topology parameters lie. For example, it is found that decreasing the STDP and HSP parameters ($P$ and $F$, respectively) always leads to higher degrees of CR in small-world and random networks, provided that the synaptic time delay parameter $\tau_c$ is fixed to some suitable values. Moreover, increasing the synaptic time delay $\tau_c$ induces multiple CR (MCR) in small-world and random networks, with MCR becoming more pronounced as the STDP and HSP parameters decrease. On the other hand, the degree of CR is found to vary in a non-monotonic fashion when the network parameters, including the rewiring probability, average degree, and synaptic time delay, are varied. 


The rest of the paper is organized as follows: In Sec. \ref{Sec. II}, we describe the mathematical neural network model, the STDP learning rule, and the strategy of HSP that would allow the time-varying small-world and random networks to adhere to their respective architecture. In Sec. \ref{Sec. III}, we describe the computational methods used. In Sec. \ref{Sec. IV}, we present and discuss numerical results. We summarize and conclude in Sec. \ref{Sec. V}.


\section{Model description}\label{Sec. II}
\subsection{Neural Network Model}
\marius{Unlike the mathematically simpler but biophysically less relevant neuron models (e.g., the FitzHugh-Nagumo model \cite{fitzhugh1961impulses}), the more complicated Hodgkin-Huxley (HH) \cite{hodgkin1952quantitative} neuron model can provide experimentally testable hypotheses that are mature enough to guide experiments in \textit{vivo} and \textit{vitro}.}
Thus, as a paradigmatic model with well-known biophysical relevance, we study the effects of STDP and HSP in a network of HH neurons, whose membrane potential is governed by
\begin{align}\label{eq:1}
\begin{split}
\hspace{-6.0mm}\displaystyle{C_m\frac{dV_{i}}{dt}} = &- g_{_{\text{Na}}}^{max}m_{i}^3h_{i}(V_{i}-V_{_{\text{Na}}}) - g_{_{\text{K}}}^{max}n_{i}^4(V_{i}-V_{_{\text{K}}})\\ 
&- g_{_{\text{L}}}^{max}(V_{i}-V_{_{\text{L}}}) + I_{i}^{syn}(t),
\end{split}
\end{align}
where the variable $V_i$, $i=1,...,N,$ represents the membrane potential (measured in $\mathrm{mV}$) of neuron $i$, and $t$ is the time (measured in $\mathrm{ms}$).
The capacitance of the membrane of each neuron is represented by $C_m = 1 \mathrm{\mu F/cm^3}$.  The conductances $g_{_{\text{Na}}}^{max}=120$ $\mathrm{mS/cm^2}$, $g_{_{\text{K}}}^{max}=36$ $\mathrm{mS/cm^2}$,  and $g_{_{\text{L}}}^{max}=0.3$ $\mathrm{mS/cm^2}$ 
respectively denote the maximal sodium, potassium, and leakage conductance when all ion channels are open. The potentials $V_{_{\text{Na}}}= 50.0$ $\mathrm{mV}$, $V_{_{\text{K}}} = - 77.0$ $\mathrm{mV}$, and $V_{_{\text{L}}}=-54.4$ $\mathrm{mV}$ are the reversal potentials for sodium,
potassium and leak channels, respectively. 

$m_i^3h_i$ and $n_i^4$ in Eq.~\eqref{eq:1} are respectively the mean portions of the open sodium and potassium ion channels within a membrane patch, while
$x_{i}=\{m_{i},h_{i},n_{i}\}$ represent auxiliary dimensionless $[0,1]$-valued dynamical variables representing 
the sodium activation, sodium inactivation, and potassium activation, respectively. The dynamics of these gating variables $(x_i = m_i,h_i,n_i)$, depending on the voltage-dependent opening and closing rate functions $\alpha_{{x_{i}}}(V_i)$ and $\beta_{{x_{i}}}(V_i)$, are given by
%
\begin{equation}\label{eq:2}
 \displaystyle{\frac{dx_{i}}{dt}} = \alpha_{{x_{i}}}(V_{i})(1 - x_{i}) - \beta_{{x_{i}}}(V_{i})x_{i} + \displaystyle{\xi_{x_i}(t)},
\end{equation}
where the rate functions are given by
\begin{equation}\label{eq:3}
\begin{split}
\left\{\begin{array}{lcl}
\alpha_{m_i}(V_i) &=& \displaystyle{ \frac{(V_i+40)/10}{1-\exp{[-(V_i+40)/10}]},}\\ [4.0mm]
\beta_{m_i}(V_i) &=&  \displaystyle{4\exp{\big[-(V_i+65)/18\big]},}\\[4.0mm] 
\alpha_{h_i}(V_i) &=&  \displaystyle{0.07\exp{\big[-(V_i+65)/20\big]},}\\[2.0mm] 
\beta_{h_i}(V_i) &=&  \displaystyle{\frac{1}{1+\exp{[-(V_i+35)/10]}},}\\[4.0mm] 
\alpha_{n_i}(V_i) &=&  \displaystyle{\frac{(V_i+55)/100}{1-\exp{[-(V_i+55)/10}]},}\\[4.0mm]
\beta_{n_i}(V_i) &=&  \displaystyle{0.125\exp{\big[-(V_i+65)/80\big]}}.
\end{array}\right.
\end{split}
\end{equation}

$\xi_{x_i}(t)$ $(x_{i}=\{m_{i},h_{i},n_{i}\})$ in Eq.\eqref{eq:2} represent ion channel noises in the HH neurons. We will use the sub-unit noise as the ion channel noises \cite{fox1997stochastic,white2000channel} where $\xi_{x_i}(t)$ $(x_{i}=\{m_{i},h_{i},n_{i}\})$ are given by independent zero mean Gaussian white noise sources whose autocorrelation functions are given as
\begin{equation}\label{eq:4}
\begin{split}
\left\{\begin{array}{lcl}
 \langle\xi_{m_i}(t)\xi_{m_i}(t')\rangle = \displaystyle{ \frac{2\alpha_{m_i}(V_i)\beta_{m_i}(V_i)}{\rho_{Na}A_i\big[\alpha_{m_i}(V_i)+\beta_{m_i}(V_i)\big]}\delta(t-t')},\\ [5.0mm]
\langle\xi_{h_i}(t)\xi_{h_i}(t')\rangle = \displaystyle{ \frac{2\alpha_{h_i}(V_i)\beta_{h_i}(V_i)}{\rho_{Na}A_i\big[\alpha_{h_i}(V_i)+\beta_{h_i}(V_i)\big]}\delta(t-t')},\\ [5.0mm]
\langle\xi_{n_i}(t)\xi_{n_i}(t')\rangle = \displaystyle{ \frac{2\alpha_{n_i}(V_i)\beta_{n_i}(V_i)}{ \rho_KA_i\big[\alpha_{n_i}(V_i)+\beta_{n_i}(V_i)\big]}\delta(t-t')},
\end{array}\right.
\end{split}
\end{equation}
where $\rho_{Na}$ and $\rho_K$ are the sodium and potassium channel densities, respectively, and $A_i$ is the membrane patch area (\marius{measured in $\mathrm{\mu m^2}$}) of the $i$th neuron. For simplicity, we assume that all the neurons in the network have the same membrane patch area, i.e., we choose $A_1=A_2=...=A_N=A$. 


\subsection{Synapses and STDP Rule}
The term $I_{i}^{syn}(t)$ in Eq.\eqref{eq:1} models the inhibitory and uni-directional chemical synapses between the neurons and also controls the STDP learning rule between these connected neurons. The synaptic current $I_{i}^{syn}(t)$ of the $i$th neuron at time $t$ is given by
\begin{equation}\label{eq:5}
I_{i}^{syn}(t) = - \sum_{j=1(\neq i)}^{N}\ell_{ij}(t)g_{ij}(t)s_j(t)\big[V_i(t)- V_{syn}\big],
\end{equation}
where the synaptic connectivity matrix $L (=\{\ell_{ij}(t)\})$ has $\ell_{ij}(t)=1$ if the neuron $j$ is pre-synaptic to the neuron $i$; otherwise, $\ell_{ij}(t)=0$. The synaptic connection is modeled either as a time-varying small-world network or a time-varying random network.
The small-world and the random network are generated using the Watts-Strogatz algorithm \cite{watts1998collective}, where for a given average degree $\langle k \rangle$, the value of the rewiring probability $\beta\in[0,1]$ in the algorithm will determine whether we generate a small-world network (i.e., when $\beta\in(0,1)$) or a completely random network (i.e., when $\beta=1$). This study does not consider regular networks (i.e., when $\beta=0$). The control parameters of the network topology are the average degree $\langle k \rangle$ and the rewiring probability $\beta$.

The fraction of open synaptic ion channels at time $t$ of the $j$th neuron is represented by $s_j(t)$ in Eq.\eqref{eq:5} and its time-evolution is governed by \cite{yu2015spike}:
 \begin{equation}\label{eq:5a}
\frac{ds_j}{dt} = \frac{2(1 - s_j)}{1 + \displaystyle{\exp\Bigg[- \frac{V_j(t-\tau_c)}{V_{shp}}\Bigg]}}-s_j,
 \end{equation}
 where $V_j(t-\tau_c)$ is the action potential of the pre-synaptic neuron $j$ at earlier time $t-\tau_c$,  $\tau_c$ (in unit of $\mathrm{ms}$) is delayed time which will be used as a control parameter of the chemical synapses. $V_{shp}=5.0$ $\mathrm{mV}$ determines the threshold of the membrane potential above which the post-synaptic neuron $i$ is affected by the pre-synaptic neuron $j$. 
 
The weight of the synaptic connection from the pre-synaptic $j$th neuron to the post-synaptic $i$th neuron is represented by $g_{ij}(t)$ in Eq.\eqref{eq:5}.  According to the STDP mechanism, with increasing time $t$, the synaptic strength $g_{ij}$ for each synapse is updated with a nearest-spike pair-based STDP rule \cite{morrison2007spike}. The synaptic coupling strength $g_{ij}(t)$ update via the synaptic modification function $M$, which depends on the current value of the synaptic weight $g_{ij}(t)$ and which is defined as follows \cite{xie2018spike}:
 \begin{eqnarray}\label{eq:6}
%\begin{split}
\left\{\begin{array}{lcl}
 g_{ij}(t + \Delta t) = g_{ij}(t) + \Delta g_{ij},\\[3.0mm]
\Delta g_{ij}=g_{ij}(t)M(\Delta t),
  \\[3.0mm]
M(\Delta t)=
  \left\{
\begin{array}{ll}
\displaystyle{P\exp{(-\lvert\Delta t\rvert/\tau_{p})}\:\:\text{if}~\Delta t>0 }\\[1.0mm]
\displaystyle{- D\exp{(-\lvert\Delta t\rvert/\tau_{d})}\:\:\text{if}~\Delta t<0}\\[1.0mm]
0 \:\:\text{if}~\Delta t=0,
\end{array} 
\right.
\end{array}\right.
%\end{split}
\end{eqnarray}
where $\Delta t=t_i -t_j$, $t_i$ (or $t_j$) represents the spiking time of the $i$th ($j$th) neuron. The amount of synaptic modification is controlled by the adjusting potentiation and depression rate parameters of the STDP rule, represented by $P$ and $D$, respectively. \marius{The potentiation and depression temporal windows of the synaptic modification are controlled by $\tau_p$ and $\tau_d$, respectively.}

Experimental studies have demonstrated that the temporal window for synaptic weakening is approximately the same as that for synaptic strengthening \cite{bi1998synaptic,feldman2005map,song2000competitive}. Synaptic potentiation is consistently induced when the post-synaptic spike generates within a time window of $20$ $\mathrm{ms}$ after the pre-synaptic spike, and depression is induced conversely. Furthermore, STDP is usually viewed as depression-dominated. Thus, in this study, we set the temporal window parameters at $\tau_p = \tau_d$ = 20 $\mathrm{ms}$ \cite{song2000competitive} and $D/P=1.05$, and we choose $P$ as the control parameter of the STDP rule.


\subsection{Time-varying Networks and HSP Rule}
Here, we consider  the  network to have a small-world structure \cite{bassett2006small,liao2017small,bassett2006adaptive,muldoon2016small}, constructed by the Watts-Strogatz network algorithm \cite{watts1998collective}, whose Laplacian matrix is a zero row sum matrix with average degree $\langle k\rangle$ and rewiring probability $\beta\in(0,1)$. To study the effects of HSP, i.e., the effects of time-dependence of the network topology such that it adheres to a small-world topology as time advances, we implement the following strategy for the time-evolution of synapses (edges): \textit{at each integration
time step $dt$, if there is an edge between two distant neighbors, it is rewired to a nearest neighbor of one of the neurons (nodes) with probability $(1 - \beta)Fdt$. If the edge is between two nearest neighbors, then with probability $\beta Fdt$, it is replaced by a connection to a randomly chosen distant node}.  
In case of a random network (i.e., when $\beta=1$ in Watts-Strogatz network algorithm), we implement the following strategy for the time-evolution of edges: \textit{at each integration
time step $dt$, if there is an edge between node $i$ and $j$, it will be rewired such that node $i$ ($j$) connects to any another node excluding $j$ ($i$) with probability $\big(1-\frac{\langle k\rangle}{N-1}\big)Fdt$.} We notice that with these strategies, the network topology (small-world or random) is always preserved as time advances.

In the current work, the control parameter of HSP will be the characteristic rewiring frequency parameter $F$, which reflects the time-varying nature of the edges after each (integration) time step $dt$. Larger values of $F$ reflect more rapid switching of the synapses. It is important to note that in real neural networks, the synapses may change at different rates depending on factors such as the developmental stage of the network and/or environmental stimuli. Thus, in the current work, it is reasonable to investigate a large range of rewiring frequencies, $F\in[0.0,1.0]$ \marius{$\mathrm{Hz}$}. Typically, though, the rewiring frequencies are expected to be small in real neural networks \cite{rakshit2018emergence}. \marius{Thus, the numerical simulations of our HH neural network with small values of $F$ are probably the most relevant indicators of the behavior of CR in real neural networks.}


\section{Computational method}\label{Sec. III}
The flow of control in the simulations is presented in the
Appendix. The two outermost loops in the pseudo-code are
on the parameters $P$ and $F$, resulting in Fig. \ref{fig:1}. The parameter in the 
outermost loop (i.e., $P$) is replaced by other parameters to get results presented in
the rest of the figures. 

To measure the degree of regularity of the spiking activity induced by the mechanism of CR in the networks, we use the inverse coefficient of variation --- an important statistical measure based on the time intervals between spikes \cite{pikovsky1997coherence, masoliver2017coherence} and which is related to the timing precision of information processing in neural systems \cite{pei1996noise}. 

For $N=100$ neurons, we numerically integrate Eqs.\eqref{eq:1}-\eqref{eq:5a} with the STDP learning rule of Eq.\eqref{eq:6} and the HSP strategies described above using the Euler–Maruyama algorithm \cite{higham2001algorithmic} with the time step $dt = 0.005$ $\mathrm{ms}$ for a total integration time of $T=2.5\times10^{3}$ $\mathrm{ms}$.  The results shown in the next section were averaged over 20 independent realizations for each set of parameter values and random initial conditions to warrant reliable statistical accuracy with respect to the small-world and random network generations and numerical simulations. For each realization,  we choose random initial points $[V_i(0),x_i(0)]$ for the $i$th ($i = 1,...,N$) neuron with uniform probability in the range of $V_i(0)\in(-75, 40)$, $x_i(0)\in(0,1)$, $x_{i}(0)=\{m_{i}(0),h_{i}(0),n_{i}(0)\}$. As with all the quantities calculated, we have carefully excluded the transient behavior from simulations. After a \marius{sufficiently long transient time of $T_0=2.0\times10^{3}$ $\mathrm{ms}$, we start recording the neuron spiking times $t_i^{\ell}$ ($\ell\in\mathbb{N}$ counts the spiking times)}. 

To prevent unbounded growth, negative conductances (i.e., negative coupling strength), and elimination of synapses (i.e., $g_{ij}=0$), we set a range with the lower and upper  bounds: $g_{ij}\in[g_{min},g_{max}]=[0.0001,0.35]$, \marius{where $g_{max}=0.35$ $\mathrm{mS/cm^2}$ is in the range of the maximum synaptic conductances 
[0.3,0.5] $\mathrm{mS/cm^2}$ usually measured in the standard Hodgkin-Huxley neuron \cite{ren2012hopf,popovych2013self}, and the lower bound $g_{min}=0.0001$ is set to ensure not to miss any effects that occur outside of classical parameter ranges.} Moreover, the initial weight of all excitable synapses is normally distributed in the interval $[g_{min},g_{max}]$, with mean $g_0=0.185$ and standard deviation $\sigma_0=0.02$.

For $N=100$ coupled neurons, \marius{the reciprocal  of the normalized standard deviation of the mean inter-spike intervals, denoted here by $\Omega$, measures the average variability of spike trains of the network \cite{gabbiani1998principles} (i.e., a measure of the regularity of the noise-induced spiking activity), and is computed as \cite{masoliver2017coherence,gong2005optimal}:}
\begin{equation}\label{eq:9}
    \Omega =
    \frac{\overline{\langle \mathrm{\tau} \rangle}}{\sqrt{\overline{\langle \mathrm{\tau}^2 \rangle} - \overline{\langle \mathrm{\tau} \rangle^2}}},
   % \frac{\sqrt{\overline{\langle \mathrm{\tau}^2 \rangle} - \overline{\langle \mathrm{\tau} \rangle^2}}}
    %    {\overline{\langle \mathrm{\tau} \rangle}},
\end{equation}
%
where
$\overline{\langle \mathrm{\tau} \rangle} = N^{-1} \sum_{i=1}^N \langle \mathrm{\tau}_i \rangle$ and 
$\overline{\langle \mathrm{\tau}^2 \rangle} = N^{-1}\sum_{i=1}^N \langle \mathrm{\tau}_i^2 \rangle$, with
$\langle \mathrm{\tau}_i \rangle$ 
and 
$\langle \mathrm{\tau}_i^2 \rangle$ representing
the mean and mean squared \marius{inter-spike interval} (over time),  $\mathrm{\tau}_i = t_i^{\ell+1}-t_i^{\ell}>0$, of neuron $i$.
We determine the spike occurrence times $t_i^{\ell}$ from the instant $t$ when the membrane potential variable $V_i(t)$ crosses the threshold $V_{\mathrm{th}}=0.0$ \marius{$\mathrm{mV}$}. A larger (lower) value of $\Omega$ indicates a higher (lower) degree of CR, i.e., a higher (lower) average temporal coherence \marius{of the spiking neurons.}
\marius{At this point, we emphasize the fact that $\Omega$ is just a measure of the regularity of the noise-induced spiking activity and not a measure of the efficiency of the control method, which compares the relative time scale of the neuronal dynamics and the networks updates to the total number of time steps in the integration. The occurrence of coherent noise-induced spiking activity, i.e., CR, crucially depends on whether the system's parameters are fixed sufficiently near but before a bifurcation threshold. How coherent or incoherent (as measured by $\Omega$) the noise-induced spiking activity is,  depends on how close the parameters are to the bifurcation threshold. Varying one or some of these parameters (e.g., $\tau_c$, $F$) will vary the proximity of the system from the bifurcation thresholds and, consequently, a variation in the degree of coherence indicated by the variation in $\Omega$.}

\marius{Furthermore, we notice that the network size considered in this work ($N=100$) is significantly smaller than those of the real neural networks in the brain --- the order of 80 billion neurons. Thus, the results presented in this work are a test of principle. For the moment, we will only focus on whether and, if so, how STDP and HSP can jointly affect the degree of CR. Future research projects could investigate large-network-size effects on the degree of CR in the presence of both STDP and HSP.}

\marius{In Figs.~\ref{fig:0}(a)-(c), we show examples of the neural activity in a small-world ($\beta=0.25$) neural network consisting of $N=100$ neurons while also illustrating the phenomenon of CR with respect to the channel noise intensity, which is controlled by the membrane patch area $A$. We notice from Eq. \eqref{eq:4} that membrane patch area $A$ appears in the denominator. Thus, the intensity of channel noise is inversely proportional to the membrane patch area $A$ --- the larger (smaller) $A$ is, the weaker (stronger) the channel noise intensity. With smaller $A$, ions scramble for the small number of available opened channels. In comparison, with larger $A$, their movements become more deterministic, as there is now a sufficiently large number of opened channels available.} 

\marius{In  Fig. \ref{fig:0}(a), we apply a weak channel noise intensity by fixed membrane patch area at a large number, $A=400 $ $\mathrm{\mu m^2}$. The neural activity indicates incoherent spiking, with some neurons even incapable of spiking. In  Fig. \ref{fig:0}(b), we increase the membrane patch area to $A=4.0$ $\mathrm{\mu m^2}$ and the neural activity achieves resonance during which the spiking becomes very coherent with a period (average inter-spike interval) of $\overline{\tau}=15.95$ $\mathrm{ms}$. In  Fig. \ref{fig:0}(c), When we apply a strong channel noise by fixing $A=0.15$ $\mathrm{\mu m^2}$, the neural activity becomes very incoherent. In  Fig. \ref{fig:0}(d), we show an example of the neural activity in the random ($\beta=1$) neural network at peak coherence with a period (average inter-spike interval) of $\overline{\tau}=15.95$ $\mathrm{ms}$.}

\marius{As we pointed out earlier, CR occurs when the regularity of noise-induced oscillations is a non-monotonic function of the noise amplitude (in our case $A$) or another system parameter. So, throughout the rest of this paper, we fix the membrane patch area at its resonant value, i.e., $A=4.0.$ $\mathrm{\mu m^2}$, and study CR with respect to  the STDP, HSP, and the network parameters ($P$, $F$ $\tau_c$, $\langle k \rangle$, $\beta$).}

\marius{Furthermore, before presenting and discussing the results, it is important to point out already that the spiking frequency at resonance in the networks in Fig. \ref{fig:0} is given by $1/\overline{\tau}\approx0.063$ $\mathrm{Hz}$ can be lost when the system parameters change and  push the system into a stronger excitable regime  leading to incoherent oscillations like in Figs. \ref{fig:0}(a) and (c). Therefore, unlike what one would most probably expect,  the observed behaviors of the degree of CR do not emerge due to the interplay between the rewiring frequency and the spiking frequency at resonance (which may even be lost for certain parameter values). Therefore, we provide theoretical explanations for our results from the perspective of phase synchronization.} 


\begin{figure*}
\centering
\includegraphics[width=8.0cm,height=4.0cm]{fig_1a.png}\includegraphics[width=8.0cm,height=4.0cm]{fig_1b.png}\\[3.0mm]\includegraphics[width=8.0cm,height=4.0cm]{fig_1c.png}\includegraphics[width=8.0cm,height=4.0cm]{fig_1d.png}
\caption{\marius{Spatio-temporal activity of the membrane potential variable $V$ (in $\mathrm{mV}$) in (a)-(c) small-world network with $\beta=0.25$, and (d) random network with $\beta=1$. (a) $A=400 $ $\mathrm{\mu m^2}$: incoherent activity. (b) $A=4.0 $ $\mathrm{\mu m^2}$: coherent activity with period of oscillation $\overline{\tau}=15.95$ $\mathrm{ms}$. (c) $A=0.15$ $\mathrm{\mu m^2}$: incoherent activity. (d) $A=4.0 $ $\mathrm{\mu m^2}$: coherent activity with period of oscillation $\overline{\tau}=15.95$ $\mathrm{ms}$.
Other parameters: $P=0.1\times10^{-5}$, $F=1.0\times10^{-3}$ $\mathrm{Hz}$, $\tau_c=13.0$ $\mathrm{ms}$, $\langle k \rangle=5$.}}
\label{fig:0}
\end{figure*}


\section{Numerical results and discussion}\label{Sec. IV}
We recall that we aim to study the combined effect of the HSP strategy (controlled by the characteristic rewiring frequency parameter $F$) and (i) the STDP rule (controlled by the adjusting rate parameter $P$), (ii) the time delay of chemical synapses $\tau_c$, (iii) the average degree of the networks $\langle k \rangle$, (iv) the rewiring probability of the network $\beta$, on the degree of coherence of spiking in small-world and random networks. %\marius{In the Appendix, we summarize in Table \ref{tab1} our results on the variations in the degree of CR.}


\subsection{Combined effects of $F$ and $P$}
In Figs. \ref{fig:1}(a1)-(a3), we respectively depict in the $F-P$ plane the contour plots of $\Omega$ measuring the degree of CR, the average coupling strength of the network $G$, and the degree of phase synchronization $R$ for a time-varying small-world network with time delay $\tau_c=13.0$ \marius{$\mathrm{ms}$}, average degree $\langle k \rangle=5$, and rewiring probability $\beta=0.25$. To see how the average coupling strength $G\in[0.0001,0.35]$ and the degree of phase synchronization $R\in[0,1]$ of the network changes with $F$ and $P$, we will average the synaptic weights and the Kuramoto order parameter over the entire population and time:
\begin{equation}\label{eq:8}
%\begin{split}
%\left\{\begin{array}{lcl}
\small{
G = \displaystyle{\Bigg \langle\frac{1}{N^2}\sum\limits_{i=1}^{N}\sum\limits_{j=1}^{N}g_{ij}(t)\Bigg \rangle_t};\:
R=\displaystyle{\Bigg \langle\bigg|\frac{1}{N}\sum\limits_{j=1}^N\exp{[i\phi_{j}(t)]}\bigg|\Bigg \rangle_t}}
%\end{array}\right.
%\end{split}
\end{equation}
 where $\big|\cdot\big|$ represents the absolute value and $\big\langle\cdot\big\rangle_t$ the average over time in the interval $t\in[T_0,T]$. In the argument of the exponential function: $i = \sqrt{-1}$ and the quantity $\phi_{j}(t)= 2\pi \ell + 2\pi(t-t_{_{j}}^{\ell})/(t_{_{j}}^{\ell+1}-t_{_{j}}^{\ell})$ with $t\in[t_{_{j}}^{\ell},t_{_{j}}^{\ell+1})$ approximates the phase of the $j$th neuron and linearly increases over $2\pi$ from one spike to the next. The degree of phase synchronization increases as $R\in[0,1]$ increases.

As we pointed out earlier, when the effect of depression dominates that of potentiation (i.e., when $D$ is larger than $P$), the decrement of synaptic strength is stronger than its increment. Hence, the smaller the value of $P$, the larger the network's average coupling strength $G$.

In Fig. \ref{fig:1}(a1), the contour of $\Omega$ is plotted against $F$ and $P$ for a small-world network. The result indicates that for static (i.e. when the rewiring frequency is $F=0$ \marius{$\mathrm{Hz}$} and slowly varying small-world networks (i.e., when $F\in[0,0.5\times10^{-3}]$ \marius{$\mathrm{Hz}$}), $\Omega$ increases (indicating a higher degree of coherence) as $P$ decreases. For smaller values of $P (<1.0\times10^{-5})$, as the rewiring frequency increases (i.e., when $F>0.5\times10^{-3}$ \marius{$\mathrm{Hz}$}),  $\Omega$ decreases (indicating lower degree of coherence).

In Fig. \ref{fig:1}(a2), the contour of $G$ is plotted against $F$ and $P$ for the small-world network of Fig. \ref{fig:1}(a1). 
First, because $P$ is smaller than $D$ (i.e., $D/P=1.05$), the depression dominates the synaptic modifications as the 
average coupling strength $G\in[0.11,0.18]$ is always less than the network's mean initial synaptic strength $g_0=0.185$. We observe that at each value of $F$, $G$ always increases as $P$ decreases. And for each value of $P$, as $F$ increases in $[0,1]$, $G$ shows a non-monotonic behavior with a maximum value occurring at $F\approx10^{-1}$ \marius{$\mathrm{Hz}$}. 

In Fig. \ref{fig:1}(a3), the contour of $R$ is plotted against $F$ and $P$ for the small-world network of Fig. \ref{fig:1}(a1) and whose average coupling strength is depicted in Fig. \ref{fig:1}(a2). We observe that the degree of phase synchronization $R$ increases with decreasing $P$ --- an immediate consequence of the average coupling strength $G$ increasing with decreasing $P$. We observe that at each value of $F$, $R$ increases as $P$ decreases. And for each value of $P$, as $F$ increases in $[0,1]$, $R$ also shows a non-monotonic behavior with a maximum value occurring at $F\approx10^{-1}$ \marius{$\mathrm{Hz}$}, just as with $G$ in Fig. \ref{fig:1}(a2). It is worth noting that the highest degree of phase synchronization achieved is never full, i.e., the largest value of the order parameter is $R\approx0.16\neq1$. 
\marius{This is because LTD dominates (as a result of setting $D/P=1.05$) in the network, with the average synaptic weight between the neurons weakening below $g_{max}/2$.} Nevertheless, the degree of synchronization in the network is strong enough to affect the degree of CR. 

In Figs. \ref{fig:1}(b1)-(b3), we present the contours of $\Omega$, $G$, and $R$ for the random network, respectively. First, we notice that similar to a small-world network, smaller $P$ (and consequently larger $G$ and $R$) and smaller $F(<1.5\times10^{-4}$ \marius{$\mathrm{Hz}$}), the random network produces a larger $\Omega$ (i.e., higher coherence). The differences in the behavior of coherence in both types of networks are that: (i) In the random network, independently of the value of $P$ (and consequently, independently of the value of $G$), higher rewiring frequencies ($F>10^{-3}$ \marius{$\mathrm{Hz}$}) permanently deteriorate the degree of coherence, as indicated by the very low value of $\Omega\approx0.10$. On the other hand, in the small-world network, we can still have a high degree of coherence with $\Omega\ge30$, depending on the value of $P<2.5\times10^{-5}$. (ii) In the random network, a significantly slower switch of synaptic connections, i.e., when $F<1.5\times10^{-4}$ \marius{$\mathrm{Hz}$}  (compared to $F<0.5\times10^{-3}$ \marius{$\mathrm{Hz}$} in the small-world network) is optimal for the best degree of coherence occurring in the red regions of Figs. \ref{fig:1}(a1) and (b1).

Comparing Figs. \ref{fig:1}(a1)-(a3) with a small-world topology, we observe that in general, $\Omega$ increases to its highest values as $G$ increases (causing $R$ to also increase), especially at smaller values of $F<0.5\times10^{-3}$ \marius{$\mathrm{Hz}$}. For a random network in Figs. \ref{fig:1}(b1)-(b3), with even smaller values of $F<1.5\times10^{-4}$ \marius{$\mathrm{Hz}$}, a similar behavior is observed. 

The fact that the degree of coherence becomes better at larger $G$ (i.e., smaller $P$) and smaller $F$ in both small-world and random networks can be intuitively explained as follows: First, we recall that the chemical synapses are uni-directional and so information from the pre-synaptic neuron $j$ can be transferred to the post-synaptic neuron $i$, \marius{but not the other way around} (as it will have been if bi-directional electrical synapses mediated the links). Secondly, the noise in the network is local, i.e., $\xi_{x_i}(t)$ ($i=1,2,...,N$) in Eq.\eqref{eq:2} are independent Gaussian processes. The locality of these stochastic processes naturally introduces some heterogeneity in the noise-induced spiking times of the neurons in the network. Thirdly, we also note that connected neurons stay permanently connected (i.e., when $F=0$ \marius{$\mathrm{Hz}$}) or stay connected for a relatively long time (i.e., when $0<F\ll1$ \marius{$\mathrm{Hz}$}) before switching their connections to previously unconnected neurons. In both cases, the better degree of synchronization (red and orange regions in Figs. \ref{fig:1}(a3) and (b3)) induced by larger values of $G$ (orange and yellow regions in Fig. \ref{fig:1}(a2); red and orange regions in Fig. \ref{fig:1}(b2)) is maintained for a relatively long time ($0<F\ll1$ \marius{$\mathrm{Hz}$}) or permanently ($F=0$ \marius{$\mathrm{Hz}$}). 

Now, this relatively stronger degree of synchronization may occur via two scenarios: (I) the post-synaptic neurons $i$ with \textit{less coherent} spiking times synchronizing the pre-synaptic neurons $j$ with \textit{more coherent} spiking times. This would then lead to an overall  \textit{more coherent} spiking times of the entire network as indicated by the red region in Figs. \ref{fig:1}(a1) and (b1) with a higher degree of coherence $\Omega\ge50$. (II) the post-synaptic neurons $i$ with \textit{more coherent} spiking times synchronizing the pre-synaptic neurons $j$ with \textit{less coherent} spiking times. In this case, we get an overall  \textit{less coherent} spiking times of the entire network as indicated by the lower degree of coherence $\Omega\leq45$ represented by the orange, yellow, green, cyan, and blue colors in Fig. \ref{fig:1}(a1) (when $F<0.5\times10^{-3}$ \marius{$\mathrm{Hz}$}) and Fig. \ref{fig:1}(b1) (when $F<1.5\times10^{-4}$ \marius{$\mathrm{Hz}$}).

In Figs. \ref{fig:1}(a1) and (b1), we observe a deterioration of the degree of coherence (especially in the random network in Figs. \ref{fig:1}(b1)) for small $P<2.5\times10^{-5}$ and higher frequencies ($F>10^{-3}$ \marius{$\mathrm{Hz}$}), \marius{even though for} this same range of values of $P$ and $F$, the average coupling strength $G$ is relatively strong (see Figs. \ref{fig:1}(a2) and (b2)) leading to the relatively high degree synchronization (see Figs. \ref{fig:1}(a3) and (b3)) observed when the networks were static or slowly varying. \marius{This observation can be explained by the occurrence of synchronization via scenario II described above, in addition to the fact that this degree of synchronization is unstable due to rapidly switching links between the neurons.}

\marius{In Figs. \ref{fig:1}(a3) and (b3), we can observe some fluctuations, i.e., several small yellow regions in the orange region. To explain this observation, it is worth noting that the numerical difference between the values of $R$ in the yellow and orange areas is minimal. Secondly, because the synaptic weights exhibit long-term depression (i.e., weakening of synaptic strength as $P$ decreases), it becomes harder for now weakly coupled neurons to (phase) synchronize their noise-induced spiking activity. Hence, the average over the number of realizations of the simulations sometimes leads to minimally different values of the order parameter $R$ as $P$ and $F$ change.}

In the remaining subsections of this paper, we study the effects of HSP and STDP on CR by looking at the behavior of $\Omega$ with respect to $F$ at three different values of $P$ when the network control parameters, including the time delay of the connections $\tau_c$, the average degree $\langle k \rangle$, and the rewiring probability $\beta$ of the networks, are independently varied. The three values of $P$ selected are such that we have (i) a large average synaptic strength G, i.e., $P=0.1\times10^{-5}$, leading to a relatively high degree of synchronization, (ii) an intermediate average synaptic strength G, i.e., $P=3.0\times10^{-5}$, leading to an intermediate degree of synchronization, and (iii) a small average synaptic strength G, i.e., $P=12.5\times10^{-5}$, leading to a low degree of synchronization.

\begin{figure*}
\centering
\includegraphics[width=5.5cm,height=3.41cm]{fig_2_a1.png}\includegraphics[width=5.5cm,height=3.41cm]{fig_2_a2.png}\includegraphics[width=5.5cm,height=3.41cm]{fig_2_a3.png}\\[2.0mm]
\includegraphics[width=5.5cm,height=3.41cm]{fig_2_b1.png}\includegraphics[width=5.5cm,height=3.41cm]{fig_2_b2.png}\includegraphics[width=5.5cm,height=3.41cm]{fig_2_b3.png}
\caption{Inverse coefficient of variation $\Omega$ in the rewiring frequency $F$ and adjusting rate $P$ parameter space for: (a1) small-world network with $\beta=0.25$, $\langle k\rangle=5$, $\tau_c=13.0$ \marius{$\mathrm{ms}$}, and (b1) random network with $\beta=1$, $\langle k\rangle=5$, $\tau_c=13.0$ \marius{$\mathrm{ms}$}. 
The corresponding variations of the average coupling strength $G$ in the networks in (a1) and (b1) are shown in (a2) and (b2), respectively. The corresponding variation in the degree of phase synchronization $R$ in the networks in (a1) and (b1) are shown in (a3) and (b3), respectively.}
\label{fig:1}
\end{figure*}


\subsection{Combined effect of $F$, $\tau_c$, and $P$}
In Figs. \ref{fig:2}(a1)-(a3), we show the contour plots of $\Omega$ against $F$, and the time delay $\tau_c$ in a small-world network at three values of $P$. In Fig. \ref{fig:2}(a1), it is seen that the smallest value of $P=0.1\times10^{-5}$ (i.e., when the weakening effect of STDP on the synaptic weights is the least pronounced) and a small value of $F<10^{-3}$ \marius{$\mathrm{Hz}$} (i.e., when the links switch slowly or remain static), the spiking coherence of the network is optimized only at some values of the time delay, i.e., at $\tau_c=\{13, 26, 42, 58, 76\}$.

In Fig. \ref{fig:2}(a2), we increase the weakening effect of STDP on the synaptic weights by increasing the value of the adjusting rate to $P=3.0\times10^{-5}$. It is shown that as $\tau_c$ increases, $\Omega$ also intermittently increases and decreases, indicating the presence of MCR. However, the intermittent peak values of $\Omega$ have smaller (compared to Fig. \ref{fig:2}(a1)) amplitudes. Furthermore, at the intermittent values of $\tau_c$ where $\Omega$ peaks, $F$ has a less significant (compared to Fig. \ref{fig:2}(a1)) effect on $\Omega$. 

In Figs. \ref{fig:2}(b1)-(b3), we show the contour plots of $\Omega$ against $F$ and $\tau_c$ in the random network at the three values of $P$. For $F<10^{-3}$ \marius{$\mathrm{Hz}$}, the results are qualitatively the same as in the small-world network in Figs. \ref{fig:2}(a1)-(a3).  However, irrespective of the value of $\tau_c$, when $F\ge10^{-3}$ \marius{$\mathrm{Hz}$}, there is a sudden drop in the degree of CR ($\Omega<5$), leading to the complete muting of MCR. 

In Figs. \ref{fig:2}(a3) and (b3), we further increase the weakening effect of the STDP rule on the synaptic weights by increasing the value of the adjusting rate to $P=12.5\times10^{-5}$ in the small-world and random network, respectively. Irrespective of $F$ and $\tau_c$,  we observe that in both types of networks, the degree of coherence is degraded significantly to very low levels, alongside the disappearance of MCR. It has been shown in \cite{yamakou2019control} that decreasing the coupling strength in a time-delayed FHN neural network increases the excitability of the network, making it more difficult and even impossible to achieve CR. In this viewpoint, the deterioration of coherence alongside the disappearance of MCR with increasing $P$ can be explained by the fact that larger values of $P$  (leading to a weakening of the time-delayed synaptic weight) induce a stronger degree of excitability, making it difficult to achieve a reasonably high degree of CR.  

\marius{
Next, we provide a theoretical explanation for the observation where the spiking time behavior of the neurons intermittently becomes ordered and less ordered, exhibiting MCR as $\tau_c$ increases. First, we recall that if a deterministic delayed differential equation (DDE) $\dot{x}= f(x(t),x(t-\tau_c))$, where $\tau_c$ is the time delay, possesses a solution $x(t)$ with period $\overline{\tau}$, then $x(t)$ also solves $\dot{x}= f(x(t),x(t-\tau_c-n\overline{\tau}))$, for all positive integers $n\in\mathbb{N}$. We see that our stochastic system of HH delayed differential equations could satisfy this property if it behaves like a deterministic delayed differential equation (DDE). This would be possible if our stochastic delayed HH equations could admit (quasi-) periodic solutions, i.e., (quasi-) deterministic spiking times. We know that (quasi-) deterministic spiking times can be achieved via CR, a phenomenon during which the inter-spike intervals in a time series are (almost) the same, leading to a period of neural activity $\overline{\tau}$ (i.e., the averaged inter-spike interval of the time series) which should be (approximately) equal or at least of the order of the distance between the periodic horizontal CR bands in Fig. \ref{fig:2}. The distance between the first four periodic horizontal CR bands in Fig. \ref{fig:2} is approximately $15.75$ $\mathrm{ms}$, while in Fig. \ref{fig:0}(b), the period of neural activity $\overline{\tau}$ at peak coherence is $\overline{\tau}=15.95$ $\mathrm{ms}$ --- they are quite close, hence the phenomenon of MCR.
}

\marius{
Furthermore, we recall that the degree of CR always enhances (degrades) when we get closer (farther away) from the bifurcation thresholds \cite{pikovsky1997coherence,neiman1997coherence,hizanidis2008control,gu2011coherence}. The time delay in the nonlinear form of chemical synapses given in Eq.\eqref{eq:5a} has been shown to modulate the excitability of neural networks \cite{masoliver2017coherence,yamakou2019control}. 
Therefore, the observation where the peak values of $\Omega$ occurring at values $\tau_c=13$, 26, 42, 58, and 76 $\mathrm{ms}$ (corresponding to the horizontal bands of peak coherence in Fig. \ref{fig:2}) decreases $\tau_c$ increases, can be explained as follows: as the value of $\tau_c$ increases, the network gets farther away from the bifurcation thresholds (i.e., its degree of excitability is enhanced as $\tau_c$ increases --- confirmed by the simulations (not shown) where stronger noise intensities are required to induce spikes from the excitable regime when the time delay becomes larger), leading to a decrease in the degree of coherence provoked by the rarity of spikes. In this case, our stochastic delayed HH equations no longer behave like a deterministic DDE with the periodic property of the solutions stated above. Hence, the gradual and, eventually, the complete appearance of MCR as $\tau_c$ increases.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}
\centering
\includegraphics[width=5.5cm,height=3.41cm]{fig_3_a1.png}\includegraphics[width=5.5cm,height=3.41cm]{fig_3_a2.png}\includegraphics[width=5.5cm,height=3.41cm]{fig_3_a3.png}\\[2.0mm]
\includegraphics[width=5.5cm,height=3.41cm]{fig_3_b1.png}\includegraphics[width=5.5cm,height=3.41cm]{fig_3_b2.png}\includegraphics[width=5.5cm,height=3.41cm]{fig_3_b3.png}
\caption{ Inverse coefficient of variation $\Omega$ in the rewiring frequency $F$ and time delay $\tau_c$ parameter space in (a1)-(a3) a small-world network with $\beta=0.25$ and $\langle k\rangle=5$ at the indicated values of $P$; and (b1)-(b3) a random network with $\beta=1$ and $\langle k\rangle=5$ at the indicated values of the $P$.}
\label{fig:2}
\end{figure*}


\subsection{Combined effect of $F$, $\langle k \rangle$, and $P$}
In Figs. \ref{fig:3}(a1)-(a3), we show the contour plots of $\Omega$ against $F$, and the average degree $\langle k \rangle$  in a small-world network ($\beta=0.25$) at the same three previous values of $P$, with the time delay at $\tau_c=13.0$ \marius{$\mathrm{ms}$}, i.e., a value of $\tau_c$, from Fig. \ref{fig:2}, at which we have the highest degree of CR.
In each of these figures, we observe that irrespective of the value of $F$, larger values of $\langle k \rangle$ induce a higher degree of CR. \marius{This behavior can be explained by the fact that with higher values of $\langle k \rangle$, the network becomes denser, leading to more interaction between the neurons in the network. This can, in turn, facilitate synchronization in the network where less coherent neurons (having low $\Omega$ values) synchronize the spiking times of the more coherent ones (having high $\Omega$ values). This then has an overall effect of increasing the averaged $\Omega$ of the network, thus enhancing CR. }

\marius{On the other hand, as the network becomes
less dense (i.e., with smaller values of $\langle k \rangle$), all the neurons in the network can no longer so easily synchronize (in particular, of course, those which are not connected); hence, the averaged $\Omega$ of the network is calculated with low $\Omega$ values (of less coherent neurons which cannot easily synchronize due to sparsity of the network) and high $\Omega$ values (of more coherent neurons). This has the overall effect of shifting the
averaged $\Omega$ to lower values, thus deteriorating CR.} Moreover, in Figs. \ref{fig:3}(a1)-(a3), we observe that smaller values of $P$ increase the degree of CR. This is explained by the fact that smaller $P$ strengthens the synaptic weights between neurons (see Figs. \ref{fig:1}(a2) and (b2)) and hence improves their synchronization (see Figs. \ref{fig:1}(a3) and (b3)), which lead to a better degree of CR.  

In Figs. \ref{fig:3}(b1)-(b3), we show the contour plots of $\Omega$ against $F$, and the average degree $\langle k \rangle$  in the random network ($\beta=1$) at the same three previous values of $P$, with the time delay at $\tau_c=13.0$ \marius{$\mathrm{ms}$}. First, we observe that in these figures, increasing $\langle k \rangle$ increases the degree of CR for the same reasons we gave for the case of the small-world network. However, in contrast to the small-world network where only $\langle k \rangle$ significantly affects the degree of CR, both $\langle k \rangle$ and $F$ significantly affect the degree of CR in the random network. In particular, we observe that in Figs. \ref{fig:3}(b1) and (b2), for $F\in[0,10^{-3}]$ \marius{$\mathrm{Hz}$} we have a higher degree of CR as $\langle k \rangle$ increases. However, when $F>10^{-3}$ \marius{$\mathrm{Hz}$}, the high degree of CR deteriorates significantly—comparing Figs. \ref{fig:3}(b1)-(b3), we see that increasing the value of $P$ (i.e., weakening the synaptic weights and hence poorer synchronization) leads to a lower degree of CR.
\begin{figure*}
\centering
\includegraphics[width=5.5cm,height=3.41cm]{fig_4_a1.png}\includegraphics[width=5.5cm,height=3.41cm]{fig_4_a2.png}\includegraphics[width=5.5cm,height=3.41cm]{fig_4_a3.png}\\[2.0mm]
\includegraphics[width=5.5cm,height=3.41cm]{fig_4_b1.png}\includegraphics[width=5.5cm,height=3.41cm]{fig_4_b2.png}\includegraphics[width=5.5cm,height=3.41cm]{fig_4_b3.png}
\caption{ Inverse coefficient of variation $\Omega$ in the rewiring frequency $F$ and average degree $\langle k\rangle$ parameter space in (a1)-(a3) small-world network with $\beta=0.25$ and $\tau_c=13.0$ \marius{$\mathrm{ms}$} at the indicated values of $P$; and (b1)-(b3) a random network with $\beta=1$ and $\tau_c=13.0$ \marius{$\mathrm{ms}$} at the indicated values of $P$.}
\label{fig:3}
\end{figure*}


\subsection{Combined effect of $F$, $\beta$, and $P$}
\marius{All the results presented for the small-world network in Figs. \ref{fig:0}-\ref{fig:3} are obtained with a rewiring probability of $\beta=0.25$. In this subsection, for the sake of completeness, we explore the variation in the degree of CR when the small-world networks are generated with different values of the rewiring probability.}

In Figs. \ref{fig:4}(a1)-(a3), we show the contour plots of $\Omega$ against $F$, and the rewiring probability $\beta\in[0.05,1]$ (which increases with the number of random short cuts in the small-world network) at the same three previous values of $P$, a time delay of $\tau_c=13.0$ \marius{$\mathrm{ms}$}, and a relatively low average degree of $\langle k \rangle=5$. 

In Fig. \ref{fig:4}(a1), with a very low value of $P$ (which strengthens the synaptic weights of the networks), both the small-world ($\beta\in[0.2,1)$) and random ($\beta=1$) networks have a very high degree of CR if the rate at which the networks rewire is relatively low, i.e., $F\in[0,10^{-3}]$ \marius{$\mathrm{Hz}$}. We also see that if the number of random shortcuts in the small-world network is low (i.e., $\beta<0.2$), then all the values of $F$ do not significantly affect the high degree of CR. But this high degree of CR deteriorates significantly for $\beta>0.2$ and for $F>10^{-3}$ \marius{$\mathrm{Hz}$}.

In Fig. \ref{fig:4}(a2), with an intermediate value of $P$, the behavior of CR in the random network (i.e., when $\beta=1$) remains qualitatively the same when compared to Fig. \ref{fig:4}(a1). Except that the degree of CR has decreased because of the weakening of the synaptic weights induced by the larger value of $P$. However, in the small-world networks, i.e., when $\beta\in[0.05,1)$, the behavior of CR has changed qualitatively and quantitatively. In particular, we observe that for \marius{$\beta\approx0.05$}, higher rewiring frequencies $F>10^{-3}$ \marius{$\mathrm{Hz}$} are required to enhance the degree of CR. This behavior contrasts with that in Fig. \ref{fig:4}(a1), where higher $F$ gradually deteriorates the degree of CR.

In Fig. \ref{fig:4}(a3), we have a relatively large value of $P$. 
For the random network (i.e., $\beta=1$), all rewiring frequencies deteriorate the degree of CR, in contrast to Figs. \ref{fig:4}(a1) and (a2)  with low and intermediate values of $P$, where the random network will exhibit a high degree of CR at small values of $F(<10^{-3})$ and a low degree of CR at higher values of $F(>10^{-3})$. For the small-world networks (i.e., $\beta\in[0.05,1)$), all the values of $\beta$ and the $F$ deteriorate the degree of CR, except for relatively higher values $\beta\in[0.55,0.85)$ and $F(>10^{-1})$, where the intermediate degree of CR is maintained from the two previous cases with low and intermediate values of $P$.

In Figs. \ref{fig:4}(b1)-(b3), we show the contour plots of $\Omega$ against $F$, and the rewiring probability $\beta\in[0.05,1]$ (which increases with the number of random short cuts in the small-world network) at the same three previous values of $P$, a time delay of $\tau_c=13.0$ \marius{$\mathrm{ms}$}, and a higher (compared to Figs. \ref{fig:4}(a1)-(a3)) average degree of $\langle k \rangle=10$.  First, when we compare Figs. \ref{fig:4}(b1)-(b3), we see that, again, larger values of $P$ deteriorate the degree of CR. Secondly, for the random networks (i.e., when $\beta=1$), a combination of slowly varying connections (i.e., when $F<10^{-3}$ \marius{$\mathrm{Hz}$}) with low or intermediate values of $P$ enhances the degree of CR. However, at higher values of $P$, even these small rewiring frequencies ($F<10^{-3}$ \marius{$\mathrm{Hz}$}) cannot enhance the low degree of CR. For the small-world networks, i.e., when $\beta\in[0.05,1)$, the relatively higher value of the average degree $\langle k \rangle=10$ promotes more interaction in the denser network, which favors synchronization in addition to the stronger synaptic weights induced by the low and intermediate values of $P$ in Figs. \ref{fig:4}(b1) and (b2). 

In Fig. \ref{fig:4}(b3), the relatively larger value of $P$ has deteriorated the degree of CR. However, higher rewiring frequencies ($F>10^{-2}$ \marius{$\mathrm{Hz}$}) induce a more enhanced degree of CR in contrast to  Fig. \ref{fig:4}(b1), where the highest degree of CR is achieved with relatively lower rewiring frequencies.
Thus, Fig. \ref{fig:4} indicates that increasing the number of random shortcuts (which increases with $\beta\in[0.05,1)$ in a small-world network), lower rewiring frequencies $(F<10^{-1}$ \marius{$\mathrm{Hz}$}) outperform the higher ones $(F>10^{-1}$ \marius{$\mathrm{Hz}$}) when the STDP parameter is small, i.e., $P=0.1\times10^{-5}$. But when $P$ becomes larger (e.g., $P=12.5\times10^{-5}$), higher rewiring frequencies $(F>10^{-1}$ \marius{$\mathrm{Hz}$}) outperform the lower ones ($F<10^{-1}$ \marius{$\mathrm{Hz}$}) as $\beta\in[0.05,1)$ increases. 
\begin{figure*}
\centering
\includegraphics[width=5.5cm,height=3.41cm]{fig_5_a1.png}\includegraphics[width=5.5cm,height=3.41cm]{fig_5_a2.png}\includegraphics[width=5.5cm,height=3.41cm]{fig_5_a3.png}\\[2.0mm]\includegraphics[width=5.5cm,height=3.41cm]{fig_5_b1.png}
\includegraphics[width=5.5cm,height=3.41cm]{fig_5_b2.png}\includegraphics[width=5.5cm,height=3.41cm]{fig_5_b3.png}
\caption{Inverse coefficient of variation $\Omega$ in the rewiring frequency $F$ and rewiring probability $\beta$ parameter space in (a1)-(a3) small-world ($0.05\leq\beta<1$) and random ($\beta=1$) networks with $\tau_c=13.0$ \marius{$\mathrm{ms}$} and $\langle k\rangle=5$ at the indicated values of $P$; and (b1)-(b3) small-world ($0.05\leq\beta<1$) and random ($\beta=1$) with $\tau_c=13.0$ \marius{$\mathrm{ms}$} and $\langle k\rangle=10$ at the indicated values of $P$.}
\label{fig:4}
\end{figure*}


\section{Summary and conclusions}\label{Sec. V}
In summary, we have numerically investigated the phenomenon of CR in adaptive small-world and random neural networks driven by STDP and HSP. It is found that the degree of CR strongly depends on the adjusting rate parameter $P$, which controls STDP, and the characteristic rewiring frequency parameter $F$, which controls HSP. Decreasing $P$ (which increases the weakening effect of STDP on the synaptic weights) and decreasing $F$ (which slows down the swapping rate of synapses between neurons) leads to a higher degree of CR in both the small-world (depending on the value of rewiring probability $\beta$) and random networks. It is found that the synaptic time delays $\tau_c$ can induce multiple CR (MCR) in both small-world and random networks, with MCR becoming more pronounced at smaller values of both $P$ and $F$. Within the $P-F$ parameter regime in which MCR occurs, increasing the time delay reduces the peak values of the inverse coefficient of variation and, thus, the degree of CR. It is also found that irrespective of the rewiring frequency $F$, the degree of CR increases when the average degree $\langle k \rangle$ in small-world increases. However, for a given average degree and rewiring frequency, higher values of the adjusting rate parameter $P$ turn to deteriorate the degree of CR.

On the other hand, for random networks, the increase in the degree of CR with the increase in the average degree $\langle k \rangle$ depends on the rewiring frequency. With higher rewiring frequencies ($F>10^{-3}$ \marius{$\mathrm{Hz}$}), a larger average degree is required to enhance the degree of CR in the random network. Furthermore, it is also found that while large values of $F$ ($>10^{-1}$ \marius{$\mathrm{Hz}$}) can either deteriorate (when $P$ is small) or enhance (when $P$ are relatively large), the degree of CR in small-world networks (with $\beta\in[0.05,1)$ ), in random networks (when $\beta=1$) they can only deteriorate the degree of CR, regardless of the value of $P$. 

It is worth noting that the results presented in this paper may be sensitive to the choice of rewiring strategies used to maintain the small-worldness and the complete randomness of the time-varying small-world and random networks, respectively. At this point, nevertheless, our results have the implication that inherent background noise, the prevalent spike-timing-dependent plasticity, and homeostatic structural plasticity can jointly play a significant constructive role in enhancing the time precision of firing, when the right amount of time delays, average degree, and randomness are introduced in the neural systems. 

\marius{
There is strong experimental evidence that acetylcholine, monoamines, and other signaling molecules can control STDP \cite{brzosko2019neuromodulation}. Also, the control of synapses in the brain has become more accessible via drugs that affect neurotransmitters \cite{pardridge2012drug}. Thus, our results could guide the control of synapses and STDP for optimal neural information processing via CR in electrophysiological experiments. Neuromorphic engineering is an active and rapidly developing field where engineers designed bio-inspired artificial neural circuits to process information differently to perform specific computational tasks \cite{panzeri2022constraints,eberhardt1989vlsi}. Thus, our results could find applications in the design of \textit{ad hoc} artificial neural circuits engineered to use CR to optimize signal processing.}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \end{widetext}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{widetext}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{appendix}\label{algo}
\begin{algorithm}[H]
\tcc{ 
$X_i(t)$ $=\{ V_i(t),\:m_i(t),\:h_i(t),\:n_i(t)$: variables of coupled SDEs in Eqs.\eqref{eq:1} and \eqref{eq:2}\;
$t$: time\;
$T$: total integration time\;
$N$: network size\;
$M$: number of realizations\;
$F$: rewiring frequency of synapses\;
$F_{max}$: maximal rewiring frequency\;
$P$: STDP control parameter\;
$P_{min}$: min of $P$\;
$P_{max}$: max of $P$\;
$\ell_{ij}(t)$: adjacency  matrix\;
$g_{ij}(t)$: synaptic weights\; 
$g_m$: average of synaptic weights over $t$ and $N$ of the $m^{th}$ realization\;
$\beta$: rewiring probability in Watts-Strogatz algorithm\;
$t^n_i$ : $n^{th}$ spike time of the $i^{th}$ neuron\;
$\omega_m$: inverse  coefficient of variation of the $m^{th}$ realization\;
$r_m$: order parameter of the  $m^{th}$ realization\;
$\Omega$: average inverse coefficient of variation over $M$\;
$R$: average order parameter over $M$\;
$G$: average of synaptic weights over $M$\;
}	
\KwInput{$T$, $N$, $M$, $F$, $P$, $\beta$}
\KwOutput{$\Omega, G, R$}
$P \gets P_{min}$ \tcp*{Initialize the adjusting rate parameter}
\While{$ P \leq P_{max}$ }  { 
$F\leftarrow 0$ \tcp*{Initialize the rewiring frequency}
	\While{$ F \leq F_{max}$ } {
		\For{$m \in  1,2,\dots,M$}{
			Init $X_i(t)\:,\:\ell_{ij}(t)$ \tcp*{Random initial conditions of SDEs and initial SW or RND network adjacency matrix}
			\For{$t \in 0,\dots,T $}{
				Integrate network of SDEs in Eqs.\eqref{eq:1} and \eqref{eq:2}\tcp*{Using the Euler-Maruyama method}
				Record the current voltage spike times $t^{n}_i$ from $V_i(t)$\tcp*{Times $t$ at which $V_i(t)\ge V_{\mathrm{th}}=0.0$}
				\If{$\Delta t_{ij}:=t_i - t_j > 0$}  {
					$\Delta M\gets P\exp{(-\lvert\Delta t_{ij}\rvert/\tau_{p})}$ 
			\tcp*{$t_i$\:,\:$t_j$: nearest-spike times of post ($i$) \& pre ($j$) neuron} 
			}
		
				\If{$\Delta t_{ij} <0$} {
				$\Delta M \gets  -1.05 P\exp{(-\lvert\Delta t_{ij}\rvert/\tau_{d})}$ 
			}
		
			\If{$\Delta t_{ij} = 0$} {
				$\Delta M \gets  0$ 
			}
				$g_{ij}(t) \gets g_{ij}(t) + g_{ij}(t)\Delta M$\tcp*{update synaptic weights}
					$\ell_{ij}(t) \gets \widetilde{\ell_{ij}}(t) $ \tcp*{Update the adjacency matrix with  $\widetilde{\ell_{ij}}(t)$ obtained by randomly rewiring $\ell_{ij}(t)$ with 
     frequency $F$ according to the small-world ($\beta\in(0,1)$) or random ($\beta=1$) network rewiring strategy}
					}
			$\overline{\langle \mathrm{\tau} \rangle}\gets \big \langle  \big \langle t_i^{n+1} - t_i^n \big\rangle_{t}\big\rangle_{{N}}$,\:
			$\overline{\langle \mathrm{\tau}^2 \rangle} \gets \big \langle  \big \langle (t_i^{n+1} - t_i^n)^2 \big\rangle_{t}\big\rangle_{{N}}$ \tcp*{Compute mean \& mean squared ISI (on $t$ and $N$)}
	
		
			$\omega_m \gets  \displaystyle{\frac{\overline{\langle \mathrm{\tau} \rangle}}{\sqrt{\overline{\langle \mathrm{\tau}^2 \rangle} - \overline{\langle \mathrm{\tau} \rangle^2}}}}$\:,
			$g_m \gets \displaystyle{\bigg \langle N^{-2}\sum\limits_{i=1}^{N}\sum\limits_{j=1}^{N}g_{ij}(t)\bigg \rangle_t}$\;
			$r_m \gets \displaystyle{\bigg \langle\bigg|N^{-1}\sum\limits_{i=1}^N\exp{\Big[j\Big(2\pi \ell + 2\pi(t-t_{_{i}}^{n})/(t_{_{i}}^{n+1}-t_{_{i}}^{n})\Big)\Big]}\bigg|\bigg \rangle_t}$ \tcp*{where $j=\sqrt{-1}$}
			
			Add $\omega_m$ to $\omega$\;
			Add $g_m$ to $g$\;
			Add $r_m$ to $r$\;	
		}
		$\Omega \gets \omega/M$ \tcp*{Compute averages over the $M$ realizations}
		$G \gets g/M$ \tcp*{Compute averages over the $M$ realizations}
		$R \gets r/M$ \tcp*{Compute averages over the $M$ realizations}
		$ F \gets F + \Delta F$ \tcp*{Increment the HSP control parameter}
	} 
$P \gets P + \Delta P$  \tcp*{Increment the STDP control parameter}
\caption{Flow of control in the simulations}
}
\end{algorithm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{widetext}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \begin{table*}[h]
% \begin{minipage}{\textwidth}
% \caption{Summary of the combined effect of STDP, HSP, and network parameters on the degree of CR. 
% The inclined arrows \textcolor{red}{$\nearrow$} and \textcolor{blue}{$\searrow$} represent an increase and a decrease in the value of a parameter in the interval indicated, respectively. The vertical arrow \textcolor{blue}{$\downarrow$} represents a rapid decrease in the degree of CR, in contrast to gradual increase \textcolor{red}{$\nearrow$} or decrease \textcolor{blue}{$\searrow$} in the degree of CR. For example, the row with: $P\:\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$\:;\:$\langle k \rangle\:\textcolor{blue}{\searrow}$ $[2,30]$\:;\:$F\:\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$ $[0,1]$\:;\: $\Omega\:\textcolor{blue}{\searrow}$, means that increasing or decreasing $P$, decreasing $\langle k \rangle$ in $[2,30]$, and decreasing or increasing $F$ in $[0,1]$, will lead to a decrease in $\Omega$.}\label{tab1}
% \begin{center}
% \begin{tabular}{|c|c|c|c|c|}
% \hline
% \textbf{Topology}   & \textbf{STDP parameter} & \textbf{Network parameters}& \textbf{HSP parameter} & \textbf{Degree of CR}\\
% \hline
% \multirow{13}{*}{\textbf{Small-world}}   
% & $P\:\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$ &  $\tau_c=13.0$ $\mathrm{ms}$, $\langle k \rangle=5$, $\beta=0.25$ &  $F\:\textcolor{red}{\nearrow}$ $[0,1]$ &  $ \Omega\:\textcolor{blue}{\searrow}$ \\ \cline{2-5}
% & $P\:\textcolor{red}{\nearrow}$   &   $\tau_c=13.0$ $\mathrm{ms}$, $\langle k \rangle=5$, $\beta=0.25$  &  $F\:\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$ $[0,1]$  &  $ \Omega\:\textcolor{blue}{\searrow}$ \\ \cline{2-5}
% & $P\:\textcolor{blue}{\searrow}$ &    $\tau_c=13.0$ $\mathrm{ms}$, $\langle k \rangle=5$, $\beta=0.25$ & $F\:\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$ $[0,1]$  & $ \Omega\:\textcolor{red}{\nearrow}$ \\\cline{2-5}
% & $P\:\textcolor{red}{\nearrow}$        &  $\tau_c\:\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$ \{13, 26, 42, 58, 76\}  & $F\:\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$ $[0,1]$  &  $\Omega\:\textcolor{blue}{\searrow}$ \\ \cline{2-5}
% & $P\:\textcolor{blue}{\searrow}$    &  $\tau_c\:\textcolor{blue}{\searrow}$ $\{13, 26, 42, 58, 76\}$ &  $F\:\textcolor{blue}{\searrow}$ $[0,1]$ &  $\Omega\:\textcolor{red}{\nearrow}$ \\ \cline{2-5}
% & $P\:\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$         &  $\tau_c\:\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$ $[0,100]-\{13, 26, 42, 58, 76\}$   &  
% $F\:\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$ $[0,1]$  &  $\Omega\:\textcolor{blue}{\searrow}$ \\ \cline{2-5}
% & $P\:\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$ &  $\langle k \rangle\:\textcolor{blue}{\searrow}$ $[2,30]$  &  $F\:\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$ $[0,1]$   &  $\Omega\:\textcolor{blue}{\searrow}$ \\ \cline{2-5}
% & $P\:\textcolor{blue}{\searrow} $             &  $\langle k \rangle\:\textcolor{red}{\nearrow}$ $[2,30]$  & $F\:\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$ $[0,1]$  &  $\Omega\:\textcolor{red}{\nearrow}$ \\ \cline{2-5}
% & $P$ \text{is low}              &  $\beta\:\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$ $[0.05,1)$    &  $F\:\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$ $[0,10^{-3}]$  &  $\Omega\:\textcolor{red}{\nearrow}$ \\ \cline{2-5}
% & $P$ \text{is low}               &  $\beta\:\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$ $[0.05,1)$    &  $F\:\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$ $(10^{-3},1]$  &  $\Omega\:\textcolor{blue}{\searrow}$ \\ \cline{2-5}
% & $P$ \text{is medium}              &  $\beta\:\textcolor{blue}{\searrow}$ $[0.05,1)$   &  $F\:\textcolor{blue}{\searrow}$ $[0,1]$&  $\Omega\:\textcolor{blue}{\searrow}$ \\ \cline{2-5}
% & $P$ \text{is large}               &  $\beta\:\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$ $[0.05,1)$    &  $F\:\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$ $[0,10^{-1}]$  &  $\Omega\:\textcolor{blue}{\searrow}$ \\ \cline{2-5}
% & $P$ \text{is large}               &  $\beta\:\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$ $[0.5,0.95)$    &  $F\:\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$ $[10^{-1},1]$  &  $\Omega\:\textcolor{red}{\nearrow}$ \\ \cline{2-5}
                                
% \hline
% \multirow{12}{*}{\textbf{Random}}   
% & $P\:\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$  &   $\tau_c=13.0$ $\mathrm{ms}$, $\langle k \rangle=5$ &  $F\:\textcolor{red}{\nearrow}$ $[0,1]$ &  $ \Omega\:\textcolor{blue}{\downarrow}$ \\ \cline{2-5}
% & $P\:\textcolor{red}{\nearrow}$   &   $\tau_c=13.0$ $\mathrm{ms}$, $\langle k \rangle=5$  &  $F\:\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$ $[0,1]$  &  $\Omega\:\textcolor{blue}{\searrow}$  \text{or}  $\textcolor{blue}{\downarrow}$ \\ \cline{2-5}
% & $P\:\textcolor{blue}{\searrow}$ &   $\tau_c=13.0$ $\mathrm{ms}$, $\langle k \rangle=5$ & $F\:\textcolor{blue}{\searrow}$ $[0,1]$ & $ \Omega  \textcolor{red}{\nearrow}$ \\\cline{2-5}
% & $P\:\textcolor{red}{\nearrow}$        &  $\tau_c\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$ $\{13, 26, 42, 58, 76\}$   &  $F\:\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$ $[0,1]$  &  
% $\Omega\:\textcolor{blue}{\searrow}$  \text{or}  $\textcolor{blue}{\downarrow}$  \\ \cline{2-5}
% & $P\:\textcolor{blue}{\searrow}$    &  $\tau_c\:\textcolor{blue}{\searrow}$  $\{13, 26, 42, 58, 76\}$ &  $F\:\textcolor{blue}{\searrow}$ $[0,1]$ &  $\Omega\:\textcolor{red}{\nearrow}$ \\ \cline{2-5}
% & $P\:\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$         &  $\tau_c\:\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$ $[0,100]-\{13, 26, 42, 58, 76\}$    &  
% $F\:\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$ $[0,1]$  &  $\Omega \textcolor{blue}{\searrow}$  \text{or}  $\textcolor{blue}{\downarrow}$ \\ \cline{2-5}
% & $P\:\textcolor{blue}{\searrow}$    &  $\langle k \rangle\:\textcolor{blue}{\searrow}$ $[2,30]$  &  $F\:\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$  $[0,10^{-3}]$  &  $\Omega\:\textcolor{blue}{\searrow}$ \\ \cline{2-5}
% & $P$ is low or medium    &  $\langle k \rangle\: \textcolor{red}{\nearrow}$ $[2,30]$  &   $F\:\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$ $[0,10^{-3}]$  &  $\Omega\:\textcolor{red}{\nearrow}$ \\ \cline{2-5}
% & $P$ is low or medium     &  $\langle k \rangle\: \textcolor{blue}{\searrow}$  $[2,23]$  &  $F\:\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$ $(10^{-3},1]$  &  $\Omega\:\textcolor{blue}{\downarrow}$ \\ \cline{2-5}
% & $P$ is low or medium     &  $\langle k \rangle\:\textcolor{red}{\nearrow}$ $(23,30]$  &   $F\:\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$ $[10^{-3},1]$  &  $\Omega\:\textcolor{red}{\nearrow}$ \\ \cline{2-5}
% & $P$ is large   &  $\langle k \rangle\:\textcolor{blue}{\searrow}$ $[2,30]$  &   $F\:\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$ $[0,1]$  &  $\Omega\:\textcolor{blue}{\searrow}$ \\ \cline{2-5}
% & $P$ is large   &  $\langle k \rangle\:\textcolor{red}{\nearrow}$ $[2,30]$  &   $F\:\textcolor{blue}{\searrow}$\:\text{or}\:$\textcolor{red}{\nearrow}$ $[0,1]$  &  $\Omega\:\textcolor{red}{\nearrow}$ \\ \cline{2-5}
% \hline
% \end{tabular}
% \end{center}
% \end{minipage}
% \end{table*}


\begin{acknowledgments}
MEY acknowledges support from the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) -- Project No. 456989199. 
\end{acknowledgments}


%\bibliography{apssamp}% Produces the bibliography via BibTeX.
% %\bibliography{refs}{}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{widetext}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\providecommand{\noopsort}[1]{}\providecommand{\singleletter}[1]{#1}%
\begin{thebibliography}{86}%
\makeatletter
\providecommand \@ifxundefined [1]{%
 \@ifx{#1\undefined}
}%
\providecommand \@ifnum [1]{%
 \ifnum #1\expandafter \@firstoftwo
 \else \expandafter \@secondoftwo
 \fi
}%
\providecommand \@ifx [1]{%
 \ifx #1\expandafter \@firstoftwo
 \else \expandafter \@secondoftwo
 \fi
}%
\providecommand \natexlab [1]{#1}%
\providecommand \enquote  [1]{``#1''}%
\providecommand \bibnamefont  [1]{#1}%
\providecommand \bibfnamefont [1]{#1}%
\providecommand \citenamefont [1]{#1}%
\providecommand \href@noop [0]{\@secondoftwo}%
\providecommand \href [0]{\begingroup \@sanitize@url \@href}%
\providecommand \@href[1]{\@@startlink{#1}\@@href}%
\providecommand \@@href[1]{\endgroup#1\@@endlink}%
\providecommand \@sanitize@url [0]{\catcode `\\12\catcode `\$12\catcode
  `\&12\catcode `\#12\catcode `\^12\catcode `\_12\catcode `\%12\relax}%
\providecommand \@@startlink[1]{}%
\providecommand \@@endlink[0]{}%
\providecommand \url  [0]{\begingroup\@sanitize@url \@url }%
\providecommand \@url [1]{\endgroup\@href {#1}{\urlprefix }}%
\providecommand \urlprefix  [0]{URL }%
\providecommand \Eprint [0]{\href }%
\providecommand \doibase [0]{http://dx.doi.org/}%
\providecommand \selectlanguage [0]{\@gobble}%
\providecommand \bibinfo  [0]{\@secondoftwo}%
\providecommand \bibfield  [0]{\@secondoftwo}%
\providecommand \translation [1]{[#1]}%
\providecommand \BibitemOpen [0]{}%
\providecommand \bibitemStop [0]{}%
\providecommand \bibitemNoStop [0]{.\EOS\space}%
\providecommand \EOS [0]{\spacefactor3000\relax}%
\providecommand \BibitemShut  [1]{\csname bibitem#1\endcsname}%
\let\auto@bib@innerbib\@empty
%</preamble>
\bibitem [{\citenamefont {Benzi}\ \emph {et~al.}(1982)\citenamefont {Benzi},
  \citenamefont {Parisi}, \citenamefont {Sutera},\ and\ \citenamefont
  {Vulpiani}}]{benzi1982stochastic}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {R.}~\bibnamefont
  {Benzi}}, \bibinfo {author} {\bibfnamefont {G.}~\bibnamefont {Parisi}},
  \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {Sutera}}, \ and\ \bibinfo
  {author} {\bibfnamefont {A.}~\bibnamefont {Vulpiani}},\ }\href@noop {}
  {\bibfield  {journal} {\bibinfo  {journal} {Tellus}\ }\textbf {\bibinfo
  {volume} {34}},\ \bibinfo {pages} {10} (\bibinfo {year} {1982})}\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Hou}\ \emph {et~al.}(2005)\citenamefont {Hou},
  \citenamefont {Qu},\ and\ \citenamefont {Xin}}]{hou2005transfer}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {Z.}~\bibnamefont
  {Hou}}, \bibinfo {author} {\bibfnamefont {K.}~\bibnamefont {Qu}}, \ and\
  \bibinfo {author} {\bibfnamefont {H.}~\bibnamefont {Xin}},\ }\href@noop {}
  {\bibfield  {journal} {\bibinfo  {journal} {ChemPhysChem}\ }\textbf {\bibinfo
  {volume} {6}},\ \bibinfo {pages} {58} (\bibinfo {year} {2005})}\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {H{\"a}nggi}(2002)}]{hanggi2002stochastic}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {P.}~\bibnamefont
  {H{\"a}nggi}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal}
  {ChemPhysChem}\ }\textbf {\bibinfo {volume} {3}},\ \bibinfo {pages} {285}
  (\bibinfo {year} {2002})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Horsthemke}\ and\ \citenamefont
  {Lefever}(1984)}]{horsthemke1984noise}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {W.}~\bibnamefont
  {Horsthemke}}\ and\ \bibinfo {author} {\bibfnamefont {R.}~\bibnamefont
  {Lefever}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal}
  {Noise-induced transitions: theory and applications in physics, chemistry,
  and biology}\ ,\ \bibinfo {pages} {164}} (\bibinfo {year}
  {1984})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {McDonnell}\ and\ \citenamefont
  {Ward}(2011)}]{mcdonnell2011benefits}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {M.~D.}\ \bibnamefont
  {McDonnell}}\ and\ \bibinfo {author} {\bibfnamefont {L.~M.}\ \bibnamefont
  {Ward}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal} {Nature
  Reviews Neuroscience}\ }\textbf {\bibinfo {volume} {12}},\ \bibinfo {pages}
  {415} (\bibinfo {year} {2011})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Longtin}(1993)}]{longtin1993stochastic}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.}~\bibnamefont
  {Longtin}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal}
  {Journal of Statistical Physics}\ }\textbf {\bibinfo {volume} {70}},\
  \bibinfo {pages} {309} (\bibinfo {year} {1993})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Gluckman}\ \emph {et~al.}(1998)\citenamefont
  {Gluckman}, \citenamefont {So}, \citenamefont {Netoff}, \citenamefont
  {Spano},\ and\ \citenamefont {Schiff}}]{gluckman1998stochastic}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {B.~J.}\ \bibnamefont
  {Gluckman}}, \bibinfo {author} {\bibfnamefont {P.}~\bibnamefont {So}},
  \bibinfo {author} {\bibfnamefont {T.~I.}\ \bibnamefont {Netoff}}, \bibinfo
  {author} {\bibfnamefont {M.~L.}\ \bibnamefont {Spano}}, \ and\ \bibinfo
  {author} {\bibfnamefont {S.~J.}\ \bibnamefont {Schiff}},\ }\href@noop {}
  {\bibfield  {journal} {\bibinfo  {journal} {Chaos: An Interdisciplinary
  Journal of Nonlinear Science}\ }\textbf {\bibinfo {volume} {8}},\ \bibinfo
  {pages} {588} (\bibinfo {year} {1998})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Bulsara}\ \emph {et~al.}(1991)\citenamefont
  {Bulsara}, \citenamefont {Jacobs}, \citenamefont {Zhou}, \citenamefont
  {Moss},\ and\ \citenamefont {Kiss}}]{bulsara1991stochastic}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.}~\bibnamefont
  {Bulsara}}, \bibinfo {author} {\bibfnamefont {E.}~\bibnamefont {Jacobs}},
  \bibinfo {author} {\bibfnamefont {T.}~\bibnamefont {Zhou}}, \bibinfo {author}
  {\bibfnamefont {F.}~\bibnamefont {Moss}}, \ and\ \bibinfo {author}
  {\bibfnamefont {L.}~\bibnamefont {Kiss}},\ }\href@noop {} {\bibfield
  {journal} {\bibinfo  {journal} {Journal of Theoretical Biology}\ }\textbf
  {\bibinfo {volume} {152}},\ \bibinfo {pages} {531} (\bibinfo {year}
  {1991})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Muratov}\ \emph {et~al.}(2005)\citenamefont
  {Muratov}, \citenamefont {Vanden-Eijnden},\ and\ \citenamefont
  {Weinan}}]{muratov2005self}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {C.~B.}\ \bibnamefont
  {Muratov}}, \bibinfo {author} {\bibfnamefont {E.}~\bibnamefont
  {Vanden-Eijnden}}, \ and\ \bibinfo {author} {\bibfnamefont {E.}~\bibnamefont
  {Weinan}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal}
  {Physica D: Nonlinear Phenomena}\ }\textbf {\bibinfo {volume} {210}},\
  \bibinfo {pages} {227} (\bibinfo {year} {2005})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Yamakou}\ and\ \citenamefont
  {Tran}(2022)}]{yamakou2022levy}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {M.~E.}\ \bibnamefont
  {Yamakou}}\ and\ \bibinfo {author} {\bibfnamefont {T.~D.}\ \bibnamefont
  {Tran}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal}
  {Nonlinear Dynamics}\ }\textbf {\bibinfo {volume} {107}},\ \bibinfo {pages}
  {2847} (\bibinfo {year} {2022})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Yamakou}\ \emph
  {et~al.}(2022{\natexlab{a}})\citenamefont {Yamakou}, \citenamefont
  {Heinsalu}, \citenamefont {Patriarca},\ and\ \citenamefont
  {Scialla}}]{yamakou2022diversity}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {M.~E.}\ \bibnamefont
  {Yamakou}}, \bibinfo {author} {\bibfnamefont {E.}~\bibnamefont {Heinsalu}},
  \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {Patriarca}}, \ and\
  \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {Scialla}},\ }\href@noop
  {} {\bibfield  {journal} {\bibinfo  {journal} {Physical Review E}\ }\textbf
  {\bibinfo {volume} {106}},\ \bibinfo {pages} {L032401} (\bibinfo {year}
  {2022}{\natexlab{a}})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Yamakou}\ and\ \citenamefont
  {Jost}(2017)}]{yamakou2017simple}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {M.~E.}\ \bibnamefont
  {Yamakou}}\ and\ \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {Jost}},\
  }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal} {EPL (Europhysics
  Letters)}\ }\textbf {\bibinfo {volume} {120}},\ \bibinfo {pages} {18002}
  (\bibinfo {year} {2017})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Gutkin}\ \emph {et~al.}(2009)\citenamefont {Gutkin},
  \citenamefont {Jost},\ and\ \citenamefont {Tuckwell}}]{gutkin2009inhibition}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {B.~S.}\ \bibnamefont
  {Gutkin}}, \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {Jost}}, \ and\
  \bibinfo {author} {\bibfnamefont {H.~C.}\ \bibnamefont {Tuckwell}},\
  }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal}
  {Naturwissenschaften}\ }\textbf {\bibinfo {volume} {96}},\ \bibinfo {pages}
  {1091} (\bibinfo {year} {2009})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Buchin}\ \emph {et~al.}(2016)\citenamefont {Buchin},
  \citenamefont {Rieubland}, \citenamefont {H{\"a}usser}, \citenamefont
  {Gutkin},\ and\ \citenamefont {Roth}}]{buchin2016inverse}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.}~\bibnamefont
  {Buchin}}, \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {Rieubland}},
  \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {H{\"a}usser}}, \bibinfo
  {author} {\bibfnamefont {B.~S.}\ \bibnamefont {Gutkin}}, \ and\ \bibinfo
  {author} {\bibfnamefont {A.}~\bibnamefont {Roth}},\ }\href@noop {} {\bibfield
   {journal} {\bibinfo  {journal} {PLoS Computational Biology}\ }\textbf
  {\bibinfo {volume} {12}} (\bibinfo {year} {2016})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Yamakou}\ and\ \citenamefont
  {Jost}(2018)}]{yamakou2018weak}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {M.~E.}\ \bibnamefont
  {Yamakou}}\ and\ \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {Jost}},\
  }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal} {Biological
  Cybernetics}\ }\textbf {\bibinfo {volume} {112}},\ \bibinfo {pages} {445}
  (\bibinfo {year} {2018})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Pikovsky}\ and\ \citenamefont
  {Kurths}(1997)}]{pikovsky1997coherence}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.~S.}\ \bibnamefont
  {Pikovsky}}\ and\ \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont
  {Kurths}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal}
  {Physical Review Letters}\ }\textbf {\bibinfo {volume} {78}},\ \bibinfo
  {pages} {775} (\bibinfo {year} {1997})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Yamakou}\ \emph
  {et~al.}(2022{\natexlab{b}})\citenamefont {Yamakou}, \citenamefont {Tran},\
  and\ \citenamefont {Jost}}]{yamakou2022optimal}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {M.~E.}\ \bibnamefont
  {Yamakou}}, \bibinfo {author} {\bibfnamefont {T.~D.}\ \bibnamefont {Tran}}, \
  and\ \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {Jost}},\ }\href@noop
  {} {\bibfield  {journal} {\bibinfo  {journal} {Frontiers in Physics}\
  }\textbf {\bibinfo {volume} {10}},\ \bibinfo {pages} {909365} (\bibinfo
  {year} {2022}{\natexlab{b}})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Yamakou}\ and\ \citenamefont
  {Jost}(2019)}]{yamakou2019control}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {M.~E.}\ \bibnamefont
  {Yamakou}}\ and\ \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {Jost}},\
  }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal} {Physical Review
  E}\ }\textbf {\bibinfo {volume} {100}},\ \bibinfo {pages} {022313} (\bibinfo
  {year} {2019})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Yamakou}\ and\ \citenamefont
  {Inack}(2023)}]{yamakou2023coherence}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {M.~E.}\ \bibnamefont
  {Yamakou}}\ and\ \bibinfo {author} {\bibfnamefont {E.~M.}\ \bibnamefont
  {Inack}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal}
  {Nonlinear Dynamics, https://doi.org/10.1007/s11071-023-08238-8}\ ,\ \bibinfo
  {pages} {1 }} (\bibinfo {year} {2023})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {V{\'a}zquez-Rodr{\'\i}guez}\ \emph
  {et~al.}(2017)\citenamefont {V{\'a}zquez-Rodr{\'\i}guez}, \citenamefont
  {Avena-Koenigsberger}, \citenamefont {Sporns}, \citenamefont {Griffa},
  \citenamefont {Hagmann},\ and\ \citenamefont
  {Larralde}}]{vazquez2017stochastic}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {B.}~\bibnamefont
  {V{\'a}zquez-Rodr{\'\i}guez}}, \bibinfo {author} {\bibfnamefont
  {A.}~\bibnamefont {Avena-Koenigsberger}}, \bibinfo {author} {\bibfnamefont
  {O.}~\bibnamefont {Sporns}}, \bibinfo {author} {\bibfnamefont
  {A.}~\bibnamefont {Griffa}}, \bibinfo {author} {\bibfnamefont
  {P.}~\bibnamefont {Hagmann}}, \ and\ \bibinfo {author} {\bibfnamefont
  {H.}~\bibnamefont {Larralde}},\ }\href@noop {} {\bibfield  {journal}
  {\bibinfo  {journal} {Scientific Reports}\ }\textbf {\bibinfo {volume} {7}},\
  \bibinfo {pages} {1} (\bibinfo {year} {2017})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Sun}\ \emph {et~al.}(2008)\citenamefont {Sun},
  \citenamefont {Perc}, \citenamefont {Lu},\ and\ \citenamefont
  {Kurths}}]{sun2008spatial}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {X.}~\bibnamefont
  {Sun}}, \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {Perc}}, \bibinfo
  {author} {\bibfnamefont {Q.}~\bibnamefont {Lu}}, \ and\ \bibinfo {author}
  {\bibfnamefont {J.}~\bibnamefont {Kurths}},\ }\href@noop {} {\bibfield
  {journal} {\bibinfo  {journal} {Chaos: An Interdisciplinary Journal of
  Nonlinear Science}\ }\textbf {\bibinfo {volume} {18}},\ \bibinfo {pages}
  {023102} (\bibinfo {year} {2008})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Lu}\ \emph {et~al.}(2020)\citenamefont {Lu},
  \citenamefont {Jia}, \citenamefont {Ge}, \citenamefont {Xu},\ and\
  \citenamefont {Li}}]{lu2020inverse}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {L.}~\bibnamefont
  {Lu}}, \bibinfo {author} {\bibfnamefont {Y.}~\bibnamefont {Jia}}, \bibinfo
  {author} {\bibfnamefont {M.}~\bibnamefont {Ge}}, \bibinfo {author}
  {\bibfnamefont {Y.}~\bibnamefont {Xu}}, \ and\ \bibinfo {author}
  {\bibfnamefont {A.}~\bibnamefont {Li}},\ }\href@noop {} {\bibfield  {journal}
  {\bibinfo  {journal} {Nonlinear Dynamics}\ ,\ \bibinfo {pages} {1}} (\bibinfo
  {year} {2020})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Gao}\ \emph {et~al.}(2001)\citenamefont {Gao},
  \citenamefont {Hu},\ and\ \citenamefont {Hu}}]{gao2001stochastic}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {Z.}~\bibnamefont
  {Gao}}, \bibinfo {author} {\bibfnamefont {B.}~\bibnamefont {Hu}}, \ and\
  \bibinfo {author} {\bibfnamefont {G.}~\bibnamefont {Hu}},\ }\href@noop {}
  {\bibfield  {journal} {\bibinfo  {journal} {Physical Review E}\ }\textbf
  {\bibinfo {volume} {65}},\ \bibinfo {pages} {016209} (\bibinfo {year}
  {2001})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Guo}\ and\ \citenamefont
  {Li}(2009)}]{guo2009stochastic}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {D.}~\bibnamefont
  {Guo}}\ and\ \bibinfo {author} {\bibfnamefont {C.}~\bibnamefont {Li}},\
  }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal} {Physical Review
  E}\ }\textbf {\bibinfo {volume} {79}},\ \bibinfo {pages} {051921} (\bibinfo
  {year} {2009})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Liu}\ \emph {et~al.}(2014)\citenamefont {Liu},
  \citenamefont {Wang}, \citenamefont {Yu}, \citenamefont {Deng}, \citenamefont
  {Tsang}, \citenamefont {Chan},\ and\ \citenamefont {Wong}}]{liu2014effects}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {C.}~\bibnamefont
  {Liu}}, \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {Wang}}, \bibinfo
  {author} {\bibfnamefont {H.}~\bibnamefont {Yu}}, \bibinfo {author}
  {\bibfnamefont {B.}~\bibnamefont {Deng}}, \bibinfo {author} {\bibfnamefont
  {K.}~\bibnamefont {Tsang}}, \bibinfo {author} {\bibfnamefont
  {W.}~\bibnamefont {Chan}}, \ and\ \bibinfo {author} {\bibfnamefont
  {Y.}~\bibnamefont {Wong}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo
  {journal} {Communications in Nonlinear Science and Numerical Simulation}\
  }\textbf {\bibinfo {volume} {19}},\ \bibinfo {pages} {1088} (\bibinfo {year}
  {2014})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Gosak}\ \emph {et~al.}(2010)\citenamefont {Gosak},
  \citenamefont {Koro{\v{s}}ak},\ and\ \citenamefont
  {Marhl}}]{gosak2010optimal}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {M.}~\bibnamefont
  {Gosak}}, \bibinfo {author} {\bibfnamefont {D.}~\bibnamefont
  {Koro{\v{s}}ak}}, \ and\ \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont
  {Marhl}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal}
  {Physical Review E}\ }\textbf {\bibinfo {volume} {81}},\ \bibinfo {pages}
  {056104} (\bibinfo {year} {2010})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Toral}\ \emph {et~al.}(2003)\citenamefont {Toral},
  \citenamefont {Mirasso},\ and\ \citenamefont {Gunton}}]{toral2003system}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {R.}~\bibnamefont
  {Toral}}, \bibinfo {author} {\bibfnamefont {C.}~\bibnamefont {Mirasso}}, \
  and\ \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {Gunton}},\
  }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal} {EPL (Europhysics
  Letters)}\ }\textbf {\bibinfo {volume} {61}},\ \bibinfo {pages} {162}
  (\bibinfo {year} {2003})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Semenova}\ and\ \citenamefont
  {Zakharova}(2018)}]{semenova2018weak}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {N.}~\bibnamefont
  {Semenova}}\ and\ \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont
  {Zakharova}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal}
  {Chaos: An Interdisciplinary Journal of Nonlinear Science}\ }\textbf
  {\bibinfo {volume} {28}},\ \bibinfo {pages} {051104} (\bibinfo {year}
  {2018})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Tuckwell}\ and\ \citenamefont
  {Jost}(2011)}]{tuckwell2011effects}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {H.~C.}\ \bibnamefont
  {Tuckwell}}\ and\ \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont
  {Jost}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal} {Journal
  of Computational Neuroscience}\ }\textbf {\bibinfo {volume} {30}},\ \bibinfo
  {pages} {361} (\bibinfo {year} {2011})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Uzuntarla}\ \emph {et~al.}(2017)\citenamefont
  {Uzuntarla}, \citenamefont {Barreto},\ and\ \citenamefont
  {Torres}}]{uzuntarla2017inverse}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {M.}~\bibnamefont
  {Uzuntarla}}, \bibinfo {author} {\bibfnamefont {E.}~\bibnamefont {Barreto}},
  \ and\ \bibinfo {author} {\bibfnamefont {J.~J.}\ \bibnamefont {Torres}},\
  }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal} {PLoS Computational
  Biology}\ }\textbf {\bibinfo {volume} {13}},\ \bibinfo {pages} {e1005646}
  (\bibinfo {year} {2017})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Yilmaz}\ \emph {et~al.}(2013)\citenamefont {Yilmaz},
  \citenamefont {Uzuntarla}, \citenamefont {Ozer},\ and\ \citenamefont
  {Perc}}]{yilmaz2013stochastic}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {E.}~\bibnamefont
  {Yilmaz}}, \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {Uzuntarla}},
  \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {Ozer}}, \ and\ \bibinfo
  {author} {\bibfnamefont {M.}~\bibnamefont {Perc}},\ }\href@noop {} {\bibfield
   {journal} {\bibinfo  {journal} {Physica A: Statistical Mechanics and its
  Applications}\ }\textbf {\bibinfo {volume} {392}},\ \bibinfo {pages} {5735}
  (\bibinfo {year} {2013})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Wang}\ \emph {et~al.}(2009)\citenamefont {Wang},
  \citenamefont {Perc}, \citenamefont {Duan},\ and\ \citenamefont
  {Chen}}]{wang2009delay}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {Q.}~\bibnamefont
  {Wang}}, \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {Perc}}, \bibinfo
  {author} {\bibfnamefont {Z.}~\bibnamefont {Duan}}, \ and\ \bibinfo {author}
  {\bibfnamefont {G.}~\bibnamefont {Chen}},\ }\href@noop {} {\bibfield
  {journal} {\bibinfo  {journal} {Chaos: An Interdisciplinary Journal of
  Nonlinear Science}\ }\textbf {\bibinfo {volume} {19}},\ \bibinfo {pages}
  {023112} (\bibinfo {year} {2009})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Yilmaz}\ \emph {et~al.}(2015)\citenamefont {Yilmaz},
  \citenamefont {Baysal},\ and\ \citenamefont {Ozer}}]{yilmaz2015enhancement}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {E.}~\bibnamefont
  {Yilmaz}}, \bibinfo {author} {\bibfnamefont {V.}~\bibnamefont {Baysal}}, \
  and\ \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {Ozer}},\ }\href@noop
  {} {\bibfield  {journal} {\bibinfo  {journal} {Physics Letters A}\ }\textbf
  {\bibinfo {volume} {379}},\ \bibinfo {pages} {1594} (\bibinfo {year}
  {2015})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Zamani}\ \emph {et~al.}(2020)\citenamefont {Zamani},
  \citenamefont {Novikov},\ and\ \citenamefont
  {Gutkin}}]{zamani2020concomitance}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.}~\bibnamefont
  {Zamani}}, \bibinfo {author} {\bibfnamefont {N.}~\bibnamefont {Novikov}}, \
  and\ \bibinfo {author} {\bibfnamefont {B.}~\bibnamefont {Gutkin}},\
  }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal} {Communications in
  Nonlinear Science and Numerical Simulation}\ }\textbf {\bibinfo {volume}
  {82}},\ \bibinfo {pages} {105024} (\bibinfo {year} {2020})}\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Gammaitoni}\ \emph {et~al.}(1999)\citenamefont
  {Gammaitoni}, \citenamefont {L{\"o}cher}, \citenamefont {Bulsara},
  \citenamefont {H{\"a}nggi}, \citenamefont {Neff}, \citenamefont {Wiesenfeld},
  \citenamefont {Ditto},\ and\ \citenamefont
  {Inchiosa}}]{gammaitoni1999controlling}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {L.}~\bibnamefont
  {Gammaitoni}}, \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont
  {L{\"o}cher}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {Bulsara}},
  \bibinfo {author} {\bibfnamefont {P.}~\bibnamefont {H{\"a}nggi}}, \bibinfo
  {author} {\bibfnamefont {J.}~\bibnamefont {Neff}}, \bibinfo {author}
  {\bibfnamefont {K.}~\bibnamefont {Wiesenfeld}}, \bibinfo {author}
  {\bibfnamefont {W.}~\bibnamefont {Ditto}}, \ and\ \bibinfo {author}
  {\bibfnamefont {M.~E.}\ \bibnamefont {Inchiosa}},\ }\href@noop {} {\bibfield
  {journal} {\bibinfo  {journal} {Physical Review Letters}\ }\textbf {\bibinfo
  {volume} {82}},\ \bibinfo {pages} {4574} (\bibinfo {year}
  {1999})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Gluckman}\ \emph {et~al.}(1996)\citenamefont
  {Gluckman}, \citenamefont {Netoff}, \citenamefont {Neel}, \citenamefont
  {Ditto}, \citenamefont {Spano},\ and\ \citenamefont
  {Schiff}}]{gluckman1996stochastic}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {B.~J.}\ \bibnamefont
  {Gluckman}}, \bibinfo {author} {\bibfnamefont {T.~I.}\ \bibnamefont
  {Netoff}}, \bibinfo {author} {\bibfnamefont {E.~J.}\ \bibnamefont {Neel}},
  \bibinfo {author} {\bibfnamefont {W.~L.}\ \bibnamefont {Ditto}}, \bibinfo
  {author} {\bibfnamefont {M.~L.}\ \bibnamefont {Spano}}, \ and\ \bibinfo
  {author} {\bibfnamefont {S.~J.}\ \bibnamefont {Schiff}},\ }\href@noop {}
  {\bibfield  {journal} {\bibinfo  {journal} {Physical Review Letters}\
  }\textbf {\bibinfo {volume} {77}},\ \bibinfo {pages} {4098} (\bibinfo {year}
  {1996})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Sinha}\ and\ \citenamefont
  {Chakrabarti}(1998)}]{sinha1998deterministic}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {S.}~\bibnamefont
  {Sinha}}\ and\ \bibinfo {author} {\bibfnamefont {B.~K.}\ \bibnamefont
  {Chakrabarti}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal}
  {Physical Review E}\ }\textbf {\bibinfo {volume} {58}},\ \bibinfo {pages}
  {8009} (\bibinfo {year} {1998})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Zambrano}\ \emph {et~al.}(2007)\citenamefont
  {Zambrano}, \citenamefont {Casado},\ and\ \citenamefont
  {Sanju{\'a}n}}]{zambrano2007chaos}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {S.}~\bibnamefont
  {Zambrano}}, \bibinfo {author} {\bibfnamefont {J.~M.}\ \bibnamefont
  {Casado}}, \ and\ \bibinfo {author} {\bibfnamefont {M.~A.}\ \bibnamefont
  {Sanju{\'a}n}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal}
  {Physics Letters A}\ }\textbf {\bibinfo {volume} {366}},\ \bibinfo {pages}
  {428} (\bibinfo {year} {2007})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Sinha}(1999)}]{sinha1999noise}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {S.}~\bibnamefont
  {Sinha}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal} {Physica
  A: Statistical Mechanics and its Applications}\ }\textbf {\bibinfo {volume}
  {270}},\ \bibinfo {pages} {204} (\bibinfo {year} {1999})}\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Nobukawa}\ and\ \citenamefont
  {Shibata}(2019)}]{nobukawa2019controlling}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {S.}~\bibnamefont
  {Nobukawa}}\ and\ \bibinfo {author} {\bibfnamefont {N.}~\bibnamefont
  {Shibata}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal}
  {Scientific Reports}\ }\textbf {\bibinfo {volume} {9}},\ \bibinfo {pages} {1}
  (\bibinfo {year} {2019})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Gerstner}\ \emph {et~al.}(1996)\citenamefont
  {Gerstner}, \citenamefont {Kempter}, \citenamefont {Van~Hemmen},\ and\
  \citenamefont {Wagner}}]{gerstner1996neuronal}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {W.}~\bibnamefont
  {Gerstner}}, \bibinfo {author} {\bibfnamefont {R.}~\bibnamefont {Kempter}},
  \bibinfo {author} {\bibfnamefont {J.~L.}\ \bibnamefont {Van~Hemmen}}, \ and\
  \bibinfo {author} {\bibfnamefont {H.}~\bibnamefont {Wagner}},\ }\href@noop {}
  {\bibfield  {journal} {\bibinfo  {journal} {Nature}\ }\textbf {\bibinfo
  {volume} {383}},\ \bibinfo {pages} {76} (\bibinfo {year} {1996})}\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Markram}\ \emph {et~al.}(1997)\citenamefont
  {Markram}, \citenamefont {L{\"u}bke}, \citenamefont {Frotscher},\ and\
  \citenamefont {Sakmann}}]{markram1997regulation}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {H.}~\bibnamefont
  {Markram}}, \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {L{\"u}bke}},
  \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {Frotscher}}, \ and\
  \bibinfo {author} {\bibfnamefont {B.}~\bibnamefont {Sakmann}},\ }\href@noop
  {} {\bibfield  {journal} {\bibinfo  {journal} {Science}\ }\textbf {\bibinfo
  {volume} {275}},\ \bibinfo {pages} {213} (\bibinfo {year}
  {1997})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Morrison}\ \emph {et~al.}(2007)\citenamefont
  {Morrison}, \citenamefont {Aertsen},\ and\ \citenamefont
  {Diesmann}}]{morrison2007spike}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.}~\bibnamefont
  {Morrison}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {Aertsen}}, \
  and\ \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {Diesmann}},\
  }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal} {Neural
  Computation}\ }\textbf {\bibinfo {volume} {19}},\ \bibinfo {pages} {1437}
  (\bibinfo {year} {2007})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Greenough}\ and\ \citenamefont
  {Bailey}(1988)}]{greenough1988anatomy}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {W.~T.}\ \bibnamefont
  {Greenough}}\ and\ \bibinfo {author} {\bibfnamefont {C.~H.}\ \bibnamefont
  {Bailey}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal} {Trends
  in Neurosciences}\ }\textbf {\bibinfo {volume} {11}},\ \bibinfo {pages} {142}
  (\bibinfo {year} {1988})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Van~Ooyen}\ and\ \citenamefont
  {Butz-Ostendorf}(2017)}]{van2017rewiring}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.}~\bibnamefont
  {Van~Ooyen}}\ and\ \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont
  {Butz-Ostendorf}},\ }\href@noop {} {\emph {\bibinfo {title} {The rewiring
  brain: a computational approach to structural plasticity in the adult
  brain}}}\ (\bibinfo  {publisher} {Academic Press},\ \bibinfo {year}
  {2017})\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Bennett}\ \emph {et~al.}(2018)\citenamefont
  {Bennett}, \citenamefont {Kirby},\ and\ \citenamefont
  {Finnerty}}]{bennett2018rewiring}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {S.~H.}\ \bibnamefont
  {Bennett}}, \bibinfo {author} {\bibfnamefont {A.~J.}\ \bibnamefont {Kirby}},
  \ and\ \bibinfo {author} {\bibfnamefont {G.~T.}\ \bibnamefont {Finnerty}},\
  }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal} {Neuroscience \&
  Biobehavioral Reviews}\ }\textbf {\bibinfo {volume} {88}},\ \bibinfo {pages}
  {51} (\bibinfo {year} {2018})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Ko}\ \emph {et~al.}(2013)\citenamefont {Ko},
  \citenamefont {Cossell}, \citenamefont {Baragli}, \citenamefont {Antolik},
  \citenamefont {Clopath}, \citenamefont {Hofer},\ and\ \citenamefont
  {Mrsic-Flogel}}]{ko2013emergence}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {H.}~\bibnamefont
  {Ko}}, \bibinfo {author} {\bibfnamefont {L.}~\bibnamefont {Cossell}},
  \bibinfo {author} {\bibfnamefont {C.}~\bibnamefont {Baragli}}, \bibinfo
  {author} {\bibfnamefont {J.}~\bibnamefont {Antolik}}, \bibinfo {author}
  {\bibfnamefont {C.}~\bibnamefont {Clopath}}, \bibinfo {author} {\bibfnamefont
  {S.~B.}\ \bibnamefont {Hofer}}, \ and\ \bibinfo {author} {\bibfnamefont
  {T.~D.}\ \bibnamefont {Mrsic-Flogel}},\ }\href@noop {} {\bibfield  {journal}
  {\bibinfo  {journal} {Nature}\ }\textbf {\bibinfo {volume} {496}},\ \bibinfo
  {pages} {96} (\bibinfo {year} {2013})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Holtmaat}\ and\ \citenamefont
  {Svoboda}(2009)}]{holtmaat2009experience}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.}~\bibnamefont
  {Holtmaat}}\ and\ \bibinfo {author} {\bibfnamefont {K.}~\bibnamefont
  {Svoboda}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal}
  {Nature Reviews Neuroscience}\ }\textbf {\bibinfo {volume} {10}},\ \bibinfo
  {pages} {647} (\bibinfo {year} {2009})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Hilgetag}\ and\ \citenamefont
  {Goulas}(2016)}]{hilgetag2016brain}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {C.~C.}\ \bibnamefont
  {Hilgetag}}\ and\ \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont
  {Goulas}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal} {Brain
  Structure and Function}\ }\textbf {\bibinfo {volume} {221}},\ \bibinfo
  {pages} {2361} (\bibinfo {year} {2016})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Valencia}\ \emph {et~al.}(2008)\citenamefont
  {Valencia}, \citenamefont {Martinerie}, \citenamefont {Dupont},\ and\
  \citenamefont {Chavez}}]{valencia2008dynamic}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {M.}~\bibnamefont
  {Valencia}}, \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont
  {Martinerie}}, \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {Dupont}},
  \ and\ \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {Chavez}},\
  }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal} {Physical Review
  E}\ }\textbf {\bibinfo {volume} {77}},\ \bibinfo {pages} {050905} (\bibinfo
  {year} {2008})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Turrigiano}(2012)}]{turrigiano2012homeostatic}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {G.}~\bibnamefont
  {Turrigiano}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal}
  {Cold Spring Harbor Perspectives in Biology}\ }\textbf {\bibinfo {volume}
  {4}},\ \bibinfo {pages} {a005736} (\bibinfo {year} {2012})}\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Butz}\ \emph {et~al.}(2014)\citenamefont {Butz},
  \citenamefont {Steenbuck},\ and\ \citenamefont 
{vanOoyen}}]{butz2014homeostatic}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {M.}~\bibnamefont
  {Butz}}, \bibinfo {author} {\bibfnamefont {I.~D.}\ \bibnamefont {Steenbuck}},
  \ and\ \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {van Ooyen}},\
  }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal} {Frontiers in
  Synaptic Neuroscience}\ }\textbf {\bibinfo {volume} {6}},\ \bibinfo {pages}
  {7} (\bibinfo {year} {2014})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Pozo}\ and\ \citenamefont
  {Goda}(2010)}]{pozo2010unraveling}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {K.}~\bibnamefont
  {Pozo}}\ and\ \bibinfo {author} {\bibfnamefont {Y.}~\bibnamefont {Goda}},\
  }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal} {Neuron}\ }\textbf
  {\bibinfo {volume} {66}},\ \bibinfo {pages} {337} (\bibinfo {year}
  {2010})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Watt}\ and\ \citenamefont
  {Desai}(2010)}]{watt2010homeostatic}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.~J.}\ \bibnamefont
  {Watt}}\ and\ \bibinfo {author} {\bibfnamefont {N.~S.}\ \bibnamefont
  {Desai}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal}
  {Frontiers in Synaptic Neuroscience}\ ,\ \bibinfo {pages} {5}} (\bibinfo
  {year} {2010})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Galtier}\ and\ \citenamefont
  {Wainrib}(2013)}]{galtier2013biological}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {M.~N.}\ \bibnamefont
  {Galtier}}\ and\ \bibinfo {author} {\bibfnamefont {G.}~\bibnamefont
  {Wainrib}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal}
  {Neural Computation}\ }\textbf {\bibinfo {volume} {25}},\ \bibinfo {pages}
  {2815} (\bibinfo {year} {2013})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Jia}\ \emph {et~al.}(2011)\citenamefont {Jia},
  \citenamefont {Gu},\ and\ \citenamefont {Li}}]{jia2011coherence}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {B.}~\bibnamefont
  {Jia}}, \bibinfo {author} {\bibfnamefont {H.-G.}\ \bibnamefont {Gu}}, \ and\
  \bibinfo {author} {\bibfnamefont {Y.-Y.}\ \bibnamefont {Li}},\ }\href@noop {}
  {\bibfield  {journal} {\bibinfo  {journal} {Chinese Physics Letters}\
  }\textbf {\bibinfo {volume} {28}},\ \bibinfo {pages} {090507} (\bibinfo
  {year} {2011})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Yu}\ \emph {et~al.}(2015)\citenamefont {Yu},
  \citenamefont {Guo}, \citenamefont {Wang}, \citenamefont {Deng},\ and\
  \citenamefont {Wei}}]{yu2015spike}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {H.}~\bibnamefont
  {Yu}}, \bibinfo {author} {\bibfnamefont {X.}~\bibnamefont {Guo}}, \bibinfo
  {author} {\bibfnamefont {J.}~\bibnamefont {Wang}}, \bibinfo {author}
  {\bibfnamefont {B.}~\bibnamefont {Deng}}, \ and\ \bibinfo {author}
  {\bibfnamefont {X.}~\bibnamefont {Wei}},\ }\href@noop {} {\bibfield
  {journal} {\bibinfo  {journal} {Physica A: Statistical Mechanics and its
  Applications}\ }\textbf {\bibinfo {volume} {419}},\ \bibinfo {pages} {307}
  (\bibinfo {year} {2015})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Xie}\ \emph {et~al.}(2016)\citenamefont {Xie},
  \citenamefont {Gong},\ and\ \citenamefont {Wang}}]{xie2016effect}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {H.}~\bibnamefont
  {Xie}}, \bibinfo {author} {\bibfnamefont {Y.}~\bibnamefont {Gong}}, \ and\
  \bibinfo {author} {\bibfnamefont {Q.}~\bibnamefont {Wang}},\ }\href@noop {}
  {\bibfield  {journal} {\bibinfo  {journal} {The European Physical Journal B}\
  }\textbf {\bibinfo {volume} {89}},\ \bibinfo {pages} {1} (\bibinfo {year}
  {2016})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Xie}\ \emph {et~al.}(2018)\citenamefont {Xie},
  \citenamefont {Gong},\ and\ \citenamefont {Wang}}]{xie2018spike}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {H.}~\bibnamefont
  {Xie}}, \bibinfo {author} {\bibfnamefont {Y.}~\bibnamefont {Gong}}, \ and\
  \bibinfo {author} {\bibfnamefont {B.}~\bibnamefont {Wang}},\ }\href@noop {}
  {\bibfield  {journal} {\bibinfo  {journal} {Chaos, Solitons \& Fractals}\
  }\textbf {\bibinfo {volume} {108}},\ \bibinfo {pages} {1} (\bibinfo {year}
  {2018})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {FitzHugh}(1961)}]{fitzhugh1961impulses}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {R.}~\bibnamefont
  {FitzHugh}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal}
  {Biophysical Journal}\ }\textbf {\bibinfo {volume} {1}},\ \bibinfo {pages}
  {445} (\bibinfo {year} {1961})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Hodgkin}\ and\ \citenamefont
  {Huxley}(1952)}]{hodgkin1952quantitative}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.~L.}\ \bibnamefont
  {Hodgkin}}\ and\ \bibinfo {author} {\bibfnamefont {A.~F.}\ \bibnamefont
  {Huxley}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal} {The
  Journal of Physiology}\ }\textbf {\bibinfo {volume} {117}},\ \bibinfo {pages}
  {500} (\bibinfo {year} {1952})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Fox}(1997)}]{fox1997stochastic}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {R.~F.}\ \bibnamefont
  {Fox}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal}
  {Biophysical Journal}\ }\textbf {\bibinfo {volume} {72}},\ \bibinfo {pages}
  {2068} (\bibinfo {year} {1997})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {White}\ \emph {et~al.}(2000)\citenamefont {White},
  \citenamefont {Rubinstein},\ and\ \citenamefont {Kay}}]{white2000channel}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {J.~A.}\ \bibnamefont
  {White}}, \bibinfo {author} {\bibfnamefont {J.~T.}\ \bibnamefont
  {Rubinstein}}, \ and\ \bibinfo {author} {\bibfnamefont {A.~R.}\ \bibnamefont
  {Kay}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal} {Trends in
  Neurosciences}\ }\textbf {\bibinfo {volume} {23}},\ \bibinfo {pages} {131}
  (\bibinfo {year} {2000})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Watts}\ and\ \citenamefont
  {Strogatz}(1998)}]{watts1998collective}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {D.~J.}\ \bibnamefont
  {Watts}}\ and\ \bibinfo {author} {\bibfnamefont {S.~H.}\ \bibnamefont
  {Strogatz}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal}
  {nature}\ }\textbf {\bibinfo {volume} {393}},\ \bibinfo {pages} {440}
  (\bibinfo {year} {1998})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Bi}\ and\ \citenamefont
  {Poo}(1998)}]{bi1998synaptic}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {G.-q.}\ \bibnamefont
  {Bi}}\ and\ \bibinfo {author} {\bibfnamefont {M.-m.}\ \bibnamefont {Poo}},\
  }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal} {Journal of
  Neuroscience}\ }\textbf {\bibinfo {volume} {18}},\ \bibinfo {pages} {10464}
  (\bibinfo {year} {1998})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Feldman}\ and\ \citenamefont
  {Brecht}(2005)}]{feldman2005map}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {D.~E.}\ \bibnamefont
  {Feldman}}\ and\ \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont
  {Brecht}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal}
  {Science}\ }\textbf {\bibinfo {volume} {310}},\ \bibinfo {pages} {810}
  (\bibinfo {year} {2005})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Song}\ \emph {et~al.}(2000)\citenamefont {Song},
  \citenamefont {Miller},\ and\ \citenamefont {Abbott}}]{song2000competitive}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {S.}~\bibnamefont
  {Song}}, \bibinfo {author} {\bibfnamefont {K.~D.}\ \bibnamefont {Miller}}, \
  and\ \bibinfo {author} {\bibfnamefont {L.~F.}\ \bibnamefont {Abbott}},\
  }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal} {Nature
  Neuroscience}\ }\textbf {\bibinfo {volume} {3}},\ \bibinfo {pages} {919}
  (\bibinfo {year} {2000})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Bassett}\ and\ \citenamefont
  {Bullmore}(2006)}]{bassett2006small}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {D.~S.}\ \bibnamefont
  {Bassett}}\ and\ \bibinfo {author} {\bibfnamefont {E.}~\bibnamefont
  {Bullmore}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal} {The
  Neuroscientist}\ }\textbf {\bibinfo {volume} {12}},\ \bibinfo {pages} {512}
  (\bibinfo {year} {2006})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Liao}\ \emph {et~al.}(2017)\citenamefont {Liao},
  \citenamefont {Vasilakos},\ and\ \citenamefont {He}}]{liao2017small}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {X.}~\bibnamefont
  {Liao}}, \bibinfo {author} {\bibfnamefont {A.~V.}\ \bibnamefont {Vasilakos}},
  \ and\ \bibinfo {author} {\bibfnamefont {Y.}~\bibnamefont {He}},\ }\href@noop
  {} {\bibfield  {journal} {\bibinfo  {journal} {Neuroscience \& Biobehavioral
  Reviews}\ }\textbf {\bibinfo {volume} {77}},\ \bibinfo {pages} {286}
  (\bibinfo {year} {2017})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Bassett}\ \emph {et~al.}(2006)\citenamefont
  {Bassett}, \citenamefont {Meyer-Lindenberg}, \citenamefont {Achard},
  \citenamefont {Duke},\ and\ \citenamefont {Bullmore}}]{bassett2006adaptive}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {D.~S.}\ \bibnamefont
  {Bassett}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont
  {Meyer-Lindenberg}}, \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont
  {Achard}}, \bibinfo {author} {\bibfnamefont {T.}~\bibnamefont {Duke}}, \ and\
  \bibinfo {author} {\bibfnamefont {E.}~\bibnamefont {Bullmore}},\ }\href@noop
  {} {\bibfield  {journal} {\bibinfo  {journal} {Proceedings of the National
  Academy of Sciences}\ }\textbf {\bibinfo {volume} {103}},\ \bibinfo {pages}
  {19518} (\bibinfo {year} {2006})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Muldoon}\ \emph {et~al.}(2016)\citenamefont
  {Muldoon}, \citenamefont {Bridgeford},\ and\ \citenamefont
  {Bassett}}]{muldoon2016small}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {S.~F.}\ \bibnamefont
  {Muldoon}}, \bibinfo {author} {\bibfnamefont {E.~W.}\ \bibnamefont
  {Bridgeford}}, \ and\ \bibinfo {author} {\bibfnamefont {D.~S.}\ \bibnamefont
  {Bassett}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal}
  {Scientific Reports}\ }\textbf {\bibinfo {volume} {6}},\ \bibinfo {pages} {1}
  (\bibinfo {year} {2016})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Rakshit}\ \emph {et~al.}(2018)\citenamefont
  {Rakshit}, \citenamefont {Bera}, \citenamefont {Ghosh},\ and\ \citenamefont
  {Sinha}}]{rakshit2018emergence}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {S.}~\bibnamefont
  {Rakshit}}, \bibinfo {author} {\bibfnamefont {B.~K.}\ \bibnamefont {Bera}},
  \bibinfo {author} {\bibfnamefont {D.}~\bibnamefont {Ghosh}}, \ and\ \bibinfo
  {author} {\bibfnamefont {S.}~\bibnamefont {Sinha}},\ }\href@noop {}
  {\bibfield  {journal} {\bibinfo  {journal} {Physical Review E}\ }\textbf
  {\bibinfo {volume} {97}},\ \bibinfo {pages} {052304} (\bibinfo {year}
  {2018})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Masoliver}\ \emph {et~al.}(2017)\citenamefont
  {Masoliver}, \citenamefont {Malik}, \citenamefont {Sch{\"o}ll},\ and\
  \citenamefont {Zakharova}}]{masoliver2017coherence}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {M.}~\bibnamefont
  {Masoliver}}, \bibinfo {author} {\bibfnamefont {N.}~\bibnamefont {Malik}},
  \bibinfo {author} {\bibfnamefont {E.}~\bibnamefont {Sch{\"o}ll}}, \ and\
  \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {Zakharova}},\ }\href@noop
  {} {\bibfield  {journal} {\bibinfo  {journal} {Chaos: An Interdisciplinary
  Journal of Nonlinear Science}\ }\textbf {\bibinfo {volume} {27}},\ \bibinfo
  {pages} {101102} (\bibinfo {year} {2017})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Pei}\ \emph {et~al.}(1996)\citenamefont {Pei},
  \citenamefont {Wilkens},\ and\ \citenamefont {Moss}}]{pei1996noise}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {X.}~\bibnamefont
  {Pei}}, \bibinfo {author} {\bibfnamefont {L.}~\bibnamefont {Wilkens}}, \ and\
  \bibinfo {author} {\bibfnamefont {F.}~\bibnamefont {Moss}},\ }\href@noop {}
  {\bibfield  {journal} {\bibinfo  {journal} {Physical Review Letters}\
  }\textbf {\bibinfo {volume} {77}},\ \bibinfo {pages} {4679} (\bibinfo {year}
  {1996})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Higham}(2001)}]{higham2001algorithmic}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {D.~J.}\ \bibnamefont
  {Higham}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal} {SIAM
  Review}\ }\textbf {\bibinfo {volume} {43}},\ \bibinfo {pages} {525} (\bibinfo
  {year} {2001})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Ren}\ \emph {et~al.}(2012)\citenamefont {Ren},
  \citenamefont {Kolwankar}, \citenamefont {Samal},\ and\ \citenamefont
  {Jost}}]{ren2012hopf}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {Q.}~\bibnamefont
  {Ren}}, \bibinfo {author} {\bibfnamefont {K.~M.}\ \bibnamefont {Kolwankar}},
  \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {Samal}}, \ and\ \bibinfo
  {author} {\bibfnamefont {J.}~\bibnamefont {Jost}},\ }\href@noop {} {\bibfield
   {journal} {\bibinfo  {journal} {Physical Review E}\ }\textbf {\bibinfo
  {volume} {86}},\ \bibinfo {pages} {056103} (\bibinfo {year}
  {2012})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Popovych}\ \emph {et~al.}(2013)\citenamefont
  {Popovych}, \citenamefont {Yanchuk},\ and\ \citenamefont
  {Tass}}]{popovych2013self}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {O.~V.}\ \bibnamefont
  {Popovych}}, \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {Yanchuk}}, \
  and\ \bibinfo {author} {\bibfnamefont {P.~A.}\ \bibnamefont {Tass}},\
  }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal} {Scientific
  Reports}\ }\textbf {\bibinfo {volume} {3}},\ \bibinfo {pages} {1} (\bibinfo
  {year} {2013})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Gabbiani}\ and\ \citenamefont
  {Koch}(1998)}]{gabbiani1998principles}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {F.}~\bibnamefont
  {Gabbiani}}\ and\ \bibinfo {author} {\bibfnamefont {C.}~\bibnamefont
  {Koch}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal} {Methods
  in neuronal modeling}\ }\textbf {\bibinfo {volume} {12}},\ \bibinfo {pages}
  {313} (\bibinfo {year} {1998})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Gong}\ \emph {et~al.}(2005)\citenamefont {Gong},
  \citenamefont {Wang}, \citenamefont {Hou},\ and\ \citenamefont
  {Xin}}]{gong2005optimal}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {Y.}~\bibnamefont
  {Gong}}, \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {Wang}}, \bibinfo
  {author} {\bibfnamefont {Z.}~\bibnamefont {Hou}}, \ and\ \bibinfo {author}
  {\bibfnamefont {H.}~\bibnamefont {Xin}},\ }\href@noop {} {\bibfield
  {journal} {\bibinfo  {journal} {ChemPhysChem}\ }\textbf {\bibinfo {volume}
  {6}},\ \bibinfo {pages} {1042} (\bibinfo {year} {2005})}\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Neiman}\ \emph {et~al.}(1997)\citenamefont {Neiman},
  \citenamefont {Saparin},\ and\ \citenamefont {Stone}}]{neiman1997coherence}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.}~\bibnamefont
  {Neiman}}, \bibinfo {author} {\bibfnamefont {P.~I.}\ \bibnamefont {Saparin}},
  \ and\ \bibinfo {author} {\bibfnamefont {L.}~\bibnamefont {Stone}},\
  }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal} {Physical Review
  E}\ }\textbf {\bibinfo {volume} {56}},\ \bibinfo {pages} {270} (\bibinfo
  {year} {1997})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Hizanidis}\ and\ \citenamefont
  {Sch{\"o}ll}(2008)}]{hizanidis2008control}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {J.}~\bibnamefont
  {Hizanidis}}\ and\ \bibinfo {author} {\bibfnamefont {E.}~\bibnamefont
  {Sch{\"o}ll}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal}
  {Physical Review E}\ }\textbf {\bibinfo {volume} {78}},\ \bibinfo {pages}
  {066205} (\bibinfo {year} {2008})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Gu}\ \emph {et~al.}(2011)\citenamefont {Gu},
  \citenamefont {Zhang}, \citenamefont {Wei}, \citenamefont {Yang},
  \citenamefont {Liu},\ and\ \citenamefont {Ren}}]{gu2011coherence}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {H.}~\bibnamefont
  {Gu}}, \bibinfo {author} {\bibfnamefont {H.}~\bibnamefont {Zhang}}, \bibinfo
  {author} {\bibfnamefont {C.}~\bibnamefont {Wei}}, \bibinfo {author}
  {\bibfnamefont {M.}~\bibnamefont {Yang}}, \bibinfo {author} {\bibfnamefont
  {Z.}~\bibnamefont {Liu}}, \ and\ \bibinfo {author} {\bibfnamefont
  {W.}~\bibnamefont {Ren}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo
  {journal} {International Journal of Modern Physics B}\ }\textbf {\bibinfo
  {volume} {25}},\ \bibinfo {pages} {3977} (\bibinfo {year}
  {2011})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Brzosko}\ \emph {et~al.}(2019)\citenamefont
  {Brzosko}, \citenamefont {Mierau},\ and\ \citenamefont
  {Paulsen}}]{brzosko2019neuromodulation}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {Z.}~\bibnamefont
  {Brzosko}}, \bibinfo {author} {\bibfnamefont {S.~B.}\ \bibnamefont {Mierau}},
  \ and\ \bibinfo {author} {\bibfnamefont {O.}~\bibnamefont {Paulsen}},\
  }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal} {Neuron}\ }\textbf
  {\bibinfo {volume} {103}},\ \bibinfo {pages} {563} (\bibinfo {year}
  {2019})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Pardridge}(2012)}]{pardridge2012drug}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {W.~M.}\ \bibnamefont
  {Pardridge}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal}
  {Journal of cerebral blood flow \& metabolism}\ }\textbf {\bibinfo {volume}
  {32}},\ \bibinfo {pages} {1959} (\bibinfo {year} {2012})}\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Panzeri}\ \emph {et~al.}(2022)\citenamefont
  {Panzeri}, \citenamefont {Janotte}, \citenamefont {Peque{\~n}o-Zurro},
  \citenamefont {Bonato},\ and\ \citenamefont
  {Bartolozzi}}]{panzeri2022constraints}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {S.}~\bibnamefont
  {Panzeri}}, \bibinfo {author} {\bibfnamefont {E.}~\bibnamefont {Janotte}},
  \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {Peque{\~n}o-Zurro}},
  \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {Bonato}}, \ and\ \bibinfo
  {author} {\bibfnamefont {C.}~\bibnamefont {Bartolozzi}},\ }\href@noop {}
  {\bibfield  {journal} {\bibinfo  {journal} {Neuromorphic Computing and
  Engineering}\ }\textbf {\bibinfo {volume} {3}},\ \bibinfo {pages} {012001}
  (\bibinfo {year} {2022})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Eberhardt}\ \emph {et~al.}(1989)\citenamefont
  {Eberhardt}, \citenamefont {Duong},\ and\ \citenamefont
  {Thakoor}}]{eberhardt1989vlsi}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {S.~P.}\ \bibnamefont
  {Eberhardt}}, \bibinfo {author} {\bibfnamefont {T.}~\bibnamefont {Duong}}, \
  and\ \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {Thakoor}},\ }in\
  \href@noop {} {\emph {\bibinfo {booktitle} {Proceedings Third Annual Parallel
  Processing Symposium}}},\ Vol.~\bibinfo {volume} {1}\ (\bibinfo {year}
  {1989})\ pp.\ \bibinfo {pages} {257--267}\BibitemShut {NoStop}%
\end{thebibliography}%

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \end{widetext}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}