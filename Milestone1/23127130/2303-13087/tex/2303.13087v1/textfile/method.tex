\begin{figure*}
	\vspace{-8mm}
	\begin{minipage}[t]{0.32\textwidth}
		\centering
		\includegraphics[width=\linewidth]{Flatness_0.png}
	\end{minipage}
	\begin{minipage}[t]{0.32\textwidth}
		\centering
		\includegraphics[width=\linewidth]{Flatness_1.png}
	\end{minipage}
	\begin{minipage}[t]{0.32\textwidth}
		\centering
		\includegraphics[width=\linewidth]{Flatness_2.png}
	\end{minipage}\\
	\begin{minipage}[t]{0.32\textwidth}
		\centering
		\includegraphics[width=\linewidth]{Flatness_3.png}
	\end{minipage}
	\begin{minipage}[t]{0.32\textwidth}
		\centering
		\includegraphics[width=\linewidth]{Flatness_4.png}
	\end{minipage}
	\begin{minipage}[t]{0.32\textwidth}
		\centering
		\includegraphics[width=\linewidth]{Flatness_5.png}
	\end{minipage}
	\vspace{-4mm}
	\caption{\small Sharpness during networking training on clean ($s=0$) and corrupted distributions ($s=1$ to $5$).}
	\vspace{-5mm}
	\label{fig:sharpness}
\end{figure*}



\section{Methodology}
\label{sec:method}
%\begin{wrapfigure}{r}{6.5cm}
%	\vspace{-5mm}
%	\includegraphics[width=\linewidth]{flatness_simple.pdf}
%	\vspace{-4mm}
%	\caption{\small Flatness during networking training on clean (left) and corrupted (right) distributions with $s=5$.}
%	\vspace{-5mm}
%	\label{fig:flatness}
%\end{wrapfigure}

In robust generalization problems, we are given a training set $\mathcal{D}^{\text{train}}$ containing $n$ image examples, each example $x\in\mathcal{X}$ is given a class label $y\in\mathcal{Y}=\left\{1, 2, ..., c\right\}$. Moreover, the training set is corrupted by a certain type of noise whose severity $s$ follows a Poisson distribution $P(s; \lambda)$. Here we assume $\lambda=1$ which indicates that the mean number of the noise photon $u$ that occurred during a time interval is $1$. Therefore, the distribution $P$ of the whole training set is composed of $S$ sub-distributions $P_s, s\in\left\{1, 2, ..., S\right\}$ with varied levels of corruption. Our goal is to learn a robust model $\theta \in \Theta$ that can achieve good generalization performance on challenging data distributions $P_s$ with large severity.

The general objective of SharpDRO is formulated as:
\vspace{-1mm}
\begin{equation}
	\begin{aligned}
		\min_{\theta} \left\{\mathcal{L}_{\text{SharpDRO}}:= \mathbb{E}_{(x, y)\sim Q}\left[\mathcal{L}(\theta; (x, y))\right] +\right.\\
		\left. \mathbb{E}_{(x, y)\sim Q}\left[\mathcal{R}(\theta; (x, y))\right]\right\},
	\end{aligned}
	\label{eq:SharpDRO}
	\vspace{-1mm}
\end{equation}
where the first term denotes the risk minimization using loss function $\mathcal{L}$, meanwhile a worst-case distribution $Q$ is selected based on the model prediction. The second term $\mathcal{R}$ indicates the sharpness minimization which aims to maximally improve the generalization performance on the worst-case distribution $Q$. Specifically, as shown in Figure~\ref{fig:sharpness}, the sharpness gradually increases as the corruption severity enlarges. Therefore, to accomplish robust generalization, we are motivated to emphasize the worst-case distribution. As a result, we can produce much smaller sharpness compared to other methods, especially on severely corrupted distributions.


In the following, we first introduce worst-case sharpness for robust generalization. Then, we demonstrate worst-case data selection on two scenarios. Finally, we provide a detailed optimization process and convergence analysis.

\subsection{Sharpness for Robust Generalization}

The main challenge of robust generalization is that the training distribution is extremely imbalanced, as shown in Figure~\ref{fig:poisson}. The performance on the abundant clean data is quite satisfactory, but robustness regarding the corrupted distribution is highly limited, owing to the severe disturbance of corruption as well as the insufficiency of noisy data. To enhance the generalization performance, we leverage sharpness to fully exploit the worst-case data. Specifically, sharpness~\cite{foret2020sharpness, kim2022fisher, liu2022towards,wu2020adversarial,zheng2021regularizing} is measured by \textbf{the largest loss change} when model weight $\theta$ is perturbed with $\epsilon$, formally:
\vspace{-0.5mm}
\begin{equation}
    \small
	\mathcal{R}:=\max_{\|\epsilon\|_2\le\rho}\{\mathcal{L}(\theta+\epsilon; (x, y)) - \mathcal{L}(\theta; (x, y))\},
	\label{eq:sharpness}
\vspace{-0.5mm}
\end{equation}
where $\rho$ is a scale parameter to control the perturbation magnitude. By supposing $\epsilon$ is small enough, we can have:
\vspace{-0.5mm}
\begin{equation}
\small
	\mathcal{L}(\theta+\epsilon) - \mathcal{L}(\theta)\approx\nabla\mathcal{L}(\theta)\epsilon.
\vspace{-0.5mm}
\end{equation}
Further, we hope to obtain the largest loss change to find the optimal weight perturbation $\epsilon^*$, which is be computed as:
\vspace{-0.5mm}
\begin{equation}
\small
	\epsilon^*:=\argmax_{\|\epsilon\|_2\le\rho}{\nabla\mathcal{L}(\theta)\epsilon}.
\vspace{-0.5mm}
\end{equation}
By following dual norm problem, the optimal $\epsilon^*$ can be solved as $\rho\sign(\nabla\mathcal{L}(\theta))$~\cite{foret2020sharpness}, which is essentially the $\infty$-norm of the gradient $\nabla\mathcal{L}$ multiplied with a scale parameter $\rho$. Hence, common sharpness minimization aims to minimize:
\begin{equation}
\small
	\mathbb{E}_{(x, y)\sim Q}\mathcal{R}:=\mathcal{L}(\theta+\rho\sign(\nabla\mathcal{L}(\theta; (x, y)))) - \mathcal{L}(\theta; (x, y)).
	\label{eq:sharpness_minimization}
\end{equation}
The intuition is that the perturbation along the gradient norm direction increases the loss value significantly. When training on corrupted distributions, the scarce noisy data scatter sparsely in the high-dimensional space. As a consequence, the neighbor of each datum could not be sufficiently explored, thus producing a sharp loss curve. During test, the unseen noisy data is likely to fall on an unexplored point with a large loss, further causing inaccurate model predictions.

Therefore, instead of directly applying sharpness minimization on the whole dataset, which leads to poor generalization performance~\cite{cha2021swad} (as demonstrated in Section~\ref{sec:ablation_study}), we focus on sharpness minimization over the worst-case distribution $Q$. By conducting the worst-case sharpness minimization, we can enhance the flatness of our classifier. Consequently, when predicting unknown data during the test phase, a flat loss landscape is more likely to produce a low loss than a sharp one, hence our SharpDRO can generalize better than other DRO methods. However, the robust performance largely depends on the worst-case distribution $Q$, so next, we explain our worst-case data selection.



\subsection{Worst-Case Data Selection}
Generally, the worst-case data selection focuses on finding the most uncertain data distribution $Q$ from the uncertainty set $\mathcal{Q}$, which is a $f$-divergence ball from the training distribution $P$~\cite{ben2013robust, duchi2018learning, hu2018does}. Most works assume each distribution is distinguishable from the other. However, when the distribution index is not available, it would be very hard to select worst-case data. In this section, we investigate two situations: distribution-aware robust generalization and distribution-agnostic robust generalization.



\subsubsection{Distribution-Aware Robust Generalization}
When given annotations to denote different severity of corruptions, the image data $x$ is paired with class label $y$ and distribution index $s$. Then, the worst-case distribution $Q$ can be found by identifying the sub-distribution $P_s\in P$ that yields the largest loss. Hence, we can optimize through:
%\begin{equation}
%	\begin{aligned}
%		\min_{\theta} \Big\{\mathcal{L}_{\text{SharpDRO}}:=\max_{\omega_s;\atop Q = \{\omega_s P_s\}_{s=1}^S} \big\{\sum_{(x_i, y_i)\in Q}\left[\mathcal{L}(\theta; (x_i, y_i))\right]\big\} + \right. \\ \left. \sum_{(x_i, y_i)\in Q}\left[\mathcal{R}(\theta; (x_i, y_i))\right]\Big\},
%	\end{aligned}
%	\label{eq:distribution_aware}
%\end{equation}
\vspace{-1mm}
\begin{align}
\small
	\min_{\theta} & \Big\{\max_{\omega_s; \atop Q = \{\omega_s P_s\}_{s=1}^S} \big\{\sum_{(x_i, y_i)\in Q}\left[\mathcal{L}(\theta,\omega_s; (x_i, y_i))\right]\big\}  \label{eq:distribution_aware}\\
	&\qquad + \sum_{(x_i, y_i)\in Q}\left[\mathcal{R}(\theta,\omega_s; (x_i, y_i))\right]\Big\}, \nonumber
\vspace{-3mm}
\end{align}
where $\omega_s$ belongs to a $(S-1)$-dimensional probability simplex. The first term simply recovers the learning target of GroupDRO~\cite{sagawa2019distributionally,hu2018does} and helps find the worst-case distribution $Q$. Then, by emphasizing the selected $P_s$, the second sharpness minimization term can act as a sharpness regularizer. As a result, SharpDRO can learn a flatter loss surface on the worst-case data, thus generalize better compared to GroupDRO, as discussed in Section~\ref{sec:experiments}.


\subsubsection{Distribution-Agnostic Robust Generalization}
Due to the annotations being extremely expensive in the real world, a practical challenge is how to learn a robust model without a distribution index. Unlike JTT~\cite{liu2021just} which trains the model through two stages, we aim to solve this problem more efficiently by detecting the worst-case data during network training. As the corrupted data essentially lie out-of-distribution, so we are motivated to conduct OOD detection~\cite{hendrycks2019deep, li2022out, liang2017enhancing, liu2020energy, wei2022mitigating} to find the worst-case data.

Particularly, we re-utilize the previously computed weight perturbation $\epsilon^*$ to compute an OOD score:
\begin{equation}
	\omega_i = \max f(\theta; (x_i)) - \max f(\theta+\epsilon^*; (x_i)),
	\label{eq:ood_score}
\end{equation}
where $f(\cdot)$ stands for the $c$-dimensional label prediction in the label space, whose maximum value is considered as prediction confidence. Intuitively, as the model is much more robust to the clean distribution than the corrupted distribution, the prediction of clean data usually exhibits more stability than scarce noisy data when facing perturbations. Hence, if an example comes from a rarely explored distribution, its prediction certainty would deviate significantly from the original value, thus producing a large OOD score, as shown in Section~\ref{sec:ood_score}. Note that the major difference is that we target generalization on worst-case data, but OOD detection aims to exclude OOD data.

To this end, we can construct our worst-case dataset as $Q:=\left\{\sum_{i=1}^M \bar{\omega}_i\cdot(x_i, y_i): \bar{\omega}_i=\frac{\omega_i}{\frac{1}{M}\sum_{i=1}^M \omega_i}\right\}$, where normalization on $\omega_i$ is performed simultaneously. Then, the learning target of the distribution-agnostic setting becomes:
%\begin{equation}
%		\min_{\theta} \Big\{ \sum_{(x_i, y_i)\in Q}\mathcal{L}(\theta; (x_i, y_i)) +  \sum_{(x_i, y_i)\in Q}\mathcal{R}(\theta; (x_i, y_i))\Big\}.
%	\label{eq:distribution_agnostic}
%\end{equation}
\begin{align}
	\small
		\min_{\theta}& \Big\{\max_{\bar{\omega}_i} \big\{\sum_{(x_i, y_i)\in Q}\left[\mathcal{L}(\theta,\bar{\omega}_i; (x, y))\right]\big\} \label{eq:distribution_agnostic}\\
		&\qquad +  \sum_{(x_i, y_i)\in Q}\left[\mathcal{R}(\theta,\bar{\omega}_i; (x, y))\right]\Big\}, \nonumber
\end{align}
Therefore, the worst-case data can be selected by focusing on the examples with large OOD scores. In this way, our sharpDRO can be successfully deployed into the distribution-agnostic setting to ensure robust generalization, whose effectiveness is demonstrated by quantitative and qualitative results in Sections~\ref{sec:distribution_agnostic} and~\ref{sec:ood_score}. Next, we give details about implementing SharpDRO.



%\subsection{Practical Implementation}
%Overall, the training process of SharpDRO is summarized in Algorithm~\ref{alg:sharpdro}. Note that our SharpDRO requires two backward phases, so the time complexity of this form is twice as much as plain training, for efficient sharpness computation, please refer to~\cite{du2022sharpness, zhao2022penalizing}. In the first step, we record the label prediction $p$ of each data during inference and simultaneously compute the loss $\mathcal{L}$. Additionally, in the first backward pass, we store the computed gradient $\nabla\mathcal{L}(\theta)$.  Further, by adding $\epsilon^*$, we use the perturbed model to compute the second label prediction $\hat{p}$, which is further leveraged to compute the sharpness $\mathcal{R}$. Moreover, in the distribution-agnostic setting, the predictions $p$ and $\hat{p}$ from two forward steps are used to compute the OOD score $\omega_i$. Then, we add the recorded gradient $\nabla\mathcal{L}(\theta)$ back to the model parameter and conduct sharpness minimization over the selected worst-case data. In this way, our SharpDRO can be correctly performed. In the next section, we give specific details about our experimental setting and conduct extensive quantitative as well as qualitative analyses to empirically validate the proposed SharpDRO. Please see \textbf{Appendix} for more details.

\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\begin{algorithm}[H]
	\small
	\caption{\small Optimization process of SharpDRO}
	\label{alg:sharpdro}
	\begin{algorithmic}[1]
		\State Training set $\mathcal{D}^{\text{train}}=\left\{x_i, y_i\right\}_{i=1}^M$ containing Poisson distributed noisy corruptions; Model parameter $\theta \gets \theta_0$; Weighting parameter $\omega \gets \omega_0$; Learning rate: $\eta_{\theta}$, $\eta_{\omega}$.
		\For{$t \in 0,1, \ldots,T-1$}
		\If {\textit{Distribution-aware}}
		\State \textit{\color{black!60} $\triangleright$ Loss maximization via optimizing $\omega_{t+1}$}
		\State $\omega_{t+1} := \arg\max_{\omega} \left\{\mathbb{E}_{(x, y)\sim \omega P_s}\left[\mathcal{L}(\theta_{t},\omega; (x, y))\right]\right\}$; 
		\ElsIf {\textit{Distribution-agnostic}}
		\State{\textit{\color{black!60} $\triangleright$ OOD detection for computing $\omega_{t+1}$}}
		\State Update $\omega_{t+1}$ via Eq.~\ref{eq:ood_score}; 
		\EndIf
		\State \textit{\color{black!60} $\triangleright$ Optimize variable $\theta$}
		\State $\theta_{t+1} = \arg\min_{\theta}\Big\{\mathbb{E}_{(x,y)\sim w_tP}[\mathcal{L}(\theta,\omega_t) + \mathcal{R}(\theta,\omega_t)]  \Big\}$
		\EndFor
	\end{algorithmic}
\end{algorithm}

\vspace{-3mm}
\subsection{Optimization for SharpDRO}
\label{sec:optimization}
In both distribution-aware and distribution-agnostic scenarios, the worst-case data distribution is identified using distribution weighting parameter $\omega_s$ and OOD score $\omega$, respectively. Intuitively, their effect is similar: finding the worst data distribution which yields the maximum loss. Therefore, without loss of generality, we consider the maximization in Eqs.~\ref{eq:distribution_aware} and~\ref{eq:distribution_agnostic} as the optimization on the same weighting parameter $\omega$ and the samples $(x,y)$ can be considered i.i.d. from $\mathcal{Q}$ weighted by $\omega$ to compute the loss value $\mathcal{L}$. Moreover, the sharpness regularization can be reformulated in the same way as Eq.~\ref{eq:sharpness} by including $\omega$: $\mathcal{R}(\theta,\omega;(x,y))=\max_{\|\epsilon\|_2\leq \rho}\{\mathcal{L}(\theta+\epsilon,\omega;(x,y))-\mathcal{L}(\theta,\omega;(x,y))\}$. Therefore, our general learning objective can be formulated as a bi-level optimization problem:
\vspace{-2mm}
\begin{align}
\small
& \min_{\theta} \mathbb{E}_{(x, y)\sim Q}\left[\mathcal{L}(\theta,\omega^{*}; (x, y))\right] + \mathcal{R}(\theta,\omega^{*}; (x, y))   \\
& \qquad \text{s. t.}\ \omega^{*} = \arg\max_{\omega} \mathbb{E}_{(x, y)\sim Q}\left[\mathcal{L}(\theta,\omega; (x, y))\right].
\vspace{-4mm}
\end{align}
The optimization process is shown in Algorithm.~\ref{alg:sharpdro}. Specifically, we first update the weighting parameter $\omega$ based on the empirical risk term $\mathcal{L}$ using stochastic gradient ascent. Then, by leveraging the updated $\omega$, we optimize the general objective which contains both risk minimization of $\mathcal{L}$ and worst-case sharpness minimization of $\mathcal{R}$. We iterate these processes until convergence, hoping to minimize the risk on target loss function $\mathcal{L}$ with the worst-case data distribution.





% \noindent
% \textbf{Optimization:}
% In Algorithm.~\ref{alg:sharpdro}, we demonstrate the optimization process of SharpDRO. Specifically, In the first step, we store the gradient of the original $\mathcal{L}$ regarding $\theta$ as $\theta^{tmp}$, which will be used to compute the second term of $\mathcal{R}$. Then, in the second step, we select the worst-case data distribution by increasing the loss function $\mathcal{L}$ via gradient ascent on parameter $\omega$. Finally, we add $\theta^{tmp}$ back into $\theta$, and conduct worst-case sharpness minimization of $\mathcal{L}$ based on the updated weighting parameter $\omega$.


% \noindent
% \textbf{Stochastic Gradient Descent:}
% Note that the computed gradient is denoted as $\nabla\mathcal{L}$ in optimization process, in practice, it is computed by using stochastic gradient descent on samples from empirical distribution. Specifically, we assume the training set $\mathcal{D}^{\text{train}}$ follows a given distribution $Q$. The expected gradient value is estimated by each empirical sample $\{(x_i,y_i)\}_{i=1}^M$ containing $M$ examples. Mathematically, $\nabla_{\theta}\mathcal{L}=\frac{1}{M}\sum_{i=1}^M \frac{\partial \mathcal{L}}{\partial \theta }(\theta,\omega;(x_i,y_i))$ and $\nabla_{\omega}\mathcal{L}=\frac{1}{M}\sum_{i=1}^M\frac{\partial\mathcal{L}}{\partial\omega}(\theta,\omega;(x_i,y_i))$, where $\frac{\partial\mathcal{L}}{\partial\theta}$ and $\frac{\partial\mathcal{L}}{\partial\omega}$ are the unbiased estimation such that $\mathbb{E}_{(x,y)\sim Q}[\frac{\partial\mathcal{L}}{\partial\theta}(\theta,\omega;(x,y))]=\nabla_{\theta}\mathbb{E}_{(x,y)\sim Q}\mathcal{L}(\theta,\omega;(x,y))$ and $\mathbb{E}_{(x,y)\sim Q}[\frac{\partial\mathcal{L}}{\partial\omega}(\theta,\omega;(x,y))]=\nabla_{\omega}\mathbb{E}_{(x,y)\sim Q}\mathcal{L}(\theta,\omega;(x,y))$.



\noindent
\textbf{Convergence Analysis:}
	First we give some brief notations: $\mathbb{L}(\theta,\omega):=\mathbb{E}_{(x,y)\sim Q}\mathcal{L}(\theta,\omega;(x,y))$. The worst-case data distribution which has the maximum loss is denoted by $\omega^*(\theta):= \arg\max_{\omega}\mathbb{L}(\theta,\omega)$. We can obtain the convergence to a stationary point of $\mathbb{L}^*(\theta):=\max_{\omega}\mathbb{L}(\theta,\omega)=\mathbb{L}(\theta,\omega^*(\theta))$ by averaged gradient 
	 $\frac{1}{T}\sum_{t=0}^{T-1}\mathbb{E}\|\nabla \mathbb{L}^*(\theta_t)\|^2$.


\begin{table*}
\vspace{-8mm}
	\scriptsize
	\centering
	\caption{Quantitative comparisons on distribution-aware robust generalization setting. Averaged accuracy ($\%$) with standard deviations are computed over three independent trials.}
	\vspace{-0.2cm}
	\setlength{\tabcolsep}{2.8mm}
	\label{tab:distribution_aware}
	\begin{tabular}{lllcccccc}
		\toprule[1pt]
		\multirow{2}{*}{data} & \multirow{2}{*}{Type} & \multirow{2}{*}{Method} & \multicolumn{6}{c}{Corruption Severity} \\
		&  &  & \multicolumn{1}{c}{0} & \multicolumn{1}{c}{1} & \multicolumn{1}{c}{2} & \multicolumn{1}{c}{3} & \multicolumn{1}{c}{4} & \multicolumn{1}{c}{5} \\ \midrule[0.6pt]
		\multirow{10}{*}{CIFAR10} & \multirow{5}{*}{Gaussian} & ERM & \multicolumn{1}{c}{$90.9\pm0.02$} & \multicolumn{1}{c}{$89.2\pm0.02$} & \multicolumn{1}{c}{$86.4\pm0.03$} & \multicolumn{1}{c}{$85.9\pm0.01$} & \multicolumn{1}{c}{$83.5\pm0.01$} & \multicolumn{1}{c}{$78.8\pm0.01$} \\
		&  & IRM & \multicolumn{1}{c}{$91.8\pm0.01$} & \multicolumn{1}{c}{$90.3\pm0.01$} & \multicolumn{1}{c}{$89.5\pm0.01$} & \multicolumn{1}{c}{$86.7\pm0.02$} & \multicolumn{1}{c}{$81.8\pm0.02$} & \multicolumn{1}{c}{$80.0\pm0.02$} \\
		&  & REx & \multicolumn{1}{c}{$91.3\pm0.03$} & \multicolumn{1}{c}{$89.5\pm0.02$} & \multicolumn{1}{c}{$88.1\pm0.02$} & \multicolumn{1}{c}{$86.7\pm0.02$} & \multicolumn{1}{c}{$83.3\pm0.01$} & \multicolumn{1}{c}{$80.5\pm0.02$} \\
		&  & GroupDRO & \multicolumn{1}{c}{$90.2\pm0.03$} & \multicolumn{1}{c}{$89.1\pm0.02$} & \multicolumn{1}{c}{$88.4\pm0.04$} & \multicolumn{1}{c}{$84.3\pm0.01$} & \multicolumn{1}{c}{$83.0\pm0.02$} & \multicolumn{1}{c}{$78.2\pm0.02$} \\
		&  & SharpDRO & \multicolumn{1}{c}{$\bm{92.9}\pm\bm{0.02}$} & \multicolumn{1}{c}{$\bm{91.3}\pm\bm{0.02}$} & \multicolumn{1}{c}{$\bm{90.5}\pm\bm{0.01}$} & \multicolumn{1}{c}{$\bm{88.4}\pm\bm{0.02}$} & \multicolumn{1}{c}{$\bm{86.9}\pm\bm{0.01}$} & \multicolumn{1}{c}{$\bm{84.7}\pm\bm{0.01}$} \\ \cline{2-9} 
		
		& \multirow{5}{*}{JPEG} & ERM & \multicolumn{1}{c}{$91.0\pm0.02$} & \multicolumn{1}{c}{$89.0\pm0.02$} & \multicolumn{1}{c}{$86.2\pm0.02$} & \multicolumn{1}{c}{$83.1\pm0.02$} & \multicolumn{1}{c}{$82.5\pm0.03$} & \multicolumn{1}{c}{$81.4\pm0.03$} \\
		&  & IRM & \multicolumn{1}{c}{$90.2\pm0.02$} & \multicolumn{1}{c}{$88.2\pm0.02$} & \multicolumn{1}{c}{$86.7\pm0.03$} & \multicolumn{1}{c}{$84.0\pm0.02$} & \multicolumn{1}{c}{$82.9\pm0.03$} & \multicolumn{1}{c}{$81.6\pm0.02$}  \\
		&  & REx & \multicolumn{1}{c}{$89.6\pm0.03$} & \multicolumn{1}{c}{$89.2\pm0.02$} & \multicolumn{1}{c}{$86.0\pm0.03$} & \multicolumn{1}{c}{$85.8\pm0.03$} & \multicolumn{1}{c}{$82.7\pm0.03$} & \multicolumn{1}{c}{$81.9\pm0.02$}  \\
		&  & GroupDRO & \multicolumn{1}{c}{$90.3\pm0.02$} & \multicolumn{1}{c}{$88.6\pm0.03$} & \multicolumn{1}{c}{$86.5\pm0.03$} & \multicolumn{1}{c}{$84.2\pm0.02$} & \multicolumn{1}{c}{$83.2\pm0.02$} & \multicolumn{1}{c}{$82.1\pm0.02$} \\
		&  & SharpDRO & \multicolumn{1}{c}{$\bm{91.2}\pm\bm{0.01}$} & \multicolumn{1}{c}{$\bm{89.3}\pm\bm{0.02}$} & \multicolumn{1}{c}{$\bm{87.6}\pm\bm{0.02}$} & \multicolumn{1}{c}{$\bm{86.6}\pm\bm{0.02}$} & \multicolumn{1}{c}{$\bm{85.8}\pm\bm{0.03}$} & \multicolumn{1}{c}{$\bm{84.5}\pm\bm{0.01}$} \\
		\midrule[0.6pt]
		
		
		\multirow{10}{*}{CIFAR100} & \multirow{5}{*}{Gaussian} & ERM & $68.2\pm0.01$ & $64.8\pm0.01$ & $60.6\pm0.01$ & $56.9\pm0.01$ & $53.9\pm0.01$ & $50.2\pm0.03$ \\
		&  & IRM & $64.7\pm0.02$ & $64.7\pm0.01$ & $62.2\pm0.01$ & $54.5\pm0.02$ & $53.4\pm0.03$ & $50.4\pm0.01$ \\
		&  & REx & $68.0\pm0.03$ & $65.1\pm0.03$ & $61.8\pm0.01$ & $56.8\pm0.01$ & $53.2\pm0.01$ & $51.5\pm0.01$ \\
		&  & GroupDRO & $66.1\pm0.01$ & $61.7\pm0.02$ & $59.3\pm0.03$ & $53.6\pm0.01$ & $54.0\pm0.02$ & $50.6\pm0.02$ \\
		&  & SharpDRO & $\bm{71.2}\pm\bm{0.02}$ & $\bm{70.1}\pm\bm{0.01}$ & $\bm{68.6}\pm\bm{0.01}$ & $\bm{58.8}\pm\bm{0.01}$ & $\bm{57.5}\pm\bm{0.02}$ & $\bm{53.8}\pm\bm{0.03}$
		\\ \cline{2-9} 
		
		& \multirow{5}{*}{JPEG} & ERM & $64.7\pm0.01$ & $62.8\pm0.02$ & $57.2\pm0.02$ & $54.7\pm0.03$ & $54.0\pm0.02$ & $50.6\pm0.03$ \\
		&  & IRM & $64.2\pm0.02$ & $62.8\pm0.04$ & $58.0\pm0.01$ & $56.3\pm0.02$ & $55.0\pm0.02$ & $51.8\pm0.03$ \\
		&  & REx & $63.5\pm0.03$ & $62.2\pm0.02$ & $58.4\pm0.03$ & $56.5\pm0.03$ & $55.1\pm0.02$ & $52.2\pm0.01$ \\
		&  & GroupDRO & $63.4\pm0.02$ & $61.6\pm0.04$ & $58.6\pm0.02$ & $57.2\pm0.02$ & $55.8\pm0.03$ & $53.1\pm0.02$ \\
		&  & SharpDRO & $\bm{65.3}\pm\bm{0.02}$ & $\bm{63.0}\pm\bm{0.02}$ & $\bm{59.8}\pm\bm{0.02}$ & $\bm{58.8}\pm\bm{0.02}$ & $\bm{57.8}\pm\bm{0.03}$ & $\bm{55.3}\pm\bm{0.03}$ \\ \midrule[0.6pt]
		
		
		
		
		\multirow{10}{*}{ImageNet30} & \multirow{5}{*}{Gaussian} & ERM & $87.5\pm0.01$ & $84.6\pm0.01$ & $81.9\pm0.01$ & $76.5\pm0.01$ & $71.2\pm0.01$ & $65.3\pm0.01$ \\ 
		&  & IRM & $86.6\pm0.01$ & $84.4\pm0.03$ & $80.6\pm0.01$ & $75.2\pm0.01$ & $70.7\pm0.03$ & $64.8\pm0.01$ \\ 
		&  & REx& $86.3\pm0.01$ & $83.8\pm0.03$ & $81.1\pm0.02$ & $75.6\pm0.02$ & $71.5\pm0.01$ & $66.1\pm0.03$ \\ 
		&  & GroupDRO & $85.1\pm0.02$ & $84.2\pm0.01$ & $81.2\pm0.03$ & $76.3\pm0.03$ & $72.0\pm0.02$ & $66.3\pm0.01$ \\ 
		&  & SharpDRO& $\bm{88.4}\pm\bm{0.02}$ & $\bm{87.6}\pm\bm{0.01}$ & $\bm{83.3}\pm\bm{0.01}$ & $\bm{79.1}\pm\bm{0.02}$ & $\bm{73.5}\pm\bm{0.03}$ & $\bm{68.7}\pm\bm{0.01}$ \\  \cline{2-9} 
		
		
		& \multirow{5}{*}{JPEG} & ERM & $86.8\pm0.03$ & $85.3\pm0.03$ & $83.2\pm0.02$ & $82.6\pm0.01$ & $80.4\pm0.04$ & $78.2\pm0.02$ \\
		&  & IRM & $86.2\pm0.03$ & $85.1\pm0.02$ & $83.8\pm0.03$ & $83.2\pm0.03$ & $81.6\pm0.02$ & $79.1\pm0.01$ \\
		&  & REx & $85.8\pm0.02$ & $85.3\pm0.02$ & $83.5\pm0.02$ & $82.9\pm0.02$ & $81.4\pm0.02$ & $78.2\pm0.02$ \\
		&  & GroupDRO & $86.7\pm0.02$ & $84.9\pm0.02$ & $84.1\pm0.02$ & $84.5\pm0.02$ & $82.3\pm0.02$ & $79.0\pm0.02$ \\
		&  & SharpDRO & $\bm{87.4}\pm\bm{0.02}$ & $\bm{86.4}\pm\bm{0.03}$ & $\bm{86.2}\pm\bm{0.03}$ & $\bm{85.6}\pm\bm{0.02}$ & $\bm{83.9}\pm\bm{0.02}$ & $\bm{82.1}\pm\bm{0.03}$ \\  \bottomrule[1pt]
		
	\end{tabular}
\vspace{-2mm}
\end{table*}

\vspace{-2mm}
% \newtheorem{theorem}{Theorem}[section]
\begin{theorem}[\textbf{Informal}] Assuming the loss function $\mathbb{L}$ is $l$-Lipschitz smooth, satisfies $\mu$-Polyak-≈Åojasiewicz (PL) condition on the second variable $\omega$, and has unbiased estimation about the gradient as well as $\sigma^2$ bounded variance, we can get the convergence rate during $T$ iterations:
\begin{equation*}
\small
\begin{aligned}
\!\frac{1}{T}\!\sum_{t=0}^{T-1}\mathbb{E}\|\nabla\mathbb{L}^*(\theta_t)\|^2
&    \!\leq\! 320\sqrt{\frac{3\kappa^4l(\mathbb{E}[\mathbb{L}^*(\theta_0)]\!-\!\min_{\theta}\mathbb{E}[\mathbb{L}^*(\theta)])\sigma^2}{11MT}}\\
&=\mathcal{O}\left(\frac{\kappa^2}{\sqrt{MT}}\right),
\end{aligned}
\end{equation*}
where the conditional number $\kappa=l/\mu$ and $M$ means the sample batch(here we can choose $M=1$)\footnote{The resulting bound here means our SharpDRO can converge to the $\epsilon$-stationary point in $\frac{1}{\epsilon^2}$ iterations. Moreover, we will present our proof details in the \textbf{Appendix}, including the definitions, assumptions, and lemmas.}.
\end{theorem}




