\section{Experiments}
\label{sec:experiments}
In our experiments, we first give details about our experimental setup. Then, we conduct quantitative experiments to compare to proposed SharpDRO with the most popular baseline methods by considering both distribution-aware and distribution agnostic settings, which shows the capability of SharpDRO to tackle the most challenging distributions. Finally, we conduct qualitative analyses to investigate the effectiveness of SharpDRO in achieving robust generalization.



\begin{table*}[t]
\vspace{-8mm}
	\scriptsize
	\centering
	\caption{Quantitative comparisons on distribution-agnostic robust generalization setting. Averaged accuracy ($\%$) with standard deviations are computed over three independent trails.}
		\vspace{-0.2cm}
	\setlength{\tabcolsep}{2.8mm}
	\label{tab:distribution_agnostic}
	\begin{tabular}{lllcccccc}
		\toprule[1pt]
		\multirow{2}{*}{Dataset} & \multirow{2}{*}{Type} & \multirow{2}{*}{Method} & \multicolumn{6}{c}{Corruption Severity} \\
		&  &  & \multicolumn{1}{c}{0} & \multicolumn{1}{c}{1} & \multicolumn{1}{c}{2} & \multicolumn{1}{c}{3} & \multicolumn{1}{c}{4} & \multicolumn{1}{c}{5} \\ \midrule[0.6pt]
		\multirow{6}{*}{CIFAR10} & \multirow{3}{*}{Gaussian} & JTT & \multicolumn{1}{c}{$89.9\pm0.02$} & \multicolumn{1}{c}{$88.8\pm0.02$} & \multicolumn{1}{c}{$86.5\pm0..0$2} & \multicolumn{1}{c}{$86.1\pm0.02$} & \multicolumn{1}{c}{$83.4\pm0.03$} & \multicolumn{1}{c}{$79.8\pm0.02$} \\
		&  & EIIL & \multicolumn{1}{c}{$88.6\pm0.02$} & \multicolumn{1}{c}{$87.5\pm0.03$} & \multicolumn{1}{c}{$86.3\pm0.03$} & \multicolumn{1}{c}{$85.4\pm0.02$} & \multicolumn{1}{c}{$83.2\pm0.03$} & \multicolumn{1}{c}{$78.8\pm0.01$} \\
		&  & SharpDRO & \multicolumn{1}{c}{$\bm{91.3}\pm\bm{0.01}$} & \multicolumn{1}{c}{$\bm{90.2}\pm\bm{0.02}$} & \multicolumn{1}{c}{$\bm{88.7}\pm\bm{0.01}$} & \multicolumn{1}{c}{$\bm{87.3}\pm\bm{0.02}$} & \multicolumn{1}{c}{$\bm{84.2}\pm\bm{0.02}$} & \multicolumn{1}{c}{$\bm{84.3}\pm\bm{0.01}$} \\ \cline{2-9} 
		
		
		& \multirow{3}{*}{JPEG} & JTT & \multicolumn{1}{c}{$88.9\pm0.03$} & \multicolumn{1}{c}{$87.2\pm0.04$} & \multicolumn{1}{c}{$85.3\pm0.03$} & \multicolumn{1}{c}{$83.5\pm0.03$} & \multicolumn{1}{c}{$81.0\pm0.04$} & \multicolumn{1}{c}{$78.8\pm0.03$} \\
		&  & EIIL & \multicolumn{1}{c}{$89.4\pm0.03$} & \multicolumn{1}{c}{$87.6\pm0.03$} & \multicolumn{1}{c}{$85.3\pm0.04$} & \multicolumn{1}{c}{$83.2\pm0.03$} & \multicolumn{1}{c}{$81.6\pm0.02$} & \multicolumn{1}{c}{$79.1\pm0.01$} \\
		&  & SharpDRO & \multicolumn{1}{c}{$\bm{90.3}\pm\bm{0.02}$} & \multicolumn{1}{c}{$\bm{88.2}\pm\bm{0.02}$} & \multicolumn{1}{c}{$\bm{87.2}\pm\bm{0.02}$} & \multicolumn{1}{c}{$\bm{85.3}\pm\bm{0.02}$} & \multicolumn{1}{c}{$\bm{84.2}\pm\bm{0.02}$} & \multicolumn{1}{c}{$\bm{82.3}\pm\bm{0.03}$} \\  \midrule[0.6pt]
		
		
		\multirow{6}{*}{CIFAR100} & \multirow{3}{*}{Gaussian} & JTT & $68.0\pm0.02$ & $65.3\pm0.02$ & $61.3\pm0.01$ & $56.3\pm0.01$ & $54.2\pm0.03$ & $51.2\pm0.02$ \\
		&  & EIIL & $67.2\pm0.01$ & $66.2\pm0.02$ & $61.0\pm0.02$ & $55.8\pm0.02$ & $54.6\pm0.03$ & $52.1\pm0.02$ \\
		&  & SharpDRO & $\bm{69.6}\pm\bm{0.03}$ & $\bm{68.0}\pm\bm{0.02}$ & $\bm{63.6}\pm\bm{0.03}$ & $\bm{58.2}\pm\bm{0.02}$ & $\bm{56.5}\pm\bm{0.03}$ & $\bm{54.1}\pm\bm{0.03}$ \\ \cline{2-9} 
		
		
		& \multirow{3}{*}{JPEG} & JTT & $63.1\pm0.03$ & $61.0\pm0.04$ & $58.4\pm0.03$ & $56.2\pm0.02$ & $54.5\pm0.04$ & $51.9\pm0.03$ \\
		&  & EIIL & $63.6\pm0.02$ & $61.5\pm0.03$ & $58.8\pm0.03$ & $\bm{57.7}\pm\bm{0.02}$ & $54.2\pm0.03$ & $52.2\pm0.04$ \\
		&  & SharpDRO & $\bm{64.2}\pm\bm{0.02}$ & $\bm{62.5}\pm\bm{0.03}$ & $\bm{60.1}\pm\bm{0.03}$ & $57.6\pm0.03$ & $\bm{57.2}\pm\bm{0.02}$ & $\bm{54.8}\pm\bm{0.02}$ \\  \midrule[0.6pt]
		
	
		
		\multirow{6}{*}{ImageNet30} & \multirow{3}{*}{Gaussian} & JTT & $87.3\pm0.02$ & $84.5\pm0.02$ & $82.3\pm0.04$ & $75.6\pm0.01$ & $72.1\pm0.04$ & $66.5\pm0.02$ \\
		&  & EIIL & $\bm{88.2}\pm\bm{0.02}$ & $85.2\pm0.03$ & $81.3\pm0.02$ & $74.5\pm0.02$ & $71.5\pm0.02$ & $65.0\pm0.04$ \\
		&  & SharpDRO & $87.1\pm0.02$ & $\bm{86.9}\pm\bm{0.02}$ & $\bm{83.5}\pm\bm{0.03}$ & $\bm{78.0}\pm\bm{0.02}$ & $\bm{74.9}\pm\bm{0.02}$ & $\bm{68.4}\pm\bm{0.03}$ \\ \cline{2-9} 
		
		
		& \multirow{3}{*}{JPEG} & JTT & $85.4\pm0.02$ & $84.3\pm0.02$ & $82.5\pm0.02$ & $80.0\pm0.02$ & $78.8\pm0.03$ & $77.4\pm0.02$ \\
		&  & EIIL & $85.3\pm0.02$ & $84.2\pm0.03$ & $83.2\pm0.03$ & $80.6\pm0.02$ & $78.4\pm0.02$ & $77.2\pm0.02$ \\
		&  & SharpDRO & $\bm{86.6}\pm\bm{0.03}$ & $\bm{85.7}\pm\bm{0.02}$ & $\bm{85.0}\pm\bm{0.02}$ & $\bm{84.3}\pm\bm{0.02}$ & $\bm{83.2}\pm\bm{0.03}$ & $\bm{82.5}\pm\bm{0.02}$ \\  \bottomrule[1pt]
		
	\end{tabular}
\vspace{-2mm}
\end{table*}



\subsection{Experimental Setup}
For distribution-aware situation, we choose GroupDRO~\cite{sagawa2019distributionally}, IRM~\cite{arjovsky2019invariant}, REx~\cite{krueger2021out}, and ERM for comparisons. As for distribution-agnostic situation, we pick JTT~\cite{liu2021just} and Environment Inference for Invariant Learning (EIIL)~\cite{creager2021environment} for baseline methods\footnote{Note that we do not include sharpness minimization method SAM~\cite{foret2020sharpness} in this problem setting because its OOD generalization performance is worse than ERM. However, we conduct detailed analysis between SharpDRO and SAM in Section~\ref{sec:qualitative_analysis}}. For each problem setting, we construct corrupted dataset using CIFAR10/100~\cite{krizhevsky2009learning} and ImageNet30~\cite{russakovsky2015imagenet} datasets. Specifically, we following~\cite{hendrycks2019benchmarking} to perturb the image data with severity level varies from $1$ to $5$ by using two types of corruption: ``Gaussian Noise'' and ``JPEG Compression''. Moreover, the clean data are considered as having a corruption severity of $0$. For each corrupted distribution, we sample them with different probabilities by following Poisson distribution $P(s; \lambda=1)$, \textit{i.e.}, for $s$ varies from $0$ to $5$, the sample probabilities are $\left\{0.367, 0.367, 0.184, 0.061, 0.015, 0.003\right\}$, respectively. Then, we test the robust performance on each data distribution. For hyper-parameter $\rho$, we follow~\cite{foret2020sharpness} by setting it to $0.05$ to control the magnitude of $\epsilon^*$. For each experiment, we conduct three independent trials and report the average test accuracy with standard deviations. Please see more details on experimental setting, results on other corruptions, and practical implementation in the \textbf{Appendix}.

\subsection{Quantitative Comparisons}
In this part, we focus on three questions: 1) Can SharpDRO perform well on two situations of robust generalization? 2) Does SharpDRO generalize well on the most severely corrupted distributions? and 3) Is SharpDRO able to tackle different types of corruption? To answer these questions, we conduct experiments on both two settings by testing on different corruption types and severity levels.




\paragraph{Distribution-Aware Robust Generalization}
\label{sec:distribution_aware}
As shown in Table~\ref{tab:distribution_aware}, we can see that SharpDRO surpasses other methods with larger performance gains as the corruption severity goes stronger. Especially in CIFAR10 dataset on ``Gaussian Noise'' corruption, improvement margin between SharpDRO and second-best method is $1.1\%$ with severity of $0$, which is further increased to about $\bm{4.2\%}$ with severity of $5$, which indicates the capability of SharpDRO on generalization against severe corruptions. Moreover, SharpDRO frequently outperforms other methods on all scenarios, which manifests the robustness of SharpDRO against various corruption types.



\paragraph{Distribution-Agnostic Robust Generalization}
\label{sec:distribution_agnostic}
In Table~\ref{tab:distribution_agnostic}, we can see a similar phenomenon as in Table~\ref{tab:distribution_aware} that the more severe corruptions are applied, the larger performance gains SharpDRO achieves. Especially, in the ImageNet30 dataset corrupted by ``JPEG Compression'', SharpDRO shows about $1.2\%$ performance gains upon the second-best method with severity $0$, which is further increased to almost $\bm{5.1\%}$ with severity $5$. Moreover, SharpDRO is general to all three corruption types, as it surpasses other methods in most cases. Therefore, the proposed method can perfectly generalize to worst-case data even without the distribution annotations.


\begin{figure*}[t]
	\vspace{-6mm}
	\centering
	\begin{minipage}[t]{0.195\textwidth}
		\centering
		\includegraphics[width=\linewidth]{gradnorm_erm.png}
	\end{minipage}
	\begin{minipage}[t]{0.195\textwidth}
		\centering
		\includegraphics[width=\linewidth]{gradnorm_irm.png}
	\end{minipage}
	\begin{minipage}[t]{0.195\textwidth}
		\centering
		\includegraphics[width=\linewidth]{gradnorm_rex.png}
	\end{minipage}
	\begin{minipage}[t]{0.195\textwidth}
		\centering
		\includegraphics[width=\linewidth]{gradnorm_dro.png}
	\end{minipage}
	\begin{minipage}[t]{0.195\textwidth}
		\centering
		\includegraphics[width=\linewidth]{gradnorm_sharp.png}
	\end{minipage}
	\vspace{-3mm}
	\caption{\small Gradient norm comparisons between different methods over all corrupted distributions.}
	\label{fig:gradnorm}
	\vspace{-0.4cm}
\end{figure*}


\subsection{Qualitative Analysis}
\label{sec:qualitative_analysis}
To investigate the effectiveness of SharpDRO, we first conduct an ablation study to show that the worst-case sharpness minimization is essential for achieving generalization with robustness. Then, we utilize gradient norm, an important criterion to present training stability, to validate that our method is stable for severely corrupted distributions. Then, we analyze the hyper-parameter $\rho$ and OOD score $\bar{w}$ to disclose the effectiveness of sharpness minimization and worst-case data selection. Finally, another second-order methdo SAM~\cite{foret2020sharpness, zhong2022improving, mi2022make, sun2023adasam, sun2023fedspeed} is investigated to discover the efficiency property of SharpDRO. All analyses are conducted using CIFAR10 with ``Gaussian Noise'' corruption.

\vspace{-3mm}
\begin{table}[H]
	\small
	\caption{Ablation study. "w/o data selection" denotes training without worst-case data selection, which recovers SAM~\cite{foret2020sharpness}, and "w/o sharp min" indicates training without sharpness minimization, which is the same as GroupDRO~\cite{sagawa2019distributionally}.}
		\vspace{-0.2cm}
	\setlength{\tabcolsep}{1.05mm}
	\label{tab:ablation_study}
	\begin{tabular}{lclllll}
		\toprule[1pt]
		\multirow{2}{*}{Method} & \multicolumn{6}{c}{Corruption Severity} \\
		& 0 & \multicolumn{1}{c}{1} & \multicolumn{1}{c}{2} & \multicolumn{1}{c}{3} & \multicolumn{1}{c}{4} & \multicolumn{1}{c}{5} \\ \midrule[0.6pt]
		w/o data selection (SAM) & 93.2 & \multicolumn{1}{c}{90.5} & \multicolumn{1}{c}{87.6} & \multicolumn{1}{c}{82.1} & \multicolumn{1}{c}{80.5} & \multicolumn{1}{c}{75.4} \\
		w/o sharp min (GroupDRO) & \multicolumn{1}{l}{90.2} & 89.1 & 88.4 & 84.3 & 83.0 & 78.2 \\
		\rowcolor{gray!25} SharpDRO & \multicolumn{1}{l}{92.9} &  91.3 & 90.5 & 88.4 & 86.9 & 84.7 \\ \bottomrule[1pt]
	\end{tabular}
\vspace{-6mm}
\end{table}

\vspace{-2mm}
\paragraph{Ablation Study}
\label{sec:ablation_study}
By eliminating the worst-case data selection, we recover the original sharpness minimization method SAM~\cite{foret2020sharpness}. Then, we remove the sharpness minimization module, which is basically training via GroupDRO. The ablation results are shown in Table~\ref{tab:ablation_study}. We can see that deploying SAM on the whole training dataset can achieve improved results on the clean dataset. However, the robust performance on corrupted distributions are even worse than GroupDRO. This could be because that sharpness is easy to be dominated by principle distributions, which is misleading for generalization to small distributions. Thus, the sharpness of corrupted data would be sub-optimal. As for GroupDRO, it fails to produce a flat loss surface for worst-case data, hence cannot generalize as well as the proposed SharpDRO.



\vspace{-1mm}
\paragraph{Distributional Stability}
To show our method can be stable even in the most challenging distributions, we show the gradient norm on a validation set including corruption severity from $0$ to $5$. As shown in Figure~\ref{fig:gradnorm}, SharpDRO not only produces the smallest norm value but also can ensure almost equal gradient norm across all corrupted distributions, which indicates that SharpDRO is the most distributionally stable method among all compared methods.



\paragraph{Parameter Analysis}

\begin{figure}[t]
	\centering
    \includegraphics[width=\linewidth]{sens_oodscore.pdf}
\caption{\small (a) Sensitivity of $\rho$ whose value is set to $\left\{0.01, 0.05, 0.1, 0.5, 1, 2\right\}$. (b) Distribution of the normalized OOD score $\bar{\omega}$ on distribution $s=0$ to $5$.}
\label{fig:sens_ood}
\vspace{-0.4cm}
\end{figure}

To understand how the scale parameter $\rho$ affects our generalization performance, we conduct sensitivity analysis by changing this value and show the test results of different distributions. In figure~\ref{fig:sens_ood} (a), we find an interesting discovery that as $\rho$ increases, which indicates the perturbation magnitude $\epsilon^*$ enlarges, would enhance the generalization of severely corrupted data but degrades the performance of slightly corrupted data. This might be because the exploration of hard distributions needs to cover wide range of neighborhood to ensure generalization. On the contrary, exploration too far on easy distributions can reach out-of-distribution, thus causing performance degradation. Therefore, for practitioners who aim to generalize on small and difficult datasets, we might be able to enhance performance by aggressively setting a large perturbation scale.

\paragraph{OOD Score Analysis}
\label{sec:ood_score}
The OOD score is leveraged to select worst-case data for the distribution-agnostic setting. To show its effectiveness in selecting the noisy data, we plot the value distribution of OOD scores from all corrupted distributions in epoch $30$ in Figure~\ref{fig:sens_ood} (b). We can see the tendency that a severer corruption has larger OOD scores. Therefore, our OOD score is a valid criterion to select worst-case data. Note that during the training process, the worst-case data would be \textbf{gradually learned}, thus the OOD score can become \textbf{smaller}, which explains why the value distribution of our score is not as separable as OOD detection does.

\paragraph{Training Efficiency Analysis}
It is clear that the proposed SharpDRO method is a second-order optimization method. Hence, when compared to first-order methods such as GroupDRO and REx, computational cost is the price to pay for achieving improved generalization performance\footnote{Note that our method can be deployed with existing efficient sharpness-based methods~\cite{zhang2022ga, du2022efficient, du2022sharpness, zhao2022ss}.}. However, to further explore the advantage of SharpDRO compared to other second-order method, here we use SAM~\cite{foret2020sharpness} as a competitor, and show their computational time as well as worst-case accuracy ($s=5$) in Figure.~\ref{fig:time}. We can see that on all three datasets, our SharpDRO requires nearly the same time to train, and significantly outperforms the worst-case performance of SAM, owing to our efficient worst-case data selection which is vital for robust generalization against severe corruptions.

\begin{figure}[t]
	\centering
	\includegraphics[width=0.85\linewidth]{time.png}
	\vspace{-4mm}
	\caption{\small Efficiency comparison between SharpDRO and SAM.}
	\label{fig:time}
	\vspace{-4mm}
\end{figure}
