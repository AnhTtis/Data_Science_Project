{
    "arxiv_id": "2303.13805",
    "paper_title": "Seeing Through the Glass: Neural 3D Reconstruction of Object Inside a Transparent Container",
    "authors": [
        "Jinguang Tong",
        "Sundaram Muthu",
        "Fahira Afzal Maken",
        "Chuong Nguyen",
        "Hongdong Li"
    ],
    "submission_date": "2023-03-24",
    "revised_dates": [
        "2023-03-27"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV"
    ],
    "abstract": "In this paper, we define a new problem of recovering the 3D geometry of an object confined in a transparent enclosure. We also propose a novel method for solving this challenging problem. Transparent enclosures pose challenges of multiple light reflections and refractions at the interface between different propagation media e.g. air or glass. These multiple reflections and refractions cause serious image distortions which invalidate the single viewpoint assumption. Hence the 3D geometry of such objects cannot be reliably reconstructed using existing methods, such as traditional structure from motion or modern neural reconstruction methods. We solve this problem by explicitly modeling the scene as two distinct sub-spaces, inside and outside the transparent enclosure. We use an existing neural reconstruction method (NeuS) that implicitly represents the geometry and appearance of the inner subspace. In order to account for complex light interactions, we develop a hybrid rendering strategy that combines volume rendering with ray tracing. We then recover the underlying geometry and appearance of the model by minimizing the difference between the real and hybrid rendered images. We evaluate our method on both synthetic and real data. Experiment results show that our method outperforms the state-of-the-art (SOTA) methods. Codes and data will be available at https://github.com/hirotong/ReNeuS",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.13805v1"
    ],
    "publication_venue": "Accepted to CVPR2023"
}