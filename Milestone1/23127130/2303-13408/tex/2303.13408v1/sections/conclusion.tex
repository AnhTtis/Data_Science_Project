\section{Conclusion}

We present \model, a discourse paraphrase generation model that can rewrite multiple sentences of text and optionally leverage surrounding context. We use \model\ to stress test current AI-generated text detectors, and we find that \model\ paraphrases easily evade these detectors while approximately preserving input semantics. To defend against such paraphrase attacks, we propose a simple retrieval-based mechanism in which we search through a corpus of previously-generated sequences from an LLM API for semantically-similar generations to a given query. Our experiments show that this retrieval defense significantly outperforms baseline detectors on paraphrased text, and is effective at scale. We extensively discuss possible limitations of our defense, and we open source our pretrained models, code, and data to enable the research community to build on these ideas.

%\kkcomment{other expt ideas we won't do for first version of paper: stress test defense with noise functions, control code evals vs LLM, LFQA by domain (evaluate both paraphraser and the detection attack and defense), variation with length of attack success / paraphrase performance, simpler paraphrasers, zero-shot LLMs, generate model A test on model B, baseline comparisons to other papers will be needed.. maybe we can do sentence-level comparisons with other sentence-level paraphrasers? backtranslation from NL-augmenter?~\citep{dhole2021nl}, https://arxiv.org/pdf/1911.09661.pdf, https://arxiv.org/abs/2109.07095.. We could run it across different control codes to show the tradeoffs, fine-grained evaluation on phenomenon using context, see~\citep{jean2017does} for ideas from MT like pronoun correctness, longer sentences / complex phenomenon in the sentence (paranmt vs \booktranslate), try to show why backtranslation / paranmt is not enough compared to this dataset, Kenton feedback: . Other comments: - This paper should be flooded with examples - how the retrieval model is scoring text pairs, and how other baselines interact with the retrieval model.}