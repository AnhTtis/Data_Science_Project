\begin{abstract}
To detect the deployment of large language models for malicious use cases (e.g., fake content creation or academic plagiarism), several approaches have recently been proposed for identifying AI-generated text via watermarks or statistical irregularities. 
How robust are these detection algorithms to \emph{paraphrases} of AI-generated text? To stress test these detectors, we first train an 11B parameter paraphrase generation model (\model) that can paraphrase \emph{paragraphs}, optionally leveraging surrounding text (e.g., user-written prompts) as context.  \model\ also uses scalar knobs to control the amount of lexical diversity and reordering in the paraphrases. Paraphrasing text generated by three large language models (including GPT3.5-davinci-003) with \model\ successfully evades several detectors, including watermarking, GPTZero, DetectGPT, and OpenAI's text classifier. For example, \model\ drops the detection accuracy of DetectGPT from 70.3\% to 4.6\% (at a constant false positive rate of 1\%), without appreciably modifying the input semantics.

To increase the robustness of AI-generated text detection to paraphrase attacks, we introduce a simple defense that relies on \emph{retrieving} semantically-similar generations and must be maintained by a language model API provider. Given a candidate text, our algorithm searches a database of sequences previously generated by the API, looking for sequences that match the candidate text within a certain threshold. We empirically verify our defense using a database of 15M generations from a fine-tuned T5-XXL model and find that it can detect 80\% to 97\% of paraphrased generations across different settings, while only classifying 1\% of human-written sequences as AI-generated.\footnote{Code, data and pretrained paraphrasers will be added to \url{https://github.com/martiansideofthemoon/ai-detection-paraphrases}.
\\ *Work partly done as a student researcher in Google Research. \\ $\dagger$ Equal advising.}

\end{abstract}

% PLAINTEXT = To detect the deployment of large language models for malicious use cases (e.g., fake content creation or academic plagiarism), several approaches have recently been proposed for identifying AI-generated text via watermarks or statistical irregularities. How robust are these detection algorithms to paraphrases of AI-generated text? To stress test these detectors, we first train an 11B parameter paraphrase generation model (DIPPER) that can paraphrase paragraphs, optionally leveraging surrounding text (e.g., user-written prompts) as context. DIPPER also uses scalar knobs to control the amount of lexical diversity and reordering in the paraphrases. Paraphrasing text generated by three large language models (including GPT3.5-davinci-003) with DIPPER successfully evades several detectors, including watermarking, GPTZero, DetectGPT, and OpenAI's text classifier. For example, DIPPER drops the detection accuracy of DetectGPT from 70.3% to 4.6% (at a constant false positive rate of 1%), without appreciably modifying the input semantics. To increase the robustness of AI-generated text detection to paraphrase attacks, we introduce a simple defense that relies on retrieving semantically-similar generations and must be maintained by an LLM API provider. Given a candidate text, our algorithm searches a database of sequences previously generated by the API, looking for sequences that match the candidate text within a certain threshold. We empirically verify our defense using a database of 15M generations from a fine-tuned T5-XXL model and find that it can detect 80% to 97% of paraphrased generations across different settings, while only classifying 1% of human-written sequences as AI-generated.


%To detect the deployment of large language models for malicious use cases such as fake content creation and academic plagiarism, several recent approaches propose to identify AI-generated text via watermarks or statistical irregularities. 

%Paraphrase generation is the task of rewriting text using a different set of words and syntactic constructions, while approximately preserving its meaning. Most prior work in this area has focused on paraphrasing a single sentence in isolation, attempting to maximize diversity of the output with respect to the input. 
% Additionally, we provide a small evaluation set of 250 human-written paragraph paraphrases covering several discourse paraphrasing phenomenon like re-ordered content, sentence splits, sentence merges etc.
%We push the state-of-the-art in paraphrase generation by
%To train this model, we leverage the paragraph alignments of multiple English translations of foreign books, provided in the in \booktranslate~dataset~\citep{thai2022booktranslate}.
%which can paraphrase a  of sentences, optionally leveraging surrounding text as context. Our model can not only make word-level transformations, but also re-order content, split and merge consecutive sentences.