

\section{Defense against paraphrase attacks using retrieval}
\label{sec:defenses}
\label{sec:defense-results}

In \sectionref{sec:attack-expts}, we observed that paraphrasing is an effective attack against AI-generated text detection algorithms.  How can API providers who serve outputs from large language models (LLMs) defend against these attacks? In this section, we propose \emph{retrieval} over previously-generated sequences as a defense against paraphrase attacks. At a high level (\figureref{fig:defense-idea}), an API provider first stores every sequence generated by their LLM in a database. The API provider offers an interface that allows users to enter candidate AI-generated text as a query. The interface searches over the entire database of previously-generated text, trying to find a sequence that approximately matches the content of the input query. This search can be done using a semantic similarity scorer like SP~\citep{wieting-etal-2022-paraphrastic} or a retriever like BM25~\citep{robertson1995okapi}. Since paraphrasing approximately preserves input semantics, we expect such a defense to still be able to map paraphrased generations to their source. 

\begin{table*}[t!]
\small
\begin{center}
\begin{tabular}{ lrrrrrrrrr } 
\toprule
\multicolumn{10}{c}{\textbf{Long-form Question Answering} (300 generated tokens)}\vspace{0.1in} \\ 
  & \multicolumn{3}{c}{GPT2-XL} & \multicolumn{3}{c}{OPT-13B} & \multicolumn{3}{c}{GPT-3.5 (davinci-003)}\\
\cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10} 
& Original & + 60L & + 60L,60O & Original & + 60L &  + 60L,60O & Original & + 60L & + 60L,60O \\
\midrule
 \multicolumn{5}{l}{\emph{Baseline methods}:} \vspace{0.15cm} \\
Watermark & 100.0 & 71.1 & 55.8 & 100.0 & 65.5 & 51.4 & - & - & -\\
DetectGPT & 74.9 & 15.8 & 7.6 & 29.8 & 3.2 & 1.5 & 1.0 & 0.0 & 0.0 \\
OpenAI & 59.2 & 31.3 & 32.7 & 33.5 & 21.6 & 21.6 & 40.5 & 40.1 & 38.1 \\
\midrule
\multicolumn{10}{l}{\emph{(Ours)} Retrieval over corpus of 3K generations from model itself, with retriever:} \vspace{0.15cm} \\
%~~~SP & 100.0 & 95.0 & 92.8 & 100.0 & 94.2 & 85.4 & 100.0 & 95.4 & 89.4 \\
%~~~BM25 &  100.0 & 99.6 & 98.9 & 100.0 & 99.6 & 98.8 & 100.0 & 99.4 & 98.8  \\
~~~SP & 100.0 & 95.6 & 87.7 & 100.0 & 94.8 & 85.3 & 100.0 & 94.2 & 85.1 \\
~~~BM25 & 100.0 & 99.2 & 97.8 & 100.0 & 99.3 & 97.3 & 100.0 & 98.6 & 96.2 \\
\midrule
\multicolumn{10}{l}{\emph{(Ours)} Retrieval over corpus of 9K generations pooled from all three models, with retriever:} \vspace{0.15cm} \\
%~~~SP & \\
%~~~BM25 & 100.0 & 99.4 & 98.6 & 100.0 & 99.5 & 98.5 & 100.0 & 99.4 & 98.6 \\
~~~SP & 100.0 & 88.9 & 75.4 & 100.0 & 89.6 & 76.4 & 100.0 & 93.8 & 84.6\\
~~~BM25 & 100.0 & 98.3  & 95.2  & 100.0 & 98.5 & 94.4 & 100.0 & 98.5 & 96.0\vspace{0.05in}\\
\midrule
 \multicolumn{10}{c}{\textbf{Open-ended text generation with Wikipedia prompts} (300 generated tokens)}\vspace{0.1in} \\ 
 & \multicolumn{3}{c}{GPT2-XL} & \multicolumn{3}{c}{OPT-13B} & \multicolumn{3}{c}{GPT-3.5 (davinci-003)}\\
\cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10} 
& Original & + 60L & + 60L,60O & Original & + 60L &  + 60L,60O & Original & + 60L & + 60L,60O \\
\midrule
\multicolumn{5}{l}{\emph{Baseline methods}:} \vspace{0.15cm} \\
Watermark & 100.0 & 68.9 & 57.2 & 99.9 & 63.7 & 52.8 & - & - & -\\
DetectGPT &  70.3 & 8.7 & 4.6 & 14.3 & 0.8 & 0.3 & 2.0 & 0.5 & 0.0 \\
OpenAI & 21.6 & 13.3 & 14.8 & 11.3 & 9.1 & 10.0 & 30.0 & 15.6 & 15.6 \\
\midrule
\multicolumn{10}{l}{\emph{(Ours)} Retrieval over corpus of 3K generations from model itself, with retriever:} \vspace{0.15cm} \\
%~~~SP & 100.0 & 83.0 & 80.8 & 100.0 & 81.8 & 80.0 & 100.0 & 63.4 & 47.4 \\
%~~~BM25 & 100.0 & 99.1 & 98.0 & 100.0 & 97.2 & 95.3 & 100.0 & 58.8 & 37.4 \\
~~~SP & 100.0 & 86.4 & 81.5 & 100.0 & 84.4 & 77.7 & 100.0 & 65.9 & 49.5 \\
~~~BM25 & 100.0 & 99.0 & 98.0 & 100.0 & 97.2 & 95.3 & 100.0 & 58.8 & 37.4\\
\midrule
\multicolumn{10}{l}{\emph{(Ours)} Retrieval over corpus of 9K generations pooled from all three models, with retriever:} \vspace{0.15cm} \\
%~~~SP & 100.0 & 82.8 & 80.0 & 100.0 & 81.8 & 80.0 & 100.0 & 76.6 & 60.0 \\
%~~~BM25 & 100.0 & 98.9 & 97.8 & 100.0 & 97.1 & 95.3 & 100.0 & 58.8 & 37.4 \\
~~~SP & 100.0 & 72.1 & 63.2 & 100.0 & 74.6 & 65.6 & 100.0 & 63.1 & 45.6 \\
~~~BM25 & 100.0 & 85.0 & 78.7 & 100.0 & 87.2 & 79.1 & 100.0 & 58.8 & 37.4 \\
\bottomrule
\end{tabular}
\end{center}
\caption{Our proposed defense (retrieval) significantly improves AI-generated text detection accuracy (at false positive rate 1\%) over baselines on all settings, including our most diverse paraphrase attacks (+60L, +60L,60O).}
\label{tab:watermark-defense}
\end{table*}



In this section we first formalize our retrieval defense in \sectionref{sec:retrieval-formulation}. We then perform controlled comparisons of retrieval with other detection algorithms (\sectionref{sec:control-defense-results}) and evaluate our method at scale using a large retrieval corpus of 15M generations (\sectionref{sec:scale-defense-results}).

\subsection{Formulating the retrieval defense}
\label{sec:retrieval-formulation}
\label{sec:retriever-choice}

Let $f_\text{LM}$ be an LLM API (e.g., GPT-3.5) that takes a prompt $x$ as input and returns a continuation $y$. Let $f_\text{ret}$ be an encoder (e.g., TF-IDF, neural network) that embeds variable-length sequences into fixed-size vectors that represent the input semantics. Then, we do the following:\\

\noindent 1. \textbf{Building the database}: Let $x_1,..., x_N$ be the set of prompts that have been fed as input to the API in the past, where $N$ can potentially be very large for popular APIs (we study up to $N=$ 15M). We construct our database $\mathbf{Y}$ by:
\begin{align*}
    y_i &= f_{\text{LM}}(x_i)~~~~~~\text{for } i = 1,...,N \\
    \mathbf{y}_i &= f_{\text{ret}}(y_i)~~~~~~\text{for } i = 1,...,N \\
    \mathbf{Y} &= [\mathbf{y}_1, ... \mathbf{y}_N]
\end{align*}
The database $\mathbf{Y}$ is dynamically updated and stored on the API side. It is inaccessible to clients except via the API described in the next step.
\vspace{0.1in}

\noindent 2. \textbf{Querying the database}: Let $y'$ be a candidate text, and suppose a client wishes to know whether $y'$ was generated by the API $f_\text{LM}$. The API provider can check this by computing whether the maximum similarity score of $y'$ to an entry in the database exceeds some threshold:
\begin{align*}
    \mathbf{y}' &= f_{\text{ret}}(y') \\
    \text{score} &= \max_{i} \frac{\mathbf{y}' \cdot \mathbf{y}_i}{|\mathbf{y}'|~|\mathbf{y}_i|} \\
\text{output} &= \text{score} > L
\end{align*}

Here, $L$ is the detection threshold chosen by the API provider. We expect unperturbed machine-generated text to always get a score of 1.0, while paraphrasing the text will lower the detection score. Hence, lowering $L$ will increase the detection rate of heavily-paraphrased text but also increase the false positive rate (i.e., human-written text that resembles sequences previously generated by the LLM API can be falsely flagged). Since $N$ can be very large, the score can also be approximated using efficient nearest neighbor libraries like FAISS~\citep{johnson2019billion}. However, in this work we only compute exact inner products.

\vspace{0.1in}

\noindent \textbf{Choice of retriever $f_\text{ret}$}: We experiment with two choices for $f_\text{ret}$ including \spavg from ~\citet{wieting-etal-2022-paraphrastic} and BM25~\citep{robertson1995okapi}. We implement BM25 using the \texttt{retriv} library from~\citet{retriv2022}. In order to normalize and calibrate BM25 scores, we compute the unigram token overlap (using the evaluation script from~\citealp{rajpurkar-etal-2016-squad}) between the candidate $y'$ and the best retrieval $y*$ to get a detection score in $[0, 1]$.




\subsection{Controlled comparisons of retrieval with other AI-generated text detectors}
\label{sec:control-defense-results}


First, we conduct a controlled comparison between the detection algorithms evaluated in \sectionref{sec:attack-expts} and our retrieval method. We construct two retrieval corpora for this experiment: (a) a corpus of the 3K sequences generated by a specific LM for one of the tasks; and (b) a corpus of 9K sequences formed by concatenating the generations from all three LMs considered in this paper. We expect (b) to be a more difficult test for our method than (a), since the retriever needs to distinguish between multiple generations from different models given the same prompt. Next, we perform retrieval over this corpus using the original AI-generated text, its paraphrase (generated by \model\ using control codes L60 and L60,O60), and human-written text as queries. While in this experiment, we only consider queries that are at least 50 token long, we discuss the effect of input length in \sectionref{sec:detect-length-effect}. 
% In \tableref{tab:watermark-defense}, we observe the following across both corpora:


\begin{figure}[t!]
    \centering
    \includegraphics[width=0.48\textwidth]{figures/scale_retrieval}
    \caption{The effectiveness of retrieval as a detection strategy as a function of retrieval corpus size. In all settings we note high detection accuracy of paraphrases (at 1\% FPR), which only slightly degraded as the corpus is scaled from 1M to 15M generations.}
    \label{fig:semantic-search}
\end{figure}


\vspace{0.05in}

\tableref{tab:watermark-defense} shows that \textbf{across all LMs, retrieval is a much more effective detector than baseline detectors}. On unperturbed machine-generated text, retrieval has a 100\% detection accuracy due to exact match with the retrieval corpus. On paraphrased text, retrieval with BM25 is quite effective, detecting 97.8\% of the highest-diversity paraphrases (L60,O60) on GPT2-XL, 97.3\% on OPT-13B and 96.2\% on GPT-3.5 in long-form question answering. This is significantly better than the next best alternative with competing detectors (55.8\%, 51.4\%, 38.1\%, respectively). Even on our harder augmented database of 9K generations, detection rates continue to be high (95.2\%, 94.4\%, 96.0\%). Finally, we observe that BM25 is a more effective retriever than \spavg, scoring 95.2\% vs 75.4\% on the augmented setting in GPT2-XL with long-form question answering. These trends are consistent across different false positive rate thresholds, as shown in our ROC curves (\figureref{fig:auc-plots}).

\subsection{Is retrieval an effective detector with a large retrieval corpus?}
\label{sec:scale-defense-results}
In the previous section, we conducted experiments using the set of 9K sequences generated by all three models as the retrieval corpus. However, this is more of a toy experiment: in practice, a popular LLM API may serve millions of queries a day. As the corpus grows larger, the  false positive rate (i.e., human-written text falsely detected as machine-generated) will grow. How well do retrieval-based detectors scale?  To answer this question, we need access to a large corpus of machine-generated text. We utilize the training data used to train RankGen~\citep{krishna-etal-2022-rankgen}, which contains over 70M machine-generated sequences. We use the Project Gutenberg and Wikipedia splits of the training data, each of which contain 15M sequences generated by a T5-XXL model~\citep{raffel2020exploring} fine-tuned on the different documents in the same domain. We discard generations which are shorter than 50 tokens, and paraphrase a small subset of 2K generations to evaluate retrieval.
 \vspace{0.1in}

\noindent \textbf{Retrieval is effective even with a corpus size of 15M generations.} In \figureref{fig:semantic-search}, we plot the detection accuracy as a function of retrieval database size. Overall, we observe that detection accuracy remains consistently high across different corpus sizes (varying from 1M generations to 15M generations). We do observe slight drops in performance as the corpus size increases: just 1\% (98.3 to 97.3) on Project Gutenberg (PG19) and 9.6\% (90.0 to 80.4) on Wikipedia. Consistent with the results in \sectionref{sec:control-defense-results}, BM25 continues to outperform \spavg\ across different retrieval corpus sizes.




\begin{figure}[t!]
    \centering
    \includegraphics[width=0.48\textwidth]{figures/scale_retrieval_length}
    \caption{The variation in retrieval performance as a detector with different query lengths. Overall, retrieval performs best with queries of length 50 tokens or more. }
    \label{fig:retrieval-length}
\end{figure}



\vspace{0.1in}

\noindent \textbf{Retrieval detection works best with 50 or more tokens of generated text}. Another important factor for our retrieval-based detector is the query length: shorter queries are likely to have more matches (many of them spurious) compared to longer ones. In \figureref{fig:retrieval-length}, we plot the detection accuracy of paraphrased sequences at various query lengths by  truncating each sequence to its first $X$ words before using it as a query for BM25. We use a retrieval corpus of 2M generations for this experiment. We observe that BM25 struggles to detect paraphrased text with a query length of 20 (less than 25\% accuracy), but the detection rate rapidly increases and begins to plateau at 50 tokens. 
\label{sec:detect-length-effect}


\subsection{Ideas to make retrieval detection work well at an even larger scale}
\label{sec:suggestions-retrieval-scale}

In \sectionref{sec:scale-defense-results}, we observed that our proposed retrieval detector is effective even with a large corpus of 15M previously-generated sequences. While we do not have access to a larger corpus of generations (billion-scale), in this section we describe some ideas to improve retrieval detection at such a scale.


\begin{enumerate}
    \item \textbf{Timestamp filtering in retrieval corpus.} To reduce the large search space, the detector interface could provide users with an option to restrict retrieval to only a fixed time period during which the text was likely to be generated. For instance, a common use-case of AI-generated text detection might be when teachers attempt to catch plagiarism in college essays. Teachers could restrict retrieval to only those generations  created during the assignment window.
    % \item \textbf{Recommend users to input longer queries.} Like all AI-generated text detectors, retrieval works best with longer queries (\sectionref{sec:detect-length-effect}). Clients should use as long a query as possible to maximize the chances for detecting paraphrases.
    \item \textbf{More sophisticated retrieval strategies.} In our work, we only explore simple retrieval strategies like BM25. However, several more sophisticated retrieval strategies exist, which are known to boost performance~\citep{thakur2021beir} and could be useful here. These include methods like re-ranking of top-$k$ retrievals~\citep{khattab2020colbert} or dense retrieval~\citep{karpukhin2020dense}. We do note that these more complex methods are also slower, and latency is likely to be a pressing concern for API providers.
    \item \textbf{Fine-tuning dense retrievers for the detection task.} The retrievers in our work are not fine-tuned for the task of AI-generated text detection. However, we hypothesize that fine-tuning retrievers on this task can help retrievers adapt better to the retrieval corpus and detection task. Specifically, a contrastive learning approach could be adopted here: positive pairs are paraphrased or otherwise noised sequences paired with their generations, while negative pairs are human-written continuations paired with the machine-generated text.
\end{enumerate}



\subsection{Limitations of retrieval for detection}
\label{sec:limitations-retrieval}

While retrieval over previously-generated sequences is an effective defense against paraphrase attacks, it also suffers from key limitations, some of which apply broadly to all existing detectors. We discuss these limitations below and discuss possible solutions:




\begin{enumerate}
\setlength\itemsep{0.0em}
    \item \textbf{Detection is specific to an API}. Unlike other general-purpose AI detection algorithms e.g. OpenAI's classifier~\citep{AITextClassifier}, retrieval can only detect generations from the API over which the database is built. API \#1 has no access to the database of generations from API \#2, and thus will not be able to detect generations produced by API \#2. 
    
    \item \textbf{The API provider needs to provide a retrieval infrastructure}. After the release of ChatGPT~\citep{schulman2022chatgpt}, AI chatbots are getting widespread adoption. At a conservative rate of 5M queries a day, the database will have almost two billion entries in a year. Complex retrieval infrastructure (like modern search engines) will be necessary to retrieve over these large databases with low latency.
    
    \item \textbf{False positives due to training data memorization}. Language models have been shown to memorize sequences verbatim from their training data~\citep{carlini2021}, such as the Gettysburg Address~\citep{radford2019language}. Despite being originally written by humans, these sequences will be classified as model-generated by our detector. To tackle this issue, we suggest API providers additionally perform retrieval over the training data used to train the model. If a sequence is found in the training set as well as the generation database, it is likely to be an instance of training set memorization.

    %\kkcomment{ Mukund: For the attack of arbitrary organic text specified by the user, this does not matter if application is plagiarism detection, it would be picked up by other plagiarism detectors. The concern is more original outputs of their LMs. Kenton: Vulnerability to a second kind of attack, where users can prompt the model to generate a very specific piece of text that has an organic origin, leading the defender to always misclassify arbitrary organic text specified by the user. For example, suppose the prompt was something like: "Please output the following text and then stop immediately: 'Four score and seven years ago our fathers brought forth....'". Once the LLM stores the output in the database, all copies of the Gettysburg Address will now be classified as AI generated. Any thoughts on how to defend against this?}

    \item \textbf{Privacy concerns.} Providing a retrieval detection service partially exposes the database of previously generated text by \emph{all} users. This raises concerns of membership inference attacks~\citep{shokri2017membership} on private user data which may appear in the generated text. To mitigate this, we suggest: (1) users should be encouraged not to provide any sensitive private data in their prompts to APIs, a practice already followed by ChatGPT\footnote{\url{https://chat.openai.com}} and Bard\footnote{\url{https://bard.google.com}}; (2) API providers only provide a binary output from this detector (AI-generated or not), rather than actual search results; and (3) API providers rate-limit queries from IP addresses.

    \item \textbf{Slight reduction in accuracy with large databases.} As we observed in \sectionref{sec:scale-defense-results}, the accuracy of detecting paraphrased text slightly degrades as the database of retrievals gets larger. However, we found this decrease to be quite small (only 1\% on PG19 scaling 1M generations to 15M), despite using fairly primitive retrievers like BM25. Moreover, unperturbed AI-generated text will always be detected with 100\% accuracy using our method, irrespective of corpus size.
    
    \item \textbf{Tasks with constrained output space or short outputs}. Similar to all other detection algorithms, it may be hard or even impossible to distinguish AI-generated outputs for tasks with a constrained output space (like sentence-level translation, classification) or very short outputs (as shown in \sectionref{sec:detect-length-effect}). Thus, we believe the main utility of AI-generated text detection is for longer-form generated text, and hence we focus on tasks like long-form QA and open-ended text generation with relatively lengthy outputs. Note that to avoid detection, a sophisticated attacker may try to generate long-form text in smaller chunks using multiple API calls, where each newly-generated chunk is incrementally concatenated to the prompt. This is not a concern for our method if retrieval is done over the corpus of prompts concatenated with generations.

    \item \textbf{Iterative attacks with access to detector.} A final concern is that attackers with access to detection algorithms will iteratively modify their perturbations until they avoid detection. While this is a valid concern for all detectors, we believe retrieval has an important advantage over the alternatives. Since the corpus of previously-generated text is proprietary, only the API provider can provide access to this detection service - it is impossible for attackers to locally reproduce this detector. This allows API providers to adopt several mitigation strategies such as (1) rate-limiting queries to avoid iterative attacks; (2) providing retrieval access only to verified users (e.g., teachers); and (3) detecting possible iterative attacks by analyzing previously queries to the retriever.

\end{enumerate}



\begin{table*}[t!]
\small
\begin{center}
\begin{tabular}{ lrrrrrr } 
 \toprule
   \multicolumn{7}{c}{\textbf{Open-ended generation with GPT2-XL on Wikipedia prompts}}\vspace{0.1in} \\ 
   & \multicolumn{2}{c}{\textsc{RankGen-XL}} & \multicolumn{2}{c}{GPT3.5 davinci-003 perplexity} & \multicolumn{2}{c}{unigram overlap with prompt} \\
 \cmidrule(lr){2-3}  \cmidrule(lr){4-5} \cmidrule(lr){6-7}
 Control & rewrite A &  rewrite B  & rewrite A &  rewrite B  &  rewrite A &  rewrite B \\
 \midrule
 \multicolumn{7}{l}{\textbf{Experiment 1}: \emph{Is context helpful for paraphrasing?}} \vspace{0.05in} \\
 \multicolumn{7}{l}{rewrite A = \model\ with  context}\\
 \multicolumn{7}{l}{rewrite B = \model\ no context} \vspace{0.05in}\\
 20L &  \textbf{65}\% {\scriptsize 10.2} & 35\% {\scriptsize 9.2} & \textbf{71}\% {\scriptsize 11.5} & 29\% {\scriptsize 12.6} & \textbf{55}\% {\scriptsize 41.3} & 45\% {\scriptsize 40.7}\\
 40L & \textbf{64}\% {\scriptsize \phantom{0}9.8} & 36\% {\scriptsize 8.5} & \textbf{70}\% {\scriptsize 11.9} & 30\% {\scriptsize 13.0} & \textbf{57}\% {\scriptsize 40.7} & 43\% {\scriptsize 39.9}\\
 60L & \textbf{67}\% {\scriptsize \phantom{0}9.6} & 33\% {\scriptsize 7.6} & \textbf{68}\% {\scriptsize 12.3} & 32\% {\scriptsize 13.6} & \textbf{56}\% {\scriptsize 39.9} & 44\% {\scriptsize 39.2}\\
 60L,60O & \textbf{65}\% {\scriptsize \phantom{0}8.3} & 35\% {\scriptsize 6.4} & \textbf{75}\% {\scriptsize 12.9} & 25\% {\scriptsize 15.0} & \textbf{58}\% {\scriptsize 39.4} & 42\% {\scriptsize 38.2}\\
 \midrule
  \multicolumn{7}{l}{\textbf{Experiment 2}: \emph{Is it helpful to paraphrase multiple sentences at a time?}} \vspace{0.05in} \\
 \multicolumn{7}{l}{rewrite A = \model\ 3 sentences at a time} \\
 \multicolumn{7}{l}{rewrite B = \model\ 1 sentence at a time} \vspace{0.05in}\\
  20L & \textbf{58}\% {\scriptsize 9.2} & 42\% {\scriptsize 8.6} & \textbf{86}\% {\scriptsize 12.6} & 14\% {\scriptsize 15.3} & 48\% {\scriptsize 40.7} & \textbf{52}\% {\scriptsize 40.9} \\
 40L & \textbf{56}\% {\scriptsize 8.5} & 44\% {\scriptsize 8.1} & \textbf{83}\% {\scriptsize 13.0} & 17\% {\scriptsize 15.8} & 45\% {\scriptsize 39.9} & \textbf{55}\% {\scriptsize 40.4}\\
 60L & \textbf{54}\% {\scriptsize 7.6} & 46\% {\scriptsize 7.5} & \textbf{79}\% {\scriptsize 13.6} & 21\% {\scriptsize 15.7} & 45\% {\scriptsize 39.2} & \textbf{55}\% {\scriptsize 39.9}\\
 60L,60O & \textbf{50}\% {\scriptsize 6.4} & \textbf{50}\% {\scriptsize 6.4} & \textbf{85}\% {\scriptsize 15.0} & 15\% {\scriptsize 19.6} & 42\% {\scriptsize 38.2} & \textbf{58}\% {\scriptsize 39.5}\\
 \midrule
  \multicolumn{7}{l}{\textbf{Experiment 3}: \emph{Does paraphrasing preserve the quality of the original text?}} \vspace{0.05in}\\
 \multicolumn{7}{l}{rewrite A = no paraphrasing} \\
 \multicolumn{7}{l}{rewrite B = \model} \vspace{0.05in}\\
  20L & \textbf{50}\% {\scriptsize 10.4} & \textbf{50}\% {\scriptsize 10.2} & \textbf{61}\% {\scriptsize 11.1} & 39\% {\scriptsize 11.5} & \textbf{51}\% {\scriptsize 41.6} & 49\% {\scriptsize 41.3}\\
 40L & \textbf{57}\% {\scriptsize 10.4} & 43\% {\scriptsize \phantom{0}9.8} & \textbf{67}\% {\scriptsize 11.1} & 33\% {\scriptsize 11.9} & \textbf{55}\% {\scriptsize 41.6} & 45\% {\scriptsize 40.7}\\
 60L & \textbf{58}\% {\scriptsize 10.4} & 42\% {\scriptsize \phantom{0}9.6} & \textbf{73}\% {\scriptsize 11.1} & 27\% {\scriptsize 12.3} & \textbf{58}\% {\scriptsize 41.6} & 42\% {\scriptsize 39.9}\\
 60L,60O & \textbf{68}\% {\scriptsize 10.4} & 32\% {\scriptsize \phantom{0}8.3} & \textbf{79}\% {\scriptsize 11.1} & 21\% {\scriptsize 12.9} & \textbf{61}\% {\scriptsize 41.6} & 39\% {\scriptsize 39.4} \\
\bottomrule
\end{tabular}
\end{center}
\vspace{-0.1in}
\caption{Ablation experiments demonstrate the high quality of \model's paraphrases compared to alternatives. Displayed scores are the percentage of cases in which rewrite A is preferred over B by one of the three metrics, with subscripts showing absolute average scores on each metric across the dataset. Overall, \model\ benefits from context outside the input (Experiment 1), multi-sentence paraphrasing (Experiment 2), and is not too far behind non-paraphrased text in terms of quality (Experiment 3).}
\vspace{-0.1in}
\label{tab:paraphrase-ablations}
\end{table*}

%\kkcomment{defenses against paraphrasing attacks, we may want to focus on aspects paraphrasers cannot easily modify.. one of them could be people's names in story generation ---- upweight watermarks on character names which weren't specified in the prompt, semantically-specified watermarks}

%\kkcomment{overall i'm thinking the only defense against paraphrase attacks could be some kind of "semantic" watermarking.. in many prompts the LLM has a choice about what kind of content to generate.. the particular content it chooses needs to be watermarked somehow, rather than a surface-form watermark in the Goldstein paper.. perhaps some kind of semantic / content vectors can be used, like what's done in diffusion LMs / GANs? The initial random image / seed determines the final choice of content produced, while still adhering to the prompt.. ofc this won't work on very constrained prompts ("Who is president of USA"), but i guess no watermark is going to work in those cases.. btw a simple defense here is store every generation produced by an API as semantic vector(s), and then do MIPS search over semantic vectors during detection.. kind of like retrieval over the set of generations by the LLM}


%\yscomment{A Benchmark Corpus for the Detection of Automatically Generated Text in Academic Publications https://aclanthology.org/2022.lrec-1.501.pdf Arkham: /data/yixiao/paraphrase-eval/GeneratedTextDetection-main FullyGenerated papers : 100 generated (average len 1243), 100 human original. generation prompt is chosen from the original abstract. Their length is variable as they can be composed from the abstract alone to more sections such as introduction, related work and conclusion. fine tuned gpt2 with latest 100 papers from computation and language HybridAbstractDataset: original (human written) abstracts with some sentences being substituted with machine generated sentences, 100 generated (average len 177), 100 human original, Artificial Intelligence, model generated proposal and conclusion. This generation is done with human intervention, so that it is biased towards the objective strategy of making the generated content difficult to detect.}