


\section{Introduction}
Deformable objects are omnipresent in our world, and grasping them is critical for food handling \cite{Gemici2014IROS}, robotic surgery \cite{Smolen2009ICACHI}, and domestic tasks \cite{Sanchez2018IJRR, Zhu2022RAM}. However, their physical complexities pose challenges for key aspects of grasp planning, including modeling, simulation, learning, and optimization. Deformable objects have infinite degrees of freedom and require continuum mechanics models to accurately predict their responses to body forces (e.g., gravity) and surface tractions (e.g., contacts). For deformable solids, continuum models can predict two field quantities critical for robot grasping, \textit{stress} tensors and \textit{deformation} vectors defined at every point in the object~\cite{timoshenko2010}. In general, low-stress grasps are desirable to reduce material fatigue from repeated grasping, or to avoid exceeding the yield stress of the object, at which point permanent deformation or failure occurs. Predicting deformation is also critical, especially when grasping containers. One may want to minimize the deformation on a box of crackers to avoid crushing the contents, or maximize the deformation on a bottle of ketchup to efficiently squeeze out the contents. 

Although knowledge of stress and deformation fields is useful, deriving closed-form solutions is intractable for general cases. Moreover, direct real-world measurement is extremely difficult  without cumbersome instrumentation.  Consequently, robotic grasping has historically leveraged rigid-body models, for which deformation is ignored and object state can be simply described by 6D pose and velocity~\cite{Murray1994,mason2001mechanics}. 

\begin{figure}
\centering
\includegraphics[width=\columnwidth]{figs/front_fig_mustard_only.png}
\caption{\textbf{(A)} DefGraspNets predicts the stress and deformation fields from grasping an unseen object $1500$x faster than FEM, and \textbf{(B)} enables gradient-based grasp refinement to optimize these fields.}
\label{fig:front_fig}\vspace{-12pt}
\end{figure}

On the other hand, we can use deformable-object \textit{simulators} to access these quantities and plan grasps accordingly. However, such simulators rely on complex numerical models like the gold-standard 3D finite element method (FEM) \cite{YinScienceRobotics2021, Arriola2020FRAI}. Although FEM can simulate the result of any grasp on a deformable object \cite{Huang2022RAL}, each evaluation can take minutes on a CPU-based industry-standard simulator~\cite{Narang2021IJRR} and seconds on a GPU-based robotics simulator~\cite{Narang2021Latent}, which is prohibitively slow for online grasp planning. Moreover, while differentiable simulators enable gradient-based optimization for parameter estimation~\cite{Heiden2022AutoRob} and control optimization~\cite{Xu2022ICLR,Heiden2022AutoRob}, few studies have explored their application to robotic grasping, and they are typically slower than standard FEM.

We propose \emph{DefGraspNets}, a graph neural network that can enable grasp planning by predicting the stress and deformation fields resulting from grasps and allowing efficient optimization (Fig.~\ref{fig:front_fig}). We demonstrate that this network is 1) \textbf{fast}, with a ${\sim}1500$x speed-up compared to a GPU-based FEM simulator, 2) \textbf{accurate}, with stress and deformation fields consistent with ground-truth FEM, 3) \textbf{generalizable}, with reliable rankings of grasp candidates over unseen poses, elastic moduli, in-category objects, and out-of-category objects, and 4) \textbf{differentiable}, enabling gradient-based optimization for grasp refinement. Finally, we conduct pilot studies that verify agreement of DefGraspNets, trained purely in simulation, with real-world outcomes. Data and code can be found on our website\footnote{\url{https://sites.google.com/view/defgraspnets}}.



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "root"
%%% End:
