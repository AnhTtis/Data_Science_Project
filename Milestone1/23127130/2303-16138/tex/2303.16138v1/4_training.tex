\section{Data Generation and Model Training}\label{sec:training}
We now describe our simulation-based approach to training DefGraspNets.
We design a set of 60 object primitive models as a high-level abstraction of real-world geometries grouped into geometric categories (e.g., cuboids, cylinders, ellipsoids, annuli), and instances within each category have different dimensions and aspect ratios. Our dataset also includes a set of 11 of fruits and vegetables (e.g., apples, eggplants, potatoes) based on 3D scans \cite{ybjDataset}. Tetrahedral volume meshes are generated for each deformable object using fTetWild~\cite{ftw}. Triangular surface meshes are generated for the gripper fingers using Onshape.

For each pre-contacted object mesh $M_o$, 100 grasps are generated using an antipodal sampler~\cite{EppnerISRR2019} wherein randomly-sampled surface points define gripper contact points, surface normals define grasp axes, and 4 rotations are regularly drawn about each grasp axis. These 100 grasps correspond to 100 gripper meshes $M_g$. Each grasp is evaluated using the DefGraspSim\cite{Huang2022RAL} simulation framework (built upon Isaac Gym\cite{makoviychuk2021isaac} and the FleX FEM solver\cite{macklin2019non}) with the Franka parallel-jaw gripper. DefGraspSim evaluates the stress and deformation fields of the deformable object during grasping. 

Given an object-grasp pair $(M_o, M_g)$ in DefGraspSim, the gripper applies a linearly increasing amount of force on the object until $F_g^{max} = 15$\units{N} is reached in a zero-gravity environment.\footnote{For the elastic moduli examined ($1e^4 \leq E \leq 1e^7$~\units{Pa}), $15$\units{N} was observed to induce substantial stress and deformation; gravity was ignored due to having negligible effect on stress and deformation compared to contact forces.} This  force was achieved by directly commanding DOF torque applied at the gripper joints. The values of the stress ($\vec{\sigma}$) and deformation fields ($\vec{d}$) at all object vertices are saved over 50 evenly-spaced substeps throughout the entire grasping trajectory. 
Formally, our dataset $D$ is composed of input-output pairs, each consisting of a candidate grasp pose $X_i$ and corresponding set of fields $Y_i$, that is, $D=\{X_i=(M_g, M_o, F_g), Y_i=(\vec{\sigma},\vec{d})\}_{i=1}^N$, where $0 \leq F_g \leq 15$. Dataset $D$ has $N = \#~objects \times 100 \times 50=3.55e5$ unique points. Because our network performs one-step predictions of the final state and is ideal for quasistatic interactions, all unstable grasps involving chaotic dynamics are not included in $D$. 


The values of the stress field $\vec{\sigma}$ at all object vertices are computed as follows: first, the second-order stress tensor at each tetrahedral element of $M_o$ is acquired from DefGraspSim. The stress tensors at each vertex are calculated by averaging the stress tensors at all adjacent elements. Each stress tensor is then converted to the scalar von Mises stress (i.e., the second invariant of the deviatoric stress), which is widely used to quantify whether a material has yielded \cite{timoshenko2010}. The values of the deformation field $\vec{d}$ are defined simply as the distance between the positions of the pre-contacted vertices of $M_o$ and their positions under gripper force $F_g$. 

Contact edges $E^C$ are formed based on the threshold $\epsilon = 5$mm. Our networks are trained with a decaying learning rate from $5e^{-5}$ to $1e^{-6}$ over 25 epochs and a batch size of $1$. A latent size of $128$ and $L=15$ message passing steps are used, where all MLPs have 2 hidden layers. Loss is defined as the sum of the MSE of stress and deformation over all nodes. On a single RTX 3090 GPU, the network trains at approximately 1600 steps per minute.  
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "root"
%%% End:
