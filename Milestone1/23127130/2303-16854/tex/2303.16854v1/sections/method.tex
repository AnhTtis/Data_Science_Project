\section{Approach}
Providing detailed instructions to annotators is crucial when using crowdsourcing to annotate data, as it can help crowd workers better understand task requirements and annotation standards, ultimately  improving the quality and accuracy of annotated data. 
The instructions for each task mainly includes three parts: task description, category definition, and demonstrated examples. 

Motivated by the guidance to human annotators, we will introduce how to convert GPT-3.5 into a zero-shot data annotator by providing guidance on the task description and category definitions in Section \ref{approach.zero}. Then, we will show how to transform GPT-3.5 into a few-shot data annotator with the demonstrated examples in Section \ref{approach.few}. 
% use the two-step method, `explain-then-annotate', to . 
We show the crowdsourcing annotation and our proposed `explain-then-annotate' processes in Figure \ref{fig.annotation}.

\subsection{GPT-3.5 as a Zero-shot Data Annotator}\label{approach.zero}
In the zero-shot setting, we can only provide the task description and category definitions to annotators. The task description includes information on task definition, task purpose, and so on. Category definitions require clear definitions for each category, so that the crowd workers can understand the meaning and standard of each category.

In the same vein, we furnish GPT-3.5 with the task description and category definitions, which enable GPT-3.5 to function as a zero-shot data annotator. We show the zero-shot prompts for GPT-3.5 on the user query and keyword relevance assessment, WiC and BoolQ tasks in Tables \ref{tab.qk.zero-shot}, \ref{tab.wic.zero-shot} and \ref{tab.boolq.zero-shot}, respectively. 


\begin{table*}[t] 
  \centering
 \footnotesize
%   \scriptsize
  % \tiny
   \begin{tabular}{
    m{0.1\textwidth}<{\centering}|
    m{0.84\textwidth}
    }
    \toprule
    \textbf{Input}  & Directions: Given a search engine query: "\textbf{google data studio sharepoint}", first, consider what the user could have in mind when they type in the query and allow for misspellings or other ambiguity, then classify the relevance of keyword: "\textbf{sharepoint migration tool file share}" to the query into one of the following categories: "Not bad", "Bad". The definitions of the categories are\newline
"Not bad": the keyword is relevant to the user's search query. This can include: broader or narrower product selection, competitor or alternative products, accessories, products often purchased together and related topics as well as direct matches to the user's search.\newline
"Bad": the keyword is not relevant to the user's search query. There is no relationship between the query and keyword. This includes but is not limited to: incorrect/unrelated product, unrelated topic, wrong location when location is important, cannot be used in place of query product nor are they commonly purchased together, etc.\newline
Briefly explain why the relevance is "\textbf{Bad}", with a response length not exceeding 100 words.   \\
    \midrule
    \textbf{Output 1}  & The relevance of the keyword "sharepoint migration tool file share" to the search query "google data studio sharepoint" is "Bad". This keyword is not relevant to the user's search query as it pertains to a different tool or technology (SharePoint) that is not mentioned in the search query. The keyword focuses on a migration tool for SharePoint file sharing, while the search query is focused on Google Data Studio. There is no relationship between the two, so the keyword is not relevant to the user's search query.\\
    \midrule
    \textbf{Output 2}  & The relevance of "sharepoint migration tool file share" to the search query "google data studio sharepoint" is "Bad." The keyword is not relevant to the user's search query because it deals with SharePoint migration and file sharing, whereas the user's query is focused on Google Data Studio and SharePoint. There is no relationship between these two topics, and the keyword cannot be used in place of the query product.\\
    \midrule
    \textbf{Output 3}  & The relevance is "Bad". The keyword "sharepoint migration tool file share" is not directly related to the query "google data studio sharepoint". The keyword refers to tools and services for migrating data from SharePoint to another file share platform, whereas the query is about using Google Data Studio to connect with SharePoint data. There is no clear relationship between the two topics.\\
    \midrule
    \textbf{Output 4}  & The relevance of the keyword "sharepoint migration tool file share" to the search query "google data studio sharepoint" is "Bad". The keyword is about a tool for migrating data from SharePoint, which is not directly related to Google Data Studio. Google Data Studio is a data visualization and reporting tool, not a migration tool for SharePoint.\\
    \midrule
    \textbf{Output 5}  & The relevance is "Bad" as the keyword "sharepoint migration tool file share" has no direct relation to the user's search query "google data studio sharepoint". The keyword pertains to a tool used for migrating data within a SharePoint platform, while the query is focused on Google Data Studio and SharePoint. These two concepts are not directly related and therefore, the keyword is not relevant to the user's search query.\\
    \bottomrule
 \end{tabular}
 \caption
 { Illustration of how to use a LLM to generate explanations for the user query and keyword relevance assessment task. 
"Input" and "Output" refer to the prompt provided to the LLM and the generated explanations, respectively.}\label{tab.qk.explanation} 
\end{table*} 

\subsection{GPT-3.5 as a Few-shot Data Annotator}\label{approach.few}
When annotating data, providing annotation examples for each category to annotators can help crowd workers better understand how to annotate and classify the data accurately. Similarly, we also provide the demonstrated examples to GPT-3.5, thus changing it into a few-shot data annotator. 
We show the few-shot prompts for GPT-3.5 on the user query and keyword relevance assessment, WiC and BoolQ tasks in Tables \ref{tab.qk.few-shot}, \ref{tab.wic.few-shot} and \ref{tab.boolq.few-shot}, respectively. 

Recent work \cite{wei2022chain} has shown that adding human written rationales to the demonstrated examples, called as chain-of-thought (CoT), can elicit the LLMs' reasoning ability, thus gaining improvements on reasoning tasks. 
In this paper, we find that GPT-3.5 \footnote{We resort to ChatGPT, the latest version of GPT-3.5, to generate explanations.} is a good reasoner who can automatically generate reasonable explanations for demonstrated examples. In the following, we will introduce how to generate explanations with GPT-3.5, and then create few-shot CoT prompts with the generated explanations.



\paragraph{Generating Explanations with GPT-3.5.} 
In this step, we simulate the way humans explain problems to induce GPT-3.5 to explain the annotated examples. To be concrete, we present the task description, specific example, and the corresponding true labels to GPT-3.5, and then ask it to answer why the corresponding answer for that example is the given label. By doing so, GPT-3.5 will generate reasonable explanations. 
For the user query and keyword relevance assessment task, 
we show how to use GPT-3.5 to explain why the label between the user query ``\textbf{google data studio sharepoint}'' and the keyword ``\textbf{sharepoint migration tool file share}'' is ``\textbf{Bad}'' in Table \ref{tab.qk.explanation}. 
Please refer to Table \ref{tab.boolq.1} and Table \ref{tab.wic.1} for how to generate explanations for the demonstrated examples of BoolQ and WiC.
\paragraph{Creating Few-shot CoT Prompts.}
After getting the explanations generated by GPT-3.5, we can construct the few-shot CoT prompt. 
We show the few-shot CoT prompts for GPT-3.5 on the user query and keyword relevance assessment, WiC and BoolQ tasks in Tables \ref{tab.qk.few-shot-cot}, \ref{tab.wic.few-shot-cot} and \ref{tab.boolq.few-shot-cot}, respectively.