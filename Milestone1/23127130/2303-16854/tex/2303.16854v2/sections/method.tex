\section{Approach}
Providing detailed instructions is crucial for crowdsourced workers to annotate data, as it helps them better understand task requirements and annotation standards, ultimately improving the quality and accuracy of annotated data. 
The instructions for each task mainly include three parts: task description, category definition, and demonstrated examples. 

Motivated by the guidance to human annotators, we will introduce how to convert GPT-3.5 into a zero-shot data annotator by providing guidance on the task description and category definitions in Section \ref{approach.zero}. Then, we will show how to transform GPT-3.5 into a few-shot data annotator using demonstrated examples in Section \ref{approach.few}. 
% For the ease of understanding, we show the crowdsourcing annotation and our proposed \textit{explain-then-annotate} processes in Figure \ref{fig.annotation}.
To make it easier to understand, we have provided a visual representation of the crowdsourcing annotation and AnnoLLM in Figure \ref{fig.annotation}.
Finally, in Section \ref{approach.create}, we will demonstrate the utilization of AnnoLLM for constructing the conversation-based information retrieval dataset.


\subsection{GPT-3.5 as a Zero-shot Data Annotator}\label{approach.zero}
In the zero-shot setting, we give the annotators only the task description and category definitions. 
The task description includes information on the task definition and purpose. Category definitions provide clear definitions for each category, so that the crowd workers can understand the meaning and standard of each category. 
Similarly, we provide GPT-3.5 with the task description and category definitions, allowing it to act as a zero-shot data annotator. 
We present the zero-shot prompts for GPT-3.5 on the user query and keyword relevance assessment (QK), WiC, and BoolQ tasks in Tables \ref{tab.qk.zero-shot}, \ref{tab.wic.zero-shot}, and \ref{tab.boolq.zero-shot}, respectively. 







\subsection{GPT-3.5 as a Few-shot Data Annotator}\label{approach.few}
Providing labeled samples for each category can help annotators better understand how to annotate the data accurately. Similarly, we can also offer demonstrated examples to GPT-3.5, enabling it to serve as a few-shot annotator. 
We show the few-shot prompts for GPT-3.5 on QK, WiC, and BoolQ tasks in Tables \ref{tab.qk.few-shot}, \ref{tab.wic.few-shot}, and \ref{tab.boolq.few-shot}, respectively. 

Recent research \cite{wei2022chain} has discovered that adding human written rationales to demonstrated examples, called as chain-of-thought (CoT), can elicit LLMs' reasoning ability, thus gaining improvements on reasoning tasks. 
In this paper, we find that GPT-3.5\footnote{We resort to ChatGPT to generate explanations.} 
is proficient at generating reasonable explanations for demonstrated examples. 
% is a good reasoner who can automatically generate reasonable explanations for demonstrated examples. 
In the following, we will introduce how to generate explanations with GPT-3.5, and then create few-shot CoT prompts with the generated explanations.


\paragraph{Generating Explanations with GPT-3.5.} 
In this step, we simulate the human reasoning process to induce GPT-3.5 to explain the annotated examples. 
To be concrete, we present the task description, specific examplease, and the corresponding true labels to GPT-3.5, and then ask it to explain why the given label is appropriate for that example. By doing so, GPT-3.5 will generate reasonable explanations. 
For the QK task, we show how to use GPT-3.5 to explain why the label between the user query ``\textbf{google data studio sharepoint}'' and the keyword ``\textbf{sharepoint migration tool file share}'' is ``\textbf{Bad}'' in Table \ref{tab.qk.explanation} in Appendix \ref{sec.appendix.a}.  
Please refer to Table \ref{tab.wic.1} and Table \ref{tab.boolq.1} for how to generate explanations for the demonstrated examples of WiC and BoolQ.

\paragraph{Creating Few-shot CoT Prompts.}
We construct the few-shot CoT prompt using  the explanations generated by GPT-3.5. 
We show the few-shot CoT prompts on QK, WiC, and BoolQ tasks in Tables \ref{tab.qk.few-shot-cot}, \ref{tab.wic.few-shot-cot}, and \ref{tab.boolq.few-shot-cot} in Appendix \ref{sec.appendix.d}, respectively.

\subsection{GPT-3.5 as a Few-shot Data Creator}\label{approach.create}
AnnoLLM is not limited to labeling classification data. Next, we will introduce how we used AnnoLLM to construct the conversation-based information retrieval dataset. 
This dataset will facilitate the research and construction of conversation-based retrieval models.

Recently, ChatGPT, as a general artificial intelligence chatbot, has gained widespread attention, leading to the emergence of numerous information retrieval needs in the form of conversations. 
Specifically, during a conversation, users may ask questions that go beyond the knowledge scope of ChatGPT, requiring us to retrieve relevant literature from external knowledge bases. Traditional information retrieval datasets typically consist of queries $q$ and positive paragraphs $p$, denoted as $D = \{(q, p)\}$. 
We found that retrieval models trained on traditional datasets perform poorly on the conversation-based retrieval task (please refer to Section \ref{ConIR} for more details). 
This illustrates the necessity of constructing conversation-based retrieval datasets. 
Therefore, we propose to create a conversation-based information retrieval dataset. 

Conversation-based information retrieval aims to retrieve relevant passages from a large corpus for conversations. It is non-trivial to manually create datasets for this task. One intuitive idea is to use ChatGPT to generate a multi-turn conversation $c$ based on the query $q$ and the corresponding positive paragraph $p$, constructing a conversation dataset, $\{(c, p)\}$. 
However, we have found that this approach results in a dataset where a large portion of the conversation $c$ is directly copied from $p$. This is not desirable since it becomes easy to find $p$ related to $c$ based on word overlaps. 

To address this issue, we first utilize ChatGPT to enrich the given text paragraph $p$, obtaining $p^{\prime}$ (see Table \ref{tab.enrich_text.zero-shot}). Then, we generate the conversation $c$ based on the expanded paragraph $p^{\prime}$ and the given query $q$ (see Table \ref{tab.conversation_generation.zero-shot}). 
The expanded paragraph $p^{\prime}$ usually contains not only the information from the original paragraph $p$ but also some more detailed relevant information, while reducing the overlap of words with the original paragraph. 
In this way, the generated conversation $c$ can avoid having a large amount of identical text segments with the original paragraph $p$. However, since the expanded paragraph $p^{\prime}$ contains information beyond the original paragraph $p$, this may result in a relatively low relevance between the generated conversation $c$ and the original paragraph $p$. In other words, the original paragraph $p$ may not be a positive paragraph for the generated conversation $c$. 
Therefore, it is necessary to filter out the conversation instance $c$ that has low relevance to the original paragraph $p$. 
Due to the comparable data annotation capability of our proposed AnnoLLM, we naturally used AnnoLLM to judge whether the generated conversation $c$ and the original paragraph $p$ are related (see Table \ref{tab.data_filter.few-shot-cot}), and discarded data pairs that are irrelevant, resulting in the conversation-based information retrieval dataset.

