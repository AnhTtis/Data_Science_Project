\section{Limitations}
In this paper, we present the remarkable potential of AnnoLLM powered by GPT-3.5 to supplant crowdsourced annotators. Nevertheless, it is essential to acknowledge that our assessment of the proposed method's effectiveness is constrained by limited computational resources, restricting our investigation solely to GPT-3.5 series models.
To gain further insights, future endeavors should encompass supplementary experiments involving diverse language models, including PaLM and LLaMA. These additional investigations will undoubtedly enrich the understanding of the subject and expand the horizons of our research.


% There are two possible limitations of this work. 
% Firstly, limited by sufficient computational resources, we only verify the effectiveness of our proposed method on GPT series models. 
% Further experiments with other language models, such as PaLM and LLaMA are left as future work. 
% The second limitation is that the retrieved evidence may not be relevant to the input claim, which cannot provide useful information for correcting the factual errors within the input claim. 
% Since our work mainly focuses on improving factual error correction through the introduction of the pivot task, we leave the improvement of evidence retrieval to future work. 
