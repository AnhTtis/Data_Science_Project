\appendix


% \section{Additional model validity checks}

% \subsection{Experiment construction}
% Let's say we want to construct $k$ communities where $f_i$ is the fraction of group $i$. Furthermore we want $p_{ij}$ to denote the average connection probability between two groups

% \section{Additional experiments}
% Issue alignment (some kind of interesting covariance structure)
% Ablation studies.
% --> Edge rewireing vs. edge addition

% --> Node removal

% Robustness checks: show that qualitative results hold over time

% \paragraph{Model Validity}
% \mc{We agree that external validity of our model is hard to establish. However our work combines two established models: Jackson Rogers for the underlying natural network growth and algorithmic growth via addition of recommended links. Prior simulation based evaluation uses similar ‘algorithmic growth’ with static underlying networks. We will add an internal validity section where we show that the quantitative insights are robust to simulation parameters. Further, we will detail how simulation parameters are instantiated in order to achieve a desired degree distribution and group level connections probabilities.}

% \mc{Argue the following: This model displays realistic behavior with respect to network evolution:\\
% --Densification\\
% -- Small diameter\\
% -- Use an example to argue that this model  can explain growth of citation networks. (can just point to Ali’s paper perhaps)
% }


% \mc{Finally argue that this model is flexible enough to create  any number of properties. Expected degree; between group heterogeneity; i.e. moment matching. Present data generation in appendix}

% \section{OLD STUFF}
% \subsubsection{Probability function} 
% We choose the probability of connection between any two node to be the following: $p = \frac{1}{1 + e^{<v_i, v_j>a + b}}$, where and $a, b$ are parameters that can be adjusted to strengthen or lessen the probability of connections as desired. This function allows for flexibility in that any edge can exist, but scales the probability in accordance with the similarity between any two nodes ie. we assume that nodes that are close in Euclidean distance are more likely to be connected.

% \subsubsection{Neighbor of neighbors algorithm}
% Rather than connecting to neighbors of neighbors based on vector properties, we instead connect to each neighbor of neighbor with uniform probability $q$. This way our neighbors of neighbors selection is an intrinsic property of the graph structure as opposed to our vector embeddings. We scale $q$ dynamically as the network grows to keep the number of accepted connections within a reasonable number.

% \subsubsection{Hazard function}
% Our experiments also utilize an exponential hazard function $f(A) = c d^A + k$, where $c, d$ are experimentally determined constants, to mimic the mortality rate among humans. This naturally expands the timescale of our experiments to include multiple generations which might be unreasonable. We would alternatively suggest analyzing "trending" and "dying" social media to achieve a more reasonable timescale.
% \subsubsection{Triadic closure} We utilize three related algorithms for triadic closure. We highlight the main one here:
% \begin{algorithm}
% \For{node in G}{
%     color $\gets$ node.color\;
%     set $\gets$ neighbors at distance two\;
%     sample $\gets$ uniformly sample set\;
%     \eIf{\upshape{color is sample color}}{add edge with prob $q$}{add edge with prob $p$}
% }
% \end{algorithm}
% Each node receives one recommendation, upon which it either accepts or rejects according to probability $p$ or $q$. 

% \subsubsection{Adamic-Adar}
\newpage
\section{Additional Experiments}

\subsection{Behavioral assumptions} \label{app:rewire_acc}
In this section we investigate two behavioral assumptions: edge rewiring and choice homophily. Under edge rewiring assumption upon accepting a recommended edge the node will remove at random one of it's existing edges. Under choice homophily nodes accept recommendations according to embedding similarity rather than with a constant probability, assumed in the main body of the paper. Figure \ref{fig:bevarior_variants} shows the trajectories of homophily, clustering and Gini coefficient under different behavioral assumption. In the case of edge-rewiring (Fig. \ref{fig:bevarior_variants_b}, \ref{fig:bevarior_variants_d}) the delayed impacts to Gini coefficient diminish. The behavioral assumption that nodes accept preferentially nodes with high embedding similarity unsurprisingly leads to further increases in observed homophily for both \latent{} and \fof{} recommenders (Fig \ref{fig:bevarior_variants_c}, \ref{fig:bevarior_variants_d}). 


\begin{figure}
    \centering
    
    \begin{subfigure}[b]{0.85\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/delayed_effects.pdf}
    \caption{Edge addition + Constant recommendation acceptance probability (plot in Sec. \ref{subsec:delayed})}
    \label{fig:bevarior_variants_a}
    \end{subfigure}

    \begin{subfigure}[b]{0.85\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/delayed_effects_constant_False_True.pdf}
    \caption{Edge rewiring + Constant recommendation acceptance probability}
    \label{fig:bevarior_variants_b}
    \end{subfigure}

    \begin{subfigure}[b]{0.85\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/delayed_effects_embedding_False_False.pdf}
    \caption{Edge addition + Choice homophily}
    \label{fig:bevarior_variants_c}
    \end{subfigure}

        \begin{subfigure}[b]{0.85\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/delayed_effects_embedding_False_True.pdf}
    \caption{Edge rewiring + Choice homophily}
    \label{fig:bevarior_variants_d}
    \end{subfigure}
    
    \caption{Counterfactual trajectory of homophily, global clustering and Gini coefficient for \latent{} and \fof{} recommendations applied over varying intervention intervals. The solid black line represents the evolution of the metric under natural growth dynamics. The blue lines represent trajectories for the \latent{} recommender whereas the orange lines correspond to \fof.  The shaded area corresponds to the 95\% confidence intervals calculated over 5 independent trajectories. }
    \label{fig:bevarior_variants}
\end{figure}


\subsection{Intervention Variants} \label{app:rec_variants}
In Fig. \ref{fig:rec_variants_a} we consider different choices of temperature parameter $\beta$ for the \latent{} recommender. All recorded metrics increase as the recommendations become more deterministic (uncreasing $\beta$). Note that $\beta =4$ and $\beta=10$ are nearly indistinguishable in the homophily graph whereas $\beta=4$ and $\beta=2$ are close in the graph of the clustering coefficient. This suggests that different metrics have different sensitivities to changes in recommendation intervention.

In Fig. \ref{fig:rec_variants_b} we compare \fof{} with a neighborhood based recommendation algorithm that recommends node pairs with highers Adamic-Adar index. The Adamic-Adar index assigns a higher similarity score to pairs of low degree nodes that share many neighbors in common. This change leads to extreme increase in the clustering coefficient.
\begin{figure}
    \centering
    \begin{subfigure}[b]{0.9\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/delayed_effects_latent_beta.pdf}
    \caption{\latent{} recommender}
    \label{fig:rec_variants_a}
    \end{subfigure}

    \begin{subfigure}[b]{0.9\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/delayed_effects_adamic.pdf}
    \caption{\fof{} recommender}
    \label{fig:rec_variants_b}
    \end{subfigure}
    \caption{Counterfactual trajectories for variants of \latent{} and \fof{} recommenders}
    \label{fig:rec_variants}
\end{figure}


\subsection{Naive and Interference Adjusted estimates for A/B evaluation}\label{app:ab}
%\paragraph{Average degree.} A naive estimation of the average degree for treatment and control groups is simply the average degree of all the treatment nodes and all the control nodes, respectively. However, as the control group also receives algorithmic links from the treatment group, we adjust the estimate of the average degree of the control group by discounting the edges of the control group that are formed during the algorithmic intervention.
First we comment on the naive and adjuted estimation procedure for each metric.
\paragraph{Homophily.} Naively, we estimate homophily for an A/B evaluation by assigning one community as treatment and the other as control and measuring the homophily for each community. To adjust the estimate for the control group, we discount the algorithmic edges received by the control group, whereas to adjust for the treatment, we double the count of the algorithmic edges that the treatment group forms with the control group.
\paragraph{Clustering.} Naively, we estimate the group-level clustering coefficient for treatment and control by averaging node-level clustering for treatment and control groups respectively. We adjust the estimate for the treatment/control group by calculating its clustering coefficient only among the treatment/control neighbors, i.e., in a sub-network with only the treatment/control nodes.
\paragraph{Gini coefficient.} We naively estimate Gini coefficient by simply measuring the value within the treatment and control groups, respectively. We adjust Gini coefficient by discounting the algorithmic edges for the control group.

Fig. \ref{fig:ab_naive} shows the naive estimates derived from the A/B evaluation.

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.9\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/ab_conclusion_constant_False_False_embedding_False.pdf}
    \caption{\latent{} recommender}
    \end{subfigure}

    \begin{subfigure}[b]{0.9\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/ab_conclusion_constant_False_False_random_fof_False.pdf}
    \caption{\fof{} recommender}
    \end{subfigure}
    \caption{A/B Evaluations: Solid lines correspond to ground truth counterfactual evaluation of homophily, clustering and Gini coefficient. Dashed lines correspond to trajectories estimated \emph{naively} from running an A/B test.}
    \label{fig:ab_naive}
\end{figure}












% \section{Detailed Notes on Construction}
% \subsection{Homophily}
% Given a graph $G = (V, E)$. Assume there are $M$ groups; each with share $s_i: \ \sum_{i=1}^M = 1$. Let $p_{ij}$ be the probability that two randomly selected nodes from groups $i$ and $j$ respectively are connected. (Recall that in our model these probabilities for each pair of nodes can be slightly different since the probabilities depend on the inner product of the node embeddings).

% Homophily of a group is measured as:
% $$H_i = \frac{E_{ii}}{E_i} - s_i$$

% where $E_{ii}$ is the number of edges between nodes in the group $i$ and $E_i$ is the number of edges that have at least one node in $i$.

% Therefore homophily measures how much larger is the affinity of the group towards making connections within the group compared to the background rate $s_i$. Therefore if $H_i > 0$ the group displays homophily; meaning that it prefers connections within the group; if $H_i < 0$ then the group is heterophilic.

% Given group shares $s_i$ and edge probabilities $p_{ij}$ one can compute expected homophily values:

% First note the $\mathbb{E}[E_{ii}] = p_{ii}(s_i N)^2$ where $N$ is the total number of edges. Similarly $\mathbb{E}[E_i] = \sum_{j=1}^M p_{ij}(s_i N)(s_j N) $.

% Therefore homophily can be computed as:
% $H_i = \frac{p_{ii}s_i}{\sum_{j=1}^M p_{ij}s_j} - s_i$

% Just from this equation, we can tell that the group-wise probabilities $p_{ij}$ tell us more information than the homophily values (for instance we get the same H values if we scale the probabilities $p'_{ij} = cp_{ij}$).

% Now let's say we want to target some specific homophily values. How should we design the $p_{ij}$ values in order to achieve that? There are $M$ homophily values; but there are $\frac{M(M+1)}{2}$ $p_{ij}$ values; so the homophily values cannot uniquely determine the probabilities.

% Since there is more information in the $p_{ij}$ we should instead run the experiments with respect to these. We can add a measurement of the homophily of each group to the list of metrics. 

% \subsection{From $p_{ij}$ to vector embedding}

% Suppose we want to achieve some desired values for $p_{ij}$ and have to design distributions for the node embeddings. First, denote by $\mu_i$ the mean of the embeddings in the group $i$. Further recall from that:
% $$p_{ij} = \frac{1}{1+ \exp(a \langle \mu_i, \mu_j) + b}$$
% This can be rewritten as:
% $$\langle \mu_i, \mu_j \rangle = \frac{\log(\frac{1-p_{ij}}{p_{ij}})-b}{a}=: X_{ij}$$

% Now collect the columns $\mu_i \in \mathbb{R}^d$ into a matrix $\mathcal{M}\in \mathbb{R^{d\times M}}$ (recall $M$ is the number of groups).

% Therefore the goal is to find a matrix $\mathcal{M}$ such that $\mathcal{M}^T \mathcal{M} \approx X$.

% If you recall the basics of eigendecomposition from your linear algebra class you can argue that the best estimate for $\mathcal{M}$ is $U_d \sqrt{\Lambda_d}$. where $U$ and $\Lambda$ are the eigenvectors and the eigenvalues respectively of the eigendecomposition: $X = U \Lambda U^T$. (the underscore $d$ refers to the top eigenvectors and eigenvalues respectively.)