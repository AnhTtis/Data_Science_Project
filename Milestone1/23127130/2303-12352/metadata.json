{
    "arxiv_id": "2303.12352",
    "paper_title": "Training Multilayer Perceptrons by Sampling with Quantum Annealers",
    "authors": [
        "Frances Fengyi Yang",
        "Michele Sasdelli",
        "Tat-Jun Chin"
    ],
    "submission_date": "2023-03-22",
    "revised_dates": [
        "2023-03-23"
    ],
    "latest_version": 1,
    "categories": [
        "cs.LG",
        "quant-ph"
    ],
    "abstract": "A successful application of quantum annealing to machine learning is training restricted Boltzmann machines (RBM). However, many neural networks for vision applications are feedforward structures, such as multilayer perceptrons (MLP). Backpropagation is currently the most effective technique to train MLPs for supervised learning. This paper aims to be forward-looking by exploring the training of MLPs using quantum annealers. We exploit an equivalence between MLPs and energy-based models (EBM), which are a variation of RBMs with a maximum conditional likelihood objective. This leads to a strategy to train MLPs with quantum annealers as a sampling engine. We prove our setup for MLPs with sigmoid activation functions and one hidden layer, and demonstrated training of binary image classifiers on small subsets of the MNIST and Fashion-MNIST datasets using the D-Wave quantum annealer. Although problem sizes that are feasible on current annealers are limited, we obtained comprehensive results on feasible instances that validate our ideas. Our work establishes the potential of quantum computing for training MLPs.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.12352v1"
    ],
    "publication_venue": "22 pages, 15 figures"
}