\section{Introduction}
\label{sec:intro}

Skeletons represent human joints using 3D coordinate locations. 
%
Compared with RGB videos and depth data, skeletons are lightweight, \wh{privacy-preserving}, and compact to represent human motion. 
%
On account of being easier and more discriminative for analysis, skeletons have been widely used in action recognition task~\cite{zhang2020context,liu2020disentangling,zhang2020semantics,song2020stronger,peng2020learning,su2020predict}.

\input{fig/teaser}

Supervised skeleton-based action recognition methods~\cite{si2019attention,shi2019two,chen2021channel} \wh{have achieved impressive performance}.
%
However, \wh{their success highly depends} on \wh{a large amount of} labeled training data, which \wh{is} expensive to obtain. 
%
To get rid of the reliance on full supervision, self-supervised learning~\cite{zheng2018unsupervised,lin2020ms2l,su2020predict,thoker2021skeleton} has been introduced into skeleton-based action recognition. 
%
It adopts a two-stage paradigm, \wh{\textit{i.e.}} first \wh{applying} pretext tasks for unsupervised pretraining and then \wh{employing} downstream tasks for finetuning.

\wh{According to learning paradigms, all} methods can be classified into two categories: reconstruction-based~\cite{su2020predict,yang2021skeleton,kim2022global} and contrastive \wh{learning-based}.
%
Reconstruction-based methods \wh{capture} the \wh{spatial-temporal} correlation by predicting masked skeleton data. 
%
Zheng \wh{\textit{et al.}}~\cite{zheng2018unsupervised} first proposed \wh{reconstructing} masked skeletons for \wh{long-term} global motion dynamics.
%
 Besides, the contrastive learning-based methods have shown remarkable potential recently. These methods employ skeleton transformation to generate positive/negative samples.
%
Rao \wh{\textit{et al.}}~\cite{rao2021augmented} applied Shear and Crop as data augmentation.
%
Guo \wh{\textit{et al.}}~\cite{guo2021contrastive} further proposed to use more augmentations, \wh{\textit{i.e.}} rotation, masking\wh{,} and flippling, to improve the consistency of contrastive learning.

%
\wh{These} contrastive learning works treat different regions of the skeleton sequences \wh{uniformly}.
\wh{However, the motion regions contain richer action information and contribute more to action modeling.}
%
Therefore, it is sub-optimal to directly apply data transformations to all regions in the previous works, \wh{which may degrade the motion-correlated information too much}. 
For example, if the mask transformation is applied to the hand joints in the hand raising action, the motion information of the hand raising is \wh{totally} impaired.
%
It will give rise to the false positive problem, \textit{i.e.}, the semantic inconsistency due to the information loss between positive pairs.
Thus, \wh{it is necessary to adopt a distinguishable design} for motion and static regions in the data sequences.
%
% And the reconstruction task reconstructs random areas. 
% %
% But these regions may not be the region where the motion occurs. 
% %
% Therefore, it encodes a lot of motion-independent information in the model.
%
% Thus, a sequence of actions exists motion-correlated regions and static regions. It is not reasonable to treat these regions equally.

To tackle these problems, we propose a new actionlet-dependent contrastive learning method (ActCLR) by \wh{treating} motion and static regions \wh{differently}, as shown in Fig.~\ref{fig:teaser}.
An \textit{actionlet}~\cite{wang2012mining} is \wh{defined as} a conjunctive structure of skeleton joints. \wh{It is expected to be highly representative of one action and highly discriminative to distinguish the action from others.}
%
\wh{The actionlet in previous works is defined in a supervised way, which relies on action labels and has a gap with the self-supervised pretext tasks.}
%
\wh{To this end, in the unsupervised learning context, we propose to obtain actionlet by comparing the action sequence with the average motion to guide contrastive learning. In detail,} the average motion is \wh{defined as} the average of all the series in the dataset.
%
Therefore, this average motion is employed as the static anchor without motion. 
We contrast the action sequence with the average motion to get the area with the largest difference. 
This region is considered \wh{to be} the region where the motion \wh{takes place}, \textit{i.e.}, actionlet.


Based on this actionlet, we design \wh{a} motion-adaptive transformation strategy. 
The actionlet region is transformed by performing the proposed semantically \wh{preserving} data transformation.
%
\wh{Specifically,} we \wh{only} apply \wh{stronger data} transformations to non-actionlet \wh{regions}. \wh{With less interference in the motion regions, this} motion-adaptive transformation strategy makes \wh{the model learn} better semantic consistency and obtain stronger generalization performance.
%
\wh{Similarly,} we utilize a semantic-aware feature pooling method\wh{.} By extracting the features in the actionlet region, \wh{the features can be more representative of the motion without the interference of the semantics in static regions.}
%
% Finally, we utilize a regularization constraint based on entropy minimization for training. The entropy of the feature space is reduced during the optimization process to obtain a more \wh{definitive} output.


%
We provide thorough experiments and detailed analysis on NTU RGB+D~\cite{shahroudy2016ntu,liu2019ntu} and PKUMMD~\cite{liu2020pku} datasets to prove the superiority of our method. 
%
Compared to the state-of-the-art methods, our model achieves remarkable results with self-supervised learning.


In summary, our contributions \wh{are summarized as follows}:
\begin{itemize}%[leftmargin=*]
\setlength\itemsep{.3em}
\item We propose a novel unsupervised actionlet-based contrastive learning method. Unsupervised actionlets are mined as skeletal regions that are the most discriminative compared with the static anchor, \textit{i.e.}, the average motion of \wh{all} training data.
%
\item A motion-adaptive transformation strategy is designed for contrastive learning. In the actionlet region, we employ semantics-preserving data transformations to learn semantic consistency. And in non-actionlet regions, we apply \wh{stronger} data transformations to obtain stronger generalization performance.
%
\item We utilize \wh{semantic-aware} feature pooling to extract motion features of the actionlet regions. It makes features to be more focused on motion \wh{joints} without being distracted by motionless joints.
\end{itemize}