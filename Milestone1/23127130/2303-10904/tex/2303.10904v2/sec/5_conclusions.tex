\section{Conclusions}
% \lorem{3}
In this work, we propose a novel actionlet-dependent contrastive learning method. Using actionlets, we design motion-adaptive data transformation and semantic-aware feature pooling to decouple action and non-action regions. These modules make the motion information of the sequence to be attended to while reducing the interference of static regions in feature extraction. In addition, the similarity mining loss further regularizes the feature space. Experimental results show that our method can achieve remarkable performance and verify the effectiveness of our designs.