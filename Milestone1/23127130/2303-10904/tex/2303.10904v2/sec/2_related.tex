\section{Related Work}
In this section, we first introduce the related work of skeleton-based action recognition, and then briefly review contrastive learning.

\subsection{Skeleton-Based Action Recognition}
Skeleton-based action recognition is a fundamental yet challenging field in computer vision research. Previous skeleton-based motion recognition methods are usually realized with the geometric relationship of skeleton joints~\cite{vemulapalli2014human,vemulapalli2016rolling,goutsu2015motion}. The latest methods pay more attention to deep networks. Du \etal~\cite{du2015hierarchical} applied a hierarchical RNN to process body keypoints. 
% To learn the mappings between co-occurrence of joints and the human action, \wh{in} \cite{zhu2015co}, a model utilizing co-occurring joints \wh{is designed} as a strong discriminative feature and using a connection matrix. 
Attention-based methods are proposed to automatically select important skeleton joints~\cite{song2017end,zhang2018adding,song2018spatio,si2019attention} and video frames~\cite{song2017end,song2018spatio} to learn more adaptively about the simultaneous appearance of skeleton joints. However, recurrent neural networks often suffer from gradient vanishing~\cite{hochreiter2001gradient}, which may cause optimization problems. Recently, graph convolution networks attract more attention for skeleton-based action recognition. To extract both the spatial and temporal structural features from skeleton data, Yan \etal~\cite{yan2018spatial} proposed spatial-temporal graph convolution networks. To make the graphic representation more flexible, the attention mechanisms are applied in~\cite{si2019attention,shi2019two,chen2021channel} to adaptively capture discriminative features based on spatial composition and temporal dynamics.



% These supervised models have achieved excellent performance on skeleton-based action recognition. However, they rely heavily on massive data with annotated action labels. To relieve the data limitation, self-supervised methods are developed, which only require a significant number of unlabeled samples. Our work is also inspired to apply self-supervised learning for action recognition.

\subsection{Contrastive Learning}
\label{sec:contra}
Contrastive representation learning can date back to \cite{hadsell2006dimensionality}. The following approaches~\cite{tian2019contrastive,wu2018unsupervised,bachman2019learning,ye2019unsupervised,isola2015learning} learn representations by contrasting positive pairs against negative pairs to make the representations between positive pairs more similar than those between negative pairs. Researchers mainly focus on how to construct pairs to learn robust representations. SimCLR proposed by Chen \etal~\cite{chen2020simple} uses a series of data augmentation methods, such as random cropping, Gaussian blur and color distortion to generate positive samples. He \etal~\cite{he2020momentum} applied a memory module that adopts a queue to store negative samples, and the queue is constantly updated with training. In self-supervised skeleton-based action recognition, contrastive learning has also attracted the attention of numerous researchers. Rao \etal~\cite{rao2021augmented} applied MoCo for contrastive learning with a single stream. To utilize cross-stream knowledge, Li \etal~\cite{li20213d} proposed a multi-view contrastive learning method and Thoker \etal~\cite{thoker2021skeleton} employed multiple models to learn from different skeleton representations. Guo \etal~\cite{guo2021contrastive} proposed to use more extreme augmentations, which greatly improve the effect of contrastive learning. Su \etal~\cite{su2021self} proposed novel representation learning by perceiving motion consistency and continuity. 
Following MoCo v2~\cite{he2020momentum}, they exploit InfoNCE loss to optimize contrastive learning:
\begin{equation}
\label{equ:info}
\begin{aligned}
\mathcal{L}_{\text{CL}} = - \log \frac{\exp(\text{sim}(\mathbf{z}^i_q, \mathbf{z}^i_k) / \tau)}{\exp(\text{sim}(\mathbf{z}^i_q, \mathbf{z}^i_k)/ \tau) + K},
\end{aligned}
\end{equation}
where $\mathbf{z}^i_q = g_q(f_q(\mathbf{X}^i_q))$ and $\mathbf{z}^i_k = g_k(f_k(\mathbf{X}^i_k))$. $K = \sum_{j=1}^M \exp(\text{sim}(\mathbf{z}^i_q, \mathbf{m}^j)/ \tau)$ and $\tau$ is a temperature hyper-parameter. $f_q(\cdot)$ is an online encoder and $f_k(\cdot)$ is an offline encoder. $g_q(\cdot)$ is an online projector and $g_k(\cdot)$ is an offline projector. The offline encoder $f_k(\cdot)$ is updated by the momentum of the online encoder $f_q(\cdot)$ by $f_k \leftarrow \alpha f_k + (1 - \alpha) f_q$, where $\alpha$ is a momentum coefficient. $\mathbf{m}^j$ is the negative sample, stored in memory bank $\mathbf{M}$. $\text{sim}(\cdot,\cdot)$ is the cosine similarity.