@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}

@InProceedings{Chung16,
  author       = {Joon Son Chung and
               Andrew Zisserman},
  pages     = {87--103},
  title        = "Lip Reading in the Wild",
  booktitle    = "Asian Conference on Computer Vision",
  year         = "2016",
}

@article{afouras2018deep,
  title={Deep audio-visual speech recognition},
  author={Triantafyllos Afouras and
               Joon Son Chung and
               Andrew W. Senior and
               Oriol Vinyals and
               Andrew Zisserman},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  pages     = {8717--8727},
  year={2018}
}

@InProceedings{Nagrani17,
	author       = {Arsha Nagrani and
               Joon Son Chung and
               Andrew Zisserman},
	title        = "VoxCeleb: a large-scale speaker identification dataset",
	booktitle    = "Annual Conference of the International Speech Communication Association",
        pages     = {2616--2620},
	year         = "2017",
}

@InProceedings{Afouras18d,
  author       = {Triantafyllos Afouras and
               Joon Son Chung and
               Andrew Zisserman},
  title        = "LRS3-TED: a large-scale dataset for visual speech recognition",
  booktitle    = "arXiv preprint arXiv:1809.00496",
  year         = "2018",
}

@InProceedings{Chung18b,
  author       = {Joon Son Chung and
               Arsha Nagrani and
               Andrew Zisserman},
  title        = "VoxCeleb2: Deep Speaker Recognition",
  booktitle    = "Annual Conference of the International Speech Communication Association",
  pages     = {1086--1090},
  year         = "2018",
}

@InProceedings{shillingford2018large,
  title={Large-scale visual speech recognition},
  author={Brendan Shillingford and
               Yannis M. Assael and
               Matthew W. Hoffman and
               Thomas Paine and
               C{\'{\i}}an Hughes and
               Utsav Prabhu and
               Hank Liao and
               Hasim Sak and
               Kanishka Rao and
               Lorrayne Bennett and
               Marie Mulville and
               Misha Denil and
               Ben Coppin and
               Ben Laurie and
               Andrew W. Senior and
               Nando de Freitas},
  booktitle    = "Annual Conference of the International Speech Communication Association",
  pages     = {4135--4139},
  year      = {2019}
}

@inproceedings{yang2019lrw,
  title={LRW-1000: A naturally-distributed large-scale benchmark for lip reading in the wild},
  author={Yang, Shuang and Zhang, Yuanhang and Feng, Dalu and Yang, Mingmin and Wang, Chenhao and Xiao, Jingyun and Long, Keyu and Shan, Shiguang and Chen, Xilin},
  booktitle={IEEE International Conference on Automatic Face \& Gesture Recognition},
  pages={1--8},
  year={2019}
}

@inproceedings{rossler2019faceforensics++,
  title={Faceforensics++: Learning to detect manipulated facial images},
  author={Rossler, Andreas and Cozzolino, Davide and Verdoliva, Luisa and Riess, Christian and Thies, Justus and Nie{\ss}ner, Matthias},
  booktitle={IEEE/CVF International Conference on Computer Vision},
  pages={1--11},
  year={2019}
}

@inproceedings{wang2020mead,
  title={Mead: A large-scale audio-visual dataset for emotional talking-face generation},
  author={Wang, Kaisiyuan and Wu, Qianyi and Song, Linsen and Yang, Zhuoqian and Wu, Wayne and Qian, Chen and He, Ran and Qiao, Yu and Loy, Chen Change},
  booktitle={European Conference on Computer Vision},
  pages={700--717},
  year={2020},
  organization={Springer}
}

@inproceedings{zhang2021flow,
  title={Flow-guided one-shot talking face generation with a high-resolution audio-visual dataset},
  author={Zhang, Zhimeng and Li, Lincheng and Ding, Yu and Fan, Changjie},
  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3661--3670},
  year={2021}
}

@article{liu2021geometry,
  title={Geometry-guided dense perspective network for speech-driven facial animation},
  author={Liu, Jingying and Hui, Binyuan and Li, Kun and Liu, Yunke and Lai, Yu-Kun and Zhang, Yuxiang and Liu, Yebin and Yang, Jingyu},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  pages     = {4873--4886},
  year={2022},
  publisher={IEEE}
}

@inproceedings{cudeiro2019capture,
  title={Capture, learning, and synthesis of 3D speaking styles},
  author={Cudeiro, Daniel and Bolkart, Timo and Laidlaw, Cassidy and Ranjan, Anurag and Black, Michael J},
  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10101--10111},
  year={2019}
}

@inproceedings{richard2021meshtalk,
  title={MeshTalk: 3D face animation from speech using cross-modality disentanglement},
  author={Richard, Alexander and Zollh{\"o}fer, Michael and Wen, Yandong and De la Torre, Fernando and Sheikh, Yaser},
  booktitle={IEEE/CVF International Conference on Computer Vision},
  pages={1173--1182},
  year={2021}
}

@article{fanelli20103,
  title={A 3-D audio-visual corpus of affective communication},
  author={Fanelli, Gabriele and Gall, Juergen and Romsdorfer, Harald and Weise, Thibaut and Van Gool, Luc},
  journal={IEEE Transactions on Multimedia},
  volume={12},
  pages={591--598},
  year={2010}
}

@inproceedings{fan2022faceformer,
  title={FaceFormer: Speech-Driven 3D Facial Animation with Transformers},
  author={Fan, Yingruo and Lin, Zhaojiang and Saito, Jun and Wang, Wenping and Komura, Taku},
  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18770--18780},
  year={2022}
}


@inproceedings{liu2021beat,
  title={BEAT: A Large-Scale Semantic and Emotional Multi-Modal Dataset for Conversational Gestures Synthesis},
  author={Liu, Haiyang and Zhu, Zihao and Iwamoto, Naoya and Peng, Yichen and Li, Zhengqing and Zhou, You and Bozkurt, Elif and Zheng, Bo},
  booktitle={European Conference on Computer Vision},
  pages={612--630},
  year={2022}
}
    
@inproceedings{deng2019accurate,
    title={Accurate 3D Face Reconstruction with Weakly-Supervised Learning: From Single Image to Image Set},
    author={Yu Deng and Jiaolong Yang and Sicheng Xu and Dong Chen and Yunde Jia and Xin Tong},
    booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
    pages     = {285--295},
    year={2019}
}

@inproceedings{blanz1999morphable,
  title={A morphable model for the synthesis of 3D faces},
  author={Blanz, Volker and Vetter, Thomas},
  booktitle={Annual Conference on Computer Graphics and Interactive Techniques},
  pages={187--194},
  year={1999}
}

@article{li2017learning,
  title={Learning a model of facial shape and expression from 4D scans.},
  author={Tianye Li and
               Timo Bolkart and
               Michael J. Black and
               Hao Li and
               Javier Romero},
  journal={ACM Transactions on Graphics},
  volume={36},
  pages={194:1--194:17},
  year={2017}
}

@article{ekman1992argument,
  title={An argument for basic emotions},
  author={Ekman, Paul},
  journal={Cognition \& emotion},
  volume={6},
  number={3-4},
  pages={169--200},
  year={1992}
}

@article{tomar2006converting,
  title={Converting video formats with FFmpeg},
  author={Tomar, Suramya},
  journal={Linux Journal},
  volume={2006},
  number={146},
  pages={10},
  year={2006}
}


@inproceedings{wu2006real,
  title={Real-time synthesis of Chinese visual speech and facial expressions using MPEG-4 FAP features in a three-dimensional avatar.},
  author={Wu, Zhiyong and Zhang, Shen and Cai, Lianhong and Meng, Helen M},
  booktitle={Annual Conference of the International Speech Communication Association},
  pages={1802--1805},
  year={2006}
}

@article{iso2004information,
  title={Information technology—coding of audio-visual objects—part 2: visual},
  author={ISO/IEC 14496-2},
  year={2004}
}

@article{edwards2016jali,
  title={Jali: an animator-centric viseme model for expressive lip synchronization},
  author={Edwards, Pif and Landreth, Chris and Fiume, Eugene and Singh, Karan},
  journal={ACM Transactions on Graphics},
  volume={35},
  pages={1--11},
  year={2016}
}

@inproceedings{taylor2012dynamic,
  title={Dynamic units of visual speech},
  author={Taylor, Sarah L and Mahler, Moshe and Theobald, Barry-John and Matthews, Iain},
  booktitle={ACM SIGGRAPH/Eurographics conference on Computer Animation},
  pages={275--284},
  year={2012}
}

@inproceedings{chen2018lip,
  title={Lip movements generation at a glance},
  author={Chen, Lele and Li, Zhiheng and Maddox, Ross K and Duan, Zhiyao and Xu, Chenliang},
  booktitle={European Conference on Computer Vision},
  pages={520--535},
  year={2018},
  organization={Springer}
}

@inproceedings{das2020speech,
  title={Speech-driven facial animation using cascaded gans for learning of motion and texture},
  author={Das, Dipanjan and Biswas, Sandika and Sinha, Sanjana and Bhowmick, Brojeshwar},
  booktitle={European Conference on Computer Vision},
  pages={408--424},
  year={2020}
}

@inproceedings{fan2015photo,
  title={Photo-real talking head with deep bidirectional LSTM},
  author={Fan, Bo and Wang, Lijuan and Soong, Frank K and Xie, Lei},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={4884--4888},
  year={2015}
}

@inproceedings{ji2021audio,
  title={Audio-driven emotional video portraits},
  author={Ji, Xinya and Zhou, Hang and Wang, Kaisiyuan and Wu, Wayne and Loy, Chen Change and Cao, Xun and Xu, Feng},
  booktitle={IEEE/CVF conference on Computer Vision and Pattern Recognition},
  pages={14080--14089},
  year={2021}
}

@inproceedings{prajwal2020lip,
  title={A lip sync expert is all you need for speech to lip generation in the wild},
  author={Prajwal, KR and Mukhopadhyay, Rudrabha and Namboodiri, Vinay P and Jawahar, CV},
  booktitle={ACM International Conference on Multimedia},
  pages={484--492},
  year={2020}
}

@article{vougioukas2020realistic,
  title={Realistic speech-driven facial animation with gans},
  author={Vougioukas, Konstantinos and Petridis, Stavros and Pantic, Maja},
  journal={International Journal of Computer Vision},
  volume={128},
  number={5},
  pages={1398--1413},
  year={2020}
}

@inproceedings{zhou2019talking,
  title={Talking face generation by adversarially disentangled audio-visual representation},
  author={Zhou, Hang and Liu, Yu and Liu, Ziwei and Luo, Ping and Wang, Xiaogang},
  booktitle={AAAI Conference on Artificial Intelligence},
  pages={9299--9306},
  year={2019}
}

@inproceedings{10.1145/3528233.3530745,
author = {Ji, Xinya and Zhou, Hang and Wang, Kaisiyuan and Wu, Qianyi and Wu, Wayne and Xu, Feng and Cao, Xun},
title = {EAMM: One-Shot Emotional Talking Face via Audio-Based Emotion-Aware Motion Model},
year = {2022},
isbn = {9781450393379},
url = {https://doi.org/10.1145/3528233.3530745},
doi = {10.1145/3528233.3530745},
booktitle = {ACM SIGGRAPH Conference}
}

@article{sinha2022emotion,
  title={Emotion-Controllable Generalized Talking Face Generation},
  author={Sinha, Sanjana and Biswas, Sandika and Yadav, Ravindra and Bhowmick, Brojeshwar},
  journal={arXiv preprint arXiv:2205.01155},
  year={2022}
}

@inproceedings{wu2021imitating,
  title={Imitating arbitrary talking style for realistic audio-driven talking face synthesis},
  author={Wu, Haozhe and Jia, Jia and Wang, Haoyu and Dou, Yishun and Duan, Chao and Deng, Qingshan},
  booktitle={ACM International Conference on Multimedia},
  pages={1478--1486},
  year={2021}
}

@inproceedings{guo2021ad,
  title={Ad-nerf: Audio driven neural radiance fields for talking head synthesis},
  author={Guo, Yudong and Chen, Keyu and Liang, Sen and Liu, Yong-Jin and Bao, Hujun and Zhang, Juyong},
  booktitle={IEEE/CVF International Conference on Computer Vision},
  pages={5784--5794},
  year={2021}
}

@inproceedings{lahiri2021lipsync3d,
  title={Lipsync3d: Data-efficient learning of personalized 3d talking faces from video using pose and lighting normalization},
  author={Lahiri, Avisek and Kwatra, Vivek and Frueh, Christian and Lewis, John and Bregler, Chris},
  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2755--2764},
  year={2021}
}

@article{yao2022dfa,
  title={DFA-NeRF: Personalized Talking Head Generation via Disentangled Face Attributes Neural Rendering},
  author={Yao, Shunyu and Zhong, RuiZhe and Yan, Yichao and Zhai, Guangtao and Yang, Xiaokang},
  journal={arXiv preprint arXiv:2201.00791},
  year={2022}
}

@article{karras2017audio,
  title={Audio-driven facial animation by joint end-to-end learning of pose and emotion},
  author={Karras, Tero and Aila, Timo and Laine, Samuli and Herva, Antti and Lehtinen, Jaakko},
  journal={ACM Transactions on Graphics},
  volume={36},
  pages={1--12},
  year={2017}
}

@article{liu2015video,
  title={Video-audio driven real-time facial animation},
  author={Liu, Yilong and Xu, Feng and Chai, Jinxiang and Tong, Xin and Wang, Lijuan and Huo, Qiang},
  journal={ACM Transactions on Graphics},
  volume={34},
  pages={1--10},
  year={2015}
}

@article{taylor2017deep,
  title={A deep learning approach for generalized speech animation},
  author={Taylor, Sarah and Kim, Taehwan and Yue, Yisong and Mahler, Moshe and Krahe, James and Rodriguez, Anastasio Garcia and Hodgins, Jessica and Matthews, Iain},
  journal={ACM Transactions on Graphics},
  volume={36},
  pages={1--11},
  year={2017}
}

@article{mildenhall2021nerf,
  title={Nerf: Representing scenes as neural radiance fields for view synthesis},
  author={Mildenhall, Ben and Srinivasan, Pratul P and Tancik, Matthew and Barron, Jonathan T and Ramamoorthi, Ravi and Ng, Ren},
  journal={Communications of the ACM},
  volume={65},
  pages={99--106},
  year={2021}
}

@article{cao2013facewarehouse,
  title={FacewareHouse: A 3D facial expression database for visual computing},
  author={Cao, Chen and Weng, Yanlin and Zhou, Shun and Tong, Yiying and Zhou, Kun},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  volume={20},
  pages={413--425},
  year={2013}
}

@inproceedings{savran2008bosphorus,
  title={Bosphorus database for 3D face analysis},
  author={Savran, Arman and Aly{\"u}z, Ne{\c{s}}e and Dibeklio{\u{g}}lu, Hamdi and {\c{C}}eliktutan, Oya and G{\"o}kberk, Berk and Sankur, B{\"u}lent and Akarun, Lale},
  booktitle={European Workshop on Biometrics and Identity Management},
  pages={47--56},
  year={2008}
}

@inproceedings{yin20063d,
  title={A 3D facial expression database for facial behavior research},
  author={Yin, Lijun and Wei, Xiaozhou and Sun, Yi and Wang, Jun and Rosato, Matthew J},
  booktitle={International Conference on Automatic Face and Gesture Recognition},
  pages={211--216},
  year={2006}
}

@inproceedings{yang2020facescape,
  title={Facescape: a large-scale high quality 3d face dataset and detailed riggable 3d face prediction},
  author={Yang, Haotian and Zhu, Hao and Wang, Yanru and Huang, Mingkai and Shen, Qiu and Yang, Ruigang and Cao, Xun},
  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={601--610},
  year={2020}
}

@inproceedings{gerig2018morphable,
  title={Morphable face models-an open framework},
  author={Gerig, Thomas and Morel-Forster, Andreas and Blumer, Clemens and Egger, Bernhard and Luthi, Marcel and Sch{\"o}nborn, Sandro and Vetter, Thomas},
  booktitle={International Conference on Automatic Face and Gesture Recognition},
  pages={75--82},
  year={2018}
}

@article{zhang2014bp4d,
  title={Bp4d-spontaneous: a high-resolution spontaneous 3d dynamic facial expression database},
  author={Zhang, Xing and Yin, Lijun and Cohn, Jeffrey F and Canavan, Shaun and Reale, Michael and Horowitz, Andy and Liu, Peng and Girard, Jeffrey M},
  journal={Image and Vision Computing},
  volume={32},
  pages={692--706},
  year={2014}
}

@inproceedings{alashkar20143d,
  title={A 3D dynamic database for unconstrained face recognition},
  author={Alashkar, Taleb and Amor, Boulbaba Ben and Daoudi, Mohamed and Berretti, Stefano},
  booktitle={International Conference and Exhibition on 3D Body Scanning Technologies},
  year={2014}
}

@inproceedings{cosker2011facs,
  title={A FACS valid 3D dynamic action unit database with applications to 3D dynamic morphable facial modeling},
  author={Cosker, Darren and Krumhuber, Eva and Hilton, Adrian},
  booktitle={IEEE/CVF International Conference on Computer Vision},
  pages={2296--2303},
  year={2011}
}

@inproceedings{zhang2013high,
  title={A high-resolution spontaneous 3d dynamic facial expression database},
  author={Zhang, Xing and Yin, Lijun and Cohn, Jeffrey F and Canavan, Shaun and Reale, Michael and Horowitz, Andy and Liu, Peng},
  booktitle={IEEE International Conference and Workshops on Automatic Face and Gesture Recognition},
  pages={1--6},
  year={2013}
}

@inproceedings{zhang2016multimodal,
  title={Multimodal spontaneous emotion corpus for human behavior analysis},
  author={Zhang, Zheng and Girard, Jeff M and Wu, Yue and Zhang, Xing and Liu, Peng and Ciftci, Umur and Canavan, Shaun and Reale, Michael and Horowitz, Andy and Yang, Huiyuan and others},
  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3438--3446},
  year={2016}
}

@article{grishchenko2020attention,
  title={Attention mesh: High-fidelity face mesh prediction in real-time},
  author={Grishchenko, Ivan and Ablavatski, Artsiom and Kartynnik, Yury and Raveendran, Karthik and Grundmann, Matthias},
  journal={arXiv preprint arXiv:2006.10962},
  year={2020}
}

@inproceedings{rusinkiewicz2001efficient,
  title={Efficient variants of the ICP algorithm},
  author={Rusinkiewicz, Szymon and Levoy, Marc},
  booktitle={International Conference on 3-D Digital Imaging and Modeling},
  pages={145--152},
  year={2001}
}

@inproceedings{paysan20093d,
  title={A 3D face model for pose and illumination invariant face recognition},
  author={Paysan, Pascal and Knothe, Reinhard and Amberg, Brian and Romdhani, Sami and Vetter, Thomas},
  booktitle={International Conference on Advanced Video and Signal Based Surveillance},
  pages={296--301},
  year={2009}
}

@article{guo2018cnn,
  title={Cnn-based real-time dense face reconstruction with inverse-rendered photo-realistic face images},
  author={Guo, Yudong and Cai, Jianfei and Jiang, Boyi and Zheng, Jianmin and others},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={41},
  pages={1294--1307},
  year={2018}
}

@article{Laine2020diffrast,
  title   = {Modular Primitives for High-Performance Differentiable Rendering},
  author  = {Samuli Laine and Janne Hellsten and Tero Karras and Yeongho Seol and Jaakko Lehtinen and Timo Aila},
  journal = {ACM Transactions on Graphics},
  year    = {2020},
  pages     = {194:1--194:14},
  volume  = {39},
}

@article{ganan1985bayesian,
  title={Bayesian image analysis: An application to single photon emission tomography},
  author={Ganan, Stuart and McClure, D},
  journal={Amer. Statist. Assoc},
  pages={12--18},
  year={1985}
}

@inproceedings{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  booktitle = {International Conference on Learning Representations},
  year={2015}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{xing2023codetalker,
  title={Codetalker: Speech-driven 3d facial animation with discrete motion prior},
  author={Xing, Jinbo and Xia, Menghan and Zhang, Yuechen and Cun, Xiaodong and Wang, Jue and Wong, Tien-Tsin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12780--12790},
  year={2023}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@inproceedings{wu2023speech,
  title={Speech-Driven 3D Face Animation with Composite and Regional Facial Movements},
  author={Wu, Haozhe and Zhou, Songtao and Jia, Jia and Xing, Junliang and Wen, Qi and Wen, Xiang},
  booktitle={ACM International Conference on Multimedia},
  pages={6822--6830},
  year={2023}
}

@article{van2008visualizing,
  title={Visualizing data using t-SNE.},
  author={Van der Maaten, Laurens and Hinton, Geoffrey},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={86},
  pages   = {2579--2605},
  year={2008}
}

@inproceedings{peng2023emotalk,
  title={EmoTalk: Speech-driven emotional disentanglement for 3D face animation},
  author={Peng, Ziqiao and Wu, Haoyu and Song, Zhenbo and Xu, Hao and Zhu, Xiangyu and He, Jun and Liu, Hongyan and Fan, Zhaoxin},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={20687--20697},
  year={2023}
}

@inproceedings{huang2017arbitrary,
  title={Arbitrary style transfer in real-time with adaptive instance normalization},
  author={Huang, Xun and Belongie, Serge},
  booktitle={IEEE/CVF International Conference on Computer Vision},
  pages={1501--1510},
  year={2017}
}

@article{hsu2021hubert,
  title={Hubert: Self-supervised speech representation learning by masked prediction of hidden units},
  author={Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={29},
  pages={3451--3460},
  year={2021}
}

@article{tibshirani1996regression,
  title={Regression shrinkage and selection via the lasso},
  author={Tibshirani, Robert},
  journal={Journal of the Royal Statistical Society: Series B (Methodological)},
  volume={58},
  number={1},
  pages={267--288},
  year={1996},
  publisher={Wiley Online Library}
}

@inproceedings{baevski2020wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  booktitle    = {Advances in Neural Information Processing Systems},
  pages={12449--12460},
  year={2020}
}

@inproceedings{amodei2016deep,
  title={Deep speech 2: End-to-end speech recognition in english and mandarin},
  author={Amodei, Dario and Ananthanarayanan, Sundaram and Anubhai, Rishita and Bai, Jingliang and Battenberg, Eric and Case, Carl and Casper, Jared and Catanzaro, Bryan and Cheng, Qiang and Chen, Guoliang and others},
  booktitle={International Conference on Machine Learning},
  pages={173--182},
  year={2016}
}

@article{ye2022audio,
  title={Audio-driven talking face video generation with dynamic convolution kernels},
  author={Ye, Zipeng and Xia, Mengfei and Yi, Ran and Zhang, Juyong and Lai, Yu-Kun and Huang, Xuwei and Zhang, Guoxin and Liu, Yong-jin},
  journal={IEEE Transactions on Multimedia},
  year={2022},
  publisher={IEEE}
}

@article{wang2022anyonenet,
  title={AnyoneNet: Synchronized Speech and Talking Head Generation for Arbitrary Persons},
  author={Wang, Xinsheng and Xie, Qicong and Zhu, Jihua and Xie, Lei and Scharenborg, Odette},
  journal={IEEE Transactions on Multimedia},
  year={2022},
  publisher={IEEE}
}

@article{eskimez2021speech,
  title={Speech driven talking face generation from a single image and an emotion condition},
  author={Eskimez, Sefik Emre and Zhang, You and Duan, Zhiyao},
  journal={IEEE Transactions on Multimedia},
  volume={24},
  pages={3480--3490},
  year={2021},
  publisher={IEEE}
}

@article{yu2021multimodal,
  title={Multimodal learning for temporally coherent talking face generation with articulator synergy},
  author={Yu, Lingyun and Xie, Hongtao and Zhang, Yongdong},
  journal={IEEE Transactions on Multimedia},
  volume={24},
  pages={2950--2962},
  year={2021},
  publisher={IEEE}
}