\section{Experiments}

\subsection{Experiment Setups}

% \noindent\textbf{Datasets.}\quad We evaluate our method on three widely-used datasets: ShanghaiTech Part A\&B~\cite{zhang2016single} and UCF-QNRF~\cite{idrees2018composition}. ShanghaiTech Part A contains 482 images (300/182 for training/validation). ShanghaiTech Part B contains 716 images (316/400 for training/validation). UCF-QNRF includes 1535 high resolution images (1201/334 for training/validation).
\noindent\textbf{Datasets.}\quad We evaluate our method on three widely-used datasets: ShanghaiTech Part A\&B~\cite{zhang2016single} and UCF-QNRF~\cite{idrees2018composition}. ShanghaiTech Part A\&B contains 482 images (300/182 for training/validation) and 716 images (316/400 for training/validation), respectively. UCF-QNRF includes 1535 high-resolution images (1201/334 for training/validation).
% \shan{do you follow other papers to set the training and testing, if so. cite them to support your splitting} 
This setting covers from sparse scenes to dense scenes and from small dataset to large dataset.

\noindent \textbf{Evaluation metrics.}\quad As \methodname has two predicted density maps, we use their averaged density map as the final result for evaluation.
Mean Absolute Error (MAE) and Mean Squared Error (MSE) are adopted for evaluation. 
% evaluate the counting accuracy in terms of , which are both commonly-used metrics in the crowd counting community.

\begin{table}[h]
\centering
\vspace{-10pt}
\caption{Comparisons with the state-of-the-arts methods on SHA, SHB, and QNRF.
% \blue{todo: SHB need higher accuracy}
}
\scalebox{0.75}{
    \begin{tabular}{rccc}
    \shline
    \multirow{2}{*}{\textbf{Methods}} & \textbf{SHA} & \textbf{SHB} & \textbf{QNRF} \\
    & MAE / MSE & MAE / MSE & MAE / MSE \\
    \hline
    % MCNN~\cite{zhang2016single} & 110.2 / 173.2 & 26.4 / 41.3 & 277.0 / 426.0 \\
    CSRNet~\cite{li2018csrnet}  & 68.2 / 115.0 & 10.6 / 16.0 & - / - \\
    SANet~\cite{cao2018scale}  & 67.0 / 104.5 & 8.4 / 13.6 & - / - \\
    TEDnet~\cite{jiang2019crowd} & 64.2 / 109.1 & 8.2 / 12.8 & 113.0 / 188.0 \\
    BL~\cite{ma2019bayesian}      & 62.8 / 101.8 & 7.7 / 12.7  & 88.7 / 154.8 \\
    DM-Count~\cite{wang2020distribution} & 59.7 / \underline{95.7} & 7.4 / 11.8 & 85.6 / 148.3\\
    MCC~\cite{zand2022multiscale} & 71.4 / 110.4 & 9.6 / 15.0 & - / - \\
    NoisyCC~\cite{wan2020modeling}     & 61.9 / 99.6  & 7.4 / \underline{11.3}  & 85.8 / 150.6\\
    % LCM~\cite{liu2020adaptive} & 61.6 / 98.4 & 7.0 / 11.0 & 86.6 / 152.2 \\  
    GL~\cite{wan2021generalized}  & 61.3 / \textbf{95.4} & 7.3 / 11.7 & 84.3 / 147.5 \\
    LibraNet~\cite{liu2020weighing}        & \textbf{55.9} / 97.1  & \underline{7.3} / \textbf{11.3}	& 88.1 / \textbf{143.7} \\
    % P2PNet~\cite{song2021rethinking}        & \textbf{52.7} / \textbf{85.1} & \textbf{6.3} / \textbf{9.9} & 85.3 / 154.5 \\
    GauNet(CSRNet)~\cite{cheng2022rethinking}  & 61.2 / 97.8 & 7.6 / 12.7	& \underline{84.2} / 152.4 \\
    \textbf{\methodname~(ours)}     & \underline{59.2} / 97.8  & \textbf{7.1} / 12.1  & \textbf{83.4} / \underline{144.9}  \\
    \shline
    \end{tabular}
    }
\label{tab:comparison}
\end{table}

\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{fig/visualization_finalfinal.pdf}
    \vspace{-20pt}
    \caption{Visualization on SHA. The first row are the input images. The second and third rows are the predicted density maps by BL~\cite{ma2019bayesian} and \methodname, respectively. Red boxes highlight the differences between them.
    % \shan{update method name}
    }
    \label{fig:visualization}
\end{figure*}

\noindent \textbf{Implementation details.}\quad
We adopt the same data preprocessing in~\cite{ma2019bayesian}. Ground truth density maps are generated using a fixed Gaussian kernel of size 15.
Random scaling, cropping, and horizontal flipping are employed as data augmentation with an image size of $512 \times 512$.
% we adopt random scaling and horizontal flipping as data augmentation. Then we randomly crop image patches with a size of $512 \times 512$ for training. 
Adam optimizer~\cite{kingma2014adam} was used with an initial learning rate of $4.0\times 10^{-5}$ and weight decay of $1.0\times10^{-5}$. We use the cosine learning rate scheduler with a maximum epoch of 1,000. 
% Batch size is set to 8.
% \shan{this is the parameter in cosine learning?}.
For hyperparameters of cross-head supervision, 
% we set $\delta_\mathrm{max}=0.05$ for SHB and QNRF dataset; $\delta_\mathrm{max}=0.1$ for SHA dataset. 
$\delta_\mathrm{max}$ is set to $0.1$ for SHA and $0.05$ for others.
$\alpha_\mathrm{max}$ is set to $0.5$ for QNRF and $1.0$ for others.

\subsection{Comparison with State-of-the-art Methods}
We compare our method with several recent state-of-the-art methods in Table~\ref{tab:comparison}. \methodname consistently achieves the superior counting performance on all benchmark datasets. For SHA and SHB, our method achieves 59.2 and 7.1 in terms of MAE. For QNRF, \methodname improves MAE value of the second best GauNet~\cite{cheng2022rethinking} from 84.2 to 83.4.

% As shown in Table~\ref{tab:comparison}, \methodname achieves competitive performance with others and best counting accuracy on QNRF dataset. QNRF is a large crowd-counting dataset with more dense scenes, on which the problem of missing annotations is more common and has a greater adverse effect on the model training. \methodname can provide proper supervision in the area of missing annotations. Therefore, our method can learn a better counting model on QNRF.
% We note that we adopt the same CSRNet as the backbone for fair comparisons.

The predicted density maps of \methodname are visualized in Fig.~\ref{fig:visualization}. As can be seen, \methodname can predict reliable density maps with high counting accuracy in a wide range of scenes and density levels.

% \blue{The results suggest that our method achieves competitive performance and best counting accuracy compared with \cite{liu2020weighing, song2021rethinking, cheng2022rethinking} on QNRF dataset.
% QNRF is a large crowd-counting dataset with more dense scenes, on which the problem of missing annotations is more common and has a greater adverse effect on the model training. Our CHS-Net can provide proper supervision in the area of missing annotations. Therefore, our method can learn a better counting model on QNRF dataset. We note that we adopt the same CSRNet as the backbone for fair comparisons.}


% \newcommand{\tabincell}[2]{
% \begin{tabular}{@{}#1@{}}#2\end{tabular}
% }
\begin{table}[t]
\centering
\vspace{-10pt}
\caption{Ablation study. `Average' represents using the average density map of two heads for evaluation.}
 \scalebox{0.8}{
		\begin{tabular}{cccrr}  
            \shline
			Model & Cross-head Supervision & Evaluation Head & MAE & MSE\\
			\hline
			Conv. & \xmark & Conv.  & 63.8 & 110.4 \\
			Tran. & \xmark & Tran.  & 62.5 & 104.1 \\
			\hline
			\methodname & \xmark   & Conv. & 61.8 & 107.0 \\ 
			\methodname & \xmark  & Tran. & 60.7 & 103.7 \\
			\methodname & \xmark  & Average & 60.7 & 104.8\\
			\hline
			\methodname & \cmark & Conv. & 59.8 & 100.4 \\ 
			\methodname & \cmark &  Tran. & 60.0 & \textbf{96.7} \\
			\methodname & \cmark &  Average & \textbf{59.2} & 97.8 \\
			\shline
		\end{tabular}
  }
  % \vspace{-15pt}
    \label{tab:ablation}
\end{table}


\subsection{Ablation Studies}

In this section, we perform ablation studies on SHA dataset to evaluate the effectiveness of the proposed \methodname.

\noindent\textbf{Ablation study on the models.}\quad
We first evaluate the model with two heads and cross-head supervision. We have the following observations from  Table~\ref{tab:ablation}:
%our method. As shown in , we first conduct independent experiment using only convolution head or transformer head, respectively.
1) The MAE of transformer head is lower than convolution one by 1.3, which demonstrates the superior global modeling ability of the transformer. 
% 2) With cross-head supervision, \methodname has achieved significant improvements. 
2) Although without cross-head supervision, \methodname has achieved significant improvements.
3) With the progressive cross-head supervision learning strategy, the best performance is achieved with MAE of 59.2. 
4) We evaluate the performance of every single head in \methodname. The average of two heads outperforms any single head in terms of MAE, which further illustrate the advantage of \methodname.

% \noindent\textbf{Single head validation.}\quad When \methodname achieves the best counting performance, we also evaluate the performance of each single head. As shown in Table~\ref{tab:ablation}, the averaged result of two heads is superior than the result of any single head in terms of MAE. This results further illustrate the advantage of \methodname. \shan{results do not match the analysis}
% \gao{lack of some discussions or analysis between the convolution head and the transformer head, like global or local contextual information and so on.}

% \begin{table}[t]
% \centering
% 	\caption{Ablation study on SHA.}
% 		\begin{tabular}{cccrr}
%             \shline
% 			\multicolumn{2}{c}{Head} & Cross-head & \multirow{2}{*}{MAE} & \multirow{2}{*}{MSE}\\
% 			conv. & tran. & Supervision &  &  \\
% 			\hline
% 			\checkmark & & & 63.8 & 110.4 \\
% 			& \checkmark & & 62.5 & 104.1 \\
% 			\checkmark & \checkmark & & 60.7 & 104.8 \\
% 			\checkmark & \checkmark & \checkmark & \textbf{59.2} & \textbf{97.8} \\
% 			\shline
% 		\end{tabular}
% 	\label{tab:ablation}
% \end{table}

% \begin{table}[t]
% \centering
% 	\caption{Ablation study on SHA.}
% 		\begin{tabular}{ccccrr}
%             \shline
% 			\multicolumn{2}{c}{Head} & Cross-head & \multirow{2}{*}{Fusion} & \multirow{2}{*}{MAE} & \multirow{2}{*}{MSE}\\
% 			conv. & tran. & Supervision &  &  &  \\
% 			\hline
% 			\checkmark & & & - & 63.8 & 110.4 \\
% 			& \checkmark & & - & 62.5 & 104.1 \\
% 			\hline
% 			\multirow{3}{*}{\checkmark} & \multirow{3}{*}{\checkmark} &  & conv. & 61.8 & 107.0 \\ 
% 			& & & tran. & 60.7 & 103.7 \\
% 			& & & avg & 60.7 & 104.8\\
% 			\hline
% 			\multirow{3}{*}{\checkmark} & \multirow{3}{*}{\checkmark} & \multirow{3}{*}{\checkmark} & conv. & 59.8 & 100.4 \\ 
% 			&  &  & tran. & 60.0 & \textbf{96.7} \\
% 			&  &  & avg & \textbf{59.2} & 97.8 \\
% 			\shline
% 		\end{tabular}
% 	\label{tab:ablation}
% \end{table}

% \begin{table}[t]
% \centering
%     \caption{Counting result for each single head.\shan{merged to Table 2? with a fusion column? (fusion, conv, head,)}}
% 	\begin{tabular}{crrr}
%         \shline
% 		Head & Conv. & Tran. & Average\\
% 		\hline
% 		MAE  & 59.8 & 60.0 & \textbf{59.2} \\
% 		MSE  & 100.4 & \textbf{96.7} & 97.8 \\
% 		\shline
% 	\end{tabular}
% 	\label{tab:head}
% \end{table}


\noindent\textbf{Ablation study of two heads on easy/hard samples.}\quad Our method is not only an ensemble model with different heads but also contains a self-supervision mechanism implicitly, in which the two heads provide pseudo-labels for each other in the mislabeled area.
Based on this idea, we would highlight that the convolution head and transformer head have different learning capabilities.
% Here, we split the hard/easy samples according to the ratio of average density, \emph{i.e.} $density\_area/num\_point$, following~\textcolor{red}{I do not know how to split easy/hard example, and how to compute $density\_area/num\_point$, please clarify}.
Here, we simply split the hard/easy samples according to the number of humans in an image, \emph{i.e.} the 50\% samples with the most humans are hard ones, and we showcase their performance to validate our idea in Table~\ref{tab:easy-hard}. 
% Easy sample and hard sample are split by $density\_area/num\_point$ on SHA training set, which indicates the degree of occlusion.
% Table~\ref{tab:easy-hard} shows the performance of SHA dataset on easy/hard samples.
It is found that the convolution head is better at learning easy samples and the transformer head plays the opposite role, respectively. Therefore, the different learning capabilities of these two heads are of great benefit for providing supervision in the mislabeled area for each other.
% }

\begin{table}[h]
    \centering
    \vspace{-10pt}
    \caption{Ablation study of two heads on easy/hard samples.}
    \scalebox{0.8}{
    \begin{tabular}{c|c|c}
    \shline
    MAE / MSE & Easy samples & Hard samples  \\
              \hline
    Conv-head & \textbf{55.7} / \textbf{70.5}  & 216.5 / 299.6 \\
    \hline
    Tran-head & 65.2 / 83.4  & \textbf{159.1} / \textbf{204.3}\\
    \shline
    \end{tabular}
    }
    \label{tab:easy-hard}
\end{table}

\noindent\textbf{Effect of maximum noise ratio.}\quad The maximum noise ratio $\delta_\mathrm{max}$ is an important hyperparameter for \methodname. In fact, the maximum noise ratio is a kind of prior knowledge of a specific dataset. We set several values of maximum noise ratio to investigate its effect on model performance. In Table~\ref{tab:noise}, the best performance is obtained when $\delta_\mathrm{max}=0.1$, which means there are nearly 10\% noisy annotations in SHA.

\begin{table}[h]
\centering
    \vspace{-10pt}
    \caption{Effect of maximum noise ratio $\delta_\mathrm{max}$.}
    \scalebox{0.8}{
	\begin{tabular}{crrrrrr}
        \shline
		$\delta_\mathrm{max}$ & 0 & 0.01 & 0.05 & 0.10 & 0.15  & 0.30 \\
		\hline
		MAE & 60.7 & 60.8 & 61.1 & \textbf{59.2} & 60.5 & 61.0 \\
		MSE & 104.8 & 105.7 & 99.8 & \textbf{97.8} & 102.4 & 105.4 \\
		\shline
	\end{tabular}
 }
	\label{tab:noise}
\end{table} 



