\section{Introduction}
% 背景介绍
Crowd counting is to count the people from a given image in diverse crowded scenes, which is an active computer vision task with a wide range of promising applications in crowd management, traffic monitoring, surveillance systems, etc. Existing methods can be roughly categorized into detection-based~\cite{rabaud2006counting}, count-based~\cite{chan2009bayesian} and density-map-based~\cite{zhang2016single,li2018csrnet, tian2019padnet, gao2023forget}. The detection-based methods~\cite{rabaud2006counting} require laborious annotations (\ie the bounding boxes) to directly detect all persons in an image while the count-based methods~\cite{chan2009bayesian} only predict the total number of people, suffering from weak supervision.

Unlike the two categories above, 
% predict the counts of an image, which 
% The earliest crowd counting methods adopt detection-based approach to detect all the heads or body parts in an image and then count them~\cite{rabaud2006counting}. Although being intuitive, these methods heavily rely on carefully-designed handcrafted features or well-developed detection algorithms for counting. Furthermore, labeling each person---a bounding box for each head---is laborious.
% Different from the detection-based crowd counting methods, the count-based methods~\cite{chan2009bayesian} only require the total number of people rather than the exact location of each head in an image.
% Therefore, count-based methods can significantly reduce the annotation cost. The crowd counting model is expected to learn a mapping function from the given image to the total number of people directly. Although significantly reduce annotation cost, count-based approaches still suffer from unsatisfied performance due to the weak supervision. 
% 基于密度图的方法，虽然权衡了精度和标注代价，但是需要精确的标注，这通常是不现实的由于标注过程中存在的噪声。图示噪声，
%Unlike the two categories above, 
density map-based approaches~\cite{zhang2016single,li2018csrnet} are proposed to estimate the human densities in images, which can balance the performance and annotation cost. Generating a density map only requires point annotations at the center of each head, whose cost is much less than the detection-based methods. 
In addition, density maps can provide more fine-grained pixel-level supervision compared to 
the count-based methods, which has significantly improved the performance.
% In this way, counting performance is greatly improved.
% Nevertheless, the point annotations lose the scale information of each head in contrast to bounding box annotations. Therefore, it is important to generate high quality density maps to provide scale supervision. On the other hand, 
However, density map-based methods require accurate point annotations to provide reliable pixel-level supervision, which is usually unrealistic because of the potential noises in the labeling process.
% However, the pixel-level loss function in density map-based methods is highly sensitive to noisy annotations.
Fig.~\ref{fig:noisy} shows that missing annotations and location shifts commonly exist among widely-used crowd counting datasets, especially in dense scenes and low-resolution conditions. 
Therefore, directly using the pixel-level loss function for optimization may compromise the prediction performance. Furthermore, the counting model may memorize the noisy annotations~\cite{liu2020early}.
% Therefore, strict pixel-level supervision and loss functions are not necessary and even may have a negative impact on training~(\eg, overfitting to the noise annotations).

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{fig/noisy_final.pdf}
    \vspace{-10pt}
    \caption{Noisy annotations in commonly-used datasets. Red points, green points, and yellow arrows denote labeled annotations, missing annotations, and location shifts, respectively.
    %Red points are ground truth annotations. Green points are missing annotations. Yellow arrows indicate location shifts.
    % \shan{colored text is typically not allowed...}
    }
    \label{fig:noisy}
\end{figure}

\begin{figure*}[t]
    \centering
    % \includegraphics[width=0.98\linewidth]{fig/binet-finalv8.pdf}
    \includegraphics[width=0.98\linewidth]{fig/binet-dot.pdf}
    \vspace{-10pt}
    \caption{Architecture of \methodname consisting of one shared encoder and two regression heads---one convolution head and one transformer head. At the end of each head, a regression block of the same architecture is attached to produce density map. Red box indicates the area of missing annotations, in which refined supervision is more reliable than ground truth supervision.}
    \label{fig:model}
\end{figure*}

% 现有解决方案
To address this problem, Ma \etal~\cite{ma2019bayesian} designed a Bayesian loss function for instance-level supervision. Cheng \etal~\cite{cheng2019learning} proposed a Maximum Excess over Pixels (MEP) loss function, where the region with the maximum loss value is used for optimization.
Wan \etal~\cite{wan2020modeling} modeled the annotation noise using a random variable with Gaussian distribution. 
Some other methods adopt uncertainty estimation to model the noisy annotations~\cite{oh2020crowd, ranjan2020uncertainty}.
% Further, Bai \etal~\cite{bai2020adaptive} proposed a self-correction supervision learning framework, which utilizes the outputs of the model to iteratively correct the annotations.
Recently, Lin \etal~\cite{lin2022boosting} proposed instance attention loss to exclude the instance in back-propagation if its deviation is too large.
However, all of these methods above ignore one critical problem: \emph{how to explore useful supervision in noisy areas?}


% 本文的方法
%\shan{this logic should be the same as the abstract, especially the order of each contribution}
% In this paper, we apply sum-pooling operation to ground truth density maps and used the result density map as supervision~\cite{liu2020adaptive}, which not only significantly reduces video memory during training, but also significantly improves the noise robustness of model. In fact, total count is the global sum-pooling result of density map. This approach therefore generalize count-based method and density map-based under a unified framework. Further more, since above scheme cannot handle the problem of missing annotations in low-resolution and dense scenes,
Our answer is: \emph{the predicted density map itself can provide useful supervision in noisy areas.}
In this paper, we propose to use two regression heads with totally different architecture, \ie one convolution head and one transformer head, to mutually supervise each other in noisy areas.
The resultant model, \methodname, can synergize different types of inductive biases of convolutions and transformers to boost each other's performance for better counting.
% In this paper, we propose to use two regression heads with totally different architecture, \ie one convolution head and one transformer head, to mutually supervise each other in noisy areas. Thanks to the different model capacities and inductive biases of convolution operations and transformer layers, these two heads can learn different representations and boost each other's performance.
However, the quality of the predicted density map is unsatisfactory in the early stage of training and cannot be directly used for supervision. 
% To stabilize the early training process, 
To make the training reliable, we develop a progressive cross-head supervision learning strategy, that is, the true supervision density maps should be the weighted combinations of the ground truth and predictions from another head, where the weights are linearly increased as the training process goes on.
% and make the predicted density maps more reliable for supervision, we develop a progressive cross-head supervision learning strategy,
% where weights of ground truth and predictions from another head are linearly increased as the training process goes on.
% the noisy areas and weight parameters of the complementary head are linearly increased as the training process goes on.
% \gao{have to briefly clarify whose weight parameters. Why do the linearly increased parameters help to stabilize the early training process?}

% 贡献总结
The main contributions of this work are summarized as follows:
1) we propose a novel model \methodname with one convolution head and one transformer head to supervise each other in noisy areas;
2) we design a progressive cross-head supervision learning strategy to make the training process more stable; and
3) our \methodname achieves superior performance on several benchmarked datasets.
% Detailed ablation studies further validate the effectiveness of each component.
