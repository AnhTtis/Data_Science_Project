Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Lin2017,
author = {Lin, Henry and Tegmark, Max and Rolnick, David},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley//Lin, Tegmark, Rolnick - 2017 - Why does deep and cheap learning work so well.pdf:pdf},
journal = {Journal of Statistical Physics},
number = {6},
pages = {1223--1247},
title = {{Why does deep and cheap learning work so well?}},
volume = {168},
year = {2017}
}
@article{Holm2015,
author = {Holm, Darryl D.},
journal = {Proceedings of the Royal Society of London A: Mathematical, Physical and Engineering Sciences},
number = {2176},
title = {{Variational principles for stochastic fluid dynamics}},
url = {http://rspa.royalsocietypublishing.org/content/471/2176/20140963},
volume = {471},
year = {2015}
}
@inproceedings{barron1992neural,
author = {Barron, Andrew R.},
booktitle = {Proc. 7th Yale Workshop on Adaptive and Learning Systems},
pages = {69--72},
title = {{Neural net approximation}},
year = {1992}
}
@article{JamesD.Hamilton2009,
author = {{James D . Hamilton}},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/James D . Hamilton - 2009 - A New Approach to the Economic Analysis of Nonstationary Time Series and the Business Cycle.pdf:pdf},
journal = {The Econometric Society Stable },
number = {2},
pages = {357--384},
title = {{A New Approach to the Economic Analysis of Nonstationary Time Series and the Business Cycle}},
url = {http://www.jstor.org/stable/1912559},
volume = {57},
year = {2009}
}
@article{jacquier:polson:rossi,
author = {Jacquier, E and Polson, N G and Rossi, P E},
journal = {Journal of Business and Economic Statistics},
pages = {371--417},
title = {{Bayesian analysis of stochastic volatility models}},
volume = {12},
year = {1994}
}
@incollection{Cont,
author = {Cont, Rama and Tankov, Peter and Voltchkova, Ekaterina},
booktitle = {Stochastic Analysis and Applications. Volume 2},
pages = {197--217},
publisher = {Springer-Verlag},
title = {{Hedging with options in models with jumps}},
year = {2007}
}
@article{Blum2006,
author = {Blum, Avrim},
title = {{Random projection, margins, kernels, and feature-selection}},
year = {2006}
}
@book{HarveyGAS,
author = {Harvey, Andrew C.},
title = {{Dynamic Models for Volatility and Heavy Tails}},
year = {2013}
}
@article{molecules,
author = {Montaldi, J. A. and Roberts, R. M.},
issn = {0938-8974},
journal = {Journal of Nonlinear Science},
month = {feb},
number = {1},
pages = {53--88},
title = {{Relative equilibria of molecules}},
url = {http://www.springerlink.com/index/10.1007/s003329900064},
volume = {9},
year = {1999}
}
@article{Rohrdanz2013,
author = {Rohrdanz, Mary A. and Zheng, Wenwei and Clementi, Cecilia},
doi = {10.1146/annurev-physchem-040412-110006},
journal = {Annu. Rev. Phys. Chem.},
number = {1},
pages = {295--316},
title = {{Discovering mountain passes via torchlight: methods for the definition of reaction coordinates and pathways in complex macromolecular reactions}},
url = {http://dx.doi.org/10.1146/annurev-physchem-040412-110006},
volume = {64},
year = {2013}
}
@misc{Layton2003,
abstract = {Durland and McCurdy (1994) investigated the issue of duration dependence in US business cycle phases using a Markov regime switching approach, introduced by Hamilton (1989) and extended to the case of variable transition parameters by Filardo (1994). In Durland and McCurdy's model duration alone was used as an explanatory of the transition probabilities. They found that recessions were duration dependent whilst expansions were not. In this paper, we explicitly incorporate the widely-accepted US business cycle phase change dates as determined by the NBER, and use a state-dependent multinomial Logit (and Probit) modelling framework. The model incorporates both duration and movements in two leading indexes - one designed to have a short lead (SLI) and the other designed to have a longer lead (LLI) - as potential explanators. We find that doing so suggests that current duration is not only a significant determinant of transition out of recessions, but that there is some evidence that it is also weakly significant in the case of expansions. Furthermore, we find that SLI has more informational content for the termination of recessions whilst LLI does so for expansions.},
author = {Layton, Allan P and Smith, Daniel R},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Layton, Smith - 2003 - Duration Dependence in the US Business Cycle.pdf:pdf},
number = {Lli},
title = {{Duration Dependence in the US Business Cycle}},
year = {2003}
}
@inproceedings{WLPN:18,
author = {Wilson-Nunn, Daniel and Lyons, Terry and Papavasiliou, Anastasia and Ni, Hao},
booktitle = {2018 IEEE 2nd International Workshop on Arabic and Derived Script Analysis and Recognition (ASAR)},
organization = {IEEE},
pages = {135--139},
title = {{A Path Signature Approach to Online Arabic Handwriting Recognition}},
year = {2018}
}
@inproceedings{pesquera2012,
author = {Ortin, Silvia and Pesquera, Luis and Guti{\'{e}}rrez, Jos{\'{e}} Manuel},
booktitle = {Proceedings of the European Conference on Complex Systems},
doi = {10.1007/978-3-319-00395-5_107},
editor = {Gilbert, Thomas and Kirkilionis, Markus and Nicolis, Gregoire},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Ortin, Pesquera, Guti{\'{e}}rrez - 2012 - Memory and nonlinear mapping in reservoir computing with two uncoupled nonlinear delay nodes.pdf:pdf},
pages = {895--899},
publisher = {Springer International Publishing Switzerland},
title = {{Memory and nonlinear mapping in reservoir computing with two uncoupled nonlinear delay nodes}},
year = {2012}
}
@article{Hornak2006,
author = {Hornak, Viktor and Okur, Asim and Rizzo, Robert and Simmerling, Carlos},
journal = {PNAS},
number = {4},
pages = {915--920},
title = {{HIV-1 protease flaps spontaneously open and reclose in molecular dynamics simulations}},
volume = {103},
year = {2006}
}
@article{RC8,
archivePrefix = {arXiv},
arxivId = {1807.02621},
author = {Gonon, Lukas and Ortega, Juan-Pablo},
eprint = {1807.02621},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
number = {1},
pages = {100--112},
title = {{Reservoir computing universality with stochastic inputs}},
volume = {31},
year = {2020}
}
@article{hafner:herwartz,
annote = {10.1007/s00184-007-0130-y},
author = {Hafner, Christian M and Herwartz, Helmut},
issn = {0026-1335},
journal = {Metrika},
number = {2},
pages = {219--239},
publisher = {Physica Verlag, An Imprint of Springer-Verlag GmbH},
title = {{Analytical quasi maximum likelihood inference in multivariate volatility models}},
url = {http://dx.doi.org/10.1007/s00184-007-0130-y},
volume = {67},
year = {2008}
}
@article{Monien2007,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
author = {Monien, Burkhard and Preis, Robert and Schamberger, Stefan},
doi = {10.1201/9781420010749},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Monien, Preis, Schamberger - 2007 - Approximation algorithms for multilevel graph partitioning.pdf:pdf},
isbn = {9781420010749},
journal = {Handbook of Approximation Algorithms and Metaheuristics},
pages = {60--1--60--16},
title = {{Approximation algorithms for multilevel graph partitioning}},
year = {2007}
}
@article{Ornthanalai2014,
abstract = {Using index options and returns from 1996 to 2009, I estimate discrete-time models where asset returns follow a Brownian increment and a L{\'{e}}vy jump. Time variations in these models are generated with an affine GARCH, which facilitates the empirical implementation. I find that the risk premium implied by infinite-activity jumps contributes to more than half of the total equity premium and dominates that of the Brownian increments suggesting that it is more representative of the risks present in the economy. Overall, my findings suggest that infinite-activity jumps, instead of the Brownian increments, should be the default modeling choice in asset pricing models.},
author = {Ornthanalai, Chayawat},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Ornthanalai - 2014 - L{\'{e}}vy jump risk Evidence from options and returns.pdf:pdf},
issn = {0304405X},
journal = {Journal of Financial Economics},
keywords = {C22,C23,C46,Discrete-time,G01,G12,GARCH,L{\'{e}}vy process,Option valuation,Risk premium},
month = {apr},
number = {1},
pages = {69--90},
title = {{L{\'{e}}vy jump risk: Evidence from options and returns}},
url = {http://www.sciencedirect.com/science/article/pii/S0304405X13002985},
volume = {112},
year = {2014}
}
@inproceedings{Duan99,
address = {Working paper},
author = {Duan, Jin-Chuan},
title = {{Conditionally fat-tailed distributions and the volatility smile in options}},
year = {1999}
}
@book{dazord:delzant:1987,
address = {26,223--251},
author = {Dazord, P. and Delzant, T.},
booktitle = {J. Diff. Geom.},
pages = {223--251},
publisher = {J. Diff. Geom.},
title = {{Le probl{\`{e}}me g{\'{e}}n{\'{e}}ral des variables action-angle}},
volume = {26},
year = {1987}
}
@book{Albrecher:2013,
abstract = {on education (p 162): For everyone five years of age or odler in the NCHS-NHIS, the following question is asked to elicit information about their ears of schooling: "What is the highest grade or year of regular school (PERSON) has ever attended?" Respondents are then asked "Did (PERSON) finish the (NUMBER/GRADE/YEAR)? The term regular school is used to exclude time spent at technical or trade schools from the years of school reported. This two-part question is reccommended by the Bureau of the Census to reduce the upward bias that results from asking simply, "What is the highest grade or year of regular school that (PERSON) completed?" Individuals can be classified according to the nmber of years of education they recieved or whether they graduated from elementary school, high school, or college.},
author = {Albrecher, Hansj{\"{o}}rg and Binder, Andreas and Lautscham, Volkmar and Mayer, Philipp},
doi = {10.1007/978-3-0348-0519-3},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Albrecher et al. - 2013 - Introduction to Quantitative Methods for Financial Markets.pdf:pdf},
isbn = {978-3-0348-0518-6},
pages = {1--191},
title = {{Introduction to Quantitative Methods for Financial Markets}},
url = {http://link.springer.com/10.1007/978-3-0348-0519-3},
year = {2013}
}
@book{shalizi2013advanced,
address = {New York, NY},
author = {Shalizi, Cosma},
publisher = {Cambridge University Press},
title = {{Advanced Data Analysis from an Elementary Point of View}},
url = {https://pdfs.semanticscholar.org/e493/85e52c41ca8fcd1803000b1542f9d1acdc44.pdf},
year = {2013}
}
@article{GHO17jmlr,
author = {Grigoryeva, Lyudmila and Henriques, Julie and Ortega, Juan-Pablo},
journal = {Under revision for the Journal of Machine Learning Research},
title = {{Forecasting, filtering, and reconstruction of stochastic stationary signals using discrete-time reservoir computers}},
year = {2017}
}
@book{dunford1957linear,
author = {Dunford, Nelson and Schwartz, Jacob T},
publisher = {New York Interscience},
title = {{Linear Operators. Part 1: General Theory}},
year = {1957}
}
@article{zhu:cao:14,
abstract = {In this paper, we focus on the stability problem for a class of stochastic delayed recurrent neural networks. Different from the traditional stability criteria, we introduce and study a new stability criterion: the mean-square exponential input-to-state stability. To the best of our knowledge, this new stability criterion has never been discussed in the field of stochastic recurrent neural networks. The main objective of the paper is to fill the gap. With the help of the Lyapunov-Krasovskii functional, stochastic analysis theory and It??'s formula, we prove that the addressed system is mean-square exponentially input-to-state stable. Moreover, two numerical examples and their simulations are presented to verify the theoretical results well. ?? 2013 Elsevier B.V.},
author = {Zhu, Quanxin and Cao, Jinde},
doi = {10.1016/j.neucom.2013.10.029},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Exponential stability,It??'s formula,Lyapunov-Krasovskii functional,Mean-square exponential input-to-state stability,Stochastic delayed neural network},
pages = {157--163},
publisher = {Elsevier},
title = {{Mean-square exponential input-to-state stability of stochastic delayed neural networks}},
url = {http://dx.doi.org/10.1016/j.neucom.2013.10.029},
volume = {131},
year = {2014}
}
@book{Koopman:kalman,
author = {Durbin, J. and Koopman, Siem Jan},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Durbin, Koopman - 2012 - Time Series Analysis by State Space Methods.pdf:pdf},
publisher = {Oxford University Press},
title = {{Time Series Analysis by State Space Methods}},
year = {2012}
}
@article{Fridman1998,
author = {Fridman, Moshe and Harris, Lawrence},
journal = {Journal of Business {\&} Economic Statistics},
keywords = {fridman:harris},
mendeley-tags = {fridman:harris},
number = {3},
pages = {284--291},
title = {{A Maximum Likelihood Approach for Non-Gaussian Stochastic Volatility Models}},
volume = {16},
year = {1998}
}
@misc{Poggio2017,
abstract = {The paper reviews and extends an emerging body of theoretical results on deep learning including the conditions under which it can be exponentially better than shallow learning. A class of deep convolutional networks represent an important special case of these conditions, though weight sharing is not the main reason for their exponential advantage. Implications of a few key theorems are discussed, together with new results, open problems and conjectures.},
archivePrefix = {arXiv},
arxivId = {1611.00740},
author = {Poggio, Tomaso and Mhaskar, Hrushikesh and Rosasco, Lorenzo and Miranda, Brando and Liao, Qianli},
booktitle = {International Journal of Automation and Computing},
doi = {10.1007/s11633-017-1054-2},
eprint = {1611.00740},
issn = {17518520},
keywords = {Machine learning,convolutional neural networks,deep and shallow networks,deep learning,function approximation,neural networks},
title = {{Why and when can deep-but not shallow-networks avoid the curse of dimensionality: A review}},
year = {2017}
}
@article{bl,
author = {Bates, L. and Lerman, E.},
journal = {Pacific J. Math.},
number = {2},
pages = {201--229},
title = {{Proper group actions and symplectic stratified spaces}},
volume = {181},
year = {1997}
}
@book{cartan,
author = {Cartan, {\'{E}}},
publisher = {Hermann},
title = {{Le{\{}{\c{c}}{\}}ons sur les Invariants Int{\{}{\'{e}}{\}}graux}},
year = {1922}
}
@article{Flores2012,
abstract = {The evolutionary design of time series forecasters is a field that has been explored for several years now. In this paper, a complete design and training of ARMA (Auto-Regressive Moving Average) and ANN (Artificial Neural Networks) models through the use of Evolutionary Computation is presented. That is, given a time series, our proposal (EDFM – Evolutionary Design of Forecasting Models) qualitatively and quantitatively identifies a competitive model to perform the forecasting task. In the qualitative phase of the model identification, EDFM identifies the variables relevant to the process; i.e. the subset of variables, within a given window width, that provides the best forecasting, following the parsimony criterion. In the quantitative phase of the identification process, all free parameters are numerically instantiated; i.e. the coefficient of the ARMA models, or the ANN weights are determined. The results show that ANN yield better forecasts than ARMA models in all the cases presented in this paper.},
author = {Flores, Juan J. and Graff, Mario and Rodriguez, Hector},
issn = {09601481},
journal = {Renewable Energy},
keywords = {artificial neural networks,evolutionary algorithms,feature selection,time series forecasting},
month = {aug},
pages = {225--230},
title = {{Evolutive design of ARMA and ANN models for time series forecasting}},
url = {http://dx.doi.org/10.1016/j.renene.2012.01.084},
volume = {44},
year = {2012}
}
@article{NelsonGARCH90,
author = {Nelson, Daniel B.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Nelson - 1990 - Stationarity and persistence in the GARCH(1,1) model.pdf:pdf},
journal = {Econometric Theory},
number = {3},
pages = {18--334},
title = {{Stationarity and persistence in the GARCH(1,1) model}},
volume = {6},
year = {1990}
}
@article{Hummer2003,
author = {Hummer, Gerhard and Kevrekidis, Ioannis G},
doi = {http://dx.doi.org/10.1063/1.1574777},
journal = {J. Chem. Phys.},
number = {23},
pages = {10762--10773},
title = {{Coarse molecular dynamics of a peptide fragment: Free energy, kinetics, and long-time dynamics computations}},
url = {http://scitation.aip.org/content/aip/journal/jcp/118/23/10.1063/1.1574777},
volume = {118},
year = {2003}
}
@article{Brooks2001,
author = {Brooks, Chris and Burke, Simon P. and Persand, Gita},
journal = {International Journal of Forecasting},
pages = {45--56},
title = {{Benchmarks and the accuracy of GARCH model estimation}},
volume = {17},
year = {2001}
}
@article{RC19,
author = {Grigoryeva, Lyudmila and Hart, Allen G and Ortega, Juan-Pablo},
journal = {In preparation},
title = {{Embedding chaos on manifolds with state-space systems}},
year = {2020}
}
@article{Kaufmann2013,
abstract = {Achieving accurate judgment ('judgmental achievement') is of utmost importance in daily life across multiple domains. The lens model and the lens model equation provide useful frameworks for modeling components of judgmental achievement and for creating tools to help decision makers (e.g., physicians, teachers) reach better judgments (e.g., a correct diagnosis, an accurate estimation of intelligence). Previous meta-analyses of judgment and decision-making studies have attempted to evaluate overall judgmental achievement and have provided the basis for evaluating the success of bootstrapping (i.e., replacing judges by linear models that guide decision making). However, previous meta-analyses have failed to appropriately correct for a number of study design artifacts (e.g., measurement error, dichotomization), which may have potentially biased estimations (e.g., of the variability between studies) and led to erroneous interpretations (e.g., with regards to moderator variables). In the current study we therefore conduct the first psychometric meta-analysis of judgmental achievement studies that corrects for a number of study design artifacts. We identified 31 lens model studies (N = 1,151, k = 49) that met our inclusion criteria. We evaluated overall judgmental achievement as well as whether judgmental achievement depended on decision domain (e.g., medicine, education) and/or the level of expertise (expert vs. novice). We also evaluated whether using corrected estimates affected conclusions with regards to the success of bootstrapping with psychometrically-corrected models. Further, we introduce a new psychometric trim-and-fill method to estimate the effect sizes of potentially missing studies correct psychometric meta-analyses for effects of publication bias. Comparison of the results of the psychometric meta-analysis with the results of a traditional meta-analysis (which only corrected for sampling error) indicated that artifact correction leads to a) an increase in values of the lens model components, b) reduced heterogeneity between studies, and c) increases the success of bootstrapping. We argue that psychometric meta-analysis is useful for accurately evaluating human judgment and show the success of bootstrapping.},
author = {Kaufmann, Esther and Reips, Ulf Dietrich and Wittmann, Werner W},
doi = {10.1371/journal.pone.0083528},
issn = {19326203},
journal = {PLoS ONE},
number = {12},
pmid = {24391781},
title = {{A critical meta-analysis of lens model studies in human judgment and decision-making}},
volume = {8},
year = {2013}
}
@inproceedings{Sutskever2013,
author = {Sutskever, Ilya and Martens, James and Dahl, George and Hinton, Geoffrey},
booktitle = {International Conference on Machine Learning},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Sutskever et al. - 2013 - On the importance of initialization and momentum in deep learning.pdf:pdf},
issn = {08692092},
pages = {1139--1147},
title = {{On the importance of initialization and momentum in deep learning}},
year = {2013}
}
@article{Song2014,
author = {Song, Z and Xiu, D},
journal = {Journal of Econometrics},
number = {1},
pages = {176--196},
title = {{A tale of two option markets: Pricing kernels and volatility risk}},
url = {http://papers.ssrn.com/sol3/papers.cfm?abstract{\_}id=2013381},
volume = {190},
year = {2016}
}
@article{gradient:kalman:segal,
author = {{Segal, M.; Weinstein}, E.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Segal, M. Weinstein - 1989 - A new method for evaluating the log-likelihood gradient, the Hessian, and the Fisher information matrix for.pdf:pdf},
journal = {IEEE Trans. Inform. Theory},
number = {3},
pages = {682--687},
title = {{A new method for evaluating the log-likelihood gradient, the Hessian, and the Fisher information matrix for linear dynamic systems}},
volume = {35},
year = {1989}
}
@article{singreleq,
author = {Lerman, E. and Singer, S. F.},
journal = {Nonlinearity},
pages = {1637--1649},
title = {{Stability and persistence of relative equilibria at singular values of the moment map}},
volume = {11},
year = {1998}
}
@article{EEG_FMRI_2015,
author = {Gabriel, Damien and Henriques, Julie and Comte, Alexander and Grigoryeva, Lyudmila and Ortega, Juan-Pablo and Cretin, E. and Haffen, Emmanuel and Moulin, T. and Pazart, Lionnel and Aubry, R.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Gabriel et al. - 2015 - Substitute or complement Defining the relative place of EEG and fMRI in the detection of voluntary brain reactio.pdf:pdf},
journal = {Neuroscience},
pages = {435--444},
title = {{Substitute or complement? Defining the relative place of EEG and fMRI in the detection of voluntary brain reactions}},
volume = {290},
year = {2015}
}
@book{Shiryaev:Probability1,
abstract = {{\{}This book contains a systematic treatment of probability from the ground up, starting with intuitive ideas and gradually developing more sophisticated subjects, such as random walks, martingales, Markov chains, ergodic theory, weak convergence of probability measures, stationary stochastic processes, and the Kalman-Bucy filter. Many examples are discussed in detail, and there are a large number of exercises. The book is accessible to advanced undergraduates and can be used as a text for self-study. This new edition contains substantial revision and updated references. The reader will find a deeper study of topics such as the distance between probability measures, metrization of weak convergence, and contiguity of probability measures. Proofs for a number of some important results which were merely stated in the first edition have been added. The author has included new material on the probability of large deviations, on the central limit theorem for sums of dependent random variables, and on a discrete version of Ito's formula.{\}}},
author = {Shiryaev, Albert N.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Shiryaev - 2016 - Probability-1.pdf:pdf},
isbn = {0387945490},
pages = {624},
publisher = {Springer},
title = {{Probability-1}},
year = {2016}
}
@book{Davidson:Donsig,
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Davidson, Kenneth R. and Donsig, Allan P.},
doi = {10.1007/978-0-387-92712-1},
eprint = {arXiv:1011.1669v3},
isbn = {3540901639},
issn = {0172-6056},
pages = {513},
pmid = {25246403},
publisher = {Springer Science+Business Media},
title = {{Real Analysis and Applications}},
url = {http://www.amazon.com/dp/1441970223},
year = {2010}
}
@article{Lutkepohl2010,
author = {L{\"{u}}tkepohl, Helmut and Xu, Fang},
doi = {10.1007/s00181-010-0440-1},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/L{\"{u}}tkepohl, Xu - 2012 - The role of the log transformation in forecasting economic variables.pdf:pdf},
issn = {0377-7332},
journal = {Empirical Economics},
keywords = {autoregressive moving average process,forecast mean squared error,heteroskedasticity,instantaneous transformation,integrated process,jel classification c22},
month = {dec},
number = {3},
pages = {619--638},
title = {{The role of the log transformation in forecasting economic variables}},
url = {http://www.springerlink.com/index/10.1007/s00181-010-0440-1},
volume = {42},
year = {2010}
}
@article{BiaginiF.andPratelli1999,
author = {{Biagini, F. and Pratelli}, M .},
file = {:Users/JP17/JPO{\_}synch/Mendeley//:},
journal = {Journal of Applied Probability},
number = {4},
pages = {1126--1139},
title = {{Local Risk Minimization and Num{\'{e}}raire}},
volume = {36},
year = {1999}
}
@incollection{hammer:tino:boden:2007,
author = {Tino, Peter and Hammer, Barbara and Bod{\'{e}}n, Mikael},
booktitle = {Perspectives of Neural-Symbolic Integration. Studies in Computational Intelligence, vol 77.},
doi = {10.1007/978-3-540-73954-8_5},
editor = {{Hammer B.} and {Hitzler P.}},
pages = {95--133},
publisher = {Springer, Berlin, Heidelberg},
title = {{Markovian bias of neural-based architectures with feedback connections}},
url = {http://link.springer.com/10.1007/978-3-540-73954-8{\_}5},
year = {2007}
}
@article{Schumacher2008,
abstract = {This paper discusses a factor model for short-term forecasting of GDP growth using a large number of monthly and quarterly time series in real-time. To take into account the different periodicities of the data and missing observations at the end of the sample, the factors are estimated by applying an EM algorithm, combined with a principal components estimator. We discuss some in-sample properties of the estimator in a real-time environment and propose alternative methods for forecasting quarterly GDP with monthly factors. In the empirical application, we use a novel real-time dataset for the German economy. Employing a recursive forecast experiment, we evaluate the forecast accuracy of the factor model with respect to German GDP. Furthermore, we investigate the role of revisions in forecast accuracy and assess the contribution of timely monthly observations to the forecast performance. Finally, we compare the performance of the mixed-frequency model with that of a factor model, based on time-aggregated quarterly data.},
author = {Schumacher, C and Breitung, J},
institution = {Deutsche Bundesbank},
issn = {01692070},
journal = {International Journal of Forecasting},
number = {3},
pages = {386--398},
publisher = {Elsevier},
series = {Discussion Paper Series 1: Economic studies},
title = {{Real-time forecasting of German GDP based on a large factor model with monthly and quarterly data}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0169207008000393},
volume = {24},
year = {2008}
}
@book{Francq2010,
abstract = {This book provides a comprehensive and systematic approach to understanding GARCH time series models and their applications whilst presenting the most advanced results concerning the theory and practical aspects of GARCH. The probability structure of standard GARCH models is studied in detail as well as statistical inference such as identification, estimation and tests. The book also provides coverage of several extensions such as asymmetric and multivariate models and looks at financial applications.Key features:Provides up-to-date coverage of the current research in the probability, statistics and econometric theory of GARCH models.Numerous illustrations and applications to real financial series are provided.Supporting website featuring R codes, Fortran programs and data sets.Presents a large collection of problems and exercises.This authoritative, state-of-the-art reference is ideal for graduate students, researchers and practitioners in business and finance seeking to broaden their skills of understanding of econometric time series models.},
author = {Francq, Christian and Zakoian, Jean-Michel},
pages = {504},
publisher = {Wiley},
title = {{GARCH Models: Structure, Statistical Inference and Financial Applications}},
year = {2010}
}
@article{tanaka:review,
abstract = {Reservoir computing is a computational framework suited for temporal/sequential data processing. It is derived from several recurrent neural network models, including echo state networks and liquid state machines. A reservoir computing system consists of a reservoir for mapping inputs into a high-dimensional space and a readout for pattern analysis from the high-dimensional states in the reservoir. The reservoir is fixed and only the readout is trained with a simple method such as linear regression and classification. Thus, the major advantage of reservoir computing compared to other recurrent neural networks is fast learning, resulting in low training cost. Another advantage is that the reservoir without adaptive updating is amenable to hardware implementation using a variety of physical systems, substrates, and devices. In fact, such physical reservoir computing has attracted increasing attention in diverse fields of research. The purpose of this review is to provide an overview of recent advances in physical reservoir computing by classifying them according to the type of the reservoir. We discuss the current issues and perspectives related to physical reservoir computing, in order to further expand its practical applications and develop next-generation machine learning systems.},
author = {Tanaka, Gouhei and Yamane, Toshiyuki and H{\'{e}}roux, Jean Benoit and Nakane, Ryosho and Kanazawa, Naoki and Takeda, Seiji and Numata, Hidetoshi and Nakano, Daiju and Hirose, Akira},
doi = {10.1016/j.neunet.2019.03.005},
issn = {18792782},
journal = {Neural Networks},
keywords = {Machine learning,Neural networks,Neuromorphic device,Nonlinear dynamical systems,Reservoir computing},
pages = {100--123},
publisher = {Elsevier Ltd},
title = {{Recent advances in physical reservoir computing: A review}},
url = {https://doi.org/10.1016/j.neunet.2019.03.005},
volume = {115},
year = {2019}
}
@inproceedings{ElKaroui2018,
author = {{El Karoui}, Noureddine},
booktitle = {Proc. Int. Cong. of Math.},
pages = {2845--2866},
title = {{Random matrices and high-dimensional statistics: Beyond covariance matrices}},
year = {2018}
}
@article{mcgoff2020empirical,
author = {McGoff, Kevin and Nobel, Andrew B and Others},
journal = {Annals of Statistics},
number = {4},
pages = {2031--2054},
publisher = {Institute of Mathematical Statistics},
title = {{Empirical risk minimization and complexity of dynamical models}},
volume = {48},
year = {2020}
}
@article{port-ham:jacob,
author = {Vigario, R. and Sarela, J. and Jousmaki, V. and Hamalainen, M. and Oja, E.},
journal = {IEEE Transactions on Biomedical Engineering},
number = {5},
pages = {589--593},
title = {{Independent component approach to the analysis of EEG and MEG recordings}},
volume = {47},
year = {2000}
}
@article{Marcellino2010a,
abstract = {This paper compares different ways to estimate the current state of the economy using factor models that can handle unbalanced datasets. Due to the different release lags of business cycle indicators, data unbalancedness often emerges at the end of multivariate samples, which is sometimes referred to as the 'ragged edge' of the data. Using a large monthly dataset of the German economy, we compare the performance of different factor models in the presence of the ragged edge: static and dynamic principal components based on realigned data, the Expectation-Maximisation (EM) algorithm and the Kalman smoother in a state-space model context. The monthly factors are used to estimate current quarter GDP, called the 'nowcast', using different versions of what we call factor-based mixed-data sampling (Factor-MIDAS) approaches. We compare all possible combinations of factor estimation methods and Factor-MIDAS projections with respect to nowcast performance. Additionally, we compare the performance of the nowcast factor models with the performance of quarterly factor models based on time-aggregated and thus balanced data, which neglect the most timely observations of business cycle indicators at the end of the sample. Our empirical findings show that the factor estimation methods don't differ much with respect to nowcasting accuracy. Concerning the projections, the most parsimonious MIDAS projection performs best overall. Finally, quarterly models are in general outperformed by the nowcast factor models that can exploit ragged-edge data.},
author = {Marcellino, Massimiliano and Schumacher, Christian},
issn = {03059049},
journal = {Oxford Bulletin of Economics and Statistics},
number = {4},
pages = {518--550},
publisher = {SSRN},
title = {{Factor-MIDAS for now- and forecasting with ragged-edge data: A model comparison for German GDP}},
url = {http://doi.wiley.com/10.1111/j.1468-0084.2010.00591.x},
volume = {72},
year = {2010}
}
@article{Edelmann1993,
author = {Edelmann, G. M.},
journal = {Neuron},
number = {2},
pages = {115--125},
title = {{Neural darwinism: Selection and reentrant signaling in higher brain function}},
volume = {10},
year = {1993}
}
@article{Owen2005,
abstract = {Persistent vegetative state is arguably one of the least understood and most ethically troublesome neurological conditions in modern medicine. The term describes a rare disorder in which patients who emerge from coma appear to be awake, but show no signs of awareness. In recent years, a number of studies have demonstrated an important role for functional neuroimaging in the identification of residual cognitive function in patients meeting the clinical criteria for persistent vegetative state. Such studies, when successful, may be particularly useful where there is a concern about the accuracy of the diagnosis and the possibility that residual cognitive function has remained undetected. Unfortunately, functional neuroimaging in persistent vegetative state is extremely complex and subject to numerous methodological, clinical and theoretical difficulties. In this chapter, we argue that in order to most effectively define the degree and extent of preserved cognitive function in persistent vegetative state, a hierarchical approach to cognition is required. To illustrate this point, a series of functional neuroimaging paradigms in the auditory domain are described, which systematically increase in complexity in terms of the auditory and/or linguistic processes required and, therefore, the degree of preserved cognition that can be inferred from "normal" patterns of activation in persistent vegetative patients. Preliminary results in a small series of patients provide a strong basis for the systematic study of possible residual cognitive function in persistent vegetative state.},
author = {Owen, Adrian M and Coleman, Martin R and Menon, David K and Berry, Emma L and Johnsrude, Ingrid S and Rodd, Jennifer M and Davis, Matthew H and Pickard, John D},
issn = {0079-6123},
journal = {Progress in brain research},
keywords = {Auditory Perception,Cognition,Humans,Persistent Vegetative State,Persistent Vegetative State: diagnosis,Persistent Vegetative State: psychology,Psychological Techniques},
month = {jan},
pages = {457--71},
title = {{Using a hierarchical approach to investigate residual auditory cognition in persistent vegetative state.}},
url = {http://www.sciencedirect.com/science/article/pii/S0079612305500323},
volume = {150},
year = {2005}
}
@article{BetaEEG,
author = {Pfurtscheller, Gert and Neuper, C. and Brunner, C. and {Lopes da Silva}, F.},
journal = {Neurosci Lett.},
number = {3},
pages = {156--159},
title = {{Beta rebound after different types of motor imagery in man}},
volume = {378},
year = {2005}
}
@article{arnold66,
author = {Arnold, V I},
journal = {Ann. Ins. Fourier, Grenoble},
pages = {319--361},
title = {{Sur la g{\{}{\'{e}}{\}}ometrie differentielle des groupes de Lie de dimensioninfinie et ses applications {\{}{\`{a}}{\}} l'hydrodynamique des fluidsparfaits}},
volume = {16},
year = {1966}
}
@article{RC16,
author = {Grigoryeva, Lyudmila and Ortega, Juan-Pablo},
doi = {10.3934/jgm.2021028},
journal = {Journal of Geometric Mechanics},
number = {4},
pages = {647--677},
title = {{Dimension reduction in recurrent networks by canonicalization}},
volume = {13},
year = {2021}
}
@book{Meyer2009,
author = {Meyer, Kenneth R. and Offin, Daniel C.},
doi = {https://doi.org/10.1007/978-3-319-53691-0},
issn = {0066-5452},
publisher = {Springer Cham},
title = {{Introduction to Hamiltonian Dynamical Systems and the N-Body Problem}},
year = {2009}
}
@article{Gregoir2000,
author = {Gregoir, St{\'{e}}phane and Lenglart, Fabrice},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Gregoir, Lenglart - 2000 - Measuring the probability of a business cycle turning point by using a multivariate qualitative hidden Markov.pdf:pdf},
issn = {0277-6693},
journal = {Journal of Forecasting},
month = {mar},
number = {2},
pages = {81--102},
title = {{Measuring the probability of a business cycle turning point by using a multivariate qualitative hidden Markov model}},
url = {http://doi.wiley.com/10.1002/(SICI)1099-131X(200003)19:2{\%}3C81::AID-FOR734{\%}3E3.0.CO;2-L},
volume = {19},
year = {2000}
}
@article{alexander:covariance_matrices,
author = {Alexander, Carol},
journal = {Economic Notes},
number = {2},
pages = {337--359},
title = {{Principal component models for generating large covariance matrices}},
volume = {31},
year = {2003}
}
@article{Mhaskar1996,
author = {Mhaskar, N. Hrushikesh},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley//Mhaskar - 1996 - Neural networks for optimal approximation of smooth and analytic functions.pdf:pdf},
journal = {Neural computation},
number = {1},
pages = {164--177},
title = {{Neural networks for optimal approximation of smooth and analytic functions}},
volume = {8},
year = {1996}
}
@article{Symitsi2018,
author = {Symitsi, Efthymia and Symeonidis, Lazaros and Kourtis, Apostolos and Markellos, Raphael},
journal = {Journal of Banking {\&} Finance2},
pages = {153--168},
title = {{Covariance forecasting in equity markets}},
volume = {96},
year = {2018}
}
@article{FZNonstatAsymGARCH,
author = {Francq, Christian and Zako{\"{i}}an, Jean-Michel},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Francq, Zako{\"{i}}an - 2013 - Inference in nonstationary asymmetric GARCH models.pdf:pdf},
journal = {The Annals of Statistics},
number = {4},
pages = {1970--1998},
title = {{Inference in nonstationary asymmetric GARCH models}},
volume = {41},
year = {2013}
}
@article{Sullivan2003,
abstract = {Data sharing is common practice in forecasting experiments in situations where fresh data samples are difficult or expensive to generate. This means that forecasters often analyze the same dataset using a host of different models and sets of explanatory variables. This practice introduces statistical dependencies across forecasting studies that can severely distort statistical inference. Here we examine a new and inexpensive recursive bootstrap procedure that allows forecasters to account explicitly for these dependencies. The procedure allows forecasters to merge empirical evidence and draw inference in the light of previously accumulated results. In an empirical example, we merge results from predictions of daily stock prices based on (1) technical trading rules and (2) calendar rules, demonstrating both the significance of problems arising from data sharing and the simplicity of accounting for data sharing using these new methods.},
author = {Sullivan, Ryan and Timmermann, Allan and White, Halbert},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {bootstrap,calendar effects,data mining,data sharing,forecastevaluation,technical trading},
month = {apr},
number = {2},
pages = {217--227},
title = {{Forecast evaluation with shared data sets}},
url = {http://dx.doi.org/10.1016/S0169-2070(01)00140-6},
volume = {19},
year = {2003}
}
@article{Weiss1984,
abstract = {Within the class of ARMAX models we consider the effects systematic sampling or temporal aggregation may have on the dynamic relationships between variables. These include changes in lag lengths and causal ordering and may occur even in simple models. Some implications for the modelling of time series are noted. For the subclass of ARIMA models we also analyse the consequences of sampling or aggregating seasonal models.},
author = {Weiss, Andrew A.},
issn = {03044076},
journal = {Journal of Econometrics},
keywords = {Aggregation Time Series},
month = {dec},
number = {3},
pages = {271--281},
title = {{Systematic sampling and temporal aggregation in time series models}},
url = {http://dx.doi.org/10.1016/0304-4076(84)90022-8},
volume = {26},
year = {1984}
}
@article{GOZ2012,
author = {Grigoryeva, Lyudmila and Ortega, Juan-Pablo and Zub, Stanislav},
journal = {Journal of Geometric Mechanics},
number = {3},
pages = {373--415},
title = {{Stability of Hamiltonian relative equilibria in symmetric magnetically confined rigid bodies}},
volume = {6},
year = {2014}
}
@article{holler_plos,
abstract = {Current research aims at identifying voluntary brain activation in patients who are behaviorally diagnosed as being unconscious, but are able to perform commands by modulating their brain activity patterns. This involves machine learning techniques and feature extraction methods such as applied in brain computer interfaces. In this study, we try to answer the question if features/classification methods which show advantages in healthy participants are also accurate when applied to data of patients with disorders of consciousness. A sample of healthy participants (N = 22), patients in a minimally conscious state (MCS; N = 5), and with unresponsive wakefulness syndrome (UWS; N = 9) was examined with a motor imagery task which involved imagery of moving both hands and an instruction to hold both hands firm. We extracted a set of 20 features from the electroencephalogram and used linear discriminant analysis, k-nearest neighbor classification, and support vector machines (SVM) as classification methods. In healthy participants, the best classification accuracies were seen with coherences (mean = .79; range = .53-.94) and power spectra (mean = .69; range = .40-.85). The coherence patterns in healthy participants did not match the expectation of central modulated [Formula: see text]-rhythm. Instead, coherence involved mainly frontal regions. In healthy participants, the best classification tool was SVM. Five patients had at least one feature-classifier outcome with p[Formula: see text]0.05 (none of which were coherence or power spectra), though none remained significant after false-discovery rate correction for multiple comparisons. The present work suggests the use of coherences in patients with disorders of consciousness because they show high reliability among healthy subjects and patient groups. However, feature extraction and classification is a challenging task in unresponsive patients because there is no ground truth to validate the results.},
author = {H{\"{o}}ller, Yvonne and Bergmann, J{\"{u}}rgen and Thomschewski, Aljoscha and Kronbichler, Martin and H{\"{o}}ller, Peter and Crone, Julia S. and Schmid, Elisabeth V. and Butz, Kevin and Nardone, Raffaele and Trinka, Eugen},
doi = {10.1371/journal.pone.0080479},
issn = {1932-6203},
journal = {PLOS ONE},
month = {jan},
number = {11},
pages = {e80479},
pmid = {24282545},
publisher = {Public Library of Science},
title = {{Comparison of EEG-features and classification methods for motor imagery in patients with disorders of consciousness}},
url = {http://www.plosone.org/article/info:doi/10.1371/journal.pone.0080479{\#}pone-0080479-g007},
volume = {8},
year = {2013}
}
@inproceedings{Rudi2018,
author = {Rudi, Alessandro and Ciliberto, Carlo and Marconi, Gian Maria and Rosasco, Lorenzo},
booktitle = {NeurIPS},
title = {{Manifold structured prediction}},
year = {2018}
}
@article{Tikk:koczy,
abstract = {This paper deals with the approximation behaviour of soft computing techniques. First, we give a survey of the results of universal approximation theorems achieved so far in various soft computing areas, mainly in fuzzy control and neural networks. We point out that these techniques have common approximation behaviour in the sense that an arbitrary function of a certain set of functions (usually the set of continuous function, C) can be approximated with arbitrary accuracy $\epsilon$ on a compact domain. The drawback of these results is that one needs unbounded numbers of "building blocks" (i.e. fuzzy sets or hidden neurons) to achieve the prescribed $\epsilon$ accuracy. If the number of building blocks is restricted, it is proved for some fuzzy systems that the universal approximation property is lost, moreover, the set of controllers with bounded number of rules is nowhere dense in the set of continuous functions. Therefore it is reasonable to make a trade-off between accuracy and the number of the building blocks, by determining the functional relationship between them. We survey this topic by showing the results achieved so far, and its inherent limitations. We point out that approximation rates, or constructive proofs can only be given if some characteristic of smoothness is known about the approximated function. {\textcopyright} 2003 Elsevier Science Inc. All rights reserved.},
author = {Tikk, Domonkos and K{\'{o}}czy, L{\'{a}}szl{\'{o}} T. and Gedeon, Tam{\'{a}}s D.},
doi = {10.1016/S0888-613X(03)00021-5},
issn = {0888613X},
journal = {International Journal of Approximate Reasoning},
keywords = {Approximation behaviour of soft computing techniqu,Approximation rates,Constructive proofs,Course of dimensionality,Kolmogorov's theorem,Nowhere denseness,Universal approximation performed by fuzzy systems},
number = {2},
pages = {185--202},
title = {{A survey on universal approximation and its limits in soft computing techniques}},
volume = {33},
year = {2003}
}
@article{scardapane:sparse,
author = {Scardapane, Simone and Panella, Massimo and Comminiello, Danilo and Hussain, Amir and Uncini, Aurelio},
doi = {10.1109/MCI.2016.2601759},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Scardapane et al. - 2016 - Distributed reservoir computing with sparse readouts.pdf:pdf},
issn = {1556603X},
journal = {IEEE Computational Intelligence Magazine},
number = {November},
pages = {1--18},
title = {{Distributed reservoir computing with sparse readouts}},
year = {2016}
}
@techreport{NN3jaeger,
author = {Ilies, Iulian and Jaeger, Herbert and Kosuchinas, Olegas and Rincon, Monserrat and Sakenas, Vytenis and Vaskevicius, Narunas},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Ilies et al. - 2007 - Stepping forward through echoes of the past forecasting with Echo State Networks.pdf:pdf},
title = {{Stepping forward through echoes of the past: forecasting with Echo State Networks}},
year = {2007}
}
@book{Vershynin:book,
author = {Vershynin, Roman},
title = {{High-Dimensional Probability}},
year = {2017}
}
@article{Duan06,
author = {Duan, Jin-Chuan and Ritchken, Peter and Sun, Zhiqiang},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Duan, Ritchken, Sun - 2006 - Approximating GARCH-jump models, jump-diffusion processes, and option pricing.pdf:pdf},
issn = {0960-1627},
journal = {Mathematical Finance},
number = {1},
pages = {21--52},
title = {{Approximating GARCH-jump models, jump-diffusion processes, and option pricing}},
volume = {16},
year = {2006}
}
@article{Boix,
author = {Boix, Rafael R and Medina, Francisco},
title = {{Potencial escalar magn{\{}{\'{e}}{\}}tico y cargas de magnetizaci{\{}{\'{o}}{\}}n. C{\{}{\'{a}}{\}}lculo de la intensidad magn{\{}{\'{e}}{\}}tica en ausencia de corrientes libres.}}
}
@article{carnero:pena:ruiz,
author = {Carnero, M Angeles and Pe{\~{n}}a, D and Ruiz, E},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Carnero, Pe{\~{n}}a, Ruiz - 2004 - Persistence and kurtosis in GARCH and stochastic volatility models.pdf:pdf},
journal = {Journal of Financial Econometrics},
number = {2},
pages = {319--342},
title = {{Persistence and kurtosis in GARCH and stochastic volatility models}},
volume = {2},
year = {2004}
}
@article{lien:wilson,
author = {Lien, Donald and Wilson, Bradley K},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Lien, Wilson - 2001 - Multiperiod hedging in the presence of stochastic volatility.pdf:pdf},
journal = {IRFA},
number = {2},
pages = {395--406},
title = {{Multiperiod hedging in the presence of stochastic volatility}},
volume = {10},
year = {2001}
}
@book{Dieudonne:volumeII,
author = {Dieudonn{\'{e}}, Jean},
isbn = {0122155025},
publisher = {Academic Press, Inc.},
title = {{Treatise on Analysis. Volume II}},
volume = {II},
year = {1976}
}
@article{Hamilton1990,
author = {Hamilton, James D},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Hamilton - 1990 - Analysis of Time Series Subject to Changes in Regime.pdf:pdf},
journal = {Journal of Econometrics},
pages = {39--70},
title = {{Analysis of Time Series Subject to Changes in Regime}},
volume = {45},
year = {1990}
}
@article{Subasi2005,
author = {Subasi, A. and Alkan, A. and Koklukaya, E. and {Kemal Kiymik}, M.},
journal = {Neural networks},
pages = {985--997},
title = {{Wavelet neural network classification of EEG signals by using AR model with MLE preprocessing}},
volume = {18},
year = {2005}
}
@article{Huang2015,
abstract = {The emergent machine learning technique—extreme learning machines (ELMs)—has become a hot area of research over the past years, which is attributed to the growing research activities and significant contributions made by numerous researchers around the world. Recently, it has come to our attention that a number of misplaced notions and misunderstandings are being dissipated on the relationships between ELM and some earlier works. This paper wishes to clarify that (1) ELM theories manage to address the open problem which has puzzled the neural networks, machine learning and neuroscience communities for 60 years: whether hidden nodes/neurons need to be tuned in learning, and proved that in contrast to the common knowledge and conventional neural network learning tenets, hidden nodes/neurons do not need to be iteratively tuned in wide types of neural networks and learning models (Fourier series, biological learning, etc.). Unlike ELM theories, none of those earlier works provides theoretical foundations on feedforward neural networks with random hidden nodes; (2) ELM is proposed for both generalized single-hidden-layer feedforward network and multi-hidden-layer feedforward networks (including biological neural networks); (3) homogeneous architecture-based ELM is proposed for feature learning, clustering, regression and (binary/multi-class) classification. (4) Compared to ELM, SVM and LS-SVM tend to provide suboptimal solutions, and SVM and LS-SVM do not consider feature representations in hidden layers of multi-hidden-layer feedforward networks either.},
author = {Huang, Guang Bin},
doi = {10.1007/s12559-015-9333-0},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Huang - 2015 - What are Extreme Learning Machines Filling the gap between Frank Rosenblatt's dream and John von Neumann's puzzle.pdf:pdf},
issn = {18669964},
journal = {Cognitive Computation},
keywords = {Extreme learning machine,Feedforward neural network,QuickNet,Radial basis function network,Random vector functional link,Randomness},
number = {3},
pages = {263--278},
publisher = {Springer US},
title = {{What are Extreme Learning Machines? Filling the gap between Frank Rosenblatt's dream and John von Neumann's puzzle}},
volume = {7},
year = {2015}
}
@article{nfm,
author = {Marle, C.-M.},
journal = {Rend. Sem. Mat. Univers. Politecn. Torino},
number = {2},
pages = {227--251},
title = {{Mod{\'{e}}le d'action hamiltonienne d'un groupe the Lie sur une vari{\'{e}}t{\'{e}} symplectique}},
volume = {43},
year = {1985}
}
@article{Baillie79,
author = {Baillie, Richard T.},
journal = {Biometrika},
pages = {675--678},
title = {{Asymptotic prediction mean squared error for vector autoregressive models}},
volume = {66},
year = {1979}
}
@article{Iramina1996,
author = {Iramina, Keiji and Ueno, Shoogo},
issn = {0896-0267},
journal = {Brain Topography},
month = {mar},
number = {3},
pages = {297--301},
title = {{Source estimation of spontaneous MEG activity and auditory evoked responses in normal subjects during sleep}},
url = {http://link.springer.com/10.1007/BF01184788},
volume = {8},
year = {1996}
}
@misc{cvx,
author = {Grant, M and Boyd, S},
howpublished = {http://cvxr.com/cvx},
month = {apr},
title = {{CVX: Matlab Software for Disciplined Convex Programming, version 1.21}},
year = {2011}
}
@article{braioneRv1,
author = {Bauwens, Luc and Braione, Manuela and Storti, Giuseppe},
journal = {Econometrics and Statistics},
title = {{A dynamic component model for fore- casting high-dimensional realized covariance matrices}},
year = {2016}
}
@article{MuEEG,
author = {Pfurtscheller, Gert and Brunner, C. and Schl{\"{o}}gl, A. and {Lopes da Silva}, F.},
journal = {NeuroImage},
number = {1},
pages = {153--159},
title = {{Mu rhythm (de)synchronization and EEG single-trial classification of different motor imagery tasks}},
volume = {31},
year = {2006}
}
@article{Kukharenko2011_4,
annote = {in Ukrainian},
author = {Kukharenko, Oleksandra V.},
journal = {Bulletin of the Kyiv National Taras Shevchenko University},
pages = {125--130},
series = {Physic and Mathematics},
title = {{Existence conditions of solution of the first boundary value problem for system of delay equations}},
volume = {1},
year = {2011}
}
@phdthesis{BoussamaPHD,
author = {Boussama, F},
title = {{Ergodicit{\{}{\'{e}}{\}}, m{\{}{\'{e}}{\}}lange et estimation dans les mod{\{}{\`{e}}{\}}les GARCH}},
year = {1998}
}
@article{mcelroy2015direct,
author = {McElroy, Tucker},
journal = {Journal of Forecasting},
number = {4},
pages = {315--336},
publisher = {Wiley Online Library},
title = {{When are direct multi-step and iterative forecasts identical?}},
volume = {34},
year = {2015}
}
@phdthesis{Korosec1999,
author = {Korosec, D.},
title = {{Analysis of one-dimentional signals by processing of their time-frequency representation}},
year = {1999}
}
@techreport{Breiman1994,
abstract = {Bagging predictors is a method for generating multiple versions of a predictor and using these to get an aggregated predictor. The aggregation averages over the versions when predicting a numerical outcome and does a plurality vote when predicting a class. The multiple versions are formed by making bootstrap replicates of the learning set and using these as new learning sets. Tests on real and simulated data sets using classification and regression trees and subset selection in linear regression show that bagging can give substantial gains in accuracy. The vital element is the instability of the prediction method. If perturbing the learning set can cause significant changes in the predictor constructed, then bagging can improve accuracy.},
author = {Breiman, Leo},
booktitle = {Department of Statistics University of California},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Breiman - 1994 - Bagging predictors.pdf:pdf},
number = {2},
pages = {19},
title = {{Bagging predictors}},
url = {https://www.stat.berkeley.edu/{~}breiman/bagging.pdf},
year = {1994}
}
@article{ruiz1994,
author = {Ruiz, Esther},
journal = {Journal of Econometrics},
pages = {284--306},
title = {{Quasi-maximum likelihood estimation of stochastic volatility models}},
volume = {63},
year = {1994}
}
@book{Jurdjuevic2016,
author = {Jurdjuevic, Velimir},
title = {{Optimal Control and Geometry: Integrable Systems}},
year = {2016}
}
@article{Giacomini2006,
author = {Giacomini, Raffaella and Rossi, Barbara},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Giacomini, Rossi - 2006 - How Stable is the Forecasting Performance of the Yield Curve for Output Growth.pdf:pdf},
journal = {Oxford Bulletin of Economics and Statistics},
number = {SUPPLEMENT},
pages = {783--796},
title = {{How Stable is the Forecasting Performance of the Yield Curve for Output Growth ?*}},
volume = {68},
year = {2006}
}
@article{Ferrara2013,
abstract = {The global economic recession, referred to as the Great Recession, endured by the main industrialized countries during the period 2008–09, in the wake of the financial and banking crises, has pointed out the current importance of the financial sector in macroeconomics. In this article, we evaluate the predictive power of some major financial variables to anticipate GDP growth in euro area countries during this specific period of time. In this respect, we implement a Mixed Data Sampling (MIDAS)-based modelling approach, put forward by Ghysels et al. (20077. Ghysels, E., Sinko, A. and Valkanov, R. 2007. MIDAS regressions: further results and new directions. Econometric Reviews , 26: 53–90. [Taylor {\&} Francis Online]), that enables to forecast quarterly Gross Domestic Product (GDP) growth rates using exogenous variables sampled at higher frequencies. Empirical results show that, overall, stock prices help to improve the accuracy of GDP forecasts by comparison with a standard opinion survey variable, whereas oil prices and term spread appear to be less informative.},
author = {Ferrara, Laurent and Marsilli, Cl{\'{e}}ment},
journal = {Applied Economics Letters},
keywords = {Great Recession,MIDAS approach,financial variables,forecasting},
number = {3},
pages = {233--237},
title = {{Financial variables as leading indicators of GDP growth: Evidence from a MIDAS approach during the Great Recession}},
url = {http://www.tandfonline.com/doi/abs/10.1080/13504851.2012.689099},
volume = {20},
year = {2013}
}
@article{dhillon:tropp,
author = {Dhillon, Inderjit S and Tropp, Joel A},
doi = {10.1137/060649021},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Dhillon, Tropp - 2007 - Matrix nearness problems with Bregman divergences.pdf:pdf},
issn = {0895-4798},
journal = {SIAM J. Matrix Anal. Appl.},
number = {4},
pages = {1120--1146},
title = {{Matrix nearness problems with Bregman divergences}},
url = {http://dx.doi.org/10.1137/060649021},
volume = {29},
year = {2007}
}
@article{dasgupta2003elementary,
author = {Dasgupta, Sanjoy and Gupta, Anupam},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Dasgupta, Gupta - 2003 - An elementary proof of a theorem of Johnson and Lindenstrauss.pdf:pdf},
journal = {Random Structures {\&} Algorithms},
number = {1},
pages = {60--65},
publisher = {Wiley Online Library},
title = {{An elementary proof of a theorem of Johnson and Lindenstrauss}},
volume = {22},
year = {2003}
}
@article{Meissner1933,
author = {Meissner, W. and Ochsenfeld, R.},
journal = {Die Naturwissenschaften},
pages = {787--788},
title = {{A new effect in penetration of superconductors}},
volume = {21},
year = {1933}
}
@book{Malkin1949,
author = {Malkin, I. G.},
title = {{Lyapunov and Poincare methods in the theory of nonlinear perturbations}},
year = {1949}
}
@article{Wyffels2010,
abstract = {A good prediction of the future enables companies and governments to plan their investments, production and other needs. The demand for good forecasting techniques motivates many researchers coming from a wide variety of fields to develop methods for time series prediction. Many of these techniques are very complex to apply and demand lots of computational effort to execute. As an answer to this, we propose the use of Reservoir Computing, a recently developed technique for efficient training of recurrent neural networks, for monthly time series prediction. We will explain how Reservoir Computing in its basic form can be applied to time series prediction. Additionally we will extend this approach with different Reservoir Computing strategies such as seasonal adjustment or a Reservoir Computing based voting collective approach. We will investigate the performance of all the proposed strategies and compare its prediction accuracy with the linear forecasting procedure build in the Census Bureau's X-12-ARIMA program and a Nonlinear Autoregressive model using Least-Squares Support Vector Machines.},
author = {Wyffels, F. and Schrauwen, B.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Wyffels, Schrauwen - 2010 - A comparative study of Reservoir Computing strategies for monthly time series prediction.pdf:pdf},
journal = {Neurocomputing},
keywords = {Forecasting,Monthly time series,Reservoir Computing},
number = {10},
pages = {1958--1964},
title = {{A comparative study of Reservoir Computing strategies for monthly time series prediction}},
url = {http://www.sciencedirect.com/science/article/pii/S0925231210000962},
volume = {73},
year = {2010}
}
@article{cybenko,
author = {Cybenko, G.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Cybenko - 1989 - Approximation by superpositions of a sigmoidal function.pdf:pdf},
journal = {Mathematics of Control, Signals, and Systems},
month = {dec},
number = {4},
pages = {303--314},
publisher = {Springer-Verlag},
title = {{Approximation by superpositions of a sigmoidal function}},
volume = {2},
year = {1989}
}
@article{marsden_west_2001,
author = {Marsden, Jerrold E. and West, Matthew},
doi = {10.1017/S096249290100006X},
journal = {Acta Numerica},
pages = {357--514},
publisher = {Cambridge University Press},
title = {{Discrete mechanics and variational integrators}},
volume = {10},
year = {2001}
}
@article{raissi2017physics,
author = {Raissi, Maziar and Perdikaris, Paris and Karniadakis, George Em},
journal = {arXiv preprint arXiv:1711.10561},
title = {{Physics informed deep learning (part i): Data-driven solutions of nonlinear partial differential equations}},
year = {2017}
}
@article{kalman:original,
author = {Kalman, RE},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Kalman - 1960 - A new approach to linear filtering and prediction problems.pdf:pdf},
journal = {Trans. ASME, J. Basic Engineering},
pages = {35--45},
title = {{A new approach to linear filtering and prediction problems}},
url = {http://wl-s191-122.resnet.ucla.edu/book/basar{\_}control/09.pdf},
volume = {82D},
year = {1960}
}
@book{Dieudonne:volumeIV,
author = {Dieudonn{\'{e}}, Jean},
isbn = {0122155025},
publisher = {Academic Press, Inc.},
title = {{Treatise on Analysis. Volume IV}},
volume = {IV},
year = {1974}
}
@article{boal,
author = {Bobenko, A. I. and Reyman, A. G. and Semenov-Tian-Shansky, M. A.},
journal = {Commun. Math. Phys.},
pages = {321--354},
title = {{The Kowalewski top 99 years later: a Lax pair, generalizations and explicit solutions}},
volume = {122},
year = {1989}
}
@book{Wesson2011,
address = {Oxford},
author = {Wesson, John},
edition = {4th ed.},
pages = {812},
publisher = {Oxford Univ. Press},
title = {{Tokomaks}},
year = {2011}
}
@techreport{brilliant:volterra,
author = {Brilliant, M. B.},
institution = {Massachusetts Institute of Technology, Research Laboratory of Electronics},
title = {{Theory of the analysis of nonlinear systems}},
year = {1958}
}
@incollection{DynamicalSystemsMaass,
address = {Cambridge, MA},
author = {Legenstein, Robert and Maass, Wolfgang},
booktitle = {New directions in statistical signal processing: from systems to brain},
editor = {Haykin, S.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Legenstein, Maass - 2007 - What makes a dynamical system computationally powerful.pdf:pdf},
publisher = {MIT Press},
title = {{What makes a dynamical system computationally powerful?}},
year = {2007}
}
@article{Hoffmann2014,
abstract = {Making accurate judgments is an essential skill in everyday life. Although how different memory abilities relate to categorization and judgment processes has been hotly debated, the question is far from resolved. We contribute to the solution by investigating how individual differences in memory abilities affect judgment performance in 2 tasks that induced rule-based or exemplar-based judgment strategies. In a study with 279 participants, we investigated how working memory and episodic memory affect judgment accuracy and strategy use. As predicted, participants switched strategies between tasks. Furthermore, structural equation modeling showed that the ability to solve rule-based tasks was predicted by working memory, whereas episodic memory predicted judgment accuracy in the exemplar-based task. Last, the probability of choosing an exemplar-based strategy was related to better episodic memory, but strategy selection was unrelated to working memory capacity. In sum, our results suggest that different memory abilities are essential for successfully adopting different judgment strategies.},
author = {Hoffmann, Janina Anna and von Helversen, Bettina and Rieskamp, J{\"{o}}rg},
doi = {10.1037/a0037989},
isbn = {0096-3445},
issn = {1939-2222},
journal = {Journal of Experimental Psychology: General},
keywords = {episodic memory,judgment,rule-based and exemplar-based processes,working memory},
number = {6},
pages = {2242--2261},
pmid = {25285427},
title = {{Pillars of judgment: How memory abilities affect performance in rule-based and exemplar-based judgments.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0037989 http://www.ncbi.nlm.nih.gov/pubmed/25285427},
volume = {143},
year = {2014}
}
@book{Vapnik1998,
author = {Vapnik, Vladimir},
edition = {Adaptive a},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Vapnik - 1998 - Statistical Learning Theory.pdf:pdf},
publisher = {Wiley},
title = {{Statistical Learning Theory}},
year = {1998}
}
@inproceedings{BCHJ14,
address = {Working paper},
author = {Babaoglu, K. and Christoffersen, Peter F. and Heston, Steve and Jacobs, Kris},
title = {{Option valuation with volatility components, fat tails, and non-linear pricing kernels}},
year = {2014}
}
@article{Garcia1998,
author = {Garcia, Ren{\'{e}}},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Garcia - 1998 - Asymptotic Null Distribution of the Likelihood Ratio Test in Makov Switching Models.pdf:pdf},
journal = {Internation},
number = {3},
title = {{Asymptotic Null Distribution of the Likelihood Ratio Test in Makov Switching Models}},
volume = {39},
year = {1998}
}
@inproceedings{Roberts1991,
author = {Roberts, S. and Tarassenko, L.},
booktitle = {2nd Int. Conf. Artificial Neural Networks},
pages = {210--213},
title = {{EEG analysis using selforganisation}},
year = {1991}
}
@article{Atiya2000,
abstract = {How to efficiently train recurrent networks remains a challenging and active research topic. Most of the proposed training approaches are based on computational ways to efficiently obtain the gradient of the error function, and can be generally grouped into five major groups. In this study we present a derivation that unifies these approaches. We demonstrate that the approaches are only five different ways of solving a particular matrix equation. The second goal of this paper is develop a new algorithm based on the insights gained from the novel formulation. The new algorithm, which is based on approximating the error gradient, has lower computational complexity in computing the weight update than the competing techniques for most typical problems. In addition, it reaches the error minimum in a much smaller number of iterations. A desirable characteristic of recurrent network training algorithms is to be able to update the weights in an on-line fashion. We have also developed an on-line version of the proposed algorithm, that is based on updating the error gradient approximation in a recursive manner.},
author = {Atiya, A. F. and Parlos, A. G.},
doi = {10.1109/72.846741},
issn = {1045-9227},
journal = {IEEE transactions on neural networks / a publication of the IEEE Neural Networks Council},
keywords = {Acceleration,Approximation algorithms,Backpropagation algorithms,Computational complexity,Convergence,Differential equations,Error correction,Nonlinear dynamical systems,Optimal control,Time factors,accelerated convergence,algorithm unification,error function gradient,error gradient approximation,error minimum,learning (artificial intelligence),matrix equation,online weight updating,recurrent network training algorithms,recurrent neural nets,recurrent neural network training},
language = {English},
month = {jan},
number = {3},
pages = {697--709},
pmid = {18249797},
title = {{New results on recurrent network training: unifying the algorithms and accelerating convergence}},
volume = {11},
year = {2000}
}
@book{James2013,
address = {New York, NY},
author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
doi = {10.1007/978-1-4614-7138-7},
isbn = {978-1-4614-7137-0},
publisher = {Springer New York},
series = {Springer Texts in Statistics},
title = {{An Introduction to Statistical Learning}},
url = {http://link.springer.com/10.1007/978-1-4614-7138-7},
volume = {103},
year = {2013}
}
@inproceedings{Stubberuda,
author = {Stubberud, A.R. and Perryman, P.C.},
booktitle = {Conference Record of The Thirtieth Asilomar Conference on Signals, Systems and Computers},
doi = {10.1109/ACSSC.1996.600845},
isbn = {0-8186-7646-9},
pages = {141--145},
publisher = {IEEE Comput. Soc. Press},
title = {{Current state of system approximation for deterministic and stochastic systems}},
url = {http://ieeexplore.ieee.org/document/600845/},
volume = {1},
year = {1997}
}
@unpublished{Marcellino2010a,
annote = {
        

        

        

        From Duplicate 1 ( 
        

        

        

        
          

          

          

          The forecasting performance of real time estimates of the euro area output gap
          

          

          

        
        

        

        

         - Marcellino, Massimiliano; Musso, Alberto )

          

          

          

        
        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

      },
author = {Marcellino, Massimiliano and Musso, Alberto},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Marcellino, Musso - 2010 - The reliability of real time estimates of the euro area output gap.pdf:pdf;:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Marcellino, Musso - 2010 - The forecasting performance of real time estimates of the euro area output gap.pdf:pdf},
institution = {EUI},
series = {Department of Economics},
title = {{The forecasting performance of real time estimates of the euro area output gap}},
year = {2010}
}
@article{allopticreservoir2012,
author = {Duport, F. and Schneider, B. and Smerieri, A. and Haelterman, M. and Massar, S.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Duport et al. - 2012 - All-optical reservoir computing.pdf:pdf},
journal = {Optics Express},
number = {20},
pages = {22783--95},
title = {{All-optical reservoir computing}},
volume = {20},
year = {2012}
}
@book{Sangiorgio2021,
author = {Sangiorgio, Matteo and Dercole, Fabio and Guariso, Giorgio},
publisher = {Springer},
title = {{Deep Learning in Multi-step Prediction of Chaotic Dynamics: From Deterministic Models to Real-World Systems}},
year = {2021}
}
@incollection{fischer70,
author = {Fischer, A.},
booktitle = {Relativity},
editor = {et al. Carmelli, M.},
publisher = {Plenum Publishing},
title = {{A theory of superspace}},
year = {1970}
}
@book{dazord:delzant:1987,
address = {26,223--251},
author = {Dazord, P and Delzant, T},
booktitle = {J. Diff. Geom.},
pages = {223--251},
publisher = {J. Diff. Geom.},
title = {{Le probl{\{}{\`{e}}{\}}me g{\{}{\'{e}}{\}}n{\{}{\'{e}}{\}}ral des variables action-angle}},
volume = {26},
year = {1987}
}
@techreport{Wu:Guinney,
abstract = {The problems of dimension reduction and inference of statistical dependence are addressed by the modeling framework of learning gradients. The models we propose hold for Euclidean spaces as well as the manifold setting. The central quantity in this approach is an estimate of the gradient of the regression or classification function. Two quadratic forms are constructed from gradient estimates: the gradient outer product and gradient based diffusion maps. The first quantity can be used for supervised dimension reduction on manifolds as well as inference of a graphical model encoding dependencies that are predictive of a response variable. The second quantity can be used for nonlinear projections that incorporate both the geometric structure of the manifold as well as variation of the response variable on the manifold. We relate the gradient outer product to standard statistical quantities such as covariances and provide a simple and precise comparison of a variety of supervised dimensionality reduction methods. We provide rates of convergence for both inference of informative directions as well as inference of a graphical model of variable dependencies.},
author = {Wu, Qiang and Guinney, Justin and Maggioni, Mauro and Mukherjee, Sayan},
booktitle = {Journal of Machine Learning Research},
pages = {2175--2198},
title = {{Learning gradients: predictive models that infer geometry and statistical dependence}},
url = {http://www.jmlr.org/papers/volume11/wu10a/wu10a.pdf},
volume = {11},
year = {2010}
}
@article{vapnik:svms,
author = {Cortes, Corinna and Vapnik, Vladimir},
doi = {10.1007/BF00994018},
journal = {Machine Learning},
keywords = {efficient learning algorithms,neural networks,pattern recognition,polynomial classifiers,radial basis function classifiers},
pages = {273--297},
title = {{Support-vector networks}},
volume = {20},
year = {1995}
}
@article{Adams2010,
abstract = {We show that if {\$}\backslashmathcal{\{}X{\}}{\$} is a complete separable metric space and {\$}\backslashmathcal{\{}C{\}}{\$} is a countable family of Borel subsets of {\$}\backslashmathcal{\{}X{\}}{\$} with finite VC dimension, then, for every stationary ergodic process with values in {\$}\backslashmathcal{\{}X{\}}{\$}, the relative frequencies of sets {\$}C\backslashin\backslashmathcal{\{}C{\}}{\$} converge uniformly to their limiting probabilities. Beyond ergodicity, no assumptions are imposed on the sampling process, and no regularity conditions are imposed on the elements of {\$}\backslashmathcal{\{}C{\}}{\$}. The result extends existing work of Vapnik and Chervonenkis, among others, who have studied uniform convergence for i.i.d. and strongly mixing processes. Our method of proof is new and direct: it does not rely on symmetrization techniques, probability inequalities or mixing conditions. The uniform convergence of relative frequencies for VC-major and VC-graph classes of functions under ergodic sampling is established as a corollary of the basic result for sets.},
author = {Adams, Terrence M. and Nobel, Andrew B.},
journal = {Annals of Probability},
keywords = {Ergodic process,Uniform convergence,Uniform law of large numbers,VC class,VC dimension},
number = {4},
pages = {1345--1367},
title = {{Uniform convergence of Vapnik-Chervonenkis classes under ergodic sampling}},
volume = {38},
year = {2010}
}
@article{Ghysels2009a,
author = {Ghysels, Eric and Valkanov, Rossen and Rubia, Antonio},
journal = {EFA 2009 Bergen Meetings Paper, Available at SSRN: https://ssrn.com/abstract=1344742 or http://dx.doi.org/10.2139/ssrn.1344742},
title = {{Multi-period forecasts of volatility: direct, iterated, and mixed-data approaches}},
year = {2009}
}
@article{sparseJL,
author = {Kane, Daniel M. and Nelson, Jelani},
journal = {Journal of the ACM},
number = {1},
title = {{Sparser Johnson-Lindenstrauss transforms}},
volume = {61},
year = {2014}
}
@inproceedings{Holsch1989,
author = {Holschneider, M. and Kronland-Martinet, R. and Morlet, J. and Tchamitchian, Ph.},
booktitle = {Wavelets. Time-Frequency Methods and Phase Space},
pages = {286},
title = {{A real-time algorithm for signal analysis with the help of the wavelet transform}},
year = {1989}
}
@article{wu:PCA,
author = {Wu, Edmond H C and Yu, Philip L H and Li, W K},
journal = {International Journal of Neural Systems},
number = {5},
pages = {371--382},
title = {{Value at risk estimation using independent component analysis-generalized autoregressive conditional heteroscedasticity (ICA-GARCH) models}},
volume = {16},
year = {2006}
}
@article{Chris12,
author = {Christoffersen, Peter and Heston, S. L. and Jacobs, Kris},
journal = {Review of Financial Studies},
number = {8},
pages = {1963--2006},
title = {{Capturing option anomalies with a variance-dependent pricing kernel}},
volume = {26},
year = {2013}
}
@article{Verkindt1995,
abstract = {The tonotopic organization of the human auditory cortex has been investigated by means of scalp potential mapping and dipole modelling of the evoked response occurring around 100 msec after the stimulus onset. The major characteristics of the topographical changes observed with increasing stimulus frequency were statistically demonstrated. Using a 3-concentric sphere head model, the scalp potential distributions can be explained in first approximation by two equivalent current dipoles, located in the supratemporal plane and mimicking the activity of both auditory cortices. To take into account the temporal aspects of the brain activities, 3 time-varying dipole strategies were tested. Frequency dependence of the dipole orientation has been evidenced in both hemispheres with the 3 models, whereas no significant change in dipole position was found. The tilt in dipole orientation could be related to the folding geometry of Heschl's gyrus, which varies with depth. In agreement with previous MEG findings, this brings new evidence for a tonotopic organization of the auditory cortical area involved in the N100 wave generation. Moreover, distinct frequency dependences of the equivalent current dipoles were observed in the early and the late parts of the N100. This study demonstrates that simple dipolar models, applied on electrical data, make it possible to reveal functionally distinct cortical areas.},
author = {Verkindt, Chantal and Bertrand, Olivier and Perrin, Fran{\c{c}}ois and Echallier, Jean-Fran{\c{c}}ois and Pernier, Jacques},
issn = {01685597},
journal = {Electroencephalography and Clinical Neurophysiology/Evoked Potentials Section},
keywords = {Auditory cortex,Auditory evoked potential,Mapping,Time-varying dipole model,Tonotopic organization},
month = {mar},
number = {2},
pages = {143--156},
title = {{Tonotopic organization of the human auditory cortex: N100 topography and multiple dipole model analysis}},
url = {http://www.sciencedirect.com/science/article/pii/0168559794002427},
volume = {96},
year = {1995}
}
@article{Badescu2019,
author = {Badescu, Alexandru and Grigoryeva, Lyudmila and Ortega, Juan-Pablo},
journal = {Preprint},
title = {{Option pricing and hedging with one-step unscented Kalman filtered factors in non-affine stochastic volatility models}},
year = {2019}
}
@article{Rodriguez2009,
author = {Rodriguez, Alejandro and Ruiz, Esther},
doi = {10.1111/j.1467-9892.2008.00604.x},
issn = {01439782},
journal = {Journal of Time Series Analysis},
month = {mar},
number = {2},
pages = {167--178},
title = {{Bootstrap prediction intervals in state-space models}},
url = {http://doi.wiley.com/10.1111/j.1467-9892.2008.00604.x},
volume = {30},
year = {2009}
}
@article{Nuntalid2011,
author = {Nuntalid, Nuttapod and Dhoble, Kshitij and Kasabov, Nikola},
doi = {10.1007/978-3-642-24955-6_54},
isbn = {9783642249549},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Electroencephalograms (EEG),Spatio-Temporal Patterns,Stochastic neuron models,evolving probabilistic spiking neural networks},
number = {PART 1},
pages = {451--460},
title = {{EEG classification with BSA spike encoding algorithm and evolving probabilistic spiking neural network}},
volume = {7062 LNCS},
year = {2011}
}
@article{ShortlivedEEG,
author = {Pfurtscheller, Gert and Scherer, R. and M{\"{u}}ller-Putz, G. and {Lopes da Silva}, F.},
journal = {Eur J Neurosci},
number = {7},
pages = {1419--1426},
title = {{Short-lived brain state after cued motor imagery in naive subjects}},
volume = {28},
year = {2008}
}
@article{Devlin2018,
author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
journal = {CoRR},
title = {{BERT: Pre-training of deep bidirectional transformers for language understanding}},
url = {http://arxiv.org/abs/1810.04805},
volume = {abs/1810.0},
year = {2018}
}
@article{Christoffersen2010,
abstract = {Here we assess the return fitting and option valuation performance of generalized autoregressive conditional heteroscedasticity (GARCH) models. We compare component versus GARCH(1, 1) models, affine versus nonaffine GARCH models, and conditionally normal versus nonnormal GED models. We find that nonaffine models dominate affine models in terms of both fitting returns and option valuation. For the affine models, we find strong evidence in favor of the component structure for both returns and options; for the nonaffine models, the evidence is less convincing in option valuation. The evidence in favor of the nonnormal GED models is strong when fitting daily returns, but not when valuing options. Here we assess the return fitting and option valuation performance of generalized autoregressive conditional heteroscedasticity (GARCH) models. We compare component versus GARCH(1, 1) models, affine versus nonaffine GARCH models, and conditionally normal versus nonnormal GED models. We find that nonaffine models dominate affine models in terms of both fitting returns and option valuation. For the affine models, we find strong evidence in favor of the component structure for both returns and options; for the nonaffine models, the evidence is less convincing in option valuation. The evidence in favor of the nonnormal GED models is strong when fitting daily returns, but not when valuing options.},
author = {Christoffersen, Peter and Dorion, Christian and Jacobs, Kris and Wang, Yintian},
issn = {0735-0015},
journal = {Journal of Business {\&} Economic Statistics},
month = {oct},
number = {4},
pages = {483--502},
publisher = {Taylor {\&} Francis},
title = {{Volatility components, affine restrictions, and nonnormal innovations}},
url = {http://dx.doi.org/10.1198/jbes.2009.06122},
volume = {28},
year = {2010}
}
@book{lax:functional:analysis,
author = {Lax, Peter},
publisher = {Wiley-Interscience},
title = {{Functional Analysis}},
year = {2002}
}
@article{Chris2014JFQA,
author = {Christoffersen, Peter and Feunou, Bruno and Jacobs, Kris and Meddahi, Nour},
journal = {Journal of Financial and Quantitative Analysis},
number = {3},
pages = {663--697},
title = {{The economic value of realized volatility: using high-frequency returns for option valuation}},
volume = {49},
year = {2014}
}
@article{Larger:PRX,
author = {Larger, Laurent and Bayl, Antonio},
journal = {To appear in Physical Review X},
title = {{High-speed photonic Reservoir Computing using a time-delay-based architecture : Million words per second classification}},
year = {2017}
}
@article{Vrabie2009,
author = {Vrabie, D. and Lewis, F.},
journal = {Neural Networks},
number = {3},
pages = {237--246},
title = {{Neural network approach to continuous-time direct adaptive optimal control for partially unknown nonlinear systems}},
volume = {22},
year = {2009}
}
@article{OpticalNN2,
abstract = {We describe a nonlinear joint transform correlator-based two-layer neural network that uses a supervised learning algorithm for real-time face recognition. The system is trained with a sequence of facial images and is able to classify an input face image in real time. Computer simulations and optical experimental results are presented. The processor can be manufactured into a compact low-cost optoelectronic system. The use of the nonlinear joint transform correlator provides good noise robustness and good image discrimination.},
author = {Javidi, Bahram and Li, Jian and Tang, Qing},
doi = {10.1364/AO.34.003950},
issn = {0003-6935},
journal = {Applied Optics},
month = {jul},
number = {20},
pages = {3950},
publisher = {Optical Society of America},
title = {{Optical implementation of neural networks for face recognition by the use of nonlinear joint transform correlators}},
url = {https://www.osapublishing.org/abstract.cfm?URI=ao-34-20-3950},
volume = {34},
year = {1995}
}
@article{Rodriguez-Olmos2006,
author = {Rodr{\'{i}}guez-Olmos, Miguel},
journal = {Nonlinearity},
number = {4},
pages = {853--877},
title = {{Stability of relative equilibria with singular momentum values in simple mechanical systems}},
volume = {19},
year = {2006}
}
@article{At-Sahalia2000,
abstract = {Typical value-at-risk (VaR) calculations involve the probabilities of extreme dollar losses, based on the statistical distributions of market prices. Such quantities do not account for the fact that the same dollar loss can have two very different economic valuations, depending on business conditions. We propose a nonparametric VaR measure that incorporates economic valuation according to the state-price density associated with the underlying price processes. The state-price density yields VaR values that are adjusted for risk aversion, time preferences, and other variations in economic valuation. In the context of a representative agent equilibrium model, we construct an estimator of the risk-aversion coefficient that is implied by the joint observations on the cross-section of option prices and time-series of underlying assest values.},
author = {Aı̈t-Sahalia, Yacine and Lo, Andrew W.},
issn = {03044076},
journal = {Journal of Econometrics},
keywords = {C13,C22,G12,Nonparametric regression,Representative agent preferences,Risk aversion,Value-at risk},
month = {jan},
number = {1-2},
pages = {9--51},
title = {{Nonparametric risk management and implied risk aversion}},
url = {http://www.sciencedirect.com/science/article/pii/S0304407699000160},
volume = {94},
year = {2000}
}
@article{ER00,
author = {Engle, Robert F. and Rosenberg, J.},
journal = {Journal of Derivatives},
number = {1},
pages = {10--28},
title = {{Testing the volatility term structure using option hedging criteria}},
volume = {8},
year = {2000}
}
@techreport{bojowald:constrained,
author = {Bojowald, M. and Strobl, T.},
title = {{Poisson geometry in constrained systems}},
url = {hep-th/0112074},
year = {2002}
}
@article{hosking:portmanteau:corrigendum,
author = {Hosking, J R M},
issn = {0035-9246},
journal = {J. Roy. Statist. Soc. Ser. B},
number = {2},
pages = {303},
title = {{Corrigendum: ``{\{}E{\}}quivalent forms of the multivariate portmanteau statistic'' [{\{}J{\}}. {\{}R{\}}oy.$\backslash$ {\{}S{\}}tatist.$\backslash$ {\{}S{\}}oc.$\backslash$ {\{}S{\}}er.$\backslash$ {\{}B{\}} {\{}$\backslash$bf 43{\}} (1981), no.$\backslash$ 2, 261--262; {\{}MR{\}}0626774 (82h:62153)]}},
volume = {51},
year = {1989}
}
@article{Felices2012,
abstract = {This paper assesses the extent to which common factors underlie indicators of vulnerability to financial crises in emerging market economies (EMEs) and whether this link is changing over time. We use a Bayesian dynamic common factor model to estimate their common component in a sample of up to 41 countries including both developed as well as emerging economies. This permits us to interpret the component in common to both of them as a global factor. We introduce time variation into the model to investigate whether indicators are decoupling from global factors over time. While decoupling can be observed in a few cases, the exposure to global factors in most countries tends to fluctuate around the mean. Broadly speaking then, the answer is no.},
author = {Felices, Guillermo and Wieladek, Tomasz},
doi = {10.1016/j.jbankfin.2011.06.013},
issn = {03784266},
journal = {Journal of Banking {\&} Finance},
keywords = {Bayesian dynamic common factor models,C11,C22,Decoupling,F34,Financial crises},
month = {feb},
number = {2},
pages = {321--331},
title = {{Are emerging market indicators of vulnerability to financial crises decoupling from global factors?}},
url = {http://www.sciencedirect.com/science/article/pii/S0378426611002020},
volume = {36},
year = {2012}
}
@article{variance:swaps,
author = {Badescu, Alexandru M. and Cui, Zhenyu and Ortega, Juan-Pablo},
journal = {To appear in the Annals of Operations Research},
title = {{Closed-form variance swap prices under general affine GARCH models and their continuous-time limits}},
year = {2018}
}
@article{E2017a,
author = {E, W.},
journal = {Commun. Math. Stat.},
number = {1},
pages = {1--11},
title = {{A proposal on machine learning via dynamical systems}},
volume = {5},
year = {2017}
}
@misc{Wyffels2008,
abstract = {In this paper we combine wavelet decomposition and recurrent neural networks to provide fast and accurate time series predictions. The original time series is decomposed by means of wavelet decomposition into a hierarchy of time series which are easier to predict. The prediction core of our solution is given by reservoir computing, which is a recently developed technique for the very fast training of recurrent neural networks. The three time series of the ESTSP 2008 competition will be used as an illustration for our method.},
author = {Wyffels, Francis and Schrauwen, Benjamin and Stroobandt, Dirk},
booktitle = {ESTSP 2008 European Symposium on Time Series Prediction},
keywords = {Technology and Engineering,reservoir computing,time series prediction},
language = {eng},
pages = {149--158},
publisher = {Multiprint Oy/Otamedia},
title = {{Using reservoir computing in a decomposition approach for time series prediction}},
url = {https://archive.ugent.be/record/678857},
year = {2008}
}
@techreport{Ghysels2006,
abstract = {Surveys of forecasters, containing respondents'predictions of future values of growth, in- ‡ation and other key macroeconomic variables, receive a lot of attention in the {\ldots}nancial press, from investors, and from policy makers. They are apparently widely perceived to provide useful information about agents'expectations. Nonetheless, these survey forecasts su¤er from the crucial disadvantage that they are often quite stale, as they are released only infrequently, such as on a quarterly basis. In this paper, we propose methods for using asset price data to construct daily forecasts of upcoming survey releases, which we can then eval- uate. Our methods allow us to estimate what professional forecasters would predict if they were asked to make a forecast each day, making it possible to measure the e¤ects of events and news announcements on expectations. We apply these methods to forecasts for several macroeconomic variables from both the Survey of Professional Forecasters and Consensus Forecasts.},
annote = {
        From Duplicate 2 ( 
        
          Forecasting Professional Forecasters
        
         - Ghysels, Eric; Wright, Jonathan H )

        
        

        

        

      },
author = {Ghysels, Eric and Wright, Jonathan H},
booktitle = {Journal of Business and Economic Statistics},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Ghysels, Wright - 2006 - Forecasting Professional Forecasters.pdf:pdf},
institution = {Federal Reserve Board, Washington, D.C.},
issn = {07350015},
keywords = {Forecast evaluation,Kalman smoother,Kalman {\ldots}lter,Mixed frequency data sampling,News Announcements.,Ra- tional expectations,Survey forecasts},
number = {4},
pages = {504--516},
publisher = {Federal Reserve Board, Washington, D.C.},
series = {Finance and Economics Discussion},
title = {{Forecasting Professional Forecasters}},
type = {Working Paper},
url = {http://pubs.amstat.org/doi/abs/10.1198/jbes.2009.06044},
volume = {27},
year = {2006}
}
@article{Bougerol1992,
abstract = {We consider the multivariate equation X{\_}{\{}n+1{\}}=A{\_}{\{}n+1{\}}+B{\_}{\{}n+1{\}} with i.i.d. coefficients which have only a logarithmic moment. We give a necessary and sufficient condition for existence of a strictly stationary solution independent of the future.As an application we characterize the multivariate ARMA equations with general noise which have such a solution.},
author = {Bougerol, Philippe and Picard, Nico},
journal = {The Annals of Probability},
title = {{Strict Stationarity of Generalized Autoregressive Processes}},
year = {1992}
}
@article{Brewer1973,
author = {Brewer, K. R. W.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Brewer - 1973 - Some consequences of temporal aggregation and systematic sampling for ARMA and ARMAX models.pdf:pdf},
journal = {Journal of Econometrics},
pages = {133--154},
title = {{Some consequences of temporal aggregation and systematic sampling for ARMA and ARMAX models}},
volume = {1},
year = {1973}
}
@article{Robert2012,
author = {Robert, Christian Yann and Rosenbaum, Mathieu},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Robert, Rossenbaum - 2010 - Volatility and covariation estimation when miscrostructure noise and trading times are endogeous.pdf:pdf},
issn = {09601627},
journal = {Mathematical Finance},
month = {jan},
number = {1},
pages = {133--164},
title = {{Volatility and covariation estimation when microstructure noise and trading times are endogenous}},
url = {http://doi.wiley.com/10.1111/j.1467-9965.2010.00454.x},
volume = {22},
year = {2012}
}
@article{benenti:tulczyjew:1982,
author = {Benenti, S and Tulczyjew, W M},
journal = {C. R. Acad. Sc. Paris},
pages = {561--564},
title = {{Remarques sur les r{\{}{\'{e}}{\}}ductions symplectiques}},
volume = {294},
year = {1982}
}
@article{eroglu2017synchronisation,
author = {Eroglu, Deniz and Lamb, Jeroen S W and Pereira, Tiago},
journal = {Contemporary Physics},
number = {3},
pages = {207--243},
publisher = {Taylor {\&} Francis},
title = {{Synchronisation of chaos and its applications}},
volume = {58},
year = {2017}
}
@article{Choi2005,
abstract = {This article derives an analyticalapproximation to the optionformula for a spot asset price whose conditional variance equation follows a nonlinear asymmetric GARCH (NGARCH) process. The approximate optionformula, which is just a volatility adjustment in comparison to the Black–Scholes (BS) formula, is very simple and provides the volatility term structure of spot asset prices. Also, the formula shows that the most characteristic feature of an NGARCH model appears in the vega of a European option, which depends on both the spread between the long-run variance and the current one and a parameter reproduced from the stationary property of the conditional variance. This methodology can be easily extended to an optionformula for the generalized GARCH process.},
author = {Choi, Youngsoo},
doi = {10.1016/j.irfa.2004.06.007},
issn = {10575219},
journal = {International Review of Financial Analysis},
keywords = {black–scholes formula,garch process,greek letters,moment generating function,volatility term structure},
month = {jan},
number = {2},
pages = {149--164},
title = {{An analytical approximation to the option formula for the GARCH model}},
url = {http://dx.doi.org/10.1016/j.irfa.2004.06.007},
volume = {14},
year = {2005}
}
@article{niyogi:girosi,
abstract = {Feedforward networks together with their training algorithms are a class of regression techniques that can be used to learn to perform some task from a set of examples. The question of generalization of network performance from a finite training set to unseen data is clearly of crucial importance. In this article we first show that the generalization error can be decomposed into two terms: the approximation error, due to the insufficient representational capacity of a finite sized network, and the estimation error, due to insufficient information about the target function because of the finite number of samples. We then consider the problem of learning functions belonging to certain Sobolev spaces with gaussian radial basis functions. Using the above-mentioned decomposition we bound the generalization error in terms of the number of basis functions and number of examples. While the bound that we derive is specific for radial basis functions, a number of observations deriving from it apply to any approximation technique. Our result also sheds light on ways to choose an appropriate network architecture for a particular problem and the kinds of problems that can be effectively solved with finite resources, i.e., with a finite number of parameters and finite amounts of data.},
author = {Niyogi, Partha and Girosi, Federico},
doi = {10.1162/neco.1996.8.4.819},
issn = {08997667},
journal = {Neural Computation},
number = {4},
pages = {819--842},
title = {{On the relationship between generalization error, hypothesis complexity, and sample complexity for radial basis functions}},
volume = {8},
year = {1996}
}
@misc{E.J.GodolphinandJ.M.Unwin,
author = {{Godolphin, E. J. and Unwin}, J. M.},
booktitle = {Biometrika},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Godolphin, E. J. and Unwin - 1983 - Evaluation of the Covariance Matrix for the Maximum Likelihood Estimator of a Gaussian Autoregressiv.pdf:pdf},
pages = {279--284},
title = {{Evaluation of the Covariance Matrix for the Maximum Likelihood Estimator of a Gaussian Autoregressive-Moving Average Process}},
url = {http://www.jstor.org/discover/10.2307/2335968?uid=3738032{\&}uid=2134{\&}uid=2{\&}uid=70{\&}uid=4{\&}sid=47698873685407},
urldate = {2012-04-13},
year = {1983}
}
@unpublished{Kanagawa2018,
author = {Kanagawa, Motonobu and Hennig, Philipp and Sejdinovic, Dino and Sriperumbudur, Bharath K.},
title = {{Gaussian pocesses and kernel methods: A review on connections and equivalences}},
year = {2018}
}
@article{Bahoura1997,
author = {Bahoura, M. and Hassani, M. and Hubin, M.},
journal = {Computer methods and programs in biomedicine},
number = {1},
pages = {35--44},
title = {{DSP implemention of wavelet transform for real time ECG wave forms detection and heart rate analysis}},
volume = {52},
year = {1997}
}
@incollection{acg,
author = {Arms, J. M. and Cushman, R. and Gotay, M. J.},
booktitle = {The Geometry of Hamiltonian Systems},
pages = {33--51},
publisher = {Springer Verlag},
title = {{A universal reduction procedure for Hamiltonian groupactions}},
year = {1991}
}
@article{sandberg:esn,
abstract = {Some strong approximation results concerning discrete-time nonlinear input-output maps are presented. The results concern maps G that are causal, time invariant, and satisfy certain continuity and approximately finite-memory conditions. It is shown that such G's can be uniformly approximated arbitrarily well by finite sums. This can be used, for example, as a basis for adaptive filtering or for the adaptive identification of G's. Similar propositions hold also for G's that are not necessarily causal},
author = {Sandberg, Irwin W.},
doi = {10.1109/31.76498},
issn = {00984094},
journal = {IEEE Transactions on Circuits and Systems},
number = {5},
pages = {564--566},
title = {{Approximation theorems for discrete-time systems}},
volume = {38},
year = {1991}
}
@article{Chen2014a,
abstract = {The emergence of large scaled sensor networks facilitates the collection of large amounts of real-time data to monitor and control complex engineering systems. However, in many cases the collected data may be incomplete or inconsistent, while the underlying environment may be time-varying or un-formulated. In this paper, we have developed an innovative cognitive fault diagnosis framework that tackles the above challenges. This framework investigates fault diagnosis in the model space instead of in the signal space. Learning in the model space is implemented by fitting a series of models using a series of signal segments selected with a rolling window. By investigating the learning techniques in the fitted model space, faulty models can be discriminated from healthy models using one-class learning algorithm. The framework enables us to construct fault library when unknown faults occur, which can be regarded as cognitive fault isolation. This paper also theoretically investigates how to measure the pairwise distance between two models in the model space and incorporates the model distance into the learning algorithm in the model space. The results on three benchmark applications and one simulated model for the Barcelona water distribution network have confirmed the effectiveness of the proposed framework.},
archivePrefix = {arXiv},
arxivId = {1210.8291},
author = {Chen, Huanhuan and Tino, Peter and Rodan, Ali and Yao, Xin},
doi = {10.1109/TNNLS.2013.2256797},
eprint = {1210.8291},
isbn = {2162-237X VO  - 25},
issn = {2162237X},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
keywords = {Cognitive fault diagnosis,fault detection,learning in the model space,one class learning,reservoir computing (RC)},
pmid = {26017442},
title = {{Learning in the model space for cognitive fault diagnosis}},
year = {2014}
}
@article{E2019,
abstract = {Optimal a priori estimates are derived for the population risk, also known as the generalization error, of a regularized residual network model. An important part of the regularized model is the usage of a new path norm, called the weighted path norm, as the regularization term. The weighted path norm treats the skip connections and the nonlinearities differently so that paths with more nonlinearities are regularized by larger weights. The error estimates are a priori in the sense that the estimates depend only on the target function, not on the parameters obtained in the training process. The estimates are optimal, in a high dimensional setting, in the sense that both the bound for the approximation and estimation errors are comparable to the Monte Carlo error rates. A crucial step in the proof is to establish an optimal bound for the Rademacher complexity of the residual networks. Comparisons are made with existing norm-based generalization error bounds.},
archivePrefix = {arXiv},
arxivId = {1903.02154},
author = {E, Weinan and Ma, Chao and Wang, Qingcan},
eprint = {1903.02154},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/E, Ma, Wang - 2019 - A Priori Estimates of the Population Risk for Residual Networks.pdf:pdf},
keywords = {a priori estimate,residual network,weighted path norm},
pages = {1--19},
title = {{A Priori Estimates of the Population Risk for Residual Networks}},
url = {http://arxiv.org/abs/1903.02154},
year = {2019}
}
@inproceedings{fliess1981group,
author = {Fliess, Michael and Normand-Cyrot, Dorothee},
booktitle = {1981 20th IEEE Conference on Decision and Control including the Symposium on Adaptive Processes},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Fliess, Normand-Cyrot - 1981 - A group-theoretic approach to discrete-time non-linear controllability.pdf:pdf},
organization = {IEEE},
pages = {551--557},
title = {{A group-theoretic approach to discrete-time non-linear controllability}},
year = {1981}
}
@unpublished{CLplugin_Wu2013,
author = {Wu, Billy and Yao, Qiwei and Zhu, Shiwu},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Wu, Yao, Zhu - 2013 - Estimation in the presence of many nuisance parameters composite likelihood and plug-in likelihood.pdf:pdf},
title = {{Estimation in the presence of many nuisance parameters: composite likelihood and plug-in likelihood}},
year = {2013}
}
@article{clement:midas,
author = {Ferrara, Laurent and Marsilli, Cl{\'{e}}ment and Ortega, Juan-Pablo},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Ferrara, Marsilli, Ortega - 2014 - Forecasting growth during the Great Recession is financial volatility the missing ingredient.pdf:pdf},
journal = {Economic Modelling},
pages = {44--50},
title = {{Forecasting growth during the Great Recession: is financial volatility the missing ingredient?}},
volume = {36},
year = {2014}
}
@article{Bertrand1991,
author = {Bertrand, O and Perrin, F and Pernier, J},
issn = {0365-5237},
journal = {Acta oto-laryngologica. Supplementum},
keywords = {Acoustic Stimulation,Auditory Cortex,Auditory Cortex: anatomy {\&} histology,Auditory Cortex: physiology,Brain Mapping,Brain Mapping: instrumentation,Brain Mapping: methods,Computer Graphics,Electrodes,Electromagnetic Fields,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Humans,Models, Neurological},
month = {jan},
pages = {116--22; discussion 123},
title = {{Evidence for a tonotopic organization of the auditory cortex observed with auditory evoked potentials.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/1814142},
volume = {491},
year = {1991}
}
@article{Fasso2001,
author = {Fass{\`{o}}, Francesco and Lewis, Debra},
issn = {0003-9527},
journal = {Archive for Rational Mechanics and Analysis},
month = {jul},
number = {4},
pages = {259--292},
title = {{Stability properties of the Riemann ellipsoids}},
url = {http://www.springerlink.com/index/10.1007/PL00004245},
volume = {158},
year = {2001}
}
@phdthesis{Story2006,
author = {Story, Mark Allan},
school = {The University of Texas at Austin},
title = {{On Approximation Structures for Nonlinear Systems}},
year = {2006}
}
@article{AKO2018,
author = {Audrino, Francesco and Kostrov, Alexander and Ortega, Juan-Pablo},
journal = {To appear in the Journal of Financial and Quantitative Analysis},
title = {{Extending the logit model with Midas aggregation: the case of US bank failures}},
year = {2018}
}
@article{Berry1996,
author = {Berry, M. V.},
journal = {Proc. Royal Soc. London, Series A},
pages = {1207--1220},
title = {{The levitron: an adiabatic trap for spins}},
volume = {452},
year = {1996}
}
@article{ERDERS_EEG,
author = {Graimann, B. and Huggins, J. E. and Levine, S. P. and Pfurtscheller, Gert},
journal = {Clin Neurophysiol.},
number = {1},
pages = {43--47},
title = {{Visualization of significant ERD/ERS patterns in multichannel EEG and ECoG data}},
volume = {113},
year = {2002}
}
@article{Kozorez1974,
author = {Kozorez, V. V.},
journal = {Bull. of the Ac. of Sc. of USSR. Series: Mechanics of a Rigid Body (in Russian)},
pages = {29--34},
title = {{About a problem of two magnets}},
volume = {3},
year = {1974}
}
@article{Stram1986,
author = {Stram, Daniel O. and Wei, William W. S.},
doi = {10.1111/j.1467-9892.1986.tb00495.x},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Stram, Wei - 1986 - Temporal Aggregation in the Arima Process.pdf:pdf},
issn = {0143-9782},
journal = {Journal of Time Series Analysis},
keywords = {aggregate model,aggregation,arima process,change of model form},
month = {jul},
number = {4},
pages = {279--292},
title = {{Temporal Aggregation in the Arima Process}},
url = {http://doi.wiley.com/10.1111/j.1467-9892.1986.tb00495.x},
volume = {7},
year = {1986}
}
@incollection{optimal:mm,
address = {New York},
author = {Ortega, Juan-Pablo and Ratiu, Tudor S.},
booktitle = {Geometry, Mechanics, and Dynamics},
doi = {10.1007/0-387-21791-6_11},
pages = {329--362},
publisher = {Springer-Verlag},
title = {{The optimal momentum map}},
url = {http://link.springer.com/10.1007/0-387-21791-6{\_}11},
year = {2002}
}
@article{chossat:maximal,
author = {Chossat, P and Koenig, M and Montaldi, J},
journal = {C. R. Acad. Sci. Paris S{\{}{\'{e}}{\}}r. I Math.},
pages = {25--30},
title = {{Bifurcation g{\{}{\'{e}}{\}}n{\{}{\'{e}}{\}}rique d'ondes d'isotropie maximale}},
volume = {320},
year = {1995}
}
@article{swirl:paper,
author = {Vandoorne, Kristof and Mechet, Pauline and {Van Vaerenbergh}, Thomas and Fiers, Martin and Morthier, Geert and Verstraeten, David and Schrauwen, Benjamin and Dambre, Joni and Bienstman, Peter},
doi = {10.1038/ncomms4541},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Vandoorne et al. - 2014 - Experimental demonstration of reservoir computing on a silicon photonics chip.pdf:pdf},
issn = {2041-1723},
journal = {Nature Communications},
month = {mar},
pages = {78--80},
publisher = {Nature Publishing Group},
title = {{Experimental demonstration of reservoir computing on a silicon photonics chip}},
url = {http://www.nature.com/doifinder/10.1038/ncomms4541},
volume = {5},
year = {2014}
}
@article{AN07b,
author = {Alexander, Carol and Nogueira, Leonardo M.},
issn = {1469-7688},
journal = {Quantitative Finance},
month = {oct},
number = {5},
pages = {473--479},
publisher = {Routledge},
title = {{Model-free price hedge ratios for homogeneous claims on tradable assets}},
url = {http://dx.doi.org/10.1080/14697680601101700},
volume = {7},
year = {2007}
}
@article{chen1958integration,
author = {Chen, Kuo-Tsai},
journal = {Transactions of the American Mathematical Society},
number = {2},
pages = {395--407},
publisher = {JSTOR},
title = {{Integration of paths--A faithful representation of paths by noncommutative formal power series}},
volume = {89},
year = {1958}
}
@unpublished{Denkl2009,
abstract = {We consider the performance of non-optimal hedging strategies in exponential L$\backslash$'evy models. Given that both the payoff of the contingent claim and the hedging strategy admit suitable integral representations, we use the Laplace transform approach of Hubalek et al. (2006) to derive semi-explicit formulas for the resulting mean squared hedging error in terms of the cumulant generating function of the underlying L$\backslash$'evy process. In two numerical examples, we apply these results to compare the efficiency of the Black-Scholes hedge and the model delta to the mean-variance optimal hedge in a normal inverse Gaussian and a diffusion-extended CGMY L$\backslash$'evy model.},
archivePrefix = {arXiv},
arxivId = {0911.4859},
author = {Denkl, Stephan and Goy, Martina and Kallsen, Jan and Muhle-Karbe, Johannes and Pauwels, Arnd},
eprint = {0911.4859},
month = {nov},
pages = {25},
title = {{On the performance of delta hedging strategies in exponential L{\'{e}}vy models}},
url = {http://arxiv.org/abs/0911.4859},
year = {2009}
}
@incollection{MR1929373,
address = {Berlin},
author = {Duan, Jin-Chuan and Pliska, Stanley R},
booktitle = {Advances in finance and stochastics},
pages = {85--99},
publisher = {Springer},
title = {{Option pricing for co-integrated assets}},
year = {2002}
}
@book{cucker:zhou:book,
abstract = {The goal of learning theory is to approximate a function from sample values. To attain this goal it draws on statistics, approximation theory and algorithmics. This book aims to give a general overview of the theoretical foundations of learnign theory. The framework of learning -- Basic hypothesis spaces -- Estimating the sample error -- Polynomial decay of the approximation error -- Estimating covering numbers -- Logarithmic decay of the approximation error -- On the bias-variance problem -- Least squares regularization -- Support vector machines for classification -- General regularized classifiers.},
author = {Cucker, Felipe and Zhou, Ding-Xuan.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Cucker, Zhou - 2007 - Learning Theory An Approximation Theory Viewpoint(2).pdf:pdf},
pages = {224},
publisher = {Cambridge University Press},
title = {{Learning Theory : An Approximation Theory Viewpoint}},
year = {2007}
}
@unpublished{Arora2017a,
abstract = {We show that training of generative adversarial network (GAN) may not have good general- ization properties; e.g., training may appear successful but the trained distribution may be far from target distribution in standard metrics. However, generalization does occur for a weaker metric called neural net distance. It is also shown that an approximate pure equilibrium exists 1 in the discriminator/generator game for a special class of generators with natural training objectives when generator capacity and training set sizes are moderate. This existence of equilibrium inspires mix+gan protocol, which can be combined with any existing GAN training, and empirically shown to improve some of them.},
author = {Arora, Sanjeev and Ge, Rong and Liang, Yingyu and Ma, Tengyu and Zhang, Yi},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Arora et al. - 2017 - Generalization and Equilibrium in Generative Adversarial Nets (GANs).pdf:pdf},
title = {{Generalization and Equilibrium in Generative Adversarial Nets (GANs)}},
year = {2017}
}
@article{huang:guo:2,
address = {Berlin},
author = {Huang, Shih-Feng and Guo, Meihui},
editor = {Duan, Jin-Chuan and Gentle, J. and Hardle, W.},
journal = {Handbook of Computational Finance},
pages = {605--631},
publisher = {Springer-Verlag},
title = {{Dynamic programming and hedging strategies in discrete time}},
year = {2012}
}
@article{mre,
author = {Montaldi, J. A.},
journal = {Nonlinearity},
pages = {449--466},
title = {{Persistence and stability of relative equilibria}},
volume = {10},
year = {1997}
}
@article{Bouvrie2017,
author = {Bouvrie, Jake and Hamzi, Boumediene},
journal = {Journal of Computational Dynamics},
number = {(1-2)},
pages = {1--19},
title = {{Kernel methods for the approximation of some key quantities of nonlinear systems}},
volume = {4},
year = {2017}
}
@book{Zubov1984,
author = {Zubov, V. I.},
title = {{Stability of Motion}},
year = {1984}
}
@article{Guo2020,
author = {Guo, Mengmeng and Su, Jingyong and Sun, Li and Cao, Guofeng},
journal = {Journal of Applied Statistics},
number = {1},
pages = {28--44},
title = {{Statistical regression analysis of functional and shape data}},
volume = {47},
year = {2020}
}
@article{duan2009,
author = {Duan, Jin-Chuan and Wang, Yazhen and Zou, Jian},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Duan, Wang, Zou - 2009 - Convergence speed of GARCH option price to diffusion option price.pdf:pdf},
journal = {International Journal of Theoretical and Applied Finance},
number = {3},
pages = {359--391},
title = {{Convergence speed of GARCH option price to diffusion option price}},
volume = {12},
year = {2009}
}
@article{Baffigi2004,
author = {Baffigi, Alberto and Golinelli, Roberto and Parigi, Giuseppe},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Baffigi, Golinelli, Parigi - 2004 - Bridge models to forecast the euro area GDP.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {bridge model,out-of-sample forecasting accuracy,short-term gdp forecast for,the euro area},
month = {jul},
number = {3},
pages = {447--460},
title = {{Bridge models to forecast the euro area GDP}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0169207003000670},
volume = {20},
year = {2004}
}
@article{Zang:iglesias,
abstract = {The conditions under which discrete-time nonlinear affine systems possess fading memory are explored. A sufficient condition is given based on discrete-time Lyapunov theory; whereas a necessary condition is provided based on the relationship between the stability and the continuity of this system. ?? 2003 The Franklin Institute. Published by Elsevier Ltd. All rights reserved.},
author = {Zang, Guoqiang and Iglesias, Pablo A.},
doi = {10.1016/j.jfranklin.2003.11.002},
issn = {00160032},
journal = {Journal of the Franklin Institute},
keywords = {Exponential stability,Fading memory,Lyapunov theory,Nonlinear system},
number = {6-7},
pages = {489--502},
title = {{Fading memory and stability}},
volume = {340},
year = {2004}
}
@article{Lutkepohl1989,
author = {L{\"{u}}tkepohl, Helmut},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/L{\"{u}}tkepohl - 1989 - Prediction of temporally aggregated systems involving both stock and flow variables.pdf:pdf},
journal = {Statistical Papers},
pages = {279--293},
title = {{Prediction of temporally aggregated systems involving both stock and flow variables}},
url = {http://www.springerlink.com/index/A222T26606021K8U.pdf},
volume = {30},
year = {1989}
}
@article{MR1847273,
author = {Duan, Jin-Chuan and Simonato, Jean-Guy},
issn = {0165-1889},
journal = {J. Econom. Dynam. Control},
number = {11},
pages = {1689--1718},
title = {{American option pricing under GARCH by a Markov chain approximation}},
volume = {25},
year = {2001}
}
@book{trust:region,
address = {Philadelphia, PA},
author = {Conn, Andrew R and Gould, Nicholas I M and Toint, Philippe L},
isbn = {0-89871-460-5},
pages = {xx+959},
publisher = {Society for Industrial and Applied Mathematics (SIAM)},
series = {MPS/SIAM Series on Optimization},
title = {{Trust-region methods}},
year = {2000}
}
@book{bloch-book,
author = {Bloch, A.},
booktitle = {Interdisciplinary Applied Mathematics},
publisher = {Springer-Verlag},
title = {{Nonholonomic Mechanics and Control}},
volume = {24},
year = {2003}
}
@article{Li2018a,
author = {Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
journal = {Advances in Neural Information Processing Systems},
pages = {6391--6401},
title = {{Visualizing the loss landscape of neural nets}},
year = {2018}
}
@article{ambrosetti:mancini:82,
author = {Ambrosetti, A. and Mancini, G.},
journal = {J. Differential Equations},
pages = {249--256},
title = {{On a theorem by Ekeland and Lasry concerning the number of periodic Hamiltonian trajectories}},
volume = {43},
year = {1982}
}
@article{Stein81,
author = {Stein, S M.},
journal = {Annals of Statistics},
number = {6},
pages = {1135--1151},
title = {{Estimation of the mean of a multivariate normal distribution}},
volume = {9},
year = {1981}
}
@article{sandberg:tive-varying,
author = {Sandberg, Irwin W.},
journal = {International Journal of Circuit Theory and Applications},
keywords = {1,4,input,introduction and summary,is concerned in part,output stability,output stability theory,the form,time-varying linear systems,with operator relations of},
pages = {507--512},
title = {{Time-varying linear systems and input-output stability}},
volume = {28},
year = {2000}
}
@book{BauwensHandbook,
abstract = {"The main purpose of this handbook is to illustrate the mathematically fundamental implementation of various volatility models in the banking and financial industries, both at home and abroad, through use of real-world, time-sensitive applications. Conceived and written by over two-dozen experts in the field, the focus is to cohesively demonstrate how 'volatile' certain statistical decision-making techniques can be when solving a range of financial problems. By using examples derived from consulting projects, current research and course instruction, each chapter in the book offers a systematic understanding of the recent advances in volatility modeling related to real-world situations. Every effort is made to present a balanced treatment between theory and practice, as well as to showcase how accuracy and efficiency in implementing various methods can be used as indispensable tools in assessing volatility rates. Unique to the book is in-depth coverage of GARCH-family models, contagion, and model comparisons between different volatility models. To by-pass tedious computation, software illustrations are presented in an assortment of packages, ranging from R, C++, EXCEL-VBA, Minitab, to JMP/SAS"-- Volatility models -- Nonlinear models for autoregressive conditional heteroskedasticity -- Mixture and regime-switching GARCH models -- Forecasting high dimensional covariance matrices -- Mean, volatility, and skewness spillovers in equity markets -- Relating stochastic volatility estimation methods -- Multivariate stochastic volatility models -- Model selection and testing of conditional and stochastic volatility models -- Multiplicative error models -- Locally stationary volatility modeling -- Nonparametric and semiparametric volatility models : specification, estimation, and testing -- Copula-based volatility models -- Realized volatility : theory and applications -- Likelihood-based volatility estimators in the presence of market microstructure noise -- HAR modeling for realized volatility forecasting -- Forecasting volatility with MIDAS -- Jumps -- Nonparametric tests for intraday jumps : impact of periodicity and microstructure noise -- Volatility forecasts evaluation and comparison.},
author = {Bauwens, Luc and Hafner, Christian. and Laurent, S{\'{e}}bastien},
isbn = {9780470872512},
pages = {543},
publisher = {Wiley},
title = {{Handbook of volatility models and their applications}},
year = {2012}
}
@incollection{Rappelsb1975,
author = {Rappelsberger, P. and Petsche, H.},
booktitle = {Computerized EEG Analysis},
pages = {27--40},
title = {{Spectral analysis of the EEG by means of autoregression}},
year = {1975}
}
@article{Cuchiero2015,
author = {Cuchiero, Christa and Teichmann, Josef},
doi = {10.1016/J.SPA.2014.07.023},
issn = {0304-4149},
journal = {Stochastic Processes and their Applications},
month = {jan},
number = {1},
pages = {116--160},
publisher = {North-Holland},
title = {{Fourier transform methods for pathwise covariance estimation in the presence of jumps}},
url = {http://www.sciencedirect.com/science/article/pii/S0304414914001823},
volume = {125},
year = {2015}
}
@article{Matthews1994,
author = {Matthews, M.B. and Moschytz, G.S.},
doi = {10.1109/82.331544},
issn = {10577130},
journal = {IEEE Transactions on Circuits and Systems II: Analog and Digital Signal Processing},
number = {11},
pages = {740--751},
title = {{The identification of nonlinear discrete-time fading-memory systems using neural network models}},
url = {http://ieeexplore.ieee.org/document/331544/},
volume = {41},
year = {1994}
}
@article{photonicReservoir2013,
author = {Brunner, D. and Soriano, M. C. and Mirasso, C. R. and Fischer, I.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Brunner et al. - 2013 - Parallel photonic information processing at gigabyte per second data rates using transient states.pdf:pdf},
journal = {Nature Communications},
number = {1364},
title = {{Parallel photonic information processing at gigabyte per second data rates using transient states}},
volume = {4},
year = {2013}
}
@article{dm,
author = {Dellnitz, M. and Melbourne, I.},
journal = {Lectures in Appl. Math.},
pages = {163--169},
title = {{The equivariant Darboux Theorem}},
volume = {29},
year = {1992}
}
@article{CrealGAS2012,
author = {Creal, Drew and Koopman, Siem Jan and Lucas, Andr{\'{e}}},
journal = {Journal of Applied Econometrics},
number = {5},
pages = {777--795},
title = {{Generalized autoregressive score models with applications}},
volume = {28},
year = {2013}
}
@unpublished{Kock2011,
abstract = {In this work we consider forecasting macroeconomic variables dur- ing an economic crisis. The focus is on a speci{\{}{\"{O}}{\}}c class of models, the so-called single hidden-layer feedforward autoregressive neural net- work models. What makes these models interesting in the present context is that they form a class of universal approximators and may be expected to work well during exceptional periods such as ma jor economic crises. These models are often di¢ cult to estimate, and we follow the idea of White (2006) to transform the speci{\{}{\"{O}}{\}}cation and non- linear estimation problem into a linear model selection and estimation problem. To this end we employ three automatic modelling devices. One of them is White{\{}{\'{i}}{\}}s QuickNet, but we also consider Autometrics, well known to time series econometricians, and the Marginal Bridge Estimator, better known to statisticians and microeconometricians. The performance of these three model selectors is compared by look- ing at the accuracy of the forecasts of the estimated neural network models. We apply the neural network model and the three modelling techniques to monthly industrial production and unemployment se- ries of the G7 countries and the four Scandinavian ones, and focus on forecasting during the economic crisis 2007{\{}{\~{n}}{\}}2009. Forecast accuracy is measured by the root mean square forecast error. Hypothesis testing is also used to compare the performance of the di{\{}{\S}{\}}erent techniques with each other.},
author = {Kock, Anders Bredahl and Ter{\"{a}}svirta, Timo},
booktitle = {Building},
institution = {CREATES},
keywords = {Autometrics,Marginal Bridge,Wilcoxon{\{}{\'{i}}{\}}s signed-rank test,economic forecasting,estimator,neural network,nonlinear time series model},
title = {{Forecasting Performance of Three Automated Modelling Techniques during the Economic Crisis 2007}},
year = {2011}
}
@book{arnold1998random,
author = {Arnold, Ludwig},
publisher = {Springer},
title = {{Random Dynamical Systems}},
year = {1998}
}
@article{Bacharoglou2010,
author = {Bacharoglou, Athanassia G.},
journal = {Proceedings of the American Mathematical Society},
number = {7},
pages = {2619--2628},
title = {{Approximation of probability distributions by convex mixtures of Gaussian measures}},
volume = {139},
year = {2010}
}
@article{pecora:synch,
abstract = {The field of chaotic synchronization has grown considerably since its advent in 1990. Several subdisciplines and "cottage industries" have emerged that have taken on bona fide lives of their own. Our purpose in this paper is to collect results from these various areas in a review article format with a tutorial emphasis. Fundamentals of chaotic synchronization are reviewed first with emphases on the geometry of synchronization and stability criteria. Several widely used coupling configurations are examined and, when available, experimental demonstrations of their success (generally with chaotic circuit systems) are described. Particular focus is given to the recent notion of synchronous substitution - a method to synchronize chaotic systems using a larger class of scalar chaotic coupling signals than previously thought possible. Connections between this technique and well-known control theory results are also outlined. Extensions of the technique are presented that allow so-called hyperchaotic systems (systems with more than one positive Lyapunov exponent) to be synchronized. Several proposals for "secure" communication schemes have been advanced; major ones are reviewed and their strengths and weaknesses are touched upon. Arrays of coupled chaotic systems have received a great deal of attention lately and have spawned a host of interesting and, in some cases, counterintuitive phenomena including bursting above synchronization thresholds, destabilizing transitions as coupling increases (short-wavelength bifurcations), and riddled basins. In addition, a general mathematical framework for analyzing the stability of arrays with arbitrary coupling configurations is outlined. Finally, the topic of generalized synchronization is discussed, along with data analysis techniques that can be used to decide whether two systems satisfy the mathematical requirements of generalized synchronization. {\textcopyright} 1997 American Institute of Physics.},
author = {Pecora, Louis M. and Carroll, Thomas L. and Johnson, Gregg A. and Mar, Douglas J. and Heagy, James F.},
doi = {10.1063/1.166278},
issn = {10541500},
journal = {Chaos},
number = {4},
pages = {520--543},
title = {{Fundamentals of synchronization in chaotic systems, concepts, and applications}},
volume = {7},
year = {1997}
}
@unpublished{francesco:notes,
annote = {Notes on Finite Dimensional Integrable Hamiltonian Systems. Preprint,

      },
author = {Fass{\`{o}}, F.},
title = {{Notes on Finite Dimensional Integrable Hamiltonian Systems}},
year = {1999}
}
@article{Zhu2015,
abstract = {Assume that St is a stock price process and Bt is a bond price process with a constant continuously compounded risk-free interest rate, where both are defined on an appropriate probability space P. Let yt=log(St/St−1). yt can be generally decomposed into a conditional mean plus a noise with volatility components, but the discounted St is not a martingale under P. Under a general framework, we obtain a risk-neutralized measure Q under which the discounted St is a martingale in this paper. Using this measure, we show how to derive the risk neutralized price for the derivatives. Special examples, such as NGARCH, EGARCH and GJR pricing models, are given. Simulation study reveals that these pricing models can capture the “volatility skew” of implied volatilities in the European option. A small application highlights the importance of our model-based pricing procedure.},
author = {Zhu, Ke and Ling, Shiqing},
issn = {03044076},
journal = {Journal of Econometrics},
keywords = {EGARCH and GJR models,NGARCH,Non-normal innovation,Option valuation,Risk neutralized measure,Volatility skew},
month = {aug},
number = {2},
pages = {447--457},
title = {{Model-based pricing for financial derivatives}},
url = {http://www.sciencedirect.com/science/article/pii/S030440761500055X},
volume = {187},
year = {2015}
}
@article{abudsartori83,
author = {Abud, M and Sartori, G},
journal = {Annals of Physics},
pages = {307--372},
title = {{The geometry of spontaneous symmetry breaking}},
year = {1983}
}
@article{cerny:kallsen:counterexample,
author = {{\v{C}}ern{\'{y}}, Ale{\v{s}} and Kallsen, Jan},
doi = {10.1111/j.1467-9965.2007.00334.x},
issn = {0960-1627},
journal = {Math. Finance},
number = {2},
pages = {305--316},
title = {{A counterexample concerning the variance-optimal martingale measure}},
url = {http://dx.doi.org/10.1111/j.1467-9965.2007.00334.x},
volume = {18},
year = {2008}
}
@article{Beesley2015,
abstract = {Prior research has suggested that attention is determined by exploiting what is known about the most valid predictors of outcomes and exploring those stimuli that are associated with the greatest degree of uncertainty about subsequent events. Previous studies of human contingency learning have revealed evidence for one or other of these processes, but differences in the designs and procedures of these studies make it difficult to pinpoint the crucial determinant of whether attentional exploitation or exploration will dominate. Here we present two studies in which we systematically manipulated both the predictiveness of cues and uncertainty regarding the outcomes with which they were associated. This allowed us to demonstrate, for the first time, evidence of both attentional exploration and exploitation within the same experiment. Moreover, while the effect of predictiveness persisted to influence the rate of novel learning about the same cues in a second stage, the effect of uncertainty did not. This suggests that attentional exploration is more sensitive to a change of context than is exploitation. The pattern of data is simulated with a hybrid attentional model.},
author = {Beesley, Tom and Nguyen, Katherine P and Pearson, Daniel and {Le Pelley}, Mike E},
doi = {10.1080/17470218.2015.1009919},
isbn = {1747-0218, 1747-0218},
issn = {1747-0218},
journal = {The Quarterly Journal of Experimental Psychology},
keywords = {Association Learning,Attention,Choice Behavior,Cues,Fixation,Humans,Ocular,Photic Stimulation,Uncertainty},
month = {nov},
number = {11},
pages = {2175--2199},
pmid = {25832459},
publisher = {Taylor {\&} Francis},
title = {{Uncertainty and predictiveness determine attention to cues during human associative learning}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25832459 http://www.tandfonline.com/doi/full/10.1080/17470218.2015.1009919},
volume = {68},
year = {2015}
}
@unpublished{Lutkepohl2011,
author = {L{\"{u}}tkepohl, Helmut},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/L{\"{u}}tkepohl - 2011 - Vector autoregressive models.pdf:pdf},
institution = {EUI},
series = {Department of Economics},
title = {{Vector autoregressive models}},
year = {2011}
}
@article{Lyon2017,
abstract = {Tieleman, Tijmen and Hinton, Geoffrey. Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude. COURSERA: Neural Networks for Machine Learning, 4, 2012},
author = {Lyon, Richard F. and Lyon, Richard F.},
doi = {10.1017/9781139051699.031},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Lyon, Lyon - 2017 - Neural Networks for Machine Learning.pdf:pdf},
journal = {Human and Machine Hearing},
pages = {419--440},
title = {{Neural Networks for Machine Learning}},
year = {2017}
}
@article{arnoldnn,
address = {Berlin, Heidelberg},
author = {Arnold, V. I.},
doi = {10.1007/978-3-642-01742-1_2},
journal = {Proceedings of the USSR Academy of Sciences},
pages = {679--681},
publisher = {Springer Berlin Heidelberg},
title = {{On functions of three variables}},
url = {http://link.springer.com/10.1007/978-3-642-01742-1{\_}2},
volume = {114},
year = {1957}
}
@book{hamburger:theorem,
author = {Shohat, James Alexander and Tamarkin, Jacob David},
number = {1},
publisher = {American Mathematical Soc.},
title = {{The problem of moments}},
year = {1943}
}
@article{Mukherjee1988,
abstract = {Various properties of a real symmetric Toeplitz matrix $\Sigma$m with elements $\sigma$jk= a|j−k|, 1 ⩽j,k⩽m, are reviewed here. Matrices of this kind often arise in applications in statistics, econometrics, psychometrics, structural engineering, multichannel filtering, reflection seismology, etc., and it is desirable to have techniques which exploit their special structure. Possible applications of the results related to their inverse, determinant, and eigenvalue problem are suggested.},
author = {Mukherjee, Bishwa Nath and Maiti, Sadhan Samar},
doi = {10.1016/0024-3795(88)90326-6},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Mukherjee, Maiti - 1988 - On some properties of positive definite Toeplitz matrices and their possible applications.pdf:pdf},
issn = {0024-3795},
journal = {Linear Algebra and its Applications},
month = {apr},
pages = {211--240},
publisher = {North-Holland},
title = {{On some properties of positive definite Toeplitz matrices and their possible applications}},
url = {https://www.sciencedirect.com/science/article/pii/0024379588903266},
volume = {102},
year = {1988}
}
@article{Petrosian2001,
author = {Petrosian, A. A. and Prokhorov, D. V. and Lajara-Nanson, W. and Schiffer, R. B.},
doi = {10.1016/S1388-2457(01)00579-X},
isbn = {1180674324},
issn = {13882457},
journal = {Clinical neurophysiology},
keywords = {alzheimer's disease,eeg,neural networks,wavelets},
month = {aug},
number = {8},
pages = {1378--1387},
title = {{Recurrent neural network-based approach for early recognition of Alzheimer's disease in EEG}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S138824570100579X},
volume = {112},
year = {2001}
}
@article{black:scholes:paper,
author = {Black, F and Scholes, M},
journal = {J. Finance},
pages = {399--417},
title = {{The valuation of option contracts and a test of market efficiency}},
volume = {27},
year = {1972}
}
@book{kantz:Sreiber,
author = {Kantz, Holger and Schreiber, Thomas},
edition = {Second},
publisher = {Cambridge University Press},
title = {{Nonlinear Time Series Analysis}},
year = {2003}
}
@article{SOASforRC,
author = {Vandoorne, K. and Dambre, J. and Verstraeten, D. and Schrauwen, B. and Bienstman, P.},
doi = {10.1109/TNN.2011.2161771},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Vandoorne et al. - 2011 - Parallel reservoir computing using optical amplifiers.pdf:pdf},
journal = {IEEE Transactions on Neural Networks},
month = {sep},
number = {9},
pages = {1469--1481},
title = {{Parallel reservoir computing using optical amplifiers}},
url = {http://ieeexplore.ieee.org/document/5966352/},
volume = {22},
year = {2011}
}
@article{Ruiz2002,
author = {Ruiz, Esther and Pascual, Lorenzo},
issn = {0950-0804},
journal = {Journal of Economic Surveys},
month = {jul},
number = {3},
pages = {271--300},
title = {{Bootstrapping Financial Time Series}},
url = {http://doi.wiley.com/10.1111/1467-6419.00170},
volume = {16},
year = {2002}
}
@article{Freund1999,
author = {Freund, Yoav and Schapire, Robert E.},
journal = {Games and Economic Behavior},
pages = {79--103},
title = {{Adaptive game playing using multiplicative weights}},
volume = {29},
year = {1999}
}
@article{Poggio2004,
author = {Poggio, Tomaso and Rifkin, Ryan and Mukherjee, Sayan and Niyogi, Partha},
journal = {Nature},
number = {6981},
pages = {419--422},
title = {{General conditions for predictivity in learning theory}},
volume = {428},
year = {2004}
}
@article{OpticalNN,
abstract = {An optical network is described that is capable of recognizing at standard video rates the identity of faces for which it has been trained. The faces are presented under a wide variety of conditions to the system and the classification performance is measured. The system is trained by gradually adapting photorefractive holograms.},
author = {Li, Hsin-Yu Sidney and Qiao, Yong and Psaltis, Demetri},
doi = {10.1364/AO.32.005026},
issn = {0003-6935},
journal = {Applied Optics},
month = {sep},
number = {26},
pages = {5026},
publisher = {Optical Society of America},
title = {{Optical network for real-time face recognition}},
url = {https://www.osapublishing.org/abstract.cfm?URI=ao-32-26-5026},
volume = {32},
year = {1993}
}
@article{blankenstein2004singular,
author = {Blankenstein, Guido and Ratiu, Tudor S},
journal = {Reports on Mathematical Physics},
number = {2},
pages = {211--260},
publisher = {Elsevier},
title = {{Singular reduction of implicit Hamiltonian systems}},
volume = {53},
year = {2004}
}
@article{kroner:ng,
author = {Kroner, F. K. and Ng, V. K.},
journal = {The Review of Financial Studies},
pages = {817--844},
title = {{Modelling asymmetric comovements of asset returns}},
volume = {11},
year = {1998}
}
@inproceedings{BCW2015,
address = {Working paper},
author = {Bormetti, C. and Corsi, F. and Majewski, A. A.},
title = {{Term structure of variance risk premium and returns' predictability}},
year = {2016}
}
@unpublished{Giannone,
author = {Giannone, Domenico and Lenza, Michele and Momferatou, Daphne and Onorante, Luca},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Giannone et al. - 2010 - Short ‐ Term Inflation Projections a Bayesian Vector Autoregressive Approach.pdf:pdf},
institution = {ECARES},
title = {{Short ‐ Term Inflation Projections : a Bayesian Vector Autoregressive Approach}},
year = {2010}
}
@article{chossat:maximal,
author = {Chossat, P. and Koenig, M. and Montaldi, J.},
journal = {C. R. Acad. Sci. Paris S{\'{e}}r. I Math.},
pages = {25--30},
title = {{Bifurcation g{\'{e}}n{\'{e}}rique d'ondes d'isotropie maximale}},
volume = {320},
year = {1995}
}
@article{RotatedARCH,
author = {Noureldin, Diaa and Shephard, Neil and Sheppard, Kevin},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Noureldin, Shephard, Sheppard - 2014 - Multivariate Rotated ARCH models.pdf:pdf},
journal = {Journal of Econometrics},
number = {1},
pages = {16--30},
title = {{Multivariate Rotated ARCH models}},
volume = {179},
year = {2014}
}
@article{Swanson1997a,
abstract = {Nine macroeconomic variables are forecast in a real-time scenario using a variety of flexible specification, fixed specification, linear, and nonlinear econometric models. All models are allowed to evolve through time, and our analysis focuses on model selection and performance. In the context of real-time forecasts, flexible specification models (including linear autoregressive models with exogenous variables and nonlinear artificial neural networks) appear to offer a useful and viable alternative to less flexible fixed specification linear models for a subset of the economic variables which we examine, particularly at forecast horizons greater than 1-step ahead. We speculate that one reason for this result is that the economy is evolving (rather slowly) over time. This feature cannot easily be captured by fixed specification linear models, however, and manifests itself in the form of evolving coefficient estimates. We also provide additional evidence supporting the claim that models which ‘win' based on one model selection criterion (say a squared error measure) do not necessarily win when an alternative selection criterion is used (say a confusion rate measure), thus highlighting the importance of the particular cost function which is used by forecasters and ‘end-users' to evaluate their models. A wide variety of different model selection criteria and statistical tests are used to illustrate our findings.},
author = {Swanson, Norman R. and White, Halbert},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Swanson - 1997 - Forecasting Economic Time Series Using Flexible Versus Fixed Specification and Linear Versus Nonlinear Econometric Mode.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {cointegration,confusion rate,linearity,model selection,nonlinearity,parameter evolution,real-time forecasting},
month = {dec},
number = {March},
pages = {439--461},
title = {{Forecasting Economic Time Series Using Flexible Versus Fixed Specification and Linear Versus Nonlinear Econometric Models}},
url = {http://dx.doi.org/10.1016/S0169-2070(97)00030-7},
volume = {13},
year = {1997}
}
@article{Hsu2008,
abstract = {A subset selection method is proposed for vector autoregressive (VAR) processes using the Lasso [Tibshirani, R. (1996). Regression shrinkage and selection via the Lasso. Journal of the Royal Statistical Society, Series B 58, 267–288] technique. Simply speaking, Lasso is a shrinkage method in a regression setup which selects the model and estimates the parameters simultaneously. Compared to the conventional information-based methods such as AIC and BIC, the Lasso approach avoids computationally intensive and exhaustive search. On the other hand, compared to the existing subset selection methods with parameter constraints such as the top-down and bottom-up strategies, the Lasso method is computationally efficient and its result is robust to the order of series included in the autoregressive model. We derive the asymptotic theorem for the Lasso estimator under VAR processes. Simulation results demonstrate that the Lasso method performs better than several conventional subset selection methods for small samples in terms of prediction mean squared errors and estimation errors under various settings. The methodology is applied to modeling U.S. macroeconomic data for illustration.},
author = {Hsu, Nan-Jung and Hung, Hung-Lin and Chang, Ya-Mei},
issn = {01679473},
journal = {Computational Statistics {\&} Data Analysis},
month = {mar},
number = {7},
pages = {3645--3657},
title = {{Subset selection for vector autoregressive processes using Lasso}},
url = {http://dx.doi.org/10.1016/j.csda.2007.12.004},
volume = {52},
year = {2008}
}
@book{Arnold1989,
author = {Arnold, V. I.},
keywords = {Analysis,Mathematical Methods of Classical Mechanics,Mathematical and Computational Physics,Theoretical},
pages = {519},
publisher = {Springer},
title = {{Mathematical Methods of Classical Mechanics}},
url = {http://www.springer.com/mathematics/analysis/book/978-0-387-96890-2?token=gbgen{\&}wt{\_}mc=Google-{\_}-Book Search-{\_}-Springer-{\_}-EN},
year = {1989}
}
@incollection{Wu2013,
address = {Oxford},
author = {Wu, Ke and Natarajan, Bharath and Morkowchuk, Lisa and Krein, Mike and Breneman, Curt M},
booktitle = {Informatics for Materials Science and Engineering},
doi = {http://dx.doi.org/10.1016/B978-0-12-394399-6.00016-3},
editor = {Rajan, Krishna},
isbn = {978-0-12-394399-6},
keywords = {Bioinformatics,Cheminformatics,Machine learning,Materials Genome Initiative,Materials informatics,Quantitative structure–property relationships},
pages = {385--422},
publisher = {Butterworth-Heinemann},
title = {{From drug discovery QSAR to predictive materials QSPR: The evolution of descriptors, methods, and models}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123943996000163},
year = {2013}
}
@article{HGGO2013,
abstract = {Recent studies have evidenced serious difficulties in detecting covert awareness with electroencephalography-based techniques both in unresponsive patients and in healthy control subjects. This work reproduces the protocol design in two recent mental imagery studies with a larger group comprising 20 healthy volunteers. The main goal is assessing if modifications in the signal extraction techniques, training-testing/cross-validation routines, and hypotheses evoked in the statistical analysis, can provide solutions to the serious difficulties documented in the literature. The lack of robustness in the results advises for further search of alternative protocols more suitable for machine learning classification and of better performing signal treatment techniques. Specific recommendations are made using the findings in this work.},
author = {Henriques, J and Gabriel, D and Grigoryeva, L and Haffen, E and Moulin, T and Aubry, R and Pazart, L and Ortega, J.-P.},
doi = {10.1177/1550059414560397},
issn = {1550-0594},
journal = {Clinical EEG and Neuroscience},
keywords = {2014,accepted october 27,awareness detection,eeg,eeg signal classification,evoked potentials,mental imagery,received may 19,revised october 13 2014},
number = {4},
pages = {266--275},
pmid = {25488924},
title = {{Protocol Design Challenges in the Detection of Awareness in Aware Subjects Using EEG Signals}},
url = {http://eeg.sagepub.com/content/early/2014/12/03/1550059414560397.abstract},
volume = {33},
year = {2016}
}
@article{Lee,
author = {Lee, Brandon},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Lee - Unknown - Nonlinear Least Squares.pdf:pdf},
title = {{Nonlinear Least Sqaures}}
}
@book{Tropp2015,
author = {Tropp, Joel A},
number = {1-2},
title = {{An Introduction to Matrix Concentration Inequalities}},
volume = {8},
year = {2015}
}
@book{Haykin2009,
author = {Haykin, S.},
publisher = {Pearson, Addison Wesley},
title = {{Neural Networks and Learning Machines}},
year = {2009}
}
@inproceedings{Chen2013,
abstract = {We present novel, efficient, model based kernels for time series data rooted in the reservoir computation framework. The kernels are implemented by fitting reservoir models sharing the same fixed deterministically constructed state transition part to individual time series. The proposed kernels can naturally handle time series of different length without the need to specify a parametric model class for the time series. Compared with most time series kernels, our kernels are computationally efficient. We show how the model distances used in the kernel can be calculated analytically or efficiently estimated. The experimental results on synthetic and benchmark time series classification tasks confirm the efficiency of the proposed kernel in terms of both generalization accuracy and computational speed. This paper also investigates on-line reservoir kernel construction for extremely long time series.},
author = {Chen, Huanhuan and Tang, Fengzhen and Tino, Peter and Yao, Xin},
booktitle = {Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '13},
doi = {10.1145/2487575.2487700},
isbn = {9781450321747},
issn = {9781450321747},
title = {{Model-based kernel for efficient time series analysis}},
year = {2013}
}
@article{hoerl_ridge_1970,
author = {Hoerl, Arthur E. and Kennard, Robert W.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Hoerl, Kennard - 1970 - Ridge regression biased estimation for nonorthogonal problems.pdf:pdf},
journal = {Technometrics},
number = {1},
pages = {55--67},
title = {{Ridge regression: biased estimation for nonorthogonal problems}},
volume = {12},
year = {1970}
}
@article{nonholonomic:mechanical:with:bloch,
author = {Bloch, A. M. and Krishnaprasad, P. S. and Marsden, J. E. and Murray, R. M.},
journal = {Arch. Rational Mech. Anal.},
pages = {21--99},
title = {{Nonholonomic mechanical systems with symmetry}},
volume = {136},
year = {1996}
}
@article{cushman:sniatycki,
author = {Cushman, R. and Sniatycki, J.},
journal = {Canad. J. Math.},
number = {4},
pages = {715--755},
title = {{Differential structure of orbit spaces}},
volume = {53},
year = {2001}
}
@article{Pantev1995,
abstract = {This paper presents data concerning auditory evoked responses in the middle latency range (wave Pam/ Pa) and slow latency range (wave Nlm/Nl) recorded from 12 subjects. It is the first group study to report multi-channel data of both MEG and EEG recordings from the human auditory cortex. The experimental procedure involved potential and current density topographical brain mapping as well as magnetic and electric source analysis. Responses were compared for the following 3 stimulus frequencies: 500, 1000 and 4000 Hz. It was found that two areas of the auditory cortex showed mirrored tonotopic organization; one area, the source of N1m/N1 wave, exhibited higher frequencies at progressively deeper locations, while the second area, the source of the Pam/ Pa wave, exhibited higher frequencies at progressively more superficial locations. The Pa tonotopic map was located in the primary auditory cortex anterior to the N1m/N1 mirror map. It is likely that N1m/N1 results from activation of secondary auditory areas. The location of the Pa map in Al, and its N1 mirror image in secondary auditory areas is in agreement with observations from animal studies.},
author = {Pantev, C and Bertrand, O and Eulitz, C and Verkindt, C and Hampson, S and Schuierer, G and Elbert, T},
issn = {00134694},
journal = {Electroencephalography and Clinical Neurophysiology},
keywords = {Auditory cortex,EEG,Evoked magnetic field,Evoked potential,MEG,MRI,Middle latency auditory evoked potential,Middle latency auditory magnetic field,Tonotopic organization},
month = {jan},
number = {1},
pages = {26--40},
title = {{Specific tonotopic organizations of different areas of the human auditory cortex revealed by simultaneous magnetic and electric recordings}},
url = {http://www.sciencedirect.com/science/article/pii/0013469494002094},
volume = {94},
year = {1995}
}
@article{hankel:tensors,
abstract = {An mth order n-dimensional Hankel tensor is defined as a tensor A satisfying Ai1...imAi1+⋯+im-m for some numbers A0,A1,...,Am(n-1). A Hankel tensor possesses a Vandermonde decomposition (VD) A=Ak=1r$\lambda$kukm where uk=(1,wk,wk2,...,wkn-1)T is called a Vandermonde vector (V-vector). A is called a Vandermonde tensor (V-tensor) if A has a VD with each $\lambda$k=1. V-tensors are the natural extension of Vandermonde matrices. It is easy to see that all even order V-tensors are positive semidefinite (psd) and thus copositive. An odd order real symmetric tensor is psd only if it is zero. The problem when an odd order Hankel tensor is copositive is open. We present a necessary and sufficient condition for a rank-2 odd-order symmetric real tensor to be copositive. Some necessary conditions for a general V-tensor to be copositive are also presented. The singularity of V-tensors is also investigated, and we show that a V-tensor A is singular if its V-rank is less than its dimension. This condition becomes necessary if A is of odd order.},
author = {Xu, Changqing},
doi = {10.1016/j.laa.2015.02.012},
issn = {00243795},
journal = {Linear Algebra and Its Applications},
keywords = {Copositive tensor,Decomposition,Hankel tensor,Tensor,V-tensor},
pages = {56--72},
publisher = {Elsevier Inc.},
title = {{Hankel tensors, Vandermonde tensors and their positivities}},
url = {http://dx.doi.org/10.1016/j.laa.2015.02.012},
volume = {491},
year = {2016}
}
@article{Clements2008,
author = {Clements, M. and Galv{\~{a}}o, A.},
journal = {Journal of Business {\&} Economic Statistics},
pages = {546--554},
title = {{Macroeconomic forecasting with mixed-frequency data: forecasting output growth in the United States}},
volume = {26},
year = {2008}
}
@article{van2014port,
author = {van der Schaft, Arjan and Jeltsema, Dimitri},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/van der Schaft, Jeltsema - 2014 - Port-Hamiltonian systems theory An introductory overview.pdf:pdf},
journal = {Foundations and Trends in Systems and Control},
number = {2-3},
pages = {173--378},
publisher = {Now Publishers Inc. Hanover, MA, USA},
title = {{Port-Hamiltonian systems theory: An introductory overview}},
volume = {1},
year = {2014}
}
@incollection{FliessNormand1980,
author = {Fliess, Michel and Normand-Cyrot, Doroth{\'{e}}e},
booktitle = {Analysis and Optimization of Systems. Lecture Notes in Control and Information Sciences, vol. 28},
editor = {Bensoussan, A. and Lions, J.L.},
publisher = {Springer Berlin Heidelberg},
title = {{Vers une approche alg{\'{e}}brique des syst{\`{e}}mes non lin{\'{e}}aires en temps discret}},
year = {1980}
}
@inproceedings{albert:dazord:1990,
address = {Lyon},
author = {Albert, C. and Dazord, P.},
booktitle = {Travaux du S{\'{e}}minaire Sud Rhodanien de G{\'{e}}om{\'{e}}trie, II},
pages = {27--99},
publisher = {Publ. D{\'{e}}p. Math. Nouvelle S{\'{e}}r. B},
title = {{Th{\'{e}}orie des groupo{\"{i}}des symplectiques. Chapitre I. Groupo{\"{i}}des symplectiques}},
year = {1990}
}
@article{Lainscsek2013,
abstract = {Time series analysis with nonlinear delay differential equations (DDEs) reveals nonlinear as well as spectral properties of the underlying dynamical system. Here, global DDE models were used to analyze 5 min data segments of electrocardiographic (ECG) recordings in order to capture distinguishing features for different heart conditions such as normal heart beat, congestive heart failure, and atrial fibrillation. The number of terms and delays in the model as well as the order of nonlinearity of the model have to be selected that are the most discriminative. The DDE model form that best separates the three classes of data was chosen by exhaustive search up to third order polynomials. Such an approach can provide deep insight into the nature of the data since linear terms of a DDE correspond to the main time-scales in the signal and the nonlinear terms in the DDE are related to nonlinear couplings between the harmonic signal parts. The DDEs were able to detect atrial fibrillation with an accuracy of 72{\%}, congestive heart failure with an accuracy of 88{\%}, and normal heart beat with an accuracy of 97{\%} from 5 min of ECG, a much shorter time interval than required to achieve comparable performance with other methods.},
author = {Lainscsek, Claudia and Sejnowski, Terrence J},
issn = {1089-7682},
journal = {Chaos (Woodbury, N.Y.)},
keywords = {Atrial Fibrillation,Atrial Fibrillation: physiopathology,Cardiovascular,Electrocardiography,Electrocardiography: classification,Heart Failure,Heart Failure: physiopathology,Heart Rate,Heart Rate: physiology,Humans,Models,Nonlinear Dynamics,ROC Curve},
month = {jun},
number = {2},
pages = {023132},
publisher = {AIP Publishing},
title = {{Electrocardiogram classification using delay differential equations.}},
url = {http://scitation.aip.org/content/aip/journal/chaos/23/2/10.1063/1.4811544},
volume = {23},
year = {2013}
}
@article{allen:tikhonov,
author = {Hart, Allen G and Hook, James L and Dawes, Jonathan H P},
journal = {Physica D: Nonlinear Phenomena},
pages = {132882},
title = {{Echo State Networks trained by Tikhonov least squares are L2($\mu$) approximators of ergodic dynamical systems}},
year = {2021}
}
@article{Kmiecik2016,
author = {Kmiecik, Sebastian and Gront, Dominik and Kolinski, Michal and Wieteska, Lukasz and Dawid, Aleksandra Elzbieta and Kolinski, Andrzej},
journal = {Chemical Reviews},
number = {14},
pages = {7898--7936},
title = {{Coarse-grained protein models and their applications}},
volume = {116},
year = {2016}
}
@article{Bauer2011,
author = {Bauer, Gregory H. and Vorkink, Keith},
journal = {Journal of Econometrics},
number = {1},
pages = {93--101},
title = {{Forecasting multivariate realized stock market volatility}},
volume = {160},
year = {2011}
}
@article{sprecherI,
abstract = {Hecht-Nielsen proposed a feedforward neural network based on Kolmogorov's superpositionsf(xi,{\ldots},xn)=∑q=02$\pi$$\Phi$q(yq) that apply to all real valued continuous functions f(x1, {\ldots}, xn) defined on a Euclidean unit cube of dimension n ≥ 2. This network has a hidden layer that is independent of f and that transforms the n-tuples (x1, {\ldots}, xn) into the 2n + 1 variables yq, and an output layer in which f is computed. Kůrkov{\'{a}} has shown that such a network has an approximate implementation with arbitrary activation functions of sigmoidal type. Actual implementation is, however, impeded by the lack of numerical algorithms for the hidden layer which contain continuous functions of the formyq=$\Sigma$np=1$\alpha$p$\psi$(xp+qa) with constants a and $\alpha$p. This paper gives an explicit numerical implementation of the hidden layer that also enables the implementation of the output layer. Copyright {\textcopyright} 1996 Elsevier Science Ltd},
author = {Sprecher, David A.},
doi = {10.1016/0893-6080(95)00081-X},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Sprecher - 1997 - A numerical implementation of Kolmogorov's superpositions II(2).pdf:pdf},
journal = {Neural Networks},
number = {5},
pages = {765--772},
title = {{A numerical implementation of Kolmogorov's superpositions}},
volume = {9},
year = {1996}
}
@article{field:richardson:89,
author = {Field, M. J. and Richardson, R. W.},
journal = {Arch. Rational Mech. Anal.},
pages = {61--94},
title = {{Symmetry breaking and the maximal isotropy subgroup conjecture for reflection groups}},
volume = {105},
year = {1989}
}
@article{Estrella2005,
author = {Estrella, Arturo},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Estrella - 2005 - Why Does the Yield Curve Predict Output and Inflation.pdf:pdf},
issn = {0013-0133},
journal = {The Economic Journal},
month = {jul},
number = {505},
pages = {722--744},
title = {{Why Does the Yield Curve Predict Output and Inflation?}},
url = {http://doi.wiley.com/10.1111/j.1468-0297.2005.01017.x},
volume = {115},
year = {2005}
}
@article{Kanniainen2014,
abstract = {This paper uses information on VIX to improve the empirical performance of GARCH models for pricing options on the S{\&}P 500. In pricing multiple cross-sections of options, the models' performance can clearly be improved by extracting daily spot volatilities from the series of VIX rather than by linking spot volatility with different dates by using the series of the underlying's returns. Moreover, in contrast to traditional returns-based Maximum Likelihood Estimation (MLE), a joint MLE with returns and VIX improves option pricing performance, and for NGARCH, joint MLE can yield empirically almost the same out-of-sample option pricing performance as direct calibration does to in-sample options, but without costly computations. Finally, consistently with the existing research, this paper finds that non-affine models clearly outperform affine models.},
author = {Kanniainen, Juho and Lin, Binghuan and Yang, Hanxue},
issn = {03784266},
journal = {Journal of Banking {\&} Finance},
keywords = {Estimation,GARCH,Option valuation,VIX},
month = {jun},
pages = {200--211},
title = {{Estimating and using GARCH models with VIX data for option valuation}},
url = {http://www.sciencedirect.com/science/article/pii/S0378426614001186},
volume = {43},
year = {2014}
}
@article{LDX2010,
author = {Boxer, A. C. and Bergmann, R. and Ellsworth, J. L. and Garnier, G. T. and Kesner, J. and Mauel, M. E. and Woskov, P.},
file = {::},
journal = {Nature Physics},
pages = {207--212},
title = {{Turbulent inward pinch of plasma confined by a levitated dipole magnet}},
volume = {6},
year = {2010}
}
@inproceedings{dasgupta2010sparse,
author = {Dasgupta, Anirban and Kumar, Ravi and Sarl{\'{o}}s, Tam{\'{a}}s},
booktitle = {Proceedings of the forty-second ACM symposium on Theory of computing},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Dasgupta, Kumar, Sarl{\'{o}}s - 2010 - A sparse Johnson-Lindenstrauss transform.pdf:pdf},
pages = {341--350},
title = {{A sparse Johnson-Lindenstrauss transform}},
year = {2010}
}
@article{Dueker2002,
author = {Dueker, MJ},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Dueker - 2002 - Regime-Dependent Recession Forecasts and the 2001 Recession.pdf:pdf},
journal = {-FEDERAL RESERVE BANK OF SAINT LOUIS},
pages = {29--36},
title = {{Regime-Dependent Recession Forecasts and the 2001 Recession}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Regime-Dependent+Recession+Forecasts+and+the+2001+Recession{\#}0},
year = {2002}
}
@article{Cook2007,
abstract = {Beginning with a discussion of R. A. Fisher's early written re- marks that relate to dimension reduction, this article revisits principal com- ponents as a reductive method in regression, develops several model-based extensions and ends with descriptions of general approaches to model-based and model-free dimension reduction in regression. It is argued that the role for principal components and related methodology may be broader than pre- viously seen and that the common practice of conditioning on observed values of the predictors may unnecessarily limit the choice of regression methodology.},
archivePrefix = {arXiv},
arxivId = {arXiv:0708.3774v1},
author = {Cook, R. Dennis},
doi = {10.1214/088342306000000682},
eprint = {arXiv:0708.3774v1},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Cook - 2007 - Fisher lecture Dimension reduction in regression.pdf:pdf},
isbn = {0883423060000},
issn = {08834237},
journal = {Statistical Science},
keywords = {Central subspace,Grassmann manifolds,Inverse regression,Minimum average variance estimation,Principal components,Principal fitted components,Sliced inverse regression,Sufficient dimension reduction},
number = {1},
pages = {1--26},
title = {{Fisher lecture: Dimension reduction in regression}},
volume = {22},
year = {2007}
}
@article{Ott2018,
abstract = {A machine-learning approach called "reservoir computing" has been used successfully for short-term prediction and attractor reconstruction of chaotic dynamical systems from time series data. We present a theory for when and how reservoir computing is able to create accurate empirical models for chaotic dynamics, using the notions of generalized synchronization and Lyapunov exponents. We illustrate this theory through numerical experiments. We also argue that the theory applies to certain other machine learning methods for time series prediction.},
archivePrefix = {arXiv},
arxivId = {1805.03362},
author = {Lu, Zhixin and Hunt, Brian R. and Ott, Edward},
doi = {10.1063/1.5039508},
eprint = {1805.03362},
issn = {10541500},
journal = {Chaos},
number = {6},
title = {{Attractor reconstruction by machine learning}},
volume = {28},
year = {2018}
}
@article{Rombouts:Stentoft,
author = {Rombouts, Jeroen V. K. and Stentoft, Lars},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Rombouts, Stentoft - 2011 - Multivariate option pricing with time varying volatility and correlations.pdf:pdf},
journal = {Journal of Banking {\&} Finance},
number = {9},
pages = {2267--2281},
title = {{Multivariate option pricing with time varying volatility and correlations}},
url = {http://www.sciencedirect.com.ezproxy.lib.ucalgary.ca/science/article/pii/S037842661100046X{\#}},
volume = {35},
year = {2011}
}
@book{Stetter1973,
author = {Stetter, Hans J.},
publisher = {Springer-Verlag},
title = {{Analysis of Discretization Methods for Ordinary Differential Equations}},
year = {1973}
}
@inproceedings{Singh2019,
author = {Singh, Gautam and Yoon, Jaesik and Son, Youngsung and Ahn, Sungjin},
booktitle = {NeurIPS},
title = {{Sequential neural processes}},
year = {2019}
}
@article{drift,
author = {Patrick, George W.},
journal = {Journal of Nonlinear Science},
pages = {373--418},
title = {{Relative equilibria of Hamiltonian systems with symmetry: linearization, smoothness, and drift.}},
volume = {5},
year = {1995}
}
@incollection{Koppen2005,
address = {Berlin, Heidelberg},
author = {K{\"{o}}ppen, Mario and Yoshida, Kaori},
booktitle = {Soft Computing as Transdisciplinary Science and Technology},
doi = {10.1007/3-540-32391-0_28},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/K{\"{o}}ppen, Yoshida - 2005 - Universal Representation of Image Functions by the Sprecher Construction(2).pdf:pdf},
pages = {202--210},
publisher = {Springer Berlin Heidelberg},
title = {{Universal Representation of Image Functions by the Sprecher Construction}},
url = {http://link.springer.com/10.1007/3-540-32391-0{\_}28},
year = {2005}
}
@book{audin:1991,
author = {Audin, M.},
publisher = {Birkh{\"{a}}user Verlag},
title = {{The Topology of Torus Actions on Symplectic Manifolds. Progress in Mathematics. 93}},
year = {1991}
}
@misc{Shumway1999,
author = {Shumway, Tyler},
booktitle = {Young},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Shumway - 1999 - Forecasting Bankruptcy More Accurately A Simple Hazard Model.pdf:pdf},
title = {{Forecasting Bankruptcy More Accurately : A Simple Hazard Model}},
year = {1999}
}
@article{Bernardi2015,
abstract = {AbstractBackground Molecular dynamics has emerged as an important research methodology covering systems to the level of millions of atoms. However, insufficient sampling often limits its application. The limitation is due to rough energy landscapes, with many local minima separated by high-energy barriers, which govern the biomolecular motion. Scope of review In the past few decades methods have been developed that address the sampling problem, such as replica-exchange molecular dynamics, metadynamics and simulated annealing. Here we present an overview over theses sampling methods in an attempt to shed light on which should be selected depending on the type of system property studied. Major conclusions Enhanced sampling methods have been employed for a broad range of biological systems and the choice of a suitable method is connected to biological and physical characteristics of the system, in particular system size. While metadynamics and replica-exchange molecular dynamics are the most adopted sampling methods to study biomolecular dynamics, simulated annealing is well suited to characterize very flexible systems. The use of annealing methods for a long time was restricted to simulation of small proteins; however, a variant of the method, generalized simulated annealing, can be employed at a relatively low computational cost to large macromolecular complexes. General significance Molecular dynamics trajectories frequently do not reach all relevant conformational substates, for example those connected with biological function, a problem that can be addressed by employing enhanced sampling algorithms. This article is part of a Special Issue entitled Recent developments of molecular dynamics. },
annote = {Recent developments of molecular dynamics},
author = {Bernardi, Rafael C and Melo, Marcelo C R and Schulten, Klaus},
doi = {http://dx.doi.org/10.1016/j.bbagen.2014.10.019},
issn = {0304-4165},
journal = {Biochimica et Biophysica Acta (BBA) - General Subjects},
keywords = {Cellulosome,Enhanced sampling,Generalized simulated annealing,Metadynamics,Molecular dynamics,Replica-exchange molecular dynamics},
number = {5},
pages = {872--877},
title = {{Enhanced sampling techniques in molecular dynamics simulations of biological systems}},
url = {http://www.sciencedirect.com/science/article/pii/S0304416514003559},
volume = {1850},
year = {2015}
}
@book{Ledoux2005,
author = {Ledoux, Michel},
pages = {181},
publisher = {American Mathematical Society},
title = {{The Concentration of Measure Phenomenon}},
year = {2005}
}
@incollection{MR1963528,
address = {New York},
author = {Duan, Jin-Chuan and Gauthier, Genevi{\`{e}}ve and Simonato, Jean-Guy},
booktitle = {Stochastic modeling and optimization},
pages = {333--362},
publisher = {Springer},
title = {{A Markov chain method for pricing contingent claims}},
year = {2003}
}
@inproceedings{proc2021,
booktitle = {Proceedings of Machine Learning Research},
title = {{Learning for Dynamics and Control}},
year = {2021}
}
@book{Dieudonne:volumeVI,
author = {Dieudonn{\'{e}}, Jean},
isbn = {0122155025},
publisher = {Academic Press, Inc.},
title = {{Treatise on Analysis. Volume VI}},
volume = {VI},
year = {1978}
}
@article{Haussler1992,
abstract = {We describe a generalization of the PAC learning model that is based on statistical decision theory. In this model the learner receives randomly drawn examples, each example consisting of an instance x ∈ X and an outcome y ∈ Y, and tries to find a decision rule h: X → A, where h ∈ H, that specifies the appropriate action a ∈ A to take for each instance x in order to minimize the expectation of a loss l(y, a). Here X, Y, and A are arbitrary sets, l is a real-valued function, and examples are generated according to an arbitrary joint distribution on X × Y. Special cases include the problem of learning a function from X into Y, the problem of learning the conditional probability distribution on Y given X (regression), and the problem of learning a distribution on X (density estimation). We give theorems on the uniform convergence of empirical loss estimates to true expected loss rates for certain decision rule spaces H, and show how this implies learnability with bounded sample size, disregarding computational complexity. As an application, we give distribution-independent upper bounds on the sample size needed for learning with feedforward neural networks. Our theorems use a generalized notion of VC dimension that applies to classes of real-valued functions, adapted from Vapnik and Pollard's work, and a notion of capacity and metric dimension for classes of functions that map into a bounded metric space. {\textcopyright} 1992.},
archivePrefix = {arXiv},
arxivId = {1304.7771},
author = {Haussler, David},
eprint = {1304.7771},
journal = {Information and Computation},
pmid = {20651817},
title = {{Decision theoretic generalizations of the PAC model for neural net and other learning applications}},
year = {1992}
}
@article{Park1991,
abstract = {There have been several recent studies concerning feedforward networks and the problem of approximating arbitrary functionals of a finite number of real variables. Some of these studies deal with cases in which the hidden-layer nonlinearity is not a sigmoid. This was motivated by successful applications of feedforward networks with nonsigmoidal hidden-layer units. This paper reports on a related study of radial-basis-function (RBF) networks, and it is proved that RBF networks having one hidden layer are capable of universal approximation. Here the emphasis is on the case of typical RBF networks, and the results show that a certain class of RBF networks with the same smoothing factor in each kernel node is broad enough for universal approximation.},
author = {Park, J. and Sandberg, I. W.},
doi = {10.1162/neco.1991.3.2.246},
isbn = {0132733501},
issn = {0899-7667},
journal = {Neural Computation},
number = {2},
pages = {246--257},
title = {{Universal Approximation Using Radial-Basis-Function Networks}},
url = {http://www.mitpressjournals.org/doi/10.1162/neco.1991.3.2.246},
volume = {3},
year = {1991}
}
@article{kocarev1996generalized,
author = {Kocarev, Lj and Parlitz, U},
journal = {Physical Review Letters},
number = {11},
pages = {1816--1819},
publisher = {APS},
title = {{Generalized synchronization, predictability, and equivalence of unidirectionally coupled dynamical systems}},
volume = {76},
year = {1996}
}
@article{Majewski2015,
abstract = {In the current literature, the analytical tractability of discrete time option pricing models is guaranteed only for rather specific types of models and pricing kernels. We propose a very general and fully analytical option pricing framework, encompassing a wide class of discrete time models featuring multiple-component structure in both volatility and leverage, and a flexible pricing kernel with multiple risk premia. Although the proposed framework is general enough to include either GARCH-type volatility, Realized Volatility or a combination of the two, in this paper we focus on realized volatility option pricing models by extending the Heterogeneous Autoregressive Gamma (HARG) model of Corsi et al. (2013) to incorporate heterogeneous leverage structures with multiple components, while preserving closed-form solutions for option prices. Applying our analytically tractable asymmetric HARG model to a large sample of S{\&}P 500 index options, we demonstrate its superior ability to price out-of-the-money options compared to existing benchmarks.},
author = {Majewski, Adam A. and Bormetti, Giacomo and Corsi, Fulvio},
issn = {03044076},
journal = {Journal of Econometrics},
month = {aug},
number = {2},
pages = {521--531},
title = {{Smile from the past: A general option pricing framework with multiple volatility and leverage components}},
url = {http://www.sciencedirect.com/science/article/pii/S0304407615000615},
volume = {187},
year = {2015}
}
@article{HULL1987,
author = {Hull, John and White, Alan},
doi = {10.1111/j.1540-6261.1987.tb02568.x},
issn = {00221082},
journal = {The Journal of Finance},
month = {jun},
number = {2},
pages = {281--300},
title = {{The pricing of options on assets with stochastic volatilities}},
url = {http://doi.wiley.com/10.1111/j.1540-6261.1987.tb02568.x},
volume = {42},
year = {1987}
}
@unpublished{Haltmaier2008,
author = {Haltmaier, Jane},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Haltmaier - 2008 - Predicting Cycles in Economic Activity.pdf:pdf},
institution = {Board of Governors of the Federal Reserve System},
number = {926},
series = {International Finance},
title = {{Predicting Cycles in Economic Activity}},
year = {2008}
}
@article{Rohan2013,
abstract = {In this paper, a non-stationary time-varying GARCH (tvGARCH) model has been introduced by allowing the parameters of a stationary GARCH model to vary as functions of time. It is shown that the tvGARCH process is locally stationary in the sense that it can be locally approximated by stationary GARCH processes at fixed time points. We develop a two-step local polynomial procedure for the estimation of the parameter functions of the proposed model. Several asymptotic properties of the estimators have been established, including the asymptotic optimality. It is found that the tvGARCH model performs better than many of the standard GARCH models for various real data sets.},
author = {Rohan, Neelabh and Ramanathan, T. V.},
journal = {Journal of Nonparametric Statistics},
keywords = {62G05,62M10,local polynomial estimation,time-varying GARCH,volatility modelling},
language = {en},
month = {mar},
number = {1},
pages = {33--52},
publisher = {Taylor {\&} Francis},
title = {{Nonparametric estimation of a time-varying GARCH model}},
url = {http://www.tandfonline.com/doi/abs/10.1080/10485252.2012.728600{\#}.VR1f9Fp16ao},
volume = {25},
year = {2013}
}
@article{Monfort2012,
abstract = {The purpose of the paper is to introduce, in a discrete-time no-arbitrage pricing context, a bridge between the historical and the risk-neutral state vector dynamics which is wider than the one implied by a classical exponential-affine stochastic discount factor (SDF) and to preserve, at the same time, the tractability and flexibility of the associated assetpricing model. This goal is achieved by introducing the notion of exponential-quadratic SDF or, equivalently, the notion of Second-OrderEsscherTransform. The log-pricing kernel is specified as a quadratic function of the factor and the associated sources of risk are priced by means of possibly non-linear stochastic first-order and second-order risk-correction coefficients. Focusing on security market models, this approach is developed in the multivariate conditionally Gaussian framework and its usefulness is testified by the specification and calibration of what we name the Second-Order GARCH Option Pricing Model. The associated European Call option pricing formula generates a rich family of implied volatility smiles and skews able to match the typically observed ones.},
author = {Monfort, Alain and Pegoraro, Fulvio},
issn = {03784266},
journal = {Journal of Banking {\&} Finance},
keywords = {g12,g13},
month = {jun},
number = {6},
pages = {1678--1687},
title = {{Asset pricing with second-order Esscher transforms}},
url = {http://dx.doi.org/10.1016/j.jbankfin.2012.01.014},
volume = {36},
year = {2012}
}
@inproceedings{Perryman,
author = {Perryman, P.C. and Stubberud, A.R.},
booktitle = {Conference Record of The Thirtieth Asilomar Conference on Signals, Systems and Computers},
doi = {10.1109/ACSSC.1996.600846},
isbn = {0-8186-7646-9},
pages = {146--150},
publisher = {IEEE Comput. Soc. Press},
title = {{Uniform, in-probability approximation of stochastic systems}},
url = {http://ieeexplore.ieee.org/document/600846/},
volume = {1},
year = {1997}
}
@unpublished{Personal2009,
author = {Gogas, Periklis and Chionis, Dionisios and Pragidis, Ionnis},
booktitle = {Online},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Chionis, Gogas, Pragidis - 2009 - Predicting European Union Recessions in the Euro Area The Yield Curve as a Forecasting Tool of Economi.pdf:pdf},
institution = {MPRA},
number = {13911},
title = {{Predicting European Union recessions in the Euro Area: the yield curve as a forecasting tool of economic activity}},
year = {2009}
}
@article{Han2011,
author = {Hansen, Peter Reinhard and Lunde, Asger and Nason, James M.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Hansen, Lunde, Nason - 2011 - The model confidence set.pdf:pdf},
issn = {0012-9682},
journal = {Econometrica},
number = {2},
pages = {453--497},
title = {{The model confidence set}},
url = {http://doi.wiley.com/10.3982/ECTA5771},
volume = {79},
year = {2011}
}
@incollection{Andersen2013,
address = {Amsterdam},
author = {Andersen, Torben G. and Bollerslev, Tim and Christoffersen, Peter F. and Diebold, Francis X.},
booktitle = {Handbook of the Economics of Finance},
editor = {Constantinedes, G. and Harris, M. and Stulz, R.},
publisher = {Elsevier},
title = {{Financial risk measurement for financial risk management}},
year = {2013}
}
@article{symplectic:slice:theorem,
abstract = {We provide a model for an open invariant neighborhood of any orbit in a symplectic manifold endowed with a canonical proper symmetry. Our results generalize the constructions of Marle and Guillemin and Sternberg for canonical symmetries that have an associated momentum map. In these papers the momentum map played a crucial role in the construction of the tubular model. The present work shows that in the construction of the tubular model, the so-called Chu map, can be used instead, which exists for any canonical action, unlike the momentum map. Hamilton's equations for any invariant Hamiltonian function take on a particularly simple form in these tubular variables. As an application we will ¢nd situations, that we will call tubewise Hamiltonian, in which the existence of a standard momentum map in invariant neighborhoods is guaranteed. Mathematics Subject Classi¢cations (2000). 53D20, 37J15, 58J70, 58E40.},
author = {Ortega, Juan-Pablo and Ratiu, Tudor S.},
journal = {Letters in Mathematical Physics},
pages = {81--93},
title = {{A symplectic slice theorem}},
url = {https://juan-pablo-ortega.com/Publications{\_}files/symplecticslice-ev.pdf},
volume = {59},
year = {2002}
}
@article{Daix2014,
author = {Daix, N and Uccelli, E and Czornomaz, L and Caimi, D and Rossel, C and Sousa, M and Siegwart, H and Marchiori, C and Hartmann, J M and Shiu, K.-T. and Cheng, C.-W. and Krishnan, M and Lofaro, M and Kobayashi, M and Sadana, D and Fompeyrine, J},
doi = {10.1063/1.4893653},
journal = {APL Materials},
number = {8},
pages = {86104},
title = {{Towards large size substrates for III-V co-integration made by direct wafer bonding on Si}},
url = {http://aip.scitation.org/doi/abs/10.1063/1.4893653},
volume = {2},
year = {2014}
}
@article{LeeNelder1996,
annote = {With discussion},
author = {Lee, Y and Nelder, J A},
issn = {0035-9246},
journal = {J. Roy. Statist. Soc. Ser. B},
number = {4},
pages = {619--678},
title = {{Hierarchical generalized linear models}},
url = {http://links.jstor.org/sici?sici=0035-9246(1996)58:4{\%}3C619:HGLM{\%}3E2.0.CO;2-8{\&}origin=MSN},
volume = {58},
year = {1996}
}
@article{condevaux:dazord:and:molino,
address = {Lyon},
author = {Condevaux, M and Dazord, P and Molino, P},
journal = {Travaux du S{\{}{\'{e}}{\}}minaire Sud-Rhodanien de G{\{}{\'{e}}{\}}om{\{}{\'{e}}{\}}trie, I (D{\{}{\'{e}}{\}}p. Math. Nouvelle S{\{}{\'{e}}{\}}r. B)},
pages = {131--160},
publisher = {Univ. Claude-Bernard},
title = {{G{\{}{\'{e}}{\}}om{\{}{\'{e}}{\}}trie du moment}},
volume = {88-1},
year = {1988}
}
@article{Stentoft2008,
abstract = {In this paper we propose a feasible way to price American options in a model with time-varying volatility and conditional skewness and leptokurtosis, using GARCH processes and the Normal Inverse Gaussian distribution. We show how the risk-neutral dynamics can be obtained in this model, we interpret the effect of the risk-neutralization, and we derive approximation procedures which allow for a computationally efficient implementation of the model. When the model is estimated on financial returns data the results indicate that compared to the Gaussian case the extension is important. A study of the model properties shows that there are important option pricing differences compared to the Gaussian case as well as to the symmetric special case. A large scale empirical examination shows that our model out-performs the Gaussian case for pricing options on the three large US stocks as well as a major index. In particular, improvements are found when it comes to explaining the smile in implied standard deviations.},
author = {Stentoft, Lars},
doi = {10.1093/jjfinec/nbn013},
issn = {1479-8409},
journal = {Journal of Financial Econometrics},
month = {jul},
number = {4},
pages = {540--582},
title = {{American option pricing using GARCH models and the Normal Inverse Gaussian distribution}},
url = {http://jfec.oxfordjournals.org/content/6/4/540.short},
volume = {6},
year = {2008}
}
@article{Hansen2011,
author = {Hansen, Peter Reinhard and Huang, Zhuo and Shek, Howard Howan},
journal = {Journal of Applied Econometrics},
number = {6},
pages = {877--906},
title = {{Realized GARCH: a joint model for returns and realized measures of volatility}},
volume = {27},
year = {2011}
}
@article{Chossat:golubitsky,
author = {Chossat, P. and Golubitsky, M.},
journal = {SIAM J. of Math. Anal.},
pages = {1259--1270},
title = {{Iterates of maps with symmetry}},
volume = {19},
year = {1988}
}
@article{gallicchio:esp,
abstract = {In the last years, the Reservoir Computing (RC) framework has emerged as a state of-the-art approach for efficient learning in temporal domains. Recently, within the RC context, deep Echo State Network (ESN) models have been proposed. Being composed of a stack of multiple non-linear reservoir layers, deep ESNs potentially allow to exploit the advantages of a hierarchical temporal feature representation at different levels of abstraction, at the same time preserving the training efficiency typical of the RC methodology. In this paper, we generalize to the case of deep architectures the fundamental RC conditions related to the Echo State Property (ESP), based on the study of stability and contractivity of the resulting dynamical system. Besides providing a necessary condition and a sufficient condition for the ESP of layered RC networks, the results of our analysis provide also insights on the nature of the state dynamics in hierarchically organized recurrent models. In particular, we find out that by adding layers to a deep reservoir architecture, the regime of network's dynamics can only be driven towards (equally or) less stable behaviors. Moreover, our investigation shows the intrinsic ability of temporal dynamics differentiation at the different levels in a deep recurrent architecture, with higher layers in the stack characterized by less contractive dynamics. Such theoretical insights are further supported by experimental results that show the effect of layering in terms of a progressively increased short-term memory capacity of the recurrent models.},
author = {Gallicchio, Claudio and Micheli, Alessio},
doi = {10.1007/s12559-017-9461-9},
issn = {18669964},
journal = {Cognitive Computation},
keywords = {Contractivity,Deep learning,Echo state property,Reservoir computing,Stability analysis},
title = {{Echo state property of deep reservoir computing networks}},
volume = {9},
year = {2017}
}
@article{cucker:smale,
abstract = {In this report the authors study the relationship between approximation and learning, emphasizing the primary role of sampling (inductive inference). Tools and ideas from linear algebra, probability theory and numerical analysis (least squares algorithm) are widely used. As the authors say, ``practical results are not the goal of this paper. Understanding is.'' With this purpose, they illustrate their statements with several examples. The main setting is the following: the existence of an ``unknown'' function fcolon ,X to Y and a probability measure $\rho$ allowing one to randomly draw points in X times Y is assumed, such that for x in X the expected value of a randomly drawn point y in Y is f(x). The (least squares) error of f is defined by scr E(f)=intX times Y (f(x)-y) 2 d$\rho$. The main goal is to find f minimizing scr E(f), where f is taken from a subfamily scr H of continuous functions with the sup-norm on X. Along with the optimizer fscr H of the problem above, the empirical target function fz is considered, minimizing the discrete least squares error for a given sample z in (X times Y) m. Then the error scr E(fz) decomposes as a sum of the sample error (which measures how good fz is as an approximation of fscr H), studied in detail in Chapter I, and the approximation error, which depends only on scr H and $\rho$ (Chapter II). Several estimations on both errors in terms of covering numbers are provided. Also, the bias-variance trade-off problem is discussed (for larger families scr H the approximation errors decrease, but sample errors increase, and vice-versa). Chapter III is devoted to the study of a particular choice of the families scr H, which allows the analysis of algorithms from the point of view of reproducing kernel Hilbert spaces.},
author = {Cucker, Felipe and Smale, Steve},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Smale, Zhou - 2003 - Estimating the approximation error in learning theory.pdf:pdf},
journal = {Bulletin of the American Mathematical Society},
number = {1},
pages = {1--49},
title = {{On the mathematical foundations of learning}},
volume = {39},
year = {2002}
}
@article{Polyak1992,
abstract = {A new recursive algorithm of stochastic approximation type with the averaging of trajectories is investigated. Convergence with probability one is proved for a variety of classical optimization and identification problems. It is also demonstrated for these problems that the proposed algorithm achieves the highest possible rate of convergence.},
author = {Polyak, B. T. and Juditsky, A. B.},
doi = {10.1137/0330046},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Polyak, Juditsky - 1992 - Acceleration of stochastic approximation by averaging.pdf:pdf},
issn = {03630129},
journal = {SIAM Journal on Control and Optimization},
keywords = {1,12,14,16,21,29,40,5,62l20,93e10,93e12,ams,and are currently well,approximation originate in the,introduction,mos,optimal algorithms,recursive estimation,stochastic approximation,stochastic optimization,studied,subject classifications,the methods of stochastic,these methods are,works},
number = {4},
pages = {838--855},
title = {{Acceleration of stochastic approximation by averaging}},
volume = {30},
year = {1992}
}
@article{komogorovnn,
author = {Kolmogorov, A. N.},
journal = {Soviet Math. Dokl},
pages = {179--182},
title = {{On the representation of continuous functions of several variables as superpositions of functions of smaller number of variables}},
volume = {108},
year = {1956}
}
@article{Gaussian_moments2003,
author = {Triantafyllopoulos, K.},
journal = {The Mathematical Scientist},
pages = {125--128},
title = {{On the central moments of the multidimensional Gaussian distribution}},
volume = {28},
year = {2003}
}
@article{widom1966hankel,
author = {Widom, Harold},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Widom - 1966 - Hankel matrices.pdf:pdf},
journal = {Transactions of the American Mathematical Society},
number = {1},
pages = {1--35},
title = {{Hankel matrices}},
volume = {121},
year = {1966}
}
@article{Banerjee2005,
abstract = {Twenty-eight indigenous ewe lambs (6 months of age and 14.4 kg body weight (BW)) were used to evaluate the effect of feeding Sporobolus grass hay (SGH) as the only source of forage on growth, and feed and water intakes. The ewe lambs were randomly and equally allocated to two treatment groups (14 lambs/group). The ewe lambs in group 1 (treatment 1) received SGH, while lambs in group 2 (treatment 2) received Rhodes grass hay (RGH) as the only source of forage. Water was available at all times for both treatment groups. Sporobolus grass was irrigated with brackish water of high salt content (20,000 ppm) and grown in saline desert lands (sabkha) in the United Arab Emirates. The average daily dry matter intake was significantly (P .05) between the two groups at all stages. From these data, we conclude that SGH can replace Rhodes hay in sheep diet without significant effect on sheep performance.},
author = {Banerjee, Anindya and Marcellino, Massimiliano and Masten, Igor},
issn = {03059049},
journal = {Oxford Bulletin of Economics and Statistics},
number = {s1},
pages = {785--813},
title = {{Leading Indicators for Euro-area Inflation and GDP Growth}},
url = {http://doi.wiley.com/10.1111/j.1468-0084.2005.00141.x},
volume = {67},
year = {2005}
}
@article{Shin2018,
author = {Shin, Dong Wan},
journal = {Journal of Korean Statistical Society},
number = {4},
pages = {395--404},
title = {{Forecasting realized volatility: A review}},
volume = {47},
year = {2018}
}
@article{Barndorff-Nielsen2009,
author = {Barndorff-Nielsen, O. E. and Hansen, P. Reinhard and Lunde, A. and Shephard, N.},
issn = {13684221},
journal = {Econometrics Journal},
month = {nov},
number = {3},
pages = {C1--C32},
title = {{Realized kernels in practice: trades and quotes}},
url = {http://doi.wiley.com/10.1111/j.1368-423X.2008.00275.x},
volume = {12},
year = {2009}
}
@article{Buehner:ESN,
abstract = {This letter provides a brief explanation of echo state networks (ESNs) and provides a rigorous bound for guaranteeing asymptotic stability of these networks. The stability bounds presented here could aid in the design of echo state networks that would be applicable to control applications where stability is required.},
author = {Buehner, Michael and Young, Peter},
isbn = {1045-9227},
journal = {IEEE Transactions on Neural Networks},
keywords = {Echo state networks (ESNs),Lyapunov stability,Non-linear systems,Recurrent neural networks (RNN),Robust controls,Weighted operator norms},
number = {3},
pages = {820--824},
pmid = {16722187},
title = {{A tighter bound for the echo state property}},
volume = {17},
year = {2006}
}
@article{Caulfield2010,
abstract = {Could optical technology offer a solution to the heat generation and bandwidth limitations that the computing industry is starting to face? The benefits of energy-efficient passive components, low crosstalk and parallel processing suggest that the answer may be yes.},
author = {Caulfield, H. John and Dolev, Shlomi},
issn = {1749-4885},
journal = {Nature Photonics},
month = {may},
number = {5},
pages = {261--263},
publisher = {Nature Publishing Group},
shorttitle = {Nat Photon},
title = {{Why future supercomputing requires optics}},
volume = {4},
year = {2010}
}
@article{anastasis:neurips,
abstract = {Modifications to a neural network's input and output layers are often required to accommodate the specificities of most practical learning tasks. However, the impact of such changes on architecture's approximation capabilities is largely not understood. We present general conditions describing feature and readout maps that preserve an architecture's ability to approximate any continuous functions uniformly on compacts. As an application, we show that if an architecture is capable of universal approximation, then modifying its final layer to produce binary values creates a new architecture capable of deterministically approximating any classifier. In particular, we obtain guarantees for deep CNNs, deep ffNN, and universal Gaussian processes. Our results also have consequences within the scope of geometric deep learning. Specifically, when the input and output spaces are Hadamard manifolds, we obtain geometrically meaningful feature and readout maps satisfying our criteria. Consequently, commonly used non-Euclidean regression models between spaces of symmetric positive definite matrices are extended to universal DNNs. The same result allows us to show that the hyperbolic feed-forward networks, used for hierarchical learning, are universal. Our result is also used to show that the common practice of randomizing all but the last two layers of a DNN produces a universal family of functions with probability one.},
archivePrefix = {arXiv},
arxivId = {2006.02341},
author = {Kratsios, Anastasis and Bilokopytov, Ievgen},
eprint = {2006.02341},
journal = {34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.},
title = {{Non-Euclidean universal approximation}},
url = {http://arxiv.org/abs/2006.02341},
year = {2020}
}
@article{DeMenezes2006,
abstract = {Recent literature on nonlinear models has shown genetic programming to be a potential tool for forecasters. A special type of genetically programmed model, namely polynomial neural networks, is addressed. Their outputs are polynomials and, as such, they are open boxes that are amenable to comprehension, analysis, and interpretation. This paper presents a polynomial neural network forecasting system, PGP, which has three innovative features: polynomial block reformulation, local ridge regression for weight estimation, and regularized weight subset selection for pruning that uses a least absolute shrinkage and selection operator. The relative performance of this system to other established forecasting procedures is the focus of this research and is illustrated by three empirical studies. Overall, the results are very promising and indicate areas for further research.},
author = {de Menezes, Lilian M. and Nikolaev, Nikolay Y.},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {genetic programming,nonlinear models,statistical learning algorithms,tree-structured polynomial neural network models},
month = {apr},
number = {2},
pages = {249--265},
title = {{Forecasting with genetically programmed polynomial neural networks}},
url = {http://dx.doi.org/10.1016/j.ijforecast.2005.05.002},
volume = {22},
year = {2006}
}
@article{Jackwerth2000,
abstract = {A relationship exists between aggregate risk-neutral and subjective probability distributions and risk aversion functions. We empirically derive risk aversion functions implied by options prices and realized returns on the S{\&}P500 index simultaneously. These risk aversion functions dramatically change shapes around the 1987 crash: Precrash, they are positive and decreasing in wealth and largely consistent with standard assumptions made in economic theory. Postcrash, they are partially negative and partially increasing and irreconcilable with those assumptions. Mispricing in the option market is the most likely cause. Simulated trading strategies exploiting this mispricing show excess returns, even after accounting for the possibility of further crashes, transaction costs, and hedges against the downside risk.},
author = {Jackwerth, Jens Carsten},
issn = {0893-9454},
journal = {Review of Financial Studies},
month = {apr},
number = {2},
pages = {433--451},
title = {{Recovering risk aversion from option prices and realized returns}},
url = {http://rfs.oxfordjournals.org/content/13/2/433.abstract},
volume = {13},
year = {2000}
}
@book{wiggins2013chaotic,
author = {Wiggins, Stephen},
publisher = {Springer Science {\&} Business Media},
title = {{Chaotic transport in dynamical systems}},
volume = {2},
year = {2013}
}
@book{cartan,
author = {Cartan, {\'{E}}.},
publisher = {Hermann},
title = {{Le{\c{c}}ons sur les Invariants Int{\'{e}}graux}},
year = {1922}
}
@inproceedings{Sicuranza1,
author = {Sicuranza, Giovanni L. and Carini, Alberto},
booktitle = {2014 IEEE International Conference on Acoustic, Speech and Signal Processing (ICASSP)},
isbn = {9781479928934},
number = {1},
pages = {7934--7938},
title = {{A novel class of BIBO stable recursive nonlinear filters}},
year = {2014}
}
@book{Beran1994,
author = {Beran, Jan},
publisher = {CRC Press},
title = {{Statistics for Long-Memory Processes}},
year = {1994}
}
@article{Appeltant2011,
abstract = {Novel methods for information processing are highly desired in our information-driven society. Inspired by the brain's ability to process information, the recently introduced paradigm known as 'reservoir computing' shows that complex networks can efficiently perform computation. Here we introduce a novel architecture that reduces the usually required large number of elements to a single nonlinear node with delayed feedback. Through an electronic implementation, we experimentally and numerically demonstrate excellent performance in a speech recognition benchmark. Complementary numerical studies also show excellent performance for a time series prediction benchmark. These results prove that delay-dynamical systems, even in their simplest manifestation, can perform efficient information processing. This finding paves the way to feasible and resource-efficient technological implementations of reservoir computing.},
author = {Appeltant, L. and Soriano, M. C. and {Van der Sande}, G. and Danckaert, J. and Massar, S. and Dambre, J. and Schrauwen, B. and Mirasso, C. R. and Fischer, I.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Appeltant et al. - 2011 - Information processing using a single dynamical node as complex system.pdf:pdf;:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Appeltant et al. - 2011 - Information processing using a single dynamical node as complex system(2).pdf:pdf},
issn = {2041-1723},
journal = {Nature Communications},
month = {jan},
pages = {468},
publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
shorttitle = {Nat Commun},
title = {{Information processing using a single dynamical node as complex system}},
volume = {2},
year = {2011}
}
@techreport{pena:ica,
author = {Garc{\'{i}}a-Ferrer, A and Gonz{\'{a}}lez-Prieto, E and Pe{\~{n}}a},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Garc{\'{i}}a-Ferrer, Gonz{\'{a}}lez-Prieto, Pe{\~{n}}a - 2008 - A multivariate generalized independent factor GARCH model with an application to financ.pdf:pdf},
institution = {Universidad Carlos III de Madrid},
number = {28},
title = {{A multivariate generalized independent factor GARCH model with an application to financial stock returns}},
type = {Statistics and Econometrics Series},
year = {2008}
}
@article{widrowhoff,
author = {Widrow, B. and Hoff, B.},
journal = {RE WESCON Convention record},
pages = {96--104},
title = {{Adaptive switching circuits}},
volume = {4},
year = {1960}
}
@incollection{sontag1991kalman,
author = {Sontag, Eduardo D.},
booktitle = {Mathematical System Theory},
editor = {Antoulas, Athanasios C.},
pages = {453--462},
publisher = {Springer},
title = {{Kalman's controllability rank condition: from linear to nonlinear}},
year = {1991}
}
@article{frechet:volterra_series,
author = {Fr{\'{e}}chet, Maurice},
journal = {Annales scientifiques de l'Ecole Normale Sup{\'{e}}rieure. 3{\`{e}}me s{\'{e}}rie.},
pages = {193--216},
title = {{Sur les fonctionnelles continues}},
volume = {27},
year = {1910}
}
@article{Hill2002,
author = {Hill, M.T. and Frietman, E.E.E. and de Waardt, H. and {Giok-djan Khoe} and Dorren, H.J.S.},
doi = {10.1109/TNN.2002.804222},
issn = {1045-9227},
journal = {IEEE Transactions on Neural Networks},
month = {nov},
number = {6},
pages = {1504--1513},
title = {{All fiber-optic neural network using coupled SOA based ring lasers}},
url = {http://ieeexplore.ieee.org/document/1058084/},
volume = {13},
year = {2002}
}
@article{hutchinson1984kalman,
author = {Hutchinson, Charles E},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Hutchinson - 1984 - The Kalman filter applied to aerospace and electronic systems.pdf:pdf},
journal = {IEEE transactions on aerospace and electronic systems},
number = {4},
pages = {500--504},
publisher = {IEEE},
title = {{The Kalman filter applied to aerospace and electronic systems}},
year = {1984}
}
@article{Jensen2001,
author = {Jensen, Morten B. and Lunde, Asger},
issn = {1368-4221},
journal = {The Econometrics Journal},
month = {dec},
number = {2},
pages = {319--342},
title = {{The NIG-S and ARCH model: a fat-tailed, stochastic, and autoregressive conditional heteroskedastic volatility model}},
url = {http://doi.wiley.com/10.1111/1368-423X.00070},
volume = {4},
year = {2001}
}
@inproceedings{Goodman2006,
author = {Goodman, E. and Ventura, D.},
booktitle = {The 2006 IEEE International Joint Conference on Neural Network Proceedings},
doi = {10.1109/IJCNN.2006.246880},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Goodman, Ventura - 2006 - Spatiotemporal pattern recognition via liquid state machines.pdf:pdf},
isbn = {0-7803-9490-9},
pages = {3848--3853},
publisher = {IEEE},
title = {{Spatiotemporal pattern recognition via liquid state machines}},
url = {http://ieeexplore.ieee.org/document/1716628/},
year = {2006}
}
@incollection{Timmermann2006,
abstract = {Forecast combinations have frequently been found in empirical studies to produce bet- ter forecasts on average than methods based on the ex ante best individual forecasting model. Moreover, simple combinations that ignore correlations between forecast errors often dominate more reﬁned combination schemes aimed at estimating the theoretically optimal combination weights. In this chapter we analyze theoretically the factors that determine the advantages from combining forecasts (for example, the degree of corre- lation between forecast errors and the relative size of the individual models' forecast error variances). Although the reasons for the success of simple combination schemes are poorly understood, we discuss several possibilities related to model misspeciﬁca- tion, instability (non-stationarities) and estimation error in situations where the number of models is large relative to the available sample size. We discuss the role of combina- tions under asymmetric loss and consider combinations of point, interval and probability forecasts.},
author = {Timmermann, Allan},
booktitle = {Handbook of Economic Forecasting},
chapter = {4},
edition = {Elsevier},
editor = {Elliott, Graham and Granger, Clive W.J. and Timmermann, Allan},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Timmermann - 2006 - Forecast combinations.pdf:pdf},
keywords = {diversiﬁcation gains,forecast combinations,misspeciﬁcation,model,pooling and trimming,shrinkage methods},
title = {{Forecast combinations}},
year = {2006}
}
@book{Zaanen:Integration,
author = {Zaanen, Adriaan Cornelis},
edition = {Second},
publisher = {North-Holland},
title = {{Integration}},
year = {1967}
}
@article{Kvedaras2012a,
author = {Kvedaras, Virmantas and Zemlys, Vaidotas},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Kvedaras, Zemlys - 2012 - Testing the functional constraints on parameters in regressions with variables of different frequency.pdf:pdf},
issn = {01651765},
journal = {Economics Letters},
month = {aug},
number = {2},
pages = {250--254},
publisher = {Elsevier B.V.},
title = {{Testing the functional constraints on parameters in regressions with variables of different frequency}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0165176512000961 http://dx.doi.org/10.1016/j.econlet.2012.03.009},
volume = {116},
year = {2012}
}
@inproceedings{Chen2018,
author = {Chen, Ricky T. Q. and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David},
booktitle = {NeurIPS},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Hartman - Unknown - Ordinary Differential Equations.pdf:pdf},
title = {{Neural ordinary differential equations}},
year = {2018}
}
@article{Dumas1998,
author = {Dumas, Bernard and Fleming, Jeff and Whaley, Robert E.},
doi = {10.1111/0022-1082.00083},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Dumas, Fleming, Whaley - 1998 - Implied Volatility Functions Empirical Tests.pdf:pdf},
issn = {00221082},
journal = {The Journal of Finance},
month = {dec},
number = {6},
pages = {2059--2106},
title = {{Implied Volatility Functions: Empirical Tests}},
url = {http://doi.wiley.com/10.1111/0022-1082.00083},
volume = {53},
year = {1998}
}
@article{Rodan2011,
abstract = {Reservoir computing (RC) refers to a new class of state-space models with a fixed state transition structure (the reservoir) and an adaptable readout form the state space. The reservoir is supposed to be sufficiently complex so as to capture a large number of features of the input stream that can be exploited by the reservoir-to-output readout mapping. The field of RC has been growing rapidly with many successful applications. However, RC has been criticized for not being principled enough. Reservoir construction is largely driven by a series of randomized model-building stages, with both researchers and practitioners having to rely on a series of trials and errors. To initialize a systematic study of the field, we concentrate on one of the most popular classes of RC methods, namely echo state network, and ask: What is the minimal complexity of reservoir construction for obtaining competitive models and what is the memory capacity (MC) of such simplified reservoirs? On a number of widely used time series benchmarks of different origin and characteristics, as well as by conducting a theoretical analysis we show that a simple deterministically constructed cycle reservoir is comparable to the standard echo state network methodology. The (short-term) MC of linear cyclic reservoirs can be made arbitrarily close to the proved optimal value.},
author = {Rodan, Ali and Tino, Peter},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Rodan, Tino - 2011 - Minimum complexity echo state network.pdf:pdf},
issn = {1941-0093},
journal = {IEEE Transactions on Neural Networks},
keywords = {Algorithms,Artificial Intelligence,Computer Simulation,Computer Simulation: standards,Linear Models,Neural Networks (Computer),Nonlinear Dynamics,Software Design,Time Factors},
language = {English},
month = {jan},
number = {1},
pages = {131--44},
title = {{Minimum complexity echo state network.}},
volume = {22},
year = {2011}
}
@article{PattonCopula,
author = {Patton, A. J.},
journal = {International Economic Review},
number = {2},
pages = {527--556},
title = {{Modelling asymmetric exchange rate dependence}},
volume = {47},
year = {2006}
}
@book{Frenkel1996,
address = {Orlando, FL, USA},
edition = {1st},
editor = {Frenkel, Daan and Smit, Berend},
isbn = {0122673700},
publisher = {Academic Press, Inc.},
title = {{Understanding Molecular Simulation: From Algorithms to Applications}},
year = {1996}
}
@misc{lorenz1963deterministic,
author = {Lorenz, Edward N.},
booktitle = {Journal of the Atmospheric Sciences},
pages = {130--141},
title = {{Deterministic nonperiodic flow}},
volume = {20},
year = {1963}
}
@article{Mukherjee:Wu,
author = {Mukherjee, Sayan and Wu, Qiang and Zhou, Ding-Xuan},
doi = {10.3150/09-BEJ206},
issn = {1350-7265},
journal = {Bernoulli},
keywords = {Tikhonov regularization,classification,feature selection,manifold learning,regression,shrinkage estimator},
month = {feb},
number = {1},
pages = {181--207},
publisher = {Bernoulli Society for Mathematical Statistics and Probability},
title = {{Learning gradients on manifolds}},
url = {http://projecteuclid.org/euclid.bj/1265984708},
volume = {16},
year = {2010}
}
@article{a61e,
author = {Arnold, V. I.},
journal = {Soviet Math.},
pages = {247--249},
title = {{The stability of the equilibrium position of a Hamiltonian system of ordinary differential equations in the general elliptic case (English)}},
volume = {2},
year = {1961}
}
@article{Abel2013c,
author = {Abel, S and Sousa, M and Rossel, C and Caimi, D and Rossell, M D and Erni, R and Fompeyrine, J and Marchiori, C},
doi = {10.1088/0957-4484/24/28/285701},
issn = {0957-4484},
journal = {Nanotechnology},
number = {28},
pages = {article no 285701},
title = {{Controlling tetragonality and crystalline orientation in BaTiO 3 nano-layers grown on Si}},
url = {http://stacks.iop.org/0957-4484/24/i=28/a=285701?key=crossref.7ab849f0c6f95d7f0f3621362543eb70},
volume = {24},
year = {2013}
}
@misc{Nakamura2005,
abstract = {This paper evaluates the usefulness of neural networks for inflation forecasting. In a pseudo out-of-sample forecasting experiment using recent U.S. data, neural networks outperform univariate autoregressive models on average for short horizons of 1 and 2 quarters. A simple specification of the neural network model and specialized estimation procedures from the neural networks literature appear to play significant roles in the success of the neural network model.},
author = {Nakamura, Emi},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Nakamura - 2005 - Inflation Forecasting using a Neural Network.pdf:pdf},
keywords = {c51,c52,c53,e37,forecasting,jel classifications,linearity,model selection},
title = {{Inflation Forecasting using a Neural Network}},
year = {2005}
}
@incollection{schweizer:2001,
address = {Cambridge},
author = {Schweizer, Martin},
booktitle = {Option pricing, interest rates and risk management, Handbook of Mathematical Finance},
pages = {538--574},
publisher = {Cambridge University Press},
title = {{A guided tour through quadratic hedging approaches}},
year = {2001}
}
@article{kocarev1995general,
author = {Kocarev, Lj and Parlitz, U},
journal = {Physical Review Letters},
number = {25},
pages = {5028--5031},
publisher = {APS},
title = {{General approach for chaotic synchronization with applications to communication}},
volume = {74},
year = {1995}
}
@article{Corsi2013,
abstract = {We develop a discrete-time stochastic volatility option pricing model exploiting the information contained in the Realized Volatility (RV), which is used as a proxy of the unobservable log-return volatility. We model the RV dynamics by a simple and effective long-memory process, whose parameters can be easily estimated using historical data. Assuming an exponentially affine stochastic discount factor, we obtain a fully analytic change of measure. An empirical analysis of Standard and Poor's 500 index options illustrates that our model outperforms competing time-varying and stochastic volatility option pricing models.},
author = {Corsi, Fulvio and Fusari, Nicola and {La Vecchia}, Davide},
issn = {0304405X},
journal = {Journal of Financial Economics},
keywords = {C13,G12,G13,High-frequency,Option pricing,Realized volatility},
month = {feb},
number = {2},
pages = {284--304},
title = {{Realizing smiles: Options pricing with realized volatility}},
url = {http://www.sciencedirect.com/science/article/pii/S0304405X12001808},
volume = {107},
year = {2013}
}
@phdthesis{normand1983theorie,
author = {Normand-Cyrot, Doroth{\'{e}}e},
school = {Universit{\'{e}} Paris-Sud},
title = {{Th{\'{e}}orie et Pratique des Syst{\`{e}}mes Non Lin{\'{e}}aires en Temps Discret}},
year = {1983}
}
@book{Mohri:learning:2012,
author = {Mohri, Mehryar and Rostamizadeh, Afshin and Tawalkar, Ameet},
edition = {Second},
isbn = {9780262018258},
publisher = {The MIT Press},
title = {{Foundations of Machine Learning}},
year = {2018}
}
@inproceedings{HR09,
author = {Hansen, L. P. and Renault, Eric},
booktitle = {Encyclopedia of Quantitative Finance},
pages = {1418--1427},
publisher = {Wiley},
title = {{Pricing kernels and stochastic discount factors}},
year = {2009}
}
@article{arnold66,
author = {Arnold, V. I.},
journal = {Ann. Ins. Fourier, Grenoble},
pages = {319--361},
title = {{Sur la g{\'{e}}ometrie differentielle des groupes de Lie de dimensioninfinie et ses applications {\`{a}} l'hydrodynamique des fluidsparfaits}},
volume = {16},
year = {1966}
}
@article{Moneta2005,
author = {Moneta, Fabio},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Moneta - 2005 - Does the Yield Spread Predict Recessions in the Euro Area.pdf:pdf},
issn = {1367-0271},
journal = {International Finance},
month = {aug},
number = {2},
pages = {263--301},
title = {{Does the Yield Spread Predict Recessions in the Euro Area?}},
url = {http://doi.wiley.com/10.1111/j.1468-2362.2005.00159.x},
volume = {8},
year = {2005}
}
@article{Basu1986,
author = {Basu, A. K. and {Sen Roy}, S.},
journal = {Calcutta Statistical Association Bull},
pages = {123--132},
title = {{On some asymptotic results for multivariate autoregressive models with estimated parameters}},
volume = {35},
year = {1986}
}
@article{cartan:1904,
author = {Cartan, {\'{E}}.},
journal = {Ann. Ec. Norm. Sup.},
pages = {219--308},
title = {{Sur la structure des groupes infinis de transformation}},
volume = {22},
year = {1904}
}
@article{MCS:forecasting,
author = {Hansen, Peter Reinhard and Lunde, Asger and Nason, James M.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Hansen, Lunde, Nason - Unknown - Model confidence sets for forecasting models.pdf:pdf},
title = {{Model confidence sets for forecasting models}}
}
@article{Giannone2008,
abstract = {A formal method is developed for evaluating the marginal impact that intra-monthly data releases have on current-quarter forecasts (nowcasts) of real gross domestic product (GDP) growth. The method can track the real-time flow of the type of information monitored by central banks because it can handle large data sets with staggered data-release dates. Each time new data are released, the nowcasts are updated on the basis of progressively larger data sets that, reflecting the unsynchronized data-release dates, have a “jagged edge” across the most recent months.},
author = {Giannone, Domenico and Reichlin, Lucrezia and Small, David},
issn = {03043932},
journal = {Journal of Monetary Economics},
keywords = {c33,c53,e52},
month = {may},
number = {4},
pages = {665--676},
title = {{Nowcasting: The real-time informational content of macroeconomic data}},
url = {http://dx.doi.org/10.1016/j.jmoneco.2008.05.010},
volume = {55},
year = {2008}
}
@article{Diblik2012_2,
author = {Dibl{\'{i}}k, Josef and Khusainov, Denis and Kukharenko, Oleksandra},
journal = {Nonlinear Dynamics and Systems Theory},
number = {2},
pages = {251--268},
title = {{Representation of the solution for linear system of delay equations with distributed parameters}},
url = {http://sunrise-0014438.e-ndst.kiev.ua/v12n3/V12N3.pdf},
volume = {12},
year = {2012}
}
@article{abarbanel:pgs,
abstract = {Reservoir computers (RC) are a form of recurrent neural network (RNN) used for forecasting timeseries data. As with all RNNs, selecting the hyperparameters presents a challenge when training onnew inputs. We present a method based on generalized synchronization (GS) that gives direction in designing and evaluating the architecture and hyperparameters of an RC. The 'auxiliary method' for detecting GS provides a computationally efficient pre-training test that guides hyperparameterselection. Furthermore, we provide a metric for RC using the reproduction of the input system's Lyapunov exponentsthat demonstrates robustness in prediction.},
archivePrefix = {arXiv},
arxivId = {2103.00362},
author = {Platt, Jason A. and Wong, Adrian S. and Clark, Randall and Penny, Stephen G. and Abarbanel, Henry D. I.},
doi = {10.1063/5.0066013},
eprint = {2103.00362},
issn = {1054-1500},
number = {November},
publisher = {AIP Publishing LLC},
title = {{Robust forecasting using predictive generalized synchronization in reservoir computing}},
url = {http://arxiv.org/abs/2103.00362},
volume = {123118},
year = {2021}
}
@article{kulis:sustik:dhillon,
author = {Kulis, Brian and Sustik, M{\'{a}}ty{\'{a}}s A and Dhillon, Inderjit S},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Kulis, Sustik, Dhillon - 2009 - Low-rank kernel learning with Bregman matrix divergences.pdf:pdf},
issn = {1532-4435},
journal = {J. Mach. Learn. Res.},
pages = {341--376},
title = {{Low-rank kernel learning with Bregman matrix divergences}},
volume = {10},
year = {2009}
}
@misc{Hamilton2010,
author = {Hamilton, James D.},
booktitle = {Energy},
title = {{Nonlinearities and the Macroeconomic Effects of Oil Prices}},
year = {2010}
}
@article{Eichler2011,
author = {Eichler, Andreas and Leobacher, Gunther and Zellinger, Heidrun},
issn = {0929-9629},
journal = {Monte Carlo Methods and Applications},
month = {jan},
number = {2},
pages = {99--131},
title = {{Calibration of financial models using quasi-Monte Carlo}},
url = {http://www.degruyter.com/view/j/mcma.2011.17.issue-2/mcma.2011.004/mcma.2011.004.xml},
volume = {17},
year = {2011}
}
@article{Rudebusch2009,
author = {Rudebusch, Glenn D.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Rudebusch - 2009 - Forecasting Recessions The Puzzle of the Enduring Power of the Yield Curve.pdf:pdf},
issn = {0735-0015},
journal = {Journal of Business and Economic Statistics},
keywords = {Probability forecasts, Real-time, Yield spread,,and,but probably would not,first on monday and,former fed chairman,greenspan upset stock markets,merely by uttering the,occur by the end,of this year,probability forecasts,real-time,recession,saying that one might,then again on thursday,word,yield spread},
month = {oct},
number = {4},
pages = {492--503},
title = {{Forecasting Recessions: The Puzzle of the Enduring Power of the Yield Curve}},
url = {http://pubs.amstat.org/doi/abs/10.1198/jbes.2009.07213},
volume = {27},
year = {2009}
}
@article{escribano2011small,
author = {Escribano, C and Gonzalo, R and Torrano, E},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Escribano, Gonzalo, Torrano - 2011 - Small eigenvalues of large Hermitian moment matrices.pdf:pdf},
journal = {Journal of mathematical analysis and applications},
number = {2},
pages = {470--480},
publisher = {Academic Press},
title = {{Small eigenvalues of large Hermitian moment matrices}},
volume = {374},
year = {2011}
}
@article{matouvsek2008variants,
author = {Matou{\v{s}}ek, Jivri},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Matou{\v{s}}ek - 2008 - On variants of the Johnson--Lindenstrauss lemma.pdf:pdf},
journal = {Random Structures {\&} Algorithms},
number = {2},
pages = {142--156},
publisher = {Wiley Online Library},
title = {{On variants of the Johnson--Lindenstrauss lemma}},
volume = {33},
year = {2008}
}
@incollection{Kvedaras2003,
author = {Kvedaras, Virmantas and Rackauskas, Alfredas and Zuokas, Danas},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Kvedaras, Rackauskas, Zuokas - 2003 - Regression Models of Macroeconomic Indicators with Explanatory Variables Observed at a Higher Freq.pdf:pdf},
pages = {87--99},
title = {{Regression Models of Macroeconomic Indicators with Explanatory Variables Observed at a Higher Frequency}},
year = {2003}
}
@article{Cox2004,
abstract = {For likelihood-based inference involving distributions in which high-dimensional dependencies are present it may be useful to use approximate likelihoods based, for example, on the univariate or bivariate marginal distributions. The asymptotic properties of formal maximum likelihood estimators in such cases are outlined. In particular, applications in which only a single qx1 vector of observations is observed are examined. Conditions under which consistent estimators of parameters result from the approximate likelihood using only pairwise joint distributions are studied. Some examples are analysed in detail.},
author = {Cox, D. R. and Reid, N.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Cox, Reid - 2004 - A note on pseudolikelihood constructed from marginal densities.pdf:pdf},
issn = {0006-3444},
journal = {Biometrika},
month = {sep},
number = {3},
pages = {729--737},
title = {{A note on pseudolikelihood constructed from marginal densities}},
url = {http://biomet.oxfordjournals.org/content/91/3/729.short},
volume = {91},
year = {2004}
}
@article{Mukhopadhyay2020,
author = {Mukhopadhyay, Sumona and Banerjee, Santo},
doi = {10.1063/5.0009326},
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
number = {10},
pages = {103125},
title = {{Learning dynamical systems in noise using convolutional neural networks}},
url = {https://doi.org/10.1063/5.0009326},
volume = {30},
year = {2020}
}
@article{CandesRecht:FondCompMath09,
author = {Cand{\`{e}}s, Emmanuel J and Recht, Benjamin},
doi = {10.1007/s10208-009-9045-5},
issn = {1615-3375},
journal = {Found. Comput. Math.},
number = {6},
pages = {717--772},
title = {{Exact matrix completion via convex optimization}},
url = {http://dx.doi.org/10.1007/s10208-009-9045-5},
volume = {9},
year = {2009}
}
@article{bollerslev:vec,
author = {Bollerslev, Tim and Engle, Robert F. and Wooldridge, J. M.},
journal = {Journal of Political Economy},
pages = {116--131},
title = {{A capital asset pricing model with time varying covariances}},
volume = {96},
year = {1988}
}
@article{RV2006Podolskij,
author = {Christensen, K. and Podolskij, M.},
journal = {Journal of Econometrics},
number = {2},
pages = {323--349},
title = {{Realized range-based estimation of integrated variance}},
volume = {141},
year = {2007}
}
@article{Fiers2012,
abstract = {We present a tool that aids in the modeling of optical circuits, both in the frequency and in the time domain. The tool is based on the definition of a node, which can have both an instantaneous input-output relation and different state variables (e.g., temperature and carrier density) and differential equations for these states. Furthermore, each node has access to part of its input history, allowing the creation of delay lines or digital filters. Additionally, a node can contain subnodes, allowing the creation of hierarchical networks. This tool can be used in numerous applications such as frequency-domain analysis of optical ring filters, time-domain analysis of optical amplifiers, microdisks, and microcavities. Although we mainly use this tool to model optical circuits, it can also be used to model other classes of dynamical systems, such as electrical circuits and neural networks.},
author = {Fiers, Martin and {Van Vaerenbergh}, Thomas and Caluwaerts, Ken and {Vande Ginste}, Dries and Schrauwen, Benjamin and Dambre, Joni and Bienstman, Peter},
doi = {10.1364/JOSAB.29.000896},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Fiers et al. - 2012 - Time-domain and frequency-domain modeling of nonlinear optical components at the circuit-level using a node-based.pdf:pdf},
issn = {0740-3224},
journal = {Journal of the Optical Society of America B},
keywords = {Integrated optics devices,Nonlinear optics,Systems design,integrated optics},
month = {may},
number = {5},
pages = {896},
publisher = {Optical Society of America},
title = {{Time-domain and frequency-domain modeling of nonlinear optical components at the circuit-level using a node-based approach}},
url = {https://www.osapublishing.org/abstract.cfm?URI=josab-29-5-896},
volume = {29},
year = {2012}
}
@article{Carr2005,
author = {Carr, R. and Madan, Dilip B.},
journal = {Finance Research Letters},
number = {3},
pages = {125--130},
title = {{A note on sufficient conditions for no arbitrage}},
volume = {2},
year = {2005}
}
@article{Chabi-Yo2008,
abstract = {Risk aversion functions extracted from observed stock and option prices can be negative, as shown by Ait-Sahalia and Lo (2000), Journal of Econometrics 94: 9-51; and Jackwerth (2000), The Review of Financial Studies 13(2), 433-51. We rationalize this puzzle by a lack of conditioning on latent state variables. Once properly conditioned, risk aversion functions and pricing kernels are consistent with economic theory. To differentiate between the various theoretical explanations in terms of heterogeneity of beliefs or preferences, market sentiment, state-dependent utility, or regimes in fundamentals, we calibrate several consumption-based asset pricing models to match the empirical pricing kernel and risk aversion functions at different dates and over several years.},
author = {Chabi-Yo, Fousseni and Garcia, Ren{\'{e}} and Renault, Eric},
issn = {0893-9454},
journal = {Review of Financial Studies},
month = {apr},
number = {2},
pages = {973--1011},
title = {{State dependence can explain the risk aversion puzzle}},
url = {http://rfs.oxfordjournals.org/content/21/2/973.short},
volume = {21},
year = {2008}
}
@incollection{mr,
author = {Meyer, K. R.},
booktitle = {Dynamical Systems},
editor = {Peixoto, M. M.},
pages = {259--273},
publisher = {Academic Press},
title = {{Symmetries and integrals in mechanics}},
year = {1973}
}
@article{Dahlhaus2006,
author = {Dahlhaus, Rainer and Rao, Suhasini Subba},
issn = {2168-8966},
journal = {The Annals of Statistics},
keywords = {Derivative process,locally stationary,quasi-likelihood estimates,time-varying ARCH process},
month = {jun},
number = {3},
pages = {1075--1114},
publisher = {Institute of Mathematical Statistics},
title = {{Statistical inference for time-varying ARCH processes}},
url = {http://projecteuclid.org/euclid.aos/1152540743},
volume = {34},
year = {2006}
}
@article{Hamilton1988,
author = {Hamilton, James D},
journal = {Journal of Economic Dynamics and Control},
pages = {385--423},
title = {{Rational-Expectations Econometric Analysis of Changes in Regime, An Investigation of the Term Structure of Interest Rates}},
volume = {12},
year = {1988}
}
@book{Pikovsky2001,
address = {Cambridge},
author = {Pikovsky, A. and Rosenblum, M. and Kurths, J.},
publisher = {Cambridge Nonlinear Science Series 12},
title = {{Synchronization: A Universal Concept in Nonlinear Science}},
year = {2001}
}
@article{Narendra1990,
author = {Narendra, K.S. and Parthasarathy, K.},
doi = {10.1109/72.80202},
issn = {10459227},
journal = {IEEE Transactions on Neural Networks},
month = {mar},
number = {1},
pages = {4--27},
title = {{Identification and control of dynamical systems using neural networks}},
url = {http://ieeexplore.ieee.org/document/80202/},
volume = {1},
year = {1990}
}
@book{Durrett2010,
address = {Cambridge},
author = {Durrett, Rick},
edition = {Fourth},
publisher = {Cambridge University Press},
series = {Cambridge Series in Statistical and Probabilistic Mathematics},
title = {{Probability: Theory and Examples}},
year = {2010}
}
@article{Sadasivan1994,
abstract = {In this paper, we propose a neural network (NN) approach to the enhancement of EEG signals in the presence of EOG artefacts. We recast the EEG enhancement problem into the optimization framework by developing an appropriate cost function. The cost function is nothing but the energy in the enhanced EEG signal obtained through a nonlinear filter formulation, unlike the conventionally-used linear filter formulation. The minimization property of feedback-type neural networks is exploited to solve this problem. An analysis has been performed to characterize the stationary points of the suggested energy function. The hardware set-up of the developed neural network has also been derived. The optimum nonlinear filter coefficients obtained from this minimization algorithm are used to estimate the EOG artefact which is then subtracted from the corrupted EEG signal, sample by sample, to get the artefact minimized signal. The time plots as the LP spectrum show that the proposed method is very effective. Thus the power and efficacy of the NN approach have been exploited for the purpose of minimizing EOG artefacts from corrupted EEG signals.},
author = {Sadasivan, P. K. and Dutt, D. Narayana},
issn = {0010-4825},
journal = {Computers in biology and medicine},
keywords = {Electroencephalogram,Eye movement artefacts,Neural networks,Noise minimization,Nonlinear optimization,Volterra nonlinearity},
month = {nov},
number = {6},
pages = {441--449},
pmid = {7789129},
title = {{Minimization of EOG artefacts from corrupted EEG signals using a neural network approach}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/7789129},
volume = {24},
year = {1994}
}
@article{Hansen2003,
author = {Hansen, Peter Reinhard and Lunde, Asger and Nason, James M.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Hansen, Lunde, Nason - 2003 - Choosing the best volatility models the model confidence set approach(2).pdf:pdf},
issn = {0305-9049},
journal = {Oxford Bulletin of Economics and Statistics},
month = {dec},
number = {s1},
pages = {839--861},
title = {{Choosing the best volatility models: the model confidence set approach}},
url = {http://doi.wiley.com/10.1046/j.0305-9049.2003.00086.x},
volume = {65},
year = {2003}
}
@article{TauchenSV,
author = {Tauchen, G. E. and Pitts, M.},
journal = {Econometrica},
pages = {485--505},
title = {{The price variability-volume relationship on speculative markets}},
volume = {51},
year = {1983}
}
@article{Shirts2000,
author = {Shirts, Michael and Pande, Vijay S.},
doi = {10.1126/science.290.5498.1903},
issn = {0036-8075},
journal = {Science},
number = {5498},
pages = {1903--1904},
publisher = {American Association for the Advancement of Science},
title = {{Screen savers of the world unite!}},
url = {http://science.sciencemag.org/content/290/5498/1903},
volume = {290},
year = {2000}
}
@article{Gabriel2016,
abstract = {Un des d{\'{e}}fis majeurs auxquels sont confront{\'{e}}s les services de r{\'{e}}animation est de pouvoir pr{\'{e}}dire pr{\'{e}}cis{\'{e}}ment et pr{\'{e}}cocement vers quel {\'{e}}tat {\'{e}}voluera la conscience des patients dans le coma pour anoxie c{\'{e}}r{\'{e}}brale. Afin d'obtenir des indices directs sur l'{\'{e}}tat c{\'{e}}r{\'{e}}bral fonctionnel, l'emploi des potentiels {\'{e}}voqu{\'{e}}s est recommand{\'{e}}, et notamment l'enregistrement de la n{\'{e}}gativit{\'{e}} de discordance (MMN). La MMN est une onde c{\'{e}}r{\'{e}}brale apparaissant entre 100 et 200ms apr{\`{e}}s l'apparition d'un nouveau stimulus dans une s{\'{e}}quence de stimuli identique et sa pr{\'{e}}sence est un signe fort de r{\'{e}}cup{\'{e}}ration. Le standard dans la d{\'{e}}termination de la pr{\'{e}}sence d'une onde MMN en pratique clinique est l'analyse visuelle par le clinicien qui d{\'{e}}termine la diff{\'{e}}rence {\'{e}}lectrophysiologique entre les sons standards et les sons d{\'{e}}viants. Cependant, le signal {\'{e}}tant souvent de faible amplitude et bruit{\'{e}} chez les patients dans le coma, plusieurs m{\'{e}}thodes math{\'{e}}matiques ont {\'{e}}t{\'{e}} d{\'{e}}velopp{\'{e}}es pour aider le clinicien. Malheureusement, il existe autant de m{\'{e}}thodes math{\'{e}}matiques que d'{\'{e}}quipes de recherche sp{\'{e}}cialis{\'{e}}es dans la d{\'{e}}termination de la MMN. Dans cette {\'{e}}tude, nous avons cherch{\'{e}} {\`{a}} d{\'{e}}terminer si les six principales m{\'{e}}thodes math{\'{e}}matiques {\'{e}}taient une aide {\`{a}} la d{\'{e}}tection d'une onde MMN en r{\'{e}}animation. Pour cela, nous avons test{\'{e}} 27 individus parfaitement conscients dans des conditions o{\`{u}} le signal {\'{e}}lectrophysiologique pr{\'{e}}sentait un rapport signal sur bruit semblable {\`{a}} celui de patients dans le coma. De grandes disparit{\'{e}}s ont {\'{e}}t{\'{e}} observ{\'{e}}es, et une onde MMN a pu {\^{e}}tre mise en {\'{e}}vidence par toutes les m{\'{e}}thodes math{\'{e}}matiques chez seulement quatre sujets. Nos r{\'{e}}sultats montrent que l'utilisation de m{\'{e}}thodes statiques complexes ne r{\'{e}}sout pas l'incertitude quant {\`{a}} la pr{\'{e}}sence ou l'absence de la MMN et au contraire peut compliquer la prise de d{\'{e}}cision du clinicien [1].},
author = {Gabriel, Damien and Muzard, Emelyne and Henriques, Julie and Mignot, Coralie and Pazart, Lionel and Andr{\'{e}}-Obadia, Nathalie and Ortega, Juan-Pablo and Moulin, Thierry},
doi = {10.1016/j.neucli.2016.05.048},
issn = {09877053},
journal = {Neurophysiologie Clinique/Clinical Neurophysiology},
number = {2},
pages = {84--85},
title = {{L'emploi de m{\'{e}}thodes math{\'{e}}matiques pour d{\'{e}}tecter la pr{\'{e}}sence de potentiels {\'{e}}voqu{\'{e}}s dans le coma : un aide ou un fardeau ?}},
volume = {46},
year = {2016}
}
@inproceedings{el1995hierarchical,
author = {{El Hihi}, Salah and Bengio, Yoshua},
booktitle = {NIPS},
organization = {Citeseer},
pages = {493--499},
title = {{Hierarchical recurrent neural networks for long-term dependencies}},
volume = {400},
year = {1995}
}
@article{Hamilton2003,
author = {Hamilton, James D.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Hamilton - 2003 - What is an oil shock.pdf:pdf},
issn = {03044076},
journal = {Journal of Econometrics},
keywords = {economic uctuations,functional form,nonlinear models,oil shocks},
month = {apr},
number = {2},
pages = {363--398},
title = {{What is an oil shock?}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304407602002075},
volume = {113},
year = {2003}
}
@article{Kalliovirta2015,
author = {Kalliovirta, Leena and Meitz, Mika and Saikkonen, Pentti},
journal = {Journal of Time Series Analysis},
number = {2},
pages = {247--266},
title = {{A Gaussian mixture autoregressive model for univariate time series}},
volume = {36},
year = {2015}
}
@book{ott2002chaos,
author = {Ott, Edward},
edition = {Second},
publisher = {Cambridge University Press},
title = {{Chaos in Dynamical Systems}},
year = {2002}
}
@article{andersen:bollerslev,
author = {Andersen, T G and Bollerslev, T},
journal = {Journal of Empirical Finance},
pages = {115--158},
title = {{Answering the skeptics: yes, standard volatility models do provide accurate forecasts}},
volume = {4},
year = {1997}
}
@article{Meddahi2004,
abstract = {In this paper, we consider temporal aggregation of volatility models. We introduce semiparametric volatility models, termed square-root stochastic autoregressive volatility (SR-SARV), which are characterized by autoregressive dynamics of the stochastic variance. Our class encompasses the usual GARCH models and various asymmetric GARCH models. Moreover, our stochastic volatility models are characterized by multiperiod conditional moment restrictions in terms of observables. The SR-SARV class is a natural extension of the class of weak GARCH models. This extension has four advantages: (i) we do not assume that fourth moments are finite; (ii) we allow for asymmetries (skewness, leverage effect) that are excluded from weak GARCH models; (iii) we derive conditional moment restrictions and (iv) our framework allows us to study temporal aggregation of IGARCH models.},
author = {Meddahi, Nour and Renault, Eric},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Meddahi, Renault - 2004 - Temporal aggregation of volatility models.pdf:pdf},
issn = {03044076},
journal = {Journal of Econometrics},
keywords = {Asset returns,C22,C43,C50,C51,Diffusion processes,GARCH,SR-SARV,State-space,Stochastic volatility,Temporal aggregation},
month = {apr},
number = {2},
pages = {355--379},
title = {{Temporal aggregation of volatility models}},
url = {http://www.sciencedirect.com/science/article/pii/S0304407603002008},
volume = {119},
year = {2004}
}
@article{Abadi2016,
abstract = {TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.},
archivePrefix = {arXiv},
arxivId = {1603.04467},
author = {Abadi, Mart{\'{i}}n and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg S. and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Goodfellow, Ian and Harp, Andrew and Irving, Geoffrey and Isard, Michael and Jia, Yangqing and Jozefowicz, Rafal and Kaiser, Lukasz and Kudlur, Manjunath and Levenberg, Josh and Mane, Dan and Monga, Rajat and Moore, Sherry and Murray, Derek and Olah, Chris and Schuster, Mike and Shlens, Jonathon and Steiner, Benoit and Sutskever, Ilya and Talwar, Kunal and Tucker, Paul and Vanhoucke, Vincent and Vasudevan, Vijay and Viegas, Fernanda and Vinyals, Oriol and Warden, Pete and Wattenberg, Martin and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
eprint = {1603.04467},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Abadi et al. - 2016 - TensorFlow Large-Scale Machine Learning on Heterogeneous Distributed Systems.pdf:pdf},
title = {{TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems}},
url = {http://arxiv.org/abs/1603.04467},
year = {2016}
}
@article{Holmquist1988,
abstract = {Expressions in vector notation are given for the central moments, the non–central moments and the cumulants of arbitrary order of the multivariate normal distribution},
author = {Holmquist, Bj{\"{o}}rn},
issn = {0736-2994},
journal = {Stochastic Analysis and Applications},
language = {en},
month = {jan},
number = {3},
pages = {273--278},
publisher = {Marcel Dekker, Inc.},
title = {{Moments and cumulants of the multivariate normal distribution}},
url = {http://www.tandfonline.com/doi/abs/10.1080/07362998808809148?journalCode=lsaa20},
volume = {6},
year = {1988}
}
@article{berg2011smallest,
author = {Berg, Christian and Szwarc, Ryszard},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Berg, Szwarc - 2011 - The smallest eigenvalue of Hankel matrices.pdf:pdf},
journal = {Constructive Approximation},
number = {1},
pages = {107--133},
publisher = {Springer},
title = {{The smallest eigenvalue of Hankel matrices}},
volume = {34},
year = {2011}
}
@article{kalman1959unified,
author = {Kalman, R E and Bertram, J E},
journal = {Journal of the Franklin Institute},
number = {5},
pages = {405--436},
publisher = {Elsevier},
title = {{A unified approach to the theory of sampling systems}},
volume = {267},
year = {1959}
}
@inproceedings{Zoeter2004,
author = {Zoeter, Onno and Ypma, Alexander and Heskes, Tom},
booktitle = {Proceedings of the IEEE workshop on Machine Learning for Signal Processing},
title = {{Improved unscented Kalman smoothing for stock volatility estimation}},
year = {2004}
}
@article{Woods2012,
author = {Woods, Damien and Naughton, Thomas J.},
issn = {1745-2473},
journal = {Nature Physics},
month = {apr},
number = {4},
pages = {257--259},
publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
shorttitle = {Nat Phys},
title = {{Optical computing: Photonic neural networks}},
volume = {8},
year = {2012}
}
@inproceedings{Krizhevsky2012,
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
booktitle = {Advances in Neural Information Processing Systems},
editor = {Pereira, F and Burges, C J and Bottou, L and Weinberger, K Q},
publisher = {Curran Associates, Inc.},
title = {{ImageNet classification with deep convolutional neural networks}},
url = {https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
volume = {25},
year = {2012}
}
@article{Dufour1985,
author = {Dufour, Jean-Marie},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Dufour - 1985 - Unbiasedness of predictions from estimated vector autoregressions.pdf:pdf},
journal = {Econometric Theory},
number = {3},
pages = {387--402},
title = {{Unbiasedness of predictions from estimated vector autoregressions}},
volume = {1},
year = {1985}
}
@misc{Chatelain2011,
author = {Chatelain, Jean-Bernard and Ralf, Kirsten},
booktitle = {Growth (Lakeland)},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Chatelain, Ralf - 2011 - Spurious Regressions and Near-Multicollinearity, with an Application to Aid, Policies and Growth.pdf:pdf},
title = {{Spurious Regressions and Near-Multicollinearity, with an Application to Aid, Policies and Growth}},
year = {2011}
}
@article{Kukharenko2011_3,
annote = {in Ukrainian},
author = {Kukharenko, Oleksandra and Dibl{\'{i}}k, Josef and Khusainov, Denys},
journal = {Bulletin of the Kyiv National Taras Shevchenko University},
pages = {59--62},
series = {Physic and Mathematics},
title = {{Representation of solution of the first boundary value problem for delay systems}},
volume = {1},
year = {2011}
}
@inproceedings{RC4pv,
author = {Grigoryeva, Lyudmila and Henriques, Julie and Ortega, Juan-Pablo},
booktitle = {Proceedings of the 19th IEEE International Conference on Computational Science and Engineering},
doi = {doi 10.1109/CSE-EUC-DCABES.2016.231},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Grigoryeva, Henriques, Ortega - 2016 - Reservoir computing information processing of stationary signals.pdf:pdf},
pages = {496--503},
title = {{Reservoir computing: information processing of stationary signals}},
year = {2016}
}
@article{kurkova:sanguineti:curse,
abstract = {Learning from data with generalization capability is studied in the framework of minimization of regularized empirical error functionals over nested families of hypothesis sets with increasing model complexity. For Tikhonov's regularization with kernel stabilizers, minimization over restricted hypothesis sets containing for a fixed integer n only linear combinations of all n-tuples of kernel functions is investigated. Upper bounds are derived on the rate of convergence of suboptimal solutions from such sets to the optimal solution achievable without restrictions on model complexity. The bounds are of the form 1/n multiplied by a term that depends on the size of the sample of empirical data, the vector of output data, the Gram matrix of the kernel with respect to the input data, and the regularization parameter.},
author = {Kurkova, V{\v{e}}ra and Sanguineti, Marcello},
doi = {10.1016/j.jco.2004.11.002},
journal = {Journal of Complexity},
number = {3},
pages = {350--367},
title = {{Learning with generalization capability by kernel methods of bounded complexity}},
volume = {21},
year = {2005}
}
@unpublished{Kuznetsov2018,
abstract = {We present data-dependent learning bounds for the general scenario of non-stationary non-mixing stochastic processes. Our learning guarantees are expressed in terms of a data-dependent measure of sequential complexity and a discrepancy measure that can be estimated from data under some mild assumptions. We also also provide novel analysis of stable time series forecasting algorithm using this new notion of discrepancy that we introduce. We use our learning bounds to devise new algorithms for non-stationary time series forecasting for which we report some preliminary experimental results.},
archivePrefix = {arXiv},
arxivId = {1803.05814},
author = {Kuznetsov, Vitaly and Mohri, Mehryar},
eprint = {1803.05814},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Kuznetsov, Mohri - 2018 - Theory and algorithms for forecasting time series.pdf:pdf},
keywords = {discrepancy,expected sequential covering numbers,forecasting,generalization bounds,non-mixing,non-stationary,sequential rademacher complexity,sta-,time series},
number = {1994},
pages = {1--41},
title = {{Theory and algorithms for forecasting time series}},
year = {2018}
}
@incollection{UnscentedTransform,
author = {Julier, S.J. and Uhlmann, J.K.},
booktitle = {Signal Processing, Sensor Fusion, and Target Recognition VI},
editor = {Kadar, I.},
pages = {182--193},
title = {{A new extension of the Kalman filter to nonlinear systems}},
year = {1997}
}
@article{frankl1988johnson,
author = {Frankl, Peter and Maehara, Hiroshi},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Frankl, Maehara - 1988 - The Johnson-Lindenstrauss lemma and the sphericity of some graphs.pdf:pdf},
journal = {Journal of Combinatorial Theory, Series B},
number = {3},
pages = {355--362},
publisher = {Elsevier},
title = {{The Johnson-Lindenstrauss lemma and the sphericity of some graphs}},
volume = {44},
year = {1988}
}
@article{Bender2020,
author = {Bender, Christian and Thiel, Matthias},
journal = {Statistics {\&} Risk Modeling},
number = {1-2},
pages = {55--78},
title = {{Arbitrage-free interpolation of call option prices}},
volume = {37},
year = {2020}
}
@incollection{brocker:tom:dieck,
author = {Br{\"{o}}cker, Th. and Dieck, T.},
booktitle = {Graduate Text in Mathematics},
publisher = {Springer Verlag},
title = {{Representations of Compact Lie Groups}},
volume = {98},
year = {1985}
}
@article{field80,
author = {Field, M. J.},
journal = {Trans. Amer. Math. Soc.},
number = {1},
pages = {185--205},
title = {{Equivariant dynamical systems}},
volume = {259},
year = {1980}
}
@article{sprecherthesis,
author = {Sprecher, David A.},
doi = {10.2307/2033845},
journal = {Proceedings of the American Mathematical Society},
month = {apr},
number = {2},
pages = {200},
title = {{A representation theorem for continuous functions of several variables}},
url = {http://www.jstor.org/stable/2033845?origin=crossref},
volume = {16},
year = {1965}
}
@article{Tzannes1967,
author = {Tzannes, N.},
doi = {10.1109/TIT.1967.1053998},
issn = {0018-9448},
journal = {IEEE Transactions on Information Theory},
month = {apr},
number = {2},
pages = {314--314},
title = {{Polynomial expansions of random functions (Corresp.)}},
url = {http://ieeexplore.ieee.org/document/1053998/},
volume = {13},
year = {1967}
}
@article{nesterov,
author = {Nesterov, Yu.},
doi = {10.1007/s10107-004-0552-5},
issn = {0025-5610},
journal = {Math. Program.},
number = {1, Ser. A},
pages = {127--152},
title = {{Smooth minimization of non-smooth functions}},
url = {http://dx.doi.org/10.1007/s10107-004-0552-5},
volume = {103},
year = {2005}
}
@article{Menegaz2018,
author = {Menegaz, Henrique M. T. and Ishihara, João Y. and Kussaba, Hugo T. M.},
journal = {IEEE Transactions on Automatic Control},
title = {{Unscented Kalman filters for Riemannian state-space systems}},
year = {2018}
}
@article{Poloni,
author = {Poloni, Federico and Sbrana, Giacomo},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Poloni, Sbrana - Unknown - Feasible generalized least squares estimation of multivariate GARCH(1,1) models.pdf:pdf},
title = {{Feasible generalized least squares estimation of multivariate GARCH(1,1) models}}
}
@article{Scott1987,
author = {Scott, Louis O.},
issn = {1756-6916},
journal = {Journal of Financial and Quantitative Analysis},
language = {English},
month = {dec},
number = {04},
pages = {419--438},
title = {{Option pricing when the variance changes randomly: theory, estimation, and an application}},
url = {http://journals.cambridge.org/abstract{\_}S002210900001276X},
volume = {22},
year = {1987}
}
@phdthesis{gallicchio:thesis,
author = {Gallicchio, Claudio},
pages = {215},
school = {Universit{\`{a}} di Pisa},
title = {{Reservoir Computing for Learning in Structured Domains}},
year = {2011}
}
@article{lukosevicius,
author = {Luko{\v{s}}evi{\v{c}}ius, M. and Jaeger, H.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Luko{\v{s}}evi{\v{c}}ius, Jaeger - 2009 - Reservoir computing approaches to recurrent neural network training(3).pdf:pdf},
journal = {Computer Science Review},
number = {3},
pages = {127--149},
title = {{Reservoir computing approaches to recurrent neural network training}},
volume = {3},
year = {2009}
}
@article{bridges:90a,
author = {Bridges, T J},
journal = {Arch. Rational Mech. Anal.},
pages = {335--376},
title = {{The Hopf bifurcation with symmetry for the Navier-Stokes equation in {\$}\backslash{\$}{\{}{\$}{\}}(L{\{}{\_}{\}}p(\Omega)){\{}{\^{}}{\}}n\backslashbackslash{\{}\backslash{\$}{\}}with application to plane Poiseuille flow}},
volume = {106},
year = {1990}
}
@book{lamberton:lapeyre,
author = {Lamberton, Damien and Lapeyre, Bernard},
edition = {Second},
isbn = {978-1-58488-626-6},
pages = {253},
publisher = {Chapman and Hall/CRC},
series = {Chapman {\&} Hall/CRC Financial Mathematics Series},
title = {{Introduction to stochastic calculus applied to finance}},
year = {2008}
}
@book{MR1278033,
address = {Princeton, NJ},
author = {Hamilton, James D},
isbn = {0-691-04289-6},
pages = {xvi+799},
publisher = {Princeton University Press},
title = {{Time series analysis}},
year = {1994}
}
@article{Estrella2003,
author = {Estrella, Arturo and Rodrigues, Anthony P. and Schich, Sebastian},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Estrella, Rodrigues, Schich - 2003 - How Stable is the Predictive Power of the Yield Curve Evidence from Germany and the United States.pdf:pdf},
issn = {0034-6535},
journal = {Review of Economics and Statistics},
month = {aug},
number = {3},
pages = {629--644},
title = {{How Stable is the Predictive Power of the Yield Curve? Evidence from Germany and the United States}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/003465303322369777},
volume = {85},
year = {2003}
}
@article{InvertGARCH2013,
author = {Wintenberger, Olivier},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Wintenberger - 2013 - Continuous invertibility and stable QML estimation of the EGARCH(1,1) model.pdf:pdf},
journal = {Scandinavian Journal of Statistics},
number = {4},
pages = {846--867},
title = {{Continuous invertibility and stable QML estimation of the EGARCH(1,1) model}},
volume = {40},
year = {2013}
}
@article{Pennec2006,
author = {Pennec, X. and Fillard, P. and Ayache, N.},
journal = {International Journal of Computer Vision},
number = {1},
pages = {41--66},
title = {{A Riemannian framework for tensor computing}},
volume = {66},
year = {2006}
}
@unpublished{Chopin2011,
author = {Chopin, N. and Jacob, P.E. and Papaspiliopoulos, O.},
title = {{SMC{\^{}}2: A sequential Monte Carlo algorithm with particle Markov chain Monte Carlo updates}},
year = {2011}
}
@article{Exterkate2011,
author = {Exterkate, Peter and Groenen, Patrick J.F. and Heij, Christiaan and van Dijk, Dick},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Exterkate et al. - 2011 - Nonlinear Forecasting with Many Predictors using Kernel Ridge Regression.pdf:pdf},
title = {{Nonlinear Forecasting with Many Predictors using Kernel Ridge Regression}},
url = {http://ideas.repec.org/p/dgr/uvatin/20110007.html},
year = {2011}
}
@article{ER95,
author = {Engle, Robert F. and Rosenberg, J.},
journal = {Journal of Derivatives},
pages = {47--59},
title = {{GARCH gamma}},
volume = {2},
year = {1995}
}
@article{Dullin1999,
author = {Dullin, Holger R. and Easton, R. W.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Dullin, Easton - 1999 - Stability of levitrons.pdf:pdf},
journal = {Physica D.},
pages = {1--17},
title = {{Stability of levitrons}},
volume = {126},
year = {1999}
}
@article{DangVanMien1984,
author = {{Dang Van Mien}, Henri and Normand-Cyrot, Doroth{\'{e}}e},
doi = {10.1016/0005-1098(84)90023-2},
journal = {Automatica},
month = {mar},
number = {2},
pages = {175--188},
publisher = {Pergamon},
title = {{Nonlinear state affine identification methods: applications to electrical power plants}},
url = {http://www.sciencedirect.com/science/article/pii/0005109884900232},
volume = {20},
year = {1984}
}
@article{Matthews1993,
author = {Matthews, Michael B.},
doi = {10.1007/BF01189878},
issn = {0278-081X},
journal = {Circuits, Systems, and Signal Processing},
month = {jun},
number = {2},
pages = {279--307},
publisher = {Birkh{\"{a}}user-Verlag},
title = {{Approximating nonlinear fading-memory operators using neural network models}},
url = {http://link.springer.com/10.1007/BF01189878},
volume = {12},
year = {1993}
}
@article{Ortega2004re,
abstract = {For a symmetric Hamiltonian system, lower bounds for the number of relative equilibria surrounding stable and formally unstable relative equilibria on nearby energy levels are given.},
author = {Ortega, Juan-Pablo and Ratiu, Tudor S.},
doi = {10.2307/4143153},
journal = {Proceedings of the Royal Society London Ser. A Math. Phys. Eng. Sci.},
pages = {1407--1431},
publisher = {Royal Society},
title = {{Relative equilibria near stable and unstable Hamiltonian relative equilibria}},
url = {https://www.jstor.org/stable/4143153},
volume = {460},
year = {2004}
}
@article{Roberts2002,
author = {Roberts, Mark and Wulff, Claudia and Lamb, Jeroen S. W.},
journal = {Journal of Differential Equations},
number = {2},
pages = {562--604},
title = {{Hamiltonian systems near relative equilibria}},
volume = {179},
year = {2002}
}
@article{EEGcruse2012,
author = {Cruse, D. and Chennu, S. and Fern{\'{a}}ndez-Espejo, D. and Payne, W. L. and Young, G. B. and Owen, A. M.},
journal = {PLOS ONE},
number = {11},
title = {{Detecting awareness in the vegetative state: electroencephalographic evidence for attempted movements to command}},
volume = {7},
year = {2012}
}
@article{Koreisha1999TA,
author = {Koreisha, Sergio G. and Fang, Yue},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Koreisha, Fang - 1999 - Updating ARMA predictions for temporal aggregates.pdf:pdf},
keywords = {aggregation,arma processes,nonstationary processes,prediction,seasonal arma processes,temporal},
title = {{Updating ARMA predictions for temporal aggregates}},
year = {1999}
}
@unpublished{DijkVar,
author = {Opschoor, Anne and van Dijk, D. and van der Wel, Michel},
title = {{Improving density forecasts and Value-at-Risk estimates by combining densities}},
year = {2014}
}
@article{Gao:Brodzki:Mukherjee,
abstract = {We develop a geometric framework that characterizes the synchronization problem --- the problem of consistently registering or aligning a collection of objects. The theory we formulate characterizes the cohomological nature of synchronization based on the classical theory of fibre bundles. We first establish the correspondence between synchronization problems in a topological group {\$}G{\$} over a connected graph {\$}\backslashGamma{\$} and the moduli space of flat principal {\$}G{\$}-bundles over {\$}\backslashGamma{\$}, and develop a discrete analogy of the renowned theorem of classifying flat principal bundles with fix base and structural group using the representation variety. In particular, we show that prescribing an edge potential on a graph is equivalent to specifying an equivalence class of flat principal bundles, of which the triviality of holonomy dictates the synchronizability of the edge potential. We then develop a twisted cohomology theory for associated vector bundles of the flat principal bundle arising from an edge potential, which is a discrete version of the twisted cohomology in differential geometry. This theory realizes the obstruction to synchronizability as a cohomology group of the twisted de Rham cochain complex. We then build a discrete twisted Hodge theory --- a fibre bundle analog of the discrete Hodge theory on graphs --- which geometrically realizes the graph connection Laplacian as a Hodge Laplacian of degree zero. Motivated by our geometric framework, we study the problem of learning group actions --- partitioning a collection of objects based on the local synchronizability of pairwise correspondence relations. A dual interpretation is to learn finitely generated subgroups of an ambient transformation group from noisy observed group elements. A synchronization-based algorithm is also provided, and we demonstrate its efficacy using simulations and real data.},
archivePrefix = {arXiv},
arxivId = {1610.09051},
author = {Gao, Tingran and Brodzki, Jacek and Mukherjee, Sayan},
eprint = {1610.09051},
month = {oct},
title = {{The geometry of synchronization problems and learning group actions}},
year = {2016}
}
@article{Pascanu2013,
abstract = {In this paper, we explore different ways to extend a recurrent neural network (RNN) to a $\backslash$textit{\{}deep{\}} RNN. We start by arguing that the concept of depth in an RNN is not as clear as it is in feedforward neural networks. By carefully analyzing and understanding the architecture of an RNN, however, we find three points of an RNN which may be made deeper; (1) input-to-hidden function, (2) hidden-to-hidden transition and (3) hidden-to-output function. Based on this observation, we propose two novel architectures of a deep RNN which are orthogonal to an earlier attempt of stacking multiple recurrent layers to build a deep RNN (Schmidhuber, 1992; El Hihi and Bengio, 1996). We provide an alternative interpretation of these deep RNNs using a novel framework based on neural operators. The proposed deep RNNs are empirically evaluated on the tasks of polyphonic music prediction and language modeling. The experimental result supports our claim that the proposed deep RNNs benefit from the depth and outperform the conventional, shallow RNNs.},
archivePrefix = {arXiv},
arxivId = {1312.6026},
author = {Pascanu, Razvan and Gulcehre, Caglar and Cho, Kyunghyun and Bengio, Yoshua},
eprint = {1312.6026},
month = {dec},
title = {{How to construct deep recurrent neural networks}},
url = {http://arxiv.org/abs/1312.6026},
year = {2013}
}
@article{Kukharenko2010,
annote = {in Ukrainian},
author = {Kukharenko, Oleksandra and Khusainov, Denis and Verejkina, M.},
journal = {Bulletin of the Kyiv National Taras Shevchenko University},
pages = {15--22},
series = {Cybernetics},
title = {{Representation of the solution for the vibrating delay system in the form of series}},
url = {http://www.nbuv.gov.ua/old{\_}jrn/Natural/VKNU/Kib/2010{\_}10/Kukharenko{\_}Khusainov{\_}Vereikina.pdf},
year = {2011}
}
@book{luetkepohl:book,
address = {Berlin},
author = {L{\"{u}}tkepohl, Helmut},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/L{\"{u}}tkepohl - 2005 - New Introduction to Multiple Time Series Analysis.pdf:pdf},
isbn = {3-540-40172-5},
pages = {xxii+764},
publisher = {Springer-Verlag},
title = {{New Introduction to Multiple Time Series Analysis}},
year = {2005}
}
@article{MaassUniversality,
author = {Maass, Wolfgang and Joshi, Prashant and Sontag, Eduardo D.},
doi = {10.1371/journal.pcbi.0020165},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Maass, Joshi, Sontag - 2007 - Computational aspects of feedback in neural circuits.pdf:pdf},
journal = {PLoS Computational Biology},
number = {1},
pages = {e165},
publisher = {Public Library of Science},
title = {{Computational aspects of feedback in neural circuits}},
url = {http://dx.plos.org/10.1371/journal.pcbi.0020165},
volume = {3},
year = {2007}
}
@article{RC18TA,
author = {Grigoryeva, Lyudmila and Hart, Allen G and Ortega, Juan-Pablo},
journal = {Preprint},
title = {{Technical appendices to the letter "Chaos on compact manifolds: Differentiable synchronizations beyond Takens'"}},
year = {2020}
}
@article{ortin2019tackling,
author = {Ort{\'{i}}n, Silvia and Pesquera, Luis},
journal = {Frontiers in Physics},
pages = {210},
publisher = {Frontiers},
title = {{Tackling the trade-off between information processing capacity and rate in delay-based reservoir computers}},
volume = {7},
year = {2019}
}
@article{Meyer2003,
author = {Meyer, Renate and Fournier, David A. and Berg, Andreas},
doi = {10.1111/1368-423X.t01-1-00116},
issn = {13684221},
journal = {Econometrics Journal},
month = {dec},
number = {2},
pages = {408--420},
title = {{Stochastic volatility: Bayesian computation using automatic differentiation and the extended Kalman filter}},
url = {http://doi.wiley.com/10.1111/1368-423X.t01-1-00116},
volume = {6},
year = {2003}
}
@incollection{brockett:1983,
author = {Brockett, R. W.},
booktitle = {Differential Geometric Control Theory},
editor = {Brockett, R. W. and Millman, S. R. and Sussmann, H.},
publisher = {Birkh{\"{a}}user Verlag},
title = {{Asymptotic stability andfeedback stabilization}},
year = {1983}
}
@article{Bordo2008,
author = {Bordo, M and Haubrich, J},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Bordo, Haubrich - 2008 - Forecasting with the yield curve level, slope, and output 1875–1997.pdf:pdf},
issn = {01651765},
journal = {Economics Letters},
keywords = {e27,e43,forecasting,gnp growth,interest rates,jel classification},
month = {apr},
number = {1},
pages = {48--50},
title = {{Forecasting with the yield curve; level, slope, and output 1875–1997}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S016517650700198X},
volume = {99},
year = {2008}
}
@article{HoffmannUnderRevision,
author = {Hoffmann, Janina Anna and {Von Helversen}, Bettina and Rieskamp, J{\"{o}}rg},
journal = {Decision},
title = {{Testing learning mechanisms of rule-based judgment}}
}
@book{Ben-David2014,
abstract = {Machine learning is one of the fastest growing areas of computer science, with far-reaching applications. The aim of this textbook is to introduce machine learning, and the algorithmic paradigms it offers, in a principled way. The book provides an extensive theoretical account of the fundamental ideas underlying machine learning and the mathematical derivations that transform these principles into practical algorithms. Following a presentation of the basics of the field, the book covers a wide array of central topics that have not been addressed by previous textbooks. These include a discussion of the computational complexity of learning and the concepts of convexity and stability; important algorithmic paradigms including stochastic gradient descent, neural networks, and structured output learning; and emerging theoretical concepts such as the PAC-Bayes approach and compression-based bounds. Designed for an advanced undergraduate or beginning graduate course, the text makes the fundamentals and algorithms of machine learning accessible to students and non-expert readers in statistics, computer science, mathematics, and engineering.},
author = {Ben-David, Shai and Shalev-Shwartz, Shai},
booktitle = {Understanding Machine Learning: From Theory to Algorithms},
pmid = {7991770},
title = {{Understanding Machine Learning: From Theory to Algorithms}},
year = {2014}
}
@article{Gourieroux2007,
author = {Gourieroux, C. and Monfort, A.},
doi = {10.1016/j.jeconom.2005.11.015},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Gourieroux, Monfort - 2007 - Econometric specification of stochastic discount factor models.pdf:pdf},
issn = {03044076},
journal = {Journal of Econometrics},
month = {feb},
number = {2},
pages = {509--530},
title = {{Econometric specification of stochastic discount factor models}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S030440760500223X},
volume = {136},
year = {2007}
}
@article{Mukherjea1970,
author = {Mukherjea, A.},
doi = {10.1017/S0004972700041848},
issn = {0004-9727},
journal = {Bulletin of the Australian Mathematical Society},
month = {apr},
number = {02},
pages = {233},
publisher = {Cambridge University Press},
title = {{A Stone-Weierstrass theorem for random functions}},
url = {http://www.journals.cambridge.org/abstract{\_}S0004972700041848},
volume = {2},
year = {1970}
}
@book{willard:topology,
author = {Willard, Stephen},
publisher = {Addison Wesley},
title = {{General Topology}},
year = {1970}
}
@article{Claessens2011,
abstract = {This paper analyzes the interactions between business and financial cycles using an extensive database covering 44 countries for the period 1960:1–2010:4. Our analysis shows that there are strong linkages between the different phases of business and financial cycles. In particular, recessions associated with financial disruptions, notably house and equity price busts, tend to be longer and deeper than other recessions. Conversely, while recoveries following asset price busts tend to be weaker, recoveries associated with rapid growth in credit and house prices are often stronger. These findings emphasize the importance of financial market developments for the real economy.},
author = {Claessens, Stijn and Kose, M. Ayhan and Terrones, Marco E.},
issn = {00221996},
journal = {Journal of International Economics},
keywords = {e32,e44,e51,f42},
month = {may},
number = {1},
pages = {178--190},
title = {{How do business and financial cycles interact?}},
url = {http://dx.doi.org/10.1016/j.jinteco.2011.11.008},
volume = {87},
year = {2012}
}
@article{Bourmaud2014,
author = {Bourmaud, Guillaume and M{\'{e}}gret, R{\'{e}}mi and Arnaudon, Marc and Giremus, Audrey},
journal = {J Math Imaging Vis},
title = {{Continuous-discrete extended Kalman filter on matrix Lie groups using concentrated Gaussian distributions}},
year = {2014}
}
@book{Box1976,
author = {Box, George E. P. and Jenkins, Gwilym M.},
language = {eng},
publisher = {Holden-Day},
title = {{Time Series Analysis: Forecasting and Control}},
url = {http://dialnet.unirioja.es/servlet/libro?codigo=375102},
year = {1976}
}
@article{Sbrana2013,
abstract = {We provide a closed-form estimator based on the VARMA representation for the unrestricted multivariate GARCH(1,1) model. We show that the GARCH parameters can be derived analytically, using the autocovariances of the observed data, applying simple linear algebra tools. The resulting estimator is consistent and asymptotically normally distributed. Our results provide also closed-form expressions for the parameters of the temporally aggregated multivariate GARCH(1,1) discussed in Hafner (2008) [15].},
author = {Sbrana, Giacomo and Poloni, Federico},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Sbrana, Poloni - 2013 - A closed-form estimator for the multivariate GARCH(1,1) model.pdf:pdf},
journal = {Journal of Multivariate Analysis},
keywords = {1),15A24,91B84,Estimation,Multivariate GARCH(1,Temporal aggregation,VARMA},
pages = {152--162},
title = {{A closed-form estimator for the multivariate GARCH(1,1) model}},
url = {http://www.sciencedirect.com/science/article/pii/S0047259X13000912},
volume = {120},
year = {2013}
}
@book{Rudin:Functional:Analysis,
abstract = {This classic text is written for graduate courses in functional analysis. This text is used in modern investigations in analysis and applied mathematics. This new edition includes up-to-date presentations of topics as well as more examples and exercises. New topics include Kakutani's fixed point theorem, Lamonosov's invariant subspace theorem, and an ergodic theorem.This text is part of the Walter Rudin Student Series in Advanced Mathematics.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Rudin, Walter},
doi = {10.1017/CBO9781107415324.004},
edition = {Second},
eprint = {arXiv:1011.1669v3},
isbn = {0070542368},
issn = {0002-9947},
pages = {xv+424},
pmid = {25246403},
publisher = {McGraw-Hill},
title = {{Functional Analysis}},
year = {1991}
}
@article{farago_lugosi,
abstract = {In statistical pattern recognition, a classifier is called universally consistent if its error probability converges to the Bayes-risk as the size of the training data grows for all possible distributions of the random variable pair of the observation vector and its class. It is proven that if a one-layered neural network with properly chosen number of nodes is trained to minimize the empirical risk on the training data, then a universally consistent classifier results. It is shown that the exponent in the rate of convergence does not depend on the dimension if certain smoothness conditions on the distribution are satisfied. That is, this class of universally consistent classifiers does not suffer from the curse of dimensionality. A training algorithm is presented that finds the optimal set of parameters in polynomial time if the number of nodes and the space dimension is fixed and the amount of training data grows},
author = {Farag{\'{o}}, Andr{\'{a}}s and Lugosi, G{\'{a}}bor},
doi = {10.1109/18.243433},
isbn = {0780308786},
issn = {15579654},
journal = {IEEE Transactions on Information Theory},
keywords = {Pattern recognition,consistency,neural networks,nonparametric classification,training algorithms},
number = {4},
pages = {1146--1151},
title = {{Strong universal consistency of neural network classifiers}},
volume = {39},
year = {1993}
}
@article{Gallicchio2011,
abstract = {Echo State Networks (ESNs) constitute an emerging approach for efficiently modeling Recurrent Neural Networks (RNNs). In this paper we investigate some of the main aspects that can be accounted for the success and limitations of this class of models. In particular, we propose complementary classes of factors related to contractivity and architecture of reservoirs and we study their relative relevance. First, we show the existence of a class of tasks for which ESN performance is independent of the architectural design. The effect of the Markovian factor, characterizing a significant class within these cases, is shown by introducing instances of easy/hard tasks for ESNs featured by contractivity of reservoir dynamics. In the complementary cases, for which architectural design is effective, we investigate and decompose the aspects of network design that allow a larger reservoir to progressively improve the predictive performance. In particular, we introduce four key architectural factors: input variability, multiple time-scales dynamics, non-linear interactions among units and regression in an augmented feature space. To investigate the quantitative effects of the different architectural factors within this class of tasks successfully approached by ESNs, variants of the basic ESN model are proposed and tested on instances of datasets of different nature and difficulty. Experimental evidences confirm the role of the Markovian factor and show that all the identified key architectural factors have a major role in determining ESN performances. ?? 2011 Elsevier Ltd.},
author = {Gallicchio, Claudio and Micheli, Alessio},
doi = {10.1016/j.neunet.2011.02.002},
isbn = {1879-2782 (Electronic)$\backslash$r0893-6080 (Linking)},
issn = {08936080},
journal = {Neural Networks},
keywords = {Architectural design analysis,Echo state networks,Markovianity,Recurrent neural networks,Sequence processing},
number = {5},
pages = {440--456},
pmid = {21376531},
title = {{Architectural and Markovian factors of echo state networks}},
volume = {24},
year = {2011}
}
@article{Jin2020,
abstract = {We propose new symplectic networks (SympNets) for identifying Hamiltonian systems from data based on a composition of linear, activation and gradient modules. In particular, we define two classes of SympNets: the LA-SympNets composed of linear and activation modules, and the G-SympNets composed of gradient modules. Correspondingly, we prove two new universal approximation theorems that demonstrate that SympNets can approximate arbitrary symplectic maps based on appropriate activation functions. We then perform several experiments including the pendulum, double pendulum and three-body problems to investigate the expressivity and the generalization ability of SympNets. The simulation results show that even very small size SympNets can generalize well, and are able to handle both separable and non-separable Hamiltonian systems with data points resulting from short or long time steps. In all the test cases, SympNets outperform the baseline models, and are much faster in training and prediction. We also develop an extended version of SympNets to learn the dynamics from irregularly sampled data. This extended version of SympNets can be thought of as a universal model representing the solution to an arbitrary Hamiltonian system.},
author = {Jin, Pengzhan and Zhang, Zhen and Zhu, Aiqing and Tang, Yifa and Karniadakis, George Em},
doi = {https://doi.org/10.1016/j.neunet.2020.08.017},
issn = {0893-6080},
journal = {Neural Networks},
keywords = {Deep learning,Dynamical systems,Hamiltonian systems,Physics-informed,Symplectic integrators,Symplectic maps},
pages = {166--179},
title = {{SympNets: Intrinsic structure-preserving symplectic networks for identifying Hamiltonian systems}},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020303063},
volume = {132},
year = {2020}
}
@article{bottkol:77,
author = {Bottkol, M.},
journal = {Bull. Amer. Math. Soc.},
number = {3},
pages = {1060--1062},
title = {{Bifurcation of periodic orbits on manifolds, and Hamiltonian systems}},
volume = {83},
year = {1977}
}
@incollection{field91,
author = {Field, M. J.},
booktitle = {Singularity Theory and its Applications. Lecture Notes in Mathematics, vol. 1463},
editor = {Roberts, M. and Stewart, I.},
publisher = {Springer-Verlag},
title = {{Local structure of equivariant dynamics}},
year = {1991}
}
@book{chernoff:marsden:1970,
author = {Chernoff, P. R. and Marsden, J. E.},
booktitle = {Lecture Notes in Mathematics},
publisher = {Springer Verlag},
title = {{Properties of Infinite Dimensional Hamiltonian Systems}},
volume = {425},
year = {1970}
}
@article{Geman1992,
abstract = {Feedforward neural networks trained by error backpropagation are examples of nonparametric regression estimators. We present a tutorial on nonparametric inference and its relation to neural networks, and we use the statistical viewpoint to highlight strengths and weaknesses of neural models. We illustrate the main points with some recognition experiments involving artificial data as well as handwritten numerals. In way of conclusion, we suggest that current-generation feedforward neural networks are largely inadequate for difficult problems in machine perception and machine learning, regardless of parallel-versus-serial hardware or other implementation issues. Furthermore, we suggest that the fundamental challenges in neural modeling are about representation rather than learning per se. This last point is supported by additional experiments with handwritten numerals.},
author = {Geman, Stuart and Bienenstock, Elie and Doursat, Ren{\'{e}}},
issn = {0899-7667},
journal = {Neural Computation},
language = {en},
month = {jan},
number = {1},
pages = {1--58},
publisher = {MIT Press 238 Main St., Suite 500, Cambridge, MA 02142-1046 USA journals-info@mit.edu},
title = {{Neural Networks and the Bias/Variance Dilemma}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/neco.1992.4.1.1{\#}.VxeQ4Ol16ao},
volume = {4},
year = {1992}
}
@article{Schneider2015,
author = {Schneider, Bendix and Dambre, Joni and Bienstman, Peter},
doi = {10.1109/TNNLS.2015.2498763},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Schneider, Dambre, Bienstman - 2015 - Using digital masks to enhance the bandwidth tolerance and Improve the performance of on-chip r(2).pdf:pdf},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
pages = {1--6},
title = {{Using digital masks to enhance the bandwidth tolerance and Improve the performance of on-chip reservoir computing systems}},
url = {http://ieeexplore.ieee.org/document/7335614/},
year = {2015}
}
@unpublished{Niu2015,
author = {Niu, Qiankun},
title = {{No arbitrage conditions and characters of implied volatility surface}},
year = {2015}
}
@article{chorro:guegan:ielpo,
author = {Chorro, C and Guegan, D and Ielpo, F},
journal = {Quantitative Finance},
number = {7},
pages = {1079--1094},
title = {{Option pricing for GARCH-type models with generalized hyperbolic innovations}},
volume = {12},
year = {2012}
}
@article{peresetsky:yakubov,
author = {Peresetsky, Anatoly and Yakubov, Ruslan},
journal = {To appear in International Journal of Computational Economics and Econometrics},
title = {{Autocorrelation in an unobservable global trend: does it help to forecast market returns?}},
year = {2015}
}
@article{Bellego2012,
abstract = {In this paper, we analyze macro-financial linkages in the euro area by implementing an innovative factor-augmented probit model estimated using a large database. In particular, our model specification enables the identification of the leading influence of financial variables on euro area business cycles, in addition to the coincident information conveyed by standard macroeconomic variables. We also point out that dynamic factor models lead to more accurate replication of business cycles than static ones.},
author = {Bell{\'{e}}go, Christophe and Ferrara, Laurent},
issn = {02649993},
journal = {Economic Modelling},
keywords = {c25,c38,e32},
month = {sep},
number = {5},
pages = {1793--1797},
title = {{Macro-financial linkages and business cycles: A factor-augmented probit approach}},
url = {http://dx.doi.org/10.1016/j.econmod.2012.05.033},
volume = {29},
year = {2012}
}
@article{fast1,
author = {Benettin, G. and Fass{\`{o}}, F.},
journal = {Nonlinearity},
pages = {137--186},
title = {{Fast rotations of the rigid body: a study by Hamiltonian perturbation theory. Part I}},
volume = {9},
year = {1996}
}
@book{deeplearning:book,
author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
publisher = {MIT Press},
title = {{Deep Learning}},
url = {http://www.deeplearningbook.org},
year = {2016}
}
@inproceedings{Stubberud,
author = {Stubberud, A.R. and Perryman, P.C.},
booktitle = {Proceedings of 13th International Conference on Digital Signal Processing},
doi = {10.1109/ICDSP.1997.628451},
isbn = {0-7803-4137-6},
pages = {711--714},
publisher = {IEEE},
title = {{State of system approximation for stochastic systems}},
url = {http://ieeexplore.ieee.org/document/628451/},
volume = {2},
year = {1997}
}
@article{Barhoumi2012,
author = {Barhoumi, Karim and Darn{\'{e}}, Olivier and Ferrara, Laurent and Pluyaud, Bertrand},
issn = {03073378},
journal = {Bulletin of Economic Research},
month = {apr},
pages = {no--no},
title = {{Monthly GDP orecasting using bridge models: Application for the French economy}},
url = {http://doi.wiley.com/10.1111/j.1467-8586.2010.00359.x http://onlinelibrary.wiley.com/doi/10.1111/j.1467-8586.2010.00359.x/full},
volume = {forthcomin},
year = {2012}
}
@article{tikhonov:regression,
author = {Tikhonov, A. N.},
journal = {Dokl. Akad. Nauk SSSR},
number = {5},
pages = {195--198},
title = {{On the stability of inverse problems}},
volume = {39},
year = {1943}
}
@article{visick:2000,
abstract = {The Hadamard and Kronecker products of two n×m matrices A,B are related by AB=PT1(A⊗B)P2, where P1,P2 are partial permutation matrices. After establishing several properties of the P matrices, this relationship is employed to demonstrate how a simplified theory of the Hadamard product can be developed. During this process the well-known result (AB)(AB)*≤AA*BB* is extended to(AB)(AB)*≤12(AA*BB*+AB*BA*)≤AA*BB*showing an inherent link between the Hadamard product and conventional product of two matrices. This leads to a sharper bound on the spectral norm of AB,∥AB∥≤12(∥A∥2∥B∥ 2+∥AB*∥2) 1/2≤∥A∥∥B∥and an improvement on the weak majorization of AB,$\sigma$2(AB)≺w12$\sigma$ 2(A){\textperiodcentered}$\sigma$2(B)+$\sigma$2(AB)≺ w$\sigma$2(A)$\sigma$2(B). For a real non-singular matrix X and invertible diagonal matrices D,E the spectral condition number $\kappa$({\textperiodcentered}) is shown to be, if scaled, bounded below as follows:$\kappa$(DXE)≥(2∥XX-T∥2-∥XX -T∥2)1/2≥∥XXT-1∥. For A≥0, we have(IA)2≤12(IA2+AA)≤IA2and (A1/2A-1/2)2≤12(I+AA -1)≤AA-1 when A{\textgreater}0. The latter inequality is compared to Styan's inequality (AA)-1≤12(I+AA-1) when A is a correlation matrix and is shown to possess stronger properties of ordering. Finally, the relationship AB=PT1(A⊗B)P2 is applied to determine conditions of singularity of certain orderings of the Hadamard products of matrices. {\textcopyright} 2000 Elsevier Science Inc.},
author = {Visick, George},
doi = {10.1016/S0024-3795(99)00187-1},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Visick - 2000 - A quantitative version of the observation that the Hadamard product is a principal submatrix of the Kronecker product.pdf:pdf},
issn = {00243795},
journal = {Linear Algebra and Its Applications},
number = {1-3},
pages = {45--68},
title = {{A quantitative version of the observation that the Hadamard product is a principal submatrix of the Kronecker product}},
volume = {304},
year = {2000}
}
@book{Milnor1965,
author = {Milnor, John and Weaver, David W},
publisher = {Princeton university press},
title = {{Topology from the differentiable viewpoint}},
volume = {21},
year = {1997}
}
@article{ortega:bregman,
author = {Chr{\'{e}}tien, St{\'{e}}phane and Ortega, Juan-Pablo},
journal = {Computational Statistics and Data Analysis},
pages = {210--236},
title = {{Multivariate GARCH estimation via a Bregman-proximal trust-region method}},
volume = {76},
year = {2014}
}
@article{coste:dazord:weinstein:1987,
address = {2,1--62. Univ. Claude--Bernard, Lyon},
author = {Cost{\'{e}}, A and Dazord, P and Weinstein, A},
journal = {Publ. D{\{}{\'{e}}{\}}p. Math. Nouvelle S{\{}{\'{e}}{\}}r. A},
pages = {1--62},
title = {{Groupo{\{}{\"{i}}{\}}des symplectiques}},
volume = {2},
year = {1987}
}
@article{convexity:petre2,
author = {Birtea, Petre and Ortega, Juan-Pablo and Ratiu, Tudor S.},
doi = {10.1090/S0002-9947-08-04689-8},
journal = {Transactions of the American Mathematical Society},
month = {sep},
number = {02},
pages = {603--630},
title = {{Openness and convexity for momentum maps}},
url = {http://www.ams.org/journal-getitem?pii=S0002-9947-08-04689-8},
volume = {361},
year = {2008}
}
@inproceedings{hermans2013training,
author = {Hermans, Michiel and Schrauwen, Benjamin},
booktitle = {Advances in Neural Information Processing Systems},
pages = {190--198},
title = {{Training and analysing deep recurrent neural networks}},
year = {2013}
}
@incollection{fischer:80,
author = {Fischer, A. and Marsden, J. E. and Moncrief, V.},
booktitle = {Essays in General Relativity. Essay n.7},
publisher = {Academic Press},
title = {{Symmetry breaking in general relativity}},
year = {1980}
}
@article{Pinto2015,
author = {Pinto, Rafael C. and Engel, Paulo Martins},
journal = {PLOS ONE},
title = {{A fast Incremental Gaussian Mixture Model}},
volume = {10},
year = {2015}
}
@phdthesis{thesis,
annote = {From Duplicate 2 ( 

Symmetry, Reduction, and Stability in Hamiltonian Systems

- Ortega, J.-P. )

},
author = {Ortega, Juan-Pablo},
school = {University of California, Santa Cruz},
title = {{Symmetry, Reduction, and Stability in Hamiltonian Systems}},
year = {1998}
}
@unpublished{manev2,
annote = {$\backslash$textit{\{}Preprint{\}},

      },
author = {Diacu, F. and Mioc, V. and Stoica, C.},
title = {{Phase-space structure and regularization of Manev-type problems}}
}
@unpublished{Klusowski2016,
abstract = {Let {\$} f{\^{}}{\{}\backslashstar{\}} {\$} be a function on {\$} \backslashmathbb{\{}R{\}}{\^{}}d {\$} satisfying a spectral norm condition. For various noise settings, we show that {\$} \backslashmathbb{\{}E{\}}\backslash|\backslashhat{\{}f{\}} - f{\^{}}{\{}\backslashstar{\}} \backslash|{\^{}}2 \backslashleq v{\_}{\{}f{\^{}}{\{}\backslashstar{\}}{\}}\backslashleft(\backslashfrac{\{}\backslashlog d{\}}{\{}n{\}}\backslashright){\^{}}{\{}1/4{\}} {\$}, where {\$} n {\$} is the sample size and {\$} \backslashhat{\{}f{\}} {\$} is either a penalized least squares estimator or a greedily obtained version of such using linear combinations of ramp, sinusoidal, sigmoidal or other bounded Lipschitz ridge functions. Our risk bound is effective even when the dimension {\$} d {\$} is much larger than the available sample size. For settings where the dimension is larger than the square root of the sample size this quantity is seen to improve the more familiar risk bound of {\$} v{\_}{\{}f{\^{}}{\{}\backslashstar{\}}{\}}\backslashleft(\backslashfrac{\{}d\backslashlog (n/d){\}}{\{}n{\}}\backslashright){\^{}}{\{}1/2{\}} {\$}, also investigated here.},
archivePrefix = {arXiv},
arxivId = {1607.01434},
author = {Klusowski, Jason M. and Barron, Andrew R.},
eprint = {1607.01434},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Klusowski, Barron - 2016 - Risk bounds for high-dimensional ridge function combinations including neural networks.pdf:pdf},
pages = {1--32},
title = {{Risk bounds for high-dimensional ridge function combinations including neural networks}},
url = {http://arxiv.org/abs/1607.01434},
year = {2016}
}
@book{Brockwell2002,
abstract = {This book is aimed at the reader who wishes to gain a working knowledge of time series and forecasting methods as applied in economics, engineering, and the natural and social sciences. The book assumes knowledge only of basic calculus, matrix algebra and elementary statistics. This second edition contains detailed instructions on the use of the new totally windows-based computer package ITSM2000, the student version of which is included with the text. Expanded treatments are also given of several topics treated only briefly in the first edition. These include regression with time series errors, which plays an important role in forecasting and inference, and ARCH and GARCH models, which are widely used for the modeling of financial time series. These models can be fitted using the new version of ITSM.The core of the book covers stationary processes, ARMA and ARIMA processes, multivariate time series and state-space models, with an optional chapter on spectral analysis. Additional topics include the Burg and Hannan-Rissanen algorithms, unit roots, the EM algorithm, structural models, generalized state-space models with applications to time series of count data, exponential smoothing, the Holt-Winters and ARAR forecasting algorithms, transfer function models and intervention analysis. Brief introductions are also given to cointegration and to non-linear, continuous-time and long-memory models.},
author = {Brockwell, Peter J. and Davis, Richard A.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Brockwell, Davis - 2002 - Introduction to Time Series and Forecasting.pdf:pdf},
isbn = {0387953515},
pages = {434},
publisher = {Springer},
title = {{Introduction to Time Series and Forecasting}},
url = {http://books.google.com/books?id=H{\_}kgF7Zl6dQC{\&}pgis=1},
year = {2002}
}
@book{Cooksey1996,
address = {San Diego, CA},
author = {Cooksey, Ray W},
publisher = {Academic Press},
title = {{Judgment analysis: Theory, methods and applications}},
year = {1996}
}
@article{CLoverview_VarinReid2011,
author = {Varin, Cristiano and Reid, Nancy and Firth, David},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Varin, Reid, Firth - 2011 - An overview of composite likelihood methods.pdf:pdf},
journal = {Statistica Sinica},
pages = {5--42},
title = {{An overview of composite likelihood methods}},
volume = {21},
year = {2011}
}
@article{Bostanov2006,
abstract = {OBJECTIVE: This study was aimed at developing a method for extraction and assessment of event-related brain potentials (ERP) from single-trials. This method should be applicable in the assessment of single persons' ERPs and should be able to handle both single ERP components and whole waveforms.

METHODS: We adopted a recently developed ERP feature extraction method, the t-CWT, for the purposes of hypothesis testing in the statistical assessment of ERPs. The t-CWT is based on the continuous wavelet transform (CWT) and Student's t-statistics. The method was tested in two ERP paradigms, oddball and semantic priming, by assessing individual-participant data on a single-trial basis, and testing the significance of selected ERP components, P300 and N400, as well as of whole ERP waveforms. The t-CWT was also compared to other univariate and multivariate ERP assessment methods: peak picking, area computation, discrete wavelet transform (DWT) and principal component analysis (PCA).

RESULTS: The t-CWT produced better results than all of the other assessment methods it was compared with.

CONCLUSIONS: The t-CWT can be used as a reliable and powerful method for ERP-component detection and testing of statistical hypotheses concerning both single ERP components and whole waveforms extracted from either single persons' or group data.

SIGNIFICANCE: The t-CWT is the first such method based explicitly on the criteria of maximal statistical difference between two average ERPs in the time-frequency domain and is particularly suitable for ERP assessment of individual data (e.g. in clinical settings), but also for the investigation of small and/or novel ERP effects from group data.},
author = {Bostanov, Vladimir and Kotchoubey, Boris},
issn = {1388-2457},
journal = {Clinical neurophysiology : official journal of the International Federation of Clinical Neurophysiology},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Adult,Algorithms,Brain,Brain: physiology,Electroencephalography,Electroencephalography: statistics {\&} numerical dat,Event-Related Potentials, P300,Event-Related Potentials, P300: physiology,Female,Humans,Male,Signal Processing, Computer-Assisted,Time Factors},
language = {English},
month = {dec},
number = {12},
pages = {2627--44},
publisher = {Elsevier},
title = {{The t-CWT: a new ERP detection and quantification method based on the continuous wavelet transform and Student's t-statistics.}},
url = {http://www.clinph-journal.com/article/S1388245706014271/fulltext},
volume = {117},
year = {2006}
}
@article{kalman1959general,
author = {Kalman, Rudolf Emil and Bertram, J E},
journal = {Transactions of the American Institute of Electrical Engineers, Part II: Applications and Industry},
number = {6},
pages = {602--609},
publisher = {IEEE},
title = {{General synthesis procedure for computer control of single-loop and multiloop linear systems (An optimal sampling system)}},
volume = {77},
year = {1959}
}
@article{Kobayashi2008,
abstract = {We consider Bayesian shrinkage predictions for the Normal regression problem under the frequentist Kullback–Leibler risk function. Firstly, we consider the multivariate Normal model with an unknown mean and a known covariance. While the unknown mean is fixed, the covariance of future samples can be different from that of training samples. We show that the Bayesian predictive distribution based on the uniform prior is dominated by that based on a class of priors if the prior distributions for the covariance and future covariance matrices are rotation invariant. Then, we consider a class of priors for the mean parameters depending on the future covariance matrix. With such a prior, we can construct a Bayesian predictive distribution dominating that based on the uniform prior. Lastly, applying this result to the prediction of response variables in the Normal linear regression model, we show that there exists a Bayesian predictive distribution dominating that based on the uniform prior. Minimaxity of these Bayesian predictions follows from these results.},
author = {Kobayashi, Kei and Komaki, Fumiyasu},
issn = {0047259X},
journal = {Journal of Multivariate Analysis},
keywords = {primary, 62f07, 62f15,secondary, 62c10, 62j07},
month = {oct},
number = {9},
pages = {1888--1905},
title = {{Bayesian shrinkage prediction for the regression problem}},
url = {http://dx.doi.org/10.1016/j.jmva.2008.01.014},
volume = {99},
year = {2008}
}
@article{castillo:ortega,
author = {Badescu, Alexandru and del Castillo, Joan and Ortega, Juan-Pablo},
journal = {Annals of Economics and Statistics},
pages = {271--306},
title = {{Hedging of time discrete auto-regressive stochastic volatility options}},
volume = {123/124},
year = {2016}
}
@article{Scardapane2016,
abstract = {The current big data deluge requires innovative solutions for performing efficient inference on large, heterogeneous amounts of information. Apart from the known challenges deriving from high volume and velocity, real-world big data applications may impose additional technological constraints, including the need for a fully decentralized training architecture. While several alternatives exist for training feed-forward neural networks in such a distributed setting, less attention has been devoted to the case of decentralized training of recurrent neural networks (RNNs). In this paper, we propose such an algorithm for a class of RNNs known as Echo State Networks. The algorithm is based on the well-known Alternating Direction Method of Multipliers optimization procedure. It is formulated only in terms of local exchanges between neighboring agents, without reliance on a coordinating node. Additionally, it does not require the communication of training patterns, which is a crucial component in realistic big data implementations. Experimental results on large scale artificial datasets show that it compares favorably with a fully centralized implementation, in terms of speed, efficiency and generalization accuracy.},
author = {Scardapane, Simone and Wang, Dianhui and Panella, Massimo},
doi = {10.1016/j.neunet.2015.07.006},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Scardapane, Wang, Panella - 2016 - A decentralized training algorithm for Echo State Networks in distributed big data applications.pdf:pdf},
issn = {18792782},
journal = {Neural Networks},
keywords = {Alternating Direction Method of Multipliers,Big data,Distributed learning,Echo State Network,Recurrent neural network},
number = {January},
pages = {65--74},
pmid = {26341005},
title = {{A decentralized training algorithm for Echo State Networks in distributed big data applications}},
volume = {78},
year = {2016}
}
@article{Crutchfield2010,
abstract = {How dynamical systems store and process information is a fundamental question that touches a remarkably wide set of contemporary issues: from the breakdown of Moore's scaling laws--that predicted the inexorable improvement in digital circuitry--to basic philosophical problems of pattern in the natural world. It is a question that also returns one to the earliest days of the foundations of dynamical systems theory, probability theory, mathematical logic, communication theory, and theoretical computer science. We introduce the broad and rather eclectic set of articles in this Focus Issue that highlights a range of current challenges in computing and dynamical systems.},
author = {Crutchfield, James P and Ditto, William L and Sinha, Sudeshna},
issn = {1089-7682},
journal = {Chaos (Woodbury, N.Y.)},
month = {sep},
number = {3},
pages = {037101},
publisher = {AIP Publishing},
title = {{Introduction to focus issue: intrinsic and designed computation: information processing in dynamical systems-beyond the digital hegemony}},
volume = {20},
year = {2010}
}
@article{Raissi2018,
author = {Raissi, Maziar and Karniadakis, George E},
journal = {CoRR},
title = {{Hidden physics models: machine learning of nonlinear partial differential equations}},
url = {http://arxiv.org/abs/1708.00588},
volume = {abs/1708.0},
year = {2017}
}
@techreport{Ghysels2004,
author = {Ghysels, Eric and Santa-Clara, Pedro and Valkanov, Rossen},
institution = {mimeo},
number = {919},
publisher = {mimeo},
title = {{The MIDAS touch : Mixed data sampling regression models}},
year = {2004}
}
@article{agj,
author = {Arms, J. M. and Gotay, M. and Jennings, G.},
journal = {Adv. in Math.},
pages = {43--103},
title = {{Geometric and algebraic reduction for singular momentum maps}},
volume = {79},
year = {1990}
}
@incollection{Lew2004,
address = {Barcelona},
author = {Lew, Adrian and Marsden, Jerrold E. and Ortiz, Michael and West, Matthew},
booktitle = {Finite Element Methods: 1970s and Beyond. Theory and engineering applications of computational methods.},
pages = {1--18},
publisher = {International Center for Numerical Methods in Engineering (CIMNE)},
title = {{An Overview of Variational Integrators.}},
year = {2004}
}
@article{Clements2008,
author = {Clements, Michael P and Galv{\~{a}}o, Ana Beatriz},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Clements, Galv{\~{a}}o - 2008 - Macroeconomic forecasting with mixed-frequency data.pdf:pdf},
issn = {0735-0015},
journal = {Journal of Business and Economic Statistics},
keywords = {forecasting,mixed-frequency data,output growth,s,u},
month = {oct},
number = {4},
pages = {546--554},
title = {{Macroeconomic forecasting with mixed-frequency data}},
url = {http://pubs.amstat.org/doi/abs/10.1198/073500108000000015},
volume = {26},
year = {2008}
}
@article{ortin2020delay,
author = {Ort{\'{i}}n, Silvia and Pesquera, Luis},
journal = {Optics Letters},
number = {4},
pages = {905--908},
publisher = {Optical Society of America},
title = {{Delay-based reservoir computing: tackling performance degradation due to system response time}},
volume = {45},
year = {2020}
}
@article{nijmeijer1982controlled,
author = {Nijmeijer, Henk and der Schaft, Arjan},
journal = {IEEE Transactions on Automatic Control},
number = {4},
pages = {904--914},
publisher = {IEEE},
title = {{Controlled invariance for nonlinear systems}},
volume = {27},
year = {1982}
}
@article{kupka1963contributiona,
author = {Kupka, Ivan},
journal = {Contributions to differential equations},
pages = {457--484},
title = {{Contributiona la th{\'{e}}orie des champs g{\'{e}}n{\'{e}}riques}},
volume = {2},
year = {1963}
}
@article{Gabor1996,
abstract = {An algorithm for automated seizure detection using the self-organizing map (SOM) neural network (NN), with unsupervised training, was used to detect seizures in 24 long-term EEG recordings. The detection paradigm was tested on a constant 8 channel subset of 18 channel scalp EEG recordings. The NN was trained to recognize seizures using 98 training examples. A strategy was devised using wavelet transform to construct a filter that was 'matched' to the frequency features of examples used to train the NN. Four second epochs of training examples and EEGs being tested were transformed into time-independent representations of spectrograms resulting in a time-frequency representation of the time-series. Rule-based long and short term contextual features were used for detection in association with the NN. Fifty-six seizures were detected from a possible 62 (90{\%}) associated with an average 0.71 +/- 0.79 false-positive errors per hour using the same 'population' detection parameters. When the sensitivity for detection was increased, all but one of the 62 seizures were detected (98{\%}). Less than 1.0 false-positive error per hour occurred in all but 5 records when using the 'population' parameters. The combination of rule-based detection criteria employing contextual parameters and unsupervised training of NNs to recognize time-frequency patterns is a promising direction for automated seizure detection.},
author = {Gabor, A. J. and Leach, R. R. and Dowla, F. U.},
issn = {0013-4694},
journal = {Electroencephalography and clinical neurophysiology},
keywords = {Neural network,Seizure detection,Self-organizing map,Wavelet transform},
month = {sep},
number = {3},
pages = {257--266},
pmid = {8862115},
title = {{Automated seizure detection using a self-organizing neural network}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22824647},
volume = {99},
year = {1996}
}
@article{Chabi-Yo2012,
abstract = {I derive pricing kernels in which the market volatility is endogenously determined. Using the Taylor expansion series of the representative investor's marginal utility, I show that the price of market volatility risk is restricted by the investor's risk aversion and skewness preference. The risk aversion is estimated to be between two and five and is significant. The price of the market volatility is negative. Consistent with economic theory, I find that the pricing kernel decreases in the market index return and increases in market volatility. The projection of the estimated pricing kernel onto a polynomial function of the market return produces puzzling behaviors, which can be observed in the pricing kernel and absolute risk aversion functions. The inclusion of additional terms in the Taylor expansion series of the investor's marginal utility produces a pricing kernel function of market stochastic volatility, stochastic skewness, and stochastic kurtosis. The prices of risk of these moments are restricte...},
author = {Chabi-Yo, Fousseni},
issn = {0025-1909},
journal = {Management Science},
keywords = {pricing kernels,risk aversion,skewness preference,volatility risk},
language = {en},
month = {mar},
number = {3},
pages = {624--640},
publisher = {INFORMS},
title = {{Pricing kernels with stochastic skewness and volatility risk}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/mnsc.1110.1424},
volume = {58},
year = {2012}
}
@article{Nardi2011,
abstract = {The Lasso is a popular model selection and estimation procedure for linear models that enjoys nice theoretical properties. In this paper, we study the Lasso estimator for fitting autoregressive time series models. We adopt a double asymptotic framework where the maximal lag may increase with the sample size. We derive theoretical results establishing various types of consistency. In particular, we derive conditions under which the Lasso estimator for the autoregressive coefficients is model selection consistent, estimation consistent and prediction consistent. Simulation study results are reported.},
author = {Nardi, Y. and Rinaldo, A.},
issn = {0047259X},
journal = {Journal of Multivariate Analysis},
keywords = {62f12,62j07,62m10},
month = {mar},
number = {3},
pages = {528--549},
title = {{Autoregressive process modeling via the Lasso procedure}},
url = {http://dx.doi.org/10.1016/j.jmva.2010.10.012},
volume = {102},
year = {2011}
}
@article{Ren2010,
abstract = {Subset selection is a critical component of vector autoregressive (VAR) modeling. This paper proposes simple and hybrid subset selection procedures for VAR models via the adaptive Lasso. By a proper choice of tuning parameters, one can identify the correct subset and obtain the asymptotic normality of the nonzero parameters with probability tending to one. Simulation results show that for small samples, a particular hybrid procedure has the best performance in terms of prediction mean squared errors, estimation errors and subset selection accuracy under various settings. The proposed method is also applied to modeling the IS-LM data for illustration.},
author = {Ren, Yunwen and Zhang, Xinsheng},
issn = {01677152},
journal = {Statistics {\&} Probability Letters},
keywords = {adaptive lasso,bayesian information criterion,hq criterion,oracle property,vector autoregressive precesses},
month = {dec},
number = {23-24},
pages = {1705--1712},
title = {{Subset selection for vector autoregressive processes via adaptive Lasso}},
url = {http://dx.doi.org/10.1016/j.spl.2010.07.013},
volume = {80},
year = {2010}
}
@article{Noonan1991,
abstract = {A Theorem involving the convergence of random functions is presented. The Theorem is based upon the Arzela-Ascoli Theorem of Real Analysis. The development here may be useful in transient or asymptotic analysis of random functions and linear systems theory.},
author = {Noonan, Joseph P. and Polchlopek, Henry M.},
doi = {10.1155/S0161171291001059},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Noonan, Polchlopek - 1991 - An Arzela-Ascoli type theorem for random functions.pdf:pdf},
issn = {0161-1712},
journal = {International Journal of Mathematics and Mathematical Sciences},
number = {4},
pages = {789--796},
publisher = {Hindawi},
title = {{An Arzela-Ascoli type theorem for random functions}},
url = {http://www.hindawi.com/journals/ijmms/1991/137450/abs/},
volume = {14},
year = {1991}
}
@article{Schrauwen2008,
author = {Schrauwen, Benjamin and Wandermann, Marion and Verstraeten, David and Steil, Jochen J. and Stroobandt, Dirk},
journal = {Neurocomputing},
pages = {1159--1171},
title = {{Improving reservoirs using intrinsic plasticity}},
volume = {71},
year = {2008}
}
@techreport{Espinoza,
annote = {
        From Duplicate 1 ( 
        
          The role of financial variables in predicting economic activity
        
         - Espinoza, Raphael; Fornari, Fabio; Lombardi, Marco )

        
        

        

        

      },
author = {Espinoza, Raphael and Fornari, Fabio and Lombardi, Marco},
booktitle = {Horizons},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Espinoza, Fornari, Lombardi - 2009 - The role of financial variables in predicting economic activity.pdf:pdf;:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Espinoza, Fornari, Lombardi - 2009 - The Role of Financial Variables in Predicting Economic Activity in the Euro Area.pdf:pdf},
institution = {European Central Bank},
keywords = {Financial Variables,International Linkages,VAR},
series = {Middle East and Central Asia},
title = {{The Role of Financial Variables in Predicting Economic Activity in the Euro Area}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/for.1212/full},
year = {2009}
}
@article{dambre2012,
author = {Dambre, J. and Verstraeten, D. and Schrauwen, B. and Massar, S.},
doi = {doi:10.1038/srep00514},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Dambre et al. - 2012 - Information processing capacity of dynamical systems(2).pdf:pdf;:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Dambre et al. - 2012 - Information processing capacity of dynamical systems.pdf:pdf},
journal = {Scientific reports},
number = {514},
title = {{Information processing capacity of dynamical systems}},
volume = {2},
year = {2012}
}
@book{Grimmett2001,
abstract = {3rd ed. This textbook provides a wide-ranging and entertaining indroduction to probability and random processes and many of their practical applications. It includes many exercises and problems with solutions. 1. Events and their probabilities -- 2. Random variables and their distributions -- 3. Discrete random variables -- 4. Continuous random variables -- 5. Generating functions and their applications -- 6. Markov chains -- 7. Convergence of random variables -- 8. Random processes -- 9. Stationary processes -- 10. Renewals -- 11. Queues -- 12. Martingales -- 13. Diffusion processes.},
author = {Grimmett, Geoffrey. and Stirzaker, David.},
isbn = {0198572220},
pages = {596},
publisher = {Oxford University Press},
title = {{Probability and Random Processes}},
url = {https://books.google.fr/books?hl=fr{\&}lr={\&}id=G3ig-0M4wSIC{\&}oi=fnd{\&}pg=PA1{\&}dq=grimmet+stirzaker{\&}ots=BHea-JLRM1{\&}sig=P{\_}tMQJQaKDmZ0zOvD5ValI2qXl8{\#}v=onepage{\&}q=grimmet stirzaker{\&}f=false},
year = {2001}
}
@article{Cho,
author = {Chossat, P},
journal = {C. R. Acad. Sci. Paris S{\{}{\'{e}}{\}}r. I Math.},
pages = {539--541},
title = {{Bifurcation secondaire de solutions quasi-p{\{}{\'{e}}{\}}riodiques dans un probl{\{}{\`{e}}{\}}me de bifurcation invariant parsym{\{}{\'{e}}{\}}trie O(2)}},
volume = {302},
year = {1986}
}
@inproceedings{Feldkamp1998,
author = {Feldkamp, L. and Puskorius, G.},
booktitle = {Proceedings of the IEEE},
pages = {2259--2277},
title = {{A signal processing framework based on dynamic neural networks with application to problems in adaptation, filtering and classification}},
year = {1998}
}
@article{Kim2009,
abstract = {The problemof estimating underlying trends in time series data arises in a variety of disciplines. In this paper we propose a variation on Hodrick-Prescott (H-P) filtering, a widely used method for trend estimation. The proposed ℓ1 trend filtering method substitutes a sum of absolute values (i.e., ℓ1-norm) for the sum of squares used in H-P filtering to penalize variations in the estimated trend. The ℓ1 trend filtering method produces trend estimates that are piecewise linear, and therefore is well suited to analyzing time series with an underlying piecewise linear trend. The kinks, knots, or changes in slope of the estimated trend can be interpreted as abrupt changes or events in the underlying dynamics of the time series. Using specialized interior-point methods, ℓ1 trend filtering can be carried out with not much more effort than H-P filtering; in particular, the number of arithmetic operations required grows linearly with the number of data points. We describe the method and some of its basic properties, and give some illustrative examples. We show how the method is related to ℓ1 regularization based methods in sparse signal recovery and feature selection, and list some extensions of the basic method.},
author = {Kim, Seung-Jean and Koh, Kwangmoo and Boyd, Stephen and Gorinevsky, Dimitry},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Kim et al. - 2009 - L1 trend filtering.pdf:pdf},
journal = {SIAM Review},
keywords = {Hodrick-Prescott filtering,L1 regularization,detrending,feature selection,piecewise lin- ear fitting,sparse signal recovery,time series analysis,trend estima- tion.},
number = {2},
pages = {339--360},
title = {{L1 trend filtering}},
volume = {51},
year = {2009}
}
@unpublished{Scardapane2017a,
author = {Scardapane, Simone and Hussain, Amir and Uncini, Aurelio},
title = {{Group sparse regularization for deep neural networks}},
year = {2017}
}
@article{Lenglet2006,
author = {Lenglet, C. and Rousson, M. and Deriche, R.},
journal = {IEEE Transactions on Medical Imaging},
number = {6},
pages = {685--700},
title = {{DTI segmentation by statistical surface evolution}},
volume = {25},
year = {2006}
}
@unpublished{Hafner2004,
author = {Hafner, Christian M and Herwartz, Helmut},
booktitle = {Erasmus},
institution = {CAU},
keywords = {causality,local power,multivariate volatility},
title = {{Testing for Causality in Variance using Multivariate GARCH Models}},
year = {2004}
}
@article{Shirota2017,
author = {Shirota, S. and Omori, Yasuhiro and Lopes, H.F. and Piao, H.},
journal = {Econometrics and Statistics},
pages = {34--59},
title = {{Cholesky realized stochastic volatility model}},
volume = {3},
year = {2017}
}
@book{Ortega2004,
author = {Ortega, Juan-Pablo and Ratiu, Tudor S.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Ortega, Ratiu - 2004 - Momentum Maps and Hamiltonian Reduction.pdf:pdf},
pages = {xxxiv+497},
publisher = {Birkhauser Verlag},
title = {{Momentum Maps and Hamiltonian Reduction}},
year = {2004}
}
@book{mta,
author = {Abraham, Ralph and Marsden, Jerrold E. and Ratiu, Tudor S.},
publisher = {Applied Mathematical Sciences. Springer-Verlag},
title = {{Manifolds, Tensor Analysis, and Applications}},
volume = {75},
year = {1988}
}
@article{Lutkenhoner2003,
abstract = {There is still dissension as to whether the auditory evoked field (AEF) reflects tonotopy in the auditory cortex. That notwithstanding, particularly the pronounced AEF wave occurring about 100 ms after stimulus onset (N100m) is increasingly used for the investigation of issues such as cortical reorganization and representation of virtual pitch. Thus, it appears to be time for a critical revaluation of the supposed tonotopic organization of the N100m generator. In the present magnetoencephalography study, the response to tonebursts of 500 ms duration, monaurally presented 60 dB above threshold, was recorded with a 37-channel axial gradiometer system over the hemisphere contralateral to the side of stimulation. The stimulus frequencies were 250, 500, 1000, and 2000 Hz. About 250 stimuli of each type were presented in random order in four independent sessions at intervals uniformly distributed between 2 and 2.8 s. An analysis of 19 hemispheres in 10 normal-hearing subjects showed a high intraindividual reproducibility, but also a substantial interindividual variability. In most cases, the dipole location either exhibited no significant frequency dependence at all, the dipoles for the four frequencies were not orderly aligned, or the data disagreed with the single-dipole model. In the few cases showing an arrangement of dipoles consistent with the assumption of an orderly tonotopic cortical map, the most relevant coordinate varied from subject to subject. Regarding theses results, it seems crucial to understand wave N100m on the basis of individual subjects, whereas conclusions relying on mean dipole locations for groups of subjects are problematic.},
author = {L{\"{u}}tkenh{\"{o}}ner, B and Krumbholz, K and Seither-Preisler, A},
doi = {10.1016/S1053-8119(03)00172-1},
issn = {10538119},
journal = {NeuroImage},
month = {jul},
number = {3},
pages = {935--949},
title = {{Studies of tonotopy based on wave N100 of the auditory evoked field are problematic}},
url = {http://www.sciencedirect.com/science/article/pii/S1053811903001721},
volume = {19},
year = {2003}
}
@unpublished{Miller2011,
author = {Miller, J. Isaac},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Miller - 2011 - Cointegrating MIDAS Regressions and a MIDAS Test.pdf:pdf},
title = {{Cointegrating MIDAS Regressions and a MIDAS Test}},
year = {2011}
}
@book{stroock1979,
author = {Stroock, D. W. and Varadhan, S. R. S.},
pages = {338},
publisher = {Springer-Verlag},
title = {{Multidimensional diffusion processes}},
year = {1979}
}
@article{synchrEEG,
author = {Pfurtscheller, G. and {Lopes da Silva}, F.},
journal = {Clin Neurophysiol.},
number = {11},
pages = {1842--1857},
title = {{Event-related EEG/MEG synchronization and desynchronization: basic principles}},
volume = {Nov. 110},
year = {1999}
}
@unpublished{Estrella,
author = {Estrella, Arturo and Mishkin, Frederic},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Estrella, Mishkin - 1995 - Predicting US Recessions Financial Variables as Leading Indicators.pdf:pdf},
institution = {NBER},
title = {{Predicting US Recessions: Financial Variables as Leading Indicators}},
year = {1995}
}
@article{Crook2007,
author = {Crook, N.},
journal = {Neurocomputing},
pages = {1167--1176},
title = {{Nonlinear transient computation}},
volume = {70},
year = {2007}
}
@article{Halfarova2012,
author = {Halfarov{\'{a}}, Hana and Kukharenko, Alexandra and {\v{S}}marda, Zden{\v{e}}k},
journal = {APLIMAT – Journal of Applied Mathematics},
number = {2},
pages = {69--75},
title = {{Application of homotopy perturbation method to solving singular initial value problems}},
url = {http://www.journal.aplimat.com/files/Journal{\_}volume{\_}5/Number{\_}2.pdf},
volume = {5},
year = {2012}
}
@article{stark1999regularity,
author = {Stark, Jaroslav},
journal = {Ergodic theory and dynamical systems},
number = {1},
pages = {155--199},
publisher = {Cambridge University Press},
title = {{Regularity of invariant graphs for forced systems}},
volume = {19},
year = {1999}
}
@article{Kluppelberg2004,
author = {Kl{\"{u}}ppelberg, Claudia and Lindner, Alexander and Maller, Ross},
issn = {1475-6072},
journal = {Journal of Applied Probability},
keywords = {ARCH model,GARCH model,L{\'{e}}vy process,conditional hetero-scedasticity,perpetuities,stability,stationarity,stochastic integration},
month = {sep},
number = {3},
pages = {601--622},
title = {{A continuous-time GARCH process driven by a L{\'{e}}vy process: stationarity and second-order behaviour}},
url = {http://projecteuclid.org/euclid.jap/1091543413},
volume = {41},
year = {2004}
}
@article{Santa-Clara2010,
abstract = {Abstract We use a novel pricing model to imply time series of diffusive volatility and jump intensity from S{\&}P 500 index options. These two measures capture the ex ante risk assessed by investors. Using a simple general equilibrium model, we translate the implied measures of ex ante risk into an ex ante risk premium. The average premium that compensates the investor for the ex ante risks is 70{\%} higher than the premium for realized volatility. The equity premium implied from option prices is shown to significantly predict subsequent stock market returns.},
author = {Santa-Clara, Pedro and Yan, Shu},
issn = {0034-6535},
journal = {Review of Economics and Statistics},
language = {en},
month = {may},
number = {2},
pages = {435--451},
publisher = {The MIT Press},
title = {{Crashes, volatility, and the equity premium: lessons from S{\&}P 500 options}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/rest.2010.11549{\#}.Vks6sOki6ao},
volume = {92},
year = {2010}
}
@article{fhs,
author = {Barone-Adesi, Giovanni and Bourgoin, Frederick and Giannopoulos, Kostas},
journal = {Risk},
number = {8},
pages = {100--103},
title = {{Don't look back}},
volume = {11},
year = {1998}
}
@article{LePelley2016,
abstract = {Abstract This article presents a comprehensive survey of research concerning interactions between associative learning and attention in humans. Four main findings are described. First, attention is biased towards stimuli that predict their consequences reliably (learned predictiveness). This finding is consistent with the approach taken by Mackintosh (1975) in his attentional model of associative learning in non-human animals. Second, the strength of this attentional bias is modulated by the value of the outcome (learned value). That is, predictors of high-value outcomes receive especially high levels of attention. Third, the related but opposing idea that uncertainty may result in increased attention to stimuli (Pearce {\&} Hall, 1980), receives less support. This suggests that hybrid models of associative learning, incorporating the mechanisms of both the Mackintosh and Pearce-Hall theories, may not be required to explain data from human participants. Rather, a simpler model, in which attention to stimuli is determined by how strongly they are associated with significant outcomes, goes a long way to account for the data on human attentional learning. The last main finding, and an exciting area for future research and theorizing, is that learned predictiveness and learned value modulate both deliberate attentional focus, and more automatic attentional capture. The automatic influence of learning on attention does not appear to fit the traditional view of attention as being either goal-directed or stimulus-driven. Rather, it suggests a new kind of ``derived'' attention.},
author = {{Le Pelley}, Mike E and Mitchell, Chris J and Beesley, Tom and George, David N and Wills, Andy J},
doi = {10.1037/bul0000064},
issn = {1939-1455},
journal = {Psychological Bulletin},
keywords = {associative learning,attention,conditioning,reward learning},
number = {10},
pages = {1111--1140},
title = {{Attention and associative learning in humans: An integrative review.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/bul0000064},
volume = {142},
year = {2016}
}
@article{Noureldin2011,
author = {Noureldin, Diaa and Shephard, Neil and Sheppard, Kevin K.},
doi = {10.1002/jae.1260},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Noureldin, Shephard, Sheppard - 2012 - Multivariate high-frequency-based volatility (HEAVY) models.pdf:pdf},
issn = {08837252},
journal = {Journal of Applied Econometrics},
month = {aug},
number = {6},
pages = {907--933},
title = {{Multivariate high-frequency-based volatility (HEAVY) models}},
url = {http://doi.wiley.com/10.1002/jae.1260},
volume = {27},
year = {2012}
}
@article{collins,
author = {Collins, G.},
journal = {Lect. Notes in Comp. Sci.},
pages = {134--183},
title = {{Quantifier elimination for real closed fields by cylindrical algebraic decomposition}},
volume = {33},
year = {1974}
}
@article{Brandt1986,
abstract = {In this note we deal with the stochastic difference equation of the form Y n +1 = A n Y n + B n , n ∊ℤ, where the sequence is assumed to be strictly stationary and ergodic. By means of simple arguments a unique stationary solution of this equation is constructed. The stability of the stationary solution is the second subject of investigation. It is shown that under some additional assumptions},
author = {Brandt, Andreas},
journal = {Advances in Applied Probability},
keywords = {ERGODICITY,MODEL STABILITY,STATIONARY SOLUTION,STOCHASTIC DIFFERENCE EQUATION,UNIFORM STRONG LAW OF LARGE NUMBERS},
month = {mar},
number = {01},
pages = {211--220},
publisher = {Cambridge University Press},
title = {{The stochastic equation Yn +1=AnYn + Bn with stationary coefficients}},
volume = {18},
year = {1986}
}
@article{wald:mle,
author = {Wald, A},
journal = {The Annals of Mathematical Statistics},
pages = {595--601},
title = {{Note on the consistency of the maximum likelihood estimate}},
url = {http://www.jstor.org/stable/10.2307/2236315},
volume = {20},
year = {1949}
}
@article{Scardapane2017,
author = {Scardapane, Simone and Wang, Dianhui},
doi = {10.1002/widm.1200},
issn = {19424787},
journal = {Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
number = {2},
pages = {e1200},
title = {{Randomness in neural networks: an overview}},
url = {http://doi.wiley.com/10.1002/widm.1200},
volume = {7},
year = {2017}
}
@book{Apostol:analysis,
author = {Apostol, Tom},
edition = {second},
isbn = {978-0-201-00288-1},
pages = {492},
publisher = {Addison Wesley},
title = {{Mathematical Analysis}},
year = {1974}
}
@book{chandrasekhar,
author = {Chandrasekhar, S.},
publisher = {Dover Publications, Inc},
title = {{Ellipsoidal Figures of Equilibrium}},
year = {1969}
}
@article{Darolles:Gourieroux:2006,
author = {Darolles, Serge and Gourieroux, Christian and Jasiak, Joann},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Darolles, Gourieroux, Jasiak - 2006 - Structural laplace transform and compound autoregressive models.pdf:pdf},
issn = {0143-9782},
journal = {Journal of Time Series Analysis},
number = {4},
pages = {477--503},
title = {{Structural laplace transform and compound autoregressive models}},
volume = {27},
year = {2006}
}
@techreport{Jarocinski2010,
author = {Jarocinski, Marek},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Jarocinski - 2010 - Imposing parsimony in cross-country growth regressions.pdf:pdf},
institution = {European Central Bank},
keywords = {Adaptive Ridge Regression,Bayesian Model Averaging,Economic Growth,Measurement Error},
publisher = {ECB},
title = {{Imposing parsimony in cross-country growth regressions}},
type = {Working Paper},
year = {2010}
}
@article{Bottou2018,
abstract = {An abstract is not available.},
author = {Bottou, L{\'{e}}on},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Bottou - 1998 - Online learning and stochastic approximations.pdf:pdf},
isbn = {978-0-521-11791-3},
journal = {Online Learning in Neural Networks},
pages = {1--35},
title = {{Online learning and stochastic approximations}},
year = {1998}
}
@techreport{zhang:bregman,
author = {Zhang, X and Burger, M and Bresson, X and Osher, S},
institution = {UCLA CAM},
title = {{Bregmanized nonlocal regularization for deconvolution and sparse reconstruction}},
type = {Statistics and Econometrics Series},
year = {2009}
}
@article{Lutkepohl2012,
author = {L{\"{u}}tkepohl, Helmut and Xu, Fang},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/L{\"{u}}tkepohl, Xu - 2012 - The role of the log transformation in forecasting economic variables.pdf:pdf},
journal = {Empirical Economics},
keywords = {autoregressive moving average process,forecast mean squared error,heteroskedasticity,instantaneous transformation,integrated process,jel classification c22},
pages = {619--638},
title = {{The role of the log transformation in forecasting}},
year = {2012}
}
@article{eliasson:1990,
author = {Eliasson, L. H.},
journal = {Comment. Math. Helv.},
number = {1},
pages = {4--35},
title = {{Normal forms forHamiltonian systems with Poisson commuting integrals -elliptic case}},
volume = {65},
year = {1990}
}
@article{or2006a,
author = {Ortega, Juan-Pablo and Ratiu, Tudor S.},
journal = {Annals of Global Analysis and Geometry},
number = {4},
pages = {51--75},
title = {{The reduced spaces of a symplectic Lie group action}},
volume = {30},
year = {2006}
}
@article{Hotta1993,
author = {Hotta, L. K. and {Cardoso Neto}, J.},
doi = {10.1111/j.1467-9892.1993.tb00143.x},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Hotta, Cardoso Neto - 1993 - The effect of aggregation on prediction in autoregressive integrated moving-average models.pdf:pdf},
issn = {0143-9782},
journal = {Journal of Time Series Analysis},
month = {may},
number = {3},
pages = {261--269},
title = {{The effect of aggregation on prediction in autoregressive integrated moving-average models}},
url = {http://doi.wiley.com/10.1111/j.1467-9892.1993.tb00143.x},
volume = {14},
year = {1993}
}
@article{Bakshi2010,
abstract = {When the pricing kernel is U-shaped, then expected returns of claims with payout on the upside are negative for strikes beyond a threshold, determined by the slope of the U-shaped kernel in its increasing region, and have negative partial derivative with respect to strike in the increasing region of the kernel. Using returns of (i) S{\&}P 500 index calls, (ii) calls on major international equity indexes, (iii) digital calls, (iv) upside variance contracts, and (v) a theoretical construct that we denote as kernel call, we find broad support for the implications of U-shaped pricing kernels. A possible theoretical reconciliation of our empirical findings is explored through a model that accommodates heterogeneity in beliefs about return outcomes and short-selling.},
author = {Bakshi, Gurdip and Madan, Dilip and Panayotov, George},
issn = {0304405X},
journal = {Journal of Financial Economics},
keywords = {Claims on the upside,Expected returns,G0,G12,G13,Heterogeneity in beliefs,Monotonically declining pricing kernels,Negative average option returns,Short-selling,U-shaped pricing kernels},
month = {jul},
number = {1},
pages = {130--154},
title = {{Returns of claims on the upside and the viability of U-shaped pricing kernels}},
url = {http://www.sciencedirect.com/science/article/pii/S0304405X10000528},
volume = {97},
year = {2010}
}
@article{jakubczyk1990controllability,
author = {Jakubczyk, Bronislaw and Sontag, Eduardo D},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Jakubczyk, Sontag - 1990 - Controllability of nonlinear discrete-time systems A Lie-algebraic approach.pdf:pdf},
journal = {SIAM Journal on Control and Optimization},
number = {1},
pages = {1--33},
publisher = {SIAM},
title = {{Controllability of nonlinear discrete-time systems: A Lie-algebraic approach}},
volume = {28},
year = {1990}
}
@unpublished{CLpaper_BGO_2015,
author = {Bauwens, Luc and Grigoryeva, Lyudmila and Ortega, Juan-Pablo},
booktitle = {Preprint},
title = {{Non-scalar high-dimensional GARCH models: Composite likelihood estimation and empirical comparisons}},
year = {2017}
}
@book{Nesterov2004,
address = {Boston, MA},
author = {Nesterov, Yurii},
doi = {10.1007/978-1-4419-8853-9},
isbn = {978-1-4613-4691-3},
publisher = {Springer US},
series = {Applied Optimization},
title = {{Introductory Lectures on Convex Optimization}},
url = {http://link.springer.com/10.1007/978-1-4419-8853-9},
volume = {87},
year = {2004}
}
@inproceedings{Matthews,
author = {Matthews, M.B.},
booktitle = {1991., IEEE International Sympoisum on Circuits and Systems},
doi = {10.1109/ISCAS.1991.176429},
isbn = {0-7803-0050-5},
pages = {694--697},
publisher = {IEEE},
title = {{An adaptive nonlinear filter structure}},
url = {http://ieeexplore.ieee.org/document/176429/},
year = {1991}
}
@article{TiaoWei1976,
abstract = {This paper considers the effect of temporal aggregation on the dynamic relationships between two discrete time series variables. Given the model in terms of some basic time unit, the corresponding model for the aggregates is obtained. Examples are given showing that temporal aggregation can lead to a substantial loss in parameter estimation while the loss in prediction efficiency is much less severe.},
author = {Tiao, G. C. and Wei, William W. S.},
doi = {10.1093/biomet/63.3.513},
issn = {0006-3444},
journal = {Biometrika},
month = {dec},
number = {3},
pages = {513--523},
title = {{Effect of temporal aggregation on the dynamic relationship of two time series variables}},
url = {http://biomet.oxfordjournals.org/cgi/content/abstract/63/3/513},
volume = {63},
year = {1976}
}
@book{Meyer:book:matrix,
author = {Meyer, Carl},
publisher = {Society for Industrial and Applied Mathematics},
title = {{Matrix Analysis and Applied Linear Algebra Book and Solutions Manual}},
url = {http://www.amazon.fr/Matrix-Analysis-Applied-Algebra-Solutions/dp/0898714540},
year = {2000}
}
@book{GuPo1974,
author = {Guillemin, Victor and Pollack, Alan},
publisher = {American Mathematical Soc.},
title = {{Differential topology}},
volume = {370},
year = {2010}
}
@article{Goudarzi2015,
author = {Goudarzi, A. and Shabani, A. and Stefanovic, D.},
journal = {Neural Networks (IJCNN)},
pages = {1--8},
title = {{Product reservoir computing: Time-series computation with multiplicative neurons}},
year = {2015}
}
@article{convexity:petre,
author = {Birtea, Petre and Ortega, Juan-Pablo and Ratiu, Tudor S.},
journal = {Journal of Lie Theory},
number = {2},
pages = {445--469},
title = {{Metric convexity in the symplectic category}},
volume = {18},
year = {2008}
}
@techreport{Tkacz1999,
abstract = {Financial and monetary variables have long been known to contain useful leading information regarding economic activity. In this paper, the authors wish to determine whether the forecasting performance of such variables can be improved using neural network models. The main ﬁndings are that, at the 1-quarter forecasting horizon, neural networks yield no signiﬁcant forecast improvements. At the 4-quarter horizon, however, the improved forecast accuracy is statistically signiﬁcant. The root mean squared forecast errors of the best neural network models are about 15 to 19 per cent lower than their linear model counterparts. The improved forecast accuracy may be capturing more fundamental non-linearities between ﬁnancial variables and real output growth at the longer horizon},
author = {Tkacz, Greg and Hu, Sarah},
booktitle = {Working Papers},
institution = {Bank of Canada},
keywords = {econometric statistical methods,monetary financial indicators},
publisher = {Bank of Canada},
title = {{Forecasting GDP Growth Using Artificial Neural Networks}},
url = {http://test.bankofcanada.ca/fr/res/wp/1999/wp99-3.pdf},
year = {1999}
}
@article{Anderson1995b,
author = {Anderson, Charles W. and Devulapalli, V. and Stoltz, E. A.},
journal = {Neural networks for signal processing},
pages = {475--483},
title = {{EEG signal classification with different signal representations}},
volume = {V},
year = {1995}
}
@inproceedings{Shaw2014,
address = {Piscataway, NJ, USA},
author = {Shaw, David E. and Grossman, J. P. and Bank et al, Joseph A.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
doi = {10.1109/SC.2014.9},
isbn = {978-1-4799-5500-8},
pages = {41--53},
publisher = {IEEE Press},
series = {SC '14},
title = {{Anton 2: Raising the bar for performance and programmability in a special-purpose molecular dynamics supercomputer}},
url = {http://dx.doi.org/10.1109/SC.2014.9},
year = {2014}
}
@article{Verzelli2020b,
abstract = {In recent years, the machine learning community has seen a continuous growing interest in research aimed at investigating dynamical aspects of both training procedures and perfected models. Of particular interest among recurrent neural networks, we have the Reservoir Computing (RC) paradigm for its conceptual simplicity and fast training scheme. Yet, the guiding principles under which RC operates are only partially understood. In this work, we study the properties behind learning dynamical systems with RC and propose a new guiding principle based on Generalized Synchronization (GS) granting its feasibility. We show that the well-known Echo State Property (ESP) implies and is implied by GS, so that theoretical results derived from the ESP still hold when GS does. However, by using GS one can profitably study the RC learning procedure by linking the reservoir dynamics with the readout training. Notably, this allows us to shed light on the interplay between the input encoding performed by the reservoir and the output produced by the readout optimized for the task at hand. In addition, we show that - as opposed to the ESP - satisfaction of the GS can be measured by means of the Mutual False Nearest Neighbors index, which makes effective to practitioners theoretical derivations.},
author = {Verzelli, Pietro and Alippi, Cesare and Livi, Lorenzo},
doi = {10.1063/5.0056425},
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
pages = {083119},
title = {{Learn to synchronize, synchronize to learn}},
volume = {31},
year = {2021}
}
@article{JLlemma,
author = {Johnson, William B. and Lindenstrauss, Joram},
journal = {Contemporary Mathematics},
pages = {189--206},
title = {{Extensions of Lipschitz mappings into a Hilbert space}},
volume = {26},
year = {1984}
}
@article{rulkov1995generalized,
author = {Rulkov, Nikolai F and Sushchik, Mikhail M and Tsimring, Lev S and Abarbanel, Henry D I},
journal = {Physical Review E},
number = {2},
pages = {980},
publisher = {APS},
title = {{Generalized synchronization of chaos in directionally coupled chaotic systems}},
volume = {51},
year = {1995}
}
@article{Jung1998,
author = {Jung, Tzyy-Ping and Humphries, Colin and Lee, Te-Won and Makeig, Scott and McKeown, Martin J. and Iragui, Vicente and Sejnowski, Terrence J.},
doi = {10.1109/NNSP.1998.710633},
isbn = {0-7803-5060-X},
journal = {Neural setworks for signal processing},
pages = {63--72},
publisher = {Ieee},
title = {{Removing electroencephalographic artifacts: comparison between ICA and PCA}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=710633},
volume = {VIII},
year = {1998}
}
@article{Botta1986,
author = {Botta, R. F. and Harris, C. M.},
issn = {0340-4384},
journal = {Queueing Systems},
month = {sep},
number = {2},
pages = {169--190},
title = {{Approximation with generalized hyperexponential distributions: Weak convergence results}},
url = {http://link.springer.com/10.1007/BF01536187},
volume = {1},
year = {1986}
}
@article{Golowich2019,
abstract = {We study the sample complexity of learning neural networks, by providing new bounds on their Rademacher complexity assuming norm constraints on the parameter matrix of each layer. Compared to previous work, these complexity bounds have improved dependence on the network depth, and under some additional assumptions, are fully independent of the network size (both depth and width). These results are derived using some novel techniques, which may be of independent interest.},
archivePrefix = {arXiv},
arxivId = {arXiv:1712.06541v4},
author = {Golowich, Noah and Rakhlin, Alexander and Shamir, Ohad},
doi = {10.1093/imaiai/iaz007},
eprint = {arXiv:1712.06541v4},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Golowich, Rakhlin, Shamir - 2019 - Size-independent sample complexity of neural networks.pdf:pdf},
issn = {2049-8764},
journal = {Information and Inference: A Journal of the IMA},
number = {1},
pages = {1--28},
title = {{Size-independent sample complexity of neural networks}},
year = {2019}
}
@article{atiya:1999,
author = {Atiya, Amir F. and El-Shoura, Suzan M. and Shaheen, Samir I. and El-Sherif, Mohamed S.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Atiya et al. - 1999 - A comparison between neural-network forecasting techniques-case study river flow forecasting.pdf:pdf},
journal = {IEEE Transactions on Neural Networks},
number = {2},
pages = {402--409},
title = {{A comparison between neural-network forecasting techniques-case study: river flow forecasting}},
volume = {10},
year = {1999}
}
@article{Pradhan1996,
abstract = {Neural networks, inspired by the organizational principles of the human brain, have recently been used in various fields of application such as pattern recognition, identification, classification, speech, vision, signal processing, and control systems. In this study, a two-layered neural network has been trained for the recognition of temporal patterns of the electroencephalogram (EEG). This network is called a Learning Vector Quantization (LVQ) neural network since it learns the characteristics of the signal presented to it as a vector. The first layer is a competitive layer which learns to classify the input vectors. The second, linear, layer transforms the output of the competitive layer to target classes defined by the user. We have tested and evaluated the LVQ network. The network successfully detects epileptiform discharges (EDs) when trained using EEG records scored by a neurologist. Epochs of EEG containing EDs from one subject have been used for training the network, and EEGs of other subjects have been used for testing the network. The results demonstrate that the LVQ detector can generalize the learning to previously "unseen" records of subjects. This study shows that the LVQ network offers a practical solution for ED detection which is easily adjusted to an individual neurologist's style and is as sensitive and specific as an expert visual analysis.},
author = {Pradhan, N. and Sadasivan, P. K. and Arunodaya, G. R.},
issn = {0010-4809},
journal = {Computers and biomedical research},
keywords = {Adolescent,Adult,Automated,Computer Systems,Computer-Assisted,Data Display,Electroencephalography,Epilepsy,Epilepsy: diagnosis,Epilepsy: physiopathology,Humans,Neural Networks (Computer),Neurology,Pattern Recognition,Sensitivity and Specificity,Signal Processing,Temporal Lobe,Temporal Lobe: physiopathology},
month = {aug},
number = {4},
pages = {303--313},
pmid = {8812076},
title = {{Detection of seizure activity in EEG by an artificial neural network: a preliminary study}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8812076},
volume = {29},
year = {1996}
}
@article{mossin:capm,
author = {Mossin, Jan},
journal = {Econometrica},
number = {4},
pages = {768--783},
title = {{Equilibrium in a capital asset market}},
volume = {34},
year = {1966}
}
@article{AL05,
author = {Alexander, Carol and Lazar, E.},
institution = {ICMA Centre Discussion Papers in Finance},
journal = {ICMA Centre Discussion Papers in Finance},
title = {{On the continuous limit of GARCH}},
volume = {13},
year = {2005}
}
@techreport{Barhoumi2008,
abstract = {This paper evaluates different models for the short-term forecasting of real GDP growth in ten selected European countries and the euro area as a whole. Purely quarterly models are compared with models designed to exploit early releases of monthly indicators for the nowcast and forecast of quarterly GDP growth. Amongst the latter, we consider small bridge equations and forecast equations in which the bridging between monthly and quarterly data is achieved through a regression on factors extracted from large monthly datasets. The forecasting exercise is performed in a simulated real-time context, which takes account of publication lags in the individual series. In general, we fi nd that models that exploit monthly information outperform models that use purely quarterly data and, amongst the former, factor models perform best.},
author = {Barhoumi, Karim and Benk, Szilard and Cristadoro, Riccardo and Reijer, Ard Den and Jakaitiene, Audrone Audronė and Jelonek, Piotr and Rua, Ant{\'{o}}nio and R{\"{u}}nstler, Gerhard and Ruth, Karsten and Nieuwenhuyze, Christophe Van},
booktitle = {Journal of Forecasting},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Barhoumi et al. - 2008 - Short-term forecasting of GDP using large monthly datasets a pseudo real-time forecast evaluation exercise.pdf:pdf},
institution = {European Central Bank},
issn = {02776693},
number = {7},
pages = {595--611},
publisher = {European Central Bank},
title = {{Short-term forecasting of GDP using large monthly datasets: a pseudo real-time forecast evaluation exercise}},
type = {Working Paper},
url = {http://doi.wiley.com/10.1002/for.1105},
volume = {28},
year = {2008}
}
@misc{Bacrya,
author = {Bacry, E and Muzy, J F},
booktitle = {Physical Review},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Bacry, Muzy - Unknown - Multifractal models for asset prices.pdf:pdf},
keywords = {fat tails,multifractal,stochastic volatility,volatility},
pages = {1--13},
title = {{Multifractal models for asset prices}}
}
@book{Pardalos2008,
author = {Pardalos, Panos M. and Yatsenko, Vitaly},
pages = {370},
publisher = {Springer Verlag},
title = {{Optimization and Control of Bilinear Systems}},
year = {2008}
}
@article{GCHMGO2013,
author = {Gabriel, Damien and Comte, Alexander and Henriques, Julie and Magnin, E. and Grigoryeva, Lyudmila and Ortega, Juan-Pablo and Haffen, Emmanuel and Moulin, T. and Pazart, L. and Aubry, R.},
doi = {10.1177/1550059413507209},
journal = {Clinical EEG and Neuroscience},
number = {4},
pages = {E111},
title = {{EEG- and fMRI-based communication tools in disorders of consciousness: which is the most reliable method?}},
volume = {44},
year = {2013}
}
@book{Lutkepohl1987,
address = {Berlin},
author = {L{\"{u}}tkepohl, Helmut},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/L{\"{u}}tkepohl - 1987 - Forecasting Aggregated Vector ARMA Processes.pdf:pdf},
publisher = {Springer-Verlag},
title = {{Forecasting Aggregated Vector ARMA Processes}},
year = {1987}
}
@inproceedings{Chen2021,
abstract = {We consider the learning and prediction of nonlinear time series generated by a latent symplectic map. A special case is (not necessarily separable) Hamiltonian systems, whose solution flows give such symplectic maps. For this special case, both generic approaches based on learning the vector field of the latent ODE and specialized approaches based on learning the Hamiltonian that generates the vector field exist. Our method, however, is different as it does not rely on the vector field nor assume its existence; instead, it directly learns the symplectic evolution map in discrete time. Moreover, we do so by representing the symplectic map via a generating function, which we approximate by a neural network (hence the name GFNN). This way, our approximation of the evolution map is always $\backslash$emph{\{}exactly{\}} symplectic. This additional geometric structure allows the local prediction error at each step to accumulate in a controlled fashion, and we will prove, under reasonable assumptions, that the global prediction error grows at most $\backslash$emph{\{}linearly{\}} with long prediction time, which significantly improves an otherwise exponential growth. In addition, as a map-based and thus purely data-driven method, GFNN avoids two additional sources of inaccuracies common in vector-field based approaches, namely the error in approximating the vector field by finite difference of the data, and the error in numerical integration of the vector field for making predictions. Numerical experiments further demonstrate our claims.},
author = {Chen, Renyi and Tao, Molei},
booktitle = {Proceedings of the 38th International Conference on Machine Learning},
editor = {Meila, Marina and Zhang, Tong},
pages = {1717--1727},
publisher = {PMLR},
series = {Proceedings of Machine Learning Research},
title = {{Data-driven prediction of general Hamiltonian dynamics via learning exactly-symplectic maps}},
url = {https://proceedings.mlr.press/v139/chen21r.html},
volume = {139},
year = {2021}
}
@article{blankenstein:2003,
address = {Seville},
author = {Blankenstein, G.},
journal = {2nd IFAC Workshop on Lagrangian andHamiltonian Methods for Nonlinear Control},
pages = {61--66},
title = {{A joined geometric structure for Hamiltonian and gradient control systems}},
year = {2003}
}
@article{Koiran1998,
abstract = {Most of the work on the Vapnik-Chervonenkis dimension of neural networks has been focused on feedforward networks. However, recurrent networks are also widely used in learning applications, in particular when time is a relevant parameter. This paper provides lower and upper bounds for the VC dimension of such networks. Several types of activation functions are discussed, including threshold, polynomial, piecewise-polynomial and sigmoidal functions. The bounds depend on two independent parameters: the number w of weights in the network, and the length k of the input sequence. In contrast, for feedforward networks, VC dimension bounds can be expressed as a function of w only. An important difference between recurrent and feed-forward nets is that a fixed recurrent net can receive inputs of arbitrary length. Therefore we are particularly interested in the case k ≫ w. Ignoring multiplicative constants, the main results say roughly the following: • For architectures with activation $\sigma$ = any fixed nonlinear polynomial, the VC dimension is ≈ wk. • For architectures with activation $\sigma$ = any fixed piecewise polynomial, the VC dimension is between wk and w2k. • For architectures with activation $\sigma$ = ℋ (threshold nets), the VC dimension is between w log(k/w) and min{\{}wk log wk, w2+ w log wk{\}}. • For the standard sigmoid $\sigma$(x)= 1/(1 + e-x), the VC dimension is between wk and w4k2. An earlier version of this paper has appeared in Proc. 3rd European Workshop on Computational Learning Theory, Lecture Notes in Computer Science vol. 1208, Springer, Berlin, 1997, pp. 223-237. {\textcopyright} 1998 Elsevier Science B.V. All rights reserved.},
author = {Koiran, Pascal and Sontag, Eduardo D.},
journal = {Discrete Applied Mathematics},
title = {{Vapnik-Chervonenkis dimension of recurrent neural networks}},
year = {1998}
}
@book{lindquist:picci,
author = {Lindquist, Anders and Picci, Giorgio},
isbn = {9783662457498},
publisher = {Springer-Verlag},
title = {{Linear Stochastic Systems}},
year = {2015}
}
@article{beltrame,
author = {Beltrame, P. and Chossat, P. and Laure, P.},
journal = {C. R. Acad. Sci. Paris S{\'{e}}r. I Math.},
pages = {1049--1052},
title = {{Convection en double diffusion dans unecoque sph{\'{e}}rique}},
volume = {325},
year = {1997}
}
@unpublished{RGARCH_KLIC,
author = {Banulescu, Georgiana-Denisa and Hansen, Peter Reinhard and Huang, Zhuo},
title = {{Volatility during the financial crisis through the lens of high frequency data: a realized GARCH approach}},
year = {2015}
}
@inproceedings{Zha2019,
author = {Zha, Zhiyuan and Wen, Bihan and Zhang, Jiachao and Zhou, Jiantao and Zhu, Ce},
booktitle = {Proceedings of IEEE International Conference on Image Processing},
title = {{A comparative study for the nuclear norms minimization methods}},
year = {2019}
}
@article{duan:GARCH:pricing,
author = {Duan, Jin-Chuan},
issn = {0960-1627},
journal = {Mathematical Finance},
number = {1},
pages = {13--32},
title = {{The GARCH option pricing model}},
volume = {5},
year = {1995}
}
@article{ohsawa2013symmetry,
author = {Ohsawa, Tomoki},
journal = {SIAM Journal on Control and Optimization},
number = {1},
pages = {96--120},
publisher = {SIAM},
title = {{Symmetry reduction of optimal control systems and principal connections}},
volume = {51},
year = {2013}
}
@incollection{Andersen2006review,
abstract = {Volatility has been one of the most active and successful areas of research in time series econometrics and economic forecasting in recent decades. This chapter provides a selective survey of the most important theoretical developments and empirical insights to emerge from this burgeoning literature, with a distinct focus on forecasting applications. Volatility is inherently latent, and Section 1 begins with a brief intuitive account of various key volatility concepts. Section 2 then discusses a series of different economic situations in which volatility plays a crucial role, ranging from the use of volatility forecasts in portfolio allocation to density forecasting in risk management. Sections 3-5 present a variety of alternative procedures for univariate volatility modeling and forecasting based on the GARCH, stochastic volatility and realized volatility paradigms, respectively. Section 6 extends the discussion to the multivariate problem of forecasting conditional covariances and correlations, and Section 7 discusses volatility forecast evaluation methods in both univariate and multivariate cases. Section 8 concludes briefly. {\textcopyright} 2006 Elsevier B.V. All rights reserved.},
author = {Andersen, Torben G. and Bollerslev, Tim and Christoffersen, Peter F. and Diebold, Francis X.},
booktitle = {Handbook of Economic Forecasting},
doi = {10.1016/S1574-0706(05)01015-3},
editor = {Elliott, G. and Granger, Clive W.J. and Timmermann, Allan},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Andersen et al. - 2006 - Volatility and correlation forecasting.pdf:pdf},
isbn = {9780444513953},
issn = {15740706},
keywords = {GARCH,covariance forecasting,realized volatility,stochastic volatility,volatility modeling},
pages = {777--878},
publisher = {Elsevier},
title = {{Volatility and correlation forecasting}},
year = {2006}
}
@article{smale1963stable,
author = {Smale, Stephen},
journal = {Annali della Scuola Normale Superiore di Pisa-Classe di Scienze},
number = {1-2},
pages = {97--116},
title = {{Stable manifolds for differential equations and diffeomorphisms}},
volume = {17},
year = {1963}
}
@article{Heston1993,
abstract = {I use a new technique to derive a closed-form solution for the price of a European call option on an asset with stochastic volatility. The model allows arbitrary correlation between volatility and spot asset returns. I introduce stochastic interest rates and show how to apply the model to bond options and foreign currency options. Simulations show that correlation between volatility and the spot asset's price is important for explaining return skewness and strike-price biases in the Black-Scholes (1973) model. The solution technique is based on characteristic functions and can be applied to other problems},
author = {Heston, S. L.},
doi = {10.1093/rfs/6.2.327},
issn = {14657368},
journal = {Review of Financial Studies},
month = {apr},
number = {2},
pages = {327--343},
title = {{A closed-form solution for options with stochastic volatility with applications to bond and currency options}},
url = {http://rfs.oxfordjournals.org/cgi/content/abstract/6/2/327},
volume = {6},
year = {1993}
}
@phdthesis{Chainarong_thesis,
author = {Kesamoon, Chainarong},
school = {Universitat Aut{\`{o}}noma de Barcelona},
title = {{Volatility Forecasting with Latent Information and Exogenous Variables}},
year = {2015}
}
@book{tsay:book,
author = {Tsay, Ruey S.},
publisher = {Wiley},
title = {{Analysis of Financial Time Series}},
year = {2010}
}
@article{Granger1988,
abstract = {The first sections of the paper show that causality tests can be relevant when considering the effectiveness of a control mechanism, rejecting some results in earlier papers. The relevance comes from a more careful consideration of what information is available to whom and when, compared to previous work. The final section of the paper extends this analysis to cointegrated variables, when causality is a necessary consequence.},
author = {Granger, Clive. W. J.},
issn = {01651889},
journal = {Journal of Economic Dynamics and Control},
month = {jun},
number = {2-3},
pages = {551--559},
title = {{Causality, cointegration, and control}},
url = {http://dx.doi.org/10.1016/0165-1889(88)90055-3},
volume = {12},
year = {1988}
}
@book{Devroye1996,
author = {Devroye, Luc and Gy{\"{o}}rfi, L{\'{a}}szl{\'{o}} and Lugosi, G{\'{a}}bor},
pages = {636},
publisher = {Springer-Verlag, New York},
title = {{A Probabilistic Theory of Pattern Recognition}},
year = {1996}
}
@book{meer:hopf,
author = {van der Meer, Jan Cees},
publisher = {Springer-Verlag},
title = {{The Hamiltonian Hopf Bifurcation}},
year = {1985}
}
@unpublished{DeepNN2016,
author = {Dixon, Matthew and Klabjan, Diego and Bang, Jin Hoon},
title = {{Classiffication-based financial markets prediction using deep neural networks}},
year = {2016}
}
@article{Balkin2000,
abstract = {Artificial neural networks (ANNs) are an information processing paradigm inspired by the way the brain processes information. Using neural networks requires the investigator to make decisions concerning the architecture or structure used. ANNs are known to be universal function approximators and are capable of exploiting nonlinear relationships between variables. This method, called Automated ANNs, is an attempt to develop an automatic procedure for selecting the architecture of an artificial neural network for forecasting purposes. It was entered into the M-3 Time Series Competition. Results show that ANNs compete well with the other methods investigated, but may produce poor results if used under certain conditions.},
author = {Balkin, Sandy D. and Ord, J. Keith},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Balkin, Ord - 2000 - Automatic neural network modeling for univariate time series.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {architecture,artificial neural networks,automated anns},
month = {oct},
number = {4},
pages = {509--515},
title = {{Automatic neural network modeling for univariate time series}},
url = {http://dx.doi.org/10.1016/S0169-2070(00)00072-8},
volume = {16},
year = {2000}
}
@article{Bridges,
author = {Bridges, T J},
journal = {Stud. Appl. Math.},
pages = {93--120},
title = {{{\$}\backslash{\$}{\{}{\$}{\}}O(2)\backslashbackslash{\{}\backslash{\$}{\}}-invariant hamiltonians on {\$}\backslash{\$}{\{}{\$}{\}}\backslashbackslashbC{\{}\backslash{\^{}}{\{}{\}}{\}}4\backslashbackslash{\{}\backslash{\$}{\}}and the (m,n) mode-interaction problem for capillary-gravity waves}},
volume = {82},
year = {1990}
}
@article{tonotopie,
abstract = {To measure the level of residual cognitive function in patients with disorders of consciousness, the use of electrophysiological and neuroimaging protocols of increasing complexity is recommended. This work presents an EEG-based method capable of assessing at an individual level the integrity of the auditory cortex at the bedside of patients and can be seen as the first cortical stage of this hierarchical approach. The method is based on two features: first, the possibility of automatically detecting the presence of a N100 wave and second, in showing evidence of frequency processing in the auditory cortex with a machine learning based classification of the EEG signals associated with different frequencies and auditory stimulation modalities. In the control group of twelve healthy volunteers, cortical frequency processing was clearly demonstrated. EEG recordings from two patients with disorders of consciousness showed evidence of partially preserved cortical processing in the first patient and none in the second patient. From these results, it appears that the classification method presented here reliably detects signal differences in the encoding of frequencies and is a useful tool in the evaluation of the integrity of the auditory cortex. Even though the classification method presented in this work was designed for patients with disorders of consciousness, it can also be applied to other pathological populations.},
author = {Henriques, Julie and Pazart, Lionel and Grigoryeva, Lyudmila and Muzard, Emelyne and Beaussant, Yvan and Haffen, Emmanuel and Moulin, Thierry and Aubry, Regis and Ortega, Juan Pablo and Gabriel, Damien},
doi = {10.1371/journal.pone.0146788},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Henriques et al. - 2016 - Bedside evaluation of the functional organization of the auditory cortex in patients with disorders of conscio.pdf:pdf},
issn = {19326203},
journal = {PLoS ONE},
number = {1},
pages = {1--11},
pmid = {26789734},
title = {{Bedside evaluation of the functional organization of the auditory cortex in patients with disorders of consciousness}},
url = {http://dx.doi.org/10.1371/journal.pone.0146788},
volume = {11},
year = {2016}
}
@inproceedings{Stentoft2015,
address = {Working paper},
author = {Simonato, Jean-Guy and Stentoft, Lars},
title = {{Which pricing approach for options under GARCH with non-normal innovations?}},
year = {2015}
}
@article{Ben-DavidMarks2014,
author = {Ben-David, Avishai and Marks, Justin},
journal = {IEEE Geoscience and Remote Sensing Letters},
number = {9},
pages = {1499--1503},
title = {{Geodesic paths for time-dependent covariance matrices in a Riemannian manifold}},
volume = {11},
year = {2014}
}
@unpublished{Li2018,
abstract = {We establish a margin based data dependent generalization error bound for a general family of deep neural networks in terms of the depth and width, as well as the Jacobian of the networks. Through introducing a new characterization of the Lipschitz properties of neural network family, we achieve significantly tighter generalization bounds than existing results. Moreover, we show that the generalization bound can be further improved for bounded losses. Aside from the general feedforward deep neural networks, our results can be applied to derive new bounds for popular architectures, including convolutional neural networks (CNNs) and residual networks (ResNets). When achieving same generalization errors with previous arts, our bounds allow for the choice of larger parameter spaces of weight matrices, inducing potentially stronger expressive ability for neural networks. Numerical evaluation is also provided to support our theory.},
archivePrefix = {arXiv},
arxivId = {1806.05159},
author = {Li, Xingguo and Lu, Junwei and Wang, Zhaoran and Haupt, Jarvis and Zhao, Tuo},
eprint = {1806.05159},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Li et al. - 2018 - On tighter generalization bound for deep neural networks CNNs, ResNets, and Beyond.pdf:pdf},
pages = {1--26},
title = {{On tighter generalization bound for deep neural networks: CNNs, ResNets, and Beyond}},
url = {http://arxiv.org/abs/1806.05159},
year = {2018}
}
@book{cucker:zhou,
author = {Cucker, Felipe and Zhou, Ding Xuan},
isbn = {9780521865593},
pages = {224},
publisher = {Cambridge University Press},
title = {{Learning Theory: An Approximation Theory Viewpoint}},
year = {2007}
}
@article{Tino2013,
author = {Tino, Peter and Rodan, Ali},
journal = {Neurocomputing},
pages = {58--63},
title = {{Short term memory in input-driven linear dynamical systems}},
volume = {112},
year = {2013}
}
@article{hosking:portmanteau:equivalent,
author = {Hosking, J R M},
issn = {0035-9246},
journal = {J. Roy. Statist. Soc. Ser. B},
number = {2},
pages = {261--262},
title = {{Equivalent forms of the multivariate portmanteau statistic}},
volume = {43},
year = {1981}
}
@article{Branicky,
abstract = {We explore the simulation and computational capabilities of hybrid and continuous dynamical systems. The continuous dynamical systems considered are ordinary differential equations (ODEs). For hybrid systems we concentrate on models that combine ODEs and discrete dynamics (e.g., finite automata). We review and compare four such models from the literature. Notions of simulation of a discrete dynamical system by a continuous one are developed. We show that hybrid systems whose equations can describe a precise binary timing pulse (exact clock) can simulate arbitrary reversible discrete dynamical systems defined on closed subsets of Rn. The simulations require continuous ODEs in R2n with the exact clock as input. All four hybrid systems models studied here can implement exact clocks. We also prove that any discrete dynamical system in Zn can be simulated by continuous ODEs in R2n + 1. We use this to show that smooth ODEs in R3 can simulate arbitrary Turing machines, and hence possess the power of universal computation. We use the famous asynchronous arbiter problem to distinguish between hybrid and continuous dynamical systems. We prove that one cannot build an arbiter with devices described by a system of Lipschitz ODEs. On the other hand, all four hybrid systems models considered can implement arbiters even if their ODEs are Lipschitz.},
author = {Branicky, Michael S.},
doi = {10.1016/0304-3975(94)00147-B},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Branicky - 1995 - Universal computation and other capabilities of hybrid and continuous dynamical systems.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
number = {1},
pages = {67--100},
publisher = {Elsevier},
title = {{Universal computation and other capabilities of hybrid and continuous dynamical systems}},
volume = {138},
year = {1995}
}
@article{Greven2018,
author = {Greven, Sonja and Scheipl, Fabian},
journal = {Statistical Modelling},
number = {1-2},
pages = {1--35},
title = {{A general framework for functional regression modelling}},
volume = {17},
year = {2018}
}
@article{Ortega2005re,
abstract = {This paper includes results centered around three topics, all of them related with the nonlinear stability of equilibria in constrained dynamical systems. First, we prove an energy-Casimir type sufficient condition for stability that uses functions that are not necessarily conserved by the flow and that takes into account the asymptotically stable behavior that may occur in certain constrained systems, such as Poisson and Leibniz dynamical systems. Second, this method is specifically adapted to Poisson systems obtained via a reduction procedure and we show in examples that the kind of stability that we propose is appropriate when dealing with the stability of the equilibria of some constrained mechanical systems. Finally, we discuss two situations in which the use of continuous Casimir functions in stability studies is equivalent to the topological stability methods introduced by Patrick et al. (Arch. Rational Mech. Anal., 2004, preprint arXiv:math.DS/0201239v1, to appear).},
author = {Ortega, Juan-Pablo and Planas-Bielsa, V{\'{i}}ctor and Ratiu, Tudor S.},
doi = {10.1016/J.JDE.2004.09.016},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Ortega, Planas-Bielsa, Ratiu - 2005 - Asymptotic and Lyapunov stability of constrained and Poisson equilibria.pdf:pdf},
issn = {0022-0396},
journal = {Journal of Differential Equations},
month = {jul},
number = {1},
pages = {92--127},
publisher = {Academic Press},
title = {{Asymptotic and Lyapunov stability of constrained and Poisson equilibria}},
url = {https://www.sciencedirect.com/science/article/pii/S0022039604003912},
volume = {214},
year = {2005}
}
@unpublished{Chen2019,
author = {Chen, Xinshi},
title = {{Review: Ordinary differential equations for deep learning}},
year = {2019}
}
@article{Menn2005,
author = {Menn, Christian and Rachev, Svetlozar},
journal = {European Journal of Operational Research},
number = {1},
pages = {201--209},
title = {{A GARCH option pricing model with a-stable innovations}},
volume = {163},
year = {2005}
}
@book{simmons:topology,
author = {Simmons, George F.},
pages = {364},
publisher = {McGraw-Hill},
title = {{Topology and Modern Analysis}},
year = {1963}
}
@article{leonard:1997,
author = {Leonard, N. E.},
journal = {Automatica},
number = {3},
pages = {331--346},
title = {{Stability of a bottom-heavy underwater vehicle}},
volume = {33},
year = {1997}
}
@article{candesTao:IEEEIT10,
author = {Cand{\`{e}}s, Emmanuel J and Tao, Terence},
doi = {10.1109/TIT.2010.2044061},
issn = {0018-9448},
journal = {IEEE Trans. Inform. Theory},
number = {5},
pages = {2053--2080},
title = {{The power of convex relaxation: near-optimal matrix completion}},
url = {http://dx.doi.org/10.1109/TIT.2010.2044061},
volume = {56},
year = {2010}
}
@article{Patton2011,
author = {Patton, A. J.},
journal = {Journal of Econometrics},
number = {1},
pages = {246--256},
title = {{Volatility forecast comparison using imperfect volatility proxies}},
volume = {160},
year = {2011}
}
@article{Taylor:review,
author = {Taylor, Stephen J},
journal = {Mathematical Finance},
pages = {183--204},
title = {{Modelling stochastic volatility: a review and comparative study}},
volume = {4},
year = {1994}
}
@article{Kukharenko2011_1,
annote = {in Russian},
author = {Kukharenko, Oleksandra and Khusainov, Denis},
journal = {Bulletin of Institute of Mathematic of Ukraine},
number = {2},
pages = {112--131},
title = {{Control of solutions of parabolic linear equation}},
volume = {8},
year = {2011}
}
@article{hornik,
abstract = {This paper rigorously establishes that standard multilayer feedforward networks with as few as one hidden layer using arbitrary squashing functions are capable of approximating any Borel measurable function from one finite dimensional space to another to any desired degree of accuracy, provided sufficiently many hidden units are available. In this sense, multilayer feedforward networks are a class of universal approximators.},
author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
doi = {10.1016/0893-6080(89)90020-8},
issn = {08936080},
journal = {Neural Networks},
number = {5},
pages = {359--366},
title = {{Multilayer feedforward networks are universal approximators}},
volume = {2},
year = {1989}
}
@book{granger:newbold,
address = {San Diego, CA},
author = {Granger, Clive. W. J. and Newbold, P},
edition = {Second},
publisher = {Academic Press},
title = {{Forecasting Economic Time Series}},
year = {1986}
}
@book{Kimura2006,
author = {Kimura, H. and Tsuchiya, K. and Ishiguro, A. and Witt, H.},
pages = {298},
publisher = {Springer},
title = {{Adaptive Motion of Animals and Machines}},
year = {2006}
}
@article{SOASfirst,
abstract = {We propose photonic reservoir computing as a new approach to optical signal processing in the context of large scale pattern recognition problems. Photonic reservoir computing is a photonic implementation of the recently proposed reservoir computing concept, where the dynamics of a network of nonlinear elements are exploited to perform general signal processing tasks. In our proposed photonic implementation, we employ a network of coupled Semiconductor Optical Amplifiers (SOA) as the basic building blocks for the reservoir. Although they differ in many key respects from traditional software-based hyperbolic tangent reservoirs, we show using simulations that such a photonic reservoir can outperform traditional reservoirs on a benchmark classification task. Moreover, a photonic implementation offers the promise of massively parallel information processing with low power and high speed.},
author = {Vandoorne, Kristof and Dierckx, Wouter and Schrauwen, Benjamin and Verstraeten, David and Baets, Roel and Bienstman, Peter and {Van Campenhout}, Jan},
doi = {10.1364/OE.16.011182},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Vandoorne et al. - 2008 - Toward optical signal processing using Photonic Reservoir Computing.pdf:pdf},
issn = {1094-4087},
journal = {Optics Express},
keywords = {Nonlinear optics,Optical neural systems,Semiconductor optical amplifiers,integrated optics},
month = {jul},
number = {15},
pages = {11182},
publisher = {Optical Society of America},
title = {{Toward optical signal processing using Photonic Reservoir Computing}},
url = {https://www.osapublishing.org/oe/abstract.cfm?uri=oe-16-15-11182},
volume = {16},
year = {2008}
}
@article{stefan,
author = {Stefan, Peter},
journal = {Bulletin of the American Mathematical Society},
number = {6},
pages = {1142--1145},
title = {{Accessibility and foliations with singularities}},
volume = {80},
year = {1974}
}
@inproceedings{kalman:Festschrift,
author = {Antoulas, Athanasios C.},
booktitle = {A Festschrift in Honor of Professor R. E. Kalman on the Occasion of his 60th Birthday},
editor = {Antoulas, Athanasios C.},
isbn = {9783662085486},
publisher = {Springer-Verlag},
title = {{Mathematical System Theory. The Influence of R. E. Kalman.}},
year = {1991}
}
@phdthesis{Jingyu2010,
author = {Jingyu, Fu},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Jingyu - 2010 - Modeling Multivariate Volatilities via Most Predictable Factor.pdf:pdf},
school = {National University of Singapore},
title = {{Modeling Multivariate Volatilities via Most Predictable Factor}},
year = {2010}
}
@article{Cai2011,
abstract = {This paper aims to extend the analytical tractability of the Black–Scholes model to alternative models with arbitrary jump size distributions. More precisely, we propose a jump diffusion model for asset prices whose jump sizes have a mixed-exponential distribution, which is a weighted average of exponential distributions but with possibly negative weights. The new model extends existing models, such as hyperexponential and double-exponential jump diffusion models, because the mixed-exponential distribution can approximate any distribution as closely as possible, including the normal distribution and various heavy-tailed distributions. The mixed-exponential jump diffusion model can lead to analytical solutions for Laplace transforms of prices and sensitivity parameters for path-dependent options such as lookback and barrier options. The Laplace transforms can be inverted via the Euler inversion algorithm. Numerical experiments indicate that the formulae are easy to implement and accurate. The analytical so...},
author = {Cai, Ning and Kou, S. G.},
issn = {0025-1909},
journal = {Management Science},
keywords = {Merton's normal jump diffusion model,barrier options,first passage times,jump diffusion,lookback options,mixed-exponential distributions},
language = {en},
month = {nov},
number = {11},
pages = {2067--2081},
publisher = {INFORMS},
title = {{Option pricing under a mixed-exponential jump diffusion model}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/mnsc.1110.1393},
volume = {57},
year = {2011}
}
@article{Robbins1951,
author = {Robbins, Herbert and Monro, Sutton},
journal = {The Annals of Mathematical Statistics},
number = {3},
pages = {400--407},
title = {{A stochastic approximation method}},
volume = {22},
year = {1951}
}
@article{dungey:kalman,
author = {Dungey, Mardi and Martin, Vance L. and Pagan, Adrian R.},
journal = {Journal of Applied Econometrics},
number = {6},
pages = {697--715},
title = {{A multivariate latent factor decomposition of international bond yield spreads}},
volume = {15},
year = {2001}
}
@article{hart:ESNs,
abstract = {Echo State Networks (ESNs) are a class of single-layer recurrent neural networks that have enjoyed recent attention. In this paper we prove that a suitable ESN, trained on a series of measurements of an invertible dynamical system induces a continuously differentiable map from the dynamical system's phase space to the ESN's reservoir space. We then prove that the Echo State Map is generically an embedding with positive probability. Under additional mild assumptions, we further conjecture that the Echo State Map is almost surely an embedding. For sufficiently large, and specially structured, but still randomly generated ESNs, we prove that there exists a linear readout layer that allows the ESN to predict the next observation of a dynamical system arbitrarily well. Consequently, if the dynamical system under observation is structurally stable then the trained ESN will exhibit dynamics that are topologically conjugate to the future behaviour of the observed dynamical system. Our theoretical results connect the theory of ESNs to the delay-embedding literature for dynamical systems, and are supported by numerical evidence from simulations of the traditional Lorenz equations. The simulations confirm that, from a one dimensional observation function, an ESN can accurately infer a range of geometric and topological features of the dynamics such as the eigenvalues of equilibrium points, Lyapunov exponents and homology groups.},
archivePrefix = {arXiv},
arxivId = {1908.05202},
author = {Hart, Allen G and Hook, James L and Dawes, Jonathan H P},
eprint = {1908.05202},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Hart, Hook, Dawes - 2020 - Embedding and approximation theorems for echo state networks(2).pdf:pdf},
journal = {Neural Networks},
pages = {234--247},
title = {{Embedding and approximation theorems for echo state networks}},
url = {http://arxiv.org/abs/1908.05202},
volume = {128},
year = {2020}
}
@article{Laporte2018,
abstract = {We propose a new design for a passive photonic reservoir computer on a silicon photonics chip which can be used in the context of optical communication applications, and study it through detailed numerical simulations. The design consists of a photonic crystal cavity with a quarter-stadium shape, which is known to foster interesting mixing dynamics. These mixing properties turn out to be very useful for memory-dependent optical signal processing tasks, such as header recognition. The proposed, ultra-compact photonic crystal cavity exhibits a memory of up to 6 bits, while simultaneously accepting bitrates in a wide region of operation. Moreover, because of the inherent low losses in a high-Q photonic crystal cavity, the proposed design is very power efficient.},
author = {Laporte, Floris and Katumba, Andrew and Dambre, Joni and Bienstman, Peter},
doi = {10.1364/OE.26.007955},
issn = {1094-4087},
journal = {Optics Express},
keywords = {Numerical simulation,Photonic crystal cavities,Photonic crystal waveguides,Photonic crystals,Q factor,Waveguides},
month = {apr},
number = {7},
pages = {7955},
publisher = {Optical Society of America},
title = {{Numerical demonstration of neuromorphic computing with photonic crystal cavities}},
url = {https://www.osapublishing.org/abstract.cfm?URI=oe-26-7-7955},
volume = {26},
year = {2018}
}
@inproceedings{Doya92,
author = {Doya, K.},
booktitle = {Proceedings of IEEE International Symposium on Circuits and Systems},
doi = {10.1109/ISCAS.1992.230622},
isbn = {0-7803-0593-0},
pages = {2777--2780},
publisher = {IEEE},
title = {{Bifurcations in the learning of recurrent neural networks}},
url = {http://ieeexplore.ieee.org/document/230622/},
volume = {6},
year = {1992}
}
@article{altay:pinar:leyffer,
author = {Altay-Salih, Aslihan and Pinar, Mustafa {\c{C}}. and Leyffer, Sven},
doi = {10.1137/S003614450140011},
issn = {0036-1445},
journal = {SIAM Rev.},
number = {3},
pages = {485----503 (electronic)},
title = {{Constrained nonlinear programming for volatility estimation with GARCH models}},
url = {http://dx.doi.org/10.1137/S003614450140011},
volume = {45},
year = {2003}
}
@techreport{Forni,
author = {Forni, Mario and Hallin, Marc and Lippi, Marco and Reichlin, Lucrezia and Ruj, Z Z Z Fhsu and Modena, Universit{\`{a}}},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Forni et al. - 2002 - Do Financial Variables Help Forecasting Inflation and Real Activity in the Euro Area.pdf:pdf},
institution = {CEPR},
number = {3146},
title = {{Do Financial Variables Help Forecasting Inflation and Real Activity in the Euro Area?}},
type = {Discussion Paper},
year = {2002}
}
@article{google:nature,
abstract = {Modern computers separate computation and memory. Computation is performed by a processor, which can use an addressable memory to bring operands in and out of play. This confers two important benefits: the use of extensible storage to write new information and the ability to treat the contents of memory as variables. Variables are critical to algorithm generality: to perform the same procedure on one datum or another, an algorithm merely has to change the address it reads from. In contrast to computers, the computational and memory resources of artificial neural networks are mixed together in the network weights and neuron activity. This is a major liability: as the memory demands of a task increase, these networks cannot allocate new storage dynam-ically, nor easily learn algorithms that act independently of the values realized by the task variables. Although recent breakthroughs demonstrate that neural networks are remarkably adept at sensory processing 1 , sequence learning 2,3 and reinforcement learning 4 , cognitive scientists and neuroscientists have argued that neural networks are limited in their ability to represent variables and data structures 5–9 , and to store data over long timescales without interference 10,11 . We aim to combine the advantages of neu-ral and computational processing by providing a neural network with read–write access to external memory. The access is narrowly focused, minimizing interference among memoranda and enabling long-term storage 12,13 . The whole system is differentiable, and can therefore be trained end-to-end with gradient descent, allowing the network to learn how to operate and organize the memory in a goal-directed manner.},
archivePrefix = {arXiv},
arxivId = {arXiv:1410.5401v2},
author = {Graves, Alex and Wayne, Greg and Reynolds, Malcolm and Harley, Tim and Danihelka, Ivo and Grabska-Barwi{\'{n}}ska, Agnieszka and {G{\'{o}}mez Colmenarejo}, Sergio and Grefenstette, Edward and Ramalho, Tiago and Agapiou, John and Badia, Adri{\`{a}} Puigdom{\`{e}}nech and {Moritz Hermann}, Karl and Zwols, Yori and Ostrovski, Georg and Cain, Adam and King, Helen and Summerfield, Christopher and Blunsom, Phil and Kavukcuoglu, Koray and Hassabis, Demis},
doi = {10.1038/nature20101},
eprint = {arXiv:1410.5401v2},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Graves et al. - 2016 - Hybrid computing using a neural network with dynamic external memory.pdf:pdf},
isbn = {0896-6273},
issn = {0028-0836},
journal = {Nature Publishing Group},
number = {7626},
pages = {471--476},
pmid = {26774160},
publisher = {Nature Publishing Group},
title = {{Hybrid computing using a neural network with dynamic external memory}},
url = {http://dx.doi.org/10.1038/nature20101},
volume = {538},
year = {2016}
}
@article{Wang2017,
abstract = {This paper contributes to a development of randomized methods for neural networks. The proposed learner model is generated incrementally by stochastic configuration (SC) algorithms, termed as Stochastic Configuration Networks (SCNs). In contrast to the existing randomised learning algorithms for single layer feed-forward neural networks (SLFNNs), we randomly assign the input weights and biases of the hidden nodes in the light of a supervisory mechanism, and the output weights are analytically evaluated in either constructive or selective manner. As fundamentals of SCN-based data modelling techniques, we establish some theoretical results on the universal approximation property. Three versions of SC algorithms are presented for regression problems (applicable for classification problems as well) in this work. Simulation results concerning both function approximation and real world data regression indicate some remarkable merits of our proposed SCNs in terms of less human intervention on the network size setting, the scope adaptation of random parameters, fast learning and sound generalization.},
archivePrefix = {arXiv},
arxivId = {1702.03180},
author = {Wang, Dianhui and Li, Ming},
eprint = {1702.03180},
number = {February},
title = {{Stochastic Configuration Networks: Fundamentals and Algorithms}},
year = {2017}
}
@article{QMLforSREofGARCH,
author = {Straumann, Daniel and Mikosch, Thomas},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Straumann, Mikosch - 2006 - Quasi-maximum-likelihood estimation in conditionally heteroscedastic time series A stochastic recurrence equ.pdf:pdf},
journal = {The Annals of Statistics},
number = {5},
pages = {2449--2495},
title = {{Quasi-maximum-likelihood estimation in conditionally heteroscedastic time series: A stochastic recurrence equations approach}},
volume = {34},
year = {2006}
}
@misc{Andrade2011a,
author = {Andrade, Philippe and Ghysels, Eric},
title = {{Tails of inflation forecasts and tales of monetary policy}},
year = {2011}
}
@article{Thiel2013,
annote = {News {\&} Views},
author = {Thiel, Walter and Hummer, Gerhard},
issn = {0028-0836},
journal = {Nature},
month = {dec},
number = {7478},
pages = {96--97},
publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
title = {{Nobel 2013 Chemistry: Methods for computational chemistry}},
url = {http://dx.doi.org/10.1038/504096a},
volume = {504},
year = {2013}
}
@book{Nyberg2008,
author = {Nyberg, Henri},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Nyberg - 2008 - Dynamic probit models and financial variables in recession forecasting.pdf:pdf},
number = {225},
title = {{Dynamic Probit Models and Financial Variables in Recession Forecasting}},
volume = {17},
year = {2008}
}
@article{SR,
author = {Rombouts, Jeroen V. K. and Stentoft, Lars},
journal = {International Journal of Forecasting},
number = {3},
pages = {635--650},
title = {{Option pricing with asymmetric heteroskedastic normal mixture models}},
volume = {31},
year = {2015}
}
@inproceedings{Vershynin2010,
author = {Vershynin, Roman},
booktitle = {3rd IEEE International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP)},
title = {{On the role of sparsity in Compressed Sensing and random matrix theory}},
year = {2010}
}
@article{sandberg:time-delay,
abstract = {We consider a large family of approximately-finite memory causal time-invariant maps G from an input set S to a set of IR-valued functions, with the members of both sets of functions defined on the nonnegative integers, and we give an upper bound on the error in approximating a G using a two-stage structure consisting of a tapped delay line followed by a static neural network. As an application, information is given concerning the long-standing problem of determining the order of a Volterra-series approximation so that a given quality of approximation can be achieved. We have also obtained a corresponding result for the approximation of not-necessarily-causal input-output maps with inputs and outputs that may depend on more than one variable. These results are of interest, for example, in connection with image processing},
author = {Sandberg, I W},
doi = {10.1007/BF01203110},
issn = {0278-081X},
journal = {Circuits, Systems, and Signal Processing},
keywords = {IR-valued functions,Volterra series,Volterra-series approximation,approximately-finite memory causal time-invariant,approximation theory,delays,image processing,input set,neural nets,nonlinear network analysis,nonlinear systems,nonnegative integers,static neural network,tapped delay line,time-delay neural networks,two-stage structure,upper bound},
number = {5},
pages = {653--655},
title = {{Time-delay neural networks, Volterra series, and rates of approximation}},
volume = {17},
year = {1998}
}
@article{tihonov_ridge_1963,
author = {Tikhonov, A. N},
journal = {Dokl. Akad. Nauk SSSR},
pages = {501--504},
title = {{Solution of incorrectly formulated problems and the regularization method}},
volume = {151},
year = {1963}
}
@article{Dryden2009,
author = {Dryden, Ian L. and Koloydenko, Alexey and Zhou, Diwei},
journal = {The Annals of Applied Statistics},
number = {3},
pages = {1102--1123},
title = {{Non-Eucleadian statistics for covariance matrices, with applications to diffusion tensor imaging}},
volume = {3},
year = {2009}
}
@article{eca:english,
author = {Arnold, V. I.},
journal = {Amer. Math. Soc. Transl.},
pages = {267--269},
title = {{On an a priori estimate in the theory of hydrodynamical stability. (English)}},
volume = {79},
year = {1969}
}
@article{Makovoz.1996,
author = {Makovoz., Yuly},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Makovoz. - 1996 - Random approximants and neural networks(2).pdf:pdf},
journal = {Journal of Approximation Theory},
number = {1},
pages = {98--109},
title = {{Random approximants and neural networks}},
volume = {85},
year = {1996}
}
@article{Baillie1981,
abstract = {The asymptotic distribution of prediction is derived for the general simultaneous equation model with lagged endogenous variables and vector autoregressive errors. The results turn out to be particularly simple when no lagged endogenous variables are present.},
author = {Baillie, Richard T.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Baillie - 1981 - Prediction from the dynamic simultaneous equation model with vector autoregressive errors.pdf:pdf},
journal = {Econometrica},
number = {5},
pages = {1331--1337},
title = {{Prediction from the dynamic simultaneous equation model with vector autoregressive errors}},
volume = {49},
year = {1981}
}
@article{Hu2016,
author = {Hu, R. and Hochstrasser, M.},
journal = {Cell Research},
number = {4},
pages = {389--390},
title = {{Recent progress in ubiquitin and ubiquitin-like protein (Ubl) signaling}},
volume = {26},
year = {2016}
}
@article{lazaro:ortega2,
author = {L{\'{a}}zaro-Cam{\'{i}}, Andreu and Ortega, Juan-Pablo},
journal = {Stochastics and Dynamics},
number = {1},
pages = {1--46},
title = {{Reduction, reconstruction, and skew-product decomposition of symmetric stochastic differential equations}},
volume = {9},
year = {2009}
}
@article{Ginzburg1947,
author = {Ginzburg, Vitaly L.},
journal = {Phys.-Uspekhi},
number = {2},
pages = {174--209},
title = {{Mezotrons theory and nuclear forces (in Russian)}},
volume = {31},
year = {1947}
}
@article{Moshiri2000,
author = {Moshiri, Saeed and Cameron, Norman},
journal = {Journal of Forecasting},
pages = {201--217},
title = {{Neural networks versus econometric models in forecasting inflation}},
volume = {19},
year = {2000}
}
@article{Christoffersen2006,
abstract = {Index option prices differ systematically from Black–Scholes prices. Out-of-the-money put prices (and in-the-money call prices) are relatively high compared to the Black–Scholes price. Motivated by these empirical facts, we develop a new discrete-time dynamic model of stock returns with inverse Gaussian innovations. The model allows for conditional skewness as well as conditional heteroskedasticity and a leverage effect. We present an analytic option pricing formula consistent with this stock return dynamic. An extensive empirical test of the model using S{\&}P500 index options shows that the new inverse Gaussian GARCH model's performance is superior to a standard existing nested model for out-of-the money puts.},
author = {Christoffersen, Peter and Heston, Steve and Jacobs, Kris},
doi = {10.1016/j.jeconom.2005.01.010},
issn = {03044076},
journal = {Journal of Econometrics},
keywords = {g12},
month = {mar},
number = {1-2},
pages = {253--284},
title = {{Option valuation with conditional skewness}},
url = {http://dx.doi.org/10.1016/j.jeconom.2005.01.010},
volume = {131},
year = {2006}
}
@article{Ritchken1999,
author = {Ritchken, Peter and Trevor, Rob},
doi = {10.1111/0022-1082.00109},
issn = {0022-1082},
journal = {The Journal of Finance},
month = {feb},
number = {1},
pages = {377--402},
title = {{Pricing Options under Generalized GARCH and Stochastic Volatility Processes}},
url = {http://doi.wiley.com/10.1111/0022-1082.00109},
volume = {54},
year = {1999}
}
@incollection{sep-ergodic-hierarchy,
author = {Frigg, Roman and Berkovitz, Joseph and Kronz, Fred},
booktitle = {The {\{}Stanford{\}} Encyclopedia of Philosophy},
edition = {{\{}F{\}}all 202},
editor = {Zalta, Edward N},
howpublished = {$\backslash$url{\{}https://plato.stanford.edu/archives/fall2020/entries/ergodic-hierarchy/{\}}},
publisher = {Metaphysics Research Lab, Stanford University},
title = {{The Ergodic Hierarchy}},
year = {2020}
}
@incollection{gonzalez2000time,
author = {Gonzalez, Oscar},
booktitle = {Mechanics: from theory to computation},
pages = {257--275},
publisher = {Springer},
title = {{Time integration and discrete Hamiltonian systems}},
year = {2000}
}
@inproceedings{bruges:deepRC,
abstract = {In this paper we propose an empirical analysis of deep recur-rent neural networks (RNNs) with stacked layers. The analysis aims at the study and proposal of approaches to develop and enhance multiple time-scale and hierarchical dynamics in deep recurrent architectures, within the efficient Reservoir Computing (RC) approach for RNN modeling. Results point out the actual relevance of layering and RC parameters aspects on the diversification of temporal representations in deep recurrent models.},
address = {Bruges (Belgium)},
author = {Gallicchio, Claudio and Micheli, Alessio},
booktitle = {ESANN 2016 proceedings, European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning. Bruges (Belgium), 27-29 April 2016.},
isbn = {9782875870278},
number = {April},
pages = {497--502},
title = {{Deep reservoir computing: a critical analysis}},
year = {2016}
}
@article{brockett:1993,
author = {Brockett, R. W.},
journal = {Proc. Symp. Pure Math. AMS},
number = {I},
pages = {69--92},
title = {{Differential geometry and the design of gradient algorithms}},
volume = {54 (I)},
year = {1993}
}
@misc{There2010,
author = {de Bandt, Olivier and Malik, Sheheryar and de Bandt, Olivier and Malik, Sheheryar},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Bandt, Malik - 2010 - Is there evidence of shift-contagion in international housing markets.pdf:pdf},
institution = {Banque de France},
title = {{Is there evidence of shift-contagion in international housing markets?}},
year = {2010}
}
@article{Karplus2002,
address = {Department of Chemistry and Chemical Biology, Harvard University, Cambridge, Massachusetts 02138, USA. marci@tammy.harvard.edu},
author = {Karplus, Martin and McCammon, J Andrew},
doi = {10.1038/nsb0902-646},
issn = {1072-8368},
journal = {Nature Structural {\&} Molecular Biology},
keywords = {kaltes{\_}wasser,mds,review},
month = {sep},
number = {9},
pages = {646--652},
pmid = {12198485},
publisher = {Nature Publishing Group},
title = {{Molecular dynamics simulations of biomolecules}},
url = {http://dx.doi.org/10.1038/nsb0902-646},
volume = {9},
year = {2002}
}
@article{farago:lugosi:universal,
abstract = {In statistical pattern recognition, a classifier is called universally consistent if its error probability converges to the Bayes-risk as the size of the training data grows for all possible distributions of the random variable pair of the observation vector and its class. It is proven that if a one-layered neural network with properly chosen number of nodes is trained to minimize the empirical risk on the training data, then a universally consistent classifier results. It is shown that the exponent in the rate of convergence does not depend on the dimension if certain smoothness conditions on the distribution are satisfied. That is, this class of universally consistent classifiers does not suffer from the curse of dimensionality. A training algorithm is presented that finds the optimal set of parameters in polynomial time if the number of nodes and the space dimension is fixed and the amount of training data grows},
author = {Farag{\'{o}}, Andr{\'{a}}s and Lugosi, G{\'{a}}bor},
doi = {10.1109/18.243433},
isbn = {0780308786},
issn = {15579654},
journal = {IEEE Transactions on Information Theory},
keywords = {.Pattern recognition,consistency,neural networks,nonparametric classification,training algorithms},
number = {4},
pages = {1146--1151},
title = {{Strong Universal Consistency of Neural Network Classifiers}},
volume = {39},
year = {1993}
}
@article{Ewald2007,
author = {Ewald, Christian-Oliver and Yang, Zhaojun},
issn = {1432-2994},
journal = {Mathematical Methods of Operations Research},
month = {dec},
number = {1},
pages = {97--123},
title = {{Utility based pricing and exercising of real options under geometric mean reversion and risk aversion toward idiosyncratic risk}},
url = {http://link.springer.com/10.1007/s00186-007-0190-9},
volume = {68},
year = {2007}
}
@article{Lancaster1972,
author = {Lancaster, P. and Farahat, H. K.},
doi = {10.1090/S0025-5718-1972-0305099-X},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Lancaster, Farahat - 1972 - Norms on direct sums and tensor products.pdf:pdf},
issn = {0025-5718},
journal = {Mathematics of Computation},
month = {may},
number = {118},
pages = {401--401},
title = {{Norms on direct sums and tensor products}},
url = {http://www.ams.org/jourcgi/jour-getitem?pii=S0025-5718-1972-0305099-X},
volume = {26},
year = {1972}
}
@article{Smale2003,
abstract = {Let B be a Banach space and (ℋ,‖{\textperiodcentered}‖ℋ) be a dense, imbedded subspace. For a ∈ B, its distance to the ball of ℋ with radius R (denoted as I(a, R)) tends to zero when R tends to infinity. We are interested in the rate of this convergence. This approximation problem arose from the study of learning theory, where B is the L2 space and ℋ is a reproducing kernel Hilbert space. The class of elements having I(a, R) = O(R-r) with r {\textgreater} 0 is an interpolation space of the couple (B, ℋ). The rate of convergence can often be realized by linear operators. In particular, this is the case when ℋ is the range of a compact, symmetric, and strictly positive definite linear operator on a separable Hilbert space B. For the kernel approximation studied in Learning Theory, the rate depends on the regularity of the kernel function. This yields error estimates for the approximation by reproducing kernel Hilbert spaces. When the kernel is smooth, the convergence is slow and a logarithmic convergence rate is presented for analytic kern...},
author = {Smale, Steve and Zhou, Ding-Xuan},
doi = {10.1142/S0219530503000089},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Smale, Zhou - 2003 - Estimating the approximation error in learning theory.pdf:pdf;:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Smale, Zhou - 2003 - Estimating the approximation error in learning theory.pdf:pdf},
journal = {Analysis and Applications},
number = {01},
pages = {17--41},
publisher = {World Scientific Publishing Company},
title = {{Estimating the approximation error in learning theory}},
url = {http://www.worldscientific.com/doi/abs/10.1142/S0219530503000089},
volume = {01},
year = {2003}
}
@unpublished{Kingma2014,
abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
archivePrefix = {arXiv},
arxivId = {1412.6980},
author = {Kingma, Diederik P. and Ba, Jimmy},
eprint = {1412.6980},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Kingma, Ba - 2014 - Adam A method for stochastic optimization.pdf:pdf},
pages = {1--15},
title = {{Adam: A method for stochastic optimization}},
url = {http://arxiv.org/abs/1412.6980},
year = {2014}
}
@article{ruiz:var,
author = {Santos, Andr{\'{e}} A. P. and Nogales, Francisco J. and Ruiz, Esther},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Santos, Nogales, Ruiz - Unknown - Comparing univariate and multivariate models to forecast portfolio value-at-risk.pdf:pdf},
journal = {Preprint},
title = {{Comparing univariate and multivariate models to forecast portfolio value-at-risk}}
}
@article{lintner:capm,
author = {Lintner, John},
journal = {The Review of Economics and Statistics},
number = {1},
pages = {13--37},
title = {{The valuation of risk assets and the selection of risky investments in stock portfolios and capital budgets}},
volume = {47},
year = {1965}
}
@incollection{Stock2006,
abstract = {Historically, time series forecasts of economic variables have used only a handful of predictor variables, while forecasts based on a large number of predictors have been the province of judgmental forecasts and large structural econometric models. The past decade, however, has seen considerable progress in the development of time series fore- casting methods that exploit many predictors, and this chapter surveys these methods. The ﬁrst group of methods considered is forecast combination (forecast pooling), in which a single forecast is produced from a panel of many forecasts. The second group of methods is based on dynamic factor models, in which the comovements among a large number of economic variables are treated as arising from a small number of un- observed sources, or factors. In a dynamic factor model, estimates of the factors (which become increasingly precise as the number of series increases) can be used to forecast individual economic variables. The third group of methods is Bayesian model averag- ing, in which the forecasts from very many models, which differ in their constituent variables, are averaged based on the posterior probability assigned to each model. The chapter also discusses empirical Bayes methods, in which the hyperparameters of the priors are estimated. An empirical illustration applies these different methods to the problem of forecasting the growth rate of the U.S. index of industrial production with 130 predictor variables.},
author = {Stock, James H and Watson, Mark W},
booktitle = {Handbook of Economic Forecasting},
edition = {Elsevier},
editor = {Elliot, Graham and Granger, Clive W.J. and Timmermann, Allan},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Stock, Watson - 2006 - Forecasting with Many Predictors.pdf:pdf},
keywords = {Bayesian,dynamic factor models,empirical Bayes forecasts,forecast combining,model averaging,principal components analysis,shrinkage forecasts},
number = {05},
title = {{Forecasting with Many Predictors}},
volume = {1},
year = {2006}
}
@book{Rudin:Mathematical:Analysis,
author = {Rudin, Walter},
edition = {Third},
isbn = {007054235X},
pages = {342},
publisher = {McGraw-Hill},
title = {{Principles of Mathematical Analysis}},
year = {1976}
}
@article{Carnero2012,
abstract = {GARCH volatilities depend on the unconditional variance, which is a non-linear function of the parameters. Consequently, they can have larger biases than estimated parameters. Using robust methods to estimate both parameters and volatilities is shown to outperform Maximum Likelihood procedures.},
author = {Carnero, M. Angeles and Pe{\~{n}}a, Daniel and Ruiz, Esther},
issn = {01651765},
journal = {Economics Letters},
keywords = {c22},
month = {jan},
number = {1},
pages = {86--90},
title = {{Estimating GARCH volatility in the presence of outliers}},
url = {http://dx.doi.org/10.1016/j.econlet.2011.09.023},
volume = {114},
year = {2012}
}
@incollection{Engle2008a,
address = {Oxford},
author = {Engle, Robert F.},
booktitle = {The Methodology and Practice of Econometrics: Papers in Honour of David F Hendry},
editor = {Castle, J. L. and Shephard, N.},
publisher = {Oxford University Press},
title = {{High dimensional dynamic correlations}},
year = {2008}
}
@unpublished{SDfactor2016,
author = {Boswijk, Peter and Liu, Yang},
title = {{Score-driven variance-factor models}},
year = {2016}
}
@article{Audrino2016,
author = {Audrino, F. and Knaus, S.D.},
journal = {Econometric Reviews},
number = {8-10},
pages = {1485--1521},
title = {{Lassoing the HAR model: A model selection perspective on realized volatility dynamics}},
volume = {35},
year = {2016}
}
@article{Theodorou2010,
author = {Theodorou, Evangelos and Buchli, Jonas and Schaal, Stefan},
journal = {Journal of Machine Learning Research},
pages = {3137--3181},
title = {{A generalized path integral control approach to reinforcement learning}},
volume = {11},
year = {2010}
}
@article{Ibanez-Soria2019,
author = {Ib{\'{a}}{\~{n}}ez-Soria, David and Soria-Frisch, Aureli and Garcia-Ojalvo, Jordi and Ruffini, Giulio},
journal = {PLOS ONE},
title = {{Characterization of the non-stationary nature of steady-state visual evoked potentials using echo state networks}},
year = {2019}
}
@article{Maass2000,
abstract = {Experimental data show that biological synapses behave quite differently from the symbolic synapses in all common artificial neural network models. Biological synapses are dynamic; their “weight” changes on a short timescale by several hundred percent in dependence of the past input to the synapse. In this article we address the question how this inherent synaptic dynamics (which should not be confused with long term learning) affects the computational power of a neural network. In particular, we analyze computations on temporal and spatiotemporal patterns, and we give a complete mathematical characterization of all filters that can be approximated by feedforward neural networks with dynamic synapses. It turns out that even with just a single hidden layer, such networks can approximate a very rich class of nonlinear filters: all filters that can be characterized by Volterra series. This result is robust with regard to various changes in the model for synaptic dynamics. Our characterization result provides...},
author = {Maass, Wolfgang and Sontag, Eduardo D.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Maass, Sontag - 2000 - Neural Systems as Nonlinear Filters.pdf:pdf},
issn = {0899-7667},
journal = {Neural Computation},
language = {en},
month = {aug},
number = {8},
pages = {1743--1772},
publisher = {MIT Press 238 Main St., Suite 500, Cambridge, MA 02142-1046 USA journals-info@mit.edu},
title = {{Neural Systems as Nonlinear Filters}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/089976600300015123},
volume = {12},
year = {2000}
}
@inproceedings{systemsTheory:udine,
author = {Marchesini, G and Mitter, S. K.},
booktitle = {Mathematical Systems Theory. Proceedings of the International Symposium Udine, Italy, June 16-27,1975},
doi = {10.1007/978-3-642-51576-7},
editor = {Marchesini, G and Mitter, S. K.},
isbn = {9783540115533},
publisher = {Springer-Verlag, New York},
title = {{Mathematical Systems Theory}},
volume = {131},
year = {1976}
}
@article{Manjunath:Jaeger2,
abstract = {We provide substantial simplifications in the understanding of qualitative dynamics of random difference equations (RDEs) by constructing closed relations using their typical instantiations. We con...},
author = {Manjunath, G. and Jaeger, H.},
doi = {10.1137/120868815},
journal = {SIAM Journal on Mathematical Analysis},
month = {jan},
number = {1},
pages = {459--483},
publisher = {Society for Industrial and Applied Mathematics},
title = {{The dynamics of random difference equations is remodeled by closed relations}},
volume = {46},
year = {2014}
}
@article{Subasi2005b,
author = {Subasi, Abdulhamit and Ercelebi, Ergun},
doi = {10.1016/j.cmpb.2004.10.009},
journal = {Computer methods and programs in biomedicine},
pages = {87--99},
title = {{Classification of EEG signals using neural network and logistic regression}},
volume = {78},
year = {2005}
}
@article{pascanu:rnn,
abstract = {In this paper, we explore different ways to extend a recurrent neural network (RNN) to a $\backslash$textit{\{}deep{\}} RNN. We start by arguing that the concept of depth in an RNN is not as clear as it is in feedforward neural networks. By carefully analyzing and understanding the architecture of an RNN, however, we find three points of an RNN which may be made deeper; (1) input-to-hidden function, (2) hidden-to-hidden transition and (3) hidden-to-output function. Based on this observation, we propose two novel architectures of a deep RNN which are orthogonal to an earlier attempt of stacking multiple recurrent layers to build a deep RNN (Schmidhuber, 1992; El Hihi and Bengio, 1996). We provide an alternative interpretation of these deep RNNs using a novel framework based on neural operators. The proposed deep RNNs are empirically evaluated on the tasks of polyphonic music prediction and language modeling. The experimental result supports our claim that the proposed deep RNNs benefit from the depth and outperform the conventional, shallow RNNs.},
archivePrefix = {arXiv},
arxivId = {1312.6026},
author = {Pascanu, Razvan and Gulcehre, Caglar and Cho, Kyunghyun and Bengio, Yoshua},
eprint = {1312.6026},
journal = {arXiv},
month = {dec},
title = {{How to construct deep recurrent neural networks}},
url = {http://arxiv.org/abs/1312.6026},
year = {2013}
}
@article{Jalalvand2015,
author = {Jalalvand, Azarakhsh and Demuynck, Kris and {De Neve}, Wesley and {Van de Walle}, Rik and Martens, Jean-Pierre},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Jalalvand et al. - 2015 - Design of reservoir computing systems for noise-robust speech and handwriting recognition.pdf:pdf},
journal = {28th Conference on Graphics, Patterns and Images (accepted in the Workshop of Theses and Dissertations (WTD)) Proceedingsaccepted in the Workshop of Theses and Dissertations (WTD)) Proceedings},
keywords = {Reservoir Computing,Technology and Engineering,artificial neural networks,computing networks,image processing,noise robustness,speech processing},
number = {2},
title = {{Design of reservoir computing systems for noise-robust speech and handwriting recognition}},
year = {2015}
}
@article{Julier2000,
author = {Julier, S.J. and Uhlmann, J.K. and Durrant-Whyte, H. F.},
journal = {IEEE Transactions on Automatic Control},
number = {3},
pages = {477--482},
title = {{A new method for the nonlinear transformation of means and covariances in filters and estimators}},
volume = {45},
year = {2000}
}
@book{bilinearTS,
author = {{Subba Rao}, T. and Gabr, M.M.},
publisher = {Springer-Verlag},
title = {{An Introduction to Bispectral Analysis and Bilinear Time Series Models}},
year = {1984}
}
@article{Vivian2012,
abstract = {Volatility is a key determinant of derivative prices and optimal hedge ratios. This paper examines whether there are structural breaks in commodity spot return volatility using an iterative cumulative sum of squares procedure and then uses GARCH (1,1) to model volatility during each regime. The main empirical finding is the very limited evidence of commodity volatility breaks during the recent financial crisis. This suggests commodity return volatility was not exceptionally high during the recent financial crisis compared to the 1985–2010 sample period as a whole. For many commodities there are multiple idiosyncratic breaks in volatility; this suggests commodity specific supply or demand factors are important determinants of volatility. The empirical results overall are consistent with the view that commodities are too diverse to be considered as an asset class. Finally, we find commodity volatility persistence remains very high for many commodity returns even after structural breaks are accounted for.},
author = {Vivian, Andrew and Wohar, Mark E.},
issn = {10424431},
journal = {Journal of International Financial Markets, Institutions and Money},
keywords = {c12,c32,g01,g10},
month = {apr},
number = {2},
pages = {395--422},
title = {{Commodity volatility breaks}},
url = {http://dx.doi.org/10.1016/j.intfin.2011.12.003},
volume = {22},
year = {2012}
}
@misc{iht,
keywords = {iht},
title = {iht.univ.kiev.ua},
url = {http://iht.univ.kiev.ua/en/}
}
@misc{Owyang2009,
abstract = {Previous studies have found that the term spread has signi{\ldots}cant information content for forecasting recessions. These studies typically use probit or logit models to assess the probability of recession at various horizons. Most of these models use monthly averages of interest rates, potentially discarding important information about the timing of changes in the yield curve. In this paper, we exploit this timing information by implementing a mixed sampling probit, a binary variable extension of the MIDAS model suggested by Ghysels, Santa Clara, and Valkanov (2004).},
author = {Owyang, Michael T.},
booktitle = {Burns},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Owyang - 2009 - Forecasting Recessions Using the Mixed Frequency Probit.pdf:pdf},
keywords = {business cycle,midas,term spread},
number = {2004},
title = {{Forecasting Recessions Using the Mixed Frequency Probit}},
year = {2009}
}
@book{Kalajdzievski:topology,
author = {Kalajdzievski, Sasho},
publisher = {CRC Press},
title = {{An Illustrated Introduction to Topology and Homotopy}},
year = {2015}
}
@article{Kohlhoff2014,
annote = {Article},
author = {Kohlhoff, Kai J. and Shukla, Diwakar and Lawrenz, Morgan and Bowman, Gregory R. and Konerding, David E. and Belov, Dan and Altman, Russ B. and Pande, Vijay S.},
issn = {1755-4330},
journal = {Nature Chemistry},
month = {jan},
number = {1},
pages = {15--21},
publisher = {Nature Publishing Group},
title = {{Cloud-based simulations on Google Exacycle reveal ligand modulation of GPCR activation pathways}},
url = {http://dx.doi.org/10.1038/nchem.1821},
volume = {6},
year = {2014}
}
@article{Astrom1980,
abstract = {The basic ideas behind the parameter estimation methods are discussed in a general setting. The application to estimation or parameters in dynamical systems is treated in detail using the prototype problem of estimating parameters in a continuous time system using discrete time measurements. Computational aspects are discussed. Theoretical results in consistency, asymptotic normality and efficiency are covered. Model validation and selection of model structures are discussed. An example is given which illustrates some properties of the methods and shows the usefulness of interactive computing. Additional examples illustrate what happens when the data has different artefacts.},
author = {{\AA}str{\"{o}}m, K. J.},
doi = {10.1016/0005-1098(80)90078-3},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/{\AA}str{\"{o}}m - 1980 - Maximum likelihood and prediction error methods.pdf:pdf},
issn = {00051098},
journal = {Automatica},
keywords = {computer applications,computer-aided design,continuous time systems,identification,least squares approximations,linear systems,modelling,nonlinear systems,parameter estimation,sampled data systems,stochastic systems},
month = {sep},
number = {5},
pages = {551--574},
title = {{Maximum likelihood and prediction error methods}},
url = {http://dx.doi.org/10.1016/0005-1098(80)90078-3},
volume = {16},
year = {1980}
}
@inproceedings{Roch16,
address = {Working paper},
author = {Roch, Alexandre F.},
booktitle = {SSRN Electronic Journal},
doi = {10.2139/ssrn.2730892},
title = {{Asymptotic asset pricing and bubbles in discrete time}},
url = {http://www.ssrn.com/abstract=2730892},
year = {2016}
}
@article{FrankeNN,
abstract = {Knowledge about the distribution of a statistical estimator is important for various purposes, such as the construction of confidence intervals for model parameters or the determination of critical values of tests. A widely used method to estimate this distribution is the so-called bootstrap, which is based on an imitation of the probabilistic structure of the data-generating process on the basis of the information provided by a given set of random observations. In this article we investigate this classical method in the context of artificial neural networks used for estimating a mapping from input to output space. We establish consistency results for bootstrap estimates of the distribution of parameter estimates.},
author = {Franke, J{\"{u}}rgen and Neumann, Michael H.},
doi = {10.1162/089976600300015204},
issn = {0899-7667},
journal = {Neural Computation},
month = {aug},
number = {8},
pages = {1929--1949},
publisher = {MIT Press 238 Main St., Suite 500, Cambridge, MA 02142-1046 USA journals-info@mit.edu},
title = {{Bootstrapping neural networks}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/089976600300015204},
volume = {12},
year = {2000}
}
@article{GO13,
author = {Grigoryeva, Lyudmila and Ortega, Juan-Pablo},
journal = {Preprint},
title = {{Singular ridge regression with homoscedastic residuals: generalization error with estimated parameters}},
year = {2016}
}
@book{abraham:robbin,
address = {Inc},
author = {Abraham, R and Robbin, J},
publisher = {W. A. Benjamin},
title = {{Transversal Mappings and Flows}},
year = {1967}
}
@article{charles2014short,
author = {Charles, A and Yap, H and Rozell, C},
journal = {Neural Computation},
title = {{Short term network memory capacity via the restricted isometry property}},
volume = {26},
year = {2014}
}
@article{bollt2021explaining,
author = {Bollt, Erik},
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
number = {1},
pages = {13108},
publisher = {AIP Publishing LLC},
title = {{On explaining the surprising success of reservoir computing forecaster of chaos? The universal machine learning dynamical system with contrast to VAR and DMD}},
volume = {31},
year = {2021}
}
@inproceedings{Chen2019a,
author = {Chen, Dexiong and Jacob, Laurent and Mairal, Julien},
booktitle = {NeurIPS},
title = {{Recurrent kernel networks}},
year = {2019}
}
@article{Sontag1979,
author = {Sontag, E.},
doi = {10.1109/TCS.1979.1084646},
issn = {0098-4094},
journal = {IEEE Transactions on Circuits and Systems},
month = {may},
number = {5},
pages = {342--356},
title = {{Realization theory of discrete-time nonlinear systems: Part I-The bounded case}},
url = {http://ieeexplore.ieee.org/document/1084646/},
volume = {26},
year = {1979}
}
@article{lazaro:ortega3,
author = {L{\'{a}}zaro-Cam{\'{i}}, Andreu and Ortega, Juan-Pablo},
journal = {Journal of Geometric Mechanics},
number = {3},
pages = {295--315},
title = {{The stochastic Hamilton-Jacobi equation}},
volume = {1},
year = {2009}
}
@unpublished{Bachouch2020,
author = {Bachouch, Achref and Hur{\'{e}}, C{\^{o}}me and Langren{\'{e}}, Nicolas and Pham, Huyen},
title = {{Deep neural networks algorithms for stochastic control problems on finite horizon: numerical applications}},
year = {2020}
}
@article{Brownlees2011,
abstract = {Within models for nonnegative time series, it is common to encounter deterministic components (trends, seasonalities) which can be specified in a flexible form. This work proposes the use of shrinkage type estimation for the parameters of such components. The amount of smoothing to be imposed on the estimates can be chosen using different methodologies: Cross-Validation for dependent data or the recently proposed Focused Information Criterion. We illustrate such a methodology using a semiparametric autoregressive conditional duration model that decomposes the conditional expectations of durations into their dynamic (parametric) and diurnal (flexible) components. We use a shrinkage estimator that jointly estimates the parameters of the two components and controls the smoothness of the estimated flexible component. The results show that, from the forecasting perspective, an appropriate shrinkage strategy can significantly improve on the baseline maximum likelihood estimation.},
author = {Brownlees, Christian T. and Gallo, Giampiero M.},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {acd,cv,fic,forecasting,mem,shrinkage estimation},
month = {apr},
number = {2},
pages = {365--378},
title = {{Shrinkage estimation of semiparametric multiplicative error models}},
url = {http://dx.doi.org/10.1016/j.ijforecast.2010.04.005},
volume = {27},
year = {2011}
}
@book{Billingsley:book,
abstract = {Probability and Measure offers advanced students, scientists, and engineers an integrated introduction to measure theory and probability. Retaining the unique approach of the previous editions, this text interweaves material on probability and measure, so that probability problems generate an interest in measure theory and measure theory is then developed and applied to probability. Probability and Measure provides thorough coverage of probability, measure, integration, random variables and expected values, convergence of distributions, derivatives and conditional probability, and stochastic processes.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Billingsley, Patrick},
doi = {10.1016/0167-9473(95)90197-3},
edition = {Anniversar},
eprint = {arXiv:1011.1669v3},
isbn = {0471804789},
issn = {01679473},
pages = {636},
pmid = {25246403},
publisher = {Wiley},
title = {{Probability and Measure}},
year = {2012}
}
@misc{Rigollet2015,
author = {Rigollet, Philippe},
title = {{High Dimensional Statistics: Lecture Notes}},
url = {http://www-math.mit.edu/{~}rigollet/PDFs/RigNotes15.pdf},
year = {2015}
}
@article{BCO:note:2015,
abstract = {In this paper we study a conditional version of the Wang transform in the context of discrete GARCH models and their diffusion limits. Our first contribution shows that the conditional Wang transform and Duans generalized local risk-neutral valuation relationship based on equilibrium considerations, lead to the same GARCH option pricing model. We derive the weak limit of an asymmetric GARCH model risk-neutralized via Wang's transform. The connection with stochastic volatility limits constructed using other standard pricing kernels, such as the conditional Esscher transform or the extended Girsanov principle, is further investigated by comparing the corresponding market prices of variance risk.},
author = {Badescu, Alexandru and Cui, Zhenyu and Ortega, Juan-Pablo},
doi = {10.1016/j.frl.2016.07.011},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Badescu, Cui, Ortega - 2016 - A note on the Wang transform for stochastic volatility pricing models.pdf:pdf},
issn = {15446123},
journal = {Finance Research Letters},
pages = {189--196},
title = {{A note on the Wang transform for stochastic volatility pricing models}},
volume = {19},
year = {2016}
}
@article{lu:bassett:2020,
abstract = {Regardless of the marked differences between biological and artificial neural systems, one fundamental similarity is that they are essentially dynamical systems that can learn to imitate other dynamical systems whose governing equations are unknown. The brain is able to learn the dynamic nature of the physical world via experience; analogously, artificial neural systems such as reservoir computing networks (RCNs) can learn the long-term behavior of complex dynamical systems from data. Recent work has shown that the mechanism of such learning in RCNs is invertible generalized synchronization (IGS). Yet, whether IGS is also the mechanism of learning in biological systems remains unclear. To shed light on this question, we draw inspiration from features of the human brain to propose a general and biologically feasible learning framework that utilizes IGS. To evaluate the framework's relevance, we construct several distinct neural network models as instantiations of the proposed framework. Regardless of their particularities, these neural network models can consistently learn to imitate other dynamical processes with a biologically feasible adaptation rule that modulates the strength of synapses. Further, we observe and theoretically explain the spontaneous emergence of four distinct phenomena reminiscent of cognitive functions: (i) learning multiple dynamics; (ii) switching among the imitations of multiple dynamical systems, either spontaneously or driven by external cues; (iii) filling-in missing variables from incomplete observations; and (iv) deciphering superimposed input from different dynamical systems. Collectively, our findings support the notion that biological neural networks can learn the dynamic nature of their environment through the mechanism of IGS.},
author = {Lu, Zhixin and Bassett, Danielle S.},
doi = {10.1063/5.0004344},
issn = {10897682},
journal = {Chaos},
number = {063133},
pmid = {32611103},
publisher = {AIP Publishing LLC},
title = {{Invertible generalized synchronization: A putative mechanism for implicit learning in neural systems}},
volume = {30},
year = {2020}
}
@article{Estrella1997,
author = {Estrella, Arturo and Mishkin, Frederic},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Estrella, Mishkin - 1997 - The predictive power of the term structure of interest rates in Europe and the United States Implications for.pdf:pdf},
issn = {00142921},
journal = {European Economic Review},
month = {jul},
number = {7},
pages = {1375--1401},
title = {{The predictive power of the term structure of interest rates in Europe and the United States: Implications for the European Central Bank}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0014292196000505},
volume = {41},
year = {1997}
}
@article{Chris04,
author = {Christoffersen, Peter and Jacobs, Kris},
journal = {Management Science},
pages = {1204--1221},
title = {{Which GARCH model for option valuation?}},
volume = {50},
year = {2004}
}
@book{Draguna2012,
author = {Draguna, Vrabie and Vamvoudakis, Kyriakos and Lewis, Frank},
pages = {400},
publisher = {IET Digital Library},
title = {{Optimal Adaptive Control and Differential Games by Reinforcement Learning Principles}},
year = {2012}
}
@article{jaeger2,
author = {Jaeger, Herbert and Luko{\v{s}}evi{\v{c}}ius, Mantas and Popovici, Dan and Siewert, Udo},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Jaeger et al. - 2007 - Optimization and applications of echo state networks with leaky-integrator neurons.pdf:pdf},
journal = {Neural Networks},
number = {3},
pages = {335--352},
title = {{Optimization and applications of echo state networks with leaky-integrator neurons}},
volume = {20},
year = {2007}
}
@inproceedings{Hanson2019,
author = {Hanson, Joshua and Raginsky, Maxim},
booktitle = {NeurIPS},
title = {{Universal approximation of input-output maps by temporal convolutional nets}},
year = {2019}
}
@phdthesis{Zub2005,
author = {Zub, Stanislav},
school = {V.M. Glushkov Institute of Cybernetics of National Academy of Sciences of Ukraine},
title = {{Influence of superconductive elements topology on the stability of a rigid body equilibrium (in Ukrainian)}},
year = {2005}
}
@article{FZtestStatGARCH,
author = {Francq, Christian and Zako{\"{i}}an, Jean-Michel},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Francq, Zako{\"{i}}an - 2012 - Strict stationarity testing and estimation of explosive and stationary generalized autoregressive conditional.pdf:pdf},
journal = {Econometrica},
number = {2},
pages = {821--861},
title = {{Strict stationarity testing and estimation of explosive and stationary generalized autoregressive conditional heteroscedasticity models}},
volume = {80},
year = {2012}
}
@article{sandberg:bibo,
author = {Sandberg, Irwin W},
journal = {Multidimensional Systems and Signal Processing},
keywords = {bibo stability,discrete-space systems,discrete-time systems,linear systems},
pages = {425--428},
title = {{A note on BIBO stability of linear discrete-space systems}},
volume = {10},
year = {1999}
}
@article{Coleman1968,
author = {Coleman, Bernard D. and Mizel, Victor J.},
journal = {Archive for Rational Mechanics and Analysis},
month = {jan},
number = {1},
pages = {18--31},
publisher = {Springer-Verlag},
title = {{On the general theory of fading memory}},
volume = {29},
year = {1968}
}
@unpublished{Gonon2020,
author = {Gonon, L. and Grigoryeva, L. and Kukharenko, O. and Ortega, J.-P.},
title = {{Forecasting realized variances with reservoir computing}},
year = {2021}
}
@article{glenetal:product:distributions,
author = {Glen, Andrew G and Leemis, Lawrence M and Drew, John H},
doi = {10.1016/S0167-9473(02)00234-7},
issn = {0167-9473},
journal = {Comput. Statist. Data Anal.},
number = {3},
pages = {451--464},
title = {{Computing the distribution of the product of two continuous random variables}},
url = {http://dx.doi.org/10.1016/S0167-9473(02)00234-7},
volume = {44},
year = {2004}
}
@article{Busing2010,
abstract = {Reservoir computing (RC) systems are powerful models for online computations on input sequences. They consist of a memoryless readout neuron that is trained on top of a randomly connected recurrent neural network. RC systems are commonly used in two flavors: with analog or binary (spiking) neurons in the recurrent circuits. Previous work indicated a fundamental difference in the behavior of these two implementations of the RC idea. The performance of an RC system built from binary neurons seems to depend strongly on the network connectivity structure. In networks of analog neurons, such clear dependency has not been observed. In this letter, we address this apparent dichotomy by investigating the influence of the network connectivity (parameterized by the neuron in-degree) on a family of network models that interpolates between analog and binary networks. Our analyses are based on a novel estimation of the Lyapunov exponent of the network dynamics with the help of branching process theory, rank measures that estimate the kernel quality and generalization capabilities of recurrent networks, and a novel mean field predictor for computational performance. These analyses reveal that the phase transition between ordered and chaotic network behavior of binary circuits qualitatively differs from the one in analog circuits, leading to differences in the integration of information over short and long timescales. This explains the decreased computational performance observed in binary circuits that are densely connected. The mean field predictor is also used to bound the memory function of recurrent circuits of binary neurons.},
author = {B{\"{u}}sing, Lars and Schrauwen, Benjamin and Legenstein, Robert},
issn = {1530-888X},
journal = {Neural computation},
keywords = {Algorithms,Animals,Computer Simulation,Memory,Neural Networks (Computer),Neurons,Time Factors},
language = {en},
month = {may},
number = {5},
pages = {1272--311},
publisher = {MIT Press 238 Main St., Suite 500, Cambridge, MA 02142-1046, USA email: journals-info@mit.edu},
title = {{Connectivity, dynamics, and memory in reservoir computing with binary and analog neurons.}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/neco.2009.01-09-947{\#}.VUiMY1p16ao},
volume = {22},
year = {2010}
}
@article{Pereda1999,
abstract = {Interhemispheric differences in the EEG of nine healthy right-handed human subjects (C3 vs. C4 derivations) were investigated during resting wake with closed eyes (CE) and sleep stages I, II, III, IV and REM. The harmonic power spectral density within the EEG main spectral bands, the fractal (Dr) and the correlation (D2) dimension as well as the largest Lyapunov exponent (lambda1) of both hemispheres were compared. In addition, the relationships between non-linear and spectral measures were analyzed. Dr, D2, lambda1 and the power in alpha band exhibited interhemispheric differences during waking, the values from the right hemisphere (RH) being higher than those of the left (LH) except for lambda1. During slow wave sleep (SWS), non-linear parameters detected opposite EEG asymmetries (D2 in stage III and lambda1 in stage IV) to those found in the other behavioural stages. In addition, both D2 and lambda1 were correlated (negatively) with the power in the delta band, but lambda1 was also correlated (positively) with the power in the alpha and beta bands. In conclusion, RH appears to be more complex though more predictable than the LH during CE and sleep stages I and II, these characteristics changing to the LH during SWS.},
author = {Pereda, E. and Gamundi, A. and Nicolau, M. C. and Rial, R. and Gonz{\'{a}}lez, J.},
issn = {0304-3940},
journal = {Neuroscience letters},
keywords = {Alpha Rhythm,Beta Rhythm,Brain,Brain: physiology,Delta Rhythm,Electroencephalography,Functional Laterality,Humans,REM,REM: physiology,Reproducibility of Results,Sleep,Sleep Stages,Sleep Stages: physiology,Theta Rhythm,Wakefulness,Wakefulness: physiology},
month = {mar},
number = {1},
pages = {37--40},
pmid = {10218905},
title = {{Interhemispheric differences in awake and sleep human EEG: a comparison between non-linear and spectral measures}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10218905},
volume = {263},
year = {1999}
}
@book{smola:ML,
author = {Smola, Alex and Vishwanathan, S.V.N.},
pages = {226},
publisher = {Cambridge University Press},
title = {{Introduction to Machine Learning}},
year = {2008}
}
@article{cushman:kemppainen:sniatycki,
author = {Cushman, R. and Kemppainen, D. and Sniatycki, J. and Bates, L.},
journal = {Rep. Math. Phys.},
pages = {275--286},
title = {{Geometry of nonholonomic constraints}},
volume = {36},
year = {1995}
}
@book{RCLectures,
author = {Gonon, Lukas and Grigoryeva, Lyudmila and Ortega, Juan-Pablo},
publisher = {European Mathematical Society},
title = {{Lectures on the Learning of Dynamic Processes (In Preparation)}},
year = {2019}
}
@article{Zub2014,
author = {Zub, Stanislav},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Zub - 2014 - Stable orbital motion of magnetic dipole in the field of permanent magnets.pdf:pdf},
journal = {Physica D},
pages = {67--73},
title = {{Stable orbital motion of magnetic dipole in the field of permanent magnets}},
volume = {275},
year = {2014}
}
@article{cirelli:pizzocchero:1990,
author = {Cirelli, R. and Pizzocchero, L.},
journal = {Nonlinearity},
pages = {1057--1080},
title = {{On the integrability of quantum mechanics as an infinite dimensional Hamiltonian system}},
volume = {3},
year = {1990}
}
@article{Liang2008,
abstract = {We report a low-temperature process for covalent bonding of thermal SiO2 to plasma-enhanced chemical vapor deposited (PECVD) SiO2 for Si-compound semiconductor integration. A record-thin interfacial oxide layer of 60{\^{A}} nm demonstrates sufficient capability for gas byproduct diffusion and absorption, leading to a high surface energy of 2.65{\^{A}} J/m2 after a 2-h 300{\{}$\backslash$textdegree{\}}C anneal. O2 plasma treatment and surface chemistry optimization in dilute hydrofluoric (HF) solution and NH4OH vapor efficiently suppress the small-size interfacial void density down to 2{\^{A}} voids/cm2, dramatically increasing the wafer-bonded device yield. Bonding-induced strain, as determined by x-ray diffraction measurements, is negligible. The demonstration of a 50{\^{A}} mm InP epitaxial layer transferred to a silicon-on-insulator (SOI) substrate shows the promise of the method for wafer-scale applications.},
author = {Liang, Di and Fang, Alexander W and Park, Hyundai and Reynolds, Tom E and Warner, Keith and Oakley, Douglas C and Bowers, John E},
doi = {10.1007/s11664-008-0489-1},
issn = {1543-186X},
journal = {Journal of Electronic Materials},
number = {10},
pages = {1552--1559},
title = {{Low-Temperature, Strong SiO2-SiO2 Covalent Wafer Bonding for III--V Compound Semiconductors-to-Silicon Photonic Integrated Circuits}},
url = {http://dx.doi.org/10.1007/s11664-008-0489-1},
volume = {37},
year = {2008}
}
@book{Marsden1994,
address = {New York},
author = {Marsden, Jerrold E. and Ratiu, Tudor S.},
edition = {Second},
pages = {500},
publisher = {Springer-Verlag},
title = {{Introduction to mechanics and symmetry}},
year = {1999}
}
@article{Yamamoto1981,
author = {Yamamoto, Taku},
journal = {Biometrika},
pages = {485--492},
title = {{Predictions of multivariate autoregressive-moving average models}},
volume = {65},
year = {1981}
}
@article{delcastillo:lee:1,
author = {del Castillo, Joan and Lee, Youngjo},
issn = {1471-082X},
journal = {Stat. Model.},
number = {3},
pages = {263--283},
title = {{GLM-methods for volatility models}},
volume = {8},
year = {2008}
}
@article{hafner2008,
author = {Hafner, C. M.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Hafner - 2008 - Temporal aggregation of multivariate GARCH processes.pdf:pdf},
journal = {Journal of Econometrics},
keywords = {c22,causality in variance,jel classification,multivariate garch,realized volatility,temporal aggregation,volatility forecasts},
number = {1},
pages = {26--54},
title = {{Temporal aggregation of multivariate GARCH processes}},
url = {http://www.sciencedirect.com/science/article/pii/S0304407607001583},
volume = {142},
year = {2008}
}
@article{Hubalek2006,
author = {Hubalek, F. and Kallsen, J. and Krawczyk, L.},
journal = {Annals of Applied Probability},
number = {2},
pages = {853--885},
title = {{Variance-optimal hedging for processes with stationary independent increments}},
volume = {16},
year = {2006}
}
@inproceedings{Graves2013,
author = {Graves, Alex and Mohamed, Abdel-Rahman and Hinton, Geoffrey},
booktitle = {2013 IEEE International Conference on Acoustics, Speech and Signal Processing},
doi = {10.1109/ICASSP.2013.6638947},
isbn = {978-1-4799-0356-6},
month = {may},
pages = {6645--6649},
publisher = {IEEE},
title = {{Speech recognition with deep recurrent neural networks}},
url = {http://ieeexplore.ieee.org/document/6638947/},
year = {2013}
}
@book{field,
author = {Field, M. J.},
booktitle = {Memoirs of the American Math. Soc.},
publisher = {Memoirs of the American Math. Soc. 120},
title = {{Symmetry breaking for compact Lie groups}},
volume = {120},
year = {1996}
}
@phdthesis{Hein2005,
author = {Hein, Matthias},
title = {{Geometrical aspects of statistical learning theory}},
year = {2005}
}
@book{Comets:Meyre,
address = {Paris},
author = {Comets, Francis and Meyre, Thierry},
publisher = {Dunod},
title = {{Calcul Stochastique et Mod{\`{e}}les de Diffusions}},
year = {2006}
}
@book{Cohen1995,
author = {Cohen, Leon},
publisher = {Prentice Hall},
title = {{Time-Frequency Analysis}},
year = {1995}
}
@techreport{Pesaran2004,
author = {Pesaran, M Hashem and Timmermann, Allan},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Pesaran, Timmermann - 2004 - Real Time Econometrics.pdf:pdf},
institution = {IZA},
keywords = {automated model selection,data snooping,recursive/sequential modelling,specification search},
number = {1108},
series = {Discussion Paper},
title = {{Real Time Econometrics}},
year = {2004}
}
@unpublished{Bianchi2018,
author = {Bianchi, Filippo Maria and Scardapane, Simone and L{\o}kse, Sigurd and Jenssen, Robert},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Bianchi et al. - 2018 - Reservoir computing approaches for representation and classi cation of multivariate time series.pdf:pdf},
title = {{Reservoir computing approaches for representation and classi cation of multivariate time series}},
year = {2018}
}
@article{recht:fazel:parrilo,
author = {Recht, B. and Fazel, M. and Parrilo, P.},
journal = {Preprint},
title = {{Guaranteed Minimum-Rank Solutions of Linear Matrix Equations via Nuclear Norm Minimization}},
year = {2009}
}
@article{tutorial:bayesian:optimization,
abstract = {We present a tutorial on Bayesian optimization, a method of finding the maximum of expensive cost functions. Bayesian optimization employs the Bayesian technique of setting a prior over the objective function and combining it with evidence to get a posterior function. This permits a utility-based selection of the next observation to make on the objective function, which must take into account both exploration (sampling from areas of high uncertainty) and exploitation (sampling areas likely to offer improvement over the current best observation). We also present two detailed extensions of Bayesian optimization, with experiments---active user modelling with preferences, and hierarchical reinforcement learning---and a discussion of the pros and cons of Bayesian optimization based on our experiences.},
archivePrefix = {arXiv},
arxivId = {1012.2599},
author = {Brochu, Eric and Cora, Vlad M and {Nandode Freitas}},
doi = {1012.2599},
eprint = {1012.2599},
journal = {arXiv},
number = {arXiv:1012.2599},
pages = {49},
title = {{A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchical Reinforcement Learning}},
year = {2010}
}
@article{MontaldiOlmos2011,
abstract = {We consider Hamiltonian systems with symmetry, and relative equilibria with isotropy subgroup of positive dimension. The stability of such relative equilibria has been studied by Ortega and Ratiu ( 1999 Nonlinearity [/0951-7715/12/3/315] 12 693–720 ) and by Lerman and Singer ( 1998 Nonlinearity [/0951-7715/11/6/012] 11 1637–49 ). In both papers the authors give sufficient conditions for stability which require first determining a splitting of a subalgebra of {\#}{\#}IMG{\#}{\#} [http://ej.iop.org/images/0951-7715/24/10/007/non383555in001.gif] {\{}$\backslash$mathfrak{\{}g{\}}{\}} , with different splittings giving different criteria. In this note we remove this splitting construction and so provide a more general and more straightforward criterion for stability. The result is also extended to apply to systems whose momentum maps are not coadjoint equivariant.},
author = {Montaldi, James and Rodr{\'{i}}guez-Olmos, Miguel},
issn = {0951-7715},
journal = {Nonlinearity},
month = {oct},
number = {10},
pages = {2777--2783},
title = {{On the stability of Hamiltonian relative equilibria with non-trivial isotropy}},
volume = {24},
year = {2011}
}
@article{osborne1,
author = {Osborne, M R and Presnell, B and Turlach, B A},
journal = {J. Comput. Graphical Stat.},
pages = {319--337},
title = {{On the {\{}L{\}}asso and its dual}},
volume = {9},
year = {2000}
}
@article{duan:ems1,
author = {Duan, Jin-Chuan and Simonato, Jean-Guy},
journal = {Management Science},
number = {9},
pages = {1218--1233},
title = {{Empirical martingale simulation of asset prices}},
volume = {44},
year = {1998}
}
@article{boccaletti:reports:2002,
author = {Boccaletti, S. and Kurths, J. and Osipov, G. and Valladares, D. L. and Zhou, C. S.},
journal = {Physics Reports},
pages = {1--101},
title = {{The synchronization of chaotic systems}},
volume = {366},
year = {2002}
}
@book{kms93,
author = {Kol{\'{a}}r, Ivan and Michor, Peter W and Slov{\'{a}}k, Jan},
publisher = {Springer Science {\&} Business Media},
title = {{Natural Operations in Differential Geometry}},
year = {2013}
}
@article{Alani2010,
author = {Al-ani, Tarik and Trad, D.},
journal = {Intelligent and Biosensors},
pages = {25--66},
title = {{Signal processing and classification approaches for brain-computer interface}},
year = {2010}
}
@article{NonstatARCH2004,
author = {Jensen, S{\"{o}}ren Tolver and Rahbek, Anders},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Jensen, Rahbek - 2004 - Asymptotic normality of the QMLE estimator of ARCH in the nonstationary case.pdf:pdf},
journal = {Econometrica},
number = {2},
pages = {641--646},
title = {{Asymptotic normality of the QMLE estimator of ARCH in the nonstationary case}},
volume = {72},
year = {2004}
}
@article{Zheng2012,
author = {Zheng, Weihua and Schafer, Nicholas P and Davtyan, Aram and Papoian, Garegin A and Wolynes, Peter G},
doi = {10.1073/pnas.1216215109},
journal = {Proceedings of the National Academy of Sciences},
number = {47},
pages = {19244--19249},
title = {{Predictive energy landscapes for protein–protein association}},
url = {http://www.pnas.org/content/109/47/19244.abstract},
volume = {109},
year = {2012}
}
@article{Metcalf1995,
abstract = {Many recent theoretical papers have come under attack for modeling prices as Geometric Brownian Motion. This process can diverge over time, implying that firms facing this price process can earn infinite profits. We explore the significance of this attack and contrast investment under Geometric Brownian Motion with investment assuming mean reversion. While analytically more complex, mean reversion in many cases is a more plausible assumption, allowing for supply responses to increasing prices. We show that cumulative investment is generally unaffected by the use of a mean reversion process rather than Geometric Brownian Motion and provide an explanation for this result.},
author = {Metcalf, Gilbert E. and Hassett, Kevin A.},
issn = {01651889},
journal = {Journal of Economic Dynamics and Control},
keywords = {C6,E2,Investment,Stochastic processes,Uncertainty},
month = {nov},
number = {8},
pages = {1471--1488},
title = {{Investment under alternative return assumptions Comparing random walks and mean reversion}},
url = {http://www.sciencedirect.com/science/article/pii/0165188994008389},
volume = {19},
year = {1995}
}
@article{Marcellino2004,
author = {Marcellino, Massimiliano},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Marcellino - 2004 - Forecasting EMU macroeconomic variables.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {european monetary union,forecasting,instability,non-linear models,non-linearity,time-varying models},
month = {jun},
number = {2},
pages = {359--372},
title = {{Forecasting EMU macroeconomic variables}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0169207003001018},
volume = {20},
year = {2004}
}
@article{peresetsky:2,
author = {Korhonen, Iikka and Peresetsky, Anatoly},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Korhonen, Peresetsky - 2013 - Extracting global stochastic trend from non-synchronous data.pdf:pdf},
institution = {Bank of Finland},
journal = {Bank of Finland, BOFIT Discussion Papers},
title = {{Extracting global stochastic trend from non-synchronous data}},
volume = {15/2013},
year = {2013}
}
@article{blackbox:quanta,
author = {Wolchover, Natalie},
journal = {Quanta Magazine},
title = {{New theory cracks open the black box of deep learning}},
url = {https://www.quantamagazine.org/new-theory-cracks-open-the-black-box-of-deep-learning-20170921/{\#}},
year = {2017}
}
@article{amm,
author = {Arms, J. M. and Marsden, J. E. and Moncrief, V.},
journal = {Comm. Math. Phys.},
pages = {455--478},
title = {{Symmetry and bifurcations of momentum mappings}},
volume = {78},
year = {1975}
}
@article{Shephard1998,
author = {Shephard, Kim S. and Chib, S.},
journal = {Review of Economic Studies},
keywords = {shephard:chib},
mendeley-tags = {shephard:chib},
pages = {361--393},
title = {{Stochastic volatility: likelihood inference and comparison with ARCH models}},
volume = {65},
year = {1998}
}
@phdthesis{Matthews:thesis,
author = {Matthews, Michael B.},
doi = {10.3929/ETHZ-A-000625223},
keywords = {DISCRETE,FADING (TELECOMMUNICATIONS),SCHWUND (NACHRICHTENTECHNIK),SIGNAL PROCESSING (TELECOMMUNICATIONS),SIGNALVERARBEITUNG (NACHRICHTENTECHNIK),TIME CONTROL SYSTEMS (CONTROL SYSTEMS THEORY),ZEITDISKRETE REGELUNGSSYSTEME (THEORIE DER REGELUN},
school = {ETH Z{\"{u}}rich},
title = {{On the Uniform Approximation of Nonlinear Discrete-Time Fading-Memory Systems Using Neural Network Models}},
url = {https://www.research-collection.ethz.ch:443/handle/20.500.11850/140592},
year = {1992}
}
@article{Kilian2008,
abstract = {Large fluctuations in energy prices have been a distinguishing characteristic of the U.S. economy since the 1970s. Turmoil in the Middle East, rising energy prices in the U.S. and evidence of global warming recently have reignited interest in the link between energy prices and economic performance. This paper addresses a number of the key issues in this debate: What are energy price shocks and where do they come from? How responsive is energy demand to changes in energy prices? How do consumers' expenditure patterns evolve in response to energy price shocks? How do energy price shocks affect real output, inflation, stock markets and the balance-of-payments? Why do energy price increases seem to cause recessions, but energy price decreases do not seem to cause expansions? Why has there been a surge in gasoline prices in recent years? Why has this new energy price shock not caused a recession so far? Have the effects of energy price shocks waned since the 1980s and, if so, why? As the paper demonstrates, it is critical to account for the endogeneity of energy prices and to differentiate between the effects of demand and supply shocks in energy markets, when answering these questions.},
author = {Kilian, Lutz},
institution = {CEPR},
journal = {Journal of Economic Literature},
keywords = {Asymmetry,Causality,Channels of transmission,Cr},
month = {nov},
number = {4},
pages = {871--909},
title = {{The economic effects of energy price shocks}},
type = {Discussion Paper},
url = {http://ideas.repec.org/p/cpr/ceprdp/6559.html},
volume = {46},
year = {2008}
}
@article{Chatelle2012,
author = {Chatelle, Camille and Chennu, Srivas and Noirhomme, Quentin and Cruse, Damian and Owen, Adrian M. and Laureys, Steven},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Chatelle et al. - 2012 - Brain–computer interfacing in disorders of consciousness.pdf:pdf},
journal = {Brain Injury},
number = {12},
pages = {1510--1522},
title = {{Brain–computer interfacing in disorders of consciousness}},
volume = {26},
year = {2012}
}
@article{osborne2,
author = {Osborne, M R and Presnell, B and Turlach, B A},
journal = {IMA J. Numer. Anal.},
pages = {389--403},
title = {{A new approach to variable selection in least squares problems}},
volume = {20},
year = {2000}
}
@article{RC10,
author = {Gonon, Lukas and Grigoryeva, Lyudmila and Ortega, Juan-Pablo},
journal = {Journal of Machine Learning Research},
number = {240},
pages = {1--61},
title = {{Risk bounds for reservoir computing}},
volume = {21},
year = {2020}
}
@article{Kozorez1977,
author = {Kozorez, V. V. and Cheborin, O. G.},
journal = {Bull. of the Ac. of Sc. of USSR. Series A (in Russian)},
pages = {80--81},
title = {{On stability of equilibrium in the system of two ideal curent-carrying circuits}},
volume = {1},
year = {1977}
}
@book{lakshmanan2011dynamics,
author = {Lakshmanan, Muthusamy and Senthilkumar, Dharmapuri Vijayan},
publisher = {Springer Science {\&} Business Media},
title = {{Dynamics of Nonlinear Time-Delay Systems}},
year = {2011}
}
@article{Christensen2010,
author = {Christensen, K. and Kinnebrock, S. and Podolskij, M.},
journal = {Journal of Econometrics},
number = {1},
pages = {116--133},
title = {{Pre-averaging estimators of the ex-post covariance matrix in noisy diffusion models with non-synchronous data}},
volume = {159},
year = {2010}
}
@article{Kim2007,
abstract = {This study investigates the effectiveness of a hybrid approach based on the artificial neural networks (ANNs) for time series properties, such as the adaptive time delay neural networks (ATNNs) and the time delay neural networks (TDNNs), with the genetic algorithms (GAs) in detecting temporal patterns for stock market prediction tasks. Since ATNN and TDNN use time-delayed links of the network into a multi-layer feed-forward network, the topology of which grows by on layer at every time step, it has one more estimate of the number of time delays in addition to several control variables of the ANN design. To estimate these many aspects of the ATNN and TDNN design, a general method based on trial and error along with various heuristics or statistical techniques is proposed. However, for the reason that determining the number of time delays or network architectural factors in a stand-alone mode does not guarantee the illuminating improvement of the performance for building the ATNN and TDNN model, we apply GAs to support optimization of the number of time delays and network architectural factors simultaneously for the ATNN and TDNN model. The results show that the accuracy of the integrated approach proposed for this study is higher than that of the standard ATNN, TDNN and the recurrent neural network (RNN).},
author = {Kim, Hyun-jung and Shin, Kyung-shik},
doi = {10.1016/j.asoc.2006.03.004},
issn = {15684946},
journal = {Applied Soft Computing},
number = {2},
pages = {569--576},
title = {{A hybrid approach based on neural networks and genetic algorithms for detecting temporal patterns in stock markets}},
volume = {7},
year = {2007}
}
@article{Eltes2016,
abstract = {Barium titanate (BaTiO3) has become an attractive material to extend the functionalities of the silicon photonics platform because of its large Pockels coefficient of more than 1000 pm/V. BaTiO3 integrated epitaxially on silicon-on-insulator substrates can be structured in passive and electro-optic silicon photonic devices using slot-waveguide geometries, both of which have been demonstrated. However, all devices demonstrated so far suffer from high optical propagation losses of ∼40–600 dB/cm, which limits their performance compared with state-of-the-art silicon photonics devices ({\{}{\textless}{\}}2 dB/cm). Here, we identify the origin of these high propagation losses and demonstrate a path to fabricate low-loss BaTiO3–Si waveguides with propagation losses of only 6 dB/cm. In particular, we identified the thin strontium titanate (SrTiO3) seed layer typically used for the epitaxial deposition of BaTiO3 on silicon as the main source of absorption: When manufacturing slot-waveguide structures, the BaTiO3/SrTiO3 layer stack ...},
author = {Eltes, Felix and Caimi, Daniele and Fallegger, Florian and Sousa, Marilyne and O'Connor, Eamon and Rossell, Marta D and Offrein, Bert and Fompeyrine, Jean and Abel, Stefan},
doi = {10.1021/acsphotonics.6b00350},
issn = {2330-4022},
journal = {ACS Photonics},
keywords = {Pockels effect,barium titanate,hydrogenation,propagation losses,silicon photonics},
pages = {1698},
title = {{Low-Loss BaTiO3 –Si Waveguides for Nonlinear Integrated Photonics}},
url = {http://pubs.acs.org/doi/abs/10.1021/acsphotonics.6b00350},
volume = {3},
year = {2016}
}
@article{Boyd1985,
author = {Boyd, S. and Chua, L.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Boyd, Chua - 1985 - Fading memory and the problem of approximating nonlinear operators with Volterra series.pdf:pdf},
journal = {IEEE Transactions on Circuits and Systems},
number = {11},
pages = {1150--1161},
title = {{Fading memory and the problem of approximating nonlinear operators with Volterra series}},
volume = {32},
year = {1985}
}
@article{marzen:capacity,
abstract = {Recurrent networks are trained to memorize their input better, often in the hopes that such training will increase the ability of the network to predict. We show that networks designed to memorize input can be arbitrarily bad at prediction. We also find, for several types of inputs, that one-node networks optimized for prediction are nearly at upper bounds on predictive capacity given by Wiener filters, and are roughly equivalent in performance to randomly generated five-node networks. Our results suggest that maximizing memory capacity leads to very different networks than maximizing predictive capacity, and that optimizing recurrent weights can decrease reservoir size by half an order of magnitude.},
author = {Marzen, Sarah},
doi = {10.1103/PhysRevE.96.032308},
issn = {24700053},
journal = {Physical Review E},
number = {3},
pages = {1--7},
title = {{Difference between memory and prediction in linear recurrent networks}},
volume = {96},
year = {2017}
}
@article{pos,
annote = {
        From Duplicate 1 ( 
        
          Non-linear stability of singular relative periodic orbits in Hamiltonian systems with symmetry
        
         - Ortega, J.-P.; Ratiu, Tudor S. )
And  Duplicate 2 ( 
        
          A Dirichlet criterion for the stability of periodic and relative periodic orbits in Hamiltonian systems
        
         - Ortega, J.-P.; Ratiu, T. S. )

        
        

        

        

      },
author = {Ortega, Juan-Pablo and Ratiu, Tudor S.},
journal = {Journal of Geometry and Physics},
number = {2},
pages = {160--188},
title = {{Non-linear stability of singular relative periodic orbits in Hamiltonian systems with symmetry}},
volume = {32},
year = {1999}
}
@article{gauthier2021next,
author = {Gauthier, Daniel J and Bollt, Erik and Griffith, Aaron and Barbosa, Wendson A S},
journal = {arXiv preprint arXiv:2106.07688},
title = {{Next Generation Reservoir Computing}},
year = {2021}
}
@unpublished{Steinwart2017,
author = {Steinwart, Ingo},
title = {{Convergence types and rates in generic Karhunen-Lo{\'{e}}ve expansions with applications to sample path properties}},
year = {2017}
}
@article{po,
author = {Ortega, J.-P. and Ratiu, T. S.},
journal = {Journal of Geometry and Physics},
pages = {131--159},
title = {{A Dirichlet criterion for the stability of periodic and relative periodic orbits in Hamiltonian systems}},
volume = {32},
year = {1999}
}
@article{delcastillo:lee:2,
author = {Lim, Johan and Woojoo, Lee and Lee, Youngjo and del Castillo, Joan},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Lim et al. - 2011 - The hierarchical-likelihood approach to autoregressive stochastic volatility models.pdf:pdf},
journal = {Computational Statistics and Data Analysis},
number = {55},
pages = {248--260},
title = {{The hierarchical-likelihood approach to autoregressive stochastic volatility models}},
volume = {55},
year = {2011}
}
@book{Chorro2015,
author = {Chorro, C. and Gu$\backslash$'egan, D. and Ielpo, F.},
publisher = {Springer Berlin Heidelberg},
title = {{A Time Series Approach to Option Pricing: Models, Methods and Empirical Performances}},
year = {2015}
}
@book{hungerford:algebra,
author = {Hungerford, Thomas W.},
doi = {10.1007/978-1-4612-6101-8},
publisher = {Springer New York},
title = {{Algebra}},
year = {1974}
}
@article{Triefenbach2010,
abstract = {Automatic speech recognition has gradually improved over the years, but the reliable recognition of unconstrained speech is still not within reach. In order to achieve a breakthrough, many research groups are now investigating new methodologies that have potential to outperform the Hidden Markov Model technology that is at the core of all present commercial systems. In this paper, it is shown that the recently introduced concept of Reservoir Computing might form the basis of such a methodology. In a limited amount of time, a reservoir system that can recognize the elementary sounds of continuous speech has been built. The system already achieves a state-of-the-art performance, and there is evidence that the margin for further improvements is still significant.},
author = {Triefenbach, Fabian and Jalalvand, Azarakhsh and Schrauwen, Benjamin and Martens, Jean-Pierre},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Triefenbach et al. - 2010 - Phoneme recognition with large hierarchical reservoirs.pdf:pdf},
isbn = {9781617823800},
issn = {1049-5258},
journal = {Advances in Neural Information Processing Systems 23},
pages = {1--9},
title = {{Phoneme recognition with large hierarchical reservoirs}},
url = {http://books.nips.cc/papers/files/nips23/NIPS2010{\_}0760.pdf},
volume = {23},
year = {2010}
}
@article{Huang2006,
abstract = {It is clear that the learning speed of feedforward neural networks is in general far slower than required and it has been a major bottleneck in their applications for past decades. Two key reasons behind may be: (1) the slow gradient-based learning algorithms are extensively used to train neural networks, and (2) all the parameters of the networks are tuned iteratively by using such learning algorithms. Unlike these conventional implementations, this paper proposes a new learning algorithm called extreme learning machine (ELM) for single-hidden layer feedforward neural networks (SLFNs) which randomly chooses hidden nodes and analytically determines the output weights of SLFNs. In theory, this algorithm tends to provide good generalization performance at extremely fast learning speed. The experimental results based on a few artificial and real benchmark function approximation and classification problems including very large complex applications show that the new algorithm can produce good generalization performance in most cases and can learn thousands of times faster than conventional popular learning algorithms for feedforward neural networks.11For the preliminary idea of the ELM algorithm, refer to “Extreme Learning Machine: A New Learning Scheme of Feedforward Neural Networks”, Proceedings of International Joint Conference on Neural Networks (IJCNN2004), Budapest, Hungary, 25–29 July, 2004.},
author = {Huang, Guang-Bin and Zhu, Qin-Yu and Siew, Chee-Kheong},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Back-propagation algorithm,Extreme learning machine,Feedforward neural networks,Random node,Real-time learning,Support vector machine},
month = {dec},
number = {1-3},
pages = {489--501},
title = {{Extreme learning machine: Theory and applications}},
volume = {70},
year = {2006}
}
@article{Beightler1966,
author = {Beightler, Charles S. and Wilde, Douglass J.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Beightler, Wilde - 1966 - Diagonalization of quadratic forms by Gauss elimination.pdf:pdf},
journal = {Management Science},
number = {5},
pages = {371--379},
title = {{Diagonalization of quadratic forms by Gauss elimination}},
volume = {12},
year = {1966}
}
@book{Shapiro:Farrago,
author = {Shapiro, Joel H},
isbn = {9783319279763},
pages = {221},
publisher = {Springer International Publishing Switzerland},
title = {{A Fixed-Point Farrago}},
year = {2016}
}
@article{Buteneers2011,
abstract = {INTRODUCTION
In this paper we propose a technique based on reservoir computing (RC) to mark epileptic seizures on the intra-cranial electroencephalogram (EEG) of rats. RC is a recurrent neural networks training technique which has been shown to possess good generalization properties with limited training. 

MATERIALS
The system is evaluated on data containing two different seizure types: absence seizures from genetic absence epilepsy rats from Strasbourg (GAERS) and tonic–clonic seizures from kainate-induced temporal-lobe epilepsy rats. The dataset consists of 452hours from 23 GAERS and 982hours from 15 kainate-induced temporal-lobe epilepsy rats. 

METHODS
During the preprocessing stage, several features are extracted from the EEG. A feature selection algorithm selects the best features, which are then presented as input to the RC-based classification algorithm. To classify the output of this algorithm a two-threshold technique is used. This technique is compared with other state-of-the-art techniques. 

RESULTS
A balanced error rate (BER) of 3.7{\%} and 3.5{\%} was achieved on the data from GAERS and kainate rats, respectively. This resulted in a sensitivity of 96{\%} and 94{\%} and a specificity of 96{\%} and 99{\%} respectively. The state-of-the-art technique for GAERS achieved a BER of 4{\%}, whereas the best technique to detect tonic–clonic seizures achieved a BER of 16{\%}. 

CONCLUSION
Our method outperforms up-to-date techniques and only a few parameters need to be optimized on a limited training set. It is therefore suited as an automatic aid for epilepsy researchers and is able to eliminate the tedious manual review and annotation of EEG.},
author = {Buteneers, Pieter and Verstraeten, David and van Mierlo, Pieter and Wyckhuys, Tine and Stroobandt, Dirk and Raedt, Robrecht and Hallez, Hans and Schrauwen, Benjamin},
doi = {10.1016/j.artmed.2011.08.006},
issn = {09333657},
journal = {Artificial Intelligence in Medicine},
number = {3},
pages = {215--223},
title = {{Automatic detection of epileptic seizures on the intra-cranial electroencephalogram of rats using reservoir computing}},
volume = {53},
year = {2011}
}
@article{Berry_frog,
author = {Berry, M. V. and Geim, A. K.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Berry, Geim - 1997 - Of flying frogs and levitrons.pdf:pdf},
journal = {Eur. J. Phys.},
pages = {307--313},
title = {{Of flying frogs and levitrons}},
volume = {18},
year = {1997}
}
@article{chow:1939,
author = {Chow, W. L.},
journal = {Math. Ann.},
pages = {98--105},
title = {{{\"{U}}ber Systeme von linearen partiellen Differentialgleichungen erster Ordnung}},
volume = {117},
year = {1939}
}
@article{Poschel1993,
author = {P{\"{o}}schel, J{\"{u}}rgen},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/P{\"{o}}schel - 1993 - Nekhoroshev estimates for quasi-convex Hamiltonian systems.pdf:pdf},
journal = {Mathematische Zeitschrift},
pages = {187--216},
title = {{Nekhoroshev estimates for quasi-convex Hamiltonian systems}},
volume = {213},
year = {1993}
}
@article{DeGMatthews2018,
author = {{de G. Matthews}, Alexander G. and Rowland, Mark and Hron, Jiri and Turner, Richard E. and Ghahramani, Zoubin},
title = {{Gaussian process behaviour in wide deep neural networks}},
year = {2018}
}
@article{Li2008,
abstract = {The accuracy of a single diagnostic test for binary outcome can be summarized by the area under the receiver operating characteristic (ROC) curve. Volume under the surface and hypervolume under the manifold have been proposed as extensions for multiple class diagnosis (Scurfield, 1996, 1998). However, the lack of simple inferential procedures for such measures has limited their practical utility. Part of the difficulty is that calculating such quantities may not be straightforward, even with a single test. The decision rule used to generate the ROC surface requires class probability assessments, which are not provided by the tests. We develop a method based on estimating the probabilities via some procedure, for example, multinomial logistic regression. Bootstrap inferences are proposed to account for variability in estimating the probabilities and perform well in simulations. The ROC measures are compared to the correct classification rate, which depends heavily on class prevalences. An example of tumor classification with microarray data demonstrates that this property may lead to substantially different analyses. The ROC-based analysis yields notable decreases in model complexity over previous analyses.},
author = {Li, Jialiang and Fine, Jason P},
doi = {10.1093/biostatistics/kxm050},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Li, Fine - 2008 - ROC analysis with multiple classes and multiple tests methodology and its application in microarray studies.pdf:pdf},
issn = {1468-4357},
journal = {Biostatistics (Oxford, England)},
keywords = {Algorithms,Artificial Intelligence,Biometry,Biometry: methods,Carcinoma,Decision Support Techniques,Diagnosis,Diagnostic Tests,Differential,Ewing,Ewing: diagnosis,Ewing: genetics,Humans,Lymphoma,Neuroblastoma,Neuroblastoma: diagnosis,Neuroblastoma: genetics,Non-Hodgkin,Non-Hodgkin: diagnosis,Non-Hodgkin: genetics,Oligonucleotide Array Sequence Analysis,Oligonucleotide Array Sequence Analysis: methods,Oligonucleotide Array Sequence Analysis: statistic,Probability,ROC Curve,Regression Analysis,Reproducibility of Results,Rhabdomyosarcoma,Rhabdomyosarcoma: diagnosis,Rhabdomyosarcoma: genetics,Routine,Routine: methods,Routine: statistics {\&} numerical,Sarcoma,Small Cell,Small Cell: classification,Small Cell: genetics,Weights and Measures},
month = {jul},
number = {3},
pages = {566--76},
pmid = {18304996},
title = {{ROC analysis with multiple classes and multiple tests: methodology and its application in microarray studies.}},
url = {http://biostatistics.oxfordjournals.org/cgi/content/abstract/9/3/566},
volume = {9},
year = {2008}
}
@incollection{fliess:bilinear,
author = {Fliess, Michel},
booktitle = {Mathematical Systems Theory},
editor = {Marchesini, G and Mitter, S K},
pages = {122--148},
publisher = {Springer Verlag},
title = {{Un outil algebrique : les series formelles non commutatives}},
year = {1976}
}
@techreport{Kuzin2009a,
abstract = {This paper compares the mixed-data sampling (MIDAS) and mixed-frequency VAR (MF-VAR) approaches to model specification in the presence of mixed- frequency data, e.g., monthly and quarterly series. MIDAS leads to parsimonious models based on exponential lag polynomials for the coefficients, whereas MF-VAR does not restrict the dynamics and therefore can suffer from the curse of dimensionality. But if the restrictions imposed by MIDAS are too stringent, the MF-VAR can perform better. Hence, it is difficult to rank MIDAS and MF-VAR a priori, and their relative ranking is better evaluated empirically. In this paper, we compare their performance in a relevant case for policy making, i.e., nowcasting and forecasting quarterly GDP growth in the euro area, on a monthly basis and using a set of 20 monthly indicators. It turns out that the two approaches are more complementary than substitutes, since MF-VAR tends to perform better for longer horizons, whereas MIDAS for shorter horizons.},
annote = {From Duplicate 2 ( 

MIDAS vs. Mixed-Frequency VAR:Nowcasting GDP in the Euro Area

- Kuzin, Vladimir; Marcellino, Massimiliano; Schumacher, Christian )

},
author = {Kuzin, Vladimir and Marcellino, Massimiliano and Schumacher, Christian},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Kuzin, Marcellino, Schumacher - 2009 - MIDAS vs. mixed-frequency VAR nowcasting GDP in the euro area.pdf:pdf;:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Kuzin, Marcellino, Schumacher - 2009 - MIDAS vs. Mixed-Frequency VARNowcasting GDP in the Euro Area.pdf:pdf},
institution = {CEPR},
keywords = {MIDAS,VAR and nowcasting,euro area growth,mixed-frequency,mixed-frequency data},
publisher = {CEPR Discussion Papers 7445},
series = {Department of Economics},
title = {{MIDAS vs. mixed-frequency VAR: nowcasting GDP in the euro area}},
type = {Discussion Paper},
year = {2009}
}
@inproceedings{Choromanski2017,
author = {Choromanski, Krzysztof and Rowland, Mark},
booktitle = {NeurIPS},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Choromanski, Rowland - 2017 - The unreasonable effectiveness of structured random orthogonal embeddings.pdf:pdf},
title = {{The unreasonable effectiveness of structured random orthogonal embeddings}},
year = {2017}
}
@inproceedings{Lindnder2009,
author = {Lindner, Alexander},
booktitle = {Handbook of Financial Time Series},
editor = {Andersen, Torben G and Davis, Richard A. and Krei{\ss}, Jens-Peter and Mikosch, Thomas},
publisher = {Springer-Verlag},
title = {{Continuous time approximations to GARCH and stochastic volatility models}},
year = {2009}
}
@unpublished{lagrangian:reduction:by:stages,
annote = {Preprint,},
author = {Cendra, H. and Marsden, J. E. and Ratiu, T. S.},
title = {{Lagrangian reduction by stages}},
year = {1998}
}
@article{astab,
author = {Arnold, V. I.},
journal = {Dokl. Mat. Nauk SSSR},
pages = {773--777},
title = {{Conditions for nonlinear stability of the stationary plane curvilinear flows of an ideal fluid.}},
volume = {162},
year = {1965}
}
@book{Cucker2007,
author = {Cucker, F. and Zhou, D.X.},
publisher = {Cambridge University Press},
title = {{Learning Theory: An Approximation Theory Viewpoint}},
year = {2007}
}
@unpublished{Brunetti2002,
author = {Brunetti, Celso and Lildholdt, Peter Myhre},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Brunetti, Lildholdt - 2002 - Return-based and range-based (co)variance estimation - with an application to foreign exchange markets.pdf:pdf},
institution = {Center for Analytical Finance - University of Aarhus, Aarhus School of Business},
number = {127},
title = {{Return-based and range-based (co)variance estimation - with an application to foreign exchange markets}},
year = {2002}
}
@article{Harris1998,
author = {Harris, C. M. and Wolpert, Daniel M.},
journal = {Nature},
pages = {780--784},
title = {{Signal-dependent noise determines motor planning}},
volume = {394},
year = {1998}
}
@incollection{maass2,
author = {Maass, Wolfgang},
booktitle = {Computability In Context: Computation and Logic in the Real World},
chapter = {8},
editor = {{Barry Cooper}, S. S. and Sorbi, Andrea},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Maass - 2011 - Liquid state machines motivation, theory, and applications.pdf:pdf},
pages = {275--296},
title = {{Liquid state machines: motivation, theory, and applications}},
year = {2011}
}
@article{Bai2008,
abstract = {This paper studies two refinements to the method of factor forecasting. First, we consider the method of quadratic principal components that allows the link function between the predictors and the factors to be non-linear. Second, the factors used in the forecasting equation are estimated in a way to take into account that the goal is to forecast a specific series. This is accomplished by applying the method of principal components to ‘targeted predictors' selected using hard and soft thresholding rules. Our three main findings can be summarized as follows. First, we find improvements at all forecast horizons over the current diffusion index forecasts by estimating the factors using fewer but informative predictors. Allowing for non-linearity often leads to additional gains. Second, forecasting the volatile one month ahead inflation warrants a high degree of targeting to screen out the noisy predictors. A handful of variables, notably relating to housing starts and interest rates, are found to have systematic predictive power for inflation at all horizons. Third, the targeted predictors selected by both soft and hard thresholding changes with the forecast horizon and the sample period. Holding the set of predictors fixed as is the current practice of factor forecasting is unnecessarily restrictive.},
author = {Bai, Jushan and Ng, Serena},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Bai, Ng - 2008 - Forecasting economic time series using targeted predictors.pdf:pdf},
issn = {03044076},
journal = {Journal of Econometrics},
keywords = {diffusion index,factor models,hard thresholding,lars,lasso},
month = {oct},
number = {2},
pages = {304--317},
title = {{Forecasting economic time series using targeted predictors}},
url = {http://dx.doi.org/10.1016/j.jeconom.2008.08.010},
volume = {146},
year = {2008}
}
@inproceedings{girosi1995approximation,
author = {Girosi, Federico},
booktitle = {Proc. International Conference on Artificial Neural Networks},
editor = {Fogelman-Soulie, F. and Gallinari, P.},
pages = {295--302},
title = {{Approximation error bounds that use VC-bounds}},
volume = {1},
year = {1995}
}
@inproceedings{Pinto2011,
author = {Pinto, Rafael C. and Engel, Paulo Martins and Heinen, Milton Roberto},
booktitle = {Proceedings of the IX ENIA-Brazilian Meeting on Artificial Intelligence},
title = {{Echo State Incremental Gaussian Mixture Network for spatio-temporal pattern processing}},
year = {2011}
}
@article{Natschlager:117806,
abstract = {We will discuss in this survey article a new framework for analysing computations on time series and in particular on spike trains, introduced in (Maass et. al. 2002). In contrast to common computational models this new framework does not require that information can be stored in some stable states of a computational system. It has recently been shown that such models where all events are transient can be successfully applied to analyse computations in neural systems and (independently) that the basic ideas can also be used to solve engineering tasks such as the design of nonlinear controllers. Using an illustrative example we will develop the main ideas of the proposed model. This illustrative example is generalized and cast into a rigorous mathematical model: the Liquid State Machine. A mathematical analysis shows that there are in principle no computational limitations of liquid state machines in the domain of time series computing. Finally we discuss several successful applications of the framework in the area of computational neuroscience and in the field of artificial neural networks.},
author = {Natschl{\"{a}}ger, T and Maass, W and Markram, H},
journal = {Special Issue on Foundations of Information Processing of TELEMATIK},
number = {1},
pages = {39--43},
title = {{The "Liquid Computer": a novel strategy for real-time computing on time series}},
url = {http://infoscience.epfl.ch/record/117806},
volume = {8},
year = {2002}
}
@unpublished{Dasgupta,
abstract = {Quantitative risk management, particularly volatility forecasting, is critically important to traders, portfolio managers as well as policy makers. In this paper, we applied quantum reservoir computing for forecasting VIX (the CBOE volatility index), a highly non-linear and memory intensive `real-life' signal that is driven by market dynamics and trader psychology and cannot be expressed by a deterministic equation. As a first step, we lay out the systematic design considerations for using a NISQ reservoir as a computing engine (which should be useful for practitioners). We then show how to experimentally evaluate the memory capacity of various reservoir topologies (using IBM-Q's Rochester device) to identify the configuration with maximum memory capacity. Once the optimal design is selected, the forecast is produced by a linear combination of the average spin of a 6-qubit quantum register trained using VIX and SPX data from year 1990 onwards. We test the forecast performance over the sub-prime mortgage crisis period (Dec 2007 - Jun 2009). Our results show a remarkable ability to predict the volatility during the Great Recession using today's NISQs.},
archivePrefix = {arXiv},
arxivId = {2004.08240},
author = {Dasgupta, Samudra and Hamilton, Kathleen E. and Banerjee, Arnab},
eprint = {2004.08240},
title = {{Designing a NISQ reservoir with maximal memory capacity for volatility forecasting}},
url = {http://arxiv.org/abs/2004.08240},
year = {2020}
}
@unpublished{King2007,
author = {King, Thomas B and Levin, Andrew T and Perli, Roberto},
booktitle = {Finance and Economics},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/King, Levin, Perli - 2007 - Financial Market Perceptions of Recession Risk.pdf:pdf},
institution = {Federal Reserve Board},
title = {{Financial Market Perceptions of Recession Risk}},
year = {2007}
}
@article{Snyder2013,
author = {Snyder, David and Goudarzi, Alireza and Teuscher, Christof},
issn = {1539-3755},
journal = {Physical Review E},
month = {apr},
number = {4},
pages = {042808},
title = {{Computational capabilities of random automata networks for reservoir computing}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.87.042808},
volume = {87},
year = {2013}
}
@article{Charles2006,
abstract = {This study investigates the effects of the terrorist attacks in U.S. on September 11, 2001, on international stock markets. We examine 10 daily stock market indexes using the outlier detection methodology. We show that the international stock markets experienced large (permanent and temporary) shocks in response to the terrorist attacks and its aftermath. We also show that taking into account these events can improve modelling financial risk, especially the volatility in stock market prices.},
author = {Charles, Am{\'{e}}lie and Darn{\'{e}}, Olivier},
issn = {02649993},
journal = {Economic Modelling},
keywords = {c5,g1},
month = {jul},
number = {4},
pages = {683--698},
title = {{Large shocks and the September 11th terrorist attacks on international stock markets}},
url = {http://dx.doi.org/10.1016/j.econmod.2006.03.008},
volume = {23},
year = {2006}
}
@article{Zhang2005,
abstract = {Neural networks have been widely used as a promising method for time series forecasting. However, limited empirical studies on seasonal time series forecasting with neural networks yield mixed results. While some find that neural networks are able to model seasonality directly and prior deseasonalization is not necessary, others conclude just the opposite. In this paper, we investigate the issue of how to effectively model time series with both seasonal and trend patterns. In particular, we study the effectiveness of data preprocessing, including deseasonalization and detrending, on neural network modeling and forecasting performance. Both simulation and real data are examined and results are compared to those obtained from the Box–Jenkins seasonal autoregressive integrated moving average models. We find that neural networks are not able to capture seasonal or trend variations effectively with the unpreprocessed raw data and either detrending or deseasonalization can dramatically reduce forecasting errors. Moreover, a combined detrending and deseasonalization is found to be the most effective data preprocessing approach.},
author = {Zhang, G.Peter and Qi, Min},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {box–jenkins method,forecasting,neural networks,seasonality,time series},
month = {jan},
number = {2},
pages = {501--514},
title = {{Neural network forecasting for seasonal and trend time series}},
url = {http://dx.doi.org/10.1016/j.ejor.2003.08.037},
volume = {160},
year = {2005}
}
@article{audrinoTrojani2011,
author = {Audrino, Francesco and Trojani, Fabio},
journal = {Journal of Business and Economic Statistics},
number = {1},
pages = {138--149},
title = {{A general multivariate threshold GARCH model with dynamic conditional correlations}},
volume = {29},
year = {2011}
}
@article{lanne:saikkonen,
author = {Lanne, Markku and Saikkonen, Pentti},
doi = {10.1198/073500106000000404},
journal = {Journal of Business and Economic Statistics},
number = {1},
pages = {61--75},
title = {{A Multivariate Generalized Orthogonal Factor GARCH Model}},
url = {http://pubs.amstat.org/doi/abs/10.1198/073500106000000404},
volume = {25},
year = {2007}
}
@article{ibanez2018detection,
author = {Ib{\'{a}}{\~{n}}ez-Soria, David and Garc{\'{i}}a-Ojalvo, Jordi and Soria-Frisch, Aureli and Ruffini, Giulio},
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
number = {3},
pages = {33118},
publisher = {AIP Publishing LLC},
title = {{Detection of generalized synchronization using echo state networks}},
volume = {28},
year = {2018}
}
@inproceedings{Diblik2011,
address = {Stevens Point, Wisconsin, USA},
author = {Dibl{\'{i}}k, Josef and Mor{\'{a}}vkov{\'{a}}, Blanka and Khusainov, Denys and Kukharenko, Aleksandra},
booktitle = {Proceedings of MMES'11/DEEE'11/COMATIA'11},
isbn = {978-1-61804-055-8},
keywords = {controllability,delayed exponentials,fourier method,impulses,single delay},
pages = {82--87},
publisher = {World Scientific and Engineering Academy and Society (WSEAS)},
title = {{Delayed exponential functions and their application to representations of solutions of linear equations with constant coefficients and with single delay}},
url = {http://dl.acm.org/citation.cfm?id=2183109.2183125},
year = {2011}
}
@article{RelVol2005b,
author = {A{\"{i}}t-Sahalia, Yacine and Mykland, Per A. and Zhang, Lan},
journal = {The Review of Financial Studies},
number = {2},
pages = {351--416},
title = {{How often to sample a continuous-time process in the presence of market microstructure noise}},
volume = {18},
year = {2005}
}
@book{bookMatrixDistributions2000,
author = {Gupta, A.K. and Nagar, D.K.},
publisher = {Chapman and Hall/CRC},
title = {{Matrix Variate Distributions}},
year = {2000}
}
@article{Cruse2012a,
abstract = {Functional neuroimaging has shown that the absence of externally observable signs of consciousness and cognition in severely brain-injured patients does not necessarily indicate the true absence of such abilities. However, relative to traumatic brain injury, nontraumatic injury is known to be associated with a reduced likelihood of regaining overtly measurable levels of consciousness. We investigated the relationships between etiology and both overt and covert cognitive abilities in a group of patients in the minimally conscious state (MCS).},
author = {Cruse, Damian and Chennu, Srivas and Chatelle, Camille and Fern{\'{a}}ndez-Espejo, Davinia and Bekinschtein, Tristan A. and Pickard, John D. and Laureys, Steven and Owen, Adrian M.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Cruse et al. - 2012 - Relationship between etiology and covert cognition in the minimally conscious state.pdf:pdf},
issn = {1526-632X},
journal = {Neurology},
keywords = {Adolescent,Adult,Aged,Arousal,Arousal: physiology,Automatic Data Processing,Awareness,Awareness: physiology,Brain Injuries,Brain Injuries: complications,Child,Cognition,Cognition: physiology,Coma,Coma: psychology,Communication,Consciousness,Consciousness: physiology,Electroencephalography,Female,Hearing,Hearing: physiology,Humans,Imagination,Imagination: physiology,Male,Middle Aged,Movement,Movement: physiology,Ocular,Ocular: physiology,Persistent Vegetative State,Persistent Vegetative State: etiology,Persistent Vegetative State: psychology,Prognosis,Reflex,Reflex: physiology,Support Vector Machines,Verbal Behavior,Verbal Behavior: physiology,Vision,Young Adult},
month = {mar},
number = {11},
pages = {816--22},
title = {{Relationship between etiology and covert cognition in the minimally conscious state.}},
url = {http://www.neurology.org/content/78/11/816.short},
volume = {78},
year = {2012}
}
@book{cartan:1908,
address = {25,57--194},
author = {Cartan, {\'{E}}.},
booktitle = {Ann. Ec. Norm. Sup.},
pages = {57--194},
publisher = {Ann. Ec. Norm. Sup.},
title = {{Les sous-groupes des groupes continus des groupes continus de transformation}},
volume = {25},
year = {1908}
}
@article{ChoDias,
author = {Chossat, P. and Dias, F.},
journal = {J. Nonlin. Sci.},
pages = {105--129},
title = {{The 1:2 resonance with O(2) symmetry and its applications in hydrodynamics}},
volume = {5},
year = {1995}
}
@unpublished{Hernandez2017,
author = {Hernandez, Andreas},
title = {{Model calibration: global optimizer vs. neural network}},
year = {2017}
}
@article{grizzle1984optimal,
author = {Grizzle, J and Marcus, Sl},
journal = {IEEE transactions on automatic control},
number = {11},
pages = {1037--1040},
publisher = {IEEE},
title = {{Optimal control of systems possessing symmetries}},
volume = {29},
year = {1984}
}
@article{casdagli:1991,
abstract = {Takens' theorem demonstrates that in the absence of noise a multidimensional state space can be reconstructed from a scalar time series. This theorem gives little guidance, however, about practical considerations for reconstructing a good state space. We extend Takens' treatment, applying statistical methods to incorporate the effects of observational noise and estimation error. We define the distortion matrix, which is proportional to the conditional covariance of a state, given a series of noisy measurements, and the noise amplification, which is proportional to root-square time series prediction errors with an ideal model. We derive explicit formulae for these quantities, and we prove that in the low noise limit minimizing the distortion is equivalent to minimizing the noise amplification. We identify several different scaling regimes for distortion and noise amplification, and derive asymptotic scaling laws. When the dimension and Lyapunov exponents are sufficiently large these scaling laws show that, no matter how the state space is reconstructed, there is an explosion in the noise amplification - from a practical point of view determinism is lost, and the time series is effectively a random process. In the low noise, large data limit we show that the technique of local singular value decomposition is an optimal coordinate transformation, in the sense that it achieves the minimum distortion in a state space of the lowest possible dimension. However, in numerical experiments we find that estimation error complicates this issue. For local approximation methods, we analyze the effect of reconstruction on estimation error, derive a scaling law, and suggest an algorithm for reducing estimation errors. {\textcopyright} 1991.},
author = {Casdagli, Martin and Eubank, Stephen and Farmer, J. Doyne and Gibson, John},
doi = {10.1016/0167-2789(91)90222-U},
issn = {01672789},
journal = {Physica D: Nonlinear Phenomena},
number = {1-3},
pages = {52--98},
title = {{State space reconstruction in the presence of noise}},
volume = {51},
year = {1991}
}
@incollection{sussmann:bilinear:systems,
author = {Sussmann, H{\'{e}}ctor J.},
booktitle = {Mathematical Systems Theory},
editor = {Marchesini, G and MItter, S K},
pages = {172--191},
publisher = {Springer Verlag},
title = {{Semigroup representations, bilinear approximations of input-output maps, and generalized inputs}},
year = {1976}
}
@article{ortega:lazaro1,
author = {L{\'{a}}zaro-Cam{\'{i}}, Andreu and Ortega, Juan-Pablo},
journal = {Reports on Mathematical Physics},
number = {1},
pages = {65--122},
title = {{Stochastic Hamiltonian dynamical systems}},
volume = {61},
year = {2008}
}
@article{Kauppi2008b,
author = {Kauppi, Heikki and Saikkonen, Pentti},
file = {::;::},
issn = {0034-6535},
journal = {Review of Economics and Statistics},
month = {nov},
number = {4},
pages = {777--791},
title = {{Predicting U.S. Recessions with Dynamic Binary Response Models}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/rest.90.4.777},
volume = {90},
year = {2008}
}
@inproceedings{Kidger2019,
author = {Kidger, Patrick and Lyons, Terry},
booktitle = {Proceedings of Thirty Third Conference on Learning Theory},
pages = {2306--2327},
title = {{Universal approximation with deep narrow networks}},
year = {2020}
}
@misc{Wu2016,
author = {Wu, Yihong},
title = {{Information-theoretic Methods in High-dimensional Statistics: Lecture Notes}},
url = {http://www.stat.yale.edu/{~}yw562/teaching/598/},
year = {2016}
}
@article{Bassani2006,
author = {Bassani, Roberto},
doi = {10.1007/s11012-005-4503-x},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Bassani - 2006 - Earnshaw (1805-1888) and passive magnetic levitation.pdf:pdf},
journal = {Meccanica},
pages = {375--389},
title = {{Earnshaw (1805-1888) and passive magnetic levitation}},
volume = {41},
year = {2006}
}
@article{Kiymik2004,
abstract = {We propose a novel method for automatic recognition of alertness level from full spectrum electroencephalogram (EEG) recordings. This procedure uses power spectral density (PSD) of discrete wavelet transform (DWT) of full spectrum EEG as an input to an artificial neural network (ANN) with three discrete outputs: alert, drowsy and sleep. The error back propagation neural network is selected as a classifier to discriminate the alertness level of a subject. EEG signals were obtained from 30 healthy subjects. The group consisted of 14 females and 16 males with ages ranging from 18 to 65 years and a mean age of 33.5 years, and a body mass index (BMI) of 32.4 +/- 7.3 kg/m2. Alertness level and classification properties of ANN were tested using the data recorded in 12 healthy subjects, whereby the EEG recordings were not used been used to train the ANN. The statistics were used as a measure of potential applicability of the ANN. The accuracy of the ANN was 96 +/- 3{\%} alert, 95 +/- 4{\%} drowsy and 94 +/- 5{\%} sleep. The results suggest that the automatic recognition algorithm is applicable for distinguishing between alert, drowsy and sleep state in recordings that have not been used for the training.},
author = {Kiymik, M. Kemal and Akin, Mehmet and Subasi, Abdulhamit},
doi = {10.1016/j.jneumeth.2004.04.027},
issn = {0165-0270},
journal = {Journal of neuroscience methods},
keywords = {Adolescent,Adult,Aged,Electroencephalography,Electroencephalography: methods,Female,Humans,Male,Middle Aged,Neural Networks (Computer),Recognition (Psychology),Recognition (Psychology): physiology,Wakefulness,Wakefulness: physiology},
month = {oct},
number = {2},
pages = {231--240},
pmid = {15488236},
title = {{Automatic recognition of alertness level by using wavelet transform and artificial neural network}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15488236},
volume = {139},
year = {2004}
}
@article{Caporale2003,
author = {Caporale, Guglielmo Maria and Spagnolo, Nicola},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Caporale, Spagnolo - 2003 - Asset prices and output growth volatility the effects of financial crises.pdf:pdf},
issn = {01651765},
journal = {Economics Letters},
keywords = {c32,financial crises,g15,jel classification,multivariate garch,output growth,stock prices,volatility},
month = {apr},
number = {1},
pages = {69--74},
title = {{Asset prices and output growth volatility: the effects of financial crises}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0165176502002896},
volume = {79},
year = {2003}
}
@article{Weng:2019,
abstract = {Recent advances have demonstrated the effectiveness of a machine-learning approach known as "reservoir computing" for model-free prediction of chaotic systems. We find that a well-trained reservoir computer can synchronize with its learned chaotic systems by linking them with a common signal. A necessary condition for achieving this synchronization is the negative values of the sub-Lyapunov exponents. Remarkably, we show that by sending just a scalar signal, one can achieve synchronism in trained reservoir computers and a cascading synchronization among chaotic systems and their fitted reservoir computers. Moreover, we demonstrate that this synchronization is maintained even in the presence of a parameter mismatch. Our findings possibly provide a path for accurate production of all expected signals in unknown chaotic systems using just one observational measure.},
author = {Weng, Tongfeng and Yang, Huijie and Gu, Changgui and Zhang, Jie and Small, Michael},
doi = {10.1103/PhysRevE.99.042203},
issn = {24700053},
journal = {Physical Review E},
keywords = {doi:10.1103/PhysRevE.99.042203 url:https://doi.org},
number = {4},
pages = {1--7},
pmid = {31108603},
publisher = {American Physical Society},
title = {{Synchronization of chaotic systems and their machine-learning models}},
volume = {99},
year = {2019}
}
@article{Todorov2002,
author = {Todorov, Emanuel and Jordan, Michael I.},
journal = {Nature Neuroscience},
pages = {1226--1235},
title = {{Optimal feedback control as a theory of motor coordination}},
volume = {5},
year = {2002}
}
@article{sussmann,
author = {Sussmann, H{\'{e}}ctor J},
journal = {Transactions of the American Mathematical Society},
pages = {171--188},
title = {{Orbits of families of vector fields and integrability of distributions}},
volume = {180},
year = {1973}
}
@inproceedings{gutierrez2012,
author = {Guti{\'{e}}rrez, J. M. and San-Mart{\'{i}}n, D. and Ort{\'{i}}n, S. and Pesquera, L.},
booktitle = {20th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Guti{\'{e}}rrez et al. - 2012 - Simple reservoirs with chain topology based on a single time-delay nonlinear node.pdf:pdf},
pages = {13--18},
title = {{Simple reservoirs with chain topology based on a single time-delay nonlinear node}},
year = {2012}
}
@techreport{george:volterra,
author = {George, Donald A.},
institution = {Massachusetts Institute of Technology, Research Laboratory of Electronics},
pages = {1--108},
title = {{Continuous nonlinear systems}},
url = {http://oai.dtic.mil/oai/oai?verb=getRecord{\&}metadataPrefix=html{\&}identifier=AD0246281},
year = {1959}
}
@article{Sosso2013,
annote = {PMID: 26296172},
author = {Sosso, Gabriele C and Miceli, Giacomo and Caravati, Sebastiano and Giberti, Federico and Behler, J{\"{o}}rg and Bernasconi, Marco},
doi = {10.1021/jz402268v},
journal = {The Journal of Physical Chemistry Letters},
number = {24},
pages = {4241--4246},
title = {{Fast crystallization of the phase change compound GeTe by large-scale molecular dynamics simulations}},
url = {http://dx.doi.org/10.1021/jz402268v},
volume = {4},
year = {2013}
}
@inproceedings{IEEEprocsRC2,
author = {Grigoryeva, Lyudmila and Henriques, Julie and Larger, Laurent and Ortega, Juan-pablo},
booktitle = {Proceedings of the 19th IEEE International Conference on Computational Science and Engineering},
doi = {10.1109/CSE-EUC-DCABES.2016.230},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Grigoryeva et al. - 2016 - Time-delay reservoir computers and high-speed information processing capacity.pdf:pdf},
isbn = {9781509035939},
keywords = {-reservoir computing,architec-,computing,echo state networks,memory capacity,neural,time-delay reservoir},
pages = {492--495},
title = {{Time-delay reservoir computers and high-speed information processing capacity}},
year = {2016}
}
@inproceedings{Renault:Khrapov,
address = {Working paper},
author = {Khrapov, Stanislav and Renault, Eric},
title = {{Affine option pricing model in discrete time}},
year = {2016}
}
@article{manev1,
author = {Delgado, J. and Diacu, F. N. and Lacomba, E. A. and Mingarelli, A. and Mioc, V. and P{\'{e}}rez, E. and AndStoica, C},
journal = {J. Math. Phys.},
number = {6},
pages = {2748--2761},
title = {{The global flow of the Manev problem}},
volume = {37},
year = {1996}
}
@article{Stock2003,
author = {Stock, James H and Watson, Mark W},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Stock, Watson - 2003 - Forecasting output and inflation The role of asset prices.pdf:pdf},
issn = {0022-0515},
journal = {Journal of Economic Literature},
month = {sep},
number = {3},
pages = {788--829},
title = {{Forecasting output and inflation: The role of asset prices}},
url = {http://pubs.aeaweb.org/doi/abs/10.1257/002205103322436197},
volume = {41},
year = {2003}
}
@article{Dillon_Lebanon_CL_2009,
author = {Dillon, J.V. and Lebanon, G.},
journal = {Proceedings of the 12th International Conference on Artificial Intelligence and Statistics (AISTATS)},
pages = {129--136},
title = {{Statistical and computational tradeoffs in stochastic composite likelihood}},
volume = {5},
year = {2009}
}
@misc{Banerjee2011,
author = {Banerjee, Anindya and Marcellino, Massimiliano and Masten, Igor},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Banerjee, Marcellino, Masten - 2011 - Forecasting with Factor-augmented Error Correction Models.pdf:pdf},
keywords = {coin-,dynamic factor models,error correction models,factor-augmented error correction models,favar,forecasting,tegration},
title = {{Forecasting with Factor-augmented Error Correction Models}},
year = {2011}
}
@article{engle:sheppard:dcc,
author = {Engle, Robert F and Sheppard, Kevin},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Engle, Sheppard - 2001 - Theoretical and empirical properties of dynamic conditional correlation multivariate GARCH.pdf:pdf},
journal = {Preprint, UCSD},
keywords = {dynamic correlation,multivariate garch,volatility},
title = {{Theoretical and Empirical properties of Dynamic Conditional Correlation Multivariate GARCH}},
year = {2001}
}
@article{Simon2001,
author = {Simon, M. D. and Heflinger, L. O. and Geim, A. K.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Simon, Heflinger, Geim - 2001 - Diamagnetically stabilized magnet levitation.pdf:pdf},
journal = {Am. J. Phys.},
number = {6},
pages = {702--713},
title = {{Diamagnetically stabilized magnet levitation}},
volume = {69},
year = {2001}
}
@techreport{Goldfine2013b,
author = {Goldfine, Andrew M. and Bardin, Jonathan C. and Noirhomme, Quentin and Fins, Joseph and Schiff, Nicholas D. and Victor, Jonathan D.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Goldfine et al. - 2013 - Referee report on Reanalysis of Bedside detection of awareness in the vegetative state a cohort study.pdf:pdf},
title = {{Referee report on: Reanalysis of "Bedside detection of awareness in the vegetative state: a cohort study."}},
year = {2013}
}
@article{eckmann:ruelle,
abstract = {Physical and numerical experiments show that deterministic noise, or chaos, is ubiquitous. While a good understanding of the onset of chaos has been achieved, using as a mathematical tool the geometric theory of differentiable dynamical systems, moderately excited chaotic systems require new tools, which are provided by the ergodic theory of dynamical systems. This theory has reached a stage where fruitful contact and exchange with physical experiments has become widespread. The present review is an account of the main mathematical ideas and their concrete implementation in analyzing experiments. The main subjects are the theory of dimensions (number of excited degrees of freedom), entropy (production of information), and characteristic exponents (describing sensitivity to initial conditions). The relations between these quantities, as well as their experimental determination, are discussed. The systematic investigation of these quantities provides us for the first time with a reasonable understanding of dynamical systems, excited well beyond the quasiperiodic regimes. This is another step towards understanding highly turbulent fluids. {\textcopyright} 1985 The American Physical Society.},
author = {Eckmann, J.-P. and Ruelle, D.},
doi = {10.1103/RevModPhys.57.617},
issn = {00346861},
journal = {Reviews of Modern Physics},
number = {3},
pages = {617--656},
title = {{Ergodic theory of chaos and strange attractors}},
volume = {57},
year = {1985}
}
@unpublished{Livi2016,
author = {Livi, Lorenzo and Bianchi, Filippo Maria and Alippi, Cesare},
title = {{Determination of the edge of criticality in echo state networks through Fisher information maximization}},
year = {2016}
}
@article{Saad1998a,
author = {Saad, E.W. and Prokhorov, D.V. and Wunsch, D.C.},
doi = {10.1109/72.728395},
issn = {10459227},
journal = {IEEE Transactions on Neural Networks},
number = {6},
pages = {1456--1470},
title = {{Comparative study of stock trend prediction using time delay, recurrent and probabilistic neural networks}},
url = {http://ieeexplore.ieee.org/document/728395/},
volume = {9},
year = {1998}
}
@article{slm,
author = {Simo, J. C. and Lewis, D. and Marsden, J. E.},
journal = {Arch. Rational Mech. Anal.},
pages = {15--59},
title = {{Stability of relative equilibria. Part I: The reduced energy-momentum method}},
volume = {115},
year = {1991}
}
@article{scarpadaneLasso,
abstract = {In this paper, we consider the joint task of simultaneously optimizing (i) the weights of a deep neural network, (ii) the number of neurons for each hidden layer, and (iii) the subset of active input features (i.e., feature selection). While these problems are generally dealt with separately, we present a simple regularized formulation allowing to solve all three of them in parallel, using standard optimization routines. Specifically, we extend the group Lasso penalty (originated in the linear regression literature) in order to impose group-level sparsity on the network's connections, where each group is defined as the set of outgoing weights from a unit. Depending on the specific case, the weights can be related to an input variable, to a hidden neuron, or to a bias unit, thus performing simultaneously all the aforementioned tasks in order to obtain a compact network. We perform an extensive experimental evaluation, by comparing with classical weight decay and Lasso penalties. We show that a sparse version of the group Lasso penalty is able to achieve competitive performances, while at the same time resulting in extremely compact networks with a smaller number of input features. We evaluate both on a toy dataset for handwritten digit recognition, and on multiple realistic large-scale classification problems.},
archivePrefix = {arXiv},
arxivId = {1607.00485},
author = {Scardapane, Simone and Comminiello, Danilo and Hussain, Amir and Uncini, Aurelio},
eprint = {1607.00485},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Scardapane et al. - 2016 - Group Sparse Regularization for Deep Neural Networks(2).pdf:pdf},
month = {jul},
title = {{Group Sparse Regularization for Deep Neural Networks}},
url = {http://arxiv.org/abs/1607.00485},
year = {2016}
}
@misc{Pesaran2010,
abstract = {This paper considers combining forecasts generated from the same model but over different estimation windows. It develops theoretical results for random walks with breaks in the drift and volatility and for a linear regression model with a break in the slope parameter. Averaging forecasts over different estimation windows leads to a lower bias and root mean square forecast error than forecasts based on a single estimation window for all but the smallest breaks. An application to weekly returns on 20 equity index futures shows that averaging forecasts over estimation windows leads to a smaller RMSFE than some competing methods.},
author = {Pesaran, M Hashem and Pick, Andreas},
booktitle = {Forecast},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Pesaran, Pick - 2010 - Forecast Combination across Estimation Windows.pdf:pdf},
keywords = {Forecast averaging,estimation windows,exponential down-weighting,structural breaks},
title = {{Forecast Combination across Estimation Windows}},
year = {2010}
}
@article{kloeden2003synchronization,
author = {Kloeden, Peter E},
journal = {Electronic Journal of Differential Equations},
number = {39},
pages = {1--10},
publisher = {Southwest Texas State University, Department of Mathematics, San Marcos, TX{\~{}}{\ldots}},
title = {{Synchronization of nonautonomous dynamical systems.}},
volume = {2003},
year = {2003}
}
@techreport{Arora2005,
author = {Arora, Sanjeev and Hazan, Elad and Kale, Satyen},
title = {{The multiplicative weights update method: a meta algorithm and applications}},
year = {2005}
}
@article{Nesterov1983,
author = {Nesterov, Yurii},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Nesterov - 1983 - A method for solving the convex programming problem with convergence rate o(1k2).pdf:pdf},
journal = {Dokl. Akad. Nauk SSSR},
pages = {543--547},
title = {{A method for solving the convex programming problem with convergence rate o(1/k{\^{}}2)}},
volume = {269},
year = {1983}
}
@phdthesis{perryman:thesis,
author = {Perryman, Paul C.},
pages = {118},
school = {University of California, Irvine},
title = {{Approximation Theory for Deterministic and Stochastic Nonlinear Systems}},
year = {1996}
}
@article{Giacomini2004,
abstract = {In this paper we compare the relative efficiency of different methods of forecasting the aggregate of spatially correlated variables. Small sample simulations confirm the asymptotic result that improved forecasting performance can be obtained by imposing a priori constraints on the amount of spatial correlation in the system. One way to do so is to aggregate forecasts from a space-time autoregressive model (Elements of Spatial Structure, Cambridge University Press, Cambridge, 1975), which offers a solution to the ‘curse of dimensionality' that arises when forecasting with VARs. We also show that ignoring spatial correlation, even when it is weak, leads to highly inaccurate forecasts. Finally, if the system satisfies a ‘poolability' condition, there is a benefit in forecasting the aggregate variable directly.},
author = {Giacomini, Raffaella and Granger, Clive W.J.},
issn = {03044076},
journal = {Journal of Econometrics},
keywords = {c33,c43,c53},
month = {jan},
number = {1-2},
pages = {7--26},
title = {{Aggregation of space-time processes}},
url = {http://dx.doi.org/10.1016/S0304-4076(03)00132-5},
volume = {118},
year = {2004}
}
@article{Rojas2002,
abstract = {Background: Deficits in basic auditory perception have been described in schizophrenia. Previous electrophysiologic imaging research has documented a structure-function disassociation in the auditory system in schizophrenia. This study examines whether the most fundamental level of auditory cortical organization, tonotopy, is altered in schizophrenia. Methods: The tonotopic organization for five tone frequencies in 19 patients with schizophrenia and 22 comparison subjects was evaluated using magnetoencephalography. Auditory evoked magnetic field dipole locations were examined for the N100m component for each frequency. Results: The expected linear relationship between depth and frequency was found in the comparison subjects but not in the schizophrenia group (p {\textless} .004). In addition, normal anterior-posterior asymmetry of the N100m was found to be reduced at all five stimulation frequencies employed in the study (p {\textless} .04). No relationships between clinical symptom ratings and either tonotopy or asymmetry were observed. Conclusions: This finding suggests that the tonotopic organization of the auditory cortex in schizophrenia is disturbed and may help explain the relatively poor behavioral performance of schizophrenia patients on simple frequency discrimination tasks. Alterations in fundamental sensory organization may underlie or interact with higher order cognitive mechanisms to produce changes in cognitive task performance.},
author = {Rojas, Donald C. and Bawn, Susie D. and Carlson, Jon P. and Arciniegas, David B. and Teale, Peter D. and Reite, Martin L.},
issn = {00063223},
journal = {Biological Psychiatry},
keywords = {Magnetoencephalography,auditory cortex,evoked potentials},
month = {jul},
number = {1},
pages = {32--39},
title = {{Alterations in tonotopy and auditory cerebral asymmetry in schizophrenia}},
url = {http://www.sciencedirect.com/science/article/pii/S0006322301013658},
volume = {52},
year = {2002}
}
@article{atiyah:bott:82,
author = {Atiyah, M. F. and Bott, R.},
journal = {Phil. Trans. R. Soc. Lond. A},
pages = {523--615},
title = {{The Yang-Mills equations over Riemann surfaces}},
volume = {308},
year = {1982}
}
@article{Dueker1997,
author = {Dueker, M},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Dueker - 1997 - Strengthening the Case for the Yield Curve as a Predictor of U.S. Recessions.pdf:pdf},
journal = {Review},
number = {1995},
pages = {41--51},
title = {{Strengthening the Case for the Yield Curve as a Predictor of U.S. Recessions}},
url = {http://ideas.repec.org/a/fip/fedlrv/y1997imarp41-51.html},
year = {1997}
}
@article{Idel2017,
abstract = {Given a real-valued positive semidefinite matrix, Williamson proved that it can be diagonalised using symplectic matrices. The corresponding diagonal values are known as the symplectic spectrum. This paper is concerned with the stability of Williamson's decomposition under perturbations. We provide norm bounds for the stability of the symplectic eigenvalues and prove that if S diagonalises a given matrix M to Williamson form, then S is stable if the symplectic spectrum is nondegenerate and STS is always stable. Finally, we sketch a few applications of the results in quantum information theory.},
author = {Idel, Martin and {Soto Gaona}, Sebasti{\'{a}}n and Wolf, Michael M},
doi = {https://doi.org/10.1016/j.laa.2017.03.013},
issn = {0024-3795},
journal = {Linear Algebra and its Applications},
keywords = { Perturbation bounds, Symplectic eigenvalues,Williamson's normal form},
pages = {45--58},
title = {{Perturbation bounds for Williamson's symplectic normal form}},
url = {https://www.sciencedirect.com/science/article/pii/S0024379517301751},
volume = {525},
year = {2017}
}
@article{Jones:kalman,
author = {Jones, Richard H.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Jones - 1980 - Maximum likelihood fitting of ARMA models to time series with missing observations.pdf:pdf},
journal = {Technometrics},
keywords = {missing observations,time series analysis},
number = {3},
pages = {389--395},
title = {{Maximum likelihood fitting of ARMA models to time series with missing observations}},
volume = {22},
year = {1980}
}
@article{schmah2010,
abstract = {We compare 10 methods of classifying fMRI volumes by applying them to data from a longitudinal study of stroke recovery: adaptive Fisher's linear and quadratic discriminant; gaussian naive Bayes; support vector machines with linear, quadratic, and radial basis function (RBF) kernels; logistic regression; two novel methods based on pairs of restricted Boltzmann machines (RBM); and K-nearest neighbors. All methods were tested on three binary classification tasks, and their out-of-sample classification accuracies are compared. The relative performance of the methods varies considerably across subjects and classification tasks. The best overall performers were adaptive quadratic discriminant, support vector machines with RBF kernels, and generatively trained pairs of RBMs.},
author = {Schmah, Tanya and Yourganov, Grigori and Zemel, Richard S and Hinton, Geoffrey E and Small, Steven L. and Strother, Stephen C.},
doi = {10.1162/NECO_a_00024},
isbn = {0899-7667},
issn = {0899-7667},
journal = {Neural computation},
number = {11},
pages = {2729--2762},
pmid = {20804386},
title = {{Comparing classification methods for longitudinal fMRI studies.}},
volume = {22},
year = {2010}
}
@article{remillard:rubenthaler,
author = {R{\'{e}}millard, Bruno and Rubenthaler, Sylvain},
journal = {Quantitative Finance},
number = {6},
pages = {819--825},
title = {{On optimal hedging in discrete time}},
volume = {13},
year = {2014}
}
@book{evens:lu,
author = {Evens, S. and Lu, J.-H.},
booktitle = {Ann. Ecol. Norm. Sup.},
publisher = {To appear in Ann. Ecol. Norm. Sup,},
title = {{On the variety of Lagrangian subalgebras}},
year = {2001}
}
@article{Varin2005,
abstract = {Spatial generalized linear mixed models are flexible models for a variety of applications, where spatially dependent and non-Gaussian random variables are observed. The focus is inference in spatial generalized linear mixed models for large data sets. Maximum likelihood or Bayesian Markov chain Monte Carlo approaches may in such cases be computationally very slow or even prohibitive. Alternatively, one may consider a composite likelihood, which is the product of likelihoods of subsets of data. In particular, a composite likelihood based on pairs of observations is adopted. In order to maximize the pairwise likelihood, a new expectation–maximization-type algorithm which uses numerical quadrature is introduced. The method is illustrated on simulated data and on data from air pollution effects for fish populations in Norwegian lakes. A comparison with alternative methods is given. The proposed algorithm is found to give reasonable parameter estimates and to be computationally efficient.},
author = {Varin, Cristiano and H{\o}st, Gudmund and Skare, {\O}ivind},
doi = {10.1016/j.csda.2004.07.021},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Varin, H{\o}st, Skare - 2005 - Pairwise likelihood inference in spatial generalized linear mixed models.pdf:pdf},
issn = {01679473},
journal = {Computational Statistics {\&} Data Analysis},
keywords = {Composite likelihood,Expectation–maximization algorithm,Gauss–Hermite quadrature,Model-based geostatistics,Pairwise likelihood},
month = {jun},
number = {4},
pages = {1173--1191},
title = {{Pairwise likelihood inference in spatial generalized linear mixed models}},
url = {http://www.sciencedirect.com/science/article/pii/S0167947304002403},
volume = {49},
year = {2005}
}
@article{stam2002generalized,
author = {Stam, Cornelis J and van Walsum, Anne Marie van Cappellen and Pijnenburg, Yolande A L and Berendse, Henk W and de Munck, Jan C and Scheltens, Philip and van Dijk, Bob W},
journal = {Journal of Clinical Neurophysiology},
number = {6},
pages = {562--574},
publisher = {LWW},
title = {{Generalized synchronization of MEG recordings in Alzheimer's disease: evidence for involvement of the gamma band}},
volume = {19},
year = {2002}
}
@book{sastrybook,
author = {Sastry, Shankar},
publisher = {Springer-Verlag},
title = {{Nonlinear Systems. Analysis, Stability, and Control}},
year = {1999}
}
@article{weightedls,
author = {Rekic-Vukovic, Amra and Okicic, Nermin and Dunjakovic, Enes},
journal = {Advances in Mathematics: Scientific Journal},
number = {2},
pages = {127--138},
title = {{On weighted Banach sequence spaces}},
volume = {4},
year = {2015}
}
@article{Tiao1972,
abstract = {The problem of modelling and forecasting temporal aggregates of time series is discussed. Let zt be the basic series and xT be the m-component temporal aggregatos. Forecasts of future xT may be constructed from data on (i) zt or (ii) xT. It is shown that, for large m, there is no gain in using the basic data if zt is stationary, but considerable gain can be obtained when zt is nonstationary.},
author = {Tiao, G. C.},
doi = {10.1093/biomet/59.3.525},
issn = {0006-3444},
journal = {Biometrika},
month = {dec},
number = {3},
pages = {525--531},
title = {{Asymptotic behaviour of temporal aggregates of time series}},
url = {http://biomet.oxfordjournals.org/cgi/content/abstract/59/3/525},
volume = {59},
year = {1972}
}
@article{SEstationary,
author = {Brandt, Andreas},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Brandt - 1986 - The Stochastic Equation Yn1=AnYnBn with Stationary Coefficients.pdf:pdf},
journal = {Advances in Applied Probability},
number = {1},
pages = {211--220},
title = {{The Stochastic Equation Yn+1=AnYn+Bn with Stationary Coefficients}},
volume = {18},
year = {1986}
}
@article{vortices:lim,
author = {Lim, C. and Montaldi, J. A. and Roberts, R. M.},
journal = {Physica D.},
pages = {97--135},
title = {{Relative equilibria of point vortices on the sphere}},
volume = {148},
year = {2001}
}
@article{Badescu:Ortega:jedc,
author = {Badescu, Alex and Elliott, Robert J and Ortega, Juan-Pablo},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Badescu, Elliott, Ortega - 2014 - Quadratic hedging schemes for non-Gaussian GARCH models.pdf:pdf},
journal = {Journal of Economic Dynamics and Control},
pages = {13--32},
title = {{Quadratic hedging schemes for non-Gaussian GARCH models}},
volume = {42},
year = {2014}
}
@article{Geweke2010,
abstract = {Bayesian inference in a time series model provides exact out-of-sample predictive distributions that fully and coherently incorporate parameter uncertainty. This study compares and evaluates Bayesian predictive distributions from alternative models, using as an illustration five alternative models of asset returns applied to daily S{\&}P 500 returns from the period 1976 through 2005. The comparison exercise uses predictive likelihoods and is inherently Bayesian. The evaluation exercise uses the probability integral transformation and is inherently frequentist. The illustration shows that the two approaches can be complementary, with each identifying strengths and weaknesses in models that are not evident using the other.},
author = {Geweke, John and Amisano, Gianni},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {forecasting,garch,inverse probability transformation,markov mixture,predictive likelihood,s{\&}p 500 returns,stochastic volatility},
month = {apr},
number = {2},
pages = {216--230},
title = {{Comparing and evaluating Bayesian predictive distributions of asset returns}},
url = {http://dx.doi.org/10.1016/j.ijforecast.2009.10.007},
volume = {26},
year = {2010}
}
@article{Xue2017,
abstract = {Recently, echo state network (ESN) has attracted a great deal of attention due to its high accuracy and efficient learning performance. Compared with the traditional random structure and classical sigmoid units, simple circle topology and leaky integrator neurons have more advantages on reservoir computing of ESN. In this paper, we propose a new model of ESN with both circle reservoir structure and leaky integrator units. By comparing the prediction capability on Mackey-Glass chaotic time series of four ESN models: classical ESN, circle ESN, traditional leaky integrator ESN, circle leaky integrator ESN, we find that our circle leaky integrator ESN shows significantly better performance than other ESNs with roughly 2 orders of magnitude reduction of the predictive error. Moreover, this model has stronger ability to approximate nonlinear dynamics and resist noise than conventional ESN and ESN with only simple circle structure or leaky integrator neurons. Our results show that the combination of circle topology and leaky integrator neurons can remarkably increase dynamical diversity and meanwhile decrease the correlation of reservoir states, which contribute to the significant improvement of computational performance of Echo state network on time series prediction.},
author = {Xue, Fangzheng and Li, Qian and Li, Xiumin},
doi = {10.1371/journal.pone.0181816},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Xue, Li, Li - 2017 - The combination of circle topology and leaky integrator neurons remarkably improves the performance of echo state n.pdf:pdf},
issn = {1932-6203},
journal = {PloS one},
number = {7},
pages = {e0181816},
pmid = {28759581},
publisher = {Public Library of Science},
title = {{The combination of circle topology and leaky integrator neurons remarkably improves the performance of echo state network on time series prediction.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/28759581 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC5536322},
volume = {12},
year = {2017}
}
@article{nfm1,
author = {Marle, C.-M.},
editor = {Dazord, P. and Desolneux-Moulis, N.},
journal = {S{\'{e}}minaire Sud-Rhodanien de G{\'{e}}om{\'{e}}trie II},
pages = {19--35},
title = {{Le voisinage d'une orbite d'uneaction hamiltonienne d'un groupe de Lie}},
year = {1984}
}
@book{Marie:Duflo,
author = {Duflo, Marie},
doi = {10.2307/2669576},
isbn = {9783642081750},
issn = {01621459},
publisher = {Springer-Verlag Berlin Heidelberg},
title = {{Random Iterative Models}},
year = {1997}
}
@book{Hartman,
author = {Hartman, Philip},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Hartman - Unknown - Ordinary Differential Equations.pdf:pdf},
title = {{Ordinary Differential Equations}}
}
@article{Guhaniyogi2016,
author = {Guhaniyogi, Rajarshi and Dunson, David B.},
journal = {Journal of Machine Learning Reasearch},
title = {{Compressed Gaussian process for manifold regression}},
volume = {17},
year = {2016}
}
@article{Bartlett2006,
author = {Bartlett, Peter L. and Jordan, Michael I. and Mcauliffe, Jon D.},
journal = {Journal of the American Statistical Association},
number = {473},
pages = {138--156},
title = {{Convexity, classification, and risk bounds}},
volume = {101},
year = {2006}
}
@book{Bousquet2016,
author = {Bousquet, Olivier and Boucheron, St{\'{e}}phane and Lugosi, G{\'{a}}bor},
title = {{Introduction to Statistical Learning Theory: Lecture Notes}},
year = {2016}
}
@article{BS2004,
author = {Bauwens, Luc and Veredas, David},
journal = {Journal of Econometrics},
number = {2},
pages = {381--412},
title = {{The stochastic conditional duration model: A latent factor model for the analysis of financial durations}},
volume = {119},
year = {2004}
}
@article{corticalMaass,
abstract = {It is quite difficult to construct circuits of spiking neurons that can carry out complex computational tasks. On the other hand even randomly connected circuits of spiking neurons can in principle be used for complex computational tasks such as time-warp invariant speech recognition. This is possible because such circuits have an inherent tendency to integrate incoming information in such a way that simple linear readouts can be trained to transform the current circuit activity into the target output for a very large number of computational tasks. Consequently we propose to analyze circuits of spiking neurons in terms of their roles as analog fading memory and non-linear kernels, rather than as implementations of specific computational operations and algorithms. This article is a sequel to [W. Maass, T. Natschl{\"{a}}ger, H. Markram, Real-time computing without stable states: a new framework for neural computation based on perturbations, Neural Comput. 14 (11) (2002) 2531-2560, Online available as {\#}130 from: {\textless}http://www.igi.tugraz.at/maass/publications.html{\textgreater}], and contains new results about the performance of generic neural microcircuit models for the recognition of speech that is subject to linear and non-linear time-warps, as well as for computations on time-varying firing rates. These computations rely, apart from general properties of generic neural microcircuit models, just on capabilities of simple linear readouts trained by linear regression. This article also provides detailed data on the fading memory property of generic neural microcircuit models, and a quick review of other new results on the computational power of such circuits of spiking neurons.},
author = {Maass, Wolfgang and Natschl{\"{a}}ger, Thomas and Markram, Henry},
doi = {10.1016/j.jphysparis.2005.09.020},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Maass, Natschl{\"{a}}ger, Markram - 2004 - Fading memory and kernel properties of generic cortical microcircuit models.pdf:pdf},
isbn = {0928-4257 (Print)$\backslash$n0928-4257 (Linking)},
issn = {09284257},
journal = {Journal of Physiology Paris},
keywords = {Analog memory,Computational models,Computational power,Linear regression,Neural circuits,Non-linear kernels,Speech processing,Spiking neurons},
number = {4-6 SPEC. ISS.},
pages = {315--330},
pmid = {16310350},
title = {{Fading memory and kernel properties of generic cortical microcircuit models}},
volume = {98},
year = {2004}
}
@phdthesis{Baztarrica2002,
abstract = {Recent advances in computer hardware and signal processing have made possible the use of EEG signals or “brain waves” for communication between humans and computers. Locked-in patients have now a way to communicate with the outside world, but even with the last modern techniques, such systems still suffer communication rates on the order of 2-3 tasks/minute. In addition, existing systems are not likely to be designed with flexibility in mind, leading to slow systems that are difficult to improve. a technique This diploma project explores the effectiveness of Time – Frequency Analysis as of classifying different mental tasks through the use of the electroencephalogram (EEG). EEG signals from several subjects through 6 channels (electrodes) have been studied during the performance of five mental tasks (a baseline resting task, mental multiplication, geometric figure rotation, mental letter composition, and counting). Improved off-line classification of two of them (“geometric figure rotation” and “mental letter composition”), for which poor results had been obtained with autoregressive models before, were the principal objective of this project. Different methods based on Time Frequency Representations have been considered for the classification between the two tasks mentioned above. A non-iterative method based on the Ambiguity Function was finally selected. The results indicate that this method is able to extract in half-second, distinguishing features from the data, that could be classified as belonging to one of the two tasks with an average percentage accuracy which tends to zero. The same results were found when the method was exported for five tasks EEG signal classification. The work presented here is a part of a larger project, whose goal is to classify EEG signals belonging to a varied set of mental activities in a real time Brain Computer Interface, in order to investigate the feasibility of using different mental tasks as a wide communication channel between people and computers.},
author = {{Baztarrica Ochoa}, Jorge},
isbn = {012466606X},
pages = {1--72},
title = {{EEG signal classification for brain computer interface applications}},
year = {2002}
}
@article{Abel2013a,
abstract = {The development of silicon photonics could greatly benefit from the linear electro-optical properties, absent in bulk silicon, of ferroelectric oxides, as a novel way to seamlessly connect the electrical and optical domain. Of all oxides, barium titanate exhibits one of the largest linear electro-optical coefficients, which has however not yet been explored for thin films on silicon. Here we report on the electro-optical properties of thin barium titanate films epitaxially grown on silicon substrates. We extract a large effective Pockels coefficient of r(eff) = 148 pm V(-1), which is five times larger than in the current standard material for electro-optical devices, lithium niobate. We also reveal the tensor nature of the electro-optical properties, as necessary for properly designing future devices, and furthermore unambiguously demonstrate the presence of ferroelectricity. The integration of electro-optical active films on silicon could pave the way towards power-efficient, ultra-compact integrated devices, such as modulators, tuning elements and bistable switches.},
author = {Abel, Stefan and St{\"{o}}ferle, Thilo and Marchiori, Chiara and Rossel, Christophe and Rossell, Marta D M D Marta D and Erni, Rolf and Caimi, Daniele and Sousa, Marilyne and Chelnokov, Alexei and Offrein, Bert J B J Bert J and Fompeyrine, Jean},
doi = {10.1038/ncomms2695},
issn = {2041-1723},
journal = {Nature Communications},
pages = {1671},
pmid = {23575675},
publisher = {Nature Publishing Group},
title = {{A strong electro-optically active lead-free ferroelectric integrated on silicon}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23575675 http://www.nature.com/doifinder/10.1038/ncomms2695},
volume = {4},
year = {2013}
}
@book{Rasmussen:book:2007,
author = {Rasmussen, Martin},
booktitle = {Lecture Notes in Mathematics},
doi = {10.1007/978-3-540-71225-1},
isbn = {3540712240},
issn = {00758434},
pages = {1--224},
publisher = {Springer Berlin Heidelberg},
title = {{Attractivity and Bifurcation for Nonautonomous Dynamical Systems}},
volume = {1907},
year = {2007}
}
@phdthesis{Ekeblom2006,
author = {Ekeblom, Daniel},
booktitle = {Current},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Ekeblom - 2006 - What is the Probability of a Recession in the United States.pdf:pdf},
school = {Lund University, Sweden},
title = {{What is the Probability of a Recession in the United States ?}},
year = {2006}
}
@inproceedings{Stulp2012,
author = {Stulp, Freek and Sigaud, Oliver},
booktitle = {ICML},
title = {{Path integral policy improvement with covariance matrix adaptation}},
year = {2012}
}
@article{Palmowski2002,
author = {Palmowski, Zbigniew and Rolski, Tomasz},
issn = {1350-7265},
journal = {Bernoulli},
keywords = {Cameron-Martin-Girsanov theorem,Markov additive process,Markov process,diffusion process,exponential change of measure,extended generator,local martingale,piecewise deterministic Markov process},
language = {EN},
month = {dec},
number = {6},
pages = {767--785},
publisher = {Bernoulli Society for Mathematical Statistics and Probability},
title = {{A technique for exponential change of measure for Markov processes}},
url = {http://projecteuclid.org/euclid.bj/1076364805},
volume = {8},
year = {2002}
}
@article{Cartea2011,
abstract = {Using high frequency data for the price dynamics of equities we measure the impact that market microstructure noise has on estimates of the: (i) volatility of returns; and (ii) variance–covariance matrix of n assets. We propose a Kalman-filter-based methodology that allows us to deconstruct price series into the true efficient price and the microstructure noise. This approach allows us to employ volatility estimators that achieve very low Root Mean Squared Errors (RMSEs) compared to other estimators that have been proposed to deal with market microstructure noise at high frequencies. Furthermore, this price series decomposition allows us to estimate the variance covariance matrix of n assets in a more efficient way than the methods so far proposed in the literature. We illustrate our results by calculating how microstructure noise affects portfolio decisions and calculations of the equity beta in a CAPM setting.},
author = {Cartea, {\'{A}}lvaro and Karyampas, Dimitrios},
issn = {03784266},
journal = {Journal of Banking {\&} Finance},
keywords = {C22,Covariation of assets,G12,G14,High-frequency data,Kalman filter,Market microstructure noise,Volatility estimation},
month = {dec},
number = {12},
pages = {3319--3334},
title = {{Volatility and covariation of financial assets: A high-frequency analysis}},
url = {http://www.sciencedirect.com/science/article/pii/S0378426611001737},
volume = {35},
year = {2011}
}
@book{White1959,
address = {New York},
author = {White, David C. and Woodson, Herbert H.},
publisher = {John Wiley {\&} Sons},
title = {{Electromechanical energy conversion}},
year = {1959}
}
@book{bc,
author = {Brickell, F. and Clark, R. S.},
publisher = {VanNostrand Reinhold Company},
title = {{Differentiable Manifolds, An Introduction}},
year = {1970}
}
@article{Lutkepohl2009,
abstract = {Aggregated times series variables can be forecasted in diﬀerent ways. For exam- ple, they may be forecasted on the basis of the aggregate series or forecasts of disaggregated variables may be obtained ﬁrst and then these forecasts may be aggregated. A number of forecasts are presented and compared. Classical theoretical results on the relative eﬃciencies of diﬀerent forecasts are reviewed and some complications are discussed which invalidate the theoretical results. Contemporaneous as well as temporal aggregation are considered.},
author = {L{\"{u}}tkepohl, Helmut},
file = {:Users/JP17/Dropbox/JPO{\_}synch/Mendeley//L{\"{u}}tkepohl - 2010 - Forecasting aggregated time series variables A survey.pdf:pdf;:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/L{\"{u}}tkepohl - 2009 - Forecasting Aggregated Time Series Variables.pdf:pdf},
journal = {Journal of Business Cycle Measurement and Analysis},
keywords = {Autoregressive moving-average process,contemporane-,ous aggregation,temporal aggregation,vector autoregressive moving-average process},
number = {2},
pages = {1--26},
title = {{Forecasting aggregated time series variables: A survey}},
url = {http://www.isae.it/MFC/2009/lutkepohl.pdf http://cadmus.eui.eu/handle/1814/11256},
volume = {2010},
year = {2010}
}
@book{Kloeden:Rasmussen,
author = {Kloeden, Peter E. and Rasmussen, Martin},
doi = {10.3934/dcdsb.2015.20.703},
isbn = {9780821868713},
issn = {1531-3492},
publisher = {American Mathematical Society},
title = {{Nonautonomous Dynamical Systems}},
url = {http://www.aimsciences.org/journals/displayArticlesnew.jsp?paperID=10767},
year = {2010}
}
@book{Bauer:probability,
author = {Bauer, Heinz},
pages = {523},
publisher = {de Gruyter},
title = {{Probability Theory}},
year = {1996}
}
@misc{Rossi2011a,
abstract = {This paper proposes new methodologies for evaluating out-of-sample forecasting performance that are robust to the choice of the estimation window size. The method- ologies involve evaluating the predictive ability of forecasting models over a wide range of window sizes. We show that the tests proposed in the literature may lack power to detect predictive ability, and might be subject to data snooping across di¤erent window sizes if used repeatedly. An empirical application shows the usefulness of the methodologies for evaluating exchange rate models'forecasting ability},
author = {Rossi, Barbara and Inoue, Atsushi},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Rossi, Inoue - 2011 - Out-of-Sample Forecast Tests Robust to the Window Size Choice.pdf:pdf},
keywords = {Estimation Window.,Forecast Evaluation,Predictive Ability Testing},
title = {{Out-of-Sample Forecast Tests Robust to the Window Size Choice}},
year = {2011}
}
@article{Kuznetsov2017,
abstract = {This paper presents the first generalization bounds for time series pre-diction with a non-stationary mixing stochastic process. We prove Rademacher complexity learning bounds for both average-path generalization with non-station-ary $\beta$-mixing processes and path-dependent generalization with non-stationary $\phi$-mixing processes. Our guarantees are expressed in terms of $\beta$-or $\phi$-mixing coef-ficients and a natural measure of discrepancy between training and target distri-butions. They admit as special cases previous Rademacher complexity bounds for non-i.i.d. stationary distributions, for independent but not identically distributed random variables, or for the i.i.d. case. We show that, using a new sub-sample selection technique we introduce, our bounds can be tightened under the natu-ral assumption of asymptotically stationary stochastic processes. We also prove that fast learning rates can be achieved by extending existing local Rademacher complexity analyses to the non-i.i.d. setting. We conclude the paper by providing generalization bounds for learning with unbounded losses and non-i.i.d. data.},
author = {Kuznetsov, Vitaly and Mohri, Mehryar},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Kuznetsov, Mohri - 2017 - Generalization bounds for non-stationary mixing processes.pdf:pdf},
journal = {Machine Learning},
keywords = {Asymptotic stationarity,Fast rates,Generalization bounds,Local Rademacher complexity,Markov processes,Mixing,Non-stationary processes,Time series,Unbounded loss},
number = {1},
pages = {93--117},
publisher = {Springer US},
title = {{Generalization bounds for non-stationary mixing processes}},
volume = {106},
year = {2017}
}
@article{Ortega1999a,
author = {Ortega, Juan-Pablo and Ratiu, Tudor S.},
journal = {Nonlinearity},
pages = {693--720},
title = {{Stability of Hamiltonian relative equilibria}},
volume = {12},
year = {1999}
}
@book{bou,
author = {Bourbaki, N},
publisher = {Hermann},
title = {{Vari{\{}{\'{e}}{\}}t{\{}{\'{e}}{\}}s diff{\{}{\'{e}}{\}}rentielles et analytiques. Fascicule de r{\{}{\'{e}}{\}}sultats}},
year = {1971}
}
@article{Lutkepohl1985,
author = {L{\"{u}}tkepohl, Helmut},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/L{\"{u}}tkepohl - 1985 - The joint asymptotic distribution of multistep prediction errors of estimated vector autoregressions.pdf:pdf},
journal = {Economic Letters},
pages = {103--106},
title = {{The joint asymptotic distribution of multistep prediction errors of estimated vector autoregressions}},
volume = {17},
year = {1985}
}
@article{Sun1999,
abstract = {grantor: University of Toronto},
author = {Sun, Xiang and Xiang},
keywords = {Thesis},
publisher = {National Library of Canada = Biblioth{\`{e}}que nationale du Canada},
title = {{The Lasso and its implementation for neural networks}},
year = {1999}
}
@article{Martinenghi:2012,
author = {Martinenghi, R. and Rybalko, S. and Jacquot, M. and Chembo, Y. K. and Larger, Laurent},
journal = {Phys. Rev. Lett.},
pages = {244101},
title = {{Photonic non-linear transient computing with multiple-delay wavelength dynamics}},
volume = {108},
year = {2012}
}
@article{Mocanu2018,
author = {Mocanu, Decebal Constantin and Mocanu, Elena and Stone, Peter and Nguyen, Phuong H. and Gibescu, Madeleine and Liotta, Antonio},
journal = {Nature Communications},
title = {{Scalable training of artificial neural networks with adaptive sparse connectivity inspired by network science}},
volume = {9},
year = {2018}
}
@inproceedings{hanson2019universal,
author = {Hanson, Joshua and Raginsky, Maxim},
booktitle = {Advances in Neural Information Processing Systems},
pages = {14071--14081},
title = {{Universal approximation of input-output maps by temporal convolutional nets}},
year = {2019}
}
@unpublished{Silvestrini2005,
abstract = {In this paper we feature state-of-the-art econometric methodology of temporal aggre- gation for univariate linear time series, namely ARIMA-GARCH models. We present a unified overview of temporal aggregation techniques for this broad class of processes and we explain in detail, although intuitively, the technical machinery behind the results. An empirical application with Belgian public deficit data illustrates the main issues.},
author = {Silvestrini, Andrea and Veredas, David},
institution = {Core Discussion Paper},
keywords = {ARIMA,GARCH,Temporal aggregation,seasonality},
title = {{Temporal aggregation of univariate linear time series models}},
url = {http://webdoc.sub.gwdg.de/ebook/serien/e/CORE/dp2005{\_}59.pdf},
year = {2005}
}
@techreport{Bauer2017,
author = {Bauer, Benedikt and Kohler, Michael},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley//Bauer, Kohler - 2017 - On deep learning as a remedy for the curse of dimensionality in nonparametric regression.pdf:pdf},
title = {{On deep learning as a remedy for the curse of dimensionality in nonparametric regression}},
year = {2017}
}
@article{Qin2008,
abstract = {Previous studies implicated potential value of mismatch negativity (MMN) in predicting recovery of consciousness in patients with disorders of consciousness (DOC). We have adopted a novel MMN evoked by subject's own name (SON), a self-referential stimulus thought to be powerful in evoking residual brain activity, and examined the correlation between the MMN and recovery of consciousness in patients with chronic ({\textgreater}1 month) DOC. Twelve patients and 12 age-matched healthy controls were investigated. The patients were diagnosed as coma (n=4), vegetative state (VS, n=6), and minimally conscious state (MCS, n=2), mainly based on the JFK Coma Recovery Scale-Revised. The SON-evoked MMN (SON-MMN) was present in seven patients. Critically, the presence of SON-MMN was significantly correlated with recovery of consciousness. While four of the five patients (three VS and two coma) showing SON-MMN changed to MCS 3 months later, the rest of the patients (three VS and two coma) without SON-MMN failed to show any clinical improvement. Our study thus illustrates that the subject's own name is effective in evoking MMN in patients with DOC, and that SON-MMN has potential prognostic values in predicting recovery of consciousness.},
author = {Qin, Pengmin and Di, Haibo and Yan, Xiaodan and Yu, Senming and Yu, Dan and Laureys, Steven and Weng, Xuchu},
issn = {0304-3940},
journal = {Neuroscience letters},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Adolescent,Adult,Auditory Perception,Case-Control Studies,Chronic Disease,Consciousness Disorders,Consciousness Disorders: physiopathology,Contingent Negative Variation,Contingent Negative Variation: physiology,Electroencephalography,Evoked Potentials, Auditory,Evoked Potentials, Auditory: physiology,Female,Follow-Up Studies,Glasgow Coma Scale,Humans,Male,Middle Aged,Names},
month = {dec},
number = {1},
pages = {24--8},
title = {{Mismatch negativity to the patient's own name in chronic disorders of consciousness.}},
url = {http://www.sciencedirect.com/science/article/pii/S030439400801416X},
volume = {448},
year = {2008}
}
@book{bourbaki:topology:1-4,
author = {Bourbaki, N.},
chapter = {1-4},
publisher = {Springer-Verlag},
title = {{General Topology}},
year = {1989}
}
@article{pathak2018,
abstract = {A model-based approach to forecasting chaotic dynamical systems utilizes knowledge of the mechanistic processes governing the dynamics to build an approximate mathematical model of the system. In contrast, machine learning techniques have demonstrated promising results for forecasting chaotic systems purely from past time series measurements of system state variables (training data), without prior knowledge of the system dynamics. The motivation for this paper is the potential of machine learning for filling in the gaps in our underlying mechanistic knowledge that cause widely-used knowledge-based models to be inaccurate. Thus, we here propose a general method that leverages the advantages of these two approaches by combining a knowledge-based model and a machine learning technique to build a hybrid forecasting scheme. Potential applications for such an approach are numerous (e.g., improving weather forecasting). We demonstrate and test the utility of this approach using a particular illustrative version of a machine learning known as reservoir computing, and we apply the resulting hybrid forecaster to a low-dimensional chaotic system, as well as to a high-dimensional spatiotemporal chaotic system. These tests yield extremely promising results in that our hybrid technique is able to accurately predict for a much longer period of time than either its machine-learning component or its model-based component alone.},
archivePrefix = {arXiv},
arxivId = {1803.04779},
author = {Pathak, Jaideep and Wikner, Alexander and Fussell, Rebeckah and Chandra, Sarthak and Hunt, Brian R. and Girvan, Michelle and Ott, Edward},
doi = {10.1063/1.5028373},
eprint = {1803.04779},
issn = {10541500},
journal = {Chaos},
number = {4},
title = {{Hybrid forecasting of chaotic processes: Using machine learning in conjunction with a knowledge-based model}},
volume = {28},
year = {2018}
}
@article{Ng2002,
author = {Ng, Andrew and Jordan, Michael I.},
journal = {Advances in Neural Information Processing Systems},
title = {{On discriminative vs. generative classifiers: A comparison of logistic regression and naive bayes}},
volume = {14},
year = {2002}
}
@article{ComteLiebermanMGARCH,
author = {Comte, F. and Lieberman, O.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Comte, Lieberman - 2003 - Asymptotic theory for multivariate GARCH processes.pdf:pdf},
journal = {Journal of Multivariate Analysis},
pages = {61--84},
title = {{Asymptotic theory for multivariate GARCH processes}},
volume = {84},
year = {2003}
}
@article{Silvestrini2007a,
author = {Silvestrini, Andrea and Salto, Matteo and Moulin, Laurent and Veredas, David},
doi = {10.1007/s00181-007-0132-7},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Silvestrini et al. - 2007 - Monitoring and forecasting annual public deficit every month the case of France.pdf:pdf},
issn = {0377-7332},
journal = {Empirical Economics},
month = {feb},
number = {3},
pages = {493--524},
title = {{Monitoring and forecasting annual public deficit every month: the case of France}},
url = {http://www.springerlink.com/index/10.1007/s00181-007-0132-7},
volume = {34},
year = {2007}
}
@article{ceni:ashwin:paper1,
abstract = {Machine learning provides fundamental tools both for scientific research and for the development of technologies with significant impact on society. It provides methods that facilitate the discovery of regularities in data and that give predictions without explicit knowledge of the rules governing a system. However, a price is paid for exploiting such flexibility: machine learning methods are typically black boxes where it is difficult to fully understand what the machine is doing or how it is operating. This poses constraints on the applicability and explainability of such methods. Our research aims to open the black box of recurrent neural networks, an important family of neural networks used for processing sequential data. We propose a novel methodology that provides a mechanistic interpretation of behaviour when solving a computational task. Our methodology uses mathematical constructs called excitable network attractors, which are invariant sets in phase space composed of stable attractors and excitable connections between them. As the behaviour of recurrent neural networks depends both on training and on inputs to the system, we introduce an algorithm to extract network attractors directly from the trajectory of a neural network while solving tasks. Simulations conducted on a controlled benchmark task confirm the relevance of these attractors for interpreting the behaviour of recurrent neural networks, at least for tasks that involve learning a finite number of stable states and transitions between them.},
archivePrefix = {arXiv},
arxivId = {1807.10478},
author = {Ceni, Andrea and Ashwin, Peter and Livi, Lorenzo},
doi = {10.1007/s12559-019-09634-2},
eprint = {1807.10478},
isbn = {1255901909634},
issn = {18669964},
journal = {Cognitive Computation},
keywords = {Bifurcations,Dynamical systems,Network attractors,Recurrent neural networks},
number = {2},
pages = {330--356},
publisher = {Cognitive Computation},
title = {{Interpreting recurrent neural networks behaviour via excitable network attractors}},
volume = {12},
year = {2020}
}
@book{artin,
address = {New York},
author = {Artin, E.},
publisher = {Interscience},
title = {{Geometric Algebra}},
year = {1963}
}
@article{aref2002development,
author = {Aref, Hassan},
journal = {Physics of Fluids},
number = {4},
pages = {1315--1325},
publisher = {American Institute of Physics},
title = {{The development of chaotic advection}},
volume = {14},
year = {2002}
}
@article{dazord:1985,
author = {Dazord, P.},
journal = {Nederl. Akad. Wetensch. Indag. Math.},
pages = {21--39},
title = {{Feuilletages {\`{a}} singularit{\'{e}}s}},
volume = {47},
year = {1985}
}
@article{tino:symmetric,
abstract = {We study asymptotic properties of Fisher memory of linear Echo State Networks with randomized symmetric state space coupling. In particular, two reservoir constructions are considered: (1) More direct dynamic coupling construction using a class of Wigner matrices and (2) positive semi-definite dynamic coupling obtained as a product of unconstrained stochastic matrices. We show that the maximal Fisher memory is achieved when the input-to-state coupling is collinear with the dominant eigenvector of the reservoir coupling matrix. In the case of Wigner reservoirs we show that as the system size grows, the contribution to the Fisher memory of self-coupling of reservoir units is negligible. We also prove that when the input-to-state coupling is collinear with the sum of eigenvectors of the state space coupling, the expected normalized memory is four and eight time smaller than the maximal memory value for the Wigner and product constructions, respectively.},
author = {Tino, Peter},
doi = {10.1016/j.neucom.2017.11.076},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Echo State Network,Fisher memory of dynamical systems,Recurrent neural network,Reservoir Computing},
pages = {4--8},
publisher = {Elsevier B.V.},
title = {{Asymptotic Fisher memory of randomized linear symmetric Echo State Networks}},
url = {https://doi.org/10.1016/j.neucom.2017.11.076},
volume = {298},
year = {2018}
}
@article{Chen2012,
abstract = {This paper presents a systematic study on the properties of blocked linear systems that have resulted from blocking discrete-time linear time invariant systems. The main idea is to explore the relationship between the blocked and the unblocked systems. Existing results are reviewed and a number of important new results are derived. Focus is given particularly on the zero properties of the blocked system as no such study has been found in the literature.},
author = {Chen, Weitian and Anderson, Brian D.O. and Deistler, Manfred and Filler, Alexander},
issn = {00051098},
journal = {Automatica},
keywords = {linear systems,system blocking or lifting,system zeros},
month = {oct},
number = {10},
pages = {2520--2525},
title = {{Properties of blocked linear systems}},
url = {http://dx.doi.org/10.1016/j.automatica.2012.06.020},
volume = {48},
year = {2012}
}
@article{BROADIE2007,
author = {Broadie, Mark and Chernov, Mikhail and Johannes, Michael},
issn = {00221082},
journal = {The Journal of Finance},
month = {jun},
number = {3},
pages = {1453--1490},
title = {{Model specification and risk premia: evidence from futures options}},
url = {http://doi.wiley.com/10.1111/j.1540-6261.2007.01241.x},
volume = {62},
year = {2007}
}
@article{RC15,
author = {Gonon, Lukas and Grigoryeva, Lyudmila and Ortega, Juan-Pablo},
journal = {Physica D},
number = {132721},
pages = {1--13.},
title = {{Memory and forecasting capacities of nonlinear recurrent networks}},
volume = {414},
year = {2020}
}
@misc{Rodriguez2011,
author = {Rodriguez, Abel and Puggioni, Gavino},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Rodriguez, Puggioni - 2011 - Bayesian model selection approaches to MIDAS regression.pdf:pdf},
keywords = {gross national product,interest rates,mixed frequency data,model averaging,model selection},
number = {1991},
title = {{Bayesian model selection approaches to MIDAS regression}},
year = {2011}
}
@unpublished{Carriero2009,
author = {Carriero, Andrean and Kapetanios, George and Marcellino, Massimiliano},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Carriero, Kapetanios, Marcellino - 2009 - Forecasting large datasets with bayesian reduced rank multivariate models.pdf:pdf},
institution = {EUI},
series = {Department of Economics},
title = {{Forecasting large datasets with bayesian reduced rank multivariate models}},
year = {2009}
}
@article{Bae2011,
abstract = {Since the Asian financial crisis in 1997–98, Asian countries have made continuous efforts to promote monetary and financial cooperation for developing regionally well-established bond markets. This paper empirically evaluates the developments of bond markets in the East-Asia region based on the recently developed empirical methodology of dynamic cross-country bond yield interactions. To this end, we use a two-step state space model to examine the existence of the global and regional factor and analyze the effect of both factors on four Asian countries' yield curves. We find that both global and regional factors play an important role in explaining these countries' yield factors, although the regional factor appears to have a smaller role than the global factor and that this result seems to be robust to different subsamples. We interpret this result as evidence on the existence of the regional commonality and on endeavors toward Asian bond markets.},
author = {Bae, Byung Yoon and Kim, Dong Heon},
issn = {1016-8737},
journal = {International Economic Journal},
keywords = {Bond market,C5,E4,F3,G1,Kalman filter,Term structure,dynamic factor model,global yield,regional yield},
language = {en},
month = {dec},
number = {4},
pages = {717--738},
publisher = {Routledge},
title = {{Global and Regional Yield Curve Dynamics and Interactions: The Case of Some Asian Countries}},
url = {http://www.tandfonline.com/doi/abs/10.1080/10168737.2011.636632{\#}.VQp-SFoi6ao},
volume = {25},
year = {2011}
}
@book{karatzas:shreve,
address = {New York, NY},
author = {Karatzas, Ioannis and Shreve, Steven E.},
doi = {10.1007/978-1-4684-0302-2},
isbn = {978-1-4684-0304-6},
publisher = {Springer US},
series = {Graduate Texts in Mathematics},
title = {{Brownian Motion and Stochastic Calculus}},
url = {http://www.springerlink.com/index/10.1007/978-1-4684-0302-2},
volume = {113},
year = {1988}
}
@unpublished{Lewis2002,
author = {Lewis, Andrew},
title = {{A brief on controllability of nonlinear systems}},
year = {2002}
}
@book{Horn:Johnson,
address = {Cambridge},
annote = {Corrected reprint of the 1991 original},
author = {Horn, Roger A. and Johnson, Charles R.},
isbn = {0-521-46713-6},
pages = {viii+607},
publisher = {Cambridge University Press},
title = {{Topics in matrix analysis}},
year = {1994}
}
@article{rossenbaum2010,
author = {Robert, Christian Y. and Rossenbaum, Mathieu},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Robert, Rossenbaum - 2010 - Volatility and covariation estimation when miscrostructure noise and trading times are endogeous.pdf:pdf},
journal = {Mathematical Finance},
title = {{Volatility and covariation estimation when miscrostructure noise and trading times are endogeous}},
year = {2010}
}
@article{RC12,
author = {Gonon, Lukas and Grigoryeva, Lyudmila and Ortega, Juan-Pablo},
institution = {In preparation},
journal = {arXiv preprint 2002.05933},
title = {{Approximation error estimates for random neural networks and reservoir systems}},
year = {2020}
}
@unpublished{corsi2017,
author = {Buccheri, Giuseppe and Bormetti, Giacomo and Corsi, Fulvio and Lillo, Fabrizio},
title = {{A score-driven conditional correlation model for noisy and asynchronous data: an application to high-frequency covariance dynamics}},
year = {2017}
}
@inproceedings{albert:dazord:1988,
address = {Lyon},
author = {Albert, C and Dazord, P},
booktitle = {Travaux du S{\$}\backslash{\$}'eminaire Sud Rhodanien de G{\$}\backslash{\$}'eom{\$}\backslash{\$}'etrie, II},
chapter = {I},
pages = {51--105},
publisher = {Univ. Claude-Bernard. Publ. D{\$}\backslash{\$}'ep. Math. Nouvelle S{\$}\backslash{\$}'er. B},
title = {{Th{\{}{\'{e}}{\}}orie des groupo{\{}{\"{i}}{\}}des symplectiques. Chapitre I. Th{\$}\backslash{\$}'eorie g{\$}\backslash{\$}'en{\$}\backslash{\$}'erale des groupo{\$}\backslash{\$}"{\{}{\{}{\}}{\$}\backslash{\$}i{\{}{\}}{\}}des de Lie}},
volume = {88},
year = {1988}
}
@article{Abel2016,
abstract = {Ultrafast and highly efficient optical modulators that are based on the Pockels effect are key components of today's optical communication networks. For the next generation of photonic links, silicon photonic technology is used to establish a new wave of densely integrated optic components. However, this new technology cannot exploit the advantages of using the Pockels effect for optical switching for two reasons: First, silicon does not exhibit any Pockels effect, and second, attempts to combine nonlinear materials with silicon photonics have been cumbersome. Here, we demonstrate a path to integrate barium titanate thin films with strong Pockels coefficients into silicon photonic structures. We highlight various design options, discuss the actual fabrication process, and present experimental results of functional passive and active structures. Examples include couplers and interferometers, as well as active, electrically driven nonvolatilely tunable ring resonators with a tunability of 4 {\$}\mu{\$}W/nm. Our results represent a major advancement in the field of ultralow-power silicon photonic switches based on nonlinear oxides, and demonstrate the potential of novel applications based on the hybrid barium titanate–silicon photonic platform.},
author = {Abel, Stefan and Stoferle, Thilo and Marchiori, Chiara and Caimi, Daniele and Czornomaz, Lukas and Stuckelberger, Michael and Sousa, Marilyne and Offrein, Bert J and Fompeyrine, Jean},
doi = {10.1109/JLT.2015.2510282},
issn = {0733-8724},
journal = {Journal of Lightwave Technology},
keywords = {Epitaxial layers,Nanophotonics,Optoelectronic devices,Silicon photonics},
month = {apr},
number = {8},
pages = {1688--1693},
title = {{A Hybrid Barium Titanate–Silicon Photonics Platform for Ultraefficient Electro-Optic Tuning}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7360872},
volume = {34},
year = {2016}
}
@article{Bogacz1999,
abstract = {Artefacts are noises introduced to an EEG signal by patient's movements and sources of electric field outside the patient's body. The artefacts impede a doctor's expertise and an automatic analysis of the signal. The most common and characteristic kind of artefacts are blinking artefacts. This paper presents a neural based approach to finding artefacts in the signal. The inputs to the network are different coefficients computed for a window of the signal, expressing some characteristic properties of blinking artefacts. 41 coefficients were designed. Sensitivity and correlation analyses were used to choose 14 coefficients for the network's inputs. One used a large training set including coefficients for over 27000 windows, containing different kinds of EEG waves. Three classification algorithms were compared: k-neighbours, RBF networks and back propagation networks. The program was tested on the EEG signal and was highly evaluated by a domain expert},
author = {Bogacz, Rafal and Markowska-Kaczmar, Urszula and Kozik, Andrzej},
journal = {{\ldots} 4 th Conference on Neural {\ldots}},
title = {{Blinking artefact recognition in EEG signal using artificial neural network}},
url = {http://www.cs.bristol.ac.uk/Publications/Papers/2000061.pdf},
year = {1999}
}
@misc{Bacry,
author = {Bacry, E and Duvernet, L},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Bacry, Duvernet - Unknown - Continuous-time skewed multifractal processes as a model for financial returns.pdf:pdf},
keywords = {We present the construction of a continuous time s,includ- ing odd order moments. It is based on a na,including asymmetry and multifractal scaling.},
pages = {1--24},
title = {{Continuous-time skewed multifractal processes as a model for financial returns}}
}
@inproceedings{Pereira2020,
author = {Pereira, Marcus and Wang, Ziyi and Chen, Tianrong and Reed, Emily and Theodorou, Evangelos},
booktitle = {Proceedings of the 2nd Conference on Learning for Dynamics and Control},
pages = {728--738},
title = {{Feynman-Kac neural network architectures for stochastic control using second-order FBSDE theory}},
year = {2020}
}
@unpublished{hamilton:oil,
author = {Hamilton, James},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Hamilton - 2009 - Causes and consequences of the oil shock of 2007-08.pdf:pdf},
series = {Brookings papers on economic activity},
title = {{Causes and consequences of the oil shock of 2007-08}},
year = {2009}
}
@article{maass1,
author = {Maass, W. and Natschl{\"{a}}ger, T. and Markram, H.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Maass, Natschl{\"{a}}ger, Markram - 2002 - Real-time computing without stable states a new framework for neural computation based on pertu(2).pdf:pdf},
journal = {Neural Computation},
pages = {2531--2560},
title = {{Real-time computing without stable states: a new framework for neural computation based on perturbations}},
volume = {14},
year = {2002}
}
@book{Hirsch:book,
author = {Hirsch, Morris W.},
publisher = {Springer Verlag},
title = {{Differential Topology}},
year = {1976}
}
@incollection{foellmer:schweizer,
address = {New York},
author = {F{\"{o}}llmer, Hans and Schweizer, Martin},
booktitle = {Applied stochastic analysis (London, 1989)},
pages = {389--414},
publisher = {Gordon and Breach},
series = {Stochastics Monogr.},
title = {{Hedging of contingent claims under incomplete information}},
volume = {5},
year = {1991}
}
@unpublished{Candes2010,
author = {Cand{\`{e}}s, Emmanuel J},
title = {{Mathematics of sparsity (and a few other things)}},
year = {2010}
}
@article{Yu2005,
abstract = {This paper is concerned with the specification for modelling financial leverage effect in the context of stochastic volatility (SV) models. Two alternative specifications co-exist in the literature. One is the Euler approximation to the well-known continuous time SV model with leverage effect and the other is the discrete time SV model of Jacquier et al. (J. Econometrics 122 (2004) 185). Using a Gaussian nonlinear state space form with uncorrelated measurement and transition errors, I show that it is easy to interpret the leverage effect in the conventional model whereas it is not clear how to obtain and interpret the leverage effect in the model of Jacquier et al. Empirical comparisons of these two models via Bayesian Markov chain Monte Carlo (MCMC) methods further reveal that the specification of Jacquier et al. is inferior. Simulation experiments are conducted to study the sampling properties of Bayes MCMC for the conventional model.},
author = {Yu, Jun},
doi = {10.1016/j.jeconom.2004.08.002},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Yu - 2005 - On leverage in a stochastic volatility model.pdf:pdf},
issn = {03044076},
journal = {Journal of Econometrics},
keywords = {Bayes factors,C11,C15,G12,Leverage effect,Markov chain Monte Carlo,Nonlinear state space models,Particle filter,Quasi maximum likelihood},
month = {aug},
number = {2},
pages = {165--178},
title = {{On leverage in a stochastic volatility model}},
url = {http://www.sciencedirect.com/science/article/pii/S0304407604001435},
volume = {127},
year = {2005}
}
@article{Tecchio2000,
abstract = {The aim of the study was to investigate and follow up the tonotopic organization of the primary auditory cortex in otosclerotic patients before and after corrective surgery. The characteristics of primary auditory cortex activation were studied in ten otosclerotic patients (i.e., subjects suffering from a conductive hearing loss, prior to and following stapes substitution). Magnetoencephalographic recordings of auditory evoked fields by tone-burst stimulation at octave frequencies between 250 and 2000 Hz were performed during monaural stimulation. The brain topography of the main cortical response (N100m) generators at different tones was studied in patients and compared with ten healthy controls; pre- post-surgical changes were also correlated to their clinical outcome following corrective surgery. A significant decrease of the tonotopic extension in the cortical region responsive to the four explored frequencies was found in patients before surgery with respect to the control population. At the time of postsurgical follow-up, the tonotopic representation had enlarged and was approaching the dimensions seen in normal subjects, although with higher variability. The extent of the enlargement of the postoperative tonotopically organized area was directly correlated with the postsurgery period duration. Our findings indicate that auditory cortical areas of human adults undergo functional reorganization following peripheral alteration of the sensory input entering the CNS. The restriction of the cortical tonotopic region caused by the long-term reduction of acoustic input is followed by a reorganization within the usual boundaries following the recovery of auditory function; this process is taking place in a time scale of a few weeks.},
author = {Tecchio, F and Bicciolo, G and {De Campora}, E and Pasqualetti, P and Pizzella, V and Indovina, I and Cassetta, E and Romani, G L and Rossini, P M},
issn = {1065-9471},
journal = {Human brain mapping},
keywords = {Adult,Audiometry,Auditory Cortex,Auditory Cortex: physiology,Auditory Perception,Auditory Perception: physiology,Basilar Membrane,Basilar Membrane: physiology,Female,Humans,Magnetoencephalography,Male,Middle Aged,Otosclerosis,Otosclerosis: complications,Otosclerosis: physiopathology,Otosclerosis: surgery,Prosthesis Implantation,Stapes Surgery,Treatment Outcome},
month = {may},
number = {1},
pages = {28--38},
title = {{Tonotopic cortical changes following stapes substitution in otosclerotic patients: a magnetoencephalographic study.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10843516},
volume = {10},
year = {2000}
}
@article{garcia:renault,
author = {Garcia, R and Renault, E},
journal = {Mathematical Finance},
number = {8},
pages = {153--161},
title = {{Note on hedging in ARCH-type option pricing models}},
volume = {8},
year = {1999}
}
@inproceedings{albert:dazord:1988,
address = {Lyon},
author = {Albert, C. and Dazord, P.},
booktitle = {Travaux du S$\backslash$'eminaire Sud Rhodanien de G$\backslash$'eom$\backslash$'etrie, II},
chapter = {I},
pages = {51--105},
publisher = {Univ. Claude-Bernard. Publ. D$\backslash$'ep. Math. Nouvelle S$\backslash$'er. B},
title = {{Th{\'{e}}orie des groupo{\"{i}}des symplectiques. Chapitre I. Th$\backslash$'eorie g$\backslash$'en$\backslash$'erale des groupo$\backslash$"{\{}$\backslash$i{\}}des de Lie}},
volume = {88},
year = {1988}
}
@book{prigent:book,
author = {Prigent, J. L.},
pages = {xiv + 424},
publisher = {Springer},
title = {{Weak Convergence of Financial Markets}},
year = {2003}
}
@article{BES,
abstract = {The Esscher transform is an important tool in actuarial science. Since the pioneering work of Gerber and Shiu (1994), the use of the Esscher transform for option valuation has also been investigated extensively. However, the relationships between the asset pricing model based on the Esscher transform and some fundamental equilibrium-based asset pricing models, such as consumption-based models, have so far not been well-explored. In this paper, we attempt to bridge the gap between consumption-based models and asset pricing models based on Esscher-type transformations in a discrete-time setting. Based on certain assumptions for the distributions of asset returns, changes in aggregate consumptions and returns on the market portfolio, we construct pricing measures that are consistent with those arising from Esscher-type transformations. Explicit relationships between the market price of risk, and the risk preference parameters are derived for some particular cases.},
author = {Badescu, Alex and Elliott, Robert J. and Siu, Tak Kuen},
issn = {01676687},
journal = {Insurance: Mathematics and Economics},
keywords = {consumption-based model,esscher transform,esscher–girsanov transform,euler equation,exponential affine form,radon–nikodym derivative,stochastic discount factor,utility function},
month = {dec},
number = {3},
pages = {337--347},
title = {{Esscher transforms and consumption-based models}},
url = {http://dx.doi.org/10.1016/j.insmatheco.2009.08.001},
volume = {45},
year = {2009}
}
@unpublished{l4l5,
annote = {$\backslash$textit{\{}Preprint{\}},},
author = {Benettin, G. and Fass{\`{o}}, F. and Guzzo, M.},
title = {{Nekhoroshev-stability of L4 and L5 in the spatial restricted three-body problem}},
year = {1999}
}
@article{alvarez2005breaking,
author = {Alvarez, Gonzalo and Li, Shujun and Montoya, Fausto and Pastor, G and Romera, M},
journal = {Chaos, Solitons {\&} Fractals},
number = {3},
pages = {775--783},
publisher = {Elsevier},
title = {{Breaking projective chaos synchronization secure communication using filtering and generalized synchronization}},
volume = {24},
year = {2005}
}
@article{Kukharenko2011_2,
author = {Kukharenko, Oleksandra},
journal = {Bulletin of the Kyiv National Taras Shevchenko University},
pages = {26--30},
series = {Cybernetics},
title = {{Solution of the Cauchy problem for oscillatory equation with delay}},
url = {http://arxiv.org:443/find/math/1/au:+Kukharenko{\_}O/0/1/0/all/0/1},
year = {2011}
}
@book{valent:elasticity,
author = {Valent, Tullio},
isbn = {9781461274605},
publisher = {Springer Verlag},
title = {{Boundary Value Problems of Finite Elasticity}},
year = {1988}
}
@article{drost:nijman:garch,
author = {Drost, Feike C and Nijman, Theo E},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Drost, Nijman - 1993 - Temporal aggregation of GARCH processes.pdf:pdf},
issn = {0012-9682},
journal = {Econometrica},
number = {4},
pages = {909--927},
title = {{Temporal aggregation of GARCH processes}},
volume = {61},
year = {1993}
}
@article{doukhan2008weakly,
author = {Doukhan, Paul and Wintenberger, Olivier},
journal = {Stochastic Processes and their Applications},
number = {11},
pages = {1997--2013},
publisher = {Elsevier},
title = {{Weakly dependent chains with infinite memory}},
volume = {118},
year = {2008}
}
@article{Hao2013,
abstract = {In this article, we derive the corresponding implied VIX formulas under the locally risk-neutral valuation relationship (LRNVR) proposed by Duan (1995) when a class of square-root stochastic autoregressive volatility (SR-SARV) models are proposed for S{\&}P 500 index. The empirical study shows that the GARCH implied VIX is consistently and significantly lower than the CBOE VIX for all kinds of GARCH model investigated when they are estimated with returns only. When jointly estimated with both returns and VIX, the parameters are distorted unreasonably, and the GARCH implied VIX still cannot fit the CBOE VIX from various statistical aspects. The source of this discrepancy is then theoretically analyzed. We conclude that the GARCH option pricing under the LRNVR fails to incorporate the price of volatility or variance risk premium.},
author = {Hao, J. and Zhang, J. E.},
issn = {1479-8409},
journal = {Journal of Financial Econometrics},
month = {jan},
number = {3},
pages = {556--580},
title = {{GARCH option pricing models, the CBOE VIX, and variance risk premium}},
url = {http://jfec.oxfordjournals.org/content/11/3/556.short},
volume = {11},
year = {2013}
}
@techreport{Kris2000,
author = {Forbes, Kristin and Rigobon, Roberto},
booktitle = {NBER Working Paper},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Forbes, Rigobon - 2000 - Contagion in Latin America Definitions, Measurement, and Policy Implications.pdf:pdf},
institution = {NBER},
title = {{Contagion in Latin America: Definitions, Measurement, and Policy Implications}},
year = {2000}
}
@article{DeAlmeida1991,
abstract = {We discuss the results of a comparative study of the performance of neural networks and conventional methods in forecasting time series. Our work was initially inspired by previously published works that yielded inconsistent results about comparative performance. We have experimented with three time series of different complexity using different feed forward, backpropagation neural network models and the standard Box-Jenkins model. Our experiments demonstrate that for time series with long memory, both methods produced comparable results. However, for series with short memory, neural networks outper formed the Box-Jenkins model. We note that some of the comparable results arise since the neural network and time series model appear to be functionally similar models. We have found that for time series of different complexities there are optimal neural network topologies and parameters that enable them to learn more efficiently. Our initial conclusions are that neural networks are robust and provide good long-term forecasting. They are also parsimonious in their data requirements. Neural networks represent a promising alternative for forecasting, but there are problems determining the optimal topology and parameters for efficient learning.},
author = {de Almeida, C. and Fishwick, P. A.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/de Almeida, Fishwick - 1991 - Time series forecasting using neural networks vs. Box-Jenkins methodology.pdf:pdf},
issn = {0037-5497},
journal = {Simulation},
month = {nov},
number = {5},
pages = {303--310},
title = {{Time series forecasting using neural networks vs. Box-Jenkins methodology}},
url = {http://sim.sagepub.com/content/57/5/303.short},
volume = {57},
year = {1991}
}
@book{Shiryaev:Probability2,
author = {Shiryaev, Albert N.},
edition = {Third},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Shiryaev - 2019 - Probability-2.pdf:pdf},
isbn = {9780387722078},
publisher = {Sprin},
title = {{Probability-2}},
year = {2019}
}
@article{condevaux:dazord:and:molino,
address = {Lyon},
author = {Condevaux, M. and Dazord, P. and Molino, P.},
journal = {Travaux du S{\'{e}}minaire Sud-Rhodanien de G{\'{e}}om{\'{e}}trie, I (D{\'{e}}p. Math. Nouvelle S{\'{e}}r. B)},
pages = {131--160},
publisher = {Univ. Claude-Bernard},
title = {{G{\'{e}}om{\'{e}}trie du moment}},
volume = {88-1},
year = {1988}
}
@article{Morris2015,
author = {Morris, Jeffrey S.},
journal = {Annual Review of Statistics and Its Application},
pages = {321--359},
title = {{Functional regression}},
volume = {2},
year = {2015}
}
@article{Smale2004,
author = {Smale, Steve and Zhou, Ding-Xuan},
journal = {Bull. Amer. Math. Soc.},
pages = {279--305},
title = {{Shannon sampling and function reconstruction from point values}},
volume = {41},
year = {2004}
}
@article{Hobson2004,
author = {Hobson, David},
doi = {10.1111/j.0960-1627.2004.00204.x},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Hobson - 2004 - Stochastic volatility models, correlation and the q-optimal measure.pdf:pdf},
issn = {0960-1627},
journal = {Mathematical Finance},
month = {oct},
number = {4},
pages = {537--556},
title = {{Stochastic volatility models, correlation and the q-optimal measure}},
url = {http://doi.wiley.com/10.1111/j.0960-1627.2004.00204.x},
volume = {14},
year = {2004}
}
@unpublished{Cuchiero2019,
author = {Cuchiero, Christa and Larsson, Martin and Teichmann, Josef},
title = {{Deep neural networks, generic universal interpolation, and controlled ODEs}},
year = {2019}
}
@article{Hosking1981,
abstract = {The family of autoregressive integrated moving-average processes, widely used in time series analysis, is generalized by permitting the degree of differencing to take fractional values. The fractional differencing operator is defined as an infinite binomial series expansion in powers of the backward-shift operator. Fractionally differenced processes exhibit long-term persistence and antipersistence; the dependence between observations a long time span apart decays much more slowly with time span than is the case with the more commonly studied time series models. Long-term persistent processes have applications in economics and hydrology; compared to existing models of long-term persistence, the family of models introduced here offers much greater flexibility in the simultaneous modelling of the short-term and long-term behaviour of a time series.},
author = {Hosking, J. R M},
journal = {Biometrika},
keywords = {Autoregressive integrated moving-average process,Fractional differencing,Long-term persistence,Time series},
title = {{Fractional differencing}},
year = {1981}
}
@misc{Poczos2015,
author = {Poczos, Barnabas},
title = {{Machine Learning Intro: Lecture Notes}},
url = {http://www.cs.cmu.edu/{~}bapoczos/Classes/ML10715{\_}2015Fall/slides/Lecture1{\_}Introduction.pdf},
year = {2015}
}
@article{RVHansen,
author = {Hansen, P. R. and Lunde, Asger},
journal = {Journal of Business {\&} Economic Statistics},
number = {2},
pages = {127--161},
title = {{Realized variance and market microstructure noise}},
volume = {24},
year = {2006}
}
@article{dellnitz:melbourne:marsden,
author = {Dellnitz, M. and Melbourne, I. and Marsden, J. E.},
journal = {Nonlinearity},
pages = {979--996},
title = {{Generic bifurcation of Hamiltonian vector fields with symmetry}},
volume = {5},
year = {1992}
}
@article{brockett:1988,
author = {Brockett, R. W.},
journal = {Linear Algebra and its Applications},
pages = {79--91},
title = {{Dynamical systems that sort lists and solve linear programming systems}},
volume = {146},
year = {1991}
}
@article{Diedrichsen2010,
author = {Diedrichsen, J. and Shadmehr, R. and Ivry, R.},
journal = {Trends in cognitive sciences},
number = {1},
pages = {31--39},
title = {{The coordination of movement: optimal feedback control and beyond}},
volume = {14},
year = {2010}
}
@article{Gautier2006,
author = {Gautier, Erwan},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Gautier - 2006 - Les march{\'{e}}s financiers comme indicateurs avanc{\'{e}}s des retournements conjoncturels le cas am{\'{e}}ricain.pdf:pdf},
journal = {BULLETIN DE LA BANQUE DE FRANCE},
keywords = {cycle d'affaires,indicateurs avanc{\'{e}}s},
pages = {61--71},
title = {{Les march{\'{e}}s financiers comme indicateurs avanc{\'{e}}s des retournements conjoncturels: le cas am{\'{e}}ricain}},
url = {http://www.banque-france.fr/archipel/publications/bdf{\_}bm/bdf{\_}bm{\_}2006/bdf{\_}bm{\_}153.pdf{\#}page=67},
volume = {153},
year = {2006}
}
@book{Dieudonne:volumeIII,
author = {Dieudonn{\'{e}}, Jean},
isbn = {0122155025},
publisher = {Academic Press, Inc.},
title = {{Treatise on Analysis. Volume III}},
volume = {III},
year = {1972}
}
@article{sandberg:volterra,
author = {Sandberg, Irwin W.},
journal = {IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications},
number = {1},
pages = {135--139},
title = {{Bounds for discrete-time Volterra series representations}},
volume = {46},
year = {1999}
}
@article{Morawietz2016,
author = {Morawietz, Tobias and Singraber, Andreas and Dellago, Christoph and Behler, J{\"{o}}rg},
doi = {10.1073/pnas.1602375113},
journal = {Proceedings of the National Academy of Sciences},
number = {30},
pages = {8368--8373},
title = {{How van der Waals interactions determine the unique properties of water}},
url = {http://www.pnas.org/content/113/30/8368.abstract},
volume = {113},
year = {2016}
}
@inproceedings{Gibbons2010,
author = {Gibbons, Thomas E.},
booktitle = {The 2010 International Joint Conference on Neural Networks (IJCNN)},
doi = {10.1109/IJCNN.2010.5596307},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Gibbons - 2010 - Unifying quality metrics for reservoir networks.pdf:pdf},
isbn = {978-1-4244-6916-1},
month = {jul},
pages = {1--7},
publisher = {IEEE},
title = {{Unifying quality metrics for reservoir networks}},
url = {http://ieeexplore.ieee.org/document/5596307/},
year = {2010}
}
@article{bernard:cui,
author = {Bernard, Carole and Cui, Zhenyu and McLeish, Don},
journal = {Mathematical Finance},
number = {1},
pages = {194--223},
title = {{On the martingale property in stochastic volatility models based on time-homogeneous diffusions}},
volume = {27},
year = {2017}
}
@article{hosking:portmanteau,
author = {Hosking, J R M},
issn = {0003-1291},
journal = {J. Amer. Statist. Assoc.},
number = {371},
pages = {602--608},
title = {{The multivariate portmanteau statistic}},
volume = {75},
year = {1980}
}
@book{birkhoff27,
author = {Birkhoff, G. D.},
booktitle = {Colloquium Publications},
publisher = {American mathematical society},
title = {{Dynamical Systems}},
volume = {9},
year = {1927}
}
@article{Foss2000,
author = {Foss, J. and Milton, J.},
journal = {J Neurophysiol},
number = {2},
pages = {975--985},
title = {{Multistability in recurrent neural loops arising from delay}},
volume = {84},
year = {2000}
}
@inproceedings{duan1996,
address = {Working paper},
annote = {From Duplicate 2 ( 

A unified theory of option pricing under stochastic volatility: from GARCH to diffusion

- Duan, Jin-Chuan )

},
author = {Duan, Jin-Chuan},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Duan - 1996 - A unified theory of option pricing under stochastic volatility.pdf:pdf},
title = {{A unified theory of option pricing under stochastic volatility}},
year = {1996}
}
@book{matrices,
author = {Petersen, Kaare Brandt and Pedersen, Michael Syskind},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Petersen, Pedersen - 2012 - The Matrix Cookbook.pdf:pdf},
publisher = {Technical University of Denmark},
title = {{The Matrix Cookbook}},
year = {2012}
}
@article{Liljeblom1997,
author = {Liljeblom, Eva and Stenius, Marianne},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Liljeblom, Stenius - 1997 - Macroeconomic volatility and stock market volatility empirical evidence on Finnish data.pdf:pdf},
issn = {0960-3107},
journal = {Applied Financial Economics},
month = {aug},
number = {4},
pages = {419--426},
title = {{Macroeconomic volatility and stock market volatility: empirical evidence on Finnish data}},
url = {http://www.informaworld.com/openurl?genre=article{\&}doi=10.1080/096031097333538{\&}magic=crossref{\%}7C{\%}7CD404A21C5BB053405B1A640AFFD44AE3},
volume = {7},
year = {1997}
}
@book{Quang:Murino,
author = {{Quang Minh}, H{\`{a}} and Murino, Vittorio},
publisher = {Morgan and Claypool Publishers},
title = {{Covariances in Computer Vision and Machine Learning}},
year = {2018}
}
@article{reduction:optimal:cras,
author = {Ortega, Juan-Pablo and Ratiu, Tudor S.},
journal = {Comptes Rendus de l'Acad{\'{e}}mie des Sciences - Series I - Mathematics},
pages = {999--1004},
title = {{The symplectic reduced spaces of a Poisson action}},
volume = {334},
year = {2002}
}
@inproceedings{Cabrera2017,
author = {Cabrera, Diego and Sancho, Fernando and Tobar, Felipe},
booktitle = {International Conference on Sensing, Diagnostics, Prognostics, and Control},
pages = {57--62},
title = {{Combining reservoir computing and variational inference for efficient one-class learning on dynamical systems}},
year = {2017}
}
@book{Smythe1939,
address = {New York},
author = {Smythe, W. R.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Smythe - 1939 - Static and Dynamic Electricity.djvu:djvu},
publisher = {McGraw-Hill},
title = {{Static and Dynamic Electricity}},
year = {1939}
}
@article{Pelsser08,
author = {Pelsser, Antoon},
issn = {1783-1350},
journal = {ASTIN Bulletin},
language = {English},
month = {may},
number = {01},
pages = {171--181},
publisher = {Cambridge University Press},
title = {{On the applicability of the Wang transform for pricing financial risks}},
url = {http://journals.cambridge.org/abstract{\_}S0515036100015129},
volume = {38},
year = {2008}
}
@unpublished{Gale2019,
author = {Gale, Trevor and Elsen, Erich and Hooker, Sara},
title = {{The state of sparsity in deep neural networks}},
year = {2019}
}
@misc{Andrade2011,
author = {Andrade, Philippe and Ghysels, Eric and Fourel, Val{\`{e}}re and Idier, Julien},
title = {{Inflation Risks in the Euro Area}},
year = {2011}
}
@book{hall:heyde:book,
author = {Hall, P. and Heyde, C C},
publisher = {Academic Press},
title = {{Martingale Limit Theory and Its Application}},
year = {1980}
}
@article{Braunbek1939,
author = {Braunbek, W.},
journal = {Z. Phys.},
pages = {753--763},
title = {{Freischwebende Korper im elecktrischen und magnetischen Feld}},
volume = {112},
year = {1939}
}
@article{Kaufmann2009,
author = {Kaufmann, Esther and Athanasou, James a.},
doi = {10.1024/1421-0185.68.2.99},
issn = {1421-0185},
journal = {Swiss Journal of Psychology},
keywords = {judgment achievement,lens model equation,meta-analysis,social judgment theory},
month = {jan},
number = {2},
pages = {99--112},
title = {{A Meta-Analysis of Judgment Achievement as Defined by the Lens Model Equation}},
url = {http://psycontent.metapress.com/openurl.asp?genre=article{\&}id=doi:10.1024/1421-0185.68.2.99},
volume = {68},
year = {2009}
}
@article{Maiorov2000,
author = {Maiorov, V. and Meir, Ron},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley//Maiorov, Meir - 2000 - On the near optimality of the stochastic approximation of smooth functions by neural networks.pdf:pdf},
journal = {Advances in Computational Mathematics},
number = {1},
pages = {79--103},
title = {{On the near optimality of the stochastic approximation of smooth functions by neural networks}},
volume = {13},
year = {2000}
}
@unpublished{sbrana:silvestrini:2014,
author = {Sbrana, Giacomo and Silvestrini, Andrea and Venditti, Fabrizio},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Sbrana, Silvestrini, Venditti - 2014 - Short term inflation forecasting a M.E.T.A. approach.pdf:pdf},
title = {{Short term inflation forecasting: a M.E.T.A. approach}},
year = {2014}
}
@book{Friz:Hairer:Rough:Paths,
author = {Friz, Peter K. and Hairer, Martin},
pages = {251},
publisher = {Springer Verlag},
title = {{A Course on Rough Paths}},
year = {2014}
}
@article{cantrijn:de:leon:98,
author = {Cantrijn, F. and de Le{\'{o}}n, M. and Marrero, J. C. and de Diego, D. M.},
journal = {Rep. Math. Phys.},
number = {1/2},
pages = {25--45},
title = {{Reduction of nonholonomic mechanical systems with symmetries}},
volume = {42},
year = {1998}
}
@article{de_mol:sparse,
author = {Brodie, J and Daubechies, I and {De Mol}, C and Giannone, D and Loris, I},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Brodie et al. - 2009 - Sparse and stable Markowitz portfolios.pdf:pdf;:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Brodie et al. - 2009 - Sparse and stable Markowitz portfolios(2).pdf:pdf},
journal = {PNAS},
number = {30},
pages = {12267--12272},
title = {{Sparse and stable Markowitz portfolios}},
volume = {106},
year = {2009}
}
@article{Monfardini2008,
author = {Monfardini, Chiara and Radice, Rosalba},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Monfardini, Radice - 2008 - Testing Exogeneity in the Bivariate Probit Model A Monte Carlo Study.pdf:pdf},
issn = {0305-9049},
journal = {Oxford Bulletin of Economics and Statistics},
month = {apr},
number = {2},
pages = {271--282},
title = {{Testing Exogeneity in the Bivariate Probit Model: A Monte Carlo Study}},
url = {http://doi.wiley.com/10.1111/j.1468-0084.2007.00486.x},
volume = {70},
year = {2008}
}
@article{Corsi2009,
author = {Corsi, F.},
journal = {Journal of Financial Econometrics},
number = {2},
pages = {174--196},
title = {{A simple approximate long-memory model of realized volatility}},
volume = {7},
year = {2009}
}
@article{AlexanderRakhlinKarthikSridharan2015,
abstract = {We consider the problem of sequential prediction and provide tools to study the minimax value of the associated game. Classical statistical learning theory provides several useful complexity measures to study learning with i.i.d. data. Our proposed sequential complexities can be seen as extensions of these measures to the sequential setting. The developed theory is shown to yield precise learning guarantees for the problem of sequential prediction. In particular, we show necessary and sufficient conditions for online learnability in the setting of supervised learning. Several examples show the utility of our framework: we can establish learnability without having to exhibit an explicit online learning algorithm.},
author = {Rakhlin, Alexander and Sridharan, Karthik and Tewari, Ambuj},
journal = {Journal of Machine Learning Research},
pages = {155--186},
title = {{Online learning via sequential complexities}},
volume = {16},
year = {2010}
}
@techreport{wolpert1,
author = {Wolpert, Robert},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Wolpert - Unknown - The laws of large numbers.pdf:pdf},
title = {{The laws of large numbers}},
url = {http://www.isds.duke.edu/courses/Fall10/sta205/lec/wk-07.pdf}
}
@article{Behler2007,
author = {Behler, J{\"{o}}rg and Parrinello, Michele},
doi = {10.1103/PhysRevLett.98.146401},
journal = {Phys. Rev. Lett.},
month = {apr},
number = {14},
pages = {146401},
publisher = {American Physical Society},
title = {{Generalized neural-network representation of high-dimensional potential-energy surfaces}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.98.146401},
volume = {98},
year = {2007}
}
@unpublished{CvMtestGARCH,
author = {Ghoudi, Kilani and R{\'{e}}millard, Bruno},
title = {{Serial independence tests of conditional mean and variance models}},
year = {2016}
}
@article{Trolle2009,
abstract = {Commodity derivatives are becoming an increasingly important part of the global derivatives market. Here we develop a tractable stochastic volatility model for pricing commodity derivatives. The model features unspanned stochastic volatility, quasi-analytical prices of options on futures contracts, and dynamics of the futures curve in terms of a low-dimensional affine state vector. We estimate the model on NYMEX crude oil derivatives using an extensive panel data set of 45,517 futures prices and 233,104 option prices, spanning 4082 business days. We find strong evidence for two predominantly unspanned volatility factors.},
author = {Trolle, A. B. and Schwartz, E. S.},
issn = {0893-9454},
journal = {Review of Financial Studies},
month = {may},
number = {11},
pages = {4423--4461},
title = {{Unspanned stochastic volatility and the pricing of commodity derivatives}},
url = {http://rfs.oxfordjournals.org/content/early/2009/05/10/rfs.hhp036.short},
volume = {22},
year = {2009}
}
@article{Man2004,
author = {Man, K. S.},
doi = {10.1016/j.ijforecast.2003.11.010},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Man - 2004 - Linear prediction of temporal aggregates under model misspecification.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {linear prediction,model misspecification,periodic time series,temporal aggregation},
month = {oct},
number = {4},
pages = {659--670},
title = {{Linear prediction of temporal aggregates under model misspecification}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0169207003001547},
volume = {20},
year = {2004}
}
@article{Tino2019,
author = {Tino, Peter},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Tino - 2020 - Dynamical systems as temporal feature spaces.pdf:pdf},
journal = {Journal of Machine Learning Research},
pages = {1--42},
title = {{Dynamical systems as temporal feature spaces}},
volume = {21},
year = {2020}
}
@article{Robert2002,
abstract = {The electroencephalogram (EEG), a highly complex signal, is one of the most common sources of information used to study brain function and neurological disorders. More than 100 current neural network applications dedicated to EEG processing are presented. Works are categorized according to their objective (sleep analysis, monitoring anesthesia depth, brain-computer interface, EEG artifact detection, EEG source-based localization, etc.). Each application involves a specific approach (long-term analysis or short-term EEG segment analysis, real-time or time delayed processing, single or multiple EEG-channel analysis, etc.), for which neural networks were generally successful. The promising performances observed are demonstrative of the efficiency and efficacy of systems developed. This review can aid researchers, clinicians and implementors to understand up-to-date interest in neural network tools for EEG processing. The extended bibliography provides a database to assist in possible new concepts and idea development.},
author = {Robert, Claude and Gaudy, Jean-Fran{\c{c}}ois and Limoge, Aim{\'{e}}},
issn = {1388-2457},
journal = {Clinical neurophysiology},
keywords = {Electroencephalogram,Neural network,Review},
month = {may},
number = {5},
pages = {694--701},
pmid = {11976049},
title = {{Electroencephalogram processing using neural networks}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11976049},
volume = {113},
year = {2002}
}
@article{horvath2021deep,
author = {Horvath, Blanka and Muguruza, Aitor and Tomas, Mehdi},
journal = {Quantitative Finance},
number = {1},
pages = {11--27},
publisher = {Taylor {\&} Francis},
title = {{Deep learning volatility: a deep neural network perspective on pricing and calibration in (rough) volatility models}},
volume = {21},
year = {2021}
}
@article{Chang2009,
abstract = {This paper investigates the statistical properties of estimators of the parameters and unobserved series for state space models with integrated time series. In particular, we derive the full asymptotic results for maximum likelihood estimation using the Kalman filter for a prototypical class of such models—those with a single latent common stochastic trend. Indeed, we establish the consistency and asymptotic mixed normality of the maximum likelihood estimator and show that the conventional method of inference is valid for this class of models. The models we explicitly consider comprise a special–yet useful–class of models that may be employed to extract the common stochastic trend from multiple integrated time series. Such models can be very useful to obtain indices that represent fluctuations of various markets or common latent factors that affect a set of economic and financial variables simultaneously. Moreover, our derivation of the asymptotics of this class makes it clear that the asymptotic Gaussianity and the validity of the conventional inference for the maximum likelihood procedure extends to a larger class of more general state space models involving integrated time series. Finally, we demonstrate the utility of this class of models extracting a common stochastic trend from three sets of time series involving short- and long-term interest rates, stock return volatility and trading volume, and Dow Jones stock prices.},
author = {Chang, Yoosoon and {Isaac Miller}, J. and Park, Joon Y.},
issn = {03044076},
journal = {Journal of Econometrics},
keywords = {C13,C32,Common stochastic trend,Interest rates,Kalman filter,Maximum likelihood estimation,Permanent–transitory decomposition,State space model,Stock price index,Volume and volatility},
month = {jun},
number = {2},
pages = {231--247},
title = {{Extracting a common stochastic trend: Theory with some applications}},
url = {http://www.sciencedirect.com/science/article/pii/S0304407608002212},
volume = {150},
year = {2009}
}
@techreport{jaeger:course,
author = {Jaeger, Herbert},
institution = {Jacobs University Bremen},
title = {{Machine learning: an introduction}},
year = {2014}
}
@article{chen:donoho:saunders,
author = {Chen, S S and Donoho, D and Saunders, M},
journal = {SIAM Rev.},
pages = {129--159},
title = {{Atomic decomposition by basis pursuit}},
volume = {43},
year = {2001}
}
@unpublished{Chattopadhyay2019,
abstract = {In this paper, the performance of three deep learning methods for predicting short-term evolution and reproducing the long-term statistics of a multi-scale spatio-temporal Lorenz 96 system is examined. The methods are: echo state network (a type of reservoir computing, RC-ESN), deep feed-forward artificial neural network (ANN), and recurrent neural network with long short-term memory (RNN-LSTM). This Lorenz system has three tiers of nonlinearly interacting variables representing slow/large-scale ({\$}X{\$}), intermediate ({\$}Y{\$}), and fast/small-scale ({\$}Z{\$}) processes. For training or testing, only {\$}X{\$} is available; {\$}Y{\$} and {\$}Z{\$} are never known/used. It is shown that RC-ESN substantially outperforms ANN and RNN-LSTM for short-term prediction, e.g., accurately forecasting the chaotic trajectories for hundreds of numerical solver's time steps, equivalent to several Lyapunov timescales. RNN-LSTM and ANN show some prediction skills as well; RNN-LSTM bests ANN. Furthermore, even after losing the trajectory, data predicted by RC-ESN and RNN-LSTM have probability density functions (PDFs) that closely match the true PDF, even at the tails. PDF of the ANN data deviates from the true PDF. Implications, caveats, and applications to data-driven and inexact, data-assisted surrogate modeling of complex dynamical systems such as weather/climate are discussed.},
archivePrefix = {arXiv},
arxivId = {1906.08829},
author = {Chattopadhyay, Ashesh and Hassanzadeh, Pedram and Palem, Krishna and Subramanian, Devika},
booktitle = {arXiv: 1906.08829},
eprint = {1906.08829},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Chattopadhyay et al. - 2019 - Data-driven prediction of a multi-scale Lorenz 96 chaotic system using a hierarchy of deep learning method.pdf:pdf},
title = {{Data-driven prediction of a multi-scale Lorenz 96 chaotic system using a hierarchy of deep learning methods: Reservoir computing, ANN, and RNN-LSTM}},
url = {http://arxiv.org/abs/1906.08829},
year = {2019}
}
@article{Caporin2012,
author = {Caporin, Massimiliano and McAleer, Michael},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Caporin, McAleer - 2012 - Do we really need both BEKK and DCC A tale of two multivariate GARCH models.pdf:pdf},
issn = {09500804},
journal = {Journal of Economic Surveys},
month = {sep},
number = {4},
pages = {736--751},
title = {{Do we really need both BEKK and DCC? A tale of two multivariate GARCH models.}},
url = {http://doi.wiley.com/10.1111/j.1467-6419.2011.00683.x},
volume = {26},
year = {2012}
}
@techreport{Tay2007,
author = {Tay, Anthony S},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Tay - 2007 - Financial Variables as Predictors of Real Output Growth.pdf:pdf},
institution = {SMU Economics {\&} Statistics},
number = {14},
title = {{Financial Variables as Predictors of Real Output Growth}},
type = {Working Paper},
year = {2007}
}
@book{Neal1996,
author = {Neal, Radford M.},
publisher = {Springer-Verlag New York},
title = {{Bayesian Learning for Neural Networks}},
year = {1996}
}
@incollection{WeiTempAggr1979,
author = {Wei, William W. S.},
booktitle = {Seasonal Analysis of Economic Time Series},
editor = {Zellner, Arnold},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Wei - 1979 - Some Consequences of Temporal Aggregation in Seasonal Time Series Models.pdf:pdf},
pages = {433--448},
publisher = {NBER},
title = {{Some Consequences of Temporal Aggregation in Seasonal Time Series Models}},
year = {1979}
}
@book{compressed:sensing:book,
author = {Eldar, Yonina C. and Kutyniok, Gitta and (editors)},
publisher = {Cambridge University Press},
title = {{Compressed Sensing}},
year = {2012}
}
@article{CLBICGaoSong2010,
author = {Gao, Xin and Song, Peter X.-K.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Gao, Song - 2010 - Composite likelihood Bayesian Information Criteria for model selection in high-dimensional data.pdf:pdf},
journal = {Journal of the American Statistical Association},
number = {492},
pages = {1531--1540},
title = {{Composite likelihood Bayesian Information Criteria for model selection in high-dimensional data}},
volume = {105},
year = {2010}
}
@article{Galbraith2000a,
author = {Galbraith, John and Tkacz, Greg},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Galbraith, Tkacz - 2000 - Testing for asymmetry in the link between the yield spread and output in the G-7 countries.pdf:pdf},
issn = {02615606},
journal = {Journal of International Money and Finance},
keywords = {asymmetry,economic activity,yield spread},
month = {oct},
number = {5},
pages = {657--672},
title = {{Testing for asymmetry in the link between the yield spread and output in the G-7 countries}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0261560600000231},
volume = {19},
year = {2000}
}
@book{Rudin:real:analysis,
author = {Rudin, Walter},
edition = {Third},
pages = {415},
publisher = {McGraw-Hill},
title = {{Real and Complex Analysis}},
year = {1987}
}
@article{kaeck:hedging,
author = {Kaeck, Andreas},
journal = {Review of Finance},
number = {4},
pages = {1535--1569},
title = {{Hedging surprises, jumps, and model misspecification: a risk management perspective on hedging S{\&}P 500 options}},
volume = {17},
year = {2013}
}
@book{Marsden1992,
address = {Cambridge},
author = {Marsden, Jerrold E.},
booktitle = {Mathematical Society Lecture Note Series},
pages = {254},
publisher = {Cambridge University Press},
title = {{Lectures on mechanics. London Mathematical Society Lecture Note Series, vol. 174}},
year = {1992}
}
@article{jiang2004chaotic,
author = {Jiang-Feng, Xu and Le-Quan, Min and Guan-Rong, Chen},
journal = {Chinese Physics Letters},
number = {8},
pages = {1445},
publisher = {IOP Publishing},
title = {{A chaotic communication scheme based on generalized synchronization and hash functions}},
volume = {21},
year = {2004}
}
@book{fiedler,
author = {Fiedler, B.},
publisher = {Springer-Verlag},
title = {{Global Bifurcation of Periodic Solutions with Symmetry. Lecture Notes in Mathematics, vol. 1309}},
year = {1988}
}
@unpublished{Bellone2005,
author = {Bellone, Benoit and Gautier, Erwan and Coent, S{\'{e}}bastien Le},
institution = {Banque de Frnace},
title = {{Les march{\{}{\'{e}}{\}}s financiers anticipent-ils les retournements conjoncturels?}},
year = {2005}
}
@article{Freund1997,
author = {Freund, Yoav and Schapire, Robert E.},
journal = {Journal of Computer and System Sciences},
number = {1},
pages = {119--139},
title = {{A decision-theoretic generalization of online learning and an application to boosting}},
volume = {55},
year = {1997}
}
@article{GJ2006,
author = {Gouri{\'{e}}roux, Christian and Jasiak, Joann},
journal = {Journal of Forecasting},
pages = {129--152},
title = {{Autoregressive Gamma Processes}},
volume = {25},
year = {2006}
}
@article{paper1:persitence,
abstract = {We use new global tools in singular reduction in order to generalize some results on the persistence and smoothness of critical relative elements in Hamiltonian systems with symmetry, obtained by Montaldi (see [5] and [4]) and Patrick (see [8]), to the case in which the elements considered have non-trivial symmetry. De nouveaux outils globaux dans la th{\'{e}}orie de r{\'{e}}duction singuli{\`{e}}re sont utilis{\'{e}}s pour g{\'{e}}n{\'{e}}raliser les r{\'{e}}sultats de Montaldi (voir [5] et [4]) et Patrick (voir [8]) sur la persistance et la diff{\'{e}}rentiabilit{\'{e}} des {\'{e}}l{\'{e}}ments critiques relatifs dans les syst{\`{e}}mes hamiltoniens sym{\'{e}}triques si ces {\'{e}}l{\'{e}}ments poss{\`{e}}dent une sym{\'{e}}trie non triviale.},
author = {Ortega, Juan-Pablo and Ratiu, Tudor S.},
doi = {10.1016/S0764-4442(97)88714-9},
issn = {0764-4442},
journal = {Comptes Rendus de l'Acad{\'{e}}mie des Sciences - Series I - Mathematics},
month = {nov},
number = {10},
pages = {1107--1111},
publisher = {Elsevier Masson},
title = {{Persistence and smoothness of critical relative elements in Hamiltonian systems with symmetry}},
url = {https://www.sciencedirect.com/science/article/pii/S0764444297887149},
volume = {325},
year = {1997}
}
@article{Chorro2010,
abstract = {In a discrete time option pricing framework, we compare the empirical performance of two pricing methodologies, namely the affine stochastic discount factor (SDF) and the empirical martingale correction methodologies. Using a CAC 40 options dataset, the differences are found to be small: the higher order moment correction involved in the SDF approach may not be that essential to reduce option pricing errors. This paper puts into evidence the fact that an appropriate modelling under the historical measure associated with an adequate correction (that we call here a “martingale correction”) permits to provide option prices which are close to market ones.},
author = {Chorro, C. and Gu{\'{e}}gan, D. and Ielpo, F.},
issn = {15446123},
journal = {Finance Research Letters},
keywords = {C5,C8,CAC 40,G12,G17,Generalized Hyperbolic distribution,Incomplete market,Martingale correction,Option pricing,Stochastic discount factor},
month = {mar},
number = {1},
pages = {24--28},
title = {{Martingalized historical approach for option pricing}},
url = {http://www.sciencedirect.com/science/article/pii/S1544612309000579},
volume = {7},
year = {2010}
}
@article{melino:turnbull,
author = {Melino, A and Turnbull, S M},
journal = {Journal of Econometrics},
pages = {239--265},
title = {{Pricing foreign currency options with stochastic volatility}},
volume = {45},
year = {1990}
}
@article{cicortas:2000,
author = {Cicorta{\c{c}}, G.},
journal = {Gen. Math.},
number = {1-2},
pages = {55--64},
title = {{Note on some properties of Lusternik-Schnirelmann category}},
volume = {8},
year = {2000}
}
@article{bridges:90,
author = {Bridges, T. J.},
journal = {Math. Proc. Camb. Phil. Soc.},
pages = {575--601},
title = {{Bifurcation of periodic solutions near a collision of eigenvalues of opposite signature}},
volume = {108},
year = {1990}
}
@article{Aceituno2017,
abstract = {As one of the most important paradigms of recurrent neural networks, the echo state network (ESN) has been applied to a wide range of fields, from robotics to medicine, finance, and language processing. A key feature of the ESN paradigm is its reservoir --- a directed and weighted network of neurons that projects the input time series into a high dimensional space where linear regression or classification can be applied. Despite extensive studies, the impact of the reservoir network on the ESN performance remains unclear. Combining tools from physics, dynamical systems and network science, we attempt to open the black box of ESN and offer insights to understand the behavior of general artificial neural networks. Through spectral analysis of the reservoir network we reveal a key factor that largely determines the ESN memory capacity and hence affects its performance. Moreover, we find that adding short loops to the reservoir network can tailor ESN for specific tasks and optimize learning. We validate our findings by applying ESN to forecast both synthetic and real benchmark time series. Our results provide a new way to design task-specific ESN. More importantly, it demonstrates the power of combining tools from physics, dynamical systems and network science to offer new insights in understanding the mechanisms of general artificial neural networks.},
archivePrefix = {arXiv},
arxivId = {1707.02469},
author = {Aceituno, Pau Vilimelis and Gang, Yan and Liu, Yang-Yu},
eprint = {1707.02469},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Aceituno, Gang, Liu - 2017 - Tailoring artificial neural networks for optimal learning.pdf:pdf},
month = {jul},
title = {{Tailoring artificial neural networks for optimal learning}},
url = {http://arxiv.org/abs/1707.02469},
year = {2017}
}
@article{NijmanPalmARIMA1990,
author = {Nijman, Theo E. and Palm, Franz C.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Nijman, Palm - 1990 - Predictive accuracy gain from disaggregate sampling in ARIMA models.pdf:pdf},
journal = {Journal of Business and Economic Statistics},
number = {4},
pages = {405--415},
title = {{Predictive accuracy gain from disaggregate sampling in ARIMA models}},
volume = {8},
year = {1990}
}
@unpublished{Arora2019,
abstract = {Recent works have cast some light on the mystery of why deep nets fit any data and generalize despite being very overparametrized. This paper analyzes training and generalization for a simple 2-layer ReLU net with random initialization, and provides the following improvements over recent works: (i) Using a tighter characterization of training speed than recent papers, an explanation for why training a neural net with random labels leads to slower training, as originally observed in [Zhang et al. ICLR'17]. (ii) Generalization bound independent of network size, using a data-dependent complexity measure. Our measure distinguishes clearly between random labels and true labels on MNIST and CIFAR, as shown by experiments. Moreover, recent papers require sample complexity to increase (slowly) with the size, while our sample complexity is completely independent of the network size. (iii) Learnability of a broad class of smooth functions by 2-layer ReLU nets trained via gradient descent. The key idea is to track dynamics of training and generalization via properties of a related kernel.},
archivePrefix = {arXiv},
arxivId = {arXiv:1703.00573v5},
author = {Arora, Sanjeev and Du, Simon S. and Hu, Wei and Li, Zhiyuan and Wang, Ruosong},
doi = {10.1007/bf01708009},
eprint = {arXiv:1703.00573v5},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Arora et al. - 2019 - Fine-Grained Analysis of Optimization and Generalization for Overparameterized Two-Layer Neural Networks.pdf:pdf},
isbn = {9783642017414},
issn = {0026-9255},
title = {{Fine-Grained Analysis of Optimization and Generalization for Overparameterized Two-Layer Neural Networks}},
url = {http://arxiv.org/abs/1901.08584},
year = {2019}
}
@article{becker2019deep,
author = {Becker, Sebastian and Cheridito, Patrick and Jentzen, Arnulf},
journal = {Journal of Machine Learning Research},
pages = {74},
publisher = {MIT Press},
title = {{Deep optimal stopping}},
volume = {20},
year = {2019}
}
@inproceedings{Meintrup2019,
author = {Meintrup, Stefan and Munteanu, Alexander and Rohde, Dennis},
booktitle = {NeurIPS},
title = {{Random projections and sampling algorithms for clustering of high-dimensional polygonal curves}},
year = {2019}
}
@book{Malkin:stability,
author = {Malkin, I.G.},
title = {{Theory of Stability of Motion}}
}
@unpublished{He2015,
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
title = {{Deep residual learning for image recognition}},
year = {2015}
}
@article{Hsiao2002,
author = {Hsiao, Cheng and Shen, Yan and Fujiki, Hiroshi and Angeles, Los and Bay, Clear Water and Kong, Hong and Studies, Economic and Evans, P and Granger, Clive. W. J. and Klein, L and Zellner, A and Society, Econometric},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Hsiao et al. - 2002 - Aggregate vs Disaggregate Data Analysis A Paradox in the Estimation of Money Demand Function of Japan Under the L.pdf:pdf},
journal = {Monetary and Economic Studies},
title = {{Aggregate vs Disaggregate Data Analysis | A Paradox in the Estimation of Money Demand Function of Japan Under the Low Interest Rate Policy}},
year = {2002}
}
@article{Alon1997,
author = {Alon, N. and Ben-David, Shai and Cesa-Bianchi, N. and Haussler, David},
journal = {Journal of the ACM},
number = {4},
pages = {615--631},
title = {{Scale-sensitive dimensions, uniform convergence, and learnability}},
volume = {44},
year = {1997}
}
@article{Jaeger2016,
author = {Jaeger, Herbert},
doi = {10.1038/nature19477},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Jaeger - 2016 - Artificial intelligence Deep neural reasoning.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
month = {oct},
number = {7626},
pages = {467--468},
publisher = {Nature Research},
title = {{Artificial intelligence: Deep neural reasoning}},
url = {http://www.nature.com/doifinder/10.1038/nature19477},
volume = {538},
year = {2016}
}
@misc{Nowak2009,
author = {Nowak, Robert},
booktitle = {Lecture 3},
title = {{Statistical Learning Theory: Lecture Notes}},
year = {2009}
}
@article{BasrakRegularGARCH,
author = {Basrak, Bojan and Davis, Richard A. and Mikosch, Thomas},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Basrak, Davis, Mikosch - 2002 - Regular variation of GARCH processes.pdf:pdf},
journal = {Stochastic Processes and their Applications},
pages = {95--115},
title = {{Regular variation of GARCH processes}},
volume = {99},
year = {2002}
}
@article{Pascual2004,
author = {Pascual, Lorenzo and Romo, Juan and Ruiz, Esther},
doi = {10.1111/j.1467-9892.2004.01713.x},
issn = {0143-9782},
journal = {Journal of Time Series Analysis},
month = {jul},
number = {4},
pages = {449--465},
title = {{Bootstrap predictive inference for ARIMA processes}},
url = {http://doi.wiley.com/10.1111/j.1467-9892.2004.01713.x},
volume = {25},
year = {2004}
}
@article{barre:1973,
author = {Barre, R.},
journal = {Ann. Inst. Fourier},
number = {3},
pages = {227--312},
title = {{De quelques aspects dela th{\'{e}}orie des q-vari{\'{e}}t{\'{e}}s diff{\'{e}}rentielles et analytiques}},
volume = {23},
year = {1973}
}
@techreport{Million,
author = {Million, Elizabeth},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Million - Unknown - The Hadamard product.pdf:pdf},
title = {{The Hadamard product}}
}
@article{Andrews1983,
author = {Andrews, Donald},
journal = {Cowles Founda-tion Discussion Papers 664},
title = {{First order autoregressive processes and strong mixing}},
year = {1983}
}
@incollection{Terasvirta2006,
author = {Ter{\"{a}}svirta, Timo},
booktitle = {Handbook of Economic Forecasting},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Ter{\"{a}}svirta - 2006 - Forecasting Economic Variables with Nonlinear Models.pdf:pdf},
number = {05},
publisher = {Elsevier B.V.},
title = {{Forecasting Economic Variables with Nonlinear Models}},
volume = {1},
year = {2006}
}
@article{sandberg:linearization,
author = {Sandberg, Irwin W.},
doi = {10.1002/cta.205},
isbn = {0780374487},
issn = {00989886},
journal = {International Journal of Circuit Theory and Applications},
keywords = {Fr{\'{e}}chet derivatives,Hadamard's condition,Linearization,Stability},
number = {5},
pages = {511--517},
title = {{Stability and linearization: Discrete-time systems}},
volume = {30},
year = {2002}
}
@article{CvMtest2007,
author = {Genest, C. and Quessy, J. and R{\'{e}}millard, B.},
journal = {The Annals of Statistics},
pages = {169--191},
title = {{Assymptoric local efficiency of Cram{\'{e}}r-von-Mises tests for multivariate independence}},
volume = {35},
year = {2007}
}
@article{bollerslev:ccc,
author = {Bollerslev, Tim},
journal = {Review of Economics and Statistics},
number = {3},
pages = {498--505},
title = {{Modelling the coherence in short-run nominal exchange rates: A multivariate generalized ARCH model}},
volume = {72},
year = {1990}
}
@article{hunt:ott:1997,
abstract = {We consider simple Lyapunov-exponent-based conditions under which the response of a system to a chaotic$\backslash$ndrive is a smooth function of the drive state. We call this differentiable generalized synchronization {\~{}}DGS!.$\backslash$nWhen DGS does not hold, we quantify the degree of nondifferentiability using the HoЁlder exponent. We also$\backslash$ndiscuss the consequences of DGS and give an illustrative numerical example.},
author = {Hunt, Brian R. and Ott, Edward and Yorke, James A.},
doi = {10.1103/PhysRevE.55.4029},
issn = {1063651X},
journal = {Physical Review E},
number = {4},
pages = {4029--4034},
title = {{Differentiable generalized synchronization of chaos}},
volume = {55},
year = {1997}
}
@article{Tian2008,
abstract = {Fitting logistic regression models is challenging when their parameters are restricted. In this article, we first develop a quadratic lower-bound (QLB) algorithm for optimization with box or linear inequality constraints and derive the fastest QLB algorithm corresponding to the smallest global majorization matrix. The proposed QLB algorithm is particularly suited to problems to which EM-type algorithms are not applicable (e.g., logistic, multinomial logistic, and Cox's proportional hazards models) while it retains the same EM ascent property and thus assures the monotonic convergence. Secondly, we generalize the QLB algorithm to penalized problems in which the penalty functions may not be totally differentiable. The proposed method thus provides an alternative algorithm for estimation in lasso logistic regression, where the convergence of the existing lasso algorithm is not generally ensured. Finally, by relaxing the ascent requirement, convergence speed can be further accelerated. We introduce a pseudo-Newton method that retains the simplicity of the QLB algorithm and the fast convergence of the Newton method. Theoretical justification and numerical examples show that the pseudo-Newton method is up to 71 (in terms of CPU time) or 107 (in terms of number of iterations) times faster than the fastest QLB algorithm and thus makes bootstrap variance estimation feasible. Simulations and comparisons are performed and three real examples (Down syndrome data, kyphosis data, and colon microarray data) are analyzed to illustrate the proposed methods.},
author = {Tian, Guo-Liang and Tang, Man-Lai and Fang, Hong-Bin and Tan, Ming},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Tian et al. - 2008 - Efficient methods for estimating constrained parameters with applications to lasso logistic regression.pdf:pdf},
issn = {0167-9473},
journal = {Computational statistics {\&} data analysis},
month = {mar},
number = {7},
pages = {3528--3542},
title = {{Efficient methods for estimating constrained parameters with applications to lasso logistic regression.}},
url = {http://dx.doi.org/10.1016/j.csda.2007.11.007},
volume = {52},
year = {2008}
}
@incollection{Buteneers2009,
author = {Buteneers, Pieter and Schrauwen, Benjamin and Verstraeten, David and Stroobandt, Dirk},
booktitle = {Advances in Neuro-Information Processing},
doi = {10.1007/978-3-642-02490-0_7},
pages = {56--63},
publisher = {Springer Berlin Heidelberg},
title = {{Real-Time Epileptic Seizure Detection on Intra-cranial Rat Data Using Reservoir Computing}},
url = {http://link.springer.com/10.1007/978-3-642-02490-0{\_}7},
year = {2009}
}
@unpublished{Dueker2001,
author = {Dueker, Michael and Wesche, Katrin},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Dueker, Wesche - 2001 - European Business Cycles New Indices and Analysis of their Synchronicity.pdf:pdf},
institution = {The Federal Reserve Bank of St. Louis},
title = {{European Business Cycles : New Indices and Analysis of their Synchronicity}},
year = {2001}
}
@article{bierstone,
author = {Bierstone, E.},
journal = {Topology},
pages = {245--252},
title = {{Lifting isotopies from orbit spaces}},
volume = {14},
year = {1975}
}
@book{Kantorovich:Akilov,
author = {Kantorovich, L. V. and Akilov, G. P.},
edition = {Second},
publisher = {Pergamon Press},
title = {{Functional Analysis}},
year = {1982}
}
@article{HafnerCopula,
author = {Hafner, C. and Manner, H.},
journal = {Journal of Applied Econometrics},
number = {20},
pages = {269--295},
title = {{Dynamic stochastic copula models: Estimation, inference and applications}},
volume = {27},
year = {2011}
}
@article{Salehi2013,
abstract = {This paper seeks to investigate an approach of photonic reservoir computing for optical speech recognition on an examination isolated digit recognition task. An analytical approach in photonic reservoir computing is further drawn on to decrease time consumption, compared to numerical methods; which is very important in processing large signals such as speech recognition. It is also observed that adjusting reservoir parameters along with a good nonlinear mapping of the input signal into the reservoir, analytical approach, would boost recognition accuracy performance. Perfect recognition accuracy (i.e. 100{\{}{\%}{\}}) can be achieved for noiseless speech signals. For noisy signals with 0-10 db of signal to noise ratios, however, the accuracy ranges observed varied between 92{\{}{\%}{\}} and 98{\{}{\%}{\}}. In fact, photonic reservoir application demonstrated 9-18{\{}{\%}{\}} improvement compared to classical reservoir networks with hyperbolic tangent nodes. {\{}{\textcopyright}{\}} 2013 Elsevier B.V.},
author = {Salehi, Mohammad Reza and Abiri, Ebrahim and Dehyadegari, Louiza},
doi = {10.1016/j.optcom.2013.05.036},
issn = {00304018},
journal = {Optics Communications},
keywords = {Classic reservoir computing,Photonic reservoir computing,Semiconductor optical amplifiers,Speech recognition},
pages = {135--139},
publisher = {Elsevier},
title = {{An analytical approach to photonic reservoir computing - A network of SOA's - For noisy speech recognition}},
url = {http://dx.doi.org/10.1016/j.optcom.2013.05.036},
volume = {306},
year = {2013}
}
@unpublished{Proietti2011,
author = {Proietti, Tommaso and L{\"{u}}tkepohl, Helmut},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Proietti, L{\"{u}}tkepohl - 2011 - Does the Box-Cox transformation help in forecasting macroeconomic time series.pdf:pdf},
institution = {EUI},
series = {Department of Economics},
title = {{Does the Box-Cox transformation help in forecasting macroeconomic time series?}},
year = {2011}
}
@phdthesis{Hebiri2009,
author = {Hebiri, Mohamed},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Hebiri - 2009 - Quelques questions de s{\'{e}}lection de variables autour de l'estimateur lasso.pdf:pdf},
school = {Universit{\'{e}} Paris Diderot - Paris 7},
title = {{Quelques questions de s{\'{e}}lection de variables autour de l'estimateur lasso}},
year = {2009}
}
@article{WANG2002,
author = {Wang, Shaun S.},
issn = {0515-0361},
journal = {ASTIN Bulletin},
language = {English},
month = {nov},
number = {2},
pages = {213--234},
publisher = {Cambridge University Press},
title = {{A Universal Framework for Pricing Financial and Insurance Risks}},
url = {http://journals.cambridge.org/abstract{\_}S051503610001312X},
volume = {32},
year = {2002}
}
@article{engle:dcc,
author = {Engle, Robert F},
journal = {Journal of Business and Economic Statistics},
pages = {339--350},
title = {{Dynamic conditional correlation: a simple class of multivariate GARCH models}},
volume = {20},
year = {2002}
}
@article{Reinsel1980,
author = {Reinsel, G.},
journal = {Journal of the Royal Statistical Society. Series B},
pages = {328--333},
title = {{Asymptotic properties of prediction errors for multivariate autoregressive model using estimated parameters}},
volume = {42},
year = {1980}
}
@article{Anderson1971,
abstract = {A theory of information integration is applied to attitudes and social{\$}\backslash{\$}njudgments, based on a principle of information integration. For quantitative{\$}\backslash{\$}nanalysis, a simple but general algebraic model of judgment is used,{\$}\backslash{\$}nin which each informational stimulus is characterized by two parameters,{\$}\backslash{\$}nscale value and weight. Functional measurement procedures are employed{\$}\backslash{\$}nto derive equal-interval scales of parameter values. Exact tests{\$}\backslash{\$}nbased on analysis of variance are given for four applications of{\$}\backslash{\$}nthe model, and these applications are reconsidered under the further{\$}\backslash{\$}nrestriction imposed by the averaging hypothesis. Qualitative comparisons{\$}\backslash{\$}nare made to several other theories of attitude change. Tendencies{\$}\backslash{\$}ntoward balance and congruity are shown to be consequences of the{\$}\backslash{\$}nprinciple of information integration. Critical tests between integration{\$}\backslash{\$}ntheory, and balance and congruity theories are also suggested. Similar{\$}\backslash{\$}ncomparisons are made to summation theory, logical-consistency theory,{\$}\backslash{\$}nassimilation- contrast theory, and similarity-attraction theory.{\$}\backslash{\$}nMolar and molecular analyses of communication structure are considered{\$}\backslash{\$}nbriefly and the analysis of inconsistency resolution within integration{\$}\backslash{\$}ntheory is also discussed. Finally, it is noted that integration theory{\$}\backslash{\$}nhas had reasonable success in the areas of learning, perception,{\$}\backslash{\$}njudgment, decision making, and personality impressions, as well as{\$}\backslash{\$}nattitude change. It may thus provide a beginning to a unified general{\$}\backslash{\$}ntheory.},
author = {Anderson, Norman H},
doi = {10.1037/h0030834},
isbn = {1939-1471},
issn = {0033-295X},
journal = {Psychological Review},
number = {3},
pages = {171--206},
title = {{Integration theory and attitude change.}},
url = {http://content.apa.org/journals/rev/78/3/171},
volume = {78},
year = {1971}
}
@unpublished{Du2018,
abstract = {Gradient descent finds a global minimum in training deep neural networks despite the objective function being non-convex. The current paper proves gradient descent achieves zero training loss in polynomial time for a deep over-parameterized neural network with residual connections (ResNet). Our analysis relies on the particular structure of the Gram matrix induced by the neural network architecture. This structure allows us to show the Gram matrix is stable throughout the training process and this stability implies the global optimality of the gradient descent algorithm. We further extend our analysis to deep residual convolutional neural networks and obtain a similar convergence result.},
archivePrefix = {arXiv},
arxivId = {1811.03804},
author = {Du, Simon S. and Lee, Jason D. and Li, Haochuan and Wang, Liwei and Zhai, Xiyu},
eprint = {1811.03804},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Du et al. - 2018 - Gradient descent finds global minima of deep neural networks.pdf:pdf},
title = {{Gradient descent finds global minima of deep neural networks}},
url = {http://arxiv.org/abs/1811.03804},
year = {2018}
}
@unpublished{Hure2018,
author = {Hur{\'{e}}, C{\^{o}}me and Pham, Huyen and Bachouch, Achref and Langren{\'{e}}, Nicolas},
title = {{Deep neural networks algorithms for stochastic control problems on fi nite horizon, part I: convergence analysis}},
year = {2018}
}
@article{hilbert13,
author = {Hilbert, D.},
doi = {10.1007/BF01447867},
journal = {Mathematische Annalen},
month = {dec},
number = {1},
pages = {243--250},
publisher = {Springer-Verlag},
title = {{{\"{U}}ber die Gleichung neunten Grades}},
url = {http://link.springer.com/10.1007/BF01447867},
volume = {97},
year = {1927}
}
@article{lazaro:ortega4,
author = {L{\'{a}}zaro-Cam{\'{i}}, Andreu and Ortega, Juan-Pablo},
journal = {Annales de l'Institut Henri Poincar{\'{e}}, Probabilit{\'{e}}},
number = {4},
pages = {910--931},
title = {{Superposition rules and stochastic Lie-Scheffers systems}},
volume = {45},
year = {2009}
}
@article{Wang00,
author = {Wang, S. S.},
journal = {Journal of Risk and Insurance},
number = {1},
pages = {15--36},
title = {{A class of distortion operators for pricing financial and insurance risk}},
volume = {67},
year = {2000}
}
@article{Murray2019,
author = {Murray, James M.},
journal = {eLife},
title = {{Local online learning in recurrent networks with random feedback}},
volume = {8},
year = {2019}
}
@book{sontag:book,
abstract = {This textbook introduces the core concepts and results of Control and System Theory. Unique in its emphasis on foundational aspects, it takes a "hybrid" approach in which basic results are derived for discrete and continuous time scales, and discrete and continuous state variables. Primarily geared towards mathematically advanced undergraduate or graduate students, it may also be suitable for a second engineering course in control which goes beyond the classical frequency domain and state-space material. The choice of topics, together with detailed end-of-chapter links to the bibliography, makes it an excellent research reference as well. The Second Edition constitutes a substantial revision and extension of the First Edition, mainly adding or expanding upon advanced material, including: Lie-algebraic accessibility theory, feedback linearization, controllability of neural networks, reachability under input constraints, topics in nonlinear feedback design (such as backstepping, damping, control-Lyapunov functions, and topological obstructions to stabilization), and introductions to the calculus of variations, the maximum principle, numerical optimal control, and linear time-optimal control. Also covered, as in the First Edition, are notions of systems and automata theory, and the algebraic theory of linear systems, including controllability, observability, feedback equivalence, and minimality; stability via Lyapunov, as well as input/output methods; linear-quadratic optimal control; observers and dynamic feedback; Kalman filtering via deterministic optimal observation; parametrization of stabilizing controllers, and facts about frequency domain such as the Nyquist criterion.},
author = {Sontag, Eduardo},
doi = {10.1007/978-3-540-69532-5_16},
isbn = {9780387984896},
pages = {532},
publisher = {Springer-Verlag},
title = {{Mathematical Control Theory: Deterministic Finite Dimensional Systems}},
url = {papers2://publication/uuid/28C81B69-DB6C-433C-91C8-F6761AB37FAB},
year = {1998}
}
@article{zhang:echo,
author = {{Bai Zhang} and Miller, D. J. and {Yue Wang}},
doi = {10.1109/TNNLS.2011.2178562},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
month = {jan},
number = {1},
pages = {175--182},
title = {{Nonlinear system modeling with random matrices: echo state networks revisited}},
url = {http://ieeexplore.ieee.org/document/6105577/},
volume = {23},
year = {2012}
}
@article{Cruse2012,
abstract = {OBJECTIVES: Functional neuroimaging has shown that the absence of externally observable signs of consciousness and cognition in severely brain-injured patients does not necessarily indicate the true absence of such abilities. However, relative to traumatic brain injury, nontraumatic injury is known to be associated with a reduced likelihood of regaining overtly measurable levels of consciousness. We investigated the relationships between etiology and both overt and covert cognitive abilities in a group of patients in the minimally conscious state (MCS). METHODS: Twenty-three MCS patients (15 traumatic and 8 nontraumatic) completed a motor imagery EEG task in which they were required to imagine movements of their right-hand and toes to command. When successfully performed, these imagined movements appear as distinct sensorimotor modulations, which can be used to determine the presence of reliable command-following. The utility of this task has been demonstrated previously in a group of vegetative state patients. RESULTS: Consistent and robust responses to command were observed in the EEG of 22{\%} of the MCS patients (5 of 23). Etiology had a significant impact on the ability to successfully complete this task, with 33{\%} of traumatic patients (5 of 15) returning positive EEG outcomes compared with none of the nontraumatic patients (0 of 8). CONCLUSIONS: The overt behavioral signs of awareness (measured with the Coma Recovery Scale-Revised) exhibited by nontraumatic MCS patients appear to be an accurate reflection of their covert cognitive abilities. In contrast, one-third of a group of traumatically injured patients in the MCS possess a range of high-level cognitive faculties that are not evident from their overt behavior.},
author = {Cruse, D and Chennu, S and Chatelle, C and Fern{\'{a}}ndez-Espejo, D and Bekinschtein, T A and Pickard, J D and Laureys, S and Owen, A M},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Cruse et al. - 2012 - Relationship between etiology and covert cognition in the minimally conscious state.pdf:pdf},
issn = {1526-632X},
journal = {Neurology},
keywords = {Adolescent,Adult,Aged,Arousal,Arousal: physiology,Automatic Data Processing,Awareness,Awareness: physiology,Brain Injuries,Brain Injuries: complications,Child,Cognition,Cognition: physiology,Coma,Coma: psychology,Communication,Consciousness,Consciousness: physiology,Electroencephalography,Female,Hearing,Hearing: physiology,Humans,Imagination,Imagination: physiology,Male,Middle Aged,Movement,Movement: physiology,Ocular,Ocular: physiology,Persistent Vegetative State,Persistent Vegetative State: etiology,Persistent Vegetative State: psychology,Prognosis,Reflex,Reflex: physiology,Support Vector Machines,Verbal Behavior,Verbal Behavior: physiology,Vision,Young Adult},
language = {en},
month = {mar},
number = {11},
pages = {816--822},
publisher = {Lippincott Williams {\{}{\&}{\}} Wilkins},
title = {{Relationship between etiology and covert cognition in the minimally conscious state.}},
url = {http://www.neurology.org/content/78/11/816.full},
volume = {78},
year = {2012}
}
@article{Ghysels2007,
author = {Ghysels, Eric and Sinko, Arthur and Valkanov, Rossen},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Ghysels, Sinko, Valkanov - 2007 - MIDAS regressions Further results and new directions.pdf:pdf},
issn = {0747-4938},
journal = {Econometric Reviews},
keywords = {microstructure noise,nonlinear midas,risk,tick-by-tick applications,volatility},
month = {feb},
number = {1},
pages = {53--90},
title = {{MIDAS regressions: Further results and new directions}},
url = {http://www.tandfonline.com/doi/abs/10.1080/07474930600972467},
volume = {26},
year = {2007}
}
@article{Pesaran2011,
abstract = {This paper conducts a broad-based comparison of iterated and direct multi-period forecasting approaches applied to both univariate and multivariate models in the form of parsimonious factor-augmented vector autoregressions. To account for serial correlation in the residuals of the multi-period direct forecasting models we propose a new SURE-based estimation method and modified Akaike information criteria for model selection. Empirical analysis of the 170 variables studied by Marcellino, Stock and Watson (2006) shows that information in factors helps improve forecasting performance for most types of economic variables although it can also lead to larger biases. It also shows that SURE estimation and finite-sample modifications to the Akaike information criterion can improve the performance of the direct multi-period forecasts.},
author = {Pesaran, M. Hashem and Pick, Andreas and Timmermann, Allan},
issn = {03044076},
journal = {Journal of Econometrics},
month = {sep},
number = {1},
pages = {173--187},
title = {{Variable selection, estimation and inference for multi-period forecasting problems}},
url = {http://dx.doi.org/10.1016/j.jeconom.2011.02.018},
volume = {164},
year = {2011}
}
@article{Bollerslev2018,
author = {Bollerslev, T. and Patton, A. J. and Quaedvlieg, R.},
journal = {Journal of Econometrics},
number = {1},
pages = {71--91},
title = {{Modeling and forecasting (un)reliable realized covariances for more reliable financial decisions}},
volume = {207},
year = {2018}
}
@article{Rakhlin2014,
abstract = {MUCs are glycoproteins with various roles in homeostasis and carcinogenesis. Among other actions, MUC1 may inhibit cell-cell and cell-stroma interactions and function as a signal transducer, participating in cancer progression. In contrast, MUC2 is normally found only in goblet cells, where it contributes to the protective barrier function of these cells. Recently, a tumour suppressor role has been demonstrated for MUC2, and both MUC1 and MUC2 appear to have important roles in pancreatic neoplasia. MUC1 appears to be a marker of aggressive phenotype and may facilitate the vascular spread of carcinoma cells. In contrast, MUC2 is rarely detectable in aggressive pancreatic tumours, but is commonly expressed in intraductal papillary mucinous neoplasms (IPMNs), which are rare, indolent tumours, in intestinal IPMNs, and in indolent colloid carcinomas. MUC2 appears to be not only a marker of this indolent pathway, but also partly responsible for its less aggressive nature. Thus, in pancreatic neoplasia, MUC1 and MUC2 have potential diagnostic and prognostic value as markers of aggressive and indolent phenotypes, respectively, and have potential as therapeutic targets.},
author = {Rakhlin, Alexander and Sridharan, Karthik and Tewari, Ambuj},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Rakhlin, Sridharan, Tewari - 2014 - Sequential complexities and uniform martingale laws of large numbers.pdf:pdf},
journal = {Probability Theory and Related Fields},
keywords = {Dependent data,Empirical processes,Rademacher averages,Sequential prediction,Uniform Glivenko–Cantelli classes},
number = {1-2},
pages = {111--153},
pmid = {15113850},
title = {{Sequential complexities and uniform martingale laws of large numbers}},
volume = {161},
year = {2014}
}
@article{abraham:aggregation,
author = {Abraham, Bovas},
journal = {International Statistical Review},
keywords = {aggregates},
number = {3},
pages = {285--291},
title = {{Temporal aggregation and time series}},
volume = {50},
year = {1982}
}
@article{BEO2013,
address = {available at http://ssrn.com/abstract=2348407},
author = {Badescu, Alexandru and Elliott, Robert J. and Ortega, Juan-Pablo},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Badescu, Elliott, Ortega - 2015 - Non-Gaussian GARCH option pricing models and their diffusion limits.pdf:pdf},
institution = {Working paper},
journal = {European Journal of Operational Research},
pages = {820--830},
title = {{Non-Gaussian GARCH option pricing models and their diffusion limits}},
volume = {247},
year = {2015}
}
@book{peter2004machine,
author = {Peter, Sincak and Kaoru, Hirota and Jan, Vascak},
isbn = {981238751X},
publisher = {World Scientific},
title = {{Machine Intelligence: Quo Vadis?}},
url = {http://dl.acm.org/citation.cfm?id=6787{\%}5Cnhttp://books.google.com/books?hl=en{\&}lr={\&}id=AxA6EMfAKGsC{\&}oi=fnd{\&}pg=PR5{\&}dq=Machine+intelligence+quo+vadis{\%}3F{\&}ots=-V3TfZ7SRJ{\&}sig=5PQFVa4QIM0btc6l5q349rAl2s4},
year = {2004}
}
@article{Kukharenko2016,
annote = {PMID: 27588692},
author = {Kukharenko, Oleksandra and Sawade, Kevin and Steuer, Jakob and Peter, Christine},
doi = {10.1021/acs.jctc.6b00503},
journal = {Journal of Chemical Theory and Computation},
pages = {4726--4734},
title = {{Using dimensionality reduction to systematically expand conformational sampling of intrinsically disordered peptides}},
url = {http://dx.doi.org/10.1021/acs.jctc.6b00503},
volume = {12},
year = {2016}
}
@book{Borodin:Salminen,
address = {Basel},
author = {Borodin, Andrei N. and Salminen, Paavo},
publisher = {Birkhauser Verlag},
title = {{Handbook of Brownian Motion-Facts and Formulae}},
year = {2002}
}
@article{Pascual2005,
abstract = {In this paper, we propose a bootstrap procedure to construct prediction intervals for future values of a variable after a linear ARIMA model has been fitted to its power transformation. The procedure is easy to implement and provides a useful tool in empirical applications given that it is often the case that, for example, the log-transformation is modeled when the variable of interest for prediction is the original one. The advantages over existing methods for computing prediction intervals of power-transformed time series are that the proposed bootstrap intervals incorporate the variability due to parameter estimation and do not rely on distributional assumptions neither on the original variable nor on the transformed one. We derive the asymptotic distribution and show the good behavior of the bootstrap approach versus alternative procedures by means of Monte Carlo experiments. Finally, the procedure is illustrated by analyzing three real-time series data sets.},
author = {Pascual, Lorenzo and Romo, Juan and Ruiz, Esther},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {box–cox transformations,forecasting,non-gaussian distributions,resampling methods},
month = {apr},
number = {2},
pages = {219--235},
title = {{Bootstrap prediction intervals for power-transformed time series}},
url = {http://dx.doi.org/10.1016/j.ijforecast.2004.09.006},
volume = {21},
year = {2005}
}
@article{buehler2019deep,
author = {Buehler, Hans and Gonon, Lukas and Teichmann, Josef and Wood, Ben},
journal = {Quantitative Finance},
number = {8},
pages = {1271--1291},
publisher = {Taylor {\&} Francis},
title = {{Deep hedging}},
volume = {19},
year = {2019}
}
@article{chua1976qualitative,
author = {Chua, L and Green, D},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Chua, Green - 1976 - A qualitative analysis of the behavior of dynamic nonlinear networks Steady-state solutions of nonautonomous networ.pdf:pdf},
journal = {IEEE Transactions on Circuits and Systems},
number = {9},
pages = {530--550},
publisher = {IEEE},
title = {{A qualitative analysis of the behavior of dynamic nonlinear networks: Steady-state solutions of nonautonomous networks}},
volume = {23},
year = {1976}
}
@techreport{Chauvet2012,
abstract = {This paper provides an extensive analysis of the predictive ability of financial volatility measures for economic activity. We construct monthly measures of aggregated and industry-level stock volatility, and bond market volatility from daily returns. We model log financial volatility as composed of a long-run component that is common across all series, and a short-run component. If volatility has components, volatility proxies are characterized by large measurement error, which veils analysis of their fundamental information and relationship with the economy. We find that there are substantial gains from using the long term component of the volatility measures for linearly projecting future economic activity, as well as for forecasting business cycle turning points. When we allow for asymmetry in the long-run volatility component, we find that it provides early signals of upcoming recessions. In a real-time out-of-sample analysis of the last recession, we find that these signals are concomitant with the first signs of distress in the financial markets due to problems in the housing sector around mid-2007 and the implied chronology is consistent with the crisis timeline.},
author = {Chauvet, Marcelle and Senyuz, Zeynep and Yoldas, Emre},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Chauvet, Senyuz, Yoldas - 2012 - What does financial volatility tell us about macroeconomic fluctuations.pdf:pdf},
institution = {Federal Reserve Board},
keywords = {Business Cycles,Dynamic Factor Model,Forecasting,Markov Switching.,Probit model,Realized Volatility},
publisher = {Federal Reserve Board, Washington DC},
series = {Finance and Economics Discussion},
title = {{What does financial volatility tell us about macroeconomic fluctuations?}},
type = {Working Paper},
year = {2012}
}
@book{Loeve1977,
author = {Lo{\`{e}}ve, Michel},
edition = {Fourth},
pages = {425},
publisher = {Springer-Verlag, New York},
title = {{Probability Theory I}},
year = {1977}
}
@incollection{LutkepohlHandbook2006,
address = {Berlin},
author = {L{\"{u}}tkepohl, Helmut},
booktitle = {Handbook of Economic Forecasting},
editor = {Elliott, Graham and Granger, Clive and Timmermann, Allan},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/L{\"{u}}tkepohl - 2004 - Forecasting with VARMA Models.pdf:pdf;:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/L{\"{u}}tkepohl - 2006 - Forecasting with VARMA models.pdf:pdf},
number = {05},
pages = {287--325},
publisher = {Elsevier},
title = {{Forecasting with VARMA models}},
url = {http://www.eui.eu/Personal/Luetkepohl/VARMA-r1.pdf},
volume = {1},
year = {2006}
}
@article{CappielloAsymmetric2006,
author = {Cappiello, Lorenzo and Engle, Robert F. and Sheppard, Kevin K.},
journal = {Journal of Financial Economics},
number = {4},
pages = {537--572},
title = {{Asymmetric dynamics in the correlations of global equity and bond returns}},
volume = {4},
year = {2006}
}
@article{andersen:sorensen,
author = {Andersen, T G and S{\o}rensen, B E},
journal = {Journal of Business and Economic Statistics},
pages = {328--352},
title = {{GMM estimation of a stochastic volatility model: A Monte Carlo study}},
volume = {14},
year = {1996}
}
@article{Vlachas2019,
abstract = {How effective are Recurrent Neural Networks (RNNs) in forecasting the spatiotemporal dynamics of chaotic systems ? We address this question through a comparative study of Reservoir Computing (RC) and backpropagation through time (BPTT) algorithms for gated network architectures on a number of benchmark problems. We quantify their relative prediction accuracy on the long-term forecasting of Lorenz-96 and the Kuramoto-Sivashinsky equation and calculation of its Lyapunov spectrum. We discuss their implementation on parallel computers and highlight advantages and limitations of each method. We find that, when the full state dynamics are available for training, RC outperforms BPTT approaches in terms of predictive performance and capturing of the long-term statistics, while at the same time requiring much less time for training. However, in the case of reduced order data, large RC models can be unstable and more likely, than the BPTT algorithms, to diverge in the long term. In contrast, RNNs trained via BPTT capture well the dynamics of these reduced order models. This study confirms that RNNs present a potent computational framework for the forecasting of complex spatio-temporal dynamics.},
archivePrefix = {arXiv},
arxivId = {1910.05266},
author = {Vlachas, Pantelis R. and Pathak, Jaideep and Hunt, Brian R. and Sapsis, Themistoklis P. and Girvan, Michelle and Ott, Edward and Koumoutsakos, Petros},
eprint = {1910.05266},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Vlachas et al. - 2019 - Forecasting of Spatio-temporal Chaotic Dynamics with Recurrent Neural Networks a comparative study of Reservoir.pdf:pdf},
journal = {arXiv: 1910.05266},
keywords = {time-series forecasting},
title = {{Forecasting of Spatio-temporal Chaotic Dynamics with Recurrent Neural Networks: a comparative study of Reservoir Computing and Backpropagation Algorithms}},
url = {http://arxiv.org/abs/1910.05266},
year = {2019}
}
@article{euler:semidirect:products,
author = {Cendra, H. and Holm, D. D. and Marsden, J. E. and Ratiu, T. S.},
journal = {AMS Translations},
pages = {1--25},
title = {{Lagrangian reduction, the Euler-Poincar{\'{e}} equations, and semidirect products}},
volume = {186},
year = {1998}
}
@article{braioneRV2,
author = {Bauwens, Luc and Braione, Manuela and Storti, Giuseppe},
journal = {Annals of Economics and Statistics},
title = {{Forecasting comparison of long term component dynamic models for realized covariance matrices}},
year = {2016}
}
@article{dazord:1985,
author = {Dazord, P},
journal = {Nederl. Akad. Wetensch. Indag. Math.},
pages = {21--39},
title = {{Feuilletages {\{}{\`{a}}{\}} singularit{\{}{\'{e}}{\}}s}},
volume = {47},
year = {1985}
}
@article{Fernando2003,
annote = {bucket of water - cognitive computing, often mentioned as example},
author = {Fernando, Chrisantha and Sojakka, Sampsa},
journal = {7th European Conf. on Artificial Life},
pages = {588--597},
title = {{Pattern recognition in a bucket}},
year = {2003}
}
@article{Aielli2013,
abstract = {In this paper some issues that arise with the Dynamic Conditional Correlation (DCC) model are addressed. It is proven that the DCC large system estimator can be inconsistent, and that the traditional interpretation of the DCC correlation parameters can lead to misleading conclusions. A more tractable dynamic conditional correlation model, called cDCC model, is then suggested. The cDCC model allows for a large system estimator which is heuristically proven to be consistent. Sufficient stationarity conditions for cDCC processes of interest are established. The empirical performances of the DCC and cDCC large system estimators are compared via simulations and applications to real data.},
author = {Aielli, Gian Piero},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Aielli - 2013 - Dynamic Conditional Correlation on Properties and Estimation.pdf:pdf},
issn = {0735-0015},
journal = {Journal of Business {\&} Economic Statistics},
keywords = {Generalized Profile Likelihood.,Integrated Correlation,Multivariate GARCH Model,Quasi-Maximum-Likelihood,Two-step Estimation},
language = {en},
month = {jul},
number = {3},
pages = {282--299},
publisher = {Taylor {\&} Francis Group},
title = {{Dynamic Conditional Correlation: on Properties and Estimation}},
url = {http://amstat.tandfonline.com/doi/abs/10.1080/07350015.2013.771027{\#}.UaX9EZUjiap},
volume = {31},
year = {2013}
}
@article{Kalman1962,
author = {Kalman, R. E.},
journal = {Proceedings of National Academy Of Sciences USA},
number = {4},
pages = {596--600},
title = {{Canonical structure of linear dynamical systems}},
volume = {48},
year = {1962}
}
@incollection{vershynin:random:matrices,
author = {Vershynin, Roman},
booktitle = {Compressed Sensing},
pages = {210--268},
publisher = {Cambridge University Press},
title = {{Introduction to the non-asymptotic analysis of random matrices}},
year = {2012}
}
@article{Verousis2010,
author = {Verousis, T. and ap Gwilym, O.},
journal = {Journal of Derivatives and Hedge Funds},
pages = {323--340},
title = {{An improved algorithm for cleaning Ultra High-Frequency data}},
volume = {15},
year = {2010}
}
@article{zaremba,
abstract = {We present a simple regularization technique for Recurrent Neural Networks (RNNs) with Long Short-Term Memory (LSTM) units. Dropout, the most successful technique for regularizing neural networks, does not work well with RNNs and LSTMs. In this paper, we show how to correctly apply dropout to LSTMs, and show that it substantially reduces overfitting on a variety of tasks. These tasks include language modeling, speech recognition, image caption generation, and machine translation.},
archivePrefix = {arXiv},
arxivId = {1409.2329},
author = {Zaremba, Wojciech and Sutskever, Ilya and Vinyals, Oriol},
eprint = {1409.2329},
journal = {arXiv},
month = {sep},
title = {{Recurrent neural network regularization}},
url = {http://arxiv.org/abs/1409.2329},
year = {2014}
}
@unpublished{Jorda2008,
author = {Jord{\`{a}}, Oscar and Marcellino, Massimiliano},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Jord{\`{a}}, Marcellino - 2008 - Path forecast evaluation.pdf:pdf},
institution = {EUI},
title = {{Path forecast evaluation}},
year = {2008}
}
@article{Elhilali2008,
abstract = {Sound systems and speech technologies can benefit greatly from a deeper understanding of how the auditory system, and particularly the auditory cortex, is able to parse complex acoustic scenes into meaningful auditory objects and streams under adverse conditions. In the current work, a biologically plausible model of this process is presented, where the role of cortical mechanisms in organizing complex auditory scenes is explored. The model consists of two stages: (i) a feature analysis stage that maps the acoustic input into a multidimensional cortical representation and (ii) an integrative stage that recursively builds up expectations of how streams evolve over time and reconciles its predictions with the incoming sensory input by sorting it into different clusters. This approach yields a robust computational scheme for speaker separation under conditions of speech or music interference. The model can also emulate the archetypal streaming percepts of tonal stimuli that have long been tested in human subjects. The implications of this model are discussed with respect to the physiological correlates of streaming in the cortex as well as the role of attention and other top-down influences in guiding sound organization.},
author = {Elhilali, Mounya and Shamma, Shihab A},
issn = {1520-8524},
journal = {The Journal of the Acoustical Society of America},
keywords = {Acoustic Stimulation,Attention,Auditory Cortex,Auditory Cortex: physiology,Auditory Perception,Cluster Analysis,Computer Simulation,Humans,Models, Biological,Music,Noise,Pattern Recognition, Automated,Pattern Recognition, Physiological,Perceptual Masking,Pitch Perception,Sound Spectrography,Speech Perception,Time Factors},
month = {dec},
number = {6},
pages = {3751--71},
publisher = {Acoustical Society of America},
title = {{A cocktail party with a cortical twist: how cortical mechanisms contribute to sound segregation.}},
url = {http://scitation.aip.org/content/asa/journal/jasa/124/6/10.1121/1.3001672},
volume = {124},
year = {2008}
}
@article{Stentoft11,
author = {Stentoft, Lars},
journal = {Journal of Empirical Finance},
pages = {880--902},
title = {{American option pricing with discrete and continuous time models: An empirical comparison}},
volume = {18},
year = {2011}
}
@inproceedings{Anderson1996,
abstract = {Neural networks are trained to classify half-second segments of six-channel, EEGdata into one of five classes corresponding to five cognitive tasks performed by four subjects. Two and three-layer feedfor- ward neural networks are trained using 10-fold cross-validation and early stopping to control over-fitting. EEG signals were represented as autoregressive (AR) models.The average percentage of test segments correctly classified ranged from 71{\%} for one subject to 38{\%} foranother subject. Clusteranalysis of the resulting neural networks' hidden-unit weight vectors identifies which EEGchannels aremost relevant to this discrimination problem.},
author = {Anderson, Charles W. and Sijercic, Zlatko},
booktitle = {EANN},
title = {{Classification of EEG signals from four subjects during five mental tasks}},
year = {1996}
}
@article{Buteneers2013,
abstract = {In recent years, an increasing number of studies have investigated the effects of closed-loop anti-epileptic treatments. Most of the current research still is very labour intensive: real-time treatment is manually triggered and conclusions can only be drawn after multiple days of manual review and annotation of the electroencephalogram (EEG). In this paper we propose a technique based on reservoir computing (RC) to automatically and in real-time detect epileptic seizures in the intra-cranial EEG (iEEG) of epileptic rats in order to immediately trigger seizure treatment. The performance of the system is evaluated in two different seizure types: absence seizures from genetic absence epilepsy rats from Strasbourg (GAERS) and limbic seizures from post status epilepticus (PSE) rats. The dataset consists of 452 hours iEEG from 23 GAERS and 2083 hours iEEG from 22 PSE rats. In the default set-up the system detects 0.09 and 0.13 false positives per seizure and misses 0.07 and 0.005 events per seizure for GAERS and PSE rats respectively. It achieves an average detection delay below 1s in GAERS and less than 10s in the PSE data. This detection delay and the number of missed seizures can be further decreased when a higher false positive rate is allowed. Our method outperforms state-of-the-art detection techniques and only a few parameters require optimization on a limited training set. It is therefore suited for automatic seizure detection based on iEEG and may serve as a useful tool for epilepsy researchers. The technique avoids the time-consuming manual review and annotation of EEG and can be incorporated in a closed-loop treatment strategy.},
author = {Buteneers, Pieter and Verstraeten, David and Nieuwenhuyse, Bregt Van and Stroobandt, Dirk and Raedt, Robrecht and Vonck, Kristl and Boon, Paul and Schrauwen, Benjamin},
doi = {10.1016/j.eplepsyres.2012.07.013},
issn = {09201211},
journal = {Epilepsy Research},
number = {2},
pages = {124--134},
title = {{Real-time detection of epileptic seizures in animal models using reservoir computing}},
volume = {103},
year = {2013}
}
@article{Boix,
author = {Boix, Rafael R. and Medina, Francisco},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Boix, Medina - Unknown - Potencial escalar magn{\'{e}}tico y cargas de magnetizaci{\'{o}}n. C{\'{a}}lculo de la intensidad magn{\'{e}}tica en ausencia de co.pdf:pdf},
title = {{Potencial escalar magn{\'{e}}tico y cargas de magnetizaci{\'{o}}n. C{\'{a}}lculo de la intensidad magn{\'{e}}tica en ausencia de corrientes libres.}}
}
@article{Bauwens2006,
author = {Bauwens, Luc and Laurent, S{\'{e}}bastien and Rombouts, Jeroen V. K.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Bauwens, Laurent, Rombouts - 2006 - Multivariate GARCH models a survey.pdf:pdf},
issn = {0883-7252},
journal = {Journal of Applied Econometrics},
month = {jan},
number = {1},
pages = {79--109},
title = {{Multivariate GARCH models: a survey}},
url = {http://doi.wiley.com/10.1002/jae.842},
volume = {21},
year = {2006}
}
@article{moskalenko2010generalized,
author = {Moskalenko, Olga I and Koronovskii, Alexey A and Hramov, Alexander E},
journal = {Physics Letters A},
number = {29},
pages = {2925--2931},
publisher = {Elsevier},
title = {{Generalized synchronization of chaos for secure communication: Remarkable stability to noise}},
volume = {374},
year = {2010}
}
@article{Hoque1988,
abstract = {The finite-sample behaviour of the multi-period least-squares forecast is considered in the simple normal autoregressive model yt = $\beta$yt–1 + ut where ‖$\beta$‖ {\textless} 1. Necessary and sufficient conditions are established for the existence of the forecast bias and the mean-square forecast error (MSFE) and an exact expression for the MSFE is given. Exact numerical results are obtained for both the stationary and the fixed start-up case. Our main conclusions are that for small values of $\beta$ the MSFE is a decreasing function of the number of forecast periods, and that the behaviour of the MSFE in the stationary and the fixed start-up case is very similar, except for values of ‖$\beta$‖ close to 1.},
author = {Hoque, Asraul and Magnus, Jan R. and Pesaran, Bahram},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Hoque, Magnus, Pesaran - 1988 - The exact multi-period mean-square forecast error for the first-order autoregressive model.pdf:pdf},
issn = {03044076},
journal = {Journal of Econometrics},
month = {nov},
number = {3},
pages = {327--346},
title = {{The exact multi-period mean-square forecast error for the first-order autoregressive model}},
url = {http://dx.doi.org/10.1016/0304-4076(88)90062-0},
volume = {39},
year = {1988}
}
@inproceedings{hechtnielsen,
author = {Hecht-Nielsen},
booktitle = {International Joint Conference on Neural Networks},
doi = {10.1109/IJCNN.1989.118638},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Hecht-Nielsen - 1989 - Theory of the Backpropagation Neural Network.pdf:pdf},
pages = {593--605 vol.1},
publisher = {IEEE},
title = {{Theory of the backpropagation neural network}},
url = {http://ieeexplore.ieee.org/document/118638/},
year = {1989}
}
@article{Hinton2006,
author = {Hinton, G E and Salakhutdinov, R R},
doi = {10.1126/science.1127647},
issn = {0036-8075},
journal = {Science},
number = {5786},
pages = {504--507},
publisher = {American Association for the Advancement of Science},
title = {{Reducing the Dimensionality of Data with Neural Networks}},
url = {http://science.sciencemag.org/content/313/5786/504},
volume = {313},
year = {2006}
}
@article{Stentoft2005,
abstract = {As extensions to the Black–Scholes model with constant volatility, optionpricing models with time-varying volatility have been suggested within the framework of generalized autoregressive conditional heteroskedasticity (GARCH). However, application of the GARCHoptionpricing model has been hampered by the lack of simulation techniques able to incorporate early exercise features. In the present paper, we show how new simulation techniques can be used to price options which have the possibility of early exercise in a GARCH framework. We report the results from an extensive Monte Carlo study, indicating that incorporating GARCH features in the optionpricing model can potentially help explain some empirically well documented systematic pricing errors. Our empirical analysis of out-of-sample performance shows that GARCH effects are important when pricingoptions on individual stocks and lead to improvements over the constant volatility model. Specifications of the exponential GARCH-type generally have the smallest pricing errors.},
author = {Stentoft, Lars},
doi = {10.1016/j.jempfin.2004.08.001},
issn = {09275398},
journal = {Journal of Empirical Finance},
keywords = {c22,c53,g13},
month = {sep},
number = {4},
pages = {576--611},
title = {{Pricing American options when the underlying asset follows GARCH processes}},
url = {http://dx.doi.org/10.1016/j.jempfin.2004.08.001},
volume = {12},
year = {2005}
}
@book{cramer:mle,
abstract = {In this classic of statistical mathematical theory, Harald Cram{\'{e}}r joins the two major lines of development in the field: while British and American statisticians were developing the science of statistical inference, French and Russian probabilitists transformed the classical calculus of probability into a rigorous and pure mathematical theory. The result of Cram{\'{e}}r's work is a masterly exposition of the mathematical methods of modern statistics that set the standard that others have since sought to follow.For anyone with a working knowledge of undergraduate mathematics the book is self contained. The first part is an introduction to the fundamental concept of a distribution and of integration with respect to a distribution. The second part contains the general theory of random variables and probability distributions while the third is devoted to the theory of sampling, statistical estimation, and tests of significance.},
author = {Cram{\'{e}}r, Harald},
isbn = {0691005478},
pages = {575},
publisher = {Princeton University Press},
title = {{Mathematical Methods of Statistics}},
url = {http://books.google.com/books?hl=fr{\&}lr={\&}id=CRTKKaJO0DYC{\&}pgis=1},
year = {1946}
}
@article{aeyels1981generic,
author = {Aeyels, Dirk},
journal = {SIAM Journal on Control and Optimization},
number = {5},
pages = {595--603},
publisher = {SIAM},
title = {{Generic observability of differentiable systems}},
volume = {19},
year = {1981}
}
@article{mcleod:li:test,
author = {McLeod, A I and Li, W K},
issn = {0143-9782},
journal = {J. Time Ser. Anal.},
number = {4},
pages = {269--273},
title = {{Diagnostic checking {\{}ARMA{\}} time series models using squared-residual autocorrelations}},
volume = {4},
year = {1983}
}
@unpublished{Munkhdalai2020,
author = {Munkhdalai, Tsendsuren and Sordoni, Alessandro and Wang, Tong and Trischler, Adam},
title = {{Metalearned neural memory}},
year = {2020}
}
@book{Pisier2016,
author = {Pisier, Gilles},
publisher = {Cambridge University Press},
title = {{Martingales in Banach Spaces}},
year = {2016}
}
@incollection{sontag:polynomial:1979,
author = {Sontag, Eduardo D.},
booktitle = {Lecture Notes Control in Control and Information Sciences. Vol. 13},
publisher = {Springer Verlag},
title = {{Polynomial Response Maps}},
year = {1979}
}
@article{Andersen2003,
author = {Andersen, Torben G. and Bollerslev, Tim and Diebold, Francis X. and Labys, Paul},
doi = {10.1111/1468-0262.00418},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Andersen et al. - 2003 - Modeling and forecasting realized volatility.pdf:pdf},
issn = {0012-9682},
journal = {Econometrica},
month = {mar},
number = {2},
pages = {579--625},
title = {{Modeling and forecasting realized volatility}},
url = {http://doi.wiley.com/10.1111/1468-0262.00418},
volume = {71},
year = {2003}
}
@article{Lindsay_CL_1988,
author = {Lindsay, Bruce G.},
journal = {Contemporary Mathematics},
pages = {221--239},
title = {{Composite likelihood methods}},
volume = {80},
year = {1988}
}
@unpublished{Lobo2019,
author = {Lobo, Jesus L. and {Del Ser}, Javier and Bifet, Albert and Kasabov, Nikola},
title = {{Spiking neural networks and online learning: An overview and perspectives}},
year = {2019}
}
@article{Amemiya1972,
author = {Amemiya, Takeshi and Wu, Roland Y.},
journal = {Journal of the American Statistical Association},
number = {339},
pages = {628--632},
title = {{The effect of aggregation on prediction in the autoregressive model}},
volume = {67},
year = {1972}
}
@article{Phan2013,
abstract = {In their Personal View article in the August issue of The Lancet Neurology, Ralf Jox and colleagues discuss ethical and social aspects of requests from family members and surrogate decision makers for novel interventions in the clinical care of patients with disorders of consciousness (DOC).1 Functional imaging and neurophysiological approaches have been used to show awareness in some patients with DOC, despite clinical unresponsiveness. Jox and colleagues state that clinicians “must increasingly respond to requests by patients' families and surrogate decision makers to use novel techniques for diagnosis, prognosis, and treatment.” This statement could be interpreted in several ways, and I am concerned that clinicians might draw the conclusion that such interventions should be offered as part of routine clinical care. The responses of clinicians to requests for the use of novel techniques have far reaching consequences for patients, members of their immediate family, doctors, and the legal profession.
To effect a clinical “paradigm shift”—in which novel imaging and neurophysiological tests are available in routine clinical care—researchers would need to provide convincing evidence of the need for change, and to show that such change in clinical practice would not be harmful to patients. However, apart from references to results published in highly specialised journals—the product of studies by a small number of investigators in the field—these important data were not provided by Jox and colleagues. Consequently, it is uncertain whether or not a paradigm shift is needed or whether research in this exciting field must be continued.
As discussed by the authors, clinicians have difficulty differentiating the minimally conscious state (MCS) from the vegetative state or unresponsive wakefulness syndrome.2 Investigators are assessing data on the natural history of these disorders, but our knowledge is far from complete.3 In patients in a MCS, investigators have described wilful modulation of the functional MRI (fMRI) signal4 in survivors of traumatic brain injury, but wilful modulation was not seen in patients with anoxic coma. This raises questions about the topography of brain injury in patients with traumatic brain injury and anoxic coma, and the residual brain network necessary to generate neurophysiological activity that can be detected in these tests. Such simple data could be invaluable to clinicians in predicting the type of patient who would have such responses on fMRI. For example, damage to the white matter tracts and the thalami on diffusion tensor imaging has been proposed to help in differentiating between persistent vegetative state and MCS.5 Unfortunately, these data linking the location of injury to fMRI or electrophysiological test results were not the focus of this Personal View. This lack of information makes it difficult for clinicians to decide when to call in help, and whom to call in, to do such tests.
Few groups have undertaken studies using the novel imaging and neurophysiological approaches that Jox and colleagues describe, which demand a good understanding of the relevant research methodology and the use of mathematical platforms such as MATLAB (MathWorks, Natick, Massachusetts, USA), FMRIB Software Library (FSL), and Statistical Parametric Mapping (SPM) for the processing of functional images. I am not certain how many clinicians (neurologists and radiologists) are familiar with these analyses, which leads to the question of how generalisable these research methods are and to concerns about the potential harm to patients if such tests are not done properly.
Finally, what are the effects of these findings (modulation of brain activity) in patients with DOC on the patients and families involved in the research cited by Jox and colleagues?4 The authors state that requests for these interventions “provide an opportunity for clinicians to learn about patients' values and preferences”, but I am not certain how this can be achieved in practice. One can never be truly certain of the values of patients with DOC, because this understanding would require communication beyond simple answers such as yes and no. When the authors say that clinicians should “maintain clinical acumen for changes in patient status with the patients' best interests in mind”, do they mean that these patients should have regular MRIs every week for months or for years?
TGP has received honoraria as a speaker for Bayer and Genzyme.},
author = {Phan, Thanh G},
issn = {1474-4465},
journal = {Lancet neurology},
keywords = {Attitude of Health Personnel,Consciousness Disorders,Consciousness Disorders: diagnosis,Consciousness Disorders: therapy,Decision Making,Decision Making: ethics,Humans,Professional-Family Relations,Professional-Family Relations: ethics},
month = {feb},
number = {2},
pages = {131--2},
title = {{Disorders of consciousness: are we ready for a paradigm shift?}},
url = {http://www.thelancet.com/journals/a/article/PIIS1474-4422{\%}2812{\%}2970289-2/fulltext},
volume = {12},
year = {2013}
}
@article{galtier:sto,
abstract = {A method is provided for designing and training noise-driven recurrent neural networks as models of stochastic processes. The method unifies and generalizes two known separate modeling approaches, Echo State Networks (ESN) and Linear Inverse Modeling (LIM), under the common principle of relative entropy minimization. The power of the new method is demonstrated on a stochastic approximation of the El Ni{\~{n}}o phenomenon studied in climate research. {\textcopyright} 2014 Elsevier Ltd.},
archivePrefix = {arXiv},
arxivId = {arXiv:1402.1613v1},
author = {Galtier, Mathieu N. and Marini, Camille and Wainrib, Gilles and Jaeger, Herbert},
doi = {10.1016/j.neunet.2014.04.002},
eprint = {arXiv:1402.1613v1},
issn = {18792782},
journal = {Neural Networks},
keywords = {Echo state networks,El Nino southern oscillation,Linear inverse modeling,Relative entropy,Stochastic processes},
pages = {10--21},
pmid = {24815743},
publisher = {Elsevier Ltd},
title = {{Relative entropy minimizing noisy non-linear neural network to approximate stochastic processes}},
url = {http://dx.doi.org/10.1016/j.neunet.2014.04.002},
volume = {56},
year = {2014}
}
@techreport{tutorial:jaeger,
author = {Jaeger, Herbert},
institution = {Fraunhofer Institute for Autonomous Intelligent Systems},
pages = {46},
title = {{A tutorial on training recurrent neural networks, covering BPPT, RTRL, EKF and the "echo state network" approach}},
url = {http://minds.jacobs-university.de/sites/default/files/uploads/papers/ESNTutorialRev.pdf},
year = {2013}
}
@article{kaastra:1996,
author = {Kaastra, Iebeling and Boyd, Milton},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Kaastra, Boyd - 1996 - Designing a neural network for forecasting financial and economic time series.pdf:pdf},
journal = {Neurocomputing},
pages = {215--236},
title = {{Designing a neural network for forecasting financial and economic time series}},
volume = {10},
year = {1996}
}
@article{Stein1991,
abstract = {We study the stock price distributions that arise when prices follow a diffusion process with a stochastically varying volatility parameters. We use analytic techniques to derive an explicit closed-form solution for the case when volatility is driven by an arithmetic Ornstein-Uhlenbeck (or AR1) process. We then apply our results to two related problems in the finance literature: (i) options pricing in a world of stochastic volatility, and (ii) the relationship between stochastic volatility and the nature of 'fat tails' in stock price distributions.},
author = {Stein, E. M.},
doi = {10.1093/rfs/4.4.727},
issn = {14657368},
journal = {Review of Financial Studies},
month = {oct},
number = {4},
pages = {727--752},
title = {{Stock price distributions with stochastic volatility: an analytic approach}},
url = {http://rfs.oxfordjournals.org/content/4/4/727.short},
volume = {4},
year = {1991}
}
@article{Pastor2013,
author = {Stulp, Freek and Buchli, Jonas and Theodorou, Evangelos and Schaal, Stefan},
journal = {Robotics and Autonomous Systems},
number = {4},
pages = {351--361},
title = {{From dynamic movement primitives to associative skill memories}},
volume = {61},
year = {2013}
}
@book{Dieudonne:volumeV,
author = {Dieudonn{\'{e}}, Jean},
isbn = {0122155025},
publisher = {Academic Press, Inc.},
title = {{Treatise on Analysis. Volume V}},
volume = {V},
year = {1977}
}
@unpublished{CliveGranger1988,
author = {Granger, Clive W.J.},
institution = {Institute for Empirical Economics and University of Minnesota},
title = {{Aggregation of Time Series Variables, a survey}},
url = {http://minneapolisfed.org/research/DP/DP1.pdf},
year = {1988}
}
@article{Kloeden2003,
author = {Kloeden, Peter E.},
journal = {Electronic Journal of Differential Equations},
pages = {1--10},
title = {{Synchronization of nonautonomous dynamical systems}},
volume = {39},
year = {2003}
}
@book{Abraham1978,
author = {Abraham, Ralph and Marsden, Jerrold E.},
edition = {2nd},
publisher = {Addison-Wesley, Reading, MA},
title = {{Foundations of Mechanics}},
year = {1978}
}
@misc{Reinhart2009,
author = {Reinhart, Carmen M and Rogoff, Kenneth S},
booktitle = {World},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Reinhart, Rogoff - 2009 - The Aftermath of Financial Crises.pdf:pdf},
title = {{The Aftermath of Financial Crises}},
year = {2009}
}
@book{rohatgi1976,
author = {Rohatgi, Vijay K. and Saleh, A. K. Md. Ehsanes},
publisher = {John Wiley {\&} Sons},
title = {{An Introduction to Probability and Statistics}},
year = {1976}
}
@article{Pascanu2013a,
author = {Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Pascanu, Mikolov, Bengio - 2013 - On the difficulty of training recurrent neural networks.pdf:pdf},
journal = {Proceedings of Machine Learning Research},
number = {3},
pages = {1310--1318},
title = {{On the difficulty of training recurrent neural networks}},
volume = {28},
year = {2013}
}
@book{Munkres:topology,
author = {Munkres, James},
edition = {Second},
pages = {503},
publisher = {Pearson},
title = {{Topology}},
year = {2014}
}
@article{Basu1987,
author = {Basu, A. K. and {Sen Roy}, S.},
journal = {Calcutta Statistical Association Bulletin},
pages = {29--37},
title = {{On asymptotic prediction problems for multivariate autoregressive models in the unstable nonexplosive case}},
volume = {36},
year = {1987}
}
@incollection{james:stein,
address = {Berkeley, Calif.},
author = {James, W and Stein, Charles},
booktitle = {Proc. 4th Berkeley Sympos. Math. Statist. and Prob., Vol. I},
pages = {361--379},
publisher = {Univ. California Press},
title = {{Estimation with quadratic loss}},
year = {1961}
}
@article{Kukharenko2014,
author = {Kukharenko, Oleksandra},
journal = {Advances in Dynamical Systems and Applications},
number = {2},
pages = {199--211},
title = {{Control in systems of delay hyperbolic equations}},
url = {http://campus.mst.edu/adsa/contents/v9n2p7.pdf},
volume = {9},
year = {2014}
}
@article{pyragas:1996,
abstract = {It is shown that synchronization in unidirectionally coupled chaotic systems develops in two stages as the coupling strength is increased. The first stage is characterized by a weak synchronization, i.e., a response system subjected to a driving system undergoes a transition and exhibits a behavior completely insensitive to initial conditions. Further increase of the coupling strength causes the dimension decrease of the overall dynamics and leads finally to a strong synchronization. In this stage, the dimension of the strange attractor in the full phase space of the two systems saturates to the dimension of the driving attractor. {\textcopyright} 1996 The American Physical Society.},
author = {Pyragas, K.},
doi = {10.1103/PhysRevE.54.R4508},
issn = {1063651X},
journal = {Physical Review E - Statistical Physics, Plasmas, Fluids, and Related Interdisciplinary Topics},
number = {5},
pages = {4508--4511},
title = {{Weak and strong synchronization of chaos}},
volume = {54},
year = {1996}
}
@article{DeMiguel:naive,
author = {DeMiguel, Victor and Garlappi, Lorenzo and Uppal, Raman},
doi = {10.1093/rfs/hhm075},
journal = {Review of Financial Studies},
number = {5},
pages = {1915--1953},
title = {{Optimal Versus Naive Diversification: How Inefficient is the 1/N Portfolio Strategy?}},
url = {http://rfs.oxfordjournals.org/content/22/5/1915.abstract},
volume = {22},
year = {2009}
}
@article{RC21,
author = {Grigoryeva, Lyudmila and Hart, Allen G and Ortega, Juan-Pablo},
journal = {arXiv},
title = {{Learning strange attractors with reservoir systems}},
year = {2021}
}
@article{JPS2010,
author = {Jarrow, Robert A. and Protter, Philip and Shimbo, Kazuhiro},
issn = {09601627},
journal = {Mathematical Finance},
month = {apr},
number = {2},
pages = {145--185},
title = {{Asset price bubbles in incomplete markets}},
url = {http://doi.wiley.com/10.1111/j.1467-9965.2010.00394.x},
volume = {20},
year = {2010}
}
@article{Esscher1932,
author = {Esscher, F.},
journal = {Skandinavisk Aktuarietidskrift},
pages = {175--195},
title = {{On the probability function in the collective theory of risk}},
volume = {15},
year = {1932}
}
@article{Marcellino2010,
abstract = {This paper compares different ways to estimate the current state of the economy using factor models that can handle unbalanced datasets. Due to the different release lags of business cycle indicators, data unbalancedness often emerges at the end of multivariate samples, which is sometimes referred to as the 'ragged edge' of the data. Using a large monthly dataset of the German economy, we compare the performance of different factor models in the presence of the ragged edge: static and dynamic principal components based on realigned data, the Expectation-Maximisation (EM) algorithm and the Kalman smoother in a state-space model context. The monthly factors are used to estimate current quarter GDP, called the 'nowcast', using different versions of what we call factor-based mixed-data sampling (Factor-MIDAS) approaches. We compare all possible combinations of factor estimation methods and Factor-MIDAS projections with respect to nowcast performance. Additionally, we compare the performance of the nowcast factor models with the performance of quarterly factor models based on time-aggregated and thus balanced data, which neglect the most timely observations of business cycle indicators at the end of the sample. Our empirical findings show that the factor estimation methods don't differ much with respect to nowcasting accuracy. Concerning the projections, the most parsimonious MIDAS projection performs best overall. Finally, quarterly models are in general outperformed by the nowcast factor models that can exploit ragged-edge data.},
author = {Marcellino, Massimiliano and Schumacher, Christian},
issn = {03059049},
journal = {Oxford Bulletin of Economics and Statistics},
number = {4},
pages = {518--550},
publisher = {SSRN},
title = {{Factor MIDAS for nowcasting and forecasting with ragged-edge data: A model comparison for German GDP}},
url = {http://doi.wiley.com/10.1111/j.1468-0084.2010.00591.x},
volume = {72},
year = {2010}
}
@inproceedings{kulis:sra:dhillon,
author = {Kulis, Brian and Sustik, Suvrit S and Dhillon, Inderjit S},
booktitle = {Proceedings of the 12th International Conference on Artificial Intelligence and Statistics (AISTATS) 2009},
pages = {296--303},
title = {{Convex perturbations for scalable semidefinite programming}},
year = {2009}
}
@article{JuslinOlssonEtAl2003,
author = {Juslin, Peter and Olsson, Henrik and Olsson, Anna-Carin},
doi = {10.1037/0096-3445.132.1.133},
issn = {0096-3445},
journal = {Journal of Experimental Psychology: General},
keywords = {Exemplar,numerische Sch{\"{a}}tzungen,numerische Sch�tzungen},
number = {1},
pages = {133--156},
title = {{Exemplar effects in categorization and multiple-cue judgment.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0096-3445.132.1.133},
volume = {132},
year = {2003}
}
@inproceedings{Allen-Zhu2019,
abstract = {Deep neural networks (DNNs) have demonstrated dominating performance in many fields; since AlexNet, networks used in practice are going wider and deeper. On the theoretical side, a long line of works has been focusing on training neural networks with one hidden layer. The theory of multi-layer networks remains largely unsettled. In this work, we prove why stochastic gradient descent (SGD) can find {\$}\backslashtextit{\{}global minima{\}}{\$} on the training objective of DNNs in {\$}\backslashtextit{\{}polynomial time{\}}{\$}. We only make two assumptions: the inputs are non-degenerate and the network is over-parameterized. The latter means the network width is sufficiently large: {\$}\backslashtextit{\{}polynomial{\}}{\$} in {\$}L{\$}, the number of layers and in {\$}n{\$}, the number of samples. Our key technique is to derive that, in a sufficiently large neighborhood of the random initialization, the optimization landscape is almost-convex and semi-smooth even with ReLU activations. This implies an equivalence between over-parameterized neural networks and neural tangent kernel (NTK) in the finite (and polynomial) width setting. As concrete examples, starting from randomly initialized weights, we prove that SGD can attain 100{\%} training accuracy in classification tasks, or minimize regression loss in linear convergence speed, with running time polynomial in {\$}n,L{\$}. Our theory applies to the widely-used but non-smooth ReLU activation, and to any smooth and possibly non-convex loss functions. In terms of network architectures, our theory at least applies to fully-connected neural networks, convolutional neural networks (CNN), and residual neural networks (ResNet).},
archivePrefix = {arXiv},
arxivId = {1811.03962},
author = {Allen-Zhu, Zeyuan and Li, Yuanzhi and Song, Zhao},
booktitle = {ICML},
eprint = {1811.03962},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Allen-Zhu, Li, Song - 2018 - A convergence theory for deep learning via over-parameterization.pdf:pdf},
title = {{A convergence theory for deep learning via over-parameterization}},
url = {http://arxiv.org/abs/1811.03962},
year = {2019}
}
@book{Silvestrini2008,
author = {Silvestrini, Andrea and Veredas, David},
booktitle = {Journal of Economic Surveys},
doi = {10.1111/j.1467-6419.2007.00538.x},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Silvestrini, Veredas - 2008 - Temporal aggregation of univariate and multivariate time series models a survey.pdf:pdf},
issn = {0950-0804},
month = {jul},
number = {3},
pages = {458--497},
title = {{Temporal aggregation of univariate and multivariate time series models: a survey}},
url = {http://doi.wiley.com/10.1111/j.1467-6419.2007.00538.x},
volume = {22},
year = {2008}
}
@inproceedings{greydanus2019hamiltonian,
author = {Greydanus, Samuel and Dzamba, Misko and Yosinski, Jason},
booktitle = {Advances in Neural Information Processing Systems},
pages = {15353--15363},
title = {{Hamiltonian neural networks}},
year = {2019}
}
@article{Chevillon2007,
author = {Chevillon, Guillaume},
doi = {10.1111/j.1467-6419.2007.00518.x},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Chevillon - 2007 - Direct multi-step estimation and forecasting.pdf:pdf;:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Chevillon - 2007 - Direct multi-step estimation and forecasting(2).pdf:pdf},
issn = {0950-0804},
journal = {Journal of Economic Surveys},
keywords = {adaptive estimation,multi-step forecasting,non-stationarity,struc-,tural breaks,varying horizon},
month = {sep},
number = {4},
pages = {746--785},
title = {{Direct multi-step estimation and forecasting}},
url = {http://doi.wiley.com/10.1111/j.1467-6419.2007.00518.x},
volume = {21},
year = {2007}
}
@article{Paquot2012,
abstract = {Reservoir computing is a recently introduced, highly efficient bio-inspired approach for processing time dependent data. The basic scheme of reservoir computing consists of a non linear recurrent dynamical system coupled to a single input layer and a single output layer. Within these constraints many implementations are possible. Here we report an optoelectronic implementation of reservoir computing based on a recently proposed architecture consisting of a single non linear node and a delay line. Our implementation is sufficiently fast for real time information processing. We illustrate its performance on tasks of practical importance such as nonlinear channel equalization and speech recognition, and obtain results comparable to state of the art digital implementations.},
author = {Paquot, Y. and Duport, F. and Smerieri, A. and Dambre, J. and Schrauwen, B. and Haelterman, M. and Massar, S.},
issn = {2045-2322},
journal = {Scientific reports},
language = {en},
month = {jan},
pages = {287},
publisher = {Nature Publishing Group},
title = {{Optoelectronic reservoir computing}},
volume = {2},
year = {2012}
}
@book{Daubech1992,
author = {Daubechies, Ingrid},
title = {{Ten Lectures on Wavelets}},
year = {1992}
}
@misc{Raginsky2017,
author = {Raginsky, Maxim},
title = {{Statistical Learning Theory: Lecture Notes}},
url = {http://maxim.ece.illinois.edu/teaching/SLT/},
year = {2017}
}
@article{Lutkepohl1984,
author = {L{\"{u}}tkepohl, Helmut},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/L{\"{u}}tkepohl - 1984 - Forecasting contemporaneously aggregated Vector ARMA processes.pdf:pdf},
journal = {Journal of Business {\&} Economic Statistics},
keywords = {aic,subset vector autoregression},
number = {3},
pages = {201--214},
title = {{Forecasting contemporaneously aggregated Vector ARMA processes}},
url = {http://www.jstor.org/stable/10.2307/1391703},
volume = {2},
year = {1984}
}
@article{Heinecke2020,
author = {Heinecke, Andreas and Ho, Jinn and Hwang, Wen-Liang},
journal = {IEEE Signal Processing Letters},
pages = {1175--1179},
title = {{Refinement and universal approximation via sparsely connected relu convolution nets}},
volume = {27},
year = {2020}
}
@article{ing2003,
author = {Ing, Ching-Kang},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Ing - 2003 - Multistep prediction in autoregressive processes.pdf:pdf},
journal = {Econometric Theory},
number = {2},
pages = {254--279},
title = {{Multistep prediction in autoregressive processes}},
volume = {19},
year = {2003}
}
@misc{TheMendeleySupportTeam2011,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/The Mendeley Support Team - 2011 - Getting Started with Mendeley.pdf:pdf},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@article{Jimenez1995,
author = {Jimenez, J. C. and Biscay, R. and Montoto, O.},
journal = {Biological Cybernetics},
pages = {249--259},
title = {{Modeling the electroencephalogram by means of spatial spline smoothing and temporal autoregression}},
volume = {72},
year = {1995}
}
@article{McDonald2012,
abstract = {We derive generalization error bounds for traditional time-series forecasting models. Our results hold for many standard forecasting tools including autoregressive models, moving average models, and, more generally, linear state-space models. These non-asymptotic bounds need only weak assumptions on the data-generating process, yet allow forecasters to select among competing models and to guarantee, with high probability, that their chosen model will perform well. We motivate our techniques with and apply them to standard economic and financial forecasting tools---a GARCH model for predicting equity volatility and a dynamic stochastic general equilibrium model (DSGE), the standard tool in macroeconomic forecasting. We demonstrate in particular how our techniques can aid forecasters and policy makers in choosing models which behave well under uncertainty and mis-specification.},
author = {McDonald, Daniel J. and Shalizi, Cosma Rohilla and Schervish, Mark},
journal = {Journal of Machine Learning Research},
keywords = {generalization error,linear time-invariant systems,model selection,prediction risk,space models,state-,vc dimension},
pages = {1--40},
title = {{Nonparametric risk bounds for time-series forecasting}},
volume = {18},
year = {2017}
}
@article{Duan2004,
abstract = {This paper investigates theoretical and practical aspects of options that are based upon two or more assets which are co-integrated. For this purpose, a new, discrete-time model of assetprices is developed, a model featuring both the co-integration property as well as stochastic volatilities. Using a GARCH, equilibrium-based option pricing approach, it is shown that when volatilities are deterministic the optionprices do not depend on the co-integration parameters, except for the mis-specification effect as to the manner in which the volatilities are estimated. However, with stochastic volatilities the optionprices explicitly depend upon the co-integration parameters. In order to understand these results better, this paper also examines a continuous-time, diffusion limit of the assetprice system and empirically studies the co-integration effect using spread options based upon the S{\&}P500 and the NASDAQ100. These numerical results suggest that consideration of co-integration can substantially alter the value, delta and vega of a spread option.},
author = {Duan, Jin-Chuan and Pliska, Stanley R.},
issn = {01651889},
journal = {Journal of Economic Dynamics and Control},
keywords = {c3,g13},
month = {jan},
number = {4},
pages = {727--754},
title = {{Option valuation with co-integrated asset prices}},
url = {http://dx.doi.org/10.1016/S0165-1889(03)00042-3},
volume = {28},
year = {2004}
}
@article{pollock2003,
author = {Pollock, D.S.G.},
journal = {Computational Statistics {\&} Data Analysis},
pages = {37--75},
title = {{Recursive estimation in econometrics}},
volume = {44},
year = {2003}
}
@article{sandberg:extra:term,
abstract = {A central role in the theory of discrete-time linear systems is played$\backslash$nby the idea that every such system has an input-output map that can$\backslash$nbe represented by a convolution or the familiar generalization of$\backslash$na convolution. This thinking involves an oversight that was recently$\backslash$ncorrected by adding an additional term to the representation. Here$\backslash$nwe give and discuss a corresponding result for the important case$\backslash$nof representations of multidimensional continuous-space system maps},
author = {Sandberg, Irwin W.},
doi = {10.1002/(SICI)1097-007X(199907/08)27:4<415::AID-CTA70>3.0.CO;2-Z},
issn = {00989886},
journal = {International Journal of Circuit Theory and Applications},
keywords = {Additional term,Linear systems,Multidimensional systems},
number = {4},
pages = {415--420},
title = {{Multidimensional linear systems: The extra term}},
volume = {27},
year = {1999}
}
@book{Zupan1999,
address = {New York, NY},
author = {Zupan, J. and Gasteiger, J.},
edition = {2nd},
publisher = {John Wiley $\backslash${\&} Sons},
title = {{Neural Networks in Chemistry and Drug Design}},
year = {1999}
}
@book{hebbey:book:english,
author = {Hebey, Emmanuel},
publisher = {Springer-Verlag Berlin Heidelberg},
title = {{Sobolev Spaces on Riemannian Manifolds}},
year = {1996}
}
@unpublished{Prater2016,
abstract = {Reservoir computing is a recently introduced machine learning paradigm that has been shown to be well-suited for the processing of spatiotemporal data. Rather than training the network node connections and weights via backpropagation in traditional recurrent neural networks, reservoirs instead have fixed connections and weights among the 'hidden layer' nodes, and traditionally only the weights to the output layer of neurons are trained using linear regression. We claim that for signal classification tasks, one may forgo the weight training step entirely and instead use a simple supervised clustering method. The proposed method is analyzed theoretically and explored through numerical experiments on real-world data. The examples demonstrate that the proposed clustering method outperforms the traditional trained output weight approach in terms of speed, accuracy, and sensitivity to reservoir parameters.},
archivePrefix = {arXiv},
arxivId = {arXiv:1604.03073v1},
author = {Prater, Ashley},
eprint = {arXiv:1604.03073v1},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Prater - 2016 - Reservoir computing for spatiotemporal signal classification without trained output weights.pdf:pdf},
number = {April},
pages = {1--12},
title = {{Reservoir computing for spatiotemporal signal classification without trained output weights}},
year = {2016}
}
@article{Choudhry2007,
abstract = {This paper investigates empirically the change(s) in the long-run relationship(s) between the stock prices of eight Far East countries around the Asian financial crisis of 1997–98. Further tests are conducted to check the change in the influence of the Japanese and the US stock markets in the Far East Region before, during and after the crisis. Empirical investigation is conducted by means of rolling correlation coefficients, the Johansen multivariate cointegration method, causality tests and band spectrum regression. Results show significant long-run relationship(s) and linkage between the Far East markets before, during, and after the crisis. The most significant linkage and relationship are found during the crisis period. Results mostly indicate larger US influence in all periods but some evidence of increasing Japanese influence is also shown.},
author = {Choudhry, Taufiq and Lu, Lin and Peng, Ke},
issn = {10575219},
journal = {International Review of Financial Analysis},
keywords = {BSR,Cointegration,Financial crisis,G1,G14,Rolling correlation coefficient},
month = {jan},
number = {3},
pages = {242--261},
title = {{Common stochastic trends among Far East stock prices: Effects of the Asian financial crisis}},
url = {http://www.sciencedirect.com/science/article/pii/S1057521906000998},
volume = {16},
year = {2007}
}
@article{clapp:puppe:1986,
author = {Clapp, M. and Puppe, D.},
journal = {Transactions Amer. Math. Soc.},
pages = {603--620},
title = {{Invariants of Lusternik-Schnirelmann type and the topology of critical sets}},
volume = {298},
year = {1986}
}
@article{field:83,
author = {Field, M. J.},
journal = {Proc. London Math. Soc.},
pages = {487--516},
title = {{Isotopy and stability of equivariant diffeomorphisms}},
volume = {46},
year = {1983}
}
@book{HandbookEconForecasting2006,
abstract = {The aim of the Handbooks in Economics series is to produce Handbooks for various branches of economics, each of which is a definitive source, reference, and teaching supplement for use by professional researchers and advanced graduate students. Each Handbook provides self-contained surveys of the current state of a branch of economics in the form of chapters prepared by leading specialists on various aspects of this branch of economics. These surveys summarize not only received results but also newer devel- opments, from recent journal articles and discussion papers. Some original material is also included, but the main goal is to provide comprehensive and accessible surveys. The Handbooks are intended to provide not only useful reference volumes for profes- sional collections but also possible supplementary readings for advanced courses for graduate students in economics.},
edition = {1},
editor = {Elliott, Graham and Granger, Clive and Timmermann, Allan},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Unknown - 2006 - Handbook of Economic Forecasting.pdf:pdf},
isbn = {9780444513953},
publisher = {Elsevier},
title = {{Handbook of Economic Forecasting}},
year = {2006}
}
@article{Hauser1994a,
abstract = {In this paper, we present a technique for constructing a class of quadratic Lyapunov functions for exponentially stable periodic orbits. This construction is facilitated by the use of a special set of local coordinates that serve to highlight the tangential and transverse dynamics of the system.},
author = {Hauser, John},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Hauser - 1994 - Converse Lyapunov functions for exponentially stable periodic orbits.pdf:pdf},
issn = {01676911},
journal = {Systems {\&} Control Letters},
keywords = {Converse Lyapunov functions,nonlinear systems,periodic Lyapunov equation,periodic orbits,stability,transverse linearization},
month = {jul},
number = {1},
pages = {27--34},
title = {{Converse Lyapunov functions for exponentially stable periodic orbits}},
url = {http://www.sciencedirect.com/science/article/pii/0167691194900787},
volume = {23},
year = {1994}
}
@article{Bridges,
author = {Bridges, T. J.},
journal = {Stud. Appl. Math.},
pages = {93--120},
title = {{$\backslash${\$}O(2)\backslash{\$}-invariant hamiltonians on $\backslash${\$}\backslashbC{\^{}}4\backslash{\$} and the (m,n) mode-interaction problem for capillary-gravity waves}},
volume = {82},
year = {1990}
}
@phdthesis{Callonnec2005,
author = {Callonnec, Ga{\"{e}}l},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Callonnec - 2005 - Politique mon{\'{e}}taire et bulle sp{\'{e}}culative.pdf:pdf},
school = {Institut d'Etudes Politiques de Paris},
title = {{Politique mon{\'{e}}taire et bulle sp{\'{e}}culative}},
year = {2005}
}
@phdthesis{BatresThesis,
author = {Batres-Estrada, Gilberto},
title = {{Deep Learning for Multivariate Financial Time Series}},
year = {2015}
}
@inproceedings{sontag:universalTuring,
author = {Siegelmann, Hava T and Sontag, Eduardo D.},
booktitle = {COLT '92 Proceedings of the fifth annual workshop on Computational learning theory},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Siegelmann, Sontag - 1992 - On the computational power of neural nets.pdf:pdf},
issn = {1016-3328},
pages = {440--449},
title = {{On the computational power of neural nets}},
year = {1992}
}
@article{Siu04,
author = {Siu, Tak Kuen and Tong, Howell and Yang, H.},
journal = {North American Actuarial Journal},
number = {3},
pages = {17--32},
title = {{On pricing derivatives under GARCH models: a dynamic Gerber-Shiu approach}},
volume = {8},
year = {2004}
}
@article{persistence:periodic,
author = {Montaldi, J. A.},
journal = {C. R. Acad. Sci. Paris S{\'{e}}r. I Math.},
pages = {553--558},
title = {{Persistance d'orbites p{\'{e}}riodiques relatives dans les syst{\`{e}}mes hamiltoniens sym{\'{e}}triques}},
volume = {324},
year = {1997}
}
@inproceedings{SX2003b,
address = {Berlin, Heidelberg},
author = {Scheinkman, Jos{\'{e}} A. and Xiong, Wei},
booktitle = {Paris-Princeton Lectures on Mathematical Finance 2003},
editor = {Carmona, Ren{\'{e}} A. and {\c{C}}inlar, Erhan and Ekeland, Ivar and Jouini, Elyes and Scheinkman, Jos{\'{e}} A. and Touzi, Nizar},
pages = {217--250},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Mathematics},
title = {{Heterogeneous beliefs, speculation and trading in financial markets}},
url = {http://www.springerlink.com/index/10.1007/b98353},
volume = {1847},
year = {2004}
}
@incollection{nfgs,
address = {Dordrecht},
author = {Guillemin, V. and Sternberg, S.},
booktitle = {Differential Geometric Methods in Mathematical Physics},
editor = {Sternberg, S.},
pages = {161--175},
publisher = {Reidel Publishing Company},
title = {{A normal form for the momentum map}},
year = {1984}
}
@book{Crainic:and:Fernandes:annals,
author = {Crainic, M. and {Loja Fernandes}, R.},
booktitle = {Ann. of Math.},
publisher = {To appear in Ann. ofMath,},
title = {{Integrability of Lie brackets}},
year = {2000}
}
@book{brown:churchill,
author = {Brown, James Ward and Churchill, Ruel V.},
edition = {Eighth},
publisher = {McGraw-Hill},
title = {{Complex Variables and Applications Eighth Edition}},
year = {2009}
}
@article{kalman1960new,
author = {Kalman, Rudolph Emil},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Kalman - 1960 - A new approach to linear filtering and prediction problems(2).pdf:pdf},
journal = {Journal of Basic Engineering},
number = {1},
pages = {35--45},
title = {{A new approach to linear filtering and prediction problems}},
volume = {82},
year = {1960}
}
@article{Busemeyer1993,
abstract = {Examines the influences of the validity of once cue on the effectiveness of another cue for predicting a criterion. Demonstration of a cue competition effect (CCE); Analysis of the regression coefficients estimated from the predictions of the subject as a function of training; Generality of CCE from contexts in which the cues are positively correlated.},
author = {Busemeyer, Jerome R and Myung, In Jae and McDaniel, Mark A M},
doi = {10.1111/j.1467-9280.1993.tb00486.x},
isbn = {09567976},
issn = {0956-7976},
journal = {Psychological Science},
month = {may},
number = {3},
pages = {190--195},
pmid = {8562440},
title = {{Cue competition effects: Empirical tests of adaptive network learning models}},
url = {http://pss.sagepub.com/lookup/doi/10.1111/j.1467-9280.1993.tb00486.x http://pss.sagepub.com/content/4/3/190.short},
volume = {4},
year = {1993}
}
@article{Schoeneman2020,
author = {Schoeneman, Frank and Chandola, Varun and Napp, Nils and Wodo, Olga and Zola, Jaroslaw},
journal = {Algorithms},
number = {30},
title = {{Learning manifolds from dynamic process data}},
volume = {13},
year = {2020}
}
@incollection{Han:Mu,
author = {Han, Min and Mu, Dayun},
booktitle = {Advances in Neural Networks - International Symposium on Neural Networks 2010},
doi = {10.1007/978-3-642-13278-0_58},
editor = {Zhang, L. and Lu, B. L. and Kwok, J.},
pages = {450--456},
publisher = {Springer, Berlin, Heidelberg},
title = {{Multi-reservoir echo state network with sparse Bayesian learning}},
url = {http://link.springer.com/10.1007/978-3-642-13278-0{\_}58},
year = {2010}
}
@article{gallant:wihite,
abstract = {Recently, multiple input, single output, single hidden-layer feedforward neural networks have been shown to be capable of approximating a nonlinear map and its partial derivatives. Specifically, neural nets have been shown to be dense in various Sobolev spaces. Building upon this result, we show that a net can be trained so that the map and its derivatives are learned. Specifically, we use a result of Gallant's to show that least squares and similar estimates are strongly consistent in Sobolev norm provided the number of hidden units and the size of the training set increase together. We illustrate these results by an application to the inverse problem of chaotic dynamics: recovery of a nonlinear map from a time series of iterates. These results extend automatically to nets that embed the single hidden layer, feedforward network as a special case.},
author = {Gallant, A. Ronald and White, Halbert},
doi = {10.1016/S0893-6080(05)80011-5},
issn = {08936080},
journal = {Neural Networks},
number = {1},
pages = {129--138},
title = {{On learning the derivatives of an unknown mapping with multilayer feedforward networks}},
volume = {5},
year = {1992}
}
@article{bregman:diverg,
author = {Bregman, L.M.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Bregman - 1967 - ￼The relaxation method of finding the common point of convex sets and its application to the solution of problems in.pdf:pdf},
journal = {Zh. vychisl. mat. Mat. Fiz.},
number = {3},
pages = {620--631},
title = {{￼The relaxation method of finding the common point of convex sets and its application to the solution of problems in convex programming}},
volume = {7},
year = {1967}
}
@article{Alexander2007,
abstract = {A price process is scale-invariant if and only if the returns distribution is independent of the price measurement scale. We show that most stochastic processes used for pricing options on financial assets have this property and that many models not previously recognised as scale-invariant are indeed so. We also prove that price hedge ratios for a wide class of contingent claims under a wide class of pricing models are model-free. In particular, previous results on model-free price hedge ratios of vanilla options based on scale-invariant models are extended to any contingent claim with homogeneous pay-off, including complex, path-dependent options. However, model-free hedge ratios only have the minimum variance property in scale-invariant stochastic volatility models when price–volatility correlation is zero. In other stochastic volatility models and in scale-invariant local volatility models, model-free hedge ratios are not minimum variance ratios and our empirical results demonstrate that they are less efficient than minimum variance hedge ratios.},
annote = {From Duplicate 1 ( 

Model-free hedge ratios and scale-invariant models

- Alexander, Carol; Nogueira, Leonardo M. )

},
author = {Alexander, Carol and Nogueira, Leonardo M.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Alexander, Nogueira - 2007 - Model-free hedge ratios and scale-invariant models.pdf:pdf},
issn = {03784266},
journal = {Journal of Banking {\&} Finance},
keywords = {C14,G13,Hedging,Local volatility,Minimum variance,Model-free,Scale invariance,Stochastic volatility,c14,g13},
month = {jun},
number = {6},
pages = {1839--1861},
title = {{Model-free hedge ratios and scale-invariant models}},
url = {http://dx.doi.org/10.1016/j.jbankfin.2006.11.011 http://www.sciencedirect.com/science/article/pii/S0378426607000313},
volume = {31},
year = {2007}
}
@article{Egusquiza2022,
author = {Egusquiza, I L and Parra-Rodriguez, A},
doi = {10.1103/PhysRevB.106.024510},
journal = {Physical Review B},
month = {jul},
number = {2},
pages = {24510},
publisher = {American Physical Society},
title = {{Algebraic canonical quantization of lumped superconducting networks}},
url = {https://link.aps.org/doi/10.1103/PhysRevB.106.024510},
volume = {106},
year = {2022}
}
@article{scenario:generator,
author = {Ortega, Juan-Pablo and Pullirsch, Rainer and Teichmann, Josef and Wergieluk, J.},
title = {{A new approach for scenario generation in risk management.}},
year = {2009}
}
@article{Araujo2020,
author = {Araujo, Flavio Abreu and Riou, Mathieu and Torrejon, Jacob and Tsunegi, Sumito and Querlioz, Damien and Yakushiji, Kay and Fukushima, Akio and Kubota, Hitoshi and Yuasa, Shinji and Stiles, Mark D. and Grollier, Julie},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Araujo et al. - 2020 - Role of non-linear data processing on speech recognition task in the framework of reservoir computing.pdf:pdf},
journal = {Scientific reports},
title = {{Role of non-linear data processing on speech recognition task in the framework of reservoir computing}},
volume = {10},
year = {2020}
}
@book{Dieudonne:analysis,
author = {Dieudonn{\'{e}}, J},
pages = {387},
publisher = {Academic Press},
title = {{Foundations of Modern Analysis}},
year = {1969}
}
@misc{Vanstone1,
author = {Vanstone, Bruce and Tan, Clarence},
booktitle = {Encyclopedia of information science and technology},
doi = {10.4018/978-1-59904-941-0.ch099},
pages = {1758--1764},
publisher = {IGI Global},
title = {{Artificial neural networks in financial trading}},
url = {http://services.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/978-1-59904-941-0.ch099},
year = {2005}
}
@article{eca,
author = {Arnold, V. I.},
journal = {Izv. Vyssh. Uchebn. Zaved. Mat. Nauk},
pages = {3--5},
title = {{On an a priori estimate in the theory of hydrodynamical stability. (Russian)}},
volume = {54},
year = {1969}
}
@article{Ubeyli2008,
abstract = {A new approach based on the implementation of probabilistic neural network (PNN) is presented for classification of electroencephalogram (EEG) signals. In practical applications of pattern recognition, there are often diverse features extracted from raw data which needs recognizing. Because of the importance of making the right decision, the present work is carried out for searching better classification procedures for the EEG signals. Decision making was performed in two stages: feature extraction by eigenvector methods and classification using the classifiers trained on the extracted features. The aim of the study is classification of the EEG signals by the combination of eigenvector methods and the PNN. The purpose is to determine an optimum classification scheme for this problem and also to infer clues about the extracted features. The present research demonstrated that the power levels of the power spectral density (PSD) estimates obtained by the eigenvector methods are the features which well represent the EEG signals and the PNN trained on these features achieved high classification accuracies.},
author = {Ubeyli, Elif Derya},
doi = {10.1016/j.neunet.2008.08.005},
issn = {0893-6080},
journal = {Neural networks},
keywords = {Algorithms,Electroencephalography,Electroencephalography: classification,Electroencephalography: statistics {\&} numerical dat,Humans,Models,Neural Networks (Computer),ROC Curve,Reproducibility of Results,Statistical},
month = {nov},
number = {9},
pages = {1410--1417},
pmid = {18815008},
publisher = {Elsevier Ltd},
title = {{Implementing eigenvector methods/probabilistic neural networks for analysis of EEG signals}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18815008},
volume = {21},
year = {2008}
}
@article{Phillips1979a,
abstract = {Previous work on characterising the distribution of forecast errors in time series models by statistics such as the asymptotic mean square error has assumed that observations used in estimating parameters are statistically independent of those used to construct the forecasts themselves. This assumption is quite unrealistic in practical situations and the present paper is intended to tackle the question of how the statistical dependence between the parameter estimates and the final period observations used to generate forecasts affects the sampling distribution of the forecast errors. We concentrate on the first-order autoregression and, for this model, show that the conditional distribution of forecast errors given the final period observation is skewed towards the origin and that this skewness is accentuated in the majority of cases by the statistical dependence between the parameter estimates and the final period observation.},
author = {Phillips, Peter C.B.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Phillips - 1979 - The sampling distribution of forecasts from a first-order autoregression.pdf:pdf},
issn = {03044076},
journal = {Journal of Econometrics},
month = {feb},
number = {3},
pages = {241--261},
title = {{The sampling distribution of forecasts from a first-order autoregression}},
url = {http://dx.doi.org/10.1016/0304-4076(79)90073-3},
volume = {9},
year = {1979}
}
@article{sicuranza2,
abstract = {{\textcopyright} 2016 IEEE. In this paper, we first introduce a novel sub-class of recursive linear-in-the-parameters nonlinear filters, called recursive functional link polynomial filters, which are derived by using the constructive rule of Volterra filters. These filters are universal approximators, according to the Stone-Weierstrass theorem, and offer a remedy to the main drawback of their finite memory counterparts, that is the curse of dimensionality. Since recursive nonlinear filters become, in general, unstable for large input signals, we then consider a simple stabilization procedure by slightly modifying the input-output relationship of recursive functional link polynomial filters. The resulting filters are always stable and, even though no more universal approximators, still offer good modeling performance for nonlinear systems.},
author = {Carini, Alberto and Sicuranza, Giovanni L.},
doi = {10.1109/EUSIPCO.2016.7760666},
isbn = {9780992862657},
issn = {22195491},
journal = {European Signal Processing Conference},
keywords = {Bounded-input bounded-output stability,Linear-in-the-parameters nonlinear filters,Recursive functional link polynomial filters,Universal approximators},
number = {3},
pages = {2335--2339},
title = {{Recursive functional link polynomial filters: An introduction}},
volume = {2016-Novem},
year = {2016}
}
@article{lpasl2,
author = {Gunawan, Hendra and Konca, Sukran and Idris, Mochammad},
journal = {Bitlis Eren University Journal of Science and Technology},
number = {1},
pages = {1--9},
title = {p-summable sequence spaces with inner products},
volume = {5},
year = {2015}
}
@article{RV2006Zhang,
author = {Zhang, Lan},
journal = {Bernoulli},
number = {6},
pages = {1019--1043},
title = {{Efficient estimation of stochastic volatility using noisy observations: A multi-scale approach}},
volume = {12},
year = {2006}
}
@article{Mardt2018,
author = {Mardt, Andreas and Pasquali, Luca and Wu, Hao and No{\'{e}}, Frank},
journal = {Nature Communications},
title = {{VAMPnets for deep learning of molecular kinetics}},
volume = {9},
year = {2018}
}
@article{BEM,
author = {Barone-Adesi, Giovanni and Engle, Robert F. and Mancini, L.},
journal = {Review of Financial Studies},
pages = {1223--1258},
title = {{A GARCH option pricing model in incomplete markets}},
volume = {21},
year = {2008}
}
@article{kallsen:taqqu,
author = {Kallsen, Jan and Taqqu, M. S.},
journal = {Mathematical Finance},
number = {1},
pages = {13--26},
title = {{Option pricing in ARCH-type models}},
volume = {8},
year = {1998}
}
@article{Rangvid2002,
abstract = {In this article, we use recursive and rolling cointegration methods to test for a system ofseveral exchange rates being within the process of convergence. We use the methods to analyse how the convergence of five exchange rates within the (European) Exchange Rate Mechanism has developed during the ERM period. We find that the number of cointegration vectors in the system of ERM exchange rates increases as the sample period is extended, and interpret this as a sign of increased convergence of ERM exchange rates. In particular, we find no evidence of convergence in the first years of the ERM and strong evidence of convergence in the last years of the ERM. In the analyses we acknowledge that managed exchange rates, such as exchange rates in ERM target zones, can be misaligned at their observed values as compared to their fundamental free-float values. For this reason, we also study convergence of filtered shadow exchange rates. We use two filters to extract the shadow exchange rates: a linear filter and a non-linear filter.},
author = {Rangvid, J. and Sorensen, C.},
issn = {0972-6527},
journal = {Journal of Emerging Market Finance},
month = {sep},
number = {2},
pages = {183--213},
title = {{Convergence in the ERM and Declining Numbers of Common Stochastic Trends}},
url = {http://emf.sagepub.com/content/1/2/183.short},
volume = {1},
year = {2002}
}
@article{grizzle1985structure,
author = {Grizzle, Jessy and Marcus, Steven},
journal = {IEEE Transactions on Automatic Control},
number = {3},
pages = {248--258},
publisher = {IEEE},
title = {{The structure of nonlinear control systems possessing symmetries}},
volume = {30},
year = {1985}
}
@article{Economist2018,
abstract = {Making accurate judgments is an essential skill in everyday life. Although how different memory abilities relate to categorization and judgment processes has been hotly debated, the question is far from resolved. We contribute to the solution by investigating how individual differences in memory abilities affect judgment performance in 2 tasks that induced rule-based or exemplar-based judgment strategies. In a study with 279 participants, we investigated how working memory and episodic memory affect judgment accuracy and strategy use. As predicted, participants switched strategies between tasks. Furthermore, structural equation modeling showed that the ability to solve rule-based tasks was predicted by working memory, whereas episodic memory predicted judgment accuracy in the exemplar-based task. Last, the probability of choosing an exemplar-based strategy was related to better episodic memory, but strategy selection was unrelated to working memory capacity. In sum, our results suggest that different memory abilities are essential for successfully adopting different judgment strategies.},
address = {San Diego, CA},
author = {Economist},
doi = {10.1037/0033-2909.134.3.404},
editor = {{Lamberts K.} and Shanks, D},
isbn = {09567976},
issn = {1939-1455},
keywords = {0033-2909,10,1037,134,1952,1955,3,404,ALM,Association Learning,Attention,Choice Behavior,Cues,Exemplar,Fixation,Funktionslernen,Humans,Linsenmodell,Metaanalyse,Ocular,Photic Stimulation,Uncertainty,associative learning,attention,bootstrapping,conceptual framework of brunswik,conditioning,doi,dx,episodic memory,hammond,http,in a seminal contribution,judgment,judgment achievement,judgmental accuracy,learning,lens model,lens model equation,lens model to study,linear models,meta-analysis,numerische Sch{\"{a}}tzungen,numerische Sch�tzungen,org,reward learning,rule-based and exemplar-based processes,s,social judgment theory,suggested using the,supp,supplemental material,working memory},
month = {may},
pmid = {25285427},
publisher = {Taylor {\&} Francis},
title = {{AI-spy}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/bul0000064 http://pss.sagepub.com/lookup/doi/10.1111/j.1467-9280.1993.tb00486.x http://pss.sagepub.com/content/4/3/190.short http://www.ncbi.nlm.nih.gov/pubmed/25832459 http://www.tandfonline.com/doi/full/10.1080/},
year = {2018}
}
@article{GHLO2014,
author = {Grigoryeva, Lyudmila and Henriques, Julie and Larger, Laurent and Ortega, Juan-Pablo},
journal = {Neural Networks},
pages = {59--71},
title = {{Stochastic time series forecasting using time-delay reservoir computers: performance and universality}},
volume = {55},
year = {2014}
}
@book{Ledoux2013,
abstract = {{\{}New isoperimetric inequalities and random process techniques have recently appeared at the basis of the modern understanding of Probability in Banach spaces. Based on these tools, the book presents a complete treatment of the main aspects of Probability in Banach spaces (boundedness and continuity of random processes, integrability and limit theorems for vector valued random variables,...) and of some of their links to Geometry of Banach spaces. Its purpose is to present some of the main aspects of this theory, from the foundations to the latest develop- ments, treated with the most recent and updated tools. In particular, the most important features are the sys- tematic use of isoperimetry and related concentration of measure phenomena (to study integrability and limit theorems for vector valued random variables), and recent abstract random process techniques (entropy and majorizing measures). Some examples of these probabilistic ideas to classical Banach space theory complete this exposition.{\}}},
author = {Ledoux, Michel and Talagrand, Michel},
booktitle = {Probability in Banach Spaces},
doi = {10.1007/978-3-642-20212-4},
title = {{Probability in Banach Spaces}},
year = {2013}
}
@article{Varin2006,
abstract = {Ordinal categorical time series may be analyzed as censored observations from a suitable latent stochastic process, which describes the underlying evolution of the system. This approach may be considered as an alternative to Markov chain models or to regression methods for categorical time series data. The problem of parameter estimation is solved through a simple pseudolikelihood, called pairwise likelihood. This inferential methodology is successfully applied to the class of autoregressive ordered probit models. Potential usefulness for inference and model selection within more general classes of models are also emphasized. Illustrations include simulation studies and two simple real data applications.},
author = {Varin, Cristiano and Vidoni, Paolo},
doi = {10.1016/j.csda.2006.09.009},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Varin, Vidoni - 2006 - Pairwise likelihood inference for ordinal categorical time series.pdf:pdf},
issn = {01679473},
journal = {Computational Statistics {\&} Data Analysis},
keywords = {Alofi data,Model selection,Ordinal categorical data,Oxford–Cambridge boat race data,Pairwise likelihood,Quantized data,Time series},
month = {dec},
number = {4},
pages = {2365--2373},
title = {{Pairwise likelihood inference for ordinal categorical time series}},
url = {http://www.sciencedirect.com/science/article/pii/S016794730600332X},
volume = {51},
year = {2006}
}
@article{Swanson1997,
abstract = {We take a model selection approach to the question of whether a class of adaptive prediction models ("artificial neural networks") are useful for predicting future values of 9 macroeconomic variables. We use a variety of out-of-sample forecast-based model selection criteria including forecast error measures and forecast direction accuracy. In order to compare our predictions to professionally available survey predictions, we implement an ex ante (or real-time) forecasting procedure. One dimension of this approach is that we construct a real-time economic data set which has the characteristic that data avail- able at time t do not contain any information which has been allowed to "leak" in from future time periods, as often happens with fully revised macroeconomic data. We also investigate the issue of appropriate window sizes for rolling-window-based prediction methods. Results indicate that adaptive models often outperform a variety of nonadaptive models, as well as professional forecasters, when used to predict levels as well as the direction of change in various macroeconomic variables. Further, model selection based on an in-sample Schwarz Information Criterion (SIC) does not appear to be a reliable guide to out-of-sample performance, in the case of the variables considered here. Thus, the in-sample SIC apparently fails to offer a convenient shortcut to true out-of-sample performance measures.},
author = {Swanson, Norman R. and White, Halbert},
journal = {The Review of Economics and Statistics},
keywords = {Adaptive Modeling,Artificial Neural Networks,Ex-ante Forecasting,Information Criteria.,Model Selection,Rol- ling Windows,Unrevised Data},
number = {4},
pages = {540--550},
title = {{A Model Selection Approach to Real-Time Macroeconomic Forecasting Using Linear Models and Artificial Neural Networks}},
volume = {79},
year = {1997}
}
@article{Chennu2013,
abstract = {Recent research suggests that despite the seeming inability of patients in vegetative and minimally conscious states to generate consistent behaviour, some might possess covert awareness detectable with functional neuroimaging. These findings motivate further research into the cognitive mechanisms that might support the existence of consciousness in these states of profound neurological dysfunction. One of the key questions in this regard relates to the nature and capabilities of attention in patients, known to be related to but distinct from consciousness. Previous assays of the electroencephalographic P300 marker of attention have demonstrated its presence and potential clinical value. Here we analysed data from 21 patients and 8 healthy volunteers collected during an experimental task designed to engender exogenous or endogenous attention, indexed by the P3a and P3b components, respectively, in response to a pair of word stimuli presented amongst distractors. Remarkably, we found that the early, bottom-up P3a and the late, top-down P3b could in fact be dissociated in a patient who fitted the behavioural criteria for the vegetative state. In juxtaposition with healthy volunteers, the patient's responses suggested the presence of a relatively high level of attentional abilities despite the absence of any behavioural indications thereof. Furthermore, we found independent evidence of covert command following in the patient, as measured by functional neuroimaging during tennis imagery. Three other minimally conscious patients evidenced non-discriminatory bottom-up orienting, but no top-down engagement of selective attentional control. Our findings present a persuasive case for dissociable attentional processing in behaviourally unresponsive patients, adding to our understanding of the possible levels and applications of consequent conscious awareness.},
author = {Chennu, Srivas and Finoia, Paola and Kamau, Evelyn and Monti, Martin M and Allanson, Judith and Pickard, John D and Owen, Adrian M and Bekinschtein, Tristan A},
issn = {2213-1582},
journal = {NeuroImage. Clinical},
keywords = {Attention,Consciousness,Electroencephalography,Minimally conscious state,Vegetative state},
month = {jan},
pages = {450--61},
title = {{Dissociable endogenous and exogenous attention in disorders of consciousness.}},
url = {http://www.sciencedirect.com/science/article/pii/S2213158213001381},
volume = {3},
year = {2013}
}
@inproceedings{Bouchard2004,
author = {Bouchard, Guillaume and Triggs, Bill},
booktitle = {16th IASC International Symposium on Computational Statistics (COMPSTAT '04)},
pages = {721--728},
title = {{The tradeoff between generative and discriminative classifiers}},
year = {2004}
}
@article{persistence:periodic,
author = {Montaldi, J A},
journal = {C. R. Acad. Sci. Paris S{\{}{\'{e}}{\}}r. I Math.},
pages = {553--558},
title = {{Persistance d'orbites p{\{}{\'{e}}{\}}riodiques relatives dans les syst{\{}{\`{e}}{\}}mes hamiltoniens sym{\{}{\'{e}}{\}}triques}},
volume = {324},
year = {1997}
}
@inproceedings{LSS2014,
address = {Working paper},
author = {Linn, Matthew and Shive, Sophie and Shumway, Tyler},
booktitle = {SSRN Electronic Journal},
doi = {10.2139/ssrn.2383527},
title = {{Pricing kernel monotonicity and conditional information}},
url = {http://www.ssrn.com/abstract=2383527},
year = {2014}
}
@misc{Brauning2011,
author = {Brauning, Falk and Koopman, Siem Jan},
booktitle = {Business},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Brauning, Koopman - 2011 - Forecasting the business cycle using realised measures of the economy an empirical study.pdf:pdf},
number = {December},
pages = {1--2},
title = {{Forecasting the business cycle using realised measures of the economy : an empirical study}},
year = {2011}
}
@article{Gabor1946,
author = {Gabor, D.},
journal = {Journal of the Institution of Electrical Engineers. Part III : Radio and Communication Engineering},
number = {26},
pages = {429--441},
title = {{Theory of communication. Part 1: The analysis of information}},
volume = {93},
year = {1946}
}
@unpublished{Discussione,
author = {Borin, Alessandro and Cristadoro, Riccardo and Golinelli, Roberto and Parigi, Giuseppe},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Borin et al. - 2012 - Forecasting world output the rising importance of emerging economies.pdf:pdf},
institution = {Banca d'Italia},
title = {{Forecasting world output: the rising importance of emerging economies}},
year = {2012}
}
@book{Fabrizio2010,
abstract = {In this work, we present a novel approach to the mathematical analysis of equations with memory based on the notion of a state, namely, the initial configuration of the system which can be unambiguously determined by the knowledge of the future dynamics. As a model, we discuss the abstract version of an equation arising from linear viscoelasticity. It is worth mentioning that our approach goes back to the heuristic derivation of the state framework, devised by L.Deseri, M.Fabrizio and M.J.Golden in "The concept of minimal state in viscoelasticity: new free energies and applications to PDEs", Arch. Ration. Mech. Anal., vol. 181 (2006) pp.43-96. Starting from their physical motivations, we develop a suitable functional formulation which, as far as we know, is completely new.},
author = {Fabrizio, Mauro and Giorgi, Claudio and Pata, Vittorino},
booktitle = {Archive for Rational Mechanics and Analysis},
number = {1},
pages = {189--232},
title = {{A new approach to equations with memory}},
volume = {198},
year = {2010}
}
@article{Verzelli2020,
abstract = {Reservoir computing is a popular approach to design recurrent neural networks, due to its training simplicity and its approximation performance. The recurrent part of these networks is not trained (e.g. via gradient descent), making them appealing for analytical studies, raising the interest of a vast community of researcher spanning from dynamical systems to neuroscience. It emerges that, even in the simple linear case, the working principle of these networks is not fully understood and the applied research is usually driven by heuristics. A novel analysis of the dynamics of such networks is proposed, which allows one to express the state evolution using the controllability matrix. Such a matrix encodes salient characteristics of the network dynamics: in particular, its rank can be used as an input-indepedent measure of the memory of the network. Using the proposed approach, it is possible to compare different architectures and explain why a cyclic topology achieves favourable results.},
archivePrefix = {arXiv},
arxivId = {2003.10585},
author = {Verzelli, Pietro and Alippi, Cesare and Livi, Lorenzo and Tino, Peter},
eprint = {2003.10585},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Verzelli et al. - 2020 - Input representation in recurrent neural networks dynamics.pdf:pdf},
month = {mar},
title = {{Input representation in recurrent neural networks dynamics}},
url = {http://arxiv.org/abs/2003.10585},
year = {2020}
}
@article{labbe:remillard,
author = {Labb{\'{e}}, Chantal and R{\'{e}}millard, Bruno and Renaud, Jean-Fran{\c{c}}ois},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Labb{\'{e}}, R{\'{e}}millard, Renaud - 2012 - A simple discretization scheme for nonnegative diffusion processes with application to option pricin.pdf:pdf},
journal = {The Journal of Computational Finance},
number = {2},
pages = {3--35},
title = {{A simple discretization scheme for nonnegative diffusion processes with application to option pricing}},
volume = {15},
year = {2012}
}
@article{Song2017,
author = {Song, Huan and Thiagarajan, Jayaraman J. and Sattigeri, Prasanna and Spanias, Andreas},
title = {{Optimizing kernel machines using deep learning}},
year = {2017}
}
@article{lai:xing:chen,
author = {Lai, Tze Leung and Xing, Haipeng and Chen, Zehao},
journal = {The Annals of Applied Statistics},
number = {2A},
pages = {798--823},
title = {{Mean-variance portfolio optimization when means and covariances are unknown}},
volume = {5},
year = {2011}
}
@article{Lord2010,
abstract = {Using an Euler discretization to simulate a mean-reverting CEV process gives rise to the problem that while the process itself is guaranteed to be nonnegative, the discretization is not. Although an exact and efficient simulation algorithm exists for this process, at present this is not the case for the CEV-SV stochastic volatility model, with the Heston model as a special case, where the variance is modelled as a mean-reverting CEV process. Consequently, when using an Euler discretization, one must carefully think about how to fix negative variances. Our contribution is threefold. Firstly, we unify all Euler fixes into a single general framework. Secondly, we introduce the new full truncation scheme, tailored to minimize the positive bias found when pricing European options. Thirdly and finally, we numerically compare all Euler fixes to recent quasi-second order schemes of Kahl and J{\"{a}}ckel, and Ninomiya and Victoir, as well as to the exact scheme of Broadie and Kaya. The choice of fix is found to be extremely important. The full truncation scheme outperforms all considered biased schemes in terms of bias and root-mean-squared error. Using an Euler discretization to simulate a mean-reverting CEV process gives rise to the problem that while the process itself is guaranteed to be nonnegative, the discretization is not. Although an exact and efficient simulation algorithm exists for this process, at present this is not the case for the CEV-SV stochastic volatility model, with the Heston model as a special case, where the variance is modelled as a mean-reverting CEV process. Consequently, when using an Euler discretization, one must carefully think about how to fix negative variances. Our contribution is threefold. Firstly, we unify all Euler fixes into a single general framework. Secondly, we introduce the new full truncation scheme, tailored to minimize the positive bias found when pricing European options. Thirdly and finally, we numerically compare all Euler fixes to recent quasi-second order schemes of Kahl and J{\"{a}}ckel, and Ninomiya and Victoir, as well as to the exact scheme of Broadie and Kaya. The choice of fix is found to be extremely important. The full truncation scheme outperforms all considered biased schemes in terms of bias and root-mean-squared error.},
author = {Lord, Roger and Koekkoek, Remmert and Dijk, Dick Van},
doi = {10.1080/14697680802392496},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Lord, Koekkoek, Dijk - 2010 - A comparison of biased simulation schemes for stochastic volatility models.pdf:pdf},
issn = {1469-7688},
journal = {Quantitative Finance},
month = {feb},
number = {2},
pages = {177--194},
publisher = {Routledge},
title = {{A comparison of biased simulation schemes for stochastic volatility models}},
url = {http://dx.doi.org/10.1080/14697680802392496},
volume = {10},
year = {2010}
}
@article{Adeli2003,
abstract = {About 1{\%} of the people in the world suffer from epilepsy and 30{\%} of epileptics are not helped by medication. Careful analyses of the electroencephalograph (EEG) records can provide valuable insight and improved understanding of the mechanisms causing epileptic disorders. Wavelet transform is particularly effective for representing various aspects of non-stationary signals such as trends, discontinuities, and repeated patterns where other signal processing approaches fail or are not as effective. In this research, discrete Daubechies and harmonic wavelets are investigated for analysis of epileptic EEG records. Wavelet transform is used to analyze and characterize epileptiform discharges in the form of 3-Hz spike and wave complex in patients with absence seizure. Through wavelet decomposition of the EEG records, transient features are accurately captured and localized in both time and frequency context. The capability of this mathematical microscope to analyze different scales of neural rhythms is shown to be a powerful tool for investigating small-scale oscillations of the brain signals. Wavelet analyses of EEGs obtained from a population of patients can potentially suggest the physiological processes undergoing in the brain in epilepsy onset. A better understanding of the dynamics of the human brain through EEG analysis can be obtained through further analysis of such EEG records.},
author = {Adeli, Hojjat and Zhou, Ziqin and Dadmehr, Nahid},
issn = {0165-0270},
journal = {Journal of neuroscience methods},
keywords = {Absence,Absence: diagnosis,Absence: physiopathology,Algorithms,Computational Biology,Computational Biology: statistics {\&} numerical data,Data Interpretation,Electroencephalography,Electroencephalography: statistics {\&} numerical dat,Epilepsy,Humans,Models,Neurological,Neurology,Neurology: statistics {\&} numerical data,Statistical},
month = {feb},
number = {1},
pages = {69--87},
pmid = {12581851},
title = {{Analysis of EEG records in an epileptic patient using wavelet transform}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12581851},
volume = {123},
year = {2003}
}
@book{Kallenberg2002,
author = {Kallenberg, Olav},
publisher = {Springer New York},
series = {Probability and Its Applications},
title = {{Foundations of Modern Probability}},
year = {2002}
}
@inproceedings{Cabrera2017,
author = {Cabrera, Diego and Sancho, Fernando and Tobar, Felipe},
booktitle = {International Conference on Sensing, Diagnostics, Prognostics, and Control},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Cabrera, Sancho, Tobar - 2017 - Combining reservoir computing and variational inference for efficient one-class learning on dynamical sy.pdf:pdf},
title = {{Combining reservoir computing and variational inference for efficient one-class learning on dynamical systems}},
year = {2017}
}
@article{Jones,
abstract = {A general convergence criterion for certain iterative sequences in Hilbert space is presented. For an important subclass of these sequences, estimates of the rate of convergence are given. Under very mild assumptions these results establish an {\$}O(1/ \backslashsqrt n){\$} nonsampling convergence rate for projection pursuit regression and neural network training; where n represents the number of ridge functions, neurons or coefficients in a greedy basis expansion.},
author = {Jones, Lee K.},
doi = {10.2307/2242184},
journal = {The Annals of Statistics},
number = {1},
pages = {608--613},
publisher = {Institute of Mathematical Statistics},
title = {{A simple lemma on greedy approximation in hilbert space and convergence rates for projection pursuit regression and neural network training}},
volume = {20},
year = {1992}
}
@article{Oliva_TDE,
author = {Oliva, W. M.},
journal = {Journal of Differential Equations},
number = {3},
pages = {483--496},
title = {{Functional differential equations on compact manifolds and an approximation theorem}},
volume = {5},
year = {1969}
}
@article{henderson:vec,
author = {Henderson, Harold V and Searle, S R},
journal = {The Canadian Journal of Statistics},
number = {1},
pages = {65--81},
title = {{Vec and vech operators for matrices with some uses in Jacobians and multivariate statistics}},
volume = {7},
year = {1979}
}
@phdthesis{thesis:patrick,
author = {Patrick, George W.},
school = {University of California, Berkeley},
title = {{Two Axially Symmetric Coupled Rigid Bodies: Relative Equilibria, Stability, Bifurcations, and a Momentum Preserving Symplectic Integrator}},
year = {1995}
}
@article{siegelmann1,
author = {Siegelmann, Hava T and Sontag, Eduardo D.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Siegelmann, Sontag - 1994 - Analog computation networks via neural networks.pdf:pdf},
journal = {Theoretical Computer Science},
pages = {331--360},
title = {{Analog computation networks via neural networks}},
volume = {131},
year = {1994}
}
@article{Schutte2012,
author = {Sch{\"{u}}tte, Christof and Winkelmann, Stefanie and Hartmann, Carsten},
doi = {10.1007/s10107-012-0547-6},
issn = {1436-4646},
journal = {Mathematical Programming},
number = {1},
pages = {259--282},
title = {{Optimal control of molecular dynamics using Markov state models}},
url = {http://dx.doi.org/10.1007/s10107-012-0547-6},
volume = {134},
year = {2012}
}
@inproceedings{gretton2005measuring,
author = {Gretton, Arthur and Bousquet, Olivier and Smola, Alex and Sch{\"{o}}lkopf, Bernhard},
booktitle = {International conference on algorithmic learning theory},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Gretton et al. - 2005 - Measuring statistical dependence with Hilbert-Schmidt norms.pdf:pdf},
pages = {63--77},
publisher = {Springer},
title = {{Measuring statistical dependence with Hilbert-Schmidt norms}},
year = {2005}
}
@book{hammer:hitzler,
author = {Hammer, Barbara and Hitzler, Pascal},
booktitle = {Integration The Vlsi Journal},
editor = {Hammer, Barbara and Hitzler, Pascal},
isbn = {9783540710776},
publisher = {Springer-Verlag},
title = {{Perspectives of Neural-Symbolic Integration. Studies in Computational Intelligence , Volume 77}},
year = {2007}
}
@article{Hotta2004,
author = {Hotta, Luiz K. and Pereira, Pedro L. Valls and Ota, Rissa},
doi = {10.1007/BF02595778},
issn = {1133-0686},
journal = {Test},
month = {dec},
number = {2},
pages = {371--402},
title = {{Effect of outliers on forecasting temporally aggregated flow variables}},
url = {http://www.springerlink.com/index/10.1007/BF02595778},
volume = {13},
year = {2004}
}
@article{Panopoulou2007,
author = {Panopoulou, E},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Panopoulou - 2007 - Predictive financial models of the euro area A new evaluation test.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {aggregation,financial variables,forecasting accuracy,output growth},
month = {oct},
number = {4},
pages = {695--705},
title = {{Predictive financial models of the euro area: A new evaluation test}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S016920700700043X},
volume = {23},
year = {2007}
}
@article{ruiz:var:methods,
author = {Nieto, Mar{\'{i}}a Rosa and Ruiz, Esther},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Nieto, Ruiz - 2008 - Measuring financial risk comparison of alternative procedures to estimate VaR and ES.pdf:pdf},
journal = {Preprint},
title = {{Measuring financial risk: comparison of alternative procedures to estimate VaR and ES.}},
year = {2008}
}
@article{Bartlett2017,
abstract = {This paper presents a margin-based multiclass generalization bound for neural networks that scales with their margin-normalized "spectral complexity": their Lipschitz constant, meaning the product of the spectral norms of the weight matrices, times a certain correction factor. This bound is empirically investigated for a standard AlexNet network trained with SGD on the mnist and cifar10 datasets, with both original and random labels; the bound, the Lipschitz constants, and the excess risks are all in direct correlation, suggesting both that SGD selects predictors whose complexity scales with the difficulty of the learning task, and secondly that the presented bound is sensitive to this complexity.},
archivePrefix = {arXiv},
arxivId = {arXiv:1706.08498v2},
author = {Bartlett, Peter L. and Foster, Dylan J. and Telgarsky, Matus},
eprint = {arXiv:1706.08498v2},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Bartlett, Foster, Telgarsky - 2017 - Spectrally-normalized margin bounds for neural networks.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
pages = {6241--6250},
title = {{Spectrally-normalized margin bounds for neural networks}},
volume = {2017-Decem},
year = {2017}
}
@article{hambly2010uniqueness,
author = {Hambly, Ben and Lyons, Terry},
journal = {Annals of Mathematics},
pages = {109--167},
publisher = {JSTOR},
title = {{Uniqueness for the signature of a path of bounded variation and the reduced path group}},
year = {2010}
}
@article{Bruveris2011,
author = {Bruveris, M. and Gay-Balmaz, F. and Holm, D. D. and Ratiu, T. S.},
doi = {10.1007/s00332-010-9079-5},
journal = {Journal of Nonlinear Science},
month = {feb},
number = {1},
pages = {115--150},
publisher = {Springer-Verlag},
title = {{The momentum map representation of images}},
url = {http://link.springer.com/10.1007/s00332-010-9079-5},
volume = {21},
year = {2011}
}
@article{Christodoulakis:dcc,
author = {Christodoulakis, George A. and Satchellb, Stephen E.},
journal = {European Journal of Operational Research},
number = {2},
pages = {351--370},
title = {{Correlated ARCH (CorrARCH): modelling the time-varying conditional correlation between financial asset returns}},
volume = {139},
year = {2002}
}
@article{huang:guo:1,
author = {Huang, Shih-Feng and Guo, Meihui},
issn = {1017-0405},
journal = {Statistica Sinica},
number = {3},
pages = {1037--1054},
title = {{Financial derivative valuation - a dynamic semiparametric approach}},
volume = {19},
year = {2009}
}
@inproceedings{Hofrichter2015,
author = {Hofrichter, J and Czornomaz, L and Horst, F and Seifried, M and Caimi, D and Meier, N and Fompeyrine, J and Offrein, Bert J},
booktitle = {ECOC proceeding},
title = {{A mode-engineered hybrid III-V – on – silicon photodetector}},
year = {2015}
}
@book{Boucheron2013,
author = {Boucheron, St{\'{e}}phane and Lugosi, G{\'{a}}bor and Massart, Pascal},
pages = {489},
publisher = {Oxford University Press},
title = {{Concentration Inequalities: A Nonasymptotic Theory of Independence}},
year = {2013}
}
@article{embedology:2018,
author = {Eftekhari, Armin and Yap, Han Lun and Wakin, Michael B. and Rozell, Christopher J.},
doi = {10.1103/PhysRevE.97.022222},
issn = {2470-0045},
journal = {Physical Review E},
month = {feb},
number = {2},
pages = {022222},
publisher = {American Physical Society},
title = {{Stabilizing embedology: geometry-preserving delay-coordinate maps}},
url = {https://link.aps.org/doi/10.1103/PhysRevE.97.022222},
volume = {97},
year = {2018}
}
@article{Homma1988,
author = {Homma, Toshiteru and Atlas, Les A. and {Marks II}, Robert J.},
journal = {Advances in Neural Information Processing Systems},
pages = {31--40},
title = {{An artificial neural network for spatio-temporal bipolar patters: Application to phoneme classification}},
volume = {1},
year = {1988}
}
@article{euler:semidirect:products,
author = {Cendra, H and Holm, D D and Marsden, J E and Ratiu, T S},
journal = {AMS Translations},
pages = {1--25},
title = {{Lagrangian reduction, the Euler-Poincar{\{}{\'{e}}{\}} equations, and semidirect products}},
volume = {186},
year = {1998}
}
@article{blaom:phases,
author = {Blaom, A.},
journal = {Differential Geom. Appl.},
number = {3},
pages = {231--252},
title = {{Reconstruction phases via Poisson reduction}},
volume = {12},
year = {2000}
}
@article{Cruse2011,
abstract = {Patients diagnosed as vegetative have periods of wakefulness, but seem to be unaware of themselves or their environment. Although functional MRI (fMRI) studies have shown that some of these patients are consciously aware, issues of expense and accessibility preclude the use of fMRI assessment in most of these individuals. We aimed to assess bedside detection of awareness with an electroencephalography (EEG) technique in patients in the vegetative state.},
author = {Cruse, Damian and Chennu, Srivas and Chatelle, Camille and Bekinschtein, Tristan A. and Fern{\'{a}}ndez-Espejo, Davinia and Pickard, John D. and Laureys, Steven and Owen, Adrian M.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Cruse et al. - 2011 - Bedside detection of awareness in the vegetative state a cohort study.pdf:pdf},
issn = {1474-547X},
journal = {The Lancet},
keywords = {Adolescent,Adult,Awareness,Cohort Studies,Coma,Coma: diagnosis,Electroencephalography,Electroencephalography: methods,Female,Humans,Magnetic Resonance Imaging,Male,Middle Aged,Motor Cortex,Motor Cortex: physiopathology,Persistent Vegetative State,Persistent Vegetative State: physiopathology,Point-of-Care Systems,Young Adult},
month = {dec},
number = {9809},
pages = {2088--94},
title = {{Bedside detection of awareness in the vegetative state: a cohort study.}},
url = {http://dx.doi.org/10.1016/S0140-6736(11)61224-5},
volume = {378},
year = {2011}
}
@article{Leok2011,
author = {Leok, Melvin and Zhang, Jingjing},
journal = {IMA J Numer Anal},
number = {4},
pages = {1497--1532},
title = {{Discrete Hamiltonian variational integrators}},
volume = {31},
year = {2011}
}
@article{RV2005a,
author = {Zhang, Lan and Mykland, Per A. and A{\"{i}}t-Sahalia, Yacine},
journal = {Journal of the American Statistical Association},
pages = {1394--1411},
title = {{A tale of two time scales: determining integrated volatility with noisy high-frequency data}},
volume = {100},
year = {2005}
}
@article{krylov1931numerical,
author = {Krylov, A .N.},
journal = {News Acad. Sci. USSR},
pages = {491--539},
title = {{On the numerical solution of equation by which are determined in technical problems the frequencies of small vibrations of material systems}},
volume = {7},
year = {1931}
}
@article{Hofmann2008,
author = {Hofmann, Thomas and Sch{\"{o}}lkopf, Bernhard and Smola, Alexander J.},
journal = {The Annals of Statistics},
number = {3},
pages = {1171--1220},
title = {{Kernel methods in machine learning}},
volume = {36},
year = {2008}
}
@unpublished{Shen2018,
author = {Shen, Jonathan and Pang, Ruoming and Weiss, Ron J. and Schuster, Mike and Jaitly, Navdeep},
title = {{Natural TTS synthesis by conditioning WaveNet on el spectrogram predictions}},
year = {2018}
}
@inproceedings{BKASL:19,
author = {Bonnier, Patric and Kidger, Patrick and Perez-Arribas, Imanol and Salvi, Cristopher and Lyons, Terry},
booktitle = {Advances in Neural Information Processing Systems},
pages = {3105--3115},
title = {{Deep signature transforms}},
year = {2019}
}
@article{Donoho2000,
author = {Donoho, David L.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley//Donoho - 2000 - High-dimensional data analysis The curses and blessings of dimensionality.pdf:pdf},
journal = {AMS math challenges lecture},
number = {32},
title = {{High-dimensional data analysis: The curses and blessings of dimensionality}},
volume = {1 (2000)},
year = {2000}
}
@article{GO2,
author = {Grygor'yeva, Lyudmyla V. and Ortega, Juan-Pablo},
journal = {In preparation},
title = {{Multistep forecasting using temporally aggregated multivariate conditionally heteroscedastic models}},
year = {2012}
}
@article{Davis2003,
author = {Davis, Nicole and Kutan, Ali},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Davis, Kutan - 2003 - Inflation and output as predictors of stock returns and volatility international evidence.pdf:pdf},
issn = {0960-3107},
journal = {Applied Financial Economics},
month = {sep},
number = {9},
pages = {693--700},
title = {{Inflation and output as predictors of stock returns and volatility: international evidence}},
url = {http://www.informaworld.com/openurl?genre=article{\&}doi=10.1080/09603100210139429{\&}magic=crossref{\%}7C{\%}7CD404A21C5BB053405B1A640AFFD44AE3},
volume = {13},
year = {2003}
}
@article{markowitz:selection,
author = {Markowitz, H},
journal = {J. Finance},
pages = {77--91},
title = {{Portfolio selection}},
volume = {7},
year = {1952}
}
@article{Bougerol_1992,
author = {Bougerol, P. and Picard, N.},
journal = {Ann. Probab.},
pages = {1714--1730},
title = {{Strict stationarity of generalized autoregressive processes}},
volume = {20},
year = {1992}
}
@unpublished{Kristin1999,
author = {Forbes, Kristin and Rigobon, Roberto},
booktitle = {NBER},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Forbes, Rigobon - 1999 - No Contagion, Only Interdependence Measuring Stock Market Co-Movement.pdf:pdf},
institution = {NBER},
number = {July},
title = {{No Contagion, Only Interdependence: Measuring Stock Market Co-Movement}},
year = {1999}
}
@book{Taylor:Book2,
address = {Princeton},
author = {Taylor, Stephen J},
isbn = {0-691-11537-0},
pages = {xv+525},
publisher = {Princeton University Press},
title = {{Asset Price Dynamics, Volatility, and Prediction}},
year = {2005}
}
@inproceedings{FGP2012,
address = {Working paper},
author = {Fusari, N and Gonzalez-Perez, M T},
organization = {Northwestern University},
title = {{Volatility dynamics and the term structure of the variance risk premium}},
year = {2012}
}
@article{Behler2011,
author = {Behler, J{\"{o}}rg},
doi = {10.1039/C1CP21668F},
journal = {Phys. Chem. Chem. Phys.},
number = {40},
pages = {17930--17955},
publisher = {The Royal Society of Chemistry},
title = {{Neural network potential-energy surfaces in chemistry: a tool for large-scale simulations}},
url = {http://dx.doi.org/10.1039/C1CP21668F},
volume = {13},
year = {2011}
}
@article{danielsson;simulated:ml,
author = {Dan{\'{i}}elsson, J},
journal = {Journal of Econometrics},
pages = {375--400},
title = {{Stochastic volatility in asset prices: estimation with simulated maximum likelihood}},
volume = {64},
year = {1994}
}
@article{gogarch,
author = {van der Weide, Roy},
journal = {J. Appl. Econ.},
number = {17},
pages = {549--564},
title = {{GO-GARCH: a multivariate generalized orthogonal GARCH model}},
volume = {17},
year = {2002}
}
@article{Golosnoy2012,
abstract = {We propose a ConditionalAutoregressiveWishart (CAW) model for the analysis of realized covariance matrices of asset returns. Our model assumes an autoregressive moving average structure for the scale matrix of the Wishart distribution. It accounts for positive definiteness of covariance matrices without imposing parametric restrictions, and can be estimated by Maximum Likelihood. We also propose extensions of the CAW model obtained by including a Mixed Data Sampling (MIDAS) component and Heterogeneous Autoregressive (HAR) dynamics for long-run fluctuations. The CAW models are applied to realized variances and covariances for five New York Stock Exchange stocks.},
author = {Golosnoy, Vasyl and Gribisch, Bastian and Liesenfeld, Roman},
doi = {10.1016/j.jeconom.2011.11.004},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Golosnoy, Gribisch, Liesenfeld - 2012 - The conditional autoregressive Wishart model for multivariate stock market volatility.pdf:pdf},
issn = {03044076},
journal = {Journal of Econometrics},
keywords = {c32,c58,g17},
month = {mar},
number = {1},
pages = {211--223},
title = {{The conditional autoregressive Wishart model for multivariate stock market volatility}},
url = {http://dx.doi.org/10.1016/j.jeconom.2011.11.004},
volume = {167},
year = {2012}
}
@article{latala2005some,
author = {Lata{\l}a, Rafa{\l}},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Lata{\l}a - 2005 - Some estimates of norms of random matrices.pdf:pdf},
journal = {Proceedings of the American Mathematical Society},
number = {5},
pages = {1273--1282},
title = {{Some estimates of norms of random matrices}},
volume = {133},
year = {2005}
}
@article{weiss2016survey,
author = {Weiss, Karl and Khoshgoftaar, Taghi M and Wang, DingDing},
journal = {Journal of Big data},
number = {1},
pages = {1--40},
publisher = {SpringerOpen},
title = {{A survey of transfer learning}},
volume = {3},
year = {2016}
}
@article{leshno:bounded,
abstract = {Several researchers characterized the activation function under which multilayer feedforward networks can act as universal approximators. We show that most of all the characterizations that were reported thus far in the literature are special cases of the following general result: A standard multilayer feedforward network with a locally bounded piecewise continuous activation function can approximate any continuous function to any degree of accuracy if and only if the network's activation function is not a polynomial. We also emphasize the important role of the threshold, asserting that without it the last theorem does not hold. {\textcopyright} 1993 Pergamon Press Ltd.},
author = {Leshno, Moshe and Lin, Vladimir Ya and Pinkus, Allan and Schocken, Shimon},
doi = {10.1016/S0893-6080(05)80131-5},
isbn = {0893-6080},
issn = {08936080},
journal = {Neural Networks},
keywords = {Activation functions,Lp($\mu$) approximation,Multilayer feedforward networks,Role of threshold,Universal approximation capabilities},
number = {6},
pages = {861--867},
title = {{Multilayer feedforward networks with a nonpolynomial activation function can approximate any function}},
volume = {6},
year = {1993}
}
@article{Gadat2007,
author = {Gadat, S{\'{e}}bastien and Younes, Laurent},
journal = {Journal of Machine Learning Research},
number = {Mar},
pages = {509--547},
title = {{A stochastic algorithm for feature selection in pattern recognition}},
url = {http://www.jmlr.org/papers/v8/gadat07a.html},
volume = {8},
year = {2007}
}
@article{billio2006,
author = {Billio, Monica and Caporin, Massimiliano and Gobbo, Michele},
journal = {Applied Financial Economics Letters},
number = {2},
pages = {123--130},
title = {{Flexible Dynamic Conditional Correlation multivariate GARCH models for asset allocation}},
volume = {2},
year = {2006}
}
@article{mclachlan2006geometric,
author = {McLachlan, Robert I and Quispel, G Reinout W},
journal = {Journal of Physics A: Mathematical and General},
number = {19},
pages = {5251},
publisher = {IOP Publishing},
title = {{Geometric integrators for ODEs}},
volume = {39},
year = {2006}
}
@article{PersioNN,
author = {{Di Persio}, Luca and Honchar, Oleksandr},
journal = {International Journal of Economics and Management Systems},
pages = {158--162},
title = {{Artificial neural networks approach to the forecast of stock market price movements}},
volume = {1},
year = {2016}
}
@inproceedings{Vanstone2003,
address = {Sydney},
author = {Vanstone, B. and Tan, C.},
booktitle = {Proceedings of the 8th Australian {\&} New Zealand intelligent information systems conference (ANZIIS 2003)},
pages = {7},
title = {{A survey of the application of soft computing to investment and financial trading}},
year = {2003}
}
@article{patrick:roberts:wulff:2002,
author = {Patrick, George W. and Roberts, Mark and Wulff, Claudia},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Patrick, Roberts, Wulff - 2004 - Stability of Poisson equilibria and Hamiltonian relative equilibria by energy methods.pdf:pdf},
journal = {Archive for Rational Mechanics and Analysis},
number = {3},
pages = {301--344},
title = {{Stability of Poisson equilibria and Hamiltonian relative equilibria by energy methods}},
volume = {174},
year = {2004}
}
@article{Brunner2015,
author = {Brunner, D. and Fischer, I.},
journal = {Optics Letters},
pages = {3854},
title = {{Reconfigurable semiconductor laser networks based on diffractive coupling}},
volume = {40},
year = {2015}
}
@article{Deihimi2012,
abstract = {The paper presents the application of echo state network (ESN) to short-term load forecasting (STLF) problem in power systems for both 1-h and 24-h ahead predictions while using the least number of inputs: current-hour load, predicted target-hour temperature, and only for 24-h ahead forecasting, day-type index. The study is much attractive due to inclusion of weekends/holidays what makes STLF problem much more difficult. The main aim is to show the great capabilities of ESN as a stand-alone forecaster to learn complex dynamics of hourly electric load time series and forecast the near future loads with high accuracies. ESN as the state-of-the-art recurrent neural network (RNN) gains a reservoir of dynamics tapped by trained output units with a simple and fast single-stage training process. Furthermore, the application of ESN to predict the target-hour temperature needed by ESN-based load forecasters is examined. Since temperature prediction errors affect load forecasting accuracy, effects of such errors on ESN-based load forecasting are studied by both sensitivity analysis and applying noisy temperature series. Real hourly load and temperature data of a North-American electric utility is used as the data set. The results reflect that the ESN-based STLF method provides load forecasts with acceptable high accuracy.},
author = {Deihimi, Ali and Showkati, Hemen},
doi = {10.1016/j.energy.2012.01.007},
issn = {03605442},
journal = {Energy},
number = {1},
pages = {327--340},
title = {{Application of echo state networks in short-term electric load forecasting}},
volume = {39},
year = {2012}
}
@article{RUBINSTEIN1994,
author = {Rubinstein, Mark},
issn = {00221082},
journal = {The Journal of Finance},
month = {jul},
number = {3},
pages = {771--818},
title = {{Implied Binomial Trees}},
url = {http://doi.wiley.com/10.1111/j.1540-6261.1994.tb00079.x},
volume = {49},
year = {1994}
}
@article{Venetis2003,
author = {Venetis, Ionnis A. and Paya, Ivan and Peel, David},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Venetis, Paya, Peel - 2003 - Re-examination of the predictability of economic activity using the yield spread a nonlinear approach.pdf:pdf},
issn = {10590560},
journal = {International Review of Economics {\&} Finance},
keywords = {real gdp growth,smooth transition nonlinearity,str,time-varying parameters,tv-,yield spread},
number = {2},
pages = {187--206},
title = {{Re-examination of the predictability of economic activity using the yield spread: a nonlinear approach}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1059056002001478},
volume = {12},
year = {2003}
}
@article{Rangvid2001,
abstract = {The degree of convergence among three major European stock markets is analyzed within the framework of a recursive common stochastic trends analysis. The results point towards a decreasing number of common stochastic trends influencing the stock markets, i.e. the degree of convergence among European stock markets has been increased during the recent two decades.},
author = {Rangvid, Jesper},
issn = {01651765},
journal = {Economics Letters},
keywords = {Common trends,F41,G15,Recursive estimations,Stock market integration},
month = {jun},
number = {3},
pages = {383--389},
title = {{Increasing convergence among European stock markets?}},
url = {http://www.sciencedirect.com/science/article/pii/S0165176501003615},
volume = {71},
year = {2001}
}
@article{balan,
author = {Balan, R},
journal = {Bolletino della Unione Matematica Italiana},
number = {8-A},
pages = {335--344},
title = {{A note about the integrability of distributions with singularities}},
volume = {7},
year = {1994}
}
@book{volterra:book,
author = {Volterra, V.},
publisher = {Dover},
title = {{Theory of Functionals and of Integral and Integro-Differential Equations.}},
year = {1959}
}
@article{Miller2012,
author = {Miller, J. Isaac},
title = {{Mixed-frequency Cointegrating Regressions with Parsimonious Distributed Lag Structures}},
url = {http://ideas.repec.org/p/umc/wpaper/1211.html},
year = {2012}
}
@book{Aliprantis2006,
author = {Aliprantis, Charalambos D. and Border, Kim C.},
booktitle = {Infinite Dimensional Analysis: A Hitchhiker's Guide},
doi = {10.1007/3-540-29587-9},
edition = {Third},
isbn = {3540295860},
pages = {1--705},
publisher = {Springer Verlag},
title = {{Infinite Dimensional Analysis: A Hitchhiker's Guide}},
year = {2006}
}
@article{Lyons:1998,
author = {Lyons, Terry},
journal = {Revista Matem{\'{a}}tica Iberoamericana},
number = {2},
pages = {215--310},
title = {{Differential equations driven by rough signals}},
volume = {14},
year = {1998}
}
@article{DeMol2008,
abstract = {This paper considers Bayesian regression with normal and double-exponential priors as forecasting methods based on large panels of time series. We show that, empirically, these forecasts are highly correlated with principal component forecasts and that they perform equally well for a wide range of prior choices. Moreover, we study conditions for consistency of the forecast based on Bayesian regression as the cross-section and the sample size become large. This analysis serves as a guide to establish a criterion for setting the amount of shrinkage in a large cross-section.},
author = {Mol, Christine De and Giannone, Domenico and Reichlin, Lucrezia and {De Mol}, Christine},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Mol, Giannone, Reichlin - 2006 - Forecasting using a large number of predictors is bayesian regression a valid alternative to principal.pdf:pdf},
institution = {European Central Bank},
issn = {03044076},
journal = {Journal of Econometrics},
keywords = {Bayesian VAR,Lasso regression,c11,c13,c33,c53,ridge regression},
month = {oct},
number = {2},
pages = {318--328},
title = {{Forecasting using a large number of predictors: Is Bayesian shrinkage a valid alternative to principal components?}},
url = {http://dx.doi.org/10.1016/j.jeconom.2008.08.011},
volume = {146},
year = {2008}
}
@article{Owen2006,
abstract = {We used functional magnetic resonance imaging to demonstrate preserved conscious awareness in a patient fulfilling the criteria for a diagnosis of vegetative state. When asked to imagine playing tennis or moving around her home, the patient activated predicted cortical areas in a manner indistinguishable from that of healthy volunteers.},
author = {Owen, Adrian M and Coleman, Martin R and Boly, Melanie and Davis, Matthew H and Laureys, Steven and Pickard, John D},
doi = {10.1126/science.1130197},
issn = {1095-9203},
journal = {Science (New York, N.Y.)},
keywords = {Adult,Awareness,Brain,Brain Injuries,Brain Injuries: physiopathology,Brain Injuries: psychology,Brain Mapping,Brain: physiopathology,Consciousness,Female,Humans,Magnetic Resonance Imaging,Neurons,Neurons: physiology,Persistent Vegetative State,Persistent Vegetative State: physiopathology,Persistent Vegetative State: psychology},
month = {sep},
number = {5792},
pages = {1402},
pmid = {16959998},
title = {{Detecting awareness in the vegetative state.}},
url = {http://www.sciencemag.org/content/313/5792/1402.short},
volume = {313},
year = {2006}
}
@book{chevalley:46,
author = {Chevalley, C.},
publisher = {Princeton University Press},
title = {{Theory of Lie Groups}},
year = {1946}
}
@unpublished{Carriero2010,
author = {Carriero, A and Kapetanios, G and Marcellino, Massimiliano},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Carriero, Kapetanios, Marcellino - 2010 - Forecasting government bond yields with large bayesian VARs.pdf:pdf},
institution = {EUI},
series = {Department of Economics},
title = {{Forecasting government bond yields with large bayesian VARs}},
year = {2010}
}
@unpublished{Recht2018,
abstract = {Machine learning is currently dominated by largely experimental work focused on improvements in a few key tasks. However, the impressive accuracy numbers of the best performing models are questionable because the same test sets have been used to select these models for multiple years now. To understand the danger of overfitting, we measure the accuracy of CIFAR-10 classifiers by creating a new test set of truly unseen images. Although we ensure that the new test set is as close to the original data distribution as possible, we find a large drop in accuracy (4{\%} to 10{\%}) for a broad range of deep learning models. Yet more recent models with higher original accuracy show a smaller drop and better overall performance, indicating that this drop is likely not due to overfitting based on adaptivity. Instead, we view our results as evidence that current accuracy numbers are brittle and susceptible to even minute natural variations in the data distribution.},
archivePrefix = {arXiv},
arxivId = {1806.00451},
author = {Recht, Benjamin and Roelofs, Rebecca and Schmidt, Ludwig and Shankar, Vaishaal},
eprint = {1806.00451},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Recht et al. - 2018 - Do CIFAR-10 Classifiers Generalize to CIFAR-10.pdf:pdf},
pages = {1--25},
title = {{Do CIFAR-10 Classifiers Generalize to CIFAR-10?}},
url = {http://arxiv.org/abs/1806.00451},
year = {2018}
}
@article{nfm,
author = {Marle, C.-M.},
journal = {Rend. Sem. Mat. Univers. Politecn. Torino},
number = {2},
pages = {227--251},
title = {{Mod{\{}{\'{e}}{\}}le d'action hamiltonienne d'un groupe the Lie sur une vari{\{}{\'{e}}{\}}t{\{}{\'{e}}{\}} symplectique}},
volume = {43},
year = {1985}
}
@article{livi:multistability,
abstract = {A recurrent neural network (RNN) possesses the echo state property (ESP) if, for a given input sequence, it “forgets” any internal states of the driven (nonautonomous) system and asymptotically follows a unique, possibly complex trajectory. The lack of ESP is conventionally understood as a lack of reliable behaviour in RNNs. Here, we show that RNNs can reliably perform computations under a more general principle that accounts only for their local behaviour in phase space. To this end, we formulate a generalisation of the ESP and introduce an echo index to characterise the number of simultaneously stable responses of a driven RNN. We show that it is possible for the echo index to change with inputs, highlighting a potential source of computational errors in RNNs due to characteristics of the inputs driving the dynamics.},
archivePrefix = {arXiv},
arxivId = {2001.07694},
author = {Ceni, Andrea and Ashwin, Peter and Livi, Lorenzo and Postlethwaite, Claire},
doi = {10.1016/j.physd.2020.132609},
eprint = {2001.07694},
issn = {01672789},
journal = {Physica D: Nonlinear Phenomena},
keywords = {Echo state property,Input-driven systems,Machine learning,Multistability,Nonautonomous dynamical systems,Recurrent neural networks},
number = {September},
pages = {132609},
publisher = {Elsevier B.V.},
title = {{The echo index and multistability in input-driven recurrent neural networks}},
url = {https://doi.org/10.1016/j.physd.2020.132609},
volume = {412},
year = {2020}
}
@inproceedings{Petrosian1996,
author = {Petrosian, Arthur and Homan, Richard and Prokhorov, Danil and {Wunsch II}, Donald},
booktitle = {Proceedings of SPIE The International Society for Optical Engineering},
pages = {834--843},
title = {{Classification of epileptic EEG using neural network and wavelet transform}},
year = {1996}
}
@book{ChoLau,
author = {Chossat, P. and Lauterbach, R.},
booktitle = {Advanced Series in Nonlinear Dynamics},
publisher = {World Scientific},
title = {{Methods in Equivariant Bifurcations and Dynamical Systems}},
volume = {15},
year = {2000}
}
@article{Chauvet2005,
author = {Chauvet, Marcelle and Potter, Simon},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Chauvet, Potter - 2005 - Forecasting recessions using the yield curve.pdf:pdf},
issn = {0277-6693},
journal = {Journal of Forecasting},
keywords = {bayesian,clas-,recession forecast,structural breaks,yield curve},
month = {mar},
number = {2},
pages = {77--103},
title = {{Forecasting recessions using the yield curve}},
url = {http://doi.wiley.com/10.1002/for.932},
volume = {24},
year = {2005}
}
@misc{Bouwman2005,
author = {Bouwman, Kees E and Jacobs, Jan P A M},
booktitle = {Burns},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Bouwman, Jacobs - 2005 - Forecasting with real-time macroeconomic data the ragged-edge problem and revisions.pdf:pdf},
keywords = {data revisions,leading index,ragged edge,real-time data},
number = {May 2004},
pages = {1--23},
title = {{Forecasting with real-time macroeconomic data : the ragged-edge problem and revisions}},
year = {2005}
}
@article{Breiman1996,
author = {Breiman, Leo},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Breiman - 1996 - Heuritics of instability and stabilization.pdf:pdf},
journal = {The Annals of Statistics},
number = {January 1995},
pages = {2350--2383},
title = {{Heuritics of instability and stabilization}},
volume = {24},
year = {1996}
}
@inproceedings{indyk1998approximate,
author = {Indyk, Piotr and Motwani, Rajeev},
booktitle = {Proceedings of the thirtieth annual ACM symposium on Theory of computing},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Indyk, Motwani - 1998 - Approximate nearest neighbors towards removing the curse of dimensionality.pdf:pdf},
pages = {604--613},
title = {{Approximate nearest neighbors: towards removing the curse of dimensionality}},
year = {1998}
}
@article{inubushi2020transfer,
author = {Inubushi, Masanobu and Goto, Susumu},
journal = {Physical Review E},
number = {4},
pages = {43301},
publisher = {APS},
title = {{Transfer learning for nonlinear dynamics and its application to fluid turbulence}},
volume = {102},
year = {2020}
}
@article{Doerr2018,
author = {Doerr, Andreas and Daniel, Christian and Schiegg, Martin and Nguyen-Tuong, Duy and Schaal, Stefan and Toussaint, Marc and Trimpe, Sebastian},
title = {{Probabilistic recurrent state-space models}},
year = {2018}
}
@article{Kurkova1995,
abstract = {We examine the effect of constraining the number of hidden units. For one-hidden-layer networks with a fairly general type of units (including perceptrons with any bounded activation function and radial-basis-function units), we show that when also the size of parameters is bounded, the best approximation property is satisfied, which means that there always exists a parametrization achieving the global minimum of any error function generated by a supremum or Lp-norm. We also show that the only functions that can be approximated with arbitrary accuracy by increasing parameters in networks with a fixed number of Heaviside perceptrons are functions equal almost everywhere to functions that can be exactly computed by such networks. We give a necessary condition on values that such piecewise constant functions must achieve. {\textcopyright} 1995.},
author = {Kurkova, V{\v{e}}ra},
doi = {10.1016/0893-6080(95)00027-W},
issn = {08936080},
journal = {Neural Networks},
keywords = {Approximation of functions,Bounded number of hidden units,Heaviside perceptrons,One-hidden-layer neutral networks,Radial-basis-function units},
number = {5},
pages = {745--750},
title = {{Approximation of functions by perceptron networks with bounded number of hidden units}},
volume = {8},
year = {1995}
}
@article{Belloni2011a,
abstract = {We propose a pivotal method for estimating high-dimensional sparse linear regression models, where the overall number of regressors p is large, possibly much larger than n, but only s regressors are significant. The method is a modification of the lasso, called the square-root lasso. The method is pivotal in that it neither relies on the knowledge of the standard deviation{\{}sigma{\}} nor does it need to pre-estimate{\{}sigma{\}} . Moreover, the method does not rely on normality or sub-Gaussianity of noise. It achieves near-oracle performance, attaining the convergence rate {\{}sigma{\}}{\{}(s/n) log p{\}}1/2 in the prediction norm, and thus matching the performance of the lasso with known{\{}sigma{\}} . These performance results are valid for both Gaussian and non-Gaussian errors, under some mild moment restrictions. We formulate the square-root lasso as a solution to a convex conic programming problem, which allows us to implement the estimator using efficient algorithmic methods, such as interior-point and first-order methods.},
author = {Belloni, A. and Chernozhukov, V. and Wang, L.},
issn = {0006-3444},
journal = {Biometrika},
month = {nov},
number = {4},
pages = {791--806},
title = {{Square-root lasso: pivotal recovery of sparse signals via conic programming}},
url = {http://biomet.oxfordjournals.org/content/98/4/791.short},
volume = {98},
year = {2011}
}
@book{AnalysisBanachSpaces:vol1,
author = {Hyt{\"{o}}nen, Tuomas and van Neerven, Jan and Veraar, Mark and Weis, Lutz},
publisher = {Springer International Publishing},
title = {{Analysis in Banach Spaces}},
volume = {I},
year = {2016}
}
@article{harvey:shephard:1996,
abstract = {A stochastic volatility model may be estimated by a quasi-maximum likelihood procedure by transforming to a linear state-space form. The method is extended to handle correlation between the two disturbances in the model and applied to data on stock returns},
author = {Harvey, Andrew C. and Shephard, Neil},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Harvey, Shephard - 1996 - Estimation of an asymmetric stochastic volatility model for asset returns.pdf:pdf},
isbn = {Journal of Business {\&} Economic Statistics, Vol. 14, No. 4, 1996: pp. 429–434},
journal = {Journal of Business and Economic Statistics},
keywords = {Ancillarity,Kalman filter,Leverage,Quasi-maximum likelihood,Stock returns},
language = {en},
month = {jul},
number = {4},
pages = {429--434},
publisher = {Taylor {\&} Francis Group},
title = {{Estimation of an asymmetric stochastic volatility model for asset returns}},
url = {http://amstat.tandfonline.com/doi/abs/10.1080/07350015.1996.10524672{\#}.UjCm2xYjiao},
volume = {14},
year = {1996}
}
@article{CJO,
address = {Working paper},
author = {Christoffersen, Peter and Jacobs, Kris and Ornthanalai, C.},
editor = {Paper, Working},
journal = {Journal of Derivatives},
pages = {8--41},
title = {{GARCH option valuation: theory and evidence}},
volume = {21},
year = {2013}
}
@article{Shalova2020,
author = {Shalova, Anna and Oseledets, Ivan},
journal = {arXiv preprint arXiv:2006.03445},
title = {{Tensorized transformer for dynamical systems modeling}},
year = {2020}
}
@article{CombStorti2015,
author = {Amendola, A. and Storti, G.},
journal = {Journal of Forecasting},
number = {2},
pages = {83--91},
title = {{Model uncertainty and forecast combination in high-dimensional multivariate volatility prediction}},
volume = {34},
year = {2015}
}
@unpublished{nig:eberlein,
address = {Freiburg},
author = {Eberlein, Ernst and Hammerstein, Ernst August},
institution = {University of Freiburg. Department of Mathematical Stochastics.},
title = {{Generalized hyperbolic and inverse Gaussian distributions: limiting cases and approximation of processes}},
year = {2003}
}
@article{Ripatti2001,
author = {Ripatti, Antti},
issn = {1469-8056},
journal = {Macroeconomic Dynamics},
keywords = {Cointegrated VAR Model,Gradual Structural Change,Nonlinear Deterministic Trend},
language = {English},
month = {sep},
number = {04},
pages = {577--597},
title = {{VECTOR AUTOREGRESSIVE PROCESSES WITH NONLINEAR TIME TRENDS IN COINTEGRATING RELATIONS}},
url = {http://journals.cambridge.org/abstract{\_}S1365100501023069},
volume = {5},
year = {2001}
}
@techreport{jaeger2001,
author = {Jaeger, Herbert},
booktitle = {German National Research Center for Information Technology},
institution = {German National Research Center for Information Technology},
title = {{The `echo state' approach to analysing and training recurrent neural networks with an erratum note}},
year = {2010}
}
@article{sszub12,
author = {Zub, Stanislav},
journal = {Intellectual Archive},
number = {2},
pages = {14--24},
title = {{Research into orbital motion stability in system of two magnetically interacting bodies}},
volume = {1},
year = {2012}
}
@article{Cotter,
abstract = {This paper shows that the Cerebellar Model Articulation Controller (CMAC) is structurally similar to networks derived from a theorem of Kolmogorov. As a foundation for this comparison, we review of a proof of Kolmogorov's theorem. From this proof and an analysis of the CMAC we derive two lemmas describing functions that cannot be modeled by a CMAC. The first lemma states that such functions have zero average value over response regions of CMAC association cells. The second lemma states that such functions have local oscillations exceeding a quantifiable percentage of the global maximum absolute value of error. This second lemma gives bounds on errors caused by hash tables used as association cells in the CMAC. We present three examples illustrating the lemmas.},
author = {Cotter, Neil E. and Guillerm, Thierry J.},
doi = {10.1016/S0893-6080(05)80021-8},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Cotter, Guillerm - 1992 - The CMAC and a theorem of Kolmogorov.pdf:pdf},
issn = {08936080},
journal = {Neural Networks},
number = {2},
pages = {221--228},
title = {{The CMAC and a theorem of Kolmogorov}},
volume = {5},
year = {1992}
}
@article{KM2004,
abstract = {For both the academic and the financial communities it is a familiar stylized fact that stock market returns have negative skewness and severe excess kurtosis. This stylized fact has been supported by a vast collection of empirical studies. Given that the conventional measures of skewness and kurtosis are computed as an average and that averages are not robust, we ask: “How useful are the measures of skewness and kurtosis used in previous empirical studies?” To answer this question, we provide a survey of robust measures of skewness and kurtosis from the statistics literature and carry out extensive Monte Carlo simulations that compare the conventional measures with the robust measures of our survey. An application of the robust measures to daily S{\&}P500 index data indicates that the stylized facts might have been accepted too readily. We suggest that looking beyond the standard skewness and kurtosis measures can provide deeper and more accurate insight into market returns behavior.},
author = {Kim, Tae-Hwan and White, Halbert},
doi = {10.1016/S1544-6123(03)00003-5},
issn = {15446123},
journal = {Finance Research Letters},
number = {1},
pages = {56--73},
title = {{On more robust estimation of skewness and kurtosis}},
volume = {1},
year = {2004}
}
@unpublished{Frale2008,
author = {Frale, Cecilia and Marcellino, Massimiliano and Mazzi, Gian Luigi and Proietti, Tommaso},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Frale et al. - 2008 - A monthly indicator of the euro area GDP.pdf:pdf},
institution = {EUI},
title = {{A monthly indicator of the euro area GDP}},
year = {2008}
}
@article{BCC,
author = {Bakshi, Gurdip and Cao, Charles and Chen, Zhiwu},
doi = {10.1111/j.1540-6261.1997.tb02749.x},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Bakshi, Cao, Chen - 1997 - Empirical performance of alternative option pricing models.pdf:pdf},
issn = {00221082},
journal = {The Journal of Finance},
month = {dec},
number = {5},
pages = {2003--2049},
title = {{Empirical performance of alternative option pricing models}},
url = {http://doi.wiley.com/10.1111/j.1540-6261.1997.tb02749.x},
volume = {52},
year = {1997}
}
@article{SiklosNg2001,
author = {Siklos, Pierre L. and Ng, Patrick},
issn = {1361-374X},
journal = {Pacific Economic Review},
month = {feb},
number = {1},
pages = {89--110},
title = {{Integration Among Asia-Pacific and International Stock Markets: Common Stochastic Trends and Regime Shifts}},
url = {http://doi.wiley.com/10.1111/1468-0106.00120},
volume = {6},
year = {2001}
}
@book{rugh:book,
author = {Rugh, Wilson J.},
publisher = {The Johns Hopkins University Press},
title = {{Nonlinear System Theory. The Volterra/Wiener Approach}},
year = {1981}
}
@article{Trouve1998,
author = {Trouv{\'{e}}, Alain},
doi = {10.1023/A:1008001603737},
journal = {International Journal of Computer Vision},
number = {3},
pages = {213--221},
publisher = {Kluwer Academic Publishers},
title = {{Diffeomorphisms groups and pattern matching in image analysis}},
url = {http://link.springer.com/10.1023/A:1008001603737},
volume = {28},
year = {1998}
}
@book{wiener:book,
author = {Wiener, Norbert},
pages = {131},
publisher = {The Technology Press of MIT},
title = {{Nonlinear Problems in Random Theory}},
year = {1958}
}
@book{cb,
author = {Cushman, R. H. and Bates, L. M.},
publisher = {Birkh{\"{a}}user Verlag},
title = {{Global Aspects of Classical Integrable Systems}},
year = {1997}
}
@article{Monti,
author = {Monti, Martin M. and Vanhaudenhuyse, Audrey and Coleman, Martin R. and Boly, Melanie and {Pickard, John D. Tshibanda}, Luaba and Owen, Adrian M. and Laureys, Steven},
journal = {The New England Journal of Medicine},
pages = {579--589},
title = {{Willful modulation of brain activity in disorders of consciousness}},
volume = {362},
year = {2010}
}
@article{Cox1981,
author = {Cox, D. R.},
journal = {Scandinavian Journal of Statistics},
number = {2},
pages = {93--115},
title = {{Statistical analysis of time series: Some recent developments}},
volume = {8},
year = {1981}
}
@unpublished{Grohs2021,
author = {Grohs, Philipp and Voigtlaender, F.},
title = {{Proof of the theory-to-practice gap in deep learning via sampling complexity bounds for neural network approximation spaces}},
year = {2021}
}
@phdthesis{Callonnec2005,
author = {Callonnec, Ga{\"{e}}l},
school = {Institut d'Etudes Politiques de Paris},
title = {{Politique mon{\{}{\'{e}}{\}}taire et bulle sp{\{}{\'{e}}{\}}culative}},
year = {2005}
}
@article{Chauvet2002,
author = {Chauvet, Marcelle and Potter, Simon},
issn = {01651765},
journal = {Economics Letters},
keywords = {bayesian,c53,classical methods,e52,jel classification,recession forecast,structural breaks,yield curve},
month = {oct},
number = {2},
pages = {245--253},
title = {{Predicting a recession: evidence from the yield curve in the presence of structural breaks}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0165176502001283},
volume = {77},
year = {2002}
}
@article{Badescu08a,
abstract = {Optionpricing based on GARCH models is typically obtained under the assumption that the random innovations are standard normal (normal GARCH models). However, these models fail to capture the skewness and the leptokurtosis in financial data. We propose a new method to compute option prices using a nonparametric density estimator for the distribution of the driving noise. We investigate the pricing performances of this approach using two different risk neutral measures: the Esscher transform pioneered by Gerber and Shiu [Gerber, H.U., Shiu, E.S.W., 1994a. Optionpricing by Esscher transforms (with discussions). Trans. Soc. Actuar. 46, 99–91], and the extended Girsanov principle introduced by Elliot and Madan [Elliot, R.J., Madan, D.G., 1998. A discrete time equivalent martingale 9 measure. Math. Finance 8, 127–152]. Both measures are justified by economic arguments and are consistent with Duan's [Duan, J.-C., 1995. The GARCHoptionpricing model. Math. Finance 5, 13–32] local risk neutral valuation relationship (LRNVR) for normal GARCH models. The main advantage of the two measures is that one can price derivatives using skewed or heavier tailed innovations distributions to model the returns. An empirical study regarding the European Call option valuation on S{\&}P500 Index shows: (i) under both risk neutral measures our semiparametric algorithm performs better than the existing normal GARCH models if we allow for a leverage effect and (ii) the pricing errors when using the Esscher transform are quite small even though our estimation procedure is based only on historical return data.},
author = {Badescu, Alexandru M. and Kulperger, Reg J.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Badescu, Kulperger - 2008 - GARCH option pricing A semiparametric approach.pdf:pdf},
issn = {01676687},
journal = {Insurance: Mathematics and Economics},
keywords = {esscher transform,extended girsanov principle,garch,kernel density estimator,optionpricing,semiparametric pricing},
month = {aug},
number = {1},
pages = {69--84},
title = {{GARCH option pricing: A semiparametric approach}},
volume = {43},
year = {2008}
}
@inproceedings{Amodei2016,
author = {Amodei, Dario and Ananthanarayanan, Sundaram and Anubhai, Rishita and Bai, Jingliang},
booktitle = {Proceedings of the 33rd International Conference on Machine Learning},
title = {{Deep Speech 2 : End-to-end speech recognition in English and Mandarin}},
year = {2016}
}
@inproceedings{LNO:14,
author = {Lyons, Terry and Ni, Hao and Oberhauser, Harald},
booktitle = {Proceedings of the 2014 International Conference on Big Data Science and Computing},
pages = {1--8},
title = {{A feature set for streams and an application to high-frequency financial tick data}},
year = {2014}
}
@book{dk,
author = {Duistermaat, J. J. and Kolk, J. A.},
booktitle = {Universitext},
publisher = {Springer-Verlag},
title = {{Lie Groups}},
year = {1999}
}
@article{Usset2015,
author = {Usset, Joseph and Staicu, Ana-Maria and Maity, Arnab},
journal = {Computational Statistics and Data Analysis},
title = {{Interaction models for functional regression}},
year = {2015}
}
@article{Brandt1990,
author = {Brandt, E. H.},
journal = {Am. J. Phys.},
number = {1},
pages = {43--49},
title = {{Rigid levitation and suspension of high-temperature superconductors by magnets}},
volume = {58},
year = {1990}
}
@article{Agarwal2012,
author = {Agarwal, Sameer and Iyer, Anand P. and Panda, Aurojit and Madden, Samuel and Mozafari, Barzan and Stoica, Ion},
issn = {21508097},
journal = {Proceedings of the VLDB Endowment},
month = {aug},
number = {12},
pages = {1902--1905},
publisher = {VLDB Endowment},
title = {{Blink and it's done}},
url = {http://dl.acm.org/citation.cfm?id=2367502.2367533},
volume = {5},
year = {2012}
}
@article{Franas1985,
author = {Franaszczuk, P. J. and Blinowska, K. J. and Kowalczyk, M.},
journal = {Biological Cybern.},
pages = {239--247},
title = {{The application of parametric multichannel spectral estimates in the study of electrical brain activity}},
volume = {51},
year = {1985}
}
@inproceedings{Allen-Zhu2019a,
author = {Allen-Zhu, Zeyuan and Li, Yuanzhi and Song, Zhao},
booktitle = {33rd Conference on Neural Information Processing Systems (NeurIPS 2019)},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Allen-Zhu, Li, Song - 2019 - On the convergence rate of training recurrent neural networks.pdf:pdf},
title = {{On the convergence rate of training recurrent neural networks}},
year = {2019}
}
@article{combJFE2017,
author = {Caldeira, Joao F. and Moura, Guilherme V. and Nogales, Francisco J. and Santos, Andr{\'{e}} A. P.},
journal = {Journal of Financial Econometrics},
number = {2},
pages = {247--285},
title = {{Combining multivariate volatility forecasts: An economic-based approach}},
volume = {15},
year = {2017}
}
@article{Badescu:option:pricing,
author = {Badescu, Alex and Elliott, Robert J and Kulperger, Reg and Jarkko, Miettinen and Siu, Tak Kuen},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Badescu et al. - 2011 - A comparison of pricing kernels for GARCH option pricing with generalized hyperbolic distributions.pdf:pdf},
journal = {International Journal of Theoretical and Applied Finance},
number = {5},
pages = {669--708},
title = {{A comparison of pricing kernels for GARCH option pricing with generalized hyperbolic distributions}},
volume = {14},
year = {2011}
}
@book{Rahman:Schmeisser,
address = {Oxford},
author = {Rahman, Q. I. and Schmeisser, G.},
pages = {742},
publisher = {Clarendon Press},
title = {{Analytic Theory of Polynomials}},
year = {2002}
}
@article{mardia:kurtosis,
author = {Mardia, K V},
issn = {0006-3444},
journal = {Biometrika},
number = {3},
pages = {519--530},
title = {{Measures of multivariate skewness and kurtosis with applications}},
volume = {57},
year = {1970}
}
@article{Gilchrist2009,
author = {Gilchrist, Simon and Yankov, Vladimir and Zakraj{\v{s}}ek, Egon},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Gilchrist, Yankov, Zakraj{\v{s}}ek - 2009 - Credit market shocks and economic fluctuations Evidence from corporate bond and stock markets☆.pdf:pdf},
issn = {03043932},
journal = {Journal of Monetary Economics},
keywords = {corporate bond spreads,financial accelerator},
month = {may},
number = {4},
pages = {471--493},
title = {{Credit market shocks and economic fluctuations: Evidence from corporate bond and stock markets☆}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304393209000440},
volume = {56},
year = {2009}
}
@incollection{Maltarollo2013,
author = {Maltarollo, Vin{\'{i}}cius Gon{\c{c}}alves and Hon{\'{o}}rio, K{\'{a}}thia Maria and da Silva, Alb{\'{e}}rico Borges},
chapter = {Artificial},
doi = {10.5772/51275},
editor = {Suzuki, Kenji},
publisher = {InTech},
title = {{Applications of Artificial Neural Networks in Chemical Problems}},
url = {http://www.intechopen.com/books/export/citation/BibTex/artificial-neural-networks-architectures-and-applications/applications-of-artificial-neural-networks-in-chemical-problems},
year = {2013}
}
@phdthesis{Culpep1999,
abstract = {Artificial neural networks were trained to classify segments of 12 channel EEG data into one of five classes corresponding to five cognitive tasks performed by one subject. Three-layer feedforward neural networks were trained using a validation set to control over-fitting. Independent Component Analysis (ICA) was used to segregate obvious artifactual EEG components from other sources, and a frequency-band representa- tion was used to represent the sources computed by ICA. The most nota- ble result is an 85{\%} accuracy rate on differentiation between two tasks, using a segment of EEG 1/20th of a second long.},
author = {Culpepper, Jack},
pages = {1--10},
title = {{Discriminating Mental States Using EEG Represented by Power Spectral Density}},
year = {1999}
}
@article{cortes:et:al:2003,
address = {Seville},
author = {Cort{\'{e}}s, J. and van der Schaft, J. and Crouch, P. E.},
journal = {2nd IFAC Workshop on Lagrangian and Hamiltonian Methods for Nonlinear Control},
pages = {73--78},
title = {{Gradient realization of nonlinear control systems}},
year = {2003}
}
@article{SX2003a,
author = {Scheinkman, Jos{\'{e}} A. and Xiong, Wei},
journal = {Journal of Political Economy},
pages = {1183--1220},
title = {{Overconfidence and speculative bubbles}},
url = {http://www.jstor.org/stable/10.1086/378531?seq=1{\#}page{\_}scan{\_}tab{\_}contents},
volume = {111},
year = {2003}
}
@incollection{review:multivariate:GARCH:handbook,
address = {Berlin},
author = {Silvennoinen, A and Ter{\"{a}}svirta, T},
booktitle = {Handbook of Financial Time Series},
pages = {201--229},
publisher = {Springer},
title = {{Multivariate GARCH models}},
year = {2009}
}
@article{Pekarsky1998,
abstract = {In this paper we analyze the dynamics of N point vortices moving on a sphere from the point of view of geometric mechanics. The formalism is developed for the general case of N vortices, and the details are worked out for the (integrable) case of three vortices. The system under consideration is SO(3) invariant; the associated momentum map generated by this SO(3) symmetry is equivariant and corresponds to the moment of vorticity. Poisson reduction corresponding to this symmetry is performed; the quotient space is constructed and its Poisson bracket structure and symplectic leaves are found explicitly. The stability of relative equilibria is analyzed by the energy-momentum method. Explicit criteria for stability of different configurations with generic and nongeneric momenta are obtained. In each case a group of transformations is specified, modulo which one has stability in the original (unreduced) phase space. Special attention is given to the distinction between the cases when the relative equilibrium is a nongreat circle equilateral triangle and when the vortices line up on a great circle.},
author = {Pekarsky, Sergey and Marsden, Jerrold E.},
journal = {Journal of Mathematical Physics},
keywords = {Caltech Library Services},
month = {nov},
number = {11},
pages = {5894--5907},
title = {{Point vortices on a sphere: Stability of relative equilibria}},
url = {http://authors.library.caltech.edu/3610/1/PEKjmp98.pdf},
volume = {39},
year = {1998}
}
@inproceedings{Kidambi2018,
abstract = {Momentum based stochastic gradient methods such as heavy ball (HB) and Nesterov's accelerated gradient descent (NAG) method are widely used in practice for training deep networks and other supervised learning models, as they often provide significant improvements over stochastic gradient descent (SGD). Rigorously speaking, "fast gradient" methods have provable improvements over gradient descent only for the deterministic case, where the gradients are exact. In the stochastic case, the popular explanations for their wide applicability is that when these fast gradient methods are applied in the stochastic case, they partially mimic their exact gradient counterparts, resulting in some practical gain. This work provides a counterpoint to this belief by proving that there exist simple problem instances where these methods cannot outperform SGD despite the best setting of its parameters. These negative problem instances are, in an informal sense, generic; they do not look like carefully constructed pathological instances. These results suggest (along with empirical evidence) that HB or NAG's practical performance gains are a by-product of mini-batching. Furthermore, this work provides a viable (and provable) alternative, which, on the same set of problem instances, significantly improves over HB, NAG, and SGD's performance. This algorithm, referred to as Accelerated Stochastic Gradient Descent (ASGD), is a simple to implement stochastic algorithm, based on a relatively less popular variant of Nesterov's Acceleration. Extensive empirical results in this paper show that ASGD has performance gains over HB, NAG, and SGD.},
author = {Kidambi, Rahul and Netrapalli, Praneeth and Jain, Prateek and Kakade, Sham},
booktitle = {2018 Information Theory and Applications Workshop, ITA 2018},
doi = {10.1109/ITA.2018.8503173},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Kidambi et al. - 2018 - On the insufficiency of existing momentum schemes for stochastic optimization.pdf:pdf},
isbn = {9781728101248},
number = {2007},
pages = {1--23},
title = {{On the insufficiency of existing momentum schemes for stochastic optimization}},
year = {2018}
}
@article{hornik:derivatives,
abstract = {We give conditions ensuring that multilayer feedforward networks with as few as a single hidden layer and an appropriately smooth hidden layer activation function are capable of arbitrarily accurate approximation to an arbitrary function and its derivatives. In fact, these networks can approximate functions that are not differentiable in the classical sense, but possess only a generalized derivative, as is the case for certain piecewise differentiable functions. The conditions imposed on the hidden layer activation function are relatively mild; the conditions imposed on the domain of the function to be approximated have practical implications. Our approximation results provide a previously missing theoretical justification for the use of multilayer feedforward networks in applications requiring simultaneous approximation of a function and its derivatives.},
author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
doi = {10.1016/0893-6080(90)90005-6},
issn = {08936080},
journal = {Neural Networks},
number = {5},
pages = {551--560},
title = {{Universal approximation of an unknown mapping and its derivatives using multilayer feedforward networks}},
volume = {3},
year = {1990}
}
@article{baum1966statistical,
author = {Baum, Leonard E and Petrie, Ted},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Baum, Petrie - 1966 - Statistical inference for probabilistic functions of finite state Markov chains.pdf:pdf},
journal = {The annals of mathematical statistics},
number = {6},
pages = {1554--1563},
publisher = {JSTOR},
title = {{Statistical inference for probabilistic functions of finite state Markov chains}},
volume = {37},
year = {1966}
}
@article{Engle2002,
abstract = {Time varying correlations are often estimated with multivariate generalized autoregressive conditional heteroskedasticity (GARCH) models that are linear in squares and cross products of the data. A new class of multivariate models called dynamic conditional correlation models is proposed. These have the flexibility of univariate GARCH models coupled with parsimonious parametric models for the correlations. They are not linear but can often be estimated very simply with univariate or two-step methods based on the likelihood function. It is shown that they perform well in a variety of situations and provide sensible empirical results. Time varying correlations are often estimated with multivariate generalized autoregressive conditional heteroskedasticity (GARCH) models that are linear in squares and cross products of the data. A new class of multivariate models called dynamic conditional correlation models is proposed. These have the flexibility of univariate GARCH models coupled with parsimonious parametric models for the correlations. They are not linear but can often be estimated very simply with univariate or two-step methods based on the likelihood function. It is shown that they perform well in a variety of situations and provide sensible empirical results.},
author = {Engle, Robert},
doi = {10.1198/073500102288618487},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Engle - 2002 - Dynamic Conditionl Correlation - A Simple Class of Multivariate GARCH Models.pdf:pdf},
issn = {0735-0015},
journal = {Journal of Business {\&} Economic Statistics},
month = {jul},
number = {3},
pages = {339--350},
publisher = {Taylor {\&} Francis},
title = {{Dynamic Conditional Correlation}},
url = {http://dx.doi.org/10.1198/073500102288618487},
volume = {20},
year = {2002}
}
@article{Rodriguez-Olmos2008,
author = {Rodr{\'{i}}guez-Olmos, Miguel and Sousa-Dias, M. Esmeralda},
issn = {0938-8974},
journal = {Journal of Nonlinear Science},
month = {nov},
number = {2},
pages = {179--219},
title = {{Nonlinear Stability of Riemann Ellipsoids with Symmetric Configurations}},
url = {http://www.springerlink.com/index/10.1007/s00332-008-9032-z http://link.springer.com/10.1007/s00332-008-9032-z},
volume = {19},
year = {2008}
}
@article{Flury2011,
author = {Flury, Thomas and Shephard, Neil},
journal = {Econometric Theory},
number = {5},
pages = {933--956},
title = {{Bayesian inference based only on simulated likelihood: Particle filter analysis of dynamic economic models}},
volume = {27},
year = {2011}
}
@unpublished{Pelagatti2009,
author = {Pelagatti, Matteo and Lisi, Francesco},
title = {{Variance initialization in GARCH estimation}},
year = {2009}
}
@article{hafner:kurtosis,
author = {Hafner, Christian M},
journal = {Journal of Financial Econometrics},
number = {1},
pages = {26--54},
title = {{Fourth moment structure of multivariate GARCH models}},
volume = {1},
year = {2001}
}
@incollection{gb08,
author = {Grant, M and Boyd, S},
booktitle = {Recent Advances in Learning and Control},
editor = {Blondel, V and Boyd, S and Kimura, H},
pages = {95--110},
publisher = {Springer-Verlag Limited},
series = {Lecture Notes in Control and Information Sciences},
title = {{Graph implementations for nonsmooth convex programs}},
year = {2008}
}
@article{BrownMariano,
author = {Brown, Bryan W. and Mariano, Roberto S.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Brown, Mariano - 1989 - Measures of deterministic prediction bias in nonlinear models.pdf:pdf},
journal = {International Economic Review},
pages = {667--684},
title = {{Measures of deterministic prediction bias in nonlinear models}},
url = {http://www.jstor.org/stable/10.2307/2526782},
volume = {30},
year = {1989}
}
@unpublished{Evermann2017,
author = {Evermann, Joerg and Rehse, Jana-Rebecca and Fettke, Peter},
title = {{Predicting process behaviour using deep learning}},
year = {2017}
}
@article{Hai:13,
author = {Hairer, Martin},
issn = {0103-0752},
journal = {Braz. J. Probab. Stat.},
number = {2},
pages = {175--210},
publisher = {Institute of Mathematical Statistics (IMS), Bethesda, MD; Brazilian Statistical Association, S{\~{a}}o Paulo},
title = {{Introduction to regularity structures}},
volume = {29},
year = {2015}
}
@inproceedings{Taylor1982,
author = {Taylor, Stephen J},
booktitle = {Time series analysis: theory and practice I},
editor = {Anderson, Brian D.O.},
pages = {1961--1979},
title = {{Financial returns modelled by the product of two stochastic processes, a study of daily sugar prices}},
year = {1982}
}
@book{bierstone:1980,
address = {Rio de Janeiro},
author = {Bierstone, E.},
booktitle = {Monografias de Matem{\'{a}}tica},
publisher = {Instituto de Matem{\'{a}}tica Pura e Aplicada},
title = {{The Structure of Orbit Spaces and the Singularities of Equivariant Mappings}},
volume = {35},
year = {1980}
}
@article{Marcellino2007,
abstract = {Predicting the future evolution of GDP growth and inflation is a central concern in economics. Forecasts are typically produced either from economic theory based models or from simple linear time series models. While a time series model can provide a reasonable benchmark to evaluate the value added of economic theory relative to the pure explanatory power of the past behavior of the variable, recent developments in time series analysis suggest that more sophisticated time series models could provide more serious benchmarks for economic models. In this paper we evaluate whether these complicated time series models can outperform standard linear models for forecasting GDP growth and inflation. We consider a large variety of models and evaluation criteria, using a bootstrap algorithm to evaluate the statistical significance of our results. Our main conclusion is that in general linear time series models can be hardly beaten if they are carefully specified. However, we also identify some important cases where the adoption of a more complicated benchmark can alter the conclusions of economic analyses about the driving forces of GDP growth and inflation.},
author = {Marcellino, Massimiliano and Bocconi, Iep-universit{\`{a}}},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Marcellino, Bocconi - 2007 - A comparison of time series models for forecasting GDP growth and inflation.pdf:pdf},
institution = {Bocconi University, Italia},
journal = {Spring},
keywords = {carlos iii,forecasting,frank diebold,george kapetanios,growth,hashem pesaran,humboldt,i am grateful,inflation,lutz kilian,mark watson seminar,niels haldrup,non linear models,participants bocconi,time varying models,todd clark,toni espasa,venezia},
number = {April},
title = {{A comparison of time series models for forecasting GDP growth and inflation}},
url = {http://www.eui.eu/Personal/Marcellino/1.pdf},
year = {2007}
}
@article{PhengpisApilado2004,
abstract = {Whether economic interdependence among countries is a contributing factor to cointegration and common stochastic trends in international stock markets is indiscernible due to contradictory results from prior empirical work. This study aims to add clarity to this issue through a more distinct grouping of countries and methodological enhancements. A comparative analysis of cointegration is conducted between stock market price indices of major Economic and Monetary Union (EMU) and non-EMU countries. The conventional Johansen methodology is augmented with several diagnostic techniques (that have not been all inclusive in previous studies) to ensure the robustness of test results. Major findings pertinent to investors and policymakers are that economic interdependence appears to be the important contributing factor and that the U.S. stock market does not exert influences on long-run performances of other included stock markets. Furthermore, while the UK is not an EMU member, it may be viewed as a quasi EMU participant due to its stock market being cointegrated with and yet one of the common stochastic trends (besides those of Germany, Italy, and the Netherlands) within the EMU stock markets under investigation.},
author = {Phengpis, Chanwit and Apilado, Vince P.},
issn = {10575219},
journal = {International Review of Financial Analysis},
keywords = {Cointegration,Common stochastic trends,Economic interdependence,F02,F36,G15,International financial markets},
month = {sep},
number = {3},
pages = {245--263},
title = {{Economic interdependence and common stochastic trends: A comparative analysis between EMU and non-EMU stock markets}},
url = {http://www.sciencedirect.com/science/article/pii/S105752190400016X},
volume = {13},
year = {2004}
}
@article{LeLyNi:2013,
abstract = {We bring the theory of rough paths to the study of non-parametric statistics on streamed data. We discuss the problem of regression where the input variable is a stream of information, and the dependent response is also (potentially) a stream. A certain graded feature set of a stream, known in the rough path literature as the signature, has a universality that allows formally, linear regression to be used to characterise the functional relationship between independent explanatory variables and the conditional distribution of the dependent response. This approach, via linear regression on the signature of the stream, is almost totally general, and yet it still allows explicit computation. The grading allows truncation of the feature set and so leads to an efficient local description for streams (rough paths). In the statistical context this method offers potentially significant, even transformational dimension reduction. By way of illustration, our approach is applied to stationary time series including the familiar AR model and ARCH model. In the numerical examples we examined, our predictions achieve similar accuracy to the Gaussian Process (GP) approach with much lower computational cost especially when the sample size is large.},
archivePrefix = {arXiv},
arxivId = {1309.0260},
author = {Levin, Daniel and Lyons, Terry and Ni, Hao},
eprint = {1309.0260},
journal = {Preprint},
number = {291244},
pages = {1--40},
title = {{Learning from the past, predicting the statistics for the future, learning an evolving system}},
url = {http://arxiv.org/abs/1309.0260},
year = {2013}
}
@article{Rossana1995,
author = {{Robert Rossana and John Seater} and Rossana, Robert J. and Seater, John J.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Robert Rossana and John Seater - Unknown - Temporal Aggregation and Economic Time Series.pdf:pdf;:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Robert Rossana and John Seater, Rossana, Seater - 1995 - Temporal aggregation and economic time series.pdf:pdf},
journal = {Journal of Business and Economic Statistics Economic Statistics},
number = {4},
pages = {441--451},
title = {{Temporal aggregation and economic time series}},
url = {http://www4.ncsu.edu/{~}jjseater/PDF/PublishedPapers/TempAggEconTimeSeries.pdf},
volume = {13},
year = {1995}
}
@incollection{Kevrekidis2011,
address = {Berlin, Heidelberg},
author = {Das, Payel and Frewen, Thomas A and Kevrekidis, Ioannis G and Clementi, Cecilia},
chapter = {Think Glob},
doi = {10.1007/978-3-642-14941-2_6},
editor = {Gorban, N Alexander and Roose, Dirk},
isbn = {978-3-642-14941-2},
pages = {113--131},
publisher = {Springer Berlin Heidelberg},
title = {{Coping with Complexity: Model Reduction and Data Analysis}},
url = {http://dx.doi.org/10.1007/978-3-642-14941-2{\_}6},
year = {2011}
}
@techreport{Goudarzi2016,
abstract = {Recurrent neural networks (RNN) are simple dynamical systems whose computational power has been attributed to their short-term memory. Short-term memory of RNNs has been previously studied analytically only for the case of orthogonal networks, and only under annealed approximation , and uncorrelated input. Here for the first time, we present an exact solution to the memory capacity and the task-solving performance as a function of the structure of a given network instance, enabling direct determination of the function-structure relation in RNNs. We calculate the memory capacity for arbitrary networks with exponentially correlated input and further related it to the performance of the system on signal processing tasks in a supervised learning setup. We compute the expected error and the worst-case error bound as a function of the spectra of the network and the correlation structure of its inputs and outputs. Our results give an explanation for learning and generalization of task solving using short-term memory, which is crucial for building alternative computer architectures using physical phenomena based on the short-term memory principle. Excitable dynamical systems, or reservoirs, store a short-term memory of a driving input signal in their instantaneous state [1]. This memory can produce a desired output in a linear readout layer, which can be trained efficiently using ordinary linear regression or gradient descent. This paradigm, called reservoir computing (RC), was originally proposed as a simplified model of information processing in the prefrontal cortex [2]. It was later generalized to explain computation in cortical mi-crocircuits [3] and to facilitate training in recurrent neu-ral networks [4]. A central feature of RC is the lack of fine tuning of the underlying dynamical system: any random structure that guarantees a stable dynamics gives rise to short-term memory [3, 4]. Analogous behavior has also been observed in selective response in random neu-ral populations [6]. Furthermore, fixed underlying structure in RC makes it suitable for implementing computation using spatially distributed physical phenomena[13-15, 17-21]. Such approaches can give us a way to store and process information more efficiently than with von Neumann architecture [7]. Short-term memory in neural networks has been studied for uncorrelated input u(t) under annealed approximation , i.e., connectivity is resampled independently at each time step [8]. That study considered only linear orthogonal networks, where the columns of the connectiv-ity matrix are pairwise orthogonal and the node transfer functions are linear. A memory function m($\tau$) was defined to measure the ability of the system to reconstruct input from $\tau$ time steps ago, i.e., u(t−$\tau$), from the present system state x(t). It was shown that the total memory capacity cannot exceed the N degrees of freedom in the system. For networks with saturating nonlinearity, the memory scales with √ N [1]; however, by fine-tuning the nonlinearity one can achieve near-linear scaling of memory capacity [9]. In nonlinear networks, it is very difficult to analyze the complete memory function and even harder to relate it to the performance on computational tasks, as is evident from many works in this area with hard-to-reconcile conclusions (see Ref. [5]). Model-Consider a discrete-time network of N nodes. The network weight matrix $\Omega$ is N × N with spectral radius $\lambda$ {\textless} 1. A time-dependent scalar input signal u t is fed to the network using the input weight vector $\omega$. The evolution of the network state x t and the output y t is governed by x t+1 = $\Omega$x t + $\omega$u t , and (1) y t+1 = $\Psi$x t+1 , (2) where $\Psi$ = (XX) −1 X Y is an N-dimensional column vector calculated for a desired output y t. Here, each column of X is the state of the network at time x t and each column of Y is the corresponding desired output at each time step. In practice it is sometimes necessary to use Tikhonov regularization to calculate the readout weights, i.e., $\Psi$ = XX + $\gamma$ 2 I −1 X Y , where $\gamma$ is a regularization factor that needs to be adjusted depending on $\Omega$, $\omega$, and u t [5]. Calculating $\Psi$ for a given problem requires the following input-output-dependent evaluations (Appendix A): XX = ∞ i,j=0 $\Omega$ i $\omega$R uu (i − j)$\omega$ ($\Omega$) j , and (3) XY = ∞ i=0 $\Omega$ i $\omega$R u y (i), (4) where R uu (i − j) = u t u t−(i−j) and R u y (i − j) = u t y t−(i−j) are the autocorrelation of the input and the},
archivePrefix = {arXiv},
arxivId = {1604.06929v1},
author = {Goudarzi, Alireza and Marzen, Sarah and Banda, Peter and Feldman, Guy and Lakin, Matthew R and Teuscher, Christof and Stefanovic, Darko},
eprint = {1604.06929v1},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Goudarzi et al. - 2016 - Memory and information processing in recurrent neural networks.pdf:pdf},
title = {{Memory and information processing in recurrent neural networks}},
url = {https://arxiv.org/pdf/1604.06929.pdf},
year = {2016}
}
@article{sprecherII,
abstract = {This paper presents a numerical algorithm for the parallel computations {\$}\Phi{\$}q in the Kolmogorov superpositions f(x)={\$}\Sigma{\$}q=0m{\$}\Phi{\$}q○{\$}\xi{\$}(xq),x=(x1,{\{}{\ldots}{\}},xn)andxq=(x1+qa,{\{}{\ldots}{\}},xn+qa), thereby providing the final step in their numerical implementation. The first step consisting of the f-independent computation of the functions {\$}\xi{\$}(xq) = {\$}\Sigma{\$}pn=1 {\$}\alpha{\$}p{\$}\psi{\$}(xp + qa) with a fixed {\$}\psi{\$} and constants a and {\$}\alpha{\$}p in a hidden layer in the Hecht-Nielsen feedforward neural network has been accomplished previously. The step taken in this paper is the implementation of the output layer of the network that computes an arbitrary known continuous real-valued function f defined on the unit cube {\{}{\oe}{\}}n. Employed for the purpose is an iterative method which is intended as a basis for the possible development of adaptive methods that build on this approach. Each function {\$}\Phi{\$}q is obtained iteratively through a series {\$}\Sigma{\$}r{\$}\Phi{\$}qr which is determined on an f and q dependent subsequence dqk1,dqk2,dqk3 {\{}{\ldots}{\}} of rational coordinates dqkr=dqkr,1,{\{}{\ldots}{\}},dqkrn such that {\$}\Phi{\$}qr is determined at the coordinate points {\$}\xi{\$}(dqkr). The paper also includes alternative constructions of the functions {\$}\Phi{\$}qr and a brief discussion of the differentiability of {\$}\Phi{\$}q ο {\$}\xi{\$}(xq); together with a previous result it gives a constructive proof of Kolmogorov's theorem. {\{}{\textcopyright}{\}} 1997 Elsevier Science Ltd. All Rights Reserved.},
author = {Sprecher, David A.},
doi = {10.1016/S0893-6080(96)00073-1},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Sprecher - 1997 - A numerical implementation of Kolmogorov's superpositions II.pdf:pdf},
journal = {Neural Networks},
number = {3},
pages = {447--457},
title = {{A numerical implementation of Kolmogorov's superpositions II}},
volume = {10},
year = {1997}
}
@article{Polyak1964,
abstract = {For the solution of the functional equation P (x) = 0 (1) (where P is an operator, usually linear, from B into B, and B is a Banach space) iteration methods are generally used. These consist of the construction of a series x0, ..., xn, ..., which converges to the solution (see, for example [1]). Continuous analogues of these methods are also known, in which a trajectory x(t), 0 ≤ t ≤ ∞ is constructed, which satisfies the ordinary differential equation in B and is such that x(t) approaches the solution of (1) as t → ∞ (see [2]). We shall call the method a k-step method if for the construction of each successive iteration xn+1 we use k previous iterations xn, ..., xn-k+1. The same term will also be used for continuous methods if x(t) satisfies a differential equation of the k-th order or k-th degree. Iteration methods which are more widely used are one-step (e.g. methods of successive approximations). They are generally simple from the calculation point of view but often converge very slowly. This is confirmed both by the evaluation of the speed of convergence and by calculation in practice (for more details see below). Therefore the question of the rate of convergence is most important. Some multistep methods, which we shall consider further, which are only slightly more complicated than the corresponding one-step methods, make it possible to speed up the convergence substantially. Note that all the methods mentioned below are applicable also to the problem of minimizing the differentiable functional (x) in Hilbert space, so long as this problem reduces to the solution of the equation grad (x) = 0. {\textcopyright} 1964.},
author = {Polyak, B. T.},
doi = {10.1016/0041-5553(64)90137-5},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Polyak - 1964 - Some methods of speeding up the convergence of iteration methods.pdf:pdf},
issn = {00415553},
journal = {USSR Computational Mathematics and Mathematical Physics},
number = {5},
pages = {1--17},
title = {{Some methods of speeding up the convergence of iteration methods}},
volume = {4},
year = {1964}
}
@book{Bullo2005,
author = {Bullo, Francesco and Lewis, Andrew},
publisher = {Springer New York},
title = {{Geometric Control of Mechanical Systems}},
year = {2005}
}
@book{Arbib:handbook,
edition = {Second},
editor = {Arbib, Michael A.},
pages = {1290},
publisher = {MIT Press},
title = {{The Handbook of Brain Theory and Neural Networks}},
year = {2003}
}
@article{smodg,
author = {Patrick, George W.},
journal = {Journal of Geometry and Physics},
pages = {111--119},
title = {{Relative equilibria in Hamiltonian systems: the dynamic interpretation of nonlinear stability on a reduced phase space}},
volume = {9},
year = {1992}
}
@book{siotani1985,
address = {Columbus, Ohio},
author = {Siotani, M. and Hayakawa, T. and Fujikoshi, Y.},
publisher = {American Sciences Press},
title = {{Modern Multivariate Statistical Analysis: A Graduate Course and Handbook}},
year = {1985}
}
@article{Ahn2006,
author = {Ahn, Eun S. and Lee, Jin Man},
issn = {0960-3107},
journal = {Applied Financial Economics},
month = {jul},
number = {11},
pages = {777--784},
title = {{Volatility relationship between stock performance and real output}},
url = {http://www.tandfonline.com/doi/abs/10.1080/09603100500424775},
volume = {16},
year = {2006}
}
@book{Cesa-Bianchi2006,
author = {Cesa-Bianchi, Nicolo and Lugosi, G{\'{a}}bor},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Cesa-Bianchi, Lugosi - 2006 - Prediction, Learning, and Games.pdf:pdf},
publisher = {Cambridge University Press},
title = {{Prediction, Learning, and Games}},
year = {2006}
}
@article{GO1bis,
author = {Grigoryeva, Lyudmila and Ortega, Juan-Pablo},
journal = {International Journal of Computational Economics and Econometrics},
number = {3},
pages = {289--318},
title = {{Asymptotic forecasting error evaluation for estimated temporally aggregated linear processes}},
volume = {5},
year = {2015}
}
@book{Doya2006,
author = {Doya, K. and Ishii, Shin and Pouget, Alexandre and Rao, Rajesh},
pages = {344},
publisher = {MIT Press},
title = {{Bayesian Brain. Probabilistic Approaches to Neural Coding}},
year = {2006}
}
@article{Barshan:2011,
abstract = {We propose "supervised principal component analysis (supervised PCA)", a generalization of PCA that is uniquely effective for regression and classification problems with high-dimensional input data. It works by estimating a sequence of principal components that have maximal dependence on the response variable. The proposed supervised PCA is solvable in closed-form, and has a dual formulation that significantly reduces the computational complexity of problems in which the number of predictors greatly exceeds the number of observations (such as DNA microarray experiments). Furthermore, we show how the algorithm can be kernelized, which makes it applicable to non-linear dimensionality reduction tasks. Experimental results on various visualization, classification and regression problems show significant improvement over other supervised approaches both in accuracy and computational efficiency. {\textcopyright} 2011 Elsevier Ltd. All rights reserved.},
author = {Barshan, Elnaz and Ghodsi, Ali and Azimifar, Zohreh and {Zolghadri Jahromi}, Mansoor},
doi = {10.1016/j.patcog.2010.12.015},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Barshan et al. - 2011 - Supervised principal component analysis Visualization, classification and regression on subspaces and submanifol.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Classification,Dimensionality reduction,Kernel methods,Principal component analysis (PCA),Regression,Supervised learning,Visualization},
number = {7},
pages = {1357--1371},
publisher = {Elsevier},
title = {{Supervised principal component analysis: Visualization, classification and regression on subspaces and submanifolds}},
url = {http://dx.doi.org/10.1016/j.patcog.2010.12.015},
volume = {44},
year = {2011}
}
@book{Choquet--Bruhat:and:DeWitt--Morette,
author = {Choquet-Bruhat, Y. and DeWitt-Morette, C.},
edition = {Second},
publisher = {North-Holland},
title = {{Analysis, Manifolds, and Physics}},
year = {1982}
}
@inproceedings{Sacchi2007,
author = {Sacchi, Rodrigo and Ozturk, Mustafa C. and Principe, Jose C. and Carneiro, Adriano A. F. M. and da Silva, Ivan N.},
booktitle = {2007 International Joint Conference on Neural Networks},
doi = {10.1109/IJCNN.2007.4371334},
isbn = {978-1-4244-1379-9},
month = {aug},
pages = {2403--2408},
publisher = {IEEE},
title = {{Water inflow forecasting using the echo state network: a Brazilian case study}},
url = {http://ieeexplore.ieee.org/document/4371334/},
year = {2007}
}
@article{Christoffersen1998,
author = {Christoffersen, Peter F.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Christoffersen - 1998 - Evaluating Interval Forecasts.pdf:pdf},
issn = {00206598},
journal = {International Economic Review},
month = {nov},
number = {4},
pages = {841},
title = {{Evaluating Interval Forecasts}},
url = {http://www.jstor.org/stable/2527341?origin=crossref},
volume = {39},
year = {1998}
}
@book{BrocDavisYellowBook,
annote = {this paperback edition is a reprint of the 1991 edition.time series: theory and methods is a systematic account of linear time series models and their application to the modeling and prediction of data collected sequentially in ...},
author = {Brockwell, Peter J. and Davis, Richard A.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Brockwell, Davis - 2006 - Time Series Theory and Methods.pdf:pdf},
keywords = {econometrics,statistical theory and methods,time series: theory and methods},
pages = {577},
publisher = {Springer-Verlag},
title = {{Time Series: Theory and Methods}},
url = {http://www.springer.com/statistics/statistical+theory+and+methods/book/978-0-387-97429-3?changeHeader},
year = {2006}
}
@book{Nerrsterov:book,
author = {Nesterov, Yurii},
edition = {Second},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Nesterov - 2018 - Lectures on Convex Optimization.pdf:pdf},
isbn = {9783319915777},
publisher = {Springer},
title = {{Lectures on Convex Optimization}},
url = {http://www.springer.com/series/7393},
year = {2018}
}
@book{schetzen:book,
author = {Schetzen, M.},
publisher = {Wiley},
title = {{The Volterra and Wiener Theories of Nonlinear Systems}},
year = {1980}
}
@article{Sandberg:noterepresentation,
author = {Sandberg, Irwin W.},
doi = {10.1002/cta.164},
issn = {00989886},
journal = {International Journal of Circuit Theory and Applications},
keywords = {Linear systems,Representation theorems,Stochastic inputs},
number = {5},
pages = {505--509},
title = {{A note on representation theorems for linear discrete-space systems with stochastic inputs}},
volume = {29},
year = {2001}
}
@book{mitchell:1997,
author = {Mitchell, T. M.},
isbn = {0070428077},
pages = {414},
publisher = {McGraw-Hill},
title = {{Machine Learning}},
year = {1997}
}
@article{CLrobustness_XuReid2011,
abstract = {Composite likelihood methods have been receiving growing interest in a number of different application areas, where the likelihood function is too cumbersome to be evaluated. In the present paper, some theoretical properties of the maximum composite likelihood estimate (MCLE) are investigated in more detail. Robustness of consistency of the MCLE is studied in a general setting, and clarified and illustrated through some simple examples. We also carry out a simulation study of the performance of the MCLE in a constructed model suggested by Arnold (2010) that is not multivariate normal, but has multivariate normal marginal distributions.},
author = {Xu, Ximing and Reid, Nancy},
issn = {03783758},
journal = {Journal of Statistical Planning and Inference},
keywords = {Consistency,Godambe information,Model misspecification,Pseudo-likelihood},
month = {sep},
number = {9},
pages = {3047--3054},
title = {{On the robustness of maximum composite likelihood estimate}},
url = {http://www.sciencedirect.com/science/article/pii/S0378375811001236},
volume = {141},
year = {2011}
}
@article{Samaranayake1988,
author = {Samaranayake, V. A. and Hasza, David P.},
doi = {10.1111/j.1467-9892.1988.tb00477.x},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Samaranayake, Hasza - 1988 - Properties of predictors for multivariate autoregressive models with estimated parameters.pdf:pdf},
issn = {0143-9782},
journal = {Journal of Time Series Analysis},
number = {4},
pages = {361--383},
title = {{Properties of predictors for multivariate autoregressive models with estimated parameters}},
url = {http://doi.wiley.com/10.1111/j.1467-9892.1988.tb00477.x},
volume = {9},
year = {1988}
}
@article{sharpeCAPM,
author = {Sharpe, William F.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Sharpe - 1964 - Capital asset prices a theory of market equilibrium under conditions of risk.pdf:pdf},
journal = {The Journal of Finance},
number = {3},
pages = {425--442},
title = {{Capital asset prices: a theory of market equilibrium under conditions of risk}},
volume = {19},
year = {1964}
}
@article{LeCun1998,
author = {LeCun, Yann and Bottou, L{\'{e}}on and Bengio, Yoshua and Haffner, Patrick},
journal = {Proceedings of the IEEE},
number = {11},
pages = {2278--2324},
title = {{Gradient-based learning applied to document recognition}},
volume = {86},
year = {1998}
}
@book{delzant:1988,
address = {116,315--339},
author = {Delzant, T},
booktitle = {Bull. Soc. Math. France},
pages = {315--339},
publisher = {Bull. Soc. Math. France},
title = {{Hamiltoniens p{\{}{\'{e}}{\}}riodique set images convexes de l'application moment}},
volume = {116},
year = {1988}
}
@article{levitronMarsden,
author = {Krechetnikov, R. and Marsden, Jerrold E.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Krechetnikov, Marsden - 2006 - On destabilizing effects of two fundamental non-conservative forces.pdf:pdf},
journal = {Physica D.},
pages = {25--32},
title = {{On destabilizing effects of two fundamental non-conservative forces}},
volume = {214},
year = {2006}
}
@article{BR2016,
abstract = {The nature of the dependence between discontinuities in prices and contemporaneous discontinuities in volatility (co-jumps) has been reported by many as being elusive, in terms of sign, magnitude, and statistical significance. Using a novel identification strategy in continuous time relying on trade-level information for spot variance estimation, as well as infinitesimal cross-moments, we document that a sizeable proportion of discontinuous changes in prices are associated with strongly anti-correlated, contemporaneous, discontinuous changes in volatility. Assuming a possibly nonmonotonic pricing kernel, we illustrate the equilibrium implications of price and volatility co-jumps for return and variance risk premia.},
author = {Bandi, F.M. and Ren{\`{o}}, R.},
doi = {10.1016/j.jfineco.2015.05.007},
issn = {0304405X},
journal = {Journal of Financial Economics},
number = {1},
pages = {107--146},
title = {{Price and volatility co-jumps}},
volume = {119},
year = {2016}
}
@unpublished{Garnelo2018,
author = {Garnelo, M. and Schwarz, J. and Rosenbaum, D. and Viola, F. and Rezende, D. J. and Eslami, S. and Teh, Y. W.},
title = {{Neural processes}},
year = {2018}
}
@article{Marcellino2006,
abstract = {“Iterated” multiperiod-ahead time series forecasts are made using a one-period ahead model, iterated forward for the desired number of periods, whereas “direct” forecasts are made using a horizon-specific estimated model, where the dependent variable is the multiperiod ahead value being forecasted. Which approach is better is an empirical matter: in theory, iterated forecasts are more efficient if the one-period ahead model is correctly specified, but direct forecasts are more robust to model misspecification. This paper compares empirical iterated and direct forecasts from linear univariate and bivariate models by applying simulated out-of-sample methods to 170 U.S. monthly macroeconomic time series spanning 1959–2002. The iterated forecasts typically outperform the direct forecasts, particularly, if the models can select long-lag specifications. The relative performance of the iterated forecasts improves with the forecast horizon.},
author = {Marcellino, Massimiliano and Stock, James H. and Watson, Mark W.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Marcellino, Stock, Watson - 2006 - A comparison of direct and iterated multistep AR methods for forecasting macroeconomic time series.pdf:pdf},
issn = {03044076},
journal = {Journal of Econometrics},
keywords = {c32,e37,e47},
month = {nov},
number = {1-2},
pages = {499--526},
title = {{A comparison of direct and iterated multistep AR methods for forecasting macroeconomic time series}},
url = {http://dx.doi.org/10.1016/j.jeconom.2005.07.020},
volume = {135},
year = {2006}
}
@article{alquier:wintenberger,
abstract = {Tributyrin, a prodrug of natural butyrate, has been evaluated with an aim to overcome pharmacokinetic drawbacks of natural butyrate as a drug, i.e., its rapid metabolization and inability to achieve pharmacologic concentrations in neoplastic cells. We studied the effects of tributyrin on growth, differentiation and vitamin D receptor expression in Caco-2 cells, a human colon cancer cell line. Tributyrin was more potent in inhibiting growth and inducing cell differentiation than natural butyrate. The effect was further enhanced after addition of physiologic concentrations of dihydroxycholecalciferol [(OH)2D3]. The synergistic effect of tributyrin and (OH)2D3 in Caco-2 cells was due to tributyrin-induced overexpression of the vitamin D receptor, as measured by reverse transcriptase-polymerase chain reaction. Treatment with tributyrin increased binding of (OH)2D3 to its receptor 1.5-fold, without any change in receptor affinity. We conclude that tributyrin may, at least in part, exert its growth-reducing and differentiation-inducing effect in Caco-2 cells by an upregulation of the vitamin D receptor; this may provide a useful therapeutic approach in chemoprevention and treatment of colorectal cancer by the two nutrients occurring naturally in human diet.},
archivePrefix = {arXiv},
arxivId = {arXiv:0902.2924v4},
author = {Alquier, Pierre and Wintenberger, Olivier},
doi = {10.3150/11-BEJ359},
eprint = {arXiv:0902.2924v4},
isbn = {1756-4646},
issn = {1350-7265},
journal = {Bernoulli},
keywords = {adaptative inference,aggregation of estimators,autoregression estimation,model,model selection,randomized estimators,selection,statistical learning,time series prediction,weak dependence},
number = {3},
pages = {883--913},
pmid = {24121865},
title = {{Model selection for weakly dependent time series forecasting}},
volume = {18},
year = {2012}
}
@article{KO:19,
author = {Kir{\'{a}}ly, Franz J and Oberhauser, Harald},
journal = {Journal of Machine Learning Research},
publisher = {Journal of Machine Learning Research},
title = {{Kernels for sequentially ordered data}},
volume = {20},
year = {2019}
}
@inproceedings{Eldan2015,
abstract = {We show that there is a simple (approximately radial) function on {\$}\backslashreals{\^{}}d{\$}, expressible by a small 3-layer feedforward neural networks, which cannot be approximated by any 2-layer network, to more than a certain constant accuracy, unless its width is exponential in the dimension. The result holds for virtually all known activation functions, including rectified linear units, sigmoids and thresholds, and formally demonstrates that depth -- even if increased by 1 -- can be exponentially more valuable than width for standard feedforward neural networks. Moreover, compared to related results in the context of Boolean functions, our result requires fewer assumptions, and the proof techniques and construction are very different.},
archivePrefix = {arXiv},
arxivId = {1512.03965},
author = {Eldan, Ronen and Shamir, Ohad},
booktitle = {Conference on Learning Theory},
eprint = {1512.03965},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Eldan, Shamir - 2015 - The power of depth for feedforward neural networks.pdf:pdf},
pages = {1--33},
title = {{The power of depth for feedforward neural networks}},
url = {http://arxiv.org/abs/1512.03965},
year = {2015}
}
@article{dirac:50,
author = {Dirac, P. A. M.},
journal = {Canad. J. Math.},
pages = {129--148},
title = {{Generalized Hamiltonian mechanics}},
volume = {2},
year = {1950}
}
@article{Lutkepohl1986,
author = {L{\"{u}}tkepohl, Helmut},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/L{\"{u}}tkepohl - 1986 - Forecasting temporally aggregated vector ARMA processes.pdf:pdf},
journal = {Journal of Forecasting},
pages = {85--95},
title = {{Forecasting temporally aggregated vector ARMA processes}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/for.3980050202/abstract},
volume = {5},
year = {1986}
}
@article{Stinchcombe:bounded,
author = {Stinchcombe, M. and White, H.},
doi = {10.1109/IJCNN.1990.137817},
journal = {1990 IJCNN International Joint Conference on Neural Networks},
pages = {7--16 vol.3},
title = {{Approximating and learning unknown mappings using multilayer feedforward networks with bounded weights}},
url = {http://ieeexplore.ieee.org/document/5726775/},
year = {1990}
}
@article{Weijers2012,
author = {Weijers, Huub},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Weijers - 2012 - High-temperature superconducting magnet cables reach a record current at a magnetic field of 20 T.pdf:pdf},
journal = {MagLab Reports},
pages = {9},
title = {{High-temperature superconducting magnet cables reach a record current at a magnetic field of 20 T}},
year = {2012}
}
@article{or2006,
author = {Ortega, Juan-Pablo and Ratiu, Tudor S.},
journal = {Reports on Mathematical Physics},
pages = {51--75},
title = {{The stratified spaces of a symplectic Lie group action}},
volume = {58},
year = {2006}
}
@book{Fields,
booktitle = {In Integration algorithms and classical mechanics},
editor = {Marsden, Jerrold E. and Patrick, George W. and Shadwick, William F.},
publisher = {American mathematical society},
title = {{Integration algorithms and classical mechanics. Fields Institute comminucations, vol. 10}},
year = {1996}
}
@book{Anders_book,
address = {Munchen},
author = {Anders, U.},
editor = {Vahlen},
title = {{Statistische Neuronale Netze}},
year = {1997}
}
@book{kim:nelson,
author = {Kim, Chang-Jin and Nelson, Charles R.},
pages = {297},
publisher = {The MIT Press},
title = {{State-Space Models with Regime Switching}},
year = {1999}
}
@inproceedings{peyresq:lectures,
editor = {Montaldi, James and Ratiu, Tudor S.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Unknown - 2005 - Geometric Mechanics and Symmetry. The Peyresq Lectures.pdf:pdf},
pages = {407},
publisher = {Cambridge University Press},
title = {{Geometric Mechanics and Symmetry. The Peyresq Lectures.}},
year = {2005}
}
@misc{Adrian2010a,
author = {Adrian, T and Estrella, A},
keywords = {financial intermediation,monetary policy},
publisher = {Federal Reserve Bank of New York 421},
title = {{Monetary Cycles, Financial Cycles, and the Business Cycle}},
url = {http://www.newyorkfed.org/infoletters/2002/jan/20020108.pdf http://papers.ssrn.com/sol3/Delivery.cfm/SSRN{\_}ID1532309{\_}code387943.pdf?abstractid=1532309},
year = {2010}
}
@article{Boyle1980,
abstract = {This paper analyses the distribution of returns on a hedged portfolio, consisting of a European call option and its associated stock, when the portfolio is rebalanced at discrete time intervals. Under the assumptions of the Black-Scholes model this distribution is particularly skew. In tests of the average return on a hedged portfolio this skewness leads to biased t-statistics. The paper explores the nature and extent of this bias and suggests procedures for overcoming it. Other aspects of discrete hedging are also discussed.},
author = {Boyle, Phelim P. and Emanuel, David},
doi = {10.1016/0304-405X(80)90003-3},
issn = {0304405X},
journal = {Journal of Financial Economics},
month = {sep},
number = {3},
pages = {259--282},
title = {{Discretely adjusted option hedges}},
url = {http://dx.doi.org/10.1016/0304-405X(80)90003-3},
volume = {8},
year = {1980}
}
@article{bartolomei2006disturbed,
author = {Bartolomei, Fabrice and Bosma, Ingeborg and Klein, Martin and Baayen, Johannes C and Reijneveld, Jaap C and Postma, Tjeerd J and Heimans, Jan J and van Dijk, Bob W and de Munck, Jan C and de Jongh, Arent and Cover, Keith S. and Stam, Cornelis J.},
journal = {Clinical Neurophysiology},
number = {9},
pages = {2039--2049},
publisher = {Elsevier},
title = {{Disturbed functional connectivity in brain tumour patients: evaluation by graph analysis of synchronization matrices}},
volume = {117},
year = {2006}
}
@article{bernton2019parameter,
author = {Bernton, Espen and Jacob, Pierre E and Gerber, Mathieu and Robert, Christian P},
journal = {Information and Inference: A Journal of the IMA},
number = {4},
pages = {657--676},
publisher = {Oxford University Press},
title = {{On parameter estimation with the Wasserstein distance}},
volume = {8},
year = {2019}
}
@article{dellaportas:risk,
author = {Dellaportas, Petros and Mijatovic, Aleksandar},
journal = {Risk},
number = {May},
pages = {62--67},
title = {{Smile transformation for price prediction}},
year = {2014}
}
@article{Arkhipov2006,
author = {Arkhipov, Anton and Freddolino, Peter L and Imada, Katsumi and Namba, Keiichi and Schulten, Klaus},
doi = {http://dx.doi.org/10.1529/biophysj.106.093443},
issn = {0006-3495},
journal = {Biophysical Journal},
number = {12},
pages = {4589--4597},
title = {{Coarse-grained molecular dynamics simulations of a rotating bacterial flagellum}},
url = {http://www.sciencedirect.com/science/article/pii/S0006349506721701},
volume = {91},
year = {2006}
}
@article{BS,
author = {Black, Fischer and Scholes, Myron},
doi = {10.1086/260062},
issn = {0022-3808},
journal = {Journal of Political Economy},
month = {jan},
number = {3},
pages = {637--659},
title = {{The pricing of options and corporate liabilities}},
url = {http://ci.nii.ac.jp/naid/30017678132/en/},
volume = {81},
year = {1973}
}
@article{comon:ica,
author = {Comon, P},
journal = {Signal Processing},
pages = {287--314},
title = {{Independent component analysis: a new concept?}},
volume = {36},
year = {1994}
}
@unpublished{UMIDAS:Foroni,
author = {Foroni, Claudia and Marcellino, Massimiliano and Schumacher, Christian},
institution = {Deutsche Bundesbank},
number = {35},
title = {{U-MIDAS : MIDAS regressions with unrestricted lag polynomials}},
year = {2011}
}
@unpublished{Bellone2005,
author = {Bellone, Benoit and Gautier, Erwan and Coent, S{\'{e}}bastien Le},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Bellone, Gautier, Coent - 2005 - Les march{\'{e}}s financiers anticipent-ils les retournements conjoncturels.pdf:pdf},
institution = {Banque de Frnace},
title = {{Les march{\'{e}}s financiers anticipent-ils les retournements conjoncturels?}},
year = {2005}
}
@inproceedings{kostant66,
author = {Kostant, B.},
booktitle = {Proc. US--Japan Seminar on Diff. Geom., Kyoto. Nippon Hyronsha, Tokyo},
title = {{Orbits, symplectic structures and representation theory}},
year = {1966}
}
@inproceedings{Tanneberg2017,
author = {Tanneberg, Daniel and Peters, Jan and Rueckert, Elmar},
booktitle = {Conference on Robot Learning},
title = {{Online learning with stochastic recurrent neural networks using intrinsic motivation signals}},
year = {2017}
}
@book{book_Graybill1982,
author = {Graybill, Franklin A.},
publisher = {Brooks/Cole},
title = {{Matrices With Applications in Statistics}},
year = {1982}
}
@article{hornik:new:results,
abstract = {We show that standard feedforward networks with as few as a single hidden layer can uniformly approximate continuous functions on compacta provided that the activation function $\psi$ is locally Riemann integrable and nonpolynomial, and have universal Lp($\mu$) approximation capabilities for finite and compactly supported input environment measures $\mu$ provided that $\psi$ is locally bounded and nonpolynomial. In both cases, the input-to-hidden weights and hidden layer biases can be constrained to arbitrarily small sets; if in addition $\psi$ is locally analytic a single universal bias will do. {\textcopyright} 1993, Pergamon Press Ltd.. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Hornik, K.},
doi = {10.1016/S0893-6080(09)80018-X},
eprint = {arXiv:1011.1669v3},
isbn = {0893-6080},
issn = {08936080},
journal = {Neural Networks},
keywords = {Feedforward networks,Small weight sets,Universal approximation capabilities,Universal bias},
number = {8},
pages = {1069--1072},
pmid = {15664853},
publisher = {Pergamon Press Ltd.},
title = {{Some new results on neural network approximation}},
url = {http://dx.doi.org/10.1016/S0893-6080(09)80018-X},
volume = {6},
year = {1993}
}
@unpublished{Vanschoren2018,
author = {Vanschoren, Joaquin},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Vanschoren - 2018 - Meta-learning A survey.pdf:pdf},
title = {{Meta-learning: A survey}},
year = {2018}
}
@article{LundeRV,
author = {Lunde, Asger and Shephard, Neil and Sheppard, Kevin K.},
journal = {Journal of Business {\&} Economic Statistics},
number = {4},
pages = {504--518},
title = {{Econometrics analysis of vast co- variance matrices using composite realized kernels and their application to portfolio choice}},
volume = {34},
year = {2016}
}
@article{henriques:ortega,
author = {Henriques, Julie and Ortega, Juan-Pablo},
journal = {Studies in Nonlinear Dynamics and Econometrics},
number = {4},
pages = {383--402},
title = {{Construction, management, and performance of sparse Markowitz portfolios}},
volume = {18},
year = {2014}
}
@book{ledoux:talagrand,
author = {Ledoux, Michel and Talagrand, Michel},
doi = {10.1007/978-1-4612-0367-4},
isbn = {3-540-52013-9},
pages = {480},
publisher = {Springer-Verlag},
title = {{Probability in Banach Spaces}},
year = {1991}
}
@book{franses:vanDijk2000,
author = {Franses, P. H. and van Dijk, D.},
pages = {298},
publisher = {Cambridge University Press},
title = {{Non-Linear Time Series Models in Empirical Finance}},
year = {2000}
}
@article{Adrian2008,
author = {Adrian, Tobias and Estrella, Arturo},
issn = {01651765},
journal = {Economics Letters},
keywords = {1,classifying monetary tightening cycles,discriminant analysis,e44,e52,g0,interest rates,jel classification,logit,monetary,monetary policy,real activity slows after,term structure,the extent to which},
month = {may},
number = {2},
pages = {260--264},
title = {{Monetary tightening cycles and the predictability of economic activity}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0165176507002649},
volume = {99},
year = {2008}
}
@article{Armesto2009,
author = {Armesto, Michelle T. and Hernandez-Murillo, R. and Owyang, Michael T. and Piger, J.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Armesto et al. - 2009 - Measuring the information content of the beige book a mixed data sampling approach.pdf:pdf},
journal = {Journal of Money, Credit, and Banking},
pages = {35--55},
title = {{Measuring the information content of the beige book: a mixed data sampling approach}},
volume = {41},
year = {2009}
}
@article{Lymburn:2019,
abstract = {We employ reservoir computing for a reconstruction task in coupled chaotic systems, across a range of dynamical relationships including generalized synchronization. For a drive-response setup, a temporal representation of the synchronized state is discussed as an alternative to the known instantaneous form. The reservoir has access to both representations through its fading memory property, each with advantages in different dynamical regimes. We also extract signatures of the maximal conditional Lyapunov exponent in the performance of variations of the reservoir topology. Moreover, the reservoir model reproduces different levels of consistency where there is no synchronization. In a bidirectional coupling setup, high reconstruction accuracy is achieved despite poor observability and independent of generalized synchronization.},
author = {Lymburn, Thomas and Walker, David M. and Small, Michael and J{\"{u}}ngling, Thomas},
doi = {10.1063/1.5120733},
issn = {10541500},
journal = {Chaos},
number = {093133},
pmid = {31575144},
title = {{The reservoir's perspective on generalized synchronization}},
volume = {29},
year = {2019}
}
@book{Sutton1998,
address = {Cambridge, MA},
author = {Sutton, R.S. and Barto, A.G.},
publisher = {MIT Press},
title = {{Reinforcement Learning}},
year = {1998}
}
@article{stefanb,
author = {Stefan, Peter},
journal = {Proceedings of the London Mathematical Society},
number = {4},
pages = {699--713},
title = {{Accessible sets, orbits, and foliations with singularities}},
volume = {3},
year = {1974}
}
@article{Bertholon2008,
author = {Bertholon, H. and Monfort, Alain and Pegoraro, Fulvio},
journal = {Journal of Financial Econometrics},
number = {4},
pages = {407--458},
title = {{Econometric asset pricing modeling}},
volume = {6},
year = {2008}
}
@unpublished{Wu2016a,
author = {Wu, Yonghui and Schuster, Mike and Chen, Zhifeng and Le, Quoc V. and Norouzi, Mohammad},
title = {{Google's neural machine translation system: Bridging the gap between human and machine translation}},
year = {2016}
}
@article{networksSpiking,
abstract = {The computational power of formal models for networks of spiking neurons is compared with that of other neural network models based on McCulloch Pitts neurons (i.e., threshold gates), respectively, sigmoidal gates. In particular it is shown that networks of spiking neurons are, with regard to the number of neurons that are needed, computationally more powerful than these other neural network models. A concrete biologically relevant function is exhibited which can be computed by a single spiking neuron (for biologically reasonable values of its parameters), but which requires hundreds of hidden units on a sigmoidal neural net. On the other hand, it is known that any function that can be computed by a small sigmoidal neural net can also be computed by a small network of spiking neurons. This article does not assume prior knowledge about spiking neurons, and it contains an extensive list of references to the currently available literature on computations in networks of spiking neurons and relevant results from neurobiology.},
author = {Maass, Wolfgang},
doi = {10.1016/S0893-6080(97)00011-7},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Maass - 1997 - Networks of spiking neurons The third generation of neural network models.pdf:pdf},
isbn = {08936080},
issn = {08936080},
journal = {Neural Networks},
keywords = {Computational complexity,Integrate-and-fire neutron,Lower bounds,Sigmoidal neural nets,Spiking neuron},
number = {9},
pages = {1659--1671},
title = {{Networks of spiking neurons: The third generation of neural network models}},
volume = {10},
year = {1997}
}
@book{Dedecker2007a,
author = {Dedecker, J. and Doukhan, P. and Lang, G. and Le{\'{o}}n, J. R. and Louhichi, S. and Prieur, C.},
publisher = {Springer Science+Business Media},
title = {{Weak Dependence: With Examples and Applications}},
year = {2007}
}
@article{Deihimi2013,
abstract = {In this paper, WESN (wavelet echo state network) with a novel ESN-based reconstruction stage is applied to both STLF (short-term load forecasting) and STTF (short-term temperature forecasting). Wavelet transform is used as the front stage for multi-resolution decomposition of load or temperature time series. ESNs function as forecasters for decomposed components. A modified shuffled frog leaping algorithm is used for optimizing ESNs. Both one-hour and 24-h ahead predictions are studied where the number of inputs are kept minimum. The performance of the proposed WESN-based load forecasters are investigated for three cases as the predicted temperature input is fed by actual temperatures, output of the WESN-based temperature forecasters and noisy temperatures. Effects of temperature errors on load forecasts are studied locally by sensitivity analysis. Hourly loads and temperatures of a North-American electric utility are used for this study. First, results of the proposed forecasters are compared with those of ESN-based forecasters that have previously shown high capability as stand-alone forecasters. Next, the WESN-based forecasters are compared with other models either previously tested on the data used here or to be rebuilt for testing on these data. Comparisons reveal significant improvements on accuracy of both STLF and STTF using the proposed forecasters.},
author = {Deihimi, Ali and Orang, Omid and Showkati, Hemen},
doi = {10.1016/j.energy.2013.06.007},
issn = {03605442},
journal = {Energy},
pages = {382--401},
title = {{Short-term electric load and temperature forecasting using wavelet echo state networks with neural reconstruction}},
volume = {57},
year = {2013}
}
@inproceedings{Ioffe2015,
author = {Ioffe, Sergey and Szegedy, Christian},
booktitle = {Proceedings of the 32nd International Conference on Machine Learning},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Ioffe, Szegedy - 2015 - Batch Normalization Accelerating Deep Network Training by Reducing Internal Covariate Shift.pdf:pdf},
pages = {448--456},
title = {{Batch normalization: Accelerating deep network training by reducing internal covariate shift}},
year = {2015}
}
@article{Kunst2008,
author = {Kunst, Robert M},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Kunst - 2008 - Cross Validation of Prediction Models for Seasonal Time Series by Parametric Bootstrapping 1 Introduction.pdf:pdf},
journal = {Austrian Journal of Statistics},
number = {3{\&}4},
pages = {271--284},
title = {{Cross Validation of Prediction Models for Seasonal Time Series by Parametric Bootstrapping 1 Introduction}},
volume = {37},
year = {2008}
}
@article{Angelini2011,
abstract = {Summary This paper evaluates models that exploit timely monthly releases to compute early estimates of current quarter GDP (now-casting) in the euro area. We compare traditional methods used at institutions with a new method proposed by Giannone et al. The method consists in bridging quarterly GDP with monthly data via a regression on factors extracted from a large panel of monthly series with different publication lags. We show that bridging via factors produces more accurate estimates than traditional bridge equations. We also show that survey data and other ‘soft' information are valuable for now-casting.},
author = {Angelini, Elena and Camba-Mendez, Gonzalo and Giannone, Domenico and Reichlin, Lucrezia and R{\"{u}}nstler, Gerhard},
issn = {1368-423X},
journal = {The Econometrics Journal},
keywords = {Factor model,Forecasting,Large data sets,Monetary policy,News,Real-time data},
number = {1},
pages = {C25----C44},
publisher = {Blackwell Publishing Ltd},
title = {{Short-term forecasts of euro area GDP growth}},
url = {http://dx.doi.org/10.1111/j.1368-423X.2010.00328.x},
volume = {14},
year = {2011}
}
@article{KLIC_1951,
author = {Kullback, L. and Leibler, R. A.},
journal = {Annals of Mathematical Statistics},
pages = {79--86},
title = {{On information and sufficiency}},
volume = {22},
year = {1951}
}
@article{Shwartz:Ziv2017b,
abstract = {Despite their great success, there is still no comprehensive theoretical understanding of learning with Deep Neural Networks (DNNs) or their inner organization. Previous work proposed to analyze DNNs in the $\backslash$textit{\{}Information Plane{\}}; i.e., the plane of the Mutual Information values that each layer preserves on the input and output variables. They suggested that the goal of the network is to optimize the Information Bottleneck (IB) tradeoff between compression and prediction, successively, for each layer. In this work we follow up on this idea and demonstrate the effectiveness of the Information-Plane visualization of DNNs. Our main results are: (i) most of the training epochs in standard DL are spent on {\{}$\backslash$emph compression{\}} of the input to efficient representation and not on fitting the training labels. (ii) The representation compression phase begins when the training errors becomes small and the Stochastic Gradient Decent (SGD) epochs change from a fast drift to smaller training error into a stochastic relaxation, or random diffusion, constrained by the training error value. (iii) The converged layers lie on or very close to the Information Bottleneck (IB) theoretical bound, and the maps from the input to any hidden layer and from this hidden layer to the output satisfy the IB self-consistent equations. This generalization through noise mechanism is unique to Deep Neural Networks and absent in one layer networks. (iv) The training time is dramatically reduced when adding more hidden layers. Thus the main advantage of the hidden layers is computational. This can be explained by the reduced relaxation time, as this it scales super-linearly (exponentially for simple diffusion) with the information compression from the previous layer.},
archivePrefix = {arXiv},
arxivId = {1703.00810},
author = {Shwartz-Ziv, Ravid and Tishby, Naftali},
eprint = {1703.00810},
month = {mar},
title = {{Opening the black box of deep neural networks via information}},
url = {http://arxiv.org/abs/1703.00810},
year = {2017}
}
@article{Ernst1995,
author = {Ernst, U. and Pawelzik, K. and Geisel, T.},
journal = {Phys. Rev. Lett.},
pages = {1570},
title = {{Synchronization induced by temporal delays in pulse-coupled oscillator}},
volume = {27},
year = {1995}
}
@article{ChevKor:2016,
abstract = {In these notes, we wish to provide an introduction to the signature method, focusing on its basic theoretical properties and recent numerical applications. The notes are split into two parts. The first part focuses on the definition and fundamental properties of the signature of a path, or the path signature. We have aimed for a minimalistic approach, assuming only familiarity with classical real analysis and integration theory, and supplementing theory with straightforward examples. We have chosen to focus in detail on the principle properties of the signature which we believe are fundamental to understanding its role in applications. We also present an informal discussion on some of its deeper properties and briefly mention the role of the signature in rough paths theory, which we hope could serve as a light introduction to rough paths for the interested reader. The second part of these notes discusses practical applications of the path signature to the area of machine learning. The signature approach represents a non-parametric way for extraction of characteristic features from data. The data are converted into a multi-dimensional path by means of various embedding algorithms and then processed for computation of individual terms of the signature which summarise certain information contained in the data. The signature thus transforms raw data into a set of features which are used in machine learning tasks. We will review current progress in applications of signatures to machine learning problems.},
archivePrefix = {arXiv},
arxivId = {1603.03788},
author = {Chevyrev, Ilya and Kormilitzin, Andrey},
eprint = {1603.03788},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Chevyrev, Kormilitzin - 2016 - A Primer on the Signature Method in Machine Learning(2).pdf:pdf},
journal = {Preprint},
title = {{A Primer on the Signature Method in Machine Learning}},
year = {2016}
}
@article{LaFleur2013,
abstract = {OBJECTIVE: At the balanced intersection of human and machine adaptation is found the optimally functioning brain-computer interface (BCI). In this study, we report a novel experiment of BCI controlling a robotic quadcopter in three-dimensional (3D) physical space using noninvasive scalp electroencephalogram (EEG) in human subjects. We then quantify the performance of this system using metrics suitable for asynchronous BCI. Lastly, we examine the impact that the operation of a real world device has on subjects' control in comparison to a 2D virtual cursor task.

APPROACH: Five human subjects were trained to modulate their sensorimotor rhythms to control an AR Drone navigating a 3D physical space. Visual feedback was provided via a forward facing camera on the hull of the drone.

MAIN RESULTS: Individual subjects were able to accurately acquire up to 90.5{\%} of all valid targets presented while travelling at an average straight-line speed of 0.69 m s(-1).

SIGNIFICANCE: Freely exploring and interacting with the world around us is a crucial element of autonomy that is lost in the context of neurodegenerative disease. Brain-computer interfaces are systems that aim to restore or enhance a user's ability to interact with the environment via a computer and through the use of only thought. We demonstrate for the first time the ability to control a flying robot in 3D physical space using noninvasive scalp recorded EEG in humans. Our work indicates the potential of noninvasive EEG-based BCI systems for accomplish complex control in 3D physical space. The present study may serve as a framework for the investigation of multidimensional noninvasive BCI control in a physical environment using telepresence robotics.},
author = {LaFleur, Karl and Cassady, Kaitlin and Doud, Alexander and Shades, Kaleb and Rogin, Eitan and He, Bin},
issn = {1741-2552},
journal = {Journal of neural engineering},
month = {aug},
number = {4},
pages = {046003},
title = {{Quadcopter control in three-dimensional space using a noninvasive motor imagery-based brain-computer interface.}},
url = {http://stacks.iop.org/1741-2552/10/i=4/a=046003},
volume = {10},
year = {2013}
}
@article{baer,
author = {Baer, A.},
journal = {J. Reine Angew. Math.},
pages = {199--207},
title = {{Zur Einf{\"{u}}hrung des Scharbegriffs}},
volume = {160},
year = {1929}
}
@article{Zhao2005,
author = {Zhao, Yinshan and Joe, Harry},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Zhao, Joe - 2005 - Composite likelihood estimation in multivariate data analysis.pdf:pdf},
issn = {03195724},
journal = {Canadian Journal of Statistics},
month = {sep},
number = {3},
pages = {335--356},
title = {{Composite likelihood estimation in multivariate data analysis}},
url = {http://doi.wiley.com/10.1002/cjs.5540330303},
volume = {33},
year = {2005}
}
@article{Diblik2012_1,
annote = {Article ID 219040},
author = {Dibl{\'{i}}k, Josef and Khusainov, Denis and Kukharenko, Oleksandra and Svoboda, Zden{\v{e}}k},
doi = {10.1155/2012/219040},
journal = {Abstract and Applied Analysis},
title = {{Solution of the first boundary-value problem for a system of autonomous second-order linear partial differential equations of parabolic type with a single delay}},
volume = {2012},
year = {2012}
}
@article{MR2301768,
author = {{\v{C}}ern{\'{y}}, Ale{\v{s}}},
doi = {10.1111/j.1467-9965.2007.00299.x},
issn = {0960-1627},
journal = {Math. Finance},
number = {2},
pages = {175--203},
title = {{Optimal continuous-time hedging with leptokurtic returns}},
url = {http://dx.doi.org/10.1111/j.1467-9965.2007.00299.x},
volume = {17},
year = {2007}
}
@book{bredon,
author = {Bredon, G. E.},
publisher = {Academic Press},
title = {{Introduction to Compact Transformation Groups}},
year = {1972}
}
@book{Marsden2007,
address = {Berlin},
author = {Marsden, Jerrold E. and Misiolek, Gerard and Ortega, Juan-Pablo and Perlmutter, Matthew and Ratiu, Tudor S.},
pages = {xvi+524},
publisher = {Springer-Verlag},
title = {{Hamiltonian reduction by stages}},
year = {2007}
}
@book{camacho:neto,
author = {Camacho, C. and {Lins Neto}, A.},
publisher = {Birkh{\"{a}}user},
title = {{Geometric Theory of Foliations}},
year = {1985}
}
@article{Bloch:Toda,
author = {Bloch, A.},
journal = {Physica D},
number = {3-4},
pages = {297--315},
title = {{Asymptotic Hamiltonian dynamics: the Toda lattice, the three-wave interaction and the non-holonomic Chaplygin sleigh}},
volume = {141},
year = {2000}
}
@article{Roch2018,
author = {Roch, Alexandre F.},
journal = {Mathematics and Financial Economics},
pages = {275--304},
title = {{Asymptotic asset pricing and bubbles}},
volume = {12},
year = {2018}
}
@article{KarelaiaHogarth2008,
abstract = {The mathematical representation of E. Brunswik's (1952) lens model has been used extensively to study human judgment and provides a unique opportunity to conduct a meta-analysis of studies that covers roughly 5 decades. Specifically, the authors analyzed statistics of the "lens model equation" (L. R. Tucker, 1964) associated with 249 different task environments obtained from 86 articles. On average, fairly high levels of judgmental achievement were found, and people were seen to be capable of achieving similar levels of cognitive performance in noisy and predictable environments. Further, the effects of task characteristics that influence judgment (numbers and types of cues, inter-cue redundancy, function forms and cue weights in the ecology, laboratory versus field studies, and experience with the task) were identified and estimated. A detailed analysis of learning studies revealed that the most effective form of feedback was information about the task. The authors also analyzed empirically under what conditions the application of bootstrapping--or replacing judges by their linear models--is advantageous. Finally, the authors note shortcomings of the kinds of studies conducted to date, limitations in the lens model methodology, and possibilities for future research.},
author = {Karelaia, Natalia and Hogarth, Robin M},
doi = {10.1037/0033-2909.134.3.404},
isbn = {0033-2909},
issn = {0033-2909},
journal = {Psychological Bulletin},
keywords = {0033-2909,10,1037,134,1952,1955,3,404,Linsenmodell,Metaanalyse,bootstrapping,conceptual framework of brunswik,doi,dx,hammond,http,in a seminal contribution,judgmental accuracy,learning,lens model,lens model to study,linear models,numerische Sch{\"{a}}tzungen,numerische Sch�tzungen,org,s,suggested using the,supp,supplemental material},
number = {3},
pages = {404--426},
pmid = {18444703},
title = {{Determinants of linear judgment: A meta-analysis of lens model studies}},
volume = {134},
year = {2008}
}
@unpublished{Klos2019,
author = {Klos, Christian and {Kalle Kossio}, Yasloslav Felipe and Goedeke, Sven and Gilra, Aditya and Memmesheimer, Raoul-Martin},
title = {{Dynamical learning of dynamics}},
year = {2019}
}
@book{Adams:Fournier,
author = {Adams, Robert A. and Fournier, John J.F.},
edition = {Second},
isbn = {0120441438},
pages = {305},
publisher = {Academic Press},
title = {{Sobolev Spaces}}
}
@article{Jaeger04,
author = {Jaeger, Herbert and Haas, Harald},
doi = {10.1126/science.1091277},
journal = {Science},
number = {5667},
pages = {78--80},
title = {{Harnessing Nonlinearity: Predicting Chaotic Systems and Saving Energy in Wireless Communication}},
volume = {304},
year = {2004}
}
@book{roy1957,
address = {New York},
author = {Roy, S.N.},
publisher = {John Wiley {\&} Sons},
title = {{Some Aspects of Multivariate Analysis}},
year = {1957}
}
@article{Grubbs1950,
author = {Grubbs, Frank E.},
issn = {2168-8990},
journal = {The Annals of Mathematical Statistics},
language = {EN},
month = {mar},
number = {1},
pages = {27--58},
publisher = {Institute of Mathematical Statistics},
title = {{Sample Criteria for Testing Outlying Observations}},
url = {http://projecteuclid.org/euclid.aoms/1177729885},
volume = {21},
year = {1950}
}
@unpublished{Oreshkin2020,
author = {Oreshkin, Boris N. and Carpov, Dmitri and Chapados, Nicolas and Bengio, Yoshua},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Oreshkin et al. - 2020 - Meta-learning framework with applications to zero-shot time-series forecasting.pdf:pdf},
title = {{Meta-learning framework with applications to zero-shot time-series forecasting}},
year = {2020}
}
@article{duan:ems2,
author = {Duan, Jin-Chuan and Gauthier, Genevi{\`{e}}ve and Simonato, Jean-Guy},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Duan, Gauthier, Simonato - 2001 - Asymptotic distribution of the EMS option price estimator.pdf:pdf},
journal = {Mgmt. Sci.},
number = {8},
pages = {1122--1132},
title = {{Asymptotic distribution of the EMS option price estimator}},
volume = {47},
year = {2001}
}
@book{Merkin:stability,
address = {New York, NY},
author = {Merkin, David R.},
pages = {319},
publisher = {Springer-Verlag},
title = {{Introduction to the Theory of Stability}},
year = {1997}
}
@techreport{Foroni2011,
author = {Foroni, Claudia and Marcellino, Massimiliano},
institution = {EUI},
keywords = {MIDAS,factor models,forecsting,mixed-frequency VAR,mixed-frequency data,nowcsting},
series = {Department of Economics},
title = {{A comparison of mixed approaches for modelling euro area macroeconomic variables}},
year = {2011}
}
@inproceedings{goudarzi:2015,
author = {B{\"{u}}rger, Jens and Goudarzi, Alireza and Stefanovic, Darko and Teuscher, Christof},
booktitle = {2015 IEEE/ACM International Symposium on Nanoscale Architectures (NANOARCH)},
isbn = {9781467378499},
pages = {33--38},
title = {{Hierarchical composition of memristive networks for real-time computing}},
year = {2015}
}
@article{Geiger2016,
author = {Geiger, Philipp and Dellago, Christoph},
doi = {http://dx.doi.org/10.1063/1.4825111},
journal = {The Journal of Chemical Physics},
number = {16},
title = {{Neural networks for local structure detection in polymorphic systems}},
url = {http://scitation.aip.org/content/aip/journal/jcp/139/16/10.1063/1.4825111},
volume = {139},
year = {2013}
}
@article{Christoffersen2008,
abstract = {This paper presents a new model for the valuation of European options, in which the volatility of returns consists of two components. One is a long-run component and can be modeled as fully persistent. The other is short-run and has a zero mean. Our model can be viewed as an affine version of Engle and Lee [1999. A permanent and transitory component model of stock return volatility. In: Engle, R., White, H. (Eds.), Cointegration, Causality, and Forecasting: A Festschrift in Honor of Clive W.J. Granger. Oxford University Press, New York, pp. 475–497], allowing for easy valuation of European options. The model substantially outperforms a benchmark single-component volatility model that is well established in the literature, and it fits options better than a model that combines conditional heteroskedasticity and Poisson–normal jumps. The component model's superior performance is partly due to its improved ability to model the smirk and the path of spot volatility, but its most distinctive feature is its ability to model the volatility term structure. This feature enables the component model to jointly model long-maturity and short-maturity options.},
author = {Christoffersen, Peter F. and Jacobs, Kris and Ornthanalai, Chayawat and Wang, Yintian},
doi = {10.1016/j.jfineco.2007.12.003},
issn = {0304405X},
journal = {Journal of Financial Economics},
keywords = {G12,GARCH,Out-of-sample,Volatility term structure},
month = {dec},
number = {3},
pages = {272--297},
title = {{Option valuation with long-run and short-run volatility components☆}},
url = {http://www.sciencedirect.com/science/article/pii/S0304405X0800144X},
volume = {90},
year = {2008}
}
@article{ljung:box:test,
author = {Ljung, Greta M and Box, George E P},
journal = {Biometrika},
pages = {297--303},
title = {{On a measure of lack of fit in time series models}},
volume = {65},
year = {1978}
}
@techreport{esser,
author = {Esser, E},
institution = {UCLA CAM},
title = {{Applications of Lagrangian-based alternating direction methods and connections to split Bregman}},
type = {Statistics and Econometrics Series},
year = {2009}
}
@article{sandberg:zplus,
abstract = {Much is known about time-invariant nonlinear systems with inputs and$\backslash$noutputs defined on R+ that possess approximately finite memory. For$\backslash$nexample, under mild additional conditions, they can be approximated$\backslash$narbitrarily well by the maps of certain interesting simple structures.$\backslash$nAn important fact that gives meaning to results concerning such systems$\backslash$nis that the approximately finite memory condition is known to be$\backslash$noften met. Here we consider the known proposition that if a causal$\backslash$ntime-invariant continuous-time input-output map H has fading memory$\backslash$non a certain set of bounded functions defined on all of R, then H$\backslash$ncan be approximated arbitrarily well by a finite Volterra series$\backslash$noperator. We show that in a certain sense, involving the existence$\backslash$nof extensions of system maps, this result too has wide applicability.},
author = {Sandberg, Irwin W.},
doi = {10.1109/TCSI.2002.804547},
issn = {10577122},
journal = {International Journal of Circuit Theory and Applications},
keywords = {Approximately finite memory,Fading memory,Input-output maps,Nonlinear systems},
number = {11},
pages = {381--388},
title = {{Z+ fading memory and extensions of input-output maps}},
volume = {29},
year = {2001}
}
@article{Goldfine2013a,
author = {Goldfine, Andrew M. and Bardin, Jonathan C. and Noirhomme, Quentin and Fins, Joseph and Schiff, Nicholas D. and Victor, Jonathan D.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Goldfine et al. - 2013 - Reanalysis of “Bedside detection of awareness in the vegetative state a cohort study”.pdf:pdf;:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Goldfine et al. - 2013 - Webappendix for Reanalysis of “Bedside detection of awareness in the vegetative state a cohort study.”.pdf:pdf},
journal = {The Lancet. Correspondance},
pages = {289--291},
title = {{Webappendix for Reanalysis of “Bedside detection of awareness in the vegetative state: a cohort study.”}},
volume = {381},
year = {2013}
}
@article{Boussama2011,
abstract = {Conditions for the existence of strictly stationary multivariate GARCH processes in the so-called BEKK parametrisation, which is the most general form of multivariate GARCH processes typically used in applications, and for their geometric ergodicity are obtained. The conditions are that the driving noise is absolutely continuous with respect to the Lebesgue measure and zero is in the interior of its support and that a certain matrix built from the GARCH coefficients has spectral radius smaller than one. To establish the results, semi-polynomial Markov chains are defined and analysed using algebraic geometry.},
author = {Boussama, Farid and Fuchs, Florian and Stelzer, Robert},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Boussama, Fuchs, Stelzer - 2011 - Stationarity and geometric ergodicity of BEKK multivariate GARCH models.pdf:pdf},
journal = {Stochastic Processes and their Applications},
keywords = {60B99,60J05,62M10,91G70,Foster–Lyapunov drift condition,Geometric ergodicity,Harris recurrence,Multivariate GARCH,Stationarity,Stochastic volatility,primary,secondary,$\beta$-mixing},
number = {10},
pages = {2331--2360},
title = {{Stationarity and geometric ergodicity of BEKK multivariate GARCH models}},
url = {http://www.sciencedirect.com/science/article/pii/S0304414911001372},
volume = {121},
year = {2011}
}
@article{sl,
author = {Sjamaar, R. and Lerman, E.},
journal = {Annals of Mathematics},
pages = {375--422},
title = {{Stratified symplectic spaces and reduction}},
volume = {134},
year = {1991}
}
@article{Hassler2006,
author = {Hassler, Uwe and Wolters, J{\"{u}}rgen},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Hassler, Wolters - 2006 - Autoregressive distributed lag models and cointegration.pdf:pdf},
issn = {0002-6018},
journal = {Allgemeines Statistisches Archiv},
keywords = {asymptotically normal inference,cointegration testing,error-correction},
month = {mar},
number = {1},
pages = {59--74},
title = {{Autoregressive distributed lag models and cointegration}},
url = {http://www.springerlink.com/index/10.1007/s10182-006-0221-5},
volume = {90},
year = {2006}
}
@article{BalzazarSuperTuring,
author = {Balcazar, J.L. and Gavalda, R. and Siegelmann, Hava T.},
journal = {IEEE Transactions on Information Theory},
number = {4},
pages = {1175--1183},
title = {{Computational power of neural networks: a characterization in terms of Kolmogorov complexity}},
volume = {43},
year = {1997}
}
@article{hornik1991,
abstract = {--We show that standard multilayer feedfbrward networks with as few as a single hidden layer and arbitrary bounded and nonconstant activation function are universal approximators with respect to LP(lt) per-formance criteria, for arbitrary finite input environment measures p, provided only that sufficiently many hidden units are available. If the activation function is continuous, bounded and nonconstant, then continuous mappings can be learned uniformly over compact input sets. We also give very general conditions ensuring that networks with sufficiently smooth activation functions are capable of arbitrarily accurate approximation to a{\_}Function and its derivatives.},
author = {Hornik, Kurt},
doi = {10.1016/0893-6080(91)90009-T},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Hornik - 1991 - Approximation capabilities of muitilayer feedforward networks(2).pdf:pdf},
journal = {Neural Networks},
keywords = {--multilayer feedforward networks,1,activation function,approximation,d,distance between functions,environment measure,i n t r,input,measured by the uniform,o d u c,p,smooth approximation,sobolev spaces,t i o n,uniform approximation,universal approximation capabilities},
number = {1989},
pages = {251--257},
title = {{Approximation capabilities of muitilayer feedforward networks}},
volume = {4},
year = {1991}
}
@article{Oh2002,
abstract = {Trading in stock market indices has gained unprecedented popularity in major financial markets around the world. However, the prediction of stock price index is a very difficult problem because of the complexity of the stock market data. This study proposes stock trading model based on chaotic analysis and piecewise nonlinear model. The core component of the model is composed of four phases: The first phase determines time-lag size in input variables using chaotic analysis. The second phase detects successive change-points in the stock market data and the third phase forecasts the change-point group with backpropagation neural networks (BPNs). The final phase forecasts the output with BPN. The experimental results are encouraging and show the usefulness of the proposed model with respect to profitability.},
author = {Oh, Kyong Joo and Kim, Kyoung-jae},
doi = {10.1016/S0957-4174(01)00058-6},
issn = {09574174},
journal = {Expert Systems with Applications},
number = {3},
pages = {249--255},
title = {{Analyzing stock market tick data using piecewise nonlinear model}},
volume = {22},
year = {2002}
}
@techreport{huke:2006,
abstract = {The embedding theorem of Takens forms a birdge between the theory of nonlinear dynamical systems and the analysis of experimental time series. This memorandum describes the theorem, and gives a detailed account of its proof. The necessary differential topology is briefly reviewed, and then a proof of the theorem is presented; this proof follows broadly the argument of takens, although it differs in some details. Some extensions to the theorem, which facilitate its use in applications, are described. The memo concludes with a brief discussion of what the theorem implies about time series, viewed as the raw material for signal processing algorithms.},
author = {Huke, Jeremy P.},
institution = {Manchester Institute for Mathematical Sciences. The University of Manchester},
issn = {1749-9097},
title = {{Embedding nonlinear dynamical systems: a guide to Takens' theorem}},
year = {2006}
}
@article{Shephard2010,
author = {Shephard, Neil and Sheppard, Kevin},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Shephard, Sheppard - 2010 - Realising the future forecasting with high-frequency-based volatility (HEAVY) models.pdf:pdf},
issn = {08837252},
journal = {Journal of Applied Econometrics},
month = {mar},
number = {2},
pages = {197--231},
title = {{Realising the future: forecasting with high-frequency-based volatility (HEAVY) models}},
url = {http://doi.wiley.com/10.1002/jae.1158},
volume = {25},
year = {2010}
}
@article{Corradi2000,
abstract = {In this note we reconsider the continuoustimelimit of the GARCH(1, 1) process. Let Yk and k2 denote, respectively, the cumulative returns and the volatility processes. We consider the continuoustime approximation of the couple ￼ We show that, by choosing different parameterizations, as a function of the discrete interval h, we can obtain either a degenerate or a non-degenerate diffusion limit. We then show that GARCH(1, 1) processes can be obtained as Euler approximations of degenerate diffusions, while any Euler approximation of a non-degenerate diffusion is a stochastic volatility process.},
author = {Corradi, Valentina},
doi = {10.1016/S0304-4076(99)00053-6},
issn = {03044076},
journal = {Journal of Econometrics},
keywords = {degenerate diffusions,diffusion approximation,garch},
month = {may},
number = {1},
pages = {145--153},
title = {{Reconsidering the continuous time limit of the GARCH(1,1) process}},
url = {http://dx.doi.org/10.1016/S0304-4076(99)00053-6},
volume = {96},
year = {2000}
}
@article{Hamilton1996,
author = {Hamilton, James D. and Lin, Gang},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Hamilton, Lin - 1996 - Stock market volatility and the business cycle.pdf:pdf},
issn = {08837252},
journal = {Journal of Applied Econometrics},
month = {sep},
number = {5},
pages = {573--593},
title = {{Stock market volatility and the business cycle}},
url = {http://doi.wiley.com/10.1002/(SICI)1099-1255(199609)11:5{\%}3C573::AID-JAE413{\%}3E3.0.CO;2-T},
volume = {11},
year = {1996}
}
@article{Steinwart2012,
author = {Steinwart, Ingo and Scovel, Clint},
journal = {Constructive Approximation},
number = {3},
pages = {363--417},
title = {{Mercer's theorem on general domains: on the interaction between measures, kernels, and RKHSs}},
volume = {35},
year = {2012}
}
@book{Arbib1987,
author = {Arbib, Michael A.},
booktitle = {Brains, Machines, and Mathematics},
doi = {10.1007/978-1-4612-4782-1},
publisher = {Springer US},
title = {{Brains, Machines, and Mathematics}},
year = {1987}
}
@article{Verzelli2019,
author = {Verzelli, Pietro and Alippi, Cesare and Livi, Lorenzo},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Verzelli, Alippi, Livi - 2019 - Echo State Networks with self-normalizing activations on the hyper-sphere.pdf:pdf},
journal = {Scientific Reports},
number = {13887},
title = {{Echo State Networks with self-normalizing activations on the hyper-sphere}},
volume = {9},
year = {2019}
}
@article{Jackel2015,
author = {J{\"{a}}ckel, Peter},
journal = {Wilmott},
pages = {40--53},
title = {{Let's be rational}},
volume = {75},
year = {2015}
}
@article{fastica,
author = {Hyv{\"{a}}rinen, A and Oja, E},
journal = {Neural Computation},
pages = {1483--1492},
title = {{A fast fixed-point algorithm for independent component analysis}},
volume = {9},
year = {1997}
}
@article{GO1,
author = {Grigoryeva, Lyudmila and Ortega, Juan-Pablo},
journal = {Journal of Forecasting},
pages = {577--595},
title = {{Hybrid forecasting with estimated temporally aggregated linear processes}},
url = {http://papers.ssrn.com/sol3/papers.cfm?abstract{\_}id=2148895},
volume = {33},
year = {2014}
}
@article{Manjunath:Jaeger,
abstract = {The echo state property is a key for the design and training of recur-rent neural networks within the paradigm of reservoir computing. In intuitive terms this is a passivity condition: a network having this property, when driven by an input signal, will become entrained by the input and develop an internal response signal. This excited internal dynamics can be seen as a high-dimensional, nonlinear, unique transform of the input with a rich mem-ory content. This view has implications for understanding neural dynamics beyond the field of reservoir computing. Available definitions and theorems concerning the echo state property, however, are of little practical use because they do not relate the network response to temporal or statistical properties of the driving input. Here we present a new definition of the echo state property which directly connects it to such properties. We derive a fundamental 0-1 law: if the input comes from an ergodic source, the network response has the echo state property with probability one or zero, independent of the given net-work. Furthermore we give a sufficient condition for the echo state property which connects statistical characteristics of the input to algebraic properties of the network connection matrix. The mathematical methods that we em-ploy are freshly imported from the young field of nonautonomous dynamical systems theory. Since these methods are not yet well known in neural compu-tation research, we introduce them in some detail. As a side story, we hope to demonstrate the eminent usefulness of these methods.},
archivePrefix = {arXiv},
arxivId = {1309.2848v1},
author = {Manjunath, G. and Jaeger, H.},
doi = {10.1162/NECO_a_00411},
eprint = {1309.2848v1},
isbn = {9781467312264},
issn = {0899-7667},
journal = {Neural Computation},
number = {3},
pages = {671--696},
pmid = {23272918},
title = {{Echo state property linked to an input: exploring a fundamental characteristic of recurrent neural networks}},
volume = {25},
year = {2013}
}
@article{Renard2004,
abstract = {A pairwise likelihood (PL) estimation procedure is examined in multilevel models with binary responses and probit link. The PL is obtained as the product of bivariate likelihoods for within-cluster pairs of observations. The resulting estimator still enjoys desirable asymptotic properties such as consistency and asymptotic normality. Therefore, with this approach a compromise between computational burden and loss of efficiency is sought. A simulation study was conducted to compare PL with second-order penalized quasi-likelihood (PQL2) and maximum (marginal) likelihood (ML) estimation methods. The loss of efficiency of the PL estimator is found to be generally moderate. Also, PL tends to show more robustness against convergence problems than PQL2.},
author = {Renard, Didier and Molenberghs, Geert and Geys, Helena},
doi = {10.1016/S0167-9473(02)00263-3},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Renard, Molenberghs, Geys - 2004 - A pairwise likelihood approach to estimation in multilevel probit models.pdf:pdf},
issn = {01679473},
journal = {Computational Statistics {\&} Data Analysis},
keywords = {Binary response data,Composite likelihood,Maximum marginal likelihood,Multilevel modeling,Pairwise likelihood,Penalized Quasi-Likelihood},
month = {jan},
number = {4},
pages = {649--667},
title = {{A pairwise likelihood approach to estimation in multilevel probit models}},
url = {http://www.sciencedirect.com/science/article/pii/S0167947302002633},
volume = {44},
year = {2004}
}
@article{adya:1998,
author = {Adya, Monica and Collopy, Fred},
journal = {Journal of Forecasting},
pages = {481--495},
title = {{How effective are neural networks at forecasting and prediction? A review and evaluation}},
volume = {17},
year = {1998}
}
@article{lrsm,
author = {Lewis, D. and Ratiu, T. S. and Simo, J. C. and Marsden, J. E.},
journal = {Nonlinearity},
pages = {1--48},
title = {{The heavy top: a geometric treatment}},
volume = {5},
year = {1992}
}
@article{carroll2018using,
author = {Carroll, Thomas L},
journal = {Physical Review E},
number = {5},
pages = {52209},
publisher = {APS},
title = {{Using reservoir computers to distinguish chaotic signals}},
volume = {98},
year = {2018}
}
@article{weed2019sharp,
author = {Weed, Jonathan and Bach, Francis},
journal = {Bernoulli},
number = {4A},
pages = {2620--2648},
publisher = {Bernoulli Society for Mathematical Statistics and Probability},
title = {{Sharp asymptotic and finite-sample rates of convergence of empirical measures in Wasserstein distance}},
volume = {25},
year = {2019}
}
@article{Badescu08b,
author = {Badescu, Alexandru M. and Kulperger, Reg J. and Lazar, E.},
journal = {Studies in Nonlinear Dynamics and Econometrics},
number = {2},
pages = {Article 5},
title = {{Option valuation with Normal Mixture GARCH models}},
url = {http://www.degruyter.com/view/j/snde.2008.12.2/snde.2008.12.2.1580/snde.2008.12.2.1580.xml},
volume = {12},
year = {2008}
}
@article{cicogna:81,
author = {Cicogna, G.},
journal = {Lettere al Nuovo Cimento},
pages = {600--602},
title = {{Symmetry breakdown from bifurcations}},
volume = {31},
year = {1981}
}
@article{AS1996,
abstract = {Different continuous-time models for interest rates coexist in the literature. We test parametric models by comparing their implied parametric density to the same density estimated nonparametrically. We do not replace the continuous-time model by discrete approximations, even though the data are recorded at discrete intervals. The principal source of rejection of existing models is the strong non-linearity of the drift. Around its mean, where the drift is essentially zero, the spot rate behaves like a random walk. The drift then mean-reverts strongly when far away from the mean. The volatility is higher when away from the mean.},
author = {A{\"{i}}t-Sahalia, Y.},
issn = {0893-9454},
journal = {Review of Financial Studies},
month = {apr},
number = {2},
pages = {385--426},
title = {{Testing continuous-time models of the spot interest rate}},
url = {http://rfs.oxfordjournals.org/content/9/2/385.short},
volume = {9},
year = {1996}
}
@article{ChoIo1,
author = {Chossat, P. and Iooss, G.},
journal = {Japan J. Appl. Math.},
pages = {37--68},
title = {{Primary and secondary bifurcations in the Couette-Taylor problem}},
volume = {2},
year = {1985}
}
@book{blaom:dual:pairs,
author = {Blaom, A},
booktitle = {Memoirs of the American Mathematical Society},
title = {{A Geometric Setting forHamiltonian Perturbation Theory}},
volume = {153 (numbe},
year = {2001}
}
@book{Murphy2012,
address = {Cambridge, MA},
author = {Murphy, Kevin P.},
edition = {Adaptive c},
publisher = {MIT Press},
title = {{Machine Learning: A Probabilistic Perspective}},
year = {2012}
}
@misc{Stentoft2008Realized,
author = {Stentoft, Lars},
title = {{Option pricing using realized volatility}},
year = {2008}
}
@article{Hsieh2005,
author = {Hsieh, K.C. and Ritchken, Peter},
journal = {Review of Derivatives Research},
number = {3},
pages = {129--150},
title = {{An empirical comparison of GARCH option pricing models}},
volume = {8},
year = {2005}
}
@article{GHLO2014_capacity,
annote = {From Duplicate 2 ( 

Optimal nonlinear information processing capacity in delay-based reservoir computers

- Grigoryeva, Lyudmila; Henriques, Julie; Larger, Laurent; Ortega, Juan-Pablo )

},
author = {Grigoryeva, Lyudmila and Henriques, Julie and Larger, Laurent and Ortega, Juan-Pablo},
doi = {10.1038/srep12858},
journal = {Scientific Reports},
number = {12858},
pages = {1--11},
title = {{Optimal nonlinear information processing capacity in delay-based reservoir computers}},
volume = {5},
year = {2015}
}
@techreport{Steil2009,
author = {Steil, Benn},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Steil - 2009 - Lessons of the Financial Crisis.pdf:pdf},
institution = {Center for Geoeconomic Studies},
number = {45},
title = {{Lessons of the Financial Crisis}},
year = {2009}
}
@unpublished{Doersch2016a,
author = {Doersch, Carl},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Doersch - 2016 - Tutorial on variational autoencoders.pdf:pdf},
title = {{Tutorial on variational autoencoders}},
year = {2016}
}
@article{Porta2016,
author = {Porta, Antonio La and Dangel, Roger and Jubin, Daniel and Horst, Folkert and Meier, Norbert and Chelladurai, Daniel and Swatowski, Brandon W and Tomasik, Adam C and Su, Kai and Weidner, W Ken and Offrein, Bert Jan},
doi = {10.1109/ECTC.2016.305},
isbn = {9781509012046},
issn = {05695503},
journal = {IEEE 66th Electronic Components and Technology Conference},
keywords = {sent by sei (Marc)},
mendeley-tags = {sent by sei (Marc)},
pages = {6--8},
title = {{Optical Coupling between Polymer Waveguides and a Silicon Photonics Chip in the O-band}},
volume = {2},
year = {2016}
}
@article{Scurfield1998,
abstract = {This paper presents a generalization of the theory of signaldetectability ton-eventforced-choicetasks where the evidence can be modelled by anm-dimensional vector. The generalization is based on a nonparametric model that encompasses decision rules for maximizing the proportion of correct decisions. The model assumes that observers identify events by partitioning a decision space of dimensionn−1 with a template. Translating the template by varying the decisional bias yields a set of receiver operating characteristic (ROC) surfaces. Following B. K. Scurfield [1996,J. Math. Psych.40, 253–269], event-discriminability is defined by considering the Shannon entropy of the volumes under the ROC surfaces. The resultant discriminability measure is interpreted with respect to the random vectors assumed to be associated with the decision space and shown to equate with the channel capacity of an observer in a multiple-interval forced-choicetask.},
author = {Scurfield, Brian K.},
doi = {10.1006/jmps.1997.1183},
issn = {00222496},
journal = {Journal of Mathematical Psychology},
month = {mar},
number = {1},
pages = {5--31},
title = {{Generalization of the Theory of Signal Detectability ton-Eventm-Dimensional Forced-Choice Tasks}},
url = {http://dx.doi.org/10.1006/jmps.1997.1183},
volume = {42},
year = {1998}
}
@article{DeBondt2009,
author = {de Bondt, Gabe J.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/de Bondt - 2009 - Predictive content of the stock market for output revisited.pdf:pdf},
issn = {1350-4851},
journal = {Applied Economics Letters},
month = {aug},
number = {13},
pages = {1289--1294},
title = {{Predictive content of the stock market for output revisited}},
url = {http://www.tandfonline.com/doi/abs/10.1080/17446540802481821},
volume = {16},
year = {2009}
}
@article{Andreou2010a,
author = {Andreou, Elena and Ghysels, Eric and Kourtellos, Andros},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Andreou, Ghysels, Kourtellos - 2010 - Regression models with mixed sampling frequencies.pdf:pdf},
journal = {Journal of Econometrics},
pages = {246--261},
title = {{Regression models with mixed sampling frequencies}},
volume = {158},
year = {2010}
}
@article{CL_GARCH2011,
author = {Pakel, Cavin and Shephard, Neil and Sheppard, Kevin},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Pakel, Shephard, Sheppard - 2011 - Nuisance parameters, composite likelihoods and a panel of GARCH models.pdf:pdf},
journal = {Statistica Sinica},
pages = {307--329},
title = {{Nuisance parameters, composite likelihoods and a panel of GARCH models}},
volume = {21},
year = {2011}
}
@unpublished{Pieterse2019,
author = {Pieterse, Joost and Mocanu, Decebal Constantin},
title = {{Evolving and understanding sparse deep neural networks using cosine similarity}},
year = {2019}
}
@article{spikingMaass,
abstract = {Complex real-time computations on multi-modal time-varying input streams are carried out by generic cortical microcircuits. Obstacles for the development of adequate theoretical models that could explain the seemingly universal power of cortical microcircuits for real-time computing are the complexity and diversity of their computational units (neurons and synapses), as well as the traditional emphasis on offline computing in almost all theoretical approaches towards neural computation. In this article, we initiate a rigorous mathematical analysis of the real-time computing capabilities of a new generation of models for neural computation, liquid state machines, that can be implemented with - in fact benefit from - diverse computational units. Hence, realistic models for cortical microcircuits represent special instances of such liquid state machines, without any need to simplify or homogenize their diverse computational units. We present proofs of two theorems about the potential computational power of such models for real-time computing, both on analog input streams and for spike trains as inputs. {\textcopyright} 2004 Elsevier Inc. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Maass, Wolfgang and Markram, Henry},
doi = {10.1016/j.jcss.2004.04.001},
eprint = {arXiv:1011.1669v3},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Maass, Markram - 2004 - On the computational power of circuits of spiking neurons.pdf:pdf},
isbn = {0022-0000},
issn = {00220000},
journal = {Journal of Computer and System Sciences},
number = {4},
pages = {593--616},
pmid = {25246403},
title = {{On the computational power of circuits of spiking neurons}},
volume = {69},
year = {2004}
}
@unpublished{Veredas2008,
author = {Veredas, David and Silvestrini, Andrea},
booktitle = {International Relations},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Veredas, Silvestrini - 2008 - Temporal aggregation of univariate and multivariate time series models A survey.pdf:pdf},
institution = {Banca d'Italia},
title = {{Temporal aggregation of univariate and multivariate time series models: A survey}},
year = {2008}
}
@article{Bentes2015,
abstract = {This paper examines the integration of financial markets using data from five international stock markets in the context of globalization. The theoretical basis of this study relies on the price theory and the Law of One Price, which was adjusted to the framework of financial markets. When price levels are nonstationary, cointegration and the error correction model constitute a powerful tool for the empirical examination of market integration. The error correction model provides a fully dynamic framework that allows to separating the long and the short run effects of the integration process. A dataset encompassing the daily stock price series of the PSI 20 (Portugal), IBEX 35 (Spain), FTSE 100 (UK), NIKKEI 225 (Japan) and SP 500 (US) indices from January 4th 1999 to September 19th 2014 is employed. The results highlight that these five stock markets are linked together by just one long-run relationship, although short-run movements are also present, which causes distinct deviations from the long-run equilibrium relationship. Endogeneity prevails in the system as a whole. While market integration in the sense of the Law of One Price holds, pairwise full price transmission has limited evidence. The results therefore show that stock market price movements are highly nonlinear and complex.},
author = {Bentes, S{\'{o}}nia R.},
issn = {03784371},
journal = {Physica A: Statistical Mechanics and its Applications},
keywords = {Law of one price,Market integration,Nonlinearity,Vector error correction model},
month = {jul},
pages = {205--214},
title = {{On the integration of financial markets: How strong is the evidence from five international stock markets?}},
url = {http://www.sciencedirect.com/science/article/pii/S0378437115001934},
volume = {429},
year = {2015}
}
@article{sandberg:fmp,
author = {Sandberg, Irwin W.},
journal = {Circuits, Systems, and Signal Processing},
keywords = {approximately,fading memory,finite memory,input-output maps,nonlinear systems,r,uniform fading memory},
number = {1},
pages = {43--55},
title = {{Notes of fading-memory conditions}},
volume = {22},
year = {2003}
}
@article{Kuk_CL_2000,
author = {Kuk, Anthony Y.C. and Nott, David J.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Kuk, Nott - 2000 - A pairwise likelihood approach to analyzing correlated binary data.pdf:pdf},
journal = {Statistics {\&} Probability Letters},
pages = {329--335},
title = {{A pairwise likelihood approach to analyzing correlated binary data}},
volume = {47},
year = {2000}
}
@book{Arnold1993,
address = {Berlin},
author = {Arnold, V. I. and Kozlov, V. V. and Neyshtadt, A. I.},
pages = {291},
publisher = {Springer},
title = {{Mathematical aspects of classical and celestial mechanics, Dynamical systems, III, Encyclopaedia Math. Sci., vol. 3}},
year = {1993}
}
@book{AB1999,
author = {Anthony, M. and Bartlett, P.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Anthony, Bartlett - 1999 - Neural Network Learning Theoretical Foundations.pdf:pdf},
title = {{Neural Network Learning: Theoretical Foundations}},
year = {1999}
}
@misc{Basener:Topology,
author = {Basener, William F.},
publisher = {Wiley-Interscience},
title = {{Topology and Its Applications}},
year = {2006}
}
@article{Sculthorpe-Petley2015a,
abstract = {Background: Event-related potentials (ERPs) may provide a non-invasive index of brain function for a range of clinical applications. However, as a lab-based technique, ERPs are limited by technical challenges that prevent full integration into clinical settings. New method: To translate ERP capabilities from the lab to clinical applications, we have developed methods like the Halifax Consciousness Scanner (HCS). HCS is essentially a rapid, automated ERP evaluation of brain functional status. The present study describes the ERP components evoked from auditory tones and speech stimuli. ERP results were obtained using a 5-min test in 100 healthy individuals. The HCS sequence was designed to evoke the N100, the mismatch negativity (MMN), P300, the early negative enhancement (ENE), and the N400. These components reflected sensation, perception, attention, memory, and language perception, respectively. Component detection was examined at group and individual levels, and evaluated across both statistical and classification approaches. Results: All ERP components were robustly detected at the group level. At the individual level, nonparametric statistical analyses showed reduced accuracy relative to support vector (SVM) machine classification, particularly for speech-based ERPs. Optimized SVM results were MMN: 95.6{\%}; P300: 99.0{\%}; ENE: 91.8{\%}; and N400: 92.3{\%}. Conclusions: A spectrum of individual-level ERPs can be obtained in a very short time. Machine learning classification improved detection accuracy across a large healthy control sample. Translating ERPs into clinical applications is increasingly possible at the individual level.},
author = {Sculthorpe-Petley, Lauren and Liu, Careesa and {Ghosh Hajra}, Sujoy and Parvar, Hossein and Satel, Jason and Trappenberg, Thomas P. and Boshra, Rober and D'Arcy, Ryan C N},
doi = {10.1016/j.jneumeth.2015.02.008},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Sculthorpe-Petley et al. - 2015 - A rapid event-related potential (ERP) method for point-of-care evaluation of brain function Developmen.pdf:pdf},
issn = {1872678X},
journal = {Journal of Neuroscience Methods},
keywords = {Event-related potential,MMN,N400,Neurophysiology,P300,Test battery},
pages = {64--72},
pmid = {25701685},
publisher = {Elsevier B.V.},
title = {{A rapid event-related potential (ERP) method for point-of-care evaluation of brain function: Development of the Halifax Consciousness Scanner}},
url = {http://dx.doi.org/10.1016/j.jneumeth.2015.02.008},
volume = {245},
year = {2015}
}
@article{Basak12,
abstract = {We provide fully analytical, optimal dynamic hedges in incomplete markets by employing the traditional minimum-variance criterion. Our hedges are in terms of generalized "Greeks" and naturally extend no-arbitrage-based risk management in complete markets to incomplete markets. Whereas the literature characterizes either minimum-variance static, myopic, or dynamic hedges from which a hedger may deviate unless able to precommit, our hedges are time-consistent. We apply our results to derivatives replication with infrequent trading and determine hedges and replication values, which reduce to generalized Black-Scholes expressions in specific settings. We also investigate dynamic hedging with jumps, stochastic correlation, and portfolio management with benchmarking.},
author = {Basak, S. and Chabakauri, G.},
issn = {0893-9454},
journal = {Review of Financial Studies},
month = {apr},
number = {6},
pages = {1845--1896},
title = {{Dynamic Hedging in Incomplete Markets: A Simple Solution}},
url = {http://rfs.oxfordjournals.org/content/25/6/1845.short},
volume = {25},
year = {2012}
}
@article{manganelli:sav:ecb,
author = {Simone, Manganelli and Ceci, Vladimiro and Vecchiato, Walter},
journal = {European Central Bank, Working Paper No. 194},
keywords = {Dynamic Correlations,GARCH,Risk Management,Sensitivity Analysis},
publisher = {SSRN},
title = {{Sensitivity Analysis of Volatility: A New Tool for Risk Management}},
type = {Working Paper Series},
year = {2002}
}
@article{Barndorff,
author = {Barndorff-Nielsen, Ole E.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Barndorff-Nielsen - 1997 - Normal Inverse Gaussian distributions and stochastic volatility modelling.pdf:pdf},
issn = {0303-6898},
journal = {Scandinavian Journal of Statistics},
month = {mar},
number = {1},
pages = {1--13},
title = {{Normal Inverse Gaussian distributions and stochastic volatility modelling}},
url = {http://doi.wiley.com/10.1111/1467-9469.00045},
volume = {24},
year = {1997}
}
@inproceedings{Rolnick2017,
author = {Rolnick, David and Tegmark, Max},
booktitle = {International conference on learning representations},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Rolnick, Tegmark - 2018 - The power of deeper networks for expressing natural functions(2).pdf:pdf},
series = {arXiv preprint arXiv:1705.05502},
title = {{The power of deeper networks for expressing natural functions}},
year = {2018}
}
@article{Buhlmann1996,
author = {B{\"{u}}hlmann, H. and Delbaen, F. and Embrechts, P. and Shiryaev, Albert N.},
journal = {CWI QUARTERLY},
pages = {291--317},
title = {{No-arbitrage Change of Measure and Conditional Esscher Transforms}},
year = {1996}
}
@article{smale,
author = {Smale, Steve},
journal = {Invent. Math.},
pages = {305--331, 45--64},
title = {{Topology and mechanics}},
volume = {10,11},
year = {1970}
}
@unpublished{Guerin2011,
author = {Gu{\'{e}}rin, Pierre and Marcellino, Massimiliano},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Gu{\'{e}}rin, Marcellino - 2011 - Markov-switching MIDAS models.pdf:pdf},
institution = {EUI},
series = {Department of Economics},
title = {{Markov-switching MIDAS models}},
year = {2011}
}
@unpublished{Fan2019a,
author = {Fan, Jianqing and Ma, Cong and Zhong, Yiqiao},
title = {{A selective overview of deep learning}},
year = {2019}
}
@article{Dutilleul1999,
abstract = {The maximum likelihood estimation (MLE) of the parameters of the matrix normal distribution is considered. In the absence of analytical solutions of the system of likelihood equations for the among-row and among-column covariance matrices, a two-stage algorithm must be solved to obtain their maximum likelihood estimators. A necessary and sufficient condition for the existence of maximum likelihood estimators is given and the question of their stability as solutions of the system of likelihood equations is addressed. In particular, the covariance matrix parameters and their maximum likelihood estimators are defined up to a positive multiplicative constant; only their direct product is uniquely defined. Using simulated data undertwovariance-covariancestructures that, otherwise, are indistinguishable by semivariance analysis, further specific aspects of the procedure are studied: (1) the convergence of the MLE algorithm is assessed; (2) the empirical bias of the direct product ofcovariance matrix estimators ...},
author = {Dutilleul, Pierre.},
issn = {0094-9655},
journal = {Journal of Statistical Computation and Simulation},
keywords = {Matrix normal distribution,existence and stability of estimators,maximum likelihood estimation,separability of variance-covariance structure,test of model adequacy,two-stage algorithm},
language = {en},
month = {sep},
number = {2},
pages = {105--123},
publisher = {Gordon and Breach Science Publishers},
title = {{The mle algorithm for the matrix normal distribution}},
url = {http://www-tandfonline-com.ezproxy.lib.ucalgary.ca/doi/abs/10.1080/00949659908811970},
volume = {64},
year = {1999}
}
@misc{granger1969,
author = {Granger, Clive. W. J.},
booktitle = {Operations Research Quarterly},
pages = {199--207},
title = {{Prediction with a Generalized Cost of Error Function}},
url = {http://www.jstor.org/discover/10.2307/3008559?uid=3738016{\&}uid=2{\&}uid=4{\&}sid=21100995916293},
year = {1969}
}
@inproceedings{Finn2018,
author = {Finn, Chelsea and Levine, Sergey},
booktitle = {ICLR},
title = {{Meta-learning and universality: deep representations and gradient descent can approximate any learning algorithm}},
year = {2018}
}
@book{Sarkka2013,
abstract = {"Filtering and smoothing methods are used to produce an accurate estimate of the state of a time-varying system based on multiple observational inputs (data). Interest in these methods has exploded in recent years, with numerous applications emerging in fields such as navigation, aerospace engineering, telecommunications and medicine. This compact, informal introduction for graduate students and advanced undergraduates presents the current state-of-the-art filtering and smoothing methods in a unified Bayesian framework."--Cover. 1. What are Bayesian filtering and smoothing? -- 2. Bayesian inference -- 3. Batch and recursive Bayesian estimation -- 4. Bayesian filtering equations and exact solutions -- 5. Extended and unscented Kalman filtering -- 6. General Gaussian filtering -- 7. Particle filtering -- 8. Bayesian smoothing equations and exact solutions -- 9. Extended and unscented smoothing -- 10. General Gaussian smoothing -- 11. Particle smoothing -- 12. Parameter estimation -- 13. Epilogue.},
author = {S{\"{a}}rkk{\"{a}}, Simo},
isbn = {9781107030657},
pages = {232},
publisher = {Cambridge University Press},
title = {{Bayesian Filtering and Smoothing}},
url = {http://www.cambridge.org/ch/academic/subjects/statistics-probability/applied-probability-and-stochastic-networks/bayesian-filtering-and-smoothing?format=HB{\#}EjybLohyGu4JXd28.97},
year = {2013}
}
@misc{Rosenberg2015,
author = {Rosenberg, David},
title = {{Loss Functions for Regression and Classification: Lecture Notes}},
year = {2015}
}
@article{guger:et:al,
author = {Guger, C. and Edlinger, G. and Harkam, W. and Niedermayer, I. and Pfurtscheller, Gert},
journal = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
pages = {145--147},
title = {{How many people are able to operate an EEG-based brain-computer interface (BCI)? IEEE Trans Neural Syst Rehabil Eng 2003; 11: 145-147.}},
volume = {11},
year = {2003}
}
@article{cerny:kallsen,
author = {{\v{C}}ern{\'{y}}, Ale{\v{s}} and Kallsen, Jan},
doi = {10.1111/j.1467-9965.2009.00381.x},
issn = {0960-1627},
journal = {Math. Finance},
number = {4},
pages = {591--617},
title = {{Hedging by sequential regressions revisited}},
url = {http://dx.doi.org/10.1111/j.1467-9965.2009.00381.x},
volume = {19},
year = {2009}
}
@article{Latino2010,
author = {Latino, Diogo A R S and Fartaria, Rui P S and Freitas, Filomena F M and Aires-De-Sousa, Jo{\~{a}}o and {Silva Fernandes}, Fernando M S},
doi = {10.1002/qua.22198},
issn = {1097-461X},
journal = {International Journal of Quantum Chemistry},
keywords = {ensembles of feed-forward neural networks,ethanol adsorption on Au (111),potential energy surfaces},
number = {2},
pages = {432--445},
publisher = {Wiley Subscription Services, Inc., A Wiley Company},
title = {{Approach to potential energy surfaces by neural networks. A review of recent work}},
url = {http://dx.doi.org/10.1002/qua.22198},
volume = {110},
year = {2010}
}
@article{funahashi:nakamura,
abstract = {In this paper, we prove that any finite time trajectory of a given n-dimensional dynamical system can be approximately realized by the internal state of the output units of a continuous time recurrent neural network with n output units, some hidden units, and an appropriate initial condition. The essential idea of the proof is to embed the n-dimensional dynamical system into a higher dimensional one which defines a recurrent neural network. As a corollary, we also show that any continuous curve can be approximated by the output of a recurrent neural network.},
author = {Funahashi, Ken-ichi and Nakamura, Yuichi},
doi = {10.1016/S0893-6080(05)80125-X},
issn = {0893-6080},
journal = {Neural Networks},
month = {jan},
number = {6},
pages = {801--806},
publisher = {Pergamon},
title = {{Approximation of dynamical systems by continuous time recurrent neural networks}},
url = {https://www.sciencedirect.com/science/article/pii/S089360800580125X},
volume = {6},
year = {1993}
}
@inproceedings{Chris2005,
address = {Working paper},
author = {Christoffersen, Peter and Jacobs, Kris and Mimouni, Karim},
booktitle = {Faculty of Management, McGill University},
title = {{An empirical comparison of affine and non-affine models for equity index options}},
year = {2006}
}
@article{aharonov-anandan,
author = {Aharonov, Y. and Anandan, J.},
journal = {Phys. Rev. Lett.},
pages = {1593--1596},
title = {{Phase changeduring acyclic quantum evolution}},
volume = {58},
year = {1987}
}
@article{lie:group:valued:maps,
author = {Alekseev, A. and Malkin, A. and Meinrenken, E.},
journal = {J. Differential Geom.},
pages = {445--495},
title = {{Lie group valued momentum maps}},
volume = {48},
year = {1998}
}
@article{sandberg:esn:paper,
author = {Sandberg, Irwin W},
journal = {Multidimensional Systems and Signal Processing},
pages = {267--286},
title = {{Structure theorems for nonlinear systems}},
volume = {2},
year = {1991}
}
@article{elkaroui:1997,
author = {{El Karoui}, Nicole and Peng, S. and Quenez, M. C.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/El Karoui, Peng, Quenez - 1997 - Backward Stochastic Differential Equations in Finance.pdf:pdf},
journal = {Mathematical Finance},
number = {1},
pages = {1--71},
title = {{Backward stochastic differential equations in finance}},
volume = {7},
year = {1997}
}
@book{Bapat:1997,
author = {Bapat, R. B. and Raghavan, T. E. S.},
pages = {336},
publisher = {Cambridge University Press},
title = {{Nonnegative Matrices and Applications}},
year = {1997}
}
@unpublished{Kock2011,
abstract = {In this work we consider forecasting macroeconomic variables dur- ing an economic crisis. The focus is on a speci{\"{O}}c class of models, the so-called single hidden-layer feedforward autoregressive neural net- work models. What makes these models interesting in the present context is that they form a class of universal approximators and may be expected to work well during exceptional periods such as ma jor economic crises. These models are often di¢ cult to estimate, and we follow the idea of White (2006) to transform the speci{\"{O}}cation and non- linear estimation problem into a linear model selection and estimation problem. To this end we employ three automatic modelling devices. One of them is White{\'{i}}s QuickNet, but we also consider Autometrics, well known to time series econometricians, and the Marginal Bridge Estimator, better known to statisticians and microeconometricians. The performance of these three model selectors is compared by look- ing at the accuracy of the forecasts of the estimated neural network models. We apply the neural network model and the three modelling techniques to monthly industrial production and unemployment se- ries of the G7 countries and the four Scandinavian ones, and focus on forecasting during the economic crisis 2007{\~{n}}2009. Forecast accuracy is measured by the root mean square forecast error. Hypothesis testing is also used to compare the performance of the di{\S}erent techniques with each other.},
author = {Kock, Anders Bredahl and Ter{\"{a}}svirta, Timo},
booktitle = {Building},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Kock, Ter{\"{a}}svirta - 2011 - Forecasting Performance of Three Automated Modelling Techniques during the Economic Crisis 2007.pdf:pdf},
institution = {CREATES},
keywords = {Autometrics,Marginal Bridge,Wilcoxon{\'{i}}s signed-rank test,economic forecasting,estimator,neural network,nonlinear time series model},
title = {{Forecasting Performance of Three Automated Modelling Techniques during the Economic Crisis 2007}},
year = {2011}
}
@article{Marchiori2006,
abstract = {The growth of epitaxial SrTiO3 on silicon relies on the preparation of a template layer consisting of a mixture of barium oxide and strontium oxide,(Ba,Sr)O. In this letter, the limited thermal stability of this template layer is demonstrated. X-ray photoemission spectroscopy measurements reveal that both SrTiO3/ (Ba,Sr)O and (Ba,Sr)O/Si interfaces are susceptible to chemical reactions upon thermal treatment to an extent that is correlated with the thermal budget. These results have strong implications on the overall viability of (Ba,Sr)O as template for the growth of crystalline oxides on Si.},
author = {Marchiori, Chiara and Sousa, M and Guiller, A and Siegwart, H and Locquet, J.-P. and Fompeyrine, J and Norga, G J and Seo, J W},
doi = {10.1063/1.2174095},
issn = {00036951},
journal = {Applied Physics Letters},
number = {7},
pages = {72913},
title = {{Thermal stability of the SrTiO{\{}{\textless}{\}}sub{\{}{\textgreater}{\}}3{\{}{\textless}{\}}/sub{\{}{\textgreater}{\}}∕(Ba,Sr)O stacks epitaxially grown on Si}},
url = {http://scitation.aip.org/content/aip/journal/apl/88/7/10.1063/1.2174095},
volume = {88},
year = {2006}
}
@article{KoopmanNISE2015,
author = {Koopman, S. J. and Lucas, A. and Scharth, M.},
journal = {Journal of Business {\&} Economic Statistics},
number = {1},
pages = {114--127},
title = {{Numerically accelerated importance sampling for nonlinear non-Gaussian state space models}},
volume = {33},
year = {2015}
}
@article{chan:palma:1998,
author = {Chan, Ngai Hang and Palma, Wilfredo and Others},
journal = {The Annals of Statistics},
number = {2},
pages = {719--740},
publisher = {Institute of Mathematical Statistics},
title = {{State space modeling of long-memory processes}},
volume = {26},
year = {1998}
}
@article{Lee2001,
abstract = {Financial prediction is one of the most typical applications in contemporary scientific study. In this paper, we present a fully integrated stock prediction system – NORN Predictor – a Neural Oscillatory-based Recurrent Network for finance prediction system to provide both a) long-term trend prediction, and b) short-term stock price prediction. One of the major characteristics of the proposed system is the automation of the conventional financial technical analysis technique such as market pattern analysis via the NOEGM (Neural Oscillatory-based Elastic Graph Matching) model and its integration with the Time-difference recurrent neural network models. This will provide a fully integrated and automated tool for analysis and investigation of stock investment. From the implementation point of view, the stock pricing information of 33 major Hong Kong stocks in the period from 1990 to 1999 is being adopted for system training and evaluation. As compared with the contemporary neural prediction model, the propos...},
author = {Lee, Raymond S. T. and Liu, James N. K.},
doi = {10.1142/S1469026801000354},
journal = {International Journal of Computational Intelligence and Applications},
month = {dec},
number = {04},
pages = {439--451},
publisher = {Imperial College Press},
title = {{NORN predictor-stock prediction using a neural oscillatory-based recurrent network}},
url = {http://www.worldscientific.com/doi/abs/10.1142/S1469026801000354},
volume = {01},
year = {2001}
}
@inproceedings{albert:dazord:1990,
address = {Lyon},
author = {Albert, C and Dazord, P},
booktitle = {Travaux du S{\{}{\'{e}}{\}}minaire Sud Rhodanien de G{\{}{\'{e}}{\}}om{\{}{\'{e}}{\}}trie, II},
pages = {27--99},
publisher = {Publ. D{\{}{\'{e}}{\}}p. Math. Nouvelle S{\{}{\'{e}}{\}}r. B},
title = {{Th{\{}{\'{e}}{\}}orie des groupo{\{}{\"{i}}{\}}des symplectiques. Chapitre I. Groupo{\{}{\"{i}}{\}}des symplectiques}},
year = {1990}
}
@unpublished{Crainic2000,
author = {Crainic, M. and Moerdijk, I.},
title = {{Foliation groupoids and their cyclic homology}},
year = {2000}
}
@article{crone:forecasting,
author = {Crone, S. F.},
journal = {Journal of Intelligent Systems},
title = {{Stepwise Selection of Artificial Neural Network Models for Time Series Prediction}},
volume = {15},
year = {2005}
}
@article{MR1457699,
author = {Duan, Jin-Chuan},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Duan - 1997 - Augmented GARCH(p,q) process and its diffusion limit.pdf:pdf},
journal = {Journal of Econometrics},
pages = {97--127},
title = {{Augmented GARCH(p,q) process and its diffusion limit}},
volume = {79},
year = {1997}
}
@article{linearESN,
archivePrefix = {arXiv},
arxivId = {arXiv:1603.07866v1},
author = {Couillet, Romain and Wainrib, Gilles and Sevi, Harry and Ali, Hafiz Tiomoko},
eprint = {arXiv:1603.07866v1},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Couillet et al. - 2016 - The asymptotic performance of linear echo state neural networks.pdf:pdf},
isbn = {9781467378024},
journal = {Journal of Machine Learning Research},
keywords = {Deep Learning Theory},
number = {178},
pages = {1--35},
title = {{The asymptotic performance of linear echo state neural networks}},
volume = {17},
year = {2016}
}
@book{schoelkopf:smola:book,
author = {Sch{\"{o}}lkopf, Bernhard and Smola, Alexander J.},
publisher = {MIT Press},
title = {{Learning with Kernels}},
year = {2002}
}
@article{pathak:chaos,
abstract = {We use recent advances in the machine learning area known as 'reservoir computing' to formulate a method for model-free estimation from data of the Lyapunov exponents of a chaotic process. The technique uses a limited time series of measurements as input to a high-dimensional dynamical system called a 'reservoir'. After the reservoir's response to the data is recorded, linear regression is used to learn a large set of parameters, called the 'output weights'. The learned output weights are then used to form a modified autonomous reservoir designed to be capable of producing arbitrarily long time series whose ergodic properties approximate those of the input signal. When successful, we say that the autonomous reservoir reproduces the attractor's 'climate'. Since the reservoir equations and output weights are known, we can compute derivatives needed to determine the Lyapunov exponents of the autonomous reservoir, which we then use as estimates of the Lyapunov exponents for the original input generating system. We illustrate the effectiveness of our technique with two examples, the Lorenz system, and the Kuramoto-Sivashinsky (KS) equation. In particular, we use the Lorenz system to show that achieving climate reproduction may require tuning of the reservoir parameters. For the case of the KS equation, we note that as the system's spatial size is increased, the number of Lyapunov exponents increases, thus yielding a challenging test of our method, which we find the method successfully passes.},
archivePrefix = {arXiv},
arxivId = {1710.07313},
author = {Pathak, Jaideep and Lu, Zhixin and Hunt, Brian R. and Girvan, Michelle and Ott, Edward},
doi = {10.1063/1.5010300},
eprint = {1710.07313},
issn = {10541500},
journal = {Chaos},
number = {12},
title = {{Using machine learning to replicate chaotic attractors and calculate Lyapunov exponents from data}},
volume = {27},
year = {2017}
}
@article{Aurelio2007a,
abstract = {We describe a novel unsupervised method for learning sparse, overcomplete fea- tures. The model uses a linear encoder, and a linear decoder preceded by a spar- sifying non-linearity that turns a code vector into a quasi-binary sparse code vec- tor. Given an input, the optimal code minimizes the distance between the output of the decoder and the input patch while being as similar as possible to the en- coder output. Learning proceeds in a two-phase EM-like fashion: (1) compute the minimum-energy code vector, (2) adjust the parameters of the encoder and de- coder so as to decrease the energy. The model produces “stroke detectors” when trained on handwritten numerals, and Gabor-like filters when trained on natural image patches. Inference and learning are very fast, requiring no preprocessing, and no expensive sampling. Using the proposed unsupervised method to initialize the first layer of a convolutional network, we achieved an error rate slightly lower than the best reported result on the MNIST dataset. Finally, an extension of the method is described to learn topographical filter maps.},
author = {Aurelio, Marc and Christopher, Ranzato and Sumit, Poultney and Yann, Chopra},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Aurelio et al. - 2007 - Efficient learning of sparse representations with an energy-based model.pdf:pdf},
isbn = {1424411807},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
pages = {1137--1144},
title = {{Efficient learning of sparse representations with an energy-based model}},
year = {2007}
}
@unpublished{Jacobs2019,
author = {Jacobs, Kris and Liu, Yuguo},
title = {{Estimation and filtering with big option data: Implications for asset pricing}},
year = {2019}
}
@article{fan:wang:yao,
author = {Fan, Jianqing and Wang, Mingjin and Yao, Qiwei},
doi = {10.1111/j.1467-9868.2008.00654.x},
issn = {1467-9868},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
keywords = {1) model,Bootstrap test,Causality in variance,Dimension reduction,Extended GARCH(1,Financial returns,Portfolio volatility,Quasi-maximum-likelihood estimator,Time series},
number = {4},
pages = {679--702},
publisher = {Blackwell Publishing Ltd},
title = {{Modelling multivariate volatilities via conditionally uncorrelated components}},
url = {http://dx.doi.org/10.1111/j.1467-9868.2008.00654.x},
volume = {70},
year = {2008}
}
@inproceedings{Marko1996,
author = {Marko, K. and James, L. and Feldkamp, T. and Puskorius, G. and Feldkamp, L. and Prokhorov, D.},
booktitle = {WCNN},
pages = {845--850},
title = {{Training recurrent networks for classification: realization of automotive engine diagnostics}},
year = {1996}
}
@phdthesis{marsilli:thesis,
author = {Marsilli, Cl{\'{e}}ment},
pages = {140},
school = {Universit{\'{e}} de Franche-Comt{\'{e}}},
title = {{Mixed-Frequency Modeling and Economic Forecasting}},
year = {2014}
}
@unpublished{Duan00,
author = {Duan, Jin-Chuan},
title = {{GARCH and stochastic volatility option pricing}},
year = {2000}
}
@article{cruse:brain_injury,
author = {Cruse, D. and Gantner, I. and Soddu, A. and Owen, Adrian M.},
journal = {Brain Injury},
number = {9},
pages = {1197--1201},
title = {{Lies, damned lies and diagnoses: estimating the clinical utility of assessments of covert awareness in the vegetative state.}},
volume = {28},
year = {2014}
}
@incollection{Orponen,
author = {Orponen, P.},
booktitle = {Advances in Algorithms, Languages, and Complexity},
pages = {209--224},
publisher = {Springer US},
title = {{A survey of continuous-time computation theory}},
year = {1997}
}
@article{Besag_CL,
author = {Besag, Julian},
journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
number = {2},
pages = {192--236},
title = {{Spatial interaction and the statistical analysis of lattice systems}},
volume = {36},
year = {1974}
}
@article{Ioannidis2015,
author = {Ioannidis, Dimitris and Papadopoulos, Georgios E and Anastassopoulos, Georgios and Kortsaris, Alexandros and Anagnostopoulos, Konstantinos},
doi = {http://dx.doi.org/10.1016/j.compbiolchem.2015.02.016},
issn = {1476-9271},
journal = {Computational Biology and Chemistry},
pages = {7--12},
title = {{Structural properties and interaction energies affecting drug design. An approach combining molecular simulations, statistics, interaction energies and neural networks}},
url = {http://www.sciencedirect.com/science/article/pii/S147692711500033X},
volume = {56},
year = {2015}
}
@article{Lam2009,
author = {Lam, K.P. and Ng, H.S.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Lam, Ng - 2009 - Intra-daily information of range-based volatility for MEM-GARCH.pdf:pdf},
issn = {03784754},
journal = {Mathematics and Computers in Simulation},
keywords = {garch,multiplicative error model,volatility forecasting},
month = {apr},
number = {8},
pages = {2625--2632},
title = {{Intra-daily information of range-based volatility for MEM-GARCH}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0378475408004175},
volume = {79},
year = {2009}
}
@article{AB2003,
author = {Abreu, Dilip and Brunnermeier, Markus K.},
doi = {10.1111/1468-0262.00393},
issn = {0012-9682},
journal = {Econometrica},
month = {jan},
number = {1},
pages = {173--204},
title = {{Bubbles and crashes}},
url = {http://doi.wiley.com/10.1111/1468-0262.00393},
volume = {71},
year = {2003}
}
@article{Koenig2003,
author = {Koenig, E. F. and Dolmas, D. and Piger, J.},
journal = {The Review of Economics and Statistics},
pages = {618--628},
title = {{The use and abuse of real-time data in economic forecasting}},
volume = {85},
year = {2003}
}
@book{applebaum2005quantum,
author = {Applebaum, David and Bhat, B V Rajarama and Kustermans, Johan and Lindsay, J Martin},
publisher = {Springer},
title = {{Quantum independent increment processes I: From classical probability to quantum stochastic calculus}},
year = {2005}
}
@article{sauer1991embedology,
author = {Sauer, Tim and Yorke, James A and Casdagli, Martin},
journal = {Journal of Statistical Physics},
number = {3},
pages = {579--616},
publisher = {Springer},
title = {{Embedology}},
volume = {65},
year = {1991}
}
@article{Younes2008,
author = {Younes, Laurent and Michor, Peter and Shah, Jayant and Mumford, David},
doi = {10.4171/RLM/506},
isbn = {0-387-98643-X},
issn = {1120-6330},
journal = {Rendiconti Lincei - Matematica e Applicazioni},
keywords = {EPDiff,Groups of diffeomorphisms,deformable templates,image registration,shape analysis},
number = {1},
pages = {25--57},
publisher = {Springer-Verlag, New York},
title = {{A metric on shape space with explicit geodesics}},
url = {http://www.ems-ph.org/doi/10.4171/RLM/506},
volume = {19},
year = {2008}
}
@article{Kvedaras2010,
author = {Kvedaras, Virmantas and Ra{\v{c}}kauskas, Alfredas},
issn = {03059049},
journal = {Oxford Bulletin of Economics and Statistics},
month = {oct},
number = {5},
pages = {600--620},
title = {{Regression Models with Variables of Different Frequencies: The Case of a Fixed Frequency Ratio*}},
url = {http://doi.wiley.com/10.1111/j.1468-0084.2010.00585.x},
volume = {72},
year = {2010}
}
@article{williamson1937normal,
author = {Williamson, John},
journal = {American Journal of Mathematics},
number = {3},
pages = {599--617},
publisher = {JSTOR},
title = {{On the normal forms of linear canonical transformations in dynamics}},
volume = {59},
year = {1937}
}
@misc{Wasserman2016,
author = {Wasserman, Larry},
booktitle = {http://www.stat.cmu.edu/∼larry/=sml},
title = {{Statistical Machine Learning: Lecture Notes}},
url = {http://www.stat.cmu.edu/∼larry/=sml},
year = {2016}
}
@inproceedings{Liepvre2013,
abstract = {This paper reports on a hybrid III-V on silicon arrayed waveguide grating laser, operating on 5 wavelength channels spaced by 392 GHz, with a threshold current around 40mA and a maximum output power around 3 dBm.},
author = {Liepvre, A Le and Jany, C and Accard, A and Lamponi, M and Make, D and Lelarge, F and Fedeli, J M and Messaoudene, S and Bordel, D and Duan, G H},
booktitle = {10th International Conference on Group IV Photonics},
doi = {10.1109/Group4.2013.6644415},
issn = {1949-2081},
keywords = {III-V semiconductors;arrayed waveguide gratings;el},
month = {aug},
pages = {150--151},
title = {{A wavelength selectable hybrid III {\#}x2013;V/Si laser fabricated by wafer bonding}},
year = {2013}
}
@article{Andreou2013,
author = {Andreou, Elena and Ghysels, Eric and Kourtellos, Andros},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Andreou, Ghysels, Kourtellos - 2013 - Should macroeconomic forecasters use daily financial data and how.pdf:pdf},
journal = {Journal of Business and Economic Statistics},
number = {2},
pages = {240--251},
title = {{Should macroeconomic forecasters use daily financial data and how?}},
volume = {31},
year = {2013}
}
@article{Doya2001,
author = {Doya, K. and Kimura, H. and Kawato, M.},
journal = {IEEE Control Systems Magazine},
number = {4},
pages = {42--54},
title = {{Neural mechanisms of learning and control}},
volume = {21},
year = {2001}
}
@article{RV2008Dijk,
author = {Martens, M. and Van, Dijk},
journal = {Journal of Econometrics},
number = {1},
pages = {181--207},
title = {{Measuring volatility with the realized range}},
volume = {138},
year = {2007}
}
@unpublished{Bencivelli2012,
author = {Bencivelli, Lorenzo and Marcellino, Massimiliano and Moretti, Gianluca},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Bencivelli, Marcellino, Moretti - 2012 - Selecting predictors by using Bayesian model averaging in bridge models.pdf:pdf},
institution = {Banca d'Italia},
keywords = {Bayesian model averaging,bridge models.,business cycle analysis,forecasting},
title = {{Selecting predictors by using Bayesian model averaging in bridge models}},
type = {Temi di discussione (Economic working papers)},
url = {http://ideas.repec.org/p/bdi/wptemi/td{\_}872{\_}12.html},
year = {2012}
}
@inproceedings{Heinen2011,
author = {Heinen, Milton Roberto and Engel, Paulo Martins and Pinto, Rafael C.},
booktitle = {Proc VIII Encontro Nacional de Intelig{\^{e}}ncia Artificial (ENIA2011)},
title = {{IGMN: An incremental gaussian mixture network that learns instantaneously from data flows}},
year = {2011}
}
@article{Pathak:PRL,
author = {Pathak, Jaideep and Hunt, Brian and Girvan, Michelle and Lu, Zhixin and Ott, Edward},
doi = {10.1103/PhysRevLett.120.024102},
isbn = {2420629205},
issn = {10797114},
journal = {Physical Review Letters},
keywords = {doi:10.1103/PhysRevLett.120.024102 url:https://doi},
number = {2},
pages = {24102},
publisher = {American Physical Society},
title = {{Model-Free Prediction of Large Spatiotemporally Chaotic Systems from Data: A Reservoir Computing Approach}},
url = {https://doi.org/10.1103/PhysRevLett.120.024102},
volume = {120},
year = {2018}
}
@article{holonomy:ambrose:singer,
author = {Ambrose, W. and Singer, I. M.},
journal = {Trans. Amer. Math. Soc.},
pages = {428--443},
title = {{A theorem on holonomy}},
volume = {75},
year = {1953}
}
@article{duchesne:lalancette:test,
author = {Duchesne, Pierre and Lalancette, Simon},
issn = {0319-5724},
journal = {Canad. J. Statist.},
number = {3},
pages = {275--292},
title = {{On testing for multivariate {\{}ARCH{\}} effects in vector time series models}},
volume = {31},
year = {2003}
}
@article{LuceyMuckley2011,
abstract = {In this paper, we examine the scope for in ternational stock portfolio diversification, from the viewpoint of a United States representative investor, in regard to both the Asian and the European stock markets. Our findings indicate that despite correlation style evidence to the contrary, the European stock markets provide a superior long-term diversification opportunity relative to that provided by the Asian stock markets. Hence, a short-term measurement of interdependence appears to be uninformative with respect to the diversification opportunities of investors with longer term investment horizons. In terms of methodology, we adopt common stochastic trend tests, including a common stochastic trend test which accounts for generalised autoregressive conditional heteroskedasticity effects in conjunction with the recursive estimation of these tests to estimate the development of long-term stock market interdependence linkages. Recursively estimated robust correlations between the international stock markets are utilised to reveal the nature of short-term stock market interdependence linkages.},
author = {Lucey, Brian M. and Muckley, Cal},
issn = {10575219},
journal = {International Review of Financial Analysis},
keywords = {Cointegration,Correlation,F3,G1,Portfolio diversification,Stock market linkages},
month = {aug},
number = {4},
pages = {215--224},
title = {{Robust global stock market interdependencies}},
url = {http://www.sciencedirect.com/science/article/pii/S1057521911000093},
volume = {20},
year = {2011}
}
@article{CaviarPaper,
abstract = {Value at risk (VaR) is the standard measure of market risk used by financial institutions. Interpreting the VaR as the quantile of future portfolio values conditional on current information, the conditional autoregressive value at risk (CAViaR) model specifies the evolution of the quantile over time using an autoregressive process and estimates the parameters with regression quantiles. Utilizing the criterion that each period the probability of exceeding the VaR must be independent of all the past information, we introduce a new test of model adequacy, the dynamic quantile test. Applications to real data provide empirical support to this methodology.},
author = {Engle, Robert F and Manganelli, Simone},
doi = {10.1198/073500104000000370},
issn = {0735-0015},
journal = {Journal of Business {\&} Economic Statistics},
keywords = {Nonlinear regression quantile,Risk management,Specification testing},
language = {en},
month = {oct},
number = {4},
pages = {367--381},
publisher = {Taylor {\&} Francis},
title = {{Conditional autoregressive value at risk by regression quantiles}},
url = {http://amstat.tandfonline.com/doi/abs/10.1198/073500104000000370{\#}.UiDJIxYjiao},
volume = {22},
year = {2004}
}
@article{Fieuws_Verbeke_CL_2006,
author = {Fieuws, S. and Verbeke, G.},
journal = {Biometrics},
pages = {424--431},
title = {{Pairwise fitting of mixed models for the joint modeling of multivariate longitudinal profiles}},
volume = {62},
year = {2006}
}
@article{Varin2008,
author = {Varin, Cristiano},
doi = {10.1007/s10182-008-0060-7},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Varin - 2008 - On composite marginal likelihoods.pdf:pdf},
issn = {1863-8171},
journal = {AStA Advances in Statistical Analysis},
month = {feb},
number = {1},
pages = {1--28},
title = {{On composite marginal likelihoods}},
url = {http://link.springer.com/10.1007/s10182-008-0060-7},
volume = {92},
year = {2008}
}
@inproceedings{Allen-Zhu2019,
abstract = {Recurrent Neural Networks (RNNs) are among the most popular models in sequential data analysis. Yet, in the foundational PAC learning language, what concept class can it learn? Moreover, how can the same recurrent unit simultaneously learn functions from different input tokens to different output tokens, without affecting each other? Existing generalization bounds for RNN scale exponentially with the input length, significantly limiting their practical implications. In this paper, we show using the vanilla stochastic gradient descent (SGD), RNN can actually learn some notable concept class efficiently, meaning that both time and sample complexity scale polynomially in the input length (or almost polynomially, depending on the concept). This concept class at least includes functions where each output token is generated from inputs of earlier tokens using a smooth two-layer neural network.},
archivePrefix = {arXiv},
arxivId = {1902.01028},
author = {Allen-Zhu, Zeyuan and Li, Yuanzhi},
booktitle = {33rd Conference on Neural Information Processing Systems (NeurIPS 2019)},
eprint = {1902.01028},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Allen-Zhu, Li - 2019 - Can SGD learn recurrent neural networks with provable generalization.pdf:pdf;:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Allen-Zhu, Li - 2019 - Can SGD learn recurrent neural networks with provable generalization(2).pdf:pdf},
title = {{Can SGD learn recurrent neural networks with provable generalization?}},
url = {http://arxiv.org/abs/1902.01028},
year = {2019}
}
@article{leonard:marsden:1997,
author = {Leonard, N. E. and Marsden, J. E.},
journal = {Physica D},
pages = {130--162},
title = {{Stability and drift of underwater vehicle dynamics: mechanical systems with rigid motion symmetry}},
volume = {105},
year = {1997}
}
@book{boulie,
author = {Bourbaki, N},
chapter = {2-3},
publisher = {Hermann},
title = {{Groupes et alg{\{}{\`{e}}{\}}bres de Lie}},
year = {1972}
}
@book{boulie,
author = {Bourbaki, N.},
chapter = {2-3},
publisher = {Hermann},
title = {{Groupes et alg{\`{e}}bres de Lie}},
year = {1972}
}
@inproceedings{kellerer1982duality,
author = {Kellerer, Hans G},
booktitle = {Proceedings of the seventh conference on probability theory (Brasov, 1982)},
pages = {211--220},
title = {{Duality theorems and probability metrics}},
year = {1982}
}
@unpublished{Abbasi-Asl2018,
abstract = {Deep neural network models have recently been shown to be effective in predicting single neuron responses in primate visual cortex areas V4. Despite their high predictive accuracy, these models are generally difficult to interpret. This limits their applicability in characterizing V4 neuron function. Here, we propose the DeepTune framework as a way to elicit interpretations of deep neural network-based models of single neurons in area V4. V4 is a midtier visual cortical area in the ventral visual pathway. Its functional role is not yet well understood. Using a dataset of recordings of 71 V4 neurons stimulated with thousands of static natural images, we build an ensemble of 18 neural network-based models per neuron that accurately predict its response given a stimulus image. To interpret and visualize these models, we use a stability criterion to form optimal stimuli (DeepTune images) by pooling the 18 models together. These DeepTune images not only confirm previous findings on the presence of diverse shape and texture tuning in area V4, but also provide rich, concrete and nat-uralistic characterization of receptive fields of individual V4 neurons. The population analysis of DeepTune images for 71 neurons reveals how different types of curvature tuning are distributed in V4. In addition , it also suggests strong suppressive tuning for nearly half of the V4 neurons. Though we focus exclusively on the area V4, the DeepTune framework could be applied more generally to enhance the understanding of other visual cortex areas. computational neuroscience | visual cortex | V4 | tuning | stability | convolutional neural network U nderstanding the function of primate visual pathways is a major challenge in computational neuroscience. Along the ventral visual pathway, cortical area V4 is of particular interest. It is a large retinotopically-organized area located intermediate between the early primate visual cortex areas such as V1 and V2 and high-level areas in the inferior temporal (IT) lobe. V4 is believed to be crucial for visual object recognition and visual attention, but its functional role remains mysterious. Computational studies of primary visual cortex have produced powerful quantitative models of V1 (1). Contrastingly, area V4 is more difficult to model computationally than V1. This is mainly due to its highly nonlinear response (2) and diverse tuning properties (3). To understand the tuning properties of V4 neurons, one dominant traditional approach is to use handcrafted and limited synthetic stimuli (e.g. (4, 5)) to probe V4 neurons. For example, by comparing V4 neuron responses to Cartesian gratings with those to polar and hyperbolic (non-Cartesian) gratings, Gallant et al. (4, 6) found that V4 neurons are most selective for non-Cartesian gratings containing multiple ori-entations. Through a parameterized set of contour stimuli varying in angularity, curvature, and orientation, Pasupathy and Connor (5, 7) discovered that V4 neurons are selective to curved contour features. While such studies have successfully quantified V4 neuron responses to synthetic shapes, the tuning properties of most V4 neurons cannot be fully explored through these limited sets of stimuli (3). An alternative approach to designing synthetic stimuli is using a large collection of natural images directly as stimuli. This approach reduces the difficulty in stimuli design, but creates a huge challenge in modeling. Specifically, it has been found that previously proposed simple and shallow computational models of V4 neurons perform poorly on natural images (3, 8, 9). For instance, David et al. (8) introduced the spectral receptive field (SRF) model to account for second order nonlinear response properties. The SRF model enhances our understanding of V4 orientation tuning properties, but its average prediction performance for the V4 neurons studied is far from satisfying (3). More recently, advances in deep convolutional neural networks (CNNs) with multiple layers of linear and non-linear operations have led to more accurate predictive models for neurons in V4 and IT (10-12). While this deep, convolutional and non-linear architecture is the key to the high predictive performance, it also makes the models difficult to interpret. This limits their usefulness in advancing neuroscience. A natural question arises: can we use these complex and accurate models to infer tuning properties of V4 neurons? Significance Statement Understanding how primates process visual information and recognize objects in an image is a major problem in neuro-science. Along the visual pathway, the midtier cortical area V4 is of particular interest. Despite its importance in the hierarchical organization of visual processing, its function remains elusive. Accurate deep neural network-based predictive models are built for responses of V4 neurons to natural image stimuli. While interpreting these models is traditionally difficult, we introduce the DeepTune framework to equip these complex models with stable interpretation and visualization. The DeepTune images provide rich, concrete and naturalistic characterizations of V4 neurons that refine significantly findings of previous studies. They hold promise as better natural input stimuli for future closed-loop experiments.},
author = {Abbasi-Asl, Reza and Chen, Yuansi and Bloniarz, Adam and Oliver, Michael and Willmore, Ben D.B. and Gallant, Jack L. and Yu, Bin},
doi = {10.1073/pnas.XXXXXXXXXX},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Abbasi-Asl et al. - 2018 - The DeepTune framework for modeling and characterizing neurons in visual cortex area V4.pdf:pdf},
title = {{The DeepTune framework for modeling and characterizing neurons in visual cortex area V4}},
url = {www.pnas.org/cgi/doi/10.1073/pnas.XXXXXXXXXX1},
year = {2018}
}
@article{Shimada2005,
abstract = {ABSTRACT The stochastic volatility (SV) model can be regarded as a nonlinear state space model. This article proposes the Laplace approximation method to the nonlinear state space representation and applies it for estimating the SV models. We examine how the approximation works by simulations as well as various empirical studies. The Monte Carlo experiments for the standard SV model indicate that our method is comparable to the Monte-Calro Likelihood (MCL; Durbin and Koopman, 1997), Maximum Likelihood (Fridman and Harris, 1998), and Markov chain Monte Carlo (MCMC) methods in the sense of mean square error in finite sample. The empirical studies for stock markets reveal that our method provides very similar estimates of coefficients to those of the MCL. We show a relationship of our Laplace approximation method to importance sampling.
ABSTRACT The stochastic volatility (SV) model can be regarded as a nonlinear state space model. This article proposes the Laplace approximation method to the nonlinear state space representation and applies it for estimating the SV models. We examine how the approximation works by simulations as well as various empirical studies. The Monte Carlo experiments for the standard SV model indicate that our method is comparable to the Monte-Calro Likelihood (MCL; Durbin and Koopman, 1997), Maximum Likelihood (Fridman and Harris, 1998), and Markov chain Monte Carlo (MCMC) methods in the sense of mean square error in finite sample. The empirical studies for stock markets reveal that our method provides very similar estimates of coefficients to those of the MCL. We show a relationship of our Laplace approximation method to importance sampling.},
author = {Shimada, Junji and Tsukuda, Yoshihiko},
doi = {10.1081/SAC-200055729},
issn = {0361-0918},
journal = {Communications in Statistics - Simulation and Computation},
month = {apr},
number = {2},
pages = {429--450},
publisher = {Taylor {\&} Francis},
title = {{Estimation of Stochastic Volatility Models: An Approximation to the Nonlinear State Space Representation}},
url = {http://dx.doi.org/10.1081/SAC-200055729},
volume = {34},
year = {2005}
}
@article{Brandt1989,
author = {Brandt, E. H.},
journal = {Science},
pages = {349--355},
title = {{Levitation in physics}},
volume = {243},
year = {1989}
}
@article{Aielli2009,
author = {Aielli, Gian Piero},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Aielli - 2009 - Dynamic Conditional Correlations on Properties and Estimation.pdf:pdf},
keywords = {consistency,dynamic conditional correlation,integrated correlation,multivariate garch,step estimation,two-},
title = {{Dynamic Conditional Correlations : on Properties and Estimation}},
year = {2009}
}
@techreport{peresetsky:1,
author = {Korhonen, Iikka and Peresetsky, Anatoly},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Korhonen, Peresetsky - 2013 - What determines stock market behavior in Russia and other emerging countries.pdf:pdf},
institution = {Bank of Finland},
title = {{What determines stock market behavior in Russia and other emerging countries?}},
year = {2013}
}
@article{Yuan2010,
author = {Yuan, By Ming and Cai, T. Tony},
journal = {The Annals of Statistics},
number = {6},
pages = {3412--3444},
title = {{A reproducing kernel Hilbert space approach to functional linear regression}},
volume = {38},
year = {2010}
}
@article{matrices:dawid,
author = {Dawid, A. P.},
journal = {Biometrika},
number = {1},
pages = {265--274},
title = {{Some matrix-variate distribution theory: notational considerations and a Bayesian application}},
volume = {68},
year = {1981}
}
@article{LSTM,
author = {Hochreiter, Sepp and Schmidhuber, J{\"{u}}rgen},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Hochreiter, Schmidhuber - 1997 - Long short-term memory.pdf:pdf},
journal = {Neural Computation},
number = {8},
pages = {1735--1780},
title = {{Long short-term memory}},
volume = {9},
year = {1997}
}
@phdthesis{Grygoryeva2009,
author = {Grygor'yeva, Lyudmyla V.},
pages = {228},
school = {Taras Shevchenko National University of Kyiv},
title = {{Computer technologies in modeling of free magnets dynamics (in Ukrainian)}},
year = {2009}
}
@article{Tsodyks1998,
abstract = {Transmission across neocortical synapses depends on the frequency of presynaptic activity (Thomson {\&} Deuchars, 1994). Interpyramidal synapses in layer V exhibit fast depression of synaptic transmission, while other types of synapses exhibit facilitation of transmission. To study the role of dynamic synapses in network computation, we propose a unified phenomenological model that allows computation of the postsynaptic current generated by both types of synapses when driven by an arbitrary pattern of action potential (AP) activity in a presynaptic population. Using this formalism, we analyze different regimes of synaptic transmission and demonstrate that dynamic synapses transmit different aspects of the presynaptic activity depending on the average presynaptic frequency. The model also allows for derivation of mean-field equations, which govern the activity of large, interconnected networks. We show that the dynamics of synaptic transmission results in complex sets of regular and irregular regimes of netwo...},
author = {Tsodyks, Misha and Pawelzik, Klaus and Markram, Henry},
doi = {10.1162/089976698300017502},
journal = {Neural Computation},
month = {may},
number = {4},
pages = {821--835},
publisher = {MIT Press 238 Main St., Suite 500, Cambridge, MA 02142-1046 USA journals-info@mit.edu},
title = {{Neural networks with dynamic synapses}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/089976698300017502},
volume = {10},
year = {1998}
}
@article{williamson1936algebraic,
author = {Williamson, John},
journal = {American Journal of Mathematics},
number = {1},
pages = {141--163},
publisher = {JSTOR},
title = {{On the algebraic problem concerning the normal forms of linear dynamical systems}},
volume = {58},
year = {1936}
}
@unpublished{Doersch2016,
author = {Doersch, Carl},
title = {{Tutorial on variational autoencoders}},
url = {https://arxiv.org/abs/1606.05908},
year = {2016}
}
@article{Bekinschtein,
author = {Bekinschtein, Tristan A. and Coleman, Martin R. and Niklison, J. and Pickard, John D. and Manes, F.},
journal = {Journal of Neurology Neurosurgery and Psychiatry},
pages = {826--838},
title = {{Can electromyography objectively detect voluntary movement in disorders of consciousness?}},
volume = {79},
year = {2009}
}
@article{sussmann:realization,
author = {Sussmann, Hector},
journal = {Mathematical Systems Theory},
pages = {263--284},
title = {{Existence and uniqueness of realizations of nonlinear systems}},
volume = {10},
year = {1977}
}
@article{alexander:chibumba,
author = {Alexander, Carol and Chibumba, A M},
journal = {Preprint, University of Sussex},
title = {{Multivariate orthogonal factor GARCH}},
year = {1997}
}
@unpublished{KLIC,
author = {Bao, Yong and Lee, Tae-Hwy and Saltoglu, Burak},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Bao, Lee, Saltoglu - 2006 - Comparing density forecast models.pdf:pdf},
title = {{Comparing density forecast models}},
year = {2006}
}
@article{Vamvoudakis2017,
author = {Vamvoudakis, Kyriakos and Modares, Hamidreza and Kiumarsi, Bahare and Lewis, Frank},
journal = {IEEE Control Systems Magazine},
number = {1},
pages = {33--52},
title = {{Game theory-based control system algorithms with real-time reinforcement learning: How to solve multiplayer games online}},
volume = {37},
year = {2017}
}
@book{Cheban:2004,
abstract = {Autonomous dynamical systems -- Non-autonomous dissipative dynamical systems -- Analytic dissipative systems -- The structure of the Levinson center of system with the condition of the hyperbolicity -- Method of Lyapunov functions -- Dissipativity of some classes of equations -- Upper semi-continuity of attractors -- The relationships between pullback, forward and global attractors -- Pullback attractors of C-analytic systems -- Pullback attractors under discretization -- Global attractors of non-autonomous Navier-Stokes equations -- Global attractors of V-monotone dynamical systems -- Linear almost periodic dynamical systems -- Triangular maps.},
author = {Cheban, David N},
isbn = {9812560289},
pages = {503},
publisher = {World Scientific},
title = {{Global Attractors of Non-Autonomous Dissipative Dynamical Systems}},
year = {2004}
}
@misc{Rossi2011,
abstract = {We evaluate predictive density forecasts for a large number of macroeconomic pre- dictors for U.S. output growth and inﬂation. Our focus on predictive density forecasts acknowledges the possibility that, although some predictors can improve or deterio- rate point forecasts, they might have the opposite eﬀect on the uncertainty around the forecasts. Overall, we ﬁnd that the distributional assumptions attributed to commonly used forecasting models are mis-speciﬁed, and the mis-speciﬁcation is mostly related to form of the assumed parametric distribution for both inﬂation and output growth forecasts. There is some evidence of violations of the independence and identical dis- tribution assumptions as well. The mis-speciﬁcation is more pronounced for inﬂation than for output growth.},
author = {Rossi, Barbara and Sekhposyan, Tatevik},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Rossi, Sekhposyan - 2011 - Evaluating Density Forecasts for U.S. Output Growth and Inflation in a Large Macroeconomic Data Set.pdf:pdf},
keywords = {Density Forecasts,Forecast Evaluation,Instability,Structural Change},
pages = {1--36},
title = {{Evaluating Density Forecasts for U.S. Output Growth and Inflation in a Large Macroeconomic Data Set}},
year = {2011}
}
@article{newman2018necessary,
author = {Newman, Julian},
journal = {Ergodic Theory and Dynamical Systems},
number = {5},
pages = {1857--1875},
publisher = {Cambridge University Press},
title = {{Necessary and sufficient conditions for stable synchronization in random dynamical systems}},
volume = {38},
year = {2018}
}
@article{maassFinite,
abstract = {We discuss in this short survey article some current mathematical models from neurophysiology for the computational units of biological neural systems: neurons and synapses. These models are contrasted with the computational units of common artificial neural network models, which reflect the state of knowledge in neurophysiology 50 years ago. We discuss the problem of carrying out computations in circuits consisting of biologically realistic computational units, focusing on the biologically particularly relevant case of computations on time series. Finite state machines are frequently used in computer science as models for computations on time series. One may argue that these models provide a reasonable common conceptual basis for analyzing computations in computers and biological neural systems, although the emphasis in biological neural systems is shifted more towards asynchronous computation on analog time series. In the second half of this article some new computer experiments and theoretical results are discussed, which address the question whether a biological neural system can, in principle, learn to behave like a given simple finite state machine. {\textcopyright} 2002 Elsevier Science B.V. All rights reserved.},
author = {Natschl{\"{a}}ger, Thomas and Maass, Wolfgang},
doi = {10.1016/S0304-3975(02)00099-3},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Natschl{\"{a}}ger, Maass - 2002 - Spiking neurons and the induction of finite state machines.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Computational neuroscience,Dynamic synapses,Finite state machines,Grammatical inference,Spiking neurons},
number = {1},
pages = {251--265},
title = {{Spiking neurons and the induction of finite state machines}},
volume = {287},
year = {2002}
}
@book{bloch2015nonholonomicbook,
author = {Bloch, Anthony M},
edition = {Second},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley//Bloch - 2015 - Nonholonomic Mechanics and Control.pdf:pdf},
publisher = {Springer},
title = {{Nonholonomic Mechanics and Control}},
year = {2015}
}
@article{hermans:rkhs,
author = {Hermans, M and Schrauwen, B},
journal = {Neural Computation},
pages = {104--133},
title = {{Recurrent kernel machines: computation with infinite echo state networks}},
volume = {24},
year = {2012}
}
@article{Palm1992,
author = {Palm, Franz C. and Zellner, Arnold},
doi = {10.1002/for.3980110806},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Palm, Zellner - 1992 - To combine or not to combine issues of combining forecasts.pdf:pdf},
issn = {02776693},
journal = {Journal of Forecasting},
month = {dec},
number = {8},
pages = {687--701},
title = {{To combine or not to combine? issues of combining forecasts}},
url = {http://doi.wiley.com/10.1002/for.3980110806},
volume = {11},
year = {1992}
}
@article{sandberg:bilinear,
author = {Sandberg, I.W.},
journal = {Circuits, Systems, and Signal Processing},
number = {6},
pages = {691--702},
title = {{On the stability of bilinear filters}},
volume = {17},
year = {1998}
}
@article{clapp:puppe:1991,
author = {Clapp, M. and Puppe, D.},
journal = {J. reine. angew. Math.},
pages = {1--29},
title = {{Critical point theory with symmetries}},
volume = {418},
year = {1991}
}
@article{Badescu:Cui:Ortega:2015,
author = {Badescu, Alexandru and Cui, Zhenyu and Ortega, Juan-Pablo},
journal = {Preprint},
title = {{Option pricing under exponential linear pricing kernels: from GARCH to diffusions}},
year = {2015}
}
@article{duistermaat:heckman:formula,
author = {Duistermaat, J. J. and Heckman, G. J.},
journal = {Invent. Math.},
pages = {259--268},
title = {{On the variation of the cohomology of the symplectic form ofthe reduced phase space}},
volume = {69},
year = {1982}
}
@article{Marcellino2003,
author = {Marcellino, Massimiliano and Stock, James H and Watson, Mark W},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Marcellino, Stock, Watson - 2003 - Macroeconomic forecasting in the Euro area Country specific versus area-wide information.pdf:pdf},
issn = {00142921},
journal = {European Economic Review},
month = {feb},
number = {1},
pages = {1--18},
title = {{Macroeconomic forecasting in the Euro area: Country specific versus area-wide information}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0014292102002064},
volume = {47},
year = {2003}
}
@article{Koopman2016,
author = {Koopman, Siem Jan and Lucas, Andr{\'{e}} and Scharth, Marcel},
journal = {The Review of Economics and Statistics},
number = {1},
pages = {97--110},
title = {{Predicting time-varying parameters with parameter-driven and observation-driven models}},
volume = {98},
year = {2016}
}
@article{White2004,
author = {White, Olivia and Lee, Daniel and Sompolinsky, Haim},
issn = {0031-9007},
journal = {Physical Review Letters},
month = {apr},
number = {14},
pages = {148102},
title = {{Short-Term Memory in Orthogonal Neural Networks}},
volume = {92},
year = {2004}
}
@inproceedings{Neyshabur2015,
abstract = {We investigate the capacity, convexity and characterization of a general family of norm-constrained feed-forward networks.},
archivePrefix = {arXiv},
arxivId = {arXiv:1503.00036v2},
author = {Neyshabur, Behnam and Tomioka, Ryota and Srebro, Nathan},
booktitle = {Conference on Learning Theory},
eprint = {arXiv:1503.00036v2},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Neyshabur, Tomioka, Srebro - 2015 - Norm-based capacity control in neural networks.pdf:pdf},
issn = {15337928},
keywords = {Deep Learning,Feed-Forward Neural Networks,Scale-Sensitive Capacity Control},
pages = {1376--1401},
title = {{Norm-based capacity control in neural networks}},
year = {2015}
}
@article{Andersen1998,
abstract = {A voluminous literature has emerged for modeling the temporal dependencies in financial market volatility using ARCH and stochastic volatility models. While most of these studies have documented highly significant in-sample parameter estimates and pronounced intertemporal volatility persistence, traditional ex-post forecast evaluation criteria suggest that the models provide seemingly poor volatility forecasts. Contrary to this contention, we show that volatility models produce strikingly accurate interdaily forecasts for the latent volatility factor that would be of interest in most financial applications. New methods for improved ex-post interdaily volatility measurements based on high-frequency intradaily data are also discussed.},
author = {Andersen, Torben G and Bollerslev, Tim},
issn = {00206598},
journal = {International Economic Review},
number = {4},
pages = {885--905},
publisher = {Wiley-Blackwell for the Economics Department of the University of Pennsylvania and Institute of Social and Economic Research -- Osaka University},
title = {{Answering the skeptics: Yes, standard volatility models do provide accurate forecasts}},
url = {http://www.jstor.org/stable/2527343},
volume = {39},
year = {1998}
}
@article{LeCun1989,
author = {LeCun, Y. and Boser, B. and Denker, J. S. and Henderson, D. and Howard, R. E. and Hubbard, W. and Jackel, L. D.},
institution = {AT$\backslash${\&}T Bell Laboratories},
journal = {Neural Computation},
pages = {541--551},
title = {{Backpropagation applied to handwritten zip code recognition}},
volume = {1},
year = {1989}
}
@misc{Galvao2007,
author = {Galv{\~{a}}o, A B},
keywords = {asset prices,c22,c53,e44,group,i would like to,jel codes,ken wallis,mary econometrics reading,midas,nonlinear time,output growth,participants of the queen,predictive ability,smooth transition,thank mike clements,the 2006 esem and,the conference of 50,the udine workshop on,years of econometrics},
title = {{Changes in predictive ability with mixed frequency data}},
url = {http://www.cardiff.ac.uk/carbs/econ/resources/seminars/galvaowpqmul.pdf},
year = {2007}
}
@article{Vuckovic2002,
abstract = {We present a novel method for classifying alert vs drowsy states from 1 s long sequences of full spectrum EEG recordings in an arbitrary subject. This novel method uses time series of interhemispheric and intrahemispheric cross spectral densities of full spectrum EEG as the input to an artificial neural network (ANN) with two discrete outputs: drowsy and alert. The experimental data were collected from 17 subjects. Two experts in EEG interpretation visually inspected the data and provided the necessary expertise for the training of an ANN. We selected the following three ANNs as potential candidates: (1) the linear network with Widrow-Hoff (WH) algorithm; (2) the non-linear ANN with the Levenberg-Marquardt (LM) rule; and (3) the Learning Vector Quantization (LVQ) neural network. We showed that the LVQ neural network gives the best classification compared with the linear network that uses WH algorithm (the worst), and the non-linear network trained with the LM rule. Classification properties of LVQ were validated using the data recorded in 12 healthy volunteer subjects, yet whose EEG recordings have not been used for the training of the ANN. The statistics were used as a measure of potential applicability of the LVQ: the t-distribution showed that matching between the human assessment and the network output was 94.37+/-1.95{\%}. This result suggests that the automatic recognition algorithm is applicable for distinguishing between alert and drowsy state in recordings that have not been used for the training.},
author = {Vuckovic, Aleksandra and Radivojevic, Vlada and Chen, Andrew C. N. and Popovic, Dejan},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Vuckovic et al. - 2002 - Automatic recognition of alertness and drowsiness from EEG by an artificial neural network.pdf:pdf},
issn = {1350-4533},
journal = {Medical engineering {\&} physics},
keywords = {Adult,Computer-Assisted,Electroencephalography,Electroencephalography: methods,Female,Humans,Male,Neural Networks (Computer),Sensitivity and Specificity,Signal Processing,Sleep Stages,Sleep Stages: physiology,Wakefulness,Wakefulness: classification,Wakefulness: physiology},
month = {jun},
number = {5},
pages = {349--360},
pmid = {12052362},
title = {{Automatic recognition of alertness and drowsiness from EEG by an artificial neural network}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12052362},
volume = {24},
year = {2002}
}
@book{marsden_complex_analysis,
author = {Marsden, Jerrold E. and Hoffman, Michael J.},
edition = {Third},
publisher = {W. H. Freeman and Company},
title = {{Basic Complex Analysis}},
year = {1999}
}
@book{aubin:book,
author = {Aubin, Thierry},
isbn = {3540607528},
publisher = {Springer-Verlag Berlin Heidelberg},
title = {{Some Nonlinear Problems in Riemannian Geometry}},
year = {1998}
}
@article{Brennan,
author = {Brennan, M. J.},
journal = {Journal of Finance},
number = {1},
pages = {53--68},
title = {{The pricing of contingent claims in discrete time models}},
volume = {24},
year = {1979}
}
@inproceedings{Arjovsky2017,
abstract = {We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to other distances between distributions.},
archivePrefix = {arXiv},
arxivId = {1701.07875},
author = {Arjovsky, Martin and Chintala, Soumith and Bottou, Leon},
booktitle = {International Conference on Machine Learning},
doi = {10.1080/15563650600584519},
eprint = {1701.07875},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Arjovsky, Chintala, Bottou - 2017 - Wasserstein Generative Adversarial Network.pdf:pdf},
issn = {1938-7228},
pages = {1--44},
pmid = {16749549},
title = {{Wasserstein Generative Adversarial Network}},
year = {2017}
}
@unpublished{Guilmeau-baron2003,
author = {Guilmeau-baron, H{\'{e}}l{\`{e}}ne and Baron, Guillaume and Petithuguenin, S{\'{e}}bastien},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Guilmeau-baron, Baron, Petithuguenin - 2003 - Un Indicateur de Retournement Conjoncturel dans la Zone Euro.pdf:pdf},
institution = {Minist{\`{e}}re de l'Economie, des Finances et de l'Industrie},
title = {{Un Indicateur de Retournement Conjoncturel dans la Zone Euro}},
year = {2003}
}
@article{RC20,
author = {Gonon, Lukas and Ortega, Juan-Pablo},
journal = {Neural Networks},
pages = {10--13},
title = {{Fading memory echo state networks are universal}},
volume = {138},
year = {2021}
}
@article{Taylor2017,
author = {Taylor, Nick},
journal = {International Journal of Forecasting},
pages = {770--785},
title = {{Realised variance forecasting under Box-Cox transformations}},
volume = {33},
year = {2017}
}
@article{MR1903168,
author = {Duan, Jin-Chuan and Popova, Ivilina and Ritchken, Peter},
issn = {1469-7688},
journal = {Quant. Finance},
number = {2},
pages = {116--132},
title = {{Option pricing under regime switching}},
volume = {2},
year = {2002}
}
@article{Foresi2005,
abstract = {From a large options data set on major equity indexes across the world, the authors find that worldwide, implied volatilities of options on equity indexes exhibit strikingly similar behaviors. When plotted against moneyness, implied volatilities show a heavily skewed smirk pattern, implying that out–of–the–money put options are more expensive than the corresponding out–of–the–money call options and that the risk–neutral return distribution for these indexes is heavily negatively skewed. Furthermore, as the option maturity increases from one month to five years, the implied volatility smirk does not flatten out but steepens, indicating that the risk–neutral distribution of equity index returns becomes even more negatively skewed at longer horizons. The average term structure of the implied volatility level is relatively flat, and the standard deviation of the implied volatility declines as maturity increases. Although fairly persistent, the implied volatility series are stationary. Finally, principal compo...},
author = {Foresi, Silverio and Wu, Liuren},
issn = {1074-1240},
journal = {The Journal of Derivatives},
language = {en},
month = {jan},
number = {2},
pages = {8--21},
publisher = {Institutional Investor Journals},
title = {{Crash–O–Phobia}},
url = {http://www.iijournals.com/doi/abs/10.3905/jod.2005.605352?journalCode=jod},
volume = {13},
year = {2005}
}
@book{Wei:book,
author = {Wei, William W. S.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Wei - 2006 - Time Series Analysis. Univariate and Multivariate Methods.pdf:pdf},
publisher = {Pearson, Addison Wesley},
title = {{Time Series Analysis. Univariate and Multivariate Methods}},
year = {2006}
}
@unpublished{Ruthotto2018,
author = {Ruthotto, Lars and Haber, Eldad},
title = {{Deep neural networks motivated by partial differential equations}},
year = {2018}
}
@article{pelletier:dcc,
author = {Pelletier, Denis},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Pelletier - 2006 - Regime switching for dynamic correlations.pdf:pdf},
journal = {Journal of Econometrics},
number = {1-2},
pages = {445--473},
title = {{Regime switching for dynamic correlations}},
volume = {131},
year = {2006}
}
@incollection{Koprinkova-Hristova2015,
author = {Koprinkova-Hristova, P. and Bozhkov, L. and Georgieva, P.},
booktitle = {Practical Applications of Agents, Multi-Agent Systems, and Sustainability: The PAAMS Collection},
doi = {10.1007/978-3-319-18944-4_11},
isbn = {978-3-319-19032-7},
keywords = {Affective computing,EEG data classification and clustering,Echo state network,Feature selection},
pages = {131--141},
publisher = {Springer Verlag},
title = {{Echo state networks for feature selection in affective computing}},
url = {http://link.springer.com/10.1007/978-3-319-19033-4},
year = {2015}
}
@article{Barron1993,
author = {Barron, A.R.},
doi = {10.1109/18.256500},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Barron - 1993 - Universal approximation bounds for superpositions of a sigmoidal function(3).pdf:pdf},
issn = {00189448},
journal = {IEEE Transactions on Information Theory},
month = {may},
number = {3},
pages = {930--945},
title = {{Universal approximation bounds for superpositions of a sigmoidal function}},
url = {http://ieeexplore.ieee.org/document/256500/},
volume = {39},
year = {1993}
}
@book{Jacob2012,
author = {Jacob, Birgit and Zwart, Hans},
booktitle = {Linear Port-Hamiltonian Systems on Infinite-dimensional Spaces},
doi = {10.1007/978-3-0348-0399-1},
isbn = {978-3-0348-0398-4},
publisher = {Birkh{\"{a}}user},
title = {{Linear Port-Hamiltonian Systems on Infinite-dimensional Spaces}},
year = {2012}
}
@article{Pantelidis2004,
author = {Pantelidis, T},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Pantelidis - 2004 - Testing for Granger causality in variance in the presence of causality in mean.pdf:pdf},
issn = {01651765},
journal = {Economics Letters},
keywords = {c14,c22,causality in mean,causality in variance,garch,jel classification},
month = {nov},
number = {2},
pages = {201--207},
title = {{Testing for Granger causality in variance in the presence of causality in mean}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0165176504001697},
volume = {85},
year = {2004}
}
@book{dudley2018real,
author = {Dudley, Richard M},
publisher = {CRC Press},
title = {{Real analysis and probability}},
year = {2018}
}
@article{Diron2008,
author = {Diron, Marie},
issn = {02776693},
journal = {Journal of Forecasting},
month = {aug},
number = {5},
pages = {371--390},
title = {{Short-term forecasts of euro area real GDP growth: an assessment of real-time performance based on vintage data}},
url = {http://doi.wiley.com/10.1002/for.1067},
volume = {27},
year = {2008}
}
@inproceedings{YJL:15,
author = {Yang, Weixin and Jin, Lianwen and Liu, Manfei},
booktitle = {2015 13th International Conference on Document Analysis and Recognition (ICDAR)},
organization = {IEEE},
pages = {546--550},
title = {{Chinese character-level writer identification using path signature feature, DropStroke and deep CNN}},
year = {2015}
}
@article{ci85,
author = {Cari{\~{n}}ena, J. F. and Ibort, L. A.},
journal = {Il Nuovo Cimento},
pages = {41--49},
title = {{Locally Hamiltonian systems with symmetry and a generalized Noether's theorem}},
volume = {87B},
year = {1985}
}
@article{RV2008Barndorff,
author = {Barndorff-Nielsen, Ole E. and Hansen, P. Reinhard and Lunde, Asger and Shephard, Neil},
journal = {Econometrica},
number = {6},
pages = {1481--1536},
title = {{Designing realized kernels to measure the ex post variation of equity prices in the presence of noise}},
volume = {76},
year = {2008}
}
@misc{Engle2008,
abstract = {Building models for high dimensional portfolios is important in risk management and asset allocation. Here we propose a novel and fast way of estimating models of time-varying covariances that overcome an undiagnosed incidental parameter problem which has troubled existing methods when applied to hundreds or even thousands of assets. Indeed we can handle the case where the cross-sectional dimension is larger than the time series one. The theory of this new strategy is developed in some detail, allowing formal hypothesis testing to be carried out on these models. Simulations are used to explore the performance of this inference strategy while empirical examples are reported which show the strength of this method. The out of sample hedging performance of various models estimated using this method are compared.},
author = {Pakel, Cavit and Engle, Robert F. and Shephard, Neil and Sheppard, Kevin K.},
booktitle = {SSRN eLibrary},
doi = {10.2139/ssrn.1354497},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Pakel et al. - 2014 - Fitting Vast Dimensional Time-Varying Covariance Models.pdf:pdf},
publisher = {SSRN},
title = {{Fitting Vast Dimensional Time-Varying Covariance Models}},
url = {http://ssrn.com/paper=1354497},
year = {2014}
}
@article{Ceriotti2013,
author = {Ceriotti, Michele and Tribello, Gareth A and Parrinello, Michele},
doi = {10.1021/ct3010563},
journal = {Journal of Chemical Theory and Computation},
number = {3},
pages = {1521--1532},
title = {{Demonstrating the transferability and the descriptive power of sketch-map}},
volume = {9},
year = {2013}
}
@article{KRMK11,
author = {Keller-Ressel, Martin and Muhle-Karbe, Johannes},
issn = {0949-2984},
journal = {Finance and Stochastics},
month = {mar},
number = {1},
pages = {107--133},
title = {{Asymptotic and exact pricing of options on variance}},
url = {http://link.springer.com/10.1007/s00780-012-0178-z},
volume = {17},
year = {2012}
}
@inproceedings{Atlas1997,
author = {Atlas, L. and Droppo, J. and McLaughlin, J.},
booktitle = {Proceedings of SPIE The International Society for Optical Engineering},
pages = {161--171},
title = {{Optimizing time-frequency distributions for automatic classification}},
volume = {3162},
year = {1997}
}
@book{Tamm1979,
author = {Tamm, I. E.},
publisher = {Mir},
title = {{Fundamentals of the theory of electricity (in Russian)}},
year = {1979}
}
@article{sandberg:uniform:nonlinear,
author = {Sandberg, Irwin W.},
doi = {10.1002/cta.269},
issn = {00989886},
journal = {International Journal of Circuit Theory and Applications},
keywords = {Approximately finite memory,Input-output maps,Non-linear systems,Time-invariant systems,Uniform approximation},
number = {3},
pages = {105--116},
title = {{Uniform approximation of time-invariant non-linear systems}},
volume = {32},
year = {2004}
}
@article{cartan:1909,
author = {Cartan, {\'{E}}.},
journal = {Ann. Ec. Norm. Sup.},
pages = {93--161},
title = {{Les groupes continus, infinis, simples}},
volume = {26},
year = {1909}
}
@misc{Koop2011,
abstract = {This paper compares the forecasting performance of different models which have been proposed for forecasting in the presence of structural breaks. These models differ in their treatment of the break process, the parameters defining the model which applies in each regime and the out-of-sample probability of a break occurring. In an extensive empirical evaluation involving many important macroeconomic time series, we demonstrate the presence of structural breaks and their importance for forecasting in the vast majority of cases. However, we find no single forecasting model consistently works best in the presence of structural breaks. In many cases, the formal modeling of the break process is important in achieving good forecast performance. However, there are also many cases where simple, rolling OLS forecasts perform well.},
author = {Bauwens, Luc and Koop, Gar and Korobilis, Dimitris and Rombouts, Jeroen V.K.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Bauwens et al. - 2011 - A Comparison of Forecasting Procedures for Macroeconomic Series the Contribution of Structural Break Models.pdf:pdf},
institution = {CIRPEE},
keywords = {Bayesian inference,Forecasting,Markov switching,change-points},
title = {{A Comparison of Forecasting Procedures for Macroeconomic Series : the Contribution of Structural Break Models}},
year = {2011}
}
@article{Duarte2004,
author = {Duarte, Agustin and Venetis, Ioannis A. Ionnis A. and Paya, Ivan},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Duarte, Venetis, Paya - 2005 - Predicting real growth and the probability of recession in the Euro area using the yield spread.pdf:pdf;:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Duarte, Venetis, Paya - 2004 - Predicting real growth and the probability of recession in the euro area using the yield spread.pdf:pdf},
institution = {Instituto Valenciano de Investigaciones Econ{\'{o}}micas},
issn = {01692070},
journal = {Applied Economics},
keywords = {forecasting accuracy,growth,recession,term spread and real,threshold models},
month = {apr},
number = {2},
pages = {261--277},
title = {{Predicting real growth and the probability of recession in the Euro area using the yield spread}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0169207004000779},
volume = {21},
year = {2004}
}
@article{DeMassari2013,
abstract = {Patients in the completely locked-in state have no means of communication and they represent the target population for brain-computer interface research in the last 15 years. Although different paradigms have been tested and different physiological signals used, to date no sufficiently documented completely locked-in state patient was able to control a brain-computer interface over an extended time period. We introduce Pavlovian semantic conditioning to enable basic communication in completely locked-in state. This novel paradigm is based on semantic conditioning for online classification of neuroelectric or any other physiological signals to discriminate between covert (cognitive) 'yes' and 'no' responses. The paradigm comprised the presentation of affirmative and negative statements used as conditioned stimuli, while the unconditioned stimulus consisted of electrical stimulation of the skin paired with affirmative statements. Three patients with advanced amyotrophic lateral sclerosis participated over an extended time period, one of which was in a completely locked-in state, the other two in the locked-in state. The patients' level of vigilance was assessed through auditory oddball procedures to study the correlation between vigilance level and the classifier's performance. The average online classification accuracies of slow cortical components of electroencephalographic signals were around chance level for all the patients. The use of a non-linear classifier in the offline classification procedure resulted in a substantial improvement of the accuracy in one locked-in state patient achieving 70{\%} correct classification. A reliable level of performance in the completely locked-in state patient was not achieved uniformly throughout the 37 sessions despite intact cognitive processing capacity, but in some sessions communication accuracies up to 70{\%} were achieved. Paradigm modifications are proposed. Rapid drop of vigilance was detected suggesting attentional variations or variations of circadian period as important factors in brain-computer interface communication with locked-in state and completely locked-in state.},
author = {{De Massari}, Daniele and Ruf, Carolin A and Furdea, Adrian and Matuz, Tamara and van der Heiden, Linda and Halder, Sebastian and Silvoni, Stefano and Birbaumer, Niels},
issn = {1460-2156},
journal = {Brain : a journal of neurology},
keywords = {Adult,Aged,Brain,Brain: pathology,Brain: physiology,Conditioning (Psychology),Conditioning (Psychology): physiology,Electroencephalography,Electroencephalography: methods,Female,Humans,Male,Quadriplegia,Quadriplegia: diagnosis,Quadriplegia: physiopathology,Quadriplegia: psychology},
month = {jun},
number = {Pt 6},
pages = {1989--2000},
title = {{Brain communication in the locked-in state.}},
url = {http://brain.oxfordjournals.org/content/136/6/1989.short},
volume = {136},
year = {2013}
}
@article{Horst2013,
abstract = {We present 1-to-8 wavelength (de-)multiplexer devices based on a binary tree of cascaded Mach-Zehnder-like lattice filters, and manufactured using a 90 nm CMOS-integrated silicon photonics technology. We demonstrate that these devices combine a flat pass-band over more than 50{\{}{\%}{\}} of the channel spacing with low insertion loss of less than 1.6 dB, and have a small device size of approximately 500 × 400 {\$}\mu{\$}m. This makes this type of filters well suited for application as WDM (de-)multiplexer in silicon photonics transceivers for optical data communication in large scale computer systems.},
author = {Horst, Folkert and Green, William M J and Assefa, Solomon and Shank, Steven M and Vlasov, Yurii A and Offrein, Bert J},
doi = {10.1364/OE.21.011652},
issn = {1094-4087},
journal = {Optics Express},
number = {10},
pages = {11652--11658},
pmid = {23736388},
title = {{Cascaded Mach-Zehnder wavelength filters in silicon photonics for low loss and flat pass-band WDM (de-) multiplexing}},
url = {http://www.opticsinfobase.org/abstract.cfm?URI=oe-21-10-11652},
volume = {21},
year = {2013}
}
@book{dirac:64,
author = {Dirac, P. A. M.},
publisher = {Academic Press},
title = {{Lectures on Quantum Mechanics}},
year = {1964}
}
@article{BonatoRV2012,
author = {Bonato, M. and Caporin, Massimiliano and Ranaldo, A.},
journal = {The European Journal of Finance},
number = {9},
pages = {761--774},
title = {{A forecast-based comparison of re- stricted wishart autoregressive models for realized covariance matrices}},
volume = {18},
year = {2012}
}
@article{Hansen1992,
author = {Hansen, B. E.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Hansen - 1992 - The likelihood ratio test under nonstandard conditions Testing the markov switching model of gnp.pdf:pdf},
issn = {08837252},
journal = {Journal of Applied Econometrics},
month = {dec},
number = {S1},
pages = {S61--S82},
title = {{The likelihood ratio test under nonstandard conditions: Testing the markov switching model of gnp}},
url = {http://doi.wiley.com/10.1002/jae.3950070506},
volume = {7},
year = {1992}
}
@article{Boussama2000,
author = {Boussama, Farid},
journal = {C. R. Acad. Sci. Paris S{\{}{\'{e}}{\}}r. I Math.},
pages = {81--84},
title = {{Normalit{\'{e}} asymptotique de l'estimateur du pseudo-maximum de vraisemblance d'un mod{\`{e}}le GARCH}},
volume = {331},
year = {2000}
}
@incollection{ccccc,
author = {Marcellino, Massimiliano},
booktitle = {Handbook of Economic Forecasting},
chapter = {Leading In},
edition = {Elsevier},
editor = {Elliott, Graham and Granger, Clive W.J. and Timmermann, Allan},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Marcellino - 2011 - Leading Indicators.pdf:pdf},
number = {05},
pages = {879--960},
title = {{Leading Indicators}},
volume = {1},
year = {2011}
}
@unpublished{Bordo2003,
author = {Bordo, Michael},
booktitle = {The American Political Science Review},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Bordo - 2003 - Stock Market Crashes, Productivity Boom Busts and Recessions Some Historical Evidence.pdf:pdf},
institution = {Rutgers University},
month = {dec},
number = {4},
title = {{Stock Market Crashes, Productivity Boom Busts and Recessions: Some Historical Evidence}},
volume = {79},
year = {2003}
}
@article{abudsartori81,
author = {Abud, M and Sartori, G},
journal = {Physics Letters},
pages = {147--152},
title = {{The geometry of orbit - space and natural minima of Higgs potentials}},
volume = {104B},
year = {1981}
}
@article{Saad1998,
author = {Saad, E. and Prokhorov, D. and Wunsch, D.},
journal = {IEEE Transactions on Biomedical Engineering},
number = {6},
pages = {1456--1470},
title = {{Comparative study of stock trend prediction using time delay, recurrent and probabilistic neural networks}},
volume = {9},
year = {1998}
}
@article{Francq2000,
author = {Francq, Christian and Zako{\"{i}}an, Jean-Michel},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Francq, Zako{\"{i}}an - 2000 - Estimating weak GARCH representations.pdf:pdf},
journal = {Econometric Theory},
language = {English},
month = {oct},
number = {05},
pages = {692--728},
publisher = {Cambridge University Press},
title = {{Estimating weak GARCH representations}},
volume = {16},
year = {2000}
}
@incollection{Bharucha-Reid1972,
author = {Bharucha-Reid, A. T.},
booktitle = {Random Integral Equations},
chapter = {1},
doi = {10.1016/S0076-5392(08)60804-8},
month = {jan},
pages = {7--63},
publisher = {Elsevier},
title = {{Probability theory in Banach spaces: an introductory survey}},
url = {http://www.sciencedirect.com/science/article/pii/S0076539208608048},
year = {1972}
}
@article{ottSeparChaotic2020,
author = {Krishnagopal, Sanjukta and Girvan, Michelle and Ott, Edward and Hunt, Brian},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Krishnagopal et al. - 2020 - Separation of chaotic signals by reservoir computing.pdf:pdf},
journal = {Chaos},
number = {023123},
title = {{Separation of chaotic signals by reservoir computing}},
volume = {30},
year = {2020}
}
@unpublished{Phillips2003,
author = {Phillips, Peter C.B. and Sun, Yixiao and Jin, Sainan},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Phillips, Sun, Jin - 2003 - Consistent HAC estimation and robust regression testing using sharp origin kernels with no truncation.pdf:pdf},
number = {1407},
title = {{Consistent HAC estimation and robust regression testing using sharp origin kernels with no truncation}},
year = {2003}
}
@article{Subasi2006,
abstract = {An accurate and computationally efficient means of classifying electromyographic (EMG) signal patterns has been the subject of considerable research effort in recent years. Quantitative analysis of EMG signals provides an important source of information for the diagnosis of neuromuscular disorders. Following the recent development of computer-aided EMG equipment, different methodologies in the time domain and frequency domain have been followed for quantitative analysis. In this study, feedforward error backpropagation artificial neural networks (FEBANN) and wavelet neural networks (WNN) based classifiers were developed and compared in relation to their accuracy in classification of EMG signals. In these methods, we used an autoregressive (AR) model of EMG signals as an input to classification system. A total of 1200 MUPs obtained from 7 normal subjects, 7 subjects suffering from myopathy and 13 subjects suffering from neurogenic disease were analyzed. The success rate for the WNN technique was 90.7{\%} and for the FEBANN technique 88{\%}. The comparisons between the developed classifiers were primarily based on a number of scalar performance measures pertaining to the classification. The WNN-based classifier outperformed the FEBANN counterpart. The proposed WNN classification may support expert decisions and add weight to EMG differential diagnosis.},
author = {Subasi, Abdulhamit and Yilmaz, Mustafa and Ozcalik, Hasan Riza},
doi = {10.1016/j.jneumeth.2006.03.004},
issn = {0165-0270},
journal = {Journal of neuroscience methods},
keywords = {Adolescent,Adult,Algorithms,Child,Electromyography,Electromyography: classification,Electromyography: instrumentation,Electromyography: statistics {\&} numerical data,Female,Humans,Male,Models,Muscular Diseases,Muscular Diseases: physiopathology,Neural Networks (Computer),Reference Values,Regression Analysis,Reproducibility of Results,Statistical},
month = {sep},
number = {1-2},
pages = {360--367},
pmid = {16621003},
title = {{Classification of EMG signals using wavelet neural network}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16621003},
volume = {156},
year = {2006}
}
@article{ferreira2013,
abstract = {Reservoir computing is a framework for computation like a recurrent neural network that allows for the black box modeling of dynamical systems. In contrast to other recurrent neural network approaches, reservoir computing does not train the input and internal weights of the network, only the readout is trained. However it is necessary to adjust parameters to create a "good" reservoir for a given application. In this study we introduce a method, called RCDESIGN (reservoir computing and design training). RCDESIGN combines an evolutionary algorithm with reservoir computing and simultaneously looks for the best values of parameters, topology and weight matrices without rescaling the reservoir matrix by the spectral radius. The idea of adjust the spectral radius within the unit circle in the complex plane comes from the linear system theory. However, this argument does not necessarily apply to nonlinear systems, which is the case of reservoir computing. The results obtained with the proposed method are compared with results obtained by a genetic algorithm search for global parameters generation of reservoir computing. Four time series were used to validate RCDESIGN. ?? 2012 Elsevier Ltd. All rights reserved.},
author = {Ferreira, Aida A. and Ludermir, Teresa B. and {De Aquino}, Ronaldo R B},
doi = {10.1016/j.eswa.2013.01.029},
isbn = {0957-4174},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Echo state networks,Evolutionary algorithm,Reservoir computing},
number = {10},
pages = {4172--4182},
title = {{An approach to reservoir computing design and training}},
url = {http://dx.doi.org/10.1016/j.eswa.2013.01.029},
volume = {40},
year = {2013}
}
@article{Ganguli2008,
abstract = {To perform nontrivial, real-time computations on a sensory input stream, biological systems must retain a short-term memory trace of their recent inputs. It has been proposed that generic high-dimensional dynamical systems could retain a memory trace for past inputs in their current state. This raises important questions about the fundamental limits of such memory traces and the properties required of dynamical systems to achieve these limits. We address these issues by applying Fisher information theory to dynamical systems driven by time-dependent signals corrupted by noise. We introduce the Fisher Memory Curve (FMC) as a measure of the signal-to-noise ratio (SNR) embedded in the dynamical state relative to the input SNR. The integrated FMC indicates the total memory capacity. We apply this theory to linear neuronal networks and show that the capacity of networks with normal connectivity matrices is exactly 1 and that of any network of N neurons is, at most, N. A nonnormal network achieving this bound is subject to stringent design constraints: It must have a hidden feedforward architecture that superlinearly amplifies its input for a time of order N, and the input connectivity must optimally match this architecture. The memory capacity of networks subject to saturating nonlinearities is further limited, and cannot exceed square root N. This limit can be realized by feedforward structures with divergent fan out that distributes the signal across neurons, thereby avoiding saturation. We illustrate the generality of the theory by showing that memory in fluid systems can be sustained by transient nonnormal amplification due to convective instability or the onset of turbulence.},
author = {Ganguli, Surya and Huh, Dongsung and Sompolinsky, Haim},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Information Theory,Mathematics,Memory,Memory: physiology,Models,Neural Networks (Computer),Neural Pathways,Neurological,Neurons,Neurons: metabolism},
month = {dec},
number = {48},
pages = {18970--5},
title = {{Memory traces in dynamical systems.}},
volume = {105},
year = {2008}
}
@article{Sarishvili2006,
abstract = {We describe a nonlinear regression problem, where the regression functions have an additive structure and the dependent variable is a one-dimensional time series. Multivariate time series with unknown time delay operators are used as independent variables. By fitting a feedforward neural network with block structure to the data, we estimated the additive regression function and, parallel to this, the time lags. We present the consistency proof of neural network weights estimator and the time lag estimator independently from each other. In the practical part of the article, we present the useful feature of blocked neural networks to estimate the relevance measures of each input variable in a simple way. Furthermore, we propose an approach to solve the well-known variable selection problem for the class of nonlinear multivariate beta-mixing time series models considered here. Finally, we apply the methodology to an artificial example.},
author = {Sarishvili, A. and Andersson, Ch. and Franke, J. and Kroisandt, G.},
doi = {10.1162/neco.2006.18.10.2568},
journal = {Neural Computation},
month = {oct},
number = {10},
pages = {2568--2581},
publisher = {MIT Press 238 Main St., Suite 500, Cambridge, MA 02142-1046 USA journals-info@mit.edu},
title = {{On the consistency of the blocked neural network estimator in time series analysis}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/neco.2006.18.10.2568},
volume = {18},
year = {2006}
}
@unpublished{Bekierman2016,
author = {Bekierman, Jeremias and Manner, Hans},
title = {{Improved forecasting of realized variance measures}},
year = {2016}
}
@article{Kozorez1978,
author = {Kozorez, V. V. and Cheborin, O. G.},
journal = {Bull. of the Ac. of Sc. of USSR. Series A (in Russian)},
pages = {995--998},
title = {{On one collinear case of the problem of three magnets}},
volume = {11},
year = {1978}
}
@incollection{bates:prices,
address = {Amsterdam},
author = {Bates, D.},
booktitle = {Handbook of Statistics, Statistical Methods in Finance},
editor = {Maddala, G. S. and Rao, C. R.},
pages = {567--611},
publisher = {Elsevier},
title = {{Testing option pricing models}},
year = {1996}
}
@incollection{Kalman2010,
address = {Berlin, Heidelberg},
author = {Kalman, R.E.},
booktitle = {Controllability and Observability},
doi = {10.1007/978-3-642-11063-4_1},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Kalman - 2010 - Lectures on Controllability and Observability.pdf:pdf},
pages = {1--149},
publisher = {Springer Berlin Heidelberg},
title = {{Lectures on Controllability and Observability}},
url = {http://link.springer.com/10.1007/978-3-642-11063-4{\_}1},
year = {2010}
}
@article{kalman:mit,
abstract = {Bibliography: p. 82-83.},
author = {Sandell, Nils Richard. and Yared, Khaled Ibrahim.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Sandell, Yared - 1978 - Maximum likelihood identification of state space models for linear dynamic systems.pdf:pdf},
journal = {Electronic Systems Laboratory, Dept. of Electrical Engineering and Computer Science, Massachusetts Institute of Technology.},
keywords = {System analysis,TK7855.M41 E386 no.814},
language = {eng},
publisher = {Electronic Systems Laboratory, Dept. of Electrical Engineering and Computer Science, Massachusetts Institute of Technology},
title = {{Maximum likelihood identification of state space models for linear dynamic systems}},
url = {http://dspace.mit.edu/handle/1721.1/1297},
volume = {R-814},
year = {1978}
}
@article{T.2004,
author = {T., HenryLan and Olekalns, Nilss and Thong, Jonathan},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/T., Olekalns, Thong - 2004 - Do stock market returns predict changes to output Evidence from a nonlinear panel data model.pdf:pdf},
issn = {0377-7332},
journal = {Empirical Economics},
keywords = {current depth of recession,e32,jel classification,panel data,stock returns},
month = {sep},
number = {3},
pages = {527--540},
title = {{Do stock market returns predict changes to output? Evidence from a nonlinear panel data model}},
url = {http://springerlink.metapress.com/openurl.asp?genre=article{\&}id=doi:10.1007/s00181-003-0182-4},
volume = {29},
year = {2004}
}
@book{cerny:book,
address = {Princeton, NJ},
annote = {From Duplicate 1 ( 

Mathematical techniques in finance

- {\v{C}}ern{\'{y}}, Ale{\v{s}} )



Tools for incomplete markets



From Duplicate 2 ( 

Mathematical techniques in finance

- {\v{C}}ern{\'{y}}, Ale{\v{s}} )



Tools for incomplete markets,
Available electronically at
$\backslash$url{\{}http://pup.princeton.edu/titles/7606.html{\}}},
author = {{\v{C}}ern{\'{y}}, Ale{\v{s}}},
edition = {Second},
isbn = {0-691-08806-3; 0-691-08807-1},
pages = {xxii+390},
publisher = {Princeton University Press},
title = {{Mathematical techniques in finance}},
year = {2009}
}
@article{Lusch2018,
author = {Lusch, Bethany and Kutz, Nathan J. and Brunton, Steven L.},
journal = {Nature Communications},
title = {{Deep learning for universal linear embeddings of nonlinear dynamics}},
volume = {9},
year = {2018}
}
@article{hafner:dcc,
author = {Hafner, Christian M. and Franses, P. H.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Hafner, Franses - 2009 - A generalized Dynamic Conditional Correlation model simulation and application to many assets.pdf:pdf},
institution = {Erasmus University Rotterdam},
journal = {Econometric Reviews},
number = {6},
pages = {612--631},
series = {Econometric Institute Report EI 2003-18},
title = {{A generalized Dynamic Conditional Correlation model: simulation and application to many assets}},
volume = {28},
year = {2009}
}
@article{maurey:result,
author = {Pisier, G},
journal = {S{\'{e}}minaire d'analyse fonctionnelle {\'{E}}cole Polytechnique},
pages = {1--12},
title = {{Remarques sur un r{\'{e}}sultat non publi{\'{e}} de B. Maurey}},
url = {http://www.numdam.org/article/SAF{\_}1980-1981{\_}{\_}{\_}{\_}A5{\_}0.pdf},
year = {1981}
}
@book{Christmann2008,
author = {Christmann, Andreas and Steinwart, Ingo},
publisher = {Springer New York},
title = {{Support Vector Machines}},
year = {2008}
}
@article{Bacry2008,
abstract = {In this paper, we make a short overview of continuous cascade models recently introduced to model asset return fluctuations. We show that these models account in a very parcimonious manner for most of ‘stylized facts' of financial time-series. We review in more details the simplest continuous cascade namely the log-normal multifractal random walk (MRW). It can simply be considered as a stochastic volatility model where the (log-) volatility memory has a peculiar ‘logarithmic' shape. This model possesses some appealing stability properties with respect to time aggregation. We describe how one can estimate it using a GMM method and we present some applications to volatility and (VaR) Value at Risk forecasting.},
author = {Bacry, E. and Kozhemyak, A. and Muzy, Jean-Fran{\c{c}}ois},
doi = {10.1016/j.jedc.2007.01.024},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Bacry, Kozhemyak, Muzy - 2008 - Continuous cascade models for asset returns.pdf:pdf},
issn = {01651889},
journal = {Journal of Economic Dynamics and Control},
month = {jan},
number = {1},
pages = {156--199},
title = {{Continuous cascade models for asset returns}},
url = {http://www.sciencedirect.com/science/article/pii/S0165188907000449},
volume = {32},
year = {2008}
}
@unpublished{McGibbon2014,
abstract = {We present a machine learning framework for modeling protein dynamics. Our approach uses L1-regularized, reversible hidden Markov models to understand large protein datasets generated via molecular dynamics simulations. Our model is motivated by three design principles: (1) the requirement of massive scalability; (2) the need to adhere to relevant physical law; and (3) the necessity of providing accessible interpretations, critical for both cellular biology and rational drug design. We present an EM algorithm for learning and introduce a model selection criteria based on the physical notion of convergence in relaxation timescales. We contrast our model with standard methods in biophysics and demonstrate improved robustness. We implement our algorithm on GPUs and apply the method to two large protein simulation datasets generated respectively on the NCSA Bluewaters supercomputer and the Folding@Home distributed computing network. Our analysis identifies the conformational dynamics of the ubiquitin protein critical to cellular signaling, and elucidates the stepwise activation mechanism of the c-Src kinase protein.},
archivePrefix = {arXiv},
arxivId = {1405.1444},
author = {McGibbon, Robert T. and Ramsundar, Bharath and Sultan, Mohammad M. and Kiss, Gert and Pande, Vijay S.},
eprint = {1405.1444},
keywords = {hmm,l1{\_}regularization},
month = {may},
title = {{Understanding protein dynamics with L1-regularized reversible hidden Markov models}},
url = {http://arxiv.org/abs/1405.1444},
year = {2014}
}
@article{McElhoe1966,
author = {McElhoe, Bruce A.},
journal = {IEEE Transactions on Aerospace and Electronic Systems},
number = {4},
pages = {613--623},
title = {{An assessment of the navigation and course corrections for a manned flyby of Mars or Venus}},
volume = {2},
year = {1966}
}
@article{funahashi:universality,
author = {Funahashi, Ken-ichi},
journal = {Neural Networks},
pages = {183--192},
title = {{On the approximate realization of continuous mappings by neural networks}},
volume = {2},
year = {1989}
}
@article{dullin:2004,
author = {Dullin, Holger R.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Dullin - 2004 - Poisson integrator for symmetric rigid bodies.pdf:pdf},
journal = {Regular and Chaotic Dynamics},
number = {3},
pages = {255--264},
title = {{Poisson integrator for symmetric rigid bodies}},
volume = {9},
year = {2004}
}
@article{elliott:madan:mcmm,
author = {Elliott, Robert J. and Madan, Dilip B.},
doi = {10.1111/1467-9965.00048},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Elliott, Madan - 1998 - A discrete time equivalent martingale measure.pdf:pdf},
issn = {0960-1627},
journal = {Mathematical Finance},
number = {2},
pages = {127--152},
title = {{A discrete time equivalent martingale measure}},
url = {http://dx.doi.org/10.1111/1467-9965.00048},
volume = {8},
year = {1998}
}
@article{clm,
author = {Cari{\~{n}}ena, J. F. and L{\'{o}}pez, C. and Mart{\'{i}}nez, E.},
journal = {J. Phys. A:Math. Gen.},
pages = {4777--4786},
title = {{A new approach to the converse of Noether's theorem}},
volume = {22},
year = {1989}
}
@article{magnus:neudecker,
author = {Magnus, Jan R and Neudecker, H},
issn = {0090-5364},
journal = {Ann. Statist.},
number = {2},
pages = {381--394},
title = {{The commutation matrix: some properties and applications}},
volume = {7},
year = {1979}
}
@article{CL_VarinVidoni2005,
author = {Varin, Cristiano and Vidoni, Paolo},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Varin, Vidoni - 2005 - A note on composite likelihood inference and model selection.pdf:pdf},
journal = {Biometrika},
number = {3},
pages = {519--528},
title = {{A note on composite likelihood inference and model selection}},
volume = {92},
year = {2005}
}
@book{priestley:tsbook,
author = {Priestley, M. B.},
pages = {237},
publisher = {Academic Press},
title = {{Non-linear and Non-stationary Time Series Analysis}},
year = {1988}
}
@article{Tse2000,
author = {Tse, Yiu Kuen and Tsui, Albert K.C.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Tse, Tsui - 2000 - A Multivariate GARCH Model with Time-Varying Correlations.pdf:pdf},
issn = {1556-5068},
journal = {SSRN Electronic Journal},
keywords = {acknowledgement,bekk model,by the national university,c12,constant correlation,garch model,jel classification,k,maximum likelihood estimate,monte carlo method,multivariate,tse acknowledges the support,varying correlation,y},
number = {July 2000},
title = {{A Multivariate GARCH Model with Time-Varying Correlations}},
url = {http://www.ssrn.com/abstract=250228},
year = {2000}
}
@book{Linde:Banach,
author = {Linde, Werner},
doi = {10.1112/blms/19.5.501},
publisher = {John Wiley {\&} Sons},
title = {{Probability in Banach Spaces - Stable and Infinitely Divisible Distributions}},
year = {1986}
}
@article{sandberg:constructive,
author = {Sandberg, Irwin W.},
journal = {International Journal of Circuit Theory and Applications},
keywords = {constructive approximation,discrete-time systems,non-linear systems},
pages = {109--120},
title = {{Constructive approximation of non-linear discrete-time systems}},
volume = {28},
year = {2000}
}
@article{RC3,
abstract = {This paper addresses the reservoir design problem in the context of delay-based reservoir computers for multidimensional input signals, parallel architectures, and real-time multitasking. First, an approximating reservoir model is presented in those frameworks that provides an explicit functional link between the reservoir parameters and architecture and its performance in the execution of a specific task. Second, the inference properties of the ridge regression estimator in the multivariate context is used to assess the impact of finite sample training on the decrease of the reservoir capacity. Finally, an empirical study is conducted that shows the adequacy of the theoretical results with the empirical performances exhibited by various reservoir architectures in the execution of several nonlinear tasks with multidimensional inputs. Our results confirm the robustness properties of the parallel reservoir architecture with respect to task misspecification and parameter choice that had already been documented in the literature.},
author = {Grigoryeva, Lyudmila and Henriques, Julie and Larger, Laurent and Ortega, Juan-Pablo},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Grigoryeva et al. - 2016 - Nonlinear memory capacity of parallel time-delay reservoir computers in the processing of multidimensional si.pdf:pdf},
journal = {Neural Computation},
keywords = {big data,echo state networks,liquid state machines,memory capacity,multidimensional signals processing,parallel computing,reservoir computing,time-delay reservoir},
pages = {1411--1451},
title = {{Nonlinear memory capacity of parallel time-delay reservoir computers in the processing of multidimensional signals}},
volume = {28},
year = {2016}
}
@article{ANTONIOU,
abstract = {Wavelets are known to have intimate connections to several other parts of mathematics, notably phase-space analysis of signal processing, reproducing kernel Hilbert spaces, coherent states in quantum mechanics, spline approximation theory. windowed Fourier transforms, and filter banks. Here, we establish and survey a new connection, namely to stochastic processes. Key to this link are the Kolmogorov systems of ergodic theory.},
author = {Antoniou, I. and Gustafson, K.},
issn = {0378-4754},
journal = {Mathematics and computers in simulation},
keywords = {Ecuaci{\'{o}}n Kolmogorov,Equation Kolmogorov,Ergodic theory,Kolmogorov equation,Proceso estoc{\'{a}}stico,Processus stochastique,Stochastic process,Teor{\'{i}}a erg{\'{o}}dica,Th{\'{e}}orie ergodique,Transformaci{\'{o}}n ondita,Transformation ondelette,Wavelet transformation},
language = {eng},
number = {1-2},
pages = {81--104},
publisher = {Elsevier},
title = {{Wavelets and stochastic processes}},
url = {http://cat.inist.fr/?aModele=afficheN{\&}cpsidt=1905627},
volume = {49}
}
@article{Nelson1990,
abstract = {This paper investigates the convergence of stochastic difference equations (e.g., ARCH) to stochastic differential equations as the length of the discrete time intervals between observations goes to zero. These results are applied to the GARCH(1,1) model of Bollerslev (1986) and to the AR(1) Exponential ARCHmodel of Nelson (1989). In their continuous time limits, the conditional variance processes in these models have stationary distributions that are inverted gamma and lognormal, respectively. In addition, a class of diffusionapproximations based on the Exponential ARCHmodel is developed.},
author = {Nelson, Daniel B.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Nelson - 1990 - ARCH models as diffusion approximations.pdf:pdf},
issn = {03044076},
journal = {Journal of Econometrics},
month = {jul},
number = {1-2},
pages = {7--38},
title = {{ARCH models as diffusion approximations}},
url = {http://dx.doi.org/10.1016/0304-4076(90)90092-8},
volume = {45},
year = {1990}
}
@article{Hermans2010,
abstract = {Reservoir Computing is a novel technique which employs recurrent neural networks while circumventing difficult training algorithms. A very recent trend in Reservoir Computing is the use of real physical dynamical systems as implementation platforms, rather than the customary digital emulations. Physical systems operate in continuous time, creating a fundamental difference with the classic discrete time definitions of Reservoir Computing. The specific goal of this paper is to study the memory properties of such systems, where we will limit ourselves to linear dynamics. We develop an analytical model which allows the calculation of the memory function for continuous time linear dynamical systems, which can be considered as networks of linear leaky integrator neurons. We then use this model to research memory properties for different types of reservoir. We start with random connection matrices with a shifted eigenvalue spectrum, which perform very poorly. Next, we transform two specific reservoir types, which are known to give good performance in discrete time, to the continuous time domain. Reservoirs based on uniform spreading of connection matrix eigenvalues on the unit disk in discrete time give much better memory properties than reservoirs with random connection matrices, where reservoirs based on orthogonal connection matrices in discrete time are very robust against noise and their memory properties can be tuned. The overall results found in this work yield important insights into how to design networks for continuous time.},
author = {Hermans, Michiel and Schrauwen, Benjamin},
issn = {1879-2782},
journal = {Neural networks : the official journal of the International Neural Network Society},
keywords = {Algorithms,Linear Models,Memory,Neural Networks (Computer),Time Factors},
month = {apr},
number = {3},
pages = {341--55},
title = {{Memory in linear recurrent neural networks in continuous time.}},
volume = {23},
year = {2010}
}
@article{Hinton2012,
abstract = {When a large feedforward neural network is trained on a small training set, it typically performs poorly on held-out test data. This "overfitting" is greatly reduced by randomly omitting half of the feature detectors on each training case. This prevents complex co-adaptations in which a feature detector is only helpful in the context of several other specific feature detectors. Instead, each neuron learns to detect a feature that is generally helpful for producing the correct answer given the combinatorially large variety of internal contexts in which it must operate. Random "dropout" gives big improvements on many benchmark tasks and sets new records for speech and object recognition.},
archivePrefix = {arXiv},
arxivId = {1207.0580},
author = {Hinton, Geoffrey E. and Srivastava, Nitish and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan R.},
eprint = {1207.0580},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Hinton et al. - 2012 - Improving neural networks by preventing co-adaptation of feature detectors.pdf:pdf},
pages = {1--18},
title = {{Improving neural networks by preventing co-adaptation of feature detectors}},
url = {http://arxiv.org/abs/1207.0580},
year = {2012}
}
@book{villani2009optimal,
author = {Villani, C{\'{e}}dric},
publisher = {Springer},
title = {{Optimal Transport: Old and New}},
year = {2009}
}
@incollection{foellmer:sondermann,
address = {Amsterdam},
author = {F{\"{o}}llmer, Hans and Sondermann, Dieter},
booktitle = {Contributions to mathematical economics},
pages = {205--223},
publisher = {North-Holland},
title = {{Hedging of nonredundant contingent claims}},
year = {1986}
}
@article{Bereau2012,
annote = {PMID: 26593018},
author = {Bereau, Tristan and Globisch, Christoph and Deserno, Markus and Peter, Christine},
doi = {10.1021/ct200888u},
journal = {Journal of Chemical Theory and Computation},
number = {10},
pages = {3750--3758},
title = {{Coarse-grained and atomistic simulations of the salt-stable cowpea chlorotic mottle virus (SS-CCMV) subunit 26-49: $\beta$-barrel stability of the hexamer and pentamer geometries}},
url = {http://dx.doi.org/10.1021/ct200888u},
volume = {8},
year = {2012}
}
@article{Cox_CL,
author = {Cox, D. R.},
journal = {Biometrika},
pages = {269--276},
title = {{Partial likelihood}},
volume = {62},
year = {1975}
}
@misc{halmos:naive:set,
author = {Halmos, Paul R.},
keywords = {mathematics},
publisher = {Dover Publications, Inc},
title = {{Naive Set Theory}},
volume = {1},
year = {2017}
}
@article{gine1984,
author = {Gin{\'{e}}, E. and Zinn, J.},
journal = {Annals of Probability},
pages = {929--989},
title = {{Some limit theorems for empirical processes}},
volume = {12},
year = {1984}
}
@article{francesco:poinsot,
author = {Fass{\`{o}}, F.},
journal = {Journal of Applied Mathematics and Physics (ZAMP)},
pages = {953--976},
title = {{The Euler-Poinsot top: a non-commutatively integrable systemwithout global action-angle coordinates}},
volume = {47},
year = {1996}
}
@article{Box1964,
author = {Box, George E. P. and Cox, D. R.},
journal = {Journal of the Royal Statistical Society. Series B},
pages = {211--246},
title = {{An analysis of transformations (with discussion)}},
volume = {26},
year = {1964}
}
@unpublished{PS02,
author = {Prigent, J. L. and Scaillet, O.},
title = {{Weak convergence of hedging strategies of contingent claims}},
year = {2002}
}
@article{van1981symmetries,
author = {van der Schaft, Arjan},
journal = {Systems {\&} Control Letters},
number = {2},
pages = {108--115},
publisher = {Elsevier},
title = {{Symmetries and conservation laws for Hamiltonian systems with inputs and outputs: A generalization of Noether's theorem}},
volume = {1},
year = {1981}
}
@article{bourguignon75,
author = {Bourguignon, J. P.},
journal = {Comp. Math.},
pages = {1--41},
title = {{Une stratification de l'espace des structures riemanniennes}},
volume = {30},
year = {1975}
}
@article{harvey:1980,
author = {Gardner, G. and Harvey, A. C. and Phillips, G. D. A.},
issn = {00359254},
journal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
keywords = {maximum likelihood},
number = {3},
pages = {311--322},
publisher = {Blackwell Publishing for the Royal Statistical Society},
title = {{An algorithm for exact maximum likelihood estimation of autoregressive-moving average models by means of Kalman filtering}},
url = {http://www.jstor.org/stable/2346910},
volume = {29},
year = {1980}
}
@book{oliva_hale,
author = {Hale, Jack K. and Magalhães, Luis T. and Oliva, Waldyr M.},
edition = {Springer},
pages = {282},
publisher = {Springer Verlag},
title = {{Dynamics in Infinite Dimensions}},
year = {2002}
}
@unpublished{Liu2019,
author = {Liu, H. and Markowich, P.},
title = {{Selection dynamics for deep neural networks}},
year = {2019}
}
@article{bates:graumann,
author = {Bates, L. and Graumann, H. and MacDonnell, C.},
journal = {Rep. Math. Phys.},
number = {3},
pages = {295--308},
title = {{Examples of gauge conservation laws in nonholonomic systems}},
volume = {37},
year = {1996}
}
@article{LassoRV,
author = {Callot, Laurent and Kock, Anders Bredahl and Medeiros, Marcelo},
journal = {Journal of Applied Econometrics},
number = {1},
pages = {140--158},
title = {{Modeling and forecasting large realized covariance matrices and portfolio choice}},
volume = {32},
year = {2016}
}
@incollection{Franke1999,
address = {Berlin, Heidelberg},
author = {Franke, J{\"{u}}rgen},
booktitle = {Operations Research Proceedings 1998},
doi = {10.1007/978-3-642-58409-1_27},
pages = {271--282},
publisher = {Springer Berlin Heidelberg},
title = {{Nonlinear and nonparametric methods for analyzing financial time series}},
url = {http://link.springer.com/10.1007/978-3-642-58409-1{\_}27},
year = {1999}
}
@book{Kozorez1981,
address = {Kiev},
author = {Kozorez, V. V.},
pages = {139},
publisher = {Naukova dumka},
title = {{Dynamic Systems of Free Magnetically Interacting Bodies (in Russian)}},
year = {1981}
}
@article{C:77,
author = {Chen, Kuo-Tsai},
journal = {Bulletin of the American Mathematical Society},
pages = {831--879},
title = {{Iterated path integrals}},
year = {1977}
}
@article{Dueker2005,
author = {Dueker, Michael},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Dueker - 2005 - Dynamic Forecasts of Qualitative Variables.pdf:pdf},
issn = {0735-0015},
journal = {Journal of Business and Economic Statistics},
keywords = {dummy endogenous variable,dynamic probit,recession forecasting},
month = {jan},
number = {1},
pages = {96--104},
title = {{Dynamic Forecasts of Qualitative Variables}},
url = {http://pubs.amstat.org/doi/abs/10.1198/073500104000000613},
volume = {23},
year = {2005}
}
@article{Yamamoto1980,
author = {Yamamoto, Taku},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Yamamoto - 1980 - On the treatment of autocorrelated errors in the multiperiod prediction of dynamic simultaneous equation models.pdf:pdf},
journal = {International Economic Review},
number = {3},
pages = {735--748},
title = {{On the treatment of autocorrelated errors in the multiperiod prediction of dynamic simultaneous equation models}},
url = {http://www.jstor.org/stable/10.2307/2526365},
volume = {21},
year = {1980}
}
@article{Rumyantsev1957,
author = {Rumyantsev, V. V.},
journal = {Bull. of the Moscow State University (Series: Mathematics)},
pages = {9--16},
title = {{On stability of motion with rrespect to part of variables}},
volume = {4},
year = {1957}
}
@article{Ait-Sahalia1998,
author = {A{\"{i}}t-Sahalia, Yacine and Lo, Andrew W.},
issn = {00221082},
journal = {The Journal of Finance},
month = {apr},
number = {2},
pages = {499--547},
title = {{Nonparametric Estimation of State-Price Densities Implicit in Financial Asset Prices}},
url = {http://doi.wiley.com/10.1111/0022-1082.215228},
volume = {53},
year = {1998}
}
@article{cabessa:2016,
abstract = {We provide a characterization of the expressive powers of several models of deterministic and nondeterministic first-order recurrent neural networks according to their attractor dynamics. The expressive power of neural nets is expressed as the topological complexity of their underlying neural $\omega$-languages, and refers to the ability of the networks to perform more or less complicated classification tasks via the manifestation of specific attractor dynamics. In this context, we prove that most neural models under consideration are strictly more powerful than Muller Turing machines. These results provide new insights into the computational capabilities of recurrent neural networks.},
author = {Cabessa, J{\'{e}}r{\'{e}}mie and Villa, Alessandro E.P.},
doi = {10.1016/j.jcss.2016.04.006},
issn = {10902724},
journal = {Journal of Computer and System Sciences},
keywords = {Analog computation,Attractors,Evolving systems,Expressive power,Learning,Neural computation,Recurrent neural networks,Spatiotemporal patterns,Turing machines,$\omega$-languages},
number = {8},
pages = {1232--1250},
publisher = {Elsevier Inc.},
title = {{Expressive power of first-order recurrent neural networks determined by their attractor dynamics}},
url = {http://dx.doi.org/10.1016/j.jcss.2016.04.006},
volume = {82},
year = {2016}
}
@book{Schechter:Handbook,
author = {Schechter, Eric},
isbn = {0126227608},
publisher = {Academic Press},
title = {{Handbook of Analysis and its Foundations}},
volume = {91},
year = {1997}
}
@inproceedings{Ferreira2008,
author = {Ferreira, Aida A. and Ludermir, Teresa B. and de Aquino, Ronaldo R. B. and Lira, Milde M. S. and Neto, Otoni N.},
booktitle = {2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence)},
doi = {10.1109/IJCNN.2008.4634019},
isbn = {978-1-4244-1820-6},
month = {jun},
pages = {1649--1656},
publisher = {IEEE},
title = {{Investigating the use of Reservoir Computing for forecasting the hourly wind speed in short -term}},
url = {http://ieeexplore.ieee.org/document/4634019/},
year = {2008}
}
@article{Ambrozeviciute2008,
author = {Ambro{\v{z}}evi{\v{c}}iūtė, D. and Klive{\v{c}}ka, A.},
issn = {0363-1672},
journal = {Lithuanian Mathematical Journal},
month = {jan},
number = {1},
pages = {1--16},
title = {{On the tvGARCH(1,1) model: Existence, CLT, and tail index}},
url = {http://link.springer.com/10.1007/s10986-008-0001-x},
volume = {48},
year = {2008}
}
@unpublished{Yamauchi2019,
author = {Yamauchi, Yuta and Omori, Yasuhiro},
title = {{Multivariate stochastic volatility model with realized volatilities and pairwise realized correlations}},
year = {2019}
}
@article{duflo:vergne,
author = {Duflo, M. and Vergne, M.},
journal = {C. R. Acad. Sci. Paris},
pages = {583--585},
title = {{Une propriet{\'{e}} de la repr{\'{e}}sentation coadjointe d'une alg{\'{e}}bre de Lie}},
volume = {268},
year = {1969}
}
@article{Umegaki:Bharucha,
author = {Umegaki, Hisaharu and Bharucha-Reid, A. T.},
doi = {10.1016/0022-247X(70)90119-8},
issn = {10960813},
journal = {Journal of Mathematical Analysis and Applications},
number = {1},
pages = {49--67},
title = {{Banach space-valued random variables and tensor products of Banach spaces}},
volume = {31},
year = {1970}
}
@article{bates:sniatycki,
author = {Bates, L. and Sniatycki, J.},
journal = {Rep. Math. Phys.},
number = {1},
pages = {99--115},
title = {{Nonholonomic reduction}},
volume = {32},
year = {1993}
}
@book{Loeve1978,
author = {Lo{\`{e}}ve, Michel},
edition = {Fourth},
pages = {413},
publisher = {Springer-Verlag, New York},
title = {{Probability Theory II}},
year = {1978}
}
@article{Ortega2003rpo,
abstract = {An estimate on the number of distinct relative periodic orbits around a stable relative equilibrium in a Hamiltonian system with continuous symmetry is given. This result constitutes a generalization to the Hamiltonian symmetric framework of a classical result by Weinstein and Moser on the existence of periodic orbits in the energy levels surrounding a stable equilibrium. The estimate obtained is very precise in the sense that it provides a lower bound for the number of relative periodic orbits at each prescribed energy and momentum values neighbouring the stable relative equilibrium in question and with any prefixed (spatio-temporal) isotropy subgroup. Moreover, it is easily computable in particular examples. It is interesting to see how, in our result, the existence of non-trivial relative periodic orbits requires (generic) conditions on the higher-order terms of the Taylor expansion of the Hamiltonian function, in contrast with the purely quadratic requirements of the Weinstein–Moser theorem, which emphasizes the highly nonlinear character of the relatively periodic dynamical objects.},
author = {Ortega, Juan-Pablo},
doi = {10.1017/S0308210500002602},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Ortega - 2003 - Relative normal modes for nonlinear Hamiltonian systems.pdf:pdf},
issn = {0308-2105},
journal = {Proceedings of the Royal Society of Edinburgh: Section A Mathematics},
month = {jun},
number = {3},
pages = {665--704},
publisher = {Royal Society of Edinburgh Scotland Foundation},
title = {{Relative normal modes for nonlinear Hamiltonian systems}},
url = {http://www.journals.cambridge.org/abstract{\_}S0308210500002602},
volume = {133},
year = {2003}
}
@article{Rodriguez2010,
author = {Rodriguez, Alejandro Abel and Puggioni, Gavino},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Rodriguez, Puggioni - 2010 - Mixed frequency models Bayesian approaches to estimation and prediction.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {gross national product,interest rates,mixed frequency data,model averaging,model selection},
month = {apr},
number = {2},
pages = {293--311},
publisher = {Elsevier B.V.},
title = {{Mixed frequency models: Bayesian approaches to estimation and prediction}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0169207010000154},
volume = {26},
year = {2010}
}
@article{Dacorogna1997,
abstract = {In this paper we present both a new formulation of the HARCH process and a study of the forecasting accuracy of ARCH-type models for predicting short-term volatility. Using high frequency data, the market volatility is expressed in terms of partial volatilities which are formally exponential moving averages of squared returns measured at different frequencies. This new formulation is shown to produce more accurate fits to the data and, at the same time, to be easier to compute than the earlier version of the HARCH process. This is obtained without losing the nice property of the HARCH process to identify different market components. In a second part, some performance measures of forecasting accuracy are discussed and the ARCH-type models are shown to be good predictors of the short-term hourly historical volatility with the new formulation of the HARCH process being the best predictor.},
author = {Dacorogna, Michel M. and M{\"{u}}ller, Ulrich A. and Pictet, Olivier V. and Olsen, Richard B.},
doi = {10.2139/ssrn.36960},
issn = {1556-5068},
journal = {SSRN Electronic Journal},
title = {{Modelling Short-Term Volatility with GARCH and HARCH Models}},
url = {http://papers.ssrn.com/abstract=36960},
year = {1997}
}
@article{Hansen1996,
author = {Hansen, Bruce},
journal = {Econometrica},
number = {2},
pages = {413--430},
title = {{Inference when a nuisance parameter is not identified under the null hypothesis}},
volume = {64},
year = {1996}
}
@article{alber:luther:1998,
author = {Alber, M. S. and Luther, G. G. and Marsden, J. E. and Robbins, J. M.},
journal = {Physica D},
pages = {271--290},
title = {{Geometric phases, reduction and Lie-Poisson structure for the resonant three-wave interaction}},
volume = {123},
year = {1998}
}
@article{kravchenko2006completeness,
author = {Kravchenko, Aleksei Stanislavovich},
journal = {Siberian Mathematical Journal},
number = {1},
pages = {68--76},
publisher = {Springer},
title = {{Completeness of the space of separable measures in the Kantorovich-Rubinshtein metric}},
volume = {47},
year = {2006}
}
@article{Holler2013,
author = {H{\"{o}}ller, Yvonne and Bergmann, J{\"{u}}rgen and Thomschewski, Aljoscha and Kronbichler, Martin and H{\"{o}}ller, Peter and Crone, Julia S. and Schmid, Elisabeth V. and Butz, Kevin and Nardone, Raffaele and Trinka, Eugen},
doi = {10.1371/journal.pone.0080479},
editor = {Fridman, Esteban Andres},
journal = {PLoS ONE},
month = {nov},
number = {11},
pages = {e80479},
publisher = {Public Library of Science},
title = {{Comparison of EEG-features and classification methods for motor Imagery in patients with disorders of consciousness}},
url = {http://dx.plos.org/10.1371/journal.pone.0080479},
volume = {8},
year = {2013}
}
@article{karniadakis2021physics,
author = {Karniadakis, George Em and Kevrekidis, Ioannis G and Lu, Lu and Perdikaris, Paris and Wang, Sifan and Yang, Liu},
journal = {Nature Reviews Physics},
number = {6},
pages = {422--440},
publisher = {Nature Publishing Group},
title = {{Physics-informed machine learning}},
volume = {3},
year = {2021}
}
@article{baer,
author = {Baer, A},
journal = {J. Reine Angew. Math.},
pages = {199--207},
title = {{Zur Einf{\{}{\"{u}}{\}}hrung des Scharbegriffs}},
volume = {160},
year = {1929}
}
@article{Shen2016,
annote = {PMID: 27552235},
author = {Shen, Lin and Wu, Jingheng and Yang, Weitao},
doi = {10.1021/acs.jctc.6b00663},
journal = {Journal of Chemical Theory and Computation},
number = {10},
pages = {4934--4946},
title = {{Multiscale quantum mechanics/molecular mechanics simulations with neural networks}},
url = {http://dx.doi.org/10.1021/acs.jctc.6b00663},
volume = {12},
year = {2016}
}
@article{verstraeten,
author = {Verstraeten, D. and Schrauwen, B. and D'Haene, M. and Stroobandt, D.},
journal = {Neural Networks},
pages = {391--403},
title = {{An experimental unification of reservoir computing methods}},
volume = {20},
year = {2007}
}
@article{Estrella2006,
author = {Estrella, Arturo and Trubin, Mary R},
journal = {Current Issues in Economics and Finance},
keywords = {real time,recessions,yield curve},
number = {5},
title = {{The Yield Curve as a Leading Indicator : Some Practical Issues}},
volume = {12},
year = {2006}
}
@article{brayton:moser,
author = {Brayton, R. K. and Moser, J. K.},
journal = {Quart. Appl. Math.},
pages = {1--33, 81--104},
title = {{A theory of nonlinear networks. Part I and Part II}},
volume = {22},
year = {1964}
}
@incollection{BusemeyerByunEtAl1997,
address = {Cambridge, MA, US},
author = {Busemeyer, Jerome R and Byun, Eunhee and Delosh, Edward L and McDaniel, Mark A M},
booktitle = {Knowledge, concepts and categories},
editor = {{Lamberts K.} and Shanks, D},
keywords = {ALM,Funktionslernen},
pages = {408--437},
publisher = {MIT Press},
title = {{Learning functional relations based on experience with input-output pairs by humans and artificial neural networks}},
year = {1997}
}
@inproceedings{LeySwan16,
address = {Working paper},
author = {Ley, Christophe and Reinert, Gesine and Swan, Yvik},
title = {{Approximate computation of expectations: a canonical Stein operator}},
year = {2014}
}
@article{Polyak1979,
author = {Polyak, Boris T. and Tsypkin, Ya. Z.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Polyak, Tsypkin - 1979 - Adaptive estimation algorithms Convergence, optimality, stability.pdf:pdf;:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Polyak, Tsypkin - 1979 - Adaptive estimation algorithms Convergence, optimality, stability.pdf:pdf},
journal = {Automation and Remote Control (Avtomatika i Telemekhanika)},
number = {1979},
title = {{Adaptive estimation algorithms: Convergence, optimality, stability}},
year = {1979}
}
@book{Bharucha:RIE,
author = {Bharucha-Reid, Albert T.},
isbn = {9780120957507},
pages = {267},
publisher = {Academic Press},
title = {{Random Integral Equations}},
url = {https://www.sciencedirect.com/bookseries/mathematics-in-science-and-engineering/vol/96/suppl/C},
year = {1972}
}
@article{Engle2006,
author = {Engle, Robert F. and Colacito, Riccardo},
doi = {10.1198/073500106000000017},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Engle, Colacito - 2006 - Testing and Valuing Dynamic Correlations for Asset Allocation.pdf:pdf},
journal = {Journal of Business {\&} Economic Statistics},
keywords = {ditional heteroscedasticity,dynamic conditional correlation,forecast evaluation,generalized autoregressive con-},
number = {2},
pages = {238--253},
title = {{Testing and Valuing Dynamic Correlations for Asset Allocation}},
volume = {24},
year = {2006}
}
@book{souriau,
address = {Paris},
author = {Souriau, Jean-Marie},
publisher = {Dunod},
title = {{Structure des Syst{\`{e}}mes Dynamiques}},
year = {1969}
}
@book{Sternberg:dynamical:book,
author = {Sternberg, Shlomo},
isbn = {0486477053},
pages = {272},
publisher = {Dover},
title = {{Dynamical Systems}},
url = {http://www.math.harvard.edu/library/sternberg/},
year = {2010}
}
@article{rueschendorf:thomsen,
abstract = {Some general closedness properties of sum spaces of measurable functions are established. As application one obtains existence and uniqueness results for solutions of the generalized Schr$\backslash$"odinger problem under an integrability condition but without any topological or boundedness assumptions. They also allow to prove an interesting structural result for distributions with multivariate marginals, to prove existence results for optimal approximations in additive statistical models, and to give an extension of Kolmogorov's representation theorem for continuous functions of severalvariables. This extension implies that any locally bounded measurable function has an exact representation by a neural network with one hidden layer.},
author = {R{\"{u}}schendorf, L. and Thomsen, W.},
doi = {10.1137/S0040585X97976301},
issn = {0040585X},
journal = {Theory of Probability {\&} Its Applications},
keywords = {Kolmogorov representation theorem,Schr{\"{o}}dinger equation,additivemodels,multivariate marginals,sum spaces},
month = {jan},
number = {3},
pages = {483--494},
publisher = {Society for Industrial and Applied Mathematics},
title = {{Closedness of sum spaces and the generalized schr{\"{o}}dinger Problem}},
url = {http://epubs.siam.org/doi/10.1137/S0040585X97976301},
volume = {42},
year = {1998}
}
@article{foellmer:schweizer:89,
author = {F{\"{o}}llmer, Hans and Schweizer, Martin},
journal = {ASTIN Bull.},
pages = {147--160},
title = {{Hedging by sequential regression: an introduction to the mathematics of option trading}},
volume = {18},
year = {1989}
}
@article{lee:raymond:1975,
author = {Lee, Ronnie and Raymond, Frank},
doi = {10.1016/0040-9383(75)90034-8},
issn = {00409383},
journal = {Topology},
number = {1},
pages = {49--57},
title = {{Manifolds covered by Euclidean space}},
volume = {14},
year = {1975}
}
@article{afm,
author = {Arms, J. M. and Fischer, A. E. and Marsden, J. E.},
journal = {C. R. Acad. Sci. Paris S{\'{e}}r. I Math.},
pages = {517--520},
title = {{Une approche symplectique pour des th{\'{e}}or{\`{e}}mes the d{\'{e}}composition en g{\'{e}}om{\'{e}}trie ourelativit{\'{e}} g{\'{e}}n{\'{e}}rale}},
volume = {281},
year = {1975}
}
@article{Sandmann1998,
abstract = {This paper discusses the MonteCarlomaximumlikelihood method of estimating stochasticvolatility (SV) models. The basic SV model can be expressed as a linear state space model with log chi-square disturbances. The likelihood function can be approximated arbitrarily accurately by decomposing it into a Gaussian part, constructed by the Kalman filter, and a remainder function, whose expectation is evaluated by simulation. No modifications of this estimation procedure are required when the basic SV model is extended in a number of directions likely to arise in applied empirical research. This compares favorably with alternative approaches. The finite sample performance of the new estimator is shown to be comparable to the MonteCarlo Markov chain (MCMC) method.},
author = {Sandmann, Gleb and Koopman, Siem Jan},
doi = {10.1016/S0304-4076(98)00016-5},
issn = {03044076},
journal = {Journal of Econometrics},
keywords = {c15,c22},
month = {dec},
number = {2},
pages = {271--301},
title = {{Estimation of stochastic volatility models via Monte Carlo maximum likelihood}},
url = {http://dx.doi.org/10.1016/S0304-4076(98)00016-5},
volume = {87},
year = {1998}
}
@inproceedings{Long2018,
abstract = {Partial differential equations (PDEs) play a prominent role in many disciplines of science and engineering. PDEs are commonly derived based on empirical observations. However, with the rapid development of sensors, computational power, and data storage in the past decade, huge quantities of data can be easily collected and efficiently stored. Such vast quantity of data offers new opportunities for data-driven discovery of physical laws. Inspired by the latest development of neural network designs in deep learning, we propose a new feed-forward deep network, called PDE-Net, to fulfill two objectives at the same time: to accurately predict dynamics of complex systems and to uncover the underlying hidden PDE models. Comparing with existing approaches, our approach has the most flexibility by learning both differential operators and the nonlinear response function of the underlying PDE model. A special feature of the proposed PDE-Net is that all filters are properly constrained, which enables us to easily identify the governing PDE models while still maintaining the expressive and predictive power of the network. These constrains are carefully designed by fully exploiting the relation between the orders of differential operators and the orders of sum rules of filters (an important concept originated from wavelet theory). Numerical experiments show that the PDE-Net has the potential to uncover the hidden PDE of the observed dynamics, and predict the dynamical behavior for a relatively long time, even in a noisy environment.},
author = {Long, Zichao and Lu, Yiping and Ma, Xianzhong and Dong, Bin},
booktitle = {Proceedings of the 35th International Conference on Machine Learning},
editor = {Dy, Jennifer and Krause, Andreas},
pages = {3208--3216},
publisher = {PMLR},
series = {Proceedings of Machine Learning Research},
title = {{PDE-Net: Learning PDEs from Data}},
url = {https://proceedings.mlr.press/v80/long18a.html},
volume = {80},
year = {2018}
}
@book{cho:hale:82,
author = {Chow, S.-N. and Hale, J. K.},
booktitle = {Grundleheren der mathematischen Wissenschaften},
publisher = {Springer Verlag},
title = {{Methods of Bifurcation Theory}},
volume = {251},
year = {1982}
}
@unpublished{Zhang2018,
author = {Zhang, Jiong and Lei, Qi and Dhillon, Inderjit S},
title = {{Stabilizing gradients for deep neural networks via efficient SVD parameterization}},
year = {2018}
}
@article{Feunou2012,
abstract = {We develop a discrete-time affine stochastic volatility model with time-varying conditional skewness (SVS). Importantly, we disentangle the dynamics of conditional volatility and conditional skewness in a coherent way. Our approach allows current asset returns to be asymmetric conditional on current factors and past information, which we term contemporaneous asymmetry. Conditional skewness is an explicit combination of the conditional leverage effect and contemporaneous asymmetry. We derive analytical formulas for various return moments that are used for generalized method of moments (GMM) estimation. Applying our approach to S{\&}P500 index daily returns and option data, we show that one- and two-factor SVS models provide a better fit for both the historical and the risk-neutral distribution of returns, compared to existing affine generalized autoregressive conditional heteroscedasticity (GARCH), and stochastic volatility with jumps (SVJ) models. Our results are not due to an overparameterization of the mod...},
author = {Feunou, Bruno and T{\'{e}}dongap, Rom{\'{e}}o},
issn = {0735-0015},
journal = {Journal of Business {\&} Economic Statistics},
keywords = {Affine model,Conditional skewness,Discrete time,GMM,Option pricing},
language = {en},
month = {oct},
number = {4},
pages = {576--591},
publisher = {Taylor {\&} Francis Group},
title = {{A stochastic volatility model with conditional skewness}},
url = {http://amstat.tandfonline.com/doi/abs/10.1080/07350015.2012.715958},
volume = {30},
year = {2012}
}
@article{achlioptas2003database,
author = {Achlioptas, Dimitris},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Achlioptas - 2003 - Database-friendly random projections Johnson-Lindenstrauss with binary coins.pdf:pdf},
journal = {Journal of computer and System Sciences},
number = {4},
pages = {671--687},
publisher = {Elsevier},
title = {{Database-friendly random projections: Johnson-Lindenstrauss with binary coins}},
volume = {66},
year = {2003}
}
@book{bartsch:94,
author = {Bartsch, T.},
publisher = {Springer Lecture Notes in Mathematics. Vol. 1560},
title = {{Topological Methods for Variational Problems with Symmetries}},
year = {1994}
}
@misc{Wright2006,
author = {Wright, Jonathan H},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Wright - 2006 - The Yield Curve and Predicting Recessions.pdf:pdf},
publisher = {Federal Reserve Board, Washington DC},
title = {{The Yield Curve and Predicting Recessions}},
year = {2006}
}
@book{berger2012panoramic,
author = {Berger, Marcel},
publisher = {Springer Science {\&} Business Media},
title = {{A Panoramic View of Riemannian Geometry}},
year = {2012}
}
@book{Hille:Phillips,
author = {Hille, Einar and Phillips, Ralph S.},
publisher = {American Mathematical Society},
title = {{Functional Analysis and Semi-Groups}},
year = {1957}
}
@article{Tribello2012,
author = {Tribello, G. A. and Ceriotti, M. and Parinello, M.},
journal = {Proceedings of National Academy Of Sciences USA},
number = {14},
pages = {5196--5201},
title = {{Using sketch-map coordinates to analyze and bias molecular dynamics simulations}},
volume = {109},
year = {2012}
}
@article{rossenbaum2011,
abstract = {In this paper, we provide a model which accommodates the assumption of a continuous efficient price with the inherent properties of ultra-high-frequency transaction data (price discreteness, irregular temporal spacing, diurnal patterns...). Our approach consists in designing a stochastic mechanism for deriving the transaction prices from the latent efficient price. The main idea behind the model is that, if a transaction occurs at some value on the tick grid and leads to a price change, then the efficient price has been close enough to this value shortly before the transaction. We call uncertainty zones the bands around the mid-tick grid where the efficient price is too far from the tick grid to trigger a price change. In our setting, the width of these uncertainty zones quantifies the aversion to price changes of the market participants. Furthermore, this model enables us to derive approximated values of the efficient price at some random times, which is particularly useful for building statistical procedures. Convincing results are obtained through a simulation study and the use of the model over 10 representative stocks.},
author = {Robert, Christian Y. and Rossenbaum, Mathieu and Rosenbaum, M.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Robert, Rossenbaum, Rosenbaum - 2011 - A new approach for the dynamics of ultra-high-frequency data the model with uncertainty zones.pdf:pdf},
issn = {1479-8409},
journal = {Journal of Financial Econometrics},
month = {jun},
number = {2},
pages = {344--366},
title = {{A new approach for the dynamics of ultra-high-frequency data: the model with uncertainty zones}},
url = {http://jfec.oxfordjournals.org/content/9/2/344.short},
volume = {9},
year = {2011}
}
@article{Laurent-Polz2011,
abstract = {We describe the linear and nonlinear stability and instability of certain symmetric configurations of point vortices on the sphere forming relative equilibria. These configurations consist of one or two rings, and a ring with one or two polar vortices. Such configurations have dihedral symmetry, and the symmetry is used to block diagonalize the relevant matrices, to distinguish the subspaces on which their eigenvalues need to be calculated, and also to describe the bifurcations that occur as eigenvalues pass through zero.},
author = {Laurent-Polz, Frederic and Montaldi, James and Roberts, Mark},
journal = {Journal of Geometric Mechanics},
keywords = {37 Dynamical systems and ergodic theory,76 Fluid mechanics},
month = {dec},
number = {4},
pages = {439--486},
title = {{Point vortices on the sphere: stability of symmetric relative equilibria}},
url = {http://eprints.ma.man.ac.uk/1594/},
volume = {3},
year = {2011}
}
@article{Bacry2001,
abstract = {Multifractal random walks (MRW) correspond to simple solvable “stochastic volatility” processes. Moreover, they provide a simple interpretation of multifractal scaling laws and multiplicative cascade process paradigms in terms of volatility correlations. We show that they are able to reproduce most of the recent empirical findings concerning financial time series: no correlation between price variations, long-range volatility correlations and multifractal statistics.},
author = {Bacry, E. and Delour, J. and Muzy, J.F.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Bacry, Delour, Muzy - 2001 - Modelling financial time series using multifractal random walks.pdf:pdf},
issn = {03784371},
journal = {Physica A: Statistical Mechanics and its Applications},
month = {oct},
number = {1-2},
pages = {84--92},
title = {{Modelling financial time series using multifractal random walks}},
url = {http://www.sciencedirect.com/science/article/pii/S0378437101002849},
volume = {299},
year = {2001}
}
@article{cartan1967calcul,
author = {Cartan, Henri},
publisher = {Hermann},
title = {{Calcul Diff{\'{e}}rentiel}},
year = {1967}
}
@article{brain:ortega,
abstract = {Sir, We read with great interest the correspondence between Tzovara and colleagues and Naccache et al. regarding the neural detection of sound sequences in the absence of con-sciousness (Naccache et al., 2015; Tzovara et al., 2015a, b). We believe that this discussion raises important questions on the way to use event-related potentials (ERPs) for predicting the recovery of comatose patients. Two aspects of the corres-pondence particularly caught our attention: (i) the difficulty in obtaining a perfect neural detection in the control group of fully conscious subjects; and (ii) the variability of the statis-tical analyses used to detect neural signs of awareness. First, in their replication of the elegant local global para-digm conceived to evaluate consciousness, Tzovara et al. could not obtain a significant conscious effect in all aware control subjects, which contradicts the perfect per-formance obtained in the original studies (Bekinschtein et al., 2009; Faugeras et al., 2011, 2012; King et al., 2013). Such a decrease in performance has also been observed in the replication of other experimental designs used to detect signs of awareness (Owen et al., 2006; Monti et al., 2010) both by others (Comte et al., 2015; Gabriel et al., 2015) and the same research team (Fernandez-Espejo et al., 2014). Replication studies are vital for clinical and scientific progress and the slightest change in the design or in the population tested can dra-matically alter the detection of awareness, as in the repli-cation performed by Tzovara and colleagues. The experience of the clinical team is also of major importance. For example, in the local global paradigm, subjects must be given precisely worded instructions otherwise the task might be complex to understand. One can nevertheless question whether a perfect detection of awareness in con-trol subjects is a prerequisite before testing patients with disorders of consciousness. Indeed, the cerebral activity of these patients is altered and the electrophysiological signal is hardly comparable to healthy controls in terms of top-ography, amplitude, and latency. Second, the use of a different statistical method to ana-lyse the electrophysiological signal is a major issue both in scientific research and in clinical routine. In the past 10 years, increasingly complex analysis methods have been de-veloped to detect neural responses in coma. Mismatch negativity studies in comatose patients provide a striking example. These protocols are frequently used by neurolo-gists because of their good predictive value of awakening (see Morlet and Fischer, 2014 for a review). The standard in clinical practice is to detect the presence of a mismatch negativity visually, i.e. to inspect whether there is an elec-trophysiological difference between standard and deviant tones on fronto-central electrodes (Kane et al., 1996; Rodriguez et al., 2014). However, considering that the elec-trophysiological signal is often small and noisy in comatose patients, several research teams have proposed the use of mathematical methods to confirm (Fischer et al., 1999; Naccache et al., 2005; Qin, et al., 2008) or to replace (Daltrozzo et al., 2009; Tzovara et al., 2013) the visual evaluation. The problem for clinicians is the vast array of mathematical methods and research teams devoted to the detection of mismatch negativity in coma. As the signal processing stages and the mathematical approaches differ widely in these statistical methods, differ-ent parts of the neural response could be detected. With the generation of mismatch negativity at both frontal and tem-poral lobe sources, some methods may reveal a stronger contribution from one brain region than the other, and inversely. This is especially true when the neural response is reduced because of the low signal-to-noise ratio, for ex-ample, for comatose patients. We are currently conducting conventional and high-density electroencephalography research aimed at compar-ing visual and mathematical methods for the evaluation of consciousness in comatose patients. From this research, we have already extracted preliminary neural responses from a control group of 27 conscious subjects. These subjects were tested with a classic mismatch negativity design based on the presentation of standard tones at 1000 Hz and deviant tones at 2000 Hz. To get a signal comparable to comatose patients in terms of signal-to-noise ratio, only 378 standard and 67 deviant tones were used. Sample frequency was set at 1000 Hz and epochs ranging from 20 ms prestimulus to 300 ms post-stimulus were extracted for each experimental condition and participant. Baseline was defined as the 20 ms period prior to stimulus onset. Individual data were then bandpass-filtered to 1–30 Hz. Six analysis methods were compared, all already success-fully used to detect the presence of a mismatch negativity in comatose patients. The first method was visual; the stand-ard in most intensive care units. For each subject, the mis-match negativity was measured by subtracting the average of standard tones with the average of deviant tones. The presence of this ERP was assessed by two expert neurolo-gists (N.A.-O. and E.M.), taking into account the morph-ology, latency and topography of the response. All other methods were statistical. The second method (Naccache et al., 2005) used a sample-by-sample t-test in the time window 100–200 ms. In the third method (Qin et al., 2008), a sample-by-sample t-test was used only at the peak of the mismatch negativity. The fourth method (Fischer et al., 1999) was a cross-correlation. The fifth method (Daltrozzo et al., 2009) was a t-continuous wavelet transform and the sixth (Tzovara et al., 2013) was a multi-variate analysis. For all mathematical methods, the referen-cing of data, the electrodes to analyse, the time windows of interest, and significance levels were similar to the original published studies. Results are presented in Table 1. Large discrepancies were found across all subjects. When looking at consisten-cies among methods, we found that, in four subjects only, a mismatch negativity was detected with all methods. Nevertheless, a mismatch negativity was detected with at least two methods in all subjects. For each subject, the mean number of methods detecting signal differences was 4.07 AE 1.27 and the median number was 4. When looking at each method separately, significant detection of neural differences was found in all subjects with the fifth method, whereas significant differences were found in only 44{\%} of subjects with the third method. Our results show that the choice of statistical method could have a dramatic influence on the detection of neural differences. Considering that most of these methods rely on complex methodological approaches, assessing the origin of these neural detection differences is problematic. These methods should therefore be complementary and not confirmatory. Moreover, if one mathematical method gave 100{\%} detection in our conscious subjects (Daltrozzo et al., 2009), a comparison with unconscious subjects is neces-sary: this ensures that there is no over-detection of re-sponses and a high level of false positives, which would be troublesome in clinical routine. From a clinical point of view, these results also suggest that the visual inspection of ERPs is mandatory to limit over-detections. It is extremely difficult, if at all possible, to define the 'best' analysis method. This depends on many other factors, such as the design of the protocol, the type of electrodes, and the number of trials, which makes performance comparisons difficult. Our results suggest that the use of complex statis-tical methods does not resolve this uncertainty and may con-versely complicate the clinician's decision. Depending on the analysis method selected by the clinician, some comatose patients with preserved cognitive functions may be wrongly classified as conscious or unconscious, which consequently raises both ethical and therapeutic issues. In that respect, the comparison of the local global paradigm with different ana-lysis methods on the same comatose patients proposed by Naccache et al. (2015) and Tzovara et al. (2015b) will be of scientific and clinical value.},
author = {Gabriel, Damien and Muzard, Emelyne and Henriques, Julie and Mignot, Coralie and Pazart, Lionel and Andr??-Obadia, Nathalie and Ortega, Juan Pablo and Moulin, Thierry},
doi = {10.1093/brain/aww065},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Gabriel et al. - 2016 - Replicability and impact of statistics in the detection of neural responses of consciousness.pdf:pdf},
issn = {14602156},
journal = {Brain},
number = {6},
pages = {e30},
pmid = {27017191},
title = {{Replicability and impact of statistics in the detection of neural responses of consciousness}},
volume = {139},
year = {2016}
}
@article{engle:bekk,
author = {Engle, Robert F. and Kroner, F. K.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Engle, Kroner - 1995 - Multivariate simultaneous generalized ARCH.pdf:pdf},
journal = {Econometric Theory},
pages = {122--150},
title = {{Multivariate simultaneous generalized ARCH}},
volume = {11},
year = {1995}
}
@article{RC18,
author = {Grigoryeva, Lyudmila and Hart, Allen G and Ortega, Juan-Pablo},
journal = {Physical Review E - Statistical Physics, Plasmas, Fluids, and Related Interdisciplinary Topics},
pages = {062204},
title = {{Chaos on compact manifolds: Differentiable synchronizations beyond the Takens theorem}},
volume = {103},
year = {2021}
}
@article{Eecke:1974,
author = {{Ver Eecke}, Paul},
journal = {Cahiers de topologie et g{\'{e}}om{\'{e}}trie diff{\'{e}}rentielle cat{\'{e}}goriques},
number = {3},
pages = {293--339},
title = {{Sur le calcul diff{\'{e}}rentiel dans les espaces vectoriels topologiques}},
volume = {15},
year = {1974}
}
@article{brandt:1926,
author = {Brandt, W.},
journal = {Math. Ann.},
pages = {360--366},
title = {{{\"{U}}ber eine Verallgemeinerung des Gruppenbegriffes}},
volume = {96},
year = {1926}
}
@book{Arora2007,
author = {Arora, Sanjeev and Barak, Boaz},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Arora, Barak - 2007 - Computational Complexity A Modern Approach.pdf:pdf},
title = {{Computational Complexity: A Modern Approach}},
year = {2007}
}
@techreport{Galvao2010,
author = {Galv{\~{a}}o, Ana Beatriz and Marcellino, Massimiliano},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Galv{\~{a}}o, Marcellino - 2010 - Endogenous monetary policy regimes and the great moderation.pdf:pdf},
institution = {EUI},
series = {Department of Economics},
title = {{Endogenous monetary policy regimes and the great moderation}},
year = {2010}
}
@article{Li2001,
author = {Li, W. K. and Ling, Shiqing and MacAleer, Michael},
keywords = {ARCH-Modell,Theorie,Working Paper,Zeitreihenanalyse},
language = {eng},
publisher = {Osaka: Osaka University, Institute of Social and Economic Research (ISER)},
title = {{A survey of recent theoretical results for time series models with GARCH errors}},
url = {http://www.econstor.eu/handle/10419/92581},
year = {2001}
}
@article{kalman1961new,
author = {Kalman, R E and Bucy, R S},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Kalman, Bucy - 1961 - New results in linear filtering and prediction theory.pdf:pdf},
journal = {Trans. ASME, D},
pages = {95--108},
title = {{New results in linear filtering and prediction theory}},
volume = {83},
year = {1961}
}
@article{BCO2015,
author = {Badescu, Alexandru and Cui, Zhenyu and Ortega, Juan-Pablo},
journal = {Journal of Financial Econometrics},
number = {4},
pages = {602--648},
title = {{Non-affine GARCH option pricing models, variance dependent kernels, and diffusion limits}},
url = {https://doi.org/10.1093/jjfinec/nbx022},
volume = {15},
year = {2017}
}
@article{diaz:desrochers,
author = {Diaz, Hernando and Desrochers, Alan A.},
journal = {Automatica},
number = {5},
pages = {629--641},
title = {{Modeling of nonlinear discrete-time systems from input-output data}},
volume = {24},
year = {1988}
}
@book{Hyndman2013,
abstract = {Getting started -- The forecaster's toolbox -- Judgmental forecasts -- Simple regression -- Multiple regression -- Time series decomposition -- Exponential smoothing -- ARIMA models -- Advanced forecasting methods.},
author = {Hyndman, Rob J. and Athanasopoulos, George},
isbn = {0987507109},
pages = {292},
publisher = {OTexts},
title = {{Forecasting : Principles and Practice}},
url = {https://www.otexts.org/book/fpp{\#}printed{\_}copy},
year = {2013}
}
@article{Jaeger:2002,
author = {Jaeger, Herbert},
journal = {Fraunhofer Institute for Autonomous Intelligent Systems. Technical Report.},
title = {{Short term memory in echo state networks}},
volume = {152},
year = {2002}
}
@misc{Banulescu2012,
author = {Banulescu, Denisa and Candelon, Bertrand and Hurlin, Christophe},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Banulescu, Candelon, Hurlin - 2012 - Do We Need Intra-Daily Data to Forecast Daily Volatility.pdf:pdf},
keywords = {high-frequency data,midas,volatility forecasting},
title = {{Do We Need Intra-Daily Data to Forecast Daily Volatility ?}},
year = {2012}
}
@article{poulsen:2009,
author = {Poulsen, Rolf and Schenk-Hopp{\'{e}}, Klaus Reiner and Ewald, Christian-Oliver},
doi = {10.1080/14697680902852738},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Poulsen, Schenk-Hopp{\'{e}}, Ewald - 2009 - Risk minimization in stochastic volatility models model risk and empirical performance.pdf:pdf},
issn = {1469-7688},
journal = {Quantitative Finance},
number = {6},
pages = {693--704},
title = {{Risk minimization in stochastic volatility models: model risk and empirical performance}},
url = {http://dx.doi.org/10.1080/14697680902852738},
volume = {9},
year = {2009}
}
@article{Wang2017,
author = {Wang, Yu},
journal = {2017 American Control Conference (ACC)},
pages = {5324--5329},
title = {{A new concept using LSTM Neural Networks for dynamic system identification}},
year = {2017}
}
@article{JensenNostatGARCH,
author = {Jensen, S{\"{o}}ren Tolver and Rahbek, Anders},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Jensen, Rahbek - 2004 - Asymptotic inference for nonstationary GARCH.pdf:pdf},
journal = {Econometric Theory},
number = {6},
pages = {1203--1226},
title = {{Asymptotic inference for nonstationary GARCH}},
volume = {20},
year = {2004}
}
@article{Dehouck2009,
author = {Dehouck, Yves and Grosfils, Aline and Folch, Benjamin and Gilis, Dimitri and Bogaerts, Philippe and Rooman, Marianne},
doi = {10.1093/bioinformatics/btp445},
journal = {Bioinformatics},
number = {19},
pages = {2537--2543},
title = {{Fast and accurate predictions of protein stability changes upon mutations using statistical potentials and neural networks: PoPMuSiC-2.0}},
url = {http://bioinformatics.oxfordjournals.org/content/25/19/2537.abstract},
volume = {25},
year = {2009}
}
@inproceedings{P2013,
address = {Heidelberg},
author = {Protter, Philip},
booktitle = {Paris-Princeton Lectures on Mathematical Finance 2013},
editor = {Henderson, Vicky and Sircar, Ronnie},
pages = {1--108},
publisher = {Springer International Publishing},
series = {Lecture Notes in Mathematics},
title = {{A mathematical theory of financial bubbles}},
url = {http://link.springer.com/10.1007/978-3-319-00413-6},
volume = {2081},
year = {2013}
}
@article{Audrino2019,
author = {Audrino, Francesco and Huang, Chen and Ostap, Okhrin},
journal = {Studies in Nonlinear Dynamics and Econometrics},
number = {3},
title = {{Flexible HAR model for realized volatility}},
volume = {23},
year = {2019}
}
@article{tse:dcc,
author = {Tse, Y. K. and Tsui, A. K. C.},
journal = {Journal of Business and Economic Statistics},
pages = {351--362},
title = {{A multivariate GARCH with time-varying correlations}},
volume = {20},
year = {2002}
}
@article{chen1957integration,
author = {Chen, Kuo-Tsai},
journal = {Annals of Mathematics},
number = {1},
pages = {163--178},
publisher = {JSTOR},
title = {{Integration of paths, geometric invariants and a generalized Baker-Hausdorff formula}},
volume = {65},
year = {1957}
}
@unpublished{Zhang2016,
abstract = {Despite their massive size, successful deep artificial neural networks can exhibit a remarkably small difference between training and test performance. Conventional wisdom attributes small generalization error either to properties of the model family, or to the regularization techniques used during training. Through extensive systematic experiments, we show how these traditional approaches fail to explain why large neural networks generalize well in practice. Specifically, our experiments establish that state-of-the-art convolutional networks for image classification trained with stochastic gradient methods easily fit a random labeling of the training data. This phenomenon is qualitatively unaffected by explicit regularization, and occurs even if we replace the true images by completely unstructured random noise. We corroborate these experimental findings with a theoretical construction showing that simple depth two neural networks already have perfect finite sample expressivity as soon as the number of parameters exceeds the number of data points as it usually does in practice. We interpret our experimental findings by comparison with traditional models.},
archivePrefix = {arXiv},
arxivId = {1611.03530},
author = {Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
eprint = {1611.03530},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Zhang et al. - 2016 - Understanding deep learning requires rethinking generalization.pdf:pdf},
title = {{Understanding deep learning requires rethinking generalization}},
url = {http://arxiv.org/abs/1611.03530},
year = {2016}
}
@book{riskmetrics,
address = {New York},
author = {Riskmetrics},
edition = {4th},
publisher = {J. P. Morgan},
title = {{Riskmetrics Technical Document}},
year = {1996}
}
@article{Fengler2009,
author = {Fengler, Matthias},
journal = {Quantitative Finance},
number = {4},
pages = {417--428},
title = {{Arbitrage-free smoothing of the implied volatility surface}},
volume = {9},
year = {2009}
}
@incollection{benenti:1983,
address = {Bologna},
author = {Benenti, S.},
booktitle = {Proceedings of the international meeting Geometry and Physics},
editor = {Modugno, M.},
pages = {11--41},
publisher = {Pitagora Editrice},
title = {{The category of symplectic reductions}},
year = {1983}
}
@article{sandberg:volterra:2,
author = {Sandberg, Irwin W.},
journal = {Circuits, Systems, and Signal Processing},
number = {6},
pages = {703--708},
title = {{A note on representation theorems for linear discrete-space systems}},
volume = {17},
year = {1998}
}
@article{Wainrib2016,
author = {Wainrib, Gilles and Galtier, Mathieu N.},
doi = {10.1016/j.neunet.2015.12.013},
journal = {Neural Networks},
month = {apr},
pages = {39--45},
title = {{A local echo state property through the largest Lyapunov exponent}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0893608015002828},
volume = {76},
year = {2016}
}
@article{Nyberg2008,
abstract = {In this paper, various financial variables are examined as predictors of the probability of a recession in the USA and Germany. We propose a new dynamic probit model that outperforms the standard static model, giving accurate out-of-sample forecasts in both countries for the recession period that began in 2001, as well as the beginning of the recession in 2008. In accordance with previous findings, the domestic term spread proves to be an important predictive variable, but stock market returns and the foreign term spread also have predictive power in both countries. In the case of Germany, the interest rate differential between the USA and Germany is also a useful additional predictor. Copyright 2009 John Wiley {\&} Sons, Ltd.},
author = {Nyberg, Henri},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Nyberg - 2008 - Dynamic probit models and financial variables in recession forecasting.pdf:pdf},
institution = {HECER},
issn = {02776693},
journal = {Journal of Forecasting},
number = {225},
pages = {215--230},
title = {{Dynamic probit models and financial variables in recession forecasting}},
url = {http://doi.wiley.com/10.1002/for.1161},
volume = {17},
year = {2008}
}
@unpublished{Luo2018,
author = {Luo, Ruiyan and Qi, Xin},
title = {{Interaction model and model selection for function-on-function regression}},
year = {2018}
}
@article{billio:2005,
author = {Billio, Monica and Caporin, Massimiliano},
journal = {Statistical Methods {\&} Applications},
pages = {145--161},
title = {{Multivariate Markov switching dynamic conditional correlation GARCH representations for contagion analysis}},
volume = {14},
year = {2005}
}
@book{bou,
author = {Bourbaki, N.},
publisher = {Hermann},
title = {{Vari{\'{e}}t{\'{e}}s diff{\'{e}}rentielles et analytiques. Fascicule de r{\'{e}}sultats}},
year = {1971}
}
@incollection{franke2000,
address = {London},
author = {Franke, J.},
booktitle = {Statistics and Finance: An Interface},
publisher = {Imperial College Press},
title = {{Portfolio management and market risk quantification using neural networks}},
year = {2000}
}
@article{LNA:19,
author = {Lyons, Terry and Nejad, Sina and Perez-Arribas, Imanol},
journal = {Preprint available at arXiv:1905.00711},
title = {{Nonparametric pricing and hedging of exotic derivatives}},
year = {2019}
}
@article{Bartlett2003,
abstract = {We investigate the use of certain data-dependent estimates of the complexity of a function class, called Rademacher and Gaussian complexities. In a decision theoretic setting, we prove general risk bounds in terms of these complexities. We consider function classes that can be expressed as combinations of functions from basis classes and show how the Rademacher and Gaussian complexities of such a function class can be bounded in terms of the complexity of the basis classes. We give examples of the application of these techniques in finding data-dependent risk bounds for decision trees, neural networks and support vector machines.},
archivePrefix = {arXiv},
arxivId = {arXiv:1507.02293v1},
author = {Bartlett, Peter L. and Mendelson, Shahar},
eprint = {arXiv:1507.02293v1},
journal = {Journal of Machine Learning Research},
keywords = {Data-Dependent Complexity,Error Bounds,Maximum Discrepancy,Rademacher Averages},
number = {3},
pages = {463--482},
pmid = {19477997},
title = {{Rademacher and Gaussian complexities: Risk bounds and structural results}},
volume = {3},
year = {2003}
}
@unpublished{cholcov2016,
author = {Boudt, K. and Laurent, S{\'{e}}bastien and Lunde, A. and Quaedvlieg, R. and Orimar, S.},
title = {{Positive semidefinite integrated covariance estimation, factorizations and asynchronicity}},
year = {2016}
}
@inproceedings{cabessa:2015,
author = {Cabessa, Jeremie and Villa, Alessandro E.P.},
booktitle = {2015 International Joint Conference on Neural Networks (IJCNN)},
doi = {10.1109/IJCNN.2015.7280648},
isbn = {978-1-4799-1960-4},
month = {jul},
pages = {1--8},
publisher = {IEEE},
title = {{Computational capabilities of recurrent neural networks based on their attractor dynamics}},
url = {http://ieeexplore.ieee.org/document/7280648/},
year = {2015}
}
@unpublished{Szegedy2013,
author = {Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley//Szegedy et al. - 2013 - Intriguing properties of neural networks.pdf:pdf},
series = {arXiv preprint arXiv:1312.6199},
title = {{Intriguing properties of neural networks}},
year = {2013}
}
@article{Dongsung:2015,
abstract = {In a planar free-hand drawing of an ellipse, the speed of movement is proportional to the -1/3 power of the local curvature, which is widely thought to hold for general curved shapes. We investigated this phenomenon for general curved hand movements by analyzing an optimal control model that maximizes a smoothness cost and exhibits the -1/3 power for ellipses. For the analysis, we introduced a new representation for curved movements based on a moving reference frame and a dimensionless angle coordinate that revealed scale-invariant features of curved movements. The analysis confirmed the power law for drawing ellipses but also predicted a spectrum of power laws with exponents ranging between 0 and -2/3 for simple movements that can be characterized by a single angular frequency. Moreover, it predicted mixtures of power laws for more complex, multifrequency movements that were confirmed with human drawing experiments. The speed profiles of arbitrary doodling movements that exhibit broadband curvature profiles were accurately predicted as well. These findings have implications for motor planning and predict that movements only depend on one radian of angle coordinate in the past and only need to be planned one radian ahead.},
author = {Huh, Dongsung and Sejnowski, Terrence J.},
doi = {10.1073/pnas.1510208112},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Huh, Sejnowski - 2015 - Spectrum of power laws for curved hand movements.pdf:pdf},
issn = {10916490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Free-hand drawing,Motor system,Optimal control,Power law},
number = {29},
pages = {E3950--E3958},
title = {{Spectrum of power laws for curved hand movements}},
volume = {112},
year = {2015}
}
@article{Gerber94,
author = {Gerber, H. U. and Shiu, E. S. W.},
journal = {Transactions of the Society of Actuaries},
pages = {99--191},
title = {{Option pricing by Esscher transforms}},
volume = {46},
year = {1994}
}
@article{mourier,
author = {Mourier, Edith},
journal = {Annales de l'Institut Henri Poincar{\'{e}}},
number = {3},
pages = {161--244},
title = {{El{\'{e}}ments al{\'{e}}atoires dans un espace de Banach}},
volume = {13},
year = {1953}
}
@article{Yildiz2012,
abstract = {An echo state network (ESN) consists of a large, randomly connected neural network, the reservoir, which is driven by an input signal and projects to output units. During training, only the connections from the reservoir to these output units are learned. A key requisite for output-only training is the echo state property (ESP), which means that the effect of initial conditions should vanish as time passes. In this paper, we use analytical examples to show that a widely used criterion for the ESP, the spectral radius of the weight matrix being smaller than unity, is not sufficient to satisfy the echo state property. We obtain these examples by investigating local bifurcation properties of the standard ESNs. Moreover, we provide new sufficient conditions for the echo state property of standard sigmoid and leaky integrator ESNs. We furthermore suggest an improved technical definition of the echo state property, and discuss what practicians should (and should not) observe when they optimize their reservoirs for specific tasks.},
author = {Yildiz, Izzet B and Jaeger, Herbert and Kiebel, Stefan J},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Yildiz, Jaeger, Kiebel - 2012 - Re-visiting the echo state property.pdf:pdf},
issn = {1879-2782},
journal = {Neural Networks},
keywords = {Algorithms,Computer Simulation,Learning,Models,Neural Networks (Computer),Neurological,Neurons,Neurons: physiology,Nonlinear Dynamics,Time Factors},
month = {nov},
pages = {1--9},
title = {{Re-visiting the echo state property.}},
volume = {35},
year = {2012}
}
@article{Banerjee2006,
author = {Banerjee, Anindya and Marcellino, Massimiliano},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Banerjee, Marcellino - 2006 - Are there any reliable leading indicators for US inflation and GDP growth.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {factor model,gdp growth,inflation,leading indicator,model selection},
month = {jan},
number = {1},
pages = {137--151},
title = {{Are there any reliable leading indicators for US inflation and GDP growth?}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S016920700500035X},
volume = {22},
year = {2006}
}
@phdthesis{ding:thesis,
author = {Ding, Z},
school = {University of California, San Diego},
title = {{Time Series Analysis of Speculative Returns}},
year = {1994}
}
@book{casella:berger,
author = {Casella, George and Berger, Roger L.},
edition = {Second},
pages = {660},
publisher = {Duxbury},
title = {{Statistical Inference}},
year = {2002}
}
@article{farkas:bosak:2016,
abstract = {Reservoir computing became very popular due to its potential for efficient design of recurrent neural networks, exploiting the computational properties of the reservoir structure. Various approaches, ranging from appropriate reservoir initialization to its optimization by training have been proposed. In this paper, we extend our previous work and focus on short-term memory capacity, introduced by Jaeger in case of echo state networks. Memory capacity has been previously shown to peak at criticality, when the network switches from a stable regime to an unstable dynamic regime. Using computational experiments with nonlinear ESNs, we systematically analyze the memory capacity from the perspective of several parameters and their relationship, namely the input and reservoir weights scaling, reservoir size and its sparsity. We also derive and test two gradient descent based orthogonalization procedures for recurrent weights matrix, which considerably increase the memory capacity, approaching the upper bound, which is equal to the reservoir size, as proved for linear reservoirs. Orthogonalization procedures are discussed in the context of existing methods and their benefit is assessed.},
author = {Farkas, Igor and Bosak, Radomir and Gergel, Peter},
doi = {10.1016/j.neunet.2016.07.012},
isbn = {0893-6080},
issn = {18792782},
journal = {Neural Networks},
keywords = {Echo-state network,Memory capacity,Reservoir orthogonalization,Spectral properties},
pages = {109--120},
title = {{Computational analysis of memory capacity in echo state networks}},
volume = {83},
year = {2016}
}
@book{Bishop1996,
author = {Bishop, Christopher M.},
title = {{Neural Networks for Pattern Recognition}},
year = {1996}
}
@article{mackey-glass:paper,
author = {Mackey, M. C. and Glass, L.},
journal = {Science},
pages = {287--289},
title = {{Oscillation and chaos in physiological control systems}},
volume = {197},
year = {1977}
}
@book{connes:1994,
author = {Connes, A.},
publisher = {Academic Press},
title = {{Noncommutative Geometry}},
year = {1994}
}
@misc{BO2013,
author = {Brunnermeier, Markus K. and Oehmke, Martin},
booktitle = {Handbook of the Economics of Finance},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Brunnermeier, Oehmke - 2013 - Bubbles, financial crises, and systemic risk.pdf:pdf},
month = {sep},
pages = {1221--1288},
publisher = {Elsevier},
title = {{Bubbles, financial crises, and systemic risk}},
url = {http://www.nber.org/papers/w18398},
year = {2013}
}
@article{Chodera2014,
author = {Chodera, John D and No{\'{e}}, Frank},
doi = {10.1016/j.sbi.2014.04.002},
issn = {1879-033X},
journal = {Current opinion in structural biology},
keywords = {markov},
month = {apr},
pages = {135--144},
pmid = {24836551},
title = {{Markov state models of biomolecular conformational dynamics}},
url = {http://dx.doi.org/10.1016/j.sbi.2014.04.002},
volume = {25},
year = {2014}
}
@article{ortega:garch:pricing,
abstract = {We apply a quadratic hedging scheme developed by F{\"{o}}llmer, Schweizer, and Sondermann to European contingent products whose underlying asset is modeled using a GARCH process and show that local risk-minimizing strategies with respect to the physical measure do exist, even though an associated minimal martingale measure is only available in the presence of bounded innovations. More importantly, since those local risk-minimizing strategies are in general convoluted and difficult to evaluate, we introduce Girsanov-like risk-neutral measures for the log-prices that yield more tractable and useful results. Regarding this subject, we focus on GARCH time series models with Gaussian innovations and we provide specific sufficient conditions concerning the finiteness of the kurtosis, under which those martingale measures are appropriate in the context of quadratic hedging. When this equivalent martingale measure is adapted to the price representation we are able to recover the classical pricing formulas of Duan and Heston and Nandi, as well as hedging schemes that improve the performance of those proposed in the literature.
We apply a quadratic hedging scheme developed by F{\"{o}}llmer, Schweizer, and Sondermann to European contingent products whose underlying asset is modeled using a GARCH process and show that local risk-minimizing strategies with respect to the physical measure do exist, even though an associated minimal martingale measure is only available in the presence of bounded innovations. More importantly, since those local risk-minimizing strategies are in general convoluted and difficult to evaluate, we introduce Girsanov-like risk-neutral measures for the log-prices that yield more tractable and useful results. Regarding this subject, we focus on GARCH time series models with Gaussian innovations and we provide specific sufficient conditions concerning the finiteness of the kurtosis, under which those martingale measures are appropriate in the context of quadratic hedging. When this equivalent martingale measure is adapted to the price representation we are able to recover the classical pricing formulas of Duan and Heston and Nandi, as well as hedging schemes that improve the performance of those proposed in the literature.},
author = {Ortega, Juan-Pablo},
doi = {10.1080/14697688.2010.494164},
issn = {1469-7688},
journal = {Quantitative Finance},
month = {oct},
number = {7},
pages = {1095--1110},
publisher = {Routledge},
title = {{GARCH options via local risk minimization}},
url = {http://www.tandfonline.com/doi/abs/10.1080/14697688.2010.494164},
volume = {12},
year = {2012}
}
@article{Carr1999,
author = {Carr, R. and Madan, Dilip B.},
journal = {Journal of Computational Finance},
number = {4},
pages = {61--73},
title = {{Option valuation using the Fast Fourier Transform}},
volume = {2},
year = {1999}
}
@article{SVGARCHSteady,
author = {Barndorff-Nielsen, Ole E. and Shephard, Neil},
journal = {J. Roy. Statist. Soc. Ser. B},
pages = {167--241},
title = {{Non-Gaussian OU based mod- els and some of their uses in financial economics (with discussion)}},
volume = {63},
year = {2001}
}
@article{ekeland:lasry:80,
author = {Ekeland, I and Lasry, J.-M.},
journal = {Ann. Math.},
pages = {283--319},
title = {{On the number of periodic trajectories for a Hamiltonian flow on a convex energy surface}},
volume = {112},
year = {1980}
}
@article{filed:82,
author = {Field, M. J.},
journal = {Bull. Austral. Math. Soc.},
pages = {161--180},
title = {{On the structure of a class of equivariant maps}},
volume = {26},
year = {1982}
}
@article{pascal:hopf,
author = {Chossat, P. and Ortega, J.-P. and Ratiu, T. S.},
journal = {Archive for Rational Mechanics and Analysis},
pages = {1--33},
title = {{Hamiltonian Hopf bifurcation with symmetry}},
volume = {163},
year = {2002}
}
@article{Hogarth1992,
author = {Hogarth, Robin M and Einhorn, Hillel J},
journal = {Cognitive Psychology},
pages = {1--55},
title = {{Order effects in belief updating: The belief adjustment model}},
volume = {24},
year = {1992}
}
@inproceedings{Duchi2010a,
abstract = {We present a new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning. Metaphorically, the adaptation allows us to find needles in haystacks in the form of very predictive but rarely seen features. Our paradigm stems from recent advances in stochastic optimization and online learning which employ proximal functions to control the gradient steps of the algorithm. We describe and analyze an apparatus for adaptively modifying the proximal function, which significantly simplifies setting a learning rate and results in regret guarantees that are provably as good as the best proximal function that can be chosen in hindsight. We give several efficient algorithms for empirical risk minimization problems with common and important regularization functions and domain constraints. We experimentally study our theoretical analysis and show that adaptive subgradient methods outperform state-of-the-art, yet non-adaptive, subgradient algorithms.},
author = {Duchi, John and Hazan, Elad and Singer, Yoram},
booktitle = {COLT 2010 - The 23rd Conference on Learning Theory},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Duchi, Hazan, Singer - 2010 - Adaptive subgradient methods for online learning and stochastic optimization.pdf:pdf},
isbn = {9780982252925},
keywords = {adaptivity,online learning,stochastic convex optimization,subgradient methods},
pages = {257--269},
title = {{Adaptive subgradient methods for online learning and stochastic optimization}},
volume = {12},
year = {2010}
}
@phdthesis{Foroni2012a,
author = {Foroni, Claudia},
booktitle = {Doctor},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Foroni - 2012 - Econometric Models for Mixed-Frequency Data.pdf:pdf},
number = {September},
school = {European University Institute},
title = {{Econometric Models for Mixed-Frequency Data}},
year = {2012}
}
@article{Liesenfeld2003,
author = {Liesenfeld, Roman and Richard, Jean-Fran{\c{c}}ois},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Liesenfeld, Richard - 2003 - Univariate and multivariate stochastic volatility models estimation and diagnostics.pdf:pdf},
journal = {Journal of Empirical Finance},
number = {4},
pages = {505--531},
title = {{Univariate and multivariate stochastic volatility models: estimation and diagnostics}},
url = {http://www.sciencedirect.com.ezproxy.lib.ucalgary.ca/science/article/pii/S0927539802000725},
volume = {10},
year = {2003}
}
@techreport{Charles2017,
abstract = {Recurrent neural networks (RNNs) have drawn interest from machine learning researchers because of their effectiveness at preserving past inputs for time-varying data processing tasks. To understand the success and limitations of RNNs, it is critical that we advance our analysis of their fundamental memory properties. We focus on echo state networks (ESNs), which are RNNs with simple memoryless nodes and random connectivity. In most existing analyses, the short-term memory (STM) capacity results conclude that the ESN network size must scale linearly with the input size for unstructured inputs. The main contribution of this paper is to provide general results characterizing the STM capacity for linear ESNs with multidimensional input streams when the inputs have common low-dimensional structure: sparsity in a basis or significant statistical dependence between inputs. In both cases, we show that the number of nodes in the network must scale linearly with the information rate and poly-logarithmically with the input dimension. The analysis relies on advanced applications of random matrix theory and results in explicit non-asymptotic bounds on the recovery error. Taken together, this analysis provides a significant step forward in our understanding of the STM properties in RNNs.},
author = {Charles, Adam S and Yin, Dong and Rozell, Christopher J},
booktitle = {Journal of Machine Learning Research},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Charles, Yin, Rozell - 2017 - Distributed sequence memory of multidimensional inputs in recurrent networks.pdf:pdf},
pages = {1--37},
title = {{Distributed sequence memory of multidimensional inputs in recurrent networks}},
url = {http://www.jmlr.org/papers/volume18/16-270/16-270.pdf},
volume = {18},
year = {2017}
}
@book{Hairer2002,
address = {Berlin},
author = {Hairer, E. and Lubich, C. and Wanner, G.},
publisher = {Springer},
title = {{Geometric numerical integration}},
year = {2002}
}
@unpublished{Manneschi2019,
author = {Manneschi, Luca and Lin, Andrew C. and Vasilaki, Eleni},
title = {{SpaRCe: Sparse reservoir computing}},
year = {2019}
}
@article{Mullainathan:Spiess,
abstract = {Machines are increasingly doing "intelligent" things. Face recognition algorithms use a large dataset of photos labeled as having a face or not to estimate a function that predicts the presence y of a face from pixels x. This similarity to econometrics raises questions: How do these new empirical tools fit with what we know? As empirical economists, how can we use them? We present a way of thinking about machine learning that gives it its own place in the econometric toolbox. Machine learning not only provides new tools, it solves a different problem. Specifically, machine learning revolves around the problem of prediction, while many economic applications revolve around parameter estimation. So applying machine learning to economics requires finding relevant tasks. Machine learning algorithms are now technically easy to use: you can download convenient packages in R or Python. This also raises the risk that the algorithms are applied naively or their output is misinterpreted. We hope to make them conceptually easier to use by providing a crisper understanding of how these algorithms work, where they excel, and where they can stumble—and thus where they can be most usefully applied.},
author = {Mullainathan, Sendhil and Spiess, Jann},
doi = {10.1257/jep.31.2.87},
issn = {0895-3309},
journal = {Journal of Economic Perspectives},
number = {2},
pages = {87--106},
title = {{Machine learning: an applied econometric approach}},
url = {http://pubs.aeaweb.org/doi/10.1257/jep.31.2.87},
volume = {31},
year = {2017}
}
@article{Fleming2003,
abstract = {We show that, for three common SARV models, fitting a minimum mean square linear filter is equivalent to fitting a GARCH model. This suggests that GARCH models may be useful for filtering, forecasting, and parameter estimation in stochastic volatility settings. To investigate, we use simulations to evaluate how the three SARV models and their associated GARCH filters perform under controlled conditions and then we use daily currency and equity index returns to evaluate how the models perform in a risk management application. Although the GARCH models produce less precise forecasts than the SARV models in the simulations, it is not clear that the performance differences are large enough to be economically meaningful. Consistent with this view, we find that the GARCH and SARV models perform comparably in tests of conditional value-at-risk estimates using the actual data.},
author = {Fleming, J. and Kirby, Chris},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Fleming - 2003 - A closer look at the relation between GARCH and stochastic autoregressive volatility.pdf:pdf},
issn = {1479-8409},
journal = {Journal of Financial Econometrics},
month = {sep},
number = {3},
pages = {365--419},
title = {{A closer look at the relation between GARCH and stochastic autoregressive volatility}},
url = {http://jfec.oxfordjournals.org/content/1/3/365.short},
volume = {1},
year = {2003}
}
@article{mwr,
author = {Marsden, Jerrold E. and Weinstein, Alan},
journal = {Reports on Mathematical Physics},
number = {1},
pages = {121--130},
title = {{Reduction of symplectic manifolds with symmetry}},
volume = {5},
year = {1974}
}
@article{Pascual2001,
abstract = {We use a bootstrap procedure to study the impact of parameter estimation on prediction densities, focusing on seasonal ARIMA processes with possibly non normal innovations. We compare prediction densities obtained using the Box and Jenkins approach with bootstrap densities which may be constructed either taking into account parameter estimation variability or using parameter estimates as if they were known parameters. By means of Monte Carlo experiments, we show that the average coverage of the intervals is closer to the nominal value when intervals are constructed incorporating parameter uncertainty. The effects of parameter estimation are particularly important for small sample sizes and when the error distribution is not Gaussian. We also analyze the effect of the estimation method on the shape of prediction densities comparing prediction densities constructed when the parameters are estimated by Ordinary Least Squares (OLS) and by Least Absolute Deviations (LAD). We show how, when the error distribution is not Gaussian, the average coverage and length of intervals based on LAD estimates are closer to nominal values than those based on OLS estimates. Finally, the performance of the bootstrap intervals is illustrated with two empirical examples.},
author = {Pascual, Lorenzo and Romo, Juan and Ruiz, Esther},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {forecasting,least absolute deviations,non normal distributions,ordinary least squares},
month = {jan},
number = {1},
pages = {83--103},
title = {{Effects of parameter estimation on prediction densities: a bootstrap approach}},
url = {http://dx.doi.org/10.1016/S0169-2070(00)00069-8},
volume = {17},
year = {2001}
}
@article{Ikramov2018,
abstract = {A simple proof of Williamson's theorem is given. This theorem states that a real symmetric positive definite matrix A of even order can be brought to diagonal form $\Lambda$ by a symplectic congruence transformation. The diagonal entries of $\Lambda$ are called symplectic eigenvalues of A. The problem of calculating these values is also discussed.},
author = {Ikramov, Kh. D},
doi = {10.3103/S0278641918010041},
issn = {1934-8428},
journal = {Moscow University Computational Mathematics and Cybernetics},
pages = {1--4},
title = {{On the symplectic eigenvalues of positive definite matrices}},
volume = {42},
year = {2018}
}
@article{Pascual2006,
abstract = {A new bootstrap procedure to obtain prediction densities of returns and volatilities of GARCH processes is proposed. Financial market participants have shown an increasing interest in prediction intervals as measures of uncertainty. Furthermore, accurate predictions of volatilities are critical for many financial models. The advantages of the proposed method are that it allows incorporation of parameter uncertainty and does not rely on distributional assumptions. The finite sample properties are analyzed by an extensive Monte Carlo simulation. Finally, the technique is applied to the Madrid Stock Market index, IBEX-35.},
author = {Pascual, Lorenzo and Romo, Juan and Ruiz, Esther},
issn = {01679473},
journal = {Computational Statistics {\&} Data Analysis},
keywords = {non-gaussian distributions,nonlinear models,resampling methods,time series},
month = {may},
number = {9},
pages = {2293--2312},
title = {{Bootstrap prediction for returns and volatilities in GARCH models}},
url = {http://dx.doi.org/10.1016/j.csda.2004.12.008},
volume = {50},
year = {2006}
}
@article{Mukherjee2002,
author = {Mukherjee, Sayan and Niyogi, Partha and Poggio, Tomaso and Rifkin, Ryan},
journal = {Advances in Computational Mathematics},
number = {1-3},
pages = {161--193},
title = {{Learning theory: stability is sufficient for generalization and necessary and sufficient for consistency of empirical risk minimization}},
volume = {25},
year = {2006}
}
@article{Reesor04,
author = {McLeish, D. L. and Reesor, R. M.},
journal = {North American Actuarial Journal},
number = {2},
pages = {128--144},
title = {{Risk, entropy, and the transformation of distributions}},
volume = {7},
year = {2003}
}
@article{kilian:1996,
abstract = {We investigate the computational power of recurrent neural networks that apply the sigmoid activation function $\sigma$(x) = [2/(1 + e-x)] - 1. These networks are extensively used in automatic learning of non-linear dynamical behavior. We show that in the noiseless model, there exists a universal architecture that can be used to compute any recursive (Turing) function. This is the first result of its kind for the sigmoid activation function; previous techniques only applied to linearized and truncated version of this function. The significance of our result, besides the proving technique itself, lies in the popularity of the sigmoidal function both in engineering applications of artificial neural networks and in biological modelling. Our techniques can be applied to a much more general class of "sigmoidal-like" activation functions, suggesting that Turing universality is a relatively common property of recurrent neural network models. {\textcopyright} 1996 Academic Press, Inc.},
author = {Kilian, Joe and Siegelmann, Hava T.},
doi = {10.1006/inco.1996.0062},
issn = {08905401},
journal = {Information and Computation},
number = {1},
pages = {48--56},
title = {{The dynamic universality of sigmoidal neural networks}},
volume = {128},
year = {1996}
}
@article{Vinckier2015,
author = {Vinckier, Q and Duport, F and Smerieri, A and Vandoorne, K and Bienstman, Peter and Haelterman, M. and Massar, S.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Vinckier et al. - 2015 - High-performance photonic reservoir computer based on a coherently driven passive cavity.pdf:pdf},
journal = {Optica},
number = {5},
pages = {438--446},
title = {{High-performance photonic reservoir computer based on a coherently driven passive cavity}},
url = {https://www.osapublishing.org/abstract.cfm?uri=optica-2-5-438},
volume = {2},
year = {2015}
}
@book{germs,
author = {Br{\"{o}}cker, Th. and Lander, L.},
booktitle = {London Mathematical Society Lecture Note Series},
publisher = {Cambridge University Press},
title = {{Differentiable germs and catastrophes}},
volume = {17},
year = {1975}
}
@book{boothby2003introduction,
author = {Boothby, William M},
edition = {Second rev},
publisher = {Academic Press, Inc.},
title = {{An Introduction to Differentiable Manifolds and Riemannian Geometry}},
year = {2003}
}
@incollection{cizek:spokoini,
address = {Berlin, Heidelberg},
author = {Cizek, Pavel and Spokoiny, Vladimir},
booktitle = {Handbook of Financial Time Series},
editor = {Mikosch, Thomas and Krei{\ss}, Jens-Peter and Davis, Richard A. and Andersen, Torben Gustav},
pages = {169--185},
publisher = {Springer Berlin Heidelberg},
title = {{Varying coefficient GARCH models}},
url = {http://www.springerlink.com/index/10.1007/978-3-540-71297-8},
year = {2009}
}
@article{manjunath:tino:jaeger,
abstract = {Most dynamic models of interest in machine learning, robotics, AI or cognitive science are nonautonomous and input-driven. In the last few years number of important innovations have occurred in mathemati- cal research on nonautonomous systems. In understanding the long term behavior of nonautonomous systems, the notion of an attractor is fun- damental. With a time varying input, it turns out that for a notion of an attractor to be useful, the attractor cannot a single subset, but must be conceived as a sequence of sets varying with time as well. The aim of this tutorial is to illuminate useful notions of attractors of nonautonomous systems, and also introduce some newly emerging concepts of dynamical systems theory which are particularly relevant for input driven systems.},
author = {Manjunath, G. and Tiňo, P. and Jaeger, H.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Manjunath, Tiňo, Jaeger - 2012 - Theory of input driven dynamical systems.pdf:pdf},
isbn = {9782874190490},
journal = {ESANN 2012 proceedings, 20th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning},
pages = {1--12},
title = {{Theory of input driven dynamical systems}},
year = {2012}
}
@article{sandberg:volterra:3,
author = {Sandberg, Irwin W.},
journal = {Mathematical Problems in Engineering},
pages = {369--375},
title = {{A representation theorem for linear discrete-space systems}},
volume = {4},
year = {1998}
}
@article{fliess:1981,
author = {Fliess, Michel},
journal = {Bull. Soc. Math. France},
pages = {3--40},
title = {{Fonctionnelles causales non lin{\'{e}}aires et ind{\'{e}}termin{\'{e}}es non commutatives}},
volume = {109},
year = {1981}
}
@article{RC6,
abstract = {A new class of non-homogeneous state-affine systems is introduced. Sufficient conditions are identified that guarantee first, that the associated reservoir computers with linear readouts are causal, time-invariant, and satisfy the fading memory property and second, that a subset of this class is universal in the category of fading memory filters with stochastic almost surely bounded inputs. This means that any discrete-time filter that satisfies the fading memory property with random inputs of that type can be uniformly approximated by elements in the non-homogeneous state-affine family.},
archivePrefix = {arXiv},
arxivId = {1712.00754},
author = {Grigoryeva, Lyudmila and Ortega, Juan-Pablo},
eprint = {1712.00754},
journal = {Journal of Machine Learning Research},
number = {24},
pages = {1--40},
title = {{Universal discrete-time reservoir computers with stochastic inputs and linear readouts using non-homogeneous state-affine systems}},
url = {http://arxiv.org/abs/1712.00754},
volume = {19},
year = {2018}
}
@article{Hamilton2001,
annote = {
        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

        

   },
author = {Hamilton, James D. and Kim, Dong Heon},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Hamilton, Kim - 2002 - A Reexamination of the Predictability of Economic Activity Using the Yield Spread.pdf:pdf;:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Hamilton, Kim - 2001 - A Re-examination of the Predictability of Economic Activity Using the Yield Spread.pdf:pdf},
issn = {1556-5068},
journal = {Journal of Money, Credit, and Banking},
number = {2},
pages = {340--360},
title = {{A Re-examination of the Predictability of Economic Activity Using the Yield Spread}},
url = {http://www.ssrn.com/abstract=245584 http://muse.jhu.edu/content/crossref/journals/journal{\_}of{\_}money{\_}credit{\_}and{\_}banking/v034/34.2hamilton.pdf},
volume = {34},
year = {2002}
}
@unpublished{bauwens:otranto:vdcc,
author = {Bauwens, Luc and Otranto, Edoardo},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Bauwens, Otranto - 2013 - Modeling the dependence of conditional correlations on volatility.pdf:pdf},
title = {{Modeling the dependence of conditional correlations on volatility}},
year = {2013}
}
@article{Petrosian2000,
abstract = {Predicting the onset of epileptic seizure is an important and di{\$}cult biomedical problem, which has attracted substantial attention of the intelligent computing community over the past two decades. We apply recurrent neural networks (RNN) combined with signal wavelet decomposition to the problem. We input raw EEG and its wavelet-decomposed subbands into RNNtraining/testing, as opposed to speci"c signal features extracted from EEG. To the best of our knowledge this approach has never been attempted before. The data used included both scalp and intracranial EEG recordings obtained from two epileptic patients. We demonstrate that the existence of a `preictala stage (immediately preceding seizure) of some minutes duration is quite feasible. },
author = {Petrosian, Arthur and Prokhorov, Danil and Homan, Richard},
journal = {Neurocomputing},
keywords = {eeg,epileptic seizure,recurrent neural network,wavelet transform},
pages = {201--218},
title = {{Recurrent neural network based prediction of epileptic seizures in intra-and extracranial EEG}},
url = {http://www.sciencedirect.com/science/article/pii/S0925231299001265},
volume = {30},
year = {2000}
}
@article{DCC_BGO,
author = {Bauwens, Luc and Grigoryeva, Lyudmila and Ortega, Juan-Pablo},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Bauwens, Grigoryeva, Ortega - 2016 - Estimation and empirical performance of non-scalar dynamic conditional correlation models.pdf:pdf},
journal = {Computational Statistics and Data Analysis},
pages = {17--36},
title = {{Estimation and empirical performance of non-scalar dynamic conditional correlation models}},
volume = {100},
year = {2016}
}
@inproceedings{Rahimi2008,
abstract = {Random networks of nonlinear functions have a long history of empirical success in function fitting but few theoretical guarantees. In this paper, using techniques from probability on Banach Spaces, we analyze a specific architecture of random nonlinearities, provide Linfin and L2 error bounds for approximating functions in Reproducing Kernel Hilbert Spaces, and discuss scenarios when these expansions are dense in the continuous functions. We discuss connections between these random nonlinear networks and popular machine learning algorithms and show experimentally that these networks provide competitive performance at far lower computational cost on large-scale pattern recognition tasks.},
author = {Rahimi, Ali and Recht, Benjamin},
booktitle = {46th Annual Allerton Conference on Communication, Control, and Computing},
doi = {10.1109/ALLERTON.2008.4797607},
isbn = {9781424429264},
title = {{Uniform approximation of functions with random bases}},
year = {2008}
}
@article{Kuk_CL_2000,
author = {Kuk, Anthony Y C and Nott, David J},
journal = {Statistics {\&} Probability Letters},
pages = {329--335},
title = {{A pairwise likelihood approach to analyzing correlated binary data}},
volume = {47},
year = {2000}
}
@incollection{duistermaat:84,
author = {Duistermaat, J. J.},
booktitle = {Bifurcation Theory and Applications},
edition = {Lecture No},
editor = {Salvadori, L},
publisher = {Springer Verlag},
title = {{Bifurcations of periodic solutions near equilibrium points of Hamiltonian systems}},
volume = {1057},
year = {1984}
}
@article{Rosenberg2006,
author = {Rosenberg, Joshua V and Maurer, Samuel},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Rosenberg, Maurer - 2006 - Signal or Noise Implications of the Term Premium for Recession Forecasting.pdf:pdf},
journal = {Economic Policy Review},
keywords = {recession forecasting,term premiu,term structure},
pages = {1--11},
title = {{Signal or noise? Implications of the term premium for recession forecasting}},
year = {2006}
}
@article{Craddock2000,
author = {Craddock, M. and Heath, D. and Platen, E.},
journal = {Journal of Computational Finance},
title = {{Numerical inversion of Laplace transforms: Survey of techniques with applications to derivative pricing}},
year = {2000}
}
@article{Lutkepohl1986a,
author = {L{\"{u}}tkepohl, Helmut},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/L{\"{u}}tkepohl - 1986 - Comparison of predictors for aggregated time series.pdf:pdf},
journal = {International Journal of Forecasting},
pages = {461--475},
title = {{Comparison of predictors for aggregated time series}},
volume = {2},
year = {1986}
}
@article{mori:kurtosis,
author = {M{\'{o}}ri, T F and Rohatgi, V K and Sz{\'{e}}kely, G J},
issn = {0040-361X},
journal = {Theory Probab. Appl.},
number = {3},
pages = {547--551},
title = {{On multivariate skewness and kurtosis}},
volume = {38},
year = {1993}
}
@article{Ling2002,
abstract = {This paper investigates some structural properties of a family of GARCH processes. A simple sufficient condition for the existence of the $\alpha$$\delta$-order stationary solution of the processes is derived, where $\alpha$∈(0,1] and $\delta${\textgreater}0. The solution is strictly stationary and ergodic, and the causal expansion of the family of GARCH processes is also established. Furthermore, the necessary and sufficient condition for the existence of the moments is obtained. The technique used in this paper for the moment conditions is different from that used in He and Terasvirta (J. Econom. 92 (1999a) 173), and avoids the assumption that the process started at some finite value infinitely many periods ago. Moreover, the conditions for the strict stationarity of the model and the existence of its moments are simple to check and should prove useful in practice.},
author = {Ling, Shiqing and McAleer, Michael},
issn = {03044076},
journal = {Journal of Econometrics},
keywords = {C22,C51,Ergodicity,Existence of moments,GARCH,Stationarity},
month = {jan},
number = {1},
pages = {109--117},
title = {{Stationarity and the existence of moments of a family of GARCH processes}},
url = {http://www.sciencedirect.com/science/article/pii/S0304407601000902},
volume = {106},
year = {2002}
}
@techreport{Demertzis2010,
author = {Demertzis, Maria and Marcellino, Massimiliano and Viegi, Nicola},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Demertzis, Marcellino, Viegi - 2010 - Anchors for inflation expectations.pdf:pdf},
institution = {EUI},
series = {Department of Economics},
title = {{Anchors for inflation expectations}},
year = {2010}
}
@article{benenti:tulczyjew:1982,
author = {Benenti, S. and Tulczyjew, W. M.},
journal = {C. R. Acad. Sc. Paris},
pages = {561--564},
title = {{Remarques sur les r{\'{e}}ductions symplectiques}},
volume = {294},
year = {1982}
}
@article{widom1966small,
author = {Widom, Harold and Wilf, Herbert},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Widom, Wilf - 1966 - Small eigenvalues of large Hankel matrices.pdf:pdf},
journal = {Proceedings of the American Mathematical Society},
number = {2},
pages = {338--344},
publisher = {JSTOR},
title = {{Small eigenvalues of large Hankel matrices}},
volume = {17},
year = {1966}
}
@article{GST_GOP_2015,
author = {Grigoryeva, Lyudmila and Ortega, Juan-Pablo and Peresetsky, Anatoly},
journal = {Econometrics and Statistics},
pages = {67--82},
title = {{Volatility forecasting using global stochastic financial trends extracted from non-synchronous data}},
volume = {5},
year = {2018}
}
@techreport{Rigollet:notes,
author = {Rigollet, Philippe},
title = {{High Dimensional Statistics}},
year = {2015}
}
@unpublished{Camacho2010,
author = {Camacho, Maximo and Perez-quiros, Gabriel and Poncela, Pilar},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Camacho, Perez-quiros, Poncela - 2010 - Green shoots in the Euro area. A real time measure.pdf:pdf},
institution = {Banco de Expana},
keywords = {Business Cycles,Output Growth,Time Series.},
title = {{Green shoots in the Euro area. A real time measure}},
year = {2010}
}
@article{Ikeda1979,
abstract = {In the stationary situation the transmitted light by a ring cavity containing a homogeneously broadened two level absorber exhibits a multiple-valued response to a constant incident light. The stability of the stationary state is investigated in the fast limit of the atomic relaxation. The stationary state is not always stable even when it belongs to the branch with a positive differential gain. In some cases all the stationary states becomes unstable and the transmitted light exhibits a “chaotic” behavior.},
author = {Ikeda, Kensuke},
issn = {00304018},
journal = {Optics Communications},
month = {aug},
number = {2},
pages = {257--261},
title = {{Multiple-valued stationary state and its instability of the transmitted light by a ring cavity system}},
volume = {30},
year = {1979}
}
@inproceedings{mincer:zarnowitz,
address = {New York},
author = {Mincer, J and Zarnowitz, V},
booktitle = {Economics Forecasts and Expectations},
editor = {Mincer, J},
publisher = {National Bureau of Economic Research},
title = {{The evaluation of economic forecasts}},
year = {1969}
}
@article{zhou:2020,
abstract = {Deep learning has been widely applied and brought breakthroughs in speech recognition, computer vision, and many other domains. Deep neural network architectures and computational issues have been well studied in machine learning. But there lacks a theoretical foundation for understanding the approximation or generalization ability of deep learning methods generated by the network architectures such as deep convolutional neural networks. Here we show that a deep convolutional neural network (CNN) is universal, meaning that it can be used to approximate any continuous function to an arbitrary accuracy when the depth of the neural network is large enough. This answers an open question in learning theory. Our quantitative estimate, given tightly in terms of the number of free parameters to be computed, verifies the efficiency of deep CNNs in dealing with large dimensional data. Our study also demonstrates the role of convolutions in deep CNNs.},
archivePrefix = {arXiv},
arxivId = {1805.10769},
author = {Zhou, Ding Xuan},
doi = {10.1016/j.acha.2019.06.004},
eprint = {1805.10769},
issn = {1096603X},
journal = {Applied and Computational Harmonic Analysis},
keywords = {Approximation theory,Convolutional neural network,Deep learning,Universality},
number = {2},
pages = {787--794},
publisher = {Elsevier Inc.},
title = {{Universality of deep convolutional neural networks}},
url = {https://doi.org/10.1016/j.acha.2019.06.004},
volume = {48},
year = {2020}
}
@book{vanderSchaft2014,
author = {van der Schaft, Arjan and Jeltsema, Dimitri},
booktitle = {Foundations and Trends in Systems and Control},
doi = {10.1561/2600000002},
issn = {2325-6818},
number = {2-3},
pages = {173--378},
title = {{Port-hamiltonian systems theory: an introductory overview}},
url = {http://dx.doi.org/10.1561/2600000002},
volume = {1},
year = {2014}
}
@phdthesis{Pakel_thesis_CL,
author = {Pakel, Cavit},
title = {{Bias Reduction in Nonlinear and Dynamic Panels in the Presence of Cross-Section Dependence}},
year = {2014}
}
@article{Alomar2016,
abstract = {Hardware implementation of artificial neural networks (ANNs) allows exploiting the inherent parallelism of these systems. Nevertheless, they require a large amount of resources in terms of area and power dissipation. Recently, Reservoir Computing (RC) has arisen as a strategic technique to design recurrent neural networks (RNNs) with simple learning capabilities. In this work, we show a new approach to implement RC systems with digital gates. The proposed method is based on the use of probabilistic computing concepts to reduce the hardware required to implement different arithmetic operations. The result is the development of a highly functional system with low hardware resources. The presented methodology is applied to chaotic time-series forecasting.{\textless}/p{\textgreater}},
author = {Alomar, Miquel L. and Canals, Vincent and Perez-Mora, Nicolas and Mart{\'{i}}nez-Moll, V{\'{i}}ctor and Rossell{\'{o}}, Josep L. and Ctor and Rossell{\&}{\#}xf3 and {Josep L.}},
doi = {10.1155/2016/3917892},
journal = {Computational Intelligence and Neuroscience},
pages = {1--14},
publisher = {Hindawi Publishing Corporation},
title = {{FPGA-based stochastic echo state networks for time-series forecasting}},
url = {http://www.hindawi.com/journals/cin/2016/3917892/},
volume = {2016},
year = {2016}
}
@article{BN2004,
author = {Bunnermeier, Markus K. and Nagel, Stefan},
issn = {00221082},
journal = {The Journal of Finance},
month = {oct},
number = {5},
pages = {2013--2040},
title = {{Hedge Funds and the Technology Bubble}},
url = {http://doi.wiley.com/10.1111/j.1540-6261.2004.00690.x},
volume = {59},
year = {2004}
}
@article{Hagem2001,
author = {Hagemann, D. and Naumann, E. and Thayer, J. F.},
journal = {Psychophysiology},
pages = {847--857},
title = {{The quest for EEG reference revisited: a glance from brain asymmetry research}},
volume = {38},
year = {2001}
}
@article{cerny:kallsen:annals,
author = {{\v{C}}ern{\'{y}}, Ale{\v{s}} and Kallsen, Jan},
doi = {10.1214/009117906000000872},
issn = {0091-1798},
journal = {Ann. Probab.},
number = {4},
pages = {1479--1531},
title = {{On the structure of general mean-variance hedging strategies}},
url = {http://dx.doi.org/10.1214/009117906000000872},
volume = {35},
year = {2007}
}
@article{merton:bspaper,
author = {Merton, R},
journal = {J. Finan. Econ.},
pages = {125--144},
title = {{Option pricing when underlying stock returns are discontinuous}},
volume = {3},
year = {1976}
}
@article{CIT-006,
author = {Gray, Robert M},
doi = {10.1561/0100000006},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Gray - 2006 - Toeplitz and Circulant Matrices A Review.pdf:pdf},
issn = {1567-2190},
journal = {Foundations and Trends in Communications and Information Theory},
number = {3},
pages = {155--239},
title = {{Toeplitz and Circulant Matrices: A Review}},
url = {http://dx.doi.org/10.1561/0100000006},
volume = {2},
year = {2006}
}
@article{gay2011clebsch,
author = {Gay-Balmaz, Fran{\c{c}}ois and Ratiu, Tudor S},
journal = {J. Geom. Mech},
number = {1},
pages = {41--79},
title = {{Clebsch optimal control formulation in mechanics}},
volume = {3},
year = {2011}
}
@unpublished{Carr2010,
author = {Carr, R. and Wu, L.},
title = {{A new simple approach for constructing implied volatility surfaces}},
year = {2010}
}
@article{bienstman:SR,
abstract = {We present a numerical study of a passive integrated photonics reservoir computing platform based on multimodal Y-junctions. We propose a novel design of this junction where the level of adiabaticity is carefully tailored to capture the radiation loss in higher-order modes, while at the same time providing additional mode mixing that increases the richness of the reservoir dynamics. With this design, we report an overall average combination efficiency of 61{\%} compared to the standard 50{\%} for the single-mode case. We demonstrate that with this design, much more power is able to reach the distant nodes of the reservoir, leading to increased scaling prospects. We use the example of a header recognition task to confirm that such a reservoir can be used for bit-level processing tasks. The design itself is CMOS-compatible and can be fabricated through the known standard fabrication procedures.},
author = {Katumba, Andrew and Heyvaert, Jelle and Schneider, Bendix and Uvin, Sarah and Dambre, Joni and Bienstman, Peter},
doi = {10.1038/s41598-018-21011-x},
issn = {20452322},
journal = {Scientific Reports},
number = {1},
pages = {1--10},
publisher = {Springer US},
title = {{Low-loss photonic reservoir computing with multimode photonic integrated circuits}},
url = {http://dx.doi.org/10.1038/s41598-018-21011-x},
volume = {8},
year = {2018}
}
@article{engle:arch,
abstract = {Traditional econometric models assume a constant one-period forecast variance. To generalize this implausible assumption, a new class of stochastic processes called autoregressive conditional heteroscedastic (ARCH) processes are introduced in this paper. These are mean zero, serially uncorrelated processes with nonconstant variances conditional on the past, but constant unconditional variances. For such processes, the recent past gives information about the one-period forecast variance. A regression model is then introduced with disturbances following an ARCH process. Maximum likelihood estimators are described and a simple scoring iteration formulated. Ordinary least squares maintains its optimality properties in this set-up, but maximum likelihood is more efficient. The relative efficiency is calculated and can be infinite. To test whether the disturbances follow an ARCH process, the Lagrange multiplier procedure is employed. The test is based simply on the autocorrelation of the squared OLS residuals. This model is used to estimate the means and variances of inflation in the U.K. The ARCH effect is found to be significant and the estimated variances increase substantially during the chaotic seventies.},
author = {Engle, Robert F.},
journal = {Econometrica},
number = {4},
pages = {987--1007},
publisher = {The Econometric Society},
title = {{Autoregressive conditional heteroscedasticity with estimates of the variance of United Kingdom inflation}},
volume = {50},
year = {1982}
}
@article{Pereda1998,
abstract = {The question of whether the finite values of the correlation dimension (D2), used as an index of EEG complexity are due to its chaotic nature or they reflect its behaviour as linearly-correlated noise, remains open. This report aims at clarifying this by measuring D2 and analysing the non-linear nature of EEG through the method of surrogate data as well as by calculating the fractal exponent (beta) via coarse graining spectral analysis (CGSA) in nine adult subjects during waking and sleep states. The results show that even if it is possible to get an estimation of D2 in all states, non-linear structure appears to be present only during slow wave sleep (SWS). EEG exhibits random fractal structure with 1/f(-beta) spectrum (1 {\textless} beta {\textless} 3) and a negative linear correlation between D2 and beta in all states except during SWS. In consequence, in those states, finite D2 values could be attributed to the fractal nature of EEG and not to the presence of low-dimensional chaos, and therefore, it the use of beta would be more appropriate to describe the complexity of EEG, due to its lower computational cost.},
author = {Pereda, E. and Gamundi, A. and Rial, R. and Gonz{\'{a}}lez, J.},
issn = {0304-3940},
journal = {Neuroscience letters},
keywords = {Adult,Electroencephalography,Electroencephalography: methods,Electroencephalography: statistics {\&} numerical dat,Female,Fractals,Humans,Male,Nonlinear Dynamics,Sleep,Wakefulness},
month = {jul},
number = {2},
pages = {91--94},
pmid = {9697926},
title = {{Non-linear behaviour of human EEG: fractal exponent versus correlation dimension in awake and sleep stages}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9697926},
volume = {250},
year = {1998}
}
@book{Dudley2014,
author = {Dudley, R. M.},
edition = {2nd},
publisher = {Cambridge University Press},
title = {{Uniform Central Limit Theorems}},
year = {2014}
}
@article{RoxanaRV,
author = {Chiriac, R. and Voev, V.},
journal = {Journal of Applied Econometrics},
number = {6},
pages = {922--947},
title = {{Modelling and forecasting multivariate realized volatility}},
volume = {26},
year = {2011}
}
@book{Serfling1980,
author = {Serfling, Robert J.},
booktitle = {New York},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Serfling - 1980 - Approximation theorems of mathematical statistics.pdf:pdf},
isbn = {0471219274},
publisher = {John Wiley and Sons},
title = {{Approximation theorems of mathematical statistics}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/9780470316481.refs/summary},
year = {1980}
}
@article{sszub10,
author = {Zub, Stanislav},
journal = {J. Num. Appl. Math.},
number = {3},
pages = {49--62},
title = {{Hamiltonian formalism for magnetic interaction of free bodies}},
volume = {102},
year = {2010}
}
@book{gourieroux:book,
address = {New York},
author = {Gouri{\'{e}}roux, Christian},
isbn = {0-387-94876-7},
pages = {x+228},
publisher = {Springer-Verlag},
series = {Springer Series in Statistics},
title = {{ARCH models and financial applications}},
year = {1997}
}
@article{siegelmann:1997,
author = {Siegelmann, H.T. and Horne, B.G. and Giles, C.L.},
doi = {10.1109/3477.558801},
issn = {10834419},
journal = {IEEE Transactions on Systems, Man and Cybernetics, Part B (Cybernetics)},
month = {apr},
number = {2},
pages = {208--215},
title = {{Computational capabilities of recurrent NARX neural networks}},
url = {http://ieeexplore.ieee.org/document/558801/},
volume = {27},
year = {1997}
}
@article{Wager2013,
abstract = {Dropout and other feature noising schemes control overfitting by artificially corrupting the training data. For generalized linear models, dropout performs a form of adaptive regularization. Using this viewpoint, we show that the dropout regularizer is first-order equivalent to an L2 regularizer applied after scaling the features by an estimate of the inverse diagonal Fisher information matrix. We also establish a connection to AdaGrad, an online learning algorithm, and find that a close relative of AdaGrad operates by repeatedly solving linear dropout-regularized problems. By casting dropout as regularization, we develop a natural semi-supervised algorithm that uses unlabeled data to create a better adaptive regularizer. We apply this idea to document classification tasks, and show that it consistently boosts the performance of dropout training, improving on state-of-the-art results on the IMDB reviews dataset.},
archivePrefix = {arXiv},
arxivId = {arXiv:1307.1493v2},
author = {Wager, Stefan and Wang, Sida and Liang, Percy},
eprint = {arXiv:1307.1493v2},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Wager, Wang, Liang - 2013 - Dropout training as adaptive regularization.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
pages = {1--11},
title = {{Dropout training as adaptive regularization}},
year = {2013}
}
@incollection{french:encyclopedia,
author = {French, Robert M.},
booktitle = {Encyclopedia of Cognitive Science},
pages = {431--435},
publisher = {Nature Publishing Group},
title = {{Catastrophic interference in connectionist networks}},
year = {2003}
}
@article{llt,
author = {Lewis, D.},
journal = {Journal of Nonlinear Science},
pages = {63--102},
title = {{Stacked Lagrange tops}},
volume = {8},
year = {1998}
}
@phdthesis{BoussamaPHD,
author = {Boussama, F.},
title = {{Ergodicit{\'{e}}, m{\'{e}}lange et estimation dans les mod{\`{e}}les GARCH}},
year = {1998}
}
@article{Andrieu2010,
author = {Andrieu, Christophe and Doucet, Arnaud and Holenstein, Roman},
journal = {Journal of the Royal Statistical Society B},
pages = {269--342},
title = {{Particle Markov chain Monte Carlo methods}},
volume = {72},
year = {2010}
}
@article{Pusk1994,
author = {Puskorius, G. and Feldkamp, L.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Puskorius, Feldkamp - 1994 - Neurocontrol of nonlinear dynamical systems with Kalman filter trained recurrent networks.pdf:pdf},
journal = {IEEE Transactions on Neural Networks},
number = {2},
pages = {279--290},
title = {{Neurocontrol of nonlinear dynamical systems with Kalman filter trained recurrent networks}},
volume = {5},
year = {1994}
}
@article{Clements2009,
author = {Clements, Michael P and Galv{\~{a}}o, A.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Clements - 2009 - Forecasting US output growth using Leading Indicators An appraisal using MIDAS models.pdf:pdf},
journal = {Journal of Applied Econometrics},
number = {7},
pages = {1187--1206},
title = {{Forecasting US output growth using leading indicators: an appraisal using MIDAS models}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/jae.1075/full},
volume = {7},
year = {2009}
}
@inproceedings{Luetkepohl84a,
abstract = {When a temporally and contemporaneously aggregated vector stochastic process is being forecasted there are various alternative predictors that could be used. For example, a disaggregated process could be forecasted and the forecasts could be aggregated or the aggregated process could be forecasted directly. A framework is developed in which these and other predictors can be analyzed and compared. The relative efficiencies of various predictors are derived.},
address = {London},
author = {L{\"{u}}tkepohl, Helmut},
booktitle = {Fourth International Symposium on Forecasting},
title = {{Predictors for temporally and contemporaneously aggregated stationary processes}},
year = {1984}
}
@article{subba:bilinear,
author = {Rao, T Subba},
journal = {Journal of the Royal Statistical Society B},
keywords = {bilinear time series models,conditions for stationarity,pressure wave,sunspot data,volterra series},
number = {2},
pages = {244--255},
title = {{On the theory of bilinear models}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:on+the+theory+of+bilinear+models{\#}2},
volume = {43},
year = {1981}
}
@misc{temporal:aggregation:code,
author = {Grigoryeva, Lyudmila and Ortega, Juan-Pablo},
title = {{Temporal aggregation and forecasting errors library. https://github.com/lgrigoryeva/ARMA-Temporal-Aggregation}},
url = {https://github.com/lgrigoryeva/ARMA-Temporal-Aggregation},
year = {2014}
}
@article{JLPaper,
author = {Cuchiero, Christa and Gonon, Lukas and Grigoryeva, Lyudmila and Ortega, Juan-Pablo and Teichmann, Josef},
journal = {In preparation},
title = {{Approximation of dynamics by randomized signature}},
year = {2021}
}
@article{Handley2010,
author = {Handley, Chris M. and Popelier, Paul L. A.},
journal = {The Journal of Physical Chemistry A},
number = {10},
pages = {3371--3383},
title = {{Potential energy surfaces fitted by artificial neural networks}},
volume = {114},
year = {2010}
}
@book{Taylor:Book1,
address = {Chichester},
author = {Taylor, Stephen J},
publisher = {John Wiley {\&} Sons},
title = {{Modelling Financial Time Series}},
year = {1986}
}
@book{Steinwart2008,
author = {Steinwart, I. and Christmann, A.},
publisher = {Springer},
title = {{Support Vector Machines}},
year = {2008}
}
@incollection{kurkova:curse,
address = {Boston, MA},
author = {Kůrkov{\'{a}}, V{\v{e}}ra},
booktitle = {Computer Intensive Methods in Control and Signal Processing},
doi = {10.1007/978-1-4612-1996-5_16},
pages = {261--270},
publisher = {Birkh{\"{a}}user Boston},
title = {{Dimension-independent rates of approximation by neural networks}},
year = {1997}
}
@misc{Galvao2007,
author = {Galv{\~{a}}o, AB},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Galv{\~{a}}o - 2007 - Changes in predictive ability with mixed frequency data.pdf:pdf},
keywords = {asset prices,c22,c53,e44,group,i would like to,jel codes,ken wallis,mary econometrics reading,midas,nonlinear time,output growth,participants of the queen,predictive ability,smooth transition,thank mike clements,the 2006 esem and,the conference of 50,the udine workshop on,years of econometrics},
title = {{Changes in predictive ability with mixed frequency data}},
url = {http://www.cardiff.ac.uk/carbs/econ/resources/seminars/galvaowpqmul.pdf},
year = {2007}
}
@article{manjunath:prsl,
abstract = {Reservoir computing, a highly successful neuromorphic computing scheme used to filter, predict, classify temporal inputs, has entered an era of microchips for several other engineering and biological applications. A basis for reservoir computing is memory-loss or the echo state property. It is an open problem on how design parameters of the reservoir can be optimized to maximize reservoir freedom to map an input robustly and yet have its close-by-variants represented in the reservoir differently. We present a framework to analyze stability due to input and parameter perturbations and make a surprising fundamental conclusion, that the echo state property is $\backslash$emph{\{}equivalent{\}} to robustness to input in any nonlinear recurrent neural network that may or may not be in the gambit of reservoir computing. Further, backed by theoretical conclusions, we define and find the difficult-to-describe $\backslash$emph{\{}input specific{\}} edge-of-criticality or the echo state property threshold, which defines the boundary between parameter related stability and instability.},
archivePrefix = {arXiv},
arxivId = {2001.00766},
author = {Manjunath, G},
doi = {10.1098/rspa.2020.0563},
eprint = {2001.00766},
journal = {To appear in Proceedings of the Royal Society London Ser. A Math. Phys. Eng. Sci.},
pages = {1--25},
title = {{Stability and memory-loss go hand-in-hand: three results in dynamics {\&} computation}},
url = {http://arxiv.org/abs/2001.00766},
year = {2020}
}
@article{Khintchine1923,
author = {Khintchine, A.},
journal = {Mathematische Zeitschriften},
pages = {109--116},
title = {{{\"{U}}ber dyadische Br{\"{u}}che}},
volume = {18},
year = {1923}
}
@article{Hsieh2013,
abstract = {The kernel support vector machine (SVM) is one of the most widely used classification methods; however, the amount of computation required becomes the bottleneck when facing millions of samples. In this paper, we propose and analyze a novel divide-and-conquer solver for kernel SVMs (DC-SVM). In the division step, we partition the kernel SVM problem into smaller subproblems by clustering the data, so that each subproblem can be solved independently and efficiently. We show theoretically that the support vectors identified by the subproblem solution are likely to be support vectors of the entire kernel SVM problem, provided that the problem is partitioned appropriately by kernel clustering. In the conquer step, the local solutions from the subproblems are used to initialize a global coordinate descent solver, which converges quickly as suggested by our analysis. By extending this idea, we develop a multilevel Divide-and-Conquer SVM algorithm with adaptive clustering and early prediction strategy, which outperforms state-of-the-art methods in terms of training speed, testing accuracy, and memory usage. As an example, on the covtype dataset with half-a-million samples, DC-SVM is 7 times faster than LIBSVM in obtaining the exact SVM solution (to within {\$}10{\^{}}{\{}-6{\}}{\$} relative error) which achieves 96.15{\%} prediction accuracy. Moreover, with our proposed early prediction strategy, DC-SVM achieves about 96{\%} accuracy in only 12 minutes, which is more than 100 times faster than LIBSVM.},
author = {Hsieh, Cho-Jui and Si, Si and Dhillon, Inderjit S.},
month = {nov},
title = {{A Divide-and-Conquer Solver for Kernel Support Vector Machines}},
url = {http://arxiv.org/abs/1311.0914},
year = {2013}
}
@article{frey1997,
author = {Frey, R{\"{u}}diger},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Frey - 1996 - Derivative asset analysis in models with level-dependent and stochastic volatility(2).pdf:pdf},
journal = {CWI QUARTERLY},
pages = {1--34},
title = {{Derivative asset analysis in models with level-dependent and stochastic volatility}},
volume = {10},
year = {1996}
}
@article{WerbosBPTT90,
author = {Werbos, Paul J.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Werbos - 1990 - Backpropagation through time what it does and how to do it.pdf:pdf},
journal = {Proceedings of the IEEE},
number = {10},
pages = {1550 -- 1560},
title = {{Backpropagation through time: what it does and how to do it}},
volume = {78},
year = {1990}
}
@article{Bucci2018,
author = {Bucci, Andrea},
journal = {Journal of Advanced Studies in Finance},
number = {2},
pages = {94--138},
title = {{Forecasting realized volatility: A review}},
volume = {8},
year = {2018}
}
@article{ESN_2012_TS,
author = {Sheng, Chunyang and Zhao, Jun and Liu, Ying and Wang, Wei},
journal = {Neurocomputing},
pages = {186--195},
title = {{Prediction for noisy nonlinear time series by echo state network based on dual estimation}},
volume = {82},
year = {2012}
}
@book{Hale:functional_differential_equations,
author = {Hale, Jack},
pages = {365},
publisher = {Springer-Verlag},
title = {{Theory of Functional Differential Equations}},
year = {1977}
}
@unpublished{Herwartz2011,
author = {Herwartz, Helmut and L{\"{u}}tkepohl, Helmut},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Herwartz, L{\"{u}}tkepohl - 2011 - Structural vector autoregressions with Markov switching combining conventional with statistical identifica.pdf:pdf},
institution = {EUI},
series = {Department of Economics},
title = {{Structural vector autoregressions with Markov switching: combining conventional with statistical identification of shocks}},
year = {2011}
}
@article{bollerslev:garch,
abstract = {A natural generalization of the ARCH (Autoregressive Conditional Heteroskedastic) process introduced in Engle (1982) to allow for past conditional variances in the current conditional variance equation is proposed. Stationarity conditions and autocorrelation structure for this new class of parametric models are derived. Maximum likelihood estimation and testing are also considered. Finally an empirical example relating to the uncertainty of the inflation rate is presented.},
author = {Bollerslev, Tim},
issn = {0304-4076},
journal = {Journal of Econometrics},
number = {3},
pages = {307--327},
title = {{Generalized autoregressive conditional heteroskedasticity}},
volume = {31},
year = {1986}
}
@unpublished{Andersen2008,
author = {Andersen, Torben G. and Benzoni, Luca},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Andersen, Benzoni - 2008 - Realized volatility.pdf:pdf},
pages = {1021},
series = {Federal Reserve Bank of Chicago},
title = {{Realized volatility}},
year = {2008}
}
@book{Sanz-Serna1994,
address = {London},
author = {Sanz-Serna, J. M. and Calvo, M. P.},
publisher = {Chapman and Hall},
title = {{Numerical Hamiltonian problems}},
year = {1994}
}
@article{Baillie1996,
author = {Baillie, Richard T.},
journal = {Journal of Econometrics},
number = {1},
pages = {5--59},
title = {{Long memory processes and fractional integration in econometrics}},
volume = {73},
year = {1996}
}
@article{C2015,
abstract = {A continuous-time diffusion process is very popular in modeling and provides useful tools to analyze particularly, but not restricted to, a variety of economic and financial variables. The transition probability density function (TPDF) of a diffusion process plays an important role in understanding and explaining the dynamics of the process. A new way to find closed-form approximate TPDFs for multivariate diffusions is proposed in this paper. This method can be applied to general multivariate time-inhomogeneous diffusion processes, as long as, roughly speaking, they have smooth drift and volatility functions. A diffusion process is said to be reducible if it can be converted into a unit diffusion process where the volatility is the identity matrix. We have established how to obtain the approximate TPDF of a reducible diffusion explicitly. When a diffusion process is not reducible, an explicit form of approximate TPDF can be obtained by using the results in A{\"{i}}t-Sahalia (2008) and Choi (2013). The TPDF expansion suggested here enables us to obtain a recursive formula for the coefficient of the approximate TPDF for a multivariate jump diffusion. Monte Carlo simulation studies of conducting maximum likelihood estimation (MLE) using our approximations provide convincing evidence that our TPDF expansion can be used for the MLE when the true TPDF is unavailable. We also applied our approximate TPDFs to option pricing. The differences between our option prices and those from the Extended Black–Scholes formula are shown to be quite small. This implies that our methods can be employed to price assets whose underlying state variables follow general diffusion models.},
author = {Choi, Seungmoon},
issn = {03044076},
journal = {Journal of Econometrics},
keywords = {C13,C16,G13,Maximum likelihood estimation,Multivariate diffusion,Option pricing,Transition probability density function},
month = {jul},
number = {1},
pages = {57--73},
title = {{Explicit form of approximate transition probability density functions of diffusion processes}},
url = {http://www.sciencedirect.com/science/article/pii/S0304407615000275},
volume = {187},
year = {2015}
}
@book{Bishop1980,
address = {New York, NY},
author = {Bishop, R. L. and Goldberg, S.},
publisher = {Dover},
title = {{Tensor Analysis on Manifolds}},
year = {1980}
}
@article{Coulibaly2010a,
abstract = {The use of echo state network (ESN) for dynamical system modeling is known as Reservoir Computing and has been shown to be effective for a number of applications, including signal processing, learning grammatical structure, time series prediction and motor/system control. However, the performance of Reservoir Computing approach on hydrological time series remains largely unexplored. This study investigates the potential of ESN or Reservoir Computing for long-term prediction of lake water levels. Great Lakes water levels from 1918 to 2005 are used to develop and evaluate the ESN models. The forecast performance of the ESN-based models is compared with the results obtained from two benchmark models, the conventional recurrent neural network (RNN) and the Bayesian neural network (BNN). The test results indicate a strong ability of ESN models to provide improved lake level forecasts up to 10-month ahead - suggesting that the inherent structure and innovative learning approach of the ESN is suitable for hydrological time series modeling. Another particular advantage of ESN learning approach is that it simplifies the network training complexity and avoids the limitations inherent to the gradient descent optimization method. Overall, it is shown that the ESN can be a good alternative method for improved lake level forecasting, performing better than both the RNN and the BNN on the four selected Great Lakes time series, namely, the Lakes Erie, Huron-Michigan, Ontario, and Superior. ?? 2009 Elsevier B.V. All rights reserved.},
author = {Coulibaly, Paulin},
doi = {10.1016/j.jhydrol.2009.11.027},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Coulibaly - 2010 - Reservoir Computing approach to Great Lakes water level forecasting.pdf:pdf},
isbn = {0022-1694},
issn = {00221694},
journal = {Journal of Hydrology},
keywords = {Echo state network,Forecasting,Great Lakes,Lake levels,Lake water levels,Reservoir Computing},
number = {1-2},
pages = {76--88},
publisher = {Elsevier B.V.},
title = {{Reservoir Computing approach to Great Lakes water level forecasting}},
url = {http://dx.doi.org/10.1016/j.jhydrol.2009.11.027},
volume = {381},
year = {2010}
}
@article{fast2,
author = {Benettin, G. and Fass{\`{o}}, F. and Guzzo, M.},
journal = {Nonlinearity},
pages = {1695--1717},
title = {{Fast rotations of the rigid body: a study by Hamiltonian perturbation theory. Part II: gyroscopic rotations}},
volume = {10},
year = {1997}
}
@article{chu:1975,
author = {Chu, R. Y.},
journal = {Trans. Amer. Math. Soc.},
pages = {145--159},
title = {{Symplectic homogeneous spaces}},
volume = {197},
year = {1975}
}
@article{RC13,
author = {Cuchiero, Christa and Gonon, Lukas and Grigoryeva, Lyudmila and Ortega, Juan-Pablo and Teichmann, Josef},
journal = {Preprint arXiv:2010.14615},
title = {{Discrete-time signatures and randomness in reservoir computing}},
year = {2020}
}
@book{Shadmehr2012,
author = {Shadmehr, Reza and Mussa-Ivaldi, Sandro},
pages = {400},
publisher = {MIT Press},
title = {{Biological Learning and Control}},
year = {2012}
}
@article{lee:nelder:2,
author = {Lee, Youngjo and Nelder, John A},
doi = {10.1111/j.1467-9876.2006.00538.x},
issn = {0035-9254},
journal = {J. Roy. Statist. Soc. Ser. C},
number = {2},
pages = {139--185},
title = {{Double hierarchical generalized linear models}},
url = {http://dx.doi.org/10.1111/j.1467-9876.2006.00538.x},
volume = {55},
year = {2006}
}
@article{Dacorogna1996,
annote = {
        From Duplicate 1 ( 
        
          Changing time scale for short-term forecasting in financial markets
        
         - Dacorogna, Michel M.; Gauvreau, Cindy L.; M{\"{u}}ller, Ulrich A.; Olsen, Richard B.; Pictet, Olivier V. )

        
        

        

        

      },
author = {Dacorogna, Michel M. and Gauvreau, Cindy L. and M{\"{u}}ller, Ulrich A. and Olsen, Richard B. and Pictet, Olivier V.},
doi = {10.1002/(SICI)1099-131X(199604)15:3<203::AID-FOR619>3.0.CO;2-Y},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Dacorogna et al. - 1996 - Changing time scale for short-term forecasting in financial markets.pdf:pdf},
issn = {02776693},
journal = {Journal of Forecasting},
month = {apr},
number = {3},
pages = {203--227},
title = {{Changing time scale for short-term forecasting in financial markets}},
url = {http://doi.wiley.com/10.1002/(SICI)1099-131X(199604)15:3{\%}3C203::AID-FOR619{\%}3E3.0.CO;2-Y},
volume = {15},
year = {1996}
}
@article{almon1965,
author = {Almon, S.},
journal = {Econometrica},
number = {1},
pages = {178--196},
title = {{The distributed lag between capital appropriations and expenditures}},
volume = {33},
year = {1965}
}
@article{Peters2001,
abstract = {Intention of movement of left or right index finger, or right foot is recognized in electroencephalograms (EEGs) from three subjects. We present a multichannel classification method that uses a "committee" of artificial neural networks to do this. The classification method automatically finds spatial regions on the skull relevant for the classification task. Depending on subject, correct recognition of intended movement was achieved in 75{\%}-98{\%} of trials not seen previously by the committee, on the basis of single EEGs of one-second duration. Frequency filtering did not improve recognition. Classification was optimal during the actual movement, but a first peak in the classification success rate was observed in all subjects already when they had been cued which movement later to perform.},
author = {Peters, B. O. and Pfurtscheller, G. and Flyvbjerg, H.},
doi = {10.1109/10.900270},
issn = {0018-9294},
journal = {Transactions on biomedical engineering},
keywords = {Adult,Computer-Assisted,Electroencephalography,Electroencephalography: classification,Female,Fingers,Humans,Male,Movement,Movement: physiology,Neural Networks (Computer),Reference Values,Signal Processing},
month = {jan},
number = {1},
pages = {111--116},
pmid = {11235582},
title = {{Automatic differentiation of multichannel EEG signals}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11235582},
volume = {48},
year = {2001}
}
@article{Vapnik1968,
author = {Vapnik, Vladimir and Chervonenkis, A. Ya.},
journal = {Dokl. Akad. Nauk SSSR},
number = {4},
pages = {781},
title = {{On the uniform convergence of relative frequencies of events to their probabilities}},
volume = {181},
year = {1968}
}
@article{Batten2014,
author = {Batten, Jonathan A. and Kinateder, Harald and Wagner, Niklas},
journal = {Physica A: Statistical Mechanics and its Applications},
pages = {71--81},
title = {{Multifractality and value-at-risk forecasting of exchange rates}},
volume = {401},
year = {2014}
}
@article{Gautier2006,
author = {Gautier, Erwan},
journal = {BULLETIN DE LA BANQUE DE FRANCE},
keywords = {cycle d'affaires,indicateurs avanc{\{}{\'{e}}{\}}s},
pages = {61--71},
title = {{Les march{\{}{\'{e}}{\}}s financiers comme indicateurs avanc{\{}{\'{e}}{\}}s des retournements conjoncturels: le cas am{\{}{\'{e}}{\}}ricain}},
url = {http://www.banque-france.fr/archipel/publications/bdf{\%}7B{\_}{\%}7Dbm/bdf{\%}7B{\_}{\%}7Dbm{\%}7B{\_}{\%}7D2006/bdf{\%}7B{\_}{\%}7Dbm{\%}7B{\_}{\%}7D153.pdf{\%}7B{\#}{\%}7Dpage=67},
volume = {153},
year = {2006}
}
@article{RC9,
author = {Grigoryeva, Lyudmila and Ortega, Juan-Pablo},
journal = {Journal of Machine Learning Research},
number = {179},
pages = {1--62},
title = {{Differentiable reservoir computing}},
volume = {20},
year = {2019}
}
@article{Schmidhuber:overview,
abstract = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow and Deep Learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning {\&} evolutionary computation, and indirect search for short programs encoding deep and large networks.},
author = {Schmidhuber, J{\"{u}}rgen},
doi = {10.1016/j.neunet.2014.09.003},
issn = {08936080},
journal = {Neural Networks},
pages = {85--117},
title = {{Deep learning in neural networks: An overview}},
volume = {61},
year = {2015}
}
@techreport{Ferrara2012,
abstract = {The global economic recession, referred to as the Great Recession, endured by the main industrialized countries during the period 2008-09, in the wake of the financial and banking crisis, has pointed out the current importance of the financial sector in macroeconomics. In this paper, we evaluate the predictive power of some major financial variables to anticipate GDP growth in euro area countries during this specific period of time. In this respect, we implement a MIDAS-based modeling approach, put forward by Ghysels et al. (2007), that enables to forecast quarterly GDP growth rates using exogenous variables sampled at higher frequencies. Empirical results show that, overall, stock prices help to improve the accuracy of GDP forecasts by comparison with a standard opinion survey variable, while oil prices and term spread appear to be less informative.},
author = {Ferrara, Laurent and Marsilli, Cl{\'{e}}ment},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Ferrara, Marsilli - 2012 - Financial variables as leading indicators of GDP growth Evidence from a MIDAS approach during the Great Reces.pdf:pdf},
institution = {EconomiX},
number = {0},
title = {{Financial variables as leading indicators of GDP growth: Evidence from a MIDAS approach during the Great Recession}},
type = {Working Paper},
url = {http://ideas.repec.org/p/drm/wpaper/2012-19.html},
year = {2012}
}
@book{LeimkuhlerBook,
author = {Leimkuhler, Benedict and Reich, Sebastian},
publisher = {Cambridge University Press},
title = {{Simulating Hamiltonian Dynamics}},
year = {2004}
}
@article{Gersch1977,
author = {Gersch, W. and Yonemoto, J.},
journal = {Computers and biomedical research},
pages = {113--125},
title = {{Automatic classification of multivariate EEG's using an amount of information measure and the eigenvalues of parametric time series model features}},
volume = {10},
year = {1977}
}
@article{Birnbaum1976,
abstract = {Subjects were trained, with feedback, to predict a numerical criterion from each of two separate cues and then asked, without feedback, to predict it from a pair of independent cues or a single cue. Their intuitive predictions were quakitatively inconsistent with an additive model, since the effect of one cue varied inversely with the number of cues available, and with a constant-weight averaging model, since the effect of one cue varied inversely with the validity of the other cue. The data were consistent with a relative-weight averaging model, which assumes that subjective cue values are averaged using weights that depend on cue validities. Normative and descriptive theories of intuitive prediction are compared},
author = {Birnbaum, Michael H},
doi = {10.2307/1421615},
isbn = {0002-9556},
issn = {00029556},
journal = {The American Journal of Psychology},
month = {sep},
number = {3},
pages = {417--429},
title = {{Intuitive numerical prediction}},
url = {http://www.jstor.org/stable/1421615?origin=crossref},
volume = {89},
year = {1976}
}
@article{Bousquet2002,
abstract = {We define notions of stability for learning algorithms and derive bounds on their generalization error based on the empirical error and the leave-one-out error. We then study the stability properties of large classes of learning algorithms such as regularization based algorithms. In particular we focus on Hilbert space regularization and Kullback-Liebler regularization. We then apply the results to SVM for regression and classification and to maximum entropy discrimination.},
author = {Bousquet, Olivier and Elisseeff, Andr{\'{e}}},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Bousquet, Elisseeff - 2002 - Stability and generalisaiton.pdf:pdf},
journal = {Journal of Machine Learning Reasearch},
keywords = {Complex system,Importance degree computation,Reliability allocation},
pages = {499--526},
title = {{Stability and generalisaiton}},
volume = {2},
year = {2002}
}
@article{Zhang1998,
abstract = {Interest in using artificial neural networks (ANNs) for forecasting has led to a tremendous surge in research activities in the past decade. While ANNs provide a great deal of promise, they also embody much uncertainty. Researchers to date are still not certain about the effect of key factors on forecasting performance of ANNs. This paper presents a state-of-the-art survey of ANN applications in forecasting. Our purpose is to provide (1) a synthesis of published research in this area, (2) insights on ANN modeling issues, and (3) the future research directions.},
author = {Zhang, Guoqiang and {Eddy Patuwo}, B. and {Y. Hu}, Michael},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Zhang, Eddy Patuwo, Y. Hu - 1998 - Forecasting with artificial neural networks the state of the art.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {forecasting,neural networks},
month = {mar},
number = {1},
pages = {35--62},
title = {{Forecasting with artificial neural networks: the state of the art}},
url = {http://dx.doi.org/10.1016/S0169-2070(97)00044-7},
volume = {14},
year = {1998}
}
@article{field94,
author = {Field, M. J.},
editor = {Chossat, P.},
journal = {New Trends and New Tools, Proceedings of the E.B.T.G. Conference, NATO ASI Series, Series C, vol. 437},
pages = {111--122},
publisher = {Kluwer Academic Publishers},
title = {{Blowing-up in equivariant bifurcation theory, Dynamics, Bifurcation, and Symmetry}},
year = {1994}
}
@article{Kleiner2014,
author = {Kleiner, Ariel and Talwalkar, Ameet and Sarkar, Purnamrita and Jordan, Michael I.},
issn = {13697412},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
month = {sep},
number = {4},
pages = {795--816},
title = {{A scalable bootstrap for massive data}},
url = {http://doi.wiley.com/10.1111/rssb.12050},
volume = {76},
year = {2014}
}
@book{Refenes_book,
author = {Refenes, A.-P.},
publisher = {Oxford: Clarendon Press},
title = {{Neural Networks for Pattern Recognition}},
year = {195}
}
@techreport{jaeger:advanced:course,
author = {Jaeger, Herbert},
institution = {Jacobs University Bremen},
pages = {169},
title = {{Advanced Machine Learning}},
url = {http://minds.jacobs-university.de/sites/default/files/uploads/teaching/lectureNotes/LN{\_}ML{\_}Fall11.pdf},
year = {2013}
}
@book{delzant:1988,
address = {116,315--339},
author = {Delzant, T.},
booktitle = {Bull. Soc. Math. France},
pages = {315--339},
publisher = {Bull. Soc. Math. France},
title = {{Hamiltoniens p{\'{e}}riodique set images convexes de l'application moment}},
volume = {116},
year = {1988}
}
@book{she:book,
author = {Wu, Min and He, Yong and She, Jin-Hua},
publisher = {Springer},
title = {{Stability Analysis and Robust Control of Time-Delay Systems}},
year = {2010}
}
@article{Rahimi2007,
abstract = {To accelerate the training of kernel machines, we propose to map the input data to a randomized low-dimensional feature space and then apply existing fast linear methods. Our randomized features are designed so that the inner products of the transformed data are approximately equal to those in the feature space of a user specified shift-invariant kernel. We explore two sets of random features, provide convergence bounds on their ability to approximate various radial basis kernels, and show that in large-scale classification and regression tasks linear machine learning algorithms that use these features outperform state-of-the-art large-scale kernel machines.},
author = {Rahimi, Ali and Recht, Ben},
doi = {10.1.1.145.8736},
isbn = {160560352X},
journal = {Advances in neural information},
pmid = {4519940},
title = {{Random features for large-scale kernel machines}},
year = {2007}
}
@article{Earnshaw1842,
author = {Earnshaw, Samuel},
journal = {Trans. Camb. Phil. Soc.},
pages = {97--112},
title = {{On the nature of the molecular forces which regulate the constitution of the luminiferous ether}},
volume = {7},
year = {1842}
}
@article{kantorovich1958space,
author = {Kantorovich, Leonid Vasilevich and Rubinshtein, S G},
journal = {Vestnik of the St. Petersburg University: Mathematics},
number = {7},
pages = {52--59},
publisher = {Allerton Press, Inc.},
title = {{On a space of totally additive functions}},
volume = {13},
year = {1958}
}
@article{barre:1973,
author = {Barre, R},
journal = {Ann. Inst. Fourier},
number = {3},
pages = {227--312},
title = {{De quelques aspects dela th{\{}{\'{e}}{\}}orie des q-vari{\{}{\'{e}}{\}}t{\{}{\'{e}}{\}}s diff{\{}{\'{e}}{\}}rentielles et analytiques}},
volume = {23},
year = {1973}
}
@article{Vendruscolo2011,
author = {Vendruscolo, Michele and Dobson, Christopher M.},
doi = {http://dx.doi.org/10.1016/j.cub.2010.11.062},
issn = {0960-9822},
journal = {Current Biology},
number = {2},
pages = {R68 -- R70},
title = {{Protein dynamics: Moore's law in molecular biology}},
url = {http://www.sciencedirect.com/science/article/pii/S0960982210015289},
volume = {21},
year = {2011}
}
@article{Wang2008,
abstract = {Group lasso is a natural extension of lasso and selects variables in a grouped manner. However, group lasso suffers from estimation inefficiency and selection inconsistency. To remedy these problems, we propose the adaptive group lasso method. We show theoretically that the new method is able to identify the true model consistently, and the resulting estimator can be as efficient as oracle. Numerical studies confirmed our theoretical findings.},
author = {Wang, Hansheng and Leng, Chenlei},
issn = {01679473},
journal = {Computational Statistics {\&} Data Analysis},
month = {aug},
number = {12},
pages = {5277--5286},
title = {{A note on adaptive group lasso}},
url = {http://dx.doi.org/10.1016/j.csda.2008.05.006},
volume = {52},
year = {2008}
}
@article{AS2008,
author = {A{\"{i}}t-Sahalia, Yacine},
issn = {2168-8966},
journal = {The Annals of Statistics},
keywords = {Diffusions,discrete observations,expansions,likelihood},
language = {EN},
month = {apr},
number = {2},
pages = {906--937},
publisher = {Institute of Mathematical Statistics},
title = {{Closed-form likelihood expansions for multivariate diffusions}},
url = {http://projecteuclid.org/euclid.aos/1205420523},
volume = {36},
year = {2008}
}
@book{Feynman1964,
author = {Feynman, R. P. and Leighton, R. B. and Sands, M.},
publisher = {Addison-Wesley},
title = {{The Feynman lectures on physics. Volume II}},
year = {1964}
}
@article{Makeig1996,
author = {Makeig, Scott and Jung, Tzyy-Ping and Sejnowski, Terrence J.},
journal = {Advances in Neural Information Processing Systems},
pages = {931--937},
title = {{Using feedforward neural networks to monitor alertness from changes in EEG correlation and coherence}},
volume = {8},
year = {1996}
}
@incollection{takensembedding,
author = {Takens, Floris},
doi = {10.1007/BFb0091924},
pages = {366--381},
publisher = {Springer Berlin Heidelberg},
title = {{Detecting strange attractors in turbulence}},
url = {http://link.springer.com/10.1007/BFb0091924},
year = {1981}
}
@book{AnalysisBanachSpaces:vol2,
archivePrefix = {arXiv},
arxivId = {1502.0414},
author = {Hyt{\"{o}}nen, Tuomas and van Neerven, Jan and Veraar, Mark and Weis, Lutz},
doi = {10.1142/S0219199715500388},
eprint = {1502.0414},
isbn = {9783319485195},
issn = {02191997},
pages = {630},
publisher = {Springer International Publishing},
title = {{Analysis in Banach Spaces}},
url = {http://arxiv.org/abs/1502.0414},
volume = {II},
year = {2017}
}
@article{MarcellinoTempAggr1999,
author = {Marcellino, Massimiliano},
file = {::;::;:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Marcellino - 1999 - Some consequences of temporal aggregation in empirical analysis.pdf:pdf},
journal = {Journal of Business and Economic Statistics},
keywords = {Aggregation ARMA},
number = {1},
pages = {129--136},
title = {{Some consequences of temporal aggregation in empirical analysis}},
url = {http://www.jstor.org/discover/10.2307/1392244?uid=3738016{\&}uid=2134{\&}uid=2{\&}uid=70{\&}uid=4{\&}sid=47698748814307},
volume = {17},
year = {1999}
}
@techreport{Frale2011,
author = {Frale, Cecilia and Monteforte, Libero},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Frale, Monteforte - 2011 - FaMIDAS A Mixed Frequency Factor Model with MIDAS structure.pdf:pdf},
institution = {Banca d'Italia},
keywords = {In this paper a dynamic factor model with mixed fr,also allowing for pooled forecast from factor mode,the Kalman filter is applied,where the past observations of high frequency indi,which is particularly suited for dealing with unba},
number = {2001},
title = {{FaMIDAS : A Mixed Frequency Factor Model with MIDAS structure}},
type = {Working Paper},
year = {2011}
}
@article{Guyon2003,
author = {Guyon, Isabelle and Elisseeff, Andr{\'{e}}},
journal = {Journal of Machine Learning Research},
pages = {1157--1182},
title = {{An introduction to variable and feature selection}},
volume = {3},
year = {2003}
}
@unpublished{billio2003,
author = {Billio, M. and Caporin, Massimiliano and Gobbo, M.},
title = {{Block dynamic conditional correlation multivariate GARCH models}},
year = {2003}
}
@article{GourRV2009,
author = {Gouri{\'{e}}roux, Christian and Jasiak, Joann and Sufana, R.},
journal = {Journal of Econometrics},
number = {2},
pages = {167--181},
title = {{The wishart autoregressive process of multivariate stochastic volatility}},
volume = {150},
year = {2009}
}
@inproceedings{sszub08,
author = {Zub, Stanislav},
booktitle = {ACAT08},
pages = {116--121},
title = {{Mathematical model of magnetically interacting rigid bodies}},
year = {2008}
}
@inproceedings{XSJFZ:16,
author = {Xie, Zecheng and Sun, Zenghui and Jin, Lianwen and Feng, Ziyong and Zhang, Shuye},
booktitle = {2016 23rd International Conference on Pattern Recognition (ICPR)},
organization = {IEEE},
pages = {4011--4016},
title = {{Fully convolutional recurrent network for handwritten chinese text recognition}},
year = {2016}
}
@inproceedings{Tsoi1994,
author = {Tsoi, A. C. and So, D. S. C. and Sergejew, A.},
booktitle = {Advances in Neural Information Processing Systems},
pages = {1151--1158},
title = {{Classification of electroencephalogram using artificial neural networks}},
year = {1994}
}
@article{Benettin1998,
author = {Benettin, G. and Fass{\`{o}}, Francesco and Guzzo, M.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Benettin, Fass{\`{o}}, Guzzo - 1998 - Nekhoroshev stability of L4and L5 in the spatial restricted three-body problem.pdf:pdf},
journal = {Regular and Chaotic Dynamics},
number = {3},
pages = {56--71},
title = {{Nekhoroshev stability of L4and L5 in the spatial restricted three-body problem}},
volume = {3},
year = {1998}
}
@article{Vandoorne2014,
author = {Vandoorne, K. and Mechet, P. and {Van Vaerenbergh}, T.},
journal = {Nature Communications},
pages = {1--6},
title = {{Experimental demonstration of reservoir computing on a silicon photonics chip}},
volume = {5},
year = {2014}
}
@book{Kushner2003,
author = {Kushner, Harrold and Yin, George},
edition = {2nd},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Kushner, Yin - 2003 - Stochastic Approximation and Recursive Algorithms and Applications.pdf:pdf},
isbn = {0387008942},
publisher = {Springer-Verlag Limited},
title = {{Stochastic Approximation and Recursive Algorithms and Applications}},
year = {2003}
}
@article{durdy:perets,
author = {Durdyev, R. I. and Peresetsky, Anatoly},
journal = {Applied Econometrics},
number = {3},
pages = {81--100},
title = {{Autocorrelation in the global stochastic trend}},
volume = {35},
year = {2014}
}
@incollection{White2006,
author = {White, Halbert},
booktitle = {Handbook of Economic Forecasting},
edition = {Elsevier},
editor = {Elliott, Graham and Granger, Clive W.J. and Timmermann, Allan},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/White - 2006 - Approximate Nonlinear Forecasting Methods.pdf:pdf},
number = {05},
title = {{Approximate Nonlinear Forecasting Methods}},
volume = {1},
year = {2006}
}
@article{Jeon1991,
abstract = {This article reports an investigation of the behavior of stock prices in major world stock exchanges based on univariate and multivariate approaches. The evidence shows that each series of stock prices in the New York, London, Tokyo, and Frankfurt stock exchanges during the period from January 1975 through March 1990 has a unit root. The multivariate tests for unit roots, however, show that there are three unit roots in a system of stock prices in the world's four largest stock exchanges, suggesting the existance of a common stochastic trend in the system. The subsample estimation results are consistent with greater globalization of world stock markets during the 1980s.},
author = {Jeon, Bang Nam and Chiang, Thomas C.},
issn = {01486195},
journal = {Journal of Economics and Business},
month = {nov},
number = {4},
pages = {329--338},
title = {{A system of stock prices in world stock exchanges: Common stochastic trends for 1975–1990}},
url = {http://www.sciencedirect.com/science/article/pii/014861959190029V},
volume = {43},
year = {1991}
}
@article{Christoffersen2009,
abstract = {We provide results for the valuation of European-style contingent claims for a large class of specifications of the underlying asset returns. Our valuation results obtain in a discrete time, infinite state space setup using the no-arbitrage principle and an equivalent martingale measure (EMM). Our approach allows for general forms of heteroskedasticity in returns, and valuation results for homoskedastic processes can be obtained as a special case. It also allows for conditional nonnormal return innovations, which is critically important because heteroskedasticity alone does not suffice to capture the option smirk. We analyze a class of EMMs for which the resulting risk-neutral return dynamics are from the same family of distributions as the physical return dynamics. In this case, our framework nests the valuation results obtained by Duan (1995) and Heston and Nandi (2000) by allowing for a time-varying price of risk and nonnormal innovations. We provide extensions of these results to more general EMMs and to discrete-time stochastic volatility models, and we analyze the relation between our results and those obtained for continuous-time models.},
author = {Christoffersen, Peter and Elkamhi, R. and Feunou, B. and Jacobs, Kris},
doi = {10.1093/rfs/hhp078},
issn = {0893-9454},
journal = {Review of Financial Studies},
month = {oct},
number = {5},
pages = {2139--2183},
title = {{Option valuation with conditional heteroskedasticity and nonnormality}},
url = {http://rfs.oxfordjournals.org/content/23/5/2139.short},
volume = {23},
year = {2009}
}
@article{grohs:deep,
abstract = {We derive fundamental lower bounds on the connectivity and the memory requirements of deep neural networks guaranteeing uniform approximation rates for arbitrary function classes in {\$}L{\^{}}2(\backslashmathbb{\{}R{\}}{\^{}}d){\$}. In other words, we establish a connection between the complexity of a function class and the complexity of deep neural networks approximating functions from this class to within a prescribed accuracy. Additionally, we prove that our lower bounds are achievable for a broad family of function classes. Specifically, all function classes that are optimally approximated by a general class of representation systems---so-called $\backslash$emph{\{}affine systems{\}}---can be approximated by deep neural networks with minimal connectivity and memory requirements. Affine systems encompass a wealth of representation systems from applied harmonic analysis such as wavelets, ridgelets, curvelets, shearlets, {\$}\backslashalpha{\$}-shearlets, and more generally {\$}\backslashalpha{\$}-molecules. This result elucidates a remarkable universality property of neural networks and shows that they achieve the optimum approximation properties of all affine systems combined. As a specific example, we consider the class of {\$}1/\backslashalpha{\$}-cartoon-like functions, which is approximated optimally by {\$}\backslashalpha{\$}-shearlets. We also explain how our results can be extended to the case of functions on low-dimensional immersed manifolds. Finally, we present numerical experiments demonstrating that the standard stochastic gradient descent algorithm generates deep neural networks providing close-to-optimal approximation rates at minimal connectivity. Moreover, these results show that stochastic gradient descent actually learns approximations that are sparse in the representation systems optimally sparsifying the function class the network is trained on.},
archivePrefix = {arXiv},
arxivId = {1705.01714},
author = {B{\"{o}}lcskei, Helmut and Grohs, Philipp and Kutyniok, Gitta and Petersen, Philipp},
eprint = {1705.01714},
journal = {SIAM J. Math. Data Sci.},
keywords = {41a25,41a46,42c15,42c40,68t05,82c32,94a12,94a34,ams subject classification,connectivity,deep neural networks,function approximation,optimal sparse approximation,shearlets,sparse},
number = {1},
pages = {8--45},
title = {{Optimal approximation with sparsely connected deep neural networks}},
url = {http://arxiv.org/abs/1705.01714},
volume = {1},
year = {2019}
}
@article{rossenbaum2013,
author = {Hoffmann, M. and Rosenbaum, M. and Yoshida, N. and Hoffman, M. and Rossenbaum, Mathieu},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Hoffmann et al. - 2013 - Estimation of the lead-lag parameter from non-synchronous data.pdf:pdf},
issn = {1350-7265},
journal = {Bernoulli},
language = {EN},
month = {may},
number = {2},
pages = {426--461},
publisher = {Bernoulli Society for Mathematical Statistics and Probability},
title = {{Estimation of the lead-lag parameter from non-synchronous data}},
url = {http://projecteuclid.org/euclid.bj/1363192034},
volume = {19},
year = {2013}
}
@article{fdr_correction,
author = {Benjamini, Yoav and Hochberg, Yosef},
journal = {Journal of the Royal Statistical Society. Series B},
number = {1},
pages = {289--300},
title = {{Controlling the false discovery rate: a practical and powerful approach to multiple testing}},
url = {http://www.jstor.org/discover/10.2307/2346101?uid=3738016{\&}uid=2{\&}uid=4{\&}sid=21103886992967},
volume = {57},
year = {1995}
}
@article{Marcellino2008,
abstract = {Predicting the future evolution of GDP growth and inflation is a central concern in economics. Forecasts are typically produced either from economic theory-based models or from simple linear time series models. While a time series model can provide a reasonable benchmark to evaluate the value added of economic theory relative to the pure explanatory power of the past behavior of the variable, recent developments in time series analysis suggest that more sophisticated time series models could provide more serious benchmarks for economic models. In this paper we evaluate whether these complicated time series models can outperform standard linear models for forecasting GDP growth and inflation. We consider a large variety of models and evaluation criteria, using a bootstrap algorithm to evaluate the statistical significance of our results. Our main conclusion is that in general linear time series models can hardly be beaten if they are carefully specified. However, we also identify some important cases where the adoption of a more complicated benchmark can alter the conclusions of economic analyses about the driving forces of GDP growth and inflation.},
author = {Marcellino, Massimiliano},
journal = {Journal of Forecasting},
number = {4},
pages = {305--340},
publisher = {Wiley Online Library},
series = {Journal of Forecasting},
title = {{A linear benchmark for forecasting GDP growth and inflation?}},
url = {http://ideas.repec.org/a/jof/jforec/v27y2008i4p305-340.html},
volume = {27},
year = {2008}
}
@article{Rahimi2009,
abstract = {Randomized neural networks are immortalized in this well-known AI Koan: In the days when Sussman was a novice, Minsky once came to him as he sat hacking at the PDP-6. “What are you doing?” asked Minsky. “I am training a randomly wired neural net to play tic-tac-toe,” Sussman replied. “Why is the net wired ran- domly?” asked Minsky. Sussman replied, “I do not want it to have any precon- ceptions of how to play.” Minsky then shut his eyes. “Why do you close your eyes?” Sussman asked his teacher. “So that the room will be empty,” replied Minsky. At that moment, Sussman was enlightened. We analyze shallow random networks with the help of concentration of measure inequalities. Specifically, we consider architectures that compute a weighted sum of their inputs after passing them through a bank of arbitrary randomized nonlin- earities. We identify conditions under which these networks exhibit good classi- fication performance, and bound their test error in terms of the size of the dataset and the number of random nonlinearities. 1},
author = {Rahimi, Ali and Recht, B},
isbn = {9781605609492},
journal = {Advances in Neural Information Processing Systems},
title = {{Weighted sums of random kitchen sinks: Replacing minimization with randomization in learning}},
year = {2009}
}
@inproceedings{Medianu2013,
author = {Medianu, Silviu and Lefevre, Laurent and Stefanoiu, Dan},
booktitle = {2nd International Conference on Systems and Computer Science},
doi = {10.1109/IcConSCS.2013.6632023},
pages = {56--61},
title = {{Identifiability of linear lossless Port-controlled Hamiltonian systems}},
year = {2013}
}
@book{bott,
author = {Bott, R. and Tu, L.},
booktitle = {Graduate Texts in Mathematics},
publisher = {Springer-Verlag},
title = {{Differential Forms in Algebraic Topology}},
volume = {82},
year = {1982}
}
@article{Noirhomme2015,
abstract = {Given the fact that clinical bedside examinations can have a high rate of misdiagnosis, machine learning techniques based on neuroimaging and electrophysiological measurements are increasingly being considered for comatose patients and patients with unresponsive wakefulness syndrome, a minimally conscious state or locked-in syndrome. Machine learning techniques have the potential to move from group-level statistical results to personalized predictions in a clinical setting. They have been applied for the purpose of (1) detecting changes in brain activation during functional tasks, equivalent to a behavioral command-following test and (2) estimating signs of consciousness by analyzing measurement data obtained from multiple subjects in resting state. In this review, we provide a comprehensive overview of the literature on both approaches and discuss the translation of present findings to clinical practice. We found that most studies struggle with the difficulty of establishing a reliable behavioral assessment and fluctuations in the patient's levels of arousal. Both these factors affect the training and validation of machine learning methods to a considerable degree. In studies involving more than 50 patients, small to moderate evidence was found for the presence of signs of consciousness or good outcome, where one study even showed strong evidence for good outcome.},
author = {Noirhomme, Quentin and Brecheisen, Ralph and Lesenfants, Damien and Antonopoulos, Georgios and Laureys, Steven},
doi = {10.1016/j.neuroimage.2015.12.006},
isbn = {1095-9572},
issn = {10959572},
journal = {NeuroImage},
keywords = {Classifier,Coma,Diagnosis,Disorders of consciousness,Locked-in syndrome,Machine learning,Minimally conscious state,Prognosis,Unresponsive wakefulness syndrome,Vegetative state},
pmid = {26690804},
publisher = {Elsevier Inc.},
title = {{"Look at my classifier's result": Disentangling unresponsive from (minimally) conscious patients}},
url = {http://dx.doi.org/10.1016/j.neuroimage.2015.12.006},
year = {2015}
}
@inproceedings{SalaAdesi2015,
address = {Working paper},
author = {Sala, Carlo and {Barone Adesi}, Giovanni},
booktitle = {SSRN Electronic Journal},
doi = {10.2139/ssrn.2646925},
title = {{The pricing kernel anomaly: the case of the information that did not bark}},
url = {http://www.ssrn.com/abstract=2646925},
year = {2015}
}
@article{Creti2012,
author = {Creti, Anna and Jo{\"{e}}ts, Marc and Mignon, Val{\'{e}}rie},
institution = {University of Paris West - Nanterre la D{\'{e}}fense, EconomiX},
journal = {Energy Economics},
pages = {16--38},
title = {{On the links between stock and commodity markets' volatility}},
type = {Working Paper},
url = {http://ideas.repec.org/p/drm/wpaper/2012-42.html},
volume = {37},
year = {2013}
}
@unpublished{OShea2015,
author = {O'Shea, Keiron and Nash, Ryan},
title = {{An introduction to Convolutional Neural Networks}},
year = {2015}
}
@article{Tateishi2010,
abstract = {We consider the problem of constructing nonlinear regression models with Gaussian basis functions, using lasso regularization. Regularization with a lasso penalty is an advantageous in that it estimates some coefficients in linear regression models to be exactly zero. We propose imposing a weighted lasso penalty on a nonlinear regression model and thereby selecting the number of basis functions effectively. In order to select tuning parameters in the regularization method, we use a deviance information criterion proposed by Spiegelhalter et al. (2002), calculating the effective number of parameters by Gibbs sampling. Simulation results demonstrate that our methodology performs well in various situations.},
author = {Tateishi, Shohei and Matsui, Hidetoshi and Konishi, Sadanori},
issn = {03783758},
journal = {Journal of Statistical Planning and Inference},
keywords = {basis expansion,bayes approach,information criterion,lasso,nonlinear regression,regularization},
month = {may},
number = {5},
pages = {1125--1134},
title = {{Nonlinear regression modeling via the lasso-type regularization}},
url = {http://dx.doi.org/10.1016/j.jspi.2009.10.015},
volume = {140},
year = {2010}
}
@book{foellmer:schied:book,
address = {Berlin},
annote = {An introduction in discrete time},
author = {F{\"{o}}llmer, Hans and Schied, Alexander},
doi = {10.1515/9783110198065},
isbn = {3-11-017119-8},
pages = {x+422},
publisher = {Walter de Gruyter and Co.},
series = {de Gruyter Studies in Mathematics},
title = {{Stochastic Finance}},
url = {http://dx.doi.org/10.1515/9783110198065},
volume = {27},
year = {2002}
}
@article{Bates2005,
abstract = {This article presents a simple “model-free” method for inferring deltas and gammas from implicit volatility patterns. An illustration indicates that Black–Scholes deltas and gammas are substantially biased in the presence of the sort of smirks and smiles evident in stock index options.},
author = {Bates, David S.},
doi = {10.1016/j.frl.2005.08.004},
issn = {15446123},
journal = {Finance Research Letters},
keywords = {c65,g11,g12,g13},
month = {dec},
number = {4},
pages = {195--200},
title = {{Hedging the smirk}},
url = {http://dx.doi.org/10.1016/j.frl.2005.08.004},
volume = {2},
year = {2005}
}
@unpublished{Rodriguez2017,
author = {Rodriguez, Nathaniel and Izquierdo, Eduardo and Ahn, Yong-Yeol},
title = {{Optimal modularity and memory capacity of neural networks}},
year = {2017}
}
@article{CL_Lindsay2011,
author = {Lindsay, Bruce G. and Yi, Grace Y. and Sun, Jianping},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Lindsay, Yi, Sun - 2011 - Issues and strategies in the selection of composite likelihoods.pdf:pdf},
journal = {Statistica Sinica},
pages = {71--105},
title = {{Issues and strategies in the selection of composite likelihoods}},
volume = {21},
year = {2011}
}
@techreport{girosi:translates,
author = {Girosi, Federico and Anzellotti, Gabriele},
institution = {Defense Technical Information Center},
isbn = {0123456789},
title = {{Convergence rates of approximation by translates}},
url = {http://www.dtic.mil/docs/citations/ADA260100},
volume = {AIM 1288},
year = {1992}
}
@article{Witten2014,
author = {Witten, Rafi and Cand{\`{e}}s, Emmanuel},
issn = {0178-4617},
journal = {Algorithmica},
month = {may},
number = {1},
pages = {264--281},
title = {{Randomized Algorithms for Low-Rank Matrix Factorizations: Sharp Performance Bounds}},
url = {http://link.springer.com/10.1007/s00453-014-9891-7},
volume = {72},
year = {2014}
}
@article{Andrew1991,
author = {Andrews, Donald W. K.},
journal = {Econometrica},
number = {3},
pages = {817--858},
title = {{Heteroskedasticity and autocorrelation consistent covariance matrix estimation}},
volume = {59},
year = {1991}
}
@unpublished{Gallicchio2019,
author = {Gallicchio, Claudio and Micheli, Alessio and Pedrelli, Luca},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Gallicchio, Micheli, Pedrelli - 2019 - Comparison between DeepESNs and gated RNNs on multivariate time-series prediction.pdf:pdf},
title = {{Comparison between DeepESNs and gated RNNs on multivariate time-series prediction}},
year = {2019}
}
@article{coste:dazord:weinstein:1987,
address = {2,1--62. Univ. Claude--Bernard, Lyon},
author = {Cost{\'{e}}, A. and Dazord, P. and Weinstein, A.},
journal = {Publ. D{\'{e}}p. Math. Nouvelle S{\'{e}}r. A},
pages = {1--62},
title = {{Groupo{\"{i}}des symplectiques}},
volume = {2},
year = {1987}
}
@article{Fan_regression,
author = {Fan, J. and Yao, Qiwei},
journal = {Biometrika},
pages = {645--660},
title = {{Efficient estimation of conditional variance functions in stochastic regression}},
volume = {85},
year = {1998}
}
@unpublished{nonejad:kalman,
author = {Nonejad, Nima},
pages = {57},
title = {{Do oil prices predict the conditional distribution of aggregate stock market returns?}},
year = {2017}
}
@book{horn:matrix:analysis,
author = {Horn, Roger A. and Johnson, Charles R.},
edition = {Second},
pages = {643},
publisher = {Cambridge University Press},
title = {{Matrix Analysis}},
year = {2013}
}
@article{Barndorff-Nielsen2002a,
author = {Barndorff-Nielsen, Ole E. and Shephard, Neil},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Barndorff-Nielsen, Shephard - 2002 - Econometric analysis of realized volatility and its use in estimating stochastic volatility models.pdf:pdf},
journal = {Journal of the Royal Statistical Society. Series B},
number = {2},
pages = {253--280},
title = {{Econometric analysis of realized volatility and its use in estimating stochastic volatility models}},
volume = {64},
year = {2002}
}
@article{bates:98,
author = {Bates, L.},
journal = {Rep. Math. Phys.},
number = {1/2},
pages = {231--247},
title = {{Examples of singular nonholonomic reduction}},
volume = {42},
year = {1998}
}
@article{Bailer-Jones1998,
annote = {PMID: 10221578},
author = {Bailer-Jones, Coryn A L and MacKay, David J C and Withers, Philip J},
doi = {10.1088/0954-898X_9_4_008},
journal = {Network: Computation in Neural Systems},
number = {4},
pages = {531--547},
publisher = {Taylor {\&} Francis},
title = {{A recurrent neural network for modelling dynamical systems}},
url = {https://doi.org/10.1088/0954-898X{\_}9{\_}4{\_}008},
volume = {9},
year = {1998}
}
@article{Boussama2000,
author = {Boussama, Farid},
journal = {C. R. Acad. Sci. Paris S{\'{e}}r. I Math.},
pages = {81--84},
title = {{Normalit{\'{e}} asymptotique de l'estimateur du pseudo-maximum de vraisemblance d'un mod{\`{e}}le GARCH}},
volume = {331},
year = {2000}
}
@inproceedings{Kuznetsov2015,
author = {Kuznetsov, Vitaly and Mohri, Mehryar},
booktitle = {NIPS},
title = {{Learning theory and algorithms for forecasting non-stationary time series}},
year = {2015}
}
@article{hammer:tino:2003,
abstract = {Recent experimental studies indicate that recurrent neural networks initialized with “small” weights are inherently biased toward definite memory machines (Tiňno, {\v{C}}erňansk{\'{y}}, {\&} Beňu{\v{s}}kov{\'{a}}, 2002a, 2002b). This article establishes a theoretical counterpart: transition function of recurrent network with small weights and squashing activation function is a contraction. We prove that recurrent networks with contractive transition function can be approximated arbitrarily well on input sequences of unbounded length by a definite memory machine. Conversely, every definite memory machine can be simulated by a recurrent network with contractive transition function. Hence, initialization with small weights induces an architectural bias into learning with recurrent neural networks. This bias might have benefits from the point of view of statistical learning theory: it emphasizes one possible region of the weight space where generalization ability can be formally proved. It is well known that standard recurrent neural n...},
author = {Hammer, Barbara and Tino, Peter},
doi = {10.1162/08997660360675080},
journal = {Neural Computation},
month = {aug},
number = {8},
pages = {1897--1929},
publisher = {MIT Press 238 Main St., Suite 500, Cambridge, MA 02142-1046 USA journals-info@mit.edu},
title = {{Recurrent neural networks with small weights implement definite memory machines}},
url = {http://www.mitpressjournals.org/doi/10.1162/08997660360675080},
volume = {15},
year = {2003}
}
@article{Arkadiev1947,
author = {Arkadiev, V.},
journal = {Nature},
pages = {330},
title = {{A floating magnet}},
volume = {160},
year = {1947}
}
@article{ogESN2012,
author = {Strauss, T. and Wustlich, W. and Labahn, R.},
journal = {Neural Computation},
number = {12},
pages = {3246--3276},
title = {{Design strategies for weight matrices of echo state networks}},
volume = {24},
year = {2012}
}
@article{bartsch:97,
author = {Bartsch, T.},
journal = {Ann. Inst. H. Poincar{\'{e}} Anal. Non Lin{\'{e}}aire},
number = {6},
pages = {691--718},
title = {{A generalization of the Weinstein-Moser theorems on periodic orbits of a Hamiltonian system near an equilibrium}},
volume = {14},
year = {1997}
}
@book{port-ham:jacob,
author = {Jacob, Birgit and Zwart, Hans J.},
booktitle = {Integral Equations and Operator Theory},
doi = {10.1007/bf01194932},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Jacob, Zwart - 20121 - Linear Port-Hamiltonian Systems on Infinite-dimensional Spaces.pdf:pdf},
isbn = {9783034803984},
issn = {0378-620X},
number = {1},
publisher = {Birkhauser Verlag},
title = {{Linear Port-Hamiltonian Systems on Infinite-dimensional Spaces}},
volume = {14},
year = {20121}
}
@article{pascal,
author = {Chossat, P. and Lewis, D. and Ortega, J.-P. and Ratiu, T. S.},
journal = {Advances in Applied Mathematics},
pages = {10--45},
title = {{Bifurcation of relative equilibria in mechanical systems with symmetry}},
volume = {31},
year = {2003}
}
@article{Todorov2004,
author = {Todorov, Emanuel},
journal = {Nature Neuroscience},
pages = {907--915},
title = {{Optimality principles in sensorimotor control}},
volume = {7},
year = {2004}
}
@article{harvey:ruiz:shephard,
author = {Harvey, A. C. and Ruiz, E and Shephard, Neil},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Harvey, Ruiz, Shephard - 1994 - Multivariate stochastic variance models.pdf:pdf},
journal = {Review of Economic Studies},
pages = {247--264},
title = {{Multivariate stochastic variance models}},
volume = {61},
year = {1994}
}
@article{Holm2009,
author = {Holm, Darryl D. and Trouv{\'{e}}, Alain and Younes, Laurent},
doi = {10.1090/S0033-569X-09-01134-2},
issn = {0033-569X},
journal = {Quarterly of Applied Mathematics},
month = {sep},
number = {4},
pages = {661--685},
title = {{The Euler-Poincar{\'{e}} theory of metamorphosis}},
url = {http://www.ams.org/qam/2009-67-04/S0033-569X-09-01134-2/},
volume = {67},
year = {2009}
}
@book{engleCorrelationsBook,
address = {Princeton, NJ},
author = {Engle, Robert},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Engle - 2009 - Anticipating Correlations.pdf:pdf},
publisher = {Princeton University Press},
title = {{Anticipating Correlations}},
year = {2009}
}
@article{dccmidas,
abstract = {The idea of component models for volatility is extended to dynamic correlations. We propose a model of dynamic correlations with a short- and long-run component specification. We call this class of models DCC-MIDAS as the key ingredients are a combination of the Engle (2002) DCC model, the Engle and Lee (1999) component GARCH model to replace the original DCC dynamics with a component specification and the Engle, Ghysels, and Sohn (2006) GARCH-MIDAS component specification that allows us to extract a long-run correlation component via mixed data sampling. We provide a comprehensive econometric analysis of the new class of models, including conditions for positive semi-definiteness, and provide extensive empirical evidence that supports the model specification.},
author = {Colacito, Riccardo and Engle, RF Robert F. and Ghysels, Eric},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Colacito, Engle - 2011 - A component model for dynamic correlations.pdf:pdf},
journal = {Journal of Econometrics},
pages = {45--59},
publisher = {SSRN},
title = {{A component model for dynamic correlations}},
url = {http://www.sciencedirect.com/science/article/pii/S0304407611000406 http://ssrn.com/paper=1354526},
volume = {164},
year = {2011}
}
@article{Manton2013,
author = {Manton, Jonathan H.},
title = {{A primer on stochastic differential geometry for signal processing}},
year = {2013}
}
@inproceedings{Zoubek2008,
abstract = {This paper focuses on the development of an automatic system for sleep analysis. The system proposed in this paper combines two phases needed in sleep analysis. In a first step, an artefact detection system selects the polysomnographic signals (EEG, EOG, EMG) that are not corrupted by artefacts. In a second step, relevant features are extracted from the selected signals and classified using a neural network chosen among a bank of four neural networks. The four classifiers differ one from the others by the signals used for the classification. They were learnt using information provided by different combination of signals (EEG, EEG+EOG, EEG+EMG, EEG+EOG+EMG). Thus, the complete system enables the classification to be performed using relevant features computed from artefact-free signals, without losing too many data. The performance reached by the two-steps system is 85{\%} of accuracy, calculated on 47 night sleep recordings.},
author = {Zoubek, Luk{\'{a}}{\v{s}} and Charbonnier, Sylvie and Lesecq, Suzanne and Buguet, Alain and Chapotot, Florian},
booktitle = {17th IFAC World Congress},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Zoubek et al. - 2008 - A two-steps sleep wake stages classifier taking into account artefacts in the polysomnographic signals.pdf:pdf},
isbn = {9781123478},
pages = {5227--5232},
title = {{A two-steps sleep / wake stages classifier taking into account artefacts in the polysomnographic signals}},
year = {2008}
}
@article{Gibson2013,
abstract = {OBJECTIVE: We sought to determine whether the sensorimotor rhythms (SMR) elicited during motor imagery (MI) of complex and familiar actions could be more reliably detected with electroencephalography (EEG), and subsequently classified on a single-trial basis, than those elicited during relatively simpler imagined actions.

METHODS: Groups of healthy volunteers, including experienced pianists and ice hockey players, performed MI of varying complexity and familiarity. Their electroencephalograms were recorded and compared using brain-computer interface (BCI) approaches and spectral analyses.

RESULTS: Relative to simple MI, significantly more participants produced classifiable SMR for complex MI. During MI of performance of a complex musical piece, the EEG of the experienced pianists was classified significantly more accurately than during MI of performance of a simpler musical piece. The accuracy of EEG classification was also significantly more sustained during complex MI.

CONCLUSION: MI of complex actions results in EEG responses that are more reliably classified for more individuals than MI of relatively simpler actions, and familiarity with actions enhances these responses in some cases.

SIGNIFICANCE: The accuracy of SMR-based BCIs in non-communicative patients may be improved by employing familiar and complex actions. Increased sensitivity to MI may also improve diagnostic accuracy for severely brain-injured patients in a vegetative state.},
author = {Gibson, Raechelle M and Chennu, Srivas and Owen, Adrian M and Cruse, Damian},
issn = {1872-8952},
journal = {Clinical neurophysiology : official journal of the International Federation of Clinical Neurophysiology},
month = {dec},
publisher = {Elsevier},
title = {{Complexity and familiarity enhance single-trial detectability of imagined movements with electroencephalography.}},
url = {http://www.clinph-journal.com/article/S1388-2457(13)01235-2/abstract},
year = {2013}
}
@book{shephardSV2005,
address = {Oxford},
author = {Shephard, Neil},
publisher = {Oxford University Press},
title = {{Stochastic Volatility: Selected Readings}},
year = {2005}
}
@techreport{huke:muldoon:2015,
author = {Huke, Jeremy P. and Muldoon, Mark R.},
institution = {Manchester Institute for Mathematical Sciences. The University of Manchester},
title = {{Embedding and time series analysis}},
year = {2015}
}
@article{almost:Poisson,
author = {Cantrijn, F. and de Le{\'{o}}n, M. and {Mart{\'{i}}n de Diego}, D.},
journal = {Nonlinearity},
number = {3},
pages = {721--737},
title = {{On almost-Poisson structures in nonholonomic mechanics}},
volume = {12},
year = {1999}
}
@inproceedings{nedoma1957note,
author = {Nedoma, Jrfei},
booktitle = {Transactions of the First Prague Conference on Information Theory, Statistical Decision Functions, Random Processes (Liblice, 1956), Publishing House of the Czechoslovak Academy of Sciences, Prague},
pages = {139--141},
title = {{Note on generalized random variables}},
year = {1957}
}
@article{mrs,
author = {Montaldi, J. A. and Roberts, R. M. and Stewart, I. N.},
journal = {Phil. Trans. R. Soc. Lond. A},
pages = {237--293},
title = {{Periodic solutions near equilibria of symmetric Hamiltonian systems}},
volume = {325},
year = {1988}
}
@article{Haselsteiner2000,
abstract = {This paper compares two different topologies of neural networks. They are used to classify single trial electroencephalograph (EEG) data from a brain-computer interface (BCI). A short introduction to time series classification is given, and the used classifiers are described. Standard multilayer perceptrons (MLPs) are used as a standard method for classification. They are compared to finite impulse response (FIR) MLPs, which use FIR filters instead of static weights to allow temporal processing inside the classifier. A theoretical comparison of the two architectures is presented. The results of a BCI experiment with three different subjects are given and discussed. These results demonstrate the higher performance of the FIR MLP compared with the standard MLP.},
author = {Haselsteiner, Ernst and Pfurtscheller, Gert},
issn = {1063-6528},
journal = {Transactions on rehabilitation engineering},
keywords = {Cerebral Cortex,Cerebral Cortex: physiology,Computer-Assisted,Electroencephalography,Image Processing,Neural Networks (Computer),User-Computer Interface},
month = {dec},
number = {4},
pages = {457--463},
pmid = {11204036},
title = {{Using time-dependent neural networks for EEG classification}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11204036},
volume = {8},
year = {2000}
}
@unpublished{Duttagupta,
author = {Duttagupta, Rupa and Barrera, Natalia},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Duttagupta, Barrera - 2010 - The Impact of the Global Crisis on Canada What Do Macro-Financial Linkages Tell Us.pdf:pdf},
institution = {IMF},
series = {Western Hemisphere Department},
title = {{The Impact of the Global Crisis on Canada : What Do Macro-Financial Linkages Tell Us ?}},
year = {2010}
}
@unpublished{Filonov2017,
author = {Filonov, Pavel and Kitashov, Fedor and Lavrentyev, Andrey},
title = {{RNN-based early cyber-attack detection for the Tennessee Eastman process}},
year = {2017}
}
@inproceedings{Maas2013,
abstract = {Deep neural network acoustic models produce substantial gains in large vocabulary continuous speech recognition systems. Emerging work with rectified linear (ReL) hidden units demonstrates additional gains in final system performance relative to more commonly used sigmoidal nonlinearities. In this work, we explore the use of deep rectifier networks as acoustic models for the 300 hour Switchboard conversational speech recognition task. Using simple training procedures without pretraining, networks with rectifier nonlinearities produce 2{\%} absolute reductions in word error rates over their sigmoidal counterparts. We analyze hidden layer representations to quantify differences in how ReL units encode inputs as compared to sigmoidal units. Finally, we evaluate a variant of the ReL unit with a gradient more amenable to optimization in an attempt to further improve deep rectifier networks.},
author = {Maas, Andrew L and Hannun, Awni Y and Ng, Andrew Y},
booktitle = {iCML Workshop on Deep Learning for Audio, Speech and Language Processing},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Maas, Hannun, Ng - 2013 - Rectifier nonlinearities improve neural network acoustic models.pdf:pdf},
title = {{Rectifier nonlinearities improve neural network acoustic models}},
volume = {28},
year = {2013}
}
@unpublished{Bardsen2009,
author = {B{\aa}rdsen, Gunnar and L{\"{u}}tkepohl, Helmut},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/B{\aa}rdsen, L{\"{u}}tkepohl - 2009 - Forecasting levels of log variables in vector autoregressions.pdf:pdf},
institution = {EUI},
series = {Department of Economics},
title = {{Forecasting levels of log variables in vector autoregressions}},
year = {2009}
}
@article{Charles2005,
abstract = {We propose to extend the additive outlier (AO) identification procedure developed by Franses and Ghijsels (Franses, P.H., Ghijsels, H., 1999. Additive outliers, GARCH and forecasting volatility. International Journal of Forecasting, 15, 1–9) to take into account the innovative outliers (IOs) in a GARCH model. We apply it to three daily stock market indexes and examine the effects of outliers on the diagnostics of normality.},
author = {Charles, Am{\'{e}}lie and Darn{\'{e}}, Olivier},
issn = {01651765},
journal = {Economics Letters},
keywords = {c5,g1},
month = {mar},
number = {3},
pages = {347--352},
title = {{Outliers and GARCH models in financial data}},
url = {http://dx.doi.org/10.1016/j.econlet.2004.07.019},
volume = {86},
year = {2005}
}
@article{Belloni2011,
abstract = {This article is about estimation and inference methods for high dimensional sparse (HDS) regression models in econometrics. High dimensional sparse models arise in situations where many regressors (or series terms) are available and the regression function is well-approximated by a parsimonious, yet unknown set of regressors. The latter condition makes it possible to estimate the entire regression function effectively by searching for approximately the right set of regressors. We discuss methods for identifying this set of regressors and estimating their coefficients based on {\$}\backslashell{\_}1{\$}-penalization and describe key theoretical results. In order to capture realistic practical situations, we expressly allow for imperfect selection of regressors and study the impact of this imperfect selection on estimation and inference results. We focus the main part of the article on the use of HDS models and methods in the instrumental variables model and the partially linear model. We present a set of novel inference results for these models and illustrate their use with applications to returns to schooling and growth regression.},
author = {Belloni, Alexandre and Chernozhukov, Victor and Hansen, Christian},
month = {dec},
title = {{Inference for High-Dimensional Sparse Econometric Models}},
url = {http://arxiv.org/abs/1201.0220},
year = {2011}
}
@article{Cho,
author = {Chossat, P.},
journal = {C. R. Acad. Sci. Paris S{\'{e}}r. I Math.},
pages = {539--541},
title = {{Bifurcation secondaire de solutions quasi-p{\'{e}}riodiques dans un probl{\`{e}}me de bifurcation invariant parsym{\'{e}}trie O(2)}},
volume = {302},
year = {1986}
}
@article{Diebold2002,
abstract = {We propose and evaluate explicit tests of the null hypothesis of no difference in the accuracy of two competing forecasts. In contrast to previously developed tests, a wide variety of accuracy measures can be used (in particular, the loss of function need not be quadratic and need not even be symmetric), and forecast errors can be non-Gaussian, nonzero mean, serially correlated, and contemporaneously correlated. Asymptotic and exact finite-sample tests are proposed, evaluated, and illustrated.},
author = {Diebold, Francis X and Mariano, Robert S},
issn = {0735-0015},
journal = {Journal of Business {\&} Economic Statistics},
keywords = {Economic loss function,Exchange rates,Forecast evaluation,Forecasting,Nonparametric tests,Sign test},
language = {en},
month = {jan},
number = {1},
pages = {134--144},
publisher = {Taylor {\&} Francis},
title = {{Comparing Predictive Accuracy}},
url = {http://amstat.tandfonline.com/doi/abs/10.1198/073500102753410444{\#}.UiDOAxYjiao},
volume = {20},
year = {2002}
}
@inproceedings{GRU2014,
author = {Cho, Kyunghyun and van Merri{\"{e}}nboer, Bart and Gulcehre, Caglar and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
booktitle = {Conference on Empirical Methods in Natural Language Processing},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Cho et al. - 2014 - Learning phrase representations using RNN encoder-decoder for statistical machine translation.pdf:pdf},
title = {{Learning phrase representations using RNN encoder-decoder for statistical machine translation}},
year = {2014}
}
@article{Lyons:2014,
abstract = {Rough path theory is focused on capturing and making precise the interactions between highly oscillatory and non-linear systems. It draws on the analysis of LC Young and the geometric algebra of KT Chen. The concepts and the uniform estimates, have widespread application and have simplified proofs of basic questions from the large deviation theory and extended Ito's theory of SDEs; the recent applications contribute to (Graham) automated recognition of Chinese handwriting and (Hairer) formulation of appropriate SPDEs to model randomly evolving interfaces. At the heart of the mathematics is the challenge of describing a smooth but potentially highly oscillatory and vector valued path {\$}x{\_}{\{}t{\}}{\$} parsimoniously so as to effectively predict the response of a nonlinear system such as {\$}dy{\_}{\{}t{\}}=f(y{\_}{\{}t{\}})dx{\_}{\{}t{\}}{\$}, {\$}y{\_}{\{}0{\}}=a{\$}. The Signature is a homomorphism from the monoid of paths into the grouplike elements of a closed tensor algebra. It provides a graduated summary of the path {\$}x{\$}. Hambly and Lyons have shown that this non-commutative transform is faithful for paths of bounded variation up to appropriate null modifications. Among paths of bounded variation with given Signature there is always a unique shortest representative. These graduated summaries or features of a path are at the heart of the definition of a rough path; locally they remove the need to look at the fine structure of the path. Taylor's theorem explains how any smooth function can, locally, be expressed as a linear combination of certain special functions (monomials based at that point). Coordinate iterated integrals form a more subtle algebra of features that can describe a stream or path in an analogous way; they allow a definition of rough path and a natural linear "basis" for functions on streams that can be used for machine learning.},
archivePrefix = {arXiv},
arxivId = {1405.4537},
author = {Lyons, Terry},
eprint = {1405.4537},
journal = {Preprint},
keywords = {e product,functional regres-,machine learning,numerical approximation of parabolic,pde,regularity structures,rough paths,shu,sion,tensor algebra},
title = {{Rough paths, Signatures and the modelling of functions on streams}},
year = {2014}
}
@article{Laurent2009,
author = {Laurent, S{\'{e}}bastien and Rombouts, J. and Violante, Francesco},
journal = {Journal of Econometrics},
number = {1},
pages = {1--10},
title = {{On loss functions and ranking forecasting performances of multivariate volatility models}},
url = {http://papers.ssrn.com/sol3/papers.cfm?abstract{\_}id=1507090},
volume = {173},
year = {2013}
}
@book{krasovskiy:book,
author = {Krasovskiy, N. N.},
publisher = {Stanford University Press},
title = {{Stability of Motion}},
year = {1963}
}
@article{Larger2012,
abstract = {Many information processing challenges are difficult to solve with traditional Turing or von Neumann approaches. Implementing unconventional computational methods is therefore essential and optics provides promising opportunities. Here we experimentally demonstrate optical information processing using a nonlinear optoelectronic oscillator subject to delayed feedback. We implement a neuro-inspired concept, called Reservoir Computing, proven to possess universal computational capabilities. We particularly exploit the transient response of a complex dynamical system to an input data stream. We employ spoken digit recognition and time series prediction tasks as benchmarks, achieving competitive processing figures of merit.},
author = {Larger, L. and Soriano, M. C. and Brunner, D. and Appeltant, L. and Gutierrez, J. M. and Pesquera, L. and Mirasso, C. R. and Fischer, I.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Larger et al. - 2012 - Photonic information processing beyond Turing an optoelectronic implementation of reservoir computing.pdf:pdf},
issn = {1094-4087},
journal = {Optics Express},
keywords = {Information processing,Instabilities and chaos,Optical processing devices},
month = {jan},
number = {3},
pages = {3241},
publisher = {OSA},
shorttitle = {Opt. Express},
title = {{Photonic information processing beyond Turing: an optoelectronic implementation of reservoir computing}},
volume = {20},
year = {2012}
}
@article{Barndorff-Nielsen2002,
author = {Barndorff-Nielsen, Ole E. and Shephard, Neil},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Barndorff-Nielsen, Shephard - 2002 - Estimating quadratic variation using realized variance.pdf:pdf},
journal = {Journal of Applied Econometrics},
pages = {457--477},
title = {{Estimating quadratic variation using realized variance}},
volume = {17},
year = {2002}
}
@phdthesis{Hebiri2009,
author = {Hebiri, Mohamed},
school = {Universit{\{}{\'{e}}{\}} Paris Diderot - Paris 7},
title = {{Quelques questions de s{\{}{\'{e}}{\}}lection de variables autour de l'estimateur lasso}},
year = {2009}
}
@article{SbranaPoloniMETA,
author = {Sbrana, Giacomo and Poloni, Federico},
journal = {Int. J. Production Economics},
pages = {143--150},
title = {{A note on forecasting demand using the multivariate exponential smoothing framework}},
volume = {162},
year = {2015}
}
@unpublished{Bianchi2016,
abstract = {A recurrent neural network (RNN) is a universal approximator of dynamical systems, whose performance often depends on sensitive hyperparameters. Tuning of such hyperparameters may be difficult and, typically, based on a trial-and-error approach. In this work, we adopt a graph-based framework to interpret and characterize the internal RNN dynamics. Through this insight, we are able to design a principled unsupervised method to derive configurations with maximized performances, in terms of prediction error and memory capacity. In particular, we propose to model time series of neurons activations with the recently introduced horizontal visibility graphs, whose topological properties reflect important dynamical features of the underlying dynamic system. Successively, each graph becomes a layer of a larger structure, called multiplex. We show that topological properties of such a multiplex reflect important features of RNN dynamics and are used to guide the tuning procedure. To validate the proposed method, we consider a class of RNNs called echo state networks. We perform experiments and discuss results on several benchmarks and real-world dataset of call data records.},
archivePrefix = {arXiv},
arxivId = {1609.03068},
author = {Bianchi, Filippo Maria and Livi, Lorenzo and Alippi, Cesare and Jenssen, Robert},
eprint = {1609.03068},
pages = {1--13},
title = {{Multiplex visibility graphs to investigate recurrent neural networks dynamics}},
url = {http://arxiv.org/abs/1609.03068},
year = {2016}
}
@book{Math1995,
address = {Washington D.C., USA},
author = {{Committee on Mathematical Challenges from Computational Chemistry} and {Commission on Physical Sciences, Mathematics, and Applications} and {Division on Engineering and Physical Sciences and National Research Council}},
doi = {10.17226/4886},
isbn = {978-0-309-05097-5},
publisher = {National Academy Press},
title = {{Mathematical Challenges from Theoretical/Computational Chemistry}},
url = {http://www.nas.edu/catalog/4886},
year = {1995}
}
@book{burghelea,
address = {Timisoara},
author = {Burghelea, D. and Albu, A. and Ratiu, T. S.},
booktitle = {Monografii Matematice},
publisher = {Universitatea Timisoara},
title = {{Compact Lie Group Actions (in Romanian)}},
volume = {5},
year = {1975}
}
@article{Hanin2019,
author = {Hanin, Boris},
journal = {Mathematics},
number = {10},
title = {{Universal function approximation by deep neural nets with bounded width and ReLU activations}},
volume = {7},
year = {2019}
}
@article{AS1999,
author = {A{\"{i}}t-Sahalia, Yacine},
issn = {0022-1082},
journal = {The Journal of Finance},
month = {aug},
number = {4},
pages = {1361--1395},
title = {{Transition densities for interest rate and other nonlinear diffusions}},
url = {http://doi.wiley.com/10.1111/0022-1082.00149},
volume = {54},
year = {1999}
}
@article{Tzovara2012,
abstract = {Auditory evoked potentials are informative of intact cortical functions of comatose patients. The integrity of auditory functions evaluated using mismatch negativity paradigms has been associated with their chances of survival. However, because auditory discrimination is assessed at various delays after coma onset, it is still unclear whether this impairment depends on the time of the recording. We hypothesized that impairment in auditory discrimination capabilities is indicative of coma progression, rather than of the comatose state itself and that rudimentary auditory discrimination remains intact during acute stages of coma. We studied 30 post-anoxic comatose patients resuscitated from cardiac arrest and five healthy, age-matched controls. Using a mismatch negativity paradigm, we performed two electroencephalography recordings with a standard 19-channel clinical montage: the first within 24 h after coma onset and under mild therapeutic hypothermia, and the second after 1 day and under normothermic conditions. We analysed electroencephalography responses based on a multivariate decoding algorithm that automatically quantifies neural discrimination at the single patient level. Results showed high average decoding accuracy in discriminating sounds both for control subjects and comatose patients. Importantly, accurate decoding was largely independent of patients' chance of survival. However, the progression of auditory discrimination between the first and second recordings was informative of a patient's chance of survival. A deterioration of auditory discrimination was observed in all non-survivors (equivalent to 100{\%} positive predictive value for survivors). We show, for the first time, evidence of intact auditory processing even in comatose patients who do not survive and that progression of sound discrimination over time is informative of a patient's chance of survival. Tracking auditory discrimination in comatose patients could provide new insight to the chance of awakening in a quantitative and automatic fashion during early stages of coma.},
author = {Tzovara, Athina and Rossetti, Andrea O and Spierer, Lucas and Grivel, Jeremy and Murray, Micah M and Oddo, Mauro and {De Lucia}, Marzia},
doi = {10.1093/brain/aws264},
issn = {1460-2156},
journal = {Brain : a journal of neurology},
month = {nov},
title = {{Progression of auditory discrimination based on neural decoding predicts awakening from coma.}},
url = {http://brain.oxfordjournals.org/content/early/2012/11/12/brain.aws264.short},
year = {2012}
}
@article{laurent:nonlinearity,
author = {Laurent-Polz, F.},
journal = {Nonlinearity},
pages = {143--171},
title = {{Point vortices on the sphere: a case with opposite vorticities}},
volume = {15},
year = {2002}
}
@article{Laurent2011,
author = {Laurent, S{\'{e}}bastien and Rombouts, Jeroen V. K. and Violante, Francesco},
doi = {10.1002/jae.1248},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Laurent, Rombouts, Violante - 2012 - On the forecasting accuracy of multivariate GARCH models.pdf:pdf},
issn = {08837252},
journal = {Journal of Applied Econometrics},
keywords = {c10,c32,c51 c52,c53,confidence set,forecasting,g10,jel classification,loss function,maastricht university,model,multivariate garch,superior predictive ability,the netherlands and universit,variance matrix},
month = {apr},
number = {6},
pages = {934--955},
title = {{On the forecasting accuracy of multivariate GARCH models}},
url = {http://doi.wiley.com/10.1002/jae.1248},
volume = {27},
year = {2012}
}
@book{Shiryaeve:problem:book,
author = {Shiryaev, Albert N.},
doi = {10.1007/978-1-4614-3688-1},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Shiryaev - 2012 - Problems in Probability.pdf:pdf},
isbn = {9780387302935},
publisher = {Springer},
title = {{Problems in Probability}},
year = {2012}
}
@unpublished{Schmidt-Hieber2017,
author = {Schmidt-Hieber, Johannes},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Schmidt-Hieber - 2017 - Nonparametric regression using deep neural networks with relu activation function.pdf:pdf},
series = {arXiv preprint arXiv:1708.06633},
title = {{Nonparametric regression using deep neural networks with relu activation function}},
year = {2017}
}
@incollection{dijkinbook,
author = {Kaashoek, J. F. and van Dijk, H. K.},
booktitle = {Computer-Aided Econometrics},
chapter = {12},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Kaashoek, van Dijk - 2003 - Neural networks an econometric tool.pdf:pdf},
publisher = {CRC Press},
title = {{Neural networks: an econometric tool}},
year = {2003}
}
@article{sandberg:linear:note,
abstract = {The cornerstone of the theory of discrete-space single-input single-output linear systems is the idea that every such system has an input-output map H that can be represented by a convolution or the familiar generalization of a convolution. This thinking involves an oversight which, for the case of bounded inputs mapped continuously into bounded outputs, was recently corrected by adding an additional term to the representation. Here we give a more general result that addresses an important larger family of inputs},
author = {Sandberg, Irwin W.},
doi = {10.1109/ISCAS.1999.777622},
isbn = {0-7803-5471-0},
journal = {Circuits, Systems, and Signal Processing},
number = {6},
pages = {703--708},
title = {{A note on representation theorems for linear discrete-space systems}},
volume = {17},
year = {1998}
}
@article{Lutkepohl2010b,
author = {L{\"{u}}tkepohl, Helmut},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/L{\"{u}}tkepohl - 2010 - Forecasting nonlinear aggregates and aggregates with time-varying weights(2).pdf:pdf;:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/L{\"{u}}tkepohl - 2010 - Forecasting nonlinear aggregates and aggregates with time-varying weights.pdf:pdf},
institution = {EUI},
journal = {EUI Working Papers},
series = {Department of Economics},
title = {{Forecasting nonlinear aggregates and aggregates with time-varying weights}},
url = {http://papers.ssrn.com/sol3/papers.cfm?abstract{\_}id=1597622},
year = {2010}
}
@article{fernandes2005,
author = {Fernandes, M. and {de Sa Mota}, B. and Rocha, G.},
journal = {Economics Letters},
pages = {435--440},
title = {{A multivariate conditional autoregressive range model}},
volume = {86},
year = {2005}
}
@article{Kuhnel2019,
author = {K{\"{u}}hnel, Line and Sommer, Stefan and Arnaudon, Alexis},
journal = {Applied Mathematics and Computation},
pages = {411--437},
title = {{Differential geometry and stochastic dynamics with deep learning numerics}},
volume = {356},
year = {2019}
}
@article{Kozorez1976,
author = {Kozorez, V. V. and Kolodeev, I. D. and Kryukov, M. I. and Lyashenko, A. M. and Rashkovan, V. M. and Cheborin, O. G.},
journal = {Bull. of the Ac. of Sc. of USSR. Series A (in Russian)},
pages = {248--149},
title = {{On potential well of magnetic interaction between ideal current-carrying curcuits}},
volume = {3},
year = {1976}
}
@inproceedings{Vapnik1991,
author = {Vapnik, Vladimir},
booktitle = {Advances in Neural Information Processing Systems 4 (NIPS 1991)},
pages = {831--838},
title = {{Principles of risk minimization for learning theory}},
year = {1991}
}
@article{couillet2016Proc,
author = {Couillet, Romain and Wainrib, Gilles and Ali, Hafiz Tiomoko and Sevi, Harry},
journal = {Proceedings of The 33rd International Conference on Machine Learning},
pages = {517--525},
title = {{A random matrix approach to echo-state neural networks}},
year = {2016}
}
@book{Lord2014,
author = {Lord, Gabriel J. and Powell, Catherine E. and Shardlow, Tony},
isbn = {978-0-521-89990-1},
pages = {503},
publisher = {Cambridge University Press},
title = {{An Introduction to Computational Stochastic PDES}},
year = {2014}
}
@book{bourbaki:lie:1-3,
author = {Bourbaki, N.},
chapter = {1-3},
publisher = {Springer Verlag},
title = {{Lie Groups and Lie Algebras}},
year = {1989}
}
@unpublished{Estrella1998,
author = {Estrella, Arturo and Rodrigues, Anthony P},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Estrella, Rodrigues - 1998 - Consistent Covariance Matrix Estimation In Probit Models with Autocorrelated Errors.pdf:pdf},
institution = {Federal Reserve Bank of New York},
keywords = {and colleagues at the,autocorrelation,bank of new york,do not necessarily represent,federal reserve bank of,generalized method of moments,kenneth west,new,of the authors and,of the federal reserve,or the federal reserve,probit,system,thank christopher sims,the views expressed in,this paper are those,those,we would like to},
title = {{Consistent Covariance Matrix Estimation In Probit Models with Autocorrelated Errors}},
year = {1998}
}
@article{BGLY:16,
author = {Boedihardjo, Horatio and Geng, Xi and Lyons, Terry and Yang, Danyu},
journal = {Advances in Mathematics},
pages = {720--737},
publisher = {Elsevier},
title = {{The signature of a rough path: uniqueness}},
volume = {293},
year = {2016}
}
@article{ADRIAN2008,
author = {Adrian, Tobias and Rosenberg, Joshua},
issn = {00221082},
journal = {The Journal of Finance},
month = {dec},
number = {6},
pages = {2997--3030},
title = {{Stock Returns and Volatility: Pricing the Short-Run and Long-Run Components of Market Risk}},
url = {http://doi.wiley.com/10.1111/j.1540-6261.2008.01419.x},
volume = {63},
year = {2008}
}
@unpublished{Antonik2018,
author = {Antonik, Piotr and Haelterman, Marc and Massar, S.},
title = {{Brain-inspired photonic signal processor for periodic pattern generation and chaotic system emulation}},
year = {2018}
}
@article{RC7,
archivePrefix = {arXiv},
arxivId = {http://arxiv.org/abs/1806.00797},
author = {Grigoryeva, Lyudmila and Ortega, Juan-Pablo},
eprint = {/arxiv.org/abs/1806.00797},
journal = {Neural Networks},
pages = {495--508},
primaryClass = {http:},
title = {{Echo state networks are universal}},
volume = {108},
year = {2018}
}
@article{Lin2011,
abstract = {Stock trading system to assist decision-making is an emerging research area and has great commercial potentials. Successful trading operations should occur near the reversal points of price trends. Traditional technical analysis, which usually appears as various trading rules, does aim to look for peaks and bottoms of trends and is widely used in stock market. Unfortunately, it is not convenient to directly apply technical analysis since it depends on person's experience to select appropriate rules for individual share. In this paper, we enhance conventional technical analysis with Genetic Algorithms by learning trading rules from history for individual stock and then combine different rules together with Echo State Network to provide trading suggestions. Numerous experiments on S{\&}P 500 components demonstrate that whether in bull or bear market, our system significantly outperforms buy-and-hold strategy. Especially in bear market where S{\&}P 500 index declines a lot, our system still profits.},
author = {Lin, Xiaowei and Yang, Zehong and Song, Yixu},
doi = {10.1016/j.eswa.2011.03.001},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Lin, Yang, Song - 2011 - Intelligent stock trading system based on improved technical analysis and Echo State Network.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
number = {9},
pages = {11347--11354},
title = {{Intelligent stock trading system based on improved technical analysis and Echo State Network}},
volume = {38},
year = {2011}
}
@book{Elements:learning:book,
author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
edition = {Second},
pages = {745},
publisher = {Springer Verlag},
title = {{The Elements of Statistical Learning}},
year = {2013}
}
@article{ChungLiu1994,
abstract = {This study examines the common stochastic trends among national stock prices of the U.S. and five East Asian countries, including Japan, Taiwan, Hong Kong, Singapore, and South Korea. Through Johansen's maximum likelihood estimation procedure, two cointegration relationships are identified and the six stock price variables are found to share four common unit roots. The result suggests that the U.S. and Taiwan markets may not belong to a “common” stock region containing the remaining four countries. The result also shows that most variables have the same adjustment speed in moving from short-run disequilibria toward the common trend. Finally, impulse response analyses suggest that short-run adjustments to temporary shocks occur rather quickly for some countries, and that for others the pattern and magnitude of the adjustments may be influenced by commonalities in ethnic and other backgrounds of the countries involved.},
author = {Chung, Pin J. and Liu, Donald J.},
issn = {10629769},
journal = {The Quarterly Review of Economics and Finance},
month = {sep},
number = {3},
pages = {241--259},
title = {{Common stochastic trends in pacific rim stock markets}},
url = {http://www.sciencedirect.com/science/article/pii/1062976994900264},
volume = {34},
year = {1994}
}
@unpublished{Wu2011,
author = {Wu, Harry and Ozyildirim, Ataman},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Wu, Ozyildirim - 2011 - Modeling trends, Cyclical movements and Turning points of the Chinese Economy.pdf:pdf},
keywords = {Trends,chinese macroeconomic statistics,coincidence and leading economic indicators,cycles and turning points of China's growth},
title = {{Modeling trends, Cyclical movements and Turning points of the Chinese Economy}},
volume = {10},
year = {2011}
}
@book{Grosse-Erdmann:2011,
author = {Grosse-Erdmann, Karl-G. and {Peris Manguillot}, Alfred},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Grosse-Erdmann, Peris Manguillot - 2011 - Linear Chaos.pdf:pdf},
isbn = {9781447121695},
publisher = {Springer},
title = {{Linear Chaos}},
year = {2011}
}
@inproceedings{alexander:ogarch,
author = {Alexander, Carol},
booktitle = {Mastering Risk},
editor = {Alexander, Carol},
pages = {21--38},
publisher = {Financial Times-Prentice Hall},
title = {{Orthogonal GARCH}},
volume = {2},
year = {1998}
}
@book{cannas:weinstein,
author = {{Cannas da Silva}, A. and Weinstein, A.},
booktitle = {Berkeley Mathematics Lecture Note series},
publisher = {American Mathematical Society},
title = {{Geometric Models for Noncommutative Algebras}},
year = {1999}
}
@article{Poggio2003,
abstract = {Learning is key to developing systems tailored to a broad range of data analysis and information extraction tasks. We outline the mathematical foundations of learning theory and describe a key algorithm of it.},
author = {Poggio, Tomaso and Smale, Steve},
journal = {Notices of the American Mathematical Society (AMS)},
number = {5},
pages = {537--544},
title = {{The mathematics of learning: dealing with data}},
volume = {50},
year = {2003}
}
@incollection{LyonsCaLe:2004,
address = {Berlin, Heidelberg},
author = {Lyons, Terry and Caruana, Michael and L{\'{e}}vy, Thierry},
booktitle = {Differential Equations Driven by Rough Paths. Ecole d'Et{\'{e}} de Probabilit{\'{e}}s de Saint-Flour XXXIV - 2004},
doi = {10.1007/978-3-540-71285-5_5},
pages = {81--93},
publisher = {Springer Berlin Heidelberg},
title = {{Differential Equations Driven by Rough Paths}},
url = {http://link.springer.com/10.1007/978-3-540-71285-5{\_}5},
year = {2004}
}
@article{efron:lars,
author = {Efron, Bradley and Hastie, J and Johnstone, Iain and Tibshirani, Robert and Hastie, Trevor},
issn = {2168-8966},
journal = {The Annals of Statistics},
keywords = {Lasso,boosting,coefficient paths,linear regression,variable selection},
month = {jan},
number = {2},
pages = {407--499},
title = {{Least angle regression}},
url = {http://projecteuclid.org/euclid.aos/1083178935},
volume = {32},
year = {2004}
}
@article{Anderson1998,
abstract = {This article explores the use of scalar and multivariate autoregressive (AR) models to extract features from the human electroencephalogram (EEG) with which mental tasks can be discriminated. This is part of a larger project to investigate the feasibility of using EEG to allow paralyzed persons to control a device such as a wheelchair. EEG signals from four subjects were recorded while they performed two mental tasks. Quarter-second windows of six-channel EEG were transformed into four different representations: scalar AR model coefficients, multivariate AR coefficients, eigenvalues of a correlation matrix, and the Karhunen-Lo{\`{e}}ve transform of the multivariate AR coefficients. Feature vectors defined by these representations were classified with a standard, feedforward neural network trained via the error backpropagation algorithm. The four representations produced similar results, with the multivariate AR coefficients performing slightly better and more consistently with an average classification accuracy of 91.4{\%} on novel, untrained, EEG signals.},
author = {Anderson, Charles W. and Stolz, Erik A. and Shamsunder, Sanyogita},
doi = {10.1109/10.661153},
issn = {0018-9294},
journal = {IEEE Transactions on biomedical engineering},
keywords = {Electroencephalography,Feasibility Studies,Humans,Mental Processes,Mental Processes: physiology,Models,Multivariate Analysis,Neural Networks (Computer),Regression Analysis,Statistical},
month = {mar},
number = {3},
pages = {277--286},
pmid = {9509744},
title = {{Multivariate autoregressive models for classification of spontaneous electroencephalographic signals during mental tasks}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9509744},
volume = {45},
year = {1998}
}
@misc{Harrigan,
author = {Harrigan, Roy},
publisher = {US patent},
title = {{Levitation device}},
year = {1983}
}
@article{Klusowski2018,
abstract = {We establish {\$} L{\^{}}{\{}\backslashinfty{\}} {\$} and {\$} L{\^{}}2 {\$} error bounds for functions of many variables that are approximated by linear combinations of ReLU (rectified linear unit) and squared ReLU ridge functions with {\$} \backslashell{\^{}}1 {\$} and {\$} \backslashell{\^{}}0 {\$} controls on their inner and outer parameters. With the squared ReLU ridge function, we show that the {\$} L{\^{}}2 {\$} approximation error is inversely proportional to the inner layer {\$} \backslashell{\^{}}0 {\$} sparsity and it need only be sublinear in the outer layer {\$} \backslashell{\^{}}0 {\$} sparsity. Our constructions are obtained using a variant of the Jones-Barron probabilistic method, which can be interpreted as either stratified sampling with proportionate allocation or two-stage cluster sampling. We also provide companion error lower bounds that reveal near optimality of our constructions. Despite the sparsity assumptions, we showcase the richness and flexibility of these ridge combinations by defining a large family of functions, in terms of certain spectral conditions, that are particularly well approximated by them.},
author = {Klusowski, Jason M. and Barron, Andrew R.},
doi = {10.1109/TIT.2018.2874447},
issn = {00189448},
journal = {IEEE Transactions on Information Theory},
keywords = {Ridge combinations,approximation error,rectified linear unit,sparse models,spline,stratified sampling},
title = {{Approximation by combinations of ReLU and squared ReLU ridge functions with l1 and l0 controls}},
year = {2018}
}
@book{lasota1998chaos,
author = {Lasota, Andrzej and Mackey, Michael C},
publisher = {Springer Science {\&} Business Media},
title = {{Chaos, Fractals, and Noise: Stochastic Aspects of Dynamics}},
volume = {97},
year = {1998}
}
@article{wu2018physics,
author = {Wu, Jin-Long and Xiao, Heng and Paterson, Eric},
journal = {Physical Review Fluids},
number = {7},
pages = {74602},
publisher = {APS},
title = {{Physics-informed machine learning approach for augmenting turbulence models: A comprehensive framework}},
volume = {3},
year = {2018}
}
@inproceedings{Khusainov2011,
author = {Khusainov, Denys and Dibl{\'{i}}k, Josef and Kukharenko, Oleksandra},
booktitle = {Proceedings of the 7th Conference on Mathematics and Physics on Technical Universities},
isbn = {978-80-7231-816-2},
pages = {235--242},
title = {{Solution of the Dirichlet boundary value problem for one system of linear partial differential equations with delay}},
year = {2011}
}
@article{DeRyck2021,
author = {{De Ryck}, Tim and Lanthaler, Samuel and Mishra, Siddhartha},
journal = {Neural Networks},
pages = {732--750},
title = {{On the approximation of functions by tanh neural networks}},
volume = {143},
year = {2021}
}
@article{BD2004,
abstract = {This paper surveys the literature on option pricing from its origins to the present. An extensive review of valuation methods for European- and American-style claims is provided. Applications to complex securities and numerical methods are surveyed. Emphasis is placed on recent trends and developments in methodology and modeling.},
author = {Broadie, Mark and Detemple, Jerome B.},
issn = {0025-1909},
journal = {Management Science},
keywords = {American options,jump and stochastic volatility models,option pricing,risk-neutral valuation},
language = {en},
month = {sep},
number = {9},
pages = {1145--1177},
publisher = {INFORMS},
title = {{Option pricing: valuation models and applications}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/mnsc.1040.0275},
volume = {50},
year = {2004}
}
@article{bott:82,
author = {Bott, R.},
journal = {Bull. Amer. Math. Soc.},
number = {2},
pages = {331--358},
title = {{Lectures on Morse Theory, old and new}},
volume = {7},
year = {1982}
}
@article{atiyah:82,
author = {Atiyah, M. F.},
journal = {Bull. London Math. Soc.},
pages = {1--15},
title = {{Convexity and commuting hamiltonians}},
volume = {14},
year = {1982}
}
@unpublished{Brueggemann2011,
author = {Brueggemann, Ralf and L{\"{u}}tkepohl, Helmut},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Brueggemann, L{\"{u}}tkepohl - 2011 - Forecasting contemporaneous aggregates with stochastic aggregation weights.pdf:pdf},
institution = {EUI},
series = {Department of Economics},
title = {{Forecasting contemporaneous aggregates with stochastic aggregation weights}},
year = {2011}
}
@article{muldoon:1998,
abstract = {We present a new embedding theorem for time series, in the spirit of Takens's theorem, but requiring multivariate signals. Our result is part of a growing body of work that extends the domain of geometric time series analysis to some genuinely stochastic systems - including such natural examples as xj+1 = $\phi$(xj) + $\eta$j where $\phi$ is some fixed map and the $\eta$j are i.i.d. random displacements.},
author = {Muldoon, Mark R. and Broomhead, David S. and Huke, Jeremy P. and Hegger, Rainer},
doi = {10.1080/02681119808806259},
issn = {02681110},
journal = {Dynamics and Stability of Systems},
number = {2},
pages = {175--186},
title = {{Delay embedding in the presence of dynamical noise}},
volume = {13},
year = {1998}
}
@article{Armesto2010,
author = {Armesto, Michelle T and Engemann, Kristie M and Owyang, Michael T},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Armesto, Engemann, Owyang - 2010 - Forecasting with Mixed Frequencies.pdf:pdf},
journal = {Federal Reserve Bank of St. Louis Review},
keywords = {C32,Federal Reserve Bank of St. Louis,Kristie Engemann,Michael Mike Owyang,Michelle Armesto,economic resear,economic research},
number = {6},
pages = {521--536},
title = {{Forecasting with Mixed Frequencies}},
volume = {92},
year = {2010}
}
@unpublished{Salehinejad2017,
author = {Salehinejad, Hojjat and Baarbe, Julianne and Sankar, Sharan and Barfett, Joseph and Colak, Errol and Valaee, Shahrokh},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Exterkate et al. - 2011 - Nonlinear Forecasting with Many Predictors using Kernel Ridge Regression.pdf:pdf},
title = {{Recent advances in recurrent neural networks}},
year = {2017}
}
@article{Kauppi2008,
author = {Kauppi, Heikki},
journal = {Group},
number = {31},
title = {{Yield-Curve Based Probit Models for Forecasting US Recessions: Stability and Dynamics}},
url = {http://ethesis.helsinki.fi/julkaisut/eri/hecer/disc/221/yieldcur.pdf},
year = {2008}
}
@article{van1987symmetries,
author = {der Schaft, A J},
journal = {SIAM journal on control and optimization},
number = {2},
pages = {245--259},
publisher = {SIAM},
title = {{Symmetries in optimal control}},
volume = {25},
year = {1987}
}
@article{Franke2006,
author = {Franke, J{\"{u}}rgen and Diagne, Mabouba},
doi = {10.1524/stnd.2006.24.2.233},
issn = {0721-2631},
journal = {Statistics {\&} Decisions},
month = {jan},
number = {2},
pages = {233--253},
title = {{Estimating market risk with neural networks}},
url = {http://www.degruyter.com/view/j/stnd.2006.24.issue-2/stnd.2006.24.2.233/stnd.2006.24.2.233.xml},
volume = {24},
year = {2006}
}
@misc{Bec2011,
author = {Bec, Fr{\'{e}}d{\'{e}}rique and Bouabdallah, Othman and Ferrara, Laurent},
booktitle = {October},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Bec, Bouabdallah, Ferrara - 2011 - The European Way Out of Recessions.pdf:pdf},
keywords = {asymmetric business cycles,bounce-back effects,c22,e32,jel classification,threshold autoregression},
pages = {1--23},
title = {{The European Way Out of Recessions}},
year = {2011}
}
@article{Schorfheide2005a,
abstract = {The paper considers multi-step forecasting of a stationary vector process under a quadratic loss function with a collection of finite-order vector autoregressions (VAR). Under severe misspecification it is preferable to use the multi-step loss function also for parameter estimation. We propose a modification to Shibata's (Ann. Statist. 8 (1980) 147) final prediction error criterion to jointly choose the VAR lag order and one of two predictors: the maximum likelihood estimator plug-in predictor or the loss function estimator plug-in predictor. A Monte Carlo experiment illustrates the theoretical results and documents the empirical performance of the selection criterion.},
author = {Schorfheide, Frank},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Schorfheide - 2005 - VAR forecasting under misspecification.pdf:pdf},
issn = {03044076},
journal = {Journal of Econometrics},
keywords = {c11,c32,c53},
month = {sep},
number = {1},
pages = {99--136},
title = {{VAR forecasting under misspecification}},
url = {http://dx.doi.org/10.1016/j.jeconom.2004.08.009},
volume = {128},
year = {2005}
}
@article{Jung2000,
abstract = {Eye movements, eye blinks, cardiac signals, muscle noise, and line noise present serious problems for electroenceph- alographic {\~{}}EEG! interpretation and analysis when rejecting contaminated EEG segments results in an unacceptable data loss. Many methods have been proposed to remove artifacts from EEG recordings, especially those arising from eye movements and blinks. Often regression in the time or frequency domain is performed on parallel EEG and electrooculographic {\~{}}EOG! recordings to derive parameters characterizing the appearance and spread of EOG artifacts in the EEG channels. Because EEG and ocular activity mix bidirectionally, regressing out eye artifacts inevitably involves subtracting relevant EEG signals from each record as well. Regression methods become even more problematic when a good regressing channel is not available for each artifact source, as in the case of muscle artifacts. Use of principal component analysis {\~{}}PCA! has been proposed to remove eye artifacts from multichannel EEG. However, PCA cannot completely separate eye artifacts from brain signals, especially when they have comparable amplitudes. Here, we propose a new and generally applicable method for removing a wide variety of artifacts from EEG records based on blind source separation by independent component analysis {\~{}}ICA!. Our results on EEG data collected from normal and autistic subjects show that ICA can effectively detect, separate, and remove contamination from a wide variety of artifactual sources in EEG records with results comparing favorably with those obtained using regression and PCA methods. ICA can also be used to analyze blink-related brain activity.},
author = {Jung, TP and Makeig, Scott and Humphries, Colin},
journal = {Psychophysiology},
number = {98},
pages = {163--178},
title = {{Removing electroencephalographic artifacts by blind source separation}},
url = {http://onlinelibrary.wiley.com/doi/10.1111/1469-8986.3720163/abstract},
volume = {37},
year = {2000}
}
@inproceedings{Chen2020,
author = {Chen, Zhengdao and Zhang, Jianyu and Arjovsky, Martin and Bottou, L{\'{e}}on},
booktitle = {International Conference on Learning Representations},
title = {{Symplectic recurrent neural networks}},
url = {https://openreview.net/forum?id=BkgYPREtPr},
year = {2020}
}
@article{Simon1997,
author = {Simon, M. D. and Heflinger, L. O. and Ridgway, S. L.},
journal = {Am. J. Phys.},
pages = {286--292},
title = {{Spin stabilized magnetic levitation}},
volume = {65},
year = {1997}
}
@article{CL_AR_NgJoe2011,
author = {Ng, Chi Tim and Joe, Harry and Karlis, Dimitris and Liu, Juxin},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Ng et al. - 2011 - Composite likelihood for time series models with a latent autoregressive process.pdf:pdf},
journal = {Statistica Sinica},
pages = {279--305},
title = {{Composite likelihood for time series models with a latent autoregressive process}},
volume = {21},
year = {2011}
}
@article{Lin2009,
abstract = {Neural network has been popular in time series prediction in financial areas because of their advantages in handling nonlinear systems. This paper presents a study of using a novel recurrent neural network–echo state network (ESN) to predict the next closing price in stock markets. The Hurst exponent is applied to adaptively determine initial transient and choose sub-series with greatest predictability during training. The experiment results on nearly all stocks of S{\&}P 500 demonstrate that ESN outperforms other conventional neural networks in most cases. Experiments also indicate that if we include principle component analysis (PCA) to filter noise in data pretreatment and choose appropriate parameters, we can effectively prevent coarse prediction performance. But in most cases PCA improves the prediction accuracy only a little.},
author = {Lin, Xiaowei and Yang, Zehong and Song, Yixu},
doi = {10.1016/j.eswa.2008.09.049},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Lin, Yang, Song - 2009 - Short-term stock price prediction based on echo state networks.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
number = {3},
pages = {7313--7317},
title = {{Short-term stock price prediction based on echo state networks}},
volume = {36},
year = {2009}
}
@article{Wiggins1987,
abstract = {This paper numerically solves the call option valuation problem given a fairly general continuous stochastic process for return volatility. Statistical estimators for volatility process parameters are derived, and parameter estimates are calculated for several individual stocks and indices. The resulting estimated option values do not differ dramatically from Black-Scholes values in most cases, although there is some evidence that for longer-maturity index options, Black-Scholes overvalues out-of-the-money calls in relation to in-the-money calls.},
author = {Wiggins, James B.},
doi = {10.1016/0304-405X(87)90009-2},
issn = {0304405X},
journal = {Journal of Financial Economics},
month = {dec},
number = {2},
pages = {351--372},
title = {{Option values under stochastic volatility: Theory and empirical estimates}},
url = {http://dx.doi.org/10.1016/0304-405X(87)90009-2},
volume = {19},
year = {1987}
}
@inproceedings{esn2014,
author = {Barancok, P. and Farkas, I.},
booktitle = {Proceedings of the International Conference on Artificial Neural Networks (ICANN)},
pages = {41--48},
title = {{Memory capacity of input-driven echo state networks at the edge of chaos}},
year = {2014}
}
@article{Verzelli2019a,
abstract = {Among the various architectures of Recurrent Neural Networks, Echo State Networks (ESNs) emerged due to their simplified and inexpensive training procedure. These networks are known to be sensitive to the setting of hyper-parameters, which critically affect their behavior. Results show that their performance is usually maximized in a narrow region of hyper-parameter space called edge of criticality. Finding such a region requires searching in hyper-parameter space in a sensible way: hyper-parameter configurations marginally outside such a region might yield networks exhibiting fully developed chaos, hence producing unreliable computations. The performance gain due to optimizing hyper-parameters can be studied by considering the memory–nonlinearity trade-off, i.e., the fact that increasing the nonlinear behavior of the network degrades its ability to remember past inputs, and vice-versa. In this paper, we propose a model of ESNs that eliminates critical dependence on hyper-parameters, resulting in networks that provably cannot enter a chaotic regime and, at the same time, denotes nonlinear behavior in phase space characterized by a large memory of past inputs, comparable to the one of linear networks. Our contribution is supported by experiments corroborating our theoretical findings, showing that the proposed model displays dynamics that are rich-enough to approximate many common nonlinear systems used for benchmarking.},
author = {Verzelli, Pietro and Alippi, Cesare and Livi, Lorenzo},
doi = {10.1038/s41598-019-50158-4},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Verzelli, Alippi, Livi - 2019 - Echo state networks with self-normalizing activations on the hyper-sphere(2).pdf:pdf},
issn = {2045-2322},
journal = {Scientific Reports},
keywords = {Computer science,Nonlinear phenomena},
month = {dec},
number = {1},
pages = {13887},
publisher = {Nature Publishing Group},
title = {{Echo state networks with self-normalizing activations on the hyper-sphere}},
url = {http://www.nature.com/articles/s41598-019-50158-4},
volume = {9},
year = {2019}
}
@misc{Bai2010,
author = {Bai, Jennie and Ghysels, Eric and Wright, Jonathan H.},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Bai, Ghysels, Wright - 2010 - State Space Models and MIDAS Regressions.pdf:pdf},
title = {{State Space Models and MIDAS Regressions}},
url = {http://www.unc.edu/{~}eghysels/papers/BGW{\_}Kalman{\_}vs{\_}MIDAS{\_}EG{\_}July{\_}17{\_}10.pdf},
year = {2010}
}
@article{Kasa1992,
abstract = {This paper presents evidence concerning the number of common stochastic trends in the equity markets of the U.S., Japan, England, Germany, and Canada. Monthly and quarterly data from January 1974 through August 1990 on Morgan Stanley's Capital International indices are used to compute Johansen (1990) tests for common trends. The results indicate the presence of a single common trend driving these countries' stock markets. Estimates of the factor loadings suggest that this trend is most important in the Japanese market and least important in the Canadian market. To interpret this evidence the paper demonstrates that under weak conditions the unit root and cointegration structure of stock prices should mirror the unit root and cointegration structure of their dividend payments. The paper tests this prediction by constructing national dividend series from Capital International's dividend yield data. as well as by using GNP data. As with stock prices, the evidence points to a single common trend, although the stochastic properties and relative importance of this trend differs somewhat from the trend in stock prices.},
author = {Kasa, Kenneth},
issn = {03043932},
journal = {Journal of Monetary Economics},
month = {feb},
number = {1},
pages = {95--124},
title = {{Common stochastic trends in international stock markets}},
url = {http://www.sciencedirect.com/science/article/pii/030439329290025W},
volume = {29},
year = {1992}
}
@article{sontag:VC,
author = {Sontag, Eduardo D.},
journal = {NATO ASI Series F Computer and Systems Sciences},
pages = {69--96},
title = {{VC dimension of neural networks}},
volume = {168},
year = {1998}
}
@article{Klinshov2015,
author = {Klinshov, V. and L{\"{u}}cken, L. and Shchapin, D. and Nekorkin, V. and Yanchuk, S.},
journal = {Physical Review E},
number = {4},
pages = {042914},
title = {{Emergence and combinatorial accumulation of jittering regimes in spiking oscillators with delayed feedback}},
volume = {92},
year = {2015}
}
@article{tibshirani:lasso,
author = {Tibshirani, Robert},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Tibshirani - 1996 - Regression Shrinkage and Selection via the Lasso.pdf:pdf},
journal = {J. R. Stat. Soc. Ser. B},
keywords = {Quadratuc programming,Regression,Shrinkage,Subset selection},
number = {1},
pages = {267--288},
title = {{Regression shrinkage and selection via the LASSO}},
volume = {58},
year = {1996}
}
@article{Stock2012,
abstract = {This article provides a simple shrinkage representation that describes the operational characteristics of various forecasting methods designed for a large number of orthogonal predictors (such as principal components). These methods include pretest methods, Bayesian model averaging, empirical Bayes, and bagging. We compare empirically forecasts from these methods with dynamic factor model (DFM) forecasts using a U.S. macroeconomic dataset with 143 quarterly variables spanning 1960?2008. For most series, including measures of real economic activity, the shrinkage forecasts are inferior to the DFM forecasts. This article has online supplementary material.
This article provides a simple shrinkage representation that describes the operational characteristics of various forecasting methods designed for a large number of orthogonal predictors (such as principal components). These methods include pretest methods, Bayesian model averaging, empirical Bayes, and bagging. We compare empirically forecasts from these methods with dynamic factor model (DFM) forecasts using a U.S. macroeconomic dataset with 143 quarterly variables spanning 1960?2008. For most series, including measures of real economic activity, the shrinkage forecasts are inferior to the DFM forecasts. This article has online supplementary material.},
author = {Stock, James H. and Watson, Mark W.},
issn = {0735-0015},
journal = {Journal of Business {\&} Economic Statistics},
month = {oct},
number = {4},
pages = {481--493},
publisher = {Taylor {\&} Francis},
title = {{Generalized Shrinkage Methods for Forecasting Using Many Predictors}},
url = {http://dx.doi.org/10.1080/07350015.2012.715956},
volume = {30},
year = {2012}
}
@book{Folland1995,
author = {Folland, G. B.},
edition = {Second},
publisher = {Princeton University Press},
title = {{Introduction to Partial Differential Equations}},
year = {1995}
}
@article{Dror2010,
annote = {200910373[PII]},
author = {Dror, Ron O and Jensen, Morten {\O} and Borhani, David W and Shaw, David E},
doi = {10.1085/jgp.200910373},
issn = {0022-1295},
journal = {J Gen Physiol},
month = {jun},
number = {6},
pages = {555--562},
publisher = {The Rockefeller University Press},
title = {{Exploring atomic resolution physiology on a femtosecond to millisecond timescale using molecular dynamics simulations}},
url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2888062/},
volume = {135},
year = {2010}
}
@article{Pan2014,
author = {Pan, Jiahui and Xie, Qiuyou and He, Yanbin and Wang, Fei and Di, Haibo and Laureys, Steven and Yu, Ronghao and Li, Yuanqing},
doi = {10.1088/1741-2560/11/5/056007},
issn = {1741-2560},
journal = {Journal of Neural Engineering},
month = {oct},
number = {5},
pages = {056007},
publisher = {IOP Publishing},
title = {{Detecting awareness in patients with disorders of consciousness using a hybrid brain–computer interface}},
url = {http://stacks.iop.org/1741-2552/11/i=5/a=056007?key=crossref.971f17f15c6c662de8d37eca5ebd9f10},
volume = {11},
year = {2014}
}
@article{Anderson1995a,
author = {Anderson, Charles W. and Devulapalli, S. V. and Stolz, E. A.},
journal = {Scientific programming},
number = {3},
pages = {171--183},
title = {{Determing mental state from EEG signals using neural networks}},
volume = {4},
year = {1995}
}
@article{calabi70,
author = {Calabi, E.},
journal = {Problems in Analysis (Princeton University Press)},
pages = {1--26},
title = {{On the group of automorphisms of a symplectic manifold}},
year = {1970}
}
@book{do:carmo:1993,
author = {do Carmo, Manfredo Perdig{\~{a}}o},
publisher = {Birkh{\"{a}}user Boston},
title = {{Riemannian Geometry}},
year = {1992}
}
@article{Kiefer1952,
abstract = {Let M(x) be a regression function which has a maximum at the unknown point $\theta$. M(x) is itself unknown to the statistician who, however, can take observations at any level x. This paper gives a scheme whereby, starting from an arbitrary point x1, one obtains successively x2, x3, ⋯ such that xn converges to $\theta$ in probability as n → ∞.},
author = {Kiefer, J. and Wolfowitz, J.},
doi = {10.1214/aoms/1177729392},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Kiefer, Wolfowitz - 1952 - Stochastic estimation of the maximum of a regression function.pdf:pdf},
issn = {0003-4851},
journal = {The Annals of Mathematical Statistics},
number = {3},
pages = {462--466},
title = {{Stochastic estimation of the maximum of a regression function}},
volume = {23},
year = {1952}
}
@unpublished{Lanne2008,
author = {Lanne, Markku and L{\"{u}}tkepohl, Helmut},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Lanne, L{\"{u}}tkepohl - 2008 - Stock prices and economic fluctuations a markov switching structural vector autoregressive analysis.pdf:pdf},
institution = {EUI},
series = {Department of Economics},
title = {{Stock prices and economic fluctuations: a markov switching structural vector autoregressive analysis}},
year = {2008}
}
@article{bridges:90a,
author = {Bridges, T. J.},
journal = {Arch. Rational Mech. Anal.},
pages = {335--376},
title = {{The Hopf bifurcation with symmetry for the Navier-Stokes equation in $\backslash${\$}(L{\_}p(\Omega)){\^{}}n\backslash{\$} with application to plane Poiseuille flow}},
volume = {106},
year = {1990}
}
@article{heston:nandi,
author = {Heston, S L and Nandi, S},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Heston, Nandi - 2000 - A closed-form GARCH option valuation model.pdf:pdf},
journal = {Review of Financial Studies},
number = {3},
pages = {585--625},
title = {{A closed-form GARCH option valuation model}},
volume = {13},
year = {2000}
}
@book{buhlmann:van,
author = {B{\"{u}}hlmann, Peter and van der Geer, Sara},
pages = {558},
publisher = {Springer Berlin Heidelberg},
title = {{Statistics for High-Dimensional Data}},
year = {211}
}
@article{Wang2019,
author = {Wang, Jianzhou and Niu, Tong and Lu, Haiyan and Yang, Wendong and Du, Pei},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Wang et al. - 2019 - A novel framework of reservoir computing for deterministic and probabilistic wind power forecasting.pdf:pdf},
journal = {IEEE Transactions on Sustainable Energy},
number = {1},
pages = {337 -- 349},
title = {{A novel framework of reservoir computing for deterministic and probabilistic wind power forecasting}},
volume = {11},
year = {2019}
}
@article{souriau1966,
author = {Souriau, Jean-Marie},
journal = {Comm. Math. Phys.},
pages = {374--398},
title = {{Quantification g{\'{e}}om{\'{e}}trique}},
volume = {1},
year = {1966}
}
@article{RC:phonecalls,
abstract = {We approach the problem of forecasting the load of incoming calls in a cell of a mobile network using Echo State Networks. With respect to previous approaches to the problem, we consider the inclusion of additional telephone records regarding the activity registered in the cell as exogenous variables, by investigating their usefulness in the forecasting task. Additionally, we analyze different methodologies for training the readout of the network, including two novel variants, namely ??-SVR and an elastic net penalty. Finally, we employ a genetic algorithm for both the tasks of tuning the parameters of the system and for selecting the optimal subset of most informative additional time-series to be considered as external inputs in the forecasting problem. We compare the performances with standard prediction models and we evaluate the results according to the specific properties of the considered time-series.},
author = {Bianchi, Filippo Maria and Scardapane, Simone and Uncini, Aurelio and Rizzi, Antonello and Sadeghian, Alireza},
doi = {10.1016/j.neunet.2015.08.010},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Bianchi et al. - 2015 - Prediction of telephone calls load using Echo State Network with exogenous variables.pdf:pdf},
issn = {18792782},
journal = {Neural Networks},
keywords = {Call data records,Echo State Networks,Exogenous variables,Forecasting,Genetic algorithm,Time-series},
number = {November},
pages = {204--213},
pmid = {26413714},
title = {{Prediction of telephone calls load using Echo State Network with exogenous variables}},
volume = {71},
year = {2015}
}
@article{online:regression,
abstract = {In this demo, we present the StreamFitter system for real-time linear regression analysis on continuous data streams. In order to perform regression on data streams, it is necessary to continuously update the regression model while receiving new data. In this demo, we will present two approaches for on-line, multi-dimensional linear regression analysis of stream data, namely Incremental Mathematical Stream Regression (IMSR) and Approximate Stream Regression (ASR). These methods dynamically recompute the regression model, considering not only the data records of the current window, but also the synopsis of the previous data. Therefore, the refined parameters more accurately model the entire data stream. The demo will show that the proposed methods are not only efficient in time and space, but also generate better fitted regression functions compared to the traditional sliding window methods and well-adapted to data changes. {\textcopyright} 2011 Springer-Verlag.},
author = {Nadungodage, C.H. and Xia, Y. and Li, F. and Ge, J.},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
number = {PART 2},
pages = {458--461},
title = {{StreamFitter: A real time linear regression analysis system for continuous data streams}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79955114143{\&}partnerID=40{\&}md5=9c91f6212d65dca09884a46b867aef58},
volume = {6588 LNCS},
year = {2011}
}
@article{FM07,
author = {Fornari, F. and Mele, A.},
journal = {Econometric Reviews},
pages = {205--227},
title = {{Weak convergence and distributional assumptions for a general class of nonlinear ARCH models}},
volume = {16},
year = {1997}
}
@techreport{Avouyi-dovi2005,
author = {Avouyi-dovi, Sanvi and Matheron, Julien},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Avouyi-dovi, Matheron - 2005 - Interactions between business cycles, stock market cycles and interest rates the stylised facts.pdf:pdf},
institution = {Banque de France},
title = {{Interactions between business cycles, stock market cycles and interest rates: the stylised facts}},
type = {Working Paper},
year = {2005}
}
@article{Andersen2001,
author = {Andersen, Torben G. and Bollerslev, Tim and Diebold, Francis X. and Labys, Paul},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Andersen et al. - 2001 - The distribution of realized exchange rate volatility.pdf:pdf},
journal = {Journal of the American Statistical Association},
number = {453},
pages = {42--55},
title = {{The distribution of realized exchange rate volatility}},
volume = {96},
year = {2001}
}
@article{Qin2019,
author = {Qin, Tong and Wu, Kailiang and Xiu, Dongbin},
doi = {10.1016/j.jcp.2019.06.042},
journal = {Journal of Computational Physics},
month = {oct},
pages = {620--635},
publisher = {Elsevier {\{}BV{\}}},
title = {{Data driven governing equations approximation using deep neural networks}},
url = {https://doi.org/10.1016{\%}2Fj.jcp.2019.06.042},
volume = {395},
year = {2019}
}
@article{duflo:vergne,
author = {Duflo, M and Vergne, M},
journal = {C. R. Acad. Sci. Paris},
pages = {583--585},
title = {{Une propriet{\{}{\'{e}}{\}} de la repr{\{}{\'{e}}{\}}sentation coadjointe d'une alg{\{}{\'{e}}{\}}bre de Lie}},
volume = {268},
year = {1969}
}
@article{hagan2002managing,
author = {Hagan, Patrick S and Kumar, Deep and Lesniewski, Andrew S and Woodward, Diana E},
journal = {The Best of Wilmott},
pages = {249--296},
title = {{Managing smile risk}},
volume = {1},
year = {2002}
}
@article{Subasi2005a,
abstract = {Electrophysiological recordings are considered a reliable method of assessing a person's alertness. Sleep medicine is asked to offer objective methods to measure daytime alertness, tiredness and sleepiness. As EEG signals are non-stationary, the conventional method of frequency analysis is not highly successful in recognition of alertness level. This paper deals with a novel method of analysis of EEG signals using wavelet transform, and classification using ANN. EEG signals were decomposed into the frequency sub-bands using wavelet transform and a set of statistical features was extracted from the sub-bands to represent the distribution of wavelet coefficients. Then these statistical features were used as an input to an ANN with three discrete outputs: alert, drowsy and sleep. The error back-propagation neural network is selected as a classifier to discriminate the alertness level of a subject. EEG signals were obtained from 30 healthy subjects. The group consisted of 14 females and 16 males with ages ranging from 18 to 65 years and a mean age of 33.5 years, and a Body Mass Index (BMI) of 32.4G7.3 kg/m2. Alertness level and classification properties ofANNwere tested using the data recorded in 12 healthy subjects, whereby the EEG recordings were not used to train the ANN. The statistics were used as a measure of potential applicability of the ANN. The accuracy of the ANN was 95G3{\%} alert, 93G4{\%} drowsy and 92G5{\%} sleep.},
author = {Subasi, Abdulhamit},
doi = {10.1016/j.eswa.2004.12.027},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Subasi - 2005 - Automatic recognition of alertness level from EEG by using neural network and wavelet coefficients.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {alert,ann,artificial neural network,discrete wavelet transform,drowsy,dwt,eeg,electroencephalogram,sleep},
month = {may},
number = {4},
pages = {701--711},
title = {{Automatic recognition of alertness level from EEG by using neural network and wavelet coefficients}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0957417404001745},
volume = {28},
year = {2005}
}
@incollection{Maltarollo2013,
author = {Maltarollo, V. G. and Hon$\backslash$'orio, K. M. and {Ferreira da Silva}, A. B.},
booktitle = {Artificial Neural Net- works - Architectures and Applications},
publisher = {InTech},
title = {{Applications of artificial neural networks in chemi- cal problems}},
year = {2013}
}
@book{bayen:and:company,
address = {111(1),61--110},
author = {Bayen, F. and Flato, M. and Fronsdal, C. and Lichnerowicz, A. and Sternheimer, D.},
booktitle = {Ann. Physics},
number = {1},
pages = {61--110},
publisher = {Deformations of symplectic structures. Ann. Physics},
title = {{Deformation theory and quantization I. Deformations of symplectic structures}},
volume = {111},
year = {1978}
}
@article{AS2002,
author = {A{\"{i}}t-Sahalia, Yacine},
issn = {0012-9682},
journal = {Econometrica},
month = {jan},
number = {1},
pages = {223--262},
title = {{Maximum likelihood estimation of discretely sampled diffusions: a closed-form approximation approach}},
url = {http://doi.wiley.com/10.1111/1468-0262.00274},
volume = {70},
year = {2002}
}
@article{Schumacher2010,
abstract = {Papers on factor forecasting are often focused on national data only. This paper highlights the role of international data for forecasting German GDP and shows how targeted predictors as proposed by Bai and Ng [Forecasting economic time series using targeted predictors, Journal of Econometrics 146 (2008), 304–317] can improve forecast accuracy.},
author = {Schumacher, Christian},
file = {:Users/JPO/Dropbox/JPO{\_}synch/Mendeley/Schumacher - 2010 - Factor forecasting using international targeted predictors The case of German GDP.pdf:pdf},
issn = {01651765},
journal = {Economics Letters},
keywords = {c53,f47,factor models,forecasting,international data,variable selection},
month = {may},
number = {2},
pages = {95--98},
title = {{Factor forecasting using international targeted predictors: The case of German GDP}},
url = {http://dx.doi.org/10.1016/j.econlet.2009.12.036},
volume = {107},
year = {2010}
}
@article{Goncalves2011,
author = {Gon{\c{c}}alves, S{\'{i}}lvia and Meddahi, Nour},
journal = {Journal of Econometrics},
pages = {129--144},
title = {{Box–Cox transforms for realized volatility}},
volume = {160},
year = {2011}
}

@book{Polderman1998,
	author = {Jan Willem Polderman and Jan C. Willems},
	title = {Introduction to Mathematical Systems Theory},
	publisher = {Springer New York, NY},
	year = {1998}
}


@InProceedings{Valperga2022,
	title = 	 {Learning Reversible Symplectic Dynamics},
	author =       {Valperga, Riccardo and Webster, Kevin and Turaev, Dmitry and Klein, Victoria and Lamb, Jeroen},
	booktitle = 	 {Proceedings of The 4th Annual Learning for Dynamics and Control Conference},
	pages = 	 {906--916},
	year = 	 {2022},
	editor = 	 {Firoozi, Roya and Mehr, Negar and Yel, Esen and Antonova, Rika and Bohg, Jeannette and Schwager, Mac and Kochenderfer, Mykel},
	volume = 	 {168},
	series = 	 {Proceedings of Machine Learning Research},
	month = 	 {23--24 Jun},
	publisher =    {PMLR},
	pdf = 	 {https://proceedings.mlr.press/v168/valperga22a/valperga22a.pdf},
	url = 	 {https://proceedings.mlr.press/v168/valperga22a.html}
}

@article{acciaio2022metric,
  title={Metric hypertransformers are universal adapted maps},
  author={Acciaio, Beatrice and Kratsios, Anastasis and Pammer, Gudmund},
  journal={arXiv preprint arXiv:2201.13094},
  year={2022}
}

@article{Krzysztof1983,
	author = {Tchoń, Krzysztof},
	year = {1983},
	month = {01},
	pages = {},
	title = {On generic properties of linear systems: An overview},
	volume = {19},
	journal = {Kybernetika}
}

@article{Son2022,
	author = {Son, Nguyen and Stykel, Tatjana},
	year = {2022},
	month = {08},
	pages = {},
	title = {Symplectic eigenvalues of positive-semidefinite matrices and the trace minimization theorem},
	doi = {10.48550/arXiv.2208.05291}
}

@inproceedings{
	Zhong2020Symplectic,
	title={Symplectic ODE-Net: Learning Hamiltonian Dynamics with Control},
	author={Yaofeng Desmond Zhong and Biswadip Dey and Amit Chakraborty},
	booktitle={International Conference on Learning Representations},
	year={2020},
	url={https://openreview.net/forum?id=ryxmb1rKDS}
}

@article{Tong2021,
	title = {Symplectic neural networks in Taylor series form for Hamiltonian systems},
	journal = {Journal of Computational Physics},
	volume = {437},
	pages = {110325},
	year = {2021},
	issn = {0021-9991},
	doi = {https://doi.org/10.1016/j.jcp.2021.110325},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999121002205},
	author = {Yunjin Tong and Shiying Xiong and Xingzhe He and Guanghan Pan and Bo Zhu},
	keywords = {Machine learning, Hamiltonian system, Physics-informed neural network, Taylor series expansion}
}

@article{Medianu2021,
	title = {Structural identifiability of linear Port Hamiltonian systems},
	journal = {Systems {\&} Control Letters},
	volume = {151},
	pages = {104915},
	year = {2021},
	issn = {0167-6911},
	doi = {https://doi.org/10.1016/j.sysconle.2021.104915},
	url = {https://www.sciencedirect.com/science/article/pii/S0167691121000451},
	author = {Silviu Medianu and Laurent Lefèvre}
}

@article{celledoni2023learning,
  title={Learning Hamiltonians of constrained mechanical systems},
  author={Celledoni, Elena and Leone, Andrea and Murari, Davide and Owren, Brynjulf},
  journal={Journal of Computational and Applied Mathematics},
  volume={417},
  pages={114608},
  year={2023},
  publisher={Elsevier}
}

@book{de2006symplectic,
  title={Symplectic geometry and quantum mechanics},
  author={De Gosson, Maurice A},
  volume={166},
  year={2006},
  publisher={Springer Science \& Business Media}
}

@book{mackenzie2005general,
author = {Mackenzie, Kirill C H},
number = {213},
publisher = {Cambridge University Press},
title = {{General theory of Lie groupoids and Lie algebroids}},
year = {2005}
}

@article{maschke1992,
	title = {Port-Controlled Hamiltonian Systems: Modelling Origins and Systemtheoretic Properties},
	journal = {IFAC Proceedings Volumes},
	volume = {25},
	number = {13},
	pages = {359-365},
	year = {1992},
	note = {2nd IFAC Symposium on Nonlinear Control Systems Design 1992, Bordeaux, France, 24-26 June},
	issn = {1474-6670},
	doi = {https://doi.org/10.1016/S1474-6670(17)52308-3},
	url = {https://www.sciencedirect.com/science/article/pii/S1474667017523083},
	author = {B.M. Maschke and A.J. {van der Schaft}},
	keywords = {Network dynamics, general Poisson structures, gyrators, Hamiltonian equations, observation space, minimal realizations},
	abstract = {It is shown that the network representation (as obtained through the generalized bond graph formalism) of non-resistive physical systems in interaction with their environment leads to a well- defined class of (nonlinear) control systems, called port-controlled Hamiltonian systems. A first basic feature of these systems is that their internal dynamics is Hamiltonian with respect to a Poisson structure determined by the topology of the network and to a Hamiltonian given by the stored energy. Secondly the network representation provides automatically (intrinsically to the notation) to every port-control variable (input) a port-conjugated variable as output. This definition of port-conjugated input and output variables, based on energy considerations, is shown to have important consequences for the observability and controllability properties, as well as the external characterization of port- controlled Hamiltonian systems.}
}

@article{Brockett1972,
	title = {Lie algebras and linear differential equations},
	editor = {Leonard Weiss},
	booktitle = {Ordinary Differential Equations},
	publisher = {Academic Press},
	pages = {379-386},
	year = {1972},
	isbn = {978-0-12-743650-0},
	doi = {https://doi.org/10.1016/B978-0-12-743650-0.50036-8},
	url = {https://www.sciencedirect.com/science/article/pii/B9780127436500500368},
	author = {Roger W. Brockett and Abdolhossein Rahimi},
	abstract = {Publisher Summary
	This chapter discusses certain symmetry properties possessed by the solutions of linear differential equations. The two results are established on the Lie algebra generated by a pair ofn by nmatrices. In order to avoid undue repetition, one agrees to call a matrix of rational functionsG(s) regular if it is square and approaches zero as|s| approached infinity. It is possible to associate a Lie algebra with each regular matrix of rational functions in a natural way. The symplectic matrices form a group and the Eigen values of symplectic matrices occur in reciprocal pairs. That is to say, if λ is an eigenvalue of a symplectic matrix. then so is 1/λ. This observation together with the basic ideas of Floquet theory enables one to show that for 0 ≤ t < ∞ all solutions are bounded for ɛ sufficiently small provided A(t) and B(t) are Hamiltonian and the solution of the equationhas distinctcharacteristicmultipliers all lying on the unitcircle.}
}

@inproceedings{Crouch1987,
	title={Variational and Hamiltonian Control Systems},
	author={Peter E. Crouch and Arjan van der Schaft},
	year={1987}
}

@article{kalman1963,
	author = {Kalman, R. E.},
	title = {Mathematical Description of Linear Dynamical Systems},
	journal = {Journal of the Society for Industrial and Applied Mathematics Series A Control},
	volume = {1},
	number = {2},
	pages = {152-192},
	year = {1963},
	doi = {10.1137/0301010},
	
	URL = { 
	
	https://doi.org/10.1137/0301010
	
	
	
	},
	eprint = { 
	
	https://doi.org/10.1137/0301010
	
	
	
	}
	,
	abstract = { There are two different ways of describing uynamicu systems: (i) bymeans of state variables and (ii) by input/output relations. The first method may be regarded as an axiornatization of Newton’s laws of mechanics and is taken to be the basic definition of a system.It is then shown (in the linear case) that the input/output relations determine only one part of a system, that which is completely observable and completely controllable. Using the theory of controllability and observability, methods are given for calculating irreducible realization of a given impulse-response matrix. In particular, an explicit procedure is given to determine the minimal number of state variables necessary to realize a given transfer-function matrix. Difficulties arising from the use of reducible realizations are discussed briefly. }
}

@article{lazaro2008stochastic,
  title={Stochastic Hamiltonian dynamical systems},
  author={L{\'a}zaro-Cam{\'\i}, Joan-Andreu and Ortega, Juan-Pablo},
  journal={Reports on Mathematical Physics},
  volume={61},
  number={1},
  pages={65--122},
  year={2008},
  publisher={Elsevier}
}

@book{bismut1982mecanique,
  title={M{\'e}canique al{\'e}atoire},
  author={Bismut, Jean-Michel},
  year={1982},
  publisher={Springer}
}

@inproceedings{beckers2022gaussian,
author = {Beckers, Thomas and Seidman, Jacob and Perdikaris, Paris and Pappas, George J},
booktitle = {2022 IEEE 61st Conference on Decision and Control (CDC)},
organization = {IEEE},
pages = {1447--1453},
title = {{Gaussian process port-Hamiltonian systems: Bayesian learning with physics prior}},
year = {2022}
}

@article{desai2021port,
author = {Desai, Shaan A and Mattheakis, Marios and Sondak, David and Protopapas, Pavlos and Roberts, Stephen J},
journal = {Physical Review E},
number = {3},
pages = {34312},
publisher = {APS},
title = {{Port-Hamiltonian neural networks for learning explicit time-dependent dynamical systems}},
volume = {104},
year = {2021}
}

@article{nageshrao2015adaptive,
author = {Nageshrao, S P and Lopes, G A D and Jeltsema, D and Babuska, R},
journal = {IEEE Transactions on Automatic Control},
pages = {37},
title = {{Adaptive and learning control of port-Hamiltonian systems: a survey}},
year = {2015}
}

@article{cherifi2020overview,
author = {Cherifi, Karim},
journal = {Physica D: Nonlinear Phenomena},
pages = {132620},
publisher = {Elsevier},
title = {{An overview on recent machine learning techniques for Port Hamiltonian systems}},
volume = {411},
year = {2020}
}
