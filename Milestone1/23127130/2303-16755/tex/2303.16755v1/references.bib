@article{christiano2017deep,
  title={{Deep reinforcement learning from human preferences}},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017},
  url="https://arxiv.org/pdf/1706.03741.pdf"
}

@inproceedings{qi2020stanza,
    title={{Stanza: A {Python} Natural Language Processing Toolkit for Many Human Languages}},
    author={Qi, Peng and Zhang, Yuhao and Zhang, Yuhui and Bolton, Jason and Manning, Christopher D.},
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations",
    year={2020}
}

@article{perez2022red,
  title={{Red Teaming Language Models with Language Models}},
  author={Perez, Ethan and Huang, Saffron and Song, Francis and Cai, Trevor and Ring, Roman and Aslanides, John and Glaese, Amelia and McAleease, Nat and Irving, Geoffrey},
  journal={arXiv preprint arXiv:2202.03286},
  year={2022}
}

@article{leike2018scalable,
  title={Scalable agent alignment via reward modeling: a research direction},
  author={Leike, Jan and Krueger, David and Everitt, Tom and Martic, Miljan and Maini, Vishal and Legg, Shane},
  journal={arXiv preprint arXiv:1811.07871},
  year={2018}
}

@article{stiennon2020learning,
  title={Learning to summarize with human feedback},
  author={Stiennon, Nisan and Ouyang, Long and Wu, Jeffrey and Ziegler, Daniel and Lowe, Ryan and Voss, Chelsea and Radford, Alec and Amodei, Dario and Christiano, Paul F},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={3008--3021},
  year={2020},
  url="https://arxiv.org/pdf/2009.01325.pdf"
}

@article{ziegler2019fine,
  title={Fine-tuning language models from human preferences},
  author={Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
  journal={arXiv preprint arXiv:1909.08593},
  year={2019},
  url="https://arxiv.org/pdf/1909.08593.pdf"
}

@article{nakano2021webgpt,
  title={{WebGPT: Browser-assisted question-answering with human feedback}},
  author={Nakano, Reiichiro and Hilton, Jacob and Balaji, Suchir and Wu, Jeff and Ouyang, Long and Kim, Christina and Hesse, Christopher and Jain, Shantanu and Kosaraju, Vineet and Saunders, William and others},
  journal={arXiv preprint arXiv:2112.09332},
  year={2021},
  url="https://arxiv.org/pdf/2112.09332.pdf"
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Preprint},
  year={2022},
  url="https://cdn.openai.com/papers/Training_language_models_to_follow_instructions_with_human_feedback.pdf"
}


@article{elhage2021mathematical,
   title={{A Mathematical Framework for Transformer Circuits}},
   author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Bai, Yuntao and Chen, Anna and Conerly, Tom and DasSarma, Nova and Drain, Dawn and Ganguli, Deep and Hatfield-Dodds, Zac and Hernandez, Danny and Jones, Andy and Kernion, Jackson and Lovitt, Liane and Ndousse, Kamal and Amodei, Dario and Brown, Tom and Clark, Jack and Kaplan, Jared and McCandlish, Sam and Olah, Chris},
   year={2021},
   journal={Transformer Circuits Thread},
   note={https://transformer-circuits.pub/2021/framework/index.html}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  url="https://arxiv.org/pdf/2005.14165.pdf",
  pages={1877--1901},
  year={2020}
}

@inproceedings{bender2021dangers,
  title={{On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?��}},
  author={Bender, Emily M and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
  booktitle={Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
  pages={610--623},
  year={2021}
}

@article{bommasani2021opportunities,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}

@article{kenton2021alignment,
  title={Alignment of language agents},
  author={Kenton, Zachary and Everitt, Tom and Weidinger, Laura and Gabriel, Iason and Mikulik, Vladimir and Irving, Geoffrey},
  journal={arXiv preprint arXiv:2103.14659},
  year={2021}
}

@article{weidinger2021ethical,
  title={Ethical and social risks of harm from Language Models},
  author={Weidinger, Laura and Mellor, John and Rauh, Maribeth and Griffin, Conor and Uesato, Jonathan and Huang, Po-Sen and Cheng, Myra and Glaese, Mia and Balle, Borja and Kasirzadeh, Atoosa and others},
  journal={arXiv preprint arXiv:2112.04359},
  year={2021}
}

@article{tamkin2021understanding,
  title={Understanding the capabilities, limitations, and societal impact of large language models},
  author={Tamkin, Alex and Brundage, Miles and Clark, Jack and Ganguli, Deep},
  journal={arXiv preprint arXiv:2102.02503},
  year={2021}
}

@article{gehman2020realtoxicityprompts,
  title={{Realtoxicityprompts: Evaluating neural toxic degeneration in language models}},
  author={Gehman, Samuel and Gururangan, Suchin and Sap, Maarten and Choi, Yejin and Smith, Noah A},
  journal={arXiv preprint arXiv:2009.11462},
  year={2020},
  url="https://aclanthology.org/2020.findings-emnlp.301.pdf"
}

@article{maynez2020faithfulness,
  title={On faithfulness and factuality in abstractive summarization},
  author={Maynez, Joshua and Narayan, Shashi and Bohnet, Bernd and McDonald, Ryan},
  journal={arXiv preprint arXiv:2005.00661},
  year={2020}
}
@article{schmidt2019generalization,
  title={Generalization in generation: A closer look at exposure bias},
  author={Schmidt, Florian},
  journal={arXiv preprint arXiv:1910.00292},
  year={2019}
}

@inproceedings{ross2011reduction,
  title={A reduction of imitation learning and structured prediction to no-regret online learning},
  author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={627--635},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{askell2021general,
  title={{A General Language Assistant as a Laboratory for Alignment}},
  author={Askell, Amanda and Bai, Yuntao and Chen, Anna and Drain, Dawn and Ganguli, Deep and Henighan, Tom and Jones, Andy and Joseph, Nicholas and Mann, Ben and DasSarma, Nova and others},
  journal={arXiv preprint arXiv:2112.00861},
  year={2021}
}

@inproceedings{paranjape-etal-2021-prompting,
    title = "Prompting Contrastive Explanations for Commonsense Reasoning Tasks",
    author = "Paranjape, Bhargavi  and
      Michael, Julian  and
      Ghazvininejad, Marjan  and
      Hajishirzi, Hannaneh  and
      Zettlemoyer, Luke",
    booktitle = "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-acl.366",
    doi = "10.18653/v1/2021.findings-acl.366",
    pages = "4179--4192",
}

@article{latcinnik2020explaining,
  title={Explaining question answering models through text generation},
  author={Latcinnik, Veronica and Berant, Jonathan},
  journal={arXiv preprint arXiv:2004.05569},
  year={2020}
}

@inproceedings{shwartz-etal-2020-unsupervised,
    title = "Unsupervised Commonsense Question Answering with Self-Talk",
    author = "Shwartz, Vered  and
      West, Peter  and
      Le Bras, Ronan  and
      Bhagavatula, Chandra  and
      Choi, Yejin",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.373",
    doi = "10.18653/v1/2020.emnlp-main.373",
    pages = "4615--4629",
    abstract = "Natural language understanding involves reading between the lines with implicit background knowledge. Current systems either rely on pre-trained language models as the sole implicit source of world knowledge, or resort to external knowledge bases (KBs) to incorporate additional relevant knowledge. We propose an unsupervised framework based on self-talk as a novel alternative to multiple-choice commonsense tasks. Inspired by inquiry-based discovery learning (Bruner, 1961), our approach inquires language models with a number of information seeking questions such as {``}what is the definition of...{''} to discover additional background knowledge. Empirical results demonstrate that the self-talk procedure substantially improves the performance of zero-shot language model baselines on four out of six commonsense benchmarks, and competes with models that obtain knowledge from external KBs. While our approach improves performance on several benchmarks, the self-talk induced knowledge even when leading to correct answers is not always seen as helpful by human judges, raising interesting questions about the inner-workings of pre-trained language models for commonsense reasoning.",
}

@inproceedings{rajani-etal-2019-explain,
    title = "Explain Yourself! Leveraging Language Models for Commonsense Reasoning",
    author = "Rajani, Nazneen Fatema  and
      McCann, Bryan  and
      Xiong, Caiming  and
      Socher, Richard",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1487",
    doi = "10.18653/v1/P19-1487",
    pages = "4932--4942",
    abstract = "Deep learning models perform poorly on tasks that require commonsense reasoning, which often necessitates some form of world-knowledge or reasoning over information not immediately present in the input. We collect human explanations for commonsense reasoning in the form of natural language sequences and highlighted annotations in a new dataset called Common Sense Explanations (CoS-E). We use CoS-E to train language models to automatically generate explanations that can be used during training and inference in a novel Commonsense Auto-Generated Explanation (CAGE) framework. CAGE improves the state-of-the-art by 10{\%} on the challenging CommonsenseQA task. We further study commonsense reasoning in DNNs using both human and auto-generated explanations including transfer to out-of-domain tasks. Empirical results indicate that we can effectively leverage language models for commonsense reasoning.",
}

@article{camburu2018snli,
  title={e-snli: Natural language inference with natural language explanations},
  author={Camburu, Oana-Maria and Rockt{\"a}schel, Tim and Lukasiewicz, Thomas and Blunsom, Phil},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018},
  url="https://arxiv.org/pdf/1812.01193.pdf"
}

@inproceedings{kumar-talukdar-2020-nile,
    title = "{NILE} : Natural Language Inference with Faithful Natural Language Explanations",
    author = "Kumar, Sawan  and
      Talukdar, Partha",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.771",
    doi = "10.18653/v1/2020.acl-main.771",
    pages = "8730--8742",
    abstract = "The recent growth in the popularity and success of deep learning models on NLP classification tasks has accompanied the need for generating some form of natural language explanation of the predicted labels. Such generated natural language (NL) explanations are expected to be faithful, i.e., they should correlate well with the model{'}s internal decision making. In this work, we focus on the task of natural language inference (NLI) and address the following question: can we build NLI systems which produce labels with high accuracy, while also generating faithful explanations of its decisions? We propose Natural-language Inference over Label-specific Explanations (NILE), a novel NLI method which utilizes auto-generated label-specific NL explanations to produce labels along with its faithful explanation. We demonstrate NILE{'}s effectiveness over previously reported methods through automated and human evaluation of the produced labels and explanations. Our evaluation of NILE also supports the claim that accurate systems capable of providing testable explanations of their decisions can be designed. We discuss the faithfulness of NILE{'}s explanations in terms of sensitivity of the decisions to the corresponding explanations. We argue that explicit evaluation of faithfulness, in addition to label and explanation accuracy, is an important step in evaluating model{'}s explanations. Further, we demonstrate that task-specific probes are necessary to establish such sensitivity.",
}
@inproceedings{zhao2021lirex,
  title={{LIREx: Augmenting Language Inference with Relevant Explanations}},
  author={Zhao, Xinyan and Vydiswaran, VG Vinod},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  pages={14532--14539},
  year={2021}
}
@article{hase2021can,
  title={When can models learn from explanations? a formal framework for understanding the roles of explanation data},
  author={Hase, Peter and Bansal, Mohit},
  journal={arXiv preprint arXiv:2102.02201},
  year={2021},
  url="https://arxiv.org/pdf/2102.02201.pdf"
}

@article{stacey2021natural,
  title={{Supervising Model Attention with Human Explanations for Robust Natural Language Inference}},
  author={Stacey, Joe and Belinkov, Yonatan and Rei, Marek},
  journal={arXiv preprint arXiv:2104.08142},
  year={2021},
  url="https://arxiv.org/pdf/2104.08142.pdf"
}

@misc{pruthi2021evaluating,
      title={{Evaluating Explanations: How much do explanations from the teacher aid students?}}, 
      author={Danish Pruthi and Rachit Bansal and Bhuwan Dhingra and Livio Baldini Soares and Michael Collins and Zachary C. Lipton and Graham Neubig and William W. Cohen},
      year={2021},
      eprint={2012.00893},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{narang2020wt5,
      title={{WT5?! Training Text-to-Text Models to Explain their Predictions}}, 
      author={Sharan Narang and Colin Raffel and Katherine Lee and Adam Roberts and Noah Fiedel and Karishma Malkan},
      year={2020},
      eprint={2004.14546},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{lin2021truthfulqa,
      title={{TruthfulQA: Measuring How Models Mimic Human Falsehoods}}, 
      author={Stephanie Lin and Jacob Hilton and Owain Evans},
      year={2021},
      eprint={2109.07958},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{
mahmoudieh2022zeroshot,
title={{Zero-Shot Reward Specification via Grounded Natural Language}},
author={Parsa Mahmoudieh and Sayna Ebrahimi and Deepak Pathak and Trevor Darrell},
year={2022},
url={https://openreview.net/forum?id=zRb7IWkTZAU}
}

@misc{goyal2019using,
      title={{Using Natural Language for Reward Shaping in Reinforcement Learning}}, 
      author={Prasoon Goyal and Scott Niekum and Raymond J. Mooney},
      year={2019},
      eprint={1903.02020},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{kaplan2017beating,
      title={{Beating Atari with Natural Language Guided Reinforcement Learning}}, 
      author={Russell Kaplan and Christopher Sauer and Alexander Sosa},
      year={2017},
      eprint={1704.05539},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{andreas2017learning,
      title={{Learning with Latent Language}}, 
      author={Jacob Andreas and Dan Klein and Sergey Levine},
      year={2017},
      eprint={1711.00482},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{henighan2020scaling,
      title={{Scaling Laws for Autoregressive Generative Modeling}}, 
      author={Tom Henighan and Jared Kaplan and Mor Katz and Mark Chen and Christopher Hesse and Jacob Jackson and Heewoo Jun and Tom B. Brown and Prafulla Dhariwal and Scott Gray and Chris Hallacy and Benjamin Mann and Alec Radford and Aditya Ramesh and Nick Ryder and Daniel M. Ziegler and John Schulman and Dario Amodei and Sam McCandlish},
      year={2020},
      eprint={2010.14701},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{kaplan2020scaling,
      title={{Scaling Laws for Neural Language Models}}, 
      author={Jared Kaplan and Sam McCandlish and Tom Henighan and Tom B. Brown and Benjamin Chess and Rewon Child and Scott Gray and Alec Radford and Jeffrey Wu and Dario Amodei},
      year={2020},
      eprint={2001.08361},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@misc{neelakantan2022text,
      title={{Text and Code Embeddings by Contrastive Pre-Training}}, 
      author={Arvind Neelakantan and Tao Xu and Raul Puri and Alec Radford and Jesse Michael Han and Jerry Tworek and Qiming Yuan and Nikolas Tezak and Jong Wook Kim and Chris Hallacy and Johannes Heidecke and Pranav Shyam and Boris Power and Tyna Eloundou Nekoul and Girish Sastry and Gretchen Krueger and David Schnurr and Felipe Petroski Such and Kenny Hsu and Madeleine Thompson and Tabarak Khan and Toki Sherbakov and Joanne Jang and Peter Welinder and Lilian Weng},
      year={2022},
      eprint={2201.10005},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{lin-2004-rouge,
    title = "{ROUGE}: A Package for Automatic Evaluation of Summaries",
    author = "Lin, Chin-Yew",
    booktitle = "Text Summarization Branches Out",
    month = jul,
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W04-1013",
    pages = "74--81",
}
@misc{raffel2020exploring,
      title={{Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer}}, 
      author={Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
      year={2020},
      eprint={1910.10683},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{Radford2019LanguageMA,
  title={{Language Models are Unsupervised Multitask Learners}},
  author={Alec Radford and Jeff Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever},
  year={2019},
  url="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf"
}

@misc{Radford2018ImprovingLU,
  title={{Improving Language Understanding by Generative Pre-Training}},
  url={https://openai-assets.s3.amazonaws.com/research-covers/language-unsupervised/language_understanding_paper.pdf},
  author={Alec Radford and Karthik Narasimhan},
  year={2018}
}

@article{ganguli2022predictability,
  title={{Predictability and Surprise in Large Generative Models}},
  author={Ganguli, Deep and Hernandez, Danny and Lovitt, Liane and DasSarma, Nova and Henighan, Tom and Jones, Andy and Joseph, Nicholas and Kernion, Jackson and Mann, Ben and Askell, Amanda and others},
  journal={arXiv preprint arXiv:2202.07785},
  year={2022}
}

@misc{gao2022scaling,
  doi = {10.48550/ARXIV.2210.10760},
  
  url = {https://arxiv.org/abs/2210.10760},
  
  author = {Gao, Leo and Schulman, John and Hilton, Jacob},
  
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Scaling Laws for Reward Model Overoptimization},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@inproceedings{paulus2018deep,
    title={{A Deep Reinforced Model for Abstractive Summarization}},
    author={Romain Paulus and Caiming Xiong and Richard Socher},
    booktitle={International Conference on Learning Representations},
    year={2018},
    url={https://openreview.net/forum?id=HkAClQgA-},
}

@inproceedings{wei2022finetuned,
title={{Finetuned Language Models are Zero-Shot Learners}},
author={Jason Wei and Maarten Bosma and Vincent Zhao and Kelvin Guu and Adams Wei Yu and Brian Lester and Nan Du and Andrew M. Dai and Quoc V Le},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=gEZrGCozdqR}
}

@misc{bach2022promptsource,
      title={{PromptSource: An Integrated Development Environment and Repository for Natural Language Prompts}},
      author={Stephen H. Bach and Victor Sanh and Zheng-Xin Yong and Albert Webson and Colin Raffel and Nihal V. Nayak and Abheesht Sharma and Taewoon Kim and M Saiful Bari and Thibault Fevry and Zaid Alyafeai and Manan Dey and Andrea Santilli and Zhiqing Sun and Srulik Ben-David and Canwen Xu and Gunjan Chhablani and Han Wang and Jason Alan Fries and Maged S. Al-shaibani and Shanya Sharma and Urmish Thakker and Khalid Almubarak and Xiangru Tang and Xiangru Tang and Mike Tian-Jian Jiang and Alexander M. Rush},
      year={2022},
      eprint={2202.01279},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{rae2021scaling,
  title={Scaling language models: Methods, analysis \& insights from training gopher},
  author={Rae, Jack W and Borgeaud, Sebastian and Cai, Trevor and Millican, Katie and Hoffmann, Jordan and Song, Francis and Aslanides, John and Henderson, Sarah and Ring, Roman and Young, Susannah and others},
  journal={arXiv preprint arXiv:2112.11446},
  year={2021},
  url="https://arxiv.org/pdf/2112.11446.pdf"
}

@inproceedings{volske-etal-2017-tl,
    title = "{TL};{DR}: Mining {R}eddit to Learn Automatic Summarization",
    author = {V{\"o}lske, Michael  and
      Potthast, Martin  and
      Syed, Shahbaz  and
      Stein, Benno},
    booktitle = "Proceedings of the Workshop on New Frontiers in Summarization",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W17-4508",
    doi = "10.18653/v1/W17-4508",
    pages = "59--63",
    abstract = "Recent advances in automatic text summarization have used deep neural networks to generate high-quality abstractive summaries, but the performance of these models strongly depends on large amounts of suitable training data. We propose a new method for mining social media for author-provided summaries, taking advantage of the common practice of appending a {``}TL;DR{''} to long posts. A case study using a large Reddit crawl yields the Webis-TLDR-17 dataset, complementing existing corpora primarily from the news genre. Our technique is likely applicable to other social media sites and general web crawls.",
}


@InProceedings{andreas2017modular,
  title = 	 {Modular Multitask Reinforcement Learning with Policy Sketches},
  author =       {Jacob Andreas and Dan Klein and Sergey Levine},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {166--175},
  year = 	 {2017},
  editor = 	 {Precup, Doina and Teh, Yee Whye},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/andreas17a/andreas17a.pdf},
  url = 	 {https://proceedings.mlr.press/v70/andreas17a.html},
  abstract = 	 {We describe a framework for multitask deep reinforcement learning guided by policy sketches. Sketches annotate tasks with sequences of named subtasks, providing information about high-level structural relationships among tasks but not how to implement them—specifically not providing the detailed guidance used by much previous work on learning policy abstractions for RL (e.g. intermediate rewards, subtask completion signals, or intrinsic motivations). To learn from sketches, we present a model that associates every subtask with a modular subpolicy, and jointly maximizes reward over full task-specific policies by tying parameters across shared subpolicies. Optimization is accomplished via a decoupled actor–critic training objective that facilitates learning common behaviors from multiple dissimilar reward functions. We evaluate the effectiveness of our approach in three environments featuring both discrete and continuous control, and with sparse rewards that can be obtained only after completing a number of high-level subgoals. Experiments show that using our approach to learn policies guided by sketches gives better performance than existing techniques for learning task-specific or shared policies, while naturally inducing a library of interpretable primitive behaviors that can be recombined to rapidly adapt to new tasks.}
}


@inproceedings{wiegreffe-etal-2021-measuring,
    title = "{M}easuring Association Between Labels and Free-Text Rationales",
    author = "Wiegreffe, Sarah  and
      Marasovi{\'c}, Ana  and
      Smith, Noah A.",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.804",
    doi = "10.18653/v1/2021.emnlp-main.804",
    pages = "10266--10284",
    abstract = "In interpretable NLP, we require faithful rationales that reflect the model{'}s decision-making process for an explained instance. While prior work focuses on extractive rationales (a subset of the input words), we investigate their less-studied counterpart: free-text natural language rationales. We demonstrate that *pipelines*, models for faithful rationalization on information-extraction style tasks, do not work as well on {``}reasoning{''} tasks requiring free-text rationales. We turn to models that *jointly* predict and rationalize, a class of widely used high-performance models for free-text rationalization. We investigate the extent to which the labels and rationales predicted by these models are associated, a necessary property of faithful explanation. Via two tests, *robustness equivalence* and *feature importance agreement*, we find that state-of-the-art T5-based joint models exhibit desirable properties for explaining commonsense question-answering and natural language inference, indicating their potential for producing faithful free-text rationales.",
}

@inproceedings{wiegreffe2021teach,
title={{Teach Me to Explain: A Review of Datasets for Explainable Natural Language Processing}},
author={Sarah Wiegreffe and Ana Marasovic},
booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 1)},
year={2021},
url={https://openreview.net/forum?id=ogNcxJn32BZ}
}

@inproceedings{luketina2019survey,
  title     = {A Survey of Reinforcement Learning Informed by Natural Language},
  author    = {Luketina, Jelena and Nardelli, Nantas and Farquhar, Gregory and Foerster, Jakob and Andreas, Jacob and Grefenstette, Edward and Whiteson, Shimon and Rocktäschel, Tim},
  booktitle = {Proceedings of the Twenty-Eighth International Joint Conference on
               Artificial Intelligence, {IJCAI-19}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},             
  pages     = {6309--6317},
  year      = {2019},
  month     = {7},
  doi       = {10.24963/ijcai.2019/880},
  url       = {https://doi.org/10.24963/ijcai.2019/880},
}

@article{chaplot2017gated,
  title={{Gated-Attention Architectures for Task-Oriented Language Grounding}},
  author={Chaplot, Devendra Singh and Sathyendra, Kanthashree Mysore and Pasumarthi, Rama Kumar and Rajagopal, Dheeraj and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:1706.07230},
  year={2017},
  url="https://arxiv.org/pdf/1706.07230.pdf"
}

@article{holtzman2019curious,
  title={The curious case of neural text degeneration},
  author={Holtzman, Ari and Buys, Jan and Du, Li and Forbes, Maxwell and Choi, Yejin},
  journal={arXiv preprint arXiv:1904.09751},
  year={2019},
  url="https://arxiv.org/pdf/1904.09751.pdf"
}

@article{sanh2021multitask,
  title={Multitask prompted training enables zero-shot task generalization},
  author={Sanh, Victor and Webson, Albert and Raffel, Colin and Bach, Stephen H and Sutawika, Lintang and Alyafeai, Zaid and Chaffin, Antoine and Stiegler, Arnaud and Scao, Teven Le and Raja, Arun and others},
  journal={arXiv preprint arXiv:2110.08207},
  year={2021}
}

@article{lampinen2022can,
  title={Can language models learn from explanations in context?},
  author={Lampinen, Andrew K and Dasgupta, Ishita and Chan, Stephanie CY and Matthewson, Kory and Tessler, Michael Henry and Creswell, Antonia and McClelland, James L and Wang, Jane X and Hill, Felix},
  journal={arXiv preprint arXiv:2204.02329},
  year={2022}
}

@article{tam2022semantic,
  title={Semantic Exploration from Language Abstractions and Pretrained Representations},
  author={Tam, Allison C and Rabinowitz, Neil C and Lampinen, Andrew K and Roy, Nicholas A and Chan, Stephanie CY and Strouse, DJ and Wang, Jane X and Banino, Andrea and Hill, Felix},
  journal={arXiv preprint arXiv:2204.05080},
  year={2022}
}

@inproceedings{rupprecht2018guide,
  title={Guide me: Interacting with deep networks},
  author={Rupprecht, Christian and Laina, Iro and Navab, Nassir and Hager, Gregory D and Tombari, Federico},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={8551--8561},
  year={2018}
}

@article{tian2022image,
  title={Image Search with Text Feedback by Additive Attention Compositional Learning},
  author={Tian, Yuxin and Newsam, Shawn and Boakye, Kofi},
  journal={arXiv preprint arXiv:2203.03809},
  year={2022}
}

@article{lin2022inferring,
  title={Inferring Rewards from Language in Context},
  author={Lin, Jessy and Fried, Daniel and Klein, Dan and Dragan, Anca},
  journal={arXiv preprint arXiv:2204.02515},
  year={2022}
}

@article{austin2021program,
  author    = {Jacob Austin and
               Augustus Odena and
               Maxwell I. Nye and
               Maarten Bosma and
               Henryk Michalewski and
               David Dohan and
               Ellen Jiang and
               Carrie J. Cai and
               Michael Terry and
               Quoc V. Le and
               Charles Sutton},
  title     = {Program Synthesis with Large Language Models},
  journal   = {CoRR},
  volume    = {abs/2108.07732},
  year      = {2021},
  url       = {https://arxiv.org/abs/2108.07732},
  eprinttype = {arXiv},
  eprint    = {2108.07732},
  timestamp = {Fri, 29 Apr 2022 17:42:58 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2108-07732.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{ramesh2022hierarchical,
  doi = {10.48550/ARXIV.2204.06125},
  
  url = {https://arxiv.org/abs/2204.06125},
  
  author = {Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Hierarchical Text-Conditional Image Generation with CLIP Latents},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@misc{sharma2022correcting,
  doi = {10.48550/ARXIV.2204.05186},
  
  url = {https://arxiv.org/abs/2204.05186},
  
  author = {Sharma, Pratyusha and Sundaralingam, Balakumar and Blukis, Valts and Paxton, Chris and Hermans, Tucker and Torralba, Antonio and Andreas, Jacob and Fox, Dieter},
  
  keywords = {Robotics (cs.RO), Artificial Intelligence (cs.AI), Computation and Language (cs.CL), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Correcting Robot Plans with Natural Language Feedback},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@inproceedings{guo2018dialog,
 author = {Guo, Xiaoxiao and Wu, Hui and Cheng, Yu and Rennie, Steven and Tesauro, Gerald and Feris, Rogerio},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Dialog-based Interactive Image Retrieval},
 url = {https://proceedings.neurips.cc/paper/2018/file/a01a0380ca3c61428c26a231f0e49a09-Paper.pdf},
 volume = {31},
 year = {2018}
}

@inproceedings{elgohary-etal-2020-speak,
    title = "Speak to your Parser: Interactive Text-to-{SQL} with Natural Language Feedback",
    author = "Elgohary, Ahmed  and
      Hosseini, Saghar  and
      Hassan Awadallah, Ahmed",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.187",
    doi = "10.18653/v1/2020.acl-main.187",
    pages = "2065--2077",
    abstract = "We study the task of semantic parse correction with natural language feedback. Given a natural language utterance, most semantic parsing systems pose the problem as one-shot translation where the utterance is mapped to a corresponding logical form. In this paper, we investigate a more interactive scenario where humans can further interact with the system by providing free-form natural language feedback to correct the system when it generates an inaccurate interpretation of an initial utterance. We focus on natural language to SQL systems and construct, SPLASH, a dataset of utterances, incorrect SQL interpretations and the corresponding natural language feedback. We compare various reference models for the correction task and show that incorporating such a rich form of feedback can significantly improve the overall semantic parsing accuracy while retaining the flexibility of natural language interaction. While we estimated human correction accuracy is 81.5{\%}, our best model achieves only 25.1{\%}, which leaves a large gap for improvement in future research. SPLASH is publicly available at https://aka.ms/Splash{\_}dataset.",
}

@article{li2016dialogue,
  title={Dialogue learning with human-in-the-loop},
  author={Li, Jiwei and Miller, Alexander H and Chopra, Sumit and Ranzato, Marc'Aurelio and Weston, Jason},
  journal={arXiv preprint arXiv:1611.09823},
  year={2016}
}

@article{weston2016dialog,
  title={Dialog-based language learning},
  author={Weston, Jason E},
  journal={Advances in Neural Information Processing Systems},
  volume={29},
  year={2016}
}

@article{matiana2021cut,
  title={Cut the CARP: Fishing for zero-shot story evaluation},
  author={Matiana, Shahbuland and Smith, JR and Teehan, Ryan and Castricato, Louis and Biderman, Stella and Gao, Leo and Frazier, Spencer},
  journal={arXiv preprint arXiv:2110.03111},
  year={2021}
}




@article{hancock2019learning,
  title={Learning from dialogue after deployment: Feed yourself, chatbot!},
  author={Hancock, Braden and Bordes, Antoine and Mazare, Pierre-Emmanuel and Weston, Jason},
  journal={arXiv preprint arXiv:1901.05415},
  year={2019}
}

@inproceedings{nguyen2021interactive,
  title={Interactive learning from activity description},
  author={Nguyen, Khanh X and Misra, Dipendra and Schapire, Robert and Dud{\'\i}k, Miroslav and Shafto, Patrick},
  booktitle={International Conference on Machine Learning},
  pages={8096--8108},
  year={2021},
  organization={PMLR}
}

@article{li2022using,
  title={Using Interactive Feedback to Improve the Accuracy and Explainability of Question Answering Systems Post-Deployment},
  author={Li, Zichao and Sharma, Prakhar and Lu, Xing Han and Cheung, Jackie CK and Reddy, Siva},
  journal={arXiv preprint arXiv:2204.03025},
  year={2022}
}

@article{fidler2017teaching,
  title={Teaching machines to describe images with natural language feedback},
  author={Fidler, Sanja and others},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}
@article{sumers2021learning,
  title={Learning rewards from linguistic feedback},
  author={Sumers, Theodore R and Ho, Mark K and Hawkins, Robert D and Narasimhan, Karthik and Griffiths, Thomas L},
  journal={feedback},
  volume={1},
  number={2},
  pages={3},
  year={2021}
}

@article{korbak2022rl,
  title={RL with KL penalties is better viewed as Bayesian inference},
  author={Korbak, Tomasz and Perez, Ethan and Buckley, Christopher L},
  journal={arXiv preprint arXiv:2205.11275},
  year={2022}
}
@article{levine2018reinforcement,
  title={Reinforcement learning and control as probabilistic inference: Tutorial and review},
  author={Levine, Sergey},
  journal={arXiv preprint arXiv:1805.00909},
  year={2018}
}
@article{abdolmaleki2018maximum,
  title={Maximum a posteriori policy optimisation},
  author={Abdolmaleki, Abbas and Springenberg, Jost Tobias and Tassa, Yuval and Munos, Remi and Heess, Nicolas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1806.06920},
  year={2018}
}

@inproceedings{hoffman2015stochastic,
  title={Stochastic structured variational inference},
  author={Hoffman, Matthew and Blei, David},
  booktitle={Artificial Intelligence and Statistics},
  pages={361--369},
  year={2015},
  organization={PMLR}
}

@article{hermann2015teaching,
  title={Teaching machines to read and comprehend},
  author={Hermann, Karl Moritz and Kocisky, Tomas and Grefenstette, Edward and Espeholt, Lasse and Kay, Will and Suleyman, Mustafa and Blunsom, Phil},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}


@inproceedings{scheurer2022training,
  title={Training language models with language feedback},
  author={Scheurer, J{\'e}r{\'e}my and Campos, Jon Ander and Chan, Jun Shern and Chen, Angelica and Cho, Kyunghyun and Perez, Ethan},
  booktitle={The First Workshop on Learning with Natural Language Supervision at ACL},
  year={2022}
}


@article{chen2023feedback,
  title={Improving Code Generation by Training with Natural Language Feedback},
  author={Angelica Chen and Scheurer Jérémy and Tomasz Korbak and Jon Ander Campos and Jun Shern Chan and Samuel R. Bowman and Kyunghyun Cho and Ethan Perez},
  url={https://github.com/nyu-mll/ILF-for-code-generation/blob/main/ilf_for_code_gen.pdf},
  year={2023},
  journal={Preprint},
}


@misc{goodhart_gao,
    author = "Jacob Hilton and Leo Gao",
    title = "Measuring goodhart's Law",
    year = "2022",
    howpublished  = "https://openai.com/blog/measuring-goodharts-law/",
    addendum = "(accessed: 21.12.2022)",
}

@misc{openai_documentation,
    author = "OpenAI",
    title = "OpenAI finetuning documentation",
    year = "2022",
    howpublished  = "https://beta.openai.com/docs/api-reference/fine-tunes/create",
    addendum = "(accessed: 6.01.2023)",
}



@article{zhang2022opt,
  title={Opt: Open pre-trained transformer language models},
  author={Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others},
  journal={arXiv preprint arXiv:2205.01068},
  year={2022}
}

@article{wei2022chain,
  title={Chain of thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Chi, Ed and Le, Quoc and Zhou, Denny},
  journal={arXiv preprint arXiv:2201.11903},
  year={2022}
}

@article{saunders2022self,
  title={Self-critiquing models for assisting human evaluators},
  author={Saunders, William and Yeh, Catherine and Wu, Jeff and Bills, Steven and Ouyang, Long and Ward, Jonathan and Leike, Jan},
  journal={arXiv preprint arXiv:2206.05802},
  year={2022}
}

@article{bai2022constitutional,
  title={Constitutional AI: Harmlessness from AI Feedback},
  author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal={arXiv preprint arXiv:2212.08073},
  year={2022}
}

@article{schick2022peer,
  title={PEER: A Collaborative Language Model},
  author={Schick, Timo and Dwivedi-Yu, Jane and Jiang, Zhengbao and Petroni, Fabio and Lewis, Patrick and Izacard, Gautier and You, Qingfei and Nalmpantis, Christoforos and Grave, Edouard and Riedel, Sebastian},
  journal={arXiv preprint arXiv:2208.11663},
  year={2022}
}

@article{dohan2022language,
  title={Language model cascades},
  author={Dohan, David and Xu, Winnie and Lewkowycz, Aitor and Austin, Jacob and Bieber, David and Lopes, Raphael Gontijo and Wu, Yuhuai and Michalewski, Henryk and Saurous, Rif A and Sohl-Dickstein, Jascha and others},
  journal={arXiv preprint arXiv:2207.10342},
  year={2022}
}

@article{shi2022life,
  title={When Life Gives You Lemons, Make Cherryade: Converting Feedback from Bad Responses into Good Labels},
  author={Shi, Weiyan and Dinan, Emily and Shuster, Kurt and Weston, Jason and Xu, Jing},
  journal={arXiv preprint arXiv:2210.15893},
  year={2022}
}

@article{liu2022improving,
  title={On Improving Summarization Factual Consistency from Natural Language Feedback},
  author={Liu, Yixin and Deb, Budhaditya and Teruel, Milagro and Halfaker, Aaron and Radev, Dragomir and Awadallah, Ahmed H},
  journal={arXiv preprint arXiv:2212.09968},
  year={2022}
}

@article{xu2022learning,
  title={Learning New Skills after Deployment: Improving open-domain internet-driven dialogue with human feedback},
  author={Xu, Jing and Ung, Megan and Komeili, Mojtaba and Arora, Kushal and Boureau, Y-Lan and Weston, Jason},
  journal={arXiv preprint arXiv:2208.03270},
  year={2022}
}

@article{perez2021true,
  title={True few-shot learning with language models},
  author={Perez, Ethan and Kiela, Douwe and Cho, Kyunghyun},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={11054--11070},
  year={2021}
}


@misc{openai_feedme,
    author = "OpenAI",
    title = "Model index for researchers",
    year= "2022",
    howpublished  = "https://beta.openai.com/docs/model-index-for-researchers",
    addendum = "(accessed: 5.1.2023)",
}


@article{lu2021fantastically,
  title={Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity},
  author={Lu, Yao and Bartolo, Max and Moore, Alastair and Riedel, Sebastian and Stenetorp, Pontus},
  journal={arXiv preprint arXiv:2104.08786},
  year={2021}
}

@misc{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  publisher={OpenAI},
}

