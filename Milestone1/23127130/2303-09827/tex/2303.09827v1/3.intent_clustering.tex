\section{DSTC11 Intent Clustering Task}
In this task, participants are required to assign an intent label to each dialogue turn. A set of dialogues are provided as input, and each turn is pre-labeled with both its speaker role (i.e., Agent or Customer) and dialogue acts (i.e., InformIntent or not). One development dataset and two test datasets are provided, and each dataset consists of approximately 1K customer support spoken conversations with manual transcriptions and annotations. The development dataset derives from an insurance-related customer support service, and each conversation has an average of 70 turns. In addition, the development dataset contains ground truth intent annotations that allow participants to test and evaluate the model. The number of intent types and the domains of the test dataset are not revealed until the development phase ends. Note that no training dataset is given, as this challenge aims to zero-shot intent induction.