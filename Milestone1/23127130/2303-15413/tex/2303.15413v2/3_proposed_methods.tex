\section{Score Distillation and the Janus Problem}
\label{sec:problem}
SJC~\cite{wang2022score} defines the probability density function of parameters $\theta$ of 3D volume (\eg, NeRF~\cite{mildenhall2021nerf}) as an expectation of the likelihood of 2D rendered images $\mathbf{z}_\theta$ from uniformly sampled object-space viewpoints. Unlike this definition, our approach defines the density function of the parameters $\theta$ as a product of conditional likelihoods given a set of uniformly sampled viewpoints $\Pi$ and user prompt $\omega$. This can be expressed as:
\begin{equation}
\tilde{p}_{\textrm{3D}}(\theta) = \prod_{\xi\in \Pi} p_{\textrm{2D}}(\mathbf{z}_\theta | \xi, \omega),
\label{eq:density}
\end{equation}
where $p_{\textrm{2D}}$ and $\tilde{p}_{\textrm{3D}}$ denote the probability density of 2D image distribution and unnormalized density of 3D parametrizations, respectively. By using this formulation, we avoid using Jensen's inequality, in contrast to \cite{wang2022score}. Applying the logarithm to each side of the equation yields:
\begin{equation}
\begin{split}
\log \tilde{p}_{\textrm{3D}}(\theta) &= \sum_{\xi\in \Pi} \log p_{\textrm{2D}}(\mathbf{z}_\theta | \xi, \omega).
\end{split}
\label{eq:log-density}
\end{equation}
By taking the gradient of $\log \tilde{p}_{\textrm{3D}}(\theta)$, we can directly obtain $\nabla_\theta \log p_{\textrm{3D}}(\theta)$, since the normalizing constant is irrelevant to $\theta$. Using the chain rule, we obtain:
\begin{equation}
\begin{split}
\nabla_\theta\log p_{\textrm{3D}}&(\theta) = \sum_{\xi\in \Pi} \nabla_\theta\log p_{\textrm{2D}}(\mathbf{z}_\theta | \xi, \omega),\\&= Z \cdot \mathbb{E}_{\xi\in\Pi} \left[\nabla_\theta\log p_{\textrm{2D}}(\mathbf{z}_\theta | \xi, \omega)\right]\\
&= Z \cdot \mathbb{E}_{\xi\in\Pi} \left[\nabla_{\mathbf{z}_\theta}\log p_{\textrm{2D}}(\mathbf{z}_\theta | \xi, \omega)\frac{\partial \mathbf{z}_\theta}{\partial \theta}\right],
\end{split}
\label{eq:grad}
\end{equation}
where $Z=|\Pi|$ is a constant, and $\nabla_{\mathbf{z}_\theta}\log p_{\textrm{2D}}(\mathbf{z}_\theta | \xi, \omega)$ is practically estimated by diffusion models~\cite{karras2022elucidating}. Note that this definition generalizes SJC~\cite{wang2022score} and even $\nabla_\theta \mathcal{L}_\textrm{SDS}$ in DreamFusion\cite{poole2022dreamfusion}, which can be easily seen as the estimation of Eq.~\ref{eq:grad} with a different weighting rule and sampler. This is further expanded by applying Bayes' rule as follows:
\begin{equation}
\begin{split}
=Z \cdot \mathbb{E}_{\xi\in\Pi} \biggr[\bigl(&\underbrace{\nabla_{\mathbf{z}_\theta}\log p_{\textrm{2D}}(\mathbf{z}_\theta)}_{\textrm{Unconditional score}}\\+ &\underbrace{\nabla_{\mathbf{z}_\theta}\log p_{\textrm{2D}}(\xi, \omega | \mathbf{z}_\theta)}_{\textrm{Pose-prompt gradient}}\bigl)\frac{\partial \mathbf{z}_\theta}{\partial \theta}\biggr].
\end{split}
\label{eq:bayes}
\end{equation}

\begin{figure}[t]
\centering
\includegraphics[width=1.0\linewidth]{figures/method_revised_revised.pdf}
\vspace{-20pt}
\caption{\textbf{Illustration of our framework.} We propose prompt and score debiasing techniques to estimate robust and unbiased gradients of the 3D parameters w.r.t. the viewpoints.} \vspace{-20pt}
\label{fig:method}
\end{figure}



The first gradient term, reflecting the unconditional score modeled by 2D diffusion models~\cite{ho2020denoising,song2020score}, contains a bias that affects images viewed closely from specific viewpoints during early 3D optimization when $\mathbf{z}_\theta$ is noisy. This contributes to the Janus problem, as facial views are more prevalent in 2D data distribution for some objects.

On the other hand, the pose-prompt gradient in Eq.~\ref{eq:bayes} is guidance~\cite{song2020score,ho2021classifier,dhariwal2021diffusion,hong2022improving} that drives the rendered image to better represent a specific camera pose and user prompt. The term is further expanded:
\begin{equation}
\begin{split}
\nabla_{\mathbf{z}_\theta}\log p_{\textrm{2D}}(\xi, \omega | \mathbf{z}_\theta) = &\nabla_{\mathbf{z}_\theta}\log p_{\textrm{2D}}(\xi | \mathbf{z}_\theta)\\+&\nabla_{\mathbf{z}_\theta}\log p_{\textrm{2D}}(\omega | \mathbf{z}_\theta)\\+& \nabla_{\mathbf{z}_\theta}\log C,
\end{split}
\label{eq:divide-pcmi}
\end{equation}
where $C$ is defined as $\frac{p_{\textrm{2D}}(\xi,\omega|\mathbf{z}_\theta)}{p_{\textrm{2D}}(\xi|\mathbf{z}_\theta)p_{\textrm{2D}}(\omega|\mathbf{z}_\theta)}=\frac{p_{\textrm{2D}}(\xi|\omega,\mathbf{z}_\theta)}{p_{\textrm{2D}}(\xi|\mathbf{z}_\theta)}$, which represents the pointwise conditional mutual information (PCMI). If a viewpoint $\xi$ and a user prompt $\omega$ are contradictory, \ie, ${p_{\textrm{2D}}(\xi|\omega,\mathbf{z}_\theta)}\ll{p_{\textrm{2D}}(\xi|\mathbf{z}_\theta)}$, then $C$ approximates to $0$ for every $\mathbf{z}_\theta$. Furthermore, the terms $\nabla_{\mathbf{z}_\theta}\log p_{\textrm{2D}}(\xi | \mathbf{z}_\theta)$ and $\nabla_{\mathbf{z}_\theta}\log p_{\textrm{2D}}(\omega | \mathbf{z}_\theta)$ have an adverse effect, making the optimization particularly challenging.

\begin{figure}[t]
    \centering
    \begin{subfigure}{0.3\linewidth}
        \includegraphics[width=\linewidth]{figures/frog.png}
    \end{subfigure}
    \begin{subfigure}{0.3\linewidth}
        \includegraphics[width=\linewidth]{figures/frog_grad.png}
    \end{subfigure}
    \begin{subfigure}{0.3\linewidth}
        \includegraphics[width=\linewidth]{figures/frog_video.png}
    \end{subfigure}\vspace{0.13em}
    \begin{subfigure}{0.3\linewidth}
        \includegraphics[width=\linewidth]{figures/duck.png}
    \end{subfigure}
    \begin{subfigure}{0.3\linewidth}
        \includegraphics[width=\linewidth]{figures/duck_grad.png}
    \end{subfigure}
    \begin{subfigure}{0.3\linewidth}
        \includegraphics[width=\linewidth]{figures/duck_video.png}
    \end{subfigure}\vspace{0.13em}
    \begin{subfigure}{0.3\linewidth}
        \includegraphics[width=\linewidth]{figures/unicorn.png}
        \subcaption{Rendered image}
    \end{subfigure}
    \begin{subfigure}{0.3\linewidth}
        \includegraphics[width=\linewidth]{figures/unicorn_grad.png}
        \subcaption{2D score}
    \end{subfigure}
    \begin{subfigure}{0.3\linewidth}
        \includegraphics[width=\linewidth]{figures/unicorn_video.png}
        \subcaption{Generated result}
    \end{subfigure}\vspace{-10pt}
    \caption{\textbf{Visualization of the magnitude of the estimated $\nabla_{\mathbf{z}_\theta}\log p_{\textrm{2D}}(\mathbf{z}_\theta | \xi, \omega)$ during the optimization.} This visualization demonstrates that erroneous 2D scores result in critical artifacts, \eg, additional legs, beaks, and horns in this figure.} \vspace{-15pt}
    \label{fig:score}
\end{figure}

\section{Score Debiasing}
\label{sec:score-debiasing}

If the unconditional score, $\nabla_{\mathbf{z}_\theta}\log p_{\textrm{2D}}(\mathbf{z}_\theta)$, is biased towards some viewing directions, which is likely in 2D data as mentioned in Sec.~\ref{sec:problem}, it can negatively affect the 3D consistency and realism of generated objects through the chain rule (Eq.~\ref{eq:grad}). Moreover, large magnitudes in the user prompt gradient, $\nabla_{\mathbf{z}_\theta}\log p_{\textrm{2D}}(\omega | \mathbf{z}_\theta)$, can also cause issues by introducing text-related artifacts that are not present in the image rendered from a 3D field. Such artifacts include extra faces, beaks, and horns (see Fig.~\ref{fig:qualitative} and Fig.~\ref{fig:score}), which are unrealistic or inconsistent with the 3D object's structure.

High magnitude in those two terms is typically observed when the perturbed-and-denoised image by diffusion models significantly deviates from the rendered image in the corresponding pixels (Fig.~\ref{fig:score}). Hence, adjusting this gradient is necessary to reduce the artifacts and improve the realism of the generated 3D objects. However, the 2D bias that flows into the 3D field has hardly been formulated or adjusted for better optimization and 3D consistency.
\vspace{-10pt}

\paragraph{Dynamic thresholding of 2D-to-3D scores.}
\label{sec:dynamic}

In light of the need to control the flow of 2D scores to 3D volume (Sec.~\ref{sec:score-debiasing}) and inspired by the clipping methods~\cite{mikolov2012statistical,saharia2022photorealistic}, we propose an effective method that dynamically truncates the scores in order to mitigate the effects of bias and artifacts in the predicted 2D scores. Specifically, we linearly increase the truncation value throughout the optimization:
\begin{equation}
\begin{split}
\psi_{\textrm{dynamic}} &:= (1 - \tau) \psi_{\textrm{start}} + \tau \psi_{\textrm{end}},\\
\nabla_{\mathbf{z}_\theta}\log p_{\textrm{2D}} &= \textrm{Clip}(\nabla_{\mathbf{z}_\theta}\log p_{\textrm{2D}}(\mathbf{z}_\theta | \xi, \omega), \psi_{\textrm{dynamic}}),
\end{split}
\label{eq:dynamic}
\end{equation}
where $\tau=\frac{\textrm{(step)}}{\textrm{(max step)}}$ and $\textrm{Clip}(\textbf{a},b) = \textrm{max}(\textrm{min}(\textbf{a}, b), -b).$
This is a coarse-to-fine strategy~\cite{mildenhall2021nerf,dupont2022data}, since in the early stages of optimization, we need to focus on the overall structure and shape, which do not require the large magnitudes of the 2D scores, while in later stages, we focus more on the details that require higher magnitudes. With this strategy, we obtain a better trade-off between 3D consistency and 2D faithfulness than statically clipping the scores.

\begin{figure}[t]
\centering
\includegraphics[width=0.95\linewidth, height=4cm]{figures/back_view_a_dog.png}
\vspace{-10pt}
\caption*{\emph{``Back view of a dog''}}
\includegraphics[width=0.95\linewidth, height=4cm]{figures/back_view_a_smiling_dog.png}
\vspace{-10pt}
\caption*{\emph{``Back view of a smiling dog"}}
\vspace{-10pt}
\caption{\textbf{Samples from Stable Diffusion~\cite{rombach2022high} given a text prompt with contradiction.} Despite ``Back view of" is given in the prompts, the word ``smiling" in the prompt makes diffusion models biased towards the front view of an object.} \vspace{-15pt}
\label{fig:contradiction}
\end{figure}


\section{Prompt Debiasing}
\label{sec:prompt-debiasing}
Most text-to-3D generation methods that distill diffusion models~\cite{poole2022dreamfusion, lin2022magic3d, wang2022score} achieve a certain level of view consistency by concatenating view prompts (\eg, ``back view of") with user prompts. This simple and effective method utilizes the knowledge of large-scale text-to-image models. However, we argue that the current strategy of creating a view-dependent prompt by simply concatenating a view prompt with a user prompt is intrinsically problematic, as it can result in a contradiction between them. This contradiction is one of the causes that make diffusion models not follow a view prompt. Therefore, in the following subsection, we propose identifying the contradiction between the view prompt and user prompt using off-the-shelf language models trained with masked language modeling (MLM)~\cite{devlin2018bert}.

Additionally, instead of naively assigning regular regions to view prompt augmentations, in the next subsection, we reduce the discrepancy between the view prompt and object-space pose by adjusting the regions.
\vspace{-10pt}

\paragraph{Identifying contradiction utilizing language models.}
\label{sec:mut}
The prompt gradient term $\nabla_{\mathbf{z}_\theta}\log p_{\textrm{2D}}(\omega | \mathbf{z}_\theta)$ may cancel out the pose gradient term $\nabla_{\mathbf{z}_\theta}\log p_{\textrm{2D}}(\xi | \mathbf{z}_\theta)$ needed for the view consistency of generated 3D objects, as we can derive from Eq.~\ref{eq:divide-pcmi}. For example, if the view prompt is ``back view of" and the user prompt is ``a smiling dog", it results in a contradiction since an observer cannot see the dog's smile viewing from the back. This contradiction is one of the causes that makes diffusion models not follow a view prompt, but instead follow a word like "smiling" in a user prompt, as depicted in Fig.~\ref{fig:contradiction}.

In this regard, we propose a method for identifying contradictions using language models trained with masked language modeling (MLM). Specifically, let $V$ represent a set of possible view prompts, and let $U$ be a set of size 2, which contains the presence and absence of a word in the user prompt for brevity. We then compute the following:
\begin{equation}
\textrm{PMI}(v, u)=\frac{P(v | u)}{\sum_{u'\in U} P(v | u') P(u')},
\label{eq:contradiction}
\end{equation}
where we can model $P(v | u)$ with masked language modeling by alternating the view prompts and normalizing them, and $P(u)$ is a user-defined faithfulness. If $P(u)=1$, the word will never be removed from the user prompt. We then filter out the word $u$ that has a lower value of $\textrm{PMI}(v, u)$ than a threshold. Note that Eq.~\ref{eq:contradiction} is equal to the pointwise mutual information (PMI) since:
\begin{equation}
\frac{P(v | u)}{\sum_{u'\in U} P(v | u') P(u')} = \frac{P(v | u)}{P(v)} = \frac{P(v, u)}{P(v)P(u)},
\label{eq:pmi}
\end{equation}
and removing a contradiction implies removing the word that has a low PMI with the view prompts.
\vspace{-10pt}

\paragraph{Reducing discrepancy between view prompts and object-space poses.}
\label{sec:discrepancy}
Existing methods~\cite{poole2022dreamfusion,wang2022score,lin2022magic3d,metzer2022latent} use view prompt augmentations by dividing the camera space into some regular sections (\eg, front, back, side, and overhead in DreamFusion~\cite{poole2022dreamfusion}). However, this approach does not match the real distribution of object-space poses in image-text pairs, \eg, front view may cover a narrower region. Therefore, we make practical adjustments to the range of view prompts, such as reducing the azimuth range of the "front view" by half. Furthermore, we search for precise view prompts~\cite{poole2022dreamfusion,wang2022score} that give us improved results.
