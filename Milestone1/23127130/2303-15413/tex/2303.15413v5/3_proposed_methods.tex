\section{Score Distillation and the Janus Problem}
\label{sec:problem}
SJC~\cite{wang2022score} defines the probability density function of parameters $\theta$ of 3D volume (\textit{e.g.}, NeRF~\cite{mildenhall2021nerf}) as an expectation of the likelihood of 2D rendered images $\mathbf{z}_\theta$ from uniformly sampled object-space viewpoints (Eq.~6 in \cite{wang2022score}). Unlike this definition, our approach defines the density function of the parameters $\theta$ as a product of conditional likelihoods given a set of uniformly sampled viewpoints $\Lambda$ and user prompt $\omega$. This can be expressed as:
\begin{equation}
\tilde{p}_{\textrm{3D}}(\theta) = \prod_{\lambda\in \Lambda} p_{\textrm{2D}}(\mathbf{z}_\theta | \lambda, \omega),
\label{eq:density}
\end{equation}
where $p_{\textrm{2D}}$ and $\tilde{p}_{\textrm{3D}}$ denote the probability density of 2D image distribution and unnormalized density of 3D parametrizations, respectively. By using this formulation, we avoid using Jensen's inequality, in contrast to \cite{wang2022score}. Applying the logarithm to each side of the equation yields:
\begin{equation}
\begin{split}
\log \tilde{p}_{\textrm{3D}}(\theta) &= \sum_{\lambda\in \Lambda} \log p_{\textrm{2D}}(\mathbf{z}_\theta | \lambda, \omega).
\end{split}
\label{eq:log-density}
\end{equation}
By taking the gradient of $\log \tilde{p}_{\textrm{3D}}(\theta)$, we can directly obtain $\nabla_\theta \log p_{\textrm{3D}}(\theta)$, since the normalizing constant of $\tilde{p}_{\textrm{3D}}$ is irrelevant to $\theta$. Using the chain rule, we obtain:
\begin{equation}
\begin{split}
\nabla_\theta\log p_{\textrm{3D}}(\theta) = \sum_{\lambda\in \Lambda} \nabla_\theta\log p_{\textrm{2D}}(\mathbf{z}_\theta | \lambda, \omega) &= Z \cdot \mathbb{E}_{\lambda\in\Lambda} \left[\nabla_\theta\log p_{\textrm{2D}}(\mathbf{z}_\theta | \lambda, \omega)\right]\\&= Z \cdot \mathbb{E}_{\lambda\in\Lambda} \left[\nabla_{\mathbf{z}_\theta}\log p_{\textrm{2D}}(\mathbf{z}_\theta | \lambda, \omega)\frac{\partial \mathbf{z}_\theta}{\partial \theta}\right],
\end{split}
\label{eq:grad}
\end{equation}
where $Z=|\Lambda|$ is a constant, and $\nabla_{\mathbf{z}_\theta}\log p_{\textrm{2D}}(\mathbf{z}_\theta | \lambda, \omega)$ is practically estimated by diffusion models~\cite{karras2022elucidating}. Note that this definition generalizes SJC~\cite{wang2022score} and even $\nabla_\theta \mathcal{L}_\textrm{SDS}$ in DreamFusion\cite{poole2022dreamfusion}, which can be easily seen as the estimation of Eq.~\ref{eq:grad} with a different weighting rule and sampler. This is further expanded by applying Bayes' rule as follows:
\begin{equation}
\begin{split}
\nabla_\theta\log p_{\textrm{3D}}(\theta) =Z \cdot \mathbb{E}_{\lambda\in\Lambda} \biggr[\bigl(\underbrace{\nabla_{\mathbf{z}_\theta}\log p_{\textrm{2D}}(\mathbf{z}_\theta)}_{\textrm{Unconditional score}}+ \underbrace{\nabla_{\mathbf{z}_\theta}\log p_{\textrm{2D}}(\lambda, \omega | \mathbf{z}_\theta)}_{\textrm{Pose-prompt gradient}}\bigl)\frac{\partial \mathbf{z}_\theta}{\partial \theta}\biggr].
\end{split}
\label{eq:bayes}
\end{equation}
The first gradient term, reflecting the unconditional score modeled by 2D diffusion models~\cite{ho2020denoising,song2020score}, contains a bias that affects images viewed from typical viewpoints during early optimization of 3D volume when $\mathbf{z}_\theta$ is noisy. This contributes to the Janus problem, as facial views are more prevalent in the 2D data distribution for some objects.

On the other hand, the pose-prompt gradient in Eq.~\ref{eq:bayes} is guidance~\cite{song2020score,ho2021classifier,dhariwal2021diffusion,hong2022improving} that drives the rendered image to better represent a specific camera pose and user prompt. The term is further expanded:
\begin{equation}
\nabla_{\mathbf{z}_\theta}\log p_{\textrm{2D}}(\lambda, \omega | \mathbf{z}_\theta) = \nabla_{\mathbf{z}_\theta}\log p_{\textrm{2D}}(\lambda | \mathbf{z}_\theta)\\+\nabla_{\mathbf{z}_\theta}\log p_{\textrm{2D}}(\omega | \mathbf{z}_\theta)\\+ \nabla_{\mathbf{z}_\theta}\log C,
\label{eq:divide-pcmi}
\end{equation}
where $C$ is defined as $\frac{p_{\textrm{2D}}(\lambda,\omega|\mathbf{z}_\theta)}{p_{\textrm{2D}}(\lambda|\mathbf{z}_\theta)p_{\textrm{2D}}(\omega|\mathbf{z}_\theta)}=\frac{p_{\textrm{2D}}(\lambda|\omega,\mathbf{z}_\theta)}{p_{\textrm{2D}}(\lambda|\mathbf{z}_\theta)}$, which represents the pointwise conditional mutual information (PCMI). If a viewpoint $\lambda$ and a user prompt $\omega$ are contradictory, \textit{i.e.}, ${p_{\textrm{2D}}(\lambda|\omega,\mathbf{z}_\theta)}\ll{p_{\textrm{2D}}(\lambda|\mathbf{z}_\theta)}$, then $C$ approximates to $0$ for every $\mathbf{z}_\theta$. Simultaneously, the terms $\nabla_{\mathbf{z}_\theta}\log p_{\textrm{2D}}(\lambda | \mathbf{z}_\theta)$ and $\nabla_{\mathbf{z}_\theta}\log p_{\textrm{2D}}(\omega | \mathbf{z}_\theta)$ have an adverse effect on the 3D scene, making the view-consistent optimization particularly challenging.



\section{Methodology}

\subsection{Score debiasing}
\label{sec:score-debiasing}

\paragraph{Motivation and overview.}
If the unconditional score, $\nabla_{\mathbf{z}_\theta}\log p_{\textrm{2D}}(\mathbf{z}_\theta)$, is biased towards some viewing directions, which is likely in 2D data as mentioned in Sec.~\ref{sec:problem}, it can negatively affect the 3D consistency and realism of generated objects through the chain rule (Eq.~\ref{eq:grad}). Moreover, large magnitudes in the user prompt gradient, $\nabla_{\mathbf{z}_\theta}\log p_{\textrm{2D}}(\omega | \mathbf{z}_\theta)$, can also cause issues by introducing text-related artifacts that are not present in the image rendered from a 3D field (see Fig.~\ref{fig:qualitative} and Fig.~\ref{fig:score}). Such artifacts include extra faces, beaks, and horns, which are unrealistic or inconsistent with the 3D object's structure.

\begin{wrapfigure}{r}{7.0cm}
  \centering
  \vspace{-10pt}
\includegraphics[width=1.0\linewidth]{figures/score_prob.pdf}
  \vspace{-15pt}
  \caption{\textbf{Visualization of the magnitude of the estimated $\nabla_{\mathbf{z}_\theta}\log p_{\textrm{2D}}(\mathbf{z}_\theta | \lambda, \omega)$ during the optimization.} This visualization demonstrates that erroneous 2D scores result in critical artifacts, \textit{e.g.}, additional legs, beaks, and horns in this figure.}
  \label{fig:score}
      \vspace{-10pt}
\end{wrapfigure}

High magnitude in those two terms is typically observed when the perturbed-and-denoised image by diffusion models significantly deviates from the rendered image in the corresponding pixels (Fig.~\ref{fig:score}). Hence, adjusting this gradient is necessary to reduce the artifacts and improve the realism of the generated 3D objects. However, the 2D bias that flows into the 3D field has hardly been formulated or adjusted for better optimization and 3D consistency.

The intuition behind the scale of the distilled score $\nabla_{\mathbf{z}_\theta} \log p_{\sqrt{2}\sigma}(\mathbf{z}_\theta)$ can be mathematically elucidated by examining its relationship with the expectation term. Concretely, the distilled score serves as an approximation of the expected value of the difference between the distorted image $D(\mathbf{z}_\theta + \sigma n; \sigma)$ and the original rendered image $\mathbf{z}_\theta$, normalized by the square of the noise scale. This expectation is evaluated with respect to the normal distribution $\mathcal{N}(0, \mathbf{I})$ from which the noise term $n$ is sampled. Note that the noise term not only facilitates the use of diffusion models but can also be interpreted as a random perturbation applied to the rendered image $\mathbf{z}_\theta$.

In this context, the expectation term provides a measure of the sensitivity of the denoising process to variations in the noise. In other words, the magnitude of the estimated score can be interpreted as the (scaled) deviation of the original rendered image $\mathbf{z}_\theta$ from the 3D field. Notably, NeRF-W~\cite{martin2021nerf} also provides a mechanism for handling uncertainty by explicitly rendering the variance. On the contrary, we propose a novel and efficient method to directly clamp the estimated score, effectively suppressing significant deviations that ignore either geometry or appearance, thereby addressing the intrinsic bias inherent in score-based models.

\vspace{-5pt}
\paragraph{Dynamic clipping of 2D-to-3D scores.}
\label{sec:dynamic}

In light of the need to control the flow of 2D scores to 3D volume (Sec.~\ref{sec:score-debiasing}) and inspired by the clipping methods~\cite{mikolov2012statistical,saharia2022photorealistic}, we propose an effective method that truncates the scores to mitigate the effects of bias and artifacts in the predicted 2D scores:
\begin{equation}
\begin{split}
{\nabla_{\mathbf{z}_\theta}\log p^{\textrm{clipped}}_{\textrm{2D}}} &= \textrm{Clip}(\nabla_{\mathbf{z}_\theta}\log p_{\textrm{2D}}(\mathbf{z}_\theta | \lambda, \omega), \psi_{\textrm{static}}),
\end{split}
\label{eq:static}
\end{equation}
where $\textrm{Clip}(x,c) = \textrm{max}(\textrm{min}(x, c), -c)$. This score clipping prevents artifacts such as extra faces, horns, eyes, and ears from appearing on the 3D objects.

However, the application of naive score clipping creates a large threshold-dependent tradeoff between 3D consistency and 2D fidelity: the lower the threshold, the more artifacts are removed, but at the expense of 2D fidelity.
To circumvent this, we introduce an effective coarse-to-fine strategy~\cite{mildenhall2021nerf,dupont2022data}:
\begin{equation}
\begin{split}
\psi_{\textrm{dynamic}} &:= (1 - \tau) \psi_{\textrm{start}} + \tau \psi_{\textrm{end}},\\
{\nabla_{\mathbf{z}_\theta}\log p^{\textrm{clipped}}_{\textrm{2D}}} &= \textrm{Clip}(\nabla_{\mathbf{z}_\theta}\log p_{\textrm{2D}}(\mathbf{z}_\theta | \lambda, \omega), \psi_{\textrm{dynamic}}),
\end{split}
\label{eq:dynamic}
\end{equation}
where $\tau=\frac{\text{(step)}}{\text{(max step)}}$. In the early stages of optimization, we focus on the overall structure and shape, which do not require the large magnitudes of the 2D scores, while in later stages, we focus more on the details that require higher magnitudes, so we increase the threshold as the optimization progresses. We provide an illustration in Appendix~\ref{appendix:optimization} to show what the rendered image at each step looks like as the scene undergoes optimization.

\subsection{Prompt debiasing}
\label{sec:prompt-debiasing}

\paragraph{Motivation and overview.}
Text-to-3D generation methods that distill diffusion models~\cite{poole2022dreamfusion, wang2022score} achieve a certain level of view consistency by concatenating view prompts (\textit{e.g.}, "back view of") with user prompts~\cite{poole2022dreamfusion,lin2022magic3d,wang2022score,metzer2022latent,riu2023zero,seo2023let}. This simple and effective method leverages the knowledge of large-scale text-to-image models.

\begin{wrapfigure}{r}{7.0cm}
  \centering
  \vspace{-12pt}
  \includegraphics[width=1.0\linewidth]{figures/prompt_prob.pdf}
  \vspace{-15pt}
  \caption{\textbf{Samples from Stable Diffusion~\cite{rombach2022high} given a text prompt with contradiction.} Despite "Back view of" is given in the prompts, the word "smiling" in the prompt makes diffusion models biased towards the front view of objects.}
  \label{fig:contradiction}\vspace{-10pt}
  \vspace{-20pt}
\end{wrapfigure}

However, we argue that the current strategy of creating a view-dependent prompt by simply concatenating a view prompt with a user prompt is intrinsically problematic, as it can result in a contradiction between them. This contradiction is one of the causes that make diffusion models not follow the view prompt.

Therefore, in the following subsection, we propose identifying the contradiction between the view prompt and user prompt using off-the-shelf language models trained with masked language modeling (MLM)~\cite{devlin2018bert}.


Additionally, instead of naively assigning regular regions for view prompt augmentations, in the next subsection, we reduce the discrepancy between the view prompt and object-space pose by adjusting the regions.

\vspace{-5pt}
\paragraph{Identifying contradiction.}
\label{sec:mut}
The prompt gradient term $\nabla_{\mathbf{z}_\theta}\log p_{\textrm{2D}}(\omega | \mathbf{z}_\theta)$ may cancel out the pose gradient term $\nabla_{\mathbf{z}_\theta}\log p_{\textrm{2D}}(\lambda | \mathbf{z}_\theta)$ needed for the view consistency of generated 3D objects, as we can derive from Eq.~\ref{eq:divide-pcmi}. For example, if the view prompt is "back view of" and the user prompt is "a smiling dog", it results in a contradiction since an observer cannot see the dog's smile viewing from the back. This causes diffusion models not to follow a view prompt, but instead to follow a word like "smiling" in a user prompt, as shown in Fig.~\ref{fig:contradiction}.

In this regard, we propose a method for identifying contradictions using language models trained with masked language modeling (MLM). Specifically, let $V$ represent a set of possible view prompts, and let $U$ be a set of size 2, which contains the presence and absence of a word in the user prompt for brevity. We then compute the following:
\begin{equation}
 \frac{P(v | u)}{P(v)} =
\frac{P(v | u)}{\sum_{u'\in U} P(v | u') P(u')},
\label{eq:contradiction}
\end{equation}
where we technically model $P(v | u)$ with masked language modeling by alternating the view prompts and normalizing them, and $P(u)$ is a user-defined faithfulness. Note that Eq.~\ref{eq:contradiction} corresponds to the pointwise mutual information (PMI), as $\textrm{PMI}(v, u) \triangleq \frac{P(v, u)}{P(v)P(u)} = \frac{P(v | u)}{P(u)}$, and removing a contradiction involves eliminating a word with a low PMI value concerning the view prompts. In practice, a word from a user prompt is omitted if the value falls below a certain threshold.

\vspace{-5pt}
\paragraph{Reducing discrepancy between view prompts and camera poses.}
\label{sec:discrepancy}
Existing methods~\cite{poole2022dreamfusion,wang2022score,lin2022magic3d,metzer2022latent} utilize view prompt augmentations by dividing the camera space into some regular sections (\textit{e.g.,} front, back, side, and overhead in DreamFusion~\cite{poole2022dreamfusion}). However, this approach does not match the real distribution of object-centric poses in image-text pairs; \textit{e.g.,} the front view may cover a narrower region. Therefore, we make practical adjustments to the range of view prompts, such as reducing the azimuth range of the "front view" by half, and also search for precise view prompts~\cite{poole2022dreamfusion,wang2022score} that yield improved results.
