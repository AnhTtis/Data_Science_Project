\section{Background}

\paragraph{Diffusion models.}
Denoising diffusion models~\cite{ho2020denoising,song2021denoising} generate images through progressive denoising process. During training, denoising diffusion probabilistic models (DDPM)~\cite{ho2020denoising} optimizes the following simplified objective:
\begin{equation}
L_{\textrm{DDPM}} := \mathbb{E}_{\bm{\epsilon} \sim \mathcal{N}(0, \mathbf{I}), \mathbf{x}_0, t} \left[\big\|\bm{\epsilon} - \bm{\epsilon}_\phi(\mathbf{x}_t, t)\big\|^2\right],
\end{equation}
where $\bm{\epsilon}_\phi$ is a network of the diffusion model parameterized by $\phi$, $t \in \{T, T-1, ..., 1\}$ is a timestep, $\mathbf{x}_0$ is an original image, and $\mathbf{x}_t$ denotes a perturbed image according to the timestep $t$. During inference, starting from $\mathbf{x}_t$, DDPM samples a previous sample $\mathbf{x}_{t-1}$ from a normal distribution with probability density of $p_{\phi}(\mathbf{x}_{t-1}|\mathbf{x}_t)$.

Some works fit DDPM into the generalized frameworks, \textit{e.g.}, non-Markovian~\cite{song2021denoising}, score-based~\cite{song2020score,karras2022elucidating}, \textit{etc}. Notably, denoising diffusion models have a tight relationship with score-based models~\cite{song2020score,karras2022elucidating} in the continuous form. Furthermore, it has been shown that denoising diffusion models can be refactored into the canonical form of denoising score matching using the same network parameterization~\cite{karras2022elucidating}. This formulation further facilitates the direct computation of 2D scores~\cite{song2019generative, karras2022elucidating} with the following equation:
\begin{equation}
\nabla_{\mathbf{x}} \log p(\mathbf{x}; \sigma) = \frac{D_{\phi}(\mathbf{x}; \sigma) - \mathbf{x}}{\sigma^2},
\end{equation}
where $D_{\phi}$ is an optimal denoiser network trained for every $\sigma$. With some preconditioning, a diffusion model $\bm{\epsilon}_\phi$~\cite{ho2020denoising, song2021denoising, nichol2021improved, rombach2022high} turns into a denoiser $D_{\phi}$.

Recent advancements in diffusion models have sparked increased interest in text-to-image generation~\cite{ramesh2022hierarchical,rombach2022high,saharia2022photorealistic,nichol2021glide}. Diffusion guidance techniques~\cite{dhariwal2021diffusion,ho2021classifier,nichol2021glide,hong2022improving} have been developed to enable the control of the generation process based on various conditions such as class labels~\cite{ho2021classifier,dhariwal2021diffusion}, text captions~\cite{nichol2021glide}, or internal information~\cite{hong2022improving}. In particular, our work conditions text prompts with classifier-free guidance~\cite{ho2021classifier}, which is formulated as follows given a conditional diffusion model $\bm{\epsilon}_\phi(\mathbf{x}_t, t, \omega)$:
\begin{equation}
\tilde{\bm{\epsilon}} = \bm{\epsilon}_\phi(\mathbf{x}_t, t, \omega) + s\cdot(\bm{\epsilon}_\phi(\mathbf{x}_t, t, \omega) - \bm{\epsilon}_\phi(\mathbf{x}_t, t)),
\end{equation}
where $\tilde{\bm{\epsilon}}$ is the guided output, $\omega$ is the user-given text prompt (\emph{user prompt} for brevity), and $s$ is the guidance scale~\cite{ho2021classifier}.

\begin{figure}[t]
\centering
\includegraphics[width=1.0\textwidth]{figures/main_fig3.pdf}\\
\vspace{+5pt}
\caption{\textbf{Illustration of our framework.} We propose prompt and score debiasing techniques to estimate robust and unbiased gradients of the 3D parameters w.r.t. the viewpoints.}
\label{fig:method}\vspace{-10pt}
\end{figure}

\vspace{-5pt}
\paragraph{Score distillation for text-to-3D generation.}

Diffusion models have shown remarkable performance in text-to-image modeling~\cite{nichol2021glide,ramesh2022hierarchical,saharia2022photorealistic,hong2022improving,rombach2022high}. On top of this, DreamFusion~\cite{poole2022dreamfusion} proposes the score-distillation sampling (SDS) method that uses text-to-image diffusion models to optimize neural fields~\cite{mildenhall2021nerf}, achieving encouraging results. The score-distillation sampling utilizes the gradient computed by the following equation:
\begin{equation}
\nabla_{\theta} L_{\textrm{SDS}} \triangleq \mathbb{E}_{\bm{\epsilon} \sim \mathcal{N}(0, \mathbf{I}), t} \left[w(t)(\bm{\epsilon}_\phi(\mathbf{z}_t, t, \omega) - \bm{\epsilon})\frac{\partial \mathbf{z}_\theta}{\partial \theta}\right],
\label{eq:sds}
\end{equation}
where $\mathbf{z}_t$ denotes the $t$-step noised version of $\mathbf{z}_\theta$ which is a rendered image from a NeRF network with parameters $\theta$~\cite{mildenhall2021nerf}, and $w(t)$ is a scaling function only dependent on $t$. This gradient omits the Jacobian of the diffusion backbone, leading to tractable optimization in differentiable parameterizations~\cite{poole2022dreamfusion}.

On the other hand, in light of the interpretation of diffusion models as denoisers, SJC~\cite{wang2022score} presents a new approach directly using the score estimation, called perturb-and-average scoring (PAAS). The work shows that the U-Net Jacobian emerging in DreamFusion is not even necessary, as well as forming a strong baseline using publicly open Stable Diffusion~\cite{rombach2022high}. The perturb-and-average score approximates to a score with an inflated noise level:
\begin{equation}
\nabla_{\mathbf{z}_\theta} \log p_{\sqrt{2}\sigma}(\mathbf{z}_\theta) \approx \mathbb{E}_{n \sim \mathcal{N}(0, \mathbf{I})} \left[\frac{D_\theta(\mathbf{z}_\theta+\sigma n; \sigma) - \mathbf{z}_\theta}{\sigma^2}\right],
\label{eq:paas}
\end{equation}
where the expectation is practically estimated by Monte Carlo sampling. This score estimate is then directly plugged into the 2D-to-3D chain rule and produces:
\begin{equation}
\nabla_{\theta} L_{\textrm{PAAS}} \triangleq \mathbb{E}_{\mathbf{z}_\theta} \left[\nabla_{\mathbf{z}_\theta} \log p_{\sqrt{2}\sigma}(\mathbf{z}_\theta)\frac{\partial \mathbf{z}_\theta}{\partial \theta}\right].
\label{eq:sjc}
\end{equation}
Although the derivation is different from SDS in DreamFusion~\cite{poole2022dreamfusion}, it is straightforward to show that the estimation $\nabla_{\theta} L_{\textrm{PAAS}}$ is the same as $\nabla_{\theta} L_{\textrm{SDS}}$ with a different weighting rule and sampler~\cite{karras2022elucidating}.

In general, frameworks distilling the score of text-to-image diffusion models~\cite{poole2022dreamfusion,lin2022magic3d,wang2022score,metzer2022latent,riu2023zero,seo2023let} achieve a certain level of view consistency by concatenating view prompts (\textit{e.g}., "back view of") with user prompts~\cite{poole2022dreamfusion,lin2022magic3d,wang2022score,metzer2022latent,riu2023zero,seo2023let}. Although this is an important part in score distillation, it is rarely discussed. In the following section, we elucidate this altogether, uncovering the underlying causes of the Janus problem.