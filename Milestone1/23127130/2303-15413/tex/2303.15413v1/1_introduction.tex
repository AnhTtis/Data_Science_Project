\section{Introduction}
Recently, significant advancements have been made in the field of zero-shot text-to-3D generation~\cite{jain2022zero}, particularly with the integration of score distillation techniques~\cite{lin2022magic3d, wang2022score, poole2022dreamfusion, metzer2022latent} and diffusion models~\cite{karras2022elucidating, song2020score, song2019generative, ho2020denoising, saharia2022photorealistic, rombach2022high, song2021denoising, dhariwal2021diffusion} to optimize Neural Radiance Fields (NeRF)~\cite{mildenhall2021nerf}. These methods provide a solution for generating a wide range of 3D objects from a textual input, without requiring 3D supervision. Despite their considerable promise, these approaches often encounter a view inconsistency problem. One of the most notable problems is the multi-face issue, also referred to as \emph{the Janus problem}, which is illustrated in the ``Baseline" of Fig.~\ref{fig:qualitative}. This problem constrains the applicability of the methods~\cite{lin2022magic3d, wang2022score, poole2022dreamfusion, metzer2022latent}, but the Janus problem is rarely formulated or carefully analyzed in previous literature.

To address the view inconsistency problem, we delve into the formulation of score-distilling text-to-3D generation presented in \cite{poole2022dreamfusion,wang2022score,metzer2022latent,lin2022magic3d}. We generalize and expand the assumptions about the gradients regarding the 3D parameterization in previous works, such as DreamFusion~\cite{poole2022dreamfusion} and Score Jacobian Chaining (SJC)~\cite{wang2022score}, and identify the main causes of the problem within the estimated score. The score further derives the unconditional score and pose-prompt gradient, both of which interrupt the estimation of unbiased gradients concerning the 3D volume. Therefore, refining them is necessary for generating more realistic and view-consistent 3D objects.

\begin{figure}[t]
\centering
\includegraphics[width=1\linewidth]{figures/janus.pdf}\vspace{-12pt}
\caption{\textbf{Comparison between the baseline (SJC~\cite{wang2022score}) and ours.} Our debiasing methods qualitatively reduce view inconsistencies in zero-shot text-to-3D and the so-called \emph{Janus problem}.}
\label{fig:qualitative}\vspace{-20pt}
\end{figure}

Building on this concept and drawing inspiration from gradient clipping~\cite{mikolov2012statistical} and dynamic thresholding~\cite{saharia2022photorealistic}, we propose a score debiasing method that performs dynamic score thresholding. Specifically, this method cuts off the score estimated by 2D diffusion models to mitigate the impact of erroneous bias. With this debiasing approach, we reduce artifacts in generated 3D objects and alleviate the view inconsistency problem by striking a balance between faithfulness to 2D models and 3D consistency. Furthermore, we find that by gradually increasing the truncation value, which aligns with the coarse-to-fine nature of generating 3D objects~\cite{dupont2022data,mildenhall2021nerf}, we achieve a better trade-off for 3D consistency without significantly compromising faithfulness.

On the other hand, as the first attempt to address the bias issue in prompts, we further present a prompt debiasing method. In contrast to prior works~\cite{poole2022dreamfusion,wang2022score,lin2022magic3d} that simply concatenate a view prompt and user prompt, our method reduces inherent contradiction between them by leveraging a language model trained with a masked language modeling (MLM) objective~\cite{devlin2018bert}, computing the pointwise mutual information. Additionally, we decrease the discrepancy between the assignment of the view prompt and object-space pose by adjusting the range of view prompts. These enable text-to-image models~\cite{saharia2022photorealistic, rombach2022high, nichol2021glide} to predict accurate 2D scores, resulting in 3D objects that possess more realistic and consistent structures.
