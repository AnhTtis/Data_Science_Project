\section{INTRODUCTION}

Humanoid robots are frequently designed to be capable of a wide range of motions. Making full use of these platforms as well as understanding their limitations requires an ability to generate and deploy coordinated, multi-contact maneuvers. Generating such motions is achieved by relaxing assumptions about the robot's posture, contactable limbs and contact modes (e.g. planar, line or point contacts) in order to maintain motion generality. The quasi-static case has been well-studied and mature tools exist for reasoning about arbitrary friction constraints \cite{bretl2008testing}, admissible trajectory timing \cite{pham2014general}, and actuation margins \cite{orsolino2020feasible}. However, leveraging these tools for search-based planning presents a number of obstacles. Primarily, multi-contact motions have an inherently large branching factor which can cause planning to be computationally intractable or rely on heuristics \cite{tonneau2018efficient, bouyarmane2018multi}. Additionally, it is challenging to construct generic posture scoring functions that perform well over a large space of configurations. In this work we present a teleoperation framework which builds on existing multi-contact feasibility metrics, namely \cite{bretl2008testing, orsolino2020feasible}, by providing feasibility visualization to the operator. The operator guides the trajectory using contact and posture tasks and is informed of motion feasibility during teleoperation.

% Alternatively, operator-driven approaches have been shown as an effective method of commanding complex humanoid motion \cite{zucker2015general, johnson2017team, marion2018director, darvish2023teleoperation, allspaw2021implementing}. 

% There have been many recent successful results of VR-based humanoid teleoperation \cite{darvish2023teleoperation, allspaw2021implementing, wonsick2021human, elobaid2020telexistence}. VR offers flexible and expressive operator input when manipulating virtual artifacts \cite{groechel2022tool} and has been shown to reduce operation time compared to conventional desktop interfaces \cite{sheetz2022comparing}.

% With many recent successful results using VR \cite{darvish2023teleoperation, allspaw2021implementing, wonsick2021human, elobaid2020telexistence, jorgensen2022cockpit} we believe it is a well-suited solution to the problem of generating multi-contact humanoid trajectories.

% There have been many successful results using VR \cite{darvish2023teleoperation, allspaw2021implementing, wonsick2021human, elobaid2020telexistence, jorgensen2022cockpit}

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{Figures/TitleFigure.jpg}
    \caption{Demonstration of the presented teleoperation framework on Valkyrie in various multi-contact scenarios. The operator (top-right) uses a VR application (top-left) to iteratively create keyframes by dragging a preview robot to the desired configuration. Trajectories are validated in simulation (bottom-left) and hardware (bottom-right) on the Valkyrie humanoid.}
    \label{fig:scripting_title_figure}
\end{figure}

The aim of this teleoperation approach is to capture a wide family of multi-contact maneuvers, including crawling, kneeling, bracing against a wall as well as normal standing. In addition to the contact and actuation feasibility checks mentioned above, these motions require a flexible interface for generating atypical contacts and postures. In our interface, the operator can generate contact points anywhere on the surface of a mesh approximation of the robot. Similarly, taskspace posture setpoints can be generated for any link, with configurable priority weighting and constrained axes. 

The presented work is implemented as a Virtual Reality (VR) interface.  Our design prioritizes flexible operator input and visualizing spatial artifacts, matching many strengths of VR. Research has shown VR offers flexible and expressive operator input when manipulating virtual artifacts \cite{groechel2022tool} and has been shown to reduce operation time compared to conventional desktop interfaces \cite{sheetz2022comparing}. However, our approach is not unique to VR and the presented results are independent of the use of VR. We validate our interface in three simulated teleoperation experiments in which the robot performs multi-contact maneuvers. For experiment two, we deploy the motion on a physical Valkyrie robot to perform a crouch-to-kneel motion.

\renewcommand{\arraystretch}{1.2}
\begin{table*}
\centering
% \captionof{table}{Comparison of motion configurability among humanoid motion generation systems} \label{tab:comparison} 
\captionof{table}{Comparison of approaches to motion configurability in multi-contact motion generation systems.} \label{tab:comparison} 
\begin{tabular}{ | c | c | c | c | c | } 
 \hline
 Related Work & Contactable Links & Commanded Posture & Contact Points on Robot & Contact Modes \\
 \hline
 \hline
 \textbf{Ours} & Hands, Elbows, Knees, Feet & Taskspace, Joint Position, CoM & Operator Specified & Point, Line, Plane \\
 \hline
 Brossette et al. \cite{brossette2018multicontact} & Hands, Feet & Taskspace, Joint Position, CoM & Predefined & Point, Plane \\
 \hline
 Rouxel et al. \cite{rouxel2022multicontact} & Hands, Feet & Taskspace & Predefined & Point, Plane \\
 \hline
 Hiraoka et al. \cite{hiraoka2021online} & Hands, Knees, Feet & Taskspace & Operator Specified & Point, Plane \\
 \hline
 Henze et al. \cite{henze2017multi} & Hands, Knees, Feet & Taskspace, Joint Position, CoM & Predefined & Point, Plane \\
 \hline
 Polverini et al. \cite{polverini2020multi} & Hands, Feet & Taskspace, CoM & Predefined & Point \\
\hline
 Otani et al. \cite{otani2017adaptive} & Hands, Elbows, Knees, Feet & Taskspace & Predefined & Point, Plane \\
 \hline
\end{tabular}
\end{table*}

% To test the framework, we generate trajectories for a set of diverse multi-contact scenarios and validate them in simulation and hardware on a NASA Valkyrie humanoid.

% Posture scoring is a difficult problem <citation?>. For unorthodox postures, it's hard. Our approach is to fully rely on human intuition and create an interface that is very flexible with respect to setpoints. >> We use a maximally flexible approach and have the user place control frames and select enables axes to avoid ruling out any postures.

% What kinds of motion feasibility information.
% - CoM stability margin
% - Proximity of joint torques to saturation
% - Collision

% The presented Virtual Reality (VR) based teleoperation framework is designed to be highly configurable with respect to kinematic tasks and contact modes. Taskspace posture setpoints can be generated for any link, with configurable weight and constrained axes. Contact points can be placed anywhere on a convex approximation of the robot's surface, with line and planar contact possible through proper contact point placement. This represents a design trade-off by creating higher cognitive demand in exchange for higher operator expression. We mitigate cognitive demand by performing real-time estimation of motion feasibility, checking quasi-static contact stability and collisions along an interpolated trajectory. The benefit of this design choice is capturing motions with unique posture constraints and contact modes, such as knee and elbow contacts. To test the framework, we generate trajectories for a set of diverse multi-contact scenarios and validate them in simulation and hardware on a NASA Valkyrie humanoid.

% For final paragraph, could be even more on-the-nose by pointing out maneuvers that are possible, such as toeing off, forearm placements and chest contacts

% The main contributions of this work are in the generality of gaits and motions which are commandable through this teleoperation framework:
% \begin{enumerate}
%     \item A generalized use of interactable constraint anchors which enables arbitrary postures and contact modes.
%     \item Fast quasi-static motion feasibility based on a friction- and actuation-aware CoM support region.
%     \item We deploy the proposed framework in several multi-contact scenarios (expand)
% \end{enumerate}

% In this paper we present a VR-based framework which enables an operator to create  ...
% The aim is to have a design general enough that it can be used for a wide range of motions such as ...
% In contrast to many methods which aim to retarget the operator's motion onto the robot, in our approach the operator directly constraints the robot by ...
% This represents a design trade-off by creating higher operator burden in exchange for a higher level fidelity for the operator's 
% By implementing features to assist the operator in specifying kinematic objectives, we believe the level of operator burden can be mitigated and this can be seen as a viable alternative to retargeting.

% 


% General approach

% Approach with more details and highlight contributions

% Overview:
% Humanoids need to be able to perform a large space of multi-contact motions. Or put another way, there needs to be reliable ways of generating whole-body multi-contact motions.
% This requires the robot to make contact with arbitrary links and have non-standard postures.
% While autonomous footstep planners have become capable of handling a variety of terrain, there remains to be an equivalent general planner for whole-body motions. One factor is the search space becomes considerably bigger. The other is that it becomes difficult to define what constitutes a ``good'' posture or contact set in general.
% The state-of-the-art teleoperation approaches focus on retargeting the operator's motion to the robot's motion. This may be limiting when specific posture is required, for instance a preferred joint position which cannot be easily mapped to a human or mass distribution of the robot does not match a human and results in motions that aren't feasible, or labelling of contact states.


% This paper addresses the problem of enabling humanoid robots to achieve non-gaited multi-contact motions such as crawling, bracing against a wall, standing up from a fall, rolling over, sit-to-stand, and so on. In gaited humanoid footstep planning, the decision space at a search node is often $SE(2)$ for flat ground \cite{chestnutt2005footstep} and $SE(3)$ for rough terrain \cite{deits2014footstep}. In such cases, the sequence of contacting bodies is dictated by the gait and a planner only determines the location of a given contact point. Conversely, for non-gaited contact planning the contact sequence needs to be determined by the planner, which significantly increases the dimensionality of the search space. For example, the decision space for flat ground becomes $n\times SE(2)$, where $n$ is the number of available contacting bodies.

% There are many approaches to solving this problem of dimensionality. One approach is to decompose the problem by first solving a "guide-path" for the root body \cite{bouyarmane2009potential, tonneau2018efficient} which can in turn be used as a heuristic to guide a low-level contact planner \cite{bouyarmane2011multi}. Another approach is to rely on sampling-based methods to determine feasible contact transitions and score them according to proximity to a goal. While these approaches can guarantee metrics such as collision-avoidance and static equilibrium, a major limitation is the difficulty to create general heuristics for natural gaits and posture.

% We present a framework designed to enable a human operator to determine contact sequences and posture while enforcing feasibility, such as collision-checking and static equilibrium. Our major contributions are:

% \begin{itemize}
%     \item An operator-driven framework for generating feasible and natural multi-contact trajectories.
%     \item Fast generation of contact and posture objectives through a virtual-reality interface.
%     \item Visual operator feedback of feasibility status.
% \end{itemize}
