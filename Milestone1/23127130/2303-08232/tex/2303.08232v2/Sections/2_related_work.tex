\section{RELATED WORK}

% Overview of teleop/retargeting
Translating an operator's intent to robot motion is a challenging task, particularly when commanding coordinated motions to legged or dexterous robots. This challenge has given rise to various retargeting frameworks for efficiently mapping operator input to robot motion. Methods for retargeting depend on factors such as available human measurements, task application and control scheme \cite{darvish2023teleoperation}.

% Supervisory bipedal teleop
There has been significant progress in supervisory-style interfaces for humanoid teleoperation in which the operator provides intermittent, high-level input. This became a popular approach in the DARPA Robotics Challenge (DRC) by having the user provide walking, posture or grasp setpoints with varied levels of customization among the teams \cite{johnson2017team}. For example, Zucker et al. \cite{zucker2015general} included one user-adjustable setpoint per end-effector with jointspace, world-frame and body-frame control modes. Marion et al. \cite{marion2018director} had additional flexibility such as selecting chest, pelvis and CoM setpoints as well as the taskspace constraint set and base of the kinematic chain. Motion validation consisted of collision checks \cite{zucker2015general} and validating that the CoM remains within the support region \cite{marion2018director}.

% Multi-contact tele-op, motion feasibility
Adapting these interfaces for multi-contact scenarios presents many challenges, the main one being motion feasibility. For quasi-static motion, a feasible CoM region with respect to contact friction constraints \cite{bretl2008testing} and actuation constraints \cite{orsolino2020feasible} can be employed. This has been extensively used in multi-contact motion planning, particularly for contact-first approaches \cite{polverini2020multi, escande2013planning, vaillant2016multi}. Vaillant et al. \cite{vaillant2016multi} enabled an operator to teleoperate a ladder-climbing scenario by specifying a contact sequence. In contrast to such discrete search-based approaches Brossette et al. \cite{brossette2018multicontact} optimized contact points over a manifold approximation of the contactable environment surface. Rouxel et al. \cite{rouxel2022multicontact} retarget an operator-commanded set of posture and contact constraints to achieve quasi-statically stable multi-contact motions.

% Multi-contact tele-op, operator expressiveness
Another major challenge with teleoperation in multi-contact scenarios in enabling a high degree of operator expression for commanding arbitrary postures and contact modes. The use of VR and Motion Capture (MoCap) enables more sophisticated operator mapping through partial or whole-body kinematic retargeting. Early pioneering work by Pollard et al. \cite{pollard2002adapting} used MoCap data from a human actor to mimic dancing motions by mapping to the torso and upper body of a fixed-base humanoid. The operator-to-robot mapping accounted for joint limits, velocity limits and singularities. Choi et al. \cite{choi2019towards} used MoCap for retargeting human motion data to humanoid robots with vastly different morphologies. There has also been work in using MoCap for more contact-rich scenarios \cite{di2016multi, otani2017adaptive}. Otani et al. \cite{otani2017adaptive} implemented a motion capture based retargeting scheme for multi-contact manipulation scenarios. Operator motion is mapped to support, free and manipulation tracking sets and demonstrated in simulation by bracing against a table while manipulating an object. 

%In the recent Avatar XPRIZE\footnote[1]{\url{https://www.xprize.org/prizes/avatar}}, the Italian Institute of Technology team used a variety of inputs to teleoperate iCub3 \cite{dafarra2022icub3}. Walking behavior was commanded through an omnidirectional treadmill and arm setpoints through a haptic suit.

% Extensions of this work include online reference motion for enabling upper-body dancing with active balance \cite{dariush2009online} and simulated stepping and Tai-chi maneuvers \cite{yamane2010control}. 
% Recently, there have been integrated architectures in which the operator commands reference postures through a retargeting scheme and walking behavior through a joystick or treadmill \cite{penco2019multimode, elobaid2020telexistence, jorgensen2022cockpit}. These architectures have had success in tasks requiring both walking and manipulation such as door opening, wall bracing and debris removal.

\begin{figure}[!t]
    \centering
    \includegraphics[width=0.83\columnwidth]{Figures/ControlFlow4.png}
    \caption{Control flow of our multi-contact teleoperation framework.}
    \label{fig:control_flow}
\end{figure}

% Comparison of this work to others
\subsection{Contribution}
Our teleoperation framework is designed for high motion configurability by relaxing restrictions on the set of contactable limbs and commanded posture objectives (Tab. \ref{tab:comparison}). The main contribution of this framework are as follows:

\begin{itemize}
\item Teleoperation with contact points placed arbitrarily on the robot surface and contact feasibility visualized as an actuation-aware CoM stability margin.
\item Transition feasibility by visualizing contact removability and checking contact stability along an interpolated trajectory.
\item Interface controls to configure the weight, axis constraints and control frame of posture tasks.
\end{itemize}

\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{Figures/Teleoperat_Combo_Figure.jpg}
    \caption{(a) Operator view in VR with Valkyrie leaning against a wall. (b) Convex mesh model of Valkyrie. Taskspace posture anchors are generated with a control frame that lies inside the shape(s) corresponding to the configured link. Similarly, contact point anchors are generated along the surface of the shape(s) corresponding to the contacting link. (c) Contact points are projected to the surface of the robot or environment mesh while creating (top) or placing (bottom) a contact point anchor. The arrow indicates the surface normal of the robot or environment mesh. (d) Main menu used to export/load keyframe scripts, toggle visualization, configure solver behavior and switch between placing taskspace posture and contact anchors. (e) Joint anchor menu. (f) Taskspace posture/contact point anchor menu.}
    \label{fig:teleop_combo}
\end{figure*}


% MoCap-based approaches such as Otani et al. \cite{otani2017adaptive} often rely on offline processing of motion data to integrate knee or elbow contacts and thus don't allow for motion feasibility to be reviewed in real-time or for contact modes (i.e. point, line, plane) to be explicitly commanded. While many other state-of-the-art teleoperation approaches such as Rouxel et al. \cite{rouxel2022multicontact}, Zucker at al. \cite{zucker2015general} and Dafarra et al. \cite{dafarra2022icub3} do perform real-time feasibility assessment, they only allow a limited set of contact modes, often restricted to feet and hand contacts. In contrast, our framework enables arbitrary contact locations, such as elbows and knees, and also allows the operator to specify point, line or planar contact modes for all contactable links while receiving real-time feedback about motion feasibility.

% mention that contact modes are inferred in Mocap/retargetting
% add chest contact to one of the sims

% \begin{enumerate}
%     %
%     \item Contact points at any surface of the robot's mesh to allow arbitrary contact modes.
%     \item Posture objectives for any robot link with configurable constraint sets and task priority.
%     \item Real-time display of the friction- and actuation-aware CoM support region to inform the operator of feasibility margins.
% \end{enumerate}