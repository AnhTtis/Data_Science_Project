\section{ARCHITECTURE}

\begin{figure}
    \centering
    \includegraphics[width=0.92\columnwidth]{Figures/Pipeline.png}
    \caption{High-level architecture of the motion generation framework. Solid arrows designate ROS 2 messages which are sent between modules. Hollow arrows designate saving and loading to file. Blue dashed lines represent a message-level layer of abstraction.}
    \label{fig:script_pipeline}
\end{figure}

The diagram in Fig. \ref{fig:script_pipeline} shows the control flow of our framework. At a high level, the operator creates whole-body trajectories by incrementally generating statically stable, collision-free key frames. These key frames can either be created offline using a simulation or online with hardware and are logged for future editing and reuse. At a software level, there are three processes involved in generating trajectories. The first is the user-interface (UI) which enables the operator to specify kinematic objectives and validate key frames. Both a VR app in Java Monkey Engine \cite{JME} and a desktop app in JavaFX \cite{JavaFX} are implemented with similar functionality. In practice, the VR UI is preferred for generating trajectories from scratch and the desktop for editing existing trajectories. The VR app is developed for the Valve Index \cite{Index} and also has bindings for the HTC Vive \cite{Vive}. The second process is an optimization-based inverse kinematics solver (Sec. \ref{sec:ik}) which solves for whole-body configurations given a set of kinematic objectives. The third process is a robot controller which executes the commanded motion in either a physics simulator or on hardware. Both the UI and robot controller have message-layer abstraction to allow any permutation of active modules (Fig. \ref{fig:script_pipeline}). All inter-process communication is done through ROS 2 messages \cite{ros2}.

% The architecture of the framework is shown in Fig. 2
% It consists of four main components. 
%   - The first is an optimization-based inverse kinematics solver. This solver accepts kinematic tasks and outputs whole-body configurations, next section has deets
%   - The second component is a GUI for the operator to interface with the kinematics solver. Both a VR and desktop app are implemented with identical functionality. The idea is to create trajectories from scratch in VR and have the desktop app for offline editing. 
%   - The third component represents the robot's onboard controller, which executes motions commanded by the operator
%   - The fourth is the sequence of keyframes being assembled

% We develop trajectories by prototyping in simulation, assembling a library of trajectories which can be dispatched online.

% Messaging is all done in ROS 2. 