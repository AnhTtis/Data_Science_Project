\section{INTRODUCTION}

Humanoid robots are frequently designed to be capable of a wide range of motions. Making full use of these platforms as well as understanding their limitations requires an ability to generate and deploy coordinated, multi-contact maneuvers. Generating such motions requires relaxing assumptions about the robot's posture and contactable limbs in order to maintain generality. The application of search-based planning to this problem presents a number of obstacles. Primarily, multi-contact motions have an inherently large branching factor which can cause planning to be computationally intractable or rely on heuristics \cite{tonneau2018efficient, bouyarmane2018multi}. Additionally it is challenging to construct generalized posture scoring functions that perform well over a large space of configurations. Alternatively, operator-driven approaches have been proven as a reliable means of commanding complex humanoid motion \cite{zucker2015general, johnson2017team, marion2018director}. With many recent successful results using virtual reality (VR) \cite{darvish2023teleoperation, allspaw2021implementing, wonsick2021human, elobaid2020telexistence, jorgensen2022cockpit} we believe it is a well-suited solution to the problem of generating multi-contact humanoid trajectories.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{Figures/TitleFigure_reduced.PNG}
    \caption{Demonstration of the presented motion generation framework on Valkyrie in various multi-contact scenarios. The virtual reality application (top-left) enables the operator to iteratively create key frames by dragging the robot to the desired configuration. The desktop application (top-right) is used for editing and analysis of trajectories. Trajectories are validated in simulation (bottom-left) and hardware (bottom-right) on the Valkyrie humanoid.}
    \label{fig:scripting_title_figure}
\end{figure}

In this paper we present a VR-based framework which enables the operator to create whole-body trajectories by iteratively posing the robot in contact stable, collision-free configurations. This is achieved by mapping kinematic objectives to virtual elements which can be easily created, removed or modified by the operator. The aim of this design is creating a system with sufficient generality for use in a wide range of motions and contact modes. Following this approach, the operator can constrain any rigid body or joint and the framework makes no assumptions about the robot's posture or contacting limbs. This represents a design trade-off by creating higher operator burden in exchange for increased operator expressiveness. We make this design choice in order to have a single framework for handling many multi-contact scenarios, such as crawling, climbing, leaning, rolling and kneeling. To test our framework, we generate trajectories for a set of diverse multi-contact scenarios and validate them in simulation and hardware on a NASA Valkyrie humanoid.

% However, operator burden is mitigated by tools for intuitive and contact-consistent configuration and robot and visual cues which indicate the level of actuation-feasibility. 

The main contributions of this framework are in the implementation of the VR UI and the generality of motion generation (Section \ref{sec:vrui}):
\begin{enumerate}
    \item A generalized use of interactable constraint anchors which contain no assumptions of the environment or preferred posture.
    \item Automated constraints and visual cues for CoM feasibility through an actuation-aware constraint region and force polytopes.
    \item An intuitive mechanism for generating robot-environment contact constraints.
\end{enumerate}

% In this paper we present a VR-based framework which enables an operator to create  ...
% The aim is to have a design general enough that it can be used for a wide range of motions such as ...
% In contrast to many methods which aim to retarget the operator's motion onto the robot, in our approach the operator directly constraints the robot by ...
% This represents a design trade-off by creating higher operator burden in exchange for a higher level fidelity for the operator's 
% By implementing features to assist the operator in specifying kinematic objectives, we believe the level of operator burden can be mitigated and this can be seen as a viable alternative to retargeting.

% 



% General approach

% Approach with more details and highlight contributions

% Overview:
% Humanoids need to be able to perform a large space of multi-contact motions. Or put another way, there needs to be reliable ways of generating whole-body multi-contact motions.
% This requires the robot to make contact with arbitrary links and have non-standard postures.
% While autonomous footstep planners have become capable of handling a variety of terrain, there remains to be an equivalent general planner for whole-body motions. One factor is the search space becomes considerably bigger. The other is that it becomes difficult to define what constitutes a ``good'' posture or contact set in general.
% The state-of-the-art teleoperation approaches focus on retargeting the operator's motion to the robot's motion. This may be limiting when specific posture is required, for instance a preferred joint position which cannot be easily mapped to a human or mass distribution of the robot does not match a human and results in motions that aren't feasible, or labelling of contact states.


% This paper addresses the problem of enabling humanoid robots to achieve non-gaited multi-contact motions such as crawling, bracing against a wall, standing up from a fall, rolling over, sit-to-stand, and so on. In gaited humanoid footstep planning, the decision space at a search node is often $SE(2)$ for flat ground \cite{chestnutt2005footstep} and $SE(3)$ for rough terrain \cite{deits2014footstep}. In such cases, the sequence of contacting bodies is dictated by the gait and a planner only determines the location of a given contact point. Conversely, for non-gaited contact planning the contact sequence needs to be determined by the planner, which significantly increases the dimensionality of the search space. For example, the decision space for flat ground becomes $n\times SE(2)$, where $n$ is the number of available contacting bodies.

% There are many approaches to solving this problem of dimensionality. One approach is to decompose the problem by first solving a "guide-path" for the root body \cite{bouyarmane2009potential, tonneau2018efficient} which can in turn be used as a heuristic to guide a low-level contact planner \cite{bouyarmane2011multi}. Another approach is to rely on sampling-based methods to determine feasible contact transitions and score them according to proximity to a goal. While these approaches can guarantee metrics such as collision-avoidance and static equilibrium, a major limitation is the difficulty to create general heuristics for natural gaits and posture.

% We present a framework designed to enable a human operator to determine contact sequences and posture while enforcing feasibility, such as collision-checking and static equilibrium. Our major contributions are:

% \begin{itemize}
%     \item An operator-driven framework for generating feasible and natural multi-contact trajectories.
%     \item Fast generation of contact and posture objectives through a virtual-reality interface.
%     \item Visual operator feedback of feasibility status.
% \end{itemize}
