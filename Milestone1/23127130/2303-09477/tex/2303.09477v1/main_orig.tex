\def\year{2022}\relax
%File: formatting-instructions-latex-2022.tex
%release 2022.1
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage{aaai22}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} % DO NOT CHANGE THIS
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in}  % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in}  % DO NOT CHANGE THIS
%
% These are recommended to typeset algorithms but not required. See the subsubsection on algorithms. Remove them if you don't have algorithms in your paper.
\usepackage{algorithm}
% \usepackage{algorithmic}
% \usepackage{algpseudocode}
\usepackage[noend]{algpseudocode} % The noend option will discard end of loop lines like end if, end for, end procedure, etc.

\usepackage[dvipsnames]{xcolor}

\newcommand{\rishi}[1]{\textcolor{purple}{#1}}
\newcommand{\methodname}{LoHA*}

\newcommand{\alg}[1]{\textsf{#1}}
\newcommand{\msf}[1]{\ensuremath{\mathsf{#1}}}
%
% These are are recommended to typeset listings but not required. See the subsubsection on listing. Remove this block if you don't have listings in your paper.
\usepackage{newfloat}
\usepackage{listings}
\lstset{%
	basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
	numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
	aboveskip=0pt,belowskip=0pt,%
	showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
%
%\nocopyright
%
% PDF Info Is REQUIRED.
% For /Title, write your title in Mixed Case.
% Don't use accents or commands. Retain the parentheses.
% For /Author, add all authors within the parentheses,
% separated by commas. No accents, special characters
% or commands are allowed.111111111111111
% Keep the /TemplateVersion tag as is
\pdfinfo{
/Title (Local Heuristic)
/Author (Rishi Veerapaneni, Maxim Likhachev)
/TemplateVersion (2022.1)
}

\usepackage{hhline} % RVAdded
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{placeins}
\usepackage{amsthm}
\usepackage{amssymb}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
% \newtheorem*{lemma}{Lemma}
% \usepackage{algpseudocode} % RVAdded
% DISALLOWED PACKAGES
% \usepackage{authblk} -- This package is specifically forbidden
% \usepackage{balance} -- This package is specifically forbidden
% \usepackage{color (if used in text)
% \usepackage{CJK} -- This package is specifically forbidden
% \usepackage{float} -- This package is specifically forbidden
% \usepackage{flushend} -- This package is specifically forbidden
% \usepackage{fontenc} -- This package is specifically forbidden
% \usepackage{fullpage} -- This package is specifically forbidden
% \usepackage{geometry} -- This package is specifically forbidden
% \usepackage{grffile} -- This package is specifically forbidden
% \usepackage{hyperref} -- This package is specifically forbidden
% \usepackage{navigator} -- This package is specifically forbidden
% (or any other package that embeds links such as navigator or hyperref)
% \indentfirst} -- This package is specifically forbidden
% \layout} -- This package is specifically forbidden
% \multicol} -- This package is specifically forbidden
% \nameref} -- This package is specifically forbidden
% \usepackage{savetrees} -- This package is specifically forbidden
% \usepackage{setspace} -- This package is specifically forbidden
% \usepackage{stfloats} -- This package is specifically forbidden
% \usepackage{tabu} -- This package is specifically forbidden
% \usepackage{titlesec} -- This package is specifically forbidden
% \usepackage{tocbibind} -- This package is specifically forbidden
% \usepackage{ulem} -- This package is specifically forbidden
% \usepackage{wrapfig} -- This package is specifically forbidden
% DISALLOWED COMMANDS
% \nocopyright -- Your paper will not be published if you use this command
% \addtolength -- This command may not be used
% \balance -- This command may not be used
% \baselinestretch -- Your paper will not be published if you use this command
% \clearpage -- No page breaks of any kind may be used for the final version of your paper
% \columnsep -- This command may not be used
% \newpage -- No page breaks of any kind may be used for the final version of your paper
% \pagebreak -- No page breaks of any kind may be used for the final version of your paperr
% \pagestyle -- This command may not be used
% \tiny -- This is not an acceptable font size.
% \vspace{- -- No negative value may be used in proximity of a caption, figure, table, section, subsection, subsubsection, or reference
% \vskip{- -- No negative value may be used to alter spacing above or below a caption, figure, table, section, subsection, subsubsection, or reference

\setcounter{secnumdepth}{1} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai22.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

% Title

% Your title must be in mixed case, not sentence case.
% That means all verbs (including short verbs like be, is, using,and go),
% nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while
% articles, conjunctions, and prepositions are lower case unless they
% directly follow a colon or long dash
\title{Local Heuristics and How to Use Them in Search-based Planning}
\author{
    %Authors
    % All authors must be in the same font size and format.
    Rishi Veerapaneni, Maxim Likhachev
}
\affiliations{
    %Afiliations
    % \textsuperscript{\rm 1} 
    Robotics Institute, Carnegie Mellon University \\
    \{rveerapa, mlikhach\}@andrew.cmu.edu
}

%Example, Single Author, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\iffalse
\title{My Publication Title --- Single Author}
\author {
    Author Name
}
\affiliations{
    Affiliation\\
    Affiliation Line 2\\
    name@example.com
}
\fi

\iffalse
%Example, Multiple Authors, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\title{My Publication Title --- Multiple Authors}
\author {
    % Authors
    First Author Name,\textsuperscript{\rm 1}
    Second Author Name, \textsuperscript{\rm 2}
    Third Author Name \textsuperscript{\rm 1}
}
\affiliations {
    % Affiliations
    \textsuperscript{\rm 1} Affiliation 1\\
    \textsuperscript{\rm 2} Affiliation 2\\
    firstAuthor@affiliation1.com, secondAuthor@affilation2.com, thirdAuthor@affiliation1.com
}
\fi


\begin{document}

\maketitle

\begin{abstract}
weoijoisjofslkflsjifjsoifsd
\end{abstract}

\section{Introduction}\label{sec:intro}
Motion planning is a field with many real world applications, including autonomous car navigation, robotic arm manipulation, and multi-agent warehouse autonomy. Heuristic search is a common deterministic motion planning class of algorithms that plans paths from start and goal positions by searching over different paths. Heuristic search algorithms use heuristics (along with other mechanisms) to speed up the path planning process.

The majority of heuristic search algorithms assume known environmental data (i.e. the graph) to compute valid/invalid nodes and edges for the search algorithm. Given this transition data, heuristic search algorithms can directly work on vastly different maps, i.e. heuristic search algorithms can generalize to new environments. Additionally heuristic search algorithms have strong theoretical guarantees of completeness and bounded suboptimality given enough computation time.


% However, most classical techniques do not use this data to inform their search in any other way. 

Modern machine learning techniques, e.g. reinforcement or imitation learning, on the other hand utilize observational data of the environment to determine paths. These methods can learn complex values and policies from raw input and perform well on environments similar to those seen during training, but generalizing to out-of-distribution maps remains a challenging problem. Most machine learning techniques also lack guarantees on completeness or solution quality.

Recent work have started to bridge the gap of heuristic search and machine learning by learning a neural network which returns a heuristic or policy (almost always a heuristic) that is used in a heuristic search algorithm (typically weighted A*). These methods show improvements in speed compared to heuristic search and improvements in success rate compared to pure machine learning. However, none address the generalization issues fundamental in using machine learning.


Our goal is to combine the best of two worlds of heuristic search's generalization and machine learning's speed up. Concretely, we would like a method that
1. Generalizes to new environments,
2. Uses environment data to speed up performance,
3. Maintains solution completeness and suboptimality guarantees.
We do this by introducing \methodname{} which learns neural network which returns a local heuristic that improves performance. We show that \methodname{} can generalize to new environments and speed up performance compared to pure heuristic search, all while maintaining suboptimality guarantees. Additionally, we show that \methodname{} generalizes better than just using machine learning.


Our main contributions are:
\begin{enumerate}
    \item Introducing \methodname{} which utilizes local features and successfully learns a local heuristic that \textit{generalizes across new environments} and speeds up planning by 2-4x node expansion reduction.
    \item Describing a general procedure for identifying domains where learning a local heuristic can produce speed-ups.
    \item Introducing and analyzing Non-Blocking Batch A*, a general suboptimal A* algorithm that computes states's heuristic value in batches to decrease the neural network forward pass overhead. Crucially NBBA* lazily updates heuristic values and does not block expansions of states without the expensive heuristic.
\end{enumerate}

\section{Related work}
There are several works that incorporate machine learning with search-based planning. We focus on deterministic planning algorithms as those are most relevant.
Readers interested in sampling-based approaches that attempt to use local features to speed up planning should look into \cite{chamzas2019local-experiences-for-global-motion-planning, sparkFlame2021, fire2022} which use prior experience and local features to inform local sampling distribution and speed up their sampling-based planning. 

The majority of prior works incorporating machine learning with search-based planning do so by attempting to directly learn the cost-to-go heuristic to the goal state. \cite{deepCubeA2019} and \cite{deepCubeAQ2021} learn such functions on a Rubik Cube and other combinatorial tasks (e.g. 24-tile problem, Sokoban) using reinforcement learning and is able to solve 100\% of their test configurations. \cite{deepCubeA2019} also introduces Batch Weighted A* which expands states in batches to speed up the use of neural networks, but does not enable bounded-suboptimality.
\cite{learningHeuristicA2020} learns a global heuristic function on \textit{one} single map and therefore only takes in start-goal locations (omitting the actual map data). \citep{learningGlobalHF2011} is an early work which uses curriculum learning and a small NN to learn global heuristics on different classical combinatorial problems (e.g. 3x3 Rubik Cube, 24-tile problem). 
For all these methods, it is unclear how their learnt heuristic would generalize to similar but different scenarios outside of their training distribution, e.g. a different goal Rubik Cube state, or similarly-generated but completely different maps. Our work aims to do more than just speed-up search by machine learning, but to do so in such a way that our model generalizes to different environments without additional training. 

A few other works attempt to use learning to speed up search by learning different metrics.
\citep{sail2017} learns a priority value off local features of the \textit{search state}, e.g. states on the closed list, which determines their expansion policy. On the other hand we learn a local heuristic based on local features, which allows our method to be useable across different search instantiations (e.g. different weights).
\citep{learnExpansionDelay2021} learns a map-specific inadmissible expansion delay heuristic that they shows speeds up search.

The closest prior work is \cite{scaleFree2021} which attempts to generalize across different distributions by using a scale-free attention network trained by imitation and curriculum learning that returns both an action probability distribution and cost-to-goal heuristic. They are able to achieve decent generalization which they attribute to their attention architecture and training curriculum.

We aim to generalize to different distributions using a completely different mechanism; limiting the learning problem to a ``local" sub-problem. Unlike all existing literature which attempts to directly predict the entire cost-to-goal heuristic or priority ordering, we attempt to only predict the cost to reduce the heuristic by a fixed amount K and look at a correspondingly small region of the environment. This enables us to generalize directly to completely different overall environments that consistent of similar local problems. Additionally, this can dramatically ease the learning problem by substantially reducing the required training dataset size, training time, and model size.

\section{Method}
% $$w_{so}$$
Our main insight is that instead of solving the entire shortest path problem, we can solve a significantly smaller local planning problem and combine that with our overall planning problem. 
Concretely, in heuristic search problems we are usually given a global consistent heuristic $h$ which predicts the entire cost to go. This global heuristic is usually based on a simplified abstracted state-space like a backwards Dijkstra's from the goal. Crucially, $h$ does not take into account the full dynamics of the robot and environment transition/obstacle data, as otherwise $h$ would be perfect and have solved the entire problem. This discrepancy between $h$ and the true model causes local optimums that slow down planning.


\subsection{Local Heuristic}
We propose to learn a local heuristic $h_{k}$ that takes full consideration of the robot dynamics and environmental obstacles to predict the cost to reduce $h$ by a hyper-parameter $K$. We then obtain a more informed heuristic $h'(s) = h_k(s) + [h(s) - K]$. Conceptually, the local heuristic can be thought of as learning a residual on top of the global heuristic which incorporates an informed local look-ahead.
Concretely, at a state $s$, $h_{NN}(s)$ takes in local environmental data $E_K(s)$ and global heuristic data $H_K(s)$ centered at a region around $s$ and predicts the minimum cost required to reduce the heuristic by at least $K$. 
Given a local region with $E_K(s)$ and $H_K(s)$, our value for $h_k(s)$ is 
\begin{equation} \label{equation:hl}
h_k(s) = \min_{s'}
\begin{cases}
    c(s,s') & h(s') \leq h(s) - K \\
    c(s,s') + [h(s') - (h(s)-K)]  & s' \in \text{Border}
    % \infty \\
\end{cases}
\end{equation}
To reach the goal, we must traverse through some state $s''$ with heuristic value $\leq h(s)-K$. $s''$ could be in the local region (top case). Or if $s''$ is outside the local region, then for each s' on the border, $h(s') - (h(s)-K)$ is the minimum additional cost to go from s' to s'', resulting in a total lower bound cost to s'' through s' of $c(s,s') + [h(s') - (h(s)-K)]$ (middle case).
To have the possibility of reaching the first case, our local region should ideally contain at least one state $s'$ with $h(s') \leq h(s) - K$.
% Crucially, these states to not need to be reachable; if none are reachable then we cannot reach the goal as we cannot even reach any intermediate $s'$ (bottom case).

We proceed to describe how our inputs look for our planning problem of a robotic $(x,y,\theta)$ system in a 2D environment.
Since the environment is 2D, $E_K(s)$ is a 2D image centered at state $s$.
We utilize a Manhattan heuristic for $h$ which can be thought of the solution for the simplified $(x,y)$ planning problem without obstacles. $H_K(s)$ is then also a 2D image centered at state $s$. 
Since we utilize a Manhattan heuristic, we are guaranteed that an image with width $K$ will contain states $s'$ with $h(s') \leq h(s) - K$. Therefore in our case, the size of our inputs are $2K+1$ square images centered at state $s$.

Now while running search, instead of using $h(s)$, we can compute $h_k$ and use $h'(s) = h_k(s) + [h(s) - K]$.


\subsection{Training Procedure}
We utilize supervised learning to train a model to learn $h_k$.
Equation \ref{equation:hl} describes $h_k$ as the minimum across states in the local region. We can efficiently search over this space by doing a Dijkstra or local A* search using $h$ and return early as soon as we find a state that satisfies Equation \ref{equation:hl} rather than searching the entire space. Now given a state $s$, we can quickly compute the true $h_k$ value.

\textbf{Collecting data:} A naive approach to collect training data would be to randomly sample states $s$. However, this may over and under sample regions in the state space that are not relevant during runtime. This distribution mismatch between training and runtime can hurt performance. We therefore collect training data by running normal A* and storing the inputs $s, H_k(s), E_k(s)$ and corresponding target value $h_k(s)$ of states $s$ we encounter during search.

\textbf{Neural network inputs:} We naively would feed $s, H_k(s), E_k(s)$ into the neural network. The state $s$ however is map specific; feeding $s$ into the neural network could prevent generalizing to new maps.
We observe that we can view the inputs from the robot's perspective at $s$.
In our $(x,y,\theta)$ set-up, this means we can omit $(x,y)$, and since $\theta \in [N,S,E,W]$, so we can rotate $H_k(s)$ and $E_k(s)$ to be from the robot's frame. Our input to the neural network is then just the rotated $H_k(s)$ and $E_k(s)$ 2D images, and the objective is to regress to $h_k$. We can utilize any architecture we desire, including Convolution Networks or flattening the input and using just fully connected layers.

\textbf{Loss function:} One issue we discovered when training our neural network is that regressing directly to $h_k$ caused issue when the range of $h_k$ is large. The regular mean square error objective prioritizes samples with larger values, reducing the prediction quality for many lower range values. An effective alternate we found was regressing to $\log(h_k+1)$ which is a measure of relative error but has better statistical properties than relative error or other alternatives \citep{relativeErrorLog}. The $+1$ is numerically required as $h_k$ can equal 0.


\section{Non-Blocking Bounded Batch A*}
Neural network inferences are known to be faster when computed on batches of inputs rather than computed many times individually. Recently, there have been several works that describe different ways for "Batch" A*. \citet{deepCubeA2019} describes "Batch Weighted A*", BWAS, which expands B states from their OPEN queue. This unfortunately does not maintain any suboptimality bounds with the inadmissible learnt heuristics. \citet{kfocal} improves upon BWAS by utilizing a $w_{so}$ bounded suboptimal Focal Search and expanding B nodes at once from the FOCAL queue, which maintains bounded suboptimality with the inadmissible learnt heuristic. Their method shows large runtime benefits by increasing the batch size B to decrease the runtime overhead. Another recent work \citet{optimalSearchNN} describes a batch A* mechanism that maintains optimality, but contains several restrictions on its use case as it requires an admissible learnt heuristic and a problem where many states may share the same heuristic values.

Our Non-Blocking Bounded Batch A* is closest to \citet{kfocal} as we utilize a $w_{so}$ bounded suboptimal search and an inadmissible heuristic. Our two key differences are that instead of expanding "B" states at once, we lazily compute the informed heuristic in batches and that we eliminate waiting by allowing expanding states without the informed heuristic. We show that these are required to sustain reduction in nodes generated and obtain speed-ups.
Additionally, we provide mathematical insight on how this batch mechanism affects performance with our neural network local heuristic.

\subsection{Performance degradation estimation}
As batch size increases, we expect some degradation in the number of nodes saved as we use the informed heuristic less frequently. However, it is unclear how exactly it will degrade. Our hypothesis is that we can model the degradation as a function involving "local optimum" size.

Let us call the set of nodes expanded by A* using $h$ as $V$, and the set of nodes expanded by A* using $h'$ as $V'$. The set of nodes saved $V_s$ is $V_s = V \setminus V'$. States $s \in V_s$ must be saved for two reasons and fall into two disjoint categories $V_{d\text{irect}} = OPEN \cap V_s$ and $V_{i\text{ndirect}} = V_s \setminus V_d$ correspondingly. States in $V_d$ have $h'(s) > h(s)$, i.e. the local heuristic must be returning a non-zero value increasing the priority of $s$ such that it is never the minimum in the queue and never gets expanded. States in $V_i$ are not expanded as they are not even placed in OPEN as all their ancestors fall into $V_d$, i.e. none of their ancestors are never expanded with $h'$ so the state itself will never be expanded.

Figure BLAH shows how a local optima region is divided into $V_d$ and $V_i$. The main insight is that we can view the behaviour on average of having multiple linear ordered $N_1, N_2, N_3, ..., N_{V_s/V_i}$ node regions and analyzing the effect of using NB3A* with a batchsize of B. For conceptual simplicity we assume in our analysis that expanding a state results in exactly $D$ additional nodes placed in the FOCAL list and subsequent batch waitlist. For analysis, we focus on counting the extra expansions of states in $L=V_s/V_d$.

% With $B \leq D$, when we expand the parent node which will add $D$ and result in $h'$ being batch evaluated on $N_1$. Therefore $N_1$ will not be expanded and we will expand no additional nodes.
% With $D < B \leq 2D$, there is a 1/2 probability for each node in FOCAL of having $h'$ evaluated before it gets expanded. Thus with $1/2$ we will expand $N_1$ and evaluate $N_2$, and with 1/2 we will evaluate $N_1$. Our additional expected expansion is $1/2$.

In general with batchsize $B$, we have a probability $1/(B/D)$ of expanding each node $N_i$. Let $F = B/D$. 
Our expected number of nodes expanded is:
% $$\sum_{i=0}^{\min(L,F)} \frac{1}{F}$$. 
\begin{equation}
\begin{cases}
\sum_{i=0}^{F} \frac{1}{F} = \frac{F}{2} & F \leq L \\
\sum_{i=0}^{L} \frac{1}{F} + (1-L/F)L = L - \frac{L^2}{2F} & F \geq L
\end{cases}
\end{equation}
Our ratio of additional used nodes is then $\frac{F}{2L}$ and $1 - \frac{L}{2F}$.

A planning instance will contain local regions of different sizes. From this analysis, we care mainly about the percent of local regions of size greater than F (which result in behaviour 1) and less than F (which result in behaviour 2). We expect that as B and F increases (F increases linearly with B), we should have more instances of the second case. 

\subsection{Predicted behaviours}
1. As B increases, we will move from the first regime to the second regime. Our performance degradation should be linear initially (1st regime) and then turn into a $1 - \frac{L}{2F}$ later. \\
2. If we imagine the local optimas as areas with $V_d$ corresponding to the circumference and $V_s$ corresponding to the entire area, our $L = V_s/V_d$ should increase proportionally to the square root of the area of the local optima. Concretely, increase local optima by a multiplicative factor of $\alpha$ should increase $L$ to $\sqrt{\alpha}L$. We predict the degradation should decrease proportionally. As the planning scenario increases the size of local optimas, $L$ should increase as in (2) and we should see a linear decrease in degradation. \\
3. As $K$ increases, the local optimum size the lookahead can avoid should generally increase. However it is unclear how $K$ affects the size of the region it can avoid (e.g. not clear from math if it should be linear). Our hypothesis is then that generally increasing $K$ should reduce the performance degradation. This is not necessarily intuitive as one could naively expect that performance degradation remains constant regardless of $K$ (their logic that with $K$ lookahead we save more nodes so increasing our batch size could hurt more). \\
4. Our analysis is agnostic to the frequency of local optimas; as the frequency of local optimas change, we expect no significant changes in degradation. This is slightly conterintuitive as without this analysis, one could expect a larger batch size to hurt more if there are more local optimas.



% L nodes in local optimum, with P "entry" points.
% L/P nodes per entry point.
% Compute LH every Q times, with Q=B/A. 
% Each entry point will result in extra expansions until Q. So sort of Q extra expansions.
% If Q $<$ L/P, then before we do 0 expansions (L/P savings) per entry. Now we do Q expansions per entry (L/P-Q savings).
% If Q $<=$ L/P, then we sort of fill up the local optimum too fast.

% Let L/P = some constant C.
% According to this math, our decrease in savings is now (C-B/A)/C = 1 - B/(A*C). As B increases, our savings should linearly decrease until B/A $>= C$, i.e. B $>=$ A*C when we should be the same as no local heuristic.
% We can test this out by running SBWA* and seeing if our savings linearly decreases as B increases.

\section{Local Heuristic Experimental Results}


\subsection{Determining if/when Local Heuristic is Useful}
Show plots using true local heuristic and how it reduces node expansions. Show how the time to compute lookahead increases as K increases. Can also show a noisy heuristic does not reduce the improvement as much.

\subsection{Learning a Local Heuristic}
Show that we can learn it easily.
Show that it can generalize to test set.

\subsection{Using learnt heuristic}
Show that we can use it effectively.

\subsection{Weighted Search with Local Heuristic}
Talk about semi-double penalizing the look ahead. We can ``correct" the f-value by not incorporate it in the weight. Each new f-value is the best f-value of children in the future, so we are essentially forward propagating those values early in search.

\section{NB3A* Experimental Results}
\subsection{Variants/Baselines}
Show non-blocking version and how that doesn't work well.

\subsection{Batch performance degradation}
Show how increasing the batch size increases nodes expanded as expected. \cite{optimalSearchNN} shows a similar relationship without explanations while \cite{kfocal} shows an opposite relationship for Rubik Cube. 

\subsection{Predicted vs Actual behaviour}
Describe modelling the problem and solving it via non-linear least squares estimation.

1. We seems to see a linear and then 1-L/2F relationship. \\
2. We do not observe a linear change as the local optimum increases. \\
3. We see that as K increases, our predicted C increases. Increase is not linear and changes per environments in a way that seems reasonably consistent with the environment and our expectations. \\
4. Roughly matches expectations with no large difference between changes in frequency. \\


\section{Limitation, Future Work, and Conclusion}


\clearpage
\bibliography{ref} 

\end{document}
