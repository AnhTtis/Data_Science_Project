{
    "arxiv_id": "2303.15940",
    "paper_title": "TransAudio: Towards the Transferable Adversarial Audio Attack via Learning Contextualized Perturbations",
    "authors": [
        "Qi Gege",
        "Yuefeng Chen",
        "Xiaofeng Mao",
        "Yao Zhu",
        "Binyuan Hui",
        "Xiaodan Li",
        "Rong Zhang",
        "Hui Xue"
    ],
    "submission_date": "2023-03-28",
    "revised_dates": [
        "2023-03-29"
    ],
    "latest_version": 1,
    "categories": [
        "cs.SD",
        "eess.AS"
    ],
    "abstract": "In a transfer-based attack against Automatic Speech Recognition (ASR) systems, attacks are unable to access the architecture and parameters of the target model. Existing attack methods are mostly investigated in voice assistant scenarios with restricted voice commands, prohibiting their applicability to more general ASR related applications. To tackle this challenge, we propose a novel contextualized attack with deletion, insertion, and substitution adversarial behaviors, namely TransAudio, which achieves arbitrary word-level attacks based on the proposed two-stage framework. To strengthen the attack transferability, we further introduce an audio score-matching optimization strategy to regularize the training process, which mitigates adversarial example over-fitting to the surrogate model. Extensive experiments and analysis demonstrate the effectiveness of TransAudio against open-source ASR models and commercial APIs.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.15940v1"
    ],
    "publication_venue": null
}