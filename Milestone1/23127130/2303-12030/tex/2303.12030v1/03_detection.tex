\section{What is a Detection?} 
\label{sec:what_is_a_detection}

% General Background
The data post-processing routine combines the sequence of individual observations taken over the course of one night into a single image. In this residual image potential planet candidates appear as bright spots. A priori, we do not know if a bright spot is actually a planet, and the decision of whether it is bright enough to be counted as a detection is always a balancing of the risk that it is just part of the noise.
In order to quantify this risk, we use hypothesis testing. The classical approach based on the t-test \citep[for a general background on hypothesis testing and the t-test see Chapter 9 of][]{larsenIntroductionMathematicalStatistics2012} was introduced by \cite{mawetFUNDAMENTALLIMITATIONSHIGH2014} and is illustrated in Figure \ref{fig:hypothesis_testing}. The test procedure can be split into three main steps:

% Step 1:
In the first step, we extract values for the noise and the potential planet. It is important that the noise is taken from positions that are representative for the noise we expect at the position of the signal. A common approach is to use noise with the same separation from the star. Further, noise and signal must be extracted in the same way, ideally independent of the resolution of the detector.
%
This can be done by averaging pixel values inside apertures of $1 \lambda / D$ diameter. The result are two samples: the noise sample $\mathcal{X} = \{\overline{X}_1, ..., \overline{X}_n \}$ and the planet sample $\mathcal{Y} = \{\overline{Y}_1 \}$. Note, that the planet sample only contains a single observation.

% Step 2:
% two sample test in general
% Introduce the general problem: We have observations: 1. a planet sample 2. a noise sample; We want to make a statement about the underlaying distributions' expected values.
In the next step, two competing hypotheses are formulated: first, that our observation can be explained without the presence of a planet. This is the \emph{null hypothesis} $H_0$. Second, the hypothesis that our observation is indeed attributable to the existence of a planet. This is the \emph{alternative hypothesis} $H_1$. 
%
% Test for differences in means -> signal present vs signal absent
% The concrete Version in Mawet et al
In order to decide which of the two hypotheses to favor we need to make assumptions and explicitly formulate $H_0$ and $H_1$. The t-test assumes that our observations are drawn independent and identically distributed (i.i.d) from normal distributions $\{\overline{X}_1, ..., \overline{X}_n \} \sim \mathcal{N}(\mu_\mathcal{X}, \sigma_\mathcal{X})$, $\{\overline{Y}_1\} \sim \mathcal{N}(\mu_\mathcal{Y}, \sigma_\mathcal{Y})$ where the parameters $\mu_\mathcal{X}, \mu_\mathcal{Y}, \sigma_\mathcal{X}, \sigma_\mathcal{Y}$ are unknown. In addition, it is assumed that the distributions of the signal and the noise have the same variance\footnote{
% why the assumption about similar variance might be valid
Note, that the value of $\overline{Y}_{1}$ is not just the pure planet signal but also contains speckle noise: $\overline{Y}_{1} = S_{\text{planet}} + \overline{X}_{n+1}$ where $S_{\text{planet}}$ is the contribution of the planet signal and $\overline{X}_{n+1}$ is the speckle noise at the position of the planet. We can describe $S_{\text{planet}}$ as Poisson (photon shot noise) and keep the Gaussian assumption for $\overline{X}_{n+1}$. The resulting probability density function (PDF) for $\overline{Y}_{1}$ is then the convolution of the Poisson PDF with the Gaussian PDF \citep[Theorem 5.2.9 in][]{casellaStatisticalInference2002}. Thus, by assuming equal variance, we assume that the effect of photon shot noise is negligible compared to the speckle noise.} $\sigma_\mathcal{X} = \sigma_\mathcal{Y}=\sigma$.
%
In case no planet is present we would expect that $\mathcal{X}$ and $\mathcal{Y}$ originate from the same distribution. Thus, we can formulate $H_0: \mu_\mathcal{X} = \mu_\mathcal{Y}$. In case a planet is present we expect $\mathcal{Y}$ to be brighter than $\mathcal{X}$. This gives us $H_1: \mu_\mathcal{X} < \mu_\mathcal{Y}$. 
%
%Note, any difference in means greater than zero $\delta_\mu = \mu_Y - \mu_X >0$ is counted as a detection. 
%
% What influences our certainty about the differences in means?
A closer look at step 2 in Figure \ref{fig:hypothesis_testing} shows that $H_0$ becomes unlikely as the distance between the noise observations (blue crosses) and planet observation (orange cross) increases and the variance of the noise sample decreases.
%
% Step 3:
We can quantify this effect using the \textit{test statistic} of the two sample t-test \citep{mawetFUNDAMENTALLIMITATIONSHIGH2014}

\begin{equation}
\label{eq:SNR}
	T = \frac{\hat{\mu}_\mathcal{Y} - \hat{\mu}_\mathcal{X}}{\hat{\sigma}_{\mathcal{X}}\sqrt{1 + 1/n}} \,.
\end{equation}
The equation is simplified for the special case in HCI where $\mathcal{Y}$ contains only a single value. The mean estimates of the signal and noise sample are denoted as $\hat{\mu}_\mathcal{Y}=\overline{\mathcal{Y}} = \overline{Y}_1$ and $\hat{\mu}_\mathcal{X}=\overline{\mathcal{X}}$, while $\hat{\sigma}_\mathcal{X}$ is the Bessel corrected standard deviation of $\mathcal{X}$.
%The pooled sample standard deviation $\hat{\sigma}_{X, Y}$ can be calculated by:
%\begin{equation}
%	\hat{\sigma}^2_{X, Y} =  \frac{(n-1)\hat{\sigma}_X^2 + (m-1)\hat{\sigma}_Y^2}{n+m-2}
%\end{equation}
%
Under $H_0$ and if $\hat{\mu}_\mathcal{X}$ and $\hat{\mu}_\mathcal{Y}$ follow a normal distribution, $T$ follows a student t-distribution with $\nu=n-1$ degrees of freedom. The t-distribution does not depend on the unknown parameters $\mu_\mathcal{X}, \mu_\mathcal{Y}, \sigma$. This allows us to compute the \textit{detection uncertainty} by

\begin{equation}
	\label{eq:FPF_ttest}
	\text{FPF} = \int_{T_{\text{obs}}}^{\infty} p(T = t | H_0) \,d x \,,
\end{equation}
where $T_{\text{obs}}$ denotes the value of $T$ that we compute for our observation and $p(T = t | H_0)$ is the probability density function of the t-distribution.
%
The false-positive-fraction (FPF) gives the risk that we reject $H_0$ in favor of $H_1$ although no planet is present. In panel 3 of \mbox{Figure \ref{fig:hypothesis_testing}} we obtain $T_{\text{obs}} = 2.28$ which corresponds to an $\text{FPF}=0.0243$. That is, in $2.43\%$ of the cases in which no planet is present we get a $T_{\text{obs}} \geq 2.28$. If the calculated FPF is below a previously defined detection threshold we treat our observation as a detection. Since small values of the FPF quickly become difficult to read, we use the following notation in this paper:
\begin{equation}
	x \, \sigma_{\mathcal{N}} := 1 - \Phi(x) = \text{FPF}
\end{equation}
where $\Phi$ is the cumulative density function of the standard normal distribution. That is, we express the FPF values in terms of the quantiles of the standard normal distribution $x$. For example we write $5\sigma_{\mathcal{N}}$ for $\text{FPF}=2.87 \times 10^{-7}$ and $3\sigma_{\mathcal{N}}$ for $\text{FPF}=1.25 \times 10^{-3}$. Note, $\sigma_{\mathcal{N}}$ should not to be confused with $\hat{\sigma}_{\mathcal{X}}$.

% Difference between noise and statistics distribution
It is crucial to distinguish between the assumed distribution of the noise (Gaussian) and the distribution of the test statistic (t-distribution). The t-distribution does not describe the nature of the noise but the effect of the sample size. 
%
For small $n$ the values of $\hat{\mu}_\mathcal{X}$,  $\hat{\mu}_\mathcal{Y}$ and $\hat{\sigma}_{\mathcal{X}}$ are less accurate w.r.t. the true but unknown parameters $\mu_\mathcal{X}$,  $\mu_\mathcal{Y}$ and $\sigma$. This uncertainty is compensated by the heavier tails of the t-distribution for small $\nu$. 
%
% relationship to classical SNR
For $n \rightarrow \infty$ Equation \ref{eq:SNR} converges to the classical definition of the signal-to-noise ratio (SNR) \citep[compare e.g.][]{meshkatFURTHEREVIDENCEPLANETARY2013} and the t-distribution converges to the normal distribution. 
%
In this limit we obtain the classical false alarm probabilities of $\text{FPF}=2.87 \times 10^{-7}$ for $T=5$ and $\text{FPF}=1.25 \times 10^{-3}$ for $T=3$. 
%
% SNR vs FPF: Why one should report confidence levels not SNR
Note that the factor $1 / \sqrt{1 + 1/n}$ in Equation \ref{eq:SNR} is not a correction for the classical SNR in case of small sample sizes. It is a normalization that ensures that $p(T = t | H_0)$ follows a standard t-distribution. The small sample size at inner radii affects both, the value of $T_{\text{obs}}$ as well as the shape of the t-distribution. Any value of $T_{\text{obs}}$ or SNR is meaningless if we do not consider the sample size and underlying  assumptions of the test. For example at $2 \lambda /D$ we need $ T_{\text{obs}}\geq 11.2$ for a $5\sigma_{\mathcal{N}}$ detection while at $10 \lambda /D$ a value of $ T_{\text{obs}}\geq5.6$ is sufficient. Therefore, any detection threshold should be specified as a FPF and not in terms of $T_{\text{obs}}$ nor SNR. 
