\section{Pivot for the Laplace Distribution}
\label{sec:pivot_proof}
Let $Z$ be a random variable following a standard distribution with no unknown parameters (e.g. a standard Gaussian or Laplacian). The random variables $X = Z q_\mathcal{X} + w_\mathcal{X} \sim \mathcal{F}(q_\mathcal{X}, w_\mathcal{X})$ and $Y = Z q_\mathcal{Y} + w_\mathcal{Y} \sim \mathcal{F}(q_\mathcal{Y}, w_\mathcal{Y})$ with ${w_\mathcal{X}, w_\mathcal{Y} \in \mathbb{R}}$ and ${q_\mathcal{X}, q_\mathcal{Y} \in \mathbb{R}^+}$ from a location-scale family of $Z$. In case of the normal distribution $Z \sim \mathcal{N}(0, 1)$ with $q = \sigma, t=\mu$ and $Z \sim \mathcal{L}(0, 1)$ with $q = b, w=\mu$ for the Laplacian distribution.

%
We consider a two sample dataset $\mathcal{X} = {X_1, ..., X_n} \sim \mathcal{F}(q_\mathcal{X}, w_\mathcal{X})$ and $\mathcal{Y} ={Y_1, ..., Y_m} \sim \mathcal{F}(q_\mathcal{Y}, w_\mathcal{Y})$ under the assumption of equal scale ${q_\mathcal{X} = q_\mathcal{Y} = q}$. We want to test the null hypothesis ${H_0: w_\mathcal{X} - w_\mathcal{Y} = 0}$ against the alternative ${H_1: w_\mathcal{Y} - w_\mathcal{X} > 0}$ using the test statistic of the two sample t-test (c.f. Equation \ref{eq:SNR} for the special case of $m=1$ used in HCI):

\begin{equation}
T = \frac{\hat{\mu}_\mathcal{Y} - \hat{\mu}_\mathcal{X}}{\hat{\sigma}_{\mathcal{X}, \mathcal{Y}} \sqrt{1/n + 1/m}}
\end{equation}
where $\hat{\mu}_\mathcal{X}$ and $\hat{\mu}_\mathcal{Y}$ are the sample averages:

\begin{equation}
	\hat{\mu}_\mathcal{X} = \overline{\mathcal{X}} =\frac{1}{n} \sum_{i=1}^{n} X_i \qquad \hat{\mu}_\mathcal{Y} = \overline{\mathcal{Y}} = \frac{1}{m} \sum_{j=1}^{m} Y_j
\end{equation}
and $\hat{\sigma}_{\mathcal{X}, \mathcal{Y}}$ is the pooled standard deviation of the two samples:

\begin{equation}
	\hat{\sigma}_{\mathcal{X}, \mathcal{Y}}^2 = \frac{(n-1)\hat{\sigma}_{\mathcal{X}}^2 + (m-1)\hat{\sigma}_{\mathcal{Y}}^2}{n+m-2}
\end{equation}
with

\begin{eqnarray}
	\hat{\sigma}_{\mathcal{X}}^2 &= \frac{1}{n-1}\sum_{i=1}^n \left(X_i - \overline{\mathcal{X}}\right)^2 \\ \hat{\sigma}_{\mathcal{Y}}^2 &= \frac{1}{m-1}\sum_{j=1}^m \left(Y_j - \overline{\mathcal{Y}}\right)^2
\end{eqnarray}
Under $H_0$ the test statistic $T$ follows a distribution that is independent of the parameters $w_\mathcal{X}, w_\mathcal{Y}, q$, i.e. it is a pivot. The following proof is inspired by exercise 9.9 in \cite{casellaStatisticalInference2002}.

\textbf{Proof:}
\begin{align*}
	\hat{\sigma}_{\mathcal{X}}^2 
	&= \frac{1}{n-1} \sum_{i=1}^n \left(Z_i q_\mathcal{X} + w_\mathcal{X} - \overline{Z} q_\mathcal{X} - w_\mathcal{X} \right)^2 \\
	&= \frac{q_\mathcal{X}^2}{n-1} \sum_{i=1}^n \left(Z_i - \overline{Z}\right)^2 \\
	&= q_\mathcal{X}^2 \hat{\sigma}_{Z_n}^2
\end{align*}
The same holds for $\hat{\sigma}_{\mathcal{Y}}^2 = q_\mathcal{Y}^2\hat{\sigma}_{Z_m}^2$. With $q_\mathcal{X} = q_\mathcal{Y} = q$ it follows:

\begin{align*}
	\hat{\sigma}_{\mathcal{X}, \mathcal{Y}}^2 
		&= \frac{q^2(n-1)\hat{\sigma}_{Z_n}^2 + q^2(m-1)\hat{\sigma}_{Z_m}^2}{n+m-2} \\
		&= q^2 \hat{\sigma}_{Z_n Z_m}^2
\end{align*}
We re-write the test statistic $T$:

\begin{align*}
	T &= \frac{\frac{1}{n} \sum_{i=1}^{n} X_i - \frac{1}{m} \sum_{j=1}^{m} Y_j}
			  {\hat{\sigma}_{\mathcal{X}, \mathcal{Y}} \sqrt{(1/n + 1/m)}}\\
		&= \frac{\frac{1}{n} \sum_{i=1}^{n} \left(Z_i q + w_\mathcal{X} \right)  - \frac{1}{m} \sum_{j=1}^{m} \left(Z_j q + w_\mathcal{Y}\right)}
		{\hat{\sigma}_{\mathcal{X}, \mathcal{Y}} \sqrt{(1/n + 1/m)}} \\
		&=\frac{q \left(\frac{1}{n}\sum_{i=1}^{n} Z_i - \frac{1}{m}\sum_{j=1}^{m} Z_j\right)}{q \hat{\sigma}_{Z_n Z_m} \sqrt{(1/n + 1/m)}} + \frac{w_\mathcal{X} - w_\mathcal{Y}}{q \hat{\sigma}_{Z_n Z_m} \sqrt{(1/n + 1/m)}}
\end{align*}
Under $H_0$ we have $w_\mathcal{X} = w_\mathcal{Y}$. It follows:

\begin{equation}
	T=\frac{\overline{Z_n} - \overline{Z_m}}{\hat{\sigma}_{Z_n Z_m} \sqrt{(1/n + 1/m)}}
\end{equation}
All  quantities $\overline{Z_n}, \overline{Z_m}, \hat{\sigma}_{Z_n Z_m}$ are independent of $w_\mathcal{X}, w_\mathcal{Y}, q$. $\blacksquare$