\section{Discrete Haar Basis}\label{sec:haarbasis}
The $2^k\times 2^k$ discrete Haar basis matrix $\mm{A}_k$ is defined recursively with $\mm{A}_0 = [1]$ and 
\begin{equation}\label{eq:haardef}
\mm{A}_k = \begin{bmatrix}\mm{A}_{k-1} & \mm{I}_{2^{k-1}}\\\mm{A}_{k-1} & -\mm{I}_{2^{k-1}} \end{bmatrix},    
\end{equation}
where $\mm{I}_{2^{k-1}}$ is the $2^{k-1} \times 2^{k-1}$ identity matrix. This matrix arises from the following tree structure. Construct a depth $k$ perfect binary tree, and let $r$ be an additional node. We make the root of the perfect binary tree the left child of $r$, and $r$ becomes the root of our tree. Every non-leaf node represents a column in the matrix while every root-to-leaf path corresponds to a row in the matrix. Whenever the path proceeds down the left child from some node $i$, entry $i$ of the corresponding row will have value $+1$. If instead the path proceeds down the right child of $i$, entry $i$ of the corresponding row will have value $-1$. Thus every row will have $k$ non-zero entries. It is also not hard to show that, for any $\pm 1$ coloring of the columns, there is a row whose nonzero entries are equal to the corresponding column colors, and, therefore, $\disc(\mm{A}_k) = k$. Kunisky~\cite{kunisky2023discrepancy} describes this in detail.

In addition, we define the $\{0,1\}^{2^k\times 2^k}$ matrices $\mm{A}_k^+$ and $\mm{A}_k^-$ to be the indicator matrices of the positive and negatives elements of $\mm{A}_k$ respectively. Here an \emph{indicator matrix} will have one in some entry if and only the corresponding entry of $\mm{A}_k$ is non-zero and positive, in the case of $\mm{A}_k^+$, or negative, in the case of $\mm{A}_k^-$. Note that $\mm{A}_k = \mm{A}_k^{+} - \mm{A}_k^{-}$. Finally define, 
\begin{equation}\label{eq:haar-indicators}
    \mm{A}_k^{\pm}\coloneqq \begin{pmatrix}\mm{A}_k^{+}\\\mm{A}_k^{-}\end{pmatrix}.
\end{equation}
We bound the hereditary discrepancy to determinant lower bound ratio for both $\mm{P}_N \otimes \mm{A}_k$ and $\mm{P}_N \otimes \mm{A}_k^{\pm}$.

\begin{theorem}\label{thm:kunisky-ratio}
    For the power matrix $\mm{P}_N$, the discrete Haar basis $\mm{A}_k$, and the stacked indicator matrix $\mm{A}_k^{\pm}$ as defined in equation~\eqref{eq:haar-indicators},
    \begin{align}
        \frac{\herdisc\left(\mm{P}_{N}\otimes\mm{A}_k\right)}{\detlb\left(\mm{P}_{N}\otimes\mm{A}_k\right)} &\gtrsim \sqrt{N\cdot k}, \label{eq:kunisky-ratio}\\
        \frac{\herdisc\left(\mm{P}_{N}\otimes\mm{A}_k^{\pm}\right)}{\detlb\left(\mm{P}_{N}\otimes\mm{A}_k^{\pm}\right)} &\gtrsim \sqrt{N\cdot k} \label{eq:haar-indicator-ratio}.
    \end{align}
\end{theorem}
\begin{proof}
First we apply the proof structure described in the previous section to $\mm{A}_k$. In particular, we show that $\detlb(\mm{A}_k) = O(1)$ in Lemma~\ref{lem:ub-kunisky-detlb} and that $\disc_1(\mm{A}_k) \gtrsim \sqrt{k}$ in Lemma~\ref{lem:lb-kunisky-disc1}. Applying Lemma~\ref{lem:detlb-amplification} to the first result and Lemma~\ref{lem:disc-amplification} to the second, we have that $\detlb\left(\mm{P}_{N}\otimes\mm{A}_k\right) \lesssim \sqrt{N}$ and $\disc\left(\mm{P}_{N}\otimes\mm{A}_k\right) \gtrsim N\cdot\sqrt{k}$. It follows that 
\[\frac{\herdisc\left(\mm{P}_{N}\otimes\mm{A}_k\right)}{\detlb\left(\mm{P}_{N}\otimes\mm{A}_k\right)} \geq \frac{\disc\left(\mm{P}_{N}\otimes\mm{A}_k\right)}{\detlb\left(\mm{P}_{N}\otimes\mm{A}_k\right)} \gtrsim \sqrt{N\cdot k}.\]   
The process for $\mm{A}_k^{\pm}$ is similar. To show an upper bound on $\detlb(\mm{A}_k^{\pm})$, use Corollary~\ref{cor:haar-decomp} where $\mm{A}_k^+$ and $\mm{A}_k^-$ are shown to be TUM. Since the determinant of any square submatrix of either matrix is at most one in absolute value, we can apply Lemma 4 of~\cite{matouvsek2013determinant} to $\mm{A}_k^+$ and $\mm{A}_k^-$ to obtain $\detlb(\mm{A}_k^{\pm}) = O(1)$. To obtain the lower bound on $\disc_1(\mm{A}_k^{\pm})$, we will recall that $\disc_1(\mm{A}_k) \gtrsim \sqrt{k}$ from Lemma~\ref{lem:lb-kunisky-disc1}. Note that, for any \(\mm{x} \in \{-1, +1\}^{2^k}\), by the triangle inequality
\[
\frac{1}{2^k}\|\mm{A}_k\mm{x}\|_1 
= \frac{1}{2^k}\|(\mm{A}_k^+ - \mm{A}_k^-) \mm{x}\|_1 
\le 2\left(\frac{1}{2^{k+1}}\|\mm{A}_k^+\mm{x}\|_1 + \frac{1}{2^{k+1}}\|\mm{A}_k^-\mm{x}\|_1\right).
\]
Therefore, $\disc_1(\mm{A}_k^{\pm}) \gtrsim \sqrt{k}$ as well. Apply Lemma~\ref{lem:detlb-amplification} and Lemma~\ref{lem:disc-amplification} to $\detlb(\mm{A}_k^{\pm}) = O(1)$ and $\disc_1(\mm{A}_k^{\pm 1}) \gtrsim \sqrt{k}$ respectively to obtain equation~\eqref{eq:haar-indicator-ratio}.
\end{proof}

\begin{lemma}\label{lem:ub-kunisky-detlb}
    $\detlb(\mm{A}_k) \leq 2$.
\end{lemma}
\begin{proof}
We show that any $i \times i$ square submatrix $\mm{B}$ of $\mm{A}_k$ satisfies $|\det(\mm{B})| \leq 2^{i}$. First, define $M_{k}(i) \coloneqq \max_{\mm{B}}|\det(\mm{B})|$ where the maximum is taken over all $i\times i$ submatrices $\mm{B}$ of $\mm{A}_k$. We compute $M_{k}(i)$ recursively by considering the forms that all $i\times i$ submatrices of $\mm{A}_k$ can take:
\begin{enumerate}
    \item $\mm{B}$ only contain elements from the first $2^{k-1}$ columns of $\mm{A}_k$,
    \item $\mm{B}$ only contain elements from the second $2^{k-1}$ columns of $\mm{A}_k$, or
    \item $\mm{B}$ contain elements from both the first and second $2^{k-1}$ columns of $\mm{A}_k$.
\end{enumerate}
We use the recursive formula \eqref{eq:haardef} to analyze these cases.
In the first case the resulting submatrix is either entirely contained in $\mm{A}_{k-1}$ up to rearranging rows, or contains a duplicated row. The magnitude of the determinant of these submatrices can be bounded above by $M_{k-1}(i)$ and $0$, respectively. In the second case we note that the submatrix is TUM. To see this, recall that the second $2^{k-1}$ columns of $\mm{A}_k$ consist of an identity matrix and its negation stacked on top of one another. Any square submatrix is entirely contained in the identity matrix or contains duplicated (and negated) rows. Thus the absolute value of the determinant of this kind of submatrix is at most one. It remains to consider the third case. Let $\mm{B}$ be a submatrix of $\mm{A}_k$ with some $j$ columns coming from the second $2^{k-1}$ columns of $\mm{A}_k$ for $1 \leq j < i$. For any such column there is either one or two non-zero entries, equal to $1$ or $-1$. If there is only one non-zero entry, then this reduces to computing $M_k(i-1)$ since we can perform a co-factor expansion on this column. If there are two non-zero entries, then we can permute the rows so that they are adjacent. This only changes the sign of the resulting determinant. Notice that the two rows are identical except for the sign of the non-zero entries. When performing a co-factor expansion on these two entries, the $(i-1)\times(i-1)$ submatrix that results when removing either row and the column is identical. Thus $|\det(\mm{B})|$ is at most twice the absolute value of the determinant of this $(i-1)\times(i-1)$ submatrix. After removing all the columns and associated rows of $\mm{B}$ from the second half of $\mm{A}_k$ in this way, we see that $|\det(\mm{B})| \leq 2^{j}M_{k-1}(i-j)$. Since, in the base case, $M_0(1) = 1$, the claim follows.
\end{proof}
Using a similar argument as above, we can show that the matrices $\mm{A}_k^+$ and $\mm{A}_k^-$ are TUM. Note that, using \eqref{eq:haardef}, $\mm{A}_k^+$ and $\mm{A}_k^-$ can be recursively defined as $\mm{A}_0^+ = [1]$, $\mm{A}_0^- = [0]$, and
\begin{equation}\label{eq:recursive-def-signed-id}
    \mm{A}_k^+ = \begin{bmatrix}
        \mm{A}_{k-1}^+ & \mm{I}_{2^{k-1}}\\
        \mm{A}_{k-1}^+ & \mm{0}
    \end{bmatrix}
    \qquad
    \mm{A}_k^- = \begin{bmatrix}
        \mm{A}_{k-1}^- & \mm{0}\\
        \mm{A}_{k-1}^- & \mm{I}_{2^{k-1}}
    \end{bmatrix},
\end{equation}
where $\mm{0}$ is the all zeros matrix of appropriate dimension, and $\mm{I}_{2^{k-1}}$ is the $2^{k-1}$ by $2^{k-1}$ identity matrix.

\begin{corollary}\label{cor:haar-decomp}
    $\mm{A}_k^+$ and $\mm{A}_k^-$ are TUM matrices where $\mm{A}_k^+$ and $\mm{A}_k^-$ are indicators of the positive and negatives entries of $\mm{A}_k$, respectively.
\end{corollary}
\begin{proof}
    We only consider $\mm{A}_k^+$ as the proof that $\mm{A}_k^-$ is a TUM matrix is similar. The proof proceeds by induction on $k$. Consider some $i \times i$ submatrix $\mm{B}$ of $\mm{A}_k^+$. If $\mm{B}$ is entirely contained in first half of the columns of $\mm{A}_k^+$, then we are done by the inductive hypothesis; if $\mm{B}$ is entirely contained in the second half of the columns of $\mm{A}_k^+$, then $\mm{B}$ is a submatrix of the identity matrix or has a row of $0$'s, and the absolute value of its determinant is at most $1$. Thus it suffices to consider the case where $\mm{B}$ has some columns from the first half of $\mm{A}_k^+$ and some columns from the second half of $\mm{A}_k^+$. Since any column from the second half has only one non-zero entry, equal to $1$, performing  co-factor expansions on the columns in the second half shows that the absolute value of the determinant will only be as large as the absolute value of the determinant of some smaller square sub-matrix in $\mm{A}_{k-1}^+$. Note that in the base case, $|\det(\mm{A}_0^+)| = 1$.
\end{proof}

\begin{lemma}\label{lem:lb-kunisky-disc1}
$\disc_1(\mm{A}_k) = \frac{k+1}{2^{k}}\binom{k}{\floor{(k+1)/2}} \cong \sqrt{k}$.
\end{lemma}
\begin{proof}
The proof for $k = 0$ is trivial, so we focus on the case $k \ge 1$. Let $\tilde{\mm{A}}_k$ denote the $2^k \times (2^k - 1)$ matrix equal to $\mm{A}_k$ with the first column, all of whose entries are $1$, removed. Note that this is equivalent to removing the root node $r$ and keeping only the perfect binary tree of depth $k$ in the tree structure of the Haar basis, as described at the beginning of the section. \modified{We have the following key claim.}

\begin{claim}\label{claim:haar-permute}
    For any $\mm{x} \in \{\pm 1\}^{2^k - 1}$ there exists a permutation which maps the entries of $\tilde{\mm{A}}_k\mm{x}$ to those of $\tilde{\mm{A}}_k\mathbf{1}$. 
\end{claim}
\begin{proof}
Our proof is by induction on $k$. When $k = 1$,we have a root node with two children corresponding to the matrix
\[
\tilde{\mm{A}}_1 = \begin{bmatrix}
1\\
-1
\end{bmatrix}.
\]
 When $\mm{x} = [1]$, $\tilde{\mm{A}}_1\mm{x} = \tilde{\mm{A}}_1\mathbf{1}$ and the identity permutation suffices; when $\mm{x} = [-1]$, $\tilde{\mm{A}}_1\mm{x} = -\tilde{\mm{A}}_1\mathbf{1}$ and it suffices to swap the two entries.

Consider some height $k$ perfect binary tree corresponding to $\tilde{\mm{A}}_k$. Let $u$ be the root of the tree with left and right children $u_+$ and $u_-$ respectively. Since every root-to-leaf path must go through $u_+$ or $u_-$, this forms a partition of the rows of $\tilde{\mm{A}}_k$. In particular, we can rearrange $\tilde{\mm{A}}_k$ as
\[\tilde{\mm{A}}_k = \begin{bmatrix}
    \mathbf{1} & \tilde{\mm{A}}_{k-1} & \mm{0}\\
    -\mathbf{1} & \mm{0} & \tilde{\mm{A}}_{k-1} 
\end{bmatrix}.\]
Consider the $\tilde{\mm{A}}_{k-1}$ submatrices which appear in $\tilde{\mm{A}}_{k}$. The $\tilde{\mm{A}}_{k-1}$ submatrix in the first $2^{k-1}$ rows has rows which correspond to root-to-leaf paths with leaves in the subtree rooted at $u_+$. Its columns correspond to nodes in the same subtree. The $\tilde{\mm{A}}_{k-1}$ submatrix in the second $2^{k-1}$ rows is defined similarly on the subtree rooted at $u_-$. Write the vector $\mm{x}$ as $[x_u, \mm{x}_+, \mm{x}_-]^{\top}$ where $x_u$ is the color of the node $u$ and $\mm{x}_+$ and $\mm{x}_-$ are the colors of the nodes in the subtrees rooted at $u_+$ and $u_-$, respectively. Consider the value of $x_u$. If $x_u = 1$, then by the inductive hypothesis, there exists a permutation which takes the entries of $\tilde{\mm{A}}_{k-1}\mm{x}_+$ to the entries of $\tilde{\mm{A}}_{k-1}\mathbf{1}$ and another permutation which takes the entries of $\tilde{\mm{A}}_{k-1}\mm{x}_-$ to the entries of $\tilde{\mm{A}}_{k-1}\mathbf{1}$. These two permutations can be combined to form a permutation which maps the entries of $\tilde{\mm{A}}_k\mm{x}$ to the entries of $\tilde{\mm{A}}_k\mathbf{1}$. Otherwise $x_u = -1$. Again, there exists a permutation $\pi_1$ which takes $\tilde{\mm{A}}_{k-1}\mm{x}_+$ to $\tilde{\mm{A}}_{k-1}\mathbf{1}$ and another permutation $\pi_2$ which takes $\tilde{\mm{A}}_{k-1}\mm{x}_-$ to $\tilde{\mm{A}}_{k-1}\mathbf{1}$. We can construct a permutation which maps the elements of $\tilde{\mm{A}}_k\mm{x}$ to those of $\tilde{\mm{A}}_k\mathbf{1}$ by by first applying $\pi_1$ to the first $2^{k-1}$ entries of $\tilde{\mm{A}}_k\mm{x}$, and $\pi_2$ to the remaining $2^{k-1}$ entries, and then swapping the first $2^{k-1}$ entries with the second $2^{k-1}$ entries. 
\end{proof}
\modified{
Note that, for any $\mm{x} \in\{\pm 1\}^{2^k}$, \(\disc_1(\mm{A}_k,\mm{x}) = \disc_1(\mm{A}_k,-\mm{x})\). Then, we have
\[
\disc_1(\mm{A}_k,\mm{x}) = \frac12(\disc_1(\mm{A}_k,\mm{x}) + \disc_1(\mm{A}_k,-\mm{x}))
\]
By Claim~\ref{claim:haar-permute}, and, since all entries of the first column of $\mm{A}_k$ are equal to $1$,
\begin{align*}
    \disc_1(\mm{A}_k,\mm{x}) &= \frac{1}{2^{k}} \sum_{i=1}^{2^k}\frac{|\tilde{\mm{a}}_i^\top \mathbf{1}+1| + |\tilde{\mm{a}}_i^\top \mathbf{1}-1|}{2}\\
    &= \frac{1}{2^{k+1}} \sum_{i=1}^{2^k}|\tilde{\mm{a}}_i^\top \mathbf{1}+1| 
    + 
    \frac{1}{2^{k+1}} \sum_{i=1}^{2^k}  |\tilde{\mm{a}}_i^\top \mathbf{1}-1|,
\end{align*}
where $\tilde{\mm{a}}_i^\top$ is the $i$-th row of $\tilde{\mm{A}}_k$. Recall that each row of $\tilde{\mm{A}}_k$ has exactly $k$
non-zero entries, and every sign pattern for these $k$ entries appears exactly once, as each row in $\tilde{\mm{A}}_k$ corresponds to a root-to-leaf path in a depth $k$ perfect binary tree, and the sign pattern corresponds to the sequence of left and right turns made by the path. In particular, there are exactly ${k\choose \ell}$ rows $\tilde{\mm{a}}_i$ for which $\tilde{\mm{a}}_i^\top \mathbf{1}$ equals $k-2\ell$, since such rows have $k-\ell$ non-zero entries equal to $+1$, and $\ell$ non-zero entries equal to $-1$. %Swapping the role of the $+1$ and $-1$ non-zero entries, we also have exactly $k \choose \ell$ rows $\tilde{\mm{a}_i}$ for which $\tilde{\mm{a}}_i^\top \mathbf{1}$ equals $-k+2\ell$.
Substituting above, we have
\begin{align*}
   \frac{1}{2^{k+1}} \sum_{i=1}^{2^k}|\tilde{\mm{a}}_i^\top \mathbf{1}+1| 
    + 
    &\frac{1}{2^{k+1}} \sum_{i=1}^{2^k} |\tilde{\mm{a}}_i^\top \mathbf{1}-1|\\
    &=
     \frac{1}{2^{k+1}} \sum_{\ell=0}^k {k\choose \ell}|k+1-2\ell| 
    + 
    \frac{1}{2^{k+1}} \sum_{\ell=0}^k {k\choose \ell}|k-1-2\ell|\\
    &= 
     \frac{1}{2^{k+1}} \sum_{\ell=0}^{k} {k\choose \ell}|k+1-2\ell| 
    + 
    \frac{1}{2^{k+1}} \sum_{\ell=1}^{k+1} {k\choose \ell-1}|k+1-2\ell|\\
     &=
    \frac{1}{2^{k+1}} \sum_{\ell=0}^{k+1} \left({k\choose \ell}+{k\choose \ell-1}\right)|k+1-2\ell| \\
    &=
    \frac{1}{2^{k+1}} \sum_{\ell=0}^{k+1} {k+1\choose \ell}|k+1-2\ell|.
\end{align*}
The second equality above follows by a change of variables in the second sum, the third equality uses the convention $\binom{k}{k+1} = \binom{k}{-1} = 0$, and the last equality follows form Pascal's identity.}

\modified{Now, by Lemma~\ref{lem:lb-kunisky-computation} below, we have that \[\sum_{\ell=0}^{k+1} {k+1\choose \ell}|k+1-2\ell| = 2(k+1)\binom{k}{\floor{(k+1)/2}},\] which implies that $\disc_1(\tilde{\mm{A}}_k) \cong\sqrt{k}$ since $\binom{k}{\floor{(k+1)/2}} \cong 2^{k}/\sqrt{k}$ by Stirling's approximation.}
\end{proof}

The above proof also has a probabilistic interpretation. We show that, for a uniformly random row $\mm{a}^{\top}$ of $\tilde{\mm{A}}_k$ and a fixed coloring $\mm{x} \in \{\pm 1\}^{2^k-1}$, $\mm{a}^{\top}\mm{x}$ is distributed like $X_1 + \cdots + X_k$ where the $X_i$s are independent Rademacher random variables \modified{(i.e. random variables uniform in $\{-1,+1\}$)}. Recall that uniformly choosing a row of $\tilde{\mm{A}}_k$ corresponds to uniformly choosing a root-to-leaf path in the depth $k$ perfect binary tree. Further, the non-leaf nodes of the tree correspond to the columns of $\tilde{\mm{A}}_k$. Thus we know that exactly $k$ entries of the row will be non-zero. \modified{Let the indices of these entries be $U_1, ..., U_k$, and note that $\mm{a}^{\top}\mm{x} = x_{U_1}a_{U_1} + \cdots + x_{U_k}a_{U_k}$. The key observation is that, conditional on the values of $U_1, \ldots, U_{\ell}$, $a_{U_\ell}$ is equally likely to be $-1$ or $+1$, since the a uniformly random path in the binary tree going through $U_1, \ldots, U_\ell$ is equally likely to visit the left or the right child of $U_\ell$. We can then show that $x_{U_1}a_{U_1} + \cdots + x_{U_k}a_{U_k}$ has the same distribution as a sum of $k$ independent Rademacher random variables by induction on $k$. In the base case, $a_{U_1}$ is uniform in $\{-1, +1\}$, and so is $x_{U_1}a_{U_1}$. Suppose $x_{U_1}a_{U_1} + \cdots + x_{U_{k-1}}a_{U_{k-1}}$ is distributed as the sum of $k-1$ independent Rademacher random variables. Conditional on the choice of $U_1, \ldots, U_k$, $a_{U_k}$, and, therefore, $x_{U_k}a_{U_k}$ are equally likely to be $-1$ or $+1$. Taking expectation over the choice of $U_1, \ldots, U_k$ finishes the proof.}

%Note that $\disc_1(\tilde{\mm{A}}_k) = \min_{\mm{x} \in \{\pm 1\}^{p_k}}\frac{\norm{\tilde{\mm{A}}_k\mm{x}}_1}{2^k}$ which is equivalent to $\min_{\mm{x} \in \{\pm 1\}^{p_k}} \EE\left|\mm{a}^{\top}\mm{x}\right|$ where $\mm{a}^{\top}$ is a random row of $\tilde{\mm{A}}_k$. Fix coloring $\mm{x} \in \{\pm 1\}^{p_k}$ and choose a random row $\mm{a}^{\top}$. Let $X_1, ..., X_{p_k}$ be a sequence of random variables where $X_i$ is the value of entry $i$ of $\mm{a}^{\top}$.\sn{I don't think you want entry \(i\). You want the entry corresponding to the \(i\)-th node on the path represented by \(\mm{a}\). I guess that's the \(i\)-th nonzero entry in \(\mm{a}\)?} We will show that, conditioned on $X_1, ..., X_{i-1}$, $X_i$ is unbiased. It follows that $\chi_1X_1 + \cdots + \chi_{p_k}X_{p_k}$ is distributed like $X_1 + \cdots + X_{p_k}$ and $\disc_1(\tilde{\mm{A}}_k) = \EE_{\mm{a}}\left|\mm{a}^{\top}\mathbf{1}\right|$. To show that $X_i$ is unbiased, we will use induction on $k$. The base case where $k = 1$ is the same as before. Suppose that the random variables $X_1, ..., X_{p_{k-1}}$ are unbiased when conditioned on the variables of smaller index, we will show that $X_{p_{k-1}+1}, ..., X_{p_k}$ are similarly unbiased. Note that for any pair of distinct indices $s, t \in \left\{p_{k-1} + 1, ..., p_k\right\}$, $X_s$ is independent of $X_t$ since any row can have at most one non-zero entry in column $s$ and $t$.\sn{I don't understand this explanation, and I don't think they are independent. I also do not understand why you even need this.} Thus it suffices to consider $X_{p_k}$ and show that it is unbiased conditioned on $X_1, ..., X_{p_{k-1}}$. 

The next lemma is likely a well-known calculation. We include a proof due to Lavrov, for completeness.
\begin{lemma}[\cite{lavrov2018}]\label{lem:lb-kunisky-computation}
    $\sum_{\ell=0}^{k}\binom{k}{\ell}|k-2\ell| = 2k\cdot\binom{k-1}{\floor{k/2}}$.
\end{lemma}
\begin{proof}
Recall the identity $\binom{k}{\ell}\ell = \binom{k-1}{\ell-1}k$. We write
\begin{align*}
    \sum_{\ell = 0}^k\binom{k}{\ell}|k-2\ell| &= \sum_{\ell < k/2}\binom{k}{\ell}(k-2\ell) - \sum_{\ell > k/2}\binom{k}{\ell}(k-2\ell)\\
    &= k\left(\sum_{\ell < k/2}\binom{k}{\ell} - \sum_{\ell > k/2}\binom{k}{\ell}\right) - 2\left(\sum_{\ell < k/2}\binom{k}{\ell}\ell - \sum_{\ell > k/2}\binom{k}{\ell}\ell\right)\\
    &= 2k\left(\sum_{\ell > k/2}\binom{k-1}{\ell-1} - \sum_{\ell < k/2}\binom{k-1}{\ell-1}\right)\\
    &= 2k\binom{k-1}{\floor{k/2}}.
\end{align*}
Here, the first equality follows since $\binom{k}{\ell}\left(k - 2(k/2)\right) = 0$ when $k$ is even. The last equality follows by consider the parity of $k$; when $k$ is even, we obtain a $\binom{k-1}{k/2}$ term after cancellation, and when $k$ is odd, we obtain a $\binom{k-1}{\floor{k/2}}$ term after cancellation.
\end{proof}
Note that when we divide the identity by $2^k$, we obtain the expectation of a sum of $k$ independent Rademacher random variables. The asymptotic version of this identity follows from Khintchine's inequality.
%\begin{claim}
%    For $1 \leq p \le k$, $\disc_p(\mm{A}_k) = %\end{claim}
%\begin{proof}
% From Claim~\ref{claim:haar-permute} it folows that
% $\disc_p(\tilde{\mm{A}}_k) = disc_p(\tilde{\mm{A}}_k,
% \mathbf{1})$. Either using the observation that each sign pattern of
% the non-zero entries in the a row of $\tilde{\mm{A}}_k$ appears
% exactly once, or using the alternate probabilistic proof presented
% after Lemma~\ref{lem:lb-kunisky-disc1}, we see that
% $disc_p(\tilde{\mm{A}}_k, \mathbf{1})$ is the $L_p$ norm of a sum of $k$ independent Rademacher random variables. Thus, by Khintchine's inequality, $\disc_p(\tilde{\mm{A}}_k) \leq \Theta(\sqrt{pk})$.
%\end{proof}

\begin{proof}[Proof of Theorem~\ref{thm:main}]
    Consider the range of $m$ in $[n, n^2]$ and $\left(n^2, 2^{n^{(1-\epsilon)}}\right]$ separately. In the first interval, we let $\mm{A}$ be the matrix $\mm{A}_k$ padded with $m - n$ rows of zeros. Here, $\frac{\herdisc(\mm{A})}{\detlb(\mm{A})} \cong \log n \cong \sqrt{\log m\cdot \log n}$. When $m \in \left(n^2, 2^{n^{(1-\epsilon)}}\right]$, we consider the matrix $\mm{P}_N\otimes \mm{A}_k$ where $N = \floor{\log_2(m/n)}$ and $k = \floor{\log_2 n^{\epsilon}}$. Observe that $\mm{P}_{N}\otimes\mm{A}_{k}$ is an $m' \times n'$ matrix where $m' = 2^{N+k} \leq m/n^{1 - \epsilon} < m$ and $n' = N\cdot2^k \leq \log_2(m/n) \cdot n^{\epsilon} \leq n - n^{\epsilon}\log n$ since $m \leq 2^{n^{(1-\epsilon)}}$. We obtain $\mm{A}$ by padding $\mm{P}_N\otimes\mm{A}_k$ with zero vectors so that it has exactly $m$ rows and $n$ columns. Note that $\log m \cong N$ and $\log n \cong k$. By Theorem~\ref{thm:kunisky-ratio}, $\frac{\herdisc(\mm{A})}{\detlb(\mm{A})}  \gtrsim\sqrt{Nk} \gtrsim \sqrt{\log m\log n}$, as required. 

    The reader might object that the matrix $\mm{A}_k$ has negative entries which would not occur for incidence matrices of a set system, but we can remedy this by considering $\mm{A}_k^{\pm}$ as defined in Theorem~\ref{thm:kunisky-ratio} instead.
\end{proof}


\subsection{Other Notable Properties}\label{sec:othernotableproperties}
We can make a few more observations about the properties of $\mm{A}_k$.
\begin{claim}
    $|\det(\mm{A}_{k})| = 2^{2^k - 1}$.
\end{claim}
\begin{proof}
    Note that the columns of $\mm{A}_{k}$ are orthogonal so $|\det(\mm{A}_k)|$ is equal to the product of the $\ell_2$-norms of columns. Since the $i$th column has magnitude $2^{2^{i-1}}$, $|\det(\mm{A}_k)| = 2^{2^{k-1} + 2^{k-2} + \cdots + 2^{0}} = 2^{2^k-1}$.
\end{proof}

Next we prove Theorem~\ref{thm:tight-matousek-example}, showing that $\mm{A}_k$ serves as an example that equation~\eqref{eq:matousek-eq2} of~\cite{matouvsek2013determinant} --- mentioned in the introduction --- is tight. 
\begin{proof}[Proof of Theorem~\ref{thm:tight-matousek-example}]
To see this, it suffices to show that $\vecdisc\left(\mm{A}_k\right)^2 = \Omega(k)$. Let $\mm{v}_0, \mm{v}_1, ..., \mm{v}_q$ be the vector colors assigned to the $2^k$ columns of $\mm{A}_k$. Recall that $\mm{A}_k$ corresponds to a tree with root node $r$, where $r$ has no right child, and the left child is the root of a perfect binary tree of depth $k$. The root to leaf paths of this tree represent rows in $\mm{A}_k$. For any path $r, t_1, ..., t_i$ from $r$ to a node $t_i$, let $\overline{\mm{v}}_{t_i} = \mm{v}_{r} + \sum_{j=1}^{i-1} a_{t_j}\mm{v}_{t_j}$ where $a_{t_j}$ is $1$ if $t_{j+1}$ is the left child of $t_{j}$, and $-1$ otherwise. We will show that there exists a root-to-leaf $t_k$ path $t_1, ..., t_k$ such that $\left\|\overline{\mm{v}}_{t_k}\right\|_2^2 \ge k$. In particular we show that at every internal node $t$, with children $t_+$ and $t_-$, must have $\norm{\overline{\mm{v}}_{t_+}}^2 \geq 1 + \norm{\overline{\mm{v}}_t}^2$ or $\norm{\overline{\mm{v}}_{t_-}}^2 \geq 1 + \norm{\overline{\mm{v}}_t}^2$. To see this, note that
\[\norm{\overline{\mm{v}}_{t_+}}^2 = \norm{\overline{\mm{v}}_{t} + \mm{v}_{t}}^2 = \norm{\overline{\mm{v}}_{t}}^2 + \norm{\mm{v}_{t}}^2 + 2\anglebrac{\overline{\mm{v}}_{t}, \mm{v}_{t}} = \norm{\overline{\mm{v}}_{t}}^2 + 1 + 2\anglebrac{\overline{\mm{v}}_{t}, \mm{v}_{t}}.\]
Similarly, we have that $\norm{\overline{\mm{v}}_{t_-}}^2 = \norm{\overline{\mm{v}}_{t}}^2 + 1 - 2\anglebrac{\overline{\mm{v}}_{t}, \mm{v}_{t}}$. The claim then follows since either $\anglebrac{\overline{\mm{v}}_{t}, \mm{v}_{t}} \geq 0$ or $-\anglebrac{\overline{\mm{v}}_{t}, \mm{v}_{t}} \geq 0$. The theorem then follows from the tree interpretation of $\mm{A}_k$.
\end{proof}

In~\cite{Lovasz1986discrepancy} there appears an open problem of
S\'{o}s which asks if the hereditary discrepancy of a union of two
sets systems is bounded above by the discrepancy of each individual
set system i.e.\ for set systems $(X, \mathcal{S}_1)$ and $(X,
\mathcal{S}_2)$ is it true that $\herdisc(\mathcal{S}_1\cup
\mathcal{S}_2) \leq f(\herdisc(\mathcal{S}_1),
\herdisc(\mathcal{S}_2))$ for some function $f$? It turns out that no
such bound exists. The Hoffman example\footnote{Hoffman's set system
  $\mathcal{F}$ is defined on a regular $k$-ary tree of depth $k$ and
  obtains
  $\frac{\herdisc(\mm{A}_{\mathcal{F}})}{\detlb(\mm{A_{\mathcal{F}}})}
  = \Theta\left(\frac{\log n}{\log\log n}\right)$. Let $T$ be a
  $k$-regular tree with height $k$. The universe consists of the nodes
  of $T$. Let $\mathcal{F}_1$ be the sets of all root-to-leaf paths in
  $T$, and $\mathcal{F}_2$ be the set of all sibling sets (all nodes
  with the same parent) of internal nodes in $T$. Then $\mathcal{F} =
  \mathcal{F}_1 \cup \mathcal{F}_2$. We have that
  $\herdisc(\mathcal{F}_1), \herdisc(\mathcal{F}_2) \leq 1$,
  $\detlb(\mathcal{F}) = O(1)$, and $\disc(\mathcal{F}) =
  \Omega(k/\log k)$. See~\cite{matousek2009geometric} Section 4.4.},
the example of P{\'a}lv{\"o}lgyi~\cite{palvolgyi2010indecomposable},
and the three permutations family of Newman, Neiman, and Nikolov~\cite{newman2012beck} are instances of such pairs of set systems whose individual hereditary discrepancies are at most $1$, but whose union on a universe of size $n$ has discrepancy $\Omega(\log n/\log \log n)$ (for the Hoffman example) or $\Omega(\log n)$ (for the other two).

We see that $\mm{A}_k$ --- with the decomposition into $\mm{A}_k^+$
and $\mm{A}_k^-$ --- is another similar counter-example of S\'{o}s'
conjecture. While it matches the $\Omega(\log n)$ discrepancy lower
bound of the P{\'a}lv{\"o}lgyi and Newman-Neiman-Nikolov constructions, it is simpler to analyze.
\begin{claim}\label{claim:haar-is-Sos}
    With $\mm{A}_k^\pm$ as described above Claim~\ref{cor:haar-decomp}, 
    \[\disc\left(\mm{A}_k^{\pm}\right) \gtrsim k.\] 
\end{claim}
\begin{proof}
    Recall that $\disc(\mm{A}_k) = k$. We claim that $\disc(\mm{A}^\pm_k) \ge \frac12 \disc(\mm{A}_k)$, and this proves the claim. Indeed, take any coloring $\mm{x}$. Let $\mm{a}^{\top}$ be the row of $\mm{A}_k$ achieving $|\mm{a}^{\top}\mm{x}| = \disc(\mm{A}_k, \mm{x})$ and let $\mm{a}_+^{\top}$ and $\mm{a}_-^{\top}$ be the corresponding rows in the copy of $\mm{A}^{+}$ and $\mm{A}^-$ in $\mm{A}^{\pm}$ respectively. Since $\disc(\mm{A}_k) \leq |\mm{a}^{\top}\mm{x}| = |\mm{a}_+^{\top}\mm{x} - \mm{a}_-^{\top}\mm{x}|$, by the triangle inequality we have that either $|\mm{a}_+^{\top}\mm{x}| \geq \disc(\mm{A}_k)/2$ or $|\mm{a}_-^{\top}\mm{x}| \geq \disc(\mm{A}_k)/2$.
\end{proof}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
