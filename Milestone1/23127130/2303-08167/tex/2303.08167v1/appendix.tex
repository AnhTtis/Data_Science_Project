\appendix
\section{Bounds on Hereditary Discrepancy}
The following result is a consequence of well known lemmas. We recount it here for completeness.

For a metric space $(T, d)$, let $\mathcal{N}(T, d, \epsilon)$ be the covering number of $T$ i.e.\ $\mathcal{N}(T, d, \epsilon)$ is the smallest number of closed balls with centers in $T$ and radii $\epsilon$ whose union covers $T$. Further, let $\norm{Y}_{\psi_2}$ be the sub-gaussian norm of a real-valued random variable $Y$ where $\norm{Y}_{\psi_2} \coloneqq \inf\{t \geq 0: \EE \exp\left(Y^2/t^2\right) \leq 2\}$. Finally, for a class of real-valued functions $\mathcal{F}$ defined on a probability space $(\Omega, \mu)$, where \(\Omega\) is a finite set, we define the $L^2(\mu)$ norm by
\(
\|f\|_{L^2(\mu)} := \left(\sum_{\omega \in \Omega} |f(\omega)|^2\mu(\omega)\right)^{1/2}.
\)
If $\mu$ is the uniform measure on $\Omega$, then we simple write $L^2$ rather than $L^2(\mu)$. 

\begin{lemma}\label{lem:herdisc-vc-ub}
    For a non-constant incidence matrix $\mm{A}\in \{0,1\}^{m\times n}$, $\herdisc(\mm{A}) \lesssim\sqrt{n\cdot\dim(\mm{A})}$.
\end{lemma}
\begin{proof}
    Since $\dim(\mm{B}) \le \dim(\mm{A})$ for any submatrix $\mm{B}$ of $\mm{A}$, it is enough to show that $\disc(\mm{A}) \lesssim \sqrt{n\cdot\dim(\mm{A})}$.
    We prove that this bounds is satisfied in expectation by a uniformly random coloring $\mm{x} \in \{-1, +1\}^n$.    Let $\mathcal{F}$ denote the class of indicator functions defined by the rows of $\mm{A}$, i.e., for every $i \in [m]$, we define a function $f_{i}: [n] \rightarrow \{0,1\}$ given by $f_i(j) = a_{i,j}$. 

    We will show that 
    \[\EE\sup_{f\in \mathcal{F}} \left|\frac{1}{\sqrt{n}}\sum_{i = 1}^{n}x_if\left(i\right)\right| \lesssim \sqrt{\dim(\mathcal{F})}\]
    where $x_1, x_2, ... x_n$ are independent Rademacher random variables. 
    
    For each indicator function $f$, define the random variable $Z_f \coloneqq \left|\frac{1}{\sqrt{n}}\sum_{i=1}^{n} x_if(i)\right|$. Note that this is off from the discrepancy of the row indicated by $f$ by a multiple of $\sqrt{n}$, i.e., $\disc(\mm{A},\mm{x}) = \sqrt{n} \sup_{f \in \mathcal{F}} Z_f$. Consider the random process $(Z_f)_{f\in \mathcal{F}}$. We will apply Dudley's inequality (Lemma~\ref{lem:v-dudley}) to show that 
    \begin{equation}\label{eq:dudley}
        \EE\sup_{f \in \mathcal{F}} Z_f \lesssim \int_0^1\sqrt{\log \mathcal{N}\left(\mathcal{F}, L^2, \epsilon\right)}d\epsilon.
    \end{equation}
    In order to apply Dudley's inequality we must show that $(Z_f)_{f\in \mathcal{F}}$ has sub-gaussian increments. Note that, since $\norm{x_i}_{\psi_2} \lesssim 1$, we have 
    \[\norm{Z_f - Z_g}_{\psi} = \frac{1}{\sqrt{n}}\left\|\left|\sum_{i=1}^{n}x_if(i)\right|-\left|\sum_{i=1}^{n}x_ig(i)\right|\right\|_{\psi_2} \leq \frac{1}{\sqrt{n}}\left\|\sum_{i=1}^{n}x_i(f-g)(i)\right\|_{\psi_2} \lesssim \left(\frac{1}{n}\sum_{i=1}^n(f-g)(i)^2\right)^{1/2},\]
    where the second step follows from the reverse triangle inequality, and the final step by Hoeffding's lemma. The right hand side is $\norm{f - g}_{L^2}$ so when we apply Dudley's inequality as shown in Lemma~\ref{lem:v-dudley}, we obtain Equation~\ref{eq:dudley}. 
    
    Using Theorem~\ref{thm:v-covering-number}, we can bound the covering number with respect to the normalized $L_2$ norm as 
    \[\log \mathcal{N}\left(\mathcal{F}, L^2, \epsilon\right) \lesssim \dim(\mathcal{F})\log \left(\frac{2}{\epsilon}\right).\]
    Plugging the right hand side into the integral in Equation~\ref{eq:dudley} and integrating, we have $\EE \sup_{f \in \mathcal{F}}Z_f \lesssim \sqrt{\dim(\mathcal{F})}$. Recall that the discrepancy of the row indicated by $f$ is $\sqrt{n}\cdot Z_f$, thus the hereditary discrepancy is bounded above as $\disc(\mm{A}) \lesssim\sqrt{n\dim(\mathcal{F})}$, as was our goal.
\end{proof}

\begin{lemma}{\textup{(Dudley's Inequality,~\cite{vershynin2018high} Remark 8.1.5).}}\label{lem:v-dudley}
    Let $(X_t)_{t\in T}$ be a random process on a metric space $(T, d)$ with sub-gaussian increments i.e.\ there exists a $K \geq 0$ such that $\norm{X_t - X_s}_{\psi_2} \leq Kd(t,s)$ for all $t, s \in T$. Then 
    \[\EE \sup_{t,s \in T}\left|X_t - X_s\right| \lesssim K\int_0^{\infty}\sqrt{\log \mathcal{N}(T, d, \epsilon)}d\epsilon.\]
\end{lemma}

\begin{theorem}\textup{(Covering Numbers via VC Dimension,~\cite{vershynin2018high} 8.3.18).}\label{thm:v-covering-number}
    Let $\mathcal{F}$ be a class of Boolean functions on a probability space $(\Omega, \Sigma, \mu)$. Then, for every $\epsilon \in (0, 1)$, we have
    \[\mathcal{N}\left(\mathcal{F}, L^2(\mu), e\right) \leq \left(\frac{2}{\epsilon}\right)^{C\cdot\dim(\mathcal{F})}\]
    for an absolute constant $C$.
\end{theorem}

We note that Lemma~\ref{lem:herdisc-vc-ub} can likely be improved further, for example by following the techniques of~\cite{matousek95tight}, and carefully tracking constants.