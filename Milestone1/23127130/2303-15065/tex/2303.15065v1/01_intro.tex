
\section{Introduction}

In clinical practice, Magnetic Resonance Imaging (MRI) provides important information for diagnosing and monitoring patient conditions \cite{menze2014multimodal,commowick2016msseg}. To capture the complex pathophysiological aspects during disease progression, multi-parametric MRI (such as T1w, T2w, DIR, FLAIR) is routinely acquired.
Image acquisition inherently poses a trade-off between scan time, resolution, and signal-to-noise ratio (SNR) \cite{plenge2012super}.
To maximize the source of information within a reasonable time budget, clinical protocol often combines anisotropic 2D scans of different contrasts in complementary viewing directions.
Although acquired 2D scans offer an excellent in-plane resolution, they lack important details in the orthogonal out-of-plane.
For a reliable pathological assessment, radiologists often resort to a second scan of a different contrast in the orthogonal viewing direction.
Furthermore, poor out-of-plane resolution significantly affects the accuracy of volumetric downstream image analysis, such as radiomics and lesion volume estimation, which usually require isotropic 3D scans.
As multi-parametric isotropic 3D scans are not always feasible to acquire due to time-constraints~\cite{plenge2012super}, motion~\cite{gholipour2010robust}, and patient's condition~\cite{ha2020one}, super-resolution offers a convenient alternative to obtain the same from anisotropic 2D scans.

Recently, it has been shown that acquiring three complementary 2D views of the \emph{same contrast} may yield higher SNR at reduced scan time \cite{plenge2012super,wu2021irem}. However, it remains under-explored if orthogonal anisotropic 2D views of \emph{different contrasts} can benefit from each other based on the underlying anatomical consistency. Additionally, whether such strategies can further decrease scan times while preserving similar resolution and SNR remains unanswered. Moreover, unlike conventional super-resolution models trained on a cohort, a personalized model is of clinical relevance to avoid the danger of potential misdiagnosis caused by cohort-learned biases. In this work, we mitigate these gaps by proposing a novel multi-contrast super-resolution framework that only requires the patient-specific low-resolution MR scans of different sequences (and views) as supervision. As shown in various settings, our approach is not limited to specific contrasts or views but provides a generic framework for super-resolution. The contributions in this paper are three-fold:



\begin{enumerate}
    \item To the best of our knowledge, our work is the first to enable subject-specific multi-contrast super-resolution from low-resolution scans without needing any high-resolution training data. We demonstrate that neural implicit functions (NIF) are good candidates to learn from complementary views of multi-parametric sequences and can efficiently fuse low-resolution images into anatomically faithful super-resolution.
    \item We introduce Mutual Information (MI) \cite{wells1996multi} as an evaluation metric and find that our method preserves the MI between high-resolution ground truths in its predictions. Further observation of its convergence to the ground truth value during training motivates us to use MI as an early stopping criterion.
    \item We extensively evaluate our method on multiple brain MRI datasets and show that it achieves high visual quality for different contrasts and views and preserves pathological details, highlighting its potential clinical usage.
\end{enumerate}