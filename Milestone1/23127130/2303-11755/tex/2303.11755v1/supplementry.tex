\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{array} 
\usepackage{tabularray}
\usepackage{subcaption}
%\usepackage{xcolor}
\usepackage{float}
\usepackage[x11names]{xcolor}
\usepackage{subcaption}

\newcolumntype{P}[1]{>{\small \centering\arraybackslash}p{#1}}
%\usepackage{mathbbol}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

% \iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{4599} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ificcvfinal\pagestyle{empty}\fi
\newcommand*{\ShowNotes}{}
\ifdefined\ShowNotes
  \newcommand{\colornote}[3]{{\color{#1}\bf{#2: #3}\normalfont}}
\else
  \newcommand{\colornote}[3]{}
\fi

\newcommand {\ayellet}[1]{\colornote{blue}{AT}{#1}}
\newcommand {\gefen}[1]{\colornote{red}{GD}{#1}}
\newcommand {\elad}[1]{\colornote{teal}{EH}{#1}}

\definecolor{teaser_pink}{RGB}{190, 0, 0} % 192
\definecolor{teaser_green}{RGB}{101, 156, 64} % 84, 130, 53
\definecolor{teaser_blue}{RGB}{56, 102, 182} % 47, 85, 151
\definecolor{teaser_brown}{RGB}{159, 72, 15} % 132, 60, 12
\definecolor{teaser_gray}{RGB}{99, 99, 99} % 82, 82, 82
\definecolor{teaser_yellow}{RGB}{230, 173, 0} % 191, 144, 0
\definecolor{arrow_green}{RGB}{84, 130, 53}
\definecolor{arrow_red}{RGB}{192, 0, 0}
\definecolor{clavicula}{RGB}{127, 96, 0}


\begin{document}

%%%%%%%%% TITLE
%\title{Joint Image-Report Embedding for Medical Data}
\title{LIMITR: Leveraging Local Information for Medical Image-Text Representation (Supplementary material ) }
\author{First Author\\
Institution1\\
Institution1 address\\
{\tt\small firstauthor@i1.org}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Second Author\\
Institution2\\
First line of institution2 address\\
{\tt\small secondauthor@i2.org}
}

\maketitle
% Remove page # from the first page of camera-ready.
\ificcvfinal\thispagestyle{empty}\fi
\section{Phrase-grounding}
For phrase-grounding evaluation (on MS-CXR dataset), we followed [3] and trained our model using only the impression section of the reports.
For this task, we dropped all the images of MS-CXR from the training set, to make sure that our model uses them only for inference.
Qualitative results presented below for each of the $8$ abnormality classes in MS-CXR dataset (Figure \ref{fig:phrasse grounding}). 






\section{Cross modal alignment-extension }
Throughout the paper, for simplicity, we describe how our method creates and utilizes weighted visual representation with respect to each textual feature. We hereby extend the explanation from the paper and describe the complementary direction -- weighted textual features with respect to each image region. 

\textbf{Cross modal alignment.} 
This section is extension of section 3.2 from the paper. 
To create the weighted textual features with respect to each image region we start with computing the cosine similarity $c_{ij}$ between $v_{i}$ and $t_{j}$, to create $c_i=[c_{i1},c_{i2},\dots,  c_{iN_w}]$.
It is further
normalized using softmax,  in order to get an attention weight:
%of each region with respect to each word:
\begin{equation}
{w_{i}=softmax(\lambda c_{i})}.
\end{equation} 
The attended visual feature $m_i$ with respect to the $i^{th}$ image region is the weighted sum of all the textual local representations: 
\begin{equation}
{m_{i}=\sum_{j=1}^{N_w}w _{i}[j] \cdot t_{j}}.
\label{eq:uj}
\end{equation} 

Next, we calculate the alignment between $v_i$ and its corresponding  $m_i$. 
The local alignment $a_{i}$ is calculated as:
%
\begin{equation}
{a_{i}=\mathcal{A}(m_{i},v_{i})=\frac{ m_{i}\circ v_{i}}{\left \|  m_{i}\circ v_{i} \right \|_{2}}},
\label{eq:aj}
\end{equation}
where $\circ$ is an element-wise multiplication and $\left \| \cdot  \right \|_{2}$ is the $L_2$-norm.

\begin{figure}[tb]
\centering
\includegraphics[width=1\linewidth]{Images/cross_model_wordattn.png}
\caption{{\bf Cross-modal alignment- textual weighted representation.} 
Given an image-report pair $(x_v,x_t)$, we compute for each image region $v_i$  its corresponding textual weighted representation $m_i$.
This is done by using the  similarity between each word representation $t_j$ to $v_i$ as the weight for this region $w_i[j]$. 
The right text shows that the words that correspond to the selected image region are highlighted in orange, representing the higher weight of these words.
The final textual representation, $m_i$, is created by a weighted sum of $t_j$. This figure corresponds to figure $3$ from the paper.
}
\label{fig:cross modal alignment}
\end{figure}

\textbf{Aggregation.} 
This section is extension of section 3.3 from the paper. 
The local alignments are aggregated into a single alignment vector using a weighted sum. 
Let the local alignments, computed at the alignment module, be $\mathcal{A}_{T}=\left \{a_{1},a_{2},a_{3}...a_{N_r}\right \}$.
Let $\bar{a}$ be the mean of $\mathcal{A}_T$.
The weight of $a_t$  is defined as:
\begin{equation}
q_{t}=\biggl( softmax \Bigl( \frac{W_q  \, \bar{a} \cdot (W_k \, \mathcal{A}_T)^T}{\sqrt{d}} \Bigr) \biggr)_t,
\end{equation} 
where $1 \leq t \leq N_r$, $W_q$ and $W_k$ are linear transformations of the self-attention, and $d$ is the feature dimension. 

The final alignment vector between an image and a report is defined as:
\begin{equation}
{a_{f}=\sum_{t=1}^{N_r} q _{t} \, (W_v \cdot a_{t})}.
\end{equation}
\textbf{Loss.}
This section is extension of section 3.4 from the paper. 
Recall that our loss is composed of three components: global, local internal and local external. 
The use of weighted textual features influence only local alignments, therefore we hereby describe the local internal and local external losses which use the weighted textual features with respect to each image region.

Local external loss: 
the loss is computed as described in equation (8), while this time $\mathcal{A}_{agg}$ is the aggregated representation based on the weighted-textual representations and the visual representations, as described in the section above.

Local internal loss:  $L_{int}$, is given the local visual representation, $v_i$, as well as its corresponding attention weighted textual representation, $m_i$.

The loss is defined as follows:
%
\begin{equation}
\begin{split}
& L_{int}(x_v^{k},x_t^{k})=\sum_{i=1}^{N_r}(l_{k}^{v_i|m}+ l_{k}^{m_i|v}), \\ 
& l^{v_i|m}_k=-log\left ( \frac{exp(a_i(v_i,m_i)/\tau)}{\sum_{j=1}^{N_r}exp(a_i(v_i,m_j)/\tau)} \right ),\\ 
& l^{m_i|v}_k=-log\left ( \frac{exp(a_i(v_i,m_i)/\tau)}{\sum_{j=1}^{N_r}exp(a_i(v_j,m_i)/\tau)} \right ).
\end{split}
\label{eq:lint}
\end{equation} 
%

We sum the losses related to the weighted visual features with the losses related to the weighted textual features for both the local internal loss and the local external loss.
\begin{figure*}[t]
\centering
% \small
\begin{tabular}{m{0.2in} P{1.5in} P{1.5in} P{1.5in} P{1.5in}}
\multirow{14}{*}{ \hfil\rotatebox[origin=c]{90}{\textbf{Atelectasis}}}&
 "Left lower lobe collapse is new" & "possible small left pleural effusion with adjacent atelectasis" & "left lower lobe is still collapsed" & "multisegmental lower lobe opacities are present, consistent with areas of atelectasis lung" \\
 &CNR 1.625 & CNR 1.932 & CNR 1.663 & CNR 0.909 \\
 &
\subfloat{\includegraphics[width=1\linewidth]{Images/atelectasis1.png}} &
\subfloat{\includegraphics[width=1\linewidth]{Images/atelectasis2.jpg}} &
\subfloat{\includegraphics[width=1\linewidth]{Images/atelectasis3.jpg}} &
\subfloat{\includegraphics[width=1\linewidth]{Images/atelectasis4.jpg}}\\\hline
\multirow{14}{*}{\hfil\rotatebox[origin=c]{90}{\textbf{Lung Opacity}}}&
 "hazy opacity in the left suprahilar lung may represent ground-glass opacity" & "patchy ground-glass opacities are seen in the left lung base" & "ground-glass opacities in the left lung" & "patchy ground-glass opacity in the mid right lung is also present" \\
 &CNR 1.877 & CNR 1.599 & CNR 1.413 & CNR 2.897 \\
 &
\subfloat{\includegraphics[width=1\linewidth]{Images/lungopacity1.png}} &
\subfloat{\includegraphics[width=1\linewidth]{Images/lungopacity2.png}} &
\subfloat{\includegraphics[width=1\linewidth]{Images/lungopacity3.png}} &
\subfloat{\includegraphics[width=1\linewidth]{Images/lungopacity4.png}}\\\hline
\multirow{14}{*}{\hfil\rotatebox[origin=c]{90}{\textbf{Pleural effusion}}}&
 "small pleural effusion is stable" & "moderate right pleural effusion is unchanged compared to the prior exam" & "the minimal left pleural effusion persists" & "small amount of associated right pleural effusion is demonstrated" \\
&CNR 2.507 & CNR 1.900 & CNR 1.658 & CNR 1.602 \\
&
\subfloat{\includegraphics[width=1\linewidth]{Images/effusion1.jpg}} &
\subfloat{\includegraphics[width=1\linewidth]{Images/effusion2.png}} &
\subfloat{\includegraphics[width=1\linewidth]{Images/effusion3.jpg}} &
\subfloat{\includegraphics[width=1\linewidth]{Images/effusion4.jpg}}\\\hline
\multirow{14}{*}{\hfil\rotatebox[origin=c]{90}{\textbf{Edema}}}&
 "evidence of worsening pulmonary edema and mitral regurgitation " & "hazy bilateral parenchymal opacities favored to represent edema" & "hazy perihilar opacities maybe due to pulmonary edema" & "interstitial edema is present in the right lower lung" \\
&CNR 1.832 & CNR 1.378 & CNR 1.698 & CNR 1.810 \\
&
\subfloat{\includegraphics[width=1\linewidth]{Images/edema1.jpg}} &
\subfloat{\includegraphics[width=1\linewidth]{Images/edema2.jpg}} &
\subfloat{\includegraphics[width=1\linewidth]{Images/edema3.jpg}} &
\subfloat{\includegraphics[width=1\linewidth]{Images/edema4.jpg}}\\\hline
\end{tabular}

\label{fig:phrasse grounding}
\end{figure*}

\setcounter{figure}{1}

\begin{figure*}[t]
\centering
\small
\begin{tabular}{m{0.2in} P{1.5in} P{1.5in} P{1.5in} P{1.5in}}
\multirow{14}{*}{ \hfil\rotatebox[origin=c]{90}{\textbf{Cardiomegaly}}}&
"enlarged cardiac silhouette" & "enlarged cardiac silhouette" & "enlarged cardiac silhouette" & "heart size is enlarged" \\
&CNR 1.455 & CNR 1.471 & CNR 1.294 & CNR 0.908 \\
&
\subfloat{\includegraphics[width=1\linewidth]{Images/cardiomegaly1.png}} &
\subfloat{\includegraphics[width=1\linewidth]{Images/cardiomegaly2.png}} &
\subfloat{\includegraphics[width=1\linewidth]{Images/cardiomegaly3.png}} &
\subfloat{\includegraphics[width=1\linewidth]{Images/cardiomegaly4.png}}\\\hline
\multirow{14}{*}{ \hfil\rotatebox[origin=c]{90}{\textbf{Pneumonia}}}&
"left lower lobe pneumonia" & "right lower lung pneumonia" & "patchy left base opacity" & "parenchymal opacity in the left lower lobe" \\
&CNR 2.538 & CNR 1.877 & CNR 2.097 & CNR 1.931 \\
&
\subfloat{\includegraphics[width=1\linewidth]{Images/pneumonia1.png}} &
\subfloat{\includegraphics[width=1\linewidth]{Images/pneumonia2.png}} &
\subfloat{\includegraphics[width=1\linewidth]{Images/pneumonia3.png}} &
\subfloat{\includegraphics[width=1\linewidth]{Images/pneumonia4.png}}\\\hline
\multirow{14}{*}{ \hfil\rotatebox[origin=c]{90}{\textbf{Pneumothorax}}}&
"large right pneumothorax" & "right-sided basal pneumothorax" & "right-sided hydro pneumothorax" & "apical component of pneumothorax" \\
&CNR 1.071 & CNR 1.385 & CNR 1.358 & CNR 1.370 \\
&
\subfloat{\includegraphics[width=1\linewidth]{Images/pneumothorax1.png}} &
\subfloat{\includegraphics[width=1\linewidth]{Images/pneumothorax2.png}} &
\subfloat{\includegraphics[width=1\linewidth]{Images/pneumothorax3.png}} &
\subfloat{\includegraphics[width=1\linewidth]{Images/pneumothorax4.png}}\\\hline
\multirow{14}{*}{ \hfil\rotatebox[origin=c]{90}{\textbf{Consolidation}}}&
"there is left lower lobe consolidation" & "patchy consolidation in the mid left lung" & "patchy consolidation in the lower lung" & "patchy consolidation in the central right lung" \\
&CNR 1.982 & CNR 2.419 & CNR 2.118 & CNR 1.695 \\
&
\subfloat{\includegraphics[width=1\linewidth]{Images/consolidation1.png}} &
\subfloat{\includegraphics[width=1\linewidth]{Images/consolidation2.png}} &
\subfloat{\includegraphics[width=1\linewidth]{Images/consolidation3.png}} &
\subfloat{\includegraphics[width=1\linewidth]{Images/consolidation4.png}}\\\hline

\end{tabular}
\caption{\textbf{Phrase-grounding --- qualitative results.} Given a phrase and an image, the goal is to produce a similarity map between the phrase and the image. 
Brighter color indicates higher similarity of that region to the given phrase.
The results are measured using CNR; higher values indicate good localization of the phrase in the image.
Each row in the figure represents one of the abnormalitiy classes of MS-CXR dataset. 
Recall that our model was not trained for that task, but still learned to match well between image regions and their corresponding phrases.
}
\label{fig:phrasse grounding}
\end{figure*}

\section{Implementation details}
\textbf{Data pre-processing.} 
For training we used MIMIC-CXR dataset.

Images: we resize the original images to 256 pixels on the larger dimension and randomly/center cropped (training/inference) the resized images. 
We used Resnet50 as our image encoder. 
We extract the local features from the last convolution layer to get 19X19 feature maps which result in 361 local image regions.

Reports: we extract the impression and findings sections of the report using the official script provided in the github of MIMIC-CXR.
We used Bio-clinical BERT tokenizer to tokenize the extracted text.
Following [8] we set the maximum number of tokens per report to 97. 

\textbf{Training details.}
We used Adam optimizer with an initial learning rate of 5e-5 and a weight decay of 1e-6. 
We measured the performance on the validation set using $Recall@K$ where K=1,5,10 for both Image-to-Text retrieval and Text-to-Image. 
We set the maximum number of epochs to 50 and used the sum of those metrics $R_{sum}$ as the early stopping criteria (plateau over 5 epochs).
The best checkpoint is defined as the checkpoint with the highest $R_{sum}$.
 We use batch size of 48.
 All models were trained on a single A100 GPU.
For all losses we used $\tau = 0.1 $.
\end{document}