
\section{Related Work}

\subsection{Video Prediction}
Early video prediction methods~\cite{prednet,mcnet,dvf} only utilize RGB frames as inputs. For example, PredNet~\cite{prednet} learns an unsupervised neural network, with each layer making local predictions and forwarding deviations from those predictions to subsequent network layers.
%
MCNet~\cite{mcnet} decomposes the input frames into motion and content components, which are processed by two separete encoders. DVF~\cite{dvf} is a fully-convolutional encoder-decoder network synthesizing intermediate and future frames by approximating voxel flow for motion estimation. Later, extra information is exploited by video prediction models in pursuit of better performance. The methods of Vid2vid~\cite{vid2vid}, Seg2vid~\cite{seg2vid}, HVP~\cite{hvp}, and SADM~\cite{sadm} require additional semantic maps or human pose information for better video prediction results. Additionally, Qi~\etal~\cite{qi} used additional depth maps and semantic maps to explicitly inference scene dynamics in 3D space. FVS~\cite{fvs} separates the inputs into foreground objects and background areas by semantic and instance maps, and uses a spatial transformer to predict the motion of foreground objects.
%
In this paper, we develop a light-weight and efficient video prediction network that requires only sRGB images as the inputs.

\subsection{Optical Flow}
Optical flow estimation aims to estimate the per-pixel motion between adjacent frames. 
%
Deep learning-based optical flow models have been considerably advanced since Flownet~\cite{flownet}, a pioneering work to learn convolutional neural models from synthetic data. 
%
Flownet2.0~\cite{flownet2} improves the accuracy of optical flow estimation by stacking subnetworks for iterative refinement.
%
A coarse-to-fine spatial pyramid network is employed in SPynet~\cite{spynet} to estimate optical flow at multiple scales. 
%
PWC-Net~\cite{pwcnet} employs feature warping operation at different resolution and uses a cost volume layer to refine the estimated flow at each resolution.
%
% 
%
RAFT~\cite{raft} proposes a lightweight recurrent network that is weight-sharing during the iterative process.
%
FlowFormer~\cite{flowformer} designs an encoder to output latent tokens and a recurrent decoder to decode features and refine the estimated flow iteratively. In video synthesis, optical flow for downstream tasks~\cite{vimeo,dvf,rife,qvi,zhang2023extracting} is also a hot research topic. Based on these approaches, for the video prediction task, we aim to design a flow estimation network that can specifically transform based on each sample.

\begin{figure*}[ht]
	\centering
	\includegraphics[width=0.9\linewidth]{image/bigfig1.pdf}
	\caption{\textbf{Overview of the proposed Dynamic Multi-scale Voxel Flow Network (DMVFN)}.
$(a)$: To predict a future frame, we use the \textbf{voxel flow}~\cite{dvf} to guide the pixel fusion of the input frames. The voxel flow contains the prediction of object motion and occlusion. $(b)$: \textbf{DMVFN} contains several MVFBs with decreasing scaling factor $S^i$.
According to the routing vector $v$ estimated by a Routing Module, a sub-network is selected to process the input image. 
$(c)$: Each \textbf{MVFB} has a scaling factor $S^i$, which means that the motion path is performed on images whose sizes are $1/S^i$ of the original. $(d)$: Two consecutive frames are fed into several neural layers and a Differentiable Bernoulli sample to generate the hard routing vector.
}
	\label{fig:predict}
\end{figure*}

\subsection{Dynamic Network}
The design of the dynamic networks is mainly divided into three categories: spatial-wise, temporal-wise, and sample-wise~\cite{dynamicnn}. 
%
Spatial-wise dynamic networks perform different operations in different spatial regions for reducing computational redundancy and keeping performance comparable~\cite{sbnet,dynamicconv,mga}. 
%
In addition to the spatial dimension, dynamic processing can also be applied in the temporal dimension.
%
Temporal-wise dynamic networks improve the efficiency by performing less or no computation on unimportant sequence elements~\cite{yeung2016end, su2016leaving, wu2019adaframe}.
%
For handling the input in a data-dependent manner, sample-wise dynamic networks adaptively change the network parameters to improve the performance~\cite{harley2017segmentation,su2019pixel,dcn,dcn2}, or adaptively adjust network structures to reduce the extra computation~\cite{skipnet,veit2018convolutional}. Designing and training a dynamic network is not trivial because it is difficult to directly make a model with complex topology connections. We need to design a well-structured and robust model before considering its dynamics.
%
In this paper, we design a module that dynamically perceives the magnitude of input motion to select the network structure.
%
