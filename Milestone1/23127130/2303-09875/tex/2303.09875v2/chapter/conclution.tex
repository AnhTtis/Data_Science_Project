\section{Conclusion}
 
In this work, we developed an efficient Dynamic Multi-scale Voxel Flow Network (DMVFN) that excels previous video prediction methods on dealing with complex motions of different scales. With the proposed routing module, our DMVFN adaptively activates different sub-networks based on the input frames, improving the prediction performance while reducing the computation costs. Experiments on diverse benchmark datasets demonstrated that our DMVFN achieves \sota performance with greatly reduced computation burden. We believe our DMVFN can provide general insights for long-term prediction, video frame synthesis, and representation learning~\cite{hafner2023mastering,ha2018world}. We hope our DMVFN will inspire further research in light-weight video processing and make video prediction more accessible for downstream tasks such as CODEC for streaming video.

Our DMVFN can be improved at several aspects. Firstly, iteratively predicting future frames suffers from accumulate errors.
%We has shown that our DMVFN is perceptive to the time interval. 
This issue may be addressed by further bringing explicit temporal modeling~\cite{qvi,TMNet2021,ifrnet,rife} to our DMVFN.
%
Secondly, our DMVFN simply selects the nodes in a chain network topology, which can be improved by exploring more complex topology. For example, our routing module can be extended to automatically determine the scaling factors for parallel branches~\cite{darts}.
%
Thirdly, forecast uncertainty modeling is more of an extrapolation abiding to past flow information, especially considering bifurcation, which exceeds the current capability of our DMVFN. We believe that research on long-term forecast uncertainty may uncover deeper interplay with dynamic modeling methods~\cite{ha2018world,akan2021slamp}.
% 

\noindent
\textbf{Acknowledgements}. We sincerely thank Wen Heng for his exploration on neural architecture search at Megvii Research and Tianyuan Zhang for meaningful suggestions. This work is supported in part by the National Natural Science Foundation of China (No. 62002176 and 62176068).