\begin{wrapfigure}{r!}{0.5\textwidth}
\centering
\includegraphics[width=0.9\linewidth]{PLEX.png}
\caption{\setlength{\parindent}{12pt}
\small \textbf{\appr\ architecture.} \replaced{}{This diagram illustrates the information flow during PLEX training,  described in \Cref{sec:arch}}. \appr\ is optimized using the planner's loss $\LL_{PL}$ (computation shown with black arrows $\uparrow$), and the executor's loss $\LL_{EX}$ (computation shown with gray arrows ${\textcolor{gray} \uparrow}$). The symbols `\textbf{=}' and `\textbf{\textcolor{gray} =}' denote stopgrads, where backpropagation is halted. Each input modality $m$ is embedded using a modality-specific encoder $\phi_m$. Video demonstration embeddings $\tilde g, \tilde I_{1:T}$, and (optionally) $\tilde R_{1:T}$ are used to train the planner \replaced{}{\emph{over the embedding space}} \replaced{with}{using} the prediction loss $\LL_{PL}$ \replaced{in the embedding space}{}. Visuomotor trajectory embeddings $\tilde I_{1:T}, \tilde p_{1:T}, \tilde a_{1:T}$ are passed to the executor to compute the inverse dynamics loss $\LL_{EX}$. Note that if the image encoder $\phi_I$ isn't frozen, $\LL_{EX}$'s gradients will update $\phi_I$. In contrast, the planner's own loss $\LL_{PL}$ never affects $\phi_I$ (see stopgrad symbol \textbf{=}).
}
\label{fig:transformer}
\vspace{-14mm}
\end{wrapfigure}