@article{venuto2022multi,
  title={Multi-Environment Pretraining Enables Transfer to Action Limited Datasets},
  author={Venuto, David and Yang, Sherry and Abbeel, Pieter and Precup, Doina and Mordatch, Igor and Nachum, Ofir},
  journal={arXiv preprint arXiv:2211.13337},
  year={2022}
}

@inproceedings{li2022meta,
  title={Meta-imitation learning by watching video demonstrations},
  author={Li, Jiayi and Lu, Tao and Cao, Xiaoge and Cai, Yinghao and Wang, Shuo},
  booktitle={International Conference on Learning Representations},
  year={2022}
}

@article{karamcheti2023language,
  title={Language-driven representation learning for robotics},
  author={Karamcheti, Siddharth and Nair, Suraj and Chen, Annie S and Kollar, Thomas and Finn, Chelsea and Sadigh, Dorsa and Liang, Percy},
  journal={arXiv preprint arXiv:2302.12766},
  year={2023}
}

@article{chane2023learning,
  title={Learning Video-Conditioned Policies for Unseen Manipulation Tasks},
  author={Chane-Sane, Elliot and Schmid, Cordelia and Laptev, Ivan},
  journal={arXiv preprint arXiv:2305.06289},
  year={2023}
}

@inproceedings{ahn2022can,
  title={Do as {I} can, not as {I} say: Grounding language in robotic affordances},
  author={Ahn, Michael and Brohan, Anthony and Brown, Noah and Chebotar, Yevgen and Cortes, Omar and David, Byron and Finn, Chelsea and Gopalakrishnan, Keerthana and Hausman, Karol and Herzog, Alex and others},
  booktitle={CoRL},
  year={2022}
}

@article{mees2022matters,
  title={What matters in language conditioned robotic imitation learning over unstructured data},
  author={Mees, Oier and Hermann, Lukas and Burgard, Wolfram},
  journal={IEEE Robotics and Automation Letters},
  volume={7},
  number={4},
  pages={11205--11212},
  year={2022},
  publisher={IEEE}
}

@article{hakhamaneshi2021hierarchical,
  title={Hierarchical few-shot imitation with skill transition models},
  author={Hakhamaneshi, Kourosh and Zhao, Ruihan and Zhan, Albert and Abbeel, Pieter and Laskin, Michael},
  journal={arXiv preprint arXiv:2107.08981},
  year={2021}
}

@article{silva2021lancon,
  title={LanCon-Learn: Learning With Language to Enable Generalization in Multi-Task Manipulation},
  author={Silva, Andrew and Moorman, Nina and Silva, William and Zaidi, Zulfiqar and Gopalan, Nakul and Gombolay, Matthew},
  journal={IEEE Robotics and Automation Letters},
  volume={7},
  number={2},
  pages={1635--1642},
  year={2021},
  publisher={IEEE}
}


@article{xihan2022skill,
  title={SKILL-IL: Disentangling Skill and Knowledge in Multitask Imitation Learning},
  author={Xihan, Bian and Mendez, Oscar and Hadfield, Simon},
  journal={arXiv preprint arXiv:2205.03130},
  year={2022}
}

@inproceedings{vowels2020dvae,
  author = {Vowels, Matthew J. and Camgoz, Necati Cihan and Bowden, Richard},
  title = {NestedVAE: Isolating Common Factors via Weak Supervision},
  booktitle={CVPR},
  year = {2020}
}


@article{nasiriany2022learning,
  title={Learning and Retrieval from Prior Data for Skill-based Imitation Learning},
  author={Nasiriany, Soroush and Gao, Tian and Mandlekar, Ajay and Zhu, Yuke},
  journal={arXiv preprint arXiv:2210.11435},
  year={2022}
}

@article{mandi2022effectiveness,
  title={On the Effectiveness of Fine-tuning Versus Meta-reinforcement Learning},
  author={Mandi, Zhao and Abbeel, Pieter and James, Stephen},
  journal={CoRL 2022 Workshop on Pre-training Robot Learning},
  year={2022}
}

@inproceedings{lynch2019play,
  author = {Lynch, Corey and Khansari, Mohi and Xiao, Ted and Kumar, Vikash and Tompson, Jonathan and Levine, Sergey and Sermanet, Pierre},
  title = {Learning Latent Plans from Play},
  booktitle = {coRL},
  year = {2019}
}


@inproceedings{xie2018few,
  title={Few-shot goal inference for visuomotor learning and planning},
  author={Xie, Annie and Singh, Avi and Levine, Sergey and Finn, Chelsea},
  booktitle={Conference on Robot Learning},
  pages={40--52},
  year={2018},
  organization={PMLR}
}

@inproceedings{xu2022pgiorl,
  author = {Xu, Haoran and Jiang, Li and Li, Jianxiong and Zhan, Xianyuan},
  title = {A Policy-Guided Imitation Approach for Offline Reinforcement Learning},
  booktitle = {arXiv},
  year = {2022}
}

@inproceedings{dance2021conditioned,
  title={Conditioned Reinforcement Learning for Few-Shot Imitation},
  author={Dance, Christopher R and Perez, Julien and Cachet, Th{\'e}o},
  booktitle={International Conference on Machine Learning},
  pages={2376--2387},
  year={2021},
  organization={PMLR}
}

@inproceedings{yen2020see,
  author = {Yen-Chen, Lin and Zeng, Andy and Song, Shuran and Isola, Phillip and Lin, Tsung-Yi},
  title = {Learning to See before Learning to Act: Visual Pre-training for Manipulation},
  booktitle = {ICRA},
  year = {2020}
}

@inproceedings{nair2017knot,
  author = {Nair, Ashvin and Chen, Dian and Agrawal, Pulkit and Isola, Phillip and Abbeel, Pieter and Malik, Jitendra and Levine, Sergey},
  title = {Combining Self-Supervised Learning and Imitation for Vision-Based Rope Manipulation},
  booktitle = {ICRA},
  year = {2017}
}


@inproceedings{li2019oil,
  author = {Li, Guohao and Müller, Matthias and Casser, Vincent and Smith, Neil and Michels, Dominik L. and Ghanem, Bernard},
  title = {OIL: Observational Imitation Learning},
  booktitle = {RSS},
  year = {2018}
}



@article{gupta2019relay,
  title={Relay policy learning: Solving long-horizon tasks via imitation and reinforcement learning},
  author={Gupta, Abhishek and Kumar, Vikash and Lynch, Corey and Levine, Sergey and Hausman, Karol},
  journal={arXiv preprint arXiv:1910.11956},
  year={2019}
}

@inproceedings{ren2021generalization,
  title={Generalization guarantees for imitation learning},
  author={Ren, Allen and Veer, Sushant and Majumdar, Anirudha},
  booktitle={Conference on Robot Learning},
  pages={1426--1442},
  year={2021},
  organization={PMLR}
}

@inproceedings{jang2021bc,
  title={{BC-Z}: Zero-shot task generalization with robotic imitation learning},
  author={Jang, Eric and Irpan, Alex and Khansari, Mohi and Kappler, Daniel and Ebert, Frederik and Lynch, Corey and Levine, Sergey and Finn, Chelsea},
  booktitle={Conference on Robot Learning},
  pages={991--1002},
  year={2021}
}

@article{shang2021starformer,
  title={StARformer: Transformer with State-Action-Reward Representations for Visual Reinforcement Learning},
  author={Shang, Jinghuan and Kahatapitiya, Kumara and Li, Xiang and Ryoo, Michael S},
  journal={arXiv preprint arXiv:2110.06206},
  year={2021}
}

@article{kim2022training,
  title={Training Robots without Robots: Deep Imitation Learning for Master-to-Robot Policy Transfer},
  author={Kim, Heecheol and Ohmura, Yoshiyuki and Nagakubo, Akihiko and Kuniyoshi, Yasuo},
  journal={arXiv preprint arXiv:2202.09574},
  year={2022}
}

@inproceedings{prakash2021multi,
  title={Multi-modal fusion transformer for end-to-end autonomous driving},
  author={Prakash, Aditya and Chitta, Kashyap and Geiger, Andreas},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7077--7087},
  year={2021}
}

@inproceedings{kim2021transformer,
  title={Transformer-based deep imitation learning for dual-arm robot manipulation},
  author={Kim, Heecheol and Ohmura, Yoshiyuki and Kuniyoshi, Yasuo},
  booktitle={2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={8965--8972},
  year={2021},
  organization={IEEE}
}


@article{kim2022memory,
  title={Memory-based gaze prediction in deep imitation learning for robot manipulation},
  author={Kim, Heecheol and Ohmura, Yoshiyuki and Kuniyoshi, Yasuo},
  journal={arXiv preprint arXiv:2202.04877},
  year={2022}
}

@inproceedings{chen2021decision,
      title={Decision Transformer: Reinforcement Learning via Sequence Modeling}, 
      author={Lili Chen and Kevin Lu and Aravind Rajeswaran and Kimin Lee and Aditya Grover and Michael Laskin and Pieter Abbeel and Aravind Srinivas and Igor Mordatch},
      booktitle = {NeurIPS},
        year = {2021}
}


@inproceedings{pathak2018zs,
  author = {Pathak, Deepak and Mahmoudieh, Parsa and Luo, Guanghao and Agrawal, Pulkit and Chen, Dian and Shentu, Yide and Shelhamer, Evan and Malik, Jitendra and Efros, Alexei A. and Darrell, Trevor},
  title = {Zero-Shot Visual Imitation},
  booktitle={ICLR},
  year = {2018}
}




@inproceedings{robonetv1,
  author = {Dasari, Sudeep and Ebert, Frederik and Tian, Stephen and Nair, Suraj and Bucher, Bernadette and Schmeckpeper, Karl and Singh, Siddharth and Levine, Sergey and Finn, Chelsea},
  title = {RoboNet: Large-Scale Multi-Robot Learning},
  booktitle = {CoRL},
  year = {2019}
}

@inproceedings{robonetv2,
  author = {Ebert, Frederik and Yang, Yanlai and Schmeckpeper, Karl and Bucher, Bernadette and Georgakis, Georgios and Daniilidis, Kostas and Finn, Chelsea and Levine, Sergey},
  title = {Bridge Data: Boosting Generalization of Robotic Skills with Cross-Domain Datasets},
  booktitle = {RSS},
  year = {2022}
}



@misc{youtue8m,
  author = {Abu-El-Haija, Sami and Kothari, Nisarg and Lee, Joonseok and Natsev, Paul and Toderici, George and Varadarajan, Balakrishnan and Vijayanarasimhan, Sudheendra},
  title = {YouTube-8M: A Large-Scale Video Classification Benchmark},
  publisher = {arXiv},
  year = {2016}
}



@ARTICLE{Damen2022RESCALING,
           title={Rescaling Egocentric Vision: Collection, Pipeline and Challenges for EPIC-KITCHENS-100},
           author={Damen, Dima and Doughty, Hazel and Farinella, Giovanni Maria  and and Furnari, Antonino 
           and Ma, Jian and Kazakos, Evangelos and Moltisanti, Davide and Munro, Jonathan 
           and Perrett, Toby and Price, Will and Wray, Michael},
           journal   = {International Journal of Computer Vision (IJCV)},
           year      = {2022},
           volume = {130},
           pages = {33–55}
} 

@misc{ptr2022,
  author = {Kumar, Aviral and Singh, Anikait and Ebert, Frederik and Yang, Yanlai and Finn, Chelsea and Levine, Sergey},
  title = {Pre-Training for Robots: Offline RL Enables Learning New Tasks from a Handful of Trials},
  publisher = {arXiv},
  year = {2022}
  }



@INPROCEEDINGS{Damen2018EPICKITCHENS,
   title={Scaling Egocentric Vision: The EPIC-KITCHENS Dataset},
   author={Damen, Dima and Doughty, Hazel and Farinella, Giovanni Maria  and Fidler, Sanja and 
           Furnari, Antonino and Kazakos, Evangelos and Moltisanti, Davide and Munro, Jonathan 
           and Perrett, Toby and Price, Will and Wray, Michael},
   booktitle={European Conference on Computer Vision (ECCV)},
   year={2018}
} 


@INPROCEEDINGS{Radosavovic2022RWRL,
  author = {Radosavovic, Ilija and Xiao, Tete and James, Stephen and Abbeel, Pieter and Malik, Jitendra and Darrell, Trevor},
  title = {Real World Robot Learning with Masked Visual Pre-training},
  booktitle = {CoRL},
  year = {2022}
}


@inproceedings{rados2021soil,
  author = {Radosavovic, Ilija and Wang, Xiaolong and Pinto, Lerrel and Malik, Jitendra},
  title = {State-Only Imitation Learning for Dexterous Manipulation},
  booktitle={IROS},
  year = {2021}
}

@inproceedings{caron2021emerging,
  title={Emerging Properties in Self-Supervised Vision Transformers},
  author={Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J\'egou, Herv\'e  and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  booktitle={Proceedings of the International Conference on Computer Vision (ICCV)},
  year={2021}
}

@inproceedings{brown2020gpt3,
  author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  title = {Language Models are Few-Shot Learners},
  booktitle = {NeurIPS},
  year = {2020}
}

@article{rt2022,
  author = {Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Dabis, Joseph and Finn, Chelsea and Gopalakrishnan, Keerthana and Hausman, Karol and Herzog, Alex and Hsu, Jasmine and Ibarz, Julian and Ichter, Brian and Irpan, Alex and Jackson, Tomas and Jesmonth, Sally and Joshi, Nikhil J and Julian, Ryan and Kalashnikov, Dmitry and Kuang, Yuheng and Leal, Isabel and Lee, Kuang-Huei and Levine, Sergey and Lu, Yao and Malla, Utsav and Manjunath, Deeksha and Mordatch, Igor and Nachum, Ofir and Parada, Carolina and Peralta, Jodilyn and Perez, Emily and Pertsch, Karl and Quiambao, Jornell and Rao, Kanishka and Ryoo, Michael and Salazar, Grecia and Sanketi, Pannag and Sayed, Kevin and Singh, Jaspiar and Sontakke, Sumedh and Stone, Austin and Tan, Clayton and Tran, Huong and Vanhoucke, Vincent and Vega, Steve and Vuong, Quan and Xia, Fei and Xiao, Ted and Xu, Peng and Xu, Sichun and Yu, Tianhe and Zitkovich, Brianna},
  title = {{RT}-1: Robotics Transformer for Real-World Control at Scale},
  journal={arXiv},
  year = {2022}
}

@inproceedings{dosovitskiy2021image,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      booktitle={ICLR}
}

@inproceedings{rgb2021corl,
  author = {Lee, Alex X. and Devin, Coline and Zhou, Yuxiang and Lampe, Thomas and Bousmalis, Konstantinos and Springenberg, Jost Tobias and Byravan, Arunkumar and Abdolmaleki, Abbas and Gileadi, Nimrod and Khosid, David and Fantacci, Claudio and Chen, Jose Enrique and Raju, Akhil and Jeong, Rae and Neunert, Michael and Laurens, Antoine and Saliceti, Stefano and Casarini, Federico and Riedmiller, Martin and Hadsell, Raia and Nori, Francesco},
  title = {Beyond Pick-and-Place: Tackling Robotic Stacking of Diverse Shapes},
  booktitle={CoRL},
  year = {2021}
}


@misc{ebert2018visual,
      title={Visual Foresight: Model-Based Deep Reinforcement Learning for Vision-Based Robotic Control}, 
      author={Frederik Ebert and Chelsea Finn and Sudeep Dasari and Annie Xie and Alex Lee and Sergey Levine},
      year={2018},
      eprint={1812.00568},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}

@inproceedings{schmeckpeper2020reinforcement,
      title={Reinforcement Learning with Videos: Combining Offline Observations with Interaction}, 
      author={Karl Schmeckpeper and Oleh Rybkin and Kostas Daniilidis and Sergey Levine and Chelsea Finn},
      year={2020},
      booktitle={CoRL}
}

@misc{sontakke2021video2skill,
      title={Video2Skill: Adapting Events in Demonstration Videos to Skills in an Environment using Cyclic MDP Homomorphisms}, 
      author={Sumedh A Sontakke and Sumegh Roychowdhury and Mausoom Sarkar and Nikaash Puri and Balaji Krishnamurthy and Laurent Itti},
      year={2021},
      eprint={2109.03813},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{grauman2022ego4d,
      title={Ego4D: Around the World in 3,000 Hours of Egocentric Video}, 
      author={Kristen Grauman and Andrew Westbury and Eugene Byrne and Zachary Chavis and Antonino Furnari and Rohit Girdhar and Jackson Hamburger and Hao Jiang and Miao Liu and Xingyu Liu and Miguel Martin and Tushar Nagarajan and Ilija Radosavovic and Santhosh Kumar Ramakrishnan and Fiona Ryan and Jayant Sharma and Michael Wray and Mengmeng Xu and Eric Zhongcong Xu and Chen Zhao and Siddhant Bansal and Dhruv Batra and Vincent Cartillier and Sean Crane and Tien Do and Morrie Doulaty and Akshay Erapalli and Christoph Feichtenhofer and Adriano Fragomeni and Qichen Fu and Abrham Gebreselasie and Cristina Gonzalez and James Hillis and Xuhua Huang and Yifei Huang and Wenqi Jia and Weslie Khoo and Jachym Kolar and Satwik Kottur and Anurag Kumar and Federico Landini and Chao Li and Yanghao Li and Zhenqiang Li and Karttikeya Mangalam and Raghava Modhugu and Jonathan Munro and Tullie Murrell and Takumi Nishiyasu and Will Price and Paola Ruiz Puentes and Merey Ramazanova and Leda Sari and Kiran Somasundaram and Audrey Southerland and Yusuke Sugano and Ruijie Tao and Minh Vo and Yuchen Wang and Xindi Wu and Takuma Yagi and Ziwei Zhao and Yunyi Zhu and Pablo Arbelaez and David Crandall and Dima Damen and Giovanni Maria Farinella and Christian Fuegen and Bernard Ghanem and Vamsi Krishna Ithapu and C. V. Jawahar and Hanbyul Joo and Kris Kitani and Haizhou Li and Richard Newcombe and Aude Oliva and Hyun Soo Park and James M. Rehg and Yoichi Sato and Jianbo Shi and Mike Zheng Shou and Antonio Torralba and Lorenzo Torresani and Mingfei Yan and Jitendra Malik},
      year={2022},
      eprint={2110.07058},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{vaswani2017attention,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2017},
      booktitle={NeurIPS}
}

@inproceedings{radford2021clip,
author={A. Radford and J. W. Kim and C. Hallacy and A. Ramesh and G. Goh and S. Agarwal and G. Sastry and A. Askell and P. Mishkin and J. Clark and G. Krueger and and I. Sutskever},
title={Learning transferable visual models from natural language supervision},
title={ICML},
year={2021}
}

@inproceedings{devlin2019bert,
author={J. Devlin and M.-W. Chang and K. Lee and K. Toutanova},
title={BERT: Pre-training of deep bidirectional transformers for language understanding},
booktitle={NAACL-HLT},
year={2019}
}

@article{fm2021,
  author = {Bommasani, Rishi and Hudson, Drew A. and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S. and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and Brynjolfsson, Erik and Buch, Shyamal and Card, Dallas and Castellon, Rodrigo and Chatterji, Niladri and Chen, Annie and Creel, Kathleen and Davis, Jared Quincy and Demszky, Dora and Donahue, Chris and Doumbouya, Moussa and Durmus, Esin and Ermon, Stefano and Etchemendy, John and Ethayarajh, Kawin and Fei-Fei, Li and Finn, Chelsea and Gale, Trevor and Gillespie, Lauren and Goel, Karan and Goodman, Noah and Grossman, Shelby and Guha, Neel and Hashimoto, Tatsunori and Henderson, Peter and Hewitt, John and Ho, Daniel E. and Hong, Jenny and Hsu, Kyle and Huang, Jing and Icard, Thomas and Jain, Saahil and Jurafsky, Dan and Kalluri, Pratyusha and Karamcheti, Siddharth and Keeling, Geoff and Khani, Fereshte and Khattab, Omar and Koh, Pang Wei and Krass, Mark and Krishna, Ranjay and Kuditipudi, Rohith and Kumar, Ananya and Ladhak, Faisal and Lee, Mina and Lee, Tony and Leskovec, Jure and Levent, Isabelle and Li, Xiang Lisa and Li, Xuechen and Ma, Tengyu and Malik, Ali and Manning, Christopher D. and Mirchandani, Suvir and Mitchell, Eric and Munyikwa, Zanele and Nair, Suraj and Narayan, Avanika and Narayanan, Deepak and Newman, Ben and Nie, Allen and Niebles, Juan Carlos and Nilforoshan, Hamed and Nyarko, Julian and Ogut, Giray and Orr, Laurel and Papadimitriou, Isabel and Park, Joon Sung and Piech, Chris and Portelance, Eva and Potts, Christopher and Raghunathan, Aditi and Reich, Rob and Ren, Hongyu and Rong, Frieda and Roohani, Yusuf and Ruiz, Camilo and Ryan, Jack and Ré, Christopher and Sadigh, Dorsa and Sagawa, Shiori and Santhanam, Keshav and Shih, Andy and Srinivasan, Krishnan and Tamkin, Alex and Taori, Rohan and Thomas, Armin W. and Tramèr, Florian and Wang, Rose E. and Wang, William and Wu, Bohan and Wu, Jiajun and Wu, Yuhuai and Xie, Sang Michael and Yasunaga, Michihiro and You, Jiaxuan and Zaharia, Matei and Zhang, Michael and Zhang, Tianyi and Zhang, Xikun and Zhang, Yuhui and Zheng, Lucia and Zhou, Kaitlyn and Liang, Percy},
  title = {On the Opportunities and Risks of Foundation Models},
  journal={arXiv},
  year = {2021}
}

@article{spatsoft,
  author = {Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  title = {End-to-End Training of Deep Visuomotor Policies},
  journal = {JMLR},
  year = {2016}
}


@inproceedings{resnet,
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  title = {Deep Residual Learning for Image Recognition},
  booktitle = {CVPR},
  year = {2016}
}


@inproceedings{nair2022r3m,
  author = {Nair, Suraj and Rajeswaran, Aravind and Kumar, Vikash and Finn, Chelsea and Gupta, Abhinav},
  title = {{R3M}: A Universal Visual Representation for Robot Manipulation},
  booktitle = {CoRL},
  year = {2022}
}

@inproceedings{khosla2020scl,
  author = {Khosla, Prannay and Teterwak, Piotr and Wang, Chen and Sarna, Aaron and Tian, Yonglong and Isola, Phillip and Maschinot, Aaron and Liu, Ce and Krishnan, Dilip},
  title = {Supervised Contrastive Learning},
  booktitle={NeurIPS},
  year = {2020}
}

@misc{robosuite,
  author = {Zhu, Yuke and Wong, Josiah and Mandlekar, Ajay and Martín-Martín, Roberto},
  title = {Robosuite: A Modular Simulation Framework and Benchmark for Robot Learning},
  publisher = {arXiv},
  year = {2020}
}


@inproceedings{singh2020cog,
      title={COG: Connecting New Skills to Past Experience with Offline Reinforcement Learning}, 
      author={Avi Singh and Albert Yu and Jonathan Yang and Jesse Zhang and Aviral Kumar and Sergey Levine},
      year={2020},
      booktitle={CoRL}
}

@inproceedings{shrid2021clip,
  author = {Shridhar, Mohit and Manuelli, Lucas and Fox, Dieter},
  title = {{CLIP}ort: What and Where Pathways for Robotic Manipulation},
  booktitle = {CoRL},
  year = {2021}
}


@inproceedings{zeng2022transporter,
      title={Transporter Networks: Rearranging the Visual World for Robotic Manipulation}, 
      author={Andy Zeng and Pete Florence and Jonathan Tompson and Stefan Welker and Jonathan Chien and Maria Attarian and Travis Armstrong and Ivan Krasin and Dan Duong and Ayzaan Wahid and Vikas Sindhwani and Johnny Lee},
      year={2020},
      booktitle={CoRL}
}

@misc{videomae2022,
  author = {Tong, Zhan and Song, Yibing and Wang, Jue and Wang, Limin},
  title = {Video{MAE}: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training},
  booktitle = {arXiv},
  year = {2022}
}

@inproceedings{mcil21rss,
  author = {Lynch, Corey and Sermanet, Pierre},
  title = {Language Conditioned Imitation Learning over Unstructured Data},
  booktitle={RSS},
  year = {2021}
}

@inproceedings{vpt2022,
  author = {Baker, Bowen and Akkaya, Ilge and Zhokhov, Peter and Huizinga, Joost and Tang, Jie and Ecoffet, Adrien and Houghton, Brandon and Sampedro, Raul and Clune, Jeff},  
  title = {Video PreTraining (VPT): Learning to Act by Watching Unlabeled Online Videos},
  booktitle={NeurIPS},
  year = {2022}
}


@inproceedings{chen2021learning,
      title={Learning Generalizable Robotic Reward Functions from "In-The-Wild" Human Videos}, 
      author={Annie S. Chen and Suraj Nair and Chelsea Finn},
      year={2021},
      booktitle={RSS}
}

@inproceedings{scvr2021,
  author = {Qian, Rui and Meng, Tianjian and Gong, Boqing and Yang, Ming-Hsuan and Wang, Huisheng and Belongie, Serge and Cui, Yin},
  title = {Spatiotemporal Contrastive Video Representation Learning},
  booktitle={CVPR},
  year={2021}
}



@misc{gato,
  author = {Reed, Scott and Zolna, Konrad and Parisotto, Emilio and Colmenarejo, Sergio Gomez and Novikov, Alexander and Barth-Maron, Gabriel and Gimenez, Mai and Sulsky, Yury and Kay, Jackie and Springenberg, Jost Tobias and Eccles, Tom and Bruce, Jake and Razavi, Ali and Edwards, Ashley and Heess, Nicolas and Chen, Yutian and Hadsell, Raia and Vinyals, Oriol and Bordbar, Mahyar and de Freitas, Nando},
  title = {A Generalist Agent},
  publisher = {arXiv},
  year = {2022},
}


@misc{janner2021reinforcement,
      title={Reinforcement Learning as One Big Sequence Modeling Problem}, 
      author={Michael Janner and Qiyang Li and Sergey Levine},
      year={2021}
}

@inproceedings{dasari2020transformers,
      title={Transformers for One-Shot Visual Imitation}, 
      author={Sudeep Dasari and Abhinav Gupta},
      year={2020},
      booktitle={CoRL}
}


@inproceedings{finn2017os, 
  author = {Finn, Chelsea and Yu, Tianhe and Zhang, Tianhao and Abbeel, Pieter and Levine, Sergey},
  title = {One-Shot Visual Imitation Learning via Meta-Learning},
  booktitle = {CoRL},
  year = {2017}
}


@inproceedings{mandi2021generalizable,
      title={Towards More Generalizable One-shot Visual Imitation Learning}, 
      author={Zhao Mandi and Fangchen Liu and Kimin Lee and Pieter Abbeel},
      year={2022},
      booktitle={ICRA}
}

@inproceedings{zhou2020watch,
      title={Watch, Try, Learn: Meta-Learning from Demonstrations and Reward}, 
      author={Allan Zhou and Eric Jang and Daniel Kappler and Alex Herzog and Mohi Khansari and Paul Wohlhart and Yunfei Bai and Mrinal Kalakrishnan and Sergey Levine and Chelsea Finn},
      year={2020},
      booktitle={ICLR}
}


@inproceedings{yu2018daml,
  author = {Yu, Tianhe and Finn, Chelsea and Xie, Annie and Dasari, Sudeep and Zhang, Tianhao and Abbeel, Pieter and Levine, Sergey},
  title = {One-Shot Imitation from Observing Humans via Domain-Adaptive Meta-Learning},
  booktitle={RSS},
  year = {2018},
}


@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{mtformer2022,
title={{MTF}ormer: Multi-Task Learning via Transformer and Cross-Task Reasoning},
author={Xiaogang Xu and Hengshuang Zhao and Vibhav Vineet and Ser-Nam Lim and Antonio Torralba},
booktitle={ECCV},
year={2022}
}

@inproceedings{robomimic2021,
  title={What Matters in Learning from Offline Human Demonstrations for Robot Manipulation},
  author={Ajay Mandlekar and Danfei Xu and Josiah Wong and Soroush Nasiriany and Chen Wang and Rohun Kulkarni and Li Fei-Fei and Silvio Savarese and Yuke Zhu and Roberto Mart\'{i}n-Mart\'{i}n},
  booktitle={CoRL},
  year={2021}
}

@inproceedings{mw2019,
  author = {Yu, Tianhe and Quillen, Deirdre and He, Zhanpeng and Julian, Ryan and Narayan, Avnish and Shively, Hayden and Bellathur, Adithya and Hausman, Karol and Finn, Chelsea and Levine, Sergey},
  title = {Meta-World: A Benchmark and Evaluation for Multi-Task and Meta Reinforcement Learning},
  booktitle={CoRL},
  year = {2019}
}

@article{du2023unipi,
  author = {Du, Yilun and Yang, Mengjiao and Dai, Bo and Dai, Hanjun and Nachum, Ofir and Tenenbaum, Joshua B. and Schuurmans, Dale and Abbeel, Pieter},
  title = {Learning Universal Policies via Text-Guided Video Generation},
  journal={arXiv},
  year = {2023}
}



@article{levine2016end,
  title={End-to-end training of deep visuomotor policies},
  author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={1334--1373},
  year={2016},
  publisher={JMLR. org}
}

@article{radford2019language,
  title={Language Models are Unsupervised Multitask Learners},
  author={Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  year={2019}
}

@article{ho2022imagenvideo,
  author = {Ho, Jonathan and Chan, William and Saharia, Chitwan and Whang, Jay and Gao, Ruiqi and Gritsenko, Alexey and Kingma, Diederik P. and Poole, Ben and Norouzi, Mohammad and Fleet, David J. and Salimans, Tim},
  title = {Imagen {V}ideo: High Definition Video Generation with Diffusion Models},
  journal={arXiv},
  year = {2022}
}


@inproceedings{chen2020simple,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={International conference on machine learning},
  pages={1597--1607},
  year={2020},
  organization={PMLR}
}

@inproceedings{orig,
  author    = {Zihang Dai and
               Zhilin Yang and
               Yiming Yang and
               Jaime G. Carbonell and
               Quoc Viet Le and
               Ruslan Salakhutdinov},
  editor    = {Anna Korhonen and
               David R. Traum and
               Llu{\'{\i}}s M{\`{a}}rquez},
  title     = {Transformer-XL: Attentive Language Models beyond a Fixed-Length Context},
  booktitle = {ACL},
  year      = {2019},
}

@InProceedings{WMG,
  title = 	 {Working Memory Graphs},
  author =       {Loynd, Ricky and Fernandez, Roland and Celikyilmaz, Asli and Swaminathan, Adith and Hausknecht, Matthew},
  booktitle = 	 {ICML},
  year = 	 {2020}
}

@InProceedings{GTrXL,
  title = 	 {Stabilizing Transformers for Reinforcement Learning},
  author =       {Parisotto, Emilio and Song, Francis and Rae, Jack and Pascanu, Razvan and Gulcehre, Caglar and Jayakumar, Siddhant and Jaderberg, Max and Kaufman, Rapha{\"e}l Lopez and Clark, Aidan and Noury, Seb and Botvinick, Matthew and Heess, Nicolas and Hadsell, Raia},
  booktitle = 	 {ICML},
  year = 	 {2020}
}

@article{instructrl2022,
  author = {Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L. and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul and Leike, Jan and Lowe, Ryan},
  title = {Training language models to follow instructions with human feedback},
  journal={arXiv preprint arXiv:2203.02155},
  year = {2022}
}

@article{Roformer,
  author = {Su, Jianlin and Lu, Yu and Pan, Shengfeng and Murtadha, Ahmed and Wen, Bo and Liu, Yunfeng},
  title = {RoFormer: Enhanced Transformer with Rotary Position Embedding},
  publisher = {arXiv preprint arXiv:2104.09864},
  year = {2021}
}

@article{PaLM,
  author = {Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and Schuh, Parker and Shi, Kensen and Tsvyashchenko, Sasha and Maynez, Joshua and Rao, Abhishek and Barnes, Parker and Tay, Yi and Shazeer, Noam and Prabhakaran, Vinodkumar and Reif, Emily and Du, Nan and Hutchinson, Ben and Pope, Reiner and Bradbury, James and Austin, Jacob and Isard, Michael and Gur-Ari, Guy and Yin, Pengcheng and Duke, Toju and Levskaya, Anselm and Ghemawat, Sanjay and Dev, Sunipa and Michalewski, Henryk and Garcia, Xavier and Misra, Vedant and Robinson, Kevin and Fedus, Liam and Zhou, Denny and Ippolito, Daphne and Luan, David and Lim, Hyeontaek and Zoph, Barret and Spiridonov, Alexander and Sepassi, Ryan and Dohan, David and Agrawal, Shivani and Omernick, Mark and Dai, Andrew M. and Pillai, Thanumalayan Sankaranarayana and Pellat, Marie and Lewkowycz, Aitor and Moreira, Erica and Child, Rewon and Polozov, Oleksandr and Lee, Katherine and Zhou, Zongwei and Wang, Xuezhi and Saeta, Brennan and Diaz, Mark and Firat, Orhan and Catasta, Michele and Wei, Jason and Meier-Hellstern, Kathy and Eck, Douglas and Dean, Jeff and Petrov, Slav and Fiedel, Noah},
  title = {PaLM: Scaling Language Modeling with Pathways},
  journal = {arXiv preprint arXiv:2204.02311},
  year = {2022}
}

@misc{PaLM-E,
  author = {Driess, Danny and Xia, Fei and Sajjadi, Mehdi S. M. and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and Huang, Wenlong and Chebotar, Yevgen and Sermanet, Pierre and Duckworth, Daniel and Levine, Sergey and Vanhoucke, Vincent and Hausman, Karol and Toussaint, Marc and Greff, Klaus and Zeng, Andy and Mordatch, Igor and Florence, Pete},
  title = {PaLM-E: An Embodied Multimodal Language Model},
  journal = {arXiv preprint arXiv:2303.03378},
  year = {2023}
}
