\vspace{-1mm}
\section{Conclusion and limitations}
\vspace{-1mm}

We have introduced \appr, a transformer-based sensorimotor model architecture that can be pretrained on robotic manipulation-relevant data realistically available in quantity. Our experimental results show that \appr demonstrate strong zero-shot performance and can be effectively finetuned with demonstrations to further boost its performance. In particular, \appr shows superior performance on human-collected demonstrations because of its usage of relative positional encoding.

\vspace{-2mm}
\paragraph{Limitations}
We believe that \appr\ has great potential as a model architecture for general robotic manipulation, but in most of our experiments so far, the training data came from the same robot on which the trained model was ultimately deployed. In reality, most available multi-task video demonstration data $\mtvd$ is generated by other robots or even people. This can cause a mismatch between the demonstrations and the target robot's capabilities and setups. Planning hierarchically first in the skill space as, e.g., in \citet{lynch2019play}, and then in the observation embedding space may address this issue. In addition, so far we have trained \appr\ on simulated data. The eventual goal, and indeed a significant motivation for this work, would be to pretrain on internet-scale ``in-the-wild'' video datasets~\cite{youtue8m,ho2022imagenvideo,grauman2022ego4d}. Also, with the rise of powerful LLMs such as \citet{instructrl2022}, switching \appr\ to language for task specification can facilitate  generalization across tasks.

