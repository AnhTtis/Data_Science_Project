\vspace{-5pt}
In this paper, we address the 3D inconsistency problem within SDS-based text-to-3D generation. We propose a novel framework, dubbed \ours, that effectively incorporates 3D awareness into a pretrained 2D diffusion model. Our method utilizes viewpoint-specific depth maps from a coarse 3D structure, complemented with a sparse depth injector and semantic code sampling for semantic consistency. Our approach offers a practical solution for addressing the limitations of current text-to-3D generation techniques and opens up possibilities for generating more realistic 3D scenes from text prompts. Our experimental results demonstrate the effectiveness of our framework, outperforming previous models in quantitative metrics and qualitative human evaluation.


