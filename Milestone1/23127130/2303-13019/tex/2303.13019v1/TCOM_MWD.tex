%\documentclass[journal]{IEEEtran}
%\documentclass[11pt, draftclsnofoot, onecolumn]{IEEEtran}
\documentclass[journal,draftcls,onecolumn,12pt,twoside]{IEEEtranTCOM}
% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf

\else

\fi




\usepackage{mathrsfs}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{indentfirst}
\usepackage{array}
\usepackage{cite}
\usepackage{enumerate}
\usepackage{bm}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{algorithmic}
\usepackage{multirow}
\usepackage{epstopdf}
\usepackage{verbatim}
\usepackage{stfloats}
\usepackage{color}
\usepackage{caption}
\usepackage{booktabs}
\usepackage{footnote}


\newtheorem{theorem}{\bf{Theorem}}
\newtheorem{lemma}{\bf{Lemma}}
\newtheorem{proposition}{\bf{Proposition}}
\newtheorem{corollary}{\bf{Corollary}}
\newtheorem{conjecture}{\bf{Conjecture}}
\newtheorem{definition}{\bf{Definition}}
\newtheorem{remark}{\bf{Remark}}
\SetKwComment{Comment}{//}{}

\begin{document}

\title{{Construction Methods Based Minimum Weight Distribution for Polar Codes with Successive Cancellation List Decoding}}
\author{Jinnan Piao, Dong Li, Jindi Liu, Xueting Yu, Zhibo Li, Ming Yang, and Peng Zeng
\thanks{
%This work was supported in part by the National Key Research and Development Program of China under Grant 2018YFE0205801, in part by the Ningbo Science and Technology Program under Grant 2018B10089 and in part by the Liaoning Soft Science Research Program under Grant 2021JH4/10400014. (\emph{Corresponding Author: Dong Li})
This work is supported in part by the National Natural Science Foundation of China under Grant 62201562, in part by the Ningbo Science and Technology Program under Grant 2018B10089 and in part by the Liaoning Soft Science Research Program under Grant 2021JH4/10400014. (\emph{Corresponding Author: Dong Li})
}
%\thanks{Copyright (c) 2015 IEEE. Personal use of this material is permitted. However, permission to use this material for any other purposes must be obtained from the IEEE by sending a request to pubs-permissions@ieee.org.}
%\thanks{This work is supported by National Key R\&D Program of China (No. 2018YFE0205501), the National Natural Science Foundation of China (No. 62201562). {\it (Corresponding author: Dong Li.)}}
\thanks{
The authors are with the State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences, Shenyang 110016, China, with the Key Laboratory of Networked Control Systems,  Chinese Academy of Sciences, Shenyang 110016, China, and also with the Institutes for Robotics and Intelligent Manufacturing, Chinese Academy of Sciences, Shenyang 110169, China.
(e-mail: piaojinnan@sia.cn; lidong@sia.cn; liujindi@sia.cn; yuxueting@sia.cn; lizhibo@sia.cn; yangming@sia.cn; zp@sia.cn).
}
}

\maketitle
\begin{abstract}

In this paper, we focus on the construction methods based MWD for polar codes to improve the performance with successive cancellation list (SCL) decoding. We first propose an ordered and nested reliability sequence, namely MWD sequence, to improve the ML performance of polar codes and apply fast construction without the original channel information. In the MWD sequence, the synthetic channels are sorted by the partial MWD which is used to evaluate the influence of information bit on MWD and we prove the MWD sequence is the optimum sequence under ML decoding. Then, since the list size of SCL decoding is limited, we introduce an entropy constraint to establish a relationship between the list size and the ML performance and propose a heuristic and greedy construction method named bit grouping reorder based MWD (BGR-MWD) algorithm. In the algorithm, we divide the synthetic channels into groups by the partial MWD and greedily reorder the synthetic channels in some groups until the entropy constraint is satisfied. The simulation results show the MWD sequence is suitable for constructing polar codes with short code length. Meanwhile, the BGR-MWD algorithm has superior performance over the traditional construction methods for long code length.

\end{abstract}

\begin{IEEEkeywords}
Polar codes, sequence construction, minimum weight distribution, monomial codes, successive cancellation list decoding.
\end{IEEEkeywords}


\IEEEpeerreviewmaketitle

\section{Introduction}

\subsection{Relative Research}

\IEEEPARstart{P}{olar} codes, invented by Ar{\i}kan, have been proved to achieve the capacity of arbitrary binary-input discrete memoryless channels (B-DMCs) as the code length goes to infinity with the successive cancellation (SC) decoding \cite{arikan}.
However, the performance of polar codes is weak at short to moderate code lengths under SC decoding. To improve the block error rate (BLER) performance, the successive cancellation list (SCL) decoding \cite{niuscl,talvardyscl} is proposed.
Since polar codes demonstrate advantages in error performance and other attractive application prospects, they have been adopted as the coding scheme for the control channel of the enhanced Mobile Broadband (eMBB) service category in the fifth generation wireless communication systems (5G) \cite{3GPP_5G_polar}.

According to the polarization effect, the original channels of polar codes are transformed into synthetic channels
with different reliability. The construction of polar codes is selecting the most reliable synthetic channels to transmit information bits and others to transmit frozen bits.
The widely used design principle is to minimize the BLER under the SC decoding. The Bhattacharyya parameter \cite{arikan} is the first construction method to precisely calculate the mutual information of each synthetic channel in the binary erasure channel (BEC).
For other B-DMCs, the density evolution (DE) algorithm, initially proposed in \cite{DE} and improved in \cite{TalVardy}, tracks the probability distribution of the logarithmic likelihood ratio (LLR) of each synthetic channel and provides theoretical guarantees on the estimation accuracy with a high computational cost.
For the binary-input additive white Gaussian noise (BI-AWGN) channel, the Gaussian approximation (GA) algorithm \cite{GA,GA_DAI} approximates the probability distribution of the LLR as Gaussian distribution and gives accurate reliability evaluation with limited complexity.
For fading channels, the polar spectrum \cite{PolarSpectrum, PolarSpectrumFastFading} is proposed to derive the upper bound of the
error probability of the synthetic channels in order to construct polar codes.
Generally, the above algorithms are known as channel-dependent construction, since the reliabilities of synthetic channels are derived from the original channel parameters.

From the viewpoint of system design, the construction should be independent of channel conditions in order to facilitate the practical application of polar codes. Sch{\"u}rch \cite{PartialOrder} first finds the partial reliability order is invariant in any B-DMC and proposes the concept of partial order (PO).
Then, He \emph{et al.} \cite{PW} propose the polarization weight (PW) algorithm exploiting the index expansion of synthetic channels to design a universal reliability sequence without the channel parameters. However, the PW sequence has performance loss for polar codes with the code length $N \ge 1024$.
In 5G, polar codes are constructed by a fixed universal polar sequence \cite{5GDesignPolar} for all the code configurations by computer searching with the maximum polar sequence length $1024$.

To improve the performance of polar codes under SCL decoding,
several construction algorithms based on machine learning \cite{ConstructionAI,ConstructionGenetic,ConstructionRL} are first proposed and have remarkable performance with extreme complexity.
Then, Mondelli \emph{et al.} \cite{RMpolar} show that the performance of polar codes with SCL decoding depends on its maximum likelihood (ML) performance.
To minimize the ML performance of short precoded polar codes,
Miloslavskaya \emph{et al.} \cite{DesShortPolarSCL, RecDesPolarSCL} propose a construction method under SCL decoding to optimize the precoding matrix with a large number of code search.

A method to evaluate the ML performance is calculating the union bound (UB) by the distance spectrum of polar codes.
Nevertheless, enumerating the distance spectrum has exponential complexity and it is almost impossible for long code length. In the high signal-to-noise ratio (SNR) region, the minimum weight distribution (MWD) is the main factor influencing the UB \cite{LinShuBook}.
To analyze the MWD of polar codes, the SCL based methods \cite{ADSCL,dsliu,CRCdesign} with excessively large list size are used to enumerate the codewords. Then, a polynomial-time method is proposed in \cite{calculate_MWD} to calculate the MWD of polar codes obeying the PO.
For any construction of polar-like codes, the sphere constraint based enumeration methods \cite{sphereMWD} are proposed to analyze the MWD.
The MWD is also used to optimize the CRC-polar concatenated codes to make the BLER performance close to the normal approximation of BI-AWGN capacity for short code length \cite{PolarOpt0025}. Thus, MWD is a critical metric to evaluate the ML decoding performance and optimize polar codes under SCL decoding.

\subsection{Motivation}

The SCL decoding is widely used for polar codes and its performance can approach the ML performance with limited list size \cite{talvardyscl}. Meanwhile, the MWD is an effective metric to evaluate ML performance. Thus, in this paper, we focus on the construction methods based MWD to improve the performance of polar codes under SCL decoding.

\subsection{Main Contributions}

In this paper, we introduce a new concept named partial MWD to evaluate the influence of each synthetic channel on MWD.
Based on the partial MWD, we design an ordered and nested reliability sequence, namely MWD sequence, to improve the ML performance of polar codes and apply fast construction without the original channel information.
Then, due to the limited list size of SCL decoding in practice, we establish a relationship between the list size and the ML performance and propose a heuristic and greedy construction method named bit grouping reorder based MWD (BGR-MWD) algorithm to construct polar codes with SCL decoding.

The main contributions of this paper can be summarized as follows.

\begin{enumerate}
  \item We first introduce a new concept on the synthetic channels of polar codes, named partial MWD, which is used to evaluate the influence of each synthetic channel on the MWD when the information bit is transmitted in the synthetic channel.
      Then, on the basis of the partial MWD, we order the synthetic channels and obtain a construction sequence unrelated to the original channel information, called MWD sequence.
      Finally, we prove that the MWD sequence is nested and the polar codes constructed by the MWD sequence have the optimum ML performance compared with traditional construction methods.
  \item A heuristic and greedy BGR-MWD algorithm is proposed to approach the ML performance of polar codes under SCL decoding with limited list size.
      To design the BGR-MWD algorithm, we first establish a relationship between the list size and the ML performance by the entropy of the synthetic channels transmitting information bits, named entropy constraint.
      Then, the BGR-MWD algorithm divides the synthetic channels into several groups according to the partial MWD and greedily reorders the synthetic channels in some groups until the information set satisfies the entropy constraint.
      We propose two reorder methods in this paper. The first is based on the entropy of the synthetic channels. The second uses the PW sequence to reorder the synthetic channels in order to improve the practicability of the BGR-MWD algorithm.

\end{enumerate}

The experimental results show that the proposed MWD sequence is suitable for constructing polar codes for short code length and has about $1.13$dB performance gain compared with the polar sequence in 5G for code length $128$ at code rate $0.75$ and BLER $10^{-4}$. Meanwhile, the BGR-MWD algorithm can be regarded as a good construction and shows better BLER performance under SCL decoding than other traditional construction methods for long code length.
Specifically, it has about $0.7$dB performance gain compared with the GA algorithm for code length $1024$ at code rate $0.75$ and BLER $10^{-3}$.

The remainder of the paper is organized as follows. Section
II describes the preliminaries of polar codes, MWD and SCL decoding.
In Section III, we introduce the concept of partial MWD and propose the MWD sequence. The BGR-MWD algorithm is proposed in Section IV. Section V shows the performance of polar codes constructed by the MWD sequence and the BGR-MWD algorithm. Section VI concludes this paper.

\section{Notations and Preliminaries}

\subsection{Notation Conventions}

In this paper, the lowercase letters, e.g., $x$, are used to denote scalars. The bold lowercase letters (e.g., ${\bf{x}}$) are used to denote vectors.
Notation ${{\bf x}_i^j}$ denotes the subvector $(x_i,\cdots,x_j)$ and $x_i$ denotes the $i$-th element of ${\bf{x}}$.
The sets are denoted by calligraphic characters, e.g., $\cal{X}$, and the notation $|\cal{X}|$ denotes the cardinality of $\cal{X}$.
%In addition, ${\cal X} \backslash x$ denotes the set with element $x$ excluded.
The bold capital letters, such as $\bf{X}$, are used to denote matrices.
%The notation $\bf{X}^\prime$ stand for the transpose transpose of $\mathbf{X}$.
%The element in the $i$-th row and the $j$-th column of matrix $\bf{X}$ is written as $x_{i,j}$.
Furthermore, we write ${\bf{F}}^{\otimes n}$ to denote the $n$-th Kronecker power of $\bf{F}$.
Throughout this paper, $\bf 0$ and $\bf 1$ mean an all-zero vector and an all-one vector, respectively, and $\log \left(  \cdot  \right)$ means ``base 2 logarithm''.

\subsection{Polar Codes}

Polar codes depend on the polarization effect \cite{arikan} of the matrix
${{\bf F} = \left[
\begin{smallmatrix}
1&0\\
1&1
\end{smallmatrix}
\right]}$.
For an $(N,K)$ polar code with code length $N = 2^n$ and code rate $R = K/N$, the polarization effect generates $N$ synthetic channels $W_N^{\left(i\right)}, i = 0,1,\cdots,N-1$.
Each synthetic channel has different reliability $R\left(W_N^{\left(i\right)}\right)$ and the information bits are transmitted in the $K$ most reliable synthetic channels.
Therefore, the information set of polar codes defined by ${\cal A}$ with cardinality $|{\cal A}|=K$ is composed of the indices of the $K$ most reliable synthetic channels. Then, the frozen set ${\cal A}^c$ with cardinality $|{\cal A}^c|=N-K$ is a complementary set of ${\cal A}$.
The codeword ${\bf c}$ of the polar code is calculated by ${\bf c}  = {\bf u}{\bf G}$, where ${\bf u}$ is an $N$-length information sequence and ${\bf G}$ is ${\bf F}^{\otimes n}$.
The information sequence ${\bf u}$ is generated by assigning $u_i$ to information bit if $i \in {\cal A}$, and assigning $u_i$ to $0$ if $i \in {\cal A}^c$.

Without loss of generality, the AWGN channel and binary phase shift keying (BPSK) modulation are considered in this paper. Thus, each coded bit $c_i \in \left\{0,1\right\}$ is modulated into the transmitted signal by $s_i = 1 - 2c_i$. Then, the received sequence is ${\bf y} = {\bf s} + {\bf n}$, where $n_i$ is i.i.d. AWGN with zero mean and variance $\sigma^2$.


\subsection{Minimum Weight Distribution}

The distance spectrum of an $(N,K)$ binary linear block code, denoted by $A_d$, is the number of codewords of the code with the Hamming weight $d$. The pairwise error probability between two codewords modulated by BPSK differing in $d$ positions and coherently detected in the AWGN channel is $Q\left(\sqrt{\frac{{2dRE_b}}{{{N_0}}}}\right)$, where $E_b$ is the energy of the transmitted bit, $N_0$ is the one-sided power spectral density of AWGN and
\begin{equation}\label{Q_function}
Q(x)=\frac{1}{{\sqrt {2\pi }  }}\int_x^\infty  {{e^{ - \frac{{{t^2}}}{2}}}dt}
\end{equation}
is the probability that a Gaussian random variable with zero mean and unit variance exceeds the value $x$. Assuming that an all-zero codeword $\bf 0$ is transmitted, the UB \cite{LinShuBook} of ML performance is
\begin{equation}\label{union_bound}
P_e
\le \sum\limits_{d = {d_{\min }}}^N {{A_d}Q\left( {\sqrt {\frac{{2dR{E_b}}}{{{N_0}}}} } \right)} .
\end{equation}

Then, since the MWD (i.e., $d_{\min}$ and $A_{d_{\min}}$) is the main factor influencing the ML performance in the high SNR region \cite{LinShuBook}, (\ref{union_bound}) is approximated as
\begin{equation}\label{union_bound_a}
P_e \approx {{A_{d_{\min}}}Q\left( {\sqrt {\frac{{2{d_{\min}}R{E_b}}}{{{N_0}}}} } \right)},
\end{equation}
where $d_{\min}$ is the minimum Hamming weight of the linear block code and ${A_{d_{\min}}}$ is the number of the codewords with $d_{\min}$. In this paper, the approximate UB (AUB) calculated by (\ref{union_bound_a}) is used to evaluate the ML performance of polar codes.

\subsection{Successive Cancellation List Decoding}

Polar codes can be decoded by the SC decoding algorithm with the decoding complexity $O(N\log N)$.
Although SC decoding can achieve the channel capacity with the infinite code length, its performance is unsatisfactory for the short or medium code lengths.

Thus, the SCL decoding is proposed, which recursively computes $P_i({\hat {\bf u}}_0^i, {\bf y}) \propto \Pr({\hat {\bf u}}_0^i, {\bf y})$ for $i=0,1,\cdots,N-1$ with the process similar to the SC decoding except keeping at most $L$ survival paths. Discarding ${\bf y}$ from $P_i({\hat {\bf u}}_0^i, {\bf y})$, $P_i({\hat {\bf u}}_0^i)$ is referred as the myopic likelihood of the sequence ${\hat {\bf u}}_0^i$.
Let ${\mathcal U}_{i} \subseteq \left\{0,1\right\}^{i+1}, i = 0,\cdots, N-1$ be the subset including the $L$ survival paths at the $i$-th decoding step and we have
\begin{equation}
P_i({\hat {\bf u}}_0^i) \propto \Pr({\hat {\bf u}}_0^i, {\bf y}) \propto P_{i-1}({\hat {\bf u}}_0^{i-1}) \Pr({\hat u}_i|{\hat {\bf u}}_0^{i-1}, {\bf y}).
\end{equation}
When $u_{i+1}$ is an information bit, the $L$ survival paths in ${\mathcal U}_{i}$ are split into $2L$ paths with attempting calculating $P_{i+1}({\hat {\bf u}}_0^i, {\hat u}_{i+1}=0)$ and $P_{i+1}({\hat {\bf u}}_0^i, {\hat u}_{i+1}=1)$.
Then, ${\mathcal U}_{i+1}$ is decided by selecting the $L$ most likely paths with larger $P_{i+1}({\hat {\bf u}}_0^{i+1})$ from the $2L$ split paths. When $u_{i+1}$ is frozen bit, the $L$ survival paths in ${\mathcal U}_{i}$ are simply extended with the correct frozen bit.



\section{Minimum Weight Distribution Sequence}

In this section, we first describe the decreasing monomial codes and the calculation process of the MWD of polar codes.
Then, the concept of partial MWD is introduced to evaluate the influence of synthetic channel transmitting information bit on MWD.
Finally, we use the partial MWD to design the nested MWD sequence and prove that the polar codes constructed by the MWD sequence have the optimum ML performance.

\subsection{Decreasing Monomial Codes}

An $\left(N, K\right)$ polar code can be viewed as a decreasing monomial code with the monomial set ${\mathcal M}$ and the information subset ${\mathcal I}$.
Each synthetic channel of polar codes corresponds to a monomial.
For the synthetic channel $W_N^{\left(i\right)}$,
%$i$-th row of the generator matrix $\bf G$,
the binary representation
of $i$ is
\begin{equation}\label{binary_i}
{\bf b}^i = \left[b_0^i,b_1^i\cdots,b_{n-1}^i\right],
\end{equation}
where $b_0^i$ and $b_{n-1}^i$ are the least significant bit and the most significant bit, respectively.
Given the binary variable collection $\left\{x_0,x_1,\cdots,x_{n-1}\right\}$, the monomial $f_i$ corresponding to $W_N^{\left(i\right)}$ contains the variables with
the bit-positions of zero in ${\bf b}^i$, i.e.,
\begin{equation}\label{monomial_l}
f_i = \prod_{l=0}^{n-1}{x_l^{1 - b_l^i}} = \prod_{m = 1}^{\deg \left(f_i\right)}{x_{i_m}},
\end{equation}
where $i_m$ is the index of the $l$-th zero in ${\bf b}^i$ with $i_1 < \cdots < i_{\deg \left(f_i\right)}$
and $\deg \left(f_i\right)$ is the degree of $f_i$, i.e.,
\begin{equation}\label{degfi}
\deg \left(f_i\right) = n - \sum_{l=0}^{n-1}{b_l^i}.
\end{equation}

The monomial set ${\mathcal M}$ including all the $N$ monomials is
\begin{equation}\label{Mn}
{\mathcal M} = \left\{f_i\left| i=0,1,\cdots,N-1 \right. \right\}
\end{equation}
and the information subset ${\mathcal I}$ is
\begin{equation}\label{monomial_I}
{\mathcal I} = \left\{f_i\left| i \in {\mathcal A} \right. \right\}.
\end{equation}

In \cite{PartialOrder} and \cite{calculate_MWD}, the synthetic channels exhibit a PO ``$\preceq$'' with respect to their reliability, i.e., $f_i \preceq f_j$ means $W_N^{\left(i\right)}$ is more reliable than $W_N^{\left(j\right)}$. The PO for the monomials with the same degree is defined as follows.
\begin{definition}\label{def1_PO}
Given two monomials $f_i = \prod_{m=1}^{D}{{{x}_{i_m}}}$ and $f_j = \prod_{m=1}^{D}{{{x}_{j_m}}}$ with the same degree $D = \deg \left(f_i\right) = \deg \left(f_j\right)$, we have $f_i \preceq f_j$,
if and only if $i_m \le j_m, m = 1,2,\cdots,D$.
\end{definition}

The definition of the PO for the monomials with different degrees is as follows.
\begin{definition}\label{def2_PO}
Given two monomials $f_i = \prod_{m=1}^{\deg(f_i)}{{{x}_{i_m}}}$ and $f_j = \prod_{m=1}^{\deg(f_j)}{{{x}_{j_m}}}$ with $\deg(f_i) \neq \deg(f_j)$, we have $f_i \preceq f_j$, if and only if there is a divisor $f_j^*$ of $f_j$ making $f_i \preceq f_j^*$.
\end{definition}


A polar code is a decreasing monomial code with the monomials in ${\mathcal I}$ obeying the PO in Definition \ref{def1_PO} and Definition \ref{def2_PO}, which means that if $W_N^{\left(j\right)}$ is selected as the information channel, all the synthetic channels more reliable than $W_N^{\left(j\right)}$ satisfying the PO are also the information channels, i.e., if $f_i \preceq f_j$ and $f_j \in {\mathcal I}$, we have $f_i \in {\mathcal I}$.

For the decreasing monomial codes, a method to calculate the MWD is introduced in \cite{calculate_MWD}. Let ${\mathcal I}_r$ be the subset of ${\mathcal I}$ with the monomials having degree $r$, i.e.,
\begin{equation}
{\mathcal I}_r = \left\{f_i \left| \deg(f_i) = r, f_i \in {\mathcal I} \right.\right\},
\end{equation}
and $r_{\max}^{\mathcal I}$ be the maximum degree of the monomials in ${\mathcal I}$, i.e.,
\begin{equation}
r_{\max}^{\mathcal I} = \max_{f_i \in {\mathcal I}}{\deg{(f_i)}}.
\end{equation}
The number of the minimum weight codewords with ${\mathcal I}$ is
\begin{equation}\label{CalMWDAdmin}
A_{d_{\min}}^{\mathcal I} = 2^{r_{\max}^{\mathcal I}} \times \sum_{f_i \in {\mathcal I}_{r_{\max}^{\mathcal I}}}{2^{\left|\lambda_{f_i}\right|}},
\end{equation}
where the minimum Hamming weight with the subset ${\mathcal I}$ is
\begin{equation}\label{CalMWDdmin}
d_{\min}^{\mathcal I} = 2^{n-r_{\max}^{\mathcal I}}
\end{equation}
and
\begin{equation}\label{LamedaCal}
\left|\lambda_{f_i}\right| =\frac{\deg(f_i)\left(1-\deg(f_i)\right)}{2} + \sum_{m=1}^{\deg(f_i)}{i_m}.
\end{equation}


\subsection{Partial MWD}

We propose a new concept, namely partial MWD, which is used to evaluate the influence of each synthetic channel on the MWD when the synthetic channel is selected to transmit the information bit.

Assuming that existing an ordered construction sequence ${\bf q} = \left[q_0,q_1,\cdots,q_{N-1}\right]$ obeys the PO in Definition \ref{def1_PO} and Definition \ref{def2_PO} with $W_N^{(q_{k-1})}$ more reliable than $W_N^{(q_{k})}$, given the subset
\begin{equation}
{\mathcal I}^{k} = \left\{f_{q_0},f_{q_1},\cdots,f_{q_{k-1}}\right\},
\end{equation}
according to \eqref{CalMWDAdmin} and \eqref{CalMWDdmin}, the difference of the MWD between ${\mathcal I}^{k}$ and ${\mathcal I}^{k-1}$ is as follows:
\begin{enumerate}
  \item If $\deg(f_{q_k}) = r_{\max}^{{\mathcal I}^{k-1}}$, we have
      $d_{\min}^{{\mathcal I}^{k}} = d_{\min}^{{\mathcal I}^{k-1}} = 2^{n-\deg(f_{q_k})}$
      and
     $ A_{d_{\min}}^{{\mathcal I}^k} - A_{d_{\min}}^{{\mathcal I}^{k-1}} = 2^{\deg(f_{q_k}) + \left|\lambda_{f_{q_k}}\right|}$.
  \item If $\deg(f_{q_k}) > r_{\max}^{{\mathcal I}^{k-1}}$, we have
      $d_{\min}^{{\mathcal I}^k} = 2^{n-\deg(f_{q_k})} < d_{\min}^{{\mathcal I}^{k-1}}$
      and
      $A_{d_{\min}}^{{\mathcal I}^k} = 2^{\deg(f_{q_k}) + \left|\lambda_{f_{q_k}}\right|}$.
  \item If $\deg(f_{q_k}) < r_{\max}^{{\mathcal I}^{k-1}}$, we have
      $d_{\min}^{{\mathcal I}^{k}} = d_{\min}^{{\mathcal I}^{k-1}}$
      and
      $A_{d_{\min}}^{{\mathcal I}^k} = A_{d_{\min}}^{{\mathcal I}^{k-1}}$.
\end{enumerate}

As shown above, the MWD is changed in 1) and 2) and the MWD difference is related to $f_{q_k}$.
Thus, the partial MWD is defined as
\begin{definition}\label{DefinitionPartialMWD}
The partial MWD of $W_N^{(i)}$ is a two-tuple $\left(d_i, A_i\right)$ with
\begin{equation}\label{PMWDdmin}
d_i = 2^{n-\deg(f_{i})}
\end{equation}
and
\begin{equation}\label{PMWDAdmin}
A_i = 2^{\deg(f_{i}) + \left|\lambda_{f_{i}}\right|}.
\end{equation}
\end{definition}

The partial MWD $\left(d_i, A_i\right)$ means the influence on the MWD when $W_N^{(i)}$ is selected as the information channel with the information set ${\mathcal A}$ obeying the PO.

\subsection{Construction Sequence Based MWD}

In this part, we first propose criteria to order the $N$ synthetic channels based on the partial MWD and design a construction sequence. Then, we prove that the sequence is nested and has the optimum performance evaluated by the AUB in \eqref{union_bound_a}.

The relationship of the partial MWD associated with the PO shown in Definition \ref{def1_PO} and Definition \ref{def2_PO} is provided in Lemma \ref{LemmaPO1} and Lemma \ref{LemmaPO2}, respectively.
\begin{lemma}\label{LemmaPO1}
For the PO in Definition \ref{def1_PO}, given $f_i = \prod_{m=1}^{D}{{{x}_{i_m}}}$ and $f_j = \prod_{m=1}^{D}{{{x}_{j_m}}}$ with $f_i \preceq f_j$ and $D = \deg \left(f_i\right) = \deg \left(f_j\right)$, we have $A_i < A_j$.
\end{lemma}
\begin{proof}
According to \eqref{LamedaCal} and \eqref{PMWDAdmin}, we have
$A_i = 2^{\frac{3D-D^2}{2} + \sum_{m=1}^{D}{i_m}}$ and
$A_j = 2^{\frac{3D-D^2}{2} + \sum_{m=1}^{D}{j_m}}$.
By Definition \ref{def1_PO}, we have
$\sum_{m=1}^{D}{i_m} < \sum_{m=1}^{D}{j_m}$.
Thus, $A_i < A_j$ is derived.
\end{proof}

\begin{lemma}\label{LemmaPO2}
For the PO in Definition \ref{def2_PO}, given two monomials $f_i$ and $f_j $ with $\deg(f_i) < \deg(f_j)$ and $f_i \preceq f_j$, we have $d_i > d_j$.
\end{lemma}
\begin{proof}
The proof is clear by \eqref{PMWDdmin}.
\end{proof}

Then, the order criteria for $W_N^{(i)}$ based on the partial MWD are as follows:
\begin{enumerate}
  \item According to Lemma \ref{LemmaPO2}, $W_N^{(i)}$ with larger $d_i$ has the larger $R\left(W_N^{\left(i\right)}\right)$ than others.
  \item According to Lemma \ref{LemmaPO1}, when the synthetic channels have the identical $d_i$, $W_N^{(i)}$ with less $A_i$ has the larger $R\left(W_N^{\left(i\right)}\right)$ than the others.
  \item When the synthetic channels have the identical $d_i$ and $A_i$, $W_N^{(i)}$ with larger $i$ has the larger $R\left(W_N^{\left(i\right)}\right)$ than others.
\end{enumerate}



Based on criterion 1), the monomials of $W_N^{(i)}$, $i = 0, 1, \cdots, N-1$ are divided into $(n+1)$ subsets
\begin{equation}\label{DivideM}
{\mathcal M}_r = \left\{ f_i \left| \deg(f_i) = r, f_i \in {\mathcal M} \right. \right\}, r = 0,1,\cdots,n.
\end{equation}
and the monomials in ${\mathcal M}_r$ have the identical $d_i$, i.e.,
\begin{equation}\label{dMonomialSubset}
d_i = 2^{n-r}, f_i \in {\mathcal M}_r.
\end{equation}
Then, let ${\mathcal B}_r$ be the subset of the indices of the synthetic channels corresponding to the monomials in ${\mathcal M}_r$, i.e.,
\begin{equation}\label{DivideA}
{\mathcal B}_r = \left\{ i \left| f_i \in {\mathcal M}_r \right. \right\}, r = 0,1,\cdots,n.
\end{equation}
Hence, the synthetic channels in different subsets have different reliability levels, i.e.,
\begin{equation}\label{cre1dRelia}
\begin{aligned}
R\left(W_N^{\left(i\right)}\right) > R\left(W_N^{\left(j\right)}\right),
\text{ if }
i \in {\mathcal B}_r, j \in {\mathcal B}_{s} \text{ and } r < s.
\end{aligned}
\end{equation}

Then, criterion 2) is used to order the synthetic channels in the identical subset. For $W_N^{\left(i\right)}$ with $i \in {\mathcal B}_r$, calculate $A_i$ by \eqref{PMWDAdmin}. The reliability order is
\begin{equation}
\begin{aligned}
R\left(W_N^{\left(i\right)}\right) > R\left(W_N^{\left(j\right)}\right),
\text{ if }
A_i < A_j, i \in {\mathcal B}_r \text{ and } j \in {\mathcal B}_r.
\end{aligned}
\end{equation}

Finally, the synthetic channels in the identical subset with the same partial MWD are ordered by criterion 3). The reliability order is
\begin{equation}
\begin{aligned}
R\left(W_N^{\left(i\right)}\right) > R\left(W_N^{\left(j\right)}\right),
\text{ if }
i > j, A_i = A_j, i \in {\mathcal B}_r \text{ and } j \in {\mathcal B}_r.
\end{aligned}
\end{equation}

\begin{algorithm}[t]
\setlength{\abovecaptionskip}{0.cm}
\setlength{\belowcaptionskip}{-0.cm}
\caption{MWD sequence}\label{SequenceDesign}

\KwIn {The code length $N$;}
\KwOut {The $N$-length MWD sequence ${\bf q}$;}

Calculate $\left(d_i, A_i\right)$ of $W_N^{(i)}, i=0,1,\cdots,N-1$ by \eqref{PMWDdmin} and \eqref{PMWDAdmin}\;

Divide the $N$ synthetic channels into $(n+1)$ subsets ${\mathcal B}_r, r = 0,1,\cdots,n$ by \eqref{DivideA}\;

Initialize $B_r \leftarrow \sum_{i=0}^{r}{\left|{\mathcal B}_i\right|}, r = 0,1,\cdots,n$ and $B_{-1} = 0$\;

\For{$r = 0,1,\cdots,n$}
{
    Initialize a $\left| {\mathcal B}_r \right|$-length sequence ${\bf p}$\;

    Initialize ${\mathcal T} \leftarrow {\mathcal B}_r$ and $j \leftarrow 0$\;

    \While{${\mathcal T} \ne \varnothing$}
    {
        ${\mathcal Q} \leftarrow \underset{i \in {\mathcal T}}{\mathop{\arg \min }}\,A_i $\;
        $a \leftarrow {\mathop{\max }}\, {\mathcal Q}$\;
        $p_j \leftarrow a$,
        $j \leftarrow j + 1$ and
        ${\mathcal T} \leftarrow {\mathcal T} - a$\;
    }
    \For{$k = 0,1,\cdots,\left|{\mathcal B}_r\right|-1$}
    {
        ${q}_{B_{r-1}+k} \leftarrow {p}_k$\;
    }
}
\Return $\bf q$\;
\end{algorithm}



According to the criteria, the reliability order is clear and the construction sequence based MWD is designed directly. The corresponding design method is described in Algorithm \ref{SequenceDesign}.

In step 1 and step 2 of Algorithm \ref{SequenceDesign}, we calculate the partial MWD $\left(d_i, A_i\right)$ of $W_N^{(i)}, i=0,1,\cdots,N-1$ and divide the $N$ synthetic channels into $\left(n+1\right)$ subsets ${\mathcal B}_r, r = 0,1,\cdots, n$ by \eqref{DivideA}.
Clearly, according to \eqref{DivideM} to \eqref{cre1dRelia}, the Hamming weight of the synthetic channel in ${\mathcal B}_r$ is larger than that in ${\mathcal B}_s$ if $r < s$, which obeys criterion 1).
Then, in step 5 and step 6, we initialize a $\left|{\mathcal B}_r\right|$-length vector ${\bf p}$ and a set ${\mathcal T}$,
where ${\bf p}$ records the ordered result of the $\left|{\mathcal B}_r\right|$ elements in ${\mathcal B}_r$ and ${\mathcal T}$ includes the indices of the unordered synthetic channels in ${\mathcal B}_r$.
Step 8 obeys criterion 2) and obtains the set ${\mathcal Q}$ including the indices of the synthetic channels in ${\mathcal B}_r$ with the minimum $A_i$.
Step 9 obeys criterion 3) and decides the index of the most reliable synthetic channel from ${\mathcal Q}$, i.e, the maximum element $a$ in ${\mathcal Q}$.
In step 10, $a$ is recorded in $\bf p$ and deleted from ${\mathcal T}$.
In step 11 and step 12, $\bf p$ is recorded in the $N$-length MWD sequence ${\bf q}$.
After all the synthetic channels are ordered, the MWD sequence ${\bf q}$ is decided, which can be used to construct polar codes with the reliability order $R\left(W_N^{\left(q_i\right)}\right) > R\left(W_N^{\left(q_j\right)}\right)$ if $i < j$.





Then, in Lemma \ref{LemmaML}, we prove the polar codes constructed by the MWD sequence have the optimum performance evaluated by the AUB in \eqref{union_bound_a}.
In Lemma \ref{LemmaNested}, we prove the MWD sequence is nested, which means that the MWD sequence can be used similarly to the polar sequence \cite{3GPP_5G_polar} in 5G.



\begin{lemma}\label{LemmaML}
An $(N,K)$ polar code constructed by the MWD sequence $\bf q$ has the optimum ML performance evaluated by the AUB in the high SNR region.
\end{lemma}
\begin{proof}
In the high SNR region, according to \eqref{union_bound_a}, the AUB increases as $d_{\min}$ decreases. When $d_{\min}$ is fixed, the AUB increases as $A_{d_{\min}}$ increases. Hence, the optimum polar code should ensure having 1) the maximum $d_{\min}$ and 2) the minimum $A_{d_{\min}}$ when $d_{\min}$ is identical.

Let an $(N,K)$ polar code ${\mathcal C}$ constructed by $\bf q$ has the information set
\begin{equation}\label{MWDSA}
{\mathcal A} = \left\{q_0,q_1,\cdots,q_{K-1} \right\}.
\end{equation}
The information set ${\mathcal A}'$ of any other polar code ${\mathcal C}'$ has at least one element with the index equal or larger than $K$, i.e.,
$\exists q_i \in {\mathcal A}'$ making $i \ge K$.
According to criterion 1), the minimum Hamming weight of ${\mathcal C}$ is $d_{\min} = d_{q_{K-1}}$ and we have
$d_{q_{K-1}} \ge d_i, i = K,K+1,\cdots,N-1$.
Thus, the polar code constructed by $\bf q$ has the maximum $d_{\min}$.

Assuming that the minimum Hamming weight of ${\mathcal C}'$ is
$d_{\min}' = d_{\min}$, the numbers of codewords of ${\mathcal C}$ and ${\mathcal C}'$ with the minimum Hamming weight $d_{\min}$ are
$A_{d_{\min}} = \sum_{i \in ({\mathcal A} \cap {\mathcal B}_{r}) }{A_i}$ and
$A_{d_{\min}'} = \sum_{i \in ({\mathcal A}' \cap {\mathcal B}_{r}) }{A_i}$, respectively, where $r = n - \log{d_{\min}}$. According to criterion 2), $\forall \overline{\mathcal B} \subseteq {\mathcal B}_{r}$ with $|\overline{\mathcal B}| = |{\mathcal A} \cap {\mathcal B}_{r}|$ makes
\begin{equation}\label{EqLeAdmin1}
A_{d_{\min}} \le \sum_{i \in \overline{\mathcal B}}{A_i}.
\end{equation}
Then, since
$|{\mathcal A} \cap {\mathcal B}_{r}| \le |{\mathcal A}' \cap {\mathcal B}_{r}|$, we can obtain
$\exists \overline{\mathcal B} \subseteq ({\mathcal A}' \cap {\mathcal B}_{r})$ with $|\overline{\mathcal B}| = |{\mathcal A} \cap {\mathcal B}_{r}|$ making
\begin{equation}\label{EqLeAdmin2}
\sum_{i \in \overline{\mathcal B}}{A_i} \le A_{d_{\min}'}.
\end{equation}
According to \eqref{EqLeAdmin1} and \eqref{EqLeAdmin2}, we have
$A_{d_{\min}} \le A_{d_{\min}'}$.
Hence, the polar code constructed by $\bf q$ has the minimum $A_{d_{\min}}$ when $d_{\min}$ is identical. Thus, Lemma \ref{LemmaML} is proved.
\end{proof}



\begin{lemma}\label{LemmaNested}
Let ${\bf q}^N = \left[q_0^{N}, q_1^{N},\cdots,q_{N-1}^{N}\right]$ and ${\bf q}^{2N} = \left[q_0^{2N}, q_1^{2N},\cdots,q_{2N-1}^{2N}\right]$ be $N$-length and $2N$-length MWD sequences, respectively. For any ${q}_i^{N}$ and ${q}_j^{N}$ with $i < j$, we can find ${q}_k^{2N} = q_i^{N}$ and ${q}_l^{2N} = q_j^{N}$ with $k < l$, which means that the MWD sequence is nested.
\end{lemma}
\begin{proof}
Let $f_{{q}_i^{N}}$, $f_{{q}_j^{N}}$, $f_{{q}_k^{2N}}$ and $f_{{q}_l^{2N}}$ be the monomials corresponding to ${q}_i^{N}$, ${q}_j^{N}$, ${q}_k^{2N}$ and ${q}_l^{2N}$,  respectively.
Given ${q}_k^{2N} = q_i^{N}$ and ${q}_l^{2N} = q_j^{N}$, we have
%\begin{equation}
%\begin{aligned}
%\label{LemmaNestEq1}
%{q}_k^{2N} = q_i^{N} &\Rightarrow f_{{q}_k^{2N}} = f_{{q}_i^{N}} \cdot x_{n} \\ &\Rightarrow \deg(f_{{q}_k^{2N}}) = \deg(f_{{q}_i^{N}}) + 1,
%\end{aligned}
%\end{equation}
%\begin{equation}
%\begin{aligned}
%\label{LemmaNestEq2}
%{q}_l^{2N} = q_j^{N} &\Rightarrow f_{{q}_l^{2N}} = f_{{q}_j^{N}} \cdot x_{n} \\
%&\Rightarrow \deg(f_{{q}_l^{2N}}) = \deg(f_{{q}_j^{N}}) + 1.
%\end{aligned}
%\end{equation}
\begin{equation}
\begin{aligned}
\label{LemmaNestEq1}
{q}_k^{2N} = q_i^{N} \Rightarrow f_{{q}_k^{2N}} = f_{{q}_i^{N}} \cdot x_{n} \Rightarrow \deg(f_{{q}_k^{2N}}) = \deg(f_{{q}_i^{N}}) + 1,
\end{aligned}
\end{equation}
\begin{equation}
\begin{aligned}
\label{LemmaNestEq2}
{q}_l^{2N} = q_j^{N} \Rightarrow f_{{q}_l^{2N}} = f_{{q}_j^{N}} \cdot x_{n} \Rightarrow \deg(f_{{q}_l^{2N}}) = \deg(f_{{q}_j^{N}}) + 1.
\end{aligned}
\end{equation}
Assuming $i < j$, we have $d_{{q}_i^{N}} \ge d_{{q}_j^{N}}$, which leads to
\begin{equation}
\deg(f_{{q}_i^{N}}) \le \deg(f_{{q}_j^{N}}) \Rightarrow \deg(f_{{q}_k^{2N}}) \le \deg(f_{{q}_l^{2N}}).
\end{equation}
If $\deg(f_{{q}_i^{N}}) < \deg(f_{{q}_j^{N}})$, by \eqref{LemmaNestEq1} and \eqref{LemmaNestEq2}, we obtain
\begin{equation}
\deg(f_{{q}_k^{2N}}) < \deg(f_{{q}_l^{2N}}) \Rightarrow d_{{q}_k^{2N}} > d_{{q}_l^{2N}} \Rightarrow k < l.
\end{equation}
If $\deg(f_{{q}_i^{N}}) = \deg(f_{{q}_j^{N}})$, we have
$A_{{{q}_i^{N}}} \le A_{{{q}_j^{N}}}$, since $i < j$.
By \eqref{PMWDAdmin}, we have
\begin{equation}\label{LemmaNestEq5}
A_{{{q}_k^{2N}}} \le A_{{{q}_l^{2N}}}.
\end{equation}
Equality holds in \eqref{LemmaNestEq5} iff $A_{{{q}_i^{N}}} = A_{{{q}_j^{N}}}$.
For $A_{{{q}_k^{2N}}} < A_{{{q}_l^{2N}}}$,we have $k < l$ by criterion 2).
For $A_{{{q}_k^{2N}}} = A_{{{q}_l^{2N}}}$, we have $A_{{{q}_i^{N}}} = A_{{{q}_j^{N}}}$, which derives
\begin{equation}
{q}_i^{N} > {q}_j^{N} \Rightarrow {q}_k^{2N} > {q}_l^{2N} \Rightarrow k < l
\end{equation}
by criterion 3).
Hence, Lemma \ref{LemmaNested} is proved.
\end{proof}



\begin{figure}[t]
\setlength{\abovecaptionskip}{0.cm}
\setlength{\belowcaptionskip}{-0.cm}
  \centering{\includegraphics[scale=0.5]{MWDExample.pdf}}
  \caption{Fig. \ref{FigExampleMWD}(a), Fig. \ref{FigExampleMWD}(b) and Fig. \ref{FigExampleMWD}(c) illustrate the examples of the nested MWD sequences with $N = 4, 8, 16$, respectively.}\label{FigExampleMWD}
  \vspace{-0em}
\end{figure}



Then, Fig. \ref{FigExampleMWD} provides examples to illustrate the MWD sequence. In Fig. \ref{FigExampleMWD} (a), Fig. \ref{FigExampleMWD}(b) and Fig. \ref{FigExampleMWD}(c), the examples of the MWD sequences with $N = 4, 8, 16$ are provided, respectively.
For each example, we calculate the partial MWD by \eqref{PMWDdmin} and \eqref{PMWDAdmin} and obtain the MWD sequence by Algorithm \ref{SequenceDesign}.
The MWD sequences in Fig. \ref{FigExampleMWD}(a), Fig. \ref{FigExampleMWD}(b) and Fig. \ref{FigExampleMWD}(c) are
\begin{align}
{\bf q}^4 &= \left[3,2,1,0\right],\\
{\bf q}^8 &= \left[7,6,5,3,4,2,1,0\right],\\
{\bf q}^{16} &= \left[15,14,13,11,7,12,10,9,6,5,3,8,4,2,1,0\right].
\end{align}
The elements colored green in ${\bf q}^4$ have the identical order in ${\bf q}^8$ and ${\bf q}^{16}$. Then, the elements colored blue in ${\bf q}^8$ also have the same order in ${\bf q}^{16}$. Thus, ${\bf q}^4$ is nested in ${\bf q}^8$ which is also nested in ${\bf q}^{16}$.

\begin{remark}
By Lemma \ref{LemmaNested}, given an $N_{\max}$-length MWD sequence ${\bf q}^{N_{\max}}$, any $(N,K)$ polar code with $N \le N_{\max}$ can be constructed by ${\bf q}^{N_{\max}}$. The construction method is identical to the polar sequence in 5G, which means the MWD sequence is practical.
\end{remark}

\begin{remark}
Though polar codes constructed by the MWD sequence have the optimum performance by Lemma \ref{LemmaML}, achieving the performance is difficult for long code length under the SCL decoding with limited list size. Thus, a suitable construction method based MWD for SCL decoding is required.
\end{remark}


\section{Construction Methods Based MWD for SCL Decoding}

In this section, we first introduce the construction criterion according to the information-theoretic perspective on SCL decoding. Then, we use the criterion to provide a construction method called BGR-MWD algorithm.

\subsection{Construction Criterion}

The information-theoretic perspective on SCL decoding proposed in \cite{InformationSCL} establishes the relationship between the average list size and the ML decoding over binary memoryless symmetric channels in Theorem \ref{theorem1}.

\begin{theorem}\label{theorem1}
The set of survival path ${\hat {\bf u}}_0^i$ with a larger likelihood than some fraction of that for true path ${\bf u}_0^i$ after the $i$-stage of SCL decoding is
\begin{equation}\label{theoEq1}
{\mathcal S}_{\alpha}^{(i)}\left({\bf u}_0^i\right) \triangleq \left\{{\hat {\bf u}}_0^i|P_i({\hat {\bf u}}_0^i) \ge \alpha P_i({{\bf u}}_0^i) \right\},
\end{equation}
where the fraction is $\alpha \le 1$. The average of the logarithm of the cardinality is upper bounded by
\begin{equation}\label{theo1upper}
\mathbb{E}\left[ \log{|{\mathcal S}_{\alpha}^{(i)}|} \right] \le \log{\alpha^{-1}} +\sum_{j \in {\mathcal A}^{(i)}}{H\left(W_N^{(j)}\right)},
\end{equation}
where ${\mathcal A}^{(i)} \triangleq {\mathcal A} \bigcap \left\{0,1,\cdots,i\right\}$ and ${H\left(W_N^{(j)}\right)}$ is the entropy of $W_N^{(j)}$.
\end{theorem}

Assuming $\alpha = 1$, \eqref{theoEq1} is simplified as
\begin{equation}
{\mathcal S}_{1}^{(i)}\left({\bf u}_0^i\right) \triangleq \left\{{\hat {\bf u}}_0^i|P_i({\hat {\bf u}}_0^i) \ge P_i({{\bf u}}_0^i) \right\}.
\end{equation}
The SCL decoding can achieve the ML performance if $L$ satisfies
\begin{equation}\label{BGRcre1}
L \ge |{\mathcal S}_{1}^{(i)}|, i = 0,1,\cdots,N-1.
\end{equation}


Due to obtain ${\mathcal S}_{1}^{(i)}$ requiring high search complexity, $|{\mathcal S}_{1}^{(i)}|$ is replaced with the average list size $\mathbb{E}\left[ \log{|{\mathcal S}_{1}^{(i)}|} \right]$ and we obtain
\begin{equation}\label{BGRcre2}
\log{L} \ge \mathbb{E}\left[ \log{|{\mathcal S}_{1}^{(i)}|} \right].
\end{equation}
Introducing \eqref{theo1upper} into \eqref{BGRcre2}, $L$ should satisfies
\begin{equation}\label{BGRcre3}
\log{L} \ge \sum_{j \in {\mathcal A}^{(i)}}{H\left(W_N^{(j)}\right)} \ge \mathbb{E}\left[ \log{|{\mathcal S}_{1}^{(i)}|} \right].
\end{equation}
Hence, to make the SCL decoding after the $N$-stage achieve the ML performance, $L$ should satisfy the entropy constraint as
\begin{equation}\label{BGRcre4}
\log{L} \ge {H\left({\mathcal A}\right)},
\end{equation}
where ${H\left({\mathcal A}\right)} \triangleq \sum_{j \in {\mathcal A}}{H\left(W_N^{(j)}\right)}$.

\begin{lemma}\label{lemma5}
Polar codes constructed by GA algorithm have the minimum ${H\left({\mathcal A}\right)}$.
\end{lemma}
\begin{proof}
In GA algorithm, $W_N^{(j)}$ is regarded as a BI-AWGN channel and the equivalent noise variance is $\sigma_j^2$.
For an $(N,K)$ polar code, GA algorithm selects $K$ synthetic channels with the minimum $\sigma_j^2$ to decide the information set ${\mathcal A}$. Then, due to $H\left(W_N^{(j)}\right) \propto \sigma_j^2$, the polar code constructed by GA algorithm has the minimum ${H\left({\mathcal A}\right)}$.
\end{proof}

By Lemma \ref{lemma5}, polar codes constructed by GA algorithm shows the minimum ${H\left({\mathcal A}\right)}$ satisfying \eqref{BGRcre4}
and can achieve ML performance by the SCL decoding with limited list size.
However, the influence of the MWD on ML performance is not considered in GA algorithm.
By contrast, the proposed MWD sequence has the optimum ML performance, but can not achieve the ML performance for long code length with limited list size, since the MWD sequence unsatisfies the entropy constraint in \eqref{BGRcre4}.

Thus, a trade-off between the GA algorithm and the MWD sequence should be considered for constructing the polar codes under SCL decoding. The construction criterion is optimizing the MWD while satisfying the entropy constraint.


\subsection{Bit Grouping Reorder Based MWD Algorithms}

\begin{algorithm}[t]
\setlength{\abovecaptionskip}{0.cm}
\setlength{\belowcaptionskip}{-0.cm}
\caption{BGR-MWD algorithm}\label{BGRMWDGA}

\KwIn {The code length $N$, the information length $K$ and the list size $L$;}
\KwOut {The information set ${\mathcal A}$;}

Divide the $N$ synthetic channels into $(n+1)$ subsets ${\mathcal B}_r, r = 0,1,\cdots,n$ by \eqref{DivideA}\;
Calculate $H\left(W_N^{(j)}\right)$, $j=0,1,\cdots,N-1$\;
Decide ${\mathcal A}$ by the MWD sequence ${\bf q}$\;
Find $k$ making ${\mathcal A} \bigcap {\mathcal B}_k \ne \varnothing$ and ${\mathcal A} \bigcap {\mathcal B}_{k+1} = \varnothing$\;
Set $a \leftarrow k - 1$ and $b \leftarrow k$\;

\While{$\log{L} < {H\left({\mathcal A}\right)}$}
{
    ${\mathcal B} \leftarrow \bigcup\limits_{r=a,\cdots ,b}{\mathcal B}_r$ and obtain ${\mathcal T}$ by \eqref{BGRMWDGAT}\;
    \If{${\mathcal A} = \left({\mathcal{A}}-{\mathcal{A}}\bigcap {\mathcal{B}} \right)\bigcup {\mathcal{T}}$ and $a = 0$ and $b = n$}
    {
        {\bf break}\;
    }
    ${\mathcal A} \leftarrow \left({\mathcal{A}}-{\mathcal{A}}\bigcap {\mathcal{B}} \right)\bigcup {\mathcal{T}}$\;
    $a \leftarrow \max{(a - 1, 0)}$ and $b \leftarrow \min{(b + 1, n)}$\;
}
\Return ${\mathcal A}$\;
\end{algorithm}

\begin{algorithm}[t]
\setlength{\abovecaptionskip}{0.cm}
\setlength{\belowcaptionskip}{-0.cm}
\caption{BGR-MWD-PW algorithm}\label{BGRMWDPW}
\KwIn {The code length $N$, the information length $K$ and the list size $L$;}
\KwOut {The information set ${\mathcal A}$;}

Divide the $N$ synthetic channels into $(n+1)$ subsets ${\mathcal B}_r, r = 0,1,\cdots,n$ by \eqref{DivideA}\;
Calculate $H\left(W_N^{(j)}\right)$, $j=0,1,\cdots,N-1$\;
Decide ${\mathcal A}$ by the MWD sequence ${\bf q}$\;
Find $k$ making ${\mathcal A} \bigcap {\mathcal B}_k \ne \varnothing$ and ${\mathcal A} \bigcap {\mathcal B}_{k+1} = \varnothing$\;
Set $a \leftarrow k - 1$ and $b \leftarrow k$\;
Calculate the PW sequence $\bf w$\;

\While{$\log{L} < {H\left({\mathcal A}\right)}$}
{
    ${\mathcal B} \leftarrow \bigcup\limits_{r=a,\cdots ,b}{\mathcal B}_r$ and obtain ${\mathcal T}$ by \eqref{BGRMWDPWT}\;
    \If{$a = 0$ and $b = n$}
    {
        {\bf break}\;
    }

    ${\mathcal A} \leftarrow \left({\mathcal{A}}-{\mathcal{A}}\bigcap {\mathcal{B}} \right)\bigcup {\mathcal{T}}$\;
    $a \leftarrow \max{(a - 1, 0)}$ and $b \leftarrow \min{(b + 1, n)}$\;
}
\Return ${\mathcal A}$\;
\end{algorithm}

To satisfy the construction criterion, we propose a heuristic and greedy algorithm named BGR-MWD algorithm.
The BGR-MWD algorithm divides the synthetic channels into several groups by the partial MWD and gradually reorders the synthetic channels in some groups to reduce ${H\left({\mathcal A}\right)}$ until the entropy constraint is satisfied.
We propose two BGR-MWD algorithms and the corresponding processes are described in Algorithm \ref{BGRMWDGA} and Algorithm \ref{BGRMWDPW} with reorder methods based on entropy and PW sequence, respectively.

\begin{figure}[t]
\setlength{\abovecaptionskip}{0.cm}
\setlength{\belowcaptionskip}{-0.cm}
  \centering{\includegraphics[scale=0.5]{BGRMWDExample.pdf}}
  \caption{The information sets obtained by BGR-MWD and BGR-MWD-PW algorithms with $N=32$, $K=16$, $L=2$ and $E_b/N_0=1.25$dB.}\label{FigExampleBGRMWDExample}
  \vspace{-0em}
\end{figure}

In Algorithm \ref{BGRMWDGA}, we first divide $N$ synthetic channels into $(n+1)$ subsets ${\mathcal B}_r, r = 0,1,\cdots,n$ by \eqref{DivideA} and decide ${\mathcal A}$ by the MWD sequence ${\bf q}$.
Then, we judge ${\mathcal A}$ satisfying \eqref{BGRcre4} or not.
If not, we reorder the synthetic channels in some groups according to $H\left(W_N^{\left(j\right)}\right)$ as follows.
First, we find $k$ making ${\mathcal A} \bigcap {\mathcal B}_k \ne \varnothing$ and ${\mathcal A} \bigcap {\mathcal B}_{k+1} = \varnothing$ and
decide the initial reorder groups ${\mathcal B}_r$, $r = a, \cdots, b$ with $a = k - 1$ and $b = k$. Second, given ${\mathcal B} = \bigcup\limits_{r=a,\cdots ,b}{\mathcal B}_r$, we find $|{\mathcal A} \bigcap {\mathcal B}|$ synthetic channels in ${\mathcal B}$ with the minimum $H\left(W_N^{\left(j\right)}\right)$ , i.e.,
\begin{equation}\label{BGRMWDGAT}
{\mathcal{T}}=\underset{{\mathcal{T}}\in {\mathcal{B}},\left| {\mathcal{T}} \right|=\left| {\mathcal{A}}\bigcap {\mathcal{B}} \right|}{\mathop{\arg \min }}\,\sum\limits_{j\in {\mathcal{T}}}{H\left(W_N^{(j)}\right)}.
\end{equation}
Third, update ${\mathcal A} \leftarrow \left({\mathcal{A}}-{\mathcal{A}}\bigcap {\mathcal{B}} \right)\bigcup {\mathcal{T}}$ and judge the new information set satisfying \eqref{BGRcre4} or not.
If not, enlarge the reorder groups by $a \leftarrow \max{(a - 1, 0)}$ and $b \leftarrow \min{(b + 1, n)}$ and reorder the synthetic channels in ${\mathcal B}_r$, $r = a, \cdots, b$ until ${\mathcal A}$ satisfies \eqref{BGRcre4} or no information set can satisfy \eqref{BGRcre4}, i.e., when $a = 0$ and $b = n$, ${\mathcal A}$ is unchanged after updating.

Furthermore, we use the PW sequence to order the synthetic channels in the reorder groups, which is named BGR-MWD-PW algorithm described in Algorithm \ref{BGRMWDPW}. The process of Algorithm \ref{BGRMWDPW} is similar to that of Algorithm \ref{BGRMWDGA} except step 8 which uses the PW sequence ${\bf w}$ to decide the $\left| {\mathcal{A}}\bigcap {\mathcal{B}} \right|$ most reliable synthetic channels in ${\mathcal B}$, i.e.,
\begin{equation}\label{BGRMWDPWT}
{\mathcal{T}}=\underset{{\mathcal{T}}\in {\mathcal{B}},\left| {\mathcal{T}} \right|=\left| {\mathcal{A}}\bigcap {\mathcal{B}} \right|}{\mathop{\arg \max }}\,\sum\limits_{j\in {\mathcal{T}}}{w_j}.
\end{equation}



\begin{remark}
When the reorder groups ${\mathcal B}_r$, $r = a, \cdots, b$ are fixed, we can modify ${\mathcal A}$ by reordering the synthetic channels in ${\mathcal B} = \bigcup\limits_{r=a,\cdots ,b}{\mathcal B}_r$, which means ${\mathcal A}$ can be decided by the parameters $N$, $K$, $a$, $b$, $\bf q$ and $\bf w$. Thus, a potential practical construction table can be designed by establishing the relationship among $N$, $K$, $a$ and $b$ so as to construct polar codes unrelated to the channel parameters.
\end{remark}



Fig. \ref{FigExampleBGRMWDExample} shows the information sets obtained by BGR-MWD and BGR-MWD-PW algorithms, where $N=32$, $K=16$, $L=2$ and $E_b/N_0=1.25$dB.
In Fig. \ref{FigExampleBGRMWDExample}, the information set ${\mathcal A}$ decided by ${\bf q}$ is
\begin{equation}\label{EqExampleBGR1}
{\mathcal A} = \left\{31,30,29,27,23,15,28,26,25,22,21,14,19,13,11,7\right\}.
\end{equation}
Then, due to
\begin{equation}
\log L=1 < {H\left({\mathcal A}\right)}=1.064,
\end{equation}
we should optimize ${\mathcal A}$ to satisfy \eqref{BGRcre4}. By Algorithm \ref{BGRMWDGA}, ${\mathcal A}$ is modified as
\begin{equation}\label{EqExampleBGR2}
{\mathcal A} = \left\{31,30,29,27,23,15,28,26,25,22,21,14,19,13,11,24\right\},
\end{equation}
which satisfies \eqref{BGRcre4}, i.e.,
\begin{equation}
\log L=1 > {H\left({\mathcal A}\right)}=0.993.
\end{equation}
Hence, the information set in \eqref{EqExampleBGR2} is more suitable than that in \eqref{EqExampleBGR1} for the $(32,16)$ polar code with $L = 2$.
By Algorithm \ref{BGRMWDPW}, we also obtain the same information set as \eqref{EqExampleBGR2}.



\section{Performance Evaluation}

In this section, we first provide the performance of polar codes with MWD sequence. Then, the performance of polar codes with BGR-MWD and BGR-MWD-PW algorithms is illustrated.

\subsection{Simulation Results of MWD Sequence}



%\begin{table}[t]
%\renewcommand\arraystretch{1}
%  \centering
%  \caption{The MWD sequence ${\bf q}^{128}$ with $N = 128$.}\label{TabMWDsequenceN128}
%  %\resizebox{\linewidth}{!}
%  {
%\begin{tabular}{|c|c|c|c|c|c|c|c|}
%\hline
%${\bf q}_0^{15}$& ${\bf q}_{16}^{31}$ & ${\bf q}_{32}^{47}$  & ${\bf q}_{48}^{63}$ & ${\bf q}_{64}^{79}$& ${\bf q}_{80}^{95}$ & ${\bf q}_{96}^{111}$ & ${\bf q}_{112}^{127}$\\ \hline
%127 & 94  & 108 & 54 & 112 & 70 & 13 & 18 \\ \hline
%126 & 107 & 113 & 83 & 104 & 49 & 11 & 12 \\ \hline
%125 & 93  & 106 & 77 & 100 & 42 & 7  & 17 \\ \hline
%123 & 62  & 92  & 53 & 88  & 28 & 96 & 10 \\ \hline
%119 & 103 & 105 & 46 & 98  & 69 & 80 & 9  \\ \hline
%111 & 91  & 102 & 75 & 84  & 41 & 72 & 6  \\ \hline
%95  & 61  & 90  & 51 & 56  & 38 & 48 & 5  \\ \hline
%63  & 87  & 60  & 45 & 97  & 26 & 68 & 3  \\ \hline
%124 & 59  & 101 & 30 & 82  & 67 & 40 & 64 \\ \hline
%122 & 79  & 89  & 71 & 76  & 37 & 66 & 32 \\ \hline
%121 & 55  & 86  & 43 & 52  & 25 & 36 & 16 \\ \hline
%118 & 47  & 58  & 29 & 81  & 22 & 24 & 8  \\ \hline
%117 & 31  & 99  & 39 & 74  & 35 & 65 & 4  \\ \hline
%110 & 120 & 85  & 27 & 50  & 21 & 34 & 2  \\ \hline
%115 & 116 & 78  & 23 & 44  & 14 & 20 & 1  \\ \hline
%109 & 114 & 57  & 15 & 73  & 19 & 33 & 0  \\ \hline
%\end{tabular}
%}
%\end{table}
\begin{table}[t]
\renewcommand\arraystretch{0.8}
\centering
\caption{The MWD sequence ${\bf q}^{128}$ with $N = 128$.}\label{TabMWDsequenceN128}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline
${\bf q}_0^{7}$& ${\bf q}_{8}^{15}$ & ${\bf q}_{16}^{23}$  & ${\bf q}_{24}^{31}$ & ${\bf q}_{32}^{39}$& ${\bf q}_{40}^{47}$ & ${\bf q}_{48}^{55}$ & ${\bf q}_{56}^{63}$ & ${\bf q}_{64}^{71}$& ${\bf q}_{72}^{79}$ & ${\bf q}_{80}^{87}$  & ${\bf q}_{88}^{95}$ & ${\bf q}_{96}^{103}$& ${\bf q}_{104}^{111}$ & ${\bf q}_{112}^{119}$ & ${\bf q}_{120}^{127}$
\\ \hline
127 & 124 & 94  & 59  & 108 & 101 & 54 & 30 & 112 & 82 & 70 & 67 & 13 & 40 & 18 & 64 \\ \hline
126 & 122 & 107 & 79  & 113 & 89  & 83 & 71 & 104 & 76 & 49 & 37 & 11 & 66 & 12 & 32 \\ \hline
125 & 121 & 93  & 55  & 106 & 86  & 77 & 43 & 100 & 52 & 42 & 25 & 7  & 36 & 17 & 16 \\ \hline
123 & 118 & 62  & 47  & 92  & 58  & 53 & 29 & 88  & 81 & 28 & 22 & 96 & 24 & 10 & 8  \\ \hline
119 & 117 & 103 & 31  & 105 & 99  & 46 & 39 & 98  & 74 & 69 & 35 & 80 & 65 & 9  & 4  \\ \hline
111 & 110 & 91  & 120 & 102 & 85  & 75 & 27 & 84  & 50 & 41 & 21 & 72 & 34 & 6  & 2  \\ \hline
95  & 115 & 61  & 116 & 90  & 78  & 51 & 23 & 56  & 44 & 38 & 14 & 48 & 20 & 5  & 1  \\ \hline
63  & 109 & 87  & 114 & 60  & 57  & 45 & 15 & 97  & 73 & 26 & 19 & 68 & 33 & 3  & 0  \\ \hline
\end{tabular}
\vspace{-0em}
\end{table}
%\begin{table}[htbp]
%%\renewcommand\arraystretch{1}
%  \centering
%  \caption{The MWD sequence ${\bf q}^{256}$ with $N = 256$.}\label{TabMWDsequenceN256}
%  %\resizebox{\linewidth}{!}
%  {
%\begin{tabular}{|c|c|c|c|c|c|c|c|}
%\hline
%${\bf q}_0^{31}$& ${\bf q}_{32}^{63}$ & ${\bf q}_{64}^{95}$  & ${\bf q}_{96}^{127}$ & ${\bf q}_{128}^{159}$& ${\bf q}_{160}^{191}$ & ${\bf q}_{192}^{223}$ & ${\bf q}_{224}^{255}$\\ \hline
%255 & 119 & 118 & 216 & 105 & 27  & 134 & 80  \\ \hline
%254 & 159 & 203 & 226 & 102 & 23  & 81  & 132 \\ \hline
%253 & 111 & 179 & 212 & 90  & 15  & 74  & 72  \\ \hline
%251 & 95  & 173 & 184 & 60  & 224 & 50  & 48  \\ \hline
%247 & 63  & 158 & 225 & 163 & 208 & 44  & 130 \\ \hline
%239 & 248 & 117 & 210 & 149 & 200 & 133 & 68  \\  \hline
%223 & 244 & 110 & 204 & 142 & 176 & 73  & 40  \\  \hline
%191 & 242 & 199 & 180 & 101 & 196 & 70  & 129 \\  \hline
%127 & 236 & 171 & 120 & 89  & 168 & 49  & 66  \\  \hline
%252 & 241 & 157 & 209 & 86  & 112 & 42  & 36  \\  \hline
%250 & 234 & 115 & 202 & 58  & 194 & 28  & 24  \\  \hline
%249 & 220 & 109 & 178 & 147 & 164 & 131 & 65  \\  \hline
%246 & 233 & 94  & 172 & 141 & 152 & 69  & 34  \\  \hline
%245 & 230 & 167 & 116 & 99  & 104 & 41  & 20  \\  \hline
%238 & 218 & 155 & 201 & 85  & 193 & 38  & 33  \\  \hline
%243 & 188 & 107 & 198 & 78  & 162 & 26  & 18  \\  \hline
%237 & 229 & 93  & 177 & 57  & 148 & 67  & 12  \\ \hline
%222 & 217 & 62  & 170 & 54  & 100 & 37  & 17  \\  \hline
%235 & 214 & 151 & 156 & 139 & 88  & 25  & 10  \\  \hline
%221 & 186 & 103 & 114 & 83  & 161 & 22  & 9   \\  \hline
%190 & 124 & 91  & 108 & 77  & 146 & 35  & 6   \\  \hline
%231 & 227 & 61  & 197 & 53  & 140 & 21  & 5   \\  \hline
%219 & 213 & 143 & 169 & 46  & 98  & 14  & 3   \\  \hline
%189 & 206 & 87  & 166 & 135 & 84  & 19  & 128 \\  \hline
%126 & 185 & 59  & 154 & 75  & 56  & 13  & 64  \\  \hline
%215 & 182 & 79  & 113 & 51  & 145 & 11  & 32  \\ \hline
%187 & 122 & 55  & 106 & 45  & 138 & 7   & 16  \\  \hline
%125 & 211 & 47  & 92  & 30  & 97  & 192 & 8   \\  \hline
%207 & 205 & 31  & 195 & 71  & 82  & 160 & 4   \\  \hline
%183 & 181 & 240 & 165 & 43  & 76  & 144 & 2   \\  \hline
%123 & 174 & 232 & 153 & 29  & 52  & 96  & 1   \\  \hline
%175 & 121 & 228 & 150 & 39  & 137 & 136 & 0   \\ \hline
%\end{tabular}
%}
%\end{table}
\begin{table}[t]
\renewcommand\arraystretch{0.8}
\centering
\caption{The MWD sequence ${\bf q}^{256}$ with $N = 256$.}\label{TabMWDsequenceN256}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline
${\bf q}_0^{15}$& ${\bf q}_{16}^{31}$ & ${\bf q}_{32}^{47}$  & ${\bf q}_{48}^{63}$ & ${\bf q}_{64}^{79}$& ${\bf q}_{80}^{95}$ & ${\bf q}_{96}^{111}$ & ${\bf q}_{112}^{127}$ &
${\bf q}_{128}^{143}$& ${\bf q}_{144}^{159}$ & ${\bf q}_{160}^{175}$  & ${\bf q}_{176}^{191}$ & ${\bf q}_{192}^{207}$& ${\bf q}_{208}^{223}$ & ${\bf q}_{224}^{239}$ & ${\bf q}_{240}^{255}$\\ \hline
255 & 237 & 119 & 229 & 118 & 93  & 216 & 177 & 105 & 57  & 27  & 148 & 134 & 67  & 80  & 12  \\ \hline
254 & 222 & 159 & 217 & 203 & 62  & 226 & 170 & 102 & 54  & 23  & 100 & 81  & 37  & 132 & 17  \\ \hline
253 & 235 & 111 & 214 & 179 & 151 & 212 & 156 & 90  & 139 & 15  & 88  & 74  & 25  & 72  & 10  \\ \hline
251 & 221 & 95  & 186 & 173 & 103 & 184 & 114 & 60  & 83  & 224 & 161 & 50  & 22  & 48  & 9   \\ \hline
247 & 190 & 63  & 124 & 158 & 91  & 225 & 108 & 163 & 77  & 208 & 146 & 44  & 35  & 130 & 6   \\ \hline
239 & 231 & 248 & 227 & 117 & 61  & 210 & 197 & 149 & 53  & 200 & 140 & 133 & 21  & 68  & 5   \\ \hline
223 & 219 & 244 & 213 & 110 & 143 & 204 & 169 & 142 & 46  & 176 & 98  & 73  & 14  & 40  & 3   \\ \hline
191 & 189 & 242 & 206 & 199 & 87  & 180 & 166 & 101 & 135 & 196 & 84  & 70  & 19  & 129 & 128 \\ \hline
127 & 126 & 236 & 185 & 171 & 59  & 120 & 154 & 89  & 75  & 168 & 56  & 49  & 13  & 66  & 64  \\ \hline
252 & 215 & 241 & 182 & 157 & 79  & 209 & 113 & 86  & 51  & 112 & 145 & 42  & 11  & 36  & 32  \\ \hline
250 & 187 & 234 & 122 & 115 & 55  & 202 & 106 & 58  & 45  & 194 & 138 & 28  & 7   & 24  & 16  \\ \hline
249 & 125 & 220 & 211 & 109 & 47  & 178 & 92  & 147 & 30  & 164 & 97  & 131 & 192 & 65  & 8   \\ \hline
246 & 207 & 233 & 205 & 94  & 31  & 172 & 195 & 141 & 71  & 152 & 82  & 69  & 160 & 34  & 4   \\ \hline
245 & 183 & 230 & 181 & 167 & 240 & 116 & 165 & 99  & 43  & 104 & 76  & 41  & 144 & 20  & 2   \\ \hline
238 & 123 & 218 & 174 & 155 & 232 & 201 & 153 & 85  & 29  & 193 & 52  & 38  & 96  & 33  & 1   \\ \hline
243 & 175 & 188 & 121 & 107 & 228 & 198 & 150 & 78  & 39  & 162 & 137 & 26  & 136 & 18  & 0   \\ \hline
\end{tabular}
\vspace{-0em}
\end{table}

In this subsection, the MWD sequence obtained by Algorithm \ref{SequenceDesign} is first provided. Then, the BLER performance of polar codes constructed by the MWD sequence is shown. The polar codes are decoded by SCL decoding.

Table \ref{TabMWDsequenceN128} and Table \ref{TabMWDsequenceN256} provide the proposed MWD sequence ${\bf q}^{256}$ and ${\bf q}^{128}$, respectively.
From Table \ref{TabMWDsequenceN128} and Table \ref{TabMWDsequenceN256}, we can observe that the order of the elements in ${\bf q}^{128}$ is identical to that in ${\bf q}^{256}$, which means the MWD sequence is nested and can replace the polar sequence \cite{3GPP_5G_polar} in 5G.

Fig. \ref{FigTargetSNR} shows the minimum required SNRs of polar codes constructed by polar sequence, GA algorithm and MWD sequence to achieve the target BLER under the AWGN channel with the code rate range $R = 0.0625 \sim 0.9375$. The required SNRs of AUB equal to the target BLER are also provided.
The MWD sequences in Table \ref{TabMWDsequenceN128} and Table \ref{TabMWDsequenceN256} are used to construct polar codes in Fig. \ref{FigTargetSNR}(a) and Fig. \ref{FigTargetSNR}(b), respectively.



Fig. \ref{FigTargetSNR}(a) provides the required SNRs of SCL decoding with $N=128$, $L = 8$ and BLER $\le 10^{-4}$.
In Fig. \ref{FigTargetSNR}(a), we observe that the required SNRs of polar sequence, GA algorithm and MWD sequence are close to the required SNRs of corresponding AUB.
Since the polar codes constructed by the MWD sequence have the optimum AUB, the required SNRs are less than or equal to those of the polar sequence and GA algorithm.
Specifically, the MWD sequence shows about $0.68$dB and $1.13$dB SNR gaps at $R = 0.75$ compared with the GA algorithm and the polar sequence, respectively.
Thus, MWD sequence can improve the performance of polar codes with medium list size for short code length.
Then, there is about $0.45$dB SNR gap between the MWD sequence and the corresponding AUB at $R = 0.5$, which means SCL decoding with list size larger than $8$ can provides less minimum required SNR to achieve BLER $\le 10^{-4}$.

\begin{figure}[t]
\setlength{\abovecaptionskip}{0.cm}
\setlength{\belowcaptionskip}{-0.cm}
  \centering{\includegraphics[scale=0.42]{TargetSNR.pdf}}
  \caption{Fig. \ref{FigTargetSNR}(a) and Fig. \ref{FigTargetSNR}(b) illustrate the minimum required SNRs of polar codes decoded by SCL decoding with $L = 8$ and $L = 16$ to achieve BLER $\le 10^{-4}$ and BLER $\le 10^{-3}$ under the AWGN channel with $N = 128$ and $N = 256$, respectively.}\label{FigTargetSNR}
  \vspace{-0em}
\end{figure}


Fig. \ref{FigTargetSNR}(b) provides the required SNRs of SCL decoding with $N=256$, $L = 16$ and BLER $\le 10^{-3}$.
In Fig. \ref{FigTargetSNR}(b), the optimum AUB of the MWD sequence also leads to the corresponding minimum required SNRs less than or equal to those of GA algorithm and polar sequence.
The MWD sequence has about $0.75$dB and $1.07$dB SNR gaps at $R = 0.5625$ compared with the GA algorithm and the polar sequence, respectively.
Compared with Fig. \ref{FigTargetSNR}(a), more cases show SNR gaps between the MWD sequence and the AUB.
Specifically, the SNR gaps are $0.38$dB, $1.37$dB and $0.83$dB at $R = 0.3125$, $R = 0.375$ and $R = 0.625$, respectively.
The reason is that as the code length increases, the polar codes constructed by the MWD sequence cannot satisfy \eqref{BGRcre4}, which means the required SNRs of the MWD sequence with limited list size deviate from the ML performance. Thus, increasing list size can further improve the performance of MWD sequence to approach the ML performance.

In general, the MWD sequence is a nested construction method unrelated to the channel parameters and can replace the polar sequence in 5G for short polar codes with superior performance under SCL decoding over other sequence construction methods.


\subsection{Simulation Results of BGR-MWD Algorithms}

\begin{figure}[t]
\setlength{\abovecaptionskip}{0.cm}
\setlength{\belowcaptionskip}{-0.cm}
  \centering{\includegraphics[scale=0.42]{N1024.pdf}}
  \caption{The BLER performance of polar codes constructed by different construction methods with $N = 1024$ and $L = 32$, where the information lengths of Fig. \ref{FigN1024K256L32}(a), Fig. \ref{FigN1024K256L32}(b) and Fig. \ref{FigN1024K256L32}(c) are $K = 256$, $K=512$ and $K=768$, respectively}\label{FigN1024K256L32}
  \vspace{-0em}
\end{figure}

In this subsection, we first provide the BLER performance of the proposed BGR-MWD and BGR-MWD-PW algorithms. Then, the BLER performance with different list sizes is provided.

\begin{figure}[t]
\setlength{\abovecaptionskip}{0.cm}
\setlength{\belowcaptionskip}{-0.cm}
  \centering{\includegraphics[scale=0.42]{List.pdf}}
  \caption{The BLER performance among different construction methods with different list sizes, where Fig. \ref{FigList}(a) and Fig. \ref{FigList}(b) show the comparison between BGR-MWD and GA algorithms and Fig. \ref{FigList}(c) and Fig. \ref{FigList}(d) provide the comparison between BGR-MWD-PW algorithm and PW sequence.}\label{FigList}
  \vspace{-0em}
\end{figure}

Fig. \ref{FigN1024K256L32} provides the BLER performance of polar codes constructed by the BGR-MWD and BGR-MWD-PW algorithms with $N = 1024$ and $L=32$. The information lengths in Fig. \ref{FigN1024K256L32}(a), Fig. \ref{FigN1024K256L32}(b) and Fig. \ref{FigN1024K256L32}(c) are $K = 256$, $K=512$ and $K=768$, respectively.
In Fig. \ref{FigN1024K256L32}, we first observe that the MWD sequence has the optimum AUB but the worst BLER performance among the construction methods under SCL decoding.
By contrast, the BGR-MWD algorithm shows worse AUB but better BLER performance than the MWD sequence.
Specifically, the BGR-MWD algorithm has about $1.3$dB, $1.2$dB and $0.6$dB performance gain compared to the MWD sequence at BLER $10^{-3}$ with $K = 256$, $K=512$ and $K=768$, respectively.
The reason is that the information set obtained by the BGR-MWD algorithm satisfies the entropy constraint, so the BGR-MWD algorithm can use less list size to approach the ML performance compared with the MWD sequence.
Thus, the entropy constraint is a reasonable criterion in order to close to the ML performance by SCL decoding with limited list size.
Then, we observe that the BLER performance of GA algorithm coincides with the corresponding AUB and has about $0.8$dB, $0.7$dB and $0.7$dB worse than that of the BGR-MWD algorithm in Fig. \ref{FigN1024K256L32}(a), Fig. \ref{FigN1024K256L32}(b) and Fig. \ref{FigN1024K256L32}(c), respectively.
This is because the construction criterion of GA algorithm is minimizing the BLER upper bound of SC decoding rather than optimizing the MWD.
In comparison, the BGR-MWD algorithm is a trade-off between the GA algorithm and the MWD sequence and tries to optimize the MWD and satisfy the entropy constraint to approach the ML performance with limited list size.
Hence, the BGR-MWD algorithm is more suitable for constructing polar codes for long code length compared with GA algorithm and MWD sequence.
Finally, though the reorder methods of BGR-MWD and BGR-MWD-PW algorithms are different,
we observe in Fig. \ref{FigN1024K256L32} that the BLER performance of the two construction methods coincides with each other, since the two methods have almost identical AUB and both satisfy the entropy constraint.
Thus, using the PW sequence to reorder the synthetic channels in the BGR-MWD-PW algorithm is almost no BLER performance loss and a potential practical construction table unrelated to the channel parameters can be designed when the reorder groups are decided.

Fig. \ref{FigList} illustrates the BLER performance of BGR-MWD and BGR-MWD-PW algorithms with different list sizes, where Fig. \ref{FigList}(a) and Fig. \ref{FigList}(b) show the performance comparison between BGR-MWD and GA algorithms and Fig. \ref{FigList}(c) and Fig. \ref{FigList}(d) provide the performance comparison between BGR-MWD-PW algorithm and PW sequence.
In Fig. \ref{FigList}(a) and Fig. \ref{FigList}(b), we observe that the GA algorithm with different list sizes shows almost identical BLER performance coinciding with the corresponding AUB in the medium to high SNR region, since GA algorithm has the optimum ${H\left({\mathcal A}\right)}$ which leads SCL decoding with small list size can approach the ML performance of polar codes.
By contrast, as $L$ increases, the BLER performance of BGR-MWD algorithm gradually approaches the corresponding AUB.
Specifically, Fig. \ref{FigList}(a) shows about $0.63$dB, $0.5$dB and $0.38$dB performance gaps between the BGR-MWD algorithm and the AUB with $L = 4, 8, 16$ at BLER $10^{-3}$, respectively, and Fig. \ref{FigList}(b) provides about $0.37$dB, $0.25$dB and $0.13$dB performance gaps between the BGR-MWD algorithm and the AUB with $L = 8, 16, 32$ at BLER $10^{-3}$, respectively.
Therefore, increasing the list size can further improve the BLER performance of polar codes constructed by BGR-MWD algorithm to approach the corresponding AUB.
From Fig. \ref{FigList}(c) and Fig. \ref{FigList}(d), we can also obtain the similar result that increasing the list size is an effective method to improve the BLER performance of BGR-MWD-PW algorithm.

In general, BGR-MWD and BGR-MWD-PW algorithms can be regarded as two good constructions and show superior performance under SCL decoding with limited list size over other traditional construction methods for long code length.



\section{Conclusion}

In this paper, the construction methods based MWD are proposed to improve the performance of polar codes under SCL decoding.
To design the construction methods, we introduce a new concept named partial MWD to evaluate the influence of each information bit on MWD.
On the basis of the partial MWD, we first propose the MWD sequence to improve the ML performance of polar codes and apply fast construction without the channel parameters.
Then, we establish a relationship between the list size and the ML performance and propose the entropy constraint. With the constraint and the MWD sequence, we design BGR-MWD and BGR-MWD-PW algorithms to construct polar codes. The simulation results show that the MWD sequence has superior performance under SCL decoding over other sequence construction
methods for short code length and the BGR-MWD and BGR-MWD-PW algorithms are suitable for constructing polar codes for long code length with limited list size.

\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,myrefs}

\end{document}


