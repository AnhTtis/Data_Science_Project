\begin{figure*}[t]
\centering 
\begin{tabular}{cc}
    \vspace{-5pt}  
    \begin{subfigure}{0.63\textwidth}
        \includegraphics[width=\textwidth]{figures/method/temporal_matching.pdf}
        \vspace{-15pt}
        \caption{}
        \label{fig:matching_learning}
    \end{subfigure}
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\textwidth]{figures/method/non_temporal_matching.pdf}
        \vspace{-15pt}
        \caption{}
        \label{fig:non_temporal_matching_learning}
    \end{subfigure}
\end{tabular}
    \vspace{-2ex}
    \caption{\textbf{Matching functions on the temporal similarity matrix $M$.} We show how each method estimates a scalar video-to-video similarity given the input pairwise similarity matrix. The functions can be classified as a) temporal or b) non-temporal whether they use the temporal position of the features or not.
    \label{fig:matching}
    \vspace{-3ex}
    }
\end{figure*}