@misc{reuters,
  title = {Chat{GPT} sets record for fastest-growing user base - analyst note},
  howpublished = {\url{https://www.reuters.com/technology/chatgpt-sets-record-fastest-growing-user-base-analyst-note-2023-02-01/}},
  note = {Accessed: 2023-02-20}
}

@misc{theguardian,
  title = {Chat{GPT} reaches 100 million users two months after launch},
  howpublished = {\url{https://www.theguardian.com/technology/2023/feb/02/chatgpt-100-million-users-open-ai-fastest-growing-app}},
  note = {Accessed: 2023-02-20}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{yang2019xlnet,
  title={Xlnet: Generalized autoregressive pretraining for language understanding},
  author={Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Russ R and Le, Quoc V},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  publisher={OpenAI}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{chowdhery2022palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={arXiv preprint arXiv:2203.02155},
  year={2022}
}

@article{wang2023can,
  title={Can chatgpt write a good boolean query for systematic review literature search?},
  author={Wang, Shuai and Scells, Harrisen and Koopman, Bevan and Zuccon, Guido},
  journal={arXiv preprint arXiv:2302.03495},
  year={2023}
}

@article{kung2023performance,
  title={Performance of ChatGPT on USMLE: Potential for AI-assisted medical education using large language models},
  author={Kung, Tiffany H and Cheatham, Morgan and Medenilla, Arielle and Sillos, Czarina and De Leon, Lorie and Elepa{\~n}o, Camille and Madriaga, Maria and Aggabao, Rimel and Diaz-Candido, Giezel and Maningo, James and others},
  journal={PLOS Digital Health},
  volume={2},
  number={2},
  pages={e0000198},
  year={2023},
  publisher={Public Library of Science}
}

@article{liebrenz2023generating,
  title={Generating scholarly content with ChatGPT: ethical challenges for medical publishing},
  author={Liebrenz, Michael and Schleifer, Roman and Buadze, Anna and Bhugra, Dinesh and Smith, Alexander},
  journal={The Lancet Digital Health},
  year={2023},
  publisher={Elsevier}
}

@article{jiao2023chatgpt,
  title={Is ChatGPT a good translator? A preliminary study},
  author={Jiao, Wenxiang and Wang, Wenxuan and Huang, Jen-tse and Wang, Xing and Tu, Zhaopeng},
  journal={arXiv preprint arXiv:2301.08745},
  year={2023}
}

@article{patel2023chatgpt,
  title={ChatGPT: the future of discharge summaries?},
  author={Patel, Sajan B and Lam, Kyle},
  journal={The Lancet Digital Health},
  year={2023},
  publisher={Elsevier}
}

@article{frieder2023mathematical,
  title={Mathematical capabilities of ChatGPT},
  author={Frieder, Simon and Pinchetti, Luca and Griffiths, Ryan-Rhys and Salvatori, Tommaso and Lukasiewicz, Thomas and Petersen, Philipp Christian and Chevalier, Alexis and Berner, Julius},
  journal={arXiv preprint arXiv:2301.13867},
  year={2023}
}

@misc{biswas2023chatgpt,
  title={ChatGPT and the future of medical writing},
  author={Biswas, Som},
  journal={Radiology},
  pages={223312},
  year={2023},
  publisher={Radiological Society of North America}
}

@article{jeblick2022chatgpt,
  title={ChatGPT Makes Medicine Easy to Swallow: An Exploratory Case Study on Simplified Radiology Reports},
  author={Jeblick, Katharina and Schachtner, Balthasar and Dexl, Jakob and Mittermeier, Andreas and St{\"u}ber, Anna Theresa and Topalis, Johanna and Weber, Tobias and Wesp, Philipp and Sabel, Bastian and Ricke, Jens and others},
  journal={arXiv preprint arXiv:2212.14882},
  year={2022}
}

@article{rao2023evaluating,
  title={Evaluating ChatGPT as an Adjunct for Radiologic Decision-Making},
  author={Rao, Arya S and Kim, John and Kamineni, Meghana and Pang, Michael and Lie, Winston and Succi, Marc},
  journal={medRxiv},
  pages={2023--02},
  year={2023},
  publisher={Cold Spring Harbor Laboratory Press}
}

@article{sarraju2023appropriateness,
  title={Appropriateness of Cardiovascular Disease Prevention Recommendations Obtained From a Popular Online Chat-Based Artificial Intelligence Model},
  author={Sarraju, Ashish and Bruemmer, Dennis and Van Iterson, Erik and Cho, Leslie and Rodriguez, Fatima and Laffin, Luke},
  journal={JAMA},
  year={2023}
}

@misc{promptperfect,
  title = {Prompt{P}erfect: elevate your prompts to perfection},
  howpublished = {\url{https://promptperfect.jina.ai/}},
  note = {Accessed: 2023-02-20}
}

@misc{gpt4,
  title = {{GPT}-4},
  howpublished = {\url{https://openai.com/research/gpt-4}},
  note = {Accessed: 2023-03-14}
}

@article{gpt4tech,
  title={{GPT}-4 technique report},
  author={Open{AI}},
  year={2023}
}