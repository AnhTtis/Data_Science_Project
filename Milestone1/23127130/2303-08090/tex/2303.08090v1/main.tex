\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{multirow}
\usepackage{array}
\usepackage{longtable}
\usepackage{pdflscape}
\usepackage{url}
\usepackage{rotating}
\usepackage{xcolor}
\usepackage{hyphenat}
%next two lines for removing overfullbox in printing bibliography
\usepackage{etoolbox}
\apptocmd{\sloppy}{\hbadness 10000\relax}{}{}

\newcommand{\pkg}[1]{{\normalfont\fontseries{b}\selectfont #1}} \let\proglang=\textsf \let\code=\texttt

\title{A global exploratory comparison of country self-citations 1996-2019}
\author{Alberto Baccini$^1$   Eugenio Petrovich$^{2,3}$}

\date{
    \small$^1${Department of Economics and Statistics, University of Siena, Italy}\\
    $^2$Department of Philosophy and Education Sciences, University of Turin, Italy\\
    $^3$Department of Philosophy, Tilburg University, the Netherlands \\ [2ex]
    %March 2023
}


\begin{document}

\maketitle

\noindent \textbf{Abstract:} Self-citations are a key topic in evaluative bibliometrics because they can artificially inflate citation-related performance indicators. Recently, self-citations defined at the largest scale, i.e., country self-citations, have started to attract the attention of researchers and policymakers. According to a recent research, in fact, the anomalous trends in the country self-citation rates of some countries, such as Italy, have been induced by the distorting effect of citation metrics-centered science policies. In the present study, we investigate the trends of country self-citations in 50 countries over the world in the period 1996-2019 using Scopus data. Results show that for most countries country self-citations have decreased over time. 12 countries (Colombia, Egypt, Indonesia, Iran, Italy, Malaysia, Pakistan, Romania, Russian Federation, Saudi Arabia, Thailand, and Ukraine), however, exhibit different behavior, with anomalous trends of self-citations. We argue that these anomalies should be attributed to the aggressive science policies adopted by these countries in recent years, which are all characterized by direct or indirect incentives for citations. Our analysis confirms that when bibliometric indicators are integrated into systems of incentives, they are capable of affecting rapidly and visibly the citation behavior of entire countries.

\medskip

\noindent \textbf{Keywords:} Self-citations, country self-citation, performance-based funding systems, research evaluation

\medskip

\noindent \textbf{Acknowledgments:} \textit{This work uses Scopus data provided by Elsevier through the ICSR Lab. We are very grateful to Lucio Barabesi, Jeroen Bass for his help in retrieving the data, and Giuseppe De Nicolao for insightful discussions in the early stage of the research. Alberto Baccini acknowledges the funding by the Italian Ministry of University, PRIN project: 2017MPXW98}
\newpage
\section{Introduction}
\label{sec:intro}
Since the early times of citation indexes, self-citations have attracted the attention of bibliometricians \cite{garfield_is_1979, garfield_new_1963}. In evaluative bibliometrics, the main concern with self-citations is that they can potentially inflate impact metrics or distort their meaning \cite{glanzel_concise_2006, macroberts_mismeasure_2018, schubert_weight_2006, szomszor_how_2020}. It has thus been debated whether they should be removed from citation indicators \cite{aksnes_macro_2003, costas_is_2010, fowler_does_2007, thijs_influence_2006}. In descriptive bibliometrics, on the other hand, self-citations have been studied from the point of view of scholarly communication. The motivations for self-citing have been classified \cite{bonzi_motivations_1991, pichappan_other_2002} and self-citations have been used to investigate how scientific authors relate with their own production \cite{hyland_self-citation_2003, white_authors_2001}. %The incidence of self-citations in different fields has been calculated as well \cite{hutson_self-citation_2006, thijs_influence_2006}.

In the most general sense, self-citation occurs when an entity (e.g., an author, journal, institution, or country) receives a citation from a publication produced by the same entity \cite{sugimoto_measuring_2018}. Even if all self-citations derive from the act of self-referencing, self-citations and self-references should be distinguished \cite{khelfaoui_measuring_2020}. For technical reasons shortly described below, the results derived from observing self-citations or self-references are different and so does their interpretation. This paper focuses on country self-citations. 
%adopts  the information gained from using one or the other changes dramatically  Self-citations are citations \textit{received} in a defined publication window by a target entity \textcolor{red}{from the same entity in a present or future citation window. For instance, the self citations received by an author in a given year  are citations lobal self citations of an author are citations recevied by a an author }

%cite{lawani_heterogeneity_1982} called them diachronous or prospective self-citations.
%\textcolor{red}{Self-references instead are citations that are \textit{given} by a target entity . \cite{lawani_heterogeneity_1982} called the former diachronous or prospective self-citations and the latter synchronous or retrospective self-citations. 
%For an author, a high rate of diachronous self-citations may indicate intellectual isolation \cite{white_authors_2001}. A high rate of synchronous self-citations, i.e., self-references, on the other hand, may show scarce attention to the work of other researchers in the field or that the author works in a little and specialized niche \cite{lawani_heterogeneity_1982}. %%% a me questa cosa non convince per nulla. data una finestra di pubblicazioni la somma delle self-reference=somma delle self-citations. I conteggi cambiano se modifichi la finestra citazionale. Ciò che cambia nel calcolo del tasso di self-reference o self-citations è il denominatore.


%In the case of multi-authored papers, the author self-citations can be computed by considering also the citations to her/his papers generated by her/his co-authors. For instance, Scopus database permits to compute an author's citations by excluding self-citations of this author only, or by excluding self-citations of all the co-authors

Depending on the entity considered, self-citation can be classified into different types \cite{szomszor_how_2020}. The most basic is the \textit{author self-citation}, which occurs when the publications written by an author are cited by in the following publications by the same author. For multi-authored publications, author self-citation can be defined narrowly or broadly, i.e., including or not citations generated by co-authors. Author self-citations intended in the extensive sense are sometimes called co-author self-citations \cite{ioannidis_generalized_2015} or all-author to all-author self-citations \cite{szomszor_how_2020}. \textit{Journal self-citation} occurs when an article published in a certain journal is cited by a subsequent publication in the same journal \cite{leydesdorff_caveats_2008}; this form of self-citation has been mainly studied to understand how it can influence or even manipulate the journal Impact Factor \cite{andrade_journals_2009, hartley_cite_2012, yu_self-cited_2007}. \textit{Institution self-citation} happens when the authors of the cited and of the citing publications share the same affiliation \cite{gul_prevalence_2017, hellsten_self-citations_2007}. By extending rather inappropriately the notion of self-citation, \textit{language self-citation} refers to citations occurring among publications in the same language \cite{egghe_own-language_1999}, and \textit{field self-citation} for citations between publications belonging to the same academic field \cite{tagliacozzo_self-citations_1977}.

In the context of the study of the scientific performance of countries, the self-citations defined at the highest level of aggregation, i.e., \textit{country self-citations}, have recently started to attract some attention, both from researchers \cite{baccini_citation_2019, bakare_country_2017, bardeesi_impact_2021, jaffe_countries_2011, minasny_individual_2010, shehatta_impact_2019} and in science policy reports \cite{national_science_board_science_2018}. A country self-citation, also called sometimes domestic citation (e.g., \cite{lancho_barrantes_citation_2012}), occurs when the publications produced by the researchers of a country are subsequently cited by researchers of the same country. As for author self-citations, also country self-citations should be distinguished from country \textit{self-references}. The former shows how much of the citation impact of a country is generated from within the country itself, whereas the latter shows how much the publications of a country refer to scientific knowledge produced within that country. Notably, country self-references depend only on the behavior of the researchers from the country. By contrast, country self-citations are determined also by the behavior of other citing countries \cite{khelfaoui_measuring_2020}.

In this study, the trends of country self-citations in 50 countries over the world are investigated in order to reveal groups of countries characterized by similar self-citation behavior in time. The main interest consists in individuating countries that \textit{deviate} from standard trends because these anomalies may signal perturbations in the scientific development possibly induced by science policies. Italy is a case in point in this sense, as previous research has revealed an anomalous rise in the country’s self-citations after the introduction of pervasive bibliometric evaluation \cite{abramo_effects_2021, baccini_citation_2019, peroni_practice_2020, scarpa_impact_2018, seeber_self-citations_2019, vercelli_self-citation_2022}. 
%(for a different interpretation see \cite{dantuono_citation_2019}).

The paper is structured as follows. In the next section, the bibliometric indicators based on country self-citations are reviewed. Then, the indicators, data, and analytical methods used in this study (time-series analysis) are presented. The main findings are shown in the Results section, whereas, in the Discussion section, we focus on countries characterized by anomalous self-citation trends. Based on the detailed reconstruction of the research policies adopted by these countries, it is argued that the anomalous trends are most likely explained by the adaptive response of scientists to the systems of incentives established by the policies themselves. Accordingly, Conclusions suggest to manage bibliometric indicators in research policy contexts with extreme caution.


\section{Review of the main indicators based on country self-citations}
\label{sec:review}

As anticipated, self-citations and self-references are defined, computed, and interpreted in different ways. To highlight these differences \cite{lawani_heterogeneity_1982}, for example, called the former diachronous or prospective self-citations and the latter synchronous or retrospective self-citations.


Self-citations can be defined as citations from citing sources to cited items that are both produced by (at least) the same entity $E$, i.e. a same author, journal, institution, or country. Different ways of defining these entities entail the use of different algorithms, which will be discussed in the next paragraph.

The computation of self-citations requires the definition of: (i) a publication window delimiting the cited items as the ones published in it. For the sake of simplicity, in what follows, the publication window is set at one year, hence the cited items considered are only the ones published in the year $y$; and (ii) a citation window delimiting the citing sources as the ones published in it. 
Let $y$ be the reference year for calculation and also the publication window; $T$ is the length of the observation period, expressed in years. Self-citations of an entity $E$ in the year $y$ can be defined as:
\begin{equation}
S_{E,y} = \sum_{i=k} ^T s_E(y,y-1+i), 
\end{equation}
\noindent where $s_E(y,y-1+i)$ is the number of  self-citations received by the set of cited items published by the entity $E$ in the publication window $y$, from citing sources produced by the same entity $E$ in the citation window ($y-1+i$). 
The citation window includes the years $(y-1+i)$ for $i=k$, \dots, $T$, where $k\in \{1,\dots, T\}$ is chosen by the user for setting the desired time interval for observing citations. If $k>1$ citation window and publication window are disjoint; for $k=1$ and $T>1$ they are partially overlapped, and for $k=T=1$ they are completely overlapped. In the first case, citing sources are published in years following the publication windows; in the second case, the citation window includes the publication window and the following years; in the third one, citation window and publication window coincide.   
Analogously, the total citations received by the set of cited items published by the entity $E$ in the year $y$ can be defined as: 
 \begin{equation}
C_{E,y}= \sum_{i=k} ^T c_E(y,y-1+i)
\end{equation}
\noindent where $c_E(y,y-1+i)$ is the number of citations received by the set of cited items published by $E$ in the publication window $y$, from citing sources published in the citation window $y-1+i$.

The basic indicator is the \textit{self-citation rate} ($SR_E,y$) for entity $E$ in the year $y$, defined as the ratio between the self-citations and the total number of citations received by $E$ \cite{baccini_citation_2019, bardeesi_impact_2021, frame_national_1988, moed_citation_2005}:
\begin{equation}
SR_{E,y} = \frac{S_{E,y}}{C_{E,y}} =\frac{\sum_{i=k} ^T s_E(y,y-1+i)}{\sum_{i=k} ^T c_E(y,y-1+i)},
\end{equation}
\noindent where $SR_{E,y}\in[0,1]$.
$C_{E,y}$ is usually interpreted as a proxy of the academic impact of the entity $E$. $S_{E,y}$ is an indicator of academic impact generated by self-citations of $E$. Hence, a self-citation rate can be interpreted as the proportion of the academic impact of $E$ due to its self-citation activity. It should be noted, that the denominator of the ratio is concretely produced by the citing choices of the whole scholarly community, and the ratio relates the self-citing choices of $E$ with respect to the citing choices of the whole scholarly community.

Also self-references indicate citation from citing sources to cited items both produced by (at least) the same entity, but the set of citing sources and cited items are defined in different ways with respect to self-citations. Moreover, the computation of self-reference requires only a publication window for the set of citing sources. If the publication window is set also at one year, the cited sources are the publications produced by $E$ in the year $y$, and cited items are  (all or part of) the items listed in the bibliographies of the citing sources. $SB_{E,y}$, i.e. the number of self-references in the year $y$, is computed by summing up the citations from citing sources published in the year $y$ by $E$ to cited items previously produced by $E$.
Analogously, $R_{E,y}$ indicates the total number of citations received by cited items from citing sources produced by $E$ in the year $y$. The self-reference ratio $SBR_{E,y}$ for the year $y$ is thus defined as: 
 \begin{equation}
SBR_{E,y}= \frac{SB_{E,y}} {R_{E,y}}. 
\end{equation}
When references are observed, the focus of the analysis is on the use of previous knowledge by the entity $E$, and not on the academic impact of the scientific production of $E$. It should be noted that the denominator of the ratio is, in this case, produced also by the citing choices of $E$. $SBR_E$ should be interpreted as an indicator of how much $E$ uses in its current work the knowledge that it had previously produced. For instance, for an author, a relatively high value of $SBR_{E,y}$ may indicate that her/his work is largely based on her/his previous work. This in turn may be due to scarce attention to the work of other researchers in the field or to the fact that the author works in a little and specialized niche \cite{lawani_heterogeneity_1982}. A relatively high value of $SR_{E,y}$, instead, indicates that a relatively high share of her/his academic impact is due to her/his self-citation activity.

The basic indicator in the literature on country self-citations is the \textit{country self-citation rate}. Hereafter $N$ denotes the entity ``country''; the self-citation rate of country $N$ in the year $y$ is the ratio between its country self-citations and the total number of citations received by that country \cite{baccini_citation_2019, bardeesi_impact_2021, frame_national_1988, moed_citation_2005}:

\begin{equation}
SR_{N,y}= \frac{S_{N,y}}{C_{N,y}} 
\end{equation}

\noindent where $S_{N,y}$ is the raw number of self-citations of country $N$ in the year $y$ and $C_{N,y}$ is the total number of citations received by $N$ in the year $y$. 

Computing the total of country self-citations for a country $S_{N,y}$ is, however, less obvious than it may seem. As detailed in Section \ref{sec:csc_types}, country self-citations can be in fact computed either narrowly or broadly, depending on how citations to international publications are considered. In \cite{baccini_citation_2019}, a variant of the self-citation rate indicator called ``inwardness'' is developed, characterized by a citation window variable in lenght.  A \textit{broad} definition of country self-citation is adopted, according to which a citation is considered a country self-citation when the intersection between the set of the countries of affiliation of the author(s) of the cited publication,  and the set of the countries of affiliation of the author(s) of the citing publication, is not empty. This broad definition of country self-citation has the desirable property of ascribing to the world an inwardness value of inwardness $1$, which makes therefore the inwardness an indicator normalized for the size of the country in terms of publications (see \cite{baccini_citation_2019} for details). This property, however, does not hold for the $SR_{N,y}$ when the country self-citations are computed narrowly (see Sec. \ref{sec:csc_types}).

%\textcolor{red}{This indicator is only apparently simple. But the notion of country self-citation is very slippery and the algorithms used for counting country self-citations define different measures, with different properties. If a publication-based perspective is adopted, self-citations for a given country can be computed by considering citations to articles authored by at least one author affiliated to that country, from other articles authored by at least one author affiliated to that country. This is a restrictive definition. An alternative definition enlarges the notion of country self-citation by considering also the citations received by an international article (i.e., an article with authors coming from different countries) from other articles authored by scholars affiliated to all the countries that contributed to the considered international article.} 
%\textcolor{red}{This second definition of self-citation is adopted by SCIVAL and it is the base for calculating the indicator called Inwardness ($I$) by \cite{baccini_citation_2019}. 
%Inwardness is an indicator normalized for the size of the country in terms of publications. This property does not hold in general for self-citation rates defined with different algorithms, since it depends by the fact that Inwardness of the world is equal to 1 \cite{baccini_citation_2019}.}

Inwardness is interpreted as a measure of the self-referentiality of a country: a higher level of inwardness suggests that the scientific publications produced by a country attract mainly the interest of the national community, whereas a lower level of inwardness suggests that the scientific production is cited mainly abroad.  
In the same sense, \cite{ladle_assessing_2012} related country self-citations to the degree of scientific insularity of nations. \cite{ladle_assessing_2012} also suggested several factors that may explain why developing countries show higher self-citation rates, among which a focus on applied scientific issues that respond to the perceived needs of national development, poor referencing practice, insufficient training of graduate students, preference for literature in national language than in English, and the proliferation of low-quality national journals. As \cite{baccini_citation_2019} have shown, however, also developed countries may show anomalous raises in self-citation rates induced by research evaluation policies that reward raw citation metrics.

A variant of the self-citation rate is the citation domesticity indicator \cite{glanzel_domesticity_2005}, in which citations coming from international publications are evenly distributed among the citing countries. Apart from \cite{glanzel_domesticity_2005}, however, fractional counting of country self-citations has never been considered in the following literature. This may be explained by the fact that most more recent studies collect data on country self-citations from Elsevier’s SCImago or SciVal platforms, which do not apply fractional counting \cite{elsevier_research_2018}. %A fractional approach to author self-citations has been proposed by \cite{schubert_weight_2006}. 

The complement of the self-citation rate is the \textit{foreign citation rate} $FR_{N,y}$, also called ``international scholarly impact of scientific research'' by \cite{hassan_measuring_2013}:

\begin{equation}
    FR_{N,y} = \frac{C_{N,y}-S_{N,y}}{C_{N,y}} = 1 - SR_{N,y}
\end{equation}

The country self-citation rate results to be positively correlated with the publication output of a country. In particular, \cite{minasny_individual_2010} proposed a model where the country self-citation rate increases with the logarithm of the output:

\begin{equation}
    SR_{N,y} \propto \log P_{N,y}    
\end{equation}

\noindent where $P_{N,y}$ is the number of publications of country $N$ in the year $y$. This occurs because bigger countries have more domestic papers to cite and, hence, are more likely to attract citations from their own researchers than smaller countries \cite{bookstein_own_1999, frame_national_1988, moed_citation_2005}. By contrast, the average number of citations per document of a country is negatively correlated with self-citation rates \cite{jaffe_countries_2011}. Self-citation rates have increased over time: according to \cite{jaffe_countries_2011} estimates, the average self-citation rate of 62 countries raised of 28.9\% from 1996 to 2009. \cite{baccini_citation_2019} noted as well that the Inwardness of G10 countries increased during the period 2000-2016 with a mean increase of 5.2 percentage points.

To correct from the size-dependency of self-citation rates, \cite{frame_national_1988} proposed to compare the self-citation rates with the world-share of publication of a country, based on the idea that if the publications from a country are cited as expected, then its share of country self-citations is proportional to its share of world publications. More recently, this indicator has been called ``over-citation ratio'' ($OCR_{N,y}$) by \cite{bakare_country_2017} and is defined as:

\begin{equation}
    OCR_{N,y} = \frac{\frac{S_{N,y}}{C_{N,y}}}{\frac{P_{N,y}}{P_{w,y}}} = \frac{SR_{N,y}}{\alpha_{N,y}}
\end{equation}
 
\noindent where $P_{w,y}$ is the total number of publications in the world and $\alpha_{N,y}$ the proportion of publications of country $N$ in the world. An over-citation ratio higher than 1 means that the country receives more citations from its own publications than expected based on its relative weight in the world scientific production. %\footnote The $OCR$ is equivalent to the \textit{relative own-language preference} ($ROLP$) indicator proposed by \cite{bookstein_own_1999}, the only difference between the two is that the latter is calculated with language self-citations. \cite{danell_geographical_2013} used an indicator identical to the $OCR$ calling it \textit{normalized rate of country self-citation}.} 
At the field level, \cite{bakare_country_2017} found that, as expected, over-citation ratio is higher for scientific fields of more national interest. %ma gli usa sono un bel controesempio

However, the over-citation ratio results to be size-dependent, as it is highly influenced by the denominator in the formula, i.e., the fraction of papers published by a country. For countries with high weight in the world publication output, such as the USA, the $OCR_{N,y}$ will be always smaller than for small countries. For instance, for a country publishing one-third of the papers in the world ($\alpha_{N,y} = 33\%$), the $OCR_{N,y}$ can never exceed a value of $1/0.33 \approx 3$, whereas a small country that published $\alpha_{N,y} = 3.3\%$ of world papers, the maximum value of the $OCR_{N,y}$ raises to 30 \cite{moed_citation_2005, egghe_own-language_1999}. In fact, \cite{bakare_country_2017} found that there is a  negative power correlation between $OCR_{N,y}$ and $\alpha_{N,y}$:

\begin{equation}
    OCR_{N,y} \propto \frac{1}{\alpha_{N,y}^J}.
\end{equation}

A further indicator, based on probability ratio, has thus been proposed, first in the study of language self-citations by \cite{bookstein_own_1999} and then adapted to country self-citations by \cite{moed_citation_2005}. This indicator, called ``odds-ratio`` ($O_{N,y}$), relates two ratios: the numerator is the ratio of country self-citations to foreign citations, and the denominator is the ratio of domestic publication proportion to foreign publication proportion: 

\begin{equation}
    O_{N,y} = \frac{SR_{N,y} / (1 - SR_{N,y})}{\alpha_{N,y} / (1 - \alpha_{N,y})}.
\end{equation}

The odds-ratio $O_{N,y}$ measures to what extent the country relative preference to cite its own publications is greater or smaller than the existing ratio of its domestic publications to publications from other countries. Note that for small values of $SR$ and $\alpha$, the odds-ratio approaches the over-citation ratio. 
%\footnote{Another option to adjust for the different output of countries is the Insularity indicator ($Ins$) proposed by \cite{ladle_assessing_2012}, which is defined as the difference between self-citation rates and the country share of world publications:
%\begin{equation}
%Ins_N= SR_N - \alpha_N    
%\end{equation}

%\textcolor{red}{la parte per Lucio è incorreggibile. Il problema è l'uso del termine "estimate" per cui lui dice che dopo non si capisce più nulla. Trattandosi di stima si dovrebbe distinguere parametri da stimare e parametri stimati. Lui dice che sarebbe opportuno raccontare a parole eliminando le formule}
%Let $O_o$ be the average probability that authors from a certain country cite a paper from their own countries, and $O_f$ be the average probability that they cite papers from other countries. The indicator of odds-ratio $O$ is defined as the ratio between these two probabilities:
%\begin{equation}
%    O= \frac{O_o}{O_f}
%\end{equation}
 
%To estimate $O_o$ and $O_f$, \cite{bookstein_own_1999} assume that the measured self-citation rate of a country $SR_N$ is equal to the ratio between the probability that an author cites a paper from its own country, and the total probability of citing either a domestic paper or a foreign one. Remembering that $\alpha_N$ is the share of publications of country $N$ in the world and that $1 - \alpha_N$ is accordingly the proportion of publications from other countries, the number of domestic papers can be expressed as $P_N= \alpha_N P_w$  and, therefore, the $SR_N$ as:
%\begin{equation}
%    SR_N=  \frac{\alpha_N P_w O_o}{\alpha_N P_w O_o + (1 - \alpha_N) P_w O_f } 
%\end{equation}

%By dividing for $O_o \alpha_c$, it yields:

%\begin{equation}
%    SR_N = \frac{1}{1 + \frac{O_f (1 - \alpha_N)}{\alpha_N O_o}}
%\end{equation}

%Since $SR_N$ and $\alpha_N$  are known from empirical measurement, the odds-ratio $O_N$ for country $N$ can be calculated as follow:


%This indicator relates two ratios: the ratio of country self-citations to foreign citations (the numerator) and the ratio of domestic publication share to foreign publication share (the denominator). Hence, it tells us to what extent a country relative preference to cite its own publications is greater (or smaller) than the existing ratio of its domestic publications to publications from other countries. Note that for small values of $SR$ and $\alpha$, the odds-ratio approaches the over-citation ratio. 

The odds-ratio has three drawbacks as well, however \cite{egghe_own-language_1999}. First, if a country cites only its own publication, the measure is infinite. Second, it is oversensitive to small variations in the $SR_{N,y}$. Third, it is not normalized between 0 and 1. To fix these issues, \cite{egghe_own-language_1999} proposed the following indicator of relative self-citation rate:

\begin{equation}
    E_{N,y} = SR_{N,y} \ln(\frac{1}{\alpha_{N,y}}).
\end{equation}

According to their interpretation, this formula considers the publication proportion $\alpha_{N,y}$ as a stimulus to the publication-citation system and the relative self-citation rate $E_{N,y}$ as the subjective reaction of the system, which depends logarithmically on the intensity of the stimulus, as in Weber-Fechner equation. The function also expresses the law of diminishing returns: the larger $\alpha_{N,y}$, the less important the changes in the relative self-citation rate. The relative self-citation rate has the advantages of being normalized and size-independent. Besides its mathematical merits, however, its meaning is less transparent compared to all the previous alternatives.

\section{Methods and data}
\label{sec:methods}

As anticipated, this work handles time series analysis of country self-citations: time-series clustering techniques are used for detecting countries whose self-citation behavior is similar \cite{aghabozorgi_time-series_2015, warren_liao_clustering_2005}. 
To build the time-series, a preliminary distinction between extensive (or broad) and restrictive (or narrow) country self-citations is introduced.  The two counts are conceptually different and generate different estimates of country self-citations. Hence, two self-citation indicators are defined.  %and their time series are built whose trend over time will constitute the time-series. Among the indicators offered in the literature (see Sec. \ref{sec:review} above), the self-citation ratio results to be the most suitable for our analysis, as we explain below. Once these preliminary definitions are set up, we can thus retrieve t

The relevant data from a citation database for the countries of interest are next retrieved and the time-series generated. The distance between the time-series is then calculated using a suitable distance measure and the structure of the distance matrix thus obtained is explored using multi-dimensional scaling (MDS). In the resulting MDS maps, countries characterized by similar trends will be placed close to each other, whereas countries with different trends far away \cite{borg_modern_2010}.

Fig. \ref{fig:methodology} sums up the phases of the present study. In the next paragraphs, the methodological and technical choices taken in each step are presented in detail and justified.

\begin{figure}
    \centering
    \includegraphics[scale = 0.7]{Methods_diagram_2.png}
    \caption{Phases of the analysis.}
    \label{fig:methodology}
\end{figure}

\subsection{Country self-citations of Type I and II}
\label{sec:csc_types}
As said above, country self-citations can be computed in different ways depending on how self-citations to international publications, i.e. publications with authors from different countries, are considered. Analogously to author self-citations, the count of country self-citations for international publications can be done by adopting a \textit{publication-based} or a \textit{author-based} perspective \cite{abramo_effects_2021}.  

%are intended \textit{extensively}, all citations coming from co-authors of the target publication are counted in (hence the name \textit{co-author self-citations} used in \cite{ioannidis_generalized_2015}). By contrast, when author self-citations are intended \textit{restrictively}, only citations from the focal author are considered \cite{fowler_does_2007, sugimoto_measuring_2018}. \cite{abramo_effects_2021} call the two approaches \textit{publication-based} and \textit{author-based}, respectively. Scopus, differently from Web of Science, allows one to calculate both kinds of author self-citations \cite{li_same_2020}}

%Similarly to author self-citations, country self-citations can be computed in many ways. In the case of author self-citations, the difference depends on how self-citations to multi-authored publications are considered. When author self-citations are intended \textit{extensively}, all citations coming from co-authors of the target publication are counted in (hence the name \textit{co-author self-citations} used in \cite{ioannidis_generalized_2015}). By contrast, when author self-citations are intended \textit{restrictively}, only citations from the focal author are considered \cite{fowler_does_2007, sugimoto_measuring_2018}. \cite{abramo_effects_2021} call the two approaches \textit{publication-based} and \textit{author-based}, respectively. Scopus, differently from Web of Science, allows one to calculate both kinds of author self-citations \cite{li_same_2020}.

The extensive publication-based perspective, adopted in the Inwardness indicator and implemented in the SciVal database, considers as country self-citations \textit{all} citations coming from the collaborating countries. In the following, these extensively-intended country self-citations are referred to as country self-citation of Type I ({$SR^I$}), by omitting for simplicity the indexes of the publication window $y$ and of the country $N$. The second way of counting country self-citations is author-based and more restrictive. Country self-citations of Type II ($SR^{II}$) are computed by considering only national \textit{author} self-citations: a publication produced by (at least) an author of a given country receives a country self-citation of Type II if the citing publication is authored by one of the authors of the cited one, and this author is affiliated with the considered country. 

%In the case of country self-citations, the same reasoning applies to international publications, i.e., publications produced by different countries: according to the extensive interpretation, \textit{all} citations coming from the collaborating countries are counted in, whereas, according to the restrictive interpretation, only citations from the \textit{focal country} are considered. In the following, we will call \textit{country self-citations Type I} those computed following the extensive approach and \textit{country self-citations Type II} those computed following the restrictive one. In the Appendix, formal definitions of the two types are provided.

%Based on the previous definitions, the the difference delta between the country self-citations of Type I and Type II of a country should be attributed to the publications the country produces with other countries, i.e., to its international publications. A wider delta means that these international collaborations are widely cited not only by the focal country but also by the collaborating countries, increasing Type I but not Type II self-citations. A shorter delta, by contrast, means that the country has few international collaborations and/or that they do not attract citations from the collaborating countries. The delta between Type I and Type II is therefore related to the international citation impact of a country. A wider delta means that these international collaborations are widely cited not only by the focal country but also by the collaborating countries, increasing Type I but not Type II self-citations. A shorter delta, by contrast, means that the country has few international collaborations and/or that they do not attract citations from the collaborating countries. The delta between Type I and Type II is therefore related to the international citation impact of a country.\footnote{The delta however is a very rough indicator of international impact because it considers only country self-citations and no “foreign” citations.

\begin{figure}
    \centering
    \includegraphics[scale = 0.5]{Cit_network_example2.png}
    \caption{Toy citation network. Nodes represent publications and arrows citation links. The authors of each publication, represented by capital letters, and their affiliation country, represented by acronyms, are shown inside each publication node.}
    \label{fig:network_example}
\end{figure}

The example in Fig. \ref{fig:network_example} clarifies the computation of the two types. The Figure shows a citation network comprising publications labeled as $1,2,\dots,8$, of which 3 are cited items and 5 are citing sources, and 8 citations indicated by the arrows linking the pairs of cited and the citing publications: $(1,4),(1,5), \dots,(3,8)$. The publications are authored by 5 authors labeled $A,B,C,D,E$ from 3 countries: Italy (IT), Netherlands (NL) and Canada (CA). Inside each node, the authors of the relative publication and their countries of affiliation are reported by letters and acronyms. Three statistics for the two cited countries (Italy and Netherlands) are then calculated (Table \ref{tab:self_cit_ex}): the total number of country citations, the total number of country self-citations Type I, and the total number of country self-citations Type II. For country citations, it is sufficient to count the citations landing on the publications produced by each country: the 3 Italian publications get 8 citations and the 1 Dutch publication 5 citations. For country self-citations Type I, we must compare for each citation the set of countries of the citing publications with that of the cited publications: when the intersection is not empty, the citation counts as a country self-citation Type I. Thus, Italy collects 7 country self-citations Type I, the Netherlands 4. Note, however, that the Dutch-Italian publication 1 receives only 1 citation from a publication with a Dutch author (publication $5$), whereas the other three citing publications $6$, $7$, and $8$ are in fact from Italian authors. This happens because country self-citations Type I of international publications include the citations coming from \textit{any} of the collaborating country. This means, however, that international publications tend to inflate the country self-citations (see \cite{baccini_citation_2019}, sec. 3). 

Country self-citations of Type II allow us precisely to correct this distortion: they include only those citations coming from the focal country. Then, if the focal country is the Netherlands, only the citation-link $(1,5)$ will count as a country self-citation Type II for the Netherlands because it links two publications sharing the same Dutch author $B$. Citations $(1,6)$ and $(1,8)$, by contrast, will not count because they are generated by the Italian co-author of $B$. Symmetrically, citation $(1,5)$ will not count for Italy, whereas $(1,6)$ and $(1,8)$ will. Table \ref{tab:self_cit_ex} shows analytically in which relationship each citation-link stands with the two countries and reports the three statistics for each country. Note that no fractional counting was applied: citations from multi-author or international publications or landing on multi-author or international publications are not divided among the cited or citing countries.


\begin{table}
    \centering
\caption{Classification of citations in Fig. \ref{fig:network_example} based on the two definitions of country self-citation. No fractional counting is applied.}    
\begin{tabular}{c| ccc | ccc}
    \hline
     & \multicolumn{3}{c}{\centering{Italy: }}    
     & \multicolumn{3}{|c}{\centering{Netherlands:}}\\
     & \multicolumn{3}{c}{\centering{3 cited publications}}    
     & \multicolumn{3}{|c}{\centering{1 cited publication}}\\
     & \multicolumn{3}{c}{\centering{4 citing publications}}    
     & \multicolumn{3}{|c}{\centering{1 citing publication}}\\
    
     \hline
        Link & Citation & Self-cit & Self-cit & Citation & Self-cit & Self-cit \\
         &  & Type I & Type II &  & Type I & Type II \\
        
        \hline
1-4 & $\bullet$ &  &  & $\bullet$ &  & \\
1-5 & $\bullet$ & $\bullet$ &  & $\bullet$ & $\bullet$ & $\bullet$ \\
1-6 & $\bullet$ & $\bullet$ & $\bullet$ & $\bullet$ & $\bullet$ & \\
1-7 & $\bullet$ & $\bullet$ &  & $\bullet$ & $\bullet$ & \\
1-8 & $\bullet$ & $\bullet$ & $\bullet$ & $\bullet$ & $\bullet$ & \\
2-6 & $\bullet$ & $\bullet$ & $\bullet$ &  &  & \\
2-8 & $\bullet$ & $\bullet$ & $\bullet$ &  &  & \\
3-8 & $\bullet$ & $\bullet$ & $\bullet$ &  &  & \\
\hline
Tot & 8 & 7 & 5 & 5 & 4 & 1 \\

\hline
    \end{tabular}
        \label{tab:self_cit_ex}
\end{table}


Based on the previous definitions, the difference between the country self-citations of Type I and Type II of a country should be attributed mainly to the publications the country produces with other countries, i.e., to its international publications. A wider difference means that these international collaborations are widely cited not only by the focal country but also by the collaborating countries, increasing Type I but not Type II self-citations. A shorter difference, by contrast, means that the country has few international collaborations and/or that they do not attract citations from the collaborating countries. The difference between Type I and Type II is therefore related to the international citation impact of a country.
%\footnote{The difference however is a very rough indicator of international impact because it considers only country self-citations and no “foreign” citations. \textcolor{red}{Non capisco la nota. E' necessaria?}}

Part of the difference between the country self-citations of Type I and Type II of a country can be attributed also to citations generated by country publications that are not also author self-citations. In particular, the country self-citations of Type II do not capture citation exchanges between groups of national authors who cite each other but do not collaborate directly on writing papers. %(intra-country citation circulation). 

\subsection{Indicator design}
\label{sec:ind_design}

Section \ref{sec:review} above presented several indicators based on country self-citations. However, only the self-citation rate $SR$ is a pure citation indicator. The others integrate in different ways publication counts to correct for the size-dependency of the $SR$. 

In static analyses of country self-citations, indicators encapsulating both publications and country self-citations are useful, but they become problematic when the temporal dimension is considered. In fact, the trend of the publications-plus-self-citations indicators results to be affected both by the publication trend and the self-citation trend. The indicators, however, cannot say which of them is the driver. Consider, for instance, the \textit{over-citation ratio}: an increasing over-citation ratio over time may be caused both by a raise in the self-citation rate with the share of country publications remaining stable or by a decrease in the share of country publications with the self-citation rate remaining stable. The indicator as such does not say which of the two dynamics has taken place. Moreover, the share of country publications depends on the publication activities of other countries as well: a country with increasing scientific productivity, such as China, makes automatically decrease the publication shares of the other countries, even if their productivity has remained stable. Therefore, too many dynamics affect the trends of the over-citation ratio. An analogous reasoning applies to the other mixed indicators. 

Since the focus of this paper is on country self-citation dynamics, the most suitable indicator is the \textit{self-citation ratio} only. Specifically, two variants of the indicator will be computed: one based on country self-citations Type I (\textit{extensive} self-citation ratio, $SR^I$) and one based on country self-citations Type II (\textit{restrictive} self-citation ratio, $SR^{II}$). Country self-citations of Type I are affected by citations coming from other countries and they allow capturing the effect of \textit{citation clubs} at the country level, i.e., strategic exchanges of citations between researchers in the same country that are not co-authors \cite{baccini_citation_2019}. The $SR^I$, like the Inwardness, is a size-independent measure of country self-citation, since it is normalized for the size of country publications; $SR^{II}$ is instead not normalized.

The last step in the design of the indicator is the definition of an appropriate \textit{citation window}. A citation window is required to correct for the fact that older publications have more time to accumulate citations. In evaluative bibliometrics, longer citation windows are sometimes recommended to capture the delayed impact of publications \cite{glanzel_measuring_2019}. For our study, however, a long citation window has two shortcomings. The first one is that the  larger the citation window, the more observations are lost in the time series since, for the more recent years, the citation window is not complete. 

%\textcolor{red}{ho eliminato l'esempio perché non è corretto. Si persono osservazioni a seconda della lunghezza della serie e dell'anno di partenza. Nel nostro caso si perdono sempre $i-1$ osservazioni, dove $i$ è la lunghezza. Ma questo non si può vedere se prima non si scrive la formula}
%Indeed, a citation window of $i$ years reduces the number of computable values of exactly $i$ years, resulting in a shorter time-series. For instance, if the yearly country citation and self-citation counts are available for the period 2000-2020, a 5-years citation window permits to compute the self-citation ratio only for the years 2000-2016, because for the years 2017-2020 the citation window is incomplete. If an anomaly occurs in the last years of the dataset, it cannot be detected. 

The second one is a smoothing effect on perturbations. Imagine an anomalous peak in country self-citations due to a nationwide policy change, which determines an amount of 80 country self-citations Type II at year $y_0$. Imagine that the policy is afterward dismissed so that the country self-citations return to “normal” values of 40 in the following years $y_1$ and $y_2$. Lastly, stipulate that the country total citations have remained stable at 100 for all three years. Now, if we use a 1-year citation window, i.e., we count only the citations coming from publications that appeared in the same year of the cited publications, the $SR^{II}$ for the three years will result to be, respectively, 0.8, 0.4, and 0.4. With this citation window, the peak at year $y_o$ is clearly visible. With a 2-year citation window, which sums together the self-citations of the cited years and those of the next year, by contrast, the values will be 0.6 and 0.4 (note the value for cited year $y_2$ can no longer be calculated). Finally, with a 3-year citation window, the $SR^{II}$ at year $y_0$ will result to be 0.53 (no further values can be computed). The aggregation of the anomalous year with the normal ones has reduced the visibility of the anomaly. With a sufficiently long citation window, the anomaly might even disappear, being absorbed by the average trend.

The yearly Type I or Type II self-citation ratios for country $N$ in the year $y$ are computed by setting a 2-year citation window as follows: 
\begin{equation}
SR_N = \frac{S_{N,y}}{C_{N,y}} =\frac{\sum_{i=1} ^2 s_{N}(y,y-1+i)}{\sum_{i=1} ^2 c_{N}(y,y-1+i)}.
\end{equation}

Therefore, for a country $N$, the number of citations and self-citations Type I/Type II collected in a given year $y$ are computed by considering citations and self-citations Type I/Type II received in the year $y$ by the cited items published in the year $y$ from the citing sources published in the years $y$ and $y+1$.
This choice permits reducing at a minimum of one year the loss of observations in each time-series; moreover, it permits limiting the smoothing effect and highlighting anomalies in trends. 
To check for the effect of the citation window, i.e., to check whether the final results were affected by the choice of the citation window, all the analyses were repeated by using also 1-year and 5-year citation windows, by mimicking the usual citation windows of journal impact factors \cite{todeschini_handbook_2016}. These results, which are qualitatively similar to those reported in the paper, can be found in the Supplementary Materials.
 
 %Therefore, in the calculation of the self-citation ratio, the number of country self-citations Type I/Type II collected by a country in a given year $y$ is computed as the sum of the country self-citations Type I/Type II received in that year by the publications appeared in that and the following  year (i.e., $S_{c,y}+S_{c,y+1}$), whereas the number of country citations (the denominator of the ratio) is computed as the sum of the country citations collected by the country publications over the same years (i.e., $C_{c,y}+C_{c,y+1}$):
%\begin{equation}
%    SR_{c,y}^I = \frac{\sum_{i=1}^2 S_c^I (y,y+i)}{\sum_{i=1}^2C_c (y,y+i)}
%\end{equation}

%\begin{equation}
%    SR_{c,y}^{II} = \frac{\sum_{i=1}^2 S_c^{II} (y,y+i)}{\sum_{i=1}^2C_c (y,y+i)}
%\end{equation}

%In practice, this amounts to computing the $SR$ using a moving 2-year forward-looking citation window.

\subsection{Data}
\label{sec:data}

Scopus data were used for the computation of the indicators and data were provided by Elsevier through its ICSR Lab. The identification of author self-citations used in the calculation of Type II country self-citations relies on the Scopus author profiling procedure described in \cite{baas_scopus_2020}. 

Countries with at least 100,000 publications indexed in the Scopus databases in the period 1996-2019 were considered ($n=50$). The indicators were computed for each country on a yearly basis from 1996 to 2019 using, as said above, a 2-year citation window. Publications from all Scopus fields were aggregated, i.e., for each country, the entire scientific output was considered, with no distinction of the research area. Thus, for each indicator, 50 time-series (1 per country) with 24 observations each (1 per year) were computed. In the Supplementary Materials, the trends of the \textit{over-citation ratio}, \textit{odds-ratio}, and \textit{relative self-citation rate} are available as well. All were calculated using both Types of country self-citations.

Table \ref{tab:desc_stats} provides the descriptive statistics of the countries in the dataset.




\subsection{Comparing time-series}

In the literature on time-series analysis, numerous measures for comparing time-series have been developed (reviews can be found in \cite{montero_tsclust_2014, aghabozorgi_time-series_2015, warren_liao_clustering_2005}). The various measures encapsulate different senses in which two time-series may be similar or dissimilar. Choosing the suitable measure depends both on the nature of the data and the purposes of the analysis.

In the present setting, the measure should satisfy three conditions. First, it should \textit{not} be sensible to the mere magnitude of the difference between the self-citation ratios, since self-citation ratios are partly affected by the size of the country: bigger countries tend to have higher self-citation ratios. This excludes all measures based on the point-wise distance between the time-series. Second, the measure should be sensitive to \textit{trends} and \textit{changes in trends} of self-citation ratios, as these events may be associated with external perturbations, such as policy changes, useful in explaining the phenomenon. Third, the measure should not assume any underlying statistical model for self-citation ratios, in order to avoid unjustified assumptions on the dynamics of the self-citations over time. 

\newpage
\begin{table}[htb!]%{c c c c c c}
\centering
\caption{Descriptive statistics. The overline indicates the mean. Publications include only research articles, reviews, and conference papers. Citations ($\overline{C}$)  and self-citations ($\overline{S^I}$ and $\overline{S^{II}}$)  are computed on a 2-year citation window. Citing sources include all types of documents. Years: 1996-2019.}
\resizebox{\textwidth}{.30\paperheight}{\begin{tabular}{l c c c c c}
 \hline
 & & International &  & &  \\
  Country & Publications & Publications & $\overline{C}$ & $\overline{S^I}$ & $\overline{S^{II}}$ \\
 && $\%$ & & & \\ 
\hline
United States & 11,414,720 & 27.5 & 1,464,481.7 & 797,739.3 & 306,809.7 \\
China & 6,479,473 & 17.9 & 504,359.4 & 317,813.6 & 114,974.0 \\
United Kingdom & 3,153,786 & 43.6 & 419,930.0 & 130,947.8 & 79,121.6 \\
Germany & 2,947,845 & 42.5 & 376,685.1 & 129,782.3 & 86,071.0 \\
Japan & 2,788,160 & 21.4 & 231,987.1 & 85,635.3 & 63,336.1 \\
France & 2,064,932 & 45.6 & 245,978.8 & 71,137.5 & 50,673.5 \\
India & 1,733,461 & 16.6 & 112,886.3 & 45,132.6 & 29,494.7 \\
Italy & 1,711,410 & 39.2 & 213,541.0 & 69,307.8 & 50,916.5 \\
Canada & 1,690,621 & 43.7 & 216,283.8 & 54,260.4 & 40,718.7 \\
Spain & 1,364,243 & 40.4 & 157,716.2 & 45,689.5 & 33,642.1 \\
Australia & 1,320,648 & 44.3 & 171,197.2 & 47,861.2 & 35,692.6 \\
Russian Federation & 1,167,226 & 25.9 & 60,725.2 & 26,180.6 & 20,718.6 \\
South Korea & 1,158,182 & 25.9 & 105,930.1 & 30,022.7 & 22,081.7 \\
Brazil & 976,69 & 27.8 & 69,322.7 & 23,589.9 & 16,348.8 \\
Netherlands & 935,681 & 50.7 & 149,365.2 & 34,158.1 & 26,825.5 \\
Switzerland & 694,479 & 60.0 & 123,581.9 & 25,734.6 & 20,675.7 \\
Poland & 682,376 & 29.3 & 53,484.4 & 17,605.0 & 13,987.6 \\
Taiwan & 672,686 & 22.4 & 54,105.9 & 14,520.2 & 11,800.8 \\
Sweden & 646,746 & 52.3 & 95,146.9 & 20,784.7 & 17,090.6 \\
Turkey & 597,155 & 19.1 & 38,182.5 & 10,944.1 & 7,591.9 \\
Iran & 563,672 & 20.8 & 46,282.9 & 19,845.8 & 14,466.0 \\
Belgium & 521,363 & 55.7 & 77,294.0 & 16,065.7 & 14,232.2 \\
Denmark & 386,678 & 54.5 & 64,885.1 & 13,284.3 & 11,391.4 \\
Austria & 380,443 & 54.7 & 52,936.2 & 10,928.6 & 9,766.2 \\
Israel & 368,383 & 42.2 & 47,940.3 & 9,543.1 & 8,384.1 \\
Czech Republic & 339,348 & 37.9 & 30,120.1 & 8,700.5 & 7,332.9 \\
Finland & 335,323 & 47.9 & 45,315.2 & 10,208.1 & 8,925.1 \\
Mexico & 326,559 & 39.4 & 25,077.1 & 6,014.5 & 4,895.2 \\
Hong Kong & 311,764 & 59.3 & 38,812.4 & 8,124.7 & 7,515.1 \\
Malaysia & 310,874 & 35.5 & 21,162.5 & 7,031.0 & 5,714.8 \\
Greece & 306,955 & 41.5 & 33,923.5 & 7,385.5 & 6,482.3 \\
Portugal & 306,884 & 48.3 & 34,792.4 & 8,413.6 & 7,636.2 \\
Norway & 305,437 & 51.7 & 40,642.6 & 8,923.3 & 7,451.2 \\
Singapore & 292,723 & 51.5 & 41,668.3 & 8,539.5 & 7,830.5 \\
South Africa & 276,641 & 42.9 & 27,013.8 & 7,259.7 & 5,606.1 \\
New Zealand & 231,225 & 48.9 & 26,678.4 & 5,947.3 & 5,053.0 \\
Egypt & 221,805 & 42.1 & 17,146.1 & 4,617.4 & 3,928.0 \\
Argentina & 211,228 & 40.7 & 19,398.9 & 4,275.7 & 3,619.9 \\
Romania & 210,962 & 32.2 & 14,083.3 & 4,307.6 & 3,490.0 \\
Ukraine & 201,738 & 34.1 & 10,129.3 & 3,686.2 & 3,290.4 \\
Saudi Arabia & 201,523 & 63.8 & 25,274.4 & 5,862.0 & 5,302.3 \\
Ireland & 196,413 & 51.6 & 27,564.5 & 4,974.7 & 4,639.1 \\
Hungary & 193,999 & 44.9 & 20,569.6 & 4,395.8 & 3,796.7 \\
Thailand & 188,262 & 39.6 & 14,465.1 & 3,219.8 & 2,706.9 \\
Pakistan & 168,222 & 42.4 & 14,633.1 & 4,746.5 & 3,640.3 \\
Chile & 154,667 & 54.9 & 17,123.8 & 3,908.5 & 3,130.5 \\
Indonesia & 150,879 & 27.9 & 6,574.9 & 2,575.6 & 1,908.5 \\
Slovakia & 115,855 & 41.3 & 8,905.9 & 2,378.4 & 1,866.2 \\
Croatia & 107,419 & 31.5 & 7,925.5 & 1,765.6 & 1,523.6 \\
Colombia & 107,333 & 47.5 & 9,269.6 & 1,814.2 & 1,470.0 \\
\hline
\end{tabular}}

\label{tab:desc_stats}
\end{table}

The following dissimilarity measure based on Pearson’s correlation satisfies all the three requirements specified above:

\begin{equation}
    d(\boldsymbol{X},\boldsymbol{Y}) = \sqrt{2(1 - \rho(\boldsymbol{X},\boldsymbol{Y})} 
\end{equation}

\noindent where $\boldsymbol{X}=(X_1,\dots, X_n)$, $\boldsymbol{Y}=(Y_1,\dots, Y_n)$ are the time-series considered and $\rho(\boldsymbol{X},\boldsymbol{Y})$ is the Pearson correlation index. 

This measure was proposed originally by \cite{golay_new_1998} and implemented in the function \code{diss.COR} of the package \pkg{TSclusts} \cite{montero_tsclust_2014} for \proglang{R} \cite{R}.
The measure is bounded between 0, when there is a perfect correlation between the time-series, and 2, where there is perfect anti-correlation between them. When the two series show no correlation at all, the value is $\sqrt{2}$.

All the dissimilarities between pairs of country trends can be arranged in a dissimilarity matrix. This in turn can be visualized using Kruskal's Non-metric Multidimensional Scaling, one form of non-metric MDS which respects the ranking of dissimilarities rather than their absolute values \cite{borg_modern_2010}. The function \code{isoMDS} of the package \pkg{MASS} \cite{MASS} in \proglang{R} can be used to produce MDS maps.

\section{Results}
\label{sec:results}

Figure \ref{fig:TS} shows the trends of the 50 countries for the two indicators $SR^I$ and $SR^{II}$. Three main observations can be made on these trends. First, the proportion of country self-citations of both types has decreased over time in most countries, following a linear pattern with more or less pronounced oscillations depending on the country. Three countries, however, deviate from this general behavior: in the case of Indonesia, Ukraine, and the Russian Federation, in fact, the trends of both indicators show an inversion  from descending to ascending.

Second, the $SR^I$ and $SR^{II}$ trends are highly correlated for most of the countries, with both indicators following similar trajectories over time. Again, there is a notable exception represented by China, which is the only country where the share of country self-citations of Type I has surged (China $SR^I$ has increased by 24.1 p.p. between 1996 and 2018) while that of self-citations of Type II has substantially contracted ($SR^{II}$ has decreased by 22 p.p. in the same period).

Third, the difference between $SR^I$ and $SR^{II}$ varies over time differently depending on the country (Figure \ref{fig:TS_delta} and Table \ref{tab:desc_stats}). 

\newpage    
\begin{table}[htb!]
\centering
\caption{Average country self-citations of type I and type II and their average difference. All values are multiplied by 100. }

\resizebox{!}{0.30\paperheight}
{\begin{tabular}{l c c c}   
 \hline
 \\
Country & $\overline{SR^I}$ & $\overline{SR^{II}}$ & $\overline{SR^I - SR^{II}}$\\
\hline
Argentina & 25.6 & 22.7 & 3.0 \\
Australia & 30.2 & 23.6 & 6.6 \\
Austria & 22.9 & 21.0 & 2.0 \\
Belgium & 23.2 & 21.1 & 2.1 \\
Brazil & 36.6 & 27.8 & 8.8 \\
Canada & 26.6 & 20.6 & 6.1 \\
Chile & 24.8 & 21.0 & 3.8 \\
China & 57.0 & 30.5 & 26.5 \\
Colombia & 21.0 & 18.9 & 2.0 \\
Croatia & 28.9 & 25.4 & 3.6 \\
Czech Republic & 32.6 & 28.4 & 4.1 \\
Denmark & 22.6 & 19.8 & 2.8 \\
Egypt & 30.1 & 27.4 & 2.7 \\
Finland & 25.0 & 22.1 & 2.9 \\
France & 30.5 & 22.1 & 8.5 \\
Germany & 36.0 & 24.4 & 11.6 \\
Greece & 25.1 & 22.8 & 2.3 \\
Hong Kong & 26.7 & 25.3 & 1.4 \\
Hungary & 24.3 & 21.7 & 2.6 \\
India & 41.9 & 31.1 & 10.8 \\
Indonesia & 26.1 & 21.6 & 4.5 \\
Iran & 45.8 & 38.6 & 7.2 \\
Ireland & 19.9 & 19.1 & 0.8 \\
Israel & 21.7 & 19.4 & 2.3 \\
Italy & 33.1 & 25.0 & 8.1 \\
Japan & 38.5 & 28.7 & 9.8 \\
Malaysia & 34.1 & 30.2 & 4.0 \\
Mexico & 27.1 & 23.1 & 4.0 \\
Netherlands & 24.8 & 20.0 & 4.8 \\
New Zealand & 25.4 & 21.7 & 3.7 \\
Norway & 24.9 & 21.1 & 3.8 \\
Pakistan & 35.9 & 30.1 & 5.7 \\
Poland & 35.7 & 29.7 & 6.1 \\
Portugal & 28.2 & 26.6 & 1.6 \\
Romania & 34.4 & 31.1 & 3.2 \\
Russian Federation & 41.1 & 34.3 & 6.9 \\
Saudi Arabia & 26.1 & 24.6 & 1.5 \\
Singapore & 26.3 & 25.0 & 1.3 \\
Slovakia & 30.0 & 25.8 & 4.2 \\
South Africa & 30.3 & 24.6 & 5.8 \\
South Korea & 32.0 & 25.1 & 6.9 \\
Spain & 31.7 & 24.5 & 7.3 \\
Sweden & 24.1 & 20.1 & 3.9 \\
Switzerland & 22.1 & 18.2 & 3.9 \\
Taiwan & 30.8 & 26.2 & 4.6 \\
Thailand & 24.2 & 20.9 & 3.4 \\
Turkey & 33.2 & 25.2 & 7.9 \\
Ukraine & 39.5 & 36.9 & 2.6 \\
United Kingdom & 33.0 & 20.4 & 12.6 \\
United States & 56.1 & 21.7 & 34.4 \\
\hline
\end{tabular}}
\label{tab:diff_stats}
\end{table}


In particular, we can distinguish three groups of countries based on how the difference develops over time. The first group is characterized by an increasing difference, with the two curves of $SR^I$ and $SR^{II}$ progressively diverging. It includes Brazil, Chile, China, Colombia, Egypt, Hungary, India, Indonesia, Iran, Malaysia, Pakistan, Romania, Russian Federation, Slovakia, Turkey, and Ukraine. The second group shows a stable difference, meaning that the two curves follow parallel directions. It includes Argentina, Australia, Austria, Belgium, Canada, Croatia, Czech Republic, Denmark, Finland, France, Germany, Greece, Hong Kong, Ireland, Israel, Italy, Japan, Mexico, Netherlands, New Zealand, Norway, Poland, Portugal, Saudi Arabia, Singapore, South Africa, South Korea, Spain, Sweden, Switzerland, Taiwan, Thailand, and the United Kingdom. The last group includes only one country, the United States, where the difference reduces over time, i.e., the curves tend to converge. Note that all G10 countries, apart from the United States, belong to the second group and are all characterized by a significant difference between $SR^I$ and $SR^{II}$, with the United States showing the highest difference of all countries considered (mean difference = 34.4).


%Some interesting patterns can be highlighted. First, m 
%The trends of $SR^I$ and $SR^{II}$ are correlated for most countries: the share of country self-citations of both types has generally decreased over time. Indonesia, the Russian Federation \textcolor{red}{and the Ukraike show a changing trend from descending to ascending for both indicators}. The most notable exception is China  $SR^I$ and $SR^{II}$ for which  

\begin{sidewaysfigure}
    \centering
    \includegraphics[width = \textwidth]{TS_cit1_Inw1_Inw2.png}
    \caption{Country self-citation rate $SR^I$ and $SR^{II}$ by country. Yearly data 1996-2019. }
    \label{fig:TS}
\end{sidewaysfigure}

%Countries can be classified into three groups depending on how the difference between $SR^I$ and $SR^{II}$ develops over time (Figure \ref{fig:TS_delta} and Table \ref{tab:delta_stats}). The first group of countries is characterized by an increasing difference: Brazil, Chile, China, Colombia, Egypt, Hungary, India, Indonesia, Iran, Malaysia, Pakistan, Romania, Russian Federation, Slovakia, Turkey, and Ukraine. A second group by an almost stable difference, which can be more or less pronounced: Argentina, Australia, Austria, Belgium, Canada, Croatia, Czech Republic, Denmark, Finland, France, Germany, Greece, Hong Kong, Ireland, Israel, Italy, Japan, Mexico, Netherlands, New Zealand, Norway, Poland, Portugal, Saudi Arabia, Singapore, South Africa, South Korea, Spain, Sweden, Switzerland, Taiwan, Thailand, and the United Kingdom. 
%Lastly, there is only one country, the United States, where the difference reduces over time. The United States is at the same time the country with the highest difference. All G10 countries, apart from the United States, belong to the second group and are all characterized by a significant difference between $SR^I$ and $SR^{II}$. 

\begin{sidewaysfigure}
    \centering
    \includegraphics[width = \textwidth]{TS_Delta_Inw1_Inw2.png}
    \caption{Simple difference between $SR^I$ and $SR^{II}$ over time by country. The solid red line represents yearly data (1996-2019), and the dotted black line is the average difference in the whole period.}
    \label{fig:TS_delta}
\end{sidewaysfigure}



%Instead of the visual inspection of Figure \ref{fig:TS}, dissimilarities between pairs of country trends are computed by the correlation-based distance $d_{COR}$. 
The correlation-based distance was used to produce two matrices $M^I$ and $M^{II}$ of order $50 \times 50$, which represent the distances between the 50 countries’ trends respectively on the $SR^I$ and $SR^{II}$. 

The structures of the two matrices were visualized using Kruskal's Non-metric Multidimensional Scaling in the two MDS maps in Figures \ref{fig:MDS_SR_I} and \ref{fig:MDS_SR_II}, based respectively on $SR^I$ and $SR^{II}$ trends. As explained in Section \ref{sec:methods}, the distance between the dots representing the countries on the MDS maps is inversely proportional to the similarity of their $SR$ trends, so that countries characterized by similar trends will be placed closer and countries characterized by dissimilar trends far away. Note that, in both maps, the distances of the points on the 2-D map distort the original distances between the time-series only slightly, as shown by the low values of the stress of the MDS solutions (respectively, 9.18\% and 7.45\%). 

In the MDS map for $SR^I$ (Figure \ref{fig:MDS_SR_I}), three zones can be distinguished. The first is the big cluster in the left area, where most of the countries are concentrated. The second is the belt that surrounds the cluster and includes Iran, Romania, Pakistan, Thailand, Colombia, Saudi Arabia, Ukraine, Egypt, India, and, most notably, Italy, the only G10 country that is not placed inside the big cluster. The third zone comprises the rest of the map, where countries characterized by very specific trends are scattered: Malaysia, China, Indonesia, and the Russian Federation.

\begin{sidewaysfigure}
    \centering
    \includegraphics[width = \textwidth]{Non-Metric_MDS_COR_cit1_Inw1.png}
    \caption{MDS solution for $SR^I$. G10 countries are in bold. Stress = 9.18\%}
    \label{fig:MDS_SR_I}
\end{sidewaysfigure}

The MDS map for $SR^{II}$ (Figure \ref{fig:MDS_SR_II}) largely confirms this picture, showing significant overlap with the structural features of the previous map. Again, we find a big cluster including most of the countries, surrounded by a belt and, in the distant zones of the map, a scattering of anomalous countries. The belt includes the same countries as the belt in the previous map: Italy's anomalous position with respect to G10 countries is confirmed. The most important difference between the two maps is China: under the profile of the $SR^I$ trend, the country was placed in the distant zone, whereas under the profile of the $SR^{II}$ trend, it is placed within the big cluster.  

\begin{sidewaysfigure}
    \centering
    \includegraphics[width = \textwidth]{Non-Metric_MDS_COR_cit1_Inw2.png}
    \caption{MDS solution for $SR^{II}$. G10 countries are in bold. Stress = 7.45\%. Note that the points of Malaysia and Indonesia are outside the plot.}
    \label{fig:MDS_SR_II}
\end{sidewaysfigure}

\section{Discussion}
\label{sec:discussion}

The decreasing trend in both $SR^I$ and $SR^{II}$ which characterizes most of the countries shows that, in most of the cases, the overall citation impact of countries has grown more than the proportion of citation impact generated by domestic authors, i.e., that the denominator of both indicators has increased more than their numerator (see Section \ref{sec:ind_design}). The faster increase in citations may be related in turn to the overall growth of scientific production and how it impacts the length of the reference lists of scientific publications. According to \cite{pan_memory_2018}, in fact, the world scientific production exhibits 4\% annual growth in publications and 1.8\% annual growth in the number of references per publication. Combined, these dynamics produce a 12-year doubling period in the total amount of references, which results in turn in a generalized increase in citations \cite{nicolaisen_number_2021}. The decreasing trends, thus, may be simply due to the different rates of growth of the numerator and the denominator of the indicators used here: country self-citations of Type I or Type II grow less than bibliographic references.

%\textcolor{red}{non sono convinto che la frase successiva stia qua. staiamo guardando la dinamica, non le cause della dinamica. Forse il commento successivo va ripristinato?}The modification of citation habits due to the increasing role of citation metrics in research evaluation is probably another pulling factor behind the increase in citations \cite{wouters_citation_2014}.

% Add comment on decreasing trends: this may simply be due to different rates of growth of the numerator and the denominator of the indicators used here: country self-citations of Type I or of Type II growth less than bibliographic references. This general trend is due to the explosion of scholarly literature and also to a modification of citation habits due to the general publish or perish environment.

The observed decreasing trend in the $SR^I$, however, contradicts previous studies of the development of this indicator over time: \cite{baccini_citation_2019}, in fact, report an average increase of +5.2 p.p. in the $SR^I$ of G10 countries between 2000 and 2016. Namely, the discrepancy between the present results and \cite{baccini_citation_2019} depends on the different way of computing the $SR^I$ indicator. Indeed, \cite{baccini_citation_2019} used a non-fixed citation window, which included all the years from the publication year to 2016. For example, for the cited items published in the year 2000, a 17-year citation window was used, by summing up all citations from 2000 to 2016; whereas, for the year 2006, the citation window was 11 years long, including citations from 2006 to 2016; for 2016, the citation window included only 1 year, i.e., only citations from 2016 itself were counted. Since self-citations are in general younger than external citations \cite{tagliacozzo_self-citations_1977, lin_relationship_2012}, they tend to represent a higher proportion of total citations for the years when the citation window is shorter. Hence, \cite{baccini_citation_2019} registered an inflation of $SR^I$ for more recent years, as the citation window shortens. The present study, by contrast, does not suffer from this problem as it is based on a fixed citation window, i.e., only a fixed number of years after the target year is considered (see Section \ref{sec:ind_design}). 

Turning now to a more substantial interpretation of the results, there are two patterns that are worth highlighting. First, the emerging giant of science, China, is characterized by a unique behavior: China $SR^I$ and $SR^{II}$ show almost opposite trends, with the former significantly increasing and the latter significantly decreasing. If the increasing $SR^I$ trend shows that Chinese scientists heavily rely on the scientific production of their own country, the decreasing $SR^{II}$ trend indicates that author self-citations are diminishing, in line with Western countries. Interestingly, this divergence results in a growing difference over time between the two indicators (Figure \ref{fig:TS_delta}), which can be interpreted as a sign of the rising international impact of Chinese publications. As noted above, in fact, the difference between $SR^I$ and $SR^{II}$ depends on the citations of the international publications of a country. A wider difference means that these international collaborations are widely cited not only by the focal country (China, in our case) but also by the collaborating countries. Results, therefore, seem to show that international collaborations of Chinese authors are increasingly cited by other countries as well, another sign of the new status of China as a scientific superpower \cite{tollefson_china_2018}. Notably, India shows an increasing difference as well, which may be interpreted analogously as a sign of the rising scientific impact of this country.
% Add comments on China and India where the delta increases over time (explanation: impact of international publications increase)

The second key pattern, emerging from the MDS maps, is that there are several countries whose self-citation behavior stands out from that of the big majority of countries. With a couple of exceptions (China and India), these countries are the same when the two indicators are considered: Colombia, Egypt, Indonesia, Iran, Italy, Malaysia, Pakistan, Romania, Russian Federation, Saudi Arabia, Thailand, and Ukraine. Interestingly, all these anomalous countries have adopted, in the recent past, specific research policies aiming at increasing publication output and citation impact of their national scientific community. In the following sections, the recent history of the research policies in each group of anomalous countries is reconstructed. It will be shown that all these policies are characterized by direct or indirect incentives that may create room for the strategic use of self-citations. $SR^I$ and $SR^{II}$, therefore, seem to be sensitive to policy-induced perturbations of the citation habits.

%\subsection{A glance to anomalous countries}
%\label{sec:glance}

\subsection{Post-soviet countries: Russian Federation, Ukraine, and Romania}

Since 2007, Russian Federation adopted measures aimed to boost research productivity, in the form of performance based funding and individual payment for publications \cite{RN1800}. In 2012, Putin’s May decrees N. 599 introduced various incentives for stimulating “the development of science in Russia and an increase in the number of articles by Russian scientists in the Web of Science Journals” \cite{RN1708, RN1709}. In particular, the project "5top100"  aimed to push at least five Russian universities to enter the top hundred of leading international universities according to the global universities rank \cite{RN1802}. The project council paid attention to bibliometric indicators, including the number of publications and citations in Web of Science and Scopus \cite{RN1802}. At the local level, Russian universities introduced new promotion criteria and financial incentives for faculty. After the policy intervention, the research productivity of the country significantly increased \cite{RN1709, RN1711, RN1710, RN1802, RN1803}. However, a contemporary rise in country self-citations in conference proceedings has been noted \cite{RN1709} and the spread of unethical practices after the policy change, including “predatory journals”, plagiarism, and paper mills, has been repeatedly denounced \cite{RN1713, RN1712}.
%Moed and co-authors documented the boom of Russian research production after the policy intervention, by limiting to discuss about the reliability of available databases for the measurement of research performance. They noted a rise of country self-citations in conference proceedings \cite{RN1709}. ALso other authors highlighted the positive effect on publication records of Russian researchers \cite{RN1711, RN1710, RN1802, RN1803}. 
%The spread of unethical practices following the change in policy is documented with respect to the diffusion of “predatory journals”, plagiarism and paper mills \cite{RN1713, RN1712}. %The changing slope of SRI and SRII trend coincides with the introduction of the new research policy in Russian Federation, by suggesting that boosting in country self-citation is an effect of the new policy.

As to Ukraine, the new law “On scientific and Technical Activity” was enacted on January 16, 2016 (http://iht.univ.kiev.ua/ncst2016/index-en.html). It established a National Council of Ukraine on Science and Technology directly controlled by the ministers. The following year, the European Commission organized a Peer review of the Ukrainian Research and Innovation System largely supporting the new law. One of the key recommendations issued by the Commission was to identify research universities after a period of 5 years by taking into consideration also “the number of international publications and citations”. In the meantime, the use of bibliometric indicators become largely diffused in Ukraine for ranking institutions \cite{RN1736}, for distributing financial awards, and for evaluating projects \cite{RN1738}. According to \cite{RN1737}, “until 2015 publication requirements for becoming associate professor and professor included only articles in Ukrainian journals. In 2015 they were substituted for articles in journals indexed in Scopus and WoS”. According to scientists interviewed by \cite{RN1734}, Ukrainian academy suffers from a significant and inherited problem of misconduct and plagiarism. Possibly grafted on this tradition, new forms of adaptation to the bibliometric game are arising, such as publishing articles in selected national journals \cite{RN1739} and in Scopus de-listed journals \cite{RN1738}. Evidence about over-citations and self-citations has been provided as well \cite{RN1738}.

Lastly, Romania started major reforms of tertiary education following the provisions of the Law of Education n. 1/2011 by modifying recruitment, university funding, and quality assurance \cite{RN1784}. It was introduced also a research-driven classification and ranking system for universities managed by the Romanian Ministry of Education University, which constituted the informative basis of performance based funding \cite{RN1788}. Academic and research staff recruitment and promotion changed radically from a model based on in-breeding to one taking into account individual performances measured by number of publications and citations \cite{RN1784}. The Romanian Program for Rewarding Research Results, which had already started in 2007, was strengthened with direct payment to authors for publication in indexed journals \cite{RN1763}. \cite{RN1789} described in detail the functioning of the program, and highlighted that articles are rewarded according to the metrics of the journal where they are published. According to their analysis, monetary incentives supported productivity, but not impact of Romanian research. The presence of incentives to publication might push toward misconduct, as suggested by the Romanian high level of retractions \cite{RN1767}. Evidence of self-citation and citation stacking for Romanian journals may be correlated to the necessity to boost journal metrics \cite{RN1458}.

\subsection{Southeast Asia: Malaysia, Thailand, Indonesia}

According to an UNESCO report \cite{RN1725}, university rankings are central in the research policies of Malaysia and Thailand:  ``A key ingredient in high rankings is a university’s publication rate. Consequently, faculty members – particularly those teaching in graduate programmes – are under pressure to publish in top-tier international journals''. According to \cite{RN1729}, Asian higher education institutions witnessed the  ``proliferation of policies surrounding the fanaticism with metrics [for] incentivising scholars to publish through selected publication''. 

In Malaysia the discussion about university performances and rankings start-ed early \cite{RN1726}. Policy interventions happened in a highly centralized structure, where salaries and promotion criteria were defined directly by the Ministry of education. In 2007, Malaysian government adopted a National Higher Education Strategy Plan introducing a performance based funding of universities \cite{RN1727}. The strategic objective to ``empower research teams with new teamwork concepts to produce international level research output'' was defined in an action plan for ``improving the quality of faculty publications''. Remarkably, the only indicator adopted was the ``Increased percentage of staff achieving at least 100 citations'' \cite{RN1728}. The upward trend of Malaysian country self-citations coincides with the years following this government intervention. In recent years, decentralized policies adopted by universities provide individual payment schemes for publications \cite{RN1724} (https://tinyurl.com/4t5kpd2h; https://tinyurl.com/mr33rzcn) and received citations (https://tinyurl.com/n3779dz3). 

As to Thailand, the government initiated the establishment of the National Research University (NRU) project in 2009. “This plan aimed at developing academic excellences to enhance the country’s research activities and to promote the better university-industry linkages for national competitiveness. The Office of the Higher Education Commission’s selection criteria were mainly based on the ranking system conducted by Times Higher Education-Quacquarelli Symonds (THE-QS) and the impact factor of publications published on Scopus database” \cite{RN1732}. A list of excellent universities was also defined \cite{RN1731}. 

Indonesia was ``the weakest nation in all relative scientometric indicators'', with respect to Malayisia, Philippines, Thailand and Vietnam \cite{RN1714}. According to \cite{RN1715} “the increase in the number of publications in recent years [...] is a reflection of government policy on research and academic careers and attempts to improve the position of Indonesian universities in international ranking”. The main intervention was the Indonesian law on higher education Number 12/2012. \cite{RN1716} documented that “Academics who are successful in publishing their articles in Scopus- indexed journals would be rewarded with a certain amount of money and it goes directly to their pocket. Such a standard is also used as a measure for promotions [...], for payment of certified academics, and for honorary allowance.  […] The obligation to publish articles in reputable international journals has become integrated into doctoral programs and serves as a requirement to be met prior to the completion of the study”. According to a survey \cite{RN1716}, Indonesian “academics have attributed their interpretation of the rewards as a mere completion of publishing in any kinds of journals indexed in Scopus apart from the consideration of the quality. Consequently, academics have performed their own way or strategy of publishing through the easiest, fastest, cheapest open access journals and proceedings”. The performance in terms of citations per paper appeared not so high with respect to other neighborhood countries until 2017 \cite{RN1717}. \cite{RN1718} documented that Indonesia has made a recent and remarkable shift towards conference proceedings publishing.  Rochmyaningsih \cite{RN1719} criticized the adoption of this aggressive policy by arguing that “the developing world needs more than numbers”.  In 2017 Indonesia’s Ministry of Research, Technology and Higher Education introduced Indonesia’s Science and Technology Index (SINTA; https://sinta.kemdikbud.go.id/), based on Scopus data, that “gives  recognition  to  Indonesian scientists, triggers competition among them, and motivates them to be better” \cite{RN1720}. The number of papers, citations, and H-index are mixed in an index used for evaluating research grants applications, promotions, and salary negotiations. According to \cite{RN1720} several top scorers  “had  inflated their SINTA score by publishing large numbers of papers in low-quality journals, citing their  own  work  excessively,  or  forming  networks of scientists who cited each other”. The present paper documents that the adoption of policies both in 2012 and 2017 was flanked by a modification of self-citation strategies of Indonesian scientists. 

\subsection{Muslim-majority countries: Egypt, Iran, Saudi Arabia, Pakistan}

According to \cite{RN1751}, Egypt, Iran, Pakistan, and Saudi Arabia differ from other Muslim-majority countries in terms of research performance. In particular, Egypt and Saudi Arabia have been the most active research producers from the Arab world in the last 20 years. Like other Arab countries, they adopted a reform of the tertiary education and witnessed a remarkable growth of publications and citations \cite{RN1744, RN1745, RN1751}, matched however by a rising number of retractions due to misconduct \cite{RN1747, RN1746}. More in general, according to \cite{RN1757}, the problem of corruption is widespread in Arab universities.

Since the mid-2000s, Saudi Arabia adopted National Developments plans aiming to support research productivity \cite{RN1742}, by mixing centralized strategies, such as the National Science Technology and Innovation Plan inspired to the US National Science Foundation, and decentralized ones adopted by universities \cite{RN1743}. According to \cite{RN1748} this catching-up strategy of Saudi Arabia universities started in 2007, and it was mainly  based on attempts to raise research outputs, prestige, and rankings (e.g. https://tinyurl.com/4s8b6hef), by allocating “significant research funding to support industry-based Research Chairs as well as the employment of high-profile international researchers to lead projects that will be staffed by university faculty and postdoctoral students” \cite{RN1742}. Individual incentives for researchers are largely adopted, with pays and promotions attached to publications and citations (e.g. https://tinyurl.com/2s3zchwk;  https://tinyurl.com/5n96nmrt). The strategy of affiliating to Saudi Arabia universities external highly cited researchers for improving rankings received early critics  \cite{RN1749, RN1779, RN1750}. Nonetheless, \cite{RN1783} claim that self-citations are not anomalous in Saudi Arabia, at least in the medical specialties.

In comparison to Saudi Arabia, the governance of Egyptian universities is traditionally much more centralized \cite{RN1758}. According to \cite{RN1745}, Egypt “demonstrate[s] the importance of incentives within hiring organizations, specifically whether researchers are rewarded for publications or obtaining funding”. Indeed, the Ministry of Scientific Research introduced competitive funding to research in 2007, by favouring basic research, the formation of research groups, and international collaborations. At a single university level, “internal practices recognize and reward certain forms of performance more than others—such as teaching, administration, graduate supervision, advising and outreach—as well as the expected quantity and prestige of scientific publications” \cite{RN1745}. According to some researchers interviewed in \cite{RN1755}, individual financial incentives and national awards \cite{RN1756} represent the main push leading to the improvement of Egypt’s higher education sector. Others have a less positive attitude and highlight the diffusion of malpractices in research such as plagiarism, data fabrication, and manipulation \cite{RN1754}. According to a comprehensive survey of Egyptian researchers, financial rewards for publications together with low salaries are among the most important risk factors leading to research misconduct \cite{RN1754}. Finally, it should be noted that Egyptian universities provide individual awards for citations (e.g. https://bu.edu.eg/BUNews/25947).

 %presents a comprehensive survey about the perceptions of Egyptian researchers about the practices of research misconduct. In his field work, he documented that the 

As to Pakistan, the government of the country established in 2002, by following the recommendation of a task force of the World Bank, a Higher Education Commission aimed at expanding the higher education sector and to improve research in the country.  Various measures were adopted, including incentives aimed to promote research and scholarship \cite{RN1761, RN1760, RN1762}. Since 2002, a financial incentive based on number of publications, number of citations received, and Impact Factor of journals was also introduced \cite{RN1764, RN1766}. The growth of international publications, collaborations, and citations is considered as a result of these policies \cite{RN1759, RN1760, RN1766}. Still, Pakistan is currently one of the leading countries in terms of retractions \cite{RN1747, RN1767}, and, according to \cite{RN1771}, under the rising menace of scholarly black-market pushed-up by monetary incentives. 

Iran had between 1980 and 2010, “one of the fastest rates of growth in scientific production that the world has witnessed”, probably due to nuclear technology development program \cite{RN1774}. In 2009, Iran announced a 20-year "comprehensive plan for science" focused on higher education and stronger links between industry and academia \cite{RN1778, RN1776}. The quantitative growth of Iranian science has continued until now \cite{RN1777, RN1778}. It is a controversial issue, however, whether this development has been matched by the increase of scientific quality too \cite{RN1777, RN1773}. According to a critic, “the state has imposed deeply short-sighted research policies on universities with the sole objective of increasing the number of publications, which is in turn used in its propaganda to demonstrate progress in technological self-sufficiency and mask significant shortcomings caused by decades of isolation due to the regime’s international policy. [...]
%In reality, however, regardless of their scholarly quality, an overwhelming majority of the papers published by Iranian researchers do not contribute to the nation’s prosperity. 
A top-down incentive for publication along with lack of real demand from the economy, which is not based on new technology development, have pushed Iranian researchers to focus on the publishability of their works rather than their relevance and practical impact” \cite{RN1773}. As in the other countries, “the government’s policy in higher education makes academic promotions and student graduation contingent upon publication of papers in scientific journals. These policies have created an environment that lends itself to the most extreme form of the publish-or-perish paradigm” \cite{RN1772}. Retractions of articles authored by Iranian scientists have attracted attentions worldwide \cite{RN1780, RN1781}. Anomalous rate of self-citations has been documented as well \cite{RN1782}. 


\subsection{Colombia}

Since 2002, Colombia has introduced a model of wage incentive based on research productivity, the Faculty Promotion Policy for Colombian Public Universities (Decree 1279 of 2002). The performance rating is based on a national scientific journals index called Publindex. In 2009, the Ministry of education started to measure production in terms of citation in the WoS database. In 2018, the system was finally strengthened \cite{RN1798}.  By and large, this legislation established a pay-for-performance system through salary points calculated in accordance with the higher education degrees, academic rank (fixed components) and academic productivity (variable component) \cite{RN1791, RN1793, RN1795}. \cite{RN1798} documented by anecdotal evidence that self-citations and citation clubs are perceived as current problems by Colombian scholars.  

\subsection{Italy}
Italy is among the top 10 producers of science in terms of global production and total citations (Table \ref{tab:desc_stats}) and it has been considered the main European competitor of the United Kingdom for citation impact \cite{Elsevier, UK_research}. However, data shows that Italy is the only G10 country exhibiting an anomalous trend of self-citations. The Italian anomaly is especially visible when compared with the trends of the other G10 countries: from 2010, Italy starts to diverge from the benchmark countries in both indicators (Figure \ref{fig:Italy}). At the end of the observation period, it results to be the country with the highest $SR^{II}$, above Japan.

\begin{sidewaysfigure}
    \centering
    \includegraphics[scale = 0.8]{Italy_vs_G10.png}
    \caption{G10 countries' trends in $SR^I$ and $SR^{II}$. Italian trends are in bold green.}
    \label{fig:Italy}
\end{sidewaysfigure}

The beginning of the change in the trend coincides with the wide process of reformation of the Italian university system started by the government in 2010 (Law 240/2010). A governmental agency (ANVUR) was established in charge of monitoring and evaluating the Italian research system and, in 2011, the first national research assessment exercise started, followed by a second round in 2015. In both, the evaluation was largely based on the automatic or semi-automatic use of algorithms fed by citation indicators \cite{RN164,baccini_they_2016}. Universities started to be funded according to their performance in the research assessments. Moreover, the reform modified also the recruitment and advancement system for university professors by introducing a national scientific qualification (ASN). This qualification is mandatory both for hiring and promotion and, in order to obtain it, candidates in natural sciences, life sciences, and engineering, must exceed publication and citation thresholds centrally defined by ANVUR \cite{baccini_citation_2019}. As a result of these reforms, bibliometric performance has acquired a central role in the career of Italian scientists \cite{petrovich_bibliometrics_2022}. At the same time, anomalous rises in Italian self-citations have been documented by several studies \cite{abramo_effects_2021, baccini_citation_2019, peroni_practice_2020, scarpa_impact_2018, seeber_self-citations_2019, vercelli_self-citation_2022}.
% As seen in the preceding section all anomalous countries, with the exception of Italy, are lagging behind the frontier of scientific production. In terms of global production and total citations, only Italy appears among the top 10 producers of science (see Table 2). Indeed, all the anomalous countries appear to have adopted aggressive science policy aimed to climb the rankings of global science. From this point of view, the position of Italy appears very peculiar, by having adopted research policies that none of the other G10 countries have adopted. A comparison of SRI and SRI for the g10 countries shows the anomaly of Italy.   


\section{Conclusions}
\label{sec:conclusions}

Since the early times of citation indexes, preoccupations with the opportunistic use of citations have been voiced by bibliometricians and the scientific community \cite{garfield_citation_1979, narin_evaluative_1976}. The centrality acquired by metrics in the various ganglia of the research system, from the career of individual scientists to the ranking of institutions until the evaluation of the scientific performance of entire countries, has further sharpened these concerns 
\cite{biagioli_academic_2019, rijcke_evaluation_2016, szomszor_how_2020, hicks_bibliometrics:_2015, burrows_living_2012}. Self-citation, in particular, has persistently been indicated as among the easiest strategies available to scientists for artificially boosting their citation-related performance indicators \cite{ioannidis_standardized_2019, szomszor_how_2020}, raising the question of whether scientists, under pressure, do indeed attempt to game citation scores by increasing self-citation.

In the present study, we investigated how the propensity to self-citation changed in 50 countries all over the world from 1996 to 2019, using two different indicators based on country self-citations. The results show that, for most countries, self-citation rates have decreased over time following similar patterns. Tendency to self-citation, both at the country level and for individual scientists, seems in fact to be declining. Against this background, however, there are some countries that exhibit anomalous behavior, showing self-citation trends that are significantly different from those of  ``standard'' countries.

The analysis of the research policies adopted by these anomalous countries in the last years has revealed that they \textit{all} share a common trait, namely the introduction of direct or indirect rewards for the bibliometric performance of scientists. The temporal association we found in all anomalous countries between changes in policies on the one hand and changes in the self-citation behavior of the national scientific community on other hand suggests that scientists do indeed respond to the new climate of incentives by altering, among other things, their citation habits. Policy pressure seems therefore capable of affecting rapidly and visibly the citation behavior of entire countries, possibly distorting global rankings of countries based on citations \cite{shehatta_impact_2019}. 

Clearly, we cannot offer a full-fledged \textit{causal} explanation of our data, displaying the causal chains that start from the policy and end with the citation choices of individual authors. Neither we can demonstrate that the \textit{whole} self-citation gain of anomalous countries is due to opportunistic adaptation to research policies. Still, the most likely high-level explanation of the macro-trends we observe is that the policies centered on or emphasizing citation performance do significantly affect the behavior of scientists. 

From this point of view, this study contributes to the ongoing discussion on research evaluation systems by showing that when bibliometric indicators are integrated into systems of incentives, they cease to be neutral measures to become active components in the research system. As such, they are able to modify the behavior of entire scientific communities. Hence, they should be handled by science policy makers with the most extreme caution.


\newpage
\bibliographystyle{plain}
\bibliography{Bibliography}


\end{document}
