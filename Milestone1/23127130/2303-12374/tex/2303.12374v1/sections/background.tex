
\section{Background}

This section introduces GPU auto-tuning with Kernel Tuner and explains how Kernel Launcher improves the software engineering experience by extending Kernel Tuner's capabilities.

Kernel Tuner is designed for tuning GPU kernels -- written in CUDA or OpenCL -- that are usually extracted from a larger application. % in any host programming language. 
While Kernel Tuner is written in Python, no code that uses Kernel Tuner needs to become part of the host application, nor does Kernel Tuner insert any dependencies into the kernel source code, which can still be compiled with their regular compilers after tuning.
This means that the host application can be written in any programming language.

To tune a kernel (see Listing~\ref{fig:vector-add-kernel}), application developers create a small Python script (see Listing~\ref{fig:kernel-tuner-example}) that specifies the kernel source code, name, problem size, arguments, and tunable parameters:
\begin{itemize}
\item The kernel \emph{source code} is specified by pointing to a file that should be able to compile in isolation.
\item The kernel \emph{name} in the source code. The name can include tunable parameter as C++ template arguments.
\item The \emph{problem size} denotes the dimensions of problem domain of the GPU kernel. For most kernels, the problem size is related to the size of the input/output domain of the GPU kernel. Kernel Tuner uses the problem size to calculate the total number of threads blocks. %, while the size of thread blocks may vary. 
\item The kernel \emph{arguments} is a list of multi-dimensional arrays and scalar values. These arguments are passed as function arguments to the GPU kernel. In most cases, the tuning script generates random arrays for the input data and declares empty arrays for the output data.
\item The \emph{tunable parameters} are specified as named parameters with lists of possible values. The parameters are passed as compile-time constants to the kernel code. 
\end{itemize}

% 
Kernel Tuner supports many additionally arguments to specify, for example, search space restrictions, output verification, user-defined metrics, or tuning objectives. 
We refer to the Kernel Tuner documentation\footnote{\url{http://kerneltuner.github.io}} for an extensive description of the function {\tt tune\_kernel}.

Kernel Tuner is designed to automatically explore the search space by compiling configuration-specific kernels and then running benchmarks on the GPU. 
However, as the number of tunable parameters increases, the search space generally grows exponentially, which can make it impractical to explore exhaustively. 
In order to address this challenge, Kernel Tuner incorporates several optimization strategies to optimize the auto-tuning process.

Once the optimal kernel configuration has been determined by the tuner, this information needs to be integrated back into the target application. 
Kernel Tuner supports \emph{compile-time} kernel selection through an API that can generate C header files.
These header files include multiple targets, one for each GPU, that allows a build system (e.g., Make or CMake) to select the optimal kernel configuration for a particular target GPU during compilation. 
In this way, the application can achieve optimal performance a particular GPU, as long as the target GPU is known at compile-time and performance does not depend on the input size.


\begin{figure}[t!]\centering
\begin{lstlisting}[caption={Example of a CUDA kernel for vector addition.},label={fig:vector-add-kernel}]
template <int block_size>
__global__ void vector_add(float *c, float *a, float *b, int n) {
    int i = blockIdx.x * block_size + threadIdx.x;
    if (i<n) {
        c[i] = a[i] + b[i];
    }
}
\end{lstlisting}\vspace{-10pt}
%\end{figure}
%\begin{figure}[t!]
\centering
\begin{lstlisting}[language=Python,caption={Example a Python script using Kernel Tuner to tune the vector add kernel from Listing~\ref{fig:vector-add-kernel}},label={fig:kernel-tuner-example}]
import numpy as np
from kernel_tuner import tune_kernel

def tune():
    kernel_name = "vector_add<block_size>"
    kernel_file = "vector_add.cu"

    size = 10000000

    a = np.random.randn(size).astype(np.float32)
    b = np.random.randn(size).astype(np.float32)
    c = np.zeros(size).astype(np.float32)
    n = np.int32(size)

    args = [c, a, b, n]

    tune_params = dict()
    tune_params["block_size"] = [32, 64, 128, 256]

    return tune_kernel(kernel_name, kernel_file, size, args, tune_params)
\end{lstlisting}\vspace{-20pt}
\end{figure}


There are three areas where Kernel Launcher aims to improve both the software engineering process and the performance portability of the resulting tuned application. 
First, currently, users need to create a separate Python script for each kernel that requires tuning. 
While this approach may work for applications with only a few bottleneck kernels, it does not scale well and becomes unmanageable for large applications that have dozens of kernels.

Second, Kernel Tuner requires the user to generate valid input data to be used by the kernel.
%'s interface is written in Python and expects the kernel arguments to be specified using Python data types, such as Numpy, Cupy, or Torch ndarrays
This works well for kernels that use simple data structures or accept randomly generated data. 
However, for kernels that operate on complex data structures, like lookup tables or graphs, generating realistic input data that matches the data used in real runs of the application can be challenging. 
This places a significant burden on application developers.

Third, while the compile-time kernel selection functionality offered by Kernel Tuner has the advantage that little to no modification are required to the host application, it has some clear limitations.
To achieve optimal performance on every GPU and problem size, the application needs to be recompiled every time. 
Additionally, using a compile-time kernel selection approach in applications where the same kernel may be executed on different problems within a single run is complex and requires considerable engineering effort.

Kernel Launcher aims to enhance the software engineering experience of using Kernel Tuner for developing tunable applications. 
It goes beyond the existing capabilities of Kernel Tuner by offering runtime kernel selection and compilation. 
With these features, Kernel Launcher enables the creation of optimal, performance-portable applications that can reuse the same tunable kernel for different problems within a single execution of the same application.