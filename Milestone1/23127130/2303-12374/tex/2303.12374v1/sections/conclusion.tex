\section{Conclusion}\label{sec:conclusion}

% re-re-re-explain what we did
In this work, we have presented Kernel Launcher: A C++ library that eases the development of auto-tuned CUDA applications. 
Kernel Launcher introduces tunable kernel definitions that merge the tuning code into the host application, reducing redundancy and fragmentation in the source code.
Kernel Launcher introduces {\em capturing} tunable kernels by storing all the information required to tune the kernel during execution, fully automating the process of tuning kernels using Kernel Tuner.
Kernel Launcher then uses wisdom files to select and compile the optimal kernel configuration at runtime.
%
Finally, we have demonstrated that Kernel Launcher can be used to create optimal-performance portable CUDA applications, with a clean API that resembles the CUDA runtime API and with little extra work for application developers.

We have evaluated Kernel Launcher using MicroHH, a computational fluid dynamics code, on two GPUs, the A100 and A4000. Even though these GPUs are based on the same architecture (Nvidia Ampere), using a configuration tuned on one GPU, for a specific problem size and precision, on the other GPU only results in 70\%-77\% and 69\%-82\% (A100 to A4000), and 67\%-83\% and 50\%-77\% (A4000 to A100), of the potential performance for two kernels in MicroHH.
Moreover, using the performance portability metric, we have shown that tuning only for one scenario and then using this configuration in all scenarios may lead to worse overall performance compared to not tuning the code at all.
Using Kernel Launcher, the application always selects the optimal configuration to achieve 100\% of the potential performance in each scenario, thus achieving optimal performance portability.

This work is not without limitations. 
Applications for which the kernel problem size is unknown beforehand cannot be tuned at compile time. 
Kernel Launcher does support fuzzy matching to select kernels with the closest matching problem size, so if the distribution of problem sizes can be sampled Kernel Launcher can still be used, but performance may be suboptimal. 
Additionally, Kernel Launcher uses the problem size as the primary descriptive feature on which  configurations are selected for one GPU. For irregular problems, such as graphs or sparse matrices, performance may depend strongly on the data itself rather than its size. Kernel Launcher currently does not support selecting on features other than the problem size and GPU, and as such, performance may be suboptimal for irregular algorithms. 

% what have we learned

% explain in what sense the world will be a better place now
