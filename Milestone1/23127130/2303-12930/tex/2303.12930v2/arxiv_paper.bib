@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}
@inproceedings{tian2018audio,
  title={Audio-visual event localization in unconstrained videos},
  author={Tian, Yapeng and Shi, Jing and Li, Bochen and Duan, Zhiyao and Xu, Chenliang},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={247--263},
  year={2018}
}
@inproceedings{tian2020unified,
  title={Unified multisensory perception: Weakly-supervised audio-visual video parsing},
  author={Tian, Yapeng and Li, Dingzeyu and Xu, Chenliang},
  booktitle={European Conference on Computer Vision},
  pages={436--454},
  year={2020},
  organization={Springer}
}
@inproceedings{lee2021acav100m,
  title={Acav100m: Automatic curation of large-scale datasets for audio-visual video representation learning},
  author={Lee, Sangho and Chung, Jiwan and Yu, Youngjae and Kim, Gunhee and Breuel, Thomas and Chechik, Gal and Song, Yale},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10274--10284},
  year={2021}
}
@inproceedings{chen2020vggsound,
  title={Vggsound: A large-scale audio-visual dataset},
  author={Chen, Honglie and Xie, Weidi and Vedaldi, Andrea and Zisserman, Andrew},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={721--725},
  year={2020},
  organization={IEEE}
}
@inproceedings{gemmeke2017audio,
  title={Audio set: An ontology and human-labeled dataset for audio events},
  author={Gemmeke, Jort F and Ellis, Daniel PW and Freedman, Dylan and Jansen, Aren and Lawrence, Wade and Moore, R Channing and Plakal, Manoj and Ritter, Marvin},
  booktitle={2017 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={776--780},
  year={2017},
  organization={IEEE}
}
@inproceedings{arandjelovic2017look,
  title={Look, listen and learn},
  author={Arandjelovic, Relja and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={609--617},
  year={2017}
}
@article{kay2017kinetics,
  title={The kinetics human action video dataset},
  author={Kay, Will and Carreira, Joao and Simonyan, Karen and Zhang, Brian and Hillier, Chloe and Vijayanarasimhan, Sudheendra and Viola, Fabio and Green, Tim and Back, Trevor and Natsev, Paul and others},
  journal={arXiv preprint arXiv:1705.06950},
  year={2017}
}
@inproceedings{dutta2019vgg,
  author = {Dutta, Abhishek and Zisserman, Andrew},
  title = {The {VIA} Annotation Software for Images, Audio and Video},
  booktitle = {Proceedings of the 27th ACM International Conference on Multimedia},
  series = {MM '19},
  year = {2019},
  isbn = {978-1-4503-6889-6/19/10},
  location = {Nice, France},
  numpages = {4},
  url = {https://doi.org/10.1145/3343031.3350535},
  doi = {10.1145/3343031.3350535},
  publisher = {ACM},
  address = {New York, NY, USA},
}
@inproceedings{caba2015activitynet,
  title={Activitynet: A large-scale video benchmark for human activity understanding},
  author={Caba Heilbron, Fabian and Escorcia, Victor and Ghanem, Bernard and Carlos Niebles, Juan},
  booktitle={Proceedings of the ieee conference on computer vision and pattern recognition},
  pages={961--970},
  year={2015}
}
@article{church1990word,
  title={Word association norms, mutual information, and lexicography},
  author={Church, Kenneth and Hanks, Patrick},
  journal={Computational linguistics},
  volume={16},
  number={1},
  pages={22--29},
  year={1990}
}
@ARTICLE{2017arXiv170201460S,
   author = {{Szyma{\'n}ski}, P. and {Kajdanowicz}, T.},
   title = "{A scikit-based Python environment for performing multi-label classification}",
   journal = {ArXiv e-prints},
   archivePrefix = "arXiv",
   eprint = {1702.01460},
   year = 2017,
   month = feb
}
@inproceedings{lin2019bmn,
  title={Bmn: Boundary-matching network for temporal action proposal generation},
  author={Lin, Tianwei and Liu, Xiao and Li, Xin and Ding, Errui and Wen, Shilei},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={3889--3898},
  year={2019}
}
@inproceedings{lin2018bsn,
  title={Bsn: Boundary sensitive network for temporal action proposal generation},
  author={Lin, Tianwei and Zhao, Xu and Su, Haisheng and Wang, Chongjing and Yang, Ming},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={3--19},
  year={2018}
}
@inproceedings{bai2020boundary,
  title={Boundary content graph neural network for temporal action proposal generation},
  author={Bai, Yueran and Wang, Yingying and Tong, Yunhai and Yang, Yang and Liu, Qiyue and Liu, Junhui},
  booktitle={European Conference on Computer Vision},
  pages={121--137},
  year={2020},
  organization={Springer}
}
@inproceedings{xu2020g,
  title={G-tad: Sub-graph localization for temporal action detection},
  author={Xu, Mengmeng and Zhao, Chen and Rojas, David S and Thabet, Ali and Ghanem, Bernard},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10156--10165},
  year={2020}
}
@inproceedings{long2019gaussian,
  title={Gaussian temporal awareness networks for action localization},
  author={Long, Fuchen and Yao, Ting and Qiu, Zhaofan and Tian, Xinmei and Luo, Jiebo and Mei, Tao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={344--353},
  year={2019}
}
@article{yang2020revisiting,
  title={Revisiting anchor mechanisms for temporal action localization},
  author={Yang, Le and Peng, Houwen and Zhang, Dingwen and Fu, Jianlong and Han, Junwei},
  journal={IEEE Transactions on Image Processing},
  volume={29},
  pages={8535--8548},
  year={2020},
  publisher={IEEE}
}
@inproceedings{lin2021learning,
  title={Learning salient boundary feature for anchor-free temporal action localization},
  author={Lin, Chuming and Xu, Chengming and Luo, Donghao and Wang, Yabiao and Tai, Ying and Wang, Chengjie and Li, Jilin and Huang, Feiyue and Fu, Yanwei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3320--3329},
  year={2021}
}
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@inproceedings{tan2021relaxed,
  title={Relaxed transformer decoders for direct action proposal generation},
  author={Tan, Jing and Tang, Jiaqi and Wang, Limin and Wu, Gangshan},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={13526--13535},
  year={2021}
}
@inproceedings{zhang2022actionformer,
  title={Actionformer: Localizing moments of actions with transformers},
  author={Zhang, Chenlin and Wu, Jianxin and Li, Yin},
  booktitle={European Conference on Computer Vision},
  pages={492--510},
  year={2022},
  organization={Springer}
}
@article{liu2022end,
  title={End-to-end temporal action detection with transformer},
  author={Liu, Xiaolong and Wang, Qimeng and Hu, Yao and Tang, Xu and Zhang, Shiwei and Bai, Song and Bai, Xiang},
  journal={IEEE Transactions on Image Processing},
  volume={31},
  pages={5427--5441},
  year={2022},
  publisher={IEEE}
}
@article{mesaros2016metrics,
  title={Metrics for polyphonic sound event detection},
  author={Mesaros, Annamaria and Heittola, Toni and Virtanen, Tuomas},
  journal={Applied Sciences},
  volume={6},
  number={6},
  pages={162},
  year={2016},
  publisher={MDPI}
}
@inproceedings{mesaros2016tut,
  title={TUT database for acoustic scene classification and sound event detection},
  author={Mesaros, Annamaria and Heittola, Toni and Virtanen, Tuomas},
  booktitle={2016 24th European Signal Processing Conference (EUSIPCO)},
  pages={1128--1132},
  year={2016},
  organization={IEEE}
}
@inproceedings{cakir2015polyphonic,
  title={Polyphonic sound event detection using multi label deep neural networks},
  author={Cakir, Emre and Heittola, Toni and Huttunen, Heikki and Virtanen, Tuomas},
  booktitle={2015 international joint conference on neural networks (IJCNN)},
  pages={1--7},
  year={2015},
  organization={IEEE}
}
@inproceedings{parascandolo2016recurrent,
  title={Recurrent neural networks for polyphonic sound event detection in real life recordings},
  author={Parascandolo, Giambattista and Huttunen, Heikki and Virtanen, Tuomas},
  booktitle={2016 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={6440--6444},
  year={2016},
  organization={IEEE}
}
@inproceedings{wu2019dual,
  title={Dual attention matching for audio-visual event localization},
  author={Wu, Yu and Zhu, Linchao and Yan, Yan and Yang, Yi},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={6292--6300},
  year={2019}
}
@inproceedings{xu2020cross,
  title={Cross-modal relation-aware networks for audio-visual event localization},
  author={Xu, Haoming and Zeng, Runhao and Wu, Qingyao and Tan, Mingkui and Gan, Chuang},
  booktitle={Proceedings of the 28th ACM International Conference on Multimedia},
  pages={3893--3901},
  year={2020}
}
@inproceedings{zhou2021positive,
  title={Positive sample propagation along the audio-visual event line},
  author={Zhou, Jinxing and Zheng, Liang and Zhong, Yiran and Hao, Shijie and Wang, Meng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8436--8444},
  year={2021}
}
@inproceedings{xia2022cross,
  title={Cross-Modal Background Suppression for Audio-Visual Event Localization},
  author={Xia, Yan and Zhao, Zhou},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19989--19998},
  year={2022}
}
@inproceedings{hershey2017cnn,
  title={CNN architectures for large-scale audio classification},
  author={Hershey, Shawn and Chaudhuri, Sourish and Ellis, Daniel PW and Gemmeke, Jort F and Jansen, Aren and Moore, R Channing and Plakal, Manoj and Platt, Devin and Saurous, Rif A and Seybold, Bryan and others},
  booktitle={2017 ieee international conference on acoustics, speech and signal processing (icassp)},
  pages={131--135},
  year={2017},
  organization={IEEE}
}
@inproceedings{carreira2017quo,
  title={Quo vadis, action recognition? a new model and the kinetics dataset},
  author={Carreira, Joao and Zisserman, Andrew},
  booktitle={proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6299--6308},
  year={2017}
}
@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}
@inproceedings{carion2020end,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={European conference on computer vision},
  pages={213--229},
  year={2020},
  organization={Springer}
}
@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}
@inproceedings{tirupattur2021modeling,
  title={Modeling multi-label action dependencies for temporal action localization},
  author={Tirupattur, Praveen and Duarte, Kevin and Rawat, Yogesh S and Shah, Mubarak},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1460--1470},
  year={2021}
}
@inproceedings{lin2017focal,
  title={Focal loss for dense object detection},
  author={Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2980--2988},
  year={2017}
}
@inproceedings{rezatofighi2019generalized,
  title={Generalized intersection over union: A metric and a loss for bounding box regression},
  author={Rezatofighi, Hamid and Tsoi, Nathan and Gwak, JunYoung and Sadeghian, Amir and Reid, Ian and Savarese, Silvio},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={658--666},
  year={2019}
}
@inproceedings{bodla2017soft,
  title={Soft-NMS--improving object detection with one line of code},
  author={Bodla, Navaneeth and Singh, Bharat and Chellappa, Rama and Davis, Larry S},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={5561--5569},
  year={2017}
}
@inproceedings{teed2020raft,
  title={Raft: Recurrent all-pairs field transforms for optical flow},
  author={Teed, Zachary and Deng, Jia},
  booktitle={European conference on computer vision},
  pages={402--419},
  year={2020},
  organization={Springer}
}
@inproceedings{qing2021temporal,
  title={Temporal context aggregation network for temporal action proposal refinement},
  author={Qing, Zhiwu and Su, Haisheng and Gan, Weihao and Wang, Dongliang and Wu, Wei and Wang, Xiang and Qiao, Yu and Yan, Junjie and Gao, Changxin and Sang, Nong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={485--494},
  year={2021}
}
@article{kayser2015multisensory,
  title={Multisensory causal inference in the brain},
  author={Kayser, Christoph and Shams, Ladan},
  journal={PLoS biology},
  volume={13},
  number={2},
  pages={e1002075},
  year={2015},
  publisher={Public Library of Science San Francisco, CA USA}
}
@article{spence2007audiovisual,
  title={Audiovisual multisensory integration},
  author={Spence, Charles},
  journal={Acoustical science and technology},
  volume={28},
  number={2},
  pages={61--70},
  year={2007},
  publisher={Acoustical Society of Japan}
}
@article{nagrani2021attention,
  title={Attention bottlenecks for multimodal fusion},
  author={Nagrani, Arsha and Yang, Shan and Arnab, Anurag and Jansen, Aren and Schmid, Cordelia and Sun, Chen},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={14200--14213},
  year={2021}
}
@InProceedings{Chen_2021_CVPR,
    author    = {Chen, Honglie and Xie, Weidi and Afouras, Triantafyllos and Nagrani, Arsha and Vedaldi, Andrea and Zisserman, Andrew},
    title     = {Localizing Visual Sounds the Hard Way},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {16867-16876}
}
@InProceedings{Owens_2018_ECCV,
author = {Owens, Andrew and Efros, Alexei A.},
title = {Audio-Visual Scene Analysis with Self-Supervised Multisensory Features},
booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
month = {September},
year = {2018}
}
@article{liu2022visual,
  title={Visual sound localization in the wild by cross-modal interference erasing},
  author={Liu, Xian and Qian, Rui and Zhou, Hang and Hu, Di and Lin, Weiyao and Liu, Ziwei and Zhou, Bolei and Zhou, Xiaowei},
  journal={arXiv preprint arXiv:2202.06406},
  volume={2},
  year={2022}
}
@inproceedings{zhao2021video,
  title={Video self-stitching graph network for temporal action localization},
  author={Zhao, Chen and Thabet, Ali K and Ghanem, Bernard},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={13658--13667},
  year={2021}
}
@inproceedings{senocak2018learning,
  title={Learning to localize sound source in visual scenes},
  author={Senocak, Arda and Oh, Tae-Hyun and Kim, Junsik and Yang, Ming-Hsuan and Kweon, In So},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4358--4366},
  year={2018}
}
@inproceedings{li2022learning,
  title={Learning to Answer Questions in Dynamic Audio-Visual Scenarios},
  author={Li, Guangyao and Wei, Yake and Tian, Yapeng and Xu, Chenliang and Wen, Ji-Rong and Hu, Di},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19108--19118},
  year={2022}
}
@article{xie2021segformer,
  title={SegFormer: Simple and efficient design for semantic segmentation with transformers},
  author={Xie, Enze and Wang, Wenhai and Yu, Zhiding and Anandkumar, Anima and Alvarez, Jose M and Luo, Ping},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={12077--12090},
  year={2021}
}
@article{idrees2017thumos,
  title={The thumos challenge on action recognition for videos “in the wild”},
  author={Idrees, Haroon and Zamir, Amir R and Jiang, Yu-Gang and Gorban, Alex and Laptev, Ivan and Sukthankar, Rahul and Shah, Mubarak},
  journal={Computer Vision and Image Understanding},
  volume={155},
  pages={1--23},
  year={2017},
  publisher={Elsevier}
}
@article{damen2020rescaling,
  title={Rescaling egocentric vision},
  author={Damen, Dima and Doughty, Hazel and Farinella, Giovanni Maria and Furnari, Antonino and Kazakos, Evangelos and Ma, Jian and Moltisanti, Davide and Munro, Jonathan and Perrett, Toby and Price, Will and others},
  journal={arXiv preprint arXiv:2006.13256},
  year={2020}
}
@article{lin2021exploring,
  title={Exploring cross-video and cross-modality signals for weakly-supervised audio-visual video parsing},
  author={Lin, Yan-Bo and Tseng, Hung-Yu and Lee, Hsin-Ying and Lin, Yen-Yu and Yang, Ming-Hsuan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={11449--11461},
  year={2021}
}
@inproceedings{sigurdsson2016hollywood,
  title={Hollywood in homes: Crowdsourcing data collection for activity understanding},
  author={Sigurdsson, Gunnar A and Varol, G{\"u}l and Wang, Xiaolong and Farhadi, Ali and Laptev, Ivan and Gupta, Abhinav},
  booktitle={Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11--14, 2016, Proceedings, Part I 14},
  pages={510--526},
  year={2016},
  organization={Springer}
}
@inproceedings{kuehne2014language,
  title={The language of actions: Recovering the syntax and semantics of goal-directed human activities},
  author={Kuehne, Hilde and Arslan, Ali and Serre, Thomas},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={780--787},
  year={2014}
}