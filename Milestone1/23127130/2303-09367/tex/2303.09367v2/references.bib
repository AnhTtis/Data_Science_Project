@inproceedings{li2022phasic,
  title={Phasic Self-Imitative Reduction for Sparse-Reward Goal-Conditioned Reinforcement Learning},
  author={Li, Yunfei and Gao, Tian and Yang, Jiaqi and Xu, Huazhe and Wu, Yi},
  booktitle={International Conference on Machine Learning},
  year={2022},
}

@inproceedings{oh2018self,
  title={Self-imitation learning},
  author={Oh, Junhyuk and Guo, Yijie and Singh, Satinder and Lee, Honglak},
  booktitle={International Conference on Machine Learning},
  year={2018},
}

@inproceedings{ferret2021self,
  title={Self-Imitation Advantage Learning},
  author={Ferret, Johan and Pietquin, Olivier and Geist, Matthieu},
  booktitle={International Conference on Autonomous Agents and Multiagent Systems},
  year={2021}
}
@inproceedings{liu2022goal,
  title     = {Goal-Conditioned Reinforcement Learning: Problems and Solutions},
  author    = {Liu, Minghuan and Zhu, Menghui and Zhang, Weinan},
  booktitle = {International Joint Conference on
               Artificial Intelligence},
  year      = {2022}
}

@inproceedings{ghosh2021learning,
    title={Learning to Reach Goals via Iterated Supervised Learning},
    author={Dibya Ghosh and Abhishek Gupta and Ashwin Reddy and Justin Fu and Coline Manon Devin and Benjamin Eysenbach and Sergey Levine},
    booktitle={International Conference on Learning Representations},
    year={2021}
}

@inproceedings{ma2022far,
    title={How Far I'll Go: Offline Goal-Conditioned Reinforcement Learning via f-Advantage Regression},
    author={Yecheng Jason Ma and Jason Yan and Dinesh Jayaraman and Osbert Bastani},
    booktitle={Advances in Neural Information Processing Systems},
    year={2022}
}

@inproceedings{yang2022rethinking,
    title={Rethinking Goal-Conditioned Supervised Learning and Its Connection to Offline {RL}},
    author={Rui Yang and Yiming Lu and Wenzhe Li and Hao Sun and Meng Fang and Yali Du and Xiu Li and Lei Han and Chongjie Zhang},
    booktitle={International Conference on Learning Representations},
    year={2022}
}

@inproceedings{emmons2022rvs,
    title={RvS: What is Essential for Offline {RL} via Supervised Learning?},
    author={Scott Emmons and Benjamin Eysenbach and Ilya Kostrikov and Sergey Levine},
    booktitle={International Conference on Learning Representations},
    year={2022}
}

@inproceedings{andrychowicz2017hindsight,
 author = {Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, Pieter and Zaremba, Wojciech},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Hindsight Experience Replay},
 year = {2017}
}

@misc{sergey2020offline,
    author = {Sergey Levine and Aviral Kumar and George Tucker and Justin Fu},
    title = {Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems},
    year = {2020},
    eprint = {arXiv:2005.01643},
}

@article{seo2019rewards,
  author={Seo, Minah and Vecchietti, Luiz Felipe and Lee, Sangkeum and Har, Dongsoo},
  journal={IEEE Access}, 
  title={Rewards Prediction-Based Credit Assignment for Reinforcement Learning With Sparse Binary Rewards}, 
  year={2019},
  volume={7},
  number={},
  pages={118776-118791}
}

@inproceedings{kumar2020conservative,
 author = {Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Conservative Q-Learning for Offline Reinforcement Learning},
 year = {2020}
}

@inproceedings{fujimoto2021minimalist,
    title={A Minimalist Approach to Offline Reinforcement Learning},
    author={Scott Fujimoto and Shixiang Gu},
    booktitle={Advances in Neural Information Processing Systems},
    year={2021}
}

@inproceedings{chebotar2021actionable,
    title={Actionable models: Unsupervised offline reinforcement learning of robotic skills},
    author={Yevgen Chebotar and Karol Hausman and Yao Lu and Ted Xiao and Dmitry Kalashnikov and Jake Varley and Alex Irpan and Benjamin Eysenbach and Ryan Julian and Chelsea Finn and Sergey Levine},
    booktitle={International Conference on Machine Learning},
    year={2021}
}

@misc{peng19advantage,
	author = {Xue Bin Peng and Aviral Kumar and Grace Zhang and Sergey Levine},
	title = {Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning},
	eprint = {arXiv:1910.00177},
	year = {2019}
}


@inproceedings{wang2018exponentially,
    author = {Wang, Qing and Xiong, Jiechao and Han, Lei and sun, peng and Liu, Han and Zhang, Tong},
    booktitle = {Advances in Neural Information Processing Systems},
    title = {Exponentially Weighted Imitation Learning for Batched Historical Data},
    year = {2018}
}

@inproceedings{eysenbach2022contrastive,
    title={Contrastive Learning as Goal-Conditioned Reinforcement Learning},
    author={Benjamin Eysenbach and Tianjun Zhang and Sergey Levine and Ruslan Salakhutdinov},
    booktitle={Advances in Neural Information Processing Systems},
    year={2022},
}

@inproceedings{chane2021goal,
    title={Goal-conditioned reinforcement learning with imagined subgoals},
    author={Chane-Sane, Elliot and Schmid, Cordelia and Laptev, Ivan},
    booktitle={International Conference on Machine Learning},
    year={2021},
}

@inproceedings{nair2018visual,
    author = {Nair, Ashvin V and Pong, Vitchyr and Dalal, Murtaza and Bahl, Shikhar and Lin, Steven and Levine, Sergey},
    booktitle = {Advances in Neural Information Processing Systems},
    title = {Visual Reinforcement Learning with Imagined Goals},
    year = {2018}
}

@inproceedings{nasiriany2019planning,
    author = {Nasiriany, Soroush and Pong, Vitchyr and Lin, Steven and Levine, Sergey},
    booktitle = {Advances in Neural Information Processing Systems},
    title = {Planning with Goal-Conditioned Policies},
    year = {2019}
}

@misc{li2022hierarchical,
  title={Hierarchical Planning Through Goal-Conditioned Offline Reinforcement Learning},
  author={Li, Jinning and Tang, Chen and Tomizuka, Masayoshi and Zhan, Wei},
  eprint={arXiv:2205.11790},
  year={2022}
}

@inproceedings{mannor2004dynamic, 
    author = {Mannor, Shie and Menache, Ishai and Hoze, Amit and Klein, Uri}, 
    title = {Dynamic Abstraction in Reinforcement Learning via Clustering}, 
    year = {2004}, 
    booktitle = {International Conference on Machine Learning}
}

@inproceedings{ghosh2018divide,
    title={Divide-and-Conquer Reinforcement Learning},
    author={Dibya Ghosh and Avi Singh and Aravind Rajeswaran and Vikash Kumar and Sergey Levine},
    booktitle={International Conference on Learning Representations},
    year={2018}
}

@article{karimpanal2017identification,
  author    = {Thommen George Karimpanal and
               Erik Wilhelm},
  title     = {Identification and off-policy learning of multiple objectives using
               adaptive clustering},
  journal   = {Neurocomputing},
  volume    = {263},
  pages     = {39--47},
  year      = {2017},
}

@inproceedings{wei2018learning,
  author={Wei, Haoran and Corder, Kevin and Decker, Keith},
  booktitle={International Conference on Machine Learning and Applications}, 
  title={Q-Learning Acceleration via State-Space Partitioning}, 
  year={2018},
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@misc{plappert2018multi,
  Author = {Matthias Plappert and Marcin Andrychowicz and Alex Ray and Bob McGrew and Bowen Baker and Glenn Powell and Jonas Schneider and Josh Tobin and Maciek Chociej and Peter Welinder and Vikash Kumar and Wojciech Zaremba},
  Title = {Multi-Goal Reinforcement Learning: Challenging Robotics Environments and Request for Research},
  Year = {2018},
  eprint = {arXiv:1802.09464},
}

@misc{fu2020d4rl,
    title={D4RL: Datasets for Deep Data-Driven Reinforcement Learning},
    author={Justin Fu and Aviral Kumar and Ofir Nachum and George Tucker and Sergey Levine},
    year={2020},
    eprint={arXiv:2004.07219},
}

@inproceedings{kaelbling1993learning,
  title={Learning to achieve goals},
  author={Kaelbling, Leslie Pack},
  booktitle = {International Joint Conference on Artificial Intelligence},
  year={1993}
}

@misc{ma2020clustered,
    title={Clustered Reinforcement Learning},
    author={Xiao Ma and Shen-Yi Zhao and Zhao-Heng Yin and Wu-Jun Li},
    year={2020},
    eprint={arXiv:1906.02457}
}

@inproceedings{schaul2015universal,
    title = 	 {Universal Value Function Approximators},
    author = 	 {Schaul, Tom and Horgan, Daniel and Gregor, Karol and Silver, David},
    booktitle = 	 {International Conference on Machine Learning},
    year = 	 {2015},
}


@book{sutton2018reinforcement,
    author = {Sutton, Richard S. and Barto, Andrew G.},
    title = {Reinforcement Learning: An Introduction},
    year = {2018},
    publisher = {MIT press},
    address = {Cambridge, MA, USA},
}

@inproceedings{ding2019goal,
    author = {Ding, Yiming and Florensa, Carlos and Abbeel, Pieter and Phielipp, Mariano},
    booktitle = {Advances in Neural Information Processing Systems},
    title = {Goal-conditioned Imitation Learning},
    year = {2019}
}

@inproceedings{mandlekar2020iris,
    title={Iris: Implicit reinforcement without interaction at scale for learning control from offline robot manipulation data},
    author={Mandlekar, Ajay and Ramos, Fabio and Boots, Byron and Savarese, Silvio and Fei-Fei, Li and Garg, Animesh and Fox, Dieter},
    booktitle={International Conference on Robotics and Automation},
    year={2020},
}

@inproceedings{charlesworth2020plangan,
    author = {Charlesworth, Henry and Montana, Giovanni},
    booktitle = {Advances in Neural Information Processing Systems},
    title = {PlanGAN: Model-based Planning With Sparse Rewards and Multiple Goals},
    year = {2020}
}

@inproceedings{yang2021mher,
    title={{MHER}: Model-based Hindsight Experience Replay},
    author={Rui Yang and Meng Fang and Lei Han and Yali Du and Feng Luo and Xiu Li},
    booktitle={Deep RL Workshop NeurIPS 2021},
    year={2021},
}

@inproceedings{fang2019curriculum,
    author = {Fang, Meng and Zhou, Tianyi and Du, Yali and Han, Lei and Zhang, Zhengyou},
    booktitle = {Advances in Neural Information Processing Systems},
    title = {Curriculum-guided Hindsight Experience Replay},
    year = {2019}
}

@inproceedings{kim2021landmarkguided,
    title={Landmark-Guided Subgoal Generation in Hierarchical Reinforcement Learning},
    author={Junsu Kim and Younggyo Seo and Jinwoo Shin},
    booktitle={Advances in Neural Information Processing Systems},
    year={2021},
}

@inproceedings{zhang2021worldmodel,
    title={World model as a graph: Learning latent landmarks for planning},
    author={Zhang, Lunjun and Yang, Ge and Stadie, Bradly C},
    booktitle={International Conference on Machine Learning},
    year={2021},
}

@article{raffin2021stablebaselines,
  author  = {Antonin Raffin and Ashley Hill and Adam Gleave and Anssi Kanervisto and Maximilian Ernestus and Noah Dormann},
  title   = {Stable-Baselines3: Reliable Reinforcement Learning Implementations},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
  volume  = {22},
  number  = {268},
  pages   = {1-8},
  url     = {http://jmlr.org/papers/v22/20-1364.html}
}

@inproceedings{durugkar2021adversarial,
    title={Adversarial intrinsic motivation for reinforcement learning},
    author={Durugkar, Ishan and Tec, Mauricio and Niekum, Scott and Stone, Peter},
    booktitle={Advances in Neural Information Processing Systems},
    year={2021}
}

@inproceedings{ho2016generative,
    author = {Ho, Jonathan and Ermon, Stefano},
    booktitle = {Advances in Neural Information Processing Systems},
    title = {Generative Adversarial Imitation Learning},
    year = {2016}
}

@inproceedings{bain1995framework,
    title={A Framework for Behavioural Cloning.},
    author={Bain, Michael and Sammut, Claude},
    booktitle={Machine Intelligence 15},
    pages={103--129},
    year={1995}
}

@inproceedings{mezghani2022learning,
    title={Learning Goal-Conditioned Policies Offline with Self-Supervised Reward Shaping},
    author={Lina Mezghani and Sainbayar Sukhbaatar and Piotr Bojanowski and Alessandro Lazaric and Karteek Alahari},
    booktitle={Conference on Robot Learning},
    year={2022},
}

@misc{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  eprint={arXiv: 1412.6980},
  year={2014}
}

@misc{schroecker2020universal,
  title={Universal value density estimation for imitation learning and goal-conditioned reinforcement learning},
  author={Schroecker, Yannick and Isbell, Charles},
  eprint={arXiv: 2002.06473},
  year={2020}
}

@inproceedings{lillicrap2016continuous,
  title={Continuous control with deep reinforcement learning},
  author={Timothy P. Lillicrap and Jonathan J. Hunt and Alexander Pritzel and Nicolas Manfred Otto Heess and Tom Erez and Yuval Tassa and David Silver and Daan Wierstra},
  booktitle={International Conference on Learning Representations},
  year={2016},
}

@inproceedings{fujimoto2019off,
  title={Off-Policy Deep Reinforcement Learning without Exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle={International Conference on Machine Learning},
  year={2019}
}

@inproceedings{fujimoto2018addressing,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and Hoof, Herke and Meger, David},
  booktitle={International Conference on Machine Learning},
  year={2018}
}

@inproceedings{jurgenson2020sub,
  title = {Sub-Goal Trees a Framework for Goal-Based Reinforcement Learning},
  author = {Jurgenson, Tom and Avner, Or and Groshev, Edward and Tamar, Aviv},
  booktitle = {International Conference on Machine Learning},
  year = 	 {2020},
}

@misc{dhiman2018floyd,
  author = {Dhiman, Vikas and Banerjee, Shurjo and Siskind, Jeffrey M. and Corso, Jason J.},
  title = {Floyd-Warshall Reinforcement Learning: Learning from Past Experiences to Reach New Goals},
  year = {2018},
  eprint={arXiv: 1809.09318},
}
