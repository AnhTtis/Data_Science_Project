

\begin{table*}
\caption{Datasets and related descriptions for the autonomous driving dataset.}
\label{tab:dataset}
\centering
\begin{tabular}{cccc} 
\hline
\rowcolor[rgb]{0.937,0.937,0.937} Dataset & Year & Sensors                                       & Scenarios                        \\ 
\hline
KITTI \cite{kitti}                                     & 2013 & 4 cameras; 1 LiDAR                            & City; Countryside; Highway       \\
Comma.ai \cite{commonai}                                  & 2016 & 1 monocular camera; 1 point grey
  camera     & Highway scenarios                \\
Oxford
  RobotCar \cite{oxfod}                         & 2016 & 6 Cameras; 3 LiDARS; Speed; GPS; INS                 & City; Contain weather changed    \\
Mapillary
  Vistas \cite{mapillary}                        & 2017 & Image devices                                 & Street Scenarios                  \\
nuScenes \cite{nuscenes}                                  & 2019 & 6 Cameras; 5 Radars; 1 LiDAR                  & Street Scenarios                  \\
ApolloScape \cite{apolloscape}                               & 2019 & 2 Cameras; 2 LiDAR; GPS; IMU                  & Street Scenarios                  \\
Waymo
  Open Dataset \cite{waymo}                      & 2019 & 5 Cameras; 5LiDAR;~                           & 1150 Street Scenarios            \\
BDD100K \cite{BDD}                                   & 2020 & 1 Camera; GPS; IMU                            & Street scenarios in 4 cities     \\
A2D2 \cite{A2D2}                                      & 2020 & 6 Cameras; 5 LiDAR; GPS; IMU                    & 360° Street Scenarios             \\
Automine \cite{Automine}                                  & 2021 & 2 Cameras; 1 LiDAR; GPS; IMU                    & The first open-pit mine dataset  \\
AI4MARS \cite{Mars}                                  & 2021 & 2 Cameras                                  & The first large-scale dataset in Mars  \\

SODA10M \cite{huawei}                                  & 2021 & 1 Camera                                  & City Scenarios in 31 cities with all kinds of weathers   \\

SUPS \cite{SUPS}                                      & 2022 & 6 Cameras; 1 LiDAR; GPS; IMU                   & Underground parking scenarios    \\
DRIVERTRUTH \cite{drivetruth}                               & 2022 & 1 Camera; 1 LiDAR; GPS; IMU;
  Control signal & City Scenarios based-on CARLA    \\

ROAD \cite{PAMI}                                      & 2023 & 1 Camera             & Scenarios in \cite{oxfod} for road event detection    \\
\hline
\end{tabular}
\end{table*}

\section{EXPERIMENT PLATFORM \label{experiments}}
Testing IVs in real systems often comes with potentially fatal safety risks. Therefore, algorithms in autonomous driving are often evaluated in artificial systems with the utilization of open-source datasets and simulation platforms \cite{OpenCDA}.

\subsection{Dataset}
The end-to-end method leverages widely available large-scale datasets of human driving to be trained to approximate human standards. Consequently, the training process requires a large amount of data from driving scenarios. The magnitude, abundance, and distribution of the dataset directly affect the safety, robustness, and generalization of the trained model \cite{TVT9}. Though constructing and assembling novel datasets for IVs is time-consuming, numerous generic and influential datasets are available for research, such as Comma.ai \cite{commonai}, Bdd100K \cite{BDD}, A2D2 \cite{A2D2}, Automine \cite{Automine}, DriverTruth \cite{drivetruth} and Sups \cite{SUPS}, most of the famous dataset is shown in Table. \ref{tab:dataset}.

KITTI \cite{kitti} is a pioneer in this field and also the most famous autonomous driving dataset. Thanks to its good task scaling, KITTI now covers a wide range of basking perception tasks, such as object detection, sceneflow, depth estimation, tracking and so on.

Comma.ai \cite{commonai} enriches the diversity of data by additionally collecting localization information and control signals, so it can be implemented for more tasks, for example, localization and planning.

BDD100K \cite{BDD} and SODA10M \cite{huawei} alleviate diversity and volume problems by constructing large-scale simulation scenarios, both of them collect several urban scenarios under various weather conditions in more than 31 cities, they also come with a rich set of labels: scene tagging, object bounding box, lane marking, drivable area, full-frame semantic and instance segmentation, multiple object tracking, and multiple objects tracking.

A2D2 \cite{A2D2} is a commercial-grade dataset that is well-suited for diverse perception tasks, bridging the gap between public datasets which are deficient in comprehensive vehicular information. Compared with previous datasets, it provides a 360° point cloud perception field by 5 LiDARs to enable full scene perception for autonomous driving.


The following dataset provides traffic scenarios that are distinct from structured scenarios. Automine \cite{Automine} constructs the pioneering open-pit mine dataset for IVs, comprising 18 hours of transportation videos and localization information gathered from 6 open-pit mines.  The distinctive features of open-pit mines, such as uneven and rough terrain, intense light, and copious dust, pose significant challenges. The Automine serves as a valuable resource to address the gaps in the open-pit mine dataset, and supports the advancement of autonomous mining technology. AI4MARS \cite{Mars} proposes another interesting large-scale dataset, which consists of 35,000 semantic segmentation full images of the surface of Mars.

Currently, datasets cover almost all tasks of autonomous driving and play  an increasingly vital role in  facilitating the training and validation of  intelligent vehicle algorithms. These supports establish the requisite groundwork to implement autonomous driving.

\subsection{Simulation Platform}
Testing autonomous driving algorithms in real-world scenarios is often accompanied by significant potential risks, simulation testing shows a smart method to validate algorithms that can speed up testing due to its low cost and high safety.

%so simulation testing is a major form of intelligent vehicle testing by constructing an autonomous driving scenario through sensor simulation, vehicle dynamics modeling, advanced graphics processing, traffic flow simulation, digital modeling, and scenario modeling to build a relatively realistic driving scenario.

Many autonomous driving simulation platforms have been developed with open-source code and protocols, which are available for the testing of algorithms in autonomous driving. SUMO \cite{SUMO}, an open-source and microscopic traffic simulation platform, developed by the German Aerospace Center, offers a powerful validation platform for large-scale transportation algorithms. It is equipped with a well-designed interface that supports a broad range of data formats. Owing to its superior features, SUMO has been one of the earliest and most extensively utilized simulators. Moreover, Apollo \cite{apolloscape} and Autoware \cite{autoware} not only provide a simulation platform for validating algorithms but also equip open-source algorithms for each task, providing developers with a complete development-validation-deployment chain.

In the context of the ego-vehicle autonomous driving method, CARLA \cite{carla} offers a suitable answer. It is an open-source simulator for urban autonomous driving scenarios, which facilitates the development, training, and validation of the underlying urban autonomous driving system.

In the field of the multi-vehicle interaction method, TORCS \cite{torcs}  provides an open racing car simulator with over 50 diverse vehicle models and more than 20 racing tracks. Furthermore, it has the ability to race against 50 vehicles simultaneously, making it a valuable tool for research in this field. MetaDrive \cite{metadrive} proposes an open-source platform to support the research of generalizable reinforcement learning algorithms for machine autonomy. It is highly compositional and capable of generating an infinite number of diverse driving scenarios through both procedural generation and real data importing. The other simulation platforms and their related descriptions are shown in Table. \ref{tab:simulator}.

% \usepackage{colortbl}
% \begin{tabular}{m{2.25cm} c m{2cm}  m{2.5cm}  m{2.4cm} m{4cm} m{2cm}}

%\rowcolor[rgb]{0.937,0.937,0.937} \multicolumn{1}{c}{\textbf{Article}} & \textbf{Category} & \multicolumn{1}{c}{\textbf{Input}}      & \multicolumn{1}{c}{\textbf{Output}} & \multicolumn{1}{c}{\textbf{Implement Tasks}} & \multicolumn{1}{c}{\textbf{Auxiliary Method}}                                              & \multicolumn{1}{c}{\textbf{\textbf{Dataset}}}  

\begin{table*}
\caption{Simulation platforms and related descriptions for autonomous driving based on visual perception.}
\label{tab:simulator}
\centering
\begin{tabular}{cc m{12cm}} 
\hline
\rowcolor[rgb]{0.937,0.937,0.937} \textbf{Platform} & \textbf{Latest Version} & \multicolumn{1}{c}{\textbf{Description}}                                                                                                                        \\ 
\hline
PTV 
  Vissim                                        & V2023                   & Traffic simulation platform
  focused on complex intersection design and active traffic management.                                                             \\
VTD                                                 & V2.2 (19.01)            & Provides a complete bottom-up
  simulation platform, including ADAS and automation systems.                                                                     \\
SUMO \cite{SUMO}                               & V1.15.0 (22.11)           & Provides a purely microscopic traffic model that can be defined to customize each vehicle.                              \\
TORCS                                               & V1.3.8 (17.03)          & Support for running a large
  number of agents at the same time, allowing for scheduling functions in dense
  vehicle areas.                                    \\
SVL
  Simulator \cite{SVL}                                     & V2021.3 (21.05)         & Enables developers to simulate
  billions of miles and arbitrary corner cases to accelerate algorithm
  development and system integration.                     \\
V-Rep                                               & V3.6.2 (19.01)          & With a driving actions
  assessment function, which indicates the agent behavior based on the result.                                                          \\
CarMaker                                             & V10.0 (21.10)           & Specifically designed for the
  development and seamless testing of cars and light-duty vehicles in all
  development stages.                                   \\
CARLA \cite{carla}                                               & V0.9.13 (21.11)         & Various city maps are provided
  for autonomous driving algorithms, as well as support for customized sensor
  types and weather conditions.                    \\
AriSim \cite{airsim}                                              & V1.8.1 (22.06)          & The capability to quickly
  complete autonomous driving tests, and build various scenarios (urban,
  countryside, highway, field, etc.)                      \\

Apollo \cite{apolloscape}                                             & V8.0 (22.12)            & Support for learning and
  validation of single and multi-vehicle autonomous driving algorithms on urban
  scenarios.                                           \\
Autoware \cite{autoware}                                            & V1.11.0 (21.05)         & An open-source autonomous
  driving platform, which include all component of autonomous function for
  intelligent vehicle.                                     \\
Drive
  Constellation                               & V6.05 (22.10)           & Provides a computing platform
  based on two different servers that can undertake large-scale vehicle data
  interaction services.                              \\
MetaDrive \cite{metadrive}                                           & V0.2.6.0 (22.11)        & A wide range of road segments
  are available, which can be customized to generate a variety of complex
  scenarios, more suitable for reinforcement learning.  \\
\hline
\end{tabular}
\end{table*}

\subsection{Physical Platform}

With the increase in computer computing capabilities, simulation testing has become increasingly capable of meeting the testing requirements for various scenarios and has proven effective in solving the long-tail problem associated with such systems. However, pre-trained models used in a simulator typically require fine-tuning prior to implementation in the real world.  Moreover, while simulation testing can cover a wide range of scenarios, it can't account for all corner cases. Consequently, a professional and safe semi-open autonomous driving validation site is essential [\cite{LiComp}.

Autonomous driving technology achieved significant development over the past few decades, and several countries adopt policies permitting the testing of robotic taxis on public roads.  In the United States, Waymo is now permitted to test robotaxis on the streets of San Francisco from 2022. Nuro recently begins to deploy autonomous delivery vehicles in Arizona, California, and Texas. In England, Aurrigo is conducting a trial of an autonomous shuttle at Birmingham airport. Wayve is authorized to test autonomous vehicles over long distances between five cities. In China, the commercialization of autonomous driving is rapidly progressing, with companies such as Apollo, Pony, and Momenta already implementing IVs in several cities. Additionally, Waytous is working on unmanned transport in unstructured and closed scenarios and has already provided driverless solutions for several open-pit mines.