% ANIMATION
% ROBUST LOCOMOTION

@article{kim2019highly,
  title={Highly dynamic quadruped locomotion via whole-body impulse control and model predictive control},
  author={Kim, Donghyun and Di Carlo, Jared and Katz, Benjamin and Bledt, Gerardo and Kim, Sangbae},
  journal={arXiv preprint arXiv:1909.06586},
  year={2019}
}


@inproceedings{bledt2018cheetah,
  title={Mit cheetah 3: Design and control of a robust, dynamic quadruped robot},
  author={Bledt, Gerardo and Powell, Matthew J and Katz, Benjamin and Di Carlo, Jared and Wensing, Patrick M and Kim, Sangbae},
  booktitle={2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={2245--2252},
  year={2018},
  organization={IEEE}
}

@article{park2017high,
  title={High-speed bounding with the MIT Cheetah 2: Control design and experiments},
  author={Park, Hae-Won and Wensing, Patrick M and Kim, Sangbae},
  journal={The International Journal of Robotics Research},
  volume={36},
  number={2},
  pages={167--192},
  year={2017},
  publisher={SAGE Publications Sage UK: London, England}
}

@book{raibert1986legged,
  title={Legged robots that balance},
  author={Raibert, Marc H},
  year={1986},
  publisher={MIT press}
}

@article{haarnoja2018learning,
  title={Learning to walk via deep reinforcement learning},
  author={Haarnoja, Tuomas and Ha, Sehoon and Zhou, Aurick and Tan, Jie and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:1812.11103},
  year={2018}
}


@article{lee2020learning,
  title={Learning quadrupedal locomotion over challenging terrain},
  author={Lee, Joonho and Hwangbo, Jemin and Wellhausen, Lorenz and Koltun, Vladlen and Hutter, Marco},
  journal={Science robotics},
  volume={5},
  number={47},
  pages={eabc5986},
  year={2020},
  publisher={American Association for the Advancement of Science}
}

@article{hwangbo2019learning,
  title={Learning agile and dynamic motor skills for legged robots},
  author={Hwangbo, Jemin and Lee, Joonho and Dosovitskiy, Alexey and Bellicoso, Dario and Tsounis, Vassilios and Koltun, Vladlen and Hutter, Marco},
  journal={Science Robotics},
  volume={4},
  number={26},
  pages={eaau5872},
  year={2019},
  publisher={American Association for the Advancement of Science}
}

@article{miki2022learning,
  title={Learning robust perceptive locomotion for quadrupedal robots in the wild},
  author={Miki, Takahiro and Lee, Joonho and Hwangbo, Jemin and Wellhausen, Lorenz and Koltun, Vladlen and Hutter, Marco},
  journal={Science Robotics},
  volume={7},
  number={62},
  pages={eabk2822},
  year={2022},
  publisher={American Association for the Advancement of Science}
}

@article{kumar2021rma,
  title={Rma: Rapid motor adaptation for legged robots},
  author={Kumar, Ashish and Fu, Zipeng and Pathak, Deepak and Malik, Jitendra},
  journal={arXiv preprint arXiv:2107.04034},
  year={2021}
}

@inproceedings{rudin2022learning,
  title={Learning to walk in minutes using massively parallel deep reinforcement learning},
  author={Rudin, Nikita and Hoeller, David and Reist, Philipp and Hutter, Marco},
  booktitle={Conference on Robot Learning},
  pages={91--100},
  year={2022},
  organization={PMLR}
}

@article{margolis2022rapid,
  title={Rapid locomotion via reinforcement learning},
  author={Margolis, Gabriel B and Yang, Ge and Paigwar, Kartik and Chen, Tao and Agrawal, Pulkit},
  journal={arXiv preprint arXiv:2205.02824},
  year={2022}
}

@article{zhang2018mode,
  title={Mode-adaptive neural networks for quadruped motion control},
  author={Zhang, He and Starke, Sebastian and Komura, Taku and Saito, Jun},
  journal={ACM Transactions on Graphics (TOG)},
  volume={37},
  number={4},
  pages={1--11},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@article{peng2020learning,
  title={Learning agile robotic locomotion skills by imitating animals},
  author={Peng, Xue Bin and Coumans, Erwin and Zhang, Tingnan and Lee, Tsang-Wei and Tan, Jie and Levine, Sergey},
  journal={arXiv preprint arXiv:2004.00784},
  year={2020}
}

@inproceedings{gleicher1998retargetting,
  title={Retargetting motion to new characters},
  author={Gleicher, Michael},
  booktitle={Proceedings of the 25th annual conference on Computer graphics and interactive techniques},
  pages={33--42},
  year={1998}
}

@article{won2020,
author = {Won, Jungdam and Gopinath, Deepak and Hodgins, Jessica},
title = {A Scalable Approach to Control Diverse Behaviors for Physically Simulated Characters},
year = {2020},
issue_date = {August 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3386569.3392381},
doi = {10.1145/3386569.3392381},
abstract = {Human characters with a broad range of natural looking and physically realistic behaviors will enable the construction of compelling interactive experiences. In this paper, we develop a technique for learning controllers for a large set of heterogeneous behaviors. By dividing a reference library of motion into clusters of like motions, we are able to construct experts, learned controllers that can reproduce a simulated version of the motions in that cluster. These experts are then combined via a second learning phase, into a general controller with the capability to reproduce any motion in the reference library. We demonstrate the power of this approach by learning the motions produced by a motion graph constructed from eight hours of motion capture data and containing a diverse set of behaviors such as dancing (ballroom and breakdancing), Karate moves, gesturing, walking, and running.},
journal = {ACM Trans. Graph.},
month = {aug},
articleno = {33},
numpages = {12},
keywords = {neural network, reinforcement learning, locomotion control, deep learning, character animation, physics-based simulation and control}
}

@article{deepmimic,
author = {Peng, Xue Bin and Abbeel, Pieter and Levine, Sergey and van de Panne, Michiel},
title = {DeepMimic: Example-Guided Deep Reinforcement Learning of Physics-Based Character Skills},
year = {2018},
issue_date = {August 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {37},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3197517.3201311},
doi = {10.1145/3197517.3201311},
abstract = {A longstanding goal in character animation is to combine data-driven specification of behavior with a system that can execute a similar behavior in a physical simulation, thus enabling realistic responses to perturbations and environmental variation. We show that well-known reinforcement learning (RL) methods can be adapted to learn robust control policies capable of imitating a broad range of example motion clips, while also learning complex recoveries, adapting to changes in morphology, and accomplishing user-specified goals. Our method handles keyframed motions, highly-dynamic actions such as motion-captured flips and spins, and retargeted motions. By combining a motion-imitation objective with a task objective, we can train characters that react intelligently in interactive settings, e.g., by walking in a desired direction or throwing a ball at a user-specified target. This approach thus combines the convenience and motion quality of using motion clips to define the desired style and appearance, with the flexibility and generality afforded by RL methods and physics-based animation. We further explore a number of methods for integrating multiple clips into the learning process to develop multi-skilled agents capable of performing a rich repertoire of diverse skills. We demonstrate results using multiple characters (human, Atlas robot, bipedal dinosaur, dragon) and a large variety of skills, including locomotion, acrobatics, and martial arts.},
journal = {ACM Trans. Graph.},
month = {jul},
articleno = {143},
numpages = {14},
keywords = {physics-based character animation, motion control, reinforcement learning}
}

@article{peng2021amp,
  title={Amp: Adversarial motion priors for stylized physics-based character control},
  author={Peng, Xue Bin and Ma, Ze and Abbeel, Pieter and Levine, Sergey and Kanazawa, Angjoo},
  journal={ACM Transactions on Graphics (TOG)},
  volume={40},
  number={4},
  pages={1--20},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{peng2022ase,
  title={Ase: Large-scale reusable adversarial skill embeddings for physically simulated characters},
  author={Peng, Xue Bin and Guo, Yunrong and Halper, Lina and Levine, Sergey and Fidler, Sanja},
  journal={ACM Transactions On Graphics (TOG)},
  volume={41},
  number={4},
  pages={1--17},
  year={2022},
  publisher={ACM New York, NY, USA}
}

@article{won2021control,
  title={Control strategies for physically simulated characters performing two-player competitive sports},
  author={Won, Jungdam and Gopinath, Deepak and Hodgins, Jessica},
  journal={ACM Transactions on Graphics (TOG)},
  volume={40},
  number={4},
  pages={1--11},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@misc{a1,
    title={A1 by Unitree Robotics},
    author={Unitree},
    howpublished={https://www.unitree.com/products/a1},
    journal={A1}
} 

@inproceedings{escontrela2022adversarial,
  title={Adversarial motion priors make good substitutes for complex reward functions},
  author={Escontrela, Alejandro and Peng, Xue Bin and Yu, Wenhao and Zhang, Tingnan and Iscen, Atil and Goldberg, Ken and Abbeel, Pieter},
  booktitle={2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={25--32},
  year={2022},
  organization={IEEE}
}

@article{kim2022human,
  title={Human Motion Control of Quadrupedal Robots using Deep Reinforcement Learning},
  author={Kim, Sunwoo and Sorokin, Maks and Lee, Jehee and Ha, Sehoon},
  journal={arXiv preprint arXiv:2204.13336},
  year={2022}
}

@article{li2021fastmimic,
  title={FastMimic: Model-based Motion Imitation for Agile, Diverse and Generalizable Quadrupedal Locomotion},
  author={Li, Tianyu and Won, Jungdam and Ha, Sehoon and Rai, Akshara},
  journal={arXiv preprint arXiv:2109.13362},
  year={2021}
}

@article{Yang_2020,
	doi = {10.1126/scirobotics.abb2174},
  
	url = {https://doi.org/10.1126%2Fscirobotics.abb2174},
  
	year = 2020,
	month = {dec},
  
	publisher = {American Association for the Advancement of Science ({AAAS})},
  
	volume = {5},
  
	number = {49},
  
	author = {Chuanyu Yang and Kai Yuan and Qiuguo Zhu and Wanming Yu and Zhibin Li},
  
	title = {Multi-expert learning of adaptive legged locomotion},
  
	journal = {Science Robotics}
}

@article{heess2019,
  author    = {Nicolas Heess and
               Dhruva TB and
               Srinivasan Sriram and
               Jay Lemmon and
               Josh Merel and
               Greg Wayne and
               Yuval Tassa and
               Tom Erez and
               Ziyu Wang and
               S. M. Ali Eslami and
               Martin A. Riedmiller and
               David Silver},
  title     = {Emergence of Locomotion Behaviours in Rich Environments},
  journal   = {CoRR},
  volume    = {abs/1707.02286},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.02286},
  eprinttype = {arXiv},
  eprint    = {1707.02286},
  timestamp = {Mon, 22 Jul 2019 16:19:02 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/HeessTSLMWTEWER17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{raisim,
  title={Per-contact iteration method for solving contact dynamics},
  author={Hwangbo, Jemin and Lee, Joonho and Hutter, Marco},
  journal={IEEE Robotics and Automation Letters},
  url="www.raisim.com",
  volume={3},
  number={2},
  pages={895--902},
  year={2018},
  publisher={IEEE}
}

@misc{unitree,
title={Unitree robotics},
note={http://www.unitree.cc/}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{kumar2022cascaded,
  title={Cascaded Compositional Residual Learning for Complex Interactive Behaviors},
  author={Kumar, K Niranjan and Essa, Irfan and Ha, Sehoon},
  journal={arXiv preprint arXiv:2212.08954},
  year={2022}
}

@article{wijmans2019dd,
  title={Dd-ppo: Learning near-perfect pointgoal navigators from 2.5 billion frames},
  author={Wijmans, Erik and Kadian, Abhishek and Morcos, Ari and Lee, Stefan and Essa, Irfan and Parikh, Devi and Savva, Manolis and Batra, Dhruv},
  journal={arXiv preprint arXiv:1911.00357},
  year={2019}
}

@article{winkler2018gait,
  title={Gait and trajectory optimization for legged systems through phase-based end-effector parameterization},
  author={Winkler, Alexander W and Bellicoso, C Dario and Hutter, Marco and Buchli, Jonas},
  journal={IEEE Robotics and Automation Letters},
  volume={3},
  number={3},
  pages={1560--1567},
  year={2018},
  publisher={IEEE}
}

@article{Ji_2022,
	doi = {10.1109/lra.2022.3151396},
  
	url = {https://doi.org/10.1109%2Flra.2022.3151396},
  
	year = 2022,
	month = {apr},
  
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  
	volume = {7},
  
	number = {2},
  
	pages = {4630--4637},
  
	author = {Gwanghyeon Ji and Juhyeok Mun and Hyeongjun Kim and Jemin Hwangbo},
  
	title = {Concurrent Training of a Control Policy and a State Estimator for Dynamic and Robust Legged Locomotion},
  
	journal = {{IEEE} Robotics and Automation Letters}
}