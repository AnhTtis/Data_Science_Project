@INPROCEEDINGS {9710580,
author = {Z. Liu and Y. Lin and Y. Cao and H. Hu and Y. Wei and Z. Zhang and S. Lin and B. Guo},
booktitle = {2021 IEEE/CVF International Conference on Computer Vision (ICCV)},
title = {Swin Transformer: Hierarchical Vision Transformer using Shifted Windows},
year = {2021},
volume = {},
issn = {},
pages = {9992-10002},
abstract = {This paper presents a new vision Transformer, called Swin Transformer, that capably serves as a general-purpose backbone for computer vision. Challenges in adapting Transformer from language to vision arise from differences between the two domains, such as large variations in the scale of visual entities and the high resolution of pixels in images compared to words in text. To address these differences, we propose a hierarchical Transformer whose representation is computed with Shifted windows. The shifted windowing scheme brings greater efficiency by limiting self-attention computation to non-overlapping local windows while also allowing for cross-window connection. This hierarchical architecture has the flexibility to model at various scales and has linear computational complexity with respect to image size. These qualities of Swin Transformer make it compatible with a broad range of vision tasks, including image classification (87.3 top-1 accuracy on ImageNet-1K) and dense prediction tasks such as object detection (58.7 box AP and 51.1 mask AP on COCO test-dev) and semantic segmentation (53.5 mIoU on ADE20K val). Its performance surpasses the previous state-of-the-art by a large margin of +2.7 box AP and +2.6 mask AP on COCO, and +3.2 mIoU on ADE20K, demonstrating the potential of Transformer-based models as vision backbones. The hierarchical design and the shifted window approach also prove beneficial for all-MLP architectures. The code and models are publicly available at https://github.com/microsoft/Swin-Transformer.},
keywords = {image segmentation;computer vision;visualization;computational modeling;semantics;object detection;computer architecture},
xdoi = {10.1109/ICCV48922.2021.00986},
xurl = {https://xdoi.ieeecomputersociety.org/10.1109/ICCV48922.2021.00986},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {oct}
}

@inproceedings{10.5555/3495724.3495883,
author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
title = {Language Models Are Few-Shot Learners},
year = {2020},
isbn = {9781713829546},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We demonstrate that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even becoming competitive with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks. We also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora.},
booktitle = {Proceedings of the 34th International Conference on Neural Information Processing Systems},
articleno = {159},
numpages = {25},
location = {Vancouver, BC, Canada},
series = {NIPS'20}
}

@article{reiser_graph_2022,
	title = {Graph neural networks for materials science and chemistry},
	volume = {3},
	issn = {2662-4443},
	xurl = {https://xdoi.org/10.1038/s43246-022-00315-6},
	xdoi = {10.1038/s43246-022-00315-6},
	abstract = {Machine learning plays an increasingly important role in many areas of chemistry and materials science, being used to predict materials properties, accelerate simulations, design new structures, and predict synthesis routes of new materials. Graph neural networks (GNNs) are one of the fastest growing classes of machine learning models. They are of particular relevance for chemistry and materials science, as they directly work on a graph or structural representation of molecules and materials and therefore have full access to all relevant information required to characterize materials. In this Review, we provide an overview of the basic principles of GNNs, widely used datasets, and state-of-the-art architectures, followed by a discussion of a wide range of recent applications of GNNs in chemistry and materials science, and concluding with a road-map for the further development and application of GNNs.},
	number = {1},
	journal = {Communications Materials},
	author = {Reiser, Patrick and Neubert, Marlen and Eberhard, André and Torresi, Luca and Zhou, Chen and Shao, Chen and Metni, Houssam and van Hoesel, Clint and Schopmans, Henrik and Sommer, Timo and Friederich, Pascal},
	month = nov,
	year = {2022},
	pages = {93},
}

@article{10.5555/3322706.3361996,
author = {Elsken, Thomas and Metzen, Jan Hendrik and Hutter, Frank},
title = {Neural Architecture Search: A Survey},
year = {2021},
issue_date = {January 2019},
publisher = {JMLR.org},
volume = {20},
number = {1},
issn = {1532-4435},
abstract = {Deep Learning has enabled remarkable progress over the last years on a variety of tasks, such as image recognition, speech recognition, and machine translation. One crucial aspect for this progress are novel neural architectures. Currently employed architectures have mostly been developed manually by human experts, which is a time-consuming and error-prone process. Because of this, there is growing interest in automated neural architecture search methods. We provide an overview of existing work in this field of research and categorize them according to three dimensions: search space, search strategy, and performance estimation strategy.},
journal = {J. Mach. Learn. Res.},
month = {mar},
pages = {1997–2017},
numpages = {21},
keywords = {search space design, autoML, neural architecture search, search strategy, autoDL, performance estimation strategy}
}

@inproceedings{gao_estimating_2020,
	address = {New York, NY, USA},
	series = {{ESEC}/{FSE} 2020},
	title = {Estimating {GPU} memory consumption of deep learning models},
	isbn = {9781450370431},
	xurl = {https://xdoi.org/10.1145/3368089.3417050},
	xdoi = {10.1145/3368089.3417050},
	abstract = {Deep learning (DL) has been increasingly adopted by a variety of software-intensive systems. Developers mainly use GPUs to accelerate the training, testing, and deployment of DL models. However, the GPU memory consumed by a DL model is often unknown to them before the DL job executes. Therefore, an improper choice of neural architecture or hyperparameters can cause such a job to run out of the limited GPU memory and fail. Our recent empirical study has found that many DL job failures are due to the exhaustion of GPU memory. This leads to a horrendous waste of computing resources and a significant reduction in development productivity. In this paper, we propose DNNMem, an accurate estimation tool for GPU memory consumption of DL models. DNNMem employs an analytic estimation approach to systematically calculate the memory consumption of both the computation graph and the DL framework runtime. We have evaluated DNNMem on 5 real-world representative models with different hyperparameters under 3 mainstream frameworks (TensorFlow, PyTorch, and MXNet). Our extensive experiments show that DNNMem is effective in estimating GPU memory consumption.},
	xurldate = {2023-02-19},
	booktitle = {Proceedings of the 28th {ACM} {Joint} {Meeting} on {European} {Software} {Engineering} {Conference} and {Symposium} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Gao, Yanjie and Liu, Yu and Zhang, Hongyu and Li, Zhengxian and Zhu, Yonghao and Lin, Haoxiang and Yang, Mao},
	month = nov,
	year = {2020},
	keywords = {estimation model, program analysis, memory consumption, deep learning},
	pages = {1342--1352},
}

@inproceedings{10.1145/3545008.3545051,
author = {Liu, Liang and Shen, Mingzhu and Gong, Ruihao and Yu, Fengwei and Yang, Hailong},
title = {NNLQP: A Multi-Platform Neural Network Latency Query and Prediction System with An Evolving Database},
year = {2023},
isbn = {9781450397339},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
xurl = {https://xdoi-org.proxy.bnl.lu/10.1145/3545008.3545051},
xdoi = {10.1145/3545008.3545051},
abstract = {Deep neural networks (DNNs) are widely used in various applications. The accurate and latency feedback is essential for model design and deployment. In this work, we attempt to alleviate the cost of model latency acquisition from two aspects: latency query and latency prediction. To ease the difficulty of acquiring model latency on multi-platform, our latency query system can automatically convert DNN model into the corresponding executable format, and measure latency on the target hardware. Powered by this, latency queries can be fulfilled with a simple interface calling. For the efficient utilization of previous latency knowledge, we employ a MySQL database to store numerous models and the corresponding latencies. In our system, the efficiency of latency query can be boosted by 1.8 \texttimes{}. For latency prediction, we first represent neural networks with the unified GNN-based graph embedding. With the help of the evolving database, our model-based latency predictor achieves better performance, which realizes 12.31% accuracy improvement compared with existing methods. Our codes are open-sourced at https://github.com/ModelTC/NNLQP.},
booktitle = {Proceedings of the 51st International Conference on Parallel Processing},
articleno = {78},
numpages = {14},
keywords = {multi-platform, latency prediction, latency query, neural network},
location = {Bordeaux, France},
series = {ICPP '22}
}

@inproceedings{DBLP:conf/iclr/QiST17,
  author    = {Hang Qi and
               Evan R. Sparks and
               Ameet Talwalkar},
  title     = {Paleo: {A} Performance Model for Deep Neural Networks},
  booktitle = {5th International Conference on Learning Representations, {ICLR} 2017,
               Toulon, France, April 24-26, 2017, Conference Track Proceedings},
  publisher = {OpenReview.net},
  year      = {2017},
  xurl       = {https://openreview.net/forum?id=SyVVJ85lg},
  timestamp = {Thu, 25 Jul 2019 14:26:01 +0200},
  bibxurl    = {https://dblp.org/rec/conf/iclr/QiST17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{10.1145/3477133.3477137,
author = {Wang, Chuan-Chi and Liao, Ying-Chiao and Kao, Ming-Chang and Liang, Wen-Yew and Hung, Shih-Hao},
title = {Toward Accurate Platform-Aware Performance Modeling for Deep Neural Networks},
year = {2021},
issue_date = {March 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {1},
issn = {1559-6915},
xurl = {https://xdoi-org.proxy.bnl.lu/10.1145/3477133.3477137},
xdoi = {10.1145/3477133.3477137},
abstract = {In this paper, we provide a fine-grain machine learning-based method, PerfNetV2, which improves the accuracy of our previous work for modeling the neural network performance on a variety of GPU accelerators. Given an application, the proposed method can be used to predict the inference time and training time of the convolutional neural networks used in the application, which enables the system developer to optimize the performance by choosing the neural networks and/or incorporating the hardware accelerators to deliver satisfactory results in time. Furthermore, the proposed method is capable of predicting the performance of an unseen or non-existing device, e.g. a new GPU which has a higher operating frequency with less processor cores, but more memory capacity. This allows a system developer to quickly search the hardware design space and/or fine-tune the system configuration. Compared to the previous works, PerfNetV2 delivers more accurate results by modeling detailed host-accelerator interactions in executing the full neural networks and improving the architecture of the machine learning model used in the predictor. Our case studies show that PerfNetV2 yields a mean absolute percentage error within 13.1% on LeNet, AlexNet, and VGG16 on NVIDIA GTX-1080Ti, while the error rate on a previous work published in ICBD 2018 could be as large as 200%.},
journal = {SIGAPP Appl. Comput. Rev.},
month = {jul},
pages = {50–61},
numpages = {12},
keywords = {benchmark, machine learning, heterogeneous systems, performance prediction}
}

@inproceedings{10.1145/3458864.3467882,
author = {Zhang, Li Lyna and Han, Shihao and Wei, Jianyu and Zheng, Ningxin and Cao, Ting and Yang, Yuqing and Liu, Yunxin},
title = {Nn-Meter: Towards Accurate Latency Prediction of Deep-Learning Model Inference on Diverse Edge Devices},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
xurl = {https://xdoi.org/10.1145/3458864.3467882},
xdoi = {10.1145/3458864.3467882},
abstract = {With the recent trend of on-device deep learning, inference latency has become a crucial metric in running Deep Neural Network (DNN) models on various mobile and edge devices. To this end, latency prediction of DNN model inference is highly desirable for many tasks where measuring the latency on real devices is infeasible or too costly, such as searching for efficient DNN models with latency constraints from a huge model-design space. Yet it is very challenging and existing approaches fail to achieve a high accuracy of prediction, due to the varying model-inference latency caused by the runtime optimizations on diverse edge devices.In this paper, we propose and develop nn-Meter, a novel and efficient system to accurately predict the inference latency of DNN models on diverse edge devices. The key idea of nn-Meter is dividing a whole model inference into kernels, i.e., the execution units on a device, and conducting kernel-level prediction. nn-Meter builds atop two key techniques: (i) kernel detection to automatically detect the execution unit of model inference via a set of well-designed test cases; and (ii) adaptive sampling to efficiently sample the most beneficial configurations from a large space to build accurate kernel-level latency predictors. Implemented on three popular platforms of edge hardware (mobile CPU, mobile GPU, and Intel VPU) and evaluated using a large dataset of 26,000 models, nn-Meter significantly outperforms the prior state-of-the-art.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {81–93},
numpages = {13},
keywords = {edge AI, inference latency prediction, deep neural network},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}


@Article{electronics11152316,
author = {Sponner, Max and Waschneck, Bernd and Kumar, Akash},
TITLE = {AI-Driven Performance Modeling for AI Inference Workloads},
JOURNAL = {Electronics},
VOLUME = {11},
YEAR = {2022},
NUMBER = {15},
ARTICLE-NUMBER = {2316},
xurl = {https://www.mdpi.com/2079-9292/11/15/2316},
ISSN = {2079-9292},
ABSTRACT = {Deep Learning (DL) is moving towards deploying workloads not only in cloud datacenters, but also to the local devices. Although these are mostly limited to inference tasks, it still widens the range of possible target architectures significantly. Additionally, these new targets usually come with drastically reduced computation performance and memory sizes compared to the traditionally used architectures&mdash;and put the key optimization focus on the efficiency as they often depend on batteries. To help developers quickly estimate the performance of a neural network during its design phase, performance models could be used. However, these models are expensive to implement as they require in-depth knowledge about the hardware architecture and the used algorithms. Although AI-based solutions exist, these either require large datasets that are difficult to collect on the low-performance targets and/or limited to a small number of target platforms and metrics. Our solution exploits the block-based structure of neural networks, as well as the high similarity in the typically used layer configurations across neural networks, enabling the training of accurate models on significantly smaller datasets. In addition, our solution is not limited to a specific architecture or metric. We showcase the feasibility of the solution on a set of seven devices from four different hardware architectures, and with up to three performance metrics per target&mdash;including the power consumption and memory footprint. Our tests have shown that the solution achieved an error of less than 1 ms (2.6%) in latency, 0.12 J (4%) in energy consumption and 11 MiB (1.5%) in memory allocation for the whole network inference prediction, while being up to five orders of magnitude faster than a benchmark.},
xdoi = {10.3390/electronics11152316}
}



@inproceedings{10.1145/3542929.3563510,
author = {Li, Baolin and Patel, Tirthak and Samsi, Siddharth and Gadepally, Vijay and Tiwari, Devesh},
title = {MISO: Exploiting Multi-Instance GPU Capability on Multi-Tenant GPU Clusters},
year = {2022},
isbn = {9781450394147},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
xurl = {https://xdoi-org.proxy.bnl.lu/10.1145/3542929.3563510},
xdoi = {10.1145/3542929.3563510},
abstract = {GPU technology has been improving at an expedited pace in terms of size and performance, empowering HPC and AI/ML researchers to advance the scientific discovery process. However, this also leads to inefficient resource usage, as most GPU workloads, including complicated AI/ML models, are not able to utilize the GPU resources to their fullest extent - encouraging support for GPU multi-tenancy. We propose MISO, a technique to exploit the Multi-Instance GPU (MIG) capability on the latest NVIDIA datacenter GPUs (e.g., A100, H100) to dynamically partition GPU resources among co-located jobs. MISO's key insight is to use the lightweight, more flexible Multi-Process Service (MPS) capability to predict the best MIG partition allocation for different jobs, without incurring the overhead of implementing them during exploration. Due to its ability to utilize GPU resources more efficiently, MISO achieves 49% and 16% lower average job completion time than the unpartitioned and optimal static GPU partition schemes, respectively.},
booktitle = {Proceedings of the 13th Symposium on Cloud Computing},
pages = {173–189},
numpages = {17},
keywords = {resource sharing, multi-tenancy, multi-instance GPU},
location = {San Francisco, California},
series = {SoCC '22}
}

@inproceedings{10.1145/3444950.3447284,
author = {Bouhali, Noureddine and Ouarnoughi, Hamza and Niar, Smail and El Cadi, Abdessamad Ait},
title = {Execution Time Modeling for CNN Inference on Embedded GPUs},
year = {2021},
isbn = {9781450389525},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
xurl = {https://xdoi-org.proxy.bnl.lu/10.1145/3444950.3447284},
xdoi = {10.1145/3444950.3447284},
abstract = {Machine learning is one of the most cutting edge methods in computer vision. Convolutional Neural Networks (CNN) in particular are widely used in edge computing based applications such as autonomous driving for image recognition or object tracking. Different constraints exist in this application area such as real-time, energy consumption, memory resources, etc. Choosing the optimal CNN for each GPU at hand is really hard to do, while maintaining high levels of accuracy and performance. This makes prior knowledge about the execution time a necessary prerequisite information before the final deployment of the CNN on the edge GPU platform. In this paper, we compare 5 execution time prediction models on a large set of CNNs-based applications. The tested predictors use machine learning regression approach. The proposed methodology is based on the utilization of high level CNN features. At the opposite of state-of-the-art approaches, no implementation or profiling on the hardware is required. A Mean Absolute Percentage Error (MAPE) of 5% using Support Vector Regression and Artificial Neural Networks has been obtained in the experiments. Our comparison shows the efficiency of these models to rapidly explore a large space of CNN models or Hardware configurations.},
booktitle = {Proceedings of the 2021 Drone Systems Engineering and Rapid Simulation and Performance Evaluation: Methods and Tools Proceedings},
pages = {59–65},
numpages = {7},
location = {Budapest, Hungary},
series = {DroneSE and RAPIDO '21}
}

@article{DBLP:journals/corr/abs-2205-12095,
  author    = {Lu Bai and
               Weixing Ji and
               Qinyuan Li and
               Xilai Yao and
               Wei Xin and
               Wanyi Zhu},
  title     = {DNNAbacus: Toward Accurate Computational Cost Prediction for Deep
               Neural Networks},
  journal   = {CoRR},
  volume    = {abs/2205.12095},
  year      = {2022},
  xurl       = {https://xdoi.org/10.48550/arXiv.2205.12095},
  xdoi       = {10.48550/arXiv.2205.12095},
  eprinttype = {arXiv},
  eprint    = {2205.12095},
  timestamp = {Mon, 30 May 2022 15:47:29 +0200},
  bibxurl    = {https://dblp.org/rec/journals/corr/abs-2205-12095.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{8863962,
  author={Lu, Zongqing and Rallapalli, Swati and Chan, Kevin and Pu, Shiliang and Porta, Thomas La},
  journal={IEEE Transactions on Mobile Computing}, 
  title={Augur: Modeling the Resource Requirements of ConvNets on Mobile Devices}, 
  year={2021},
  volume={20},
  number={2},
  pages={352-365},
  xdoi={10.1109/TMC.2019.2946538}}


@INPROCEEDINGS {8622396,
author = {D. Justus and J. Brennan and S. Bonner and A. McGough},
booktitle = {2018 IEEE International Conference on Big Data (Big Data)},
title = {Predicting the Computational Cost of Deep Learning Models},
year = {2018},
volume = {},
issn = {},
pages = {3873-3882},
abstract = {Deep learning is rapidly becoming a go-to tool for many artificial intelligence problems due to its ability to outperform other approaches and even humans at many problems. Despite its popularity we are still unable to accurately predict the time it will take to train a deep learning network to solve a given problem. This training time can be seen as the product of the training time per epoch and the number of epochs which need to be performed to reach the desired level of accuracy. Some work has been carried out to predict the training time for an epoch &amp;#x2013; most have been based around the assumption that the training time is linearly related to the number of floating point operations required. However, this relationship is not true and becomes exacerbated in cases where other activities start to dominate the execution time. Such as the time to load data from memory or loss of performance due to non-optimal parallel execution. In this work we propose an alternative approach in which we train a deep learning network to predict the execution time for parts of a deep learning network. Timings for these individual parts can then be combined to provide a prediction for the whole execution time. This has advantages over linear approaches as it can model more complex scenarios. But, also, it has the ability to predict execution times for scenarios unseen in the training data. Therefore, our approach can be used not only to infer the execution time for a batch, or entire epoch, but it can also support making a well-informed choice for the appropriate hardware and model.},
keywords = {},
xdoi = {10.1109/BigData.2018.8622396},
xurl = {https://xdoi.ieeecomputersociety.org/10.1109/BigData.2018.8622396},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {dec}
}


@inproceedings{yang_perfestimator_2021,
	title = {{PerfEstimator}: {A} {Generic} and {Extensible} {Performance} {Estimator} for {Data} {Parallel} {DNN} {Training}},
	shorttitle = {{PerfEstimator}},
	xdoi = {10.1109/CloudIntelligence52565.2021.00012},
	abstract = {Understanding the performance of data parallel DNN training at large-scale is crucial for supporting efficient DNN cloud deployment as well as facilitating the design and optimization of scalable DNN systems. Existing works adopt analytical modeling, which may fall short in capturing the system behaviors resulting from the fast evolving DNN systems and constantly proposed optimizations. In this paper, we present PerfEstimator, a generic and extensible estimator for accurate performance estimation of large-scale data parallel DNN training. PerfEstimator is driven by three major components, namely, an extensible attributed graph based performance model, a computation and synchronization profiling and simulating tool for obtaining runtime time costs on a single machine, and a computation-synchronization pipeline builder to derive the scaling factors. Our evaluation highlights that PerfEstimator can accurately predict the performance of data parallel DNN training jobs with a prediction error of 0.2-11\%.},
	booktitle = {2021 {IEEE}/{ACM} {International} {Workshop} on {Cloud} {Intelligence} ({CloudIntelligence})},
	author = {Yang, Chengru and Li, Zhehao and Ruan, Chaoyi and Xu, Guanbin and Li, Cheng and Chen, Ruichuan and Yan, Feng},
	month = may,
	year = {2021},
	keywords = {Computational modeling, Training, profiling, modeling, cloud-computation, Costs, machine-learning, Market research, Pipelines, Runtime, system, Tools},
	pages = {13--18},
	file = {Yang et al_2021_PerfEstimator.pdf:C\:\\Users\\karthick.pannerselva\\Work\\One_Drive\\OneDrive\\Zotero\\Yang et al_2021_PerfEstimator.pdf:application/pdf},
}


@inproceedings{yu_habitat_2021,
  title = {{Habitat: A Runtime-Based Computational Performance Predictor
    for Deep Neural Network Training}},
  author = {Yu, Geoffrey X. and Gao, Yubo and Golikov, Pavel and
    Pekhimenko, Gennady},
  booktitle = {{Proceedings of the 2021 USENIX Annual Technical Conference
    (USENIX ATC'21)}},
  year = {2021},
}

@inproceedings{MLSYS2021_85d8ce59,
 author = {Kaufman, Sam and Phothilimthana, Phitchaya and Zhou, Yanqi and Mendis, Charith and Roy, Sudip and Sabne, Amit and Burrows, Mike},
 booktitle = {Proceedings of Machine Learning and Systems},
 editor = {A. Smola and A. Dimakis and I. Stoica},
 pages = {387--400},
 title = {A Learned Performance Model for Tensor Processing Units},
 xurl = {https://proceedings.mlsys.org/paper/2021/file/85d8ce590ad8981ca2c8286f79f59954-Paper.pdf},
 volume = {3},
 year = {2021}
}

@inproceedings{10.5555/3495724.3496603,
author = {Dudziak, \L{}ukasz and Chau, Thomas and Abdelfattah, Mohamed S. and Lee, Royson and Kim, Hyeji and Lane, Nicholas D.},
title = {BRP-NAS: Prediction-Based NAS Using GCNs},
year = {2020},
isbn = {9781713829546},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Neural architecture search (NAS) enables researchers to automatically explore broad design spaces in order to improve efficiency of neural networks. This efficiency is especially important in the case of on-device deployment, where improvements in accuracy should be balanced out with computational demands of a model. In practice, performance metrics of model are computationally expensive to obtain. Previous work uses a proxy (e.g., number of operations) or a layer-wise measurement of neural network layers to estimate end-to-end hardware performance but the imprecise prediction diminishes the quality of NAS. To address this problem, we propose BRP-NAS, an efficient hardware-aware NAS enabled by an accurate performance predictor-based on graph convolutional network (GCN). What is more, we investigate prediction quality on different metrics and show that sample efficiency of the predictor-based NAS can be improved by considering binary relations of models and an iterative data selection strategy. We show that our proposed method outperforms all prior methods on NAS-Bench-101 and NAS-Bench-201, and that our predictor can consistently learn to extract useful features from the DARTS search space, improving upon the second-order baseline. Finally, to raise awareness of the fact that accurate latency estimation is not a trivial task, we release LatBench - a latency dataset of NAS-Bench-201 models running on a broad range of devices.},
booktitle = {Proceedings of the 34th International Conference on Neural Information Processing Systems},
articleno = {879},
numpages = {11},
location = {Vancouver, BC, Canada},
series = {NIPS'20}
}

@inproceedings{10.1145/3211346.3211348,
author = {Roesch, Jared and Lyubomirsky, Steven and Weber, Logan and Pollock, Josh and Kirisame, Marisa and Chen, Tianqi and Tatlock, Zachary},
title = {Relay: A New IR for Machine Learning Frameworks},
year = {2018},
isbn = {9781450358347},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
xurl = {https://xdoi-org.proxy.bnl.lu/10.1145/3211346.3211348},
xdoi = {10.1145/3211346.3211348},
abstract = {Machine learning powers diverse services in industry including search, translation, recommendation systems, and security. The scale and importance of these models require that they be efficient, expressive, and portable across an array of heterogeneous hardware devices. These constraints are often at odds; in order to better accommodate them we propose a new high-level intermediate representation (IR) called Relay. Relay is being designed as a purely-functional, statically-typed language with the goal of balancing efficient compilation, expressiveness, and portability. We discuss the goals of Relay and highlight its important design constraints. Our prototype is part of the open source NNVM compiler framework, which powers Amazon's deep learning framework MxNet.},
booktitle = {Proceedings of the 2nd ACM SIGPLAN International Workshop on Machine Learning and Programming Languages},
pages = {58–68},
numpages = {11},
keywords = {differentiable programming, compilers, intermediate representation, machine learning},
location = {Philadelphia, PA, USA},
series = {MAPL 2018}
}

@inproceedings{10.5555/3294771.3294869,
author = {Hamilton, William L. and Ying, Rex and Leskovec, Jure},
title = {Inductive Representation Learning on Large Graphs},
year = {2017},
isbn = {9781510860964},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Low-dimensional embeddings of nodes in large graphs have proved extremely useful in a variety of prediction tasks, from content recommendation to identifying protein functions. However, most existing approaches require that all nodes in the graph are present during training of the embeddings; these previous approaches are inherently transductive and do not naturally generalize to unseen nodes. Here we present GraphSAGE, a general inductive framework that leverages node feature information (e.g., text attributes) to efficiently generate node embeddings for previously unseen data. Instead of training individual embeddings for each node, we learn a function that generates embeddings by sampling and aggregating features from a node's local neighborhood. Our algorithm outperforms strong baselines on three inductive node-classification benchmarks: we classify the category of unseen nodes in evolving information graphs based on citation and Reddit post data, and we show that our algorithm generalizes to completely unseen graphs using a multi-graph dataset of protein-protein interactions.},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
pages = {1025–1035},
numpages = {11},
location = {Long Beach, California, USA},
series = {NIPS'17}
}

@misc{https://xdoi.org/10.48550/arxiv.1609.02907,
  xdoi = {10.48550/ARXIV.1609.02907},
  
  xurl = {https://arxiv.org/abs/1609.02907},
  
  author = {Kipf, Thomas N. and Welling, Max},
  
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Semi-Supervised Classification with Graph Convolutional Networks},
  
  publisher = {arXiv},
  
  year = {2016},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://xdoi.org/10.48550/arxiv.1710.10903,
  xdoi = {10.48550/ARXIV.1710.10903},
  
  xurl = {https://arxiv.org/abs/1710.10903},
  
  author = {Veličković, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Liò, Pietro and Bengio, Yoshua},
  
  keywords = {Machine Learning (stat.ML), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), Social and Information Networks (cs.SI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Graph Attention Networks},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://xdoi.org/10.48550/arxiv.1810.00826,
  xdoi = {10.48550/ARXIV.1810.00826},
  
  xurl = {https://arxiv.org/abs/1810.00826},
  
  author = {Xu, Keyulu and Hu, Weihua and Leskovec, Jure and Jegelka, Stefanie},
  
  keywords = {Machine Learning (cs.LG), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {How Powerful are Graph Neural Networks?},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://xdoi.org/10.48550/arxiv.1506.01186,
  xdoi = {10.48550/ARXIV.1506.01186},
  
  xurl = {https://arxiv.org/abs/1506.01186},
  
  author = {Smith, Leslie N.},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Cyclical Learning Rates for Training Neural Networks},
  
  publisher = {arXiv},
  
  year = {2015},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://xdoi.org/10.48550/arxiv.2203.00854,
  xdoi = {10.48550/ARXIV.2203.00854},
  
  xurl = {https://arxiv.org/abs/2203.00854},
  
  author = {Cheng, Shenggan and Zhao, Xuanlei and Lu, Guangyang and Fang, Jiarui and Yu, Zhongming and Zheng, Tian and Wu, Ruidong and Zhang, Xiwen and Peng, Jian and You, Yang},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Distributed, Parallel, and Cluster Computing (cs.DC), Quantitative Methods (q-bio.QM), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Biological sciences, FOS: Biological sciences},
  
  title = {FastFold: Reducing AlphaFold Training Time from 11 Days to 67 Hours},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{
xu2018how,
title={How Powerful are Graph Neural Networks?},
author={Keyulu Xu and Weihua Hu and Jure Leskovec and Stefanie Jegelka},
booktitle={International Conference on Learning Representations},
year={2019},
xurl={https://openreview.net/forum?id=ryGs6iA5Km},
}

@article{
  velickovic2018graph,
  title="{Graph Attention Networks}",
  author={Veli{\v{c}}kovi{\'{c}}, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Li{\`{o}}, Pietro and Bengio, Yoshua},
  journal={International Conference on Learning Representations},
  year={2018},
  xurl={https://openreview.net/forum?id=rJXMpikCZ},
  note={accepted as poster},
}

@inproceedings{kipf2017semi,
  title={Semi-Supervised Classification with Graph Convolutional Networks},
  author={Kipf, Thomas N. and Welling, Max},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2017}
}

@INPROCEEDINGS{7926641,
  author={Smith, Leslie N.},
  booktitle={2017 IEEE Winter Conference on Applications of Computer Vision (WACV)}, 
  title={Cyclical Learning Rates for Training Neural Networks}, 
  year={2017},
  volume={},
  number={},
  pages={464-472},
  xdoi={10.1109/WACV.2017.58}}
