@book{adams1995hitchhiker,
  title={The Hitchhiker's Guide to the Galaxy},
  author={Adams, D.},
  isbn={9781417642595},
  url={http://books.google.com/books?id=W-xMPgAACAAJ},
  year={1995},
  publisher={San Val}
}

@article{koenker2001quantile,
  title={Quantile regression},
  author={Koenker, Roger and Hallock, Kevin F},
  journal={Journal of economic perspectives},
  volume={15},
  number={4},
  pages={143--156},
  year={2001}
}
@article{meinshausen2006quantile,
  title={Quantile regression forests.},
  author={Meinshausen, Nicolai and Ridgeway, Greg},
  journal={Journal of Machine Learning Research},
  volume={7},
  number={6},
  year={2006}
}

@article{breiman2001random,
  title={Random forests},
  author={Breiman, Leo},
  journal={Machine learning},
  volume={45},
  number={1},
  pages={5--32},
  year={2001},
  publisher={Springer}
}

@article{benard2021shaff,
  title={SHAFF: Fast and consistent SHApley eFfect estimates via random Forests},
  author={B{\'e}nard, Cl{\'e}ment and Biau, G{\'e}rard and Da Veiga, S{\'e}bastien and Scornet, Erwan},
  journal={arXiv preprint arXiv:2105.11724},
  year={2021}
}

@article{benard2021mda,
  title={MDA for random forests: inconsistency, and a practical solution via the Sobol-MDA},
  author={B{\'e}nard, Cl{\'e}ment and Da Veiga, S{\'e}bastien and Scornet, Erwan},
  journal={arXiv preprint arXiv:2102.13347},
  year={2021}
}

@article{amit1997shape,
  title={Shape quantization and recognition with randomized trees},
  author={Amit, Yali and Geman, Donald},
  journal={Neural computation},
  volume={9},
  number={7},
  pages={1545--1588},
  year={1997},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{breiman1984classification,
  title={Classification and regression trees. Wadsworth Int},
  author={Breiman, Leo and Friedman, Jerome and Olshen, Richard and Stone, Charles},
  journal={Group},
  volume={37},
  number={15},
  pages={237--251},
  year={1984}
}

@article{lin2006random,
  title={Random forests and adaptive nearest neighbors},
  author={Lin, Yi and Jeon, Yongho},
  journal={Journal of the American Statistical Association},
  volume={101},
  number={474},
  pages={578--590},
  year={2006},
  publisher={Taylor \& Francis}
}

@article{ishwaran2008random,
  title={Random survival forests},
  author={Ishwaran, Hemant and Kogalur, Udaya B and Blackstone, Eugene H and Lauer, Michael S},
  journal={The annals of applied statistics},
  volume={2},
  number={3},
  pages={841--860},
  year={2008},
  publisher={Institute of Mathematical Statistics}
}

@misc{wager2017estimation,
      title={Estimation and Inference of Heterogeneous Treatment Effects using Random Forests}, 
      author={Stefan Wager and Susan Athey},
      year={2017},
      eprint={1510.04342},
      archivePrefix={arXiv},
      primaryClass={stat.ME}
}

@inproceedings{du2021wasserstein,
  title={Wasserstein Random Forests and Applications in Heterogeneous Treatment Effects},
  author={Du, Qiming and Biau, G{\'e}rard and Petit, Fran{\c{c}}ois and Porcher, Rapha{\"e}l},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1729--1737},
  year={2021},
  organization={PMLR}
}

@article{elie2020random,
  title={Random forest estimation of conditional distribution functions and conditional quantiles},
  author={Elie-Dit-Cosaque, Kevin and Maume-Deschamps, V{\'e}ronique},
  journal={Electronic Journal of Statistics},
  volume={16},
  number={2},
  pages={6553--6583},
  year={2022},
  publisher={The Institute of Mathematical Statistics and the Bernoulli Society}
}

@article{scornet2015consistency,
  title={Consistency of random forests},
  author={Scornet, Erwan and Biau, G{\'e}rard and Vert, Jean-Philippe},
  journal={The Annals of Statistics},
  volume={43},
  number={4},
  pages={1716--1741},
  year={2015},
  publisher={Institute of Mathematical Statistics}
}

@article{biau2012analysis,
  title={Analysis of a random forests model},
  author={Biau, G{\'e}rard},
  journal={The Journal of Machine Learning Research},
  volume={13},
  pages={1063--1095},
  year={2012},
  publisher={JMLR. org}
}

@article{goehry2020random,
  title={Random forests for time-dependent processes},
  author={Goehry, Benjamin},
  journal={ESAIM: Probability and Statistics},
  volume={24},
  pages={801--826},
  year={2020}
}

@article{mentch2016quantifying,
  title={Quantifying uncertainty in random forests via confidence intervals and hypothesis tests},
  author={Mentch, Lucas and Hooker, Giles},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={841--881},
  year={2016},
  publisher={JMLR. org}
}

@book{gyorfi2002distribution,
  title={A distribution-free theory of nonparametric regression},
  author={Gy{\"o}rfi, L{\'a}szl{\'o} and Kohler, Michael and Krzy{\.z}ak, Adam and Walk, Harro},
  volume={1},
  year={2002},
  publisher={Springer}
}

@inproceedings{wang2020towards,
  title={Towards Probabilistic Sufficient Explanations},
  author={Wang, Eric and Khosravi, Pasha and Van den Broeck, Guy},
  booktitle={Extending Explainable AI Beyond Deep Models and Classifiers Workshop at ICML (XXAI)},
  year={2020}
}

@inproceedings{Chen2012TheSP,
  title={The Same-Decision Probability: A New Tool for Decision Making},
  author={S. Chen and Arthur Choi and Adnan Darwiche},
  year={2012}
}

@inproceedings{benard2021interpretable,
  title={Interpretable random forests via rule extraction},
  author={B{\'e}nard, Cl{\'e}ment and Biau, G{\'e}rard and Veiga, S{\'e}bastien and Scornet, Erwan},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={937--945},
  year={2021},
  organization={PMLR}
}

@article{amoukou2021consistent,
  title={Consistent Sufficient Explanations and Minimal Local Rules for explaining regression and classification models},
  author={Amoukou, Salim I and Brunel, Nicolas JB},
  journal={arXiv preprint arXiv:2111.04658},
  year={2021}
}

@inproceedings{Papadopoulos2002InductiveCM,
  title={Inductive Confidence Machines for Regression},
  author={Harris Papadopoulos and Kostas Proedrou and Vladimir Vovk and Alexander Gammerman},
  booktitle={European Conference on Machine Learning},
  year={2002}
}

@article{Lei2016DistributionFreePI,
  title={Distribution-Free Predictive Inference for Regression},
  author={Jing Lei and Max G'Sell and Alessandro Rinaldo and Ryan J. Tibshirani and Larry A. Wasserman},
  journal={Journal of the American Statistical Association},
  year={2016},
  volume={113},
  pages={1094 - 1111}
}

@article{Vovk2012CrossconformalP,
  title={Cross-conformal predictors},
  author={Vladimir Vovk},
  journal={Annals of Mathematics and Artificial Intelligence},
  year={2012},
  volume={74},
  pages={9-28}
}

@article{romano2019conformalized,
  title={Conformalized quantile regression},
  author={Romano, Yaniv and Patterson, Evan and Candes, Emmanuel},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{papadopoulos2008normalized,
  title={Normalized nonconformity measures for regression conformal prediction},
  author={Papadopoulos, Harris and Gammerman, Alex and Vovk, Volodya},
  booktitle={Proceedings of the IASTED International Conference on Artificial Intelligence and Applications (AIA 2008)},
  pages={64--69},
  year={2008}
}

@article{guanlocalizer,
    author = {Guan, Leying},
    title = "{Localized conformal prediction: a generalized inference framework for conformal prediction}",
    journal = {Biometrika},
    year = {2022},
    month = {07},
    abstract = "{We propose a new inference framework called localized conformal prediction. It generalizes the framework of conformal prediction by offering a single-test-sample adaptive construction that emphasizes a local region around this test sample, and can be combined with different conformal scores. The proposed framework enjoys an assumption-free finite sample marginal coverage guarantee, and it also offers additional local coverage guarantees under suitable assumptions. We demonstrate how to change from conformal prediction to localized conformal prediction using several conformal scores, and we illustrate a potential gain via numerical examples.}",
    issn = {1464-3510},
    doi = {10.1093/biomet/asac040},
    url = {https://doi.org/10.1093/biomet/asac040},
    note = {asac040},
    eprint = {https://academic.oup.com/biomet/advance-article-pdf/doi/10.1093/biomet/asac040/45911782/asac040.pdf},
}

@article{han2022split,
  title={Split Localized Conformal Prediction},
  author={Han, Xing and Tang, Ziyang and Ghosh, Joydeep and Liu, Qiang},
  journal={arXiv preprint arXiv:2206.13092},
  year={2022}
}

@article{nadaraya1964estimating,
  title={On estimating regression},
  author={Nadaraya, Elizbar A},
  journal={Theory of Probability \& Its Applications},
  volume={9},
  number={1},
  pages={141--142},
  year={1964},
  publisher={SIAM}
}

@article{bian2022training,
  title={Training-conditional coverage for distribution-free predictive inference},
  author={Bian, Michael and Barber, Rina Foygel},
  journal={arXiv preprint arXiv:2205.03647},
  year={2022}
}

@article{barber2022conformal,
  title={Conformal prediction beyond exchangeability},
  author={Barber, Rina Foygel and Candes, Emmanuel J and Ramdas, Aaditya and Tibshirani, Ryan J},
  journal={arXiv preprint arXiv:2202.13415},
  year={2022}
}

@article{tibshirani2019conformal,
  title={Conformal prediction under covariate shift},
  author={Tibshirani, Ryan J and Foygel Barber, Rina and Candes, Emmanuel and Ramdas, Aaditya},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{vovk2012conditional,
  title={Conditional validity of inductive conformal predictors},
  author={Vovk, Vladimir},
  booktitle={Asian conference on machine learning},
  pages={475--490},
  year={2012},
  organization={PMLR}
}

@article{kim2020predictive,
  title={Predictive inference is free with the jackknife+-after-bootstrap},
  author={Kim, Byol and Xu, Chen and Barber, Rina},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={4138--4149},
  year={2020}
}

@article{Barber2019,
   abstract = {We consider the problem of distribution-free predictive inference, with the goal of producing predictive coverage guarantees that hold conditionally rather than marginally. Existing methods such as conformal prediction offer marginal coverage guarantees, where predictive coverage holds on average over all possible test points, but this is not sufficient for many practical applications where we would like to know that our predictions are valid for a given individual, not merely on average over a population. On the other hand, exact conditional inference guarantees are known to be impossible without imposing assumptions on the underlying distribution. In this work we aim to explore the space in between these two, and examine what types of relaxations of the conditional coverage property would alleviate some of the practical concerns with marginal coverage guarantees while still being possible to achieve in a distribution-free setting.},
   author = {Rina Foygel Barber and Emmanuel J. Candès and Aaditya Ramdas and Ryan J. Tibshirani},
   doi = {10.1093/imaiai/iaaa017},
   issn = {20498772},
   issue = {2},
   journal = {Information and Inference},
   keywords = {conformal prediction,distribution-free inference,predictive inference},
   month = {3},
   pages = {455-482},
   title = {The limits of distribution-free conditional predictive inference},
   volume = {10},
   url = {http://arxiv.org/abs/1903.04684},
   year = {2019},
}




@article{barber2021predictive,
  title={Predictive inference with the jackknife+},
  author={Barber, Rina Foygel and Candes, Emmanuel J and Ramdas, Aaditya and Tibshirani, Ryan J},
  journal={The Annals of Statistics},
  volume={49},
  number={1},
  pages={486--507},
  year={2021},
  publisher={Institute of Mathematical Statistics}
}

@book{vovk2005algorithmic,
  title={Algorithmic learning in a random world},
  author={Vovk, Vladimir and Gammerman, Alexander and Shafer, Glenn},
  year={2005},
  publisher={Springer Science \& Business Media}
}

@inproceedings{kivaranovic2020adaptive,
  title={Adaptive, distribution-free prediction intervals for deep networks},
  author={Kivaranovic, Danijel and Johnson, Kory D and Leeb, Hannes},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4346--4356},
  year={2020},
  organization={PMLR}
}

@article{fontana2023conformal,
  title={Conformal prediction: a unified review of theory and new challenges},
  author={Fontana, Matteo and Zeni, Gianluca and Vantini, Simone},
  journal={Bernoulli},
  volume={29},
  number={1},
  pages={1--23},
  year={2023},
  publisher={Bernoulli Society for Mathematical Statistics and Probability}
}

@inproceedings{Schaeffer2007SurveyGC,
  title={Survey Graph clustering},
  author={Satu Elisa Schaeffer},
  year={2007}
}

@article{traag2019louvain,
  title={From Louvain to Leiden: guaranteeing well-connected communities},
  author={Traag, Vincent A and Waltman, Ludo and Van Eck, Nees Jan},
  journal={Scientific reports},
  volume={9},
  number={1},
  pages={1--12},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{delvenne2010stability,
  title={Stability of graph communities across time scales},
  author={Delvenne, J-C and Yaliraki, Sophia N and Barahona, Mauricio},
  journal={Proceedings of the national academy of sciences},
  volume={107},
  number={29},
  pages={12755--12760},
  year={2010},
  publisher={National Acad Sciences}
}

@report{Xu2020,
   abstract = {We develop a general framework constructing distribution-free prediction intervals for dynamic time series. We show that our intervals asymptotically attain valid conditional and marginal coverages for a broad class of predictions functions and time series. We also show that our interval width converges to that of the oracle prediction interval asymptotically. Moreover, we introduce a computationally efficient algorithm called \verb|EnbPI| that wraps around ensemble predictors, which is closely related to conformal prediction (CP) but does not require data exchangeability. \verb|EnbPI| avoids data-splitting and is computationally efficient by avoiding retraining and thus scalable to sequentially producing prediction intervals. We perform extensive simulation and real-data analyses to demonstrate its effectiveness compared with existing methods.},
   author = {Chen Xu and Yao Xie},
   keywords = {anomaly detection,asymptotic guarantee,conformal prediction,data,network inference with missing,time-series predictive inference},
   pages = {1-42},
   title = {Conformal prediction for dynamic time-series},
   volume = {1},
   url = {http://arxiv.org/abs/2010.09107},
   year = {2020},
}

@article{Lei2014DistributionfreePB,
  title={Distribution‐free prediction bands for non‐parametric regression},
  author={Jing Lei and Larry A. Wasserman},
  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  year={2014},
  volume={76}
}

@article{sesia2020comparison,
  title={A comparison of some conformal quantile regression methods},
  author={Sesia, Matteo and Cand{\`e}s, Emmanuel J},
  journal={Stat},
  volume={9},
  number={1},
  pages={e261},
  year={2020},
  publisher={Wiley Online Library}
}


@InProceedings{izbicki20a,
  title = 	 {Flexible distribution-free conditional predictive bands using density estimators},
  author =       {Izbicki, Rafael and Shimizu, Gilson and Stern, Rafael},
  booktitle = 	 {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},
  pages = 	 {3068--3077},
  year = 	 {2020},
  editor = 	 {Chiappa, Silvia and Calandra, Roberto},
  volume = 	 {108},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {26--28 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v108/izbicki20a/izbicki20a.pdf},
  url = 	 {https://proceedings.mlr.press/v108/izbicki20a.html},
  abstract = 	 {Conformal methods create prediction bands that control average coverage assuming solely i.i.d. data. Besides average coverage, one might also desire to control conditional coverage, that is, coverage for every new testing point. However, without strong assumptions, conditional coverage is unachievable. Given this limitation, the literature has focused on methods with asymptotical conditional coverage. In order to obtain this property, these methods require strong conditions on the dependence between the target variable and the features. We introduce two conformal methods based on conditional density estimators that do not depend on this type of assumption to obtain asymptotic conditional coverage: Dist-split and CD-split. While Dist-split asymptotically obtains optimal intervals, which are easier to interpret than general regions, CD-split obtains optimal size regions, which are smaller than intervals. CD-split also obtains local coverage by creating prediction bands locally on a partition of the features space. This partition is data-driven and scales to high-dimensional settings. In a wide variety of simulated scenarios, our methods have a better control of conditional coverage and have smaller length than previously proposed methods.}
}

@article{additiveStone,
author = {Charles J. Stone},
title = {{Additive Regression and Other Nonparametric Models}},
volume = {13},
journal = {The Annals of Statistics},
number = {2},
publisher = {Institute of Mathematical Statistics},
pages = {689 -- 705},
keywords = {Additivity, nonparametric model, rate of convergence, Spline},
year = {1985},
doi = {10.1214/aos/1176349548},
URL = {https://doi.org/10.1214/aos/1176349548}
}

@article{massart1990tight,
  title={The tight constant in the Dvoretzky-Kiefer-Wolfowitz inequality},
  author={Massart, Pascal},
  journal={The annals of Probability},
  pages={1269--1283},
  year={1990},
  publisher={JSTOR}
}

@inproceedings{grinsztajn2022tree,
  title={Why do tree-based models still outperform deep learning on typical tabular data?},
  author={Grinsztajn, Leo and Oyallon, Edouard and Varoquaux, Gael},
  booktitle={Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  year={2022}
}

@article{valiant1984theory,
  title={A theory of the learnable},
  author={Valiant, Leslie G},
  journal={Communications of the ACM},
  volume={27},
  number={11},
  pages={1134--1142},
  year={1984},
  publisher={Acm New York, NY, USA}
}

@article{klusowski2021universal,
  title={Universal consistency of decision trees in high dimensions},
  author={Klusowski, Jason M},
  journal={arXiv preprint arXiv:2104.13881},
  year={2021}
}

@article{concrete,
  title={Modeling of strength of high-performance concrete using artificial neural networks},
  author={Yeh, I-C},
  journal={Cement and Concrete research},
  volume={28},
  number={12},
  pages={1797--1808},
  year={1998},
  publisher={Elsevier}
}

@misc{uci_dataset,
author = "Dua, Dheeru and Graff, Casey",
year = "2017",
title = "{UCI} Machine Learning Repository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences"}

@article{chernozhukov2010quantile,
  title={Quantile and probability curves without crossing},
  author={Chernozhukov, Victor and Fern{\'a}ndez-Val, Iv{\'a}n and Galichon, Alfred},
  journal={Econometrica},
  volume={78},
  number={3},
  pages={1093--1125},
  year={2010},
  publisher={Wiley Online Library}
}

@article{breiman1996bagging,
  title={Bagging predictors', Machine Learning24, 123--140},
  author={Breiman, L},
  journal={Google Scholar Google Scholar Digital Library Digital Library},
  year={1996}
}

@book{molnar2022,
  title      = {Interpretable Machine Learning},
  author     = {Christoph Molnar},
  year       = {2022},
  subtitle   = {A Guide for Making Black Box Models Explainable},
  edition    = {2},
  url        = {https://christophm.github.io/interpretable-ml-book}
}


@article{biau2012analysis,
  title={Analysis of a random forests model},
  author={Biau, G{\'e}rard},
  journal={The Journal of Machine Learning Research},
  volume={13},
  pages={1063--1095},
  year={2012},
  publisher={JMLR. org}
}


@article{mentch2016quantifying,
  title={Quantifying uncertainty in random forests via confidence intervals and hypothesis tests},
  author={Mentch, Lucas and Hooker, Giles},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={841--881},
  year={2016},
  publisher={JMLR. org}
}


@incollection{NIPS2017_7062,
title = {A Unified Approach to Interpreting Model Predictions},
author = {Lundberg, Scott M and Lee, Su-In},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {4765--4774},
year = {2017}
}

@misc{Covert2020,
archivePrefix = {arXiv},
arxivId = {2011.14878},
author = {Covert, Ian C. and Lundberg, Scott and Lee, Su In},
booktitle = {arXiv},
eprint = {2011.14878},
file = {:Users/brunel/Library/Application Support/Mendeley Desktop/Downloaded/Covert, Lundberg, Lee - 2020 - Explaining by Removing A Unified Framework for Model Explanation.pdf:pdf},
issn = {23318422},
keywords = {Cooperative game theory,Information theory,Interpretability,Model explanation,Psychology},
month = {nov},
publisher = {arXiv},
title = {{Explaining by removing: A unified framework for model explanation}},
url = {http://arxiv.org/abs/2011.14878},
year = {2020}
}

@article{chen2020true,
  title={True to the Model or True to the Data?},
  author={Chen, Hugh and Janizek, Joseph D and Lundberg, Scott and Lee, Su-In},
  journal={arXiv preprint arXiv:2006.16234},
  year={2020}
}

@misc{UCIADULT:2019 ,
author = "Dua, Dheeru and Graff, Casey",
year = "2017",
title = "{UCI} Machine Learning Repository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences" }

@article{lundberg2020local2global,
  title={From local explanations to global understanding with explainable AI for trees},
  author={Lundberg, Scott M. and Erion, Gabriel and Chen, Hugh and DeGrave, Alex and Prutkin, Jordan M. and Nair, Bala and Katz, Ronit and Himmelfarb, Jonathan and Bansal, Nisha and Lee, Su-In},
  journal={Nature Machine Intelligence},
  volume={2},
  number={1},
  pages={2522-5839},
  year={2020},
  publisher={Nature Publishing Group}
}

@inproceedings{janzing2019feature,
  title={Feature relevance quantification in explainable AI: A causal problem},
  author={Janzing, Dominik and Minorics, Lenon and Bl{\"o}baum, Patrick},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2907--2916},
  year={2020},
  organization={PMLR}
}

@inproceedings{heskes2020causal,
  author    = {Tom Heskes and
               Evi Sijben and
               Ioan Gabriel Bucur and
               Tom Claassen},
  editor    = {Hugo Larochelle and
               Marc'Aurelio Ranzato and
               Raia Hadsell and
               Maria{-}Florina Balcan and
               Hsuan{-}Tien Lin},
  title     = {Causal Shapley Values: Exploiting Causal Knowledge to Explain Individual
               Predictions of Complex Models},
  booktitle = {Advances in Neural Information Processing Systems 33: Annual Conference
               on Neural Information Processing Systems 2020, NeurIPS 2020, December
               6-12, 2020, virtual},
  year      = {2020},
  url       = {https://proceedings.neurips.cc/paper/2020/hash/32e54441e6382a7fbacbbbaf3c450059-Abstract.html},
  timestamp = {Tue, 19 Jan 2021 15:57:21 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/HeskesSBC20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ma2020predictive,
  author    = {Sisi Ma and
               Roshan Tourani},
  editor    = {Thuc Duy Le and
               Lin Liu and
               Kun Zhang and
               Emre Kiciman and
               Peng Cui and
               Aapo Hyv{\"{a}}rinen},
  title     = {Predictive and Causal Implications of using Shapley Value for Model
               Interpretation},
  booktitle = {Proceedings of the 2020 {KDD} Workshop on Causal Discovery (CD@KDD
               2020), San Diego, CA, USA, 24 August 2020},
  series    = {Proceedings of Machine Learning Research},
  volume    = {127},
  pages     = {23--38},
  publisher = {{PMLR}},
  year      = {2020},
  url       = {http://proceedings.mlr.press/v127/ma20a.html},
  timestamp = {Fri, 11 Dec 2020 12:14:42 +0100},
  biburl    = {https://dblp.org/rec/conf/kdd/MaT20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{l2x,
  author    = {Jianbo Chen and
               Le Song and
               Martin J. Wainwright and
               Michael I. Jordan},
  editor    = {Jennifer G. Dy and
               Andreas Krause},
  title     = {Learning to Explain: An Information-Theoretic Perspective on Model
               Interpretation},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning,
               {ICML} 2018, Stockholmsm{\"{a}}ssan, Stockholm, Sweden, July
               10-15, 2018},
  series    = {Proceedings of Machine Learning Research},
  volume    = {80},
  pages     = {882--891},
  publisher = {{PMLR}},
  year      = {2018},
  url       = {http://proceedings.mlr.press/v80/chen18j.html},
  timestamp = {Wed, 03 Apr 2019 18:17:30 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/ChenSWJ18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{yoon2018invase,
  title={INVASE: Instance-wise variable selection using neural networks},
  author={Yoon, Jinsung and Jordon, James and van der Schaar, Mihaela},
  booktitle={International Conference on Learning Representations},
  year={2018}
}


@inproceedings{shapleyBasedFS1,
author = {Zaeri-Amirani, Mohammad and Afghah, Fatemeh and Mousavi, Sajad},
year = {2018},
month = {07},
pages = {319-323},
title = {A Feature Selection Method Based on Shapley Value to False Alarm Reduction in ICUs A Genetic-Algorithm Approach},
volume = {2018},
journal = {Conference proceedings: ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Conference},
doi = {10.1109/EMBC.2018.8512266}
}


@article{shapleyBasedFS2,
  author    = {Shay B. Cohen and
               Gideon Dror and
               Eytan Ruppin},
  title     = {Feature Selection via Coalitional Game Theory},
  journal   = {Neural Comput.},
  volume    = {19},
  number    = {7},
  pages     = {1939--1961},
  year      = {2007},
  url       = {https://doi.org/10.1162/neco.2007.19.7.1939},
  doi       = {10.1162/neco.2007.19.7.1939},
  timestamp = {Tue, 01 Sep 2020 13:11:29 +0200},
  biburl    = {https://dblp.org/rec/journals/neco/CohenDR07.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{shapleyBasedFS3,
  author    = {Xin Sun and
               Yanheng Liu and
               Jin Li and
               Jianqi Zhu and
               Xuejie Liu and
               Hui{-}Ling Chen},
  title     = {Using cooperative game theory to optimize the feature selection problem},
  journal   = {Neurocomputing},
  volume    = {97},
  pages     = {86--93},
  year      = {2012},
  url       = {https://doi.org/10.1016/j.neucom.2012.05.001},
  doi       = {10.1016/j.neucom.2012.05.001},
  timestamp = {Sun, 02 Jun 2019 20:50:34 +0200},
  biburl    = {https://dblp.org/rec/journals/ijon/SunLLZLC12.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{Chen2013AnEA,
author = {Chen, Suming and Choi, Arthur and Darwiche, Adnan},
title = {An Exact Algorithm for Computing the Same-Decision Probability},
year = {2013},
isbn = {9781577356332},
publisher = {AAAI Press},
pages = {2525–2531},
numpages = {7},
location = {Beijing, China},
series = {IJCAI '13}
}

@article{ProbCirc20,
  author    = {Choi, YooJung and Vergari, Antonio and Van den Broeck, Guy},
  title     = {Probabilistic Circuits: A Unifying Framework for Tractable Probabilistic Models},
  month     = {oct},
  year      = {2020},
  url       = "http://starai.cs.ucla.edu/papers/ProbCirc20.pdf",
  keywords  = {techreport}
}

@misc{aas2020explaining,
      title={Explaining individual predictions when features are dependent: More accurate approximations to Shapley values}, 
      author={Kjersti Aas and Martin Jullum and Anders Løland},
      year={2020},
      eprint={1903.10464},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@article{friedman2001,
author = "Friedman, Jerome H.",
doi = "10.1214/aos/1013203451",
fjournal = "Annals of Statistics",
journal = "Ann. Statist.",
month = "10",
number = "5",
pages = "1189--1232",
publisher = "The Institute of Mathematical Statistics",
title = "Greedy function approximation: A gradient boosting 			 machine.",
url = "https://doi.org/10.1214/aos/1013203451",
volume = "29",
year = "2001"
}

@article{shapley1953,
author = "Lloyd S Shapley",
journal = "Contribution to the Theory of Games",
pages = "307--317",
title = "Greedy function approximation: A gradient boosting 			 machine.",
url = "https://www.rand.org/content/dam/rand/pubs/research_memoranda/2008/RM670.pdf",
volume = "2",
year = "1953"
}


@article{goldstein2014peeking,
  title={Peeking inside the black box: Visualizing statistical learning with plots of individual conditional expectation},
  author={Goldstein, Alex and Kapelner, Adam and Bleich, Justin and Pitkin, Emil},
  journal={Journal of Computational and Graphical Statistics},
  volume={24},
  number={1},
  pages={44--65},
  year={2015},
  publisher={Taylor \& Francis}
}

@inproceedings{ribeiro2016why,
  title={" Why should i trust you?" Explaining the predictions of any classifier},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={1135--1144},
  year={2016}
}

@inproceedings{ribeiro2018anchors,
  title={Anchors: High-precision model-agnostic explanations},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}


@article{strumbelj2010,
author = {Strumbelj, Erik and Kononenko, Igor},
year = {2010},
month = {01},
pages = {1-18},
title = {An Efficient Explanation of Individual Classifications using Game Theory},
volume = {11},
journal = {Journal of Machine Learning Research},
doi = {10.1145/1756006.1756007}
}

@article{lundberg2020local,
  title={From local explanations to global understanding with explainable AI for trees},
  author={Lundberg, Scott M and Erion, Gabriel and Chen, Hugh and DeGrave, Alex and Prutkin, Jordan M and Nair, Bala and Katz, Ronit and Himmelfarb, Jonathan and Bansal, Nisha and Lee, Su-In},
  journal={Nature machine intelligence},
  volume={2},
  number={1},
  pages={56--67},
  year={2020},
  publisher={Nature Publishing Group}
}

@article{meinshausen2010stability,
  title={Stability selection},
  author={Meinshausen, Nicolai and B{\"u}hlmann, Peter},
  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume={72},
  number={4},
  pages={417--473},
  year={2010},
  publisher={Wiley Online Library}
}

@article{yu2020veridical,
  title={Veridical data science},
  author={Yu, Bin and Kumbier, Karl},
  journal={Proceedings of the National Academy of Sciences},
  volume={117},
  number={8},
  pages={3920--3929},
  year={2020},
  publisher={National Acad Sciences}
}



@misc{LUCAS,
author = {Dataset LUCAS},
title = {LUCAS (LUng CAncer Simple set) dataset},
howpublished= {http://www.causality.inf.ethz.ch/data/LUCAS.html}
}

@article{Ishwaran2008,
  title={Random survival forests},
  author={Ishwaran, Hemant and Kogalur, Udaya B and Blackstone, Eugene H and Lauer, Michael S and others},
  journal={Annals of Applied Statistics},
  volume={2},
  number={3},
  pages={841--860},
  year={2008},
  publisher={Institute of Mathematical Statistics}
}

@article{barber2019predictive,
  title={Predictive inference with the jackknife+},
  author={Barber, Rina Foygel and Candes, Emmanuel J and Ramdas, Aaditya and Tibshirani, Ryan J},
  journal={arXiv preprint arXiv:1905.02928},
  year={2019}
}

@article{aas2021explaining,
  title={Explaining predictive models using Shapley values and non-parametric vine copulas},
  author={Aas, Kjersti and Nagler, Thomas and Jullum, Martin and L{\o}land, Anders},
  journal={arXiv preprint arXiv:2102.06416},
  year={2021}
}

@inproceedings{kumar2020problems,
  title={Problems with Shapley-value-based explanations as feature importance measures},
  author={Kumar, I Elizabeth and Venkatasubramanian, Suresh and Scheidegger, Carlos and Friedler, Sorelle},
  booktitle={International Conference on Machine Learning},
  pages={5491--5500},
  year={2020},
  organization={PMLR}
}


@article{alvarez2018robustness,
  title={On the robustness of interpretability methods},
  author={Alvarez-Melis, David and Jaakkola, Tommi S},
  journal={arXiv preprint arXiv:1806.08049},
  year={2018}
}

@article{sellereite2020shapr,
  title={shapr: An R-package for explaining machine learning models with dependence-aware Shapley values},
  author={Sellereite, Nikolai and Jullum, Martin},
  journal={Journal of Open Source Software},
  volume={5},
  number={46},
  pages={2027},
  year={2020}
}

@article{covert2020explaining,
  title={Explaining by Removing: A Unified Framework for Model Explanation},
  author={Covert, Ian and Lundberg, Scott and Lee, Su-In},
  journal={arXiv preprint arXiv:2011.14878},
  year={2020}
}

@article{frye2020shapley,
  title={Shapley explainability on the data manifold},
  author={Frye, Christopher and de Mijolla, Damien and Begley, Tom and Cowton, Laurence and Stanley, Megan and Feige, Ilya},
  journal={arXiv preprint arXiv:2006.01272},
  year={2020}
}

@article{au2021grouped,
  title={Grouped Feature Importance and Combined Features Effect Plot},
  author={Au, Quay and Herbinger, Julia and Stachl, Clemens and Bischl, Bernd and Casalicchio, Giuseppe},
  journal={arXiv preprint arXiv:2104.11688},
  year={2021}
}

@article{fryer2021shapley,
  title={Shapley values for feature selection: the good, the bad, and the axioms},
  author={Fryer, Daniel and Str{\"u}mke, Inga and Nguyen, Hien},
  journal={arXiv preprint arXiv:2102.10936},
  year={2021}
}


@inproceedings{liu2008isolation,
  title={Isolation forest},
  author={Liu, Fei Tony and Ting, Kai Ming and Zhou, Zhi-Hua},
  booktitle={2008 eighth ieee international conference on data mining},
  pages={413--422},
  year={2008},
  organization={IEEE}
}

@article{benard2021sirus,
  title={Sirus: Stable and interpretable rule set for classification},
  author={B{\'e}nard, Cl{\'e}ment and Biau, G{\'e}rard and Da Veiga, S{\'e}bastien and Scornet, Erwan},
  journal={Electronic Journal of Statistics},
  volume={15},
  number={1},
  pages={427--505},
  year={2021},
  publisher={Institute of Mathematical Statistics and Bernoulli Society}
}

@article{shih2018symbolic,
  title={A symbolic approach to explaining bayesian network classifiers},
  author={Shih, Andy and Choi, Arthur and Darwiche, Adnan},
  journal={arXiv preprint arXiv:1805.03364},
  year={2018}
}

@inproceedings{ignatiev2019abduction,
  title={Abduction-based explanations for machine learning models},
  author={Ignatiev, Alexey and Narodytska, Nina and Marques-Silva, Joao},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={1511--1519},
  year={2019}
}

@article{darwiche2020reasons,
  title={On the reasons behind decisions},
  author={Darwiche, Adnan and Hirth, Auguste},
  journal={arXiv preprint arXiv:2002.09284},
  year={2020}
}

@article{audemard2021explanatory,
  title={On the Explanatory Power of Decision Trees},
  author={Audemard, Gilles and Bellart, Steve and Bounia, Louenas and Koriche, Fr{\'e}d{\'e}ric and Lagniez, Jean-Marie and Marquis, Pierre},
  journal={arXiv preprint arXiv:2108.05266},
  year={2021}
}

@techreport{choi2020probabilistic,
  title={Probabilistic circuits: A unifying framework for tractable probabilistic models},
  author={Choi, YooJung and Vergari, Antonio and Van den Broeck, Guy},
  year={2020},
  institution={Technical report}
}

@article{amoukou2021accurate,
  title={Accurate and robust Shapley Values for explaining predictions and focusing on local important variables},
  author={Amoukou, Salim I and Brunel, Nicolas JB and Sala{\"u}n, Tangi},
  journal={arXiv preprint arXiv:2106.03820},
  year={2021}
}

@article{ghalebikesabi2021locality,
  title={On Locality of Local Explanation Models},
  author={Ghalebikesabi, Sahra and Ter-Minassian, Lucile and Diaz-Ordaz, Karla and Holmes, Chris},
  journal={arXiv preprint arXiv:2106.14648},
  year={2021}
}

@article{ignatiev2019validating,
  title={On validating, repairing and refining heuristic ML explanations},
  author={Ignatiev, Alexey and Narodytska, Nina and Marques-Silva, Joao},
  journal={arXiv preprint arXiv:1907.02509},
  year={2019}
}

@inproceedings{slack2020fooling,
  title={Fooling lime and shap: Adversarial attacks on post hoc explanation methods},
  author={Slack, Dylan and Hilgard, Sophie and Jia, Emily and Singh, Sameer and Lakkaraju, Himabindu},
  booktitle={Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society},
  pages={180--186},
  year={2020}
}

@inproceedings{jethani2021have,
  title={Have We Learned to Explain?: How Interpretability Methods Can Learn to Encode Predictions in their Interpretations.},
  author={Jethani, Neil and Sudarshan, Mukund and Aphinyanaphongs, Yindalon and Ranganath, Rajesh},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1459--1467},
  year={2021},
  organization={PMLR}
}

@article{ArenalGutirrez1996UnconditionalGTBoostrap,
  title={Unconditional Glivenko-Cantelli-type theorems and weak laws of large numbers for bootstrap},
  author={Eusebio Arenal-Guti{\'e}rrez and Carlos Matr{\'a}n and Juan Antonio Cuesta-Albertos},
  journal={Statistics \& Probability Letters},
  year={1996},
  volume={26},
  pages={365-375}
}


@inproceedings{Vapnik1971ChervonenkisOTFrequencies,
  title={Chervonenkis: On the uniform convergence of relative frequencies of events to their probabilities},
  author={Vladimir Naumovich Vapnik},
  year={1971}
}

@article{Gosiewska2019DoNT,
  title={Do Not Trust Additive Explanations},
  author={Alicja Gosiewska and P. Biecek},
  journal={arXiv: Learning},
  year={2019}
}

@misc{Dua:2019 ,
author = "Dua, Dheeru and Graff, Casey",
year = "2017",
title = "{UCI} Machine Learning Repository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences" }


@article{imodels2021,
  title={imodels: a python package for fitting interpretable models},
  author={Singh, Chandan and Nasseri, Keyan and Tan, Yan Shuo and Tang, Tiffany and Yu, Bin},
  journal={Journal of Open Source Software},
  volume={6},
  number={61},
  pages={3192},
  year={2021}
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}


@article{rawal2020beyond,
  title={Beyond individualized recourse: Interpretable and interactive summaries of actionable recourses},
  author={Rawal, Kaivalya and Lakkaraju, Himabindu},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={12187--12198},
  year={2020}
}

@misc{globalce,
  doi = {10.48550/ARXIV.2204.06917},
  
  url = {https://arxiv.org/abs/2204.06917},
  
  author = {Ley, Dan and Mishra, Saumitra and Magazzeni, Daniele},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Computers and Society (cs.CY), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Global Counterfactual Explanations: Investigations, Implementations and Improvements},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{survey_counterfactual,
  author    = {Amir{-}Hossein Karimi and
               Gilles Barthe and
               Bernhard Sch{\"{o}}lkopf and
               Isabel Valera},
  title     = {A survey of algorithmic recourse: definitions, formulations, solutions,
               and prospects},
  journal   = {CoRR},
  volume    = {abs/2010.04050},
  year      = {2020},
  url       = {https://arxiv.org/abs/2010.04050},
  eprinttype = {arXiv},
  eprint    = {2010.04050},
  timestamp = {Tue, 13 Oct 2020 15:25:23 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2010-04050.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{optimalce_vidal,
  author    = {Axel Parmentier and
               Thibaut Vidal},
  title     = {Optimal Counterfactual Explanations in Tree Ensembles},
  journal   = {CoRR},
  volume    = {abs/2106.06631},
  year      = {2021},
  url       = {https://arxiv.org/abs/2106.06631},
  eprinttype = {arXiv},
  eprint    = {2106.06631},
  timestamp = {Tue, 15 Jun 2021 16:35:15 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2106-06631.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{face_counterfactual,
  author    = {Rafael Poyiadzi and
               Kacper Sokol and
               Ra{\'{u}}l Santos{-}Rodriguez and
               Tijl De Bie and
               Peter A. Flach},
  title     = {{FACE:} Feasible and Actionable Counterfactual Explanations},
  journal   = {CoRR},
  volume    = {abs/1909.09369},
  year      = {2019},
  url       = {http://arxiv.org/abs/1909.09369},
  eprinttype = {arXiv},
  eprint    = {1909.09369},
  timestamp = {Thu, 14 Oct 2021 09:17:24 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1909-09369.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{prototype_basedce,
  author    = {Arnaud Van Looveren and
               Janis Klaise},
  title     = {Interpretable Counterfactual Explanations Guided by Prototypes},
  journal   = {CoRR},
  volume    = {abs/1907.02584},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.02584},
  eprinttype = {arXiv},
  eprint    = {1907.02584},
  timestamp = {Mon, 08 Jul 2019 14:12:33 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1907-02584.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{counterfactual_r2,
  author    = {Yu{-}Liang Chou and
               Catarina Moreira and
               Peter Bruza and
               Chun Ouyang and
               Joaquim A. Jorge},
  title     = {Counterfactuals and Causability in Explainable Artificial Intelligence:
               Theory, Algorithms, and Applications},
  journal   = {CoRR},
  volume    = {abs/2103.04244},
  year      = {2021},
  url       = {https://arxiv.org/abs/2103.04244},
  eprinttype = {arXiv},
  eprint    = {2103.04244},
  timestamp = {Fri, 19 Mar 2021 08:43:26 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2103-04244.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{counterfactual_r1,
  author    = {Sahil Verma and
               John P. Dickerson and
               Keegan Hines},
  title     = {Counterfactual Explanations for Machine Learning: {A} Review},
  journal   = {CoRR},
  volume    = {abs/2010.10596},
  year      = {2020},
  url       = {https://arxiv.org/abs/2010.10596},
  eprinttype = {arXiv},
  eprint    = {2010.10596},
  timestamp = {Mon, 26 Oct 2020 15:39:44 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2010-10596.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{dice,
author = {Mothilal, Ramaravind K. and Sharma, Amit and Tan, Chenhao},
title = {Explaining Machine Learning Classifiers through Diverse Counterfactual Explanations},
year = {2020},
isbn = {9781450369367},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3351095.3372850},
doi = {10.1145/3351095.3372850},
abstract = {Post-hoc explanations of machine learning models are crucial for people to understand and act on algorithmic predictions. An intriguing class of explanations is through counterfactuals, hypothetical examples that show people how to obtain a different prediction. We posit that effective counterfactual explanations should satisfy two properties: feasibility of the counterfactual actions given user context and constraints, and diversity among the counterfactuals presented. To this end, we propose a framework for generating and evaluating a diverse set of counterfactual explanations based on determinantal point processes. To evaluate the actionability of counterfactuals, we provide metrics that enable comparison of counterfactual-based methods to other local explanation methods. We further address necessary tradeoffs and point to causal implications in optimizing for counterfactuals. Our experiments on four real-world datasets show that our framework can generate a set of counterfactuals that are diverse and well approximate local decision boundaries, outperforming prior approaches to generating diverse counterfactuals. We provide an implementation of the framework at https://github.com/microsoft/DiCE.},
booktitle = {Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
pages = {607–617},
numpages = {11},
location = {Barcelona, Spain},
series = {FAT* '20}
}

@article{Karimi2020ModelAgnosticCE,
  title={Model-Agnostic Counterfactual Explanations for Consequential Decisions},
  author={Amir-Hossein Karimi and Gilles Barthe and Borja Balle and Isabel Valera},
  journal={ArXiv},
  year={2020},
  volume={abs/1905.11190}
}

@inproceedings{diverce_ce,
author = {Russell, Chris},
title = {Efficient Search for Diverse Coherent Explanations},
year = {2019},
isbn = {9781450361255},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3287560.3287569},
doi = {10.1145/3287560.3287569},
abstract = {This paper proposes new search algorithms for counterfactual explanations based upon mixed integer programming. We are concerned with complex data in which variables may take any value from a contiguous range or an additional set of discrete states. We propose a novel set of constraints that we refer to as a "mixed polytope" and show how this can be used with an integer programming solver to efficiently find coherent counterfactual explanations i.e. solutions that are guaranteed to map back onto the underlying data structure, while avoiding the need for brute-force enumeration. We also look at the problem of diverse explanations and show how these can be generated within our framework.},
booktitle = {Proceedings of the Conference on Fairness, Accountability, and Transparency},
pages = {20–28},
numpages = {9},
keywords = {Counterfactual Explanation, Linear Program, Machine Learning},
location = {Atlanta, GA, USA},
series = {FAT* '19}
}



@article{rethinkinxai,
  author    = {Himabindu Lakkaraju and
               Dylan Slack and
               Yuxin Chen and
               Chenhao Tan and
               Sameer Singh},
  title     = {Rethinking Explainability as a Dialogue: {A} Practitioner's Perspective},
  journal   = {CoRR},
  volume    = {abs/2202.01875},
  year      = {2022},
  url       = {https://arxiv.org/abs/2202.01875},
  eprinttype = {arXiv},
  eprint    = {2202.01875},
  timestamp = {Wed, 09 Feb 2022 15:43:35 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2202-01875.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Ustun2019ActionableRI,
  title={Actionable Recourse in Linear Classification},
  author={Berk Ustun and Alexander Spangher and Yang Liu},
  journal={Proceedings of the Conference on Fairness, Accountability, and Transparency},
  year={2019}
}

@article{Wachter2017CounterfactualEW,
  title={Counterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR},
  author={Sandra Wachter and Brent Daniel Mittelstadt and Chris Russell},
  journal={Cybersecurity},
  year={2017}
}

  

@article{CHOU202259,
title = {Counterfactuals and causability in explainable artificial intelligence: Theory, algorithms, and applications},
journal = {Information Fusion},
volume = {81},
pages = {59-83},
year = {2022},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2021.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S1566253521002281},
author = {Yu-Liang Chou and Catarina Moreira and Peter Bruza and Chun Ouyang and Joaquim Jorge},
keywords = {Deep learning, Explainable AI, Causability, Counterfactuals, Causality},
abstract = {Deep learning models have achieved high performance across different domains, such as medical decision-making, autonomous vehicles, decision support systems, among many others. However, despite this success, the inner mechanisms of these models are opaque because their internal representations are too complex for a human to understand. This opacity makes it hard to understand the how or the why of the predictions of deep learning models. There has been a growing interest in model-agnostic methods that make deep learning models more transparent and explainable to humans. Some researchers recently argued that for a machine to achieve human-level explainability, this machine needs to provide human causally understandable explanations, also known as causability. A specific class of algorithms that have the potential to provide causability are counterfactuals. This paper presents an in-depth systematic review of the diverse existing literature on counterfactuals and causability for explainable artificial intelligence (AI). We performed a Latent Dirichlet topic modelling analysis (LDA) under a Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) framework to find the most relevant literature articles. This analysis yielded a novel taxonomy that considers the grounding theories of the surveyed algorithms, together with their underlying properties and applications to real-world data. Our research suggests that current model-agnostic counterfactual algorithms for explainable AI are not grounded on a causal theoretical formalism and, consequently, cannot promote causability to a human decision-maker. Furthermore, our findings suggest that the explanations derived from popular algorithms in the literature provide spurious correlations rather than cause/effects relationships, leading to sub-optimal, erroneous, or even biased explanations. Thus, this paper also advances the literature with new directions and challenges on promoting causability in model-agnostic approaches for explainable AI.}
}

@inproceedings{dace,
  title={DACE: Distribution-Aware Counterfactual Explanation by Mixed-Integer Linear Optimization},
  author={Kentaro Kanamori and Takuya Takagi and Ken Kobayashi and Hiroki Arimura},
  booktitle={IJCAI},
  year={2020}
}


@inproceedings{cet4,
  title={Counterfactual Explanation Trees: Transparent and Consistent Actionable Recourse with Decision Trees},
  author={Kentaro Kanamori and Takuya Takagi and Ken Kobayashi and Yuichi Ike},
  booktitle={Proceedings of The 25th International Conference on Artificial Intelligence and Statistics, PMLR 151:1846-1870},
  year={2022}
}

@article{Loh2011ClassificationAR,
  title={Classification and regression trees},
  author={Wei-Yin Loh},
  journal={Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
  year={2011},
  volume={1}
}

@inproceedings{review_simulated_annealing,
author = {Guilmeau, Thomas and Chouzenoux, Emilie and Elvira, Víctor},
year = {2021},
month = {07},
pages = {101-105},
title = {Simulated Annealing: a Review and a New Scheme},
doi = {10.1109/SSP49050.2021.9513782}
}

@inproceedings{
    sdv,
    author={N. {Patki} and R. {Wedge} and K. {Veeramachaneni}},
    booktitle={2016 IEEE International Conference on Data Science and Advanced Analytics (DSAA)},
    title={The Synthetic Data Vault},
    year={2016},
    volume={},
    number={},
    pages={399-410},
    keywords={data analysis;relational databases;synthetic data vault;SDV;generative model;relational database;multivariate modelling;predictive model;data analysis;data science;Data models;Databases;Computational modeling;Predictive models;Hidden Markov models;Numerical models;Synthetic data generation;crowd sourcing;data science;predictive modeling},
    doi={10.1109/DSAA.2016.49},
    ISSN={},
    month={Oct}
}

@inproceedings{modeling_td,
  title={Modeling Tabular data using Conditional GAN},
  author={Lei Xu and Maria Skoularidou and Alfredo Cuesta-Infante and Kalyan Veeramachaneni},
  booktitle={NeurIPS},
  year={2019}
}

@article{california_data,
title = {Sparse spatial autoregressions},
journal = {Statistics, Probability Letters},
volume = {33},
number = {3},
pages = {291-297},
year = {1997},
issn = {0167-7152},
doi = {https://doi.org/10.1016/S0167-7152(96)00140-X},
url = {https://www.sciencedirect.com/science/article/pii/S016771529600140X},
author = {R. {Kelley Pace} and Ronald Barry},
keywords = {Spatial autoregression, SAR, Sparse matrices},
abstract = {Given local spatial error dependence, one can construct sparse spatial weight matrices. As an illustration of the power of such sparse structures, we computed a simultaneous autoregression using 20 640 observations in under 19 min despite needing to compute a 20 640 by 20 640 determinant 10 times.}
}

@misc{winedata,
author = "M. Lichman",
year = "2013",
title = "{UCI} Machine Learning Repository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences" }

@misc{compasdata,
author = "Jeff Larson and Surya Mattu and Lauren Kirchner and and Julia Angwin",
year = "2016",
title = " How we analyzed the compas recidivism algorithm",
url = "https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm."}

@misc{helocdata,
author = "FICO",
year = "2018",
title = " FICO. Explainable machine learning challenge",
url = "https://community.fico.com/
s/explainable-machine-learning-challenge."}

@misc{nhanes,
author = "CDC",
year = "1999-2022",
title = "National Health and Nutrition Examination Survey",
url = "https://wwwn.cdc.gov/Nchs/Nhanes/Default.aspx."}

@inbook{yanebm,
author = {Lecun, Yann and Chopra, Sumit and Hadsell, Raia},
year = {2006},
month = {01},
pages = {},
title = {A tutorial on energy-based learning}
}

@inproceedings{ebmduvenaud,
  title={Your classifier is secretly an energy based model and you should treat it like one},
  author={Grathwohl, Will and Wang, Kuan-Chieh and Jacobsen, Joern-Henrik and Duvenaud, David and Norouzi, Mohammad and Swersky, Kevin},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{bayesianRuleListRudin,
  title={A Bayesian Framework for Learning Rule Sets for Interpretable Classification},
  author={Tong Wang and Cynthia Rudin and Finale Doshi-Velez and Yimin Liu and Erica Klampfl and Perry MacNeille},
  journal={J. Mach. Learn. Res.},
  year={2017},
  volume={18},
  pages={70:1-70:37}
}

@article{OptimalDecisionTreeRudin,
  title={Generalized Optimal Sparse Decision Trees},
  author={Jimmy J. Lin and Chudi Zhong and Diane Hu and Cynthia Rudin and Margo I. Seltzer},
  journal={ArXiv},
  year={2020},
  volume={abs/2006.08690}
}

@misc{himanoisycounterfactuals,
  doi = {10.48550/ARXIV.2203.06768},
  
  url = {https://arxiv.org/abs/2203.06768},
  
  author = {Pawelczyk, Martin and Datta, Teresa and van-den-Heuvel, Johannes and Kasneci, Gjergji and Lakkaraju, Himabindu},
  
  keywords = {Machine Learning (cs.LG), Computers and Society (cs.CY), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Algorithmic Recourse in the Face of Noisy Human Responses},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@inproceedings{black2020fliptest,
  title={Fliptest: fairness testing via optimal transport},
  author={Black, Emily and Yeom, Samuel and Fredrikson, Matt},
  booktitle={Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
  pages={111--121},
  year={2020}
}

@article{de2021transport,
  title={Transport-based counterfactual models},
  author={De Lara, Lucas and Gonz{\'a}lez-Sanz, Alberto and Asher, Nicholas and Loubes, Jean-Michel},
  journal={arXiv preprint arXiv:2108.13025},
  year={2021}
}

@article{wilks1941determination,
  title={Determination of sample sizes for setting tolerance limits},
  author={Wilks, Samuel S},
  journal={The Annals of Mathematical Statistics},
  volume={12},
  number={1},
  pages={91--96},
  year={1941},
  publisher={JSTOR}
}

@article{wald1943extension,
  title={An extension of Wilks' method for setting tolerance limits},
  author={Wald, Abraham},
  journal={The Annals of Mathematical Statistics},
  volume={14},
  number={1},
  pages={45--55},
  year={1943},
  publisher={JSTOR}
}

@misc{diabetes,
author = "Kaggle",
year = "2016",
title = "Pima Indians Diabetes Database",
url = "https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database"}


@article{basu2018iterative,
  title={Iterative random forests to discover predictive and stable high-order interactions},
  author={Basu, Sumanta and Kumbier, Karl and Brown, James B and Yu, Bin},
  journal={Proceedings of the National Academy of Sciences},
  volume={115},
  number={8},
  pages={1943--1948},
  year={2018},
  publisher={National Acad Sciences}
}

@article{lundbergshap,
  title={A unified approach to interpreting model predictions},
  author={Lundberg, Scott M and Lee, Su-In},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}


@article{sage,
  author    = {Ian Covert and
               Scott Lundberg and
               Su{-}In Lee},
  title     = {Understanding Global Feature Contributions Through Additive Importance
               Measures},
  journal   = {CoRR},
  volume    = {abs/2004.00668},
  year      = {2020},
  url       = {https://arxiv.org/abs/2004.00668},
  eprinttype = {arXiv},
  eprint    = {2004.00668},
  timestamp = {Wed, 08 Apr 2020 17:08:25 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2004-00668.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{improvingkernelCovert,
  author    = {Ian Covert and
               Su{-}In Lee},
  title     = {Improving KernelSHAP: Practical Shapley Value Estimation via Linear
               Regression},
  journal   = {CoRR},
  volume    = {abs/2012.01536},
  year      = {2020},
  url       = {https://arxiv.org/abs/2012.01536},
  eprinttype = {arXiv},
  eprint    = {2012.01536},
  timestamp = {Fri, 04 Dec 2020 12:07:23 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2012-01536.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{williamson2020efficient,
      title={Efficient nonparametric statistical inference on population feature importance using Shapley values}, 
      author={Brian D. Williamson and Jean Feng},
      year={2020},
      eprint={2006.09481},
      archivePrefix={arXiv},
      primaryClass={stat.ME}
}

@inproceedings{grunewalder2018plug,
  title={Plug-in estimators for conditional expectations and probabilities},
  author={Grunewalder, Steffen},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1513--1521},
  year={2018},
  organization={PMLR}
}

@article{williamson2021general,
  title={A general framework for inference on algorithm-agnostic variable importance},
  author={Williamson, Brian D and Gilbert, Peter B and Simon, Noah R and Carone, Marco},
  journal={Journal of the American Statistical Association},
  pages={1--14},
  year={2021},
  publisher={Taylor \& Francis}
}

@article{nori2019interpretml,
  title={InterpretML: A Unified Framework for Machine Learning Interpretability},
  author={Nori, Harsha and Jenkins, Samuel and Koch, Paul and Caruana, Rich},
  journal={arXiv preprint arXiv:1909.09223},
  year={2019}
}

@inproceedings{lou2012intelligible,
  title={Intelligible models for classification and regression},
  author={Lou, Yin and Caruana, Rich and Gehrke, Johannes},
  booktitle={Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={150--158},
  year={2012}
}

@article{feldman2005relative,
  title={Relative importance and value},
  author={Feldman, Barry E},
  journal={Available at SSRN 2255827},
  year={2005}
}

@article{johnson2004history,
  title={History and use of relative importance indices in organizational research},
  author={Johnson, Jeff W and LeBreton, James M},
  journal={Organizational research methods},
  volume={7},
  number={3},
  pages={238--257},
  year={2004},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}

@article{gromping2007estimators,
  title={Estimators of relative importance in linear regression based on variance decomposition},
  author={Gr{\"o}mping, Ulrike},
  journal={The American Statistician},
  volume={61},
  number={2},
  pages={139--147},
  year={2007},
  publisher={Taylor \& Francis}
}

@inproceedings{garreau2020explaining,
  title={Explaining the explainer: A first theoretical analysis of LIME},
  author={Garreau, Damien and Luxburg, Ulrike},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1287--1296},
  year={2020},
  organization={PMLR}
}

@article{hastie1987generalized,
  title={Generalized additive models: some applications},
  author={Hastie, Trevor and Tibshirani, Robert},
  journal={Journal of the American Statistical Association},
  volume={82},
  number={398},
  pages={371--386},
  year={1987},
  publisher={Taylor \& Francis}
}

@InProceedings{pmlr-v151-amoukou22a,
  title = 	 { Accurate Shapley Values for explaining tree-based models },
  author =       {Amoukou, Salim I. and Sala\"un, Tangi and Brunel, Nicolas},
  booktitle = 	 {Proceedings of The 25th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {2448--2465},
  year = 	 {2022},
  editor = 	 {Camps-Valls, Gustau and Ruiz, Francisco J. R. and Valera, Isabel},
  volume = 	 {151},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {28--30 Mar},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v151/amoukou22a/amoukou22a.pdf},
  url = 	 {https://proceedings.mlr.press/v151/amoukou22a.html},
  abstract = 	 { Although Shapley Values (SV) are widely used in explainable AI, they can be poorly understood and estimated, implying that their analysis may lead to spurious inferences and explanations. As a starting point, we remind an invariance principle for SV and derive the correct approach for computing the SV of categorical variables that are particularly sensitive to the encoding used. In the case of tree-based models, we introduce two estimators of Shapley Values that exploit the tree structure efficiently and are more accurate than state-of-the-art methods. Simulations and comparisons are performed with state-of-the-art algorithms and show the practical gain of our approach. Finally, we discuss the ability of SV to provide reliable local explanations. We also provide a Python package that compute our estimators at https://github.com/salimamoukou/acv00. }
}

@article{dhurandhar2018explanations,
  title={Explanations based on the missing: Towards contrastive explanations with pertinent negatives},
  author={Dhurandhar, Amit and Chen, Pin-Yu and Luss, Ronny and Tu, Chun-Chen and Ting, Paishun and Shanmugam, Karthikeyan and Das, Payel},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{klusowski2020sparse,
  title={Sparse learning with CART},
  author={Klusowski, Jason},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={11612--11622},
  year={2020}
}

@article{breiman2003setting,
  title={Setting up, using, and understanding random forests V4. 0},
  author={Breiman, Leo and Cutler, A},
  journal={University of California, Department of Statistics},
  year={2003}
}

@misc{bikesharing,
author = "Kaggle",
year = "2015",
title = "Bike Sharing Demand",
url = "https://www.kaggle.com/c/bike-sharing-demand"}

@misc{attrition,
author = "Kaggle",
year = "2017",
title = "IBM HR Analytics Employee
Attrition Performance",
url = "www.kaggle.com/pavansubhasht/
ibm-hr-analytics-attrition-dataset"}

@article{owen2017shapley,
  title={On Shapley value for measuring importance of dependent inputs},
  author={Owen, Art B and Prieur, Cl{\'e}mentine},
  journal={SIAM/ASA Journal on Uncertainty Quantification},
  volume={5},
  number={1},
  pages={986--1002},
  year={2017},
  publisher={SIAM}
}

@inproceedings{chen2016xgboost,
  title={Xgboost: A scalable tree boosting system},
  author={Chen, Tianqi and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining},
  pages={785--794},
  year={2016}
}

@article{pedregosa2011scikit,
  title={Scikit-learn: Machine learning in Python},
  author={Pedregosa, Fabian and Varoquaux, Ga{\"e}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and others},
  journal={the Journal of machine Learning research},
  volume={12},
  pages={2825--2830},
  year={2011},
  publisher={JMLR. org}
}

@article{lin2021locally,
  title={Locally valid and discriminative prediction intervals for deep learning models},
  author={Lin, Zhen and Trivedi, Shubhendu and Sun, Jimeng},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={8378--8391},
  year={2021}
}