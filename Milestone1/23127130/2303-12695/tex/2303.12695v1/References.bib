@book{adams1995hitchhiker,
  title={The Hitchhiker's Guide to the Galaxy},
  author={Adams, D.},
  isbn={9781417642595},
  url={http://books.google.com/books?id=W-xMPgAACAAJ},
  year={1995},
  publisher={San Val}
}

@article{koenker2001quantile,
  title={Quantile regression},
  author={Koenker, Roger and Hallock, Kevin F},
  journal={Journal of economic perspectives},
  volume={15},
  number={4},
  pages={143--156},
  year={2001}
}
@article{meinshausen2006quantile,
  title={Quantile regression forests.},
  author={Meinshausen, Nicolai and Ridgeway, Greg},
  journal={Journal of Machine Learning Research},
  volume={7},
  number={6},
  year={2006}
}

@article{breiman2001random,
  title={Random forests},
  author={Breiman, Leo},
  journal={Machine learning},
  volume={45},
  number={1},
  pages={5--32},
  year={2001},
  publisher={Springer}
}

@article{benard2021shaff,
  title={SHAFF: Fast and consistent SHApley eFfect estimates via random Forests},
  author={B{\'e}nard, Cl{\'e}ment and Biau, G{\'e}rard and Da Veiga, S{\'e}bastien and Scornet, Erwan},
  journal={arXiv preprint arXiv:2105.11724},
  year={2021}
}

@article{benard2021mda,
  title={MDA for random forests: inconsistency, and a practical solution via the Sobol-MDA},
  author={B{\'e}nard, Cl{\'e}ment and Da Veiga, S{\'e}bastien and Scornet, Erwan},
  journal={arXiv preprint arXiv:2102.13347},
  year={2021}
}

@article{amit1997shape,
  title={Shape quantization and recognition with randomized trees},
  author={Amit, Yali and Geman, Donald},
  journal={Neural computation},
  volume={9},
  number={7},
  pages={1545--1588},
  year={1997},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{breiman1984classification,
  title={Classification and regression trees. Wadsworth Int},
  author={Breiman, Leo and Friedman, Jerome and Olshen, Richard and Stone, Charles},
  journal={Group},
  volume={37},
  number={15},
  pages={237--251},
  year={1984}
}

@article{lin2006random,
  title={Random forests and adaptive nearest neighbors},
  author={Lin, Yi and Jeon, Yongho},
  journal={Journal of the American Statistical Association},
  volume={101},
  number={474},
  pages={578--590},
  year={2006},
  publisher={Taylor \& Francis}
}

@article{ishwaran2008random,
  title={Random survival forests},
  author={Ishwaran, Hemant and Kogalur, Udaya B and Blackstone, Eugene H and Lauer, Michael S},
  journal={The annals of applied statistics},
  volume={2},
  number={3},
  pages={841--860},
  year={2008},
  publisher={Institute of Mathematical Statistics}
}

@misc{wager2017estimation,
      title={Estimation and Inference of Heterogeneous Treatment Effects using Random Forests}, 
      author={Stefan Wager and Susan Athey},
      year={2017},
      eprint={1510.04342},
      archivePrefix={arXiv},
      primaryClass={stat.ME}
}

@inproceedings{du2021wasserstein,
  title={Wasserstein Random Forests and Applications in Heterogeneous Treatment Effects},
  author={Du, Qiming and Biau, G{\'e}rard and Petit, Fran{\c{c}}ois and Porcher, Rapha{\"e}l},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1729--1737},
  year={2021},
  organization={PMLR}
}

@article{elie2020random,
  title={Random forest estimation of conditional distribution functions and conditional quantiles},
  author={Elie-Dit-Cosaque, Kevin and Maume-Deschamps, V{\'e}ronique},
  journal={arXiv preprint arXiv:2006.06998},
  year={2020}
}

@article{scornet2015consistency,
  title={Consistency of random forests},
  author={Scornet, Erwan and Biau, G{\'e}rard and Vert, Jean-Philippe},
  journal={The Annals of Statistics},
  volume={43},
  number={4},
  pages={1716--1741},
  year={2015},
  publisher={Institute of Mathematical Statistics}
}

@article{biau2012analysis,
  title={Analysis of a random forests model},
  author={Biau, G{\'e}rard},
  journal={The Journal of Machine Learning Research},
  volume={13},
  pages={1063--1095},
  year={2012},
  publisher={JMLR. org}
}

@article{goehry2020random,
  title={Random forests for time-dependent processes},
  author={Goehry, Benjamin},
  journal={ESAIM: Probability and Statistics},
  volume={24},
  pages={801--826},
  year={2020}
}

@article{mentch2016quantifying,
  title={Quantifying uncertainty in random forests via confidence intervals and hypothesis tests},
  author={Mentch, Lucas and Hooker, Giles},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={841--881},
  year={2016},
  publisher={JMLR. org}
}

@book{gyorfi2002distribution,
  title={A distribution-free theory of nonparametric regression},
  author={Gy{\"o}rfi, L{\'a}szl{\'o} and Kohler, Michael and Krzy{\.z}ak, Adam and Walk, Harro},
  volume={1},
  year={2002},
  publisher={Springer}
}

@inproceedings{wang2020towards,
  title={Towards Probabilistic Sufficient Explanations},
  author={Wang, Eric and Khosravi, Pasha and Van den Broeck, Guy},
  booktitle={Extending Explainable AI Beyond Deep Models and Classifiers Workshop at ICML (XXAI)},
  year={2020}
}

@inproceedings{Chen2012TheSP,
  title={The Same-Decision Probability: A New Tool for Decision Making},
  author={S. Chen and Arthur Choi and Adnan Darwiche},
  year={2012}
}

@inproceedings{benard2021interpretable,
  title={Interpretable random forests via rule extraction},
  author={B{\'e}nard, Cl{\'e}ment and Biau, G{\'e}rard and Veiga, S{\'e}bastien and Scornet, Erwan},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={937--945},
  year={2021},
  organization={PMLR}
}

@article{amoukou2021consistent,
  title={Consistent Sufficient Explanations and Minimal Local Rules for explaining regression and classification models},
  author={Amoukou, Salim I and Brunel, Nicolas JB},
  journal={arXiv preprint arXiv:2111.04658},
  year={2021}
}

@inproceedings{Papadopoulos2002InductiveCM,
  title={Inductive Confidence Machines for Regression},
  author={Harris Papadopoulos and Kostas Proedrou and Vladimir Vovk and Alexander Gammerman},
  booktitle={European Conference on Machine Learning},
  year={2002}
}

@article{Lei2016DistributionFreePI,
  title={Distribution-Free Predictive Inference for Regression},
  author={Jing Lei and Max G'Sell and Alessandro Rinaldo and Ryan J. Tibshirani and Larry A. Wasserman},
  journal={Journal of the American Statistical Association},
  year={2016},
  volume={113},
  pages={1094 - 1111}
}

@article{Vovk2012CrossconformalP,
  title={Cross-conformal predictors},
  author={Vladimir Vovk},
  journal={Annals of Mathematics and Artificial Intelligence},
  year={2012},
  volume={74},
  pages={9-28}
}

@article{romano2019conformalized,
  title={Conformalized quantile regression},
  author={Romano, Yaniv and Patterson, Evan and Candes, Emmanuel},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{papadopoulos2008normalized,
  title={Normalized nonconformity measures for regression conformal prediction},
  author={Papadopoulos, Harris and Gammerman, Alex and Vovk, Volodya},
  booktitle={Proceedings of the IASTED International Conference on Artificial Intelligence and Applications (AIA 2008)},
  pages={64--69},
  year={2008}
}

@article{guanlocalizer,
    author = {Guan, Leying},
    title = "{Localized conformal prediction: a generalized inference framework for conformal prediction}",
    journal = {Biometrika},
    year = {2022},
    month = {07},
    abstract = "{We propose a new inference framework called localized conformal prediction. It generalizes the framework of conformal prediction by offering a single-test-sample adaptive construction that emphasizes a local region around this test sample, and can be combined with different conformal scores. The proposed framework enjoys an assumption-free finite sample marginal coverage guarantee, and it also offers additional local coverage guarantees under suitable assumptions. We demonstrate how to change from conformal prediction to localized conformal prediction using several conformal scores, and we illustrate a potential gain via numerical examples.}",
    issn = {1464-3510},
    doi = {10.1093/biomet/asac040},
    url = {https://doi.org/10.1093/biomet/asac040},
    note = {asac040},
    eprint = {https://academic.oup.com/biomet/advance-article-pdf/doi/10.1093/biomet/asac040/45911782/asac040.pdf},
}

@article{han2022split,
  title={Split Localized Conformal Prediction},
  author={Han, Xing and Tang, Ziyang and Ghosh, Joydeep and Liu, Qiang},
  journal={arXiv preprint arXiv:2206.13092},
  year={2022}
}

@article{nadaraya1964estimating,
  title={On estimating regression},
  author={Nadaraya, Elizbar A},
  journal={Theory of Probability \& Its Applications},
  volume={9},
  number={1},
  pages={141--142},
  year={1964},
  publisher={SIAM}
}

@article{bian2022training,
  title={Training-conditional coverage for distribution-free predictive inference},
  author={Bian, Michael and Barber, Rina Foygel},
  journal={arXiv preprint arXiv:2205.03647},
  year={2022}
}

@article{barber2022conformal,
  title={Conformal prediction beyond exchangeability},
  author={Barber, Rina Foygel and Candes, Emmanuel J and Ramdas, Aaditya and Tibshirani, Ryan J},
  journal={arXiv preprint arXiv:2202.13415},
  year={2022}
}

@article{tibshirani2019conformal,
  title={Conformal prediction under covariate shift},
  author={Tibshirani, Ryan J and Foygel Barber, Rina and Candes, Emmanuel and Ramdas, Aaditya},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{vovk2012conditional,
  title={Conditional validity of inductive conformal predictors},
  author={Vovk, Vladimir},
  booktitle={Asian conference on machine learning},
  pages={475--490},
  year={2012},
  organization={PMLR}
}

@article{kim2020predictive,
  title={Predictive inference is free with the jackknife+-after-bootstrap},
  author={Kim, Byol and Xu, Chen and Barber, Rina},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={4138--4149},
  year={2020}
}

@article{Barber2019,
   abstract = {We consider the problem of distribution-free predictive inference, with the goal of producing predictive coverage guarantees that hold conditionally rather than marginally. Existing methods such as conformal prediction offer marginal coverage guarantees, where predictive coverage holds on average over all possible test points, but this is not sufficient for many practical applications where we would like to know that our predictions are valid for a given individual, not merely on average over a population. On the other hand, exact conditional inference guarantees are known to be impossible without imposing assumptions on the underlying distribution. In this work we aim to explore the space in between these two, and examine what types of relaxations of the conditional coverage property would alleviate some of the practical concerns with marginal coverage guarantees while still being possible to achieve in a distribution-free setting.},
   author = {Rina Foygel Barber and Emmanuel J. Candès and Aaditya Ramdas and Ryan J. Tibshirani},
   doi = {10.1093/imaiai/iaaa017},
   issn = {20498772},
   issue = {2},
   journal = {Information and Inference},
   keywords = {conformal prediction,distribution-free inference,predictive inference},
   month = {3},
   pages = {455-482},
   title = {The limits of distribution-free conditional predictive inference},
   volume = {10},
   url = {http://arxiv.org/abs/1903.04684},
   year = {2019},
}




@article{barber2021predictive,
  title={Predictive inference with the jackknife+},
  author={Barber, Rina Foygel and Candes, Emmanuel J and Ramdas, Aaditya and Tibshirani, Ryan J},
  journal={The Annals of Statistics},
  volume={49},
  number={1},
  pages={486--507},
  year={2021},
  publisher={Institute of Mathematical Statistics}
}

@book{vovk2005algorithmic,
  title={Algorithmic learning in a random world},
  author={Vovk, Vladimir and Gammerman, Alexander and Shafer, Glenn},
  year={2005},
  publisher={Springer Science \& Business Media}
}

@inproceedings{kivaranovic2020adaptive,
  title={Adaptive, distribution-free prediction intervals for deep networks},
  author={Kivaranovic, Danijel and Johnson, Kory D and Leeb, Hannes},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4346--4356},
  year={2020},
  organization={PMLR}
}

@article{fontana2023conformal,
  title={Conformal prediction: a unified review of theory and new challenges},
  author={Fontana, Matteo and Zeni, Gianluca and Vantini, Simone},
  journal={Bernoulli},
  volume={29},
  number={1},
  pages={1--23},
  year={2023},
  publisher={Bernoulli Society for Mathematical Statistics and Probability}
}

@inproceedings{Schaeffer2007SurveyGC,
  title={Survey Graph clustering},
  author={Satu Elisa Schaeffer},
  year={2007}
}

@article{traag2019louvain,
  title={From Louvain to Leiden: guaranteeing well-connected communities},
  author={Traag, Vincent A and Waltman, Ludo and Van Eck, Nees Jan},
  journal={Scientific reports},
  volume={9},
  number={1},
  pages={1--12},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{delvenne2010stability,
  title={Stability of graph communities across time scales},
  author={Delvenne, J-C and Yaliraki, Sophia N and Barahona, Mauricio},
  journal={Proceedings of the national academy of sciences},
  volume={107},
  number={29},
  pages={12755--12760},
  year={2010},
  publisher={National Acad Sciences}
}

@report{Xu2020,
   abstract = {We develop a general framework constructing distribution-free prediction intervals for dynamic time series. We show that our intervals asymptotically attain valid conditional and marginal coverages for a broad class of predictions functions and time series. We also show that our interval width converges to that of the oracle prediction interval asymptotically. Moreover, we introduce a computationally efficient algorithm called \verb|EnbPI| that wraps around ensemble predictors, which is closely related to conformal prediction (CP) but does not require data exchangeability. \verb|EnbPI| avoids data-splitting and is computationally efficient by avoiding retraining and thus scalable to sequentially producing prediction intervals. We perform extensive simulation and real-data analyses to demonstrate its effectiveness compared with existing methods.},
   author = {Chen Xu and Yao Xie},
   keywords = {anomaly detection,asymptotic guarantee,conformal prediction,data,network inference with missing,time-series predictive inference},
   pages = {1-42},
   title = {Conformal prediction for dynamic time-series},
   volume = {1},
   url = {http://arxiv.org/abs/2010.09107},
   year = {2020},
}

@article{Lei2014DistributionfreePB,
  title={Distribution‐free prediction bands for non‐parametric regression},
  author={Jing Lei and Larry A. Wasserman},
  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  year={2014},
  volume={76}
}

@article{sesia2020comparison,
  title={A comparison of some conformal quantile regression methods},
  author={Sesia, Matteo and Cand{\`e}s, Emmanuel J},
  journal={Stat},
  volume={9},
  number={1},
  pages={e261},
  year={2020},
  publisher={Wiley Online Library}
}


@InProceedings{izbicki20a,
  title = 	 {Flexible distribution-free conditional predictive bands using density estimators},
  author =       {Izbicki, Rafael and Shimizu, Gilson and Stern, Rafael},
  booktitle = 	 {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},
  pages = 	 {3068--3077},
  year = 	 {2020},
  editor = 	 {Chiappa, Silvia and Calandra, Roberto},
  volume = 	 {108},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {26--28 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v108/izbicki20a/izbicki20a.pdf},
  url = 	 {https://proceedings.mlr.press/v108/izbicki20a.html},
  abstract = 	 {Conformal methods create prediction bands that control average coverage assuming solely i.i.d. data. Besides average coverage, one might also desire to control conditional coverage, that is, coverage for every new testing point. However, without strong assumptions, conditional coverage is unachievable. Given this limitation, the literature has focused on methods with asymptotical conditional coverage. In order to obtain this property, these methods require strong conditions on the dependence between the target variable and the features. We introduce two conformal methods based on conditional density estimators that do not depend on this type of assumption to obtain asymptotic conditional coverage: Dist-split and CD-split. While Dist-split asymptotically obtains optimal intervals, which are easier to interpret than general regions, CD-split obtains optimal size regions, which are smaller than intervals. CD-split also obtains local coverage by creating prediction bands locally on a partition of the features space. This partition is data-driven and scales to high-dimensional settings. In a wide variety of simulated scenarios, our methods have a better control of conditional coverage and have smaller length than previously proposed methods.}
}

@article{additiveStone,
author = {Charles J. Stone},
title = {{Additive Regression and Other Nonparametric Models}},
volume = {13},
journal = {The Annals of Statistics},
number = {2},
publisher = {Institute of Mathematical Statistics},
pages = {689 -- 705},
keywords = {Additivity, nonparametric model, rate of convergence, Spline},
year = {1985},
doi = {10.1214/aos/1176349548},
URL = {https://doi.org/10.1214/aos/1176349548}
}

@article{massart1990tight,
  title={The tight constant in the Dvoretzky-Kiefer-Wolfowitz inequality},
  author={Massart, Pascal},
  journal={The annals of Probability},
  pages={1269--1283},
  year={1990},
  publisher={JSTOR}
}

@inproceedings{grinsztajn2022tree,
  title={Why do tree-based models still outperform deep learning on typical tabular data?},
  author={Grinsztajn, Leo and Oyallon, Edouard and Varoquaux, Gael},
  booktitle={Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  year={2022}
}

@article{valiant1984theory,
  title={A theory of the learnable},
  author={Valiant, Leslie G},
  journal={Communications of the ACM},
  volume={27},
  number={11},
  pages={1134--1142},
  year={1984},
  publisher={Acm New York, NY, USA}
}

@article{klusowski2021universal,
  title={Universal consistency of decision trees in high dimensions},
  author={Klusowski, Jason M},
  journal={arXiv preprint arXiv:2104.13881},
  year={2021}
}

@article{concrete,
  title={Modeling of strength of high-performance concrete using artificial neural networks},
  author={Yeh, I-C},
  journal={Cement and Concrete research},
  volume={28},
  number={12},
  pages={1797--1808},
  year={1998},
  publisher={Elsevier}
}

@misc{uci,
author = "Dua, Dheeru and Graff, Casey",
year = "2017",
title = "{UCI} Machine Learning Repository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences" }

@article{chernozhukov2010quantile,
  title={Quantile and probability curves without crossing},
  author={Chernozhukov, Victor and Fern{\'a}ndez-Val, Iv{\'a}n and Galichon, Alfred},
  journal={Econometrica},
  volume={78},
  number={3},
  pages={1093--1125},
  year={2010},
  publisher={Wiley Online Library}
}