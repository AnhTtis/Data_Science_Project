\documentclass[10pt]{article}
\usepackage[top=0.5in,left=0.7in,footskip=0.75in,marginparwidth=1in]{geometry}
%\usepackage[top=0.5in,left=1.3in,footskip=0.75in,marginparwidth=2in]{geometry}
\usepackage{bbm}

% use Unicode characters - try changing the option if you run into troubles with special characters (e.g. umlauts)
\usepackage[utf8]{inputenc}
% clean citations
%% \usepackage{cite, amsmath}
\usepackage{amsmath}

% hyperref makes references clicky. use \url{www.example.com} or \href{www.example.com}{description} to add a clicky url
\usepackage{nameref,hyperref}

% line numbers
\usepackage[right]{lineno}

% improves typesetting in LaTeX
\usepackage{microtype}
\DisableLigatures[f]{encoding = *, family = * }

% text layout - change as needed
\raggedright
\setlength{\parindent}{0.5cm}
\textwidth 7.00in 
\textheight 9in

% Remove % for double line spacing
%\usepackage{setspace} 
%\doublespacing

% use adjustwidth environment to exceed text width (see examples in text)
\usepackage{changepage}

% adjust caption style
\usepackage[aboveskip=1pt,labelfont=bf,labelsep=period,singlelinecheck=off]{caption}

% remove brackets from references
\makeatletter
\renewcommand{\@biblabel}[1]{\quad#1.}
\makeatother

% headrule, footrule and page numbers
\usepackage{lastpage,fancyhdr,graphicx}
\usepackage{epstopdf}
\pagestyle{myheadings}
\pagestyle{fancy}
%\pagestyle{empty}
\renewcommand{\headrulewidth}{0pt}
\fancyhf{}
\rfoot{\thepage/\pageref{LastPage}}
%\renewcommand{\footrule}{\hrule height 2pt \vspace{2mm}}
\renewcommand{\footrulewidth}{0pt}
%\fancyheadoffset[L]{2.25in}
\fancyfootoffset[L]{2.25in}

% use \textcolor{color}{text} for colored text (e.g. highlight to-do areas)
\usepackage{color}

% define custom colors (this one is for figure captions)
\definecolor{Gray}{gray}{.25}

% this is required to include graphics
\usepackage{graphicx}

% use if you want to put caption to the side of the figure - see example in text
\usepackage{sidecap}

%\usepackage[sorting=none]{biblatex}

% use for have text wrap around figures
\usepackage{wrapfig}
\usepackage[pscoord]{eso-pic}
\usepackage[fulladjust]{marginnote}
\reversemarginpar

% zz
\usepackage{float}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{ragged2e}
\justifying
% zz
\usepackage{color,soul}
\usepackage{booktabs, caption}
%\newcolumntype{?}{!{\vrule width 1pt}}
\usepackage{tabularx}
\newcolumntype{?}[1]{!{\vrule width #1}}
\usepackage{lineno}
\usepackage{setspace}
\usepackage{bbm, amsmath, amsfonts}
\usepackage{float}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{ragged2e}
\usepackage{graphicx}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}%[ruled,vlined]{algorithm2e}

\newcommand\mycommfont[1]{\footnotesize\ttfamily\textcolor{blue}{#1}}
\SetCommentSty{mycommfont}
\SetKwInput{KwInput}{Input}                % Set the Input
\SetKwInput{KwOutput}{Output}              % set the Output
\newlength\mylen
\newcommand\myinput[1]{%
  \settowidth\mylen{\KwIn{}}%
  \setlength\hangindent{\mylen}%
  \hspace*{\mylen}#1\\}

\usepackage{tabularx}
\newcolumntype{?}[1]{!{\vrule width #1}}
\usepackage{amsmath}
\usepackage{multirow}
\renewcommand{\thefigure}{S\arabic{figure}}
\renewcommand{\thetable}{S\arabic{table}}
%zz

% document begins here
\begin{document}
\vspace*{0.35in}

% title goes here:
\begin{flushleft}
{\Large
\textbf\newline{GRAF: GRAPH ATTENTION-AWARE FUSION NETWORKS}
}
\newline
% authors go here:
\\
Ziynet Nesibe Kesimoglu\textsuperscript{1},
Serdar Bozdag\textsuperscript{1,2,3}
\\
\bigskip
\bf{1} Dept. of Computer Science and Engineering, University of North Texas, Denton, TX
\\
\bf{2} Dept. of Mathematics, University of North Texas, Denton, TX
\\
\bf{3} BioDiscovery Institute, University of North Texas, Denton, TX
\\
\bigskip
%* correseponding@author.mail

\end{flushleft}

\section{Supplementary Methods}

\subsection{Data splitting}
For ACM, IMDB, and DBLP datasets, we kept the number of sample sizes in training/validation/test splits the same as the used library. ACM data has 600/300/2125 samples for training/validation/test splits, while IMDB data has 400/400/3478 and DBLP data has 400/400/3257, respectively. However, we regenerated training, validation, and test splits as stratified, thus keeping the class label ratio of original data same for each split. For DrugADR data, we divided 664 drugs into training/validation/test splits as stratified and having 338/113/113 (60\%/20\%/20\%) drugs, respectively. 

\subsection{Experimental setup}
We used the training and validation splits to tune the hyperparameters (i.e., hidden layer size, learning rate, and percentage of edges to keep) of the final model. We tried learning rates of 0.01, 0.001, 0.005, and 0.0001; hidden sizes of 32, 64, 128, 256, and 512; and 10 values as hyperparameters of the edge elimination step (namely 10\%, 20\%, ... and 100\%, where x\% means x\% of the edges will be kept based on the normalized weights, and 100\% means no edge elimination). 

We repeated whole process 10 times for each hyperparameter combination and used the hyperparameter combination giving the best median macro-weighted F1 (macro F1) score on the validation data. Using this hyperparameter combination, final model was built and evaluated 10 times on the test data, which was never seen during training and hyperparameter tuning. The evaluation metrics (macro F1 score, weighted F1 score, and accuracy) were obtained from the median of these 10 runs.


Dropout was 0.6, head size was 8, and weight decay was 0.001 for HAN model (as default). For all the models, early stopping was used with patience of 10 and Adam optimization \cite{kingma2014adam} was used to optimize. 

The experiments were run on servers with 2x AMD 7763 2.45GHz CPUs and 2048GB RAM. When we checked computational time on DrugADR data after calculating attention weights (i.e., running HAN), GRAF takes approximately 10 minutes with all edges kept and time reduces when edges were eliminated. For different hidden size and learning rates, computational time varied up to 1 hour. We observed HAN's training time was not consistent taking 10 minutes to 8 hours per run.

\subsection{DrugADR data preparation}

For drug ADR prediction task, we collected drug-ADR pairs from ADReCS (v3.1) \cite{cai2015adrecs}. We got five most frequent ADR (with more than 300 frequencies) using ADR Frequency (FAERS) readily available in ADReCS data. We used them as our class labels and mapped drugs to their most frequent ADRs among these five labels. We ended up with 664 drugs: 192 with Dizziness, 57 with Hypersensitivity, 127 with Pyrexia, 132 with Rash, and 156 with Vomiting.

We collected 1024-bit SMILES fingerprints as node features using RDKit (Open-source cheminformatics at \href{https://www.rdkit.org}{https://www.rdkit.org}) on drug structures obtained from DrugBank \cite{wishart2006drugbank} (released on 2023/01/04 as SDF format). 

We collected four drug similarity networks from \cite{olayan2018ddr} based on: drug ATC (Anatomical Therapeutic Chemical) code-based similarity, drug interactions-based similarity, chemical structures-based molecular fingerprints similarity, and drug side effects-based similarity. All files are under the folder DDR\_data/DrugBank/sim\_line at \href{https://bitbucket.org/RSO24/ddr/src/master/DDR_Data.zip}{https://bitbucket.org/RSO24/ddr/src/master/DDR\_Data.zip}. Files used in this study are listed below:
\begin{itemize}
    \item     All\_DB\_Did\_ATC\_codes\_FDA\_Sim\_D\_T\_in\_R\_basedOn\_Dsmi\_TNoFalseAA\_interacts
    \item All\_DB\_Did\_D\_interactions\_FDA\_Sim\_D\_T\_in\_R\_basedOn\_Dsmi\_TNoFalseAA\_interacts
    \item DRUGBANK\_FDA\_SIMCOMP\_similarity\_filtered\_D\_T\_in\_R\_basedOn\_Dsmi\_TNoFalseAA\_interacts
    \item DrugBank\_SIDER\_Sim\_D\_T\_in\_R\_basedOn\_Dsmi\_TNoFalseAA\_interacts
\end{itemize}
The details of each similarity network are in the Supplemental file of \cite{olayan2018ddr}. We collected all the networks and checked their data distributions. These networks were weighted and in range (0,1], and a high number of interactions exist in each. We only kept the edges where the weight is $1$, which is the maximum possible value. If we end up with an edge number less than 1000, then we decreased the threshold by $0.1$. Finally, we had 8,158 edges in drug ATC code-based similarity network (with threshold $\ge 0.6$), 10,518 edges in drug interactions-based similarity network (with threshold $\ge 0.6$), 7,328 edges in chemical structures-based molecular fingerprints similarity network (with threshold $\ge 0.4$), and 3,512 edges in drug side effects-based similarity network (with threshold $\ge 0.3$). 

%We generated DrugADR data using these four drug similarity networks and SMILES fingerprints as node features. In addition, using the same similarity networks, we generated DrugADR$_{\text{onehot}}$ data where the node features were one-hot encoded features and reported the results in Supplementary Table S3 (\%40 of the edges were kept in the experiment).


\subsection{Sensitivity to different data splits}
To check the impact of different training percentages on prediction results, we generated additional split sets with different training/validation percentages. We kept 20\% of data for testing only and this split was the same for all the split sets. We generated four additional split sets with the thresholds 20\%, 40\%, 60\%, and 80\%. Threshold x\% means that x\% of the remained data (i.e. data excluding test split) is used as training split while using the rest as validation. Thus, training/validation/test splits have 20\%/16\%/64\%, 20\%/32\%/48\%, 20\%/48\%/32\%, and 20\%/64\%/16\% for the thresholds 20\%, 40\%, 60\%, and 80\%, respectively. We did this analysis on IMDB data only, since it is the smallest dataset with only two networks. For other data with four networks and with big networks (millions of edges), we had increased computational time, especially when we have higher sample size in training split. Similarly, we excluded SUPREME from this analysis because of increased computational time. We repeated each evaluation 10 times for each split set and reported the median of those runs in Supplemental Figures S1, S2, and S3.

\newpage

\newpage
\section{Supplementary Algorithms}
The overall attention-aware network fusion strategy is shown in Supplementary Algorithm \ref{alg:netwFusion}. Bias vectors before applying the non-linearity are omitted for simplicity.


\begin{algorithm}[h]
\DontPrintSemicolon
  \setlength{\lineskip}{5pt}
  \KwInput{Graph $ \mathcal{G}= (\mathcal{V},\mathcal{E})$ where $\mathcal{V}$ is a set of $n$ nodes, i.e., $\mathcal{V} = \{v_1, v_2, ..., v_n\}$, and $\mathcal{E}^{\phi}$ is a set of edges between nodes \newline
  $(v_i,v_j) \in \mathcal{E}^{\phi}$ when $v_i$ and $v_j$ have based on the association $\phi$ a
  \newline
  $(v_i,v_j) \in \mathcal{E}^{\phi} \iff (v_j,v_i) \in \mathcal{E}^{\phi}$ (undirected graph)\newline
  feature matrix $\mathcal{X} \in \mathbb{R}^{nxf}$ 
  }
  
  
  \KwOutput{Adjacency matrix $\mathcal{A}$}
  \For{$c \in \{1,2...C\}$}{
  
    \For{$\phi \in \{1,2...\Phi\}$} 
    {
        Node type-specific transformation: ${h_i} = {{M_{\Theta}}}.{ x_i}$ \;
        \For{$v_i \in \mathcal{V}$}
        {
            \For{$v_j \in \mathcal{N}^{\phi}_{i}=\left\{v_{j}:\left(v_{i}, v_{j}\right) \in \mathcal{E}^{\phi}\right\}$}
            {
                $e_{ij}^{\phi} = \text{LeakyReLU}\left(({{a}}^{\phi})^{\mathbb{T}}.{[h_i||h_j]}\right)$ \;
                Weight coefficient $\alpha_{ij}^{\phi}=$softmax$_j(e_{ij}^{\phi}) = \dfrac{\text{exp}(e_{ij}^{\phi})}{\sum_{k\in \mathcal{N}^{\phi}_{i}}\text{exp}\left(e_{ik}^{\phi}\right)}$ \;
            }
        }
        Association-specific embedding ${z_i^{\phi}}=\sigma\left(\sum_{v_j \in \mathcal{N}^{\phi}_{i}}\alpha_{ij}^{\phi}.{ h_j}\right)$ \;
        
        Association-specific combined embedding ${ \mathcal{Z}^{\phi}}$ \;
        $f^{\phi} = \dfrac{1}{|\mathcal{V}|}. \sum_{v_i\in \mathcal{V}} {{q}}^{\mathbb{T}}.$tanh$({{M_0}}.{ z_i^{\phi}})$  \;
    }
   Association weight coefficient $\beta^{\phi}=$softmax$_\phi(f^{\phi})=\dfrac{\text{exp}(f^{\phi})}{\text{exp}\left(\sum_{i\in \Phi}f^{i}\right)}$ \;

    Final embedding $\mathcal{Z}=\sigma\left(\sum_{i \in \Phi}\beta^{i}.\mathcal{Z}^{i}\right)$ \;
    Cross-entropy loss \;

    Backpropagation and final parameter obtention\;

    $\beta^{\phi}_{c} = \beta^{\phi}$ \; 
    $\alpha_{ijc}^{\phi} = \alpha_{ij}^{\phi}$\;

}
$\beta^{\phi} = \frac{1}{C}\sum_{c \in \{1,2...C\}}\beta^{\phi}_{c}$ \;
$\alpha_{ij}^{\phi} = \frac{1}{C}\sum_{c \in \{1,2...C\}}\alpha_{ijc}^{\phi}$ \;
$
\mathcal{A}[i,j]=\sum_{\phi \in \{1,2...\Phi\}
}  \left(
\beta^{\phi} \alpha_{ij}^{\phi}  I_{\mathcal{E}^{\phi}}(v_{i}, v_{j})
\right)
$
\caption{Attention-aware network fusion.}
\label{alg:netwFusion}\end{algorithm}

\newpage
\section{Supplementary Tables}

\begin{table*}[h]
  \caption{Node classification results as accuracy and weighted F1 scores (\%) [Performance evaluation as accuracy and weighted F1 scores in four node classification tasks: movie genre prediction from IMDB data, paper type prediction task from ACM data, author research area prediction task from DBLP data, and drug ADR (adverse drug reaction) prediction task. The best result is highlighted as bold and second-best as italic. $\text{GRAF}_{asc}$ and $\text{GRAF}_{node}$ denote GRAF with only association- and only node-level attention, respectively. $\text{GRAF}_{edge}$ denotes GRAF without edge elimination. $\text{SUPREME}_{min}$, $\text{SUPREME}_{med}$, and $\text{SUPREME}_{max}$ denote the worst, median, and best model based on validation macro F1 among all network combinations. GCN, GAT, and GATv2 were evaluated for every single network, and the best performance was reported. [GAT: Graph Attention Network, GCN: Graph Convolutional Network, MLP: Multi-layer Perceptron, RF: Random Forest, SVM: Support Vector Machine].]}
  \label{suptab:grafResults}
  \centering
  \begin{tabular}{lrrrr?{0.5mm}rrrr}
    \hline
    & \multicolumn{4} {c} {\textbf {Accuracy}} & \multicolumn{4} {c} {\textbf {Weighted F1}}\\
    \hline
    \textbf{Method} & \textbf{IMDB}& \textbf{ACM}& \multicolumn{1} {c}{\textbf{DBLP}}& \textbf{DrugADR}& \textbf{IMDB}& \textbf{ACM}& \textbf{DBLP}&\textbf{DrugADR}\\
 \hline
GCN&58.5±0&91.5±0&91.2±0&\textbf{41.4±0}&58.5±0&91.5±0&91.4±0&\textbf{43.2±0}\\
GAT&56.9±0&91.0±0&92.1±1&\textit{41.0±2}&56.7±0&91.0±0&92.0±1&37.7±2\\
GATv2&56.8±1&90.9±1&90.8±1&39.8±2&56.6±1&90.9±1&90.7±1&37.6±2\\
MLP&55.0±1&89.0±1&79.2±1&30.4±4&54.8±1&88.9±1&79.2±1&26.2±5\\
RF&53.7±0&89.0±0&70.7±0&39.1±1&53.7±0&88.9±0&70.3±0&34.3±1\\
SVM&54.9±0&88.5±0&77.1±0&26.3±0&55.0±0&88.5±0&77.1±0&26.3±0\\
HAN&61.1±0&91.9±1&92.1±1&38.3±1&60.9±0&91.9±1&92.0±1&35.6±1\\
\hline
$\text{SUPREME}_{min}$&54.5±1&90.7±1&78.6±2&36.5±4&54.2±2&90.7±0&78.6±2& 34.0±5\\
$\text{SUPREME}_{med}$&57.1±1&92.4±1&91.4±1&38.3±3&57.0±2&92.3±1&91.4±1&36.2±3\\
$\text{SUPREME}_{max}$&60.9±2&\textbf{93.4±1}&\textbf{92.9±2}&38.3±2&60.7±3&\textbf{93.3±1}&\textbf{92.9±2}&36.5±2\\
\hline
$\text{GRAF}_{asc}$&56.9±0&84.3±2&90.6±0&34.2±2&57.0±0&84.2±2&90.8±0&35.7±3\\
$\text{GRAF}_{node}$&\textit{61.6±0}&90.8±2&91.0±1&38.3±3&\textit{61.7±0}&90.9±2&91.1±1&40.0±4\\
$\text{GRAF}_{edge}$&\textbf{62.3±0}&92.2±0&91.9±1&40.6±2&\textbf{62.3±0}&92.2±0&91.9±0&41.8±3\\
\hline
GRAF&\textbf{62.3±0}&\textit{92.5±0}&\textit{92.2±1}&\textit{41.0±2}&\textbf{62.3±0}&\textit{92.5±0}&\textit{92.2±1}&\textit{42.0±2}\\

   \hline
  \end{tabular}
\end{table*}



\begin{table*}[ht]
  \caption{Association-level attentions [*A: Author, C: Conference, D: Director, M: Movie, P: Paper, R: Actor, S: Subject, T: Term. G-G$_x$ denotes drug-drug similarity networks based on four similarities in the order mentioned in Supplementary Methods 1.3.]}
  \label{tab:attentions}
  \centering
  \begin{tabular}{lrrrrr}
    \hline
    \textbf{Dataset} &  \textbf{Association}*&\textbf{Attention} \\
    \hline
    \multirow{2}*{IMDB} & MRM & 0.44\\
    & MDM & 0.56\\
    \hline
    \multirow{2}*{ACM}  & PAP & 0.66\\
    & PSP & 0.34\\

     \hline
    \multirow{4}*{DBLP} & APA &  0.23  \\
    & APAPA & 0.13\\
    & APCPA& 0.64\\
    & APTPA & 0.01 \\
        \hline
    %\multirow{4}*{DrugADR$_{\text{onehot}}$} & G-G$_{1}$ &  0.24\\
    %& G-G$_{2}$ & 0.25\\
    %& G-G$_{3}$ & 0.26\\
    %& G-G$_{4}$ & 0.25 \\
    %\midrule
    \multirow{4}*{DrugADR} & G-G$_{1}$ &  0.19\\
    & G-G$_{2}$ & 0.14\\
    & G-G$_{3}$ & 0.23\\
    & G-G$_{4}$ & 0.43 \\
    
    \hline
  \end{tabular}  
  
\end{table*}



%\begin{table}
%  \caption{Node classification results on DrugADR$_\text{onehot}$ data(\%)}
%  \label{tab:grafResults}
%  \centering
%  \begin{tabular}{lrrrrrr}
%    \toprule
%    \textbf{Method} & \textbf{Accuracy}& \textbf{Weighted F1}& \textbf{Macro F1}\\
% \midrule
%GCN&40.7±0&43.7±0&33.9±0\\
%GAT&39.8±5&34.6±6&29.5±6\\
%GATv2&40.3±4&35.7±5&30.8±5\\
%MLP&29.2±4&13.2±4&9.0±3\\
%RF&29.2±0&13.2±0&9.0±0\\
%SVM&29.2±0&13.2±0&9.0±0\\
%HAN&43.8±5&40.8±1&35.3±10\\\midrule
%$\text{SUPREME}_{min}$& 30.1±1&25.3±5&20.4±5\\
%$\text{SUPREME}_{med}$& 40.3±2&36.6±2&31.2±2\\
%$\text{SUPREME}_{max}$& 37.6±3&37.0±3&36.1±4\\
%\midrule
%$\text{GRAF}_{asc}$&38.9±1&41.2±2&30.5±1\\
%$\text{GRAF}_{node}$&40.7±2&44.8±2&31.4±2\\
%$\text{GRAF}_{edge}$&40.7±1&44.4±2&31.7±1\\
%\midrule
%GRAF&\textbf{44.2±1}&\textbf{46.6±1}&\textbf{38.2±1}\\
%   \bottomrule
%  \end{tabular}
%{
% \begin{flushleft}
% \footnotesize 
%Performance evaluation on drug ADR (adverse drug reaction) prediction task using one-hot encoded node features. $\text{GRAF}_{asc}$ and $\text{GRAF}_{node}$ denote GRAF with only association- and only node-level attention, respectively. $\text{GRAF}_{edge}$ denotes GRAF without edge elimination. $\text{SUPREME}_{min}$, $\text{SUPREME}_{med}$, and $\text{SUPREME}_{max}$ denote the worst, median, and best model based on validation macro F1 among all network combinations. GCN, GAT, and GATv2 were evaluated for every single network, and the best performance was reported. [GAT: Graph Attention Network, GCN: Graph Convolutional Network, MLP: Multi-layer Perceptron, RF: Random Forest, SVM: Support Vector Machine]
% \end{flushleft}}
% \end{table}


\newpage
\section{Supplementary Figures}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.85\linewidth]{Splits_mf1}
 \caption{Performance with different training splits on IMDB data (macro F1).}
 \label{gfig:s1_1}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.85\linewidth]{Splits_wf1}
  \caption{Performance with different training splits on IMDB data (weighted F1).}
 \label{gfig:s1_2}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.85\linewidth]{Splits_acc}
  \caption{Performance with different training splits on IMDB data (accuracy).}
 \label{gfig:s1_3}
\end{figure}



\begin{figure}[h]
  \centering
  \includegraphics[width=0.9\linewidth]{EdgePercentages_MacroF1}
 \caption{Performance with different edge percentages (macro F1).}
 \label{gfig:s2}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.9\linewidth]{EdgePercentages_WeightedF1}
  \caption{Performance with different edge percentages (weighted F1).}
 \label{gfig:s3}
\end{figure}

\begin{figure}[!h]
  \centering
  \includegraphics[width=0.9\linewidth]{EdgePercentages_Accuracy}
  \caption{Performance with different edge percentages (accuracy).}
 \label{gfig:s4}
\end{figure}
\newpage

\bibliography{bib}
\bibliographystyle{unsrt}


\end{document}
