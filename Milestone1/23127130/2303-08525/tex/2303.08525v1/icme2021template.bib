@article{de2017video,
	title={Video processing for panoramic streaming using HEVC and its scalable extensions},
	author={de la Fuente, Y S{\'a}nchez and Skupin, Robert and Schierl, Thomas},
	journal={Multimedia Tools and Applications},
	volume={76},
	number={4},
	pages={5631--5659},
	year={2017},
	publisher={Springer}
}

@article{stengel2016gaze,
	title={Gaze-contingent computational displays: Boosting perceptual fidelity},
	author={Stengel, Michael and Magnor, Marcus},
	journal={IEEE Signal Processing Magazine},
	volume={33},
	number={5},
	pages={139--148},
	year={2016},
	publisher={IEEE}
}

@article{gaddam2016tiling,
	title={Tiling in interactive panoramic video: Approaches and evaluation},
	author={Gaddam, Vamsidhar Reddy and Riegler, Michael and Eg, Ragnhild and Griwodz, Carsten and Halvorsen, P{\aa}l},
	journal={IEEE Transactions on Multimedia},
	volume={18},
	number={9},
	pages={1819--1831},
	year={2016},
	publisher={IEEE}
}

@article{zhai2020perceptual,
	title={Perceptual image quality assessment: a survey},
	author={Zhai, Guangtao and Min, Xiongkuo},
	journal={Science China Information Sciences},
	volume={63},
	number={11},
	pages={211301},
	year={2020},
	publisher={Science China Press}
}

@inproceedings{2016A,
  title={A Deep Multi-Level Network for Saliency Prediction},
  author={ Cornia, M.  and  Baraldi, L.  and  Serra, G.  and  Cucchiara, R. },
  booktitle={International Conference on Pattern Recognition},
  year={2016},
}

@ARTICLE{8240654,
  author={Wang, Wenguan and Shen, Jianbing},
  journal={IEEE Transactions on Image Processing}, 
  title={Deep Visual Attention Prediction}, 
  year={2018},
  volume={27},
  number={5},
  pages={2368-2378},
  doi={10.1109/TIP.2017.2787612}
}

@article{lebreton2018gbvs360,
	title={GBVS360, BMS360, ProSal: Extending existing saliency prediction models from 2D to omnidirectional images},
	author={Lebreton, Pierre and Raake, Alexander},
	journal={Signal Processing: Image Communication},
	volume={69},
	pages={69--78},
	year={2018},
	publisher={Elsevier}
}

@article{zhu2018prediction,
	title={The prediction of head and eye movement for 360 degree images},
	author={Zhu, Yucheng and Zhai, Guangtao and Min, Xiongkuo},
	journal={Signal Processing: Image Communication},
	volume={69},
	pages={15--25},
	year={2018},
	publisher={Elsevier}
}

@article{zhang2015exploiting,
	title={Exploiting surroundedness for saliency detection: a boolean map approach},
	author={Zhang, Jianming and Sclaroff, Stan},
	journal={IEEE transactions on pattern analysis and machine intelligence},
	volume={38},
	number={5},
	pages={889--902},
	year={2015},
	publisher={IEEE}
}

@article{harel2007graph,
	title={Graph-based visual saliency},
	author={Harel, Jonathan and Koch, Christof and Perona, Pietro},
	year={2007},
	publisher={MIT Press}
}

@article{pan2017salgan,
	title={Salgan: Visual saliency prediction with generative adversarial networks},
	author={Pan, Junting and Ferrer, Cristian Canton and McGuinness, Kevin and O'Connor, Noel E and Torres, Jordi and Sayrol, Elisa and Giro-i-Nieto, Xavier},
	journal={arXiv preprint arXiv:1701.01081},
	year={2017}
}

@article{monroy2018salnet360,
	title={Salnet360: Saliency maps for omni-directional images with cnn},
	author={Monroy, Rafael and Lutz, Sebastian and Chalasani, Tejo and Smolic, Aljosa},
	journal={Signal Processing: Image Communication},
	volume={69},
	pages={26--34},
	year={2018},
	publisher={Elsevier}
}

@inproceedings{li2018recurrent,
	title={Recurrent squeeze-and-excitation context aggregation net for single image deraining},
	author={Li, Xia and Wu, Jianlong and Lin, Zhouchen and Liu, Hong and Zha, Hongbin},
	booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
	pages={254--269},
	year={2018}
}

@inproceedings{chao2018salgan360,
	title={Salgan360: Visual saliency prediction on 360 degree images with generative adversarial networks},
	author={Chao, Fang-Yi and Zhang, Lu and Hamidouche, Wassim and Deforges, Olivier},
	booktitle={2018 IEEE International Conference on Multimedia \& Expo Workshops (ICMEW)},
	pages={01--04},
	year={2018},
	organization={IEEE}
}

@inproceedings{chen2020salbinet360,
	title={Salbinet360: Saliency prediction on 360 images with local-global bifurcated deep network},
	author={Chen, Dongwen and Qing, Chunmei and Xu, Xiangmin and Zhu, Huansheng},
	booktitle={2020 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)},
	pages={92--100},
	year={2020},
	organization={IEEE}
}

@article{chao2020multi,
	title={A Multi-FoV Viewport-based Visual Saliency Model Using Adaptive Weighting Losses for 360Â° Images},
	author={Chao, Fang-Yi and Zhang, Lu and Hamidouche, Wassim and D{\'e}forges, Olivier},
	journal={IEEE Transactions on Multimedia},
	volume={23},
	pages={1811-1826},
	year={2021},
	publisher={IEEE}
}

@article{startsev2018360,
	title={360-aware saliency estimation with conventional image saliency predictors},
	author={Startsev, Mikhail and Dorr, Michael},
	journal={Signal Processing: Image Communication},
	volume={69},
	pages={43--52},
	year={2018},
	publisher={Elsevier}
}

@article{battisti2018feature,
	title={A feature-based approach for saliency estimation of omni-directional images},
	author={Battisti, Federica and Baldoni, Sara and Brizzi, Michele and Carli, Marco},
	journal={Signal Processing: Image Communication},
	volume={69},
	pages={53--59},
	year={2018},
	publisher={Elsevier}
}

@inproceedings{chen2021visual,
	title={Visual Saliency Prediction on 360 Degree Images With CNN},
	author={Chen, Xinlang and Gao, Pan and Wei, Ran},
	booktitle={2021 IEEE International Conference on Multimedia \& Expo Workshops (ICMEW)},
	pages={1--6},
	year={2021},
	organization={IEEE}
}

@inproceedings{hu2018squeeze,
	title={Squeeze-and-excitation networks},
	author={Hu, Jie and Shen, Li and Sun, Gang},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={7132--7141},
	year={2018}
}

@inproceedings{maas2013rectifier,
	title={Rectifier nonlinearities improve neural network acoustic models},
	author={Maas, Andrew L and Hannun, Awni Y and Ng, Andrew Y and others},
	booktitle={Proc. icml},
	volume={30},
	number={1},
	pages={3},
	year={2013},
	organization={Citeseer}
}

@book{mandic2001recurrent,
	title={Recurrent neural networks for prediction: learning algorithms, architectures and stability},
	author={Mandic, Danilo and Chambers, Jonathon},
	year={2001},
	publisher={Wiley}
}

@article{cho2014learning,
	title={Learning phrase representations using RNN encoder-decoder for statistical machine translation},
	author={Cho, Kyunghyun and Van Merri{\"e}nboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
	journal={arXiv preprint arXiv:1406.1078},
	year={2014}
}

@inproceedings{isola2017image,
	title={Image-to-image translation with conditional adversarial networks},
	author={Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={1125--1134},
	year={2017}
}

@inproceedings{jiang2015salicon,
	title={Salicon: Saliency in context},
	author={Jiang, Ming and Huang, Shengsheng and Duan, Juanyong and Zhao, Qi},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={1072--1080},
	year={2015}
}

@inproceedings{rai2017dataset,
	title={A dataset of head and eye movements for 360 degree images},
	author={Rai, Yashas and Guti{\'e}rrez, Jes{\'u}s and Le Callet, Patrick},
	booktitle={Proceedings of the 8th ACM on Multimedia Systems Conference},
	pages={205--210},
	year={2017}
}

@inproceedings{rai2017saliency,
	title={Which saliency weighting for omni directional image quality assessment?},
	author={Rai, Yashas and Le Callet, Patrick and Guillotel, Philippe},
	booktitle={2017 Ninth International Conference on Quality of Multimedia Experience (QoMEX)},
	pages={1--6},
	year={2017},
	organization={IEEE}
}

@article{sitzmann2018saliency,
	title={Saliency in VR: How do people explore virtual environments?},
	author={Sitzmann, Vincent and Serrano, Ana and Pavel, Amy and Agrawala, Maneesh and Gutierrez, Diego and Masia, Belen and Wetzstein, Gordon},
	journal={IEEE transactions on visualization and computer graphics},
	volume={24},
	number={4},
	pages={1633--1642},
	year={2018},
	publisher={IEEE}
}

@article{bylinskii2018different,
	title={What do different evaluation metrics tell us about saliency models?},
	author={Bylinskii, Zoya and Judd, Tilke and Oliva, Aude and Torralba, Antonio and Durand, Fr{\'e}do},
	journal={IEEE transactions on pattern analysis and machine intelligence},
	volume={41},
	number={3},
	pages={740--757},
	year={2018},
	publisher={IEEE}
}

@inproceedings{maugey2017saliency,
	title={Saliency-based navigation in omnidirectional image},
	author={Maugey, Thomas and Le Meur, Olivier and Liu, Zhi},
	booktitle={2017 IEEE 19th International Workshop on Multimedia Signal Processing (MMSP)},
	pages={1--6},
	year={2017},
	organization={IEEE}
}

@inproceedings{de2017look,
	title={Look around you: Saliency maps for omnidirectional images in VR applications},
	author={De Abreu, Ana and Ozcinar, Cagri and Smolic, Aljosa},
	booktitle={2017 Ninth International Conference on Quality of Multimedia Experience (QoMEX)},
	pages={1--6},
	year={2017},
	organization={IEEE}
}

@article{ling2018saliency,
	title={A saliency prediction model on 360 degree images using color dictionary based sparse representation},
	author={Ling, Jing and Zhang, Kao and Zhang, Yingxue and Yang, Daiqin and Chen, Zhenzhong},
	journal={Signal Processing: Image Communication},
	volume={69},
	pages={60--68},
	year={2018},
	publisher={Elsevier}
}

@inproceedings{chen2017fast,
	title={Fast image processing with fully-convolutional networks},
	author={Chen, Qifeng and Xu, Jia and Koltun, Vladlen},
	booktitle={Proceedings of the IEEE International Conference on Computer Vision},
	pages={2497--2506},
	year={2017}
}

@article{yu2015multi,
	title={Multi-scale context aggregation by dilated convolutions},
	author={Yu, Fisher and Koltun, Vladlen},
	journal={arXiv preprint arXiv:1511.07122},
	year={2015}
}
@article{kim2020acoustic,
  title={Acoustic Room Modelling using 360 Stereo Cameras},
  author={Kim, Hansung and Remaggi, Luca and Fowler, Sam and Jackson, Philip and Hilton, Adrian},
  journal={IEEE Transactions on Multimedia},
  year={2020},
  publisher={IEEE}
}
@article{yaqoob2020survey,
  title={A survey on adaptive 360 video streaming: Solutions, challenges and opportunities},
  author={Yaqoob, Abid and Bi, Ting and Muntean, Gabriel-Miro},
  journal={IEEE Communications Surveys \& Tutorials},
  volume={22},
  number={4},
  pages={2801--2838},
  year={2020},
  publisher={IEEE}
}
@inproceedings{linardos2021deepgaze,
  title={DeepGaze IIE: Calibrated prediction in and out-of-domain for state-of-the-art saliency modeling},
  author={Linardos, Akis and Kummerer, Matthias and Press, Ori and Bethge, Matthias},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={12919--12928},
  year={2021}
}
@inproceedings{long2015fully,
  title={Fully convolutional networks for semantic segmentation},
  author={Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3431--3440},
  year={2015}
}
@inproceedings{szegedy2016rethinking,
  title={Rethinking the inception architecture for computer vision},
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2818--2826},
  year={2016}
}
@inproceedings{he2016identity,
  title={Identity mappings in deep residual networks},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={European conference on computer vision},
  pages={630--645},
  year={2016},
  organization={Springer}
}
@article{zhou2021projection,
  title={Projection Invariant Feature and Visual Saliency-Based Stereoscopic Omnidirectional Image Quality Assessment},
  author={Zhou, Xuemei and Zhang, Yun and Li, Na and Wang, Xu and Zhou, Yang and Ho, Yo-Sung},
  journal={IEEE Transactions on Broadcasting},
  year={2021},
  publisher={IEEE}
}
@article{paul2018efficient,
  title={Efficient multiview video coding using 3-D coding and saliency-based bit allocation},
  author={Paul, Manoranjan},
  journal={IEEE Transactions on Broadcasting},
  volume={64},
  number={2},
  pages={235--246},
  year={2018},
  publisher={IEEE}
}
@article{liu2018deep,
  title={A deep spatial contextual long-term recurrent convolutional network for saliency detection},
  author={Liu, Nian and Han, Junwei},
  journal={IEEE Transactions on Image Processing},
  volume={27},
  number={7},
  pages={3264--3274},
  year={2018},
  publisher={IEEE}
}
@inproceedings{xu2015show,
  title={Show, attend and tell: Neural image caption generation with visual attention},
  author={Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and Cho, Kyunghyun and Courville, Aaron and Salakhudinov, Ruslan and Zemel, Rich and Bengio, Yoshua},
  booktitle={International conference on machine learning},
  pages={2048--2057},
  year={2015},
  organization={PMLR}
}


@article{A01,
  title={Deep visual attention prediction},
  author={Wang, Wenguan and Shen, Jianbing},
  journal={IEEE Transactions on Image Processing},
  volume={27},
  number={5},
  pages={2368--2378},
  year={2017},
  publisher={IEEE}
}

@article{A02,
  title={A deep spatial contextual long-term recurrent convolutional network for saliency detection},
  author={Liu, Nian and Han, Junwei},
  journal={IEEE Transactions on Image Processing},
  volume={27},
  number={7},
  pages={3264--3274},
  year={2018},
  publisher={IEEE}
}

@article{A03,
  title={Predicting human eye fixations via an lstm-based saliency attentive model},
  author={Cornia, Marcella and Baraldi, Lorenzo and Serra, Giuseppe and Cucchiara, Rita},
  journal={IEEE Transactions on Image Processing},
  volume={27},
  number={10},
  pages={5142--5154},
  year={2018},
  publisher={IEEE}
}

@article{A04,
  title={Salgan: Visual saliency prediction with generative adversarial networks},
  author={Pan, Junting and Ferrer, Cristian Canton and McGuinness, Kevin and O'Connor, Noel E and Torres, Jordi and Sayrol, Elisa and Giro-i-Nieto, Xavier},
  journal={arXiv preprint arXiv:1701.01081},
  year={2017}
}

@inproceedings{A05,
  title={A deep multi-level network for saliency prediction},
  author={Cornia, Marcella and Baraldi, Lorenzo and Serra, Giuseppe and Cucchiara, Rita},
  booktitle={2016 23rd International Conference on Pattern Recognition (ICPR)},
  pages={3488--3493},
  year={2016},
  organization={IEEE}
}

@article{A06,
  title={Optimal eye movement strategies in visual search},
  author={Najemnik, Jiri and Geisler, Wilson S},
  journal={Nature},
  volume={434},
  number={7031},
  pages={387--391},
  year={2005},
  publisher={Nature Publishing Group}
}

@article{A07,
  title={A model of saliency-based visual attention for rapid scene analysis},
  author={Itti, Laurent and Koch, Christof and Niebur, Ernst},
  journal={IEEE Transactions on pattern analysis and machine intelligence},
  volume={20},
  number={11},
  pages={1254--1259},
  year={1998},
  publisher={Ieee}
}

@article{A08,
  title={Spatial statistics and attentional dynamics in scene viewing},
  author={Engbert, Ralf and Trukenbrod, Hans A and Barthelm{\'e}, Simon and Wichmann, Felix A},
  journal={Journal of vision},
  volume={15},
  number={1},
  pages={14--14},
  year={2015},
  publisher={The Association for Research in Vision and Ophthalmology}
}

@article{li2022spherical,
  title={Spherical Convolution empowered Viewport Prediction in 360 Video Multicast with Limited FoV Feedback},
  author={Li, Jie and Han, Ling and Zhang, Chong and Li, Qiyue and Liu, Zhi},
  journal={ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM)},
  year={2022},
  publisher={ACM New York, NY}
}

@ARTICLE{TII-Saliency,
  author={Umer, Ayaz and Termritthikun, Chakkrit and Qiu, Tie and Leong, Philip H. W. and Lee, Ivan},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={On-Device Saliency Prediction Based on Pseudoknowledge Distillation}, 
  year={2022},
  volume={18},
  number={9},
  pages={6317-6325},
  doi={10.1109/TII.2022.3153365}}
  
  @ARTICLE{TII-360,
  author={Wei, Xuekai and Zhou, Mingliang and Jia, Weijia},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={Towards Low-Latency and High-Quality Adaptive 360-Degree Streaming}, 
  year={2022},
  volume={},
  number={},
  pages={1-10},
  doi={10.1109/TII.2022.3192398}}

  @inproceedings{zerman2020textured,
  title={Textured mesh vs coloured point cloud: A subjective study for volumetric video compression},
  author={Zerman, Emin and Ozcinar, Cagri and Gao, Pan and Smolic, Aljosa},
  booktitle={2020 Twelfth International Conference on Quality of Multimedia Experience (QoMEX)},
  pages={1--6},
  year={2020},
  organization={IEEE}
}
@article{gao2019occlusion,
  title={Occlusion-aware depth map coding optimization using allowable depth map distortions},
  author={Gao, Pan and Smolic, Aljosa},
  journal={IEEE Transactions on Image Processing},
  volume={28},
  number={11},
  pages={5266--5280},
  year={2019},
  publisher={IEEE}
}
@article{gao2020quality,
  title={Quality assessment for omnidirectional video: A spatio-temporal distortion modeling approach},
  author={Gao, Pan and Zhang, Pengwei and Smolic, Aljosa},
  journal={IEEE Transactions on Multimedia},
  volume={24},
  pages={1--16},
  year={2020},
  publisher={IEEE}
}
@article{zerman2019subjective,
  title={Subjective and objective quality assessment for volumetric video compression},
  author={Zerman, Emin and Gao, Pan and Ozcinar, Cagri and Smolic, Aljosa},
  journal={Electronic Imaging},
  volume={2019},
  number={10},
  pages={323--1},
  year={2019},
  publisher={Society for Imaging Science and Technology}
}




