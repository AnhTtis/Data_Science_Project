\section{Counterexamples}
\label{sec:counterexamples}

We now present two examples in which thinning strategies do not work.
The first  involves a natural exponential family that is based on a distribution that {\em cannot} be written as the convolution of two distributions. In this case, Theorem~\ref{thm:natural-exponential-families} implies that we cannot thin it by addition. In fact, we will prove a stronger statement: namely, that  there does not exist \emph{any} function $T(\cdot)$ that can thin it.  The second example involves a convolution-closed family outside of the natural exponential family in which addition is not sufficient. In this case, taking $T(\cdot)$ to be addition does not enable thinning, as Theorem \ref{thm:generalized-thinning} does not apply.

\subsection{The Bernoulli family cannot be thinned}
\label{sec:bernoulli}

Let $P_{\theta}$ denote the $\mathrm{Bernoulli}(\theta)$ distribution, where $\theta$ is the probability of success. Recall that this distribution can be written as a natural exponential family (with natural parameter $\log \left( \frac{\theta}{1 - \theta} \right)$). By Theorem \ref{thm:backwards-natexpfam}, if $P_\theta$ can be thinned, then the thinning function must be a convolution. However, as the next theorem shows, the Bernoulli distribution cannot be written as a convolution of independent, non-constant random variables.

\begin{theorem}[The Bernoulli is not a convolution]\label{thm:bernoulli}
If $Z^{(1)}$ and $Z^{(2)}$ are independent, non-constant random variables, then $Z^{(1)}+Z^{(2)}$
cannot be a Bernoulli random variable.
\end{theorem}

Theorem~\ref{thm:bernoulli} is proven in Supplement~\ref{app:bernoulli-convolution}. 

As the Bernoulli distribution cannot be written as a convolution of non-constant random variables, it cannot achieve the two conclusions of Theorem~\ref{thm:backwards-natexpfam} simultaneously. Thus, a contrapositive argument applied to Theorem~\ref{thm:backwards-natexpfam} leads to the next result.

\begin{corollary}
\label{cor:bern2}
    The Bernoulli family cannot be thinned by any function $T(\cdot)$.
\end{corollary}



This corollary of Theorems \ref{thm:backwards-natexpfam} and \ref{thm:bernoulli} is proven in Supplement \ref{app:bern2}. A similar argument reveals that the categorical distribution also cannot be thinned.

\subsection{The Cauchy family cannot be thinned by addition}
\label{subsec:cauchy}

Suppose now that our interest lies in a random variable $X=T(\Xt{1},\Xt{2})$, where $T(\Xt{1}, \Xt{2})$ is \emph{not} sufficient for the parameter $\theta$ based on $(\Xt{1},\Xt{2})$. This means that the conditional distribution of $(\Xt{1},\Xt{2})$ given $T(\Xt{1},\Xt{2})$ depends on $\theta$, and thus that we cannot thin $X$ by $T(\cdot)$.  We see this in the following example.

\begin{exmp}[The trouble with thinning $\text{Cauchy}(\theta_1, \theta_2)$ by addition] \label{ex:cauchy}
Recall that the Cauchy family, $\text{Cauchy}(\theta_1, \theta_2)$, indexed by $\theta=(\theta_1,\theta_2)$,  is convolution-closed. In particular, if $\Xt{1},\Xt{2}\overset{iid}{\sim}\text{Cauchy}\left(\frac{1}{2}\theta_1, \frac{1}{2}\theta_2\right)$, then $\Xt{1} + \Xt{2}\sim\text{Cauchy}(\theta_1, \theta_2)$.  It is tempting therefore to try thinning this family by $T(\xt{1},\xt{2})=\xt{1}+\xt{2}$.  However, the sum $\Xt{1} + \Xt{2}$ is not sufficient for $\theta$, which means that Theorem~\ref{thm:generalized-thinning} does not apply and in particular $G_t$, the conditional distribution of $(\Xt{1},\Xt{2})$ given $\Xt{1} + \Xt{2}=t$, \emph{is} a function of $\theta$. Therefore, we cannot thin the Cauchy family with unknown parameters by addition. 
\end{exmp}

We can take this result a step further: given Cauchy random variables, the only sufficient statistic for $\theta$ is a permutation of the data 
\citep[p.~275]{CaseBerg}. 
Thus, there is no family $\mathcal{P}$ and corresponding function $T(\cdot)$ that reduces the data for which thinning will produce independent Cauchy random variables. However, we can apply sample splitting (which, as shown in Section~\ref{sec:sample-splitting}, is based on a $T(\cdot)$ that does not reduce the data) to thin a vector of independent and identically distributed Cauchy random variables.
