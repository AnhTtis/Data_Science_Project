\section{Thinning natural exponential families}
\label{sec:natural-exp-fam}

In Section~\ref{subsec:natural}, we show how to thin a natural exponential family into two or more natural exponential families.  In Section~\ref{subsec:neufeld}, we show how the convolution-closed thinning proposal of \citet{neufeld2023data} can be understood in light of natural exponential family thinning.  Finally, in Section~\ref{subsec:natural-to-general}, we show how natural exponential families can be thinned into more general (i.e., not necessarily natural) exponential families.

\subsection{Thinning natural into natural exponential families} 
\label{subsec:natural}

 
A natural exponential family \citep{lehmann2005testing} starts with a known probability distribution $H$, and then forms a family of distributions $\mathcal P^H=\{P^H_\theta:\theta\in\Omega\}$ based on $H$, as follows: 
\begin{equation}
    dP^H_\theta(x)=e^{x^\top\theta-\psi_H(\theta)}dH(x).\label{eq:natural}
\end{equation}
The normalizing constant $e^{-\psi_H(\theta)}$ ensures that $P_\theta$ is a probability distribution, and we take $\Omega$ to be the set of $\theta$ for which this normalization is possible (i.e. for which $\psi_H(\theta)<\infty$).  

The next theorem presents a property of $H$ that is  necessary and sufficient for the resulting natural exponential family $\mathcal P^H$ to be thinned by addition into $K$ natural exponential families.  To streamline the statement of the theorem, we start with a definition.
 
\begin{definition}[$K$-way convolution]
\label{def:conv}
A probability distribution $H$ is the $K$-way convolution of distributions $H_1,\ldots, H_K$ if $\sum_{k=1}^KY_k\sim H$ for $(Y_1,\ldots,Y_K)\sim H_1\times\cdots\times H_K$.
\end{definition}

\begin{theorem}[Thinning natural exponential families by addition]\label{thm:natural-exponential-families}
The natural exponential family $\mathcal P^H$ can be thinned by $T(\xt{1},\ldots,\xt{K})=\sum_{k=1}^K\xt{k}$ into $K$ natural exponential families $\mathcal P^{H_1},\ldots,\mathcal P^{H_K}$ if and only if $H$ is the $K$-way convolution of $H_1,\ldots,H_K$.
\end{theorem}

The $K$ natural exponential families in Theorem \ref{thm:natural-exponential-families} can be different from each other, but they are all indexed by the same $\theta\in\Omega$ that was used in the original family $\mathcal P^H$. The proof of Theorem~\ref{thm:natural-exponential-families} is in Supplement~\ref{app:pf-exp-fam}. 

\cite{neufeld2023data} show that it is possible to thin a Gaussian random variable by addition into $K$ independent Gaussians.  We now see that this result follows from Theorem~\ref{thm:natural-exponential-families}. 

\begin{exmp}[Thinning $N_n(\theta, I_n)$] 
\label{exmp:gaussian}
The family of $N_n(\theta, I_n)$ distributions is a natural exponential family indexed by $\theta\in\mathbb{R}^n$. It can be written in the notation of this section as 
$\mathcal{P}^H$, where $H$ represents the $N_n(0_n, I_n)$ distribution.  Furthermore, $H$ is the $K$-way convolution of $H_k = N_n(0_n, \epsilon_k I_n)$ for $k = 1, 2, \ldots, K$, where $\epsilon_1,\ldots,\epsilon_K>0$ and $\sum_{k=1}^K \epsilon_k=1$.  Thus, by Theorem~\ref{thm:natural-exponential-families},   we can thin  $\mathcal{P}^H$ by addition into $\mathcal P^{H_1}, \ldots, \mathcal P^{H_K}$, where $P_\theta^{H_k}=N_n(\epsilon_k \theta, \epsilon_k I_n)$. %Unlike the Poisson example, here each $\mathcal P^{H_k}$ is a different family unless $\epsilon_k=1/K$.
\end{exmp}

In Supplement \ref{app:UV}, we show that Example \ref{exmp:gaussian} is closely connected 
to a randomization strategy that has been frequently used in the literature.

Not all natural exponential families satisfy the condition of Theorem \ref{thm:natural-exponential-families}. 
We prove in Section \ref{sec:bernoulli} that the distribution $H=\text{Bernoulli}(0.5)$ cannot be written as the sum of two independent, non-constant random variables. 
Since $\mathcal P^{\text{Bernoulli}(0.5)}$ is the $\text{Bernoulli}([1+e^{-\theta}]^{-1})$ natural exponential family, Theorem \ref{thm:natural-exponential-families} implies that Bernoulli random variables cannot be thinned by addition into natural exponential families. In Section~\ref{sec:bernoulli} we will further prove that {\em no function} $T(\cdot)$ can thin the Bernoulli family.

\subsection{Connections to \citet{neufeld2023data}}
\label{subsec:neufeld}

\cite{neufeld2023data} focus on convolution-closed families, i.e., those for which convolving two or more distributions (see Definition~\ref{def:conv}) in the family produces a distribution that is in the family. 
They provide a recipe for decomposing 
a random variable $X$ drawn from a distribution in such a family into independent random variables $X^{(1)}, \ldots, X^{(K)}$ that sum to yield $X$.  
We now show that their decompositions of exponential dispersion families are encompassed by Theorem~\ref{thm:natural-exponential-families}.

\emph{Exponential dispersion families} \citep{jorgensen1992exponential, jorgensen1998stationary} are a subclass of convolution-closed families. Given a distribution $H$ with $\psi_H(\theta)<\infty$ for $\theta\in\Omega$ (as in \eqref{eq:natural}), we identify the set of distributions $H_\lambda$ for which $\psi_{H_\lambda}(\cdot)=\lambda\psi_H(\cdot)$ (i.e., distributions whose cumulant generating function is a multiple of $H$'s cumulant generating function).  We define $\Lambda$ to be the set of $\lambda$ for which such a distribution $H_\lambda$ exists.  Then, an (additive) \emph{exponential dispersion family} is $\mathcal{P} = \bigcup_{\lambda \in \Lambda}\mathcal P^{H_\lambda}$, where $\mathcal P^{H_\lambda}$ is the natural exponential family generated by $H_\lambda$ (see \eqref{eq:natural}).  The distributions in $\mathcal P$ are indexed over $(\theta,\lambda)\in\Omega\times\Lambda$ and take the form $dP^{H_\lambda}_{\theta} (x) = e^{x^\top \theta - \lambda \psi_H(\theta)} dH_\lambda(x)$. 

In words, an exponential dispersion family results from  combining a collection of related natural exponential families.  For example, starting with $H=\text{Bernoulli(1/2)}$, we can take $\Lambda=\mathbb Z^+$ since for any positive integer $\lambda$, $H_\lambda=\text{Binomial}(\lambda,1/2)$ satisfies the necessary cumulant generating function relationship.  Then, $\mathcal P^{\text{Binomial}(\lambda,1/2)}$ corresponds to the binomial natural exponential family that results from fixing $\lambda$. 
Finally, allowing $\lambda$ to vary gives the full binomial exponential dispersion family, which is the set of all binomial distributions (varying both of the parameters of the binomial distribution). 


By construction, for any $\lambda_1,\ldots,\lambda_K\in\Omega$, convolving $P^{H_{\lambda_1}}_\theta,\ldots,P^{H_{\lambda_K}}_\theta$ gives the distribution $P^{H_\lambda}_\theta$, where $\lambda=\sum_{k=1}^K\lambda_k$.  The next corollary is an immediate application of Theorem~\ref{thm:natural-exponential-families} in the context of exponential dispersion families.
Notably, 
 the distributions $\Qt{k}_\theta$ themselves still belong to the exponential dispersion family $\mathcal P$ to which the distribution of $X$ belongs. 
\begin{corollary}[Thinning while remaining inside an exponential dispersion family] \label{cor:neufeld}
Consider an exponential dispersion family $\mathcal{P} = \bigcup_{\lambda \in \Lambda}\mathcal P^{H_\lambda}$ and suppose $\lambda_1,\ldots,\lambda_K\in\Lambda$.  Then for $\lambda=\sum_{k=1}^K\lambda_k$, we can thin the natural exponential family $\mathcal P^{H_\lambda}$ by $T(\xt{1},\ldots,\xt{K})=\sum_{k=1}^K\xt{k}$ into the natural exponential families $\mathcal P^{H_{\lambda_1}},\ldots,\mathcal P^{H_{\lambda_K}}$.
\end{corollary}
This result corresponds exactly to the data thinning proposal of  \cite{neufeld2023data}.  We see from Corollary~\ref{cor:neufeld} that that proposal thins a natural exponential family, $\mathcal P^{H_\lambda}$, into a \emph{different} set of natural exponential families, 
$\mathcal P^{H_{\lambda_1}},\ldots,\mathcal P^{H_{\lambda_K}}$. However, 
 from the perspective of exponential dispersion families, it thins an exponential dispersion family into the same exponential dispersion family.  Continuing the binomial example from above, the corollary tells us that we can thin the binomial family with $\lambda$ as the number of trials into two or more binomial families with smaller numbers of trials, provided that $\lambda>1$.

\cite{neufeld2023data} focus on convolution-closed families, not exponential dispersion families. However, \cite{jorgensen1998stationary} note that all convolution-closed families that have moment-generating functions can be written as exponential dispersion families. The Cauchy distribution is convolution-closed, but does not have a moment generating function and thus is not an exponential dispersion family. As we will see in Example~\ref{ex:cauchy}, the $\text{Cauchy}(\theta_1, \theta_2)$ distribution cannot be thinned by addition: decomposing it using the recipe of \citet{neufeld2023data} requires knowledge of both unknown parameters. Thus, not all convolution-closed distributions can be thinned by addition in the sense of Definition~\ref{def:thinning}. However, \cite{neufeld2023data} claim that all convolution-closed distributions \emph{can} be thinned. This apparent discrepancy  is due to a slight difference in the definition of thinning between our paper and theirs: in Definition~\ref{def:thinning}, we require that $G_t$ not depend on $\theta$; however, \cite{neufeld2023data} have no such requirement. In practice, data thinning is useful only if $G_t$ does not depend on $\theta$, and so there is no meaningful difference between the two definitions.
 


\subsection{Thinning natural into general exponential families} 
\label{subsec:natural-to-general}


In this section, we apply Algorithm~\ref{alg:recipe} in the case that $\cQt{k}$ are (possibly non-natural) exponential families, for which the sufficient statistic need not be the identity. 
In particular, for $k=1,\ldots, K$, we let $\cQt{k}=\{\Qt{k}_\theta:\theta\in\Omega\}$ denote an exponential family based on a known distribution $H_k$ and sufficient statistic $T^{(k)}(\cdot)$:
\begin{equation}\label{eq:exp-fam}
d\Qt{k}_\theta(x)=\exp\{[T^{(k)}(x)]^\top\eta(\theta)-\psi_k(\theta)\}dH_k(x).
\end{equation}
As in Section \ref{subsec:natural}, $e^{-\psi_k(\theta)}$ is the normalizing constant needed to ensure that $\int d\Qt{k}_\theta(x)=1$ and $\Omega$ is the set of $\theta$ for which $\psi_k(\theta)<\infty$.  The function $\eta(\cdot)$ maps $\theta$ to the natural parameter.  We note that  $\sum_{k=1}^K T^{(k)}(\Xt{k})$ is a sufficient statistic for $\theta$ based on $(\Xt{1},\dots,\Xt{K})\sim \Qt{1}_\theta\times\cdots\times\Qt{K}_\theta$.   Then  Algorithm~\ref{alg:recipe} tells us that we can thin the distribution of this sufficient statistic. This  leads to the next result.

\begin{proposition}[Thinning natural exponential families with more general functions $T(\cdot)$] \label{prop:exp-family}
Let $\Xt{1},\dots,\Xt{K}$ be independent random variables with $\Xt{k}\sim\Qt{k}_\theta$ for $k=1,\ldots,K$ from any (i.e., possibly non-natural) exponential families $\cQt{k}$ as in \eqref{eq:exp-fam}.
Let $P_\theta$ denote the distribution of $\sum_{k=1}^K T^{(k)}(\Xt{k})$. Then, $\mathcal P=\{P_\theta:\theta\in\Omega\}$ is a natural exponential family, and we can thin it  into $\Xt{1},\ldots,\Xt{K}$ using the function $T(\xt{1},\dots,\xt{K})=\sum_{k=1}^K T^{(k)}(\xt{k})$.
\end{proposition}
The fact that $\mathcal P$ in this result is a natural exponential family follows from recalling that the sufficient statistic of an exponential family follows a natural exponential family \citep[Lemma~2.7.2(i)]{lehmann2005testing}. 
Many named exponential families are not natural exponential families, involving non-identity functions $T^{(k)}(\cdot)$, such as the logarithm or polynomials.  Therefore, to thin into those families, Proposition~\ref{prop:exp-family} will be useful.

Proposition~\ref{prop:exp-family} implies that many natural exponential families \textit{can} be thinned by a function of the form $T(\xt{1},\dots,\xt{K})=\sum_{k=1}^K T^{(k)}(\xt{k})$. The next theorem states that if a natural exponential family can be thinned, then the thinning function \textit{must} take this form. 

\begin{theorem}[Thinning functions for natural exponential families] \label{thm:backwards-natexpfam}
Suppose $X\sim P_\theta$, where $\mathcal{P}=\{P_\theta: \theta\in\Omega\}$ is a full-rank natural exponential family with density/mass function $p_\theta(x)=\exp(\theta^\top x - \psi(\theta))h(x)$. If $\mathcal{P}$ can be thinned by $T(\cdot)$ into $\Xt{1},\dots,\Xt{K}$, then:
\begin{enumerate}
    \item The function $T(\xt{1},\dots,\xt{K})$ is of the form $\sum_{k=1}^K T^{(k)}(\xt{k})$.
    \item $\Xt{k}\overset{\text{ind}}{\sim} \Qt{k}_\theta$ where $\Qt{k}_\theta$ is an exponential family with sufficient statistic $T^{(k)}(\Xt{k})$.
\end{enumerate}
\end{theorem}

The proof of Theorem~\ref{thm:backwards-natexpfam} 
is provided in Supplement~\ref{app:pf-backwards}. 

To illustrate the flexibility provided by Proposition~\ref{prop:exp-family} and Theorem~\ref{thm:backwards-natexpfam}, we demonstrate that a natural exponential family $\mathcal P$ can be thinned by different functions $T(\cdot)$, leading to families of distributions $\cQt{1},\ldots,\cQt{K}$ different from $\mathcal P$. Specifically, we consider three possible $K$-fold thinning strategies for a gamma distribution when the shape, $\alpha$, is known but the rate\footnote{Although $\theta$ is often used in the gamma distribution to denote the scale parameter, here we use it to denote the rate parameter.} $\theta$, is unknown.  

\begin{exmp}[Thinning $\text{Gamma}(\alpha,\theta)$ with $\alpha$ known, approach 1] \label{ex:dtgamma} 
Following Algorithm~\ref{alg:recipe}, we start with $\Xt{k} \overset{iid}{\sim} \text{Gamma}\left(\frac{\alpha}{K},\theta\right)$ for $k=1,\ldots,K$, and note that $T(\Xt{1},\dots,\Xt{K})=\sum_{k=1}^K\Xt{k}$ is sufficient for $\theta$. Thus, we can thin the distribution of $\sum_{k=1}^K\Xt{k}$.  A well-known property of the gamma distribution tells us that this is a $\text{Gamma}(\alpha,\theta)$ distribution.  Sampling from $G_t$ as in Theorem~\ref{thm:generalized-thinning} 
corresponds exactly to the multi-fold gamma data thinning recipe of \cite{neufeld2023data} where $\epsilon_k=\frac{1}{K}$.
\end{exmp}

Alternatively, when $\alpha$ can be expressed as half of a natural number, we can apply Proposition~\ref{prop:exp-family} to decompose the gamma family into centred normal data. 

\begin{exmp}[Thinning $\text{Gamma}(\alpha,\theta)$ with $\alpha=K/2$ known, approach 2] \label{ex:scaled-normal}
Starting with $\Xt{k} \overset{iid}{\sim} N(0,\frac{1}{2\theta})$, notice that $T^{(k)}(\xt{k})=(\xt{k})^2$. We thus apply Proposition~\ref{prop:exp-family} using $T(\xt{1},\dots,\xt{K})=\sum_{k=1}^K(\xt{k})^2$ to thin the sufficient statistic, $\sum_{k=1}^K(\Xt{k})^2\sim\frac{1}{2\theta}\chi_K^2=\text{Gamma}\left(\frac{K}{2},\theta\right)$, into $(\Xt{1},\dots,\Xt{K})$. The function $G_t$ from Theorem~\ref{thm:generalized-thinning} is the conditional distribution $(\Xt{1},\dots,\Xt{K})|\sum_{k=1}^K(\Xt{k})^2=t$. By rotational symmetry of the $N_K(0,(2\theta)^{-1}I_K)$ distribution (the joint distribution of $(\Xt{1},\dots,\Xt{K})$)
, $G_t$ is the uniform distribution on the $(K-1)$-sphere of radius $t^{1/2}$. To sample from this conditional distribution, we generate $Z\sim N_K(0,I_K)$ and then take  $(\Xt{1},\dots,\Xt{K})|X$ to be $X^{1/2}\frac{Z}{\|Z\|_2}$.
\end{exmp}

If $\alpha$ is a natural number, applying a similar logic leads to a family of decompositions indexed by a hyperparameter $\nu>0$ that thin the gamma family with unknown rate into the Weibull family with unknown scale. See Example \ref{ex:weibull} in Supplement \ref{subsec:weibull-proofs}. 



