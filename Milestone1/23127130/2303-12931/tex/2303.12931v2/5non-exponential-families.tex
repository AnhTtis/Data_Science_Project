\section{Thinning outside of exponential families}
\label{sec:outside-exp-fam}

In this section, we focus on thinning outside of exponential families.
Outside of the exponential family, only certain distributions with domains that vary with the parameter of interest have sufficient statistics that are bounded as the sample size increases \citep{darmois, koopman, pitman_1936}. 
Thus, we first consider a setting where $\theta$ alters the support of the distribution (Section~\ref{sec:varysupport}), and then one where the sufficient statistic's dimension grows as the sample size increases (Section~\ref{sec:sample-splitting}). 

\subsection{Thinning distributions with varying support} \label{sec:varysupport}

We consider examples in which the parameter of interest, $\theta$, changes the support of a distribution. 
In Example~\ref{ex:scaled-uniform}, $\theta$ scales the support.  

\begin{exmp}[Thinning $\text{Unif}(0,\theta)$] \label{ex:scaled-uniform}
We start with  $\Xt{k} \overset{iid}{\sim} \theta \cdot\text{Beta}\left(\frac{1}{K},1\right)$ for $k=1,\ldots,K$, and note that $T(\Xt{1},\dots,\Xt{K}) = \max(\Xt{1},\dots,\Xt{K})$ is sufficient for $\theta$. 
 Furthermore, $\max(\Xt{1},\dots,\Xt{K}) \sim \text{Unif}(0, \theta)$. Thus, we define $G_t$ to be the conditional distribution of 
 $(\Xt{1},\dots,\Xt{K})$ given $\max(\Xt{1},\dots,\Xt{K}) = t$. Then, 
 by Theorem~\ref{thm:generalized-thinning}, 
 we can thin  $X \sim \text{Unif}(0, \theta)$ by 
 sampling from  $G_X$. 
To do this, we first   
draw $C\sim\text{Categorical}_K\left(1/K, \ldots, 1/K\right)$. Then, $\Xt{k} = C_kX+(1-C_k)Z_k$ where $Z_k \overset{iid}{\sim} X\cdot\text{Beta}\left(\frac{1}{K},1\right)$.
\end{exmp}
This is a special case of Example~\ref{ex:scaled-beta} in Supplement~\ref{subsec:scaled-beta-proofs}, in which we thin the scale family $\theta\cdot\text{Beta}(\alpha,1)$ where $\alpha$ is known. Setting $\alpha=1$ yields Example \ref{ex:scaled-uniform}.

Similar thinning results can be identified for distributions in which $\theta$ shifts the support. In Supplement~\ref{subsec:shifted-exponential-proofs}, we show that $X\sim \mathrm{SExp}(\theta,\lambda)$, the location family generated by shifting an exponential random variable by $\theta$, can be thinned by the minimum function.

\subsection{Sample splitting as a special case of generalized data thinning}\label{sec:sample-splitting}

We now consider sample splitting, a well-known approach for splitting a sample of  observations into two or more sets \citep{cox1975note}. 
We show that sample splitting can be viewed as an instance of generalized thinning. In this setting, $X=(X_1,\ldots,X_n)$ is a sample of independent and identically distributed random variables, $X_i\in\mathcal X$, each having distribution $F\in\mathcal F$, where $\mathcal F$ is some (potentially non-parametric) family of distributions and $\mathcal X$ is the set of values that the random variable $X_i$ can take (most commonly $\mathcal X=\mathbb R^p$).  That is, $X\sim P_F\in \mathcal P$, where
$\mathcal P=\{F^n:F\in\mathcal F\}$,
and $F^n=F\times\cdots\times F$ denotes the joint distribution of $n$ independent random variables drawn from $F$. 


\begin{exmp}[Sample splitting is a special case of generalized data thinning] \label{ex:samplesplit}
We begin with $\Xt{k} := (\Xt{k}_{1},\ldots,\Xt{k}_{n_k}) \overset{iid}{\sim} F^{n_k}$, for $k=1,\ldots,K$. Here, 
$n_1,\ldots,n_K >0$, 
 and $\sum_{k=1}^K n_k=n$. 
 That is, 
for $k=1,\ldots,K$, $\Xt{k}\in\mathcal X^{n_k}$ denotes a set of $n_k$ independent and identically distributed draws from $F$.

Our goal is to thin $S(X)$, where $S:\mathcal X^n\to\mathcal X^n$ sorts the entries of its input based on their values.
We define $T:\mathcal X^{n_1}\times\cdots\times \mathcal X^{n_K}\to \mathcal X^n$ as
$T(\xt{1},\ldots,\xt{K})=S((\xt{1},\ldots,\xt{K}))$,
the function that  concatenates its arguments and then applies $S(\cdot)$. 
Then $T(\Xt{1},\ldots,\Xt{K})$ is a sufficient statistic for $F$, and 
furthermore, $T(\Xt{1},\ldots,\Xt{k}) \overset{D}{=} S(X)$. 

We define $G_t$ to be the conditional distribution of $(\Xt{1},\ldots,\Xt{K})$ given $  T(\Xt{1},\ldots,\Xt{K})=t$. Suppose we observe $X\sim F^n$. 
Then, by Theorem~\ref{thm:generalized-thinning}, we can indirectly thin $X$ through $S(\cdot)$ by $T(\cdot)$ by sampling from $G_X$. This conditional distribution is uniform over all   
$\frac{n!}{n_1!\cdots n_K!}$ assignments of $n$ items to $K$ groups of sizes $n_1,\ldots,n_K$. Thus, to sample from $G_X$, we randomly partition the sample of size $n$ into $K$ groups of sizes $n_1,\ldots,n_K$.
This is precisely the same as sample splitting. 
\end{exmp}
