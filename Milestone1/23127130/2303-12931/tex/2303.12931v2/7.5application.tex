\section{Changepoint detection in wind speed data}
\label{sec:changepoint}

To demonstrate the utility of generalized data thinning, we consider detecting changepoints in the variance of wind speed data. We use a wind speed dataset \citep{haslett1989space} collected in the Irish town of Claremorris, available in the R package \texttt{gstat} \citep{pebesma2004multivariable}. 
\citet{killick2014changepoint} took first differences to remove the periodic mean, and then modeled the
resulting $X_i$ for $i = 1, \dots, n$ as independent observations with $X_i \sim \text{Normal}(0, \theta_i)$. They then estimated changepoints in the variance $\theta_1,\ldots,\theta_n$. Here, we take their analysis a step further by testing for a difference in variance on either side of each estimated changepoint. 


First, we consider a naive approach.

\noindent \emph{Naive approach that uses the same data for estimation and validation:}
\begin{enumerate}
\item We compute $Z_i := X_i^2$. Note that $Z_i  \sim \text{Gamma}\left(\frac{1}{2}, \frac{1}{2\theta_i}\right)$.
    \item 
We estimate changepoints in $Z_1,\ldots,Z_n$.
\item We fit a gamma GLM to test for a change in the rate of $Z_i$ on either side of each estimated changepoint. 
\end{enumerate}
To estimate changepoints in Step 2, we use the nonparametric changepoint detection method of \citet{haynes2017computationally}, implemented in the \texttt{changepoint.np} R package, with a manual penalty of 10 and a minimum segment length of 10 days.


However, using the same data to estimate and test changepoints will lead to many false discoveries, as has been pointed out by \cite{hyun2021post} and \cite{jewell2022testing} in a related setting. 
Generalized data thinning offers a solution to this problem.

\noindent \emph{Generalized data thinning approach:}
\begin{enumerate}
\item We indirectly thin each $X_i$ through the function $S(x_i)=x_i^2$, as in Example~\ref{ex:other}.1 (with $\mu=0$).  This yields $\Xt{1}_1,\ldots,\Xt{1}_n$ and $\Xt{2}_1,\ldots,\Xt{2}_n$, where $\Xt{1}_i, \Xt{2}_i \sim \mathrm{Gamma}\left(\frac{1}{4}, \frac{1}{2 \theta_i}\right)$ and $\Xt{1}_i$ and $\Xt{2}_i$ are independent. 
\item We estimate changepoints in $\Xt{1}_1,\ldots,\Xt{1}_n$.
\item We fit a gamma GLM to test whether there is a change in the rate of  $\Xt{2}_1,\ldots,\Xt{2}_n$ on either side of each estimated changepoint. 
\end{enumerate}
In Step 2, we once again apply  the nonparametric changepoint detection method of \citet{haynes2017computationally} with a manual penalty of 10 and a minimum segment length of 10 days.


In Figures~\ref{fig:simulation}, \ref{fig:null}, and \ref{fig:alt} of Supplement~\ref{app:changepoint}, we demonstrate in a simulation 
that the naive approach fails to control the type 1 error rate, whereas our generalized data thinning approach does control the type 1 error rate.  Turning back to the actual data, the top two panels of Figure \ref{fig:application}  show the results of applying the naive and data thinning approaches. We see that the naive method's p-values are below the 0.05 threshold
for nearly half of the estimated changepoints. By contrast, the data thinning approach's p-values are below the 0.05 threshold
for only three of 53 estimated changepoints. In light of the results in Supplement~\ref{app:changepoint}, we believe that most of the  changepoints for which we rejected the null hypothesis using 
the naive approach are false positives.

\begin{figure}[!h]
\begin{center}
\includegraphics[width=\textwidth]{figures/application_changepointGDT.pdf}
\end{center}
\caption{Results for the wind speed data analysis described in Section \ref{sec:changepoint}. In each panel, the $x$-axis indexes the days. \emph{First row:} Wind speed data over time, as well as results of the naive approach: red lines indicate changepoints estimated  using all of the data, and red asterisks indicate the estimated changepoints for which the  p-value computed using all of the data was below the 0.05 threshold. 
\emph{Second row:} Same as the first row, but for the data thinning approach: blue lines indicate changepoints  estimated using the training set, and blue asterisks indicate those with test set p-values below 0.05. \emph{Third row:} We binned the 2,000 days into  10-day windows. For each 10-day window, we display the percentage of replicates of data thinning for which at least one changepoint was estimated on the training set. Dashed lines are drawn every 365 days. \emph{Fourth row:} 
We binned the 2,000 days into  10-day windows. For  each 10-day window, we display the percentage of replicates of data thinning for which at least one changepoint was estimated on the training set \emph{and} that estimated changepoint had a test set p-value below 0.05.}
\label{fig:application}
\end{figure}
\cite{yu2020veridical} point out that it is important for the findings of a data analysis to be stable across perturbations of the data; a similar argument underlies the  stability selection proposal of \cite{meinshausen2010stability}. 
In this spirit,  
we repeat the thinning procedure 100 times. The third panel of  Figure \ref{fig:application} displays, for each 10-day window, the percentage of replicates in which at least one changepoint was estimated  using the training set. The fourth panel displays, for each 10-day window, the percentage of replicates for  which there was at least one changepoint estimated using the training set, \emph{and} that estimated changepoint had a test set p-value below 0.05.  

We conclude by noting that data thinning has a substantial advantage over sample splitting in this example.  As noted in Section~\ref{sec:sample-splitting}, sample splitting assumes that the observations are independent and identically distributed, which is explicitly not the case in this setting.  An approach that is sometimes used in this context is to assign alternate points to train and test sets.  However, such a deterministic splitting rule would not allow for a stability analysis such as the one displayed in the two lower panels of Figure~\ref{fig:application}.



