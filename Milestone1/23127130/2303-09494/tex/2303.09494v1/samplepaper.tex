% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}
%
\usepackage{graphicx}
\usepackage{cite}
\usepackage{amsmath }
\usepackage{multicol}
\usepackage{tabularx} % in the 


%multi-column
%\multicolumn{number cols}{align}{text} % align: l,c,r
 
%multi-row
\usepackage{multirow}
 
%\multirow{number rows}{width}{text}

\usepackage{multirow}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{mathptmx}
\usepackage{soul}\setuldepth{article}
 \usepackage{float}
\usepackage{amsmath}
\usepackage{cases}
\usepackage{array}

\usepackage{graphicx,changepage}
%\usepackage[hidelinks]{hyperref}
\usepackage{hyperref}
\hypersetup{ colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    citecolor=blue,
    urlcolor=cyan,
    pdftitle={Overleaf Example},
    pdfpagemode=FullScreen,
    }
%\usepackage[colorlinks=true, urlcolor=blue, pdfborder={0 0 0}]{hyperref}
\usepackage{graphicx}
\graphicspath{ {./images/} }
% (2) specify encoding
\usepackage[T1]{fontenc}
\usepackage{geometry}
% (3) load symbol definitions
\usepackage{textcomp}
\usepackage{rotating}



%\usepackage{times}
%\normalfont
%\usepackage[T1]{fontenc}
%\usepackage[mtplusscr,mtbold]{mathtime}
%
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

\begin{document}
%
\title{Knowledge Distillation for Adaptive MRI Prostate Segmentation Based on Limit-Trained Multi-Teacher Models}
%
\titlerunning{AKD\_MRI}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Eddardaa Ben Loussaief\inst{1} \and Hatem Rashwan\inst{1} \and Mohammed Ayad \inst{2} \and Mohammed Zakaria Hassan\inst{1}
\and
Domenec Puig\inst{1}}

\authorrunning{Eddardaa et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{Department of Computer Engineering and Mathematics, Universitat Rovira I Virgili. \\
\email{eddardaa.benloussaief@urv.cat} \and Department of Electronic, Electric and Automatic Engineering, Universitat Rovira I Virgili, \\ 43007 Tarragona, Spain
}

 \maketitle              % typeset the header of the contribution
%
\begin{abstract}
% Recently, we have witnessed significant advances in the performance of deep models applied to various medical tasks. these models have a complex architecture and strong learning ability and thereby a huge computational complexity. To deal with this problem, an efficient learning scheme has been introduced that consists of distilling the knowledge from a cumbersome well-trained model to  a lightweight model. Knowledge distillation (KD) forces a student model to improve its  reliability through a complex teacher, hence we obtain a compact model, with low parameters which able to achieve a significant performance enhancement. In This work, we deploy a knowledge distillation framework for prostate MRI segmentation, we propose to combine features-based distillation with  KD and Dice losses. We further  demonstrate its effectiveness on MRI segmentation for prostate tumors through the application of two compression procedures, where the student model learns from a single well-trained teacher. Furthermore, to distill more discriminated knowledge, we integrate cross-teacher learning where the compact model should be grasped by receiving the knowledge from multiple teachers. As results. we obtained an enhanced lightweight model without any extra computation cost and its performance achieves up to  $40\%$ in our experiments.
With numerous medical tasks, the performance of deep models has recently experienced considerable improvements. These models are often adept learners. Yet, their intricate architectural design and high computational complexity make deploying them in clinical settings challenging, particularly with devices with limited resources. To deal with this issue, Knowledge Distillation (KD) has been proposed as a compression method and an acceleration technology. KD is an efficient learning strategy that can transfer knowledge from a burdensome model (i.e., teacher model) to a lightweight model (i.e., student model). Hence we can obtain a compact model with low parameters with preserving the teacher's performance. Therefore, we develop a KD-based deep model for prostate MRI segmentation in this work by combining features-based distillation with Kullback–Leibler divergence, Lovasz, and Dice losses. We further demonstrate its effectiveness by applying two compression procedures: 1) distilling knowledge to a student model from a single well-trained teacher, and 2) since most of the medical applications have a small dataset, we train multiple teachers that each one trained with a small set of images to learn an adaptive student model as close to the teachers as possible considering the desired accuracy and fast inference time. Extensive experiments were conducted on a public multi-site prostate tumor dataset, showing that the proposed adaptation KD strategy improves the dice similarity score by $9\%$, outperforming all tested well-established baseline models.
\keywords{Prostate MRI segmentation \and compact model \and knowledge distillation \and  multiple teachers distillation.}
\end{abstract}
\section{Introduction}

Magnetic Resonance Imaging (MRI) has been widely used for medical imaging diagnosis, i.e., semantic segmentation that consists of pixel-level interpretation by providing; as a result,  so-called segmentation masks. However, medical imaging segmentation remains challenging due to various factors, i.e., limited data resources and image acquisition (imaging modalities and scanning protocols). Deep learning (DL) networks have proven their efficiency in various medical tasks, especially semantic segmentation.  For instance, UNet \cite{r10} is the most used DL architecture for medical imaging segmentation that can handle small training data.
% due to its structure that is composed of down-sampling and up-sampling blocks, Unet has proven its accuracy in the segmentation results even with limited data
Recently, many efforts have been proposed to upgrade the UNet architecture, i.e., by adopting a strong features extractor, such as ResNet \cite{r21},  as well as by integrating attention blocks or upgrading UNet to support 3D data as described in 3D-UNet \cite{r12}, thereby increasing  computational components and expansion of  the storage. Thus, deploying UNet and its variants in a real-time clinical setting is still challenging. In response to the issues mentioned previously, some recent works have started exploiting lightweight models, i.e., ESPNet \cite{r20}, ENet \cite{r19}, MobileNet-v2 \cite{r22}, etc., in real-time medical imaging segmentation, but with accepting the degrade of accuracy. Thus, there is a dilemma in balancing the model performance and the low computational cost. 

Hinton et al. \cite{r8} have proposed a new learning schema, knowledge distillation (KD), to overcome the above drawbacks. KD tends to distill the learning from a well-trained teacher to a lightweight student model, enhancing the latter's performance by preserving the teacher's performance. KD has recently gained the attention of several researchers in semantic segmentation. For instance, Xu et al.\cite{r9} proposed using a growing teacher assistant network (GTAN) for CT liver segmentation. The role of the proposed GTAN is to leverage the difference between the size of the models used, i.e., teacher and student.
Furthermore, Li et al. \cite{r26} adopted mutual KD to improve cross-modality segmentation, transferring prior knowledge from CT images to MRI images. In \cite{r7}, the knowledge adaptation for brain segmentation adopts the same teacher and student models network and exploits the coordinate distillation (CD) that incorporates the channel and space information. Additionally, in \cite{r3}, KD is applied for 3D  optical microscope image segmentation. However, the aforementioned methods teach the student network by only distilling the logits on the final teacher's output. Thus, the student still yields segmentation results with low accuracy.

Therefore, many recent methods developed feature-based KD methods to consider the intermediate features generated during the learning process and distill more discriminated information. In \cite{r1}, He et al. introduced an affinity distillation module to optimize the similarity between teacher and student features. In turn, Liu et al. \cite{r2} adopted two distillation schemes by applying pixel and structured pair-wise distillation based on intermediate feature learning. Qin et al.\cite{r4} investigated a new module called importance maps distillation that aims to match the student's feature maps with the teacher's feature maps through a re-scaling process. Due to the complex structure of medical data and the difference in the scanning protocols and patient privacy, the aforementioned methods may not yield good segmentation results in real-time clinic use.

To this end, Huang et al. \cite{r6} proposed to collect data from different hospitals to train an adaptive teacher model. To deal with the information disclosure and sharing of patients' data.% Back et al. \cite{r5} deployed a KD-based model to produce a mobile-device-based model allowing users to upload their data on their phones for the classification of skin disease. 
Training a teacher model with images from different sources will improve the model's generalization and it could yield good segmentation results. However, it can also introduce biases and confounding factors that negatively affect the model's performance. For example, hospitals may use different imaging machines with different settings, resulting in image quality and resolution variations. The model may learn to rely on these variations to distinguish between different classes, which can lead to poor generalization when applied to new data \cite{r34}. Here,  Multi-teacher KD can potentially help to address the issue of training DL models with medical images from different sites and hospitals with different scanning protocols. In the case of medical image segmentation, multi-teacher KD can help capture a wider range of features and patterns from the data, improving the student model's ability to generalize and adapt across different sources and protocols. The different teacher models may be trained on different subsets of the data, allowing the student model to learn from a diverse set of examples \cite{r35}. Additionally, medical datasets are always limited to a small set of images. Accordingly, we need to multi-teacher KD, but teachers trained with limited data. As far as we know, almost no methods have considered multi-teaching distillation training with limited data to build a valuable system-based distillation for medical imaging segmentation.

Consequently, in this work, we aim to develop multi-teacher framework-based distillation to tackle the problem of medical data sharing and limitations. We propose a novel learning scheme where the student model learns from the cross-teacher's logits and tends to mimic the middle teachers' features during the distillation process. Concretely, we perform two distillation architectures: 1) We adopt the intermediate features-based mapping along with KL\_divergence as logits-based to transfer the knowledge from the off-the-shelf MRI segmentation models to a compact model, i.e. a lightweight student model. 2) The majority of multi-teacher based distillation vote to the teacher that has the highest logits distribution or perform the averaging of the soft targets. Unlike these simple distillation manners, we propose an adaptive KD in that our strategy guides the training of the student model by aggregating the knowledge from $N$ teachers (we adopt here $n=3$)  through an adaptive weight. Furthermore, our selection of the teachers' networks no longer only considers the the-off-shelf segmentation networks with a high number of parameters, but also we share the dataset between the teachers. Specifically, to tackle the patient disclosure information and to respond to the real-time segmentation for the clinical setting, we split our data into three small sets to train the teachers separately. We conduct extensive experiments to validate the proposed distillation schemes on public prostate MRI datasets collected from different sources \cite{r17}. The results demonstrate the remarkable improvement of the lightweight model achieving an improvement of $~9\%$  for the MRI prostate tumor segmentation dice score compared to the state-of-the-art.

% \section{ Brief Literature Review}
% \subsection{Prostate imaging segmentation}

% Over the past few years, major advances in prostate tumor segmentation. Clark et al \cite{r11} adopted Unet  proposed in \cite{r10} to perform the T2 MRI  prostate segmentation. After the appearance of the Unet, Isensee et al.\cite{r12} introduced an improved Unet, nnUnet that compresses domain knowledge and chooses the best nnU-Net (2D or 3D) model for a given dataset.  Zhu et al.\cite{r15} adopted a cascade Unet where the first network tends to segment the whole prostate gland then the result of this later fed into the second network to detect the peripheral zone. Yu et al.\cite{r16} adjusted Unet architecture by incorporating  a residual connection that improves the
% prostate segmentation by using a features summation in the upsampling block.
% Tian el.\cite{r13} has proposed a PSPNet architecture by integrating fully connected networks.  Liu et al.\cite{r14} proposed an FCN with ResNet50 as the backbone for the detection of the prostate zones with the mechanism of feature pyramid attention. Zhu et al.\cite{r18} proposed a novel domain adaptation-based method, where they introduced a boundary-weighted segmentation to exceed the limited source data. To deal with the underfitting problem during the training, Liu et al.\cite{r17} implemented a robust multi-site segmentation model by aggregating prostate MRI from multiple sources.

% \subsection{Knowledge distillation}
% Knowledge distillation \cite{r8} is a compression form that aims to learn a lightweight model under limited computational resources from a powerful teacher network meanwhile retaining this latter's high-level capability. Recently, we have witnessed the use of knowledge distillation in medical imaging segmentation.
% % For example, Ho et al. \cite{r23} utilized KD for Chest X-Ray Abnormalities classification for lung disease. Two distillation procedures have been introduced where the student network has the option to distill from a cumbersome and efficient teacher model or to learn from itself i.e. self\_teacher distillation. In \cite{r24}, Wang et al. proposed an efficient self-supervised knowledge distillation-based framework that encodes the intra-instance feature representation  for skin lesion classification from dermoscopic images.
% For example, Dou et al. \cite{r25} introduced an unpaired cross-modality KD framework that shares the convolutions kernels of networks across CT and MRI scans for cardiac  and abdominal organ segmentation. In \cite{r7}, an efficient distillation scheme for brain segmentation has been proposed, it is based on coordinate distillation that incorporates space and channel information. Li et al. \cite{r26} proposed a mutual distillation scheme for cardiac segmentation to transfer the knowledge from an assistant modality to another target modality through an Image Alignment Module (IAM) to reduce the gap across data. In \cite{r4}, to boost the lightweight model to mimic the middle features extracted from the teacher network during the training, Qin et al.\cite{r4} constructed a novel module i.e. Importance Maps Distillation (IMD) for liver and kidney segmentation that guides the student network re-scale the features' student to imitate the features maps of the teacher. Noothout et al. \cite{r27} adopted two ensembles of convolutional neural networks as teacher
% models to segment the brain MRI imaging, chest CT, and cardiac
% cine-MRI. Xu et al.\cite{r9} proposed a growing teacher assistant network (GTAN) along with the main teacher to optimize the  disparity of teacher and student model sizes. They employed two self-teacher networks as growing teacher assistants as an intermediate bridge to transfer the knowledge from the principal teacher and the student. Referring to the aforementioned approaches, we conduct our distillation pipeline. 
\section{Methodology}
\subsection{Knowledge Distillation (KD)}
This work is DL-based KD technique for domain adaptation, it aims to generate a lightweight model through the guidance of a large and complex teacher network. During the distillation process, the student model imitates the teacher to gain a competitive performance. Thus, we can obtain a compact model KD-trained with a few parameters, and its efficiency is also improved.

\begin{figure}[H]
 \begin{center}
  \includegraphics[width=0.7\textwidth, height = 0.45\columnwidth]{overview3.png}
  \caption{Overview of the proposed  distillation pipeline.}
  \label{fig1}
  \end{center}
  \vspace{-1cm}
\end{figure}

The entire distillation structure shown in Fig. \ref{fig1} comprises two schemes. The first is mono-teacher distillation, where the student learns from a single cumbersome teacher well-trained. The second distillation scenario tends to learn the lightweight model from multi-teacher trained with limited data. We aim to enable the student to learn extra information from multiple teachers and to empower it to be adaptive to real-time prostate MRI segmentation for any hospital dataset to deal with private data sharing. Benefiting from MRI prostate multi-sources \cite{r17} data that we use for evaluating the two KD schemes, we split the large dataset into three small sets and then train the teachers individually using one set. Hence, we enable the ensemble of teachers to distill the student network through transferring process that uses the same losses as a mono-teacher. 
Our model ensures that the teacher models are diverse enough to capture a wide range of data variations while avoiding redundancy that could lead to overfitting. Additionally, we ensure that the student model can effectively learn from the ensemble of teacher models, which may require specialized training techniques based on effective distillation loss functions.

\subsection{Network optimization}
\label{sec1}
 Fig. \ref{fig1} illustrates the distillation pipeline introduced in this paper, where the architecture takes the MRI imaging as a stack of 2D grayscale slices. We adopt a transferring architecture comprised of logits-based and feature-based distillation.\par Logits-based distillation has been conducted in \cite{r8} as an efficient architecture to learn the student network from the soft targets provided by a well-optimized teacher model. In our paper, we propose a distillation architecture that uses soft targets that contains the class probability and the essential information for the student to mimic the output of the pre-trained teacher. The transfer probability is as follows:
\begin{equation}
\centering q_{i}=\frac{exp(z_{i}/\lambda)}{\sum_{j}exp(z_{j}/\lambda)},
\label{eq1}
\end{equation}
where $q_{i}$ indicates the input probability and $z_{i}$ denotes the ith class of the logits output, i.e., $z_{0}$ background and $z_{1}$ prostate. $\lambda$ is a hyperparameter referred to as the temperature to balance the distillation loss. Inspired by \cite{r8},  we determine a prediction  distillation that enables the lightweight model to learn the prediction probability of the final output segmentation of the teacher model, i.e., softmax output. The logits-based distillation loss is precisely measured by Kullback–Leibler (KL) divergence across the student's and teacher's softmax predictions. Thus, prediction distillation loss is defined by: 
\begin{equation}
    \centering KL_{loss}=\frac{1}{N}\sum_{i}^{N}KL(p_{i}^{s}||p_{i}^{t}),
    \label{eq2}
\end{equation}
 where the KL divergence function is denoted by $KL(.)$, where $N=w\times h$, all the pixels in segmentation, and $p_{i}^{s}$ and $p_{i}^{t}$ indicate the probability of ith pixel pair in the segmentation map of the student's and teacher's softmax  outcome, respectively. 
 
 Motivated by \cite{r1, r4}, along with the prediction distillation loss measured in (\ref{eq2}), we explore an intermediate distillation loss to conduct the feature-based distillation that considers an importance distillation loss and an affinity distillation loss to interpolate the student's and teacher's feature maps and optimize the similarity across them. Considering the intermediate distillation loss across middle feature maps for the teacher and student networks, we adopt a $Mid_{loss}$ that measure the importance and affinity losses proposed in \cite{r1,r4}. $Mid_{loss}$ and defined as follows:
\begin{equation}
        Mid_{loss}=\sum_{(i,j) \in P}||\frac{M_{i}^{s}}{||M_{i}^{s}||_{2}} -   \frac{M_{j}^{t}}{||M_{j}^{t}||_{2}}||_{1} + \sum_{(i,j) \in P}||V_{rc}^{s}-V_{rc}^{t}||_{2},
\end{equation}
where $M_{i}^{s}$ and $M_{j}^{t}$ are the importance maps of the ith and jth layer extracted from the student and teacher, respectively. $||.||_{1}$ and $||.||_{2}$ are the L1 and L2 normalization. P is the collection of pixel pair positions of the same size. $V_{rc}^{s}$ and $V_{rc}^{t}$ represent the region contrast vectors for the student and teacher, respectively ( as described in \cite{r1,r4}). The importance loss matches the teacher's feature maps to the student's features maps by re-scaling the latter. However, the region contrast consists of the transfer of the relationship information across networks by enabling the student model to imitate the region contrast between the region information of the foreground area and the background area.
    
 
 %We adopt the losses mentioned above  i.e. $KL_{loss}$, importance loss, and affinity loss as a $KD_{loss}$. 

To compare the student's segmentation mask with a hard target, i.e., ground truth, we consider the segmentation loss $Seg_{loss}$ that adopts Lovasz-softmax loss \cite{r28}, which is particularly useful for class imbalance present and boundary alignment, in addition to dice similarity loss \cite{r32}, as follows:
\begin{equation}
    \centering Seg_{loss}= \alpha_{1} Dice_{loss} + \alpha_{2} Lovasz_{loss},
    \label{eq3}
\end{equation}
where $\alpha_{1}$ and $\alpha_{2}$ are hyperparameters set to 0.2 and 0.3, respectively.  

As shown in Fig. \ref{fig1}, to obtain an end-to-end trainable student network, we exploit a combination of losses to perform the global distillation loss, $KD_{loss}$. Hence the total distillation for the mono-teacher scenario is given by the following formula:
    \begin{equation}
        \centering KD_{loss}=Seg_{loss} +\alpha Mid_{loss} + \beta KL_{loss},
        \label{eq4}
    \end{equation}
where $Seg_{loss}$ and $KL_{loss}$ presented in (\ref{eq2}) and (\ref{eq3}), respectively. $\alpha$ and $\beta$ are set to 0.1. The hyperparameters setting was settled after such empirical attempts  to conduct efficient segmentation results.\par 
For multi-teacher distillation, we introduce an adaptive strategy to empower the student to learn from all the teachers in the prediction distillation process. Thus, we propose an adaptive weight to compute the final output of three teacher models, $p_{i}^{t}=w_{j}\sum_{j}p^{t_{j}}$, where $j = 1:n$ and $n$ is the number of teachers, (in this work $n=3$ and $w_{j} \in \{w_{1}, w_{2}, w_{3}\}$). The adaptive weights $w_{j}$ calculated by:

\begin{math}
\centering
  \left\{
    \begin{array}{c}
      w_{1}=Dice_{loss}(p^{t_{1}},y)/\sum_{j}(Dice_{loss}(p^{t_{j}},y)\\
  w_{2}=Dice_{loss}(p^{t_{2}},y)/\sum_{j}(Dice_{loss}(p^{t_{j}},y)). \\
  w_{3}=Dice_{loss}(p^{t_{3}},y)/\sum_{j}(Dice_{loss}(p^{t_{j}},y))
    \end{array}
  \right.
\end{math} \\
\\
The new $KL_{loss}$ measures the prediction distillation between the final  $p_{i}^{t}$ and the student's output, $p_{i}^{s}$ as shown (\ref{eq2}). We also calculate the $Mid_loss$ across the three teachers and the student network as follows:
\begin{equation}
    Mid_{loss}= w_1Mid_{loss}(T1,S) + w_2Mid_{loss}(T2,s) + w_3Mid_{loss}(T3,S).
\end{equation}
%Hence, we perform the formula \ref{eq4} to measure the total distillation loss over the three teachers.



\section{Experiments}
\subsection{Dataset and evaluation metric}
\label{secdata}
We conducted our experiments on a publicly available MRI prostate dataset \cite{r17}, where the data comprises six different sites that were collected from three public datasets, i.e. The sites 1,2, and 3 are from  NCI-ISBI2013 \cite{r29}, and I2CVB \cite{r30}, respectively. Whilst sites 4, 5, and 6 are collected from PROMISE12 \cite{r31}. The data consists of 116 patient cases with a total slice number of $1740$ with their corresponding segmentation masks. For mono-teacher distillation, we split the data  into $80\%$, $5\%$, and $15\%$ for training, validation, and testing, respectively. According to multi-teacher distillation, we adopt the following site pair partitions: (1,2),  (3,4), and (5,6) for training teachers 1, 2, and 3, respectively. We compute the dice similarity score to assess  MRI segmentation results to different baseline architectures. 

\subsection{Setup}
A series of extensive experiments were conducted to validate the efficiency of our distillation pipeline. We select the powerful off-shelf-segmentation models, such as DeepLabv3+ \cite{r3},  PSPNet \cite{r13}, FCN\_ResNet101 \cite{r14}, and ResNext-101-32x8d \cite{r35} as teacher networks, and several publicity available lightweight networks, i.e.,  ENet \cite{r19}, ESPNet \cite{r20}, and MobileNet-v2 \cite{r22} as student models. We adopted the PyTorch official setup of all tested networks to train and test them on Gefore RTX 3050 ti(8GB). Adam optimizer was used during the training with its default configuration ($\beta_1 0.9$ and $\beta_2=0.999$) and an initial learning rate of 0.01. We also used CyclicLR to schedule the learning rate with the lowest learning rate of 0.000001 and step size=2000. We trained the models to converge with 100 epochs.

\subsection{Results}
\subsubsection{\textbf{\textit{Mono-teacher based distillation:}} }
We aim to learn a student network from a single teacher for the first scenario in our distillation pipeline. The teacher is well trained with the training set of cite{r17}, including the six sites. To demonstrate the power of the distillation scheme in the efficiency enhancement of a lightweight model, we conducted empirical series, where we adopted ENet \cite{r19}, ESPNet \cite{r20}, and MobileNet-v2 \cite{r22} as student networks with a low number of parameters. In turn, we selected complex teacher networks, i.e.,  DeepLabv3+ \cite{r3},  PSPNet \cite{r13}, FCN\_ResNet101 \cite{r14}, and ResNext-101-32x8d \cite{r35} to guide the aforementioned student models. DeepLabv3+ and PSPNet networks, with a backbone of ResNet50 \cite{r21}, and ResNet101 used as a backbone for FCN. The aforementioned networks are tailored for medical imaging tasks in the literature with high accuracy. We present quantitative segmentation results for MRI tumor prostate from the dataset in \cite{r17} in the table \ref{tab:single teacher}. As shown, with the appropriate selection of the teacher networks, all students are adept at learning and mimic the teachers' capability and achieve higher performance compared to the level of the teacher's performance. It is obvious to remark that ENet, ESPNet, and MobilENet-v2 embrace the maximal improvement of 5.87\%
(80.03 to 85.9), 9.1\% (75.5 to 84.3) and 6.9\% (78.4 to 85.3) in dice score, respectively. It is clear that all student networks are improved, however, they are still under the teacher's performance, but saving millions of parameters. The best improvement was yielded with ENet and FCN\_ResNet101 as a teacher with a Dice score of $85.9\%$. In Fig. \ref{fig2}-(column 4), we visualize the segmentation masks of two test samples where the lightweight network MobileNet-v2 was distilled from PSPNet. As shown, there is a significant difference across the segmentation masks given by MobileNet-v2 as baseline (column 3) and after distillation concretely for the second sample.
\begin{table}[ht]
\caption{CROSS EXPERIMENTS RESULTS BETWEEN A SINGLE TEACHER AND STUDENT ON MRI PROSTATE TUMOR SEGMENTATION. }
\begin{center}
\begin{tabular}{c |c|c|c}
    \hline
  Method & Dice score ($\% \pm std$)  & Params (M) & FLOPs (G)\\ \hline \hline
   \multicolumn{4}{c}{Teacher Networks (Baseline)}\\ \hline\hline
   
    T1: DeepLabV3+ & 89.01 $\pm 0.001$ & 56.8  &273.94   \\
                               T2: Fcn\_ResNet101 & 90.0 $\pm 0.002$ & 51.96  & 199.74   \\
                                T3:PSPNet & 86.3 $\pm 0.004$ &46.71   & 207.7   \\
                                T4:ResNext101 & 85.02 $\pm 0.006$ & 86.74  &96.54   \\
                               
                               \hline
    \hline
    \multicolumn{4}{c}{Student Networks}\\ \hline\hline
     S1: ENet Baseline & 80.03 $\pm 0.007$ & 353.76k  & 2.2   \\
     T1\_KD\_ENet & 84.6 $\pm 0.002$ & --&-- \\
     T2\_KD\_ENet &85.9 $\pm 0.001$&--&--\\
     T3\_KD\_ENet &84.2 $\pm 0.001$&--&-- \\
     T4\_KD\_ENet &83.7 $\pm 0.004$&--&--
\\     \hline \hline
   S2: ESPNet Baseline & 75.2 $\pm 0.081$ & 183.72k  & 1.27   \\
   T1\_KD\_ESPNet &81.9 $\pm 0.001$&--&-- \\
   T2\_KD\_ESPNet &84.3$ \pm 0.002$&--&--\\
   T3\_KD\_ESPNet&81.7 $\pm 0.004$&--&--\\
   T4\_KD\_ESPNet&80.5 $\pm 0.006$&--&--\\

   \hline\hline
    S3: MobileNet-v2 Baseline & 78.4 $\pm 0.008$ &2.23  & 19.84  \\
    T1\_KD\_MobileNet-v2 &82.3 $\pm 0.003$&--&--\\
    T2\_KD\_MobileNet-v2&81.2 $ \pm 0.001$&--&--\\
    T3\_KD\_MobileNet-v2 &85.3 $\pm 0.001$&--&--\\
    T4\_KD\_MobileNet-v2 &80.1 $\pm 0.006$&--&--\\
    \hline \hline
  
\end{tabular}
\end{center}
\label{tab:single teacher}
\vspace{-1cm}
\end{table}
The FLOPS and number of parameters are calculated using the Flops counter in PyTorch framework \textbf{ptflops} by feeding the input size, $1\times384\times384$, %to the function \textbf{get\_model\_complexity\_info} along
with the trained model to interpret the computational complexity of this latter as listed in the table \ref{tab:single teacher}. The ESPNet provided the lowest FLOPs among all tested models with FLOPs of $1.27 G$. The distillation with a well-trained teacher significantly improved the segmentation results with a huge reduction in FLOPs and number parameters.



\subsubsection{\textbf{\textit{Multi-teacher based distillation :}}}
We performed experiments to explore the multi-teacher distillation concept and verify if the student could learn more information through distilling from n teachers trained with limited data. In this work, we selected three teachers, T1: Deeplabv3+ \cite{r3},T2: PSPNet \cite{r13}, and T3: FCN-ResNet101 \cite{r14}, which yielded the best dice score as  baselines. Our multi-teacher network selection was also based on the model that empowers the lightweight student to gain the highest enhancement, i.e., we adopted PSPNet, DeepLabv3+, and FCN\_ResNet101 to conduct multi-teacher distillation architecture. The three teachers were trained with limited data; each teacher trained with two sites out of the six sites of the whole dataset as described in Section \ref{secdata}. As described in Section \ref{sec1}, we introduced an adaptive weight determinate by the dice loss for each teacher separately for the prediction distillation loss and the intermediate loss. Table \ref{tab: multi-teacher} lists the performance of the student networks distilling from three powerful teachers. Referring to table \ref{tab:single teacher}, all the students, i.e., ENet \cite{r19}, ESPNet \cite{r20}, and MobileNet-v2 \cite{r22} grasp a significant improvement in the dice score, when they distilled from Deeplabv3+ \cite{r3}, PSPNet \cite{r13}, and FCN\_ResNet101 \cite{r14} already tailored on state\_of\_the\_art medical imaging segmentation. 
\begin{table}[H]
\caption{CROSS EXPERIMENTS RESULTS BETWEEN A THREE TEACHER AND STUDENT ON MRI PROSTATE TUMOR SEGMENTATION. }
\begin{center}
\begin{tabular}{c |c}
    \hline
  Method & Dice score ($\% \pm std$)  \\ \hline \hline
   \multicolumn{2}{c}{Multi-Teacher Distillation }\\ \hline\hline
   
   
     S1: ENet Baseline & 80.03 $\pm 0.007$  \\
     T1+T2+T3\_KD\_ENet & 83.8 $\pm 0.004$  \\
     
   \hline \hline
   S2: ESPNet Baseline & 75.2 $\pm 0.081$  \\
   T1+T2+T3\_KD\_ESPNet &83.4 $\pm 0.003$ \\
  

   \hline\hline
    S3: MobileNet-v2 Baseline & 78.4 $\pm 0.008$ \\
    T1+T2+T3\_KD\_MobileNet-v2 &84.8 $\pm 0.004$\\
    
    \hline \hline
  
\end{tabular}
\end{center}
\label{tab: multi-teacher}


\end{table}
As shown in Table \ref{tab: multi-teacher}, all the student networks achieved better segmentation results, where they gain an improvement of up to 3.77\% (80.03 to 83.8), 8.2\% (75.2 to 83.4), and 6.4\% (78.4 to 84.8) for ENet, ESPNet, and MobileNet-v2, respectively. ESPNet is the lightest model with a high dice score compared to the ENet with a slight difference of a Dice score of $1\%$. Furthermore, we can observe that the multi-teacher distillation scheme gained a comparable dice score to the mono-teacher distillation. However, our aim is not only to construct a distillation pipeline that enables a lightweight model to imitate the strong teacher's performance, as obtained from mono-teacher distillation but also to build a compact adaptive model that can cope with multi-source data and data disclosure problems, as well as can be used on limited devices without extra computation cost. In other words, we are not seeking to empower the student to achieve higher performance from multiple teachers than a single teacher till we emphasize that distilling from multi-teacher could help the student to benefit from each teacher's capability separately. 


Qualitatively, in Fig. \ref{fig2}, the segmentation results from multi-teacher are visualized to demonstrate that their predictions are more discriminated and representative of that from a single teacher in the same cases (see rows 1 and 2 in Fig. \ref{fig2}). In turn, the third row represents the case where the mono-teacher distillation produces a better segmentation result than the multi-teacher. Thus, we validate that the paradigm of multi-teacher distillation could perform well for medical imaging analysis, i.e., segmentation and classification. We can say that the student networks can improve even with teachers trained with a small dataset. Yet, referring to the obtained result, the multi-teaching scheme should be improved to leverage the prediction results, and this could be our coming work.
 
\begin{figure}[H]
 \begin{center}
  \includegraphics[width=0.6\textwidth, height=7.5cm]{result_kd.png}
  \caption{Visualization of the prediction results of knowledge distillation architecture.}
  \label{fig2}
  \end{center}
  \vspace{-1cm}
\end{figure}

\section{Conclusion}

To sum up, This work presented two knowledge distillation schemes based on single and multi-teacher. This study has shown that our proposed approach of applying multi-teacher framework-based distillation can overcome the problem of medical data sharing and data limitation while maintaining the model's performance with as low as possible computational costs and outperforming the state-of-the-art in terms of dice score for MRI prostate segmentation by an improvement of $~9.0\%$ in some cases. The results proved that we could preserve the accuracy of the complex models trained with limited data in lightweight models that can be executed on devices with limited resources. However, our study was only conducted on MRI scans, and we did not address other medical imaging modalities, such as CT scans and X-Ray. Thus, in intermediate work, we aim to apply the distillation scheme to different image modalities. Future work explores the potential use of multi-teaching online distillation, where the teacher and student could be both end-to-end trainable in parallel through an online pipeline to boost the generalization of the student network within a faster inference time.
%To sum up, our study has shown that our proposed approach of applying multi-teacher framework-based distillation overcame the problem of medical data sharing and data limitation while maintaining the model's performance with as low as possible computational costs, as well as outpassed the state-of-the-art dice score in MRI prostate segmentation by $~9.1\%$. However, it is important to acknowledge the limitations of our study, as it was only conducted on MRI scans, and as we are addressing medical imaging here, CT scans, X-Ray, etc. should be considered as well. In addition, the distillation pipeline focused on MRI prostate tumour segmentation, other body organs were not considered here. Furthermore, it is mandatory to mention that two distillation modes exist, i.e. off-line that all the state\_of\_the\_art segmentation methods and me adopted,  unlike the on-line distillation that consists of building an end\_to\_end trainable  distillation framework, where the teacher and student networks are updated together during the distillation process. In the meantime, our future research explores the potential use of multi-teaching online distillation so that the teacher and student can be both trained in parallel through an online pipeline to boost the generalization of the student network within a faster inference time.
\section*{Acknowledgement}
This research was done thanks to The RadioCancers project (Grant agreement ID: PID2019-105789RB-I00) funded by the National Spanish Ministry of Science and Innovation, SPAIN.



%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
\bibliographystyle{splncs04}
\bibliography{thebibliography}
%
\begin{thebibliography}{8}
\bibitem{r1}
He T, Shen C, Tian Z, Gong D, Sun C, Yan Y. Knowledge adaptation for efficient semantic segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2019 (pp. 578-587).

\bibitem{r2}
Liu Y, Chen K, Liu C, Qin Z, Luo Z, Wang J. Structured knowledge distillation for semantic segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2019 (pp. 2604-2613).
\bibitem{r3}
Chen LC, Papandreou G, Kokkinos I, Murphy K, Yuille AL. Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs. IEEE transactions on pattern analysis and machine intelligence. 2017 Apr 27;40(4):834-48.
\bibitem{r4}
Qin D, Bu JJ, Liu Z, Shen X, Zhou S, Gu JJ, Wang ZH, Wu L, Dai HF. Efficient medical image segmentation based on knowledge distillation. IEEE Transactions on Medical Imaging. 2021 Jul 20;40(12):3820-31.
\bibitem{r5}
Back S, Lee S, Shin S, Yu Y, Yuk T, Jong S, Ryu S, Lee K. Robust skin disease classification by distilling deep neural network ensemble for the mobile diagnosis of herpes zoster. IEEE Access. 2021 Jan 25;9:20156-69.
\bibitem{r6}
Huang Z, Wang Z, Chen J, Zhu Z, Li J. Real-time colonoscopy image segmentation based on ensemble knowledge distillation. In2020 5th International Conference on Advanced Robotics and Mechatronics (ICARM) 2020 Dec 18 (pp. 454-459). IEEE.
\bibitem{r7}
Qi Y, Zhang W, Wang X, You X, Hu S, Chen J. Efficient Knowledge Distillation for Brain Tumor Segmentation. Applied Sciences. 2022 Jan;12(23):11980.
\bibitem{r8} Hinton G, Vinyals O, Dean J. Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531. 2015 Mar 9.
\bibitem{r9} Xu P, Kim K, Koh J, Wu D, Lee YR, Park SY, Tak WY, Liu H, Li Q. Efficient knowledge distillation for liver CT segmentation using growing assistant network. Physics in Medicine \& Biology. 2021 Nov 26;66(23):235005.
\bibitem{r10}
Ronneberger O, Fischer P, Brox T. U-net: Convolutional networks for biomedical image segmentation. InMedical Image Computing and Computer-Assisted Intervention–MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18 2015 (pp. 234-241). Springer International Publishing.
\bibitem{r11}
Clark T, Wong A, Haider MA, Khalvati F. Fully deep convolutional neural networks for segmentation of the prostate gland in diffusion-weighted MR images. InImage Analysis and Recognition: 14th International Conference, ICIAR 2017, Montreal, QC, Canada, July 5–7, 2017, Proceedings 14 2017 (pp. 97-104). Springer International Publishing.
\bibitem{r12}
Isensee F, Petersen J, Klein A, Zimmerer D, Jaeger PF, Kohl S, Wasserthal J, Koehler G, Norajitra T, Wirkert S, Maier-Hein KH. nnu-net: Self-adapting framework for u-net-based medical image segmentation. arXiv preprint arXiv:1809.10486. 2018 Sep 27.

\bibitem{r13}
Tian Z, Liu L, Zhang Z, Fei B. PSNet: prostate segmentation on MRI based on a convolutional neural network. Journal of medical imaging. 2018 Apr 1;5(2):021208-.
\bibitem{r14}
Liu Y, Yang G, Mirak SA, Hosseiny M, Azadikhah A, Zhong X, Reiter RE, Lee Y, Raman SS, Sung K. Automatic prostate zonal segmentation using fully convolutional network with feature pyramid attention. IEEE Access. 2019 Nov 8;7:163626-32.
\bibitem{r15}
Zhu Y, Wei R, Gao G, Ding L, Zhang X, Wang X, Zhang J. Fully automatic segmentation on prostate MR images based on cascaded fully convolution network. Journal of Magnetic Resonance Imaging. 2019 Apr;49(4):1149-56.
\bibitem{r16}
Yu L, Yang X, Chen H, Qin J, Heng PA. Volumetric ConvNets with mixed residual connections for automated prostate segmentation from 3D MR images. In Proceedings of the AAAI Conference on Artificial Intelligence 2017 Feb 10 (Vol. 31, No. 1).
\bibitem{r17}
Liu Q, Dou Q, Yu L, Heng PA. MS-Net: multi-site network for improving prostate segmentation with heterogeneous MRI data. IEEE transactions on medical imaging. 2020 Feb 17;39(9):2713-24.
\bibitem{r18}
Zhu Q, Du B, Yan P. Boundary-weighted domain adaptive neural network for prostate MR image segmentation. IEEE transactions on medical imaging. 2019 Aug 13;39(3):753-63.
\bibitem{r19}
Paszke A, Chaurasia A, Kim S, Culurciello E. ENet: A deep neural network architecture for real-time semantic segmentation. arXiv preprint arXiv:1606.02147. 2016 Jun 7.r
\bibitem{r20}
Mehta S, Rastegari M, Caspi A, Shapiro L, Hajishirzi H. ESPNet: Efficient spatial pyramid of dilated convolutions for semantic segmentation. In Proceedings of the European conference on computer vision (ECCV) 2018 (pp. 552-568).
\bibitem{r21}
He K, Zhang X, Ren S, Sun J. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition 2016 (pp. 770-778).
\bibitem{r22}
Sandler M, Howard A, Zhu M, Zhmoginov A, Chen LC. MobileNet-v2: Inverted residuals and linear bottlenecks. In Proceedings of the IEEE conference on computer vision and pattern recognition 2018 (pp. 4510-4520).
\bibitem{r23}
Ho TK, Gwak J. Utilizing knowledge distillation in deep learning for classification of chest X-ray abnormalities. IEEE Access. 2020 Sep 1;8:160749-61.
\bibitem{r24}
Wang Y, Wang Y, Cai J, Lee TK, Miao C, Wang ZJ. SSD-KD: A self-supervised diverse knowledge distillation method for lightweight skin lesion classification using dermoscopic images. Medical Image Analysis. 2023 Feb 1;84:102693.
\bibitem{r25}
Dou Q, Liu Q, Heng PA, Glocker B. Unpaired multi-modal segmentation via knowledge distillation. IEEE transactions on medical imaging. 2020 Feb 3;39(7):2415-25.
\bibitem{r26}
Li K, Yu L, Wang S, Heng PA. Towards cross-modality medical image segmentation with online mutual knowledge distillation. InProceedings of the AAAI conference on artificial intelligence 2020 Apr 3 (Vol. 34, No. 01, pp. 775-783).
\bibitem{r27}
Noothout JM, Lessmann N, Van Eede MC, van Harten LD, Sogancioglu E, Heslinga FG, Veta M, van Ginneken B, Išgum I. Knowledge distillation with ensembles of convolutional neural networks for medical image segmentation. Journal of Medical Imaging. 2022 Sep 1;9(5):052407-.
\bibitem{r28}
Berman M, Triki AR, Blaschko MB. The lovász-softmax loss: A tractable surrogate for the optimization of the intersection-over-union measure in neural networks. In Proceedings of the IEEE conference on computer vision and pattern recognition 2018 (pp. 4413-4421).
\bibitem{r29}
Bloch, N., Madabhushi, A., Huisman, H., Freymann, J., et al.: NCI-ISBI 2013 Challenge: Automated Segmentation of Prostate Structures. (2015)
\bibitem{r30}
Lemaitre, G., Marti, R., FreixENet, J., Vilanova. J. C., et al.: Computer-Aided Detection and diagnosis for prostate cancer based on mono and multi-parametric MRI: A review. In: Computers in Biology and Medicine, vol. 60, pp. 8-31 (2015)
\bibitem{r31}
 Litjens, G., Toth, R., Ven, W., Hoeks, C., et al.: Evaluation of prostate segmentation algorithms for MRI: The promise12 challenge. In: Medical Image Analysis. , vol. 18, pp. 359-373 (2014)
 \bibitem{r32}
 Sudre CH, Li W, Vercauteren T, Ourselin S, Jorge Cardoso M. Generalised dice overlap as a deep learning loss function for highly unbalanced segmentations. InDeep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support: Third International Workshop, DLMIA 2017, and 7th International Workshop, ML-CDS 2017, Held in Conjunction with MICCAI 2017, Québec City, QC, Canada, September 14, Proceedings 3 2017 (pp. 240-248). Springer International Publishing.
 \bibitem{r34} Choi, Min Seo, et al. "Clinical evaluation of atlas-and deep learning-based automatic segmentation of multiple organs and clinical target volumes for breast cancer." Radiotherapy and Oncology 153 (2020): 139-145.
 \bibitem{r35} Wang, Kai, et al. "Mulde: Multi-teacher knowledge distillation for low-dimensional knowledge graph embeddings." Proceedings of the Web Conference 2021. 2021. 
 \bibitem{r35}
 Xie S, Girshick R, Dollár P, Tu Z, He K. Aggregated residual transformations for deep neural networks. In Proceedings of the IEEE conference on computer vision and pattern recognition 2017 (pp. 1492-1500).
 
\end{thebibliography}
\end{document}
