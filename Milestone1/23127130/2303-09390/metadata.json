{
    "arxiv_id": "2303.09390",
    "paper_title": "On the Interplay Between Misspecification and Sub-optimality Gap in Linear Contextual Bandits",
    "authors": [
        "Weitong Zhang",
        "Jiafan He",
        "Zhiyuan Fan",
        "Quanquan Gu"
    ],
    "submission_date": "2023-03-16",
    "revised_dates": [
        "2023-03-17"
    ],
    "latest_version": 1,
    "categories": [
        "cs.LG",
        "stat.ML"
    ],
    "abstract": "We study linear contextual bandits in the misspecified setting, where the expected reward function can be approximated by a linear function class up to a bounded misspecification level $ζ>0$. We propose an algorithm based on a novel data selection scheme, which only selects the contextual vectors with large uncertainty for online regression. We show that, when the misspecification level $ζ$ is dominated by $\\tilde O (Δ/ \\sqrt{d})$ with $Δ$ being the minimal sub-optimality gap and $d$ being the dimension of the contextual vectors, our algorithm enjoys the same gap-dependent regret bound $\\tilde O (d^2/Δ)$ as in the well-specified setting up to logarithmic factors. In addition, we show that an existing algorithm SupLinUCB (Chu et al., 2011) can also achieve a gap-dependent constant regret bound without the knowledge of sub-optimality gap $Δ$. Together with a lower bound adapted from Lattimore et al. (2020), our result suggests an interplay between misspecification level and the sub-optimality gap: (1) the linear contextual bandit model is efficiently learnable when $ζ\\leq \\tilde O(Δ/ \\sqrt{d})$; and (2) it is not efficiently learnable when $ζ\\geq \\tilde Ω(Δ / {\\sqrt{d}})$. Experiments on both synthetic and real-world datasets corroborate our theoretical results.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.09390v1"
    ],
    "publication_venue": "28 pages, 2 figures, 2 tables"
}