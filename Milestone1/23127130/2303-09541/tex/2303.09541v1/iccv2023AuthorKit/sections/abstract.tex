\begin{abstract}
Recent text-to-image generative models have exhibited remarkable abilities in generating high-fidelity and photo-realistic images. However, despite the visually impressive results, these models often struggle to preserve plausible human structure in the generations. Due to this reason, while generative models have shown promising results in aiding downstream image recognition tasks by generating large volumes of synthetic data, 
they remain infeasible for improving downstream human pose perception and understanding. In this work, we propose Diffusion model with Human Pose Correction (\Ours{}), a text-conditioned method that generates photo-realistic images with plausible posed humans by injecting prior knowledge about human body structure. We show that \Ours{} effectively improves the realism of human generations. Furthermore, as the generations are accompanied by 3D meshes that serve as ground truths, \Ours{}'s generated image-mesh pairs are well-suited for downstream human mesh recovery task, where a shortage of 3D training data has long been an issue.
\footnote{Code: \url{https://github.com/ZZWENG/Diffusion_HPC}}
% Through extensive experiments, we showcase the superiority of \Ours{} in terms of person image generation quality, as well as its downstream potential in improving human mesh recovery in challenging domains.
\end{abstract}

% \Jen{Titles of similar works: "InstructPix2Pix: Learning to Follow Image Editing Instructions".
% Acronyms ideas: }
% \begin{itemize}
% \item PHIDM: Posed Human Images from Diffusion Models.
% \item PHIG: Posed Human Image Generation.
% \item Diffusion-HPC: Diffusion model with Human Pose Correction.
% \item Real-HG: Realistic Human Generation
% \end{itemize}
