\vspace{-0.7cm}
\section{Introduction}
% Understanding the world from 2D is an ill-posed problem(?) But extracting 3D is costly in terms of data, equipment, incompatible with some aspects of in-the-wild human life. Single view human mesh recovery to the rescue.

In recent years, large-scale text-conditioned image generation models such as GLIDE \cite{nichol2021glide}, Imagen \cite{saharia2022photorealistic} and Stable Diffusion \cite{Rombach_2022_CVPR} have impressed the research community with their exceptional generative and compositional capabilities, owing to their training on extremely large image-text datasets \cite{schuhmann2022laion} and use of advanced model architectures \cite{ho2020denoising,dhariwal2021diffusion}. Not only do these generative models drastically elevate the quality and efficiency of content creation, but they also exhibit promising potential for enhancing other visual tasks. As shown in \citet{he2022synthetic}, large text-conditioned generative models such as GLIDE \cite{nichol2021glide} are able to generate high-quality images targeted for a specific label space (i.e. domain customization), thus making it an ideal choice for synthetic data generation to aid in downstream image recognition tasks such as single-view Human Mesh Recovery (HMR) \cite{kolotouros2019learning} where securing annotations can be not only costly, but incompatible in the wild.

% \SY{maybe list the specific tasks, to contrast with yours}

Despite the benefits of synthetic data for image recognition tasks, these text-conditioned generative models have thus far lacked the capability of advancing human pose understanding tasks.
% \SY{is it just downstream tasks? You also help SD generate better images without considering downstream tasks} 
This is because these models do not explicitly model the underlying structure of human bodies and thus frequently encounter difficulties in preserving realistic human anatomy in their generated outputs. As Figure \ref{fig:pull_figure} (a) shows, generating realistic human poses embedded in plausible scenes is a known
% \SY{is it known/reported that you can cite? Or just clear from your work}
limitation \cite{hugging_face_2022} of generative diffusion models such as Stable Diffusion \cite{Rombach_2022_CVPR}.

% Understanding the subtleties of human movement and behaviour from images is one of the basic ideas in computer vision. In recent years, single-view Human Mesh Recovery (HMR) \cite{kolotouros2019learning} has received increasing attention as an alternative for deriving meaningful information from a 2D representation of a 3D world. Despite being capable of adapting to domains where only 2D ground truth or pseudo-ground truth is available. Most HMR methods continue to rely on 3D ground truth for successfully modeling challenging human poses. However, securing 3D annotations can be not only costly, but incompatible for some of these domains.

% Recent works such as \citet{he2022synthetic}, have studied how synthetic images generated with large pre-trained diffusion models can bridge the data gap in image classification tasks. Yet, as Figure \ref{fig:pull_figure} shows generating realistic human poses embedded in plausible scenes is a known limitation of diffusion models. 

In this work, we present Diffusion model with Human Pose Correction (\Ours{}), a method that addresses the implausibility of human generations from large pre-trained text-conditioned generative models. Our intuition is that we can rectify the generated unrealistic humans (e.g. with additional limbs in non-anatomical locations) by integrating stronger human pose priors within the generation process.
% \SY{remaining part of this paragraph a little unclear. Unclear if it is a variant of your method, or if there are just simultaneous other benefits} 
Thereby, we extend the capability of pre-trained diffusion models, such as Stable Diffusion, to produce a large variety of synthetic scenes for a target domain with minimal user input. Further, unlike base diffusion models our approach produces pairs of images and ground truth meshes as a result of including body pose priors in the generation process.
% \SY{unclear how, clarify at least a high-level idea} 
These image-mesh pairs can then be employed to improve existing single-view Human Mesh Recovery methods on challenging data-scarce domains (See Figure \ref{fig:pull_figure}b, c). %We further show the flexibility of \Ours{} by validating the generation potential when including source images as additional user input.
%a domain in question with minimal user input and their learned understanding of the underlying human pose distributions. To the best of our knowledge, our work presents the first training-free attempt that addresses the challenges in generating realistic humans using large pre-trained generative models.  
% Moreover, aided by the pairs of generated scenes and meshes we show that our additional data can be employed to finetune existing single-view HMR methods to improve their performance on challenging domains. % See figure 1b,c
% We further showcase the utility of our generation method in bootstrapping training data for downstream human mesh recovery task on challenging domains through datasets SMART \cite{chen2021sportscap} and Ski-Pose dataset \cite{rhodin2018learning,sporri2016reasearch}.
% across a variety of competitive sports categories with challenging poses where we obtain an improvement of \Laura{\#} over existing methods. We also demonstrate the efficacy of our strategy under fast and extreme in-the-wild motions on the Ski-Pose dataset \cite{rhodin2018learning,sporri2016reasearch}, and show experiments under low-data regimes.
In summary, we make the following contributions.
\begin{itemize}[noitemsep,topsep=0pt]
    \item Motivated by the implausible humans produced by diffusion models, we propose a simple and effective method \Ours{} to rectify the implausibility of human generations that often occur in Stable Diffusion \cite{Rombach_2022_CVPR} results. To the best of our knowledge, our work presents the first training-free method that addresses the challenges in generating realistic humans by injecting human body structure priors within the generation process.
    % using large pre-trained generative models. \SY{your use of the word `` using'' sounds like your key insight is to improve SD by using large pretrained models. But really your key insight is injecting the structure to improve.}
    \item %We broaden the range of downstream utilities enabled by state-of-the-art generative models 
    We show that the synthetic images with corresponding 3D ground truth produced by our method are capable of adapting Human Mesh Recovery models to challenging domains (e.g. competitive sports) where supervision is limited and hard to obtain. Models finetuned with \Ours{}'s synthetic data achieve 2.6\% PCK and 4.6 PA-MPJPE improvement on SMART \cite{chen2021sportscap} and Ski-Pose 3D \cite{rhodin2018learning,sporri2016reasearch}, respectively.
    \item We quantitatively validate the improved quality of our generated images over existing text-to-image as well as state-of-the-art pose-to-image generative models.
    % \SY{be clear that SD cannot do this. Also, mention your performance.}
\end{itemize}
% We will make our code publicly available.
