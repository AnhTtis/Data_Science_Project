\section{Proofs}\label{sec:proofs}

\subsection{Proof of \Cref{lemma:schur1}}

Consider two non-negative functions $f,g$ and inputs $x\prec y$. Consider the identity
\begin{align}
    f(y)g(y)-f(x)g(x) = (f(y)-f(x))\cdot g(y)+f(x)\cdot (g(y)-g(x)).
\end{align}
If $f,g$ are Schur-convex then $f(y)-g(x)\geqslant 0$ and 
$g(y)-g(x)\geqslant 0$ and the whole expression is non-negative when $f,g$ are non-negative. This shows that $f\cdot g$ is also Schur-convex. The claim for Schur-concave functions follows analogously (the expression is then non-positive).

\subsection{Proof of \Cref{lemma:schur2}}

The proof follows from the fact that $x$ is dominated by $y$ if and only if $x$ can be produced from $y$ by a sequence of \emph{Robin-Hood operations}, and the fact that Robin-Hood operations change only two fixed components of vectors. 
%These operations 

\subsection{Proof of \Cref{thm:schur_concave}}


\begin{proof}
Note that $\mathbf{R}_q$ is a polynomial in $x_i^2$ with integer coefficients, and thus a well-defined function of $(x_i^2)$. This follows by applying the multinomial expansion and noticing that monomials with odd exponents have expectation zero due to the symmetry of Rademacher distribution. $\mathbf{R}_q$ is obviously symmetric. By \Cref{lemma:schur2} it now suffices to validate the Schur-concativity for $x_1^2,x_2^2$ and any fixed choice of $(x_i)_{j>2}$.
Define the following expressions
\begin{align}
\begin{aligned}
P&=\sum_{i\not\in\{1,2\}}x_i r_i \\
R&= \sum_{i,j\not\in\{1,2\}}x_i x_j r_i r_j,
\end{aligned}
\end{align}
then our task is to prove the Schur-concativity of the function
\begin{align}
\mathbf{R}_q \triangleq \mathbf{E} \left( P(x_1 r_1 + x_2 r_2) + x_1 x_2 r_1 r_2 + R\right)^q,
\end{align}
with respect to $x_1^2,x_2^2$.

By the multinomial expansion we find that
\begin{align}
\mathbf{R}_q \triangleq \sum_{q_1+q_2+q_3=q}\binom{q}{q_1,q_2,q_3}   \mathbf{E}\left[ (x_1r_1+x_2r_2)^{q_1}(x_1x_2 r_1 r_2)^{q_2}\right] \mathbf{E}\left[ P^{q_1}R^{q_3}\right],
\end{align}
where we used the independence of $r_1,r_2$ on $(r_i)_{i>2}$ and thus also on $P,R$. Observe that 
$P^{q_1}R^{q_3}$ is, by definition and our assumption $x_i\geqslant 0$, a polynomial in symmetric random variables $r_i$ with non-negative coefficients. This observation shows that
\begin{align}
 \mathbf{E}\left[ P^{q_1}R^{q_3}\right] \geqslant 0,
\end{align}
and by \Cref{lemma:schur1} it suffices to prove that
\begin{align}%\label{eq:schurreduction1}
F\triangleq  \mathbf{E}\left[ (x_1r_1+x_2r_2)^{q_1}(x_1x_2 r_1 r_2)^{q_2}\right] 
\end{align}
is Schur-concave as a function of $x_1^2,x_2^2$ for any non-negative integers $q_1,q_2$.

To see that $F$ is indeed a well-defined function of $x_1^2,x_2^2$, note that it equals the expectation of a polynomial in the symmetric random variables $y_i= x_i r_i$; thus only monomials with even-degrees contribute, and the result is a polynomial in $y_i^2=x_i^2$. In fact, $F$ equals the sum of even-degree monomials in the expanded polynomial $(x_1+x_2)^{q_1}(x_1x_2)^{q_2}$.

We next observe that
\begin{align}\label{eq:reduction_2}
F = 
\begin{cases}
(x_1x_2)^{q_2}\mathbf{E}\left[ (x_1r_1+x_2r_2)^{q_1} \right] & q_2 \text{ is even} \\
(x_1x_2)^{q_2-1}\mathbf{E}\left[ (x_1r_1+x_2r_2)^{q_1} x_1 x_2 r_1 r_2\right] & q_2 \text{ is odd}
\end{cases}.
\end{align}
Note that $x_1 x_2$ is Schur-concave in non-negative $x_1,x_2$; indeed, the identity
$(x_1+\epsilon)(x_2-\epsilon) = x_1 x_2 + \epsilon(x_2-x_1-\epsilon)$ shows that Robin-Hood transfers increase the value. By \Cref{lemma:schur1} we conclude that $(x_1 x_2)^{k}$ is Schur concave in $x_1^2,x_2^2$ for non-negative even $k$. 
Thus, by  \Cref{eq:reduction_2} and \Cref{lemma:schur1} we conclude that it suffices to consider the case $q_2=1$, that is, to prove the Schur-concavity of the following two functions:
\begin{align}\label{eq:reduction_3}
G_k & \triangleq \mathbf{E}\left[ (x_1r_1+x_2r_2)^{k} \right] \\
H_k &\triangleq \mathbf{E}\left[ (x_1r_1+x_2r_2)^{k} x_1 x_2 r_1 r_2\right] .
\end{align}
with respect to $x_1^2,x_2^2$ for any non-negative integer $k$. 

Using the identity $(x_1r_1+x_2r_2)^{k} = (x_1r_1+x_2r_2)^{k-2}(x_1^2+x_2^2+2x_1x_2r_1r_2)$, we find the following recurrence relation
\begin{align}
G_k &= (x_1^2+x_2^2) G_{k-2}+2H_{k-2} \\
H_k &= 2x_1^2x_2^2 G_{k-2}+(x_1^2+x_2^2) H_{k-1} ,
\end{align}
valid for $k\geqslant 2$. Since
$x_1^2+x_2^2$ and $x_1^2 x_2^2$ are Schur-concave as functions of $x_1^2,x_2^2$, by \Cref{lemma:schur1} the concavity property proven for $k-2$ implies that it is valid also for $k$.
By induction, it suffices to verify the case $k=0$ and $k=1$. But we see that
\begin{align}
\begin{aligned}
G_0& = 1 \\
G_1& = 0 \\
H_0& = 1 \\
H_1& = 2x_1^2x_2^2 \\
\end{aligned}
\end{align}
are all Schur-concave as functions of $x_1^2,x_2^2$. This completes the proof.
\end{proof}




\subsection{Proof of \Cref{thm:extreme_rademacher}}

Without loss of generality, we assume that $\|x\|_2=1$. From \Cref{thm:schur_concave} and the fact that $(x^2_i)$ majorizes  $({x^{*}_i}^2)$ we obtain
%\begin{align}
%    \mathbf{E}\left(\sum_{i<j}x_i x_i r_i r_j \right)^q \leqslant 
%    \sum_{\lambda \vdash q} C_{q,\lambda} \mathbf{m}_{2\lambda}(x)
%\end{align}
%Assuming that $\|x\|_2=1$ and $\|x\|_{\infty} \leqslant \frac{1}{\sqrt{K}}$ from this representation we arrive at
\begin{align}\label{eq:rademacher_sup}
\max_{x: \|x\|_0 \leqslant K}  \mathbf{E}\left(\sum_{i<j}x_i x_i r_i r_j \right)^q = 
\mathbf{E}\left(\sum_{i<j}x^{*}_i x^{*}_i r_i r_j \right)^q =
   \mathbf{E}\left(\frac{1}{K}\sum_{1\leqslant i<j \leqslant K} r_i r_j \right)^q,
\end{align}

Observe that $r_i = 1-2b_i$ where $(b_i)$ is a sequence of independent Bernoulli random variables with parameter $\frac{1}{2}$. Therefore,
\begin{align}\label{eq:rademacher_linear}
\begin{aligned}
    \mathbf{E}\left(\sum_{i=1}^{K}r_i\right)^q &=^{(a)} \sum_{k\in\mathbb{Z}} k^{q} \cdot \mathbf{P}\left\{\sum_{i=1}^{K}r_i = k\right\}   \\   
     &=^{(b)} \sum_{k} k^{q} \cdot \mathbf{P}\left\{\sum_{i=1}^{K}b_i = \frac{K-k}{2}\right\}  \\   
     & =^{(c)} \sum_{i=0}^{K} (K-2i)^q\cdot \mathbf{P}\left\{ \mathsf{Binom}(K,1/2) = i \right\} \\
     & =^{(d)} \frac{1}{2^{K}}\sum_{i=0}^{K} \binom{K}{i}(K-2i)^q \\
     & =^{(e)}     \frac{1}{2^K}\sum_{i}\binom{K}{i}(-K+2i)^q,
\end{aligned}
\end{align}
where in (a) we use the fact that $\sum_i r_i$ takes integer values, (b) follows by the identity $r_i = 1-2b_i$, 
(c) follows by $\mathsf{Binom}(K,1/2) \sim \sum_{i=1}^{K} b_i$, (d) uses the explicit formula on the binomial probability mass function, and finally in (e) we substitute $i:= K-i$ and use the symmetry of binomial coefficients 
$\binom{K}{i}=\binom{K}{K-i}$.

Using the above formula, we further calculate 
\begin{align}
\begin{aligned}
\mathbf{E}\left(\sum_{1\leqslant i\not=j \leqslant K} r_i r_j \right)^q& =^{(a)}  \mathbf{E}\left(\left(\sum_{i=1}^{K}r_i\right)^2-\sum_{i=1}^{K}r_i^2 \right)^q \\
  &=^{(b)} \sum_{j}\binom{q}{j}(-K)^{q-j}\mathbf{E}\left(\sum_{i=1}^{K}r_i\right)^{2j} \\
  & =^{(c)} \frac{1}{2^{K}}\sum_{i,j} \binom{q}{j} \binom{K}{i}(-K+2i)^{2j}  (-K)^{q-j}\\
  & =^{(d)} \frac{1}{2^K}(-K)^q\sum_i \binom{K}{i} \left(1-\frac{(-K+2i)^2}{K}\right)^q,
\end{aligned}
\end{align}
where (a) follows by the square sum completion, (b) follows by the binomial formula and $r_i^2=1$, (c) follows directly by  \Cref{eq:rademacher_linear}, and (d) is obtained by algebraic rearrangements.

Inserting \Cref{eq:rademacher_linear} into \Cref{eq:rademacher_sup}, we arrive at
\begin{align}\label{eq:rademacher_sup_simpler}
 \max_{x:\|x\|_0\leqslant K} \mathbf{E}\left(\sum_{1\leqslant i\not=j \leqslant K} x_i x_j r_i r_j \right)^q = \frac{1}{2^{K}} \sum_{i=0}^{K} \binom{K}{i} \left(\frac{(-K+2i)^2}{K}-1\right)^q.
\end{align}

To simplify further, let $Z\sim \frac{\mathsf{Binom}\left(K,\frac{1}{2}\right)-\frac{K}{2}}{\sqrt{\frac{K}{4}}}$ be the standardization of the symmetric binomial distribution. 
Denoting $i\sim \mathsf{Binom}\left(K,\frac{1}{2}\right)$ we have $Z^2 \sim \frac{\left(i-\frac{K}{2}\right)^2}{{\frac{K}{4}}} = \frac{(-K+2i)^2}{K}$, and
we can rewrite \Cref{eq:rademacher_sup_simpler} as follows:
% $i\sim \mathsf{Binom}\left(\frac{K}{2},\frac{1}{2}\right)$ and $Z = (i-K/2)/\sqrt{K/4}$ (standardized). Then
\begin{align}
    \max_{x:\|x\|_0\leqslant K}  \mathbf{E}\left(\sum_{1\leqslant i\not=j \leqslant K} x_i x_j r_i r_j \right)^q =  \mathbf{E}_Z \left(Z^2-1\right)^q,
\end{align}
which finishes the proof.

\subsection{Proof of \Cref{thm:main}}

We have to prove that for the distortion $E(\cdot)$ defined as in \Cref{eq:distortion} 
\begin{align}
E(x) \leqslant E(y),\quad (y_i^2) \prec (x_i^2).
\end{align}
The proof goes through several reduction steps until Schur-concavity of few simple functions.

We first observe that it suffices to prove that the moments of
\begin{align}
x \rightarrow \|\Phi x\|^2-\|x\|^2,
\end{align}
are Schur-concavity with respect to $(x_i^2)$. Indeed, since $(y_i^2) \prec (x_i^2)$ implies $\|x\|^2 = \sum_i x_i^2 = \sum_i y_i^2 = \|y\|^2$ we have
  $\mathbf{E} E(x)^q \leqslant \mathbf{E} E(y)^q$ if and only if
$\mathbf{E}(\|\Phi x\|^2-\|x\|^2)^q \leqslant \mathbf{E}(\|\Phi y\|^2-\|y\|^2)^q$, by the definition of $E$.

We first prove that the distortion of $m$-dimensional projections is the average of $m$ IID distortions of $1$-D projections. Observe that
\begin{align}\label{eq:decomposition}
    \|\Phi x\|^2 - \|x\|^2 = \sum_{k=1}^{m}\left( (\Phi_k x)^2 -   \mathbf{E}(\Phi_k x)^2 \right),
\end{align}
where $\Phi_k$ is the $k$-th row of $\Phi$; this follows by $\mathbf{E}( \Phi_k x)^2 = \sum_{i} x_i^2\mathbf{Var}[\Phi_{k,i}] = \frac{1}{m}\|x\|^2$. Furthermore, the summands in \eqref{eq:decomposition} are independent and identically distributed:
\begin{align}\label{eq:average}
    (\Phi_k x)^2 - \mathbf{E}(\Phi_k x)^2 \sim \frac{1}{m}\sum_{i\not=j} x_i x_j r_i r_j.
\end{align}

Then we note that the Schur-concativity test can be done on the 1-D case. This follows because, due to the multinomial expansion applied to \Cref{eq:average}, the $q$-th moment of $m$-dimensional distortion is a multivariate polynomial in 1-D distortion moments of order $k\leqslant q$, with non-negative coefficients; the distortion moments are themselves non-negative, and by \Cref{lemma:schur1} and \Cref{thm:schur_concave} we obtain the first part of the theorem.

Finally, applying \Cref{thm:extreme_rademacher} proves the second part.