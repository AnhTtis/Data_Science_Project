
\section{Methodology}
\input{tex_figures/igccf-architecture}
In this section we present details of the proposed model. \textit{IGCCF} comprises three different elements: (1) a graph projection module, which is used to transform a user-item bipartite graph into a homogeneous item-item graph; (2) an item embedding module, which is used to learn item embeddings starting from the item-item graph; (3) a user embedding module, which is used to build user embeddings given the user-item interaction matrix and the items embeddings. 
%\edoinline{Ask if worth adding the score module.} - no
The overall architecture is presented in Figure \ref{fig:igcmf_architecture}. 
%\khalilinline{Fig 1 is too far from where it's references. Also, this paragraph needs could be improve to read better}
% figure igcmf architecture

\subsection{Graph projection Module}
The graph convolution module operates over item embeddings which are optimised during training while the explicit representation and optimisation of separate user embeddings is not required. This gives the model the flexibility to easily make recommendations for unseen users. To fully capture the item relationships 
we construct an item-item relational graph from which extract knowledge regarding item associations during the representation learning process.
The purpose of the graph projection module is to transform the bipartite user-item graph into a homogeneous item-item graph. The simplest means of achieving this is to use a one-mode projection onto the set of item nodes $\mathcal{I}$, creating an unweighted graph with exactly $I$ nodes where two item nodes share an edge when they have at least one common neighbour in $\mathcal{U}$ \cite{Newman404}. 
This technique ignores the frequency with which two nodes share neighbors, resulting in information loss. To account for this, we build the projected item-item graph by weighting the edges based on the cosine similarity of item profiles. The edge between nodes $i$ and $j$ has weight $w_{ij} =\frac{ \textbf{r}_i \cdot \textbf{r}_j} {||\textbf{r}_i|| \cdot ||\textbf{r}_j||}$ where $i, j \in \mathcal{I}$ and indicating with $\textbf{r}_i$ the $i^{th}$ column of the matrix $\textbf{R}$. In this way we are able to retain information about the frequency with which two items share neighbors.
% This methodology doesn't take into account the frequency with which two nodes share neighbours, resulting in a loss of information. In the projected item-item graph we weight the edges by the cosine similarity between the item profiles $w_{ij} =\frac{ \textbf{r}_i \cdot \textbf{r}_j} {||\textbf{r}_i|| \cdot ||\textbf{r}_j||}$
%To this extent we resort to the cosine similarity between item profiles to weight the edges of the projected item-item graph, computing the weight of an edge as \khalilinline{would it not suffice to mention cosine similarity?}:
% \begin{equation}
% w_{ij} =\frac{ \textbf{r}_i \cdot \textbf{r}_j} {||\textbf{r}_i|| \cdot ||\textbf{r}_j||}
% \end{equation}
% where $i, j \in \mathcal{I}$ and indicating with $\textbf{r}_i$ the $i^{th}$ column of the matrix $\textbf{R}$. 
%\khalilinline{In section 3, you used subscripts for rows and superscripts for columns. Any reason the r's here are interepreted as columns?}
% With this similarity measure we preserve the information related to the frequency of interactions between two items.
The model can easily adapt to different bipartite graph projection methodologies such as hyperbolic weighting \cite{newman2001scientific} that takes into account the saturation effect; or weighting based on resource allocation \cite{zhou2007bipartite}, which doesn't assume symmetric weights between pairs of nodes.  
%We leave the exploration of using different weighting methodologies to a future work. 
%\khalilinline{Section 5.1 could be improved to read better}.

\subsubsection{Top-K pruning}
Previous works on GCNs have highlighted how the size of the neighbourhood included in the convolution operation, as well as the convolution depth, can lead to an \textit{oversmoothing} of the embeddings.
%TODO: citation for oversmoothing?
%TODO: is there a citation for anyone else doing top-k pruning?
The oversmoothing leads to a loss of embedding uniqueness, and results in the degradation of recommendation performance \cite{li2018deeper,xu2018representation,Chen_2020}. To address this problem we apply a top-K pruning preprocessing step on the edges of the item-item graph, keeping only the $K$ edges associated to the highest similarity score, for each item node. In this way only the most important neighbours are included in every convolution operation reducing the effect of the smoothing phenomenon. In section~\ref{sec:exp_topk_pruning} we show how the top-K pruning is beneficial to both training time and recommendation performance of the presented algorithm.
% \khalilinline{How does this fit into your framework? What stage? If it's Fig 1, I can't see it. Rewrite this section if possible. Where is there 5.1.1 but no 5.1.2? Do you really need a number for this sub-sub-section?}.

\subsection{Item embedding module}
The item embedding module uses information from the item-item graph to generate refined item embeddings. The primary difference between this module and previously described graph convolution modules  \cite{wang2019neural,Chen_2020,He_2020} is that we use the item-item similarity matrix as propagation matrix, allowing us to directly leverage the information provided by the weighted projection used to construct the homogeneous item graph.
%To achieve this, we use a convolution operation that differs from previously presented works
%\cite{wang2019neural,chen2020revisiting,He_2020}. Instead of using the symmetric normalised Laplacian as the propagation matrix, we resort to the normalised weighted adjacency matrix of the item-item graph. 

%TODO: we need to explain why 

%\edoinline{ref conv form} 
  
At the first iteration, $k=0$, the item embedding matrix $\textbf{X}^{(0)}$ is randomly initialised. 
%
%when $k = 0$ the item embeddings are equal to random initialized vectors of parameters.
%\begin{equation}
%\textbf{X}_{\mathcal{I}}^{(0)} = \textbf{X} 
%\end{equation}
At each subsequent iteration $k$, the item embedding matrix is a weighted combination of the embedding matrix at the previous layer $k-1$ with the propagation matrix, formed from the cosine similarity measure:
\begin{equation}
\textbf{X}^{(k)} = \textbf{P} \textbf{X}^{(k-1)} = \textbf{P}(\textbf{P}\textbf{X}^{(k-2)}) = \textbf{P}^k\textbf{X}^0\
\label{eq:power_prop_matrix}
\end{equation}
%In matrix form, \edoinline{ref eq 2} 
The representation of an item $i$ at convolution depth $k$ can be written explicitly as:
\begin{align*}
\textbf{x}_{i}^{(k)} = \sum_{j \in \mathcal{N}_i} w_{ij}\textbf{x}_j^{(k-1)}
\end{align*}
where $\mathcal{N}_i$ represents  the 1-hop neighbourhood of item $i$. 

The embedding at depth $k$ can  be directly computed using the power of the propagation matrix as shown in \autoref{eq:power_prop_matrix}, which demonstrates that, at depth $k$, the embedding can be seen as the linear combination of neighbourhoods representations up to $k$-hop distance with weights given by the $k^{th}$ power of the cosine similarity matrix $\textbf{P}^k$.

% In this work, we consider an extreme setting where no side-information is available. In situation in which item side-information can be harvested in the form of \textit{item features}, the item embedding module can easily be adapted toexploit such additional information by design it as a learnable function, such as a multi-layer perceptron, to map item features into item embeddings. In this way instead of input to the model random initialised embeddings we will input item representations derived from the input features which will be then further refined by the convolution process. This would make the model \textit{fully inductive}, capable of generating embeddings for new items that join the system post-training.
\begin{comment}
multi-layer perceptron or any other 
be 
the side-information for users and items is unavailable. But in situations were item side-information is available in the form of \textit{item features}, it would be possible to design an item embedding module based on some learnable function, such as a multi-layer perceptron, that maps item features to item embeddings. This would make the model \textit{fully inductive}, capable of generating embeddings for new items that join the system post-training. \edoinline{write something related to the fact that have item features is more common}
\end{comment}

\subsection{User embedding module}
As there are no separate user embeddings, a method to map users into the item embedding space is required. We propose to map a user inside the item latent space as a weighted combination of the items in their profile. Given the item embeddings,  a user embedding is created as:
\begin{equation}
\label{eqn:userembedding}
\textbf{x}_u = \sum_{i \in \mathcal{I}} \lambda_{ui} r_{ui}  \textbf{x}_i
\end{equation}
where 
%$r_{ui}$ represent the cell of the interaction matrix associate to user $u$ and item $i$ therefor containing a binary indicator equal to $1$ if the item $i$ is present in the profile of user $u$ $0$ otherwise, 
$\lambda_{ui}$ is a scalar weighting the contribution of item $i$ to the embedding of user $u$ and $\textbf{x}_i $ represents the embedding of item $i$. 
We can compute the user embeddings in matrix form as follows:
\begin{align*}
\textbf{U} = (\textbf{R} \odot \Lambda) \textbf{X} = \tilde{\textbf{R}}\textbf{X}   
\end{align*}
where $\odot$ indicates the Hadamard product, $\tilde{\textbf{R}}$ represents a weighted version of the interaction matrix and $\textbf{X}$ is the item embedding matrix. In the proposed work, we assign uniform weights to all user interactions and leave the investigation of different weighting mechanisms as future work. 

We want to emphasize the key advantages of modeling a user as a weighted sum of item embeddings in their profiles over having a static one-hot representation for each of them.
First, it makes the model inductive from the user perspective and endows IGCCF with the ability to perform real-time updates of the user-profile as it is possible to create the embedding of a new user as soon as they start interacting with items in the system using \autoref{eqn:userembedding}.
%\edoinline{add real-time user profile update is in the abstract}. 
Second, it improves the model's space complexity from $\mathcal{O}(I+U)$ to $\mathcal{O}(I)$ when compared to transductive models. Finally, different importance scores may be assigned to user-item interactions when generating the user embeddings, this might be beneficial in situations where recent interactions are more significant than older ones.
% \subsection{Model prediction}
% Once both item and user embeddings have been computed, the preference of a user for an item is modelled through the dot product of their embeddings $\hat{y}(u, i) = \textbf{x}_u^T \cdot \textbf{x}_i$
% % \begin{equation}
% % \hat{y}(u, i) = \textbf{x}_u^T \cdot \textbf{x}_i
% % \end{equation}
% In some recent works, more complex prediction functions have been proposed. For example, in  \cite{He_2017} the predictive function is a multi-layer perceptron.
% However, learning from  \cite{Rendle_2020} where more complex predictors are outperformed by the simple dot product on recommendation tasks, we stick to this prediction function, which does not require any further parameters beyond the embedding vectors, and it has the important benefit of being compact and fast to compute.
% %\khalilinline{which last one?} is more suitable for recommender systems in production phase, making the recommendation process faster and simpler.

\subsection{Model Training}
To learn the model parameters, we adopt the \textit{Bayesian Personalised Ranking} (BPR) loss \cite{rendle2012bpr}:
\begin{align*}
L_{BPR} = \sum_{(u,i^+,i^-)\in \mathcal{O}} -\ln \sigma (\hat{y}_{ui^+}-\hat{y}_{ui^-}) + \lambda ||\Theta||_2^2
\end{align*}
where $\mathcal{O}=\{(u, i^+, i^-)|(u, i^+) \in \mathcal{R^+}, (u, i^-) \in \mathcal{R^-}\}$ denotes the pairwise training data, $\mathcal{R^+}$ indicates the observed interactions, and $\mathcal{R^-}$ the unobserved interactions; $\sigma(\cdot)$ represents the sigmoid activation function; $\Theta$ are the parameters of the model which correspond to the item embeddings.

We use the Glorot initialisation for the item embeddings \cite{glorot2010understanding} and mini-batch stochastic gradient descent with Adam as optimiser \cite{kingma2014adam}. The preference of a user for an item is modelled through the standard dot product of their embeddings $\hat{y}(u, i) = \textbf{x}_u^T \cdot \textbf{x}_i$

\subsubsection{User-profile dropout}
It is well-known that machine learning models can suffer from overfitting. Following previously presented works on GCNs \cite{rong2019dropedge,wang2019neural,berg2017graph}, 
we design a new dropout mechanism called \textit{user-profile} dropout. Before applying ~\autoref{eqn:userembedding} to form the user embeddings,  we randomly drop entries of the weighted user interaction matrix $\tilde{R}$ with probability $p \in [0,1]$. The proposed regularisation mechanism is designed to encourage the model to rely on strong patterns that exist across items rather than allowing it to focus on a single item during the construction of user embeddings.
% Beyond the regularisation purpose, this dropout mechanism increases the inductive capability of the model, encouraging to not heavily rely on a single item for the construction of the user embeddings but to exploit robust patterns that can achieve strong performance even when very few user interactions are available.
%This will result beneficial in helping the algorithm to predict for unseen users with few interactions available.

% cutted pseudocode and complexity analysis
% The pseudocode of the training process of IGCCF is reported in ~\autoref{alg:gccf}.
% \input{tex_figures/algorithm_pseudocode}

% \subsection{Time complexity analysis}
% In this section we analyse the time complexity of the proposed model.
% The complexity of each iteration of the convergence loop is $\mathcal{O}(I \times K \times k \times F)$ to compute $\textbf{P}^k \textbf{X}$ (since $\textbf{P}$ has $I \times K$ non-zeros in total) and $\mathcal{O}(M \times F)$ to compute $\textbf{U}$, where $M$ is the number of non-zeros in $\tilde{\textbf{R}}$. Some savings can be obtained by noting that the user embeddings are only required for users $u \in B$, where $B$ denotes the batch while the number of item embeddings required to compute the gradient is 
% \[ 
% %\left| \{ i \mid (u,i,i^-) \in  B\} \cup \{ j \mid (u,i^+, j)\in  B\} \cup \{i \mid  \tilde r_{ui} \ne 0, (u, i^+,i^-) \in B\} \right|\,.
% \left| \{i \in  B\} \cup \{i \mid  \tilde r_{ui} \ne 0, u \in B\} \right|\,,
% \]
% which may be much less than $I$ if $|B|$ is small.
% %Finally, $\mathcal{O}(|B|\times I \times F  \times K \times k)$ operations are required to compute the $I \times F$ components of the gradient and $\mathcal{O}(I \times F)$ to apply it. As the number of item embeddings with non-zero gradients is 
% %\[
% %\left| \{ i \mid \exists u \in B, j \in \mathcal{I} \mbox{ s.t. } \tilde r_{uj}s^{(k)}_{ji} \ne 0 \} \right|\,
% %\]
% %where $s^{(k)}_{ji}$ is an entry of $\textbf{S}^k$ and $\textbf{S}^{k}$ is likely to be dense, we can expect that almost all item embeddings need to be updated, even for small $|B|$.

% %\begin{comment}
% % just for info - probably not needed in the paper
% The gradient of the loss can be written as,
% \begin{align*}
% \nabla L (\textbf{X}) &= -\sum_{(u,i^+,i^-) \in B} \sigma(-x_{ui^+i^-})\bigg(\mathbf{q}_u(\mathbf{x}_{i^+} - \mathbf{x}_{i^-})^T + (\mathbf{p}^{(k)}_{i^+} - \mathbf{p}^{(k)}_{i^-})\mathbf{x}_u^T\bigg)
% \end{align*}
% where $\mathbf{x}_u$ and $\mathbf{x}_i$ are the $F \times 1$ vectors consisting of $u^{\rm th}$  and $i^{\rm th}$ rows of $\textbf{U}$ and $\textbf{X}$, respectively;  and $\mathbf{p}^{(k)}_i$ are $I \times 1$ vectors, consisting of the $i^{\rm th}$ rows of $\textbf{P}^k$; $\mathbf{q}_u = \sum_{\ell} \tilde r_{u\ell} \mathbf{p}^{(k)}_\ell$; $x_{ui^+i^-} = \mathbf{x}_u \cdot (\mathbf{x}_{i^+}-\mathbf{x}_{i^-})$\footnote{$\mathbf{q}_u\mathbf{x}_i^T$ is the \textit{outer} product of a $I \times 1$ vector with an $F \times 1$ vector, yielding an $I \times F$ matrix.}.  With $\mathbf{r}_u$ denoting the $u^{\rm th}$ row of ${\tilde{\mathbf{R}}}$, $\mathbf{q}_u = (\textbf{P}^T)^k \mathbf{r}_u$, which can be computed in $\mathcal{O}(I \times K \times k )$. Similarly, $\mathbf{p}_i^{(k)} = (\textbf{P}^T)^{k-1} \mathbf{p}^{(1)}_i$. Finally, the outer products are $\mathcal{O}(I \times F)$.  Hence computing the gradient has $\mathcal{O}(|B| \times I \times (K \times k +F) )$ complexity and applying it is $\mathcal{O}(I \times F)$.
% % It is useful to compare the time complexity of the proposed item graph convolution module with respect to the Light Convolution introduced in \cite{He_2020}, which has been shown to achieve the best performance with lower complexity with respect to previously introduced graph convolution mechanisms. In LightGCN the gradient computation phase can roughly being approximated by $\mathcal{O}(|B| \times (U+I) \times (\overline{\mathcal{N}_i} \times k +F) )$

% %\big(\sum_\ell s^{(k)}_{\ell m} \tilde r_{u \ell}\big)\big(\textbf{S}^k\textbf{X}_i - \textbf{S}^k\textbf{X}_j\big) \\
% %&+ s^{(k)}_{i m} \tilde r_{u i}\textbf{S}^k\textbf{X}_i - s^{(k)}_{jm} \tilde r_{uj} \textbf{S}^k\textbf{X}_j \bigg)
% %\end{align*}



% %\begin{align*}
% %\frac {\partial L}{\partial \textbf{X}_m} &= \sum_{(u,i,j) \in B} \sigma^\prime(x_{uij})\bigg(\big(\sum_\ell s^{(k)}_{\ell m} \tilde r_{u \ell}\big)\big(\textbf{S}^k\textbf{X}_i - \textbf{S}^k\textbf{X}_j\big) \\
% %&+ s^{(k)}_{i m} \tilde r_{u i}\textbf{S}^k\textbf{X}_i - s^{(k)}_{jm} \tilde r_{uj} \textbf{S}^k\textbf{X}_j \bigg)
% %\end{align*}
% %where $x_{uij} = \sum_\ell \tilde r_{u \ell}  \textbf{S}^k\textbf{X}_\ell \cdot(\textbf{S}^k\textbf{X}_i -  \textbf{S}^k\textbf{X}_i)$.
% %\end{comment}

% %+ s_{i m} r_{u i}\tilde \textbf{X}_i - s_{jm}r_{uj} \texbf{X}_j\right)

% % {\color{red}
% % We compare the complexity of the algorithm with respect to the LightGCN.
% % A first rough complexity analysis for the LightGCN leads us to the following complexity:
% % \begin{equation}
% %     \mathcal{O}(K(U+I)(U+I)F) = \mathcal{O}(K(U+I)^2F)
% % \end{equation}
% % while for UI-GCCF we have:
% % \begin{equation}
% %     \mathcal{O}(K(IIF)+UIF) = \mathcal{O}(KI^2F + UIF)
% % \end{equation}
% % considering that for each convolution depth $k$ we have to multiply the embedding matrix times the propagation matrix.
% % }