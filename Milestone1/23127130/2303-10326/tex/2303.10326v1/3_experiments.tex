\section{Experiments}

%\subsection{Implementation Details}

%% 所有代码被实现使用Pytorch11.3和monai1.0在4个NVIDIA A100 Tensor Core GPU上。在训练阶段，损失函数联合了dice loss，bce loss 和 mse loss，并且我们使用weight decay为10-5 的AdamW优化器。Warmup为epoch总数的1/10且使用Cosine Annealing 学习率更新方式。每次迭代随机采样n个(96,96,96)大小的补丁进行训练。
\noindent
\textbf{Implementation Details.} \ Our network is implemented in Pytorch and MONAI on 4$\times$ NVIDIA A100  GPUs. In the training phase, the loss function combines DICE loss, BCE loss, and MSE loss. We adopt an AdamW optimizer with a weight decay of 10-5. The warmup is set as 1/10 of the total number of epochs, and the learning rate is updated using the Cosine Annealing schedule. Each iteration randomly samples n patches (patch size is 96$\times$96$\times$96) for training.
%%
%% 数据增强
%And All experiments apply a data enhancement transform with
Random flips, rotations, intensity scaling, and shifts are introduced for data augmentation.
%%
%% 在测试阶段，我们设置DDIM采样步数为10，且每次采样(96,96,96)大小，滑动窗口重叠率设置为0.5，直到预测完毕全部数据。
In testing, we set the number of DDIM sampling steps as 10, and the size of each sample is 96$\times$96$\times$96. The sliding window overlap rate is 0.5 until the whole volume is predicted.

\subsection{Datasets and Evaluation Metrics}

%% 为了测试我们方法的分割性能，我们使用公开的脑肿瘤分割数据集BraTS2020和腹部多器官分割数据集BTCV。Dice score and 95\% Hausdorff Distance (HD95)被应用于量化对比。
To evaluate the volumetric segmentation performance of our method, we utilize three publicly available segmentation datasets, including BraTS2020~\cite{menze2014multimodal,bakas2018identifying}, MSD Liver~\cite{antonelli2022medical} dataset, and the abdominal multi-organ segmentation dataset BTCV~\cite{BTCV}. 
Moreover, the Dice score and 95\% Hausdorff Distance (HD95) are adopted for quantitative comparison.

\noindent
\textbf{BraTS2020 dataset} contains 369 aligned four-modality MRI data (i.e., T1, T1ce, T2, FLAIR) with expert segmentation masks (i.e., GD-enhancing tumor, peritumoral edema, and tumor core). 
Each modality has a 155×240×240 volume and all modality images have already been resampled and co-registered. 
The segmentation task aims to segment the whole tumor (WT), enhancing tumor (ET), and tumor core (TC) regions.
%%
The splitting ratio for the training set, the validation set, and the test set is 0.7, 0.1, and 0.2.

\noindent
\textbf{MSD Liver dataset} has a total of 131 cases of 3D liver images with 1 modality and 2 segmentation targets (liver and liver tumor) for each 3D liver image. All data are resampled to the same space (2.0, 2.0, 2.0).
%
%% 我们按照0.7，0.1，0.2的比例划分训练集，验证集和测试集。
The  MSD liver dataset is divided into a training set, validation set, and test set according to the ratio of 0.7, 0.1, and 0.2.

\noindent
\textbf{BTCV dataset} consists of 30 cases of 3D abdominal
multi-organ images and each 3D image has 13 organ segmentation targets.
% 所有数据被重采样到相同的space(2.0, 1.5, 1.5)。此外，我们划分18个cases用于训练，12个cases用于测试。该划分方式与TransUNet方法相同。
All data are resampled to the same space (2.0, 1.5, 1.5). 
Following TransUNet, 18 cases are used for training, and the remaining 12 cases are for testing.

\subsection{Comparison with SOTA Methods}

\input{Tables/brats_result}

\input{Tables/liver_result}

\input{Tables/btcv_result}

% 为了充分的验证MDiffusionSeg方法，我们选择了多种先进的对比方法。对于BraTS2020数据集，我们选择SwinUNETR，UNETR，TransBTS，SegResNet，Attention-UNet，ModelsGenesis作为对比方法。为了公平对比，所有方法均使用公开的实现。
%In order to fully validate the MDiffusionSeg method, we chose several advanced comparison methods.
For the BraTS2020 and MSD liver datasets, we compare our Diff-UNet against state-of-the-art segmentation methods, including SwinUNETR, UNETR, TransBTS, SegResNet, Attention-UNet, and ModelsGenesis. For a fair comparison, all methods use publicly available implementations.
%% 对于BTCV数据集，由于我们使用与TransUNet相同的训练与测试数据，因此我们不训练额外的对比方法。
For the BTCV dataset, we follow same experimental setting of TransUNet to utilize the same training and testing dataset and compare with state-of-the-art methods.
%not train additional comparison methods since we use the same training and testing data as TransUNet.
 
%% Table 1 报告了所有方法在三个区域（WT，TC，ET）上的Dice和HD95得分以及平均得分。显然，我们提出的MDiffusionSeg方法在Dice得分上有非常大的优势。三个区域的平均Dice实现了85.13%，比第二名ModelsGenesis提升1.75%。同时平均的HD95也实现了3.4512，位于第三名，与前两名只有非常小的差距。
\noindent
\textbf{BraTS2020. } 
Table \ref{tab:brats_result} reports the Dice and HD95 scores and the average scores of all methods on the three regions (WT, TC, ET) for the BraTS2020 dataset. Apparently, our proposed Diff-UNet method clearly outperforms compared state-of-the-art methods in terms of the Dice score for all three regions and their average. The average Dice of the three regions achieves 85.35\%, which has a improvement of 1.97\% than the second place ModelsGenesis. Although our average HD95 score on three regions achieved 3.3898, which takes the 3rd rank, it is slightly smaller than the top two HD95 results (i.e., 3.2499 and 3.0961).

\noindent
\textbf{MSD Liver. }
% 与Table 1 类似，Table 2报告了我们提出的方法在MSD Liver数据集上的性能。相比于其他对比方法，MDiffusionSeg在Liver分割上实现了95.72%的Dice得分和0.222的hd95得分，在Liver肿瘤分割上实现了51.65的Dice得分和17.280的hd95得分。MDiffusionSeg方法在所有指标上均实现了state-of-the-art结果。
%Similar to Table \ref{tab:brats_result}, 
Table \ref{tab:liver_result} reports the Dice and HD95 performance of our proposed Diff-UNet and state-of-the-art methods on the MSD Liver dataset. Compared with other comparison methods, our Diff-UNet method has the larger Dice score and the smaller HD95 score on the Liver region, the tumor region and their average. 
Specifically, our Diff-UNet achieves a Dice score of 95.72\% and a HD95 score of 0.222 on Liver segmentation, and a Dice score of 51.65\% and a HD95 score of 17.280 on Liver tumor segmentation. And the average Dice and HD95 score on two regions are 73.69\% and 8.751. 

\noindent
\textbf{BTCV.}
%% 与TransUNet的实验设置一样，我们报告了8个腹部器官的Dice得分和平均的Dice与HD得分。Table 2的最后一行是MDiffusionSeg方法的指标。显然，我们的方法在Dice与HD得分上均实现state-of-the-art 的结果。MDiffusionSeg方法在8个器官的平均Dice得分实现了最优的83.75，同时HD得分也实现了最好的8.115。
Following the same experimental setup of TransUNet, we report the Dice scores for the eight abdominal organs and the average Dice and HD scores in Table~\ref{tab:btcv_segmentation} to compare our Diff-UNet and state-of-the-art segmentation methods. %The last row of Table 2 shows the metrics of the Diff-UNet method. 
From Table~\ref{tab:btcv_segmentation}, we can find that our Diff-UNet has the best averaged Dice and HD95 scores on eight organs.
Specially, our Diff-UNet takes the 1st rank on the Dice score for six organs, and the averaged Dice and HD95 scores are 83.75\% and 8.115.
It indicates that our Diff-UNet can achieve a more accurate multi-organ segmentation performance than state-of-the-art methods in the BTCV dataset.\
%%
Although our Diff-UNet takes the 2nd Dice rank on Spleen, and the 3rd Dice rank on Stomach, their Dice scores (89.75\% and 74.65\%) are slightly smaller than the best ones, which are 89.90\% for Spleen and 75.62\% for Stomach.
%Our method achieves state-of-the-art results for both Dice and HD scores, and the Diff-UNet method achieves the best average Dice score of 83.75 and the best average HD score of 8.115 for the eight organs.



\begin{figure}[!t]
\includegraphics[width=\textwidth]{Figures/visualization.pdf}
%% 训练阶段为一步去噪的过程，测试阶段通过迭代的方式预测分割标签，并通过我们设计的S-U Fusion模块提升分割结果的鲁棒性。
\caption{The visual comparisons on segmentation results produced by our network and state-of-the-art methods on BraTS2020 and MSD Liver datasets. Apparently, our method has a more accurate segmentation performance and is consistent with the ground truth (denoted as ``GT'').} \label{fig:visual}
\end{figure}

\noindent
\textbf{Visual Comparisons.}
Fig.~\ref{fig:visual} visually compares the segmentation results produced by our Diff-UNet and SOTA methods on BraTS2020 and MSD Liver datasets. 
We do not run the comparison method on the BTCV dataset but use the result table in TransUNet directly, so we do not show the segmentation results on the BTCV dataset.
We can find that our Diff-UNet achieves more accurate segmentation results, especially on the tiny targets, while compared methods tend to miss some target regions, or include other non-target regions (see SwinUNETR at the 2nd row) in their segmentation results. 
%which other methods can not segment greatly. The visual comparison results show that the Diff-UNet is more robust than other SOTA methods.

%% 由于我们没有在BTCV数据集上运行对比方法，而是直接使用TransUNet中的结果表格，因此我们没有展示BTCV数据集上的分割结果。
\subsection{Ablation study}
% 我们对BraTS2020数据集进行了消融实验以评估MDiffusionSeg中不同模块的作用。看 Table 3。Image encoder表示利用独立的图像编码器提取原始图像的多尺度特征，并融合至diffusion模型中。
\input{Tables/ablation_2}

\noindent
\textbf{Effectiveness of major modules.} We conduct ablation experiments on the BraTS2020 dataset to evaluate the role of different major modules (i.e., FE and SUF) involved in Diff-UNet and show their quantitative results in Table~\ref{tab:ablation_module}. 
%Feature Encoder(FE) indicates that the multi-scale features of the raw volume data are extracted using a separate image encoder and fused into the Denoising-UNet. 
%% SF 表示将扩散模型的每一步输出通过相加的方式进行融合。
%Simple Fusion(SF) indicates that the diffusion model's output of each step is fused by summing.
%% 
%SUF indicates that we use the SUF module based on iteration steps and uncertainty to calculate the fusion weights. $S$ represents the number of predictions of the diffusion model in test phase.
%%
% 消融实验结果表明，相比$baseline1$，通过添加图像编码器(baseline2)，可以为diffusion模型引入更多的图像信息，从而提升分割精度。同时，对DDIM每一步预测的分割结果进行融合($baseline3$)，可以提升模型的鲁棒性。
From the quantitative results in Table~\ref{tab:ablation_module}, we can find that ``basic+FE'' has a larger averaged Dice on three regions (i.e., WT, TC, and ET) than ``basic'', which indicates that taking our FE as the image encoder can introduce more image information to the diffusion model, thereby improving the segmentation accuracy. 
Meanwhile, the superior Dice score of ``basic+FE+SF'' over ``basic+FE'' demonstrates that fusing the segmentation results predicted at each step of DDIM can further improve the segmentation accuracy of the diffusion model.
%%
Moreover, our method has a superior Dice score over ``basic+FE+SF'', which shows that assigning different weights to integrate predictions at different DDIM steps can further enhance the segmentation performance of our method.
%are fused (``basic+FE+SUF'')
%% 此外，在baseline4-baseline6中使用我们提出的S-U Fusion模块融合扩散模型的输出结果，实现了更好的分割性能。该模块通过结合预测步数与不确定性计算融合权重，可以更好的提升网络的鲁棒性。
%% 我们还探索了S-U Fusion 模块中参数S的作用，实验结果表明，S=4时（baseline5），扩散模型得到了最优的分割效果。


\noindent
\textbf{Setting S.} Moreover, we conduct an ablation study experiment to discuss how to set the value of $S$ (see Eq.~\ref{Eq:u_i}), which is the number of predictions to compute the uncertainty in each DDIM step. Here we consider different values for $S$, and they are 3, 4, 5, and 6 and show the corresponding results in Table~\ref{tab:ablation_S}.
%%
Apparently, our method has the best averaged Dice score on three regions when $S=4$, and it has the largest Dice score of 92.23\% on WT, the second largest Dice score of 76.87\%, and the largest Dice score of 85.35\% on ET. 
Hence, we empirically set $S=4$ in our method.

\if 0
addition, better segmentation performance is achieved by fusing the output of the diffusion model using our proposed SUF module in $baseline4$-$baseline7$. This module can improve the network's robustness by combining prediction steps and uncertainty to get the fusion output.
We also explore the role of the parameter $S$ in the SUF module, and the experimental results show that the Diff-UNet obtain optimal segmentation for $S=4$ ($baseline5$).
\fi

% In addition, the simple fusion strategy is replaced with our proposed S-U Fusion module in $baseline4$, which achieves state-of-the-art segmentation performance. This module can improve the network's robustness by combining iteration steps and uncertainty to calculate the fusion output.
% % 在baseline4中，我们设置T=4，因此，在每一步迭代中，利用模型预测的4次输出计算不确定性来得到融合权重。
% In baseline4, we set $S$=4, so in each step of the iteration, the uncertainty is calculated using the four outputs of the model to obtain the fusion weights.