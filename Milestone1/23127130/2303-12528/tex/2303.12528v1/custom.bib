@article{nivre2018universal,
  title={Universal Dependencies 2.2},
  author={Nivre, Joakim and Abrams, Mitchell and Agi{\'c}, {\v{Z}}eljko and Ahrenberg, Lars and Antonsen, Lene and Aranzabe, Maria Jesus and Arutie, Gashaw and Asahara, Masayuki and Ateyah, Luma and Attia, Mohammed and others},
  year={2018}
}

@inproceedings{ponti2020xcopa,
  title={XCOPA: A Multilingual Dataset for Causal Commonsense Reasoning},
  author={Ponti, Edoardo Maria and Glava{\v{s}}, Goran and Majewska, Olga and Liu, Qianchu and Vuli{\'c}, Ivan and Korhonen, Anna},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={2362--2376},
  year={2020}
}

@inproceedings{litmus,
  title={Litmus predictor: An ai assistant for building reliable, high-performing and fair multilingual nlp systems},
  author={Srinivasan, Anirudh and Kholkar, Gauri and Kejriwal, Rahul and Ganu, Tanuja and Dandapat, Sandipan and Sitaram, Sunayana and Santhanam, Balakrishnan and Aditya, Somak and Bali, Kalika and Choudhury, Monojit},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={11},
  pages={13227--13229},
  year={2022}
}

@inproceedings{wu2020all,
  title={Are All Languages Created Equal in Multilingual BERT?},
  author={Wu, Shijie and Dredze, Mark},
  booktitle={Proceedings of the 5th Workshop on Representation Learning for NLP},
  pages={120--130},
  year={2020}
}

@inproceedings{ahuja2022economics,
  title={On the Economics of Multilingual Few-shot Learning: Modeling the Cost-Performance Trade-offs of Machine Translated and Manual Data},
  author={Ahuja, Kabir and Choudhury, Monojit and Dandapat, Sandipan},
  booktitle={Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={1369--1384},
  year={2022}
}

@article{goyal2022flores,
  title={The flores-101 evaluation benchmark for low-resource and multilingual machine translation},
  author={Goyal, Naman and Gao, Cynthia and Chaudhary, Vishrav and Chen, Peng-Jen and Wenzek, Guillaume and Ju, Da and Krishnan, Sanjana and Ranzato, Marc’Aurelio and Guzm{\'a}n, Francisco and Fan, Angela},
  journal={Transactions of the Association for Computational Linguistics},
  volume={10},
  pages={522--538},
  year={2022},
  publisher={MIT Press}
}

@inproceedings{gpt4techreport,
  title={GPT4 Technical Report},
  author={OpenAI},
  url={https://arxiv.org/pdf/2303.08774.pdf},
  year={2023}
}

@inproceedings{conneau2020unsupervised,
  title={Unsupervised Cross-lingual Representation Learning at Scale},
  author={Conneau, Alexis and Khandelwal, Kartikay and Goyal, Naman and Chaudhary, Vishrav and Wenzek, Guillaume and Guzm{\'a}n, Francisco and Grave, {\'E}douard and Ott, Myle and Zettlemoyer, Luke and Stoyanov, Veselin},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={8440--8451},
  year={2020}
}

@misc{muennighoff2022crosslingual,
      title={Crosslingual Generalization through Multitask Finetuning}, 
      author={Niklas Muennighoff and Thomas Wang and Lintang Sutawika and Adam Roberts and Stella Biderman and Teven Le Scao and M Saiful Bari and Sheng Shen and Zheng-Xin Yong and Hailey Schoelkopf and Xiangru Tang and Dragomir Radev and Alham Fikri Aji and Khalid Almubarak and Samuel Albanie and Zaid Alyafeai and Albert Webson and Edward Raff and Colin Raffel},
      year={2022},
      eprint={2211.01786},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{bert2019,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={Proceedings of naacL-HLT},
  pages={4171--4186},
  year={2019}
}

@article{graham2019translationese,
  title={Translationese in machine translation evaluation},
  author={Graham, Yvette and Haddow, Barry and Koehn, Philipp},
  journal={arXiv preprint arXiv:1906.09833},
  year={2019}
}

@misc{newbingevent,
      title={Microsoft’s ChatGPT event live blog},
      year={2023},
      url={"https://www.theverge.com/2023/2/7/23588249/microsoft-event-ai-live-blog-openai-chatgpt-bing-announcements-news"},
}

@article{chowdhery2022palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}

@article{scao2022bloom,
  title={Bloom: A 176b-parameter open-access multilingual language model},
  author={Scao, Teven Le and Fan, Angela and Akiki, Christopher and Pavlick, Ellie and Ili{\'c}, Suzana and Hesslow, Daniel and Castagn{\'e}, Roman and Luccioni, Alexandra Sasha and Yvon, Fran{\c{c}}ois and Gall{\'e}, Matthias and others},
  journal={arXiv preprint arXiv:2211.05100},
  year={2022}
}

@article{wang2019superglue,
  title={Superglue: A stickier benchmark for general-purpose language understanding systems},
  author={Wang, Alex and Pruksachatkun, Yada and Nangia, Nikita and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}



@article{patra2022beyond,
  title={Beyond english-centric bitexts for better multilingual language representation learning},
  author={Patra, Barun and Singhal, Saksham and Huang, Shaohan and Chi, Zewen and Dong, Li and Wei, Furu and Chaudhary, Vishrav and Song, Xia},
  journal={arXiv preprint arXiv:2210.14867},
  year={2022}
}

@inproceedings{khanuja2020gluecos,
  title={GLUECoS: An Evaluation Benchmark for Code-Switched NLP},
  author={Khanuja, Simran and Dandapat, Sandipan and Srinivasan, Anirudh and Sitaram, Sunayana and Choudhury, Monojit},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={3575--3585},
  year={2020}
}

@article{bang2023multitask,
  title={A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity},
  author={Bang, Yejin and Cahyawijaya, Samuel and Lee, Nayeon and Dai, Wenliang and Su, Dan and Wilie, Bryan and Lovenia, Holy and Ji, Ziwei and Yu, Tiezheng and Chung, Willy and others},
  journal={arXiv preprint arXiv:2302.04023},
  year={2023}
}

@article{hendy2023good,
  title={How Good Are GPT Models at Machine Translation? A Comprehensive Evaluation},
  author={Hendy, Amr and Abdelrehim, Mohamed and Sharaf, Amr and Raunak, Vikas and Gabr, Mohamed and Matsushita, Hitokazu and Kim, Young Jin and Afify, Mohamed and Awadalla, Hany Hassan},
  journal={arXiv preprint arXiv:2302.09210},
  year={2023}
}

@article{liang2022holistic,
  title={Holistic evaluation of language models},
  author={Liang, Percy and Bommasani, Rishi and Lee, Tony and Tsipras, Dimitris and Soylu, Dilara and Yasunaga, Michihiro and Zhang, Yian and Narayanan, Deepak and Wu, Yuhuai and Kumar, Ananya and others},
  journal={arXiv preprint arXiv:2211.09110},
  year={2022}
}

@article{ramesh2023fairness,
  title={Fairness in Language Models Beyond English: Gaps and Challenges},
  author={Ramesh, Krithika and Sitaram, Sunayana and Choudhury, Monojit},
  journal={arXiv preprint arXiv:2302.12578},
  year={2023}
}

@article{wilie2020indonlu,
  title={IndoNLU: Benchmark and resources for evaluating Indonesian natural language understanding},
  author={Wilie, Bryan and Vincentio, Karissa and Winata, Genta Indra and Cahyawijaya, Samuel and Li, Xiaohong and Lim, Zhi Yuan and Soleman, Sidik and Mahendra, Rahmad and Fung, Pascale and Bahar, Syafri and others},
  journal={arXiv preprint arXiv:2009.05387},
  year={2020}
}

@inproceedings{aguilar2020lince,
  title={LinCE: A Centralized Benchmark for Linguistic Code-switching Evaluation},
  author={Aguilar, Gustavo and Kar, Sudipta and Solorio, Thamar},
  booktitle={Proceedings of the Twelfth Language Resources and Evaluation Conference},
  pages={1803--1813},
  year={2020}
}


@book{harrison2007languages,
  title={When languages die: The extinction of the world's languages and the erosion of human knowledge},
  author={Harrison, K David},
  year={2007},
  publisher={Oxford University Press}
}

@article{liang2020xglue,
  title={Xglue: A new benchmark dataset for cross-lingual pre-training, understanding and generation},
  author={Liang, Yaobo and Duan, Nan and Gong, Yeyun and Wu, Ning and Guo, Fenfei and Qi, Weizhen and Gong, Ming and Shou, Linjun and Jiang, Daxin and Cao, Guihong and others},
  journal={arXiv preprint arXiv:2004.01401},
  year={2020}
}

@inproceedings{ruder2021xtreme,
  title={XTREME-R: Towards More Challenging and Nuanced Multilingual Evaluation},
  author={Ruder, Sebastian and Constant, Noah and Botha, Jan and Siddhant, Aditya and Firat, Orhan and Fu, Jinlan and Liu, Pengfei and Hu, Junjie and Garrette, Dan and Neubig, Graham and others},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={10215--10245},
  year={2021}
}

@inproceedings{hu2020xtreme,
  title={Xtreme: A massively multilingual multi-task benchmark for evaluating cross-lingual generalisation},
  author={Hu, Junjie and Ruder, Sebastian and Siddhant, Aditya and Neubig, Graham and Firat, Orhan and Johnson, Melvin},
  booktitle={International Conference on Machine Learning},
  pages={4411--4421},
  year={2020},
  organization={PMLR}
}

@inproceedings{Zhang2022HowRI,
  title={How Robust is Neural Machine Translation to Language Imbalance in Multilingual Tokenizer Training?},
  author={Shiyue Zhang and Vishrav Chaudhary and Naman Goyal and James Cross and Guillaume Wenzek and Mohit Bansal and Francisco Guzm{\'a}n},
  booktitle={Conference of the Association for Machine Translation in the Americas},
  year={2022}
}

@inproceedings{Khemchandani2021ExploitingLR,
  title={Exploiting Language Relatedness for Low Web-Resource Language Model Adaptation: An Indic Languages Study},
  author={Yash Khemchandani and Sarvesh Mehtani and Vaidehi Patil and Abhijeet Awasthi and Partha Pratim Talukdar and Sunita Sarawagi},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2021}
}

@article{wang2018glue,
  title={GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},
  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R},
  journal={EMNLP 2018},
  pages={353},
  year={2018}
}

@inproceedings{vilares2016cs,
  title={En-es-cs: An english-spanish code-switching twitter corpus for multilingual sentiment analysis},
  author={Vilares, David and Alonso, Miguel A and G{\'o}mez-Rodr{\'\i}guez, Carlos},
  booktitle={Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC'16)},
  pages={4149--4153},
  year={2016}
}

@inproceedings{artetxe2020cross,
  title={On the Cross-lingual Transferability of Monolingual Representations},
  author={Artetxe, Mikel and Ruder, Sebastian and Yogatama, Dani},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={4623--4637},
  year={2020}
}

@inproceedings{yang2019paws,
  title={PAWS-X: A Cross-lingual Adversarial Dataset for Paraphrase Identification},
  author={Yang, Yinfei and Zhang, Yuan and Tar, Chris and Baldridge, Jason},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={3687--3692},
  year={2019}
}

@article{doddapaneni2022indicxtreme,
  title={IndicXTREME: A Multi-Task Benchmark For Evaluating Indic Languages},
  author={Doddapaneni, Sumanth and Aralikatte, Rahul and Ramesh, Gowtham and Goyal, Shreya and Khapra, Mitesh M and Kunchukuttan, Anoop and Kumar, Pratyush},
  journal={arXiv preprint arXiv:2212.05409},
  year={2022}
}

@article{aggarwal2022indicxnli,
  title={IndicXNLI: Evaluating multilingual inference for Indian languages},
  author={Aggarwal, Divyanshu and Gupta, Vivek and Kunchukuttan, Anoop},
  journal={arXiv preprint arXiv:2204.08776},
  year={2022}
}

@inproceedings{lewis2020mlqa,
  title={MLQA: Evaluating Cross-lingual Extractive Question Answering},
  author={Lewis, Patrick and Oguz, Barlas and Rinott, Ruty and Riedel, Sebastian and Schwenk, Holger},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={7315--7330},
  year={2020}
}

@article{10.1162/tacl_a_00474,
    author = {Goyal, Naman and Gao, Cynthia and Chaudhary, Vishrav and Chen, Peng-Jen and Wenzek, Guillaume and Ju, Da and Krishnan, Sanjana and Ranzato, Marc’Aurelio and Guzmán, Francisco and Fan, Angela},
    title = "{The Flores-101 Evaluation Benchmark for Low-Resource and Multilingual Machine Translation}",
    journal = {Transactions of the Association for Computational Linguistics},
    volume = {10},
    pages = {522-538},
    year = {2022},
    month = {05},
    abstract = "{One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the lack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource languages, consider only restricted domains, or are low quality because they are constructed using semi-automatic procedures. In this work, we introduce the Flores-101 evaluation benchmark, consisting of 3001 sentences extracted from English Wikipedia and covering a variety of different topics and domains. These sentences have been translated in 101 languages by professional translators through a carefully controlled process. The resulting dataset enables better assessment of model quality on the long tail of low-resource languages, including the evaluation of many-to-many multilingual translation systems, as all translations are fully aligned. By publicly releasing such a high-quality and high-coverage dataset, we hope to foster progress in the machine translation community and beyond.}",
    issn = {2307-387X},
    doi = {10.1162/tacl_a_00474},
    url = {https://doi.org/10.1162/tacl\_a\_00474},
    eprint = {https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl\_a\_00474/2020699/tacl\_a\_00474.pdf},
}





@article{clark2020tydi,
  title={TyDi QA: A benchmark for information-seeking question answering in typologically diverse languages},
  author={Clark, Jonathan H and Choi, Eunsol and Collins, Michael and Garrette, Dan and Kwiatkowski, Tom and Nikolaev, Vitaly and Palomaki, Jennimaria},
  journal={Transactions of the Association for Computational Linguistics},
  volume={8},
  pages={454--470},
  year={2020},
  publisher={MIT Press}
}

@inproceedings{khanuja2020new,
  title={A New Dataset for Natural Language Inference from Code-mixed Conversations},
  author={Khanuja, Simran and Dandapat, Sandipan and Sitaram, Sunayana and Choudhury, Monojit},
  booktitle={Proceedings of the The 4th Workshop on Computational Approaches to Code Switching},
  pages={9--16},
  year={2020}
}

@inproceedings{Pan2017,
author = {Pan, Xiaoman and Zhang, Boliang and May, Jonathan and Nothman, Joel and Knight, Kevin and Ji, Heng},
booktitle = {Proceedings of ACL 2017},
pages = {1946--1958},
title = {{Cross-lingual name tagging and linking for 282 languages}},
year = {2017}
}



@inproceedings{Conneau2018xnli,
    title = "{XNLI}: Evaluating Cross-lingual Sentence Representations",
    author = "Conneau, Alexis  and
      Rinott, Ruty  and
      Lample, Guillaume  and
      Williams, Adina  and
      Bowman, Samuel  and
      Schwenk, Holger  and
      Stoyanov, Veselin",
    booktitle = "Proceedings of EMNLP 2018",
    year = "2018",
    pages = "2475--2485",
}

@inproceedings{Yang2019paws-x,
    title = "{PAWS-X}: A Cross-lingual Adversarial Dataset for Paraphrase Identification",
    author = "Yang, Yinfei  and
      Zhang, Yuan  and
      Tar, Chris  and
      Baldridge, Jason",
    booktitle = "Proceedings of EMNLP 2019",
    year = "2019",
    pages = "3685--3690",
}

@inproceedings{Rust2020HowGI,
  title={How Good is Your Tokenizer? On the Monolingual Performance of Multilingual Language Models},
  author={Phillip Rust and Jonas Pfeiffer and Ivan Vulic and Sebastian Ruder and Iryna Gurevych},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2020}
}

@inproceedings{DavidsonWMW17,
  author={Thomas Davidson and Dana Warmsley and Michael W. Macy and Ingmar Weber},
  title={Automated Hate Speech Detection and the Problem of Offensive Language},
  year={2017},
  cdate={1483228800000},
  pages={512-515},
  url={https://aaai.org/ocs/index.php/ICWSM/ICWSM17/paper/view/15665},
  booktitle={ICWSM},
}


@inproceedings{joshi2020state,
  title={The State and Fate of Linguistic Diversity and Inclusion in the NLP World},
  author={Joshi, Pratik and Santy, Sebastin and Budhiraja, Amar and Bali, Kalika and Choudhury, Monojit},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={6282--6293},
  year={2020}
}
@inproceedings{rajpurkar2016squad,
  title={SQuAD: 100,000+ Questions for Machine Comprehension of Text},
  author={Rajpurkar, Pranav and Zhang, Jian and Lopyrev, Konstantin and Liang, Percy},
  booktitle={Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing},
  pages={2383--2392},
  year={2016}
}

@article{Sarkar_KhudaBukhsh_2021, title={Are Chess Discussions Racist? An Adversarial Hate Speech Data Set (Student Abstract)}, volume={35}, url={https://ojs.aaai.org/index.php/AAAI/article/view/17937}, abstractNote={On June 28, 2020, while presenting a chess podcast on Grandmaster Hikaru Nakamura, Antonio Radic’s YouTube handle got blocked because it contained ``harmful and dangerous’’ content. YouTube did not give further specific reason, and the channel got reinstated within 24 hours. However, Radic speculated that given the current political situation, a referral to ``black against white’’, albeit in the context of chess, earned him this temporary ban. In this paper, via a substantial corpus of 681,995 comments, on 8,818 YouTube videos hosted by five highly popular chess-focused YouTube channels, we ask the following research question: \emph{how robust are off-the-shelf hate-speech classifiers to out-of-domain adversarial examples?} We release a data set of 1,000 annotated comments where existing hate speech classifiers misclassified benign chess discussions as hate speech. We conclude with an intriguing analogy result on racial bias with our findings pointing out to the broader challenge of color polysemy.}, number={18}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Sarkar, Rupak and KhudaBukhsh, Ashiqur R.}, year={2021}, month={May}, pages={15881-15882} }
  title = {Are Chess Discussions Racist? An Adversarial Hate Speech Data Set},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{deshpande-2022-highly,
  doi = {10.48550/ARXIV.2201.11294},
  
  url = {https://arxiv.org/abs/2201.11294},
  
  author = {Deshpande, Neha and Farris, Nicholas and Kumar, Vidhur},
  
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Highly Generalizable Models for Multilingual Hate Speech Detection},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@InProceedings{guo-2017-on,
  title = 	 {On Calibration of Modern Neural Networks},
  author =       {Chuan Guo and Geoff Pleiss and Yu Sun and Kilian Q. Weinberger},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {1321--1330},
  year = 	 {2017},
  editor = 	 {Precup, Doina and Teh, Yee Whye},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/guo17a/guo17a.pdf},
  url = 	 {https://proceedings.mlr.press/v70/guo17a.html},
  abstract = 	 {Confidence calibration – the problem of predicting probability estimates representative of the true correctness likelihood – is important for classification models in many applications. We discover that modern neural networks, unlike those from a decade ago, are poorly calibrated. Through extensive experiments, we observe that depth, width, weight decay, and Batch Normalization are important factors influencing calibration. We evaluate the performance of various post-processing calibration methods on state-of-the-art architectures with image and document classification datasets. Our analysis and experiments not only offer insights into neural network learning, but also provide a simple and straightforward recipe for practical settings: on most datasets, temperature scaling – a single-parameter variant of Platt Scaling – is surprisingly effective at calibrating predictions.}
}

@INPROCEEDINGS{he-et-al-2016-deep,
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Deep Residual Learning for Image Recognition}, 
  year={2016},
  volume={},
  number={},
  pages={770-778},
  doi={10.1109/CVPR.2016.90}}
  
  @ARTICLE{lecun-et-al-1998-gradient,
  author={Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  journal={Proceedings of the IEEE}, 
  title={Gradient-based learning applied to document recognition}, 
  year={1998},
  volume={86},
  number={11},
  pages={2278-2324},
  doi={10.1109/5.726791}}
  
  @misc{liu-et-al-2019-roberta,
  doi = {10.48550/ARXIV.1907.11692},
  
  url = {https://arxiv.org/abs/1907.11692},
  
  author = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {RoBERTa: A Robustly Optimized BERT Pretraining Approach},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{aviral-sarawagi-2019-calibration,
  author    = {Aviral Kumar and
               Sunita Sarawagi},
  title     = {Calibration of Encoder Decoder Models for Neural Machine Translation},
  journal   = {CoRR},
  volume    = {abs/1903.00802},
  year      = {2019},
  url       = {http://arxiv.org/abs/1903.00802},
  eprinttype = {arXiv},
  eprint    = {1903.00802},
  timestamp = {Sat, 30 Mar 2019 19:27:21 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1903-00802.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@InProceedings{Zhao-et-al-2021-calibrate,
  title = 	 {Calibrate Before Use: Improving Few-shot Performance of Language Models},
  author =       {Zhao, Zihao and Wallace, Eric and Feng, Shi and Klein, Dan and Singh, Sameer},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {12697--12706},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/zhao21c/zhao21c.pdf},
  url = 	 {https://proceedings.mlr.press/v139/zhao21c.html},
  abstract = 	 {GPT-3 can perform numerous tasks when provided a natural language prompt that contains a few training examples. We show that this type of few-shot learning can be unstable: the choice of prompt format, training examples, and even the order of the examples can cause accuracy to vary from near chance to near state-of-the-art. We demonstrate that this instability arises from the bias of language models towards predicting certain answers, e.g., those that are placed near the end of the prompt or are common in the pre-training data. To mitigate this, we first estimate the model’s bias towards each answer by asking for its prediction when given a training prompt and a content-free test input such as "N/A". We then fit calibration parameters that cause the prediction for this input to be uniform across answers. On a diverse set of tasks, this contextual calibration procedure substantially improves GPT-3 and GPT-2’s accuracy (up to 30.0% absolute) across different choices of the prompt, while also making learning considerably more stable.}
}

@misc{pereyra-et-al-2017,
  doi = {10.48550/ARXIV.1701.06548},
  
  url = {https://arxiv.org/abs/1701.06548},
  
  author = {Pereyra, Gabriel and Tucker, George and Chorowski, Jan and Kaiser, Łukasz and Hinton, Geoffrey},
  
  keywords = {Neural and Evolutionary Computing (cs.NE), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Regularizing Neural Networks by Penalizing Confident Output Distributions},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@INPROCEEDINGS{Platt99probabilisticoutputs,
    author = {John C. Platt},
    title = {Probabilistic Outputs for Support Vector Machines and Comparisons to Regularized Likelihood Methods},
    booktitle = {ADVANCES IN LARGE MARGIN CLASSIFIERS},
    year = {1999},
    pages = {61--74},
    publisher = {MIT Press}
}

@inproceedings{rafael-et-al-2019-when,
 author = {M\"{u}ller, Rafael and Kornblith, Simon and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {When does label smoothing help?},
 url = {https://proceedings.neurips.cc/paper/2019/file/f1748d6b0fd9d439f71450117eba2725-Paper.pdf},
 volume = {32},
 year = {2019}
}

@inproceedings{
wald2021on,
title={On Calibration and Out-of-Domain Generalization},
author={Yoav Wald and Amir Feder and Daniel Greenfeld and Uri Shalit},
booktitle={Advances in Neural Information Processing Systems},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021},
url={https://openreview.net/forum?id=XWYJ25-yTRS}
}

@article{keung-et-al-2020-marc,
  author    = {Phillip Keung and
               Yichao Lu and
               Gy{\"{o}}rgy Szarvas and
               Noah A. Smith},
  title     = {The Multilingual Amazon Reviews Corpus},
  journal   = {CoRR},
  volume    = {abs/2010.02573},
  year      = {2020},
  url       = {https://arxiv.org/abs/2010.02573},
  eprinttype = {arXiv},
  eprint    = {2010.02573},
  timestamp = {Mon, 12 Oct 2020 17:53:10 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2010-02573.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{
K2020Cross-Lingual,
title={Cross-Lingual Ability of Multilingual BERT: An Empirical Study},
author={Karthikeyan K and Zihan Wang and Stephen Mayhew and Dan Roth},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=HJeT3yrtDr}
}


@InProceedings{pmlr-v108-park20b,
  title = 	 {Calibrated Prediction with Covariate Shift via Unsupervised Domain Adaptation},
  author =       {Park, Sangdon and Bastani, Osbert and Weimer, James and Lee, Insup},
  booktitle = 	 {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},
  pages = 	 {3219--3229},
  year = 	 {2020},
  editor = 	 {Chiappa, Silvia and Calandra, Roberto},
  volume = 	 {108},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {26--28 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v108/park20b/park20b.pdf},
  url = 	 {https://proceedings.mlr.press/v108/park20b.html},
  abstract = 	 {Reliable uncertainty estimates are an important tool for helping autonomous agents or human decision makers understand and lever-age predictive models. However, existing approaches to estimating uncertainty largely ignore the possibility of covariate shift—i.e.,where the real-world data distribution may differ from the training distribution.  As a consequence, existing algorithms can overestimate certainty, possibly yielding a false sense of confidence in the predictive model. We pro-pose an algorithm for calibrating predictions that accounts for the possibility of covariate shift, given labeled examples from the train-ing distribution and unlabeled examples from the real-world distribution. Our algorithm uses importance weighting to correct for the shift from the training to the real-world distribution. However, importance weighting relies on the training and real-world distributions to be sufficiently close. Building on ideas from domain adaptation, we additionally learn a feature map that tries to equalize these two distributions. In an empirical evaluation, we show that our proposed approach outperforms existing approaches to calibrated prediction when there is covariate shift.}
}


@article{pampari-ermon-2020-unsupervised,
  author    = {Anusri Pampari and
               Stefano Ermon},
  title     = {Unsupervised Calibration under Covariate Shift},
  journal   = {CoRR},
  volume    = {abs/2006.16405},
  year      = {2020},
  url       = {https://arxiv.org/abs/2006.16405},
  eprinttype = {arXiv},
  eprint    = {2006.16405},
  timestamp = {Thu, 02 Jul 2020 14:42:48 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2006-16405.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{
braverman2020calibration,
title={Calibration, Entropy Rates, and Memory in Language Models},
author={Mark Braverman and Xinyi Chen and Sham Kakade and Karthik Narasimhan and Cyril Zhang and Yi Zhang},
year={2020},
url={https://openreview.net/forum?id=B1eQcCEtDB}
}

@inproceedings{roemmele2011choice,
  title={Choice of Plausible Alternatives: An Evaluation of Commonsense Causal Reasoning.},
  author={Roemmele, Melissa and Bejan, Cosmin Adrian and Gordon, Andrew S},
  booktitle={AAAI spring symposium: logical formalizations of commonsense reasoning},
  pages={90--95},
  year={2011}
}

@inproceedings{kingma-ba-2015-adam,
  author={Diederik P. Kingma and Jimmy Ba},
  title={Adam: A Method for Stochastic Optimization},
  year={2015},
  cdate={1420070400000},
  url={http://arxiv.org/abs/1412.6980},
  booktitle={ICLR (Poster)},
}

@article{metz-satariano-2020-alogrithm,
author={Cade Metz and Adam Satariano},
title={An Algorithm That Grants Freedom, or Takes It Away.},
url={https://www.nytimes.com/2020/02/06/technology/predictive-algorithms-crime.html},
journal={The New York Times},
year={2020},
ISSN={0362-4331}
}

@article{cuthbertson-2021-AI,
author={Anthony Cuthbertson},
title={AI mistakes ‘black and white’ chess chat for racism},
journal={The Independent},
url={https://www.independent.co.uk/tech/ai-chess-racism-youtube-agadmator-b1804160.html},
year={2021},
ISSN={1741-9743}
}

@misc{srinivasan-et-al-2021-predicting,
  doi = {10.48550/ARXIV.2110.08875},
  
  url = {https://arxiv.org/abs/2110.08875},
  
  author = {Srinivasan, Anirudh and Sitaram, Sunayana and Ganu, Tanuja and Dandapat, Sandipan and Bali, Kalika and Choudhury, Monojit},
  
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Predicting the Performance of Multilingual NLP Models},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{brown-etal-2020-language,
  author    = {Tom B. Brown and
               Benjamin Mann and
               Nick Ryder and
               Melanie Subbiah and
               Jared Kaplan and
               Prafulla Dhariwal and
               Arvind Neelakantan and
               Pranav Shyam and
               Girish Sastry and
               Amanda Askell and
               Sandhini Agarwal and
               Ariel Herbert{-}Voss and
               Gretchen Krueger and
               Tom Henighan and
               Rewon Child and
               Aditya Ramesh and
               Daniel M. Ziegler and
               Jeffrey Wu and
               Clemens Winter and
               Christopher Hesse and
               Mark Chen and
               Eric Sigler and
               Mateusz Litwin and
               Scott Gray and
               Benjamin Chess and
               Jack Clark and
               Christopher Berner and
               Sam McCandlish and
               Alec Radford and
               Ilya Sutskever and
               Dario Amodei},
  title     = {Language Models are Few-Shot Learners},
  journal   = {CoRR},
  volume    = {abs/2005.14165},
  year      = {2020},
  url       = {https://arxiv.org/abs/2005.14165},
  eprinttype = {arXiv},
  eprint    = {2005.14165},
  timestamp = {Wed, 03 Jun 2020 11:36:54 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2005-14165.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{zhang2019paws,
  title={PAWS: Paraphrase Adversaries from Word Scrambling},
  author={Zhang, Yuan and Baldridge, Jason and He, Luheng},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  pages={1298--1308},
  year={2019}
}



@article{thelwall2017heart,
  title={The Heart and soul of the web? Sentiment strength detection in the social web with SentiStrength},
  author={Thelwall, Mike},
  journal={Cyberemotions: Collective emotions in cyberspace},
  pages={119--134},
  year={2017},
  publisher={Springer}
}
@article{khanuja2021muril,
  title={Muril: Multilingual representations for indian languages},
  author={Khanuja, Simran and Bansal, Diksha and Mehtani, Sarvesh and Khosla, Savya and Dey, Atreyee and Gopalan, Balaji and Margam, Dilip Kumar and Aggarwal, Pooja and Nagipogu, Rajiv Teja and Dave, Shachi and others},
  journal={arXiv preprint arXiv:2103.10730},
  year={2021}
}

@article{shi-etal-2022-language,
  author    = {Freda Shi and
               Mirac Suzgun and
               Markus Freitag and
               Xuezhi Wang and
               Suraj Srivats and
               Soroush Vosoughi and
               Hyung Won Chung and
               Yi Tay and
               Sebastian Ruder and
               Denny Zhou and
               Dipanjan Das and
               Jason Wei},
  title     = {Language Models are Multilingual Chain-of-Thought Reasoners},
  journal   = {CoRR},
  volume    = {abs/2210.03057},
  year      = {2022},
  url       = {https://doi.org/10.48550/arXiv.2210.03057},
  doi       = {10.48550/arXiv.2210.03057},
  eprinttype = {arXiv},
  eprint    = {2210.03057},
  timestamp = {Fri, 07 Oct 2022 16:59:33 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2210-03057.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{ponti-etal-2021-modelling,
  doi = {10.48550/ARXIV.2107.11353},
  
  url = {https://arxiv.org/abs/2107.11353},
  
  author = {Ponti, Edoardo Maria and Kreutzer, Julia and Vulić, Ivan and Reddy, Siva},
  
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Modelling Latent Translations for Cross-Lingual Transfer},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{lin-etal-2022-shot,
    title = "Few-shot Learning with Multilingual Generative Language Models",
    author = "Lin, Xi Victoria  and
      Mihaylov, Todor  and
      Artetxe, Mikel  and
      Wang, Tianlu  and
      Chen, Shuohui  and
      Simig, Daniel  and
      Ott, Myle  and
      Goyal, Naman  and
      Bhosale, Shruti  and
      Du, Jingfei  and
      Pasunuru, Ramakanth  and
      Shleifer, Sam  and
      Koura, Punit Singh  and
      Chaudhary, Vishrav  and
      O{'}Horo, Brian  and
      Wang, Jeff  and
      Zettlemoyer, Luke  and
      Kozareva, Zornitsa  and
      Diab, Mona  and
      Stoyanov, Veselin  and
      Li, Xian",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.616",
    pages = "9019--9052",
    abstract = "Large-scale generative language models such as GPT-3 are competitive few-shot learners. While these models are known to be able to jointly represent many different languages, their training data is dominated by English, potentially limiting their cross-lingual generalization. In this work, we train multilingual generative language models on a corpus covering a diverse set of languages, and study their few- and zero-shot learning capabilities in a wide range of tasks. Our largest model with 7.5 billion parameters sets new state of the art in few-shot learning in more than 20 representative languages, outperforming GPT-3 of comparable size in multilingual commonsense reasoning (with +7.4{\%} absolute accuracy improvement in 0-shot settings and +9.4{\%} in 4-shot settings) and natural language inference (+5.4{\%} in each of 0-shot and 4-shot settings). On the FLORES-101 machine translation benchmark, our model outperforms GPT-3 on 171 out of 182 directions with 32 training examples, while surpassing the official supervised baseline in 45 directions. We conduct an in-depth analysis of different multilingual prompting approaches, showing in particular that strong few-shot learning performance across languages can be achieved via cross-lingual transfer through both templates and demonstration examples.",
}

@misc{Graham2022,
  author = {Neubig, Graham},
  title = {Is My NLP Model Working?},
  year="2022",
   url = {http://www.phontron.com/slides/neubig23ismynlpmodelworking.pdf},
}
