% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Remove the "review" option to generate the final version.
\usepackage[]{EMNLP2023}
% Standard package includes
\usepackage{times}
\usepackage{latexsym}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{microtype}
\usepackage{inconsolata}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{subcaption}
% \captionsetup{font=small}
% \captionsetup[sub]{font=small}
\usepackage{graphicx}
\usepackage{subfloat}
\usepackage{booktabs} % To thicken table lines
\usepackage{multirow}
\usepackage{amsmath,amssymb}
\usepackage{cuted}
\usepackage{flushend}
\usepackage{tablefootnote}
\usepackage{wrapfig}
\usepackage{xcolor}
\usepackage{colortbl} % for coloring table cells
\usepackage{mymacros} % mymacros.sty

\newif\ifcomments
\commentstrue
% \commentsfalse

 

\ifcomments
    \newcommand{\kabir}[1]{\textcolor{red}{#1 --Kabir}}
    \newcommand{\hdd}[1]{\textcolor{magenta}{#1 --Harshita}}
    \newcommand{\rishav}[1]{\textcolor{blue}{#1 --Rishav}}
    \newcommand{\akshay}[1]{\textcolor{brown}{#1 --Akshay}}
    \newcommand{\millicent}[1]{\textcolor{green}{#1 --Millicent}}
    \newcommand{\prachi}[1]{\textcolor{orange}{#1 --Prachi}}
    \newcommand{\tanuja}[1]{\textcolor{pink}{#1 --Tanuja}}
    \newcommand{\kalika}[1]{\textcolor{green}{#1 --Kalika}}
    \newcommand{\maxamed}[1]{\textcolor{blue}{#1 --Maxamed}}
    \newcommand{\sunayana}[1]{\textcolor{orange}{#1 --Sunayana}}
\else
    \newcommand{\kabir}[1]{}
    \newcommand{\hdd}[1]{}
    \newcommand{\rishav}[1]{}
    \newcommand{\akshay}[1]{}
    \newcommand{\millicent}[1]{}
    \newcommand{\prachi}[1]{}
    \newcommand{\tanuja}[1]{}
    \newcommand{\kalika}[1]{}
    \newcommand{\maxamed}[1]{}
    \newcommand{\sunayana}[1]{}
\fi



% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{MEGA: Multilingual Evaluation of Generative AI}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{\parbox{0.9\linewidth}{\centering{Kabir Ahuja\textsuperscript{$\heartsuit$}\thanks{\hspace{0.1cm} Work done when the author was at Microsoft.} \quad Harshita Diddee\textsuperscript{$\diamondsuit$}\footnotemark[1] \quad Rishav Hada \textsuperscript{$\dagger$} \quad Millicent Ochieng\textsuperscript{$\dagger$} \\ \quad  Krithika Ramesh \textsuperscript{$\spadesuit$}\footnotemark[1] \quad Prachi Jain\textsuperscript{$\dagger$} \quad Akshay Nambi\textsuperscript{$\dagger$}  \quad Tanuja Ganu\textsuperscript{$\dagger$}
 \\ Sameer Segal\textsuperscript{$\dagger$} \quad Maxamed Axmed\textsuperscript{$\dagger$} \quad Kalika Bali\textsuperscript{$\dagger$} \quad Sunayana Sitaram\textsuperscript{$\dagger$} \\
 {\rm \textsuperscript{$\heartsuit$}University of Washington \quad
\textsuperscript{$\diamondsuit$}Carnegie Mellon University \\
\textsuperscript{$\dagger$}Microsoft Corporation \quad 
\textsuperscript{$\spadesuit$}Johns Hopkins University \\}
 {\tt kahuja@cs.washington.edu, sunayana.sitaram@microsoft.com}}}}

\begin{document}
\maketitle
\begin{abstract}
Generative AI models have shown impressive performance on many Natural Language Processing tasks such as language understanding, reasoning, and language generation. An important question being asked by the AI community today is about the capabilities and limits of these models, and it is clear that evaluating generative AI is very challenging. Most studies on generative LLMs have been restricted to English and it is unclear how capable these models are at understanding and generating text in other languages. We present the first comprehensive benchmarking of generative LLMs - MEGA, which evaluates models on standard NLP benchmarks, covering 16 NLP datasets across 70 typologically diverse languages. We compare the performance of generative LLMs including Chat-GPT and GPT-4 to State of the Art (SOTA) non-autoregressive models on these tasks to determine how well generative models perform compared to the previous generation of LLMs. We present a thorough analysis of the performance of models across languages and tasks and discuss challenges in improving the performance of generative LLMs on low-resource languages. We create a framework for evaluating generative LLMs in the multilingual setting and provide directions for future progress in the field. 
\end{abstract}


\input{intro}
\input{expts}
\input{results}
\input{challenges}
% \input{discussion}
% \input{v2}
\input{related_work}
\input{conclusion}
\input{limitations}

\section*{Acknowledgments}

The authors would like to thank Barun Patra and Vishrav Chaudhary for their help with TULR evaluation results. We also thank the anonymous reviewers for their helpful feedback, which helped us improve the quality of our paper.




% Entries for the entire Anthology, followed by custom entries
\bibliography{anthology,custom}
\bibliographystyle{acl_natbib}

\appendix

\input{appendix}

\end{document}
