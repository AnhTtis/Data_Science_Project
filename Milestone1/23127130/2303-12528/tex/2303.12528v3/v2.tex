% \section{V2 dump}

% Dump all results, information etc. that does no t fit very clearly into the paper here. We will merge later

% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
% \usepackage{graphicx}
% \begin{table*}[]
% \resizebox{\textwidth}{!}{%
% \begin{tabular}{@{}ccccccccccccc@{}}
% \toprule
%  & \multicolumn{3}{c}{Google}      & \multicolumn{3}{c}{Microsoft}   & \multicolumn{3}{c}{Amazon}      & \multicolumn{3}{c}{GPT Turbo 3.5} \\
%  & Acc & $\Delta_G$\ & $\Delta_S$\ & Acc & $\Delta_G$\ & $\Delta_S$\ & Acc & $\Delta_G$\ & $\Delta_S$\ & Acc  & $\Delta_G$\  & $\Delta_S$\ \\ \midrule
% ES & 50.9          & 23.2 & 20.9 & 45            & 36.5 & 22.9 & 57.2 & 15.3 & 21.7 & \textbf{60.6} & 13.4 & 22.5 \\
% FR & \textbf{61.6} & 6.1  & 22.3 & 44.5          & 34.2 & 15.8 & 54.2 & 16.4 & 15   & 55.3          & 16.6 & 23.4 \\
% IT & 38.6          & 32.9 & 18.6 & 38.8          & 41.8 & 10.5 & 40.2 & 26.8 & 14.7 & \textbf{48.9} & 17.6 & 23.1 \\ \midrule
% RU & 37.8          & 36.7 & 11.4 & 36.9          & 42   & 8.4  & 39.8 & 34.8 & 9.4  & \textbf{40.9} & 32.2 & 12.2 \\
% UK & 38.4          & 43.5 & 10.7 & 41.3          & 46.8 & 11.9 & -    & -    & -    & \textbf{43.1} & 35.4 & 11.3 \\ \midrule
% HE & 50.8          & 11.7 & 35.5 & 44            & 22   & 29.8 & 48   & 13.6 & 45.9 & \textbf{58}   & 8.6  & 35.9 \\
% AR & 45.8          & 42.5 & 16.2 & 45            & 47.1 & 14.2 & 48.3 & 37.8 & 18.8 & \textbf{59.7} & 17.2 & 25.6 \\ \midrule
% DE & 59.4          & 12.5 & 12.6 & \textbf{74.1} & 0    & 8.8  & 62.4 & 12   & 16.7 & 61.5          & 15.4 & 20.8 \\ \bottomrule
% \end{tabular}%
% }
% \caption{Performance of commercial MT systems and LLMs on the WinoMT corpus on all tested languages, categorized by their family: Spanish, French, Italian, Russian, Ukrainian, Hebrew, Arabic, and German. Acc indicates overall gender accuracy (\% of instances the translation had the correct gender), $\Delta_G$ denotes the difference in performance (F1 score) between masculine and feminine scores, and $\Delta_S$ is the difference in performance (F1 score) between pro-stereotypical and anti-stereotypical gender role assignments (higher numbers in the two latter metrics indicate stronger biases). Numbers in bold indicate best accuracy for the language across MT systems (row), and underlined numbers indicate best accuracy for the MT system across languages (column). ∗Amazon Translate does not have a trained model for English to Ukrainian.}
% \label{tab:wino-mt}
% \end{table*}

% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
\begin{table*}[]
\resizebox{\textwidth}{!}{%
\begin{tabular}{ccccccccccccclccccc}
\hline
 &
  \multicolumn{3}{c}{Google} &
  \multicolumn{3}{c}{Microsoft} &
  \multicolumn{3}{c}{Amazon} &
  \multicolumn{3}{c}{Systran} &
  \multicolumn{3}{c}{GPT Turbo 3.5} &
  \multicolumn{3}{c}{Bloomz} \\
 &
  Acc &
  $\Delta_G$\ &
  $\Delta_S$\ &
  Acc &
  $\Delta_G$\ &
  $\Delta_S$\ &
  Acc &
  $\Delta_G$\ &
  $\Delta_S$\ &
  Acc &
  $\Delta_G$\ &
  $\Delta_S$\ &
  \multicolumn{1}{c}{Acc} &
  $\Delta_G$\ &
  $\Delta_S$\ &
  Acc &
  $\Delta_G$\ &
  $\Delta_S$\ \\ \hline
ES &
  50.9 &
  23.2 &
  20.9 &
  45 &
  36.5 &
  22.9 &
  \textbf{57.2} &
  15.3 &
  21.7 &
  42.5 &
  46.2 &
  15.6 &
  54.9 &
  22.7 &
  26.2 &
  55.6 &
  17.2 &
  32.5 \\
FR &
  \textbf{61.6} &
  6.1 &
  22.3 &
  44.5 &
  34.2 &
  15.8 &
  54.2 &
  16.4 &
  15 &
  43.4 &
  41.8 &
  -0.1 &
  52.7 &
  21.4 &
  26.1 &
  52 &
  17.8 &
  24.6 \\
IT &
  38.6 &
  32.9 &
  18.6 &
  38.8 &
  41.8 &
  10.5 &
  40.2 &
  26.8 &
  14.7 &
  38.1 &
  47.3 &
  6.3 &
  45.1 &
  21.9 &
  26.7 &
  \textbf{45.7} &
  9 &
  18.5 \\ \hline
RU &
  37.8 &
  36.7 &
  11.4 &
  36.9 &
  42 &
  8.4 &
  39.8 &
  34.8 &
  9.4 &
  37.3 &
  44.1 &
  9.2 &
  \textbf{41} &
  31.6 &
  10.2 &
  5.9 &
  INV &
  0 \\
UK &
  38.4 &
  43.5 &
  10.7 &
  41.3 &
  46.8 &
  11.9 &
  - &
  - &
  - &
  28.9 &
  22.4 &
  12.9 &
  \textbf{42.9} &
  34.2 &
  12.1 &
  16.8 &
  22.7 &
  2.2 \\ \hline
HE &
  50.8 &
  11.7 &
  35.5 &
  44 &
  22 &
  29.8 &
  48 &
  13.6 &
  45.9 &
  43.1 &
  26.9 &
  23.1 &
  \textbf{57.5} &
  7.6 &
  40.8 &
  27.5 &
  31.4 &
  5 \\
AR &
  45.8 &
  42.5 &
  16.2 &
  45 &
  47.1 &
  14.2 &
  48.3 &
  37.8 &
  18.8 &
  45.6 &
  49.4 &
  -4.1 &
  \textbf{61.1} &
  13.9 &
  27.9 &
  48.1 &
  23 &
  25.6 \\ \hline
DE &
  59.4 &
  12.5 &
  12.6 &
  \textbf{74.1} &
  0 &
  8.8 &
  62.4 &
  12 &
  16.7 &
  48.5 &
  34.5 &
  10 &
  57.5 &
  19.5 &
  14.2 &
  47.6 &
  56.2 &
  6.6 \\ \hline
\end{tabular}%
}
\caption{Performance of commercial MT systems and LLMs on the WinoMT corpus on all tested languages, categorized by their family: Spanish, French, Italian, Russian, Ukrainian, Hebrew, Arabic, and German. Acc indicates overall gender accuracy (\% of instances the translation had the correct gender), $\Delta_G$ denotes the difference in performance (F1 score) between masculine and feminine scores, and $\Delta_S$ is the difference in performance (F1 score) between pro-stereotypical and anti-stereotypical gender role assignments (higher numbers in the two latter metrics indicate stronger biases). Numbers in bold indicate best accuracy for the language across MT systems (row), and underlined numbers indicate best accuracy for the MT system across languages (column). \footnote{For Google, Microsoft, Amazon, and Systran we use the translations provided by XX. Some values differ from the original paper due to updated Spcay modules.} \footnote{Amazon Translate does not have a trained model for English to Ukrainian.} \footnote{For Ru in Bloomz, Precision in male predictions is 0 leading to Invalid (INV) in $\Delta_G$}}
\label{tab:wino-mt}
\end{table*}


% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
% \usepackage{graphicx}
\begin{table*}[]
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}llll@{}}
\toprule
Dataset(s) &
  \multicolumn{2}{c}{Template} &
  Verbalizer \\
 &
  System &
  User &
   \\ \midrule
XNLI, IndicXNLI &
  \begin{tabular}[c]{@{}l@{}}You are an NLP assistant whose purpose is to solve Natural Language Inference (NLI) problems. \\ NLI is the task of determining the inference relation between two (short, ordered) texts: entailment, \\ contradiction, or neutral.  Answer as concisely as possible in the same format as the examples below:\end{tabular} &
  \textbackslash{}texttt\{\{premise\}\}\textbackslash{}nQuestion: \{hypothesis\} True, False, or Neither? &
  \begin{tabular}[c]{@{}l@{}}Entailment : True, \\ Contradiction: False,\\ Neutral: Neither\end{tabular} \\
PAWS-X &
  \begin{tabular}[c]{@{}l@{}}You are an NLP assistant whose purpose is to perform Paraphrase Identification. The goal of \\ Paraphrase Identification is to  determine whether a pair of sentences have the same meaning. \\ Answer as concisely as possible in the same format as the examples below:\end{tabular} &
  \{sentence1\} Question: \{sentence2\} True or False? &
  - \\
XCOPA &
  \begin{tabular}[c]{@{}l@{}}You are an AI assistant whose purpose is to perform open-domain commonsense causal reasoning. \\ You will be provided a premise and two alternatives, where the task is to select the alternative that more \\ plausibly has a causal relation with the premise. Answer as concisely as possible in the same format as\\  the examples below:\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}\{ premise \} \\ \{\% if question == "cause" \%\} This happened because... \\ \{\% else \%\} As a consequence... \{\% endif \%\} \\ Help me pick the more plausible option: - \{choice1\} - \{choice2\}\end{tabular} &
  - \\
\begin{tabular}[c]{@{}l@{}}XQUAD, TyDiQA,\\ MLQA, IndicQA\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}You are an NLP assistant whose purpose is to solve reading comprehension problems. \\ You will be provided questions on a set of passages and you will need to provide the answer as it\\  appears in the passage. The answer should be in the same language as the question and the passage.\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}\{context\} Q: \{question\}Referring to the passage above, \\ the correct answer to the given question is: \{answer\}\end{tabular} &
  - \\
XStoryCloze &
  - &
  \begin{tabular}[c]{@{}l@{}}\{input\_sentence\_1\} \{input\_sentence\_2\} \{input\_sentence\_3\} \{input\_sentence\_4\}\\ What is a possible continuation for the story given the following options ?\\ Option1: \{sentence\_quiz1\}\textbackslash{}n-Option2: \{sentence\_quiz2\}\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}\{sentence\_quiz1\}: Option1, \\ \{sentence\_quiz2\}: Option2\end{tabular} \\
PANX &
  \begin{tabular}[c]{@{}l@{}}You are an NLP assistant whose purpose is to perform Named Entity Recognition (NER). \\ NER involves identifying and classifying named entities in a text into predefined categories such as \\ person names, organizations, locations, and others. You will need to use the tags defined below:\\ \textbackslash{}nO means the word doesn’t correspond to any entity.\textbackslash{}nB-PER/I-PER means the word corresponds \\ to the beginning of/is inside a person entity.\textbackslash{}nB-ORG/I-ORG means the word corresponds to the \\ beginning of/is inside an organization entity.\textbackslash{}nB-LOC/I-LOC means the word corresponds to the\\  beginning of/is inside a location entity.\textbackslash{}nDo not try to answer the question! Just tag each token in the sentence.\end{tabular} &
  \{token\_1 token\_2 ... token\_n\} &
  \begin{tabular}[c]{@{}l@{}}\{tag\_1\} \{tag\_2\} ... \{tag\_n\}: \\ \{token\_1\}\_\{tag\_1\} \{token\_2\}\_\{tag\_2\}\\  ... \{token\_n\}\_\{tag\_n\}\end{tabular} \\
UDPOS &
  \begin{tabular}[c]{@{}l@{}}You are an NLP assistant whose purpose is to perform Part of Speech (PoS) Tagging. PoS tagging is the \\ process of marking up a word in a text (corpus) as corresponding to a particular part of speech, based on\\  both its definition and its context. You will need to use the tags defined below:\end{tabular} &
  \{token\_1 token\_2 ... token\_n\} &
  \begin{tabular}[c]{@{}l@{}}\{tag\_1\} \{tag\_2\} ... \{tag\_n\}: \\ \{token\_1\}\_\{tag\_1\} \{token\_2\}\_\{tag\_2\} ... \\ \{token\_n\}\_\{tag\_n\}\end{tabular} \\
GLUECoS &
  \begin{tabular}[c]{@{}l@{}}You are an NLP assistant whose purpose is to solve Sentiment Analysis problems. Sentiment Analysis \\ is the task of determining whether the sentiment, opinion or emotion expressed in a textual data is: \\ positive, negative, or neutral. Answer as concisely as possible in the same format as the examples below:\end{tabular} &
  Does the following sentence have a positive, negative or neutral sentiment? \{text\} &
  - \\
XLSum &
  \begin{tabular}[c]{@{}l@{}}You are an NLP assistant whose purpose is to summarize any given article. You should summarize all \\ important information concisely in the same language in which you have been provided the document. \\ Following the examples provided below:\end{tabular} &
  \begin{tabular}[c]{@{}l@{}}\{document\} \\ === \\ Write a summary of the text above :\end{tabular} &
  - \\
WikiANN &
   &
   &
   \\
HONEST &
   &
   &
   \\
Jigsaw &
   &
   &
   \\
WinoMT &
   &
   &
   \\ \bottomrule
\end{tabular}%
}
\caption{Prompt type and prompt used for each dataset.}
\label{tab:prompt_template}
\end{table*}