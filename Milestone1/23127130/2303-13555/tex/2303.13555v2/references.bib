@inbook{RASMUNSON2014, 
place={Cambridge},
title={Introduction},
DOI={10.1017/CBO9781107279124.002},
booktitle={Mathematical Modeling in Chemical Engineering},
publisher={Cambridge University Press},
author={Rasmuson, Anders and Andersson, Bengt and Olsson, Louise and Andersson, Ronnie}, year={2014}, pages={1–9}}


@article{FEYO1997,
   abstract = {This paper addresses attitudes and forms of process modelling in biochemical engineering. Baker's yeast production in a fed-batch fermenter, at laboratory scale, is employed as case-study. Three modelling approaches are described and compared, viz. - the conventional mechanistic approach, formulations based on different artificial neural network (ANN) topologies and a hybrid mechanistic-ANN structure. A standard 2-step procedure of model development, estimation (training) and validation with two independent sets of experiments, has been carried out. The mechanistic model, using reaction kinetic schemes from the literature, fine tuned by classical non-linear regression, gave smooth predictions for the validation data runs, but showed limited ability in predicting the test data.. The ANN were able to describe experiments at the training stage, but failed the validation (i.e. extrapolation) procedure, giving oscillatory predictions of the process state. Additionally, this approach suffers from a strong influence of the net parameters, which must be chosen by trial and error. The hybrid model predictions are good with the training and very satisfactory with the experimental test data. The indication is that the latter is a powerful tool for process modelling in biochemical engineering, particularly when limited theoretical knowledge of the process is available.},
   author = {S. Feyo De Azevedo and B. Dahm and F. R. Oliveira},
   doi = {10.1016/s0098-1354(97)87593-x},
   issn = {00981354},
   issue = {SUPPL.1},
   journal = {Computers and Chemical Engineering},
   title = {Hybrid modelling of biochemical processes: A comparison with the conventional approach},
   volume = {21},
   year = {1997},
}

@article{Laura2020,
   abstract = {In this paper, we describe the combination of machine learning and simulation towards a hybrid modelling approach. Such a combination of data-based and knowledge-based modelling is motivated by applications that are partly based on causal relationships, while other effects result from hidden dependencies that are represented in huge amounts of data. Our aim is to bridge the knowledge gap between the two individual communities from machine learning and simulation to promote the development of hybrid systems. We present a conceptual framework that helps to identify potential combined approaches and employ it to give a structured overview of different types of combinations using exemplary approaches of simulation-assisted machine learning and machine-learning assisted simulation. We also discuss an advanced pairing in the context of Industry 4.0 where we see particular further potential for hybrid systems.},
   author = {Laura von Rueden and Sebastian Mayer and Rafet Sifa and Christian Bauckhage and Jochen Garcke},
   doi = {10.1007/978-3-030-44584-3_43},
   isbn = {9783030445836},
   issn = {16113349},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   keywords = {Hybrid approaches,Machine learning,Simulation},
   pages = {548-560},
   title = {Combining Machine Learning and Simulation to a Hybrid Modelling Approach: Current and Future Directions},
   volume = {12080 LNCS},
   year = {2020},
}

@article{Pan2022,
   abstract = {Recent advances in machine learning, coupled with low-cost computation, availability of cheap streaming sensors, data storage and cloud technologies, has led to widespread multi-disciplinary research activity with significant interest and investment from commercial stakeholders. Mechanistic models, based on physical equations, and purely data-driven statistical approaches represent two ends of the modelling spectrum. New hybrid, data-centric engineering approaches, leveraging the best of both worlds and integrating both simulations and data, are emerging as a powerful tool with a transformative impact on the physical disciplines. We review the key research trends and application scenarios in the emerging field of integrating simulations, machine learning, and statistics. We highlight the opportunities that such an integrated vision can unlock and outline the key challenges holding back its realisation. We also discuss the bottlenecks in the translational aspects of the field and the long-term upskilling requirements for the existing workforce and future university graduates.},
   author = {Indranil Pan and Lachlan R. Mason and Omar K. Matar},
   doi = {10.1016/j.ces.2021.117271},
   issn = {00092509},
   journal = {Chemical Engineering Science},
   pages = {117271},
   publisher = {Elsevier Ltd},
   title = {Data-centric Engineering: integrating simulation, machine learning and statistics. Challenges and opportunities},
   volume = {249},
   year = {2022},
}

@article{Sansana2021,
   abstract = {The chemical processing industry has relied on modeling techniques for process monitoring, control, diagnosis, optimization, and design, especially since the third industrial revolution and the emergence of Process Systems Engineering. The fourth industrial revolution, connected to massive digitization, made it possible to collect and process large volumes of data triggering the development of data-driven frameworks for knowledge extraction. However, one must not leave behind the successful solutions developed over decades based on first principle mechanistic modeling approaches. At present, both industry and researchers are realizing the need for new ways to incorporate process and phenomenological knowledge in big data and machine learning frameworks, leading to more robust and intelligible artificial intelligence solutions, capable of assisting the target stakeholders in their activities and decision processes. In this article, we review hybrid modeling techniques, associated system identification methodologies and model assessment criteria. Applications in chemical and biochemical processes are also referred.},
   author = {Joel Sansana and Mark N. Joswiak and Ivan Castillo and Zhenyu Wang and Ricardo Rendall and Leo H. Chiang and Marco S. Reis},
   doi = {10.1016/j.compchemeng.2021.107365},
   issn = {00981354},
   journal = {Computers and Chemical Engineering},
   keywords = {Gray-box modeling,Hybrid modeling,Industrial process data analytics,Metamodeling,Physics-informed machine learning,Semi-parametric modeling},
   month = {8},
   publisher = {Elsevier Ltd},
   title = {Recent trends on hybrid modeling for Industry 4.0},
   volume = {151},
   year = {2021},
}

@article{moritz2014,
   abstract = {Hybrid semi-parametric models consist of model structures that combine parametric and nonparametric submodels based on different knowledge sources. The development of a hybrid semi-parametric model can offer several advantages over traditional mechanistic or data-driven modeling, as reviewed in this paper. These advantages, such as broader knowledge base, transparency of the modeling approach and cost-effective model development, have been widely recognized, not only in academia but also in the industry.In this paper, the most common hybrid semi-parametric modeling and parameter identification techniques are revisited. Applications in the areas of (bio)chemical engineering for process monitoring, control, optimization, scale-up and model-reduction are reviewed. It is outlined that the application of hybrid semi-parametric techniques does not automatically lead into better results but that rational knowledge integration has potential to significantly improve model-based process operation and design. © 2013 Elsevier Ltd.},
   author = {Moritz von Stosch and Rui Oliveira and Joana Peres and Sebastião Feyo de Azevedo},
   doi = {10.1016/j.compchemeng.2013.08.008},
   issn = {00981354},
   journal = {Computers and Chemical Engineering},
   keywords = {Hybrid grey-box modeling,Hybrid modeling,Hybrid neural modeling,Hybrid semi-parametric modeling,Process operation/design,Semi-mechanistic modeling},
   pages = {86-101},
   publisher = {Elsevier Ltd},
   title = {Hybrid semi-parametric modeling in process systems engineering: Past, present and future},
   volume = {60},
   year = {2014},
}

@article{Rackauckas2020,
   abstract = {In the context of science, the well-known adage "a picture is worth a thousand words" might well be "a model is worth a thousand datasets." In this manuscript we introduce the SciML software ecosystem as a tool for mixing the information of physical laws and scientific models with data-driven machine learning approaches. We describe a mathematical object, which we denote universal differential equations (UDEs), as the unifying framework connecting the ecosystem. We show how a wide variety of applications, from automatically discovering biological mechanisms to solving high-dimensional Hamilton-Jacobi-Bellman equations, can be phrased and efficiently handled through the UDE formalism and its tooling. We demonstrate the generality of the software tooling to handle stochasticity, delays, and implicit constraints. This funnels the wide variety of SciML applications into a core set of training mechanisms which are highly optimized, stabilized for stiff equations, and compatible with distributed parallelism and GPU accelerators.},
   author = {Christopher Rackauckas and Yingbo Ma and Julius Martensen and Collin Warner and Kirill Zubov and Rohit Supekar and Dominic Skinner and Ali Ramadhan and Alan Edelman},
   issn = {2331-8422},
   month = {1},
   pages = {1-55},
   title = {Universal Differential Equations for Scientific Machine Learning},
   url = {http://arxiv.org/abs/2001.04385},
   year = {2020},
}

@article{Zander1999,
   abstract = {A common problem in kinetic modeling of complex chemical reactions is that a rigorous description of the reaction system, e.g., based on elementary reactions, is not possible. This is because either the reaction involves too many reactions and intermediates or the reaction mechanism is not known in sufficient detail. Alternative data-driven modeling, e.g., using neural networks, normally demands large amounts of experimental data and has poor generalization capability. In such situations a combined physical and data-driven (i.e. hybrid) model may be attractive, that utilizes the specific advantages of both approaches while avoiding their disadvantages. This paper explains the procedure of hybrid modeling of integral (i.e. time-dependent) data by using examples from chemical kinetics. The benefits of the hybrid models are described in comparison to the limiting cases of purely physical and purely data-driven models. In general, the hybrid model surpasses the purely physical and neural network models in terms of a combined interpolation- and extrapolation-range criterion.},
   author = {Hans Jörg Zander and Roland Dittmeyer and Josef Wagenliuber},
   doi = {10.1002/(SICI)1521-4125(199907)22:7<571::AID-CEAT571>3.0.CO;2-5},
   issn = {09307516},
   issue = {7},
   journal = {Chemical Engineering and Technology},
   title = {Dynamic modeling of chemical reaction systems with neural networks and hybrid models},
   volume = {22},
   year = {1999},
}

@article{Raissi2019,
   abstract = {We introduce physics-informed neural networks – neural networks that are trained to solve supervised learning tasks while respecting any given laws of physics described by general nonlinear partial differential equations. In this work, we present our developments in the context of solving two main classes of problems: data-driven solution and data-driven discovery of partial differential equations. Depending on the nature and arrangement of the available data, we devise two distinct types of algorithms, namely continuous time and discrete time models. The first type of models forms a new family of data-efficient spatio-temporal function approximators, while the latter type allows the use of arbitrarily accurate implicit Runge–Kutta time stepping schemes with unlimited number of stages. The effectiveness of the proposed framework is demonstrated through a collection of classical problems in fluids, quantum mechanics, reaction–diffusion systems, and the propagation of nonlinear shallow-water waves.},
   author = {M. Raissi and P. Perdikaris and G. E. Karniadakis},
   doi = {10.1016/j.jcp.2018.10.045},
   issn = {10902716},
   journal = {Journal of Computational Physics},
   pages = {686-707},
   publisher = {Elsevier Inc.},
   title = {Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations},
   volume = {378},
   year = {2019},
}

@article{Narayanan2021,
   abstract = {The biopharmaceutical industries are continuously faced with the pressure to reduce the development costs and accelerate development time scales. The traditional approach of heuristic-based or platform process-based optimization is soon getting obsolete, and more generalized tools for process development and optimization are required to keep pace with the emerging trends. Thus, advanced model-based methods that can reduce the can ensure accelerated development of robust processes with minimal experiments are necessary. Though mechanistic models for chromatography are quite popular, their success is limited by the need to have accurate knowledge of adsorption isotherms and mass transfer kinetics. As an alternative, in this work, a hybrid modeling approach is proposed. Thereby, the chromatographic unit behavior is learned by a combination of neural network and mechanistic model while fitting suitable experimental breakthrough curves. Since this approach does not require identifying suitable mechanistic assumptions for all the phenomena, it can be developed with lower effort. Thus, allowing the scientists to concentrate their focus on process development. The performance of the hybrid model is compared with the mechanistic Lumped kinetic Model for in-silico data and experiments conducted on a system of industrial relevance. The flexibility of the hybrid modeling approach results in about three times higher accuracies compared to Lumped Kinetic Model. This is validated for five different isotherm models used to simulate data, with the hybrid model showing about two to three times lower prediction errors in all the cases. Not only in prediction, but we could also show that the hybrid model is more robust in extrapolating across process conditions with about three times lower error than the LKM. Additionally, it could be demonstrated that an appropriately tailored formulation of the hybrid model can be used to generate representations for the underlying principles such as adsorption equilibria and mass transfer kinetics.},
   author = {Harini Narayanan and Tobias Seidler and Martin Francisco Luna and Michael Sokolov and Massimo Morbidelli and Alessandro Butté},
   doi = {10.1016/j.chroma.2021.462248},
   issn = {18733778},
   journal = {Journal of Chromatography A},
   pages = {462248},
   pmid = {34087519},
   publisher = {Elsevier B.V.},
   title = {Hybrid Models for the simulation and prediction of chromatographic processes for protein capture},
   volume = {1650},
   year = {2021},
}

@article{Narayanan2021B,
   author = {Harini Narayanan and Martin Luna and Michael Sokolov and Paolo Arosio and Alessandro Butté and Massimo Morbidelli},
   doi = {10.1021/acs.iecr.1c01317},
   issn = {0888-5885},
   journal = {Industrial \& Engineering Chemistry Research},
   month = {7},
   pages = {acs.iecr.1c01317},
   title = {Hybrid Models Based on Machine Learning and an Increasing Degree of Process Knowledge: Application to Capture Chromatographic Step},
   year = {2021},
}

@misc{Moriconi2019,
  doi = {10.48550/ARXIV.1902.10675},
  
  url = {https://arxiv.org/abs/1902.10675},
  
  author = {Moriconi, Riccardo and Deisenroth, Marc P. and Kumar, K. S. Sesh},
  
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {High-dimensional Bayesian optimization using low-dimensional feature spaces},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{Frazier2018,
  doi = {10.48550/ARXIV.1807.02811},
  
  url = {https://arxiv.org/abs/1807.02811},
  
  author = {Frazier, Peter I.},
  
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), Optimization and Control (math.OC), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Mathematics, FOS: Mathematics},
  
  title = {A Tutorial on Bayesian Optimization},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@report{,
   abstract = {Bayesian optimization (BO) is a powerful paradigm for efficient optimization of black-box objective functions. High-dimensional BO presents a particular challenge, in part because the curse of dimensionality makes it difficult to define-as well as do inference over-a suitable class of surrogate models. We argue that Gaussian process surrogate models defined on sparse axis-aligned subspaces offer an attractive compromise between flexibility and parsimony. We demonstrate that our approach , which relies on Hamiltonian Monte Carlo for inference, can rapidly identify sparse subspaces relevant to modeling the unknown objective function , enabling sample-efficient high-dimensional BO. In an extensive suite of experiments comparing to existing methods for high-dimensional BO we demonstrate that our algorithm, Sparse Axis-Aligned Subspace BO (SAASBO), achieves excellent performance on several synthetic and real-world problems without the need to set problem-specific hyperparameters.},
   author = {David Eriksson and Martin Jankowiak},
   title = {High-Dimensional Bayesian Optimization with Sparse Axis-Aligned Subspaces},
}

@inproceedings{Kingma2015,
   abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
   author = {Diederik P. Kingma and Jimmy Lei Ba},
   journal = {3rd International Conference on Learning Representations, ICLR 2015 - Conference Track Proceedings},
   title = {Adam: A method for stochastic optimization},
   year = {2015},
}

@article{Nogueira2022,
   abstract = {Abstract Universal Differential Equations (UODE) are a concept from Scientific Machine Learning that leverages the potential of the universal approximator theorem and the physical knowledge of a given system. Creating this level of hybridization within a stiff Partial Differential Equation system is a challenge. On the other hand, adsorption phenomenological models have sink/source terms that describe the adsorption equilibrium through a well-known simplified model (e.g., Langmuir, Sips, BET). These suitable mechanistic assumptions are identified through experiments, providing the parameters of the sink/source model. However, these mechanistic assumptions are a simplification of the system phenomenology. Therefore, the resulting model is limited by its premises. In this scenario, the UODE is presented as an approach that conciliates the potential of Artificial Neural Networks to learn given phenomena without conceptual simplifications. On the other hand, keeping into consideration the system physics. This work proposes a UODE system to solve the multicomponent separation by adsorption in a fixed bed column. Experimental data is used to identify the hybrid model. The required amount of data used in the model identification demonstrates that hybrid models can use a few data points to precisely describe the system. Furthermore, the obtained model can describe competitive adsorption with higher precision than the Langmuir model. This article is protected by copyright. All rights reserved.},
   author = {Idelfonso B. R. Nogueira and Vinicius V. Santana and Ana M. Ribeiro and Alírio E. Rodrigues},
   doi = {10.1002/CJCE.24495},
   issn = {1939-019X},
   journal = {The Canadian Journal of Chemical Engineering},
   keywords = {hybrid modelling,multicomponent adsorption,scientific machine learning,universal differential equations},
   month = {7},
   publisher = {John Wiley & Sons, Ltd},
   title = {Using scientific machine learning to develop universal differential equation for multicomponent adsorption separation systems},
   url = {https://onlinelibrary.wiley.com/doi/full/10.1002/cjce.24495 https://onlinelibrary.wiley.com/doi/abs/10.1002/cjce.24495 https://onlinelibrary.wiley.com/doi/10.1002/cjce.24495},
   year = {2022},
}



@inproceedings{Glorot2010,
   abstract = {Whereas before 2006 it appears that deep multilayer neural networks were not successfully trained, since then several algorithms have been shown to successfully train them, with experimental results showing the superiority of deeper vs less deep architectures. All these experimental results were obtained with new initialization or training mechanisms. Our objective here is to understand better why standard gradient descent from random initialization is doing so poorly with deep neural networks, to better understand these recent relative successes and help design better algorithms in the future. We first observe the influence of the non-linear activations functions. We find that the logistic sigmoid activation is unsuited for deep networks with random initialization because of its mean value, which can drive especially the top hidden layer into saturation. Surprisingly, we find that saturated units can move out of saturation by themselves, albeit slowly, and explaining the plateaus sometimes seen when training neural networks. We find that a new non-linearity that saturates less can often be beneficial. Finally, we study how activations and gradients vary across layers and during training, with the idea that training may be more difficult when the singular values of the Jacobian associated with each layer are far from 1. Based on these considerations, we propose a new initialization scheme that brings substantially faster convergence. Copyright 2010 by the authors.},
   author = {Xavier Glorot and Yoshua Bengio},
   issn = {15324435},
   journal = {Journal of Machine Learning Research},
   title = {Understanding the difficulty of training deep feedforward neural networks},
   volume = {9},
   year = {2010},
}

@article{Ma2021,
   abstract = {Derivatives of differential equation solutions are commonly for parameter estimation, fitting neural differential equations, and as model diagnostics. However, with a litany of choices and a Cartesian product of potential methods, it can be difficult for practitioners to understand which method is likely to be the most effective on their particular application. In this manuscript we investigate the performance characteristics of Discrete Local Sensitivity Analysis implemented via Automatic Differentiation (DSAAD) against continuous adjoint sensitivity analysis. Non-stiff and stiff biological and pharmacometric models, including a PDE discretization, are used to quantify the performance of sensitivity analysis methods. Our benchmarks show that on small stiff and non-stiff systems of ODEs (approximately < 100 parameters+ODEs), forward-mode DSAAD is more efficient than both reverse-mode and continuous forward/adjoint sensitivity analysis. The scalability of continuous adjoint methods is shown to be more efficient than discrete adjoints and forward methods after crossing this size range. These comparative studies demonstrate a trade-off between memory usage and performance in the continuous adjoint methods that should be considered when choosing the technique, while numerically unstable backsolve techniques from the machine learning literature are demonstrated as unsuitable for most scientific models. The performance of adjoint methods is shown to be heavily tied to the reverse-mode AD method used for the vector-Jacobian product calculations, with tape-based AD methods shown to be 2 orders of magnitude slower on nonlinear partial differential equations than static AD techniques. In addition, these results demonstrate the out-of-The-box applicability of DSAAD to differential-Algebraic equations, delay differential equations, and hybrid differential equation systems where the event timing and effects are dependent on model parameters, showcasing an ease of implementation advantage for DSAAD approaches. Together, these benchmarks provide a guide to help practitioners to quickly identify the best mixture of continuous sensitivities and automatic differentiation for their applications.},
   author = {Yingbo Ma and Vaibhav Dixit and Michael J. Innes and Xingjian Guo and Chris Rackauckas},
   doi = {10.1109/HPEC49654.2021.9622796},
   isbn = {9781665423694},
   issue = {2},
   journal = {2021 IEEE High Performance Extreme Computing Conference, HPEC 2021},
   title = {A Comparison of Automatic Differentiation and Continuous Sensitivity Analysis for Derivatives of Differential Equation Solutions},
   year = {2021},
}



@article{Li2018,
   abstract = {Modelling dynamic adsorption of sulfur dioxide (SO2) on activated carbons (ACs) is significant in guiding practical desulphurization processes and making highly efficient use of adsorbents in terms of the adsorption rate which largely depends on particle size. In this work, models derived from the Vermeulen and an improved linear driving force (LDF) rate equation were studied for the first time on SO2 adsorption over AC particles with different sizes. For larger particles (≥3 mm), breakthrough curves predicted by the Vermeulen equation showed good agreement with experimental data, demonstrating that intraparticle diffusion resistance varied with particle size, feed concentration, adsorption time and location. For smaller particles (1 mm), a correction on the volume-averaged adsorption capacity as a function of adsorption time and saturation in the rate equation was developed to avoid the underestimation of adsorption rate due to the inappropriate parabolic concentration profile inherent in the conventional LDF model. By providing a concentration gradient and adsorption rate closer to actual values, the improved LDF equation was confirmed to provide excellent prediction results on 1-mm particles. Different modelling characteristics of the two models indicates varying effects of intraparticle diffusion on adsorption rate with particle size regarding the specificity of SO2 physisorption on ACs.},
   author = {Ziyi Li and Yingshu Liu and Haihong Wang and Chuen Jinn Tsai and Xiong Yang and Yi Xing and Chuanzhao Zhang and Penny Xiao and Paul A. Webley},
   doi = {10.1016/j.cej.2018.07.119},
   issn = {13858947},
   issue = {July},
   journal = {Chemical Engineering Journal},
   keywords = {Activated carbons,Adsorption,Breakthrough curve modelling,Intraparticle diffusion,Sulfur dioxide},
   pages = {858-866},
   publisher = {Elsevier},
   title = {A numerical modelling study of SO2 adsorption on activated carbons with new rate equations},
   volume = {353},
   url = {https://doi.org/10.1016/j.cej.2018.07.119},
   year = {2018},
}

@article{Praditia2021,
   abstract = {Data-driven modeling of spatiotemporal physical processes with general deep learning methods is a highly challenging task. It is further exacerbated by the limited availability of data, leading to poor generalizations in standard neural network models. To tackle this issue, we introduce a new approach called the Finite Volume Neural Network (FINN). The FINN method adopts the numerical structure of the well-known Finite Volume Method for handling partial differential equations, so that each quantity of interest follows its own adaptable conservation law, while it concurrently accommodates learnable parameters. As a result, FINN enables better handling of fluxes between control volumes and therefore proper treatment of different types of numerical boundary conditions. We demonstrate the effectiveness of our approach with a subsurface contaminant transport problem, which is governed by a non-linear diffusion-sorption process. FINN does not only generalize better to differing boundary conditions compared to other methods, it is also capable to explicitly extract and learn the constitutive relationships (expressed by the retardation factor). More importantly, FINN shows excellent generalization ability when applied to both synthetic datasets and real, sparse experimental data, thus underlining its relevance as a data-driven modeling tool.},
   author = {Timothy Praditia and Matthias Karlbauer and Sebastian Otte and Sergey Oladyshkin and Martin V. Butz and Wolfgang Nowak},
   month = {4},
   title = {Finite Volume Neural Network: Modeling Subsurface Contaminant Transport},
   url = {http://arxiv.org/abs/2104.06010},
   year = {2021},
}

@book{Minceva2015,
   author = {M. Minceva and A. Ribeiro and M. Silva and A.M. Ribeiro and A.E. Rodrigues and N. Graça and J.C. Santos and C. Pereira and L.S. Pais},
   doi = {10.1016/b978-0-12-802024-1.00001-x},
   isbn = {9780128020241},
   journal = {Simulated Moving Bed Technology},
   pages = {1-30},
   title = {Principles of Simulated Moving Bed},
   year = {2015},
}

@article{rackauckas2017differentialequations,
  title={Differentialequations.jl--a performant and feature-rich ecosystem for solving differential equations in julia},
  author={Rackauckas, Christopher and Nie, Qing},
  journal={Journal of Open Research Software},
  volume={5},
  number={1},
  year={2017},
  publisher={Ubiquity Press}
}

@article{Finlayson1974,
   abstract = {The method of orthogonal collocation on finite elements is described for solution of ordinary and partial differential equations. Benefits and limitations of the method are outlined by comparison with Galerkin finite element methods. Practical difficulties are given which arise in the application to engineering problems. Areas for future research are suggested. © 1980.},
   author = {Bruce A. Finlayson},
   doi = {10.1016/0378-4754(80)90097-X},
   issn = {03784754},
   issue = {1},
   journal = {Chemical Engineering Science},
   pages = {587-596},
   title = {ORTHOGONAL COLLOCATION ON FINITE ELEMENTS},
   volume = {30},
   year = {1974},
}


@article{MA1991415,
title = {Application of orthogonal collocation on finite elements in the simulation of non-linear chromatography},
journal = {Computers \& Chemical Engineering},
volume = {15},
number = {6},
pages = {415-426},
year = {1991},
issn = {0098-1354},
doi = {https://doi.org/10.1016/0098-1354(91)87019-6},
url = {https://www.sciencedirect.com/science/article/pii/0098135491870196},
author = {Z. Ma and G. Guiochon},
abstract = {Orthogonal collocation on finite elements permits the calculation of the chromatographic elution band profiles for one or two components. The individua band profiles obtained for binary mixtures are more accurate than those derived using one of several possible finite difference methods. In most cases, the difference between these profiles is small when the column efficiency is high or the mass transfers between phases in the column are fast. When the concentration of the second eluted component is low compared to the concentration of the first one, however, the front of the second component band is much steeper than predicted by the finite difference method, in agreement with the result of the finite element calculation procedure. The advantage of the better accuracy is compensated by a considerably higher computation time.}
}

@article{Ganaie2014,
   abstract = {Cubic Hermite collocation method is proposed to solve two point linear and nonlinear boundary value problems subject to Dirichlet, Neumann, and Robin conditions. Using several examples, it is shown that the scheme achieves the order of convergence as four, which is superior to various well known methods like finite difference method, finite volume method, orthogonal collocation method, and polynomial and nonpolynomial splines and B-spline method. Numerical results for both linear and nonlinear cases are presented to demonstrate the effectiveness of the scheme.},
   author = {Ishfaq Ahmad Ganaie and Shelly Arora and V. K. Kukreja},
   doi = {10.1155/2014/365209},
   issn = {2356-7007},
   journal = {International Journal of Engineering Mathematics},
   month = {2},
   pages = {1-8},
   publisher = {Hindawi Limited},
   title = {Cubic Hermite Collocation Method for Solving Boundary Value Problems with Dirichlet, Neumann, and Robin Conditions},
   volume = {2014},
   year = {2014},
}

@article{Poyton2006,
   abstract = {Principal differential analysis (PDA) is an alternative parameter estimation technique for differential equation models in which basis functions (e.g., B-splines) are fitted to dynamic data. Derivatives of the resulting empirical expressions are used to avoid solving differential equations when estimating parameters. Benefits and shortcomings of PDA were examined using a simple continuous stirred-tank reactor (CSTR) model. Although PDA required considerably less computational effort than traditional nonlinear regression, parameter estimates from PDA were less precise. Sparse and noisy data resulted in poor spline fits and misleading derivative information, leading to poor parameter estimates. These problems are addressed by a new iterative algorithm (iPDA) in which the spline fits are improved using model-based penalties. Parameter estimates from iPDA were unbiased and more precise than those from standard PDA. Issues that need to be resolved before iPDA can be used for more complex models are discussed. © 2005 Elsevier Ltd. All rights reserved.},
   author = {A. A. Poyton and M. S. Varziri and K. B. McAuley and P. J. McLellan and J. O. Ramsay},
   doi = {10.1016/j.compchemeng.2005.11.008},
   issn = {00981354},
   issue = {4},
   journal = {Computers and Chemical Engineering},
   keywords = {Dynamic models,Parameter estimation,Principal differential analysis},
   month = {2},
   pages = {698-708},
   title = {Parameter estimation in continuous-time dynamic models using principal differential analysis},
   volume = {30},
   year = {2006},
}




@article{Li2005,
    author = {Li, Zhengfeng and Osborne, Michael R. and Prvan, Tania},
    title = "{Parameter estimation of ordinary differential equations}",
    journal = {IMA Journal of Numerical Analysis},
    volume = {25},
    number = {2},
    pages = {264-285},
    year = {2005},
    month = {04},
    abstract = "{This paper addresses the development of a new algorithm for parameter estimation of ordinary differential equations. Here, we show that (1) the simultaneous approach combined with orthogonal cyclic reduction can be used to reduce the estimation problem to an optimization problem subject to a fixed number of equality constraints without the need for structural information to devise a stable embedding in the case of non-trivial dichotomy and (2) the Newton approximation of the Hessian information of the Lagrangian function of the estimation problem should be used in cases where hypothesized models are incorrect or only a limited amount of sample data is available. A new algorithm is proposed which includes the use of the sequential quadratic programming (SQP) Gauss–Newton approximation but also encompasses the SQP Newton approximation along with tests of when to use this approximation. This composite approach relaxes the restrictions on the SQP Gauss–Newton approximation that the hypothesized model should be correct and the sample data set large enough. This new algorithm has been tested on two standard problems.}",
    issn = {0272-4979},
    doi = {10.1093/imanum/drh016},
    url = {https://doi.org/10.1093/imanum/drh016},
    eprint = {https://academic.oup.com/imajna/article-pdf/25/2/264/2090211/drh016.pdf},
}


@report{Nocedal2006,
   author = {Jorge Nocedal and Stephen J Wright},
   isbn = {2006923897},
   title = {Numerical Optimization Second Edition},
   year = {2006},
}


@article{Dandekar2020,
   abstract = {Recently, Neural Ordinary Differential Equations has emerged as a powerful framework for modeling physical simulations without explicitly defining the ODEs governing the system, but instead learning them via machine learning. However, the question: "Can Bayesian learning frameworks be integrated with Neural ODE's to robustly quantify the uncertainty in the weights of a Neural ODE?" remains unanswered. In an effort to address this question, we primarily evaluate the following categories of inference methods: (a) The No-U-Turn MCMC sampler (NUTS), (b) Stochastic Gradient Hamiltonian Monte Carlo (SGHMC) and (c) Stochastic Langevin Gradient Descent (SGLD). We demonstrate the successful integration of Neural ODEs with the above Bayesian inference frameworks on classical physical systems, as well as on standard machine learning datasets like MNIST, using GPU acceleration. On the MNIST dataset, we achieve a posterior sample accuracy of 98.5\% on the test ensemble of 10,000 images. Subsequently, for the first time, we demonstrate the successful integration of variational inference with normalizing flows and Neural ODEs, leading to a powerful Bayesian Neural ODE object. Finally, considering a predator-prey model and an epidemiological system, we demonstrate the probabilistic identification of model specification in partially-described dynamical systems using universal ordinary differential equations. Together, this gives a scientific machine learning tool for probabilistic estimation of epistemic uncertainties.},
   author = {Raj Dandekar and Karen Chung and Vaibhav Dixit and Mohamed Tarek and Aslan Garcia-Valadez and Krishna Vishal Vemula and Chris Rackauckas},
   pages = {1-20},
   title = {Bayesian Neural Ordinary Differential Equations},
   url = {http://arxiv.org/abs/2012.07244},
   year = {2020},
}


@article{Brunton2016,
   abstract = {Extracting governing equations from data is a central challenge in many diverse areas of science and engineering. Data are abundant whereas models often remain elusive, as in climate science, neuroscience, ecology, finance, and epidemiology, to name only a few examples. In this work, we combine sparsity-promoting techniques and machine learning with nonlinear dynamical systems to discover governing equations from noisy measurement data. The only assumption about the structure of the model is that there are only a few important terms that govern the dynamics, so that the equations are sparse in the space of possible functions; this assumption holds for many physical systems in an appropriate basis. In particular, we use sparse regression to determine the fewest terms in the dynamic governing equations required to accurately represent the data. This results in parsimonious models that balance accuracy with model complexity to avoid overfitting. We demonstrate the algorithm on a wide range of problems, from simple canonical systems, including linear and nonlinear oscillators and the chaotic Lorenz system, to the fluid vortex shedding behind an obstacle. The fluid example illustrates the ability of this method to discover the underlying dynamics of a system that took experts in the community nearly 30 years to resolve. We also show that this method generalizes to parameterized systems and systems that are time-varying or have external forcing.},
   author = {Steven L. Brunton and Joshua L. Proctor and J. Nathan Kutz and William Bialek},
   doi = {10.1073/pnas.1517384113},
   issn = {10916490},
   issue = {15},
   journal = {Proceedings of the National Academy of Sciences of the United States of America},
   keywords = {Dynamical systems,Machine learning,Optimization,Sparse regression,System identification},
   pages = {3932-3937},
   publisher = {National Academy of Sciences},
   title = {Discovering governing equations from data by sparse identification of nonlinear dynamical systems},
   volume = {113},
   year = {2016},
}

@software{datadrivendiffeq,
  author       = {JuliusMartensen and
                  Christopher Rackauckas and others},
  title        = {DataDrivenDiffEq.jl},
  month        = jul,
  year         = 2021,
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.5083412},
  url          = {https://doi.org/10.5281/zenodo.5083412}
}


@article{NARAYANAN2022133032,
title = {Functional-Hybrid modeling through automated adaptive symbolic regression for interpretable mathematical expressions},
journal = {Chemical Engineering Journal},
volume = {430},
pages = {133032},
year = {2022},
issn = {1385-8947},
doi = {https://doi.org/10.1016/j.cej.2021.133032},
url = {https://www.sciencedirect.com/science/article/pii/S1385894721046088},
author = {Harini Narayanan and Mariano Nicolas {Cruz Bournazou} and Gonzalo {Guillén Gosálbez} and Alessandro Butté},
keywords = {Hybrid models, Symbolic regression, Machine scientist, Interpretability, (bio) chemical processes},
abstract = {Mathematical models used for the representation of (bio)-chemical processes can be grouped into two broad paradigms: white-box or mechanistic models, completely based on knowledgeor black-box data-driven models based on patterns observed in data. However, in the past two-decade, hybrid modeling that explores the synergy between the two paradigms has emerged as a pragmatic compromise. The data-driven part of these has been largely based on conventional machine learning algorithms (e.g., artificial neural network, support vector regression), which prevents interpretability of the finally learnt model by the domain experts. In this work, we present a novel hybrid modeling framework, the Functional-Hybrid model, that uses the ranked domain-specific functional beliefs together with symbolic regression to develop dynamic models. We demonstrate the successful implementation of the Functional-Hybrid model and its interpretability, focusing on applying chemical reaction kinetic principles to classical chemical reactions, biochemistry, ecology, physiology, and a bioreactor. Furthermore, we demonstrate that during interpolation, the Functional-Hybrid model performs similarly to a Hybrid-ANN hybrid model implementing a conventional ANN. However, it provides the advantage of being –to some extent– interpretable, unlike the conventional Hybrid-ANN model. Additionally, it is shown that the Functional-Hybrid model outperforms the Hybrid-ANN model for a very low number of experiments, making it more suitable when data is scarce. Finally, the Functional-Hybrid models show superior extrapolation capabilities compared to the Hybrid-ANN model. This improved performance can be attributed to the structure imposed by the functional transformations introduced in the Functional-Hybrid model.}
}

@article{MCKAY1997981,
title = {Steady-state modelling of chemical process systems using genetic programming},
journal = {Computers \& Chemical Engineering},
volume = {21},
number = {9},
pages = {981-996},
year = {1997},
issn = {0098-1354},
doi = {https://doi.org/10.1016/S0098-1354(96)00329-8},
url = {https://www.sciencedirect.com/science/article/pii/S0098135496003298},
author = {Ben McKay and Mark Willis and Geoffrey Barton},
keywords = {genetic programming, symbolic regression, process modelling},
abstract = {Complex processes are often modelled using input-output data from experimental tests. Regression and neural network modelling techniques are commonly used for this purpose. Unfortunately, these methods provide minimal information about the model structure required to accurately represent process characteristics. In this contribution, we propose the use of Genetic Programming (GP) as a method for developing input-output process models from experimental data. GP performs symbolic regression, determining both the structure and the complexity of the model during its evolution. This has the advantage that no a priori modelling assumptions have to be made. Moreover, the technique can discriminate between relevant and irrelevant process inputs, yielding parsimonious model structures that accurately represent process characteristics. Following a tutorial example, the usefulness of the technique is demonstrated by the development of steady-state models for two typical processes, a vacuum distillation column and a chemical reactor system. A statistical analysis procedure is used to aid in the assessment of GP algorithm settings and to guide in the selection of the final model structure.}
}

@article{Cozad2018,
   abstract = {Symbolic regression methods generate expression trees that simultaneously define the functional form of a regression model and the regression parameter values. As a result, the regression problem can search many nonlinear functional forms using only the specification of simple mathematical operators such as addition, subtraction, multiplication, and division, among others. Currently, state-of-the-art symbolic regression methods leverage genetic algorithms and adaptive programming techniques. Genetic algorithms lack optimality certifications and are typically stochastic in nature. In contrast, we propose an optimization formulation for the rigorous deterministic optimization of the symbolic regression problem. We present a mixed-integer nonlinear programming (MINLP) formulation to solve the symbolic regression problem as well as several alternative models to eliminate redundancies and symmetries. We demonstrate this symbolic regression technique using an array of experiments based upon literature instances. We then use a set of 24 MINLPs from symbolic regression to compare the performance of five local and five global MINLP solvers. Finally, we use larger instances to demonstrate that a portfolio of models provides an effective solution mechanism for problems of the size typically addressed in the symbolic regression literature.},
   author = {Alison Cozad and Nikolaos V. Sahinidis},
   doi = {10.1007/s10107-018-1289-x},
   issn = {14364646},
   issue = {1},
   journal = {Mathematical Programming},
   keywords = {Global optimization,Integer nonlinear optimization,Machine learning,Symbolic regression},
   month = {7},
   pages = {97-119},
   publisher = {Springer Verlag},
   title = {A global MINLP approach to symbolic regression},
   volume = {170},
   year = {2018},
}

@article{Hai2004STUDYOT,
  title={STUDY ON THERMODYNAMICS AND KINETICS OF ADSORPTION OF p-TOLUIDINE FROM AQUEOUS SOLUTION BY HYPERCROSSLINKED POLYMERIC ADSORBENTS},
  author={Wang Hai},
  journal={Environmental Chemistry},
  year={2004}
}

@article{cranmer2020discovering,
      title={Discovering Symbolic Models from Deep Learning with Inductive Biases}, 
      author={Miles Cranmer and Alvaro Sanchez-Gonzalez and Peter Battaglia and Rui Xu and Kyle Cranmer and David Spergel and Shirley Ho},
      journal={NeurIPS 2020},
      year={2020},
      eprint={2006.11287},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@software{pysr,
  author       = {Miles Cranmer},
  title        = {PySR: Fast \& Parallelized Symbolic Regression in Python/Julia},
  month        = sep,
  year         = 2020,
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.4041459},
  url          = {http://doi.org/10.5281/zenodo.4041459}
}
