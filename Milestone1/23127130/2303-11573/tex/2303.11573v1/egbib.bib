@article{hjelm2020representation,
  title={Representation learning with video deep infomax},
  author={Hjelm, R Devon and Bachman, Philip},
  journal={arXiv preprint arXiv:2007.13278},
  year={2020}
}

@book{lucey2007investigating,
  title={Investigating spontaneous facial action recognition through aam representations of the face},
  author={Lucey, Simon and Ashraf, Ahmed Bilal and Cohn, Jeffrey F},
  volume={2},
  year={2007},
  publisher={Citeseer}
}

@article{poh2010non,
  title={Non-contact, automated cardiac pulse measurements using video imaging and blind source separation.},
  author={Poh, Ming-Zher and McDuff, Daniel J and Picard, Rosalind W},
  journal={Optics express},
  volume={18},
  number={10},
  pages={10762--10774},
  year={2010},
  publisher={Optica Publishing Group}
}

@inproceedings{contractor2022behavioral,
  title={Behavioral use licensing for responsible AI},
  author={Contractor, Danish and McDuff, Daniel and Haines, Julia Katherine and Lee, Jenny and Hines, Christopher and Hecht, Brent and Vincent, Nicholas and Li, Hanlin},
  booktitle={2022 ACM Conference on Fairness, Accountability, and Transparency},
  pages={778--788},
  year={2022}
}

@inproceedings{gideon2021way,
  title={The way to my heart is through contrastive learning: Remote photoplethysmography from unlabelled video},
  author={Gideon, John and Stent, Simon},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={3995--4004},
  year={2021}
}

@article{ekman1983autonomic,
  title={Autonomic nervous system activity distinguishes among emotions},
  author={Ekman, Paul and Levenson, Robert W and Friesen, Wallace V},
  journal={science},
  volume={221},
  number={4616},
  pages={1208--1210},
  year={1983},
  publisher={American Association for the Advancement of Science}
}

@article{krizhevsky2017imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Communications of the ACM},
  volume={60},
  number={6},
  pages={84--90},
  year={2017},
  publisher={AcM New York, NY, USA}
}

@inproceedings{kaili2016deep,
  title={Deep region and multi-label learning for facial action unit detection},
  author={Kaili, Zhao and Chu, Wen-Sheng and Zhang, Honggang},
  booktitle={In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={3391--3399},
  year={2016}
}

@article{hjelm2018learning,
  title={Learning deep representations by mutual information estimation and maximization},
  author={Hjelm, R Devon and Fedorov, Alex and Lavoie-Marchildon, Samuel and Grewal, Karan and Bachman, Phil and Trischler, Adam and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1808.06670},
  year={2018}
}

@inproceedings{burzo2012towards,
  title={Towards sensing the influence of visual narratives on human affect},
  author={Burzo, Mihai and McDuff, Daniel and Mihalcea, Rada and Morency, Louis-Philippe and Narvaez, Alexis and P{\'e}rez-Rosas, Ver{\'o}nica},
  booktitle={Proceedings of the 14th ACM international conference on Multimodal interaction},
  pages={153--160},
  year={2012}
}

@article{tarassenko2014non,
  title={Non-contact video-based vital sign monitoring using ambient light and auto-regressive models},
  author={Tarassenko, Lionel and Villarroel, Mauricio and Guazzi, Alessandro and Jorge, Joao and Clifton, DA and Pugh, Chris},
  journal={Physiological measurement},
  volume={35},
  number={5},
  pages={807},
  year={2014},
  publisher={IOP Publishing}
}

@article{d2015review,
  title={A review and meta-analysis of multimodal affect detection systems},
  author={D'mello, Sidney K and Kory, Jacqueline},
  journal={ACM computing surveys (CSUR)},
  volume={47},
  number={3},
  pages={1--36},
  year={2015},
  publisher={ACM New York, NY, USA}
}

@article{martinez2017automatic,
  title={Automatic analysis of facial actions: A survey},
  author={Martinez, Brais and Valstar, Michel F and Jiang, Bihan and Pantic, Maja},
  journal={IEEE transactions on affective computing},
  volume={10},
  number={3},
  pages={325--347},
  year={2017},
  publisher={IEEE}
}

@inproceedings{xie2021detco,
  title={Detco: Unsupervised contrastive learning for object detection},
  author={Xie, Enze and Ding, Jian and Wang, Wenhai and Zhan, Xiaohang and Xu, Hang and Sun, Peize and Li, Zhenguo and Luo, Ping},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={8392--8401},
  year={2021}
}

@article{yu2023physformer++,
  title={PhysFormer++: Facial Video-based Physiological Measurement with SlowFast Temporal Difference Transformer},
  author={Yu, Zitong and Shen, Yuming and Shi, Jingang and Zhao, Hengshuang and Cui, Yawen and Zhang, Jiehua and Torr, Philip and Zhao, Guoying},
  journal={International Journal of Computer Vision},
  pages={1--24},
  year={2023},
  publisher={Springer}
}

@inproceedings{chunghierarchical,
  title={Hierarchical Multiscale Recurrent Neural Networks},
  author={Chung, Junyoung and Ahn, Sungjin and Bengio, Yoshua},
  booktitle={International Conference on Learning Representations}
}

@inproceedings{feichtenhofer2019slowfast,
  title={Slowfast networks for video recognition},
  author={Feichtenhofer, Christoph and Fan, Haoqi and Malik, Jitendra and He, Kaiming},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={6202--6211},
  year={2019}
}

@article{mei2022informing,
  title={Informing deep neural networks by multiscale principles of neuromodulatory systems},
  author={Mei, Jie and Muller, Eilif and Ramaswamy, Srikanth},
  journal={Trends in Neurosciences},
  year={2022},
  publisher={Elsevier}
}

@article{schyns1994blobs,
  title={From blobs to boundary edges: Evidence for time-and spatial-scale-dependent scene recognition},
  author={Schyns, Philippe G and Oliva, Aude},
  journal={Psychological science},
  volume={5},
  number={4},
  pages={195--200},
  year={1994},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}

@article{weiss2002motion,
  title={Motion illusions as optimal percepts},
  author={Weiss, Yair and Simoncelli, Eero P and Adelson, Edward H},
  journal={Nature neuroscience},
  volume={5},
  number={6},
  pages={598--604},
  year={2002},
  publisher={Nature Publishing Group}
}

@article{zeng2021contrastive,
  title={Contrastive learning of global and local video representations},
  author={Zeng, Zhaoyang and McDuff, Daniel and Song, Yale and others},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={7025--7040},
  year={2021}
}

%%%%%%%%%%%%%%%%%%%%%
%%%% Facial Actions%%
%%%%%%%%%%%%%%%%%%%%%

@incollection{Cohn2007,
author = {Cohn, Jeffrey F. and Ambadar, Zara and Ekman, Paul},
booktitle = {Series in affective science. Handbook of emotion elicitation and assessment},
chapter = {Observer-b},
editor = {{J. A. Coan {\&} J. J. B. Allen}},
file = {::},
pages = {203--221},
publisher = {Oxford University Press},
title = {{Observer-based measurement of facial expression with the Facial Action Coding System}},
year = {2007}
}

@book{ekman1997face,
  title={What the face reveals: Basic and applied studies of spontaneous expression using the Facial Action Coding System (FACS)},
  author={Ekman, Rosenberg},
  year={1997},
  publisher={Oxford University Press, USA}
}

@book{fridlund2014human,
  title={Human facial expression: An evolutionary view},
  author={Fridlund, Alan J},
  year={2014},
  publisher={Academic Press}
}

@article{ekman1965differential,
  title={Differential communication of affect by head and body cues.},
  author={Ekman, Paul},
  journal={Journal of personality and social psychology},
  volume={2},
  number={5},
  pages={726},
  year={1965},
  publisher={American Psychological Association}
}

@article{erhan2010does,
  title={Why does unsupervised pre-training help deep learning?},
  author={Erhan, Dumitru and Bengio, Yoshua and Courville, Aaron and Manzagol, Pierre-Antoine and Vincent, Pascal and Bengio, Samy},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={Feb},
  pages={625--660},
  year={2010}
}

@inproceedings{huang2016hybrid,
  title={Hybrid hypergraph construction for facial expression recognition},
  author={Huang, Yuchi and Lu, Hanqing},
  booktitle={2016 23rd International Conference on Pattern Recognition (ICPR)},
  pages={4142--4147},
  year={2016},
  organization={IEEE}
}

@inproceedings{khorrami2015deep,
  title={Do deep neural networks learn facial action units when doing expression recognition?},
  author={Khorrami, Pooya and Paine, Thomas and Huang, Thomas},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision Workshops},
  pages={19--27},
  year={2015}
}

@article{srivastava2014dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={The journal of machine learning research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014},
  publisher={JMLR. org}
}

@article{mcduff2018fed+,
  title={Am-fed+: An extended dataset of naturalistic facial expressions collected in everyday settings},
  author={McDuff, Daniel and Amr, May and El Kaliouby, Rana},
  journal={IEEE Transactions on Affective Computing},
  volume={10},
  number={1},
  pages={7--17},
  year={2018},
  publisher={IEEE}
}

@inproceedings{mcduff2016affdex,
  title={AFFDEX SDK: a cross-platform real-time multi-face expression recognition toolkit},
  author={McDuff, Daniel and Mahmoud, Abdelrahman and Mavadati, Mohammad and Amr, May and Turcot, Jay and Kaliouby, Rana el},
  booktitle={Proceedings of the 2016 CHI conference extended abstracts on human factors in computing systems},
  pages={3723--3726},
  year={2016},
  organization={ACM}
}

@book{birdNaturalLanguageProcessing2009,
  title = {Natural Language Processing with {{Python}}: {{Analyzing}} Text with the Natural Language Toolkit},
  publisher = {{O'Reilly Media}},
  author = {Bird, Steven and Klein, Ewan and Loper, Edward},
  year = {2009}
}


@inproceedings{girard2017historical,
  title={Historical heterogeneity predicts smiling: Evidence from large-scale observational analyses},
  author={Girard, Jeffrey M and McDuff, Daniel},
  booktitle={2017 12th IEEE International Conference on automatic face \& gesture recognition (FG 2017)},
  pages={719--726},
  year={2017},
  organization={IEEE}
}

@inproceedings{yu2022physformer,
  title={PhysFormer: facial video-based physiological measurement with temporal difference transformer},
  author={Yu, Zitong and Shen, Yuming and Shi, Jingang and Zhao, Hengshuang and Torr, Philip HS and Zhao, Guoying},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4186--4196},
  year={2022}
}

@incollection{cohn2014automated,
  title={Automated face analysis for affective computing},
  author={Cohn, Jeffrey F and De la Torre, Fernando},
  booktitle={The Oxford handbook of affective computing},
  pages={131},
  year={2014}
}

@article{mcduff2019democratizing,
  title={Democratizing psychological insights from analysis of nonverbal behavior},
  author={McDuff, Daniel and Girard, Jeffrey M},
  year={2019},
  publisher={PsyArXiv}
}

@article{horstmann2003facial,
  title={What do facial expressions convey: Feeling states, behavioral intentions, or actions requests?},
  author={Horstmann, Gernot},
  journal={Emotion},
  volume={3},
  number={2},
  pages={150},
  year={2003},
  publisher={American Psychological Association}
}

@article{hutson2018artificial,
  title={Artificial intelligence faces reproducibility crisis.},
  author={Hutson, M},
  journal={Science (New York, NY)},
  volume={359},
  number={6377},
  pages={725},
  year={2018}
}

@article{seidel2010impact,
  title={The impact of facial emotional expressions on behavioral tendencies in women and men.},
  author={Seidel, Eva-Maria and Habel, Ute and Kirschner, Michaela and Gur, Ruben C and Derntl, Birgit},
  journal={Journal of Experimental Psychology: Human Perception and Performance},
  volume={36},
  number={2},
  pages={500},
  year={2010},
  publisher={American Psychological Association}
}

@article{pitcairn1990non,
  title={Non-verbal cues in the self-presentation of Parkinsonian patients},
  author={Pitcairn, Thomas K and Clemie, Susan and Gray, John M and Pentland, Brian},
  journal={British Journal of Clinical Psychology},
  volume={29},
  number={2},
  pages={177--184},
  year={1990},
  publisher={Wiley Online Library}
}

@inproceedings{vijay2016computational,
  title={Computational study of psychosis symptoms and facial expressions},
  author={Vijay, Supriya and Baltru{\v{s}}aitis, Tadas and Pennant, Luciana and Ong{\"u}r, Dost and Baker, Justin T and Morency, Louis-Philippe},
  booktitle={Computing and Mental Health Workshop at CHI},
  year={2016}
}

@inproceedings{stratou2013automatic,
  title={Automatic nonverbal behavior indicators of depression and PTSD: Exploring gender differences},
  author={Stratou, Giota and Scherer, Stefan and Gratch, Jonathan and Morency, Louis-Philippe},
  booktitle={2013 Humaine Association Conference on Affective Computing and Intelligent Interaction},
  pages={147--152},
  year={2013},
  organization={IEEE}
}

@inproceedings{kaltwang2012continuous,
  title={Continuous pain intensity estimation from facial expressions},
  author={Kaltwang, Sebastian and Rudovic, Ognjen and Pantic, Maja},
  booktitle={International Symposium on Visual Computing},
  pages={368--377},
  year={2012},
  organization={Springer}
}

@inproceedings{senechal2015facial,
  title={Facial action unit detection using active learning and an efficient non-linear kernel approximation},
  author={Senechal, Thibaud and McDuff, Daniel and Kaliouby, Rana},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision Workshops},
  pages={10--18},
  year={2015}
}

@article{mavadati2013disfa,
  title={Disfa: A spontaneous facial action intensity database},
  author={Mavadati, S Mohammad and Mahoor, Mohammad H and Bartlett, Kevin and Trinh, Philip and Cohn, Jeffrey F},
  journal={IEEE Transactions on Affective Computing},
  volume={4},
  number={2},
  pages={151--160},
  year={2013},
  publisher={IEEE}
}

@inproceedings{mcduff2013affectiva,
  title={Affectiva-mit facial expression dataset (am-fed): Naturalistic and spontaneous facial expressions collected},
  author={McDuff, Daniel and Kaliouby, Rana and Senechal, Thibaud and Amr, May and Cohn, Jeffrey and Picard, Rosalind},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  pages={881--888},
  year={2013}
}

@inproceedings{niu2019local,
  title={Local Relationship Learning With Person-Specific Shape Regularization for Facial Action Unit Detection},
  author={Niu, Xuesong and Han, Hu and Yang, Songfan and Huang, Yan and Shan, Shiguang},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={11917--11926},
  year={2019}
}

@inproceedings{guo2016ms,
  title={Ms-celeb-1m: A dataset and benchmark for large-scale face recognition},
  author={Guo, Yandong and Zhang, Lei and Hu, Yuxiao and He, Xiaodong and Gao, Jianfeng},
  booktitle={European Conference on Computer Vision},
  pages={87--102},
  year={2016},
  organization={Springer}
}

@article{zhao2023learning,
  title={Learning Spatio-Temporal Pulse Representation With Global-Local Interaction and Supervision for Remote Prediction of Heart Rate},
  author={Zhao, Changchen and Zhou, Menghao and Zhao, Zheng and Huang, Bin and Rao, Bing},
  journal={IEEE Journal of Biomedical and Health Informatics},
  year={2023},
  publisher={IEEE}
}

@inproceedings{baltrusaitis2018openface,
  title={Openface 2.0: Facial behavior analysis toolkit},
  author={Baltrusaitis, Tadas and Zadeh, Amir and Lim, Yao Chong and Morency, Louis-Philippe},
  booktitle={2018 13th IEEE International Conference on Automatic Face \& Gesture Recognition (FG 2018)},
  pages={59--66},
  year={2018},
  organization={IEEE}
}

@article{opencv_library,
    author = {Bradski, G.},
    citeulike-article-id = {2236121},
    journal = {Dr. Dobb's Journal of Software Tools},
    keywords = {bibtex-import},
    posted-at = {2008-01-15 19:21:54},
    priority = {4},
    title = {{The OpenCV Library}},
    year = {2000}
}

@inproceedings{seide2016cntk,
  title={CNTK: Microsoft's open-source deep-learning toolkit},
  author={Seide, Frank and Agarwal, Amit},
  booktitle={Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages={2135--2135},
  year={2016},
  organization={ACM}
}

@inproceedings{jeni2013facing,
  title={Facing imbalanced data--recommendations for the use of performance metrics},
  author={Jeni, L{\'a}szl{\'o} A and Cohn, Jeffrey F and De La Torre, Fernando},
  booktitle={2013 Humaine association conference on affective computing and intelligent interaction},
  pages={245--251},
  year={2013},
  organization={IEEE}
}

@inproceedings{gudi2015deep,
  title={Deep learning based facs action unit occurrence and intensity estimation},
  author={Gudi, Amogh and Tasli, H Emrah and Den Uyl, Tim M and Maroulis, Andreas},
  booktitle={2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG)},
  volume={6},
  pages={1--5},
  year={2015},
  organization={IEEE}
}

@inproceedings{jaiswal2016deep,
  title={Deep learning the dynamic appearance and shape of facial action units},
  author={Jaiswal, Shashank and Valstar, Michel},
  booktitle={2016 IEEE winter conference on applications of computer vision (WACV)},
  pages={1--8},
  year={2016},
  organization={IEEE}
}

@inproceedings{benitez2017recognition,
  title={Recognition of Action Units in the Wild with Deep Nets and a New Global-Local Loss.},
  author={Benitez-Quiroz, Carlos Fabian and Wang, Yan and Martinez, Aleix M},
  booktitle={ICCV},
  pages={3990--3999},
  year={2017}
}

@inproceedings{corneanu2018deep,
  title={Deep structure inference network for facial action unit recognition},
  author={Corneanu, Ciprian and Madadi, Meysam and Escalera, Sergio},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={298--313},
  year={2018}
}

@inproceedings{li2019self,
  title={Self-Supervised Representation Learning From Videos for Facial Action Unit Detection},
  author={Li, Yong and Zeng, Jiabei and Shan, Shiguang and Chen, Xilin},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={10924--10933},
  year={2019}
}

@article{takalkar2018survey,
  title={A survey: facial micro-expression recognition},
  author={Takalkar, Madhumita and Xu, Min and Wu, Qiang and Chaczko, Zenon},
  journal={Multimedia Tools and Applications},
  volume={77},
  number={15},
  pages={19301--19325},
  year={2018},
  publisher={Springer}
}

@article{mcduff2016applications,
  title={Applications of automated facial coding in media measurement},
  author={McDuff, Daniel and El Kaliouby, Rana},
  journal={IEEE transactions on affective computing},
  volume={8},
  number={2},
  pages={148--160},
  year={2016},
  publisher={IEEE}
}

@inproceedings{valstar2006fully,
  title={Fully automatic facial action unit detection and temporal analysis},
  author={Valstar, Michel and Pantic, Maja},
  booktitle={2006 Conference on Computer Vision and Pattern Recognition Workshop (CVPRW'06)},
  pages={149--149},
  year={2006},
  organization={IEEE}
}

@inproceedings{baltruvsaitis2015cross,
  title={Cross-dataset learning and person-specific normalisation for automatic action unit detection},
  author={Baltru{\v{s}}aitis, Tadas and Mahmoud, Marwa and Robinson, Peter},
  booktitle={2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG)},
  volume={6},
  pages={1--6},
  year={2015},
  organization={IEEE}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{zhao2016deep,
  title={Deep region and multi-label learning for facial action unit detection},
  author={Zhao, Kaili and Chu, Wen-Sheng and Zhang, Honggang},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={3391--3399},
  year={2016}
}

@inproceedings{li2017action,
  title={Action unit detection with region adaptation, multi-labeling learning and optimal temporal fusing},
  author={Li, Wei and Abtahi, Farnaz and Zhu, Zhigang},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={1841--1850},
  year={2017}
}

@inproceedings{zhao2018learning,
  title={Learning facial action units from web images with scalable weakly supervised clustering},
  author={Zhao, Kaili and Chu, Wen-Sheng and Martinez, Aleix M},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2090--2099},
  year={2018}
}

@inproceedings{gunderson2018inproceedings,
author = {Gundersen, Odd Erik and Kjensmo, Sigbjørn},
year = {2018},
month = {02},
pages = {},
title = {State of the Art: Reproducibility in Artificial Intelligence}
}

@article{tatman2018practical,
  title={A Practical Taxonomy of Reproducibility for Machine Learning Research},
  author={Tatman, Rachael and VanderPlas, Jake and Dane, Sohier},
  year={2018}
}

@article{mcdermott2019reproducibility,
  title={Reproducibility in Machine Learning for Health},
  author={McDermott, Matthew and Wang, Shirly and Marinsek, Nikki and Ranganath, Rajesh and Ghassemi, Marzyeh and Foschini, Luca},
  journal={arXiv preprint arXiv:1907.01463},
  year={2019}
}

@inproceedings{zhu2012we,
  title={Do We Need More Training Data or Better Models for Object Detection?.},
  author={Zhu, Xiangxin and Vondrick, Carl and Ramanan, Deva and Fowlkes, Charless C},
  booktitle={BMVC},
  volume={3},
  pages={5},
  year={2012},
  organization={Citeseer}
}

@inproceedings{girard2015much,
  title={How much training data for facial action unit detection?},
  author={Girard, Jeffrey M and Cohn, Jeffrey F and Jeni, L{\'a}szl{\'o} A and Lucey, Simon and De la Torre, Fernando},
  booktitle={2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG)},
  volume={1},
  pages={1--8},
  year={2015},
  organization={IEEE}
}

@inproceedings{lucey2010extended,
  title={The extended cohn-kanade dataset (ck+): A complete dataset for action unit and emotion-specified expression},
  author={Lucey, Patrick and Cohn, Jeffrey F and Kanade, Takeo and Saragih, Jason and Ambadar, Zara and Matthews, Iain},
  booktitle={2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition-Workshops},
  pages={94--101},
  year={2010},
  organization={IEEE}
}
@inproceedings{valstar2010induced,
  title={Induced disgust, happiness and surprise: an addition to the mmi facial expression database},
  author={Valstar, Michel and Pantic, Maja},
  booktitle={Proc. 3rd Intern. Workshop on EMOTION (satellite of LREC): Corpora for Research on Emotion and Affect},
  pages={65},
  year={2010},
  organization={Paris, France}
}

@inproceedings{savran2008bosphorus,
  title={Bosphorus database for 3D face analysis},
  author={Savran, Arman and Aly{\"u}z, Ne{\c{s}}e and Dibeklio{\u{g}}lu, Hamdi and {\c{C}}eliktutan, Oya and G{\"o}kberk, Berk and Sankur, B{\"u}lent and Akarun, Lale},
  booktitle={European Workshop on Biometrics and Identity Management},
  pages={47--56},
  year={2008},
  organization={Springer}
}

@inproceedings{shao2018deep,
  title={Deep adaptive attention for joint facial action unit detection and face alignment},
  author={Shao, Zhiwen and Liu, Zhilei and Cai, Jianfei and Ma, Lizhuang},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={705--720},
  year={2018}
}

@article{hornik1989multilayer,
  title={Multilayer feedforward networks are universal approximators},
  author={Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
  journal={Neural networks},
  volume={2},
  number={5},
  pages={359--366},
  year={1989},
  publisher={Elsevier}
}

@article{leshno1993multilayer,
  title={Multilayer feedforward networks with a nonpolynomial activation function can approximate any function},
  author={Leshno, Moshe and Lin, Vladimir Ya and Pinkus, Allan and Schocken, Shimon},
  journal={Neural networks},
  volume={6},
  number={6},
  pages={861--867},
  year={1993},
  publisher={Elsevier}
}

@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year={2016},
  publisher={MIT press}
}

@article{bengio2009learning,
  title={Learning deep architectures for AI},
  author={Bengio, Yoshua and others},
  journal={Foundations and trends{\textregistered} in Machine Learning},
  volume={2},
  number={1},
  pages={1--127},
  year={2009},
  publisher={Now Publishers, Inc.}
}

@article{bengio2007scaling,
  title={Scaling learning algorithms towards AI},
  author={Bengio, Yoshua and LeCun, Yann and others},
  journal={Large-scale kernel machines},
  volume={34},
  number={5},
  pages={1--41},
  year={2007}
}

@inproceedings{glorot2010understanding,
  title={Understanding the difficulty of training deep feedforward neural networks},
  author={Glorot, Xavier and Bengio, Yoshua},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={249--256},
  year={2010}
}

@article{mishkin2015all,
  title={All you need is a good init},
  author={Mishkin, Dmytro and Matas, Jiri},
  journal={arXiv preprint arXiv:1511.06422},
  year={2015}
}

@inproceedings{peng2018using,
  title={Using Supervised Pretraining to Improve Generalization of Neural Networks on Binary Classification Problems},
  author={Peng, Alex Yuxuan and Koh, Yun Sing and Riddle, Patricia and Pfahringer, Bernhard},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={410--425},
  year={2018},
  organization={Springer}
}

@inproceedings{fabian2016emotionet,
  title={Emotionet: An accurate, real-time algorithm for the automatic annotation of a million facial expressions in the wild},
  author={Fabian Benitez-Quiroz, C and Srinivasan, Ramprakash and Martinez, Aleix M},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={5562--5570},
  year={2016}
}

@inproceedings{jyoti2019expression,
  title={Expression empowered residen network for facial action unit detection},
  author={Jyoti, Shreyank and Sharma, Garima and Dhall, Abhinav},
  booktitle={2019 14th IEEE International Conference on Automatic Face \& Gesture Recognition (FG 2019)},
  pages={1--8},
  year={2019},
  organization={IEEE}
}


%%%%%%%%%%%%%%%%%%%%%
%%%% RPPG %%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%

@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@inproceedings{liu2023efficientphys,
  title={EfficientPhys: Enabling Simple, Fast and Accurate Camera-Based Cardiac Measurement},
  author={Liu, Xin and Hill, Brian and Jiang, Ziheng and Patel, Shwetak and McDuff, Daniel},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={5008--5017},
  year={2023}
}

@article{soleymani2011multimodal,
  title={A multimodal database for affect recognition and implicit tagging},
  author={Soleymani, Mohammad and Lichtenauer, Jeroen and Pun, Thierry and Pantic, Maja},
  journal={IEEE transactions on affective computing},
  volume={3},
  number={1},
  pages={42--55},
  year={2011},
  publisher={IEEE}
}

@article{yu2019remote,
  title={Remote photoplethysmograph signal measurement from facial videos using spatio-temporal networks},
  author={Yu, Zitong and Li, Xiaobai and Zhao, Guoying},
  journal={arXiv preprint arXiv:1905.02419},
  year={2019}
}


@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}


@inproceedings{niu2020video,
  title={Video-based remote physiological measurement via cross-verified feature disentangling},
  author={Niu, Xuesong and Yu, Zitong and Han, Hu and Li, Xiaobai and Shan, Shiguang and Zhao, Guoying},
  booktitle={European Conference on Computer Vision},
  pages={295--310},
  year={2020},
  organization={Springer}
}


% OUR REFS START HERE:

@article{ba2021overcoming,
  title={Overcoming Difficulty in Obtaining Dark-skinned Subjects for Remote-PPG by Synthetic Augmentation},
  author={Ba, Yunhao and Wang, Zhen and Karinca, Kerim Doruk and Bozkurt, Oyku Deniz and Kadambi, Achuta},
  journal={arXiv preprint arXiv:2106.06007},
  year={2021}
}

@inproceedings{chen2018deepphys,
  title={Deepphys: Video-based physiological measurement using convolutional attention networks},
  author={Chen, Weixuan and McDuff, Daniel},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={349--365},
  year={2018}
}

@article{liu2020multi,
  title={Multi-task temporal shift attention networks for on-device contactless vitals measurement},
  author={Liu, Xin and Fromm, Josh and Patel, Shwetak and McDuff, Daniel},
  journal={arXiv preprint arXiv:2006.03790},
  year={2020}
}

@article{liu2021video,
  title={Video swin transformer},
  author={Liu, Ze and Ning, Jia and Cao, Yue and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Hu, Han},
  journal={arXiv preprint arXiv:2106.13230},
  year={2021}
}


@article{mcduff2020advancing,
  title={Advancing Non-Contact Vital Sign Measurement using Synthetic Avatars},
  author={McDuff, Daniel and Hernandez, Javier and Wood, Erroll and Liu, Xin and Baltrusaitis, Tadas},
  journal={arXiv preprint arXiv:2010.12949},
  year={2020}
}

@article{poh2010advancements,
  title={Advancements in noncontact, multiparameter physiological measurements using a webcam},
  author={Poh, Ming-Zher and McDuff, Daniel J and Picard, Rosalind W},
  journal={IEEE transactions on biomedical engineering},
  volume={58},
  number={1},
  pages={7--11},
  year={2010},
  publisher={IEEE}
}

@article{takano2007heart,
  title={Heart rate measurement based on a time-lapse image},
  author={Takano, Chihiro and Ohta, Yuji},
  journal={Medical engineering \& physics},
  volume={29},
  number={8},
  pages={853--857},
  year={2007},
  publisher={Elsevier}
}

@inproceedings{tsou2020multi,
  title={Multi-task learning for simultaneous video generation and remote photoplethysmography estimation},
  author={Tsou, Yun-Yun and Lee, Yi-An and Hsu, Chiou-Ting},
  booktitle={Proceedings of the Asian Conference on Computer Vision},
  year={2020}
}

@article{verkruysse2008remote,
  title={Remote plethysmographic imaging using ambient light.},
  author={Verkruysse, Wim and Svaasand, Lars O and Nelson, J Stuart},
  journal={Optics express},
  volume={16},
  number={26},
  pages={21434--21445},
  year={2008},
  publisher={Optical Society of America}
}

@article{wang2016algorithmic,
  title={Algorithmic principles of remote PPG},
  author={Wang, Wenjin and den Brinker, Albertus C and Stuijk, Sander and De Haan, Gerard},
  journal={IEEE Transactions on Biomedical Engineering},
  volume={64},
  number={7},
  pages={1479--1491},
  year={2016},
  publisher={IEEE}
}

@inproceedings{wu2000photoplethysmography,
  title={Photoplethysmography imaging: a new noninvasive and noncontact method for mapping of the dermal perfusion changes},
  author={Wu, Ting and Blazek, Vladimir and Schmitt, Hans Juergen},
  booktitle={Optical Techniques and Instrumentation for the Measurement of Blood Composition, Structure, and Dynamics},
  volume={4163},
  pages={62--70},
  year={2000},
  organization={International Society for Optics and Photonics}
}

@inproceedings{qi2020deeprhythm,
  title={DeepRhythm: Exposing deepfakes with attentional visual heartbeat rhythms},
  author={Qi, Hua and Guo, Qing and Juefei-Xu, Felix and Xie, Xiaofei and Ma, Lei and Feng, Wei and Liu, Yang and Zhao, Jianjun},
  booktitle={Proceedings of the 28th ACM International Conference on Multimedia},
  pages={4318--4327},
  year={2020}
}

@article{bobbia2019unsupervised,
  title={Unsupervised skin tissue segmentation for remote photoplethysmography},
  author={Bobbia, Serge and Macwan, Richard and Benezeth, Yannick and Mansouri, Alamin and Dubois, Julien},
  journal={Pattern Recognition Letters},
  volume={124},
  pages={82--90},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{zhang2016multimodal,
  title={Multimodal spontaneous emotion corpus for human behavior analysis},
  author={Zhang, Zheng and Girard, Jeff M and Wu, Yue and Zhang, Xing and Liu, Peng and Ciftci, Umur and Canavan, Shaun and Reale, Michael and Horowitz, Andy and Yang, Huiyuan and others},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={3438--3446},
  year={2016}
}

@inproceedings{stricker2014non,
  title={Non-contact video-based pulse rate measurement on a mobile service robot},
  author={Stricker, Ronny and M{\"u}ller, Steffen and Gross, Horst-Michael},
  booktitle={The 23rd IEEE International Symposium on Robot and Human Interactive Communication},
  pages={1056--1062},
  year={2014},
  organization={IEEE}
}

@inproceedings{lin2019tsm,
  title={Tsm: Temporal shift module for efficient video understanding},
  author={Lin, Ji and Gan, Chuang and Han, Song},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={7083--7093},
  year={2019}
}

@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@misc{consumer2018physical,
  title={Physical Activity Monitoring for Heart Rate, ANSI/CTA-2065},
  author={Consumer Technology Association},
  year={2018},
  publisher={Consumer Technology Association Hopewell, VA, USA}
}

@article{nelson2019accuracy,
  title={Accuracy of consumer wearable heart rate measurement during an ecologically valid 24-hour period: intraindividual validation study},
  author={Nelson, Benjamin W and Allen, Nicholas B},
  journal={JMIR mHealth and uHealth},
  volume={7},
  number={3},
  pages={e10828},
  year={2019},
  publisher={JMIR Publications Inc., Toronto, Canada}
}

@article{shcherbina2017accuracy,
  title={Accuracy in wrist-worn, sensor-based measurements of heart rate and energy expenditure in a diverse cohort},
  author={Shcherbina, Anna and Mattsson, C Mikael and Waggott, Daryl and Salisbury, Heidi and Christle, Jeffrey W and Hastie, Trevor and Wheeler, Matthew T and Ashley, Euan A},
  journal={Journal of personalized medicine},
  volume={7},
  number={2},
  pages={3},
  year={2017},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@article{reece2021assessing,
  title={Assessing Heart Rate Using Consumer Technology Association Standards},
  author={Reece, Joel D and Bunn, Jennifer A and Choi, Minsoo and Navalta, James W},
  journal={Technologies},
  volume={9},
  number={3},
  pages={46},
  year={2021},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@article{carrier2020validity,
  title={Validity and reliability of physiological data in applied settings measured by wearable technology: A rapid systematic review},
  author={Carrier, Bryson and Barrios, Brenna and Jolley, Brayden D and Navalta, James W},
  journal={Technologies},
  volume={8},
  number={4},
  pages={70},
  year={2020},
  publisher={Multidisciplinary Digital Publishing Institute}
}



@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  pages={8026--8037},
  year={2019}
}


@article{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  journal={arXiv preprint arXiv:2103.14030},
  year={2021}
}


@article{yu2021transrppg,
  title={Transrppg: Remote photoplethysmography transformer for 3d mask face presentation attack detection},
  author={Yu, Zitong and Li, Xiaobai and Wang, Pichao and Zhao, Guoying},
  journal={IEEE Signal Processing Letters},
  year={2021},
  publisher={IEEE}
}

@article{de2013robust,
  title={Robust pulse rate from chrominance-based rPPG},
  author={De Haan, Gerard and Jeanne, Vincent},
  journal={IEEE Transactions on Biomedical Engineering},
  volume={60},
  number={10},
  pages={2878--2886},
  year={2013},
  publisher={IEEE}
}


@article{song2021pulsegan,
  title={PulseGAN: Learning to generate realistic pulse waveforms in remote photoplethysmography},
  author={Song, Rencheng and Chen, Huan and Cheng, Juan and Li, Chang and Liu, Yu and Chen, Xun},
  journal={IEEE Journal of Biomedical and Health Informatics},
  volume={25},
  number={5},
  pages={1373--1384},
  year={2021},
  publisher={IEEE}
}


@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}



@article{elgendi_use_2019,
	title = {The use of photoplethysmography for assessing hypertension},
	volume = {2},
	copyright = {2019 The Author(s)},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-019-0136-7},
	doi = {10.1038/s41746-019-0136-7},
	abstract = {The measurement of blood pressure (BP) is critical to the treatment and management of many medical conditions. High blood pressure is associated with many chronic disease conditions, and is a major source of mortality and morbidity around the world. For outpatient care as well as general health monitoring, there is great interest in being able to accurately and frequently measure BP outside of a clinical setting, using mobile or wearable devices. One possible solution is photoplethysmography (PPG), which is most commonly used in pulse oximetry in clinical settings for measuring oxygen saturation. PPG technology is becoming more readily available, inexpensive, convenient, and easily integrated into portable devices. Recent advances include the development of smartphones and wearable devices that collect pulse oximeter signals. In this article, we review (i) the state-of-the-art and the literature related to PPG signals collected by pulse oximeters, (ii) various theoretical approaches that have been adopted in PPG BP measurement studies, and (iii) the potential of PPG measurement devices as a wearable application. Past studies on changes in PPG signals and BP are highlighted, and the correlation between PPG signals and BP are discussed. We also review the combined use of features extracted from PPG and other physiological signals in estimating BP. Although the technology is not yet mature, it is anticipated that in the near future, accurate, continuous BP measurements may be available from mobile and wearable devices given their vast potential.},
	language = {en},
	number = {1},
	urldate = {2021-09-21},
	journal = {npj Digital Medicine},
	author = {Elgendi, Mohamed and Fletcher, Richard and Liang, Yongbo and Howard, Newton and Lovell, Nigel H. and Abbott, Derek and Lim, Kenneth and Ward, Rabab},
	month = jun,
	year = {2019},
	pages = {1--11},
}

@article{elgendi_use_2019-1,
	title = {The use of photoplethysmography for assessing hypertension},
	volume = {2},
	copyright = {2019 The Author(s)},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-019-0136-7},
	doi = {10.1038/s41746-019-0136-7},
	abstract = {The measurement of blood pressure (BP) is critical to the treatment and management of many medical conditions. High blood pressure is associated with many chronic disease conditions, and is a major source of mortality and morbidity around the world. For outpatient care as well as general health monitoring, there is great interest in being able to accurately and frequently measure BP outside of a clinical setting, using mobile or wearable devices. One possible solution is photoplethysmography (PPG), which is most commonly used in pulse oximetry in clinical settings for measuring oxygen saturation. PPG technology is becoming more readily available, inexpensive, convenient, and easily integrated into portable devices. Recent advances include the development of smartphones and wearable devices that collect pulse oximeter signals. In this article, we review (i) the state-of-the-art and the literature related to PPG signals collected by pulse oximeters, (ii) various theoretical approaches that have been adopted in PPG BP measurement studies, and (iii) the potential of PPG measurement devices as a wearable application. Past studies on changes in PPG signals and BP are highlighted, and the correlation between PPG signals and BP are discussed. We also review the combined use of features extracted from PPG and other physiological signals in estimating BP. Although the technology is not yet mature, it is anticipated that in the near future, accurate, continuous BP measurements may be available from mobile and wearable devices given their vast potential.},
	language = {en},
	number = {1},
	urldate = {2020-09-29},
	journal = {npj Digital Medicine},
	author = {Elgendi, Mohamed and Fletcher, Richard and Liang, Yongbo and Howard, Newton and Lovell, Nigel H. and Abbott, Derek and Lim, Kenneth and Ward, Rabab},
	month = jun,
	year = {2019},
	pages = {1--11},
}

@article{takazawa_assessment_1998,
	title = {Assessment of {Vasoactive} {Agents} and {Vascular} {Aging} by the {Second} {Derivative} of {Photoplethysmogram} {Waveform}},
	volume = {32},
	url = {https://www.ahajournals.org/doi/10.1161/01.HYP.32.2.365},
	doi = {10.1161/01.HYP.32.2.365},
	abstract = {—To evaluate the clinical application of the second derivative of the fingertip photoplethysmogram waveform, we performed drug administration studies (study 1) and epidemiological studies (study 2). In study 1, ascending aortic pressure was recorded simultaneously with the fingertip photoplethysmogram and its second derivative in 39 patients with a mean±SD age of 54±11 years. The augmentation index was defined as the ratio of the height of the late systolic peak to that of the early systolic peak in the pulse. The second derivative consists of an a, b, c, and d wave in systole and an e wave in diastole. Ascending aortic pressure increased after injection of 2.5 μg angiotensin from 126/74 to 160/91 mm Hg and decreased after 0.3 mg sublingual nitroglycerin to 111/73 mm Hg. The d/a, the ratio of the height of the d wave to that of the a wave, decreased after angiotensin from −0.40±0.13 to −0.62±0.19 and increased after nitroglycerin to −0.25±0.12 (P{\textless}0.001 and P{\textless}0.001, respectively). The negative d/a increased with increases in plethysmographic and ascending aortic augmentation indices (r=0.79, P{\textless}0.001, and r=0.80, P{\textless}0.001, respectively). The negative d/a reflects the late systolic pressure augmentation in the ascending aorta and may be useful for noninvasive evaluation of the effects of vasoactive agents. In study 2, the second derivative of the plethysmogram waveform was measured in a total of 600 subjects (50 men and 50 women in each decade from the 3rd to the 8th) in our health assessment center. The b/a ratio increased with age, and c/a, d/a, and e/a ratios decreased with age. Thus, the second derivative aging index was defined as b-c-d-e/a. The second derivative wave aging index (y) increased with age (x) (r=0.80, P{\textless}0.001, y=0.023x−1.515). The second derivative aging index was higher in 126 subjects with any history of diabetes mellitus, hypertension, hypercholesterolemia, and ischemic heart disease than in age-matched subjects without such a history (−0.06±0.36 versus −0.22±0.41, P{\textless}0.01). Women had a higher aging index than men (P{\textless}0.01). The b-c-d-e/a ratio may be useful for evaluation of vascular aging and for screening of arteriosclerotic disease.},
	number = {2},
	urldate = {2021-09-19},
	journal = {Hypertension},
	author = {Takazawa, Kenji and Tanaka, Nobuhiro and Fujita, Masami and Matsuoka, Osamu and Saiki, Tokuyu and Aikawa, Masaru and Tamura, Sinobu and Ibukiyama, Chiharu},
	month = aug,
	year = {1998},
	keywords = {angiotensin, augmentation index, nitroglycerin, photoplethysmography, second derivative wave, vascular aging, vasoactive agents},
	pages = {365--370},
}

@article{pereira_photoplethysmography_2020,
	title = {Photoplethysmography based atrial fibrillation detection: a review},
	volume = {3},
	copyright = {2020 The Author(s)},
	issn = {2398-6352},
	shorttitle = {Photoplethysmography based atrial fibrillation detection},
	url = {https://www.nature.com/articles/s41746-019-0207-9},
	doi = {10.1038/s41746-019-0207-9},
	abstract = {Atrial fibrillation (AF) is a cardiac rhythm disorder associated with increased morbidity and mortality. It is the leading risk factor for cardioembolic stroke and its early detection is crucial in both primary and secondary stroke prevention. Continuous monitoring of cardiac rhythm is today possible thanks to consumer-grade wearable devices, enabling transformative diagnostic and patient management tools. Such monitoring is possible using low-cost easy-to-implement optical sensors that today equip the majority of wearables. These sensors record blood volume variations—a technology known as photoplethysmography (PPG)—from which the heart rate and other physiological parameters can be extracted to inform about user activity, fitness, sleep, and health. Recently, new wearable devices were introduced as being capable of AF detection, evidenced by large prospective trials in some cases. Such devices would allow for early screening of AF and initiation of therapy to prevent stroke. This review is a summary of a body of work on AF detection using PPG. A thorough account of the signal processing, machine learning, and deep learning approaches used in these studies is presented, followed by a discussion of their limitations and challenges towards clinical applications.},
	language = {en},
	number = {1},
	urldate = {2021-09-28},
	journal = {npj Digital Medicine},
	author = {Pereira, Tania and Tran, Nate and Gadhoumi, Kais and Pelter, Michele M. and Do, Duc H. and Lee, Randall J. and Colorado, Rene and Meisel, Karl and Hu, Xiao},
	month = jan,
	year = {2020},
	pages = {1--12},
}

@article{inoue_second_2017,
	title = {Second derivative of the finger photoplethysmogram and cardiovascular mortality in middle-aged and elderly {Japanese} women},
	volume = {40},
	copyright = {2017 The Japanese Society of Hypertension},
	issn = {1348-4214},
	url = {https://www.nature.com/articles/hr2016123},
	doi = {10.1038/hr.2016.123},
	abstract = {The second derivative of the digital photoplethysmogram (SDPTG) is an indicator of arterial stiffness. The ratio of the height of the d wave to the a wave of the SDPTG (d/a) is associated with functional peripheral vascular tension and represents aortic-blood pressure (BP) augmented by reflection waves from the periphery. This longitudinal study aimed to investigate the relationship between SDPTG and cardiovascular mortality in middle-aged and elderly Japanese women. From 1998 to 2008, we recruited 4373 women (50–79 years old at baseline) who underwent medical check-ups and SDPTG measurement. The SDPTG index (d/a) was calculated from the wave component height, and was divided into quartiles (Q) according to the d/a value. The median follow-up period was 9.0 years. The d/a value was negatively associated with age and BP, and positively associated with heart rate and body height. Using the Cox proportional hazards model, the hazard ratios for cardiovascular mortality for Q2, Q3 and Q4 were significantly higher than that of Q1. In multivariate analysis, the hazard ratio was 2.30 for Q3 (95\% confidence interval (CI): 1.06–4.99, P{\textless}0.05) and 2.60 for Q4 (95\% CI: 1.21–5.60, P{\textless}0.05), after adjustment for age, height, body mass index, BP levels, heart rate and other atherosclerosis-related factors. The hazard ratios of cardiovascular mortality for Q3 and Q4 were significantly higher compared with the reference (Q1). Thus, the SDPTG d/a is an independent predictor of cardiovascular mortality in middle-aged and elderly Japanese women.},
	language = {en},
	number = {2},
	urldate = {2021-09-19},
	journal = {Hypertension Research},
	author = {Inoue, Noriko and Kawakami, Hideshi and Yamamoto, Hideya and Ito, Chikako and Fujiwara, Saeko and Sasaki, Hideo and Kihara, Yasuki},
	month = feb,
	year = {2017},
	pages = {207--211},
}

@article{hamada_clinical_1990,
	title = {Clinical significance of systolic time intervals in hypertensive patients},
	volume = {11 Suppl I},
	issn = {0195-668X},
	doi = {10.1093/eurheartj/11.suppl_i.105},
	abstract = {This paper updates the current view on clinical significance of systolic time intervals (STI) in estimating the cardiac changes associated with hypertension. The following three intervals were measured as STI: (1) electromechanical systole (QS2 interval); (2) left ventricular ejection time (LVET) and (3) pre-ejection period (PEP). Firstly, the influences of changes in heart rate, preload, afterload and myocardial contractility upon each interval were reviewed; secondly, clinical applications of STI in various types of hypertension such as essential hypertension, hypertension with angina pectoris and pheochromocytoma were studied. In patients with essential hypertension, there was a good positive correlation between PEP and left ventricular mass, and a shortening of LVET was observed only at the decompensated stage. The changes in STI in angina pectoris with or without hypertension were similar and were different from those in essential hypertensives. STI in patients with pheochromocytoma were characterized by a marked shortening of QS2 and LVET with normal PEP. These findings indicate the usefulness of STI in detecting cardiac changes in various types of hypertension.},
	language = {eng},
	journal = {European Heart Journal},
	author = {Hamada, M. and Hiwada, K. and Kokubu, T.},
	month = dec,
	year = {1990},
	pmid = {2151186},
	keywords = {Adrenal Gland Neoplasms, Angina Pectoris, Cardiac Output, Cardiomegaly, Echocardiography, Heart Ventricles, Humans, Hypertension, Myocardial Contraction, Myocardial Infarction, Pheochromocytoma, Phonocardiography, Stroke Volume, Systole, Ventricular Function, Left},
	pages = {105--113},
}

@article{boudoulas_systolic_1990,
	title = {Systolic time intervals},
	volume = {11 Suppl I},
	issn = {0195-668X},
	doi = {10.1093/eurheartj/11.suppl_i.93},
	abstract = {The systolic time intervals (STI) offer temporal description of the sequential phases of cardiac cycle which are influenced physiologically by the same variables as affect other measures of left ventricular (LV) performance. The STI hence offer a measure of ventricular function which augments other measures of ventricular performance. Because of the extreme sensitivity of this variable and the ease of its measurement the STI are well suited for studying the effect of pharmacologic agents upon the heart.},
	language = {eng},
	journal = {European Heart Journal},
	author = {Boudoulas, H.},
	month = dec,
	year = {1990},
	pmid = {2092995},
	keywords = {Cardiac Output, Cardiovascular Diseases, Echocardiography, Echocardiography, Doppler, Electrocardiography, Humans, Myocardial Contraction, Stroke Volume, Systole, Ventricular Function, Left},
	pages = {93--104},
}

@article{biering-sorensen_left_2018,
	title = {Left {Ventricular} {Ejection} {Time} is an {Independent} {Predictor} of {Incident} {Heart} {Failure} in a {Community} based {Cohort}},
	volume = {20},
	issn = {1388-9842},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6685547/},
	doi = {10.1002/ejhf.928},
	abstract = {Aims:
Systolic time intervals change in the progress of cardiac dysfunction. The usefulness of left ventricular ejection time (LVET) to predict cardiovascular morbidity, however, is unknown.

Methods and Results:
We studied middle-aged African-Americans from one of four cohorts of the Atherosclerosis Risk in Communities study (Jackson cohort, n=1,980) who underwent echocardiography between 1993 and 1995. LVET was measured by pulsed-wave Doppler of the left ventricular outflow tract and related to outcomes., A shorter LVET was associated with younger age, male sex, higher diastolic blood pressure (BP), higher proportion of diabetes, higher heart rate, higher blood glucose levels and worse fractional shortening (FS). During a median follow-up of 17.6 years, 384 (19\%) had incident heart failure (HF), 158 (8\%) had a myocardial infarction (MI), and 587 (30\%) died. In univariable analysis, a lower LVET was significantly associated with increased risk of all events (p{\textless}0.05 for all). However, after multivariable adjustment for age, sex, hypertension, diabetes, body mass index, heart rate, systolic and diastolic BP, FS and left atrium diameter, LVET remained an independent predictor only of incident HF (HR1.07 (1.02–1.14), P=0.010, per 10ms decrease). In addition, LVET provided incremental prognostic information to the known risk factors included in the Framingham risk score, in regard to predicting all outcomes except for MI.

Conclusion:
LVET is an independent predictor of incident HF in a community-based cohort and provides incremental prognostic information on the risk of future HF and death when added to known risk prediction models.},
	number = {7},
	urldate = {2021-09-30},
	journal = {European journal of heart failure},
	author = {Biering-Sørensen, Tor and Querejeta Roca, Gabriela and Hegde, Sheila M. and Shah, Amil M. and Claggett, Brian and Mosley, Thomas H. and Butler, Kenneth R. and Solomon, Scott D.},
	month = jul,
	year = {2018},
	pmid = {28872225},
	pmcid = {PMC6685547},
	pages = {1106--1114},
}

@article{abadi_tensorflow_2016,
	title = {{TensorFlow}: {Large}-{Scale} {Machine} {Learning} on {Heterogeneous} {Distributed} {Systems}},
	shorttitle = {{TensorFlow}},
	url = {http://arxiv.org/abs/1603.04467},
	abstract = {TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.},
	urldate = {2021-09-30},
	journal = {arXiv:1603.04467 [cs]},
	author = {Abadi, Martín and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg S. and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Goodfellow, Ian and Harp, Andrew and Irving, Geoffrey and Isard, Michael and Jia, Yangqing and Jozefowicz, Rafal and Kaiser, Lukasz and Kudlur, Manjunath and Levenberg, Josh and Mane, Dan and Monga, Rajat and Moore, Sherry and Murray, Derek and Olah, Chris and Schuster, Mike and Shlens, Jonathon and Steiner, Benoit and Sutskever, Ilya and Talwar, Kunal and Tucker, Paul and Vanhoucke, Vincent and Vasudevan, Vijay and Viegas, Fernanda and Vinyals, Oriol and Warden, Pete and Wattenberg, Martin and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
	month = mar,
	year = {2016},
	note = {arXiv: 1603.04467},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning},
}

@article{greenhalgh_remote_2021,
	title = {Remote management of covid-19 using home pulse oximetry and virtual ward support},
	volume = {372},
	copyright = {Published by the BMJ Publishing Group Limited. For permission to use (where not already granted under a licence) please go to http://group.bmj.com/group/rights-licensing/permissions. This article is made freely available for use in accordance with BMJ's website terms and conditions for the duration of the covid-19 pandemic or until otherwise determined by BMJ.  You may use, download and print the article for any lawful, non-commercial purpose (including text and data mining) provided that all copyright notices and trade marks are retained.https://bmj.com/coronavirus/usage},
	issn = {1756-1833},
	url = {https://www.bmj.com/content/372/bmj.n677},
	doi = {10.1136/bmj.n677},
	abstract = {\#\#\# What you need to know

Low blood oxygen—technically, hypoxaemia but usually referred to as hypoxia—can be defined as a measured oxygen saturation below 94\% in the absence (or below 88\% in the presence) of chronic lung disease.1 In most patients who die of acute covid-19, the initial illness advances insidiously, sometimes with “silent hypoxia” (hypoxia without clinically perceptible symptoms of dyspnoea23), leading to pneumonia followed by acute respiratory distress syndrome, usually in week 2.4 The underlying pathology in covid-19 related hypoxia is probably a ventilation-perfusion mismatch,5 caused by a combination of intrapulmonary shunting, loss of lung perfusion regulation, intravascular microthrombi, and reduced lung compliance leading to alveolar collapse.267

Many patients hospitalised with acute covid-19 have severe hypoxia.478 Hypoxia, silent hypoxia, and the need for supplementary oxygen are all independent predictors of worse outcomes in covid-19.8910111213141516 Novel prognostic tools such as the 4C score have shown the importance of identifying hypoxia early,917 and there are physiological reasons for managing the complication promptly and actively.118

For all these reasons, UK guidelines recommend that assessment and monitoring of breathless, unwell, or high risk patients with suspected covid-19 should include pulse oximetry.1920 Guidance published in January 2021 by the World Health Organization includes a provisional recommendation for “use of pulse oximetry monitoring at home as part of a package of care, including patient and provider education and appropriate follow-up.”21

Home …},
	language = {en},
	urldate = {2021-09-30},
	journal = {BMJ},
	author = {Greenhalgh, Trisha and Knight, Matthew and Inada-Kim, Matt and Fulop, Naomi J. and Leach, Jonathan and Vindrola-Padros, Cecilia},
	month = mar,
	year = {2021},
	pmid = {33766809},
	note = {Publisher: British Medical Journal Publishing Group
Section: Practice},
	pages = {n677},
}

@article{tamura_current_2019,
	title = {Current progress of photoplethysmography and {SPO2} for health monitoring},
	volume = {9},
	issn = {2093-9868},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6431353/},
	doi = {10.1007/s13534-019-00097-w},
	abstract = {A photoplethysmograph (PPG) is a simple medical device for monitoring blood flow and transportation of substances in the blood. It consists of a light source and a photodetector for measuring transmitted and reflected light signals. Clinically, PPGs are used to monitor the pulse rate, oxygen saturation, blood pressure, and blood vessel stiffness. Wearable unobtrusive PPG monitors are commercially available. Here, we review the principle issues and clinical applications of PPG for monitoring oxygen saturation.},
	number = {1},
	urldate = {2021-09-30},
	journal = {Biomedical Engineering Letters},
	author = {Tamura, Toshiyo},
	month = feb,
	year = {2019},
	pmid = {30956878},
	pmcid = {PMC6431353},
	pages = {21--36},
}

@inproceedings{nister_visual_2004,
	title = {Visual odometry},
	volume = {1},
	doi = {10.1109/CVPR.2004.1315094},
	abstract = {We present a system that estimates the motion of a stereo head or a single moving camera based on video input. The system operates in real-time with low delay and the motion estimates are used for navigational purposes. The front end of the system is a feature tracker. Point features are matched between pairs of frames and linked into image trajectories at video rate. Robust estimates of the camera motion are then produced from the feature tracks using a geometric hypothesize-and-test architecture. This generates what we call visual odometry, i.e. motion estimates from visual input alone. No prior knowledge of the scene nor the motion is necessary. The visual odometry can also be used in conjunction with information from other sources such as GPS, inertia sensors, wheel encoders, etc. The pose estimation method has been applied successfully to video from aerial, automotive and handheld platforms. We focus on results with an autonomous ground vehicle. We give examples of camera trajectories estimated purely from images over previously unseen distances and periods of time.},
	booktitle = {Proceedings of the 2004 {IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}, 2004. {CVPR} 2004.},
	author = {Nister, D. and Naroditsky, O. and Bergen, J.},
	month = jun,
	year = {2004},
	note = {ISSN: 1063-6919},
	keywords = {Cameras, Delay estimation, Global Positioning System, Head, Layout, Motion estimation, Navigation, Real time systems, Robustness, Tracking},
	pages = {I--I},
}

@article{gawalko_european_2021,
	title = {The {European} {TeleCheck}-{AF} project on remote app-based management of atrial fibrillation during the {COVID}-19 pandemic: centre and patient experiences},
	volume = {23},
	issn = {1099-5129},
	shorttitle = {The {European} {TeleCheck}-{AF} project on remote app-based management of atrial fibrillation during the {COVID}-19 pandemic},
	url = {https://doi.org/10.1093/europace/euab050},
	doi = {10.1093/europace/euab050},
	abstract = {TeleCheck-AF is a multicentre international project initiated to maintain care delivery for patients with atrial fibrillation (AF) during COVID-19 through teleconsultations supported by an on-demand photoplethysmography-based heart rate and rhythm monitoring app (FibriCheck®). We describe the characteristics, inclusion rates, and experiences from participating centres according the TeleCheck-AF infrastructure as well as characteristics and experiences from recruited patients.Three surveys exploring centre characteristics (n = 25), centre experiences (n = 23), and patient experiences (n = 826) were completed. Self-reported patient characteristics were obtained from the app. Most centres were academic (64\%) and specialized public cardiology/district hospitals (36\%). Majority of the centres had AF outpatient clinics (64\%) and only 36\% had AF ablation clinics. The time required to start patient inclusion and total number of included patients in the project was comparable for centres experienced (56\%) or inexperienced in mHealth use. Within 28 weeks, 1930 AF patients were recruited, mainly for remote AF control (31\% of patients) and AF ablation follow-up (42\%). Average inclusion rate was highest during the lockdown restrictions and reached a steady state at a lower level after easing the restrictions (188 vs. 52 weekly recruited patients). Majority (\&gt;80\%) of the centres reported no problems during the implementation of the TeleCheck-AF approach. Recruited patients [median age 64 (55–71), 62\% male] agreed that the FibriCheck® app was easy to use (94\%).Despite different health care settings and mobile health experiences, the TeleCheck-AF approach could be set up within an extremely short time and easily used in different European centres during COVID-19.},
	number = {7},
	urldate = {2021-09-28},
	journal = {EP Europace},
	author = {Gawałko, Monika and Duncker, David and Manninger, Martin and van der Velden, Rachel M.J. and Hermans, Astrid N.L. and Verhaert, Dominique V.M. and Pison, Laurent and Pisters, Ron and Hemels, Martin and Sultan, Arian and Steven, Daniel and Gupta, Dhiraj and Heidbuchel, Hein and Sohaib, Afzal and Wijtvliet, Petra and Tieleman, Robert and Gruwez, Henri and Chun, Julian and Schmidt, Boris and Keaney, John J. and Müller, Patrick and Lodziński, Piotr and Svennberg, Emma and Hoekstra, Olga and Jansen, Ward P.J. and Desteghe, Lien and de Potter, Tom and Tomlinson, David R. and Neubeck, Lis and Crijns, Harry J.G.M. and Pluymaekers, Nikki A.H.A. and Hendriks, Jeroen M. and Linz, Dominik and {the TeleCheck-AF investigators}},
	month = jul,
	year = {2021},
	pages = {1003--1015},
}

@article{rohmetra_ai-enabled_2021,
	title = {{AI}-enabled remote monitoring of vital signs for {COVID}-19: methods, prospects and challenges},
	issn = {1436-5057},
	shorttitle = {{AI}-enabled remote monitoring of vital signs for {COVID}-19},
	url = {https://doi.org/10.1007/s00607-021-00937-7},
	doi = {10.1007/s00607-021-00937-7},
	abstract = {The COVID-19 pandemic has overwhelmed the existing healthcare infrastructure in many parts of the world. Healthcare professionals are not only over-burdened but also at a high risk of nosocomial transmission from COVID-19 patients. Screening and monitoring the health of a large number of susceptible or infected individuals is a challenging task. Although professional medical attention and hospitalization are necessary for high-risk COVID-19 patients, home isolation is an effective strategy for low and medium risk patients as well as for those who are at risk of infection and have been quarantined. However, this necessitates effective techniques for remotely monitoring the patients’ symptoms. Recent advances in Machine Learning (ML) and Deep Learning (DL) have strengthened the power of imaging techniques and can be used to remotely perform several tasks that previously required the physical presence of a medical professional. In this work, we study the prospects of vital signs monitoring for COVID-19 infected as well as quarantined individuals by using DL and image/signal-processing techniques, many of which can be deployed using simple cameras and sensors available on a smartphone or a personal computer, without the need of specialized equipment. We demonstrate the potential of ML-enabled workflows for several vital signs such as heart and respiratory rates, cough, blood pressure, and oxygen saturation. We also discuss the challenges involved in implementing ML-enabled techniques.},
	language = {en},
	urldate = {2021-09-28},
	journal = {Computing},
	author = {Rohmetra, Honnesh and Raghunath, Navaneeth and Narang, Pratik and Chamola, Vinay and Guizani, Mohsen and Lakkaniga, Naga Rajiv},
	month = mar,
	year = {2021},
}

@article{annis_rapid_2020,
	title = {Rapid implementation of a {COVID}-19 remote patient monitoring program},
	volume = {27},
	issn = {1527-974X},
	url = {https://doi.org/10.1093/jamia/ocaa097},
	doi = {10.1093/jamia/ocaa097},
	abstract = {The study sought to evaluate early lessons from a remote patient monitoring engagement and education technology solution for patients with coronavirus disease 2019 (COVID-19) symptoms.A COVID-19–specific remote patient monitoring solution (GetWell Loop) was offered to patients with COVID-19 symptoms. The program engaged patients and provided educational materials and the opportunity to share concerns. Alerts were resolved through a virtual care workforce of providers and medical students.Between March 18 and April 20, 2020, 2255 of 3701 (60.93\%) patients with COVID-19 symptoms enrolled, resulting in over 2303 alerts, 4613 messages, 13 hospital admissions, and 91 emergency room visits. A satisfaction survey was given to 300 patient respondents, 74\% of whom would be extremely likely to recommend their doctor.This program provided a safe and satisfying experience for patients while minimizing COVID-19 exposure and in-person healthcare utilization.Remote patient monitoring appears to be an effective approach for managing COVID-19 symptoms at home.},
	number = {8},
	urldate = {2021-09-28},
	journal = {Journal of the American Medical Informatics Association},
	author = {Annis, Tucker and Pleasants, Susan and Hultman, Gretchen and Lindemann, Elizabeth and Thompson, Joshua A and Billecke, Stephanie and Badlani, Sameer and Melton, Genevieve B},
	month = aug,
	year = {2020},
	pages = {1326--1330},
}

@article{poh_diagnostic_2018,
	title = {Diagnostic assessment of a deep learning system for detecting atrial fibrillation in pulse waveforms},
	volume = {104},
	copyright = {© Article author(s) (or their employer(s) unless otherwise stated in the text of the article) 2018. All rights reserved. No commercial use is permitted unless otherwise expressly granted.},
	issn = {1355-6037, 1468-201X},
	url = {https://heart.bmj.com/content/104/23/1921},
	doi = {10.1136/heartjnl-2018-313147},
	abstract = {Objective To evaluate the diagnostic performance of a deep learning system for automated detection of atrial fibrillation (AF) in photoplethysmographic (PPG) pulse waveforms.
Methods We trained a deep convolutional neural network (DCNN) to detect AF in 17 s PPG waveforms using a training data set of 149 048 PPG waveforms constructed from several publicly available PPG databases. The DCNN was validated using an independent test data set of 3039 smartphone-acquired PPG waveforms from adults at high risk of AF at a general outpatient clinic against ECG tracings reviewed by two cardiologists. Six established AF detectors based on handcrafted features were evaluated on the same test data set for performance comparison.
Results In the validation data set (3039 PPG waveforms) consisting of three sequential PPG waveforms from 1013 participants (mean (SD) age, 68.4 (12.2) years; 46.8\% men), the prevalence of AF was 2.8\%. The area under the receiver operating characteristic curve (AUC) of the DCNN for AF detection was 0.997 (95\% CI 0.996 to 0.999) and was significantly higher than all the other AF detectors (AUC range: 0.924–0.985). The sensitivity of the DCNN was 95.2\% (95\% CI 88.3\% to 98.7\%), specificity was 99.0\% (95\% CI 98.6\% to 99.3\%), positive predictive value (PPV) was 72.7\% (95\% CI 65.1\% to 79.3\%) and negative predictive value (NPV) was 99.9\% (95\% CI 99.7\% to 100\%) using a single 17 s PPG waveform. Using the three sequential PPG waveforms in combination ({\textless}1 min in total), the sensitivity was 100.0\% (95\% CI 87.7\% to 100\%), specificity was 99.6\% (95\% CI 99.0\% to 99.9\%), PPV was 87.5\% (95\% CI 72.5\% to 94.9\%) and NPV was 100\% (95\% CI 99.4\% to 100\%).
Conclusions In this evaluation of PPG waveforms from adults screened for AF in a real-world primary care setting, the DCNN had high sensitivity, specificity, PPV and NPV for detecting AF, outperforming other state-of-the-art methods based on handcrafted features.},
	language = {en},
	number = {23},
	urldate = {2021-09-28},
	journal = {Heart},
	author = {Poh, Ming-Zher and Poh, Yukkee Cheung and Chan, Pak-Hei and Wong, Chun-Ka and Pun, Louise and Leung, Wangie Wan-Chiu and Wong, Yu-Fai and Wong, Michelle Man-Ying and Chu, Daniel Wai-Sing and Siu, Chung-Wah},
	month = dec,
	year = {2018},
	pmid = {29853485},
	note = {Publisher: BMJ Publishing Group Ltd and British Cardiovascular Society
Section: Arrhythmias and sudden death},
	keywords = {atrial fibrillation, ehealth/telemedicine/mobile health, premature ventricular beats},
	pages = {1921--1928},
}

@article{revanur_first_2021,
	title = {The {First} {Vision} {For} {Vitals} ({V4V}) {Challenge} for {Non}-{Contact} {Video}-{Based} {Physiological} {Estimation}},
	url = {http://arxiv.org/abs/2109.10471},
	abstract = {Telehealth has the potential to offset the high demand for help during public health emergencies, such as the COVID-19 pandemic. Remote Photoplethysmography (rPPG) - the problem of non-invasively estimating blood volume variations in the microvascular tissue from video - would be well suited for these situations. Over the past few years a number of research groups have made rapid advances in remote PPG methods for estimating heart rate from digital video and obtained impressive results. How these various methods compare in naturalistic conditions, where spontaneous behavior, facial expressions, and illumination changes are present, is relatively unknown. To enable comparisons among alternative methods, the 1st Vision for Vitals Challenge (V4V) presented a novel dataset containing high-resolution videos time-locked with varied physiological signals from a diverse population. In this paper, we outline the evaluation protocol, the data used, and the results. V4V is to be held in conjunction with the 2021 International Conference on Computer Vision.},
	urldate = {2021-09-28},
	journal = {arXiv:2109.10471 [cs, eess]},
	author = {Revanur, Ambareesh and Li, Zhihua and Ciftci, Umur A. and Yin, Lijun and Jeni, Laszlo A.},
	month = sep,
	year = {2021},
	note = {arXiv: 2109.10471},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Computers and Society, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing},
}

@article{cheng_prediction_2021,
	title = {Prediction of arterial blood pressure waveforms from photoplethysmogram signals via fully convolutional neural networks},
	volume = {138},
	issn = {0010-4825},
	url = {https://www.sciencedirect.com/science/article/pii/S0010482521006715},
	doi = {10.1016/j.compbiomed.2021.104877},
	abstract = {Cardiovascular disease (CVD) is one of the most serious diseases threatening human health. Arterial blood pressure (ABP) waveforms, containing vivid cardiovascular information, are of great significance for the diagnosis and the prevention of CVD. This paper proposes a deep learning model, named ABP-Net, to transform photoplethysmogram (PPG) signals into ABP waveforms that contain vital physiological information related to cardiovascular systems. In order to guarantee the quality of the predicted ABP waveforms, the structure of the network, the input signals and the loss functions are carefully designed. Specifically, a Wave-U-Net, one kind of fully convolutional neural networks (CNN), is taken as the core architecture of the ABP-Net. Besides the original PPG signals, its first derivative and second derivative signals are all utilized as the inputs of the ABP-Net. Additionally, the maximal absolute loss, accompany with the mean squared error loss is employed to ensure the match of the predicted ABP waveform with the reference one. The performance of the proposed ABP network is tested on the public MIMIC II database both in subject-dependent and subject-independent manners. Both results verify the superior performance of the proposed model over those existing methods accordingly. The mean absolute error (MAE) and the root-mean-square error (RMSE) between the predicted waveforms via the ABP-Net and the reference ones are 3.20 mmHg and 4.38 mmHg during the subject-dependent experiments while those are 5.57 mmHg and 7.15 mmHg during the subject-independent experiments. Benefiting from the predicted high-quality ABP waveforms, more ABP related physiological parameters can be better obtained, which effectively expands the application scope of PPG devices.},
	language = {en},
	urldate = {2021-09-27},
	journal = {Computers in Biology and Medicine},
	author = {Cheng, Juan and Xu, Yufei and Song, Rencheng and Liu, Yu and Li, Chang and Chen, Xun},
	month = nov,
	year = {2021},
	keywords = {Arterial blood pressure waveform, Deep learning, Non-invasive, Photoplethysmography (PPG), Wave-U-Net},
	pages = {104877},
}

@article{kingma_adam_2017,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	shorttitle = {Adam},
	url = {http://arxiv.org/abs/1412.6980},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
	urldate = {2021-09-26},
	journal = {arXiv:1412.6980 [cs]},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	month = jan,
	year = {2017},
	note = {arXiv: 1412.6980},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{lewandowska_measuring_2011,
	title = {Measuring pulse rate with a webcam — {A} non-contact method for evaluating cardiac activity},
	abstract = {In this paper the simple and robust method of measuring the pulse rate is presented. Elaborated algorithm allows for efficient pulse rate registration directly from face image captured from webcam. The desired signal was obtained by proper channel selection and principal component analysis. A developed non-contact method of heart rate monitoring is shown in the paper. The proposed technique may have a great value in monitoring person at home after adequate enhancements are introduced.},
	booktitle = {2011 {Federated} {Conference} on {Computer} {Science} and {Information} {Systems} ({FedCSIS})},
	author = {Lewandowska, Magdalena and Rumiński, Jacek and Kocejko, Tomasz and Nowak, Jędrzej},
	month = sep,
	year = {2011},
	keywords = {Electrocardiography, Face, Forehead, Heart rate, Image color analysis, Principal component analysis, Pulse measurements},
	pages = {405--410},
}

@article{wang_algorithmic_2017,
	title = {Algorithmic {Principles} of {Remote} {PPG}},
	volume = {64},
	issn = {1558-2531},
	doi = {10.1109/TBME.2016.2609282},
	abstract = {This paper introduces a mathematical model that incorporates the pertinent optical and physiological properties of skin reflections with the objective to increase our understanding of the algorithmic principles behind remote photoplethysmography (rPPG). The model is used to explain the different choices that were made in existing rPPG methods for pulse extraction. The understanding that comes from the model can be used to design robust or application-specific rPPG solutions. We illustrate this by designing an alternative rPPG method, where a projection plane orthogonal to the skin tone is used for pulse extraction. A large benchmark on the various discussed rPPG methods shows that their relative merits can indeed be understood from the proposed model.},
	number = {7},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Wang, Wenjin and den Brinker, Albertus C. and Stuijk, Sander and de Haan, Gerard},
	month = jul,
	year = {2017},
	note = {Conference Name: IEEE Transactions on Biomedical Engineering},
	keywords = {Algorithm design and analysis, Biomedical monitoring, Cameras, Color, Image color analysis, Light sources, Mathematical model, Skin, colors, photoplethysmography, remote sensing},
	pages = {1479--1491},
}

@inproceedings{edison_optical_2017,
	title = {Optical {Acceleration} for {Motion} {Description} in {Videos}},
	doi = {10.1109/CVPRW.2017.209},
	abstract = {Modern techniques for describing motion in videos are centred around velocity descriptors based on optical flow. Realizing that acceleration is as important as velocity for describing motion information, in this paper first we propose two different algorithms to compute optical acceleration. Delving deeper into the concept of optical acceleration, we use two descriptors: histogram of optical acceleration (HOA) and histogram of spatial gradient of acceleration (HSGA), to effectively encode the motion information. To assess the effectiveness of these descriptors for motion encoding, we applied it for human action recognition and abnormal event detection in videos. In fact, we used acceleration descriptors in conjunction with velocity descriptors to get a better description of motion in videos. Our experiments reveal that acceleration descriptors could provide additional information that velocity descriptors missed and hence combining them results in a superior motion descriptor.},
	booktitle = {2017 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} {Workshops} ({CVPRW})},
	author = {Edison, Anitha and Jiji, C.V.},
	month = jul,
	year = {2017},
	note = {ISSN: 2160-7516},
	keywords = {Acceleration, Adaptive optics, Biomedical optical imaging, High-speed optical techniques, Histograms, Optical imaging, Videos},
	pages = {1642--1650},
}

@article{reisner_utility_2008,
	title = {Utility of the {Photoplethysmogram} in {Circulatory} {Monitoring}},
	volume = {108},
	issn = {0003-3022},
	url = {https://doi.org/10.1097/ALN.0b013e31816c89e1},
	doi = {10.1097/ALN.0b013e31816c89e1},
	abstract = {The photoplethysmogram is a noninvasive circulatory signal related to the pulsatile volume of blood in tissue and is displayed by many pulse oximeters and bedside monitors, along with the computed arterial oxygen saturation. The photoplethysmogram is similar in appearance to an arterial blood pressure waveform. Because the former is noninvasive and nearly ubiquitous in hospitals whereas the latter requires invasive measurement, the extraction of circulatory information from the photoplethysmogram has been a popular subject of contemporary research. The photoplethysmogram is a function of the underlying circulation, but the relation is complicated by optical, biomechanical, and physiologic covariates that affect the appearance of the photoplethysmogram. Overall, the photoplethysmogram provides a wealth of circulatory information, but its complex etiology may be a limitation in some novel applications.},
	number = {5},
	urldate = {2021-09-21},
	journal = {Anesthesiology},
	author = {Reisner, Andrew and Shaltis, Phillip A. and McCombie, Devin and Asada, H Harry and Warner, David S. and Warner, Mark A.},
	month = may,
	year = {2008},
	pages = {950--958},
}

@article{elgendi_analysis_2012,
	title = {On the {Analysis} of {Fingertip} {Photoplethysmogram} {Signals}},
	volume = {8},
	issn = {1573-403X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3394104/},
	doi = {10.2174/157340312801215782},
	abstract = {Photoplethysmography (PPG) is used to estimate the skin blood flow using infrared light. Researchers from different domains of science have become increasingly interested in PPG because of its advantages as non-invasive, inexpensive, and convenient diagnostic tool. Traditionally, it measures the oxygen saturation, blood pressure, cardiac output, and for assessing autonomic functions. Moreover, PPG is a promising technique for early screening of various atherosclerotic pathologies and could be helpful for regular GP-assessment but a full understanding of the diagnostic value of the different features is still lacking. Recent studies emphasise the potential information embedded in the PPG waveform signal and it deserves further attention for its possible applications beyond pulse oximetry and heart-rate calculation. Therefore, this overview discusses different types of artifact added to PPG signal, characteristic features of PPG waveform, and existing indexes to evaluate for diagnoses.},
	number = {1},
	urldate = {2021-09-21},
	journal = {Current Cardiology Reviews},
	author = {Elgendi, Mohamed},
	month = feb,
	year = {2012},
	pmid = {22845812},
	pmcid = {PMC3394104},
	pages = {14--25},
}

@article{gamrah_mechanics_2020,
	title = {Mechanics of the dicrotic notch: {An} acceleration hypothesis},
	volume = {234},
	issn = {2041-3033},
	shorttitle = {Mechanics of the dicrotic notch},
	doi = {10.1177/0954411920921628},
	abstract = {The dicrotic notch is a prominent and distinctive feature of the pressure waveform in the central arteries. It is universally used to demarcate the end of systole and the beginning of diastole in these arteries. Despite its importance clinically, no physical mechanism for the formation of the dicrotic notch has been demonstrated convincingly. We first explore a mechanism based on the reflection of a backward wavefront from the aortic valve at the time of closure. This hypothesis is rejected on the basis of experimental evidence from measurements made in dogs. A new hypothesis is presented involving the acceleration of the aortic valve apparatus at the time of valve closure. This hypothesis is supported by new calculations of the acceleration of the aortic valve apparatus during the cardiac cycle based on computed tomography scans in man.},
	language = {eng},
	number = {11},
	journal = {Proceedings of the Institution of Mechanical Engineers. Part H, Journal of Engineering in Medicine},
	author = {Gamrah, Mazen Abou and Xu, Jing and El Sawy, Amr and Aguib, Heba and Yacoub, Magdi and Parker, Kim H.},
	month = nov,
	year = {2020},
	pmid = {32403992},
	keywords = {Acceleration, Animals, Aortic Valve, Cardiovascular system mechanics, Dogs, dynamics (biomechanics), haemodynamics, haemodynamics modelling, valve dynamics: haemodynamics, waveforms: haemodynamics},
	pages = {1253--1259},
}

@inproceedings{estepp_recovering_2014,
	title = {Recovering pulse rate during motion artifact with a multi-imager array for non-contact imaging photoplethysmography},
	doi = {10.1109/SMC.2014.6974121},
	abstract = {Photoplethysmography relies on characteristic changes in the optical absorption of tissue due to pulsatile (arterial) blood flow in peripheral vasculature. Sensors for observing the photoplethysmographic effect have traditionally required contact with the skin surface. Recent advances in non-contact imaging photoplethysmography have demonstrated that measures of cardiopulmonary system state, such as pulse rate, pulse rate variability, and respiration rate, can be obtained from a participant by imaging their face under relatively motionless conditions. A critical limitation in this method that must be resolved is the inability to recover these measures under conditions of head motion artifact. To investigate the adequacy of channel space dimensionality for the use of blind source separation in this context, nine synchronized, visible spectrum imagers positioned in a semicircular array centered on the imaged participant were used for data acquisition in a controlled lighting environment. Three-lead electrocardiogram and finger-tip reflectance photoplethysmogram were also recorded as ground truth signals. Controlled head motion artifact trial conditions were compared to trials in which the participant remained stationary, with and without the aid of a chinrest. Bootstrapped means of one-minute, non-overlapping trial segments show that, for situations involving little to no head motion, a single imager is sufficient for recovering pulse rate with an average absolute error of less than two beats per minute. However, error in the recovered pulse rate measurement for the single imager can be as high as twenty-two beats per minute when head motion artifact is severe. This increase in measurement error during motion artifact was mitigated by increasing the dimensionality of the imager channel space with multiple imagers in the array prior to applying blind source separation. In contrast to single-imager results, the multi-imager channel space resulted in an absolute error in the recovered pulse rate measurement that is comparable with pulse rate measured via fingertip reflectance photoplethysmography. These results demonstrate that non-contact, imaging photoplethysmography can be accurate in the presence of head motion artifact when a multi-imager array is implemented to increase the dimensionality of the decomposed channel space.},
	booktitle = {2014 {IEEE} {International} {Conference} on {Systems}, {Man}, and {Cybernetics} ({SMC})},
	author = {Estepp, Justin R. and Blackford, Ethan B. and Meier, Christopher M.},
	month = oct,
	year = {2014},
	note = {ISSN: 1062-922X},
	keywords = {Absorption, Arrays, Electrocardiography, Head, Photoplethysmography, Pulse measurements, Time series analysis, blind source separation, electrocardiography, imaging photoplethysmography, independent component analysis, pulse rate},
	pages = {1462--1469},
}

@inproceedings{ren_faster_2015,
	title = {Faster {R}-{CNN}: {Towards} {Real}-{Time} {Object} {Detection} with {Region} {Proposal} {Networks}},
	volume = {28},
	shorttitle = {Faster {R}-{CNN}},
	url = {https://papers.nips.cc/paper/2015/hash/14bfa6bb14875e45bba028a21ed38046-Abstract.html},
	urldate = {2021-09-18},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
	year = {2015},
}

@article{schrumpf_assessment_nodate,
	title = {Assessment of {Deep} {Learning} {Based} {Blood} {Pressure} {Prediction} {From} {PPG} and {rPPG} {Signals}},
	abstract = {Exploiting photoplethysmography signals (PPG) for non-invasive blood pressure (BP) measurement is interesting for various reasons. First, PPG can easily be measured using ﬁngerclip sensors. Second, camera-based approaches allow to derive remote PPG (rPPG) signals similar to PPG and therefore provide the opportunity for non-invasive measurements of BP. Various methods relying on machine learning techniques have recently been published. Performances are often reported as the mean average error (MAE) on the data which is problematic. This work aims to analyze the PPG- and rPPG-based BP prediction error with respect to the underlying data distribution. First, we train established neural network (NN) architectures and derive an appropriate parameterization of input segments drawn from continuous PPG signals. Second, we apply this parameterization to a larger PPG dataset and train NNs to predict BP. The resulting prediction errors increase towards less frequent BP values. Third, we use transfer learning to train the NNs for rPPG based BP prediction. The resulting performances are similar to the PPG-only case. Finally, we apply a personalization technique and retrain our NNs with subject-speciﬁc data. This slightly reduces the prediction errors.},
	language = {en},
	author = {Schrumpf, Fabian and Frenzel, Patrick and Aust, Christoph and Osterhoff, Georg and Fuchs, Mirco},
	pages = {11},
}

@article{schoettker_blood_2020,
	title = {Blood pressure measurements with the {OptiBP} smartphone app validated against reference auscultatory measurements},
	volume = {10},
	copyright = {2020 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-020-74955-4},
	doi = {10.1038/s41598-020-74955-4},
	abstract = {Mobile health diagnostics have been shown to be effective and scalable for chronic disease detection and management. By maximizing the smartphones’ optics and computational power, they could allow assessment of physiological information from the morphology of pulse waves and thus estimate cuffless blood pressure (BP). We trained the parameters of an existing pulse wave analysis algorithm (oBPM), previously validated in anaesthesia on pulse oximeter signals, by collecting optical signals from 51 patients fingertips via a smartphone while simultaneously acquiring BP measurements through an arterial catheter. We then compared smartphone-based measurements obtained on 50 participants in an ambulatory setting via the OptiBP app against simultaneously acquired auscultatory systolic blood pressure (SBP), diastolic blood pressure (DBP) and mean blood pressure (MBP) measurements. Patients were normotensive (70.0\% for SBP versus 61.4\% for DBP), hypertensive (17.1\% vs. 13.6\%) or hypotensive (12.9\% vs. 25.0\%). The difference in BP (mean ± standard deviation) between both methods were within the ISO 81,060–2:2018 standard for SBP (− 0.7 ± 7.7 mmHg), DBP (− 0.4 ± 4.5 mmHg) and MBP (− 0.6 ± 5.2 mmHg). These results demonstrate that BP can be measured with accuracy at the finger using the OptiBP smartphone app. This may become an important tool to detect hypertension in various settings, for example in low-income countries, where the availability of smartphones is high but access to health care is low.},
	language = {en},
	number = {1},
	urldate = {2021-09-10},
	journal = {Scientific Reports},
	author = {Schoettker, Patrick and Degott, Jean and Hofmann, Gregory and Proença, Martin and Bonnier, Guillaume and Lemkaddem, Alia and Lemay, Mathieu and Schorer, Raoul and Christen, Urvan and Knebel, Jean-François and Wuerzner, Arlene and Burnier, Michel and Wuerzner, Gregoire},
	month = oct,
	year = {2020},
	note = {Bandiera\_abtest: a
Cc\_license\_type: cc\_by
Cg\_type: Nature Research Journals
Number: 1
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Diseases;Health care
Subject\_term\_id: diseases;health-care},
	pages = {17827},
}

@inproceedings{patil_cambp_2017,
	address = {New York, NY, USA},
	series = {{UbiComp} '17},
	title = {{CamBP}: a camera-based, non-contact blood pressure monitor},
	isbn = {978-1-4503-5190-4},
	shorttitle = {{CamBP}},
	url = {https://doi.org/10.1145/3123024.3124428},
	doi = {10.1145/3123024.3124428},
	abstract = {Convenient monitoring of vital signs, particularly blood pressure(BP), is critical to improve the effectiveness of health-care and prevent chronic diseases. This study presents a user-friendly, low-cost, real-time, and non-contact technique for BP measurement based on the detection of photoplethysmography (PPG) using a regular webcam. Leveraging features extracted from photoplethysmograph, an individual's BP can be estimated using a neural network. Experiments were performed on 20 human participants during three different daytime slots given the influence of background illumination. Compared against the systolic blood pressure and diastolic blood pressure readings collected from a commercially available BP monitor, the proposed technique achieves an average error rate of 9.62\% (Systolic BP) and 11.63\% (Diastolic BP) for the afternoon session, and 8.4\% (Systolic BP) and 11.18\% (Diastolic BP) for the evening session. The proposed technique can be easily extended to the camera on any mobile device and thus be widely used in a pervasive manner.},
	urldate = {2021-09-09},
	booktitle = {Proceedings of the 2017 {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing} and {Proceedings} of the 2017 {ACM} {International} {Symposium} on {Wearable} {Computers}},
	publisher = {Association for Computing Machinery},
	author = {Patil, Omkar R. and Gao, Yang and Li, Borui and Jin, Zhanpeng},
	month = sep,
	year = {2017},
	keywords = {PPG, blood pressure, camera, photoplethysmography},
	pages = {524--529},
}

@article{min_genomic_2021,
	title = {Genomic and phenotypic insights from an atlas of genetic effects on {DNA} methylation},
	volume = {53},
	copyright = {2021 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-1718},
	url = {https://www.nature.com/articles/s41588-021-00923-x},
	doi = {10.1038/s41588-021-00923-x},
	abstract = {Characterizing genetic influences on DNA methylation (DNAm) provides an opportunity to understand mechanisms underpinning gene regulation and disease. In the present study, we describe results of DNAm quantitative trait locus (mQTL) analyses on 32,851 participants, identifying genetic variants associated with DNAm at 420,509 DNAm sites in blood. We present a database of {\textgreater}270,000 independent mQTLs, of which 8.5\% comprise long-range (trans) associations. Identified mQTL associations explain 15–17\% of the additive genetic variance of DNAm. We show that the genetic architecture of DNAm levels is highly polygenic. Using shared genetic control between distal DNAm sites, we constructed networks, identifying 405 discrete genomic communities enriched for genomic annotations and complex traits. Shared genetic variants are associated with both DNAm levels and complex diseases, but only in a minority of cases do these associations reflect causal relationships from DNAm to trait or vice versa, indicating a more complex genotype–phenotype map than previously anticipated.},
	language = {en},
	number = {9},
	urldate = {2021-09-08},
	journal = {Nature Genetics},
	author = {Min, Josine L. and Hemani, Gibran and Hannon, Eilis and Dekkers, Koen F. and Castillo-Fernandez, Juan and Luijk, René and Carnero-Montoro, Elena and Lawson, Daniel J. and Burrows, Kimberley and Suderman, Matthew and Bretherick, Andrew D. and Richardson, Tom G. and Klughammer, Johanna and Iotchkova, Valentina and Sharp, Gemma and Al Khleifat, Ahmad and Shatunov, Aleksey and Iacoangeli, Alfredo and McArdle, Wendy L. and Ho, Karen M. and Kumar, Ashish and Söderhäll, Cilla and Soriano-Tárraga, Carolina and Giralt-Steinhauer, Eva and Kazmi, Nabila and Mason, Dan and McRae, Allan F. and Corcoran, David L. and Sugden, Karen and Kasela, Silva and Cardona, Alexia and Day, Felix R. and Cugliari, Giovanni and Viberti, Clara and Guarrera, Simonetta and Lerro, Michael and Gupta, Richa and Bollepalli, Sailalitha and Mandaviya, Pooja and Zeng, Yanni and Clarke, Toni-Kim and Walker, Rosie M. and Schmoll, Vanessa and Czamara, Darina and Ruiz-Arenas, Carlos and Rezwan, Faisal I. and Marioni, Riccardo E. and Lin, Tian and Awaloff, Yvonne and Germain, Marine and Aïssi, Dylan and Zwamborn, Ramona and van Eijk, Kristel and Dekker, Annelot and van Dongen, Jenny and Hottenga, Jouke-Jan and Willemsen, Gonneke and Xu, Cheng-Jian and Barturen, Guillermo and Català-Moll, Francesc and Kerick, Martin and Wang, Carol and Melton, Phillip and Elliott, Hannah R. and Shin, Jean and Bernard, Manon and Yet, Idil and Smart, Melissa and Gorrie-Stone, Tyler and Shaw, Chris and Al Chalabi, Ammar and Ring, Susan M. and Pershagen, Göran and Melén, Erik and Jiménez-Conde, Jordi and Roquer, Jaume and Lawlor, Deborah A. and Wright, John and Martin, Nicholas G. and Montgomery, Grant W. and Moffitt, Terrie E. and Poulton, Richie and Esko, Tõnu and Milani, Lili and Metspalu, Andres and Perry, John R. B. and Ong, Ken K. and Wareham, Nicholas J. and Matullo, Giuseppe and Sacerdote, Carlotta and Panico, Salvatore and Caspi, Avshalom and Arseneault, Louise and Gagnon, France and Ollikainen, Miina and Kaprio, Jaakko and Felix, Janine F. and Rivadeneira, Fernando and Tiemeier, Henning and van IJzendoorn, Marinus H. and Uitterlinden, André G. and Jaddoe, Vincent W. V. and Haley, Chris and McIntosh, Andrew M. and Evans, Kathryn L. and Murray, Alison and Räikkönen, Katri and Lahti, Jari and Nohr, Ellen A. and Sørensen, Thorkild I. A. and Hansen, Torben and Morgen, Camilla S. and Binder, Elisabeth B. and Lucae, Susanne and Gonzalez, Juan Ramon and Bustamante, Mariona and Sunyer, Jordi and Holloway, John W. and Karmaus, Wilfried and Zhang, Hongmei and Deary, Ian J. and Wray, Naomi R. and Starr, John M. and Beekman, Marian and van Heemst, Diana and Slagboom, P. Eline and Morange, Pierre-Emmanuel and Trégouët, David-Alexandre and Veldink, Jan H. and Davies, Gareth E. and de Geus, Eco J. C. and Boomsma, Dorret I. and Vonk, Judith M. and Brunekreef, Bert and Koppelman, Gerard H. and Alarcón-Riquelme, Marta E. and Huang, Rae-Chi and Pennell, Craig E. and van Meurs, Joyce and Ikram, M. Arfan and Hughes, Alun D. and Tillin, Therese and Chaturvedi, Nish and Pausova, Zdenka and Paus, Tomas and Spector, Timothy D. and Kumari, Meena and Schalkwyk, Leonard C. and Visscher, Peter M. and Davey Smith, George and Bock, Christoph and Gaunt, Tom R. and Bell, Jordana T. and Heijmans, Bastiaan T. and Mill, Jonathan and Relton, Caroline L.},
	month = sep,
	year = {2021},
	note = {Bandiera\_abtest: a
Cg\_type: Nature Research Journals
Number: 9
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Epigenetics;Genetics research
Subject\_term\_id: epigenetics;genetics-research},
	pages = {1311--1321},
}

@article{hane_predicting_2020,
	title = {Predicting {Onset} of {Dementia} {Using} {Clinical} {Notes} and {Machine} {Learning}: {Case}-{Control} {Study}},
	volume = {8},
	copyright = {Unless stated otherwise, all articles are open-access distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/2.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work ("first published in the Journal of Medical Internet Research...") is properly cited with original URL and bibliographic citation information. The complete bibliographic information, a link to the original publication on http://www.jmir.org/, as well as this copyright and license information must be included.},
	shorttitle = {Predicting {Onset} of {Dementia} {Using} {Clinical} {Notes} and {Machine} {Learning}},
	url = {https://medinform.jmir.org/2020/6/e17819},
	doi = {10.2196/17819},
	abstract = {Background: Clinical trials need efficient tools to assist in recruiting patients at risk of Alzheimer disease and related dementias (ADRD). Early detection can also assist patients with financial planning for long-term care. Clinical notes are an important, underutilized source of information in machine learning models because of the cost of collection and complexity of analysis.
Objective: This study aimed to investigate the use of deidentified clinical notes from multiple hospital systems collected over 10 years to augment retrospective machine learning models of the risk of developing ADRD.
Methods: We used 2 years of data to predict the future outcome of ADRD onset. Clinical notes are provided in a deidentified format with specific terms and sentiments. Terms in clinical notes are embedded into a 100-dimensional vector space to identify clusters of related terms and abbreviations that differ across hospital systems and individual clinicians.
Results: When using clinical notes, the area under the curve (AUC) improved from 0.85 to 0.94, and positive predictive value (PPV) increased from 45.07\% (25,245/56,018) to 68.32\% (14,153/20,717) in the model at disease onset. Models with clinical notes improved in both AUC and PPV in years 3-6 when notes’ volume was largest; results are mixed in years 7 and 8 with the smallest cohorts.
Conclusions: Although clinical notes helped in the short term, the presence of ADRD symptomatic terms years earlier than onset adds evidence to other studies that clinicians undercode diagnoses of ADRD. De-identified clinical notes increase the accuracy of risk models. Clinical notes collected across multiple hospital systems via natural language processing can be merged using postprocessing techniques to aid model accuracy.},
	language = {EN},
	number = {6},
	urldate = {2021-09-07},
	journal = {JMIR Medical Informatics},
	author = {Hane, Christopher A. and Nori, Vijay S. and Crown, William H. and Sanghavi, Darshak M. and Bleicher, Paul},
	month = jun,
	year = {2020},
	note = {Company: JMIR Medical Informatics
Distributor: JMIR Medical Informatics
Institution: JMIR Medical Informatics
Label: JMIR Medical Informatics
Publisher: JMIR Publications Inc., Toronto, Canada},
	pages = {e17819},
}

@inproceedings{zhang_inductive_2020,
	title = {Inductive {Matrix} {Completion} {Based} on {Graph} {Neural} {Networks}},
	url = {https://iclr.cc/virtual_2020/poster_ByxxgCEYDS.html},
	abstract = {We propose an inductive matrix completion model without using side information. By factorizing the (rating) matrix into the product of low-dimensional latent embeddings of rows (users) and columns (items), a majority of existing matrix completion methods are transductive, since the learned embeddings cannot generalize to unseen rows/columns or to new matrices. To make matrix completion inductive, most previous works use content (side information), such as user's age or movie's genre, to make predictions. However, high-quality content is not always available, and can be hard to extract. Under the extreme setting where not any side information is available other than the matrix to complete, can we still learn an inductive matrix completion model? In this paper, we propose an Inductive Graph-based Matrix Completion (IGMC) model to address this problem. IGMC trains a graph neural network (GNN) based purely on 1-hop subgraphs around (user, item) pairs generated from the rating matrix and maps these subgraphs to their corresponding ratings. It achieves highly competitive performance with state-of-the-art transductive baselines. In addition, IGMC is inductive -- it can generalize to users/items unseen during the training (given that their interactions exist), and can even transfer to new tasks. Our transfer learning experiments show that a model trained out of the MovieLens dataset can be directly used to predict Douban movie ratings with surprisingly good performance. Our work demonstrates that: 1) it is possible to train inductive matrix completion models without using side information while achieving similar or better performances than state-of-the-art transductive methods; 2) local graph patterns around a (user, item) pair are effective predictors of the rating this user gives to the item; and 3) Long-range dependencies might not be necessary for modeling recommender systems.},
	language = {en},
	urldate = {2021-09-07},
	author = {Zhang, Muhan and Chen, Yixin},
	month = apr,
	year = {2020},
}

@techreport{hormozdiari_deepnull_2021,
	title = {{DeepNull}: {Modeling} non-linear covariate effects improves phenotype prediction and association power},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NoDerivs 4.0 International), CC BY-ND 4.0, as described at http://creativecommons.org/licenses/by-nd/4.0/},
	shorttitle = {{DeepNull}},
	url = {https://www.biorxiv.org/content/10.1101/2021.05.26.445783v1},
	abstract = {Genome-wide association studies (GWAS) are among the workhorses of statistical genetics, having detected thousands of variants associated with complex traits and diseases. A typical GWAS examines the association between genotypes and the phenotype of interest while adjusting for a set of covariates. While covariates potentially have non-linear effects on the phenotype in many real world settings, due to the challenge of specifying the model, GWAS seldom include non-linear terms. Here we introduce DeepNull, a method that models non-linear covariate effects on phenotypes using a deep neural network (DNN) and then includes the model prediction as a single extra term in the GWAS association. First, using simulated data, we show that DeepNull increases statistical power by up to 20\% while maintaining tight control of the type I error in the presence of interactions or non-linear covariate effects. Second, DeepNull maintains similar results to a standard GWAS when covariates have only linear effects on the phenotype. Third, DeepNull detects larger numbers of significant hits and loci (7\% additional loci averaged over 10 traits) than standard GWAS in ten phenotypes from the UK Biobank (n=370K). Many of the hits found only by DeepNull are biologically plausible or have previously been reported in the GWAS catalog. Finally, DeepNull improves phenotype prediction by 23\% averaged over the same ten phenotypes, the highest improvement was observed in the case of Glaucoma referral probability where DeepNull improves the phenotype prediction by 83\%.},
	language = {en},
	urldate = {2021-09-07},
	author = {Hormozdiari, Farhad and McCaw, Zachary R. and Colthurst, Thomas and Yun, Taedong and Furlotte, Nick and Carroll, Andrew and Alipanahi, Babak and McLean, Cory Y.},
	month = may,
	year = {2021},
	doi = {10.1101/2021.05.26.445783},
	note = {Company: Cold Spring Harbor Laboratory
Distributor: Cold Spring Harbor Laboratory
Label: Cold Spring Harbor Laboratory
Section: New Results
Type: article},
	pages = {2021.05.26.445783},
}

@article{mohan_graphical_2021,
	title = {Graphical {Models} for {Processing} {Missing} {Data}},
	volume = {116},
	issn = {0162-1459},
	url = {https://doi.org/10.1080/01621459.2021.1874961},
	doi = {10.1080/01621459.2021.1874961},
	abstract = {This article reviews recent advances in missing data research using graphical models to represent multivariate dependencies. We first examine the limitations of traditional frameworks from three different perspectives: transparency, estimability, and testability. We then show how procedures based on graphical models can overcome these limitations and provide meaningful performance guarantees even when data are missing not at random (MNAR). In particular, we identify conditions that guarantee consistent estimation in broad categories of missing data problems, and derive procedures for implementing this estimation. Finally, we derive testable implications for missing data models in both missing at random and MNAR categories.},
	number = {534},
	urldate = {2021-09-07},
	journal = {Journal of the American Statistical Association},
	author = {Mohan, Karthika and Pearl, Judea},
	month = apr,
	year = {2021},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/01621459.2021.1874961},
	keywords = {Graphical models, Missing data, Missing not at random, Nonignorable, Recoverability, Testability},
	pages = {1023--1037},
}

@article{nazabal_handling_2020,
	title = {Handling {Incomplete} {Heterogeneous} {Data} using {VAEs}},
	url = {http://arxiv.org/abs/1807.03653},
	abstract = {Variational autoencoders (VAEs), as well as other generative models, have been shown to be efficient and accurate for capturing the latent structure of vast amounts of complex high-dimensional data. However, existing VAEs can still not directly handle data that are heterogenous (mixed continuous and discrete) or incomplete (with missing data at random), which is indeed common in real-world applications. In this paper, we propose a general framework to design VAEs suitable for fitting incomplete heterogenous data. The proposed HI-VAE includes likelihood models for real-valued, positive real valued, interval, categorical, ordinal and count data, and allows accurate estimation (and potentially imputation) of missing data. Furthermore, HI-VAE presents competitive predictive performance in supervised tasks, outperforming supervised models when trained on incomplete data.},
	urldate = {2021-09-07},
	journal = {arXiv:1807.03653 [cs, stat]},
	author = {Nazabal, Alfredo and Olmos, Pablo M. and Ghahramani, Zoubin and Valera, Isabel},
	month = may,
	year = {2020},
	note = {arXiv: 1807.03653},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{fortuin_som-vae_2019,
	title = {{SOM}-{VAE}: {Interpretable} {Discrete} {Representation} {Learning} on {Time} {Series}},
	shorttitle = {{SOM}-{VAE}},
	url = {http://arxiv.org/abs/1806.02199},
	abstract = {High-dimensional time series are common in many domains. Since human cognition is not optimized to work well in high-dimensional spaces, these areas could benefit from interpretable low-dimensional representations. However, most representation learning algorithms for time series data are difficult to interpret. This is due to non-intuitive mappings from data features to salient properties of the representation and non-smoothness over time. To address this problem, we propose a new representation learning framework building on ideas from interpretable discrete dimensionality reduction and deep generative modeling. This framework allows us to learn discrete representations of time series, which give rise to smooth and interpretable embeddings with superior clustering performance. We introduce a new way to overcome the non-differentiability in discrete representation learning and present a gradient-based version of the traditional self-organizing map algorithm that is more performant than the original. Furthermore, to allow for a probabilistic interpretation of our method, we integrate a Markov model in the representation space. This model uncovers the temporal transition structure, improves clustering performance even further and provides additional explanatory insights as well as a natural representation of uncertainty. We evaluate our model in terms of clustering performance and interpretability on static (Fashion-)MNIST data, a time series of linearly interpolated (Fashion-)MNIST images, a chaotic Lorenz attractor system with two macro states, as well as on a challenging real world medical time series application on the eICU data set. Our learned representations compare favorably with competitor methods and facilitate downstream tasks on the real world data.},
	urldate = {2021-09-07},
	journal = {arXiv:1806.02199 [cs, stat]},
	author = {Fortuin, Vincent and Hüser, Matthias and Locatello, Francesco and Strathmann, Heiko and Rätsch, Gunnar},
	month = jan,
	year = {2019},
	note = {arXiv: 1806.02199},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{bent_engineering_2021,
	title = {Engineering digital biomarkers of interstitial glucose from noninvasive smartwatches},
	volume = {4},
	copyright = {2021 The Author(s)},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-021-00465-w},
	doi = {10.1038/s41746-021-00465-w},
	abstract = {Prediabetes affects one in three people and has a 10\% annual conversion rate to type 2 diabetes without lifestyle or medical interventions. Management of glycemic health is essential to prevent progression to type 2 diabetes. However, there is currently no commercially-available and noninvasive method for monitoring glycemic health to aid in self-management of prediabetes. There is a critical need for innovative, practical strategies to improve monitoring and management of glycemic health. In this study, using a dataset of 25,000 simultaneous interstitial glucose and noninvasive wearable smartwatch measurements, we demonstrated the feasibility of using noninvasive and widely accessible methods, including smartwatches and food logs recorded over 10 days, to continuously detect personalized glucose deviations and to predict the exact interstitial glucose value in real time with up to 84\% and 87\% accuracy, respectively. We also establish methods for designing variables using data-driven and domain-driven methods from noninvasive wearables toward interstitial glucose prediction.},
	language = {en},
	number = {1},
	urldate = {2021-08-31},
	journal = {npj Digital Medicine},
	author = {Bent, Brinnae and Cho, Peter J. and Henriquez, Maria and Wittmann, April and Thacker, Connie and Feinglos, Mark and Crowley, Matthew J. and Dunn, Jessilyn P.},
	month = jun,
	year = {2021},
	note = {Bandiera\_abtest: a
Cc\_license\_type: cc\_by
Cg\_type: Nature Research Journals
Number: 1
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Biomarkers;Biomedical engineering;Pre-diabetes
Subject\_term\_id: biomarkers;biomedical-engineering;pre-diabetes},
	pages = {1--11},
}

@article{moco_new_2018,
	title = {New insights into the origin of remote {PPG} signals in visible light and infrared},
	volume = {8},
	copyright = {2018 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-018-26068-2},
	doi = {10.1038/s41598-018-26068-2},
	abstract = {Remote photoplethysmography (PPG) is an optical measurement technique with established applications in vital signs monitoring. Recently, the consensual understanding of blood volume variations (BVVs) as the origin of PPG signals was challenged, raising validity concerns about the remote SpO2 methodology. Recognizing the imperative for new opto-physiological evidence, this investigation supports the volumetric hypothesis with living skin experiments and Monte Carlo simulations of remote PPG-amplitude in visible light (VIS) and infrared (IR). Multilayered models of the skin were developed to simulate the separate contributions from skin layers containing pulsatile arterioles to the PPG signal in the 450–1000 nm range. The simulated spectra were qualitatively compared with observations of the resting and compressed finger pad, and complemented with videocapillaroscopy. Our results indicate that remote PPG systems indeed probe arterial blood. Green wavelengths probe dermal arterioles while red-IR wavelengths also reach subcutaneous BVVs. Owing to stable penetration depths, the red-IR diagnostic window promotes the invariance of SpO2 measurements to skin non-homogeneities.},
	language = {en},
	number = {1},
	urldate = {2021-08-27},
	journal = {Scientific Reports},
	author = {Moço, Andreia V. and Stuijk, Sander and de Haan, Gerard},
	month = may,
	year = {2018},
	note = {Bandiera\_abtest: a
Cc\_license\_type: cc\_by
Cg\_type: Nature Research Journals
Number: 1
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Biomedical engineering;Health care
Subject\_term\_id: biomedical-engineering;health-care},
	pages = {8501},
}

@article{cohen_personalized_2021,
	title = {Personalized lab test models to quantify disease potentials in healthy individuals},
	copyright = {2021 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-170X},
	url = {https://www.nature.com/articles/s41591-021-01468-6},
	doi = {10.1038/s41591-021-01468-6},
	abstract = {Standardized lab tests are central for patient evaluation, differential diagnosis and treatment. Interpretation of these data is nevertheless lacking quantitative and personalized metrics. Here we report on the modeling of 2.1 billion lab measurements of 92 different lab tests from 2.8 million adults over a span of 18 years. Following unsupervised filtering of 131 chronic conditions and 5,223 drug–test pairs we performed a virtual survey of lab tests distributions in healthy individuals. Age and sex alone explain less than 10\% of the within-normal test variance in 89 out of 92 tests. Personalized models based on patients’ history explain 60\% of the variance for 17 tests and over 36\% for half of the tests. This allows for systematic stratification of the risk for future abnormal test levels and subsequent emerging disease. Multivariate modeling of within-normal lab tests can be readily implemented as a basis for quantitative patient evaluation.},
	language = {en},
	urldate = {2021-08-27},
	journal = {Nature Medicine},
	author = {Cohen, Netta Mendelson and Schwartzman, Omer and Jaschek, Ram and Lifshitz, Aviezer and Hoichman, Michael and Balicer, Ran and Shlush, Liran I. and Barbash, Gabi and Tanay, Amos},
	month = aug,
	year = {2021},
	note = {Bandiera\_abtest: a
Cg\_type: Nature Research Journals
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Medical research;Risk factors
Subject\_term\_id: medical-research;risk-factors},
	pages = {1--10},
}

@article{lu_dual-gan_nodate,
	title = {Dual-{GAN}: {Joint} {BVP} and {Noise} {Modeling} for {Remote} {Physiological} {Measurement}},
	abstract = {Remote photoplethysmography (rPPG) based physiological measurement has great application values in health monitoring, emotion analysis, etc. Existing methods mainly focus on how to enhance or extract the very weak blood volume pulse (BVP) signals from face videos, but seldom explicitly model the noises that dominate face video content. Thus, they may suffer from poor generalization ability in unseen scenarios. This paper proposes a novel adversarial learning approach for rPPG based physiological measurement by using Dual Generative Adversarial Networks (Dual-GAN) to model the BVP predictor and noise distribution jointly. The BVP-GAN aims to learn a noiseresistant mapping from input to ground-truth BVP, and the Noise-GAN aims to learn the noise distribution. The two GANs can promote each other’s capability, leading to improved feature disentanglement between BVP and noises. Besides, a plug-and-play block named ROI alignment and fusion (ROI-AF) block is proposed to alleviate the inconsistencies between different ROIs and exploit informative features from a wider receptive ﬁeld in terms of ROIs. In comparison to state-of-the-art methods, our approach achieves better performance in heart rate, heart rate variability, and respiration frequency estimation from face videos.},
	language = {en},
	author = {Lu, Hao and Han, Hu and Zhou, S Kevin},
	pages = {10},
}

@inproceedings{tsou_siamese-rppg_2020,
	address = {New York, NY, USA},
	series = {{SAC} '20},
	title = {Siamese-{rPPG} network: remote photoplethysmography signal estimation from face videos},
	isbn = {978-1-4503-6866-7},
	shorttitle = {Siamese-{rPPG} network},
	url = {https://doi.org/10.1145/3341105.3373905},
	doi = {10.1145/3341105.3373905},
	abstract = {Remote photoplethysmography (rPPG) is a contactless method for heart rate (HR) estimation from face videos. In this paper, we propose to estimate rPPG signals directly from input video sequences in an end-to-end manner. We propose a novel Siamese-rPPG network to simultaneously learn the heterogeneous and homogeneous features from two facial regions. Furthermore, to analyze the temporal periodicity of rPPG signals, we construct the network with 3D CNNs and jointly train the two-branch model under the negative Pearson loss function. Experimental results on three benchmark datasets: COHFACE, UBFC, and PURE, show that our method significantly outperforms existing methods with a large margin.},
	urldate = {2021-08-24},
	booktitle = {Proceedings of the 35th {Annual} {ACM} {Symposium} on {Applied} {Computing}},
	publisher = {Association for Computing Machinery},
	author = {Tsou, Yun-Yun and Lee, Yi-An and Hsu, Chiou-Ting and Chang, Shang-Hung},
	month = mar,
	year = {2020},
	keywords = {heart rate detection, pearson correlation, region-of-interest, remote photoplethysmography, siamese network},
	pages = {2066--2073},
}

@article{wallace_optum_2014,
	title = {Optum {Labs}: {Building} {A} {Novel} {Node} {In} {The} {Learning} {Health} {Care} {System}},
	volume = {33},
	issn = {0278-2715},
	shorttitle = {Optum {Labs}},
	url = {https://www.healthaffairs.org/doi/10.1377/hlthaff.2014.0038},
	doi = {10.1377/hlthaff.2014.0038},
	abstract = {Unprecedented change in the US health care system is being driven by the rapid uptake of health information technology and national investments in multi-institution research networks comprising academic centers, health care delivery systems, and other health system components. An example of this changing landscape is Optum Labs, a novel network “node” that is bringing together new partners, data, and analytic techniques to implement research findings in health care practice. Optum Labs was founded in early 2013 by Mayo Clinic and Optum, a commercial data, infrastructure services, and care organization that is part of UnitedHealth Group. Optum Labs now has eleven collaborators and a database of deidentified information on more than 150 million people that is compliant with the Health Insurance Portability and Accountability Act (HIPAA) of 1996. This article describes the early progress of Optum Labs. The combination of the diverse collaborator perspectives with rich data, including deep patient and provider information, is intended to reveal new insights about diseases, treatments, and patients’ behavior to guide changes in practice. Practitioners’ involvement in agenda setting and translation of findings into practical care innovations accelerates the implementation of research results. Furthermore, feedback loops from the clinic help Optum Labs expand on successes and give quick attention to challenges as they emerge.},
	number = {7},
	urldate = {2021-08-10},
	journal = {Health Affairs},
	author = {Wallace, Paul J. and Shah, Nilay D. and Dennen, Taylor and Bleicher, Paul A. and Crown, William H.},
	month = jul,
	year = {2014},
	note = {Publisher: Health Affairs},
	pages = {1187--1194},
}

@article{song_pulsegan_2020,
	title = {{PulseGAN}: {Learning} to generate realistic pulse waveforms in remote photoplethysmography},
	shorttitle = {{PulseGAN}},
	url = {http://arxiv.org/abs/2006.02699},
	abstract = {Remote photoplethysmography (rPPG) is a non-contact technique for measuring cardiac signals from facial videos. High-quality rPPG pulse signals are urgently demanded in many fields, such as health monitoring and emotion recognition. However, most of the existing rPPG methods can only be used to get average heart rate (HR) values due to the limitation of inaccurate pulse signals. In this paper, a new framework based on generative adversarial network, called PulseGAN, is introduced to generate realistic rPPG pulse signals through denoising the chrominance signals. Considering that the cardiac signal is quasi-periodic and has apparent time-frequency characteristics, the error losses defined in time and spectrum domains are both employed with the adversarial loss to enforce the model generating accurate pulse waveforms as its reference. The proposed framework is tested on the public UBFC-RPPG database in both within-database and cross-database configurations. The results show that the PulseGAN framework can effectively improve the waveform quality, thereby enhancing the accuracy of HR, the heart rate variability (HRV) and the interbeat interval (IBI). The proposed method achieves the best performance compared to the denoising autoencoder (DAE) and CHROM, with the mean absolute error of AVNN (the average of all normal-to-normal intervals) improving 20.85\% and 41.19\%, and the mean absolute error of SDNN (the standard deviation of all NN intervals) improving 20.28\% and 37.53\%, respectively, in the cross-database test. This framework can be easily extended to other existing deep learning based rPPG methods, which is expected to expand the application scope of rPPG techniques.},
	urldate = {2021-08-10},
	journal = {arXiv:2006.02699 [eess]},
	author = {Song, Rencheng and Chen, Huan and Cheng, Juan and Li, Chang and Liu, Yu and Chen, Xun},
	month = jun,
	year = {2020},
	note = {arXiv: 2006.02699},
	keywords = {Electrical Engineering and Systems Science - Image and Video Processing},
}

@article{xiao_audiovisual_2020,
	title = {Audiovisual {SlowFast} {Networks} for {Video} {Recognition}},
	url = {http://arxiv.org/abs/2001.08740},
	abstract = {We present Audiovisual SlowFast Networks, an architecture for integrated audiovisual perception. AVSlowFast has Slow and Fast visual pathways that are deeply integrated with a Faster Audio pathway to model vision and sound in a unified representation. We fuse audio and visual features at multiple layers, enabling audio to contribute to the formation of hierarchical audiovisual concepts. To overcome training difficulties that arise from different learning dynamics for audio and visual modalities, we introduce DropPathway, which randomly drops the Audio pathway during training as an effective regularization technique. Inspired by prior studies in neuroscience, we perform hierarchical audiovisual synchronization to learn joint audiovisual features. We report state-of-the-art results on six video action classification and detection datasets, perform detailed ablation studies, and show the generalization of AVSlowFast to learn self-supervised audiovisual features. Code will be made available at: https://github.com/facebookresearch/SlowFast.},
	urldate = {2021-08-09},
	journal = {arXiv:2001.08740 [cs]},
	author = {Xiao, Fanyi and Lee, Yong Jae and Grauman, Kristen and Malik, Jitendra and Feichtenhofer, Christoph},
	month = mar,
	year = {2020},
	note = {arXiv: 2001.08740},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{zhang_heart_2020,
	title = {Heart rate measurement based on video acceleration magnification},
	doi = {10.1109/CCDC49329.2020.9164451},
	abstract = {The aim of this study is to improve the effect of Eulerian video magnification in non-contact heart rate measurement. Extracting the heart rate information from subtle head movements caused by blood circulation, we overcome the adverse condition that the person in the measurement should be completely still. Firstly, the temporal acceleration filter is used to preprocess the video and filter out the large low-frequency motion in the video. Secondly, face recognition is performed on each frame of the pre-processing video and face regions are cut out. The tracked face regions are reorganized to further reduce the impact of large movements. Heart rate information could be extracted from this reconstituted video. Experiment results indicate that the proposed method is more accurate in dynamic heart rate monitoring.},
	booktitle = {2020 {Chinese} {Control} {And} {Decision} {Conference} ({CCDC})},
	author = {Zhang, Jiahui and Zhang, Ke and Yang, Xinhao and Wen, Chenrui},
	month = aug,
	year = {2020},
	note = {ISSN: 1948-9447},
	keywords = {Acceleration, Eulerian video magnification, Face, Heart rate measurement, Standards, Tracking, non-contact heart rate estimation, spatio-temporal analysis, video acceleration magnification},
	pages = {1179--1182},
}

@inproceedings{zhang_video_2017,
	address = {Honolulu, HI},
	title = {Video {Acceleration} {Magnification}},
	isbn = {978-1-5386-0457-1},
	url = {https://ieeexplore.ieee.org/document/8099544/},
	doi = {10.1109/CVPR.2017.61},
	abstract = {The ability to amplify or reduce subtle image changes over time is useful in contexts such as video editing, medical video analysis, product quality control and sports. In these contexts there is often large motion present which severely distorts current video ampliﬁcation methods that magnify change linearly. In this work we propose a method to cope with large motions while still magnifying small changes. We make the following two observations: i) large motions are linear on the temporal scale of the small changes; ii) small changes deviate from this linearity. We ignore linear motion and propose to magnify acceleration. Our method is pure Eulerian and does not require any optical ﬂow, temporal alignment or region annotations. We link temporal secondorder derivative ﬁltering to spatial acceleration magniﬁcation. We apply our method to moving objects where we show motion magniﬁcation and color magniﬁcation. We provide quantitative as well as qualitative evidence for our method while comparing to the state-of-the-art.},
	language = {en},
	urldate = {2021-08-09},
	booktitle = {2017 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Zhang, Yichao and Pintea, Silvia L. and Van Gemert, Jan C.},
	month = jul,
	year = {2017},
	pages = {502--510},
}

@article{xiao_audiovisual_2020-1,
	title = {Audiovisual {SlowFast} {Networks} for {Video} {Recognition}},
	url = {http://arxiv.org/abs/2001.08740},
	abstract = {We present Audiovisual SlowFast Networks, an architecture for integrated audiovisual perception. AVSlowFast has Slow and Fast visual pathways that are deeply integrated with a Faster Audio pathway to model vision and sound in a unified representation. We fuse audio and visual features at multiple layers, enabling audio to contribute to the formation of hierarchical audiovisual concepts. To overcome training difficulties that arise from different learning dynamics for audio and visual modalities, we introduce DropPathway, which randomly drops the Audio pathway during training as an effective regularization technique. Inspired by prior studies in neuroscience, we perform hierarchical audiovisual synchronization to learn joint audiovisual features. We report state-of-the-art results on six video action classification and detection datasets, perform detailed ablation studies, and show the generalization of AVSlowFast to learn self-supervised audiovisual features. Code will be made available at: https://github.com/facebookresearch/SlowFast.},
	urldate = {2021-08-09},
	journal = {arXiv:2001.08740 [cs]},
	author = {Xiao, Fanyi and Lee, Yong Jae and Grauman, Kristen and Malik, Jitendra and Feichtenhofer, Christoph},
	month = mar,
	year = {2020},
	note = {arXiv: 2001.08740},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{liu_swin_2021,
	title = {Swin {Transformer}: {Hierarchical} {Vision} {Transformer} using {Shifted} {Windows}},
	shorttitle = {Swin {Transformer}},
	url = {http://arxiv.org/abs/2103.14030},
	abstract = {This paper presents a new vision Transformer, called Swin Transformer, that capably serves as a general-purpose backbone for computer vision. Challenges in adapting Transformer from language to vision arise from differences between the two domains, such as large variations in the scale of visual entities and the high resolution of pixels in images compared to words in text. To address these differences, we propose a hierarchical Transformer whose representation is computed with shifted windows. The shifted windowing scheme brings greater efficiency by limiting self-attention computation to non-overlapping local windows while also allowing for cross-window connection. This hierarchical architecture has the flexibility to model at various scales and has linear computational complexity with respect to image size. These qualities of Swin Transformer make it compatible with a broad range of vision tasks, including image classification (86.4 top-1 accuracy on ImageNet-1K) and dense prediction tasks such as object detection (58.7 box AP and 51.1 mask AP on COCO test-dev) and semantic segmentation (53.5 mIoU on ADE20K val). Its performance surpasses the previous state-of-the-art by a large margin of +2.7 box AP and +2.6 mask AP on COCO, and +3.2 mIoU on ADE20K, demonstrating the potential of Transformer-based models as vision backbones. The code and models will be made publicly available at{\textasciitilde}{\textbackslash}url\{https://github.com/microsoft/Swin-Transformer\}.},
	urldate = {2021-08-09},
	journal = {arXiv:2103.14030 [cs]},
	author = {Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
	month = mar,
	year = {2021},
	note = {arXiv: 2103.14030},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{bertasius_is_2021,
	title = {Is {Space}-{Time} {Attention} {All} {You} {Need} for {Video} {Understanding}?},
	url = {http://arxiv.org/abs/2102.05095},
	abstract = {We present a convolution-free approach to video classification built exclusively on self-attention over space and time. Our method, named "TimeSformer," adapts the standard Transformer architecture to video by enabling spatiotemporal feature learning directly from a sequence of frame-level patches. Our experimental study compares different self-attention schemes and suggests that "divided attention," where temporal attention and spatial attention are separately applied within each block, leads to the best video classification accuracy among the design choices considered. Despite the radically new design, TimeSformer achieves state-of-the-art results on several action recognition benchmarks, including the best reported accuracy on Kinetics-400 and Kinetics-600. Finally, compared to 3D convolutional networks, our model is faster to train, it can achieve dramatically higher test efficiency (at a small drop in accuracy), and it can also be applied to much longer video clips (over one minute long). Code and models are available at: https://github.com/facebookresearch/TimeSformer.},
	urldate = {2021-08-09},
	journal = {arXiv:2102.05095 [cs]},
	author = {Bertasius, Gedas and Wang, Heng and Torresani, Lorenzo},
	month = jun,
	year = {2021},
	note = {arXiv: 2102.05095},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{arnab_vivit_2021,
	title = {{ViViT}: {A} {Video} {Vision} {Transformer}},
	shorttitle = {{ViViT}},
	url = {http://arxiv.org/abs/2103.15691},
	abstract = {We present pure-transformer based models for video classification, drawing upon the recent success of such models in image classification. Our model extracts spatio-temporal tokens from the input video, which are then encoded by a series of transformer layers. In order to handle the long sequences of tokens encountered in video, we propose several, efficient variants of our model which factorise the spatial- and temporal-dimensions of the input. Although transformer-based models are known to only be effective when large training datasets are available, we show how we can effectively regularise the model during training and leverage pretrained image models to be able to train on comparatively small datasets. We conduct thorough ablation studies, and achieve state-of-the-art results on multiple video classification benchmarks including Kinetics 400 and 600, Epic Kitchens, Something-Something v2 and Moments in Time, outperforming prior methods based on deep 3D convolutional networks. To facilitate further research, we will release code and models.},
	urldate = {2021-08-09},
	journal = {arXiv:2103.15691 [cs]},
	author = {Arnab, Anurag and Dehghani, Mostafa and Heigold, Georg and Sun, Chen and Lučić, Mario and Schmid, Cordelia},
	month = mar,
	year = {2021},
	note = {arXiv: 2103.15691},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{dosovitskiy_image_2021,
	title = {An {Image} is {Worth} 16x16 {Words}: {Transformers} for {Image} {Recognition} at {Scale}},
	shorttitle = {An {Image} is {Worth} 16x16 {Words}},
	url = {http://arxiv.org/abs/2010.11929},
	abstract = {While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.},
	urldate = {2021-08-09},
	journal = {arXiv:2010.11929 [cs]},
	author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
	month = jun,
	year = {2021},
	note = {arXiv: 2010.11929},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}


@article{dasari_evaluation_2021,
	title = {Evaluation of biases in remote photoplethysmography methods},
	volume = {4},
	copyright = {2021 The Author(s)},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-021-00462-z},
	doi = {10.1038/s41746-021-00462-z},
	abstract = {This work investigates the estimation biases of remote photoplethysmography (rPPG) methods for pulse rate measurement across diverse demographics. Advances in photoplethysmography (PPG) and rPPG methods have enabled the development of contact and noncontact approaches for continuous monitoring and collection of patient health data. The contagious nature of viruses such as COVID-19 warrants noncontact methods for physiological signal estimation. However, these approaches are subject to estimation biases due to variations in environmental conditions and subject demographics. The performance of contact-based wearable sensors has been evaluated, using off-the-shelf devices across demographics. However, the measurement uncertainty of rPPG methods that estimate pulse rate has not been sufficiently tested across diverse demographic populations or environments. Quantifying the efficacy of rPPG methods in real-world conditions is critical in determining their potential viability as health monitoring solutions. Currently, publicly available face datasets accompanied by physiological measurements are typically captured in controlled laboratory settings, lacking diversity in subject skin tones, age, and cultural artifacts (e.g, bindi worn by Indian women). In this study, we collect pulse rate and facial video data from human subjects in India and Sierra Leone, in order to quantify the uncertainty in noncontact pulse rate estimation methods. The video data are used to estimate pulse rate using state-of-the-art rPPG camera-based methods, and compared against ground truth measurements captured using an FDA-approved contact-based pulse rate measurement device. Our study reveals that rPPG methods exhibit similar biases when compared with a contact-based device across demographic groups and environmental conditions. The mean difference between pulse rates measured by rPPG methods and the ground truth is found to be {\textasciitilde}2\% (1 beats per minute (b.p.m.)), signifying agreement of rPPG methods with the ground truth. We also find that rPPG methods show pulse rate variability of {\textasciitilde}15\% (11 b.p.m.), as compared to the ground truth. We investigate factors impacting rPPG methods and discuss solutions aimed at mitigating variance.},
	language = {en},
	number = {1},
	urldate = {2021-08-09},
	journal = {npj Digital Medicine},
	author = {Dasari, Ananyananda and Prakash, Sakthi Kumar Arul and Jeni, László A. and Tucker, Conrad S.},
	month = jun,
	year = {2021},
	note = {Bandiera\_abtest: a
Cc\_license\_type: cc\_by
Cg\_type: Nature Research Journals
Number: 1
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Biomarkers;Developing world
Subject\_term\_id: biomarkers;developing-world},
	pages = {1--13},
}

@article{ba_overcoming_2021,
	title = {Overcoming {Difficulty} in {Obtaining} {Dark}-skinned {Subjects} for {Remote}-{PPG} by {Synthetic} {Augmentation}},
	url = {http://arxiv.org/abs/2106.06007},
	abstract = {Camera-based remote photoplethysmography (rPPG) provides a non-contact way to measure physiological signals (e.g., heart rate) using facial videos. Recent deep learning architectures have improved the accuracy of such physiological measurement significantly, yet they are restricted by the diversity of the annotated videos. The existing datasets MMSE-HR, AFRL, and UBFC-RPPG contain roughly 10\%, 0\%, and 5\% of dark-skinned subjects respectively. The unbalanced training sets result in a poor generalization capability to unseen subjects and lead to unwanted bias toward different demographic groups. In Western academia, it is regrettably difficult in a university setting to collect data on these dark-skinned subjects. Here we show a first attempt to overcome the lack of dark-skinned subjects by synthetic augmentation. A joint optimization framework is utilized to translate real videos from light-skinned subjects to dark skin tones while retaining their pulsatile signals. In the experiment, our method exhibits around 31\% reduction in mean absolute error for the dark-skinned group and 46\% improvement on bias mitigation for all the groups, as compared with the previous work trained with just real samples.},
	urldate = {2021-08-09},
	journal = {arXiv:2106.06007 [cs]},
	author = {Ba, Yunhao and Wang, Zhen and Karinca, Kerim Doruk and Bozkurt, Oyku Deniz and Kadambi, Achuta},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.06007},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{schrumpf_assessment_2021,
	title = {Assessment of deep learning based blood pressure prediction from {PPG} and {rPPG} signals},
	url = {http://arxiv.org/abs/2104.09313},
	abstract = {Exploiting photoplethysmography signals (PPG) for non-invasive blood pressure (BP) measurement is interesting for various reasons. First, PPG can easily be measured using fingerclip sensors. Second, camera-based approaches allow to derive remote PPG (rPPG) signals similar to PPG and therefore provide the opportunity for non-invasive measurements of BP. Various methods relying on machine learning techniques have recently been published. Performances are often reported as the mean average error (MAE) on the data which is problematic. This work aims to analyze the PPG- and rPPG-based BP prediction error with respect to the underlying data distribution. First, we train established neural network (NN) architectures and derive an appropriate parameterization of input segments drawn from continuous PPG signals. Second, we apply this parameterization to a larger PPG dataset and train NNs to predict BP. The resulting prediction errors increase towards less frequent BP values. Third, we use transfer learning to train the NNs for rPPG based BP prediction. The resulting performances are similar to the PPG-only case. Finally, we apply a personalization technique and retrain our NNs with subject-specific data. This slightly reduces the prediction errors.},
	urldate = {2021-08-09},
	journal = {arXiv:2104.09313 [cs, eess]},
	author = {Schrumpf, Fabian and Frenzel, Patrick and Aust, Christoph and Osterhoff, Georg and Fuchs, Mirco},
	month = apr,
	year = {2021},
	note = {arXiv: 2104.09313},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Signal Processing},
}

@article{lu_dual-gan_nodate-1,
	title = {Dual-{GAN}: {Joint} {BVP} and {Noise} {Modeling} for {Remote} {Physiological} {Measurement}},
	abstract = {Remote photoplethysmography (rPPG) based physiological measurement has great application values in health monitoring, emotion analysis, etc. Existing methods mainly focus on how to enhance or extract the very weak blood volume pulse (BVP) signals from face videos, but seldom explicitly model the noises that dominate face video content. Thus, they may suffer from poor generalization ability in unseen scenarios. This paper proposes a novel adversarial learning approach for rPPG based physiological measurement by using Dual Generative Adversarial Networks (Dual-GAN) to model the BVP predictor and noise distribution jointly. The BVP-GAN aims to learn a noiseresistant mapping from input to ground-truth BVP, and the Noise-GAN aims to learn the noise distribution. The two GANs can promote each other’s capability, leading to improved feature disentanglement between BVP and noises. Besides, a plug-and-play block named ROI alignment and fusion (ROI-AF) block is proposed to alleviate the inconsistencies between different ROIs and exploit informative features from a wider receptive ﬁeld in terms of ROIs. In comparison to state-of-the-art methods, our approach achieves better performance in heart rate, heart rate variability, and respiration frequency estimation from face videos.},
	language = {en},
	author = {Lu, Hao and Han, Hu and Zhou, S Kevin},
	pages = {10},
}

@article{mcduff_remote_2014,
	title = {Remote {Detection} of {Photoplethysmographic} {Systolic} and {Diastolic} {Peaks} {Using} a {Digital} {Camera}},
	volume = {61},
	issn = {0018-9294, 1558-2531},
	url = {http://ieeexplore.ieee.org/document/6863634/},
	doi = {10.1109/TBME.2014.2340991},
	abstract = {We present a new method for measuring photoplethysmogram (PPG) signals remotely using ambient light and a digital camera that allows for accurate recovery of the waveform morphology (from a distance of 3m). In particular, we show that the peak-to-peak time between the systolic peak and diastolic peak/inﬂection can be automatically recovered using the second order derivative of the remotely measured waveform. We compare measurements from the face with those captured using a contact ﬁnger-tip sensor and show high agreement in peak and interval timings. Furthermore, we show that results can be signiﬁcantly improved using orange, green and cyan color channels compared to the tradition red, green and blue channel combination. The absolute error in inter-beat-intervals was 26ms and the absolute error in mean systolic-diastolic peak-to-peak times was 12ms. The mean systolic-diastolic peak-to-peak times measured using the contact sensor and the camera were highly correlated, ρ = 0.94 (p{\textless}0.001). The results were obtained with a camera frame-rate of only 30Hz. This technology has signiﬁcant potential for advancing healthcare.},
	language = {en},
	number = {12},
	urldate = {2021-08-09},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {McDuff, Daniel and Gontarek, Sarah and Picard, Rosalind W.},
	month = dec,
	year = {2014},
	pages = {2948--2954},
}



@article{hill_imputation_2021,
	title = {Imputation of the continuous arterial line blood pressure waveform from non-invasive measurements using deep learning},
	volume = {11},
	copyright = {2021 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-021-94913-y},
	doi = {10.1038/s41598-021-94913-y},
	abstract = {In two-thirds of intensive care unit (ICU) patients and 90\% of surgical patients, arterial blood pressure (ABP) is monitored non-invasively but intermittently using a blood pressure cuff. Since even a few minutes of hypotension increases the risk of mortality and morbidity, for the remaining (high-risk) patients ABP is measured continuously using invasive devices, and derived values are extracted from the recorded waveforms. However, since invasive monitoring is associated with major complications (infection, bleeding, thrombosis), the ideal ABP monitor should be both non-invasive and continuous. With large volumes of high-fidelity physiological waveforms, it may be possible today to impute a physiological waveform from other available signals. Currently, the state-of-the-art approaches for ABP imputation only aim at intermittent systolic and diastolic blood pressure imputation, and there is no method that imputes the continuous ABP waveform. Here, we developed a novel approach to impute the continuous ABP waveform non-invasively using two continuously-monitored waveforms that are currently part of the standard-of-care, the electrocardiogram (ECG) and photo-plethysmogram (PPG), by adapting a deep learning architecture designed for image segmentation. Using over 150,000 min of data collected at two separate health systems from 463 patients, we demonstrate that our model provides a highly accurate prediction of the continuous ABP waveform (root mean square error 5.823 (95\% CI 5.806–5.840) mmHg), as well as the derived systolic (mean difference 2.398 ± 5.623 mmHg) and diastolic blood pressure (mean difference − 2.497 ± 3.785 mmHg) compared to arterial line measurements. Our approach can potentially be used to measure blood pressure continuously and non-invasively for all patients in the acute care setting, without the need for any additional instrumentation beyond the current standard-of-care.},
	language = {en},
	number = {1},
	urldate = {2021-08-03},
	journal = {Scientific Reports},
	author = {Hill, Brian L. and Rakocz, Nadav and Rudas, Ákos and Chiang, Jeffrey N. and Wang, Sidong and Hofer, Ira and Cannesson, Maxime and Halperin, Eran},
	month = aug,
	year = {2021},
	note = {Bandiera\_abtest: a
Cc\_license\_type: cc\_by
Cg\_type: Nature Research Journals
Number: 1
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Machine learning;Medical research;Predictive medicine
Subject\_term\_id: machine-learning;medical-research;predictive-medicine},
	pages = {15755},
}

@article{mohan_graphical_2021-1,
	title = {Graphical {Models} for {Processing} {Missing} {Data}},
	volume = {116},
	issn = {0162-1459},
	url = {https://doi.org/10.1080/01621459.2021.1874961},
	doi = {10.1080/01621459.2021.1874961},
	abstract = {This article reviews recent advances in missing data research using graphical models to represent multivariate dependencies. We first examine the limitations of traditional frameworks from three different perspectives: transparency, estimability, and testability. We then show how procedures based on graphical models can overcome these limitations and provide meaningful performance guarantees even when data are missing not at random (MNAR). In particular, we identify conditions that guarantee consistent estimation in broad categories of missing data problems, and derive procedures for implementing this estimation. Finally, we derive testable implications for missing data models in both missing at random and MNAR categories.},
	number = {534},
	urldate = {2021-07-13},
	journal = {Journal of the American Statistical Association},
	author = {Mohan, Karthika and Pearl, Judea},
	month = apr,
	year = {2021},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/01621459.2021.1874961},
	keywords = {Graphical models, Missing data, Missing not at random, Nonignorable, Recoverability, Testability},
	pages = {1023--1037},
}

@article{wander_abstract_2015,
	title = {Abstract 16124: {Aurora} - {A} {Noninvasive}, {Wrist}-worn {Device} for {Ambulatory} {Hemodynamic} {Monitoring}},
	volume = {132},
	shorttitle = {Abstract 16124},
	url = {https://www.ahajournals.org/doi/abs/10.1161/circ.132.suppl_3.16124},
	doi = {10.1161/circ.132.suppl_3.16124},
	abstract = {Introduction: Continuous, minimally invasive monitoring of arterial health has significant potential for both improving our understanding of early progression of arteriosclerosis/atherosclerosis and enabling early treatment. Though devices exist that can report heart rate and heart rate variability in fully ambulatory settings, monitoring of pulse pressure wave morphology, including pulse wave velocity (PWV) and augmentation index (AIx) - two emerging indicators of arterial stiffness - is still currently limited to benchtop systems requiring an expert operator or cuff-based systems that are not well tolerated.

Objective: To develop and validate a device capable of continuous monitoring of hemodynamic and electrophysiological signals, including computation of derived vascular stiffness indicators (peripheral PWV and AIx) comparable to current standards.

Methods: We developed a wrist-worn device for continuous radial pulse wave capture and analysis (e.g., peripheral AIx computation) and pulse wave velocity measurement (measured from EKG landmarks to the radial pulse arrival time). The core sensors on the device are (1) a pressure sensor that rests over the radial artery, (2) a pair of dry EKG electrodes in lead-I configuration, and (3) a six-axis motion sensor. It includes a Bluetooth radio for data streaming, and sufficient on-board storage for 2 weeks of ambulatory studies. To validate the device against the current gold standard for radial tonometry, we recorded multiple 60-second sessions of tonometric data using both our device (2 sessions) and the standard Millar SPT-301 tonometer (3 sessions) in 28 subjects. We then compared AIx computed from these two devices.

Results: Using our wrist-worn device we calculated AIx values that were highly consistent with those of the Millar tonometer (r = 0.927, mean difference ± SD of 0.026 ± 0.049).

Conclusions: This platform enables continuous non-invasive hemodynamic monitoring. We intend to utilize it in future studies about how peripheral AIx and PWV behave over longer time periods, how they correlate to daily activities, including sleep, exercise, and food/medication intake, and - most importantly - whether they can serve as new, ambulatory indicators of cardiovascular risk.},
	number = {suppl\_3},
	urldate = {2021-07-13},
	journal = {Circulation},
	author = {Wander, Jeremiah D and Morris, Dan and Tan, Desney},
	month = nov,
	year = {2015},
	note = {Publisher: American Heart Association},
	keywords = {Ambulatory, Hemodynamics, Noninvasive, Pulse Wave Analysis, Pulse Wave Velocity},
	pages = {A16124--A16124},
}

@inproceedings{morris_blood_2015,
	title = {Blood {Pressure} {Beyond} the {Clinic}: {Rethinking} a {Health} {Metric} for {Everyone}},
	shorttitle = {Blood {Pressure} {Beyond} the {Clinic}},
	url = {https://www.microsoft.com/en-us/research/publication/blood-pressure-beyond-clinic-rethinking-health-metric-everyone/},
	abstract = {Blood pressure (BP) is typically captured at irregular intervals, mostly in clinic environments. This approach treats BP as a static snapshot for health classification and largely ignores its value as a continuously fluctuating measure. Recognizing that consumers are increasingly capturing health metrics through wearable devices, we explored BP measurement in relation to everyday living through […]},
	language = {en-US},
	urldate = {2021-07-13},
	author = {Morris, Dan and Tan, Desney and Kendall, Logan},
	month = apr,
	year = {2015},
	pages = {1679--1688},
}

@article{misic_simulation-based_2021,
	title = {A simulation-based evaluation of machine learning models for clinical decision support: application and analysis using hospital readmission},
	volume = {4},
	copyright = {2021 The Author(s)},
	issn = {2398-6352},
	shorttitle = {A simulation-based evaluation of machine learning models for clinical decision support},
	url = {https://www.nature.com/articles/s41746-021-00468-7},
	doi = {10.1038/s41746-021-00468-7},
	abstract = {The interest in applying machine learning in healthcare has grown rapidly in recent years. Most predictive algorithms requiring pathway implementations are evaluated using metrics focused on predictive performance, such as the c statistic. However, these metrics are of limited clinical value, for two reasons: (1) they do not account for the algorithm’s role within a provider workflow; and (2) they do not quantify the algorithm’s value in terms of patient outcomes and cost savings. We propose a model for simulating the selection of patients over time by a clinician using a machine learning algorithm, and quantifying the expected patient outcomes and cost savings. Using data on unplanned emergency department surgical readmissions, we show that factors such as the provider’s schedule and postoperative prediction timing can have major effects on the pathway cohort size and potential cost reductions from preventing hospital readmissions.},
	language = {en},
	number = {1},
	urldate = {2021-06-29},
	journal = {npj Digital Medicine},
	author = {Mišić, Velibor V. and Rajaram, Kumar and Gabel, Eilon},
	month = jun,
	year = {2021},
	note = {Bandiera\_abtest: a
Cc\_license\_type: cc\_by
Cg\_type: Nature Research Journals
Number: 1
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Health policy;Health services;Statistics
Subject\_term\_id: health-policy;health-services;statistics},
	pages = {1--11},
}

@article{dasari_evaluation_2021-1,
	title = {Evaluation of biases in remote photoplethysmography methods},
	volume = {4},
	copyright = {2021 The Author(s)},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-021-00462-z},
	doi = {10.1038/s41746-021-00462-z},
	abstract = {This work investigates the estimation biases of remote photoplethysmography (rPPG) methods for pulse rate measurement across diverse demographics. Advances in photoplethysmography (PPG) and rPPG methods have enabled the development of contact and noncontact approaches for continuous monitoring and collection of patient health data. The contagious nature of viruses such as COVID-19 warrants noncontact methods for physiological signal estimation. However, these approaches are subject to estimation biases due to variations in environmental conditions and subject demographics. The performance of contact-based wearable sensors has been evaluated, using off-the-shelf devices across demographics. However, the measurement uncertainty of rPPG methods that estimate pulse rate has not been sufficiently tested across diverse demographic populations or environments. Quantifying the efficacy of rPPG methods in real-world conditions is critical in determining their potential viability as health monitoring solutions. Currently, publicly available face datasets accompanied by physiological measurements are typically captured in controlled laboratory settings, lacking diversity in subject skin tones, age, and cultural artifacts (e.g, bindi worn by Indian women). In this study, we collect pulse rate and facial video data from human subjects in India and Sierra Leone, in order to quantify the uncertainty in noncontact pulse rate estimation methods. The video data are used to estimate pulse rate using state-of-the-art rPPG camera-based methods, and compared against ground truth measurements captured using an FDA-approved contact-based pulse rate measurement device. Our study reveals that rPPG methods exhibit similar biases when compared with a contact-based device across demographic groups and environmental conditions. The mean difference between pulse rates measured by rPPG methods and the ground truth is found to be {\textasciitilde}2\% (1 beats per minute (b.p.m.)), signifying agreement of rPPG methods with the ground truth. We also find that rPPG methods show pulse rate variability of {\textasciitilde}15\% (11 b.p.m.), as compared to the ground truth. We investigate factors impacting rPPG methods and discuss solutions aimed at mitigating variance.},
	language = {en},
	number = {1},
	urldate = {2021-06-29},
	journal = {npj Digital Medicine},
	author = {Dasari, Ananyananda and Prakash, Sakthi Kumar Arul and Jeni, László A. and Tucker, Conrad S.},
	month = jun,
	year = {2021},
	note = {Bandiera\_abtest: a
Cc\_license\_type: cc\_by
Cg\_type: Nature Research Journals
Number: 1
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Biomarkers;Developing world
Subject\_term\_id: biomarkers;developing-world},
	pages = {1--13},
}

@article{hill_automated_2019,
	title = {An automated machine learning-based model predicts postoperative mortality using readily-extractable preoperative electronic health record data},
	volume = {123},
	issn = {0007-0912, 1471-6771},
	url = {https://bjanaesthesia.org/article/S0007-0912(19)30646-4/abstract},
	doi = {10.1016/j.bja.2019.07.030},
	abstract = {{\textless}h2{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}h3{\textgreater}Background{\textless}/h3{\textgreater}{\textless}p{\textgreater}Rapid, preoperative identification of patients with the highest risk for medical complications is necessary to ensure that limited infrastructure and human resources are directed towards those most likely to benefit. Existing risk scores either lack specificity at the patient level or utilise the American Society of Anesthesiologists (ASA) physical status classification, which requires a clinician to review the chart.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Methods{\textless}/h3{\textgreater}{\textless}p{\textgreater}We report on the use of machine learning algorithms, specifically random forests, to create a fully automated score that predicts postoperative in-hospital mortality based solely on structured data available at the time of surgery. Electronic health record data from 53 097 surgical patients (2.01\% mortality rate) who underwent general anaesthesia between April 1, 2013 and December 10, 2018 in a large US academic medical centre were used to extract 58 preoperative features.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Results{\textless}/h3{\textgreater}{\textless}p{\textgreater}Using a random forest classifier we found that automatically obtained preoperative features (area under the curve [AUC] of 0.932, 95\% confidence interval [CI] 0.910–0.951) outperforms Preoperative Score to Predict Postoperative Mortality (POSPOM) scores (AUC of 0.660, 95\% CI 0.598–0.722), Charlson comorbidity scores (AUC of 0.742, 95\% CI 0.658–0.812), and ASA physical status (AUC of 0.866, 95\% CI 0.829–0.897). Including the ASA physical status with the preoperative features achieves an AUC of 0.936 (95\% CI 0.917–0.955).{\textless}/p{\textgreater}{\textless}h3{\textgreater}Conclusions{\textless}/h3{\textgreater}{\textless}p{\textgreater}This automated score outperforms the ASA physical status score, the Charlson comorbidity score, and the POSPOM score for predicting in-hospital mortality. Additionally, we integrate this score with a previously published postoperative score to demonstrate the extent to which patient risk changes during the perioperative period.{\textless}/p{\textgreater}},
	language = {English},
	number = {6},
	urldate = {2021-05-26},
	journal = {British Journal of Anaesthesia},
	author = {Hill, Brian L. and Brown, Robert and Gabel, Eilon and Rakocz, Nadav and Lee, Christine and Cannesson, Maxime and Baldi, Pierre and Loohuis, Loes Olde and Johnson, Ruth and Jew, Brandon and Maoz, Uri and Mahajan, Aman and Sankararaman, Sriram and Hofer, Ira and Halperin, Eran},
	month = dec,
	year = {2019},
	pmid = {31627890},
	note = {Publisher: Elsevier},
	pages = {877--886},
}

@inproceedings{beede_human-centered_2020,
	address = {New York, NY, USA},
	series = {{CHI} '20},
	title = {A {Human}-{Centered} {Evaluation} of a {Deep} {Learning} {System} {Deployed} in {Clinics} for the {Detection} of {Diabetic} {Retinopathy}},
	isbn = {978-1-4503-6708-0},
	url = {https://doi.org/10.1145/3313831.3376718},
	doi = {10.1145/3313831.3376718},
	abstract = {Deep learning algorithms promise to improve clinician workflows and patient outcomes. However, these gains have yet to be fully demonstrated in real world clinical settings. In this paper, we describe a human-centered study of a deep learning system used in clinics for the detection of diabetic eye disease. From interviews and observation across eleven clinics in Thailand, we characterize current eye-screening workflows, user expectations for an AI-assisted screening process, and post-deployment experiences. Our findings indicate that several socio-environmental factors impact model performance, nursing workflows, and the patient experience. We draw on these findings to reflect on the value of conducting human-centered evaluative research alongside prospective evaluations of model accuracy.},
	urldate = {2021-05-25},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Beede, Emma and Baylor, Elizabeth and Hersch, Fred and Iurchenko, Anna and Wilcox, Lauren and Ruamviboonsuk, Paisan and Vardoulakis, Laura M.},
	month = apr,
	year = {2020},
	keywords = {deep learning, diabetes, health, human-centered ai},
	pages = {1--12},
}

@article{ghorbani2020deep,
  title={Deep learning interpretation of echocardiograms},
  author={Ghorbani, Amirata and Ouyang, David and Abid, Abubakar and He, Bryan and Chen, Jonathan H and Harrington, Robert A and Liang, David H and Ashley, Euan A and Zou, James Y},
  journal={NPJ digital medicine},
  volume={3},
  number={1},
  pages={1--10},
  year={2020},
  publisher={Nature Publishing Group}
}

@article{elliott_predictive_2020,
	title = {Predictive {Accuracy} of a {Polygenic} {Risk} {Score}–{Enhanced} {Prediction} {Model} vs a {Clinical} {Risk} {Score} for {Coronary} {Artery} {Disease}},
	volume = {323},
	issn = {0098-7484},
	url = {https://jamanetwork.com/journals/jama/fullarticle/2761088},
	doi = {10.1001/jama.2019.22241},
	language = {en},
	number = {7},
	urldate = {2021-05-14},
	journal = {JAMA},
	author = {Elliott, Joshua and Bodinier, Barbara and Bond, Tom A. and Chadeau-Hyam, Marc and Evangelou, Evangelos and Moons, Karel G. M. and Dehghan, Abbas and Muller, David C. and Elliott, Paul and Tzoulaki, Ioanna},
	month = feb,
	year = {2020},
	pages = {636},
}

@article{norris_removal_2020,
	title = {Removal of {Race} {From} {Estimates} of {Kidney} {Function}: {First}, {Do} {No} {Harm}},
	issn = {0098-7484},
	shorttitle = {Removal of {Race} {From} {Estimates} of {Kidney} {Function}},
	url = {https://jamanetwork.com/journals/jama/fullarticle/2773807},
	doi = {10.1001/jama.2020.23373},
	language = {en},
	urldate = {2021-05-13},
	journal = {JAMA},
	author = {Norris, Keith C. and Eneanya, Nwamaka D. and Boulware, L. Ebony},
	month = dec,
	year = {2020},
}

@article{diao_clinical_2020,
	title = {Clinical {Implications} of {Removing} {Race} {From} {Estimates} of {Kidney} {Function}},
	issn = {0098-7484},
	url = {https://jamanetwork.com/journals/jama/fullarticle/2773808},
	doi = {10.1001/jama.2020.22124},
	language = {en},
	urldate = {2021-05-13},
	journal = {JAMA},
	author = {Diao, James A. and Wu, Gloria J. and Taylor, Herman A. and Tucker, John K. and Powe, Neil R. and Kohane, Isaac S. and Manrai, Arjun K.},
	month = dec,
	year = {2020},
}

@article{vyas_hidden_2020,
	title = {Hidden in {Plain} {Sight} — {Reconsidering} the {Use} of {Race} {Correction} in {Clinical} {Algorithms}},
	volume = {383},
	issn = {0028-4793},
	url = {https://doi.org/10.1056/NEJMms2004740},
	doi = {10.1056/NEJMms2004740},
	number = {9},
	urldate = {2021-05-13},
	journal = {New England Journal of Medicine},
	author = {Vyas, Darshali A. and Eisenstein, Leo G. and Jones, David S.},
	month = aug,
	year = {2020},
	note = {Publisher: Massachusetts Medical Society
\_eprint: https://doi.org/10.1056/NEJMms2004740},
	pages = {874--882},
}

@misc{noauthor_personal_nodate,
	title = {The personal and clinical utility of polygenic risk scores {\textbar} {Nature} {Reviews} {Genetics}},
	url = {https://www.nature.com/articles/s41576-018-0018-x?spm=smpc.content.content.1.15473376001127D5jliP},
	urldate = {2021-05-12},
}

@article{cava_interpretation_2020,
	title = {Interpretation of machine learning predictions for patient outcomes in electronic health records},
	volume = {2019},
	issn = {1942-597X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7153071/},
	abstract = {Electronic health records are an increasingly important resource for understanding the interactions between patient health, environment, and clinical decisions. In this paper we report an empirical study of predictive modeling of seven patient outcomes using three state-of-the-art machine learning methods. Our primary goal is to validate the models by interpreting the importance of predictors in the final models. Central to interpretation is the use of feature importance scores, which vary depending on the underlying methodology. In order to assess feature importance, we compared univariate statistical tests, information-theoretic measures, permutation testing, and normalized coefficients from multivariate logistic regression models. In general we found poor correlation between methods in their assessment of feature importance, even when their performance is comparable and relatively good. However, permutation tests applied to random forest and gradient boosting models showed the most agreement, and the importance scores matched the clinical interpretation most frequently.},
	urldate = {2021-05-10},
	journal = {AMIA Annual Symposium Proceedings},
	author = {Cava, William La and Bauer, Christopher and Moore, Jason H. and Pendergrass, Sarah A},
	month = mar,
	year = {2020},
	pmid = {32308851},
	pmcid = {PMC7153071},
	pages = {572--581},
}

@article{xu_deep_2020,
	title = {A deep learning–based, unsupervised method to impute missing values in electronic health records for improved patient management},
	volume = {111},
	issn = {1532-0464},
	url = {https://www.sciencedirect.com/science/article/pii/S1532046420302045},
	doi = {10.1016/j.jbi.2020.103576},
	abstract = {Electronic health records (EHRs) often suffer missing values, for which recent advances in deep learning offer a promising remedy. We develop a deep learning–based, unsupervised method to impute missing values in patient records, then examine its imputation effectiveness and predictive efficacy for peritonitis patient management. Our method builds on a deep autoencoder framework, incorporates missing patterns, accounts for essential relationships in patient data, considers temporal patterns common to patient records, and employs a novel loss function for error calculation and regularization. Using a data set of 27,327 patient records, we perform a comparative evaluation of the proposed method and several prevalent benchmark techniques. The results indicate the greater imputation performance of our method relative to all the benchmark techniques, recording 5.3–15.5\% lower imputation errors. Furthermore, the data imputed by the proposed method better predict readmission, length of stay, and mortality than those obtained from any benchmark techniques, achieving 2.7–11.5\% improvements in predictive efficacy. The illustrated evaluation indicates the proposed method’s viability, imputation effectiveness, and clinical decision support utilities. Overall, our method can reduce imputation biases and be applied to various missing value scenarios clinically, thereby empowering physicians and researchers to better analyze and utilize EHRs for improved patient management.},
	language = {en},
	urldate = {2021-05-10},
	journal = {Journal of Biomedical Informatics},
	author = {Xu, Da and Hu, Paul Jen-Hwa and Huang, Ting-Shuo and Fang, Xiao and Hsu, Chih-Chin},
	month = nov,
	year = {2020},
	keywords = {Clinical decision support, Clinical predictive analytics, Deep learning, Electronic health records, Machine learning, Missing value imputation},
	pages = {103576},
}

@article{belbin_toward_2021,
	title = {Toward a fine-scale population health monitoring system},
	volume = {184},
	issn = {0092-8674, 1097-4172},
	url = {https://www.cell.com/cell/abstract/S0092-8674(21)00365-2},
	doi = {10.1016/j.cell.2021.03.034},
	language = {English},
	number = {8},
	urldate = {2021-05-04},
	journal = {Cell},
	author = {Belbin, Gillian M. and Cullina, Sinead and Wenric, Stephane and Soper, Emily R. and Glicksberg, Benjamin S. and Torre, Denis and Moscati, Arden and Wojcik, Genevieve L. and Shemirani, Ruhollah and Beckmann, Noam D. and Cohain, Ariella and Sorokin, Elena P. and Park, Danny S. and Ambite, Jose-Luis and Ellis, Steve and Auton, Adam and Bottinger, Erwin P. and Cho, Judy H. and Loos, Ruth J. F. and Abul-Husn, Noura S. and Zaitlen, Noah A. and Gignoux, Christopher R. and Kenny, Eimear E.},
	month = apr,
	year = {2021},
	pmid = {33861964},
	note = {Publisher: Elsevier},
	keywords = {biobanks, computational genomics, electronic health records, genetic ancestry, genomic medicine, health disparities, machine learning, population health},
	pages = {2068--2083.e11},
}

@article{bell_genome-wide_2010,
	title = {Genome-wide {DNA} methylation analysis for diabetic nephropathy in type 1 diabetes mellitus},
	volume = {3},
	issn = {1755-8794},
	url = {https://doi.org/10.1186/1755-8794-3-33},
	doi = {10.1186/1755-8794-3-33},
	abstract = {Diabetic nephropathy is a serious complication of diabetes mellitus and is associated with considerable morbidity and high mortality. There is increasing evidence to suggest that dysregulation of the epigenome is involved in diabetic nephropathy. We assessed whether epigenetic modification of DNA methylation is associated with diabetic nephropathy in a case-control study of 192 Irish patients with type 1 diabetes mellitus (T1D). Cases had T1D and nephropathy whereas controls had T1D but no evidence of renal disease.},
	number = {1},
	urldate = {2021-05-04},
	journal = {BMC Medical Genomics},
	author = {Bell, Christopher G. and Teschendorff, Andrew E. and Rakyan, Vardhman K. and Maxwell, Alexander P. and Beck, Stephan and Savage, David A.},
	month = aug,
	year = {2010},
	keywords = {Affect Transcription Factor Binding, Bisulphite Conversion, Diabetic Nephropathy, Singular Value Decomposition, Singular Value Decomposition Analysis},
	pages = {33},
}

@article{teschendorff_age-dependent_2010,
	title = {Age-dependent {DNA} methylation of genes that are suppressed in stem cells is a hallmark of cancer},
	volume = {20},
	issn = {1549-5469},
	doi = {10.1101/gr.103606.109},
	abstract = {Polycomb group proteins (PCGs) are involved in repression of genes that are required for stem cell differentiation. Recently, it was shown that promoters of PCG target genes (PCGTs) are 12-fold more likely to be methylated in cancer than non-PCGTs. Age is the most important demographic risk factor for cancer, and we hypothesized that its carcinogenic potential may be referred by irreversibly stabilizing stem cell features. To test this, we analyzed the methylation status of over 27,000 CpGs mapping to promoters of approximately 14,000 genes in whole blood samples from 261 postmenopausal women. We demonstrate that stem cell PCGTs are far more likely to become methylated with age than non-targets (odds ratio = 5.3 [3.8-7.4], P {\textless} 10(-10)), independently of sex, tissue type, disease state, and methylation platform. We identified a specific subset of 69 PCGT CpGs that undergo hypermethylation with age and validated this methylation signature in seven independent data sets encompassing over 900 samples, including normal and cancer solid tissues and a population of bone marrow mesenchymal stem/stromal cells (P {\textless} 10(-5)). We find that the age-PCGT methylation signature is present in preneoplastic conditions and may drive gene expression changes associated with carcinogenesis. These findings shed substantial novel insights into the epigenetic effects of aging and support the view that age may predispose to malignant transformation by irreversibly stabilizing stem cell features.},
	language = {eng},
	number = {4},
	journal = {Genome Research},
	author = {Teschendorff, Andrew E. and Menon, Usha and Gentry-Maharaj, Aleksandra and Ramus, Susan J. and Weisenberger, Daniel J. and Shen, Hui and Campan, Mihaela and Noushmehr, Houtan and Bell, Christopher G. and Maxwell, A. Peter and Savage, David A. and Mueller-Holzner, Elisabeth and Marth, Christian and Kocjan, Gabrijela and Gayther, Simon A. and Jones, Allison and Beck, Stephan and Wagner, Wolfgang and Laird, Peter W. and Jacobs, Ian J. and Widschwendter, Martin},
	month = apr,
	year = {2010},
	pmid = {20219944},
	pmcid = {PMC2847747},
	keywords = {Adult, Age Factors, Aged, Aged, 80 and over, Aging, Biomarkers, Tumor, DNA Methylation, Female, Gene Expression Regulation, Developmental, Gene Expression Regulation, Neoplastic, Gene Silencing, Genes, Genetic Predisposition to Disease, Humans, Male, Middle Aged, Neoplasms, Promoter Regions, Genetic, Stem Cells, Validation Studies as Topic, Young Adult},
	pages = {440--446},
}

@article{martin_clinical_2019,
	title = {Clinical use of current polygenic risk scores may exacerbate health disparities},
	volume = {51},
	copyright = {2019 Springer Nature America, Inc.},
	issn = {1546-1718},
	url = {https://www.nature.com/articles/s41588-019-0379-x},
	doi = {10.1038/s41588-019-0379-x},
	abstract = {Polygenic risk scores (PRS) are poised to improve biomedical outcomes via precision medicine. However, the major ethical and scientific challenge surrounding clinical implementation of PRS is that those available today are several times more accurate in individuals of European ancestry than other ancestries. This disparity is an inescapable consequence of Eurocentric biases in genome-wide association studies, thus highlighting that—unlike clinical biomarkers and prescription drugs, which may individually work better in some populations but do not ubiquitously perform far better in European populations—clinical uses of PRS today would systematically afford greater improvement for European-descent populations. Early diversifying efforts show promise in leveling this vast imbalance, even when non-European sample sizes are considerably smaller than the largest studies to date. To realize the full and equitable potential of PRS, greater diversity must be prioritized in genetic studies, and summary statistics must be publically disseminated to ensure that health disparities are not increased for those individuals already most underserved.},
	language = {en},
	number = {4},
	urldate = {2021-05-04},
	journal = {Nature Genetics},
	author = {Martin, Alicia R. and Kanai, Masahiro and Kamatani, Yoichiro and Okada, Yukinori and Neale, Benjamin M. and Daly, Mark J.},
	month = apr,
	year = {2019},
	note = {Number: 4
Publisher: Nature Publishing Group},
	pages = {584--591},
}

@article{kerminen_geographic_2019,
	title = {Geographic {Variation} and {Bias} in the {Polygenic} {Scores} of {Complex} {Diseases} and {Traits} in {Finland}},
	volume = {104},
	issn = {0002-9297},
	url = {https://www.sciencedirect.com/science/article/pii/S0002929719301879},
	doi = {10.1016/j.ajhg.2019.05.001},
	abstract = {Polygenic scores (PSs) are becoming a useful tool to identify individuals with high genetic risk for complex diseases, and several projects are currently testing their utility for translational applications. It is also tempting to use PSs to assess whether genetic variation can explain a part of the geographic distribution of a phenotype. However, it is not well known how the population genetic properties of the training and target samples affect the geographic distribution of PSs. Here, we evaluate geographic differences, and related biases, of PSs in Finland in a geographically well-defined sample of 2,376 individuals from the National FINRISK study. First, we detect geographic differences in PSs for coronary artery disease (CAD), rheumatoid arthritis, schizophrenia, waist-hip ratio (WHR), body-mass index (BMI), and height, but not for Crohn disease or ulcerative colitis. Second, we use height as a model trait to thoroughly assess the possible population genetic biases in PSs and apply similar approaches to the other phenotypes. Most importantly, we detect suspiciously large accumulations of geographic differences for CAD, WHR, BMI, and height, suggesting bias arising from the population’s genetic structure rather than from a direct genotype-phenotype association. This work demonstrates how sensitive the geographic patterns of current PSs are for small biases even within relatively homogeneous populations and provides simple tools to identify such biases. A thorough understanding of the effects of population genetic structure on PSs is essential for translational applications of PSs.},
	language = {en},
	number = {6},
	urldate = {2021-05-04},
	journal = {The American Journal of Human Genetics},
	author = {Kerminen, Sini and Martin, Alicia R. and Koskela, Jukka and Ruotsalainen, Sanni E. and Havulinna, Aki S. and Surakka, Ida and Palotie, Aarno and Perola, Markus and Salomaa, Veikko and Daly, Mark J. and Ripatti, Samuli and Pirinen, Matti},
	month = jun,
	year = {2019},
	keywords = {genetic prediction, genetic structure, population stratification},
	pages = {1169--1181},
}

@article{duncan2019analysis,
  title={Analysis of polygenic risk score usage and performance in diverse human populations},
  author={Duncan, Laramie and Shen, H and Gelaye, B and Meijsen, J and Ressler, K and Feldman, M and Peterson, R and Domingue, Ben},
  journal={Nature communications},
  volume={10},
  number={1},
  pages={1--9},
  year={2019},
  publisher={Nature Publishing Group}
}


@article{dudbridge_power_2013,
	title = {Power and {Predictive} {Accuracy} of {Polygenic} {Risk} {Scores}},
	volume = {9},
	issn = {1553-7404},
	url = {https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1003348},
	doi = {10.1371/journal.pgen.1003348},
	abstract = {Polygenic scores have recently been used to summarise genetic effects among an ensemble of markers that do not individually achieve significance in a large-scale association study. Markers are selected using an initial training sample and used to construct a score in an independent replication sample by forming the weighted sum of associated alleles within each subject. Association between a trait and this composite score implies that a genetic signal is present among the selected markers, and the score can then be used for prediction of individual trait values. This approach has been used to obtain evidence of a genetic effect when no single markers are significant, to establish a common genetic basis for related disorders, and to construct risk prediction models. In some cases, however, the desired association or prediction has not been achieved. Here, the power and predictive accuracy of a polygenic score are derived from a quantitative genetics model as a function of the sizes of the two samples, explained genetic variance, selection thresholds for including a marker in the score, and methods for weighting effect sizes in the score. Expressions are derived for quantitative and discrete traits, the latter allowing for case/control sampling. A novel approach to estimating the variance explained by a marker panel is also proposed. It is shown that published studies with significant association of polygenic scores have been well powered, whereas those with negative results can be explained by low sample size. It is also shown that useful levels of prediction may only be approached when predictors are estimated from very large samples, up to an order of magnitude greater than currently available. Therefore, polygenic scores currently have more utility for association testing than predicting complex traits, but prediction will become more feasible as sample sizes continue to grow.},
	language = {en},
	number = {3},
	urldate = {2021-05-03},
	journal = {PLOS Genetics},
	author = {Dudbridge, Frank},
	month = mar,
	year = {2013},
	note = {Publisher: Public Library of Science},
	keywords = {Genetics, Genetics of disease, Genome-wide association studies, Heredity, Linear regression analysis, Mathematical functions, Normal distribution, Single nucleotide polymorphisms},
	pages = {e1003348},
}

@article{shah2015improving,
  title={Improving phenotypic prediction by combining genetic and epigenetic associations},
  author={Shah, Sonia and Bonder, Marc J and Marioni, Riccardo E and Zhu, Zhihong and McRae, Allan F and Zhernakova, Alexandra and Harris, Sarah E and Liewald, Dave and Henders, Anjali K and Mendelson, Michael M and others},
  journal={The American Journal of Human Genetics},
  volume={97},
  number={1},
  pages={75--85},
  year={2015},
  publisher={Elsevier}
}


@article{horvath_dna_2013,
	title = {{DNA} methylation age of human tissues and cell types},
	volume = {14},
	issn = {1474-760X},
	url = {https://doi.org/10.1186/gb-2013-14-10-r115},
	doi = {10.1186/gb-2013-14-10-r115},
	abstract = {It is not yet known whether DNA methylation levels can be used to accurately predict age across a broad spectrum of human tissues and cell types, nor whether the resulting age prediction is a biologically meaningful measure.},
	number = {10},
	urldate = {2021-05-03},
	journal = {Genome Biology},
	author = {Horvath, Steve},
	month = dec,
	year = {2013},
	keywords = {Cell Passage Number, DNAm Level, Epigenetic Clock, Penalize Regression Model, Progeria},
	pages = {3156},
}

@article{zhang_dna_2015,
	title = {{DNA} {Methylation} {Patterns} {Can} {Estimate} {Nonequivalent} {Outcomes} of {Breast} {Cancer} with the {Same} {Receptor} {Subtypes}},
	volume = {10},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0142279},
	doi = {10.1371/journal.pone.0142279},
	abstract = {Breast cancer has various molecular subtypes and displays high heterogeneity. Aberrant DNA methylation is involved in tumor origin, development and progression. Moreover, distinct DNA methylation patterns are associated with specific breast cancer subtypes. We explored DNA methylation patterns in association with gene expression to assess their impact on the prognosis of breast cancer based on Infinium 450K arrays (training set) from The Cancer Genome Atlas (TCGA). The DNA methylation patterns of 12 featured genes that had a high correlation with gene expression were identified through univariate and multivariable Cox proportional hazards models and used to define the methylation risk score (MRS). An improved ability to distinguish the power of the DNA methylation pattern from the 12 featured genes (p = 0.00103) was observed compared with the average methylation levels (p = 0.956) or gene expression (p = 0.909). Furthermore, MRS provided a good prognostic value for breast cancers even when the patients had the same receptor status. We found that ER-, PR- or Her2- samples with high-MRS had the worst 5-year survival rate and overall survival time. An independent test set including 28 patients with death as an outcome was used to test the validity of the MRS of the 12 featured genes; this analysis obtained a prognostic value equivalent to the training set. The predict power was validated through two independent datasets from the GEO database. The DNA methylation pattern is a powerful predictor of breast cancer survival, and can predict outcomes of the same breast cancer molecular subtypes.},
	language = {en},
	number = {11},
	urldate = {2021-05-03},
	journal = {PLOS ONE},
	author = {Zhang, Min and Zhang, Shaojun and Wen, Yanhua and Wang, Yihan and Wei, Yanjun and Liu, Hongbo and Zhang, Dongwei and Su, Jianzhong and Wang, Fang and Zhang, Yan},
	month = nov,
	year = {2015},
	note = {Publisher: Public Library of Science},
	keywords = {Biomarkers, Breast cancer, Cancer risk factors, Cancer treatment, DNA methylation, Gene expression, Genetic causes of cancer, Treatment guidelines},
	pages = {e0142279},
}

@article{onwuka_panel_2020,
	title = {A panel of {DNA} methylation signature from peripheral blood may predict colorectal cancer susceptibility},
	volume = {20},
	issn = {1471-2407},
	url = {https://doi.org/10.1186/s12885-020-07194-5},
	doi = {10.1186/s12885-020-07194-5},
	abstract = {Differential DNA methylation panel derived from peripheral blood could serve as biomarkers of CRC susceptibility. However, most of the previous studies utilized post-diagnostic blood DNA which may be markers of disease rather than susceptibility. In addition, only a few studies have evaluated the predictive potential of differential DNA methylation in CRC in a prospective cohort and on a genome-wide basis. The aim of this study was to identify a potential panel of DNA methylation biomarkers in peripheral blood that is associated with CRC risk and therefore serve as epigenetic biomarkers of disease susceptibility.},
	number = {1},
	urldate = {2021-05-03},
	journal = {BMC Cancer},
	author = {Onwuka, Justina Ucheojor and Li, Dapeng and Liu, Yupeng and Huang, Hao and Xu, Jing and Liu, Ying and Zhang, Yuanyuan and Zhao, Yashuang},
	month = jul,
	year = {2020},
	keywords = {Colorectal cancer, DNA methylation, Methylation risk score, Peripheral blood},
	pages = {692},
}

@article{clark_24_2019,
	series = {Abstracts of the {XXVth} {World} {Congress} of {Psychiatric} {Genetics} ({WCPG}), 13 - 17 {October} 2017, {Orlando}, {Florida}},
	title = {24 - {PREDICTING} {THE} {FUTURE} {DISEASE} {STATUS} {OF} {DEPRESSED} {PATIENTS} {FROM} {DNA} {METHYLATION} {PATTERNS} {IN} {BLOOD}},
	volume = {29},
	issn = {0924-977X},
	url = {https://www.sciencedirect.com/science/article/pii/S0924977X17304777},
	doi = {10.1016/j.euroneuro.2017.08.025},
	abstract = {Background
Major Depressive Disorder (MDD) is a severe disorder with a lifetime prevalence of 15\%. Recurrent or chronic MDD, which typically requires long-term treatment, occurs in the majority of patients. As previous efforts to predict recurrence/chronicity have met with limited success, novel avenues are required. In this study, we aimed to predict the future disease status of MDD patients from DNA methylation patterns in blood.
Methods
We assayed 28 million methylation sites in 581 MDD patients from the Netherlands Study of Depression and Anxiety (NESDA). A Machine Learning algorithm condensed all information into a single predictor labeled methylation risk score (MRS). The outcome was MDD disease status six years later. To evaluate the predictive power of our MRS, we obtained an unbiased estimate of the area under the curve (AUC) using k-fold cross validation.
Results
The AUC of the MRS was 0.724. We compared our MRS with predictions based on a set of five putative MDD biomarkers (e.g., assaying neurotrophic factors or inflammation), genome-wide genetic variant data, and 27 clinical, demographic or lifestyle variables (e.g., MDD symptom severity, childhood trauma, alcohol use). The MRS not only outperformed all these predictors but also seemed to capture their predictive power as the inclusion of any of these sets did not significantly increase the AUC of the MRS.
Discussion
The current study suggests a novel avenue for predicting future MDD status using DNA methylation patterns in blood. The predictive power of the MRS is comparable to the AUC of the Framingham Risk Score, one of the most widely used clinical tools to predict coronary heart disease. This AUC level can potentially support clinical decisions about treatment strategies by providing empirical information about the likelihood MDD is chronic or will recur in the future.},
	language = {en},
	urldate = {2021-05-03},
	journal = {European Neuropsychopharmacology},
	author = {Clark, Shaunna and Hattab, Mohammad and Shabalin, Andrey and Han, Laura and Chan, Robin and Zhao, Min and Smit, Johannes and Jansen, Rick and Milaneschi, Yuri and Xie, Lin and van Grootheest, Gerard and Penninx, Brenda and Aberg, Karolina and van den Oord, Edwin},
	month = jan,
	year = {2019},
	pages = {S793--S794},
}

@article{yu_individual_2020,
	title = {Individual and joint contributions of genetic and methylation risk scores for enhancing lung cancer risk stratification: data from a population-based cohort in {Germany}},
	volume = {12},
	issn = {1868-7083},
	shorttitle = {Individual and joint contributions of genetic and methylation risk scores for enhancing lung cancer risk stratification},
	url = {https://doi.org/10.1186/s13148-020-00872-y},
	doi = {10.1186/s13148-020-00872-y},
	abstract = {Risk stratification for lung cancer (LC) screening is so far mostly based on smoking history. This study aimed to assess if and to what extent such risk stratification could be enhanced by additional consideration of genetic risk scores (GRSs) and epigenetic risk scores defined by DNA methylation.},
	language = {en},
	number = {1},
	urldate = {2021-05-03},
	journal = {Clinical Epigenetics},
	author = {Yu, Haixin and Raut, Janhavi R. and Schöttker, Ben and Holleczek, Bernd and Zhang, Yan and Brenner, Hermann},
	month = jun,
	year = {2020},
	pages = {89},
}



@article{huls_methodological_2020,
	title = {Methodological challenges in constructing {DNA} methylation risk scores},
	volume = {15},
	issn = {1559-2294},
	url = {https://doi.org/10.1080/15592294.2019.1644879},
	doi = {10.1080/15592294.2019.1644879},
	abstract = {Polygenic approaches often access more variance of complex traits than is possible by single variant approaches. For genotype data, genetic risk scores (GRS) are widely used for risk prediction as well as in association and interaction studies. Recently, interest has been growing in transferring GRS approaches to DNA methylation data (methylation risk scores, MRS), which can be used 1) as biomarkers for environmental exposures, 2) in association analyses in which single CpG sites do not achieve significance, 3) as dimension reduction approach in interaction and mediation analyses, and 4) to predict individual risks of disease or treatment success. Most GRS approaches can directly be transferred to methylation data. However, since methylation data is more sensitive to confounding, e.g. by age and tissue, it is more complex to find appropriate external weights. In this review, we will outline the adaption of current GRS approaches to methylation data and highlight occurring challenges.},
	number = {1-2},
	urldate = {2021-05-03},
	journal = {Epigenetics},
	author = {Hüls, Anke and Czamara, Darina},
	month = feb,
	year = {2020},
	pmid = {31318318},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/15592294.2019.1644879},
	keywords = {Polygenic epidemiology, epigenetic risk score, genetic risk scores, polygenic risk scores, prediction models, weighting strategies},
	pages = {1--11},
}

@article{sudlow_uk_2015,
	title = {{UK} {Biobank}: {An} {Open} {Access} {Resource} for {Identifying} the {Causes} of a {Wide} {Range} of {Complex} {Diseases} of {Middle} and {Old} {Age}},
	volume = {12},
	issn = {1549-1676},
	shorttitle = {{UK} {Biobank}},
	url = {https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1001779},
	doi = {10.1371/journal.pmed.1001779},
	abstract = {Cathie Sudlow and colleagues describe the UK Biobank, a large population-based prospective study, established to allow investigation of the genetic and non-genetic determinants of the diseases of middle and old age.},
	language = {en},
	number = {3},
	urldate = {2021-04-30},
	journal = {PLOS Medicine},
	author = {Sudlow, Cathie and Gallacher, John and Allen, Naomi and Beral, Valerie and Burton, Paul and Danesh, John and Downey, Paul and Elliott, Paul and Green, Jane and Landray, Martin and Liu, Bette and Matthews, Paul and Ong, Giok and Pell, Jill and Silman, Alan and Young, Alan and Sprosen, Tim and Peakman, Tim and Collins, Rory},
	month = mar,
	year = {2015},
	note = {Publisher: Public Library of Science},
	keywords = {Cohort studies, Global health, Intelligence tests, Magnetic resonance imaging, Prospective studies, Questionnaires, Research ethics, Scientists},
	pages = {e1001779},
}

@article{morgan_accuracy_2021,
	title = {Accuracy of {Practitioner} {Estimates} of {Probability} of {Diagnosis} {Before} and {After} {Testing}},
	issn = {2168-6106},
	url = {https://doi.org/10.1001/jamainternmed.2021.0269},
	doi = {10.1001/jamainternmed.2021.0269},
	abstract = {Accurate diagnosis is essential to proper patient care.To explore practitioner understanding of diagnostic reasoning.In this survey study, 723 practitioners at outpatient clinics in 8 US states were asked to estimate the probability of disease for 4 scenarios common in primary care (pneumonia, cardiac ischemia, breast cancer screening, and urinary tract infection) and the association of positive and negative test results with disease probability from June 1, 2018, to November 26, 2019. Of these practitioners, 585 responded to the survey, and 553 answered all of the questions. An expert panel developed the survey and determined correct responses based on literature review.A total of 553 (290 resident physicians, 202 attending physicians, and 61 nurse practitioners and physician assistants) of 723 practitioners (76.5\%) fully completed the survey (median age, 32 years; interquartile range, 29-44 years; 293 female [53.0\%]; 296 [53.5\%] White). Pretest probability was overestimated in all scenarios. Probabilities of disease after positive results were overestimated as follows: pneumonia after positive radiology results, 95\% (evidence range, 46\%-65\%; comparison P \&lt; .001); breast cancer after positive mammography results, 50\% (evidence range, 3\%-9\%; P \&lt; .001); cardiac ischemia after positive stress test result, 70\% (evidence range, 2\%-11\%; P \&lt; .001); and urinary tract infection after positive urine culture result, 80\% (evidence range, 0\%-8.3\%; P \&lt; .001). Overestimates of probability of disease with negative results were also observed as follows: pneumonia after negative radiography results, 50\% (evidence range, 10\%-19\%; P \&lt; .001); breast cancer after negative mammography results, 5\% (evidence range, \&lt;0.05\%; P \&lt; .001); cardiac ischemia after negative stress test result, 5\% (evidence range, 0.43\%-2.5\%; P \&lt; .001); and urinary tract infection after negative urine culture result, 5\% (evidence range, 0\%-0.11\%; P \&lt; .001). Probability adjustments in response to test results varied from accurate to overestimates of risk by type of test (imputed median positive and negative likelihood ratios [LRs] for practitioners for chest radiography for pneumonia: positive LR, 4.8; evidence, 2.6; negative LR, 0.3; evidence, 0.3; mammography for breast cancer: positive LR, 44.3; evidence range, 13.0-33.0; negative LR, 1.0; evidence range, 0.05-0.24; exercise stress test for cardiac ischemia: positive LR, 21.0; evidence range, 2.0-2.7; negative LR, 0.6; evidence range, 0.5-0.6; urine culture for urinary tract infection: positive LR, 9.0; evidence, 9.0; negative LR, 0.1; evidence, 0.1).This survey study suggests that for common diseases and tests, practitioners overestimate the probability of disease before and after testing. Pretest probability was overestimated in all scenarios, whereas adjustment in probability after a positive or negative result varied by test. Widespread overestimates of the probability of disease likely contribute to overdiagnosis and overuse.},
	urldate = {2021-04-19},
	journal = {JAMA Internal Medicine},
	author = {Morgan, Daniel J. and Pineles, Lisa and Owczarzak, Jill and Magder, Larry and Scherer, Laura and Brown, Jessica P. and Pfeiffer, Chris and Terndrup, Chris and Leykum, Luci and Feldstein, David and Foy, Andrew and Stevens, Deborah and Koch, Christina and Masnick, Max and Weisenberg, Scott and Korenstein, Deborah},
	month = apr,
	year = {2021},
}

@article{vos_comparison_2014,
	title = {Comparison of continuous non-invasive finger arterial pressure monitoring with conventional intermittent automated arm arterial pressure measurement in patients under general anaesthesia},
	volume = {113},
	issn = {0007-0912, 1471-6771},
	url = {https://www.bjanaesthesia.org.uk/article/S0007-0912(17)31546-5/abstract},
	doi = {10.1093/bja/aeu091},
	abstract = {{\textless}h3{\textgreater}Background{\textless}/h3{\textgreater}{\textless}p{\textgreater}For a majority of patients undergoing anaesthesia for general surgery, mean arterial pressure (MAP) is only measured intermittently by arm cuff oscillometry (MAP$_{\textrm{iNIAP}}$). In contrast, the Nexfin$^{\textrm{®}}$ device provides continuous non-invasive measurement of MAP (MAP$_{\textrm{cNIAP}}$) using a finger cuff. We explored the agreement of MAP$_{\textrm{cNIAP}}$ and MAP$_{\textrm{iNIAP}}$ with the gold standard: continuous invasive MAP measurement by placement of a radial artery catheter (MAP$_{\textrm{invasive}}$).{\textless}/p{\textgreater}{\textless}h3{\textgreater}Methods{\textless}/h3{\textgreater}{\textless}p{\textgreater}In a total of 120 patients undergoing elective general surgery and clinically requiring MAP$_{\textrm{invasive}}$ measurement, MAP$_{\textrm{iNIAP}}$ and MAP$_{\textrm{cNIAP}}$ were measured in a 30 min time period at an arbitrary moment during surgery with stable haemodynamics. MAP$_{\textrm{iNIAP}}$ was measured every 5 min.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Results{\textless}/h3{\textgreater}{\textless}p{\textgreater}Data from 112 patients were analysed. Compared with MAP$_{\textrm{invasive}}$, modified Bland–Altman analysis revealed a bias (sd) of 2 (9) mm Hg for MAP$_{\textrm{cNIAP}}$ and −2 (12) mm Hg for MAP$_{\textrm{iNIAP}}$. Percentage errors for MAP$_{\textrm{cNIAP}}$ and MAP$_{\textrm{iNIAP}}$ were 22\% and 32\%, respectively.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Conclusions{\textless}/h3{\textgreater}{\textless}p{\textgreater}In a haemodynamically stable phase in patients undergoing general anaesthesia, the agreement with invasive MAP of continuous non-invasive measurement using a finger cuff was not inferior to the agreement of intermittent arm cuff oscillometry. Continuous measurements using a finger cuff can interchangeably be used as an alternative for intermittent arm cuff oscillometry in haemodynamically stable patients, with the advantage of beat-to-beat haemodynamic monitoring.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Clinical trial registration{\textless}/h3{\textgreater}{\textless}p{\textgreater}NCT 01362335 (clinicaltrials.gov).{\textless}/p{\textgreater}},
	language = {English},
	number = {1},
	urldate = {2021-04-13},
	journal = {British Journal of Anaesthesia},
	author = {Vos, J. J. and Poterman, M. and Mooyaart, E. a. Q. and Weening, M. and Struys, M. M. R. F. and Scheeren, T. W. L. and Kalmar, A. F.},
	month = jul,
	year = {2014},
	pmid = {24740992},
	note = {Publisher: Elsevier},
	pages = {67--74},
}

@article{birney_epigenome-wide_2016,
	title = {Epigenome-wide {Association} {Studies} and the {Interpretation} of {Disease} -{Omics}},
	volume = {12},
	issn = {1553-7404},
	url = {https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1006105},
	doi = {10.1371/journal.pgen.1006105},
	abstract = {Epigenome-wide association studies represent one means of applying genome-wide assays to identify molecular events that could be associated with human phenotypes. The epigenome is especially intriguing as a target for study, as epigenetic regulatory processes are, by definition, heritable from parent to daughter cells and are found to have transcriptional regulatory properties. As such, the epigenome is an attractive candidate for mediating long-term responses to cellular stimuli, such as environmental effects modifying disease risk. Such epigenomic studies represent a broader category of disease -omics, which suffer from multiple problems in design and execution that severely limit their interpretability. Here we define many of the problems with current epigenomic studies and propose solutions that can be applied to allow this and other disease -omics studies to achieve their potential for generating valuable insights.},
	language = {en},
	number = {6},
	urldate = {2021-04-09},
	journal = {PLOS Genetics},
	author = {Birney, Ewan and Smith, George Davey and Greally, John M.},
	month = jun,
	year = {2016},
	note = {Publisher: Public Library of Science},
	keywords = {Biomarkers, DNA methylation, DNA transcription, Epigenetics, Epigenomics, Genetic polymorphism, Genome-wide association studies, Phenotypes},
	pages = {e1006105},
}

@article{candes_power_2009,
	title = {The {Power} of {Convex} {Relaxation}: {Near}-{Optimal} {Matrix} {Completion}},
	shorttitle = {The {Power} of {Convex} {Relaxation}},
	url = {http://arxiv.org/abs/0903.1476},
	abstract = {This paper is concerned with the problem of recovering an unknown matrix from a small fraction of its entries. This is known as the matrix completion problem, and comes up in a great number of applications, including the famous Netflix Prize and other similar questions in collaborative filtering. In general, accurate recovery of a matrix from a small number of entries is impossible; but the knowledge that the unknown matrix has low rank radically changes this premise, making the search for solutions meaningful. This paper presents optimality results quantifying the minimum number of entries needed to recover a matrix of rank r exactly by any method whatsoever (the information theoretic limit). More importantly, the paper shows that, under certain incoherence assumptions on the singular vectors of the matrix, recovery is possible by solving a convenient convex program as soon as the number of entries is on the order of the information theoretic limit (up to logarithmic factors). This convex program simply finds, among all matrices consistent with the observed entries, that with minimum nuclear norm. As an example, we show that on the order of nr log(n) samples are needed to recover a random n x n matrix of rank r by any method, and to be sure, nuclear norm minimization succeeds as soon as the number of entries is of the form nr polylog(n).},
	urldate = {2021-04-09},
	journal = {arXiv:0903.1476 [cs, math]},
	author = {Candes, Emmanuel J. and Tao, Terence},
	month = mar,
	year = {2009},
	note = {arXiv: 0903.1476},
	keywords = {Computer Science - Information Theory},
}

@misc{noauthor_noncontact_nodate,
	title = {Noncontact {Physiological} {Measurement} {Using} a {Camera}: {A} {Technical} {Review} and {Future} {Directions} {\textbar} {ACS} {Sensors}},
	url = {https://pubs.acs.org/doi/10.1021/acssensors.0c02042},
	urldate = {2021-04-06},
}

@inproceedings{lu_dvc_2019,
	address = {Long Beach, CA, USA},
	title = {{DVC}: {An} {End}-{To}-{End} {Deep} {Video} {Compression} {Framework}},
	isbn = {978-1-72813-293-8},
	shorttitle = {{DVC}},
	url = {https://ieeexplore.ieee.org/document/8953892/},
	doi = {10.1109/CVPR.2019.01126},
	abstract = {Conventional video compression approaches use the predictive coding architecture and encode the corresponding motion information and residual information. In this paper, taking advantage of both classical architecture in the conventional video compression method and the powerful nonlinear representation ability of neural networks, we propose the ﬁrst end-to-end video compression deep model that jointly optimizes all the components for video compression. Speciﬁcally, learning based optical ﬂow estimation is utilized to obtain the motion information and reconstruct the current frames. Then we employ two auto-encoder style neural networks to compress the corresponding motion and residual information. All the modules are jointly learned through a single loss function, in which they collaborate with each other by considering the trade-off between reducing the number of compression bits and improving quality of the decoded video. Experimental results show that the proposed approach can outperform the widely used video coding standard H.264 in terms of PSNR and be even on par with the latest standard H.265 in terms of MS-SSIM. Code is released at https://github.com/GuoLusjtu/DVC.},
	language = {en},
	urldate = {2021-03-31},
	booktitle = {2019 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Lu, Guo and Ouyang, Wanli and Xu, Dong and Zhang, Xiaoyun and Cai, Chunlei and Gao, Zhiyong},
	month = jun,
	year = {2019},
	pages = {10998--11007},
}

@article{lombardo_deep_nodate,
	title = {Deep {Generative} {Video} {Compression}},
	abstract = {The usage of deep generative models for image compression has led to impressive performance gains over classical codecs while neural video compression is still in its infancy. Here, we propose an end-to-end, deep generative modeling approach to compress temporal sequences with a focus on video. Our approach builds upon variational autoencoder (VAE) models for sequential data and combines them with recent work on neural image compression. The approach jointly learns to transform the original sequence into a lower-dimensional representation as well as to discretize and entropy code this representation according to predictions of the sequential VAE. Rate-distortion evaluations on small videos from public data sets with varying complexity and diversity show that our model yields competitive results when trained on generic video content. Extreme compression performance is achieved when training the model on specialized content.},
	language = {en},
	author = {Lombardo, Salvator and Han, Jun and Schroers, Christopher and Mandt, Stephan},
	pages = {12},
}

@article{van_buuren_multiple_2007,
	title = {Multiple imputation of discrete and continuous data by fully conditional specification},
	volume = {16},
	issn = {0962-2802},
	url = {https://doi.org/10.1177/0962280206074463},
	doi = {10.1177/0962280206074463},
	abstract = {The goal of multiple imputation is to provide valid inferences for statistical estimates from incomplete data. To achieve that goal, imputed values should preserve the structure in the data, as well as the uncertainty about this structure, and include any knowledge about the process that generated the missing data. Two approaches for imputing multivariate data exist: joint modeling (JM) and fully conditional specification (FCS). JM is based on parametric statistical theory, and leads to imputation procedures whose statistical properties are known. JM is theoretically sound, but the joint model may lack flexibility needed to represent typical data features, potentially leading to bias. FCS is a semi-parametric and flexible alternative that specifies the multivariate model by a series of conditional models, one for each incomplete variable. FCS provides tremendous flexibility and is easy to apply, but its statistical properties are difficult to establish. Simulation work shows that FCS behaves very well in the cases studied. The present paper reviews and compares the approaches. JM and FCS were applied to pubertal development data of 3801 Dutch girls that had missing data on menarche (two categories), breast development (five categories) and pubic hair development (six stages). Imputations for these data were created under two models: a multivariate normal model with rounding and a conditionally specified discrete model. The JM approach introduced biases in the reference curves, whereas FCS did not. The paper concludes that FCS is a useful and easily applied flexible alternative to JM when no convenient and realistic joint distribution can be specified.},
	language = {en},
	number = {3},
	urldate = {2021-03-26},
	journal = {Statistical Methods in Medical Research},
	author = {van Buuren, Stef},
	month = jun,
	year = {2007},
	note = {Publisher: SAGE Publications Ltd STM},
	pages = {219--242},
}

@article{raghunathan_multivariate_2001,
	title = {A {Multivariate} {Technique} for {Multiply} {Imputing} {Missing} {Values} {Using} a {Sequence} of {Regression} {Models}},
	abstract = {This article describes and evaluates a procedure for imputing missing values for a relatively complex data structure when the data are missing at random. The imputations are obtained by fitting a sequence of regression models and drawing values from the corresponding predictive distributions. The types of regression models used are linear, logistic, Poisson, generalized logit or a mixture of these depending on the type of variable being imputed. Two additional common features in the imputation process are incorporated: restriction to a relevant subpopulation for some variables and logical bounds or constraints for the imputed values. The restrictions involve subsetting the sample individuals that satisfy certain criteria while fitting the regression models. The bounds involve drawing values from a truncated predictive distribution. The development of this method was partly motivated by the analysis of two data sets which are used as illustrations. The sequential regression procedure is applied to perform multiple imputation analysis for the two applied problems. The sampling properties of inferences from multiply imputed data sets created using the sequential regression method are evaluated through simulated data sets.},
	language = {en},
	number = {12},
	journal = {Survey Methodology},
	author = {Raghunathan, Trivellore E and Lepkowski, James M and Hoewyk, John Van and Solenberger, Peter},
	year = {2001},
	pages = {11},
}

@article{malinsky_semiparametric_2020,
	title = {Semiparametric {Inference} for {Non}-monotone {Missing}-{Not}-at-{Random} {Data}: the {No} {Self}-{Censoring} {Model}},
	shorttitle = {Semiparametric {Inference} for {Non}-monotone {Missing}-{Not}-at-{Random} {Data}},
	url = {http://arxiv.org/abs/1909.01848},
	abstract = {We study the identification and estimation of statistical functionals of multivariate data missing non-monotonically and not-at-random, taking a semiparametric approach. Specifically, we assume that the missingness mechanism satisfies what has been previously called "no self-censoring" or "itemwise conditionally independent nonresponse," which roughly corresponds to the assumption that no partially-observed variable directly determines its own missingness status. We show that this assumption, combined with an odds ratio parameterization of the joint density, enables identification of functionals of interest, and we establish the semiparametric efficiency bound for the nonparametric model satisfying this assumption. We propose a practical augmented inverse probability weighted estimator, and in the setting with a (possibly high-dimensional) always-observed subset of covariates, our proposed estimator enjoys a certain double-robustness property. We explore the performance of our estimator with simulation experiments and on a previously-studied data set of HIV-positive mothers in Botswana.},
	urldate = {2021-03-25},
	journal = {arXiv:1909.01848 [math, stat]},
	author = {Malinsky, Daniel and Shpitser, Ilya and Tchetgen, Eric J. Tchetgen},
	month = dec,
	year = {2020},
	note = {arXiv: 1909.01848},
	keywords = {Mathematics - Statistics Theory, Statistics - Methodology},
}

@article{rennie_loss_nodate,
	title = {Loss {Functions} for {Preference} {Levels}: {Regression} with {Discrete} {Ordered} {Labels}},
	abstract = {We consider different types of loss functions for discrete ordinal regression, i.e. ﬁtting labels that may take one of several discrete, but ordered, values. These types of labels arise when preferences are speciﬁed by selecting, for each item, one of several rating “levels”, e.g. one through ﬁve stars. We present two general threshold-based constructions which can be used to generalize loss functions for binary labels, such as the logistic and hinge loss, and another generalization of the logistic loss based on a probabilistic model for discrete ordered labels. Experiments on the 1 Million MovieLens data set indicate that one of our construction is a signiﬁcant improvement over previous classiﬁcation- and regression-based approaches.},
	language = {en},
	author = {Rennie, Jason D M and Srebro, Nathan},
	pages = {6},
}

@article{zhao_deepfhr_2019,
	title = {{DeepFHR}: intelligent prediction of fetal {Acidemia} using fetal heart rate signals based on convolutional neural network},
	volume = {19},
	issn = {1472-6947},
	shorttitle = {{DeepFHR}},
	url = {https://doi.org/10.1186/s12911-019-1007-5},
	doi = {10.1186/s12911-019-1007-5},
	abstract = {Fetal heart rate (FHR) monitoring is a screening tool used by obstetricians to evaluate the fetal state. Because of the complexity and non-linearity, a visual interpretation of FHR signals using common guidelines usually results in significant subjective inter-observer and intra-observer variability. Objective: Therefore, computer aided diagnosis (CAD) systems based on advanced artificial intelligence (AI) technology have recently been developed to assist obstetricians in making objective medical decisions.},
	number = {1},
	urldate = {2021-03-24},
	journal = {BMC Medical Informatics and Decision Making},
	author = {Zhao, Zhidong and Deng, Yanjun and Zhang, Yang and Zhang, Yefei and Zhang, Xiaohong and Shao, Lihuan},
	month = dec,
	year = {2019},
	keywords = {Computer aided diagnosis system, Continuous wavelet transform, Convolutional neural network, Fetal acidemia, Fetal heart rate},
	pages = {286},
}

@article{schussler-fiorenza_rose_longitudinal_2019,
	title = {A longitudinal big data approach for precision health},
	volume = {25},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-170X},
	url = {https://www.nature.com/articles/s41591-019-0414-6},
	doi = {10.1038/s41591-019-0414-6},
	abstract = {Precision health relies on the ability to assess disease risk at an individual level, detect early preclinical conditions and initiate preventive strategies. Recent technological advances in omics and wearable monitoring enable deep molecular and physiological profiling and may provide important tools for precision health. We explored the ability of deep longitudinal profiling to make health-related discoveries, identify clinically relevant molecular pathways and affect behavior in a prospective longitudinal cohort (n = 109) enriched for risk of type 2 diabetes mellitus. The cohort underwent integrative personalized omics profiling from samples collected quarterly for up to 8 years (median, 2.8 years) using clinical measures and emerging technologies including genome, immunome, transcriptome, proteome, metabolome, microbiome and wearable monitoring. We discovered more than 67 clinically actionable health discoveries and identified multiple molecular pathways associated with metabolic, cardiovascular and oncologic pathophysiology. We developed prediction models for insulin resistance by using omics measurements, illustrating their potential to replace burdensome tests. Finally, study participation led the majority of participants to implement diet and exercise changes. Altogether, we conclude that deep longitudinal profiling can lead to actionable health discoveries and provide relevant information for precision health.},
	language = {en},
	number = {5},
	urldate = {2021-03-23},
	journal = {Nature Medicine},
	author = {Schüssler-Fiorenza Rose, Sophia Miryam and Contrepois, Kévin and Moneghetti, Kegan J. and Zhou, Wenyu and Mishra, Tejaswini and Mataraso, Samson and Dagan-Rosenfeld, Orit and Ganz, Ariel B. and Dunn, Jessilyn and Hornburg, Daniel and Rego, Shannon and Perelman, Dalia and Ahadi, Sara and Sailani, M. Reza and Zhou, Yanjiao and Leopold, Shana R. and Chen, Jieming and Ashland, Melanie and Christle, Jeffrey W. and Avina, Monika and Limcaoco, Patricia and Ruiz, Camilo and Tan, Marilyn and Butte, Atul J. and Weinstock, George M. and Slavich, George M. and Sodergren, Erica and McLaughlin, Tracey L. and Haddad, Francois and Snyder, Michael P.},
	month = may,
	year = {2019},
	note = {Number: 5
Publisher: Nature Publishing Group},
	pages = {792--804},
}

@article{chen_deepphys_2018,
	title = {{DeepPhys}: {Video}-{Based} {Physiological} {Measurement} {Using} {Convolutional} {Attention} {Networks}},
	shorttitle = {{DeepPhys}},
	url = {http://arxiv.org/abs/1805.07888},
	abstract = {Non-contact video-based physiological measurement has many applications in health care and human-computer interaction. Practical applications require measurements to be accurate even in the presence of large head rotations. We propose the first end-to-end system for video-based measurement of heart and breathing rate using a deep convolutional network. The system features a new motion representation based on a skin reflection model and a new attention mechanism using appearance information to guide motion estimation, both of which enable robust measurement under heterogeneous lighting and major motions. Our approach significantly outperforms all current state-of-the-art methods on both RGB and infrared video datasets. Furthermore, it allows spatial-temporal distributions of physiological signals to be visualized via the attention mechanism.},
	urldate = {2021-03-23},
	journal = {arXiv:1805.07888 [cs]},
	author = {Chen, Weixuan and McDuff, Daniel},
	month = aug,
	year = {2018},
	note = {arXiv: 1805.07888},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Human-Computer Interaction},
}

@article{zheng_learning_2017,
	title = {Learning {Multi}-{Attention} {Convolutional} {Neural} {Network} for {Fine}-{Grained} {Image} {Recognition} ({ICCV} 2017 {Oral})},
	url = {https://www.microsoft.com/en-us/research/publication/learning-multi-attention-convolutional-neural-network-fine-grained-image-recognition/},
	abstract = {Recognizing fine-grained categories (e.g., bird species) highly relies on discriminative part localization and part-based fine-grained feature learning. Existing approaches predominantly solve these challenges independently, while neglecting the fact that part localization (e.g., head of a bird) and fine-grained feature learning (e.g., head shape) are mutually correlated. In this paper, we propose a novel part learning […]},
	language = {en-US},
	urldate = {2021-03-23},
	author = {Zheng, Heliang and Fu, Jianlong and Mei, Tao and Luo, Jiebo},
	month = oct,
	year = {2017},
}

@article{malinin_predictive_2018,
	title = {Predictive {Uncertainty} {Estimation} via {Prior} {Networks}},
	url = {http://arxiv.org/abs/1802.10501},
	abstract = {Estimating how uncertain an AI system is in its predictions is important to improve the safety of such systems. Uncertainty in predictive can result from uncertainty in model parameters, irreducible data uncertainty and uncertainty due to distributional mismatch between the test and training data distributions. Different actions might be taken depending on the source of the uncertainty so it is important to be able to distinguish between them. Recently, baseline tasks and metrics have been defined and several practical methods to estimate uncertainty developed. These methods, however, attempt to model uncertainty due to distributional mismatch either implicitly through model uncertainty or as data uncertainty. This work proposes a new framework for modeling predictive uncertainty called Prior Networks (PNs) which explicitly models distributional uncertainty. PNs do this by parameterizing a prior distribution over predictive distributions. This work focuses on uncertainty for classification and evaluates PNs on the tasks of identifying out-of-distribution (OOD) samples and detecting misclassification on the MNIST dataset, where they are found to outperform previous methods. Experiments on synthetic and MNIST and CIFAR-10 data show that unlike previous non-Bayesian methods PNs are able to distinguish between data and distributional uncertainty.},
	urldate = {2021-03-22},
	journal = {arXiv:1802.10501 [cs, stat]},
	author = {Malinin, Andrey and Gales, Mark},
	month = nov,
	year = {2018},
	note = {arXiv: 1802.10501},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{amini_deep_2020,
	title = {Deep {Evidential} {Regression}},
	url = {http://arxiv.org/abs/1910.02600},
	abstract = {Deterministic neural networks (NNs) are increasingly being deployed in safety critical domains, where calibrated, robust, and efficient measures of uncertainty are crucial. In this paper, we propose a novel method for training non-Bayesian NNs to estimate a continuous target as well as its associated evidence in order to learn both aleatoric and epistemic uncertainty. We accomplish this by placing evidential priors over the original Gaussian likelihood function and training the NN to infer the hyperparameters of the evidential distribution. We additionally impose priors during training such that the model is regularized when its predicted evidence is not aligned with the correct output. Our method does not rely on sampling during inference or on out-of-distribution (OOD) examples for training, thus enabling efficient and scalable uncertainty learning. We demonstrate learning well-calibrated measures of uncertainty on various benchmarks, scaling to complex computer vision tasks, as well as robustness to adversarial and OOD test samples.},
	urldate = {2021-03-22},
	journal = {arXiv:1910.02600 [cs, stat]},
	author = {Amini, Alexander and Schwarting, Wilko and Soleimany, Ava and Rus, Daniela},
	month = nov,
	year = {2020},
	note = {arXiv: 1910.02600},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@article{selvaraju_grad-cam_2020,
	title = {Grad-{CAM}: {Visual} {Explanations} from {Deep} {Networks} via {Gradient}-based {Localization}},
	volume = {128},
	issn = {0920-5691, 1573-1405},
	shorttitle = {Grad-{CAM}},
	url = {http://arxiv.org/abs/1610.02391},
	doi = {10.1007/s11263-019-01228-7},
	abstract = {We propose a technique for producing "visual explanations" for decisions from a large class of CNN-based models, making them more transparent. Our approach - Gradient-weighted Class Activation Mapping (Grad-CAM), uses the gradients of any target concept, flowing into the final convolutional layer to produce a coarse localization map highlighting important regions in the image for predicting the concept. Grad-CAM is applicable to a wide variety of CNN model-families: (1) CNNs with fully-connected layers, (2) CNNs used for structured outputs, (3) CNNs used in tasks with multimodal inputs or reinforcement learning, without any architectural changes or re-training. We combine Grad-CAM with fine-grained visualizations to create a high-resolution class-discriminative visualization and apply it to off-the-shelf image classification, captioning, and visual question answering (VQA) models, including ResNet-based architectures. In the context of image classification models, our visualizations (a) lend insights into their failure modes, (b) are robust to adversarial images, (c) outperform previous methods on localization, (d) are more faithful to the underlying model and (e) help achieve generalization by identifying dataset bias. For captioning and VQA, we show that even non-attention based models can localize inputs. We devise a way to identify important neurons through Grad-CAM and combine it with neuron names to provide textual explanations for model decisions. Finally, we design and conduct human studies to measure if Grad-CAM helps users establish appropriate trust in predictions from models and show that Grad-CAM helps untrained users successfully discern a 'stronger' nodel from a 'weaker' one even when both make identical predictions. Our code is available at https://github.com/ramprs/grad-cam/, along with a demo at http://gradcam.cloudcv.org, and a video at youtu.be/COjUB9Izk6E.},
	number = {2},
	urldate = {2021-03-22},
	journal = {International Journal of Computer Vision},
	author = {Selvaraju, Ramprasaath R. and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
	month = feb,
	year = {2020},
	note = {arXiv: 1610.02391},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	pages = {336--359},
}

@article{xu_enmix_2016,
	title = {{ENmix}: a novel background correction method for {Illumina} {HumanMethylation450} {BeadChip}},
	volume = {44},
	issn = {0305-1048},
	shorttitle = {{ENmix}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4756845/},
	doi = {10.1093/nar/gkv907},
	abstract = {The Illumina HumanMethylation450 BeadChip is increasingly utilized in epigenome-wide association studies, however, this array-based measurement of DNA methylation is subject to measurement variation. Appropriate data preprocessing to remove background noise is important for detecting the small changes that may be associated with disease. We developed a novel background correction method, ENmix, that uses a mixture of exponential and truncated normal distributions to flexibly model signal intensity and uses a truncated normal distribution to model background noise. Depending on data availability, we employ three approaches to estimate background normal distribution parameters using (i) internal chip negative controls, (ii) out-of-band Infinium I probe intensities or (iii) combined methylated and unmethylated intensities. We evaluate ENmix against other available methods for both reproducibility among duplicate samples and accuracy of methylation measurement among laboratory control samples. ENmix out-performed other background correction methods for both these measures and substantially reduced the probe-design type bias between Infinium I and II probes. In reanalysis of existing EWAS data we show that ENmix can identify additional CpGs, and results in smaller P-value estimates for previously-validated CpGs. We incorporated the method into R package ENmix, which is freely available from Bioconductor website.},
	number = {3},
	urldate = {2021-03-22},
	journal = {Nucleic Acids Research},
	author = {Xu, Zongli and Niu, Liang and Li, Leping and Taylor, Jack A.},
	month = feb,
	year = {2016},
	pmid = {26384415},
	pmcid = {PMC4756845},
	pages = {e20},
}

@article{browning_rapid_2007,
	title = {Rapid and {Accurate} {Haplotype} {Phasing} and {Missing}-{Data} {Inference} for {Whole}-{Genome} {Association} {Studies} {By} {Use} of {Localized} {Haplotype} {Clustering}},
	volume = {81},
	issn = {0002-9297, 1537-6605},
	url = {https://www.cell.com/ajhg/abstract/S0002-9297(07)63882-8},
	doi = {10.1086/521987},
	language = {English},
	number = {5},
	urldate = {2021-03-22},
	journal = {The American Journal of Human Genetics},
	author = {Browning, Sharon R. and Browning, Brian L.},
	month = nov,
	year = {2007},
	pmid = {17924348},
	note = {Publisher: Elsevier},
	pages = {1084--1097},
}

@article{yang_gcta_2011,
	title = {{GCTA}: {A} {Tool} for {Genome}-wide {Complex} {Trait} {Analysis}},
	volume = {88},
	issn = {0002-9297},
	shorttitle = {{GCTA}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3014363/},
	doi = {10.1016/j.ajhg.2010.11.011},
	abstract = {For most human complex diseases and traits, SNPs identified by genome-wide association studies (GWAS) explain only a small fraction of the heritability. Here we report a user-friendly software tool called genome-wide complex trait analysis (GCTA), which was developed based on a method we recently developed to address the “missing heritability” problem. GCTA estimates the variance explained by all the SNPs on a chromosome or on the whole genome for a complex trait rather than testing the association of any particular SNP to the trait. We introduce GCTA's five main functions: data management, estimation of the genetic relationships from SNPs, mixed linear model analysis of variance explained by the SNPs, estimation of the linkage disequilibrium structure, and GWAS simulation. We focus on the function of estimating the variance explained by all the SNPs on the X chromosome and testing the hypotheses of dosage compensation. The GCTA software is a versatile tool to estimate and partition complex trait variation with large GWAS data sets.},
	number = {1},
	urldate = {2021-03-22},
	journal = {American Journal of Human Genetics},
	author = {Yang, Jian and Lee, S. Hong and Goddard, Michael E. and Visscher, Peter M.},
	month = jan,
	year = {2011},
	pmid = {21167468},
	pmcid = {PMC3014363},
	pages = {76--82},
}

@article{nishidate_simple_2020,
	title = {Simple and affordable imaging of multiple physiological parameters with {RGB} camera-based diffuse reflectance spectroscopy},
	volume = {11},
	copyright = {\&\#169; 2020 Optical Society of America},
	issn = {2156-7085},
	url = {https://www.osapublishing.org/boe/abstract.cfm?uri=boe-11-2-1073},
	doi = {10.1364/BOE.382270},
	abstract = {We propose a simple and affordable imaging technique to evaluate transcutaneously multiple physiological parameters by using a digital red-green-blue camera. In this method, the RGB-values were converted into tristimulus values in the CIE (Commission Internationale de l\&\#x2019;Eclairage) XYZ color space, which is compatible with the common color spaces. Monte Carlo simulation for light transport in biological tissue was then performed to specify the relationship among the XYZ-values and the concentrations of oxygenated hemoglobin, deoxygenated hemoglobin, bilirubin, and melanin. The concentration of total hemoglobin and tissue oxygen saturation were also calculated from the estimated concentrations of oxygenated and deoxygenated hemoglobin. In vivo experiments with bile duct ligation in rats demonstrated that the estimated bilirubin concentration increased after ligation of the bile duct and reached around 22 mg/dl at 116 h after the onset of ligation, which corresponds to the ground truth value of bilirubin measured by a commercially available transcutaneous bilirubinometer. Experiments with rats while varying the fraction of inspired oxygen demonstrated that oxygenated hemoglobin and deoxygenated hemoglobin decreased and increased, respectively, as the fraction of inspired oxygen decreased. Consequently, tissue oxygen saturation dramatically decreased. We further extended the method to a non-contact imaging photo-plethysmograph and estimation of the percutaneous oxygen saturation. An empirical formula to estimate percutaneous oxygen saturation was derived from the pulse wave amplitudes of oxygenated and deoxygenated hemoglobin. The estimated percutaneous oxygen saturation dropped remarkably when a faction of inspired oxygen was below 19\&\#x0025;, indicating the onset of hypoxemia due to hypoxia, whereas the tissue oxygen saturation decreased gradually according to the reduction of the faction of inspired oxygen. The results in this study indicate the potential of this method for imaging of multiple physiological parameters in skin tissue and evaluating an optical biomedical imaging technique that enables cost-effective, easy-to-use, portable, remotely administered, and/or point-of-care solutions.},
	language = {EN},
	number = {2},
	urldate = {2021-03-22},
	journal = {Biomedical Optics Express},
	author = {Nishidate, Izumi and Minakawa, Masashi and McDuff, Daniel and Wares, MD Abdul and Wares, MD Abdul and Nakano, Kazuya and Haneishi, Hideaki and Aizu, Yoshihisa and Niizeki, Kyuichi},
	month = feb,
	year = {2020},
	note = {Publisher: Optical Society of America},
	pages = {1073--1091},
}

@article{mcduff_non-contact_2020,
	title = {Non-contact imaging of peripheral hemodynamics during cognitive and psychological stressors},
	volume = {10},
	copyright = {2020 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-020-67647-6},
	doi = {10.1038/s41598-020-67647-6},
	abstract = {Peripheral hemodynamics, measured via the blood volume pulse and vasomotion, provide a valuable way of monitoring physiological state. Camera imaging-based systems can be used to measure these peripheral signals without contact with the body, at distances of multiple meters. While researchers have paid attention to non-contact imaging photoplethysmography, the study of peripheral hemodynamics and the effect of autonomic nervous system activity on these signals has received less attention. Using a method, based on a tissue-like model of the skin, we extract melanin \$\${\textbackslash}text \{C\}\_\{m\}\$\$ and hemoglobin \$\${\textbackslash}text \{C\}\_\{HbO\}\$\$ concentrations from videos of the hand and face and show that significant decreases in peripheral pulse signal power (by 36\% ± 29\%) and vasomotion signal power (by 50\% ± 26\%) occur during periods of cognitive and psychological stress. Via three experiments we show that similar results are achieved across different stimuli and regions of skin (face and hand). While changes in peripheral pulse and vasomotion power were significant the changes in pulse rate variability were less consistent across subjects and tasks.},
	language = {en},
	number = {1},
	urldate = {2021-03-22},
	journal = {Scientific Reports},
	author = {McDuff, Daniel and Nishidate, Izumi and Nakano, Kazuya and Haneishi, Hideaki and Aoki, Yuta and Tanabe, Chihiro and Niizeki, Kyuichi and Aizu, Yoshihisa},
	month = jul,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {10884},
}

@article{chen_deepmag_2020,
	title = {{DeepMag}: {Source}-{Specific} {Change} {Magnification} {Using} {Gradient} {Ascent}},
	volume = {40},
	issn = {0730-0301},
	shorttitle = {{DeepMag}},
	url = {https://doi.org/10.1145/3408865},
	doi = {10.1145/3408865},
	abstract = {Many important physical phenomena involve subtle signals that are difficult to observe with the unaided eye, yet visualizing them can be very informative. Current motion magnification techniques can reveal these small temporal variations in video, but require precise prior knowledge about the target signal, and cannot deal with interference motions at a similar frequency. We present DeepMag, an end-to-end deep neural video-processing framework based on gradient ascent that enables automated magnification of subtle color and motion signals from a specific source, even in the presence of large motions of various velocities. The advantages of DeepMag are highlighted via the task of video-based physiological visualization. Through systematic quantitative and qualitative evaluation of the approach on videos with different levels of head motion, we compare the magnification of pulse and respiration to existing state-of-the-art methods. Our method produces magnified videos with substantially fewer artifacts and blurring whilst magnifying the physiological changes by a similar degree.},
	number = {1},
	urldate = {2021-03-22},
	journal = {ACM Transactions on Graphics},
	author = {Chen, Weixuan and McDuff, Daniel},
	month = sep,
	year = {2020},
	keywords = {Video magnification, deep learning},
	pages = {2:1--2:14},
}

@inproceedings{liu2021metaphys,
  title={MetaPhys: few-shot adaptation for non-contact physiological measurement},
  author={Liu, Xin and Jiang, Ziheng and Fromm, Josh and Xu, Xuhai and Patel, Shwetak and McDuff, Daniel},
  booktitle={Proceedings of the conference on health, inference, and learning},
  pages={154--163},
  year={2021}
}

@inproceedings{liu2022federated,
  title={Federated Remote Physiological Measurement with Imperfect Data},
  author={Liu, Xin and Zhang, Mingchuan and Jiang, Ziheng and Patel, Shwetak and McDuff, Daniel},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2155--2164},
  year={2022}
}

@article{nowara_benefit_2020,
	title = {The {Benefit} of {Distraction}: {Denoising} {Remote} {Vitals} {Measurements} using {Inverse} {Attention}},
	shorttitle = {The {Benefit} of {Distraction}},
	url = {http://arxiv.org/abs/2010.07770},
	abstract = {Attention is a powerful concept in computer vision. End-to-end networks that learn to focus selectively on regions of an image or video often perform strongly. However, other image regions, while not necessarily containing the signal of interest, may contain useful context. We present an approach that exploits the idea that statistics of noise may be shared between the regions that contain the signal of interest and those that do not. Our technique uses the inverse of an attention mask to generate a noise estimate that is then used to denoise temporal observations. We apply this to the task of camera-based physiological measurement. A convolutional attention network is used to learn which regions of a video contain the physiological signal and generate a preliminary estimate. A noise estimate is obtained by using the pixel intensities in the inverse regions of the learned attention mask, this in turn is used to refine the estimate of the physiological signal. We perform experiments on two large benchmark datasets and show that this approach produces state-of-the-art results, increasing the signal-to-noise ratio by up to 5.8 dB, reducing heart rate and breathing rate estimation error by as much as 30\%, recovering subtle pulse waveform dynamics, and generalizing from RGB to NIR videos without retraining.},
	urldate = {2021-03-22},
	journal = {arXiv:2010.07770 [cs, eess]},
	author = {Nowara, Ewa and McDuff, Daniel and Veeraraghavan, Ashok},
	month = oct,
	year = {2020},
	note = {arXiv: 2010.07770},
	keywords = {Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing},
}

@article{mcduff_advancing_2020,
	title = {Advancing {Non}-{Contact} {Vital} {Sign} {Measurement} using {Synthetic} {Avatars}},
	url = {http://arxiv.org/abs/2010.12949},
	abstract = {Non-contact physiological measurement has the potential to provide low-cost, non-invasive health monitoring. However, machine vision approaches are often limited by the availability and diversity of annotated video datasets resulting in poor generalization to complex real-life conditions. To address these challenges, this work proposes the use of synthetic avatars that display facial blood flow changes and allow for systematic generation of samples under a wide variety of conditions. Our results show that training on both simulated and real video data can lead to performance gains under challenging conditions. We show state-of-the-art performance on three large benchmark datasets and improved robustness to skin type and motion.},
	urldate = {2021-03-22},
	journal = {arXiv:2010.12949 [cs]},
	author = {McDuff, Daniel and Hernandez, Javier and Wood, Erroll and Liu, Xin and Baltrusaitis, Tadas},
	month = oct,
	year = {2020},
	note = {arXiv: 2010.12949},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{chen_deepmag_2018,
	title = {{DeepMag}: {Source} {Specific} {Motion} {Magnification} {Using} {Gradient} {Ascent}},
	shorttitle = {{DeepMag}},
	url = {http://arxiv.org/abs/1808.03338},
	abstract = {Many important physical phenomena involve subtle signals that are difficult to observe with the unaided eye, yet visualizing them can be very informative. Current motion magnification techniques can reveal these small temporal variations in video, but require precise prior knowledge about the target signal, and cannot deal with interference motions at a similar frequency. We present DeepMag an end-to-end deep neural video-processing framework based on gradient ascent that enables automated magnification of subtle color and motion signals from a specific source, even in the presence of large motions of various velocities. While the approach is generalizable, the advantages of DeepMag are highlighted via the task of video-based physiological visualization. Through systematic quantitative and qualitative evaluation of the approach on videos with different levels of head motion, we compare the magnification of pulse and respiration to existing state-of-the-art methods. Our method produces magnified videos with substantially fewer artifacts and blurring whilst magnifying the physiological changes by a similar degree.},
	urldate = {2021-03-22},
	journal = {arXiv:1808.03338 [cs]},
	author = {Chen, Weixuan and McDuff, Daniel},
	month = aug,
	year = {2018},
	note = {arXiv: 1808.03338},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Graphics, Computer Science - Human-Computer Interaction},
}

@article{nowara_systematic_2021,
	title = {Systematic analysis of video-based pulse measurement from compressed videos},
	volume = {12},
	copyright = {\&\#169; 2020 Optical Society of America},
	issn = {2156-7085},
	url = {https://www.osapublishing.org/boe/abstract.cfm?uri=boe-12-1-494},
	doi = {10.1364/BOE.408471},
	abstract = {Camera-based physiological measurement enables vital signs to be captured unobtrusively without contact with the body. Remote, or imaging, photoplethysmography involves recovering peripheral blood flow from subtle variations in video pixel intensities. While the pulse signal might be easy to obtain from high quality uncompressed videos, the signal-to-noise ratio drops dramatically with video bitrate. Uncompressed videos incur large file storage and data transfer costs, making analysis, manipulation and sharing challenging. To help address these challenges, we use compression specific supervised models to mitigate the effect of temporal video compression on heart rate estimates. We perform a systematic evaluation of the performance of state-of-the-art algorithms across different levels, and formats, of compression. We demonstrate that networks trained on compressed videos consistently outperform other benchmark methods, both on stationary videos and videos with significant rigid head motions. By training on videos with the same, or higher compression factor than test videos, we achieve improvements in signal-to-noise ratio (SNR) of up to 3 dB and mean absolute error (MAE) of up to 6 beats per minute (BPM).},
	language = {EN},
	number = {1},
	urldate = {2021-03-22},
	journal = {Biomedical Optics Express},
	author = {Nowara, Ewa M. and McDuff, Daniel and Veeraraghavan, Ashok},
	month = jan,
	year = {2021},
	note = {Publisher: Optical Society of America},
	pages = {494--508},
}

@article{hernandez_deepfn_2021,
	title = {{DeepFN}: {Towards} {Generalizable} {Facial} {Action} {Unit} {Recognition} with {Deep} {Face} {Normalization}},
	shorttitle = {{DeepFN}},
	url = {http://arxiv.org/abs/2103.02484},
	abstract = {Facial action unit recognition has many applications from market research to psychotherapy and from image captioning to entertainment. Despite its recent progress, deployment of these models has been impeded due to their limited generalization to unseen people and demographics. This work conducts an in-depth analysis of performance across several dimensions: individuals(40 subjects), genders (male and female), skin types (darker and lighter), and databases (BP4D and DISFA). To help suppress the variance in data, we use the notion of self-supervised denoising autoencoders to design a method for deep face normalization(DeepFN) that transfers facial expressions of different people onto a common facial template which is then used to train and evaluate facial action recognition models. We show that person-independent models yield significantly lower performance (55\% average F1 and accuracy across 40 subjects) than person-dependent models (60.3\%), leading to a generalization gap of 5.3\%. However, normalizing the data with the newly introduced DeepFN significantly increased the performance of person-independent models (59.6\%), effectively reducing the gap. Similarly, we observed generalization gaps when considering gender (2.4\%), skin type (5.3\%), and dataset (9.4\%), which were significantly reduced with the use of DeepFN. These findings represent an important step towards the creation of more generalizable facial action unit recognition systems.},
	urldate = {2021-03-22},
	journal = {arXiv:2103.02484 [cs, eess]},
	author = {Hernandez, Javier and McDuff, Daniel and Ognjen and Rudovic and Fung, Alberto and Czerwinski, Mary},
	month = mar,
	year = {2021},
	note = {arXiv: 2103.02484},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing},
}

@article{mcduff_warm_2021,
	title = {"{Warm} {Bodies}": {A} {Post}-{Processing} {Technique} for {Animating} {Dynamic} {Blood} {Flow} on {Photos} and {Avatars}},
	shorttitle = {"{Warm} {Bodies}"},
	url = {http://arxiv.org/abs/2103.07987},
	abstract = {What breathes life into an embodied agent or avatar? While body motions such as facial expressions, speech and gestures have been well studied, relatively little attention has been applied to subtle changes due to underlying physiology. We argue that subtle pulse signals are important for creating more lifelike and less disconcerting avatars. We propose a method for animating blood flow patterns, based on a data-driven physiological model that can be used to directly augment the appearance of synthetic avatars and photo-realistic faces. While the changes are difficult for participants to "see", they significantly more frequently select faces with blood flow as more anthropomorphic and animated than faces without blood flow. Furthermore, by manipulating the frequency of the heart rate in the underlying signal we can change the perceived arousal of the character.},
	urldate = {2021-03-22},
	journal = {arXiv:2103.07987 [cs]},
	author = {McDuff, Daniel and Nowara, Ewa},
	month = mar,
	year = {2021},
	note = {arXiv: 2103.07987},
	keywords = {Computer Science - Graphics, Computer Science - Human-Computer Interaction},
}

@article{attia_zachi_i_age_2019,
	title = {Age and {Sex} {Estimation} {Using} {Artificial} {Intelligence} {From} {Standard} 12-{Lead} {ECGs}},
	volume = {12},
	url = {https://www.ahajournals.org/doi/full/10.1161/CIRCEP.119.007284},
	doi = {10.1161/CIRCEP.119.007284},
	abstract = {Background:Sex and age have long been known to affect the ECG. Several biologic variables and anatomic factors may contribute to sex and age-related differences on the ECG. We hypothesized that a convolutional neural network (CNN) could be trained through a process called deep learning to predict a person’s age and self-reported sex using only 12-lead ECG signals. We further hypothesized that discrepancies between CNN-predicted age and chronological age may serve as a physiological measure of health.Methods:We trained CNNs using 10-second samples of 12-lead ECG signals from 499 727 patients to predict sex and age. The networks were tested on a separate cohort of 275 056 patients. Subsequently, 100 randomly selected patients with multiple ECGs over the course of decades were identified to assess within-individual accuracy of CNN age estimation.Results:Of 275 056 patients tested, 52\% were males and mean age was 58.6±16.2 years. For sex classification, the model obtained 90.4\% classification accuracy with an area under the curve of 0.97 in the independent test data. Age was estimated as a continuous variable with an average error of 6.9±5.6 years (R-squared =0.7). Among 100 patients with multiple ECGs over the course of at least 2 decades of life, most patients (51\%) had an average error between real age and CNN-predicted age of {\textless}7 years. Major factors seen among patients with a CNN-predicted age that exceeded chronologic age by {\textgreater}7 years included: low ejection fraction, hypertension, and coronary disease (P{\textless}0.01). In the 27\% of patients where correlation was {\textgreater}0.8 between CNN-predicted and chronologic age, no incident events occurred over follow-up (33±12 years).Conclusions:Applying artificial intelligence to the ECG allows prediction of patient sex and estimation of age. The ability of an artificial intelligence algorithm to determine physiological age, with further validation, may serve as a measure of overall health.},
	number = {9},
	urldate = {2021-03-19},
	journal = {Circulation: Arrhythmia and Electrophysiology},
	author = {{Attia Zachi I.} and {Friedman Paul A.} and {Noseworthy Peter A.} and {Lopez-Jimenez Francisco} and {Ladewig Dorothy J.} and {Satam Gaurav} and {Pellikka Patricia A.} and {Munger Thomas M.} and {Asirvatham Samuel J.} and {Scott Christopher G.} and {Carter Rickey E.} and {Kapa Suraj}},
	month = sep,
	year = {2019},
	note = {Publisher: American Heart Association},
	pages = {e007284},
}

@article{purcell_plink_2007,
	title = {{PLINK}: {A} {Tool} {Set} for {Whole}-{Genome} {Association} and {Population}-{Based} {Linkage} {Analyses}},
	volume = {81},
	issn = {0002-9297},
	shorttitle = {{PLINK}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1950838/},
	abstract = {Whole-genome association studies (WGAS) bring new computational, as well as analytic, challenges to researchers. Many existing genetic-analysis tools are not designed to handle such large data sets in a convenient manner and do not necessarily exploit the new opportunities that whole-genome data bring. To address these issues, we developed PLINK, an open-source C/C++ WGAS tool set. With PLINK, large data sets comprising hundreds of thousands of markers genotyped for thousands of individuals can be rapidly manipulated and analyzed in their entirety. As well as providing tools to make the basic analytic steps computationally efficient, PLINK also supports some novel approaches to whole-genome data that take advantage of whole-genome coverage. We introduce PLINK and describe the five main domains of function: data management, summary statistics, population stratification, association analysis, and identity-by-descent estimation. In particular, we focus on the estimation and use of identity-by-state and identity-by-descent information in the context of population-based whole-genome studies. This information can be used to detect and correct for population stratification and to identify extended chromosomal segments that are shared identical by descent between very distantly related individuals. Analysis of the patterns of segmental sharing has the potential to map disease loci that contain multiple rare variants in a population-based linkage analysis.},
	number = {3},
	urldate = {2021-03-15},
	journal = {American Journal of Human Genetics},
	author = {Purcell, Shaun and Neale, Benjamin and Todd-Brown, Kathe and Thomas, Lori and Ferreira, Manuel A. R. and Bender, David and Maller, Julian and Sklar, Pamela and de Bakker, Paul I. W. and Daly, Mark J. and Sham, Pak C.},
	month = sep,
	year = {2007},
	pmid = {17701901},
	pmcid = {PMC1950838},
	pages = {559--575},
}

@article{fung_genome-wide_2019,
	title = {Genome-wide association study identifies loci for arterial stiffness index in 127,121 {UK} {Biobank} participants},
	volume = {9},
	copyright = {2019 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-019-45703-0},
	doi = {10.1038/s41598-019-45703-0},
	abstract = {Arterial stiffness index (ASI) is a non-invasive measure of arterial stiffness using infra-red finger sensors (photoplethysmography). It is a well-suited measure for large populations as it is relatively inexpensive to perform, and data can be acquired within seconds. These features raise interest in using ASI as a tool to estimate cardiovascular disease risk as prior work demonstrates increased arterial stiffness is associated with elevated systolic blood pressure, and ASI is predictive of cardiovascular disease and mortality. We conducted genome-wide association studies (GWASs) for ASI in 127,121 UK Biobank participants of European-ancestry. Our primary analyses identified variants at four loci reaching genome-wide significance (P {\textless} 5 × 10−8): TEX41 (rs1006923; P = 5.3 × 10−12), FOXO1 (rs7331212; P = 2.2 × 10−11), C1orf21 (rs1930290, P = 1.1 × 10−8) and MRVI1 (rs10840457, P = 3.4 × 10−8). Gene-based testing revealed three significant genes, the most significant gene was COL4A2 (P = 1.41 × 10−8) encoding type IV collagen. Other candidate genes at associated loci were also involved in smooth muscle tone regulation. Our findings provide new information for understanding the development of arterial stiffness.},
	language = {en},
	number = {1},
	urldate = {2021-03-15},
	journal = {Scientific Reports},
	author = {Fung, Kenneth and Ramírez, Julia and Warren, Helen R. and Aung, Nay and Lee, Aaron M. and Tzanis, Evan and Petersen, Steffen E. and Munroe, Patricia B.},
	month = jun,
	year = {2019},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {9143},
}

@article{chirinos_julio_a_ethnic_2011,
	title = {Ethnic {Differences} in {Arterial} {Wave} {Reflections} and {Normative} {Equations} for {Augmentation} {Index}},
	volume = {57},
	url = {https://www.ahajournals.org/doi/10.1161/hypertensionaha.110.166348},
	doi = {10.1161/HYPERTENSIONAHA.110.166348},
	abstract = {Data regarding ethnic differences in wave reflections, which markedly affect the central pressure profile, are very limited. Furthermore, because age, heart rate, and body height are strong determinants of augmentation index, relating single measurements to normative data (in which augmentation index values correspond with average population values of its determinants) is challenging. We studied subject-level data from 10 550 adults enrolled in large population-based studies. In a healthy reference sample (n=3497), we assessed ethnic differences in augmentation index (ratio of second/first systolic peaks) and generated equations for adjusted z scores, allowing for a standardized comparison between individual augmentation index measurements and the normative population mean from subjects of the same age, sex, ethnic population, body height, and heart rate. After adjustment for age, body height, heart rate, and mean arterial pressure, African blacks (women: 154\%; men: 138\%) and Andean Hispanics (women: 152\%; men: 133\%) demonstrated higher central (aortic) augmentation index values than British whites (women: 140\%; men: 128\%), whereas American Indians (women: 133\%; men: 122\%) demonstrated lower augmentation index (all P{\textless}0.0001), without significant differences between Chinese and British whites. Similar results were found for radial augmentation index. Nonlinear ethnic/sex-specific equations for z scores were successfully generated to adjust individual augmentation index values for age, body height, and heart rate. Marked ethnic differences in augmentation index exist, which may contribute to ethnic differences in hypertensive organ damage. Our study provides normative data that can be used to complement the interpretation of individual hemodynamic assessments among men and women of various ethnic populations, after removing the effect of various physiological determinants.},
	number = {6},
	urldate = {2021-03-15},
	journal = {Hypertension},
	author = {{Chirinos Julio A.} and {Kips Jan G.} and {Roman Mary J.} and {Medina-Lezama Josefina} and {Li Yan} and {Woodiwiss Angela J.} and {Norton Gavin R.} and {Yasmin null} and {Van Bortel Luc} and {Wang Ji-Guang} and {Cockcroft John R.} and {Devereux Richard B.} and {Wilkinson Ian B.} and {Segers Patrick} and {McEniery Carmel M.}},
	month = jun,
	year = {2011},
	note = {Publisher: American Heart Association},
	pages = {1108--1116},
}

@article{tester_genetics_2014,
	title = {{GENETICS} {OF} {LONG} {QT} {SYNDROME}},
	volume = {10},
	issn = {1947-6094},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4051331/},
	abstract = {Long QT syndrome (LQTS) is a potentially life-threatening cardiac arrhythmia characterized by delayed myocardial repolarization that produces QT prolongation and increased risk for torsades des pointes (TdP)-triggered syncope, seizures, and sudden cardiac death (SCD) in an otherwise healthy young individual with a structurally normal heart. Currently, there are three major LQTS genes (KCNQ1, KCNH2, and SCN5A) that account for approximately 75\% of the disorder. For the major LQTS genotypes, genotype-phenotype correlations have yielded gene-specific arrhythmogenic triggers, electrocardiogram (ECG) patterns, response to therapies, and intragenic and increasingly mutation-specific risk stratification. The 10 minor LQTS-susceptibility genes collectively account for less than 5\% of LQTS cases. In addition, three atypical LQTS or multisystem syndromic disorders that have been associated with QT prolongation have been described, including ankyrin-B syndrome, Anderson-Tawil syndrome (ATS), and Timothy syndrome (TS). Genetic testing for LQTS is recommended in patients with either a strong clinical index of suspicion or persistent QT prolongation despite their asymptomatic state. However, genetic test results must be interpreted carefully.},
	number = {1},
	urldate = {2021-03-15},
	journal = {Methodist DeBakey Cardiovascular Journal},
	author = {Tester, David J. and Ackerman, Michael J.},
	year = {2014},
	pmid = {24932360},
	pmcid = {PMC4051331},
	pages = {29--33},
}

@article{ntalla_multi-ancestry_2020,
	title = {Multi-ancestry {GWAS} of the electrocardiographic {PR} interval identifies 202 loci underlying cardiac conduction},
	volume = {11},
	copyright = {2020 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-020-15706-x},
	doi = {10.1038/s41467-020-15706-x},
	abstract = {The electrocardiographic PR interval reflects atrioventricular conduction, and is associated with conduction abnormalities, pacemaker implantation, atrial fibrillation (AF), and cardiovascular mortality. Here we report a multi-ancestry (N = 293,051) genome-wide association meta-analysis for the PR interval, discovering 202 loci of which 141 have not previously been reported. Variants at identified loci increase the percentage of heritability explained, from 33.5\% to 62.6\%. We observe enrichment for cardiac muscle developmental/contractile and cytoskeletal genes, highlighting key regulation processes for atrioventricular conduction. Additionally, 8 loci not previously reported harbor genes underlying inherited arrhythmic syndromes and/or cardiomyopathies suggesting a role for these genes in cardiovascular pathology in the general population. We show that polygenic predisposition to PR interval duration is an endophenotype for cardiovascular disease, including distal conduction disease, AF, and atrioventricular pre-excitation. These findings advance our understanding of the polygenic basis of cardiac conduction, and the genetic relationship between PR interval duration and cardiovascular disease.},
	language = {en},
	number = {1},
	urldate = {2021-03-15},
	journal = {Nature Communications},
	author = {Ntalla, Ioanna and Weng, Lu-Chen and Cartwright, James H. and Hall, Amelia Weber and Sveinbjornsson, Gardar and Tucker, Nathan R. and Choi, Seung Hoan and Chaffin, Mark D. and Roselli, Carolina and Barnes, Michael R. and Mifsud, Borbala and Warren, Helen R. and Hayward, Caroline and Marten, Jonathan and Cranley, James J. and Concas, Maria Pina and Gasparini, Paolo and Boutin, Thibaud and Kolcic, Ivana and Polasek, Ozren and Rudan, Igor and Araujo, Nathalia M. and Lima-Costa, Maria Fernanda and Ribeiro, Antonio Luiz P. and Souza, Renan P. and Tarazona-Santos, Eduardo and Giedraitis, Vilmantas and Ingelsson, Erik and Mahajan, Anubha and Morris, Andrew P. and Del Greco M, Fabiola and Foco, Luisa and Gögele, Martin and Hicks, Andrew A. and Cook, James P. and Lind, Lars and Lindgren, Cecilia M. and Sundström, Johan and Nelson, Christopher P. and Riaz, Muhammad B. and Samani, Nilesh J. and Sinagra, Gianfranco and Ulivi, Sheila and Kähönen, Mika and Mishra, Pashupati P. and Mononen, Nina and Nikus, Kjell and Caulfield, Mark J. and Dominiczak, Anna and Padmanabhan, Sandosh and Montasser, May E. and O’Connell, Jeff R. and Ryan, Kathleen and Shuldiner, Alan R. and Aeschbacher, Stefanie and Conen, David and Risch, Lorenz and Thériault, Sébastien and Hutri-Kähönen, Nina and Lehtimäki, Terho and Lyytikäinen, Leo-Pekka and Raitakari, Olli T. and Barnes, Catriona L. K. and Campbell, Harry and Joshi, Peter K. and Wilson, James F. and Isaacs, Aaron and Kors, Jan A. and van Duijn, Cornelia M. and Huang, Paul L. and Gudnason, Vilmundur and Harris, Tamara B. and Launer, Lenore J. and Smith, Albert V. and Bottinger, Erwin P. and Loos, Ruth J. F. and Nadkarni, Girish N. and Preuss, Michael H. and Correa, Adolfo and Mei, Hao and Wilson, James and Meitinger, Thomas and Müller-Nurasyid, Martina and Peters, Annette and Waldenberger, Melanie and Mangino, Massimo and Spector, Timothy D. and Rienstra, Michiel and van de Vegte, Yordi J. and van der Harst, Pim and Verweij, Niek and Kääb, Stefan and Schramm, Katharina and Sinner, Moritz F. and Strauch, Konstantin and Cutler, Michael J. and Fatkin, Diane and London, Barry and Olesen, Morten and Roden, Dan M. and Benjamin Shoemaker, M. and Gustav Smith, J. and Biggs, Mary L. and Bis, Joshua C. and Brody, Jennifer A. and Psaty, Bruce M. and Rice, Kenneth and Sotoodehnia, Nona and De Grandi, Alessandro and Fuchsberger, Christian and Pattaro, Cristian and Pramstaller, Peter P. and Ford, Ian and Wouter Jukema, J. and Macfarlane, Peter W. and Trompet, Stella and Dörr, Marcus and Felix, Stephan B. and Völker, Uwe and Weiss, Stefan and Havulinna, Aki S. and Jula, Antti and Sääksjärvi, Katri and Salomaa, Veikko and Guo, Xiuqing and Heckbert, Susan R. and Lin, Henry J. and Rotter, Jerome I. and Taylor, Kent D. and Yao, Jie and de Mutsert, Renée and Maan, Arie C. and Mook-Kanamori, Dennis O. and Noordam, Raymond and Cucca, Francesco and Ding, Jun and Lakatta, Edward G. and Qian, Yong and Tarasov, Kirill V. and Levy, Daniel and Lin, Honghuang and Newton-Cheh, Christopher H. and Lunetta, Kathryn L. and Murray, Alison D. and Porteous, David J. and Smith, Blair H. and Stricker, Bruno H. and Uitterlinden, André and van den Berg, Marten E. and Haessler, Jeffrey and Jackson, Rebecca D. and Kooperberg, Charles and Peters, Ulrike and Reiner, Alexander P. and Whitsel, Eric A. and Alonso, Alvaro and Arking, Dan E. and Boerwinkle, Eric and Ehret, Georg B. and Soliman, Elsayed Z. and Avery, Christy L. and Gogarten, Stephanie M. and Kerr, Kathleen F. and Laurie, Cathy C. and Seyerle, Amanda A. and Stilp, Adrienne and Assa, Solmaz and Abdullah Said, M. and Yldau van der Ende, M. and Lambiase, Pier D. and Orini, Michele and Ramirez, Julia and Van Duijvenboden, Stefan and Arnar, David O. and Gudbjartsson, Daniel F. and Holm, Hilma and Sulem, Patrick and Thorleifsson, Gudmar and Thorolfsdottir, Rosa B. and Thorsteinsdottir, Unnur and Benjamin, Emelia J. and Tinker, Andrew and Stefansson, Kari and Ellinor, Patrick T. and Jamshidi, Yalda and Lubitz, Steven A. and Munroe, Patricia B.},
	month = may,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {2542},
}

@article{tester_genetics_2014-1,
	title = {{GENETICS} {OF} {LONG} {QT} {SYNDROME}},
	volume = {10},
	issn = {1947-6094},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4051331/},
	abstract = {Long QT syndrome (LQTS) is a potentially life-threatening cardiac arrhythmia characterized by delayed myocardial repolarization that produces QT prolongation and increased risk for torsades des pointes (TdP)-triggered syncope, seizures, and sudden cardiac death (SCD) in an otherwise healthy young individual with a structurally normal heart. Currently, there are three major LQTS genes (KCNQ1, KCNH2, and SCN5A) that account for approximately 75\% of the disorder. For the major LQTS genotypes, genotype-phenotype correlations have yielded gene-specific arrhythmogenic triggers, electrocardiogram (ECG) patterns, response to therapies, and intragenic and increasingly mutation-specific risk stratification. The 10 minor LQTS-susceptibility genes collectively account for less than 5\% of LQTS cases. In addition, three atypical LQTS or multisystem syndromic disorders that have been associated with QT prolongation have been described, including ankyrin-B syndrome, Anderson-Tawil syndrome (ATS), and Timothy syndrome (TS). Genetic testing for LQTS is recommended in patients with either a strong clinical index of suspicion or persistent QT prolongation despite their asymptomatic state. However, genetic test results must be interpreted carefully.},
	number = {1},
	urldate = {2021-03-12},
	journal = {Methodist DeBakey Cardiovascular Journal},
	author = {Tester, David J. and Ackerman, Michael J.},
	year = {2014},
	pmid = {24932360},
	pmcid = {PMC4051331},
	pages = {29--33},
}

@article{ntalla_multi-ancestry_2020-1,
	title = {Multi-ancestry {GWAS} of the electrocardiographic {PR} interval identifies 202 loci underlying cardiac conduction},
	volume = {11},
	copyright = {2020 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-020-15706-x},
	doi = {10.1038/s41467-020-15706-x},
	abstract = {The electrocardiographic PR interval reflects atrioventricular conduction, and is associated with conduction abnormalities, pacemaker implantation, atrial fibrillation (AF), and cardiovascular mortality. Here we report a multi-ancestry (N = 293,051) genome-wide association meta-analysis for the PR interval, discovering 202 loci of which 141 have not previously been reported. Variants at identified loci increase the percentage of heritability explained, from 33.5\% to 62.6\%. We observe enrichment for cardiac muscle developmental/contractile and cytoskeletal genes, highlighting key regulation processes for atrioventricular conduction. Additionally, 8 loci not previously reported harbor genes underlying inherited arrhythmic syndromes and/or cardiomyopathies suggesting a role for these genes in cardiovascular pathology in the general population. We show that polygenic predisposition to PR interval duration is an endophenotype for cardiovascular disease, including distal conduction disease, AF, and atrioventricular pre-excitation. These findings advance our understanding of the polygenic basis of cardiac conduction, and the genetic relationship between PR interval duration and cardiovascular disease.},
	language = {en},
	number = {1},
	urldate = {2021-03-12},
	journal = {Nature Communications},
	author = {Ntalla, Ioanna and Weng, Lu-Chen and Cartwright, James H. and Hall, Amelia Weber and Sveinbjornsson, Gardar and Tucker, Nathan R. and Choi, Seung Hoan and Chaffin, Mark D. and Roselli, Carolina and Barnes, Michael R. and Mifsud, Borbala and Warren, Helen R. and Hayward, Caroline and Marten, Jonathan and Cranley, James J. and Concas, Maria Pina and Gasparini, Paolo and Boutin, Thibaud and Kolcic, Ivana and Polasek, Ozren and Rudan, Igor and Araujo, Nathalia M. and Lima-Costa, Maria Fernanda and Ribeiro, Antonio Luiz P. and Souza, Renan P. and Tarazona-Santos, Eduardo and Giedraitis, Vilmantas and Ingelsson, Erik and Mahajan, Anubha and Morris, Andrew P. and Del Greco M, Fabiola and Foco, Luisa and Gögele, Martin and Hicks, Andrew A. and Cook, James P. and Lind, Lars and Lindgren, Cecilia M. and Sundström, Johan and Nelson, Christopher P. and Riaz, Muhammad B. and Samani, Nilesh J. and Sinagra, Gianfranco and Ulivi, Sheila and Kähönen, Mika and Mishra, Pashupati P. and Mononen, Nina and Nikus, Kjell and Caulfield, Mark J. and Dominiczak, Anna and Padmanabhan, Sandosh and Montasser, May E. and O’Connell, Jeff R. and Ryan, Kathleen and Shuldiner, Alan R. and Aeschbacher, Stefanie and Conen, David and Risch, Lorenz and Thériault, Sébastien and Hutri-Kähönen, Nina and Lehtimäki, Terho and Lyytikäinen, Leo-Pekka and Raitakari, Olli T. and Barnes, Catriona L. K. and Campbell, Harry and Joshi, Peter K. and Wilson, James F. and Isaacs, Aaron and Kors, Jan A. and van Duijn, Cornelia M. and Huang, Paul L. and Gudnason, Vilmundur and Harris, Tamara B. and Launer, Lenore J. and Smith, Albert V. and Bottinger, Erwin P. and Loos, Ruth J. F. and Nadkarni, Girish N. and Preuss, Michael H. and Correa, Adolfo and Mei, Hao and Wilson, James and Meitinger, Thomas and Müller-Nurasyid, Martina and Peters, Annette and Waldenberger, Melanie and Mangino, Massimo and Spector, Timothy D. and Rienstra, Michiel and van de Vegte, Yordi J. and van der Harst, Pim and Verweij, Niek and Kääb, Stefan and Schramm, Katharina and Sinner, Moritz F. and Strauch, Konstantin and Cutler, Michael J. and Fatkin, Diane and London, Barry and Olesen, Morten and Roden, Dan M. and Benjamin Shoemaker, M. and Gustav Smith, J. and Biggs, Mary L. and Bis, Joshua C. and Brody, Jennifer A. and Psaty, Bruce M. and Rice, Kenneth and Sotoodehnia, Nona and De Grandi, Alessandro and Fuchsberger, Christian and Pattaro, Cristian and Pramstaller, Peter P. and Ford, Ian and Wouter Jukema, J. and Macfarlane, Peter W. and Trompet, Stella and Dörr, Marcus and Felix, Stephan B. and Völker, Uwe and Weiss, Stefan and Havulinna, Aki S. and Jula, Antti and Sääksjärvi, Katri and Salomaa, Veikko and Guo, Xiuqing and Heckbert, Susan R. and Lin, Henry J. and Rotter, Jerome I. and Taylor, Kent D. and Yao, Jie and de Mutsert, Renée and Maan, Arie C. and Mook-Kanamori, Dennis O. and Noordam, Raymond and Cucca, Francesco and Ding, Jun and Lakatta, Edward G. and Qian, Yong and Tarasov, Kirill V. and Levy, Daniel and Lin, Honghuang and Newton-Cheh, Christopher H. and Lunetta, Kathryn L. and Murray, Alison D. and Porteous, David J. and Smith, Blair H. and Stricker, Bruno H. and Uitterlinden, André and van den Berg, Marten E. and Haessler, Jeffrey and Jackson, Rebecca D. and Kooperberg, Charles and Peters, Ulrike and Reiner, Alexander P. and Whitsel, Eric A. and Alonso, Alvaro and Arking, Dan E. and Boerwinkle, Eric and Ehret, Georg B. and Soliman, Elsayed Z. and Avery, Christy L. and Gogarten, Stephanie M. and Kerr, Kathleen F. and Laurie, Cathy C. and Seyerle, Amanda A. and Stilp, Adrienne and Assa, Solmaz and Abdullah Said, M. and Yldau van der Ende, M. and Lambiase, Pier D. and Orini, Michele and Ramirez, Julia and Van Duijvenboden, Stefan and Arnar, David O. and Gudbjartsson, Daniel F. and Holm, Hilma and Sulem, Patrick and Thorleifsson, Gudmar and Thorolfsdottir, Rosa B. and Thorsteinsdottir, Unnur and Benjamin, Emelia J. and Tinker, Andrew and Stefansson, Kari and Ellinor, Patrick T. and Jamshidi, Yalda and Lubitz, Steven A. and Munroe, Patricia B.},
	month = may,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {2542},
}

@article{hidalgo_dynamic_2009,
	title = {A {Dynamic} {Network} {Approach} for the {Study} of {Human} {Phenotypes}},
	volume = {5},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000353},
	doi = {10.1371/journal.pcbi.1000353},
	abstract = {The use of networks to integrate different genetic, proteomic, and metabolic datasets has been proposed as a viable path toward elucidating the origins of specific diseases. Here we introduce a new phenotypic database summarizing correlations obtained from the disease history of more than 30 million patients in a Phenotypic Disease Network (PDN). We present evidence that the structure of the PDN is relevant to the understanding of illness progression by showing that (1) patients develop diseases close in the network to those they already have; (2) the progression of disease along the links of the network is different for patients of different genders and ethnicities; (3) patients diagnosed with diseases which are more highly connected in the PDN tend to die sooner than those affected by less connected diseases; and (4) diseases that tend to be preceded by others in the PDN tend to be more connected than diseases that precede other illnesses, and are associated with higher degrees of mortality. Our findings show that disease progression can be represented and studied using network methods, offering the potential to enhance our understanding of the origin and evolution of human diseases. The dataset introduced here, released concurrently with this publication, represents the largest relational phenotypic resource publicly available to the research community.},
	language = {en},
	number = {4},
	urldate = {2021-03-11},
	journal = {PLOS Computational Biology},
	author = {Hidalgo, César A. and Blumm, Nicholas and Barabási, Albert-László and Christakis, Nicholas A.},
	month = apr,
	year = {2009},
	note = {Publisher: Public Library of Science},
	keywords = {Epidemiology, Genetic networks, Genetics of disease, Human genetics, Phenotypes, Protein interaction networks, Proteomic databases, Type 2 diabetes risk},
	pages = {e1000353},
}

@article{mohan_graphical_2021,
	title = {Graphical {Models} for {Processing} {Missing} {Data}},
	volume = {0},
	issn = {0162-1459},
	url = {https://doi.org/10.1080/01621459.2021.1874961},
	doi = {10.1080/01621459.2021.1874961},
	abstract = {This paper reviews recent advances in missing data research using graphical models to represent multivariate dependencies. We first examine the limitations of traditional frameworks from three different perspectives: transparency, estimability and testability. We then show how procedures based on graphical models can overcome these limitations and provide meaningful performance guarantees even when data are Missing Not At Random (MNAR). In particular, we identify conditions that guarantee consistent estimation in broad categories of missing data problems, and derive procedures for implementing this estimation. Finally we derive testable implications for missing data models in both MAR (Missing At Random) and MNAR categories.},
	number = {ja},
	urldate = {2021-03-08},
	journal = {Journal of the American Statistical Association},
	author = {Mohan, Karthika and Pearl, Judea},
	month = jan,
	year = {2021},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/01621459.2021.1874961},
	keywords = {Graphical Models, Missing Not At Random (MNAR), Missing data, Non-Ignorable, Recoverability, Testability},
	pages = {1--42},
}

@article{scholkopf_towards_2021,
	title = {Towards {Causal} {Representation} {Learning}},
	url = {http://arxiv.org/abs/2102.11107},
	abstract = {The two fields of machine learning and graphical causality arose and developed separately. However, there is now cross-pollination and increasing interest in both fields to benefit from the advances of the other. In the present paper, we review fundamental concepts of causal inference and relate them to crucial open problems of machine learning, including transfer and generalization, thereby assaying how causality can contribute to modern machine learning research. This also applies in the opposite direction: we note that most work in causality starts from the premise that the causal variables are given. A central problem for AI and causality is, thus, causal representation learning, the discovery of high-level causal variables from low-level observations. Finally, we delineate some implications of causality for machine learning and propose key research areas at the intersection of both communities.},
	urldate = {2021-03-02},
	journal = {arXiv:2102.11107 [cs]},
	author = {Schölkopf, Bernhard and Locatello, Francesco and Bauer, Stefan and Ke, Nan Rosemary and Kalchbrenner, Nal and Goyal, Anirudh and Bengio, Yoshua},
	month = feb,
	year = {2021},
	note = {arXiv: 2102.11107},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@article{houseman_dna_2012,
	title = {{DNA} methylation arrays as surrogate measures of cell mixture distribution},
	volume = {13},
	issn = {1471-2105},
	url = {https://doi.org/10.1186/1471-2105-13-86},
	doi = {10.1186/1471-2105-13-86},
	abstract = {There has been a long-standing need in biomedical research for a method that quantifies the normally mixed composition of leukocytes beyond what is possible by simple histological or flow cytometric assessments. The latter is restricted by the labile nature of protein epitopes, requirements for cell processing, and timely cell analysis. In a diverse array of diseases and following numerous immune-toxic exposures, leukocyte composition will critically inform the underlying immuno-biology to most chronic medical conditions. Emerging research demonstrates that DNA methylation is responsible for cellular differentiation, and when measured in whole peripheral blood, serves to distinguish cancer cases from controls.},
	language = {en},
	number = {1},
	urldate = {2021-03-02},
	journal = {BMC Bioinformatics},
	author = {Houseman, Eugene Andres and Accomando, William P. and Koestler, Devin C. and Christensen, Brock C. and Marsit, Carmen J. and Nelson, Heather H. and Wiencke, John K. and Kelsey, Karl T.},
	month = may,
	year = {2012},
	pages = {86},
}

@article{ribeiro_automatic_2020,
	title = {Automatic diagnosis of the 12-lead {ECG} using a deep neural network},
	volume = {11},
	copyright = {2020 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-020-15432-4},
	doi = {10.1038/s41467-020-15432-4},
	abstract = {The role of automatic electrocardiogram (ECG) analysis in clinical practice is limited by the accuracy of existing models. Deep Neural Networks (DNNs) are models composed of stacked transformations that learn tasks by examples. This technology has recently achieved striking success in a variety of task and there are great expectations on how it might improve clinical practice. Here we present a DNN model trained in a dataset with more than 2 million labeled exams analyzed by the Telehealth Network of Minas Gerais and collected under the scope of the CODE (Clinical Outcomes in Digital Electrocardiology) study. The DNN outperform cardiology resident medical doctors in recognizing 6 types of abnormalities in 12-lead ECG recordings, with F1 scores above 80\% and specificity over 99\%. These results indicate ECG analysis based on DNNs, previously studied in a single-lead setup, generalizes well to 12-lead exams, taking the technology closer to the standard clinical practice.},
	language = {en},
	number = {1},
	urldate = {2021-02-25},
	journal = {Nature Communications},
	author = {Ribeiro, Antônio H. and Ribeiro, Manoel Horta and Paixão, Gabriela M. M. and Oliveira, Derick M. and Gomes, Paulo R. and Canazart, Jéssica A. and Ferreira, Milton P. S. and Andersson, Carl R. and Macfarlane, Peter W. and Jr, Wagner Meira and Schön, Thomas B. and Ribeiro, Antonio Luiz P.},
	month = apr,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {1760},
}

@article{shao2014noncontact,
  title={Noncontact monitoring breathing pattern, exhalation flow rate and pulse transit time},
  author={Shao, Dangdang and Yang, Yuting and Liu, Chenbin and Tsow, Francis and Yu, Hui and Tao, Nongjian},
  journal={IEEE Transactions on Biomedical Engineering},
  volume={61},
  number={11},
  pages={2760--2767},
  year={2014},
  publisher={IEEE}
}

@article{10.1145/3517225,
author = {Liu, Xin and Wang, Yuntao and Xie, Sinan and Zhang, Xiaoyu and Ma, Zixian and McDuff, Daniel and Patel, Shwetak},
title = {MobilePhys: Personalized Mobile Camera-Based Contactless Physiological Sensing},
year = {2022},
issue_date = {March 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {1},
url = {https://doi.org/10.1145/3517225},
doi = {10.1145/3517225},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = {mar},
articleno = {24},
numpages = {23},
keywords = {remote PPG, rPPG, mobile health, computer vision, camera-based physiological sensing, ubiquitous computing}
}

@article{wells_strategies_2013,
	title = {Strategies for {Handling} {Missing} {Data} in {Electronic} {Health} {Record} {Derived} {Data}},
	volume = {1},
	copyright = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a  Creative Commons Attribution License  that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.  Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.  Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See  The Effect of Open Access ).  All third-party images reproduced on this journal are shared under Educational Fair Use. For more information on  Educational Fair Use , please see  this useful checklist prepared by Columbia University Libraries .   All copyright  of third-party content posted here for research purposes belongs to its original owners.  Unless otherwise stated all references to characters and comic art presented on this journal are ©, ® or ™ of their respective owners. No challenge to any owner’s rights is intended or should be inferred.},
	issn = {2327-9214},
	url = {http://egems.academyhealth.org/articles/abstract/10.13063/2327-9214.1035/},
	doi = {10.13063/2327-9214.1035},
	abstract = {This title is no longer publishing and submissions have been closed. eGEMs has transitioned from a free-standing journal to a special section within the journal Healthcare: The Journal of Delivery Science and Innovation. All published papers are currently still freely available on this website, but any new submissions should be sent to Healthcare.eGEMs (Generating Evidence \&amp; Methods to improve patient outcomes) was AcademyHealth’s open access, peer-reviewed online journal dedicated to accelerating research and quality improvement using electronic health data. Read more.},
	language = {en},
	number = {3},
	urldate = {2021-02-10},
	journal = {eGEMs (Generating Evidence \& Methods to improve patient outcomes)},
	author = {Wells, Brian J. and Nowacki, Amy S. and Chagin, Kevin and Kattan, Michael W.},
	month = dec,
	year = {2013},
	note = {Number: 3
Publisher: Ubiquity Press},
	pages = {7},
}

@article{beaulieu-jones_characterizing_2018,
	title = {Characterizing and {Managing} {Missing} {Structured} {Data} in {Electronic} {Health} {Records}: {Data} {Analysis}},
	volume = {6},
	copyright = {Unless stated otherwise, all articles are open-access distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/2.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work ("first published in the Journal of Medical Internet Research...") is properly cited with original URL and bibliographic citation information. The complete bibliographic information, a link to the original publication on http://www.jmir.org/, as well as this copyright and license information must be included.},
	shorttitle = {Characterizing and {Managing} {Missing} {Structured} {Data} in {Electronic} {Health} {Records}},
	url = {https://medinform.jmir.org/2018/1/e11},
	doi = {10.2196/medinform.8960},
	abstract = {Background: Missing data is a challenge for all studies; however, this is especially true for electronic health record (EHR)-based analyses. Failure to appropriately consider missing data can lead to biased results. While there has been extensive theoretical work on imputation, and many sophisticated methods are now available, it remains quite challenging for researchers to implement these methods appropriately. Here, we provide detailed procedures for when and how to conduct imputation of EHR laboratory results. Objective: The objective of this study was to demonstrate how the mechanism of missingness can be assessed, evaluate the performance of a variety of imputation methods, and describe some of the most frequent problems that can be encountered. Methods: We analyzed clinical laboratory measures from 602,366 patients in the EHR of Geisinger Health System in Pennsylvania, USA. Using these data, we constructed a representative set of complete cases and assessed the performance of 12 different imputation methods for missing data that was simulated based on 4 mechanisms of missingness (missing completely at random, missing not at random, missing at random, and real data modelling). Results: Our results showed that several methods, including variations of Multivariate Imputation by Chained Equations (MICE) and softImpute, consistently imputed missing values with low error; however, only a subset of the MICE methods was suitable for multiple imputation. Conclusions: The analyses we describe provide an outline of considerations for dealing with missing EHR data, steps that researchers can perform to characterize missingness within their own data, and an evaluation of methods that can be applied to impute clinical data. While the performance of methods may vary between datasets, the process we describe can be generalized to the majority of structured data types that exist in EHRs, and all of our methods and code are publicly available.},
	language = {EN},
	number = {1},
	urldate = {2021-02-10},
	journal = {JMIR Medical Informatics},
	author = {Beaulieu-Jones, Brett K. and Lavage, Daniel R. and Snyder, John W. and Moore, Jason H. and Pendergrass, Sarah A. and Bauer, Christopher R.},
	month = feb,
	year = {2018},
	note = {Company: JMIR Medical Informatics
Distributor: JMIR Medical Informatics
Institution: JMIR Medical Informatics
Label: JMIR Medical Informatics
Publisher: JMIR Publications Inc., Toronto, Canada},
	pages = {e8960},
}

@article{li_integration_2019,
	title = {Integration of genetic and clinical information to improve imputation of data missing from electronic health records},
	volume = {26},
	issn = {1527-974X},
	url = {https://doi.org/10.1093/jamia/ocz041},
	doi = {10.1093/jamia/ocz041},
	abstract = {Clinical data of patients’ measurements and treatment history stored in electronic health record (EHR) systems are starting to be mined for better treatment options and disease associations. A primary challenge associated with utilizing EHR data is the considerable amount of missing data. Failure to address this issue can introduce significant bias in EHR-based research. Currently, imputation methods rely on correlations among the structured phenotype variables in the EHR. However, genetic studies have shown that many EHR-based phenotypes have a heritable component, suggesting that measured genetic variants might be useful for imputing missing data. In this article, we developed a computational model that incorporates patients’ genetic information to perform EHR data imputation.We used the individual single nucleotide polymorphism’s association with phenotype variables in the EHR as input to construct a genetic risk score that quantifies the genetic contribution to the phenotype. Multiple approaches to constructing the genetic risk score were evaluated for optimal performance. The genetic score, along with phenotype correlation, is then used as a predictor to impute the missing values.To demonstrate the method performance, we applied our model to impute missing cardiovascular related measurements including low-density lipoprotein, heart failure, and aortic aneurysm disease in the electronic Medical Records and Genomics data. The integration method improved imputation's area-under-the-curve for binary phenotypes and decreased root-mean-square error for continuous phenotypes.Compared with standard imputation approaches, incorporating genetic information offers a novel approach that can utilize more of the EHR data for better performance in missing data imputation.},
	number = {10},
	urldate = {2021-02-10},
	journal = {Journal of the American Medical Informatics Association},
	author = {Li, Ruowang and Chen, Yong and Moore, Jason H},
	month = oct,
	year = {2019},
	pages = {1056--1063},
}

@misc{noauthor_percent_nodate,
	title = {Percent of {Hospitals}, {By} {Type}, that {Possess} {Certified} {Health} {IT}},
	url = {/quickstats/pages/certified-electronic-health-record-technology-in-hospitals.php},
	abstract = {In 2017, 96 percent of all non-federal acute care hospitals possessed certified health IT. Small rural and critical access hospitals had the lowest rates at 93 percent. Ninety-nine percent of large hospitals (more than 300 beds) had certified health IT, while 97 percent of medium-sized hospitals (more than 100 beds) had certified health IT.},
	urldate = {2021-01-26},
}

@article{jensen_temporal_2014,
	title = {Temporal disease trajectories condensed from population-wide registry data covering 6.2 million patients},
	volume = {5},
	copyright = {2014 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/ncomms5022},
	doi = {10.1038/ncomms5022},
	abstract = {A key prerequisite for precision medicine is the estimation of disease progression from the current patient state. Disease correlations and temporal disease progression (trajectories) have mainly been analysed with focus on a small number of diseases or using large-scale approaches without time consideration, exceeding a few years. So far, no large-scale studies have focused on defining a comprehensive set of disease trajectories. Here we present a discovery-driven analysis of temporal disease progression patterns using data from an electronic health registry covering the whole population of Denmark. We use the entire spectrum of diseases and convert 14.9 years of registry data on 6.2 million patients into 1,171 significant trajectories. We group these into patterns centred on a small number of key diagnoses such as chronic obstructive pulmonary disease (COPD) and gout, which are central to disease progression and hence important to diagnose early to mitigate the risk of adverse outcomes. We suggest such trajectory analyses may be useful for predicting and preventing future diseases of individual patients.},
	language = {en},
	number = {1},
	urldate = {2021-01-15},
	journal = {Nature Communications},
	author = {Jensen, Anders Boeck and Moseley, Pope L. and Oprea, Tudor I. and Ellesøe, Sabrina Gade and Eriksson, Robert and Schmock, Henriette and Jensen, Peter Bjødstrup and Jensen, Lars Juhl and Brunak, Søren},
	month = jun,
	year = {2014},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {4022},
}

@article{paik_tracing_2019,
	title = {Tracing diagnosis trajectories over millions of patients reveal an unexpected risk in schizophrenia},
	volume = {6},
	copyright = {2019 The Author(s)},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/s41597-019-0220-5},
	doi = {10.1038/s41597-019-0220-5},
	abstract = {The identification of novel disease associations using big-data for patient care has had limited success. In this study, we created a longitudinal disease network of traced readmissions (disease trajectories), merging data from over 10.4 million inpatients through the Healthcare Cost and Utilization Project, which allowed the representation of disease progression mapping over 300 diseases. From these disease trajectories, we discovered an interesting association between schizophrenia and rhabdomyolysis, a rare muscle disease (incidence {\textless} 1E-04) (relative risk, 2.21 [1.80–2.71, confidence interval = 0.95], P-value 9.54E-15). We validated this association by using independent electronic medical records from over 830,000 patients at the University of California, San Francisco (UCSF) medical center. A case review of 29 rhabdomyolysis incidents in schizophrenia patients at UCSF demonstrated that 62\% are idiopathic, without the use of any drug known to lead to this adverse event, suggesting a warning to physicians to watch for this unexpected risk of schizophrenia. Large-scale analysis of disease trajectories can help physicians understand potential sequential events in their patients.},
	language = {en},
	number = {1},
	urldate = {2021-01-15},
	journal = {Scientific Data},
	author = {Paik, Hyojung and Kan, Matthew J. and Rappoport, Nadav and Hadley, Dexter and Sirota, Marina and Chen, Bin and Manber, Udi and Cho, Seong Beom and Butte, Atul J.},
	month = oct,
	year = {2019},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {201},
}

@article{sheller_federated_2020,
	title = {Federated learning in medicine: facilitating multi-institutional collaborations without sharing patient data},
	volume = {10},
	copyright = {2020 The Author(s)},
	issn = {2045-2322},
	shorttitle = {Federated learning in medicine},
	url = {https://www.nature.com/articles/s41598-020-69250-1},
	doi = {10.1038/s41598-020-69250-1},
	abstract = {Several studies underscore the potential of deep learning in identifying complex patterns, leading to diagnostic and prognostic biomarkers. Identifying sufficiently large and diverse datasets, required for training, is a significant challenge in medicine and can rarely be found in individual institutions. Multi-institutional collaborations based on centrally-shared patient data face privacy and ownership challenges. Federated learning is a novel paradigm for data-private multi-institutional collaborations, where model-learning leverages all available data without sharing data between institutions, by distributing the model-training to the data-owners and aggregating their results. We show that federated learning among 10 institutions results in models reaching 99\% of the model quality achieved with centralized data, and evaluate generalizability on data from institutions outside the federation. We further investigate the effects of data distribution across collaborating institutions on model quality and learning patterns, indicating that increased access to data through data private multi-institutional collaborations can benefit model quality more than the errors introduced by the collaborative method. Finally, we compare with other collaborative-learning approaches demonstrating the superiority of federated learning, and discuss practical implementation considerations. Clinical adoption of federated learning is expected to lead to models trained on datasets of unprecedented size, hence have a catalytic impact towards precision/personalized medicine.},
	language = {en},
	number = {1},
	urldate = {2021-01-14},
	journal = {Scientific Reports},
	author = {Sheller, Micah J. and Edwards, Brandon and Reina, G. Anthony and Martin, Jason and Pati, Sarthak and Kotrotsou, Aikaterini and Milchenko, Mikhail and Xu, Weilin and Marcus, Daniel and Colen, Rivka R. and Bakas, Spyridon},
	month = jul,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {12598},
}

@article{barfield_accounting_2014,
	title = {Accounting for {Population} {Stratification} in {DNA} {Methylation} {Studies}},
	volume = {38},
	copyright = {© 2014 WILEY PERIODICALS, INC.},
	issn = {1098-2272},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/gepi.21789},
	doi = {https://doi.org/10.1002/gepi.21789},
	abstract = {DNA methylation is an important epigenetic mechanism that has been linked to complex diseases and is of great interest to researchers as a potential link between genome, environment, and disease. As the scale of DNA methylation association studies approaches that of genome-wide association studies, issues such as population stratification will need to be addressed. It is well-documented that failure to adjust for population stratification can lead to false positives in genetic association studies, but population stratification is often unaccounted for in DNA methylation studies. Here, we propose several approaches to correct for population stratification using principal components (PCs) from different subsets of genome-wide methylation data. We first illustrate the potential for confounding due to population stratification by demonstrating widespread associations between DNA methylation and race in 388 individuals (365 African American and 23 Caucasian). We subsequently evaluate the performance of our PC-based approaches and other methods in adjusting for confounding due to population stratification. Our simulations show that (1) all of the methods considered are effective at removing inflation due to population stratification, and (2) maximum power can be obtained with single-nucleotide polymorphism (SNP)-based PCs, followed by methylation-based PCs, which outperform both surrogate variable analysis and genomic control. Among our different approaches to computing methylation-based PCs, we find that PCs based on CpG sites chosen for their potential to proxy nearby SNPs can provide a powerful and computationally efficient approach to adjust for population stratification in DNA methylation studies when genome-wide SNP data are unavailable.},
	language = {en},
	number = {3},
	urldate = {2020-12-16},
	journal = {Genetic Epidemiology},
	author = {Barfield, Richard T. and Almli, Lynn M. and Kilaru, Varun and Smith, Alicia K. and Mercer, Kristina B. and Duncan, Richard and Klengel, Torsten and Mehta, Divya and Binder, Elisabeth B. and Epstein, Michael P. and Ressler, Kerry J. and Conneely, Karen N.},
	year = {2014},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/gepi.21789},
	keywords = {DNA methylation, association studies, population stratification, principal components},
	pages = {231--241},
}

@article{moen_genome-wide_2013,
	title = {Genome-{Wide} {Variation} of {Cytosine} {Modifications} {Between} {European} and {African} {Populations} and the {Implications} for {Complex} {Traits}},
	volume = {194},
	copyright = {Copyright © 2013 by the Genetics Society of America},
	issn = {0016-6731, 1943-2631},
	url = {https://www.genetics.org/content/194/4/987},
	doi = {10.1534/genetics.113.151381},
	abstract = {Elucidating cytosine modification differences between human populations can enhance our understanding of ethnic specificity in complex traits. In this study, cytosine modification levels in 133 HapMap lymphoblastoid cell lines derived from individuals of European or African ancestry were profiled using the Illumina HumanMethylation450 BeadChip. Approximately 13\% of the analyzed CpG sites showed differential modification between the two populations at a false discovery rate of 1\%. The CpG sites with greater modification levels in European descent were enriched in the proximal regulatory regions, while those greater in African descent were biased toward gene bodies. More than half of the detected population-specific cytosine modifications could be explained primarily by local genetic variation. In addition, a substantial proportion of local modification quantitative trait loci exhibited population-specific effects, suggesting that genetic epistasis and/or genotype × environment interactions could be common. Distinct correlations were observed between gene expression levels and cytosine modifications in proximal regions and gene bodies, suggesting epigenetic regulation of interindividual expression variation. Furthermore, quantitative trait loci associated with population-specific modifications can be colocalized with expression quantitative trait loci and single nucleotide polymorphisms previously identified for complex traits with known racial disparities. Our findings revealed abundant population-specific cytosine modifications and the underlying genetic basis, as well as the relatively independent contribution of genetic and epigenetic variations to population differences in gene expression.},
	language = {en},
	number = {4},
	urldate = {2020-12-16},
	journal = {Genetics},
	author = {Moen, Erika L. and Zhang, Xu and Mu, Wenbo and Delaney, Shannon M. and Wing, Claudia and McQuade, Jennifer and Myers, Jamie and Godley, Lucy A. and Dolan, M. Eileen and Zhang, Wei},
	month = aug,
	year = {2013},
	pmid = {23792949},
	note = {Publisher: Genetics
Section: Investigations},
	keywords = {complex trait, cytosine modification, gene expression, genetic variation, lymphoblastoid cell line},
	pages = {987--996},
}

@article{runge_inferring_2019,
	title = {Inferring causation from time series in {Earth} system sciences},
	volume = {10},
	copyright = {2019 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-019-10105-3},
	doi = {10.1038/s41467-019-10105-3},
	abstract = {The heart of the scientific enterprise is a rational effort to understand the causes behind the phenomena we observe. In large-scale complex dynamical systems such as the Earth system, real experiments are rarely feasible. However, a rapidly increasing amount of observational and simulated data opens up the use of novel data-driven causal methods beyond the commonly adopted correlation techniques. Here, we give an overview of causal inference frameworks and identify promising generic application cases common in Earth system sciences and beyond. We discuss challenges and initiate the benchmark platform causeme.netto close the gap between method users and developers.},
	language = {en},
	number = {1},
	urldate = {2020-12-16},
	journal = {Nature Communications},
	author = {Runge, Jakob and Bathiany, Sebastian and Bollt, Erik and Camps-Valls, Gustau and Coumou, Dim and Deyle, Ethan and Glymour, Clark and Kretschmer, Marlene and Mahecha, Miguel D. and Muñoz-Marí, Jordi and van Nes, Egbert H. and Peters, Jonas and Quax, Rick and Reichstein, Markus and Scheffer, Marten and Schölkopf, Bernhard and Spirtes, Peter and Sugihara, George and Sun, Jie and Zhang, Kun and Zscheischler, Jakob},
	month = jun,
	year = {2019},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {2553},
}

@article{wu_genome-wide_2019,
	title = {Genome-wide association study of medication-use and associated disease in the {UK} {Biobank}},
	volume = {10},
	copyright = {2019 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-019-09572-5},
	doi = {10.1038/s41467-019-09572-5},
	abstract = {Genome-wide association studies (GWASs) of medication use may contribute to understanding of disease etiology, could generate new leads relevant for drug discovery and can be used to quantify future risk of medication taking. Here, we conduct GWASs of self-reported medication use from 23 medication categories in approximately 320,000 individuals from the UK Biobank. A total of 505 independent genetic loci that meet stringent criteria (P {\textless} 10−8/23) for statistical significance are identified. We investigate the implications of these GWAS findings in relation to biological mechanism, potential drug target identification and genetic risk stratification of disease. Amongst the medication-associated genes are 16 known therapeutic-effect target genes for medications from 9 categories. Two of the medication classes studied are for disorders that have not previously been subject to large GWAS (hypothyroidism and gastro-oesophageal reflux disease).},
	language = {en},
	number = {1},
	urldate = {2020-12-04},
	journal = {Nature Communications},
	author = {Wu, Yeda and Byrne, Enda M. and Zheng, Zhili and Kemper, Kathryn E. and Yengo, Loic and Mallett, Andrew J. and Yang, Jian and Visscher, Peter M. and Wray, Naomi R.},
	month = apr,
	year = {2019},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {1891},
}

@article{rahmani_genome-wide_2017,
	title = {Genome-wide methylation data mirror ancestry information},
	volume = {10},
	issn = {1756-8935},
	url = {https://doi.org/10.1186/s13072-016-0108-y},
	doi = {10.1186/s13072-016-0108-y},
	abstract = {Genetic data are known to harbor information about human demographics, and genotyping data are commonly used for capturing ancestry information by leveraging genome-wide differences between populations. In contrast, it is not clear to what extent population structure is captured by whole-genome DNA methylation data.},
	number = {1},
	urldate = {2020-12-04},
	journal = {Epigenetics \& Chromatin},
	author = {Rahmani, Elior and Shenhav, Liat and Schweiger, Regev and Yousefi, Paul and Huen, Karen and Eskenazi, Brenda and Eng, Celeste and Huntsman, Scott and Hu, Donglei and Galanter, Joshua and Oh, Sam S. and Waldenberger, Melanie and Strauch, Konstantin and Grallert, Harald and Meitinger, Thomas and Gieger, Christian and Holland, Nina and Burchard, Esteban G. and Zaitlen, Noah and Halperin, Eran},
	month = jan,
	year = {2017},
	pages = {1},
}

@article{levey_new_2009,
	title = {A {New} {Equation} to {Estimate} {Glomerular} {Filtration} {Rate}},
	volume = {150},
	issn = {0003-4819},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2763564/},
	abstract = {Background
Equations to estimate glomerular filtration rate (GFR) are routinely used to assess kidney function. Current equations have limited precision and systematically underestimate measured GFR at higher levels.

Objective
To develop a new estimating equation (CKD-EPI creatinine equation).

Design
Cross-sectional analysis. Separate pooled databases for equation development and validation. Representative U.S. population for prevalence estimates.

Setting
Research studies and clinical populations (“studies”) with measured GFR. National Health and Nutrition Examination Survey (NHANES) 1999-2006.

Patients
Equation development in 10 studies (8254 people) and validation in 16 studies (3896 people). Prevalence estimates based on 16,032 people.

Measurements
GFR measured as the clearance of exogenous filtration markers (iothalamate in the development dataset; iothalamate and other markers in the validation dataset). Linear regression to estimate the logarithm of measured GFR from standardized creatinine, sex, race and age.

Results
In the validation dataset, the CKD-EPI performed better than the MDRD Study equation (p{\textless}0.001 for all subsequent comparisons), especially at higher GFR: lesser bias (median difference between measured and estimated GFR of 2.5 vs. 5.5 mL/min/1.73 m2, respectively); improved precision (interquartile range of the differences of 16.6 vs. 18.3 mL/min/1.73 m2, respectively); and greater accuracy (percent of estimated GFR within 30\% of measured GFR of 84.1 vs. 80.6\%, respectively. In NHANES, median (interquartile range) estimated GFR was 94.5 (79.7 – 108.1) vs. 85.0 (72.9 – 98.5) mL/min/1.73 m2, and the prevalence (95\% confidence interval) of CKD was 11.5 (10.6, 12.4) \% vs. 13.1 (12.1, 14.0) \%, respectively.

Limitations
Limited number of elderly people and racial and ethnic minorities with measured GFR.

Conclusions
The CKD-EPI creatinine equation is more accurate than the MDRD Study equation and could replace it for routine clinical use.},
	number = {9},
	urldate = {2020-12-03},
	journal = {Annals of internal medicine},
	author = {Levey, Andrew S. and Stevens, Lesley A. and Schmid, Christopher H. and Zhang, Yaping (Lucy) and Castro, Alejandro F. and Feldman, Harold I. and Kusek, John W. and Eggers, Paul and Van Lente, Frederick and Greene, Tom and Coresh, Josef},
	month = may,
	year = {2009},
	pmid = {19414839},
	pmcid = {PMC2763564},
	pages = {604--612},
}

@article{levey_kidney_2020,
	title = {Kidney {Disease}, {Race}, and {GFR} {Estimation}},
	volume = {15},
	issn = {1555-9041, 1555-905X},
	url = {https://cjasn.asnjournals.org/lookup/doi/10.2215/CJN.12791019},
	doi = {10.2215/CJN.12791019},
	abstract = {Assessment of GFR is central to clinical practice, research, and public health. Current Kidney Disease Improving Global Outcomes guidelines recommend measurement of serum creatinine to estimate GFR as the initial step in GFR evaluation. Serum creatinine is influenced by creatinine metabolism as well as GFR; hence, all equations to estimate GFR from serum creatinine include surrogates for muscle mass, such as age, sex, race, height, or weight. The guideline-recommended equation in adults (the 2009 Chronic Kidney Disease Epidemiology Collaboration creatinine equation) includes a term for race (specified as black versus nonblack), which improves the accuracy of GFR estimation by accounting for differences in non-GFR determinants of serum creatinine by race in the study populations used to develop the equation. In that study, blacks had a 16\% higher average measured GFR compared with nonblacks with the same age, sex, and serum creatinine. The reasons for this difference are only partly understood, and the use of race in GFR estimation has limitations. Some have proposed eliminating the race coefficient, but this would induce a systematic underestimation of measured GFR in blacks, with potential unintended consequences at the individual and population levels. We propose a more cautious approach that maintains and improves accuracy of GFR estimates and avoids disadvantaging any racial group. We suggest full disclosure of use of race in GFR estimation, accommodation of those who decline to identify their race, and shared decision making between health care providers and patients. We also suggest mindful use of cystatin C as a confirmatory test as well as clearance measurements. It would be preferable to avoid specification of race in GFR estimation if there was a superior, evidence-based substitute. The goal of future research should be to develop more accurate methods for GFR estimation that do not require use of race or other demographic characteristics.},
	language = {en},
	number = {8},
	urldate = {2020-12-02},
	journal = {Clinical Journal of the American Society of Nephrology},
	author = {Levey, Andrew S. and Titan, Silvia M. and Powe, Neil R. and Coresh, Josef and Inker, Lesley A.},
	month = aug,
	year = {2020},
	pages = {1203--1212},
}

@article{diao_clinical_2020,
	title = {Clinical {Implications} of {Removing} {Race} {From} {Estimates} of {Kidney} {Function}},
	issn = {0098-7484},
	url = {https://jamanetwork.com/journals/jama/fullarticle/2773808},
	doi = {10.1001/jama.2020.22124},
	language = {en},
	urldate = {2020-12-02},
	journal = {JAMA},
	author = {Diao, James A. and Wu, Gloria J. and Taylor, Herman A. and Tucker, John K. and Powe, Neil R. and Kohane, Isaac S. and Manrai, Arjun K.},
	month = dec,
	year = {2020},
}

@article{eneanya_reconsidering_2019,
	title = {Reconsidering the {Consequences} of {Using} {Race} to {Estimate} {Kidney} {Function}},
	volume = {322},
	issn = {0098-7484},
	url = {http://jama.jamanetwork.com/article.aspx?doi=10.1001/jama.2019.5774},
	doi = {10.1001/jama.2019.5774},
	language = {en},
	number = {2},
	urldate = {2020-12-02},
	journal = {JAMA},
	author = {Eneanya, Nwamaka Denise and Yang, Wei and Reese, Peter Philip},
	month = jul,
	year = {2019},
	pages = {113},
}

@misc{s_examining_2020,
	title = {Examining the {Potential} {Impact} of {Race} {Multiplier} {Utilization} in {Estimated} {Glomerular} {Filtration} {Rate} {Calculation} on {African}-{American} {Care} {Outcomes}},
	url = {https://pubmed.ncbi.nlm.nih.gov/33063202/},
	abstract = {Our study reveals a meaningful impact of race-adjusted eGFR on the care provided to the African-American CKD patient population.},
	language = {en},
	urldate = {2020-12-02},
	journal = {Journal of general internal medicine},
	author = {S, Ahmed and Ct, Nutt and Nd, Eneanya and Pp, Reese and K, Sivashanker and M, Morse and T, Sequist and Ml, Mendu},
	month = oct,
	year = {2020},
	pmid = {33063202},
	doi = {10.1007/s11606-020-06280-5},
	note = {ISSN: 1525-1497
Publisher: J Gen Intern Med},
}

@article{denny_phewas_2010,
	title = {{PheWAS}: demonstrating the feasibility of a phenome-wide scan to discover gene–disease associations},
	volume = {26},
	issn = {1367-4803},
	shorttitle = {{PheWAS}},
	url = {https://academic.oup.com/bioinformatics/article/26/9/1205/201211},
	doi = {10.1093/bioinformatics/btq126},
	abstract = {Abstract. Motivation: Emergence of genetic data coupled to longitudinal electronic medical records (EMRs) offers the possibility of phenome-wide association sca},
	language = {en},
	number = {9},
	urldate = {2020-11-24},
	journal = {Bioinformatics},
	author = {Denny, Joshua C. and Ritchie, Marylyn D. and Basford, Melissa A. and Pulley, Jill M. and Bastarache, Lisa and Brown-Gentry, Kristin and Wang, Deede and Masys, Dan R. and Roden, Dan M. and Crawford, Dana C.},
	month = may,
	year = {2010},
	note = {Publisher: Oxford Academic},
	pages = {1205--1210},
}

@article{wei_evaluating_2017,
	title = {Evaluating phecodes, clinical classification software, and {ICD}-9-{CM} codes for phenome-wide association studies in the electronic health record},
	volume = {12},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0175508},
	doi = {10.1371/journal.pone.0175508},
	abstract = {Objective To compare three groupings of Electronic Health Record (EHR) billing codes for their ability to represent clinically meaningful phenotypes and to replicate known genetic associations. The three tested coding systems were the International Classification of Diseases, Ninth Revision, Clinical Modification (ICD-9-CM) codes, the Agency for Healthcare Research and Quality Clinical Classification Software for ICD-9-CM (CCS), and manually curated “phecodes” designed to facilitate phenome-wide association studies (PheWAS) in EHRs. Methods and materials We selected 100 disease phenotypes and compared the ability of each coding system to accurately represent them without performing additional groupings. The 100 phenotypes included 25 randomly-chosen clinical phenotypes pursued in prior genome-wide association studies (GWAS) and another 75 common disease phenotypes mentioned across free-text problem lists from 189,289 individuals. We then evaluated the performance of each coding system to replicate known associations for 440 SNP-phenotype pairs. Results Out of the 100 tested clinical phenotypes, phecodes exactly matched 83, compared to 53 for ICD-9-CM and 32 for CCS. ICD-9-CM codes were typically too detailed (requiring custom groupings) while CCS codes were often not granular enough. Among 440 tested known SNP-phenotype associations, use of phecodes replicated 153 SNP-phenotype pairs compared to 143 for ICD-9-CM and 139 for CCS. Phecodes also generally produced stronger odds ratios and lower p-values for known associations than ICD-9-CM and CCS. Finally, evaluation of several SNPs via PheWAS identified novel potential signals, some seen in only using the phecode approach. Among them, rs7318369 in PEPD was associated with gastrointestinal hemorrhage. Conclusion Our results suggest that the phecode groupings better align with clinical diseases mentioned in clinical practice or for genomic studies. ICD-9-CM, CCS, and phecode groupings all worked for PheWAS-type studies, though the phecode groupings produced superior results.},
	language = {en},
	number = {7},
	urldate = {2020-11-24},
	journal = {PLOS ONE},
	author = {Wei, Wei-Qi and Bastarache, Lisa A. and Carroll, Robert J. and Marlo, Joy E. and Osterman, Travis J. and Gamazon, Eric R. and Cox, Nancy J. and Roden, Dan M. and Denny, Joshua C.},
	month = jul,
	year = {2017},
	note = {Publisher: Public Library of Science},
	keywords = {Breast cancer, Diabetes mellitus, Electronic medical records, Genome-wide association studies, Phenotypes, Thyroid carcinoma, Type 2 diabetes, Ulcerative colitis},
	pages = {e0175508},
}

@article{cinelli_generalizing_2020,
	title = {Generalizing experimental results by leveraging knowledge of mechanisms},
	issn = {1573-7284},
	url = {https://doi.org/10.1007/s10654-020-00687-4},
	doi = {10.1007/s10654-020-00687-4},
	abstract = {We show how experimental results can be generalized across diverse populations by leveraging knowledge of local mechanisms that produce the outcome of interest, only some of which may differ in the target domain. We use structural causal models and a refined version of selection diagrams to represent such knowledge, and to decide whether it entails the invariance of probabilities of causation across populations, which then enables generalization. We further provide: (i) bounds for the target effect when some of these conditions are violated; (ii) new identification results for probabilities of causation and the transported causal effect when trials from multiple source domains are available; as well as (iii) a Bayesian approach for estimating the transported causal effect from finite samples. We illustrate these methods both with simulated data and with a real example that transports the effects of Vitamin A supplementation on childhood mortality across different regions.},
	language = {en},
	urldate = {2020-11-19},
	journal = {European Journal of Epidemiology},
	author = {Cinelli, Carlos and Pearl, Judea},
	month = oct,
	year = {2020},
}

@article{futier_effect_2017,
	title = {Effect of {Individualized} vs {Standard} {Blood} {Pressure} {Management} {Strategies} on {Postoperative} {Organ} {Dysfunction} {Among} {High}-{Risk} {Patients} {Undergoing} {Major} {Surgery}: {A} {Randomized} {Clinical} {Trial}},
	volume = {318},
	issn = {1538-3598},
	shorttitle = {Effect of {Individualized} vs {Standard} {Blood} {Pressure} {Management} {Strategies} on {Postoperative} {Organ} {Dysfunction} {Among} {High}-{Risk} {Patients} {Undergoing} {Major} {Surgery}},
	doi = {10.1001/jama.2017.14172},
	abstract = {Importance: Perioperative hypotension is associated with an increase in postoperative morbidity and mortality, but the appropriate management strategy remains uncertain.
Objective: To evaluate whether an individualized blood pressure management strategy tailored to individual patient physiology could reduce postoperative organ dysfunction.
Design, Setting, and Participants: The Intraoperative Norepinephrine to Control Arterial Pressure (INPRESS) study was a multicenter, randomized, parallel-group clinical trial conducted in 9 French university and nonuniversity hospitals. Adult patients (n = 298) at increased risk of postoperative complications with a preoperative acute kidney injury risk index of class III or higher (indicating moderate to high risk of postoperative kidney injury) undergoing major surgery lasting 2 hours or longer under general anesthesia were enrolled from December 4, 2012, through August 28, 2016 (last follow-up, September 28, 2016).
Interventions: Individualized management strategy aimed at achieving a systolic blood pressure (SBP) within 10\% of the reference value (ie, patient's resting SBP) or standard management strategy of treating SBP less than 80 mm Hg or lower than 40\% from the reference value during and for 4 hours following surgery.
Main Outcomes and Measures: The primary outcome was a composite of systemic inflammatory response syndrome and dysfunction of at least 1 organ system of the renal, respiratory, cardiovascular, coagulation, and neurologic systems by day 7 after surgery. Secondary outcomes included the individual components of the primary outcome, durations of ICU and hospital stay, adverse events, and all-cause mortality at 30 days after surgery.
Results: Among 298 patients who were randomized, 292 patients completed the trial (mean [SD] age, 70 [7] years; 44 [15.1\%] women) and were included in the modified intention-to-treat analysis. The primary outcome event occurred in 56 of 147 patients (38.1\%) assigned to the individualized treatment strategy vs 75 of 145 patients (51.7\%) assigned to the standard treatment strategy (relative risk, 0.73; 95\% CI, 0.56 to 0.94; P = .02; absolute risk difference, -14\%, 95\% CI, -25\% to -2\%). Sixty-eight patients (46.3\%) in the individualized treatment group and 92 (63.4\%) in the standard treatment group had postoperative organ dysfunction by day 30 (adjusted hazard ratio, 0.66; 95\% CI, 0.52 to 0.84; P = .001). There were no significant between-group differences in severe adverse events or 30-day mortality.
Conclusions and Relevance: Among patients predominantly undergoing abdominal surgery who were at increased postoperative risk, management targeting an individualized systolic blood pressure, compared with standard management, reduced the risk of postoperative organ dysfunction.
Trial Registration: clinicaltrials.gov Identifier: NCT01536470.},
	language = {eng},
	number = {14},
	journal = {JAMA},
	author = {Futier, Emmanuel and Lefrant, Jean-Yves and Guinot, Pierre-Gregoire and Godet, Thomas and Lorne, Emmanuel and Cuvillon, Philippe and Bertran, Sebastien and Leone, Marc and Pastene, Bruno and Piriou, Vincent and Molliex, Serge and Albanese, Jacques and Julia, Jean-Michel and Tavernier, Benoit and Imhoff, Etienne and Bazin, Jean-Etienne and Constantin, Jean-Michel and Pereira, Bruno and Jaber, Samir and {INPRESS Study Group}},
	year = {2017},
	pmid = {28973220},
	pmcid = {PMC5710560},
	keywords = {Abdomen, Aged, Blood Pressure Determination, Cardiovascular Diseases, Epinephrine, Female, Humans, Hypotension, Intention to Treat Analysis, Kidney Diseases, Length of Stay, Male, Middle Aged, Norepinephrine, Postoperative Care, Postoperative Complications, Precision Medicine, Respiratory Tract Diseases, Surgical Procedures, Operative, Systemic Inflammatory Response Syndrome, Vasoconstrictor Agents},
	pages = {1346--1357},
}

@article{maheshwari_hypotension_2020,
	title = {Hypotension {Prediction} {Index} for {Prevention} of {Hypotension} during {Moderate}- to {High}-risk {Noncardiac} {SurgeryA} {Pilot} {Randomized} {Trial}},
	volume = {133},
	issn = {0003-3022},
	url = {https://pubs.asahq.org/anesthesiology/article/133/6/1214/110700/Hypotension-Prediction-Index-for-Prevention-of},
	doi = {10.1097/ALN.0000000000003557},
	language = {en},
	number = {6},
	urldate = {2020-11-19},
	journal = {Anesthesiology},
	author = {Maheshwari, Kamal and Shimada, Tetsuya and Yang, Dongsheng and Khanna, Sandeep and Cywinski, Jacek B. and Irefin, Samuel A. and Ayad, Sabry and Turan, Alparslan and Ruetzler, Kurt and Qiu, Yuwei and Saha, Partha and Mascha, Edward J. and Sessler, Daniel I.},
	month = dec,
	year = {2020},
	note = {Publisher: American Society of Anesthesiologists},
	pages = {1214--1222},
}

@article{monk_association_2015,
	title = {Association between {Intraoperative} {Hypotension} and {Hypertension} and 30-day {Postoperative} {Mortality} in {Noncardiac} {Surgery}},
	volume = {123},
	issn = {0003-3022},
	url = {https://pubs.asahq.org/anesthesiology/article/123/2/307/13989/Association-between-Intraoperative-Hypotension-and},
	doi = {10.1097/ALN.0000000000000756},
	language = {en},
	number = {2},
	urldate = {2020-11-19},
	journal = {Anesthesiology},
	author = {Monk, Terri G. and Bronsert, Michael R. and Henderson, William G. and Mangione, Michael P. and Sum-Ping, S. T. John and Bentt, Deyne R. and Nguyen, Jennifer D. and Richman, Joshua S. and Meguid, Robert A. and Hammermeister, Karl E.},
	month = aug,
	year = {2015},
	note = {Publisher: American Society of Anesthesiologists},
	pages = {307--319},
}

@article{mascha_intraoperative_2015,
	title = {Intraoperative {Mean} {Arterial} {Pressure} {Variability} and 30-day {Mortality} in {Patients} {Having} {Noncardiac} {Surgery}},
	volume = {123},
	issn = {0003-3022},
	url = {https://pubs.asahq.org/anesthesiology/article/123/1/79/12511/Intraoperative-Mean-Arterial-Pressure-Variability},
	doi = {10.1097/ALN.0000000000000686},
	language = {en},
	number = {1},
	urldate = {2020-11-19},
	journal = {Anesthesiology},
	author = {Mascha, Edward J. and Yang, Dongsheng and Weiss, Stephanie and Sessler, Daniel I.},
	month = jul,
	year = {2015},
	note = {Publisher: American Society of Anesthesiologists},
	pages = {79--91},
}

@article{walsh_relationship_2013,
	title = {Relationship between {Intraoperative} {Mean} {Arterial} {Pressure} and {Clinical} {Outcomes} after {Noncardiac} {SurgeryToward} an {Empirical} {Definition} of {Hypotension}},
	volume = {119},
	issn = {0003-3022},
	url = {https://pubs.asahq.org/anesthesiology/article/119/3/507/11632/Relationship-between-Intraoperative-Mean-Arterial},
	doi = {10.1097/ALN.0b013e3182a10e26},
	language = {en},
	number = {3},
	urldate = {2020-11-19},
	journal = {Anesthesiology},
	author = {Walsh, Michael and Devereaux, Philip J. and Garg, Amit X. and Kurz, Andrea and Turan, Alparslan and Rodseth, Reitze N. and Cywinski, Jacek and Thabane, Lehana and Sessler, Daniel I.},
	month = sep,
	year = {2013},
	note = {Publisher: American Society of Anesthesiologists},
	pages = {507--515},
}

@article{sun_association_2015,
	title = {Association of {Intraoperative} {Hypotension} with {Acute} {Kidney} {Injury} after {Elective} {Noncardiac} {Surgery}},
	volume = {123},
	issn = {0003-3022},
	url = {https://pubs.asahq.org/anesthesiology/article/123/3/515/14071/Association-of-Intraoperative-Hypotension-with},
	doi = {10.1097/ALN.0000000000000765},
	language = {en},
	number = {3},
	urldate = {2020-11-19},
	journal = {Anesthesiology},
	author = {Sun, Louise Y. and Wijeysundera, Duminda N. and Tait, Gordon A. and Beattie, W. Scott},
	month = sep,
	year = {2015},
	note = {Publisher: American Society of Anesthesiologists},
	pages = {515--523},
}

@article{salmasi_relationship_2017,
	title = {Relationship between {Intraoperative} {Hypotension}, {Defined} by {Either} {Reduction} from {Baseline} or {Absolute} {Thresholds}, and {Acute} {Kidney} and {Myocardial} {Injury} after {Noncardiac} {SurgeryA} {Retrospective} {Cohort} {Analysis}},
	volume = {126},
	issn = {0003-3022},
	url = {https://pubs.asahq.org/anesthesiology/article/126/1/47/652/Relationship-between-Intraoperative-Hypotension},
	doi = {10.1097/ALN.0000000000001432},
	language = {en},
	number = {1},
	urldate = {2020-11-18},
	journal = {Anesthesiology},
	author = {Salmasi, Vafi and Maheshwari, Kamal and Yang, Dongsheng and Mascha, Edward J. and Singh, Asha and Sessler, Daniel I. and Kurz, Andrea},
	month = jan,
	year = {2017},
	note = {Publisher: American Society of Anesthesiologists},
	pages = {47--65},
}

@article{maheshwari_randomized_2018,
	title = {A {Randomized} {Trial} of {Continuous} {Noninvasive} {Blood} {Pressure} {Monitoring} {During} {Noncardiac} {Surgery}},
	volume = {127},
	issn = {1526-7598},
	doi = {10.1213/ANE.0000000000003482},
	abstract = {BACKGROUND: Intraoperative hypotension is associated with postoperative mortality. Early detection of hypotension by continuous hemodynamic monitoring might prompt timely therapy, thereby reducing intraoperative hypotension. We tested the hypothesis that continuous noninvasive blood pressure monitoring reduces intraoperative hypotension.
METHODS: Patients ≥45 years old with American Society of Anesthesiologists physical status III or IV having moderate-to-high-risk noncardiac surgery with general anesthesia were included. All participating patients had continuous noninvasive hemodynamic monitoring using a finger cuff (ClearSight, Edwards Lifesciences, Irvine, CA) and a standard oscillometric cuff. In half the patients, randomly assigned, clinicians were blinded to the continuous values, whereas the others (unblinded) had access to continuous blood pressure readings. Continuous pressures in both groups were used for analysis. Time-weighted average for mean arterial pressure {\textless}65 mm Hg was compared using 2-sample Wilcoxon rank-sum tests and Hodges Lehmann estimation of location shift with corresponding asymptotic 95\% CI.
RESULTS: Among 320 randomized patients, 316 were included in the intention-to-treat analysis. With 158 patients in each group, those assigned to continuous blood pressure monitoring had significantly lower time-weighted average mean arterial pressure {\textless}65 mm Hg, 0.05 [0.00, 0.22] mm Hg, versus intermittent blood pressure monitoring, 0.11 [0.00, 0.54] mm Hg (P = .039, significance criteria P {\textless} .048).
CONCLUSIONS: Continuous noninvasive hemodynamic monitoring nearly halved the amount of intraoperative hypotension. Hypotension reduction with continuous monitoring, while statistically significant, is currently of uncertain clinical importance.},
	language = {eng},
	number = {2},
	journal = {Anesthesia and Analgesia},
	author = {Maheshwari, Kamal and Khanna, Sandeep and Bajracharya, Gausan Ratna and Makarova, Natalya and Riter, Quinton and Raza, Syed and Cywinski, Jacek B. and Argalious, Maged and Kurz, Andrea and Sessler, Daniel I.},
	year = {2018},
	pmid = {29916861},
	pmcid = {PMC6072385},
	keywords = {Aged, Anesthesia, General, Anesthesiology, Arterial Pressure, Blood Pressure, Blood Pressure Determination, Female, Hemodynamics, Humans, Hypotension, Male, Middle Aged, Monitoring, Intraoperative, Monitoring, Physiologic, Oscillometry, Reproducibility of Results, Surgical Procedures, Operative, Treatment Outcome},
	pages = {424--431},
}

@article{krieger_tale_2016,
	title = {The tale wagged by the {DAG}: broadening the scope of causal inference and explanation for epidemiology},
	volume = {45},
	issn = {0300-5771},
	shorttitle = {The tale wagged by the {DAG}},
	url = {https://academic.oup.com/ije/article/45/6/1787/2617188},
	doi = {10.1093/ije/dyw114},
	abstract = {Abstract. ‘Causal inference’, in 21st century epidemiology, has notably come to stand for a specific approach, one focused primarily on counterfactual and poten},
	language = {en},
	number = {6},
	urldate = {2020-11-17},
	journal = {International Journal of Epidemiology},
	author = {Krieger, Nancy and Davey Smith, George},
	month = dec,
	year = {2016},
	note = {Publisher: Oxford Academic},
	pages = {1787--1808},
}

@article{gidwani_crashing_2017,
	title = {The crashing patient: hemodynamic collapse},
	volume = {23},
	issn = {1070-5295},
	shorttitle = {The crashing patient},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5668154/},
	doi = {10.1097/MCC.0000000000000451},
	abstract = {Purpose of review
Rapid restoration of tissue perfusion and oxygenation are the main goals in the resuscitation of a patient with circulatory collapse. This review will focus on providing an evidence based framework of the technological and conceptual advances in the evaluation and management of the patient with cardiovascular collapse.

Recent findings
The initial approach to the patient in cardiovascular collapse continues to be based on the Ventilate–Infuse–Pump rule. Point of care ultrasound is the preferred modality for the initial evaluation of undifferentiated shock, providing information to narrow the differential diagnosis, to assess fluid responsiveness and to evaluate the response to therapy. After the initial phase of resuscitative fluid administration, which focuses on re-establishing a mean arterial pressure to 65mmHg, the use of dynamic parameters to assess preload responsiveness such as the passive leg raise test, stroke volume variation, pulse pressure variation and collapsibility of the inferior vena cava in mechanically ventilated patients is recommended.

Summary
The crashing patient remains a clinical challenge. Using an integrated approach with bedside ultrasound, dynamic parameters for the evaluation of fluid responsiveness and surrogates of evaluation of tissue perfusion have made the assessment of the patient in shock faster, safer and more physiologic.},
	number = {6},
	urldate = {2020-11-12},
	journal = {Current opinion in critical care},
	author = {Gidwani, Hitesh and Gómez, Hernando},
	month = dec,
	year = {2017},
	pmid = {28984705},
	pmcid = {PMC5668154},
	pages = {533--540},
}

@article{denny_systematic_2013,
	title = {Systematic comparison of phenome-wide association study of electronic medical record data and genome-wide association study data},
	volume = {31},
	copyright = {2013 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1546-1696},
	url = {https://www.nature.com/articles/nbt.2749},
	doi = {10.1038/nbt.2749},
	abstract = {When applied in large scale to electronic medical record data, the PheWAS approach replicates GWAS associations and reveals potentially new pleiotropic associations.},
	language = {en},
	number = {12},
	urldate = {2020-11-10},
	journal = {Nature Biotechnology},
	author = {Denny, Joshua C. and Bastarache, Lisa and Ritchie, Marylyn D. and Carroll, Robert J. and Zink, Raquel and Mosley, Jonathan D. and Field, Julie R. and Pulley, Jill M. and Ramirez, Andrea H. and Bowton, Erica and Basford, Melissa A. and Carrell, David S. and Peissig, Peggy L. and Kho, Abel N. and Pacheco, Jennifer A. and Rasmussen, Luke V. and Crosslin, David R. and Crane, Paul K. and Pathak, Jyotishman and Bielinski, Suzette J. and Pendergrass, Sarah A. and Xu, Hua and Hindorff, Lucia A. and Li, Rongling and Manolio, Teri A. and Chute, Christopher G. and Chisholm, Rex L. and Larson, Eric B. and Jarvik, Gail P. and Brilliant, Murray H. and McCarty, Catherine A. and Kullo, Iftikhar J. and Haines, Jonathan L. and Crawford, Dana C. and Masys, Daniel R. and Roden, Dan M.},
	month = dec,
	year = {2013},
	note = {Number: 12
Publisher: Nature Publishing Group},
	pages = {1102--1111},
}

@article{meid_using_2020,
	title = {Using the {Causal} {Inference} {Framework} to {Support} {Individualized} {Drug} {Treatment} {Decisions} {Based} on {Observational} {Healthcare} {Data}},
	volume = {Volume 12},
	issn = {1179-1349},
	url = {https://www.dovepress.com/using-the-causal-inference-framework-to-support-individualized-drug-tr-peer-reviewed-article-CLEP},
	doi = {10.2147/CLEP.S274466},
	abstract = {When healthcare professionals have the choice between several drug treatments for their patients, they often experience considerable decision uncertainty because many decisions simply have no single “best” choice. The challenges are manifold and include that guideline recommendations focus on randomized controlled trials whose populations do not necessarily correspond to specific patients in everyday treatment. Further reasons may be insufficient evidence on outcomes, lack of direct comparison of distinct options, and the need to individually balance benefits and risks. All these situations will occur in routine care, its outcomes will be mirrored in routine data, and could thus be used to guide decisions. We propose a concept to facilitate decision-making by exploiting this wealth of information. Our working example for illustration assumes that the response to a particular (drug) treatment can substantially differ between individual patients depending on their characteristics (het­ erogeneous treatment effects, HTE), and that decisions will be more precise if they are based on real-world evidence of HTE considering this information. However, such methods must account for confounding by indication and effect measure modification, eg, by adequately using machine learning methods or parametric regressions to estimate individual responses to pharmacological treatments. The better a model assesses the underlying HTE, the more accurate are predicted probabilities of treatment response. After probabilities for treatmentrelated benefit and harm have been calculated, decision rules can be applied and patient preferences can be considered to provide individual recommendations. Emulated trials in observational data are a straightforward technique to predict the effects of such decision rules when applied in routine care. Prediction-based decision rules from routine data have the potential to efficiently supplement clinical guidelines and support healthcare professionals in creating personalized treatment plans using decision support tools.},
	language = {en},
	urldate = {2020-11-06},
	journal = {Clinical Epidemiology},
	author = {Meid, Andreas D and Ruff, Carmen and Wirbka, Lucas and Stoll, Felicitas and Seidling, Hanna M and Groll, Andreas and Haefeli, Walter E},
	month = nov,
	year = {2020},
	pages = {1223--1234},
}

@article{moon_validation_2020,
	title = {Validation of a wearable cuff-less wristwatch-type blood pressure monitoring device},
	volume = {10},
	copyright = {2020 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-020-75892-y},
	doi = {10.1038/s41598-020-75892-y},
	abstract = {Ambulatory blood pressure (BP) monitoring is recommended to improve the management of hypertension. Here, we investigated the accuracy of BP estimated using a wearable cuff-less device, InBodyWATCH, compared with BP measured using a manual sphygmomanometer. Thirty-five adults were enrolled (age 57.1 ± 17.9 years). The BP was estimated using InBodyWATCH with an individualized estimation based on a neural network model. Three paired sets of BPs from the two devices were compared using correlation analysis and Bland–Altman plots (n = 105 paired BP readings). The correlations for both systolic and diastolic BP (SBP and DBP) between the two devices were high (r = 0.964 and 0.939, both P {\textless} 0.001). The mean difference was 2.2 ± 6.1 mmHg for SBP and −0.2 ± 4.2 mmHg for DBP; these were not significant (P = 0.472 for SBP and P = 0.880 for DBP). The proportions of estimated SBP/DBP obtained from the InBodyWATCH within ± 5 mmHg of manual SBP/DBP were 71.4\%/83.8\%; within ± 10 mmHg they were 86.7\%/98.1\%; and within ± 15 mmHg they were 97.1\%/99.0\%. The estimated BP from this wearable cuff-less device correlated highly with the manual BP and showed good accuracy, suggesting its potential to be used in ambulatory BP monitoring.},
	language = {en},
	number = {1},
	urldate = {2020-11-06},
	journal = {Scientific Reports},
	author = {Moon, Joon Ho and Kang, Myung-Kyun and Choi, Chang-Eun and Min, Jeonghee and Lee, Hae-Young and Lim, Soo},
	month = nov,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {19015},
}

@article{saugel_technological_2020,
	title = {Technological {Assessment} and {Objective} {Evaluation} of {Minimally} {Invasive} and {Noninvasive} {Cardiac} {Output} {Monitoring} {Systems}},
	volume = {133},
	issn = {0003-3022},
	url = {https://pubs.asahq.org/anesthesiology/article/133/4/921/110322/Technological-Assessment-and-Objective-Evaluation},
	doi = {10.1097/ALN.0000000000003483},
	language = {en},
	number = {4},
	urldate = {2020-10-13},
	journal = {Anesthesiology},
	author = {Saugel, Bernd and Thiele, Robert H. and Hapfelmeier, Alexander and Cannesson, Maxime},
	month = oct,
	year = {2020},
	note = {Publisher: American Society of Anesthesiologists},
	pages = {921--928},
}

@article{rieke_future_2020,
	title = {The future of digital health with federated learning},
	volume = {3},
	copyright = {2020 The Author(s)},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-020-00323-1},
	doi = {10.1038/s41746-020-00323-1},
	abstract = {Data-driven machine learning (ML) has emerged as a promising approach for building accurate and robust statistical models from medical data, which is collected in huge volumes by modern healthcare systems. Existing medical data is not fully exploited by ML primarily because it sits in data silos and privacy concerns restrict access to this data. However, without access to sufficient data, ML will be prevented from reaching its full potential and, ultimately, from making the transition from research to clinical practice. This paper considers key factors contributing to this issue, explores how federated learning (FL) may provide a solution for the future of digital health and highlights the challenges and considerations that need to be addressed.},
	language = {en},
	number = {1},
	urldate = {2020-09-29},
	journal = {npj Digital Medicine},
	author = {Rieke, Nicola and Hancox, Jonny and Li, Wenqi and Milletarì, Fausto and Roth, Holger R. and Albarqouni, Shadi and Bakas, Spyridon and Galtier, Mathieu N. and Landman, Bennett A. and Maier-Hein, Klaus and Ourselin, Sébastien and Sheller, Micah and Summers, Ronald M. and Trask, Andrew and Xu, Daguang and Baust, Maximilian and Cardoso, M. Jorge},
	month = sep,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {1--7},
}

@article{benjamens_state_2020,
	title = {The state of artificial intelligence-based {FDA}-approved medical devices and algorithms: an online database},
	volume = {3},
	copyright = {2020 The Author(s)},
	issn = {2398-6352},
	shorttitle = {The state of artificial intelligence-based {FDA}-approved medical devices and algorithms},
	url = {https://www.nature.com/articles/s41746-020-00324-0},
	doi = {10.1038/s41746-020-00324-0},
	abstract = {At the beginning of the artificial intelligence (AI)/machine learning (ML) era, the expectations are high, and experts foresee that AI/ML shows potential for diagnosing, managing and treating a wide variety of medical conditions. However, the obstacles for implementation of AI/ML in daily clinical practice are numerous, especially regarding the regulation of these technologies. Therefore, we provide an insight into the currently available AI/ML-based medical devices and algorithms that have been approved by the US Food \& Drugs Administration (FDA). We aimed to raise awareness of the importance of regulatory bodies, clearly stating whether a medical device is AI/ML based or not. Cross-checking and validating all approvals, we identified 64 AI/ML based, FDA approved medical devices and algorithms. Out of those, only 29 (45\%) mentioned any AI/ML-related expressions in the official FDA announcement. The majority (85.9\%) was approved by the FDA with a 510(k) clearance, while 8 (12.5\%) received de novo pathway clearance and one (1.6\%) premarket approval (PMA) clearance. Most of these technologies, notably 30 (46.9\%), 16 (25.0\%), and 10 (15.6\%) were developed for the fields of Radiology, Cardiology and Internal Medicine/General Practice respectively. We have launched the first comprehensive and open access database of strictly AI/ML-based medical technologies that have been approved by the FDA. The database will be constantly updated.},
	language = {en},
	number = {1},
	urldate = {2020-09-29},
	journal = {npj Digital Medicine},
	author = {Benjamens, Stan and Dhunnoo, Pranavsingh and Meskó, Bertalan},
	month = sep,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {1--8},
}

@article{torres-soto_multi-task_2020,
	title = {Multi-task deep learning for cardiac rhythm detection in wearable devices},
	volume = {3},
	copyright = {2020 The Author(s)},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-020-00320-4},
	doi = {10.1038/s41746-020-00320-4},
	abstract = {Wearable devices enable theoretically continuous, longitudinal monitoring of physiological measurements such as step count, energy expenditure, and heart rate. Although the classification of abnormal cardiac rhythms such as atrial fibrillation from wearable devices has great potential, commercial algorithms remain proprietary and tend to focus on heart rate variability derived from green spectrum LED sensors placed on the wrist, where noise remains an unsolved problem. Here we develop DeepBeat, a multitask deep learning method to jointly assess signal quality and arrhythmia event detection in wearable photoplethysmography devices for real-time detection of atrial fibrillation. The model is trained on approximately one million simulated unlabeled physiological signals and fine-tuned on a curated dataset of over 500 K labeled signals from over 100 individuals from 3 different wearable devices. We demonstrate that, in comparison with a single-task model, our architecture using unsupervised transfer learning through convolutional denoising autoencoders dramatically improves the performance of atrial fibrillation detection from a F1 score of 0.54 to 0.96. We also include in our evaluation a prospectively derived replication cohort of ambulatory participants where the algorithm performed with high sensitivity (0.98), specificity (0.99), and F1 score (0.93). We show that two-stage training can help address the unbalanced data problem common to biomedical applications, where large-scale well-annotated datasets are hard to generate due to the expense of manual annotation, data acquisition, and participant privacy.},
	language = {en},
	number = {1},
	urldate = {2020-09-29},
	journal = {npj Digital Medicine},
	author = {Torres-Soto, Jessica and Ashley, Euan A.},
	month = sep,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {1--8},
}

@article{peng_predicting_2020,
	title = {Predicting risk of late age-related macular degeneration using deep learning},
	volume = {3},
	copyright = {2020 This is a U.S. government work and not under copyright protection in the U.S.; foreign copyright protection may apply},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-020-00317-z},
	doi = {10.1038/s41746-020-00317-z},
	abstract = {By 2040, age-related macular degeneration (AMD) will affect {\textasciitilde}288 million people worldwide. Identifying individuals at high risk of progression to late AMD, the sight-threatening stage, is critical for clinical actions, including medical interventions and timely monitoring. Although deep learning has shown promise in diagnosing/screening AMD using color fundus photographs, it remains difficult to predict individuals’ risks of late AMD accurately. For both tasks, these initial deep learning attempts have remained largely unvalidated in independent cohorts. Here, we demonstrate how deep learning and survival analysis can predict the probability of progression to late AMD using 3298 participants (over 80,000 images) from the Age-Related Eye Disease Studies AREDS and AREDS2, the largest longitudinal clinical trials in AMD. When validated against an independent test data set of 601 participants, our model achieved high prognostic accuracy (5-year C-statistic 86.4 (95\% confidence interval 86.2–86.6)) that substantially exceeded that of retinal specialists using two existing clinical standards (81.3 (81.1–81.5) and 82.0 (81.8–82.3), respectively). Interestingly, our approach offers additional strengths over the existing clinical standards in AMD prognosis (e.g., risk ascertainment above 50\%) and is likely to be highly generalizable, given the breadth of training data from 82 US retinal specialty clinics. Indeed, during external validation through training on AREDS and testing on AREDS2 as an independent cohort, our model retained substantially higher prognostic accuracy than existing clinical standards. These results highlight the potential of deep learning systems to enhance clinical decision-making in AMD patients.},
	language = {en},
	number = {1},
	urldate = {2020-09-29},
	journal = {npj Digital Medicine},
	author = {Peng, Yifan and Keenan, Tiarnan D. and Chen, Qingyu and Agrón, Elvira and Allot, Alexis and Wong, Wai T. and Chew, Emily Y. and Lu, Zhiyong},
	month = aug,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {1--10},
}

@article{proskovec_association_2020,
	title = {Association of {Epigenetic} {Metrics} of {Biological} {Age} {With} {Cortical} {Thickness}},
	volume = {3},
	url = {https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2770547},
	doi = {10.1001/jamanetworkopen.2020.15428},
	abstract = {{\textless}h3{\textgreater}Importance{\textless}/h3{\textgreater}{\textless}p{\textgreater}Magnetic resonance imaging (MRI) studies of aging adults have shown substantial intersubject variability across various brain metrics, and some of this variability is likely attributable to chronological age being an imprecise measure of age-related change. Accurately quantifying one’s biological age could allow better quantification of healthy and pathological changes in the aging brain.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Objective{\textless}/h3{\textgreater}{\textless}p{\textgreater}To investigate the association of DNA methylation (DNAm)–based biological age with cortical thickness and to assess whether biological age acceleration compared with chronological age captures unique variance in cortical thinning.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Design, Setting, and Participants{\textless}/h3{\textgreater}{\textless}p{\textgreater}This cross-sectional study used high-resolution structural brain MRI data collected from a sample of healthy aging adults who were participating in a larger ongoing neuroimaging study that began in May 2014. This population-based study accrued participants from the greater Omaha, Nebraska, metropolitan area. One hundred sixty healthy adults were contacted for the MRI component, 82 of whom participated in both DNAm and MRI study components. Data analysis was performed from March to June 2019.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Main Outcomes and Measures{\textless}/h3{\textgreater}{\textless}p{\textgreater}Vertexwise cortical thickness, DNAm-based biological age, and biological age acceleration compared with chronological age were measured. A pair of multivariable regression models were computed in which cortical thickness was regressed on DNAm-based biological age, controlling for sex in the first model and also controlling for chronological age in the second model.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Results{\textless}/h3{\textgreater}{\textless}p{\textgreater}Seventy-nine adult participants (38 women; mean [SD] age, 43.82 [14.50] years; age range, 22-72 years) were included in all final analyses. Advancing biological age was correlated with cortical thinning across frontal, superior temporal, inferior parietal, and medial occipital regions. In addition, biological age acceleration relative to chronological age was associated with cortical thinning in orbitofrontal, superior and inferior temporal, somatosensory, parahippocampal, and fusiform regions. Specifically, for every 1 year of biological age acceleration, cortical thickness would be expected to decrease by 0.024 mm (95\% CI, −0.04 to −0.01 mm) in the left orbitofrontal cortex (partial\textit{r}, −0.34;\textit{P} = .002), 0.014 mm (95\% CI, −0.02 to −0.01 mm) in the left superior temporal gyrus (partial\textit{r}, −0.36;\textit{P} = .001), 0.015 mm (95\% CI, −0.02 to −0.01 mm) in the left fusiform gyrus (partial\textit{r}, −0.38;\textit{P} = .001), 0.015 mm (95\% CI, −0.02 to −0.01 mm) in the right fusiform gyrus (partial\textit{r}, −0.43;\textit{P} \&lt; .001), 0.019 mm (95\% CI, −0.03 to −0.01 mm) in the right inferior temporal sulcus (partial\textit{r}, −0.34;\textit{P} = .002), and 0.011 mm (95\% CI, −0.02 to −0.01 mm) in the right primary somatosensory cortex (partial\textit{r}, −0.37;\textit{P} = .001).{\textless}/p{\textgreater}{\textless}h3{\textgreater}Conclusions and Relevance{\textless}/h3{\textgreater}{\textless}p{\textgreater}To our knowledge, this is the first study to investigate vertexwise cortical thickness in relation to DNAm-based biological age, and the findings suggest that this metric of biological age may yield additional insight on healthy and pathological cortical aging compared with standard measures of chronological age alone.{\textless}/p{\textgreater}},
	language = {en},
	number = {9},
	urldate = {2020-09-16},
	journal = {JAMA Network Open},
	author = {Proskovec, Amy L. and Rezich, Michael T. and O’Neill, Jennifer and Morsey, Brenda and Wang, Tina and Ideker, Trey and Swindells, Susan and Fox, Howard S. and Wilson, Tony W.},
	month = sep,
	year = {2020},
	note = {Publisher: American Medical Association},
	pages = {e2015428--e2015428},
}

@article{norgeot_minimum_2020,
	title = {Minimum information about clinical artificial intelligence modeling: the {MI}-{CLAIM} checklist},
	volume = {26},
	copyright = {2020 Springer Nature America, Inc.},
	issn = {1546-170X},
	shorttitle = {Minimum information about clinical artificial intelligence modeling},
	url = {https://www.nature.com/articles/s41591-020-1041-y},
	doi = {10.1038/s41591-020-1041-y},
	abstract = {Here we present the MI-CLAIM checklist, a tool intended to improve transparent reporting of AI algorithms in medicine.},
	language = {en},
	number = {9},
	urldate = {2020-09-10},
	journal = {Nature Medicine},
	author = {Norgeot, Beau and Quer, Giorgio and Beaulieu-Jones, Brett K. and Torkamani, Ali and Dias, Raquel and Gianfrancesco, Milena and Arnaout, Rima and Kohane, Isaac S. and Saria, Suchi and Topol, Eric and Obermeyer, Ziad and Yu, Bin and Butte, Atul J.},
	month = sep,
	year = {2020},
	note = {Number: 9
Publisher: Nature Publishing Group},
	pages = {1320--1324},
}

@article{cruz_rivera_guidelines_2020,
	title = {Guidelines for clinical trial protocols for interventions involving artificial intelligence: the {SPIRIT}-{AI} extension},
	volume = {26},
	copyright = {2020 The Author(s)},
	issn = {1546-170X},
	shorttitle = {Guidelines for clinical trial protocols for interventions involving artificial intelligence},
	url = {https://www.nature.com/articles/s41591-020-1037-7},
	doi = {10.1038/s41591-020-1037-7},
	abstract = {The SPIRIT 2013 statement aims to improve the completeness of clinical trial protocol reporting by providing evidence-based recommendations for the minimum set of items to be addressed. This guidance has been instrumental in promoting transparent evaluation of new interventions. More recently, there has been a growing recognition that interventions involving artificial intelligence (AI) need to undergo rigorous, prospective evaluation to demonstrate their impact on health outcomes. The SPIRIT-AI (Standard Protocol Items: Recommendations for Interventional Trials–Artificial Intelligence) extension is a new reporting guideline for clinical trial protocols evaluating interventions with an AI component. It was developed in parallel with its companion statement for trial reports: CONSORT-AI (Consolidated Standards of Reporting Trials–Artificial Intelligence). Both guidelines were developed through a staged consensus process involving literature review and expert consultation to generate 26 candidate items, which were consulted upon by an international multi-stakeholder group in a two-stage Delphi survey (103 stakeholders), agreed upon in a consensus meeting (31 stakeholders) and refined through a checklist pilot (34 participants). The SPIRIT-AI extension includes 15 new items that were considered sufficiently important for clinical trial protocols of AI interventions. These new items should be routinely reported in addition to the core SPIRIT 2013 items. SPIRIT-AI recommends that investigators provide clear descriptions of the AI intervention, including instructions and skills required for use, the setting in which the AI intervention will be integrated, considerations for the handling of input and output data, the human–AI interaction and analysis of error cases. SPIRIT-AI will help promote transparency and completeness for clinical trial protocols for AI interventions. Its use will assist editors and peer reviewers, as well as the general readership, to understand, interpret and critically appraise the design and risk of bias for a planned clinical trial.},
	language = {en},
	number = {9},
	urldate = {2020-09-10},
	journal = {Nature Medicine},
	author = {Cruz Rivera, Samantha and Liu, Xiaoxuan and Chan, An-Wen and Denniston, Alastair K. and Calvert, Melanie J.},
	month = sep,
	year = {2020},
	note = {Number: 9
Publisher: Nature Publishing Group},
	pages = {1351--1363},
}

@article{liu_reporting_2020,
	title = {Reporting guidelines for clinical trial reports for interventions involving artificial intelligence: the {CONSORT}-{AI} extension},
	volume = {26},
	copyright = {2020 The Author(s)},
	issn = {1546-170X},
	shorttitle = {Reporting guidelines for clinical trial reports for interventions involving artificial intelligence},
	url = {https://www.nature.com/articles/s41591-020-1034-x},
	doi = {10.1038/s41591-020-1034-x},
	abstract = {The CONSORT 2010 statement provides minimum guidelines for reporting randomized trials. Its widespread use has been instrumental in ensuring transparency in the evaluation of new interventions. More recently, there has been a growing recognition that interventions involving artificial intelligence (AI) need to undergo rigorous, prospective evaluation to demonstrate impact on health outcomes. The CONSORT-AI (Consolidated Standards of Reporting Trials–Artificial Intelligence) extension is a new reporting guideline for clinical trials evaluating interventions with an AI component. It was developed in parallel with its companion statement for clinical trial protocols: SPIRIT-AI (Standard Protocol Items: Recommendations for Interventional Trials–Artificial Intelligence). Both guidelines were developed through a staged consensus process involving literature review and expert consultation to generate 29 candidate items, which were assessed by an international multi-stakeholder group in a two-stage Delphi survey (103 stakeholders), agreed upon in a two-day consensus meeting (31 stakeholders) and refined through a checklist pilot (34 participants). The CONSORT-AI extension includes 14 new items that were considered sufficiently important for AI interventions that they should be routinely reported in addition to the core CONSORT 2010 items. CONSORT-AI recommends that investigators provide clear descriptions of the AI intervention, including instructions and skills required for use, the setting in which the AI intervention is integrated, the handling of inputs and outputs of the AI intervention, the human–AI interaction and provision of an analysis of error cases. CONSORT-AI will help promote transparency and completeness in reporting clinical trials for AI interventions. It will assist editors and peer reviewers, as well as the general readership, to understand, interpret and critically appraise the quality of clinical trial design and risk of bias in the reported outcomes.},
	language = {en},
	number = {9},
	urldate = {2020-09-10},
	journal = {Nature Medicine},
	author = {Liu, Xiaoxuan and Cruz Rivera, Samantha and Moher, David and Calvert, Melanie J. and Denniston, Alastair K.},
	month = sep,
	year = {2020},
	note = {Number: 9
Publisher: Nature Publishing Group},
	pages = {1364--1374},
}

@article{bovijn_gwas_2019,
	title = {{GWAS} {Identifies} {Risk} {Locus} for {Erectile} {Dysfunction} and {Implicates} {Hypothalamic} {Neurobiology} and {Diabetes} in {Etiology}},
	volume = {104},
	issn = {0002-9297},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6323625/},
	doi = {10.1016/j.ajhg.2018.11.004},
	abstract = {Erectile dysfunction (ED) is a common condition affecting more than 20\% of men over 60 years, yet little is known about its genetic architecture. We performed a genome-wide association study of ED in 6,175 case subjects among 223,805 European men and identified one locus at 6q16.3 (lead variant rs57989773, OR 1.20 per C-allele; p = 5.71 × 10−14), located between MCHR2 and SIM1. In silico analysis suggests SIM1 to confer ED risk through hypothalamic dysregulation. Mendelian randomization provides evidence that genetic risk of type 2 diabetes mellitus is a cause of ED (OR 1.11 per 1-log unit higher risk of type 2 diabetes). These findings provide insights into the biological underpinnings and the causes of ED and may help prioritize the development of future therapies for this common disorder.},
	number = {1},
	urldate = {2020-09-07},
	journal = {American Journal of Human Genetics},
	author = {Bovijn, Jonas and Jackson, Leigh and Censin, Jenny and Chen, Chia-Yen and Laisk, Triin and Laber, Samantha and Ferreira, Teresa and Pulit, Sara L. and Glastonbury, Craig A. and Smoller, Jordan W. and Harrison, Jamie W. and Ruth, Katherine S. and Beaumont, Robin N. and Jones, Samuel E. and Tyrrell, Jessica and Wood, Andrew R. and Weedon, Michael N. and Mägi, Reedik and Neale, Benjamin and Lindgren, Cecilia M. and Murray, Anna and Holmes, Michael V.},
	month = jan,
	year = {2019},
	pmid = {30583798},
	pmcid = {PMC6323625},
	pages = {157--163},
}

@article{cardenas_nasal_2019,
	title = {The nasal methylome as a biomarker of asthma and airway inflammation in children},
	volume = {10},
	issn = {2041-1723},
	doi = {10.1038/s41467-019-11058-3},
	abstract = {The nasal cellular epigenome may serve as biomarker of airway disease and environmental response. Here we collect nasal swabs from the anterior nares of 547 children (mean-age 12.9 y), and measure DNA methylation (DNAm) with the Infinium MethylationEPIC BeadChip. We perform nasal Epigenome-Wide Association analyses (EWAS) of current asthma, allergen sensitization, allergic rhinitis, fractional exhaled nitric oxide (FeNO) and lung function. We find multiple differentially methylated CpGs (FDR {\textless} 0.05) and Regions (DMRs; ≥ 5-CpGs and FDR {\textless} 0.05) for asthma (285-CpGs), FeNO (8,372-CpGs; 191-DMRs), total IgE (3-CpGs; 3-DMRs), environment IgE (17-CpGs; 4-DMRs), allergic asthma (1,235-CpGs; 7-DMRs) and bronchodilator response (130-CpGs). Discovered DMRs annotated to genes implicated in allergic asthma, Th2 activation and eosinophilia (EPX, IL4, IL13) and genes previously associated with asthma and IgE in EWAS of blood (ACOT7, SLC25A25). Asthma, IgE and FeNO were associated with nasal epigenetic age acceleration. The nasal epigenome is a sensitive biomarker of asthma, allergy and airway inflammation.},
	language = {eng},
	number = {1},
	journal = {Nature Communications},
	author = {Cardenas, Andres and Sordillo, Joanne E. and Rifas-Shiman, Sheryl L. and Chung, Wonil and Liang, Liming and Coull, Brent A. and Hivert, Marie-France and Lai, Peggy S. and Forno, Erick and Celedón, Juan C. and Litonjua, Augusto A. and Brennan, Kasey J. and DeMeo, Dawn L. and Baccarelli, Andrea A. and Oken, Emily and Gold, Diane R.},
	year = {2019},
	pmid = {31300640},
	pmcid = {PMC6625976},
	keywords = {Adolescent, Asthma, Biomarkers, Child, CpG Islands, DNA Methylation, Epigenesis, Genetic, Epigenomics, Female, Humans, Inflammation, Male, Nasal Mucosa},
	pages = {3095},
}

@article{lee_whole-genome_2018,
	title = {Whole-genome methylation profiling of peripheral blood mononuclear cell for acute exacerbations of chronic obstructive pulmonary disease treated with corticosteroid},
	volume = {28},
	issn = {1744-6880},
	doi = {10.1097/FPC.0000000000000325},
	abstract = {OBJECTIVE: Although association studies in the general population may be relevant for determining susceptibility to chronic obstructive pulmonary disease (COPD), they may be less applicable for pharmacogenetics research in participants who have already acquired the disease.
PATIENTS AND METHODS: A genome-wide methylation profiling (generated by HumanMethylation450 BeadChips study was performed on peripheral blood mononuclear cells of 24 patients with AECOPD (acute exacerbation COPD), with good and poor responsiveness to standard corticosteroid treatment. Pyrosequencing was used to replicate the selected CpG sites in 50 patients with AECOPD with standard corticosteroid treatment.
RESULTS: The results showed the patients with AECOPD with good and poor response to standard corticosteroid treatment have a distinct DNA methylation pattern. A total of 23 CpG loci located in 19 known gene regions, including gene-body and promoter, appeared to be significantly differentially methylated. Replication by pyrosequencing revealed that one CpG site in PSMD8 showed the same trend of differential methylation and reached to statistical significance as the microarray result.
CONCLUSION: Our preliminary findings provide evidence for molecular heterogeneity in patients with AECOPD, which may contribute to significant differences in their response to COPD treatment.},
	language = {eng},
	number = {3},
	journal = {Pharmacogenetics and Genomics},
	author = {Lee, Shih-Wei and Weng, Julia Tzu-Ya and Hsu, Paul Wei-Che and Chuang, Tzu-Yi and Liu, Chih-Wei and Chen, Chung-Hsuan and Wu, Lawrence Shih-Hsin},
	year = {2018},
	pmid = {29329142},
	keywords = {Adrenal Cortex Hormones, Aged, Albuterol, Bromhexine, CpG Islands, DNA Methylation, Female, Genome, Human, Humans, Leukocytes, Mononuclear, Male, Middle Aged, Prednisolone, Promoter Regions, Genetic, Pulmonary Disease, Chronic Obstructive},
	pages = {78--85},
}

@article{elbere_significantly_2018,
	title = {Significantly altered peripheral blood cell {DNA} methylation profile as a result of immediate effect of metformin use in healthy individuals},
	volume = {10},
	issn = {1868-7083},
	doi = {10.1186/s13148-018-0593-x},
	abstract = {BACKGROUND: Metformin is a widely prescribed antihyperglycemic agent that has been also associated with multiple therapeutic effects in various diseases, including several types of malignancies. There is growing evidence regarding the contribution of the epigenetic mechanisms in reaching metformin's therapeutic goals; however, the effect of metformin on human cells in vivo is not comprehensively studied. The aim of our study was to examine metformin-induced alterations of DNA methylation profiles in white blood cells of healthy volunteers, employing a longitudinal study design.
RESULTS: Twelve healthy metformin-naïve individuals where enrolled in the study. Genome-wide DNA methylation pattern was estimated at baseline, 10 h and 7 days after the start of metformin administration. The whole-genome DNA methylation analysis in total revealed 125 differentially methylated CpGs, of which 11 CpGs and their associated genes with the most consistent changes in the DNA methylation profile were selected: POFUT2, CAMKK1, EML3, KIAA1614, UPF1, MUC4, LOC727982, SIX3, ADAM8, SNORD12B, VPS8, and several differentially methylated regions as novel potential epigenetic targets of metformin. The main functions of the majority of top-ranked differentially methylated loci and their representative cell signaling pathways were linked to the well-known metformin therapy targets: regulatory processes of energy homeostasis, inflammatory responses, tumorigenesis, and neurodegenerative diseases.
CONCLUSIONS: Here we demonstrate for the first time the immediate effect of short-term metformin administration at therapeutic doses on epigenetic regulation in human white blood cells. These findings suggest the DNA methylation process as one of the mechanisms involved in the action of metformin, thereby revealing novel targets and directions of the molecular mechanisms underlying the various beneficial effects of metformin.
TRIAL REGISTRATION: EU Clinical Trials Register, 2016-001092-74. Registered 23 March 2017, https://www.clinicaltrialsregister.eu/ctr-search/trial/2016-001092-74/LV .},
	language = {eng},
	number = {1},
	journal = {Clinical Epigenetics},
	author = {Elbere, Ilze and Silamikelis, Ivars and Ustinova, Monta and Kalnina, Ineta and Zaharenko, Linda and Peculis, Raitis and Konrade, Ilze and Ciuculete, Diana Maria and Zhukovsky, Christina and Gudra, Dita and Radovica-Spalvina, Ilze and Fridmanis, Davids and Pirags, Valdis and Schiöth, Helgi B. and Klovins, Janis},
	year = {2018},
	pmid = {30545422},
	pmcid = {PMC6293577},
	keywords = {Adult, Blood Cells, CpG Islands, DNA Methylation, DNA methylation, Epigenesis, Genetic, Epigenetics, Female, Gene Regulatory Networks, Healthy Volunteers, Humans, Longitudinal Studies, Longitudinal study, Male, Metformin, White blood cells, Whole Genome Sequencing},
	pages = {156},
}

@article{chambers_epigenome-wide_2015,
	title = {Epigenome-wide association of {DNA} methylation markers in peripheral blood from {Indian} {Asians} and {Europeans} with incident type 2 diabetes: a nested case-control study},
	volume = {3},
	issn = {2213-8595},
	shorttitle = {Epigenome-wide association of {DNA} methylation markers in peripheral blood from {Indian} {Asians} and {Europeans} with incident type 2 diabetes},
	doi = {10.1016/S2213-8587(15)00127-8},
	abstract = {BACKGROUND: Indian Asians, who make up a quarter of the world's population, are at high risk of developing type 2 diabetes. We investigated whether DNA methylation is associated with future type 2 diabetes incidence in Indian Asians and whether differences in methylation patterns between Indian Asians and Europeans are associated with, and could be used to predict, differences in the magnitude of risk of developing type 2 diabetes.
METHODS: We did a nested case-control study of DNA methylation in Indian Asians and Europeans with incident type 2 diabetes who were identified from the 8-year follow-up of 25 372 participants in the London Life Sciences Prospective Population (LOLIPOP) study. Patients were recruited between May 1, 2002, and Sept 12, 2008. We did epigenome-wide association analysis using samples from Indian Asians with incident type 2 diabetes and age-matched and sex-matched Indian Asian controls, followed by replication testing of top-ranking signals in Europeans. For both discovery and replication, DNA methylation was measured in the baseline blood sample, which was collected before the onset of type 2 diabetes. Epigenome-wide significance was set at p{\textless}1 × 10(-7). We compared methylation levels between Indian Asian and European controls without type 2 diabetes at baseline to estimate the potential contribution of DNA methylation to increased risk of future type 2 diabetes incidence among Indian Asians.
FINDINGS: 1608 (11·9\%) of 13 535 Indian Asians and 306 (4·3\%) of 7066 Europeans developed type 2 diabetes over a mean of 8·5 years (SD 1·8) of follow-up. The age-adjusted and sex-adjusted incidence of type 2 diabetes was 3·1 times (95\% CI 2·8-3·6; p{\textless}0·0001) higher among Indian Asians than among Europeans, and remained 2·5 times (2·1-2·9; p{\textless}0·0001) higher after adjustment for adiposity, physical activity, family history of type 2 diabetes, and baseline glycaemic measures. The mean absolute difference in methylation level between type 2 diabetes cases and controls ranged from 0·5\% (SD 0·1) to 1·1\% (0·2). Methylation markers at five loci were associated with future type 2 diabetes incidence; the relative risk per 1\% increase in methylation was 1·09 (95\% CI 1·07-1·11; p=1·3 × 10(-17)) for ABCG1, 0·94 (0·92-0·95; p=4·2 × 10(-11)) for PHOSPHO1, 0·94 (0·92-0·96; p=1·4 × 10(-9)) for SOCS3, 1·07 (1·04-1·09; p=2·1 × 10(-10)) for SREBF1, and 0·92 (0·90-0·94; p=1·2 × 10(-17)) for TXNIP. A methylation score combining results for the five loci was associated with future type 2 diabetes incidence (relative risk quartile 4 vs quartile 1 3·51, 95\% CI 2·79-4·42; p=1·3 × 10(-26)), and was independent of established risk factors. Methylation score was higher among Indian Asians than Europeans (p=1 × 10(-34)).
INTERPRETATION: DNA methylation might provide new insights into the pathways underlying type 2 diabetes and offer new opportunities for risk stratification and prevention of type 2 diabetes among Indian Asians.
FUNDING: The European Union, the UK National Institute for Health Research, the Wellcome Trust, the UK Medical Research Council, Action on Hearing Loss, the UK Biotechnology and Biological Sciences Research Council, the Oak Foundation, the Economic and Social Research Council, Helmholtz Zentrum Munchen, the German Research Center for Environmental Health, the German Federal Ministry of Education and Research, the German Center for Diabetes Research, the Munich Center for Health Sciences, the Ministry of Science and Research of the State of North Rhine-Westphalia, and the German Federal Ministry of Health.},
	language = {eng},
	number = {7},
	journal = {The Lancet. Diabetes \& Endocrinology},
	author = {Chambers, John C. and Loh, Marie and Lehne, Benjamin and Drong, Alexander and Kriebel, Jennifer and Motta, Valeria and Wahl, Simone and Elliott, Hannah R. and Rota, Federica and Scott, William R. and Zhang, Weihua and Tan, Sian-Tsung and Campanella, Gianluca and Chadeau-Hyam, Marc and Yengo, Loic and Richmond, Rebecca C. and Adamowicz-Brice, Martyna and Afzal, Uzma and Bozaoglu, Kiymet and Mok, Zuan Yu and Ng, Hong Kiat and Pattou, François and Prokisch, Holger and Rozario, Michelle Ann and Tarantini, Letizia and Abbott, James and Ala-Korpela, Mika and Albetti, Benedetta and Ammerpohl, Ole and Bertazzi, Pier Alberto and Blancher, Christine and Caiazzo, Robert and Danesh, John and Gaunt, Tom R. and de Lusignan, Simon and Gieger, Christian and Illig, Thomas and Jha, Sujeet and Jones, Simon and Jowett, Jeremy and Kangas, Antti J. and Kasturiratne, Anuradhani and Kato, Norihiro and Kotea, Navaratnam and Kowlessur, Sudhir and Pitkäniemi, Janne and Punjabi, Prakash and Saleheen, Danish and Schafmayer, Clemens and Soininen, Pasi and Tai, E.-Shyong and Thorand, Barbara and Tuomilehto, Jaakko and Wickremasinghe, Ananda Rajitha and Kyrtopoulos, Soterios A. and Aitman, Timothy J. and Herder, Christian and Hampe, Jochen and Cauchi, Stéphane and Relton, Caroline L. and Froguel, Philippe and Soong, Richie and Vineis, Paolo and Jarvelin, Marjo-Riitta and Scott, James and Grallert, Harald and Bollati, Valentina and Elliott, Paul and McCarthy, Mark I. and Kooner, Jaspal S.},
	month = jul,
	year = {2015},
	pmid = {26095709},
	pmcid = {PMC4724884},
	keywords = {Asian Continental Ancestry Group, Case-Control Studies, DNA Methylation, Diabetes Mellitus, Type 2, Epigenesis, Genetic, European Continental Ancestry Group, Female, Genetic Markers, Genome-Wide Association Study, Humans, Male, Middle Aged, Prospective Studies, Risk Factors},
	pages = {526--534},
}

@article{volkmar_dna_2012,
	title = {{DNA} methylation profiling identifies epigenetic dysregulation in pancreatic islets from type 2 diabetic patients},
	volume = {31},
	issn = {1460-2075},
	doi = {10.1038/emboj.2011.503},
	abstract = {In addition to genetic predisposition, environmental and lifestyle factors contribute to the pathogenesis of type 2 diabetes (T2D). Epigenetic changes may provide the link for translating environmental exposures into pathological mechanisms. In this study, we performed the first comprehensive DNA methylation profiling in pancreatic islets from T2D and non-diabetic donors. We uncovered 276 CpG loci affiliated to promoters of 254 genes displaying significant differential DNA methylation in diabetic islets. These methylation changes were not present in blood cells from T2D individuals nor were they experimentally induced in non-diabetic islets by exposure to high glucose. For a subgroup of the differentially methylated genes, concordant transcriptional changes were present. Functional annotation of the aberrantly methylated genes and RNAi experiments highlighted pathways implicated in β-cell survival and function; some are implicated in cellular dysfunction while others facilitate adaptation to stressors. Together, our findings offer new insights into the intricate mechanisms of T2D pathogenesis, underscore the important involvement of epigenetic dysregulation in diabetic islets and may advance our understanding of T2D aetiology.},
	language = {eng},
	number = {6},
	journal = {The EMBO journal},
	author = {Volkmar, Michael and Dedeurwaerder, Sarah and Cunha, Daniel A. and Ndlovu, Matladi N. and Defrance, Matthieu and Deplus, Rachel and Calonne, Emilie and Volkmar, Ute and Igoillo-Esteve, Mariana and Naamane, Najib and Del Guerra, Silvia and Masini, Matilde and Bugliani, Marco and Marchetti, Piero and Cnop, Miriam and Eizirik, Decio L. and Fuks, François},
	month = mar,
	year = {2012},
	pmid = {22293752},
	pmcid = {PMC3321176},
	keywords = {Aged, Animals, Cell Line, CpG Islands, DNA Fingerprinting, DNA Methylation, Diabetes Mellitus, Type 2, Epigenesis, Genetic, Genetic Loci, Glucose, Humans, Islets of Langerhans, Promoter Regions, Genetic, Rats, Transcription, Genetic},
	pages = {1405--1426},
}

@article{richard_dna_2017,
	title = {{DNA} {Methylation} {Analysis} {Identifies} {Loci} for {Blood} {Pressure} {Regulation}},
	volume = {101},
	issn = {1537-6605},
	doi = {10.1016/j.ajhg.2017.09.028},
	abstract = {Genome-wide association studies have identified hundreds of genetic variants associated with blood pressure (BP), but sequence variation accounts for a small fraction of the phenotypic variance. Epigenetic changes may alter the expression of genes involved in BP regulation and explain part of the missing heritability. We therefore conducted a two-stage meta-analysis of the cross-sectional associations of systolic and diastolic BP with blood-derived genome-wide DNA methylation measured on the Infinium HumanMethylation450 BeadChip in 17,010 individuals of European, African American, and Hispanic ancestry. Of 31 discovery-stage cytosine-phosphate-guanine (CpG) dinucleotides, 13 replicated after Bonferroni correction (discovery: N = 9,828, p {\textless} 1.0 × 10-7; replication: N = 7,182, p {\textless} 1.6 × 10-3). The replicated methylation sites are heritable (h2 {\textgreater} 30\%) and independent of known BP genetic variants, explaining an additional 1.4\% and 2.0\% of the interindividual variation in systolic and diastolic BP, respectively. Bidirectional Mendelian randomization among up to 4,513 individuals of European ancestry from 4 cohorts suggested that methylation at cg08035323 (TAF1B-YWHAQ) influences BP, while BP influences methylation at cg00533891 (ZMIZ1), cg00574958 (CPT1A), and cg02711608 (SLC1A5). Gene expression analyses further identified six genes (TSPAN2, SLC7A11, UNC93B1, CPT1A, PTMS, and LPCAT3) with evidence of triangular associations between methylation, gene expression, and BP. Additional integrative Mendelian randomization analyses of gene expression and DNA methylation suggested that the expression of TSPAN2 is a putative mediator of association between DNA methylation at cg23999170 and BP. These findings suggest that heritable DNA methylation plays a role in regulating BP independently of previously known genetic variants.},
	language = {eng},
	number = {6},
	journal = {American Journal of Human Genetics},
	author = {Richard, Melissa A. and Huan, Tianxiao and Ligthart, Symen and Gondalia, Rahul and Jhun, Min A. and Brody, Jennifer A. and Irvin, Marguerite R. and Marioni, Riccardo and Shen, Jincheng and Tsai, Pei-Chien and Montasser, May E. and Jia, Yucheng and Syme, Catriona and Salfati, Elias L. and Boerwinkle, Eric and Guan, Weihua and Mosley, Thomas H. and Bressler, Jan and Morrison, Alanna C. and Liu, Chunyu and Mendelson, Michael M. and Uitterlinden, André G. and van Meurs, Joyce B. and {BIOS Consortium} and Franco, Oscar H. and Zhang, Guosheng and Li, Yun and Stewart, James D. and Bis, Joshua C. and Psaty, Bruce M. and Chen, Yii-Der Ida and Kardia, Sharon L. R. and Zhao, Wei and Turner, Stephen T. and Absher, Devin and Aslibekyan, Stella and Starr, John M. and McRae, Allan F. and Hou, Lifang and Just, Allan C. and Schwartz, Joel D. and Vokonas, Pantel S. and Menni, Cristina and Spector, Tim D. and Shuldiner, Alan and Damcott, Coleen M. and Rotter, Jerome I. and Palmas, Walter and Liu, Yongmei and Paus, Tomáš and Horvath, Steve and O'Connell, Jeffrey R. and Guo, Xiuqing and Pausova, Zdenka and Assimes, Themistocles L. and Sotoodehnia, Nona and Smith, Jennifer A. and Arnett, Donna K. and Deary, Ian J. and Baccarelli, Andrea A. and Bell, Jordana T. and Whitsel, Eric and Dehghan, Abbas and Levy, Daniel and Fornage, Myriam},
	month = dec,
	year = {2017},
	pmid = {29198723},
	pmcid = {PMC5812919},
	keywords = {Aged, Blood Pressure, CpG Islands, Cross-Sectional Studies, DNA Methylation, DNA methylation, Epigenesis, Genetic, Genetic Variation, Genome-Wide Association Study, Humans, Mendelian Randomization Analysis, Mendelian randomization, Middle Aged, Nerve Tissue Proteins, Quantitative Trait Loci, Tetraspanins, blood pressure, epigenome-wide association study, gene expression, sequence variation},
	pages = {888--902},
}

@article{kazmi_associations_2020,
	title = {Associations between high blood pressure and {DNA} methylation},
	volume = {15},
	issn = {1932-6203},
	doi = {10.1371/journal.pone.0227728},
	abstract = {BACKGROUND: High blood pressure is a major risk factor for cardiovascular disease and is influenced by both environmental and genetic factors. Epigenetic processes including DNA methylation potentially mediate the relationship between genetic factors, the environment and cardiovascular disease. Despite an increased risk of hypertension and cardiovascular disease in individuals of South Asians compared to Europeans, it is not clear whether associations between blood pressure and DNA methylation differ between these groups.
METHODS: We performed an epigenome-wide association study and differentially methylated region (DMR) analysis to identify DNA methylation sites and regions that were associated with systolic blood pressure, diastolic blood pressure and hypertension. We analyzed samples from 364 European and 348 South Asian men (first generation migrants to the UK) from the Southall And Brent REvisited cohort, measuring DNA methylation from blood using the Illumina Infinium® HumanMethylation450 BeadChip.
RESULTS: One CpG site was found to be associated with DBP in trans-ancestry analyses (i.e. both ethnic groups combined), while in Europeans alone seven CpG sites were associated with DBP. No associations were identified between DNA methylation and either SBP or hypertension. Comparison of effect sizes between South Asian and European EWAS for DBP, SBP and hypertension revealed little concordance between analyses. DMR analysis identified several regions with known relationships with CVD and its risk factors.
CONCLUSION: This study identified differentially methylated sites and regions associated with blood pressure and revealed ethnic differences in these associations. These findings may point to molecular pathways which may explain the elevated cardiovascular disease risk experienced by those of South Asian ancestry when compared to Europeans.},
	language = {eng},
	number = {1},
	journal = {PloS One},
	author = {Kazmi, Nabila and Elliott, Hannah R. and Burrows, Kim and Tillin, Therese and Hughes, Alun D. and Chaturvedi, Nish and Gaunt, Tom R. and Relton, Caroline L.},
	year = {2020},
	pmid = {31999706},
	pmcid = {PMC6991984},
	keywords = {Adult, Asian Continental Ancestry Group, Blood Pressure, Cohort Studies, CpG Islands, DNA Methylation, Emigrants and Immigrants, Epigenesis, Genetic, Epigenome, European Continental Ancestry Group, Genome-Wide Association Study, Humans, Hypertension, Male, Middle Aged, Risk Factors, United Kingdom},
	pages = {e0227728},
}

@article{nakatochi_epigenome-wide_2017,
	title = {Epigenome-wide association of myocardial infarction with {DNA} methylation sites at loci related to cardiovascular disease},
	volume = {9},
	issn = {1868-7083},
	doi = {10.1186/s13148-017-0353-3},
	abstract = {BACKGROUND: Development of cardiovascular disease (CVD), including coronary artery disease, arrhythmia, and ischemic stroke, depends on environmental and genetic factors. To investigate the epigenetic basis of myocardial infarction (MI), we performed an epigenome-wide association study for this condition in elderly Japanese subjects. A total of 192 case subjects with MI and 192 control subjects were recruited from hospital attendees and the general population, respectively. Genome-wide DNA methylation (DNAm) profiles for DNA isolated from whole blood were obtained by analysis with an Infinium HumanMethylation450 BeadChip. The relation of DNAm sites found to be significantly associated with MI to nearby single nucleotide polymorphisms (SNPs) previously shown to be associated with CVD was assessed in the control group.
FINDINGS: Three DNAm sites (cg06642177, cg07786668, cg17218495) showed genome-wide significant associations with MI (p = 4.33 × 10-8, 3.96 × 10-10, and 3.77 × 10-8, respectively). Two of these sites (cg07786668, cg17218495) still showed such associations after adjustment for classical risk factors of MI (p = 1.04 × 10-7 and 6.60 × 10-8, respectively). The DNAm sites cg07786668 and cg17218495 are located in ZFHX3 (zinc finger homeobox 3) and SMARCA4 (SWI/SNF-related, matrix-associated, actin-dependent regulator of chromatin, subfamily a, member 4) genes, respectively. SNPs in ZFHX3 or SMARCA4 that were previously found to be associated with CVD were not significantly associated with these DNAm sites in our control subjects.
CONCLUSIONS: We identified two DNAm sites-cg07786668 in ZFHX3 and cg17218495 in SMARCA4- that are independently and significantly associated with MI. Our results suggest that the development of MI might be influenced by changes in DNAm at these sites via a pathway that differs from that affected by CVD-associated SNPs in these genes. The Kita-Nagoya Genomic Epidemiology (KING) study, which was the source of control samples in the present study, was registered in ClinicalTrials.gov (NCT00262691) on 6 December 2005.},
	language = {eng},
	journal = {Clinical Epigenetics},
	author = {Nakatochi, Masahiro and Ichihara, Sahoko and Yamamoto, Ken and Naruse, Keiko and Yokota, Shigeki and Asano, Hiroyuki and Matsubara, Tatsuaki and Yokota, Mitsuhiro},
	year = {2017},
	pmid = {28515798},
	pmcid = {PMC5432989},
	keywords = {Aged, Asian Continental Ancestry Group, Cardiovascular disease, Cross-Sectional Studies, DNA Helicases, DNA Methylation, DNA methylation, Epigenesis, Genetic, Epigenome-wide association study, Epigenomics, Genetic Predisposition to Disease, Genome-Wide Association Study, Homeodomain Proteins, Humans, Japan, Male, Middle Aged, Myocardial Infarction, Myocardial infarction, Nuclear Proteins, Polymorphism, Single Nucleotide, Single nucleotide polymorphism, Transcription Factors},
	pages = {54},
}

@article{rask-andersen_epigenome-wide_2016,
	title = {Epigenome-wide association study reveals differential {DNA} methylation in individuals with a history of myocardial infarction},
	volume = {25},
	issn = {1460-2083},
	doi = {10.1093/hmg/ddw302},
	abstract = {Cardiovascular diseases (CVDs) are the leading causes of death worldwide and represent a substantial economic burden on public health care systems. Epigenetic markers have potential as diagnostic markers before clinical symptoms have emerged, and as prognostic markers to inform the choice of clinical intervention. In this study, we performed an epigenome-wide association study (EWAS) for CVDs, to identify disease-specific alterations in DNA methylation. CpG methylation in blood samples from the northern Sweden population health study (NSPHS) (n = 729) was assayed on the Illumina Infinium HumanMethylation450 BeadChip. Individuals with a history of a CVD were identified in the cohort. It included individuals with hypertension (N = 147), myocardial infarction (MI) (N = 48), stroke (N = 27), thrombosis (N = 22) and cardiac arrhythmia (N = 5). Differential DNA methylation was observed at 211 CpG-sites in individuals with a history of MI (q {\textless}0.05). These sites represent 196 genes, of which 42 have been described in the scientific literature to be related to cardiac function, cardiovascular disease, cardiogenesis and recovery after ischemic injury. We have shown that individuals with a history of MI have a deviating pattern of DNA methylation at many genomic loci of which a large fraction has previously been linked to CVD. Our results highlight genes that might be important in the pathogenesis of MI or in recovery. In addition, the sites pointed out in this study can serve as candidates for further evaluation as potential biomarkers for MI.},
	language = {eng},
	number = {21},
	journal = {Human Molecular Genetics},
	author = {Rask-Andersen, Mathias and Martinsson, David and Ahsan, Muhammad and Enroth, Stefan and Ek, Weronica E. and Gyllensten, Ulf and Johansson, Åsa},
	year = {2016},
	pmid = {28172975},
	keywords = {Biomarkers, Cardiovascular Diseases, Cohort Studies, CpG Islands, DNA Methylation, Epigenesis, Genetic, Epigenomics, Female, Genome, Human, Genome-Wide Association Study, Humans, Hypertension, Male, Myocardial Infarction, Sweden},
	pages = {4739--4748},
}

@article{jaffe_mapping_2016,
	title = {Mapping {DNA} methylation across development, genotype and schizophrenia in the human frontal cortex},
	volume = {19},
	issn = {1546-1726},
	doi = {10.1038/nn.4181},
	abstract = {DNA methylation (DNAm) is important in brain development and is potentially important in schizophrenia. We characterized DNAm in prefrontal cortex from 335 non-psychiatric controls across the lifespan and 191 patients with schizophrenia and identified widespread changes in the transition from prenatal to postnatal life. These DNAm changes manifest in the transcriptome, correlate strongly with a shifting cellular landscape and overlap regions of genetic risk for schizophrenia. A quarter of published genome-wide association studies (GWAS)-suggestive loci (4,208 of 15,930, P {\textless} 10(-100)) manifest as significant methylation quantitative trait loci (meQTLs), including 59.6\% of GWAS-positive schizophrenia loci. We identified 2,104 CpGs that differ between schizophrenia patients and controls that were enriched for genes related to development and neurodifferentiation. The schizophrenia-associated CpGs strongly correlate with changes related to the prenatal-postnatal transition and show slight enrichment for GWAS risk loci while not corresponding to CpGs differentiating adolescence from later adult life. These data implicate an epigenetic component to the developmental origins of this disorder.},
	language = {eng},
	number = {1},
	journal = {Nature Neuroscience},
	author = {Jaffe, Andrew E. and Gao, Yuan and Deep-Soboslay, Amy and Tao, Ran and Hyde, Thomas M. and Weinberger, Daniel R. and Kleinman, Joel E.},
	month = jan,
	year = {2016},
	pmid = {26619358},
	pmcid = {PMC4783176},
	keywords = {Age of Onset, CpG Islands, DNA Methylation, Epigenesis, Genetic, Fetal Development, Genetic Loci, Genotype, Human Development, Humans, Prefrontal Cortex, Schizophrenia, Tissue Banks, Transcriptome},
	pages = {40--47},
}

@article{montano_association_2016,
	title = {Association of {DNA} {Methylation} {Differences} {With} {Schizophrenia} in an {Epigenome}-{Wide} {Association} {Study}},
	volume = {73},
	issn = {2168-6238},
	doi = {10.1001/jamapsychiatry.2016.0144},
	abstract = {IMPORTANCE: DNA methylation may play an important role in schizophrenia (SZ), either directly as a mechanism of pathogenesis or as a biomarker of risk.
OBJECTIVE: To scan genome-wide DNA methylation data to identify differentially methylated CpGs between SZ cases and controls.
DESIGN, SETTING, AND PARTICIPANTS: Epigenome-wide association study begun in 2008 using DNA methylation levels of 456 513 CpG loci measured on the Infinium HumanMethylation450 array (Illumina) in a consortium of case-control studies for initial discovery and in an independent replication set. Primary analyses used general linear regression, adjusting for age, sex, race/ethnicity, smoking, batch, and cell type heterogeneity. The discovery set contained 689 SZ cases and 645 controls (n = 1334), from 3 multisite consortia: the Consortium on the Genetics of Endophenotypes in Schizophrenia, the Project among African-Americans To Explore Risks for Schizophrenia, and the Multiplex Multigenerational Family Study of Schizophrenia. The replication set contained 247 SZ cases and 250 controls (n = 497) from the Genomic Psychiatry Cohort.
MAIN OUTCOMES AND MEASURES: Identification of differentially methylated positions across the genome in SZ cases compared with controls.
RESULTS: Of the 689 case participants in the discovery set, 477 (69\%) were men and 258 (37\%) were non-African American; of the 645 controls, 273 (42\%) were men and 419 (65\%) were non-African American. In our replication set, cases/controls were 76\% male and 100\% non-African American. We identified SZ-associated methylation differences at 923 CpGs in the discovery set (false discovery rate, {\textless}0.2). Of these, 625 showed changes in the same direction including 172 with P {\textless} .05 in the replication set. Some replicated differentially methylated positions are located in a top-ranked SZ region from genome-wide association study analyses.
CONCLUSIONS AND RELEVANCE: This analysis identified 172 replicated new associations with SZ after careful correction for cell type heterogeneity and other potential confounders. The overlap with previous genome-wide association study data can provide potential insights into the functional relevance of genetic signals for SZ.},
	language = {eng},
	number = {5},
	journal = {JAMA psychiatry},
	author = {Montano, Carolina and Taub, Margaret A. and Jaffe, Andrew and Briem, Eirikur and Feinberg, Jason I. and Trygvadottir, Rakel and Idrizi, Adrian and Runarsson, Arni and Berndsen, Birna and Gur, Ruben C. and Moore, Tyler M. and Perry, Rodney T. and Fugman, Doug and Sabunciyan, Sarven and Yolken, Robert H. and Hyde, Thomas M. and Kleinman, Joel E. and Sobell, Janet L. and Pato, Carlos N. and Pato, Michele T. and Go, Rodney C. and Nimgaonkar, Vishwajit and Weinberger, Daniel R. and Braff, David and Gur, Raquel E. and Fallin, Margaret Daniele and Feinberg, Andrew P.},
	year = {2016},
	pmid = {27074206},
	pmcid = {PMC6353566},
	keywords = {Adult, African Americans, CpG Islands, DNA Methylation, Epigenesis, Genetic, Epigenomics, Female, Genetic Loci, Genetic Markers, Genome-Wide Association Study, Humans, Male, Phenotype, Psychotic Disorders, Schizophrenia, Sex Factors},
	pages = {506--514},
}

@article{bustamante_epigenetic_2018,
	title = {Epigenetic profiles associated with major depression in the human brain},
	volume = {260},
	issn = {1872-7123},
	doi = {10.1016/j.psychres.2017.12.010},
	abstract = {We conducted an epigenome-wide association study of Major Depressive Disorder (MDD) in brain-derived DNA using two analytic approaches. DNA methylation data (GSE41826) was used in differential methylation (DM) analyses controlling for age, sex, suicide status, and post-mortem interval; and in weighted gene co-methylation network analyses (WGCNA) in probes mapping to transcription start sites. No probes in the DM analysis survived FDR correction. Nominally significant DM probes were enriched in synaptic function-related genes. WGCNA revealed one module correlated with MDD, enriched in genes associated with mitochondrial function. DM and WGCNA both showed enrichment of genes involved in transcription and DNA binding.},
	language = {eng},
	journal = {Psychiatry Research},
	author = {Bustamante, Angela C. and Armstrong, Don L. and Uddin, Monica},
	year = {2018},
	pmid = {29272728},
	keywords = {Brain, DNA Methylation, Depressive Disorder, Major, Epigenesis, Genetic, Female, Gene Expression Profiling, Gene Regulatory Networks, Humans, Male, Suicide},
	pages = {439--442},
}

@article{mandaviya_association_2019,
	title = {Association of dietary folate and vitamin {B}-12 intake with genome-wide {DNA} methylation in blood: a large-scale epigenome-wide association analysis in 5841 individuals},
	volume = {110},
	issn = {1938-3207},
	shorttitle = {Association of dietary folate and vitamin {B}-12 intake with genome-wide {DNA} methylation in blood},
	doi = {10.1093/ajcn/nqz031},
	abstract = {BACKGROUND: Folate and vitamin B-12 are essential micronutrients involved in the donation of methyl groups in cellular metabolism. However, associations between intake of these nutrients and genome-wide DNA methylation levels have not been studied comprehensively in humans.
OBJECTIVE: The aim of this study was to assess whether folate and/or vitamin B-12 intake are asssociated with genome-wide changes in DNA methylation in leukocytes.
METHODS: A large-scale epigenome-wide association study of folate and vitamin B-12 intake was performed on DNA from 5841 participants from 10 cohorts using Illumina 450k arrays. Folate and vitamin B-12 intakes were calculated from food-frequency questionnaires (FFQs). Continuous and categorical (low compared with high intake) linear regression mixed models were applied per cohort, controlling for confounders. A meta-analysis was performed to identify significant differentially methylated positions (DMPs) and regions (DMRs), and a pathway analysis was performed on the DMR annotated genes.
RESULTS: The categorical model resulted in 6 DMPs, which are all negatively associated with folate intake, annotated to FAM64A, WRAP73, FRMD8, CUX1, and LCN8 genes, which have a role in cellular processes including centrosome localization, cell proliferation, and tumorigenesis. Regional analysis showed 74 folate-associated DMRs, of which 73 were negatively associated with folate intake. The most significant folate-associated DMR was a 400-base pair (bp) spanning region annotated to the LGALS3BP gene. In the categorical model, vitamin B-12 intake was associated with 29 DMRs annotated to 48 genes, of which the most significant was a 1100-bp spanning region annotated to the calcium-binding tyrosine phosphorylation-regulated gene (CABYR). Vitamin B-12 intake was not associated with DMPs.
CONCLUSIONS: We identified novel epigenetic loci that are associated with folate and vitamin B-12 intake. Interestingly, we found a negative association between folate and DNA methylation. Replication of these methylation loci is necessary in future studies.},
	language = {eng},
	number = {2},
	journal = {The American Journal of Clinical Nutrition},
	author = {Mandaviya, Pooja R. and Joehanes, Roby and Brody, Jennifer and Castillo-Fernandez, Juan E. and Dekkers, Koen F. and Do, Anh N. and Graff, Mariaelisa and Hänninen, Ismo K. and Tanaka, Toshiko and de Jonge, Ester A. L. and Kiefte-de Jong, Jessica C. and Absher, Devin M. and Aslibekyan, Stella and de Rijke, Yolanda B. and Fornage, Myriam and Hernandez, Dena G. and Hurme, Mikko A. and Ikram, M. Arfan and Jacques, Paul F. and Justice, Anne E. and Kiel, Douglas P. and Lemaitre, Rozenn N. and Mendelson, Michael M. and Mikkilä, Vera and Moore, Ann Z. and Pallister, Tess and Raitakari, Olli T. and Schalkwijk, Casper G. and Sha, Jin and Slagboom, Eline P. E. and Smith, Caren E. and Stehouwer, Coen D. A. and Tsai, Pei-Chien and Uitterlinden, André G. and van der Kallen, Carla J. H. and van Heemst, Diana and Arnett, Donna K. and Bandinelli, Stefania and Bell, Jordana T. and Heijmans, Bastiaan T. and Lehtimäki, Terho and Levy, Daniel and North, Kari E. and Sotoodehnia, Nona and van Greevenbroek, Marleen M. J. and van Meurs, Joyce B. J. and Heil, Sandra G.},
	year = {2019},
	pmid = {31165884},
	pmcid = {PMC6669135},
	keywords = {Adult, Aged, DNA Methylation, DNA methylation, Diet, Epigenome-wide Association Study, Epigenomics, FFQ, Female, Folic Acid, Gene Expression Regulation, Genome-Wide Association Study, Humans, Male, Middle Aged, Vitamin B 12, diet, epigenetics, folate, genome-wide, vitamin B-12},
	pages = {437--450},
}

@article{yadav_vitamin_2018,
	title = {Vitamin {B12} supplementation influences methylation of genes associated with {Type} 2 diabetes and its intermediate traits},
	volume = {10},
	issn = {1750-192X},
	doi = {10.2217/epi-2017-0102},
	abstract = {AIM: To investigate the effect of B12 and/or folic acid supplementation on genome-wide DNA methylation.
METHODS: We performed Infinium HumanMethylation450 BeadChip (Zymo Research, CA, USA) assay in children supplemented with B12 and/or folic acid (n = 12 in each group) and investigated the functional mechanism of selected differentially methylated loci.
RESULTS: We noted significant methylation changes postsupplementation in B12 (589 differentially methylated CpGs and 2892 regions) and B12 + folic acid (169 differentially methylated CpGs and 3241 regions) groups. Type 2 diabetes-associated genes TCF7L2 and FTO; and a miRNA, miR21 were further investigated in another B12-supplementation cohort. We also demonstrate that methylation influences miR21 expression and FTO, TCF7L2, CREBBP/CBP and SIRT1 are direct targets of miR21-3p.
CONCLUSION: B12 supplementation influences regulation of several metabolically important Type 2 diabetes-associated genes through methylation of miR21. Hence, our study provides novel epigenetic explanation for the association between disordered one carbon metabolism and risk of adiposity, insulin resistance and diabetes and has translational potential.},
	language = {eng},
	number = {1},
	journal = {Epigenomics},
	author = {Yadav, Dilip K. and Shrestha, Smeeta and Lillycrop, Karen A. and Joglekar, Charu V. and Pan, Hong and Holbrook, Joanna D. and Fall, Caroline Hd and Yajnik, Chittaranjan S. and Chandak, Giriraj R.},
	year = {2018},
	pmid = {29135286},
	keywords = {Child, DNA Methylation, DNA methylation, Diabetes Mellitus, Type 2, Dietary Supplements, Epigenomics, Female, Humans, Male, MicroRNAs, Type 2 diabetes, Vitamin B 12, Vitamin B Complex, folic acid, miRNAs, molecular mechanisms, supplementation, vitamin B12},
	pages = {71--90},
}

@article{kok_effects_2015,
	title = {The effects of long-term daily folic acid and vitamin {B12} supplementation on genome-wide {DNA} methylation in elderly subjects},
	volume = {7},
	issn = {1868-7075},
	doi = {10.1186/s13148-015-0154-5},
	abstract = {BACKGROUND: Folate and its synthetic form folic acid function as donor of one-carbon units and have been, together with other B-vitamins, implicated in programming of epigenetic processes such as DNA methylation during early development. To what extent regulation of DNA methylation can be altered via B-vitamins later in life, and how this relates to health and disease, is not exactly known. The aim of this study was to identify effects of long-term supplementation with folic acid and vitamin B12 on genome-wide DNA methylation in elderly subjects. This project was part of a randomized, placebo-controlled trial on effects of supplemental intake of folic acid and vitamin B12 on bone fracture incidence (B-vitamins for the PRevention Of Osteoporotic Fractures (B-PROOF) study). Participants with mildly elevated homocysteine levels, aged 65-75 years, were randomly assigned to take 400 μg folic acid and 500 μg vitamin B12 per day or a placebo during an intervention period of 2 years. DNA was isolated from buffy coats, collected before and after intervention, and genome-wide DNA methylation was determined in 87 participants (n = 44 folic acid/vitamin B12, n = 43 placebo) using the Infinium HumanMethylation450 BeadChip.
RESULTS: After intervention with folic acid and vitamin B12, 162 (versus 14 in the placebo group) of the 431,312 positions were differentially methylated as compared to baseline. Comparisons of the DNA methylation changes in the participants receiving folic acid and vitamin B12 versus placebo revealed one single differentially methylated position (cg19380919) with a borderline statistical significance. However, based on the analyses of differentially methylated regions (DMRs) consisting of multiple positions, we identified 6 regions that differed statistically significantly between the intervention and placebo group. Pronounced changes were found for regions in the DIRAS3, ARMC8, and NODAL genes, implicated in carcinogenesis and early embryonic development. Furthermore, serum levels of folate and vitamin B12 or plasma homocysteine were related to DNA methylation of 173, 425, and 11 regions, respectively. Interestingly, for several members of the developmental HOX genes, DNA methylation was related to serum levels of folate.
CONCLUSIONS: Long-term supplementation with folic acid and vitamin B12 in elderly subjects resulted in effects on DNA methylation of several genes, among which genes implicated in developmental processes.},
	language = {eng},
	journal = {Clinical Epigenetics},
	author = {Kok, Dieuwertje E. G. and Dhonukshe-Rutten, Rosalie A. M. and Lute, Carolien and Heil, Sandra G. and Uitterlinden, André G. and van der Velde, Nathalie and van Meurs, Joyce B. J. and van Schoor, Natasja M. and Hooiveld, Guido J. E. J. and de Groot, Lisette C. P. G. M. and Kampman, Ellen and Steegenga, Wilma T.},
	year = {2015},
	pmid = {26568774},
	pmcid = {PMC4644301},
	keywords = {B-vitamins, Cancer, DNA methylation, Development, Elderly, Epigenetics, Folic acid, Infinium 450k BeadChip, Intervention trial, One-carbon metabolism, Vitamin B12},
	pages = {121},
}

@article{chu_epigenome-wide_2017,
	title = {Epigenome-wide association studies identify {DNA} methylation associated with kidney function},
	volume = {8},
	issn = {2041-1723},
	doi = {10.1038/s41467-017-01297-7},
	abstract = {Chronic kidney disease (CKD) is defined by reduced estimated glomerular filtration rate (eGFR). Previous genetic studies have implicated regulatory mechanisms contributing to CKD. Here we present epigenome-wide association studies of eGFR and CKD using whole-blood DNA methylation of 2264 ARIC Study and 2595 Framingham Heart Study participants to identify epigenetic signatures of kidney function. Of 19 CpG sites significantly associated (P {\textless} 1e-07) with eGFR/CKD and replicated, five also associate with renal fibrosis in biopsies from CKD patients and show concordant DNA methylation changes in kidney cortex. Lead CpGs at PTPN6/PHB2, ANKRD11, and TNRC18 map to active enhancers in kidney cortex. At PTPN6/PHB2 cg19942083, methylation in kidney cortex associates with lower renal PTPN6 expression, higher eGFR, and less renal fibrosis. The regions containing the 243 eGFR-associated (P {\textless} 1e-05) CpGs are significantly enriched for transcription factor binding sites of EBF1, EP300, and CEBPB (P {\textless} 5e-6). Our findings highlight kidney function associated epigenetic variation.},
	language = {eng},
	number = {1},
	journal = {Nature Communications},
	author = {Chu, Audrey Y. and Tin, Adrienne and Schlosser, Pascal and Ko, Yi-An and Qiu, Chengxiang and Yao, Chen and Joehanes, Roby and Grams, Morgan E. and Liang, Liming and Gluck, Caroline A. and Liu, Chunyu and Coresh, Josef and Hwang, Shih-Jen and Levy, Daniel and Boerwinkle, Eric and Pankow, James S. and Yang, Qiong and Fornage, Myriam and Fox, Caroline S. and Susztak, Katalin and Köttgen, Anna},
	year = {2017},
	pmid = {29097680},
	pmcid = {PMC5668367},
	keywords = {Aged, Binding Sites, CCAAT-Enhancer-Binding Protein-beta, CpG Islands, DNA Methylation, Disease Progression, E1A-Associated p300 Protein, Epigenesis, Genetic, Female, Genetic Predisposition to Disease, Genome-Wide Association Study, Glomerular Filtration Rate, Humans, Kidney, Male, Middle Aged, Prospective Studies, Protein Tyrosine Phosphatase, Non-Receptor Type 6, Renal Insufficiency, Chronic, Trans-Activators, Transcription Factors},
	pages = {1286},
}

@article{north_blood_2018,
	title = {Blood and nasal epigenetics correlate with allergic rhinitis symptom development in the environmental exposure unit},
	volume = {73},
	issn = {1398-9995},
	doi = {10.1111/all.13263},
	abstract = {BACKGROUND: Epigenetic alterations may represent new therapeutic targets and/or biomarkers of allergic rhinitis (AR). Our aim was to examine genome-wide epigenetic changes induced by controlled pollen exposure in the environmental exposure unit (EEU).
METHODS: 38 AR sufferers and eight nonallergic controls were exposed to grass pollen for 3 hours on two consecutive days. We interrogated DNA methylation at baseline and 3 hours in peripheral blood mononuclear cells (PBMCs) using the Infinium Methylation 450K array. We corrected for demographics, cell composition, and multiple testing (Benjamini-Hochberg) and verified hits using bisulfite PCR pyrosequencing and qPCR. To extend these findings to a clinically relevant tissue, we investigated DNA methylation and gene expression of mucin 4 (MUC4), in nasal brushings from a separate validation cohort exposed to birch pollen.
RESULTS: In PBMCs of allergic rhinitis participants, 42 sites showed significant DNA methylation changes of 2\% or greater. DNA methylation changes in tryptase gamma 1 (TPSG1), schlafen 12 (SLFN12), and MUC4 in response to exposure were validated by pyrosequencing. SLFN12 DNA methylation significantly correlated with symptoms (P {\textless} 0.05), and baseline DNA methylation pattern was found to be predictive of symptom severity upon grass allergen exposure (P = 0.029). Changes in MUC4 DNA methylation in nasal brushings in the validation cohort correlated with drop in peak nasal inspiratory flow (Spearman's r = 0.314, P = 0.034), and MUC4 gene expression was significantly increased (P {\textless} 0.0001).
CONCLUSION: This study revealed novel and rapid epigenetic changes upon exposure in a controlled allergen challenge facility, and identified baseline epigenetic status as a predictor of symptom severity.},
	language = {eng},
	number = {1},
	journal = {Allergy},
	author = {North, M. L. and Jones, M. J. and MacIsaac, J. L. and Morin, A. M. and Steacy, L. M. and Gregor, A. and Kobor, M. S. and Ellis, A. K.},
	month = jan,
	year = {2018},
	pmid = {28755526},
	keywords = {Adolescent, Adult, Aged, Biomarkers, Carrier Proteins, CpG Islands, DNA Methylation, Disease Susceptibility, Environmental Exposure, Epigenesis, Genetic, Epigenomics, Female, Gene Expression Profiling, Humans, Lymphocytes, Male, Middle Aged, Mucin-4, Nasal Mucosa, Pollen, Rhinitis, Allergic, Rhinitis, Allergic, Seasonal, Symptom Assessment, Young Adult, allergen challenge, allergic rhinitis, environmental exposure unit, epigenetics, pollen},
	pages = {196--205},
}

@article{mcginnis_using_2019,
	title = {Using {DNA} methylation to validate an electronic medical record phenotype for smoking},
	volume = {24},
	issn = {1369-1600},
	doi = {10.1111/adb.12670},
	abstract = {A validated, scalable approach to characterizing (phenotyping) smoking status is needed to facilitate genetic discovery. Using established DNA methylation sites from blood samples as a criterion standard for smoking behavior, we compare three candidate electronic medical record (EMR) smoking metrics based on longitudinal EMR text notes. With data from the Veterans Aging Cohort Study (VACS), we employed a validated algorithm to translate each smoking-related text note into current, past or never categories. We compared three alternative summary characterizations of smoking: most recent, modal and trajectories using descriptive statistics and Spearman's correlation coefficients. Logistic regression and area under the curve analyses were used to compare the associations of these phenotypes with the DNA methylation sites, cg05575921 and cg03636183, which are known to have strong associations with current smoking. DNA methylation data were available from the VACS Biomarker Cohort (VACS-BC), a sub-study of VACS. We also considered whether the associations differed by the certainty of trajectory group assignment ({\textless}0.80/≥0.80). Among 140 152 VACS participants, EMR summary smoking phenotypes varied in frequency by the metric chosen: current from 33 to 53 percent; past from 16 to 24 percent and never from 24 to 33 percent. The association between the EMR smoking pairs was highest for modal and trajectories (rho = 0.89). Among 728 individuals in the VACS-BC, both DNA methylation sites were associated with all three EMR summary metrics (p {\textless} 0.001), but the strongest association with both methylation sites was observed for trajectories (p {\textless} 0.001). Longitudinal EMR smoking data support using a summary phenotype, the validity of which is enhanced when data are integrated into statistical trajectories.},
	language = {eng},
	number = {5},
	journal = {Addiction Biology},
	author = {McGinnis, Kathleen A. and Justice, Amy C. and Tate, Janet P. and Kranzler, Henry R. and Tindle, Hilary A. and Becker, William C. and Concato, John and Gelernter, Joel and Li, Boyang and Zhang, Xinyu and Zhao, Hongyu and Crothers, Kristina and Xu, Ke and {VACS Project Group}},
	year = {2019},
	pmid = {30284751},
	pmcid = {PMC6541538},
	keywords = {DNA Methylation, DNA methylation, EMR smoking, Electronic Health Records, Female, Humans, Male, Middle Aged, Phenotype, Reproducibility of Results, Self Report, Smoking, Veterans, smoking methylation},
	pages = {1056--1065},
}

@article{liang_dna_2020,
	title = {{DNA} methylation signature on phosphatidylethanol, not on self-reported alcohol consumption, predicts hazardous alcohol consumption in two distinct populations},
	copyright = {2020 The Author(s)},
	issn = {1476-5578},
	url = {https://www.nature.com/articles/s41380-020-0668-x},
	doi = {10.1038/s41380-020-0668-x},
	abstract = {The process of diagnosing hazardous alcohol drinking (HAD) is based on self-reported data and is thereby vulnerable to bias. There has been an interest in developing epigenetic biomarkers for HAD that might complement clinical assessment. Because alcohol consumption has been previously linked to DNA methylation (DNAm), we aimed to select DNAm signatures in blood to predict HAD from two demographically and clinically distinct populations (Ntotal = 1,549). We first separately conducted an epigenome-wide association study (EWAS) for phosphatidylethanol (PEth), an objective measure of alcohol consumption, and for self-reported alcohol consumption in Cohort 1. We identified 83 PEth-associated CpGs, including 23 CpGs previously associated with alcohol consumption or alcohol use disorder. In contrast, no CpG reached epigenome-wide significance on self-reported alcohol consumption. Using a machine learning approach, two CpG subsets from EWAS on PEth and on self-reported alcohol consumption from Cohort 1 were separately tested for the prediction of HAD in Cohort 2. We found that a subset of 143 CpGs selected from the EWAS on PEth showed an excellent prediction of HAD with the area under the receiver operating characteristic curve (AUC) of 89.4\% in training set and 73.9\% in validation set of Cohort 2. However, CpGs preselected from the EWAS on self-reported alcohol consumption showed a poor prediction of HAD with AUC 75.2\% in training set and 57.6\% in validation set. Our results demonstrate that an objective measure for alcohol consumption is a more informative phenotype than self-reported data for revealing epigenetic mechanisms. The PEth-associated DNAm signature in blood could serve as a robust biomarker for alcohol consumption.},
	language = {en},
	urldate = {2020-09-07},
	journal = {Molecular Psychiatry},
	author = {Liang, Xiaoyu and Justice, Amy C. and So-Armah, Kaku and Krystal, John H. and Sinha, Rajita and Xu, Ke},
	month = feb,
	year = {2020},
	note = {Publisher: Nature Publishing Group},
	pages = {1--16},
}

@article{wahl_epigenome-wide_2017,
	title = {Epigenome-wide association study of body mass index, and the adverse outcomes of adiposity},
	volume = {541},
	copyright = {2016 Macmillan Publishers Limited, part of Springer Nature. All rights reserved.},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature20784},
	doi = {10.1038/nature20784},
	abstract = {A large-scale epigenome-wide association study identifies changes in DNA methylation associated with body mass index in blood and adipose tissue, and correlates DNA methylation sites with high risk of incident type 2 diabetes.},
	language = {en},
	number = {7635},
	urldate = {2020-09-05},
	journal = {Nature},
	author = {Wahl, Simone and Drong, Alexander and Lehne, Benjamin and Loh, Marie and Scott, William R. and Kunze, Sonja and Tsai, Pei-Chien and Ried, Janina S. and Zhang, Weihua and Yang, Youwen and Tan, Sili and Fiorito, Giovanni and Franke, Lude and Guarrera, Simonetta and Kasela, Silva and Kriebel, Jennifer and Richmond, Rebecca C. and Adamo, Marco and Afzal, Uzma and Ala-Korpela, Mika and Albetti, Benedetta and Ammerpohl, Ole and Apperley, Jane F. and Beekman, Marian and Bertazzi, Pier Alberto and Black, S. Lucas and Blancher, Christine and Bonder, Marc-Jan and Brosch, Mario and Carstensen-Kirberg, Maren and de Craen, Anton J. M. and de Lusignan, Simon and Dehghan, Abbas and Elkalaawy, Mohamed and Fischer, Krista and Franco, Oscar H. and Gaunt, Tom R. and Hampe, Jochen and Hashemi, Majid and Isaacs, Aaron and Jenkinson, Andrew and Jha, Sujeet and Kato, Norihiro and Krogh, Vittorio and Laffan, Michael and Meisinger, Christa and Meitinger, Thomas and Mok, Zuan Yu and Motta, Valeria and Ng, Hong Kiat and Nikolakopoulou, Zacharoula and Nteliopoulos, Georgios and Panico, Salvatore and Pervjakova, Natalia and Prokisch, Holger and Rathmann, Wolfgang and Roden, Michael and Rota, Federica and Rozario, Michelle Ann and Sandling, Johanna K. and Schafmayer, Clemens and Schramm, Katharina and Siebert, Reiner and Slagboom, P. Eline and Soininen, Pasi and Stolk, Lisette and Strauch, Konstantin and Tai, E.-Shyong and Tarantini, Letizia and Thorand, Barbara and Tigchelaar, Ettje F. and Tumino, Rosario and Uitterlinden, Andre G. and van Duijn, Cornelia and van Meurs, Joyce B. J. and Vineis, Paolo and Wickremasinghe, Ananda Rajitha and Wijmenga, Cisca and Yang, Tsun-Po and Yuan, Wei and Zhernakova, Alexandra and Batterham, Rachel L. and Smith, George Davey and Deloukas, Panos and Heijmans, Bastiaan T. and Herder, Christian and Hofman, Albert and Lindgren, Cecilia M. and Milani, Lili and van der Harst, Pim and Peters, Annette and Illig, Thomas and Relton, Caroline L. and Waldenberger, Melanie and Järvelin, Marjo-Riitta and Bollati, Valentina and Soong, Richie and Spector, Tim D. and Scott, James and McCarthy, Mark I. and Elliott, Paul and Bell, Jordana T. and Matullo, Giuseppe and Gieger, Christian and Kooner, Jaspal S. and Grallert, Harald and Chambers, John C.},
	month = jan,
	year = {2017},
	note = {Number: 7635
Publisher: Nature Publishing Group},
	pages = {81--86},
}

@article{lohoff_epigenome-wide_2020,
	title = {Epigenome-wide association study and multi-tissue replication of individuals with alcohol use disorder: evidence for abnormal glucocorticoid signaling pathway gene regulation},
	copyright = {2020 This is a U.S. government work and not under copyright protection in the U.S.; foreign copyright protection may apply},
	issn = {1476-5578},
	shorttitle = {Epigenome-wide association study and multi-tissue replication of individuals with alcohol use disorder},
	url = {https://www.nature.com/articles/s41380-020-0734-4},
	doi = {10.1038/s41380-020-0734-4},
	abstract = {Alcohol use disorder (AUD) is a chronic debilitating disorder with limited treatment options and poorly defined pathophysiology. There are substantial genetic and epigenetic components; however, the underlying mechanisms contributing to AUD remain largely unknown. We conducted the largest DNA methylation epigenome-wide association study (EWAS) analyses currently available for AUD (total N = 625) and employed a top hit replication (N = 4798) using a cross-tissue/cross-phenotypic approach with the goal of identifying novel epigenetic targets relevant to AUD. Results show that a network of differentially methylated regions in glucocorticoid signaling and inflammation-related genes were associated with alcohol use behaviors. A top probe consistently associated across all cohorts was located in the long non-coding RNA growth arrest specific five gene (GAS5) (p {\textless} 10−24). GAS5 has been implicated in regulating transcriptional activity of the glucocorticoid receptor and has multiple functions related to apoptosis, immune function and various cancers. Endophenotypic analyses using peripheral cortisol levels and neuroimaging paradigms showed that methylomic variation in GAS5 network-related probes were associated with stress phenotypes. Postmortem brain analyses documented increased GAS5 expression in the amygdala of individuals with AUD. Our data suggest that alcohol use is associated with differential methylation in the glucocorticoid system that might influence stress and inflammatory reactivity and subsequently risk for AUD.},
	language = {en},
	urldate = {2020-09-05},
	journal = {Molecular Psychiatry},
	author = {Lohoff, Falk W. and Roy, Arunima and Jung, Jeesun and Longley, Martha and Rosoff, Daniel B. and Luo, Audrey and O’Connell, Emma and Sorcher, Jill L. and Sun, Hui and Schwandt, Melanie and Hodgkinson, Colin A. and Goldman, David and Momenan, Reza and McIntosh, Andrew M. and Adams, Mark J. and Walker, Rosie M. and Evans, Kathryn L. and Porteous, David and Smith, Alicia K. and Lee, Jisoo and Muench, Christine and Charlet, Katrin and Clarke, Toni-Kim and Kaminsky, Zachary A.},
	month = may,
	year = {2020},
	note = {Publisher: Nature Publishing Group},
	pages = {1--14},
}

@article{webb_relationship_2020,
	title = {The {Relationship} between {DNA} {Methylation} and {Antidepressant} {Medications}: {A} {Systematic} {Review}},
	volume = {21},
	issn = {1422-0067},
	shorttitle = {The {Relationship} between {DNA} {Methylation} and {Antidepressant} {Medications}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7037192/},
	doi = {10.3390/ijms21030826},
	abstract = {Major depressive disorder (MDD) is the leading cause of disability worldwide and is associated with high rates of suicide and medical comorbidities. Current antidepressant medications are suboptimal, as most MDD patients fail to achieve complete remission from symptoms. At present, clinicians are unable to predict which antidepressant is most effective for a particular patient, exposing patients to multiple medication trials and side effects. Since MDD’s etiology includes interactions between genes and environment, the epigenome is of interest for predictive utility and treatment monitoring. Epigenetic mechanisms of antidepressant medications are incompletely understood. Differences in epigenetic profiles may impact treatment response. A systematic literature search yielded 24 studies reporting the interaction between antidepressants and eight genes (BDNF, MAOA, SLC6A2, SLC6A4, HTR1A, HTR1B, IL6, IL11) and whole genome methylation. Methylation of certain sites within BDNF, SLC6A4, HTR1A, HTR1B, IL11, and the whole genome was predictive of antidepressant response. Comparing DNA methylation in patients during depressive episodes, during treatment, in remission, and after antidepressant cessation would help clarify the influence of antidepressant medications on DNA methylation. Individuals’ unique methylation profiles may be used clinically for personalization of antidepressant choice in the future.},
	number = {3},
	urldate = {2020-09-05},
	journal = {International Journal of Molecular Sciences},
	author = {Webb, Lauren M. and Phillips, Kathryn E. and Ho, Man Choi and Veldic, Marin and Blacker, Caren J.},
	month = jan,
	year = {2020},
	pmid = {32012861},
	pmcid = {PMC7037192},
}

@article{luo_when_2020,
	title = {When causal inference meets deep learning},
	volume = {2},
	copyright = {2020 Springer Nature Limited},
	issn = {2522-5839},
	url = {https://www.nature.com/articles/s42256-020-0218-x},
	doi = {10.1038/s42256-020-0218-x},
	abstract = {Bayesian networks can capture causal relations, but learning such a network from data is NP-hard. Recent work has made it possible to approximate this problem as a continuous optimization task that can be solved efficiently with well-established numerical techniques.},
	language = {en},
	number = {8},
	urldate = {2020-08-13},
	journal = {Nature Machine Intelligence},
	author = {Luo, Yunan and Peng, Jian and Ma, Jianzhu},
	month = aug,
	year = {2020},
	note = {Number: 8
Publisher: Nature Publishing Group},
	pages = {426--427},
}

@article{churpek_internal_2020,
	title = {Internal and {External} {Validation} of a {Machine} {Learning} {Risk} {Score} for {Acute} {Kidney} {Injury}},
	volume = {3},
	url = {https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2769146},
	doi = {10.1001/jamanetworkopen.2020.12892},
	abstract = {{\textless}h3{\textgreater}Importance{\textless}/h3{\textgreater}{\textless}p{\textgreater}Acute kidney injury (AKI) is associated with increased morbidity and mortality in hospitalized patients. Current methods to identify patients at high risk of AKI are limited, and few prediction models have been externally validated.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Objective{\textless}/h3{\textgreater}{\textless}p{\textgreater}To internally and externally validate a machine learning risk score to detect AKI in hospitalized patients.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Design, Setting, and Participants{\textless}/h3{\textgreater}{\textless}p{\textgreater}This diagnostic study included 495 971 adult hospital admissions at the University of Chicago (UC) from 2008 to 2016 (n = 48 463), at Loyola University Medical Center (LUMC) from 2007 to 2017 (n = 200 613), and at NorthShore University Health System (NUS) from 2006 to 2016 (n = 246 895) with serum creatinine (SCr) measurements. Patients with an SCr concentration at admission greater than 3.0 mg/dL, with a prior diagnostic code for chronic kidney disease stage 4 or higher, or who received kidney replacement therapy within 48 hours of admission were excluded. A simplified version of a previously published gradient boosted machine AKI prediction algorithm was used; it was validated internally among patients at UC and externally among patients at NUS and LUMC.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Main Outcomes and Measures{\textless}/h3{\textgreater}{\textless}p{\textgreater}Prediction of Kidney Disease Improving Global Outcomes SCr-defined stage 2 AKI within a 48-hour interval was the primary outcome. Discrimination was assessed by the area under the receiver operating characteristic curve (AUC).{\textless}/p{\textgreater}{\textless}h3{\textgreater}Results{\textless}/h3{\textgreater}{\textless}p{\textgreater}The study included 495 971 adult admissions (mean [SD] age, 63 [18] years; 87 689 [17.7\%] African American; and 266 866 [53.8\%] women) across 3 health systems. The development of stage 2 or higher AKI occurred in 15 664 of 48 463 patients (3.4\%) in the UC cohort, 5711 of 200 613 (2.8\%) in the LUMC cohort, and 3499 of 246 895 (1.4\%) in the NUS cohort. In the UC cohort, 332 patients (0.7\%) required kidney replacement therapy compared with 672 patients (0.3\%) in the LUMC cohort and 440 patients (0.2\%) in the NUS cohort. The AUCs for predicting at least stage 2 AKI in the next 48 hours were 0.86 (95\% CI, 0.86-0.86) in the UC cohort, 0.85 (95\% CI, 0.84-0.85) in the LUMC cohort, and 0.86 (95\% CI, 0.86-0.86) in the NUS cohort. The AUCs for receipt of kidney replacement therapy within 48 hours were 0.96 (95\% CI, 0.96-0.96) in the UC cohort, 0.95 (95\% CI, 0.94-0.95) in the LUMC cohort, and 0.95 (95\% CI, 0.94-0.95) in the NUS cohort. In time-to-event analysis, a probability cutoff of at least 0.057 predicted the onset of stage 2 AKI a median (IQR) of 27 (6.5-93) hours before the eventual doubling in SCr concentrations in the UC cohort, 34.5 (19-85) hours in the NUS cohort, and 39 (19-108) hours in the LUMC cohort.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Conclusions and Relevance{\textless}/h3{\textgreater}{\textless}p{\textgreater}In this study, the machine learning algorithm demonstrated excellent discrimination in both internal and external validation, supporting its generalizability and potential as a clinical decision support tool to improve AKI detection and outcomes.{\textless}/p{\textgreater}},
	language = {en},
	number = {8},
	urldate = {2020-08-12},
	journal = {JAMA Network Open},
	author = {Churpek, Matthew M. and Carey, Kyle A. and Edelson, Dana P. and Singh, Tripti and Astor, Brad C. and Gilbert, Emily R. and Winslow, Christopher and Shah, Nirav and Afshar, Majid and Koyner, Jay L.},
	month = aug,
	year = {2020},
	note = {Publisher: American Medical Association},
	pages = {e2012892--e2012892},
}

@article{richens_improving_2020,
	title = {Improving the accuracy of medical diagnosis with causal machine learning},
	volume = {11},
	copyright = {2020 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-020-17419-7},
	doi = {10.1038/s41467-020-17419-7},
	abstract = {Machine learning promises to revolutionize clinical decision making and diagnosis. In medical diagnosis a doctor aims to explain a patient’s symptoms by determining the diseases causing them. However, existing machine learning approaches to diagnosis are purely associative, identifying diseases that are strongly correlated with a patients symptoms. We show that this inability to disentangle correlation from causation can result in sub-optimal or dangerous diagnoses. To overcome this, we reformulate diagnosis as a counterfactual inference task and derive counterfactual diagnostic algorithms. We compare our counterfactual algorithms to the standard associative algorithm and 44 doctors using a test set of clinical vignettes. While the associative algorithm achieves an accuracy placing in the top 48\% of doctors in our cohort, our counterfactual algorithm places in the top 25\% of doctors, achieving expert clinical accuracy. Our results show that causal reasoning is a vital missing ingredient for applying machine learning to medical diagnosis.},
	language = {en},
	number = {1},
	urldate = {2020-08-11},
	journal = {Nature Communications},
	author = {Richens, Jonathan G. and Lee, Ciarán M. and Johri, Saurabh},
	month = aug,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {3923},
}

@article{chiang_projecting_2020,
	title = {Projecting hospital resource utilization during a surge using parametric bootstrapping},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	issn = {2016-4475},
	url = {https://www.medrxiv.org/content/10.1101/2020.07.30.20164475v1},
	doi = {10.1101/2020.07.30.20164475},
	abstract = {{\textless}p{\textgreater}During the initial wave of the COVID-19 pandemic in the United States, hospitals took drastic action to ensure sufficient capacity, including canceling or postponing elective procedures, expanding the number of available intensive care beds and ventilators, and creating regional overflow hospital capacity. However, in most locations the actual number of patients did not reach the projected surge leaving available, unused hospital capacity. As a result, patients may have delayed needed care and hospitals lost substantial revenue. These initial recommendations were made based on observations and worst-case epidemiological projections, which generally assume a fixed proportion of COVID-19 patients will require hospitalization and advanced resources. This assumption has led to an overestimate of resource demand as clinical protocols improve and testing becomes more widely available throughout the course of the pandemic. Here, we present a parametric bootstrap model for forecasting the resource demands of incoming patients in the near term, and apply it to the current pandemic. We validate our approach using observed cases at UCLA Health and simulate the effect of elective procedure cancellation against worst-case pandemic scenarios. Using our approach, we show that it is unnecessary to cancel elective procedures unless the actual capacity of COVID-19 patients approaches the hospital maximum capacity. Instead, we propose a strategy of balancing the resource demands of elective procedures against projected patients by revisiting the projections regularly to maintain operating efficiency. This strategy has been in place at UCLA Health since mid-April.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-08-07},
	journal = {medRxiv},
	author = {Chiang, Jeffrey N. and An, Ulzee and Kordi, Misagh and Jew, Brandon and Kravit, Clifford and Dunne, William J. and Perez, Ronald and Parikh, Neil R. and Weil, Drew and Azar, Richard F. and Cherry, Robert and Grimley, Karen A. and Skootsky, Samuel A. and Saigal, Christopher E. and Manuel, Vladimir and Eskin, Eleazar and Halperin, Eran},
	month = aug,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory Press},
	pages = {2020.07.30.20164475},
}

@article{bloom_swab-seq_2020,
	title = {Swab-{Seq}: {A} high-throughput platform for massively scaled up {SARS}-{CoV}-2 testing},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	shorttitle = {Swab-{Seq}},
	url = {https://www.medrxiv.org/content/10.1101/2020.08.04.20167874v1},
	doi = {10.1101/2020.08.04.20167874},
	abstract = {{\textless}p{\textgreater}The rapid spread of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) is due to the high rates of transmission by individuals who are asymptomatic at the time of transmission. Frequent, widespread testing of the asymptomatic population for SARS-CoV-2 is essential to suppress viral transmission and is a key element in safely reopening society. Despite increases in testing capacity, multiple challenges remain in deploying traditional reverse transcription and quantitative PCR (RT-qPCR) tests at the scale required for population screening of asymptomatic individuals. We have developed SwabSeq, a high-throughput testing platform for SARS-CoV-2 that uses next-generation sequencing as a readout. SwabSeq employs sample-specific molecular barcodes to enable thousands of samples to be combined and simultaneously analyzed for the presence or absence of SARS-CoV-2 in a single run. Importantly, SwabSeq incorporates an in vitro RNA standard that mimics the viral amplicon, but can be distinguished by sequencing. This standard allows for end-point rather than quantitative PCR, improves quantitation, reduces requirements for automation and sample-to-sample normalization, enables purification-free detection, and gives better ability to call true negatives. We show that SwabSeq can test nasal and oral specimens for SARS-CoV-2 with or without RNA extraction while maintaining analytical sensitivity better than or comparable to that of fluorescence-based RT-qPCR tests. SwabSeq is simple, sensitive, flexible, rapidly scalable, inexpensive enough to test widely and frequently, and can provide a turn around time of 12 to 24 hours.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-08-07},
	journal = {medRxiv},
	author = {Bloom, Joshua S. and Jones, Eric M. and Gasperini, Molly and Lubock, Nathan B. and Sathe, Laila and Munugala, Chetan and Booeshaghi, A. Sina and Brandenberg, Oliver F. and Guo, Longhua and Simpkins, Scott W. and Lin, Isabella and LaPierre, Nathan and Hong, Duke and Zhang, Yi and Oland, Gabriel and Choe, Bianca Judy and Chandrasekaran, Sukantha and Hilt, Evann E. and Butte, Manish J. and Damoiseaux, Robert and Cooper, Aaron R. and Yin, Yi and Pachter, Lior and Garner, Omai B. and Flint, Jonathan and Eskin, Eleazar and Luo, Chongyuan and Kosuri, Sriram and Kruglyak, Leonid and Arboleda, Valerie A.},
	month = aug,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory Press},
	pages = {2020.08.04.20167874},
}

@article{natarajan_central_2017,
	title = {Central {Blood} {Pressure} {Monitoring} via a {Standard} {Automatic} {Arm} {Cuff}},
	volume = {7},
	issn = {2045-2322},
	url = {http://www.nature.com/articles/s41598-017-14844-5},
	doi = {10.1038/s41598-017-14844-5},
	language = {en},
	number = {1},
	urldate = {2020-08-05},
	journal = {Scientific Reports},
	author = {Natarajan, Keerthana and Cheng, Hao-Min and Liu, Jiankun and Gao, Mingwu and Sung, Shih-Hsien and Chen, Chen-Huan and Hahn, Jin-Oh and Mukkamala, Ramakrishna},
	month = dec,
	year = {2017},
	pages = {14441},
}

@article{chandrasekhar_iphone_2018,
	title = {An {iPhone} {Application} for {Blood} {Pressure} {Monitoring} via the {Oscillometric} {Finger} {Pressing} {Method}},
	volume = {8},
	copyright = {2018 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-018-31632-x},
	doi = {10.1038/s41598-018-31632-x},
	abstract = {We developed an iPhone X application to measure blood pressure (BP) via the “oscillometric finger pressing method”. The user presses her fingertip on both the front camera and screen to increase the external pressure of the underlying artery, while the application measures the resulting variable-amplitude blood volume oscillations via the camera and applied pressure via the strain gauge array under the screen. The application also visually guides the fingertip placement and actuation and then computes BP from the measurements just like many automatic cuff devices. We tested the application, along with a finger cuff device, against a standard cuff device. The application yielded bias and precision errors of −4.0 and 11.4 mmHg for systolic BP and −9.4 and 9.7 mmHg for diastolic BP (n = 18). These errors were near the finger cuff device errors. This proof-of-concept study surprisingly indicates that cuff-less and calibration-free BP monitoring may be feasible with many existing and forthcoming smartphones.},
	language = {en},
	number = {1},
	urldate = {2020-08-05},
	journal = {Scientific Reports},
	author = {Chandrasekhar, Anand and Natarajan, Keerthana and Yavarimanesh, Mohammad and Mukkamala, Ramakrishna},
	month = sep,
	year = {2018},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {13136},
}

@article{moghadam_machine-learning_2020,
	title = {A machine-learning approach to predicting hypotensive events in {ICU} settings},
	volume = {118},
	issn = {1879-0534},
	doi = {10.1016/j.compbiomed.2020.103626},
	abstract = {BACKGROUND: Predicting hypotension well in advance provides physicians with enough time to respond with proper therapeutic measures. However, the real-time prediction of hypotension with high positive predictive value (PPV) is a challenge. This is due to the dynamic changes in patients' physiological status following drug administration, which limits the quantity of useful data available for the algorithm.
METHOD: To mimic real-time monitoring, we developed a machine-learning algorithm that uses most of the available data points from patients' records to train and test the algorithm. The algorithm predicts hypotension up to 30 min in advance based on the data from only 5 min of patient physiological history. A novel evaluation method is also proposed to assess the performance of the algorithm as a function of time at every timestamp within 30 min of hypotension onset. This evaluation approach provides statistical tools to find the best possible prediction window.
RESULTS: During about 181,000 min of monitoring of 400 patients, the algorithm demonstrated 94\% accuracy, 85\% sensitivity and 96\% specificity in predicting hypotension within 30 min of the events. A high PPV of 81\% was obtained, and the algorithm predicted 80\% of hypotensive events 25 min prior to onset. It was shown that choosing a classification threshold that maximizes the F1 score during the training phase contributes to a high PPV and sensitivity.
CONCLUSIONS: This study demonstrates the promising potential of machine-learning algorithms in the real-time prediction of hypotensive events in ICU settings based on short-term physiological history.},
	language = {eng},
	journal = {Computers in Biology and Medicine},
	author = {Moghadam, Mina Chookhachizadeh and Abad, Ehsan Masoumi Khalil and Bagherzadeh, Nader and Ramsingh, Davinder and Li, Guann-Pyng and Kain, Zeev N.},
	month = mar,
	year = {2020},
	pmid = {32174328},
	keywords = {Hypotension, ICU, Machine-learning, Prediction, Short-term history},
	pages = {103626},
}

@inproceedings{subbaswamy_preventing_2019,
	title = {Preventing {Failures} {Due} to {Dataset} {Shift}: {Learning} {Predictive} {Models} {That} {Transport}},
	shorttitle = {Preventing {Failures} {Due} to {Dataset} {Shift}},
	url = {http://proceedings.mlr.press/v89/subbaswamy19a.html},
	abstract = {Classical supervised learning produces unreliable models when training and target distributions differ, with most existing solutions requiring samples from the target domain. We propose a proactive...},
	language = {en},
	urldate = {2020-07-28},
	booktitle = {The 22nd {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
	author = {Subbaswamy, Adarsh and Schulam, Peter and Saria, Suchi},
	month = apr,
	year = {2019},
	note = {ISSN: 1938-7228
Section: Machine Learning},
	pages = {3118--3127},
}

@article{hahn_bayesian_2020,
	title = {Bayesian {Regression} {Tree} {Models} for {Causal} {Inference}: {Regularization}, {Confounding}, and {Heterogeneous} {Effects}},
	issn = {1936-0975, 1931-6690},
	shorttitle = {Bayesian {Regression} {Tree} {Models} for {Causal} {Inference}},
	url = {https://projecteuclid.org/euclid.ba/1580461461},
	doi = {10.1214/19-BA1195},
	abstract = {This paper presents a novel nonlinear regression model for estimating heterogeneous treatment effects, geared specifically towards situations with small effect sizes, heterogeneous effects, and strong confounding by observables. Standard nonlinear regression models, which may work quite well for prediction, have two notable weaknesses when used to estimate heterogeneous treatment effects. First, they can yield badly biased estimates of treatment effects when fit to data with strong confounding. The Bayesian causal forest model presented in this paper avoids this problem by directly incorporating an estimate of the propensity function in the specification of the response model, implicitly inducing a covariate-dependent prior on the regression function. Second, standard approaches to response surface modeling do not provide adequate control over the strength of regularization over effect heterogeneity. The Bayesian causal forest model permits treatment effect heterogeneity to be regularized separately from the prognostic effect of control variables, making it possible to informatively “shrink to homogeneity”. While we focus on observational data, our methods are equally useful for inferring heterogeneous treatment effects from randomized controlled experiments where careful regularization is somewhat less complicated but no less important. We illustrate these benefits via the reanalysis of an observational study assessing the causal effects of smoking on medical expenditures as well as extensive simulation studies.},
	language = {EN},
	urldate = {2020-07-28},
	journal = {Bayesian Analysis},
	author = {Hahn, P. Richard and Murray, Jared S. and Carvalho, Carlos M.},
	year = {2020},
	note = {Publisher: International Society for Bayesian Analysis},
	keywords = {Bayesian, causal inference, heterogeneous treatment effects, machine learning, predictor-dependent priors, regression trees, regularization, shrinkage},
}

@article{rosenbaum_central_1983,
	title = {The central role of the propensity score in observational studies for causal effects},
	volume = {70},
	issn = {0006-3444},
	url = {https://academic.oup.com/biomet/article/70/1/41/240879},
	doi = {10.1093/biomet/70.1.41},
	abstract = {Abstract.  The propensity score is the conditional probability of assignment to a particular treatment given a vector of observed covariates. Both large and sma},
	language = {en},
	number = {1},
	urldate = {2020-07-28},
	journal = {Biometrika},
	author = {Rosenbaum, Paul R. and Rubin, Donald B.},
	month = apr,
	year = {1983},
	note = {Publisher: Oxford Academic},
	pages = {41--55},
}

@article{hernan_using_2016,
	title = {Using {Big} {Data} to {Emulate} a {Target} {Trial} {When} a {Randomized} {Trial} {Is} {Not} {Available}},
	volume = {183},
	issn = {0002-9262},
	url = {https://academic.oup.com/aje/article/183/8/758/1739860},
	doi = {10.1093/aje/kwv254},
	abstract = {Abstract.  Ideally, questions about comparative effectiveness or safety would be answered using an appropriately designed and conducted randomized experiment. W},
	language = {en},
	number = {8},
	urldate = {2020-07-28},
	journal = {American Journal of Epidemiology},
	author = {Hernán, Miguel A. and Robins, James M.},
	month = apr,
	year = {2016},
	note = {Publisher: Oxford Academic},
	pages = {758--764},
}

@inproceedings{jin_regret_2018,
	title = {Regret {Minimization} for {Partially} {Observable} {Deep} {Reinforcement} {Learning}},
	url = {http://proceedings.mlr.press/v80/jin18c.html},
	abstract = {Deep reinforcement learning algorithms that estimate state and state-action value functions have been shown to be effective in a variety of challenging domains, including learning control strategie...},
	language = {en},
	urldate = {2020-07-28},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Jin, Peter and Keutzer, Kurt and Levine, Sergey},
	month = jul,
	year = {2018},
	note = {ISSN: 1938-7228
Section: Machine Learning},
	pages = {2342--2351},
}

@article{morrison_mendelian_2020,
	title = {Mendelian randomization accounting for correlated and uncorrelated pleiotropic effects using genome-wide summary statistics},
	volume = {52},
	copyright = {2020 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-1718},
	url = {https://www.nature.com/articles/s41588-020-0631-4},
	doi = {10.1038/s41588-020-0631-4},
	abstract = {Mendelian randomization (MR) is a valuable tool for detecting causal effects by using genetic variant associations. Opportunities to apply MR are growing rapidly with the increasing number of genome-wide association studies (GWAS). However, existing MR methods rely on strong assumptions that are often violated, leading to false positives. Correlated horizontal pleiotropy, which arises when variants affect both traits through a heritable shared factor, remains a particularly challenging problem. We propose a new MR method, Causal Analysis Using Summary Effect estimates (CAUSE), that accounts for correlated and uncorrelated horizontal pleiotropic effects. We demonstrate, in simulations, that CAUSE avoids more false positives induced by correlated horizontal pleiotropy than other methods. Applied to traits studied in recent GWAS studies, we find that CAUSE detects causal relationships that have strong literature support and avoids identifying most unlikely relationships. Our results suggest that shared heritable factors are common and may lead to many false positives using alternative methods.},
	language = {en},
	number = {7},
	urldate = {2020-07-28},
	journal = {Nature Genetics},
	author = {Morrison, Jean and Knoblauch, Nicholas and Marcus, Joseph H. and Stephens, Matthew and He, Xin},
	month = jul,
	year = {2020},
	note = {Number: 7
Publisher: Nature Publishing Group},
	pages = {740--747},
}

@article{prosperi_causal_2020,
	title = {Causal inference and counterfactual prediction in machine learning for actionable healthcare},
	volume = {2},
	copyright = {2020 Springer Nature Limited},
	issn = {2522-5839},
	url = {https://www.nature.com/articles/s42256-020-0197-y},
	doi = {10.1038/s42256-020-0197-y},
	abstract = {Big data, high-performance computing, and (deep) machine learning are increasingly becoming key to precision medicine—from identifying disease risks and taking preventive measures, to making diagnoses and personalizing treatment for individuals. Precision medicine, however, is not only about predicting risks and outcomes, but also about weighing interventions. Interventional clinical predictive models require the correct specification of cause and effect, and the calculation of so-called counterfactuals, that is, alternative scenarios. In biomedical research, observational studies are commonly affected by confounding and selection bias. Without robust assumptions, often requiring a priori domain knowledge, causal inference is not feasible. Data-driven prediction models are often mistakenly used to draw causal effects, but neither their parameters nor their predictions necessarily have a causal interpretation. Therefore, the premise that data-driven prediction models lead to trustable decisions/interventions for precision medicine is questionable. When pursuing intervention modelling, the bio-health informatics community needs to employ causal approaches and learn causal structures. Here we discuss how target trials (algorithmic emulation of randomized studies), transportability (the licence to transfer causal effects from one population to another) and prediction invariance (where a true causal model is contained in the set of all prediction models whose accuracy does not vary across different settings) are linchpins to developing and testing intervention models.},
	language = {en},
	number = {7},
	urldate = {2020-07-28},
	journal = {Nature Machine Intelligence},
	author = {Prosperi, Mattia and Guo, Yi and Sperrin, Matt and Koopman, James S. and Min, Jae S. and He, Xing and Rich, Shannan and Wang, Mo and Buchan, Iain E. and Bian, Jiang},
	month = jul,
	year = {2020},
	note = {Number: 7
Publisher: Nature Publishing Group},
	pages = {369--375},
}

@article{taylor_outcome_2020,
	title = {Outcome measures based on digital health technology sensor data: data- and patient-centric approaches},
	volume = {3},
	copyright = {2020 The Author(s)},
	issn = {2398-6352},
	shorttitle = {Outcome measures based on digital health technology sensor data},
	url = {https://www.nature.com/articles/s41746-020-0305-8},
	doi = {10.1038/s41746-020-0305-8},
	abstract = {Digital health technology tools (DHTT) are technologies such as apps, smartphones, and wearables that remotely acquire health-related information from individuals. They have the potential advantages of objectivity and sensitivity of measurement, richness of high-frequency sensor data, and opportunity for passive collection of health-related data. Thus, DHTTs promise to provide patient phenotyping at an order of granularity several times greater than is possible with traditional clinical research tools. While the conceptual development of novel DHTTs is keeping pace with technological and analytical advancements, an as yet unaddressed gap is how to develop robust and meaningful outcome measures based on sensor data. Here, we describe two roadmaps which were developed to generate outcome measures based on DHTT data: one using a data-centric approach and the second a patient-centric approach. The data-centric approach to develop digital outcome measures summarizes those sensor features maximally sensitive to the concept of interest, exemplified with the quantification of disease progression. The patient-centric approach summarizes those sensor features that are optimally relevant to patients’ functioning in everyday life. Both roadmaps are exemplified for use in tracking disease progression in observational and clinical interventional studies, and with a DHTT designed to evaluate motor symptom severity and symptom experience in Parkinson’s disease. Use cases other than disease progression (e.g., case-finding) are considered summarily. DHTT research requires methods to summarize sensor data into meaningful outcome measures. It is hoped that the concepts outlined here will encourage a scientific discourse and eventual consensus on the creation of novel digital outcome measures for both basic clinical research and clinical drug development.},
	language = {en},
	number = {1},
	urldate = {2020-07-28},
	journal = {npj Digital Medicine},
	author = {Taylor, Kirsten I. and Staunton, Hannah and Lipsmeier, Florian and Nobbs, David and Lindemann, Michael},
	month = jul,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {1--8},
}

@article{sharma_wearable_2020,
	title = {Wearable radio-frequency sensing of respiratory rate, respiratory volume, and heart rate},
	volume = {3},
	copyright = {2020 The Author(s)},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-020-0307-6},
	doi = {10.1038/s41746-020-0307-6},
	abstract = {Many health diagnostic systems demand noninvasive sensing of respiratory rate, respiratory volume, and heart rate with high user comfort. Previous methods often require multiple sensors, including skin-touch electrodes, tension belts, or nearby off-the-body readers, and hence are uncomfortable or inconvenient. This paper presents an over-clothing wearable radio-frequency sensor study, conducted on 20 healthy participants (14 females) performing voluntary breathing exercises in various postures. Two prototype sensors were placed on the participants, one close to the heart and the other below the xiphoid process to couple to the motion from heart, lungs and diaphragm, by the near-field coherent sensing principle. We can achieve a satisfactory correlation of our sensor with the reference devices for the three vital signs: heart rate (r = 0.95), respiratory rate (r = 0.93) and respiratory volume (r = 0.84). We also detected voluntary breath-hold periods with an accuracy of 96\%. Further, the participants performed a breathing exercise by contracting abdomen inwards while holding breath, leading to paradoxical outward thorax motion under the isovolumetric condition, which was detected with an accuracy of 83\%.},
	language = {en},
	number = {1},
	urldate = {2020-07-28},
	journal = {npj Digital Medicine},
	author = {Sharma, Pragya and Hui, Xiaonan and Zhou, Jianlin and Conroy, Thomas B. and Kan, Edwin C.},
	month = jul,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {1--10},
}

@article{landi_deep_2020,
	title = {Deep representation learning of electronic health records to unlock patient stratification at scale},
	volume = {3},
	copyright = {2020 The Author(s)},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-020-0301-z},
	doi = {10.1038/s41746-020-0301-z},
	abstract = {Deriving disease subtypes from electronic health records (EHRs) can guide next-generation personalized medicine. However, challenges in summarizing and representing patient data prevent widespread practice of scalable EHR-based stratification analysis. Here we present an unsupervised framework based on deep learning to process heterogeneous EHRs and derive patient representations that can efficiently and effectively enable patient stratification at scale. We considered EHRs of 1,608,741 patients from a diverse hospital cohort comprising a total of 57,464 clinical concepts. We introduce a representation learning model based on word embeddings, convolutional neural networks, and autoencoders (i.e., ConvAE) to transform patient trajectories into low-dimensional latent vectors. We evaluated these representations as broadly enabling patient stratification by applying hierarchical clustering to different multi-disease and disease-specific patient cohorts. ConvAE significantly outperformed several baselines in a clustering task to identify patients with different complex conditions, with 2.61 entropy and 0.31 purity average scores. When applied to stratify patients within a certain condition, ConvAE led to various clinically relevant subtypes for different disorders, including type 2 diabetes, Parkinson’s disease, and Alzheimer’s disease, largely related to comorbidities, disease progression, and symptom severity. With these results, we demonstrate that ConvAE can generate patient representations that lead to clinically meaningful insights. This scalable framework can help better understand varying etiologies in heterogeneous sub-populations and unlock patterns for EHR-based research in the realm of personalized medicine.},
	language = {en},
	number = {1},
	urldate = {2020-07-28},
	journal = {npj Digital Medicine},
	author = {Landi, Isotta and Glicksberg, Benjamin S. and Lee, Hao-Chih and Cherng, Sarah and Landi, Giulia and Danieletto, Matteo and Dudley, Joel T. and Furlanello, Cesare and Miotto, Riccardo},
	month = jul,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {1--11},
}

@article{mastakouri_necessary_2020,
	title = {Necessary and sufficient conditions for causal feature selection in time series with latent common causes},
	url = {http://arxiv.org/abs/2005.08543},
	abstract = {We study the identification of direct and indirect causes on time series and provide necessary and sufficient conditions in the presence of latent variables. Our theoretical results and estimation algorithms require two conditional independence tests for each observed candidate time series to determine whether or not it is a cause of an observed target time series. We provide experimental results in simulations, where the ground truth is known, as well as in real data. Our results show that our method leads to essentially no false positives and relatively low false negative rates, even in confounded environments with non-unique lag effects, outperforming the widely used Granger causality and two more methods.},
	urldate = {2020-07-28},
	journal = {arXiv:2005.08543 [stat]},
	author = {Mastakouri, Atalanti A. and Schölkopf, Bernhard and Janzing, Dominik},
	month = jun,
	year = {2020},
	note = {arXiv: 2005.08543},
	keywords = {Statistics - Machine Learning, Statistics - Methodology},
}

@article{mastakouri_causal_2020,
	title = {Causal analysis of {Covid}-19 spread in {Germany}},
	url = {http://arxiv.org/abs/2007.11896},
	abstract = {In this work, we study the causal relations among German regions in terms of the spread of Covid-19 since the beginning of the pandemic, taking into account the restriction policies that were applied by the different federal states. We propose and prove a new theorem for a causal feature selection method for time series data, robust to latent confounders, which we subsequently apply on Covid-19 case numbers. We present findings about the spread of the virus in Germany and the causal impact of restriction measures, discussing the role of various policies in containing the spread. Since our results are based on rather limited target time series (only the numbers of reported cases), care should be exercised in interpreting them. However, it is encouraging that already such limited data seems to contain causal signals. This suggests that as more data becomes available, our causal approach may contribute towards meaningful causal analysis of political interventions on the development of Covid-19, and thus also towards the development of rational and data-driven methodologies for choosing interventions.},
	urldate = {2020-07-28},
	journal = {arXiv:2007.11896 [stat]},
	author = {Mastakouri, Atalanti A. and Schölkopf, Bernhard},
	month = jul,
	year = {2020},
	note = {arXiv: 2007.11896},
	keywords = {Statistics - Applications},
}

@article{briegel_clinical_2020,
	title = {Clinical {Evaluation} of a {High}-fidelity {Upper} {Arm} {Cuff} to {Measure} {Arterial} {Blood} {Pressure} during {Noncardiac} {Surgery}},
	issn = {0003-3022},
	url = {https://anesthesiology.pubs.asahq.org/article.aspx?articleid=2766554},
	doi = {10.1097/ALN.0000000000003472},
	abstract = {Abstract  Background:
     In most patients having noncardiac surgery, blood pressure is measured with the oscillometric upper arm cuff method. Although the method is noninvasive and practical, it is known to overestimate intraarterial pressure in hypotension and to underestimate it in hypertension. A high-fidelity upper arm ...},
	language = {en},
	urldate = {2020-07-28},
	journal = {Anesthesiology: The Journal of the American Society of Anesthesiologists},
	author = {Briegel, Josef and Bähner, Torsten and Kreitmeier, Alois and Conter, Philippe and Fraccaroli, Luca and Meidert, Agnes S. and Tholl, Martin and Papadakis, Georg and Deunert, Aliki and Bauer, Andreas and Hoeft, Andreas and Pfeiffer, Ulrich J.},
	month = jul,
	year = {2020},
}

@article{liang_early_2020,
	title = {Early triage of critically ill {COVID}-19 patients using deep learning},
	volume = {11},
	copyright = {2020 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-020-17280-8},
	doi = {10.1038/s41467-020-17280-8},
	abstract = {The sudden deterioration of patients with novel coronavirus disease 2019 (COVID-19) into critical illness is of major concern. It is imperative to identify these patients early. We show that a deep learning-based survival model can predict the risk of COVID-19 patients developing critical illness based on clinical characteristics at admission. We develop this model using a cohort of 1590 patients from 575 medical centers, with internal validation performance of concordance index 0.894 We further validate the model on three separate cohorts from Wuhan, Hubei and Guangdong provinces consisting of 1393 patients with concordance indexes of 0.890, 0.852 and 0.967 respectively. This model is used to create an online calculation tool designed for patient triage at admission to identify patients at risk of severe illness, ensuring that patients at greatest risk of severe illness receive appropriate care as early as possible and allow for effective allocation of health resources.},
	language = {en},
	number = {1},
	urldate = {2020-07-21},
	journal = {Nature Communications},
	author = {Liang, Wenhua and Yao, Jianhua and Chen, Ailan and Lv, Qingquan and Zanin, Mark and Liu, Jun and Wong, SookSan and Li, Yimin and Lu, Jiatao and Liang, Hengrui and Chen, Guoqiang and Guo, Haiyan and Guo, Jun and Zhou, Rong and Ou, Limin and Zhou, Niyun and Chen, Hanbo and Yang, Fan and Han, Xiao and Huan, Wenjing and Tang, Weimin and Guan, Weijie and Chen, Zisheng and Zhao, Yi and Sang, Ling and Xu, Yuanda and Wang, Wei and Li, Shiyue and Lu, Ligong and Zhang, Nuofu and Zhong, Nanshan and Huang, Junzhou and He, Jianxing},
	month = jul,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {3543},
}

@article{adibi_validation_2020,
	title = {Validation and {Utility} {Testing} of {Clinical} {Prediction} {Models}: {Time} to {Change} the {Approach}},
	volume = {324},
	issn = {0098-7484},
	shorttitle = {Validation and {Utility} {Testing} of {Clinical} {Prediction} {Models}},
	url = {https://jamanetwork.com/journals/jama/fullarticle/2762532},
	doi = {10.1001/jama.2020.1230},
	abstract = {In this Viewpoint, John Ioannidis and colleagues discuss the proliferation of undervalidated or unvalidated clinical prediction models (CPMs) and propose an open-source repository where risk prediction scores could be updated in real time and validated as a means to facilitate identification of...},
	language = {en},
	number = {3},
	urldate = {2020-07-21},
	journal = {JAMA},
	author = {Adibi, Amin and Sadatsafavi, Mohsen and Ioannidis, John P. A.},
	month = jul,
	year = {2020},
	note = {Publisher: American Medical Association},
	pages = {235--236},
}

@article{pandit_cuffless_2020,
	title = {Cuffless {Blood} {Pressure} {Monitoring}: {Promises} and {Challenges}},
	copyright = {Copyright © 2020 by the American Society of Nephrology},
	issn = {1555-9041, 1555-905X},
	shorttitle = {Cuffless {Blood} {Pressure} {Monitoring}},
	url = {https://cjasn.asnjournals.org/content/early/2020/07/16/CJN.03680320},
	doi = {10.2215/CJN.03680320},
	abstract = {Current BP measurements are on the basis of traditional BP cuff approaches. Ambulatory BP monitoring, at 15- to 30-minute intervals usually over 24 hours, provides sufficiently continuous readings that are superior to the office-based snapshot, but this system is not suitable for frequent repeated use. A true continuous BP measurement that could collect BP passively and frequently would require a cuffless method that could be worn by the patient, with the data stored electronically much the same way that heart rate and heart rhythm are already done routinely. Ideally, BP should be measured continuously and frequently during diverse activities during both daytime and nighttime in the same subject by means of novel devices. There is increasing excitement for newer methods to measure BP on the basis of sensors and algorithm development. As new devices are refined and their accuracy is improved, it will be possible to better assess masked hypertension, nocturnal hypertension, and the severity and variability of BP. In this review, we discuss the progression in the field, particularly in the last 5 years, ending with sensor-based approaches that incorporate machine learning algorithms to personalized medicine.},
	language = {en},
	urldate = {2020-07-20},
	journal = {Clinical Journal of the American Society of Nephrology},
	author = {Pandit, Jay A. and Lores, Enrique and Batlle, Daniel},
	month = jul,
	year = {2020},
	pmid = {32680913},
	note = {Publisher: American Society of Nephrology
Section: Review},
	keywords = {Ambulatory, Blood Pressure Determination, Blood Pressure Monitoring, Blood Pressure Monitors, Heart Rate, Machine Learning, Masked Hypertension, blood pressure},
}

@article{zhang_designing_nodate,
	title = {Designing {Optimal} {Dynamic} {Treatment} {Regimes}: {A} {Causal} {Reinforcement} {Learning} {Approach}},
	abstract = {A dynamic treatment regime (DTR) consists of a sequence of decision rules, one per stage of intervention, that dictates how to determine the treatment assignment to patients based on evolving treatments and covariates’ history. These regimes are particularly effective for managing chronic disorders and is arguably one of the critical ingredients underlying more personalized decisionmaking systems. All reinforcement learning algorithms for ﬁnding the optimal DTR in online settings will suffer Ω( {\textbar}DX∪S{\textbar}T ) regret on some environments, where T is the number of experiments and DX∪S is the domains of the treatments X and covariates S. This implies that T = Ω({\textbar}DX∪S{\textbar}) trials will be required to generate an optimal DTR. In many applications, the domains of X and S could be enormous, which means that the time required to ensure appropriate learning may be unattainable. We show that, if the causal diagram of the underlying environment is provided, one could achieve regret that is exponentially smaller than DX∪S. In particular, we develop two online algorithms that satisfy such regret bounds by exploiting the causal structure underlying the DTR; one is the based on the principle of optimism in the face of uncertainty (OFU-DTR), and the other uses the posterior sampling learning (PS-DTR). Finally, we introduce efﬁcient methods to accelerate these online learning procedures by leveraging the abundant, yet biased observational (non-experimental) data.},
	language = {en},
	author = {Zhang, Junzhe and Bareinboim, Elias},
	pages = {11},
}

@article{yim_predicting_2020,
	title = {Predicting conversion to wet age-related macular degeneration using deep learning},
	volume = {26},
	copyright = {2020 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-170X},
	url = {https://www.nature.com/articles/s41591-020-0867-7},
	doi = {10.1038/s41591-020-0867-7},
	abstract = {Progression to exudative ‘wet’ age-related macular degeneration (exAMD) is a major cause of visual deterioration. In patients diagnosed with exAMD in one eye, we introduce an artificial intelligence (AI) system to predict progression to exAMD in the second eye. By combining models based on three-dimensional (3D) optical coherence tomography images and corresponding automatic tissue maps, our system predicts conversion to exAMD within a clinically actionable 6-month time window, achieving a per-volumetric-scan sensitivity of 80\% at 55\% specificity, and 34\% sensitivity at 90\% specificity. This level of performance corresponds to true positives in 78\% and 41\% of individual eyes, and false positives in 56\% and 17\% of individual eyes at the high sensitivity and high specificity points, respectively. Moreover, we show that automatic tissue segmentation can identify anatomical changes before conversion and high-risk subgroups. This AI system overcomes substantial interobserver variability in expert predictions, performing better than five out of six experts, and demonstrates the potential of using AI to predict disease progression.},
	language = {en},
	number = {6},
	urldate = {2020-07-16},
	journal = {Nature Medicine},
	author = {Yim, Jason and Chopra, Reena and Spitz, Terry and Winkens, Jim and Obika, Annette and Kelly, Christopher and Askham, Harry and Lukic, Marko and Huemer, Josef and Fasler, Katrin and Moraes, Gabriella and Meyer, Clemens and Wilson, Marc and Dixon, Jonathan and Hughes, Cian and Rees, Geraint and Khaw, Peng T. and Karthikesalingam, Alan and King, Dominic and Hassabis, Demis and Suleyman, Mustafa and Back, Trevor and Ledsam, Joseph R. and Keane, Pearse A. and De Fauw, Jeffrey},
	month = jun,
	year = {2020},
	note = {Number: 6
Publisher: Nature Publishing Group},
	pages = {892--899},
}

@article{prosperi_causal_2020-1,
	title = {Causal inference and counterfactual prediction in machine learning for actionable healthcare},
	volume = {2},
	copyright = {2020 Springer Nature Limited},
	issn = {2522-5839},
	url = {https://www.nature.com/articles/s42256-020-0197-y},
	doi = {10.1038/s42256-020-0197-y},
	abstract = {Big data, high-performance computing, and (deep) machine learning are increasingly becoming key to precision medicine—from identifying disease risks and taking preventive measures, to making diagnoses and personalizing treatment for individuals. Precision medicine, however, is not only about predicting risks and outcomes, but also about weighing interventions. Interventional clinical predictive models require the correct specification of cause and effect, and the calculation of so-called counterfactuals, that is, alternative scenarios. In biomedical research, observational studies are commonly affected by confounding and selection bias. Without robust assumptions, often requiring a priori domain knowledge, causal inference is not feasible. Data-driven prediction models are often mistakenly used to draw causal effects, but neither their parameters nor their predictions necessarily have a causal interpretation. Therefore, the premise that data-driven prediction models lead to trustable decisions/interventions for precision medicine is questionable. When pursuing intervention modelling, the bio-health informatics community needs to employ causal approaches and learn causal structures. Here we discuss how target trials (algorithmic emulation of randomized studies), transportability (the licence to transfer causal effects from one population to another) and prediction invariance (where a true causal model is contained in the set of all prediction models whose accuracy does not vary across different settings) are linchpins to developing and testing intervention models.},
	language = {en},
	number = {7},
	urldate = {2020-07-16},
	journal = {Nature Machine Intelligence},
	author = {Prosperi, Mattia and Guo, Yi and Sperrin, Matt and Koopman, James S. and Min, Jae S. and He, Xing and Rich, Shannan and Wang, Mo and Buchan, Iain E. and Bian, Jiang},
	month = jul,
	year = {2020},
	note = {Number: 7
Publisher: Nature Publishing Group},
	pages = {369--375},
}

@article{hoeksel_detection_1997,
	title = {Detection of {Dicrotic} {Notch} in {Arterial} {Pressure} {Signals}},
	volume = {13},
	issn = {1573-2614},
	url = {https://doi.org/10.1023/A:1007414906294},
	doi = {10.1023/A:1007414906294},
	abstract = {Objective. A novel algorithm to detect the dicrotic notch in arterial pressure signals is proposed. Its performance is evaluated using both aortic and radial artery pressure signals, and its robustness to variations in design parameters is investigated. Methods. Most previously published dicrotic notch detection algorithms scan the arterial pressure waveform for the characteristic pressure change that is associated with the dicrotic notch. Aortic valves, however, are closed by the backwards motion of aortic blood volume. We developed an algorithm that uses arterial flow to detect the dicrotic notch in arterial pressure waveforms. Arterial flow is calculated from arterial pressure using simulation results with a three-element windkessel model. Aortic valve closure is detected after the systolic upstroke and at the minimum of the first negative dip in the calculated flow signal. Results. In 7 dogs ejection times were derived from a calculated aortic flow signal and from simultaneously measured aortic flow probe data. A total of 86 beats was analyzed; the difference in ejection times was −0.6 ± 5.4 ms (mean ± SD). The algorithm was further evaluated using 6 second epochs of radial artery pressure data measured in 50 patients. Model simulations were carried out using both a linear windkessel model and a pressure and age dependent nonlinear windkessel model. Visual inspection by an experienced clinician confirmed that the algorithm correctly identified the dicrotic notch in 98\% (49 of 50) of the patients using the linear model, and 96\% (48 of 50) of the patients using the nonlinear model. The position of the dicrotic notch appeared to be less sensitive to variations in algorithm's design parameters when a nonlinear windkessel model was used. Conclusions. The detection of the dicrotic notch in arterial pressure signals is facilitated by first calculating the arterial flow waveform from arterial pressure and a model of arterial afterload. The method is robust and reduces the problem of detecting a dubious point in a decreasing pressure signal to the detection of a well-defined minimum in a derived signal.},
	language = {en},
	number = {5},
	urldate = {2020-07-14},
	journal = {Journal of Clinical Monitoring},
	author = {Hoeksel, S.A.A.P. and Jansen, J.R.C. and Blom, J.A. and Schreuder, J.J.},
	month = sep,
	year = {1997},
	pages = {309--316},
}

@misc{noauthor_ballinger_nodate,
	title = {Ballinger},
	url = {https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16967/15916},
	urldate = {2020-06-23},
}

@article{kaisti_clinical_2019,
	title = {Clinical assessment of a non-invasive wearable {MEMS} pressure sensor array for monitoring of arterial pulse waveform, heart rate and detection of atrial fibrillation},
	volume = {2},
	copyright = {2019 The Author(s)},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-019-0117-x},
	doi = {10.1038/s41746-019-0117-x},
	abstract = {There is an unmet clinical need for a low cost and easy to use wearable devices for continuous cardiovascular health monitoring. A flexible and wearable wristband, based on microelectromechanical sensor (MEMS) elements array was developed to support this need. The performance of the device in cardiovascular monitoring was investigated by (i) comparing the arterial pressure waveform recordings to the gold standard, invasive catheter recording (n = 18), (ii) analyzing the ability to detect irregularities of the rhythm (n = 7), and (iii) measuring the heartrate monitoring accuracy (n = 31). Arterial waveforms carry important physiological information and the comparison study revealed that the recordings made with the wearable device and with the gold standard device resulted in almost identical (r = 0.9–0.99) pulse waveforms. The device can measure the heart rhythm and possible irregularities in it. A clustering analysis demonstrates a perfect classification accuracy between atrial fibrillation (AF) and sinus rhythm. The heartrate monitoring study showed near perfect beat-to-beat accuracy (sensitivity = 99.1\%, precision = 100\%) on healthy subjects. In contrast, beat-to-beat detection from coronary artery disease patients was challenging, but the averaged heartrate was extracted successfully (95\% CI: −1.2 to 1.1 bpm). In conclusion, the results indicate that the device could be useful in remote monitoring of cardiovascular diseases and personalized medicine.},
	language = {en},
	number = {1},
	urldate = {2020-06-09},
	journal = {npj Digital Medicine},
	author = {Kaisti, Matti and Panula, Tuukka and Leppänen, Joni and Punkkinen, Risto and Jafari Tadi, Mojtaba and Vasankari, Tuija and Jaakkola, Samuli and Kiviniemi, Tuomas and Airaksinen, Juhani and Kostiainen, Pekka and Meriheinä, Ulf and Koivisto, Tero and Pänkäälä, Mikko},
	month = may,
	year = {2019},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {1--10},
}

@article{kang_development_2020,
	title = {Development of a prediction model for hypotension after induction of anesthesia using machine learning},
	volume = {15},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0231172},
	doi = {10.1371/journal.pone.0231172},
	abstract = {Arterial hypotension during the early phase of anesthesia can lead to adverse outcomes such as a prolonged postoperative stay or even death. Predicting hypotension during anesthesia induction is complicated by its diverse causes. We investigated the feasibility of developing a machine-learning model to predict postinduction hypotension. Naïve Bayes, logistic regression, random forest, and artificial neural network models were trained to predict postinduction hypotension, occurring between tracheal intubation and incision, using data for the period from between the start of anesthesia induction and immediately before tracheal intubation obtained from an anesthesia monitor, a drug administration infusion pump, an anesthesia machine, and from patients’ demographics, together with preexisting disease information from electronic health records. Among 222 patients, 126 developed postinduction hypotension. The random-forest model showed the best performance, with an area under the receiver operating characteristic curve of 0.842 (95\% confidence interval [CI]: 0.736-0.948). This was higher than that for the Naïve Bayes (0.778; 95\% CI: 0.65-0.898), logistic regression (0.756; 95\% CI: 0.630-0.881), and artificial-neural-network (0.760; 95\% CI: 0.640-0.880) models. The most important features affecting the accuracy of machine-learning prediction were a patient’s lowest systolic blood pressure, lowest mean blood pressure, and mean systolic blood pressure before tracheal intubation. We found that machine-learning models using data obtained from various anesthesia machines between the start of anesthesia induction and immediately before tracheal intubation can predict hypotension occurring during the period between tracheal intubation and incision.},
	language = {en},
	number = {4},
	urldate = {2020-06-09},
	journal = {PLOS ONE},
	author = {Kang, Ah Reum and Lee, Jihyun and Jung, Woohyun and Lee, Misoon and Park, Sun Young and Woo, Jiyoung and Kim, Sang Hyun},
	month = apr,
	year = {2020},
	note = {Publisher: Public Library of Science},
	keywords = {Anesthesia, Artificial neural networks, Blood pressure, Drug administration, Hypotension, Hypotensive anesthesia, Intubation, Machine learning},
	pages = {e0231172},
}

@inproceedings{miller_noninvasive_2019,
	title = {Noninvasive {Identification} of {Hypotension} {Using} {Convolutional}-{Deconvolutional} {Networks}},
	doi = {10.1109/HealthCom46333.2019.9009594},
	abstract = {High-frequency identification of a patient's hypotensive state allows for early notification of adverse events and long-term trends. Risks of complications such as heart attack, acute kidney injury, and mortality increase with duration of hypotension during surgery, and a hypotensive state can affect the appropriate medication choices and dosages for congestive heart failure patients. Current methods for identifying hypotension are based on blood pressure cuff measurements, which are low-frequency and must be manually collected, or catheterized blood pressure sensors, which are invasive, painful, and not necessarily usable for the youngest and smallest neonatal patients. This paper explores the potential of replacing the high-frequency hypotensive state produced by the invasive arterial catheter with a high-frequency projection from a fusion of multiple noninvasive sensors. These noninvasive sensors are available for a large majority of hospital patients, and have a lower risk of adverse effects ranging from patient discomfort to site infection. In addition, using multiple sensor inputs and a robust model allows for higher-reliability identification than single-sensor architectures. Our results demonstrate that by using a single flexible convolutional-deconvolutional neural network architecture, a patient's hypotensive state may be reconstructed from any combination of the input sensor channels, with fidelity increasing in the number of available inputs.},
	booktitle = {2019 {IEEE} {International} {Conference} on {E}-health {Networking}, {Application} {Services} ({HealthCom})},
	author = {Miller, Daniel and Ward, Andrew and Bambos, Nicholas and Shin, Andrew and Scheinker, David},
	month = oct,
	year = {2019},
	keywords = {Biomedical monitoring, Blood pressure, Catheters, Electrocardiography, Hospitals, Pediatrics, Sensors, acute kidney injury, blood, blood pressure cuff measurements, blood pressure measurement, blood vessels, cardiology, cardiovascular system, catheterized blood pressure sensors, catheters, congestive heart failure patients, convolutional-deconvolutional neural network architecture, deconvolution, diseases, heart attack, high-frequency hypotensive state, high-frequency identification, high-frequency projection, hypotension, injuries, input sensor channels, kidney, medical computing, multiple noninvasive sensors, neonatal patients, paediatrics, patient care, patient monitoring, pressure sensors, single-sensor architectures, surgery},
	pages = {1--6},
}

@misc{noauthor_prediction_nodate,
	title = {Prediction of an {Acute} {Hypotensive} {Episode} {During} an {ICU}... : {Anesthesia} \& {Analgesia}},
	shorttitle = {Prediction of an {Acute} {Hypotensive} {Episode} {During} an {ICU}...},
	url = {https://journals.lww.com/anesthesia-analgesia/Fulltext/2020/05000/Prediction_of_an_Acute_Hypotensive_Episode_During.9.aspx},
	abstract = {nts. AHE prediction is of prime interest because it could allow for treatment adjustment to predict or shorten AHE.
METHODS: 
The Super Learner (SL) algorithm is an ensemble machine-learning algorithm that we specifically trained to predict an AHE 10 minutes in advance. Potential predictors included age, sex, type of care unit, severity scores, and time-evolving characteristics such as mechanical ventilation, vasopressors, or sedation medication as well as features extracted from physiological signals: heart rate, pulse oximetry, and arterial blood pressure. The algorithm was trained on the Medical Information Mart for Intensive Care dataset (MIMIC II) database. Internal validation was based on the area under the receiver operating characteristic curve (AUROC) and the Brier score (BS). External validation was performed using an external dataset from Lariboisière hospital, Paris, France.
RESULTS: 
Among 1151 patients included, 826 (72\%) patients had at least 1 AHE during their ICU stay. Using 1 single random period per patient, the SL algorithm with Haar wavelets transform preprocessing was associated with an AUROC of 0.929 (95\% confidence interval [CI], 0.899–0.958) and a BS of 0.08. Using all available periods for each patient, SL with Haar wavelets transform preprocessing was associated with an AUROC of 0.890 (95\% CI, 0.886–0.895) and a BS of 0.11. In the external validation cohort, the AUROC reached 0.884 (95\% CI, 0.775–0.993) with 1 random period per patient and 0.889 (0.768–1) with all available periods and BSs {\textless}0.1.
CONCLUSIONS: 
The SL algorithm exhibits good performance for the prediction of an AHE 10 minutes ahead of time. It allows an efficient, robust, and rapid evaluation of the risk of hypotension that opens the way to routine use....},
	language = {en-US},
	urldate = {2020-06-09},
	journal = {LWW},
	doi = {10.1213/ANE.0000000000004539},
	note = {Library Catalog: cdn.journals.lww.com},
}

@article{schussler-fiorenza_rose_longitudinal_2019,
	title = {A longitudinal big data approach for precision health},
	volume = {25},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-170X},
	url = {https://www.nature.com/articles/s41591-019-0414-6},
	doi = {10.1038/s41591-019-0414-6},
	abstract = {Precision health relies on the ability to assess disease risk at an individual level, detect early preclinical conditions and initiate preventive strategies. Recent technological advances in omics and wearable monitoring enable deep molecular and physiological profiling and may provide important tools for precision health. We explored the ability of deep longitudinal profiling to make health-related discoveries, identify clinically relevant molecular pathways and affect behavior in a prospective longitudinal cohort (n = 109) enriched for risk of type 2 diabetes mellitus. The cohort underwent integrative personalized omics profiling from samples collected quarterly for up to 8 years (median, 2.8 years) using clinical measures and emerging technologies including genome, immunome, transcriptome, proteome, metabolome, microbiome and wearable monitoring. We discovered more than 67 clinically actionable health discoveries and identified multiple molecular pathways associated with metabolic, cardiovascular and oncologic pathophysiology. We developed prediction models for insulin resistance by using omics measurements, illustrating their potential to replace burdensome tests. Finally, study participation led the majority of participants to implement diet and exercise changes. Altogether, we conclude that deep longitudinal profiling can lead to actionable health discoveries and provide relevant information for precision health.},
	language = {en},
	number = {5},
	urldate = {2020-06-05},
	journal = {Nature Medicine},
	author = {Schüssler-Fiorenza Rose, Sophia Miryam and Contrepois, Kévin and Moneghetti, Kegan J. and Zhou, Wenyu and Mishra, Tejaswini and Mataraso, Samson and Dagan-Rosenfeld, Orit and Ganz, Ariel B. and Dunn, Jessilyn and Hornburg, Daniel and Rego, Shannon and Perelman, Dalia and Ahadi, Sara and Sailani, M. Reza and Zhou, Yanjiao and Leopold, Shana R. and Chen, Jieming and Ashland, Melanie and Christle, Jeffrey W. and Avina, Monika and Limcaoco, Patricia and Ruiz, Camilo and Tan, Marilyn and Butte, Atul J. and Weinstock, George M. and Slavich, George M. and Sodergren, Erica and McLaughlin, Tracey L. and Haddad, Francois and Snyder, Michael P.},
	month = may,
	year = {2019},
	note = {Number: 5
Publisher: Nature Publishing Group},
	pages = {792--804},
}

@article{norgeot_protected_2020,
	title = {Protected {Health} {Information} filter ({Philter}): accurately and securely de-identifying free-text clinical notes},
	volume = {3},
	copyright = {2020 The Author(s)},
	issn = {2398-6352},
	shorttitle = {Protected {Health} {Information} filter ({Philter})},
	url = {https://www.nature.com/articles/s41746-020-0258-y},
	doi = {10.1038/s41746-020-0258-y},
	abstract = {There is a great and growing need to ascertain what exactly is the state of a patient, in terms of disease progression, actual care practices, pathology, adverse events, and much more, beyond the paucity of data available in structured medical record data. Ascertaining these harder-to-reach data elements is now critical for the accurate phenotyping of complex traits, detection of adverse outcomes, efficacy of off-label drug use, and longitudinal patient surveillance. Clinical notes often contain the most detailed and relevant digital information about individual patients, the nuances of their diseases, the treatment strategies selected by physicians, and the resulting outcomes. However, notes remain largely unused for research because they contain Protected Health Information (PHI), which is synonymous with individually identifying data. Previous clinical note de-identification approaches have been rigid and still too inaccurate to see any substantial real-world use, primarily because they have been trained with too small medical text corpora. To build a new de-identification tool, we created the largest manually annotated clinical note corpus for PHI and develop a customizable open-source de-identification software called Philter (“Protected Health Information filter”). Here we describe the design and evaluation of Philter, and show how it offers substantial real-world improvements over prior methods.},
	language = {en},
	number = {1},
	urldate = {2020-06-05},
	journal = {npj Digital Medicine},
	author = {Norgeot, Beau and Muenzen, Kathleen and Peterson, Thomas A. and Fan, Xuancheng and Glicksberg, Benjamin S. and Schenk, Gundolf and Rutenberg, Eugenia and Oskotsky, Boris and Sirota, Marina and Yazdany, Jinoos and Schmajuk, Gabriela and Ludwig, Dana and Goldstein, Theodore and Butte, Atul J.},
	month = apr,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {1--8},
}

@techreport{li_cue_2020,
	type = {preprint},
	title = {{CUE}: {CpG} {impUtation} {Ensemble} for {DNA} {Methylation} {Levels} {Across} the {Human} {Methylation450} ({HM450}) and {EPIC} ({HM850}) {BeadChip} {Platforms}},
	shorttitle = {{CUE}},
	url = {http://biorxiv.org/lookup/doi/10.1101/2020.05.30.107094},
	abstract = {DNA methylation at CpG dinucleotides is one of the most extensively studied epigenetic marks.},
	language = {en},
	urldate = {2020-06-04},
	institution = {Bioinformatics},
	author = {Li, Gang and Raffield, Laura and Logue, Mark and Miller, Mark W and Santos, Hudson P. and O’Shea, T.Michael and Fry, Rebecca C. and Li, Yun},
	month = may,
	year = {2020},
	doi = {10.1101/2020.05.30.107094},
}

@article{moor_topological_2020,
	title = {Topological {Autoencoders}},
	url = {http://arxiv.org/abs/1906.00722},
	abstract = {We propose a novel approach for preserving topological structures of the input space in latent representations of autoencoders. Using persistent homology, a technique from topological data analysis, we calculate topological signatures of both the input and latent space to derive a topological loss term. Under weak theoretical assumptions, we construct this loss in a differentiable manner, such that the encoding learns to retain multi-scale connectivity information. We show that our approach is theoretically well-founded and that it exhibits favourable latent representations on a synthetic manifold as well as on real-world image data sets, while preserving low reconstruction errors.},
	urldate = {2020-06-04},
	journal = {arXiv:1906.00722 [cs, math, stat]},
	author = {Moor, Michael and Horn, Max and Rieck, Bastian and Borgwardt, Karsten},
	month = feb,
	year = {2020},
	note = {arXiv: 1906.00722},
	keywords = {Computer Science - Machine Learning, Mathematics - Algebraic Topology, Statistics - Machine Learning},
}

@article{heylen_ischemia-induced_2018,
	title = {Ischemia-{Induced} {DNA} {Hypermethylation} during {Kidney} {Transplant} {Predicts} {Chronic} {Allograft} {Injury}},
	volume = {29},
	copyright = {Copyright © 2018 by the American Society of Nephrology},
	issn = {1046-6673, 1533-3450},
	url = {https://jasn.asnjournals.org/content/29/5/1566},
	doi = {10.1681/ASN.2017091027},
	abstract = {Visual Overview
{\textless}img class="highwire-fragment fragment-image" alt="Figure1" src="https://jasn.asnjournals.org/content/jnephrol/29/5/1566/F1.medium.gif" width="440" height="315"/{\textgreater}Download figureOpen in new tabDownload powerpoint

Background Ischemia during kidney transplant causes chronic allograft injury and adversely affects outcome, but the underlying mechanisms are incompletely understood. In tumors, oxygen shortage reduces the DNA demethylating activity of the ten-11 translocation (TET) enzymes, yielding hypermethylated genomes that promote tumor progression. We investigated whether ischemia similarly induces DNA hypermethylation in kidney transplants and contributes to chronic injury.
Methods We profiled genome-wide DNA methylation in three cohorts of brain-dead donor kidney allograft biopsy specimens: a longitudinal cohort with paired biopsy specimens obtained at allograft procurement (preischemia; n=13), after implantation and reperfusion (postischemia; n=13), and at 3 or 12 months after transplant (n=5 each); a cross-sectional cohort with preimplantation biopsy specimens (n=82); and a cross-sectional cohort with postreperfusion biopsy specimens (n=46).
Results Analysis of the paired preischemia and postischemia specimens revealed that methylation increased drastically in all allografts on ischemia. Hypermethylation was caused by loss of 5-hydroxymethylcytosine, the product of TET activity, and it was stable 1 year after transplant. In the preimplantation cohort, CpG hypermethylation directly correlated with ischemia time and for some CpGs, increased 2.6\% per additional hour of ischemia. Hypermethylation preferentially affected and reduced the expression of genes involved in suppressing kidney injury and fibrosis. Moreover, CpG hypermethylation in preimplantation specimens predicted chronic injury, particularly fibrosis and glomerulosclerosis, 1 year after transplant. This finding was validated in the independent postreperfusion cohort, in which hypermethylation also predicted reduced allograft function 1 year after transplant, outperforming established clinical variables.
Conclusions We highlight a novel epigenetic basis for ischemia-induced chronic allograft injury with biomarker potential.},
	language = {en},
	number = {5},
	urldate = {2020-06-04},
	journal = {Journal of the American Society of Nephrology},
	author = {Heylen, Line and Thienpont, Bernard and Naesens, Maarten and Busschaert, Pieter and Depreeuw, Jeroen and Smeets, Dominiek and Jochmans, Ina and Monbaliu, Diethard and Pirenne, Jacques and Lerut, Evelyne and Ghesquiere, Bart and Kuypers, Dirk and Lambrechts, Diether and Sprangers, Ben},
	month = may,
	year = {2018},
	pmid = {29610404},
	note = {Publisher: American Society of Nephrology
Section: Clinical Research},
	keywords = {DNA methylation, chronic allograft nephropathy, epigenetics, fibrosis, ischemia, renal transplantation},
	pages = {1566--1576},
}

@article{heylen_emerging_2016,
	title = {The {Emerging} {Role} of {DNA} {Methylation} in {Kidney} {Transplantation}: {A} {Perspective}},
	volume = {16},
	copyright = {© Copyright 2015 The American Society of Transplantation and the American Society of Transplant Surgeons},
	issn = {1600-6143},
	shorttitle = {The {Emerging} {Role} of {DNA} {Methylation} in {Kidney} {Transplantation}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/ajt.13585},
	doi = {10.1111/ajt.13585},
	abstract = {Allograft outcome depends on a range of factors, including donor age, the allo-immune response, ischemia–reperfusion injury, and interstitial fibrosis of the allograft. Changes in the epigenome, and in DNA methylation in particular, have been implicated in each of these processes, in either the kidney or other organ systems. This review provides a primer for DNA methylation analyses and a discussion of the strengths and weaknesses of current studies, but it is also a perspective for future DNA methylation research in kidney transplantation. We present exciting prospects for leveraging DNA methylation analyses as a tool in kidney biology research, and as a diagnostic or prognostic marker for predicting allograft quality and success. Topics discussed include DNA methylation changes in aging and in response to hypoxia and oxidative stress upon ischemia–reperfusion injury. Moreover, emerging evidence suggests that DNA methylation contributes to organ fibrosis and that systemic DNA methylation alterations correlate with the rate of kidney function decline in patients with chronic kidney disease and end-stage renal failure. Monitoring or targeting the epigenome could therefore reveal novel therapeutic approaches in transplantation and open up paths to biomarker discovery and targeted therapy.},
	language = {en},
	number = {4},
	urldate = {2020-06-04},
	journal = {American Journal of Transplantation},
	author = {Heylen, L. and Thienpont, B. and Naesens, M. and Lambrechts, D. and Sprangers, B.},
	year = {2016},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/ajt.13585},
	keywords = {Interstitial fibrosis and tubular atrophy, basic (laboratory) research, biomarker, cell death, genetics, genomics, ischemia reperfusion injury (IRI), kidney transplantation, nephrology, science, senescence, translational research},
	pages = {1070--1078},
}

@article{mehta_quantitative_2006,
	title = {Quantitative {Detection} of {Promoter} {Hypermethylation} as a {Biomarker} of {Acute} {Kidney} {Injury} {During} {Transplantation}},
	volume = {38},
	issn = {0041-1345},
	url = {http://www.sciencedirect.com/science/article/pii/S0041134506013947},
	doi = {10.1016/j.transproceed.2006.10.149},
	abstract = {Aberrant promoter hypermethylation, also known as epigenetics, is thought to be a promising biomarker approach to diagnose malignancies. Kidney repair after injury is a recapitulation of normal morphogenesis, with similarities to malignant transformation. We hypothesized that changes in urine epigenetics could be a biomarker approach during early kidney transplant injury and repair. We examined urine DNA for aberrant methylation of two gene promoters (DAPK and CALCA) by quantitative methylation-specific polymerase chain reaction from 13 deceased and 10 living donor kidney transplant recipients on postoperative day 2 and 65 healthy controls. Results were compared with clinical outcomes and to results of the kidney biopsy. Transplant recipients were significantly more likely to have aberrant hypermethylation of the CALCA gene promoter in urine than healthy controls (100\% vs 31\%; P {\textless} .0001). There was increased CALCA hypermethylation in the urine of deceased versus living donor transplants (21.60 ± 12.5 vs 12.19 ± 4.7; P = .04). Furthermore, there was a trend toward increased aberrant hypermethylation of urine CALCA in patients with biopsy-proven acute tubular necrosis versus acute rejection and slow or prompt graft function (mean: 20.40 ± 6.9, 13.87 ± 6.49, 17.17 ± 13.4; P = .67). However, there was no difference of CALCA hypermethylation in urine of patients with delayed graft function versus those with slow or prompt graft function (16.9 ± 6.2 vs 18.5 ± 13.7, respectively; P = .5). There was no aberrant hypermethylation of DAPK in the urine of transplant patients. Urine epigenetics is a promising biomarker approach for acute ischemic injury in transplantation that merits future study.},
	language = {en},
	number = {10},
	urldate = {2020-06-04},
	journal = {Transplantation Proceedings},
	author = {Mehta, T. K. and Hoque, M. O. and Ugarte, R. and Rahman, M. H. and Kraus, E. and Montgomery, R. and Melancon, K. and Sidransky, D. and Rabb, H.},
	month = dec,
	year = {2006},
	pages = {3420--3426},
}

@article{wing_dna_2014,
	title = {{DNA} methylation profile associated with rapid decline in kidney function: findings from the {CRIC} {Study}},
	volume = {29},
	issn = {0931-0509},
	shorttitle = {{DNA} methylation profile associated with rapid decline in kidney function},
	url = {https://academic.oup.com/ndt/article/29/4/864/1931648},
	doi = {10.1093/ndt/gft537},
	abstract = {AbstractBackground.  Epigenetic mechanisms may be important in the progression of chronic kidney disease (CKD).Methods.  We studied the genome-wide DNA methylat},
	language = {en},
	number = {4},
	urldate = {2020-06-04},
	journal = {Nephrology Dialysis Transplantation},
	author = {Wing, Maria R. and Devaney, Joseph M. and Joffe, Marshall M. and Xie, Dawei and Feldman, Harold I. and Dominic, Elizabeth A. and Guzman, Nicolas J. and Ramezani, Ali and Susztak, Katalin and Herman, James G. and Cope, Leslie and Harmon, Brennan and Kwabi-Addo, Bernard and Gordish-Dressman, Heather and Go, Alan S. and He, Jiang and Lash, James P. and Kusek, John W. and Raj, Dominic S.},
	month = apr,
	year = {2014},
	note = {Publisher: Oxford Academic},
	pages = {864--872},
}

@article{peters_clinical_2016,
	title = {Clinical potential of {DNA} methylation in organ transplantation},
	volume = {35},
	issn = {1053-2498},
	url = {http://www.sciencedirect.com/science/article/pii/S1053249816300468},
	doi = {10.1016/j.healun.2016.02.007},
	abstract = {Identification of patients at risk for post-transplant complications is a major challenge, but it will improve clinical care and patient health after organ transplantation. The poor predictive value of the current biomarkers highlights the need to explore novel and innovative methods, such as epigenetics, for the discovery of new biomarkers. Cell differentiation and function of immune cells is dependent on epigenetic mechanisms, which regulate gene expression without altering the original DNA sequence. These epigenetic mechanisms are dynamic, potentially heritable, change with age, and can be regulated and influenced by environmental conditions. One of the most well-known epigenetic mechanisms is DNA methylation, which comprises the methylation of a cytosine (C) next to a guanine (G; CpG dinucleotides). Aberrant DNA methylation is increasingly associated with disease, including immune-mediated diseases, and these alterations precede the clinical phenotype. The impact of DNA methylation profiles on transplant acceptance and rejection as well as on other post-transplant complications is unknown. In this study we examine the current evidence of the functional role of recipient and donor DNA methylation on outcome after organ transplantation. Changes in DNA methylation may predict the risk of developing post-transplant complications, such as infections, malignancies and allograft rejection. We speculate that identification of these changes in DNA methylation contributes to earlier diagnosis and prevention of post-transplant complications, leading to improved patient care.},
	language = {en},
	number = {7},
	urldate = {2020-06-04},
	journal = {The Journal of Heart and Lung Transplantation},
	author = {Peters, Fleur S. and Manintveld, Olivier C. and Betjes, Michiel G. H. and Baan, Carla C. and Boer, Karin},
	month = jul,
	year = {2016},
	keywords = {DNA methylation, biomarker, epigenetics, human, organ transplantation},
	pages = {843--850},
}

@article{vineis_dna_2011,
	title = {{DNA} methylation changes associated with cancer risk factors and blood levels of vitamin metabolites in a prospective study},
	volume = {6},
	issn = {1559-2294},
	url = {https://doi.org/10.4161/epi.6.2.13573},
	doi = {10.4161/epi.6.2.13573},
	abstract = {Aberrant DNA methylation is a major epigenetic mechanism of gene silencing in a wide range of human cancers. Previous studies on DNA methylation typically used paired tumor and normal-appearing surrounding tissues from cancer-bearing individuals. However, genomic DNA isolated from surrogate tissues such as blood cells represents an attractive material that can be exploited in the discovery of biomarkers of exposure and tumorigenesis. Here we examined the association between lung cancer and DNA methylation patterns in a panel of candidate genes. We also investigated whether blood levels of vitamin metabolites modify DNA methylation levels in blood cells. To this end, we quantitatively determined DNA methylation levels in blood cells of nested cases and controls from a prospective study with well defined dietary habits and lifestyles. Multiple CpG sites in five genes (CDKN2A/p16, RASSF1A, GSTP1, MTHFR, and MGMT) that are frequent targets of hypermethylation in a variety of human malignancies were included in the analysis. While no clear association between DNA methylation patterns and the case/control status was found, with the exception of RASSF1A hypermethylation, methylation level changed according to serum levels of 1-carbon metabolites and vitamins B. Overall, folate was associated with increased methylation levels of RASSF1A and MTHFR and methionine was associated with decreased methylation levels of RASSF1A. The associations with folate were more pronounced among never smokers while the associations with methionine were more evident among ever-smokers. These results are consistent with the notion that blood levels of 1-carbon metabolism markers and dietary/lifestyle factors may modify DNA methylation levels in blood cells and that blood cells can be exploited for the discovery of epigenetic biomarkers of exposures, providing proof-of-principle on the use of blood samples in the context of prospective studies.},
	number = {2},
	urldate = {2020-06-04},
	journal = {Epigenetics},
	author = {Vineis, Paolo and Chuang, Shu-Chun and Vaissière, Thomas and Cuenin, Cyrille and Ricceri, Fulvio and collaborators, Genair/EPIC and Johansson, Mattias and Ueland, Per and Brennan, Paul and Herceg, Zdenko},
	month = feb,
	year = {2011},
	pmid = {20978370},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.4161/epi.6.2.13573},
	pages = {195--201},
}

@article{szyf_epigenetics_2009,
	title = {Epigenetics, {DNA} {Methylation}, and {Chromatin} {Modifying} {Drugs}},
	volume = {49},
	url = {https://doi.org/10.1146/annurev-pharmtox-061008-103102},
	doi = {10.1146/annurev-pharmtox-061008-103102},
	abstract = {Evidence is emerging that several diseases and behavioral pathologies result from defects in gene function. The best-studied example is cancer, but other diseases such as autoimmune disease, asthma, type 2 diabetes, metabolic disorders, and autism display aberrant gene expression. Gene function may be altered by either a change in the sequence of the DNA or a change in epigenetic programming of a gene in the absence of a sequence change. With epigenetic drugs, it is possible to reverse aberrant gene expression profiles associated with different disease states. Several epigenetic drugs targeting DNA methylation and histone deacetylation enzymes have been tested in clinical trials. Understanding the epigenetic machinery and the differential roles of its components in specific disease states is essential for developing targeted epigenetic therapy.},
	number = {1},
	urldate = {2020-06-04},
	journal = {Annual Review of Pharmacology and Toxicology},
	author = {Szyf, Moshe},
	year = {2009},
	pmid = {18851683},
	note = {\_eprint: https://doi.org/10.1146/annurev-pharmtox-061008-103102},
	pages = {243--263},
}

@article{garcia-calzon_diabetes_2017,
	title = {Diabetes medication associates with {DNA} methylation of metformin transporter genes in the human liver},
	volume = {9},
	issn = {1868-7083},
	url = {https://doi.org/10.1186/s13148-017-0400-0},
	doi = {10.1186/s13148-017-0400-0},
	abstract = {Given that metformin is the most common pharmacological therapy for type 2 diabetes, understanding the function of this drug is of great importance. Hepatic metformin transporters are responsible for the pharmacologic action of metformin. However, epigenetics in genes encoding metformin transporters has not been fully elucidated. We examined the DNA methylation of these genes in the liver of subjects with type 2 diabetes and tested whether epigenetic alterations associate with diabetes medication, i.e., metformin or insulin plus metformin treatment.},
	number = {1},
	urldate = {2020-06-04},
	journal = {Clinical Epigenetics},
	author = {García-Calzón, Sonia and Perfilyev, Alexander and Männistö, Ville and de Mello, Vanessa D. and Nilsson, Emma and Pihlajamäki, Jussi and Ling, Charlotte},
	month = sep,
	year = {2017},
	pages = {102},
}

@article{kazmi_associations_2020,
	title = {Associations between high blood pressure and {DNA} methylation},
	volume = {15},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0227728},
	doi = {10.1371/journal.pone.0227728},
	abstract = {Background High blood pressure is a major risk factor for cardiovascular disease and is influenced by both environmental and genetic factors. Epigenetic processes including DNA methylation potentially mediate the relationship between genetic factors, the environment and cardiovascular disease. Despite an increased risk of hypertension and cardiovascular disease in individuals of South Asians compared to Europeans, it is not clear whether associations between blood pressure and DNA methylation differ between these groups. Methods We performed an epigenome-wide association study and differentially methylated region (DMR) analysis to identify DNA methylation sites and regions that were associated with systolic blood pressure, diastolic blood pressure and hypertension. We analyzed samples from 364 European and 348 South Asian men (first generation migrants to the UK) from the Southall And Brent REvisited cohort, measuring DNA methylation from blood using the Illumina Infinium® HumanMethylation450 BeadChip. Results One CpG site was found to be associated with DBP in trans-ancestry analyses (i.e. both ethnic groups combined), while in Europeans alone seven CpG sites were associated with DBP. No associations were identified between DNA methylation and either SBP or hypertension. Comparison of effect sizes between South Asian and European EWAS for DBP, SBP and hypertension revealed little concordance between analyses. DMR analysis identified several regions with known relationships with CVD and its risk factors. Conclusion This study identified differentially methylated sites and regions associated with blood pressure and revealed ethnic differences in these associations. These findings may point to molecular pathways which may explain the elevated cardiovascular disease risk experienced by those of South Asian ancestry when compared to Europeans.},
	language = {en},
	number = {1},
	urldate = {2020-06-04},
	journal = {PLOS ONE},
	author = {Kazmi, Nabila and Elliott, Hannah R. and Burrows, Kim and Tillin, Therese and Hughes, Alun D. and Chaturvedi, Nish and Gaunt, Tom R. and Relton, Caroline L.},
	month = jan,
	year = {2020},
	note = {Publisher: Public Library of Science},
	keywords = {Blood pressure, Cardiovascular diseases, DNA methylation, Ethnic epidemiology, Europe, Hypertension, Methylation, Stroke},
	pages = {e0227728},
}

@article{heyn_dna_2012,
	title = {{DNA} methylation profiling in the clinic: applications and challenges},
	volume = {13},
	copyright = {2012 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1471-0064},
	shorttitle = {{DNA} methylation profiling in the clinic},
	url = {https://www.nature.com/articles/nrg3270},
	doi = {10.1038/nrg3270},
	abstract = {Alterations in epigenetic marks — specifically DNA methylation — are an emerging biomarker that may be used in the decision-making process for disease diagnosis, prognosis and treatment, most notably in cancer, but there are examples in other diseases, such as type 1 diabetes.Alterations in epigenetic marks that are chosen as biomarkers must be carefully selected owing to the dynamic nature of these marks. These alterations may be detected in non-invasive tissues, such as serum, in addition to primary tissues and so may have advantages over genetic biomarkers.Glutathione S-transferase pi 1 (GSTP1) is the best-studied example of an epigenetic biomarker for cancer diagnosis. However, additional candidates show a high potential for future clinical applications, although specificity of diagnosis is an issue, and combinatorial approaches analysing DNA methylation alterations at several genes may improve this.Single-gene approaches have identified epigenetic biomarkers that predict cancer recurrence and survival. Recently, high-resolution genome-wide technologies have shown the potential to improve this strategy with DNA methylation signatures of cancers showing high predictive capacity of disease prognosis.DNA methylation alterations may be used as biomarkers to predict response to chemotherapy strategies. O6-methylguanine DNA methyltransferase (MGMT) and breast cancer 1, early onset (BRCA1) are examples of hypermethylated genes that predict a response to chemotherapy in cancer. Additional prognostic gene markers have already been identified and suggest DNA methylation profiling as a potent strategy to predict drug response.Recent advances in sequencing and array technologies, which are capable of screening DNA methylomes genome-wide at high-resolution, gave unexpected novel insights in cancer biology. They will be crucial for DNA methylation profiling and the identification of epigenetic biomarker for diagnosis, prognosis and prediction of drug response.},
	language = {en},
	number = {10},
	urldate = {2020-06-02},
	journal = {Nature Reviews Genetics},
	author = {Heyn, Holger and Esteller, Manel},
	month = oct,
	year = {2012},
	note = {Number: 10
Publisher: Nature Publishing Group},
	pages = {679--692},
}

@article{millard_searching_2019,
	title = {Searching for the causal effects of body mass index in over 300 000 participants in {UK} {Biobank}, using {Mendelian} randomization},
	volume = {15},
	issn = {1553-7404},
	url = {https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1007951},
	doi = {10.1371/journal.pgen.1007951},
	abstract = {Mendelian randomization (MR) has been used to estimate the causal effect of body mass index (BMI) on particular traits thought to be affected by BMI. However, BMI may also be a modifiable, causal risk factor for outcomes where there is no prior reason to suggest that a causal effect exists. We performed a MR phenome-wide association study (MR-pheWAS) to search for the causal effects of BMI in UK Biobank (n = 334 968), using the PHESANT open-source phenome scan tool. A subset of identified associations were followed up with a formal two-stage instrumental variable analysis in UK Biobank, to estimate the causal effect of BMI on these phenotypes. Of the 22 922 tests performed, our MR-pheWAS identified 587 associations below a stringent P value threshold corresponding to a 5\% estimated false discovery rate. These included many previously identified causal effects, for instance, an adverse effect of higher BMI on risk of diabetes and hypertension. We also identified several novel effects, including protective effects of higher BMI on a set of psychosocial traits, identified initially in our preliminary MR-pheWAS in circa 115,000 UK Biobank participants and replicated in a different subset of circa 223,000 UK Biobank participants. Our comprehensive MR-pheWAS identified potential causal effects of BMI on a large and diverse set of phenotypes. This included both previously identified causal effects, and novel effects such as a protective effect of higher BMI on feelings of nervousness.},
	language = {en},
	number = {2},
	urldate = {2020-06-01},
	journal = {PLOS Genetics},
	author = {Millard, Louise A. C. and Davies, Neil M. and Tilling, Kate and Gaunt, Tom R. and Smith, George Davey},
	month = feb,
	year = {2019},
	note = {Publisher: Public Library of Science},
	keywords = {Anxiety, Body mass index, Colliders, Depression, Instrumental variable analysis, Phenotypes, Population genetics, Psychological and psychosocial issues},
	pages = {e1007951},
}

@article{verbanck_detection_2018,
	title = {Detection of widespread horizontal pleiotropy in causal relationships inferred from {Mendelian} randomization between complex traits and diseases},
	volume = {50},
	copyright = {2018 The Author(s)},
	issn = {1546-1718},
	url = {https://www.nature.com/articles/s41588-018-0099-7},
	doi = {10.1038/s41588-018-0099-7},
	abstract = {Horizontal pleiotropy occurs when the variant has an effect on disease outside of its effect on the exposure in Mendelian randomization (MR). Violation of the ‘no horizontal pleiotropy’ assumption can cause severe bias in MR. We developed the Mendelian randomization pleiotropy residual sum and outlier (MR-PRESSO) test to identify horizontal pleiotropic outliers in multi-instrument summary-level MR testing. We showed using simulations that the MR-PRESSO test is best suited when horizontal pleiotropy occurs in {\textless}50\% of instruments. Next we applied the MR-PRESSO test, along with several other MR tests, to complex traits and diseases and found that horizontal pleiotropy (i) was detectable in over 48\% of significant causal relationships in MR; (ii) introduced distortions in the causal estimates in MR that ranged on average from –131\% to 201\%; (iii) induced false-positive causal relationships in up to 10\% of relationships; and (iv) could be corrected in some but not all instances.},
	language = {en},
	number = {5},
	urldate = {2020-06-01},
	journal = {Nature Genetics},
	author = {Verbanck, Marie and Chen, Chia-Yen and Neale, Benjamin and Do, Ron},
	month = may,
	year = {2018},
	note = {Number: 5
Publisher: Nature Publishing Group},
	pages = {693--698},
}

@article{takeuchi_therapeutic_2017,
	title = {Therapeutic {Response} to {Paroxetine} in {Major} {Depressive} {Disorder} {Predicted} by {DNA} {Methylation}},
	volume = {75},
	issn = {0302-282X, 1423-0224},
	url = {https://www.karger.com/Article/FullText/480512},
	doi = {10.1159/000480512},
	abstract = {\textbf{\textit{Background:}} Antidepressants have variable therapeutic effects, depending on genetic and environmental factors. Approximately 30\% of major depressive disorder (MDD) patients do not respond significantly to antidepressants such as paroxetine, a selective serotonin reuptake inhibitor (SSRI). However, the biological mechanisms behind this phenomenon are mostly unknown. Here, we examined the role of patients' epigenetic background in SSRI efficacy. \textbf{\textit{Methods:}} Genome-wide DNA methylation analysis of the peripheral blood of Japanese MDD patients was performed by using the Infinium HumanMethylation450 BeadChip. \textbf{\textit{Results:}} We compared the results of the 10 patients who best responded to paroxetine (BR) with the 10 worst responders (WR), and found 623 CpG sites with a {\textgreater}10\% difference in DNA methylation level. Among them, 218 sites were nominally significant between BR and WR (\textit{p} {\textless} 0.05), and 2 sites (cg00594917 and cg07260927) were significantly different after false discovery rate (FDR) correction (\textit{q} {\textless} 0.05). The methylation difference was greatest at cg00594917, located in the first exon of the \textit{PPFIA4} gene, which codes for liprin-α (\textit{p} = 0.00012). Hierarchical cluster analysis of 23 CpG sites in the \textit{PPFIA4} gene distinguished BR and WR, except for 1 WR patient. The cg07260927 site was located in the 5′UTR of the heparin sulfate-glucosamine 3-sulfotransferase 1 (\textit{HS3ST1}) gene (\textit{p} = 0.00013). Hierarchical cluster analysis of 28 CpG sites in \textit{HS3ST1} distinguished BR and WR, except for 1 WR and 2 BR patients. \textbf{\textit{Conclusion:}} Our results suggest that patients' DNA methylation profile at specific genes such as \textit{PPFIA4} and \textit{HS3ST1} is associated with individual variations in therapeutic responses to paroxetine.},
	language = {english},
	number = {2},
	urldate = {2020-06-01},
	journal = {Neuropsychobiology},
	author = {Takeuchi, Naohiro and Nonen, Shinpei and Kato, Masaki and Wakeno, Masataka and Takekita, Yoshiteru and Kinoshita, Toshihiko and Kugawa, Fumihiko},
	year = {2017},
	pmid = {29131015},
	note = {Publisher: Karger Publishers},
	pages = {81--88},
}

@article{menke_epigenetic_2014,
	title = {Epigenetic alterations in depression and antidepressant treatment},
	volume = {16},
	issn = {1294-8322},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4214180/},
	abstract = {Epigenetic modifications control chromatin structure and function, and thus mediate changes in gene expression, ultimately influencing protein levels. Recent research indicates that environmental events can induce epigenetic changes and, by this, contribute to long-term changes in neural circuits and endocrine systems associated with altered risk for stress-related psychiatric disorders such as major depression. In this review, we describe recent approaches investigating epigenetic modifications associated with altered risk for major depression or response to antidepressant drugs, both on the candidate gene levels as well as the genome-wide level. In this review we focus on DNA methylation, as this is the most investigated epigenetic change in depression research.},
	number = {3},
	urldate = {2020-06-01},
	journal = {Dialogues in Clinical Neuroscience},
	author = {Menke, Andreas and Binder, Elisabeth B.},
	month = sep,
	year = {2014},
	pmid = {25364288},
	pmcid = {PMC4214180},
	pages = {395--404},
}

@article{numata_blood_2015,
	title = {Blood diagnostic biomarkers for major depressive disorder using multiplex {DNA} methylation profiles: discovery and validation},
	volume = {10},
	issn = {1559-2294},
	shorttitle = {Blood diagnostic biomarkers for major depressive disorder using multiplex {DNA} methylation profiles},
	url = {https://doi.org/10.1080/15592294.2014.1003743},
	doi = {10.1080/15592294.2014.1003743},
	abstract = {Aberrant DNA methylation in the blood of patients with major depressive disorder (MDD) has been reported in several previous studies. However, no comprehensive studies using medication-free subjects with MDD have been conducted. Furthermore, the majority of these previous studies has been limited to the analysis of the CpG sites in CpG islands (CGIs) in the gene promoter regions. The main aim of the present study is to identify DNA methylation markers that distinguish patients with MDD from non-psychiatric controls. Genome-wide DNA methylation profiling of peripheral leukocytes was conducted in two set of samples, a discovery set (20 medication-free patients with MDD and 19 controls) and a replication set (12 medication-free patients with MDD and 12 controls), using Infinium HumanMethylation450 BeadChips. Significant diagnostic differences in DNA methylation were observed at 363 CpG sites in the discovery set. All of these loci demonstrated lower DNA methylation in patients with MDD than in the controls, and most of them (85.7\%) were located in the CGIs in the gene promoter regions. We were able to distinguish patients with MDD from the control subjects with high accuracy in the discriminant analysis using the top DNA methylation markers. We also validated these selected DNA methylation markers in the replication set. Our results indicate that multiplex DNA methylation markers may be useful for distinguishing patients with MDD from non-psychiatric controls.},
	number = {2},
	urldate = {2020-06-01},
	journal = {Epigenetics},
	author = {Numata, Shusuke and Ishii, Kazuo and Tajima, Atsushi and Iga, Jun-ichi and Kinoshita, Makoto and Watanabe, Shinya and Umehara, Hidehiro and Fuchikami, Manabu and Okada, Satoshi and Boku, Shuken and Hishimoto, Akitoyo and Shimodera, Shinji and Imoto, Issei and Morinobu, Shigeru and Ohmori, Tetsuro},
	month = feb,
	year = {2015},
	pmid = {25587773},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/15592294.2014.1003743},
	keywords = {DNA methylation, biomarkers, blood, epigenetic, major depressive disorder, microarray, multiplex},
	pages = {135--141},
}

@article{bycroft_uk_2018,
	title = {The {UK} {Biobank} resource with deep phenotyping and genomic data},
	volume = {562},
	copyright = {2018 Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-018-0579-z.},
	doi = {10.1038/s41586-018-0579-z},
	abstract = {The UK Biobank project is a prospective cohort study with deep genetic and phenotypic data collected on approximately 500,000 individuals from across the United Kingdom, aged between 40 and 69 at recruitment. The open resource is unique in its size and scope. A rich variety of phenotypic and health-related information is available on each participant, including biological measurements, lifestyle indicators, biomarkers in blood and urine, and imaging of the body and brain. Follow-up information is provided by linking health and medical records. Genome-wide genotype data have been collected on all participants, providing many opportunities for the discovery of new genetic associations and the genetic bases of complex traits. Here we describe the centralized analysis of the genetic data, including genotype quality, properties of population structure and relatedness of the genetic data, and efficient phasing and genotype imputation that increases the number of testable variants to around 96 million. Classical allelic variation at 11 human leukocyte antigen genes was imputed, resulting in the recovery of signals with known associations between human leukocyte antigen alleles and many diseases.},
	language = {en},
	number = {7726},
	urldate = {2020-06-01},
	journal = {Nature},
	author = {Bycroft, Clare and Freeman, Colin and Petkova, Desislava and Band, Gavin and Elliott, Lloyd T. and Sharp, Kevin and Motyer, Allan and Vukcevic, Damjan and Delaneau, Olivier and O’Connell, Jared and Cortes, Adrian and Welsh, Samantha and Young, Alan and Effingham, Mark and McVean, Gil and Leslie, Stephen and Allen, Naomi and Donnelly, Peter and Marchini, Jonathan},
	month = oct,
	year = {2018},
	note = {Number: 7726
Publisher: Nature Publishing Group},
	pages = {203--209},
}

@article{hou_accurate_2019,
	title = {Accurate estimation of {SNP}-heritability from biobank-scale data irrespective of genetic architecture},
	volume = {51},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-1718},
	url = {https://www.nature.com/articles/s41588-019-0465-0},
	doi = {10.1038/s41588-019-0465-0},
	abstract = {SNP-heritability is a fundamental quantity in the study of complex traits. Recent studies have shown that existing methods to estimate genome-wide SNP-heritability can yield biases when their assumptions are violated. While various approaches have been proposed to account for frequency- and linkage disequilibrium (LD)-dependent genetic architectures, it remains unclear which estimates reported in the literature are reliable. Here we show that genome-wide SNP-heritability can be accurately estimated from biobank-scale data irrespective of genetic architecture, without specifying a heritability model or partitioning SNPs by allele frequency and/or LD. We show analytically and through extensive simulations starting from real genotypes (UK Biobank, N = 337 K) that, unlike existing methods, our closed-form estimator is robust across a wide range of architectures. We provide estimates of SNP-heritability for 22 complex traits in the UK Biobank and show that, consistent with our results in simulations, existing biobank-scale methods yield estimates up to 30\% different from our theoretically-justified approach.},
	language = {en},
	number = {8},
	urldate = {2020-06-01},
	journal = {Nature Genetics},
	author = {Hou, Kangcheng and Burch, Kathryn S. and Majumdar, Arunabha and Shi, Huwenbo and Mancuso, Nicholas and Wu, Yue and Sankararaman, Sriram and Pasaniuc, Bogdan},
	month = aug,
	year = {2019},
	note = {Number: 8
Publisher: Nature Publishing Group},
	pages = {1244--1251},
}

@article{runge_inferring_2019,
	title = {Inferring causation from time series in {Earth} system sciences},
	volume = {10},
	copyright = {2019 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-019-10105-3},
	doi = {10.1038/s41467-019-10105-3},
	abstract = {The heart of the scientific enterprise is a rational effort to understand the causes behind the phenomena we observe. In large-scale complex dynamical systems such as the Earth system, real experiments are rarely feasible. However, a rapidly increasing amount of observational and simulated data opens up the use of novel data-driven causal methods beyond the commonly adopted correlation techniques. Here, we give an overview of causal inference frameworks and identify promising generic application cases common in Earth system sciences and beyond. We discuss challenges and initiate the benchmark platform causeme.netto close the gap between method users and developers.},
	language = {en},
	number = {1},
	urldate = {2020-05-27},
	journal = {Nature Communications},
	author = {Runge, Jakob and Bathiany, Sebastian and Bollt, Erik and Camps-Valls, Gustau and Coumou, Dim and Deyle, Ethan and Glymour, Clark and Kretschmer, Marlene and Mahecha, Miguel D. and Muñoz-Marí, Jordi and van Nes, Egbert H. and Peters, Jonas and Quax, Rick and Reichstein, Markus and Scheffer, Marten and Schölkopf, Bernhard and Spirtes, Peter and Sugihara, George and Sun, Jie and Zhang, Kun and Zscheischler, Jakob},
	month = jun,
	year = {2019},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {2553},
}

@article{runge_detecting_2019,
	title = {Detecting and quantifying causal associations in large nonlinear time series datasets},
	volume = {5},
	copyright = {Copyright © 2019 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works. Distributed under a Creative Commons Attribution License 4.0 (CC BY).. This is an open-access article distributed under the terms of the Creative Commons Attribution license, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.},
	issn = {2375-2548},
	url = {https://advances.sciencemag.org/content/5/11/eaau4996},
	doi = {10.1126/sciadv.aau4996},
	abstract = {Identifying causal relationships and quantifying their strength from observational time series data are key problems in disciplines dealing with complex dynamical systems such as the Earth system or the human body. Data-driven causal inference in such systems is challenging since datasets are often high dimensional and nonlinear with limited sample sizes. Here, we introduce a novel method that flexibly combines linear or nonlinear conditional independence tests with a causal discovery algorithm to estimate causal networks from large-scale time series datasets. We validate the method on time series of well-understood physical mechanisms in the climate system and the human heart and using large-scale synthetic datasets mimicking the typical properties of real-world data. The experiments demonstrate that our method outperforms state-of-the-art techniques in detection power, which opens up entirely new possibilities to discover and quantify causal networks from time series across a range of research fields.
A novel causal discovery method for estimating nonlinear interdependency networks from large time series datasets.
A novel causal discovery method for estimating nonlinear interdependency networks from large time series datasets.},
	language = {en},
	number = {11},
	urldate = {2020-05-27},
	journal = {Science Advances},
	author = {Runge, Jakob and Nowack, Peer and Kretschmer, Marlene and Flaxman, Seth and Sejdinovic, Dino},
	month = nov,
	year = {2019},
	note = {Publisher: American Association for the Advancement of Science
Section: Research Article},
	pages = {eaau4996},
}

@article{choi_comparison_2019,
	title = {A comparison of different methods to handle missing data in the context of propensity score analysis},
	volume = {34},
	issn = {0393-2990},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6325992/},
	doi = {10.1007/s10654-018-0447-z},
	abstract = {Propensity score analysis is a popular method to control for confounding in observational studies. A challenge in propensity methods is missing values in confounders. Several strategies for handling missing values exist, but guidance in choosing the best method is needed. In this simulation study, we compared four strategies of handling missing covariate values in propensity matching and propensity weighting. These methods include: complete case analysis, missing indicator method, multiple imputation and combining multiple imputation and missing indicator method. Concurrently, we aimed to provide guidance in choosing the optimal strategy. Simulated scenarios varied regarding missing mechanism, presence of effect modification or unmeasured confounding. Additionally, we demonstrated how missingness graphs help clarifying the missing structure. When no effect modification existed, complete case analysis yielded valid causal treatment effects even when data were missing not at random. In some situations, complete case analysis was also able to partially correct for unmeasured confounding. Multiple imputation worked well if the data were missing (completely) at random, and if the imputation model was correctly specified. In the presence of effect modification, more complex imputation models than default options of commonly used statistical software were required. Multiple imputation may fail when data are missing not at random. Here, combining multiple imputation and the missing indicator method reduced the bias as the missing indicator variable can be a proxy for unobserved confounding. The optimal way to handle missing values in covariates of propensity score models depends on the missing data structure and the presence of effect modification. When effect modification is present, default settings of imputation methods may yield biased results even if data are missing at random.},
	number = {1},
	urldate = {2020-05-25},
	journal = {European Journal of Epidemiology},
	author = {Choi, Jungyeon and Dekkers, Olaf M. and le Cessie, Saskia},
	year = {2019},
	pmid = {30341708},
	pmcid = {PMC6325992},
	pages = {23--36},
}

@article{wells_strategies_2013,
	title = {Strategies for {Handling} {Missing} {Data} in {Electronic} {Health} {Record} {Derived} {Data}},
	volume = {1},
	issn = {2327-9214},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4371484/},
	doi = {10.13063/2327-9214.1035},
	abstract = {Electronic health records (EHRs) present a wealth of data that are vital for improving patient-centered outcomes, although the data can present significant statistical challenges. In particular, EHR data contains substantial missing information that if left unaddressed could reduce the validity of conclusions drawn. Properly addressing the missing data issue in EHR data is complicated by the fact that it is sometimes difficult to differentiate between missing data and a negative value. For example, a patient without a documented history of heart failure may truly not have disease or the clinician may have simply not documented the condition. Approaches for reducing missing data in EHR systems come from multiple angles, including: increasing structured data documentation, reducing data input errors, and utilization of text parsing / natural language processing. This paper focuses on the analytical approaches for handling missing data, primarily multiple imputation. The broad range of variables available in typical EHR systems provide a wealth of information for mitigating potential biases caused by missing data. The probability of missing data may be linked to disease severity and healthcare utilization since unhealthier patients are more likely to have comorbidities and each interaction with the health care system provides an opportunity for documentation. Therefore, any imputation routine should include predictor variables that assess overall health status (e.g. Charlson Comorbidity Index) and healthcare utilization (e.g. number of encounters) even when these comorbidities and patient encounters are unrelated to the disease of interest. Linking the EHR data with other sources of information (e.g. National Death Index and census data) can also provide less biased variables for imputation. Additional methodological research with EHR data and improved epidemiological training of clinical investigators is warranted.},
	number = {3},
	urldate = {2020-05-20},
	journal = {eGEMs},
	author = {Wells, Brian J. and Chagin, Kevin M. and Nowacki, Amy S. and Kattan, Michael W.},
	month = dec,
	year = {2013},
	pmid = {25848578},
	pmcid = {PMC4371484},
}

@article{abedi_latent-based_2018,
	title = {Latent-{Based} {Imputation} of {Laboratory} {Measures} from {Electronic} {Health} {Records}: {Case} for {Complex} {Diseases}},
	copyright = {© 2018, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	shorttitle = {Latent-{Based} {Imputation} of {Laboratory} {Measures} from {Electronic} {Health} {Records}},
	url = {https://www.biorxiv.org/content/10.1101/275743v1},
	doi = {10.1101/275743},
	abstract = {{\textless}h3{\textgreater}Abstract{\textless}/h3{\textgreater} {\textless}p{\textgreater}Imputation is a key step in Electronic Health Records-mining as it can significantly affect the conclusions derived from the downstream analysis. There are three main categories that explain the missingness in clinical settings–incompleteness, inconsistency, and inaccuracy–and these can capture a variety of situations: the patient did not seek treatment, the health care provider did not enter the information, etc. We used EHR data from patients diagnosed with Inflammatory Bowel Disease from Geisinger Health System to design a novel imputation that focuses on a complex phenotype. Our approach is based on latent-based analysis integrated with clustering to group patients based on their comorbidities before imputation. IBD is a chronic illness of unclear etiology and without a complete cure. We have taken advantage of the complexity of IBD to pre-process the EHR data of 10,498 IBD patients and show that imputation can be improved using shared latent comorbidities. The R code and sample simulated input data will be available at a future time.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-05-20},
	journal = {bioRxiv},
	author = {Abedi, V. and Shivakumar, M. K. and Lu, P. and Hontecillas, R. and Leber, A. and Ahuja, M. and Ulloa, A. E. and Shellenberger, M. J. and Bassaganya-Riera, J.},
	month = mar,
	year = {2018},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {275743},
}

@inproceedings{ravichandran_respnet_2019,
	title = {{RespNet}: {A} deep learning model for extraction of respiration from photoplethysmogram},
	shorttitle = {{RespNet}},
	doi = {10.1109/EMBC.2019.8856301},
	abstract = {Respiratory ailments afflict a wide range of people and manifests itself through conditions like asthma and sleep apnea. Continuous monitoring of chronic respiratory ailments is seldom used outside the intensive care ward due to the large size and cost of the monitoring system. While Electrocardiogram (ECG) based respiration extraction is a validated approach, its adoption is limited by access to a suitable continuous ECG monitor. Recently, due to the widespread adoption of wearable smartwatches with in-built Photoplethysmogram (PPG) sensor, it is being considered as a viable candidate for continuous and unobtrusive respiration monitoring. Research in this domain, however, has been predominantly focussed on estimating respiration rate from PPG. In this work, a novel end-to-end deep learning network called RespNet is proposed to perform the task of extracting the respiration signal from a given input PPG as opposed to extracting respiration rate. The proposed network was trained and tested on two different datasets utilizing different modalities of reference respiration signal recordings. Also, the similarity and performance of the proposed network against two conventional signal processing approaches for extracting respiration signal were studied. The proposed method was tested on two independent datasets with a Mean Squared Error of 0.262 and 0.145. The cross-correlation coefficient of the respective datasets were found to be 0.933 and 0.931. The reported errors and similarity was found to be better than conventional approaches. The proposed approach would aid clinicians to provide comprehensive evaluation of sleep-related respiratory conditions and chronic respiratory ailments while being comfortable and inexpensive for the patient.},
	booktitle = {2019 41st {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society} ({EMBC})},
	author = {Ravichandran, Vignesh and Murugesan, Balamurali and Balakarthikeyan, Vaishali and Ram, Keerthi and Preejith, S.P. and Joseph, Jayaraj and Sivaprakasam, Mohanasankar},
	month = jul,
	year = {2019},
	note = {ISSN: 1558-4615},
	keywords = {Convolution, Decoding, Deep learning, Electrocardiography, Feature extraction, Monitoring, PPG sensor, RespNet, Training, asthma, chronic respiratory ailments, continuous ECG monitor, continuous respiration monitoring, deep learning model, diseases, electrocardiogram, end-to-end deep learning network, feature extraction, intensive care ward, learning (artificial intelligence), medical signal processing, neural nets, patient monitoring, photoplethysmogram sensor, photoplethysmography, pneumodynamics, reference respiration signal recordings, respiration rate, signal processing, sleep, sleep apnea, sleep-related respiratory conditions, unobtrusive respiration monitoring, wearable smartwatches},
	pages = {5556--5559},
}

@article{oconnor_distinguishing_2018,
	title = {Distinguishing genetic correlation from causation across 52 diseases and complex traits},
	volume = {50},
	copyright = {2018 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-1718},
	url = {https://www.nature.com/articles/s41588-018-0255-0},
	doi = {10.1038/s41588-018-0255-0},
	abstract = {Mendelian randomization, a method to infer causal relationships, is confounded by genetic correlations reflecting shared etiology. We developed a model in which a latent causal variable mediates the genetic correlation; trait 1 is partially genetically causal for trait 2 if it is strongly genetically correlated with the latent causal variable, quantified using the genetic causality proportion. We fit this model using mixed fourth moments \$\$\{{\textbackslash}it\{E\}\}(\{{\textbackslash}it\{{\textbackslash}alpha \}\}\_1{\textasciicircum}2\{{\textbackslash}it\{{\textbackslash}alpha \}\}\_1\{{\textbackslash}it\{{\textbackslash}alpha \}\}\_2)\$\$E(α12α1α2)and \$\$\{{\textbackslash}it\{E\}\}{\textbackslash}left( \{\{{\textbackslash}it\{{\textbackslash}alpha \}\}\_2{\textasciicircum}2\{{\textbackslash}it\{{\textbackslash}alpha \}\}\_1\{{\textbackslash}it\{{\textbackslash}alpha \}\}\_2\} {\textbackslash}right)\$\$Eα22α1α2of marginal effect sizes for each trait; if trait 1 is causal for trait 2, then SNPs affecting trait 1 (large \$\$\{{\textbackslash}it\{{\textbackslash}alpha \}\}\_1{\textasciicircum}2\$\$α12) will have correlated effects on trait 2 (large α1α2), but not vice versa. In simulations, our method avoided false positives due to genetic correlations, unlike Mendelian randomization. Across 52 traits (average n = 331,000), we identified 30 causal relationships with high genetic causality proportion estimates. Novel findings included a causal effect of low-density lipoprotein on bone mineral density, consistent with clinical trials of statins in osteoporosis.},
	language = {en},
	number = {12},
	urldate = {2020-05-14},
	journal = {Nature Genetics},
	author = {O’Connor, Luke J. and Price, Alkes L.},
	month = dec,
	year = {2018},
	note = {Number: 12
Publisher: Nature Publishing Group},
	pages = {1728--1734},
}

@article{bent_investigating_2020,
	title = {Investigating sources of inaccuracy in wearable optical heart rate sensors},
	volume = {3},
	copyright = {2020 The Author(s)},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-020-0226-6},
	doi = {10.1038/s41746-020-0226-6},
	abstract = {As wearable technologies are being increasingly used for clinical research and healthcare, it is critical to understand their accuracy and determine how measurement errors may affect research conclusions and impact healthcare decision-making. Accuracy of wearable technologies has been a hotly debated topic in both the research and popular science literature. Currently, wearable technology companies are responsible for assessing and reporting the accuracy of their products, but little information about the evaluation method is made publicly available. Heart rate measurements from wearables are derived from photoplethysmography (PPG), an optical method for measuring changes in blood volume under the skin. Potential inaccuracies in PPG stem from three major areas, includes (1) diverse skin types, (2) motion artifacts, and (3) signal crossover. To date, no study has systematically explored the accuracy of wearables across the full range of skin tones. Here, we explored heart rate and PPG data from consumer- and research-grade wearables under multiple circumstances to test whether and to what extent these inaccuracies exist. We saw no statistically significant difference in accuracy across skin tones, but we saw significant differences between devices, and between activity types, notably, that absolute error during activity was, on average, 30\% higher than during rest. Our conclusions indicate that different wearables are all reasonably accurate at resting and prolonged elevated heart rate, but that differences exist between devices in responding to changes in activity. This has implications for researchers, clinicians, and consumers in drawing study conclusions, combining study results, and making health-related decisions using these devices.},
	language = {en},
	number = {1},
	urldate = {2020-05-13},
	journal = {npj Digital Medicine},
	author = {Bent, Brinnae and Goldstein, Benjamin A. and Kibbe, Warren A. and Dunn, Jessilyn P.},
	month = feb,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {1--9},
}

@article{niederer_computational_2019,
	title = {Computational models in cardiology},
	volume = {16},
	copyright = {2018 Springer Nature Limited},
	issn = {1759-5010},
	url = {https://www.nature.com/articles/s41569-018-0104-y},
	doi = {10.1038/s41569-018-0104-y},
	abstract = {Computational models are increasingly used in cardiology to integrate multiple data sets from individual patients and create virtual-patient simulations. In this Review, Niederer and colleagues discuss how multi-scale models of cardiac electrophysiology and mechanics can support diagnostic assessment and clinical decision-making and pave the way to personalized cardiac care.},
	language = {en},
	number = {2},
	urldate = {2020-05-13},
	journal = {Nature Reviews Cardiology},
	author = {Niederer, Steven A. and Lumens, Joost and Trayanova, Natalia A.},
	month = feb,
	year = {2019},
	note = {Number: 2
Publisher: Nature Publishing Group},
	pages = {100--111},
}

@article{raghunath_prediction_2020,
	title = {Prediction of mortality from 12-lead electrocardiogram voltage data using a deep neural network},
	copyright = {2020 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-170X},
	url = {https://www.nature.com/articles/s41591-020-0870-z},
	doi = {10.1038/s41591-020-0870-z},
	abstract = {By using data from electrocardiograms, a deep learning algorithm outperforms traditional risk scores in predicting death over the course of the next year and identifies at-risk individuals with seemingly normal electrocardiograms.},
	language = {en},
	urldate = {2020-05-12},
	journal = {Nature Medicine},
	author = {Raghunath, Sushravya and Ulloa Cerna, Alvaro E. and Jing, Linyuan and vanMaanen, David P. and Stough, Joshua and Hartzel, Dustin N. and Leader, Joseph B. and Kirchner, H. Lester and Stumpe, Martin C. and Hafez, Ashraf and Nemani, Arun and Carbonati, Tanner and Johnson, Kipp W. and Young, Katelyn and Good, Christopher W. and Pfeifer, John M. and Patel, Aalpen A. and Delisle, Brian P. and Alsaid, Amro and Beer, Dominik and Haggerty, Christopher M. and Fornwalt, Brandon K.},
	month = may,
	year = {2020},
	note = {Publisher: Nature Publishing Group},
	pages = {1--6},
}

@article{ibtehaz_ppg2abp_2020,
	title = {{PPG2ABP}: {Translating} {Photoplethysmogram} ({PPG}) {Signals} to {Arterial} {Blood} {Pressure} ({ABP}) {Waveforms} using {Fully} {Convolutional} {Neural} {Networks}},
	shorttitle = {{PPG2ABP}},
	url = {http://arxiv.org/abs/2005.01669},
	abstract = {Cardiovascular diseases are one of the most severe causes of mortality, taking a heavy toll of lives annually throughout the world. The continuous monitoring of blood pressure seems to be the most viable option, but this demands an invasive process, bringing about several layers of complexities. This motivates us to develop a method to predict the continuous arterial blood pressure (ABP) waveform through a non-invasive approach using photoplethysmogram (PPG) signals. In addition we explore the advantage of deep learning as it would free us from sticking to ideally shaped PPG signals only, by making handcrafted feature computation irrelevant, which is a shortcoming of the existing approaches. Thus, we present, PPG2ABP, a deep learning based method, that manages to predict the continuous ABP waveform from the input PPG signal, with a mean absolute error of 4.604 mmHg, preserving the shape, magnitude and phase in unison. However, the more astounding success of PPG2ABP turns out to be that the computed values of DBP, MAP and SBP from the predicted ABP waveform outperforms the existing works under several metrics, despite that PPG2ABP is not explicitly trained to do so.},
	urldate = {2020-05-09},
	journal = {arXiv:2005.01669 [cs, eess]},
	author = {Ibtehaz, Nabil and Rahman, M. Sohel},
	month = may,
	year = {2020},
	note = {arXiv: 2005.01669},
	keywords = {Computer Science - Machine Learning, Electrical Engineering and Systems Science - Signal Processing},
}

@article{geleris_observational_2020,
	title = {Observational {Study} of {Hydroxychloroquine} in {Hospitalized} {Patients} with {Covid}-19},
	volume = {0},
	issn = {0028-4793},
	url = {https://doi.org/10.1056/NEJMoa2012410},
	doi = {10.1056/NEJMoa2012410},
	number = {0},
	urldate = {2020-05-08},
	journal = {New England Journal of Medicine},
	author = {Geleris, Joshua and Sun, Yifei and Platt, Jonathan and Zucker, Jason and Baldwin, Matthew and Hripcsak, George and Labella, Angelena and Manson, Daniel and Kubin, Christine and Barr, R. Graham and Sobieszczyk, Magdalena E. and Schluger, Neil W.},
	month = may,
	year = {2020},
	note = {Publisher: Massachusetts Medical Society
\_eprint: https://doi.org/10.1056/NEJMoa2012410},
	pages = {null},
}

@article{millard_searching_2019-1,
	title = {Searching for the causal effects of body mass index in over 300 000 participants in {UK} {Biobank}, using {Mendelian} randomization},
	volume = {15},
	issn = {1553-7404},
	url = {https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1007951},
	doi = {10.1371/journal.pgen.1007951},
	abstract = {Mendelian randomization (MR) has been used to estimate the causal effect of body mass index (BMI) on particular traits thought to be affected by BMI. However, BMI may also be a modifiable, causal risk factor for outcomes where there is no prior reason to suggest that a causal effect exists. We performed a MR phenome-wide association study (MR-pheWAS) to search for the causal effects of BMI in UK Biobank (n = 334 968), using the PHESANT open-source phenome scan tool. A subset of identified associations were followed up with a formal two-stage instrumental variable analysis in UK Biobank, to estimate the causal effect of BMI on these phenotypes. Of the 22 922 tests performed, our MR-pheWAS identified 587 associations below a stringent P value threshold corresponding to a 5\% estimated false discovery rate. These included many previously identified causal effects, for instance, an adverse effect of higher BMI on risk of diabetes and hypertension. We also identified several novel effects, including protective effects of higher BMI on a set of psychosocial traits, identified initially in our preliminary MR-pheWAS in circa 115,000 UK Biobank participants and replicated in a different subset of circa 223,000 UK Biobank participants. Our comprehensive MR-pheWAS identified potential causal effects of BMI on a large and diverse set of phenotypes. This included both previously identified causal effects, and novel effects such as a protective effect of higher BMI on feelings of nervousness.},
	language = {en},
	number = {2},
	urldate = {2020-05-06},
	journal = {PLOS Genetics},
	author = {Millard, Louise A. C. and Davies, Neil M. and Tilling, Kate and Gaunt, Tom R. and Smith, George Davey},
	month = feb,
	year = {2019},
	note = {Publisher: Public Library of Science},
	keywords = {Anxiety, Body mass index, Colliders, Depression, Instrumental variable analysis, Phenotypes, Population genetics, Psychological and psychosocial issues},
	pages = {e1007951},
}

@article{vaid_machine_2020,
	title = {Machine {Learning} to {Predict} {Mortality} and {Critical} {Events} in {COVID}-19 {Positive} {New} {York} {City} {Patients}},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.medrxiv.org/content/10.1101/2020.04.26.20073411v1},
	doi = {10.1101/2020.04.26.20073411},
	abstract = {{\textless}p{\textgreater}Coronavirus 2019 (COVID-19), caused by the SARS-CoV-2 virus, has become the deadliest pandemic in modern history, reaching nearly every country worldwide and overwhelming healthcare institutions. As of April 20, there have been more than 2.4 million confirmed cases with over 160,000 deaths. Extreme case surges coupled with challenges in forecasting the clinical course of affected patients have necessitated thoughtful resource allocation and early identification of high-risk patients. However, effective methods for achieving this are lacking. In this paper, we present a decision tree-based machine learning model trained on electronic health records from patients with confirmed COVID-19 at a single center within the Mount Sinai Health System in New York City. We then externally validate our model by predicting the likelihood of critical event or death within various time intervals for patients after hospitalization at four other hospitals and achieve strong performance, notably predicting mortality at 1 week with an AUC-ROC of 0.84. Finally, we establish model interpretability by calculating SHAP scores to identify decisive features, including age, inflammatory markers (procalcitonin and LDH), and coagulation parameters (PT, PTT, D-Dimer). To our knowledge, this is one of the first models with external validation to both predict outcomes in COVID-19 patients with strong validation performance and identification of key contributors in outcome prediction that may assist clinicians in making effective patient management decisions.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-04-28},
	journal = {medRxiv},
	author = {Vaid, Akhil and Somani, Sulaiman and Russak, Adam J. and Freitas, Jessica K. De and Chaudhry, Fayzan F. and Paranjpe, Ishan and Johnson, Kipp W. and Lee, Samuel J. and Miotto, Riccardo and Zhao, Shan and Beckmann, Noam and Naik, Nidhi and Arfer, Kodi and Kia, Arash and Timsina, Prem and Lala, Anuradha and Paranjpe, Manish and Glowe, Patricia and Golden, Eddye and Danieletto, Matteo and Singh, Manbir and Meyer, Dara and O'Reilly, Paul F. and Huckins, Laura H. and Kovatch, Patricia and Finkelstein, Joseph and Freeman, Robert M. and Argulian, Edgar and Kasarskis, Andrew and Percha, Bethany and Aberg, Judith A. and Bagiella, Emilia and Horowitz, Carol R. and Murphy, Barbara and Nestler, Eric J. and Schadt, Eric E. and Cho, Judy H. and Cordon-Cardo, Carlos and Fuster, Valentin and Charney, Dennis S. and Reich, David L. and Bottinger, Erwin P. and Levin, Matthew A. and Narula, Jagat and Fayad, Zahi A. and Just, Allan and Charney, Alexander W. and Nadkarni, Girish N. and Glicksberg, Benjamin S.},
	month = apr,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory Press},
	pages = {2020.04.26.20073411},
}

@article{mahevas_no_2020,
	title = {No evidence of clinical efficacy of hydroxychloroquine in patients hospitalized for {COVID}-19 infection with oxygen requirement: results of a study using routinely collected data to emulate a target trial},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	shorttitle = {No evidence of clinical efficacy of hydroxychloroquine in patients hospitalized for {COVID}-19 infection with oxygen requirement},
	url = {https://www.medrxiv.org/content/10.1101/2020.04.10.20060699v1},
	doi = {10.1101/2020.04.10.20060699},
	abstract = {{\textless}p{\textgreater}Background Treatments are urgently needed to prevent respiratory failure and deaths from coronavirus disease 2019 (COVID-19). Hydroxychloroquine (HCQ) has received worldwide attention because of positive results from small studies. Methods We used data collected from routine care of all adults in 4 French hospitals with documented SARS-CoV-2 pneumonia and requiring oxygen ≥ 2 L/min to emulate a target trial aimed at assessing the effectiveness of HCQ at 600 mg/day. The composite primary endpoint was transfer to intensive care unit (ICU) within 7 days from inclusion and/or death from any cause. Analyses were adjusted for confounding factors by inverse probability of treatment weighting. Results This study included 181 patients with SARS-CoV-2 pneumonia; 84 received HCQ within 48 hours of admission (HCQ group) and 97 did not (no-HCQ group). Initial severity was well balanced between the groups. In the weighted analysis, 20.2\% patients in the HCQ group were transferred to the ICU or died within 7 days vs 22.1\% in the no-HCQ group (16 vs 21 events, relative risk [RR] 0.91, 95\% CI 0.47-1.80). In the HCQ group, 2.8\% of the patients died within 7 days vs 4.6\% in the no-HCQ group (3 vs 4 events, RR 0.61, 95\% CI 0.13-2.89), and 27.4\% and 24.1\%, respectively, developed acute respiratory distress syndrome within 7 days (24 vs 23 events, RR 1.14, 95\% CI 0.65-2.00). Eight patients receiving HCQ (9.5\%) experienced electrocardiogram modifications requiring HCQ discontinuation. Interpretation These results do not support the use of HCQ in patients hospitalised for documented SARS-CoV-2-positive hypoxic pneumonia.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-04-24},
	journal = {medRxiv},
	author = {Mahevas, Matthieu and Tran, Viet-Thi and Roumier, Mathilde and Chabrol, Amelie and Paule, Romain and Guillaud, Constance and Gallien, Sebastien and Lepeule, Raphael and Szwebel, Tali-Anne and Lescure, Xavier and Schlemmer, Frederic and Matignon, Marie and Khellaf, Mehdi and Crickx, Etienne and Terrier, Benjamin and Morbieu, Caroline and Legendre, Paul and Dang, Julien and Schoindre, Yoland and Pawlotski, Jean-Michel and Michel, Marc and Perrodeau, Elodie and Carlier, Nicolas and Roche, Nicolas and Lastours, Victoire De and Mouthon, Luc and Audureau, Etienne and Ravaud, Philippe and Godeau, Bertrand and Costedoat, Nathalie},
	month = apr,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory Press},
	pages = {2020.04.10.20060699},
}

@article{cinelli_generalizing_nodate,
	title = {Generalizing {Experimental} {Results} by {Leveraging} {Knowledge} of {Mechanisms}},
	abstract = {We show how experimental results can be generalized across diverse populations by leveraging knowledge of local mechanisms that produce the outcome of interest, only some of which may diﬀer in the target domain. We use Structural Causal Models (SCM) and a reﬁned version of selection diagrams to represent such knowledge, and to decide whether it entails the invariance of probabilities of causation across populations, which then enables generalization. We further provide: (i) bounds for the target eﬀect when some of these conditions are violated; (ii) new identiﬁcation results for probabilities of causation and the transported causal eﬀect when trials from multiple source domains are available; as well as (iii) a Bayesian approach for estimating the transported causal eﬀect from ﬁnite samples. We illustrate these methods both with simulated data and with a real example that transports the eﬀects of Vitamin A supplementation on childhood mortality across diﬀerent regions.},
	language = {en},
	author = {Cinelli, Carlos and Pearl, Judea},
	pages = {39},
}

@article{molina_no_2020,
	title = {No evidence of rapid antiviral clearance or clinical benefit with the combination of hydroxychloroquine and azithromycin in patients with severe {COVID}-19 infection},
	issn = {0399077X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0399077X20300858},
	doi = {10.1016/j.medmal.2020.03.006},
	language = {en},
	urldate = {2020-04-23},
	journal = {Médecine et Maladies Infectieuses},
	author = {Molina, J.M. and Delaugerre, C. and Le Goff, J. and Mela-Lima, B. and Ponscarme, D. and Goldwirt, L. and de Castro, N.},
	month = mar,
	year = {2020},
	pages = {S0399077X20300858},
}

@article{wang_remdesivir_2020,
	title = {Remdesivir and chloroquine effectively inhibit the recently emerged novel coronavirus (2019-{nCoV}) in vitro},
	volume = {30},
	copyright = {2020 The Author(s)},
	issn = {1748-7838},
	url = {https://www.nature.com/articles/s41422-020-0282-0},
	doi = {10.1038/s41422-020-0282-0},
	language = {en},
	number = {3},
	urldate = {2020-04-23},
	journal = {Cell Research},
	author = {Wang, Manli and Cao, Ruiyuan and Zhang, Leike and Yang, Xinglou and Liu, Jia and Xu, Mingyue and Shi, Zhengli and Hu, Zhihong and Zhong, Wu and Xiao, Gengfu},
	month = mar,
	year = {2020},
	note = {Number: 3
Publisher: Nature Publishing Group},
	pages = {269--271},
}

@techreport{magagnoli_outcomes_2020,
	type = {preprint},
	title = {Outcomes of hydroxychloroquine usage in {United} {States} veterans hospitalized with {Covid}-19},
	url = {http://medrxiv.org/lookup/doi/10.1101/2020.04.16.20065920},
	abstract = {BACKGROUND: Despite limited and conflicting data on the use of hydroxychloroquine in patients with Covid-19, the U.S. Food and Drug Administration has authorized the emergency use of this drug when clinical trials are unavailable or infeasible. Hydroxychloroquine, alone or in combination with azithromycin, is being widely used in Covid-19 therapy based on anecdotal and limited observational evidence.},
	language = {en},
	urldate = {2020-04-22},
	institution = {Infectious Diseases (except HIV/AIDS)},
	author = {Magagnoli, Joseph and Narendran, Siddharth and Pereira, Felipe and Cummings, Tammy and Hardin, James W and Sutton, S Scott and Ambati, Jayakrishna},
	month = apr,
	year = {2020},
	doi = {10.1101/2020.04.16.20065920},
}

@article{gautret_hydroxychloroquine_2020,
	title = {Hydroxychloroquine and azithromycin as a treatment of {COVID}-19: results of an open-label non-randomized clinical trial},
	issn = {0924-8579},
	shorttitle = {Hydroxychloroquine and azithromycin as a treatment of {COVID}-19},
	url = {http://www.sciencedirect.com/science/article/pii/S0924857920300996},
	doi = {10.1016/j.ijantimicag.2020.105949},
	abstract = {Background
Chloroquine and hydroxychloroquine have been found to be efficient on SARS-CoV-2, and reported to be efficient in Chinese COV-19 patients. We evaluate the role of hydroxychloroquine on respiratory viral loads.
Patients and methods
French Confirmed COVID-19 patients were included in a single arm protocol from early March to March 16th, to receive 600mg of hydroxychloroquine daily and their viral load in nasopharyngeal swabs was tested daily in a hospital setting. Depending on their clinical presentation, azithromycin was added to the treatment. Untreated patients from another center and cases refusing the protocol were included as negative controls. Presence and absence of virus at Day6-post inclusion was considered the end point.
Results
Six patients were asymptomatic, 22 had upper respiratory tract infection symptoms and eight had lower respiratory tract infection symptoms. Twenty cases were treated in this study and showed a significant reduction of the viral carriage at D6-post inclusion compared to controls, and much lower average carrying duration than reported of untreated patients in the literature. Azithromycin added to hydroxychloroquine was significantly more efficient for virus elimination.
Conclusion
Despite its small sample size our survey shows that hydroxychloroquine treatment is significantly associated with viral load reduction/disappearance in COVID-19 patients and its effect is reinforced by azithromycin.},
	language = {en},
	urldate = {2020-04-22},
	journal = {International Journal of Antimicrobial Agents},
	author = {Gautret, Philippe and Lagier, Jean-Christophe and Parola, Philippe and Hoang, Van Thuan and Meddeb, Line and Mailhe, Morgane and Doudier, Barbara and Courjon, Johan and Giordanengo, Valérie and Vieira, Vera Esteves and Dupont, Hervé Tissot and Honoré, Stéphane and Colson, Philippe and Chabrière, Eric and La Scola, Bernard and Rolain, Jean-Marc and Brouqui, Philippe and Raoult, Didier},
	month = mar,
	year = {2020},
	keywords = {2019-nCoV, COVID-19, SARS-CoV-2, azithomycin, clinical trial, hydroxychloroquine},
	pages = {105949},
}

@article{gaskell_introduction_2020,
	title = {An {Introduction} to {Causal} {Diagrams} for {Anesthesiology} {Research}},
	volume = {132},
	issn = {0003-3022},
	url = {https://anesthesiology.pubs.asahq.org/article.aspx?articleid=2764480},
	doi = {10.1097/ALN.0000000000003193},
	abstract = {Abstract Making good decisions in the era of Big Data requires a sophisticated approach to causality. We are acutely aware that association ≠ causation, yet untangling the two remains one of our greatest challenges. This realization has stimulated a Causal Revolution in epidemiology, and the lessons learned are highly relevant ...},
	language = {en},
	number = {5},
	urldate = {2020-04-19},
	journal = {Anesthesiology: The Journal of the American Society of Anesthesiologists},
	author = {Gaskell, Amy L. and Sleigh, Jamie W.},
	month = may,
	year = {2020},
	note = {Publisher: The American Society of Anesthesiologists},
	pages = {951--967},
}

@article{schlesinger_estimation_2020,
	title = {Estimation and {Tracking} of {Blood} {Pressure} {Using} {Routinely} {Acquired} {Photoplethysmographic} {Signals} and {Deep} {Neural} {Networks}},
	volume = {2},
	issn = {2639-8028},
	url = {https://journals.lww.com/ccejournal/Fulltext/2020/04000/Estimation_and_Tracking_of_Blood_Pressure_Using.11.aspx},
	doi = {10.1097/CCE.0000000000000095},
	abstract = {Objectives: 
        Continuous tracking of blood pressure in critically ill patients allows rapid identification of clinically important changes and helps guide treatment. Classically, such tracking requires invasive monitoring with its associated risks, discomfort, and low availability outside critical care units. We hypothesized that information contained in a prevalent noninvasively acquired signal (photoplethysmograph: a byproduct of pulse oximetry) combined with advanced machine learning will allow continuous estimation of the patient’s blood pressure.
        Design: 
        Retrospective cohort study with split sampling for model training and testing.
        Setting: 
        A single urban academic hospital.
        Patients: 
        Three-hundred twenty-nine adult patients admitted to a critical care unit.
        Interventions: 
        None.
        Measurements and Main Results: 
        One hundred thirty-six thousand four-hundred fifty-nine photoplethysmography waveforms of length 30 seconds were used for training (60\%), validation (20\%), and testing (20\%) of the blood pressure estimation network. Each sample had an associated systolic, mean, and diastolic blood pressures extracted from concurrently recorded invasive arterial line waveforms. Blood pressure estimation using photoplethysmography waveforms is achieved using advanced machine learning methods (convolutional neural networks and a Siamese architectural configuration) calibrated for each patient on a single, first available photoplethysmography sample and associated blood pressure reading. The average estimation bias error was 0.52, 0.1, and –0.76 mm Hg for diastolic, mean, and systolic blood pressure, respectively, with associated mean absolute errors of 4.11, 5.51, and 7.98 mm Hg. If used to identify clinically important changes in blood pressure from the initial baseline, with a threshold of a 10 mm Hg increase or decrease in blood pressure, our algorithm shows an accuracy of 85\%, 78\%, and 74\% for diastolic, mean, and systolic blood pressure, respectively. We also report the network’s performance in detecting systolic and diastolic hypo- or hypertension with accuracies ranging from 86\% to 97\%.
        Conclusions: 
        Using advanced machine learning tools, we show that blood pressure estimation can be achieved using a common noninvasively recorded signal, the photoplethysmography. Such tools can allow for better monitoring of patients that do not have invasively recorded blood pressure, both in the critical care setting and on inpatient wards.},
	language = {en-US},
	number = {4},
	urldate = {2020-04-17},
	journal = {Critical Care Explorations {\textbar} Society of Critical Care Medicine Journal},
	author = {Schlesinger, Oded and Vigderhouse, Nitai and Moshe, Yair and Eytan, Danny},
	month = apr,
	year = {2020},
	pages = {e0095},
}

@article{mohan_efficient_nodate,
	title = {An {Efficient} {Method} for {Bayesian} {Network} {Parameter} {Learning} from {Incomplete} {Data}},
	abstract = {We propose an efﬁcient method for estimating the parameters of a Bayesian network, from incomplete datasets, i.e., datasets containing variables with missing values. In contrast to textbook approaches such as EM and the gradient method, our approach is non-iterative, yields closed form parameter estimates, and eliminates the need for inference in a Bayesian network. Our approach is capable of producing consistent parameter estimates for missing data problems that are MCAR, MAR, and in some cases, MNAR. Empirically, our approach is orders of magnitude faster than EM. When data is scarce, we learn parameters of comparable quality to EM. Given sufﬁcient data, we can learn parameters that are orders of magnitude closer to the true parameters.},
	language = {en},
	author = {Mohan, Karthika},
	pages = {9},
}

@book{hazlett_estimating_2018,
	title = {Estimating causal effects of new treatments despite self-selection: {The} case of experimental medical treatments},
	shorttitle = {Estimating causal effects of new treatments despite self-selection},
	abstract = {A method for estimating treatment effects of newly available treatments under arbitrary selection-into-treatment, as illustrated by application to novel medical treatments.},
	author = {Hazlett, Chad},
	month = jul,
	year = {2018},
}

@article{arentz_characteristics_2020,
	title = {Characteristics and {Outcomes} of 21 {Critically} {Ill} {Patients} {With} {COVID}-19 in {Washington} {State}},
	url = {https://jamanetwork.com/journals/jama/fullarticle/2763485},
	doi = {10.1001/jama.2020.4326},
	abstract = {This case series describes the clinical presentation, characteristics, and outcomes of patients with coronavirus disease 2019 (COVID-19) admitted to the intensive care unit at a public hospital in Washington State in February 2020, including initial reports of cardiomyopathy in one-third of the...},
	language = {en},
	urldate = {2020-03-20},
	journal = {JAMA},
	author = {Arentz, Matt and Yim, Eric and Klaff, Lindy and Lokhandwala, Sharukh and Riedo, Francis X. and Chong, Maria and Lee, Melissa},
	month = mar,
	year = {2020},
}

@article{palmer_using_2012,
	title = {Using multiple genetic variants as instrumental variables for modifiable risk factors},
	volume = {21},
	issn = {0962-2802},
	url = {https://doi.org/10.1177/0962280210394459},
	doi = {10.1177/0962280210394459},
	abstract = {Mendelian randomisation analyses use genetic variants as instrumental variables (IVs) to estimate causal effects of modifiable risk factors on disease outcomes. Genetic variants typically explain a small proportion of the variability in risk factors; hence Mendelian randomisation analyses can require large sample sizes. However, an increasing number of genetic variants have been found to be robustly associated with disease-related outcomes in genome-wide association studies. Use of multiple instruments can improve the precision of IV estimates, and also permit examination of underlying IV assumptions. We discuss the use of multiple genetic variants in Mendelian randomisation analyses with continuous outcome variables where all relationships are assumed to be linear. We describe possible violations of IV assumptions, and how multiple instrument analyses can be used to identify them. We present an example using four adiposity-associated genetic variants as IVs for the causal effect of fat mass on bone density, using data on 5509 children enrolled in the ALSPAC birth cohort study. We also use simulation studies to examine the effect of different sets of IVs on precision and bias. When each instrument independently explains variability in the risk factor, use of multiple instruments increases the precision of IV estimates. However, inclusion of weak instruments could increase finite sample bias. Missing data on multiple genetic variants can diminish the available sample size, compared with single instrument analyses. In simulations with additive genotype-risk factor effects, IV estimates using a weighted allele score had similar properties to estimates using multiple instruments. Under the correct conditions, multiple instrument analyses are a promising approach for Mendelian randomisation studies. Further research is required into multiple imputation methods to address missing data issues in IV estimation.},
	language = {en},
	number = {3},
	urldate = {2020-03-19},
	journal = {Statistical Methods in Medical Research},
	author = {Palmer, Tom M and Lawlor, Debbie A and Harbord, Roger M and Sheehan, Nuala A and Tobias, Jon H and Timpson, Nicholas J and Smith, George Davey and Sterne, Jonathan AC},
	month = jun,
	year = {2012},
	note = {Publisher: SAGE Publications Ltd STM},
	pages = {223--242},
}

@article{burgess_sensitivity_2017,
	title = {Sensitivity {Analyses} for {Robust} {Causal} {Inference} from {Mendelian} {Randomization} {Analyses} with {Multiple} {Genetic} {Variants}},
	volume = {28},
	issn = {1044-3983},
	url = {https://journals.lww.com/epidem/Fulltext/2017/01000/Sensitivity_Analyses_for_Robust_Causal_Inference.6.aspx},
	doi = {10.1097/EDE.0000000000000559},
	abstract = {Mendelian randomization investigations are becoming more powerful and simpler to perform, due to the increasing size and coverage of genome-wide association studies and the increasing availability of summarized data on genetic associations with risk factors and disease outcomes. However, when using multiple genetic variants from different gene regions in a Mendelian randomization analysis, it is highly implausible that all the genetic variants satisfy the instrumental variable assumptions. This means that a simple instrumental variable analysis alone should not be relied on to give a causal conclusion. In this article, we discuss a range of sensitivity analyses that will either support or question the validity of causal inference from a Mendelian randomization analysis with multiple genetic variants. We focus on sensitivity analyses of greatest practical relevance for ensuring robust causal inferences, and those that can be undertaken using summarized data. Aside from cases in which the justification of the instrumental variable assumptions is supported by strong biological understanding, a Mendelian randomization analysis in which no assessment of the robustness of the findings to violations of the instrumental variable assumptions has been made should be viewed as speculative and incomplete. In particular, Mendelian randomization investigations with large numbers of genetic variants without such sensitivity analyses should be treated with skepticism.},
	language = {en-US},
	number = {1},
	urldate = {2020-03-19},
	journal = {Epidemiology},
	author = {Burgess, Stephen and Bowden, Jack and Fall, Tove and Ingelsson, Erik and Thompson, Simon G.},
	month = jan,
	year = {2017},
	pages = {30--42},
}

@article{rimm_prospective_1995,
	title = {Prospective study of cigarette smoking, alcohol use, and the risk of diabetes in men},
	volume = {310},
	copyright = {© 1995 BMJ Publishing Group Ltd.},
	issn = {0959-8138, 1468-5833},
	url = {https://www.bmj.com/content/310/6979/555},
	doi = {10.1136/bmj.310.6979.555},
	abstract = {Objective: To examine the association between smoking, alcohol consumption, and the incidence of non-insulin dependent diabetes mellitus in men of middle years and older.
Design: Cohort questionnaire study of men followed up for six years from 1986.
Setting: The health professionals' follow up study being conducted across the United States.
Subjects: 41810 male health professionals aged 40-75 years and free of diabetes, cardiovascular disease, and cancer in 1986 and followed up for six years.
Main outcome measure: Incidence of non-insulin dependent diabetes mellitus diagnosed in the six years.
Results: During 230 769 person years of follow up 509 men were newly diagnosed with diabetes. After controlling for known risk factors men who smoked 25 or more cigarettes daily had a relative risk of diabetes of 1.94 (95\% confidence interval 1.25 to 3.03) compared with non-smokers. Men who consumed higher amounts of alcohol had a reduced risk of diabetes (P for trend {\textless}0.001). Compared with abstainers men who drank 30.0-49.9 g of alcohol daily had a relative risk of diabetes of 0.61 (95\% confidence interval 0.44 to 0.91).
Conclusions: Cigarette smoking may be an independent, modifiable risk factor for non-insulin dependent diabetes mellitus. Moderate alcohol consumption among healthy people may be associated with increased insulin sensitivity and a reduced risk of diabetes.

Key messages Key messagesEpidemiological studies have not adequately examined the independent associations between smoking, alcohol, and the risk of diabetes after accounting for obesityThis paper shows that current smoking roughly doubles the risk of diabetes among a healthy population of menModerate alcohol consumption, however, significantly decreases the risk of diabetesSmoking and alcohol may alter the risk of diabetes through long term effects on insulin secretion and insulin resistance},
	language = {en},
	number = {6979},
	urldate = {2020-03-18},
	journal = {BMJ},
	author = {Rimm, Eric B. and Chan, June and Stampfer, Meir J. and Colditz, Graham A. and Willett, Walter C.},
	month = mar,
	year = {1995},
	pmid = {7888928},
	note = {Publisher: British Medical Journal Publishing Group
Section: Paper},
	pages = {555--559},
}

@article{will_cigarette_2001,
	title = {Cigarette smoking and diabetes mellitus: evidence of a positive association from a large prospective cohort study},
	volume = {30},
	issn = {0300-5771},
	shorttitle = {Cigarette smoking and diabetes mellitus},
	url = {https://academic.oup.com/ije/article/30/3/540/736926},
	doi = {10.1093/ije/30.3.540},
	abstract = {Abstract.  Objective Only a few prospective studies have examined the relationship between the frequency of cigarette smoking and the incidence of diabetes mell},
	language = {en},
	number = {3},
	urldate = {2020-03-18},
	journal = {International Journal of Epidemiology},
	author = {Will, Julie C. and Galuska, Deborah A. and Ford, Earl S. and Mokdad, Ali and Calle, Eugenia E.},
	month = jun,
	year = {2001},
	note = {Publisher: Oxford Academic},
	pages = {540--546},
}

@article{willi_active_2007,
	title = {Active {Smoking} and the {Risk} of {Type} 2 {Diabetes}: {A} {Systematic} {Review} and {Meta}-analysis},
	volume = {298},
	issn = {0098-7484},
	shorttitle = {Active {Smoking} and the {Risk} of {Type} 2 {Diabetes}},
	url = {https://jamanetwork.com/journals/jama/fullarticle/209729},
	doi = {10.1001/jama.298.22.2654},
	abstract = {ContextObservational studies have suggested an association between active smoking and the incidence of type 2 diabetes.ObjectiveTo conduct a systematic review with meta-analysis of studies assessing the association between active smoking and incidence of type 2 diabetes.Data SourcesA search of MEDLINE (1966 to May 2007) and EMBASE (1980 to May 2007) databases was supplemented by manual searches of bibliographies of key retrieved articles, reviews of abstracts from scientific meetings, and contact with experts.Study SelectionStudies were included if they reported risk of impaired fasting glucose, impaired glucose tolerance, or type 2 diabetes in relationship to smoking status at baseline; had a cohort design; and excluded persons with diabetes at baseline.Data Extraction and Data SynthesisTwo authors independently extracted the data, including the presence or absence of active smoking at baseline, the risk of diabetes, methods used to detect diabetes, and key criteria of study quality. Relative risks (RRs) were pooled using a random-effects model. Associations were tested in subgroups representing different patient characteristics and study quality criteria.ResultsThe search yielded 25 prospective cohort studies (N = 1.2 million participants) that reported 45 844 incident cases of diabetes during a study follow-up period ranging from 5 to 30 years. Of the 25 studies, 24 reported adjusted RRs greater than 1 (range for all studies, 0.82-3.74). The pooled adjusted RR was 1.44 (95\% confidence interval [CI], 1.31-1.58). Results were consistent and statistically significant in all subgroups. The risk of diabetes was greater for heavy smokers (≥20 cigarettes/day; RR, 1.61; 95\% CI, 1.43-1.80) than for lighter smokers (RR,1.29; 95\% CI, 1.13-1.48) and lower for former smokers (RR, 1.23; 95\% CI, 1.14-1.33) compared with active smokers, consistent with a dose-response phenomenon.ConclusionActive smoking is associated with an increased risk of type 2 diabetes. Future research should attempt to establish whether this association is causal and to clarify its mechanisms.},
	language = {en},
	number = {22},
	urldate = {2020-03-18},
	journal = {JAMA},
	author = {Willi, Carole and Bodenmann, Patrick and Ghali, William A. and Faris, Peter D. and Cornuz, Jacques},
	month = dec,
	year = {2007},
	note = {Publisher: American Medical Association},
	pages = {2654--2664},
}

@book{chollet_keras_2015,
	title = {Keras},
	url = {https://keras.io},
	author = {Chollet, François and {others}},
	year = {2015},
}

@article{van_rheenen_genetic_2019,
	title = {Genetic correlations of polygenic disease traits: from theory to practice},
	volume = {20},
	copyright = {2019 Springer Nature Limited},
	issn = {1471-0064},
	shorttitle = {Genetic correlations of polygenic disease traits},
	url = {https://www.nature.com/articles/s41576-019-0137-z},
	doi = {10.1038/s41576-019-0137-z},
	abstract = {In this Review, van Rheenen et al. outline how improved methodologies have enabled genetic correlations to be estimated for almost any trait pair. Genetic correlations can improve our understanding of the shared biology and causal relationships between traits.},
	language = {en},
	number = {10},
	urldate = {2020-03-12},
	journal = {Nature Reviews Genetics},
	author = {van Rheenen, Wouter and Peyrot, Wouter J. and Schork, Andrew J. and Lee, S. Hong and Wray, Naomi R.},
	month = oct,
	year = {2019},
	note = {Number: 10
Publisher: Nature Publishing Group},
	pages = {567--581},
}

@article{artzi_prediction_2020,
	title = {Prediction of gestational diabetes based on nationwide electronic health records},
	volume = {26},
	copyright = {2020 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-170X},
	url = {https://www.nature.com/articles/s41591-019-0724-8},
	doi = {10.1038/s41591-019-0724-8},
	abstract = {Leveraging the availability of nationwide electronic health records from over 500,000 pregnancies in Israel, a machine-learning approach offers an alternative means of predicting gestational diabetes at high accuracy in the early stages of pregnancy.},
	language = {en},
	number = {1},
	urldate = {2020-03-10},
	journal = {Nature Medicine},
	author = {Artzi, Nitzan Shalom and Shilo, Smadar and Hadar, Eran and Rossman, Hagai and Barbash-Hazan, Shiri and Ben-Haroush, Avi and Balicer, Ran D. and Feldman, Becca and Wiznitzer, Arnon and Segal, Eran},
	month = jan,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {71--76},
}

@article{hyland_early_2020,
	title = {Early prediction of circulatory failure in the intensive care unit using machine learning},
	copyright = {2020 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-170X},
	url = {https://www.nature.com/articles/s41591-020-0789-4},
	doi = {10.1038/s41591-020-0789-4},
	abstract = {A machine-learning algorithm based on an array of demographic, physiological and clinical information is able to predict, hours in advance, circulatory failure of patients in the intensive-care unit.},
	language = {en},
	urldate = {2020-03-10},
	journal = {Nature Medicine},
	author = {Hyland, Stephanie L. and Faltys, Martin and Hüser, Matthias and Lyu, Xinrui and Gumbsch, Thomas and Esteban, Cristóbal and Bock, Christian and Horn, Max and Moor, Michael and Rieck, Bastian and Zimmermann, Marc and Bodenham, Dean and Borgwardt, Karsten and Rätsch, Gunnar and Merz, Tobias M.},
	month = mar,
	year = {2020},
	note = {Publisher: Nature Publishing Group},
	pages = {1--10},
}

@article{paik_tracing_2019,
	title = {Tracing diagnosis trajectories over millions of patients reveal an unexpected risk in schizophrenia},
	volume = {6},
	copyright = {2019 The Author(s)},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/s41597-019-0220-5},
	doi = {10.1038/s41597-019-0220-5},
	abstract = {The identification of novel disease associations using big-data for patient care has had limited success. In this study, we created a longitudinal disease network of traced readmissions (disease trajectories), merging data from over 10.4 million inpatients through the Healthcare Cost and Utilization Project, which allowed the representation of disease progression mapping over 300 diseases. From these disease trajectories, we discovered an interesting association between schizophrenia and rhabdomyolysis, a rare muscle disease (incidence {\textless} 1E-04) (relative risk, 2.21 [1.80–2.71, confidence interval = 0.95], P-value 9.54E-15). We validated this association by using independent electronic medical records from over 830,000 patients at the University of California, San Francisco (UCSF) medical center. A case review of 29 rhabdomyolysis incidents in schizophrenia patients at UCSF demonstrated that 62\% are idiopathic, without the use of any drug known to lead to this adverse event, suggesting a warning to physicians to watch for this unexpected risk of schizophrenia. Large-scale analysis of disease trajectories can help physicians understand potential sequential events in their patients.},
	language = {en},
	number = {1},
	urldate = {2020-03-10},
	journal = {Scientific Data},
	author = {Paik, Hyojung and Kan, Matthew J. and Rappoport, Nadav and Hadley, Dexter and Sirota, Marina and Chen, Bin and Manber, Udi and Cho, Seong Beom and Butte, Atul J.},
	month = oct,
	year = {2019},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {1--10},
}

@article{rosnati_mgp-atttcn_2019,
	title = {{MGP}-{AttTCN}: {An} {Interpretable} {Machine} {Learning} {Model} for the {Prediction} of {Sepsis}},
	shorttitle = {{MGP}-{AttTCN}},
	url = {http://arxiv.org/abs/1909.12637},
	abstract = {With a mortality rate of 5.4 million lives worldwide every year and a healthcare cost of more than 16 billion dollars in the USA alone, sepsis is one of the leading causes of hospital mortality and an increasing concern in the ageing western world. Recently, medical and technological advances have helped re-define the illness criteria of this disease, which is otherwise poorly understood by the medical society. Together with the rise of widely accessible Electronic Health Records, the advances in data mining and complex nonlinear algorithms are a promising avenue for the early detection of sepsis. This work contributes to the research effort in the field of automated sepsis detection with an open-access labelling of the medical MIMIC-III data set. Moreover, we propose MGP-AttTCN: a joint multitask Gaussian Process and attention-based deep learning model to early predict the occurrence of sepsis in an interpretable manner. We show that our model outperforms the current state-of-the-art and present evidence that different labelling heuristics lead to discrepancies in task difficulty.},
	urldate = {2020-03-05},
	journal = {arXiv:1909.12637 [cs, stat]},
	author = {Rosnati, Margherita and Fortuin, Vincent},
	month = sep,
	year = {2019},
	note = {arXiv: 1909.12637},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{fortuin_gp-vae_2020,
	title = {{GP}-{VAE}: {Deep} {Probabilistic} {Time} {Series} {Imputation}},
	shorttitle = {{GP}-{VAE}},
	url = {http://arxiv.org/abs/1907.04155},
	abstract = {Multivariate time series with missing values are common in areas such as healthcare and finance, and have grown in number and complexity over the years. This raises the question whether deep learning methodologies can outperform classical data imputation methods in this domain. However, naive applications of deep learning fall short in giving reliable confidence estimates and lack interpretability. We propose a new deep sequential latent variable model for dimensionality reduction and data imputation. Our modeling assumption is simple and interpretable: the high dimensional time series has a lower-dimensional representation which evolves smoothly in time according to a Gaussian process. The non-linear dimensionality reduction in the presence of missing data is achieved using a VAE approach with a novel structured variational approximation. We demonstrate that our approach outperforms several classical and deep learning-based data imputation methods on high-dimensional data from the domains of computer vision and healthcare, while additionally improving the smoothness of the imputations and providing interpretable uncertainty estimates.},
	urldate = {2020-03-05},
	journal = {arXiv:1907.04155 [cs, stat]},
	author = {Fortuin, Vincent and Baranchuk, Dmitry and Rätsch, Gunnar and Mandt, Stephan},
	month = feb,
	year = {2020},
	note = {arXiv: 1907.04155},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{milletari_v-net_2016,
	title = {V-{Net}: {Fully} {Convolutional} {Neural} {Networks} for {Volumetric} {Medical} {Image} {Segmentation}},
	shorttitle = {V-{Net}},
	url = {http://arxiv.org/abs/1606.04797},
	abstract = {Convolutional Neural Networks (CNNs) have been recently employed to solve problems from both the computer vision and medical image analysis fields. Despite their popularity, most approaches are only able to process 2D images while most medical data used in clinical practice consists of 3D volumes. In this work we propose an approach to 3D image segmentation based on a volumetric, fully convolutional, neural network. Our CNN is trained end-to-end on MRI volumes depicting prostate, and learns to predict segmentation for the whole volume at once. We introduce a novel objective function, that we optimise during training, based on Dice coefficient. In this way we can deal with situations where there is a strong imbalance between the number of foreground and background voxels. To cope with the limited number of annotated volumes available for training, we augment the data applying random non-linear transformations and histogram matching. We show in our experimental evaluation that our approach achieves good performances on challenging test data while requiring only a fraction of the processing time needed by other previous methods.},
	urldate = {2020-03-04},
	journal = {arXiv:1606.04797 [cs]},
	author = {Milletari, Fausto and Navab, Nassir and Ahmadi, Seyed-Ahmad},
	month = jun,
	year = {2016},
	note = {arXiv: 1606.04797},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{virtanen_scipy_2020,
	title = {{SciPy} 1.0: fundamental algorithms for scientific computing in {Python}},
	volume = {17},
	copyright = {2020 The Author(s)},
	issn = {1548-7105},
	shorttitle = {{SciPy} 1.0},
	url = {https://www.nature.com/articles/s41592-019-0686-2},
	doi = {10.1038/s41592-019-0686-2},
	abstract = {This Perspective describes the development and capabilities of SciPy 1.0, an open source scientific computing library for the Python programming language.},
	language = {en},
	number = {3},
	urldate = {2020-03-04},
	journal = {Nature Methods},
	author = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and Haberland, Matt and Reddy, Tyler and Cournapeau, David and Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and Bright, Jonathan and van der Walt, Stéfan J. and Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and Kern, Robert and Larson, Eric and Carey, C. J. and Polat, İlhan and Feng, Yu and Moore, Eric W. and VanderPlas, Jake and Laxalde, Denis and Perktold, Josef and Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and Harris, Charles R. and Archibald, Anne M. and Ribeiro, Antônio H. and Pedregosa, Fabian and van Mulbregt, Paul},
	month = mar,
	year = {2020},
	note = {Number: 3
Publisher: Nature Publishing Group},
	pages = {261--272},
}

@article{maheshwari_relationship_2018,
	title = {The relationship between {ICU} hypotension and in-hospital mortality and morbidity in septic patients},
	volume = {44},
	issn = {1432-1238},
	url = {https://doi.org/10.1007/s00134-018-5218-5},
	doi = {10.1007/s00134-018-5218-5},
	abstract = {Current guidelines recommend maintaining a mean arterial pressure (MAP) ≥ 65 mmHg in septic patients. However, the relationship between hypotension and major complications in septic patients remains unclear. We, therefore, evaluated associations of MAPs below various thresholds and in-hospital mortality, acute kidney injury (AKI), and myocardial injury.},
	language = {en},
	number = {6},
	urldate = {2020-02-28},
	journal = {Intensive Care Medicine},
	author = {Maheshwari, Kamal and Nathanson, Brian H. and Munson, Sibyl H. and Khangulov, Victor and Stevens, Mitali and Badani, Hussain and Khanna, Ashish K. and Sessler, Daniel I.},
	month = jun,
	year = {2018},
	pages = {857--867},
}

@article{fincke_cardiac_2004,
	title = {Cardiac power is the strongest hemodynamic correlate of mortality in cardiogenic shock: {A} report from the {SHOCK} trial registry},
	volume = {44},
	copyright = {American College of Cardiology Foundation},
	issn = {0735-1097, 1558-3597},
	shorttitle = {Cardiac power is the strongest hemodynamic correlate of mortality in cardiogenic shock},
	url = {http://www.onlinejacc.org/content/44/2/340},
	doi = {10.1016/j.jacc.2004.03.060},
	abstract = {Objectives We sought to analyze clinical, angiographic, and outcome correlates of hemodynamic parameters in cardiogenic shock.
Background The significance of right heart catheterization in critically ill patients is controversial, despite the prognostic importance of the derived measurements. Cardiac power is a novel hemodynamic parameter.
Methods A total of 541 patients with cardiogenic shock who were enrolled in the SHould we emergently revascularize Occluded Coronaries for cardiogenic shocK (SHOCK) trial registry were included. Cardiac power output (CPO) (W) was calculated as mean arterial pressure × cardiac output/451.
Results On univariate analysis, CPO, cardiac power index (CPI), cardiac output, cardiac index, stroke volume, left ventricular work, left ventricular work index, stroke work, mean arterial pressure, systolic and diastolic blood pressure (all p {\textless} 0.001), coronary perfusion pressure (p = 0.002), ejection fraction (p = 0.013), and pulmonary artery systolic pressure (p = 0.047) were associated with in-hospital mortality. In separate multivariate analyses, CPO (odds ratio per 0.20 W: 0.60 [95\% confidence interval, 0.44 to 0.83], p = 0.002; n = 181) and CPI (odds ratio per 0.10 W/m2: 0.65 [95\% confidence interval, 0.48 to 0.87], p = 0.004; n = 178) remained the strongest independent hemodynamic correlates of in-hospital mortality after adjusting for age and history of hypertension. There was an inverse correlation between CPI and age (correlation coefficient: −0.334, p {\textless} 0.001). Women had a lower CPI than men (0.29 ± 0.11 vs. 0.35 ± 0.15 W/m2, p = 0.005). After adjusting for age, female gender remained associated with CPI (p = 0.032).
Conclusions Cardiac power is the strongest independent hemodynamic correlate of in-hospital mortality in patients with cardiogenic shock. Increasing age and female gender are independently associated with lower cardiac power.},
	language = {en},
	number = {2},
	urldate = {2020-02-27},
	journal = {Journal of the American College of Cardiology},
	author = {Fincke, Rupert and Hochman, Judith S. and Lowe, April M. and Menon, Venu and Slater, James N. and Webb, John G. and LeJemtel, Thierry H. and Cotter, Gad and Investigators, Shock},
	month = jul,
	year = {2004},
	note = {Publisher: Journal of the American College of Cardiology
Section: Clinical research: cardiogenic shock},
	pages = {340--348},
}

@article{saugel_non-invasive_2013,
	title = {Non-invasive continuous arterial pressure measurement based on radial artery tonometry in the intensive care unit: a method comparison study using the {T}-{Line} {TL}-200pro device},
	volume = {111},
	issn = {1471-6771},
	shorttitle = {Non-invasive continuous arterial pressure measurement based on radial artery tonometry in the intensive care unit},
	doi = {10.1093/bja/aet025},
	abstract = {BACKGROUND: The T-Line TL-200pro (TL-200pro) device (Tensys Medical, Inc., San Diego, CA, USA), based on radial artery tonometry, provides an arterial pressure (AP) waveform and beat-to-beat values of systolic arterial pressure (SAP), mean arterial pressure (MAP), and diastolic arterial pressure (DAP). The aim of the study was to evaluate this non-invasive technique for continuous AP monitoring in medical intensive care unit (ICU) patients.
METHODS: Arterial pressure measurements obtained using the TL-200pro technology were compared using Bland-Altman analysis with values measured directly from a femoral arterial catheter in 34 ICU patients.
RESULTS: Arterial pressure values were analysed and compared in 4502 averaged 10-beat epochs. A bias of +0.72 mm Hg (95\% limits of agreement -9.37 to +10.82 mm Hg) was observed for MAP. For SAP and DAP, there was a mean difference of -1.39 mm Hg (95\% limits of agreement -18.74 to +15.96 mm Hg) and +4.36 mm Hg (95\% limits of agreement -8.66 to +17.38 mm Hg), respectively. The percentage error for MAP, SAP, and DAP was 12\%, 14\%, and 21\%, respectively.
CONCLUSIONS: Arterial pressure measurement based on radial artery tonometry using the TL-200pro technology is feasible in medical ICU patients. The TL-200pro system is capable of providing MAP values with high accuracy (low mean difference) and precision (narrow limits of agreement) compared with MAP measured invasively using a femoral arterial catheter. The TL-200pro technology is promising for the measurement of SAP and DAP but further development is necessary to improve accuracy and precision.},
	language = {eng},
	number = {2},
	journal = {British Journal of Anaesthesia},
	author = {Saugel, B. and Meidert, A. S. and Hapfelmeier, A. and Eyer, F. and Schmid, R. M. and Huber, W.},
	month = aug,
	year = {2013},
	pmid = {23491946},
	keywords = {Aged, Blood Pressure, Blood Pressure Determination, Blood Pressure Monitors, Critical Care, Female, Humans, Intensive Care Units, Male, Manometry, Middle Aged, Monitoring, Physiologic, Radial Artery, arterial pressure, measurement, measurement techniques, arterial pressure, monitoring, intensive care},
	pages = {185--190},
}

@article{monk_association_2015,
	title = {Association between {Intraoperative} {Hypotension} and {Hypertension} and 30-day {Postoperative} {Mortality} in {Noncardiac} {Surgery}},
	volume = {123},
	issn = {0003-3022},
	url = {https://anesthesiology.pubs.asahq.org/article.aspx?articleid=2343033},
	doi = {10.1097/ALN.0000000000000756},
	abstract = {Abstract  Background:
     Although deviations in intraoperative blood pressure are assumed to be associated with postoperative mortality, critical blood pressure thresholds remain undefined. Therefore, the authors estimated the intraoperative thresholds of systolic blood pressure (SBP), mean blood pressure (MAP), and diastolic blood pressure (DBP) associated with ...},
	language = {en},
	number = {2},
	urldate = {2020-02-27},
	journal = {Anesthesiology: The Journal of the American Society of Anesthesiologists},
	author = {Monk, Terri G. and Bronsert, Michael R. and Henderson, William G. and Mangione, Michael P. and Sum-Ping, S. T. John and Bentt, Deyne R. and Nguyen, Jennifer D. and Richman, Joshua S. and Meguid, Robert A. and Hammermeister, Karl E.},
	month = aug,
	year = {2015},
	note = {Publisher: The American Society of Anesthesiologists},
	pages = {307--319},
}

@article{mendoza_cardiac_2007,
	title = {Cardiac power output predicts mortality across a broad spectrum of patients with acute cardiac disease},
	volume = {153},
	issn = {1097-6744},
	doi = {10.1016/j.ahj.2006.11.014},
	abstract = {BACKGROUND: Cardiac power output (CPO) is a novel hemodynamic measurement that represents cardiac pumping ability. The prognostic value of CPO in a broad spectrum of patients with acute cardiac disease undergoing pulmonary artery catheterization (PAC) has not been examined.
METHODS: Consecutive patients with a primary cardiac diagnosis who were undergoing PAC in a single coronary care unit were included. The relationship between initial CPO [(mean arterial pressure x cardiac output [CO])/451] and inhospital mortality was evaluated. CPO was analyzed both as a dichotomous variable (using a cutoff value previously established among patients with cardiogenic shock) and as a continuous variable.
RESULTS: Data were available for 349 patients. The mean CPO was 0.88 +/- 0.37 W. The inhospital mortality rate was significantly higher among patients with a CPO {\textless} or = 0.53 W (n = 53) compared with those with a CPO {\textgreater} 0.53 W (n = 296) (49\% vs 20\%, P {\textless} .001). In separate multivariate analyses, both CPO and CO were associated with inhospital mortality. However, when both terms were included simultaneously, CPO remained strongly associated with mortality (odds ratio 0.63, 95\% CI 0.43-0.91, P = .01), whereas CO did not (odds ratio 1.05, 95\% CI 0.75-1.48, P = .78).
CONCLUSIONS: Cardiac power output is a strong, independent predictor of inhospital mortality in a broad spectrum of patients with primary cardiac disease undergoing PAC.},
	language = {eng},
	number = {3},
	journal = {American Heart Journal},
	author = {Mendoza, Dorinna D. and Cooper, Howard A. and Panza, Julio A.},
	month = mar,
	year = {2007},
	pmid = {17307413},
	keywords = {Acute Disease, Aged, Cardiac Output, Female, Heart Diseases, Hospital Mortality, Humans, Logistic Models, Male, Middle Aged, Myocardial Infarction, Myocardial Ischemia, Prognosis, Prospective Studies, Retrospective Studies, Shock, Cardiogenic, Survival Analysis},
	pages = {366--370},
}

@article{marvao_artificial_2020,
	title = {Artificial intelligence and the cardiologist: what you need to know for 2020},
	volume = {106},
	copyright = {© Author(s) (or their employer(s)) 2020. Re-use permitted under CC BY. Published by BMJ.. https://creativecommons.org/licenses/by/4.0/This is an open access article distributed in accordance with the Creative Commons Attribution 4.0 Unported (CC BY 4.0) license, which permits others to copy, redistribute, remix, transform and build upon this work for any purpose, provided the original work is properly cited, a link to the licence is given, and indication of whether changes were made. See: https://creativecommons.org/licenses/by/4.0/.},
	issn = {1355-6037, 1468-201X},
	shorttitle = {Artificial intelligence and the cardiologist},
	url = {https://heart.bmj.com/content/106/5/399},
	doi = {10.1136/heartjnl-2019-316033},
	abstract = {We live in an era with unprecedented availability of clinical and biological data that include electronic health records, wearable sensors, biomedical imaging and multiomics. The scale, complexity and rate at which such data are collected require innovative approaches to statistics and computer science that draw on the rapid advances in artificial intelligence (AI) for efficiently identifying actionable insights into disease processes. A basic understanding of AI’s strengths, applications and limitations is now essential for researchers and clinical cardiologists.

In this context, AI refers to a collection of computational concepts that can be summarised as a machine’s ability to generalise learning in order to efficiently achieve complex tasks autonomously. Machine learning (ML) achieves this by using algorithms to improve task performance without needing to be explicitly programmed and can be broadly divided into supervised and unsupervised approaches. In supervised learning, the mapping between paired input and output variables is iteratively optimised for use in regression and classification tasks. In unsupervised learning, only input data are available and algorithms are used to find inherent clusters or associations. In recent years, ML has become dominated by deep learning (DL), which is a methodology using multilayer neural networks to progressively obtain more abstract representations of complex data. Figure 1 provides a high-level schematic of the field of AI.



Figure 1 
Artificial Intelligence through time.



A DL algorithm consists of three types of layer: an input layer, hidden layers …},
	language = {en},
	number = {5},
	urldate = {2020-02-27},
	journal = {Heart},
	author = {Marvao, Antonio de and Dawes, Timothy JW and Howard, James Philip and O'Regan, Declan P.},
	month = mar,
	year = {2020},
	pmid = {31974212},
	note = {Publisher: BMJ Publishing Group Ltd and British Cardiovascular Society
Section: Cardiology in focus},
	pages = {399--400},
}

@article{esper_arterial_2014,
	title = {Arterial waveform analysis},
	volume = {28},
	issn = {15216896},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1521689614000718},
	doi = {10.1016/j.bpa.2014.08.002},
	language = {en},
	number = {4},
	urldate = {2020-02-25},
	journal = {Best Practice \& Research Clinical Anaesthesiology},
	author = {Esper, Stephen A. and Pinsky, Michael R.},
	month = dec,
	year = {2014},
	pages = {363--380},
}

@article{lehman_methods_2013,
	title = {Methods of {Blood} {Pressure} {Measurement} in the {ICU}},
	volume = {41},
	issn = {0090-3493},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3724452/},
	doi = {10.1097/CCM.0b013e318265ea46},
	abstract = {Objective
Minimal clinical research has investigated the significance of different blood pressure monitoring techniques in the ICU and whether systolic vs. mean blood pressures should be targeted in therapeutic protocols and in defining clinical study cohorts. The objectives of this study are to compare real-world invasive arterial blood pressure with noninvasive blood pressure, and to determine if differences between the two techniques have clinical implications.

Design
We conducted a retrospective study comparing invasive arterial blood pressure and noninvasive blood pressure measurements using a large ICU database. We performed pairwise comparison between concurrent measures of invasive arterial blood pressure and noninvasive blood pressure. We studied the association of systolic and mean invasive arterial blood pressure and noninvasive blood pressure with acute kidney injury, and with ICU mortality.

Setting
Adult intensive care units at a tertiary care hospital.

Patients
Adult patients admitted to intensive care units between 2001 and 2007.

Interventions
None.

Measurements and Main Results
Pairwise analysis of 27,022 simultaneously measured invasive arterial blood pressure/noninvasive blood pressure pairs indicated that noninvasive blood pressure overestimated systolic invasive arterial blood pressure during hypotension. Analysis of acute kidney injury and ICU mortality involved 1,633 and 4,957 patients, respectively. Our results indicated that hypotensive systolic noninvasive blood pressure readings were associated with a higher acute kidney injury prevalence (p = 0.008) and ICU mortality (p {\textless} 0.001) than systolic invasive arterial blood pressure in the same range (≤70 mm Hg). Noninvasive blood pressure and invasive arterial blood pressure mean arterial pressures showed better agreement; acute kidney injury prevalence (p = 0.28) and ICU mortality (p = 0.76) associated with hypotensive mean arterial pressure readings (≤60 mm Hg) were independent of measurement technique.

Conclusions
Clinically significant discrepancies exist between invasive and noninvasive systolic blood pressure measurements during hypotension. Mean blood pressure from both techniques may be interpreted in a consistent manner in assessing patients’ prognosis. Our results suggest that mean rather than systolic blood pressure is the preferred metric in the ICU to guide therapy. (Crit Care Med 2013;41:0–0)},
	number = {1},
	urldate = {2020-02-25},
	journal = {Critical care medicine},
	author = {Lehman, Li-wei H. and Saeed, Mohammed and Talmor, Daniel and Mark, Roger and Malhotra, Atul},
	month = jan,
	year = {2013},
	pmid = {23269127},
	pmcid = {PMC3724452},
	pages = {34--40},
}

@article{perbet_incidence_2015,
	title = {Incidence of and risk factors for severe cardiovascular collapse after endotracheal intubation in the {ICU}: a multicenter observational study},
	volume = {19},
	issn = {1364-8535},
	shorttitle = {Incidence of and risk factors for severe cardiovascular collapse after endotracheal intubation in the {ICU}},
	url = {https://doi.org/10.1186/s13054-015-0975-9},
	doi = {10.1186/s13054-015-0975-9},
	abstract = {Severe cardiovascular collapse (CVC) is a life-threatening complication after emergency endotracheal intubation (ETI) in the ICU. Many factors may interact with hemodynamic conditions during ETI, but no study to date has focused on factors associated with severe CVC occurrence. This study assessed the incidence of severe CVC after ETI in the ICU and analyzed the factors predictive of severe CVC.},
	language = {en},
	number = {1},
	urldate = {2020-02-24},
	journal = {Critical Care},
	author = {Perbet, Sebastien and De Jong, Audrey and Delmas, Julie and Futier, Emmanuel and Pereira, Bruno and Jaber, Samir and Constantin, Jean-Michel},
	month = jun,
	year = {2015},
	pages = {257},
}

@inproceedings{hanqing_cao_predicting_2008,
	title = {Predicting {ICU} hemodynamic instability using continuous multiparameter trends},
	doi = {10.1109/IEMBS.2008.4650037},
	abstract = {Background: Identifying hemodynamically unstable patients in a timely fashion in intensive care units (ICUs) is crucial because it can lead to earlier interventions and thus to potentially better patient outcomes. Current alert algorithms are typically limited to detecting dangerous conditions only after they have occurred and suffer from high false alert rates. Our objective was to predict hemodynamic instability at least two hours before a major clinical intervention (e.g., vasopressor administration), while maintaining a low false alert rate. Study population: From the MIMIC II database, containing ICU minute-by-minute heart rate (HR) and invasive arterial blood pressure (BP) monitoring trend data collected between 2001 and 2005, we identified 132 stable and 104 unstable patients that met our stability-instability criteria and had sufficient data points. Method: We first derived additional physiological parameters of shock index, rate pressure product, heart rate variability, and two measures of trending based on HR and BP. Then we developed 220 statistical features and systematically selected a small set to use for classification. We applied multi-variable logistic regression modeling to do classification and implemented validation via bootstrapping. Results: Area under receiver-operating curve (ROC) 0.83±0.03, sensitivity 0.75±0.06, and specificity 0.80±0.07; if the specificity is targeted at 0.90, then the sensitivity is 0.57±0.07. Based on our preliminary results, we conclude that the algorithms we developed using HR and BP trend data may provide a promising perspective toward reliable predictive alerts for hemodynamically unstable patients.},
	booktitle = {2008 30th {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society}},
	author = {Hanqing Cao and Eshelman, Larry and Chbat, Nicolas and Nielsen, Larry and Gross, Brian and Saeed, Mohammed},
	month = aug,
	year = {2008},
	note = {ISSN: 1558-4615},
	keywords = {Algorithms, Blood Pressure, Heart Rate, Hemodynamics, Humans, ICU intervention, Intensive Care Units, Monitoring, Physiologic, Multiparameter segment monitoring, Multiple Organ Failure, Neural Networks (Computer), ROC Curve, Regression Analysis, Reproducibility of Results, Sensitivity and Specificity, Software, Time Factors, hemodynamic deterioration, predictive alerts},
	pages = {3803--3806},
}

@article{selvaraju_grad-cam_2020,
	title = {Grad-{CAM}: {Visual} {Explanations} from {Deep} {Networks} via {Gradient}-{Based} {Localization}},
	volume = {128},
	issn = {1573-1405},
	shorttitle = {Grad-{CAM}},
	url = {https://doi.org/10.1007/s11263-019-01228-7},
	doi = {10.1007/s11263-019-01228-7},
	abstract = {We propose a technique for producing ‘visual explanations’ for decisions from a large class of Convolutional Neural Network (CNN)-based models, making them more transparent and explainable. Our approach—Gradient-weighted Class Activation Mapping (Grad-CAM), uses the gradients of any target concept (say ‘dog’ in a classification network or a sequence of words in captioning network) flowing into the final convolutional layer to produce a coarse localization map highlighting the important regions in the image for predicting the concept. Unlike previous approaches, Grad-CAM is applicable to a wide variety of CNN model-families: (1) CNNs with fully-connected layers (e.g.VGG), (2) CNNs used for structured outputs (e.g.captioning), (3) CNNs used in tasks with multi-modal inputs (e.g.visual question answering) or reinforcement learning, all without architectural changes or re-training. We combine Grad-CAM with existing fine-grained visualizations to create a high-resolution class-discriminative visualization, Guided Grad-CAM, and apply it to image classification, image captioning, and visual question answering (VQA) models, including ResNet-based architectures. In the context of image classification models, our visualizations (a) lend insights into failure modes of these models (showing that seemingly unreasonable predictions have reasonable explanations), (b) outperform previous methods on the ILSVRC-15 weakly-supervised localization task, (c) are robust to adversarial perturbations, (d) are more faithful to the underlying model, and (e) help achieve model generalization by identifying dataset bias. For image captioning and VQA, our visualizations show that even non-attention based models learn to localize discriminative regions of input image. We devise a way to identify important neurons through Grad-CAM and combine it with neuron names (Bau et al. in Computer vision and pattern recognition, 2017) to provide textual explanations for model decisions. Finally, we design and conduct human studies to measure if Grad-CAM explanations help users establish appropriate trust in predictions from deep networks and show that Grad-CAM helps untrained users successfully discern a ‘stronger’ deep network from a ‘weaker’ one even when both make identical predictions. Our code is available at https://github.com/ramprs/grad-cam/, along with a demo on CloudCV (Agrawal et al., in: Mobile cloud visual media computing, pp 265–290. Springer, 2015) (http://gradcam.cloudcv.org) and a video at http://youtu.be/COjUB9Izk6E.},
	language = {en},
	number = {2},
	urldate = {2020-02-24},
	journal = {International Journal of Computer Vision},
	author = {Selvaraju, Ramprasaath R. and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
	month = feb,
	year = {2020},
	pages = {336--359},
}

@article{porumb_precision_2020,
	title = {Precision {Medicine} and {Artificial} {Intelligence}: {A} {Pilot} {Study} on {Deep} {Learning} for {Hypoglycemic} {Events} {Detection} based on {ECG}},
	volume = {10},
	copyright = {2020 The Author(s)},
	issn = {2045-2322},
	shorttitle = {Precision {Medicine} and {Artificial} {Intelligence}},
	url = {https://www.nature.com/articles/s41598-019-56927-5},
	doi = {10.1038/s41598-019-56927-5},
	abstract = {Tracking the fluctuations in blood glucose levels is important for healthy subjects and crucial diabetic patients. Tight glucose monitoring reduces the risk of hypoglycemia, which can result in a series of complications, especially in diabetic patients, such as confusion, irritability, seizure and can even be fatal in specific conditions. Hypoglycemia affects the electrophysiology of the heart. However, due to strong inter-subject heterogeneity, previous studies based on a cohort of subjects failed to deploy electrocardiogram (ECG)-based hypoglycemic detection systems reliably. The current study used personalised medicine approach and Artificial Intelligence (AI) to automatically detect nocturnal hypoglycemia using a few heartbeats of raw ECG signal recorded with non-invasive, wearable devices, in healthy individuals, monitored 24 hours for 14 consecutive days. Additionally, we present a visualisation method enabling clinicians to visualise which part of the ECG signal (e.g., T-wave, ST-interval) is significantly associated with the hypoglycemic event in each subject, overcoming the intelligibility problem of deep-learning methods. These results advance the feasibility of a real-time, non-invasive hypoglycemia alarming system using short excerpts of ECG signal.},
	language = {en},
	number = {1},
	urldate = {2020-02-24},
	journal = {Scientific Reports},
	author = {Porumb, Mihaela and Stranges, Saverio and Pescapè, Antonio and Pecchia, Leandro},
	month = jan,
	year = {2020},
	pages = {1--16},
}

@article{levin_intraoperative_2015,
	title = {Intraoperative arterial blood pressure lability is associated with improved 30 day survival},
	volume = {115},
	issn = {0007-0912},
	url = {http://www.sciencedirect.com/science/article/pii/S0007091217310735},
	doi = {10.1093/bja/aev293},
	abstract = {Background
Arterial blood pressure lability, defined as rapid changes in arterial blood pressure, occurs commonly during anaesthesia. It is believed that hypertensive patients exhibit more lability during surgery and that lability is associated with poorer outcomes. Neither association has been rigorously tested. We hypothesized that hypertensive patients have more blood pressure lability and that increased lability is associated with increased 30 day mortality.
Methods
This was a retrospective single-centre study of surgical patients from July 2008 to December 2012. Intraoperative data were extracted from the electronic anaesthesia record. Lability was calculated as the modulus of the percentage change in mean arterial pressure between consecutive 5 min intervals. The number of episodes of lability {\textgreater}10\% was tabulated. Multivariate logistic regression was performed to determine the association between lability and 30 day mortality using derivation and validation cohorts.
Results
Inclusion criteria were met by 52 919 subjects. Of the derivation cohort, 53\% of subjects were hypertensive and 42\% used an antihypertensive medication. The median number of episodes of lability {\textgreater}10\% was 9 (interquartile range 5–14) per patient. Hypertensive subjects demonstrated more lability than normotensive patients, 10 (5–15) compared with 8 (5–12), P{\textless}0.0001. In subjects taking no antihypertensive medication, lability {\textgreater}10\% was associated with decreased 30 day mortality, odds ratio (OR) per episode 0.95 [95\% confidence interval (CI) 0.92–0.97], P{\textless}0.0001. This result was confirmed in the validation cohort, OR 0.96 (95\% CI 0.93–0.99), P=0.01, and in hypertensive patients taking no antihypertensive medication, OR 0.96 (95\% CI 0.93–0.99), P=0.002. Use of any antihypertensive medication class reduced this effect.
Conclusions
Intraoperative arterial blood pressure lability occurs more often in hypertensive patients. Contrary to common belief, increased lability was associated with decreased 30 day mortality.},
	language = {en},
	number = {5},
	urldate = {2020-02-21},
	journal = {British Journal of Anaesthesia},
	author = {Levin, M. A. and Fischer, G. W. and Lin, H. -M. and McCormick, P. J. and Krol, M. and Reich, D. L.},
	month = nov,
	year = {2015},
	keywords = {anaesthesia, anaesthesiology, blood pressure, haemodynamics, intraoperative period, perioperative period},
	pages = {716--726},
}

@article{furlotte_mixed-model_2011,
	title = {Mixed-model coexpression: calculating gene coexpression while accounting for expression heterogeneity},
	volume = {27},
	issn = {1367-4803},
	shorttitle = {Mixed-model coexpression},
	url = {https://academic.oup.com/bioinformatics/article/27/13/i288/179666},
	doi = {10.1093/bioinformatics/btr221},
	abstract = {Abstract.  Motivation: The analysis of gene coexpression is at the core of many types of genetic analysis. The coexpression between two genes can be calculated},
	language = {en},
	number = {13},
	urldate = {2020-02-20},
	journal = {Bioinformatics},
	author = {Furlotte, Nicholas A. and Kang, Hyun Min and Ye, Chun and Eskin, Eleazar},
	month = jul,
	year = {2011},
	pages = {i288--i294},
}

@article{cliord_user_nodate,
	title = {User {Guide} and {Documentation} for the {MIMIC} {II} {Database}},
	language = {en},
	author = {Cliﬀord, Gari D and Scott, Daniel J and Villarroel, Mauricio},
	pages = {76},
}

@article{desai_comparison_2020,
	title = {Comparison of {Machine} {Learning} {Methods} {With} {Traditional} {Models} for {Use} of {Administrative} {Claims} {With} {Electronic} {Medical} {Records} to {Predict} {Heart} {Failure} {Outcomes}},
	volume = {3},
	url = {https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2758475},
	doi = {10.1001/jamanetworkopen.2019.18962},
	abstract = {{\textless}h3{\textgreater}Importance{\textless}/h3{\textgreater}{\textless}p{\textgreater}Accurate risk stratification of patients with heart failure (HF) is critical to deploy targeted interventions aimed at improving patients’ quality of life and outcomes.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Objectives{\textless}/h3{\textgreater}{\textless}p{\textgreater}To compare machine learning approaches with traditional logistic regression in predicting key outcomes in patients with HF and evaluate the added value of augmenting claims-based predictive models with electronic medical record (EMR)–derived information.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Design, Setting, and Participants{\textless}/h3{\textgreater}{\textless}p{\textgreater}A prognostic study with a 1-year follow-up period was conducted including 9502 Medicare-enrolled patients with HF from 2 health care provider networks in Boston, Massachusetts (“providers” includes physicians, clinicians, other health care professionals, and their institutions that comprise the networks). The study was performed from January 1, 2007, to December 31, 2014; data were analyzed from January 1 to December 31, 2018.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Main Outcomes and Measures{\textless}/h3{\textgreater}{\textless}p{\textgreater}All-cause mortality, HF hospitalization, top cost decile, and home days loss greater than 25\% were modeled using logistic regression, least absolute shrinkage and selection operation regression, classification and regression trees, random forests, and gradient-boosted modeling (GBM). All models were trained using data from network 1 and tested in network 2. After selecting the most efficient modeling approach based on discrimination, Brier score, and calibration, area under precision-recall curves (AUPRCs) and net benefit estimates from decision curves were calculated to focus on the differences when using claims-only vs claims + EMR predictors.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Results{\textless}/h3{\textgreater}{\textless}p{\textgreater}A total of 9502 patients with HF with a mean (SD) age of 78 (8) years were included: 6113 from network 1 (training set) and 3389 from network 2 (testing set). Gradient-boosted modeling consistently provided the highest discrimination, lowest Brier scores, and good calibration across all 4 outcomes; however, logistic regression had generally similar performance (C statistics for logistic regression based on claims-only predictors: mortality, 0.724; 95\% CI, 0.705-0.744; HF hospitalization, 0.707; 95\% CI, 0.676-0.737; high cost, 0.734; 95\% CI, 0.703-0.764; and home days loss claims only, 0.781; 95\% CI, 0.764-0.798; C statistics for GBM: mortality, 0.727; 95\% CI, 0.708-0.747; HF hospitalization, 0.745; 95\% CI, 0.718-0.772; high cost, 0.733; 95\% CI, 0.703-0.763; and home days loss, 0.790; 95\% CI, 0.773-0.807). Higher AUPRCs were obtained for claims + EMR vs claims-only GBMs predicting mortality (0.484 vs 0.423), HF hospitalization (0.413 vs 0.403), and home time loss (0.575 vs 0.521) but not cost (0.249 vs 0.252). The net benefit for claims + EMR vs claims-only GBMs was higher at various threshold probabilities for mortality and home time loss outcomes but similar for the other 2 outcomes.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Conclusions and Relevance{\textless}/h3{\textgreater}{\textless}p{\textgreater}Machine learning methods offered only limited improvement over traditional logistic regression in predicting key HF outcomes. Inclusion of additional predictors from EMRs to claims-based models appeared to improve prediction for some, but not all, outcomes.{\textless}/p{\textgreater}},
	language = {en},
	number = {1},
	urldate = {2020-02-19},
	journal = {JAMA Network Open},
	author = {Desai, Rishi J. and Wang, Shirley V. and Vaduganathan, Muthiah and Evers, Thomas and Schneeweiss, Sebastian},
	month = jan,
	year = {2020},
	pages = {e1918962--e1918962},
}

@article{brajer_prospective_2020,
	title = {Prospective and {External} {Evaluation} of a {Machine} {Learning} {Model} to {Predict} {In}-{Hospital} {Mortality} of {Adults} at {Time} of {Admission}},
	volume = {3},
	url = {https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2760438},
	doi = {10.1001/jamanetworkopen.2019.20733},
	abstract = {{\textless}h3{\textgreater}Importance{\textless}/h3{\textgreater}{\textless}p{\textgreater}The ability to accurately predict in-hospital mortality for patients at the time of admission could improve clinical and operational decision-making and outcomes. Few of the machine learning models that have been developed to predict in-hospital death are both broadly applicable to all adult patients across a health system and readily implementable. Similarly, few have been implemented, and none have been evaluated prospectively and externally validated.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Objectives{\textless}/h3{\textgreater}{\textless}p{\textgreater}To prospectively and externally validate a machine learning model that predicts in-hospital mortality for all adult patients at the time of hospital admission and to design the model using commonly available electronic health record data and accessible computational methods.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Design, Setting, and Participants{\textless}/h3{\textgreater}{\textless}p{\textgreater}In this prognostic study, electronic health record data from a total of 43 180 hospitalizations representing 31 003 unique adult patients admitted to a quaternary academic hospital (hospital A) from October 1, 2014, to December 31, 2015, formed a training and validation cohort. The model was further validated in additional cohorts spanning from March 1, 2018, to August 31, 2018, using 16 122 hospitalizations representing 13 094 unique adult patients admitted to hospital A, 6586 hospitalizations representing 5613 unique adult patients admitted to hospital B, and 4086 hospitalizations representing 3428 unique adult patients admitted to hospital C. The model was integrated into the production electronic health record system and prospectively validated on a cohort of 5273 hospitalizations representing 4525 unique adult patients admitted to hospital A between February 14, 2019, and April 15, 2019.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Main Outcomes and Measures{\textless}/h3{\textgreater}{\textless}p{\textgreater}The main outcome was in-hospital mortality. Model performance was quantified using the area under the receiver operating characteristic curve and area under the precision recall curve.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Results{\textless}/h3{\textgreater}{\textless}p{\textgreater}A total of 75 247 hospital admissions (median [interquartile range] patient age, 59.5 [29.0] years; 45.9\% involving male patients) were included in the study. The in-hospital mortality rates for the training validation; retrospective validations at hospitals A, B, and C; and prospective validation cohorts were 3.0\%, 2.7\%, 1.8\%, 2.1\%, and 1.6\%, respectively. The area under the receiver operating characteristic curves were 0.87 (95\% CI, 0.83-0.89), 0.85 (95\% CI, 0.83-0.87), 0.89 (95\% CI, 0.86-0.92), 0.84 (95\% CI, 0.80-0.89), and 0.86 (95\% CI, 0.83-0.90), respectively. The area under the precision recall curves were 0.29 (95\% CI, 0.25-0.37), 0.17 (95\% CI, 0.13-0.22), 0.22 (95\% CI, 0.14-0.31), 0.13 (95\% CI, 0.08-0.21), and 0.14 (95\% CI, 0.09-0.21), respectively.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Conclusions and Relevance{\textless}/h3{\textgreater}{\textless}p{\textgreater}Prospective and multisite retrospective evaluations of a machine learning model demonstrated good discrimination of in-hospital mortality for adult patients at the time of admission. The data elements, methods, and patient selection make the model implementable at a system level.{\textless}/p{\textgreater}},
	language = {en},
	number = {2},
	urldate = {2020-02-19},
	journal = {JAMA Network Open},
	author = {Brajer, Nathan and Cozzi, Brian and Gao, Michael and Nichols, Marshall and Revoir, Mike and Balu, Suresh and Futoma, Joseph and Bae, Jonathan and Setji, Noppon and Hernandez, Adrian and Sendak, Mark},
	month = feb,
	year = {2020},
	pages = {e1920733--e1920733},
}

@article{wijnberge_effect_2020,
	title = {Effect of a {Machine} {Learning}–{Derived} {Early} {Warning} {System} for {Intraoperative} {Hypotension} vs {Standard} {Care} on {Depth} and {Duration} of {Intraoperative} {Hypotension} {During} {Elective} {Noncardiac} {Surgery}: {The} {HYPE} {Randomized} {Clinical} {Trial}},
	shorttitle = {Effect of a {Machine} {Learning}–{Derived} {Early} {Warning} {System} for {Intraoperative} {Hypotension} vs {Standard} {Care} on {Depth} and {Duration} of {Intraoperative} {Hypotension} {During} {Elective} {Noncardiac} {Surgery}},
	url = {https://jamanetwork.com/journals/jama/fullarticle/2761469},
	doi = {10.1001/jama.2020.0592},
	abstract = {{\textless}h3{\textgreater}Importance{\textless}/h3{\textgreater}{\textless}p{\textgreater}Intraoperative hypotension is associated with increased morbidity and mortality. A machine learning–derived early warning system to predict hypotension shortly before it occurs has been developed and validated.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Objective{\textless}/h3{\textgreater}{\textless}p{\textgreater}To test whether the clinical application of the early warning system in combination with a hemodynamic diagnostic guidance and treatment protocol reduces intraoperative hypotension.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Design, Setting, and Participants{\textless}/h3{\textgreater}{\textless}p{\textgreater}Preliminary unblinded randomized clinical trial performed in a tertiary center in Amsterdam, the Netherlands, among adult patients scheduled for elective noncardiac surgery under general anesthesia and an indication for continuous invasive blood pressure monitoring, who were enrolled between May 2018 and March 2019. Hypotension was defined as a mean arterial pressure (MAP) below 65 mm Hg for at least 1 minute.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Interventions{\textless}/h3{\textgreater}{\textless}p{\textgreater}Patients were randomly assigned to receive either the early warning system (n = 34) or standard care (n = 34), with a goal MAP of at least 65 mm Hg in both groups.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Main Outcomes and Measures{\textless}/h3{\textgreater}{\textless}p{\textgreater}The primary outcome was time-weighted average of hypotension during surgery, with a unit of measure of millimeters of mercury. This was calculated as the depth of hypotension below a MAP of 65 mm Hg (in millimeters of mercury) × time spent below a MAP of 65 mm Hg (in minutes) divided by total duration of operation (in minutes).{\textless}/p{\textgreater}{\textless}h3{\textgreater}Results{\textless}/h3{\textgreater}{\textless}p{\textgreater}Among 68 randomized patients, 60 (88\%) completed the trial (median age, 64 [interquartile range \{IQR\}, 57-70] years; 26 [43\%] women). The median length of surgery was 256 minutes (IQR, 213-430 minutes). The median time-weighted average of hypotension was 0.10 mm Hg (IQR, 0.01-0.43 mm Hg) in the intervention group vs 0.44 mm Hg (IQR, 0.23-0.72 mm Hg) in the control group, for a median difference of 0.38 mm Hg (95\% CI, 0.14-0.43 mm Hg;\textit{P} = .001). The median time of hypotension per patient was 8.0 minutes (IQR, 1.33-26.00 minutes) in the intervention group vs 32.7 minutes (IQR, 11.5-59.7 minutes) in the control group, for a median difference of 16.7 minutes (95\% CI, 7.7-31.0 minutes;\textit{P} \&lt; .001). In the intervention group, 0 serious adverse events resulting in death occurred vs 2 (7\%) in the control group.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Conclusions and Relevance{\textless}/h3{\textgreater}{\textless}p{\textgreater}In this single-center preliminary study of patients undergoing elective noncardiac surgery, the use of a machine learning–derived early warning system compared with standard care resulted in less intraoperative hypotension. Further research with larger study populations in diverse settings is needed to understand the effect on additional patient outcomes and to fully assess safety and generalizability.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Trial Registration{\textless}/h3{\textgreater}{\textless}p{\textgreater}ClinicalTrials.gov Identifier:NCT03376347{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-02-19},
	journal = {JAMA},
	author = {Wijnberge, Marije and Geerts, Bart F. and Hol, Liselotte and Lemmers, Nikki and Mulder, Marijn P. and Berge, Patrick and Schenk, Jimmy and Terwindt, Lotte E. and Hollmann, Markus W. and Vlaar, Alexander P. and Veelo, Denise P.},
	month = feb,
	year = {2020},
}

@article{maheshwari_performance_2020,
	title = {Performance of the {Hypotension} {Prediction} {Index} with non-invasive arterial pressure waveforms in non-cardiac surgical patients},
	issn = {1573-2614},
	url = {https://doi.org/10.1007/s10877-020-00463-5},
	doi = {10.1007/s10877-020-00463-5},
	abstract = {An algorithm derived from machine learning uses the arterial waveform to predict intraoperative hypotension some minutes before episodes, possibly giving clinician’s time to intervene and prevent hypotension. Whether the Hypotension Prediction Index works well with noninvasive arterial pressure waveforms remains unknown. We therefore evaluated sensitivity, specificity, and positive predictive value of the Index based on non-invasive arterial waveform estimates. We used continuous hemodynamic data measured from ClearSight (formerly Nexfin) noninvasive finger blood pressure monitors in surgical patients. We re-evaluated data from a trial that included 320 adults ≥ 45 years old designated ASA physical status 3 or 4 who had moderate-to-high-risk non-cardiac surgery with general anesthesia. We calculated sensitivity and specificity for predicting hypotension, defined as mean arterial pressure ≤ 65 mmHg for at least 1 min, and characterized the relationship with receiver operating characteristics curves. We also evaluated the number of hypotensive events at various ranges of the Hypotension Prediction Index. And finally, we calculated the positive predictive value for hypotension episodes when the Prediction Index threshold was 85. The algorithm predicted hypotension 5 min in advance, with a sensitivity of 0.86 [95\% confidence interval 0.82, 0.89] and specificity 0.86 [0.82, 0.89]. At 10 min, the sensitivity was 0.83 [0.79, 0.86] and the specificity was 0.83 [0.79, 0.86]. And at 15 min, the sensitivity was 0.75 [0.71, 0.80] and the specificity was 0.75 [0.71, 0.80]. The positive predictive value of the algorithm prediction at an Index threshold of 85 was 0.83 [0.79, 0.87]. A Hypotension Prediction Index of 80–89 provided a median of 6.0 [95\% confidence interval 5.3, 6.7] minutes warning before mean arterial pressure decreased to {\textless} 65 mmHg. The Hypotension Prediction Index, which was developed and validated with invasive arterial waveforms, predicts intraoperative hypotension reasonably well from non-invasive estimates of the arterial waveform. Hypotension prediction, along with appropriate management, can potentially reduce intraoperative hypotension. Being able to use the non-invasive pressure waveform will widen the range of patients who might benefit.Clinical Trial Number: ClinicalTrials.gov NCT02872896.},
	language = {en},
	urldate = {2020-02-11},
	journal = {Journal of Clinical Monitoring and Computing},
	author = {Maheshwari, Kamal and Buddi, Sai and Jian, Zhongping and Settels, Jos and Shimada, Tetsuya and Cohen, Barak and Sessler, Daniel I. and Hatib, Feras},
	month = jan,
	year = {2020},
	keywords = {Hypotension Prediction Index, Hypotension prediction, Intraoperative hypotension, Machine learning, Non-invasive blood pressure},
}

@article{attia_screening_2019,
	title = {Screening for cardiac contractile dysfunction using an artificial intelligence–enabled electrocardiogram},
	volume = {25},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-170X},
	url = {https://www.nature.com/articles/s41591-018-0240-2},
	doi = {10.1038/s41591-018-0240-2},
	abstract = {A deep learning algorithm applied to the electrocardiogram—a test of the heart’s electrical activity—can detect abnormally low contractile function of the heart, opening up the possibility for a simple screening tool for this condition.},
	language = {en},
	number = {1},
	urldate = {2020-02-07},
	journal = {Nature Medicine},
	author = {Attia, Zachi I. and Kapa, Suraj and Lopez-Jimenez, Francisco and McKie, Paul M. and Ladewig, Dorothy J. and Satam, Gaurav and Pellikka, Patricia A. and Enriquez-Sarano, Maurice and Noseworthy, Peter A. and Munger, Thomas M. and Asirvatham, Samuel J. and Scott, Christopher G. and Carter, Rickey E. and Friedman, Paul A.},
	month = jan,
	year = {2019},
	pages = {70--74},
}

@article{minchole_artificial_2019,
	title = {Artificial intelligence for the electrocardiogram},
	volume = {25},
	copyright = {2019 Springer Nature America, Inc.},
	issn = {1546-170X},
	url = {https://www.nature.com/articles/s41591-018-0306-1},
	doi = {10.1038/s41591-018-0306-1},
	abstract = {Deep-learning algorithms can be applied to large datasets of electrocardiograms, are capable of identifying abnormal heart rhythms and mechanical dysfunction, and could aid healthcare decisions.},
	language = {en},
	number = {1},
	urldate = {2020-02-07},
	journal = {Nature Medicine},
	author = {Mincholé, Ana and Rodriguez, Blanca},
	month = jan,
	year = {2019},
	pages = {22--23},
}

@article{pearl_causal_nodate,
	title = {Causal diagrams for empirical research},
	abstract = {The primary aim of this paper is to show how graphical models can be used as a mathematical language for integrating statistical and subject-matter information. In particular, the paper develops a principled, nonparametric framework for causal inference, in which diagrams are queried to determine if the assumptions available are sufficient for identifying causal effects from nonexperimental data. If so the diagrams can be queried to produce mathematical expressions for causal effects in terms of observed distributions; otherwise, the diagrams can be queried to suggest additional observations or auxiliary experiments from which the desired inferences can be obtained.},
	language = {en},
	author = {Pearl, Judea},
	pages = {20},
}

@article{luo_guidelines_2016,
	title = {Guidelines for {Developing} and {Reporting} {Machine} {Learning} {Predictive} {Models} in {Biomedical} {Research}: {A} {Multidisciplinary} {View}},
	volume = {18},
	issn = {1438-8871},
	shorttitle = {Guidelines for {Developing} and {Reporting} {Machine} {Learning} {Predictive} {Models} in {Biomedical} {Research}},
	doi = {10.2196/jmir.5870},
	abstract = {BACKGROUND: As more and more researchers are turning to big data for new opportunities of biomedical discoveries, machine learning models, as the backbone of big data analysis, are mentioned more often in biomedical journals. However, owing to the inherent complexity of machine learning methods, they are prone to misuse. Because of the flexibility in specifying machine learning models, the results are often insufficiently reported in research articles, hindering reliable assessment of model validity and consistent interpretation of model outputs.
OBJECTIVE: To attain a set of guidelines on the use of machine learning predictive models within clinical settings to make sure the models are correctly applied and sufficiently reported so that true discoveries can be distinguished from random coincidence.
METHODS: A multidisciplinary panel of machine learning experts, clinicians, and traditional statisticians were interviewed, using an iterative process in accordance with the Delphi method.
RESULTS: The process produced a set of guidelines that consists of (1) a list of reporting items to be included in a research article and (2) a set of practical sequential steps for developing predictive models.
CONCLUSIONS: A set of guidelines was generated to enable correct application of machine learning models and consistent reporting of model specifications and results in biomedical research. We believe that such guidelines will accelerate the adoption of big data analysis, particularly with machine learning methods, in the biomedical research community.},
	language = {eng},
	number = {12},
	journal = {Journal of Medical Internet Research},
	author = {Luo, Wei and Phung, Dinh and Tran, Truyen and Gupta, Sunil and Rana, Santu and Karmakar, Chandan and Shilton, Alistair and Yearwood, John and Dimitrova, Nevenka and Ho, Tu Bao and Venkatesh, Svetha and Berk, Michael},
	year = {2016},
	pmid = {27986644},
	pmcid = {PMC5238707},
	keywords = {Biomedical Research, Data Interpretation, Statistical, Humans, Interdisciplinary Studies, Machine Learning, Models, Biological, clinical prediction rule, guideline, machine learning},
	pages = {e323},
}

@article{arik_tabnet_2019,
	title = {{TabNet}: {Attentive} {Interpretable} {Tabular} {Learning}},
	shorttitle = {{TabNet}},
	url = {http://arxiv.org/abs/1908.07442},
	abstract = {We propose a novel high-performance interpretable deep tabular data learning network, TabNet. TabNet utilizes a sequential attention mechanism that softly selects features to reason from at each decision step and then aggregates the processed information to make a final prediction decision. By explicitly selecting sparse features, TabNet learns very efficiently as the model capacity at each decision step is fully utilized for the most relevant features, resulting in a high performance model. This sparsity also enables more interpretable decision making through the visualization of feature selection masks. We demonstrate that TabNet outperforms other neural network and decision tree variants on a wide range of tabular data learning datasets and yields interpretable feature attributions and insights into the global model behavior.},
	urldate = {2020-02-03},
	journal = {arXiv:1908.07442 [cs, stat]},
	author = {Arik, Sercan O. and Pfister, Tomas},
	month = sep,
	year = {2019},
	note = {arXiv: 1908.07442},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{li_novel_2019,
	title = {A {Novel} {Method} for {Calibration}-{Based} {Cuff}-{Less} {Blood} {Pressure} {Estimation}},
	doi = {10.1109/EMBC.2019.8857373},
	abstract = {Cuff-less blood pressure estimation technology is useful for cardiovascular disease monitoring. However, without calibration, cuff-less blood pressure estimation is hard to achieve clinical acceptable performance. The traditional methods are always calibrated with retraining. With the increases of the parameters number, the cost of model retraining increases several times. So we propose a novel blood pressure estimation method, which can be calibrated with reference inputs rather than with retraining. The experiment results suggest that the method we proposed can achieve clinical performance (SBP:-0.004 ± 5.869 mmHg, DBP:-0.004±4.511 mmHg) with low calibration cost.},
	booktitle = {2019 41st {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society} ({EMBC})},
	author = {Li, Zhenqi and Yan, Cong and Zhao, Wei and Hu, Jing and Jia, Dongya and Wang, Hongmei and You, Tianyuan},
	month = jul,
	year = {2019},
	note = {ISSN: 1557-170X},
	keywords = {Biomedical monitoring, Blood pressure, Calibration, Convolution, Estimation, Feature extraction, Monitoring, biomedical equipment, blood, blood pressure estimation method, blood pressure measurement, calibration, calibration cost, calibration-based cuff-less blood pressure estimation, cardiovascular disease monitoring, cardiovascular system, clinical acceptable performance, clinical performance, cuff-less blood pressure estimation technology, diseases, medical signal processing, model retraining increases, patient monitoring},
	pages = {4266--4269},
}

@inproceedings{liu_cuff-less_2019,
	title = {Cuff-less {Blood} {Pressure} {Measurement} {Based} on {Deep} {Convolutional} {Neural} {Network}},
	doi = {10.1109/EMBC.2019.8856588},
	abstract = {Cuff-less blood pressure (BP) monitoring is increasingly being needed for cardiovascular events management in clinical. Many of the existing methods, however, are based on manual feature extraction, which cannot characterize the complex relationship between the physiological signals and BP. In this study, the 16-layer VGGNet was used to construct cuff-less BP from electrocardiogram (ECG) and pressure pulse wave (PPW) signals, with no need extract features from raw signals. The deep network architecture has the ability of automatic feature learning, and the learned features are the higher-level abstract description of low-level raw physiological signals. Eight-nine middle-aged and elderly subjects were enrolled to evaluate the performance of the proposed BP estimation method, with oscillometric technique-based BP as a reference. Experimental results indicate that the proposed method had a commendable accuracy in BP estimation, with a correlation coefficient of 0.91 and an estimation error of -2.06 ± 6.89 mmHg for systolic BP, and 0.89 and -4.66 ± 4.91 mmHg for diastolic BP. This study shows that the proposed method provided a potential novel insight for the cuff-less BP estimation.},
	booktitle = {2019 41st {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society} ({EMBC})},
	author = {Liu, ZengDing and Miao, Fen and Wang, Ruxin and Liu, Jikui and Wen, Bo and Li, Ye},
	month = jul,
	year = {2019},
	note = {ISSN: 1557-170X},
	keywords = {16-layer VGGNet, Biomedical monitoring, Convolutional Neural Network, Cuff-less Blood Pressure, Deep Learning, Deep learning, Electrocardiography, Estimation, Feature extraction, Monitoring, Standards, automatic feature learning, blood pressure estimation method, blood pressure measurement, cardiovascular event, cardiovascular system, convolutional neural nets, cuff-less blood pressure measurement, cuff-less blood pressure monitoring, deep convolutional neural network, deep network architecture, diastolic blood pressure, electrocardiogram, electrocardiography, feature extraction, learning (artificial intelligence), low-level raw physiological signals, medical signal processing, oscillometric technique-based blood pressure, patient monitoring, pressure pulse wave signal, systolic blood pressure},
	pages = {3775--3778},
}

@inproceedings{yan_novel_2019,
	title = {Novel {Deep} {Convolutional} {Neural} {Network} for {Cuff}-less {Blood} {Pressure} {Measurement} {Using} {ECG} and {PPG} {Signals}},
	doi = {10.1109/EMBC.2019.8857108},
	abstract = {Cuff-less blood pressure (BP) is a potential method for BP monitoring because it is undisturbed and continuous monitoring. Existing cuff-less estimation methods are easily influenced by signal noise and non-ideal signal morphology. In this study we propose a novel well-designed Convolutional Neural Network (CNN) model named Deep-BP for BP estimation task. The structure of Deep-BP can help to capture more underlying data features associated with BP than handcrafted features, thus improving the robustness and estimation accuracy. We carry out experiments with and without calibration procedure in training stage to evaluate the performance of new method in different application scenarios. The experiment results show that the Deep-BP model achieves high accuracy and outperforms existing methods, in the experiments both with and without calibration.},
	booktitle = {2019 41st {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society} ({EMBC})},
	author = {Yan, Cong and Li, Zhenqi and Zhao, Wei and Hu, Jing and Jia, Dongya and Wang, Hongmei and You, Tianyuan},
	month = jul,
	year = {2019},
	note = {ISSN: 1557-170X},
	keywords = {BP estimation task, BP monitoring, Biomedical monitoring, Blood pressure, Convolution, ECG signals, Electrocardiography, Estimation, Feature extraction, Monitoring, PPG signals, blood pressure measurement, convolutional neural nets, convolutional neural network model, cuff-less blood pressure measurement, cuff-less estimation methods, data features, deep convolutional neural network, deep-BP model, electrocardiography, estimation accuracy, feature extraction, medical signal processing, nonideal signal morphology, patient monitoring, photoplethysmography, signal noise},
	pages = {1917--1920},
}

@inproceedings{su_long-term_2018,
	title = {Long-term blood pressure prediction with deep recurrent neural networks},
	doi = {10.1109/BHI.2018.8333434},
	abstract = {Existing methods for arterial blood pressure (BP) estimation directly map the input physiological signals to output BP values without explicitly modeling the underlying temporal dependencies in BP dynamics. As a result, these models suffer from accuracy decay over a long time and thus require frequent calibration. In this work, we address this issue by formulating BP estimation as a sequence prediction problem in which both the input and target are temporal sequences. We propose a novel deep recurrent neural network (RNN) consisting of multilayered Long Short-Term Memory (LSTM) networks, which are incorporated with (1) a bidirectional structure to access larger-scale context information of input sequence, and (2) residual connections to allow gradients in deep RNN to propagate more effectively. The proposed deep RNN model was tested on a static BP dataset, and it achieved root mean square error (RMSE) of 3.90 and 2.66 mmHg for systolic BP (SBP) and diastolic BP (DBP) prediction respectively, surpassing the accuracy of traditional BP prediction models. On a multi-day BP dataset, the deep RNN achieved RMSE of 3.84, 5.25, 5.80 and 5.81 mmHg for the 1st day, 2nd day, 4th day and 6th month after the 1st day SBP prediction, and 1.80, 4.78, 5.0, 5.21 mmHg for corresponding DBP prediction, respectively, which outperforms all previous models with notable improvement. The experimental results suggest that modeling the temporal dependencies in BP dynamics significantly improves the long-term BP prediction accuracy.},
	booktitle = {2018 {IEEE} {EMBS} {International} {Conference} on {Biomedical} {Health} {Informatics} ({BHI})},
	author = {Su, Peng and Ding, Xiao-Rong and Zhang, Yuan-Ting and Liu, Jing and Miao, Fen and Zhao, Ni},
	month = mar,
	year = {2018},
	note = {ISSN: null},
	keywords = {BP dynamics, BP estimation, BP prediction models, Computational modeling, Computer architecture, Electrocardiography, Mathematical model, Predictive models, Recurrent neural networks, SBP prediction, Training, arterial blood pressure estimation, blood pressure measurement, deep RNN model, deep recurrent neural network, electrocardiography, long-term BP prediction accuracy, long-term blood pressure prediction, mean square error methods, medical signal processing, multiday BP dataset, multilayered long short-term memory networks, photoplethysmography, physiological signals, recurrent neural nets, static BP dataset},
	pages = {323--328},
}

@article{su_long-term_2018-1,
	title = {Long-term {Blood} {Pressure} {Prediction} with {Deep} {Recurrent} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1705.04524},
	abstract = {Existing methods for arterial blood pressure (BP) estimation directly map the input physiological signals to output BP values without explicitly modeling the underlying temporal dependencies in BP dynamics. As a result, these models suffer from accuracy decay over a long time and thus require frequent calibration. In this work, we address this issue by formulating BP estimation as a sequence prediction problem in which both the input and target are temporal sequences. We propose a novel deep recurrent neural network (RNN) consisting of multilayered Long Short-Term Memory (LSTM) networks, which are incorporated with (1) a bidirectional structure to access larger-scale context information of input sequence, and (2) residual connections to allow gradients in deep RNN to propagate more effectively. The proposed deep RNN model was tested on a static BP dataset, and it achieved root mean square error (RMSE) of 3.90 and 2.66 mmHg for systolic BP (SBP) and diastolic BP (DBP) prediction respectively, surpassing the accuracy of traditional BP prediction models. On a multi-day BP dataset, the deep RNN achieved RMSE of 3.84, 5.25, 5.80 and 5.81 mmHg for the 1st day, 2nd day, 4th day and 6th month after the 1st day SBP prediction, and 1.80, 4.78, 5.0, 5.21 mmHg for corresponding DBP prediction, respectively, which outperforms all previous models with notable improvement. The experimental results suggest that modeling the temporal dependencies in BP dynamics significantly improves the long-term BP prediction accuracy.},
	urldate = {2020-01-27},
	journal = {arXiv:1705.04524 [cs, math, stat]},
	author = {Su, Peng and Ding, Xiao-Rong and Zhang, Yuan-Ting and Liu, Jing and Miao, Fen and Zhao, Ni},
	month = jan,
	year = {2018},
	note = {arXiv: 1705.04524},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Mathematics - Dynamical Systems, Statistics - Machine Learning},
}

@patent{zhao_deep_2020,
	title = {Deep learning approach for long term, cuffless, and continuous arterial blood pressure estimation},
	url = {https://patents.google.com/patent/US20200015755A1/en},
	nationality = {US},
	assignee = {Chinese University of Hong Kong (CUHK)},
	number = {US20200015755A1},
	urldate = {2020-01-27},
	author = {Zhao, Ni and Su, Peng and Zhang, Yuanting},
	month = jan,
	year = {2020},
	keywords = {blood pressure, cnn, configured, rnn, system},
}

@article{cinelli_making_2020,
	title = {Making sense of sensitivity: extending omitted variable bias},
	volume = {82},
	copyright = {© 2019 Royal Statistical Society},
	issn = {1467-9868},
	shorttitle = {Making sense of sensitivity},
	url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssb.12348},
	doi = {10.1111/rssb.12348},
	abstract = {We extend the omitted variable bias framework with a suite of tools for sensitivity analysis in regression models that does not require assumptions on the functional form of the treatment assignment mechanism nor on the distribution of the unobserved confounders, naturally handles multiple confounders, possibly acting non-linearly, exploits expert knowledge to bound sensitivity parameters and can be easily computed by using only standard regression results. In particular, we introduce two novel sensitivity measures suited for routine reporting. The robustness value describes the minimum strength of association that unobserved confounding would need to have, both with the treatment and with the outcome, to change the research conclusions. The partial R2 of the treatment with the outcome shows how strongly confounders explaining all the residual outcome variation would have to be associated with the treatment to eliminate the estimated effect. Next, we offer graphical tools for elaborating on problematic confounders, examining the sensitivity of point estimates and t-values, as well as ‘extreme scenarios’. Finally, we describe problems with a common ‘benchmarking’ practice and introduce a novel procedure to bound the strength of confounders formally on the basis of a comparison with observed covariates. We apply these methods to a running example that estimates the effect of exposure to violence on attitudes toward peace.},
	language = {en},
	number = {1},
	urldate = {2020-01-24},
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Cinelli, Carlos and Hazlett, Chad},
	year = {2020},
	keywords = {Causal inference, Confounding, Omitted variable bias, Regression, Robustness value, Sensitivity analysis},
	pages = {39--67},
}

@article{locke_genetic_2015,
	title = {Genetic studies of body mass index yield new insights for obesity biology},
	volume = {518},
	copyright = {2015 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature14177},
	doi = {10.1038/nature14177},
	abstract = {A genome-wide association study and Metabochip meta-analysis of body mass index (BMI) detects 97 BMI-associated loci, of which 56 were novel, and many loci have effects on other metabolic phenotypes; pathway analyses implicate the central nervous system in obesity susceptibility and new pathways such as those related to synaptic function, energy metabolism, lipid biology and adipogenesis.},
	language = {en},
	number = {7538},
	urldate = {2020-01-09},
	journal = {Nature},
	author = {Locke, Adam E. and Kahali, Bratati and Berndt, Sonja I. and Justice, Anne E. and Pers, Tune H. and Day, Felix R. and Powell, Corey and Vedantam, Sailaja and Buchkovich, Martin L. and Yang, Jian and Croteau-Chonka, Damien C. and Esko, Tonu and Fall, Tove and Ferreira, Teresa and Gustafsson, Stefan and Kutalik, Zoltán and Luan, Jian’an and Mägi, Reedik and Randall, Joshua C. and Winkler, Thomas W. and Wood, Andrew R. and Workalemahu, Tsegaselassie and Faul, Jessica D. and Smith, Jennifer A. and Hua Zhao, Jing and Zhao, Wei and Chen, Jin and Fehrmann, Rudolf and Hedman, Åsa K. and Karjalainen, Juha and Schmidt, Ellen M. and Absher, Devin and Amin, Najaf and Anderson, Denise and Beekman, Marian and Bolton, Jennifer L. and Bragg-Gresham, Jennifer L. and Buyske, Steven and Demirkan, Ayse and Deng, Guohong and Ehret, Georg B. and Feenstra, Bjarke and Feitosa, Mary F. and Fischer, Krista and Goel, Anuj and Gong, Jian and Jackson, Anne U. and Kanoni, Stavroula and Kleber, Marcus E. and Kristiansson, Kati and Lim, Unhee and Lotay, Vaneet and Mangino, Massimo and Mateo Leach, Irene and Medina-Gomez, Carolina and Medland, Sarah E. and Nalls, Michael A. and Palmer, Cameron D. and Pasko, Dorota and Pechlivanis, Sonali and Peters, Marjolein J. and Prokopenko, Inga and Shungin, Dmitry and Stančáková, Alena and Strawbridge, Rona J. and Ju Sung, Yun and Tanaka, Toshiko and Teumer, Alexander and Trompet, Stella and van der Laan, Sander W. and van Setten, Jessica and Van Vliet-Ostaptchouk, Jana V. and Wang, Zhaoming and Yengo, Loïc and Zhang, Weihua and Isaacs, Aaron and Albrecht, Eva and Ärnlöv, Johan and Arscott, Gillian M. and Attwood, Antony P. and Bandinelli, Stefania and Barrett, Amy and Bas, Isabelita N. and Bellis, Claire and Bennett, Amanda J. and Berne, Christian and Blagieva, Roza and Blüher, Matthias and Böhringer, Stefan and Bonnycastle, Lori L. and Böttcher, Yvonne and Boyd, Heather A. and Bruinenberg, Marcel and Caspersen, Ida H. and Ida Chen, Yii-Der and Clarke, Robert and Warwick Daw, E. and de Craen, Anton J. M. and Delgado, Graciela and Dimitriou, Maria and Doney, Alex S. F. and Eklund, Niina and Estrada, Karol and Eury, Elodie and Folkersen, Lasse and Fraser, Ross M. and Garcia, Melissa E. and Geller, Frank and Giedraitis, Vilmantas and Gigante, Bruna and Go, Alan S. and Golay, Alain and Goodall, Alison H. and Gordon, Scott D. and Gorski, Mathias and Grabe, Hans-Jörgen and Grallert, Harald and Grammer, Tanja B. and Gräßler, Jürgen and Grönberg, Henrik and Groves, Christopher J. and Gusto, Gaëlle and Haessler, Jeffrey and Hall, Per and Haller, Toomas and Hallmans, Goran and Hartman, Catharina A. and Hassinen, Maija and Hayward, Caroline and Heard-Costa, Nancy L. and Helmer, Quinta and Hengstenberg, Christian and Holmen, Oddgeir and Hottenga, Jouke-Jan and James, Alan L. and Jeff, Janina M. and Johansson, Åsa and Jolley, Jennifer and Juliusdottir, Thorhildur and Kinnunen, Leena and Koenig, Wolfgang and Koskenvuo, Markku and Kratzer, Wolfgang and Laitinen, Jaana and Lamina, Claudia and Leander, Karin and Lee, Nanette R. and Lichtner, Peter and Lind, Lars and Lindström, Jaana and Sin Lo, Ken and Lobbens, Stéphane and Lorbeer, Roberto and Lu, Yingchang and Mach, François and Magnusson, Patrik K. E. and Mahajan, Anubha and McArdle, Wendy L. and McLachlan, Stela and Menni, Cristina and Merger, Sigrun and Mihailov, Evelin and Milani, Lili and Moayyeri, Alireza and Monda, Keri L. and Morken, Mario A. and Mulas, Antonella and Müller, Gabriele and Müller-Nurasyid, Martina and Musk, Arthur W. and Nagaraja, Ramaiah and Nöthen, Markus M. and Nolte, Ilja M. and Pilz, Stefan and Rayner, Nigel W. and Renstrom, Frida and Rettig, Rainer and Ried, Janina S. and Ripke, Stephan and Robertson, Neil R. and Rose, Lynda M. and Sanna, Serena and Scharnagl, Hubert and Scholtens, Salome and Schumacher, Fredrick R. and Scott, William R. and Seufferlein, Thomas and Shi, Jianxin and Vernon Smith, Albert and Smolonska, Joanna and Stanton, Alice V. and Steinthorsdottir, Valgerdur and Stirrups, Kathleen and Stringham, Heather M. and Sundström, Johan and Swertz, Morris A. and Swift, Amy J. and Syvänen, Ann-Christine and Tan, Sian-Tsung and Tayo, Bamidele O. and Thorand, Barbara and Thorleifsson, Gudmar and Tyrer, Jonathan P. and Uh, Hae-Won and Vandenput, Liesbeth and Verhulst, Frank C. and Vermeulen, Sita H. and Verweij, Niek and Vonk, Judith M. and Waite, Lindsay L. and Warren, Helen R. and Waterworth, Dawn and Weedon, Michael N. and Wilkens, Lynne R. and Willenborg, Christina and Wilsgaard, Tom and Wojczynski, Mary K. and Wong, Andrew and Wright, Alan F. and Zhang, Qunyuan and Brennan, Eoin P. and Choi, Murim and Dastani, Zari and Drong, Alexander W. and Eriksson, Per and Franco-Cereceda, Anders and Gådin, Jesper R. and Gharavi, Ali G. and Goddard, Michael E. and Handsaker, Robert E. and Huang, Jinyan and Karpe, Fredrik and Kathiresan, Sekar and Keildson, Sarah and Kiryluk, Krzysztof and Kubo, Michiaki and Lee, Jong-Young and Liang, Liming and Lifton, Richard P. and Ma, Baoshan and McCarroll, Steven A. and McKnight, Amy J. and Min, Josine L. and Moffatt, Miriam F. and Montgomery, Grant W. and Murabito, Joanne M. and Nicholson, George and Nyholt, Dale R. and Okada, Yukinori and Perry, John R. B. and Dorajoo, Rajkumar and Reinmaa, Eva and Salem, Rany M. and Sandholm, Niina and Scott, Robert A. and Stolk, Lisette and Takahashi, Atsushi and Tanaka, Toshihiro and van’t Hooft, Ferdinand M. and Vinkhuyzen, Anna A. E. and Westra, Harm-Jan and Zheng, Wei and Zondervan, Krina T. and Heath, Andrew C. and Arveiler, Dominique and Bakker, Stephan J. L. and Beilby, John and Bergman, Richard N. and Blangero, John and Bovet, Pascal and Campbell, Harry and Caulfield, Mark J. and Cesana, Giancarlo and Chakravarti, Aravinda and Chasman, Daniel I. and Chines, Peter S. and Collins, Francis S. and Crawford, Dana C. and Adrienne Cupples, L. and Cusi, Daniele and Danesh, John and de Faire, Ulf and den Ruijter, Hester M. and Dominiczak, Anna F. and Erbel, Raimund and Erdmann, Jeanette and Eriksson, Johan G. and Farrall, Martin and Felix, Stephan B. and Ferrannini, Ele and Ferrières, Jean and Ford, Ian and Forouhi, Nita G. and Forrester, Terrence and Franco, Oscar H. and Gansevoort, Ron T. and Gejman, Pablo V. and Gieger, Christian and Gottesman, Omri and Gudnason, Vilmundur and Gyllensten, Ulf and Hall, Alistair S. and Harris, Tamara B. and Hattersley, Andrew T. and Hicks, Andrew A. and Hindorff, Lucia A. and Hingorani, Aroon D. and Hofman, Albert and Homuth, Georg and Hovingh, G. Kees and Humphries, Steve E. and Hunt, Steven C. and Hyppönen, Elina and Illig, Thomas and Jacobs, Kevin B. and Jarvelin, Marjo-Riitta and Jöckel, Karl-Heinz and Johansen, Berit and Jousilahti, Pekka and Jukema, J. Wouter and Jula, Antti M. and Kaprio, Jaakko and Kastelein, John J. P. and Keinanen-Kiukaanniemi, Sirkka M. and Kiemeney, Lambertus A. and Knekt, Paul and Kooner, Jaspal S. and Kooperberg, Charles and Kovacs, Peter and Kraja, Aldi T. and Kumari, Meena and Kuusisto, Johanna and Lakka, Timo A. and Langenberg, Claudia and Marchand, Loic Le and Lehtimäki, Terho and Lyssenko, Valeriya and Männistö, Satu and Marette, André and Matise, Tara C. and McKenzie, Colin A. and McKnight, Barbara and Moll, Frans L. and Morris, Andrew D. and Morris, Andrew P. and Murray, Jeffrey C. and Nelis, Mari and Ohlsson, Claes and Oldehinkel, Albertine J. and Ong, Ken K. and Madden, Pamela A. F. and Pasterkamp, Gerard and Peden, John F. and Peters, Annette and Postma, Dirkje S. and Pramstaller, Peter P. and Price, Jackie F. and Qi, Lu and Raitakari, Olli T. and Rankinen, Tuomo and Rao, D. C. and Rice, Treva K. and Ridker, Paul M. and Rioux, John D. and Ritchie, Marylyn D. and Rudan, Igor and Salomaa, Veikko and Samani, Nilesh J. and Saramies, Jouko and Sarzynski, Mark A. and Schunkert, Heribert and Schwarz, Peter E. H. and Sever, Peter and Shuldiner, Alan R. and Sinisalo, Juha and Stolk, Ronald P. and Strauch, Konstantin and Tönjes, Anke and Trégouët, David-Alexandre and Tremblay, Angelo and Tremoli, Elena and Virtamo, Jarmo and Vohl, Marie-Claude and Völker, Uwe and Waeber, Gérard and Willemsen, Gonneke and Witteman, Jacqueline C. and Zillikens, M. Carola and Adair, Linda S. and Amouyel, Philippe and Asselbergs, Folkert W. and Assimes, Themistocles L. and Bochud, Murielle and Boehm, Bernhard O. and Boerwinkle, Eric and Bornstein, Stefan R. and Bottinger, Erwin P. and Bouchard, Claude and Cauchi, Stéphane and Chambers, John C. and Chanock, Stephen J. and Cooper, Richard S. and Bakker, Paul I. W. de and Dedoussis, George and Ferrucci, Luigi and Franks, Paul W. and Froguel, Philippe and Groop, Leif C. and Haiman, Christopher A. and Hamsten, Anders and Hui, Jennie and Hunter, David J. and Hveem, Kristian and Kaplan, Robert C. and Kivimaki, Mika and Kuh, Diana and Laakso, Markku and Liu, Yongmei and Martin, Nicholas G. and März, Winfried and Melbye, Mads and Metspalu, Andres and Moebus, Susanne and Munroe, Patricia B. and Njølstad, Inger and Oostra, Ben A. and Palmer, Colin N. A. and Pedersen, Nancy L. and Perola, Markus and Pérusse, Louis and Peters, Ulrike and Power, Chris and Quertermous, Thomas and Rauramaa, Rainer and Rivadeneira, Fernando and Saaristo, Timo E. and Saleheen, Danish and Sattar, Naveed and Schadt, Eric E. and Schlessinger, David and Slagboom, P. Eline and Snieder, Harold and Spector, Tim D. and Thorsteinsdottir, Unnur and Stumvoll, Michael and Tuomilehto, Jaakko and Uitterlinden, André G. and Uusitupa, Matti and Harst, Pim van der and Walker, Mark and Wallaschofski, Henri and Wareham, Nicholas J. and Watkins, Hugh and Weir, David R. and Wichmann, H.-Erich and Wilson, James F. and Zanen, Pieter and Borecki, Ingrid B. and Deloukas, Panos and Fox, Caroline S. and Heid, Iris M. and O’Connell, Jeffrey R. and Strachan, David P. and Stefansson, Kari and Duijn, Cornelia M. van and Abecasis, Gonçalo R. and Franke, Lude and Frayling, Timothy M. and McCarthy, Mark I. and Visscher, Peter M. and Scherag, André and Willer, Cristen J. and Boehnke, Michael and Mohlke, Karen L. and Lindgren, Cecilia M. and Beckmann, Jacques S. and Barroso, Inês and North, Kari E. and Ingelsson, Erik and Hirschhorn, Joel N. and Loos, Ruth J. F. and Speliotes, Elizabeth K.},
	month = feb,
	year = {2015},
	pages = {197--206},
}

@article{lyall_association_2017,
	title = {Association of {Body} {Mass} {Index} {With} {Cardiometabolic} {Disease} in the {UK} {Biobank}: {A} {Mendelian} {Randomization} {Study}},
	volume = {2},
	issn = {2380-6583},
	shorttitle = {Association of {Body} {Mass} {Index} {With} {Cardiometabolic} {Disease} in the {UK} {Biobank}},
	url = {https://jamanetwork.com/journals/jamacardiology/fullarticle/2635826},
	doi = {10.1001/jamacardio.2016.5804},
	abstract = {{\textless}h3{\textgreater}Importance{\textless}/h3{\textgreater}{\textless}p{\textgreater}Higher body mass index (BMI) is a risk factor for cardiometabolic disease; however, the underlying causal associations remain unclear.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Objectives{\textless}/h3{\textgreater}{\textless}p{\textgreater}To use UK Biobank data to report causal estimates of the association between BMI and cardiometabolic disease outcomes and traits, such as pulse rate, using mendelian randomization.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Design, Setting, and Participants{\textless}/h3{\textgreater}{\textless}p{\textgreater}Cross-sectional baseline data from a population-based cohort study including 119 859 UK Biobank participants with complete phenotypic (medical and sociodemographic) and genetic data. Participants attended 1 of 22 assessment centers across the United Kingdom between 2006 and 2010. The present study was conducted from May 1 to July 11, 2016.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Main Outcomes and Measures{\textless}/h3{\textgreater}{\textless}p{\textgreater}Prevalence of hypertension, coronary heart disease, and type 2 diabetes were determined at assessment, based on self-report. Blood pressure was measured clinically. Participants self-reported sociodemographic information pertaining to relevant confounders. A polygenic risk score comprising 93 single-nucleotide polymorphisms associated with BMI from previous genome-wide association studies was constructed, and the genetic risk score was applied to derive causal estimates using a mendelian randomization approach.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Results{\textless}/h3{\textgreater}{\textless}p{\textgreater}Of the 119 859 individuals included in the study, 56 816 (47.4\%) were men; mean (SD) age was 56.87 (7.93) years. Mendelian randomization analysis showed significant positive associations between genetically instrumented higher BMI and risk of hypertension (odds ratio [OR] per 1-SD higher BMI, 1.64; 95\% CI, 1.48-1.83;\textit{P} = 1.1 × 10$^{\textrm{−19}}$), coronary heart disease (OR, 1.35; 95\% CI, 1.09-1.69;\textit{P} = .007) and type 2 diabetes (OR, 2.53; 95\% CI, 2.04-3.13;\textit{P} = 1.5 × 10$^{\textrm{−17}}$), as well as systolic blood pressure (β = 1.65 mm Hg; 95\% CI, 0.78-2.52 mm Hg;\textit{P} = 2.0 × 10$^{\textrm{−04}}$) and diastolic blood pressure (β = 1.37 mm Hg; 95\% CI, 0.88-1.85 mm Hg;\textit{P} = 3.6 × 10$^{\textrm{−08}}$). These associations were independent of age, sex, Townsend deprivation scores, alcohol intake, and smoking history.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Conclusions and Relevance{\textless}/h3{\textgreater}{\textless}p{\textgreater}The results of this study add to the burgeoning evidence of an association between higher BMI and increased risk of cardiometabolic diseases. This finding has relevance for public health policies in many countries with increasing obesity levels.{\textless}/p{\textgreater}},
	language = {en},
	number = {8},
	urldate = {2020-01-04},
	journal = {JAMA Cardiology},
	author = {Lyall, Donald M. and Celis-Morales, Carlos and Ward, Joey and Iliodromiti, Stamatina and Anderson, Jana J. and Gill, Jason M. R. and Smith, Daniel J. and Ntuk, Uduakobong Efanga and Mackay, Daniel F. and Holmes, Michael V. and Sattar, Naveed and Pell, Jill P.},
	month = aug,
	year = {2017},
	pages = {882--889},
}

@article{yang_proxy_2019,
	title = {Proxy gene-by-environment {Mendelian} randomization study confirms a causal effect of maternal smoking on offspring birthweight, but little evidence of long-term influences on offspring health},
	copyright = {© 2019, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/601443v1},
	doi = {10.1101/601443},
	abstract = {{\textless}h3{\textgreater}Abstract{\textless}/h3{\textgreater} {\textless}h3{\textgreater}Objective{\textless}/h3{\textgreater} {\textless}p{\textgreater}To validate a novel proxy gene-by-environment (G×E) Mendelian randomization (MR) approach by replicating the previously established effect of maternal smoking heaviness in pregnancy on offspring birthweight, and then use GxE MR to investigate the effect of smoking heaviness in pregnancy on offspring health outcomes in later life and grandchild’s birthweight.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Design{\textless}/h3{\textgreater} {\textless}p{\textgreater}A proxy G×E MR using participants’ genotype (i.e. rs16969968 in \textit{CHRNA5}) as a proxy for their mother’s genotype.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Setting{\textless}/h3{\textgreater} {\textless}p{\textgreater}UK Biobank.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Participants{\textless}/h3{\textgreater} {\textless}p{\textgreater}289,684 white British men and women aged 40-69 in UK Biobank.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Main outcome measures{\textless}/h3{\textgreater} {\textless}p{\textgreater}Participants’ birthweight and later life outcomes (height, body mass index, lung function, asthma, blood pressure, age at menarche, years of education, fluid intelligence score, depression/anxiety, happiness), and birthweight of female participants’ first child.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Results{\textless}/h3{\textgreater} {\textless}p{\textgreater}In our proof of principle analysis, each additional smoking-increasing allele was associated with a 0.018 (95\% confidence interval (CI): −0.026, −0.009) kg lower birthweight in the “maternal smoking during pregnancy” stratum, but no meaningful effect (−0.002kg; 95\% CI: −0.008, 0.003) in the “maternal non-smoking during pregnancy” stratum (interaction P-value=0.004). We found little evidence of an effect of maternal smoking heaviness on participants’ later life outcomes. We found the differences in associations of rs16969968 with grandchild’s birthweight between grandmothers who did versus did not smoke were heterogeneous (interaction P-value=0.042) among female participants who did (−0.020kg per allele; 95\% CI: −0.044, 0.003) versus did not (0.007kg per allele; 95\% CI: −0.005, 0.020) smoke in pregnancy.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Conclusions{\textless}/h3{\textgreater} {\textless}p{\textgreater}Our study demonstrated how offspring genotype can be used to proxy for mothers’ genotype in G×E MR. We confirmed the previously established causal effect of maternal smoking on offspring birthweight but found little evidence of an effect on long-term health outcomes in the offspring. For grandchild’s birthweight, the effect of grandmother’s smoking heaviness in pregnancy may be modulated by maternal smoking status in pregnancy.{\textless}/p{\textgreater}{\textless}h3{\textgreater}WHAT IS ALREADY KNOWN TO THIS TOPIC{\textless}/h3{\textgreater} {\textless}p{\textgreater}Heavier maternal smoking in pregnancy causes lower offspring birthweight Maternal smoking in pregnancy is also associated with offspring outcomes in later life and grandchild’s birthweight, but it is not known whether these associations are causal Understanding the transgenerational causal effects of maternal smoking heaviness in pregnancy is important to inform public health policies{\textless}/p{\textgreater}{\textless}h3{\textgreater}WHAT THIS STUDY ADDS{\textless}/h3{\textgreater} {\textless}p{\textgreater}The proxy gene-by-environment Mendelian randomization approach can be used to explore maternal effects on offspring phenotypes when maternal genetic information is unavailable The approach confirmed the causal effect of smoking on offspring birthweight.{\textless}/p{\textgreater}{\textless}p{\textgreater}Maternal smoking status in pregnancy modulates the effect of grandmother’s smoking heaviness in pregnancy on grandchild’s birthweight, highlighting the importance of smoking cessation before pregnancy in each generation{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2019-12-19},
	journal = {bioRxiv},
	author = {Yang, Qian and Millard, Louise A. C. and Smith, George Davey},
	month = apr,
	year = {2019},
	pages = {601443},
}

@article{he_deep_2015,
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	url = {http://arxiv.org/abs/1512.03385},
	abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
	urldate = {2019-12-18},
	journal = {arXiv:1512.03385 [cs]},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = dec,
	year = {2015},
	note = {arXiv: 1512.03385},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{cinelli_generalizing_nodate,
	title = {Generalizing {Experimental} {Results} by {Leveraging} {Knowledge} of {Mechanisms}},
	abstract = {We show how experimental results can be generalized across diverse populations by leveraging knowledge of mechanisms that produce the outcome of interest. We use Structural Causal Models (SCM) and a reﬁned version of selection diagrams to represent such knowledge, and to decide whether it entails conditions that enable generalizations. We further provide bounds for the target eﬀect when some of these conditions are violated. We conclude by demonstrating that the structural account oﬀers a more reliable way of analyzing generalization than positing counterfactual consequences of the actual mechanisms.},
	language = {en},
	author = {Cinelli, Carlos and Pearl, Judea},
	pages = {14},
}

@article{banda_finding_2019,
	title = {Finding missed cases of familial hypercholesterolemia in health systems using machine learning},
	volume = {2},
	copyright = {2019 The Author(s)},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-019-0101-5},
	doi = {10.1038/s41746-019-0101-5},
	abstract = {Familial hypercholesterolemia (FH) is an underdiagnosed dominant genetic condition affecting approximately 0.4\% of the population and has up to a 20-fold increased risk of coronary artery disease if untreated. Simple screening strategies have false positive rates greater than 95\%. As part of the FH Foundation′s FIND FH initiative, we developed a classifier to identify potential FH patients using electronic health record (EHR) data at Stanford Health Care. We trained a random forest classifier using data from known patients (n = 197) and matched non-cases (n = 6590). Our classifier obtained a positive predictive value (PPV) of 0.88 and sensitivity of 0.75 on a held-out test-set. We evaluated the accuracy of the classifier′s predictions by chart review of 100 patients at risk of FH not included in the original dataset. The classifier correctly flagged 84\% of patients at the highest probability threshold, with decreasing performance as the threshold lowers. In external validation on 466 FH patients (236 with genetically proven FH) and 5000 matched non-cases from the Geisinger Healthcare System our FH classifier achieved a PPV of 0.85. Our EHR-derived FH classifier is effective in finding candidate patients for further FH screening. Such machine learning guided strategies can lead to effective identification of the highest risk patients for enhanced management strategies.},
	language = {en},
	number = {1},
	urldate = {2019-12-05},
	journal = {npj Digital Medicine},
	author = {Banda, Juan M. and Sarraju, Ashish and Abbasi, Fahim and Parizo, Justin and Pariani, Mitchel and Ison, Hannah and Briskin, Elinor and Wand, Hannah and Dubois, Sebastien and Jung, Kenneth and Myers, Seth A. and Rader, Daniel J. and Leader, Joseph B. and Murray, Michael F. and Myers, Kelly D. and Wilemon, Katherine and Shah, Nigam H. and Knowles, Joshua W.},
	month = apr,
	year = {2019},
	pages = {1--8},
}

@article{bowden_mendelian_2015,
	title = {Mendelian randomization with invalid instruments: effect estimation and bias detection through {Egger} regression},
	volume = {44},
	issn = {0300-5771},
	shorttitle = {Mendelian randomization with invalid instruments},
	url = {https://academic.oup.com/ije/article/44/2/512/754653},
	doi = {10.1093/ije/dyv080},
	abstract = {Abstract.  Background: The number of Mendelian randomization analyses including large numbers of genetic variants is rapidly increasing. This is due to the prol},
	language = {en},
	number = {2},
	urldate = {2019-12-04},
	journal = {International Journal of Epidemiology},
	author = {Bowden, Jack and Davey Smith, George and Burgess, Stephen},
	month = apr,
	year = {2015},
	pages = {512--525},
}

@article{tyrrell_height_2016,
	title = {Height, body mass index, and socioeconomic status: mendelian randomisation study in {UK} {Biobank}},
	volume = {352},
	copyright = {Published by the BMJ Publishing Group Limited. For permission to use (where not already granted under a licence) please go to http://group.bmj.com/group/rights-licensing/permissions.            This is an Open Access article distributed in accordance with the terms of the Creative Commons Attribution (CC BY 3.0) license, which permits others to distribute, remix, adapt and build upon this work, for commercial use, provided the original work is properly cited. See: http://creativecommons.org/licenses/by/3.0/.},
	issn = {1756-1833},
	shorttitle = {Height, body mass index, and socioeconomic status},
	url = {https://www.bmj.com/content/352/bmj.i582},
	doi = {10.1136/bmj.i582},
	abstract = {Objective To determine whether height and body mass index (BMI) have a causal role in five measures of socioeconomic status.
Design Mendelian randomisation study to test for causal effects of differences in stature and BMI on five measures of socioeconomic status. Mendelian randomisation exploits the fact that genotypes are randomly assigned at conception and thus not confounded by non-genetic factors.
Setting UK Biobank.
Participants 119 669 men and women of British ancestry, aged between 37 and 73 years.
Main outcome measures Age completed full time education, degree level education, job class, annual household income, and Townsend deprivation index.
Results In the UK Biobank study, shorter stature and higher BMI were observationally associated with several measures of lower socioeconomic status. The associations between shorter stature and lower socioeconomic status tended to be stronger in men, and the associations between higher BMI and lower socioeconomic status tended to be stronger in women. For example, a 1 standard deviation (SD) higher BMI was associated with a £210 (€276; \$300; 95\% confidence interval £84 to £420; P=6×10−3) lower annual household income in men and a £1890 (£1680 to £2100; P=6×10−15) lower annual household income in women. Genetic analysis provided evidence that these associations were partly causal. A genetically determined 1 SD (6.3 cm) taller stature caused a 0.06 (0.02 to 0.09) year older age of completing full time education (P=0.01), a 1.12 (1.07 to 1.18) times higher odds of working in a skilled profession (P=6×10−7), and a £1130 (£680 to £1580) higher annual household income (P=4×10−8). Associations were stronger in men. A genetically determined 1 SD higher BMI (4.6 kg/m2) caused a £2940 (£1680 to £4200; P=1×10−5) lower annual household income and a 0.10 (0.04 to 0.16) SD (P=0.001) higher level of deprivation in women only.
Conclusions These data support evidence that height and BMI play an important partial role in determining several aspects of a person’s socioeconomic status, especially women’s BMI for income and deprivation and men’s height for education, income, and job class. These findings have important social and health implications, supporting evidence that overweight people, especially women, are at a disadvantage and that taller people, especially men, are at an advantage.},
	language = {en},
	urldate = {2019-12-04},
	journal = {BMJ},
	author = {Tyrrell, Jessica and Jones, Samuel E. and Beaumont, Robin and Astley, Christina M. and Lovell, Rebecca and Yaghootkar, Hanieh and Tuke, Marcus and Ruth, Katherine S. and Freathy, Rachel M. and Hirschhorn, Joel N. and Wood, Andrew R. and Murray, Anna and Weedon, Michael N. and Frayling, Timothy M.},
	month = mar,
	year = {2016},
	pmid = {26956984},
}

@article{scholkopf_causality_2019,
	title = {Causality for {Machine} {Learning}},
	url = {http://arxiv.org/abs/1911.10500},
	abstract = {Graphical causal inference as pioneered by Judea Pearl arose from research on artificial intelligence (AI), and for a long time had little connection to the field of machine learning. This article discusses where links have been and should be established, introducing key concepts along the way. It argues that the hard open problems of machine learning and AI are intrinsically related to causality, and explains how the field is beginning to understand them.},
	urldate = {2019-11-26},
	journal = {arXiv:1911.10500 [cs, stat]},
	author = {Schölkopf, Bernhard},
	month = nov,
	year = {2019},
	note = {arXiv: 1911.10500},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, I.2, I.5, K.4, Statistics - Machine Learning},
}

@article{kachuee_cuffless_2017,
	title = {Cuffless {Blood} {Pressure} {Estimation} {Algorithms} for {Continuous} {Health}-{Care} {Monitoring}},
	volume = {64},
	issn = {1558-2531},
	doi = {10.1109/TBME.2016.2580904},
	abstract = {Goal: Continuous blood pressure (BP) monitoring can provide invaluable information about individuals' health conditions. However, BP is conventionally measured using inconvenient cuff-based instruments, which prevents continuous BP monitoring. This paper presents an efficient algorithm, based on the pulse arrival time (PAT), for the continuous and cuffless estimation of the systolic BP, diastolic blood pressure (DBP), and mean arterial pressure (MAP) values. Methods: The proposed framework estimates the BP values through processing vital signals and extracting two types of features, which are based on either physiological parameters or whole-based representation of vital signals. Finally, the regression algorithms are employed for the BP estimation. Although the proposed algorithm works reliably without any need for calibration, an optional calibration procedure is also suggested, which can improve the system's accuracy even further. Results: The proposed method is evaluated on about a thousand subjects using the Association for the Advancement of Medical Instrumentation (AAMI) and the British Hypertension Society (BHS) standards. The method complies with the AAMI standard in the estimation of DBP and MAP values. Regarding the BHS protocol, the results achieve grade A for the estimation of DBP and grade B for the estimation of MAP. Conclusion: We conclude that by using the PAT in combination with informative features from the vital signals, the BP can be accurately and reliably estimated in a noninvasive fashion. Significance: The results indicate that the proposed algorithm for the cuffless estimation of the BP can potentially enable mobile health-care gadgets to monitor the BP continuously.},
	number = {4},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Kachuee, Mohammad and Kiani, Mohammad Mahdi and Mohammadzade, Hoda and Shabany, Mahdi},
	month = apr,
	year = {2017},
	keywords = {AAMI standard, Algorithms, Arteries, BHS protocol, BP estimation, Biomedical monitoring, Blood Pressure, Blood Pressure Determination, Blood Pressure Monitors, Blood pressure, British Hypertension Society standards, DBP values, Diagnosis, Computer-Assisted, Electrocardiography, Equipment Design, Equipment Failure Analysis, Estimation, Feature extraction, Humans, MAP values, Machine Learning, Monitoring, Monitoring, Ambulatory, Pulse Wave Analysis, Reproducibility of Results, Sensitivity and Specificity, advancement-of-medical instrumentation, blood pressure measurement, blood vessels, calibration, continuous BP monitoring, continuous health-care monitoring, cuffless blood pressure estimation algorithms, diastolic blood pressure, electrocardiograph, electrocardiograph (ECG), electrocardiography, feature extraction, health care, health conditions, inconvenient cuff-based instruments, mean arterial pressure, medical signal processing, mobile health, optional calibration procedure, patient monitoring, photoplethysmograph, photoplethysmograph (PPG), photoplethysmography, physiological parameters, pulse arrival time, pulse arrival time (PAT), regression algorithms, regression analysis, systolic BP, vital signal processing, whole-based representation},
	pages = {859--869},
}

@article{slapnicar_blood_2019,
	title = {Blood {Pressure} {Estimation} from {Photoplethysmogram} {Using} a {Spectro}-{Temporal} {Deep} {Neural} {Network}},
	volume = {19},
	issn = {1424-8220},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6696196/},
	doi = {10.3390/s19153420},
	abstract = {Blood pressure (BP) is a direct indicator of hypertension, a dangerous and potentially deadly condition. Regular monitoring of BP is thus important, but many people have aversion towards cuff-based devices, and their limitation is that they can only be used at rest. Using just a photoplethysmogram (PPG) to estimate BP is a potential solution investigated in our study. We analyzed the MIMIC III database for high-quality PPG and arterial BP waveforms, resulting in over 700 h of signals after preprocessing, belonging to 510 subjects. We then used the PPG alongside its first and second derivative as inputs into a novel spectro-temporal deep neural network with residual connections. We have shown in a leave-one-subject-out experiment that the network is able to model the dependency between PPG and BP, achieving mean absolute errors of 9.43 for systolic and 6.88 for diastolic BP. Additionally we have shown that personalization of models is important and substantially improves the results, while deriving a good general predictive model is difficult. We have made crucial parts of our study, especially the list of used subjects and our neural network code, publicly available, in an effort to provide a solid baseline and simplify potential comparison between future studies on an explicit MIMIC III subset.},
	number = {15},
	urldate = {2019-11-20},
	journal = {Sensors (Basel, Switzerland)},
	author = {Slapničar, Gašper and Mlakar, Nejc and Luštrek, Mitja},
	month = aug,
	year = {2019},
	pmid = {31382703},
	pmcid = {PMC6696196},
}

@article{sendak_human_2019,
	title = {"{The} {Human} {Body} is a {Black} {Box}": {Supporting} {Clinical} {Decision}-{Making} with {Deep} {Learning}},
	shorttitle = {"{The} {Human} {Body} is a {Black} {Box}"},
	url = {http://arxiv.org/abs/1911.08089},
	abstract = {Machine learning technologies are increasingly developed for use in healthcare. While research communities have focused on creating state-of-the-art models, there has been less focus on real world implementation and the associated challenges to accuracy, fairness, accountability, and transparency that come from actual, situated use. Serious questions remain under examined regarding how to ethically build models, interpret and explain model output, recognize and account for biases, and minimize disruptions to professional expertise and work cultures. We address this gap in the literature and provide a detailed case study covering the development, implementation, and evaluation of Sepsis Watch, a machine learning-driven tool that assists hospital clinicians in the early diagnosis and treatment of sepsis. We, the team that developed and evaluated the tool, discuss our conceptualization of the tool not as a model deployed in the world but instead as a socio-technical system requiring integration into existing social and professional contexts. Rather than focusing on model interpretability to ensure a fair and accountable machine learning, we point toward four key values and practices that should be considered when developing machine learning to support clinical decision-making: rigorously define the problem in context, build relationships with stakeholders, respect professional discretion, and create ongoing feedback loops with stakeholders. Our work has significant implications for future research regarding mechanisms of institutional accountability and considerations for designing machine learning systems. Our work underscores the limits of model interpretability as a solution to ensure transparency, accuracy, and accountability in practice. Instead, our work demonstrates other means and goals to achieve FATML values in design and in practice.},
	urldate = {2019-11-20},
	journal = {arXiv:1911.08089 [cs]},
	author = {Sendak, Mark and Elish, Madeleine and Gao, Michael and Futoma, Joseph and Ratliff, William and Nichols, Marshall and Bedoya, Armando and Balu, Suresh and O'Brien, Cara},
	month = nov,
	year = {2019},
	note = {arXiv: 1911.08089},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Human-Computer Interaction, Computer Science - Machine Learning},
}

@book{cinelli_making_2018,
	title = {Making {Sense} of {Sensitivity}: {Extending} {Omitted} {Variable} {Bias}},
	shorttitle = {Making {Sense} of {Sensitivity}},
	abstract = {We extend the omitted variable bias framework with a suite of tools for sensitivity analysis in regression models that: (i) does not require assumptions about the treatment assignment nor the nature of confounders; (ii) naturally handles multiple confounders, possibly acting non-linearly; (iii) exploits expert knowledge to bound sensitivity parameters; and, (iv) can be easily computed using only standard regression results. In particular, we introduce two novel sensitivity measures suited for routine reporting. The robustness value describes the minimum strength of association unobserved confounding would need to have, both with the treatment and the outcome, to change the research conclusions. The partial R2 of the treatment with the outcome shows how strongly confounders explaining all the residual outcome variation would have to be associated with the treatment to eliminate the estimated effect. Next, we offer graphical tools for elaborating on problematic confounders, examining the sensitivity of point estimates, t-values, as well as “extreme scenarios”. Finally, we describe problems with a common “benchmarking” practice and introduce a novel procedure to formally bound the strength of confounders based on comparison to observed covariates. We apply these methods to a running example that estimates the effect of exposure to violence on attitudes toward peace.},
	author = {Cinelli, Carlos and Hazlett, Chad},
	month = jan,
	year = {2018},
}

@article{voight_plasma_2012,
	title = {Plasma {HDL} cholesterol and risk of myocardial infarction: a mendelian randomisation study},
	volume = {380},
	issn = {1474-547X},
	shorttitle = {Plasma {HDL} cholesterol and risk of myocardial infarction},
	doi = {10.1016/S0140-6736(12)60312-2},
	abstract = {BACKGROUND: High plasma HDL cholesterol is associated with reduced risk of myocardial infarction, but whether this association is causal is unclear. Exploiting the fact that genotypes are randomly assigned at meiosis, are independent of non-genetic confounding, and are unmodified by disease processes, mendelian randomisation can be used to test the hypothesis that the association of a plasma biomarker with disease is causal.
METHODS: We performed two mendelian randomisation analyses. First, we used as an instrument a single nucleotide polymorphism (SNP) in the endothelial lipase gene (LIPG Asn396Ser) and tested this SNP in 20 studies (20,913 myocardial infarction cases, 95,407 controls). Second, we used as an instrument a genetic score consisting of 14 common SNPs that exclusively associate with HDL cholesterol and tested this score in up to 12,482 cases of myocardial infarction and 41,331 controls. As a positive control, we also tested a genetic score of 13 common SNPs exclusively associated with LDL cholesterol.
FINDINGS: Carriers of the LIPG 396Ser allele (2·6\% frequency) had higher HDL cholesterol (0·14 mmol/L higher, p=8×10(-13)) but similar levels of other lipid and non-lipid risk factors for myocardial infarction compared with non-carriers. This difference in HDL cholesterol is expected to decrease risk of myocardial infarction by 13\% (odds ratio [OR] 0·87, 95\% CI 0·84-0·91). However, we noted that the 396Ser allele was not associated with risk of myocardial infarction (OR 0·99, 95\% CI 0·88-1·11, p=0·85). From observational epidemiology, an increase of 1 SD in HDL cholesterol was associated with reduced risk of myocardial infarction (OR 0·62, 95\% CI 0·58-0·66). However, a 1 SD increase in HDL cholesterol due to genetic score was not associated with risk of myocardial infarction (OR 0·93, 95\% CI 0·68-1·26, p=0·63). For LDL cholesterol, the estimate from observational epidemiology (a 1 SD increase in LDL cholesterol associated with OR 1·54, 95\% CI 1·45-1·63) was concordant with that from genetic score (OR 2·13, 95\% CI 1·69-2·69, p=2×10(-10)).
INTERPRETATION: Some genetic mechanisms that raise plasma HDL cholesterol do not seem to lower risk of myocardial infarction. These data challenge the concept that raising of plasma HDL cholesterol will uniformly translate into reductions in risk of myocardial infarction.
FUNDING: US National Institutes of Health, The Wellcome Trust, European Union, British Heart Foundation, and the German Federal Ministry of Education and Research.},
	language = {eng},
	number = {9841},
	journal = {Lancet (London, England)},
	author = {Voight, Benjamin F. and Peloso, Gina M. and Orho-Melander, Marju and Frikke-Schmidt, Ruth and Barbalic, Maja and Jensen, Majken K. and Hindy, George and Hólm, Hilma and Ding, Eric L. and Johnson, Toby and Schunkert, Heribert and Samani, Nilesh J. and Clarke, Robert and Hopewell, Jemma C. and Thompson, John F. and Li, Mingyao and Thorleifsson, Gudmar and Newton-Cheh, Christopher and Musunuru, Kiran and Pirruccello, James P. and Saleheen, Danish and Chen, Li and Stewart, Alexandre F. R. and Schillert, Arne and Thorsteinsdottir, Unnur and Thorgeirsson, Gudmundur and Anand, Sonia and Engert, James C. and Morgan, Thomas and Spertus, John and Stoll, Monika and Berger, Klaus and Martinelli, Nicola and Girelli, Domenico and McKeown, Pascal P. and Patterson, Christopher C. and Epstein, Stephen E. and Devaney, Joseph and Burnett, Mary-Susan and Mooser, Vincent and Ripatti, Samuli and Surakka, Ida and Nieminen, Markku S. and Sinisalo, Juha and Lokki, Marja-Liisa and Perola, Markus and Havulinna, Aki and de Faire, Ulf and Gigante, Bruna and Ingelsson, Erik and Zeller, Tanja and Wild, Philipp and de Bakker, Paul I. W. and Klungel, Olaf H. and Maitland-van der Zee, Anke-Hilse and Peters, Bas J. M. and de Boer, Anthonius and Grobbee, Diederick E. and Kamphuisen, Pieter W. and Deneer, Vera H. M. and Elbers, Clara C. and Onland-Moret, N. Charlotte and Hofker, Marten H. and Wijmenga, Cisca and Verschuren, W. M. Monique and Boer, Jolanda M. A. and van der Schouw, Yvonne T. and Rasheed, Asif and Frossard, Philippe and Demissie, Serkalem and Willer, Cristen and Do, Ron and Ordovas, Jose M. and Abecasis, Gonçalo R. and Boehnke, Michael and Mohlke, Karen L. and Daly, Mark J. and Guiducci, Candace and Burtt, Noël P. and Surti, Aarti and Gonzalez, Elena and Purcell, Shaun and Gabriel, Stacey and Marrugat, Jaume and Peden, John and Erdmann, Jeanette and Diemert, Patrick and Willenborg, Christina and König, Inke R. and Fischer, Marcus and Hengstenberg, Christian and Ziegler, Andreas and Buysschaert, Ian and Lambrechts, Diether and Van de Werf, Frans and Fox, Keith A. and El Mokhtari, Nour Eddine and Rubin, Diana and Schrezenmeir, Jürgen and Schreiber, Stefan and Schäfer, Arne and Danesh, John and Blankenberg, Stefan and Roberts, Robert and McPherson, Ruth and Watkins, Hugh and Hall, Alistair S. and Overvad, Kim and Rimm, Eric and Boerwinkle, Eric and Tybjaerg-Hansen, Anne and Cupples, L. Adrienne and Reilly, Muredach P. and Melander, Olle and Mannucci, Pier M. and Ardissino, Diego and Siscovick, David and Elosua, Roberto and Stefansson, Kari and O'Donnell, Christopher J. and Salomaa, Veikko and Rader, Daniel J. and Peltonen, Leena and Schwartz, Stephen M. and Altshuler, David and Kathiresan, Sekar},
	month = aug,
	year = {2012},
	pmid = {22607825},
	pmcid = {PMC3419820},
	keywords = {Biomarkers, Case-Control Studies, Cholesterol, HDL, Cholesterol, LDL, Gene Frequency, Genetic Predisposition to Disease, Humans, Lipase, Mendelian Randomization Analysis, Myocardial Infarction, Polymorphism, Single Nucleotide, Prospective Studies, Risk Factors},
	pages = {572--580},
}

@article{subbaswamy_development_nodate,
	title = {From development to deployment: dataset shift, causality, and shift-stable models in health {AI}},
	shorttitle = {From development to deployment},
	url = {https://academic.oup.com/biostatistics/advance-article/doi/10.1093/biostatistics/kxz041/5631850},
	doi = {10.1093/biostatistics/kxz041},
	abstract = {The deployment of machine learning (ML) and statistical models is beginning to transform the practice of healthcare, with models now able to help clinicians dia},
	language = {en},
	urldate = {2019-11-19},
	journal = {Biostatistics},
	author = {Subbaswamy, Adarsh and Saria, Suchi},
}

@article{mohan_graphical_2018,
	title = {Graphical models for processing missing data},
	journal = {arXiv preprint arXiv:1801.03583},
	author = {Mohan, Karthika and Pearl, Judea},
	year = {2018},
}

@inproceedings{mohan_estimation_2018,
	title = {Estimation with incomplete data: the linear case},
	booktitle = {Proceedings of the 27th {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {AAAI Press},
	author = {Mohan, Karthika and Thoemmes, Felix and Pearl, Judea},
	year = {2018},
	pages = {5082--5088},
}

@article{kocaoglu_characterization_2019,
	title = {Characterization and {Learning} of {Causal} {Graphs} with {Latent} {Variables} from {Soft} {Interventions}},
	author = {Kocaoglu, Murat and Jaber, Amin and Shanmugam, Karthikeyan and Bareinboim, Elias},
	year = {2019},
}

@article{martin_sepsis_2012,
	title = {Sepsis, severe sepsis and septic shock: changes in incidence, pathogens and outcomes},
	volume = {10},
	issn = {1478-7210},
	shorttitle = {Sepsis, severe sepsis and septic shock},
	url = {https://doi.org/10.1586/eri.12.50},
	doi = {10.1586/eri.12.50},
	abstract = {Sepsis has been around since the dawn of time, having been described for more than 2000 years, although clinical definitions are recent. The consensus sepsis definitions have permitted worldwide epidemiological studies of sepsis to be conducted. We now recognize the common nature of sepsis and the consistency of its disease – particularly severe sepsis and septic shock. The incidence of sepsis, severe sepsis and septic shock continues to increase, and although Gram-positive bacterial pathogens remain the most common cause of sepsis, fungal organisms are increasing rapidly. We have made progress over the past half-century in identifying and treating patients with sepsis, and decreasing fatality rates reflect this progress. However, owing to the increasing incidence of sepsis, the number of people who die each year continues to increase. The mortality with sepsis, particularly related to treating organ dysfunction, remains a priority to clinicians worldwide and is deserving of greater public health attention.},
	number = {6},
	urldate = {2019-11-12},
	journal = {Expert Review of Anti-infective Therapy},
	author = {Martin, Greg S.},
	month = jun,
	year = {2012},
	keywords = {critical illness, infection, intensive care unit, sepsis},
	pages = {701--706},
}

@article{lin_wave-shape_2019,
	title = {Wave-shape oscillatory model for biomedical time series with applications},
	url = {http://arxiv.org/abs/1907.00502},
	abstract = {The oscillations observed in physiological time series exhibit morphological variations over time. These morphological variations are caused by intrinsic or extrinsic changes to the state of the generating system, henceforth referred to as dynamics. To model such a time series, we provide a novel hierarchical model: the wave-shape oscillatory model. In this model, time-dependent variations in cycle morphology occur along a manifold called the wave-shape manifold. To estimate the wave-shape manifold associated with an oscillatory time series, study the dynamics, and visualize the time-dependent changes along it, we apply the well-established diffusion maps (DM) algorithm to the set of all observed oscillations. We provide a theoretical guarantee on the dynamical information recovered by the DM algorithm under the proposed model. Applying the proposed model to arterial blood pressure signals recorded during general anesthesia leads to the extraction of nociception information. Applying the wave-shape oscillatory model to cardiac cycles in the electrocardiogram (ECG) leads to a new ECG-derived respiratory signal.},
	urldate = {2019-11-08},
	journal = {arXiv:1907.00502 [stat]},
	author = {Lin, Yu-Ting and Malik, John and Wu, Hau-Tieng},
	month = jun,
	year = {2019},
	note = {arXiv: 1907.00502},
	keywords = {Statistics - Applications},
}

@article{beaulieu-jones_trends_2019,
	title = {Trends and {Focus} of {Machine} {Learning} {Applications} for {Health} {Research}},
	volume = {2},
	url = {https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2753523},
	doi = {10.1001/jamanetworkopen.2019.14051},
	abstract = {{\textless}h3{\textgreater}Importance{\textless}/h3{\textgreater}{\textless}p{\textgreater}The use of machine learning applications related to health is rapidly increasing and may have the potential to profoundly affect the field of health care.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Objective{\textless}/h3{\textgreater}{\textless}p{\textgreater}To analyze submissions to a popular machine learning for health venue to assess the current state of research, including areas of methodologic and clinical focus, limitations, and underexplored areas.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Design, Setting, and Participants{\textless}/h3{\textgreater}{\textless}p{\textgreater}In this data-driven qualitative analysis, 166 accepted manuscript submissions to the Third Annual Machine Learning for Health workshop at the 32nd Conference on Neural Information Processing Systems on December 8, 2018, were analyzed to understand research focus, progress, and trends. Experts reviewed each submission against a rubric to identify key data points, statistical modeling and analysis of submitting authors was performed, and research topics were quantitatively modeled. Finally, an iterative discussion of topics common in submissions and invited speakers at the workshop was held to identify key trends.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Main Outcomes and Measures{\textless}/h3{\textgreater}{\textless}p{\textgreater}Frequency and statistical measures of methods, topics, goals, and author attributes were derived from an expert review of submissions guided by a rubric.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Results{\textless}/h3{\textgreater}{\textless}p{\textgreater}Of the 166 accepted submissions, 58 (34.9\%) had clinician involvement and 83 submissions (50.0\%) that focused on clinical practice included clinical collaborators. A total of 97 data sets (58.4\%) used in submissions were publicly available or required a standard registration process. Clinical practice was the most common application area (70 manuscripts [42.2\%]), with brain and mental health (25 [15.1\%]), oncology (21 [12.7\%]), and cardiovascular (19 [11.4\%]) being the most common specialties.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Conclusions and Relevance{\textless}/h3{\textgreater}{\textless}p{\textgreater}Trends in machine learning for health research indicate the importance of well-annotated, easily accessed data and the benefit from greater clinician involvement in the development of translational applications.{\textless}/p{\textgreater}},
	language = {en},
	number = {10},
	urldate = {2019-10-28},
	journal = {JAMA Network Open},
	author = {Beaulieu-Jones, Brett and Finlayson, Samuel G. and Chivers, Corey and Chen, Irene and McDermott, Matthew and Kandola, Jaz and Dalca, Adrian V. and Beam, Andrew and Fiterau, Madalina and Naumann, Tristan},
	month = oct,
	year = {2019},
	pages = {e1914051--e1914051},
}

@article{stuart_comprehensive_2018,
	title = {Comprehensive integration of single cell data},
	copyright = {© 2018, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/460147v1},
	doi = {10.1101/460147},
	abstract = {{\textless}p{\textgreater}Single cell transcriptomics (scRNA-seq) has transformed our ability to discover and annotate cell types and states, but deep biological understanding requires more than a taxonomic listing of clusters. As new methods arise to measure distinct cellular modalities, including high-dimensional immunophenotypes, chromatin accessibility, and spatial positioning, a key analytical challenge is to integrate these datasets into a harmonized atlas that can be used to better understand cellular identity and function. Here, we develop a computational strategy to “anchor” diverse datasets together, enabling us to integrate and compare single cell measurements not only across scRNA-seq technologies, but different modalities as well. After demonstrating substantial improvement over existing methods for data integration, we anchor scRNA-seq experiments with scATAC-seq datasets to explore chromatin differences in closely related interneuron subsets, and project single cell protein measurements onto a human bone marrow atlas to annotate and characterize lymphocyte populations. Lastly, we demonstrate how anchoring can harmonize \textit{in-situ} gene expression and scRNA-seq datasets, allowing for the transcriptome-wide imputation of spatial gene expression patterns, and the identification of spatial relationships between mapped cell types in the visual cortex. Our work presents a strategy for comprehensive integration of single cell data, including the assembly of harmonized references, and the transfer of information across datasets.{\textless}/p{\textgreater}{\textless}p{\textgreater}\textbf{Availability:} Installation instructions, documentation, and tutorials are available at: https://www.satijalab.org/seurat{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2019-10-28},
	journal = {bioRxiv},
	author = {Stuart, Tim and Butler, Andrew and Hoffman, Paul and Hafemeister, Christoph and Papalexi, Efthymia and Mauck, William M. and Stoeckius, Marlon and Smibert, Peter and Satija, Rahul},
	month = nov,
	year = {2018},
	pages = {460147},
}

@article{korsunsky_fast_2018,
	title = {Fast, sensitive, and accurate integration of single cell data with {Harmony}},
	copyright = {© 2018, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/461954v2},
	doi = {10.1101/461954},
	abstract = {{\textless}h3{\textgreater}Abstract{\textless}/h3{\textgreater} {\textless}p{\textgreater}The rapidly emerging diversity of single cell RNAseq datasets allows us to characterize the transcriptional behavior of cell types across a wide variety of biological and clinical conditions. With this comprehensive breadth comes a major analytical challenge. The same cell type across tissues, from different donors, or in different disease states, may appear to express different genes. A joint analysis of multiple datasets requires the integration of cells across diverse conditions. This is particularly challenging when datasets are assayed with different technologies in which real biological differences are interspersed with technical differences. We present Harmony, an algorithm that projects cells into a shared embedding in which cells group by cell type rather than dataset-specific conditions. Unlike available single-cell integration methods, Harmony can simultaneously account for multiple experimental and biological factors. We develop objective metrics to evaluate the quality of data integration. In four separate analyses, we demonstrate the superior performance of Harmony to four single-cell-specific integration algorithms. Moreover, we show that Harmony requires dramatically fewer computational resources. It is the only available algorithm that makes the integration of \textit{∼} 10$^{\textrm{6}}$ cells feasible on a personal computer. We demonstrate that Harmony identifies both broad populations and fine-grained subpopulations of PBMCs from datasets with large experimental differences. In a meta-analysis of 14,746 cells from 5 studies of human pancreatic islet cells, Harmony accounts for variation among technologies and donors to successfully align several rare subpopulations. In the resulting integrated embedding, we identify a previously unidentified population of potentially dysfunctional alpha islet cells, enriched for genes active in the Endoplasmic Reticulum (ER) stress response. The abundance of these alpha cells correlates across donors with the proportion of dysfunctional beta cells also enriched in ER stress response genes. Harmony is a fast and flexible general purpose integration algorithm that enables the identification of shared fine-grained subpopulations across a variety of experimental and biological conditions.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2019-10-27},
	journal = {bioRxiv},
	author = {Korsunsky, Ilya and Fan, Jean and Slowikowski, Kamil and Zhang, Fan and Wei, Kevin and Baglaenko, Yuriy and Brenner, Michael and Loh, Po-Ru and Raychaudhuri, Soumya},
	month = nov,
	year = {2018},
	pages = {461954},
}

@article{wang_bermuda:_2019,
	title = {{BERMUDA}: a novel deep transfer learning method for single-cell {RNA} sequencing batch correction reveals hidden high-resolution cellular subtypes},
	volume = {20},
	issn = {1474-760X},
	shorttitle = {{BERMUDA}},
	url = {https://doi.org/10.1186/s13059-019-1764-6},
	doi = {10.1186/s13059-019-1764-6},
	abstract = {To fully utilize the power of single-cell RNA sequencing (scRNA-seq) technologies for identifying cell lineages and bona fide transcriptional signals, it is necessary to combine data from multiple experiments. We present BERMUDA (Batch Effect ReMoval Using Deep Autoencoders), a novel transfer-learning-based method for batch effect correction in scRNA-seq data. BERMUDA effectively combines different batches of scRNA-seq data with vastly different cell population compositions and amplifies biological signals by transferring information among batches. We demonstrate that BERMUDA outperforms existing methods for removing batch effects and distinguishing cell types in multiple simulated and real scRNA-seq datasets.},
	number = {1},
	urldate = {2019-10-27},
	journal = {Genome Biology},
	author = {Wang, Tongxin and Johnson, Travis S. and Shao, Wei and Lu, Zixiao and Helm, Bryan R. and Zhang, Jie and Huang, Kun},
	month = aug,
	year = {2019},
	pages = {165},
}

@article{hie_efficient_2019,
	title = {Efficient integration of heterogeneous single-cell transcriptomes using {Scanorama}},
	volume = {37},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-1696},
	url = {https://www.nature.com/articles/s41587-019-0113-3},
	doi = {10.1038/s41587-019-0113-3},
	abstract = {Scanorama integrates single-cell RNA-seq datasets from different tissues, different labs, different experiments or different technologies.},
	language = {en},
	number = {6},
	urldate = {2019-10-27},
	journal = {Nature Biotechnology},
	author = {Hie, Brian and Bryson, Bryan and Berger, Bonnie},
	month = jun,
	year = {2019},
	pages = {685--691},
}

@article{amodio_exploring_2019,
	title = {Exploring single-cell data with deep multitasking neural networks},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/s41592-019-0576-7},
	doi = {10.1038/s41592-019-0576-7},
	abstract = {SAUCIE, a deep learning platform to analyze single-cell data across samples and platforms, allows information to be obtained from the internal layers of the network, which provides additional mechanistic understanding that can be used to further tune data analysis.},
	language = {en},
	urldate = {2019-10-27},
	journal = {Nature Methods},
	author = {Amodio, Matthew and Dijk, David van and Srinivasan, Krishnan and Chen, William S. and Mohsen, Hussein and Moon, Kevin R. and Campbell, Allison and Zhao, Yujiao and Wang, Xiaomei and Venkataswamy, Manjunatha and Desai, Anita and Ravi, V. and Kumar, Priti and Montgomery, Ruth and Wolf, Guy and Krishnaswamy, Smita},
	month = oct,
	year = {2019},
	pages = {1--7},
}

@article{lehman_methods_2013-1,
	title = {Methods of {Blood} {Pressure} {Measurement} in the {ICU}},
	volume = {41},
	issn = {0090-3493},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3724452/},
	doi = {10.1097/CCM.0b013e318265ea46},
	abstract = {Objective
Minimal clinical research has investigated the significance of different blood pressure monitoring techniques in the ICU and whether systolic vs. mean blood pressures should be targeted in therapeutic protocols and in defining clinical study cohorts. The objectives of this study are to compare real-world invasive arterial blood pressure with noninvasive blood pressure, and to determine if differences between the two techniques have clinical implications.

Design
We conducted a retrospective study comparing invasive arterial blood pressure and noninvasive blood pressure measurements using a large ICU database. We performed pairwise comparison between concurrent measures of invasive arterial blood pressure and noninvasive blood pressure. We studied the association of systolic and mean invasive arterial blood pressure and noninvasive blood pressure with acute kidney injury, and with ICU mortality.

Setting
Adult intensive care units at a tertiary care hospital.

Patients
Adult patients admitted to intensive care units between 2001 and 2007.

Interventions
None.

Measurements and Main Results
Pairwise analysis of 27,022 simultaneously measured invasive arterial blood pressure/noninvasive blood pressure pairs indicated that noninvasive blood pressure overestimated systolic invasive arterial blood pressure during hypotension. Analysis of acute kidney injury and ICU mortality involved 1,633 and 4,957 patients, respectively. Our results indicated that hypotensive systolic noninvasive blood pressure readings were associated with a higher acute kidney injury prevalence (p = 0.008) and ICU mortality (p {\textless} 0.001) than systolic invasive arterial blood pressure in the same range (≤70 mm Hg). Noninvasive blood pressure and invasive arterial blood pressure mean arterial pressures showed better agreement; acute kidney injury prevalence (p = 0.28) and ICU mortality (p = 0.76) associated with hypotensive mean arterial pressure readings (≤60 mm Hg) were independent of measurement technique.

Conclusions
Clinically significant discrepancies exist between invasive and noninvasive systolic blood pressure measurements during hypotension. Mean blood pressure from both techniques may be interpreted in a consistent manner in assessing patients’ prognosis. Our results suggest that mean rather than systolic blood pressure is the preferred metric in the ICU to guide therapy. (Crit Care Med 2013;41:0–0)},
	number = {1},
	urldate = {2019-10-25},
	journal = {Critical care medicine},
	author = {Lehman, Li-wei H. and Saeed, Mohammed and Talmor, Daniel and Mark, Roger and Malhotra, Atul},
	month = jan,
	year = {2013},
	pmid = {23269127},
	pmcid = {PMC3724452},
	pages = {34--40},
}

@article{gershengorn_variation_2014,
	title = {Variation of {Arterial} and {Central} {Venous} {Catheter} {Use} in {United} {States} {Intensive} {Care} {Units}},
	volume = {120},
	issn = {0003-3022},
	url = {https://anesthesiology.pubs.asahq.org/article.aspx?articleid=1917897},
	doi = {10.1097/ALN.0000000000000008},
	abstract = {Abstract  Background::
     Arterial catheters (ACs) and central venous catheters (CVCs) are common in intensive care units (ICUs). Few data describe which patients receive these devices and whether variability in practice exists.   Methods::
     The authors conducted an observational cohort study ...},
	language = {en},
	number = {3},
	urldate = {2019-10-22},
	journal = {Anesthesiology: The Journal of the American Society of Anesthesiologists},
	author = {Gershengorn, Hayley B. and Garland, Allan and Kramer, Andrew and Scales, Damon C. and Rubenfeld, Gordon and Wunsch, Hannah},
	month = mar,
	year = {2014},
	pages = {650--664},
}

@article{hill_automated_nodate,
	title = {An automated machine learning-based model predicts postoperative mortality using readily-extractable preoperative electronic health record data},
	issn = {0007-0912},
	url = {https://doi.org/10.1016/j.bja.2019.07.030},
	doi = {10.1016/j.bja.2019.07.030},
	abstract = {BackgroundRapid, preoperative identification of patients with the highest risk for medical complications is necessary to ensure that limited infrastructure and human resources are directed towards those most likely to benefit. Existing risk scores either lack specificity at the patient level or utilise the American Society of Anesthesiologists (ASA) physical status classification, which requires a clinician to review the chart.},
	urldate = {2019-10-19},
	journal = {British Journal of Anaesthesia},
	author = {Hill, Brian L. and Brown, Robert and Gabel, Eilon and Rakocz, Nadav and Lee, Christine and Cannesson, Maxime and Baldi, Pierre and Olde Loohuis, Loes and Johnson, Ruth and Jew, Brandon and Maoz, Uri and Mahajan, Aman and Sankararaman, Sriram and Hofer, Ira and Halperin, Eran},
}

@article{elgendi_use_2019,
	title = {The use of photoplethysmography for assessing hypertension},
	volume = {2},
	issn = {2398-6352},
	url = {https://doi.org/10.1038/s41746-019-0136-7},
	doi = {10.1038/s41746-019-0136-7},
	abstract = {The measurement of blood pressure (BP) is critical to the treatment and management of many medical conditions. High blood pressure is associated with many chronic disease conditions, and is a major source of mortality and morbidity around the world. For outpatient care as well as general health monitoring, there is great interest in being able to accurately and frequently measure BP outside of a clinical setting, using mobile or wearable devices. One possible solution is photoplethysmography (PPG), which is most commonly used in pulse oximetry in clinical settings for measuring oxygen saturation. PPG technology is becoming more readily available, inexpensive, convenient, and easily integrated into portable devices. Recent advances include the development of smartphones and wearable devices that collect pulse oximeter signals. In this article, we review (i) the state-of-the-art and the literature related to PPG signals collected by pulse oximeters, (ii) various theoretical approaches that have been adopted in PPG BP measurement studies, and (iii) the potential of PPG measurement devices as a wearable application. Past studies on changes in PPG signals and BP are highlighted, and the correlation between PPG signals and BP are discussed. We also review the combined use of features extracted from PPG and other physiological signals in estimating BP. Although the technology is not yet mature, it is anticipated that in the near future, accurate, continuous BP measurements may be available from mobile and wearable devices given their vast potential.},
	number = {1},
	journal = {npj Digital Medicine},
	author = {Elgendi, Mohamed and Fletcher, Richard and Liang, Yongbo and Howard, Newton and Lovell, Nigel H. and Abbott, Derek and Lim, Kenneth and Ward, Rabab},
	month = jun,
	year = {2019},
	pages = {60},
}

@article{argha_blood_2019,
	title = {Blood {Pressure} {Estimation} {From} {Beat}-by-{Beat} {Time}-{Domain} {Features} of {Oscillometric} {Waveforms} {Using} {Deep}-{Neural}-{Network} {Classification} {Models}},
	volume = {7},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2019.2933498},
	abstract = {In general, existing machine learning based approaches, developed for systolic and diastolic blood pressure (SBP and DBP) estimation from oscillometric waveforms (OWs), employ features extracted from the OW envelope (OWE) alone and ignore important beat-by-beat (BBB) features which represent fundamental physical properties of the entire non-invasive blood pressure (NIBP) measurement system. Unlike the existing literature, this paper proposes a novel deep-learning based method for BP estimation trained with BBB time-domain features extracted from OWs. First, we extract six time-domain features from each beat of the OW, relative to the preceding beat. Second, using the extracted BBB features along with the corresponding cuff pressures, we form a feature vector for each OW beat and locate it in one of three different classes, namely pre-systolic (PS), between systolic and diastolic (BSD) and after diastolic (AD). We then devise a deep-belief network (DBN)-deep neural network (DNN) classification model as well as a novel artificial feature extraction method for estimating SBP and DBP from feature vectors extracted from OWs and their corresponding deflation curves. The proposed DBN-DNN classification approach can effectively learn the complex nonlinear relationship between the artificial feature vectors and target classes. The SBP and DBP points are then obtained by mapping the beats at which the network output sequence switches from PS phase to BSD phase and from BSD phase to AD phase, respectively, to the deflation curve. Adopting a 5-fold cross-validation scheme and using a data base of 350 NIBP recordings gave an average mean absolute error of 1.1±2.9 mmHg for SBP and 3.0±5.6 mmHg for DBP relative to reference values. We experimentally show that the proposed DBN-DNN-based classification algorithm trained with BBB time-domain features can outperform traditional deep-learning based methods for BP estimation trained with features extracted only from OWEs.},
	journal = {IEEE Access},
	author = {Argha, A. and Wu, J. and Su, S. W. and Celler, B. G.},
	year = {2019},
	keywords = {Biomedical monitoring, Blood pressure, DBN-DNN classification model, Estimation, Feature extraction, Neural networks, Standards, Time-domain analysis, beat-by-beat time-domain features of oscillometric waveform, systolic and diastolic blood pressure estimation},
	pages = {113427--113439},
}

@misc{noauthor_mysurgeryrisk:_nodate,
	title = {{MySurgeryRisk}: {Development} and {Validation} of a... : {Annals} of {Surgery}},
	shorttitle = {{MySurgeryRisk}},
	url = {https://journals.lww.com/annalsofsurgery/Fulltext/2019/04000/MySurgeryRisk__Development_and_Validation_of_a.11.aspx},
	abstract = {d with long-term consequences. The ability to precisely forecast the risk for major complications before surgery is limited.
Methods: 
In a single-center cohort of 51,457 surgical patients undergoing major inpatient surgery, we have developed and validated an automated analytics framework for a preoperative risk algorithm (MySurgeryRisk) that uses existing clinical data in electronic health records to forecast patient-level probabilistic risk scores for 8 major postoperative complications (acute kidney injury, sepsis, venous thromboembolism, intensive care unit admission {\textgreater}48 hours, mechanical ventilation {\textgreater}48 hours, wound, neurologic, and cardiovascular complications) and death up to 24 months after surgery. We used the area under the receiver characteristic curve (AUC) and predictiveness curves to evaluate model performance.
Results: 
MySurgeryRisk calculates probabilistic risk scores for 8 postoperative complications with AUC values ranging between 0.82 and 0.94 [99\% confidence intervals (CIs) 0.81–0.94]. The model predicts the risk for death at 1, 3, 6, 12, and 24 months with AUC values ranging between 0.77 and 0.83 (99\% CI 0.76–0.85).
Conclusions: 
We constructed an automated predictive analytics framework for machine-learning algorithm with high discriminatory ability for assessing the risk of surgical complications and death using readily available preoperative electronic health records data. The feasibility of this novel algorithm implemented in real time clinical workflow requires further testing....},
	language = {en-US},
	urldate = {2019-08-28},
	journal = {LWW},
	doi = {10.1097/SLA.0000000000002706},
}

@article{fritz_using_2018,
	title = {Using machine learning techniques to develop forecasting algorithms for postoperative complications: protocol for a retrospective study},
	volume = {8},
	copyright = {© Article author(s) (or their employer(s) unless otherwise stated in the text of the article) 2018. All rights reserved. No commercial use is permitted unless otherwise expressly granted.. This is an Open Access article distributed in accordance with the Creative Commons Attribution Non Commercial (CC BY-NC 4.0) license, which permits others to distribute, remix, adapt, build upon this work non-commercially, and license their derivative works on different terms, provided the original work is properly cited and the use is non-commercial. See: http://creativecommons.org/licenses/by-nc/4.0/},
	issn = {2044-6055, 2044-6055},
	shorttitle = {Using machine learning techniques to develop forecasting algorithms for postoperative complications},
	url = {https://bmjopen.bmj.com/content/8/4/e020124},
	doi = {10.1136/bmjopen-2017-020124},
	abstract = {Introduction Mortality and morbidity following surgery are pressing public health concerns in the USA. Traditional prediction models for postoperative adverse outcomes demonstrate good discrimination at the population level, but the ability to forecast an individual patient’s trajectory in real time remains poor. We propose to apply machine learning techniques to perioperative time-series data to develop algorithms for predicting adverse perioperative outcomes.
Methods and analysis This study will include all adult patients who had surgery at our tertiary care hospital over a 4-year period. Patient history, laboratory values, minute-by-minute intraoperative vital signs and medications administered will be extracted from the electronic medical record. Outcomes will include in-hospital mortality, postoperative acute kidney injury and postoperative respiratory failure. Forecasting algorithms for each of these outcomes will be constructed using density-based logistic regression after employing a Nadaraya-Watson kernel density estimator. Time-series variables will be analysed using first and second-order feature extraction, shapelet methods and convolutional neural networks. The algorithms will be validated through measurement of precision and recall.
Ethics and dissemination This study has been approved by the Human Research Protection Office at Washington University in St Louis. The successful development of these forecasting algorithms will allow perioperative healthcare clinicians to predict more accurately an individual patient’s risk for specific adverse perioperative outcomes in real time. Knowledge of a patient’s dynamic risk profile may allow clinicians to make targeted changes in the care plan that will alter the patient’s outcome trajectory. This hypothesis will be tested in a future randomised controlled trial.},
	language = {en},
	number = {4},
	urldate = {2019-08-28},
	journal = {BMJ Open},
	author = {Fritz, Bradley A. and Chen, Yixin and Murray-Torres, Teresa M. and Gregory, Stephen and Abdallah, Arbi Ben and Kronzer, Alex and McKinnon, Sherry Lynn and Budelier, Thaddeus and Helsten, Daniel L. and Wildes, Troy S. and Sharma, Anshuman and Avidan, Michael Simon},
	month = apr,
	year = {2018},
	pmid = {29643160},
	keywords = {adult anaesthesia, health informatics, information technology},
	pages = {e020124},
}

@article{kendale_supervised_2018,
	title = {Supervised {Machine}-learning {Predictive} {Analytics} for {Prediction} of {Postinduction} {Hypotension}},
	volume = {129},
	issn = {0003-3022},
	url = {https://anesthesiology.pubs.asahq.org/article.aspx?articleid=2696388},
	doi = {10.1097/ALN.0000000000002374},
	abstract = {Abstract  Editor’s Perspective:
      What We Already Know about This Topic:
      The ability to predict postinduction hypotension remains limited and challenging due to the multitude of data elements that may be considered Novel machine-learning algorithms may offer a systematic approach ...},
	language = {en},
	number = {4},
	urldate = {2019-08-28},
	journal = {Anesthesiology: The Journal of the American Society of Anesthesiologists},
	author = {Kendale, Samir and Kulkarni, Prathamesh and Rosenberg, Andrew D. and Wang, Jing},
	month = oct,
	year = {2018},
	pages = {675--688},
}

@article{hung_automated_2018,
	title = {Automated {Performance} {Metrics} and {Machine} {Learning} {Algorithms} to {Measure} {Surgeon} {Performance} and {Anticipate} {Clinical} {Outcomes} in {Robotic} {Surgery}},
	volume = {153},
	issn = {2168-6254},
	url = {https://jamanetwork.com/journals/jamasurgery/fullarticle/2685266},
	doi = {10.1001/jamasurg.2018.1512},
	abstract = {This article describes a machine training algorithm for evaluating surgeon performance in robotic surgery that was developed using automated performance metrics collected from the robotic device.},
	language = {en},
	number = {8},
	urldate = {2019-08-28},
	journal = {JAMA Surgery},
	author = {Hung, Andrew J. and Chen, Jian and Gill, Inderbir S.},
	month = aug,
	year = {2018},
	pages = {770--771},
}

@article{ribasripoll_blood_2019,
	title = {Blood {Pressure} {Assessment} with {Differential} {Pulse} {Transit} {Time} and {Deep} {Learning}: {A} {Proof} of {Concept}},
	volume = {5},
	issn = {2296-9381, 2296-9357},
	shorttitle = {Blood {Pressure} {Assessment} with {Differential} {Pulse} {Transit} {Time} and {Deep} {Learning}},
	url = {https://www.karger.com/Article/FullText/493478},
	doi = {10.1159/000493478},
	abstract = {\textbf{\textit{Background:}} Modern clinical environments are laden with technology devices continuously gathering physiological data from patients. This is especially true in critical care environments, where life-saving decisions may have to be made on the basis of signals from monitoring devices. Hemodynamic monitoring is essential in dialysis, surgery, and in critically ill patients. For the most severe patients, blood pressure is normally assessed through a catheter, which is an invasive procedure that may result in adverse effects. Blood pressure can also be monitored noninvasively through different methods and these data can be used for the continuous assessment of pressure using machine learning methods. Previous studies have found pulse transit time to be related to blood pressure. In this short paper, we propose to study the feasibility of implementing a data-driven model based on restricted Boltzmann machine artificial neural networks, delivering a first proof of concept for the validity and viability of a method for blood pressure prediction based on these models. \textbf{\textit{Summary and Key Messages:}} For the most severe patients (e.g., dialysis, surgery, and the critically ill), blood pressure is normally assessed through invasive catheters. Alternatively, noninvasive methods have also been developed for its monitorization. Data obtained from noninvasive measurements can be used for the continuous assessment of pressure using machine learning methods. In this study, a restricted Boltzmann machine artificial neural network is used to present a first proof of concept for the validity and viability of a method for blood pressure prediction.},
	language = {english},
	number = {1},
	urldate = {2019-08-22},
	journal = {Kidney Diseases},
	author = {Ribas Ripoll, Vicent and Vellido, Alfredo},
	year = {2019},
	pmid = {30815461},
	pages = {23--27},
}

@article{choi_noninvasive_2013,
	series = {Special issue on {Recent} {Advanced} {Technologies} and {Theories} for {Grid} and {Cloud} {Computing} and {Bio}-engineering},
	title = {Noninvasive cuffless blood pressure estimation using pulse transit time and {Hilbert}–{Huang} transform},
	volume = {39},
	issn = {0045-7906},
	url = {http://www.sciencedirect.com/science/article/pii/S0045790612001711},
	doi = {10.1016/j.compeleceng.2012.09.005},
	abstract = {It is widely accepted that pulse transit time (PTT), from the R wave peak of electrocardiogram (ECG) to a characteristic point of photoplethysmogram (PPG), is related to arterial stiffness, and can be used to estimate blood pressure. A promising signal processing technology, Hilbert–Huang transform (HHT), is introduced to analyze both ECG and PPG data, which are inherently nonlinear and non-stationary. The relationship between blood pressure and PTT is illustrated, and the problems of calibration and re-calibration are also discussed in this paper. Moreover, multi-innovation recursive least square algorithm is employed to update the unknown parameter vector for the model and improve the results. Our algorithm is tested based on the continuous data from MIMIC database, and the accuracy is calculated to validate the proposed method.},
	number = {1},
	urldate = {2019-08-22},
	journal = {Computers \& Electrical Engineering},
	author = {Choi, Younhee and Zhang, Qiao and Ko, Seokbum},
	month = jan,
	year = {2013},
	pages = {103--111},
}

@article{sharifi_novel_2019,
	title = {A novel dynamical approach in continuous cuffless blood pressure estimation based on {ECG} and {PPG} signals},
	volume = {97},
	issn = {0933-3657},
	url = {http://www.sciencedirect.com/science/article/pii/S0933365718302148},
	doi = {10.1016/j.artmed.2018.12.005},
	abstract = {Continuous cuffless blood pressure (BP) monitoring has attracted much interest in finding the ideal treatment of diseases and the prevention of premature death. This paper presents a novel dynamical method, based on pulse transit time (PTT) and photoplethysmogram intensity ratio (PIR), for the continuous cuffless BP estimation. By taking the advantages of both the modeling and the prediction approaches, the proposed framework effectively estimates diastolic BP (DBP), mean BP (BP), and systolic BP (SBP). Adding past states of the cardiopulmonary system as well as present states of the cardiac system to our model caused two main improvements. First, high accuracy of the method in the beat to beat BP estimation. Second, notwithstanding noticeable BP changes, the performance of the model is preserved over time. The experimental setup includes comparative studies on a large, standard dataset. Moreover, the proposed method outperformed the most recent and cited algorithms with improved accuracy.},
	journal = {Artificial Intelligence in Medicine},
	author = {Sharifi, Iman and Goudarzi, Sobhan and Khodabakhshi, Mohammad Bagher},
	month = jun,
	year = {2019},
	keywords = {Cuffless blood pressure estimation, Multivariate adaptive regression spline, Photoplethysmogram intensity ratio, Pulse transit time, Taken’s theorem},
	pages = {143--151},
}

@article{zhang_predicting_2019,
	title = {Predicting blood pressure from physiological index data using the {SVR} algorithm},
	volume = {20},
	issn = {1471-2105},
	url = {https://doi.org/10.1186/s12859-019-2667-y},
	doi = {10.1186/s12859-019-2667-y},
	abstract = {Blood pressure diseases have increasingly been identified as among the main factors threatening human health. How to accurately and conveniently measure blood pressure is the key to the implementation of effective prevention and control measures for blood pressure diseases. Traditional blood pressure measurement methods exhibit many inherent disadvantages, for example, the time needed for each measurement is difficult to determine, continuous measurement causes discomfort, and the measurement process is relatively cumbersome. Wearable devices that enable continuous measurement of blood pressure provide new opportunities and hopes. Although machine learning methods for blood pressure prediction have been studied, the accuracy of the results does not satisfy the needs of practical applications.},
	number = {1},
	urldate = {2019-08-21},
	journal = {BMC Bioinformatics},
	author = {Zhang, Bing and Ren, Huihui and Huang, Guoyan and Cheng, Yongqiang and Hu, Changzhen},
	month = feb,
	year = {2019},
	pages = {109},
}

@article{mukkamala_toward_2015,
	title = {Toward {Ubiquitous} {Blood} {Pressure} {Monitoring} via {Pulse} {Transit} {Time}: {Theory} and {Practice}},
	volume = {62},
	issn = {0018-9294},
	shorttitle = {Toward {Ubiquitous} {Blood} {Pressure} {Monitoring} via {Pulse} {Transit} {Time}},
	doi = {10.1109/TBME.2015.2441951},
	abstract = {Ubiquitous blood pressure (BP) monitoring is needed to improve hypertension detection and control and is becoming feasible due to recent technological advances such as in wearable sensing. Pulse transit time (PTT) represents a well-known potential approach for ubiquitous BP monitoring. The goal of this review is to facilitate the achievement of reliable ubiquitous BP monitoring via PTT. We explain the conventional BP measurement methods and their limitations; present models to summarize the theory of the PTT-BP relationship; outline the approach while pinpointing the key challenges; overview the previous work toward putting the theory to practice; make suggestions for best practice and future research; and discuss realistic expectations for the approach.},
	number = {8},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Mukkamala, R. and Hahn, J. and Inan, O. T. and Mestha, L. K. and Kim, C. and Töreyin, H. and Kyal, S.},
	month = aug,
	year = {2015},
	keywords = {Arteries, Biomedical monitoring, Blood Pressure, Blood Pressure Determination, Clothing, Cuff-less blood pressure (BP), Elasticity, Equipment Design, Humans, Monitoring, Muscles, PTT-BP relationship, Pulse Wave Analysis, Signal Processing, Computer-Assisted, Strain, blood pressure measurement, body sensor networks, cuff-less blood pressure, hypertension control, hypertension detection, medical disorders, medical signal processing, patient monitoring, pulse transit time, pulse transit time (PTT), pulse wave velocity, pulse wave velocity (PWV), review, ubiquitous blood pressure monitoring, ubiquitous sensing, wearable, wearable sensing},
	pages = {1879--1901},
}

@article{imholz_fifteen_1998,
	title = {Fifteen years experience with finger arterial pressure monitoring:assessment of the technology},
	volume = {38},
	issn = {0008-6363},
	shorttitle = {Fifteen years experience with finger arterial pressure monitoring},
	url = {https://academic.oup.com/cardiovascres/article/38/3/605/326615},
	doi = {10.1016/S0008-6363(98)00067-4},
	abstract = {Abstract.  We review the Finapres technology, embodied in several TNO-prototypes and in the Ohmeda 2300 and 2300e Finapres NIBP. Finapres is an acronym for FINg},
	language = {en},
	number = {3},
	urldate = {2019-08-21},
	journal = {Cardiovascular Research},
	author = {Imholz, Ben P. M. and Wieling, Wouter and van Montfrans, Gert A. and Wesseling, Karel H.},
	month = jun,
	year = {1998},
	pages = {605--616},
}

@article{drzewiecki_arterial_1983,
	title = {Arterial tonometry: {Review} and analysis},
	volume = {16},
	issn = {0021-9290},
	shorttitle = {Arterial tonometry},
	url = {http://www.sciencedirect.com/science/article/pii/0021929083900374},
	doi = {10.1016/0021-9290(83)90037-4},
	abstract = {A review is presented of the field of arterial tonometry and of the problems involved with its application. A second generation model is developed which interprets most of the difficulties encountered in previous experimental work. The model also identifies barriers that must be overcome to allow tonometry to become a practical technique for obtaining measurement of continuous, absolute blood pressure. Problems addressed include those of calibration, positioning sensitivity, design standardization, material properties and vascular loading characteristics. Theoretical and experimental studies provide support for the application of basic biomechanical concepts for solution of these problems and suggest required design features.},
	number = {2},
	urldate = {2019-08-21},
	journal = {Journal of Biomechanics},
	author = {Drzewiecki, Gary M. and Melbin, Julius and Noordergraaf, Abraham},
	month = jan,
	year = {1983},
	pages = {141--152},
}

@article{wang_bermuda:_2019-1,
	title = {{BERMUDA}: a novel deep transfer learning method for single-cell {RNA} sequencing batch correction reveals hidden high-resolution cellular subtypes},
	volume = {20},
	issn = {1474-760X},
	shorttitle = {{BERMUDA}},
	url = {https://doi.org/10.1186/s13059-019-1764-6},
	doi = {10.1186/s13059-019-1764-6},
	abstract = {To fully utilize the power of single-cell RNA sequencing (scRNA-seq) technologies for identifying cell lineages and bona fide transcriptional signals, it is necessary to combine data from multiple experiments. We present BERMUDA (Batch Effect ReMoval Using Deep Autoencoders), a novel transfer-learning-based method for batch effect correction in scRNA-seq data. BERMUDA effectively combines different batches of scRNA-seq data with vastly different cell population compositions and amplifies biological signals by transferring information among batches. We demonstrate that BERMUDA outperforms existing methods for removing batch effects and distinguishing cell types in multiple simulated and real scRNA-seq datasets.},
	number = {1},
	urldate = {2019-08-20},
	journal = {Genome Biology},
	author = {Wang, Tongxin and Johnson, Travis S. and Shao, Wei and Lu, Zixiao and Helm, Bryan R. and Zhang, Jie and Huang, Kun},
	month = aug,
	year = {2019},
	pages = {165},
}

@article{huttunen_pulse_2019,
	title = {Pulse transit time estimation of aortic pulse wave velocity and blood pressure using machine learning and simulated training data},
	volume = {15},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007259},
	doi = {10.1371/journal.pcbi.1007259},
	abstract = {Recent developments in cardiovascular modelling allow us to simulate blood flow in an entire human body. Such model can also be used to create databases of virtual subjects, with sizes limited only by computational resources. In this work, we study if it is possible to estimate cardiovascular health indices using machine learning approaches. In particular, we carry out theoretical assessment of estimating aortic pulse wave velocity, diastolic and systolic blood pressure and stroke volume using pulse transit/arrival timings derived from photopletyshmography signals. For predictions, we train Gaussian process regression using a database of virtual subjects generated with a cardiovascular simulator. Simulated results provides theoretical assessment of accuracy for predictions of the health indices. For instance, aortic pulse wave velocity can be estimated with a high accuracy (r {\textgreater} 0.9) when photopletyshmography is measured from left carotid artery using a combination of foot-to-foot pulse transmit time and peak location derived for the predictions. Similar accuracy can be reached for diastolic blood pressure, but predictions of systolic blood pressure are less accurate (r {\textgreater} 0.75) and the stroke volume predictions are mostly contributed by heart rate.},
	language = {en},
	number = {8},
	urldate = {2019-08-20},
	journal = {PLOS Computational Biology},
	author = {Huttunen, Janne M. J. and Kärkkäinen, Leo and Lindholm, Harri},
	month = aug,
	year = {2019},
	keywords = {Aorta, Aortic valve, Arteries, Blood pressure, Coronary arteries, Heart, Heart rate, Notch signaling},
	pages = {e1007259},
}

@inproceedings{m_deep_2019,
	title = {Deep {Learning} for {Blood} {Pressure} {Estimation}: an {Approach} using {Local} {Measure} of {Arterial} {Dual} {Diameter} {Waveforms}},
	shorttitle = {Deep {Learning} for {Blood} {Pressure} {Estimation}},
	doi = {10.1109/MeMeA.2019.8802145},
	abstract = {In this work, we present a novel approach for ubiquitous blood pressure (BP) measurement that involves a deep learning technique based on the extraction of the inherent features that are indicative of arterial pressure–diameter and pulse transit relationships. The proposed artificial neural network (ANN) architecture is the first to use the combined features of local arterial dimensions and blood pulse propagation characteristics for continuous, cuffless BP estimation. A dual-channel A-mode ultrasound system and a probe with a pair of single-element ultrasound transducers were developed for simultaneous measurement of luminal diameter waveforms from small arterial segments. In our present system, the probe design was optimized to capture local vessel dynamics from the common carotid artery. The reference continuous BP corresponding to individual cardiac cycles was acquired from the same arterial segment using a tonometer synchronized with the diameter measurement system. The data required to train and validate the developed ANN-based BP estimation model was recorded by conducting an in-vivo study on 20 young subjects. Thirty-seven unique features derived from the dual diameter waveform were extracted for beat-by-beat measurement of BP parameters from the carotid site, and hence to construct the carotid pressure waveform. Experimental results showed that the proposed approach exhibited an acceptable accuracy, with a root-mean-square-error of 4 mmHg and 6 mmHg for DBP and SBP respectively. In conclusion, the proposed approach provides a potentially novel cuffless BP technique for continuous measurement of arterial pressure waveform.},
	booktitle = {2019 {IEEE} {International} {Symposium} on {Medical} {Measurements} and {Applications} ({MeMeA})},
	author = {M, N. P. and Chilaka, V. and V, R. K. and Joseph, J. and Sivaprakasam, M.},
	month = jun,
	year = {2019},
	keywords = {Arterial diameter, blood pressure, carotid artery, deep learning, feature selection, multilayer perceptron, ultrasound},
	pages = {1--6},
}

@incollection{myronenko_non-rigid_2007,
	title = {Non-rigid point set registration: {Coherent} {Point} {Drift}},
	shorttitle = {Non-rigid point set registration},
	url = {http://papers.nips.cc/paper/2962-non-rigid-point-set-registration-coherent-point-drift.pdf},
	urldate = {2019-08-19},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 19},
	publisher = {MIT Press},
	author = {Myronenko, Andriy and Song, Xubo and Carreira-Perpiñán, Miguel Á},
	editor = {Schölkopf, B. and Platt, J. C. and Hoffman, T.},
	year = {2007},
	pages = {1009--1016},
}

@article{fauw_clinically_2018,
	title = {Clinically applicable deep learning for diagnosis and referral in retinal disease},
	volume = {24},
	copyright = {2018 The Author(s)},
	issn = {1546-170X},
	url = {https://www.nature.com/articles/s41591-018-0107-6},
	doi = {10.1038/s41591-018-0107-6},
	abstract = {A novel deep learning architecture performs device-independent tissue segmentation of clinical 3D retinal images followed by separate diagnostic classification that meets or exceeds human expert clinical diagnoses of retinal disease.},
	language = {en},
	number = {9},
	urldate = {2019-08-19},
	journal = {Nature Medicine},
	author = {Fauw, Jeffrey De and Ledsam, Joseph R. and Romera-Paredes, Bernardino and Nikolov, Stanislav and Tomasev, Nenad and Blackwell, Sam and Askham, Harry and Glorot, Xavier and O’Donoghue, Brendan and Visentin, Daniel and Driessche, George van den and Lakshminarayanan, Balaji and Meyer, Clemens and Mackinder, Faith and Bouton, Simon and Ayoub, Kareem and Chopra, Reena and King, Dominic and Karthikesalingam, Alan and Hughes, Cían O. and Raine, Rosalind and Hughes, Julian and Sim, Dawn A. and Egan, Catherine and Tufail, Adnan and Montgomery, Hugh and Hassabis, Demis and Rees, Geraint and Back, Trevor and Khaw, Peng T. and Suleyman, Mustafa and Cornebise, Julien and Keane, Pearse A. and Ronneberger, Olaf},
	month = sep,
	year = {2018},
	pages = {1342--1350},
}

@article{kermany_identifying_2018,
	title = {Identifying {Medical} {Diagnoses} and {Treatable} {Diseases} by {Image}-{Based} {Deep} {Learning}},
	volume = {172},
	issn = {0092-8674},
	url = {https://doi.org/10.1016/j.cell.2018.02.010},
	doi = {10.1016/j.cell.2018.02.010},
	number = {5},
	urldate = {2019-08-19},
	journal = {Cell},
	author = {Kermany, Daniel S. and Goldbaum, Michael and Cai, Wenjia and Valentim, Carolina C.S. and Liang, Huiying and Baxter, Sally L. and McKeown, Alex and Yang, Ge and Wu, Xiaokang and Yan, Fangbing and Dong, Justin and Prasadha, Made K. and Pei, Jacqueline and Ting, Magdalene Y.L. and Zhu, Jie and Li, Christina and Hewett, Sierra and Dong, Jason and Ziyar, Ian and Shi, Alexander and Zhang, Runze and Zheng, Lianghong and Hou, Rui and Shi, William and Fu, Xin and Duan, Yaou and Huu, Viet A.N. and Wen, Cindy and Zhang, Edward D. and Zhang, Charlotte L. and Li, Oulan and Wang, Xiaobo and Singer, Michael A. and Sun, Xiaodong and Xu, Jie and Tafreshi, Ali and Lewis, M. Anthony and Xia, Huimin and Zhang, Kang},
	month = feb,
	year = {2018},
	pages = {1122--1131.e9},
}

@article{shah_making_2019,
	title = {Making {Machine} {Learning} {Models} {Clinically} {Useful}},
	url = {https://jamanetwork.com/journals/jama/fullarticle/2748179},
	doi = {10.1001/jama.2019.10306},
	abstract = {This Viewpoint reviews conventional ways of assessing performance of machine learning models to diagnose or predict outcomes, but emphasizes that if machine learning is to improve patient care the models must be evaluated for their utility in improving clinical decisions taking into account the...},
	language = {en},
	urldate = {2019-08-14},
	journal = {JAMA},
	author = {Shah, Nigam H. and Milstein, Arnold and Steven C. Bagley, PhD},
	month = aug,
	year = {2019},
}

@article{beam_translating_2016,
	title = {Translating {Artificial} {Intelligence} {Into} {Clinical} {Care}},
	volume = {316},
	issn = {0098-7484},
	url = {https://jamanetwork.com/journals/jama/fullarticle/2588761},
	doi = {10.1001/jama.2016.17217},
	abstract = {Artificial intelligence has become a frequent topic in the news cycle, with reports of breakthroughs in speech recognition, computer vision, and textual underst},
	language = {en},
	number = {22},
	urldate = {2019-08-14},
	journal = {JAMA},
	author = {Beam, Andrew L. and Kohane, Isaac S.},
	month = dec,
	year = {2016},
	pages = {2368--2369},
}

@article{beam_big_2018,
	title = {Big {Data} and {Machine} {Learning} in {Health} {Care}},
	volume = {319},
	issn = {0098-7484},
	url = {https://jamanetwork.com/journals/jama/fullarticle/2675024},
	doi = {10.1001/jama.2017.18391},
	abstract = {This Viewpoint discusses how newer technologies such as machine learning and the compilation of “big data” can be used for research and clinical applications.},
	language = {en},
	number = {13},
	urldate = {2019-08-14},
	journal = {JAMA},
	author = {Beam, Andrew L. and Kohane, Isaac S.},
	month = apr,
	year = {2018},
	pages = {1317--1318},
}

@article{yu_artificial_2018,
	title = {Artificial intelligence in healthcare},
	volume = {2},
	copyright = {2018 Springer Nature Limited},
	issn = {2157-846X},
	url = {https://www.nature.com/articles/s41551-018-0305-z},
	doi = {10.1038/s41551-018-0305-z},
	abstract = {This Review summarizes the medical applications of artificial intelligence, and its economic, legal and social implications for healthcare.},
	language = {en},
	number = {10},
	urldate = {2019-08-14},
	journal = {Nature Biomedical Engineering},
	author = {Yu, Kun-Hsing and Beam, Andrew L. and Kohane, Isaac S.},
	month = oct,
	year = {2018},
	pages = {719--731},
}

@article{hochreiter_long_1997,
	title = {Long {Short}-{Term} {Memory}},
	volume = {9},
	issn = {0899-7667},
	url = {http://dx.doi.org/10.1162/neco.1997.9.8.1735},
	doi = {10.1162/neco.1997.9.8.1735},
	abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
	number = {8},
	urldate = {2019-08-09},
	journal = {Neural Comput.},
	author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
	month = nov,
	year = {1997},
	pages = {1735--1780},
}

@article{dozat_incorporating_2016,
	title = {Incorporating {Nesterov} {Momentum} into {Adam}},
	url = {https://openreview.net/forum?id=OM0jvwB8jIp57ZJjtNEZ},
	abstract = {This work aims to improve upon the recently proposed and rapidly popular-
  ized optimization algorithm Adam (Kingma \& Ba, 2014). Adam has two main
  components—a momentum component and an adaptive...},
	urldate = {2019-08-09},
	author = {Dozat, Timothy},
	month = feb,
	year = {2016},
}

@incollection{mohan_graphical_2013,
	title = {Graphical {Models} for {Inference} with {Missing} {Data}},
	url = {http://papers.nips.cc/paper/4899-graphical-models-for-inference-with-missing-data.pdf},
	urldate = {2019-08-08},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 26},
	publisher = {Curran Associates, Inc.},
	author = {Mohan, Karthika and Pearl, Judea and Tian, Jin},
	editor = {Burges, C. J. C. and Bottou, L. and Welling, M. and Ghahramani, Z. and Weinberger, K. Q.},
	year = {2013},
	pages = {1277--1285},
}

@article{bareinboim_causal_2016,
	title = {Causal inference and the data-fusion problem},
	volume = {113},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/113/27/7345},
	doi = {10.1073/pnas.1510507113},
	abstract = {We review concepts, principles, and tools that unify current approaches to causal analysis and attend to new challenges presented by big data. In particular, we address the problem of data fusion—piecing together multiple datasets collected under heterogeneous conditions (i.e., different populations, regimes, and sampling methods) to obtain valid answers to queries of interest. The availability of multiple heterogeneous datasets presents new opportunities to big data analysts, because the knowledge that can be acquired from combined data would not be possible from any individual source alone. However, the biases that emerge in heterogeneous environments require new analytical tools. Some of these biases, including confounding, sampling selection, and cross-population biases, have been addressed in isolation, largely in restricted parametric models. We here present a general, nonparametric framework for handling these biases and, ultimately, a theoretical solution to the problem of data fusion in causal inference tasks.},
	language = {en},
	number = {27},
	urldate = {2019-08-08},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Bareinboim, Elias and Pearl, Judea},
	month = jul,
	year = {2016},
	pmid = {27382148},
	keywords = {causal inference, counterfactuals, external validity, selection bias, transportability},
	pages = {7345--7352},
}

@article{tomasev_clinically_2019,
	title = {A clinically applicable approach to continuous prediction of future acute kidney injury},
	volume = {572},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-019-1390-1},
	doi = {10.1038/s41586-019-1390-1},
	abstract = {A deep learning approach that predicts the risk of acute kidney injury may help to identify patients at risk of health deterioration within a time window that enables early treatment.},
	language = {En},
	number = {7767},
	urldate = {2019-07-31},
	journal = {Nature},
	author = {Tomašev, Nenad and Glorot, Xavier and Rae, Jack W. and Zielinski, Michal and Askham, Harry and Saraiva, Andre and Mottram, Anne and Meyer, Clemens and Ravuri, Suman and Protsyuk, Ivan and Connell, Alistair and Hughes, Cían O. and Karthikesalingam, Alan and Cornebise, Julien and Montgomery, Hugh and Rees, Geraint and Laing, Chris and Baker, Clifton R. and Peterson, Kelly and Reeves, Ruth and Hassabis, Demis and King, Dominic and Suleyman, Mustafa and Back, Trevor and Nielson, Christopher and Ledsam, Joseph R. and Mohamed, Shakir},
	month = aug,
	year = {2019},
	pages = {116},
}

@article{packiasabapathy_significance_2018,
	title = {Significance of intra-operative blood pressure data resolution: {A} retrospective, observational study},
	volume = {7},
	issn = {2046-1402},
	shorttitle = {Significance of intra-operative blood pressure data resolution},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6008844/},
	doi = {10.12688/f1000research.13810.1},
	abstract = {Background: With evolving techniques for analysis of blood pressure (BP) variability, the importance of sampling resolution for intra-operative BP still remains to be examined. This study aims at comparing BP data with beat-by-beat vs. 15 second resolution., 
Methods: This is a retrospective analysis of intra-arterial BP data obtained from cardiac surgical patients from the intra-operative period. Data was collected from two sources for each patient, one with beat-by-beat frequency, other at a frequency of once every 15 seconds. The fraction of time and area under the curve beyond systolic BP thresholds of 95 – 135 mmHg were calculated using data from both sources, for each patient. These were compared using Wilcoxon ranked sum test for paired samples using R-statistics version 3.4.3., 
Results: There was a statistically significant difference (P {\textless} 0.001) between the parameters from the two sources. This was especially true for parameters below and outside the thresholds. Only time fraction showed significant difference above the 135 mmHg threshold., 
Conclusion: Our preliminary analysis shows a definitive difference between BP descriptors, depending on sampling resolution. But the impact of this difference on the outcome predicting models of the parameters stands to be ascertained. Future larger studies, powered to examine the impact of sampling resolution on outcome predictive ability of BP descriptors, with special emphasis on dynamic markers of complexity are warranted.},
	urldate = {2019-07-24},
	journal = {F1000Research},
	author = {Packiasabapathy, Senthil and Susheela, Ammu T. and Mujica, Fernando and Subramaniam, Balachundhar},
	month = mar,
	year = {2018},
	pmid = {29946438},
	pmcid = {PMC6008844},
}

@article{arjovsky_invariant_2019,
	title = {Invariant {Risk} {Minimization}},
	url = {http://arxiv.org/abs/1907.02893},
	abstract = {We introduce Invariant Risk Minimization (IRM), a learning paradigm to estimate invariant correlations across multiple training distributions. To achieve this goal, IRM learns a data representation such that the optimal classifier, on top of that data representation, matches for all training distributions. Through theory and experiments, we show how the invariances learned by IRM relate to the causal structures governing the data and enable out-of-distribution generalization.},
	urldate = {2019-07-24},
	journal = {arXiv:1907.02893 [cs, stat]},
	author = {Arjovsky, Martin and Bottou, Léon and Gulrajani, Ishaan and Lopez-Paz, David},
	month = jul,
	year = {2019},
	note = {arXiv: 1907.02893},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{locatello_disentangling_2019,
	title = {Disentangling {Factors} of {Variation} {Using} {Few} {Labels}},
	url = {http://arxiv.org/abs/1905.01258},
	abstract = {Learning disentangled representations is considered a cornerstone problem in representation learning. Recently, Locatello et al. (2019) demonstrated that unsupervised disentanglement learning without inductive biases is theoretically impossible and that existing inductive biases and unsupervised methods do not allow to consistently learn disentangled representations. However, in many practical settings, one might have access to a very limited amount of supervision, for example through manual labeling of training examples. In this paper, we investigate the impact of such supervision on state-of-the-art disentanglement methods and perform a large scale study, training over 29000 models under well-defined and reproducible experimental conditions. We first observe that a very limited number of labeled examples (0.01--0.5\% of the data set) is sufficient to perform model selection on state-of-the-art unsupervised models. Yet, if one has access to labels for supervised model selection, this raises the natural question of whether they should also be incorporated into the training process. As a case-study, we test the benefit of introducing (very limited) supervision into existing state-of-the-art unsupervised disentanglement methods exploiting both the values of the labels and the ordinal information that can be deduced from them. Overall, we empirically validate that with very little and potentially imprecise supervision it is possible to reliably learn disentangled representations.},
	urldate = {2019-07-23},
	journal = {arXiv:1905.01258 [cs, stat]},
	author = {Locatello, Francesco and Tschannen, Michael and Bauer, Stefan and Rätsch, Gunnar and Schölkopf, Bernhard and Bachem, Olivier},
	month = may,
	year = {2019},
	note = {arXiv: 1905.01258},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{beinlich_alarm_1989,
	series = {Lecture {Notes} in {Medical} {Informatics}},
	title = {The {ALARM} {Monitoring} {System}: {A} {Case} {Study} with two {Probabilistic} {Inference} {Techniques} for {Belief} {Networks}},
	isbn = {978-3-642-93437-7},
	shorttitle = {The {ALARM} {Monitoring} {System}},
	abstract = {ALARM (A Logical Alarm Reduction Mechanism) is a diagnostic application used to explore probabilistic reasoning techniques in belief networks. ALARM implements an alarm message system for patient monitoring; it calculates probabilities for a differential diagnosis based on available evidence. The medical knowledge is encoded in a graphical structure connecting 8 diagnoses, 16 findings and 13 intermediate variables. Two algorithms were applied to this belief network: (1) a message-passing algorithm by Pearl for probability updating in multiply connected networks using the method of conditioning; and (2) the Lauritzen-Spiegelhalter algorithm for local probability computations on graphical structures. The characteristics of both algorithms are analyzed and their specific applications and time complexities are shown.},
	language = {en},
	booktitle = {{AIME} 89},
	publisher = {Springer Berlin Heidelberg},
	author = {Beinlich, Ingo A. and Suermondt, H. J. and Chavez, R. Martin and Cooper, Gregory F.},
	editor = {Hunter, Jim and Cookson, John and Wyatt, Jeremy},
	year = {1989},
	keywords = {Blocking Condition, Central Venous Pressure, Evidence Propagation, Large Clique, Total Peripheral Resistance},
	pages = {247--256},
}

@article{nelson_integrating_2019,
	title = {Integrating biomedical research and electronic health records to create knowledge-based biologically meaningful machine-readable embeddings},
	volume = {10},
	copyright = {2019 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-019-11069-0},
	doi = {10.1038/s41467-019-11069-0},
	abstract = {The Scalable Precision Medicine Oriented Knowledge Engine (SPOKE) is a heterogeneous knowledge network that integrates information from 29 public databases. Here, Nelson et al. extend SPOKE to embed clinical data from electronic health records to create medically meaningful barcodes for each medical variable.},
	language = {En},
	number = {1},
	urldate = {2019-07-11},
	journal = {Nature Communications},
	author = {Nelson, Charlotte A. and Butte, Atul J. and Baranzini, Sergio E.},
	month = jul,
	year = {2019},
	pages = {3045},
}

@article{wijst_single-cell_2018,
	title = {Single-cell {RNA} sequencing identifies celltype-specific cis-{eQTLs} and co-expression {QTLs}},
	volume = {50},
	copyright = {2018 The Author(s)},
	issn = {1546-1718},
	url = {https://www.nature.com/articles/s41588-018-0089-9},
	doi = {10.1038/s41588-018-0089-9},
	abstract = {Single-cell RNA sequencing (scRNA-seq) of {\textasciitilde}25,000 peripheral blood mononuclear cells from 45 donors identifies new celltype-specific cis-eQTLs and genetic variants that significantly alter co-expression relationships (‘co-expression QTLs’).},
	language = {En},
	number = {4},
	urldate = {2019-07-09},
	journal = {Nature Genetics},
	author = {Wijst, Monique G. P. van der and Brugge, Harm and Vries, Dylan H. de and Deelen, Patrick and Swertz, Morris A. and Franke, Lude},
	month = apr,
	year = {2018},
	pages = {493},
}

@article{hwang_single-cell_2018,
	title = {Single-cell {RNA} sequencing technologies and bioinformatics pipelines},
	volume = {50},
	copyright = {2018 The Author(s)},
	issn = {2092-6413},
	url = {https://www.nature.com/articles/s12276-018-0071-8},
	doi = {10.1038/s12276-018-0071-8},
	abstract = {Showing which genes are expressed, or switched on, in individual cells may help to reveal the first signs of disease. Each cell in an organism contains the same genetic information, but cell type and behavior depend on which genes are expressed. Previously, researchers could only sequence cells in batches, averaging the results, but technological improvements now allow sequencing of the genes expressed in an individual cell, known as single-cell RNA sequencing (scRNA-seq). Ji Hyun Lee (Kyung Hee University, Seoul) and Duhee Bang and Byungjin Hwang (Yonsei University, Seoul) have reviewed the available scRNA-seq technologies and the strategies available to analyze the large quantities of data produced. They conclude that scRNA-seq will impact both basic and medical science, from illuminating drug resistance in cancer to revealing the complex pathways of cell differentiation during development.},
	language = {En},
	number = {8},
	urldate = {2019-07-09},
	journal = {Experimental \& Molecular Medicine},
	author = {Hwang, Byungjin and Lee, Ji Hyun and Bang, Duhee},
	month = aug,
	year = {2018},
	pages = {96},
}

@misc{noauthor_integrative_nodate,
	title = {Integrative single-cell analysis {\textbar} {Nature} {Reviews} {Genetics}},
	url = {https://www.nature.com/articles/s41576-019-0093-7},
	urldate = {2019-07-09},
}

@article{zadi_mathematical_2018,
	title = {Mathematical {Modeling} of {Arterial} {Blood} {Pressure} {Using} {Photo}-{Plethysmography} {Signal} in {Breath}-hold {Maneuver}},
	url = {http://arxiv.org/abs/1811.06541},
	doi = {10.1109/EMBC.2018.8512776},
	abstract = {Recent research has shown that each apnea episode results in a significant rise in the beat-to-beat blood pressure and by a drop to the pre-episode levels when patient resumes normal breathing. While the physiological implications of these repetitive and significant oscillations are still unknown, it is of interest to quantify them. Since current array of instruments deployed for polysomnography studies does not include beat-to-beat measurement of blood pressure, but includes oximetry, it is both of clinical interest to estimate the magnitude of BP oscillations from the photoplethysmography (PPG) signal that is readily available from sleep lab oximeters. We have investigated a new method for continuous estimation of systolic (SBP), diastolic (DBP), and mean (MBP) blood pressure waveforms from PPG. Peaks and troughs of PPG waveform are used as input to a 5th order autoregressive moving average model to construct estimates of SBP, DBP, and MBP waveforms. Since breath hold maneuvers are shown to simulate apnea episodes faithfully, we evaluated the performance of the proposed method in 7 subjects (4 F; 32+-4 yrs., BMI 24.57+-3.87 kg/m2) in supine position doing 5 breath maneuvers with 90s of normal breathing between them. The modeling error ranges were (all units are in mmHg) -0.88+-4.87 to -2.19+-5.73 (SBP); 0.29+-2.39 to -0.97+-3.83 (DBP); and -0.42+-2.64 to -1.17+-3.82 (MBP). The cross validation error ranges were 0.28+-6.45 to -1.74+-6.55 (SBP); 0.09+-3.37 to -0.97+-3.67 (DBP); and 0.33+-4.34 to -0.87+-4.42 (MBP). The level of estimation error in, as measured by the root mean squared of the model residuals, was less than 7 mmHg},
	urldate = {2019-06-27},
	journal = {2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)},
	author = {Zadi, Armin Soltan and Alex, Raichel M. and Zhang, Rong and Watenpaugh, Donald E. and Behbehani, Khosrow},
	month = jul,
	year = {2018},
	note = {arXiv: 1811.06541},
	keywords = {Computer Science - Computational Engineering, Finance, and Science, Electrical Engineering and Systems Science - Signal Processing},
	pages = {2711--2714},
}

@article{goldberger_ary_l._physiobank_2000,
	title = {{PhysioBank}, {PhysioToolkit}, and {PhysioNet}},
	volume = {101},
	url = {https://www.ahajournals.org/doi/full/10.1161/01.cir.101.23.e215},
	doi = {10.1161/01.CIR.101.23.e215},
	abstract = {—The newly inaugurated Research Resource for Complex Physiologic Signals, which was created under the auspices of the National Center for Research Resources of the National Institutes of Health, is intended to stimulate current research and new investigations in the study of cardiovascular and other complex biomedical signals. The resource has 3 interdependent components. PhysioBank is a large and growing archive of well-characterized digital recordings of physiological signals and related data for use by the biomedical research community. It currently includes databases of multiparameter cardiopulmonary, neural, and other biomedical signals from healthy subjects and from patients with a variety of conditions with major public health implications, including life-threatening arrhythmias, congestive heart failure, sleep apnea, neurological disorders, and aging. PhysioToolkit is a library of open-source software for physiological signal processing and analysis, the detection of physiologically significant events using both classic techniques and novel methods based on statistical physics and nonlinear dynamics, the interactive display and characterization of signals, the creation of new databases, the simulation of physiological and other signals, the quantitative evaluation and comparison of analysis methods, and the analysis of nonstationary processes. PhysioNet is an on-line forum for the dissemination and exchange of recorded biomedical signals and open-source software for analyzing them. It provides facilities for the cooperative analysis of data and the evaluation of proposed new algorithms. In addition to providing free electronic access to PhysioBank data and PhysioToolkit software via the World Wide Web (http://www.physionet.org), PhysioNet offers services and training via on-line tutorials to assist users with varying levels of expertise.},
	number = {23},
	urldate = {2019-06-26},
	journal = {Circulation},
	author = {{Goldberger Ary L.} and {Amaral Luis A. N.} and {Glass Leon} and {Hausdorff Jeffrey M.} and {Ivanov Plamen Ch.} and {Mark Roger G.} and {Mietus Joseph E.} and {Moody George B.} and {Peng Chung-Kang} and {Stanley H. Eugene}},
	month = jun,
	year = {2000},
	pages = {e215--e220},
}

@article{johnson_mimic-iii_2016,
	title = {{MIMIC}-{III}, a freely accessible critical care database},
	volume = {3},
	copyright = {2016 Nature Publishing Group},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/sdata201635},
	doi = {10.1038/sdata.2016.35},
	abstract = {MIMIC-III (‘Medical Information Mart for Intensive Care’) is a large, single-center database comprising information relating to patients admitted to critical care units at a large tertiary care hospital. Data includes vital signs, medications, laboratory measurements, observations and notes charted by care providers, fluid balance, procedure codes, diagnostic codes, imaging reports, hospital length of stay, survival data, and more. The database supports applications including academic and industrial research, quality improvement initiatives, and higher education coursework.},
	language = {en},
	urldate = {2019-06-26},
	journal = {Scientific Data},
	author = {Johnson, Alistair E. W. and Pollard, Tom J. and Shen, Lu and Lehman, Li-wei H. and Feng, Mengling and Ghassemi, Mohammad and Moody, Benjamin and Szolovits, Peter and Anthony Celi, Leo and Mark, Roger G.},
	month = may,
	year = {2016},
	pages = {160035},
}

@article{tian_benchmarking_2019,
	title = {Benchmarking single cell {RNA}-sequencing analysis pipelines using mixture control experiments},
	volume = {16},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/s41592-019-0425-8},
	doi = {10.1038/s41592-019-0425-8},
	abstract = {A dataset made up of single cancer cells or their mixtures serves as a benchmark for testing almost 4,000 combinations of scRNA-seq data analysis methods.},
	language = {En},
	number = {6},
	urldate = {2019-06-26},
	journal = {Nature Methods},
	author = {Tian, Luyi and Dong, Xueyi and Freytag, Saskia and Cao, Kim-Anh Lê and Su, Shian and JalalAbadi, Abolfazl and Amann-Zalcenstein, Daniela and Weber, Tom S. and Seidi, Azadeh and Jabbari, Jafar S. and Naik, Shalin H. and Ritchie, Matthew E.},
	month = jun,
	year = {2019},
	pages = {479},
}

@article{galloway_development_2019,
	title = {Development and {Validation} of a {Deep}-{Learning} {Model} to {Screen} for {Hyperkalemia} {From} the {Electrocardiogram}},
	volume = {4},
	issn = {2380-6583},
	url = {https://jamanetwork.com/journals/jamacardiology/fullarticle/2729582},
	doi = {10.1001/jamacardio.2019.0640},
	abstract = {{\textless}h3{\textgreater}Importance{\textless}/h3{\textgreater}{\textless}p{\textgreater}For patients with chronic kidney disease (CKD), hyperkalemia is common, associated with fatal arrhythmias, and often asymptomatic, while guideline-directed monitoring of serum potassium is underused. A deep-learning model that enables noninvasive hyperkalemia screening from the electrocardiogram (ECG) may improve detection of this life-threatening condition.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Objective{\textless}/h3{\textgreater}{\textless}p{\textgreater}To evaluate the performance of a deep-learning model in detection of hyperkalemia from the ECG in patients with CKD.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Design, Setting, and Participants{\textless}/h3{\textgreater}{\textless}p{\textgreater}A deep convolutional neural network (DNN) was trained using 1 576 581 ECGs from 449 380 patients seen at Mayo Clinic, Rochester, Minnesota, from 1994 to 2017. The DNN was trained using 2 (leads I and II) or 4 (leads I, II, V3, and V5) ECG leads to detect serum potassium levels of 5.5 mEq/L or less (to convert to millimoles per liter, multiply by 1) and was validated using retrospective data from the Mayo Clinic in Minnesota, Florida, and Arizona. The validation included 61 965 patients with stage 3 or greater CKD. Each patient had a serum potassium count drawn within 4 hours after their ECG was recorded. Data were analyzed between April 12, 2018, and June 25, 2018.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Exposures{\textless}/h3{\textgreater}{\textless}p{\textgreater}Use of a deep-learning model.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Main Outcomes and Measures{\textless}/h3{\textgreater}{\textless}p{\textgreater}Area under the receiver operating characteristic curve (AUC) and sensitivity and specificity, with serum potassium level as the reference standard. The model was evaluated at 2 operating points, 1 for equal specificity and sensitivity and another for high (90\%) sensitivity.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Results{\textless}/h3{\textgreater}{\textless}p{\textgreater}Of the total 1 638 546 ECGs, 908 000 (55\%) were from men. The prevalence of hyperkalemia in the 3 validation data sets ranged from 2.6\% (n = 1282 of 50 099; Minnesota) to 4.8\% (n = 287 of 6011; Florida). Using ECG leads I and II, the AUC of the deep-learning model was 0.883 (95\% CI, 0.873-0.893) for Minnesota, 0.860 (95\% CI, 0.837-0.883) for Florida, and 0.853 (95\% CI, 0.830-0.877) for Arizona. Using a 90\% sensitivity operating point, the sensitivity was 90.2\% (95\% CI, 88.4\%-91.7\%) and specificity was 63.2\% (95\% CI, 62.7\%-63.6\%) for Minnesota; the sensitivity was 91.3\% (95\% CI, 87.4\%-94.3\%) and specificity was 54.7\% (95\% CI, 53.4\%-56.0\%) for Florida; and the sensitivity was 88.9\% (95\% CI, 84.5\%-92.4\%) and specificity was 55.0\% (95\% CI, 53.7\%-56.3\%) for Arizona.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Conclusions and Relevance{\textless}/h3{\textgreater}{\textless}p{\textgreater}In this study, using only 2 ECG leads, a deep-learning model detected hyperkalemia in patients with renal disease with an AUC of 0.853 to 0.883. The application of artificial intelligence to the ECG may enable screening for hyperkalemia. Prospective studies are warranted.{\textless}/p{\textgreater}},
	language = {en},
	number = {5},
	urldate = {2019-06-25},
	journal = {JAMA Cardiology},
	author = {Galloway, Conner D. and Valys, Alexander V. and Shreibati, Jacqueline B. and Treiman, Daniel L. and Petterson, Frank L. and Gundotra, Vivek P. and Albert, David E. and Attia, Zachi I. and Carter, Rickey E. and Asirvatham, Samuel J. and Ackerman, Michael J. and Noseworthy, Peter A. and Dillon, John J. and Friedman, Paul A.},
	month = may,
	year = {2019},
	pages = {428--436},
}

@book{marino_marinos_2013,
	title = {Marino's the {ICU} {Book}},
	publisher = {Lippincott Williams \& Wilkins},
	author = {Marino, Paul L},
	year = {2013},
}

@article{bur_factors_2003,
	title = {Factors influencing the accuracy of oscillometric blood pressure measurement in critically ill patients},
	volume = {31},
	issn = {0090-3493},
	url = {https://journals.lww.com/ccmjournal/fulltext/2003/03000/Factors_influencing_the_accuracy_of_oscillometric.21.aspx},
	doi = {10.1097/01.CCM.0000053650.12025.1A},
	abstract = {Objective Comparison of oscillometric blood pressure measurement with two different devices (M3000A using a new algorithm and M1008A using an established algorithm, both Hewlett Packard) and evaluation of current recommendations concerning the relation between cuff size and upper arm circumference in critically ill patients.
        Design Prospective data collection.
        Setting Emergency department in a 2000-bed inner-city hospital.
        Patients A total of 30 patients categorized into three groups according to their upper arm circumference (I, 18–25 cm; II, 25.1–33 cm; III, 33.1–47.5 cm) were enrolled in the study protocol.
        Interventions In each patient, two noninvasive blood pressure devices with three different cuff sizes were used to perform oscillometric blood pressure measurement. Invasive mean arterial blood pressure measurement was done by cannulation of the radial artery.
        Measurement and Main Results Overall, 1,011 pairs of simultaneous oscillometric and invasive blood pressure measurements were collected in 30 patients (group I, n = 10; group II, n = 10; group III, n = 10). The overall discrepancy between both methods with the M3000A was −2.4 ± 11.8 mm Hg (p {\textless} .0001) and, with the M1008A, −5.3 ± 11.6 mm Hg (p {\textless} .0001) if the recommended cuff size according to the upper arm circumference was used (352 measurements). If smaller cuff sizes than recommended were used (308 measurements performed in group II and III), the overall discrepancy between both methods with the M3000A was 1.3 ± 13.4 mm Hg (p {\textless} .024) and, with the M1008A, −2.3 ± 11.5 mm Hg (p {\textless} .0001).
        Conclusion The new algorithm reduced the overall bias of the oscillometric method but still showed a significant discrepancy between both methods of blood pressure measurement, primarily due to the mismatch between upper arm circumference and cuff size. The improvement of the algorithm alone could not result in a sufficient improvement of oscillometric blood pressure measurement. A reevaluation of the recommendations concerning the relation between upper arm circumference and cuff size are urgently required if oscillometric blood pressure measurement should become a reasonable alternative to intra-arterial blood pressure measurement in critically ill patients.},
	language = {en-US},
	number = {3},
	urldate = {2019-06-24},
	journal = {Critical Care Medicine},
	author = {Bur, Andreas and Herkner, Harald and Vlcek, Marianne and Woisetschläger, Christian and Derhaschnig, Ulla and Delle Karth, Georg and Laggner, Anton N. and Hirschl, Michael M.},
	month = mar,
	year = {2003},
	pages = {793},
}

@article{bur_accuracy_2000,
	title = {Accuracy of oscillometric blood pressure measurement according to the relation between cuff size and upper-arm circumference in critically ill patients},
	volume = {28},
	issn = {0090-3493},
	url = {https://journals.lww.com/ccmjournal/Fulltext/2000/02000/Accuracy_of_oscillometric_blood_pressure.14.aspx},
	abstract = {Objective: To evaluate the accuracy of oscillometric blood pressure measurement according to the relation between cuff size and upper-arm circumference in critically ill patients.
        Design: Prospective data collection.
        Setting: Emergency department in a 2,000-bed inner city hospital.
        Patients: Thirty-eight patients categorized into three groups according to their upper-arm circumference (group I: 18-25 cm; group II: 25.1-33 cm; and group III: 33.1-47.5 cm) were enrolled in the study protocol.
        Interventions: In each patient, all three cuff sizes (Hewlett-Packard Cuff 40401 B, C, and D) were used to perform an oscillometric blood pressure measurement at least within 3 mins until ten to 20 measurements for each cuff size were achieved. Invasive mean arterial blood pressure measurement was done by cannulation of the contralateral radial artery with direct transduction of the systemic arterial pressure waveform. The corresponding invasive blood pressure value was obtained at the end of each oscillometric measurement.
        Measurement and Main Results: Overall, 1,494 pairs of simultaneous oscillometric and invasive blood pressure measurements were collected in 38 patients (group I, n = 5; group II, n = 23; and group III, n = 10) over a total time of 72.3 hrs. Mean arterial blood pressure ranged from 35 to 165 mm Hg. The overall discrepancy between oscillometric and invasive blood pressure measurement was −6.7 ± 9.7 mm Hg (p{\textless} .0001), if the recommended cuff size according to the upper-arm circumference was used (539 measurements). Of all the blood pressure measurements, 26.4\% (n = 395) had a discrepancy of ≥10 mm Hg and 34.2\% (n = 512) exhibited a discrepancy of ≥20 mm Hg. No differences between invasive and noninvasive blood pressure measurements were noted in patients either with or without inotropic support (−6.6 + 7.2 vs. −8.6 + 6.8 mm Hg; not significant).
        Conclusion: The oscillometric blood pressure measurement significantly underestimates arterial blood pressure and exhibits a high number of measurements out of the clinically acceptable range. The relation between cuff size and upper-arm circumference contributes substantially to the inaccuracy of the oscillometric blood pressure measurement. Therefore, oscillometric blood pressure measurement does not achieve adequate accuracy in critically ill patients.},
	language = {en-US},
	number = {2},
	urldate = {2019-06-24},
	journal = {Critical Care Medicine},
	author = {Bur, Andreas and Hirschl, Michael M. and Herkner, Harald and Oschatz, Elisabeth and Kofler, Julia and Woisetschläger, Christian and Laggner, Anton N.},
	month = feb,
	year = {2000},
	pages = {371},
}

@article{wax_invasive_2011,
	title = {Invasive and {Concomitant} {Noninvasive} {Intraoperative} {Blood} {Pressure} {MonitoringObserved} {Differences} in {Measurements} and {Associated} {Therapeutic} {Interventions}},
	volume = {115},
	issn = {0003-3022},
	url = {http://anesthesiology.pubs.asahq.org/article.aspx?articleid=1934058},
	doi = {10.1097/ALN.0b013e3182330286},
	abstract = {Observed Differences in Measurements and Associated Therapeutic Interventions},
	language = {en},
	number = {5},
	urldate = {2019-06-24},
	journal = {Anesthesiology: The Journal of the American Society of Anesthesiologists},
	author = {Wax, David B. and Lin, Hung-Mo and Leibowitz, Andrew B.},
	month = nov,
	year = {2011},
	pages = {973--978},
}

@article{hicks_missing_2018,
	title = {Missing data and technical variability in single-cell {RNA}-sequencing experiments},
	volume = {19},
	issn = {1465-4644},
	url = {https://academic.oup.com/biostatistics/article/19/4/562/4599254},
	doi = {10.1093/biostatistics/kxx053},
	abstract = {SUMMARY.  Until recently, high-throughput gene expression technology, such as RNA-Sequencing (RNA-seq) required hundreds of thousands of cells to produce reliab},
	language = {en},
	number = {4},
	urldate = {2019-06-21},
	journal = {Biostatistics},
	author = {Hicks, Stephanie C. and Townes, F. William and Teng, Mingxiang and Irizarry, Rafael A.},
	month = oct,
	year = {2018},
	pages = {562--578},
}

@article{wang_cardiac_2017,
	title = {Cardiac surgery-associated acute kidney injury: risk factors, pathophysiology and treatment},
	volume = {13},
	copyright = {2017 Nature Publishing Group},
	issn = {1759-507X},
	shorttitle = {Cardiac surgery-associated acute kidney injury},
	url = {https://www.nature.com/articles/nrneph.2017.119},
	doi = {10.1038/nrneph.2017.119},
	abstract = {Cardiac surgery-associated acute kidney injury (CSA-AKI) is the most common clinically important complication in adult patients undergoing open heart surgery, and is associated with increased mortality and morbidity. In patients in intensive care units, CSA-AKI is the second most common type of AKI after septic AKI. In this Review, we explore the definition of CSA-AKI, discuss its epidemiology and identify its risk factors. We discuss current theories of the pathophysiology of CSA-AKI and describe its clinical course. Furthermore, we introduce diagnostic tools with particular reference to novel biomarkers of AKI and their potential utility; we analyse currently applied interventions aimed at attenuating AKI in patients undergoing cardiac surgery; and describe evidence from randomized controlled trials aimed at preventing or treating CSA-AKI. Finally, we explore issues in the use of renal replacement therapy, its timing, its intensity and its preferred modalities in patients with CSA-AKI, and we discuss the prognosis of CSA-AKI in terms of patient survival and kidney recovery.},
	language = {en},
	number = {11},
	urldate = {2019-06-20},
	journal = {Nature Reviews Nephrology},
	author = {Wang, Ying and Bellomo, Rinaldo},
	month = nov,
	year = {2017},
	pages = {697--711},
}

@article{xing_unobtrusive_2019,
	title = {An {Unobtrusive} and {Calibration}-free {Blood} {Pressure} {Estimation} {Method} using {Photoplethysmography} and {Biometrics}},
	volume = {9},
	copyright = {2019 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-019-45175-2},
	doi = {10.1038/s41598-019-45175-2},
	abstract = {We introduce a novel paradigm to unobtrusively and optically measure blood pressure (BP) without calibration. The algorithm combines photoplethysmography (PPG) waveform analysis and biometrics to estimate BP, and was evaluated in subjects with various age, height, weight and BP levels (n = 1249). In the young population ({\textless}50 years old) with low, medium and high systolic blood pressures (SBP, {\textless}120 mmHg; 120–139 mmHg; ≥140 mmHg), the fitting errors are 6.3 ± 7.2, −3.9 ± 7.2 and −20.2 ± 14.2 mmHg for SBP respectively; In the older population ({\textgreater}50 years old) with the same categories, the fitting errors are 12.8 ± 9.0, 0.5 ± 8.2 and −14.6 ± 11.5 mmHg for SBP respectively. A simple personalized calibration reduces fitting errors significantly (n = 147), and good peripheral perfusion helps to improve the fitting accuracy. In conclusion, PPG may be used to calculate BP without calibration in certain populations. When calibrated, it shows great potential to serially monitor BP fluctuation, which can bring tremendous economic and health benefits.},
	language = {En},
	number = {1},
	urldate = {2019-06-18},
	journal = {Scientific Reports},
	author = {Xing, Xiaoman and Ma, Zhimin and Zhang, Mingyou and Zhou, Ying and Dong, Wenfei and Song, Mingxuan},
	month = jun,
	year = {2019},
	pages = {8611},
}

@article{yamada_improving_2018,
	title = {Improving {Perioperative} {Outcomes} {Through} {Minimally} {Invasive} and {Non}-invasive {Hemodynamic} {Monitoring} {Techniques}},
	volume = {5},
	issn = {2296-858X},
	url = {https://www.frontiersin.org/articles/10.3389/fmed.2018.00144/full},
	doi = {10.3389/fmed.2018.00144},
	abstract = {An increasing number of patients require precise intraoperative hemodynamic monitoring due to aging and comorbidities. To prevent undesirable outcomes from intraoperative hypotension or hypoperfusion, appropriate threshold settings are required. These setting can vary widely from patient to patient. Goal-directed therapy techniques allow for flow monitoring as the standard for perioperative fluid management. Based on the concept of personalized medicine, individual assessment and treatment are more advantageous than conventional or uniform interventions. The recent development of minimally and noninvasive monitoring devices make it possible to apply detailed control, tracking and observation of broad patient populations, all while reducing adverse complications. In this manuscript, we review the monitoring features of each device, together with possible advantages and disadvantages of their use in optimizing patient hemodynamic management.},
	language = {English},
	urldate = {2019-06-11},
	journal = {Frontiers in Medicine},
	author = {Yamada, Takashige and Vacas, Susana and Gricourt, Yann and Cannesson, Maxime},
	year = {2018},
	keywords = {Delirium, Minimal Invasive, Monitoring, hemodynamic, noninvasive},
}

@inproceedings{sideris_building_2016,
	title = {Building {Continuous} {Arterial} {Blood} {Pressure} {Prediction} {Models} {Using} {Recurrent} {Networks}},
	doi = {10.1109/SMARTCOMP.2016.7501681},
	abstract = {This paper presents a methodology for developing highly-accurate, continuous Arterial Blood Pressure (ABP) models using only Photoplethysmography (PPG). In contrast to prior approaches, we develop a system that exhibits dynamic temporal behavior which leads to increased accuracy in modeling ABP. We validate our approach using data from patients in the intensive care unit (ICU). We show that it is possible to build highly accurate, continuous blood pressure models using only finger pulse oximeters. Our methodology achieves accurate systolic blood pressure estimation with a root mean square error 2.58 ± 1.23 across the patient sample used. Furthermore, the continuous ABP signal is estimated with a root mean square error of 6.042 ± 3.26 and correlation coefficient of 0.95 ± 0.045. Our method enables designing robust Remote Health Monitoring Systems (RMS) for Heart Failure patients without requiring traditional blood pressure monitors.},
	booktitle = {2016 {IEEE} {International} {Conference} on {Smart} {Computing} ({SMARTCOMP})},
	author = {Sideris, C. and Kalantarian, H. and Nemati, E. and Sarrafzadeh, M.},
	month = may,
	year = {2016},
	keywords = {ABP models, ABP signal estimation, Arterial blood pressure, Biomedical monitoring, Blood pressure, Heart, ICU, Linear regression, Monitoring, PPG, RMS, Training, blood pressure measurement, continuous arterial blood pressure prediction models, correlation coefficient, finger pulse oximeters, heart failure patients, intensive care unit, medical signal processing, photoplethysmography, recurrent networks, recurrent neural nets, remote health monitoring systems, root mean square error, systolic blood pressure estimation},
	pages = {1--5},
}

@article{gottlieb_method_2013,
	title = {A method for inferring medical diagnoses from patient similarities},
	volume = {11},
	issn = {1741-7015},
	url = {https://doi.org/10.1186/1741-7015-11-194},
	doi = {10.1186/1741-7015-11-194},
	abstract = {Clinical decision support systems assist physicians in interpreting complex patient data. However, they typically operate on a per-patient basis and do not exploit the extensive latent medical knowledge in electronic health records (EHRs). The emergence of large EHR systems offers the opportunity to integrate population information actively into these tools.},
	number = {1},
	urldate = {2019-05-23},
	journal = {BMC Medicine},
	author = {Gottlieb, Assaf and Stein, Gideon Y. and Ruppin, Eytan and Altman, Russ B. and Sharan, Roded},
	month = sep,
	year = {2013},
	pages = {194},
}

@article{bihorac_mysurgeryrisk:_2019,
	title = {{MySurgeryRisk}: {Development} and {Validation} of a {Machine}-learning {Risk} {Algorithm} for {Major} {Complications} and {Death} {After} {Surgery}},
	volume = {269},
	issn = {0003-4932},
	shorttitle = {{MySurgeryRisk}},
	url = {https://journals.lww.com/annalsofsurgery/fulltext/2019/04000/MySurgeryRisk__Development_and_Validation_of_a.11.aspx},
	doi = {10.1097/SLA.0000000000002706},
	abstract = {Objective: To accurately calculate the risk for postoperative complications and death after surgery in the preoperative period using machine-learning modeling of clinical data.
        Background: Postoperative complications cause a 2-fold increase in the 30-day mortality and cost, and are associated with long-term consequences. The ability to precisely forecast the risk for major complications before surgery is limited.
        Methods: In a single-center cohort of 51,457 surgical patients undergoing major inpatient surgery, we have developed and validated an automated analytics framework for a preoperative risk algorithm (MySurgeryRisk) that uses existing clinical data in electronic health records to forecast patient-level probabilistic risk scores for 8 major postoperative complications (acute kidney injury, sepsis, venous thromboembolism, intensive care unit admission {\textgreater}48 hours, mechanical ventilation {\textgreater}48 hours, wound, neurologic, and cardiovascular complications) and death up to 24 months after surgery. We used the area under the receiver characteristic curve (AUC) and predictiveness curves to evaluate model performance.
        Results: MySurgeryRisk calculates probabilistic risk scores for 8 postoperative complications with AUC values ranging between 0.82 and 0.94 [99\% confidence intervals (CIs) 0.81–0.94]. The model predicts the risk for death at 1, 3, 6, 12, and 24 months with AUC values ranging between 0.77 and 0.83 (99\% CI 0.76–0.85).
        Conclusions: We constructed an automated predictive analytics framework for machine-learning algorithm with high discriminatory ability for assessing the risk of surgical complications and death using readily available preoperative electronic health records data. The feasibility of this novel algorithm implemented in real time clinical workflow requires further testing.},
	language = {en-US},
	number = {4},
	urldate = {2019-05-21},
	journal = {Annals of Surgery},
	author = {Bihorac, Azra and Ozrazgat-Baslanti, Tezcan and Ebadi, Ashkan and Motaei, Amir and Madkour, Mohcine and Pardalos, Panagote M. and Lipori, Gloria and Hogan, William R. and Efron, Philip A. and Moore, Frederick and Moldawer, Lyle L. and Wang, Daisy Zhe and Hobson, Charles E. and Rashidi, Parisa and Li, Xiaolin and Momcilovic, Petar},
	month = apr,
	year = {2019},
	pages = {652},
}

@article{rajkomar_scalable_2018,
	title = {Scalable and accurate deep learning with electronic health records},
	volume = {1},
	copyright = {2018 The Author(s)},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-018-0029-1},
	doi = {10.1038/s41746-018-0029-1},
	abstract = {Artificial intelligence outperforms traditional statistical models at predicting a range of clinical outcomes from a patient’s entire raw electronic health record (EHR). A team led by Alvin Rajkomar and Eyal Oren from Google in Mountain View, California, USA, developed a data processing pipeline for transforming EHR files into a standardized format. They then applied deep learning models to data from 216,221 adult patients hospitalized for at least 24 h each at two academic medical centers, and showed that their algorithm could accurately predict risk of mortality, hospital readmission, prolonged hospital stay and discharge diagnosis. In all cases, the method proved more accurate than previously published models. The authors provide a case study to serve as a proof-of-concept of how such an algorithm could be used in routine clinical practice in the future.},
	language = {En},
	number = {1},
	urldate = {2019-05-21},
	journal = {npj Digital Medicine},
	author = {Rajkomar, Alvin and Oren, Eyal and Chen, Kai and Dai, Andrew M. and Hajaj, Nissan and Hardt, Michaela and Liu, Peter J. and Liu, Xiaobing and Marcus, Jake and Sun, Mimi and Sundberg, Patrik and Yee, Hector and Zhang, Kun and Zhang, Yi and Flores, Gerardo and Duggan, Gavin E. and Irvine, Jamie and Le, Quoc and Litsch, Kurt and Mossin, Alexander and Tansuwan, Justin and Wang, De and Wexler, James and Wilson, Jimbo and Ludwig, Dana and Volchenboum, Samuel L. and Chou, Katherine and Pearson, Michael and Madabushi, Srinivasan and Shah, Nigam H. and Butte, Atul J. and Howell, Michael D. and Cui, Claire and Corrado, Greg S. and Dean, Jeffrey},
	month = may,
	year = {2018},
	pages = {18},
}

@article{van_waes_association_2016,
	title = {Association between {Intraoperative} {Hypotension} and {Myocardial} {Injury} after {Vascular} {Surgery}},
	volume = {124},
	issn = {1528-1175},
	doi = {10.1097/ALN.0000000000000922},
	abstract = {BACKGROUND: Postoperative myocardial injury occurs frequently after noncardiac surgery and is strongly associated with mortality. Intraoperative hypotension (IOH) is hypothesized to be a possible cause. The aim of this study was to determine the association between IOH and postoperative myocardial injury.
METHODS: This cohort study included 890 consecutive patients aged 60 yr or older undergoing vascular surgery from two university centers. The occurrence of myocardial injury was assessed by troponin measurements as part of a postoperative care protocol. IOH was defined by four different thresholds using either relative or absolute values of the mean arterial blood pressure based on previous studies. Either invasive or noninvasive blood pressure measurements were used. Poisson regression analysis was used to determine the association between IOH and postoperative myocardial injury, adjusted for potential clinical confounders and multiple comparisons.
RESULTS: Depending on the definition used, IOH occurred in 12 to 81\% of the patients. Postoperative myocardial injury occurred in 131 (29\%) patients with IOH as defined by a mean arterial pressure less than 60 mmHg, compared with 87 (20\%) patients without IOH (P = 0.001). After adjustment for potential confounding factors including mean heart rates, a 40\% decrease from the preinduction mean arterial blood pressure with a cumulative duration of more than 30 min was associated with postoperative myocardial injury (relative risk, 1.8; 99\% CI, 1.2 to 2.6, P {\textless} 0.001). Shorter cumulative durations (less than 30 min) were not associated with myocardial injury. Postoperative myocardial infarction and death within 30 days occurred in 26 (6\%) and 17 (4\%) patients with IOH as defined by a mean arterial pressure less than 60 mmHg, compared with 12 (3\%; P = 0.08) and 15 (3\%; P = 0.77) patients without IOH, respectively.
CONCLUSIONS: In elderly vascular surgery patients, IOH defined as a 40\% decrease from the preinduction mean arterial blood pressure with a cumulative duration of more than 30 min was associated with postoperative myocardial injury.},
	language = {eng},
	number = {1},
	journal = {Anesthesiology},
	author = {van Waes, Judith A. R. and van Klei, Wilton A. and Wijeysundera, Duminda N. and van Wolfswinkel, Leo and Lindsay, Thomas F. and Beattie, W. Scott},
	month = jan,
	year = {2016},
	pmid = {26540148},
	keywords = {Aged, Biomarkers, Cohort Studies, Comorbidity, Female, Humans, Hypotension, Intraoperative Complications, Male, Monitoring, Intraoperative, Myocardial Infarction, Ontario, Postoperative Complications, Troponin, Vascular Surgical Procedures},
	pages = {35--44},
}

@article{bijker_intraoperative_2012,
	title = {Intraoperative {Hypotension} and {Perioperative} {Ischemic} {Stroke} after {General} {SurgeryA} {Nested} {Case}-control {Study}},
	volume = {116},
	issn = {0003-3022},
	url = {http://anesthesiology.pubs.asahq.org/article.aspx?articleid=2443427},
	doi = {10.1097/ALN.0b013e3182472320},
	abstract = {A Nested Case-control Study},
	language = {en},
	number = {3},
	urldate = {2019-05-21},
	journal = {Anesthesiology: The Journal of the American Society of Anesthesiologists},
	author = {Bijker, Jilles B. and Persoon, Suzanne and Peelen, Linda M. and Moons, Karel G. M. and Kalkman, Cor J. and Kappelle, L. Jaap and Klei, Wilton A. van},
	month = mar,
	year = {2012},
	pages = {658--664},
}

@article{brzezinski_radial_2009,
	title = {Radial {Artery} {Cannulation}: {A} {Comprehensive} {Review} of {Recent} {Anatomic} and {Physiologic} {Investigations}},
	volume = {109},
	issn = {0003-2999},
	shorttitle = {Radial {Artery} {Cannulation}},
	url = {https://journals.lww.com/anesthesia-analgesia/fulltext/2009/12000/Radial_Artery_Cannulation__A_Comprehensive_Review.10.aspx},
	doi = {10.1213/ANE.0b013e3181bbd416},
	abstract = {Consistent anatomic accessibility, ease of cannulation, and a low rate of complications have made the radial artery the preferred site for arterial cannulation. Radial artery catheterization is a relatively safe procedure with an incidence of permanent ischemic complications of 0.09\%. Although its anatomy in the forearm and the hand is variable, adequate collateral flow in the event of radial artery thrombosis is present in most patients. Harvesting of the radial artery as a conduit for coronary artery bypass grafting, advances in plastic and reconstructive surgery of the hand, and its use as an entry site for cardiac catheterization has provided new insight into the collateral blood flow to the hand and the impact of radial arterial instrumentation. The Modified Allen’s Test has been the most frequently used method to clinically assess adequacy of ulnar artery collateral flow despite the lack of evidence that it can predict ischemic complications in the setting of radial artery occlusion. Doppler ultrasound can be used to evaluate collateral hand perfusion in an effort to stratify risk of potential ischemic injury from cannulation. Limited research has demonstrated a beneficial effect of heparinized flush solutions on arterial catheter patency but only in patients with prolonged monitoring ({\textgreater}24 h). Conservative management may be equally as effective as surgical intervention in treating ischemic complications resulting from radial artery cannulation. Limited clinical experience with the ultrasound-guided arterial cannulation method suggests that this technique is associated with increased success of cannulation with fewer attempts. Whether use of the latter technique is associated with a decrease in complications has not yet been verified in prospective studies. Research is needed to assess the safety of using the ulnar artery as an alternative to radial artery cannulation because the proximity and attachments of the ulnar artery to the ulnar nerve may potentially expose it to a higher risk of injury.},
	language = {en-US},
	number = {6},
	urldate = {2019-05-20},
	journal = {Anesthesia \& Analgesia},
	author = {Brzezinski, Marek and Luisetti, Thomas and London, Martin J.},
	month = dec,
	year = {2009},
	pages = {1763},
}

@article{scheer_clinical_2002,
	title = {Clinical review: {Complications} and risk factors of peripheral arterial catheters used for haemodynamic monitoring in anaesthesia and intensive care medicine},
	volume = {6},
	issn = {1364-8535},
	shorttitle = {Clinical review},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC137445/},
	abstract = {In order to evaluate the complications and risk factors associated with peripheral arterial catheters used for haemodynamic monitoring, we reviewed the literature published from 1978 to 2001. We closely examined the three most commonly used arterial cannulation sites. The reviewed papers included a total of 19,617 radial, 3899 femoral and 1989 axillary artery catheterizations. Factors that contribute to higher complication rates were investigated. Major complications occurred in fewer than 1\% of the cases, and rates were similar for the radial, femoral and axillary arteries. We conclude that arterial cannulation is a safe procedure.},
	number = {3},
	urldate = {2019-05-20},
	journal = {Critical Care},
	author = {Scheer, Bernd Volker and Perel, Azriel and Pfeiffer, Ulrich J},
	year = {2002},
	pmid = {12133178},
	pmcid = {PMC137445},
	pages = {199--204},
}

@article{meidert_impact_2017,
	title = {The impact of continuous non-invasive arterial blood pressure monitoring on blood pressure stability during general anaesthesia in orthopaedic patients: {A} randomised trial},
	volume = {34},
	issn = {0265-0215},
	shorttitle = {The impact of continuous non-invasive arterial blood pressure monitoring on blood pressure stability during general anaesthesia in orthopaedic patients},
	url = {https://journals.lww.com/ejanaesthesiology/fulltext/2017/11000/The_impact_of_continuous_non_invasive_arterial.3.aspx},
	doi = {10.1097/EJA.0000000000000690},
	abstract = {BACKGROUND In patients undergoing general anaesthesia, intraoperative hypotension occurs frequently and is associated with adverse outcomes such as postoperative acute kidney failure, myocardial infarction or stroke. A history of chronic hypertension renders patients more susceptible to a decrease in blood pressure (BP) after induction of general anaesthesia. As a patient's BP is generally monitored intermittently via an upper arm cuff, there may be a delay in the detection of hypotension by the anaesthetist.
        OBJECTIVE The current study investigates whether the presence of continuous BP monitoring leads to improved BP stability.
        DESIGN Randomised, controlled and single-centre study.
        PATIENTS A total of 160 orthopaedic patients undergoing general anaesthesia with a history of chronic hypertension.
        INTERVENTION The patients were randomised to either a study group (n = 77) that received continuous non-invasive BP monitoring in addition to oscillometric intermittent monitoring, or a control group (n = 83) whose BP was monitored intermittently only. The interval for oscillometric measurements in both groups was set to 3 min. After induction of general anaesthesia, oscillometric BP values of the two groups were compared for the first hour of the procedure. Anaesthetists were blinded to the purpose of the study.
        MAIN OUTCOME MEASURE BP stability and hypotensive events.
        RESULTS There was no difference in baseline BP between the groups. After adjustment for multiple testing, mean arterial BP in the study group was significantly higher than in the control group at 12 and 15 min. Mean ± SD for study and control group, respectively were: 12 min, 102 ± 24 vs. 90 ± 26 mmHg (P = 0.039) and 15 min, 102 ± 21 vs. 90 ± 23 mmHg (P = 0.023). Hypotensive readings below a mean pressure of 55 mmHg occurred more often in the control group (25 vs. 7, P = 0.047).
        CONCLUSION Continuous monitoring contributes to BP stability in the studied population.
        TRIAL REGISTRATION NCT02519101.},
	language = {en-US},
	number = {11},
	urldate = {2019-05-20},
	journal = {European Journal of Anaesthesiology (EJA)},
	author = {Meidert, Agnes S. and Nold, Johanna S. and Hornung, Roman and Paulus, Alexander C. and Zwißler, Bernhard and Czerner, Stephan},
	month = nov,
	year = {2017},
	pages = {716},
}

@article{walsh_relationship_2013,
	title = {Relationship between {Intraoperative} {Mean} {Arterial} {Pressure} and {Clinical} {Outcomes} after {Noncardiac} {SurgeryToward} an {Empirical} {Definition} of {Hypotension}},
	volume = {119},
	issn = {0003-3022},
	url = {http://anesthesiology.pubs.asahq.org/article.aspx?articleid=1918179},
	doi = {10.1097/ALN.0b013e3182a10e26},
	abstract = {Toward an Empirical Definition of Hypotension},
	language = {en},
	number = {3},
	urldate = {2019-05-20},
	journal = {Anesthesiology: The Journal of the American Society of Anesthesiologists},
	author = {Walsh, Michael and Devereaux, Philip J. and Garg, Amit X. and Kurz, Andrea and Turan, Alparslan and Rodseth, Reitze N. and Cywinski, Jacek and Thabane, Lehana and Sessler, Daniel I.},
	month = sep,
	year = {2013},
	pages = {507--515},
}

@article{pressman_transducer_1963,
	title = {A {Transducer} for the {Continuous} {External} {Measurement} of {Arterial} {Blood} {Pressure}},
	volume = {10},
	issn = {0096-0616},
	doi = {10.1109/TBMEL.1963.4322794},
	abstract = {The objective of the research was to develop a transducer to measure arterial blood pressure. It was required that the transducer provide a continuous measure of blood pressure, that it not encumber the subject and that it not require cannulation. Two basic techniques were investigated both analytically and experimentally. First, an indirect measurement of blood pressure based on arterial deflection was attempted. Difficulties of calibration; and sensitivity to physiological changes of skin and tissue around the artery led to the decision to attempt a more direct measurement of arterial blood pressure. In this second approach, arterial deflection is restrained by the transducer and the resultant restraining force is measured. A mathematical model of the transducer artery system was developed and was used as a guide for the design of the experimental prototype transducers. Tests performed on these experimental transducers gave results consistent with the predictions of the model. These transducers have been used to measure blood pressure at large superficial arteries, with results comparable to sphygmomanometer determinations.},
	number = {2},
	journal = {IEEE Transactions on Bio-medical Electronics},
	author = {Pressman, G. L. and Newgard, P. M.},
	month = apr,
	year = {1963},
	keywords = {Arterial blood pressure, Arteries, Blood pressure, Calibration, Force measurement, Mathematical model, Pressure measurement, Prototypes, Skin, Transducers},
	pages = {73--81},
}

@article{penaz_[contribution_1976,
	title = {[{Contribution} to the continuous indirect blood pressure measurement]},
	volume = {31},
	issn = {0044-2542},
	abstract = {The plethysmanometer described follows the principle of the relaxed wall of the vessel. Here the pressure is adjusted in a finger cuff and by means of a pneumatic regulation is varied in such a way that the light plethysmogram of the adequate finger does not show any more pulsations. Thus the pressure effected on the finger above the cuff corresponds to the pressure in the finger arteries and is to be registered in mm Hg. When the course is measured in the same test person with changing of the arterial pressure (e.g. absolute arrhythmia or compressed-air pressure experiment) the blood pressure of the aorta measured when a heart catheter is diagnostically indicated shows a very close correlation to the unbloodily registered pressure of the finger arteries. On the other hand, greater varieties of the correlation coefficient which can be proved from test person to test person at present do not yet allow a formula obligatory in general, in order to tansfer the value unbloodily measured into the adequate bloody one. Nevertheless, already nowadays great ranges of application are possible for the progressing measuring of the blood pressure.},
	language = {ger},
	number = {24},
	journal = {Zeitschrift Fur Die Gesamte Innere Medizin Und Ihre Grenzgebiete},
	author = {Penáz, J. and Voigt, A. and Teichmann, W.},
	month = dec,
	year = {1976},
	pmid = {1020409},
	keywords = {Blood Pressure Determination, Humans, Plethysmography},
	pages = {1030--1033},
}

@article{fitz-henry_asa_2011,
	title = {The {ASA} classification and peri-operative risk},
	volume = {93},
	issn = {0035-8843},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3348554/},
	doi = {10.1308/147870811X565070a},
	number = {3},
	journal = {Annals of The Royal College of Surgeons of England},
	author = {Fitz-Henry, Jo},
	month = apr,
	year = {2011},
	note = {Publisher: The Royal College of Surgeons of England},
	pages = {185--187},
}

@article{Pedregosa:2011:SML:1953048.2078195,
	title = {Scikit-learn: {Machine} {Learning} in {Python}},
	volume = {12},
	issn = {1532-4435},
	url = {http://dl.acm.org/citation.cfm?id=1953048.2078195},
	journal = {J. Mach. Learn. Res.},
	author = {Pedregosa, Fabian and Varoquaux, Gaël and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, Édouard},
	month = nov,
	year = {2011},
	note = {Publisher: JMLR.org},
	pages = {2825--2830},
}

@inproceedings{jun_scalable_2014,
	address = {New York, New York, USA},
	title = {Scalable multi-access flash store for big data analytics},
	isbn = {978-1-4503-2671-1},
	url = {http://dl.acm.org/citation.cfm?doid=2554688.2554789},
	doi = {10.1145/2554688.2554789},
	abstract = {For many“Big Data”applications, the limiting factor in per- formance is often the transportation of large amount of data from hard disks to where it can be processed, i.e. DRAM. In this paper we examine an architecture for a scalable dis- tributed flash store which aims to overcome this limita- tion in two ways. First, the architecture provides a high- performance, high-capacity, scalable random-access storage. It achieves high-throughput by sharing large numbers of flash chips across a low-latency, chip-to-chip backplane net- work managed by the flash controllers. The additional la- tency for remote data access via this network is negligible as compared to flash access time. Second, it permits some com- putation near the data via a FPGA-based programmable flash controller. The controller is located in the datapath between the storage and the host, and provides hardware acceleration for applications without any additional latency. We have constructed a small-scale prototype whose network bandwidth scales directly with the number of nodes, and where average latency for user software to access flash store is less than 70µs, including 3.5µs of network overhead.},
	urldate = {2017-04-29},
	booktitle = {Proceedings of the 2014 {ACM}/{SIGDA} international symposium on {Field}-programmable gate arrays - {FPGA} '14},
	publisher = {ACM Press},
	author = {Jun, Sang-Woo and Liu, Ming and Fleming, Kermin Elliott and {Arvind}},
	year = {2014},
	keywords = {big data, flash, fpga networks, ssd, storage system},
	pages = {55--64},
}

@article{mckenna_genome_2010,
	title = {The {Genome} {Analysis} {Toolkit}: a {MapReduce} framework for analyzing next-generation {DNA} sequencing data.},
	volume = {20},
	issn = {1549-5469},
	url = {http://genome.cshlp.org/cgi/doi/10.1101/gr.107524.110},
	doi = {10.1101/gr.107524.110},
	abstract = {Next-generation DNA sequencing (NGS) projects, such as the 1000 Genomes Project, are already revolutionizing our understanding of genetic variation among individuals. However, the massive data sets generated by NGS--the 1000 Genome pilot alone includes nearly five terabases--make writing feature-rich, efficient, and robust analysis tools difficult for even computationally sophisticated individuals. Indeed, many professionals are limited in the scope and the ease with which they can answer scientific questions by the complexity of accessing and manipulating the data produced by these machines. Here, we discuss our Genome Analysis Toolkit (GATK), a structured programming framework designed to ease the development of efficient and robust analysis tools for next-generation DNA sequencers using the functional programming philosophy of MapReduce. The GATK provides a small but rich set of data access patterns that encompass the majority of analysis tool needs. Separating specific analysis calculations from common data management infrastructure enables us to optimize the GATK framework for correctness, stability, and CPU and memory efficiency and to enable distributed and shared memory parallelization. We highlight the capabilities of the GATK by describing the implementation and application of robust, scale-tolerant tools like coverage calculators and single nucleotide polymorphism (SNP) calling. We conclude that the GATK programming framework enables developers and analysts to quickly and easily write efficient and robust NGS tools, many of which have already been incorporated into large-scale sequencing projects like the 1000 Genomes Project and The Cancer Genome Atlas.},
	number = {9},
	urldate = {2017-04-18},
	journal = {Genome research},
	author = {McKenna, Aaron and Hanna, Matthew and Banks, Eric and Sivachenko, Andrey and Cibulskis, Kristian and Kernytsky, Andrew and Garimella, Kiran and Altshuler, David and Gabriel, Stacey and Daly, Mark and DePristo, Mark A},
	month = sep,
	year = {2010},
	pmid = {20644199},
	pages = {1297--303},
}

@article{Łabaj2016,
	title = {Sensitivity, specificity, and reproducibility of {RNA}-{Seq} differential expression calls},
	volume = {11},
	issn = {1745-6150},
	url = {https://doi.org/10.1186/s13062-016-0169-7},
	doi = {10.1186/s13062-016-0169-7},
	abstract = {The MAQC/SEQC consortium has recently compiled a key benchmark that can serve for testing the latest developments in analysis tools for microarray and RNA-seq expression profiling. Such objective benchmarks are required for basic and applied research, and can be critical for clinical and regulatory outcomes. Going beyond the first comparisons presented in the original SEQC study, we here present extended benchmarks including effect strengths typical of common experiments.},
	number = {1},
	journal = {Biology Direct},
	author = {Łabaj, PawełP. and Kreil, David P},
	month = dec,
	year = {2016},
	pages = {66},
}

@inproceedings{Chen:2016:XST:2939672.2939785,
	address = {New York, NY, USA},
	title = {{XGBoost}: {A} {Scalable} {Tree} {Boosting} {System}},
	isbn = {978-1-4503-4232-2},
	url = {http://doi.acm.org/10.1145/2939672.2939785},
	doi = {10.1145/2939672.2939785},
	booktitle = {Proceedings of the {22Nd} {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {ACM},
	author = {Chen, Tianqi and Guestrin, Carlos},
	year = {2016},
	note = {Series Title: KDD '16},
	keywords = {large-scale machine learning},
	pages = {785--794},
}

@article{makhzani_winner-take-all_2014,
	title = {Winner-{Take}-{All} {Autoencoders}},
	url = {http://arxiv.org/abs/1409.2752},
	abstract = {In this paper, we propose a winner-take-all method for learning hierarchical sparse representations in an unsupervised fashion. We first introduce fully-connected winner-take-all autoencoders which use mini-batch statistics to directly enforce a lifetime sparsity in the activations of the hidden units. We then propose the convolutional winner-take-all autoencoder which combines the benefits of convolutional architectures and autoencoders for learning shift-invariant sparse representations. We describe a way to train convolutional autoencoders layer by layer, where in addition to lifetime sparsity, a spatial sparsity within each feature map is achieved using winner-take-all activation functions. We will show that winner-take-all autoencoders can be used to to learn deep sparse representations from the MNIST, CIFAR-10, ImageNet, Street View House Numbers and Toronto Face datasets, and achieve competitive classification performance.},
	urldate = {2017-04-17},
	author = {Makhzani, Alireza and Frey, Brendan J.},
	month = sep,
	year = {2014},
	note = {arXiv: 1409.2752},
}

@inproceedings{chen_when_2016,
	title = {When {Spark} {Meets} {FPGAs}: {A} {Case} {Study} for {Next}-{Generation} {DNA} {Sequencing} {Acceleration}},
	isbn = {978-1-5090-2356-1},
	url = {http://ieeexplore.ieee.org/document/7544741/},
	doi = {10.1109/FCCM.2016.18},
	urldate = {2017-04-18},
	booktitle = {2016 {IEEE} 24th {Annual} {International} {Symposium} on {Field}-{Programmable} {Custom} {Computing} {Machines} ({FCCM})},
	publisher = {IEEE},
	author = {Chen, Yu-Ting and Cong, Jason and Fang, Zhenman and Lei, Jie and Wei, Peng},
	month = may,
	year = {2016},
	pages = {29--29},
}

@article{gusev_whole_2008,
	title = {Whole population, genome-wide mapping of hidden relatedness},
	volume = {19},
	issn = {1088-9051},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/18971310},
	doi = {10.1101/gr.081398.108},
	abstract = {We present GERMLINE, a robust algorithm for identifying segmental sharing indicative of recent common ancestry between pairs of individuals. Unlike methods with comparable objectives, GERMLINE scales linearly with the number of samples, enabling analysis of whole-genome data in large cohorts. Our approach is based on a dictionary of haplotypes that is used to efficiently discover short exact matches between individuals. We then expand these matches using dynamic programming to identify long, nearly identical segmental sharing that is indicative of relatedness. We use GERMLINE to comprehensively survey hidden relatedness both in the HapMap as well as in a densely typed island population of 3000 individuals. We verify that GERMLINE is in concordance with other methods when they can process the data, and also facilitates analysis of larger scale studies. We bolster these results by demonstrating novel applications of precise analysis of hidden relatedness for (1) identification and resolution of phasing errors and (2) exposing polymorphic deletions that are otherwise challenging to detect. This finding is supported by concordance of detected deletions with other evidence from independent databases and statistical analyses of fluorescence intensity not used by GERMLINE.},
	number = {2},
	urldate = {2017-07-20},
	journal = {Genome Research},
	author = {Gusev, A. and Lowe, J. K. and Stoffel, M. and Daly, M. J. and Altshuler, D. and Breslow, J. L. and Friedman, J. M. and Pe'er, I.},
	month = dec,
	year = {2008},
	pmid = {18971310},
	keywords = {IBD},
	pages = {318--326},
}

@article{doi:10.1097/ALN.0b013e31829ce6e6,
	title = {Validation of a {Risk} {Stratification} {Index} and {Risk} {Quantification} {Index} for {Predicting} {Patient} {OutcomesIn}-hospital {Mortality}, 30-day {Mortality}, 1-year {Mortality}, and {Length}-of-stay},
	volume = {119},
	url = {+},
	doi = {10.1097/ALN.0b013e31829ce6e6},
	number = {3},
	journal = {Anesthesiology},
	author = {Sigakis, Matthew J G and Bittner, Edward A and Wanderer, Jonathan P},
	year = {2013},
	pages = {525--540},
}

@article{mazumder_spectral_2010,
	title = {Spectral {Regularization} {Algorithms} for {Learning} {Large} {Incomplete} {Matrices}},
	volume = {11},
	issn = {1532-4435},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3087301/},
	abstract = {We use convex relaxation techniques to provide a sequence of regularized low-rank solutions for large-scale matrix completion problems. Using the nuclear norm as a regularizer, we provide a simple and very efficient convex algorithm for minimizing the reconstruction error subject to a bound on the nuclear norm. Our algorithm Soft-Impute iteratively replaces the missing elements with those obtained from a soft-thresholded SVD. With warm starts this allows us to efficiently compute an entire regularization path of solutions on a grid of values of the regularization parameter. The computationally intensive part of our algorithm is in computing a low-rank SVD of a dense matrix. Exploiting the problem structure, we show that the task can be performed with a complexity linear in the matrix dimensions. Our semidefinite-programming algorithm is readily scalable to large matrices: for example it can obtain a rank-80 approximation of a 10(6) × 10(6) incomplete matrix with 10(5) observed entries in 2.5 hours, and can fit a rank 40 approximation to the full Netflix training set in 6.6 hours. Our methods show very good performance both in training and test error when compared to other competitive state-of-the art techniques.},
	journal = {Journal of machine learning research : JMLR},
	author = {Mazumder, Rahul and Hastie, Trevor and Tibshirani, Robert},
	month = mar,
	year = {2010},
	keywords = {collaborative filtering, large scale convex optimization, netflix prize, nuclear norm, spectral regularization},
	pages = {2287--2322},
}

@article{rahmani_sparse_2016,
	title = {Sparse {PCA} corrects for cell type heterogeneity in epigenome-wide association studies},
	volume = {13},
	url = {http://dx.doi.org/10.1038/nmeth.3809},
	journal = {Nature Methods},
	author = {Rahmani, Elior and Zaitlen, Noah and Baran, Yael and Eng, Celeste and Hu, Donglei and Galanter, Joshua and Oh, Sam and Burchard, Esteban G and Eskin, Eleazar and Zou, James and Halperin, Eran},
	month = mar,
	year = {2016},
	note = {Publisher: Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	pages = {443},
}

@article{saito_precision-recall_2015,
	title = {The {Precision}-{Recall} {Plot} {Is} {More} {Informative} than the {ROC} {Plot} {When} {Evaluating} {Binary} {Classifiers} on {Imbalanced} {Datasets}},
	volume = {10},
	issn = {1932-6203},
	url = {http://dx.plos.org/10.1371/journal.pone.0118432},
	doi = {10.1371/journal.pone.0118432},
	abstract = {Binary classifiers are routinely evaluated with performance measures such as sensitivity and specificity, and performance is frequently illustrated with Receiver Operating Characteristics (ROC) plots. Alternative measures such as positive predictive value (PPV) and the associated Precision/Recall (PRC) plots are used less frequently. Many bioinformatics studies develop and evaluate classifiers that are to be applied to strongly imbalanced datasets in which the number of negatives outweighs the number of positives significantly. While ROC plots are visually appealing and provide an overview of a classifier's performance across a wide range of specificities, one can ask whether ROC plots could be misleading when applied in imbalanced classification scenarios. We show here that the visual interpretability of ROC plots in the context of imbalanced datasets can be deceptive with respect to conclusions about the reliability of classification performance, owing to an intuitive but wrong interpretation of specificity. PRC plots, on the other hand, can provide the viewer with an accurate prediction of future classification performance due to the fact that they evaluate the fraction of true positives among positive predictions. Our findings have potential implications for the interpretation of a large number of studies that use ROC plots on imbalanced datasets.},
	number = {3},
	urldate = {2018-04-18},
	journal = {PLOS ONE},
	author = {Saito, Takaya and Rehmsmeier, Marc},
	editor = {Brock, Guy},
	month = mar,
	year = {2015},
	note = {Publisher: Public Library of Science},
	pages = {e0118432},
}

@article{chiang_impact_2017,
	title = {The impact of structural variation on human gene expression},
	volume = {49},
	issn = {1061-4036},
	url = {http://dx.doi.org/10.1038/ng.3834},
	abstract = {Structural variants (SVs) are an important source of human genetic diversity, but their contribution to traits, disease and gene regulation remains unclear. We mapped cis expression quantitative trait loci (eQTLs) in 13 tissues via joint analysis of SVs, single-nucleotide variants (SNVs) and short insertion/deletion (indel) variants from deep whole-genome sequencing (WGS). We estimated that SVs are causal at 3.5-6.8\% of eQTLs[mdash]a substantially higher fraction than prior estimates[mdash]and that expression-altering SVs have larger effect sizes than do SNVs and indels. We identified 789 putative causal SVs predicted to directly alter gene expression: most (88.3\%) were noncoding variants enriched at enhancers and other regulatory elements, and 52 were linked to genome-wide association study loci. We observed a notable abundance of rare high-impact SVs associated with aberrant expression of nearby genes. These results suggest that comprehensive WGS-based SV analyses will increase the power of common- and rare-variant association studies.},
	number = {5},
	journal = {Nat Genet},
	author = {Chiang, Colby and Scott, Alexandra J and Davis, Joe R and Tsang, Emily K and Li, Xin and Kim, Yungil and Hadzic, Tarik and Damani, Farhan N and Ganel, Liron and Consortium, GTEx and Montgomery, Stephen B and Battle, Alexis and Conrad, Donald F and Hall, Ira M},
	month = may,
	year = {2017},
	note = {Publisher: Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	pages = {692--699},
}

@inproceedings{nowatzki_stream-dataflow_2017,
	address = {New York, New York, USA},
	title = {Stream-{Dataflow} {Acceleration}},
	isbn = {978-1-4503-4892-8},
	url = {http://dl.acm.org/citation.cfm?doid=3079856.3080255},
	doi = {10.1145/3079856.3080255},
	urldate = {2017-06-28},
	booktitle = {Proceedings of the 44th {Annual} {International} {Symposium} on {Computer} {Architecture}  - {ISCA} '17},
	publisher = {ACM Press},
	author = {Nowatzki, Tony and Gangadhar, Vinay and Ardalani, Newsha and Sankaralingam, Karthikeyan},
	year = {2017},
	keywords = {Accelerator, Architecture, CGRA, Dataflow, Domain-Specific, Programmable, Reconfigurable, Streaming},
	pages = {416--429},
}

@article{doi:10.1197/jamia.M1370,
	title = {Ten {Commandments} for {Effective} {Clinical} {Decision} {Support}: {Making} the {Practice} of {Evidence}-based {Medicine} a {Reality}},
	volume = {10},
	url = {+},
	doi = {10.1197/jamia.M1370},
	number = {6},
	journal = {Journal of the American Medical Informatics Association},
	author = {Bates, David W and Kuperman, Gilad J and Wang, Samuel and Gandhi, Tejal and Kittler, Anne and Volk, Lynn and Spurr, Cynthia and Khorasani, Ramin and Tanasijevic, Milenko and Middleton, Blackford},
	year = {2003},
	pages = {523--530},
}

@article{spain_strategies_2015,
	title = {Strategies for fine-mapping complex traits.},
	volume = {24},
	issn = {1460-2083},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/26157023},
	doi = {10.1093/hmg/ddv260},
	abstract = {Genome-wide association studies (GWAS) have identified thousands of robust and replicable genetic associations for complex disease. However, the identification of the causal variants that underlie these associations has been more difficult. This problem of fine-mapping association signals predates GWAS, but the last few years have seen a surge of studies aimed at pinpointing causal variants using both statistical evidence from large association data sets and functional annotations of genetic variants. Combining these two approaches can often determine not only the causal variant but also the target gene. Recent contributions include analyses of custom genotyping arrays, such as the Immunochip, statistical methods to identify credible sets of causal variants and the addition of functional genomic annotations for coding and non-coding variation to help prioritize variants and discern functional consequence and hence the biological basis of disease risk.},
	number = {R1},
	urldate = {2017-10-11},
	journal = {Human molecular genetics},
	author = {Spain, Sarah L and Barrett, Jeffrey C},
	month = oct,
	year = {2015},
	pmid = {26157023},
	note = {Publisher: Oxford University Press},
	pages = {R111--9},
}

@phdthesis{goldstein_tools_2013,
	title = {Tools for extracting actionable medical knowledge from genomic big data},
	url = {http://iclibezp1.cc.ic.ac.uk/login?url=http://search.proquest.com/docview/1430500484?accountid=16260%5Cnhttp://imp-primo.hosted.exlibrisgroup.com/openurl/44IMP/44IMP_services_page?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&genre=dis},
	abstract = {Cancer is an ideal target for personal genomics-based medicine that uses high-throughput genome assays such as DNA sequencing, RNA sequencing, and expression analysis (collectively called omics); however, researchers and physicians are overwhelmed by the quantities of big data from these assays and cannot interpret this information accurately without specialized tools. To address this problem, I have created software methods and tools called OCCAM (OmiC data Cancer Analytic Model) and DIPSC (Differential Pathway Signature Correlation) for automatically extracting knowledge from this data and turning it into an actionable knowledge base called the activitome. An activitome signature measures a mutation's effect on the cellular molecular pathway. As well, activitome signatures can also be computed for clinical phenotypes. By comparing the vectors of activitome signatures of different mutations and clinical outcomes, intrinsic relationships between these events may be uncovered. OCCAM identifies activitome signatures that can be used to guide the development and application of therapies. DIPSC overcomes the confounding problem of correlating multiple activitome signatures from the same set of samples. In addition, to support the collection of this big data, I have developed MedBook, a federated distributed social network designed for a medical research and decision support system. OCCAM and DIPSC are two of the many apps that will operate inside of MedBook. MedBook extends the Galaxy system with a signature database, an end-user oriented application platform, a rich data medical knowledge-publishing model, and the Biomedical Evidence Graph (BMEG). The goal of MedBook is to improve the outcomes by learning from every patient.},
	school = {University of California Santa Cruz},
	author = {Goldstein, Theodore C.},
	year = {2013},
	pmid = {1430500484},
	note = {Volume: 3589324
ISBN: 9781303278310},
	keywords = {0541:Biomedical engineering, 0564:Medicine, 0715:Bioinformatics, Applied sciences, Big data, Bioinformatics, Biological sciences, Biomedical engineering, Cancer, Genomics, Health and environmental sciences, Medicine, Pathways, Targeted therapy, Translational medicine},
}

@article{papadopoulos_tiledb_2016,
	title = {The {TileDB} {Array} {Data} {Storage} {Manager}},
	volume = {10},
	issn = {21508097},
	doi = {10.14778/3025111.3025117},
	abstract = {We present a novel storage manager for multi-dimensional ar-rays that arise in scientific applications, which is part of a larger scientific data management system called TileDB. In contrast to existing solutions, TileDB is optimized for both dense and sparse arrays. Its key idea is to organize array el-ements into ordered collections called fragments. Each frag-ment is dense or sparse, and groups contiguous array elements into data tiles of fixed capacity. The organization into frag-ments turns random writes into sequential writes, and, cou-pled with a novel read algorithm, leads to very efficient reads. TileDB enables parallelization via multi-threading and multi-processing, offering thread-/process-safety and atomicity via lightweight locking. We show that TileDB delivers compa-rable performance to the HDF5 dense array storage manager, while providing much faster random writes. We also show that TileDB offers substantially faster reads and writes than the SciDB array database system with both dense and sparse arrays. Finally, we demonstrate that TileDB is considerably faster than adaptations of the Vertica relational column-store for dense array storage management, and at least as fast for the case of sparse arrays.},
	number = {i},
	journal = {Proceedings of the VLDB Endowment},
	author = {Papadopoulos, Stavros and Madden, Samuel and Mattson, Timothy},
	year = {2016},
	keywords = {GDB, GenomicsDB, TileDB},
	pages = {349--360},
}

@article{Charlson1994,
	title = {Validation of a combined comorbidity index},
	volume = {47},
	issn = {0895-4356},
	url = {http://dx.doi.org/10.1016/0895-4356(94)90129-5},
	doi = {10.1016/0895-4356(94)90129-5},
	number = {11},
	journal = {Journal of Clinical Epidemiology},
	author = {Charlson, Mary and Szatrowski, Ted P and Peterson, Janey and Gold, Jeffrey},
	month = nov,
	year = {1994},
	note = {Publisher: Elsevier},
	keywords = {Comorbidity, Prognosis},
	pages = {1245--1251},
}

@article{doi:10.1097/ALN.0000000000001560,
	title = {Validation and {Calibration} of the {Risk} {Stratification} {Index}},
	volume = {126},
	url = {+},
	doi = {10.1097/ALN.0000000000001560},
	number = {4},
	journal = {Anesthesiology},
	author = {Chamoun, George F and Li, Linyan and Chamoun, Nassib G and Saini, Vikas and Sessler, Daniel I},
	year = {2017},
	pages = {623--630},
}

@article{koh_understanding_2017,
	title = {Understanding {Black}-box {Predictions} via {Influence} {Functions}},
	issn = {1938-7228},
	url = {http://arxiv.org/abs/1703.04730},
	abstract = {How can we explain the predictions of a black-box model? In this paper, we use influence functions -- a classic technique from robust statistics -- to trace a model's prediction through the learning algorithm and back to its training data, thereby identifying training points most responsible for a given prediction. To scale up influence functions to modern machine learning settings, we develop a simple, efficient implementation that requires only oracle access to gradients and Hessian-vector products. We show that even on non-convex and non-differentiable models where the theory breaks down, approximations to influence functions can still provide valuable information. On linear models and convolutional neural networks, we demonstrate that influence functions are useful for multiple purposes: understanding model behavior, debugging models, detecting dataset errors, and even creating visually-indistinguishable training-set attacks.},
	urldate = {2018-02-05},
	author = {Koh, Pang Wei and Liang, Percy},
	month = mar,
	year = {2017},
	note = {arXiv: 1703.04730},
}

@article{Quan2011,
	title = {Updating and {Validating} the {Charlson} {Comorbidity} {Index} and {Score} for {Risk} {Adjustment} in {Hospital} {Discharge} {Abstracts} {Using} {Data} {From} 6 {Countries}},
	volume = {173},
	issn = {0002-9262},
	url = {http://dx.doi.org/10.1093/aje/kwq433},
	abstract = {With advances in the effectiveness of treatment and disease management, the contribution of chronic comorbid diseases (comorbidities) found within the Charlson comorbidity index to mortality is likely to have changed since development of the index in 1984. The authors reevaluated the Charlson index and reassigned weights to each condition by identifying and following patients to observe mortality within 1 year after hospital discharge. They applied the updated index and weights to hospital discharge data from 6 countries and tested for their ability to predict in-hospital mortality. Compared with the original Charlson weights, weights generated from the Calgary, Alberta, Canada, data (2004) were 0 for 5 comorbidities, decreased for 3 comorbidities, increased for 4 comorbidities, and did not change for 5 comorbidities. The C statistics for discriminating in-hospital mortality between the new score generated from the 12 comorbidities and the Charlson score were 0.825 (new) and 0.808 (old), respectively, in Australian data (2008), 0.828 and 0.825 in Canadian data (2008), 0.878 and 0.882 in French data (2004), 0.727 and 0.723 in Japanese data (2008), 0.831 and 0.836 in New Zealand data (2008), and 0.869 and 0.876 in Swiss data (2008). The updated index of 12 comorbidities showed good-to-excellent discrimination in predicting in-hospital mortality in data from 6 countries and may be more appropriate for use with more recent administrative data.},
	number = {6},
	journal = {American Journal of Epidemiology},
	author = {Quan, Hude and Li, Bing and Couris, Chantal M and Fushimi, Kiyohide and Graham, Patrick and Hider, Phil and Januel, Jean-Marie and Sundararajan, Vijaya},
	month = mar,
	year = {2011},
	pages = {676--682},
}

@article{albert_role_2015,
	title = {The role of regulatory variation in complex traits and disease},
	volume = {16},
	issn = {1471-0056},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/25707927},
	doi = {10.1038/nrg3891},
	abstract = {We are in a phase of unprecedented progress in identifying genetic loci that cause variation in traits ranging from growth and fitness in simple organisms to disease in humans. However, a mechanistic understanding of how these loci influence traits is lacking for the majority of loci. Studies of the genetics of gene expression have emerged as a key tool for linking DNA sequence variation to phenotypes. Here, we review recent insights into the molecular nature of regulatory variants and describe their influence on the transcriptome and the proteome. We discuss conceptual advances from studies in model organisms and present examples of complete chains of causality that link individual polymorphisms to changes in gene expression, which in turn result in physiological changes and, ultimately, disease risk.},
	number = {4},
	urldate = {2017-04-23},
	journal = {Nature Reviews Genetics},
	author = {Albert, Frank W. and Kruglyak, Leonid},
	month = feb,
	year = {2015},
	pmid = {25707927},
	pages = {197--212},
}

@inproceedings{Davis:2006:RPR:1143844.1143874,
	address = {New York, NY, USA},
	title = {The {Relationship} {Between} {Precision}-{Recall} and {ROC} {Curves}},
	isbn = {1-59593-383-2},
	url = {http://doi.acm.org/10.1145/1143844.1143874},
	doi = {10.1145/1143844.1143874},
	booktitle = {Proceedings of the 23rd {International} {Conference} on {Machine} {Learning}},
	publisher = {ACM},
	author = {Davis, Jesse and Goadrich, Mark},
	year = {2006},
	note = {Series Title: ICML '06},
	pages = {233--240},
}

@article{zuk_mystery_2012,
	title = {The mystery of missing heritability: {Genetic} interactions create phantom heritability.},
	volume = {109},
	issn = {1091-6490},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/22223662},
	doi = {10.1073/pnas.1119675109},
	abstract = {Human genetics has been haunted by the mystery of "missing heritability" of common traits. Although studies have discovered {\textgreater}1,200 variants associated with common diseases and traits, these variants typically appear to explain only a minority of the heritability. The proportion of heritability explained by a set of variants is the ratio of (i) the heritability due to these variants (numerator), estimated directly from their observed effects, to (ii) the total heritability (denominator), inferred indirectly from population data. The prevailing view has been that the explanation for missing heritability lies in the numerator--that is, in as-yet undiscovered variants. While many variants surely remain to be found, we show here that a substantial portion of missing heritability could arise from overestimation of the denominator, creating "phantom heritability." Specifically, (i) estimates of total heritability implicitly assume the trait involves no genetic interactions (epistasis) among loci; (ii) this assumption is not justified, because models with interactions are also consistent with observable data; and (iii) under such models, the total heritability may be much smaller and thus the proportion of heritability explained much larger. For example, 80\% of the currently missing heritability for Crohn's disease could be due to genetic interactions, if the disease involves interaction among three pathways. In short, missing heritability need not directly correspond to missing variants, because current estimates of total heritability may be significantly inflated by genetic interactions. Finally, we describe a method for estimating heritability from isolated populations that is not inflated by genetic interactions.},
	number = {4},
	urldate = {2017-07-22},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Zuk, Or and Hechter, Eliana and Sunyaev, Shamil R and Lander, Eric S},
	month = jan,
	year = {2012},
	pmid = {22223662},
	note = {Publisher: National Academy of Sciences},
	pages = {1193--8},
}

@article{dennis_central_2006,
	title = {The {Central} {Codebook} ({CCB}) at the {David} {Geffen} {School} of {Medicine} at {UCLA}.},
	volume = {2006},
	issn = {1942-597X},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/17238527},
	abstract = {Separating personal health information (PHI) from research data is a critical issue. In our work the Central CodeBook (CCB) functions as an 'honest broker' by mapping between internally meaningful, subject codes (IDs) and sensitive external identifiers like medical record numbers. The CCB is a web service enabled database-backed web application that brokers communications with our evolving EMR via the Clinical Information Network Exchange (CNEX).},
	urldate = {2017-06-23},
	journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
	author = {Dennis, Robert A and Wang, Jeff and Huang, Khy and Helsley, Andrew and Robinson, Alan G},
	year = {2006},
	pmid = {17238527},
	note = {Publisher: American Medical Informatics Association},
	pages = {908},
}

@article{meidert_techniques_2018,
	title = {Techniques for {Non}-{Invasive} {Monitoring} of {Arterial} {Blood} {Pressure}},
	volume = {4},
	url = {https://www.ncbi.nlm.nih.gov/pubmed/29359130},
	doi = {10.3389/fmed.2017.00231},
	abstract = {Since both, hypotension and hypertension, can potentially impair the function of vital organs such as heart, brain, or kidneys, monitoring of arterial blood pressure (BP) is a mainstay of hemodynamic monitoring in acutely or critically ill patients. Arterial BP can either be obtained invasively via an arterial catheter or non-invasively. Non-invasive BP measurement provides either intermittent or continuous readings. Most commonly, an occluding upper arm cuff is used for intermittent non-invasive monitoring. BP values are then obtained either manually (by auscultation of Korotkoff sounds or palpation) or automatically (e.g., by oscillometry). For continuous non-invasive BP monitoring, the volume clamp method or arterial applanation tonometry can be used. Both techniques enable the arterial waveform and BP values to be obtained continuously. This article describes the different techniques for non-invasive BP measurement, their advantages and limitations, and their clinical applicability.},
	language = {eng},
	journal = {Frontiers in medicine},
	author = {Meidert, Agnes S and Saugel, Bernd},
	month = jan,
	year = {2018},
	keywords = {applanation tonometry, arterial pressure, blood pressure monitoring, non-invasive blood pressure, oscillometry, perioperative monitoring, vascular unloading technique},
	pages = {231--231},
}

@article{consortium_sparse_2015,
	title = {Sparse whole-genome sequencing identifies two loci for major depressive disorder},
	volume = {523},
	issn = {0028-0836},
	url = {http://dx.doi.org/10.1038/nature14659},
	number = {7562},
	journal = {Nature},
	author = {consortium, CONVERGE},
	month = jul,
	year = {2015},
	note = {Publisher: Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	pages = {588--591},
}

@article{Chawla:2002:SSM:1622407.1622416,
	title = {{SMOTE}: {Synthetic} {Minority} {Over}-sampling {Technique}},
	volume = {16},
	issn = {1076-9757},
	url = {http://dl.acm.org/citation.cfm?id=1622407.1622416},
	number = {1},
	journal = {J. Artif. Int. Res.},
	author = {Chawla, Nitesh V and Bowyer, Kevin W and Hall, Lawrence O and Kegelmeyer, W Philip},
	month = jun,
	year = {2002},
	note = {Publisher: AI Access Foundation
Place: USA},
	pages = {321--357},
}

@article{alexandari_separable_2017,
	title = {Separable {Fully} {Connected} {Layers} {Improve} {Deep} {Learning} {Models} {For} {Genomics}},
	url = {http://biorxiv.org/content/early/2017/07/07/146431.abstract},
	abstract = {Convolutional neural networks are rapidly gaining popularity in regulatory genomics. Typically, these networks have a stack of convolutional and pooling layers, followed by one or more fully connected layers. In genomics, the same positional patterns are often present across multiple convolutional channels. Therefore, in current state-of-the-art networks, there exists significant redundancy in the representations learned by standard fully connected layers. We present a new separable fully connected layer that learns a weights tensor that is the outer product of positional weights and cross-channel weights, thereby allowing the same positional patterns to be applied across multiple convolutional channels. Decomposing positional and cross-channel weights further enables us to readily impose biologically-inspired constraints on positional weights, such as symmetry. We also propose a novel regularizer and constraint that act on curvature in the positional weights. Using experiments on simulated and in vivo datasets, we show that networks that incorporate our separable fully connected layer outperform conventional models with analogous architectures and the same number of parameters. Additionally, our networks are more robust to hyperparameter tuning, have more informative gradients, and produce importance scores that are more consistent with known biology than conventional deep neural networks. Availability: Implementation: https://github.com/kundajelab/keras/tree/keras\_1. A gist illustrating model setup is at: goo.gl/gYooaa.},
	journal = {bioRxiv},
	author = {Alexandari, Amr Mohamed and Shrikumar, Avanti and Kundaje, Anshul},
	month = jan,
	year = {2017},
}

@article{cibulskis_sensitive_2013,
	title = {Sensitive detection of somatic point mutations in impure and heterogeneous cancer samples},
	volume = {31},
	issn = {1087-0156},
	url = {http://dx.doi.org/10.1038/nbt.2514},
	number = {3},
	journal = {Nat Biotech},
	author = {Cibulskis, Kristian and Lawrence, Michael S and Carter, Scott L and Sivachenko, Andrey and Jaffe, David and Sougnez, Carrie and Gabriel, Stacey and Meyerson, Matthew and Lander, Eric S and Getz, Gad},
	month = mar,
	year = {2013},
	note = {Publisher: Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	pages = {213--219},
}

@article{DBLP:journals/corr/abs-1801-07860,
	title = {Scalable and accurate deep learning for electronic health records},
	volume = {abs/1801.0},
	url = {http://arxiv.org/abs/1801.07860},
	journal = {CoRR},
	author = {Rajkomar, Alvin and Oren, Eyal and Chen, Kai and Dai, Andrew M and Hajaj, Nissan and Liu, Peter J and Liu, Xiaobing and Sun, Mimi and Sundberg, Patrik and Yee, Hector and Zhang, Kun and Duggan, Gavin E and Flores, Gerardo and Hardt, Michaela and Irvine, Jamie and Le, Quoc V and Litsch, Kurt and Marcus, Jake and Mossin, Alexander and Tansuwan, Justin and Wang, De and Wexler, James and Wilson, Jimbo and Ludwig, Dana and Volchenboum, Samuel L and Chou, Katherine and Pearson, Michael and Madabushi, Srinivasan and Shah, Nigam H and Butte, Atul J and Howell, Michael and Cui, Claire and Corrado, Greg and Dean, Jeff},
	year = {2018},
	note = {arXiv: 1801.07860},
}

@article{shrikumar_reverse-complement_2017,
	title = {Reverse-complement parameter sharing improves deep learning models for genomics},
	url = {http://biorxiv.org/content/early/2017/01/27/103663.abstract},
	abstract = {Deep learning approaches that have produced breakthrough predictive models in computer vision, speech recognition and machine translation are now being successfully applied to problems in regulatory genomics. However, deep learning architectures used thus far in genomics are often directly ported from computer vision and natural language processing applications with few, if any, domain-specific modifications. In double-stranded DNA, the same pattern may appear identically on one strand and its reverse complement due to complementary base pairing. Here, we show that conventional deep learning models that do not explicitly model this property can produce substantially different predictions on forward and reverse-complement versions of the same DNA sequence. We present four new convolutional neural network layers that leverage the reverse-complement property of genomic DNA sequence by sharing parameters between forward and reverse-complement representations in the model. These layers guarantee that forward and reverse-complement sequences produce identical predictions within numerical precision. Using experiments on simulated and in vivo transcription factor binding data, we show that our proposed architectures lead to improved performance, faster learning and cleaner internal representations compared to conventional architectures trained on the same data.},
	journal = {bioRxiv},
	author = {Shrikumar, Avanti and Greenside, Peyton and Kundaje, Anshul},
	month = jan,
	year = {2017},
}

@article{szegedy_rethinking_nodate,
	title = {Rethinking the {Inception} {Architecture} for {Computer} {Vision}},
	abstract = {Convolutional networks are at the core of most state-of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in vari-ous benchmarks. Although increased model size and com-putational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we are explor-ing ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21.2\% top-1 and 5.6\% top-5 error for single frame evaluation using a network with a computa-tional cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3.5\% top-5 error and 17.3\% top-1 error.},
	urldate = {2017-05-31},
	author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jonathon and Wojna, Zbigniew},
}

@article{bengio_representation_2013,
	title = {Representation {Learning}: {A} {Review} and {New} {Perspectives}},
	volume = {35},
	issn = {1939-3539},
	url = {http://arxiv.org/abs/1206.5538},
	doi = {10.1109/TPAMI.2013.50},
	abstract = {The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, autoencoders, manifold learning, and deep networks. This motivates longer term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation, and manifold learning.},
	number = {8},
	urldate = {2017-10-24},
	journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
	author = {Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
	month = jun,
	year = {2013},
	pmid = {23787338},
	note = {arXiv: 1206.5538v2
ISBN: 0162-8828},
	keywords = {AI, Abstracts, Boltzmann machine, Deep learning, Feature extraction, Learning systems, Machine learning, Manifolds, Neural networks, Speech recognition, artificial intelligence, autoencoder, autoencoders, data representation, data structures, density estimation, feature learning, geometrical connections, machine learning algorithms, manifold learning, neural nets, probabilistic models, probability, representation learning, unsupervised feature learning, unsupervised learning},
	pages = {1798--1828},
}

@article{sankar_reliability_2014,
	title = {Reliability of the {American} {Society} of {Anesthesiologists} physical status scale in clinical practice},
	volume = {113},
	issn = {0007-0912},
	url = {http://dx.doi.org/10.1093/bja/aeu100},
	abstract = {BackgroundPrevious studies, which relied on hypothetical cases and chart reviews, have questioned the inter-rater reliability of the ASA physical status (ASA-PS) scale. We therefore conducted a retrospective cohort study to evaluate its inter-rater reliability and validity in clinical practice.MethodsThe cohort included all adult patients (≥18 yr) who underwent elective non-cardiac surgery at a quaternary-care teaching institution in Toronto, Ontario, Canada, from March 2010 to December 2011. We assessed inter-rater reliability by comparing ASA-PS scores assigned at the preoperative assessment clinic vs the operating theatre. We also assessed the validity of the ASA-PS scale by measuring its association with patients' preoperative characteristics and postoperative outcomes.ResultsThe cohort included 10 864 patients, of whom 5.5\% were classified as ASA I, 42.0\% as ASA II, 46.7\% as ASA III, and 5.8\% as ASA IV. The ASA-PS score had moderate inter-rater reliability (κ 0.61), with 67.0\% of patients (n=7279) being assigned to the same ASA-PS class in the clinic and operating theatre, and 98.6\% (n=10 712) of paired assessments being within one class of each other. The ASA-PS scale was correlated with patients' age (Spearman's ρ, 0.23), Charlson comorbidity index (ρ=0.24), revised cardiac risk index (ρ=0.40), and hospital length of stay (ρ=0.16). It had moderate ability to predict in-hospital mortality (receiver-operating characteristic curve area 0.69) and cardiac complications (receiver-operating characteristic curve area 0.70).ConclusionsConsistent with its inherent subjectivity, the ASA-PS scale has moderate inter-rater reliability in clinical practice. It also demonstrates validity as a marker of patients' preoperative health status.},
	number = {3},
	journal = {BJA: British Journal of Anaesthesia},
	author = {Sankar, A and Johnson, S R and Beattie, W S and Tait, G and Wijeysundera, D N and Myles, P S},
	month = sep,
	year = {2014},
	keywords = {Anaesthesiology, Health status, Reliability and validity},
	pages = {424--432},
}

@article{zou2005regularization,
	title = {Regularization and variable selection via the elastic net},
	volume = {67},
	number = {2},
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Zou, Hui and Hastie, Trevor},
	year = {2005},
	note = {Publisher: Wiley Online Library},
	keywords = {grouping effect, lars algorithm, lasso, p, penalization},
	pages = {301--320},
}

@inproceedings{pouladi_recurrent_2015,
	title = {Recurrent {Neural} {Networks} for {Sequential} {Phenotype} {Prediction} in {Genomics}},
	isbn = {978-1-5090-1860-4},
	url = {http://ieeexplore.ieee.org/document/7563642/},
	doi = {10.1109/DeSE.2015.52},
	urldate = {2017-05-03},
	booktitle = {2015 {International} {Conference} on {Developments} of {E}-{Systems} {Engineering} ({DeSE})},
	publisher = {IEEE},
	author = {Pouladi, Farhad and Salehinejad, Hojjat and Gilani, Amir Mohammad},
	month = dec,
	year = {2015},
	pages = {225--230},
}

@inproceedings{ng_reconfigurable_2017,
	title = {Reconfigurable acceleration of genetic sequence alignment: {A} survey of two decades of efforts},
	isbn = {VO -},
	doi = {10.23919/FPL.2017.8056838},
	booktitle = {2017 27th {International} {Conference} on {Field} {Programmable} {Logic} and {Applications} ({FPL})},
	author = {Ng, H C and Liu, S and Luk, W},
	year = {2017},
	keywords = {Acceleration, Algorithm design and analysis, Bioinformatics, CPU-days, Databases, FPGA scientists, Field programmable gate arrays, Genetics, Software, bioinformatic analysis flow, bioinformatics, field programmable gate arrays, genetic sequence alignment, genetics, massive parallelism, molecular biophysics, programming flexibility, qualitative categorization, reconfigurable acceleration, reconfigurable accelerator, sequence data, software-based aligners},
	pages = {1--8},
}

@article{dlugosz_reckoner:_2016,
	title = {{RECKONER}: {Read} {Error} {Corrector} {Based} on {KMC}},
	url = {http://arxiv.org/abs/1602.03086},
	doi = {10.1093/bioinformatics/btw746},
	abstract = {Motivation: Next-generation sequencing tools have enabled producing of huge amount of genomic information at low cost. Unfortunately, presence of sequencing errors in such data affects quality of downstream analyzes. Accuracy of them can be improved by performing error correction. Because of huge amount of such data correction algorithms have to: be fast, memory-frugal, and provide high accuracy of error detection and elimination for variously-sized organisms. Results: We introduce a new algorithm for genomic data correction, capable of processing eucaryotic 300 Mbp-genome-size, high error-rated data using less than 4 GB of RAM in less than 40 minutes on 16-core CPU. The algorithm allows to correct sequencing data at better or comparable level than competitors. This was achieved by using very robust KMC{\textasciitilde}2 \$k\$-mer counter, new method of erroneous regions correction based on both \$k\$-mer counts and FASTQ quality indicators as well as careful optimization. Availability: Program is freely available at http://sun.aei.posl.pl/REFRESH/reckoner. Contact: sebastian.deorowicz@polsl.pl},
	urldate = {2017-05-12},
	author = {Dlugosz, Maciej and Deorowicz, Sebastian},
	month = feb,
	year = {2016},
	note = {arXiv: 1602.03086},
}

@article{navon_rare_2013,
	title = {Rare {Variant} {Association} {Testing} {Under} {Low}-{Coverage} {Sequencing}},
	volume = {194},
	url = {http://www.genetics.org/content/194/3/769},
	number = {3},
	urldate = {2017-04-17},
	journal = {Genetics},
	author = {Navon, Oron and Sul, Jae Hoon and Han, Buhm and Conde, Lucia and Bracci, Paige M. and Riby, Jacques and Skibola, Christine F. and Eskin, Eleazar and Halperin, Eran},
	year = {2013},
}

@article{yu_practical_2006,
	title = {Practical implementation of an efficient forward-backward algorithm for an explicit-duration hidden {Markov} model},
	volume = {54},
	issn = {1053-587X VO - 54},
	doi = {10.1109/TSP.2006.872540},
	abstract = {This correspondence addresses several practical problems in implementing a forward-backward (FB) algorithm for an explicit-duration hidden Markov model. First, the FB variables are redefined in terms of posterior probabilities to avoid possible underflows that may occur in practice. Then, a forward recursion is used that is symmetric to the backward one and can reduce the number of logic gates required to implement on a field-programmable gate-array (FPGA) chip.},
	number = {5},
	journal = {IEEE Transactions on Signal Processing},
	author = {Yu, Shun-Zheng and Kobayashi, H},
	year = {2006},
	keywords = {Explicit-duration hidden Markov model (HMM), FPGA, Field programmable gate arrays, Handwriting recognition, Hidden Markov models, Land mobile radio cellular systems, Logic gates, Magnetic resonance imaging, Signal processing algorithms, Speech analysis, Speech recognition, Videos, backward (FB) algorithm, explicit-duration hidden Markov model, field programmable gate arrays, field-programmable gate-array chip, forward\&\#8211, forward-backward algorithm, forward–, hidden Markov model (HMM), hidden Markov models, hidden semi-Markov model (HSMM), logic gates, posterior probabilities, variable duration HMM},
	pages = {1947--1951},
}

@article{doi:10.1197/jamia.M2025,
	title = {Personal {Health} {Records}: {Definitions}, {Benefits}, and {Strategies} for {Overcoming} {Barriers} to {Adoption}},
	volume = {13},
	url = {+},
	doi = {10.1197/jamia.M2025},
	number = {2},
	journal = {Journal of the American Medical Informatics Association},
	author = {Tang, Paul C and Ash, Joan S and Bates, David W and Overhage, J Marc and Sands, Daniel Z},
	year = {2006},
	pages = {121--126},
}

@article{davies_rapid_2016,
	title = {Rapid genotype imputation from sequence without reference panels.},
	volume = {48},
	issn = {1546-1718},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/27376236},
	doi = {10.1038/ng.3594},
	abstract = {Inexpensive genotyping methods are essential for genetic studies requiring large sample sizes. In human studies, array-based microarrays and high-density haplotype reference panels allow efficient genotype imputation for this purpose. However, these resources are typically unavailable in non-human settings. Here we describe a method (STITCH) for imputation based only on sequencing read data, without requiring additional reference panels or array data. We demonstrate its applicability even in settings of extremely low sequencing coverage, by accurately imputing 5.7 million SNPs at a mean r(2) value of 0.98 in 2,073 outbred laboratory mice (0.15× sequencing coverage). In a sample of 11,670 Han Chinese (1.7× coverage), we achieve accuracy similar to that of alternative approaches that require a reference panel, demonstrating that our approach can work for genetically diverse populations. Our method enables straightforward progression from low-coverage sequence to imputed genotypes, overcoming barriers that at present restrict the application of genome-wide association study technology outside humans.},
	number = {8},
	urldate = {2017-04-17},
	journal = {Nature genetics},
	author = {Davies, Robert W and Flint, Jonathan and Myers, Simon and Mott, Richard},
	month = aug,
	year = {2016},
	pmid = {27376236},
	note = {Publisher: Europe PMC Funders},
	pages = {965--9},
}

@article{marouli_rare_2017,
	title = {Rare and low-frequency coding variants alter human adult height},
	volume = {542},
	issn = {0028-0836},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/28146470},
	doi = {10.1038/nature21039},
	abstract = {Height is a highly heritable, classic polygenic trait with approximately 700 common associated variants identified through genome-wide association studies so far. Here, we report 83 height-associated coding variants with lower minor-allele frequencies (in the range of 0.1-4.8\%) and effects of up to 2 centimetres per allele (such as those in IHH, STC2, AR and CRISPLD2), greater than ten times the average effect of common variants. In functional follow-up studies, rare height-increasing alleles of STC2 (giving an increase of 1-2 centimetres per allele) compromised proteolytic inhibition of PAPP-A and increased cleavage of IGFBP-4 in vitro, resulting in higher bioavailability of insulin-like growth factors. These 83 height-associated variants overlap genes that are mutated in monogenic growth disorders and highlight new biological candidates (such as ADAMTS3, IL11RA and NOX4) and pathways (such as proteoglycan and glycosaminoglycan synthesis) involved in growth. Our results demonstrate that sufficiently large sample sizes can uncover rare and low-frequency variants of moderate-to-large effect associated with polygenic human phenotypes, and that these variants implicate relevant genes and pathways.},
	number = {7640},
	urldate = {2017-04-23},
	journal = {Nature},
	author = {Marouli, Eirini and Graff, Mariaelisa and Medina-Gomez, Carolina and Lo, Ken Sin and Wood, Andrew R. and Kjaer, Troels R. and Fine, Rebecca S. and Lu, Yingchang and Schurmann, Claudia and Highland, Heather M. and Rüeger, Sina and Thorleifsson, Gudmar and Justice, Anne E. and Lamparter, David and Stirrups, Kathleen E. and Turcot, Valérie and Young, Kristin L. and Winkler, Thomas W. and Esko, Tõnu and Karaderi, Tugce and Locke, Adam E. and Masca, Nicholas G. D. and Ng, Maggie C. Y. and Mudgal, Poorva and Rivas, Manuel A. and Vedantam, Sailaja and Mahajan, Anubha and Guo, Xiuqing and Abecasis, Goncalo and Aben, Katja K. and Adair, Linda S. and Alam, Dewan S. and Albrecht, Eva and Allin, Kristine H. and Allison, Matthew and Amouyel, Philippe and Appel, Emil V. and Arveiler, Dominique and Asselbergs, Folkert W. and Auer, Paul L. and Balkau, Beverley and Banas, Bernhard and Bang, Lia E. and Benn, Marianne and Bergmann, Sven and Bielak, Lawrence F. and Blüher, Matthias and Boeing, Heiner and Boerwinkle, Eric and Böger, Carsten A. and Bonnycastle, Lori L. and Bork-Jensen, Jette and Bots, Michiel L. and Bottinger, Erwin P. and Bowden, Donald W. and Brandslund, Ivan and Breen, Gerome and Brilliant, Murray H. and Broer, Linda and Burt, Amber A. and Butterworth, Adam S. and Carey, David J. and Caulfield, Mark J. and Chambers, John C. and Chasman, Daniel I. and Chen, Yii-Der Ida and Chowdhury, Rajiv and Christensen, Cramer and Chu, Audrey Y. and Cocca, Massimiliano and Collins, Francis S. and Cook, James P. and Corley, Janie and Galbany, Jordi Corominas and Cox, Amanda J. and Cuellar-Partida, Gabriel and Danesh, John and Davies, Gail and de Bakker, Paul I. W. and de Borst, Gert J. and de Denus, Simon and de Groot, Mark C. H. and de Mutsert, Renée and Deary, Ian J. and Dedoussis, George and Demerath, Ellen W. and den Hollander, Anneke I. and Dennis, Joe G. and Di Angelantonio, Emanuele and Drenos, Fotios and Du, Mengmeng and Dunning, Alison M. and Easton, Douglas F. and Ebeling, Tapani and Edwards, Todd L. and Ellinor, Patrick T. and Elliott, Paul and Evangelou, Evangelos and Farmaki, Aliki-Eleni and Faul, Jessica D. and Feitosa, Mary F. and Feng, Shuang and Ferrannini, Ele and Ferrario, Marco M. and Ferrieres, Jean and Florez, Jose C. and Ford, Ian and Fornage, Myriam and Franks, Paul W. and Frikke-Schmidt, Ruth and Galesloot, Tessel E. and Gan, Wei and Gandin, Ilaria and Gasparini, Paolo and Giedraitis, Vilmantas and Giri, Ayush and Girotto, Giorgia and Gordon, Scott D. and Gordon-Larsen, Penny and Gorski, Mathias and Grarup, Niels and Grove, Megan L. and Gudnason, Vilmundur and Gustafsson, Stefan and Hansen, Torben and Harris, Kathleen Mullan and Harris, Tamara B. and Hattersley, Andrew T. and Hayward, Caroline and He, Liang and Heid, Iris M. and Heikkilä, Kauko and Helgeland, Øyvind and Hernesniemi, Jussi and Hewitt, Alex W. and Hocking, Lynne J. and Hollensted, Mette and Holmen, Oddgeir L. and Hovingh, G. Kees and Howson, Joanna M. M. and Hoyng, Carel B. and Huang, Paul L. and Hveem, Kristian and Ikram, M. Arfan and Ingelsson, Erik and Jackson, Anne U. and Jansson, Jan-Håkan and Jarvik, Gail P. and Jensen, Gorm B. and Jhun, Min A. and Jia, Yucheng and Jiang, Xuejuan and Johansson, Stefan and Jørgensen, Marit E. and Jørgensen, Torben and Jousilahti, Pekka and Jukema, J. Wouter and Kahali, Bratati and Kahn, René S. and Kähönen, Mika and Kamstrup, Pia R. and Kanoni, Stavroula and Kaprio, Jaakko and Karaleftheri, Maria and Kardia, Sharon L. R. and Karpe, Fredrik and Kee, Frank and Keeman, Renske and Kiemeney, Lambertus A. and Kitajima, Hidetoshi and Kluivers, Kirsten B. and Kocher, Thomas and Komulainen, Pirjo and Kontto, Jukka and Kooner, Jaspal S. and Kooperberg, Charles and Kovacs, Peter and Kriebel, Jennifer and Kuivaniemi, Helena and Küry, Sébastien and Kuusisto, Johanna and La Bianca, Martina and Laakso, Markku and Lakka, Timo A. and Lange, Ethan M. and Lange, Leslie A. and Langefeld, Carl D. and Langenberg, Claudia and Larson, Eric B. and Lee, I-Te and Lehtimäki, Terho and Lewis, Cora E. and Li, Huaixing and Li, Jin and Li-Gao, Ruifang and Lin, Honghuang and Lin, Li-An and Lin, Xu and Lind, Lars and Lindström, Jaana and Linneberg, Allan and Liu, Yeheng and Liu, Yongmei and Lophatananon, Artitaya and Luan, Jian'an and Lubitz, Steven A. and Lyytikäinen, Leo-Pekka and Mackey, David A. and Madden, Pamela A. F. and Manning, Alisa K. and Männistö, Satu and Marenne, Gaëlle and Marten, Jonathan and Martin, Nicholas G. and Mazul, Angela L. and Meidtner, Karina and Metspalu, Andres and Mitchell, Paul and Mohlke, Karen L. and Mook-Kanamori, Dennis O. and Morgan, Anna and Morris, Andrew D. and Morris, Andrew P. and Müller-Nurasyid, Martina and Munroe, Patricia B. and Nalls, Mike A. and Nauck, Matthias and Nelson, Christopher P. and Neville, Matt and Nielsen, Sune F. and Nikus, Kjell and Njølstad, Pål R. and Nordestgaard, Børge G. and Ntalla, Ioanna and O'Connel, Jeffrey R. and Oksa, Heikki and Loohuis, Loes M. Olde and Ophoff, Roel A. and Owen, Katharine R. and Packard, Chris J. and Padmanabhan, Sandosh and Palmer, Colin N. A. and Pasterkamp, Gerard and Patel, Aniruddh P. and Pattie, Alison and Pedersen, Oluf and Peissig, Peggy L. and Peloso, Gina M. and Pennell, Craig E. and Perola, Markus and Perry, James A. and Perry, John R. B. and Person, Thomas N. and Pirie, Ailith and Polasek, Ozren and Posthuma, Danielle and Raitakari, Olli T. and Rasheed, Asif and Rauramaa, Rainer and Reilly, Dermot F. and Reiner, Alex P. and Renström, Frida and Ridker, Paul M. and Rioux, John D. and Robertson, Neil and Robino, Antonietta and Rolandsson, Olov and Rudan, Igor and Ruth, Katherine S. and Saleheen, Danish and Salomaa, Veikko and Samani, Nilesh J. and Sandow, Kevin and Sapkota, Yadav and Sattar, Naveed and Schmidt, Marjanka K. and Schreiner, Pamela J. and Schulze, Matthias B. and Scott, Robert A. and Segura-Lepe, Marcelo P. and Shah, Svati and Sim, Xueling and Sivapalaratnam, Suthesh and Small, Kerrin S. and Smith, Albert Vernon and Smith, Jennifer A. and Southam, Lorraine and Spector, Timothy D. and Speliotes, Elizabeth K. and Starr, John M. and Steinthorsdottir, Valgerdur and Stringham, Heather M. and Stumvoll, Michael and Surendran, Praveen and ‘t Hart, Leen M. and Tansey, Katherine E. and Tardif, Jean-Claude and Taylor, Kent D. and Teumer, Alexander and Thompson, Deborah J. and Thorsteinsdottir, Unnur and Thuesen, Betina H. and Tönjes, Anke and Tromp, Gerard and Trompet, Stella and Tsafantakis, Emmanouil and Tuomilehto, Jaakko and Tybjaerg-Hansen, Anne and Tyrer, Jonathan P. and Uher, Rudolf and Uitterlinden, André G. and Ulivi, Sheila and van der Laan, Sander W. and Van Der Leij, Andries R. and van Duijn, Cornelia M. and van Schoor, Natasja M. and van Setten, Jessica and Varbo, Anette and Varga, Tibor V. and Varma, Rohit and Edwards, Digna R. Velez and Vermeulen, Sita H. and Vestergaard, Henrik and Vitart, Veronique and Vogt, Thomas F. and Vozzi, Diego and Walker, Mark and Wang, Feijie and Wang, Carol A. and Wang, Shuai and Wang, Yiqin and Wareham, Nicholas J. and Warren, Helen R. and Wessel, Jennifer and Willems, Sara M. and Wilson, James G. and Witte, Daniel R. and Woods, Michael O. and Wu, Ying and Yaghootkar, Hanieh and Yao, Jie and Yao, Pang and Yerges-Armstrong, Laura M. and Young, Robin and Zeggini, Eleftheria and Zhan, Xiaowei and Zhang, Weihua and Zhao, Jing Hua and Zhao, Wei and Zhao, Wei and Zheng, He and Zhou, Wei and Rotter, Jerome I and Boehnke, Michael and Kathiresan, Sekar and McCarthy, Mark I. and Willer, Cristen J. and Stefansson, Kari and Borecki, Ingrid B. and Liu, Dajiang J. and North, Kari E. and Heard-Costa, Nancy L. and Pers, Tune H. and Lindgren, Cecilia M. and Oxvig, Claus and Kutalik, Zoltán and Rivadeneira, Fernando and Loos, Ruth J. F. and Frayling, Timothy M. and Hirschhorn, Joel N. and Deloukas, Panos and Lettre, Guillaume and Oxvig, Claus and Kutalik, Zoltán and Rivadeneira, Fernando and Loos, Ruth J F and Frayling, Timothy M and Hirschhorn, Joel N and Deloukas, Panos and Lettre, Guillaume},
	month = feb,
	year = {2017},
	pmid = {28146470},
	pages = {186--190},
}

@article{brockman_quality_2008,
	title = {Quality scores and {SNP} detection in sequencing-by-synthesis systems.},
	volume = {18},
	issn = {1088-9051},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/18212088},
	doi = {10.1101/gr.070227.107},
	abstract = {Promising new sequencing technologies, based on sequencing-by-synthesis (SBS), are starting to deliver large amounts of DNA sequence at very low cost. Polymorphism detection is a key application. We describe general methods for improved quality scores and accurate automated polymorphism detection, and apply them to data from the Roche (454) Genome Sequencer 20. We assess our methods using known-truth data sets, which is critical to the validity of the assessments. We developed informative, base-by-base error predictors for this sequencer and used a variant of the phred binning algorithm to combine them into a single empirically derived quality score. These quality scores are more useful than those produced by the system software: They both better predict actual error rates and identify many more high-quality bases. We developed a SNP detection method, with variants for low coverage, high coverage, and PCR amplicon applications, and evaluated it on known-truth data sets. We demonstrate good specificity in single reads, and excellent specificity (no false positives in 215 kb of genome) in high-coverage data.},
	number = {5},
	urldate = {2017-05-04},
	journal = {Genome research},
	author = {Brockman, William and Alvarez, Pablo and Young, Sarah and Garber, Manuel and Giannoukos, Georgia and Lee, William L and Russ, Carsten and Lander, Eric S and Nusbaum, Chad and Jaffe, David B},
	month = may,
	year = {2008},
	pmid = {18212088},
	note = {Publisher: Cold Spring Harbor Laboratory Press},
	pages = {763--70},
}

@article{browning_rapid_2007,
	title = {Rapid and accurate haplotype phasing and missing-data inference for whole-genome association studies by use of localized haplotype clustering.},
	volume = {81},
	issn = {0002-9297},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/17924348},
	doi = {10.1086/521987},
	abstract = {Whole-genome association studies present many new statistical and computational challenges due to the large quantity of data obtained. One of these challenges is haplotype inference; methods for haplotype inference designed for small data sets from candidate-gene studies do not scale well to the large number of individuals genotyped in whole-genome association studies. We present a new method and software for inference of haplotype phase and missing data that can accurately phase data from whole-genome association studies, and we present the first comparison of haplotype-inference methods for real and simulated data sets with thousands of genotyped individuals. We find that our method outperforms existing methods in terms of both speed and accuracy for large data sets with thousands of individuals and densely spaced genetic markers, and we use our method to phase a real data set of 3,002 individuals genotyped for 490,032 markers in 3.1 days of computing time, with 99\% of masked alleles imputed correctly. Our method is implemented in the Beagle software package, which is freely available.},
	number = {5},
	urldate = {2017-05-07},
	journal = {American journal of human genetics},
	author = {Browning, Sharon R and Browning, Brian L},
	month = nov,
	year = {2007},
	pmid = {17924348},
	note = {Publisher: Elsevier},
	pages = {1084--97},
}

@article{storey_rapid_2009,
	title = {Rapid and accurate multiple testing correction and power estimation for millions of correlated markers},
	volume = {5},
	issn = {15537390},
	url = {http://dx.plos.org/10.1371/journal.pgen.1000456},
	doi = {10.1371/journal.pgen.1000456},
	abstract = {With the development of high-throughput sequencing and genotyping technologies, the number of markers collected in genetic association studies is growing rapidly, increasing the importance of methods for correcting for multiple hypothesis testing. The permutation test is widely considered the gold standard for accurate multiple testing correction, but it is often computationally impractical for these large datasets. Recently, several studies proposed efficient alternative approaches to the permutation test based on the multivariate normal distribution (MVN). However, they cannot accurately correct for multiple testing in genome-wide association studies for two reasons. First, these methods require partitioning of the genome into many disjoint blocks and ignore all correlations between markers from different blocks. Second, the true null distribution of the test statistic often fails to follow the asymptotic distribution at the tails of the distribution. We propose an accurate and efficient method for multiple testing correction in genome-wide association studies--SLIDE. Our method accounts for all correlation within a sliding window and corrects for the departure of the true null distribution of the statistic from the asymptotic distribution. In simulations using the Wellcome Trust Case Control Consortium data, the error rate of SLIDE's corrected p-values is more than 20 times smaller than the error rate of the previous MVN-based methods' corrected p-values, while SLIDE is orders of magnitude faster than the permutation test and other competing methods. We also extend the MVN framework to the problem of estimating the statistical power of an association study with correlated markers and propose an efficient and accurate power estimation method SLIP. SLIP and SLIDE are available at http://slide.cs.ucla.edu.},
	number = {4},
	urldate = {2017-04-17},
	journal = {PLoS Genetics},
	author = {Han, Buhm and Kang, Hyun Min and Eskin, Eleazar},
	editor = {Storey, John D.},
	month = apr,
	year = {2009},
	pmid = {19381255},
	note = {Publisher: Wiley
ISBN: 1553-7404 (Electronic){\textbackslash}r1553-7390 (Linking)},
	pages = {e1000456},
}

@inproceedings{Arora:2014:PBL:3044805.3044872,
	title = {Provable {Bounds} for {Learning} {Some} {Deep} {Representations}},
	url = {http://dl.acm.org/citation.cfm?id=3044805.3044872},
	booktitle = {Proceedings of the 31st {International} {Conference} on {International} {Conference} on {Machine} {Learning} - {Volume} 32},
	publisher = {JMLR.org},
	author = {Arora, Sanjeev and Bhaskara, Aditya and Ge, Rong and Ma, Tengyu},
	year = {2014},
	note = {Series Title: ICML'14},
	pages = {I--584--I--592},
}

@inproceedings{huang_programming_2016,
	address = {New York, New York, USA},
	title = {Programming and {Runtime} {Support} to {Blaze} {FPGA} {Accelerator} {Deployment} at {Datacenter} {Scale}},
	isbn = {978-1-4503-4525-5},
	url = {http://dl.acm.org/citation.cfm?doid=2987550.2987569},
	doi = {10.1145/2987550.2987569},
	urldate = {2017-04-27},
	booktitle = {Proceedings of the {Seventh} {ACM} {Symposium} on {Cloud} {Computing} - {SoCC} '16},
	publisher = {ACM Press},
	author = {Huang, Muhuan and Wu, Di and Yu, Cody Hao and Fang, Zhenman and Interlandi, Matteo and Condie, Tyson and Cong, Jason},
	year = {2016},
	keywords = {FPGA-as-a-service, heterogeneous datacenter},
	pages = {456--469},
}

@article{terekhov_preoperative_2015,
	title = {Preoperative {Surgical} {Risk} {Predictions} {Are} {Not} {Meaningfully} {Improved} by {Including} the {Surgical} {Apgar} {ScoreAn} {Analysis} of the {Risk} {Quantification} {Index} and {Present}-{On}-{Admission} {Risk} {Models}},
	volume = {123},
	issn = {0003-3022},
	url = {http://dx.doi.org/10.1097/ALN.0000000000000858},
	abstract = {Abstract Background: Estimating surgical risk is critical for perioperative decision making and risk stratification. Current risk-adjustment measures do not integrate dynamic clinical parameters along with baseline patient characteristics, which may allow a more accurate prediction of surgical risk. The goal of this study was to determine whether the preoperative Risk Quantification Index (RQI) and Present-On-Admission Risk (POARisk) models would be improved by including the intraoperative Surgical Apgar Score (SAS). Methods: The authors identified adult patients admitted after noncardiac surgery. The RQI and POARisk were calculated using published methodologies, and model performance was compared with and without the SAS. Relative quality was measured using Akaike and Bayesian information criteria. Calibration was compared by the Brier score. Discrimination was compared by the area under the receiver operating curves (AUROCs) using a bootstrapping procedure for bias correction. Results: SAS alone was a statistically significant predictor of both 30-day mortality and in-hospital mortality (P \&lt; 0.0001). The RQI had excellent discrimination with an AUROC of 0.8433, which increased to 0.8529 with the addition of the SAS. The POARisk had excellent discrimination with an AUROC of 0.8608, which increased to 0.8645 by including the SAS. Similarly, overall performance and relative quality increased. Conclusions: While AUROC values increased, the RQI and POARisk preoperative risk models were not meaningfully improved by adding intraoperative risk using the SAS. In addition to the estimated blood loss, lowest heart rate, and lowest mean arterial pressure, other dynamic clinical parameters from the patient’s intraoperative course may need to be combined with procedural risk estimate models to improve risk stratification.},
	number = {5},
	journal = {Anesthesiology},
	author = {Terekhov, Maxim A and Ehrenfeld, Jesse M and Wanderer, Jonathan P},
	month = nov,
	year = {2015},
	pages = {1059--1066},
}

@inproceedings{jacob_preliminary_2007,
	title = {Preliminary results in accelerating profile {HMM} search on {FPGAs}},
	isbn = {1530-2075 VO -},
	doi = {10.1109/IPDPS.2007.370447},
	abstract = {Comparison between biosequences and probabilistic models is an increasingly important part of modern DNA and protein sequence analysis. The large and growing number of such models in today's databases demands computational approaches to searching these databases faster, while maintaining high sensitivity to biologically meaningful similarities. This work describes an FPGA-based accelerator for comparing proteins to hidden Markov models of the type used to represent protein motifs in the popular HM-MER motif finder. Our engine combines a systolic array design with enhancements to pipeline the complex Viterbi calculation that forms the core of the comparison, and to support coarse-grained parallelism and streaming of multiple sequences within one FPGA. Performance estimates based on a functioning VHDL realisation of our design show a 190 times speedup over the same computation in optimised software on a modern general-purpose CPU.},
	booktitle = {2007 {IEEE} {International} {Parallel} and {Distributed} {Processing} {Symposium}},
	author = {Jacob, A C and Lancaster, J M and Buhler, J D and Chamberlain, R D},
	year = {2007},
	keywords = {Acceleration, Biological system modeling, Biology computing, DNA, Databases, Engines, FPGA-based accelerator, Field programmable gate arrays, HMM search, Hidden Markov models, Protein sequence, Systolic arrays, VHDL, Viterbi calculation, biology computing, biosequences, database management systems, databases, field programmable gate arrays, hidden Markov models, pipeline processing, pipelining technique, probabilistic models, probability, protein sequence analysis, proteins, systolic array design, systolic arrays},
	pages = {1--8},
}

@article{alipanahi_predicting_2015,
	title = {Predicting the sequence specificities of {DNA}- and {RNA}-binding proteins by deep learning},
	volume = {33},
	issn = {1087-0156},
	url = {http://dx.doi.org/10.1038/nbt.3300},
	abstract = {Knowing the sequence specificities of DNA- and RNA-binding proteins is essential for developing models of the regulatory processes in biological systems and for identifying causal disease variants. Here we show that sequence specificities can be ascertained from experimental data with 'deep learning' techniques, which offer a scalable, flexible and unified computational approach for pattern discovery. Using a diverse array of experimental data and evaluation metrics, we find that deep learning outperforms other state-of-the-art methods, even when training on in vitro data and testing on in vivo data. We call this approach DeepBind and have built a stand-alone software tool that is fully automatic and handles millions of sequences per experiment. Specificities determined by DeepBind are readily visualized as a weighted ensemble of position weight matrices or as a 'mutation map' that indicates how variations affect binding within a specific sequence.},
	number = {8},
	journal = {Nat Biotech},
	author = {Alipanahi, Babak and Delong, Andrew and Weirauch, Matthew T and Frey, Brendan J.},
	month = aug,
	year = {2015},
	note = {Publisher: Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	pages = {831--838},
}

@article{gerstung_precision_2017,
	title = {Precision oncology for acute myeloid leukemia using a knowledge bank approach},
	volume = {49},
	issn = {1061-4036},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/28092685},
	doi = {10.1038/ng.3756},
	abstract = {Underpinning the vision of precision medicine is the concept that causative mutations in a patient's cancer drive its biology and, by extension, its clinical features and treatment response. However, considerable between-patient heterogeneity in driver mutations complicates evidence-based personalization of cancer care. Here, by reanalyzing data from 1,540 patients with acute myeloid leukemia (AML), we explore how large knowledge banks of matched genomic-clinical data can support clinical decision-making. Inclusive, multistage statistical models accurately predicted likelihoods of remission, relapse and mortality, which were validated using data from independent patients in The Cancer Genome Atlas. Comparison of long-term survival probabilities under different treatments enables therapeutic decision support, which is available in exploratory form online. Personally tailored management decisions could reduce the number of hematopoietic cell transplants in patients with AML by 20-25\% while maintaining overall survival rates. Power calculations show that databases require information from thousands of patients for accurate decision support. Knowledge banks facilitate personally tailored therapeutic decisions but require sustainable updating, inclusive cohorts and large sample sizes.},
	number = {3},
	urldate = {2017-11-07},
	journal = {Nature Genetics},
	author = {Gerstung, Moritz and Papaemmanuil, Elli and Martincorena, Inigo and Bullinger, Lars and Gaidzik, Verena I and Paschka, Peter and Heuser, Michael and Thol, Felicitas and Bolli, Niccolo and Ganly, Peter and Ganser, Arnold and McDermott, Ultan and Döhner, Konstanze and Schlenk, Richard F and Döhner, Hartmut and Campbell, Peter J},
	month = mar,
	year = {2017},
	pmid = {28092685},
	keywords = {80 and over, Acute, Adolescent, Adult, Aged, Clinical Trials as Topic, Decision Making, Female, Humans, Leukemia, Male, Middle Aged, Multicenter Studies as Topic, Myeloid, Precision Medicine, Randomized Controlled Trials as Topic, Survival Rate, Young Adult},
	pages = {332--340},
}

@article{huang_pie:_2017,
	title = {{PIE}: {A} prior knowledge guided integrated likelihood estimation method for bias reduction in association studies using electronic health records data},
	issn = {1067-5027},
	url = {http://dx.doi.org/10.1093/jamia/ocx137},
	abstract = {ObjectivesThis study proposes a novel Prior knowledge guided Integrated likelihood Estimation (PIE) method to correct bias in estimations of associations due to misclassification of electronic health record (EHR)-derived binary phenotypes, and evaluates the performance of the proposed method by comparing it to 2 methods in common practice.MethodsWe conducted simulation studies and data analysis of real EHR-derived data on diabetes from Kaiser Permanente Washington to compare the estimation bias of associations using the proposed method, the method ignoring phenotyping errors, the maximum likelihood method with misspecified sensitivity and specificity, and the maximum likelihood method with correctly specified sensitivity and specificity (gold standard). The proposed method effectively leverages available information on phenotyping accuracy to construct a prior distribution for sensitivity and specificity, and incorporates this prior information through the integrated likelihood for bias reduction.ResultsOur simulation studies and real data application demonstrated that the proposed method effectively reduces the estimation bias compared to the 2 current methods. It performed almost as well as the gold standard method when the prior had highest density around true sensitivity and specificity. The analysis of EHR data from Kaiser Permanente Washington showed that the estimated associations from PIE were very close to the estimates from the gold standard method and reduced bias by 60\%–100\% compared to the 2 commonly used methods in current practice for EHR data.ConclusionsThis study demonstrates that the proposed method can effectively reduce estimation bias caused by imperfect phenotyping in EHR-derived data by incorporating prior information through integrated likelihood.},
	journal = {Journal of the American Medical Informatics Association},
	author = {Huang, Jing and Duan, Rui and Hubbard, Rebecca A and Wu, Yonghui and Moore, Jason H and Xu, Hua and Chen, Yong},
	month = dec,
	year = {2017},
	pages = {ocx137--ocx137},
}

@inproceedings{houtgast_power-efficient_2016,
	title = {Power-{Efficient} {Accelerated} {Genomic} {Short} {Read} {Mapping} on {Heterogeneous} {Computing} {Platforms}},
	isbn = {VO -},
	doi = {10.1109/FCCM.2016.17},
	abstract = {We propose a novel FPGA-accelerated BWA-MEM implementation, a popular tool for genomic data mapping. The performance and power-efficiency of the FPGA implementation on the single Xilinx Virtex-7 Alpha Data add-in card is compared against a software-only baseline system. By offloading the Seed Extension phase onto the FPGA, a two-fold speedup in overall application-level performance is achieved and a 1.6x gain in power-efficiency. To facilitate platform and tool-agnostic comparisons, the base pairs per Joule unit is introduced as a measure of power-efficiency. The FPGA design is able to map up to 34 thousand base pairs per Joule.},
	booktitle = {2016 {IEEE} 24th {Annual} {International} {Symposium} on {Field}-{Programmable} {Custom} {Computing} {Machines} ({FCCM})},
	author = {Houtgast, E J and Sima, V M and Marchiori, G and Bertels, K and Al-Ars, Z},
	year = {2016},
	keywords = {Acceleration, Algorithm design and analysis, Bioinformatics, Computers, FPGA, FPGA design, FPGA-accelerated BWA-MEM implementation, Field programmable gate arrays, Genomics, Power demand, Xilinx Virtex-7 Alpha Data add-in card, field programmable gate arrays, genomic data mapping, genomics, heterogeneous computing platforms, logic design, power aware computing, power-efficiency, power-efficient accelerated genomic short read map, read mapping, seed extension phase offloading},
	pages = {28},
}

@article{rodriguez_parente2:_2015,
	title = {Parente2: {A} fast and accurate method for detecting identity by descent},
	volume = {25},
	issn = {15495469},
	doi = {10.1101/gr.173641.114},
	abstract = {Identity-by-descent (IBD) inference is the problem of establishing a genetic connection between two individuals through a genomic segment that is inherited by both individuals from a recent common ancestor. IBD inference is an important preceding step in a variety of population genomic studies, ranging from demographic studies to linking genomic variation with phenotype and disease. The problem of accurate IBD detection has become increasingly challenging with the availability of large collections of human genotypes and genomes: given a cohort's size, a quadratic number of pairwise genome comparisons must be performed. Therefore, computation time and the false discovery rate can also scale quadratically. To enable accurate and efficient large-scale IBD detection, we present Parente2, a novel method for detecting IBD segments. Parente2 is based on an embedded log-likelihood ratio and uses a model that accounts for linkage disequilibrium by explicitly modeling haplotype frequencies. Parente2 operates directly on genotype data without the need to phase data prior to IBD inference. We evaluate Parente2's performance through extensive simulations using real data, and show that it provides substantially higher accuracy compared to previous state-of-the-art, while maintaining high computational efficiency.},
	number = {2},
	journal = {Genome Research},
	author = {Rodriguez, Jesse M. and Bercovici, Sivan and Huang, Lin and Frostig, Roy and Batzoglou, Serafim},
	year = {2015},
	pmid = {25273070},
	note = {ISBN: 1549-5469 (Electronic){\textbackslash}r1088-9051 (Linking)},
	keywords = {IBD},
	pages = {280--289},
}

@inproceedings{cong_optimizing_2012,
	address = {New York, New York, USA},
	title = {Optimizing memory hierarchy allocation with loop transformations for high-level synthesis},
	isbn = {978-1-4503-1199-1},
	url = {http://dl.acm.org/citation.cfm?doid=2228360.2228586},
	doi = {10.1145/2228360.2228586},
	urldate = {2017-04-10},
	booktitle = {Proceedings of the 49th {Annual} {Design} {Automation} {Conference} on - {DAC} '12},
	publisher = {ACM Press},
	author = {Cong, Jason and Zhang, Peng and Zou, Yi},
	year = {2012},
	pages = {1233},
}

@inproceedings{banerjee_accelerating_2017,
	title = {On accelerating pair-{HMM} computations in programmable hardware},
	isbn = {VO -},
	doi = {10.23919/FPL.2017.8056837},
	abstract = {This paper explores hardware acceleration to significantly improve the runtime of computing the forward algorithm on Pair-HMM models, a crucial step in analyzing mutations in sequenced genomes. We describe 1) the design and evaluation of a novel accelerator architecture that can efficiently process real sequence data without performing wasteful work; and 2) aggressive memoization techniques that can significantly reduce the number of invocations of, and the amount of data transferred to the accelerator. We describe our demonstration of the design on a Xilinx Virtex 7 FPGA in an IBM Power8 system. Our design achieves a 14.85\&\#x00D7; higher throughput than an 8-core CPU baseline (that uses SIMD and multi-threading) and a 147.49 \&\#x00D7; improvement in throughput per unit of energy expended on the NA12878 sample.},
	booktitle = {2017 27th {International} {Conference} on {Field} {Programmable} {Logic} and {Applications} ({FPL})},
	author = {Banerjee, S S and El-Hadedy, M and Tan, C Y and Kalbarczyk, Z T and Lumetta, S and Iyer, R K},
	year = {2017},
	keywords = {Acceleration, Algorithm design and analysis, Bioinformatics, CPU baseline, Computational modeling, Computer architecture, Coprocessors, Field programmable gate arrays, Genomics, IBM Power8 system, Pair-HMM models, Parallel processing, Reconfigurable architectures, SIMD, Xilinx Virtex 7 FPGA, accelerator architecture, biology computing, coprocessors, crucial step, field programmable gate arrays, forward algorithm, genomics, hardware acceleration, hidden Markov models, memoization techniques, microprocessor chips, multi-threading, multiprocessing systems, mutation analysis, pair-HMM computations, programmable hardware, sequence data, sequenced genomes, wasteful work},
	pages = {1--8},
}

@article{martina_m.sc._noninvasive_2012,
	title = {Noninvasive {Continuous} {Arterial} {Blood} {Pressure} {Monitoring} with {Nexfin}®},
	volume = {116},
	url = {https://doi.org/10.1097/ALN.0b013e31824f94ed},
	doi = {10.1097/ALN.0b013e31824f94ed},
	number = {5},
	journal = {Anesthesiology: The Journal of the American Society of Anesthesiologists},
	author = {Martina M.Sc., Jerson R. and Westerhof M.Sc., Berend E., Ph.D. and van Goudoever M.Sc., Jeroen, Ph.D. and de Beaumont M.D., Edouard M F. H. and Truijen M.D., Jasper and Kim M.D., Yu-Sok and Immink M.D., Rogier V. and Jöbsis M.D., Dorothea A. and Hollmann M.D., Markus W., Ph.D. and Lahpor M.D., Jaap R., Ph.D. and de Mol M.D., Bas A J. M., Ph.D. and van Lieshout M.D., Johannes J., Ph.D.},
	month = may,
	year = {2012},
	pages = {1092--1103},
}

@article{moon_manifold_2017,
	title = {Manifold learning-based methods for analyzing single-cell {RNA}-sequencing data},
	volume = {7},
	issn = {24523100},
	url = {https://www.sciencedirect.com/science/article/pii/S2452310017301877},
	doi = {10.1016/j.coisb.2017.12.008},
	abstract = {Recent advances in single-cell RNA sequencing technologies enable deep insights into cellular development, gene regulation, and phenotypic diversity by measuring gene expression for thousands of cells in a single experiment. While these technologies hold great potential for improving our understanding of cellular states and progression, they also pose new challenges and require advanced mathematical and algorithmic tools to extract underlying biological signals. In this review, we cover one of the most promising avenues of research into unlocking the potential of scRNA-seq data: the field of manifold learning, and the related manifold assumption in data analysis. Manifold learning provides a powerful structure for algorithmic approaches to process the data, extract its dynamics, and infer patterns in it. In particular, we cover manifold learning-based methods for denoising the data, revealing gene interactions, extracting pseudotime progressions with model fitting, visualizing the cellular state space via dimensionality reduction, and clustering the data.},
	urldate = {2018-02-05},
	journal = {Current Opinion in Systems Biology},
	author = {Moon, Kevin R. and Stanley, Jay and Burkhardt, Daniel and van Dijk, David and Wolf, Guy and Krishnaswamy, Smita},
	month = feb,
	year = {2017},
	note = {Publisher: Elsevier},
	pages = {36--46},
}

@article{jensen_mining_2012,
	title = {Mining electronic health records: towards better research applications and clinical care},
	volume = {13},
	url = {http://dx.doi.org/10.1038/nrg3208},
	journal = {Nature Reviews Genetics},
	author = {Jensen, Peter B and Jensen, Lars J and Brunak, Søren},
	month = may,
	year = {2012},
	note = {Publisher: Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	pages = {395},
}

@inproceedings{fernandez_multithreaded_2012,
	title = {Multithreaded {FPGA} acceleration of {DNA} sequence mapping},
	isbn = {978-1-4673-1576-0},
	url = {http://ieeexplore.ieee.org/document/6408669/},
	doi = {10.1109/HPEC.2012.6408669},
	urldate = {2017-04-18},
	booktitle = {2012 {IEEE} {Conference} on {High} {Performance} {Extreme} {Computing}},
	publisher = {IEEE},
	author = {Fernandez, Edward B. and Najjar, Walid A. and Lonardi, Stefano and Villarreal, Jason},
	month = sep,
	year = {2012},
	pages = {1--6},
}

@article{stekhoven_missforestnon-parametric_2012,
	title = {{MissForest}—non-parametric missing value imputation for mixed-type data},
	volume = {28},
	issn = {1367-4803},
	url = {http://dx.doi.org/10.1093/bioinformatics/btr597},
	abstract = {Motivation: Modern data acquisition based on high-throughput technology is often facing the problem of missing data. Algorithms commonly used in the analysis of such large-scale data often depend on a complete set. Missing value imputation offers a solution to this problem. However, the majority of available imputation methods are restricted to one type of variable only: continuous or categorical. For mixed-type data, the different types are usually handled separately. Therefore, these methods ignore possible relations between variable types. We propose a non-parametric method which can cope with different types of variables simultaneously.Results: We compare several state of the art methods for the imputation of missing values. We propose and evaluate an iterative imputation method (missForest) based on a random forest. By averaging over many unpruned classification or regression trees, random forest intrinsically constitutes a multiple imputation scheme. Using the built-in out-of-bag error estimates of random forest, we are able to estimate the imputation error without the need of a test set. Evaluation is performed on multiple datasets coming from a diverse selection of biological fields with artificially introduced missing values ranging from 10\% to 30\%. We show that missForest can successfully handle missing values, particularly in datasets including different types of variables. In our comparative study, missForest outperforms other methods of imputation especially in data settings where complex interactions and non-linear relations are suspected. The out-of-bag imputation error estimates of missForest prove to be adequate in all settings. Additionally, missForest exhibits attractive computational efficiency and can cope with high-dimensional data.Availability: The ℝ package missForest is freely available from http://stat.ethz.ch/CRAN/.Contact:stekhoven@stat.math.ethz.ch; buhlmann@stat.math.ethz.ch},
	number = {1},
	journal = {Bioinformatics},
	author = {Stekhoven, Daniel J and Bühlmann, Peter},
	month = jan,
	year = {2012},
	pages = {112--118},
}

@article{hormozdiari_memory_2015,
	title = {Memory efficient assembly of human genome},
	volume = {13},
	issn = {0219-7200},
	url = {http://www.worldscientific.com/doi/abs/10.1142/S0219720015500080},
	doi = {10.1142/S0219720015500080},
	abstract = {The ability to detect the genetic variations between two individuals is an essential component for genetic studies. In these studies, obtaining the genome sequence of both individuals is the first step toward variation detection problem. The emergence of high-throughput sequencing (HTS) technology has made DNA sequencing practical, and is widely used by diagnosticians to increase their knowledge about the casual factor in genetic related diseases. As HTS advances, more data are generated every day than the amount that scientists can process. Genome assembly is one of the existing methods to tackle the variation detection problem. The de Bruijn graph formulation of the assembly problem is widely used in the field. Furthermore, it is the only method which can assemble any genome in linear time. However, it requires an enormous amount of memory in order to assemble any mammalian size genome. The high demands of sequencing more individuals and the urge to assemble them are the driving forces for a memory effi...},
	number = {02},
	urldate = {2017-04-17},
	journal = {Journal of Bioinformatics and Computational Biology},
	author = {Hormozdiari, Farhad and Eskin, Eleazar},
	month = apr,
	year = {2015},
	note = {Publisher:  Imperial College Press},
	keywords = {De Bruijn graph, Genome assembly, high-throughput sequencing, local assembly},
	pages = {1550008},
}

@incollection{el_amine_lazouni_machine_2013,
	address = {Cham},
	title = {Machine {Learning} {Tool} for {Automatic} {ASA} {Detection}},
	isbn = {978-3-319-00560-7},
	url = {https://doi.org/10.1007/978-3-319-00560-7_5},
	abstract = {The application of machine learning tools has shown its advantages in medical aided decision. This paper presents the implementation of three supervised learning algorithms: the C4.5 decision tree classifier, the Support Vector Machines (SVM) and the Multilayer Perceptron MLP’s in MATLAB environment, on the preoperative assessment database. The classification models were trained using a new database collected from 898 patients, each of whom being represented by 17 features and included in one among 4 classes. The patients in this database were selected from different private clinics and hospitals of western Algeria.In this paper, the proposed system is devoted to the automatic detection of some typical features corresponding to the American Society of Anesthesiologists sores (ASA scores). These characteristics are widely used by all Doctors Specialized in Anesthesia (DSA’s) in pre-anesthesia examinations. Moreover, the robustness of our system was evaluated using a 10-fold cross-validation method and the results of the three proposed classifiers were compared.},
	publisher = {Springer International Publishing},
	author = {El Amine Lazouni, Mohammed and El Habib Daho, Mostafa and Settouti, Nesma and Chikh, Mohammed Amine and Mahmoudi, Saïd},
	editor = {Amine, Abdelmalek and Otmane, Ait Mohamed and Bellatreche, Ladjel},
	year = {2013},
	doi = {10.1007/978-3-319-00560-7_5},
	pages = {9--16},
}

@article{libbrecht_machine_2015,
	title = {Machine learning applications in genetics and genomics},
	volume = {16},
	issn = {1471-0056},
	url = {http://dx.doi.org/10.1038/nrg3920},
	abstract = {The field of machine learning, which aims to develop computer algorithms that improve with experience, holds promise to enable computers to assist humans in the analysis of large, complex data sets. Here, we provide an overview of machine learning applications for the analysis of genome sequencing data sets, including the annotation of sequence elements and epigenetic, proteomic or metabolomic data. We present considerations and recurrent challenges in the application of supervised, semi-supervised and unsupervised machine learning methods, as well as of generative and discriminative modelling approaches. We provide general guidelines to assist in the selection of these machine learning methods and their practical application for the analysis of genetic and genomic data sets.},
	number = {6},
	journal = {Nature Reviews Genetics},
	author = {Libbrecht, Maxwell W and Noble, William Stafford},
	month = jun,
	year = {2015},
	note = {Publisher: Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	pages = {321--332},
}

@article{gusev_low-pass_2011,
	title = {Low-pass {Genomewide} {Sequencing} and {Variant} {Imputation} {Using} {Identity}-by-descent in an {Isolated} {Human} {Population}},
	url = {http://arxiv.org/abs/1102.3720},
	abstract = {Whole-genome sequencing in an isolated population with few founders directly ascertains variants from the population bottleneck that may be rare elsewhere. In such populations, shared haplotypes allow imputation of variants in unsequenced samples without resorting to statistical methods, as in studies of outbred cohorts. We focus on an isolated population cohort from the Pacific Island of Kosrae, Micronesia, where we previously collected SNP array and rich phenotype data for the majority of the population. We report identification of long regions with haplotypes co-inherited between pairs of individuals and methodology to leverage such shared genetic content for imputation. Our estimates show that sequencing as few as 40 personal genomes allows for imputation in up to 60\% of the 3,000-person cohort at the average locus. We ascertained a pilot data-set of whole-genome sequences from seven Kosraean individuals, with average 5X coverage. This dataset identified 5,735,306 unique sites of which 1,212,831 were previously unknown. Additionally, these Kosraen variants are unusually enriched for alleles that are rare in other populations when compared to geographic neighbors. We were able to use the presence of shared haplotypes between the seven individuals to estimate imputation accuracy of known and novel variants and achieved levels of 99.6\% and 97.3\%, respectively. This study presents the first whole-genome analysis of a homogenous isolate population with emphasis on rare variant inference.},
	urldate = {2017-06-12},
	author = {Gusev, A and Shah, MJ and Kenny, EE and Ramachandran, A and Lowe, JK and Salit, J and Lee, CC and Levandowsky, EC and Weaver, TN and Doan, QC and Peckham, HE and McLaughlin, SF and Lyons, MR and Sheth, VN and Stoffel, M and De La Vega, FM and Friedman, JM and Breslow, JL and Pe'er, I},
	month = feb,
	year = {2011},
	note = {arXiv: 1102.3720},
}

@article{doi:10.1093/bib/bbw020,
	title = {A review of bioinformatic pipeline frameworks},
	volume = {18},
	url = {+},
	doi = {10.1093/bib/bbw020},
	number = {3},
	journal = {Briefings in Bioinformatics},
	author = {Leipzig, Jeremy},
	year = {2017},
	pages = {530},
}

@inproceedings{ito_power-efficient_2016,
	title = {A power-efficient {FPGA} accelerator: {Systolic} array with cache-coherent interface for pair-{HMM} algorithm},
	isbn = {VO -},
	doi = {10.1109/CoolChips.2016.7503681},
	abstract = {A systolic array is known as a parallel hardware architecture applicable to a wide range of applications. Naive implementations, however, can lead to inefficient resource usage and low power performance. In this paper, we discuss two techniques for improving the hardware resource usage: flexible multi-threading and dummy data padding. The design was implemented to accelerate a pair-HMM algorithm on an FPGA with the IBM POWER8 CAPI (Coherent Accelerator Processor Interface) feature. The CAPI feature simplifies the software design for driving the FPGA accelerator. Our experimental result indicates that the implemented FPGA accelerator executing the pair-HMM algorithm achieves 33x higher power performance than a POWER8 processor chip executing the same algorithm.},
	booktitle = {2016 {IEEE} {Symposium} in {Low}-{Power} and {High}-{Speed} {Chips} ({COOL} {CHIPS} {XIX})},
	author = {Ito, M and Ohara, M},
	year = {2016},
	keywords = {Acceleration, FPGA, FPGA accelerator, Field programmable gate arrays, Hidden Markov models, IBM POWER8 CAPI, accelerator, cache storage, cache-coherent interface, coherent accelerator processor interface, data handling, dummy data padding, field programmable gate array, field programmable gate arrays, multi-threading, multithreading, pair-HMM, pair-HMM algorithm, parallel hardware architecture, software design, software engineering, systolic array, systolic arrays, user interfaces},
	pages = {1--3},
}

@article{guo_novel_2017,
	title = {A novel k-mer set memory ({KSM}) motif representation improves regulatory variant prediction},
	url = {http://biorxiv.org/content/early/2017/06/26/130815.abstract},
	abstract = {The representation and discovery of transcription factor (TF) sequence binding specificities is critical for understanding gene regulatory networks and interpreting the impact of disease-associated non-coding genetic variants. We present a novel TF binding motif representation, the K-mer Set Memory (KSM), which consists of a set of aligned k-mers that are over-represented at TF binding sites, and a new method called KMAC for de novo discovery of KSMs. We find that KSMs more accurately predict in vivo binding sites than position weight matrix models (PWMs) and other more complex motif models across a large set of ChIP-seq experiments. KMAC also identifies correct motifs in more experiments than four state-of-the-art motif discovery methods. In addition, KSM derived features outperform both PWM and deep learning model derived sequence features in predicting differential regulatory activities of expression quantitative trait loci (eQTL) alleles. Finally, we have applied KMAC to 1488 ENCODE TF ChIP-seq datasets and created a public resource of KSM and PWM motifs. We expect that the KSM representation and KMAC method will be valuable in characterizing TF binding specificities and in interpreting the effects of non-coding genetic variations.},
	journal = {bioRxiv},
	author = {Guo, Yuchun and Tian, Kevin and Zeng, Haoyang and Guo, Xiaoyun and Gifford, David K},
	month = jan,
	year = {2017},
}

@inproceedings{chen_novel_2015,
	title = {A novel high-throughput acceleration engine for read alignment},
	isbn = {978-1-4799-9969-9},
	url = {http://ieeexplore.ieee.org/document/7160071/},
	doi = {10.1109/FCCM.2015.27},
	abstract = {The Smith-Waterman (S-W) algorithm is widely adopted by the state-of-the-art DNA sequence aligners. Existing wave front-based methods ignored the fact that the S-W algorithm is fed with significantly varied-size inputs in modern aligners, in which the S-W algorithm is further optimized by exerting extensive pruning. In this paper, we propose an architecture, tailored for varied input sizes as well as harnessing software pruning strategies, to accelerate S-W. Our implementation demonstrates a 26.4x speedup over a 24-thread Intel Has well Xeon server, and outperforms wave front-based implementations by up to 6x with the same FPGA resource.},
	urldate = {2017-04-18},
	booktitle = {Proceedings - 2015 {IEEE} 23rd {Annual} {International} {Symposium} on {Field}-{Programmable} {Custom} {Computing} {Machines}, {FCCM} 2015},
	publisher = {IEEE},
	author = {Chen, Yu Ting and Cong, Jason and Lei, Jie and Wei, Peng},
	month = may,
	year = {2015},
	note = {ISSN: 0278-0070},
	keywords = {FPGA, HLS, Multilevel scheduling, Read alignment, Smith-Waterman},
	pages = {199--202},
}

@article{hormozdiari_colocalization_2017,
	title = {Colocalization of {GWAS} and {eQTL} {Signals} {Detects} {Target} {Genes}},
	volume = {99},
	issn = {0002-9297},
	url = {http://dx.doi.org/10.1016/j.ajhg.2016.10.003},
	doi = {10.1016/j.ajhg.2016.10.003},
	number = {6},
	journal = {The American Journal of Human Genetics},
	author = {Hormozdiari, Farhad and van de Bunt, Martijn and Segrè, Ayellet V. and Li, Xiao and Joo, Jong Wha J. and Bilow, Michael and Sul, Jae Hoon and Sankararaman, Sriram and Pasaniuc, Bogdan and Eskin, Eleazar},
	month = apr,
	year = {2017},
	note = {Publisher: Elsevier},
	pages = {1245--1260},
}

@article{sun_imputing_2008,
	title = {Imputing missing genotypic data of single-nucleotide polymorphisms using neural networks},
	volume = {16},
	issn = {1018-4813},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/18197192},
	doi = {10.1038/sj.ejhg.5201988},
	abstract = {With advances in high-throughput single-nucleotide polymorphism (SNP) genotyping, the amount of genotype data available for genetic studies is steadily increasing, and with it comes new abilities to study multigene interactions as well as to develop higher dimensional genetic models that more closely represent the polygenic nature of common disease risk. The combined impact of even small amounts of missing data on a multi-SNP analysis may be considerable. In this study, we present a neural network method for imputing missing SNP genotype data. We compared its imputation accuracy with fastPHASE and an expectation-maximization algorithm implemented in HelixTree. In a simulation data set of 1000 SNPs and 1000 subjects, 1, 5 and 10\% of genotypes were randomly masked. Four levels of linkage disequilibrium (LD), LD R2{\textless}0.2, R2{\textless}0.5, R2{\textless}0.8 and no LD threshold, were examined to evaluate the impact of LD on imputation accuracy. All three methods are capable of imputing most missing genotypes accurately (accuracy {\textgreater}86\%). The neural network method accurately predicted 92.0-95.9\% of the missing genotypes. In a real data set comparison with 419 subjects and 126 SNPs from chromosome 2, the neural network method achieves the highest imputation accuracies {\textgreater}83.1\% with missing rate from 1 to 5\%. Using 90 HapMap subjects with 1962 SNPs, fastPHASE had the highest accuracy ( approximately 97\%) while the other two methods had {\textgreater}95\% accuracy. These results indicate that the neural network model is an accurate and convenient tool, requiring minimal parameter tuning for SNP data recovery, and provides a valuable alternative to usual complete-case analysis.},
	number = {4},
	urldate = {2017-05-03},
	journal = {European Journal of Human Genetics},
	author = {Sun, Yan V and Kardia, Sharon L R},
	month = apr,
	year = {2008},
	pmid = {18197192},
	pages = {487--495},
}

@article{kichaev_integrating_2014,
	title = {Integrating {Functional} {Data} to {Prioritize} {Causal} {Variants} in {Statistical} {Fine}-{Mapping} {Studies}},
	volume = {10},
	issn = {1553-7404},
	url = {http://dx.plos.org/10.1371/journal.pgen.1004722},
	doi = {10.1371/journal.pgen.1004722},
	number = {10},
	urldate = {2017-04-17},
	journal = {PLoS Genetics},
	author = {Kichaev, Gleb and Yang, Wen-Yun and Lindstrom, Sara and Hormozdiari, Farhad and Eskin, Eleazar and Price, Alkes L. and Kraft, Peter and Pasaniuc, Bogdan},
	editor = {Di Rienzo, Anna},
	month = oct,
	year = {2014},
	note = {Publisher: Public Library of Science},
	pages = {e1004722},
}

@article{kannry_integration_2013,
	title = {Integration of {Genomics} into the {Electronic} {Health} {Record}: {Mapping} {Terra} {Incognita}},
	volume = {15},
	issn = {1098-3600},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4157459/},
	doi = {10.1038/gim.2013.102},
	abstract = {Successfully realizing the vision of genomic medicine will require management of large amounts of complex data. The electronic health record (EHR) is destined to play a critical role in the translation of genomic information into clinical care. The papers in this special issue explore the challenges associated with the implementation of genomics in the EHR. The proposed solutions are meant to provide guidance for those responsible for moving genomics into the clinic.},
	number = {10},
	journal = {Genetics in medicine : official journal of the American College of Medical Genetics},
	author = {Kannry, Joseph M and Williams, Marc S},
	month = oct,
	year = {2013},
	pages = {757--760},
}

@article{gusev_integrative_2016,
	title = {Integrative approaches for large-scale transcriptome-wide association studies},
	volume = {48},
	issn = {1061-4036},
	url = {http://dx.doi.org/10.1038/ng.3506},
	abstract = {Many genetic variants influence complex traits by modulating gene expression, thus altering the abundance of one or multiple proteins. Here we introduce a powerful strategy that integrates gene expression measurements with summary association statistics from large-scale genome-wide association studies (GWAS) to identify genes whose cis-regulated expression is associated with complex traits. We leverage expression imputation from genetic data to perform a transcriptome-wide association study (TWAS) to identify significant expression-trait associations. We applied our approaches to expression data from blood and adipose tissue measured in [sim]3,000 individuals overall. We imputed gene expression into GWAS data from over 900,000 phenotype measurements to identify 69 new genes significantly associated with obesity-related traits (BMI, lipids and height). Many of these genes are associated with relevant phenotypes in the Hybrid Mouse Diversity Panel. Our results showcase the power of integrating genotype, gene expression and phenotype to gain insights into the genetic basis of complex traits.},
	number = {3},
	journal = {Nat Genet},
	author = {Gusev, Alexander and Ko, Arthur and Shi, Huwenbo and Bhatia, Gaurav and Chung, Wonil and Penninx, Brenda W J H and Jansen, Rick and de Geus, Eco J C and Boomsma, Dorret I and Wright, Fred A and Sullivan, Patrick F and Nikkola, Elina and Alvarez, Marcus and Civelek, Mete and Lusis, Aldons J and Lehtimaki, Terho and Raitoharju, Emma and Kahonen, Mika and Seppala, Ilkka and Raitakari, Olli T and Kuusisto, Johanna and Laakso, Markku and Price, Alkes L and Pajukanta, Paivi and Pasaniuc, Bogdan},
	month = mar,
	year = {2016},
	note = {Publisher: Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	pages = {245--252},
}

@inproceedings{cong_large_1997,
	title = {Large scale circuit partitioning with loose/stable net removal and signal flow based clustering},
	isbn = {0-8186-8200-0},
	url = {http://ieeexplore.ieee.org/document/643573/},
	doi = {10.1109/ICCAD.1997.643573},
	urldate = {2017-04-10},
	booktitle = {Proceedings of {IEEE} {International} {Conference} on {Computer} {Aided} {Design} ({ICCAD}) {ICCAD}-97},
	publisher = {IEEE},
	author = {{Cong} and {Li} and {Sung Kyu Lim} and {Shibuya} and {Dongmin Xu}},
	year = {1997},
	pages = {441--446},
}

@article{pivovarov_learning_2015,
	title = {Learning probabilistic phenotypes from heterogeneous {EHR} data},
	volume = {58},
	issn = {15320464},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1532046415002233},
	doi = {10.1016/j.jbi.2015.10.001},
	urldate = {2017-07-06},
	journal = {Journal of Biomedical Informatics},
	author = {Pivovarov, Rimma and Perotte, Adler J. and Grave, Edouard and Angiolillo, John and Wiggins, Chris H. and Elhadad, Noémie},
	month = dec,
	year = {2015},
	pages = {156--165},
}

@article{he_learning_2009,
	title = {Learning from {Imbalanced} {Data}},
	volume = {21},
	issn = {1041-4347 VO - 21},
	doi = {10.1109/TKDE.2008.239},
	number = {9},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {He, H and Garcia, E A},
	year = {2009},
	keywords = {Imbalanced learning, active learning, assessment metrics., classification, complex systems, cost-sensitive learning, data availability, data engineering, data mining, decision making, imbalanced data, kernel-based learning, knowledge discovery, large-scale systems, learning, learning (artificial intelligence), networked systems, sampling methods},
	pages = {1263--1284},
}

@article{doi:10.1093/jamia/ocy009,
	title = {Interaction patterns of trauma providers are associated with length of stay},
	url = {+},
	doi = {10.1093/jamia/ocy009},
	journal = {Journal of the American Medical Informatics Association},
	author = {Chen, You and Patel, Mayur B and McNaughton, Candace D and Malin, Bradley A},
	year = {2018},
	pages = {ocy009},
}

@article{mancuso_integrating_2017,
	title = {Integrating {Gene} {Expression} with {Summary} {Association} {Statistics} to {Identify} {Genes} {Associated} with 30 {Complex} {Traits}},
	volume = {100},
	issn = {00029297},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/28238358},
	doi = {10.1016/j.ajhg.2017.01.031},
	abstract = {Although genome-wide association studies (GWASs) have identified thousands of risk loci for many complex traits and diseases, the causal variants and genes at these loci remain largely unknown. Here, we introduce a method for estimating the local genetic correlation between gene expression and a complex trait and utilize it to estimate the genetic correlation due to predicted expression between pairs of traits. We integrated gene expression measurements from 45 expression panels with summary GWAS data to perform 30 multi-tissue transcriptome-wide association studies (TWASs). We identified 1,196 genes whose expression is associated with these traits; of these, 168 reside more than 0.5 Mb away from any previously reported GWAS significant variant. We then used our approach to find 43 pairs of traits with significant genetic correlation at the level of predicted expression; of these, eight were not found through genetic correlation at the SNP level. Finally, we used bi-directional regression to find evidence that BMI causally influences triglyceride levels and that triglyceride levels causally influence low-density lipoprotein. Together, our results provide insight into the role of gene expression in the susceptibility of complex traits and diseases.},
	number = {3},
	urldate = {2017-07-10},
	journal = {The American Journal of Human Genetics},
	author = {Mancuso, Nicholas and Shi, Huwenbo and Goddard, Pagé and Kichaev, Gleb and Gusev, Alexander and Pasaniuc, Bogdan},
	month = mar,
	year = {2017},
	pmid = {28238358},
	keywords = {complex disease, complex trait, expression quantitative trait loci (eQTLs), genetic correlation, genetic covariance, genome-wide association study (GWAS), susceptibility gene, transcriptome-wide association study (TWAS)},
	pages = {473--487},
}

@article{butler_integrating_2018,
	title = {Integrating single-cell transcriptomic data across different conditions, technologies, and species},
	volume = {36},
	url = {http://dx.doi.org/10.1038/nbt.4096},
	journal = {Nature Biotechnology},
	author = {Butler, Andrew and Hoffman, Paul and Smibert, Peter and Papalexi, Efthymia and Satija, Rahul},
	month = apr,
	year = {2018},
	note = {Publisher: Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	pages = {411},
}

@article{warner_integrating_2016,
	title = {Integrating cancer genomic data into electronic health records},
	volume = {8},
	issn = {1756-994X},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5081968/},
	doi = {10.1186/s13073-016-0371-3},
	abstract = {The rise of genomically targeted therapies and immunotherapy has revolutionized the practice of oncology in the last 10–15 years. At the same time, new technologies and the electronic health record (EHR) in particular have permeated the oncology clinic. Initially designed as billing and clinical documentation systems, EHR systems have not anticipated the complexity and variety of genomic information that needs to be reviewed, interpreted, and acted upon on a daily basis. Improved integration of cancer genomic data with EHR systems will help guide clinician decision making, support secondary uses, and ultimately improve patient care within oncology clinics. Some of the key factors relating to the challenge of integrating cancer genomic data into EHRs include: the bioinformatics pipelines that translate raw genomic data into meaningful, actionable results; the role of human curation in the interpretation of variant calls; and the need for consistent standards with regard to genomic and clinical data. Several emerging paradigms for integration are discussed in this review, including: non-standardized efforts between individual institutions and genomic testing laboratories; “middleware” products that portray genomic information, albeit outside of the clinical workflow; and application programming interfaces that have the potential to work within clinical workflow. The critical need for clinical-genomic knowledge bases, which can be independent or integrated into the aforementioned solutions, is also discussed. ELECTRONIC SUPPLEMENTARY MATERIAL: The online version of this article (doi:10.1186/s13073-016-0371-3) contains supplementary material, which is available to authorized users.},
	journal = {Genome Medicine},
	author = {Warner, Jeremy L and Jain, Sandeep K and Levy, Mia A},
	month = oct,
	year = {2016},
	note = {Publisher: BioMed Central
Place: London},
	pages = {113},
}

@article{li_improving_2011,
	title = {Improving {SNP} discovery by base alignment quality},
	volume = {27},
	issn = {1367-4803},
	url = {http://dx.doi.org/10.1093/bioinformatics/btr076},
	abstract = {Summary: I propose a new application of profile Hidden Markov Models in the area of SNP discovery from resequencing data, to greatly reduce false SNP calls caused by misalignments around insertions and deletions (indels). The central concept is per-Base Alignment Quality, which accurately measures the probability of a read base being wrongly aligned. The effectiveness of BAQ has been positively confirmed on large datasets by the 1000 Genomes Project analysis subgroup.Availability:http://samtools.sourceforge.netContact:hengli@broadinstitute.org},
	number = {8},
	journal = {Bioinformatics},
	author = {Li, Heng},
	month = apr,
	year = {2011},
	pages = {1157--1158},
}

@article{browning_improving_2013,
	title = {Improving the {Accuracy} and {Efficiency} of {Identity}-by-{Descent} {Detection} in {Population} {Data}},
	volume = {194},
	url = {http://www.genetics.org/content/194/2/459.abstract},
	abstract = {Segments of indentity-by-descent (IBD) detected from high-density genetic data are useful for many applications, including long-range phase determination, phasing family data, imputation, IBD mapping, and heritability analysis in founder populations. We present Refined IBD, a new method for IBD segment detection. Refined IBD achieves both computational efficiency and highly accurate IBD segment reporting by searching for IBD in two steps. The first step (identification) uses the GERMLINE algorithm to find shared haplotypes exceeding a length threshold. The second step (refinement) evaluates candidate segments with a probabilistic approach to assess the evidence for IBD. Like GERMLINE, Refined IBD allows for IBD reporting on a haplotype level, which facilitates determination of multi-individual IBD and allows for haplotype-based downstream analyses. To investigate the properties of Refined IBD, we simulate SNP data from a model with recent superexponential population growth that is designed to match United Kingdom data. The simulation results show that Refined IBD achieves a better power/accuracy profile than fastIBD or GERMLINE. We find that a single run of Refined IBD achieves greater power than 10 runs of fastIBD. We also apply Refined IBD to SNP data for samples from the United Kingdom and from Northern Finland and describe the IBD sharing in these data sets. Refined IBD is powerful, highly accurate, and easy to use and is implemented in Beagle version 4.},
	number = {2},
	journal = {Genetics},
	author = {Browning, Brian L and Browning, Sharon R},
	month = jun,
	year = {2013},
	keywords = {IBD},
	pages = {459 LP -- 471},
}

@article{salimans_improved_nodate,
	title = {Improved {Techniques} for {Training} {GANs}},
	abstract = {We present a variety of new architectural features and training procedures that we apply to the generative adversarial networks (GANs) framework. Using our new techniques, we achieve state-of-the-art results in semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generated images are of high quality as con-firmed by a visual Turing test: our model generates MNIST samples that humans cannot distinguish from real data, and CIFAR-10 samples that yield a human error rate of 21.3\%. We also present ImageNet samples with unprecedented resolution and show that our methods enable the model to learn recognizable features of ImageNet classes.},
	urldate = {2017-08-18},
	author = {Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
}

@article{doi:10.1097/ALN.0b013e31828e12b3,
	title = {Impact of {Present}-on-admission {Indicators} on {Risk}-adjusted {Hospital} {Mortality} {Measurement}},
	volume = {118},
	url = {+},
	doi = {10.1097/ALN.0b013e31828e12b3},
	number = {6},
	journal = {Anesthesiology},
	author = {Dalton, Jarrod E and Glance, Laurent G and Mascha, Edward J and Ehrlinger, John and Chamoun, Nassib and Sessler, Daniel I},
	year = {2013},
	pages = {1298--1306},
}

@article{lemaitre2017imbalanced,
	title = {Imbalanced-learn: {A} python toolbox to tackle the curse of imbalanced datasets in machine learning},
	volume = {18},
	number = {17},
	journal = {Journal of Machine Learning Research},
	author = {Lemaitre, Guillaume and Nogueira, Fernando and Aridas, Christos K},
	year = {2017},
	pages = {1--5},
}

@article{hormozdiari_identifying_2014,
	title = {Identifying {Causal} {Variants} at {Loci} with {Multiple} {Signals} of {Association}},
	volume = {198},
	url = {http://www.genetics.org/content/198/2/497.abstract},
	abstract = {Although genome-wide association studies have successfully identified thousands of risk loci for complex traits, only a handful of the biologically causal variants, responsible for association at these loci, have been successfully identified. Current statistical methods for identifying causal variants at risk loci either use the strength of the association signal in an iterative conditioning framework or estimate probabilities for variants to be causal. A main drawback of existing methods is that they rely on the simplifying assumption of a single causal variant at each risk locus, which is typically invalid at many risk loci. In this work, we propose a new statistical framework that allows for the possibility of an arbitrary number of causal variants when estimating the posterior probability of a variant being causal. A direct benefit of our approach is that we predict a set of variants for each locus that under reasonable assumptions will contain all of the true causal variants with a high confidence level (e.g., 95\%) even when the locus contains multiple causal variants. We use simulations to show that our approach provides 20–50\% improvement in our ability to identify the causal variants compared to the existing methods at loci harboring multiple causal variants. We validate our approach using empirical data from an expression QTL study of CHI3L2 to identify new causal variants that affect gene expression at this locus. CAVIAR is publicly available online at http://genetics.cs.ucla.edu/caviar/.},
	number = {2},
	journal = {Genetics},
	author = {Hormozdiari, Farhad and Kostem, Emrah and Kang, Eun Yong and Pasaniuc, Bogdan and Eskin, Eleazar},
	month = oct,
	year = {2014},
	keywords = {CAVIAR},
	pages = {497 LP -- 508},
}

@article{hormozdiari_identification_2015,
	title = {Identification of causal genes for complex traits},
	volume = {31},
	issn = {14602059},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4542778/},
	doi = {10.1093/bioinformatics/btv240},
	abstract = {Motivation: Although genome-wide association studies (GWAS) have identified thousands of variants associated with common diseases and complex traits, only a handful of these variants are validated to be causal. We consider causal variants' as variants which are responsible for the association signal at a locus. As opposed to association studies that benefit from linkage disequilibrium (LD), the main challenge in identifying causal variants at associated loci lies in distinguishing among the many closely correlated variants due to LD. This is particularly important for model organisms such as inbred mice, where LD extends much further than in human populations, resulting in large stretches of the genome with significantly associated variants. Furthermore, these model organisms are highly structured and require correction for population structure to remove potential spurious associations. Results: In this work, we propose CAVIAR-Gene (CAusal Variants Identification in Associated Regions), a novel method that is able to operate across large LD regions of the genome while also correcting for population structure. A key feature of our approach is that it provides as output a minimally sized set of genes that captures the genes which harbor causal variants with probability \{rho\}. Through extensive simulations, we demonstrate that our method not only speeds up computation, but also have an average of 10\% higher recall rate compared with the existing approaches. We validate our method using a real mouse high-density lipoprotein data (HDL) and show that CAVIAR-Gene is able to identify Apoa2 (a gene known to harbor causal variants for HDL), while reducing the number of genes that need to be tested for functionality by a factor of 2. Availability and implementation: Software is freely available for download at genetics.cs.ucla.edu/caviar. Contact: eeskin@cs.ucla.edu},
	number = {12},
	journal = {Bioinformatics},
	author = {Hormozdiari, Farhad and Kichaev, Gleb and Yang, Wen-Yun and Pasaniuc, Bogdan and Eskin, Eleazar},
	month = jun,
	year = {2015},
	pmid = {26072484},
	note = {Publisher: Oxford University Press
ISBN: 13674811 (Electronic)},
	pages = {i206--i213},
}

@article{Rubinsteyn2017,
	title = {hammerlab/fancyimpute: {Version} 0.2.0},
	url = {https://zenodo.org/record/886614#.WtfmOC-ZNTY},
	doi = {10.5281/ZENODO.886614},
	urldate = {2018-04-18},
	author = {Rubinsteyn, Alex and Feldman, Sergey and O'Donnell, Tim and Beaulieu-Jones, Brett},
	month = sep,
	year = {2017},
}

@inproceedings{olson_hardware_2012,
	title = {Hardware {Acceleration} of {Short} {Read} {Mapping}},
	isbn = {978-1-4673-1605-7},
	url = {http://ieeexplore.ieee.org/document/6239809/},
	doi = {10.1109/FCCM.2012.36},
	urldate = {2017-04-18},
	booktitle = {2012 {IEEE} 20th {International} {Symposium} on {Field}-{Programmable} {Custom} {Computing} {Machines}},
	publisher = {IEEE},
	author = {Olson, Corey B. and Kim, Maria and Clauson, Cooper and Kogon, Boris and Ebeling, Carl and Hauck, Scott and Ruzzo, Walter L.},
	month = apr,
	year = {2012},
	pages = {161--168},
}

@article{klami_group_2015,
	title = {Group {Factor} {Analysis}},
	volume = {26},
	issn = {2162-237X VO - 26},
	doi = {10.1109/TNNLS.2014.2376974},
	number = {9},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Klami, A and Virtanen, S and Leppäaho, E and Kaski, S},
	year = {2015},
	keywords = {Analytical models, Bayes methods, Correlation, Data models, Factor analysis (FA), GFA, Load modeling, Noise, Probabilistic logic, canonical correlation analysis, correlation methods, data analysis, group factor analysis, higher level models, latent variable model, lower models, multiview learning, probabilistic algorithms, structural sparsity, structured sparsity, structured sparsity., variational inference},
	pages = {2136--2147},
}

@article{info:doi/10.2196/jmir.5870,
	title = {Guidelines for {Developing} and {Reporting} {Machine} {Learning} {Predictive} {Models} in {Biomedical} {Research}: {A} {Multidisciplinary} {View}},
	volume = {18},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/27986644},
	doi = {10.2196/jmir.5870},
	abstract = {Background: As more and more researchers are turning to big data for new opportunities of biomedical discoveries, machine learning models, as the backbone of big data analysis, are mentioned more often in biomedical journals. However, owing to the inherent complexity of machine learning methods, they are prone to misuse. Because of the flexibility in specifying machine learning models, the results are often insufficiently reported in research articles, hindering reliable assessment of model validity and consistent interpretation of model outputs. Objective: To attain a set of guidelines on the use of machine learning predictive models within clinical settings to make sure the models are correctly applied and sufficiently reported so that true discoveries can be distinguished from random coincidence. Methods: A multidisciplinary panel of machine learning experts, clinicians, and traditional statisticians were interviewed, using an iterative process in accordance with the Delphi method. Results: The process produced a set of guidelines that consists of (1) a list of reporting items to be included in a research article and (2) a set of practical sequential steps for developing predictive models. Conclusions: A set of guidelines was generated to enable correct application of machine learning models and consistent reporting of model specifications and results in biomedical research. We believe that such guidelines will accelerate the adoption of big data analysis, particularly with machine learning methods, in the biomedical research community.},
	number = {12},
	journal = {J Med Internet Res},
	author = {Luo, Wei and Phung, Dinh and Tran, Truyen and Gupta, Sunil and Rana, Santu and Karmakar, Chandan and Shilton, Alistair and Yearwood, John and Dimitrova, Nevenka and Ho, Bao Tu and Venkatesh, Svetha and Berk, Michael},
	month = dec,
	year = {2016},
	keywords = {clinical prediction rule, guideline, machine learning},
	pages = {e323},
}

@inproceedings{ahmed_heterogeneous_2015,
	title = {Heterogeneous hardware/software acceleration of the {BWA}-{MEM} {DNA} alignment algorithm},
	isbn = {VO -},
	doi = {10.1109/ICCAD.2015.7372576},
	abstract = {The fast decrease in cost of DNA sequencing has resulted in an enormous growth in available genome data, and hence led to an increasing demand for fast DNA analysis algorithms used for diagnostics of genetic disorders, such as cancer. One of the most computationally intensive steps in the analysis is represented by the DNA read alignment. In this paper, we present an accelerated version of BWA-MEM, one of the most popular read alignment algorithms, by implementing a heterogeneous hardware/software optimized version on the Convey HC2ex platform. A challenging factor of the BWA-MEM algorithm is the fact that it consists of not one, but three computationally intensive kernels: SMEM generation, suffix array lookup and local Smith-Waterman. Obtaining substantial speedup is hence contingent on accelerating all of these three kernels at once. The paper shows an architecture containing two hardware-accelerated kernels and one kernel optimized in software. The two hardware kernels of suffix array lookup and local Smith-Waterman are able to reach speedups of 2.8x and 5.7x, respectively. The software optimization of the SMEM generation kernel is able to achieve a speedup of 1.7x. This enables a total application acceleration of 2.6x compared to the original software version.},
	booktitle = {2015 {IEEE}/{ACM} {International} {Conference} on {Computer}-{Aided} {Design} ({ICCAD})},
	author = {Ahmed, N and Sima, V M and Houtgast, E and Bertels, K and Al-Ars, Z},
	year = {2015},
	keywords = {Acceleration, Arrays, BWA-MEM DNA alignment algorithm, Bioinformatics, DNA, DNA analysis algorithm, Genomics, HC2ex platform, SMEM generation, Software, Yttrium, biocomputing, diseases, genetic disorder diagnostics, heterogeneous hardware acceleration, heterogeneous software acceleration, local Smith-Waterman, medical computing, medical disorders, software optimization, suffix array lookup},
	pages = {240--246},
}

@article{decap_halvade:_2015,
	title = {Halvade: scalable sequence analysis with {MapReduce}},
	volume = {31},
	issn = {1367-4803},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/25819078},
	doi = {10.1093/bioinformatics/btv179},
	abstract = {MOTIVATION Post-sequencing DNA analysis typically consists of read mapping followed by variant calling. Especially for whole genome sequencing, this computational step is very time-consuming, even when using multithreading on a multi-core machine. RESULTS We present Halvade, a framework that enables sequencing pipelines to be executed in parallel on a multi-node and/or multi-core compute infrastructure in a highly efficient manner. As an example, a DNA sequencing analysis pipeline for variant calling has been implemented according to the GATK Best Practices recommendations, supporting both whole genome and whole exome sequencing. Using a 15-node computer cluster with 360 CPU cores in total, Halvade processes the NA12878 dataset (human, 100 bp paired-end reads, 50× coverage) in {\textless}3 h with very high parallel efficiency. Even on a single, multi-core machine, Halvade attains a significant speedup compared with running the individual tools with multithreading.},
	number = {15},
	urldate = {2017-04-23},
	journal = {Bioinformatics},
	author = {Decap, Dries and Reumers, Joke and Herzeel, Charlotte and Costanza, Pascal and Fostier, Jan},
	month = aug,
	year = {2015},
	pmid = {25819078},
	pages = {2482--2488},
}

@article{visscher_heritability_2008,
	title = {Heritability in the genomics era — concepts and misconceptions},
	volume = {9},
	issn = {1471-0056},
	url = {http://www.nature.com/doifinder/10.1038/nrg2322},
	doi = {10.1038/nrg2322},
	number = {4},
	urldate = {2017-05-09},
	journal = {Nature Reviews Genetics},
	author = {Visscher, Peter M. and Hill, William G. and Wray, Naomi R.},
	month = apr,
	year = {2008},
	note = {Publisher: Nature Publishing Group},
	pages = {255--266},
}

@inproceedings{chiang_hardware_2006,
	title = {Hardware {Accelerator} for {Genomic} {Sequence} {Alignment}},
	isbn = {1-4244-0032-5},
	url = {http://ieeexplore.ieee.org/document/4463122/},
	doi = {10.1109/IEMBS.2006.260286},
	urldate = {2017-04-18},
	booktitle = {2006 {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society}},
	publisher = {IEEE},
	author = {Chiang, Jason and Studniberg, Michael and Shaw, Jack and Seto, Stephen and Truong, Kevin},
	month = aug,
	year = {2006},
	pages = {5787--5789},
}

@article{Pearse2006,
	title = {Identification and characterisation of the high-risk surgical population in the {United} {Kingdom}},
	volume = {10},
	issn = {1364-8535},
	url = {https://doi.org/10.1186/cc4928},
	doi = {10.1186/cc4928},
	abstract = {Little is known about mortality rates following general surgical procedures in the United Kingdom. Deaths are most common in the 'high-risk' surgical population consisting mainly of older patients, with coexisting medical disease, who undergo major surgery. Only limited data are presently available to describe this population. The aim of the present study was to estimate the size of the high-risk general surgical population and to describe the outcome and intensive care unit (ICU) resource use.},
	number = {3},
	journal = {Critical Care},
	author = {Pearse, Rupert M and Harrison, David A and James, Philip and Watson, David and Hinds, Charles and Rhodes, Andrew and Grounds, R Michael and Bennett, E David},
	month = jun,
	year = {2006},
	pages = {R81},
}

@inproceedings{graves_hybrid_2013,
	title = {Hybrid speech recognition with {Deep} {Bidirectional} {LSTM}},
	isbn = {978-1-4799-2756-2},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.703.5980},
	doi = {10.1109/ASRU.2013.6707742},
	abstract = {Deep Bidirectional LSTM (DBLSTM) recurrent neural networks have recently been shown to give state-of-the-art performance on the TIMIT speech database. However, the results in that work relied on recurrent-neural-network-specific objective functions, which are difficult to integrate with existing large vocabulary speech recognition systems. This paper investigates the use of DBLSTM as an acoustic model in a standard neural network-HMM hybrid system. We find that a DBLSTM-HMM hybrid gives equally good results on TIMIT as the previous work. It also outperforms both GMM and deep network benchmarks on a subset of the Wall Street Journal corpus. However the improvement in word error rate over the deep network is modest, despite a great increase in framelevel accuracy. We conclude that the hybrid approach with DBLSTM appears to be well suited for tasks where acoustic modelling predominates. Further investigation needs to be conducted to understand how to better leverage the improvements in frame-level accuracy towards better word error rates.},
	urldate = {2017-10-25},
	booktitle = {2013 {IEEE} {Workshop} on {Automatic} {Speech} {Recognition} and {Understanding}, {ASRU} 2013 - {Proceedings}},
	author = {Graves, Alex and Jaitly, Navdeep and Mohamed, Abdel Rahman},
	year = {2013},
	keywords = {DBLSTM, HMM-RNN hybrid},
	pages = {273--278},
}

@article{pascanu_how_2013,
	title = {How to {Construct} {Deep} {Recurrent} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1312.6026},
	abstract = {In this paper, we explore different ways to extend a recurrent neural network (RNN) to a {\textbackslash}textit\{deep\} RNN. We start by arguing that the concept of depth in an RNN is not as clear as it is in feedforward neural networks. By carefully analyzing and understanding the architecture of an RNN, however, we find three points of an RNN which may be made deeper; (1) input-to-hidden function, (2) hidden-to-hidden transition and (3) hidden-to-output function. Based on this observation, we propose two novel architectures of a deep RNN which are orthogonal to an earlier attempt of stacking multiple recurrent layers to build a deep RNN (Schmidhuber, 1992; El Hihi and Bengio, 1996). We provide an alternative interpretation of these deep RNNs using a novel framework based on neural operators. The proposed deep RNNs are empirically evaluated on the tasks of polyphonic music prediction and language modeling. The experimental result supports our claim that the proposed deep RNNs benefit from the depth and outperform the conventional, shallow RNNs.},
	urldate = {2017-05-03},
	author = {Pascanu, Razvan and Gulcehre, Caglar and Cho, Kyunghyun and Bengio, Yoshua},
	month = dec,
	year = {2013},
	note = {arXiv: 1312.6026},
}

@article{hripcsak_high-fidelity_2017,
	title = {High-fidelity phenotyping: richness and freedom from bias},
	issn = {1067-5027},
	url = {http://academic.oup.com/jamia/article/doi/10.1093/jamia/ocx110/4484121/Highfidelity-phenotyping-richness-and-freedom-from},
	doi = {10.1093/jamia/ocx110},
	abstract = {Electronic health record phenotyping is the use of raw electronic health record data to assert characterizations about patients. Researchers have been doing it since the beginning of biomedical informatics, under different names. Phenotyping will benefit from an increasing focus on fidelity, both in the sense of increasing richness, such as measured levels, degree or severity, timing, probability, or conceptual relationships, and in the sense of reducing bias. Research agendas should shift from merely improving binary assignment to studying and improving richer representations. The field is actively researching new temporal directions and abstract representations, including deep learning. The field would benefit from research in nonlinear dynamics, in combining mechanistic models with empirical data, including data assimilation, and in topology. The health care process produces substantial bias, and studying that bias explicitly rather than treating it as merely another source of noise would facilitate addressing it.},
	urldate = {2017-10-24},
	journal = {Journal of the American Medical Informatics Association},
	author = {Hripcsak, George and Albers, David J},
	month = oct,
	year = {2017},
	pages = {ocx110--ocx110},
}

@inproceedings{Kannan:2017:HOD:3079856.3080245,
	address = {New York, NY, USA},
	title = {{HeteroOS}: {OS} {Design} for {Heterogeneous} {Memory} {Management} in {Datacenter}},
	isbn = {978-1-4503-4892-8},
	url = {http://doi.acm.org/10.1145/3079856.3080245},
	doi = {10.1145/3079856.3080245},
	booktitle = {Proceedings of the 44th {Annual} {International} {Symposium} on {Computer} {Architecture}},
	publisher = {ACM},
	author = {Kannan, Sudarsun and Gavrilovska, Ada and Gupta, Vishal and Schwan, Karsten},
	year = {2017},
	note = {Series Title: ISCA '17},
	keywords = {3D-stacked DRAM, Heterogeneous Memory, Hypervisor, Non-volatile memory, Operating Systems, Virtual Memory, Virtualization},
	pages = {521--534},
}

@inproceedings{huang_hardware_2017,
	address = {New York, New York, USA},
	title = {Hardware {Acceleration} of the {Pair}-{HMM} {Algorithm} for {DNA} {Variant} {Calling}},
	isbn = {978-1-4503-4354-1},
	url = {http://dl.acm.org/citation.cfm?doid=3020078.3021749},
	doi = {10.1145/3020078.3021749},
	urldate = {2017-04-18},
	booktitle = {Proceedings of the 2017 {ACM}/{SIGDA} {International} {Symposium} on {Field}-{Programmable} {Gate} {Arrays} - {FPGA} '17},
	publisher = {ACM Press},
	author = {Huang, Sitao and Manikandan, Gowthami Jayashri and Ramachandran, Anand and Rupnow, Kyle and Hwu, Wen-mei W. and Chen, Deming},
	year = {2017},
	keywords = {FPGA, PE ring, computational genomics, forward algorithm, hardware acceleration, pair-HMM},
	pages = {275--284},
}

@article{szegedy_going_nodate,
	title = {Going {Deeper} with {Convolutions}},
	abstract = {We propose a deep convolutional neural network ar-chitecture codenamed Inception that achieves the new state of the art for classification and detection in the Im-ageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the compu-tational budget constant. To optimize quality, the architec-tural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular in-carnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.},
	urldate = {2017-05-31},
	author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
}

@article{flint_genome-wide_2012,
	title = {Genome-wide association studies in mice},
	volume = {13},
	issn = {1471-0056},
	url = {http://www.nature.com/doifinder/10.1038/nrg3335},
	doi = {10.1038/nrg3335},
	number = {11},
	urldate = {2017-04-17},
	journal = {Nature Reviews Genetics},
	author = {Flint, Jonathan and Eskin, Eleazar},
	month = oct,
	year = {2012},
	note = {Publisher: Nature Publishing Group},
	pages = {807--817},
}

@article{goodfellow_generative_2014,
	title = {Generative {Adversarial} {Networks}},
	issn = {10495258},
	url = {http://arxiv.org/abs/1406.2661},
	doi = {10.1001/jamainternmed.2016.8245},
	abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
	urldate = {2017-08-12},
	journal = {arXiv preprint arXiv: …},
	author = {Goodfellow, Ij and Pouget-Abadie, Jean and Mirza, Mehdi},
	month = jun,
	year = {2014},
	pmid = {15040217},
	note = {arXiv: 1406.2661v1
ISBN: 1406.2661},
	pages = {1--9},
}

@article{mccarthy_genome-wide_2008,
	title = {Genome-wide association studies for complex traits: consensus, uncertainty and challenges},
	volume = {9},
	issn = {1471-0056},
	url = {http://www.nature.com/doifinder/10.1038/nrg2344},
	doi = {10.1038/nrg2344},
	number = {5},
	urldate = {2017-04-23},
	journal = {Nature Reviews Genetics},
	author = {McCarthy, Mark I. and Abecasis, Gonçalo R. and Cardon, Lon R. and Goldstein, David B. and Little, Julian and Ioannidis, John P. A. and Hirschhorn, Joel N.},
	month = may,
	year = {2008},
	note = {Publisher: Nature Publishing Group},
	pages = {356--369},
}

@article{sukhwani_fpga_2010,
	title = {{FPGA} acceleration of rigid-molecule docking codes},
	volume = {4},
	issn = {1751-8601},
	url = {http://digital-library.theiet.org/content/journals/10.1049/iet-cdt.2009.0013},
	doi = {10.1049/iet-cdt.2009.0013},
	number = {3},
	urldate = {2017-04-18},
	journal = {IET Computers \& Digital Techniques},
	author = {Sukhwani, B. and Herbordt, M.C.},
	month = may,
	year = {2010},
	pages = {184--195},
}

@inproceedings{Nguyen:2015:FCR:2694344.2694345,
	address = {New York, NY, USA},
	title = {{FACADE}: {A} {Compiler} and {Runtime} for ({Almost}) {Object}-{Bounded} {Big} {Data} {Applications}},
	isbn = {978-1-4503-2835-7},
	url = {http://doi.acm.org/10.1145/2694344.2694345},
	doi = {10.1145/2694344.2694345},
	booktitle = {Proceedings of the {Twentieth} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Nguyen, Khanh and Wang, Kai and Bu, Yingyi and Fang, Lu and Hu, Jianfei and Xu, Guoqing},
	year = {2015},
	note = {Series Title: ASPLOS '15},
	keywords = {big data applications, managed languages, memory management, performance optimization},
	pages = {675--690},
}

@article{visscher_five_2012,
	title = {Five years of {GWAS} discovery.},
	volume = {90},
	issn = {1537-6605},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/22243964},
	doi = {10.1016/j.ajhg.2011.11.029},
	abstract = {The past five years have seen many scientific and biological discoveries made through the experimental design of genome-wide association studies (GWASs). These studies were aimed at detecting variants at genomic loci that are associated with complex traits in the population and, in particular, at detecting associations between common single-nucleotide polymorphisms (SNPs) and common diseases such as heart disease, diabetes, auto-immune diseases, and psychiatric disorders. We start by giving a number of quotes from scientists and journalists about perceived problems with GWASs. We will then briefly give the history of GWASs and focus on the discoveries made through this experimental design, what those discoveries tell us and do not tell us about the genetics and biology of complex traits, and what immediate utility has come out of these studies. Rather than giving an exhaustive review of all reported findings for all diseases and other complex traits, we focus on the results for auto-immune diseases and metabolic diseases. We return to the perceived failure or disappointment about GWASs in the concluding section.},
	number = {1},
	urldate = {2017-04-23},
	journal = {American journal of human genetics},
	author = {Visscher, Peter M and Brown, Matthew A and McCarthy, Mark I and Yang, Jian},
	month = jan,
	year = {2012},
	pmid = {22243964},
	note = {Publisher: Elsevier},
	pages = {7--24},
}

@article{Lundberg2017,
	title = {Explainable machine learning predictions to help anesthesiologists prevent hypoxemia during surgery},
	url = {http://biorxiv.org/content/early/2017/10/21/206540.abstract},
	abstract = {Hypoxemia causes serious patient harm, and while anesthesiologists strive to avoid hypoxemia during surgery, anesthesiologists are not reliably able to predict which patients will have intraoperative hypoxemia. Using minute by minute EMR data from fifty thousand surgeries we developed and tested a machine learning based system called Prescience that predicts real-time hypoxemia risk and presents an explanation of factors contributing to that risk during general anesthesia. Prescience improved anesthesiologists\&\#039; performance when providing interpretable hypoxemia risks with contributing factors. The results suggest that if anesthesiologists currently anticipate 15\% of events, then with Prescience assistance they could anticipate 30\% of events or an estimated additional 2.4 million annually in the US, a large portion of which may be preventable because they are attributable to modifiable factors. The prediction explanations are broadly consistent with the literature and anesthesiologists\&\#039; prior knowledge. Prescience can also improve clinical understanding of hypoxemia risk during anesthesia by providing general insights into the exact changes in risk induced by certain patient or procedure characteristics. Making predictions of complex medical machine learning models (such as Prescience) interpretable has broad applicability to other data-driven prediction tasks in medicine.},
	journal = {bioRxiv},
	author = {Lundberg, Scott M and Nair, Bala and Vavilala, Monica S and Horibe, Mayumi and Eisses, Michael J and Adams, Trevor and Liston, David E and Low, Daniel King-Wai and Newman, Shu-Fang and Kim, Jerry and Lee, Su-In},
	month = jan,
	year = {2017},
}

@article{doi:10.1136/amiajnl-2012-001458,
	title = {Enhancing patient safety and quality of care by improving the usability of electronic health record systems: recommendations from {AMIA}},
	volume = {20},
	url = {+},
	doi = {10.1136/amiajnl-2012-001458},
	number = {e1},
	journal = {Journal of the American Medical Informatics Association},
	author = {Middleton, Blackford and Bloomrosen, Meryl and Dente, Mark A and Hashmat, Bill and Koppel, Ross and Overhage, J Marc and Payne, Thomas H and Rosenbloom, S Trent and Weaver, Charlotte and Zhang, Jiajie},
	year = {2013},
	pages = {e2--e8},
}

@article{Eskin:2015:DGI:2830674.2817827,
	title = {Discovering {Genes} {Involved} in {Disease} and the {Mystery} of {Missing} {Heritability}},
	volume = {58},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/2817827},
	doi = {10.1145/2817827},
	number = {10},
	journal = {Commun. ACM},
	author = {Eskin, Eleazar},
	month = sep,
	year = {2015},
	note = {Publisher: ACM
Place: New York, NY, USA},
	pages = {80--87},
}

@article{kang_discovering_2016,
	title = {Discovering {Single} {Nucleotide} {Polymorphisms} {Regulating} {Human} {Gene} {Expression} {Using} {Allele} {Specific} {Expression} from {RNA}-seq {Data}},
	volume = {204},
	url = {http://www.genetics.org/content/204/3/1057},
	number = {3},
	urldate = {2017-04-17},
	journal = {Genetics},
	author = {Kang, Eun Yong and Martin, Lisa J. and Mangul, Serghei and Isvilanonda, Warin and Zou, Jennifer and Ben-David, Eyal and Han, Buhm and Lusis, Aldons J. and Shifman, Sagiv and Eskin, Eleazar},
	year = {2016},
}

@phdthesis{van_der_maaten_dimensionality_2009,
	title = {Dimensionality {Reduction}: {A} {Comparative} {Review}},
	url = {http://www.uvt.nl/ticc},
	abstract = {In recent years, a variety of nonlinear dimensionality reduction techniques have been proposed that aim to address the limitations of traditional techniques such as PCA and classical scaling. The paper presents a review and systematic comparison of these techniques. The performances of the nonlinear techniques are investigated on artificial and natural tasks. The results of the experiments reveal that nonlinear tech-niques perform well on selected artificial tasks, but that this strong performance does not necessarily extend to real-world tasks. The paper explains these results by identi-fying weaknesses of current nonlinear techniques, and suggests how the performance of nonlinear dimensionality reduction techniques may be improved.},
	urldate = {2017-07-05},
	school = {Tilburg University},
	author = {Van Der Maaten, Laurens and Postma, Eric and Van Den Herik, Jaap},
	year = {2009},
	keywords = {CGSI},
}

@article{dalton_jarrod_e._development_2011,
	title = {Development and {Validation} of a {Risk} {Quantification} {Index} for 30-{Day} {Postoperative} {Mortality} and {Morbidity} in {Noncardiac} {Surgical} {Patients}},
	volume = {114},
	issn = {0003-3022},
	url = {http://dx.doi.org/10.1097/ALN.0b013e318219d5f9},
	number = {6},
	journal = {Anesthesiology},
	author = {Dalton Jarrod E., M A and Kurz Andrea, M D and Turan Alparslan, M D and Mascha Edward J., Ph.D. and Sessler Daniel I., M D and Saager Leif, M D},
	month = jun,
	year = {2011},
	pages = {1336--1344},
}

@article{Lee2018,
	title = {Development and {Validation} of a {Deep} {Neural} {Network} {Model} for {Prediction} of {Postoperative} {In}-hospital {Mortality}},
	issn = {0003-3022},
	url = {http://dx.doi.org/10.1097/ALN.0000000000002186},
	abstract = {Abstract Background: The authors tested the hypothesis that deep neural networks trained on intraoperative features can predict postoperative in-hospital mortality. Methods: The data used to train and validate the algorithm consists of 59,985 patients with 87 features extracted at the end of surgery. Feed-forward networks with a logistic output were trained using stochastic gradient descent with momentum. The deep neural networks were trained on 80\% of the data, with 20\% reserved for testing. The authors assessed improvement of the deep neural network by adding American Society of Anesthesiologists (ASA) Physical Status Classification and robustness of the deep neural network to a reduced feature set. The networks were then compared to ASA Physical Status, logistic regression, and other published clinical scores including the Surgical Apgar, Preoperative Score to Predict Postoperative Mortality, Risk Quantification Index, and the Risk Stratification Index. Results: In-hospital mortality in the training and test sets were 0.81\% and 0.73\%. The deep neural network with a reduced feature set and ASA Physical Status classification had the highest area under the receiver operating characteristics curve, 0.91 (95\% CI, 0.88 to 0.93). The highest logistic regression area under the curve was found with a reduced feature set and ASA Physical Status (0.90, 95\% CI, 0.87 to 0.93). The Risk Stratification Index had the highest area under the receiver operating characteristics curve, at 0.97 (95\% CI, 0.94 to 0.99). Conclusions: Deep neural networks can predict in-hospital mortality based on automatically extractable intraoperative data, but are not (yet) superior to existing methods.},
	journal = {Anesthesiology},
	author = {Lee, Christine K and Hofer, Ira and Gabel, Eilon and Baldi, Pierre and Cannesson, Maxime},
	month = apr,
	year = {2018},
}

@article{li_detecting_2014,
	title = {Detecting and correcting systematic variation in large-scale {RNA} sequencing data},
	volume = {32},
	url = {http://dx.doi.org/10.1038/nbt.3000},
	journal = {Nature Biotechnology},
	author = {Li, Sheng and Łabaj, Paweł P and Zumbo, Paul and Sykacek, Peter and Shi, Wei and Shi, Leming and Phan, John and Wu, Po-Yen and Wang, May and Wang, Charles and Thierry-Mieg, Danielle and Thierry-Mieg, Jean and Kreil, David P and Mason, Christopher E},
	month = aug,
	year = {2014},
	note = {Publisher: Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	pages = {888},
}

@article{boza_deepnano:_2016,
	title = {{DeepNano}: {Deep} {Recurrent} {Neural} {Networks} for {Base} {Calling} in {MinION} {Nanopore} {Reads}},
	url = {http://arxiv.org/abs/1603.09195},
	abstract = {Motivation: The MinION device by Oxford Nanopore is the first portable sequencing device. MinION is able to produce very long reads (reads over 100{\textasciitilde}kBp were reported), however it suffers from high sequencing error rate. In this paper, we show that the error rate can be reduced by improving the base calling process. Results: We present the first open-source DNA base caller for the MinION sequencing platform by Oxford Nanopore. By employing carefully crafted recurrent neural networks, our tool improves the base calling accuracy compared to the default base caller supplied by the manufacturer. This advance may further enhance applicability of MinION for genome sequencing and various clinical applications. Availability: DeepNano can be downloaded at http://compbio.fmph.uniba.sk/deepnano/. Contact: boza@fmph.uniba.sk},
	urldate = {2017-05-03},
	author = {Boža, Vladimír and Brejová, Broňa and Vinař, Tomáš},
	month = mar,
	year = {2016},
	note = {arXiv: 1603.09195},
	keywords = {Nanopore},
}

@article{park_deep_2015,
	title = {Deep learning for regulatory genomics},
	volume = {33},
	issn = {1087-0156},
	url = {http://www.nature.com/doifinder/10.1038/nbt.3313%5Cnhttp://www.nature.com/nbt/journal/v33/n8/full/nbt.3313.html?WT.ec_id=NBT-201508&spMailingID=49274718&spUserID=MTc3NDg2Mjc3OQS2&spJobID=741192642&spReportId=NzQxMTkyNjQyS0},
	doi = {10.1038/nbt.3313},
	abstract = {Computational modeling of DNA and RNA targets of regulatory proteins is improved by a deep-learning approach.},
	number = {8},
	journal = {Nature Biotechnology},
	author = {Park, Yongjin and Kellis, Manolis},
	month = aug,
	year = {2015},
	pmid = {26252139},
	note = {ISBN: 1087-0156},
	pages = {825--826},
}

@article{angermueller_deep_2016,
	title = {Deep learning for computational biology},
	volume = {12},
	issn = {1744-4292},
	url = {http://msb.embopress.org/lookup/doi/10.15252/msb.20156651},
	doi = {10.15252/msb.20156651},
	abstract = {Technological advances in genomics and imaging have led to an explosion of molecular and cellular profiling data from large numbers of samples. This rapid increase in biological data dimension and acquisition rate is challenging conventional analysis strategies. Modern machine learning methods, such as deep learning, promise to leverage very large data sets for finding hidden structure within them, and for making accurate predictions. In this review, we discuss applications of this new breed of analysis approaches in regulatory genomics and cellular imaging. We provide background of what deep learning is, and the settings in which it can be successfully applied to derive biological insights. In addition to presenting specific applications and providing tips for practical use, we also highlight possible pitfalls and limitations to guide computational biologists when and how to make the most use of this new technology.},
	number = {7},
	journal = {Molecular Systems Biology},
	author = {Angermueller, Christof and Pärnamaa, Tanel and Parts, Leopold and Stegle, Oliver},
	month = jul,
	year = {2016},
	pmid = {27474269},
	note = {ISBN: 17444292 (Electronic)},
	keywords = {15252, 20156651, accepted 6 june 2016, cellular imaging, computational biology, deep learning, doi 10, learning, machine, msb, received 11 april 2016, regulatory genomics, revised 2 june 2016},
	pages = {878},
}

@inproceedings{Lee:2010:DGV:1815961.1816021,
	address = {New York, NY, USA},
	title = {Debunking the {100X} {GPU} vs. {CPU} {Myth}: {An} {Evaluation} of {Throughput} {Computing} on {CPU} and {GPU}},
	isbn = {978-1-4503-0053-7},
	url = {http://doi.acm.org/10.1145/1815961.1816021},
	doi = {10.1145/1815961.1816021},
	booktitle = {Proceedings of the 37th {Annual} {International} {Symposium} on {Computer} {Architecture}},
	publisher = {ACM},
	author = {Lee, Victor W and Kim, Changkyu and Chhugani, Jatin and Deisher, Michael and Kim, Daehyun and Nguyen, Anthony D and Satish, Nadathur and Smelyanskiy, Mikhail and Chennupaty, Srinivas and Hammarlund, Per and Singhal, Ronak and Dubey, Pradeep},
	year = {2010},
	note = {Series Title: ISCA '10},
	keywords = {cpu architecture, gpu architecture, performance analysis, performance measurement, software optimization, throughput computing},
	pages = {451--460},
}

@article{lecun_deep_2015,
	title = {Deep learning},
	volume = {521},
	issn = {0028-0836},
	url = {http://dx.doi.org/10.1038/nature14539},
	abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
	number = {7553},
	journal = {Nature},
	author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	month = may,
	year = {2015},
	note = {Publisher: Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	pages = {436--444},
}

@article{he_deep_2015,
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	url = {http://arxiv.org/abs/1512.03385},
	abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
	urldate = {2017-06-09},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = dec,
	year = {2015},
	note = {arXiv: 1512.03385},
}

@article{wang_deep_nodate,
	title = {Deep {Learning} for {Identifying} {Metastatic} {Breast} {Cancer}},
	abstract = {The International Symposium on Biomedical Imaging (ISBI) held a grand challenge to evaluate computational systems for the automated detection of metastatic breast cancer in whole slide images of sentinel lymph node biop-sies. Our team won both competitions in the grand chal-lenge, obtaining an area under the receiver operating curve (AUC) of 0.925 for the task of whole slide image classifica-tion and a score of 0.7051 for the tumor localization task. A pathologist independently reviewed the same images, ob-taining a whole slide image classification AUC of 0.966 and a tumor localization score of 0.733. Combining our deep learning system's predictions with the human pathologist's diagnoses increased the pathologist's AUC to 0.995, rep-resenting an approximately 85 percent reduction in human error rate. These results demonstrate the power of using deep learning to produce significant improvements in the accuracy of pathological diagnoses.},
	urldate = {2017-04-10},
	author = {Wang, Dayong and Khosla, Aditya and Gargeya, Rishab and Irshad, Humayun and Beck, Andrew H and Israel, Beth},
}

@article{zhou_deep_nodate,
	title = {Deep {Forest}: {Towards} an {Alternative} to {Deep} {Neural} {Networks}},
	abstract = {In this paper, we propose gcForest, a decision tree ensemble approach with performance highly com-petitive to deep neural networks in a broad range of tasks. In contrast to deep neural networks which re-quire great effort in hyper-parameter tuning, gcFor-est is much easier to train; even when it is applied to different data across different domains in our ex-periments, excellent performance can be achieved by almost same settings of hyper-parameters. The training process of gcForest is efficient, and users can control training cost according to computa-tional resource available. The efficiency may be further enhanced because gcForest is naturally apt to parallel implementation. Furthermore, in con-trast to deep neural networks which require large-scale training data, gcForest can work well even when there are only small-scale training data.},
	urldate = {2017-09-28},
	author = {Zhou, Zhi-Hua and Feng, Ji},
}

@article{chen_customizable_2015,
	title = {Customizable {Computing}},
	volume = {10},
	issn = {1935-3235},
	url = {http://dx.doi.org/10.2200/S00650ED1V01Y201505CAC033},
	doi = {10.2200/S00650ED1V01Y201505CAC033},
	number = {3},
	journal = {Synthesis Lectures on Computer Architecture},
	author = {Chen, Yu-Ting and Cong, Jason and Gill, Michael and Reinman, Glenn and Xiao, Bingjun},
	month = jul,
	year = {2015},
	note = {Publisher: Morgan \& Claypool Publishers},
	pages = {1--118},
}

@article{rappoport_creating_2017,
	title = {Creating ethnicity-specific reference intervals for lab tests from {EHR} data},
	url = {https://www.biorxiv.org/content/early/2017/11/04/213892},
	doi = {10.1101/213892},
	abstract = {The results of clinical lab tests are an essential component of medical decision-making. To guide interpretation, test results are returned with reference intervals defined by the range in which 95\% of values occur in healthy individuals. Clinical laboratories often set their own reference intervals to accommodate local population and instruments variations. This approach is costly and can be biased. We describe a novel data-driven method for using electronic health record data to extract healthy patients' information to define reference intervals. We found that the distributions of many clinical lab tests differ among self-identified racial and ethnic groups (SIREs) in healthy patients. Finally, we derived SIRE-specific reference intervals and provide evidence that these intervals have clinical prognostic value. Specifically, we show that for two lab tests, serum creatinine level and hemoglobin A1C, SIRE-specific reference intervals are more predictive for need for dialysis and development type 2 diabetes than existing reference intervals.},
	urldate = {2017-11-07},
	journal = {bioRxiv},
	author = {Rappoport, Nadav and Paik, Hyojung and Oskotsky, Boris and Tor, Ruth and Ziv, Elad and Zaitlen, Noah and Butte, Atul J.},
	month = nov,
	year = {2017},
	note = {Publisher: Cold Spring Harbor Laboratory},
	pages = {213892},
}

@article{poplin_creating_2016,
	title = {Creating a universal {SNP} and small indel variant caller with deep neural networks},
	url = {http://biorxiv.org/content/early/2016/12/14/092890},
	urldate = {2017-05-03},
	journal = {bioRxiv},
	author = {Poplin, Ryan and Newburger, Dan and Dijamco, Jojo and Nguyen, Nam and Loy, Dion and Gross, Sam and McLean, Cory Y. and DePristo, Mark},
	year = {2016},
}

@article{zeng_convolutional_2016,
	title = {Convolutional neural network architectures for predicting {DNA}-protein binding},
	volume = {32},
	issn = {14602059},
	doi = {10.1093/bioinformatics/btw255},
	abstract = {Motivation: Convolutional neural networks (CNN) have outperformed conventional methods in modeling the sequence specificity of DNA–protein binding. Yet inappropriate CNN architectures can yield poorer performance than simpler models. Thus an in-depth understanding of how to match CNN architecture to a given task is needed to fully harness the power of CNNs for computational biology applications.Results: We present a systematic exploration of CNN architectures for predicting DNA sequence binding using a large compendium of transcription factor datasets. We identify the best-performing architectures by varying CNN width, depth and pooling designs. We find that adding convolutional kernels to a network is important for motif-based tasks. We show the benefits of CNNs in learning rich higher-order sequence features, such as secondary motifs and local sequence context, by comparing network performance on multiple modeling tasks ranging in difficulty. We also demonstrate how careful construction of sequence benchmark datasets, using approaches that control potentially confounding effects like positional or motif strength bias, is critical in making fair comparisons between competing methods. We explore how to establish the sufficiency of training data for these learning tasks, and we have created a flexible cloud-based framework that permits the rapid exploration of alternative neural network architectures for problems in computational biology.Availability and Implementation: All the models analyzed are available at http://cnn.csail.mit.edu.Contact: gifford@mit.eduSupplementary information: Supplementary data are available at Bioinformatics online.},
	number = {12},
	journal = {Bioinformatics},
	author = {Zeng, Haoyang and Edwards, Matthew D. and Liu, Ge and Gifford, David K.},
	year = {2016},
	pmid = {27307608},
}

@article{McIntyre2017,
	title = {Comprehensive benchmarking and ensemble approaches for metagenomic classifiers},
	volume = {18},
	issn = {1474-760X},
	url = {https://doi.org/10.1186/s13059-017-1299-7},
	doi = {10.1186/s13059-017-1299-7},
	abstract = {One of the main challenges in metagenomics is the identification of microorganisms in clinical and environmental samples. While an extensive and heterogeneous set of computational tools is available to classify microorganisms using whole-genome shotgun sequencing data, comprehensive comparisons of these methods are limited.},
	number = {1},
	journal = {Genome Biology},
	author = {McIntyre, Alexa B R and Ounit, Rachid and Afshinnekoo, Ebrahim and Prill, Robert J and Hénaff, Elizabeth and Alexander, Noah and Minot, Samuel S and Danko, David and Foox, Jonathan and Ahsanuddin, Sofia and Tighe, Scott and Hasan, Nur A and Subramanian, Poorani and Moffat, Kelly and Levy, Shawn and Lonardi, Stefano and Greenfield, Nick and Colwell, Rita R and Rosen, Gail L and Mason, Christopher E},
	month = sep,
	year = {2017},
	pages = {182},
}

@article{lundberg_consistent_2018,
	title = {Consistent {Individualized} {Feature} {Attribution} for {Tree} {Ensembles}},
	url = {http://arxiv.org/abs/1706.06060},
	abstract = {Interpreting predictions from tree ensemble methods such as gradient boosting machines and random forests is important, yet feature attribution for trees is often heuristic and not individualized for each prediction. Here we show that popular feature attribution methods are inconsistent, meaning they can lower a feature's assigned importance when the true impact of that feature actually increases. This is a fundamental problem that casts doubt on any comparison between features. To address it we turn to recent applications of game theory and develop fast exact tree solutions for SHAP (SHapley Additive exPlanation) values, which are the unique consistent and locally accurate attribution values. We then extend SHAP values to interaction effects and define SHAP interaction values. We propose a rich visualization of individualized feature attributions that improves over classic attribution summaries and partial dependence plots, and a unique "supervised" clustering (clustering based on feature attributions). We demonstrate better agreement with human intuition through a user study, exponential improvements in run time, improved clustering performance, and better identification of influential features. An implementation of our algorithm has also been merged into XGBoost and LightGBM, see http://github.com/slundberg/shap for details.},
	urldate = {2018-02-05},
	author = {Lundberg, Scott M. and Erion, Gabriel G. and Lee, Su-In},
	month = jun,
	year = {2018},
	note = {arXiv: 1802.03888},
}

@article{marshall_contribution_2016,
	title = {Contribution of copy number variants to schizophrenia from a genome-wide study of 41,321 subjects},
	volume = {49},
	issn = {1061-4036},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/27869829},
	doi = {10.1038/ng.3725},
	abstract = {Copy number variants (CNVs) have been strongly implicated in the genetic etiology of schizophrenia (SCZ). However, genome-wide investigation of the contribution of CNV to risk has been hampered by limited sample sizes. We sought to address this obstacle by applying a centralized analysis pipeline to a SCZ cohort of 21,094 cases and 20,227 controls. A global enrichment of CNV burden was observed in cases (odds ratio (OR) = 1.11, P = 5.7 × 10(-15)), which persisted after excluding loci implicated in previous studies (OR = 1.07, P = 1.7 × 10(-6)). CNV burden was enriched for genes associated with synaptic function (OR = 1.68, P = 2.8 × 10(-11)) and neurobehavioral phenotypes in mouse (OR = 1.18, P = 7.3 × 10(-5)). Genome-wide significant evidence was obtained for eight loci, including 1q21.1, 2p16.3 (NRXN1), 3q29, 7q11.2, 15q13.3, distal 16p11.2, proximal 16p11.2 and 22q11.2. Suggestive support was found for eight additional candidate susceptibility and protective loci, which consisted predominantly of CNVs mediated by nonallelic homologous recombination.},
	number = {1},
	urldate = {2017-04-23},
	journal = {Nature Genetics},
	author = {Marshall, Christian R and Howrigan, Daniel P and Merico, Daniele and Thiruvahindrapuram, Bhooma and Wu, Wenting and Greer, Douglas S and Antaki, Danny and Shetty, Aniket and Holmans, Peter A and Pinto, Dalila and Gujral, Madhusudan and Brandler, William M and Malhotra, Dheeraj and Wang, Zhouzhi and Fajarado, Karin V Fuentes and Maile, Michelle S and Ripke, Stephan and Agartz, Ingrid and Albus, Margot and Alexander, Madeline and Amin, Farooq and Atkins, Joshua and Bacanu, Silviu A and Belliveau, Richard A and Bergen, Sarah E and Bertalan, Marcelo and Bevilacqua, Elizabeth and Bigdeli, Tim B and Black, Donald W and Bruggeman, Richard and Buccola, Nancy G and Buckner, Randy L and Bulik-Sullivan, Brendan and Byerley, William and Cahn, Wiepke and Cai, Guiqing and Cairns, Murray J and Campion, Dominique and Cantor, Rita M and Carr, Vaughan J and Carrera, Noa and Catts, Stanley V and Chambert, Kimberley D and Cheng, Wei and Cloninger, C Robert and Cohen, David and Cormican, Paul and Craddock, Nick and Crespo-Facorro, Benedicto and Crowley, James J and Curtis, David and Davidson, Michael and Davis, Kenneth L and Degenhardt, Franziska and Del Favero, Jurgen and DeLisi, Lynn E and Dikeos, Dimitris and Dinan, Timothy and Djurovic, Srdjan and Donohoe, Gary and Drapeau, Elodie and Duan, Jubao and Dudbridge, Frank and Eichhammer, Peter and Eriksson, Johan and Escott-Price, Valentina and Essioux, Laurent and Fanous, Ayman H and Farh, Kai-How and Farrell, Martilias S and Frank, Josef and Franke, Lude and Freedman, Robert and Freimer, Nelson B and Friedman, Joseph I and Forstner, Andreas J and Fromer, Menachem and Genovese, Giulio and Georgieva, Lyudmila and Gershon, Elliot S and Giegling, Ina and Giusti-Rodríguez, Paola and Godard, Stephanie and Goldstein, Jacqueline I and Gratten, Jacob and de Haan, Lieuwe and Hamshere, Marian L and Hansen, Mark and Hansen, Thomas and Haroutunian, Vahram and Hartmann, Annette M and Henskens, Frans A and Herms, Stefan and Hirschhorn, Joel N and Hoffmann, Per and Hofman, Andrea and Huang, Hailiang and Ikeda, Masashi and Joa, Inge and Kähler, Anna K and Kahn, René S and Kalaydjieva, Luba and Karjalainen, Juha and Kavanagh, David and Keller, Matthew C and Kelly, Brian J and Kennedy, James L and Kim, Yunjung and Knowles, James A and Konte, Bettina and Laurent, Claudine and Lee, Phil and Lee, S Hong and Legge, Sophie E and Lerer, Bernard and Levy, Deborah L and Liang, Kung-Yee and Lieberman, Jeffrey and Lönnqvist, Jouko and Loughland, Carmel M and Magnusson, Patrik K E and Maher, Brion S and Maier, Wolfgang and Mallet, Jacques and Mattheisen, Manuel and Mattingsdal, Morten and McCarley, Robert W and McDonald, Colm and McIntosh, Andrew M and Meier, Sandra and Meijer, Carin J and Melle, Ingrid and Mesholam-Gately, Raquelle I and Metspalu, Andres and Michie, Patricia T and Milani, Lili and Milanova, Vihra and Mokrab, Younes and Morris, Derek W and Müller-Myhsok, Bertram and Murphy, Kieran C and Murray, Robin M and Myin-Germeys, Inez and Nenadic, Igor and Nertney, Deborah A and Nestadt, Gerald and Nicodemus, Kristin K and Nisenbaum, Laura and Nordin, Annelie and O'Callaghan, Eadbhard and O'Dushlaine, Colm and Oh, Sang-Yun and Olincy, Ann and Olsen, Line and O'Neill, F Anthony and Van Os, Jim and Pantelis, Christos and Papadimitriou, George N and Parkhomenko, Elena and Pato, Michele T and Paunio, Tiina and Perkins, Diana O and Pers, Tune H and Pietiläinen, Olli and Pimm, Jonathan and Pocklington, Andrew J and Powell, John and Price, Alkes and Pulver, Ann E and Purcell, Shaun M and Quested, Digby and Rasmussen, Henrik B and Reichenberg, Abraham and Reimers, Mark A and Richards, Alexander L and Roffman, Joshua L and Roussos, Panos and Ruderfer, Douglas M and Salomaa, Veikko and Sanders, Alan R and Savitz, Adam and Schall, Ulrich and Schulze, Thomas G and Schwab, Sibylle G and Scolnick, Edward M and Scott, Rodney J and Seidman, Larry J and Shi, Jianxin and Silverman, Jeremy M and Smoller, Jordan W and Söderman, Erik and Spencer, Chris C A and Stahl, Eli A and Strengman, Eric and Strohmaier, Jana and Stroup, T Scott and Suvisaari, Jaana and Svrakic, Dragan M and Szatkiewicz, Jin P and Thirumalai, Srinivas and Tooney, Paul A and Veijola, Juha and Visscher, Peter M and Waddington, John and Walsh, Dermot and Webb, Bradley T and Weiser, Mark and Wildenauer, Dieter B and Williams, Nigel M and Williams, Stephanie and Witt, Stephanie H and Wolen, Aaron R and Wormley, Brandon K and Wray, Naomi R and Wu, Jing Qin and Zai, Clement C and Adolfsson, Rolf and Andreassen, Ole A and Blackwood, Douglas H R and Bramon, Elvira and Buxbaum, Joseph D and Cichon, Sven and Collier, David A and Corvin, Aiden and Daly, Mark J and Darvasi, Ariel and Domenici, Enrico and Esko, Tõnu and Gejman, Pablo V and Gill, Michael and Gurling, Hugh and Hultman, Christina M and Iwata, Nakao and Jablensky, Assen V and Jönsson, Erik G and Kendler, Kenneth S and Kirov, George and Knight, Jo and Levinson, Douglas F and Li, Qingqin S and McCarroll, Steven A and McQuillin, Andrew and Moran, Jennifer L and Mowry, Bryan J and Nöthen, Markus M and Ophoff, Roel A and Owen, Michael J and Palotie, Aarno and Pato, Carlos N and Petryshen, Tracey L and Posthuma, Danielle and Rietschel, Marcella and Riley, Brien P and Rujescu, Dan and Sklar, Pamela and St Clair, David and Walters, James T R and Werge, Thomas and Sullivan, Patrick F and O'Donovan, Michael C and Scherer, Stephen W and Neale, Benjamin M and Sebat, Jonathan},
	month = nov,
	year = {2016},
	pmid = {27869829},
	pages = {27--35},
}

@article{excoffier_computer_2006,
	title = {Computer programs for population genetics data analysis: a survival guide},
	volume = {7},
	issn = {1471-0056},
	url = {http://www.nature.com/doifinder/10.1038/nrg1904},
	doi = {10.1038/nrg1904},
	abstract = {Recent population genetics methods can provide accurate information on the past demography of a population, which is necessary to correctly interpret patterns of linkage disequilibrium 1 , recognize regions of the genome that are under selection 2,3 or help to develop good conservation strategies and priorities 4 . At the same time, the advent of cost-efficient, large-scale genotyp-ing techniques has greatly facilitated the assessment of genetic diversity within populations. Powerful new methods have been developed to analyse these genetic data, sometimes relying on massive computations. These methods are implemented in various software packages and programs, which have grown in number tremendously in the past few years. Although many computer programs in population genetics have been successful in hiding the complexity of the computations from the user, they often rely on assumptions that are crucial for a correct interpretation of the results. There is therefore a clear need to help researchers to navigate this complicated field in order to promote the informed use of these programs. In this review, we describe some of the most widely used computer programs in population genetics, as well as a series of more specialized programs that implement new and advanced methodologies. We promote the view that the proper analysis of any population genetics data set requires the use of several approaches, beginning with the examination of the basic properties of the data, followed by various more specialized analyses, which will probably be implemented in several programs. So, unlike previous reviews of population genetics software (for examples, see REFS 5,6), we do not compare the value of the programs, nor assess their relative performance and accuracy. We instead briefly describe their principles, the statistics they compute, the assumptions they make and some of their limitations. Even though we have included many programs in this review, the list is by far not exhaustive. We have chosen, for instance, to leave aside packages that deal with phylogenetic analysis, parentage analysis, gametic phase estimation or linkage analysis, because they have been the subject of other reviews or books (for examples, see REFS 6–11), whereas no overview seems to exist for population-genetics software. Nevertheless, we have tried to include a wide range of applications, implemented in more than 20 programs that have been selected on the basis of their generality, usability, interoperability and unique features, to present a set of programs that carry out classical as well as recent and more sophisticated analyses. They therefore cover the estimation of basic descriptive statistics of genetic diversity within and between popula-tions, tests of random mating, linkage equilibrium and selective neutrality, detection of new immigrants and admixed individuals, as well as the inference of vari-ous demographic parameters, such as population size, population divergence time and migration rates. Because users usually need to analyse the same data set with several programs, we describe the input formats used by different programs, and pay special attention to their interoperability, as an important factor that limits the use of a particular program is often the need to refor-mat the raw data for that particular purpose. We also discuss some limitations and common problems associ-ated with the use of the current software and the ways in which they could be improved, and indicate potential new directions for the development of future packages.},
	number = {10},
	urldate = {2017-10-26},
	journal = {Nature Reviews Genetics},
	author = {Excoffier, Laurent and Heckel, Gerald},
	month = oct,
	year = {2006},
	pmid = {16924258},
	note = {Publisher: Nature Publishing Group
ISBN: 1471-0056},
	pages = {745--758},
}

@inproceedings{wang_communication_2017,
	title = {Communication {Optimization} on {GPU}: {A} {Case} {Study} of {Sequence} {Alignment} {Algorithms}},
	isbn = {VO -},
	doi = {10.1109/IPDPS.2017.79},
	abstract = {Data movement is increasingly becoming the bottleneck of both performance and energy efficiency in modern computation. Until recently, it was the case that there is limited freedom for communication optimization on GPUs, as conventional GPUs only provide two types of methods for inter-thread communication: using shared memory or global memory. However, a new warp shuffle instruction has been introduced since the Kepler architecture on Nvidia GPUs, which enables threads within the same warp to directly exchange data in registers. This brought new performance optimization opportunities for algorithms with intensive inter-thread communication. In this work, we deploy register shuffle in the application domain of sequence alignment (or similarly, string matching), and conduct a quantitative analysis of the opportunities and limitations of using register shuffle. We select two sequence alignment algorithms, Smith-Waterman (SW) and Pairwise-Hidden-Markov-Model (PairHMM), from the widely used Genome Analysis Toolkit (GATK) as case studies. Compared to implementations using shared memory, we obtain a significant speed-up of 1.2\&\#x00D7; and 2.1\&\#x00D7; by using shuffle instructions for SW and PairHMM. Furthermore, we develop a performance model for analyzing the kernel performance based on the measured shuffle latency from a suite of microbenchmarks. Our model provides valuable insights for CUDA programmers into how to best use shuffle instructions for performance optimization.},
	booktitle = {2017 {IEEE} {International} {Parallel} and {Distributed} {Processing} {Symposium} ({IPDPS})},
	author = {Wang, J and Xie, X and Cong, J},
	year = {2017},
	keywords = {CUDA programmers, Computer architecture, Genome Analysis Toolkit, Graphics processing units, Instruction sets, Kepler architecture, Kernel, Nvidia GPU, Optimization, PairHMM, Registers, SW, Smith-Waterman model, Synchronization, biology computing, data movement, energy conservation, energy efficiency, genomics, global memory, graphics processing units, hidden Markov models, intensive inter-thread communication, microbenchmarks, multi-threading, pairwise-hidden Markov-model, parallel architectures, performance evaluation, performance optimization, quantitative analysis, register shuffle, sequence alignment algorithms, shared memory, shared memory systems, warp shuffle instruction},
	pages = {72--81},
}

@article{yang_common_2010,
	title = {Common {SNPs} explain a large proportion of the heritability for human height},
	volume = {42},
	issn = {1061-4036},
	url = {http://dx.doi.org/10.1038/ng.608},
	number = {7},
	journal = {Nat Genet},
	author = {Yang, Jian and Benyamin, Beben and McEvoy, Brian P and Gordon, Scott and Henders, Anjali K and Nyholt, Dale R and Madden, Pamela A and Heath, Andrew C and Martin, Nicholas G and Montgomery, Grant W and Goddard, Michael E and Visscher, Peter M},
	month = jul,
	year = {2010},
	note = {Publisher: Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	pages = {565--569},
}

@article{goodwin_coming_2016,
	title = {Coming of age: ten years of next-generation sequencing technologies},
	volume = {17},
	issn = {1471-0056},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/27184599},
	doi = {10.1038/nrg.2016.49},
	abstract = {Since the completion of the human genome project in 2003, extraordinary progress has been made in genome sequencing technologies, which has led to a decreased cost per megabase and an increase in the number and diversity of sequenced genomes. An astonishing complexity of genome architecture has been revealed, bringing these sequencing technologies to even greater advancements. Some approaches maximize the number of bases sequenced in the least amount of time, generating a wealth of data that can be used to understand increasingly complex phenotypes. Alternatively, other approaches now aim to sequence longer contiguous pieces of DNA, which are essential for resolving structurally complex regions. These and other strategies are providing researchers and clinicians a variety of tools to probe genomes in greater depth, leading to an enhanced understanding of how genome sequence variants underlie phenotype and disease.},
	number = {6},
	urldate = {2017-04-23},
	journal = {Nature Reviews Genetics},
	author = {Goodwin, Sara and McPherson, John D. and McCombie, W. Richard},
	month = may,
	year = {2016},
	pmid = {27184599},
	keywords = {Nanopore, Sequencing},
	pages = {333--351},
}

@article{murphy_combining_2017,
	title = {Combining clinical and genomics queries using i2b2 – {Three} methods},
	volume = {12},
	issn = {1932-6203},
	url = {http://dx.plos.org/10.1371/journal.pone.0172187},
	doi = {10.1371/journal.pone.0172187},
	number = {4},
	urldate = {2017-04-20},
	journal = {PLOS ONE},
	author = {Murphy, Shawn N. and Avillach, Paul and Bellazzi, Riccardo and Phillips, Lori and Gabetta, Matteo and Eran, Alal and McDuffie, Michael T. and Kohane, Isaac S.},
	editor = {Groza, Tudor},
	month = apr,
	year = {2017},
	note = {Publisher: John Wiley \& Sons},
	pages = {e0172187},
}

@article{green_charting_2011,
	title = {Charting a course for genomic medicine from base pairs to bedside},
	volume = {470},
	issn = {0028-0836},
	url = {http://www.nature.com/doifinder/10.1038/nature09764},
	doi = {10.1038/nature09764},
	number = {7333},
	urldate = {2017-10-09},
	journal = {Nature},
	author = {Green, Eric D. and Guyer, Mark S. and Green, Eric D. and Guyer, Mark S. and Manolio, Teri A. and Peterson, Jane L.},
	month = feb,
	year = {2011},
	note = {Publisher: Nature Research},
	pages = {204--213},
}

@article{ewing_base-calling_1998,
	title = {Base-{Calling} of {Automated} {Sequencer} {Traces} {UsingPhred}. {I}. {Accuracy} {Assessment}},
	volume = {8},
	issn = {1088-9051, 1549-5469},
	doi = {10.1101/gr.8.3.175},
	abstract = {The availability of massive amounts of DNA sequence information has begun to revolutionize the practice of biology. As a result, current large-scale sequencing output, while impressive, is not adequate to keep pace with growing demand and, in particular, is far short of what will be required to obtain the 3-billion-base human genome sequence by the target date of 2005. To reach this goal, improved automation will be essential, and it is particularly important that human involvement in sequence data processing be significantly reduced or eliminated. Progress in this respect will require both improved accuracy of the data processing software and reliable accuracy measures to reduce the need for human involvement in error correction and make human review more efficient. Here, we describe one step toward that goal: a base-calling program for automated sequencer traces,phred, with improved accuracy. phred appears to be the first base-calling program to achieve a lower error rate than the ABI software, averaging 40\%–50\% fewer errors in the data sets examined independent of position in read, machine running conditions, or sequencing chemistry.},
	number = {3},
	journal = {Genome Research},
	author = {Ewing, Brent and Hillier, LaDeana and Wendl, Michael C. and Green, Phil},
	year = {1998},
	pmid = {9521921},
	note = {ISBN: 1088-9051},
	pages = {175--185},
}

@article{kraus_classifying_2016,
	title = {Classifying and segmenting microscopy images with deep multiple instance learning},
	volume = {32},
	issn = {1367-4803},
	url = {https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/btw252},
	doi = {10.1093/bioinformatics/btw252},
	number = {12},
	urldate = {2017-04-17},
	journal = {Bioinformatics},
	author = {Kraus, Oren Z. and Ba, Jimmy Lei and Frey, Brendan J.},
	month = jun,
	year = {2016},
	note = {Publisher: Oxford University Press},
	pages = {i52--i59},
}

@article{lazar_batfled:_nodate,
	title = {{BaTFLED}: {Bayesian} {Tensor} {Factorization} {Linked} to {External} {Data}},
	abstract = {The vast majority of current machine learning algorithms are designed to predict single responses or a vector of responses, yet many types of response are more naturally organized as matrices or higher-order tensor objects where characteristics are shared across modes. We present a new machine learning algorithm BaTFLED (Bayesian Tensor Factorization Linked to External Data) that predicts values in a three-dimensional response tensor using input features for each of the dimensions. BaTFLED uses a probabilistic Bayesian framework to learn projection matrices mapping input features for each mode into latent representations that multiply to form the response tensor. By utilizing a Tucker decomposition, the model can capture weights for interactions between latent factors for each mode in a small core tensor. Priors that encourage sparsity in the projection matrices and core tensor allow for feature selection and model regularization. This method is shown to far outperform elastic net and neural net models on 'cold start' tasks from data simulated in a three-mode structure. Additionally, we apply the model to predict dose-response curves in a panel of breast cancer cell lines treated with drug compounds that was used as a Dialogue for Reverse Engineering Assessments and Methods (DREAM) challenge. 1 The BaTFLED model},
	urldate = {2017-04-17},
	author = {Lazar, Nathan H and Gönen, Mehmet and Sönmez, Kemal},
}

@article{10.1371/journal.pcbi.1002823,
	title = {Chapter 13: {Mining} {Electronic} {Health} {Records} in the {Genomics} {Era}},
	volume = {8},
	url = {https://doi.org/10.1371/journal.pcbi.1002823},
	doi = {10.1371/journal.pcbi.1002823},
	abstract = {Abstract: The combination of improved genomic analysis methods, decreasing genotyping costs, and increasing computing resources has led to an explosion of clinical genomic knowledge in the last decade. Similarly, healthcare systems are increasingly adopting robust electronic health record (EHR) systems that not only can improve health care, but also contain a vast repository of disease and treatment data that could be mined for genomic research. Indeed, institutions are creating EHR-linked DNA biobanks to enable genomic and pharmacogenomic research, using EHR data for phenotypic information. However, EHRs are designed primarily for clinical care, not research, so reuse of clinical EHR data for research purposes can be challenging. Difficulties in use of EHR data include: data availability, missing data, incorrect data, and vast quantities of unstructured narrative text data. Structured information includes billing codes, most laboratory reports, and other variables such as physiologic measurements and demographic information. Significant information, however, remains locked within EHR narrative text documents, including clinical notes and certain categories of test results, such as pathology and radiology reports. For relatively rare observations, combinations of simple free-text searches and billing codes may prove adequate when followed by manual chart review. However, to extract the large cohorts necessary for genome-wide association studies, natural language processing methods to process narrative text data may be needed. Combinations of structured and unstructured textual data can be mined to generate high-validity collections of cases and controls for a given condition. Once high-quality cases and controls are identified, EHR-derived cases can be used for genomic discovery and validation. Since EHR data includes a broad sampling of clinically-relevant phenotypic information, it may enable multiple genomic investigations upon a single set of genotyped individuals. This chapter reviews several examples of phenotype extraction and their application to genetic research, demonstrating a viable future for genomic discovery using EHR-linked data.},
	number = {12},
	journal = {PLOS Computational Biology},
	author = {Denny, Joshua C},
	year = {2012},
	note = {Publisher: Public Library of Science},
	pages = {1--15},
}

@article{labaj_characterization_2011,
	title = {Characterization and improvement of {RNA}-{Seq} precision in quantitative transcript expression profiling},
	volume = {27},
	issn = {1367-4803},
	url = {http://dx.doi.org/10.1093/bioinformatics/btr247},
	abstract = {Motivation: Measurement precision determines the power of any analysis to reliably identify significant signals, such as in screens for differential expression, independent of whether the experimental design incorporates replicates or not. With the compilation of large-scale RNA-Seq datasets with technical replicate samples, however, we can now, for the first time, perform a systematic analysis of the precision of expression level estimates from massively parallel sequencing technology. This then allows considerations for its improvement by computational or experimental means.Results: We report on a comprehensive study of target identification and measurement precision, including their dependence on transcript expression levels, read depth and other parameters. In particular, an impressive recall of 84\% of the estimated true transcript population could be achieved with 331 million 50 bp reads, with diminishing returns from longer read lengths and even less gains from increased sequencing depths. Most of the measurement power (75\%) is spent on only 7\% of the known transcriptome, however, making less strongly expressed transcripts harder to measure. Consequently, {\textless}30\% of all transcripts could be quantified reliably with a relative error {\textless}20\%. Based on established tools, we then introduce a new approach for mapping and analysing sequencing reads that yields substantially improved performance in gene expression profiling, increasing the number of transcripts that can reliably be quantified to over 40\%. Extrapolations to higher sequencing depths highlight the need for efficient complementary steps. In discussion we outline possible experimental and computational strategies for further improvements in quantification precision.Contact:rnaseq10@boku.ac.atSupplementary information:Supplementary data are available at Bioinformatics online.},
	number = {13},
	journal = {Bioinformatics},
	author = {Łabaj, Paweł P and Leparc, Germán G and Linggi, Bryan E and Markillie, Lye Meng and Wiley, H Steven and Kreil, David P},
	month = jul,
	year = {2011},
	pages = {i383--i391},
}

@article{hardoon_canonical_2004,
	title = {Canonical {Correlation} {Analysis}: {An} {Overview} with {Application} to {Learning} {Methods}},
	volume = {16},
	issn = {0899-7667 VO - 16},
	doi = {10.1162/0899766042321814},
	number = {12},
	journal = {Neural Computation},
	author = {Hardoon, D R and Szedmak, S and Shawe-Taylor, J},
	year = {2004},
	pages = {2639--2664},
}

@inproceedings{dal2015calibrating,
	title = {Calibrating probability with undersampling for unbalanced classification},
	booktitle = {Computational {Intelligence}, 2015 {IEEE} {Symposium} {Series} on},
	publisher = {IEEE},
	author = {Dal Pozzolo, Andrea and Caelen, Olivier and Johnson, Reid A and Bontempi, Gianluca},
	year = {2015},
	pages = {159--166},
}

@inproceedings{nurvitadhi_can_2017,
	address = {New York, New York, USA},
	title = {Can {FPGAs} {Beat} {GPUs} in {Accelerating} {Next}-{Generation} {Deep} {Neural} {Networks}?},
	isbn = {978-1-4503-4354-1},
	url = {http://dl.acm.org/citation.cfm?doid=3020078.3021740},
	doi = {10.1145/3020078.3021740},
	urldate = {2017-05-25},
	booktitle = {Proceedings of the 2017 {ACM}/{SIGDA} {International} {Symposium} on {Field}-{Programmable} {Gate} {Arrays} - {FPGA} '17},
	publisher = {ACM Press},
	author = {Nurvitadhi, Eriko and Subhaschandra, Suchit and Boudoukh, Guy and Venkatesh, Ganesh and Sim, Jaewoong and Marr, Debbie and Huang, Randy and Ong Gee Hock, Jason and Liew, Yeong Tat and Srivatsan, Krishnan and Moss, Duncan},
	year = {2017},
	keywords = {FPGA, GPU, accelerator, deep learning, intel stratix 10},
	pages = {5--14},
}

@article{kettenring_canonical_1971,
	title = {Canonical {Analysis} of {Several} {Sets} of {Variables}},
	volume = {58},
	issn = {00063444},
	url = {http://www.jstor.org/stable/2334380},
	doi = {10.2307/2334380},
	abstract = {Five extensions of the classical two-set theory of canonical correlation analysis to three or more sets are considered. For each one, a model of the general principal component type is constructed to aid in motivating, comparing and understanding the methods. Procedures are developed for finding the canonical variables associated with the different approaches. Some practical considerations and an example are also included.},
	number = {3},
	journal = {Biometrika},
	author = {Kettenring, J R},
	year = {1971},
	note = {Publisher: [Oxford University Press, Biometrika Trust]},
	pages = {433--451},
}

@article{SesslerDanielI.2010,
	title = {Broadly {Applicable} {Risk} {Stratification} {System} for {Predicting} {Duration} of {Hospitalization} and {Mortality}},
	volume = {113},
	issn = {0003-3022},
	url = {http://dx.doi.org/10.1097/ALN.0b013e3181f79a8d},
	number = {5},
	journal = {Anesthesiology},
	author = {Sessler Daniel I., M D and Sigl Jeffrey C., Ph.D. and Manberg Paul J., Ph.D. and Kelley Scott D., M D and Schubert M.B.A. , Armin, M D and Chamoun Nassib G., M S},
	month = nov,
	year = {2010},
	pages = {1026--1037},
}

@inproceedings{jun_bluedbm:_2015,
	address = {New York, New York, USA},
	title = {{BlueDBM}: {An} {Appliance} for {Big} {Data} {Analytics}},
	volume = {43},
	isbn = {978-1-4503-3402-0},
	url = {http://dl.acm.org/citation.cfm?doid=2749469.2750412},
	doi = {10.1145/2749469.2750412},
	urldate = {2017-04-29},
	booktitle = {Proceedings of the 42nd {Annual} {International} {Symposium} on {Computer} {Architecture} - {ISCA} '15},
	publisher = {ACM Press},
	author = {Jun, Sang-Woo and Liu, Ming and Lee, Sungjin and Hicks, Jamey and Ankcorn, John and King, Myron and Xu, Shuotao and {Arvind} and Jun, Sang-Woo and Liu, Ming and Lee, Sungjin and Hicks, Jamey and Ankcorn, John and King, Myron and Xu, Shuotao and {Arvind}},
	year = {2015},
	note = {Issue: 3
ISSN: 0163-5964},
	pages = {1--13},
}

@book{durbin1998biological,
	title = {Biological sequence analysis: probabilistic models of proteins and nucleic acids},
	publisher = {Cambridge university press},
	author = {Durbin, Richard and Eddy, Sean R and Krogh, Anders and Mitchison, Graeme},
	year = {1998},
}

@article{schuster_bidirectional_1997,
	title = {Bidirectional recurrent neural networks},
	volume = {45},
	issn = {1053-587X},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=650093},
	doi = {10.1109/78.650093},
	abstract = {In the first part of this paper, a regular recurrent neural network (RNN) is extended to a bidirectional recurrent neural network (BRNN). The BRNN can be trained without the limitation of using input information just up to a preset future frame. This is accomplished by training it simultaneously in positive and negative time direction. Structure and training procedure of the proposed network are explained. In regression and classification experiments on artificial data, the proposed structure gives better results than other approaches. For real data, classification experiments for phonemes from the TIMIT database show the same tendency. In the second part of this paper, it is shown how the proposed bidirectional structure can be easily modified to allow efficient estimation of the conditional posterior probability of complete symbol sequences without making any explicit assumption about the shape of the distribution. For this part, experiments on real data are reported},
	number = {11},
	urldate = {2017-10-25},
	journal = {IEEE Transactions on Signal Processing},
	author = {Schuster, Mike and Paliwal, Kuldip K},
	year = {1997},
	pmid = {25246403},
	note = {arXiv: 1011.1669v3
ISBN: 1053-587X},
	keywords = {Index, Recurrent neural networks, Terms—},
	pages = {2673--2681},
}

@article{haghverdi_batch_2018,
	title = {Batch effects in single-cell {RNA}-sequencing data are corrected by matching mutual nearest neighbors},
	volume = {36},
	url = {https://doi.org/10.1038/nbt.4091},
	journal = {Nature Biotechnology},
	author = {Haghverdi, Laleh and Lun, Aaron T L and Morgan, Michael D and Marioni, John C},
	month = apr,
	year = {2018},
	pages = {421--421},
}

@article{ewing_base-calling_1998-1,
	title = {Base-calling of automated sequencer traces using phred. {II}. {Error} probabilities},
	volume = {8},
	issn = {10889051},
	doi = {10.1101/gr.8.3.186},
	abstract = {The availability of massive amounts of DNA sequence information has begun to revolutionize the practice of biology. As a result, current large-scale sequencing output, while impressive, is not adequate to keep pace with growing demand and, in particular, is far short of what will be required to obtain the 3-billion-base human genome sequence by the target date of 2005. To reach this goal, improved automation will be essential, and it is particularly important that human involvement in sequence data processing be significantly reduced or eliminated. Progress in this respect will require both improved accuracy of the data processing software and reliable accuracy measures to reduce the need for human involvement in error correction and make human review more efficient. Here, we describe one step toward that goal: a base-calling program for automated sequencer traces, phred, with improved accuracy. phred appears to be the first base-calling program to achieve a lower error rate than the ABI software, averaging 40\%-50\% fewer errors in the data sets examined independent of position in read, machine running conditions, or sequencing chemistry.},
	number = {3},
	journal = {Genome Research},
	author = {Ewing, Brent and Green, Phil},
	year = {1998},
	pmid = {9521921},
	note = {ISBN: 1088-9051},
	pages = {186--194},
}

@article{Steyerberg2010,
	title = {Assessing the {Performance} of {Prediction} {Models}: {A} {Framework} for {Traditional} and {Novel} {Measures}},
	volume = {21},
	issn = {1044-3983},
	url = {https://journals.lww.com/epidem/Fulltext/2010/01000/Assessing_the_Performance_of_Prediction_Models__A.22.aspx},
	abstract = {Abstract: The performance of prediction models can be assessed using a variety of methods and metrics. Traditional measures for binary and survival outcomes include the Brier score to indicate overall model performance, the concordance (or c) statistic for discriminative ability (or area under the receiver operating characteristic [ROC] curve), and goodness-of-fit statistics for calibration. Several new measures have recently been proposed that can be seen as refinements of discrimination measures, including variants of the c statistic for survival, reclassification tables, net reclassification improvement (NRI), and integrated discrimination improvement (IDI). Moreover, decision–analytic measures have been proposed, including decision curves to plot the net benefit achieved by making decisions based on model predictions. We aimed to define the role of these relatively novel approaches in the evaluation of the performance of prediction models. For illustration, we present a case study of predicting the presence of residual tumor versus benign tissue in patients with testicular cancer (n = 544 for model development, n = 273 for external validation). We suggest that reporting discrimination and calibration will always be important for a prediction model. Decision-analytic measures should be reported if the predictive model is to be used for clinical decisions. Other measures of performance may be warranted in specific applications, such as reclassification metrics to gain insight into the value of adding a novel predictor to an established model.},
	number = {1},
	journal = {Epidemiology},
	author = {Steyerberg, Ewout W and Vickers, Andrew J and Cook, Nancy R and Gerds, Thomas and Gonen, Mithat and Obuchowski, Nancy and Pencina, Michael J and Kattan, Michael W},
	year = {2010},
}

@article{wolters_asa_1996,
	title = {{ASA} classification and perioperative variables as predictors of postoperative outcome.},
	volume = {77},
	issn = {0007-0912},
	url = {http://dx.doi.org/10.1093/bja/77.2.217},
	abstract = {In a prospective study of 6301 surgical patients in a university hospital, we examined the strength of association between ASA physical status classification and perioperative risk factors, and postoperative outcome, using both univariate analysis and calculation of the odds ratio of the risk of developing a postoperative complication by means of a logistic regression model. Univariate analysis showed a significant correlation (P {\textless} 0.05) between ASA class and perioperative variables (intraoperative blood loss, duration of postoperative ventilation and duration of intensive care stay), postoperative complications and mortality rate. Univariate analysis of individual preoperative risk factors demonstrated their importance in the development of postoperative complications in the related organ systems. Estimating the increased risk odds ratio for single variables, we found that the risk of complication was influenced mainly by ASA class IV (risk odds ratio = 4.2) and ASA class III (risk odds ratio = 2.2). We conclude that ASA physical status classification was a predictor of postoperative outcome.},
	number = {2},
	journal = {BJA: British Journal of Anaesthesia},
	author = {Wolters, U and Wolf, T and Stützer, H and Schröder, T},
	month = aug,
	year = {1996},
	pages = {217--222},
}

@article{hackett_asa_2015,
	title = {{ASA} class is a reliable independent predictor of medical complications and mortality following surgery},
	volume = {18},
	issn = {1743-9191},
	url = {https://www.sciencedirect.com/science/article/pii/S174391911500206X},
	doi = {10.1016/J.IJSU.2015.04.079},
	abstract = {METHODS
The American Society of Anesthesiologists Physical Status classification system (ASA PS) is a method of characterizing patient operative risk on a scale of 1–5, where 1 is normal health and 5 is moribund. Every anesthesiologist is trained in this measure, and it is performed before every procedure in which a patient undergoes anesthesia. We measured the independent predictive value of ASA-PS for complications and mortality in the ACS-NSQIP database by multivariate regression. We conducted analogous regressions after standardizing ASA-PS to control for interprocedural variations in risk in the overall model and sub-analyses by surgical specialty and the most common procedures. 

RESULTS
For 2,297,629 cases (2005–2012; median age 55, min = 16, max{\textgreater}90 [90 and above are coded as 90+]), at increasing levels of ASA-PS (2–5), odds ratios (OR's) from 2.05 to 63.25 (complications, p {\textless} 0.001) and 5.77–2011.92 (mortality, p {\textless} 0.001) were observed, with non-overlapping 95\% confidence intervals. Standardization of ASA-PS (OR = 1.426 [per standard deviation above the mean ASA-PS per procedure], p {\textless} .001) and subgroup analyses yielded similar results. 

DISCUSSION
ASA PS was not only found to be associated with increased morbidity and mortality, but independently predictive when controlling for other comorbidities. Even after standardization based on procedure type, increases in ASA predicted significant increases in complication rates for morbidity and mortality post-operatively. 

CONCLUSIONS
ASA PS has strong, independent associations with post-operative medical complications and mortality across procedures. This capability, along with its simplicity, makes it a valuable prognostic metric.},
	urldate = {2018-04-17},
	journal = {International Journal of Surgery},
	author = {Hackett, Nicholas J. and De Oliveira, Gildasio S. and Jain, Umang K. and Kim, John Y.S.},
	month = jun,
	year = {2015},
	note = {Publisher: Elsevier},
	pages = {184--190},
}

@inproceedings{cong_application-specific_2004,
	address = {New York, New York, USA},
	title = {Application-specific instruction generation for configurable processor architectures},
	isbn = {1-58113-829-6},
	url = {http://portal.acm.org/citation.cfm?doid=968280.968307},
	doi = {10.1145/968280.968307},
	abstract = {Designing an application-specific embedded system in nanometer technologies has become more difficult than ever due to the rapid increase in design complexity and manufacturing cost. Efficiency and flexibility must be carefully balanced to meet different application requirements. The recently emerged configurable and extensible processor architectures offer a favorable tradeoff between efficiency and flexibility, and a promising way to minimize certain important metrics (e.g., execution time, code size, etc.) of the embedded processors. This paper addresses the problem of generating the application-specific instructions to improve the execution speed for configurable processors. A set of algorithms, including pattern generation, pattern selection, and application mapping, are proposed to efficiently utilize the instruction set extensibility of the target configurable processor. Applications of our approach to several real-life benchmarks on the Altera Nios processor show encouraging performance speedup (2.75X on average and up to 3.73X in some cases).},
	urldate = {2017-04-10},
	booktitle = {Proceeding of the 2004 {ACM}/{SIGDA} 12th international symposium on {Field} programmable gate arrays - {FPGA} '04},
	publisher = {ACM Press},
	author = {Cong, Jason and Fan, Yiping and Han, Guoling and Zhang, Zhiru},
	year = {2004},
	keywords = {asip, compilation, configurable processor, technology mapping},
	pages = {183},
}

@article{dlugosch_efficient_2014,
	title = {An {Efficient} and {Scalable} {Semiconductor} {Architecture} for {Parallel} {Automata} {Processing}},
	volume = {25},
	issn = {1045-9219},
	url = {http://ieeexplore.ieee.org/document/6719386/},
	doi = {10.1109/TPDS.2014.8},
	number = {12},
	urldate = {2017-09-11},
	journal = {IEEE Transactions on Parallel and Distributed Systems},
	author = {Dlugosch, Paul and Brown, Dave and Glendenning, Paul and Leventhal, Michael and Noyes, Harold},
	month = dec,
	year = {2014},
	pages = {3088--3098},
}

@inproceedings{shao_aladdin:_2014,
	title = {Aladdin: {A} pre-{RTL}, power-performance accelerator simulator enabling large design space exploration of customized architectures},
	isbn = {978-1-4799-4394-4},
	url = {http://ieeexplore.ieee.org/document/6853196/},
	doi = {10.1109/ISCA.2014.6853196},
	urldate = {2017-04-10},
	booktitle = {2014 {ACM}/{IEEE} 41st {International} {Symposium} on {Computer} {Architecture} ({ISCA})},
	publisher = {IEEE},
	author = {Shao, Yakun Sophia and Reagen, Brandon and Wei, Gu-Yeon and Brooks, David},
	month = jun,
	year = {2014},
	pages = {97--108},
}

@article{li_adjust_2004,
	title = {Adjust quality scores from alignment and improve sequencing accuracy.},
	volume = {32},
	issn = {1362-4962},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/15459287},
	doi = {10.1093/nar/gkh850},
	abstract = {In shotgun sequencing, statistical reconstruction of a consensus from alignment requires a model of measurement error. Churchill and Waterman proposed one such model and an expectation-maximization (EM) algorithm to estimate sequencing error rates for each assembly matrix. Ewing and Green defined Phred quality scores for base-calling from sequencing traces by training a model on a large amount of data. However, sample preparations and sequencing machines may work under different conditions in practice and therefore quality scores need to be adjusted. Moreover, the information given by quality scores is incomplete in the sense that they do not describe error patterns. We observe that each nucleotide base has its specific error pattern that varies across the range of quality values. We develop models of measurement error for shotgun sequencing by combining the two perspectives above. We propose a logistic model taking quality scores as covariates. The model is trained by a procedure combining an EM algorithm and model selection techniques. The training results in calibration of quality values and leads to a more accurate construction of consensus. Besides Phred scores obtained from ABI sequencers, we apply the same technique to calibrate quality values that come along with Beckman sequencers.},
	number = {17},
	urldate = {2017-05-04},
	journal = {Nucleic acids research},
	author = {Li, Ming and Nordborg, Magnus and Li, Lei M},
	year = {2004},
	pmid = {15459287},
	note = {Publisher: Oxford University Press},
	pages = {5183--91},
}

@inproceedings{he_adasyn:_2008,
	title = {{ADASYN}: {Adaptive} synthetic sampling approach for imbalanced learning},
	isbn = {2161-4393 VO -},
	doi = {10.1109/IJCNN.2008.4633969},
	booktitle = {2008 {IEEE} {International} {Joint} {Conference} on {Neural} {Networks} ({IEEE} {World} {Congress} on {Computational} {Intelligence})},
	author = {He, Haibo and Bai, Yang and Garcia, E A and Li, Shutao},
	year = {2008},
	keywords = {Bioinformatics, Boosting, Cancer, Data analysis, Data mining, Decision trees, Helium, Machine learning, Sampling methods, Space technology, adaptive synthetic sampling approach, classification decision boundary, imbalanced data classification, imbalanced data set learning, learning (artificial intelligence), pattern classification, sampling methods, statistical distributions, weighted distribution},
	pages = {1322--1328},
}

@article{torracinta_adaptive_2016,
	title = {Adaptive {Somatic} {Mutations} {Calls} with {Deep} {Learning} and {Semi}-{Simulated} {Data}},
	urldate = {2017-05-30},
	journal = {bioRxiv},
	author = {Torracinta, Remi and Mesnard, Laurent and Levine, Susan and Shaknovich, Rita and Hanson, Maureen and Campagne, Fabien},
	year = {2016},
}

@inproceedings{manikandan_acceleration_2016,
	title = {Acceleration of the {Pair}-{HMM} {Algorithm} for {DNA} {Variant} {Calling}},
	isbn = {VO -},
	doi = {10.1109/FCCM.2016.42},
	abstract = {In this project, we propose an SoC solution to accelerate the Pair-HMM's forward algorithm which is the key performance bottleneck in the GATK's HaplotypeCaller tool for DNA variant calling. We develop two versions of the Pair-HMM accelerator: one using High Level Synthesis (HLS), and another ring-based manual RTL implementation. We investigate the performance of the manual RTL design and HLS design in terms of design flexibility and overall run-time. We achieve a significant speed-up of up to 19x through the HLS implementation and speed-up of up to 95x through the RTL implementation of the algorithm.},
	booktitle = {2016 {IEEE} 24th {Annual} {International} {Symposium} on {Field}-{Programmable} {Custom} {Computing} {Machines} ({FCCM})},
	author = {Manikandan, G J and Huang, S and Rupnow, K and Hwu, W M W and Chen, D},
	year = {2016},
	keywords = {Acceleration, Algorithm design and analysis, Arrays, DNA, DNA variant calling, Field programmable gate arrays, GATK HaplotypeCaller tool, HLS design, Hardware, Manuals, RTL design, SoC solution, Software, biology computing, hidden Markov models, high level synthesis, molecular biophysics, pair-HMM accelerator, pair-HMM algorithm, performance evaluation, ring-based manual RTL implementation, system-on-chip},
	pages = {137},
}

@article{hofer_systematic_2016,
	title = {A {Systematic} {Approach} to {Creation} of a {Perioperative} {Data} {Warehouse}},
	volume = {122},
	issn = {0003-2999},
	url = {https://journals.lww.com/anesthesia-analgesia/Fulltext/2016/06000/A_Systematic_Approach_to_Creation_of_a.25.aspx},
	abstract = {Extraction of data from the electronic medical record is becoming increasingly important for quality improvement initiatives such as the American Society of Anesthesiologists Perioperative Surgical Home. To meet this need, the authors have built a robust and scalable data mart based on their implementation of EPIC containing data from across the perioperative period. The data mart is structured in such a way so as to first simplify the overall EPIC reporting structure into a series of Base Tables and then create several Reporting Schemas each around a specific concept (operating room cases, obstetrics, hospital admission, etc.), which contain all of the data required for reporting on various metrics. This structure allows centralized definitions with simplified reporting by a large number of individuals who access only the Reporting Schemas. In creating the database, the authors were able to significantly reduce the number of required table identifiers from {\textgreater}10 to 3, as well as to correct errors in linkages affecting up to 18.4\% of cases. In addition, the data mart greatly simplified the code required to extract data, making the data accessible to individuals who lacked a strong coding background. Overall, this infrastructure represents a scalable way to successfully report on perioperative EPIC data while standardizing the definitions and improving access for end users.},
	number = {6},
	journal = {Anesthesia \& Analgesia},
	author = {Hofer, Ira S and Gabel, Eilon and Pfeffer, Michael and Mahbouba, Mohammed and Mahajan, Aman},
	year = {2016},
}

@article{zhang_system_2018,
	title = {A {System} for {Automated} {Determination} of {Perioperative} {Patient} {Acuity}},
	volume = {42},
	issn = {1573-689X},
	url = {https://doi.org/10.1007/s10916-018-0977-7},
	doi = {10.1007/s10916-018-0977-7},
	abstract = {The widely used American Society of Anesthesiologists Physical Status (ASA PS) classification is subjective, requires manual clinician review to score, and has limited granularity. Our objective was to develop a system that automatically generates an ASA PS with finer granularity by creating a continuous ASA PS score. Supervised machine learning methods were used to create a model that predicts a patient’s ASA PS on a continuous scale using the patient’s home medications and comorbidities. Three different types of predictive models were trained: regression models, ordinal models, and classification models. The performance and agreement of each model to anesthesiologists were compared by calculating the mean squared error (MSE), rounded MSE and Cohen’s Kappa on a holdout set. To assess model performance on continuous ASA PS, model rankings were compared to two anesthesiologists on a subset of ASA PS 3 case pairs. The random forest regression model achieved the best MSE and rounded MSE. A model consisting of three random forest classifiers (split model) achieved the best Cohen’s Kappa. The model’s agreement with our anesthesiologists on the ASA PS 3 case pairs yielded fair to moderate Kappa values. The results suggest that the random forest split classification model can predict ASA PS with agreement similar to that of anesthesiologists reported in literature and produce a continuous score in which agreement in accurately judging granularity is fair to moderate.},
	number = {7},
	journal = {Journal of Medical Systems},
	author = {Zhang, Linda and Fabbri, Daniel and Lasko, Thomas A and Ehrenfeld, Jesse M and Wanderer, Jonathan P},
	year = {2018},
	pages = {123},
}

@article{vacanti_statistical_1970,
	title = {A statistical analysis of the relationship of physical status to postoperative mortality in 68.368 cases},
	volume = {49},
	issn = {0003-2999},
	abstract = {said: “It is a fact that to anaesthetize LEARNED British high-court judge once human being, to deprive him of conscious- ness outright, is to take a considerable step along the road to killing him.”l Each year many thousand Americans face the hazards of surgery and anesthesia. The vast ma- jority live through this experience; some few do not. The advent of automatic data processing systems and computers has al- lowed the compilation of many individual experiences from numerous geographic lo- cations. This report attempts to correlate the patient’s preoperative physical status with mortality.A},
	journal = {Anesth Analg},
	author = {Vacanti, Charles J and Van Houten, Robert J and Hill, Robert C},
	year = {1970},
	pmid = {5534668},
	keywords = {97115, GO, Mortality, Rutines preoperat, analysis},
	pages = {564},
}

@inproceedings{puttegowda_run-time_nodate,
	title = {A run-time reconfigurable system for gene-sequence searching},
	isbn = {0-7695-1868-0},
	url = {http://ieeexplore.ieee.org/document/1183193/},
	doi = {10.1109/ICVD.2003.1183193},
	urldate = {2017-04-18},
	booktitle = {16th {International} {Conference} on {VLSI} {Design}, 2003. {Proceedings}.},
	publisher = {IEEE Comput. Soc},
	author = {Puttegowda, K. and Worek, W. and Pappas, N. and Dandapani, A. and Athanas, P. and Dickerman, A.},
	pages = {561--566},
}

@article{depristo_framework_2011,
	title = {A framework for variation discovery and genotyping using next-generation {DNA} sequencing data},
	volume = {43},
	issn = {1061-4036},
	url = {http://dx.doi.org/10.1038/ng.806},
	number = {5},
	journal = {Nat Genet},
	author = {DePristo, Mark A and Banks, Eric and Poplin, Ryan and Garimella, Kiran V and Maguire, Jared R and Hartl, Christopher and Philippakis, Anthony A and del Angel, Guillermo and Rivas, Manuel A and Hanna, Matt and McKenna, Aaron and Fennell, Tim J and Kernytsky, Andrew M and Sivachenko, Andrey Y and Cibulskis, Kristian and Gabriel, Stacey B and Altshuler, David and Daly, Mark J},
	month = may,
	year = {2011},
	note = {Publisher: Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	pages = {491--498},
}

@article{gulshan_development_2016,
	title = {Development and {Validation} of a {Deep} {Learning} {Algorithm} for {Detection} of {Diabetic} {Retinopathy} in {Retinal} {Fundus} {Photographs}},
	volume = {316},
	issn = {0098-7484},
	url = {https://jamanetwork.com/journals/jama/fullarticle/2588763},
	doi = {10.1001/jama.2016.17216},
	abstract = {{\textless}h3{\textgreater}Importance{\textless}/h3{\textgreater}{\textless}p{\textgreater}Deep learning is a family of computational methods that allow an algorithm to program itself by learning from a large set of examples that demonstrate the desired behavior, removing the need to specify rules explicitly. Application of these methods to medical imaging requires further assessment and validation.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Objective{\textless}/h3{\textgreater}{\textless}p{\textgreater}To apply deep learning to create an algorithm for automated detection of diabetic retinopathy and diabetic macular edema in retinal fundus photographs.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Design and Setting{\textless}/h3{\textgreater}{\textless}p{\textgreater}A specific type of neural network optimized for image classification called a deep convolutional neural network was trained using a retrospective development data set of 128 175 retinal images, which were graded 3 to 7 times for diabetic retinopathy, diabetic macular edema, and image gradability by a panel of 54 US licensed ophthalmologists and ophthalmology senior residents between May and December 2015. The resultant algorithm was validated in January and February 2016 using 2 separate data sets, both graded by at least 7 US board-certified ophthalmologists with high intragrader consistency.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Exposure{\textless}/h3{\textgreater}{\textless}p{\textgreater}Deep learning–trained algorithm.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Main Outcomes and Measures{\textless}/h3{\textgreater}{\textless}p{\textgreater}The sensitivity and specificity of the algorithm for detecting referable diabetic retinopathy (RDR), defined as moderate and worse diabetic retinopathy, referable diabetic macular edema, or both, were generated based on the reference standard of the majority decision of the ophthalmologist panel. The algorithm was evaluated at 2 operating points selected from the development set, one selected for high specificity and another for high sensitivity.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Results{\textless}/h3{\textgreater}{\textless}p{\textgreater}The EyePACS-1 data set consisted of 9963 images from 4997 patients (mean age, 54.4 years; 62.2\% women; prevalence of RDR, 683/8878 fully gradable images [7.8\%]); the Messidor-2 data set had 1748 images from 874 patients (mean age, 57.6 years; 42.6\% women; prevalence of RDR, 254/1745 fully gradable images [14.6\%]). For detecting RDR, the algorithm had an area under the receiver operating curve of 0.991 (95\% CI, 0.988-0.993) for EyePACS-1 and 0.990 (95\% CI, 0.986-0.995) for Messidor-2. Using the first operating cut point with high specificity, for EyePACS-1, the sensitivity was 90.3\% (95\% CI, 87.5\%-92.7\%) and the specificity was 98.1\% (95\% CI, 97.8\%-98.5\%). For Messidor-2, the sensitivity was 87.0\% (95\% CI, 81.1\%-91.0\%) and the specificity was 98.5\% (95\% CI, 97.7\%-99.1\%). Using a second operating point with high sensitivity in the development set, for EyePACS-1 the sensitivity was 97.5\% and specificity was 93.4\% and for Messidor-2 the sensitivity was 96.1\% and specificity was 93.9\%.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Conclusions and Relevance{\textless}/h3{\textgreater}{\textless}p{\textgreater}In this evaluation of retinal fundus photographs from adults with diabetes, an algorithm based on deep machine learning had high sensitivity and specificity for detecting referable diabetic retinopathy. Further research is necessary to determine the feasibility of applying this algorithm in the clinical setting and to determine whether use of the algorithm could lead to improved care and outcomes compared with current ophthalmologic assessment.{\textless}/p{\textgreater}},
	language = {en},
	number = {22},
	urldate = {2019-05-20},
	journal = {JAMA},
	author = {Gulshan, Varun and Peng, Lily and Coram, Marc and Stumpe, Martin C. and Wu, Derek and Narayanaswamy, Arunachalam and Venugopalan, Subhashini and Widner, Kasumi and Madams, Tom and Cuadros, Jorge and Kim, Ramasamy and Raman, Rajiv and Nelson, Philip C. and Mega, Jessica L. and Webster, Dale R.},
	month = dec,
	year = {2016},
	pages = {2402--2410},
}

@article{martin_bland_statistical_1986,
	title = {{STATISTICAL} {METHODS} {FOR} {ASSESSING} {AGREEMENT} {BETWEEN} {TWO} {METHODS} {OF} {CLINICAL} {MEASUREMENT}},
	volume = {327},
	url = {http://www.sciencedirect.com/science/article/pii/S0140673686908378},
	doi = {10.1016/S0140-6736(86)90837-8},
	abstract = {In clinical measurement comparison of a new measurement technique with an established one is often needed to see whether they agree sufficiently for the new to replace the old. Such investigations are often analysed inappropriately, notably by using correlation coefficients. The use of correlation is misleading. An alternative approach, based on graphical techniques and simple calculations, is described, together with the relation between this analysis and the assessment of repeatability.},
	number = {8476},
	journal = {The Lancet},
	author = {Martin Bland, J and Altman, DouglasG.},
	year = {1986},
	pages = {307--310},
}

@article{s._universal_2018,
	title = {A {Universal} {Standard} for the {Validation} of {Blood} {Pressure} {Measuring} {Devices}},
	volume = {71},
	url = {https://doi.org/10.1161/HYPERTENSIONAHA.117.10237},
	doi = {10.1161/HYPERTENSIONAHA.117.10237},
	number = {3},
	journal = {Hypertension},
	author = {S., Stergiou George and Bruce, Alpert and Stephan, Mieke and Roland, Asmar and Neil, Atkins and Siegfried, Eckert and Gerhard, Frick and Bruce, Friedman and Thomas, Graßl and Tsutomu, Ichikawa and P., Ioannidis John and Peter, Lacy and Richard, McManus and Alan, Murray and Martin, Myers and Paolo, Palatini and Gianfranco, Parati and David, Quinn and Josh, Sarkis and Andrew, Shennan and Takashi, Usuda and Jiguang, Wang and O., Wu Colin and Eoin, O’Brien},
	month = mar,
	year = {2018},
	pages = {368--374},
}

@article{komorowski_artificial_2018,
	title = {The {Artificial} {Intelligence} {Clinician} learns optimal treatment strategies for sepsis in intensive care},
	url = {https://doi.org/10.1038/s41591-018-0213-5},
	doi = {10.1038/s41591-018-0213-5},
	abstract = {Sepsis is the third leading cause of death worldwide and the main cause of mortality in hospitals1–3, but the best treatment strategy remains uncertain. In particular, evidence suggests that current practices in the administration of intravenous fluids and vasopressors are suboptimal and likely induce harm in a proportion of patients1,4–6. To tackle this sequential decision-making problem, we developed a reinforcement learning agent, the Artificial Intelligence (AI) Clinician, which extracted implicit knowledge from an amount of patient data that exceeds by many-fold the life-time experience of human clinicians and learned optimal treatment by analyzing a myriad of (mostly suboptimal) treatment decisions. We demonstrate that the value of the AI Clinician’s selected treatment is on average reliably higher than human clinicians. In a large validation cohort independent of the training data, mortality was lowest in patients for whom clinicians’ actual doses matched the AI decisions. Our model provides individualized and clinically interpretable treatment decisions for sepsis that could improve patient outcomes.},
	journal = {Nature Medicine},
	author = {Komorowski, Matthieu and Celi, Leo A and Badawi, Omar and Gordon, Anthony C and Faisal, A Aldo},
	year = {2018},
}

@article{corey_development_2018,
	title = {Development and validation of machine learning models to identify high-risk surgical patients using automatically curated electronic health record data ({Pythia}): {A} retrospective, single-site study},
	volume = {15},
	url = {https://doi.org/10.1371/journal.pmed.1002701},
	abstract = {Leveraging a single-site surgical EHR data pipeline and repository, Kristin Corey and colleagues present a machine learning-based detection of high-risk surgical patients at their institution.},
	number = {11},
	journal = {PLOS Medicine},
	author = {Corey, Kristin M and Kashyap, Sehj and Lorenzi, Elizabeth and Lagoo-Deenadayalan, Sandhya A and Heller, Katherine and Whalen, Krista and Balu, Suresh and Heflin, Mitchell T and McDonald, Shelley R and Swaminathan, Madhav and Sendak, Mark},
	month = nov,
	year = {2018},
	pages = {e1002701--e1002701},
}

@article{kim_accuracy_2014,
	title = {Accuracy and {Precision} of {Continuous} {Noninvasive} {Arterial} {Pressure} {Monitoring} {Compared} with {Invasive} {Arterial} {Pressure}: {A} {Systematic} {Review} and {Meta}-analysis},
	volume = {120},
	url = {https://dx.doi.org/10.1097/ALN.0000000000000226},
	doi = {10.1097/ALN.0000000000000226},
	abstract = {Continuous noninvasive arterial pressure monitoring devices are available for bedside use, but the accuracy and precision of these devices have not been evaluated in a systematic review and meta-analysis. The authors performed a systematic review and meta-analysis of studies comparing continuous noninvasive arterial pressure monitoring with invasive arterial pressure monitoring. Random-effects pooled bias and SD of bias for systolic arterial pressure, diastolic arterial pressure, and mean arterial pressure were calculated. Continuous noninvasive arterial pressure monitoring was considered acceptable if pooled estimates of bias and SD were not greater than 5 and 8 mmHg, respectively, as recommended by the Association for the Advancement of Medical Instrumentation. Twenty-eight studies (919 patients) were included. The overall random-effect pooled bias and SD were −1.6 ± 12.2 mmHg (95\% limits of agreement −25.5 to 22.2 mmHg) for systolic arterial pressure, 5.3 ± 8.3 mmHg (−11.0 to 21.6 mmHg) for diastolic arterial pressure, and 3.2 ± 8.4 mmHg (−13.4 to 19.7 mmHg) for mean arterial pressure. In 14 studies focusing on currently commercially available devices, bias and SD were −1.8 ± 12.4 mmHg (−26.2 to 22.5 mmHg) for systolic arterial pressure, 6.0 ± 8.6 mmHg (−10.9 to 22.9 mmHg) for diastolic arterial pressure, and 3.9 ± 8.7 mmHg (−13.1 to 21.0 mmHg) for mean arterial pressure. The results from this meta-analysis found that inaccuracy and imprecision of continuous noninvasive arterial pressure monitoring devices are larger than what was defined as acceptable. This may have implications for clinical situations where continuous noninvasive arterial pressure is being used for patient care decisions.},
	number = {5},
	journal = {Anesthesiology: The Journal of the American Society of Anesthesiologists},
	author = {Kim, Sang-Hyun and Lilot, Marc and Sidhu, Kulraj S and Rinehart, Joseph and Yu, Zhaoxia and Canales, Cecilia and Cannesson, Maxime},
	month = may,
	year = {2014},
	pages = {1080--1097},
}

@article{hannun_cardiologist-level_2019,
	title = {Cardiologist-level arrhythmia detection and classification in ambulatory electrocardiograms using a deep neural network},
	volume = {25},
	url = {https://doi.org/10.1038/s41591-018-0268-3},
	doi = {10.1038/s41591-018-0268-3},
	abstract = {Computerized electrocardiogram (ECG) interpretation plays a critical role in the clinical ECG workflow1. Widely available digital ECG data and the algorithmic paradigm of deep learning2 present an opportunity to substantially improve the accuracy and scalability of automated ECG analysis. However, a comprehensive evaluation of an end-to-end deep learning approach for ECG analysis across a wide variety of diagnostic classes has not been previously reported. Here, we develop a deep neural network (DNN) to classify 12 rhythm classes using 91,232 single-lead ECGs from 53,549 patients who used a single-lead ambulatory ECG monitoring device. When validated against an independent test dataset annotated by a consensus committee of board-certified practicing cardiologists, the DNN achieved an average area under the receiver operating characteristic curve (ROC) of 0.97. The average F1 score, which is the harmonic mean of the positive predictive value and sensitivity, for the DNN (0.837) exceeded that of average cardiologists (0.780). With specificity fixed at the average specificity achieved by cardiologists, the sensitivity of the DNN exceeded the average cardiologist sensitivity for all rhythm classes. These findings demonstrate that an end-to-end deep learning approach can classify a broad range of distinct arrhythmias from single-lead ECGs with high diagnostic performance similar to that of cardiologists. If confirmed in clinical settings, this approach could reduce the rate of misdiagnosed computerized ECG interpretations and improve the efficiency of expert human ECG interpretation by accurately triaging or prioritizing the most urgent conditions.},
	number = {1},
	journal = {Nature Medicine},
	author = {Hannun, Awni Y and Rajpurkar, Pranav and Haghpanahi, Masoumeh and Tison, Geoffrey H and Bourn, Codie and Turakhia, Mintu P and Ng, Andrew Y},
	year = {2019},
	pages = {65--69},
}

@article{buttner_test_2019,
	title = {A test metric for assessing single-cell {RNA}-seq batch correction},
	volume = {16},
	url = {https://doi.org/10.1038/s41592-018-0254-1},
	doi = {10.1038/s41592-018-0254-1},
	abstract = {Single-cell transcriptomics is a versatile tool for exploring heterogeneous cell populations, but as with all genomics experiments, batch effects can hamper data integration and interpretation. The success of batch-effect correction is often evaluated by visual inspection of low-dimensional embeddings, which are inherently imprecise. Here we present a user-friendly, robust and sensitive k-nearest-neighbor batch-effect test (kBET; https://github.com/theislab/kBET) for quantification of batch effects. We used kBET to assess commonly used batch-regression and normalization approaches, and to quantify the extent to which they remove batch effects while preserving biological variability. We also demonstrate the application of kBET to data from peripheral blood mononuclear cells (PBMCs) from healthy donors to distinguish cell-type-specific inter-individual variability from changes in relative proportions of cell populations. This has important implications for future data-integration efforts, central to projects such as the Human Cell Atlas.},
	number = {1},
	journal = {Nature Methods},
	author = {Büttner, Maren and Miao, Zhichao and Wolf, F Alexander and Teichmann, Sarah A and Theis, Fabian J},
	year = {2019},
	pages = {43--49},
}

@article{lin_conceft_2017,
	title = {{ConceFT} for {Time}-{Varying} {Heart} {Rate} {Variability} {Analysis} as a {Measure} of {Noxious} {Stimulation} {During} {General} {Anesthesia}},
	volume = {64},
	doi = {10.1109/TBME.2016.2549048},
	number = {1},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Lin, Y and Wu, H},
	year = {2017},
	keywords = {Algorithms, Analgesia analysis, Anesthesia, Anesthetics, ConceFT, Electrocardiography, General, HRV index, Heart Rate Determination, Heart rate variability, Humans, Intraoperative, Monitoring, Physical Stimulation, Physiology, Reproducibility of Results, Sensitivity and Specificity, Software, Time-frequency analysis, Transforms, analgesia, autonomic nerve system, bioelectric potentials, clinical anesthesia, concentration of frequency and time, electroencephalography, endotracheal intubation, general anesthesia, heart rate reading, heart rate variability, human body, multitaper technique, neurophysiology, nonlinear time-frequency analysis, noxious stimulation measurement, skin, surgical skin incision, synchrosqueezing transform, synchrosqueezing transform (SST), time-frequency analysis, time-varying HRV analysis, time-varying high-frequency power, time-varying low-frequency power, time-varying low-high ratio, time–frequency analysis},
	pages = {145--154},
}

@book{su_predicting_2017,
	title = {Predicting {Blood} {Pressure} with {Deep} {Bidirectional} {LSTM} {Network}},
	author = {Su, Peng and Ding, Xiaorong and Zhang, Yuanting and Li, Ye and Zhao, Ni},
	month = may,
	year = {2017},
}

@article{liang_photoplethysmography_2018,
	title = {Photoplethysmography and {Deep} {Learning}: {Enhancing} {Hypertension} {Risk} {Stratification}},
	volume = {8},
	url = {https://www.ncbi.nlm.nih.gov/pubmed/30373211},
	doi = {10.3390/bios8040101},
	abstract = {Blood pressure is a basic physiological parameter in the cardiovascular circulatory system. Long-term abnormal blood pressure will lead to various cardiovascular diseases, making the early detection and assessment of hypertension profoundly significant for the prevention and treatment of cardiovascular diseases. In this paper, we investigate whether or not deep learning can provide better results for hypertension risk stratification when compared to the classical signal processing and feature extraction methods. We tested a deep learning method for the classification and evaluation of hypertension using photoplethysmography (PPG) signals based on the continuous wavelet transform (using Morse) and pretrained convolutional neural network (using GoogLeNet). We collected 121 data recordings from the Multiparameter Intelligent Monitoring in Intensive Care (MIMIC) Database, each containing arterial blood pressure (ABP) and photoplethysmography (PPG) signals. The ABP signals were utilized to extract blood pressure category labels, and the PPG signals were used to train and test the model. According to the seventh report of the Joint National Committee, blood pressure levels are categorized as normotension (NT), prehypertension (PHT), and hypertension (HT). For the early diagnosis and assessment of HT, the timely detection of PHT and the accurate diagnosis of HT are significant. Therefore, three HT classification trials were set: NT vs. PHT, NT vs. HT, and (NT + PHT) vs. HT. The F-scores of these three classification trials were 80.52\%, 92.55\%, and 82.95\%, respectively. The tested deep method achieved higher accuracy for hypertension risk stratification when compared to the classical signal processing and feature extraction method. Additionally, the method achieved comparable results to another approach that requires electrocardiogram and PPG signals.},
	language = {eng},
	number = {4},
	journal = {Biosensors},
	author = {Liang, Yongbo and Chen, Zhencheng and Ward, Rabab and Elgendi, Mohamed},
	month = oct,
	year = {2018},
	pages = {101--101},
}

@inproceedings{sahoo_wavelet_2011,
	title = {Wavelet based pulse rate and {Blood} pressure estimation system from {ECG} and {PPG} signals},
	isbn = {978-1-4244-9393-7},
	url = {http://ieeexplore.ieee.org/document/5762486/},
	doi = {10.1109/ICCCET.2011.5762486},
	booktitle = {2011 {International} {Conference} on {Computer}, {Communication} and {Electrical} {Technology} ({ICCCET})},
	publisher = {IEEE},
	author = {Sahoo, Ashima and Manimegalai, P and Thanushkodi, K},
	month = mar,
	year = {2011},
	keywords = {Biomedical monitoring, Blood pressure, DWT, Discrete wavelet transforms, ECG, Electrocardiography, LabVIEW, MATLAB, PPG, PTT, Pulse measurements, REALTIME, blood pressure measurement, cardiac disorder, cardiology, discrete wavelet transform, discrete wavelet transforms, electrocardiography, health monitoring, mathematics computing, medical disorders, medical signal processing, noninvasive cuff-less blood pressure estimation sy, photoplethysmography, pulse rate estimation system, pulse transit time technique, signal denoising},
	pages = {285--289},
}

@article{xing_optical_2016,
	title = {Optical blood pressure estimation with photoplethysmography and {FFT}-based neural networks},
	volume = {7},
	url = {http://www.osapublishing.org/boe/abstract.cfm?URI=boe-7-8-3007},
	doi = {10.1364/BOE.7.003007},
	abstract = {We introduce and validate a beat-to-beat optical blood pressure (BP) estimation paradigm using only photoplethysmogram (PPG) signal from finger tips. The scheme determines subject-specific contribution to PPG signal and removes most of its influence by proper normalization. Key features such as amplitudes and phases of cardiac components were extracted by a fast Fourier transform and were used to train an artificial neural network, which was then used to estimate BP from PPG. Validation was done on 69 patients from the MIMIC II database plus 23 volunteers. All estimations showed a good correlation with the reference values. This method is fast and robust, and can potentially be used to perform pulse wave analysis in addition to BP estimation.},
	number = {8},
	journal = {Biomedical Optics Express},
	author = {Xing, Xiaoman and Sun, Mingshan},
	year = {2016},
	keywords = {Biological sensing and sensors, Blood, Clinical applications, Fast Fourier transforms, Feature extraction, Medical optics instrumentation, Neural networks, Pattern recognition, Wave propagation},
	pages = {3007--3020},
}

@article{movius_use_1998,
	title = {Use of pulse oximetry for blood pressure measurement after cardiac surgery},
	volume = {78},
	url = {https://www.ncbi.nlm.nih.gov/pubmed/9659094},
	doi = {10.1136/adc.78.5.457},
	abstract = {Blood pressure measurement using pulse oximeter waveform change was compared with an oscillometric measurement and the gold standard, intra-arterial measurement, in children after cardiac surgery. Forty six patients were enrolled and divided into groups according to weight. Simultaneous blood pressure measurements were obtained from the arterial catheter, the oscillometric device, and the pulse oximeter. Pulse oximeter measurements were obtained with a blood pressure cuff proximal to the oximeter probe. The blood pressure measurements from the pulse oximeter method correlated better with intra-arterial measurements than those from the oscillometric device (0.77-0.96 v 0.42-0.83). The absolute differences between the pulse oximeter and intra-arterial measurements were significantly smaller than between the oscillometric and intra-arterial measurements in children less than 15.0 kg. The pulse oximeter waveform change is an accurate and reliable way to measure blood pressure in children non-invasively, and is superior to the oscillometric method for small patients.},
	language = {eng},
	number = {5},
	journal = {Archives of disease in childhood},
	author = {Movius, A J and Bratton, S L and Sorensen, G K},
	month = may,
	year = {1998},
	pages = {457--460},
}

@inproceedings{teng_continuous_2003,
	title = {Continuous and noninvasive estimation of arterial blood pressure using a photoplethysmographic approach},
	volume = {4},
	isbn = {0-7803-7789-3},
	url = {http://ieeexplore.ieee.org/document/1280811/},
	doi = {10.1109/IEMBS.2003.1280811},
	booktitle = {Proceedings of the 25th {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society} ({IEEE} {Cat}. {No}.{03CH37439})},
	publisher = {IEEE},
	author = {Teng, X.F. and Zhang, Y.T.},
	year = {2003},
	keywords = {0.02 mmHg, 0.21 mmHg, 4.39 mmHg, 7.32 mmHg, Arterial blood pressure, Biomedical monitoring, Blood pressure, Cardiovascular diseases, Condition monitoring, Measurement standards, Mercury (metals), Noninvasive treatment, Pressure measurement, Space vector pulse width modulation, arterial blood pressure, biomechanics, blood pressure measurement, blood vessels, cardiovascular diseases, cardiovascular system, continuous estimation, diastolic blood pressure, diastolic time, diseases, medical signal processing, noninvasive estimation, photoplethysmographic signals, plethysmography, pulse amplitude, step-climbing exercise, systolic blood pressure, systolic upstroke time},
	pages = {3153--3156},
}

@inproceedings{kurylyak_neural_2013,
	title = {A {Neural} {Network}-based method for continuous blood pressure estimation from a {PPG} signal},
	isbn = {978-1-4673-4623-8},
	url = {http://ieeexplore.ieee.org/document/6555424/},
	doi = {10.1109/I2MTC.2013.6555424},
	booktitle = {2013 {IEEE} {International} {Instrumentation} and {Measurement} {Technology} {Conference} ({I2MTC})},
	publisher = {IEEE},
	author = {Kurylyak, Yuriy and Lamonaca, Francesco and Grimaldi, Domenico},
	month = may,
	year = {2013},
	keywords = {ANN input vector, American National Standards of the Association for, Artificial Neural Network, Artificial neural networks, Biomedical monitoring, Blood pressure, Estimation, Linear regression, Monitoring, Multiparameter Intelligent Monitoring in Intensive, Neurons, PPG signal, blood pressure, blood pressure measurement, blood pressure-pulse duration relation, continuous blood pressure estimation, estimated value, estimation method accuracy, feature extraction, heartbeat analysis, hypertension, linear regression method, medical signal processing, neural nets, neural network-based method, neural networks, parameter extraction, photoplethysmography, photoplethysmography signal, possible pulse representation, pressure variation representation, reference value, regression analysis, training data extraction},
	pages = {280--283},
}

@article{ding_pulse_2017,
	title = {Pulse {Transit} {Time} {Based} {Continuous} {Cuffless} {Blood} {Pressure} {Estimation}: {A} {New} {Extension} and {A} {Comprehensive} {Evaluation}},
	volume = {7},
	url = {https://doi.org/10.1038/s41598-017-11507-3},
	doi = {10.1038/s41598-017-11507-3},
	abstract = {Cuffless technique enables continuous blood pressure (BP) measurement in an unobtrusive manner, and thus has the potential to revolutionize the conventional cuff-based approaches. This study extends the pulse transit time (PTT) based cuffless BP measurement method by introducing a new indicator – the photoplethysmogram (PPG) intensity ratio (PIR). The performance of the models with PTT and PIR was comprehensively evaluated in comparison with six models that are based on sole PTT. The validation conducted on 33 subjects with and without hypertension, at rest and under various maneuvers with induced BP changes, and over an extended calibration interval, respectively. The results showed that, comparing to the PTT models, the proposed methods achieved better accuracy on each subject group at rest state and over 24 hours calibration interval. Although the BP estimation errors under dynamic maneuvers and over extended calibration interval were significantly increased for all methods, the proposed methods still outperformed the compared methods in the latter situation. These findings suggest that additional BP-related indicator other than PTT has added value for improving the accuracy of cuffless BP measurement. This study also offers insights into future research in cuffless BP measurement for tracking dynamic BP changes and over extended periods of time.},
	number = {1},
	journal = {Scientific Reports},
	author = {Ding, Xiaorong and Yan, Bryan P and Zhang, Yuan-Ting and Liu, Jing and Zhao, Ni and Tsang, Hon Ki},
	year = {2017},
	pages = {11554--11554},
}

@article{bastarache_phenotype_2018,
	title = {Phenotype risk scores identify patients with unrecognized {Mendelian} disease patterns},
	volume = {359},
	url = {http://science.sciencemag.org/content/359/6381/1233},
	doi = {10.1126/science.aal4043},
	abstract = {Identifying the determinate factors of genetic disease has been quite successful for Mendelian inheritance of large-effect pathogenic variants. In these cases, two non- or low-functioning genes contribute to disease. However, Mendelian effects of lesser strength have generally been ignored when looking at genomic consequences in human health. Bastarache et al. used electronic records to identify the phenotypic effects of previously unidentified Mendelian variations. Their analysis suggests that individuals with undiagnosed Mendelian diseases may be more prevalent in the general population than assumed. Because of this, genetic analysis may be able to assist clinicians in arriving at a diagnosis.Science, this issue p. 1233Genetic association studies often examine features independently, potentially missing subpopulations with multiple phenotypes that share a single cause. We describe an approach that aggregates phenotypes on the basis of patterns described by Mendelian diseases. We mapped the clinical features of 1204 Mendelian diseases into phenotypes captured from the electronic health record (EHR) and summarized this evidence as phenotype risk scores (PheRSs). In an initial validation, PheRS distinguished cases and controls of five Mendelian diseases. Applying PheRS to 21,701 genotyped individuals uncovered 18 associations between rare variants and phenotypes consistent with Mendelian diseases. In 16 patients, the rare genetic variants were associated with severe outcomes such as organ transplants. PheRS can augment rare-variant interpretation and may identify subsets of patients with distinct genetic causes for common diseases.},
	number = {6381},
	journal = {Science},
	author = {Bastarache, Lisa and Hughey, Jacob J and Hebbring, Scott and Marlo, Joy and Zhao, Wanke and Ho, Wanting T and Van Driest, Sara L and McGregor, Tracy L and Mosley, Jonathan D and Wells, Quinn S and Temple, Michael and Ramirez, Andrea H and Carroll, Robert and Osterman, Travis and Edwards, Todd and Ruderfer, Douglas and Velez Edwards, Digna R and Hamid, Rizwan and Cogan, Joy and Glazer, Andrew and Wei, Wei-Qi and Feng, QiPing and Brilliant, Murray and Zhao, Zhizhuang J and Cox, Nancy J and Roden, Dan M and Denny, Joshua C},
	month = mar,
	year = {2018},
	pages = {1233--1239},
}

@article{kent_human_2002,
	title = {The human genome browser at {UCSC}.},
	volume = {12},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/12045153},
	doi = {10.1101/gr.229102},
	abstract = {As vertebrate genome sequences near completion and research refocuses to their analysis, the issue of effective genome annotation display becomes critical. A mature web tool for rapid and reliable display of any requested portion of the genome at any scale, together with several dozen aligned annotation tracks, is provided at http://genome.ucsc.edu. This browser displays assembly contigs and gaps, mRNA and expressed sequence tag alignments, multiple gene predictions, cross-species homologies, single nucleotide polymorphisms, sequence-tagged sites, radiation hybrid data, transposon repeats, and more as a stack of coregistered tracks. Text and sequence-based searches provide quick and precise access to any region of specific interest. Secondary links from individual features lead to sequence details and supplementary off-site databases. One-half of the annotation tracks are computed at the University of California, Santa Cruz from publicly available sequence data; collaborators worldwide provide the rest. Users can stably add their own custom tracks to the browser for educational or research purposes. The conceptual and technical framework of the browser, its underlying MYSQL database, and overall use are described. The web site currently serves over 50,000 pages per day to over 3000 different users.},
	number = {6},
	journal = {Genome research},
	author = {Kent, W James and Sugnet, Charles W and Furey, Terrence S and Roskin, Krishna M and Pringle, Tom H and Zahler, Alan M and Haussler, David},
	month = jun,
	year = {2002},
	pages = {996--1006},
}

@article{dong_image_2016,
	title = {Image {Super}-{Resolution} {Using} {Deep} {Convolutional} {Networks}},
	volume = {38},
	doi = {10.1109/TPAMI.2015.2439281},
	number = {2},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Dong, C and Loy, C C and He, K and Tang, X},
	year = {2016},
	keywords = {CNN, Convolutional codes, Feature extraction, Image reconstruction, Image resolution, Neural networks, Super-resolution, Training, color channel, convolution, deep convolutional neural network, deep convolutional neural networks, deep learning method, end-to-end mapping, image resolution, image restoration, image super-resolution, learning (artificial intelligence), low-resolution image, neural nets, reconstruction quality, sparse coding, sparse-coding},
	pages = {295--307},
}

@inproceedings{kim_accurate_2016,
	title = {Accurate image super-resolution using very deep convolutional networks},
	booktitle = {Proceedings of the {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Kim, Jiwon and Kwon Lee, Jung and Mu Lee, Kyoung},
	year = {2016},
	pages = {1646--1654},
}

@article{zhao_loss_2017,
	title = {Loss {Functions} for {Image} {Restoration} {With} {Neural} {Networks}},
	volume = {3},
	doi = {10.1109/TCI.2016.2644865},
	number = {1},
	journal = {IEEE Transactions on Computational Imaging},
	author = {Zhao, H and Gallo, O and Frosio, I and Kautz, J},
	year = {2017},
	keywords = {Image processing, Image quality, Image restoration, Measurement, Neural networks, computer vision, image processing, image restoration, loss function, loss functions, neural nets, neural network, neural networks, perceptually-motivated loss},
	pages = {47--57},
}

@inproceedings{dahl_pixel_2017,
	title = {Pixel {Recursive} {Super} {Resolution}},
	isbn = {VO -},
	doi = {10.1109/ICCV.2017.581},
	booktitle = {2017 {IEEE} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	author = {Dahl, R and Norouzi, M and Shlens, J},
	year = {2017},
	keywords = {Buildings, Gallium nitride, Image resolution, Predictive models, Probabilistic logic, Signal resolution, Training, given low resolution image, high magnification factors, image reconstruction, image resolution, image synthesis, low resolution photograph, particular resolution techniques, pixel recursive super resolution model, plausible high resolution images, plausible high resolution version, traditional super resolution techniques},
	pages = {5449--5458},
}

@article{romano_raisr:_2017,
	title = {{RAISR}: {Rapid} and {Accurate} {Image} {Super} {Resolution}},
	volume = {3},
	doi = {10.1109/TCI.2016.2629284},
	number = {1},
	journal = {IEEE Transactions on Computational Imaging},
	author = {Romano, Y and Isidoro, J and Milanfar, P},
	year = {2017},
	keywords = {Complexity theory, Filter Learning, Image resolution, Image restoration, Interpolation, Memory management, RAISR, Training, contrast enhancement, image enhancement, image quality, image resolution, image sharpening, rapid and accurate image superresolution, super resolution},
	pages = {110--125},
}

@article{hayat_super-resolution_2017,
	title = {Super-{Resolution} via {Deep} {Learning}},
	volume = {abs/1706.0},
	url = {http://arxiv.org/abs/1706.09077},
	journal = {CoRR},
	author = {Hayat, Khizar},
	year = {2017},
}

@article{mao_image_2016,
	title = {Image {Restoration} {Using} {Convolutional} {Auto}-encoders with {Symmetric} {Skip} {Connections}},
	volume = {abs/1606.0},
	url = {http://arxiv.org/abs/1606.08921},
	journal = {CoRR},
	author = {Mao, Xiao-Jiao and Shen, Chunhua and Yang, Yu-Bin},
	year = {2016},
}

@article{ledig_photo-realistic_2016,
	title = {Photo-{Realistic} {Single} {Image} {Super}-{Resolution} {Using} a {Generative} {Adversarial} {Network}},
	volume = {abs/1609.0},
	url = {http://arxiv.org/abs/1609.04802},
	journal = {CoRR},
	author = {Ledig, Christian and Theis, Lucas and Huszar, Ferenc and Caballero, Jose and Aitken, Andrew P and Tejani, Alykhan and Totz, Johannes and Wang, Zehan and Shi, Wenzhe},
	year = {2016},
}

@article{pingault_using_2018,
	title = {Using genetic data to strengthen causal inference in observational research},
	url = {https://doi.org/10.1038/s41576-018-0020-3},
	doi = {10.1038/s41576-018-0020-3},
	abstract = {Causal inference is essential across the biomedical, behavioural and social sciences.By progressing from confounded statistical associations to evidence of causal relationships, causal inference can reveal complex pathways underlying traits and diseases and help to prioritize targets for intervention. Recent progress in genetic epidemiology — including statistical innovation, massive genotyped data sets and novel computational tools for deep data mining — has fostered the intense development of methods exploiting genetic data and relatedness to strengthen causal inference in observational research. In this Review, we describe how such genetically informed methods differ in their rationale, applicability and inherent limitations and outline how they should be integrated in the future to offer a rich causal inference toolbox.},
	journal = {Nature Reviews Genetics},
	author = {Pingault, Jean-Baptiste and O’Reilly, Paul F and Schoeler, Tabea and Ploubidis, George B and Rijsdijk, Frühling and Dudbridge, Frank},
	year = {2018},
}

@article{potter_single-cell_2018,
	title = {Single-cell {RNA} sequencing for the study of development, physiology and disease},
	volume = {14},
	url = {https://doi.org/10.1038/s41581-018-0021-7},
	doi = {10.1038/s41581-018-0021-7},
	abstract = {An ongoing technological revolution is continually improving our ability to carry out very high-resolution studies of gene expression patterns. Current technology enables the global gene expression profiles of single cells to be defined, facilitating dissection of heterogeneity in cell populations that was previously hidden. In contrast to gene expression studies that use bulk RNA samples and provide only a virtual average of the diverse constituent cells, single-cell studies enable the molecular distinction of all cell types within a complex population mix, such as a tumour or developing organ. For instance, single-cell gene expression profiling has contributed to improved understanding of how histologically identical, adjacent cells make different differentiation decisions during development. Beyond development, single-cell gene expression studies have enabled the characteristics of previously known cell types to be more fully defined and facilitated the identification of novel categories of cells, contributing to improvements in our understanding of both normal and disease-related physiological processes and leading to the identification of new treatment approaches. Although limitations remain to be overcome, technology for the analysis of single-cell gene expression patterns is improving rapidly and beginning to provide a detailed atlas of the gene expression patterns of all cell types in the human body.},
	number = {8},
	journal = {Nature Reviews Nephrology},
	author = {Potter, S Steven},
	year = {2018},
	pages = {479--492},
}

@article{hernan_estimating_2006,
	title = {Estimating causal effects from epidemiological data},
	volume = {60},
	url = {http://jech.bmj.com/content/60/7/578.abstract},
	abstract = {In ideal randomised experiments, association is causation: association measures can be interpreted as effect measures because randomisation ensures that the exposed and the unexposed are exchangeable. On the other hand, in observational studies, association is not generally causation: association measures cannot be interpreted as effect measures because the exposed and the unexposed are not generally exchangeable. However, observational research is often the only alternative for causal inference. This article reviews a condition that permits the estimation of causal effects from observational data, and two methods—standardisation and inverse probability weighting—to estimate population causal effects under that condition. For simplicity, the main description is restricted to dichotomous variables and assumes that no random error attributable to sampling variability exists. The appendix provides a generalisation of inverse probability weighting.},
	number = {7},
	journal = {Journal of Epidemiology and Community Health},
	author = {Hernán, Miguel A and Robins, James M},
	month = jul,
	year = {2006},
	pages = {578 LP--586},
}

@article{hill_preoperative_2018,
	title = {Preoperative predictions of in-hospital mortality using electronic medical record data},
	url = {https://www.biorxiv.org/content/early/2018/05/25/329813.1},
	doi = {10.1101/329813},
	abstract = {Background: Predicting preoperative in-hospital mortality using readily-available electronic medical record (EMR) data can aid clinicians in accurately and rapidly determining surgical risk. While previous work has shown that the American Society of Anesthesiologists (ASA) Physical Status Classification is a useful, though subjective, feature for predicting surgical outcomes, obtaining this classification requires a clinician to review the patient\{{\textbackslash}textquoteright\}s medical records. Our goal here is to create an improved risk score using electronic medical records and demonstrate its utility in predicting in-hospital mortality without requiring clinician-derived ASA scores. Methods: Data from 49,513 surgical patients were used to train logistic regression, random forest, and gradient boosted tree classifiers for predicting in-hospital mortality. The features used are readily available before surgery from EMR databases. A gradient boosted tree regression model was trained to impute the ASA Physical Status Classification, and this new, imputed score was included as an additional feature to preoperatively predict in-hospital post-surgical mortality. The preoperative risk prediction was then used as an input feature to a deep neural network (DNN), along with intraoperative features, to predict postoperative in-hospital mortality risk. Performance was measured using the area under the receiver operating characteristic (ROC) curve (AUC). Results: We found that the random forest classifier (AUC 0.921, 95\%CI 0.908-0.934) outperforms logistic regression (AUC 0.871, 95\%CI 0.841-0.900) and gradient boosted trees (AUC 0.897, 95\%CI 0.881-0.912) in predicting in-hospital post-surgical mortality. Using logistic regression, the ASA Physical Status Classification score alone had an AUC of 0.865 (95\%CI 0.848-0.882). Adding preoperative features to the ASA Physical Status Classification improved the random forest AUC to 0.929 (95\%CI 0.915-0.943). Using only automatically obtained preoperative features with no clinician intervention, we found that the random forest model achieved an AUC of 0.921 (95\%CI 0.908-0.934). Integrating the preoperative risk prediction into the DNN for postoperative risk prediction results in an AUC of 0.924 (95\%CI 0.905-0.941), and with both a preoperative and postoperative risk score for each patient, we were able to show that the mortality risk changes over time. Conclusions: Features easily extracted from EMR data can be used to preoperatively predict the risk of in-hospital post-surgical mortality in a fully automated fashion, with accuracy comparable to models trained on features that require clinical expertise. This preoperative risk score can then be compared to the postoperative risk score to show that the risk changes, and therefore should be monitored longitudinally over time.},
	journal = {bioRxiv},
	author = {Hill, Brian and Brown, Robert P and Gabel, Eilon and Lee, Christine and Cannesson, Maxime and Olde Loohuis, Loes and Johnson, Ruth and Jew, Brandon and Maoz, Uri and Mahajan, Aman and Sankararaman, Sriram and Hofer, Ira and Halperin, Eran},
	year = {2018},
}

@article{hoheisel_microarray_2006,
	title = {Microarray technology: beyond transcript profiling and genotype analysis},
	volume = {7},
	url = {http://dx.doi.org/10.1038/nrg1809},
	journal = {Nature Reviews Microbiology},
	author = {Hoheisel, Jörg D},
	month = mar,
	year = {2006},
	pages = {200--200},
}

@article{hernan_instruments_2006,
	title = {Instruments for {Causal} {Inference}: {An} {Epidemiologist}'s {Dream}?},
	volume = {17},
	url = {http://www.jstor.org/stable/20486236},
	abstract = {The use of instrumental variable (IV) methods is attractive because, even in the presence of unmeasured confounding, such methods may consistently estimate the average causal effect of an exposure on an outcome. However, for this consistent estimation to be achieved, several strong conditions must hold. We review the definition of an instrumental variable, describe the conditions required to obtain consistent estimates of causal effects, and explore their implications in the context of a recent application of the instrumental variables approach. We also present (1) a description of the connection between 4 causal models-counterfactuals, causal directed acyclic graphs, nonparametric structural equation models, and linear structural equation models--that have been used to describe instrumental variables methods; (2) a unified presentation of IV methods for the average causal effect in the study population through structural mean models; and (3) a discussion and new extensions of instrumental variables methods based on assumptions of monotonicity.},
	number = {4},
	journal = {Epidemiology},
	author = {Hernán, Miguel A and Robins, James M},
	year = {2006},
	pages = {360--372},
}

@article{hogan_instrumental_2004,
	title = {Instrumental variables and inverse probability weighting for causal inference from longitudinal observational studies},
	volume = {13},
	url = {https://doi.org/10.1191/0962280204sm351ra},
	doi = {10.1191/0962280204sm351ra},
	abstract = {Inferring causal effects from longitudinal repeated measures data has high relevance to a number of areas of research, including economics, social sciences and epidemiology. In observational studies in particular, the treatment receipt mechanism is typically not under the control of the investigator; it can depend on various factors, including the outcome of interest. This results in differential selection into treatment levels, and can lead to selection bias when standard routines such as least squares regression are used to estimate causal effects.Interestingly, both the characterization of and methodology for handling selection bias can differ substantially by disciplinary tradition. In social sciences and economics, instrumental variables (IV) is the standard method for estimating linear and nonlinear models in which the error term may be correlated with an observed covariate. When such correlation is not ruled out, the covariate is called endogenous and least squares estimates of the covariate effect are typically biased. The availability of an instrumental variable can be used to reduce or eliminate the bias.In public health and clinical medicine (e.g., epidemiology and biostatistics), selection bias is typically viewed in terms of confounders, and the prevailing methods are geared toward making proper adjustments via explicit use of observed confounders (e.g., stratification, standardization). A class of methods known as inverse probability weighting (IPW) estimators, which relies on modeling selection in terms of confounders, is gaining in popularity for making such adjustments.Our objective is to review and compare IPW and IV for estimating causal treatment effects from longitudinal data, where the treatment may vary with time. We accomplish this by defining the causal estimands in terms of a linear stochastic model of potential outcomes (counterfactuals). Our comparison includes a review of terminology typically used in discussions of causal inference (e.g., confounding, endogeneity); a review of assumptions required to identify causal effects and their implications for estimation and interpretation; description of estimation via inverse weighting and instrumental variables; and a comparative analysis of data from a longitudinal cohort study of HIV-infected women. In our discussion of assumptions and estimation routines, we try to emphasize sufficient conditions needed to implement relatively standard analyses that can essentially be formulated as regression models. In that sense this review is geared toward the quantitative practitioner.The objective of the data analysis is to estimate the causal (therapeutic) effect of receiving combination antiviral therapy on longitudinal CD4 cell counts, where receipt of therapy varies with time and depends on CD4 count and other covariates. Assumptions are reviewed in context, and resulting inferences are compared. The analysis illustrates the importance of considering the existence of unmeasured confounding and of checking for ?weak instruments.? It also suggests that IV methodology may have a role in longitudinal cohort studies where potential instrumental variables are available.},
	number = {1},
	journal = {Statistical Methods in Medical Research},
	author = {Hogan, Joseph W and Lancaster, Tony},
	month = feb,
	year = {2004},
	pages = {17--48},
}

@article{robins_graphical_1987,
	title = {A graphical approach to the identification and estimation of causal parameters in mortality studies with sustained exposure periods},
	volume = {40},
	url = {https://doi.org/10.1016/S0021-9681(87)80018-8},
	doi = {10.1016/S0021-9681(87)80018-8},
	journal = {Journal of Chronic Diseases},
	author = {Robins, James},
	month = jan,
	year = {1987},
	pages = {139S--161S},
}

@article{rothman_causation_2005,
	title = {Causation and {Causal} {Inference} in {Epidemiology}},
	volume = {95},
	url = {https://doi.org/10.2105/AJPH.2004.059204},
	doi = {10.2105/AJPH.2004.059204},
	abstract = {Concepts of cause and causal inference are largely self-taught from early learning experiences. A model of causation that describes causes in terms of sufficient causes and their component causes illuminates important principles such as multicausality, the dependence of the strength of component causes on the prevalence of complementary component causes, and interaction between component causes.Philosophers agree that causal propositions cannot be proved, and find flaws or practical limitations in all philosophies of causal inference. Hence, the role of logic, belief, and observation in evaluating causal propositions is not settled. Causal inference in epidemiology is better viewed as an exercise in measurement of an effect rather than as a criterion-guided process for deciding whether an effect is present or not.},
	number = {S1},
	journal = {American Journal of Public Health},
	author = {Rothman, Kenneth J and Greenland, Sander},
	month = jul,
	year = {2005},
	pages = {S144--S150},
}

@inproceedings{pearl_causal_2010,
	title = {Causal inference},
	booktitle = {Causality: {Objectives} and {Assessment}},
	author = {Pearl, Judea},
	year = {2010},
	pages = {39--58},
}

@article{kate_prediction_2016,
	title = {Prediction and detection models for acute kidney injury in hospitalized older adults},
	volume = {16},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4812614/},
	doi = {10.1186/s12911-016-0277-4},
	abstract = {BACKGROUND: Acute Kidney Injury (AKI) occurs in at least 5 \% of hospitalized patients and can result in 40–70 \% morbidity and mortality. Even following recovery, many subjects may experience progressive deterioration of renal function. The heterogeneous etiology and pathophysiology of AKI complicates its diagnosis and medical management and can add to poor patient outcomes and incur substantial hospital costs. AKI is predictable and may be avoidable if early risk factors are identified and utilized in the clinical setting. Timely detection of undiagnosed AKI in hospitalized patients can also lead to better disease management. METHODS: Data from 25,521 hospital stays in one calendar year of patients 60 years and older was collected from a large health care system. Four machine learning models (logistic regression, support vector machines, decision trees and naïve Bayes) along with their ensemble were tested for AKI prediction and detection tasks. Patient demographics, laboratory tests, medications and comorbid conditions were used as the predictor variables. The models were compared using the area under ROC curve (AUC) evaluation metric. RESULTS: Logistic regression performed the best for AKI detection (AUC 0.743) and was a close second to the ensemble for AKI prediction (AUC ensemble: 0.664, AUC logistic regression: 0.660). History of prior AKI, use of combination drugs such as ACE inhibitors, NSAIDS and diuretics, and presence of comorbid conditions such as respiratory failure were found significant for both AKI detection and risk prediction. CONCLUSIONS: The machine learning models performed fairly well on both predicting AKI and detecting undiagnosed AKI. To the best of our knowledge, this is the first study examining the difference between prediction and detection of AKI. The distinction has clinical relevance, and can help providers either identify at risk subjects and implement preventative strategies or manage their treatment depending on whether AKI is predicted or detected.},
	journal = {BMC Medical Informatics and Decision Making},
	author = {Kate, Rohit J and Perez, Ruth M and Mazumdar, Debesh and Pasupathy, Kalyan S and Nilakantan, Vani},
	month = mar,
	year = {2016},
	pages = {39--39},
}



@article{price_principal_2006,
	title = {Principal components analysis corrects for stratification in genome-wide association studies},
	volume = {38},
	url = {http://dx.doi.org/10.1038/ng1847},
	journal = {Nature Genetics},
	author = {Price, Alkes L and Patterson, Nick J and Plenge, Robert M and Weinblatt, Michael E and Shadick, Nancy A and Reich, David},
	month = jul,
	year = {2006},
	pages = {904--904},
}

@article{alexander_fast_2009,
	title = {Fast model-based estimation of ancestry in unrelated individuals},
	volume = {19},
	url = {http://genome.cshlp.org/content/19/9/1655.abstract},
	doi = {10.1101/gr.094052.109},
	abstract = {Population stratification has long been recognized as a confounding factor in genetic association studies. Estimated ancestries, derived from multi-locus genotype data, can be used to perform a statistical correction for population stratification. One popular technique for estimation of ancestry is the model-based approach embodied by the widely applied program structure. Another approach, implemented in the program EIGENSTRAT, relies on Principal Component Analysis rather than model-based estimation and does not directly deliver admixture fractions. EIGENSTRAT has gained in popularity in part owing to its remarkable speed in comparison to structure. We present a new algorithm and a program, ADMIXTURE, for model-based estimation of ancestry in unrelated individuals. ADMIXTURE adopts the likelihood model embedded in structure. However, ADMIXTURE runs considerably faster, solving problems in minutes that take structure hours. In many of our experiments, we have found that ADMIXTURE is almost as fast as EIGENSTRAT. The runtime improvements of ADMIXTURE rely on a fast block relaxation scheme using sequential quadratic programming for block updates, coupled with a novel quasi-Newton acceleration of convergence. Our algorithm also runs faster and with greater accuracy than the implementation of an Expectation-Maximization (EM) algorithm incorporated in the program FRAPPE. Our simulations show that ADMIXTURE's maximum likelihood estimates of the underlying admixture coefficients and ancestral allele frequencies are as accurate as structure's Bayesian estimates. On real-world data sets, ADMIXTURE's estimates are directly comparable to those from structure and EIGENSTRAT. Taken together, our results show that ADMIXTURE's computational speed opens up the possibility of using a much larger set of markers in model-based ancestry estimation and that its estimates are suitable for use in correcting for population stratification in association studies.},
	number = {9},
	journal = {Genome Research},
	author = {Alexander, David H and Novembre, John and Lange, Kenneth},
	month = sep,
	year = {2009},
	pages = {1655--1664},
}

@article{koyner_development_2018,
	title = {The {Development} of a {Machine} {Learning} {Inpatient} {Acute} {Kidney} {Injury} {Prediction} {Model}*},
	volume = {46},
	url = {https://journals.lww.com/ccmjournal/Fulltext/2018/07000/The_Development_of_a_Machine_Learning_Inpatient.5.aspx},
	abstract = {Objectives: To develop an acute kidney injury risk prediction model using electronic health record data for longitudinal use in hospitalized patients. Design: Observational cohort study. Setting: Tertiary, urban, academic medical center from November 2008 to January 2016. Patients: All adult inpatients without pre-existing renal failure at admission, defined as first serum creatinine greater than or equal to 3.0 mg/dL, International Classification of Diseases, 9th Edition, code for chronic kidney disease stage 4 or higher or having received renal replacement therapy within 48 hours of first serum creatinine measurement. Interventions: None. Measurements and Main Results: Demographics, vital signs, diagnostics, and interventions were used in a Gradient Boosting Machine algorithm to predict serum creatinine–based Kidney Disease Improving Global Outcomes stage 2 acute kidney injury, with 60\% of the data used for derivation and 40\% for validation. Area under the receiver operator characteristic curve (AUC) was calculated in the validation cohort, and subgroup analyses were conducted across admission serum creatinine, acute kidney injury severity, and hospital location. Among the 121,158 included patients, 17,482 (14.4\%) developed any Kidney Disease Improving Global Outcomes acute kidney injury, with 4,251 (3.5\%) developing stage 2. The AUC (95\% CI) was 0.90 (0.90–0.90) for predicting stage 2 acute kidney injury within 24 hours and 0.87 (0.87–0.87) within 48 hours. The AUC was 0.96 (0.96–0.96) for receipt of renal replacement therapy (n = 821) in the next 48 hours. Accuracy was similar across hospital settings (ICU, wards, and emergency department) and admitting serum creatinine groupings. At a probability threshold of greater than or equal to 0.022, the algorithm had a sensitivity of 84\% and a specificity of 85\% for stage 2 acute kidney injury and predicted the development of stage 2 a median of 41 hours (interquartile range, 12–141 hr) prior to the development of stage 2 acute kidney injury. Conclusions: Readily available electronic health record data can be used to predict impending acute kidney injury prior to changes in serum creatinine with excellent accuracy across different patient locations and admission serum creatinine. Real-time use of this model would allow early interventions for those at high risk of acute kidney injury.},
	number = {7},
	journal = {Critical Care Medicine},
	author = {Koyner, Jay L and Carey, Kyle A and Edelson, Dana P and Churpek, Matthew M},
	year = {2018},
	keywords = {acute kidney injury, biomarker, electronic health record, risk assessment},
}

@article{le_manach_preoperative_2016,
	title = {Preoperative {Score} to {Predict} {Postoperative} {Mortality} ({POSPOM})},
	volume = {124},
	issn = {0000000000000},
	url = {http://insights.ovid.com/crossref?an=00000542-201603000-00016},
	doi = {10.1097/ALN.0000000000000972},
	abstract = {BACKGROUND: An accurate risk score able to predict in-hospital mortality in patients undergoing surgery may improve both risk communication and clinical decision making. The aim of the study was to develop and validate a surgical risk score based solely on preoperative information, for predicting in-hospital mortality. METHODS: From January 1, 2010, to December 31, 2010, data related to all surgeries requiring anesthesia were collected from all centers (single hospital or hospitals group) in France performing more than 500 operations in the year on patients aged 18 yr or older (n = 5,507,834). International Statistical Classification of Diseases, 10th revision codes were used to summarize the medical history of patients. From these data, the authors developed a risk score by examining 29 preoperative factors (age, comorbidities, and surgery type) in 2,717,902 patients, and then validated the risk score in a separate cohort of 2,789,932 patients. RESULTS: In the derivation cohort, there were 12,786 in-hospital deaths (0.47\%; 95\% CI, 0.46 to 0.48\%), whereas in the validation cohort there were 14,933 in-hospital deaths (0.54\%; 95\% CI, 0.53 to 0.55\%). Seventeen predictors were identified and included in the PreOperative Score to predict PostOperative Mortality (POSPOM). POSPOM showed good calibration and excellent discrimination for in-hospital mortality, with a c-statistic of 0.944 (95\% CI, 0.943 to 0.945) in the development cohort and 0.929 (95\% CI, 0.928 to 0.931) in the validation cohort. CONCLUSION: The authors have developed and validated POSPOM, a simple risk score for the prediction of in-hospital mortality in surgical patients.},
	number = {3},
	journal = {Anesthesiology},
	author = {Le Manach, Yannick and Collins, Gary and Rodseth, Reitze and Le Bihan-Benjamin, Christine and Biccard, Bruce and Riou, Bruno and Devereaux, P.J. and Landais, Paul},
	month = mar,
	year = {2016},
	pages = {570--579},
}

@article{greenland_causal_1999,
	title = {Causal {Diagrams} for {Epidemiologic} {Research}},
	volume = {10},
	url = {http://www.jstor.org/stable/3702180},
	abstract = {Causal diagrams have a long history of informal use and, more recently, have undergone formal development for applications in expert systems and robotics. We provide an introduction to these developments and their use in epidemiologic research. Causal diagrams can provide a starting point for identifying variables that must be measured and controlled to obtain unconfounded effect estimates. They also provide a method for critical evaluation of traditional epidemiologic criteria for confounding. In particular, they reveal certain heretofore unnoticed shortcomings of those criteria when used in considering multiple potential confounders. We show how to modify the traditional criteria to correct those shortcomings.},
	number = {1},
	journal = {Epidemiology},
	author = {Greenland, Sander and Pearl, Judea and Robins, James M},
	year = {1999},
	pages = {37--48},
}

@article{sigakis_validity_2016,
	title = {The {Validity} of {Discharge} {Billing} {Codes} {Reflecting} {Severe} {Maternal} {Morbidity}},
	issn = {1526-7598 (Electronic) 0003-2999 (Linking)},
	doi = {10.1213/ANE.0000000000001436},
	abstract = {BACKGROUND: Discharge diagnoses are used to track national trends and patterns of maternal morbidity. There are few data regarding the validity of the International Classification of Diseases (ICD) codes used for this purpose. The goal of our study was to try to better understand the validity of administrative data being used to monitor and assess trends in morbidity.{\textbackslash}nMETHODS: Hospital stay billing records were queried to identify all delivery admissions at the Massachusetts General Hospital for the time period 2001 to 2011 and the University of Michigan Health System for the time period 2005 to 2011. From this, we identified patients with ICD-9-Clinical Modification (CM) diagnosis and procedure codes indicative of severe maternal morbidity. Each patient was classified with 1 of 18 different medical/obstetric categories (conditions or procedures) based on the ICD-9-CM code that was recorded. Within each category, 20 patients from each institution were selected at random, and the corresponding medical charts were reviewed to determine whether the ICD-9-CM code was assigned correctly. The percentage of correct codes for each of 18 preselected clinical categories was calculated yielding a positive predictive value (PPV) and 99\% confidence interval (CI).{\textbackslash}nRESULTS: The overall number of correctly assigned ICD-9-CM codes, or PPV, was 218 of 255 (86\%; CI, 79\%-90\%) and 154 of 188 (82\%; CI, 74\%-88\%) at Massachusetts General Hospital and University of Michigan Health System, respectively (combined PPV, 372/443 [84\%; CI, 79-88\%]). Codes within 4 categories (Hysterectomy, Pulmonary edema, Disorders of fluid, electrolyte and acid-base balance, and Sepsis) had a 99\% lower confidence limit ≥75\%. Codes within 8 additional categories demonstrated a 99\% lower confidence limit between 74\% and 50\% (Acute respiratory distress, Ventilation, Other complications of obstetric surgery, Disorders of coagulation, Cardiomonitoring, Acute renal failure, Thromboembolism, and Shock). Codes within 6 clinical categories demonstrated a 99\% lower confidence limit {\textless}50\% (Puerperal cerebrovascular disorders, Conversion of cardiac rhythm, Acute heart failure [includes arrest and fibrillation], Eclampsia, Neurotrauma, and Severe anesthesia complications).{\textbackslash}nCONCLUSIONS: ICD-9-CM codes capturing severe maternal morbidity during delivery hospitalization demonstrate a range of PPVs. The PPV was high when objective supportive evidence, such as laboratory values or procedure documentation supported the ICD-9-CM code. The PPV was low when greater judgment, interpretation, and synthesis of the clinical data (signs and symptoms) was required to support a code, such as with the category Severe anesthesia complications. As a result, these codes should be used for administrative research with more caution compared with codes primarily defined by objective data.},
	journal = {Anesthesia and Analgesia},
	author = {Sigakis, Matthew J.G. and Leffert, Lisa R. and Mirzakhani, Hooman and Sharawi, Nadir and Rajala, Baskar and Callaghan, William M. and Kuklina, Elena V. and Creanga, Andreea A. and Mhyre, Jill M. and Bateman, Brian T.},
	year = {2016},
}

@article{bilimoria_development_2013,
	title = {Development and evaluation of the universal {ACS} {NSQIP} surgical risk calculator: {A} decision aid and informed consent tool for patients and surgeons},
	issn = {1879-1190 (Electronic){\textbackslash}r1072-7515 (Linking)},
	doi = {10.1016/j.jamcollsurg.2013.07.385},
	abstract = {Background Accurately estimating surgical risks is critical for shared decision making and informed consent. The Centers for Medicare and Medicaid Services may soon put forth a measure requiring surgeons to provide patients with patient-specific, empirically derived estimates of postoperative complications. Our objectives were to develop a universal surgical risk estimation tool, to compare performance of the universal vs previous procedure-specific surgical risk calculators, and to allow surgeons to empirically adjust the estimates of risk. Study Design Using standardized clinical data from 393 ACS NSQIP hospitals, a web-based tool was developed to allow surgeons to easily enter 21 preoperative factors (demographics, comorbidities, procedure). Regression models were developed to predict 8 outcomes based on the preoperative risk factors. The universal model was compared with procedure-specific models. To incorporate surgeon input, a subjective surgeon adjustment score, allowing risk estimates to vary within the estimate's confidence interval, was introduced and tested with 80 surgeons using 10 case scenarios. Results Based on 1,414,006 patients encompassing 1,557 unique CPT codes, a universal surgical risk calculator model was developed that had excellent performance for mortality (c-statistic = 0.944; Brier score = 0.011 [where scores approaching 0 are better]), morbidity (c-statistic = 0.816, Brier score = 0.069), and 6 additional complications (c-statistics {\textgreater} 0.8). Predictions were similarly robust for the universal calculator vs procedure-specific calculators (eg, colorectal). Surgeons demonstrated considerable agreement on the case scenario scoring (80\% to 100\% agreement), suggesting reliable score assignment between surgeons. Conclusions The ACS NSQIP surgical risk calculator is a decision-support tool based on reliable multi-institutional clinical data, which can be used to estimate the risks of most operations. The ACS NSQIP surgical risk calculator will allow clinicians and patients to make decisions using empirically derived, patient-specific postoperative risks. © 2013 by the American College of Surgeons.},
	journal = {Journal of the American College of Surgeons},
	author = {Bilimoria, Karl Y. and Liu, Yaoming and Paruch, Jennifer L. and Zhou, Lynn and Kmiecik, Thomas E. and Ko, Clifford Y. and Cohen, Mark E.},
	year = {2013},
}

@article{chu_epigenome-wide_2017,
	title = {Epigenome-wide association studies identify {DNA} methylation associated with kidney function},
	volume = {8},
	url = {https://doi.org/10.1038/s41467-017-01297-7},
	doi = {10.1038/s41467-017-01297-7},
	abstract = {Chronic kidney disease (CKD) is defined by reduced estimated glomerular filtration rate (eGFR). Previous genetic studies have implicated regulatory mechanisms contributing to CKD. Here we present epigenome-wide association studies of eGFR and CKD using whole-blood DNA methylation of 2264 ARIC Study and 2595 Framingham Heart Study participants to identify epigenetic signatures of kidney function. Of 19 CpG sites significantly associated (P {\textless} 1e-07) with eGFR/CKD and replicated, five also associate with renal fibrosis in biopsies from CKD patients and show concordant DNA methylation changes in kidney cortex. Lead CpGs at PTPN6/PHB2, ANKRD11, and TNRC18 map to active enhancers in kidney cortex. At PTPN6/PHB2 cg19942083, methylation in kidney cortex associates with lower renal PTPN6 expression, higher eGFR, and less renal fibrosis. The regions containing the 243 eGFR-associated (P {\textless} 1e-05) CpGs are significantly enriched for transcription factor binding sites of EBF1, EP300, and CEBPB (P {\textless} 5e-6). Our findings highlight kidney function associated epigenetic variation.},
	number = {1},
	journal = {Nature Communications},
	author = {Chu, Audrey Y and Tin, Adrienne and Schlosser, Pascal and Ko, Yi-An and Qiu, Chengxiang and Yao, Chen and Joehanes, Roby and Grams, Morgan E and Liang, Liming and Gluck, Caroline A and Liu, Chunyu and Coresh, Josef and Hwang, Shih-Jen and Levy, Daniel and Boerwinkle, Eric and Pankow, James S and Yang, Qiong and Fornage, Myriam and Fox, Caroline S and Susztak, Katalin and Köttgen, Anna},
	year = {2017},
	pages = {1286--1286},
}

@article{kang_early_2012,
	title = {Early {Surgery} versus {Conventional} {Treatment} for {Infective} {Endocarditis}},
	volume = {366},
	url = {https://doi.org/10.1056/NEJMoa1112843},
	doi = {10.1056/NEJMoa1112843},
	number = {26},
	journal = {New England Journal of Medicine},
	author = {Kang, Duk-Hyun and Kim, Yong-Jin and Kim, Sung-Han and Sun, Byung Joo and Kim, Dae-Hee and Yun, Sung-Cheol and Song, Jong-Min and Choo, Suk Jung and Chung, Cheol-Hyun and Song, Jae-Kwan and Lee, Jae-Won and Sohn, Dae-Won},
	month = jun,
	year = {2012},
	pages = {2466--2473},
}

@article{leeds_early_2017,
	title = {Early {Surgical} {Intervention} for {Acute} {Ulcerative} {Colitis} {Is} {Associated} with {Improved} {Postoperative} {Outcomes}},
	issn = {1873-4626 (Electronic) 1091-255X (Linking)},
	doi = {10.1007/s11605-017-3538-3},
	abstract = {BACKGROUND Timing of surgical intervention for acute ulcerative colitis has not been fully examined during the modern immunotherapy era. Although early surgical intervention is recommended, historical consensus for "early" ranges widely. The purpose of this study was to evaluate outcomes according to timing of urgent surgery for acute ulcerative colitis. METHODS All non-elective total colectomies in ulcerative colitis patients were identified in the National Inpatient Sample from 2002 to 2014. Procedures, comorbidities, diagnoses, and in-hospital outcomes were collected using International Classification of Disease, 9th Revision codes. An operation was defined as early if within 24 hours of admission. Results were compared between the early versus delayed surgery groups. RESULTS We found 69,936 patients that were admitted with ulcerative colitis, and 2650 patients that underwent non-elective total colectomy (3.8\%). Early intervention was performed in 20.4\% of patients who went to surgery. More early operations were performed laparoscopically (28.1\% versus 23.3\%, p = 0.021) and on more comorbid patients (Charlson Index, p = 0.008). Median total hospitalization costs were \$20,948 with an early operation versus \$33,666 with a delayed operation (p {\textless} 0.001). Delayed operation was an independent risk for a complication (OR = 1.46, p = 0.001). Increased hospitalization costs in the delayed surgery group were statistically significantly higher with a reported complication (OR = 3.00, p {\textless} 0.001) and lengths of stay (OR = 1.26, p {\textless} 0.001). CONCLUSION Delayed operations for acute ulcerative colitis are associated with increased postoperative complications, increased lengths of stay, and increased hospital costs. Further prospective studies could demonstrate that this association leads to improved outcomes with immediate surgical intervention for medically refractory ulcerative colitis.},
	journal = {Journal of Gastrointestinal Surgery},
	author = {Leeds, Ira L. and Truta, Brindusa and Parian, Alyssa M. and Chen, Sophia Y. and Efron, Jonathan E. and Gearhart, Susan L. and Safar, Bashar and Fang, Sandy H.},
	year = {2017},
	keywords = {Colectomy, Emergency surgery, Refractory, Ulcerative colitis},
}

@article{fogel_artificial_2018,
	title = {Artificial intelligence powers digital medicine},
	issn = {23986352},
	doi = {10.1038/s41746-017-0012-2},
	abstract = {Artificial intelligence (AI) has recently surpassed human performance in several domains, and there is great hope that in healthcare, AI may allow for better prevention, detection, diagnosis, and treatment of disease. While many fear that AI will disrupt jobs and the physician–patient relationship, we believe that AI can eliminate many repetitive tasks to clear the way for human-to-human bonding and the application of emotional intelligence and judgment. We review several recent studies of AI applications in healthcare that provide a view of a future where healthcare delivery is a more unified, human experience.},
	journal = {npj Digital Medicine},
	author = {Fogel, Alexander L. and Kvedar, Joseph C.},
	year = {2018},
}

@article{wasey_icd:_2018,
	title = {icd: {Tools} for {Working} with {ICD}-9 and {ICD}-10 {Codes}, and {Finding} {Comorbidities}},
	url = {https://cran.r-project.org/package=icd},
	author = {Wasey, Jack O},
	year = {2018},
}

@article{witten_penalized_2009,
	title = {A penalized matrix decomposition, with applications to sparse principal components and canonical correlation analysis},
	volume = {10},
	number = {3},
	journal = {Biostatistics},
	author = {Witten, Daniela M and Tibshirani, Robert and Hastie, Trevor},
	year = {2009},
	pages = {515--534},
}

@article{rajkomar_scalable_2018,
	title = {Scalable and accurate deep learning for {EHR} - supplement},
	abstract = {Predictive modeling with electronic health record (EHR) data is anticipated to drive personalized medicine and improve healthcare quality. Constructing predictive statistical models typically requires extraction of curated predictor variables from normalized EHR data, a labor-intensive process that discards the vast majority of information in each patient's record. We propose a representation of patients' entire, raw EHR records based on the Fast Healthcare Interoperability Resources (FHIR) format. We demonstrate that deep learning methods using this representation are capable of accurately predicting multiple medical events from multiple centers without site-specific data harmonization. We validated our approach using de-identified EHR data from two U.S. academic medical centers with 216,221 adult patients hospitalized for at least 24 hours. In the sequential format we propose, this volume of EHR data unrolled into a total of 46,864,534,945 data points, including clinical notes. Deep learning models achieved high accuracy for tasks such as predicting in-hospital mortality (AUROC across sites 0.93-0.94), 30-day unplanned readmission (AUROC 0.75-0.76), prolonged length of stay (AUROC 0.85-0.86), and all of a patient's final discharge diagnoses (frequency-weighted AUROC 0.90). These models outperformed state-of-the-art traditional predictive models in all cases. We also present a case-study of a neural-network attribution system, which illustrates how clinicians can gain some transparency into the predictions. We believe that this approach can be used to create accurate and scalable predictions for a variety of clinical scenarios, complete with explanations that directly highlight evidence in the patient's chart.},
	journal = {npj Digital Medicine},
	author = {Rajkomar, Alvin and Oren, Eyal and Chen, Kai and Dai, Andrew M. and Hajaj, Nissan and Liu, Peter J. and Liu, Xiaobing and Sun, Mimi and Sundberg, Patrik and Yee, Hector and Zhang, Kun and Duggan, Gavin E. and Flores, Gerardo and Hardt, Michaela and Irvine, Jamie and Le, Quoc and Litsch, Kurt and Marcus, Jake and Mossin, Alexander and Tansuwan, Justin and Wang, De and Wexler, James and Wilson, Jimbo and Ludwig, Dana and Volchenboum, Samuel L. and Chou, Katherine and Pearson, Michael and Madabushi, Srinivasan and Shah, Nigam H. and Butte, Atul J. and Howell, Michael and Cui, Claire and Corrado, Greg and Dean, Jeff},
	year = {2018},
}

@inproceedings{zhang_data-driven_2016,
	title = {Data-{Driven} {System} for {Perioperative} {Acuity} {Prediction}.},
	booktitle = {{AMIA}},
	author = {Zhang, Linda and Fabbri, Daniel and Wanderer, Jonathan P},
	year = {2016},
}

@article{kozanitis_genap:_2016,
	title = {{GenAp}: a distributed {SQL} interface for genomic data},
	volume = {17},
	url = {https://doi.org/10.1186/s12859-016-0904-1},
	doi = {10.1186/s12859-016-0904-1},
	abstract = {The impressively low cost and improved quality of genome sequencing provides to researchers of genetic diseases, such as cancer, a powerful tool to better understand the underlying genetic mechanisms of those diseases and treat them with effective targeted therapies. Thus, a number of projects today sequence the DNA of large patient populations each of which produces at least hundreds of terra-bytes of data. Now the challenge is to provide the produced data on demand to interested parties.},
	number = {1},
	journal = {BMC Bioinformatics},
	author = {Kozanitis, Christos and Patterson, David A},
	month = feb,
	year = {2016},
	pages = {63--63},
}

@article{sboner_real_2011,
	title = {The real cost of sequencing: higher than you think!},
	volume = {12},
	url = {https://doi.org/10.1186/gb-2011-12-8-125},
	doi = {10.1186/gb-2011-12-8-125},
	abstract = {Advances in sequencing technology have led to a sharp decrease in the cost of 'data generation'. But is this sufficient to ensure cost-effective and efficient 'knowledge generation'?},
	number = {8},
	journal = {Genome Biology},
	author = {Sboner, Andrea and Mu, Xinmeng Jasmine and Greenbaum, Dov and Auerbach, Raymond K and Gerstein, Mark B},
	month = aug,
	year = {2011},
	pages = {125--125},
}

@article{vandeweyer_variantdb:_2014,
	title = {{VariantDB}: a flexible annotation and filtering portal for next generation sequencing data},
	volume = {6},
	url = {https://doi.org/10.1186/s13073-014-0074-6},
	doi = {10.1186/s13073-014-0074-6},
	abstract = {Interpretation of the multitude of variants obtained from next generation sequencing (NGS) is labor intensive and complex. Web-based interfaces such as Galaxy streamline the generation of variant lists but lack flexibility in the downstream annotation and filtering that are necessary to identify causative variants in medical genomics. To this end, we built VariantDB, a web-based interactive annotation and filtering platform that automatically annotates variants with allele frequencies, functional impact, pathogenicity predictions and pathway information. VariantDB allows filtering by all annotations, under dominant, recessive or de novo inheritance models and is freely available at http://www.biomina.be/app/variantdb/.},
	number = {10},
	journal = {Genome Medicine},
	author = {Vandeweyer, Geert and Van Laer, Lut and Loeys, Bart and den Bulcke, Tim and Kooy, R Frank},
	month = oct,
	year = {2014},
	pages = {74--74},
}

@article{he_big_2017,
	title = {Big {Data} {Analytics} for {Genomic} {Medicine}},
	volume = {18},
	number = {2},
	journal = {International Journal of Molecular Sciences},
	author = {He, Karen Y and Ge, Dongliang and He, Max M},
	year = {2017},
}

@article{wiewiorka_benchmarking_2017,
	title = {Benchmarking distributed data warehouse solutions for storing genomic variant information},
	volume = {2017},
	url = {http://dx.doi.org/10.1093/database/bax049},
	doi = {10.1093/database/bax049},
	journal = {Database},
	author = {Wiewiórka, Marek S and Wysakowicz, Dawid P and Okoniewski, Michał J and Gambin, Tomasz},
	year = {2017},
	pages = {bax049--bax049},
}

@inproceedings{ma_risk_2018,
	series = {{KDD} '18},
	title = {Risk {Prediction} on {Electronic} {Health} {Records} with {Prior} {Medical} {Knowledge}},
	isbn = {978-1-4503-5552-0},
	url = {http://doi.acm.org/10.1145/3219819.3220020},
	doi = {10.1145/3219819.3220020},
	booktitle = {Proceedings of the 24th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {ACM},
	author = {Ma, Fenglong and Gao, Jing and Suo, Qiuling and You, Quanzeng and Zhou, Jing and Zhang, Aidong},
	year = {2018},
	keywords = {healthcare informatics, posterior regularization, prior medical knowledge},
	pages = {1910--1919},
}

@article{purushotham_benchmarking_2018,
	title = {Benchmarking deep learning models on large healthcare datasets},
	volume = {83},
	url = {http://www.sciencedirect.com/science/article/pii/S1532046418300716},
	doi = {10.1016/j.jbi.2018.04.007},
	journal = {Journal of Biomedical Informatics},
	author = {Purushotham, Sanjay and Meng, Chuizheng and Che, Zhengping and Liu, Yan},
	year = {2018},
	keywords = {Deep learning models, ICD-9 code group prediction, Length of stay, Mortality prediction, Super learner algorithm},
	pages = {112--134},
}

@article{hanley_method_1983,
	title = {A method of comparing the areas under receiver operating characteristic curves derived from the same cases.},
	volume = {148},
	url = {https://doi.org/10.1148/radiology.148.3.6878708},
	doi = {10.1148/radiology.148.3.6878708},
	abstract = {Receiver operating characteristic (ROC) curves are used to describe and compare the performance of diagnostic technology and diagnostic algorithms. This paper refines the statistical comparison of the areas under two ROC curves derived from the same set of patients by taking into account the correlation between the areas that is induced by the paired nature of the data. The correspondence between the area under an ROC curve and the Wilcoxon statistic is used and underlying Gaussian distributions (binormal) are assumed to provide a table that converts the observed correlations in paired ratings of images into a correlation between the two ROC areas. This between-area correlation can be used to reduce the standard error (uncertainty) about the observed difference in areas. This correction for pairing, analogous to that used in the paired t-test, can produce a considerable increase in the statistical sensitivity (power) of the comparison. For studies involving multiple readers, this method provides a measure of a component of the sampling variation that is otherwise difficult to obtain.},
	number = {3},
	journal = {Radiology},
	author = {Hanley, J A and McNeil, B J},
	year = {1983},
	pages = {839--843},
}

@article{hildebrandt_genetic_2010,
	title = {Genetic kidney diseases},
	volume = {375},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2898711/},
	doi = {10.1016/S0140-6736(10)60236-X},
	abstract = {Knowledge of the primary cause of a disease is essential for understanding its mechanisms and for adequate classification, prognosis, and treatment. Recently, the etiologies of many kidney diseases have been revealed as single-gene defects. This is exemplified by steroid-resistant nephrotic syndrome, which is caused by podocin mutations in {\textasciitilde}25\% of childhood and {\textasciitilde}15\% of adult cases. Knowledge of a disease-causing mutation in a single-gene disorder represents one of the most robust diagnostic examples of “personalized medicine”, because the mutation conveys an almost 100\% risk of developing the disease by a certain age. Whereas single-gene diseases are rare disorders, polygenic “risk alleles” are found in common adult-onset diseases. This review will discuss prominent renal single-gene kidney disorders and polygenic risk alleles of common disorders. We delineate how emerging techniques of total exome capture and large-scale sequencing will facilitate molecular genetic diagnosis, prognosis and specific therapy and lead to a better understanding of disease mechanisms, thus enabling development of new targeted drugs.},
	number = {9722},
	journal = {Lancet},
	author = {Hildebrandt, Friedhelm},
	month = apr,
	year = {2010},
	pages = {1287--1295},
}

@article{crowe_substance_2000,
	title = {Substance abuse and the kidney},
	volume = {93},
	url = {http://dx.doi.org/10.1093/qjmed/93.3.147},
	abstract = {Substance abuse has been increasing steadily in the UK and some other countries. Recent evidence suggests more than 40\% of young people have tried illicit drugs at some time. There are numerous medical consequences to recreational drug use, and a physician should always consider substance abuse in any unexplained illness. The renal complications of drug abuse are also becoming more frequent, and may encompass a spectrum of glomerular, interstitial and vascular diseases. Although some substances are directly nephrotoxic, a number of other mechanisms are also involved. These effects are often chronic and irreversible, but occasionally acute with possible recovery. The rapid growth of illicit drug use is clearly a major public health problem. We review the commonly used substances of abuse and their associations with renal disease.},
	number = {3},
	journal = {QJM: An International Journal of Medicine},
	author = {CROWE, A V and HOWSE, M and BELL, G M and HENRY, J A},
	month = mar,
	year = {2000},
	pages = {147--152},
}

@article{fored_acetaminophen_2001,
	title = {Acetaminophen, {Aspirin}, and {Chronic} {Renal} {Failure}},
	volume = {345},
	url = {https://doi.org/10.1056/NEJMoa010323},
	doi = {10.1056/NEJMoa010323},
	number = {25},
	journal = {New England Journal of Medicine},
	author = {Fored, C Michael and Ejerblad, Elisabeth and Lindblad, Per and Fryzek, Jon P and Dickman, Paul W and Signorello, Lisa B and Lipworth, Loren and Elinder, Carl-Gustaf and Blot, William J and McLaughlin, Joseph K and Zack, Matthew M and Nyrén, Olof},
	month = dec,
	year = {2001},
	pages = {1801--1808},
}

@article{epstein_alcohols_1997,
	title = {Alcohol's impact on kidney function},
	author = {Epstein, Murray},
	year = {1997},
}

@article{gajjala_cellular_2015,
	title = {Cellular and {Molecular} {Mechanisms} of {Chronic} {Kidney} {Disease} with {Diabetes} {Mellitus} and {Cardiovascular} {Diseases} as {Its} {Comorbidities}},
	volume = {6},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4495338/},
	doi = {10.3389/fimmu.2015.00340},
	abstract = {Chronic kidney disease (CKD), diabetes mellitus (DM), and cardiovascular diseases (CVD) are complex disorders of partly unknown genesis and mostly known progression factors. CVD and DM are the risk factors of CKD and are strongly intertwined since DM can lead to both CKD and/or CVD, and CVD can lead to kidney disease. In recent years, our knowledge of CKD, DM, and CVD has been expanded and several important experimental, clinical, and epidemiological associations have been reported. The tight cellular and molecular interactions between the renal, diabetic, and cardiovascular systems in acute or chronic disease settings are becoming increasingly evident. However, the (patho-) physiological basis of the interactions of CKD, DM, and CVD with involvement of multiple endogenous and environmental factors is highly complex and our knowledge is still at its infancy. Not only single pathways and mediators of progression of these diseases have to be considered in these processes but also the mutual interactions of these factors are essential. The recent advances in proteomics and integrative analysis technologies have allowed rapid progress in analyzing complex disorders and clearly show the opportunity for new efficient and specific therapies. More than a dozen pathways have been identified so far, including hyperactivity of the renin–angiotensin (RAS)–aldosterone system, osmotic sodium retention, endothelial dysfunction, dyslipidemia, RAS/RAF/extracellular-signal-regulated kinase pathway, modification of the purinergic system, phosphatidylinositol 3-kinase (PI 3-kinase)-dependent signaling pathways, and inflammation, all leading to histomorphological alterations of the kidney and vessels of diabetic and non-diabetic patients. Since a better understanding of the common cellular and molecular mechanisms of these diseases may be a key to successful identification of new therapeutic targets, we review in this paper the current literature about cellular and molecular mechanisms of CKD.},
	journal = {Frontiers in Immunology},
	author = {Gajjala, Prathibha Reddy and Sanati, Maryam and Jankowski, Joachim},
	month = jul,
	year = {2015},
	pages = {340--340},
}

@article{yang_models_2010,
	title = {Models of chronic kidney disease},
	volume = {7},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3030258/},
	doi = {10.1016/j.ddmod.2010.08.002},
	abstract = {Chronic kidney diseases result from recurrent or progressive injuries in glomeruli, tubules, interstitium and/or vasculature. In order to study pathogenesis, mechanisms and effects of interventions, many animal models have been developed, including spontaneous, genetic and induced models. However, these models do not exactly simulate human diseases, and most of them are strain, gender or age dependent. We review key information on various rodent models of chronic kidney diseases.},
	number = {1-2},
	journal = {Drug discovery today. Disease models},
	author = {Yang, Hai-Chun and Zuo, Yiqin and Fogo, Agnes B},
	year = {2010},
	pages = {13--19},
}

@article{bosch_rhabdomyolysis_2009,
	title = {Rhabdomyolysis and {Acute} {Kidney} {Injury}},
	volume = {361},
	url = {https://doi.org/10.1056/NEJMra0801327},
	doi = {10.1056/NEJMra0801327},
	number = {1},
	journal = {New England Journal of Medicine},
	author = {Bosch, Xavier and Poch, Esteban and Grau, Josep M},
	month = jul,
	year = {2009},
	pages = {62--72},
}

@article{moher_consort_2001,
	title = {The {CONSORT} statement: revised recommendations for improving the quality of reports of parallel-group randomised trials},
	volume = {357},
	url = {http://www.sciencedirect.com/science/article/pii/S0140673600043373},
	doi = {10.1016/S0140-6736(00)04337-3},
	number = {9263},
	journal = {The Lancet},
	author = {Moher, David and Schulz, Kenneth F and Altman, Douglas G},
	year = {2001},
	pages = {1191--1194},
}

@article{chen_causal_2018,
	title = {Causal risk factor discovery for severe acute kidney injury using electronic health records},
	volume = {18},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5872516/},
	doi = {10.1186/s12911-018-0597-7},
	abstract = {BACKGROUND: Acute kidney injury (AKI), characterized by abrupt deterioration of renal function, is a common clinical event among hospitalized patients and it is associated with high morbidity and mortality. AKI is defined in three stages with stage-3 being the most severe phase which is irreversible. It is important to effectively discover the true risk factors in order to identify high-risk AKI patients and allow better targeting of tailored interventions. However, Stage-3 AKI patients are very rare (only 0.2\% of AKI patients) with a large scale of features available in EHR (1917 potential risk features), yielding a scenario unfeasible for any correlation-based feature selection or modeling method. This study aims to discover the key factors and improve the detection of Stage-3 AKI. METHODS: A causal discovery method (McDSL) is adopted for causal discovery to infer true causal relationship between information buried in EHR (such as medication, diagnosis, laboratory tests, comorbidities and etc.) and Stage-3 AKI risk. The research approach comprised two major phases: data collection, and causal discovery. The first phase is propose to collect the data from HER (includes 358 encounters and 891 risk factors). Finally, McDSL is employed to discover the causal risk factors of Stage-3 AKI, and five well-known machine learning models are built for predicting Stage-3 AKI with 10-fold cross-validation (predictive accuracy were measured by AUC, precision, recall and F-score). RESULTS: McDSL is useful for further research of EHR. It is able to discover four causal features, all selected features are medications that are modifiable. The latest research of machine learning is employed to compare the performance of prediction, and the experimental result has verified the selected features are pivotal. CONCLUSIONS: The features selected by McDSL, which enable us to achieve significant dimension reduction without sacrificing prediction accuracy, suggesting potential clinical use such as helping physicians develop better prevention and treatment strategies.},
	number = {Suppl 1},
	journal = {BMC Medical Informatics and Decision Making},
	author = {Chen, Weiqi and Hu, Yong and Zhang, Xiangzhou and Wu, Lijuan and Liu, Kang and He, Jianqin and Tang, Zilin and Song, Xing and Waitman, Lemuel R and Liu, Mei},
	month = mar,
	year = {2018},
	pages = {13--13},
}



@article{kendale_supervised_2018,
	title = {Supervised {Machine}-learning {Predictive} {Analytics} for {Prediction} of {Postinduction} {Hypotension}},
	volume = {129},
	url = {http://dx.doi.org/10.1097/ALN.0000000000002374},
	abstract = {Abstract Editor’s Perspective: What We Already Know about This Topic: The ability to predict postinduction hypotension remains limited and challenging due to the multitude of data elements that may be considered Novel machine-learning algorithms may offer a systematic approach to predict postinduction hypotension, but are understudied What This Article Tells Us That Is New: Among 13,323 patients undergoing a variety of surgical procedures, 8.9\% experienced a mean arterial pressure less than 55 mmHg within 10 min of induction start While some machine-learning algorithms perform worse than logistic regression, several techniques may be superior Gradient boosting machine, with tuning, demonstrates a receiver operating characteristic area under the curve of 0.76, a negative predictive value of 19\%, and positive predictive value of 96\% Background: Hypotension is a risk factor for adverse perioperative outcomes. Machine-learning methods allow large amounts of data for development of robust predictive analytics. The authors hypothesized that machine-learning methods can provide prediction for the risk of postinduction hypotension. Methods: Data was extracted from the electronic health record of a single quaternary care center from November 2015 to May 2016 for patients over age 12 that underwent general anesthesia, without procedure exclusions. Multiple supervised machine-learning classification techniques were attempted, with postinduction hypotension (mean arterial pressure less than 55 mmHg within 10 min of induction by any measurement) as primary outcome, and preoperative medications, medical comorbidities, induction medications, and intraoperative vital signs as features. Discrimination was assessed using cross-validated area under the receiver operating characteristic curve. The best performing model was tuned and final performance assessed using split-set validation. Results: Out of 13,323 cases, 1,185 (8.9\%) experienced postinduction hypotension. Area under the receiver operating characteristic curve using logistic regression was 0.71 (95\% CI, 0.70 to 0.72), support vector machines was 0.63 (95\% CI, 0.58 to 0.60), naive Bayes was 0.69 (95\% CI, 0.67 to 0.69), k-nearest neighbor was 0.64 (95\% CI, 0.63 to 0.65), linear discriminant analysis was 0.72 (95\% CI, 0.71 to 0.73), random forest was 0.74 (95\% CI, 0.73 to 0.75), neural nets 0.71 (95\% CI, 0.69 to 0.71), and gradient boosting machine 0.76 (95\% CI, 0.75 to 0.77). Test set area for the gradient boosting machine was 0.74 (95\% CI, 0.72 to 0.77). Conclusions: The success of this technique in predicting postinduction hypotension demonstrates feasibility of machine-learning models for predictive analytics in the field of anesthesiology, with performance dependent on model selection and appropriate tuning.},
	number = {4},
	journal = {Anesthesiology},
	author = {Kendale, Samir and Kulkarni, Prathamesh and Rosenberg, Andrew D and Wang, Jing},
	month = oct,
	year = {2018},
	pages = {675--688},
}

@article{hatib_machine-learning_2018,
	title = {Machine-learning {Algorithm} to {Predict} {Hypotension} {Based} on {High}-fidelity {Arterial} {Pressure} {Waveform} {Analysis}},
	volume = {129},
	url = {http://dx.doi.org/10.1097/ALN.0000000000002300},
	abstract = {Abstract Editor’s Perspective: What We Already Know about This Topic: The ability to predict intraoperative hypotension may advance the ability to prevent hypotension-associated complications effectively The extent to which advanced waveform analysis of invasive arterial lines may provide meaningful forewarning remains unknown What This Article Tells Us That Is New: A machine-learning algorithm based on thousands of arterial waveform features can identify an intraoperative hypotensive event 15 min before its occurrence with a sensitivity of 88\% and specificity of 87\% Further studies must evaluate the real-time value of such algorithms in a broader set of clinical conditions and patients Background: With appropriate algorithms, computers can learn to detect patterns and associations in large data sets. The authors’ goal was to apply machine learning to arterial pressure waveforms and create an algorithm to predict hypotension. The algorithm detects early alteration in waveforms that can herald the weakening of cardiovascular compensatory mechanisms affecting preload, afterload, and contractility. Methods: The algorithm was developed with two different data sources: (1) a retrospective cohort, used for training, consisting of 1,334 patients’ records with 545,959 min of arterial waveform recording and 25,461 episodes of hypotension; and (2) a prospective, local hospital cohort used for external validation, consisting of 204 patients’ records with 33,236 min of arterial waveform recording and 1,923 episodes of hypotension. The algorithm relates a large set of features calculated from the high-fidelity arterial pressure waveform to the prediction of an upcoming hypotensive event (mean arterial pressure {\textless} 65 mmHg). Receiver-operating characteristic curve analysis evaluated the algorithm’s success in predicting hypotension, defined as mean arterial pressure less than 65 mmHg. Results: Using 3,022 individual features per cardiac cycle, the algorithm predicted arterial hypotension with a sensitivity and specificity of 88\% (85 to 90\%) and 87\% (85 to 90\%) 15 min before a hypotensive event (area under the curve, 0.95 [0.94 to 0.95]); 89\% (87 to 91\%) and 90\% (87 to 92\%) 10 min before (area under the curve, 0.95 [0.95 to 0.96]); 92\% (90 to 94\%) and 92\% (90 to 94\%) 5 min before (area under the curve, 0.97 [0.97 to 0.98]). Conclusions: The results demonstrate that a machine-learning algorithm can be trained, with large data sets of high-fidelity arterial waveforms, to predict hypotension in surgical patients’ records.},
	number = {4},
	journal = {Anesthesiology},
	author = {Hatib, Feras and Jian, Zhongping and Buddi, Sai and Lee, Christine and Settels, Jos and Sibert, Karen and Rinehart, Joseph and Cannesson, Maxime},
	month = oct,
	year = {2018},
	pages = {663--674},
}

@article{pencina_evaluating_2015,
	title = {Evaluating discrimination of risk prediction models: {The} {C} statistic},
	volume = {314},
	issn = {0098-7484},
	doi = {10.1001/jama.2015.11082},
	abstract = {Risk prediction models help clinicians develop personalized treatments for patients. The models generally use variables measured at one time point to estimate the probability of an outcome occurring within a given time in the future. It is essential to assess the performance of a risk prediction model in the setting in which it will be used. This is done by evaluating the model’s discrimination and calibration. Discrimination refers to the ability of the model to separate individuals who develop events from those who do not. In time-to-event settings, discrimination is the ability of the model to predict who will develop an event earlier and who will develop an event later or not at all. Calibration measures how accurately the model’s predictions match overall observed event rates.},
	number = {10},
	journal = {JAMA - Journal of the American Medical Association},
	author = {Pencina, Michael J. and D'Agostino, Ralph B.},
	year = {2015},
}

@article{rousseeuw_silhouettes:_1987,
	title = {Silhouettes: {A} graphical aid to the interpretation and validation of cluster analysis},
	volume = {20},
	url = {http://www.sciencedirect.com/science/article/pii/0377042787901257},
	doi = {10.1016/0377-0427(87)90125-7},
	journal = {Journal of Computational and Applied Mathematics},
	author = {Rousseeuw, Peter J},
	year = {1987},
	keywords = {Graphical display, classification, cluster analysis, clustering validity},
	pages = {53--65},
}

@article{brennecke_accounting_2013,
	title = {Accounting for technical noise in single-cell {RNA}-seq experiments},
	volume = {10},
	url = {http://dx.doi.org/10.1038/nmeth.2645},
	journal = {Nature Methods},
	author = {Brennecke, Philip and Anders, Simon and Kim, Jong Kyoung and Kołodziejczyk, Aleksandra A and Zhang, Xiuwei and Proserpio, Valentina and Baying, Bianka and Benes, Vladimir and Teichmann, Sarah A and Marioni, John C and Heisler, Marcus G},
	month = sep,
	year = {2013},
	pages = {1093--1093},
}

@article{tibshirani_class_2003,
	title = {Class prediction by nearest shrunken centroids, with applications to {DNA} microarrays},
	journal = {Statistical Science},
	author = {Tibshirani, Robert and Hastie, Trevor and Narasimhan, Balasubramanian and Chu, Gilbert},
	year = {2003},
	pages = {104--117},
}

@article{dudoit_comparison_2002,
	title = {Comparison of {Discrimination} {Methods} for the {Classification} of {Tumors} {Using} {Gene} {Expression} {Data}},
	volume = {97},
	url = {https://doi.org/10.1198/016214502753479248},
	doi = {10.1198/016214502753479248},
	number = {457},
	journal = {Journal of the American Statistical Association},
	author = {Dudoit, Sandrine and Fridlyand, Jane and Speed, Terence P},
	month = mar,
	year = {2002},
	pages = {77--87},
}

@article{gronbech_scvae:_2018,
	title = {{scVAE}: {Variational} auto-encoders for single-cell gene expression data},
	url = {http://biorxiv.org/content/early/2018/05/16/318295.abstract},
	abstract = {We propose a novel variational auto-encoder-based method for analysis of single-cell RNA sequencing (scRNA-seq) data. It avoids data preprocessing by using raw count data as input and can robustly estimate the expected gene expression levels and a latent representation for each cell. We show for several scRNA-seq data sets that our method outperforms recently proposed scRNA-seq methods in clustering cells. Our software tool scVAE has support for several count likelihood functions and a variant of the variational auto-encoder has a priori clustering in the latent space.},
	journal = {bioRxiv},
	author = {Grønbech, Christopher Heje and Vording, Maximillian Fornitz and Timshel, Pascal N and Sønderby, Casper Kaae and Pers, Tune Hannes and Winther, Ole},
	month = jan,
	year = {2018},
}

@article{ghahramani_generative_2018,
	title = {Generative adversarial networks uncover epidermal regulators and predict single cell perturbations},
	url = {http://biorxiv.org/content/early/2018/02/08/262501.abstract},
	abstract = {Recent advances have enabled gene expression profiling of single cells at lower cost. As more data is produced there is an increasing need to integrate diverse datasets and better analyse underutilised data to gain biological insights. However, analysis of single cell RNA-seq data is challenging due to biological and technical noise which not only varies between laboratories but also between batches. Here for the first time, we apply a new generative deep learning approach called Generative Adversarial Networks (GAN) to biological data. We show that it is possible to integrate diverse skin (epidermal) datasets and in doing so, our generative model is able to simulate realistic scRNA-seq data that covers the full diversity of cell types. In contrast to many machine-learning approaches, we are able to interpret internal parameters in a biologically meaningful manner. These include using internal GAN learned features for improved dimensionality reduction. Using our generative model we are able to obtain a universal representation of epidermal differentiation and use this to predict the effect of cell state perturbations on gene expression at high time-resolution. We show that our trained neural networks identify biological state-determining genes and through analysis of these networks we can obtain inferred gene regulatory relationships. In combination these attributes provide a powerful framework to progress the analysis of scRNA-seq data beyond exploratory analysis of cell clusters and towards integration of multiple datasets regardless of origin.},
	journal = {bioRxiv},
	author = {Ghahramani, Arsham and Watt, Fiona M and Luscombe, Nicholas M},
	month = jan,
	year = {2018},
}

@article{wang_deep_2016,
	title = {Deep variational canonical correlation analysis},
	journal = {arXiv preprint arXiv:1610.03454},
	author = {Wang, Weiran and Yan, Xinchen and Lee, Honglak and Livescu, Karen},
	year = {2016},
}

@article{chandar_correlational_2016,
	title = {Correlational neural networks},
	volume = {28},
	number = {2},
	journal = {Neural computation},
	author = {Chandar, Sarath and Khapra, Mitesh M and Larochelle, Hugo and Ravindran, Balaraman},
	year = {2016},
	pages = {257--285},
}

@inproceedings{andrew_deep_2013,
	title = {Deep {Canonical} {Correlation} {Analysis}},
	url = {http://proceedings.mlr.press/v28/andrew13.pdf},
	abstract = {We introduce Deep Canonical Correlation Analysis (DCCA), a method to learn complex nonlinear transformations of two views of data such that the resulting representations are highly linearly correlated. Parameters of both transformations are jointly learned to maximize the (regularized) total correlation. It can be viewed as a nonlinear extension of the linear method {\textbackslash}emphcanonical correlation analysis (CCA). It is an alternative to the nonparametric method {\textbackslash}emphkernel canonical correlation analysis (KCCA) for learning correlated nonlinear transformations. Unlike KCCA, DCCA does not require an inner product, and has the advantages of a parametric method: training time scales well with data size and the training data need not be referenced when computing the representations of unseen instances. In experiments on two real-world datasets, we find that DCCA learns representations with significantly higher correlation than those learned by CCA and KCCA. We also introduce a novel non-saturating sigmoid function based on the cube root that may be useful more generally in feedforward neural networks.},
	publisher = {PMLR},
	author = {Andrew, Galen and Arora, Raman and Bilmes, Jeff and Learning, Karen Livescu B T - Proceedings of the 30th International Conference on Machine},
	editor = {Dasgupta, Sanjoy and McAllester, David},
	month = feb,
	year = {2013},
	pages = {1247--1255},
}

@article{lin_simultaneous_2016,
	title = {Simultaneous dimension reduction and adjustment for confounding variation},
	volume = {113},
	url = {http://www.pnas.org/content/113/51/14662.abstract},
	abstract = {With the advancement in high-throughput technologies, analyzing high-dimensional data has become a common task. Dimension reduction methods have been applied to visualize and identify dominant patterns in high-dimensional data. Confounding factors, commonly observed in high-throughput biological experiments, can affect the performance of these methods, and other downstream analysis. Here, we develop a method by coupling dimension reduction with the adjustment for confounder effects. Our method is able to capture the underlying patterns, as demonstrated by a human brain exon array dataset, a model organism ENCODE RNA sequencing dataset, and simulations.Dimension reduction methods are commonly applied to high-throughput biological datasets. However, the results can be hindered by confounding factors, either biological or technical in origin. In this study, we extend principal component analysis (PCA) to propose AC-PCA for simultaneous dimension reduction and adjustment for confounding (AC) variation. We show that AC-PCA can adjust for (i) variations across individual donors present in a human brain exon array dataset and (ii) variations of different species in a model organism ENCODE RNA sequencing dataset. Our approach is able to recover the anatomical structure of neocortical regions and to capture the shared variation among species during embryonic development. For gene selection purposes, we extend AC-PCA with sparsity constraints and propose and implement an efficient algorithm. The methods developed in this paper can also be applied to more general settings. The R package and MATLAB source code are available at https://github.com/linzx06/AC-PCA.},
	number = {51},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Lin, Zhixiang and Yang, Can and Zhu, Ying and Duchi, John and Fu, Yao and Wang, Yong and Jiang, Bai and Zamanighomi, Mahdi and Xu, Xuming and Li, Mingfeng and Sestan, Nenad and Zhao, Hongyu and Wong, Wing Hung},
	month = dec,
	year = {2016},
	pages = {14662 LP--14667},
}

@inproceedings{liu_supervised_2017,
	title = {Supervised {Deep} {Canonical} {Correlation} {Analysis} for {Multiview} {Feature} {Learning} {BT}  - {Neural} {Information} {Processing}},
	isbn = {978-3-319-70136-3},
	abstract = {Recently, a new feature representation method called deep canonical correlation analysis (DCCA) has been proposed with high learning performance for multiview feature extraction of high dimensional data. DCCA is an effective approach to learn the nonlinear mappings of two sets of random variables that make the resulting DNN representations highly correlated. However, the DCCA learning process is unsupervised and thus lacks the class label information of training samples on the two views. In order to take full advantage of the class information of training samples, we propose a discriminative version of DCCA referred to as supervised DCCA (SDCCA) for feature learning, which explicitly considers the class information of samples. Compared with DCCA, the SDCCA method can not only guarantee the nonlinear maximal correlation between two views, but also minimize within-class scatter of the samples. With supervision, SDCCA can extract more discriminative features for pattern classification tasks. We test SDCCA on the handwriting recognition and speech recognition using two popular MNIST and XRMB datasets. Experimental results show that SDCCA gets higher performance than several related algorithms.},
	publisher = {Springer International Publishing},
	author = {Liu, Yan and Li, Yun and Yuan, Yun-Hao and Qiang, Ji-Peng and Ruan, Min and Zhang, Zhao},
	editor = {Liu, Derong and Xie, Shengli and Li, Yuanqing and Zhao, Dongbin and El-Alfy, El-Sayed M},
	year = {2017},
	pages = {575--582},
}

@article{benton_deep_2017,
	title = {Deep generalized canonical correlation analysis},
	journal = {arXiv preprint arXiv:1702.02519},
	author = {Benton, Adrian and Khayrallah, Huda and Gujral, Biman and Reisinger, Dee Ann and Zhang, Sheng and Arora, Raman},
	year = {2017},
}

@article{lopez_deep_2018,
	title = {Deep generative modeling for single-cell transcriptomics},
	volume = {15},
	url = {https://doi.org/10.1038/s41592-018-0229-2},
	doi = {10.1038/s41592-018-0229-2},
	abstract = {Single-cell transcriptome measurements can reveal unexplored biological diversity, but they suffer from technical noise and bias that must be modeled to account for the resulting uncertainty in downstream analyses. Here we introduce single-cell variational inference (scVI), a ready-to-use scalable framework for the probabilistic representation and analysis of gene expression in single cells (https://github.com/YosefLab/scVI). scVI uses stochastic optimization and deep neural networks to aggregate information across similar cells and genes and to approximate the distributions that underlie observed expression values, while accounting for batch effects and limited sensitivity. We used scVI for a range of fundamental analysis tasks including batch correction, visualization, clustering, and differential expression, and achieved high accuracy for each task.},
	number = {12},
	journal = {Nature Methods},
	author = {Lopez, Romain and Regier, Jeffrey and Cole, Michael B and Jordan, Michael I and Yosef, Nir},
	year = {2018},
	pages = {1053--1058},
}

@article{yarmolinsky_causal_2018,
	title = {Causal {Inference} in {Cancer} {Epidemiology}: {What} {Is} the {Role} of {Mendelian} {Randomization}?},
	volume = {27},
	url = {http://cebp.aacrjournals.org/content/27/9/995.abstract},
	doi = {10.1158/1055-9965.EPI-17-1177},
	abstract = {Observational epidemiologic studies are prone to confounding, measurement error, and reverse causation, undermining robust causal inference. Mendelian randomization (MR) uses genetic variants to proxy modifiable exposures to generate more reliable estimates of the causal effects of these exposures on diseases and their outcomes. MR has seen widespread adoption within cardio-metabolic epidemiology, but also holds much promise for identifying possible interventions for cancer prevention and treatment. However, some methodologic challenges in the implementation of MR are particularly pertinent when applying this method to cancer etiology and prognosis, including reverse causation arising from disease latency and selection bias in studies of cancer progression. These issues must be carefully considered to ensure appropriate design, analysis, and interpretation of such studies. In this review, we provide an overview of the key principles and assumptions of MR, focusing on applications of this method to the study of cancer etiology and prognosis. We summarize recent studies in the cancer literature that have adopted a MR framework to highlight strengths of this approach compared with conventional epidemiological studies. Finally, limitations of MR and recent methodologic developments to address them are discussed, along with the translational opportunities they present to inform public health and clinical interventions in cancer. Cancer Epidemiol Biomarkers Prev; 27(9); 995–1010. ©2018 AACR.},
	number = {9},
	journal = {Cancer Epidemiology Biomarkers \&amp; Prevention},
	author = {Yarmolinsky, James and Wade, Kaitlin H and Richmond, Rebecca C and Langdon, Ryan J and Bull, Caroline J and Tilling, Kate M and Relton, Caroline L and Lewis, Sarah J and Davey Smith, George and Martin, Richard M},
	month = sep,
	year = {2018},
	pages = {995 LP--1010},
}

@article{marouf_realistic_2018,
	title = {Realistic in silico generation and augmentation of single cell {RNA}-seq data using {Generative} {Adversarial} {Neural} {Networks}},
	url = {http://biorxiv.org/content/early/2018/10/24/390153.abstract},
	doi = {10.1101/390153},
	abstract = {A fundamental problem in biomedical research is the low number of observations available, mostly due to a lack of available biosamples, prohibitive costs, or ethical reasons. Augmenting few real observations with generated in silico samples could lead to more robust analysis results and a higher reproducibility rate. Here we propose the use of conditional single cell Generative Adversarial Neural Networks (cscGANs) for the realistic generation of single cell RNA-seq data. cscGANs learn non-linear gene-gene dependencies from complex, multi cell type samples and use this information to generate realistic cells of defined types. Augmenting sparse cell populations with cscGAN generated cells improves downstream analyses such as the detection of marker genes, the robustness and reliability of classifiers, the assessment of novel analysis algorithms, and might reduce the number of animal experiments and costs in consequence. cscGANs outperform existing methods for single cell RNA-seq data generation in quality and hold great promise for the realistic generation and augmentation of other biomedical data types.},
	journal = {bioRxiv},
	author = {Marouf, Mohamed and Machart, Pierre and Magruder, Daniel Sumner Sumner and Bansal, Vikas and Kilian, Christoph and Krebs, Christian F and Bonn, Stefan},
	month = jan,
	year = {2018},
	pages = {390153--390153},
}

@article{eraslan_single_2018,
	title = {Single cell {RNA}-seq denoising using a deep count autoencoder},
	url = {http://biorxiv.org/content/early/2018/04/13/300681.abstract},
	doi = {10.1101/300681},
	abstract = {Single-cell RNA sequencing (scRNA-seq) has enabled researchers to study gene expression at a cellular resolution. However, noise due to amplification and dropout may obstruct analyses, so scalable denoising methods for increasingly large but sparse scRNAseq data are needed. We propose a deep count autoencoder network (DCA) to denoise scRNA-seq datasets. DCA takes the count distribution, overdispersion and sparsity of the data into account using a zero-inflated negative binomial noise model, and nonlinear gene-gene or gene-dispersion interactions are captured. Our method scales linearly with the number of cells and can therefore be applied to datasets of millions of cells. We demonstrate that DCA denoising improves a diverse set of typical scRNA-seq data analyses using simulated and real datasets. DCA outperforms existing methods for data imputation in quality and speed, enhancing biological discovery.},
	journal = {bioRxiv},
	author = {Eraslan, Gökcen and Simon, Lukas M and Mircea, Maria and Mueller, Nikola S and Theis, Fabian J},
	month = jan,
	year = {2018},
	pages = {300681--300681},
}

@inproceedings{richter_building_2018,
	title = {Building and {Interpreting} {Risk} {Models} from {Imbalanced} {Clinical} {Data}},
	isbn = {2375-0197 VO -},
	doi = {10.1109/ICTAI.2018.00031},
	booktitle = {2018 {IEEE} 30th {International} {Conference} on {Tools} with {Artificial} {Intelligence} ({ICTAI})},
	author = {Richter, A N and Khoshgoftaar, T M},
	year = {2018},
	keywords = {Data models, Machine learning, Melanoma, Predictive models, Vegetation, class imbalance, machine learning, sparse matrix},
	pages = {143--150},
}

@article{hie_panoramic_2018,
	title = {Panoramic stitching of heterogeneous single-cell transcriptomic data},
	url = {http://biorxiv.org/content/early/2018/07/17/371179.abstract},
	doi = {10.1101/371179},
	abstract = {Researchers are generating single-cell RNA sequencing (scRNA-seq) profiles of diverse biological systems and every cell type in the human body. Leveraging this data to gain unprecedented insight into biology and disease will require assembling heterogeneous cell populations across multiple experiments, laboratories, and technologies. Although methods for scRNA-seq data integration exist, they often naively merge data sets together even when the data sets have no cell types in common, leading to results that do not correspond to real biological patterns. Here we present Scanorama, inspired by algorithms for panorama stitching, that overcomes the limitations of existing methods to enable accurate, heterogeneous scRNA-seq data set integration. Our strategy identifies and merges the shared cell types among all pairs of data sets and is orders of magnitude faster than existing techniques. We use Scanorama to combine 105,476 cells from 26 diverse scRNA-seq experiments across 9 different technologies into a single comprehensive reference, demonstrating how Scanorama can be used to obtain a more complete picture of cellular function across a wide range of scRNA-seq experiments.},
	journal = {bioRxiv},
	author = {Hie, Brian L and Bryson, Bryan and Berger, Bonnie},
	month = jan,
	year = {2018},
	pages = {371179--371179},
}

@article{wang_vasc:_2018,
	title = {{VASC}: {Dimension} {Reduction} and {Visualization} of {Single}-cell {RNA}-seq {Data} by {Deep} {Variational} {Autoencoder}},
	url = {http://www.sciencedirect.com/science/article/pii/S167202291830439X},
	doi = {10.1016/j.gpb.2018.08.003},
	abstract = {Single-cell RNA sequencing (scRNA-seq) is a powerful technique to analyze the transcriptomic heterogeneities at the single cell level. It is an important step for studying cell sub-populations and lineages, with an effective low-dimensional representation and visualization of the original scRNA-Seq data. At the single cell level, the transcriptional fluctuations are much larger than the average of a cell population, and the low amount of RNA transcripts will increase the rate of technical dropout events. Therefore, scRNA-seq data are much noisier than traditional bulk RNA-seq data. In this study, we proposed the deep variational autoencoder for scRNA-seq data (VASC), a deep multi-layer generative model, for the unsupervised dimension reduction and visualization of scRNA-seq data. VASC can explicitly model the dropout events and find the nonlinear hierarchical feature representations of the original data. Tested on over 20 datasets, VASC shows superior performances in most cases and exhibits broader dataset compatibility compared to four state-of-the-art dimension reduction and visualization methods. In addition, VASC provides better representations for very rare cell populations in the 2D visualization. As a case study, VASC successfully re-establishes the cell dynamics in pre-implantation embryos and identifies several candidate marker genes associated with early embryo development. Moreover, VASC also performs well on a 10× Genomics dataset with more cells and higher dropout rate.},
	journal = {Genomics, Proteomics \& Bioinformatics},
	author = {Wang, Dongfang and Gu, Jin},
	year = {2018},
	keywords = {Deep variational autoencoder, Dimension reduction, Dropout, Single cell RNA sequencing, Visualization},
}

@article{ding_interpretable_2018,
	title = {Interpretable dimensionality reduction of single cell transcriptome data with deep generative models},
	volume = {9},
	url = {https://doi.org/10.1038/s41467-018-04368-5},
	doi = {10.1038/s41467-018-04368-5},
	abstract = {Single-cell RNA-sequencing has great potential to discover cell types, identify cell states, trace development lineages, and reconstruct the spatial organization of cells. However, dimension reduction to interpret structure in single-cell sequencing data remains a challenge. Existing algorithms are either not able to uncover the clustering structures in the data or lose global information such as groups of clusters that are close to each other. We present a robust statistical model, scvis, to capture and visualize the low-dimensional structures in single-cell gene expression data. Simulation results demonstrate that low-dimensional representations learned by scvis preserve both the local and global neighbor structures in the data. In addition, scvis is robust to the number of data points and learns a probabilistic parametric mapping function to add new data points to an existing embedding. We then use scvis to analyze four single-cell RNA-sequencing datasets, exemplifying interpretable two-dimensional representations of the high-dimensional single-cell RNA-sequencing data.},
	number = {1},
	journal = {Nature Communications},
	author = {Ding, Jiarui and Condon, Anne and Shah, Sohrab P},
	year = {2018},
	pages = {2002--2002},
}

@article{kang_multiplexed_2017,
	title = {Multiplexed droplet single-cell {RNA}-sequencing using natural genetic variation},
	volume = {36},
	url = {https://doi.org/10.1038/nbt.4042},
	journal = {Nature Biotechnology},
	author = {Kang, Hyun Min and Subramaniam, Meena and Targ, Sasha and Nguyen, Michelle and Maliskova, Lenka and McCarthy, Elizabeth and Wan, Eunice and Wong, Simon and Byrnes, Lauren and Lanata, Cristina M and Gate, Rachel E and Mostafavi, Sara and Marson, Alexander and Zaitlen, Noah and Criswell, Lindsey A and Ye, Chun Jimmie},
	month = dec,
	year = {2017},
	pages = {89--89},
}

@article{shaham_batch_2018,
	title = {Batch {Effect} {Removal} via {Batch}-{Free} {Encoding}},
	url = {http://biorxiv.org/content/early/2018/07/31/380816.abstract},
	doi = {10.1101/380816},
	abstract = {Biological measurements often contain systematic errors, also known as "batch effects", which may invalidate downstream analysis when not handled correctly. The problem of removing batch effects is of major importance in the biological community. Despite recent advances in this direction via deep learning techniques, most current methods may not fully preserve the true biological patterns the data contains. In this work we propose a deep learning approach for batch effect removal. The crux of our approach is learning a batch-free encoding of the data, representing its intrinsic biological properties, but not batch effects. In addition, we also encode the systematic factors through a decoding mechanism and require accurate reconstruction of the data. Altogether, this allows us to fully preserve the true biological patterns represented in the data. Experimental results are reported on data obtained from two high throughput technologies, mass cytometry and single-cell RNA-seq. Beyond good performance on training data, we also observe that our system performs well on test data obtained from new patients, which was not available at training time. Our method is easy to handle, a publicly available code can be found at https://github.com/ushaham/BatchEffectRemoval2018.},
	journal = {bioRxiv},
	author = {Shaham, Uri},
	month = jan,
	year = {2018},
	pages = {380816--380816},
}

@article{shaham_removal_2017,
	title = {Removal of batch effects using distribution-matching residual networks},
	volume = {33},
	url = {http://dx.doi.org/10.1093/bioinformatics/btx196},
	abstract = {MotivationSources of variability in experimentally derived data include measurement error in addition to the physical phenomena of interest. This measurement error is a combination of systematic components, originating from the measuring instrument and random measurement errors. Several novel biological technologies, such as mass cytometry and single-cell RNA-seq (scRNA-seq), are plagued with systematic errors that may severely affect statistical analysis if the data are not properly calibrated.ResultsWe propose a novel deep learning approach for removing systematic batch effects. Our method is based on a residual neural network, trained to minimize the Maximum Mean Discrepancy between the multivariate distributions of two replicates, measured in different batches. We apply our method to mass cytometry and scRNA-seq datasets, and demonstrate that it effectively attenuates batch effects.Availability and Implementationour codes and data are publicly available at https://github.com/ushaham/BatchEffectRemoval.gitSupplementary informationSupplementary data are available at Bioinformatics online.},
	number = {16},
	journal = {Bioinformatics},
	author = {Shaham, Uri and Stanton, Kelly P and Zhao, Jun and Li, Huamin and Raddassi, Khadir and Montgomery, Ruth and Kluger, Yuval},
	month = aug,
	year = {2017},
	pages = {2539--2546},
}

@article{esteva_guide_2019,
	title = {A guide to deep learning in healthcare},
	volume = {25},
	url = {https://doi.org/10.1038/s41591-018-0316-z},
	doi = {10.1038/s41591-018-0316-z},
	abstract = {Here we present deep-learning techniques for healthcare, centering our discussion on deep learning in computer vision, natural language processing, reinforcement learning, and generalized methods. We describe how these computational techniques can impact a few key areas of medicine and explore how to build end-to-end systems. Our discussion of computer vision focuses largely on medical imaging, and we describe the application of natural language processing to domains such as electronic health record data. Similarly, reinforcement learning is discussed in the context of robotic-assisted surgery, and generalized deep-learning methods for genomics are reviewed.},
	number = {1},
	journal = {Nature Medicine},
	author = {Esteva, Andre and Robicquet, Alexandre and Ramsundar, Bharath and Kuleshov, Volodymyr and DePristo, Mark and Chou, Katherine and Cui, Claire and Corrado, Greg and Thrun, Sebastian and Dean, Jeff},
	year = {2019},
	pages = {24--29},
}

@article{norgeot_call_2019,
	title = {A call for deep-learning healthcare},
	volume = {25},
	url = {https://doi.org/10.1038/s41591-018-0320-3},
	doi = {10.1038/s41591-018-0320-3},
	abstract = {Here we argue that now is the time to create smarter healthcare systems in which the best treatment decisions are computationally learned from electronic health record data by deep-learning methodologies.},
	number = {1},
	journal = {Nature Medicine},
	author = {Norgeot, Beau and Glicksberg, Benjamin S and Butte, Atul J},
	year = {2019},
	pages = {14--15},
}

@article{lin_exploiting_2008,
	title = {Exploiting missing clinical data in {Bayesian} network modeling for predicting medical problems},
	volume = {41},
	url = {http://www.sciencedirect.com/science/article/pii/S1532046407000524},
	doi = {10.1016/j.jbi.2007.06.001},
	abstract = {When machine learning algorithms are applied to data collected during the course of clinical care, it is generally accepted that the data has not been consistently collected. The absence of expected data elements is common and the mechanism through which a data element is missing often involves the clinical relevance of that data element in a specific patient. Therefore, the absence of data may have information value of its own. In the process of designing an application intended to support a medical problem list, we have studied whether the “missingness” of clinical data can provide useful information in building prediction models. In this study, we experimented with four methods of treating missing values in a clinical data set—two of them explicitly model the absence or “missingness” of data. Each of these data sets were used to build four different kinds of Bayesian classifiers—a naive Bayes structure, a human-composed network structure, and two networks based on structural learning algorithms. We compared the performance between groups with and without explicit models of missingness using the area under the ROC curve. The results showed that in most cases the classifiers trained using the explicit missing value treatments performed better. The result suggests that information may exist in “missingness” itself. Thus, when designing a decision support system, we suggest one consider explicitly representing the presence/absence of data in the underlying logic.},
	number = {1},
	journal = {Journal of Biomedical Informatics},
	author = {Lin, Jau-Huei and Haug, Peter J},
	year = {2008},
	keywords = {Bayesian network, Clinical decision support system, Missing data, Problem list},
	pages = {1--14},
}

@article{warner_classification_2016,
	title = {Classification of hospital acquired complications using temporal clinical information from a large electronic health record},
	volume = {59},
	url = {http://www.sciencedirect.com/science/article/pii/S1532046415002889},
	doi = {10.1016/j.jbi.2015.12.008},
	abstract = {Hospital acquired complications (HACs) are serious problems affecting modern day healthcare institutions. It is estimated that HACs result in an approximately 10\% increase in total inpatient hospital costs across US hospitals. With US hospital spending totaling nearly \$900 billion per annum, the damages caused by HACs are no small matter. Early detection and prevention of HACs could greatly reduce strains on the US healthcare system and improve patient morbidity \& mortality rates. Here, we describe a machine-learning model for predicting the occurrence of HACs within five distinct categories using temporal clinical data. Using our approach, we find that at least \$10 billion of excessive hospital costs could be saved in the US alone, with the institution of effective preventive measures. In addition, we also identify several keystone features that demonstrate high predictive power for HACs over different time periods following patient admission. The classifiers and features analyzed in this study show high promise of being able to be used for accurate prediction of HACs in clinical settings, and furthermore provide novel insights into the contribution of various clinical factors to the risk of developing HACs as a function of healthcare system exposure.},
	journal = {Journal of Biomedical Informatics},
	author = {Warner, Jeremy L and Zhang, Peijin and Liu, Jenny and Alterovitz, Gil},
	year = {2016},
	keywords = {Classification, Electronic health record, Hospital acquired complications, Ranking, Temporal},
	pages = {209--217},
}

@article{topol_high-performance_2019,
	title = {High-performance medicine: the convergence of human and artificial intelligence},
	volume = {25},
	url = {https://doi.org/10.1038/s41591-018-0300-7},
	doi = {10.1038/s41591-018-0300-7},
	abstract = {The use of artificial intelligence, and the deep-learning subtype in particular, has been enabled by the use of labeled big data, along with markedly enhanced computing power and cloud storage, across all sectors. In medicine, this is beginning to have an impact at three levels: for clinicians, predominantly via rapid, accurate image interpretation; for health systems, by improving workflow and the potential for reducing medical errors; and for patients, by enabling them to process their own data to promote health. The current limitations, including bias, privacy and security, and lack of transparency, along with the future directions of these applications will be discussed in this article. Over time, marked improvements in accuracy, productivity, and workflow will likely be actualized, but whether that will be used to improve the patient–doctor relationship or facilitate its erosion remains to be seen.},
	number = {1},
	journal = {Nature Medicine},
	author = {Topol, Eric J},
	year = {2019},
	pages = {44--56},
}

@article{thottakkara_application_2016,
	title = {Application of {Machine} {Learning} {Techniques} to {High}-{Dimensional} {Clinical} {Data} to {Forecast} {Postoperative} {Complications}},
	volume = {11},
	url = {https://doi.org/10.1371/journal.pone.0155705},
	abstract = {Objective To compare performance of risk prediction models for forecasting postoperative sepsis and acute kidney injury. Design Retrospective single center cohort study of adult surgical patients admitted between 2000 and 2010. Patients 50,318 adult patients undergoing major surgery. Measurements We evaluated the performance of logistic regression, generalized additive models, naïve Bayes and support vector machines for forecasting postoperative sepsis and acute kidney injury. We assessed the impact of feature reduction techniques on predictive performance. Model performance was determined using the area under the receiver operating characteristic curve, accuracy, and positive predicted value. The results were reported based on a 70/30 cross validation procedure where the data were randomly split into 70\% used for training the model and the 30\% for validation. Main Results The areas under the receiver operating characteristic curve for different models ranged between 0.797 and 0.858 for acute kidney injury and between 0.757 and 0.909 for severe sepsis. Logistic regression, generalized additive model, and support vector machines had better performance compared to Naïve Bayes model. Generalized additive models additionally accounted for non-linearity of continuous clinical variables as depicted in their risk patterns plots. Reducing the input feature space with LASSO had minimal effect on prediction performance, while feature extraction using principal component analysis improved performance of the models. Conclusions Generalized additive models and support vector machines had good performance as risk prediction model for postoperative sepsis and AKI. Feature extraction using principal component analysis improved the predictive performance of all models.},
	number = {5},
	journal = {PLOS ONE},
	author = {Thottakkara, Paul and Ozrazgat-Baslanti, Tezcan and Hupf, Bradley B and Rashidi, Parisa and Pardalos, Panos and Momcilovic, Petar and Bihorac, Azra},
	month = may,
	year = {2016},
	pages = {e0155705--e0155705},
}

@article{schulam_reliable_2017,
	title = {Reliable {Decision} {Support} using {Counterfactual} {Models}},
	url = {https://arxiv.org/abs/1703.10651},
	author = {Schulam, Peter and Saria, Suchi},
	month = mar,
	year = {2017},
}

@article{desautels_using_2017,
	title = {Using {Transfer} {Learning} for {Improved} {Mortality} {Prediction} in a {Data}-{Scarce} {Hospital} {Setting}},
	volume = {9},
	url = {https://doi.org/10.1177/1178222617712994},
	doi = {10.1177/1178222617712994},
	abstract = {Algorithm?based clinical decision support (CDS) systems associate patient-derived health data with outcomes of interest, such as in-hospital mortality. However, the quality of such associations often depends on the availability of site-specific training data. Without sufficient quantities of data, the underlying statistical apparatus cannot differentiate useful patterns from noise and, as a result, may underperform. This initial training data burden limits the widespread, out-of-the-box, use of machine learning?based risk scoring systems. In this study, we implement a statistical transfer learning technique, which uses a large ?source? data set to drastically reduce the amount of data needed to perform well on a ?target? site for which training data are scarce. We test this transfer technique with AutoTriage, a mortality prediction algorithm, on patient charts from the Beth Israel Deaconess Medical Center (the source) and a population of 48?249 adult inpatients from University of California San Francisco Medical Center (the target institution). We find that the amount of training data required to surpass 0.80 area under the receiver operating characteristic (AUROC) on the target set decreases from more than 4000 patients to fewer than 220. This performance is superior to the Modified Early Warning Score (AUROC: 0.76) and corresponds to a decrease in clinical data collection time from approximately 6?months to less than 10?days. Our results highlight the usefulness of transfer learning in the specialization of CDS systems to new hospital sites, without requiring expensive and time-consuming data collection efforts.},
	journal = {Biomedical Informatics Insights},
	author = {Desautels, Thomas and Calvert, Jacob and Hoffman, Jana and Mao, Qingqing and Jay, Melissa and Fletcher, Grant and Barton, Chris and Chettipally, Uli and Kerem, Yaniv and Das, Ritankar},
	month = jan,
	year = {2017},
	pages = {1178222617712994--1178222617712994},
}

@article{bakken_journey_2019,
	title = {The journey to transparency, reproducibility, and replicability},
	volume = {26},
	url = {https://dx.doi.org/10.1093/jamia/ocz007},
	doi = {10.1093/jamia/ocz007},
	abstract = {Regardless of the type of biomedical and health informatics research conducted (eg computational, randomized controlled trials, qualitative, mixed methods), transparency, reproducibility, and replicability are crucial to scientific rigor, open science, and advancing the knowledge base of our field and its application across practice domains. These principles are also essential to high-quality publications in Journal of the American Medical Informatics Association (JAMIA). Transparency is reflected by explicit, clear, and open communication about the methods and procedures used to obtain the research results and is foundational to reproducibility (ability to repeatedly obtain the same results from data) and replicability (ability of other investigators to observe the same result under identical conditions).1,2 In the following paragraphs, I summarize key strategies from a number of authors1–3 as well as my own thoughts in 4 categories (data, code, connect, publish) and, when applicable, describe their relationship to publishing in JAMIA. While the principles apply across types of research, the relevance of some strategies varies.},
	number = {3},
	journal = {Journal of the American Medical Informatics Association},
	author = {Bakken, Suzanne},
	month = jan,
	year = {2019},
	pages = {185--187},
}

@inproceedings{lowery_towards_2013,
	title = {Towards efficient, personalized anesthesia using continuous reinforcement learning for propofol infusion control},
	isbn = {1948-3554 VO -},
	doi = {10.1109/NER.2013.6696208},
	booktitle = {2013 6th {International} {IEEE}/{EMBS} {Conference} on {Neural} {Engineering} ({NER})},
	author = {Lowery, C and Faisal, A A},
	year = {2013},
	keywords = {Algorithm design and analysis, Anesthesia, BIS error, Brain modeling, EEG, Indexes, Learning (artificial intelligence), Monitoring, RMSE, Surgery, anesthesiology, anesthetic agent dose reduction, bang-bang control, bang-bang controller, bispectral index, continuous actor-critic learning automaton techniq, continuous reinforcement learning algorithm, control fine tuning, depth of general anesthesia control, drug delivery systems, drugs, efficient personalized anesthesia control, electroencephalography, generic effective control strategy learning, learning (artificial intelligence), medical control systems, neurophysiology, neurotechnology, physiological simulation, propofol infusion control, surgery, surgical procedure},
	pages = {1414--1417},
}

@article{che_recurrent_2018,
	title = {Recurrent {Neural} {Networks} for {Multivariate} {Time} {Series} with {Missing} {Values}},
	volume = {8},
	url = {https://doi.org/10.1038/s41598-018-24271-9},
	doi = {10.1038/s41598-018-24271-9},
	abstract = {Multivariate time series data in practical applications, such as health care, geoscience, and biology, are characterized by a variety of missing values. In time series prediction and other related tasks, it has been noted that missing values and their missing patterns are often correlated with the target labels, a.k.a., informative missingness. There is very limited work on exploiting the missing patterns for effective imputation and improving prediction performance. In this paper, we develop novel deep learning models, namely GRU-D, as one of the early attempts. GRU-D is based on Gated Recurrent Unit (GRU), a state-of-the-art recurrent neural network. It takes two representations of missing patterns, i.e., masking and time interval, and effectively incorporates them into a deep model architecture so that it not only captures the long-term temporal dependencies in time series, but also utilizes the missing patterns to achieve better prediction results. Experiments of time series classification tasks on real-world clinical datasets (MIMIC-III, PhysioNet) and synthetic datasets demonstrate that our models achieve state-of-the-art performance and provide useful insights for better understanding and utilization of missing values in time series analysis.},
	number = {1},
	journal = {Scientific Reports},
	author = {Che, Zhengping and Purushotham, Sanjay and Cho, Kyunghyun and Sontag, David and Liu, Yan},
	year = {2018},
	pages = {6085--6085},
}

@article{lipton_critical_2015,
	title = {A {Critical} {Review} of {Recurrent} {Neural} {Networks} for {Sequence} {Learning}},
	volume = {abs/1506.0},
	url = {http://arxiv.org/abs/1506.00019},
	journal = {CoRR},
	author = {Lipton, Zachary Chase},
	year = {2015},
}

@inproceedings{sun_signal_2006,
	title = {A signal abnormality index for arterial blood pressure waveforms},
	isbn = {0276-6574 VO -},
	booktitle = {2006 {Computers} in {Cardiology}},
	author = {Sun, J X and Reisner, A T and Mark, R G},
	year = {2006},
	keywords = {Algorithm design and analysis, Arterial blood pressure, Biomedical monitoring, Blood pressure, Databases, Detectors, ECG-based false alarms, Heart rate, Hemodynamics, Low-frequency noise, Signal processing, arterial blood pressure waveform, beat-to-beat variation, blood pressure measurement, blood vessels, cardiac output estimation, electrocardiography, feature extraction, medical signal processing, noise-artifact variation, physiologic variation, sensitivity analysis, signal abnormality index},
	pages = {13--16},
}

@inproceedings{zong_open-source_2003,
	title = {An open-source algorithm to detect onset of arterial blood pressure pulses},
	isbn = {0276-6547 VO -},
	doi = {10.1109/CIC.2003.1291140},
	booktitle = {Computers in {Cardiology}, 2003},
	author = {Zong, W and Heldt, T and Moody, G B and Mark, R G},
	year = {2003},
	keywords = {Arterial blood pressure, Blood pressure, C source code, Databases, ECG annotations, Electrocardiography, Feature extraction, Frequency, Low pass filters, MIT-BIH Polysomnographic Database, Open source software, PhysioNet, PhysioToolkit, Roentgenium, Sampling methods, adaptive thresholding, arterial blood pressure pulse detection, blood pressure measurement, blood vessels, electrocardiography, medical signal detection, medical signal processing, open-source algorithm, waveform analysis, weighted slope sum function, windowed slope sum function},
	pages = {259--262},
}

@article{liang_evaluation_2019,
	title = {Evaluation and accurate diagnoses of pediatric diseases using artificial intelligence},
	url = {https://doi.org/10.1038/s41591-018-0335-9},
	doi = {10.1038/s41591-018-0335-9},
	abstract = {Artificial intelligence (AI)-based methods have emerged as powerful tools to transform medical care. Although machine learning classifiers (MLCs) have already demonstrated strong performance in image-based diagnoses, analysis of diverse and massive electronic health record (EHR) data remains challenging. Here, we show that MLCs can query EHRs in a manner similar to the hypothetico-deductive reasoning used by physicians and unearth associations that previous statistical methods have not found. Our model applies an automated natural language processing system using deep learning techniques to extract clinically relevant information from EHRs. In total, 101.6 million data points from 1,362,559 pediatric patient visits presenting to a major referral center were analyzed to train and validate the framework. Our model demonstrates high diagnostic accuracy across multiple organ systems and is comparable to experienced pediatricians in diagnosing common childhood diseases. Our study provides a proof of concept for implementing an AI-based system as a means to aid physicians in tackling large amounts of data, augmenting diagnostic evaluations, and to provide clinical decision support in cases of diagnostic uncertainty or complexity. Although this impact may be most evident in areas where healthcare providers are in relative shortage, the benefits of such an AI system are likely to be universal.},
	journal = {Nature Medicine},
	author = {Liang, Huiying and Tsui, Brian Y and Ni, Hao and Valentim, Carolina C S and Baxter, Sally L and Liu, Guangjian and Cai, Wenjia and Kermany, Daniel S and Sun, Xin and Chen, Jiancong and He, Liya and Zhu, Jie and Tian, Pin and Shao, Hua and Zheng, Lianghong and Hou, Rui and Hewett, Sierra and Li, Gen and Liang, Ping and Zang, Xuan and Zhang, Zhiqi and Pan, Liyan and Cai, Huimin and Ling, Rujuan and Li, Shuhua and Cui, Yongwang and Tang, Shusheng and Ye, Hong and Huang, Xiaoyan and He, Waner and Liang, Wenqing and Zhang, Qing and Jiang, Jianmin and Yu, Wei and Gao, Jianqun and Ou, Wanxing and Deng, Yingmin and Hou, Qiaozhen and Wang, Bei and Yao, Cuichan and Liang, Yan and Zhang, Shu and Duan, Yaou and Zhang, Runze and Gibson, Sarah and Zhang, Charlotte L and Li, Oulan and Zhang, Edward D and Karin, Gabriel and Nguyen, Nathan and Wu, Xiaokang and Wen, Cindy and Xu, Jie and Xu, Wenqin and Wang, Bochu and Wang, Winston and Li, Jing and Pizzato, Bianca and Bao, Caroline and Xiang, Daoman and He, Wanting and He, Suiqin and Zhou, Yugui and Haw, Weldon and Goldbaum, Michael and Tremoulet, Adriana and Hsu, Chun-Nan and Carter, Hannah and Zhu, Long and Zhang, Kang and Xia, Huimin},
	year = {2019},
}

@article{yeung_computer_2019,
	title = {A computer vision system for deep learning-based detection of patient mobilization activities in the {ICU}},
	volume = {2},
	url = {https://doi.org/10.1038/s41746-019-0087-z},
	doi = {10.1038/s41746-019-0087-z},
	abstract = {Early and frequent patient mobilization substantially mitigates risk for post-intensive care syndrome and long-term functional impairment. We developed and tested computer vision algorithms to detect patient mobilization activities occurring in an adult ICU. Mobility activities were defined as moving the patient into and out of bed, and moving the patient into and out of a chair. A data set of privacy-safe-depth-video images was collected in the Intermountain LDS Hospital ICU, comprising 563 instances of mobility activities and 98,801 total frames of video data from seven wall-mounted depth sensors. In all, 67\% of the mobility activity instances were used to train algorithms to detect mobility activity occurrence and duration, and the number of healthcare personnel involved in each activity. The remaining 33\% of the mobility instances were used for algorithm evaluation. The algorithm for detecting mobility activities attained a mean specificity of 89.2\% and sensitivity of 87.2\% over the four activities; the algorithm for quantifying the number of personnel involved attained a mean accuracy of 68.8\%.},
	number = {1},
	journal = {npj Digital Medicine},
	author = {Yeung, Serena and Rinaldo, Francesca and Jopling, Jeffrey and Liu, Bingbin and Mehra, Rishab and Downing, N Lance and Guo, Michelle and Bianconi, Gabriel M and Alahi, Alexandre and Lee, Julia and Campbell, Brandi and Deru, Kayla and Beninati, William and Fei-Fei, Li and Milstein, Arnold},
	year = {2019},
	pages = {11--11},
}

@article{mangul_systematic_2019,
	title = {Systematic benchmarking of omics computational tools},
	volume = {10},
	url = {https://doi.org/10.1038/s41467-019-09406-4},
	doi = {10.1038/s41467-019-09406-4},
	abstract = {Computational omics methods packaged as software have become essential to modern biological research. The increasing dependence of scientists on these powerful software tools creates a need for systematic assessment of these methods, known as benchmarking. Adopting a standardized benchmarking practice could help researchers who use omics data to better leverage recent technological innovations. Our review summarizes benchmarking practices from 25 recent studies and discusses the challenges, advantages, and limitations of benchmarking across various domains of biology. We also propose principles that can make computational biology benchmarking studies more sustainable and reproducible, ultimately increasing the transparency of biomedical data and results.},
	number = {1},
	journal = {Nature Communications},
	author = {Mangul, Serghei and Martin, Lana S and Hill, Brian L and Lam, Angela Ka-Mei and Distler, Margaret G and Zelikovsky, Alex and Eskin, Eleazar and Flint, Jonathan},
	year = {2019},
	pages = {1393--1393},
}

@article{weng_prediction_2019,
	title = {Prediction of premature all-cause mortality: {A} prospective general population cohort study comparing machine-learning and standard epidemiological approaches},
	volume = {14},
	url = {https://doi.org/10.1371/journal.pone.0214365},
	abstract = {Background Prognostic modelling using standard methods is well-established, particularly for predicting risk of single diseases. Machine-learning may offer potential to explore outcomes of even greater complexity, such as premature death. This study aimed to develop novel prediction algorithms using machine-learning, in addition to standard survival modelling, to predict premature all-cause mortality. Methods A prospective population cohort of 502,628 participants aged 40–69 years were recruited to the UK Biobank from 2006–2010 and followed-up until 2016. Participants were assessed on a range of demographic, biometric, clinical and lifestyle factors. Mortality data by ICD-10 were obtained from linkage to Office of National Statistics. Models were developed using deep learning, random forest and Cox regression. Calibration was assessed by comparing observed to predicted risks; and discrimination by area under the ‘receiver operating curve’ (AUC). Findings 14,418 deaths (2.9\%) occurred over a total follow-up time of 3,508,454 person-years. A simple age and gender Cox model was the least predictive (AUC 0.689, 95\% CI 0.681–0.699). A multivariate Cox regression model significantly improved discrimination by 6.2\% (AUC 0.751, 95\% CI 0.748–0.767). The application of machine-learning algorithms further improved discrimination by 3.2\% using random forest (AUC 0.783, 95\% CI 0.776–0.791) and 3.9\% using deep learning (AUC 0.790, 95\% CI 0.783–0.797). These ML algorithms improved discrimination by 9.4\% and 10.1\% respectively from a simple age and gender Cox regression model. Random forest and deep learning achieved similar levels of discrimination with no significant difference. Machine-learning algorithms were well-calibrated, while Cox regression models consistently over-predicted risk. Conclusions Machine-learning significantly improved accuracy of prediction of premature all-cause mortality in this middle-aged population, compared to standard methods. This study illustrates the value of machine-learning for risk prediction within a traditional epidemiological study design, and how this approach might be reported to assist scientific verification.},
	number = {3},
	journal = {PLOS ONE},
	author = {Weng, Stephen F and Vaz, Luis and Qureshi, Nadeem and Kai, Joe},
	month = mar,
	year = {2019},
	pages = {e0214365--e0214365},
}

@article{stuart_integrative_2019,
	title = {Integrative single-cell analysis},
	url = {https://doi.org/10.1038/s41576-019-0093-7},
	doi = {10.1038/s41576-019-0093-7},
	abstract = {The recent maturation of single-cell RNA sequencing (scRNA-seq) technologies has coincided with transformative new methods to profile genetic, epigenetic, spatial, proteomic and lineage information in individual cells. This provides unique opportunities, alongside computational challenges, for integrative methods that can jointly learn across multiple types of data. Integrated analysis can discover relationships across cellular modalities, learn a holistic representation of the cell state, and enable the pooling of data sets produced across individuals and technologies. In this Review, we discuss the recent advances in the collection and integration of different data types at single-cell resolution with a focus on the integration of gene expression data with other types of single-cell measurement.},
	journal = {Nature Reviews Genetics},
	author = {Stuart, Tim and Satija, Rahul},
	year = {2019},
}

@article{kiselev_challenges_2019,
	title = {Challenges in unsupervised clustering of single-cell {RNA}-seq data},
	url = {https://doi.org/10.1038/s41576-018-0088-9},
	doi = {10.1038/s41576-018-0088-9},
	abstract = {Single-cell RNA sequencing (scRNA-seq) allows researchers to collect large catalogues detailing the transcriptomes of individual cells. Unsupervised clustering is of central importance for the analysis of these data, as it is used to identify putative cell types. However, there are many challenges involved. We discuss why clustering is a challenging problem from a computational point of view and what aspects of the data make it challenging. We also consider the difficulties related to the biological interpretation and annotation of the identified clusters.},
	journal = {Nature Reviews Genetics},
	author = {Kiselev, Vladimir Yu and Andrews, Tallulah S and Hemberg, Martin},
	year = {2019},
}

@article{gayat_propensity_2010,
	title = {Propensity scores in intensive care and anaesthesiology literature: a systematic review},
	volume = {36},
	url = {https://doi.org/10.1007/s00134-010-1991-5},
	doi = {10.1007/s00134-010-1991-5},
	abstract = {Propensity score methods have been increasingly used in the last 10 years. However, the practical use of the propensity score (PS) has been reported as heterogeneous in several papers reviewing the use of propensity scores and giving some advice. No precedent work has focused on the specific application of PS in intensive care and anaesthesiology literature.},
	number = {12},
	journal = {Intensive Care Medicine},
	author = {Gayat, Etienne and Pirracchio, Romain and Resche-Rigon, Matthieu and Mebazaa, Alexandre and Mary, Jean-Yves and Porcher, Raphaël},
	year = {2010},
	pages = {1993--2003},
}

@article{karlen_photoplethysmogram_2012,
	title = {Photoplethysmogram signal quality estimation using repeated {Gaussian} filters and cross-correlation},
	volume = {33},
	url = {http://dx.doi.org/10.1088/0967-3334/33/10/1617},
	doi = {10.1088/0967-3334/33/10/1617},
	abstract = {Pulse oximeters are monitors that noninvasively measure heart rate and blood oxygen saturation (SpO2). Unfortunately, pulse oximetry is prone to artifacts which negatively impact the accuracy of the measurement and can cause a significant number of false alarms. We have developed an algorithm to segment pulse oximetry signals into pulses and estimate the signal quality in real time. The algorithm iteratively calculates a signal quality index (SQI) ranging from 0 to 100. In the presence of artifacts and irregular signal morphology, the algorithm outputs a low SQI number. The pulse segmentation algorithm uses the derivative of the signal to find pulse slopes and an adaptive set of repeated Gaussian filters to select the correct slopes. Cross-correlation of consecutive pulse segments is used to estimate signal quality. Experimental results using two different benchmark data sets showed a good pulse detection rate with a sensitivity of 96.21\% and a positive predictive value of 99.22\%, which was equivalent to the available reference algorithm. The novel SQI algorithm was effective and produced significantly lower SQI values in the presence of artifacts compared to SQI values during clean signals. The SQI algorithm may help to guide untrained pulse oximeter users and also help in the design of advanced algorithms for generating smart alarms.},
	number = {10},
	journal = {Physiological Measurement},
	author = {Karlen, W and Kobayashi, K and Ansermino, J M and Dumont, G A},
	year = {2012},
	pages = {1617--1629},
}

@article{nguyen_causal_2016,
	title = {Causal {Inference} in {Anesthesia} and {Perioperative} {Observational} {Studies}},
	volume = {6},
	url = {https://doi.org/10.1007/s40140-016-0174-5},
	doi = {10.1007/s40140-016-0174-5},
	abstract = {Observational studies are of great importance to anesthesia and perioperative care research, as they reflect routine clinical practice. However, because observational data are nonexperimental, assigning causality to identified relationships has a significant risk of bias. After describing the pros and cons of observational studies, we provide an overview of the different methods used to make causal inferences. Of these, we focus on the propensity score analysis, which achieves an increasing popularity in anesthesia and perioperative literature.},
	number = {3},
	journal = {Current Anesthesiology Reports},
	author = {Nguyen, Tri-Long and Winter, Audrey and Spence, Jessica and Leguelinel-Blache, Géraldine and Landais, Paul and Le Manach, Yannick},
	year = {2016},
	pages = {293--298},
}

@article{cicone_how_2017,
	title = {How {Nonlinear}-{Type} {Time}-{Frequency} {Analysis} {Can} {Help} in {Sensing} {Instantaneous} {Heart} {Rate} and {Instantaneous} {Respiratory} {Rate} from {Photoplethysmography} in a {Reliable} {Way}},
	volume = {8},
	url = {https://www.frontiersin.org/article/10.3389/fphys.2017.00701},
	doi = {10.3389/fphys.2017.00701},
	abstract = {Despite the population of the noninvasive, economic, comfortable, and easy-to-install photoplethysmography (PPG), it is still lacking a mathematically rigorous and stable algorithm which is able to simultaneously extract from a single-channel PPG signal the instantaneous heart rate (IHR) and the instantaneous respiratory rate (IRR). In this paper, a novel algorithm called deppG is provided to tackle this challenge. deppG is composed of two theoretically solid nonlinear-type time-frequency analyses techniques, the de-shape short time Fourier transform and the synchrosqueezing transform, which allows us to extract the instantaneous physiological information from the PPG signal in a reliable way. To test its performance, in addition to validating the algorithm by a simulated signal and discussing the meaning of ``instantaneous'', the algorithm is applied to two publicly available batch databases, the Capnobase and the ICASSP 2015 signal processing cup. The former contains PPG signals relative to spontaneous or controlled breathing in static patients, and the latter is made up of PPG signals collected from subjects doing intense physical activities. The accuracies of the estimated IHR and IRR are compared with the ones obtained by other methods, and represent the state-of-the-art in this field of research. The results suggest the potential of deppG to extract instantaneous physiological information from a signal acquired from widely available wearable devices, even when a subject carries out intense physical activities.},
	journal = {Frontiers in Physiology},
	author = {Cicone, Antonio and Wu, Hau-Tieng},
	year = {2017},
	pages = {701--701},
}

@article{daubechies_synchrosqueezed_2011,
	title = {Synchrosqueezed wavelet transforms: {An} empirical mode decomposition-like tool},
	volume = {30},
	url = {http://www.sciencedirect.com/science/article/pii/S1063520310001016},
	doi = {10.1016/j.acha.2010.08.002},
	abstract = {The EMD algorithm is a technique that aims to decompose into their building blocks functions that are the superposition of a (reasonably) small number of components, well separated in the time–frequency plane, each of which can be viewed as approximately harmonic locally, with slowly varying amplitudes and frequencies. The EMD has already shown its usefulness in a wide range of applications including meteorology, structural stability analysis, medical studies. On the other hand, the EMD algorithm contains heuristic and ad hoc elements that make it hard to analyze mathematically. In this paper we describe a method that captures the flavor and philosophy of the EMD approach, albeit using a different approach in constructing the components. The proposed method is a combination of wavelet analysis and reallocation method. We introduce a precise mathematical definition for a class of functions that can be viewed as a superposition of a reasonably small number of approximately harmonic components, and we prove that our method does indeed succeed in decomposing arbitrary functions in this class. We provide several examples, for simulated as well as real data.},
	number = {2},
	journal = {Applied and Computational Harmonic Analysis},
	author = {Daubechies, Ingrid and Lu, Jianfeng and Wu, Hau-Tieng},
	year = {2011},
	keywords = {Empirical mode decomposition, Synchrosqueezing, Time-frequency analysis, Wavelet},
	pages = {243--261},
}

@article{chen_non-parametric_2014,
	title = {Non-parametric and adaptive modelling of dynamic periodicity and trend with heteroscedastic and dependent errors},
	volume = {76},
	url = {https://doi.org/10.1111/rssb.12039},
	doi = {10.1111/rssb.12039},
	abstract = {Summary Periodicity and trend are features describing an observed sequence, and extracting these features is an important issue in many scientific fields. However, it is not an easy task for existing methods to analyse simultaneously the trend and dynamics of the periodicity such as time varying frequency and amplitude, and the adaptivity of the analysis to such dynamics and robustness to heteroscedastic dependent errors are not guaranteed. These tasks become even more challenging when there are multiple periodic components. We propose a non-parametric model to describe the dynamics of multicomponent periodicity and investigate the recently developed synchro-squeezing transform in extracting these features in the presence of a trend and heteroscedastic dependent errors. The identifiability problem of the non-parametric periodicity model is studied, and the adaptivity and robustness properties of the synchro-squeezing transform are theoretically justified in both discrete and continuous time settings. Consequently we have a new technique for decoupling the trend, periodicity and heteroscedastic, dependent error process in a general non-parametric set-up. Results of a series of simulations are provided, and the incidence time series of varicella and herpes zoster in Taiwan and respiratory signals observed from a sleep study are analysed.},
	number = {3},
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Chen, Yu-Chun and Cheng, Ming-Yen and Wu, Hau-Tieng},
	month = jun,
	year = {2014},
	keywords = {Auto-regressive moving average errors, Continuous time auto-regressive moving average pro, Cycles, Instantaneous frequency, Non-stationary processes, Periodic functions, Synchro-squeezing transform, Time–frequency analysis},
	pages = {651--682},
}

@article{daubechies_conceft:_2016,
	title = {{ConceFT}: concentration of frequency and time via a multitapered synchrosqueezed transform},
	volume = {374},
	url = {https://www.ncbi.nlm.nih.gov/pubmed/26953175},
	doi = {10.1098/rsta.2015.0193},
	abstract = {A new method is proposed to determine the time-frequency content of time-dependent signals consisting of multiple oscillatory components, with time-varying amplitudes and instantaneous frequencies. Numerical experiments as well as a theoretical analysis are presented to assess its effectiveness.},
	language = {eng},
	number = {2065},
	journal = {Philosophical transactions. Series A, Mathematical, physical, and engineering sciences},
	author = {Daubechies, Ingrid and Wang, Yi Grace and Wu, Hau-tieng},
	month = apr,
	year = {2016},
	pages = {20150193--20150193},
}

@article{wallace_comparison_1987,
	title = {Comparison of {Blood} {Pressure} {Measurement} by {Doppler} and by {Pulse} {Oximetry} {Techniques}},
	volume = {66},
	url = {https://journals.lww.com/anesthesia-analgesia/Fulltext/1987/10000/Comparison_of_Blood_Pressure_Measurement_by.19.aspx},
	number = {10},
	journal = {Anesthesia \& Analgesia},
	author = {Wallace, Charles T and Baker, J David and Alpert, Calvert C and Tankersley, Susan J and Conroy, Joanne M and Kerns, Randall E},
	year = {1987},
}


@article{esteva_dermatologist-level_2017,
	title = {Dermatologist-level classification of skin cancer with deep neural networks},
	volume = {542},
	url = {https://doi.org/10.1038/nature21056},
	journal = {Nature},
	author = {Esteva, Andre and Kuprel, Brett and Novoa, Roberto A and Ko, Justin and Swetter, Susan M and Blau, Helen M and Thrun, Sebastian},
	month = jan,
	year = {2017},
	pages = {115--115},
}

@article{daabiss_american_2011,
	title = {American {Society} of {Anaesthesiologists} physical status classification},
	volume = {55},
	issn = {0019-5049},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3106380/},
	doi = {10.4103/0019-5049.79879},
	abstract = {Although the American Society of Anaesthesiologists’ (ASA) classification of Physical Health is a widely used grading system for preoperative health of the surgical patients, multiple variations were observed between individual anaesthetist’s assessments when describing common clinical problems. This article reviews the current knowledge and evaluation regarding ASA Classification of Physical Health as well as trials for possible modification.},
	number = {2},
	journal = {Indian Journal of Anaesthesia},
	author = {Daabiss, Mohamed},
	year = {2011},
	note = {Publisher: Medknow Publications
Place: India},
	pages = {111--115},
}

@article{Hunt2014,
	title = {A comprehensive evaluation of assembly scaffolding tools},
	volume = {15},
	issn = {1474-760X},
	url = {https://doi.org/10.1186/gb-2014-15-3-r42},
	doi = {10.1186/gb-2014-15-3-r42},
	abstract = {Genome assembly is typically a two-stage process: contig assembly followed by the use of paired sequencing reads to join contigs into scaffolds. Scaffolds are usually the focus of reported assembly statistics; longer scaffolds greatly facilitate the use of genome sequences in downstream analyses, and it is appealing to present larger numbers as metrics of assembly performance. However, scaffolds are highly prone to errors, especially when generated using short reads, which can directly result in inflated assembly statistics.},
	number = {3},
	journal = {Genome Biology},
	author = {Hunt, Martin and Newbold, Chris and Berriman, Matthew and Otto, Thomas D},
	month = mar,
	year = {2014},
	pages = {R42},
}

@misc{oxford_nanopore_technologies_nanoporetech_nodate,
	title = {nanoporetech / kmer\_models},
	url = {https://github.com/nanoporetech/kmer_models/blob/master/r9.4_180mv_450bps_6mer/template_median68pA.model},
	urldate = {2017-01-01},
	author = {{Oxford Nanopore Technologies}},
}

@article{luo_3d-mice:_2017,
	title = {{3D}-{MICE}: integration of cross-sectional and longitudinal imputation for multi-analyte longitudinal clinical data},
	issn = {1067-5027},
	url = {http://dx.doi.org/10.1093/jamia/ocx133},
	abstract = {ObjectiveA key challenge in clinical data mining is that most clinical datasets contain missing data. Since many commonly used machine learning algorithms require complete datasets (no missing data), clinical analytic approaches often entail an imputation procedure to “fill in” missing data. However, although most clinical datasets contain a temporal component, most commonly used imputation methods do not adequately accommodate longitudinal time-based data. We sought to develop a new imputation algorithm, 3-dimensional multiple imputation with chained equations (3D-MICE), that can perform accurate imputation of missing clinical time series data.MethodsWe extracted clinical laboratory test results for 13 commonly measured analytes (clinical laboratory tests). We imputed missing test results for the 13 analytes using 3 imputation methods: multiple imputation with chained equations (MICE), Gaussian process (GP), and 3D-MICE. 3D-MICE utilizes both MICE and GP imputation to integrate cross-sectional and longitudinal information. To evaluate imputation method performance, we randomly masked selected test results and imputed these masked results alongside results missing from our original data. We compared predicted results to measured results for masked data points.Results3D-MICE performed significantly better than MICE and GP-based imputation in a composite of all 13 analytes, predicting missing results with a normalized root-mean-square error of 0.342, compared to 0.373 for MICE alone and 0.358 for GP alone.Conclusions3D-MICE offers a novel and practical approach to imputing clinical laboratory time series data. 3D-MICE may provide an additional tool for use as a foundation in clinical predictive analytics and intelligent clinical decision support.},
	journal = {Journal of the American Medical Informatics Association},
	author = {Luo, Yuan and Szolovits, Peter and Dighe, Anand S and Baron, Jason M},
	month = nov,
	year = {2017},
	pages = {ocx133--ocx133},
}

@article{friedland_capacity_2017,
	title = {A {Capacity} {Scaling} {Law} for {Artificial} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1708.06019},
	abstract = {In this article, we derive the calculation of two critical numbers that quantify the capabilities of artificial neural networks with gating functions, such as sign, sigmoid, or rectified linear units. First, we derive the calculation of the Vapnik-Chervonenkis dimension of a network with binary output layer, which is the theoretical limit for perfect fitting of the training data. Second, we derive what we call the MacKay dimension of the network. This is a theoretical limit indicating necessary catastrophic forgetting i.e., the upper limit for most uses of the network. Our derivation of the capacity is embedded into a Shannon communication model, which allows measuring the capacities of neural networks in bits. We then compare our theoretical derivations with experiments using different network configurations, diverse neural network implementations, varying activation functions, and several learning algorithms to confirm our upper bound. The result is that the capacity of a fully connected perceptron network scales strictly linear with the number of weights.},
	urldate = {2017-08-22},
	author = {Friedland, Gerald and Krell, Mario},
	month = aug,
	year = {2017},
	note = {arXiv: 1708.06019},
}

@article{lee_efficient_nodate,
	title = {An {Efficient} {Nonlinear} {Regression} {Approach} for {Genome}-wide {Detection} of {Marginal} and {Interacting} {Genetic} {Variations}},
	url = {http://www.cs.cmu.edu/%E2%88%BCseunghak/SPHINX/.},
	abstract = {Genome-wide association studies have revealed individual genetic variants associated with phenotypic traits such as disease risk and gene expressions. However, detecting pairwise in-teraction effects of genetic variants on traits still remains a challenge due to a large number of combinations of variants (∼ 10 11 SNP pairs in the human genome), and relatively small sample sizes (typically {\textless} 10 4). Despite recent breakthroughs in detecting interaction effects, there are still several open problems, including: (1) how to quickly process a large number of SNP pairs, (2) how to distinguish between true signals and SNPs/SNP pairs merely correlated with true sig-nals, (3) how to detect non-linear associations between SNP pairs and traits given small sam-ple sizes, and (4) how to control false positives? In this paper, we present a unified framework, called SPHINX, which addresses the aforementioned challenges. We first propose a piecewise linear model for interaction detection because it is simple enough to estimate model parameters given small sample sizes but complex enough to capture non-linear interaction effects. Then, based on the piecewise linear model, we introduce randomized group lasso under stability selection, and a screening algorithm to address the statistical and computational challenges mentioned above. In our experiments, we first demonstrate that SPHINX achieves better power than existing methods for interaction detection under false positive control. We further applied SPHINX to late-onset Alzheimer's disease dataset, and report 16 SNPs and 17 SNP pairs associated with gene traits. We also present a highly scalable implementation of our screening algorithm which can screen ∼ 118 billion candidates of associations on a 60-node cluster in {\textless} 5.5 hours. SPHINX is available at},
	urldate = {2017-10-01},
	author = {Lee, Seunghak and Lozano, Aurélie and Kambadur, Prabhanjan and Xing, Eric P},
}

@article{browning_fast_2011,
	title = {A {Fast}, {Powerful} {Method} for {Detecting} {Identity} by {Descent}},
	volume = {88},
	issn = {0002-9297},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3035716/},
	doi = {10.1016/j.ajhg.2011.01.010},
	abstract = {We present a method, fastIBD, for finding tracts of identity by descent (IBD) between pairs of individuals. FastIBD can be applied to thousands of samples across genome-wide SNP data and is significantly more powerful for finding short tracts of IBD than existing methods for finding IBD tracts in such data. We show that fastIBD can detect facets of population structure that are not revealed by other methods. In the Wellcome Trust Case Control Consortium bipolar disorder case-control data, we find a genome-wide excess of IBD in case-case pairs of individuals compared to control-control pairs. We show that this excess can be explained by the geographical clustering of cases. We also show that it is possible to use fastIBD to generate highly accurate estimates of genome-wide IBD sharing between pairs of distant relatives. This is useful for estimation of relationship and for adjusting for relatedness in association studies. FastIBD is incorporated in the freely available Beagle software package.},
	number = {2},
	journal = {American Journal of Human Genetics},
	author = {Browning, Brian L and Browning, Sharon R},
	month = feb,
	year = {2011},
	note = {Publisher: Elsevier},
	keywords = {IBD},
	pages = {173--182},
}

@article{wu_omic_2017,
	title = {–{Omic} and {Electronic} {Health} {Record} {Big} {Data} {Analytics} for {Precision} {Medicine}},
	volume = {64},
	issn = {0018-9294},
	url = {http://ieeexplore.ieee.org/document/7587347/},
	doi = {10.1109/TBME.2016.2573285},
	number = {2},
	urldate = {2017-07-06},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Wu, Po-Yen and Cheng, Chih-Wen and Kaddi, Chanchala D. and Venugopalan, Janani and Hoffman, Ryan and Wang, May D.},
	month = feb,
	year = {2017},
	pages = {263--273},
}

@misc{bengio_recurrent_1995,
	title = {Recurrent neural networks for missing or asynchronous data},
	url = {http://dl.acm.org/citation.cfm?id=2998884},
	urldate = {2017-05-03},
	publisher = {MIT Press},
	author = {Bengio, Yoshua and Gingras, Francois},
	year = {1995},
	note = {Pages: 395-401
Publication Title: Proceedings of the 8th International Conference on Neural Information Processing Systems},
}

@article{johansson_learning_2016,
	title = {Learning {Representations} for {Counterfactual} {Inference}},
	url = {http://arxiv.org/abs/1605.03661},
	abstract = {Observational studies are rising in importance due to the widespread accumulation of data in fields such as healthcare, education, employment and ecology. We consider the task of answering counterfactual questions such as, "Would this patient have lower blood sugar had she received a different medication?". We propose a new algorithmic framework for counterfactual inference which brings together ideas from domain adaptation and representation learning. In addition to a theoretical justification, we perform an empirical comparison with previous approaches to causal inference from observational data. Our deep learning algorithm significantly outperforms the previous state-of-the-art.},
	urldate = {2017-05-02},
	author = {Johansson, Fredrik D. and Shalit, Uri and Sontag, David},
	month = may,
	year = {2016},
	note = {arXiv: 1605.03661},
}

@article{kent_human_2002,
	title = {The human genome browser at {UCSC}.},
	volume = {12},
	issn = {1088-9051},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/12045153},
	doi = {10.1101/gr.229102. Article published online before print in May 2002},
	abstract = {As vertebrate genome sequences near completion and research refocuses to their analysis, the issue of effective genome annotation display becomes critical. A mature web tool for rapid and reliable display of any requested portion of the genome at any scale, together with several dozen aligned annotation tracks, is provided at http://genome.ucsc.edu. This browser displays assembly contigs and gaps, mRNA and expressed sequence tag alignments, multiple gene predictions, cross-species homologies, single nucleotide polymorphisms, sequence-tagged sites, radiation hybrid data, transposon repeats, and more as a stack of coregistered tracks. Text and sequence-based searches provide quick and precise access to any region of specific interest. Secondary links from individual features lead to sequence details and supplementary off-site databases. One-half of the annotation tracks are computed at the University of California, Santa Cruz from publicly available sequence data; collaborators worldwide provide the rest. Users can stably add their own custom tracks to the browser for educational or research purposes. The conceptual and technical framework of the browser, its underlying MYSQL database, and overall use are described. The web site currently serves over 50,000 pages per day to over 3000 different users.},
	number = {6},
	urldate = {2017-05-01},
	journal = {Genome research},
	author = {Kent, W James and Sugnet, Charles W and Furey, Terrence S and Roskin, Krishna M and Pringle, Tom H and Zahler, Alan M and Haussler, David},
	month = jun,
	year = {2002},
	pmid = {12045153},
	note = {Publisher: Cold Spring Harbor Laboratory Press},
	pages = {996--1006},
}

@article{yang_model-based_2012,
	title = {A model-based approach for analysis of spatial structure in genetic data},
	volume = {44},
	issn = {1061-4036},
	url = {http://dx.doi.org/10.1038/ng.2285},
	number = {6},
	journal = {Nat Genet},
	author = {Yang, Wen-Yun and Novembre, John and Eskin, Eleazar and Halperin, Eran},
	month = jun,
	year = {2012},
	note = {Publisher: Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	pages = {725--731},
}

@article{mcduff2021camera,
  title={Camera Measurement of Physiological Vital Signs},
  author={McDuff, Daniel},
  journal={arXiv preprint arXiv:2111.11547},
  year={2021}
}

@inproceedings{mcduff2019iphys,
  title={iphys: An open non-contact imaging-based physiological measurement toolbox},
  author={McDuff, Daniel and Blackford, Ethan},
  booktitle={2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)},
  pages={6521--6524},
  year={2019},
  organization={IEEE}
}

@article{boccignone2020open,
  title={An open framework for remote-PPG methods and their assessment},
  author={Boccignone, Giuseppe and Conte, Donatello and Cuculo, Vittorio and d’Amelio, Alessandro and Grossi, Giuliano and Lanzarotti, Raffaella},
  journal={IEEE Access},
  volume={8},
  pages={216083--216103},
  year={2020},
  publisher={IEEE}
}

@inproceedings{pilz2019vector,
  title={On the vector space in photoplethysmography imaging},
  author={Pilz, Christian},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops},
  pages={0--0},
  year={2019}
}

@article{mcduff2022scamps,
  title={SCAMPS: Synthetics for Camera Measurement of Physiological Signals},
  author={McDuff, Daniel and Wander, Miah and Liu, Xin and Hill, Brian L and Hernandez, Javier and Lester, Jonathan and Baltrusaitis, Tadas},
  journal={arXiv preprint arXiv:2206.04197},
  year={2022}
}

@article{heusch2017reproducible,
  title={A reproducible study on remote heart rate measurement},
  author={Heusch, Guillaume and Anjos, Andr{\'e} and Marcel, S{\'e}bastien},
  journal={arXiv preprint arXiv:1709.00962},
  year={2017}
}


@article{aarts2013non,
  title={Non-contact heart rate monitoring utilizing camera photoplethysmography in the neonatal intensive care unit—A pilot study},
  author={Aarts, Lonneke AM and Jeanne, Vincent and Cleary, John P and Lieber, C and Nelson, J Stuart and Oetomo, Sidarto Bambang and Verkruysse, Wim},
  journal={Early human development},
  volume={89},
  number={12},
  pages={943--948},
  year={2013},
  publisher={Elsevier}
}

@article{tarassenko2014non,
  title={Non-contact video-based vital sign monitoring using ambient light and auto-regressive models},
  author={Tarassenko, Lionel and Villarroel, Mauricio and Guazzi, Alessandro and Jorge, Joao and Clifton, DA and Pugh, Chris},
  journal={Physiological measurement},
  volume={35},
  number={5},
  pages={807},
  year={2014},
  publisher={IOP Publishing}
}

@article{yan2020high,
  title={High-throughput, contact-free detection of atrial fibrillation from video with deep learning},
  author={Yan, Bryan P and Lai, William HS and Chan, Christy KY and Au, Alex CK and Freedman, Ben and Poh, Yukkee C and Poh, Ming-Zher},
  journal={JAMA cardiology},
  volume={5},
  number={1},
  pages={105--107},
  year={2020},
  publisher={American Medical Association}
}

@inproceedings{wang2022synthetic,
  title={Synthetic Generation of Face Videos With Plethysmograph Physiology},
  author={Wang, Zhen and Ba, Yunhao and Chari, Pradyumna and Bozkurt, Oyku Deniz and Brown, Gianna and Patwa, Parth and Vaddi, Niranjan and Jalilian, Laleh and Kadambi, Achuta},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={20587--20596},
  year={2022}
}


@article{boccignone2022pyvhr,
  title={pyVHR: a Python framework for remote photoplethysmography},
  author={Boccignone, Giuseppe and Conte, Donatello and Cuculo, Vittorio and D’Amelio, Alessandro and Grossi, Giuliano and Lanzarotti, Raffaella and Mortara, Edoardo},
  journal={PeerJ Computer Science},
  volume={8},
  pages={e929},
  year={2022},
  publisher={PeerJ Inc.}
}

@article{wang2015novel,
  title={A novel algorithm for remote photoplethysmography: Spatial subspace rotation},
  author={Wang, Wenjin and Stuijk, Sander and De Haan, Gerard},
  journal={IEEE transactions on biomedical engineering},
  volume={63},
  number={9},
  pages={1974--1984},
  year={2015},
  publisher={IEEE}
}

@article{de2014improved,
  title={Improved motion robustness of remote-PPG by using the blood volume pulse signature},
  author={De Haan, Gerard and Van Leest, Arno},
  journal={Physiological measurement},
  volume={35},
  number={9},
  pages={1913},
  year={2014},
  publisher={IOP Publishing}
}

@inproceedings{pilz2018local,
  title={Local group invariance for heart rate estimation from face videos in the wild},
  author={Pilz, Christian S and Zaunseder, Sebastian and Krajewski, Jarek and Blazek, Vladimir},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition workshops},
  pages={1254--1262},
  year={2018}
}

@inproceedings{yang2023simper,
  title={SimPer: Simple Self-Supervised Learning of Periodic Targets},
  author={Yang, Yuzhe and Liu, Xin and Wu, Jiang and Borac, Silviu and Katabi, Dina and Poh, Ming-Zher and McDuff, Daniel},
  booktitle={International Conference on Learning Representations},
  year={2023},
  url={https://openreview.net/forum?id=EKpMeEV0hOo}
}

%%%%%%%%%%%%%%%%%%%%%
% GIRISH ADDED - TO SORT
%%%%%%%%%%%%%%%%%%%%%

@article{liu2022rppgtoolbox,
  title={Deep physiological sensing toolbox},
  author={Liu, Xin and Zhang, Xiaoyu and Narayanswamy, Girish and Zhang, Yuzhe and Wang, Yuntao and Patel, Shwetak and McDuff, Daniel},
  journal={arXiv preprint arXiv:2210.00716},
  year={2022}
}

% BP4D+

@inproceedings{zhang2013high,
  title={A high-resolution spontaneous 3d dynamic facial expression database},
  author={Zhang, Xing and Yin, Lijun and Cohn, Jeffrey F and Canavan, Shaun and Reale, Michael and Horowitz, Andy and Liu, Peng},
  booktitle={2013 10th IEEE international conference and workshops on automatic face and gesture recognition (FG)},
  pages={1--6},
  year={2013},
  organization={IEEE}
}

@article{zhang2014bp4d,
  title={Bp4d-spontaneous: a high-resolution spontaneous 3d dynamic facial expression database},
  author={Zhang, Xing and Yin, Lijun and Cohn, Jeffrey F and Canavan, Shaun and Reale, Michael and Horowitz, Andy and Liu, Peng and Girard, Jeffrey M},
  journal={Image and Vision Computing},
  volume={32},
  number={10},
  pages={692--706},
  year={2014},
  publisher={Elsevier}
}

@inproceedings{yang2022multi,
  title={On Multi-Domain Long-Tailed Recognition, Imbalanced Domain Generalization and Beyond},
  author={Yang, Yuzhe and Wang, Hao and Katabi, Dina},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2022}
}

@article{yu2020gradient,
  title={Gradient surgery for multi-task learning},
  author={Yu, Tianhe and Kumar, Saurabh and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},
  journal={arXiv preprint arXiv:2001.06782},
  year={2020}
}

@misc{Pytorch-PCGrad,
  author = {Wei-Cheng Tseng},
  title = {WeiChengTseng/Pytorch-PCGrad},
  url = {https://github.com/WeiChengTseng/Pytorch-PCGrad.git},
  year = {2020}
}

% COVID19
@misc{song2020role,
  title={The role of telemedicine during the COVID-19 epidemic in China—experience from Shandong province},
  author={Song, Xuan and Liu, Xinyan and Wang, Chunting},
  journal={Critical care},
  volume={24},
  number={1},
  pages={1--4},
  year={2020},
  publisher={BioMed Central}
}

@article{smith2020telehealth,
  title={Telehealth for global emergencies: Implications for coronavirus disease 2019 (COVID-19)},
  author={Smith, Anthony C and Thomas, Emma and Snoswell, Centaine L and Haydon, Helen and Mehrotra, Ateev and Clemensen, Jane and Caffery, Liam J},
  journal={Journal of telemedicine and telecare},
  volume={26},
  number={5},
  pages={309--313},
  year={2020},
  publisher={Sage Publications Sage UK: London, England}
}

@inproceedings{taigman2014deepface,
  title={Deepface: Closing the gap to human-level performance in face verification},
  author={Taigman, Yaniv and Yang, Ming and Ranzato, Marc'Aurelio and Wolf, Lior},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1701--1708},
  year={2014}
}