\section{Introduction}
\label{sec:introduction}
Quantum annealing is a form of specialized quantum computation that uses quantum fluctuations in order to search for the global minimum of a combinatorial optimization problem \cite{Kadowaki1998, Das2008, Morita2008, Hauke2020, Farhi2000, Chakrabarti2023}. programmable quantum annealers, available as cloud computing resources, are manufactured by D-Wave Systems, Inc., using superconducting flux qubits \cite{Johnson2011, Lanting2014, Boixo2013, Boixo2014, Mandr2016, King2022}. Quantum annealers are designed to minimize quadratic forms (called Hamiltonian functions), defined by
\begin{align}
    Q(x_1,\ldots,x_n) = \sum_{i=1}^n h_i x_i + \sum_{i<j} J_{ij} x_i x_j.
    \label{eq:hamiltonian}
\end{align}

The variables $x_i$ in eq.~\eqref{eq:hamiltonian} are unknown and take binary values only. The coefficients $h_i \in \R$ (linear weights) and $J_{ij} \in \R$ (quadratic couplers) are chosen by the user to define the problem under investigation, where $i,j \in \{1,\ldots,n\}$. If the variables $x_i \in \{0,1\}$ then eq.~\eqref{eq:hamiltonian} is called a \textit{QUBO} (\textit{quadratic unconstrained binary optimization}) problem, and if $x_i \in \{-1,+1\}$ it is called an \textit{Ising problem}, and importantly QUBO and Ising formulations are equivalent. Many important NP-hard problems map to simple minimization problems of the type of eq.~\eqref{eq:hamiltonian}, see \cite{Lucas2014}.

With newer generations of the D-Wave quantum annealer, an increasing number of features have been added to the machines that allow the user to obtain greater control over the annealing process. Such features include the spin reversal transform, customized anneal schedules, or anneal offsets for individual qubits. In this contribution, we focus on two of the latest features, called reverse annealing schedules and \textit{time-dependent gain in linear biases}, also known as \textit{h-gain}.

This article investigates how both the reverse annealing (RA) and h-gain (HG) features can be used to improve the quality of an initial (suboptimal) solution, which is used to seed the annealing process. In fact, the purpose of RA is to guide the annealing process from a known classical (suboptimal) state to a point where a transverse field is present, before reversing direction again and continuing with a standard forward anneal. We show that the HG feature allows one to achieve a similar goal as RA, though through a different mechanism. For both methods, one hopes that seeding the anneal with a solution that is close to optimal will help the annealer to transition to a better minimum, thereby improving the best found solution.

The HG feature allows one to put an additional weight on the linear terms in eq.~\eqref{eq:hamiltonian} in a time-dependent way. The feature was introduced to better study freeze-out points \cite{Johnson2011} and phase transitions in spin glasses \cite{Harris2018}. We show in this work that HG can also be used to bias the annealing process towards an initially computed solution. However, in contrast to RA, we only use a forward anneal. The mechanism we employ works as follows. We assume an Ising formulation in eq.~\eqref{eq:hamiltonian} with no linear terms. We then add to the given Ising formulation a new linear term that serves as a bias towards the known initial solution. Using the HG feature, we can put maximal weight on the linear terms at the start of the annealing process that biases the anneal towards the initial state, and decrease the HG strength during the annealing process to zero in order to make the annealer explore nearby solutions. An extension of this idea to Ising formulations with linear terms is presented as well. Finally, we explore schedules that combine both RA and HG in that they use a backward phase resembling an RA step and a forward phase that uses our HG idea.

Both the RA and HG techniques investigated in this work have a variety of tunable parameters. In particular, the RA feature requires the specification of annealing time duration and anneal schedule. The HG feature likewise requires annealing time,  HG schedule governing the time-dependent linear biases, and up to two additional parameters used to scale the appended linear terms in relation to the existing terms in eq.~\eqref{eq:hamiltonian}. To tune those parameters, we employ a Bayesian optimization framework \cite{Mockus1974}. The details of all optimizations being performed are given in the article, together with the best anneal schedules we found for RA and HG to encode initial solutions. These insights may prove valuable for users implementing  RA and HG.

This article is a journal version and substantial extension of the conference paper of \cite{Pelofske_2020}, published in the \textit{QCE20 IEEE International Conference on Quantum Computing and Engineering}. In addition to the conference version, the present journal article also considers an application of RA and HG to Quantum Evolution Monte Carlo (QEMC), also known as iterative reverse annealing. We demonstrate that both RA and HG can be employed in quantum annealing to encode initial states in each iteration. We investigate the performance of such QEMC algorithms on random spin glasses with native D-Wave connectivity across four different D-Wave QPUs.

The article is structured as follows. We start with a brief literature review (Section~\ref{sec:litreview}) before introducing details on how to encode an initial state prior to an annealing process using the RA and/or HG features (Section~\ref{sec:methods}). That section also describes how we employ RA and HG in connection with QEMC. Section~\ref{sec:experiments} presents experimental results for the weighted Maximum Cut problem (Section~\ref{sec:experiments_maxcut}), the weighted Maximum Clique problem (Section~\ref{sec:experiments_maxclique}), as well as QEMC (Section~\ref{sec:QEMC_experiments}). The article concludes with a discussion in Section~\ref{sec:discussion}. Certain tuning parameters we employed in our experiments are given in the appendix.

\section{Previous work}
\label{sec:litreview}
The new HG feature has not received too much attention in the literature to date. However, RA has been studied by several authors. Its idea was first introduced in \cite{Perdomo2011study} under the name of \textit{sombrero adiabatic quantum computation}. Using tests on 3-SAT instances, the authors noted that the performance of RA was dependent on the Hamming distance between the planted initial solution and the optimal solution.

On a related note, in \cite{Chancellor2017}, the author studies local search algorithms in the neighborhood of a planted state via repeated calls of a quantum device. However, the author only considers forward anneals, and reverse annealing is not explicitly considered.

A theoretical contribution can be found in \cite{Ohkuwa2018}, where authors study conditions under which RA can lead to improvements over standard annealing for the fully connected $p$-spin model. They  present a theoretical framework to characterize such cases, but remark that their results do not necessarily apply to experimental setups where RA is performed adiabatically and in a thermal environment.

An application of adiabatic RA, which is a forward anneal similar to the HG version studied here, and iterative RA as used in the D-Wave annealer, is analyzed in \cite{Yamashiro2019}, using direct numerical integration of the time-dependent Schr{\"o}dinger equation. The authors find a theoretical speed-up of adiabatic RA over QA for mean-field-type $p$-spin models. However, they also find that iterative RA as used by D-Wave does not provide such advantage in theory, which is attributed to the fact that D-Wave is not a closed system, meaning that the theoretical results may not apply.

A considerable speedup of RA over QA in a real-world application (portfolio optimization) is reported in \cite{Venturelli2019}, under the condition that RA starts from a planted heuristic solution.

Some differences of open system dynamics versus closed system RA is studied empirically in \cite{Passarelli2020} using $3$-spin models. The authors observe that RA with a pause converges to the ground state with a higher success probability than purely closed system RA, prompting the authors to conjecture that the open system dynamics makes RA work in devices such as the D-Wave annealer.





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Methods}
\label{sec:methods}
This section describes the techniques we use to encode an initial solution, both via the D-Wave's RA feature (Section~\ref{sec:reverse_annealing}), and with the help of suitably chosen additional linear term in connection with the HG feature (Sections~\ref{sec:hgain} and \ref{sec:hgain_linear}). Section~\ref{sec:ra+hg_method} describes the combined technique of RA+HG. Section~\ref{sec:parameters} states the final Hamiltonian we optimize and briefly describes the Bayesian optimization framework used to optimize the reverse quantum annealing and h-gain schedules. Section~\ref{sec:QEMC} defines the iterative state encoding procedure, also known as QEMC, when applied using reverse quantum annealing and the h-gain initial state encoding method. 

\subsection{Anneal paths based on reverse annealing}
\label{sec:reverse_annealing}

\begin{figure*}
    \centering
    \includegraphics[width=0.95\textwidth]{figures/schematics/schematic_new2.pdf}
    \caption{Left: Functions $A(s)$ and $B(s)$ controlling the annealing process, where $s \in [0,1]$ is the anneal fraction. Right: Progression of the anneal fraction $s$ for standard forward and reverse annealing with pause as a function of time $t \in [0,500]$ ms. Figure adapted from~\cite{Passarelli2020}. Note that the functions of $A(s)$ and $B(s)$ will change slightly depending on the quantum annealer. 
    \label{fig:RA}}
\end{figure*}

In a standard forward anneal (FA), all qubits are prepared in an equal superposition of all   states, as determined by the transverse field portion of the system's Hamiltonian. During annealing, the amplitude of the transverse field is being decreased towards $0$, while the Hamiltonian is slowly transformed into a Hamiltonian corresponding to the Ising problem being minimized. Specifically, the evolution of D-Wave's quantum system is described by the following time-dependent Hamiltonian
\begin{align}
    \nonumber
    H(s)=&-\frac{A(s)}{2}\Big(\sum_{i=1}^n \hat{\sigma}^{(i)}_x\Big) \\ &+\frac{B(s)}{2}\Big(\sum_{i=1}^nh_i\hat{\sigma}_z^{(i)} + \sum_{i\leq j} J_{ij} \hat{\sigma}_z^{(i)} \hat{\sigma}_z^{(j)}\Big), \label{eq:FA}
\end{align}
where the first term having the prefactor $-A(s)/2$ is the transverse field and the term following the prefactor $B(s)/2$ is the Hamiltonian corresponding to the Ising model of eq.~\eqref{eq:hamiltonian},  and $\hat{\sigma}^{(i)}_x$ and $\hat{\sigma}^{(i)}_z$ are the Pauli $x$ and $z$ gates operating on qubit $i$. The specific functions $A(s)$ and $B(s)$ used for the D-Wave 2000Q machine at Los Alamos are shown on Figure~\ref{fig:RA} (left). These functions are indexed by a parameter $s \in [0,1]$ called the \textit{anneal fraction}, which itself is a function $s(t)$ of the time $t$. In the case of the FA, it is given as $s(t)=t/T$, where $T$ is the total annealing time.

In contrast to FA, reverse annealing (RA) starts with a precomputed classical solution that is expected to be much closer in quality to an optimal one than a random starting point. Then, a two-stage process is initiated (see the red curve in Figure~\ref{fig:RA}, right), during which quantum fluctuations are first increased by reducing the anneal fraction from $s=1$ to a value $s_\text{inv}\in(0,1)$ at time $t_\text{inv}^a$. After the turning point is reached, and after an optional pause until time $t_\text{inv}^b$, the anneal follows again the path of a standard forward anneal from $s_\text{inv}$ up to $s=1$ at full annealing time $T$. Careful choices of the turning point and the initial state can lead to improvements in the solution compared to a forward anneal, see~\cite{Perdomo2011, King2018}.

\subsection{Anneal paths based on the h-gain schedule}
\label{sec:hgain}
The feature of a \textit{time-dependent gain in Hamiltonian linear biases} allows the user to have more control of the annealing process by biasing linear terms of an Ising model with the help of a time-dependent function $g(t)$ as follows:
\begin{align}
    \nonumber
    H_{\mathrm{HG}}(s) &= - \frac{A(s)}{2} \Big( \sum_{i=1}^n \hat{\sigma}_x^{(i)} \Big)\\
    &+ \frac{B(s)}{2} \Big( \sum_{i=1}^n g(t) h_i \hat{\sigma}_z^{(i)} + \sum_{i>j} J_{ij} \hat{\sigma}_z^{(i)} \hat{\sigma}_z^{(j)} \Big),
    \label{eq:hgain}
\end{align}
see~\cite{Harris2018}. Compared to eq.~\eqref{eq:FA}, we see that the linear terms of the Ising model in eq.~\eqref{eq:hgain} are weighted with a function $g(t)$, specified by the user, which controls the time-dependent gain for the linear terms. In our implementation, we initialize the function with $g(0) \in [0,5]$ (5 being the largest value allowed for D-Wave 2000Q) and decrease it to $g(T)=0$ using up to $20$ points on the schedule. The specification of the HG feature is actually more general than the way we use it in this work. For instance, the function $g(t)$ may actually return values in $[-5,5]$, it does not need to be monotonic, there is a (machine-dependent) upper bound of $500$ for the slope between changes in the schedule, and a (machine-dependent) upper bound of $20$ on the number of points determining the schedule~\cite{TechnicalDescriptionDwave}.

Our aim is to employ the HG feature to encode an initial solution at the start of the annealing process. Assume we are given an Ising problem of the type of eq.~\eqref{eq:hamiltonian} with no linear term, i.e., $h_i=0$ for all $i$. The idea lays in the observation that, for a fixed initial value $\bm{x^{(0)}} = (x_1^0,\ldots,x_n^0) \in \{-1,+1\}^n$, the minimum of the special Ising function containing only linear terms,
\begin{equation}
    \label{eq:H0}
    h(\bm{x}) = \sum_{i=1}^n (-x_i^0) x_i    
\end{equation}
for $\bm{x}=(x_1,\ldots,x_n)$, is equal to $-n$, and it occurs at $\bm{x}=\bm{x^{(0)}}$. Hence we can define $h_i=-x_i^0$ for $i=1,\dots,n$ and use a HG anneal schedule of the type of eq.~\eqref{eq:hgain}. By putting a large weight on the linear terms at the start of the anneal using the function $g(t)$, we bias the annealing solution towards our planted solution $\bm x^{(0)}$. Over the course of the anneal, the HG bias (the function $g(t)$ in eq.~\eqref{eq:hgain}) is decreased towards $0$, thus allowing the annealing process to move away from the planted solution and to explore alternative solutions in its neighborhood.

However, in order for this idea to work, the original Ising model may not have a linear term, so we can create our own linear term to encode the initial solution. For instance, Maximum Cut, Graph Partitioning, and Number Partitioning are such NP-hard problems without linear terms~\cite{Lucas2014}. Most Ising formulations of NP-hard problems, however, seem to have linear terms. Next, we will show that, even for such problems, the HG approach can be applicable.

\subsection{Using HG for Ising problems containing linear terms}
\label{sec:hgain_linear}
For problems whose Ising formulations do have linear terms, we apply the following transformation to eliminate them. First, we homogenize the polynomial in eq.~\eqref{eq:hamiltonian} by converting the linear term into a quadratic one. This is achieved by introducing a new variable $z \in \{-1,+1\}$, which we call a \textit{slack variable}. The slack variable $z$ is multiplied with each linear term, thus transforming eq.~\eqref{eq:hamiltonian} into
\begin{align}
    Q'(\bm{x},z) = \sum_{i=1}^n h_i x_i z + \sum_{i<j} J_{ij} x_i x_j.
    \label{eq:H'}
\end{align}
Note that $Q$ can be recovered from $Q'$ by setting $z=1$. Now we can apply the method as discussed in Section~\ref{sec:hgain}. After the end of the annealing process, we ignore all solutions with $z=-1$. We can guide the annealing process to favor solutions with $z=1$ by using an appropriate HG bias (initial solution).

\subsection{Reverse annealing and h-gain combined}
\label{sec:ra+hg_method}
The ideas of RA and HG can actually be combined into a single D-Wave schedule. To be precise, given an initial solution $\bm x^{(0)}$ to be encoded, we first apply the methodology of Sections~\ref{sec:hgain} and \ref{sec:hgain_linear} to arrive at a new Ising model encoding $\bm x^{(0)}$. We then solve the new Ising model using an RA schedule, which specifies the anneal fraction $s$ as a function of time, combined with an HG schedule, which specifies the gain $g(t)$ as a function of time.

If the HG Hamiltonian computed in Sections~\ref{sec:hgain} and \ref{sec:hgain_linear} requires a slack variable $z$, we also need to supply an initial state for $z$ when running RA. In order to reinforce $z=1$, we simply set $z=1$ in the RA initial state additionally to $\bm{x} = \bm x^{(0)}$. Note that the two schedules for RA+HG contain a total number of five parameters, three parameters for the RA schedule and two parameters for the HG schedule.

\subsection{Final Hamiltonian and tuning of parameters}
\label{sec:parameters}
To arrive at an effective implementation of the RA and HG methods, we need to determine appropriate values for a set of parameters, some optional, others required.

For HG, optional parameters are the coefficients $h_i$ from eq.~\eqref{eq:hgain}, for which we have so far suggested only their sign in eq.~\eqref{eq:H0}. While choosing individual weights for each $h_i$ will result in highest accuracy, it is also the most difficult to accomplish and beyond the scope of this paper. Instead, we use a single coefficient $\alpha_1$ for $i=1,\dots,n$ and, in the case when we need to homogenize the input Ising model, another coefficient $\alpha_2$ for the new variable $z$.

Combining the above, we encode an initial state using the Ising model
\begin{align}
    Q_\mathrm{final}(\bm{x},z)=\alpha_1\Big(\sum_{i=1}^n (-x_i^0) x_i\Big) - \alpha_2 z + Q'(\bm{x},z),
    \label{eq:H_final}
\end{align}
which is a function of $x_1,\ldots,x_n$ and $z$. The two scaling constants $\alpha_1$ and $\alpha_2$ allow us to control the strength enforcing the bias towards the initial solution and the condition that $z=1$. If the Ising model under consideration in eq.~\eqref{eq:hamiltonian} does not have a linear term, no new variable $z$ is needed and thus $\alpha_2=0$ in eq.~\eqref{eq:H_final}. When implementing eq.~\eqref{eq:H_final} on the D-Wave QPU, we use the internal \textit{autoscale} option, thus scaling all quadratic terms to the range $[-1,+1]$.

Parameters that are required for both RA and HG are the schedule parameters. For RA, we need the values $t_\text{inv}^a$, $t_\text{inv}^b$, and $s_\text{inv}$, see Figure~\ref{fig:RA}, plus the total annealing time $T$. For HG we need the function $g(t)$ given as a polygonal line subject to D-Wave's restrictions on magnitude, angles, and number of points. While there is some previous work that can be used as a guide for setting the schedule, in the case of HG there is no such previous work. Hence, we apply an optimization procedure for choosing the HG parameters and, in order to make a fair comparison between RA and HG, we use the same method for choosing the RA parameters.

We employ the following procedure to tune the aforementioned parameters. The tuning is done separately for the two problems that we study in more detail in the experiments of Section~\ref{sec:experiments}, the Maximum Cut and the Maximum Clique problems, as follows:
\begin{enumerate}
    \item We first fix the anneal time $T$, and then the anneal schedule for RA. After having determined $T$, we fix the starting point $(t=0,s=1)$ and the end point $(t=T,s=1)$, see Figure~\ref{fig:RA} (right). As in Figure~\ref{fig:RA} (right), we decrease the anneal fraction $s$ to a point $(t_\text{inv}^a,s_\text{inv})$. We then allow for a pause, meaning we also allow a point $(t_\text{inv}^b,s_\text{inv})$ at the same $s_\text{inv}$. All in all, we need to determine four parameters for RA: $T, t^a_\text{inv}, t^b_\text{inv},$ and $s_\text{inv}$.
    \item Similarly, for HG, we first fix $T$ and then the schedule's end points, starting at $(0,5)$ and ending at $(T,0)$. We allow for one point in-between, $(h,t)$, where $h \in [0,5]$ and $t \in (0,1)$. Together, three parameters are required for HG, that is, $T, h, t$. Note that such a shape for an HG schedule is by no means optimal, but we want to keep the number of parameters low to have a more manageable search space. However, before determining the schedule parameters, we first determine the best scaling factors $\alpha_1$ and $\alpha_2$ in eq.~\eqref{eq:H_final}. If the Ising model under consideration in eq.~\eqref{eq:hamiltonian} only has quadratic terms, homogenizing the polynomial is not necessary and we thus only need to find $\alpha_1$ in the Hamiltonian of eq.~\eqref{eq:H_final}. Otherwise, both $\alpha_1$ and $\alpha_2$ are determined.
    \item For the combined technique of RA+HG, after having determined the scaling constants $\alpha_1$ and $\alpha_2$ and the total annealing time $T$, we are left with five parameters determining the schedules: $t^a_\text{inv}, t^b_\text{inv},$ and $s_\text{inv}$ for RA, and $h, t$ for HG.
\end{enumerate}
To optimize all these parameters, we employ the Bayesian optimization tool of~\cite{bayesianopt}.
\textit{Bayesian optimization}~\cite{Mockus1974, Mockus1977, Mockus1989, Mockus2012} is a sequential optimization strategy to find the global optimum of a smooth function without the need for derivatives. Briefly, a uniform prior is put over the search space on which the function under investigation is defined. After querying a few first function evaluations, a posterior distribution is calculated which incorporates the obtained knowledge of the function evaluations (the data). Importantly, the posterior allows one to quantify the uncertainty in all unexplored areas, and it simplifies to a point mass at those locations where the function has been queried (and which are thus known exactly). Under suitable smoothness assumption on the function being optimized, the posterior allows one to exclude areas which cannot contain the global optimum, and iteratively refining unexplored areas will result in a confidence region for the global optimum. An advantage of Bayesian optimization and the reason we chose it in this research is the fact that it also works with functions that are noisy, which is the case here since the function we optimize is based on the energy values returned by the D-Wave quantum annealer.


\subsection{Quantum evolution Monte Carlo}
\label{sec:QEMC}
A straightforward extension of the methodology presented in Sections~\ref{sec:reverse_annealing} and \ref{sec:hgain} is to iteratively apply the initial state encoding over some number of iterations, where the best solution from each previous iteration serves as the seed of the new anneal. This idea often referred to in the literature as \textit{quantum evolution Monte Carlo} (QEMC) \cite{King_2021, King2018, King_2021_scaling, PRXQuantum.1.020320, https://doi.org/10.48550/arxiv.2301.01853} or \textit{iterated reverse annealing} \cite{Yamashiro2019, PhysRevApplied.17.054033, PhysRevResearch.3.033006}. Initial state encodings are also known as warm starting in other contexts \cite{ash2020warm, Sack_2021, Egger_2021, https://doi.org/10.48550/arxiv.2207.05089}. Such approaches have been used for a variety of physics simulation computations on quantum annealers. By iteratively seeding each new anneal with the previously (best) obtained solution, one hopes to incrementally improve upon the solution quality. In the remainder of this article we will refer to this method as \textit{QEMC}.


\begin{figure*}
    \centering
    \includegraphics[width=0.24\textwidth]{figures/iterated/schedules/RA_schedules.pdf}
    \includegraphics[width=0.24\textwidth]{figures/iterated/schedules/HGain_schedules_DW_2000Q_6.pdf}
    \includegraphics[width=0.24\textwidth]{figures/iterated/schedules/RA_HG.pdf}
    \includegraphics[width=0.24\textwidth]{figures/iterated/schedules/QA_pause.pdf}
    \caption{Range of RA schedules (left), single point varied HG schedule with a fixed annealing time of $50$ microseconds (middle-left), single point varied HG schedule with an HG strength of $0$ at $90$ microseconds (middle-right), and forward anneal schedules with pauses (right). The total annealing time for each schedule is $100$ microseconds. The annealing pauses for both RA and FA start at $10$ microseconds.}
    \label{fig:iterated_anneal_schedules}
\end{figure*}

We aim to employ both RA and HG to encode the initial states in QEMC before each new iteration. As in Section~\ref{sec:parameters}, these schedules have a variety of tuning parameters that we need to determine. Specifically, we test the following four different iterated state encoding methods:
\begin{enumerate}
    \item HG initial state encoding only. We design the HG schedules to be monotonically decreasing HG value over time, where the first and last point of the schedule are fixed and the middle point can be varied both in terms of the time point and the HG strength. Figure~\ref{fig:iterated_anneal_schedules} (middle-left) shows the functional shape of those HG schedules. The HG schedules are applied at the same time as the default linearly interpolated forward anneal schedule. The schedule in Figure~\ref{fig:iterated_anneal_schedules} (middle-left) decreases HG strength to $0$ at $50$ microseconds (half way through the anneal), though this point can also be varied. The earlier in the schedule the HG field is set to $0$, the less influence the initial state has on the evolution of the annealing process. Conversely, the later in the annealing process the HG field is set to $0$, the greater the influence the initial state has on the evolution of the quantum state. 
    \item RA schedule combined with the HG initial state encoding method. This method involves specifying a RA schedule as shown in Figure~\ref{fig:iterated_anneal_schedules} (left), and an HG schedule as shown in Figure~\ref{fig:iterated_anneal_schedules} (middle-right). In this case, we modify the HG schedule slightly so that it reaches an HG strength of $0$ at the same time that the RA schedule begins to move back towards the readout state. However, the HG schedule is still monotonically decreasing.
    \item FA schedule with a symmetric pause combined with the HG initial state encoding method. In this case, we combine a FA schedule with a symmetric pause as shown in Figure~\ref{fig:iterated_anneal_schedules} (right) with an HG schedule shown in Figure~\ref{fig:iterated_anneal_schedules} (middle-right). As in the previous case that combined FA and HG, the HG schedule here is constructed such that it reaches an HG strength of $0$ at the same time in the annealing process that the FA schedule stops pausing before it continues up to $s=1$. 
\end{enumerate}

Each of these four initial state encoding methods are tested on the three D-Wave quantum annealers shown in Table~\ref{table:hardware_summary}.
\begin{table*}
    \begin{center}
        \begin{tabular}{|l||l|l|l|}
        \hline
        D-Wave device chip ID & Topology name & Available qubits & Available couplers \\ 
        \hline
        \texttt{DW\_2000Q\_6} & Chimera $C_{16}$ & 2041 & 5974\\ 
        \texttt{Advantage\_system4.1} & Pegasus $P_{16}$ & 5627 & 40279\\ 
        \texttt{Advantage\_system6.1} & Pegasus $P_{16}$ & 5616 & 40135\\ 
        \hline
        \end{tabular}
    \end{center}
    \caption{Summary of D-Wave hardware used for the QEMC experiments. Note that each of these four devices has some hardware defects on the qubit topology which causes the available hardware (qubits and couplers) to be smaller than the ideal graph lattice structure.}
    \label{table:hardware_summary}
\end{table*}

We apply QEMC to random Ising models (see Section~\ref{sec:introduction}), where the couplers in each problem are designed to match the hardware graph of each the four QPUs in Table~\ref{table:hardware_summary}, meaning that the test Ising models use the entire quantum annealer chip making the search space for the optimal variable assignments quite large. An example of those hardware graphs is given in Figure~\ref{fig:hardware_graph_spin_glasses}.

We test three different weight precision levels: $10$ linearly spaced weights between $-1$ and $1$ (not including $0$), $100$ linearly spaced weights between $-1$ and $1$, and $200$ linearly spaced weights between $-1$ and $1$ (excluding $0$ so that all coefficients are nonzero). The purpose of this approach is to push the limits of the precision with which the Ising coefficients can be mapped onto the quantum annealing hardware of the D-Wave devices. All problem instances we test only contain quadratic terms, thus leaving the linear terms free to encode the initial state in our proposed HG state encoding method (Section~\ref{sec:hgain}).

\begin{figure*}
    \centering
    \includegraphics[width=0.4\textwidth]{figures/iterated/hardware_graphs/problem_coefficients_Advantage_system4.1_cropped.pdf}
    \includegraphics[width=0.4\textwidth]{figures/iterated/hardware_graphs/problem_coefficients_DW_2000Q_6_cropped.pdf}
    \caption{Cropped hardware graphs (edges of the chip are not shown) of the native connectivity for embedded spin glass instances on \texttt{Advantage\_system4.1} (left), both of which are Pegasus $P_{16}$ graphs with hardware defects, and \texttt{DW\_2000Q\_6} (right) which is a Chimera $C_{16}$ graph with hardware defects. The values of the quadratic coefficients are color coded from $-1$ (light blue) to $+1$ (purple). }
    \label{fig:hardware_graph_spin_glasses}
\end{figure*}







%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experimental analysis}
\label{sec:experiments}
This section reports on a variety of experiments conducted to assess the performance of both RA and HG, the combined of RA+HG, as well as QEMC for improving a planted solution. The experiments are divided into three subsections. In the first two subsections, and after introducing the experimental setting (Section~\ref{sec:setting}), we investigate two important NP-hard problems, the weighted Maximum Cut problem (Section~\ref{sec:experiments_maxcut}) and the weighted Maximum Clique problem (Section~\ref{sec:experiments_maxclique}). The assessment of QEMC in Section~\ref{sec:QEMC_experiments} is performed on random spin glass models. The experiments in Sections \ref{sec:experiments_maxcut} and \ref{sec:experiments_maxclique} are performed using a D-Wave 2000Q quantum annealer with chip id \texttt{DW\_2000Q\_LANL}. The experiments in Section~\ref{sec:QEMC_experiments} are performed using three other quantum annealers with chip ids \texttt{DW\_2000Q\_6}, \texttt{Advantage\_system4.1}, \texttt{Advantage\_system6.1}. 

\subsection{Experimental setting}
\label{sec:setting}
The structure of Sections~\ref{sec:experiments_maxcut} and \ref{sec:experiments_maxclique} is identical: We first fix the scaling constants in eq.~\eqref{eq:H_final} for HG before we determine a suitable annealing duration for applying each of the three methods. Afterwards, we employ Bayesian optimization to determine the best anneal schedule, parameterized as described in Section~\ref{sec:parameters}. Once both the annealing duration and the anneal schedule are found for each of the RA, HG, and RA+HG methods, we evaluate all three techniques with respect to either the cut value (for the Maximum Cut problem) or the clique weight (for the Maximum Clique problem).

The experiments on weighted maximum cut and weighted maximum clique problems used Erd{\H o}s--R{\'e}nyi random graphs~\cite{ErdosRenyi1960} with probability/density parameter $p$, where $p \in \{0.1,0.2,\ldots,0.9\}$. Once the Ising model coefficients for the Maximum Cut or Maximum Clique problem are computed for each test graph, we embed it with {\tt minorminer} \cite{Cai2014, minorminer} using a chain strength value of $2$ and the default settings on the D-Wave devices.

Throughout the experiments, we employ the RA feature of D-Wave with the \textit{reinitialize state} option being switched on (the default choice), meaning that D-Wave reinitializes the initial classical state before each anneal-readout is performed.

Moreover, we employ the {\tt bayes\_opt} tool of~\cite{bayesianopt} using the following parameters: the number of points for random exploration is set to {\tt init\_points=100}, the number of iterations for optimization is set to {\tt n\_iter=200}, and the noise level is set to {\tt alpha=0.01}. The parameter {\tt alpha} indicates to the optimizer how noisy the optimization landscape is. Since D-Wave samples are quite noisy, we observed that setting {\tt alpha} to a higher value, such as $0.01$, is favorable. However, we observe that large values of {\tt alpha} seem to cause an error in the optimizer, while smaller values lead to insufficient exploration of the optimization landscape.

In the experiments of Section~\ref{sec:QEMC_experiments}, we investigate random spin glass models which fit the D-Wave topology of the three annealer generations given in Table~\ref{table:hardware_summary}. The annealing time is always $100$ microseconds, and we read out $1000$ anneals. The readout thermalization and programming thermalization time were both set to $0$ microseconds. The option to reduce intersample correlation was enabled. For experiments involving RA, the option \texttt{reinitialize\_state} was enabled.

The maximum HG strengths that can be applied are device dependent. For \texttt{DW\_2000Q\_6} the maximum HG strength is $5$, for \texttt{Advantage\_system4.1} it is $3$, for \texttt{Advantage\_system6.1} it is $4$, and for \texttt{Advantage2\_prototype1.1} it is $5$.

All schedules with a pause had a pause duration of $80$ microseconds, with $10$ microseconds for the ramp up and ramp down parts.

The initial state for each random spin glass instance was determined by running a single job of $1000$ anneals at $100$ microsecond annealing time, using a standard forward anneal schedule. The sample with the best energy was used as the starting point for all iterative procedures. We repeat this across the different D-Wave devices (Table~\ref{table:hardware_summary}) and the different random spin glass coefficient precisions.

In all QEMC applications we used exactly $20$ iterations.

\subsection{Weighted Maximum Cut problem}
\label{sec:experiments_maxcut}
This section focuses on the weighted Maximum Cut problem, defined as follows. Given an undirected graph $G=(V,E)$ with edge weights $w(e)$ for each edge $e=(u,v)$ connecting two vertices $u,v \in V$, we define a \textit{cut} to be any partition of $V$ into the disjoint union $C_1 \cup C_2$, where $C_1 \subseteq V$ and $C_2=V \setminus C_1$. The set of cut edges, called \textit{cutset}, is defined as $\mathcal{E}=\{ e=(u,v) \in E: u \in C_1, v \in C_2\}$ and its weight is $\sum_{e \in \mathcal{E}} w(e)$. The \textit{weighted Maximum Cut problem} asks to find a cutset of maximum weight. The Ising formulation of the weighted Maximum Cut problem is obtained by modifying the (unweighted) formulation in~\cite{Hahn2017ReducingBQ}, resulting in
$$Q_{cut}(\bm{x})=\sum_{(i,j) \in E} w((i,j)) \cdot x_i x_j,$$
where $x_i, x_j \in \{-1,+1\}$. Since the Ising formulation of the Maximum Cut problem does not have linear terms, no slack variable $z$ is needed in the Ising formulation of eq.~\eqref{eq:H_final}. The scaling constant $\alpha_1$ for HG in eq.~\eqref{eq:H_final} is determined in Section~\ref{sec:experiments_maxcut_parameters}.

In order to have a baseline truth for comparing RA, HG, as well as RA+HG we proceed as follows. We generate random graphs with $65$ vertices, which is the largest size a maximum cut or maximum clique problem can be embedded into the D-Wave 2000Q quantum chip, and edge probability $p \in \{0.1,0.2,\ldots,0.9\}$, and uniformly drawn edge weights in $(-1,1)$. After fixing $10$ of those graphs for each density as well as their embeddings on D-Wave, we perform $1000$ anneals of duration $1$ ms. The best solution among those anneals is then taken as the baseline. When testing RA, HG and RA+HG, all values we report are averages over those $10$ graphs. Moreover, we generate another set of $10$ graphs for each density to use as a validation set.

\subsubsection{Setting scaling factors and annealing time}
\label{sec:experiments_maxcut_parameters}
We start by determining a suitable choice of the scaling factor $\alpha_1$ in eq.~\eqref{eq:H_final} for the Maximum Cut problem using the Bayesian optimization.

As a fitness function for the optimization, we use the improvement in the maximum cut over the baseline. Each time the optimizer issues a call to the fitness function, we supply the average of $10$ problems optimized with either RA, HG, or RA+HG (depending on which one is optimized) using the parameter set probed by the Bayesian framework. The fitness value is then the average maximum cut improvement over the baseline. We make the fitness function dependent on three parameters, the scaling factor $\alpha_1$ as well as the parameters $(h,t)$ determining the HG schedule (see Section~\ref{sec:parameters}). For this experiment the anneal time is set to $1$ ms.

After obtaining the fittest values, we fix the schedule $(h,t)$ and the annealing time of $1$ ms, and cross check the scaling factor $\alpha_1$ on a linear grid on $[0.01,1]$ in increments of $0.01$. Results for three different densities are shown in Figure~\ref{fig:maxcut_scaling}, which displays the difference in the maximum cut value to the baseline as a function of $\alpha_1$. We observe that the best choice of $\alpha_1$ is very dependent on the graph density, with, e.g.,\ the best choice for density $0.9$ occurring at $\alpha_1 \approx 0.3$. Table~\ref{tab:scaling_factors} in the appendix shows the precise optima we found for all nine densities $p \in \{0.1,\ldots,0.9\}$. We will be selecting the scaling factor depending on the underlying graph density in the remainder of this section.

\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{figures/Bayesian_Optimization/maxcut_scaling.pdf}
    \caption{Maximum Cut problem. Difference in the maximum cut value to the baseline as a function of the HG scaling factor $\alpha_1$.}
    \label{fig:maxcut_scaling}
\end{figure}

Next, we determine a suitable anneal duration for RA, HG, as well as the combined RA+HG. For this, we fix the HG schedule to the three points $[0, 5], [0.5T, 2.5], [T, 0]$ and the RA schedule to $[0, 1]$, $[0.25T, 0.25]$, $[0.75T, 0.25]$, $[T, 1]$, where $T$ is the total annealing duration (given in Table~\ref{tab:maxcut}). We note that these schedules are not optimal. Instead, they merely divide up the variable range in an equidistant fashion. We choose the anneal fraction to be around $0.25$ as suggested in~\cite{McGeoch2018}.

\begin{table*}
    \centering
    \caption{Evaluation of RA and HG, as well as RA+HG, for smallest and largest possible annealing times. Maximal cut difference on Erd{\H o}s--R{\'e}nyi graphs of density ranging from $0.1$ to $0.9$.\label{tab:maxcut}}
    \begin{tabular}{l|c||ccccccccc}
        & $T$ [ms] & 0.9 & 0.8 & 0.7 & 0.6 & 0.5 & 0.4 & 0.3 & 0.2 & 0.1\\
        \hline
        RA & 100 & 0.722 & -0.151 & 2.060 & 1.974 & 2.551 & 1.909 & 3.425 & 2.544 & 0.467\\
        RA & 2000 & 2.412 & -0.149 & 3.653 & 2.140 & 3.261 & 2.859 & 4.507 & 3.209 & 0.610\\
        HG & 1 & 5.173 & 2.084 & 3.72 & 2.632 & 3.127 & 2.799 & 2.876 & 2.082 & 0.338\\
        HG & 2000 & 3.963 & 1.266 & 2.216 & 1.421 & 2.047 & 1.617 & 1.705 & 1.525 & 0.185\\
        RA+HG & 100 & 3.853 & 2.832 & 4.867 & 3.022 & 3.478 & 3.170 & 4.32 & 2.726 & 0.526 \\ RA+HG & 2000 & 4.145 & 2.540 & 5.001 & 2.725 & 4.222 & 3.128 & 4.526 & 3.113 & 0.566
    \end{tabular}
\end{table*}
Table~\ref{tab:maxcut} shows maximum cut results for the smallest and largest possible anneal times as a function of the graph density. We observe that an annealing duration of $2000$ ms works best for RA, while a $1$ ms anneal is best for HG. The combined technique of RA+HG does not seem to be as affected by the annealing duration, but since an annealing time of $2000$ ms yields slightly better results, we decide to employ RA+HG in connection with a $2000$ ms anneal in this section.

\subsubsection{Schedule computation via Bayesian optimization}
\label{sec:experiments_maxcut_bayes}
After having fixed the annealing duration for all three methods, we proceed by determining the parameters of the anneal schedule (see Section~\ref{sec:parameters}) via Bayesian optimization. For each density, we carry out a single run of the Bayesian optimizer.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.5\textwidth]{figures/Bayesian_Optimization/GP_BO_hgain_0.5_maxcut.png}
    \caption{Bayesian optimization landscape for the HG schedule for Maximum Cut, visualized as a heatmap for graph density $0.5$ and annealing time $1$ ms. Top  shows maximum cut size improvement as a function of $g(t) \in [0,5]$ (see eq.~\eqref{eq:hgain}) on the y-axis, where $t$ is the position in the schedule (x-axis). Bottom  shows the variance of the Gaussian processes used by the Bayesian optimizer. Small dots indicate the points where the function was evaluated.}
    \label{fig:hgain_heat_map_maxcut}
\end{figure}
Since the schedule of HG has two parameters determining the midpoint in the anneal schedule (see Section~\ref{sec:parameters}), we can visualize its optimization as a heatmap in Figure~\ref{fig:hgain_heat_map_maxcut}. In particular, Figure~\ref{fig:hgain_heat_map_maxcut} shows the color coded improvement in cut size over the baseline for each possible midpoint in the HG schedule. As described in Section~\ref{sec:parameters}, this point consists of a position in the anneal and a value of the HG function $g(t) \in [0,5]$, see eq.~\eqref{eq:hgain}.

The figure shows that the best choice of the HG value, defined as the one yielding the best improvement in maximum cut difference (red values), roughly decreases with the position in the anneal. We determine the maximum in this way for each density $p \in \{0.1,\ldots,0.9\}$. The schedules for RA (3 parameters) and RA+HG (five parameters) are fitted in a similar way, one schedule per density $p \in \{0.1,\ldots,0.9\}$.

\subsubsection{Comparison of RA, HG, and RA+HG}
\label{sec:experiments_maxcut_comparison}
Having determined best schedule parameters for RA, HG, and RA+HG, we run the experiment again on 10 new graphs (per density) using these schedules. Figure~\ref{fig:maxcut_densities_rerun} shows results of this experiment. We observe that neither technique is uniformly better than the others. RA seems to be best for low densities, while HG and RA+HG perform best for high density graphs.

\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{figures/Bayesian_Optimization/maxcut_comp_new_probs.pdf}\hfill
    \caption{Comparison of RA, HG, and RA+HG with respect to the maximum cut improvement for the best schedules obtained via Bayesian optimization. Computed on \texttt{DW\_2000Q\_LANL}. }
    \label{fig:maxcut_densities_rerun}
\end{figure}

\subsubsection{Best schedules for RA, HG, and RA+HG}
\label{sec:experiments_maxcut_bestschedules}
It is interesting to look at the shape of some of the optimal schedules for RA and HG found by the Bayesian optimization. For this purpose, we visualize one example of a schedule for RA+HG.

Figure~\ref{fig:maxcut_schedules} shows the best schedules for RA and HG color-coded by density. For improved readability, we only display the schedules for $p \in \{0.1,0.5,0.9\}$.

\begin{figure*}
    \centering
    \includegraphics[width=0.5\textwidth]{figures/Bayesian_Optimization/maxcut_ra_schedules.pdf}\hfill
    \includegraphics[width=0.5\textwidth]{figures/Bayesian_Optimization/maxcut_hg_schedules.pdf}\hfill
    \caption{Maximum Cut problem. Best schedules for RA (left) and HG (right) for three different densities each, optimized for maximum cut difference. Each line is the best schedule for one density. }
    \label{fig:maxcut_schedules}
\end{figure*}

We observe a pattern for the RA schedules in Figure~\ref{fig:maxcut_schedules} (left). In particular, when optimizing for maximum cut difference, RA schedules for low densities decrease down to an anneal fraction of zero, followed by a pause until roughly the midpoint of the anneal. In contrast, RA schedules for high densities only decrease to roughly an anneal fraction of $0.5$ at the midpoint of the anneal, followed by a pause until almost the full annealing time.

Similarly, a pattern can be observed for the HG schedules in Figure~\ref{fig:maxcut_schedules} (right). The HG schedules for low densities seem to have a steeper slope at the start of the anneal, and flatten off afterwards. In contrast, schedules for high densities seem to be closer to a straight line between the start point $(0,5)$ and the end point $(1,0)$.

\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{figures/Bayesian_Optimization/3d_ra_hg.png}
    \caption{Illustration of an RA+HG schedule. Best schedule found for the Maximum Cut problem for $p=0.3$.}
    \label{fig:ra+hg_3d}
\end{figure}

An RA+HG anneal can be executed by sending to the D-Wave backend (in this case \texttt{DW\_2000Q\_LANL}) one RA schedule and one (independent) HG schedule. But while the RA aspect is easy to comprehend, the HG one is more difficult to grasp by just looking at the two component schedules because of the way the RA portion affects HG. Specifically, if $s=RA(t)$ and $g=HG(t)$ are the functions determined by the RA and HG schedules, respectively, then the real gain applied at time $t$ to the linear biases in eq.~\eqref{eq:hgain} is $(B(s)/2)HG(t)=B(RA(t))HG(t)/2$, where $B(s)$ is the function from eq.~\eqref{eq:FA}.

Figure~\ref{fig:ra+hg_3d} is given to help visualize the effect of an RA+HG schedule and the interplay between the parameters.
The time $t$ is normalized in $[0,1]$.
The RA component of the schedule, which has a pause for $t \in [0.6,0.89]$ at $s=0.21$ can be seen as a projection in the $t$-$s$ plane. 
The black line shows the HG values, specifically, the points $(t, s(t),hg(t))$ for $t\in(0,1)$.The HG schedule, which has middle point at $(t,hg)=(0.71,2.67)$, can be also seen as the lighter color projection in the $t$-$hg$ plane. 
The blue, green, and teal colors indicate the backward annealing, pause, and forward anneal phases, respectively. Finally, the cumulative gain applied to the linear biases at each time, which depends on both the values of HG and the annealing coefficient $B(s)$ from eq. (\ref{eq:hgain}), is represented by the darker colored portion of the plot. The annotated point shows the value of the gain (2.67) at the middle point of the HG schedule (at 0.71). To simplify the plot, function $B(s)$ has been normalized to $[0,1]$. We can see that the real gain applied during the pause and forward phases of the RA schedule stays mostly unchanged.

\subsection{Weighted Maximum Clique problem}
\label{sec:experiments_maxclique}
We carry out a similar analysis for the weighted Maximum Clique problem, defined as follows. For any graph $G=(V,E)$, a clique $C$ is a fully connected subset of vertices, i.e.\ $C \subseteq V$ such that $C \times C \subseteq E$. A maximum clique is a clique in $G$ of maximum size.

For the (vertex-)weighted version of the problem, we define a weight $w(v)$ for each vertex $v \in V$. The weight of a clique is accordingly defined as $w(C) = \sum_{v \in C} w(v)$. The weighted maximum clique problem asks for the clique $C \subseteq V$ having the largest weight $w(C)$. The QUBO formulation of the weighted Maximum Clique problem is obtained by modifying the (unweighted) formulation in~\cite{Chapuis2019}, resulting in
$$- \sum_{i=1}^n w(i) \cdot x_i + 2 \sum_{(i,j) \notin E} \max \{ w(i),w(j) \} \cdot x_i x_j,$$
where $x_i,x_j \in \{0,1\}$. We can convert the above QUBO formulation into an Ising problem using the equivalence given in \cite{Chapuis2019}. In contrast to the Maximum Cut problem investigated in Section~\ref{sec:experiments_maxcut}, the Maximum Clique formulation as an Ising model of the form of eq.~\eqref{eq:hamiltonian} does contain linear terms. We thus introduce a slack variable $z$ to homogenize the linear terms as in eq.~\eqref{eq:H'}, and add a new linear term encoding the initial solution as done in eq.~\eqref{eq:H_final}.

In the following experiments, we choose the vertex weights to be positive and randomly drawn from a uniform distribution in $(0.001,1)$.

\subsubsection{Setting scaling factors and annealing time}
\label{sec:experiments_maxclique_parameters}
We again focus first on the HG feature and repeat the tuning of Section~\ref{sec:experiments_maxcut_parameters}. In particular, to determine the two scaling factors $\alpha_1$ for $h(\bm x)$ and $\alpha_2$ for $z$, we run Bayesian optimization to fit both the schedule and the scaling factors simultaneously (see Section~\ref{sec:parameters}). For this, we fix the anneal time at $1$ ms.

Each time the Bayesian optimizer requests a new point, we return the average maximum clique improvement over the baseline (using $1000$ anneals) for $10$ graphs for each density. If no solutions are found, i.e.\ $z=-1$ for all $1000$ anneals, we return a large negative constant (we use $-1000$) to the optimizer.

After having obtained the result from the Bayesian optimization run, we fix the best schedule found. After initializing the Bayesian optimization algorithm with the parameters of the previous best solution (the previously found scaling constants $\alpha_1$ and $\alpha_2$ for the fixed schedule), we re-fit $\alpha_1$ and $\alpha_2$ with the help of the Bayesian optimization.

\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{figures/Bayesian_Optimization/GP_BO_scale_0.5_maxclique.png}
    \caption{Landscape in $\alpha_1$ (h-scale on the y-axis) and $\alpha_2$ (z-scale on the x-axis) explored by Bayesian optimization. Graph density for $p=0.5$. Top plot shows mean of Bayesian posterior, bottom one shows variance (uncertainty).}
    \label{fig:scaling_factor_heat_maps}
\end{figure}

Figure~\ref{fig:scaling_factor_heat_maps} shows the result of the Bayesian optimization run with a fixed annealing duration of $1$ ms and a graph density of $p=0.5$, as well as our fixed optimized schedule. We see that the best values for the scaling constants are essentially in a band around $\alpha_1=0.4$ (h-scale), with various maxima for $\alpha_2$ (z-scale). The precise optimal scaling factors for $p=0.5$ returned by the Bayesian optimization are $\alpha_1=0.35$ (for h-scale) and $\alpha_2 = 0.25$ (for z-scale), which we fix for the remainder of this section.

We repeat this procedure for the other values of $p \in \{0.1,0.2,\ldots,0.9\}$ as well, and use individual scaling constants for each density in the remainder of this section as done for the Maximum Cut problem.

\begin{table*}
    \centering
    \caption{Evaluation of RA and HG, as well as combined RA+HG, for smallest and largest possible anneal times. Maximum clique difference on Erd{\H o}s--R{\'e}nyi graphs for densities ranging from $0.1$ to $0.9$.\label{tab:maxclique}}
    \begin{tabular}{l|c||ccccccccc}
        & anneal [ms] & 0.9 & 0.8 & 0.7 & 0.6 & 0.5 & 0.4 & 0.3 & 0.2 & 0.1\\
        \hline
        RA & 100 & 0.366 & 0.142 & 0.031 & 0.068 & -0.309 & -0.124 & -0.391 & -0.364 & -0.322\\
        RA & 2000 & 0.481 & 0.289 & -0.041 &  -0.060 & -0.322 & -0.171 & -0.474 & -0.408 & -0.309\\
        HG & 1 & 1.195 & 1.307 & 1.263 & 0 & 0 & 0 & 0 & 0 & 0\\
        HG & 2000 & 0.908 & 1.004 & 1.018 & 0 & 0 & 0 & 0 & 0 & 0\\
        RA+HG & 100 & 0.780 & -0.797 & -3.874 & 0.104 & 0 & 0.659 & 0.442 & 0 & 0 \\
        RA+HG & 2000 & 1.127 & 0.050 & -2.167 & 0.011 & 0 & 0.610 & 0.309 & 0.039 & 0
    \end{tabular}
\end{table*}

After having tuned the HG feature, we now focus again on the three techniques (RA, HG and RA+HG). Similarly to Section~\ref{sec:experiments_maxcut_parameters}, we determine a suitable annealing duration for all three techniques by testing them for the shortest and longest annealing durations on Erd{\H o}s--R{\'e}nyi graphs of varying values of $p \in \{0,1,\ldots,0.9\}$.

Results are displayed in Table~\ref{tab:maxclique}, showing that RA works better for longer annealing times (especially for denser graphs), and HG works consistently better for lower annealing durations. We will thus employ RA with an annealing time of $2000$ ms in the remainder of this section, and HG with an annealing time of $1$ ms. For RA+HG we fix the annealing duration at $2000$ ms.

\subsubsection{Schedule computation via Bayesian optimization}
\label{sec:experiments_maxclique_bayes}
The experiments of the previous sections allowed us to fix the anneal times, as well as the (density dependent) schedules and scaling constants for HG, RA, as well as RA+HG. Using the calibrations of the three methods, we now evaluate HG, RA, and RA+HG on graphs of varying density with respect to the improvement of the maximum clique weight over the baseline.



\begin{figure*}
    \centering
    \includegraphics[width=0.5\textwidth]{figures/Bayesian_Optimization/maxclique_ra_schedules.pdf}\hfill
    \includegraphics[width=0.5\textwidth]{figures/Bayesian_Optimization/maxclique_hg_schedules.pdf}\hfill
    \caption{Maximum Clique problem. Best schedules for RA (left), and HG (right) optimized for maximum clique weight. Each line is the best schedule for one density.}
    \label{fig:maxclique_schedules}
\end{figure*}
Similarly to Figure~\ref{fig:maxcut_schedules} (left), we also report the best schedules found by the Bayesian optimization in the case of the Maximum Clique problem. All schedules are optimized to maximize the maximum clique weight over the baseline in a standard forward anneal.

Figure~\ref{fig:maxclique_schedules} shows the resulting schedules. For RA we see that, in contrast to the schedules for the Maximum Cut problem,  for low densities the optimal RA schedules decrease the anneal fraction at the start of the anneal to very small values, and perform a pause until almost the full annealing time. As the graph under consideration becomes denser, the anneal fraction is only decreased down to roughly $0.4$, and the pause occurs in the center having roughly a duration of half the annealing time. The schedules for HG (Figure~\ref{fig:maxclique_schedules}, right) resemble the ones observed for the Maximum Cut problem.

\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{figures/Bayesian_Optimization/GP_BO_hgain_0.5_maxclique.png}
    \caption{Maximum Clique problem. Bayesian optimization landscape for the HG schedule, visualized as a heatmap for $p=0.5$ and annealing time $1$ ms. Top shows maximum clique weight improvement as a function of $g(t) \in [0,5]$ (see eq.~\eqref{eq:hgain}) on the y-axis, where $t$ is the position in the schedule (x-axis). Bottom shows the variance of the Gaussian processes used by the Bayesian optimizer.}
    \label{fig:hgain_heat_maps}
\end{figure}
Similarly to Figure~\ref{fig:hgain_heat_map_maxcut}, we again visualize the optimization of the HG schedule as a heatmap in Figure~\ref{fig:hgain_heat_maps}. We see that the optimal point occurs at roughly position $0.2$ (anneal fraction) and has a HG value of around $1$.

\subsubsection{Comparison of RA, HG, and RA+HG}
\label{sec:experiments_maxclique_comparison}
\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{figures/Bayesian_Optimization/maxclique_comp_new_probs.pdf}
    \caption{Comparison of RA, HG, and RA+HG with respect to the improvement in maximum clique weight over the baseline. Plot uses the $10$ new problems.}
    \label{fig:maxclique_comparisons}
\end{figure}
As in Section~\ref{sec:experiments_maxcut_comparison}, we evaluate RA, HG as well as RA+HG after tuning the scaling factors, annealing durations, and schedules. Results are shown in Figure~\ref{fig:maxclique_comparisons} for $10$ new problems not used in the training set. We observe that the behavior of all three techniques is consistent: On the new problems, RA performs worst with the exception of graph density corresponding to $p=0.9$. Both HG and RA+HG perform very similarly and consistently better than RA, although they draw equal with RA for $p=0.9$.

This behavior is different from the equivalent experiment for Maximum Cut in Figure~\ref{fig:maxcut_densities_rerun}, where both HG and RA+HG were only marginally better than RA.

\begin{figure*}[ht!]
    \centering
    \includegraphics[width=0.32\textwidth]{figures/iterated/RA/fixed_init_QEMC_RA_iters20_0_Advantage_system4.1_lin10.pdf}
    \includegraphics[width=0.32\textwidth]{figures/iterated/RA/fixed_init_QEMC_RA_iters20_0_Advantage_system4.1_lin100.pdf}
    \includegraphics[width=0.32\textwidth]{figures/iterated/RA/fixed_init_QEMC_RA_iters20_0_Advantage_system4.1_lin200.pdf}\\
    \includegraphics[width=0.32\textwidth]{figures/iterated/RA/fixed_init_QEMC_RA_iters20_0_Advantage_system6.1_lin10.pdf}
    \includegraphics[width=0.32\textwidth]{figures/iterated/RA/fixed_init_QEMC_RA_iters20_0_Advantage_system6.1_lin100.pdf}
    \includegraphics[width=0.32\textwidth]{figures/iterated/RA/fixed_init_QEMC_RA_iters20_0_Advantage_system6.1_lin200.pdf}\\
    \includegraphics[width=0.32\textwidth]{figures/iterated/RA/fixed_init_QEMC_RA_iters20_0_DW_2000Q_6_lin10.pdf}
    \includegraphics[width=0.32\textwidth]{figures/iterated/RA/fixed_init_QEMC_RA_iters20_0_DW_2000Q_6_lin100.pdf}
    \includegraphics[width=0.32\textwidth]{figures/iterated/RA/fixed_init_QEMC_RA_iters20_0_DW_2000Q_6_lin200.pdf}\\
    \includegraphics[width=0.5\textwidth]{figures/legends/legend_QEMC_RA.pdf}
    \caption{QEMC with reverse annealing only. Random spin glasses on \texttt{Advantage\_system4.1} (top row), \texttt{Advantage\_system6.1} (middle row), and \texttt{DW\_2000Q\_6} (bottom row). Spin glasses generated with linearly spaced precision of $10$ (left column), $100$ (middle column), and $200$ (right column). The curves show different anneal fractions $s$ at which the symmetric reverse anneal is paused at, given in the legend. }
    \label{fig:RA_iterated_initial_state}
\end{figure*}

\subsection{Evaluation of QEMC}
\label{sec:QEMC_experiments}
We finally evaluate QEMC, that is, the technique of iteratively improving the sampled solutions. As outlined in Section~\ref{sec:QEMC}, four options are available for planting the solution in iteration. Those are the options evaluated in Sections~\ref{sec:experiments_maxcut} and \ref{sec:experiments_maxclique}, namely reverse annealing only, an h-gain field only (using the qubit coefficients to encode an initial state for the anneal), reverse annealing combined with h-gain (where the same initial states is encoded using both linear terms and the reverse annealing initial state), and forward annealing with a pause combined with h-gain initial state encoding. Each QEMC iteration uses $1000$ anneals and an annealing time of $100$ microseconds, and we plot the lowest energy state found at each iteration. For good parameter choices, we would observe that there is a monotonic decrease in the energy, e.g. the solutions are getting progressively better for the minimization combinatorial optimization problem. Each QEMC experiment (e.g. with each unique Ising model on each device) is initialized with the best solution found from a normal forward anneal (e.g. with a linearly interpolated anneal schedule) from $1000$ anneals with an annelaing time of $100$ microseconds. Therefore, each set of QEMC experiments begins in exactly the same initial state. 

\begin{figure*}[ht!]
    \centering
    \includegraphics[width=0.32\textwidth]{figures/iterated/HGain_forward_anneal/fixed_init_QEMC_HGain_iters20_0_Advantage_system4.1_lin10_POS10.pdf}
    \includegraphics[width=0.32\textwidth]{figures/iterated/HGain_forward_anneal/fixed_init_QEMC_HGain_iters20_0_Advantage_system4.1_lin100_POS10.pdf}
    \includegraphics[width=0.32\textwidth]{figures/iterated/HGain_forward_anneal/fixed_init_QEMC_HGain_iters20_0_Advantage_system4.1_lin200_POS10.pdf}\\
    \includegraphics[width=0.32\textwidth]{figures/iterated/HGain_forward_anneal/fixed_init_QEMC_HGain_iters20_0_Advantage_system6.1_lin10_POS10.pdf}
    \includegraphics[width=0.32\textwidth]{figures/iterated/HGain_forward_anneal/fixed_init_QEMC_HGain_iters20_0_Advantage_system6.1_lin100_POS10.pdf}
    \includegraphics[width=0.32\textwidth]{figures/iterated/HGain_forward_anneal/fixed_init_QEMC_HGain_iters20_0_Advantage_system6.1_lin200_POS10.pdf}\\
    \includegraphics[width=0.32\textwidth]{figures/iterated/HGain_forward_anneal/fixed_init_QEMC_HGain_iters20_0_DW_2000Q_6_lin10_POS10.pdf}
    \includegraphics[width=0.32\textwidth]{figures/iterated/HGain_forward_anneal/fixed_init_QEMC_HGain_iters20_0_DW_2000Q_6_lin100_POS10.pdf}
    \includegraphics[width=0.32\textwidth]{figures/iterated/HGain_forward_anneal/fixed_init_QEMC_HGain_iters20_0_DW_2000Q_6_lin200_POS10.pdf}
    \caption{QEMC with h-gain initial state encoding. Random spin glasses on \texttt{Advantage\_system4.1} (top row), \texttt{Advantage\_system6.1} (middle row), and \texttt{DW\_2000Q\_6} (bottom row). Spin glasses generated with linearly spaced precision of $10$ (left column), $100$ (middle column), and $200$ (right column). The curves show different HG strengths $h$, given in the legend.}
    \label{fig:QEMC_h-gain_pos50}
\end{figure*}

\subsubsection{QEMC with reverse annealing}
\label{sec:QEMC_RA}
We first consider QEMC with RA only, meaning that we iteratively refine a solution by encoding the previously found best result using RA. In this experiment, the anneal fraction $s$ at which the pause occurs is varied; we utilize $s \in \{ 0.35, 0.4, 0.45, 0.5 \}$. Figure~\ref{fig:RA_iterated_initial_state} shows our results for the three annealer generations given in Table~\ref{table:hardware_summary} (rows) and spin glass generation mechanisms (columns). Each curve is a run with a different anneal fractions $s$ for RA, given in the legend. The figure displays the minimum energy found in the $1000$ anneals in each iteration and for each parameter. 

We observe that the behavior of QEMC with reverse annealing on \texttt{Advantage\_system4.1} is quite similar to the one on \texttt{Advantage\_system6.1}, while results on \texttt{DW\_2000Q\_6} differ. For the first two devices, lower anneal fractions are suboptimal, while anneal fractions around $s \in [0.3,0.4]$ perform best. For anneal fractions which are too high, we observe little improvement of the solution over the iterations of QEMC. For \texttt{DW\_2000Q\_6}, results display a higher degree of volatility, and the values of $s$ yielding the best converge behavior are slightly higher than for the newer annealer generations, which is around $s \in [0.5,0.6]$.

\subsubsection{QEMC with h-gain state encoding}
\label{sec:QEMC_h-gain}
Next, we repeat the same experiment in Figure~\ref{fig:QEMC_h-gain_pos50}, though now we use the HG feature to plant the previous solution in each iteration. As before, the figure displays the minimum energy found in the $1000$ anneals in each iteration and for each parameter.

The time at which the h-gain schedule begins to decrease its strength on the linear terms is at $50$ microseconds, or half way through the anneal.

The results in Figure~\ref{fig:QEMC_h-gain_pos50} demonstrate that the the h-gain state encoding technique can be used to execute QEMC. We again observe that the newer generations of the D-Wave annealer, that is \texttt{Advantage\_system4.1} and \texttt{Advantage\_system6.1}, seem to be better suited for QEMC as they show a more stable convergence behavior. For \texttt{DW\_2000Q\_6}, convergence seems more unstable. In general the h-gain schedules that perform the best are when the h-gain strength is set to $0$ at $50$ microseconds into the $100$ microsecond anneal, which means that the method performs best when the initial is strongly encoded during the transverse field dominated portion of the anneal (e.g. the first half), and then is switched off for the rest of the anneal.

\subsubsection{QEMC with reverse annealing and h-gain}
\label{sec:QEMC_h-gain_RA}
As before, we can also combine RA and HG and use it to iteratively plant solutions before each anneal. This is investigated in Figure~\ref{fig:RA_and_h-gain_iterated_initial_state}, which displays the minimum energy found in the $1000$ anneals in each iteration and for each parameter combination of the anneal fraction $s$ for RA and HG strength $h$.

The results in Figure~\ref{fig:RA_and_h-gain_iterated_initial_state} are consistent with the previous ones reported in Sections~\ref{sec:QEMC_RA} and \ref{sec:QEMC_h-gain}. The newer annealer generations seem more suited for an application of QEMC, and across both \texttt{Advantage\_system4.1} and \texttt{Advantage\_system6.1} we observe a consistent improvement of the initial solution when applying QEMC. Interestingly, the best parameter combinations seems to depend more on the choice of $s$ than the choice of $h$, as roughly $s \in [0.35,0.5]$ in connection with any $h$ yields best results. On \texttt{DW\_2000Q\_6}, the application of QEMC works less well, though an improved behavior can be seen for higher precision of the mapped Ising coefficients (last column).

\begin{figure*}[ht!]
    \centering
    \includegraphics[width=0.32\textwidth]{figures/iterated/RA_HG/fixed_init_QEMC_RA_HG_iters20_0_Advantage_system4.1_lin10.pdf}
    \includegraphics[width=0.32\textwidth]{figures/iterated/RA_HG/fixed_init_QEMC_RA_HG_iters20_0_Advantage_system4.1_lin100.pdf}
    \includegraphics[width=0.32\textwidth]{figures/iterated/RA_HG/fixed_init_QEMC_RA_HG_iters20_0_Advantage_system4.1_lin200.pdf}\\
    \includegraphics[width=0.32\textwidth]{figures/iterated/RA_HG/fixed_init_QEMC_RA_HG_iters20_0_Advantage_system6.1_lin10.pdf}
    \includegraphics[width=0.32\textwidth]{figures/iterated/RA_HG/fixed_init_QEMC_RA_HG_iters20_0_Advantage_system6.1_lin100.pdf}
    \includegraphics[width=0.32\textwidth]{figures/iterated/RA_HG/fixed_init_QEMC_RA_HG_iters20_0_Advantage_system6.1_lin200.pdf}\\
    \includegraphics[width=0.32\textwidth]{figures/iterated/RA_HG/fixed_init_QEMC_RA_HG_iters20_0_DW_2000Q_6_lin10.pdf}
    \includegraphics[width=0.32\textwidth]{figures/iterated/RA_HG/fixed_init_QEMC_RA_HG_iters20_0_DW_2000Q_6_lin100.pdf}
    \includegraphics[width=0.32\textwidth]{figures/iterated/RA_HG/fixed_init_QEMC_RA_HG_iters20_0_DW_2000Q_6_lin200.pdf}
    \includegraphics[width=0.55\textwidth]{figures/legends/legend_QEMC_RA_HG.pdf}
    \caption{QEMC using reverse annealing and h-gain combined. Random spin glasses on \texttt{Advantage\_system4.1} (top row), \texttt{Advantage\_system6.1} (middle row), and \texttt{DW\_2000Q\_6} (bottom row). Spin glasses generated with linearly spaced precision of $10$ (left column), $100$ (middle column), and $200$ (right column). The curves show different combinations of both the symmetric pause anneal fractions $s$ for reverse annealing and the HG strength $h$, given in the legend. Note that the $h$ in the legend corresponds to the h-gain strength specified for at $50$ microseconds into the $100$ microsecond anneal, but the initial h-gain field is consistently set to be initialized an h-gain strength of $2$ (which in particular means this schedule can applied to all three quantum annealers).  }
    \label{fig:RA_and_h-gain_iterated_initial_state}
\end{figure*}



\subsubsection{QEMC with forward annealing with a pause and h-gain}
\label{sec:QEMC_h-gain_forward_anneal}

\begin{figure*}[ht!]
    \centering
    \includegraphics[width=0.32\textwidth]{figures/iterated/HGain_forward_pause/fixed_init_QEMC_HG_forward_QA_pause_iters20_0_Advantage_system4.1_lin10.pdf}
    \includegraphics[width=0.32\textwidth]{figures/iterated/HGain_forward_pause/fixed_init_QEMC_HG_forward_QA_pause_iters20_0_Advantage_system4.1_lin100.pdf}
    \includegraphics[width=0.32\textwidth]{figures/iterated/HGain_forward_pause/fixed_init_QEMC_HG_forward_QA_pause_iters20_0_Advantage_system4.1_lin200.pdf}
    \includegraphics[width=0.32\textwidth]{figures/iterated/HGain_forward_pause/fixed_init_QEMC_HG_forward_QA_pause_iters20_0_Advantage_system6.1_lin10.pdf}
    \includegraphics[width=0.32\textwidth]{figures/iterated/HGain_forward_pause/fixed_init_QEMC_HG_forward_QA_pause_iters20_0_Advantage_system4.1_lin100.pdf}
    \includegraphics[width=0.32\textwidth]{figures/iterated/HGain_forward_pause/fixed_init_QEMC_HG_forward_QA_pause_iters20_0_Advantage_system4.1_lin200.pdf}
    \includegraphics[width=0.32\textwidth]{figures/iterated/HGain_forward_pause/fixed_init_QEMC_HG_forward_QA_pause_iters20_0_DW_2000Q_6_lin10.pdf}
    \includegraphics[width=0.32\textwidth]{figures/iterated/HGain_forward_pause/fixed_init_QEMC_HG_forward_QA_pause_iters20_0_DW_2000Q_6_lin100.pdf}
    \includegraphics[width=0.32\textwidth]{figures/iterated/HGain_forward_pause/fixed_init_QEMC_HG_forward_QA_pause_iters20_0_DW_2000Q_6_lin200.pdf}
    \includegraphics[width=0.55\textwidth]{figures/legends/legend_QEMC_forward_annealing_HG.pdf}
    \caption{h-gain initial state encoding, with a forward anneal symmetric pause. At each iteration, and parameter combination, the minimum energy found in the $1000$ anneals is plotted as a function of iteration. The h-gain strength at which the schedule begins to monotonically decrease (Figure \ref{fig:iterated_anneal_schedules} middle left) is varied, along with the anneal fraction at which the symmetric pause occurs (Figure \ref{fig:iterated_anneal_schedules} right) in the forward anneal schedule. Random spin glass on \texttt{Advantage\_system4.1} top row, \texttt{Advantage\_system6.1} middle row, \texttt{DW\_2000Q\_6} bottom row. Left column random spin glass has linearly spaced precision of $10$, middle column has linearly spaced precision of $100$, right column has linearly spaced precision of $200$. The forward anneal pause fraction is varied, along with the h-gain strength, the legend shows which of these parameters are varied for each of the different lines in the plots. Note that the $h$ in the legend corresponds to the h-gain strength specified for at $10$ microseconds into the $100$ microsecond anneal, but the initial h-gain field is consistently set to be initialized an h-gain strength of $2$ (which in particular means this schedule can applied to all three quantum annealers). }
    \label{fig:QEMC_h-gain_FA_pause}
\end{figure*}

The schedule of forward annealing can be modified to introduce a pause during the anneal. In this case, we can use the h-gain initial state encoding method to specify an initial state, but then also use a forward annealing schedule with a pause, as opposed to the standard linearly interpolated schedule. The reasoning is that in other contexts, it has been shown that pausing can improve forward and reverse quantum annealing. Here we can utilize the h-gain field to reinforce that initial state while the pause is occurring in order to guide the iterative sampling towards monotonic solution improvement. The unknown thing a-priori is what h-gain field strength, and pause parameters, will work well for this - and we also do not know how this might compare against the combined reverse annealing and h-gain initial state encoding method. This method is the same as the method shown in Section \ref{sec:QEMC_h-gain}, but the anneal schedule is modified instead of using the standard linearly interpolated anneal schedule. 

The results for using this variant of iterative solution encoding is shown in Figure \ref{fig:QEMC_h-gain_FA_pause}. Notably the optimal schedule combination of h-gain schedules and forward annealing schedules (with pauses) is not consistent across the different quantum annealers or Ising models. For \texttt{Advantage\_system4.1} sampling the precision $10$, $100$, and $200$ Ising models the best parameter choices include the pause anneal fraction being in the range of $0.3-0.4$, and the $h$ strength being set to $0$ at $10$ seconds. This shows that the initially very strong h-gain field that is applied in the first $10$ microseconds of the anneal while the transverse field terms are still dominating the system is enough to seed the anneal and guide towards lower energy states, and provides a reasonable iterative energy improvement when used with QEMC. A similar result is seen for \texttt{Advantage\_system6.1}. For \texttt{DW\_2000Q\_6} sampling the precision $10$ Ising models, the $s=0.4$ and $h=0.5$ to $h=2$ give reasonable improvements in energy as a function of iteration. For \texttt{DW\_2000Q\_6} sampling the precision $100$ and $200$ Ising models, the parameters of $s=0.45$ and $h=0$ to $h=2$ are best. 






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion and Conclusion}
\label{sec:discussion}
In this contribution we investigated two techniques suitable to encode an initial solution prior to the anneal on the D-Wave 2000Q quantum annealer. The two techniques are the native reverse annealing feature of the D-Wave device, as well as our own method based on the h-gain feature.

Since the two techniques rely on a variety of tuning parameters, we conduct extensive testing to determine suitable annealing times, parameters, and schedules. Using optimized sets of parameters we compare both methods on both the Maximum Cut problem (whose Ising formulation does not have linear terms, thus making our h-gain technique directly applicable), as well as the Maximum Clique problem (for which we have to transform the Ising model first). Afterwards, we explore the suitability of both methods in a straightforward technique, iterated quantum annealing also referred to as QEMC. We summarize our findings as follows:

\begin{enumerate}
    \item The h-gain feature of D-Wave quantum annealers can be used to implement the QEMC algorithm. We demonstrate this using hardware-native spin glass instances. This type of iterative sampling on whole-chip quantum annealers has not been done before, but both the reverse annealing and h-gain version of this could be applied to quantum annealing chip native Ising benchmarking, such as what is demonstrated in ref. \cite{tasseff2022emerging}. 
    \item The annealing durations for RA and HG seem to be very problem dependent. However, there is a consistent pattern in the anneal schedules for the weighted maximum clique and weighted maximum cut. Specifically, for graphs of lower density, RA schedules with an early and longer pause at a low anneal fraction are advantageous, whereas for higher densities a shorter pause at an anneal fraction of around $0.5$ seems better. For HG, the optimal schedules are close to the line connecting $(0,5)$ and $(1,0)$ independently of the density.
    \item The scaling constants can be found successfully via Bayesian optimization.
    \item In our experiments, the annealer almost always returned samples with value for the slack variable $z=1$ for the optimized HG schedules. Having $z=1$ is necessary for our technique to work, but we did not expect it to happen so often. Although the precise explanation of this observation is still unknown, one possible explanation is that the HG bias helps guiding the anneals towards solutions with $z=1$. We also observe that $z=1$  occurs with much lower frequency for non-optimal HG schedules.
    \item We conclude that our technique to plant initial solutions with the help of the HG feature, as well as RA+HG, seem to be a viable alternative to reverse annealing.
\end{enumerate}

This article leaves considerable scope for future work:
\begin{enumerate}
    \item In this work we only considered RA schedules with two points defining a pause, and HG schedules with one point. However, more complicated schedules for both RA and HG are possible, including other annealing times, and RA+HG schedules with more points. 
    \item The h-gain initial state encoding technique we have proposed can be applied to many more interesting problems such as graph partitioning, the traveling salesman problem, minimum vertex cover, or graph coloring. Additionally, many of those problems themselves exist in different variants, including unweighted, vertex- or edge-weighted formulations.
    \item We used the Bayesian optimization framework of \cite{bayesianopt} in a rather ad-hoc way. Tuning the parameters of the Bayesian optimization, in particular with the aim to make the optimization more robust against the noise in the D-Wave samples, could further improve the optimized parameters and schedules we report.
    \item For cases where $z$ does not always equal 1, one could observe if the proportion of anneals where $z=1$ is higher for RA+HG in comparison to HG only, assuming all other variables are held constant. This is conjectured to be true because in RA+HG the value of $z$ is reinforced by the initial state of RA.
    \item Both the h-gain schedule and the anneal schedule can have many more points specified, allowing for very complex anneal schedules. Generally, complex anneal schedules have not been investigated in detail, for example by repeatedly turning off and on a specific state specified by the linear terms. 
    \item The Quantum alternating operator ansatz (QAOA) \cite{Hadfield_2019, https://doi.org/10.48550/arxiv.1411.4028} algorithm, which is a hybrid classical-quantum algorithm that operates on universal gate model quantum computers, can be warm-started \cite{Egger_2021}. Therefore, it can be used to iteratively improve solution quality in a similar fashion to QEMC.  
\end{enumerate}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Acknowledgments}
\label{section:acknowledgments}
This work was supported by the U.S. Department of Energy through the Los Alamos National Laboratory and the Laboratory Directed Research and Development program of Los Alamos National Laboratory under project number 20220656ER. Research presented in this article was supported by the NNSA's Advanced Simulation and Computing Beyond Moore's Law Program at Los Alamos National Laboratory. Los Alamos National Laboratory is operated by Triad National Security, LLC, for the National Nuclear Security Administration of U.S. Department of Energy (Contract No.~89233218CNA000001). The work of the H.D.\ was also supported by grant number KP-06-DB-11 of the Bulgarian National Science Fund. This research used resources provided by the Los Alamos National Laboratory Institutional Computing Program.

This work has been assigned the technical report number LA-UR-23-22902.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\appendix
\section{Appendix}

\subsection{Scaling factors for the HG technique}
\label{sec:scaling_factors}
The appendix contains the precise scaling factors $\alpha_1$ and $\alpha_2$ of eq.~\eqref{eq:H_final} we employ to apply the HG technique of Section~\ref{sec:hgain}. The Ising formulation of the Maximum Cut problem of Section~\ref{sec:experiments_maxcut} only requires one scaling factor, whereas the one of the Maximum Clique problem of Section~\ref{sec:experiments_maxclique} requires two scaling factors. They are given in Table~\ref{tab:scaling_factors} and depend on the density of the graph that each problem is applied to.

\begin{table}
    \centering
    \caption{Best scaling factor(s) for HG as a function of the graph density. Left: Parameter $\alpha_1$ of the Maximum Cut problem. Right: Parameters $\alpha_1$ and $\alpha_2$ of the Maximum Clique problem.\label{tab:scaling_factors}}
    \begin{tabular}{c|c|cc}
    Density & Maximum Cut & \multicolumn{2}{|c}{Maximum Clique}\\
    & $\alpha_1$ & $\alpha_1$ & $\alpha_2$\\
    \hline
    0.1 & 0.16 & 0.3271 & 0.2997\\
    0.2 & 0.23 & 0.2709 & 0.8897\\
    0.3 & 0.51 & 0.1997 & 0.5401\\
    0.4 & 0.48 & 0.1542 & 0.9246\\
    0.5 & 0.41 & 0.3467 & 0.2473\\
    0.6 & 0.48 & 0.2602 & 0.7586\\
    0.7 & 0.63 & 0.0292 & 0.7455\\
    0.8 & 0.93 & 0.0334 & 0.0210\\
    0.9 & 0.33 & 0.0370 & 0.5121
    \end{tabular}
\end{table}


