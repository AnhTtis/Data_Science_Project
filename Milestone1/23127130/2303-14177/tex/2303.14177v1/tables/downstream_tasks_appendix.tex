\begin{table*}[t!]
\centering
\small
\begin{tabular}{lrrrrrrr}
& \multicolumn{6}{c}{\it Few-shot Text Classification Accuracy (\%)} \\
\toprule
% \cmidrule(lr){2-9}
  & \bf AGNews & \bf DBPedia & \bf SST-2 & \bf Amazon & \bf Phrasebank  & \bf Twitter \\ 
 $\downarrow$ Model (inference parameters) &  \it Topic & \it Topic & \it Sentiment & \it Sentiment & \it Sentiment & \it Hatespeech & \bf Average \\

\midrule
Random chance & 25.0 & 7.10 & 50.0 & 50.0 & 33.3 & 50.0 & 35.9 \\
OPT (1.3B) &  42.9 & 57.2 & 72.8 & 81.3 & 72.5 & 65.1 & 65.3 \\

OPT (6.7B) &  51.9 & 58.9 & 77.0 & 83.8 & 76.4 & 39.6 & 64.6 \\
\midrule
1-cluster (1.3B) & 47.4 & 61.1 & 80.2 & 80.7 & 66.6 & 60.9 & 66.2 \\
1-cluster (6.7B) & \bf 68.1 & 62.4 & 80.7 & \bf 84.9 &  80.6 & 37.4 & 69.0 \\
\midrule

 & \multicolumn{6}{c}{\textit{Cluster Routing}}
  \vspace{1mm}
\\
% \parbox[t]{3pt}{\multirow{3}{*}{\rotatebox[origin=c]{0}{\bf {cluster routing}}}} 
16-cluster; top-1 (1.3B) & 47.1	& 62.9	& 74.3 & 	79.1 &	72.9 &	56.4 & 65.4  \\
16-cluster; top-4 (5.2B) & 49.3	& 62.3 &  80.0 &	81.3 &	  78.7 & 	61.3 & 68.8 \\
16-cluster; top-16 (20.8B) & 50.6 &	62.0 &	84.0 & 83.2 &	78.6 &	 61.7 & 69.9  \\
\midrule
 & \multicolumn{6}{c}{\textit{Updating Performance Routing}}
  \vspace{1mm}
\\

16-cluster; top-1 (1.3B) & 54.5 &	\bf 63.4	& 83.4	&	83.6		&74.7		&64.8 & 63.3 \\
16-cluster; top-4 (5.2B) &51.6		&61.5		&88.6		&83.7		&\bf 80.7	& \bf 65.3	& 68.8	 \\
16-cluster; top-16 (20.8B) & 51.1		& 60.4	&	86.0	&	83.5	&	79.8	&	62.9	& 69.1	 \\
\midrule
 & \multicolumn{6}{c}{\textit{Fixed Performance Routing (8 demonstrations)}}
  \vspace{1mm}
\\
16-cluster; top-1 (1.3B) & 45.3	& 61.9 & 	81.2 & 	83.6 &	76.4 &	60.1 & 68.1 \\
16-cluster; top-4 (5.2B) & 51.2	& 60.9	 & 81.4 &	83.0 & 	80.5& 	60.9 & 69.6 \\
16-cluster; top-16 (20.8B) & 50.6	& 60.2 &	84.1 &	83.5	& 79.1	& 60.5 & 69.6 \\
\midrule
 & \multicolumn{6}{c}{\textit{Fixed Performance Routing (8 demonstrations + 8 validation examples)}}
  \vspace{1mm} \\
16-cluster; top-1 (1.3B) & 54.5	& \bf 63.4	& 83.4	 & 83.6	& 74.7 & 64.8 & 70.7 \\
16-cluster; top-4 (5.2B) & 51.6 &	61.5 &  \bf 	88.6	 & 83.7 &	\bf 80.7 &	\bf 65.3 & \bf 71.9 \\
16-cluster; top-16 (20.8B) & 51.1 &	60.4	& 86.0	& 83.5	& 79.8 &	 62.9 & 70.6\\ 

\bottomrule
\end{tabular}
\caption{\textbf{\cbtm models with performance routing achieve even better performance on downstream tasks (\S\ref{sec:appendix_downstream_tasks}).} We display performance of models on six text classification tasks, using eight demonstrations for each example and no additional fine-tuning. We compare our cluster routing method (described in \S\ref{sec:downstream_tasks}) to variants of performance routing (described in \S\ref{sec:appendix_downstream_tasks}). Fixed performance routing with 8 demonstrations and 8 validation examples usually gets the best performance on downstream tasks, consistently outperforming even the 6.7B parameter baselines. Fixed performance routing with top-4 inference always improves performance over using all experts, and top-1 inference  does substantially better than the dense baselines at no additional inference costs. We include average performance across tasks for readability.}
\label{tab:downstream_tasks_appendix}
\end{table*}
