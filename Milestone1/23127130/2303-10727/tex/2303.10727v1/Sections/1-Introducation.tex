\section{Introduction}
\label{sec:intro}
Social ambiance, which describes the context of an environment where social interactions are happening, can be measured via speech audio~\cite{chen2021privacy,wang2014local}. Among the widely used social ambiance measure (SAM) solutions, counting the number of concurrent speakers around an individual has been verified to be associated with their mental health symptoms (e.g., depression and psychotic disorders)~\cite{chen2021privacy}.
While deep neural networks (DNNs) have enabled accurate SAM in mental health tracking by counting concurrent speakers~\cite{chen2021privacy}, it is still challenging to achieve continuous, real-time, and on-device DNN-based SAM, which is highly desirable for preserving user privacy and thus ensuring wide adoption of the aforementioned mental health tracking. 
\underline{First}, powerful DNNs are often complex while mobile/wearable devices are very limited in both computational and memory resources, e.g., deploying the wav2vec2 DNN~\cite{baevski2020wav2vec} on a Pixel 3 phone~\cite{pixel3} for speech recognition requires 2200 mW~\cite{pytorch_mobile_wav2vec2} power consumption vs. only 700 mW~\cite{zhidkov2018smartphone} allowed by the Pixel 3 phone~\cite{pixel3}.   
\underline{Second}, training DNNs usually requires a large amount of labeled data to achieve a satisfactory task accuracy, whereas SAM users expect DNNs to be trained locally on a device with limited data (e.g., less than 8 hours of training data~\cite{xu2020lrspeech}), due to both the privacy concern and prohibitive human effort needed to collect clinical SAM audio data. 


\begin{figure}[t]
    \centering
    \includegraphics[width=1.0\linewidth]{Figures/performance_v3.pdf}
    \vspace{-2em}
   \caption{DNNs searched by our ERSAM outperform state-of-the-art DNN-based SAM: achieving the best accuracy vs. hardware efficiency trade-offs while meeting the requirements of being energy-efficient and achieving real-time latency. Here a smaller volume of each data point's 3D cuboid corresponds to a better accuracy vs. hardware efficiency trade-off.}
    \label{fig:performance_overview}
    \vspace{-2em}
\end{figure}

To close the aforementioned gap between the required computational complexity for DNN-based SAM and the limited resources on mobile/wearable devices, it is critical to develop compact DNNs that ensure \underline{(i)} real-time latency (e.g., \textbf{$\leq$ 5 seconds of processing time for an audio segment of 5 seconds}~\cite{chen2021privacy}) for timely usage of the generated SAM information (e.g., real-time intervention),
\underline{(ii)} constrained energy (\textbf{$\leq$ 700mW $\cdot$ 12h~\cite{zhidkov2018smartphone}}), and \underline{(iii)} an acceptable SAM accuracy under the aforementioned low-resource settings.
Thanks to the recent success of both \underline{(i)} \textbf{H}ard\textbf{w}are-aware \textbf{N}eural \textbf{A}rchitecture \textbf{S}earch (HW-NAS)~\cite{wu2019fbnet} in developing DNN models with optimal accuracy vs. hardware efficiency trade-offs~\cite{wu2019fbnet,cai2019once,yu2020bignas} and \underline{(ii)} knowledge distillation in leveraging pre-trained giant models to boost the achievable accuracy of compact DNNs ~\cite{hinton2015distilling,gou2021knowledge}, it is natural to consider them for continuous, real-time, and on-device DNN-based SAM solutions. 
However, existing HW-NAS and knowledge distillation techniques are not directly applicable for meeting the above requirements for the following reasons: \underline{(i)} prior HW-NAS works mainly focus on computer vision or natural language processing tasks~\cite{wu2019fbnet,cai2019once}, where the search space of existing HW-NAS works might not be optimal or even feasible for DNNs dedicated to SAM due to their differences from SAM in terms of 1) input modalities (e.g., images vs. audio), 2) commonly used operators (e.g., 2D convolution vs. 1D convolution), and 3) dataset size (e.g., 150 GB ImageNet~\cite{deng2009imagenet} with $>$ 1 million images vs. 1 GB dataset with only 8 hours of audio);
and \underline{(ii)} the large cost of querying the giant models required by vanilla knowledge distillation techniques 
makes knowledge distillation impractical to be used on a local edge/mobile device.

Our key contribution is a new framework, called neural architecture search for Energy-efficient and Real-time SAM (ERSAM), which achieves continuous, real-time, and on-device DNN-based SAM, as elaborated below. 


\begin{itemize}
    \item We develop and validate a dedicated HW-NAS and knowledge distillation framework called ERSAM to develop DNN-based SAM solutions toward meeting SAM's real-world application driven requirements. 
    \item ERSAM Enabler 1: The proposed ERSAM integrates a hardware-aware search space dedicated to SAM by leveraging the cost profiling observations from state-of-the-art DNN-based SAM models on mobile phones. 
    \item ERSAM Enabler 2: We propose an efficient knowledge distillation scheme to be embedded into both the search and training processes of our ERSAM framework's HW-NAS engine, which enables the feasibility of developing compact yet effective DNNs for SAM on the local edge by only making necessary queries to the giant teacher model.
    \item ERSAM performance: As shown in Fig. \ref{fig:performance_overview}, our ERSAM framework's delivered DNNs fulfill all the above requirements, achieving \underline{(i)} \textbf{0.05 seconds ($\leq$ 5 seconds~\cite{chen2021privacy})} latency for an audio segment of 5 seconds, \underline{(ii)} \textbf{40 mW $\cdot$ 12 h ($\leq$ 700 mW $\cdot$ 12 h~\cite{zhidkov2018smartphone})} energy consumption on a Pixel 3 phone, and \underline{(iii)} 14.3\% error rate ($\downarrow$ 3.6\% than the state-of-the-art work of counting the number of speakers~\cite{stoter2018countnet}) under the low-resource setting of \textbf{8 hours ($\leq$ 8 hours~\cite{xu2020lrspeech})} training data.
\end{itemize}


