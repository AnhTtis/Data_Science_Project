\section{Related Work}
\label{sec:related_work}
\vspace{-2pt}

Our work is closely related to two topics in the visualization field: NRL and the interpretation of learned representations. 
For the broader discussion on visualizations for analyzing networks and interpreting machine learning results, refer to existing surveys~\cite{kerren2014multivariate,mcgee2019state,beck2017taxonomy,chatzimparmpas2020state}.

\vspace{-2pt}
\subsection{Learning Network Representations}
\vspace{-2pt}

NRL aims to generate a set of low-dimensional vectors (also called representation) that captures certain important characteristics of networks, nodes, or links~\cite{zhang2018network}. 
The representation is usually learned for downstream tasks, such as node classification and link prediction. 
Various NRL methods are developed, including node2vec~\cite{grover2016node2vec}, graph convolutional networks~\cite{kipf2016semi}, graph neural networks (GNNs) with the self-attention~\cite{ying2021transformers}, to name but a few~\cite{zhang2018network}. 

The researchers have been utilizing NRL for visualization to interactively examine complex network datasets.
For example, Freire et al.~\cite{freire2010manynets} represented one network by a set of network statistics (e.g., degree distribution) to compare many networks in a tabular interface. 
Gove~\cite{gove2019gragnostics} suggested several network-level features (e.g., density) that are easier to interpret and faster to compute for interactive visualization.
Other researchers utilized the occurrences of graphlets~\cite{prvzulj2007biological} (small, connected, non-isomorphic subgraph patterns in a network) to identify visually similar networks~\cite{von2009visual,harrigan2012egonav,kwon2017would}.
When node correspondence exists among networks, another common approach is directly applying DR methods to networks' adjacency matrices to capture the similarities of networks~\cite{bach2016time,fujiwara2017visual}.
Van den Elzen et al.~\cite{vandenelzen2016reducing} took a similar DR approach while further incorporating network statistics. 
Martins et al.~\cite{martins2012multidimensional,martins2017mvn} used DR to lay out nodes by their structural and semantic similarities.

Similar to ours, recently, a few works employed NN-based NRL.
Fujiwara et al.~\cite{fujiwara2022network} introduced contrastive NRL (cNRL) by integrating a variant of GNNs and contrastive learning~\cite{zou2013contrastive}.
cNRL extracts a representation of two networks, where salient characteristics in one network relative to another are highlighted.
Utilizing linear DR, they further designed an interpretable cNRL method and enhanced it with interactive visualizations~\cite{fujiwara2020visual}. 
Song et al.~\cite{song2022interactive} used GNNs to support interactive subgraph pattern search, where GNNs are used to covert each network in a comparable, fixed-length latent vector. 

Unlike the above approaches, we use NN-based NRL to obtain representations that are specifically for uncovering the associations of interest in multivariate networks.
Also, we address the interpretation of network representations with composite variable construction, which is easier to understand when compared with the approaches referring to complex coefficients in linear DR results~\cite{fujiwara2020visual,fujiwara2022network}.

\vspace{-2pt}
\subsection{Interpreting Representations}
\vspace{-2pt}

Although the interpretation support for NRL is still sparsely studied (e.g., \cite{fujiwara2020visual}), a set of interpretation methods are developed for representations of high-dimensional data. 
Such representations are often extracted by DR methods or NNs~\cite{huang2023va}. 
Existing interpretation methods can be categorized into two approaches: (1) identifying essential information to specific patterns found in representations (i.e., post-hoc explanation approach) and (2) constructing simple, interpretable representations during a learning phase (i.e., explainability-by-design approach~\cite{hamon2020robustness}).

Many visual analytics methods for the interpretation of nonlinear DR results fall under the first approach. 
For instance, researchers identified influential attributes on the cluster formation in DR results from statistical charts (e.g., boxplots of attributes for each cluster)~\cite{kwon2018clustervision,neto2021multivariate,vanozenoodt2022outoftheplane}.
As univariate statistics are often insufficient to capture the cluster characteristics, researchers further considered influences from multiple attributes~\cite{fujiwara2020supporting,joia2015uncovering,turkay2012representative,zhou2016dimension,zang2022evnet}.
For example, Joia et al.~\cite{joia2015uncovering} applied PCA to each cluster to examine multivariate influences.
Although many methods are designed to understand clusters, several methods are to understand other patterns (e.g., local correlations)~\cite{chatzimparmpas2020tvisne,faust2018dimreader,cavallo2018visual}.

There are a relatively small number of visual analytics works taking the explainability-by-design approach. 
Knittle et al.~\cite{knittel2020visual} used NNs consisting of one hidden layer with a small number of NN nodes to extract nonlinear representations that relate input attributes to a target output attribute.
This simple NN allows analysts to identify 
a small number of representations that show clear associations between the input and target attributes. 
% Then, they constructed a stacked histogram for each input attribute to visually convey such relationships in detail.
Gleicher~\cite{gleicher2013explainers} produced simple composite variables that are to classify a user-selected attribute.
To craft such composite variables, Gleicher performed a support-vector machine-based exhaustive search for the selection of composing variables while considering a balance between their simplicity and expressiveness.

In terms of using NNs to extract the input-output relationships, the work by Knittle et al.~\cite{knittel2020visual} is closely related to ours. 
However, their interpretation of the obtained representations is based only on univariate value distributions, which is insufficient when NNs capture complex input-output relationships.
Similar to Gleicher's work~\cite{gleicher2013explainers}, our work crafts simple composite variables, but we do not involve the computationally expensive exhaustive search. 
Instead, we rank variables based on their contributions to the NNs' predictions and involve analysts' knowledge to select attributes of interest.
