\vspace{-1pt}
\section{Methodology}
\vspace{-1pt}

This section introduces our visual analytics workflow and two-class density scatterplot.
We first describe design considerations of the workflow, which we identify based on our literature survey in \autoref{sec:related_work} and targeted analysis on multivariate networks.
% (for the detailed definition of multivariate networks, refer to the introduction by Kerren et al.~\cite{kerren2014multivariate}).
We then provide an overview of the workflow, followed by the details of each step.

\vspace{-1pt}
\subsection{Design Considerations}
\vspace{-1pt}

The following five design considerations (DCs) are identified to support the analysis task for understanding associations of interest and to fill the analytical gap that is not covered by existing methods.

\newcommand{\Flexibility}{DC1: Flexibility}
\newcommand{\Expressivity}{DC2: Expressivity}
\newcommand{\Interpretability}{DC3: Interpretability}
\newcommand{\Steerability}{DC4: Tunability}
\newcommand{\Extensibility}{DC5: Extensibility}

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.895\linewidth]{figures/workflow.pdf}
    \caption{\CaptionWorkflow{}}
    \label{fig:workflow}
\end{figure*}
\begin{figure*}[t]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/ui.pdf}
    \caption{\CaptionUI{}}
    \label{fig:ui}
\end{figure*}

\textbf{\Flexibility.} Analysis of multivariate networks requires reviewing intertwined relationships in both structural and semantic information~\cite{kerren2014multivariate}. 
Also, based on analysis purposes and available datasets, analysts often want to investigate networks from different levels, such as node, link, and network levels (e.g., node: \cite{martins2017mvn,fujiwara2020visual}; 
link: \cite{crnovrsanin2014visualization};
and network levels: \cite{song2022interactive,freire2010manynets,kwon2017would,vandenelzen2016reducing}).
The workflow should provide flexibility to conduct analyses from multiple aspects at various levels.
    
\textbf{\Expressivity.} Our work's main objective is to support examining associations among target (e.g., the addiction level to social media) and other related information (e.g., gender, age, and friendships). 
The workflow should be able to extract features that are expressive for this analysis task (i.e., containing important information to reveal associations) rather than providing a general summary of networks. 

\textbf{\Interpretability.} Interpretation is essential to gain insights into analysis results~\cite{knittel2020visual,gleicher2013explainers}. 
Because expressive features such as those extracted by NNs are often difficult to interpret only from each individual attribute's influence~\cite{fujiwara2020visual,cunningham2014dimensionality}, the workflow should provide more advanced interpretation support that considers the combined influence from multiple attributes.

\textbf{\Steerability.}
Conflict often exists between the expressiveness and interpretability of features (i.e., more expressive, more difficult to interpret)~\cite{gleicher2013explainers,zou2006sparse,malerba1996further}.
Also, the required preciseness of interpretation can be varied by analysis (i.e., complicated but precise interpretation vs. less precise but simpler interpretation). 
The workflow should allow control of the balance of expressiveness and interoperability. % based on analysts' interests. 
    
\textbf{\Extensibility.} Although we provide a concretized method for each step of the workflow, a different set of methods may be more suitable according to the characteristics of future datasets and analysis goals~\cite{cunningham2015linear,wu2020comprehensive,zhang2018network,fujiwara2021interactive}.
The workflow should be extensible to incorporate new or different methods.

\vspace{-1pt}
\subsection{Workflow Overview}
\vspace{-1pt}

\autoref{fig:workflow} shows our workflow for reviewing associations embedded in multivariate networks.
It consists of six steps that are performed first with a script for machine learning (Steps 1--4) and then with our user interface (UI) designed for visual analysis (Steps 5--6).
The UI is shown in \autoref{fig:ui}.
As we describe in \autoref{sec:repr_learning}, we extract structural information as a set of network measures (e.g., degree and betweenness centralities) for each element (i.e., node, link, or network); thus, in the following, we use a term, attribute, to indicate both extracted structural (e.g., degree) and semantic information (e.g., age).

\textbf{Step 1.} 
The workflow begins with the extraction and selection of input attributes and one output/target attribute. 
For example, to know how students' grades in a school class are related to their surrounding conditions, an analyst can choose their attending class size, mental health status (e.g., depression level), and centrality in social media connections (e.g., degree) as inputs and their grade as an output.

\textbf{Step 2.} 
NRL is performed based on the selected inputs and output. 
A network representation is generated by an NN trained to perform binary prediction of the output (e.g., good or bad grade) with the inputs. 
The derived representation directly relates to associations of interest. 

\textbf{Step 3.} 
This step compresses the dimensionality of the network representation into one while preserving the prediction quality as much as possible. 
This makes the remaining steps simpler to complete and the related results easier to interpret.

\textbf{Step 4.} 
This step evaluates and ranks each input attribute's contribution to the 1D compressed representation. 
The obtained ranks can be considered as recommendation levels for the inclusion of the corresponding attributes for composite variable construction in Step 5. 

\textbf{Step 5.}
Finally, based on the recommendation levels and interests, an analyst manually selects a small set of attributes (e.g., 2--5 attributes) and runs a composite variable construction algorithm. 
The optimized composite variable (e.g., $y$-axis in \autoref{fig:ui}-b2) maximally resembles the 1D compressed representation (e.g., $x$-axis in \autoref{fig:ui}-b2). 
This composite variable provides an intuitive explanation of how the selected small set of attributes is related to the output/target attribute. 

\textbf{Step 6.}
The UI in \autoref{fig:ui} visualizes the information related to each previous step as well as the detailed structural and semantic information of the multivariate network. 
By interactively reviewing visualizations, the analyst can gain insights or adjust settings for each step based on their need (the backward arrows in \autoref{fig:workflow}).
% The analyst can also refer to the UI at each step (the forward arrows in \autoref{fig:workflow}).

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.88\linewidth]{figures/scatterplots.pdf}
    \caption{\CaptionScatterplots{}}
    \label{fig:scatterplots}
\end{figure*}


\subsection{Two-class Density Scatterplot}
\label{sec:twoclass-scatterplot}

We here introduce a \textit{two-class density scatterplot} (\autoref{fig:scatterplots}-d), which we use to visualize results from most of the steps in the workflow.
From a scatterplot of two variables (e.g., the 1D compressed representation and the composite variable generated at Steps 4--5), we aim to simultaneously depict (1) patterns related to binary classes; (2) trends including correlations; (3) other supplemental patterns, such as noises, outliers, and clusters.
For example, analysts may want to review class separation to assess the quality of network representations, correlation patterns related to the composite variable to gain insights, and patterns only seen in subgroups to consider further analyses.

According to a survey on scatterplot designs~\cite{sarikaya2018scatterplots}, we should employ an aggregated-level visual encoding (e.g., binning-based encoding) of instances to reveal trends while we should show individual instances for the other tasks (e.g., finding outliers).
However, designing an encoding that satisfies these requirements is not straightforward.
For example, in \autoref{fig:scatterplots}-a, class information is encoded with colored dots. 
This encoding easily suffers from overplotting when analyzing a large dataset (e.g., 1000 instances). 
In \autoref{fig:scatterplots}-a, it is difficult to find a clear trend due to noises. 
In contrast, density scatterplots are effective in finding trends.
For instance, \autoref{fig:scatterplots}-b reveals a correlated pattern.
However, from density scatterplots, we cannot grasp distributions related to classes (e.g., whether the dense area mostly consists of a single class).
A few existing scatterplot enhancements, splatterplots~\cite{mayprga2013splatterplots} and winglets~\cite{lu2020winglets}, can show both aggregated- and instance-level information along with class information. 
However, based on our experiment~\cite{supp}, both enhancements still easily suffer from overplotting and noises.
Also, these enhancements are sensitive to the choice of parameters of their algorithms (e.g., threshold for contouring) and visualizations (e.g., dot size).


A two-class density scatterplot (\autoref{fig:scatterplots}-d) is designed to solve the above issues.
Using a bivariate colormap, a two-class density scatterplot encodes the \textit{total density} from both classes and the \textit{density ratio} of each class with color lightness and hue, respectively.
In \autoref{fig:scatterplots}-d, first, we can clearly see the correlated pattern as in the density scatterplot.
In addition, we can confirm that two dense areas at the bottom left (more red colors) and top right (more blue colors) mainly consist of a single class.
Moreover, from the purple-color area annotated with the arrow, we can observe that a part of the dense areas mixes a considerable amount of both classes' instances.
We should note that a bivariate colormap has been already utilized to simultaneously show two different measures over scatterplots (e.g., \cite{lespinats2011checkviz}).
Our contribution is in the computation of the ratio of each class's density and the color encoding design that is suitable to depict class and density information with scatterplots.

\textbf{Computation of density-related information.} Similar to an ordinary density scatterplot, we first estimate a 2D probability density function (PDF) from the coordinates of instances. 
To obtain a PDF, we apply a Gaussian kernel density estimation to all instances. 
Let $\ProbDensFuncAll$ denote a 2D PDF estimated with all instances (i.e., the total density).
Then, the density at a 2D coordinate, $\Point$, can be computed with $\ProbDensFuncAll(\Point)$.
Similarly, let $\ProbDensFuncClassZero$ and $\ProbDensFuncClassOne$ denote 2D PDFs estimated with \texttt{Class\,0}'s instances and \texttt{Class\,1}'s instances, respectively. 
Also, let $\nInstsClassZero$ and $\nInstsClassOne$ be the numbers of instances in \texttt{Class\,0} and \texttt{Class\,1}.
Then, a function that estimates the density ratio of \texttt{Class\,0} at $\Point$ can be written as: $\DensRatioFuncClassZero(\Point) = \nInstsClassZero \ProbDensFuncClassZero(\Point) / (\nInstsClassZero \ProbDensFuncClassZero(\Point) + \nInstsClassOne \ProbDensFuncClassOne(\Point))$.
If assigning the same total density for each class is more appropriate for an analysis, we can use  $\DensRatioFuncClassZero(\Point) = \ProbDensFuncClassZero(\Point) / ( \ProbDensFuncClassZero(\Point) + \ProbDensFuncClassOne(\Point))$, instead.

\textbf{Visual encoding design.}
Using a bivariate colormap, we encode $\ProbDensFuncAll(\Point)$ and $\DensRatioFuncClassZero(\Point)$.
We select color lightness to encode the total density, $\ProbDensFuncAll(\Point)$, because of its natural metaphor: the more accumulation of dots, the denser color.
We then employ hue to represent the density ratio, $\DensRatioFuncClassZero(\Point)$.
To use lightness and hue, we initially used ordinary color spaces such as HSL; however, a subtle difference in the density was difficult to recognize from the generated colors. 
Thus, we decided to utilize existing carefully designed sequential colormaps.
Specifically, we use the red and blue sequential colormaps in Matplotlib~\cite{colamaps-in-matplotlib}.
We can obtain a pair of colors corresponding to  $\ProbDensFuncAll(\Point)$ from these two colormaps and then generate a linearly interpolated color from the pair based on $\DensRatioFuncClassZero(\Point)$.
To show this 2D color space as a legend, we use a polar coordinate (see \autoref{fig:scatterplots}).
This is to clearly indicate the difference between the meanings of two measures (total density and ratio) as well as to inform that the ratio difference is less emphasized in low total-density areas.
As shown in \autoref{fig:scatterplots}-c, we also tested existing bivariate colormaps such as one introduced by Lespinats and Aupetit~\cite{lespinats2011checkviz}.
This colormap was not suitable for two-density scatterplots. 
For example, it is difficult to recognize \texttt{Class\,1}'s high-density area and the density difference between the high-density areas of \texttt{Class\,0} and \texttt{Class\,1}.

% While we develop the two-class density scatterplot for the views in \autoref{fig:ui}-b, we employ the same design for \autoref{fig:ui}-a. 
% As presented in \autoref{sec:attrib_contrib_shap}, the two-class density scatterplot can clearly show patterns of two classes even in the limited plotting space. 

\subsection{Datasets: Students and Adults’ Network Resources}
\label{sec:datasets}

In the rest of this section, our explanations refer to a real-world dataset, Dataset I, as a concrete analysis target.
In addition to this dataset, we also analyze DatasetII in our case studies (\autoref{sec:case_studies}).
Both datasets are derived from the Facebook usage and survey data of representative cohorts in Taiwan.
While Dataset I is a single multivariate network, Dataset II consists of a set of egocentric multivariate networks.

\textbf{Dataset I} is about senior college students~\cite{chang2019social}.
We represented each student as a network node and created a link based on their interactions on Facebook.
We constructed an undirected link if a ``like'', ``comment'', or ``tagged'' was made between students on a post. 
We consider such links as ``friendships'' in social media and 1-hop neighbors of each node as ``friends''.  
We further used the answers for the survey as each node's attributes.
The corresponding questions are related to the students' school life, such as their personalities, moods, and grades.
The resultant network consists of 1886 nodes, 64156 links, and 226 survey-based attributes for each node.

\textbf{Dataset II} is collected from sampled adults~\cite{lee2022indirect}.
This dataset uses Taiwan Social Change Survey, which includes important network-related topics, such as core discussion networks and network resources, as well as personal attributes, such as their backgrounds, personalities, moods, and social lives.
We generated multivariate egocentric networks by adding 1- and 2-hop neighbors of each survey respondent based on their contact records (i.e., 1-hop: direct contacts, 2-hop: indirect contacts).
We also assigned network-level attributes, such as the ego node's personality, Facebook usage statistics, and network measures (e.g., clustering coefficient).
The resultant egocentric networks consist of 345 ego nodes, 3339 1-hop neighbors, 19917 2-hop neighbors, and 11 network-level attributes.
In addition, we have information about whether each indirect contact is promoted to direct during a study period, January 1, 2015--June 30, 2017.

Below, from Dataset I, we identify and review college students' attributes that are highly related to their \texttt{scorelevel}---the past three years' mean score levels reported on a scale of four from the top to bottom. 
We used 14 survey attributes related to this analysis. 


\subsection{Learning Representations}
\label{sec:repr_learning}

We explain Steps 1--3, where we learn representations from multivariate networks. 
To provide a concise explanation, here we describe each process for producing a latent vector of each node (i.e., node feature learning).
However, the described learning processes can be easily adjusted to learn a latent vector for each link or network (\Flexibility).
\autoref{sec:cs3} demonstrates a case for network feature learning.

\subsubsection{Structural Feature Extraction for Attribute Selection}
\label{sec:preprocessing}

To select attributes related to the structural information in Step 1, we first precompute a set of structural measures~\cite{vandenelzen2016reducing,fujiwara2020visual}. 
For node feature learning, such measures can be degree, eigenvector, betweenness centralities, and many others~\cite{newman2018networks}.

These centralities inform the importance of each node from different aspects.
Degree centrality (i.e., the number of links connected to a node) measures local importance of nodes in the network.
Eigenvetor centrality (i.e., the eigenvector corresponding to the greatest eigenvalue of the network's adjacency matrix) more reflects global importance of nodes than degree centrality.
This is because eigenvector centrality considers the transitive importance of links (e.g., a link to a node with 100 links is more important than one with 1 link).
Betweenness centrality (the number of shortest paths that pass through a node) indicates a node's importance as a ``bridge'' connecting other nodes.
For details, refer to an introduction to network theory by Newman~\cite{newman2018networks}.

To capture more detailed structural information, we precompute statistics of each node's neighbors, such as the mean and variance of neighbors' degrees. 
Such statistics can be computed for semantic attributes as well (e.g., the mean age of neighbors).
The neighbor statistics are shown to be useful for various analytical tasks~\cite{rossi2018deep,fujiwara2020visual}.
For this precomputation, we specifically use DeepGL~\cite{rossi2018deep} to achieve fast computation as well as to avoid producing redundant measures. 

DeepGL summarizes 1-hop neighbors' centrality/attribute values (called \textit{base features}) with \textit{relational functions}.
For relational functions, we can specify multiple neighbor types (e.g., in-, out-, and total-neighbors) and aggregation functions (e.g., mean, variance, and maximum). 
After obtaining the neighbor statistics for all nodes, DeepGL prunes redundant statistics that show similar value distributions to others. 
The strength of pruning can be controlled with a hyperparameter of DeepGL.
Moreover, DeepGL can repeatedly apply the relational functions and pruning process to summarize farther neighbors' features. 
For more details, refer to the work by Rossi et al.~\cite{rossi2018deep}.
For Dataset I, as base features, we select 3 fundamental network centralities, degree, eigenvector, and betweenness, and the 14 survey attributes; then, we generate 1-hop total-neighbor statistics of the 17 attributes, resulting in 85 attributes in total after the pruning process.

\subsubsection{Network Representation Learning}
\label{sec:nrl}

After selecting input and output attributes in Step 1, we first apply the Z-score normalization to each attribute.
We then train an NN to predict the output from inputs, and extract representations from an NN layer (\Expressivity). 
Although we could predict an output value directly by designing the NN for a regression task, we instead categorize output values and perform binary classification of two value ends (e.g., top and bottom 25\% of attribute values). 
Since the classification is performed only on these ends, unrelated instances are not involved in training.
If we perform regression instead, the NN tries to fit all instances.
Consequently, a resulting representation may be only useful to predict values in the middle range (e.g., when fitting to the two ends is harder than the middle range).
While we assume this focus on two ends is reasonable for many analyses, NNs' settings are easy to adjust based on analytical interests.  
Another benefit of the binary-classification design is enabling a comparison of two categorical groups (e.g., students who major in engineering and business). 

By default, we use a multi-layer perceptron (MLP) consisting of five fully-connected layers (one input, three hidden, and one output layers) using the leaky rectified linear unit as an activation function. 
We then take the last hidden layer's activations as a learned representation.
% We employ the leaky rectified linear unit as an activation function to obtain expressive representations by utilizing its nonlinearity. 
With the consideration of a balance between expressivity and interpretability, we here keep the numbers and sizes of layers sufficiently small based on the size of the input data.
On the other hand, we should note that overfitting is acceptable for this step to some extent.
We simplify this step's high-dimensional network representation with linear transformation in Step 3 (\autoref{sec:repr_simplification}).
This simplification mitigates overfitting when it occurs.
The NN-based learning in Step 2 should focus on achieving an accurate alignment of the defined classes in a learned representation (i.e., high classification accuracy) rather than avoiding overfitting.
% When we have an accurate alignment, the NN's classification accuracy should be high.
% The accuracy can be checked in the UI, as shown in \autoref{fig:ui}-e.

While the simple five-layer MLP is our default NN architecture, this architecture can be easily replaced with more complex ones (\Extensibility). 
For example, when analysis needs to capture nonlinear neighbor relations in a network, we can incorporate a GNN.
If learning latent vectors of links or networks is required, we can replace the precomputation of network measures, accordingly.
For instance, we can extract the mean degree and network diameter for network feature learning.
Then, we can apply the same procedure employing an NN.


\subsubsection{Representation Simplification}
\label{sec:repr_simplification}

We simplify the high-dimensional network representation into a 1D representation for the subsequent interpretation steps (\Interpretability).
Because the NN is trained for binary classification, this simplification is similar to the process NNs usually perform for their output layer: transforming the last hidden layer's activations of multiple NN nodes into a single NN node at the output layer.
Therefore, we expect that although the simplified representation is 1D, it can preserve sufficient information for the prediction (\Expressivity).

\begin{figure}[t]
    \centering
    \includegraphics[width=0.86\linewidth]{figures/alternatives.pdf}
    \caption{1D representations generated by alternative designs. The same dataset and visualization as \autoref{fig:ui}-b1 are used (red: \texttt{Class\,0}, blue: \texttt{Class\,1}). (a) is made by applying a softmax activation function at the last layer of an MLP. (b) is generated by directly applying LDA to the dataset.}
    \label{fig:alternatives}
\end{figure}

Our simplification employs linear transformation in contrast to nonlinear transformation.
This linear transformation is the major difference from conventional NNs. 
A nonlinear activation function such as a sigmoid or softmax function encourages producing a value of 0 or 1 for classification.
As a result, the corresponding 1D representations often consist of many values close to 0 or 1.
An example of such cases is shown in \autoref{fig:alternatives}-a.
This close-to-discrete distribution makes it difficult not only to perform optimization for composite variable construction but also to observe insightful patterns from the composite variable visualization shown in \autoref{fig:ui}-b. 

One way to obtain a 1D representation with linear transformation is using a linear activation function between the last hidden and output layers, as in NNs for regression tasks.
As stated in \autoref{sec:nrl}, we, however,  want to avoid directly performing regression in the NN. 
Instead, as a post-hoc process, we apply a DR method to the high-dimensional network representation.
We specifically use LDA, which places instances of different classes as far as possible in a low-dimensional representation. 
This placement is achieved by maximizing the distance of each class’s centroid while minimizing data variance within each class.
This post-hoc process can efficiently generate a 1D representation with optimal class separation.

On the other hand, similar to NNs, LDA can easily cause overfitting when the number of instances is relatively small to the number of input features~\cite{guo2007regularized}. 
Thus, we use regularized LDA, which has a regularization mechanism to avoid overfitting~\cite{guo2007regularized}.
The use of regularized LDA brings an additional benefit for the post-hoc approach: the regularization strength can be controlled outside of the NN training process. 
Although the $L1$ and $L2$ regularizations can also be used for NNs to avoid overfitting~\cite{zou2005regularization}, the hyperparameter adjustment for these regularizations often requires many trials and errors, and becomes time-consuming by retraining NNs many times.
Applying regularization inside of LDA does not require retraining of NNs and LDA is computationally efficient; thus, we can adjust the regularization strength more conveniently (\Steerability).

The quality of the 1D representation can be investigated with a swarm-plot-like visualization, as shown in \autoref{fig:ui}-b1.
This visualization shows an instance as a dot and a 1D representation value as an $x$-coordinate.
Similar to the swarm plot~\cite{swarmplot}, $y$-direction is used to pile up dots with positional jitters to mitigate overplotting with a limited vertical space.
The resultant area height roughly shows the frequency/density around the corresponding $x$-coordinate (similar to a histogram).
We select this instance/point-based visualization to keep it consistent with other visualizations that use $x$-coordinates to represent the 1D representation values (cf. \autoref{fig:ui}-b2).
The color encoding is as with two-class density scatterplots'.
% As shown in the fan-shape colormap located at \autoref{fig:ui}-e, the color of each dot represents both the ratio of each class's density and their total density at the corresponding position.
% We explain more details of this colormap in \autoref{sec:twoclass-scatterplot}.
When the 1D representation has good quality, as seen in \autoref{fig:ui}-b1, two classes (\texttt{Class\,0}: red, \texttt{Class\,1}: blue) should have small or no overlaps. 
When the quality is not satisfactory, the analyst can update the NN architecture and/or the selection of input and output attributes.

In addition to the discussed architectures, we experimented with another alternative design: directly applying LDA to data to generate a 1D representation.
As shown in \autoref{fig:alternatives}-b, because this design did not exploit the strengths of NNs, the results often mixed two classes.

% Before we chose the above architecture first applying an MLP and then LDA, we experimented with two alternative designs. 
% As the first alternative design, we directly applied LDA  to obtain the 1D representation.
% The result after directly applying LDA to the same dataset as \autoref{fig:ui}-b is shown in \autoref{fig:alternatives}-a. 
% As this design does not utilize the strengths of NNs, the two classes are more mixed together when compared with \autoref{fig:ui}-b.
% Second, we only used an MLP, in which a softmax activation function is used to output the 1D representation (unlike our approach using LDA for this step).
% The result shown in \autoref{fig:alternatives}-b exhibits the aforementioned issue of the close-to-discrete distributions, although the two classes are well separated.
% These two results show that our final design is better for providing a good balance of expressivity and interoperability.

\subsection{Understanding Representations}
\label{sec:repr_interpretation}

We describe Steps 4 and 5, which are mainly for understanding the representation obtained through Steps 1--3 (\Interpretability).


\subsubsection{Attribute Contribution Measurement}
\label{sec:attrib_contrib_shap}

We extract each input attribute's contribution to the 1D representation, which is useful for two tasks.
% which can be considered as a latent space that disentangles the output attribute by referring to the input attributes.
First, this attribute contribution is useful to understand each attribute's relationship to the output attribute---the interpretation from a \textit{single attribute} level. 
Second, the contribution indicates attributes that should be considered for composite variables---the interpretation considering influence from \textit{multiple attributes}. 

We employ the SHAP method~\cite{lundberg2017shap} to measure the attribute contributions.
The SHAP method calculates a measure, called the SHAP value for each instance.
The SHAP value is computed based on cooperative game theory and shows how much a target value will be changed by adding each attribute value in a model (refer to \cite{lundberg2017shap} for details).
We apply the SHAP method to a transferred NN model that combines the MLP trained in Step 2 and LDA trained in Step 3.
In this case, the SHAP value indicates how much having a corresponding attribute value contributes to moving an instance toward a positive direction of the 1D representation.
For example, when an instance's \texttt{age} is 25 and its SHAP value for \texttt{age} is 0.1, having this age shifts the instance to a more positive side of the 1D representation by the magnitude of 0.1.

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/shap.pdf}
    \caption{\CaptionSHAP{}}
    \label{fig:shap}
\end{figure}

As shown in \autoref{fig:ui}-a (also \autoref{fig:shap}-c), we visualize SHAP values with a list of two-class density scatterplots, where each row corresponds to one attribute's SHAP values.
Our design uses $x$- and $y$-axes to depict the SHAP values and attribute values, respectively.
As a summary measure of each attribute's contribution, we use the mean absolute value of all instances' SHAP values.
We then sort the display order of the scatterplots based on this summary measure (i.e., top contributed attributes are listed from the top in order).

For example, in \autoref{fig:ui}-a, we see the top 3 contributed attributes are \texttt{open} (openness), \texttt{consci} (conscientiousness), and \texttt{netaddict} (internet addiction). 
Furthermore, from the corresponding scatterplots, we can gain several insights. 
While larger \texttt{open} has a more negative impact on the 1D representation reflecting \texttt{scorelevel}, larger \texttt{consci}  has a more positive impact.
Also, \texttt{netaddict} shows clearly different patterns by \texttt{Class\,0} (low \texttt{scorelevel}) and \texttt{Class\,1} (high \texttt{scorelevel}).
Larger \texttt{netaddict} tends to have a more negative impact for \texttt{Class\,0}. 

We tested different visual designs, as shown in \autoref{fig:shap}.
\autoref{fig:shap}-a follows the default plot in the SHAP Python package~\cite{shap_library}, where the swarm-plot-like visualization is used. 
$x$-coordinates correspond to SHAP values, while colors inform attribute values.
From this visualization, we can roughly see the relationships between these values (e.g., larger \texttt{open} tends to have a more negative SHAP value).
But, it is infeasible to grasp patterns that differ by class.
Even when juxtaposing a visualization that color-encodes class information, as shown in \autoref{fig:shap}-b, we still cannot clearly see such different patterns. 
In contrast, our final design (\autoref{fig:shap}-c) can clearly depict the relationships between SHAP and attribute values as well as different patterns by class.

% Each instance has one SHAP value for each attribute.
% As a summary measure of each attribute's contribution, we use the mean absolute value of all instances' SHAP values.
% Based on this summary measure, we sort and display attributes in \autoref{fig:ui}-a. 
% These ordered attributes help analysts select attributes for the composite variable construction.

\vspace{-1pt}
\subsubsection{Composite Variable Construction}
\label{sec:comp_var_construction}
\vspace{-1pt}

The composite variable is commonly used when using a single attribute is not sufficient to understand a target phenomenon (\Expressivity and {\Interpretability}). 
For example, in baseball, on-base plus slugging (OPS)---the sum of two different statistics of the player's performance, on-base percentage and slugging percentage---is used to analyze players' contributions to team runs.
This is because OPS is a simple composite variable but extremely correlates to team runs~\cite{albert2010sabermetrics}. 

\textbf{Construction algorithm.} We describe the optimization algorithm designed to construct a composite variable from user-selected attributes.
% First, we need to define the objective function for the optimization. 
To explain the 1D representation with the selected attributes as much as possible, our optimization goal is to maximize a certain \textit{measure of dependence}~\cite{reshef2016measuring} between the 1D representation and attributes. 
Such measures include Pearson's correlation, Spearman's correlation, the mutual information. 
% We use either Pearson's or Spearman's correlation coefficient as a measure of dependence.
We constrain a composite variable to a linear combination of attributes to achieve a simple, intuitive interpretation as well as an efficient optimization for interactive construction.

A linear combination that achieves the highest Pearson's correlation coefficient can be derived by multivariate linear regression. 
On the other hand, Spearman's involves a non-differentiable operation to rank the 1D representation values.
Due to non-differentiability, we cannot use simple regression or gradient-based solvers.
Thus, we employ a gradient-free solver, specifically COBYLA (or constrained optimization by linear approximations)~\cite{powell1998direct} while using the optimized result for Pearson's as an initial solution. 
Although the optimization for Pearson's is much more efficient, Spearman's could be more effective in some cases.
This is because the 1D representation is constructed from the non-linearly transformed attributes by the NN, and the 1D representation may have a nonlinear correlation with the original input attributes.
Although we currently only support Pearson's and Spearman's correlations, the algorithm can be easily extended for other measures of dependence (e.g., mutual information) by using COBYLA or a gradient-based solver.

\textbf{Interactive use.} From the view in \autoref{fig:ui}-a, an analyst can select attributes and a measure of dependence, and then generate a composite variable by clicking ``Construct New Composite Variable'' located at the bottom.
The selected attributes are highlighted with gray backgrounds.
Then, a two-class density scatterplot (\autoref{fig:ui}-b2) visualizes the relationships between the 1D representation ($x$-axis) and the constructed composite variable ($y$-axis). 
Also, multiple composite variables can be created to compare their expressivity and interpretability (\Steerability). 
A newly constructed composite variable's visualization is appended to a list of the scatterplots in a scrollable view.
Each scatterplot can be discarded by clicking a ``$\smash{\times}$'' mark at the top right.  

In essence, through this composite variable construction process, analysts can utilize their domain knowledge to review the simplified representation.
From the attributes ranked by SHAP values, the analyst can judge attributes they should consider.  
Then, with the help of the above optimization algorithm, the analyst can interactively examine and fine-tune the composite variables to gain insights.

\textbf{Analysis examples.}
For Dataset I, we compute Spearman's correlation coefficient between each of the top 5 contributed attributes and the 1D representation. The cofficients are \texttt{open}:\,-0.147, \texttt{consci}:\,0.237, \texttt{netaddict}:\,0.134, \texttt{min\_happy} (the minimum of friends' happiness levels):\,0.093, and \texttt{extra} (extraversion):\,0.026.
As shown in \autoref{fig:ui}-b2, using all these attributes, we can generate a composite variable that has a better correlation coefficient, 0.300, than any single attribute.
This coefficient is in a moderate correlation group based on Dancey and Reidy's categorization~\cite{dancey2017statistics}.
We follow Dancey and Reidy's categorization in the rest of the paper when describing correlation strengths.

Since all attributes are normalized, each attribute's weight in the composite variable shows a contribution level to the composite variable (\texttt{open}:\,-0.4, \texttt{consci}:\,+0.7, \texttt{netaddict}:\,-0.3, \texttt{min\_happy}:\,+0.3, \texttt{extra}:\,+0.3).
\texttt{consci} contributes most, as expected from its higher Spearman's correlation (0.237) than others. 
In contrast, \texttt{extra} is assigned a relatively large weight (+0.3) in spite of its extremely small correlation (0.026) as a single attribute.
The importance of \texttt{extra} can be confirmed by excluding \texttt{extra} from the composite variable construction. 
When \texttt{extra} is extruded, the composite variable's correlation coefficient decreases from 0.300 to 0.289. 
From further interactive investigations on how the inclusion of \texttt{extra} improves each other attribute's correlation, we observe that \texttt{open} has a much larger improvement (from 0.147 to 0.170) than others (e.g., \texttt{consci} has no improvement).
We can infer that, by including \texttt{open} and \texttt{extra} with different signs (-0.4 and 0.3), the composite variable captures the subtle difference between these two personalities.
Then, \texttt{scorelevel} shows higher dependence on this derived difference than either \texttt{open} or \texttt{extra}. 
This type of insight cannot be derived if only investigating a single attribute relationship to the 1D representation. 
Also, this example demonstrates the effectiveness of the SHAP-based recommendation in contrast to relying only on each attribute's correlation coefficient.

We should emphasize that while we want to make a composite variable correlated to the 1D representation to some extent (e.g., Spearman's $\smash{\geq 0.2}$, weakly correlated), we do not have to see extremely correlated results (e.g., Spearman's $\smash{\geq 0.7}$, strongly correlated).
If a strong correlation can be found with a linear combination of a few attributes, the use of NNs becomes unnecessary.
In such a case, linear learning methods such as LDA should be sufficient for the prediction. 
Our focus is taking a further step from the single-attribute-based interpretation using the SHAP or other methods~\cite{lundberg2017shap,kwon2018clustervision,neto2021multivariate}.
Our approach considers the influence of multiple attributes. 
Such an influence can be analyzed via the signed weights in a composite variable and the interactive adjustment of the composite variable. 
The correlations to each composite variable should be considered as an indicator of how much of the 1D representation is explained with the composite variable.

\vspace{-1pt}
\subsection{Interactive Visual Interface}
\vspace{-1pt}

All visualizations in the UI are fully linked and share the same or similar color encodings (e.g., red represents \texttt{Class\,0}). 
Lasso selection can be performed in \autoref{fig:ui}-a, b, c. 
The selected instances from \texttt{Classes\,0} and \texttt{1} will be highlighted in yellow (e.g., \autoref{fig:case2}-c).
With this linking, analysts can investigate specific patterns, such as outliers and subgroups.
We further provide visualizations of structural and semantic information to supplement the interpretation of the results.

\textbf{Structural information.} 
\autoref{fig:ui}-c shows network layouts as the structural information. 
Only in this view, we visualize all instances even including those not belonging to the two ends (i.e., \texttt{Classes\,0} and \texttt{1}).
This is because the precomputed network measures (e.g., degree) used for NRL are computed using links among all instances.
And, we need to review the entire network to locate patterns related to the structural information.
% , instead of the subnetwork only consisting of instances in the two ends.
We apply scalable force-directed placement (SFDP)~\cite{hu2005efficient} and then use red, blue, and gray colors to represent \texttt{Class\,0}, \texttt{Class\,1}, and other instances, respectively.
% When performing lasso selection in this view, only \texttt{Class\,0} and \texttt{Class\,1} instances inside of the lasso are selected to consistently link with the other views.

\textbf{Attribute information.} 
We visualize the distribution of each attribute as a double-bar histogram. 
By default, as shown in \autoref{fig:ui}-d, the UI shows the distribution for each class.
When the lasso selection is performed, we show the distributions of selected and non-selected instances (e.g., \autoref{fig:case1}-b1 and b2).
Because we have limited screen space, we order histograms based on the two groups' distribution differences measured by the Kolmogorov-Smirnov (KS) statistic.

\textbf{Implementation.}
The UI is developed as a web application. 
For the back end, Python is used to perform Step 1 with DeepGL, Step~2 with MLPs, Step 3 with regularized LDA, Step 4 with the SHAP method, Step 5 with multivariate regression and the COBYLA, and Step 6 with the two-class density scatterplot, SFDP, and KS statistic.
The implementation of these algorithms utilizes various libraries, such as deepgl~\cite{fujiwara2022network}, PyTorch~\cite{pytorch2019paszke} (for MLPs), ulca~\cite{fujiwara2021interactive} (for regularized LDA), SHAP~\cite{shap_library}, Scikit-learn~\cite{pedregosa2011scikit} (for multivariate regression), NumPy/SciPy~\cite{virtanen2020scipy} (for the COBYA, KS statistic, and Gaussian kernel density estimation), graph-tool~\cite{graphtool2014peixoto} (for SFDP), seaborn~\cite{waskom2021seaborn} (for the swarm-like visualization), and ColorAide~\cite{coloraide} (for color generation).
The front-end UI is implemented with HTML5, JavaScript, and D3~\cite{bostock2011d3}. 
WebSocket is used for communication between the front- and back-end modules.
