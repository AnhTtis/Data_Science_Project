
\section{Related Work}
\label{sec:related_work}

Our work is closely related to two research topics studied in the visualization field: NRL and the interpretation of learned representations. 
For the broader discussion on visualizations for analyzing networks and interpreting machine learning results, refer to existing surveys~\cite{kerren2014multivariate,mcgee2019state,beck2017taxonomy,chatzimparmpas2020state}.

\subsection{Learning Network Representations}

NRL aims to generate a set of low-dimensional vectors (also called representation) that captures certain important characteristics of networks, nodes, or links~\cite{zhang2018network}. 
The representation is usually learned for downstream tasks, such as node classification and link prediction. 
Various NRL methods are developed, including node2vec~\cite{grover2016node2vec}, graph convolutional networks~\cite{kipf2016semi}, graph neural networks (GNNs) with the self-attention~\cite{ying2021transformers}, to name but a few~\cite{zhang2018network}. 

The researchers have been utilizing NRL together with visualization to interactively examine large-scale, complex network datasets.
For example, Freire et al.~\cite{freire2010manynets} represented one network by a set of network statistics (e.g., degree distribution) and organized many networks in a tabular interface to compare them. 
Gove~\cite{gove2019gragnostics} suggested several network-level features (e.g., density) that are easier to interpret and faster to compute for interactive visualization.
To capture the network connectivity at a detailed level, the researchers measured the occurrences of graphlets~\cite{prvzulj2007biological} (small, connected, non-isomorphic subgraph patterns in a network). 
The graphlet-based representations have been used to identify visually similar networks~\cite{von2009visual,harrigan2012egonav,kwon2017would}.
When node correspondence exists among networks, another common approach is directly applying DR methods to networks' adjacency matrices to obtain a representation that shows the similarities of networks~\cite{bach2016time,fujiwara2017visual}.
Van den Elzen et al.~\cite{vandenelzen2016reducing} took a similar DR approach but they further incorporated network statistics, such as the number of nodes. 
Martins et al.~\cite{martins2012multidimensional,martins2017mvn} used DR to lay out network nodes based on their structural and semantic similarities.

Similar to ours, recently, a few works employed NN-based NRL.
Fujiwara et al.~\cite{fujiwara2022network} introduced contrastive NRL (cNRL) by integrating a variant of GNNs and contrastive learning~\cite{zou2013contrastive}.
cNRL extracts a representation of two networks, where salient characteristics in one network relative to another are highlighted.
Utilizing linear DR, they further designed an interpretable cNRL method and enhanced it with interactive visualizations~\cite{fujiwara2020visual}. 
Song et al.~\cite{song2022interactive} used GNNs to support interactive subgraph pattern search, where GNNs are used to covert each network in a comparable, fixed-length latent vector. 

As stated, unlike the above approaches, we use NN-based NRL to obtain representations that are specifically for uncovering the relations of interest in multivariate networks.
Also, we address the interpretation of the representations with the composite variable construction, which is easier to examine when compared with the approaches referring to coefficients in the linear DR results~\cite{fujiwara2020visual,fujiwara2022network}.


\subsection{Interpreting Representations}

Although the interpretation of network representations is still sparsely studied (e.g., \cite{fujiwara2020visual}), various interpretation methods are developed for high-dimensional data's representations which are often extracted by using DR methods or NNs. 
Generally, existing methods can be categorized into two approaches: (1) identifying essential information to specific patterns found in complex representations (i.e., post-hoc explanation approach) and (2) constructing simple, interpretable representations during a learning phase (i.e., explainability-by-design approach~\cite{hamon2020robustness}).

Many visual analytics methods for the interpretation of nonlinear DR results are corresponding to the first approach. 
For example, researchers visually identified attributes that are highly influential on the cluster formation in DR results from related statistical charts (e.g., boxplots of the attribute distributions for each cluster)~\cite{kwon2018clustervision,neto2021multivariate}.
As these univariate statistical charts could be insufficient to capture the characteristics of clusters, some researchers further considered the combinational influences from multiple attributes~\cite{fujiwara2020supporting,joia2015uncovering,turkay2012representative,zhou2016dimension}.
For example, to identify such influences, Joia et al.~\cite{joia2015uncovering} applied PCA to each cluster, instead of the entire data.
While the above works are mainly to understand clusters, several methods focused more on understanding other local patterns~\cite{chatzimparmpas2020tvisne,faust2018dimreader,cavallo2018visual}.

There are a relatively small number of visual analytics works taking the explainability-by-design approach. 
Knittle et al.~\cite{knittel2020visual} used NNs consisting of one hidden layer with a small number of NN nodes to extract nonlinear representations that relate input attributes to a target output attribute.
These simple NNs allowed them to review all representations held by the NN nodes and identified those showing clear relationships between the input and target attributes. 
Then, they constructed a stacked histogram for each input attribute to visually convey such relationships in detail.
Gleicher~\cite{gleicher2013explainers} produced simple composite variables that are to classify a user-selected attribute.
To craft such composite variables, Gleicher performed an exhaustive search for the selection of variables and applied support-vector machines to adjust the weight for each variable while considering a balance between, for example, simplicity and expressiveness.

In terms of using NNs to extract the input-output relationships, the work by Knittle et al.~\cite{knittel2020visual} is closely related to ours. 
However, their interpretation of the obtained representations is based only on univariate value distributions, which is insufficient when NNs capture complex input-output relationships.
Similar to Gleicher's work~\cite{gleicher2013explainers}, our work crafts simple composite variables, but we do not involve the computationally expensive exhaustive search. 
Instead, we rank variables based on their contributions to the NNs' predictions and involve analysts' knowledge to select attributes of interest.
