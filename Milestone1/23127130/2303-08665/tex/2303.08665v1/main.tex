% Template for ICIP-2022 paper; to be used with:
%          spconf.sty  - ICASSP/ICIP LaTeX style file, and
%          IEEEbib.bst - IEEE bibliography style file.
% --------------------------------------------------------------------------
\documentclass{article}
\usepackage{spconf,amsmath,graphicx}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage{graphics}
\usepackage{adjustbox}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{enumitem}
\usepackage{xcolor}

% Example definitions.
% --------------------
\def\x{{\mathbf x}}
\def\L{{\cal L}}

% Title.
% ------
\title{Identity-Preserving Knowledge Distillation for Low-resolution Face Recognition}
% Low Resolution Face Recognition via Identity-preserving Neural Network under Knowledge Distillation Framework

%
% Single address.
% ---------------
% \name{Author(s) Name(s)\thanks{Thanks to XYZ agency for funding.}}
% \address{Author Affiliation(s)}

\name{Yuhang Lu, Touradj Ebrahimi\thanks{Support from the Swiss National Science
Foundation (SNSF) 20CH21\_195532 for XAIface
CHIST-ERA-19-XAI-011 is acknowledged.}}
\address{Multimedia Signal Processing Group (MMSPG)\\
\'Ecole Polytechnique F\'ed\'erale de Lausanne (EPFL)}

%
% For example:
% ------------
%\address{School\\
%	Department\\
%	Address}
%
% Two addresses (uncomment and modify for two-address case).
% ----------------------------------------------------------
%\twoauthors
%  {A. Author-one, B. Author-two\sthanks{Thanks to XYZ agency for funding.}}
%	{School A-B\\
%	Department A-B\\
%	Address A-B}
%  {C. Author-three, D. Author-four\sthanks{The fourth author performed the work
%	while at ...}}
%	{School C-D\\
%	Department C-D\\
%	Address C-D}
%
\begin{document}
%\ninept
%
\maketitle
%
\begin{abstract}

% Recent deep learning-based face recognition systems have achieved remarkable performance on public benchmarks, but the accuracy reduces significantly in low-resolution (LR) scenarios. 

Low-resolution face recognition (LRFR) has become a challenging problem for modern deep face recognition systems.
Existing methods mainly leverage prior information from high-resolution (HR) images by either reconstructing facial details with super-resolution techniques or learning a unified feature space. 
To address this issue, this paper proposes a novel approach 
% a novel approach is proposed
which enforces the network to focus on the discriminative information stored in the low-frequency components of a low-resolution (LR) image. 
A cross-resolution knowledge distillation paradigm is first employed as the learning framework. 
An identity-preserving network, WaveResNet, and a wavelet similarity loss are then designed to 
% enhance the attention on
capture low-frequency details and boost performance. Finally, an image degradation model is conceived to simulate more realistic LR training data. Consequently, extensive experimental results show that the proposed method consistently outperforms the baseline model and other state-of-the-art methods across a variety of image resolutions.

\end{abstract}
%
\begin{keywords}
Low resolution, Face recognition, Knowledge distillation
\end{keywords}
%
\section{Introduction}
\label{sec:intro}
In the past decades, face recognition (FR) has become a key technology in society. Current state-of-the-art deep learning-based face recognition systems achieve near-perfect performance on well-known public face recognition benchmarks such as LFW \cite{huang2008labeled}.
However, these face datasets are primarily collected in controlled environments and in high resolution, which differ from face images captured by real-world devices. 
In fact, studies \cite{grm2018strengths,knoche2021image,lu2022novel} have demonstrated a significant performance deterioration of the most advanced deep face recognition systems in low-resolution scenarios.
% when facing significant resolution discrepancies

% the recognition accuracy can be significantly reduced in more realistic scenarios, such as low-resolution faces in surveillance applications.
% Studies \cite{grm2018strengths,knoche2021image,lu2022novel} have demonstrated the significant performance deterioration of the most advanced deep face recognition systems when facing resolution discrepancies. 

This work mainly focuses on the problem of low-resolution face recognition (LRFR).
Most existing approaches to cope with LRFR can be divided into two categories.
IIN the first category HR images are reconstructed from LR images with face super-resolution (FSR) techniques \cite{lai2019low}, which are then recognized by a network. Although FSR methods can generate missing information, even facial details, they are mainly optimized for visual appearance and often ignore and even alter crucial identity information. This results in limited improvement in performance. The high computational cost of the FSR module during both training and inference lays an additional burden on the entire face recognition system and heavily impairs its efficiency.

Different from FSR-based approaches, the second category converts LR and corresponding HR faces into a unified resolution-invariant feature space. These approaches rely fully on the identity information and learn a discriminative representation. Earlier work \cite{yang2017discriminative} leveraged a multidimensional scaling approach to learn a mapping matrix.
Lu et al. \cite{lu2018deep} proposed a deep coupled ResNet model with two additional branch networks to map coupled HR and LR features to a common space.
Zangeneh et al. \cite{zangeneh2020low} directly employed a two-branch structure DCNNs to learn a non-linear feature transformation. 
\cite{zha2019tcn,knoche2022octuplet} tackled the problem with a metric learning approach. Both methods were built on triplet loss and learned to reduce the resolution gap by pulling together positive HR-LR pairs and pushing away dissimilar ones. 

%%%%%%%%%%%%%%% KD Framework %%%%%%%%%%%%%%%%
\begin{figure*}[t]
	\centering
	\begin{adjustbox}{width=0.75\textwidth}
    \includegraphics[]{Framework.pdf}
	\end{adjustbox}
	\caption{The architecture of the proposed identity-preserving knowledge distillation framework}
	\label{fig:kdframework}
\end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Knowledge distillation is another line of approach that builds resolution-invariant feature space by distilling HR domain knowledge to the LR domain. This idea was first proposed in \cite{44873} to transfer knowledge from a high-performing but computationally expensive teacher network into a simple student network. 
Recent studies \cite{zhu2019low,ge2018low,feng2021resolution,shin2022teaching} have shown the potential of this approach in solving recognition problems in low-resolution domains. For instance, Zhu et al. \cite{zhu2019low} 
% and Huang et al. \cite{huang2022feature} 
addressed the low-resolution object recognition problem with the teacher-student learning paradigm. Their proposed methods simultaneously optimize the recognition loss and distillation loss and manage to distill valuable information from a deep model pre-trained on high-resolution data. Authors in \cite{ge2018low, feng2021resolution} developed efficient low-resolution face recognition models with very low computational cost by distilling the most informative facial features from teacher to student stream. More recently, \cite{shin2022teaching} performed an attention similarity knowledge distillation. Instead of the feature map, they transferred attention maps obtained from the teacher network into a student network to boost LR face recognition performance.
In this paper, a cross-resolution knowledge distillation framework is first employed, where the targeted student network is trained with multi-scale LR data and optimized with both face recognition and distillation losses.

Despite the guidance of the prior knowledge extracted from HR face images, the huge resolution disparity between HR and LR images makes it difficult for the student network to capture informative features. Frequency analysis in \cite{knoche2021image, li2020wavelet} has shown that the high-frequency information in a facial image, such as edge and noise, is eliminated during the resolution reduction, while the low-frequency subbands still preserve the most discriminative features. 
This work proposes an identity-preserving network, WaveResNet, to capture the discriminative information stored in low-frequency components of the LR images. It is adapted from ResNet \cite{he2016deep} by replacing the pooling and stride-convolution layers with a low-pass filter based on Discrete Wavelet Transform (DWT). 
The high-frequency subbands of the intermediate feature maps are filtered out to remove ambiguous and noisy information and enforce the network to focus on the more discriminative low-frequency information. 
In addition, a wavelet similarity loss is designed as an auxiliary distillation loss in order to further enhance attention in low-frequency subbands. 
Moreover, a degradation model is designed to simulate real-world LR training data and develop a more robust recognition system. The proposed method has been evaluated on four datasets in a variety of resolutions and it outperforms the baseline model and some other related work.
% Compared to the baseline and some other related work, it outperforms in most resolution settings. 

% In summary, the following contribution has been made in this paper.
% % \setlist{nolistsep}
% \begin{itemize}%[noitemsep]
%     \item An identity-preserving network (WaveResNet) is proposed to preserve the identity information stored in low-frequency subbands of LR face images, leading to performance improvement
%     \item This work employs a cross-resolution knowledge distillation framework to better fit the LRFR task and additionally designs a wavelet similarity loss to enhance attention on low-frequency components
%     \item A more practical degradation model is conceived for more realistic low-resolution image synthesis
% \end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Method}
\label{sec:method}

\subsection{Problem Definition}
This paper mainly describes and resolves the low-resolution face recognition (LRFR) problem, where the probe images are low-resolution due to the limited definition of the camera or the far distance between the camera and the subject, while the gallery images registered in the database are all of high quality and resolution. 
In the testing phase, one focuses on the face verification task and verifies the matching between an LR probe image and an HR gallery image. 

\subsection{Identity Preserving Network}

Different from FSR-based methods which recover high-frequency details for identity matching, the proposed method focuses on the information stored in the low-frequency domain and directly mines deep identity information from LR training data. Ideally, it performs efficient and accurate recognition in a variety of resolutions in face images. 

In this subsection, an identity-preserving network, WaveResNet, is proposed to remove the ambiguous and noisy high-frequency information and enhance the discriminative features in an LR image. 
More specifically, as shown in Fig.~\ref{fig:kdframework}, a low-pass convolutional filter based on Discrete Wavelet Transformation (DWT) is embedded into ResNet, denoted as WaveConv, by replacing the Maxpooling and stride convolution operations. Given an input image $\boldsymbol{x}$, a low-pass filter $\boldsymbol{f_{LL}}$ based on 2D DWT converts $\boldsymbol{x}$ into its low-frequency subband image $\boldsymbol{x_{LL}}$. The filter itself is a stride 2 convolutional operator during the transformation and downsamples the image by a factor 2. The embedded operation is defined as $\boldsymbol{x_{LL}}=(\boldsymbol{f_{LL}} \circledast \boldsymbol{x})\downarrow_{2}$, where $\circledast$ refers to convolution operator and $\downarrow_{2}$ means downsampling by 2. 

\subsection{Knowledge Distillation Framework for LRFR}

\subsubsection{Face Recognition Framework}
Fig. \ref{fig:kdframework} illustrates the knowledge distillation framework for the LRFR task. The teacher model is built on the ResNet50 network. Different from many teacher-student frameworks where the student model is a much simpler network for the sake of efficiency, the student network utilizes the proposed WaveResNet50 with the same amount of parameters to pursue high representation capability in both HR and LR data. Under this framework, the teacher network is first trained on HR images and learns to extract rich and informative facial details from high-quality training data. Then, cross-resolution distillation adapts the knowledge of discriminative features to the student network, which is trained on multi-scale LR data. 
% \textbf{Consequently, the resulting student model is deployed to recognize both high-resolution and low-resolution faces. }

\subsubsection{Losses}
% Under the framework of knowledge distillation, the following loss functions have been conceived and employed. 
\textbf{Recognition Loss:}
The popular ArcFace \cite{deng2019arcface} loss is employed by both teacher and student networks as a recognition loss to learn the discriminative power.
% The identity loss [] is formulated as follows.
\begin{align}
    \mathcal{L}_{arcface}=-\frac{1}{N} \sum_{i=1}^N \log \frac{e^{s\left(\cos \left(\theta_{y_i}+m\right)\right)}}{e^{s\left(\cos \left(\theta_{y_i}+m\right)\right)+\sum_{j=1, j \neq y_i}^n e^{s\left(\cos \left(\theta_j\right)\right)}}},
\end{align}%\vspace{-5pt}
\\
\textbf{Cross-resolution Distillation Loss:}
In the training stage, the knowledge from the teacher network is transferred to the student model with a distillation loss. 
In order to improve the performance of the student network on different sizes of LR data, the distillation process is designed in a way to enforce a constraint over features across variant resolutions in one unified feature space. During the training, multi-scale of LR training data is collected and a cross-resolution distillation loss is applied to minimize the discrepancy between HR and LR features.
Specifically, given a pair of training samples, HR image $\boldsymbol{x_H}$ and LR image $\boldsymbol{x_L}$ of random size $s$, they are respectively passed into the teacher and student networks including classification layers to obtain the logits $\boldsymbol{z_H}$ and $\boldsymbol{z^s_L}$ and calculate the loss. 
The distillation loss is expressed as:
\begin{align}
    \mathcal{L}_{distill} = \frac{1}{N} \sum_{i=1}^N  T^2 \mathcal{L}_{K L}\left(\sigma\left(\frac{z_H}{T}\right), \sigma\left(\frac{z^s_L}{T}\right)\right),
\end{align}
where $\mathcal{L}_{K L}$ refers to the KL Divergence, T is the temperature parameter to smooth the distillation loss, and $\sigma(\cdot)$ refers to the softmax function.
\\
\textbf{Wavelet Similarity Loss:}
An additional auxiliary loss, namely wavelet similarity loss, on the intermediate feature maps is introduced to further enhance the attention on low-frequency components. It enforces the student network to learn more discriminative knowledge stored in low-frequency features from the teacher.
% distill more knowledge about low-frequency features to the student network, which learns to pay more attention to identity information stored in low-frequency subbands. 
First, the feature maps from both teacher and student streams are spotted and then decomposed into multiple frequency bands by DWT. Afterward, MSELoss is applied to the low-frequency components only. The formula of the proposed wavelet similarity loss is as follows.
\begin{align}
    \mathcal{L}_{wavesim} = \sum_{k=1}^2 \lVert f_{LL}(z_H^k) - f_{LL}(z_L^k)  \rVert_2^2,
\end{align}
where $z^k$ means the intermediate feature in the $k^{th}$ stage of ResNet and $f_{LL}$ refers to the DWT-based low-pass filter.

The total loss is a weighted combination of recognition loss, distillation loss, and wavelet similarity loss.
\begin{align}
\mathcal{L}_{total} = \mathcal{L}_{arcface}+\lambda_{1} \mathcal{L}_{distill} + \lambda_{2} \mathcal{L}_{wavesim}
\end{align}

%%%%%%%%%%%%%%% Degradation Model %%%%%%%%%%%%%%%%
\begin{figure}[t]
	\centering
    \includegraphics[width=\linewidth]{DegradationModel.pdf}
	\caption{Data degradation model to produce realistic LR data.}
	\label{fig:degrade}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{-8pt}
\subsection{Degradation Model for LR Data Synthesis}
In the proposed learning framework, the student network is trained on synthesized low-resolution data. In order to develop a robust recognition system, the synthesized LR training data should not deviate much from those captured in the real world.
% those in real-world scenarios. 
% Similar ideas were adopted in other applications \cite{lu2022novel} to improve the robustness of a detector.
In the LRFR task, previous studies tend to add Gaussian blur before downsampling to better simulate the low-resolution effect on images.
This paper hand-designs a degradation model to produce LR face images that are closer to real-world data. As depicted in Fig. \ref{fig:degrade}, the HR image is first randomly corrupted by blur operation, synthetic noise, and JPEG compression artifacts. Afterward, the data is downsampled into selected sizes by bicubic operation. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Performance report %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Table generated by Excel2LaTeX from sheet 'Sheet2'
\begin{table*}[t]
  \centering
  \caption{Verification accuracy of the proposed method on multiple datasets of different resolutions. Multi-scale refers to training with data in different resolutions. Degradation means the degradation model. KD refers to the proposed knowledge distillation framework. WaveSim refers to the auxiliary wavelet similarity loss. 
  \textcolor[rgb]{ 1,  0,  0}{Red color} denotes the highest score and \textcolor[rgb]{ .267,  .447,  .769}{Blue color} denotes the second highest score. 
  }
    \begin{adjustbox}{width=0.9\textwidth}
    \begin{tabular}{ccccc|p{30pt}p{30pt}p{30pt}p{30pt}|c}
    \toprule
    \multicolumn{5}{c|}{Methods}          & \multicolumn{4}{c|}{Avg on $\cup$\{LFW,AgeDB,CPLFW,CALFW\}} & \multirow{2}[2]{*}{\shortstack{Overall\\ Average}} \\
    \cmidrule{1-9}
    Backbone  & Multi-scale & Degradation    & KD & WaveSim & \;7x7   & 14x14 & 28x28 & 112x112\scriptsize(HR) &  \\
    \midrule
    ResNet &       &       &       &       & 57.04 & 73.96 & 92.42 & \textcolor[rgb]{1,0,0}{95.38} & 79.70 \\
    ResNet & \checkmark      &       &       &       & 76.37 & 84.92 & \textcolor[rgb]{.267,.447,.769}{93.23} & 94.13 & 87.16 \\
    % ResNet & \checkmark      &  \checkmark     &       & \checkmark      & 75.76 & 87.85 & \textbf{93.28} & 94.24 & 87.78 \\
    WaveResNet & \checkmark      &       &       &       & \textcolor[rgb]{.267,.447,.769}{76.49} & 86.73 & 92.86 & 94.17 & 87.56 \\
    WaveResNet & \checkmark      & \checkmark      &       &       & \textcolor[rgb]{1,0,0}{76.95} & 87.77 & 92.55 & 93.30 & 87.64 \\
    WaveResNet & \checkmark      & \checkmark      & \checkmark      &       & 75.41 & \textcolor[rgb]{1,0,0}{88.31} & 93.18 & 94.31 & \textcolor[rgb]{.267,.447,.769}{87.80} \\
    WaveResNet & \checkmark      & \checkmark      & \checkmark      & \checkmark      & 76.41 & \textcolor[rgb]{.267,.447,.769}{88.30} & \textcolor[rgb]{1,0,0}{93.25} & \textcolor[rgb]{.267,.447,.769}{94.47} & \textcolor[rgb]{1,0,0}{88.11} \\
    \bottomrule
    \end{tabular}%
    \end{adjustbox}
  \label{tab:mixdataset}%
\end{table*}%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Experimental Results}
\label{sec:experiment}
\subsection{Experimental Settings}
\subsubsection{Datasets}
The cleaned MS1M dataset \cite{deng2019arcface} is used as the training set, which is composed of approximately 3.28M face images belonging to 72,778 identities. All the images in the training set are cropped to the size of 112x112 and aligned with five facial landmarks. 
% Under the teacher-student training framework,
Every sample is downsized in order to construct HR-LR training pairs. As for evaluation, four popular datasets are employed, i.e. LFW \cite{huang2008labeled}, AgeDB-30 \cite{moschoglou2017agedb}, CPLFW \cite{zheng2018cross}, and CALFW \cite{zheng2017cross}.
For a fair comparison with previous related work, all the testing samples are downsampled using linear interpolation instead of the degradation model. 
\vspace{-2pt}
\subsubsection{Implementation Details}
In the proposed knowledge distillation framework, the teacher network is trained on HR images only, while the student network is trained on multi-scale LR images. The downsampling scales are randomly selected and the LR images are obtained through the proposed degradation model. 
During training, both teacher and student networks are trained for 18 epochs using the SGD optimizer with a batch size of 128. The learning rate is initially set to be 0.1 and divided by 10 at 10, 13, and 16 epochs. The weights in the loss function are set to be $\lambda_{1}=1$ and $\lambda_{2}=0.05$. 
% built on a ResNet50 backbone and ArcFace loss function and is 
% employs the proposed WaveResNet as the backbone and the same ArcFace loss and
% for distillation loss and wavelet similarity loss 
% It takes approximately 3 days for training on an NVIDIA-RTX-3090 GPU. 
% The baseline model consists of ResNet50 backbone and the same ArcFace loss function and is trained under the same setting of hyper-parameters. 

% \subsection{Results}

\subsection{Performance on Multiple Datasets}
Table. \ref{tab:mixdataset} shows the verification accuracy of the proposed method on multiple datasets of different resolutions. The results of two baseline models,  in the first two columns, show that training with multi-scale data is necessary to get reasonable results on LR test images but will lead to performance deterioration on HR images. 
The rest of the results demonstrate the effectiveness of each proposed module. The proposed identity-preserving WaveResNet 
significantly improves the performance in LR testing data.
% manages to improve the overall score. 
Training with realistic synthetic data further improves the performance in LR scenarios but impairs recognition accuracy on HR images. The cross-resolution distillation framework remedies the performance sacrifice in HR images and improves the overall scores.
Finally, after employing all proposed techniques, the model demonstrates promising results on both low and high-resolution images and outperforms the baseline models.
% The first two columns are regarded as baseline models. The results show that
% significantly improves the performance on average. 

% demonstrate the effectiveness of each proposed module
\subsection{Comparison with the SOTA Approaches}
The performance of the proposed method is also compared with other SOTA approaches. 
Fig. \ref{fig:lfw} presents the results of DCR \cite{lu2018deep}, TCN \cite{zha2019tcn}, Feng et al. \cite{feng2021resolution}, Knoche et al. \cite{knoche2022octuplet}, and the proposed method on low-resolution LFW dataset. The results show that this work consistently outperforms other methods in both low and high-resolution settings. 
Additional comparison has been made on the AgeDB-30 dataset, see Table. \ref{tab:agedb}. As a result, the proposed method achieves the best performance across all resolutions of images.
% with Kim et al. \cite{kim2021quality} and Shin et al. \cite{shin2022teaching} 
Besides, it is also observable that knowledge distillation-based methods generally show relatively higher scores on very low-resolution images when compared to other methods.
% It is also notable that knowledge distillation-based methods show relatively higher scores on very low-resolution images when compared to methods based on the triplet training scheme.

% methods based on the triplet training scheme show relatively weak results on very low-resolution images when compared to . 

%%%%%%%%%%%%% Compare with SOTA %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \begin{table}[htbp]
%   \centering
%   \caption{Verification accuracy (\%) on LFW dataset.}
%     \begin{tabular}{cccccc}
%     \toprule
%     Methods & 8x8   & 12x12 & 16x16 & 20x20 & HR \\
%     \midrule
%     DCR   & 93.60  & 95.30  & 96.60  & 97.30  & 98.70 \\
%     TCN   & 90.50  & 94.70  & 97.20  & 97.80  & 98.80 \\
%     FAN   & 95.20  & -     & -     & -     & 99.50 \\
%     MK-MMD & 94.05 & 95.20  & 96.74 & 97.13 & 99.03 \\
%     Lai and Lam & 94.80  & 97.60  & 98.20  & 98.10  & 99.10 \\
%     Octuplet & 90.38 & 96.88 & 98.28 & -     & 99.55 \\
%     \bottomrule
%     \end{tabular}%
%   \label{tab:addlabel}%
% \end{table}%

\begin{figure}[t]
	\centering
    \includegraphics[width=\linewidth]{SOTACompare.pdf}
    \vspace*{-8mm}
	\caption{Verification accuracy (\%) on the LFW dataset.}
	\label{fig:lfw}
\end{figure}


\begin{table}[t]
  \centering
  \caption{Verification accuracy (\%) on the AgeDB-30 dataset.}
    \begin{tabular}{ccccc}
    \toprule
    Methods & 14x14 & 28x28 & 56x56 & 112x112 \\
    \midrule
    Kim et al. \cite{kim2021quality} & 73.20 & 87.05 & 91.27 & 92.22 \\
    Shin et al.  \cite{shin2022teaching} & 79.45 & 89.15 & 93.58 & 93.78 \\
    Proposed Method  & 81.87 & 93.95 & 96.05 & 96.50 \\
    \bottomrule
    \end{tabular}%
  \label{tab:agedb}%
\end{table}%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Discussion}
The experimental results above demonstrate the effectiveness of the proposed method in the LRFR task. In fact, each module of the method plays a different role. 
For example, the WaveResNet and synthetic LR training data mainly contribute to LR face recognition, and the cross-resolution knowledge distillation paradigm additionally elevates the performance in HR images. The wavelet similarity loss improves the performance on all resolutions. It is also notable that most of the previous work presents a relatively poor result either in high or very low-resolution data. On the contrary, the proposed method offers high performance across a variety of resolution scenarios after a proper combination of proposed modules.


% The modules in the proposed method play different roles in the LRFR task. For example, the WaveResNet and synthetic LR training data contribute a lot to the LR recognition scenario, while the cross-resolution knowledge distillation paradigm elevates the performance on HR images. The wavelet similarity loss further improves the performance on all scales. It is also noticeable that most of the other related work presents a relatively poor performance either in HR or LR data. On the contrary, the proposed method remains in high performance across variant resolutions after a proper combination of different modules.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}
\label{sec:conclusion}
This paper proposes a novel identity-preserving approach built on a knowledge distillation framework to address the low-resolution face recognition problem. A realistic data degradation model is also contributed to further improve the performance.
Extensive experiments have shown that the proposed method outperforms the baseline model and other state of the art approaches on multiple datasets under different resolution scenarios. 

% In this paper, a novel approach is proposed for the low-resolution face recognition problem. 
% This work resolves the problem by contributing an identity-preserving neural network, a cross-resolution knowledge distillation framework, and a




\vfill\pagebreak


% References should be produced using the bibtex program from suitable
% BiBTeX files (here: strings, refs, manuals). The IEEEbib.bst bibliography
% style file from IEEE produces unsorted bibliography list.
% -------------------------------------------------------------------------

\let\oldbibliography\thebibliography
\renewcommand{\thebibliography}[1]{%
  \oldbibliography{#1}%
  \setlength{\itemsep}{0pt}%
}

\bibliographystyle{IEEEbib}
\bibliography{strings,refs}

\end{document}