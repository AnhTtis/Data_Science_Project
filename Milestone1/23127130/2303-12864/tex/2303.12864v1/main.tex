\documentclass[twocolumn,amssymb,amsmath,floats,showpacs,superscriptaddress,pre,floatfix]{revtex4}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{enumerate}
\usepackage{braket}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{float}
\usepackage{physics}
\usepackage{amsmath}
\usepackage{nccmath}
\usepackage{comment}
\usepackage{mathtools,amsfonts,amssymb,amsthm, bm, nccmath}
\usepackage{color}
\usepackage{amsthm}
\usepackage{xcolor}
\newcommand{\er}{Erd\H{o}s-R\'enyi }
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}{Proposition}[]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{problem}{Problem}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newcommand{\defa}{\overset{\operatorname{def}}{=}}
\algtext*{EndWhile}% Remove "end while" text
\algtext*{EndIf}% Remove "end if" text
\algtext*{EndFor}% Remove "end For" text
\algtext*{EndFunction}% Remove "end Function" text
\renewcommand{\eqref}[1]{Eq.~(\ref{#1})}



\begin{document}


\title{Entanglement Routing Based on Fidelity Curves for Quantum Photonics Channels}

\author{Bruno~C. Coutinho\footnote{Electronic address: bruno.coutinho@lx.it.pt}}
\thanks{These two authors contributed equally}
\affiliation{Instituto de Telecomunica\c{c}\~{o}es, Lisbon, Portugal}

\author{Raul Monteiro}
\thanks{These two authors contributed equally}
\affiliation{Instituto de Telecomunica\c{c}\~{o}es, Lisbon, Portugal}

\author{Luís Bugalho}
\affiliation{Instituto Superior T\'{e}cnico, Universidade de Lisboa, Portugal}
\affiliation{Physics of Information and Quantum Technologies Group, Centro de F\'{i}sica e Engenharia de Materiais Avan\c{c}ados (CeFEMA), Lisbon, Portugal}
\affiliation{LIP6, Sorbonne Université, CNRS, Paris, France}


\author{Francisco A. Monteiro}
\affiliation{Instituto de Telecomunica\c{c}\~{o}es, Lisbon, Portugal}
\affiliation{ISCTE - Instituto Universitário de Lisboa, Portugal}


\date{\today}

\begin{abstract}
The quantum internet promises to extend entanglement correlations from nearby neighbors to any two nodes in a network. How  to efficiently distribute entanglement over large-scale networks is still an open problem that greatly depends on the technology considered. In this work, we consider quantum networks composed of photonic channels characterized by a trade-off between the entanglement generation rate and fidelity. For such networks we look at the two following problems: the one of finding the best path to connect any two given nodes in the network bipartite entanglement routing, and the problem of finding the best starting node in order to connect three nodes in the network multipartite entanglement routing. We consider two entanglement distribution models: one where entangled qubit are distributed one at a time, and a flow model where a large number of entangled qubits are distributed simultaneously. We propose the use of continuous fidelity curves (i.e., entanglement generation fidelity vs rate) as the main routing metric. Combined with multi-objective path-finding algorithms, the fidelity curves describing each link allow finding a set of paths that maximize both the end-to-end fidelity and the entanglement generation rate. For the models and networks considered, we prove that the algorithm always converges to the optimal solution, and we show through simulation that its execution time grows polynomial  with the number of nodes in the network. Our implementation grows with the number of nodes with a power between $1$ and $1.4$ depending on the network. This work paves the way for the development of path-finding algorithms for networks with complex entanglement distribution protocols, in particular  for other protocols that exhibit a trade-off between generation fidelity and rate, such as repeater-and-purify protocols. 

\end{abstract}


\maketitle
\thispagestyle{empty}



\section{Introduction}


The quantum internet has the potential of bringing new capabilities to telecommunications that otherwise would be impossible to attain via classical communication channels. To name a few, it opens the doors to theoretically fully secure communications \cite{BENNETT20147}, enhanced sensing \cite{RevModPhys.89.035002}, and distributed quantum computation~\cite{Daniele}. A quantum internet will not function in a dissimilar manner to the classical one, however, instead of distributing information, a quantum internet will rather generate entanglement between remote nodes, a type of correlation between different parties with no classical analogue~\cite{nielsen00}.
The typical model for a quantum internet is a network where the nodes store qubits in quantum memories, and the links between two nodes represent a quantum channel capable of creating quantum entanglement between the qubits stored at the nodes at both ends of the link. As often made, one assumes that it is possible to apply two-qubit gates between any two qubits inside the same node, and that each node has a fixed number of memories associated with each of the channels connected to it~\cite{PhysRevA.101.052315,Coutinho2022,Pirandola2019,doi:10.1126/science.aam9288}. 

Different metrics can be used to characterize a quantum link. A popular and useful one is the fidelity attainable by a link, however that fidelity can depend on other variables much related to the technology that one is using to sustain quantum entanglement. For example, one may apply link purification such that from a larger number of qubits, each of which having a low fidelity, one can create a lower number of qubits holding a higher fidelity degree. The technology considered in this paper is based on photon entanglement and, in this case, the achieved fidelity of a qubit pair is chiefly dependent on the number of photons (number of ``clicks'') generated, such that one can characterize the link by a trade-off curve between entanglement probability and the obtained fidelity in the entangled qubit pair.

Remote entanglement generation involving distant codes that are not directly connected can be achieved through the \textit{swapping} mechanism~\cite{insidequantum} applied at several middle nodes. This procedure creates entangled qubit pairs (ebits) between nodes (as exemplified in Fig.~\ref{fig1}). By using several swapping operations it is possible to create entanglement between any two nodes in a network, provided the path connecting the two nodes exits, and also that the end-to-end quality of the entangled pair generated observes the requirements of the specific application.

Finding the best route to distribute entanglement has proven to be a non-trivial problem and several algorithms that consider different aspects of both entanglement generation and distribution have been proposed \cite{caleffi2017optimal,Pirandola2019,chakraborty2020entanglement,Bugalho2021,ghaderibaneh2022pre,ghaderibaneh2022efficient}.
Calleffi et al. \cite{caleffi2017optimal} studied a single-qubit-generation model, meaning that one entangled qubit is attempted to be transmitted at each time, and only bipartite entanglement distribution is considered (i.e., between only two nodes). In their model, the entangled qubits start as maximally entangled and subsequently lose coherence over time due to imperfect quantum memories. They showed that it is not possible to use Dijkstra's algorithm to find the route that maximizes the entanglement distribution rate and proposed an algorithm to exactly solve this problem.
Although not directly stated, the execution time of the proposed algorithm grows supra-exponentially with the number of nodes in the network.
In \cite{caleffi2017optimal} the authors point out that for small quantum networks the supra-exponentially growth of the execution time will not be a problem.

Pirandola et. al~\cite{Pirandola2019} looked at bipartite entanglement networks based on the theoretical upper bonds for the channel capacity. In a regime where entanglement distribution is close to its theoretical upper bond, that work showed that in such regime the Dijkstra's algorithm can be used to find the path that maximizes the entanglement distribution rate between nodes, and the max-flow min-cut theorem can be used to find the maximum rate between two nodes using multiple-path entanglement distribution. Both problems can be solved in polynomial time, and this approach was later generalized in order to include multipartite entanglement distribution of GHZ-states~\cite{Bauml2020}.

Chakraborty et al.~\cite{chakraborty2020entanglement} studied bipartite entanglement distribution in a flow model where ebits have the same fidelity (quality of the entanglement), but each link has different capacities. Here, we remind that a \textit{flow model} is one where multiple ebits are attempted to be simultaneously established. Those authors proposed a multi-commodity flow algorithm that can find the optimal flow for bipartite entanglement distribution between two sets of nodes in polynomial time.

Bugalho et al. considered in \cite{Bugalho2021} bipartite and multipartite entanglement distribution assuming a single-qubit-generation model and considering that not all links have the same fidelity or entanglement generation probabilities, and combined that with imperfect quantum memories. That work considered a single source model (i.e., only one source node trying to establish entanglement with all the other nodes) and proposed a multi-objective routing algorithm to find the routes that simultaneously maximizes the bipartite or multipartite entanglement generation rate and the fidelity. The algorithm is NP-hard, even though the authors showed that, for the networks analyzed, the algorithm always converges in polynomial time.

Ghaderibaneh et al.~\cite{ghaderibaneh2022efficient} focused on a bipartite entanglement distribution model with a non-deterministic swap. As a consequence of that, the order in which each of the swapping operations are applied impacts the rate of entanglement distribution. They proposed a polynomial-time algorithm to find both the optimal path and the optimal swapping order.

Finally, Santos et al.~\cite{sarasantos} proposed a multi-objective algorithm for bipartite entanglement distribution between two nodes, considering a network based on an asymptotic description of quantum-repeater-and-purification protocols \cite{ghaderibaneh2022efficient,Coutinho2022}, however with  detail given on the specific protocol.

All of these works represent steps forward not only regarding routing techniques in the quantum networks, but also in how detailed the network models are. That being said, one is still far from having a network model that fully incorporates the intricacies of entanglement generation and distribution.


\section{Entanglement Generation}

This paper makes progresses in considering a more accurate model for a quantum network connected through quantum photonics channels that follow the model proposed in \cite{Childress:2005}. In such setups, the entanglement between qubits is generated by means of laser pulses. An increase in the duration of the laser pulses increases the probability of generating an ebit, but it also reduces its quality, as represented in Fig.~\ref{fig1}(a,b). For this reason, if the objective for a link is to generate a large amount of qubits, while its quality is a matter of less importance, one would use a longer laser pulse; in contrast, if the link requires just a few ebits but with high fidelity, then shorter pulses would be preferred.entanglement as a function of the target fidelity. \par 

Let us look in more detail at the entanglement generation scheme presented by Childress~\cite{Childress:2005}, in which two  NV-center are inside a photonic cavity, one at each end of a photonic fiber. Laser pulses are used to create entangled NV-centers excited states pairs with a fidelity
\begin{align}
    F=&\frac{1}{2}\left(1+e^{-p_{\rm em}(1-\epsilon)}\right)-\frac{p_{\rm dark}}{p}-\beta.
    \label{eq:F_vs_pem}
\end{align}
where $F$ is the fidelity of the generated ebit, and $p$ is the success probability. $p_{\rm em}$ is the emission probability that will increase with the duration of the applied laser pulse. $\epsilon$ is the collection efficiency, i.e., the probability of a photon being collected by the cavities. $p_{\rm dark}$ is the dark-count probability, referring to the probability of detecting a photon when none was emitted. $\beta$ is a parameter whose details are not directly relevant to our work; in practice, it limits the maximum fidelity that an entangled generated qubit pair can achieve using this setup. Finally, the success probability of generating an ebit is \cite{Childress:2005}
\begin{equation}
    p=\frac{1-e^{-p_{\rm em}\epsilon/2}}{2}.
    \label{eq:p_vs_pem}
\end{equation} 

\section{Entanglement propagation}

The previous section only concerned entanglement generation between nodes that are directly connected. As mentioned before, it is also possible to generate entanglement between nodes that are not directly connected, provided that there is a path connecting them. Let us consider the simple example in Fig.~\ref{fig1}(c): although node $A$ and $C$ do not share an ebit, it is possible to generate one  using a swap operation between the two qubits in node B~\cite{insidequantum}. 
This operation comes with a cost in terms of the quality of the entanglement generated, as seen in Fig.~\ref{fig1}(d). The fidelity curve for the entanglement generated between A and C (Fig.~\ref{fig1}(d)), is considerably worse than the  fidelity curves for the entanglement generated between $A$ and $B$, and $B$ and  $C$ (Fig.~\ref{fig1}(a-b)). How to compute such fidelity curves is highly dependent on the type of noise affecting the qubits, and also on the exact procedure used to create a connection between nodes $A$ and $B$.
In the present work, we assume that the noise affecting our entangled pairs can be described by a uniform depolarising channel originating in Werner states~\cite{PhysRevA.40.4277}, given by
\begin{align}
    \rho=&\frac{1-F}{3} I_4+\frac{4F-1}{3} \ket{\phi_{\rm +}}\bra{\phi_{\rm +}}\\
    &=\frac{1-\gamma}{4} I_4+\gamma \ket{\phi_{\rm +}}\bra{\phi_{\rm +}},
\end{align} 
where $\ket{\phi^{\rm +}}=\left(\bra{0 0}+\ket{1 1}\right)/\sqrt{2}$ is a maximally entangled bell state, $F$ is the fidelity of the state, and $\gamma$ is the Werner parameter that relates to the fidelity as~\cite{chakraborty2019distributed,sarasantos, Bugalho2021}
\begin{equation}
\gamma=\frac{4F-1}{3}.
\label{eq:f_vs_gamma}
\end{equation}
Werner states hold the convenient property that swapping  two or more Werners generates another Werner state with a fidelity that is easy to calculate. In fact, the end-to-end value of the Werner parameter $\gamma$ in a path is given by the product of the Werner parameter $\gamma$  of the individual links \cite{Nemoto:2015,chakraborty2019distributed,Bugalho2021}.   
For the example let us consider Fig.~(\ref{fig1}), where the entangled states between nodes A and B, and B and C are Werner states with fidelities  $F_{AB}=(3\gamma_{AB}+1)/4$, and $F_{BC}=(3\gamma_{BC}+1)/4$ respectively. The fidelity between the nodes A and C after a swapping operation at node $B$ will be  $F_{AC}=(3\gamma_{AC}+1)/4$, with $\gamma_{AC}=\gamma_{AB}\gamma_{BC}$. For a link $e$, its fidelity is denoted as $F_e$, while for a generic path $P$  the fidelity is given by $F_{P}=(3\gamma_{P}+1)/4$, where the Werner parameter of a path, $\gamma_{P}$, is given by the product of the Werner parameter of the individual links~\cite{Bugalho2021}.
In the rest of the paper, the term fidelity curves will be used to denote both fidelity and Werner parameter vs channel capacity, given the fact that the Werner parameter and the fidelity are linearly correlated to each other.
In the following subsections, we look at that entanglement distribution rate, where we consider two distribution models: a single distribution ebit distribution model \cite{sarasantos, Bugalho2021}, and a flow model~\cite {chakraborty2020entanglement,dai2020optimal}.  

\begin{figure}[tb]
    \centering
    \includegraphics[width=0.4\textwidth]{figure_1.pdf}
    \caption{\textbf{Entanglement distribution.} (a-b) Shows fidelity as a function of the entanglement generation probability $p$ (and the equivalent in terms of capacity $c$, for $n_e=1$) for two links. Two fidelity curves are depicted: one for the link between nodes $A$ and $B$ (a) and the other for the link between nodes $B$ and $C$. (c) shows a simpler quantum repeater setup. The capacity values are always between $0$ and $0.5$  since from Eqs.~(\ref{eq:F_vs_pem})-(\ref{eq:p_vs_pem}) one can verify that the entanglement generation probability of a single ebit cannot be above $0.5$. $A$, $B$ and $C$ represent three nodes: node $B$ contains two quits, with one entangled with a quibt contained in node $A$ and the other in node $C$. Applying a swapping protocol at the two qubits contained in node $B$ creates an entanglement between the qubits in nodes $A$ and $C$ according to the fidelity curve shown in (d). The end-to-end link capacity will depend on the distribution model considered, which can be either the single ebit distribution model, or the flow model. In (e) this process is described in a more formal way, where the concatenation of path $P_{AB}$ with a network link $e_{BC}$ creates a path between node $A$ and $C$ with the fidelity curve shown in (d).}
    \label{fig1}
\end{figure}

\subsection{Single ebit distribution model}

We start by describing the single distribution model. In this model, all links in a path $P$ try to generate one ebit simultaneously, and the entanglement is only generated between the source and target nodes if all links successfully  generate entanglement. This method is especially useful for situations where the quality of the quantum memories is low, therefore the entanglement between the ebit rapidly decays with time. Because all entanglement generation is made simultaneously, the links only need to be stored in a quantum memory for the time necessary to apply the swapping protocol. The resulting decay in fidelity is incorporated in the $\beta$ parameter of the fidelity curve in Eq.~(\ref{eq:F_vs_pem}).
Let us then consider a path $P$ in a network where any link $e$ generates one ebit per fixed time interval $t$ with a probability $p_e$, corresponding to an average capacity $c_e=p_e$. Note that because there is only one qubit being generated per time slot, the maximum rate (i.e., the capacity) corresponds to the probability $p_e$.
The end-to-end Werner parameter and the end-to-end rate between a source node and a goal node are respectively given by

\begin{align}
    &\gamma^{\rm sg}=\prod_{e \in P} \gamma_{e}(c_e), \label{eq:final_gamma}\\
     &c^{\rm sg}=\prod_{e \in P} c_e. \label{eq:final_capacity}
\end{align} 
Note that in different combinations of the link capacities, $\{c_e\}$, can result in the same end-to-end capacity $c^{\rm sg}$, and therefore the end-to-end Werner parameter is not a function of the end-to-end capacity. This problem can be overcome by always considering the combination of link capacities that maximizes the Werner parameter (and consequently the fidelity), or a given end-to-end capacity  $c^{\rm sg}$, defined as 
\begin{align}
    &\gamma^{\rm sg}(c^{\rm sg})=\max_{c_e}\prod_{e \in P} \gamma_{e}(c_e) \label{eq:final_gamma},
\end{align} 
and keeping the capacity given by Eq. \ref{eq:final_capacity}.
The limitation of this model is that both the fidelity and the generation probability decay with the length of the path. For this reason, the single distribution protocol might not be the preferred one for entanglement generation over long distances.
\subsection{Flow distribution model}

The previous limitation can be ameliorated in a flow distribution model, where multiple ebits are generated at the same time at each node. In this type of distribution model one considers that a link, $e$, contains $N_e$ ebits, the capacity of each link is defined as $C_e=N_e p_e$, and the capacity of a path is given by the smallest capacity of any link in the path.
The rationale is that while generating a large number of qubits at the same time, the statistical fluctuations of the entanglement generation process are low to the point that they can be ignored. Consequently, one can consider for practical purposes that a fixed amount of ebits, given by $C_e$, is generated each time that entanglement is attempted. As before, all swapping operations are executed in parallel and  therefore the method is useful when the quality of the quantum memories is low but one can generate a large number of ebits simulations. As in the case of single bit distribution model, because all the entanglements are carried out simultaneously, the links only need to be stored in a quantum memory for the time needed to apply the swapping protocol. Once again, the decay in fidelity taking place during such time will just affect the parameter $\beta$ in the fidelity curves.
Although not directly, in the model the entanglement distribution rate still decays with the distance. The capacity of each link depends on the success entanglement generation $p_e$, and therefore the fidelity and the capacity of each link are correlated (see Fig.~\ref{fig1}(a,b)). Since the ebits end-to-end fidelity decays with the distance, the only way of generating ebits with an end-to-end fidelity above a certain threshold is to reduce the entanglement distribution rate as the  distance increases. 

In the following it will be convenient to use a normalized (or relative) capacity. Let us consider the maximum number of ebits in any link in the network as $N_{\rm max}:= \max_e N_e$. The relative capacity is then given by $c_{e}= n_e p_{e}$, with $n_e$ defined as the relative number of ebits in a link $e$, defined as $n_{e}= N_e/N_{\rm max}$. In general, the fidelity of each ebit in a path decays with its capacity, and the end-to-end rate of the entanglement generation is bottlenecked by the smallest capacity among its links. If the fidelity is a monotonically decreasing function in respect to the links' capacity, the optimal solution is for all links to operate with a capacity equal to the end-to-end entanglement distribution rate  (this is shown in Appendix~\ref{optimality_1}), leading to the following end-to-end Werner parameter for path $P$:

\begin{align}
    &\gamma^{\rm flow}_{P}(c)=\prod_{e \in P} \gamma_{e}(c). \label{eq:final_gamma}
\end{align} \par 

\begin{figure}[tb]
    \centering
    \includegraphics[width=0.45\textwidth]{figure_3.pdf}
    \caption{\textbf{Non-monotonically decreasing fidelity curves.} Figure (a) shows a non-monotonically decreasing fidelity due existence of dark counts. In this example for low entanglement generation rate ($c<c_{\rm min}$), the dark counts dominates, causing a fidelity reduction. This problem can be fixed if for each value of $c_{ij}$ we select the largest fidelity with an entanglement rate above $c_{ij}$, given by Eq.~\ref{eq:fix_gamma}, and thus one obtains a monotonically decreasing function, show in Figure (b).}
    \label{fig2}
\end{figure} 

Even though this assumption is not always necessarily true, there is an easy way to overcome the cases when the fidelity curves are not monotonically decreasing functions. In our model, the fidelity curves are not monotonically decreasing functions if dark counts are present ($p_{\rm dark}>0$)~\cite{Childress2005}. As previously stated, a dark count occurs when the detector registers the arrival of a photon when none had been emitted. If the emission probability is low, those events can become dominant and reduce the quality of the generated ebit. Fig.~\ref{fig2} shows such phenomena: $F_{e}(c_{e})$ grows with the entanglement generation probability $c_{e}$ until $c_{\rm min}$, and then starts to decrease. For any value $c_{e}<c_{\rm min}$, our toy example can consider an artificial monotonically decreasing function where, for $c_{e}<c_{\rm min}$, we define $F_{e}(c_{e})\rightarrow F_{e}(c_{\rm min})$. Each link needs to know that a generation rate below $c_{\rm min}$  is artificial and automatically replaces it with $c_{\rm min}$. If multiple monotonically decreasing regions exist, one can in general apply the following transformation:
\begin{equation}
F_{e}(c)\rightarrow \max_{c' \geq c} F_{e}(c'),
    \label{eq:fix_gamma}
\end{equation} 
meaning that for each value of $c$ one selects the largest fidelity with an entanglement rate above or equal to $c$.

\section{Routing metrics, Isotonicity and Monotonicity}

Formal algebras are useful tools to understand routing, especially  when convergence to the optimal solution is of interest~\cite{Bugalho2021,sobrinho2003network,sobrinho2005algebraic}. Although an extensive explanation of routing algebras is outside of the scope of this work, we will introduce some useful concepts. The  propagation of entanglement described in the previous section is often called path extension and is denoted by $\bigoplus$. For example in Fig.~\ref{fig1}(c), the path between $A$ and $B$, $P_{AB}$ is expanded to connected $A$ and $C$ using the link $e_{BC}$. In routing theory this is termed  a concatenation between  $P_{AB}$  and the link  $e_{BC}$, and it is represented as $P_{AC}=P_{AB}\bigoplus e_{BC}$, as depicted in Fig.~\ref{fig1}(e). Routing metrics are another important concept in routing theory; they consist of a set of parameters that characterize each path and allow one to compare two paths connecting the same nodes, and decide if one is preferable to the other, or if none of them is necessarily better. A routing metric can be a real number (i.e., a simple weight), or a multidimensional quantity, for example, a set of distances or objectives. As stated earlier, the main contribution of this work is the proposal that fidelity curves can be good routing metrics, and can be used to find the optimal path between two nodes in a network.

It is known that if a routing metric is both isotonic and monotonic, a multi-objective optimization algorithm will always converge to the set of optimal solutions~\cite{Bugalho2021, sarasantos, sobrinho2005algebraic}, making it worthy to explore these two properties in detail. \textit{Monotonicity} means that when a path is extended our metric will either always increase or decrease. To explain the concept of \textit{isotonicity}, let us consider two paths, $P$ and $P'$, connecting the same end-nodes, and consider a point of the fidelity curve on both paths such that $\gamma_P(c) \leq \gamma_{P'}(c)$. When extending both paths with an extra edge, as it is exemplified in Fig.~\ref{fig3}(a), if for $P\oplus e$ and $P'\oplus e$ we still have that $\gamma_{P\oplus e}(c) \leq \gamma_{P' \oplus e}(c)$, then the metric is isotonic for the capacity $c$. The introduction of the concept of dominance allows us to contemplate the entire fidelity curve. In our work we consider that a path dominates another (denoted as $P' \textbf{ D } P$) if the fidelity curves associated with path $P'$ and $P$  are distinct, and the fidelity curve of $P'$ is above or equal to the fidelity curve of $P$ for any a capacity $c$ in the relevant domain, as exemplified in Fig.~\ref{fig3}(b). If, for every value of the capacity, the metrics are monotonic and isotonic, then the dominance relation is inherited when extending the paths, and the algorithm is then able to find the optimal solution. Since the algorithm merges curves from different paths into one, only keeping the highest value from each, as it is exemplified in Fig.~\ref{fig3}(c), isotonicity of the curve and dominance inheritance for every point of the curve has practically the same meaning. Fidelity curves are trivially isotonic and monotonic; for completeness, those facts we will proven it in the next subsection.


\subsection{Isotonicity and monotonicity for the single ebit distribution model}

\begin{figure}[tb]
    \centering
    \includegraphics[width=0.4\textwidth]{figure_2.pdf}
    \caption{\textbf{Comparison between paths and dominance.} Let us suppose that we have two paths between, $P_{AB}$ and $P'_{AB}$, node A and B as represented in (a). $P'_{AB}$ dominates $P_{AB}$ if allow of if no matter the properties of the network segment $e$. $P'_{AB} \bigoplus e $ dominates  $P_{AB} \bigoplus e $. (b)-left shows an example where $P'_{AB}$ dominates $P_{AB}$, therefore the dominant curve, (b)-left, is composed of $P'_{AB}$ only. Figure (b)-left shows an example where neither path $P'_{AB}$ or $P_{AB}$ dominates each other, therefore the resulting dominant curve, shown in (b)-left, is given by $P'_{AB}$ or $P_{AB}$ depending on the different domains where the channel capacity $c$ lies on. \label{fig3}} 
\end{figure} 

Let us divide the proof that the fidelity curves in the parallel entanglement distribution model are monotonic and isotonic metrics. 
First, it is important to note that one always obtains the same fidelity curve independently of the order of the concatenations, as shown in Appendix~\ref{optimality_0}. Given this, in order to prove  monotonicity, we need to show that the fidelity curve $\gamma_{P}(c)$ of a path $P$ is above or equal to the fidelity curve, $\gamma_{P'}(c)$, of a path $P':=P\oplus e$ where $e$ is a single link with a fidelity curve $\gamma_{e}(c)$. We can then write (see Appendix~\ref{optimality_0} for details),  
\begin{align}
\gamma_{P'}(c) = \max_{c_e' \in P'} \left[\prod_{e' \in P}\gamma_{P}(c_e')\right]=\max_{c_P,c_e} [\gamma_{P}(c_P) \gamma_{e}(c_e)],
\end{align}
with the constraint that the capacity of path $P'$ is $c$. Therefore, the product between the capacity of path $P$, $c_P$, and the capacity of the extended link, $c_e$, needs to be equal to $c$ (that is, $c_P c_e= c$). By assuming that fidelity curves are monotonically decreasing functions, one can write (see  Appendix~\ref{optimality_0} for details)
\begin{align}
\gamma_{P'}(c) = \max_{c_e} [\gamma_{P}(c/c_e) \gamma_{e}(c_e)]\leq \gamma_{P}(c),
\end{align}
where we use the fact that $\gamma_{e}(c_e)$ is at most equal to one, and therefore $c_P= c/c_e \geq c$, proving that the fidelity curves in the single ebit entanglement distribution model are monotonically decreasing metrics.  

We now move on into proving isotonicity. Let us consider two paths $P_1$ and $P_2$, and the respective extensions,  $P'_1=P_1\oplus e$, and $P'_2=P_2\oplus e$, with fidelity curves,
\begin{align}
\gamma_{P_1'}(c) =& \max_{c_{P},c_e} [\gamma_{P_1}(c_P) \gamma_{e}(c_e)]\\
\gamma_{P_2'}(c) =& \max_{c_{P},c_e} [\gamma_{P_2}(c_P) \gamma_{e}(c_e)],
\end{align}
with $c = c_P c_e$.
We need to prove that if $P_1 \textbf{ D } P_2$ it implies that $P_1' \textbf{ D } P_2'$, i.e., if the fidelity curve of path $P_1$ is equal or above the fidelity curve of path $P_2$ for all  capacities, then fidelity curve of path $P'_1$ will also be equal or above the fidelity curve of path $P'_2$, for all  capacities. One can prove this by contradiction. Let us suppose that there is a capacity value $c$ so that the fidelity of path $P'_2$ is larger than the fidelity of path $P'_1$, i.e., 

\begin{align}
\max_{c_e^*} [\gamma_{P_2}(c/c_e^*) \gamma_{e}(c_e^*)] >
\max_{c_e^{**}} [\gamma_{P_1}(c/c_e^{**}) \gamma_{e}(c_e^{**})].
\end{align}
This equation establishes that the optimal fidelity for capacity $c$ in path $P_2$ is larger than the optimal fidelity for capacity $c$ in path $P_1$. In turn, this also implies that for the value of $c_e^*$ which maximizes the fidelity in path $P_2$, we get that:
\begin{align}
\gamma_{P_2}(c/c_e^*) \gamma_{e}(c_e^*) &> \gamma_{P_1}(c/c_e^*) \gamma_{e}(c_e^*) \\
\implies \gamma_{P_2}(c/c_e^*) &> \gamma_{P_1}(c/c_e^*),
\end{align}

\noindent that is a contradiction, since we assumed a priory that $P_1$ dominates $P_2$. We  can therefore conclude that fidelity curves in the parallel are isotonic. 

\subsection{Isotonicity and monotonicity for the flow entanglement distribution model}

The proof that the fidelity curves are isonotic and monotonic in the flow model are more straightforward. Let us consider Eq.~(\ref{eq:final_gamma}) applied to a path $P$ that goes from node $i$ to node $j$ using one or more hops in between, and which is extended using a link between nodes $j$ and $k$, $e_{jk}$. In a more formal way, $P'=P\bigoplus e_{jk}$. For simplicity, we will drop the notation of the edges in link $e$. One obtains the fidelity curves,
\begin{align}
    \gamma_{P'}(c)=&\prod_{e' \in P'} \gamma_{e'}(c)= \\& \prod_{e' \in P} \gamma_{e'}(c)  \times  \gamma_{e}
     =\gamma_{P}(c) \gamma_{e}(c).
\end{align} 
Given the fact $\gamma_{e}(c)\leq1$ , we can conclude that
\begin{align}
    &\gamma_{P'}(c)  \leq \gamma_{P}(c),
\end{align} 
and from that, we conclude that the fidelity curves are a monotonically decreasing metrics in relation to path extension. 
Using the concept of dominance, one can show that in fact, these fidelity curves are also isotonic. Let us consider two paths, $P$ and $P'$, between the nodes $i$ and $j$, with the two paths characterized by $\gamma(c_{ij})$ and $\gamma'(c_{ij})$, respectively. Similarly $P\oplus e$ and $P'\oplus e$ are given by
\begin{align}
    &\gamma_{P}(c) = \gamma(c) \gamma_{jk}(c) \\
   & \gamma_{P'}(c) = \gamma'(c) \gamma_{jk}(c) 
\end{align}
and 
\begin{align}
    &\gamma'_{ik}(c)/ \gamma_{ik}(c) = \gamma'_{ij}(c)/ \gamma_{ij}(c).
\end{align}

If $P'$ dominates $P$ (i.e., $\gamma_{ij}(c)/\gamma_{ij}'(c)\geq 1$ for all values of $c$ then it is easy to see that $P'\oplus e$ also dominates $ P\oplus e$ (i.e., $\gamma_{ik}(c)/\gamma_{ik}'(c)\geq1$ for all values of $c$. Fig.~\ref{fig3}(c) shows a situation  where neither $P$ or $P'$ dominates. In such cases, the dominant curve is composed of parts of the curves of both paths.  

\section{Algorithm}
In the last section, we studied the properties of the fidelity curves as routing metrics, and we found them to be both isotonic and monotonic for the two distribution models considered. With these properties holding, it is possible to devise a simple multi-objective routing algorithm \cite{Martins1984,sobrinho2005algebraic} that finds the best routes between a source node, and all other nodes. The concept behind  the algorithm is to start at a source node and compute the fidelity curves and a priority value for the links connecting to its neighboring nodes. All discovered nodes are added to a priority queue that orders them according to the priority value, denoted as $\mathcal{A}$ in Algorithm \ref{alg:SPT}.
The algorithm then moves to the path with higher priority that connects the source node to a node $i$. This path is then extended to connect the source nodes to all neighbors of node $i$ and calculates both the fidelity curves and the priority values of these new paths. 
Inevitably, at a certain point the algorithm will find a node that already contains a fidelity curve. In this situation, the algorithm has found an alternative path to reach the neighboring node, and has to check if this new path is or is not dominated by the old paths.
In order to do this, a second data structure is required to serve as a temporary registry, denoted as $\mathcal{F^{\rm reg}}$ in Algorithm \ref{alg:SPT}. This variable keeps track of the optimal fidelity curve found for each node, alongside the respective paths (as represented in Fig.~\ref{fig3}. If the new path is dominated by the old path, (as exemplified in Fig.~\ref{fig3}(b)), the algorithm stops and moves to the next node in the priority queue. Instead, if the new path is not dominated by the old one, the fidelity curve and respective path are recomputed, (see Fig.~\ref{fig3}(c)), and therefore all paths that go through this neighboring node need to be reevaluated. This is achieved by adding this neighboring node to the added priority queue. This process continues until the priority queue is empty. Note that we did not specify how the priority value of each node is computed, simply because we do not know what is the optimal way to compute such value. Prioritizing paths with a low likelihood of being dominated will reduce the number of recomputations and paths added to the priority queue.

Although multi-objective routing algorithms often converge to the optimal solution in polynomial time, multi-objective routing problems are in general NP-hard~\cite{bokler2017multiobjective,serafini1987some}, and therefore choosing a good priority value is quite important. In our case, we used the length of the path as our priority value. The shortest paths are not necessarily the dominant paths but they are a good first guess. Because the fidelity rapidly decays with the length of the path, it becomes increasingly unlikely that longer paths will not be dominated by much shorter ones. The complexity of the protocol is numerically evaluated in the next section. We leave a rigorous analytical study of the convergence of our approach for future work.

    \begin{algorithm}[tb]
    \caption{Bipartite routing: Source-to-all}\label{alg:SPT}
    \begin{algorithmic}[0]
         \State {\bf{Data structures and objects}}
        \State $\mathcal{A}:=$ a set containing all paths that are still to be visited, defined as  $P_i$ = $\left\{d(i), F_i,n_i\right\}$, ordered as a priority queue. The order is defined by an increasing $d(k)$, with the smallest distance at the top of the priority queue.
        \State 
        \State $\mathcal{F}^{\rm reg}:=$ is a set containing, for each node $n_i$, a function $\mathcal{F}^{\rm reg}_{n_i}$  representing the concatenation of all non-dominated paths from a source to node $n_i$, and the associated paths (as represented in Fig.~\ref{fig3}).
        \State 
        \Function{PathSelection}{$source$}
        \State  Initialize $\mathcal{A}$ as $\left\{0, F_0 , source\right\}$.
        \State  Initialize $\mathcal{F}$ as set of $F_{\rm null}$ and null paths.
        \While{$\mathcal{A}$ is not empty}
            \State Select path $P_i$ at the top of the priority queue
            \State Remove $P_i$  from $\mathcal{A}$.
            \If{$\mathcal{F}^{\rm reg}_{n_i} \textbf{ D } F_i  $}
            \State Do nothing
            \Else
                \State  Update $\mathcal{F}^{\rm reg}_{n_i}$ with a concatenation of $\mathcal{F}^{\rm reg}_{n_i}$   and \State $F_i$, as described in Fig.~\ref{fig3}.
                \For{each node $n_k$ (neighbour of node $n_i$)}
                    \State Add path $P_k$ to $\mathcal{A}$.
                    \EndFor
            \EndIf
        \EndWhile
        \EndFunction
        \State
        \Return $\mathcal{F}^{\rm reg}$
\State
\State{\bf{Abbreviations}}
\State $P_k$ is the extension of path $P_i$ to all nodes $n_k$, neighbours of node $n_i$. ${P_k :=P_i \oplus e_{ik}}$.
\State{$F_0$ is a function defined as $F_0=1$ for any capacity. $F_0:= 1~\forall~c$.}
\State{$F_{\rm null}$ is a function defined as $F_{\rm null}=0$ for any capacity.}
    \end{algorithmic}
\end{algorithm}

\section{Results for bipartite entanglement distribution}
In this section we present simulations for both the single and flow ebit distribution models. Two types of complex network are considered: first, we consider an \er network \cite{Newman2010,RevModPhys.80.1275}, which is one of the most studied types of networks and secondly a  random geometric graph networks is considered.

An \er network is  composed of $V$ nodes and $L$ links connecting two random nodes, and it captures some of the properties of real-world networks, such as randomness and small-worldness (when the diameter of the network grows logarithmically with the number of nodes in the network). We consider an \er with an average degree (number of connections per node) $\langle{k}\rangle=2L/V=6$, $10$. Those values are large enough to guarantee that there is a path connecting the large majority of pairs of nodes but they are still small enough to assure that the network remains sparse ($c \ll V$).

When connected through optical fibers the entanglement distribution rate decays rapidly with the distance, and therefore it is natural to assume a network with  connection only between nodes that are physically close to each other, leading us to the second network model: the random geometric graph~\cite{christensen_rgg}. A random geometric graph is a network embedded in a geometric space, usually a $d$-dimension box of volume $1$, where $N$ nodes are randomly distributed and two nodes are connected if the distance between them is smaller than a neighborhood radius $r$.
The neighborhood radius $r$ are related to the degree of the network as
\begin{align}
 \langle{k}\rangle=V\pi r^2.
\end{align}
For simplicity, we consider that all links in the network have the same total number of entangled equbits $N_e$, and therefore  the relative number of ebits in each link is one ($n_e=1$). The only differences between the links originates from the collection efficiency $\epsilon$, the dark count $p_{\rm dark}$, and $\beta$. Those values are randomly generated for each link from uniform distributions $U(0.3, 0.4)$, $U(0,{10}^{-3})$ and $U(0,{10}^{-3})$, respectively.

The algorithm's complexity is measured via two complementary manners, as shown in Fig.~\ref{fig4}. The \texttt{WHILE} loop in Algorithm~\ref{alg:SPT} is responsible for the main computational cost of the algorithm, and it ends only when there are no remaining paths to be visited. For this class of algorithms, the number of visited paths can grow superexponentially with $N$, and therefore it is important to measure how the total number of visited paths in the proposed algorithm grows with the size of the network. Fig.~\ref{fig4}(a)  (b) (e), and (f) shows the growth to be linear or slightly sublinear for both \er and random geometric graph networks regardless the used ebit distribution model.

\begin{figure*}[tb]
    \centering
    \includegraphics[width=1\textwidth]{figure_4.pdf}
    \caption{{\bf Algorithm~\ref{alg:SPT} complexity analysis}. Simulation of bipartite entanglement distribution for photonic quantum networks with an \er network (ER) and a random geometric graph (RGG) topology, an average degree $\langle k \rangle=6$ and $10$ (blue lines), for the single, (a-d), and flow, (e-h), distribution models. Each link is characterized by three parameters: $\epsilon$, the dark count $p_{\rm dark}$, and $\beta$, randomly assigned from uniform distributions $U(0.3, 0.4)$, $U(0,{10}^{-3})$, and $U(0,{10}^{-3})$, respectively. (a-b) show the total number of visited paths as a function of the number of nodes in the network for an ER network and a RGG topology in the single distribution model, and (c-d) show the total execution time of the algorithm as a function of the number of nodes for the same  networks. (e-h) show the same information for the flow distribution model. The computational complexity in each case is estimated using a fit (shown as dashed lines) of the type $Y=k X^\alpha$, where $k$ is an overhead constant, and $\alpha$ measures the computational complexity of the algorithm. The shaded region around each point represents its variance based on 20 samples.  In in (a-b) and (e-f) one has $\alpha \approx 1$, indicating that the number of visited paths grows linearly with the size of the network. 
    In the single distribution model We obtain that $\alpha$ is never much larger than $1$, and slightly bellow one in Fig.~(b,c).  This is likely related to the fact that the single distribution model is not the most efficient model to distribute entanglement over long distances, and for long distance the number of non-dominated paths can diminish. For the flow model one obtains that $\alpha \approx 1$ in Fig.~(g), but $\alpha \approx 1.3$ in Fig.~(h), denoting that the execution time inside the \texttt{WHILE} loop in algorithm~\ref{alg:SPT} increases significantly the number of nodes in the network. All measures of complexity show the algorithm complexity of the algorithm to increase polynomially with the number of nodes.\label{fig4}}
\end{figure*}

The execution time (in seconds) of the algorithm was also measured as a function of the number of network nodes. For the single ebit distribution model network (shown in Fig.~\ref{fig4}(c) and (d)),  the execution time grows linearly or sublinearly with the number of nodes. The  sub-linearly growth is likely  related to the fact that the single distribution model is not the most efficient model to distribute entanglement over long distances, and for networks with large distances between nodes the number of non-dominated paths between nodes can be rather small. For the flow ebit distribution model, shown in Fig.~\ref{fig4}(g) and (h), one observes that the execution time grows linearly with the number of nodes for the \er network. However, for the random geometric graph, the running time grows as a power between $1.4$ and $1.5$. Random geometric networks are not small worlds and that fact leads to the existence of long paths between nodes that need to be stored in $\mathcal{F}^{\rm reg}$.
When non-dominated paths are found, $\mathcal{F}^{\rm reg}$ needs to be updated, which can be a quite complex process, leading to the supra-linear execution time of the entire algorithm. It is likely that the efficiency of the proposed algorithm can be improved with a better data-structure for $\mathcal{F}^{\rm reg}$, but since our implementation is clearly polynomial in the number of nodes, we leave such improvements for future work. 


\section{Mutipartite entanglement distribution}

The proposal made so far can be combined with the work developed in~\cite{Bugalho2021}, which aimed at establishing simultaneous entanglement between more than two nodes. Specifically, we will focus on three-partite entanglement distribution, for which the scheme proposed in~\cite{Bugalho2021} is exact. As we already proved that our bipartite metrics are both monotonic and isotonic, we can guarantee the optimality of the paths. This is the first requirement to prove that the algorithm presented in~\cite{Bugalho2021} will converge to the optimal solution. The second step is to prove that the multipartite metrics, the fidelity and rate metrics for the multipartite state, are monotonic and label-isotonic w.r.t. the paths. For these metrics, instead of adding links to extend paths, one adds paths to form trees. In the specific case of a three-partite state, the tree connecting three terminals is also a star graph. The fidelity and rate metrics for a multipartite entangled state between  three terminal nodes, $\mathcal{T} = \{T_1,T_2,T_3\}$,  is given by~\cite{Bugalho2021}:
\begin{equation}
    f^{s}_{T} = \prod_{\tau \in \mathcal{T} } \frac{1+\gamma_{s\tau}}{4} +  \prod_{\tau \in \mathcal{T} } \frac{1-\gamma_{s\tau}}{4} + \prod_{\tau \in \mathcal{T}} \frac{\gamma_{c\tau}}{2}   
    \label{eq:multirate}
\end{equation}
where $s$ is the source node. As before, the Werner parameter $\gamma_{s\tau}$ relates to the fidelity trough Eq.~(\ref{eq:f_vs_gamma}).  Following the analyses in~\cite{Bugalho2021}, the fidelity of each star is both monotonic and label-isotonic, meaning that if any of the fidelities of each path increase, so does the fidelity of the multipartite state. Therefore, given Eq.~(\ref{eq:multirate}) and the fact that the $\gamma$ functions are monotonically decreasing with the rate, the most efficient way to generate the multipartite state would be having the same rate for each path. This would maximize the overall fidelity and minimise losses from having different rates. Given this, for every point of $F_{ijk}(c)$, the metric is trivially monotonic and label-isotonic, allowing us to use the previous dominance relation for the case of trees, which are characterized by a $F_{ijk}(c)$. Therefore the optimal tree can be found by solving the equation

\begin{align}
    f_{T}(c_{T}) = &\max_{s,c_1,c_2,c_3} 
    \frac{1}{2}\Bigg[ \prod_{\tau \in \mathcal{T} }  \frac{1+\gamma_{s\tau}(c_1)}{2} +\nonumber\\
    & \prod_{\tau \in \mathcal{T} } \frac{1-\gamma_{s\tau}(c_2)}{2} + \prod_{\tau \in \mathcal{T}} \gamma_{c_3\tau}(c_3) \Bigg],\\
    c_{T}=&\begin{cases}
c_1 c_2 c_3~&\text{single}\\
 \min\{c_1,c_2,c_3\}&\text{ flow}\\
\end{cases}
    \label{eq:multifidelity}
\end{align}

where the Werner parameter $\gamma_{s\tau}$ can be computed using Algorithm \ref{alg:SPT} and Eq.~(\ref{eq:f_vs_gamma}). 

   \begin{algorithm}[tb]
   \caption{Multiparty routing: Source-to-Targets}\label{alg:Tree}
    \begin{algorithmic}[0]
        \State
        \State {\bf{Data structures}}
         \State  $\mathcal{F}^{\rm star}$ representing the concatenation of all non-dominated stars from a source to the three target nodes.
         \State
        \Function{StarSelection}{$T_1,T_2,T_3$}
        \State  Initialize $\mathcal{F}^{\rm star}$ as set of $F_{\rm null}$.
        \State  $\mathcal{F}1^{\rm reg}=\mathcal{F}^{\rm reg}(T_1)$ from Algorithm \ref{alg:SPT}
        \State  $\mathcal{F}2^{\rm reg}=\mathcal{F}^{\rm reg}(T_2)$ from Algorithm \ref{alg:SPT}
        \State  $\mathcal{F}3^{\rm reg}=\mathcal{F}^{\rm reg}(T_3)$ from Algorithm \ref{alg:SPT}
        \For{$s$ in all nodes of the network}
        \State  $F1=\mathcal{F}1_{s}^{\rm reg}$
        \State  $F2=\mathcal{F}2_{s}^{\rm reg}$
        \State $F3=\mathcal{F}3_{s}^{\rm reg}$
        \State Compute $F^{star}$ from $F1$,$F2$ and $F3$ using Eq.~(\ref{eq:multifidelity}).
        \State Update $\mathcal{F}^{\rm star}$ with a concatenation of $F_{123}$ and $\mathcal{F}^{\rm star}$
         \EndFor               
        \EndFunction
        \Return $\mathcal{F}^{\rm star}$
    \State
    \State{\bf{Abbreviations}}
    \State{$F_{\rm null}$ is a function defined as $F_{\rm null}=0$ for any capacity.}
    \end{algorithmic}
\end{algorithm}

Assuming that we already found the optimal fidelity-curves between any two nodes in the network,  one can easily find the fidelity-curve associated with multipartite entanglement distribution for a given source node and any tree nodes. What is left for us to do is to test all possible source nodes, as implemented in Algorithm \ref{alg:Tree}, suggesting  that the run time of such an approach will grow linearly with the number of nodes in the network. Fig.~\ref{fig5} shows the run time as a function of the number of nodes in our implementation. In most cases, the run time is either linear or slightly sub-linear, with the exception of the  single ebit distribution model in random geometric graphs, which exhibits an almost constant run time with respect to the number of nodes. This is due to the small number of valid paths connecting two nodes in such model. 

\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\textwidth]{figure_5.pdf}
    \caption{{\bf Algorithm~\ref{alg:Tree} complexity analysis}. Simulation of three-partite entanglement distribution for photonic quantum networks in an \er network (ER) and a random geometric graph (RGG) topology, an average degree $\langle k \rangle=10$ for the single, (a-b), and flow, (c-d), distribution models. Each link is characterized by three parameters: $\epsilon$, the dark count $p_{\rm dark}$, and $\beta$, randomly assigned from uniform distributions $U(0.3, 0.4)$, $U(0,{10}^{-3})$, and $U(0,{10}^{-3})$, respectively. (a-b) show the total execution time of the algorithm as a function of the number of nodes for the same  networks. (b-d) show the same information for the flow distribution model. The computational complexity in each case is estimated using a fit (dashed lines) of the type $Y=k X^\alpha$, where $k$ is an overhead constant, and $\alpha$ measures the computational complexity of the algorithm. The shaded region around each point represents its variance based on 15 samples.
    \label{fig5}}
\end{figure}


\section{Relation to previous works and Future directions}
With the increasing number of work on entanglement distribution and different models considered, it is useful to list some previous models  that can be addressed using our approach and models that cannot. Our methodology can be seen as a generalization of previous methods that search for the best path between a set of nodes that optimize one or multiple discrete parameters~\cite{sarasantos,Bugalho2021,PhysRevA.100.052333,Pirandola2019,Bauml2020}.
However, the proposed algorithm cannot be used to find the combination of paths that maximizes the entanglement distribution rate from a source to a target \cite{chakraborty2020entanglement,Bauml2020,Pirandola2019} using multi-paths. Multi-path routing is often addressed using  a linear programming formulation and it provides several advantages \cite{Pirandola2019, dai2020optimal, chakraborty2020entanglement, Bauml2020}; not only it allows to address multi-path routing, but one can also apply it to the scenario of multiple-sources to multiple-targets.
Unfortunately, to the best of our knowledge, our problem cannot be formulated as a linear programming one, and that is the biggest drawback of using linear programming for entanglement routing: the amount of detail one can add becomes restricted by the need of formulating the problem as a linear optimization one. Nevertheless, in our approach one can add as much detail as needed, provided that one can still define monotonic and isotonic routing metrics. An interesting way to merge these two directions would be to reformulate our work as non-linear programming problem.

The current proposal, in its present form, cannot also be used for entanglement distribution flow models with a non-deterministic swapping protocols~\cite{ghaderibaneh2022efficient,dai2020optimal}. It was shown in \cite{dai2020optimal} that, when non-deterministic swapping entanglement is considered, the distribution rate will depend on the swapping order, making the problem considerably harder. In terms of future directions, it would be interesting not only to consider  non-deterministic swapping protocols but also to include purification.
Purification combines multiple ebits pairs to generate a lower number of qubits with higher fidelity. Complex repeater protocols use rounds of  purification and swapping in order to distribute entanglement over large distances. To do this one needs to consider the different order in which the purification and swapping are applied, making the problem much harder to track, and likely it will  require a more complex routing algebra.  We leave the incorporation of non-deterministic swapping  and complex quantum repeater protocols for future works. 

\section{Conclusions}
This paper considered multipartite entanglement distribution for a quantum network connected through quantum photonics channels which hold a trade-off between entanglement generation rate and fidelity. Two entanglement distribution models were considered one where only one ebit is sent each time, and a second so-called flow model, where a large number of  ebit is distributed simultaneously. It was proposed and shown that fidelity curves can be used as a routing metric in both scenarios in combination with a multi-objective optimization algorithm. The proposed algorithm finds the best path (or best star) connecting two nodes (or three nodes) in close to linear time. The proposed method is easily adaptable and it can be used to solve routing problems over several previous quantum network models \cite{sarasantos, Bugalho2021, PhysRevA.100.052333, Pirandola2019}. 
How to incorporate multiple multi-path routing \cite{Pirandola2019,dai2020optimal,chakraborty2020entanglement,Bauml2020} and  non-deterministic swapping  in our approach is still an opening problem. We believe our works paves the way for entanglement distribution for networks with complex repeater-and-purify protocols since those display a trade-off between the entanglement generation rate and fidelity that is similar to the one in our model.\\
%
\\
{\bf{Author contributions:}} BC and FM contributed to the development of the initial concept and to the writing of the manuscript. BC, RM,  and LB contributed to the analytical calculation, proofs, and demonstration of  the project. RM and LB performed the network simulations. BC performed the data analysis of the results. \\
%
\\
{\bf{Competing interests:}} The authors declare no competing interests.\\
%
\\{}
{\bf{Data availability:}}  All data in this work are available from the corresponding author on request.\\
\\{}
{\bf{Code availability:}}  All codes in this work are available from the corresponding author on request.\\
\\{}
{\bf{Acknowledgements:}} This work has been funded by Instituto de Telecomunicações and Fundação para a Ciência e Tecnologia/Ministério da Ciência, Tecnologia e Ensino Superior (FCT/MCTES), Portugal, through National Funds co-funded European Union (EU) Funds under Project UIDB/50008/2020. The work has also been funded by the project Quantum Internet Alliance (QIA) of the European Union's Horizon 2020 research and innovation program under grant agreement No 820445. BC thanks the support of FCT through projects CEECINST/00117/2018/CP1495 and 2022.05558.PTDC. RM was supported by Fundação Calouste Gulbenkian through the Program New Talents in Quantum Technologies. LB acknowledges the support of FCT through scholarship BD/05268/2021. \\

\bibliography{sample.bib}

\appendix
\section{Optimally of sequential concatenation of fidelity curves in the single ebit distribution model}
\label{optimality_0}

We want to prove that the sequential concatenation of fidelity curves in the single ebit distribution  model always leads to the optimal solution. In a network, nodes are typically labeled by numbers, and pairs of nodes are used to identify edges, but here, to simplify the notation, one will consider a path $P$ with edges labeled numerically as $0,1,2,3,...L-1$, where $L$ is the length of the path. The optimimal solution is described by:
\begin{align}
    \gamma_{P}^{\rm sg}(c^{\rm sg})&=\max_{\{c_{i}\}} \prod_{i =0}^{L-1}
    \gamma_{i}(c_{i}), \label{Eq:iso1}
\end{align} 
with the constraint 
\begin{align}
    c^{\rm sg}=\prod_{i =0}^{L-1} c_{i}.
\end{align} 
This constraint can be easily incorporated in Eq.~(\ref{Eq:iso1}),  by rearranging the constrain as $c_0=c^{\rm sg}/\prod_{i =1}^{L-1} c_{i}$, and we obtain,
\begin{align}
    \gamma_{P}^{\rm sg}(c^{\rm sg})&=\max_{\{c_i\}} \left[ \gamma_{0}\left(\frac{c^{\rm sg}}{\prod_{i =1}^{L-1}c_{i}}\right) \prod_{i =1}^{L-1} \gamma_{i}(c_{i})\right]\label{Eq:iso2},
\end{align} 
where we added the constraint to edge $0$, but one can add the constraint to any other edge. Now that we know how to write the optimal solution for the fidelity curve in \eqref{Eq:iso1}, let us consider the concatenation of a path  $0$ and a path $1$, which can be written as,
\begin{align}
   \gamma^{\rm sg}(c_{01}^{\rm esg})  &=\max_{c_{0},c_{1}} \left[ \gamma_{0}(c_{0}) \gamma_{1}(c_1)   \right] \label{Eq:iso3}
\end{align} 
with the constraint
 \begin{align}
     &c_{01}^{\rm sg}:=c_0c_1. 
\end{align} 

Using the same approach as before, we can include this constraint into Eq.~(\ref{Eq:iso3}), and obtain
\begin{align}
   \gamma^{\rm sg}(c_{01}^{\rm sg})  &=\max_{c_{1}} \left[ \gamma_{0}\left(c_{01}^{\rm sg}/c_1\right) \gamma_{1}(c_1)   \right]. \label{Eq:iso2}
\end{align} 
Using the new notation for paths defined above, the concatenation of path $01$ with edge $2$ is given by 
\begin{align}
   \gamma^{\rm sg}(c_{012}^{\rm sg})  =&\max_{c_1} \left[ \gamma_{01}\left(\frac{c_{012}^{\rm sg}}{c_2}\right) \gamma_{2}(c_2)   \right]= \\
                                     &\max_{c_{1}} \left[ \gamma_{0}\left(\frac{c_{012}^{\rm sg}}{c_1 c_2}\right) \gamma_{1}(c_1)\gamma_{2}(c_2)\right].
   \label{Eq:iso2}
\end{align} 
Repeating this process until edge $L-1$, one obtains Eq.~(\ref{Eq:iso3}), proving the sequential concatenation of paths in the single ebit distribution model leads to the optimal fidelity curve.  

\section{Optimal link capacity in the flow distribution model}
\label{optimality_1}
In this section, we determine the optimal capacity of each link in a  quantum repeater chain for our model. In general, we can write a system of two equations to describe the fidelity in the flow distribution model, as
\begin{align}
    &\gamma_{P}(c_{P})=\max_{\{c_e\}}\prod_{e \in P} \gamma_{e}(c_{e}), \label{eq:appendex_0} \\
    &c_{P}=\min_{e \in P} c_{e}   \label{eq:appendex_1}
\end{align} \par 
\noindent where $P$ is a path connection nodes $i$ and $j$.
One wants to prove that is fidelity curve is a monotonically decreasing function, and the optimal solution to this set of equations, i.e., a solution that maximizes the Werner parameter $\gamma_{P}$ for a given rate $r_{P}$, is for all link to operate at a capacity equal to the entanglement distribution rate $c_{e}=c_{P}$, for all value of $e$. Let us call this the uniform solution. We will now prove that the uniform solution is optimal using proof-by-contradiction. Let us consider a solution of Eqs.~(\ref{eq:appendex_0})-(\ref{eq:appendex_1}) $\{c'_e\}$, with the same  entanglement distribution rate as the uniform solution $c_{e}=c_{P}$, but a larger Werner parameter, i.e.
\begin{align}
    \prod_{e \in P} \gamma_{e}(c'_{e})> \prod_{e \in P} \gamma_{e}(c_{P})\\\implies
    \prod_{e \in P} \frac{\gamma_{e}(c'_{e})}{\gamma_{e}(c_{P})}> 1
    \label{contradic:appendex_1}
\end{align} 
Since the entanglement distribution of our optimal solution is $c_{P}$ we know that  at least one link operates  at capacity $c_{P}$, and all others operate at a capacity equal or larger, $c'_{e}\leq c_{P}$.  Assuming that  fidelity curves are monotonically decreasing functions (as we do in the work) the $\gamma$-value of a link operating at a capacity $c_{P}$ is larger or equal to the $\gamma$-value of that same link operating at a capacity $c'_{e}$. One can conclude that $\gamma_{e}(c'_{e})\leq \gamma_{e}(c_{P}) \implies \gamma_{e}(c'_{e})/\gamma_{e}(c_{P})\leq 1$ for all $e$ in $P$, contradicting Eq.~(\ref{contradic:appendex_1}).

\end{document}






