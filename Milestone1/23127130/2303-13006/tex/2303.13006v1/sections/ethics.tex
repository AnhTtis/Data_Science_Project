\section{Ethical concerns and biases} \label{sec:ethics}

All individuals portrayed in this paper provided informed consent to use their images as test images. This was not possible for the images from the FFHQ~\cite{stylegan}, LFW~\cite{lfw}, AgeDB-30~\cite{agedb}, and CFP-FP~\cite{cfpfp} data sets. Therefore, we do not show them in the paper.

Our model inherits the biases of both the face recognition model and the training data set. This can manifest as either accessorizing images corresponding to certain demographic factors (\eg via make-up, clothing) or losing identity fidelity for underrepresented groups. This suggests an additional application of our work to the study of systematic biases in otherwise black-box systems.

We recognize the potential for misuse of any method that creates realistic imagery of human beings, especially when the images are made to correspond to specific individuals.  We condemn such misuse and support ongoing research into the identification of artificially manipulated data.
