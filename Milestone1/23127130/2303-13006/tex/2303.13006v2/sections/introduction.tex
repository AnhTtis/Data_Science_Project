\section{Introduction} \label{sec:intro}

Face recognition (FR) systems are omnipresent. Their applications range from classical use cases such as access control to newer ones such as tagging a picture by identity or controlling the output of generative models~\cite{smoothswap, simswap, latent_space_mapping}. The goal of an FR method $f$ is to obtain embeddings $\mb{y}$ of face images $\mb{x}$ such that the embeddings of images of the same person are closer to each other than those of images of other people. We refer to this embedding $\mb{y}$ as the \emph{identity vector} or \emph{ID vector}. In this paper, we propose a technique to sample from $p(\mb{x}|\mb{y})$, \ie to produce realistic face images from an ID vector.

By design, the many-to-one mapping of FR methods assigns multiple images of a given identity to the same ID vector. The inverse one-to-many problem, \ie producing a high-dimensional image from a low-dimensional ID vector, is extremely challenging. Previous methods often rely on the gradient of FR models either directly~\cite{DBLP:journals/corr/ZhmoginovS16} or use it during training in the form of a loss function~\cite{cole, latent_space_mapping}. This gradient or information about the model's architecture and weights is often not available, \eg if using an API of a proprietary model. We therefore focus on the more generally applicable \emph{black-box} setting, where only the resulting ID vectors are available. 
In addition to being more general, the black-box setting simplifies the analysis of different FR models as explored in the supplementary material. Another benefit is that we can easily extend our conditioning mechanism to include information from different, even non-differentiable, sources (\eg labels, biological signals).


We propose the \underline{id}entity \underline{d}enoising \underline{d}iffusion \underline{p}robabilistic \underline{m}odel (ID3PM), the first method that uses a diffusion model (DM) to invert the latent space of an FR model, \ie to generate identity-preserving face images conditioned solely on black-box ID vectors as seen in \cref{fig:teaser_small}. We show mathematically that we can effectively invert a model $f$ even without access to its gradients by using a conditional DM. This allows us to train our method with an easy-to-obtain data set of pairs of images and corresponding ID vectors (easily extracting from images) without an identity-specific loss term. 

Our method obtains state-of-the-art performance for the inversion task and is, to the best of our knowledge, the first black-box FR model inversion method \underline{with} control over the generation process as seen in \cref{fig:teaser_small}. 
Specifically, we can control (1) the diversity among samples generated from the same ID vector via the classifier-free guidance scale, (2) identity-specific features (\eg age) via smooth transitions in the ID vector latent space, 
and (3) identity-agnostic features (\eg pose) via explicit attribute conditioning.


To summarize, our main contributions are:
\begin{enumerate}[itemsep=-2pt,topsep=2pt]
    \item Showing that the conditional diffusion model loss naturally emerges from an analysis of the black-box inversion problem.
    \item Applying the resulting framework to invert face recognition models without identity-specific loss functions. 
    \item Demonstrating state-of-the-art performance in generating diverse, identity-preserving face images from black-box ID vectors.
    \item Providing control mechanisms for the face recognition model inversion task.
\end{enumerate}
