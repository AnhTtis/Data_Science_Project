\section{Conclusion} \label{sec:conclusion}

We propose a method to generate high-quality identity-preserving face images by injecting black-box, low-dimensional embeddings of a face into the residual blocks of a diffusion model. We mathematically reason and empirically show that our method produces images close to the target identity despite the absence of any identity-specific loss terms. Our method obtains state-of-the-art performance on identity preservation and output diversity, as demonstrated qualitatively and quantitatively. We further showcase advantages of our approach in providing control over the generation process. 
We thus provide a useful tool to create data sets with user-defined variations in identities and attributes as well as to analyze the latent spaces of face recognition methods, motivating more research in this direction.
