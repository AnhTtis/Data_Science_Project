\section{Limitations} \label{sec:limitations}

Our method outputs images at a relatively low resolution of $64 \times 64$. While this can be upsampled using super-resolution models, some fine identity-specific details such as moles cannot be modeled currently (but this information might not even be stored in the ID vector). Our method also has relatively long inference times ($15$ seconds per image when using batches of $16$ images on one NVIDIA RTX 3090 GPU) in the default setting, but this can be reduced to less than one second per image when using $10$ respacing steps at a slight decrease in quality as shown in the supplementary material. Our method also occasionally has small image generation artifacts, but the above aspects are expected to improve with future advancements in diffusion models. Lastly, our model inherits the biases of both the face recognition model and the training data set. This can manifest as either accessorizing images corresponding to certain demographic factors (\eg via make-up, clothing) or losing identity fidelity for underrepresented groups as shown in the supplementary material. This suggests an additional application of our work to the study of systematic biases in otherwise black-box systems.
